{
    "paper_title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
    "authors": [
        "Pingyue Zhang",
        "Zihan Huang",
        "Yue Wang",
        "Jieyu Zhang",
        "Letian Xue",
        "Zihan Wang",
        "Qineng Wang",
        "Keshigeyan Chandrasegaran",
        "Ruohan Zhang",
        "Yejin Choi",
        "Ranjay Krishna",
        "Jiajun Wu",
        "Li Fei-Fei",
        "Manling Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing, which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap, where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia, where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models. Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial beliefs during active exploration."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 4 ] . [ 1 5 5 0 7 0 . 2 0 6 2 : r Published as conference paper at ICLR THEORY OF SPACE: CAN FOUNDATION MODELS CONSTRUCT SPATIAL BELIEFS THROUGH ACTIVE EXPLORATION? Pingyue Zhang1,,, Zihan Huang, Yue Wang4,, Jieyu Zhang3,, Letian Xue1, Zihan Wang1, Qineng Wang1, Keshigeyan Chandrasegaran2, Ruohan Zhang2, Yejin Choi2, Ranjay Krishna3, Jiajun Wu2, Li Fei-Fei2, Manling Li1, 1Northwestern University 2Stanford University 3University of Washington 4Cornell University pingyuezhang@u.northwestern.edu, manling.li@northwestern.edu Equal contribution Corresponding author"
        },
        {
            "title": "ABSTRACT",
            "content": "Spatial embodied intelligence often operates under partial observability, where agents must act to acquire missing information rather than passively consume complete observations. In such settings, progress depends on actively selecting informative actions that reduce uncertainty and support the construction of spatial understanding. While multimodal foundation models have shown strong performance on passive multimodal perception and reasoning tasks, their ability to support active, self-directed exploration under partial observability has not been systematically studied. In particular, it remains unclear whether and how these models can decide what to observe next in order to build and maintain coherent spatial belief over time. We therefore propose THEORY OF SPACE, defined as an agents ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit spatial belief from sequential, partial observations. We implement THEORY OF SPACE using benchmark with textual and visual environments. Rather than solving specific tasks, the goal is curiositydriven exploration to build complete, accurate spatial belief. core innovation is spatial belief probing: we prompt it to reveal its internal spatial belief as cognitive map at each step, letting us measure the quality of its underlying spatial model. Our evaluation of state-of-the-art models on suite of downstream tasks reveals critical bottlenecks: (1) The Active-Passive Gap: Performance degrades when agents must autonomously gather information (e.g., GPT-5.2: 0.570.46); (2) Inefficiency: Models explore in an unsystematic way and with high redundancy, failing to match the efficiency of program-based proxies while producing no better results. Through belief probing, we diagnose that perception acts as an initial bottleneck, yet global beliefs suffer further from instability that causes spatial knowledge to degrade over time. Finally, using false belief paradigm to test belief revision, we uncover Belief Inertia where agents fail to overwrite obsolete priors. This issue exists in text agents but is notably severe in vision-based models. (cid:128) Website Code ı Data https://theory-of-space.github.io/ https://github.com/mll-lab-nu/Theory-of-Space https://huggingface.co/datasets/MLL-Lab/tos-data"
        },
        {
            "title": "INTRODUCTION",
            "content": "Spatial embodied intelligence relies on active exploration. Unlike disembodied systems that passively process fixed observations, an embodied agent could take actions to alter its position in the environment as exploration, selectively acquiring observations needed to construct spatial knowledge for various spatial tasks. Cognitive science shows that such active exploration leads to substantially better spatial understanding than passively receiving the same information, even when observations are identical (Held & Hein, 1963; Chrastil & Warren, 2012; 2013). But exploration isnt simply 1 Published as conference paper at ICLR 2026 Figure 1: THEORY OF SPACE: active exploration, probed belief, and evaluation. Left: top-down view of agent trajectory under partial observability in multiple-room scenes. Middle: the agents action loop of moving, rotating, and observing in textor vision-based environments, receiving egocentric observations and updating an internal belief. Right: evaluation through exploitation of the belief in spatial tasks and direct probing via probed cognitive maps. about collecting more observations. It is about efficiency, acting under uncertainty to target what is unknown or ambiguous in the agents spatial belief and maximize information gain. We propose THEORY OF SPACE as framework that explicitly treats exploration as first-class decision-making problem, decoupled from any single downstream task, focusing on opening the box of the agents internal spatial belief. Just as Theory of Mind (ToM) measures how agents model the hidden mental states of others, THEORY OF SPACE assesses an agents ability to model the hidden physical structure of the world. We define THEORY OF SPACE as an embodied agents ability to actively construct, revise in dynamic environment, and exploit an internal spatial belief formed through active exploration. Beyond end-task evaluation, THEORY OF SPACE directly probes what the agent knows, what remains uncertain, and how effectively its actions reduce those uncertainties, measured by the number of exploration steps and the uncertainty resolved per action. Figure 1 provides an overview of THEORY OF SPACEs active exploration, belief probing, and end-task evaluation. We apply THEORY OF SPACE to evaluate multimodal language models, which are promising candidates for embodied agents. By integrating vision and language, they support unified perception, reasoning, and action over time, yet existing foundation-model benchmarks offer little insight into these capabilities. Most current benchmarks fall into two categories: passive (Weston et al., 2015; Shi et al., 2022; Yang et al., 2025c; Gholami et al., 2025; Yang et al., 2025a), where the agent is only asked to reason over given observations, and task-driven (Gordon et al., 2018; Shridhar et al., 2020b; Li et al., 2025; Yang et al., 2025b), where the agent must achieve specific goal (e.g., find the red chair). In this work, we propose to systematically evaluate the active process of spatial belief construction. Unlike passive benchmarks, our THEORY OF SPACE benchmark requires agents to actively explore via moving, rotating, and observing to build coherent global beliefs. We implement scalable environment using ThreeDWorld (Gan et al., 2021) and Objaverse (Deitke et al., 2022) that provides Text-based and Vision-based worlds to localize perception versus reasoning failures. After active exploration, we evaluate the process along two axes: (i) belief exploitation via spatial downstream tasks that probe route-level and survey-level knowledge (Siegel & White, 1975; Montello, 1998); and (ii) exploration efficiency via the number of exploration steps and the accumulated information gain curve over steps, capturing how quickly an agent reduces uncertainty rather than merely increasing coverage. Finally, we design scripted proxy agents that execute strong reference trajectories to disentangle exploration from reasoning. Our evaluation of state-of-the-art foundation models reveals both promising capability in the pure text world and striking limitations in the vision world under THEORY OF SPACE. Active exploration remains primary bottleneck. Models perform reasonablely well in passive setting, but degrade when they must actively gather information (e.g., 2 Published as conference paper at ICLR 2026 GPT-5.2: 57.1 46.0; GEMINI-3 PRO: 60.5 57.3; Figure. 2). We also find major efficiency gap: rule-based proxy agents reach target coverage in 9 steps, whereas foundation models explore redundantly, requiring 14 steps without improving belief accuracy. Thus, even when models can reason about spatial tasks (as reflected in passive performance), they fail to autonomously structure the information-gathering needed to solve them. Beyond downstream task scores, core contribution of THEORY OF SPACE is explicit cognitive-map probing, which provides direct window into the agents latent spatial belief as it is constructed and revised. Rather than treating the agent as black box whose internal state is only inferred from final answers, we prompt the model to expose its evolving cognitive map during exploration, enabling measurement of both belief accuracy and belief uncertainty at each step. This probingbased assessment uniquely supports finegrained diagnosis of how models represent space: it reveals that while perception acts as an initial bottleneck, global beliefs also suffer severely from instability, causing knowledge to degrade over time. This allows us to track belief evolution over time, attribute failures to specific representational breakdowns, and evaluate whether an agent truly knows what is uncertain rather than merely producing plausible outputs. Figure 2: Evaluation accuracy vs. exploration cost for active exploration in vision-world. Faded icons mark the passive setting, where the agent gets pre-generated exploration history and only reasons. Finally, to evaluate the mechanics of dynamic spatial updating, we introduce False Belief paradigm. By altering the environment (relocating or reorienting objects) after the agents initial exploration, we uncover phenomenon we term spatial belief inertia: agents (particularly in vision-based settings) struggle to overwrite obsolete spatial priors with new sensory evidence. Despite directly observing the new configuration, models persist in their initial, now incorrect coordinates. This reveals critical failure in spatial memory revision, where foundational models lack the plasticity to revise their internal cognitive maps in response to physical changes. An important direction for future work is to extend THEORY OF SPACE beyond single-agent settings to multi-agent exploration, where additional challenges arise around coordination and aligning (or sharing) spatial beliefs across agents."
        },
        {
            "title": "2 THEORY OF SPACE",
            "content": "To build agents with spatial intelligence, we argue for evaluating not merely passive reasoning, but the active, self-directed construction of spatial belief from partial observations. We introduce THEORY OF SPACE, conceptual counterpart to Theory of Mind (ToM). While ToM models hidden mental states of others, THEORY OF SPACE models uncertain, currently unobserved structure of space. [ Definition: THEORY OF SPACE Ability to construct, revise, and exploit an internal spatial belief. Here, an internal spatial belief is mental model (Taylor & Tversky, 1992) of spatial layout and relations maintained in working memory and updated from partial observations. We formalize THEORY OF SPACE within partially observable framework over spatial structure S. The agent interacts with to generate history ht = (o0:t, a0:t), where and denote observations and actions. We define THEORY OF SPACE as the capacity to manipulate probabilistic belief Bt through three core operations: 3 Published as conference paper at ICLR 1. Construct: To form globally consistent internal spatial belief by actively seeking out and integrating partial observations. Formally, the agent integrates ht to approximate the true posterior, denoted as Bt(S) (S ht). 2. Revise: To dynamically update the internal belief by using new information acquired through further exploration to resolve conflicts with prior beliefs. Upon an environmental shift S, the agent utilizes exploratory actions to minimize the divergence from the new ground truth, i.e., Bt+t (S ht+t). 3. Exploit: To utilize the current belief to support spatial tasks. The agent utilizes policy π conditioned on the belief, π(at Bt), to perform downstream task . In benchmark context, we measure the value of belief by the performance metric achieved by this policy: (π(Bt), )."
        },
        {
            "title": "2.1 A PARADIGM FOR ASSESSING THEORY OF SPACE OF LARGE FOUNDATION MODELS",
            "content": "We propose new paradigm for Assessing THEORY OF SPACE of large foundation models, which consists of three essential components below. Task-Agonistic Active Exploration to Move From Passive Viewer to Active Explorer. Evaluating THEORY OF SPACE requires shift from downstream tasks to exploration, i.e., how an agent explores and decides what to see next. In detail, we place the agent in partially observable environment and explicitly challenge the LLM/VLM agent to actively select actions for itself, including moving, rotating, observing, and terminating. The primary goal is not to complete downstream task or follow pre-collected trajectories, but to build general-purpose internal model from its own self-directed exploration with minimal cost. This process encompasses both initial Belief Construction and dynamic Belief Revision. Inspired by the false belief paradigm in Theory of Mind (Wimmer & Perner, 1983) and spatial belief revision (Knauff et al., 2013), we evaluate whether an agent can detect dynamic environmental changes and correctly revise its internal belief during exploration. This demonstrates the ability to customize beliefs given evolving observations. Consequently, the model must identify what remains uncertain and actively terminate exploration only upon acquiring sufficient evidence to form an accurate and responsive internal map. Belief Exploitation Assessment. To translate THEORY OF SPACE into concrete evaluation tasks, we draw insights from the development of spatial representations (Siegel & White, 1975; Montello, 1998) and define two tasks to measure an agents ability to exploit its internal belief for goal-directed behavior: (1) Belief on Route evaluates path-based understanding of space organized around landmarks such as pairwise spatial relationships along egocentric navigation; (2) Belief on Survey assesses map-like birds-eye view that represents space allocentrically, allowing for the inference of global relationships. Explicit Probing of the Internal Spatial Belief. Behavioral success such as whether the agent finds the chair cannot directly reveal the quality of agents internal model. We require the agent to explicitly represent its spatial belief by probing its cognitive map at any point of exploration. Cognitive maps are structured allocentric representations of space, which is well-established in neuroscience (Tolman, 1948; OKeefe & Dostrovsky, 1971; Hafting et al., 2005). Thus, we use cognitive maps as the canonical representation of the hidden structure of space. In our implementation, we probe the agents internal belief by requiring it to externalize structured cognitive map. We evaluate the maps Correctness, and we diagnose reasoning breakdowns with dynamic signals that capture how reliably observations are integrated, tracked over time, and kept coherent across local and global structure. Additionally, we explicitly test the agents belief on uncertainty by identifying unobserved regions to measure its uncertainty modeling. This shifts the evaluation from behavioral success to direct assessment of representational competence, giving us window into the agents spatial belief development."
        },
        {
            "title": "3 BENCHMARKING THEORY OF SPACE ABILITY FOR FOUNDATION MODELS",
            "content": "Unlike task-driven benchmarks that only test task completion, we aim to answer can the agent form global environmental belief through exploration?. We structure the benchmarking into two phases. In the Exploration Phase I, the agent interacts with the environment to construct spatial belief by selecting and executing actions in the action space in 3.1, and gather sequence of local 4 Published as conference paper at ICLR 2026 observations to integrate them into unified spatial belief. In the Reasoning Phase II, the agent is asked to conduct spatial tasks (detailed in 3.2)."
        },
        {
            "title": "3.1 SPATIAL ENVIRONMENT CONSTRUCTION",
            "content": "To ensure controlled experimentation, we procedurally generate multi-room indoor layouts on an grid. Each scene is populated with indoor objects, each assigned 2D integer coordinate and cardinal orientation from (N, S, E, W). The agent begins at random position, is informed of the total number of rooms and the names of all objects in the scene, and then starts exploration. Following the Gym-style interface (Brockman et al., 2016), we define procedurally generated, highly scalable environments in which each random seed deterministically instantiates distinct multi-room layout. Action Space in the Environment. The agents interaction with the world is designed to focus on high-level decision-making rather than low-level motor control: Goto to move directly to currently visible object; Rotate to turn in place by 90, 180, or 270; Observe to perceive visible objects in the 90 field of view; and Query to obtain visible objects absolute 2D coordinates. We additionally assign costs of 1 to Observe and 2 to Query, encouraging Query to be used only when necessary to resolve ambiguity. However, across all models Query is invoked only rarely, so we restrict attention to Observe and measure exploration efficiency by step count instead of action cost. Observation Feedback from Text-Vision Parallel Environment. We offer both text-based and vision-based environments, enabling diagnostic analysis of spatial reasoning. Each Observe action returns both textual and visual feedback from 90 field of view. The Text World provides symbolic observations with discrete bins for direction and distance (e.g., chair is front-left and near, detailed below), isolating pure spatial reasoning. The Visual World instead supplies ego-centric RGB images rendered in ThreeDWorld (Gan et al., 2021) with Objaverse assets (Deitke et al., 2022), requiring perception to recover spatial relations. To calibrate perception in the visual setting, we provide two reference images, indicating unit distance (1 grid unit) / angle (a 22.5 angular cone), and showing all objects with their names and canonical front orientation, respectively. Details are shown in Appendix A.1 Spatial Relation Representation. To ensure that agents perceive and communicate about space using consistent language across tasks and modalities, we discretize spatial relationships for directions and distances. For allocentric direction, we discretize into eight 45 bins aligned with the four cardinal and four intercardinal directions, denoted compactly as {N, NE, E, SE, S, SW, W, NW}. Each bin spans 45 around its heading (e.g., = [22.5, 22.5)). For egocentric direction, within 90 forward field of view (FOV), we use five labels: front-left [45, 22.5), front-slight-left [22.5, 0), front 0, front-slight-right (0, 22.5], and front-right (22.5, 45]. For distance, measured in map units independent of direction, we define six bins: same = 0, near (0, 2], mid (2, 4], slightly far (4, 8], far (8, 16], and very far (16, 32]. 3.2 DOWNSTREAM SPATIAL TASKS We use open-ended questions rather than multiple-choice questions to reduce the risk of knowledge leakage. Drawing on prior work (Siegel & White, 1975; Montello, 1998), we define tasks to evaluate an agents Route and Survey knowledge, shown in Table 1. Route belief captures how an agent encodes paths and spatial relations from an egocentric step-by-step perspective. Survey belief is map-like, allocentric representation. An overview of the tasks is present in Figure 3. 3.3 ASSESSMENT DIMENSIONS We define assessment dimensions that align with the core THEORY OF SPACE abilities: construction and revision are evaluated via exploration efficiency and belief quality, while exploitation is evaluated via task success. (D1) Belief Construction Efficiency. Measures how efficiently the agent collapses spatial uncertainty during exploration. We quantify this using normalized information gain metric, E. Let be the number of possible positions for any object at the start of exploration (a uniform prior), and let Ci be the number of positions for object that remain consistent with all observations gathered by the agent 5 Published as conference paper at ICLR 2026 Figure 3: THEORY OF SPACE exploitation task suite: it covers route-level egocentric reasoning and survey-level allocentric mapping. Route tasks evaluate path-based inference and egocentric observations. Survey tasks test global mapping, geometric transformation, and perspective conversion. Together they cover both local navigation reasoning and global spatial abstraction. Dynamic Group Belief on Route Belief on Survey Static Pairwise Relation (direction) report allocentric direction and distance from to B. Allocentric Mapping (alloc.map) predict global coordinates (and headings) for all objects. Forward Dynamics Perspective Taking (persp.take) output the observation from specified objects perspective. Action-to-View (act2view) given sequence of Goto/Rotate, predict the final observation (one object in FOV with ego direction/distance bins). Mental Rotation (ment.rot) predict the sequence of front-facing objects during 360 self-rotation. Location2View (loc2view) given global pose, predict the observation (one object in FOV with ego bins/distances). Backward Dynamics Perspective Decision (perc.dec) infer which objects perspective the agent is currently adopting. View-to-Action (view2act) recover an action sequence that produces target observation. View2Location (view2loc) localize the agent (and optionally orientation) from target observation under the map. Table 1: Task suite comparison: Route belief emphasizes egocentric, step-by-step path reasoning; Survey belief emphasizes allocentric mapping and novel view inference. (calculated by AC-3 algorithm). The efficiency is calculated as = 1 . This score ranges from 0 (no information gained, Ci = ) to 1 (all objects perfectly localized, Ci = 1). Note that it can also be used to calculate the accumulated information gain at each step. Information gain is mainly used in text-based environments, since vision-based environments have direct access log2 (cid:80)N i=1 log2 max(1,Ci) Published as conference paper at ICLR 2026 to scenes without such ambiguity. Therefore, for vision-based environments, we directly use node coverage to measure exploration efficiency. Belief Representation and Quality Assessment. core contribution of THEORY OF SPACE is disentangling spatial memory from spatial inference. We structurally decompose the probed cognitive map into two components: (D2) The Cognitive Map (Observed): Measures fidelity and coherent integration of observations over time. We evaluate using two criteria: (1) Correctness, alignment with ground truth, computed as composite of positional, directional, and facing accuracy; and (2) dynamic reasoning diagnostics, including Perception quality, Self-tracking, Stability, and Local Global Consistency, reflecting internal coherence such as the absence of contradictions within the relational graph and between maps and relations. (D3) The Uncertainty Map (Unobserved): Measures how well the agent models plausible hypotheses about unobserved regions. We assess Uncertainty Modeling by providing candidate set of positions formed by randomly sampled points from both observed and unobserved areas, and measuring the agents ability to identify valid locations via F1. This separation lets us diagnose whether failures stem from misestimating the observed world or from insufficient reasoning about what remains unobserved. (D4) Belief Revision. Measures the agents ability to revise its spatial belief under latent environment changes. We evaluate this using the False Belief task (5.3), where objects are covertly manipulated (translated or rotated) following the initial exploration. The agent must re-explore to detect these discrepancies; we measure the accuracy of these identified changes (both object identity and transformation type) using the F1 score. Furthermore, we introduce Belief Inertia to quantify whether belief revision remain biased toward obsolete priors. (D5) Belief Exploitation Success. Measures task success when the agent must utilize its spatial belief. For tasks involving spatial relations (direction, persp.take, action2view), we score direction and distance separately, awarding 0.5 for each correct component. For tasks that output coordinates (view2loc, alloc.map), we compute coordinate similarity score. 3.4 EXPLORATION STRATEGIES To rigorously evaluate spatial cognition, we distinguish between two capabilities: the ability to acquire information (exploration) and the ability to synthesize it (reasoning). We present two evaluation settings: (i) Active Exploration, where the agent must plan actions to reduce uncertainty, and (ii) Passive Comprehension, where the agent reasons over standardized logs generated by scripted proxies. Uncertainty-Driven On-Policy Exploration. We conduct active evaluation to understand agent ability in exploring the environment to gather necessary information in building spatial belief. In this setting, the evaluated agent must plan and execute its own information-gathering policy. At each step, the agent selects an action based on its observation history and current objective, then receives new observations (text or image). Exploration continues until the agent issues an exploration termination or reaches the step budget. Success requires balancing two goals: maximizing coverage of unknown relations while minimizing action cost. This setting directly reveals whether the agent can recognize what it does not yet know and actively reduce uncertainty through exploration. Passive Exploration via Scripted Proxy Agents. Evaluating THEORY OF SPACE requires disentangling two intertwined factors: how well an agent explores, and how well it reasons about the observations gathered. An agent may fail either due to suboptimal exploration policy (missing key evidence) or deficiency in integrating observations into coherent belief. To isolate the latter, we introduce proxy agents as an exploration control. In this setting, evaluated models are fed fixed stream of observations generated by proxy agent. By enforcing standardized exploration path, we eliminate variance caused by exploration failures, allowing for fair evaluation of core reasoning abilities across different architectures. We design two scripted proxies to provide standardized exploration logs. The SCOUT agent is used for visual environments, who rotates at each location to guarantee all objects are observed. Leveraging visual cues like distance, these compact logs are sufficient for accurate belief construction. The STRATEGIST agent is used for text environments, which 7 Published as conference paper at ICLR 2026 follows belief-driven edge-coverage policy and actively selects viewpoints to maximally reduce ambiguity in coarse symbolic observations. It is implemented with AC-3 constraint propagation to prune inconsistent hypotheses and ensure relations are uniquely determined. Implementation details for both agents appear in Appendix A.1."
        },
        {
            "title": "4 EVALUATION AND ANALYSIS",
            "content": "We evaluate set of state-of-the-art proprietary and open-source foundation models. They are evaluated on both passive and active settings described in 3.4. Unless otherwise specified for ablations, all experiments use three connected 6 6 rooms with 4 objects in each (total 12 objects). To enable like-for-like comparison between the text and vision settings, we instantiate identical room layouts across modalities. We use 384 384 images in the vision setting. We generate 100 scenes and create three questions per task per scene, yielding 3 9 100 = 2700 questions per setting. We mainly evaluate six foundation models: GPT-5.2 (OpenAI, 2025), GEMINI-3 PRO (Google, 2025), CLAUDE-4.5-SONNET (Anthropic, 2025), GLM-4.6V (Zhipu AI Team, 2025), QWEN3-VL (Bai et al., 2025) (235B-A22B-Thinking), and INTERNVL-3.5 (Wang et al., 2025) (241B-A28B). For closed-source reasoning models GPT-5.2, GEMINI-3 PRO, and CLAUDE-4.5-SONNET, we set the temperature to 1 and the maximum number of tokens to 32768. For all other models, we set the temperature to 0. INTERNVL-3.5 supports at most 10 images, so we omit it for the vision-based world setting. direction persp.take perc.dec. act2view view2act alloc.map ment.rot loc2view view2loc Methods Avg.step Route Survey Avg. Static (S) Dynamic (D) Static (S) Dynamic (D) Proprietary Models GPT-5.2 GEMINI-3 PRO CLAUDE-4.5 SONNET Open-source Models GLM-4.6V QWEN3-VL HUMAN HUMAN WITH TOOL Proprietary Models GPT-5.2 GEMINI-3 PRO CLAUDE-4.5 SONNET Open-source Models GLM-4.6V INTERNVL-3.5 QWEN3-VL HUMAN HUMAN WITH TOOL 17.2 13.6 19. 15.0 16.3 9.8 11.1 11.4 13.5 18.7 14.5 15.0 14.1 10.8 12.8 40.0 56.3 23.7 15.8 16.8 94.5 100.0 68.8 78.0 65. 20.8 28.8 32.3 87.8 100.0 Vision-based World 36.7 36.7 23.3 56.2 68.2 18.7 43.8 47.2 33.3 18.5 23.3 100.0 100. 3.3 13.4 100.0 100.0 Text-based World 14.0 24.8 100.0 100.0 70.5 79.2 65.3 19.7 44.8 45.7 82.1 100.0 80.3 90.6 79.0 12.7 26.0 48.2 100.0 100. 71.0 75.3 62.7 21.8 36.8 33.3 85.5 100.0 40.3 54.0 10.7 0.7 5.7 93.4 97.8 53.7 76.3 51.7 3.7 7.3 11.7 86.8 100. 43.4 63.5 37.4 18.9 25.8 93.4 100.0 77.9 81.0 68.8 13.9 31.0 36.4 66.6 100.0 59.7 73.0 34.7 8.0 16.3 100.0 100. 81.0 94.0 76.3 9.3 27.7 34.7 100.0 100.0 56.9 65.4 33.7 18.5 21.5 100.0 100.0 79.1 83.3 57.0 22.7 33.8 35.7 95.6 100. 37.8 52.2 50.9 31.8 43.7 86.7 93.4 66.0 76.2 67.0 26.2 38.9 49.9 75.8 91.2 46.0 57.3 29.6 14.4 21.3 96.4 99. 72.0 81.5 65.9 16.8 30.6 36.8 86.7 99.0 Table 2: Exploitation Performance (%) of Belief Construction via Active Exploration. Models autonomously plan actions and are evaluated on exploration cost, route-level reasoning, and surveylevel reasoning across textand vision-based environments. GEMINI-3 PRO leads every task and all reasoning metrics, while GPT-5.2 achieves the lowest exploration cost in text-world. Humans outperform in both settings, especially in vision. Humans can use instruments such as protractors and compasses to infer object positions precisely. Active Exploration Results. We evaluate models as active agents, where they must autonomously explore the environment to build their spatial belief and terminate the exploration process by their own. This setting tests the full THEORY OF SPACE pipeline, requiring the agent to simultaneously plan an efficient information-gathering trajectory, integrate observations, and maintain coherent cognitive map under uncertainty. The agents performance is measured by its Exploration Efficiency as shown in 3.3 and its final accuracy on the downstream spatial tasks. The agent has maximum of 20 exploration steps. Table 2 presents the active performance of the models, providing holistic view of their ability to translate curiosity into knowledge. Figure 4 illustrates information gain over 8 Published as conference paper at ICLR direction persp.take perc.dec act2view view2act alloc.map ment.rot loc2view view2loc Methods Proprietary Models GPT-5.2 GEMINI-3 PRO CLAUDE-4.5 SONNET Open-source Models GLM-4.6V QWEN3-VL Proprietary Models GPT-5.2 GEMINI-3 PRO CLAUDE-4.5 SONNET Open-source Models GLM-4.6V INTERNVL-3.5 QWEN3-VL Static (S) Dynamic (D) Static (S) Dynamic (D) Route Vision-based World Survey 47.3 63.8 47.3 11.5 20.8 84.5 82.7 73.0 22.3 36.7 40.8 35.0 36.3 33. 24.5 28.3 88.2 92.7 80.7 39.8 67.8 69.3 63.9 57.5 37.7 54.5 49.0 40.8 49.3 58.0 15. 19.0 4.7 22.7 16.7 Text-based World 2.7 4.7 97.0 97.0 90.7 25.0 42.7 56.5 89.0 87.5 77.7 25.3 41.2 50. 76.0 75.7 59.0 4.7 8.7 17.7 64.8 67.2 54.8 22.9 33.2 96.3 86.2 76.9 21.2 37.3 42. 83.3 85.3 58.3 11.7 21.7 98.3 91.3 74.3 9.0 19.3 40.3 50.3 70.4 44.7 20.0 27. 94.8 85.7 59.2 27.0 38.7 42.5 65.6 57.0 54.8 33.6 40.8 89.2 80.0 70.7 35.7 43.8 54. Avg. 57.1 60.5 43.1 16.7 24.9 90.4 86.5 73.6 23.4 37.4 45.6 Table 3: Exploitation Performance (%) of Belief Construction via Passive Observations. Models are evaluated as passive comprehension agents on Routeand Survey-level reasoning using standardized observation logs from scripted proxy explorers, decoupling exploration from belief construction across textand vision-based environments. GEMINI-3 PRO leads most tasks in the vision-based world and achieves the best overall average, while GPT-5.2 leads the text-based world and attains the best overall average. the course of the exploration turns. GPT-5.2 acquires substantial information early on, but its rate of gain slows in later turns, resulting in lower cumulative information gain than GEMINI-3 PRO and CLAUDE-4.5 SONNET. Moreover, none of the models achieves full coverage relative to the proxy agent. We benchmarked three human subjects across five text and five vision scenes. Humans consistently outperformed foundation models in both domains, particularly in vision. Intuitively, humans scored higher in vision than text as visual information is easier to process. With tools, they achieved near-perfect accuracy Passive Exploration Results. We evaluate models on trajectories generated by rule-based proxy agent to understand models core spatial reasoning ability regardless of its exploration strategy. The performance of various models in both text-based and vision-based environments is summarized in Table 3. As evaluated, the results show clear separation: GPT-5.2 and GEMINI-3 PRO lead by wide margin over other systems, particularly open-source models. substantial modality gap persists, with text performance far better than vision performance for all models. (cid:17) Key Findings: Modality Gap Modality Gap Exists: text significantly outperforms vision. Overall, active accuracies underperform the passive setting. Incomplete exploration leads to drops: Figure 4 shows that GPT-5.2 gathers information quickly but often terminates prematurely, leaving uncertainty and lowering active scores relative to passive. Compared to the strategist proxy, which achieves full certainty, models remain less thorough. second critical disparity is the efficiency gap. In the vision domain, the SCOUT proxy reaches target coverage in 9 steps, whereas autonomous models expend significantly more actions with no performance benefit. This inefficiency is further highlighted in the text domain. While our primary text experiments utilize the STRATEGIST proxy for maximum coverage, we additionally evaluated the SCOUT proxy in text world. The text-based SCOUT similarly averages 9 steps. When following these concise trajectories, GPT-5.2 and GEMINI-3 PRO achieve accuracies of 83.9 and 86.7, respectively. These scores surpass their active exploration performance (72.0, 81.5 for GPT-5.2 and GEMINI-3 PRO, as in Table 2), demonstrating that models perform better when guided by short, efficient proxy path than when exploring autonomously. Published as conference paper at ICLR 2026 Text-based World Methods 2-room 4-room pass. act. steps pass. act. steps GPT-5.2 92.3 77.8 GEMINI-3 PRO 86.7 80.6 6. 6.2 86.5 66.0 16.4 81.2 77.7 19.7 Vision-based World Methods 2-room 4-room pass. act. steps pass. act. steps GPT-5.2 59.3 51.5 10.8 52.6 40.3 23. GEMINI-3 PRO 58.3 57.8 6.6 56.2 51.5 19.7 Table 4: Exploitation Performance (%) for Multi-Room Settings (2-room and 4-room). pass. for passive avg acc, act. for active avg acc, steps for average steps. Different Room Settings. For the two best-performing models, GPT-5.2 and GEMINI-3 PRO, we further evaluate reasoning and exploration under different room configurations: four-room setting and two three-room settings. In the four-room setting, the main room connects to the other three rooms. Table 4 reports results across different room settings. As the number of rooms increases, exploration cost rises accordingly. For both GPT-5.2 and GEMINI-3 PRO, performance declines as the room number increases, and the activepassive performance gap widens with room number. Moreover, GEMINI-3 PRO requires nearly the same number of exploration steps in the text-only and vision-based environments. Detailed results are in Appendix B. Figure 4: Accumulated information gain over exploration steps in the text world. (cid:17) Key Findings: Active Exploration as the Bottleneck Performance and Efficiency Deficit: Active agents score lower than reasoning on rule based program histories, and explore less efficiently than the program. Incomplete Coverage: Active agent fails to achieve complete information coverage. Complexity-Widened Gap: The active versus passive difference grows with environment scale; GEMINI-3 PRO degrades least. Exploration Pattern Manual inspection of agent exploration histories reveals distinct behavioral patterns. For GPT-5.2, the active-passive performance gap stems from unsystematic exploration. Specifically, the agent tends to prioritize any newly discovered door, immediately jumping to inspect it and often leaving the current room partially unexplored. This is compounded by object omission and path redundancy. In contrast, GEMINI-3 PRO adopts more methodical rotate-and-scan strategy, scanning its surroundings before transitioning to new rooms, which is behavior mirroring the SCOUT proxy agent. Further examples are provided in Appendix C."
        },
        {
            "title": "5 HOW DO FOUNDATION MODELS MANAGE INTERNAL SPATIAL BELIEF?",
            "content": "In this section, we use the THEORY OF SPACE belief-probing mechanism (as proposed in 2.1) to diagnose how MLLMs manage internal spatial beliefs and move beyond treating the agent as black box. Figure 5 shows the example of how we probe the belief of agent at each exploration step 5.1 COGNITIVE MAP PROBING Instead of treating the spatial belief as black box, we probe the agents internal state to distinguish verifying known facts from hypothesizing about the unknown. The agent externalizes its belief via structured JSON containing Cognitive Map, which records objects currently or previously observed within the field of view. Representation. For consolidated map, the agent presents its belief as single, allocentric cognitive map serialized in structured JSON. The map maintains (i) global layout anchored to the agents initial pose, and (ii) local snapshot that records only the currently visible objects with the current pose as origin to diagnose immediate perceptual errors. 10 Published as conference paper at ICLR Figure 5: Internal Spatial Belief Probing. At each step, the agent executes an action, receives an observation, and updates its spatial belief. We probe this belief by prompting the agent to (i) output JSON-structured cognitive map of all observed objects and (ii) select the next unexplored position from top-down view given set of labeled candidate points. For clarity, the figure shows the probing process for single step. Metrics. We evaluate consolidated map using three complementary metrics. Positional accuracy (pos.acc) is the Euclidean similarity between predicted and true object coordinates: (K/N ) eRMSE/L, where RMSE is the root mean squared error between predicted and ground-truth object positions, is the RMS ℓ2-norm of the positions of all objects in the scene, and K/N is the coverage (the ratio of the number of predicted objects to the number of ground-truth objects N). Directional accuracy (dir.acc) is the accuracy of directional relationship between each pair of objects. Facing accuracy (facing.acc) is the fraction of objects whose predicted facing matches the ground truth. Using global and local belief representations, we compute set of diagnostic scores at each turn (all per-turn except Correctness, which is computed only at the final turn after termination). Unless noted, scores are averaged over turns and scenes: Correctness (final): Measures the accuracy of the agents terminal global spatial belief. At the last turn, we evaluate the predicted global map and report composite score given by the (equally weighted) mean of the three metrics defined above, with weights 1/3 each. We compute dir.acc only for correctness, since the global cognitive map prioritizes consistent pairwise spatial relations. Perception: Measures how accurately the agent interprets newly observed local structure. We compare the predicted local map to the ground-truth local map for the current field of view (FOV), counting only objects that appear in the FOV for the first time. Self-tracking: Measures how well the model estimates its own pose over time. We infer the agents pose from the predicted global map and compare it against the ground-truth agent state. Local Global consistency: Measures whether new local evidence is incorporated into the global belief coherently. Within the same turn, we compare local and global predictions to verify that newly perceived structure is integrated without contradictions. 11 Published as conference paper at ICLR 2026 ori. pos. overall ori. pos. ori. pos. ori. pos. ori. pos. Methods Correctness (%) Perception (%) Stability (%) Selftracking (%) Uncertainty (%) Local Global (%) Vision-based World 58.7 68.3 57.9 52.9 72.4 68.5 65.4 61.8 20.2 GPT-5.2 GEMINI-3 PRO 32. 42.0 62.5 32.2 52.1 33.5 43.8 GPT-5.2 91.0 GEMINI-3 PRO 92.5 75.1 75.5 80.0 81. 100 99.9 86.8 88.2 96.4 91.6 86.0 84.8 96.7 90.8 Text-based World 56.4 62.0 67.6 67.7 93.3 98.8 98.0 99.9 64.7 73.9 86.7 85. 53.7 70.2 64.5 79.2 Table 5: Spatial Belief Quality via Cognitive Map Probing. We measure final map correctness and turn-level perception, local global consistency, stability, self-tracking, and uncertainty in textvs. vision-worlds. ori. for orientation and pos. for position. Across models, vision lags text on all metrics, with the largest drop on orientation and stability. Stability: Measures whether beliefs about previously observed objects remain non-degrading over time. For each previously observed object, at every subsequent turn we check that its predicted state does not worsen; the per-check score is 1 if the prediction is no worse than in the previous turn. Results in Table 5 indicate substantial modality gap between vision and text: performance drops markedly in the vision setting across all metrics, not just belief Correctness. Self-tracking does not appear to be primary bottleneck, models can often maintain an accurate belief about their own pose. Perception remains key limitation for state-of-the-art models in visual world settings. In particular, recognizing an objects facing direction is especially challenging: agents frequently fail to infer orientation and achieve near-chance (or worse) facing Correctness. This weakness is consistent with Table 2, where agents perform poorly on perspective-taking tasks (about 36% accuracy). Stability & Decay. Crucially, the metric reveals that spatial beliefs are highly brittle not just for orientation, but also for position. While Perception scores indicate that models can capture local spatial details with reasonable accuracy, this initial fidelity fails to translate into final map Correctness. This performance gap highlights critical failure in state maintenance: even when objects are correctly perceived initially, the agent frequently overwrites these verified facts with incorrect predictions in subsequent turns. Thus, the low final Correctness stems not solely from perceptual errors, but from the cumulative effect of unstable belief updates, where valid spatial memories degrade over the course of the episode. (cid:17) Key Findings: Cognitive Map Failures (Orientation, Stability, and Belief Drift) Orientation Gap: Vision perception is bottleneck, especially for object orientation. Unstable Map: Beliefs about previously observed objects degrades over time. Belief Drift: New updates corrupt earlier correct perceptions, lowering final correctness. Cognitive Map Validation & Correlation. To validate the utility of the probed cognitive map and investigate whether it faithfully reflects the agents reasoning process, we first conducted two ablation studies: Sufficiency Test (Oracle Map): We conditioned the model on the ground-truth cognitive map before generating answers for evaluation. Performance rose to near-perfect levels ( 95% for both models in both worlds). This confirms that our cognitive map representation captures all necessary information for the tasks; performance bottlenecks stem from the agents inability to accurately construct the map, not the representation format itself. Alignment Test (Explicit Reasoning): We prompted the model to explicitly generate the cognitive map before answering the evaluation questions. This resulted in slight performance degradation compared to direct answering. These results reveal an externalization gap: the models latent internal spatial belief is richer or more accurate than the discretized JSON output it produces. While it is lossy compression of the agents true internal state, the explicit map remains strong diagnostic signal. We support this Published as conference paper at ICLR 2026 claim by computing the Pearson correlation between the agents cognitive map Correctness and downstream task performance. To ensure robust correlation, we calculate the average performance across five independent cognitive map runs for each sample. As shown in Table 6, belief correctness is consistently and positively correlated with downstream success in both modalities, with all correlations significant (p < .001). The association is stronger in vision (r=0.570/0.645) than in text (r=0.418/0.466). The stronger vision correlation suggests that perception-driven mapping errors and unstable belief updates more directly translate into task failures. Thus, we establish map probing as validated diagnostic proxy for failure analysis. While acknowledging that correlation does not imply causality, we treat the explicit map as robust, albeit conservative, signal for diagnosing reasoning breakdowns rather than definitive evidence. (cid:17) Key Findings: Maps as Diagnostic Proxy Lossy but Diagnostic: Though lossy compression, map correctness correlates significantly with downstream success, making it strong diagnostic signal."
        },
        {
            "title": "5.2 UNCERTAINTY MAP PROBING",
            "content": "To probe an agents ability to model uncertainty, we provide it with top-down view of the scene in which all objects are removed, and we overlay set of candidate points. These points are sampled randomly and include both previously observed and unobserved locations. The agents task is to identify which candidate points remain unobserved, thereby revealing its belief over unseen regions. Methods GPT-5.2 GEMINI-3 PRO Text (%) 41.8 46.6 Vision (%) 57.0 64.5 Table 6: Pearson correlation (r) between spatial-belief correctness and downstream evaluation performance. All correlations are significant (p < .001). Representation. The agent receives an empty top down map that shows only the candidate points and its current position, with no objects present. The agent must select the points that have not yet been observed. In the text based world, the top down map is represented as an symbolic grid, where different symbols denote the agent, gates, and candidate points. In the vision based world, all objects are removed and the agent instead receives top down image of the environment, check examples in Appendix A.1. We use F1 to evaluate selected points. We report Uncertainty scores in Table 5. GEMINI-3 PRO models uncertainty better than GPT-5.2 in both textand vision-based settings. These results help explain the information gain and cognitive map trends in Figure 6. GPT-5.2 achieves higher initial information gain (i.e., it ramps up faster), likely because it quickly commits to an explore-the-doors strategy. However, it generalizes poorly to unobserved regions, reflected by the subsequent plateau in Figure 6: additional steps yield little marginal gain. In contrast, although GEMINI-3 PRO improves more slowly at the beginning, its cognitive map accuracy continues to increase with exploration, suggesting it keeps collecting useful evidence and progressively resolving uncertainty. 5.3 BELIEF REVISION TASK Figure 6: Accumulated Information Gain and Cognitive Map Correctness over steps. Spatial intelligence requires not only mapping static environments but also maintaining beliefs under non-stationarity. Inspired by false belief protocols in developmental psychology (Wimmer & Perner, 1983; Baron-Cohen et al., 1985) and spatial belief revision (Knauff et al., 2013), we introduce dynamic perturbation task to probe the agents ability to discard obsolete priors and reintegrate new evidence. 13 Published as conference paper at ICLR Task Protocol. Following the initial exploration phase, we introduce discrete environmental shift: subset of = 4 objects are stochastically relocated or reoriented. The agent, retaining its memory (exploration history), must actively re-explore the environment to identify the state changes. This requires the agent to detect conflicts between its internal belief state and new sensory observations. Metrics. We evaluate performance along four complementary axes: Identification Accuracy (F1): How precisely the agent pinpoints which objects changed. We compute the F1 score for detecting the subset of objects whose position or orientation shifted. Average Steps: How efficiently the agent revises its beliefs to completion. We report Total Steps needed to identify all changes, and Redundancy Steps, defined as the number of steps taken after the last changed object has been observed. Ideally, Redundancy 0, indicating the agent recognizes when updating is complete. Belief Correctness: How accurate the updated beliefs are on the changed subset. We compute correctness as in 5.1, but restrict evaluation to changed objects to isolate the fidelity of reexploration. Belief Inertia: Whether updating remains systematically biased toward obsolete priors. To quantify attraction back to pre-shift beliefs, we test whether the residual error of the updated belief aligns with the direction of the old belief. For each shifted object i, let bold denote the pre-shift belief, bnew the post-revision belief, and gnew the post-shift ground truth. Define the gnew prior-offset and post-revision error vectors: vi = bold . We define positional inertia as gnew , ei = bnew i spos = vi ei vi + ϵ (cid:125) (cid:123)(cid:122) (cid:124) Directional alignment (cos θi) (cid:18) exp bnew 2 bold 2σ2 (cid:124) (cid:123)(cid:122) Proximity weight (wi) (cid:19) . (cid:125) Here cos θi is large when the remaining error after updating still points toward the obsolete location, while wi downweights such alignment when the belief has moved far from bold . We set σ to dynamic noise scale: the RMS localization error on the first re-observed unchanged objects during re-exploration; ϵ ensures numerical stability. Under unbiased updating, E[spos ] 0, whereas spos > 0 indicates systematic pull toward the obsolete prior. For orientation shifts, we (cid:1) , where ϕ denotes the predicted orientation. It flags measure inertia via sori failures to overwrite the obsolete facing direction. = 1(cid:0)ϕnew = ϕold i Table 7 corroborates the modality gap observed in previous sections: vision-based agents significantly underperform their text-based counterparts. This performance drop is characterized by increased exploration redundancy and lower accuracy in identifying changed objects. Notably, while belief inertia persists across both modalities, it is markedly more severe in vision-based agents, particularly regarding object orientation. Vision models frequently fail to overwrite their initial spatial memory, persisting with obsolete facing estimates despite new visual evidence. This also suggests that fine-grained orientation estimation remains critical bottleneck for visual spatial reasoning. (cid:17) Key Findings: Vision Deficiencies & Belief Inertia Vision-based Revision Failures: Vision agents suffer from excessive exploration redundancy and poor accuracy in identifying object shifts. Belief Inertia: Agents, especially vision-based ones, persist in obsolete spatial coordinates despite new observations. 14 Published as conference paper at ICLR 2026 Methods all red. Avg. Steps ori. pos. Identification (%) ori. Belief pos. ori. Belief pos. Correctness (%) Inertia (%) Text-based World GPT-5.2 GEMINI-3 PRO 6.92 7.79 GPT-5.2 GEMINI-3 PRO 13.06 10.29 0.55 0.18 6.20 3. 98.4 98.8 97.9 98.7 Vision-based World 14.3 23.9 68.0 82.5 89.5 91.8 16.7 30.3 69.7 72. 42.9 63.1 5.5 7.9 68.9 51.1 12.5 5.7 34.7 14.4 Table 7: Belief updating under environmental shifts. After relocating/reorienting k=4 objects, we evaluate change identification, re-exploration cost (including redundancy (red.)), and belief correctness/update in textvs. vision-worlds. Vision agents require more redundant steps and show severe orientation inertia, failing to overwrite obsolete facing beliefs despite new evidence."
        },
        {
            "title": "6 RELATED WORK",
            "content": "Passive Spatial Reasoning. Early paradigms treat spatial reasoning as static inference: given textual description, agents answer relational queries (Weston et al., 2015; Shi et al., 2022; Mirzaee et al., 2021; Li et al., 2024). Other benchmarks probe understanding from single image, asking for relative directions, topological relations, or metric attributes (Ma et al., 2024; Deng et al., 2025; Cheng et al., 2024; Chen et al., 2024; Liao et al., 2024; Kamath et al., 2023). Multi-view and video benchmarks raise difficulty by requiring cross-view integration, egocentricallocentric conversion, and temporal consistency (Yang et al., 2025c; Xu et al., 2025; Wu et al., 2025; Yeh et al., 2025; Gholami et al., 2025; Zhou et al., 2025b). Recent works explicitly adopt cognitive maps: VSI-Bench (Yang et al., 2025a) shows map formation improves video QA, and MindCube (Yin et al., 2025) demonstrates that predicting layouts boosts multi-view reasoning. While informative, these benchmarks remain disembodied, as agents reason only over pre-collected trajectories. Active Exploration for Spatial Understanding. Research has also examined agents that actively explore, but their exploration is usually tied to task-specific goals rather than building general spatial belief. Embodied question answering benchmarks evaluate agents by whether they can gather evidence to answer questions (Das et al., 2018; Gordon et al., 2018; Majumdar et al., 2024; Ginting et al., 2025; Ren et al., 2024). Instruction-following settings extend household tasks to long horizons and realistic scenes, often with dialog or language grounding (Shridhar et al., 2020b; Kim et al., 2024; Shridhar et al., 2020a; Puig et al., 2018; Padmakumar et al., 2022; Gao et al., 2022). Navigation benchmarks stress path execution and generalization across diverse environments (Anderson et al., 2018; Jain et al., 2019; Ku et al., 2020; Krantz et al., 2020; Nguyen & III, 2019; Wang et al., 2024; Zhao et al., 2025). Spatial reference tasks focus on grounding natural-language descriptions in embodied search (Qi et al., 2019; Zhou et al., 2025a), and manipulation (Jiang et al., 2023; Mees et al., 2022; Srivastava et al., 2022; Wu et al., 2023). While existing benchmarks incorporate active perception, they largely rely on task-driven foraging. This paradigm conflates the efficiency of environmental exploration with downstream task performance, often fostering brittle spatial representations that lack generalizability (Bonawitz et al., 2011). Beyond the above task-driven active exploration, EXCALIBURZhu et al. (2023) also considers task-agnostic exploration, but its RL training can induce goal leakage and encodes maps implicitly in policy weights. In contrast, we study zero-shot foundation-model agents with no environment-specific training for task-agnostic exploration, emphasizing exploration efficiency via minimal-cost uncertainty reduction (rather than coverage), and evaluating not only task success but also the belief construction process via explicit belief probing."
        },
        {
            "title": "7 CONCLUSIONS",
            "content": "We introduce THEORY OF SPACE, which asks whether foundation models can function as spatial agents under partial observability: not merely answering questions from fixed views, but actively acquiring information through self-directed exploration to construct, revise, and exploit an internal spatial belief. Building on this framing, we contribute new evaluation paradigm centered on task-agnostic active exploration, downstream spatial tasks for belief exploitation assessment, and 15 Published as conference paper at ICLR 2026 explicit probing of internal beliefs via cognitive-map externalization. We implement THEORY OF SPACE in multimodal environment that instantiates parallel textand vision-based worlds, enabling controlled diagnosis of failures across symbolic versus perceptual observation streams. key strength of this design is that it makes spatial belief measurable rather than implicit. By requiring models to externalize evolving cognitive maps and uncertainty over unobserved regions, THEORY OF SPACE evaluates more than end task accuracy: it reveals the correctness, internal consistency, and temporal dynamics of belief formation, and quantifies how localized mistakes propagate into global map corruption over time. Empirically, active exploration is major bottleneck: end-task performance drops and exploration is less efficient than passive viewing, with the gap widening as room complexity increases. Belief probes make these error sources explicit: in vision, perception error often appears early, and models also exhibit belief instability, where correct information is later overwritten or forgotten, cascading into inconsistencies and lower map fidelity. Finally, when environments change and previously held beliefs must be revised, models exhibit strong belief inertia. They fail to overwrite obsolete priors, and this inertia is especially pronounced for vision-based models, particularly for orientation and facing updates. Taken together, THEORY OF SPACE reframes spatial evaluation from can the model answer? to can the model build and maintain coherent, revisable spatial world model through efficient information gathering? We hope this benchmark and its belief-centric measurements provide foundation for developing models with (i) uncertainty-aware and efficient exploration policies, (ii) robust state/belief maintenance under long horizons, and (iii) reliable mechanisms for revising beliefs when the world changes."
        },
        {
            "title": "REFERENCES",
            "content": "Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sunderhauf, Ian Reid, Stephen Gould, and Anton Van Den Hengel. Vision-and-language navigation: Interpreting visuallygrounded navigation instructions in real environments. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 36743683, 2018. Anthropic. System card: Claude sonnet 4.5. https://assets.anthropic.com/ m/12f214efcc2f457a/original/Claude-Sonnet-4-5-System-Card.pdf, September 2025. System card (PDF). Shuai Bai, Yuxuan Cai, Ruizhe Chen, ..., and Ke Zhu. Qwen3-vl: The next generation multimodal llm from qwen / alibaba cloud. arXiv preprint, 2025. URL https://arxiv.org/abs/2511. 21631. Simon Baron-Cohen, Alan Leslie, and Uta Frith. Does the autistic child have theory of mind? Cognition, 21(1):3746, 1985. Elizabeth Bonawitz, Patrick Shafto, Hyowon Gweon, Noah Goodman, Elizabeth Spelke, and Laura Schulz. The double-edged sword of pedagogy: Instruction limits spontaneous exploration and discovery. Cognition, 120(3):322330, 2011. Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016. Boyuan Chen, Zhuo Xu, Sean Kirmani, Brain Ichter, Dorsa Sadigh, Leonidas Guibas, and Fei Xia. Spatialvlm: Endowing vision-language models with spatial reasoning capabilities. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1445514465, 2024. An-Chieh Cheng, Hongxu Yin, Yang Fu, Qiushan Guo, Ruihan Yang, Jan Kautz, Xiaolong Wang, and Sifei Liu. Spatialrgpt: Grounded spatial reasoning in vision-language models. Advances in Neural Information Processing Systems, 37:135062135093, 2024. Elizabeth Chrastil and William Warren. Active and passive contributions to spatial learning. Psychonomic bulletin & review, 19(1):123, 2012. Elizabeth Chrastil and William Warren. Active and passive spatial learning in human navigation: acquisition of survey knowledge. Journal of experimental psychology: learning, memory, and cognition, 39(5):1520, 2013. 16 Published as conference paper at ICLR Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, and Dhruv Batra. Embodied question answering. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 110, 2018. Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, and Ali Farhadi. Objaverse: universe of annotated 3d objects, 2022. URL https://arxiv.org/abs/2212.08051. Nianchen Deng, Lixin Gu, Shenglong Ye, Yinan He, Zhe Chen, Songze Li, Haomin Wang, Xingguang Wei, Tianshuo Yang, Min Dou, et al. Internspatial: comprehensive dataset for spatial reasoning in vision-language models. arXiv preprint arXiv:2506.18385, 2025. Chuang Gan, Jeremy Schwartz, Seth Alter, Damian Mrowca, Martin Schrimpf, James Traer, Julian De Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi Sano, Kuno Kim, Elias Wang, Michael Lingelbach, Aidan Curtis, Kevin Feigelis, Daniel M. Bear, Dan Gutfreund, David Cox, Antonio Torralba, James J. DiCarlo, Joshua B. Tenenbaum, Josh H. McDermott, and Daniel L. K. Yamins. Threedworld: platform for interactive multi-modal physical simulation, 2021. URL https://arxiv.org/abs/2007.04954. Xiaofeng Gao, Qiaozi Gao, Ran Gong, Kaixiang Lin, Govind Thattai, and Gaurav S. Sukhatme. IEEE Robotics and Dialfred: Dialogue-enabled agents for embodied instruction following. Automation Letters, 7(4):1004910056, 2022. Also available as arXiv:2202.13330. Mohsen Gholami, Ahmad Rezaei, Zhou Weimin, Yong Zhang, and Mohammad Akbari. Spatial reasoning with vision-language models in ego-centric multi-view scenes. arXiv preprint arXiv:2509.06266, 2025. Muhammad Fadhil Ginting, Dong-Ki Kim, Xiangyun Meng, Andrzej Reinke, Bandi Jai Krishna, Navid Kayhani, Oriana Peltzer, David D. Fan, Amirreza Shaban, Sung-Kyun Kim, Mykel J. Kochenderfer, Ali akbar Agha-mohammadi, and Shayegan Omidshafiei. Enter the mind palace: Reasoning and planning for long-term active embodied question answering, 2025. URL https: //arxiv.org/abs/2507.12846. Google. Gemini 3 pro: Model card. deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf, ber 2025. Model card (GA/preview update for Gemini 3 Pro). https://storage.googleapis.com/ NovemDaniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, and Ali Farhadi. Iqa: Visual question answering in interactive environments. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 40894098, 2018. Torkel Hafting, Marianne Fyhn, Sturla Molden, May-Britt Moser, and Edvard Moser. Microstructure of spatial map in the entorhinal cortex. Nature, 436(7052):801806, 2005. Richard Held and Alan Hein. Movement-produced stimulation in the development of visually guided behavior. Journal of comparative and physiological psychology, 56(5):872, 1963. Vihan Jain, Gabriel Magalhaes, Alexander Ku, Ashish Vaswani, Eugene Ie, and Jason Baldridge. Stay on the path: Instruction fidelity in vision-and-language navigation. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL), 2019. Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, Yanjun Chen, Li Fei-Fei, Anima Anandkumar, Yuke Zhu, and Linxi Fan. Vima: General robot manipulation with multimodal prompts. In Proceedings of the 40th International Conference on Machine Learning (ICML), 2023. arXiv preprint arXiv:2210.03094. Amita Kamath, Jack Hessel, and Kai-Wei Chang. Whats up with vision-language models? investigating their struggle with spatial reasoning. arXiv preprint arXiv:2310.19785, 2023. Taewoong Kim, Cheolhong Min, Byeonghwi Kim, Jinyeon Kim, Wonje Jeung, and Jonghyun Choi. Realfred: An embodied instruction following benchmark in photo-realistic environments. In ECCV, 2024. 17 Published as conference paper at ICLR Markus Knauff, Leandra Bucher, Antje Krumnack, and Jelica Nejasmic. Spatial belief revision. Journal of Cognitive Psychology, 25(2):147156, 2013. Jacob Krantz, Erik Wijmans, Arjun Majumdar, Dhruv Batra, and Stefan Lee. Beyond the nav-graph: Vision-and-language navigation in continuous environments. In European Conference on Computer Vision, pp. 104120. Springer, 2020. Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, and Jason Baldridge. Room-across-room: Multilingual vision-and-language navigation with dense spatiotemporal grounding. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020. Fangjun Li, David Hogg, and Anthony Cohn. Reframing spatial reasoning evaluation in language models: real-world simulation benchmark for qualitative reasoning. arXiv preprint arXiv:2405.15064, 2024. Manling Li, Shiyu Zhao, Qineng Wang, Kangrui Wang, Yu Zhou, Sanjana Srivastava, Cem Gokmen, Tony Lee, Li Erran Li, Ruohan Zhang, Weiyu Liu, Percy Liang, Li Fei-Fei, Jiayuan Mao, and Jiajun Wu. Embodied agent interface: Benchmarking llms for embodied decision making, 2025. URL https://arxiv.org/abs/2410.07166. Yuan-Hong Liao, Rafid Mahmood, Sanja Fidler, and David Acuna. Reasoning paths with reference objects elicit quantitative spatial reasoning in large vision-language models. arXiv preprint arXiv:2409.09788, 2024. Wufei Ma, Haoyu Chen, Guofeng Zhang, Yu-Cheng Chou, Celso de Melo, and Alan Yuille. 3dsrbench: comprehensive 3d spatial reasoning benchmark. arXiv preprint arXiv:2412.07825, 2024. Arjun Majumdar, Anurag Ajay, Xiaohan Zhang, Pranav Putta, Sriram Yenamandra, Mikael Henaff, Sneha Silwal, Paul Mcvay, Oleksandr Maksymets, Sergio Arnaud, et al. Openeqa: Embodied question answering in the era of foundation models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 1648816498, 2024. Oier Mees, Lukas Hermann, Erick Rosete-Beas, and Wolfram Burgard. Calvin: benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks. IEEE Robotics and Automation Letters, 7(3), 2022. Also available as arXiv:2112.03227. Roshanak Mirzaee, Hossein Rajaby Faghihi, Qiang Ning, and Parisa Kordjmashidi. Spartqa:: textual question answering benchmark for spatial reasoning. arXiv preprint arXiv:2104.05832, 2021. Daniel R. Montello. new framework for understanding the acquisition of spatial knowledge in large-scale environments. Spatial and temporal reasoning in geographic information systems, pp. 143154, 1998. Khanh Nguyen and Hal Daume III. Help, anna! visual navigation with natural multimodal assistance via retrospective curiosity-encouraging imitation learning. In arXiv preprint arXiv:1909.01871, 2019. John OKeefe and Jonathan Dostrovsky. The hippocampus as spatial map: preliminary evidence from unit activity in the freely-moving rat. Brain research, 1971. OpenAI. Gpt-5.2 system card. https://cdn.openai.com/pdf/ 3a4153c8-c748-4b71-8e31-aecbde944f8d/oai_5_2_system-card.pdf, August 2025. System card. Aishwarya Padmakumar, Jesse Thomason, Ayush Shrivastava, Patrick Lange, Anjali Narayan-Chen, Spandana Gella, Robinson Piramuthu, Gokhan Tur, and Dilek Hakkani-Tur. Teach: Task-driven embodied agents that chat. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pp. 20172025, 2022. 18 Published as conference paper at ICLR 2026 Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, and Antonio Torralba. Virtualhome: Simulating household activities via programs. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2018. URL https://arxiv. org/abs/1806.07011. Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William Yang Wang, Chunhua Shen, and Anton van den Hengel. Reverie: Remote embodied visual referring expression in real indoor environments. arXiv preprint arXiv:1904.10151, 2019. Allen Ren, Jaden Clark, Anushri Dixit, Masha Itkina, Anirudha Majumdar, and Dorsa Sadigh. Explore until confident: Efficient exploration for embodied question answering. arXiv preprint arXiv:2403.15941, 2024. Zhengxiang Shi, Qiang Zhang, and Aldo Lipani. Stepgame: new benchmark for robust multihop spatial reasoning in texts. In Proceedings of the AAAI conference on artificial intelligence, volume 36, pp. 1132111329, 2022. Mani Shridhar, Roozbeh Mottaghi, Yonatan Bisk, Luke Zettlemoyer, and Dieter Fox. Alfworld: Aligning text and embodied environments for interactive task learning. arXiv preprint arXiv:2010.03768, 2020a. Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. Alfred: benchmark for interpreting grounded instructions for everyday tasks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 1074010749, 2020b. Alan W. Siegel and Sheldon H. White. The development of spatial representations of large-scale environments. Advances in Child Development and Behavior, 10:955, 1975. Sanjana Srivastava, Chengshu Li, Michael Lingelbach, Roberto Martın-Martın, Fei Xia, Kent Elliott Vainio, Zheng Lian, Cem Gokmen, Shyamal Buch, Karen Liu, Silvio Savarese, Hyowon Gweon, Jiajun Wu, and Li Fei-Fei. Behavior: Benchmark for everyday household activities in virtual, interactive, and ecological environments. In Aleksandra Faust, David Hsu, and Gerhard Neumann (eds.), Proceedings of the 5th Conference on Robot Learning, volume 164 of Proceedings of Machine Learning Research, pp. 477490. PMLR, 0811 Nov 2022. Holly Taylor and Barbara Tversky. Spatial mental models derived from survey and route descriptions. Journal of Memory and language, 31(2):261292, 1992. Edward Tolman. Cognitive maps in rats and men. Psychological review, 55(4):189, 1948. Weiyun Wang, Zhangwei Gao, Lixin Gu, Hengjun Pu, Long Cui, Xingguang Wei, Zhaoyang Liu, Linglin Jing, Shenglong Ye, Jie Shao, et al. Internvl3. 5: Advancing open-source multimodal models in versatility, reasoning, and efficiency. arXiv preprint arXiv:2508.18265, 2025. Zhaowei Wang, Hongming Zhang, Tianqing Fang, Ye Tian, Yue Yang, Kaixin Ma, Xiaoman Pan, Yangqiu Song, and Dong Yu. Divscene: Benchmarking lvlms for object navigation with diverse scenes and objects. arXiv preprint arXiv:2410.02730, 2024. Jason Weston, Antoine Bordes, Sumit Chopra, Alexander Rush, Bart Van Merrienboer, Armand Joulin, and Tomas Mikolov. Towards ai-complete question answering: set of prerequisite toy tasks. arXiv preprint arXiv:1502.05698, 2015. Heinz Wimmer and Josef Perner. Beliefs about beliefs: Representation and constraining function of wrong beliefs in young childrens understanding of deception. Cognition, 13(1):103128, 1983. Haoning Wu, Xiao Huang, Yaohui Chen, Ya Zhang, Yanfeng Wang, and Weidi Xie. Spatialscore: Towards unified evaluation for multimodal spatial understanding. arXiv preprint arXiv:2505.17012, 2025. Yue Wu, Xuan Tang, Tom M. Mitchell, and Yuanzhi Li. Smartplay: benchmark for llms as intelligent agents. arXiv preprint arXiv:2310.01557, 2023. 19 Published as conference paper at ICLR 2026 Runsen Xu, Weiyao Wang, Hao Tang, Xingyu Chen, Xiaodong Wang, Fu-Jen Chu, Dahua Lin, Matt Feiszli, and Kevin Liang. Multi-spatialmllm: Multi-frame spatial understanding with multi-modal large language models. arXiv preprint arXiv:2505.17015, 2025. Jihan Yang, Shusheng Yang, Anjali Gupta, Rilyn Han, Li Fei-Fei, and Saining Xie. Thinking in space: How multimodal large language models see, remember, and recall spaces. In Proceedings of the Computer Vision and Pattern Recognition Conference, pp. 1063210643, 2025a. Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, and Tong Zhang. Embodiedbench: Comprehensive benchmarking multi-modal large language models for visiondriven embodied agents, 2025b. URL https://arxiv.org/abs/2502.09560. Sihan Yang, Runsen Xu, Yiman Xie, Sizhe Yang, Mo Li, Jingli Lin, Chenming Zhu, Xiaochen Chen, Haodong Duan, Xiangyu Yue, et al. Mmsi-bench: benchmark for multi-image spatial intelligence. arXiv preprint arXiv:2505.23764, 2025c. Chun-Hsiao Yeh, Chenyu Wang, Shengbang Tong, Ta-Ying Cheng, Ruoyu Wang, Tianzhe Chu, Yuexiang Zhai, Yubei Chen, Shenghua Gao, and Yi Ma. Seeing from another perspective: Evaluating multi-view understanding in mllms. arXiv preprint arXiv:2504.15280, 2025. Baiqiao Yin, Qineng Wang, Pingyue Zhang, Jianshu Zhang, Kangrui Wang, Zihan Wang, Jieyu Zhang, Keshigeyan Chandrasegaran, Han Liu, Ranjay Krishna, et al. Spatial mental modeling from limited views. arXiv preprint arXiv:2506.21458, 2025. Yong Zhao, Kai Xu, Zhengqiu Zhu, Yue Hu, Zhiheng Zheng, Yingfeng Chen, Yatai Ji, Chen Gao, Yong Li, and Jincai Huang. Cityeqa: hierarchical llm agent on embodied question answering benchmark in city space. arXiv preprint arXiv:2502.12532, 2025. Zhipu AI Team. Glm-4.6v: Native multimodal foundation model. Technical report / model release, 2025. URL https://z.ai/blog/glm-4.6v. Available online; native multimodal vision + reasoning model (128k context) among open-source LLMs. Enshen Zhou, Jingkun An, Cheng Chi, Yi Han, Shanyu Rong, Chi Zhang, Pengwei Wang, Zhongyuan Wang, Tiejun Huang, Lu Sheng, and Shanghang Zhang. Roborefer: Towards spatial referring with reasoning in vision-language models for robotics. arXiv preprint arXiv:2506.04308, 2025a. Shijie Zhou, Alexander Vilesov, Xuehai He, Ziyu Wan, Shuwang Zhang, Aditya Nagachandra, Di Chang, Dongdong Chen, Xin Eric Wang, and Achuta Kadambi. Vlm4d: Towards spatiotemporal awareness in vision language models. arXiv preprint arXiv:2508.02095, 2025b. Hao Zhu, Raghav Kapoor, So Yeon Min, Winson Han, Jiatai Li, Kaiwen Geng, Graham Neubig, Yonatan Bisk, Aniruddha Kembhavi, and Luca Weihs. Excalibur: Encouraging and evaluating embodied exploration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1493114942, 2023. 20 Published as conference paper at ICLR"
        },
        {
            "title": "A TECHNICAL DETAILS",
            "content": "A.1 BENCHMARK CONSTRUCTION We expose the ToS world as Gym-like interface (Brockman et al., 2016): agents interact in discrete steps under partial observability at resolution of 384384 to construct and revise an internal spatial belief, which we later exploit in evaluation tasks. Scenes are procedurally generated multi-room layouts on an grid with named indoor objects (each with integer (x, y) and heading in {N,E,S,W}) and randomized agent spawn pose. We restrict multi-room layouts to tree topology: the roomadjacency graph is connected and acyclic (no loops). Text-based World At each step, OBSERVE returns symbolic snapshot of objects in the current room within 90 forward FOV. For every visible object we provide discretized egocentric direction (e.g., front-left) and distance bins (e.g., near/mid/far), plus object identity and facing when determinable. Egocentric observations are rendered with 90-degree field of view (FOV), discretized into angular and distance bins as specified in Figure 7a. Visibility is room-bounded; doorways act as transparent portals only when the agent stands in them, enabling dual-room visibility. Optional noise modules perturb bins for ablations. Vision-based World We procedurally generate scenes in 3D simulator with two controllable parameters: the level (number of rooms) and the object count per room. Objects are drawn from library of 293 distinct 3D models, grouped into 6 categories and 37 subtypes, primarily everyday household items (see Figure 7b). To ensure diversity, each object type appears at most once in given scene. (a) Field of view (FOV) specification for the agent in our tasks. The FOV spans 90 in front of the agent and is divided into angular bins (e.g., front, front-slight left, front-left) and distance ranges (near [0,2], mid [2,5], far [5,10]). This egocentric perception defines how spatial relations are observed and reported. (b) Distribution of all 3D models used in our vision tasks. Figure 7: Demonstration figures for FOV and 3D model distribution For task setup, we additionally generate instructional (Figure 8) and orientation (Figure 9) images that serve as references for the agent in vision-world. We include both images in the vision prompt. Object placement follows validity constraints (e.g., collision avoidance, minimum spacing), and random seeds control reproducibility across environments. 21 Published as conference paper at ICLR 2026 Figure 8: Example of distance cues in the vision prompt. The colored cylinders illustrate objects placed at different distances from the agent: yellow at 2 m, blue at 1 m, red at 2 m, and green at 3 m, providing calibration for mapping visual observations to discretized distance bins. Figure 9: Object appearance and orientation cues in the vision prompt. Objects with facing direction are shown from both the front and side views, while objects without inherent orientation are displayed only from the front view. This provides the agent with consistent visual references for recognizing shape and facing. Information Gain Calculation We use the AC-3 arc-consistency algorithm to maintain, for each object, domain of feasible grid cells. Initially, every objects domain spans the entire 20 20 map. Each new observation is compiled into unary and binary constraints (e.g., egocentric direction/distance bins, room visibility/occlusion, and ALLDIFFERENT to prevent collisions). When constraint is 22 Published as conference paper at ICLR 2026 added, AC-3 iteratively prunes any cell in one objects domain that is unsupported by the domains of related objects, propagating revisions along incident arcs until fixed point is reached (all arcs are consistent). While AC-3 alone does not guarantee global consistency, in our setting all constraints are derived from valid trajectory; therefore the ground-truth assignment remains supported and is never pruned, ensuring that domains stay non-empty throughout propagation. Proxy agents We implement two scripted proxies to provide strong, reproducible baselines. SCOUT. From its spawn pose, the agent performs 360 sweep (four cardinal ROTATE+OBSERVE actions) to capture all views at the initial location. It then follows fixed room-visitation order: upon discovering doorway, it enters the adjacent room, executes the same sequential sweep, and repeats this visitsweepadvance routine until every room has been observed at least once. STRATEGIST. The first stage mirrors SCOUT: panoramic sweep to register all currently visible objects. Thereafter, within the current room the agent maintains, for each object, set of feasible positions (domain) induced by accumulated observations. At each turn it: (i) selects the object with the largest remaining domain (highest positional uncertainty); (ii) moves to viewpoint that best constrains this object (e.g., near it or along sightline that intersects the most candidate cells); (iii) at that viewpoint, orients to test pairwise relations: it computes unresolved pairwise directions between the target object and all others in the room, identifies the direction bin with the highest outstanding count, and OBSERVEs in that orientation first. The procedure iterates until all objects in the room are resolved (domains shrink to singletons), then proceeds to the next unvisited room and repeats. Prompts We show the detailed designs of our prompts for exploration in Figure 10, evaluation prompts in Figure 11, cognitive map prompts in Figure 12, and top-down view for uncertainty modeling in Figure 13. Figure 10: Exploration prompts 23 Published as conference paper at ICLR 2026 Figure 11: Evaluation prompt design. We show the prompt for each evaluation task. 24 Published as conference paper at ICLR 2026 Figure 12: Belief probing prompt design. We use these prompts to ask the model to output cognitive map or select unobserved points. Figure 13: The symbol map and the image map provide parallel representations of the same environment for text and vision settings in uncertainty probing prompts. 25 Published as conference paper at ICLR"
        },
        {
            "title": "B EVALUATION SETUPS",
            "content": "To enable like-for-like comparison between the text and vision settings, we instantiate identical room layouts across modalities. Concretely, we generate 100 evaluation instances with IDs 099; for each ID, we use the ID itself as the random seed to drive task sampling in both environments. This seed tying guarantees deterministic layouts and bit-for-bit reproducibility across modalities. Additional Results We show detailed results for different room settings including two-room and four-room layouts. In both the two-room and four-room settings, we use the same room size and the same number of objects per room as in the three-room setting. For the four-room setting, we connect the main room with all the others. We evaluate GPT-5.2 and GEMINI-3 PRO, the two best-performing models. Additionally, we tested higher resolution, but found no performance gain. Table 8 and 9 report passive and active performance of the two-room setting. Table 10 and 11 report passive and active performance of the three-room setting. As the number of rooms increases, exploration cost rises accordingly. The results also underscore the importance of efficient exploration: in the four-room setting, which demands more strategic exploration, the gap between active and passive performance becomes substantially larger. direction persp.take perc.dec act2view view2act alloc.map ment.rot loc2view view2loc Static (S) Dynamic (D) Static (S) Dynamic (D) Methods Route Survey Vision-based World Proprietary Models GPT-5.2 GEMINI-3 PRO 39.2 57.8 37.3 33.9 63.3 53.8 53.8 48. 58.3 58.7 Text-based World 68.2 64.6 92.7 83.3 52.3 54.7 68.6 69.8 Proprietary Models GPT-5.2 GEMINI-3 PRO 85.3 88.2 92.0 86.7 99.0 91.7 90.0 87.3 83.0 79.3 97.2 90. 99.7 92.7 89.5 81.5 95.2 82.9 Avg. 59.3 58.3 92.3 86. Table 8: Exploitation Performance (%) via Passive Observations under two rooms settings. direction persp.take perc.dec. act2view view2act alloc.map ment.rot loc2view view2loc Methods Avg.cost Proprietary Models GPT-5.2 GEMINI-3 PRO 10.8 6.6 Proprietary Models GPT-5.2 GEMINI-3 PRO 6.2 6.2 Static (S) Dynamic (D) Static (S) Dynamic (D) Route Vision-based World Survey 41.3 51.7 36.2 36. 48.2 63.0 49.0 47.2 54.7 56.0 56.9 63.4 72.0 85.0 45.2 50. 59.7 67.5 Text-based World 68.7 76.0 67.3 68.3 90.0 89.0 76.8 77. 64.0 72.7 83.4 83.1 92.7 96.0 73.7 77.5 83.7 86.2 Avg. 51.5 57.8 77.8 80.6 Table 9: Exploitation Performance (%) via Active Exploration under two rooms settings. direction persp.take perc.dec act2view view2act alloc.map ment.rot loc2view view2loc Static (S) Dynamic (D) Static (S) Dynamic (D) Methods Route Survey Vision-based World Proprietary Models GPT-5.2 GEMINI-3 PRO 47.0 63.5 37.7 35.5 59.7 58. 38.3 42.8 40.3 43.0 Text-based World 60.1 64.4 73.7 81.7 50.5 48.8 65.9 67. Proprietary Models GPT-5.2 GEMINI-3 PRO 83.8 81.2 88.2 91.3 94.3 96.7 86.8 82.2 62.7 68. 94.8 76.8 93.7 81.3 82.0 74.2 92.5 79.0 Avg. 52.6 56. 86.5 81.2 Table 10: Exploitation Performance (%) via Passive Observations under four rooms settings. 26 Published as conference paper at ICLR 2026 direction persp.take perc.dec. act2view view2act alloc.map ment.rot loc2view view2loc Methods Avg.cost Proprietary Models GPT-5.2 GEMINI-3 PRO Proprietary Models GPT-5.2 GEMINI-3 PRO 23.2 19. 16.4 19.7 Static (S) Dynamic (D) Static (S) Dynamic (D) Route Vision-based World Survey 41.2 59.8 33.2 34.2 49.0 60.3 30.8 34.7 30.7 46. 32.5 56.8 49.7 62.7 40.5 44.0 55.4 64.8 Text-based World 65.3 76. 69.0 77.2 74.3 91.7 62.8 73.3 44.3 64.3 66.6 77.0 76.3 83. 57.5 74.0 77.8 81.9 Avg. 40.3 51.5 66.0 77.7 Table 11: Exploitation Performance (%) via Active Exploration under four rooms settings."
        },
        {
            "title": "C ADDITIONAL VISUALIZATION EXAMPLES",
            "content": "We include concrete examples of task formats and answer styles with open-ended, format-constrained outputs in Figure 14. Cognitive map output by models We visualize the turn-by-turn cognitive maps (in Figures 15 and 16 of GPT-5.2, comparing them against ground-truth maps. The performance is noticeably stronger in text-based environments than in vision-based ones. Exploration pattern examples by models We include representative trajectories from each model to illustrate the active exploration patterns identified in our analysis, shown in Figure 17, 18, 19, 20, and 21 . These examples highlight how different models manifest recurring exploration behaviors: for instance, GPT-5.2 often adopts finding-gate strategy, rotating until doorway is detected before moving toward it, while other models more frequently repeat redundant checks. All figures mark the agents position and orientation explicitly, with actions annotated beneath each frame and shared legend provided for each trajectory. Analysis Platform We also include some demonstrations in Figure 22, 24, 23, 25, and 26 of our designed platform for better analysis 27 Published as conference paper at ICLR Figure 14: Examples of task formats and answer styles used. Each block illustrates spatial reasoning task type in our suite (Route-level and Survey-level), including the corresponding input context and an example open-ended answer that must follow strict output format. In the vision setting, textual scene descriptions in the questions are replaced by rendered observation images. 28 Published as conference paper at ICLR 2026 Figure 15: GPT-5.2s turn-by-turn cognitive map in text world during exploration. Figure 16: GPT-5.2s turn-by-turn cognitive map in vision world during exploration. Figure 17: Example trajectory illustrating GPT-5.2s door-finding strategy and systematic sweeping pattern: Upon detecting door, the agent navigates toward it and executes strategic rotation to maximize environmental coverage. The process terminates once all target objects have been successfully identified. 29 Published as conference paper at ICLR 2026 Figure 18: Example trajectory illustrating GPT-5.2s omission pattern: Observing the door too early may lead the agent to skip the rest of the exploration, causing incomplete environmental discovery. Figure 19: Example trajectory illustrating GEMINI-3 PROs door-finding strategy and systematic sweeping pattern in vision world: Upon detecting door, the agent navigates toward it and executes strategic rotation to maximize environmental coverage. The process terminates once all target objects have been successfully identified. 30 Published as conference paper at ICLR Figure 20: Example trajectory illustrating GEMINI-3 PROs object sweeping pattern mostly found in text world: Orbit the starting object using it as the pivot point. Randomly select an observed door to jump to new object, then resume pivoting around the new target in continuous loop. Figure 21: Example trajectory illustrating CLAUDE-4.5 SONNETs exploration pattern: There is no clear exploration pattern. 31 Published as conference paper at ICLR 2026 Figure 22: Platform designed by us for analysis (chart) Figure 23: Visualization Platform for analysis: Metrics for active exploration in text world 32 Published as conference paper at ICLR 2026 Figure 24: Visualization Platform for analysis: Metrics for active exploration in vision world Figure 25: Visualization Platform for analysis: one turn of active exploration in text-world, including agents action and cognitive map. 33 Published as conference paper at ICLR Figure 26: Visualization Platform for analysis: one turn of active exploration in vision-world"
        }
    ],
    "affiliations": [
        "Cornell University",
        "Northwestern University",
        "Stanford University",
        "University of Washington"
    ]
}