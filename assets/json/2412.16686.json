{
    "paper_title": "NILE: Internal Consistency Alignment in Large Language Models",
    "authors": [
        "Minda Hu",
        "Qiyuan Zhang",
        "Yufei Wang",
        "Bowei He",
        "Hongru Wang",
        "Jingyan Zhou",
        "Liangyou Li",
        "Yasheng Wang",
        "Chen Ma",
        "Irwin King"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As a crucial step to enhance LLMs alignment with human intentions, Instruction Fine-Tuning (IFT) has a high demand on dataset quality. However, existing IFT datasets often contain knowledge that is inconsistent with LLMs' internal knowledge learned from the pre-training phase, which can greatly affect the efficacy of IFT. To address this issue, we introduce NILE (iNternal consIstency aLignmEnt) framework, aimed at optimizing IFT datasets to unlock LLMs' capability further. NILE operates by eliciting target pre-trained LLM's internal knowledge corresponding to instruction data. The internal knowledge is leveraged to revise the answer in IFT datasets. Additionally, we propose a novel Internal Consistency Filtering (ICF) method to filter training samples, ensuring its high consistency with LLM's internal knowledge. Our experiments demonstrate that NILE-aligned IFT datasets sharply boost LLM performance across multiple LLM ability evaluation datasets, achieving up to 66.6% gain on Arena-Hard and 68.5% on Alpaca-Eval V2. Further analysis confirms that each component of the NILE}framework contributes to these substantial performance improvements, and provides compelling evidence that dataset consistency with pre-trained internal knowledge is pivotal for maximizing LLM potential."
        },
        {
            "title": "Start",
            "content": ": Internal Consistency Alignment in Large Language Models Minda Hu1, Qiyuan Zhang2, Yufei Wang3, Bowei He2, Hongru Wang1, Jingyan Zhou1 Liangyou Li3, Yasheng Wang3, Chen Ma2, Irwin King1 1The Chinese University of Hong Kong 2City University of Hong Kong 3Huawei Noahs Ark Lab {mindahu21, king}@cse.cuhk.edu.hk 4 2 0 2 1 2 ] . [ 1 6 8 6 6 1 . 2 1 4 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "As crucial step to enhance LLMs alignment with human intentions, Instruction FineTuning (IFT) has high demand on dataset quality. However, existing IFT datasets often contain knowledge that is inconsistent with LLMs internal knowledge learned from the pre-training phase, which can greatly affect the efficacy of IFT. To address this issue, we introduce NILE (iNternal consIstency aLignmEnt) framework, aimed at optimizing IFT datasets to unlock LLMs capability further. NILE operates by eliciting target pre-trained LLMs internal knowledge corresponding to instruction data. The internal knowledge is leveraged to revise the answer in IFT datasets. Additionally, we propose novel Internal Consistency Filtering (ICF) method to filter training samples, ensuring its high consistency with LLMs internal knowledge. Our experiments demonstrate that NILE-aligned IFT datasets sharply boost LLM performance across multiple LLM ability evaluation datasets, achieving up to 66.6% gain on Arena-Hard and 68.5% on Alpaca-Eval V2. Further analysis confirms that each component of the NILE framework contributes to these substantial performance improvements, and provides compelling evidence that dataset consistency with pre-trained internal knowledge is pivotal for maximizing LLM potential."
        },
        {
            "title": "Introduction",
            "content": "Instruction Fine-Tuning (IFT), which fine-tunes LLMs on instruction-response pairs, has been proven to be an effective and crucial method to enhance the capabilities and controllability of large language models (LLMs) (Touvron et al., 2023; Dubey et al., 2024; Zhang et al., 2023). Most IFT approaches predominantly focus on the quantity and diversity of datasets, based on the assumption that greater size of instruction-response pairs would lead to better performance (Honovich et al., 2023; Wang et al., 2023a; Taori et al.; Chiang et al., 2023; Figure 1: Demonstration of LLM internal knowledge and world knowledge from IFT datasets. Sun et al., 2024). These approaches narrowly focus on data quantity while overlooking IFTs core purpose: unlocking the latent capabilities of pretrained LLMs. They fail to examine the crucial relationship between SFT training data and the underlying pre-trained models. Recent findings delve into this problem deeper, revealing that the alignment between underlying world knowledge derived from IFT datasets and the internal knowledge stored within the parameters of LLMs is crucial for determining their performance (Kang et al., 2024). This alignment creates meaningful connections between IFT datasets and the downstream performance of specific LLMs, offering theoretical guidelines for the generation and selection of IFT datasets tailored to enhance the effectiveness of particular LLMs. Specifically, when world knowledge from IFT datasets conflicts entirely with LLMs internal knowledge, these encoded associations are largely neglected, and the LLM tends to merely predict an intelligent blind guess by mimicking surface-level patterns such as text styles without truly understanding task intentions. Nevertheless, further experiments (Ren et al., 2024) observe that only incorporating certain degree of world knowledge that is incompatible with LLMs internal parameter knowledge into IFT datasets brings more performance boost. There are recent attempts (Li et al., 2024b; Cao et al.; Li et al., 2024d; Liu et al., 2024; Li et al., 2024a) to maintain consistent formatting at superficial level such as text styles, but they still overlook the need for managing internal consistency. Inspired by previous findings, we propose novel framework called NILE (INTERNAL CONSISTENCY ALIGNMENT). To tackle the aforementioned issues, NILE is designed to generate and select better IFT datasets considering the consistency between internal parameter knowledge in LLMs and world knowledge in IFT datasets. Specifically, we leverage the off-the-shelf LLMs to revise given IFT datasets based on the internal parameter knowledge and then select the samples considering the relationship between the implicit world knowledge and internal parameter knowledge. It is important to highlight that our method does not rely on any additional forms of supervision (i.e., human experts). To conclude, our contributions can be summarized as follows: We propose NILE, novel framework to generate and select better IFT datasets considering the consistency between internal parameter knowledge in LLMs and world knowledge in IFT datasets, as illustrated in Figure 1. Through comprehensive ablation studies and empirical analysis, we demonstrate that maintaining consistency between IFT datasets and LLMs internal knowledge is crucial for unlocking model capabilities. Our results provide strong evidence that each component of NILE contributes to performance gains. Our extensive experiments across multiple benchmarks show that NILE-optimized datasets enable substantial improvements in LLM performance, achieving up to 66.6% gains on Arena-Hard and 68.5% on AlpacaEval V2. These results demonstrate that NILEs balanced integration of world and internal knowledge enhances LLMs ability to generalize to novel tasks and domains. or self-critique prompting methods (Wang et al., 2024; Zhang et al., 2024) to automatically generate instruction-tuning datasets. For examples, Self-Instruct (Wang et al., 2023a) leverage GPT3 to expand asks to many diverse domains in the in-context learning manner while several recent studies directly use latest SOTA model to generate the response or reflect on current samples (Mukherjee et al., 2023), such as WizardLM (Xu et al., 2023) and Reflection-tuning (Li et al., 2024a). In addition to focusing on quality side, another area of work aims to create more diverse and larger instruction-tuning datasets. For example, UltraChat (Ding et al., 2023) defines specific scopes and systematically generates wide range of instructions within each area. In contrast, Magpie (Xu et al., 2024) only feed the left-side templates up to the position reserved for user messages as input to generate more diverse user queries."
        },
        {
            "title": "2.2 Data Selection in Instruction Tuning",
            "content": "Data selection (or revision) have been widely studied in large language model instruction tuning, considering the importance of data quality in model training (Li et al., 2024b; Cao et al.; Li et al., 2024d; Zhou et al., 2024; Liu et al., 2024; Li et al., 2024a). Most previous studies fall into two categories: 1) relying on more powerful models or human experts to select better data (Zhou et al., 2024; Liu et al., 2024); 2) calculating the ppl gains considering generated samples and original samples (Li et al., 2024a). While both methods improve downstream performance, they face significant limitations, such as the high cost of human labeling. More importantly, such studies (Chen et al.; Li et al.; Sun et al., 2024) can not provide fundamental explanations regarding the key factors that define better instruction-tuning datasets. In contrast to these approaches, our work aligns the internal knowledge of LLMs with external world knowledge derived from ITF datasets, resulting in improved datasets that offer better explainability and transparency."
        },
        {
            "title": "2.1 Data Synthesis in Instruction Tuning",
            "content": "Earlier research on instruction tuning has primarily focused on developing large, high-quality datasets curated by human experts (Wei et al., 2022; Wang et al., 2022). However, this process is often timeconsuming and labor-intensive. Thus, several studies have explored the use of more advanced models Figure 2 demonstrates our framework NILE for increasing knowledge affinity between LLMs internal knowledge and instruction-tuning datasets. (1) It can be divided into three parts: INTERNAL KNOWLEDGE EXTRACTION (IKE), (2) KNOWLEDGE-AWARE SAMPLE REVISION INTERNAL CONSISTENCY (KSR), and (3) Figure 2: Overview of our NILE framework. FILTERING (ICF). IKE accesses the memory of pretrained LLMs to sample their internal knowledge. KSR revises existing dataset samples by automatically infusing the sampled internal knowledge. ICF introduces novel internal consistency measurement to filter out low-quality revisions from the second phase. Notably, our framework is decoupled from and easily integrated into current LLM alignment pipelines. In the following subsections, we introduce the above three components in detail. Implementation details of IKE, KSR, and ICF are listed in Appendix A.1. 3."
        },
        {
            "title": "Internal Knowledge Extraction",
            "content": "1...n, ao This step aims to effectively sample the internal knowledge from the target pre-trained LLM for instructions in the original IFT dataset. Specifically, for original instruction tuning datasets, Do has data samples formatted as Do = {qo 1...n}. Here we define the concatenated sequence qo = {instructiono, inputo} as complete instruction, and ao = answero as its corresponding answer. We aim to guide to output its corresponding internal knowledge ikM related to qo by utilizqo ing in-context learning techniques, i.e., few-shot prompting. Instead of fixed examples in the prompt, we first select relevant samples as examples, then prompt to generate knowledge w.r.t. qo. As shown in Figure 2, the process of IKE involves the following steps: 1. We first construct database index demo = m, ikd m)}, which is fix set 1), . . . , (qd 1, ikd {(qd Generate list of related knowledge about the following Instruction and Input up to 500 words. Do not directly output the answer, but focus on the related knowledge required for answering the Input. Instruction: \"{instructiond Input: \"{inputd }\" }\" Table 1: Prompt for generating internal knowledge demonstration ikd related to qd . of demonstrations contains samples. {qd } is randomly sampled from an IFT dataset. We then prompt strong LLM as the teacher to generate corresponding knowledge ikd for each qd as shown in Table 1. Details are provided in Appendix A.1.3. 1 , ikR 1 ), . . . , (qR 2. For each qo, we select few-shot examples R(qo) = {(qR )} from demo by the semantic similarity between qo and {qd }. We employ information retrieval algorithms, such as BM25, as the retriever to compute the semantic similarity. , ikR 3. The retrieved demonstration samples R(qo) are fed into the target LLM to enable incontext learning. This allows the LLM to accurately expose its internal knowledge ikM related to the original instruction qo by utilizing the prompt design in Table 2. By following this approach, we can effectively {few_shot_prompt (qR 1...k, ikR 1...k) } Instruction: {instructiono, inputo} Related Knowledge: Table 2: Prompt for knowledge extraction. Sample fewshot demonstration prompt is listed in A.1.3. extract the internal knowledge of unaligned LLMs relevant to the original instructions, leveraging the power of few-shot demonstration learning."
        },
        {
            "title": "3.2 Knowledge-aware Sample Revision",
            "content": "After obtaining an accurate sampling ikM qo of the target LLMs internal knowledge for each original instruction qo, we design prompt for the revisor LLM agent Ar to infuse ikM qo into the current instruction and get the revised answer aik. The prompt for KSR is displayed in Table 3. Provide better response based on \"{ao}\" to comply with given instruction, input, and related knowledge. Instruction: {instructiono} Input:{inputo} Related Knowledge: {ikM qo } Please directly output the improved response. Table 3: Prompt for Knowledge-aware Sample Revision. This step aims to enhance affinity between the target model Ms internal knowledge ikM qo and the original answer ao from Do with world knowledge, resulting an improved answer aik. 3."
        },
        {
            "title": "Internal Consistency Filtering",
            "content": "In this stage, we evaluate the effectiveness of KSR by comparing the quality of the revised answer aik with the original answer ao. Drawing inspiration from IFD and PMI (Li et al., 2023), we introduce novel metric called INTERNAL CONSISTENCY INDEX (ICI) to quantify how well one answer promotes knowledge associations in the pretrained LLM M. During the instruction alignment process, the loss of sample pair (q, a) is computed using the sequence probability of conditioned on q: PM(a q) = (cid:88) log PM (cid:0)wa q, wa 1, wa 2, . . . , wa i1 (cid:1) ,"
        },
        {
            "title": "1\nN",
            "content": "i=1 (1) where wi is the tokens in and is the sequence length of a. This probability measures the familiarity of with answer given the context q. It can also reflect the strength of the encoded association between and in the LLMs representations, which is empirically supported by Kang et al.. Building upon this idea, we formulate ICI as follows: ICIM(q, aik) = PM(aik q, ikM ) PM(aik q) , (2) where PM(aik q) measures the associations between revised responses aik and instructions alone, while PM(aik q, ikM ) captures the overall association strength between aik and the combination of and its corresponding extracted internal knowledge ikM . To isolate the influence of ikM on the revised answer a, we minimize the influence of in the ICI formulation by dividing PM(a q, ikM ) with PM(a q). For samples with higher ICI values, the model more effectively integrates and leverages the explicitly provided internal knowledge when generating the revised answer, suggesting stronger alignment between the revised answer and the models internal knowledge. Conversely, for samples with lower ICI values, providing internal knowledge may not benefit or could even hinder the generation of the revised answer, indicating that the revised answer does not have strong association with what the model has learned internally, as suggested by (Ren et al., 2024). Therefore, we employ filtering mechanism ICF to filter out these redundant low ICI samples to an aligned dataset Daligned for finetuning an aligned LLM Ma from M. To control other variables in the experiment and ensure stable improvement, we revert to the original samples (q, ao) when the ICI values of (q, aik) are lower than threshold β: Daligned = {qo where aaligned }, 1...n, aaligned 1...n (cid:26) aik , if ICIM(qo ao , otherwise = , aik ) > β (3)"
        },
        {
            "title": "4 Experiments",
            "content": "For the main experiment, we use open source models like MISTRAL-7B-V0.3 (Jiang et al., 2023) and LLAMA-3.1-8B (Dubey et al., 2024) on two public datasets Alpaca (Taori et al.) and OpenOrca (Mukherjee et al., 2023) to examine NILE frameworks robustness extensively. In addition, we conduct an ablation study to evaluate the efficacy of our design choices in the pipeline. More experiment details and case studies can be found in Appendix A.1. 4."
        },
        {
            "title": "IFT Datasets",
            "content": "Alpaca The Alpaca dataset contains 52,000 instruction-following data generated using the techniques in the Self-Instruct (Wang et al., 2023b). It starts with limited (e.g., 175 in our study) seed set of manually written tasks that are used to guide the overall generation. Then language models are utilized and prompted to augment these instructions and create corresponding instruction-answer instances. In our experiments, we use all the samples in newer version of Alpaca1 dataset, which includes instruction-following instances generated using GPT-4 (Peng et al., 2023). Orca OpenOrca is large-scale dataset built upon the Flan 2022 Collection (Mukherjee et al., 2023; Longpre et al., 2023). In the Orca dataset, query-response pairs are augmented with detailed responses from GPT-4 that explain the reasoning process of the teacher as it generates the response. In contrast with vanilla instruction tuning methods like Alpaca providing little opportunity for mimicking the thought process, this dataset provides additional signals for learning to elicit such explanations. For experiments, we use the officially released dataset2, and randomly select 50, 000 sample pairs from pool of 1 million samples."
        },
        {
            "title": "4.2 Evaluation",
            "content": "We briefly introduce evaluation methods used in our experiments as follows. Arena-Hard Arena-Hard-Auto3 is popular open-ended evaluation tool for instruction-tuned LLMs (Li et al., 2024c). It contains 500 challenging user queries. GPT-4-Turbo is prompted as 1https://huggingface.co/datasets/vicgalle/ alpaca-gpt4 2https://huggingface.co/datasets/Open-Orca/ 1million-gpt3https://github.com/lmarena/arena-hard-auto judge to compare the models responses against baseline model. Notably, Arena-Hard keeps high correlation and separability to Chatbot Arena (Chiang et al., 2024). Alpaca-Eval V2 Alpaca-Eval V24 is an automatic evaluation system for instruction-following language models (Dubois et al., 2024). It builds upon the original AlpacaEval system, which benchmarked against OpenAIs Davinci-003. AlpacaEval V2 instead uses GPT-4-Turbo, signaling the new state-of-the-art model since the original systems creation. key innovation in Alpaca-Eval V2 is the introduction of Length-Controlled Win Rates (LCWR). It increases the correlation with ChatBot Arena to 0.98, significantly decreasing length gameability in comparison with the original Win Rate (WR). In presenting experimental results, we display reports both metrics in the format: LCWR / WR. This provides more comprehensive picture of model performance, with LCWR serving as the primary metric while still allowing comparison to the original WR scores. MTBench MT-Bench comprises 80 multi-turn questions spanning eight distinct knowledge domains. The models are required to respond to an initial question and subsequently provide second response to follow-up question. GPT-4 assesses each models responses on scale from 1 to 10, and the overall score is determined by the mean over the two turns across all questions. We evaluate using the Fastchat implementation5. BBH Big Bench Hard6 (BBH) is suite of 23 challenging BIG-Bench tasks (Suzgun et al., 2023; Srivastava et al., 2022). These tasks are chosen because prior language models showed performance below the average human-raters. Since many tasks in BBH require multi-step reasoning, CoT prompting is added to better depict the LLMs capacities on these complex tasks that are challenging even for humans. 4."
        },
        {
            "title": "Implementation details",
            "content": "We finetune MISTRA-7B-V0.3 and METALLAMA-3.1-8B models for our experiments. For 4https://github.com/tatsu-lab/alpaca_eval 5https://github.com/lm-sys/FastChat/blob/main/ fastchat/llm_judge 6https://github.com/EleutherAI/ lm-evaluation-harness/tree/main/lm_eval/tasks/ bbh selecting retriever in IKE, we find that BM25 is more effective than strong neural retriever such as contriver (Lei et al., 2023) in retrieving higherquality demonstrations, which is evaluated and validated in Appendix A.1.2. To maintain better state of internal consistency, we set β in Eq. 3 to the 1-st percentile of the dataset for Alpaca, and to the 2-nd percentile for OpenOrca to rule out small amount of low ICI samples."
        },
        {
            "title": "4.4 Baselines",
            "content": "Vanilla Vanilla setting refers to using the original, unmodified IFT datasets for fine-tuning LLMs such as MISTRAL and LLAMA-3. This serves as baseline to compare the effectiveness of dataset revision techniques. SR Sample Revision (SR) marks the baseline for revising the instruction-answer pairs without leveraging any internal knowledge from the target LLM M. This lets SR solely infuse knowledge from the revisor agent Ar into IFT datasets. Details of SR can be found in A.1.5. NILE NILE represents our complete proposed method. In the experiments, Alpaca and Orca datasets undergo step-by-step revision process through the pipeline of IKE, KSR, and ICF introduced in Section 3."
        },
        {
            "title": "4.5 Results on Orca Dataset",
            "content": "Table 4 shows the performance of our NILE framework and all baselines on model MISTRAL-7BV0.3 and LLAME-3.1-8B in OpenOrca dataset. As we can see, Orca dataset brings unbalanced improvements on different LLMs, with LLAMA3 having less improvements on Arena-Hard and Alpaca-Eval V2 LCWR and more on MTBench and BBH than MISTRAL, which reflect different underlying characteristics and potentially difference internal knowledge in these two models. Compared with ORCA VANILLA, ORCA + NILE brings substantial improvements on all benchmarks It increases Arena-Hard score in both LLMs. by 1.4 points (26.4% relative improvement) in MISTRAL and 2.4 points (66.6%) in LLAMA-3. NILE also significantly enhances Alpaca-Eval V2 LCWR from 12.73 to 21.63 in MISTRAL and 10.84 to 13.70 in LLAMA-3, achieving 68.5% and 26.4% relative improvements respectively. In addition, it is noteworthy that NILE also brings considerable boosts on BBH benchmark by 4.64 in MISTRAL and by 1.05 in LLAMA-3. BBH tasks mainly focus on tasks requiring complex reasoning and expert knowledge, and performance lift of ORCA + NILE compared to ORCA VANILLA indicates the fact that alignment dataset revised by NILE encroaches fewer LLMs innate capability of multi-step complex reasoning since instructions in OpenOrca dataset itself is barely involved with multi-step complex reasoning, and yet ORCA + NILE helps unleashing the reasoning ability of the LLMs, as shown in the result of BBH. The universal improvements in these four well-tested benchmarks provide strong support for NILEs effectiveness in improving LLMs general capacity. Compared to ORCA + NILE, ORCA + SR infuses only the internal knowledge of the GPT-4 revisor model without utilizing extracted knowledge from MISTRAL and LLAMA-3 or the ICF phase. The experiment involving ORCA + SR is designed to investigate the contribution that introducing LLMs own internal knowledge makes in the NILE framework. ORCA + NILE largely surpasses ORCA + SR by 3.4 and 5.0 points on AlpacaEval V2 LCWR and BBH in MISTRAL model, 1.3 and 1.8 points on Alpaca-Eval V2 LCWR and Arena-Hard in LLAMA-3. This indicates that internal knowledge extracted from LLMs is crucial for bringing more performance uplift in LLMs general capability."
        },
        {
            "title": "4.6 Results on Alpaca",
            "content": "Compared with Orca dataset, LLMs finetuned with Alpaca dataset is generally weaker than ones with Orca, which highlights the sheer quality differences between the two datasets. Desipte these differences, ALPACA + NILE still bring signficant improvements over ALPACA VANILLA in all metrics, coming close to or even surpassing ORCA VANILLA in most of the benchmarks except BHH. It achieves performance uplift by 3.7 and 4.1 points on AlpacaEval V2 LCWR and BBH in MISTRAL. Moreover, ALPACA + NILE raises Alpaca-Eval V2 LCWR and Arena-Hard by 3.1 and 2.7 in LLAMA-3. Measured against ALPACA + SR, ALPACA + NILE still maintains major advantages. It enhances Arena-Hard and Alpaca-Eval V2 by 2.0 and 3.9 in MISTRAL model, 1.5 and 1.6 in LLAMA3. These results further illustrate the necessity of extracting internal knowledge in NILE. Method Arena-Hard Alpaca-Eval V2 MTBench BBH ALPACA VANILLA ALPACA + SR ALPACA + NILE ORCA VANILLA ORCA + SR ORCA + NILE ALPACA VANILLA ALPACA + SR ALPACA + NILE ORCA VANILLA ORCA + SR ORCA + NILE MISTRAL-7B-V0. 3.00 4.20 6.20 5.30 5.70 6.70 11.73 / 7.39 11.50 / 6.52 15.39 / 9.70 12.84 / 9.54 18.19 / 15.24 21.63 / 17.25 META-LLAMA-3.1-8B 2.10 3.30 4. 3.60 4.20 6.00 7.58 / 5.53 9.08 / 6.84 10.69 / 10.43 10.84 / 7.52 12.36 / 10.46 13.70 / 12.11 6.37 6.28 6.56 5.34 6.13 6.73 6.31 6.39 6. 7.01 7.18 7.48 34.46 38.40 38.52 46.37 46.01 51.01 58.64 59.91 61.40 63.02 63.77 64.05 Table 4: Main experiment results on Alpaca and OpenOrca datasets. The highest values are bolded, and the second highest is underlined."
        },
        {
            "title": "Sources",
            "content": "We closely examine the effect of introducing LLMs internal knowledge into NILE by switching the original internal knowledge source from MISTRAL to that from LLAMA-3 in KSR (extracted by FIXED DEMONSTRATION (FD) prompting described in Appendix A.2.2). Table 5 shows the comprehensive advantage of using LLAMA-3s internal knowledge over using MISTRALs. Switching from MISTRAL to LLAMA-3 increases Arena-Hard by 1.6 and 1.2 points in LLAMA-3 model on the Alpaca and Orca dataset. It is also interesting to see that using internal knowledge from MISTRAL has huge negative impact on LLAMA-3 on the BBH task requiring expert knowledge and complex reasoning, further highlighting the importance of such consistency. This suggests that maintaining general consistency between world knowledge from datasets and LLM internal knowledge is of necessity in effective IFT."
        },
        {
            "title": "4.7.2 Effects of IKE Fewshot Number\nTable 6 examines how different few-shot numbers\nof demonstration learning in IKE affect LLM per-\nformance. Here we evaluate three variants: 1) W.\nFD, which extracts LLM’s internal knowledge with\na fixed 2-shot demonstrations described in A.2.2;\n2) W. FS 1 IKE, which retrieves the top 1 most\nsimilar samples with BM25 as demonstrations; and\n3) W. FS 2 IKE, which retrieves the top 2 most\nsimilar samples with BM25 as demonstrations;\nThough W. FS 2 IKE leads to degradation in some\nbenchmarks, such as Arena-Hard for ALPACA and\nAlpaca-Eval for ORCA, it still achieves overall im-",
            "content": "provements with BBH for ALPACA increasing by 0.7 and Arena-Hard for ORCA increasing by 0.3. The results show the IKE phase is necessary for unaligned LLMs to more effectively extract internal knowledge, while fixed prompting reaches subpar performance."
        },
        {
            "title": "4.7.3 Effects of KAR",
            "content": "Figure 3: Distribution plot of sentence embedding similarity score in ALPACA dataset for MISTRAL model. To validate KARs effectiveness in enhancing internal consistency between world knowledge from instructions and the models internal knowledge, we conducted experiments measuring the similarity between extracted internal knowledge and baseline knowledge across different models and datasets. In LLAMA-3 and MISTRAL, we used the instructions from the Alpaca and Orca as prompts to evaluate the models internal knowledge. Then, we obtained the models vanilla output for these instructions, the output generated using KSR, and the output using SR. We randomly sampled 10,000 instrucMethod Arena-Hard Alpaca-Eval V2 MTBench BBH ALPACA + KSR (MISTRAL) ALPACA + KSR (LLAMA) ORCA + KSR (MISTRAL) ORCA + KSR (LLAMA) 4.00 4.80 5.10 5.20 9.14 / 7.29 10.75 / 9. 12.50 / 10.25 13.67 / 11.21 6.64 6.67 5.93 7.51 57.67 60.73 22.32 64.03 Table 5: Effects of KSR in LLAMA-3 finetuning with internal knowledge from different LLMs. The highest values are bolded. Method Arena-Hard Alpaca-Eval V2 MTBench BBH ALPACA + KSR W. FD ALPACA + KSR W. FS 1 IKE ALPACA + KSR W. FS 2 IKE ORCA + KSR W. FD ORCA + KSR W. FS 1 IKE ORCA + KSR W. FS 2 IKE 4.80 4.50 4.50 5.20 4.90 5.50 10.75 / 9.38 11.20 / 9.75 10.82 / 10.56 13.67 / 11.21 12.46 / 10.99 13.00 / 11.50 6.67 6.72 6. 7.51 7.40 7.43 60.73 59.25 61.40 64.03 63.89 64.29 Table 6: Effects of IKE with different fewshot numbers (FS) in LLAMA-3. The highest values are bolded, and the second highest is underlined."
        },
        {
            "title": "Method",
            "content": "Arena-Hard Alpaca-Eval V2 MTBench BBH ALPACA + NILE WO. ICF ALPACA + NILE W. ICF (LOW) ALPACA + NILE W. ICF (HIGH) ORCA + NILE WO. ICF ORCA + NILE W. ICF (LOW) ORCA + NILE W. ICF (HIGH) 4.50 4.80 4.50 5.50 6.00 4.80 10.82 / 10.56 10.69 / 10.43 9.92 / 9.70 13.00 / 11.50 13.70 / 12.11 13.19 / 11.49 6.76 6.90 6.79 7.43 7.48 7. 61.40 61.40 61.71 64.29 64.05 63.95 Table 7: Effects of ICF using different β parameters in LLAMA-3. The highest values are bolded, and the second highest is underlined. tions to calculate the sentence similarity between three generated outputs and the internal knowledge. As demonstrated in Figure 3, the similarity score distribution of the outputs generated by KSR is significantly closer to 1 compared to the other two methods, with Chi-squared test p-values lower than 0.01. More experiment results are exhibited in Appendix A.2.3. These results provide strong evidence supporting the effectiveness of the KSR approach in increasing the internal consistency from instructions by integrating relevant world and internal knowledge."
        },
        {
            "title": "4.7.4 Effects of ICF",
            "content": "Table 7 looks into the effect of ICF. β is set to 1-st percentile in ALPACA + NILE (LOW) and to 2-nd percentile in ORCA + NILE (LOW). For both ALPACA + NILE (HIGH) and ORCA + NILE (HIGH), we set β to 10-th percentile. The results empirically prove that striking balance between consistent and inconsistent knowledge in the IFT dataset is necessary for NILE to achieve ideal performance. We find the general advantage of ALPACA + NILE (LOW) over ALPACA + NILE (HIGH) and discarding ICF (ALPACA + NILE WO. ICF), indicating that surplus of overly consistent or inconsistent samples in IFT datasets both hurt LLMs performance, and it is crucial to find the middle ground in these samples. This experiment further verifies our design choices of the ICF phase in NILE."
        },
        {
            "title": "5 Conclusion",
            "content": "We present NILE, an innovative framework designed to enhance the quality of IFT datasets by aligning them with LLMs internal knowledge. Our extensive experiments demonstrate substantial improvements across various benchmarks, highlighting the crucial role of maintaining consistency between models internal knowledge and external knowledge in datasets. Each component of the NILE framework has been validated, reinforcing its importance in achieving better alignment. NILE offers promising directions for boosting the capabilities of LLMs and unlocking their full potential."
        },
        {
            "title": "Limitations",
            "content": "While NILE can already obtain satisfactory performance, future works should expand NILEs training by utilizing the complete OpenOrca dataset rather than the current 50,000-sample subset (5% of the dataset), due to limited time and computational resources. Additionally, future research should examine NILEs capability for iterative instruction refinement, as the current implementation uses only single revision pass. These expansions could further enhance NILEs instruction-following capabilities."
        },
        {
            "title": "Ethics Statement",
            "content": "We conduct this study strictly under the guidance of community ethical principles. The utilized IFT datasets are reported to be safe and free of content that may contain discrimination, personally identifiable information, or any other undesirable behaviors. We meticulously curate our instructions to the LLMs to ensure that the tasks are limited to knowledge generation and knowledge-relevant revisions, thereby avoiding content that may pose ethical concerns."
        },
        {
            "title": "References",
            "content": "Yihan Cao, Yanbin Kang, Chi Wang, and Lichao Sun. Instruction mining: Instruction data selection for tuning large language models. Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan Gu. Self-play fine-tuning converts weak language models to strong language models. In Forty-first International Conference on Machine Learning. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph Gonzalez, et al. 2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. See https://vicuna. lmsys. org (accessed 14 April 2023), 2(3):6. Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph Gonzalez, et al. 2024. Chatbot arena: An open platform for evaluating llms by human preference. ArXiv preprint, abs/2403.04132. Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023. Enhancing chat language models by scaling high-quality instructional conversaIn Proceedings of the 2023 Conference on tions. Empirical Methods in Natural Language Processing, pages 30293051, Singapore. Association for Computational Linguistics. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. ArXiv preprint, abs/2407.21783. Yann Dubois, Balázs Galambosi, Percy Liang, and Tatsunori Hashimoto. 2024. Length-controlled alpacaeval: simple way to debias automatic evaluators. ArXiv preprint, abs/2404.04475. Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2023. Unnatural instructions: Tuning language models with (almost) no human labor. In The 61st Annual Meeting Of The Association For Computational Linguistics. AQ Jiang, Sablayrolles, Mensch, Bamford, DS Chaplot, de las Casas, Bressand, Lengyel, Lample, Saulnier, et al. 2023. Mistral 7b (2023). ArXiv preprint, abs/2310.06825. Katie Kang, Eric Wallace, Claire Tomlin, Aviral Kumar, and Sergey Levine. 2024. Unfamiliar finetuning examples control how language models hallucinate. ArXiv preprint, abs/2403.05612. Yibin Lei, Liang Ding, Yu Cao, Changtong Zan, Andrew Yates, and Dacheng Tao. 2023. Unsupervised dense retrieval with relevance-aware contrastive pretraining. In Findings of the Association for Computational Linguistics: ACL 2023, pages 1093210940, Toronto, Canada. Association for Computational Linguistics. Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Jiuxiang Gu, and Tianyi Zhou. 2024a. Selective reflectiontuning: Student-selected data recycling for LLM instruction-tuning. In Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024, pages 1618916211. Association for Computational Linguistics. Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, and Jing Xiao. 2023. From quantity to quality: Boosting llm performance with self-guided data selection for instruction tuning. ArXiv preprint, abs/2308.12032. Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, and Jing Xiao. 2024b. From quantity to quality: Boosting llm performance with self-guided data selection for instruction tuning. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 75957628. Tianle Li, Wei-Lin Chiang, Evan Frick, Lisa Dunlap, Tianhao Wu, Banghua Zhu, Joseph Gonzalez, and Ion Stoica. 2024c. From crowdsourced data to highquality benchmarks: Arena-hard and benchbuilder pipeline. ArXiv preprint, abs/2406.11939. Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Omer Levy, Luke Zettlemoyer, Jason Weston, and Mike Lewis. Self-alignment with instruction backtranslation. In The Twelfth International Conference on Learning Representations. Yunshui Li, Binyuan Hui, Xiaobo Xia, Jiaxi Yang, Min Yang, Lei Zhang, Shuzheng Si, Ling-Hao Chen, Junhao Liu, Tongliang Liu, Fei Huang, and Yongbin Li. 2024d. One-shot learning as instruction data prospector for large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024, pages 45864601. Association for Computational Linguistics. Yilun Liu, Shimin Tao, Xiaofeng Zhao, Ming Zhu, Wenbing Ma, Junhao Zhu, Chang Su, Yutai Hou, Miao Zhang, Min Zhang, et al. 2024. Coachlm: Automatic instruction revisions improve the data quality in llm instruction tuning. In 2024 IEEE 40th International Conference on Data Engineering (ICDE), pages 51845197. IEEE. Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc Le, Barret Zoph, Jason Wei, et al. 2023. The flan collection: Designing data and methods for effective instruction tuning. In International Conference on Machine Learning, pages 2263122648. PMLR. Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023. Orca: Progressive learning from complex explanation traces of gpt-4. ArXiv preprint, abs/2306.02707. Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with gpt-4. ArXiv preprint, abs/2304.03277. Mengjie Ren, Boxi Cao, Hongyu Lin, Cao Liu, Xianpei Han, Ke Zeng, Wan Guanglu, Xunliang Cai, and Le Sun. 2024. Learning or self-aligning? rethinking instruction fine-tuning. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6090 6105, Bangkok, Thailand. Association for Computational Linguistics. Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. 2022. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. ArXiv preprint, abs/2206.04615. Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming Yang, and Chuang Gan. 2024. Principle-driven selfalignment of language models from scratch with minimal human supervision. Advances in Neural Information Processing Systems, 36. Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny Zhou, and Jason Wei. 2023. Challenging BIG-bench tasks and whether chain-of-thought can solve them. In Findings of the Association for Computational Linguistics: ACL 2023, pages 1300313051, Toronto, Canada. Association for Computational Linguistics. Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori Hashimoto. Alpaca: strong, replicable instruction-following model; 2023. URL https://crfm. stanford. edu/2023/03/13/alpaca. html. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. ArXiv preprint, abs/2307.09288. Rui Wang, Hongru Wang, Fei Mi, Boyang Xue, Yi Chen, Kam-Fai Wong, and Ruifeng Xu. 2024. Enhancing large language models against inductive instructions with dual-critique prompting. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 53455363, Mexico City, Mexico. Association for Computational Linguistics. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023a. Self-instruct: Aligning language models with self-generated instructions. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1348413508. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b. Self-instruct: Aligning language models with self-generated instructions. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1348413508, Toronto, Canada. Association for Computational Linguistics. Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur Sampat, Siddhartha Mishra, Sujan Reddy A, Sumanta Patro, Tanay Dixit, and Xudong Shen. 2022. Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 50855109, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2022. Finetuned language models are zero-shot learners. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions. Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and Bill Yuchen Lin. 2024. Magpie: Alignment data synthesis from scratch by prompting aligned llms with nothing. Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et al. 2023. Instruction tuning for large language models: survey. ArXiv preprint, abs/2308.10792. Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, and Helen Meng. 2024. Self-tuning: Instructing llms to effectively acquire new knowledge through self-teaching. Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2024. Lima: Less is more for alignment. Advances in Neural Information Processing Systems, 36."
        },
        {
            "title": "A Appendix",
            "content": "A."
        },
        {
            "title": "Implementation Details of NILE",
            "content": "For all experiments in this work, we use the Python 3.10.14 environment and vLLM 0.5.5 library7 for LLM local inference of both MISTRAL and LLAMA-3. For vLLM inference hypermeters, we set the random seed to 42, max_tokens to 1024, temperature to 0.7, top_k to 50, top_p to 0.7, and repetition_penalty to 1. We run all experiments on server with an Intel Xeon Silver 4309Y CPU and 8 Nvidia RTX A6000 GPU having 48GB GDDR6 VRAM, and we utilize official checkpoints MISTRAL-7B-V0.38 for MISTRAL and LLAMA-3.1-8B9 for LLAMA-3. 7https://github.com/vllm-project/vllm 8https://huggingface.co/mistralai/ Mistral-7B-v0.3 9https://huggingface.co/meta-llama/Llama-3. 1-8B For LLM instruction fine-tuning in this work, we choose llama-recipes10 for LLAMA-3 and alignment-handbook11 for MISTRAL. For LLAMA3 fine-tuning, we set context_length to 2048, gradient_accumulation_step to 32, learning rate to 2e5, and training batch size to 4. As for MISTRAL fine-tuning, we set context_length to 2048, gradient_accumulation_step to 32, learning rate to 2e-5, training batch size to 4, lr_scheduler_type to \"cosine\", num_train_epochs to 3, and warmup_ratio to 0.1. Fine-tuning for both LLAMA-3 and MISTRAL is done within 5 hours using 8 A6000 GPU. A.1.1 Internal Knowledge Extraction (IKE) , inputd For demonstration sample, we randomly sample = 5, 000 instruction pairs qd = {instructiond } from Alpaca dataset12, since instructions in it are simple and straightforward, which is suitable for LLM demonstration learning. We leverage GPT-4-TURBO-2024-0409 through Openai API as the teacher LLMs for generating demonstrations given qd shown in Table 1. For GPT-4 endpoints, we use openai 1.42.0 python library and set to 1, temperature to 0.7, and max_tokens to 1,024. We stick to the regulations from the OpenAI company when accessing its API. For retriever in IKE, we choose the BM25 and Contriver implementation13 from the Pyserini 0.38.0 library. A.1.2 Design Choice: BM25 vs Contriver The performance gain of the NILE choosing BM25 over Contriver in IKE is shown in Table 8. A.1."
        },
        {
            "title": "IKE Sample Demonstration",
            "content": "Table 9 illustrates the sample 2-shot demonstration set from IKE, and Table 10 shows two samples from the demonstration database demo in IKE. A.1.4 Knowledge-aware Sample Revision (KSR) For KSR, we also use GPT-4-TURBO-2024-0409 endpoint as revisor agent Ar. We use openai 1.42.0 python library with set to 1, temperature to 0.7, and max_tokens to 1,024. We run KSR on 52,000 samples from the Alpaca dataset and 50,000 samples from the OpenOrca dataset. Case 10https://github.com/meta-llama/llama-recipes 11https://github.com/huggingface/ alignment-handbook 12https://huggingface.co/datasets/vicgalle/ alpaca-gpt4 13https://github.com/castorini/pyserini Method Arena-Hard Alpaca-Eval V2 MTBench BBH ORCA + NILE W. CONTRIVER ORCA + NILE W. BM25 4.70 5.50 14.63 / 12.17 13.00 / 11.50 7.29 7. 64.00 64.29 Table 8: Comparison between choosing BM25 and Contriver. The highest values are bolded. 2 )}: 2 , ikR 1 ), (qR Instruction instructiono: Recommend 3 books that could get someone into new field of study. Input inputo: None 2-shot Demonstration demo(qo) = {(qR 1 , ikR qR 1 : Provide 3 pieces of advice for someone who is struggling to stay motivated in their studies. ikR 1 : 1. Understanding Motivation: It is essential to comprehend the concept of motivation, including intrinsic and extrinsic motivation. Intrinsic motivation refers to doing something because it is inherently interesting or enjoyable, while extrinsic motivation involves doing something because it leads to separable outcome. Understanding these types of motivation can help identify what drives an individuals desire to study and how to bolster it. 2. Goal Setting: Knowledge of effective goal-setting strategies is crucial. Setting specific, measurable, achievable, relevant, and time-bound (SMART) goals can help create clear roadmap for studying. This process can help break down the overwhelming feeling into manageable tasks, making it easier to stay motivated. ...... qR 2 : Please recommend movie for someone who likes animated films. ikR 2 : 1. Understanding Animated Films: Animated films, also known as cartoons, use drawn or computer-generated imagery to create the illusion of movement. They can be in 2D, 3D, stop-motion or other animation techniques. Knowledge of the different styles and techniques of animation is crucial to recommending films that align with specific preferences. 2. Popular Animation Studios: Some of the most prominent animation studios include Disney, Pixar, DreamWorks, Studio Ghibli, and Illumination. Each studio has its own unique style and storytelling approach. Familiarity with the filmographies of these studios can help in making informed recommendations. 3. Genres within Animation: Animated films encompass wide range of genres, from adventure and fantasy to drama and comedy. Some animated films are targeted towards children, while others might appeal to broader age range including adults. Understanding the various genres and their target audiences can guide the recommendation process. 4. Cultural and Thematic Elements: Animated films often incorporate diverse cultural stories and themes. Films might explore complex themes like identity, family, and morality, or might be more light-hearted and comedic. Awareness of these elements can help match film to viewers personal interests and values. ...... Table 9: Sample 2-shot demonstration in IKE. studies of KSR can be found in Table 13. These results display the KSRs capability to infuse internal knowledge information into original answers through revision. A.1.5 Sample Revision (SR) Unlike KSR, SAMPLE REVISION (SR) does not revise for each instruction pair (qo, ao). Therefore, Ar in SR only uses external knowledge such as world knowledge from (qo, ao) and its own paramqd 1 : What would be the best type of exercise for person who has arthritis? ikd 1 : 1. Understanding Arthritis: Arthritis is chronic condition characterized by inflammation in the joints, which can cause pain, stiffness, and reduced mobility. There are different types of arthritis, such as osteoarthritis and rheumatoid arthritis, each with varying symptoms and treatment approaches. 2. Impact of Exercise on Arthritis: Exercise is generally considered beneficial for individuals with arthritis. It can help to reduce joint pain, increase flexibility, improve muscle strength, enhance endurance, and promote overall physical function. 3. Types of Exercise Suitable for Arthritis: - Low-impact Aerobic Activities: These exercises are gentle on the joints and include walking, swimming, and cycling. They help in cardiovascular conditioning without putting excessive stress on the joints. - Resistance Training: Using light weights or resistance bands can help strengthen the muscles around the joints, providing better support and reducing the burden on the joints. - Flexibility Exercises: Activities such as stretching and yoga can improve joint flexibility and range of motion, helping to alleviate stiffness. ...... qd 2 : Calculate the atomic mass for lithium. ikd 2 : 1. Understanding Atomic Mass: Atomic mass, also known as atomic weight, is defined as the weighted average mass of atoms of an element based on the abundance of each isotope of the element in nature. It is usually measured in atomic mass units (amu). 2. Isotopes: Isotopes are atoms of the same element that have the same number of protons but different numbers of neutrons. This results in different mass numbers for each isotope. The atomic mass of an element is calculated by taking into account the masses and relative abundances of all its naturally occurring isotopes. 3. Lithium Isotopes: Lithium has two stable isotopes, lithium-6 (6Li) and lithium-7 (7Li). These isotopes differ in their neutron count, affecting their individual atomic masses. Lithium-6 has 3 neutrons, while lithium-7 has 4 neutrons. 4. Natural Abundance: The natural abundance of an isotope refers to the percentage of that isotope found naturally in sample of the element. For lithium, lithium-7 is more abundant than lithium-6. The exact percentages of natural abundance can vary slightly depending on the source, but generally, lithium-7 accounts for about 92.5% while lithium-6 is about 7.5%. ...... Table 10: Samples from demonstration database demo in IKE. eter knowledge, being completely isolated from internal knowledge ikM qo of M. Table 11 shows the detailed prompt of the revisor Ar in SR. Provide better response based on \"{ao}\" to comply with given instruction, input, and related knowledge. A.2 Experiment Details A.2.1 Benchmarks Instruction: {instructiono} Input:{inputo} We use the officially recommended settings from all benchmarks for evaluation. For Alpaca-Eval V2, we use \"alpaca_eval_cot_gpt4_turbo_fn\" as annotators, and we set max_new_tokens to 1024, temperature to 1.0, top_p to 1.0 and batch_size to 128. For Arena-Hard, we set temperature to Please directly output the improved response. Table 11: Prompt for Sample Revision. 0.0, max_tokens to 1024, judge_model to gpt-41106-preview, baseline_model to gpt-4-0314, and num_choices to 1. For BBH and MTBench, we use the default settings in the official source code. A.2.2 Fixed Demonstration (FD) Table 12 provides the prompt of the Fixed Demonstration (FD) used for extracting LLM internal knowledge in the experiments. The FD employs fixed set of 2-shot demonstrations, serving as baseline for IKE without incorporating demonstration learning. A.2.3 Effects of KSR Sentence embedding similarity distribution plots across datasets and models are Table 4. The average similarity score of KSR outputs in these plots consistently exceeds that of the other two outputs. All distribution are proven by the Chi-squared Test to be significantly different from each other with the p-value lower than 0.01. Figure 4: Distribution of sentence embedding similarity across different LLMs and IFT datasets. Instruction: \"Give three tips for staying healthy.\" Related Knowledge: * Importance of health: Maintaining good health is crucial for overall well-being and quality of life. * Factors affecting health: persons health can be influenced by various factors such as diet, exercise, sleep, stress, and genetics. * Prevention is key: Preventing illnesses and maintaining good health requires adopting healthy habits and making lifestyle changes. * Healthy habits: Developing healthy habits such as regular exercise, balanced diet, and adequate sleep can help prevent chronic diseases. * Lifestyle changes: Making lifestyle changes such as quitting smoking, reducing sugar intake, and managing stress can also contribute to good health. * Importance of self-care: Taking care of ones physical, emotional, and mental health is essential for overall well-being. * Access to healthcare: Having access to quality healthcare and medical facilities is also important for staying healthy. * Healthy behaviors: Engaging in healthy behaviors such as regular check-ups, vaccinations, and screenings can help prevent illnesses and detect health issues early. * Health literacy: Having knowledge and understanding of health-related information is important for making informed decisions about ones health. Instruction: \"What are the three primary colors?\" Related Knowledge: * Primary colors are colors that cannot be created by mixing other colors together. * The three primary colors are: 1. Red 2. Blue 3. Yellow * Primary colors are the base colors used to create all other colors. * By mixing different combinations of primary colors, you can create secondary colors, tertiary colors, and wide range of shades and hues. * Primary colors are often used in art, design, and painting to create bold and vibrant colors. * The primary colors are also used in color theory to understand how colors interact with each other and how they can be used to create contrast, harmony, and balance. * In addition to art and design, primary colors are also used in science, technology, engineering, and mathematics (STEM) fields, such as physics, chemistry, and biology, to describe and analyze the properties of light and color. * The primary colors are fundamental concept in many cultures and have been used in art and design for centuries, with examples found in ancient civilizations such as Egypt, Greece, and China. Instruction: {instructiono, inputo} Related Knowledge: Table 12: Prompt for Fixed Demonstration (FD)."
        },
        {
            "title": "Internal Knowledge",
            "content": "Vanilla: \"Reminder: Renew Your Subscription Today!\" Revised: \"Action Required: Time to Renew Your Subscription!\" Compose new email subject line for following email. Input: The email body contains request to renew subscription. senWrite tence containing hyperbolic metaphor. Input: None Vanilla: He was so hungry, he could eat an entire elephant. Revised: He was so ravenous, he could devour mountain of hamburgers as tall as Everest. Create 3-5 sentence definition for the term \"data science\". Input: None Vanilla: Data science is an interdisciplinary field that combines techniques from statistics, mathematics, computer science, and information science to extract insights and knowledge from data. This field deals with both structured and unstructured data, using algorithms, predictive models, and machine learning to make informed decisions. Data science has broad applications, from businesses and marketing to healthcare and scientific research, where it is used to answer questions, find patterns, and make strategic decisions. Revised: Data science is an interdisciplinary field that uses methods from statistics, mathematics, computer science, and domain-specific knowledge to extract insights and information from both structured and unstructured data. It employs techniques such as machine learning, predictive modeling, and data mining to analyze data sets, identify patterns, and make predictions. The ultimate goal of data science is to help organizations make informed decisions, optimize processes, and solve complex problems by leveraging vast amounts of data. This field is critical across various industries, including healthcare, finance, and technology, where data-driven insights are essential for strategic decision-making and operational improvements. Email subject line: The subject line of an email is the first thing recipient sees and can determine whether they open the email or not. It should be clear, concise, and relevant to the email content.* Subscription renewal: subscription renewal is request to continue receiving service or product after the initial subscription period has ended. It is important to provide clear instructions and information about the renewal process.* Clear instructions: Providing clear instructions in the email body can help ensure that the recipient understands the request and knows what to do next. It is important to use simple language and avoid technical jargon.* Information about renewal process: Including information about the renewal process, such as the cost, payment options, and deadlines, can help the recipient make an informed decision and take the necessary steps to renew their subscription.* Call-to-action: Including clear call-to-action in the email body can help ensure that the recipient knows what to do next and takes the desired action. It is important to use strong and direct call-to-action that is easy to understand and takes the recipient to the next step. Hyperbole is figure of speech that uses exaggeration for emphasis or effect.* Hyperbolic metaphors are metaphors that use hyperbole to create vivid and dramatic image.* For example, \"The crowd was so large that it stretched from one end of the stadium to the other.\"* This metaphor uses hyperbole to create dramatic image of the crowds size.* Hyperbolic metaphors can be used to create strong emotional response or to make point more effectively.* They can also be used to add humor or to create sense of exaggeration or absurdity. Data science is an interdisciplinary field that combines techniques from statistics, computer science, and domain knowledge to extract insights from data.* It involves the use of advanced analytics and machine learning algorithms to analyze large datasets and identify patterns, trends, and correlations.* Data scientists use various tools and techniques such as data mining, predictive modeling, and natural language processing to uncover insights and make predictions about future events.* The goal of data science is to use data to solve complex problems, make better decisions, and drive business value.* Data science has become increasingly important in recent years due to the rapid growth of data and the need for organizations to make sense of it.* Data scientists play critical role in many industries, including healthcare, finance, retail, and technology, where they help organizations gain insights from data to improve operations, optimize processes, and make better decisions. Table 13: Case study of KSR. Related KSR revisions and internal knowledge are marked in red."
        }
    ],
    "affiliations": [
        "City University of Hong Kong",
        "Huawei Noahs Ark Lab",
        "The Chinese University of Hong Kong"
    ]
}