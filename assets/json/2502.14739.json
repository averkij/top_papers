{
    "paper_title": "SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines",
    "authors": [
        "M-A-P Team",
        "Xinrun Du",
        "Yifan Yao",
        "Kaijing Ma",
        "Bingli Wang",
        "Tianyu Zheng",
        "Kang Zhu",
        "Minghao Liu",
        "Yiming Liang",
        "Xiaolong Jin",
        "Zhenlin Wei",
        "Chujie Zheng",
        "Kaixing Deng",
        "Shuyue Guo",
        "Shian Jia",
        "Sichao Jiang",
        "Yiyan Liao",
        "Rui Li",
        "Qinrui Li",
        "Sirun Li",
        "Yizhi Li",
        "Yunwen Li",
        "Dehua Ma",
        "Yuansheng Ni",
        "Haoran Que",
        "Qiyao Wang",
        "Zhoufutu Wen",
        "Siwei Wu",
        "Tianshun Xing",
        "Ming Xu",
        "Zhenzhu Yang",
        "Zekun Moore Wang",
        "Junting Zhou",
        "Yuelin Bai",
        "Xingyuan Bu",
        "Chenglin Cai",
        "Liang Chen",
        "Yifan Chen",
        "Chengtuo Cheng",
        "Tianhao Cheng",
        "Keyi Ding",
        "Siming Huang",
        "Yun Huang",
        "Yaoru Li",
        "Yizhe Li",
        "Zhaoqun Li",
        "Tianhao Liang",
        "Chengdong Lin",
        "Hongquan Lin",
        "Yinghao Ma",
        "Zhongyuan Peng",
        "Zifan Peng",
        "Qige Qi",
        "Shi Qiu",
        "Xingwei Qu",
        "Yizhou Tan",
        "Zili Wang",
        "Chenqing Wang",
        "Hao Wang",
        "Yiya Wang",
        "Yubo Wang",
        "Jiajun Xu",
        "Kexin Yang",
        "Ruibin Yuan",
        "Yuanhao Yue",
        "Tianyang Zhan",
        "Chun Zhang",
        "Jingyang Zhang",
        "Xiyue Zhang",
        "Xingjian Zhang",
        "Yue Zhang",
        "Yongchi Zhao",
        "Xiangyu Zheng",
        "Chenghua Zhong",
        "Yang Gao",
        "Zhoujun Li",
        "Dayiheng Liu",
        "Qian Liu",
        "Tianyu Liu",
        "Shiwen Ni",
        "Junran Peng",
        "Yujia Qin",
        "Wenbo Su",
        "Guoyin Wang",
        "Shi Wang",
        "Jian Yang",
        "Min Yang",
        "Meng Cao",
        "Xiang Yue",
        "Zhaoxiang Zhang",
        "Wangchunshu Zhou",
        "Jiaheng Liu",
        "Qunshu Lin",
        "Wenhao Huang",
        "Ge Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have demonstrated remarkable proficiency in mainstream academic disciplines such as mathematics, physics, and computer science. However, human knowledge encompasses over 200 specialized disciplines, far exceeding the scope of existing benchmarks. The capabilities of LLMs in many of these specialized fields-particularly in light industry, agriculture, and service-oriented disciplines-remain inadequately evaluated. To address this gap, we present SuperGPQA, a comprehensive benchmark that evaluates graduate-level knowledge and reasoning capabilities across 285 disciplines. Our benchmark employs a novel Human-LLM collaborative filtering mechanism to eliminate trivial or ambiguous questions through iterative refinement based on both LLM responses and expert feedback. Our experimental results reveal significant room for improvement in the performance of current state-of-the-art LLMs across diverse knowledge domains (e.g., the reasoning-focused model DeepSeek-R1 achieved the highest accuracy of 61.82% on SuperGPQA), highlighting the considerable gap between current model capabilities and artificial general intelligence. Additionally, we present comprehensive insights from our management of a large-scale annotation process, involving over 80 expert annotators and an interactive Human-LLM collaborative system, offering valuable methodological guidance for future research initiatives of comparable scope."
        },
        {
            "title": "Start",
            "content": "SuperGPQA: Scaling LLM Evaluation across"
        },
        {
            "title": "285 Graduate Disciplines",
            "content": "M-A-P ByteDance.Inc, 2077.AI https://supergpqa.github.io/"
        },
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have demonstrated remarkable proficiency in mainstream academic disciplines such as mathematics, physics, and computer science. However, human knowledge encompasses over 200 specialized disciplines, far exceeding the scope of existing benchmarks. The capabilities of LLMs in many of these specialized fieldsparticularly in light industry, agriculture, and service-oriented disciplinesremain inadequately evaluated. To address this gap, we present SuperGPQA, comprehensive benchmark that evaluates graduate-level knowledge and reasoning capabilities across 285 disciplines. Our benchmark employs novel Human-LLM collaborative filtering mechanism to eliminate trivial or ambiguous questions through iterative refinement based on both LLM responses and expert feedback. Our experimental results reveal significant room for improvement in the performance of current state-of-the-art LLMs across diverse knowledge domains ( e.g., the reasoning-focused model DeepSeek-R1 achieved the highest accuracy of 61.82% on SuperGPQA), highlighting the considerable gap between current model capabilities and artificial general intelligence. Additionally, we present comprehensive insights from our management of large-scale annotation process, involving over 80 expert annotators and an interactive Human-LLM collaborative system, offering valuable methodological guidance for future research initiatives of comparable scope. 5 2 0 2 0 2 ] . [ 1 9 3 7 4 1 . 2 0 5 2 : r Figure 1. Benchmark Comparison. Left: Radar Chart. Discrimination: The degree of distinction between different models (detailed in Sec. 4.4). Climbing Space: The remaining improvement space for the SOTA models. Corr. with Arena: Correlation with Chatbot Arena Elo scores. Right: Performance comparison of SOTA models across different benchmarks."
        },
        {
            "title": "Contents",
            "content": "1 Introduction 2 Data Collection 2.1 Source Screening . 2.2 Transcription . . . . . . 2.3 Quality Inspection . 3 Statistics 4 Experiments 4.1 Baseline Models . 4.2 Main Results . . ."
        },
        {
            "title": "4.3 Further Analysis .",
            "content": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.4 Analysis of Disciplinary Discrimination Power . . . . . . . . . . . . . . ."
        },
        {
            "title": "5 Related Work",
            "content": "5.1 Large Language Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2 LLM Benchmarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "6 Contributions and Acknowledgements",
            "content": "A Difficulty-Stratified Samples"
        },
        {
            "title": "B Annotation Tutorial",
            "content": "B.1 Material Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.2 Annotation Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.2.1 Original Transcription Method . . . . . . . . . . . . . . . . . . . . B.2.2 Non-Choice Conversion Method . . . . . . . . . . . . . . . . . . . B.2.3 Statement Combination Method . . . . . . . . . . . . . . . . . . . B.2.4 Confusion-options Generation . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "C Data Filtering and Manual Review Process Details",
            "content": "C.1 Rule-Based Pre-Check . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.2 LLM-Based Quality Inspection . . . . . . . . . . . . . . . . . . . . . . . . C.2.1 Validity Check . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.2.2 Negative and Extreme Inquiry Detection . . . . . . . . . . . . . . C.2.3 Multimodal Exclusion . . . . . . . . . . . . . . . . . . . . . . . . . 2 4 5 6 8 10 16 16 16 20 25 25 25 26 39 41 42 42 43 44 47 47 48 49 50 C.2.4 Field Relevance Evaluation . . . . . . . . . . . . . . . . . . . . . . C.2.5 Completeness Assessment . . . . . . . . . . . . . . . . . . . . . . . C.3 Manual Quality Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.4 Reasons for Failing Quality Inspection . . . . . . . . . . . . . . . . . . . . Quantitative Overview of Disciplines at Three Levels Detailed Dataset Statistics Evaluation Prompt F.1 Zero-shot Prompt . F.2 Five-shot Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Further Experiment Analysis G.1 Impact of Subfield Information . . . . . . . . . . . . . . . . . . . . . . . . G.2 Robustness of the Evaluation . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "J More Comprehensive Analysis of Baseline Performances",
            "content": "K Ranking of the Top Five Models in Each of the 285 Subfields 54 56 58 59 66 69 69 69 72 73 77 84"
        },
        {
            "title": "L Detailed Scores of Each Discipline for All Evaluated Models",
            "content": "103 3 1. Introduction Large language models (LLMs) have greatly changed human life. LLMs are seen as the next technological singularity and proved to surpass human performance in many areas [Phan et al., 2025], significantly improving work efficiency. However, the measurement of LLMs accessibility on various real-world professionalism remains an unresolved issue, especially in the long-tailed fields with less attention, such as light industry, agriculture, and various service-related disciplines. Many popular benchmarks, such as MMLU [Hendrycks et al., 2020], GPQA [Rein et al., 2023], and MMLU-pro [Wang et al., 2024b], evaluate LLMs abilities across different fields, while mainly focus on common fields like mathematics, physics, chemistry, biology, and law, limiting these benchmarks practical significance on many real-world professionalisms. These benchmarks fail to cover the diverse and long-tail knowledge accumulated by humans. Moreover, large language models have achieved very high scores on these benchmarks, making them lose their value as challenging frontiers. To address the gap, we introduce SuperGPQA, comprehensive evaluation at the boundaries of human knowledge covering the evaluation of 285 graduate-level disciplines knowledge and reasoning capacities. SuperGPQA provides at least 50 questions for each graduate-level disciplines to guarantee its accessibility on various real-world professionalism. SuperGPQA is developed by large-scale human-LLM collaboration system, with crowd-sourcing annotators, experts, and state-of-the-art (SOTA) LLMs participating in, and then verified by rigorous 3-stage quality inspection process, to guarantee its reliability. Moreover, SuperGPQA is qualified as challenging frontier for SOTA reasoning LLMs, instruct LLMs, and base LLMs, where the best LLMs (e.g., o1 and Deepseek-R1) only achieve score of around 60. For building SuperGPQA, we propose large-scale human-LLM collaboration system and share the valuable lessons learned in the paper. We divide the annotation system of SuperGPQA into three major stages: Source Screening, Transcription, and Quality Inspection. During the source screening stage, expert annotators collect credible resources of different disciplines questions to guarantee the reliability and difficulty of the raw questions. During the transcription stage, crowd-sourcing annotators are asked to revise or translate the raw questions to multiple-choice questions, generate complementary confusion options, and estimate the difficulty and reliability of these questions. Crowd-sourcing annotators estimate the difficulty and reliability of candidate questions based on both expert judgments and the accuracy of LLMs responses during 4 the annotation process. Crowd-sourcing annotators, rigorous real-time plagiarism checks with existing candidate questions, and robust filtering system based on SOTA LLMs are adopted in the transcription stage to reduce the waste of funding and expert manpower. During the quality inspection stage, we adopt rigorous three-stage quality inspection process: We select suspicious candidate questions based on checklist of LLMs responses. Expert annotators review the suspicious candidate questions with unrestricted access to the web and revise these questions. The easy questions are further tailored based on the accuracy of LLMs responses to guarantee the discrimination of SuperGPQA. We share several major insights based on the evaluation results of SuperGPQA: Reasoning capacities matter. The reasoning models (e.g., DeepSeek-R1, o1-202412-17) achieve the best performance in SuperGPQA. Instruction tuning is very helpful. For example, the results (47.40, 40.75) of DeepSeek-V3 and Qwen2.5-72B-Instruct are better than the results (32.14, 34.33) of DeepSeek-V3-Base and Qwen2.5-72B lot, respectively. More powerful LLMs lead to more balanced results. On different difficulties. the results of simple, middle, and hard splits of DeepSeek-R1 are 63.59, 63.63, and 56.87. In contrast, the results of easy, middle, and hard splits of Qwen2.5-14B-Instruct are 44.82, 37.90, and 19.97. Models are better in newer versions. For example, the results of GPT-4o-2024-1120, GPT-4o-2024-08-06, and GPT-4o-2024-05-13 are 44.40, 41.64, and 39.76, respectively. 2. Data Collection We solicit difficult questions from well-educated experts and crowd-sourcing annotators, where we consider experts as individuals having or pursuing PhD, as in GPQA [Rein et al., 2023], and crowd-sourcing annotators as undergraduates and master students from top-tier Chinese universities, i.e.mainly from Tsinghua University, Peking University, Zhejiang University, Beihang University, and Chinese Academy of Sciences. Figure shows the three major stages of SuperGPQAs data collection pipeline: Source Screening, Transcription, and Quality Inspection, which are separately detailed in subsection 2.1, 5 subsection 2.2, and subsection 2.3. First, experts select credible resources of different disciplines questions. Second, crowd-sourcing annotators revise the raw questions from credible resources to candidate questions. Finally, rigorous human-LLM collaboration quality inspection process is adopted to select difficult and reliable questions from candidate questions. Figure 2. Data Collection Process of SuperGPQA. 2.1. Source Screening Lessons: Crowd-Sourcing Annotators are not capable of collecting credible resources for multiple-choice question annotation with high expertise requirements. The questions and answers (QAs) on exercise websites are not always reliable, even sometimes these QAs are claimed verified. Multiple-choice questions modified from calculation and reasoning problems usually are more discriminatory than the original multi-choice questions available online. During the source screening stage, only expert annotators are allowed to collect credible resources of different disciplines questions to guarantee the reliability and difficulty of the raw questions. In the early stage of collecting candidate questions of SuperGPQA, we trust crowd-sourcing annotators to collect credible resources themselves. 6 However, the candidate questions based on the resources found by the crowd-sourcing annotators are always judged too easy or unreliable by expert annotators. As result, significant portion of early funding is wasted on ineffective questions annotated by crowd-sourcing annotators. Additionally, we point out that QAs on exercise websites are not always reliable. In the early stage of SuperGPQA collection process, some annotators, even expert annotators, trust exercise websites that serve as corroboration of their reasoning process and answers. In the subsequent quality inspection stage, this proved to be costly mistake, leading us to spend significant amount of time and cost correcting erroneous answers derived from online exercise websites. Furthermore, we find that many SOTA LLMs, such as GPT-4o, o1-mini, and Gemini-flash, exhibit high frequency of consistency in both process and answers with the erroneous processes and answers from several online exercise websites. The observations reveal that the reliability of the solutions provided by online exercise websites is limited and there is significant risk of data leakage. Expert annotators are asked to provide raw questions from credible resources with screenshot for further annotation in the source screening stage. The screenshot greatly eases the workload of quality inspection. We observe that the efficiency of quality inspection is greatly improved with the source screenshot provided. The priority order for selecting original questions is: Example problems with solutions from textbooks. Calculation and reasoning-needed questions with solutions from websites. Reasoning-needed multiple-choice questions with solutions from websites. General multiple-choice questions with solutions from websites. Questions only with answers but deemed correct by expert annotators. sampled list of credible resources certified by expert annotators is provided in Appendix and Appendix for reference. 7 Figure 3. Rewriting Samples of Questions Requiring the Selection of Correct or Incorrect Options. 2.2. Transcription Lessons: Crowd-sourcing annotators have low accuracy in judging generated distractors. For question types like selecting correct or incorrect options, it is easy to generate flawed distractors, requiring unified rewriting at this stage. During the transcription stage, crowd-sourcing annotators are asked to revise the original questions into candidate questions. Specifically, the following operations are performed: Translate non-English questions into English with academic language. Convert non-multiple-choice questions into multiple-choice format. Standardize the rewriting of questions requiring the selection of correct or incorrect statements, as shown in Figure 3. Include region-specific information where necessary, such as specifying the country for laws mentioned in the questions, except for universally accepted rules. The questions requiring the selection of correct or incorrect statements must be standardized as shown in Figure 3. Because we notice that even SOTA LLMs, e.g. Claude-3.5Sonnet, GPT-4o-0806, suffer from generating correct suitable confounders for questions 8 requiring the selection of correct or incorrect statements. The full transcription tutorial is provided in Appendix B. 2.3. Quality Inspection Lessons: Questions where LLMs choose the same incorrect option are highly suspicious. Cases where multiple or all SOTA LLMs make the same error often indicate that the LLMs have memorized explanations from incorrect exercise websites, based on SOTA LLMs responses. We refer to the data quality inspection and filtering methods used in LIME and MMLU-Redux Zhu et al. [2024], Gema et al. [2024], Wu et al. [2024], etc. The quality inspection process consists of three substages: Rule-based Quality Inspection, LLMbased Quality Inspection, and Expert-based Quality Inspection. Candidate questions with clear formatting issues are identified and filtered out by rule-based quality inspection. The full checklist of rule-based quality inspection refers to subsection C.1. We then adopt several SOTA LLMs to generate responses and additional tags to these reserved candidate questions. LLM-based quality inspection includes validity checks, negative and extreme inquiry detection, multimodal exclusion, field relevance evaluation, completeness assessment, and discrimination tagging based on SOTA LLMs responses. It provides an estimation of not only the correctness but also the discrimination of the candidate questions. Finally, we ask the expert annotators to re-annotate the suspicious candidate questions. The checklist for selecting suspicious candidate questions refer to subsection C.2. We adopt GPT-4o-2024-08-06, Gemini-2.0-flash, Doubao-1.5-pro-32k-250115, Claude-3.5-Sonnet, DeepSeek-R1, QwQ, Qwen-2.5-72B-Instruct as SOTA LLMs for selecting suspicious candidate questions. During the re-annotation process, following the rules stated in GPQA [Rein et al., 2023], expert annotators are asked to review and solve the given candidate questions with unrestricted access to the web. They spend over 30 minutes on each candidate question according to the post-annotation interview. The tutorial for manual quality review refers to subsection C.3. 3. Statistics Discipline #Num. Question #Tokens Answer #Tokens Options Cal. Rate Max Min Avg Max Min Avg #Num. #Tokens Engineering Medicine Science Philosophy Military Science Economics Management Sociology Literature History Agriculture Law Education Overall 7892 2755 9838 347 205 501 143 1676 674 485 484 26529 715 447 623 336 314 308 107 869 331 560 173 869 4 5 5 7 5 7 5 6 7 6 7 67.26 352 39.06 89 69.77 44.63 30.03 36.15 71 50 41.87 217 25.31 35.80 75 28.38 125 27.25 66.38 23.35 89 37 58.42 372 1 1 1 1 1 1 1 1 1 1 1 13.86 7.57 16.89 8.93 6.76 7. 7.77 7.34 6.82 5.32 5.32 12. 5.74 12.86 9.76 9.67 9.71 9. 9.29 9.86 9.72 9.87 8.78 9. 9.91 9.73 9.78 9.67 13.67 7. 16.75 8.42 6.40 7.12 6.62 6. 6.75 5.49 5.24 11.45 5.39 12. 55.40% 3.34% 66.34% 0.29% 3.41% 20.50% 3.79% 2.10% 0.60% 1.04% 1.44% 0.46% 0.41% 42.33% Table 1. Statistics of SuperGPQA. Tokens are calculated with Tiktoken using cl100k_base encoding. We propose SuperGPQA, designed as comprehensive benchmark to probe the upper bounds of state-of-the-art Large Language Models capabilities. With 26,529 questions spanning 13 disciplines, 72 fields, and 285 subfields, it substantially surpasses existing benchmarks in both scale and taxonomic depth. Compared to similar hard benchmarks such as GPQA (448 questions) and MMLU-Pro (12,032 questions), SuperGPQA not only contains larger question pool but also features more challenging format with an average of 9.67 options per question, significantly higher than the conventional 4-option format (e.g., MMLU). Comprehensiveness and Discrimination. As revealed in Table 1, the distribution of questions across disciplines reveals notable concentration in STEM fields, with Science (9,838 questions), Engineering (7,892 questions), and Medicine (2,755 questions) collectively accounting for 77.2% of the benchmark. While this distribution might appear uneven at first glance, it emerges from our rigorous question collection and validation process. During the data annotation phase, we source comparable number of reference books for each of the 285 subfields (the subfields are detailed in Table 2 and 10 Discipline Agronomy(485) Economics(873) Education(484) Engineering(7892) Field : Subfield Animal Husbandry(103) : Animal Nut. & Feed Sci.; Animal Rear. & Breed. Aquaculture(56) : Aquacult. Crop Science(145) : Crop Sci. Forestry(131) : Forest Cult. & Gen. Breed.; Landsc. Plants & Orn. Hort. Veterinary Medicine(50) : Vet. Med. Applied Economics(723) : Econ. Stats.; Fin.; Indus. Econ.; Int. Trade; Labor Econ.; Nat. & Def. Econ.; Pub. Fin.; Quant. Econ. Theoretical Economics(150) : Econ. Hist.; Pol. Econ.; West. Econ. Education(247) : Edu. Tech. & Prin.; Presch. Edu.; Spec. Edu.; Theory of Curric. & Instr. Physical Education(150) : Phys. Edu. & Train.; Sports Hum. & Socio.; Sports Sci. & Med. Psychology(87) : Psychol. Aeronautical and Astronautical Science and Technology(119) : Aeronaut. & Astronaut. Sci. & Tech. Agricultural Engineering(104) : Agric. Environ. & Soil-Water Eng.; Agric. Mech. Eng. Architecture(162) : Arch. Design & Theory; Arch. Hist.; Urban Plan. & Design Chemical Engineering and Technology(410) : Chem. Transport Eng.; Elem. of Chem. React. Eng.; Fluid Flow & Heat Transfer in Chem. Eng.; Mass Trans. & Sep. Process in Chem. Eng. Civil Engineering(358) : Bridge & Tunnel Eng.; Geotech. Eng.; Struct. Eng.; Urban Infra. Eng. Computer Science and Technology(763) : Adv. Prog. Lang.; Comp. Arch.; Comp. Net.; Comp. Soft. & Theory; Data Struc.; Databases; Formal Lang.; Oper. Sys.; Pattern Recog.; Princip. of Comp. Org. Control Science and Engineering(190) : Control Theory & Eng.; Guid. Nav. & Control; Oper. Res. & Cyber. Electrical Engineering(556) : Elect. Theory & New Tech.; High Volt. & Insul. Tech.; Power Elec. & Elec. Drives; Power Sys. & Autom. Electronic Science and Technology(246) : Circuits & Sys.; Electromag. Field & Microwave Tech.; Microelect. & Solid-State Elec. Environmental Science and Engineering(189) : Environ. Eng.; Environ. Sci.; Environ. & Res. Protect. Food Science and Engineering(109) : Food Biochem.; Food Proc. & Stor. Eng. Forestry Engineering(100) : Forest Eng.; Wood Sci. & Tech. Geological Resources and Geological Engineering(50) : Geol. Res. & Geol. Eng. Hydraulic Engineering(218) : Hydraul. & Hydrol.; Water Cons. & Hydropower Eng. Information and Communication Engineering(504) : Antenna & Radio Comm.; Comm. Prin.; Comm. & Info. Sys.; Optical Fiber Comm.; Signal & Info. Proc. Instrument Science and Technology(50) : Instr. Sci. & Tech. Materials Science and Engineering(289) : Mater. Phys. & Chem.; Mater. Proc. Eng. Mechanical Engineering(176) : Manuf. Autom.; Mechatron. Eng. Mechanics(908) : Fund. of Dyn. & Control; Rigid Body Mech.; Solid Mech.; Theor. Fluid Mech.; Theor. Mech. Metallurgical Engineering(255) : Iron & Steel Metall.; Non-fer. Metall.; Phys. Chem. of Metall. Proc.; Princip. of Metall. Mining Engineering(100) : Mineral Proc. Eng.; Mining & Safety Eng. Naval Architecture and Ocean Engineering(138) : Marine Eng.; Ship Mech. & Design Prin. Nuclear Science and Technology(107) : Nuc. Energy & React. Tech.; Radiation Prot. & Nuclear Tech. Appl. Optical Engineering(376) : Applied Opt.; Laser Tech.; Optoelect. Tech.; Theor. Opt. Petroleum and Natural Gas Engineering(112) : Oil & Gas Field Dev. & Stor. & Trans. Eng.; Poromech. & Res. Phys. Power Engineering and Engineering Thermophysics(684) : Eng. Fluid Mech.; Eng. Thermophys.; Fluid Mach. & Eng.; Heat Trans.; Internal Comb. Eng.; Power Mach. & Eng.; Refrig. & Cryogen. Eng.; Thermal Energy Eng. Surveying and Mapping Science and Technology(168) : Carto. & Geo. Info. Eng.; Dig. Survey. & Remote Sens. Appl.; Geodesy & Survey. Eng. Textile Science and Engineering(100) : Text. Chem. & Dyeing Eng.; Text. Mater. Sci. Transportation Engineering(251) : Road & Rail. Eng.; Traffic Info. Eng. & Control; Transp. Plan. & Manag.; Vehicle Oper. Eng. Weapon Science and Technology(100) : Mil. Chem. & Pyro.; Weapon Syst. Sci. & Eng. History(674) History(674) : Archaeol. & Museol.; Hist. Geo.; World Hist. Table 2. The Disciplinary Categories of SuperGPQA (1/2). Discipline Field : Subfield Law(656) Literature and Arts(1676) Management(501) Medicine(2755) Law(591) : Civil & Comm. Law; Const. & Admin. Law; Contract Law; Crim. Law; Int. Law; Law & Soc. Gov.; Legal Theory & Hist.; Mil. Law; Proced. Law Political Science(65) : Pol. Sci. Art Studies(603) : Broad. & TV Art; Dance Stud.; Design Arts; Drama & Opera Stud.; Film Stud.; Fine Arts Journalism and Communication(207) : Comm. & Broad.; Hist. & Theory of Jour. & Media Mngmt.; Jour. & News Prac. Language and Literature(440) : Class. Chinese Lit.; Fr. Lang. & Lit.; Ling. & Appl. Ling.; Lit. Hist.; Lit. Theory; Mod. & Cont. Chinese Lit.; Phil. & Bib.; Russ. Lang. & Lit. Musicology(426) : Comp.; Harm.; Instr. & Perf.; Music Hist., Ed. & Tech.; Music Forms & Anal.; Pitch & Scales Business Administration(142) : Bus. & Acct. Mngmt.; Tour. Mngmt. & Tech. Econ. Mngmt. Library, Information and Archival Management(150) : Info. Mngmt. Sci.; Info. Mngmt. & Comm.; Lib. & Arch. Sci. Management Science and Engineering(58) : Mngmt. Sci. & Eng. Public Administration(151) : Ed. Econ., Mngmt. & Soc. Sec.; Land Res. Mngmt. & Admin. Mngmt.; Soc. Med. & Health Mngmt. Basic Medicine(567) : For. Med.; Hum. Anat. & Hist.-Emb.; Immun.; Path. Biol.; Pathol. & Pathophys.; Rad. Med. Clinical Medicine(1218) : Anesth.; Clin. Lab. Diagn.; Derm. & Ven.; Emerg. Med.; Geriat. Med.; Imag. & Nucl. Med.; Intern. Med.; Neurol.; Nurs. & Rehabil. Med.; Obst. & Gyneco.; Oncol.; Ophth.; Oto. & Rhinol.; Pediatr.; Psych. & Ment. Health; Surg. Pharmacy(278) : Medic. Chem.; Microbiol. & Biochem. Pharm.; Pharm. Anal.; Pharmaceut.; Pharmacol. Public Health and Preventive Medicine(292) : Epidemiol. & Health Stats.; Health Tox. & Envir. Health; Matern., Child & Adol. Health; Nutr. & Food Hyg. Stomatology(132) : Basic Stom.; Clin. Stom. Traditional Chinese Medicine(268) : Trad. Chin. Health Pres.; Trad. Chin. Med. Theory; Trad. Chin. Pharm. Military Science(205) Military Science(205) : Mil. Command & Info. Systems; Mil. Logistics & Equip.; Mil. Mngmt.; Mil. Thought & Hist. Philosophy(347) Philosophy(347) : Ethics; Logic; Phil. Aesth.; Phil. of Sci. & Tech.; Relig. Stud. Science(9838) Astronomy(405) : Astron. Obs. & Tech.; Astrophys.; Cosmology; Solar Sys. Sci.; Stell. & Interst. Evol. Atmospheric Science(203) : Atm. Phys. & Envir.; Dyn. Meteorol.; Meteorol. Biology(1120) : Biochem. & Mol. Biol.; Biophys.; Botany; Cell Biol.; Ecol.; Genet.; Microbiol.; Physiol.; Zool. Chemistry(1769) : Analyt. Chem.; Electrochem.; Inorg. Chem.; Org. Chem.; Phys. Chem.; Polym. Chem. & Phys.; Radiochem. Geography(133) : Hum. Geogr.; Phys. Geogr. Geology(341) : Geochem.; Miner., Petrol. & Econ. Geol.; Paleontol. & Stratig.; Prin. of Seism. Expl.; Struct. Geol. Geophysics(100) : Solid Earth Geophys.; Space Phys. Mathematics(2622) : Adv. Algebra; Combinat. Math.; Comput. Math.; Crypt.; Discr. Math.; Func. of Complex Vars.; Func. of Real Vars.; Fund. Math.; Fuzzy Math.; Geo. & Topol.; Graph Theory; Group Theory; Math. Anal.; Num. Theory; Num. Anal.; Ord. Diff. Eq.; Poly. & Ser. Exp.; Prob. & Stats.; Spec. Num. Theory; Stoch. Proc. Oceanography(200) : Hydrogeol.; Marine Biol.; Marine Chem.; Underwater Acou. Physical Oceanography(50) : Phys. Oceanogr. Physics(2845) : Acou.; Atom. & Mol. Phys.; Electrodyn.; Fluid Phys.; Part. & Nucl. Phys.; Polym. Phys.; Quant. Mech.; Relativity; Semicond. Phys.; Solid State Phys.; Stat. Mech.; Subatom. & Atom. Phys.; Thermodyn.; Thermo. & Stat. Phys. Systems Science(50) : Sys. Sci. Sociology(143) Sociology(143) : Demo. & Anthrop.; Soc. & Folklore Studies Table 3. The Disciplinary Categories of SuperGPQA (2/2). Table 3 and the reference sources in Table 11, Appendix and Appendix I. However, the STEM disciplines yielded more questions meeting our stringent quality and difficulty criteria aforementioned in section 2, where the questions and options are filtered through rigorous rule-based, model-based and human-based pipeline. This natural emergence of STEM-heavy distribution aligns with the benchmarks goal of probing LLMs upper-bound capabilities in complex reasoning tasks. Despite the relatively smaller representation of non-STEM disciplines (e.g., Philosophy: 347, Literature: 1,676, History: 674 questions), our experiments demonstrate that these subsets effectively discriminate various SOTA LLMs performance levels (detailed in subsection 4.2). This once again validates the discriminative power of our benchmark across all domains, regardless of sample size. Difficulty. The difficulty distribution across disciplines  (Table 4)  reveals varying levels of complexity. In STEM fields, we observe more balanced distribution of difficulty levels. For instance, Engineering questions are distributed as 31.1% hard, 43.9% middle, and 25.0% easy, while Science shows 42.8% hard, 42.0% middle, and 15.2% easy. NonSTEM disciplines generally show different pattern, with higher proportion of easy and middle-difficulty questions. Notably, 42.33% of all questions require mathematical calculations or formal reasoning, with Science (66.34%) and Engineering (55.40%) showing the highest calculation rates. Difficulty Agro. Econ. Edu. Eng. Hist. Law Lit. & Arts Mgmt. Med. Military Sci. Phil. Sci. Socio. Hard (#N) Hard (%) Middle (#N) Middle (%) Easy (#N) Easy (%) 7 1. 219 45.2 259 53.4 47 5. 565 64.7 261 29.9 1 0. 179 37.0 304 62.8 2458 31. 3462 43.9 1972 25.0 3 0. 180 26.7 491 72.8 57 8. 343 52.3 256 39.0 Total 873 484 7892 674 656 0.7 496 29.6 1168 69.7 6 1.2 236 47.1 259 51. 217 7.9 1629 59.1 909 33. 501 2755 4 2.0 78 38. 123 60.0 205 27 7.8 52.7 137 39.5 4210 42.8 42.0 1495 15.2 1 0.7 31.5 97 67.8 347 9838 Table 4. Distribution of Difficulty Levels Across Disciplines. #N denotes the number of samples. Sentence Length. Question and answer length analysis reveals substantial variation across disciplines. The average question length is 58.42 tokens, with Literature questions showing the highest maximum length (869 tokens) and Engineering questions averaging 67.26 tokens. The answer options maintain length pattern similar to the general options across different disciplines, averaging 12.86 tokens per option. Such consistent 13 Figure 4. The Visualization of the Text Embeddings of Question-Answer Pairs Across Disciplines. length distribution across options aligns with one of the requirements of error option curation, which tries to confuse the models by providing confusing options in similar lengths. Semantic Visualization. As shown in Figure 4, we employ t-SNE visualization of question-answer pair embeddings to visualize the distribution SuperGPQA1 and to further show the comprehensiveness of it. The resulting visualization demonstrates clear clustering patterns across disciplines while maintaining substantial overlap in conceptual spaces. The Engineering and Science demonstrate the highest degree of embedding overlap, suggesting strong semantic similarities in their Q&A patterns. The humanities cluster (Literature, Philosophy, History) shows diffuse boundaries but maintains distinct centroids. The Military Science exhibits relatively isolated embedding patterns, indicating unique domain-specific language. This analysis shows aligning 1We use the gte-large-en-v1.5 [Li et al., 2023, Zhang et al., 2024b] encoding model and set the t-SNE parameters as: perplexity 100, learning rate 500, and 1000 iteration. For clearer visualization, we randomly select maximum 1000 samples from each disciplines. 14 Figure 5. The Correlation Coefficients between Different Benchmarks. For MMLU, we record the results under the 5-shot setting. conclusions from Figure 6 and reveals that the semantic structure of the SuperGPQA pairs reflects both the traditional organization of academic disciplines and their natural intellectual relationships, effectively capturing both domain-specific knowledge and cross-disciplinary connections. Figure 6. The Correlation Between Disciplines in SuperGPQA. 15 4. Experiments 4.1. Baseline Models We evaluate 6 reasoning models (o3-mini has three modes), 28 chat models and 17 base models on SuperGPQA, which includes closed-source models, open-source models, and fully open-source models. The reasoning models include Deepseek-R1 and DeepseekR1-Zero [Guo et al., 2025], o1 and o1-mini [OpenAI, 2024b], QwQ [Team, 2024b], and o3-mini [OpenAI, 2025] series models. The chat models include closed-source models such as Doubao-1.5-pro, Qwen-max, Claude-3.5 [Anthropic, 2024], Gemini [Team, 2024a], GPT-4o [OpenAI, 2024a], Yi-Lightning [Wake et al., 2024], and open-source models like MiniMax-Text-01 [Li et al., 2025], Qwen2.5 [Yang et al., 2024a] series, Llama-3.1 [Dubey et al., 2024] series, Mistral [Jiang et al., 2023] and Mixtral [Jiang et al., 2024] series, Gemma-2 [Team et al., 2024]series, Yi-1.5 [Young et al., 2024] series, Phi4 [Abdin et al., 2024], and Granite-3.1 [Granite Team, 2024]. Additionally, there are fully open-source models like MAP-Neo [Zhang et al., 2024a] and OLMo-2 [OLMo et al., 2024]. According to our test results, these models still show significant gap when compared to industry standards level. The base models include Qwen2.5 [Yang et al., 2024a] series, DeepseekV3 [Liu et al., 2024], Yi-1.5 [Young et al., 2024] series, Llama-3.1 [Dubey et al., 2024] series, Gemma-2 [Team et al., 2024] series, and Mistral [Jiang et al., 2023] and Mixtral [Jiang et al., 2024] series. Reasoning models and chat models are evaluated using zero-shot approach, while base models are assessed using five-shot evaluation. Specifically, the five-shot evaluation for base models follow similar methodology to MMLU-Pro. The specific prompts employed for both the zero-shot and five-shot evaluations are detailed in Appendix F. For all main results, the temperature is set to 0. The maximum number of new tokens is set to 32K for reasoning models, while for all other models, it is set to 4K. More model results can be found in Appendix J, and all detailed results are provided in Appendix L. 4.2. Main Results We present the performances of the baselines on different levels, difficulties  (Table 5)  and disciplines  (Table 6)  . Overall Results. In general, the top-performed reasoning models (e.g., DeepSeek-R1, o1-2024-12-17) achieve the best overall performance in SuperGPQA. The effectiveness of instruction tuning to improve the performances is once again verified in the benchmark. 16 Model Overall (sample) Overall (subfield) Overall (field) Overall (discipline) Easy (sample) Middle (sample) Hard (sample) Reasoning Models DeepSeek-R1 o1-2024-12-17 DeepSeek-R1-Zero o3-mini-2025-01-31-high o3-mini-2025-01-31-medium o3-mini-2025-01-31-low o1-mini-2024-09-12 QwQ Doubao-1.5-pro-32k-250115 Doubao-1.5-pro-32k-241225 Qwen-max-2025-01-25 Claude-3-5-sonnet-20241022 Gemini-2.0-flash DeepSeek-V3 MiniMax-Text-01 GPT-4o-2024-11-20 Llama-3.1-405B-Instruct GPT-4o-2024-08-06 Qwen2.5-72B-Instruct Mistral-Large-Instruct-2411 Qwen-max-2024-09-19 Qwen2.5-32B-Instruct Llama-3.3-70B-Instruct Phi-4 Qwen2.5-14B-Instruct Llama-3.1-70B-Instruct Yi-Lightning Mixtral-8x22B-Instruct-v0.1 Qwen2.5-7B-Instruct Gemma-2-27B-it Qwen2.5-3B-Instruct Granite-3.1-8B-instruct Qwen2.5-1.5B-Instruct OLMo-2-1124-13B-Instruct MAP-Neo-7B-Instruct-v0.1 OLMo-2-1124-7B-Instruct Qwen2.5-72B Qwen2.5-32B DeepSeek-V3-Base Qwen2.5-14B Yi-1.5-34B Llama-3.1-70B Qwen2.5-7B Llama-3.1-405B Gemma-2-27B Mixtral-8x22B-v0.1 Qwen2.5-3B Mistral-7B-v0.3 Qwen2.5-1.5B OLMo-2-1124-13B MAP-Neo-7B Granite-3.1-8B-Base OLMo-2-1124-7B 61.82 60.24 60.24 55.22 52.69 48.03 45.22 43.59 55.09 50.93 50.08 48.16 47.73 47.40 45.11 44.40 43.14 41.64 40.75 40.65 39.96 38.76 37.69 37.65 35.15 34.86 33.42 29.23 28.78 27.43 23.31 20.83 18.82 18.66 17.05 16.81 34.33 33.16 32.14 30.19 27.62 27.22 25.36 25.23 24.49 22.41 20.14 19.48 17.17 16.07 15.76 15.69 15.15 62.61 61.25 61.62 54.94 52.66 48.51 45.46 44.40 56.55 52.41 52.75 51.38 48.70 49.10 47.46 47.62 46.43 44.79 43.66 43.38 42.93 41.18 40.56 39.59 37.72 38.94 36.57 32.14 30.78 30.50 25.45 22.85 20.91 20.46 18.52 18. 38.08 36.52 34.79 33.33 30.78 30.52 28.19 28.09 27.35 24.71 22.81 21.50 19.31 18.75 17.48 16.98 17.62 61.23 59.94 60.95 52.11 49.95 45.89 42.53 43.19 Chat Models 55.62 51.76 52.47 51.23 47.80 48.31 46.97 47.50 45.83 44.91 43.32 43.13 42.16 40.40 40.15 38.61 37.41 39.18 36.45 32.28 30.37 30.42 25.86 22.92 20.75 20.60 18.42 18.57 Base Models 38.70 37.33 34.58 34.14 31.03 31.28 28.73 28.33 27.96 25.04 23.30 21.81 19.80 19.82 18.26 16.79 18. 59.95 59.44 60.99 48.32 46.07 42.63 39.33 41.63 54.39 51.24 51.65 53.15 46.10 47.35 47.06 48.84 47.35 46.29 42.10 43.37 41.62 39.43 41.12 37.66 36.07 40.57 36.92 32.82 30.63 31.30 25.57 22.26 22.11 21.80 18.70 18.85 39.54 38.29 34.71 34.54 32.55 32.55 29.60 30.15 28.58 25.02 24.42 22.27 21.35 21.37 19.54 16.65 19.60 63.59 64.40 65.06 53.05 51.30 48.80 46.77 46.46 57.70 53.54 58.16 59.04 53.06 55.63 54.51 56.84 56.06 55.22 48.84 52.92 50.23 47.42 49.68 45.43 44.82 48.22 43.38 42.52 37.77 40.90 33.10 29.48 27.41 27.10 23.26 22.80 46.20 45.12 41.28 42.27 39.68 40.78 36.58 37.58 36.26 32.78 30.42 27.62 24.52 27.24 22.86 20.40 24. 63.63 61.44 62.61 56.09 53.79 50.21 47.34 47.40 60.15 56.56 54.95 51.91 49.56 50.11 48.60 48.75 46.31 45.11 45.42 43.28 43.63 43.05 40.68 40.91 37.90 37.85 35.32 29.73 30.98 27.45 23.50 19.79 18.19 17.85 16.62 15.82 38.12 36.58 34.50 31.44 27.95 26.95 25.94 25.12 24.07 21.67 19.81 18.65 16.79 14.41 14.64 15.65 13.83 56.87 53.67 50.99 56.16 52.37 43.53 40.00 34.07 43.80 38.70 33.09 29.99 38.84 33.86 28.98 23.50 23.70 20.98 24.10 22.81 22.60 22.13 19.55 23.69 19.97 15.22 19.35 13.82 15.23 12.64 12.24 13.09 10.45 10.74 10.95 11.90 15.01 14.34 18.20 14.85 13.86 12.78 12.10 11.86 12.27 12.26 9.40 11.96 9.74 6.57 9.83 10.60 7. Table 5. Performance on SuperGPQA. LLMs are scored sample-wise, subfield-wise, field-wise, and discipline-wise levels to ensure fair assessment despite imbalanced question distributions. The highest, the second-best and the third-best scores are shown in ùëèùëúùë• , bold and underlined, respectively. 17 Model Agr. Econ. Edu. Eng. Hist. Law Lit & Arts Mgt. Med. Mil Sci. Phil. Sci. Soc. Reasoning Models 54.43 DeepSeek-R1 DeepSeek-R1-Zero 53.81 50.93 o1-2024-12-17 o3-mini-2025-01-31-high 41.03 o3-mini-2025-01-31-medium 40.62 37.32 o3-mini-2025-01-31-low 34.02 o1-mini-2024-09-12 38.14 QwQ Doubao-1.5-pro-32k-250115 Doubao-1.5-pro-32k-241225 claude-3-5-sonnet-20241022 qwen-max-2025-01-25 Llama-3.1-405B-Instruct gpt-4o-2024-11-20 gpt-4o-2024-05-13 DeepSeek-V3 Qwen2.5-72B-Instruct MiniMax-Text-01 gpt-4o-2024-08-06 Mistral-Large-Instruct-2411 gemini-2.0-flash Llama-3.1-70B-Instruct Llama-3.3-70B-Instruct qwen-max-2024-09-19 Qwen2.5-32B-Instruct Qwen2.5-14B-Instruct Yi-Lighting Phi-4 Gemma-2-27B-it Qwen2.5-7B-Instruct Mixtral-8x22B-Instruct-v0.1 Qwen2.5-3B-Instruct Granite-3.1-8B-instruct Qwen2.5-1.5B-Instruct OLMo-2-1124-13B-Instruct Yi-1.5-6B-Chat MAP-Neo-7B-Instruct-v0.1 Qwen2.5-0.5B-Instruct Qwen2.5-32B Qwen2.5-72B Qwen2.5-14B Llama-3.1-405B Llama-3.1-70B Gemma-2-27B DeepSeek-V3-Base Qwen2.5-7B Yi-1.5-34B Mixtral-8x7B-v0.1 Gemma-2-9B Mistral-7B-v0.3 Mixtral-8x22B-v0.1 Qwen2.5-3B MAP-Neo-7B OLMo-2-1124-13B Qwen2.5-1.5B Granite-3.1-8B-Base Qwen2.5-0.5B 50.93 47.42 47.01 44.33 43.09 42.27 41.44 41.24 41.24 39.79 39.59 38.76 38.56 37.11 36.70 36.49 36.49 36.08 33.81 32.78 31.13 29.28 28.25 25.36 24.74 22.27 20.82 20.41 17.94 16.91 38.76 36.29 34.02 29.28 28.87 28.87 28.66 28.25 28.25 28.04 27.22 25.98 23.92 22.47 20.21 19.59 19.18 15.46 15.05 66.09 66.44 61.17 54.07 51.32 45.25 45.02 47.77 65.06 60.14 56.59 57.50 49.71 46.74 40.78 49.48 46.62 49.60 40.78 42.27 45.93 41.12 40.55 45.02 43.07 37.69 39.18 40.21 29.32 34.59 33.45 26.35 20.16 22.57 22.68 23.83 17.64 16.49 40.89 44.33 34.82 27.95 29.67 27.26 35.17 31.96 35.85 24.97 26.23 20.96 23.94 23.83 18.10 20.27 20.73 17.87 12.37 54.75 60.54 53.31 46.28 41.74 38.43 36.16 45. 55.58 54.75 53.72 56.40 45.45 50.00 44.21 43.80 44.42 47.52 44.42 42.15 42.36 41.94 40.29 45.66 45.45 39.26 35.95 39.26 30.99 35.33 33.68 30.99 23.76 27.27 25.21 25.62 21.69 17.98 45.87 45.25 40.08 31.20 36.36 30.79 39.05 38.02 37.60 29.34 30.99 25.62 27.27 28.31 23.35 26.24 28.10 15.08 16.32 63.10 60.28 59.17 56.41 53.83 48.20 45.41 43.37 55.60 50.76 47.57 50.81 41.89 42.83 37.47 47.21 41.12 44.88 38.84 39.66 48.37 33.88 36.44 39.84 38.93 35.87 32.53 37.27 26.72 28.38 29.02 22.83 21.60 17.64 18.18 18.50 16.79 9.77 32.70 33.39 30.26 23.61 26.19 24.09 31.87 24.89 27.32 20.67 21.79 19.02 22.02 19.74 15.43 15.21 16.50 16.26 10.30 55.19 58.61 60.98 36.80 35.01 32.94 26.26 29. 65.24 66.77 63.87 45.73 43.60 39.79 35.98 45.88 Chat Models 42.88 37.54 53.56 44.81 50.00 52.52 50.74 47.18 30.71 45.25 50.89 44.96 45.25 33.09 41.25 35.16 30.71 26.41 36.05 30.27 24.78 22.85 30.86 18.55 16.32 16.47 16.91 13.95 13.50 10.09 58.84 54.12 60.21 54.12 55.34 53.81 52.90 51.07 45.88 54.27 54.12 47.87 49.24 45.88 44.66 44.05 41.92 37.04 37.35 41.46 35.06 32.62 34.60 25.61 24.70 26.37 22.10 25.61 21.19 13.87 Base Models 28.49 31.31 28.49 34.12 32.94 22.85 30.12 22.55 24.63 23.89 21.81 14.84 20.33 18.40 15.28 19.73 15.43 11.72 11. 39.94 44.21 36.89 34.30 33.38 28.96 37.20 30.34 34.45 30.79 26.83 24.24 27.59 26.37 21.34 22.41 21.95 18.29 12.96 52.45 56.86 55.79 39.44 37.11 36.22 32.22 32.82 42.30 38.31 50.42 44.93 43.20 46.72 45.11 45.23 34.90 43.02 46.30 41.11 43.68 35.08 38.54 39.08 32.76 31.44 36.34 31.62 29.42 24.28 30.55 22.32 20.53 17.84 19.57 18.79 16.35 12.89 30.91 35.50 28.94 30.79 32.64 27.51 33.65 25.06 30.25 27.27 23.81 20.11 24.64 21.60 18.79 20.88 17.72 13.84 14.92 57.09 59.68 57.29 51.50 48.50 43.71 40.52 41.32 53.29 52.69 51.30 54.69 47.70 47.31 41.32 48.50 42.32 48.90 45.51 43.31 41.32 46.11 45.51 45.11 39.52 41.52 38.12 39.12 34.93 33.33 35.13 30.94 25.15 24.95 21.96 24.15 20.96 15. 40.72 43.51 40.32 34.13 36.73 32.73 37.33 28.54 36.13 30.74 28.94 23.55 30.14 28.14 21.76 26.15 23.35 14.57 11.78 59.93 60.65 62.25 51.72 50.34 48.09 44.32 43.88 59.13 54.99 49.26 56.37 49.04 52.52 48.82 46.10 45.74 47.08 50.49 43.23 43.77 44.21 43.77 43.41 42.21 36.91 36.95 37.79 31.00 32.60 30.53 26.82 20.58 22.58 21.81 21.89 18.91 14.12 38.84 43.12 34.37 29.47 30.96 27.80 34.70 30.56 31.18 25.05 26.06 22.61 22.50 25.41 17.10 19.96 20.87 14.81 12.23 57.07 58.54 60.49 46.34 45.85 41.46 39.51 40.00 54.15 53.66 59.51 49.27 52.20 52.20 50.73 48.29 45.37 48.29 50.73 48.78 51.22 47.80 46.34 47.32 44.88 38.05 42.44 39.02 39.02 32.68 44.39 27.32 27.80 25.37 25.85 29.27 25.85 13. 47.80 46.34 40.00 39.51 40.98 37.56 37.07 31.71 40.49 37.56 32.68 30.24 28.78 30.73 24.88 25.85 24.88 20.49 16.59 63.11 63.69 61.38 51.01 48.13 44.09 39.48 43.52 61.96 57.06 52.45 56.20 48.41 52.74 45.24 43.23 43.52 45.53 47.84 42.07 45.53 42.94 42.94 43.23 39.19 38.04 37.75 40.63 35.45 34.58 32.85 27.09 21.33 27.67 27.38 25.36 21.61 12.68 43.52 42.94 37.75 31.70 36.89 31.70 38.62 36.60 35.45 30.84 27.09 25.94 24.50 29.39 22.19 26.51 25.65 20.17 15.56 63.69 59.93 61.76 61.72 58.79 53.24 51.09 46.33 55.54 51.57 45.02 47.51 39.80 40.67 35.41 48.30 39.33 43.81 38.41 39.24 50.20 30.04 34.96 38.24 38.24 34.20 30.85 38.87 24.81 27.54 26.95 21.64 19.70 16.85 16.39 17.60 15.99 8. 29.45 29.38 26.68 21.47 23.30 21.38 30.08 22.04 23.80 17.87 20.01 17.47 20.96 16.54 13.16 11.93 14.48 15.44 8.74 67.13 67.13 64.34 46.15 44.06 45.45 41.26 43.36 51.75 53.15 64.34 54.55 49.65 54.55 53.85 55.94 46.15 53.85 53.85 50.35 53.85 48.25 42.66 38.46 39.16 36.36 42.66 41.26 34.27 30.07 36.36 26.57 23.08 19.58 24.48 23.78 14.69 12.59 39.86 38.46 36.36 24.48 34.27 30.07 37.76 34.27 37.76 28.67 27.97 18.88 28.67 26.57 22.38 23.08 28.67 22.38 13.99 Table 6. Performance on SuperGPQA. We present LLMs performance on different disciplines. The highest, the second-best and the third-best scores are shown in ùëèùëúùë• , bold and underlined, respectively. For instance, the results (47.40, 40.75) of DeepSeek-V3 and Qwen2.5-72B-Instruct are significantly better than the results (32.14, 34.33) of DeepSeek-V3-Base and Qwen2.572B, respectively. More powerful LLMs achieve more balanced results on different difficulties. For example, the results of simple, middle and hard splits of DeepSeek-R1 are 63.59, 63.63 and 56.87. In contrast, the results of simple, middle and hard splits of Qwen2.5-14B-Instruct are 44.82, 37.90 and 19.97. Observations for Reasoning Models. Surprisingly, the performance gap between DeepSeek-R1 and DeepSeek-R1-Zero is relatively small. In Table 6, the DeepSeek-R1 only beats DeepSeek-R1-Zero in two disciplines (i.e., Science and Engineering). In the other disciplines, the DeepSeek-R1-Zero is slightly better than DeepSeek-R1, which leaves the optimal training paradigm of the reason models an open question. From the performances across different dimensions, compared to the o1-2024-12-17 model, the newer o1-mini and o3-mini models show decreasing scores except in science and engineering, suggesting potential data leakage. Moreover, for different versions of o3mini (o3-mini-2025-01-31-high, o3-mini-2025-01-31-medium, o3-mini-2025-01-31-low), we observe obvious performance gaps for different difficulties. Advantages from Pre-training Corpus. The newer versions of proprietary LLMs achieve significant improvements on SuperGPQA, considering the incremental growing of qwen-max series (2024-09-192025-01-25: 39.96 50.08) and GPT-4o series (2024-0513 2024-08-06 2024-11-20: 39.76 41.64 44.40). Such incremental performances following the chronological order suggest that the developers of proprietary models highly value the incorporation of long-tailed knowledge. Moreover, we conjecture that the LLMs from Chinese firms (e.g., Qwen and Doubao) generally show superior performances is partially because their data collection pipelines are more aligned to SuperGPQA, i.e., considerable ratio of the references are translated from Chinese textbooks. Progress of Open-source. The SuperGPQA also reveals pessimistic open-source progress from the research community. In the dimension of pre-training corpus curation, the fully open-sourced LLMs (e.g., MAP-Neo-7B and OLMo-2-1124-13B) perform similarly and lag behind to other non fully open ones in similar sizes (e.g., Qwen2.5-7B). It can also be observed that, compared to the proprietary models, most of the open-weight LLMs except for the DeepSeek-R1 series are not satisfactory in our benchmark, especially 19 (a) Impact of subfield information. (b) Model robustness analysis. Figure 7. (a) Accuracy comparison of Qwen2.5 models (0.5B72B) with and without subfield information in prompts. Larger models benefit more from additional context. (b) Robustness evaluation across 24 semantically equivalent prompts, indicating larger models exhibit higher stability with lower variance. the hard questions. Difficulty-Specific Capabilities. The difficulty stratification in SuperGPQA reveals distinct capability patterns between reasoning-focused and knowledge-oriented LLMs. As shown in Table 5, the hard split specifically challenges models reasoning capacities, while easy and middle splits better reflect factual knowledge mastery. For instance, the o3-mini series exhibits lower scores than Doubao-1.5-pro-32k-250115 on easy and middle splits, yet surpasses it significantly on hard questions. This dichotomy suggests that: Chat-oriented LLMs (e.g., Doubao series) excel at knowledge recall for common professional questions but struggle with complex reasoning in long-tail domains. Reasoning-specialized models demonstrate superior performance on hard questions through enhanced logical processing, despite potential compromises in broad knowledge coverage. This differentiation validates SuperGPQAs design rationale using difficulty levels as diagnostic tools to dissect complementary capabilities in modern LLMs. 4.3. Further Analysis Effect of Subfield Information in Prompts. To investigate the impact of subfield information on model performance, we conduct zero-shot evaluations under two conditions: (1) zero-shot-with-subfield, where the prompt includes description of the problems 20 subfield, and (2) zero-shot-without-subfield, where no such information is provided. The prompts of zero-shot-with-subfield are shown in subsection G.1. We evaluate Qwen2.5Instruct models ranging from 0.5B to 72B parameters across these two settings. Figure 7a show that incorporating subfield information generally leads to improved performance, particularly for larger models. For example, Qwen2.5-72B-Instruct achieves an accuracy of 41.93% in the zero-shot-with-subfield setting, compared to 40.82% without subfield annotations. Similarly, Qwen2.5-32B-Instruct improves from 39.13% to 39.65%, and Qwen2.5-14B-Instruct sees minor increase from 35.36% to 35.78%, suggesting that additional contextual information helps larger models refine their reasoning by narrowing down the relevant domain. However, for smaller models like Qwen2.5-0.5BInstruct and Qwen2.5-1.5B-Instruct, the introduction of subfield information does not lead to noticeable gain in accuracy. Qwen2.5-0.5B-Instruct performs slightly worse with subfield annotations (10.62% vs. 11.12%), while Qwen2.5-1.5B-Instruct shows nearidentical performance (18.09% vs. 18.62%), indicating that smaller models may lack the capacity to leverage fine-grained domain-specific cues effectively, relying more on general knowledge retrieval rather than contextual domain disambiguation. Robustness Analysis. Benchmark evaluations can be significantly influenced by slight variations in prompts, leading to inconsistencies in model ranking and overall assessment reliability. To investigate this phenomenon, we conduct robustness experimentacross Qwen2.5-Instruct models (0.5B72B), employing 24 distinct yet semantically equivalent prompts in zero-shot setting, using the same evaluation parameters as in the main results. Specifically, we employ 4 types of initial prompts and 6 types of question formats, resulting in combination of 24 different prompt styles to verify the robustness of our bench. The combination of initial prompt 1 and question format 1 is the default prompt for our evaluation. The detailed prompts are shown in the subsection G.2. Figure 7b shows that larger models exhibit increased robustness, as steady improvement in accuracy from 9.80% of Qwen2.5-0.5B-Instruct to 41.15% of Qwen2.5-72B-Instruct while variance decreases (ùúé = 1.37 for the smallest model, dropping to ùúé 0.27 0.36 in the largest models). This demonstrates the our evaluation framework is more stable with maximum standard deviation SD of 1.37%, that mitigates prompt-induced instability and provides more reliable basis for model assessment. (a) Best of (BoN) performance (b) Majority Voting performance comparison comparison Figure 8. Performance comparison of Qwen2.5-72B-Instruct and Doubao-1.5-pro-32k-20250115 under two ensembling strategies: (a) Best of (BoN) and (b) Majority Voting. BoN shows that Qwen2.5-72B-Instruct benefits more from increased sampling, whereas Majority Voting favors Doubao-1.5-pro-32k-20250115 due to its more consistent output distribution. Best of (BoN) Analysis. BoN (Best of N) is strategy that selects the highestquality response from independent generations which utilize stochastic sampling to improve overall performance. In our experiments, we evaluate Qwen2.5-72B-Instruct and Doubao-1.5-pro-32k-20250115 under BoN settings ranging from ùëÅ = 1 to ùëÅ = 32, with results presented in Figure 8a. Qwen2.5-72B-Instruct exhibits steeper BoN curve compared to Doubao-1.5-pro-32k-20250115, suggesting that Qwen benefits more significantly from multiple sampling attempts, likely due to higher variance in response quality. Conversely, Doubao-1.5-pro-32k-20250115 shows stronger initial performance but more gradual BoN gain, implying that its response distribution is more consistent but less opportunistic in leveraging multiple trials. Notably, while Doubao maintains lead in early BoN values (ùëÅ 15), Qwen2.5-72B-Instruct surpasses it around Bo24 and continues to outperform at Bo32, indicating that for scenarios where extensive sampling is feasible, Qwen2.5-72B-Instruct demonstrates greater ability to exploit high-quality outputs. Majority Voting Analysis. 2 Majority Voting is strategy that selects the most frequently generated response from multiple independent runs. We evaluate Majority Voting using Qwen2.5-72B-Instruct and Doubao-1.5-pro-32k-20250115 shown in Figure 8b. When multiple options receive the same highest number of votes, the answer is 2Both the BoN and Majority Voting analyses are conducted using the same set of inference results, generated with temperature = 0.7 and repeated for 32 independent runs. 22 considered correct if the correct option is among them. We show that Doubao-1.5-pro32k-20250115 consistently outperforms Qwen2.5-72B-Instruct across all voting sizes, exhibiting stable performance around 55-57%. In contrast, Qwen2.5-72B-Instruct demonstrates fluctuations, particularly for lower N, with performance largely remaining in the 40-45% range, indicating that Doubao generates more consistent responses across independent runs. 4.4. Analysis of Disciplinary Discrimination Power To systematically evaluate the discrimination power across disciplines, we employ two complementary analytical approaches: descriptive statistics and discrimination indices analysis. The descriptive statistics approach examines the distribution characteristics of model performance within each discipline through three key metrics: Mean Accuracy: Reflects the overall difficulty level of the discipline. Standard Deviation (SD): Measures the dispersion of model performance. Coefficient of Variation (CV): Normalizes the standard deviation by mean accuracy, enabling cross-discipline comparison. The discrimination indices analysis complements this by comparing performance extremes through: High-Low Group Difference (Œî): Calculates the mean accuracy gap between the top 3 and bottom 3 models in each discipline. Table 7 presents complete results with group comparisons across all 13 disciplines, highlighting key patterns through color coding. Our systematic analysis reveals two distinct patterns in disciplinary discrimination power: High-discrimination disciplines: History (SD=8.45, CV=0.175, Œî=19.19) and Law (SD=7.17, CV=0.126, Œî=16.62) demonstrate the strongest differentiation capacity, indicating models exhibit substantially varied performance in these domains. Low-discrimination disciplines: Military Science (SD=4.99, CV=0.093, Œî=11.55), Engineering (SD=5.75, CV=0.107, Œî=13.13), and Management (SD=5.21, CV=0.099, Œî=10.98) exhibit performance convergence among top models. 23 Discipline Descriptive Statistics Discrimination Indices Analysis Mean Acc. SD CV High Low Engineering Philosophy Medicine Economics Science Law History Education Military Science Management Literature & Arts Agronomy Sociology 53.93 55.56 54. 58.25 54.52 56.92 48.28 52.15 53. 52.73 46.94 46.97 57.83 5.75 7. 6.44 6.96 6.86 7.17 8.45 5. 4.99 5.21 6.58 5.58 7.33 0. 60.85 47.72 0.132 62.92 46.59 0. 60.94 46.38 0.120 65.86 49.83 0. 62.39 46.94 0.126 65.29 48.68 0. 58.26 39.07 0.114 57.51 44.15 0. 59.51 47.97 0.099 58.02 47.04 0. 55.03 40.02 0.119 53.06 40.27 0. 66.20 50.35 Œî 13.13 16.33 14. 16.04 15.45 16.62 19.19 13.36 11. 10.98 15.02 12.78 15.85 Table 7. Comprehensive Discrimination Analysis with Several Key Evaluation Metrics (Mean Acc.: Mean Accuracy, SD: Standard Deviation, CV: Coefficient of Variation, Œî: High-Low Group Difference). The observed dichotomy between humanities and STEM disciplines emerges from fundamental differences in knowledge representation. The heightened discrimination in humanities (History CV=0.175) likely originates from: Context-dependent reasoning requiring real-world knowledge synthesis. Cultural nuance interpretation demands. Ethical judgment variance in open-ended scenarios. Conversely, the performance convergence in STEM fields (Engineering CV=0.107) reflects: Standardized problem-solving patterns in technical domains. Mathematical consistency in training corpora. Concentrated optimization efforts by model developers. This finding validates our experimental design hypothesis: when evaluating topperforming models (per-discipline top 10 selection), humanities disciplines better reveal capability differences due to their complexity beyond pattern recognition, while STEM 24 metrics approach performance ceilings. Our results emphasize the critical need for comprehensive cross-domain evaluation frameworks to fully capture models heterogeneous capabilities beyond technical domains. 5. Related Work 5.1. Large Language Models The landscape of natural language processing has been transformed by recent breakthroughs in Large Language Models (LLMs) [Zhang et al., 2024a, Young et al., 2024]. The introduction of GPT-3 marked significant milestone, showcasing its ability to interpret tasks and examples from textual inputs with minimal prior training. Recently, the latest generation of LLMs (e.g., GPT-4 [OpenAI, 2023], Claude-3.5 3, Gemini [Team, 2023], and Llama-3 [AI@Meta, 2024]), have exhibited remarkable progress in sophisticated reasoning across diverse fields. To comprehensively evaluate and challenge the expanding capabilities of these advanced AI systems, we present SuperGPQA. This novel benchmark is specifically crafted to probe the knowledge boundaries of existing LLMs. 5.2. LLM Benchmarks Recently, the development of the Large Language Model (LLM) has been transformed by the introduction of various benchmarks [Cobbe et al., 2021, Wang et al., 2024a, Bai et al., 2024]. Notable examples include GLUE [Wang et al., 2019b] and its successor SuperGLUE [Wang et al., 2019a], which have been instrumental in propelling advancements in language comprehension tasks. These foundational benchmarks paved the way for more specialized assessments, such as MMLU [Hendrycks et al., 2020], HotpotQA [Yang et al., 2018], BigBench [Srivastava et al., 2022], HellaSwag [Zellers et al., 2019], CommonsenseQA [Talmor et al., 2019], KOR-Bench [Ma et al., 2024], SimpleQA [Wei et al., 2024a] and Chinese SimpleQA [He et al., 2024a]. These newer benchmarks have expanded the evaluation scope to encompass content generation, knowledge understanding, and complex reasoning abilities. While numerous benchmarks have been developed to evaluate LLMs capabilities and alignment with human values, these have often focused narrowly on performance within singular tasks or domains. To enable more comprehensive LLM assessment, we propose SuperGPQA to scale the LLM evaluation to 285 graduate-level disciplines and provide comprehensive and fine-grained analysis of foundation models. 3https://www.anthropic.com/news/claude-3-5-sonnet 25 6. Contributions and Acknowledgements Multimodal Art Projection (M-A-P) is non-profit open-source AI research community, ran by donation. The community members are working on research topics in wide range of spectrum, including but not limited to the pre-training paradigm of foundation models, large-scale data collection and processing, and the derived applications on coding, reasoning and music generation. Our team members contribute to the development of SuperGPQA from the following perspectives: Data Annotation Management Model Evaluation Data Annotation Data Quality Inspection Result Analysis Paper Writing"
        },
        {
            "title": "Leading Authors",
            "content": "Xinrun Du, M-A-P Yifan Yao, M-A-P Kaijing Ma, M-A-P Bingli Wang, SAU"
        },
        {
            "title": "Outstanding Contributors",
            "content": "Tianyu Zheng, M-A-P, Tiktok Kang Zhu, M-A-P, OPPO Minghao Liu, 2077.AI Yiming Liang, M-A-P, CASIA Zhenlin Wei, CASIA Xiaolong Jin, Purdue University Chujie Zheng, Tsinghua University Core Contributors (Alphabet Order) Kaixing Deng, CDUT Shuyue Guo, M-A-P ester Yunwen Li, CUHK-Shenzhen Shian Jia, Zhejiang University Dehua Ma, M-A-P Sichao Jiang, Zhejiang University Yuansheng Ni, M-A-P Yiyan Liao, Peking University Haoran Que, Zhipu Rui Li, Peking University Qiyao Wang, DUT Qinrui Li, UCSB Zhoufutu Wen, ByteDance.Inc Sirun Li, Peking University Siwei Wu, The University of ManchYizhi Li, The University of Manchester 26 Tianshun Xing, M-A-P Zekun Moore Wang, M-A-P, Beihang Ming Xu, NJUPT University Zhenzhu Yang, M-A-P, CUGB Junting Zhou, Peking University Contributors (Alphabet Order) Yuelin Bai, M-A-P Qige Qi, ByteDance.Inc Xingyuan Bu, Alibaba.Inc Shi Qiu, Peking University Chenglin Cai, 01.AI Xingwei Qu, The University of Liang Chen, Peking University Manchester Yifan Chen, ByteDance.Inc Yizhou Tan, Harvard University Chengtuo Cheng, Abaka.AI Zili Wang Tianhao Cheng, Fudan University Chenqing Wang, 2077.AI Keyi Ding, Hangzhou Dianzi UniverHao Wang, Beihang University sity Yiya Wang, Peking University Siming Huang, The University of Yubo Wang, University of Waterloo Melbourne Yun Huang, NUS Jiajun Xu, Meta Kexin Yang Yaoru Li, Zhejiang University Ruibin Yuan, HKUST Yizhe Li, Zhejiang University Yuanhao Yue, Fudan University Zhaoqun Li, Zhejiang University Tianyang Zhan, ByteDance.Inc Tianhao Liang, Zhejiang University Chun Zhang, ByteDance.Inc Chengdong Lin, Hangzhou Dianzi Jingyang Zhang, Zhejiang University University Xiyue Zhang, Peking University Hongquan Lin, University of Science Xingjian Zhang, Princeton University and Technology of China Yue Zhang, ByteDance.Inc Yinghao Ma, Queen Mary University Yongchi Zhao, Alibaba.Inc of London Xiangyu Zheng, Fudan University Zhongyuan Peng, Alibaba.Inc Chenghua Zhong, USTB Zifan Peng, HKUST-Guangzhou Organization and Sponsor Committee (Alphabet Order) Yang Gao, Nanjing University Qian Liu, Tiktok Zhoujun Li, Beihang University Tianyu Liu Dayiheng Liu Shiwen Ni, SIAT-CAS 27 Junran Peng, USTB Min Yang, SIAT-CAS Yujia Qin, ByteDance.Inc Meng Cao, MBZUAI Wenbo Su Xiang Yue, M-A-P Guoyin Wang, ByteDance.Inc Zhaoxiang Zhang, CASIA Shi Wang, ICT-CAS Wangchunshu Zhou, OPPO Jian Yang, Beihang University Corresponding Authors Jiaheng Liu, M-A-P, Nanjing UniverWenhao Huang, M-A-P, ByteDance.Inc sity Ge Zhang, M-A-P, ByteDance.Inc Qunshu Lin, Abaka.AI"
        },
        {
            "title": "References",
            "content": "M. Abdin, J. Aneja, H. S. Behl, S. Bubeck, R. Eldan, S. Gunasekar, M. Harrison, R. J. Hewett, M. Javaheripi, P. Kauffmann, J. R. Lee, Y. T. Lee, Y. Li, W. Liu, C. C. T. Mendes, A. Nguyen, E. Price, G. de Rosa, O. Saarikivi, A. Salim, S. Shah, X. Wang, R. Ward, Y. Wu, D. Yu, C. Zhang, and Y. Zhang. Phi-4 technical report. ArXiv, abs/2412.08905, 2024. URL https://api.semanticscholar.org/CorpusID:274656307. AI-MO. Aimo validation aime, 2024. URL https://huggingface.co/datasets/AI -MO/aimo-validation-aime. Validation set containing 90 AIME problems from 2022-2024 contests. AI@Meta. Llama 3 model card. 2024. URL https://github.com/meta-llama/lla ma3/blob/main/MODEL_CARD.md. Anthropic. Claude 3.5 sonnet model card addendum, 2024. URL https://www.pa perswithcode.com/paper/claude-3-5-sonnet-model-card-addendum. Accessed: 2024-09-21. G. Bai, J. Liu, X. Bu, Y. He, J. Liu, Z. Zhou, Z. Lin, W. Su, T. Ge, B. Zheng, et al. Mt-bench101: fine-grained benchmark for evaluating large language models in multi-turn dialogues. arXiv preprint arXiv:2402.14762, 2024. K. Chernyshev, V. Polshkov, E. Artemova, A. Myasnikov, V. Stepanov, A. Miasnikov, and S. Tilga. U-math: university-level benchmark for evaluating mathematical skills in llms. arXiv preprint arXiv:2412.03205, 2024. doi: 10.48550/arXiv.2412.03205. URL https://arxiv.org/abs/2412.03205. Version v3: 14 Jan 2025. K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman. Training verifiers to solve math word problems, 2021. A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. Z. Fei, X. Shen, D. Zhu, F. Zhou, Z. Han, S. Zhang, K. Chen, Z. Shen, and J. Ge. Lawbench: Benchmarking legal knowledge of large language models. arXiv preprint arXiv:2309.16289, 2023. K. Fronsdal, A. Gulati, B. Miranda, E. Chen, E. Xia, B. de Moraes Dumont, and S. Koyejo. Putnam-axiom: functional and static benchmark for measuring higher level mathematical reasoning. NeurIPS 2024 Workshop on MATH-AI, October 2024. URL https://openreview.net/pdf?id=YXnwlZe0yf. Published: 09 Oct 2024, Last Modified: 09 Oct 2024. B. Gao, F. Song, Z. Yang, Z. Cai, Y. Miao, Q. Dong, L. Li, C. Ma, L. Chen, R. Xu, Z. Tang, B. Wang, D. Zan, S. Quan, G. Zhang, L. Sha, Y. Zhang, X. Ren, T. Liu, and B. Chang. Omni-math: universal olympiad level mathematic benchmark for large language models, 2024. URL https://arxiv.org/abs/2410.07985. A. P. Gema, J. O. J. Leang, G. Hong, A. Devoto, A. C. M. Mancino, R. Saxena, X. He, Y. Zhao, X. Du, M. R. G. Madani, et al. Are we done with mmlu? arXiv preprint arXiv:2406.04127, 2024. I. Granite Team. Granite 3.0 language models, 2024. D. Guo, D. Yang, H. Zhang, J. Song, R. Zhang, R. Xu, Q. Zhu, S. Ma, P. Wang, X. Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. Y. He, S. Li, J. Liu, Y. Tan, W. Wang, H. Huang, X. Bu, H. Guo, C. Hu, B. Zheng, Z. Lin, X. Liu, D. Sun, S. Lin, Z. Zheng, X. Zhu, W. Su, and B. Zheng. Chinese simpleqa: chinese factuality evaluation for large language models, 2024a. URL https://arxiv.org/abs/2411.07140. Y. He, S. Li, J. Liu, Y. Tan, W. Wang, H. Huang, X. Bu, H. Guo, C. Hu, B. Zheng, Z. Lin, X. Liu, D. Sun, S. Lin, Z. Zheng, X. Zhu, W. Su, and B. Zheng. Chinese simpleqa: chinese factuality evaluation for large language models, 2024b. URL https://arxiv.org/abs/2411.07140. D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020. A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023. 30 A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas, E. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024. D. Jin, E. Pan, N. Oufattole, W.-H. Weng, H. Fang, and P. Szolovits. What disease does this patient have? large-scale open domain question answering dataset from medical exams. arXiv preprint arXiv:2009.13081, 2020. Y. Jin, Z. Li, C. Zhang, T. Cao, Y. Gao, P. Jayarao, M. Li, X. Liu, R. Sarkhel, X. Tang, et al. Shopping mmlu: massive multi-task online shopping benchmark for large language models. arXiv preprint arXiv:2410.20745, 2024. A. Li, B. Gong, B. Yang, B. Shan, C. Liu, C. Zhu, C. Zhang, C. Guo, D. Chen, D. Li, et al. Minimax-01: Scaling foundation models with lightning attention. arXiv preprint arXiv:2501.08313, 2025. Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang. Towards general text embeddings with multi-stage contrastive learning. arXiv preprint arXiv:2308.03281, 2023. A. Liu, B. Feng, B. Xue, B. Wang, B. Wu, C. Lu, C. Zhao, C. Deng, C. Zhang, C. Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024. Z. Liu, B. Tan, H. Wang, W. Neiswanger, T. Tao, H. Li, F. Koto, Y. Wang, S. Sun, O. Pangarkar, R. Fan, Y. Gu, V. Miller, L. Ma, L. Tang, N. Ranjan, Y. Zhuang, G. He, R. Wang, M. Deng, R. Algayres, Y. Li, Z. Shen, P. Nakov, and E. Xing. Llm360 k2: Building 65b 360-open-source large language model from scratch, 2025. URL https://arxiv.org/abs/2501.07124. K. Ma, X. Du, Y. Wang, H. Zhang, Z. Wen, X. Qu, J. Yang, J. Liu, M. Liu, X. Yue, W. Huang, and G. Zhang. Kor-bench: Benchmarking language models on knowledge-orthogonal reasoning tasks, 2024. URL https://arxiv.org/abs/2410.06526. A. of Problem Solving. Aime problems and solutions, 2024. URL https://artofpro blemsolving.com/wiki/index.php/AIME_Problems_and_Solutions. Online resource for AIME competition problems. T. OLMo, P. Walsh, L. Soldaini, D. Groeneveld, K. Lo, S. Arora, A. Bhagia, Y. Gu, S. Huang, M. Jordan, et al. 2 olmo 2 furious. arXiv preprint arXiv:2501.00656, 2024. OpenAI. Gpt-4 technical report. PREPRINT, 2023. 31 OpenAI. Gpt-4o system card. Technical report, OpenAI, 2024a. https://www.openai .com/research/gpt-4o. OpenAI. o1 system card. Technical report, OpenAI, 2024b. https://openai.com/o1/. OpenAI. o3-mini system card. Technical report, OpenAI, 2025. https://openai.com /index/openai-o3-mini/. A. Pal, L. K. Umapathi, and M. Sankarasubbu. Medmcqa: large-scale multi-subject multi-choice dataset for medical domain question answering. In G. Flores, G. H. Chen, T. Pollard, J. C. Ho, and T. Naumann, editors, Proceedings of the Conference on Health, Inference, and Learning, volume 174 of Proceedings of Machine Learning Research, pages 248260. PMLR, 0708 Apr 2022. URL https://proceedings.mlr.press/v /pal22a.html. L. Phan, A. Gatti, Z. Han, N. Li, J. Hu, H. Zhang, S. Shi, M. Choi, A. Agrawal, A. Chopra, A. Khoja, R. Kim, J. Hausenloy, O. Zhang, M. Mazeika, D. Anderson, T. Nguyen, M. Mahmood, F. Feng, S. Y. Feng, H. Zhao, M. Yu, V. Gangal, C. Zou, Z. Wang, J. P. Wang, P. Kumar, O. Pokutnyi, R. Gerbicz, S. Popov, J.-C. Levin, M. Kazakov, J. Schmitt, G. Galgon, A. Sanchez, Y. Lee, W. Yeadon, S. Sauers, M. Roth, C. Agu, S. Riis, F. Giska, S. Utpala, Z. Giboney, G. M. Goshu, J. o. A. Xavier, S.-J. Crowson, M. M. Naiya, N. Burns, L. Finke, Z. Cheng, H. Park, F. Fournier-Facio, J. Wydallis, M. Nandor, A. Singh, T. Gehrunger, J. Cai, B. McCarty, D. Duclosel, J. Nam, J. Zampese, R. G. Hoerr, A. Bacho, G. A. Loume, A. Galal, H. Cao, A. C. Garretson, D. Sileo, Q. Ren, D. Cojoc, P. Arkhipov, U. Qazi, L. Li, S. Motwani, C. S. d. Witt, E. Taylor, J. Veith, E. Singer, T. D. Hartman, P. Rissone, J. Jin, J. W. L. Shi, C. G. Willcocks, J. Robinson, A. Mikov, A. Prabhu, L. Tang, X. Alapont, J. L. Uro, K. Zhou, E. d. O. Santos, A. P. Maksimov, E. Vendrow, K. Zenitani, J. Guillod, Y. Li, J. Vendrow, V. Kuchkin, N. Ze-An, P. Marion, D. Efremov, J. Lynch, K. Liang, A. Gritsevskiy, D. Martinez, B. Pageler, N. Crispino, D. Zvonkine, N. W. Fraga, S. Soori, O. Press, H. Tang, J. Salazar, S. R. Green, L. Br√ºssel, M. Twayana, A. Dieuleveut, T. R. Rogers, W. Zhang, B. Li, J. Yang, A. Rao, G. Loiseau, M. Kalinin, M. Lukas, C. Manolescu, S. Mishra, A. G. K. Kamdoum, T. Kreiman, T. Hogg, A. Jin, C. Bosio, G. Sun, B. P. Coppola, T. Tarver, H. Heidinger, R. Sayous, S. Ivanov, J. M. Cavanagh, J. Shen, J. M. Imperial, P. Schwaller, S. Senthilkuma, A. M. Bran, A. Dehghan, A. Algaba, B. Verbeken, D. Noever, R. P. V, L. Schut, I. Sucholutsky, E. Zheltonozhskii, D. Lim, R. Stanley, S. Sivarajan, T. Yang, J. Maar, J. Wykowski, M. Oller, J. Sandlin, A. Sahu, Y. Hu, S. Fish, N. Heydari, A. Apronti, K. Rawal, T. G. Vilchis, Y. Zu, M. Lackner, J. Koppel, 32 J. Nguyen, D. S. Antonenko, S. Chern, B. Zhao, P. Arsene, A. Goldfarb, S. Ivanov, R. Poswiata, C. Wang, D. Li, D. Crisostomi, A. Achilleos, B. Myklebust, A. Sen, D. Perrella, N. Kaparov, M. H. Inlow, A. Zang, E. Thornley, D. Orel, V. Poritski, S. Ben-David, Z. Berger, P. Whitfill, M. Foster, D. Munro, L. Ho, D. B. Hava, A. Kuchkin, R. Lauff, D. Holmes, F. Sommerhage, K. Schneider, Z. Kazibwe, N. Stambaugh, M. Singh, I. Magoulas, D. Clarke, D. H. Kim, F. M. Dias, V. Elser, K. P. Agarwal, V. E. G. Vilchis, I. Klose, C. Demian, U. Anantheswaran, A. Zweiger, G. Albani, J. Li, N. Daans, M. Radionov, V. Rozho Àán, Z. Ma, C. Stump, M. Berkani, J. Platnick, V. Nevirkovets, L. Basler, M. Piccardo, F. Jeanplong, N. Cohen, J. Tkadlec, P. Rosu, P. Padlewski, S. Barzowski, K. Montgomery, A. Menezes, A. Patel, Z. Wang, J. Tucker-Foltz, J. Stade, T. Goertzen, F. Kazemi, J. Milbauer, J. A. Ambay, A. Shukla, Y. C. L. Labrador, A. Givr√©, H. Wolff, V. Rossbach, M. F. Aziz, Y. Kaddar, Y. Chen, R. Zhang, J. Pan, A. Terpin, N. Muennighoff, H. Schoelkopf, E. Zheng, A. Carmi, A. Jones, J. Shah, E. D. L. Brown, K. Zhu, M. Bartolo, R. Wheeler, A. Ho, S. Barkan, J. Wang, M. Stehberger, E. Kretov, K. Sridhar, Z. EL-Wasif, A. Zhang, D. Pyda, J. Tam, D. M. Cunningham, V. Goryachev, D. Patramanis, M. Krause, A. Redenti, D. Bugas, D. Aldous, J. Lai, S. Coleman, M. Bahaloo, J. Xu, S. Lee, S. Zhao, N. Tang, M. K. Cohen, M. Carroll, O. Paradise, J. H. Kirchner, S. Steinerberger, M. Ovchynnikov, J. O. Matos, A. Shenoy, B. A. d. O. Junior, M. Wang, Y. Nie, P. Giordano, P. Petersen, A. Sztyber-Betley, P. Shukla, J. Crozier, A. Pinto, S. Verma, P. Joshi, Z.-X. Yong, A. Tee, J. Andr√©oletti, O. Weller, R. Singhal, G. Zhang, A. Ivanov, S. Khoury, H. Mostaghimi, K. Thaman, Q. Chen, T. Q. Kh√°nh, J. Loader, S. Cavalleri, H. Szlyk, Z. Brown, J. Roberts, W. Alley, K. Sun, R. Stendall, M. Lamparth, A. Reuel, T. Wang, H. Xu, S. G. Raparthi, P. Hern√°ndez-C√°mara, F. Martin, D. Malishev, T. Preu, T. Korbak, M. Abramovitch, D. Williamson, Z. Chen, B. B√°lint, M. S. Bari, P. Kassani, Z. Wang, B. Ansarinejad, L. P. Goswami, Y. Sun, H. Elgnainy, D. Tordera, G. Balabanian, E. Anderson, L. Kvistad, A. J. Moyano, R. Maheshwari, A. Sakor, M. Eron, I. C. McAlister, J. Gimenez, I. Enyekwe, A. F. D.O., S. Shah, X. Zhou, F. Kamalov, R. Clark, S. Abdoli, T. Santens, K. Meer, H. K. Wang, K. Ramakrishnan, E. Chen, A. Tomasiello, G. B. D. Luca, S.-Z. Looi, V.-K. Le, N. Kolt, N. M√ºndler, A. Semler, E. Rodman, J. Drori, C. J. Fossum, M. Jagota, R. Pradeep, H. Fan, T. Shah, J. Eicher, M. Chen, K. Thaman, W. Merrill, C. Harris, J. Gross, I. Gusev, A. Sharma, S. Agnihotri, P. Zhelnov, S. Usawasutsakorn, M. Mofayezi, S. Bogdanov, A. Piperski, M. Carauleanu, D. K. Zhang, D. Ler, R. Leventov, I. Soroko, T. Jansen, P. Lauer, J. Duersch, V. Taamazyan, W. Morak, W. Ma, W. Held, T. D. Huy, R. Xian, A. R. Zebaze, M. Mohamed, J. N. Leser, M. X. Yuan, L. Yacar, J. Lengler, H. Shahrtash, E. Oliveira, J. W. Jackson, D. E. Gonzalez, A. Zou, 33 M. Chidambaram, T. Manik, H. Haffenden, D. Stander, A. Dasouqi, A. Shen, E. Duc, B. Golshani, D. Stap, M. Uzhou, A. B. Zhidkovskaya, L. Lewark, M. Vincze, D. Wehr, C. Tang, Z. Hossain, S. Phillips, J. Muzhen, F. Ekstr√∂m, A. Hammon, O. Patel, N. Remy, F. Farhidi, G. Medley, F. Mohammadzadeh, M. Pe√±aflor, H. Kassahun, A. Friedrich, C. Sparrow, T. Sakal, O. Dhamane, A. K. Mirabadi, E. Hallman, M. Battaglia, M. Maghsoudimehrabani, H. Hoang, A. Amit, D. Hulbert, R. Pereira, S. Weber, S. Mensah, N. Andre, A. Peristyy, C. Harjadi, H. Gupta, S. Malina, S. Albanie, W. Cai, M. Mehkary, F. Reidegeld, A.-K. Dick, C. Friday, J. Sidhu, W. Kim, M. Costa, H. Gurdogan, B. Weber, H. Kumar, T. Jiang, A. Agarwal, C. Ceconello, W. S. Vaz, C. Zhuang, H. Park, A. R. Tawfeek, D. Aggarwal, M. Kirchhof, L. Dai, E. Kim, J. Ferret, Y. Wang, M. Yan, K. Burdzy, L. Zhang, A. Franca, D. T. Pham, K. Y. Loh, J. Robinson, S. Gul, G. Chhablani, Z. Du, A. Cosma, C. White, R. Riblet, P. Saxena, J. Votava, V. Vinnikov, E. Delaney, S. Halasyamani, S. M. Shahid, J.-C. Mourrat, L. Vetoshkin, R. Bacho, V. Ginis, A. Maksapetyan, F. d. l. Rosa, X. Li, G. Malod, L. Lang, J. Laurendeau, F. Adesanya, J. Portier, L. Hollom, V. Souza, Y. A. Zhou, Y. Yalƒ±n, G. D. Obikoya, L. Arnaboldi, R. M. Pokorny), F. Bigi, K. Bacho, P. Clavier, G. Recchia, M. Popescu, N. Shulga, N. M. Tanwie, T. C. Lux, B. Rank, C. Ni, A. Yakimchyk, H. Q. Liu, O. H√§ggstr√∂m, E. Verkama, H. Narayan, H. Gundlach, L. Brito-Santana, B. Amaro, V. Vajipey, R. Grover, Y. Fan, G. P. R. e. Silva, L. Xin, Y. Kratish, J. ≈Åucki, W.-D. Li, J. Xu, K. J. Scaria, F. Vargus, F. Habibi, L. T. Lian, E. Rodol√†, J. Robins, V. Cheng, D. Grabb, I. Bosio, T. Fruhauff, I. Akov, E. J. Y. Lo, H. Qi, X. Jiang, B. Segev, J. Fan, S. Martinson, E. Y. Wang, K. Hausknecht, M. P. Brenner, M. Mao, Y. Jiang, X. Zhang, D. Avagian, E. J. Scipio, M. R. Siddiqi, A. Ragoler, J. Tan, D. Patil, R. Plecnik, A. Kirtland, R. G. Montecillo, S. Durand, O. F. Bodur, Z. Adoul, M. Zekry, G. Douville, A. Karakoc, T. C. B. Santos, S. Shamseldeen, L. Karim, A. Liakhovitskaia, N. Resman, N. Farina, J. C. Gonzalez, G. Maayan, S. Hoback, R. D. O. Pena, G. Sherman, H. Mariji, R. Pouriamanesh, W. Wu, G. Demir, S. Mendoza, I. Alarab, J. Cole, D. Ferreira, B. Johnson, H. Milliron, M. Safdari, L. Dai, S. Arthornthurasuk, A. Pronin, J. Fan, A. Ramirez-Trinidad, A. Cartwright, D. Pottmaier, O. Taheri, D. Outevsky, S. Stepanic, S. Perry, L. Askew, R. A. H. Rodr√≠guez, A. Dendane, S. Ali, R. Lorena, K. Iyer, S. M. Salauddin, M. Islam, J. Gonzalez, J. Ducey, R. Campbell, M. Somrak, V. Mavroudis, E. Vergo, J. Qin, B. Borb√°s, E. Chu, J. Lindsey, A. Radhakrishnan, A. Jallon, I. McInnis, A. Hoover, S. M√∂ller, S. Bian, J. Lai, T. Patwardhan, S. Yue, A. Wang, and D. Hendrycks. Humanitys last exam. arXiv, 2025. D. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, and S. R. Bowman. Gpqa: graduate-level google-proof q&a benchmark. arXiv preprint 34 arXiv:2311.12022, 2023. A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso, A. Kluska, A. Lewkowycz, A. Agarwal, A. Power, A. Ray, A. Warstadt, A. W. Kocurek, A. Safaya, A. Tazarv, A. Xiang, A. Parrish, A. Nie, A. Hussain, A. Askell, A. Dsouza, A. Rahane, A. S. Iyer, A. Andreassen, A. Santilli, A. Stuhlm√ºller, A. M. Dai, A. La, A. K. Lampinen, A. Zou, A. Jiang, A. Chen, A. Vuong, A. Gupta, A. Gottardi, A. Norelli, A. Venkatesh, A. Gholamidavoodi, A. Tabassum, A. Menezes, A. Kirubarajan, A. Mullokandov, A. Sabharwal, A. Herrick, A. Efrat, A. Erdem, A. Karakas, and et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. CoRR, abs/2206.04615, 2022. doi: 10.48550/arXiv.2206.04615. URL https://doi.org/10.48550/arXiv.2206.04615. A. Talmor, J. Herzig, N. Lourie, and J. Berant. Commonsenseqa: question answering challenge targeting commonsense knowledge. In J. Burstein, C. Doran, and T. Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 41494158. Association for Computational Linguistics, 2019. doi: 10.18653/v1/n19-1421. URL https://doi.org/10.18653/v1/n19-1421. G. Team. Gemini: family of highly capable multimodal models. arXiv preprint arXiv: 2312.11805, 2023. G. Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context, 2024a. URL https://arxiv.org/abs/2403.05530. G. Team, M. Riviere, S. Pathak, P. G. Sessa, C. Hardin, S. Bhupatiraju, L. Hussenot, T. Mesnard, B. Shahriari, A. Ram√©, et al. Gemma 2: Improving open language models at practical size. arXiv preprint arXiv:2408.00118, 2024. Q. Team. Qwq: Reflect deeply on the boundaries of the unknown, November 2024b. URL https://qwenlm.github.io/blog/qwq-32b-preview/. A. Wake, B. Chen, C. Lv, C. Li, C. Huang, C. Cai, C. Zheng, D. Cooper, F. Zhou, F. Hu, et al. Yi-lightning technical report. arXiv preprint arXiv:2412.01253, 2024. A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Superglue: stickier benchmark for general-purpose language un35 derstanding systems. In H. M. Wallach, H. Larochelle, A. Beygelzimer, F. dAlch√©Buc, E. B. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 32613275, 2019a. URL https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f 046bf4923da8de6-Abstract.html. A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. GLUE: multitask benchmark and analysis platform for natural language understanding. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019b. URL https://openreview.net/forum?i d=rJ4km2R5t7. P. Wang, Y. Wu, Z. M. Wang, J. Liu, X. Song, Z. Peng, K. Deng, C. Zhang, J. Wang, J. Peng, G. Zhang, H. Guo, Z. Zhang, W. Su, and B. Zheng. Mtu-bench: multi-granularity tool-use benchmark for large language models. ArXiv, abs/2410.11710, 2024a. Y. Wang, X. Ma, G. Zhang, Y. Ni, A. Chandra, S. Guo, W. Ren, A. Arulraj, X. He, Z. Jiang, T. Li, M. Ku, K. Wang, A. Zhuang, R. Fan, X. Yue, and W. Chen. Mmlu-pro: more robust and challenging multi-task language understanding benchmark. In Advances in Neural Information Processing Systems (NeurIPS) 2024, Track on Datasets and Benchmarks, 2024b. doi: 10.48550/arXiv.2406.01574. Spotlight Paper, Version v6: 6 Nov 2024. J. Wei, N. Karina, H. W. Chung, Y. J. Jiao, S. Papay, A. Glaese, J. Schulman, and W. Fedus. Measuring short-form factuality in large language models. ArXiv, abs/2411.04368, 2024a. URL https://api.semanticscholar.org/CorpusID:273877483. J. Wei, N. Karina, H. W. Chung, Y. J. Jiao, S. Papay, A. Glaese, J. Schulman, and W. Fedus. Measuring short-form factuality in large language models, 2024b. URL https: //arxiv.org/abs/2411.04368. S. Wu, Z. Peng, X. Du, T. Zheng, M. Liu, J. Wu, J. Ma, Y. Li, J. Yang, W. Zhou, Q. Lin, J. Zhao, Z. Zhang, W. Huang, G. Zhang, C. Lin, and J. H. Liu. comparative study on reasoning patterns of openais o1 model, 2024. URL https://arxiv.org/abs/24 10.13639. A. Yang, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu, C. Li, D. Liu, F. Huang, H. Wei, et al. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115, 2024a. B. Yang, Q. Yang, and R. Liu. Utmath: Math evaluation with unit test via reasoning-tocoding thoughts. arXiv preprint arXiv:2411.07240, 2024b. Z. Yang, P. Qi, S. Zhang, Y. Bengio, W. W. Cohen, R. Salakhutdinov, and C. D. Manning. Hotpotqa: dataset for diverse, explainable multi-hop question answering. In E. Riloff, D. Chiang, J. Hockenmaier, and J. Tsujii, editors, Proceedings of the Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 23692380. Association for Computational Linguistics, 2018. doi: 10.18653/v1/d18-1259. URL https://doi.org/10.18653/v1/d18-1 259. A. A. Young, B. Chen, C. Li, C. Huang, G. Zhang, G. Zhang, H. Li, J. Zhu, J. Chen, J. Chang, K. Yu, P. Liu, Q. Liu, S. Yue, S. Yang, S. Yang, T. Yu, W. Xie, W. Huang, X. Hu, X. Ren, X. Niu, P. Nie, Y. Xu, Y. Liu, Y. Wang, Y. Cai, Z. Gu, Z. Liu, and Z. Dai. Yi: Open foundation models by 01.ai. ArXiv, abs/2403.04652, 2024. R. Yuan, H. Lin, Y. Wang, Z. Tian, S. Wu, T. Shen, G. Zhang, Y. Wu, C. Liu, Z. Zhou, Z. Ma, L. Xue, Z. Wang, Q. Liu, T. Zheng, Y. Li, Y. Ma, Y. Liang, X. Chi, R. Liu, Z. Wang, P. Li, J. Wu, C. Lin, Q. Liu, T. Jiang, W. Huang, W. Chen, E. Benetos, J. Fu, G. Xia, R. Dannenberg, W. Xue, S. Kang, and Y. Guo. Chatmusician: Understanding and generating music intrinsically with llm, 2024. R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi. Hellaswag: Can machine really finish your sentence? In A. Korhonen, D. R. Traum, and L. M√†rquez, editors, Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28August 2, 2019, Volume 1: Long Papers, pages 47914800. Association for Computational Linguistics, 2019. doi: 10.18653/v1/p19-1472. URL https://doi.org/10.18653/v1/p19-1472. G. Zhang, S. Qu, J. Liu, C. Zhang, C. Lin, C. L. Yu, D. Pan, E. Cheng, J. Liu, Q. Lin, et al. Map-neo: Highly capable and transparent bilingual large language model series. arXiv preprint arXiv:2405.19327, 2024a. X. Zhang, Y. Zhang, D. Long, W. Xie, Z. Dai, J. Tang, H. Lin, B. Yang, P. Xie, F. Huang, et al. mgte: Generalized long-context text representation and reranking models for multilingual text retrieval. arXiv preprint arXiv:2407.19669, 2024b. Q. Zhao, Y. Huang, T. Lv, L. Cui, Q. Sun, S. Mao, X. Zhang, Y. Xin, Q. Yin, S. Li, and F. Wei. Mmlu-cf: contamination-free multi-task language understanding benchmark, 2024. URL https://arxiv.org/abs/2412.15194. 37 K. Zhu, Q. Zang, S. Jia, S. Wu, F. Fang, Y. Li, S. Gavin, T. Zheng, J. Guo, B. Li, et al. Lime: Less is more for mllm evaluation. arXiv preprint arXiv:2409.06851, 2024. 38 A. Difficulty-Stratified Samples Easy Sample Question: Which of the following statements about dance studies are correct? 1. According to Dantos definition, context is an art world with modern aspects. 2. La Bayad√®re is ballet created during the French July Revolution. 3. The ballet Sylvia is dance drama created during the Paris Commune period in 1871. 4. Korean court dance, when calculated according to temporal principles, does not belong to secondary civilization. Options: A) 1, 3 B) 1, 4 C) 1,2,4 D) 2,3 E) 1,2, F) 3 G) 4 H) 3,4 I) 1,2,3,4 J) 2,4 Answer: 3, Answer letter: Discipline: Literature and Arts Field: Art Studies Subfield: Dance Studies Difficulty: easy"
        },
        {
            "title": "Middle Sample",
            "content": "Question: deck of playing cards has 52 cards, and each shuffle changes the order of the cards, which is permutation. If each shuffle strictly follows the operation below: first divide the cards into two equal parts, then interlace the cards from each part alternately, so that the first and last cards remain in their original positions while all other cards are rearranged. Express this permutation as product of disjoint cycles, write out the 39 cyclic structure of this permutation, and determine the minimum number of shuffles needed to restore the deck to its original order. Options: A) (12, 2, 86), 8 B) (12, 5, 56), 6 C) (13, 1, 85), 15 D) (11, 4, 76), 11 E) (12, 4, 64), 12 F) (22, 1, 95), 9 G) (12, 3, 75), 10 H) (21, 2, 76), 7 I) (22, 3, 65), 5 J) (12, 6, 46), 4 Answer:(12, 2, 86), Answer letter: Discipline: Science Field: Mathematics Subfield: Group Theory Difficulty: middle"
        },
        {
            "title": "3 Hard Sample",
            "content": "Question: certain transmitter has transmission power of 10 W, carrier frequency of 900 MHz, transmission antenna gain ùê∫T = 2, and receiving antenna gain ùê∫R = 3. Calculate the output power of the receiver and the path loss at distance of 10 km from the transmitter in free space. Options: A) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) (cid:16) ùúÜ 3ùúãùëë = 2. 55 1012 = 5. 19 1011 ( BII 142. 43 dB) B) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 2 (cid:16) ùúÜ 4ùúãùëë = 5. 07 1011 = 1. 97 1010 ( BII 101. 95 dB) C) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 2 (cid:16) ùúÜ 4ùúãùëë = 1. 74 1010 = 4. 81 109 ( BII 98. 48 dB) D) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 2 (cid:16) ùúÜ 5ùúãùëë = 8. 40 1010 ùêø = ùëÉ ùëÉ ùêø = ùëÉ ùëÉ ùêø = ùëÉ ùëÉ ùêø = ùëÉ ùëÉ = 3. 98 109 ( BII 96. 07 dB) E) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 2 (cid:16) ùúÜ 4ùúãùëë = 2. 93 1010 40 = 6. 29 109 ( BII 99. 90 dB) ùêø = ùëÉ ùëÉ ùêø = ùëÉ ùëÉ ùêø = ùëÉ ùëÉ ùêø = ùëÉ ùëÉ ùêø = ùëÉ ùëÉ F) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 2 (cid:16) ùúÜ 3ùúãùëë = 6. 83 1010 = 1. 46 1010 ( BII 89. 35 dB) G) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 3 (cid:16) ùúÜ 4ùúãùëë = 9. 11 1011 = 3. 64 1010 ( BII 104. 78 dB) H) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) (cid:16) ùúÜ 4ùúãùëë = 3. 12 1009 = 9. 24 109 ( BII 99. 63 dB) I) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 2 (cid:16) ùúÜ 4ùúãùëë = 4. 22 1010 = 2. 37 1010 ( BII 103. 75 dB) J) ùëÉR = ùëÖTùê∫Tùê∫R (cid:17) 2 (cid:16) ùúÜ 6ùúãùëë = 7. 95 1011 ùêø = ùëÉ ùëÉ Answer: = 2. 50 1010 ( BII 102. 20 dB) ùëÉR = ùëÖTùê∫Tùê∫R (cid:19) (cid:18) ùúÜ 4ùúãùëë = 4. 22 1010 ùêø = ùëÉT ùëÉR = 2. 37 1010 ( BII 103. 75 dB) Answer letter: Discipline: Engineering Field: Information and Communication Engineering Subfield: Communication Principles Difficulty: hard B. Annotation Tutorial B.1. Material Requirements The specific requirements for material selection are as follows: Ensure the selected materials are accurate, with correct answers. Ensure the materials cover variety of knowledge points and are free from regional bias. The selected materials should be correctly stated and involve certain level of academic reasoning, with difficulty appropriate for graduate-level study. Avoid using materials that rely on images as conditions. Verify that the materials comply with copyright requirements. 41 B.2. Annotation Methods During the annotation process, the following four methods are primarily used: 1) Original Transcription Method, 2) Non-Choice Conversion Method, and 3) Statement Combination Method. B.2.1. Original Transcription Method Original Transcription Description: Directly transcribe the original multiple-choice questions, ensuring the question maintains its original meaning and correctness. Additional distractors are included to increase the difficulty of the question or enhance its discriminative power. Operations: 1. Material Review: Ensure that the materials meet the aforementioned requirements, including accuracy, diversity, neutrality (free from regional bias), non-image-based content, and compliance with copyright regulations. 2. Question Transcription: Use OCR tools to recognize the text in the materials or directly paste the original content. Transcribe the question content word-for-word, ensuring no key information is omitted, with particular attention to the accurate transcription of formulas. 3. Option Transcription: Use OCR tools to recognize the text in the materials or directly paste the original content. Transcribe the options word-for-word, ensuring no key information is omitted, with particular attention to the accurate transcription of formulas. 4. Answer Identification: Clearly mark the correct answer within the list of options, ensuring its accuracy and uniqueness. 5. Distractor Addition: Add distractors while maintaining the quality of the options (avoiding meaningless or excess correct answers) until the annotator deems the level of confusion sufficient. The number of options should be between 4 and 10, with more options being preferred to increase the difficulty and discriminatory power of the question. 6. Field Completion: Complete the category fields (\"discipline\",\"field\",\"subfield\") and select the appropriate difficulty level to ensure the integrity and accuracy of the question information. B.2.2. Non-Choice Conversion Method Non-Choice Conversion Description: Convert non-multiple-choice questions (such as calculation questions, fill-in-theblank questions, etc.) into multiple-choice format, ensuring that the conditions of the question are complete and the final result is accurate while generating reasonable distractors based on the analysis steps or calculation process. Operations: 1. Material Review: Ensure that the materials meet the aforementioned requirements, including accuracy, diversity, neutrality (free from regional bias), non-image-based content, and compliance with copyright regulations. Ensure that the conditions of the question are complete and do not cause ambiguity. Add supplementary explanations if necessary. Ensure that the answer does not contain any essential explanatory process that is unsuitable for adaptation or transcription. 2. Question Transcription: Use OCR tools to recognize the text in the material or directly paste the original text. Transcribe the content of the original question word by word, ensuring that all numbers, formulas, or condition information in the question are accurate and complete to avoid ambiguity or incorrect answers. Add supplementary information if the question requires prior conditions from other questions. 3. Answer Transcription: Identify and select the correct result for the appropriate question based on the answer analysis process. item Use OCR tools to recognize results in the material and confirm that all numerical and formula information in the answer is accurate. 4. Distractor Addition: On the basis of the correct answer, consider setting common calculation errors (such as rounding errors, sign mistakes, digit errors, etc.) as distractors. For numerical results, the setting of distractors should consider reasonable ranges of calculation errors to ensure differentiation between options. 5. Answer Identification: Clearly mark the correct answer within the list of options, ensuring its accuracy and uniqueness. 6. Field Completion: Complete the category fields (\"discipline\",\"field\",\"subfield\") and select the appropriate difficulty level to ensure the integrity and accuracy of the question information. B.2.3. Statement Combination Method Statement Combination Description: By integrating stated expressions related to multiple concepts or knowledge points, multi-level, multi-perspective multiple-choice question is constructed to increase the comprehensiveness and depth of examination of the topic. Operations: 1. Statement Extraction: Extract core concepts, definitions, relationships between concepts, application cases, and common misconceptions from textbooks and related learning resources, ensuring that the statements are representative and comprehensive. Extract important statements from multiple-choice questions, covering multiple knowledge points to avoid being limited to single definition or formula, thus enhancing the overall comprehensiveness of the questions. Ensure that the extracted statements are accurate and concise, avoiding redundancy or vague expressions. The content should cover both correct and incorrect situations to provide foundation for subsequent adaptation. 2. Statement Adaptation: Adapt the extracted statements to include both correct and incorrect versions. Incorrect statements should be somewhat misleading, avoiding obvious or easily dismissible errors. 44 Number the adapted statements (e.g., I, II, III, etc.). Arrange the statements in reasonable order, avoiding bias towards any direction (e.g., always placing correct statements first). 3. Question Design: Depending on the need, questions may limit the scope or conditions being tested. \"Which of the following statements about [knowledge point] is correct?\" \"Which of the following statements about [knowledge point] is incorrect?\" 4. Combination Design: Combine the numbered statements to create options, such as and II; II and III; III, VI, and VII. Ensure that there is exactly one correct answer among the options. 5. Answer Identification: Clearly mark the correct answer within the list of options, ensuring its accuracy and uniqueness. 6. Field Completion: Complete the category fields (\"discipline\",\"field\",\"subfield\") and select the appropriate difficulty level to ensure the integrity and accuracy of the question information. B.2.4. Confusion-options Generation During the annotation process, we use large models to assist in generating distractors. We select Claude-3.5, GPT-4, Doubao, and Qwen2.5-72B-Instruct, and follow the prompt below to generate confusion options. In the annotation process, model is randomly selected to generate confusion option, which is then double-checked by the annotator. Finally, the confirmed confusion option is used as the final option. Prompt You are an expert in creating multiple-choice questions. Your task is to generate plausible but incorrect distractors for given question that only has one correct answer. You are skilled at introducing subtle yet distinct mathematical errors to the existing answer options, making the distractor look reasonable but still wrong. Input Description: You will be given: 45 question stem. set of answer options (no numbering). The correct answer (no numbering). Guidelines: 1. Generate Distractor: The distractor must be incorrect (not the correct answer). The distractor should introduce subtle mathematical error while maintaining the formula structure. It must be distinct from all existing options, including the correct answer. Avoid any repetition or overlap with the existing answer options in terms of value or meaning. Plausibility: The distractor should look reasonable and appear to be potential answer, but still be wrong. Ensure the question still has exactly one correct answer after adding the distractor. 2. Uniqueness Check: Thoroughly check all existing options (including the correct one) to ensure the distractor is unique. If the distractor matches any existing option, regenerate it. The distractor must not create ambiguity; the correct answer must remain the sole valid choice. 3. Formatting: Ensure the distractor matches the format of the existing options (e.g., fractions, exponents, etc.). Avoid formatting inconsistencies such as misplaced symbols or spaces. Output Format: <distractor> your generated distractor here </distractor> Do not include explanations or extra information. Do not include numbering. Input: Question: \"{}\", Options: {}, Correct Answer: \"{}\" Output: 46 C. Data Filtering and Manual Review Process Details In the data processing workflow, we employ three-stage filtering and review mechanism to ensure data quality: 1. Rule-Based Pre-Check subsection C.1: Data undergoes initial screening based on predefined code rules, quickly identifying and eliminating clearly invalid data points, thereby enhancing efficiency and reducing subsequent workload. 2. LLM-Based Quality Inspection subsection C.2: Large language models are utilized to perform in-depth quality assessments of the data, identifying potential errors and inconsistencies, thereby improving the accuracy and completeness of the data. 3. Manual Quality Review subsection C.3: Experienced data analysts conduct final review to ensure the high quality and usability of the data, correcting potential misjudgments and incorporating domain knowledge for comprehensive evaluation. C.1. Rule-Based Pre-Check Table 8 presents the rules for data filtering and pre-checking, including text normalization, validation of the consistency of questions and options, integrity checks of answers, and requirements for the completeness of metadata such as difficulty, discipline, and others. 47 Category Rules Replace full-width punctuation with half-width punctuation. Remove unnecessary whitespace characters (e.g., spaces, newline characters, tab spaces). Text Replace common escape characters. Add missing escape characters. Not Empty or Placeholder. Ensure the question field is in string format to avoid errors. Text length > 5. Text Standardization. Question Perplexity 100, calculated using the Qwen2.5-0.5B-Instruct model. No Semantic Duplicates: For given question ùëûùëñ, the cosine similarity with each existing question ùëû ùëó : CosineSimilarity(ùëûùëñ, ùëû ùëó) = < 0.90 ei ej ei ej where ei and ej are embeddings generated by the model SentenceTransformer(\"all-MiniLM-L6v2\"), and Faiss is used for efficient similarity search. 4 Option count 10. No empty or meaningless options (e.g., no empty strings, no only whitespace characters, no common placeholders like none, null). Options No duplicate options. Remove built-in option prefixes, using regular expressions(rÀÜ([A-Ja-j])[.s] , rÀÜ(([A-Ja-j])) , rÀÜ([A-Ja-j])) ). Text Standardization for each option. Not Empty or Placeholder. Answer Within options list. Text Standardization. Difficulty Ensure difficulty exists. Discipline Ensure discipline, field, and subfield exist. Table 8. Detailed Criteria for Rule-Based Pre-Check. C.2. LLM-Based Quality Inspection This section outlines the quality inspection process of LLMs in data processing, including: 1) Validity Check, 2) Negative and Extreme Inquiry Detection, 3) Multimodal Exclusion, 4) Field Relevance Evaluation, 5) Solvability Assessment. 48 C.2.1. Validity Check Purpose Validate the questions correctness, ensuring it follows the standards, can be answered with the given text, and the options are complete and reasonable. Prompt You are master of format checking, skilled at verifying whether multiple-choice questions in JSON format conform to the specifications. You will receive an input in JSON format containing question, options, and the answer, for example: { question: \"Question content\", options: [Option content, Option content, Option content, Option content], answer: \"Answer content\" } Please determine whether the text in the JSON represents complete and solvable multiple-choice question. It must meet the following requirements: 1. The question must explicitly pose specific problem or ask clear question that can be answered or calculated. If the question does not clearly ask something (e.g., if it is vague, incomplete, or does not directly ask for specific answer), it should be considered invalid. valid question should directly require an answer, such as asking for numerical value or selection (e.g., \"What is the value of X?\", \"Which of the following is correct?\", etc.). Questions that lack clear problem or dont ask for specific answer must be marked invalid. 2. The question, options, and answer must be fully defined. If any part is missing or unclear (e.g., if the answer does not match any of the listed options), the question should be deemed invalid. Note that the number of options is not factor in determining completenesshaving only one option is acceptable as long as the content is complete and coherent. 3. The question, options, and answer must be directly relevant to each other. The options should not reference each other, and there should be no circular dependencies or inter-referencing between options (e.g., Option is true because Option is false). Each option must stand independently, with no cross-references to other options. 49 4. Negative phrasing such as The following options are incorrect or None of the above is not allowed in the question. The question should use positive phrasing (e.g., Which of the following is correct?) to avoid confusion. If negative phrasing is detected in the question, it should be deemed invalid. 5. The question must be in valid multiple-choice format. If the question is not suitable for multiple-choice format (e.g., it is free-form answer question like problem or essay), it should be deemed invalid. Ensure that the question is designed specifically for multiple-choice answering, rather than being question that requires an open-ended response. Please return the result in the following JSON format: { \"is_valid\": true/false } Ensure that the output is valid JSON format and do not return any unrelated information. Input: { question: \"{}\", options: {}, answer: \"{}\" } Output: C.2.2. Negative and Extreme Inquiry Detection Purpose Identify negative questions that may appear in the options, such as Which of the following options is incorrect? or Which of the following is not correct?. Also, identify questions that use \"most\" to indicate higher degree of likelihood or preference, such as Which of the following is most likely to occur? or Which option is most appropriate?. These types of questions are prone to having distractors that meet the conditions. 50 Prompt 1 Please evaluate whether the following text is valid and well-formed multiple-choice question, adhering to the following criteria: 1. The question must not be negation (e.g., \"Which of the following is NOT...?\" or \"What is not...?\"). 2. The question should avoid vague or ambiguous phrasing, such as \"Which of the following is the best/worst...?\" or other uncertain expressions. 3. The answer choices should not be all affirmations or all negations, such as \"All of the above\" or \"None of the above,\" as these are considered inappropriate. Please return the result in the following JSON format: { \"is_valid\": true/false } Ensure that the output is valid JSON and do not return any unrelated information. Example input 1: { question: Which of the following procedure is not done in CHC?, options: [\"Aboion\", \"Blood transfusion\", \"Caesaran section\", \"Urine microscopy and culture sensitivity\"], answer: Urine microscopy and culture sensitivity } Example output 1: { \"is_valid\": false } Example input 2: { question: Most common viral cause of acquired aqueductal stenosis is?, options: [\"Rubella\", \"Mumps\", \"Toxoplasma\", \"Enterovirus\"], answer: Mumps } Example output 2: 51 { \"is_valid\": false } Example input 3: { question: Acute cerebral edema occurs at high altitude due to, options: [\"apillary blood pressure\", \"Cerebral arteriolar dilation\", \"Hypoxic damage to capillary walls leading to capillary leak\", \"All of the above\"], answer: All of the above } Example output 3: { \"is_valid\": false } Example input 4: { question: Rideal Walker test is used to determine the efficiency of the, options: [\"Disinfectant\", \"Moist heat sterilisation\", \"Antibiotics\", \"Dry heat sterilization\"], answer: Disinfectant } Example output 4: { \"is_valid\": true } Input: { \"question\": {}, \"options\": {}, \"answer\": {} } Output: Prompt 2 Input Description: You will be given: question statement (Question). Guidelines: 1. Analyze the final part of the question (the actual question being asked) to check for specific phrases: \"incorrect\" incorrect\" in context like \"which of the following is \"most\" in context like \"which is most likely\" 2. If either of these phrases appears in the questions final asking part, output true, followed by brief explanation of why the phrase is present. 3. If neither phrase is found in the questions final part, output false, followed by brief explanation. Output Format: Provide response with: true or false as the first part of the output brief explanation that justifies your answer Example Input: Question: \"A new technology is introduced in manufacturing plant. Which of the following is most likely to occur?\" Example Output: { } \"is_valid\": true/false, Explanation: Brief explanation of why the phrase is present. 53 Question: {} Output: { } \"is_valid\": true/false, C.2.3. Multimodal Exclusion Purpose Check if the question relies on multimodal image information, and remove questions involving image information."
        },
        {
            "title": "Prompt",
            "content": "You will be given question or problem statement. Please determine if it strictly requires visual/image input to be solved. Only output true if the question absolutely cannot be solved without an image (e.g. \"What color is the car in this image?\", \"Describe the graph shown\"). For all other cases where the question could potentially be answered with just text, output false (e.g. math problems, logic puzzles, verbal descriptions). Output format: If visual input is strictly required: true + brief reason Otherwise: false + brief reason Question: {} C.2.4. Field Relevance Evaluation Purpose Assess whether the classification labels are appropriate. Evaluate the classification level by level: First, check if the \"discipline\" is relevant to the question. If the \"discipline\" is appropriate, assess whether the \"field\" is relevant. If the \"field\" is suitable, evaluate whether the \"subfield\" is relevant. 54 If the \"subfield\" is highly relevant to the question, the entire classification (\"discipline,\" \"field,\" and \"subfield\") is considered appropriate, even if there are minor mismatches in the \"discipline\" or \"field.\" If no levels meet the above criteria, or if any level other than \"subfield\" is deemed inappropriate and the \"subfield\" is not highly relevant, the classification is considered not relevant. Prompt You are an expert in hierarchical classification. Based on the given question and the provided three-level classification structure (discipline, field, subfield), evaluate whether the classification assigned to the question is appropriate. Classification Structure: { } \"discipline\": \"{}\", \"field\": \"{}\", \"subfield\": \"{}\" Question: {} Instructions: 1. Evaluate the classification level by level: First, check if the discipline is relevant to the question. If discipline is appropriate, evaluate if the field is relevant. If field is appropriate, evaluate if the subfield is relevant. 2. Special rule: If the subfield is found to be highly relevant to the question, the entire classification (discipline, field, and subfield) is considered appropriate, regardless of minor mismatches in discipline or field. 3. If no levels meet the above criteria, or if any level other than subfield is deemed inappropriate without subfield being highly relevant, the classification is considered not relevant. 4. Output strictly and exclusively in the following JSON format and dont output any explanation, just output JSON: { \"is_relevant\": true/false } C.2.5. Completeness Assessment Purpose Determine if the question is solvable, considering the following two dimensions: Confidence: The level of confidence in the answer, categorized as \"High,\" \"Medium,\" or \"Low.\" Missing Information: If an accurate answer cannot be provided, assess whether it is due to missing information (e.g., diagrams, formulas, known conditions) that makes the problem unsolvable, or if it is due to other reasons (e.g., high difficulty or uncertainty)."
        },
        {
            "title": "Prompt",
            "content": "Please review and solve the following problems: 1. Attempt to solve the problem and assess your confidence level in the answer. 2. If you cannot provide an accurate answer, evaluate whether it is due to missing information (e.g., diagrams, formulas, known conditions) that makes the problem unsolvable, or if its due to other reasons (e.g., high difficulty or uncertainty in solving). 3. Output format: \"final_answer_letter\": \"A\", \"confidence\": \"High\", \"missing_info\": false { } Rules: If the problem is missing \"diagram\" (such as geometry question requiring visual true and explain that the absence of the input), mark it as missing_info: diagram or visual representation makes the question unsolvable. If the problem contains sufficient information but is difficult (e.g., requiring complex false reasoning or having multiple possible solutions), mark missing_info: and assign confidence level based on the models reasoning process: \"High\": If the problem is simple and straightforward, with clear solution. 56 \"Medium\": If the problem involves multiple steps or requires further reasoning. \"Low\": If the problem is complex, involves extensive information, or the model is uncertain about the solution. If the problem is missing key necessary information (such as numbers, formulas, or critical conditions), mark it as missing_info: true. Output Format: # The final answer option letter (e.g., A, B, C...) final_answer_letter: \"A\" # Confidence level (High, Medium, Low) confidence: \"High\" # Whether key information is missing, boolean (true or false) missing_info: false Examples: Question: \"Calculate the difference between and B.\" missing_info: true explanation: \"Missing the values of and B, so it cannot be calculated.\" answer: \"A\" confidence: \"Low\" Question: \"Given geometric shape, calculate its area.\" missing_info: true explanation: \"The diagram is missing, so it cannot be solved.\" answer: \"B\" confidence: \"Low\" Question: \"Given the radius of circle as 5, calculate the area of the circle.\" missing_info: false explanation: \"The problem is complete and solvable, high confidence.\" answer: \"A\" confidence: \"High\" Question: {} Output: final_answer_letter: \"A\" confidence: \"High\" missing_info: false 57 C.3. Manual Quality Review Table 9 outlines the manual review process, focusing on ensuring consistency, clarity, accuracy, global perspective, and appropriate difficulty, while validating the correctness and uniqueness of answers and proper categorization. Category Focus Description Source Consistency Align question source with annotations. Condition Completeness Base answers solely on provided text. Avoid needing additional conditions like charts or legal clauses. Question Clarity Be clear and specific. Have only one correct answer. Avoid vague or open-ended questions. Question Expression Accuracy Write in English. Use precise terminology. Formula and Numerical Accuracy Write formulas in LaTeX. Accurately translate specialized terms. Global Perspective Align key formulas and numerical details. Frame from global perspective. Avoid regional bias. Expression Accuracy Accurately translate proper nouns and terminology. Formula and Numerical Accuracy Ensure formula and numerical accuracy. Correctly format in LaTeX. Distractor Relevance Distinguish from correct answers. Make incorrect options meaningful but not correct. Answer Correctness Answer Uniqueness Match correct options in length and format. Ensure the answer is in the options. Accurately answers the question. Ensure the answer is unique. Avoid multiple valid answers due to vague wording or incorrect options. Difficulty Matching Match difficulty to graduate-level. Difficulty Reasonableness Ensure difficulty is reasonable based on complexity and presented options. Category Accuracy Categorize correctly with accurate primary and secondary subjects. Options Answer Difficulty Discipline Category Validity Correctly fill category fields. No missing or unnecessary fields. Table 9. Detailed Guidelines for Manual Quality Review. 58 C.4. Reasons for Failing Quality Inspection Question Block 1 Question: Consider resistor made from hollow cylinder of carbon as shown below. The inner radius of the cylinder is ùëÖùëñ = 0.2mm and the outer radius is ùëÖùëú = 0.3mm. The length of the resistor is ùêø = 0.9mm. The resistivity of the carbon is ùúå = 3.5 105 Œ© ùëö. What is the resistance? Options: 3.0 1. 5.0 2.0 1.5 2.8 3.5 4. 2.5 1.8 Answer: 2.5 Error Analysis Block 1 Error Type: Condition Setting Defect Error Analysis: The solution to the correction problem requires diagram as condition; without the diagram, the problem cannot be solved. Therefore, this question lacks condition setting and cannot be answered. Question Block 2 Question: Which of the following descriptions about the function of gastrointestinal motility is incorrect? Options: Controlling the release of bile from the gallbladder Facilitating the absorption of nutrients into the bloodstream Assisting in the immune response of the gut Regulating the pace of digestion Stimulating enzyme production in the pancreas Breaking down large food molecules into smaller molecules 59 Mixing food with digestive juices Propelling food through the digestive tract Coordinating muscle contractions in the digestive system Maintaining the pH balance in the stomach Answer: Breaking down large food molecules into smaller molecules Error Analysis Block 2 Error Type: Incorrect option construction Error Analysis: Options such as stimulating enzyme production in the pancreas, maintaining the pH balance in the stomach, and several other choices are correct answers to the question. Questions involving terms like \"incorrect\" or \"most\" require careful construction of distractors, but the reviewer fails to ensure the uniqueness of the correct answer. Question Block 3 Question: Ross claims that we learn of our prima facie duties: Options: from the moral judgments we make in various situations. by seeing the prima facie rightness of particular acts, and then apprehending general principles. from the explicit moral instruction we receive as children. through societal norms and cultural values. from religious teachings or scriptures. by observing the consequences of our actions. by intuitively understanding moral obligations. by proving them philosophically. by apprehending general principles, and then inferring the prima facie rightness of particular acts. through legal regulations and laws. Answer: by seeing the prima facie rightness of particular acts, and then apprehending general principles Error Analysis Block Error Type: Missing Contextual Information Error Analysis: The problem does not provide sufficient contextual information, such as Rosss background or theories, to allow for proper comprehension and answer selection. 60 Question Block 4 Question: About the I-type system tracking the step signal, whats the steady-state error between them? Options: 10 infinity 2 -0. 1 0.5 undefined 0 -1 Answer: 0 Error Analysis Block 4 Error Type: Distractor Quality Issue Error Analysis: Some options, such as \"infinity\" and \"undefined,\" may not be relevant or may be poorly constructed. These distractors may not effectively contribute to creating meaningful confusion. Question Block 5 Question: cube of iron was heated to 70C and transferred to beaker containing 100g of water at 20C. The final temperature of the water and the iron was 23C. What is the heat capacity? Options: 0.310 ùêæ 1 ùëî1 0.740 ùêæ 1 ùëî1 0.582 ùêæ 1 ùëî1 1.200 ùêæ 1 ùëî1 0.453 ùêæ 1 ùëî1 0.235 ùêæ 1 ùëî1 1.004 ùêæ 1 ùëî1 0.505 ùêæ 1 ùëî1 0.875 ùêæ 1 ùëî 61 0.690 ùêæ 1 ùëî1 Answer: 0.453 ùêæ 1 ùëî1 Error Analysis Block 5 Error Type: Condition Setting Defect Error Analysis: The problem lacks critical information about the mass of the iron cube, which makes it unsolvable. Question Block 6 Question: The Central Committee of the Communist Party of China and the Central Government are striving to enhance our countrys military security functions. In order to achieve this, they should further promote the governance of the military according to law and strict discipline, focusing on the crucial ( ). Options: Checks and Balances on the Exercise of Power Procedures and Control of Power Maintenance and Supervision of Power Regulation and Oversight of Authority Coordination and Monitoring of Authority Systems and Regulation of Governance Security and Management of Authority Power Operation Management Power Operation Guarantee Power Operation Coordination Answer: Checks and Balances on the Exercise of Power Error Analysis Block 6 Error Type: Region-Specific Context Missing Error Analysis: The question has clear regional context (China) that should be accounted for in item selection or modification. Additionally, the item could be better adapted or refined to enhance clarity and relevance. Question Block Question: Use the example below to answer the question that follows. Identify the type of dissonance found above the asterisk in the given voice-leading example. 62 Options: Neighbor tone Appoggiatura Suspension Passing tone Answer: Passing tone Error Analysis Block 7 Error Type: Missing Contextual Information Error Analysis: The question lacks the necessary example (voice-leading notation) and cannot be answered. Question Block 8 Question: Suppose an electric field E(ùë•, ùë¶, ùëß) has the form ùê∏ùë• = ùëéùë•, ùê∏ ùë¶ = 0, ùê∏ùëß = where ùëé is constant. What is the charge density? How do you account for the fact that the field points in particular direction, when the charge density is uniform? Options: ùúñ0ùë• ùúñ0 ùë¶ ùë•ùëéùúñ ùúñ0ùëé ùë•ùúñ0 ùúñùëßùëé ùúñ0ùëß ùëéùúñùë¶ ùúñùëéùë¶ ùúñùë• ùëé Answer: ùúñ0ùëé Error Analysis Block Error Type: Incomplete Question and Answer Construction Error Analysis: The question contains two sub-questions, but the answer and options only address one, causing ambiguity. 63 D. Quantitative Overview of Disciplines at Three Levels Discipline Field Subfield Discipline Field Subfield Agronomy(485) Animal Husbandry(103) Animal Nutrition and Feed Science(52) Engineering(7892) Geological Resources and Geological Resources and Geological Engineering(50) Animal Rearing and Breeding(51) Hydraulic Engineering(218) Hydraulics and Hydrology(136) Geological Engineering(50) Aquaculture(56) Crop Science(145) Aquaculture(56) Crop Science(145) Forestry(131) Forest Cultivation and Genetic Breeding(81) Landscape Plants and Ornamental Horticulture(50) Veterinary Medicine(50) Veterinary Medicine(50) Economics(873) Applied Economics(723) Economic Statistics(50) Information and Communication Antenna and Radio Communication(114) Water conservancy and Hydropower Engineering(82) Engineering(504) Communication Principles(116) Communication and Information Systems(69) Optical Fiber Communication(50) Signal and Information Processing(155) Finance(176) Instrument Science and Instrument Science and Technology(50) Industrial Economics(84) Materials Science and Materials Physics and Chemistry(199) Technology(50) International Trade(69) Labor Economics(74) National and Defense Economics(50) Public Finance(120) Quantitative Economics(100) Theoretical Economics(150) Economic History(50) Political Economy(50) Western Economics(50) Engineering(289) Materials Processing Engineering(90) Mechanical Engineering(176) Manufacturing Automation(126) Mechatronic Engineering(50) Mechanics(908) Fundamentals of Dynamics and Control(347) Rigid Body Mechanics(173) Solid Mechanics(93) Theoretical Fluid Mechanics(140) Theoretical Mechanics(155) Education(484) Education(247) Educational Technology and Principles(96) Metallurgical Engineering(255) Iron and Steel Metallurgy(105) Preschool Education(50) Special Education(50) Theory of Curriculum and Instruction(51) Non-ferrous Metallurgy(50) Physical Chemistry of Metallurgical Process(50) Principles of Metallurgy(50) Physical Education(150) Physical Education and Training(50) Mining Engineering(100) Mineral Processing Engineering(50) Sports Humanities and Sociology(50) Sports Science and Medicine(50) Naval Architecture and Ocean Marine Engineering(50) Engineering(138) Mining and Safety Engineering(50) Psychology(87) Psychology(87) Ship Mechanics and Design Principles(88) Engineering(7892) Aeronautical and Astronautical Aeronautical and Astronautical Science and Nuclear Science and Nuclear Energy and Reactor Technology(57) Science and Technology(119) Technology(119) Technology(107) Agricultural Engineering(104) Agricultural Environment and Soil-Water Engineering(54) Radiation Protection and Nuclear Technology Agricultural Mechanization Engineering(50) Optical Engineering(376) Applied Optics(124) Applications(50) Architecture(162) Architectural Design and Theory(50) Architectural History(62) Urban Planning and Design(50) Laser Technology(50) Optoelectronic Technology(67) Theoretical Optics(135) Chemical Engineering and Chemical Transport Engineering(50) Petroleum and Natural Gas Oil and Gas Field Development and Storage & Technology(410) Engineering(112) Transportation Engineering(62) Elements of Chemical Reaction Engineering(107) Poromechanics and Reservoir Physics(50) Fluid Flow and Heat Transfer in Chemical Engineering(107) Power Engineering and Engineering Fluid Mechanics(84) Mass Transport and Separation Process in Chemical Engineering Thermophysics(146) Engineering Thermophysics(684) Civil Engineering(358) Bridge and Tunnel Engineering(51) Engineering(146) Geotechnical Engineering(179) Structural Engineering(57) Urban Infrastructure Engineering(71) Computer Science and Advanced Programming Languages(50) Technology(763) Computer Architecture(50) Computer Networks(59) Computer Software and Theory(79) Data Structures(99) Databases(157) Formal Languages(52) Operating Systems(85) Pattern Recognition(50) Principles of Computer Organization(82) Control Theory and Control Engineering(89) Control Science and Engineering(190) Fluid Machinery and Engineering(64) Heat Transfer(129) Internal Combustion Engineering(50) Power Machinery and Engineering(52) Refrigeration and Cryogenic Engineering(50) Thermal Energy Engineering(109) Surveying and Mapping Science Cartography and Geographic Information Engineering(50) and Technology(168) Textile Science and Engineering(100) Digital Surveying and Remote Sensing Applications(68) Geodesy and Surveying Engineering(50) Textile Chemistry and Dyeing Engineering(50) Transportation Engineering(251) Road and Railway Engineering(50) Textile Materials Science(50) Traffic Information Engineering and Control(65) Transportation Planning and Management(86) Vehicle Operation Engineering(50) Guidance, Navigation and Control(51) Weapon Science and Military Chemistry and Pyrotechnics(50) Technology(100) Electrical Engineering(556) Electrical Theory and New Technologies(190) History(674) History(674) Archaeology and Museology(104) Operations Research and Cybernetics(50) Weapon Systems Science and Engineering(50) High Voltage and Insulation Technology(88) Power Electronics and Electrical Drives(182) Historical Geography(142) World History(428) Electronic Science and Circuits and Systems(108) Constitutional and Administrative Law(50) Power Systems and Automation(96) Law(656) Law(591) Civil and Commercial Law(118) Technology(246) Electromagnetic Field and Microwave Technology(88) Microelectronics and Solid-State Electronics(50) Environmental Science and Environmental Engineering(89) Engineering(189) Environmental Science(50) Environmental and Resource Protection(50) Food Science and Engineering(109) Food Biochemistry(50) Food Processing and Storage Engineering(59) Forestry Engineering(100) Forest Engineering(50) Political Science(65) Wood Science and Technology(50) - - Contract Law(50) Criminal Law(116) International Law(57) Law and Social Governance(50) Legal Theory and Legal History(50) Military Law(50) Procedural Law(50) Political Science(65) - Table 10. Comprehensive Overview of Three Levels of Disciplines and Their Sample Sizes. 64 Discipline Field Subfield Discipline Field Subfield Literature and Art Studies(603) Broadcasting and Television Art(50) Philosophy(347) Philosophy(347) Religious Studies(50) Arts(1676) Dance Studies(50) Design Arts(62) Drama and Opera Studies(82) Film Studies(158) Fine Arts(201) Science(9838) Astronomy(405) Astronomical Observation and Technology(100) Astrophysics(69) Cosmology(78) Solar System Science(88) Stellar and Interstellar Evolution(70) Journalism and Communication(207) Communication and Broadcasting(58) Atmospheric Science(203) Atmospheric Physics and Atmospheric Environment(69) History and Theory of Journalism and Media Management(59) Journalism and News Practice(90) Dynamic Meteorology(50) Meteorology(84) Language and Literature(440) Classical Chinese Literature(50) Biology(1120) Biochemistry and Molecular Biology(99) French Language and Literature(50) Linguistics and Applied Linguistics(50) Literary History(69) Literary Theory(64) Modern and Contemporary Chinese Literature(50) Philology and Bibliography(50) Russian Language and Literature(57) Musicology(426) Composition(50) Harmony(60) Instrumentation and Performance(65) Music History, Education, and Technology(145) Musical Forms and Analysis(50) Pitch and Scales(56) Management(501) Business Administration(142) Business and Accounting Management(92) Tourism Management and Technological Economics Management(50) Biophysics(50) Botany(166) Cell Biology(87) Ecology(144) Genetics(184) Microbiology(161) Physiology(120) Zoology(109) Chemistry(1769) Analytical Chemistry(396) Electrochemistry(222) Inorganic Chemistry(138) Organic Chemistry(171) Physical Chemistry(706) Polymer Chemistry and Physics(76) Radiochemistry(60) Library, Information and Archival Information Management Science(50) Geography(133) Human Geography(50) Management(150) Information Management and Communication(50) Library and Archival Science(50) Geology(341) Physical Geography(83) Geochemistry(50) Management Science and Management Science and Engineering(58) Mineralogy, Petrology, and Economic Geology(121) Engineering(58) Public Administration(151) Education Economics, Management and Social Security(50) Land Resource Management and Administrative Management(51) Social Medicine and Health Management(50) Paleontology and Stratigraphy(50) Principles of Seismic Exploration(50) Structural Geology(70) Medicine(2755) Basic Medicine(567) Forensic Medicine(50) Geophysics(100) Solid Earth Geophysics(50) Human Anatomy and Histology-Embryology(189) Space physics(50) Mathematics(2622) Advanced Algebra(202) Immunology(69) Pathogen Biology(94) Pathology and Pathophysiology(115) Radiation Medicine(50) Clinical Medicine(1218) Anesthesiology(50) Clinical Laboratory Diagnostics(50) Dermatology and Venereology(66) Emergency Medicine(66) Geriatric Medicine(50) Imaging and Nuclear Medicine(67) Internal Medicine(202) Neurology(189) Nursing and Rehabilitation Medicine(50) Obstetrics and Gynecology(102) Oncology(58) Ophthalmology(50) Otorhinolaryngology(50) Pediatrics(50) Psychiatry and Mental Health(50) Surgery(68) Microbiology and Biochemical Pharmacy(50) Pharmaceutical Analysis(50) Pharmaceutics(73) Pharmacology(55) Combinatorial Mathematics(191) Computational Mathematics(50) Cryptography(50) Discrete Mathematics(89) Functions of Complex Variables(122) Functions of Real Variables(67) Fundamental Mathematics(197) Fuzzy Mathematics(50) Geometry and Topology(265) Graph Theory(51) Group Theory(50) Mathematical Analysis(288) Number Theory(220) Numerical Analysis(67) Ordinary Differential Equations(160) Polynomials and Series Expansions(179) Probability and Statistics(224) Special Number Theory(50) Stochastic Processes(50) Hydrogeology(50) Marine Biology(50) Marine Chemistry(50) Underwater Acoustics(50) Pharmacy(278) Medicinal Chemistry(50) Oceanography(200) Physical Oceanography(50) Physical Oceanography(50) Public Health and Preventive Epidemiology and Health Statistics(83) Physics(2845) Acoustics(245) Medicine(292) Health Toxicology and Environmental Health(80) Maternal, Child and Adolescent Health(79) Nutrition and Food Hygiene(50) Stomatology(132) Basic Stomatology(53) Clinical Stomatology(79) Traditional Chinese Medicine(268) Traditional Chinese Health Preservation(59) Traditional Chinese Medicine Theory(90) Traditional Chinese Pharmacy(119) Military Military Science(205) Military Command and Information Systems(50) Science(205) Philosophy(347) Philosophy(347) Military Logistics and Equipment(54) Military Management(50) Military Thought and History(51) Ethics(68) Logic(70) Atomic and Molecular Physics(210) Electrodynamics(583) Fluid Physics(134) Particle and Nuclear Physics(225) Polymer Physics(109) Quantum Mechanics(206) Relativity(79) Semiconductor Physics(61) Solid State Physics(147) Statistical Mechanics(50) Subatomic and Atomic Physics(51) Thermodynamics(215) Thermodynamics and Statistical Physics(530) Systems Science(50) Systems Science(50) Philosophical Aesthetics(109) Sociology(143) Sociology(143) Demography and Anthropology(50) Philosophy of Science and Technology(50) Social and Folklore Studies(93) Table 10. Continued: Comprehensive Overview of Three Levels of Disciplines and Their Sample Sizes. E. Detailed Dataset Statistics (a) Agriculture. (b) Economics. (c) Education. (d) Engineering. (e) History. (f) Law. (g) Literature. (h) Management. (i) Medicine. (j) Military Science. (k) Philosophy. (l) Science. (m) Sociology. Figure 9. Question Length Distribution Across Disciplines. 66 (a) Agriculture. (b) Economics. (c) Education. (d) Engineering. (e) History. (f) Law. (g) Literature. (h) Management. (i) Medicine. (j) Military Science. (k) Philosophy. (l) Science. (m) Sociology. Figure 10. Answer Length Distribution Across Disciplines. 67 (a) Agriculture. (b) Economics. (c) Education. (d) Engineering. (e) History. (f) Law. (g) Literature. (h) Management. (i) Medicine. (j) Military Science. (k) Philosophy. (l) Science. (m) Sociology. Figure 11. Option Count Distribution Across Disciplines. 68 F. Evaluation Prompt F.1. Zero-shot Prompt Zero-shot Answer the following multiple-choice question. There is only one correct answer. The last line of your response should be in the format Answer: $LETTER (without quotes), where LETTER is one of A, B, C, D, E, F, G, H, I, or J. {Question} Question format example: Question: microwave oven is connected to an outlet, 120 V, and draws current of 2 amps. At what rate is energy being used by the microwave oven? A) 240 B) 120 C) 10 D) 480 E) 360 F) 200 G) 30 H) 150 I) 60 J) 300 F.2. Five-shot Prompt Five-shot Answer the following multiple-choice question. There is only one correct answer. The last line of your response should be in the format Answer: $LETTER (without quotes), where LETTER is one of A, B, C, D, E, F, G, H, I, or J. Question: refracting telescope consists of two converging lenses separated by 100 cm. The eye-piece lens has focal length of 20 cm. The angular magnification of the telescope is ( ). A) 10 B) 40 C) 6 D) 25 E) 15 F) 50 G) 30 H) 4 I) J) 20 Answer: Lets think step by step. In refracting telescope, if both lenses are converging, the focus of both lenses must be between the two lenses, and thus the focal lengths of the two lenses must add up to their separation. Since the focal length of one lens is 20 cm, the focal length of the other must be 80 cm. The magnification is the ratio of these two focal lengths, or 4. Answer: H. Question: Say the pupil of your eye has diameter of 5 mm and you have telescope with an aperture of 50 cm. How much more light can the telescope gather than your eye? A) 1000 times more B) 50 times more C) 5000 times more D) 500 times more E) 10000 times more F) 20000 times more G) 2000 times more H) 100 times more I) 10 times more J) N/A Answer: Lets think step by step. The amount of light telescope can gather compared to the human eye is proportional to the area of its apertures. The area of circle is given by the formula ùê¥ = ùúã (cid:0) ùê∑ , where ùê∑ is the diameter. Therefore, the relative light-gathering 2 power is calculated as: (cid:1) 2 (cid:17) 2 (cid:17) (cid:16) 50 cm 2 (cid:16) 5 mm 2 = (cid:17) 2 (cid:17) 2 (cid:16) 50 cm 0.1 cm (cid:16) 5 mm 0.1 cm = 5002 52 = 10000. Answer: E. Question: Where do most short-period comets come from and how do we know? A) The Kuiper belt; short period comets tend to be in the plane of the solar system like the Kuiper belt. B) The asteroid belt; short period comets tend to come from random directions indicating 70 spherical distribution of comets called the asteroid belt. C) The asteroid belt; short period comets tend to be in the plane of the solar system just like the asteroid belt. D) The Oort cloud; short period comets have orbital periods similar to asteroids like Vesta and are found in the plane of the solar system just like the Oort cloud. E) The Oort Cloud; short period comets tend to come from random directions indicating spherical distribution of comets called the Oort Cloud. F) The Oort cloud; short period comets tend to be in the plane of the solar system just like the Oort cloud. G) The asteroid belt; short period comets have orbital periods similar to asteroids like Vesta and are found in the plane of the solar system just like the asteroid belt. Answer: Lets think step by step. Most short-period comets originate from the Kuiper belt. This is deduced from the observation that these comets tend to follow orbits that lie in the plane of the solar system, similar to the distribution of objects in the Kuiper belt itself. Thus, the alignment of these cometary orbits with the ecliptic plane points to their Kuiper belt origin. Answer: A. Question: Colors in soap bubble result from light ( ). A) dispersion B) deflection C) refraction D) reflection E) interference F) converted to different frequency G) polarization H) absorption I) diffraction J) transmission Answer: Lets think step by step.The colorful patterns observed in soap bubble are caused by the phenomenon of light interference. This occurs when light waves bounce between the two surfaces of the soap film, combining constructively or destructively based on their phase differences and the varying thickness of the film. These interactions result in vibrant color patterns due to variations in the intensity of different wavelengths of light. Answer: E. Question: microwave oven is connected to an outlet, 120 V, and draws current of 2 amps. At what rate is energy being used by the microwave oven? 71 A) 240 B) 120 C) 10 D) 480 E) 360 F) 200 G) 30 H) 150 I) 60 J) 300 Answer: Lets think step by step. The rate of energy usage, known as power, in an electrical circuit is calculated by the product of voltage and current. For microwave oven connected to 120 outlet and drawing current of 2 amps, the power consumption can be calculated as follows: Power = Voltage Current = 120 2 = 240 W. Therefore, the microwave oven uses energy at rate of 240 watts. Answer: A. {Question} Answer: Lets think step by step. G. Further Experiment Analysis G.1. Impact of Subfield Information We conduct zero-shot evaluations under two conditions to investigate the impact of subfield information. 1) zero-shot-with-subfield, where the prompt includes description of the problems subfield, and (2)zero-shot-without-subfield, where no subfield information is provided.The prompts employed for the zero-shot-with-subfield evaluation are presented below. Zero-shot-with-subfield Answer the following multiple choice question about {subfield} There is only one correct answer. The last line of your response should be in the format Answer: $LETTER (without quotes), where LETTER is one of A, B, C, D, E, F, G, H, I, or J. Question format example: The common-mode rejection ratio of the first stage amplification circuit in three-op-amp differential circuit is determined by ( ). A) the absolute value of the difference in the common-mode rejection ratio of A1 and A2 themselves B) all of the above C) the average of A1 and A2s common-mode rejection ratios D) the sum of A1 and A2s common-mode rejection ratios E) the product of A1 and A2s common-mode rejection ratios F) the square root of the product of A1 and A2s common-mode rejection ratios G) the size of A2s common-mode rejection ratio H) the size of A1s common-mode rejection ratio I) The difference in the common-mode rejection ratio of A1 and A2 themselves J) input resistance G.2. Robustness of the Evaluation We employ 4 types of initial prompts and 6 types of question formats, resulting in combination of 24 different prompt styles to verify the robustness of our bench. The initial prompts and 6 types of question formats are listed below. Initial Prompt 1 Answer the following multiple choice question. There is only one correct answer. The last line of your response should be in the format Answer: $LETTER (without quotes), where LETTER is one of A, B, C, D, E, F, G, H, I, or J. Initial Prompt You are helpful assistant. Answer the given multiple-choice question. Only one option is correct. The last line of your response should be in the format The correct answer is: $LETTER, where LETTER is one of A, B, C, D, E, F, G, H, I, or J. Initial Prompt 3 Select the correct answer for the following multiple-choice question. There is only one valid choice. The last line of your response should be in the format Answer: $LETTER (without quotes), where LETTER is one of A, B, C, D, E, F, G, H, I, or J. 73 Initial Prompt 4 Review the following multiple-choice question and choose the one correct answer. Ensure that your response concludes with line exactly formatted as The correct answer is: $LETTER, where LETTER represents one of A, B, C, D, E, F, G, H, I, or J. Question Format Example 1 The common-mode rejection ratio of the first stage amplification circuit in three-op-amp differential circuit is determined by ( ). A) the absolute value of the difference in the common-mode rejection ratio of A1 and A2 themselves B) all of the above C) the average of A1 and A2s common-mode rejection ratios D) the sum of A1 and A2s common-mode rejection ratios E) the product of A1 and A2s common-mode rejection ratios F) the square root of the product of A1 and A2s common-mode rejection ratios G) the size of A2s common-mode rejection ratio H) the size of A1s common-mode rejection ratio I) The difference in the common-mode rejection ratio of A1 and A2 themselves J) input resistance Question Format Example 2 The common-mode rejection ratio of the first stage amplification circuit in three-op-amp differential circuit is determined by ( ). A. the absolute value of the difference in the common-mode rejection ratio of A1 and themselves B. all of the above C. the average of A1 and A2s common-mode rejection ratios D. the sum of A1 and A2s common-mode rejection ratios E. the product of A1 and A2s common-mode rejection ratios F. the square root of the product of A1 and A2s common-mode rejection ratios G. the size of A2s common-mode rejection ratio H. the size of A1s common-mode rejection ratio I. The difference in the common-mode rejection ratio of A1 and A2 themselves J. input resistance Your response: 74 Question Format Example Question: The common-mode rejection ratio of the first stage amplification circuit in three-op-amp differential circuit is determined by ( ). Options: A) the absolute value of the difference in the common-mode rejection ratio of A1 and A2 themselves B) all of the above C) the average of A1 and A2s common-mode rejection ratios D) the sum of A1 and A2s common-mode rejection ratios E) the product of A1 and A2s common-mode rejection ratios F) the square root of the product of A1 and A2s common-mode rejection ratios G) the size of A2s common-mode rejection ratio H) the size of A1s common-mode rejection ratio I) The difference in the common-mode rejection ratio of A1 and A2 themselves J) input resistance Please begin answering. Question Format Example 4 Q: The common-mode rejection ratio of the first stage amplification circuit in threeop-amp differential circuit is determined by ( ). (A) the absolute value of the difference in the common-mode rejection ratio of A1 and A2 themselves (B) all of the above (C) the average of A1 and A2s common-mode rejection ratios (D) the sum of A1 and A2s common-mode rejection ratios (E) the product of A1 and A2s common-mode rejection ratios (F) the square root of the product of A1 and A2s common-mode rejection ratios (G) the size of A2s common-mode rejection ratio (H) the size of A1s common-mode rejection ratio (I) The difference in the common-mode rejection ratio of A1 and A2 themselves (J) input resistance Question Format Example 5 **Question**: The common-mode rejection ratio of the first stage amplification circuit in three-op-amp differential circuit is determined by ( ). **Options**: (A) the absolute value of the difference in the common-mode rejection ratio of A1 and themselves (B) all of the above (C) the average of A1 and A2s common-mode rejection ratios (D) the sum of A1 and A2s common-mode rejection ratios (E) the product of A1 and A2s common-mode rejection ratios (F) the square root of the product of A1 and A2s common-mode rejection ratios (G) the size of A2s common-mode rejection ratio (H) the size of A1s common-mode rejection ratio (I) The difference in the common-mode rejection ratio of A1 and A2 themselves (J) input resistance Question Format Example Question: The common-mode rejection ratio of the first stage amplification circuit in three-op-amp differential circuit is determined by ( ). Options: A: the absolute value of the difference in the common-mode rejection ratio of A1 and A2 themselves B: all of the above C: the average of A1 and A2s common-mode rejection ratios D: the sum of A1 and A2s common-mode rejection ratios E: the product of A1 and A2s common-mode rejection ratios F: the square root of the product of A1 and A2s common-mode rejection ratios G: the size of A2s common-mode rejection ratio H: the size of A1s common-mode rejection ratio I: The difference in the common-mode rejection ratio of A1 and A2 themselves J: input resistance 76 H. Textbook List for Question Source Reference Table 11. The textbooks used as reference in the paper. SCIENCE"
        },
        {
            "title": "Physical Oceanography Of Coastal And Shelf",
            "content": "Materials Science and Engineering, An"
        },
        {
            "title": "Introduction to Astronomy and Cosmology",
            "content": "Black Holes, White Dwarfs, and Neutron Stars Abstract Algebra: Theory And Applications"
        },
        {
            "title": "Essentials Of Geology",
            "content": "Atoms, Radiation, And Radiation Protection Physical Principles Of Sedimentology: Theoretical Physics Text and Exercise Books:"
        },
        {
            "title": "Readable Textbook For Beginners And Experts",
            "content": "Volume 5: Gauge Theory of Weak Interactions Textbook Of Engineering Geology Introduction To Mathematical Physics The Changing Earth: Exploring Geology And Quantum Paradoxes: Quantum Theory For The Evolution Perplexed Introduction To Ocean Circulation And Physics Of Sedimentology: Textbook And Modeling Reference Entangled Systems: New Directions In Rigid Body Mechanics: Mathematics, Physics Quantum Physics And Applications Introduction To Thermodynamics And Kinetic Ultrahigh Pressure Metamorphism: University Theory Of Matter Textbook Inverse Methods In Physical Oceanography Elements Of Physical Oceanography Nonlinear Physical Oceanography È´òÂàÜÂ≠êÂåñÂ≠¶‰∏éÁâ©ÁêÜÂ≠¶‰π†ÊåáÂØºÂèä‰π†È¢òÈõÜ Astronomy Today ÊîæÂ∞ÑÂåñÂ≠¶‰π†È¢òÊ±áÁºñ Áâ©ÁêÜÂåñÂ≠¶Â≠¶‰π†ÊåáÂØº Âü∫Á°ÄÊúâÊú∫ÂåñÂ≠¶ Áâ©ÁêÜÂåñÂ≠¶Ëß£È¢òÊÄùË∑ØÂíåÊñπÊ≥ï Á≤íÂ≠êÂ§©‰ΩìÁâ©ÁêÜ ÈöèÊú∫ËøáÁ®ãÂèäÂ∫îÁî®‰π†È¢òÈõÜ Â£∞Â≠¶‰π†È¢òÈõÜ Â§©‰ΩìÁâ©ÁêÜÊ¶ÇËÆ∫ Êó†Êú∫ÂåñÂ≠¶ ÂêâÁ±≥Â§öÁª¥Â•áÊï∞Â≠¶ÂàÜÊûê‰π†È¢òÈõÜÈ¢òËß£ ÂçäÂØº‰ΩìÁâ©ÁêÜÂ≠¶ Â≠¶‰π†È¢òÈõÜÂèäËØ¶Ëß£ ÂçäÂØº‰ΩìÁâ©ÁêÜ‰π†È¢òÂèäËß£Á≠î Â§©‰ΩìÊµãÈáèÂíåÂ§©‰ΩìÂäõÂ≠¶Âü∫Á°Ä ÁªÜËÉûÁîüÁâ©Â≠¶ Ëøë‰ª£Áâ©ÁêÜ‰π†È¢òËß£Á≠î ÁÉ≠Â≠¶‰π†È¢òÊÄùËÄÉÈ¢òËß£È¢òÊåáÂØº ÁªÜËÉûÁîüÁâ©Â≠¶ÂÆûÈ™å‰∏é‰π†È¢òÊåáÂØº ÂéüÂ≠ê(Ëøë‰ª£)Áâ©ÁêÜÂ≠¶ÁßëÂ≠¶ÂåñËÄÉËØïÁêÜËÆ∫‰∏éÂÆû Ë∑µ ÂåñÂ≠¶ ‰∏≠ÂøÉÁßëÂ≠¶ Continued ÁæéÂõΩÁâ©ÁêÜËØïÈ¢ò‰∏éËß£Á≠î Á¨¨4Âç∑ ÂéüÂ≠êÁâ©ÁêÜÂ≠¶ Ê†∏‰∏éÁ≤íÂ≠êÁâ©ÁêÜÂ≠¶ ÁæéÂõΩÁâ©ÁêÜËØïÈ¢ò‰∏éËß£Á≠î Á¨¨‰∫îÂç∑: ÁÉ≠ÂäõÂ≠¶‰∏éÁªü ËÆ°Áâ©ÁêÜÂ≠¶ Ê¶ÇÁéá‰∏éÈöèÊú∫ËøáÁ®ã‰π†È¢òÈõÜ ‰∏ã ÈöèÊú∫ËøáÁ®ã ÈöèÊú∫ËøáÁ®ã‰π†È¢òËß£Êûê Âõ∫‰ΩìÁâ©ÁêÜÂØºËÆ∫ È´òÁ≠âÂ≠¶Ê†°ÁêÜÂ∑•Á±ªËØæÁ®ãÂ≠¶‰π†ËæÖÂØº‰∏õ‰π¶ KittelÂõ∫‰ΩìÁâ©ÁêÜÂØºËÆ∫‰π†È¢òËØ¶Ëß£ Áâ©ÁêÜÂ≠¶Â§ßÈ¢òÂÖ∏ ÂéüÂ≠êÂàÜÂ≠êÁâ©ÁêÜÂ≠¶ ÂæÆÂàÜÂá†‰Ωï Êï∞ÂÄºÂàÜÊûêÂ≠¶‰π†ËæÖÂØº ‰π†È¢òËß£Êûê ÁªºÂêàÂåñÂ≠¶ ÂÖâÂ≠¶ Áé∞‰ª£ÂàÜÂ≠êÁîüÁâ©Â≠¶ Ê¶ÇÁéáËÆ∫ Áâ©ÁêÜÂåñÂ≠¶ È´òÂàÜÂ≠êÂåñÂ≠¶ Áâ©ÁêÜÂ≠¶Â§ßÈ¢òÂÖ∏ Áõ∏ÂØπËÆ∫Áâ©ÁêÜÂ≠¶ Ê∞¥Â£∞Â≠¶ÂéüÁêÜ Ê®°Á≥äÊï∞Â≠¶ÂéüÁêÜÂèäÂ∫îÁî® Âõ∫‰ΩìÁâ©ÁêÜÂ≠¶ ÁîµÁ£ÅÂ≠¶ Á¶ªÊï£Êï∞Â≠¶ÂèäÂÖ∂Â∫îÁî® Êï∞Â≠¶ÂàÜÊûêÊïôÁ®ã Êï∞ÁêÜÁªüËÆ° ÈÅó‰º†Â≠¶Â≠¶‰π†ÊåáÂØº‰∏éÈ¢òËß£ ÁîüÁâ©ÂåñÂ≠¶"
        },
        {
            "title": "ENGINEERING",
            "content": "Analytical solutions for transport processes: fluid Process Control Engineering: Textbook for mechanics, heat and mass transfer Chemical, Mechanical and Electrical Engineers Textbook of Seismic Design: Structures, Piping Simulation and Optimization of Furnaces and Systems, and Components Kilns for Nonferrous Metallurgical Engineering The Principles of Naval Architecture Series: Process Software and Digital Networks: Strength of Ships and Ocean Structures Instrument Engineers Handbook Unconventional Oil and Gas Resources: Production and Transport of Oil and Gas: Exploitation and Development Gathering and Transportation Radioactive Investigations of Oil and Gas Wells Residential Land Development Practices Radio Navigation Systems for Airports and Fundamentals of Solid-State Electronics"
        },
        {
            "title": "Airways",
            "content": "Instrument Engineers Handbook: Process"
        },
        {
            "title": "Machines",
            "content": "Fluid Mechanics for Engineers: Graduate Materials Science and Engineering: An"
        },
        {
            "title": "A Textbook on Heat Transfer",
            "content": "78 Continued"
        },
        {
            "title": "Process and Applications in Agricultural",
            "content": "Think Java: How to Think Like Computer"
        },
        {
            "title": "Fiber Optic Sensors",
            "content": "Fusion: An Introduction to the Physics and Phase Diagrams in Metallurgy: Their"
        },
        {
            "title": "Risk Analysis for Prevention of Hazardous",
            "content": "Optical Imaging and Photography: Introduction"
        },
        {
            "title": "Situations in Petroleum and Natural Gas",
            "content": "to Science and Technology of Optics, Sensors and"
        },
        {
            "title": "Fundamentals of Ship Hydrodynamics",
            "content": "Corrosion Engineering: Principles and Practice"
        },
        {
            "title": "Introductory Soil and Water Conservation",
            "content": "Prism and Lens Making: Textbook for Optical"
        },
        {
            "title": "Glassworkers",
            "content": "Alternating Current Circuits Textbook of Engineering Drawing Food Science and Technology Textbook of Food Science and Technology Examining Ecology: Exercises in Environmental Aquatic Chemistry: For Water and Wastewater Biology and Conservation Hydraulic Power Plants Treatment Applications Nuclear and Radiochemistry Physiological Ecology of Forest Production Textbook of Robotics: Basic Concepts Metallurgy Fundamentals Random Signal Analysis Mechanical Metallurgy ‰ø°ÊÅØËÆ∫‰∏éÁºñÁ†ÅÁêÜËÆ∫:ÂâëÊ°•Â§ßÂ≠¶ÁúüÈ¢òÁ≤æËß£ Ê∞¥ÂäõÂ≠¶‰π†È¢òËß£Êûê-‰∏ãÂÜå ÁÉ≠ÂäõÂ≠¶‰∏éÁªüËÆ°Áâ©ÁêÜÂ≠¶Â≠¶‰π†ÊåáÂØº Ê∞¥ÂäõÂ≠¶‰π†È¢òËß£Êûê-‰∏äÂÜå Ê∞¥ÂäõÂ≠¶Â≠¶‰π†ÊåáÂØº‰∏é‰π†È¢òËß£Á≠î ËØØÂ∑ÆÁêÜËÆ∫‰∏éÊµãÈáèÂπ≥Â∑ÆÂü∫Á°Ä‰π†È¢òÈõÜ ÂÖâÁîµÂ§ßÂú∞ÊµãÈáè‰ª™Âô®Â≠¶ ‰π†È¢òÂÆûÈ™åÊ£ÄÊµã ÂåñÂ∑•ÂéüÁêÜ ÊµÅ‰ΩìÊµÅÂä®‰∏é‰º†ÁÉ≠ÂàÜÂÜåÂ≠¶‰π†ÊåáÂØº Áª¥‰øÆÂèäÊìç‰ΩúÈÉ®ÂàÜ ÁîµÂ≠êÁ∫øË∑Ø‰π†È¢òÈõÜ ÁîµÂ≠êÊäÄÊúØÂü∫Á°ÄÊ®°ÊãüÈÉ®ÂàÜÁ¨¨ÂÖ≠Áâà Â≠¶‰π†ËæÖÂØº‰∏é ‰π†È¢òËß£Á≠î ÁêÜËÆ∫ÂäõÂ≠¶‰π†È¢òÈõÜ Â∑•Á®ãÊµãÈáè‰π†È¢òÈõÜ Êó†Á∫øÁîµÈÄö‰ø°Á≥ªÁªü ÁêÜËÆ∫‰æãÈ¢ò‰π†È¢ò ÊµÅ‰ΩìÂäõÂ≠¶ÁêÜËÆ∫‰æãÈ¢ò‰∏é‰π†È¢ò ‰∫§ÈÄöËøêËæìÂ∑•Á®ãÂ≠¶ ‰∫§ÈÄöÂ∑•Á®ãÂ≠¶Âü∫Á°Ä ‰π¶ ÁîµÂ≠êÊäÄÊúØÂü∫Á°Ä‰π†È¢òÈõÜÂèäËß£Á≠î ÁîµÂ≠êÁîµË∑Ø‰∏éÁ≥ªÁªüÂü∫Á°Ä(Ê∏ÖÂçéÂ§ßÂ≠¶ÁîµÂ≠êÂ∑•Á®ãÁ≥ª Ê†∏ÂøÉËØæÁ≥ªÂàóÊïôÊùê) ÂåñÂ∑•ÊµÅ‰ΩìÊµÅÂä®Âíå‰º†ÁÉ≠ Â∑•Á®ãÁÉ≠ÂäõÂ≠¶‰π†È¢òËß£Á≠î ÁîµÂäõÁîµÂ≠êÊäÄÊúØÂ≠¶‰π†ÊåáÂØº‰π†È¢òÈõÜÂèä‰ªøÁúü ‰º†ÁÉ≠Â≠¶Á¨¨‰∫îÁâà ‰∫§ÈÄöÂ∑•Á®ãÂ≠¶ËÆ°ÁÆóÁ§∫‰æã È´òÁîµÂéãÁªùÁºòÊäÄÊúØ 79 Continued ÂÖâÁîµÊäÄÊúØ ÈõÜÊàêÁîµË∑ØËÆæËÆ°Âü∫Á°Ä ÂúüÂäõÂ≠¶ÂèäÂü∫Á°ÄÂ∑•Á®ãÂ≠¶‰π†ËæÖÂØº‰∏é‰π†È¢òÁ≤æËß£ ÁîµÂåñÂ≠¶ÂéüÁêÜ ÂúüÂäõÂ≠¶Â≠¶‰π†ÊåáÂØº‰∏éËÄÉÈ¢òÁ≤æËß£ ÂÖâÁ∫§ÈÄö‰ø°Á≥ªÁªüÂ≠¶‰π†ÊåáÂØº‰∏é‰π†È¢òËß£Êûê Â§©Á∫øÂéüÁêÜ‰π†È¢òÈõÜ Âõ∫ÊÄÅÁîµÂ≠êËÆ∫ Áâ©ÁêÜÂ••ÊûóÂåπÂÖãÁ´ûËµõÂ§ßÈ¢òÂÖ∏(ÁîµÁ£ÅÂ≠¶Âç∑) ËøêÁ≠πÂ≠¶‰π†È¢òÈõÜ Á¨¨5Áâà ÂÜú‰∏öÁªèÊµéÁÆ°ÁêÜ ÂÖâÁ∫§ÈÄö‰ø°Á≥ªÁªü Ê®°ÊãüÁîµË∑ØÂèäÂÖ∂Â∫îÁî® ÁîµÁ£ÅÂ≠¶ÂçÉÈ¢òËß£ Ëê•ÂÖª‰∏éÈ£üÂìÅÂç´ÁîüÂ≠¶Â≠¶‰π†ÊåáÂØºÂèä‰π†È¢òÈõÜ ÁîµÁ£ÅÂ≠¶Á¨¨‰∫åÁâà‰π†È¢òÂàÜÊûê‰∏éËß£Á≠î ÂÖ¨Ë∑ØÂ∑•Á®ãÁÆ°ÁêÜ‰∏éÂÆûÂä°ÂëΩÈ¢òÁÇπÂÖ®Èù¢Ëß£ËØª ÂüéÂ∏ÇËßÑÂàí‰∏éËÆæËÆ° Áüø‰∏öÂ∑•Á®ãÁÆ°ÁêÜ‰∏éÂÆûÂä°Â§ç‰π†È¢òÈõÜ Ê®°ÂºèËØÜÂà´ ËÆ°ÁÆóÊú∫Êìç‰ΩúÁ≥ªÁªüÂ≠¶‰π†ÊåáÂØº‰∏éÈ¢òËß£ Â≤©ÂúüÂ∑•Á®ãÊï∞ÂÄºËÆ°ÁÆó Â∑•Á®ãÊùêÊñôÂ≠¶ ÊùêÊñôÂõ∫‰ΩìÂäõÂ≠¶ ÂåñÂ≠¶ÂèçÂ∫îÂ∑•Á®ãÂéüÁêÜ‰æãÈ¢ò‰∏é‰π†È¢ò ËΩ¶ËæÜÂ∑•Á®ãËÄÉÁ†îÈ¢ò Á©∫Ê∞îÂä®ÂäõÂ≠¶Âü∫Á°Ä ÁªüËÆ°ÂäõÂ≠¶ ÂÜú‰∏öÊ∞¥ÂúüÂ∑•Á®ãÂøÖ‰ºö100È¢ò Âà∂ÂÜ∑‰∏é‰ΩéÊ∏©ÂéüÁêÜ Â∑•Á®ãÊùêÊñô ÊµÅ‰ΩìÂäõÂ≠¶‰π†È¢òÈõÜ Â∑•Á®ãÁÉ≠ÂäõÂ≠¶Â≠¶‰π†ËæÖÂØº‰∏é‰π†È¢òËß£Á≠î ÁîµÂäõÁîµÂ≠êÊäÄÊúØ‰π†È¢òËß£Á≠îÂÆûÈ™å‰∏éËØæÁ®ãËÆæËÆ° 2000Â∑•Á®ãÁÉ≠ÂäõÂ≠¶‰π†È¢òÁ≤æËß£ Áâ©ÁêÜÂ≠¶Â§ßÈ¢òÂÖ∏ ÁÉ≠Â≠¶ ÁÉ≠ÂäõÂ≠¶ ÁªüËÆ°Áâ©ÁêÜ ÊåáÂØº Áâ©ÁêÜÂ≠¶Â§ßÈ¢òÂÖ∏ ÈáèÂ≠êÂäõÂ≠¶ Â§ßÂú∞ÊµãÈáèÂ≠¶Âü∫Á°Ä ËàπËà∂Ë¥ßËøê‰π†È¢òÈõÜ Á¨¨2Áâà ËΩÆÊú∫Â∑•Á®ãÂü∫Á°Ä ËàπËà∂ÁªìÊûÑÂäõÂ≠¶‰π†È¢òÈõÜ Ê†∏ÊäÄÊúØÂ∫îÁî®ËæêÂ∞ÑÂÆâÂÖ®‰∏éÈò≤Êä§ ÊùêÊñôÁßëÂ≠¶Âü∫Á°ÄËæÖÂØº‰∏é‰π†È¢ò ÁªìÊûÑÂäõÂ≠¶Â≠¶‰π†ÊåáÂØº‰∏éÂÖ∏Âûã‰æãÈ¢òËß£Êûê ÂÜÖÁáÉÊú∫ÂéüÁêÜ‰π†È¢òÈõÜ ÂåñÂ∑•Á≥ªÁªüÂ∑•Á®ã È´òÁîµÂéãÊäÄÊúØ ÊüìÊñôÂåñÂ≠¶ Áé∞‰ª£ÊéßÂà∂Â∑•Á®ã Â∫îÁî®Ê®°Á≥äÊï∞Â≠¶ ÁîµÂåñÂ≠¶ÊñπÊ≥ïÂéüÁêÜÂíåÂ∫îÁî® ÁîµÂäõÁ≥ªÁªüÂàÜÊûê‰∏≠ÁöÑËÆ°ÁÆóÊñπÊ≥ï ÁªìÊûÑÂäõÂ≠¶ÊïôÁ®ã ‰∫§ÈÄöËøêËæìÂ∑•Á®ãÂØºËÆ∫ Ëá™Âä®ÊéßÂà∂ÁêÜËÆ∫‰∏éËÆæËÆ° ‰ø°Âè∑‰∏éÁ≥ªÁªü ÊùêÊñôÂäõÂ≠¶ ÁîµÂä®ÂäõÂ≠¶ Êú∫Ê¢∞ËÆæËÆ°Âü∫Á°Ä ÊùêÊñôÁßëÂ≠¶Âü∫Á°Ä Ê†∏ÂèçÂ∫îÂ†ÜÁâ©ÁêÜÂàÜÊûê ÁîµË∑ØÂü∫Á°Ä Êï∞Â≠ó‰ø°Âè∑Â§ÑÁêÜ ÂåñÂ∑•ÂéüÁêÜ ÁÉ≠ÂäõÂ≠¶‰∏éÁªüËÆ°Áâ©ÁêÜÂ≠¶ ÁîµÂäõÁ≥ªÁªüÂàÜÊûê ÁîµÂäõÁ≥ªÁªüËÆæÂ§á‰∏éÊé•Á∫ø ËøáÁ®ãÊéßÂà∂Á≥ªÁªü‰∏é‰ª™Ë°® Continued MEDICINE Textbook Of Clinical Pharmacy Practice: Drugs For The Heart: Textbook With Online"
        },
        {
            "title": "Updates",
            "content": "Pharmaceutical Analysis: Textbook For Textbook Of Hepatology: From Basic Science To"
        },
        {
            "title": "Pharmacy Students And Pharmaceutical",
            "content": "Clinical Practice, 2 Volume In One File, 3Rd Ed"
        },
        {
            "title": "Two Volumes In One File",
            "content": "Goodman And Gilmans Manual Of Pharmaceutical Chemistry: Drugs And Their"
        },
        {
            "title": "Biological Targets",
            "content": "Textbook Of Drug Design And Discovery, Third The Pancreas : An Integrated Textbook Of Basic"
        },
        {
            "title": "Edition",
            "content": "Science, Medicine, And Surgery The Esc Textbook Of Cardiovascular Medicine Public Health Medicine For The Tropics Medical Entomology: Textbook On Public Textbook Of Clinical Occupational And Health And Veterinary Problems Caused By Environmental Medicine Arthropods General Practice and Ethics: Uncertainty and Responsibility ÂåªÂ≠¶Â∫îËØïÈ¢òÂ∫ì‰∏õ‰π¶ Â¶á‰∫ßÁßëÂ≠¶ ÊîæÂ∞ÑÂåªÂ≠¶ ÁîüÁêÜÂ≠¶ ÁóÖÁêÜÂ≠¶ Âç´ÁîüÁªüËÆ°Â≠¶ ÊØíÁêÜÂ≠¶Âü∫Á°Ä Ê≥ïÂåªÂ≠¶ ÁúºÁßëÂ≠¶ ÂåªÂ≠¶Áü•ËØÜËÆ∞ÂøÜ‰∏éËÄÉËØï‰∏ÄÁÇπÈÄö ÁóÖÁêÜÂ≠¶ ËøêÂä®ÁîüÁêÜÂ≠¶ ÁîüÁâ©ÂåñÂ≠¶ ÂÜÖÁßëÂ≠¶ ÊµÅË°åÁóÖÂ≠¶ ÂåªÂ≠¶ÂÖçÁñ´Â≠¶‰π†È¢òÈõÜ Â§ñÁßëÂ≠¶ ‰∏¥Â∫äÊ£ÄÈ™åÂü∫Á°Ä ÊµÅË°åÁóÖÂ≠¶Â≠¶‰π†ÊåáÂØº‰∏é‰π†È¢òÈõÜ ÁéØÂ¢ÉÂç´ÁîüÂ≠¶‰π†È¢òÈõÜ ËçØÁâ©ÂåñÂ≠¶ ËçØÁâ©ÂåñÂ≠¶Â≠¶‰π†ÊåáÂØº‰∏é‰π†È¢òÈõÜ ÂÜÖÁßë‰∏ªÊ≤ªÂåªÂ∏àËµÑÊ†ºËÄÉËØï‰π†È¢òÁ≤æÈÄâÈõÜ È¢ÑÈò≤ÂåªÂ≠¶‰π†È¢òÁ≤æÈÄâ ÂÖ®ÁßëÂåªÂ≠¶‰π†È¢òÈõÜ ËçØÂâÇÂ≠¶Â≠¶‰π†ÊåáÂØº‰∏é‰π†È¢òÈõÜ ÁöÆËÇ§ÊÄßÁóÖÂ≠¶‰π†È¢òÈõÜ ‰∏¥Â∫äÂåªÂ≠¶Â∫îËØï‰π†È¢òÈõÜ Ê£ÄÈ™åÂåªÂ≠¶‰π†È¢òÈõÜ Â§ñÁßëÂ≠¶‰π†È¢òÈõÜ ÁúºÁßëÂ≠¶‰π†È¢òÈõÜ ÂÖçÁñ´Â≠¶‰∏éÁóÖÂéüÁîüÁâ©Â≠¶‰π†È¢òÈõÜ ÂÑøÁ´•Â∞ëÂπ¥Âç´ÁîüÂ≠¶Â≠¶‰π†ÊåáÂØº‰∏é‰π†È¢òÈõÜ ËçØÁêÜÂ≠¶Â∫îËØï‰π†È¢òÈõÜ ÂÖçÁñ´Â≠¶Âü∫Á°Ä‰∏éÁóÖÂéüÁîüÁâ©Â≠¶‰π†È¢òÈõÜ ‰∏≠ÂåªÂü∫Á°ÄÁêÜËÆ∫ Continued Âè£ËÖîÂÜÖÁßëÂ≠¶ ËçØÂâÇÂ≠¶ ‰∏≠ÂåªÂü∫Á°ÄÁêÜËÆ∫‰π†È¢òÈõÜ ‰∏≠ËçØÂ≠¶ Á•ûÁªèÁóÖÂ≠¶ ËçØÁêÜÂ≠¶ ËçØÁâ©ÂàÜÊûê LITERATURE & ARTS Radio as Art: Concepts, Spaces, Practices"
        },
        {
            "title": "The Practice of Public Art",
            "content": "Qupai in Chinese Music: Melodic Models in Fundamentals, Function, And Form Theory And"
        },
        {
            "title": "Examples of Chinese Ornament",
            "content": "Japanese Postpositions: Theory and Practice"
        },
        {
            "title": "The Ultimate French Review and Practice",
            "content": "Jazz Composition: Theory and Practice ÊñáÁåÆÂ≠¶Ê¶ÇË¶Å Harmony in Practice: Answer Book Ë•øÊñπÈü≥‰πêÂè≤ ‰º†Êí≠Â≠¶ÂéüÁêÜÁ¨¨‰∏âÁâà Ë∑®ÊñáÂåñ‰∫§ÈôÖ ÊñáÂ≠¶ÁêÜËÆ∫ ‰∏≠ÂõΩÁé∞‰ª£ÊñáÂ≠¶‰∏âÂçÅÂπ¥ Ëâ∫ÊúØÊ¶ÇËÆ∫ ÈùûÊñáÂ≠¶ÁøªËØëÁêÜËÆ∫‰∏éÂÆûË∑µ ‰∏≠ÂõΩÊñáÂ≠¶ÁêÜËÆ∫ÊâπËØÑÂè≤ Â§ñÂõΩÊñáÂ≠¶Âè≤ ‰∏≠Â§ñÊàèÂâßÂè≤ ÁøªËØëËÆ∫ÈõÜ ÂÜúÂ≠¶Ê¶ÇËÆ∫ Ê§çÁâ©ÁîüÁêÜÂ≠¶ Ê§çÁâ©Áîü‰∫ßÂ≠¶"
        },
        {
            "title": "AGRONOMY",
            "content": "Ê£ÆÊûóÂüπËÇ≤Â≠¶ ÁîüÊÄÅÂ≠¶ Ê§çÁâ©Â≠¶ ÁªèÊµéÊûóÊ†ΩÂüπÂ≠¶ÊÄªËÆ∫ Âõ≠ÊûóÊ†ëÊú®Ê†ΩÂüπÂ≠¶ Ê£ÆÊûóÊòÜËô´Â≠¶ ÂúüÂ£§Â≠¶ Ê∞¥‰∫ßÂÖªÊÆñÂ∑•Á®ãÂ≠¶ Ëî¨ËèúÂüπÂÖªÂ≠¶ÊÄªËÆ∫ ÂÖΩÂåªÂ≠¶Ê¶ÇËÆ∫ Ê£ÆÊûóÁªèÁêÜÂ≠¶ Ê§çÁâ©ËµÑÊ∫êÂ≠¶ Ê∞¥‰∫ßÂÖªÊÆñÂ≠¶ ÂÖΩÂåªÁóÖÁêÜÁîüÁêÜ ‰ΩúÁâ©Â≠¶"
        },
        {
            "title": "Legal Issues in Social Work Practice and",
            "content": "Natural Law in Court: History of Legal"
        },
        {
            "title": "Theory in Practice",
            "content": "Legal Feminisms: Theory and Practice Law, Practice and Procedure of Arbitration"
        },
        {
            "title": "The Law and Practice of the International",
            "content": "Chinese Insurance Contracts: Law and Practice Continued"
        },
        {
            "title": "Criminal Court",
            "content": "Litigation and Trial Practice Ê≥ïÁêÜÂ≠¶ Ê≥ïÁêÜÂ≠¶ ÂÖ®ÁêÉËßÜÈáé ÂÆ™Ê≥ïÂ≠¶ Ê∞ëÊ≥ïÂ≠¶ ÁªèÊµéÊ≥ïÂ≠¶ ÂõΩÈôÖÈáëËûçÊ≥ï Discrimination Law and Practice Ê≥ïÂ≠¶ÂØºËÆ∫ Ê≥ïÂæãÁöÑÊ¶ÇÂøµ ÂÆ™Ê≥ïÂ≠¶ÂéüÁêÜ ÂõΩÈôÖÊ≥ï ÂõΩÈôÖÁßÅÊ≥ï ÂõΩÈôÖË¥∏ÊòìÊ≥ï Back to Section Start Back to Table of Contents 83 I. Benchmarks for Data Expansion Table 12. Benchmark List for Data Supplementation in SuperGPQA Annotation. Benchmark Name Title Year LawBench LawBench: Benchmarking Legal Knowledge of Large 2023 Language Models Fei et al. [2023] MedMCQA MedMCQA: Large-scale Multi-Subject Multi-Choice 2022 Dataset for Medical domain Question Answering Pal et al. [2022] MedQA What Disease does this Patient Have? Large-scale 2020 Open Domain Question Answering Dataset from Medical Exams Jin et al. [2020] MMLU-Pro MMLU-Pro: More Robust and Challenging MultiTask Language Understanding Benchmark Wang et al. [2024b] MMLU-CF MMLU-CF: Contamination-free Multi-task Lan2024 guage Understanding Benchmark Zhao et al. [2024] ShoppingMMLU Shopping MMLU: Massive Multi-Task Online Shop2024 ping Benchmark for Large Language Models Jin et al. [2024] UTMath UTMath: Math Evaluation with Unit Test via 2024 Reasoning-to-Coding Thoughts Yang et al. [2024b] MusicTheoryBench ChatMusician: Understanding and Generating Music Intrinsically with LLM Yuan et al. [2024] Omni-Math Omni-MATH: Universal Olympiad Level Mathe2024 matic Benchmark For Large Language Models Gao et al. [2024] U-MATH U-MATH: University-Level Benchmark for Evalu2024 ating Mathematical Skills in LLMs Chernyshev et al. [2024] Putnam-AXIOM Putnam-AXIOM: Functional and Static Benchmark 2024 for Measuring Higher Level Mathematical Reasoning Fronsdal et al. [2024] Short-form Factuality Measuring short-form factuality in large language 2024 models Wei et al. [2024b] Chinese SimpleQA Chinese SimpleQA: Chinese Factuality Evaluation for Large Language Models He et al. [2024b] AIME-AOPS AIME Problems and Solutions of Problem Solving 2024 [2024] AIMO Validation AIME AIMO Validation AIME: Internal Validation Set for 2024 AIMO Progress Prize AI-MO [2024]"
        },
        {
            "title": "Back to Section Start",
            "content": "Back to Table of Contents J. More Comprehensive Analysis of Baseline Performances In addition to the models discussed in the subsection 4.2, Table 13 and Table 14 provide more comprehensive analysis of baseline performances, including evaluations of models from the Yi-1.5 (6B, 9B), OLMo-2 (7B), Mistral (Small), granite-3.1 (2B), gemma-2 (2b, 9b), Llama-3.1 (8B), Mixtral (8x7B), and K2 [Liu et al., 2025]. 85 Model Overall (sample) Overall (subfield) Overall (field) Overall (discipline) Easy (sample) Middle (sample) Hard (sample) DeepSeek-R1 o1-2024-12-17 DeepSeek-R1-Zero o3-mini-2025-01-31-high o3-mini-2025-01-31-medium o3-mini-2025-01-31-low o1-mini-2024-09-12 QwQ Doubao-1.5-pro-32k-250115 Doubao-1.5-pro-32k-241225 qwen-max-2025-01-25 claude-3-5-sonnet-20241022 gemini-2.0-flash DeepSeek-V3 MiniMax-Text-01 gpt-4o-2024-11-20 Llama-3.1-405B-Instruct gpt-4o-2024-08-06 Qwen2.5-72B-Instruct Mistral-Large-Instruct-2411 qwen-max-2024-09-19 gpt-4o-2024-05-13 Qwen2.5-32B-Instruct Llama-3.3-70B-Instruct phi-4 Qwen2.5-14B-Instruct Llama-3.1-70B-Instruct Yi-Lightning Mixtral-8x22B-Instruct-v0.1 Qwen2.5-7B-Instruct gemma-2-27b-it Yi-1.5-34B-Chat Mistral-Small-Instruct-2409 gemma-2-9b-it Qwen2.5-3B-Instruct Yi-1.5-9B-Chat K2-Chat Mixtral-8x7B-Instruct-v0.1 granite-3.1-8b-instruct Llama-3.1-8B-Instruct Yi-1.5-6B-Chat Qwen2.5-1.5B-Instruct OLMo-2-1124-13B-Instruct gemma-2-2b-it granite-3.1-2b-instruct Mistral-7B-Instruct-v0.3 MAP-Neo-7B-Instruct-v0.1 OLMo-2-1124-7B-Instruct Qwen2.5-0.5B-Instruct Qwen2.5-72B Qwen2.5-32B DeepSeek-V3-Base Qwen2.5-14B Yi-1.5-34B Llama-3.1-70B Qwen2.5-7B Llama-3.1-405B gemma-2-27b Yi-1.5-9B gemma-2-9b Mixtral-8x22B-v0.1 Mixtral-8x7B-v0.1 K2 Yi-1.5-6B Qwen2.5-3B Llama-3.1-8B Mistral-7B-v0.3 Qwen2.5-1.5B granite-3.1-2b-base OLMo-2-1124-13B MAP-Neo-7B granite-3.1-8b-base OLMo-2-1124-7B gemma-2-2b Qwen2.5-0.5B 61.82 60.24 60.24 55.22 52.69 48.03 45.22 43.59 55.09 50.93 50.08 48.16 47.73 47.40 45.11 44.40 43.14 41.64 40.75 40.65 39.96 39.76 38.76 37.69 37.65 35.15 34.86 33.42 29.23 28.78 27.43 26.03 25.89 24.04 23.31 23.17 22.47 22.10 20.83 20.50 19.24 18.82 18.66 18.61 17.92 17.82 17.05 16.81 10.77 34.33 33.16 32.14 30.19 27.62 27.22 25.36 25.23 24.49 23.10 22.56 22.41 21.76 20.92 20.20 20.14 19.93 19.48 17.17 16.18 16.07 15.76 15.69 15.15 13.57 10.74 Reasoning Models 61.23 59.94 60.95 52.11 49.95 45.89 42.53 43.19 Chat Models 55.62 51.76 52.47 51.23 47.80 48.31 46.97 47.50 45.83 44.91 43.32 43.13 42.16 43.13 40.40 40.15 38.61 37.41 39.18 36.45 32.28 30.37 30.42 28.84 28.69 27.06 25.86 25.65 24.61 24.73 22.92 24.52 21.39 20.75 20.60 19.97 19.11 19.65 18.42 18.57 12.47 Base Models 38.70 37.33 34.58 34.14 31.03 31.28 28.73 28.33 27.96 25.69 25.47 25.04 25.45 23.88 22.56 23.30 22.77 21.81 19.80 17.91 19.82 18.26 16.79 18.30 15.43 12.09 59.95 59.44 60.99 48.32 46.07 42.63 39.33 41.63 54.39 51.24 51.65 53.15 46.10 47.35 47.06 48.84 47.35 46.29 42.10 43.37 41.62 45.23 39.43 41.12 37.66 36.07 40.57 36.92 32.82 30.63 31.30 29.08 28.59 27.74 25.57 26.07 24.61 26.36 22.26 26.12 22.21 22.11 21.80 20.50 19.58 20.09 18.70 18.85 13.47 39.54 38.29 34.71 34.54 32.55 32.55 29.60 30.15 28.58 26.17 26.26 25.02 27.36 24.65 23.44 24.42 23.87 22.27 21.35 18.09 21.37 19.54 16.65 19.60 16.21 13. 62.61 61.25 61.62 54.94 52.66 48.51 45.46 44.40 56.55 52.41 52.75 51.38 48.70 49.10 47.46 47.62 46.43 44.79 43.66 43.38 42.93 43.19 41.18 40.56 39.59 37.72 38.94 36.57 32.14 30.78 30.50 28.81 28.46 26.89 25.45 25.32 24.59 24.76 22.85 24.07 21.32 20.91 20.46 19.91 19.02 19.64 18.52 18.08 11.92 38.08 36.52 34.79 33.33 30.78 30.52 28.19 28.09 27.35 25.40 25.19 24.71 24.92 23.62 22.10 22.81 22.42 21.50 19.31 17.90 18.75 17.48 16.98 17.62 14.98 11.88 63.59 64.40 65.06 53.05 51.30 48.80 46.77 46.46 57.70 53.54 58.16 59.04 53.06 55.63 54.51 56.84 56.06 55.22 48.84 52.92 50.23 53.37 47.42 49.68 45.43 44.82 48.22 43.38 42.52 37.77 40.90 36.99 37.93 37.81 33.10 32.75 30.58 34.19 29.48 32.82 27.90 27.41 27.10 26.40 23.94 26.37 23.26 22.80 14.90 46.20 45.12 41.28 42.27 39.68 40.78 36.58 37.58 36.26 32.52 33.88 32.78 33.66 30.97 28.37 30.42 30.33 27.62 24.52 23.13 27.24 22.86 20.40 24.43 19.12 14. 63.63 61.44 62.61 56.09 53.79 50.21 47.34 47.40 60.15 56.56 54.95 51.91 49.56 50.11 48.60 48.75 46.31 45.11 45.42 43.28 43.63 42.38 43.05 40.68 40.91 37.90 37.85 35.32 29.73 30.98 27.45 26.74 25.89 23.05 23.50 24.05 21.95 20.52 19.79 20.37 18.83 18.19 17.85 16.95 17.58 16.64 16.62 15.82 10.88 38.12 36.58 34.50 31.44 27.95 26.95 25.94 25.12 24.07 22.98 21.34 21.67 20.32 20.01 19.64 19.81 18.94 18.65 16.79 14.91 14.41 14.64 15.65 13.83 13.47 10.78 56.87 53.67 50.99 56.16 52.37 43.53 40.00 34.07 43.80 38.70 33.09 29.99 38.84 33.86 28.98 23.50 23.70 20.98 24.10 22.81 22.60 20.45 22.13 19.55 23.69 19.97 15.22 19.35 13.82 15.23 12.64 12.81 12.70 10.60 12.24 11.19 14.44 11.49 13.09 7.22 10.44 10.45 10.74 12.85 11.87 10.41 10.95 11.90 6.07 15.01 14.34 18.20 14.85 13.86 12.78 12.10 11.86 12.27 12.96 12.20 12.26 11.13 11.40 12.20 9.40 10.16 11.96 9.74 10.67 6.57 9.83 10.60 7.15 7.63 6. Table 13. Detailed Performance Overview on SuperGPQAPivot Table 1. LLMs are scored sample-wise, subfield-wise, field-wise, and discipline-wise levels to ensure fair assessment despite imbalanced question counts. The columns Easy(sample), Middle(sample), and Hard(sample) represent average scores according to difficulty. The highest score in each column is indicated with ùëèùëúùë• ; the second-best score is in bold, and the third-best score is underlined. 86 Model Agr. Econ. Edu. Eng. Hist. Law Lit & Arts Mgt. Med. Mil Sci. Phil. Sci. Soc. DeepSeek-R1 54.43 DeepSeek-R1-Zero 53.81 o1-2024-12-17 50.93 41.03 o3-mini-2025-01-31-high o3-mini-2025-01-31-medium 40.62 37.32 o3-mini-2025-01-31-low 34.02 o1-mini-2024-09-12 38.14 QwQ Doubao-1.5-pro-32k-250115 Doubao-1.5-pro-32k-241225 claude-3-5-sonnet-20241022 qwen-max-2025-01-25 Llama-3.1-405B-Instruct gpt-4o-2024-11-20 gpt-4o-2024-05-13 DeepSeek-V3 Qwen2.5-72B-Instruct MiniMax-Text-01 gpt-4o-2024-08-06 Mistral-Large-Instruct-2411 gemini-2.0-flash Llama-3.1-70B-Instruct Llama-3.3-70B-Instruct qwen-max-2024-09-19 Qwen2.5-32B-Instruct Qwen2.5-14B-Instruct Yi-Lighting phi-4 gemma-2-27b-it Qwen2.5-7B-Instruct Mistral-Small-Instruct-2409 Yi-1.5-34B-Chat Mixtral-8x22B-Instruct-v0.1 Mixtral-8x7B-Instruct-v0.1 gemma-2-9b-it Qwen2.5-3B-Instruct granite-3.1-8b-instruct Llama-3.1-8B-Instruct gemma-2-2b-it Yi-1.5-9B-Chat K2-Chat Qwen2.5-1.5B-Instruct OLMo-2-1124-13B-Instruct OLMo-2-1124-7B-Instruct Yi-1.5-6B-Chat Mistral-7B-Instruct-v0.3 granite-3.1-2b-instruct MAP-Neo-7B-Instruct-v0.1 Qwen2.5-0.5B-Instruct Qwen2.5-32B Qwen2.5-72B Qwen2.5-14B Llama-3.1-405B Llama-3.1-70B gemma-2-27b DeepSeek-V3-Base Qwen2.5-7B Yi-1.5-34B Mixtral-8x7B-v0.1 gemma-2-9b Mistral-7B-v0.3 Yi-1.5-9B Mixtral-8x22B-v0.1 Llama-3.1-8B K2 Qwen2.5-3B Yi-1.5-6B MAP-Neo-7B OLMo-2-1124-13B Qwen2.5-1.5B granite-3.1-2b-base OLMo-2-1124-7B gemma-2-2b granite-3.1-8b-base Qwen2.5-0.5B 50.93 47.42 47.01 44.33 43.09 42.27 41.44 41.24 41.24 39.79 39.59 38.76 38.56 37.11 36.70 36.49 36.49 36.08 33.81 32.78 31.13 29.28 28.87 28.87 28.25 27.22 27.01 25.36 24.74 24.74 24.33 24.12 22.68 22.27 20.82 20.82 20.41 20.00 18.14 17.94 16. 38.76 36.29 34.02 29.28 28.87 28.87 28.66 28.25 28.25 28.04 27.22 25.98 25.77 23.92 23.30 22.68 22.47 22.06 20.21 19.59 19.18 18.76 18.35 18.35 15.46 15.05 66.09 66.44 61.17 54.07 51.32 45.25 45.02 47.77 65.06 60.14 56.59 57.50 49.71 46.74 40.78 49.48 46.62 49.60 40.78 42.27 45.93 41.12 40.55 45.02 43.07 37.69 39.18 40.21 29.32 34.59 26.23 31.27 33.45 24.51 27.15 26.35 20.16 24.40 21.31 29.90 23.37 22.57 22.68 14.66 23.83 17.75 19.93 17.64 16.49 40.89 44.33 34.82 27.95 29.67 27.26 35.17 31.96 35.85 24.97 26.23 20.96 26.12 23.94 22.22 20.62 23.83 25.89 18.10 20.27 20.73 18.33 17.30 16.15 17.87 12.37 54.75 60.54 53.31 46.28 41.74 38.43 36.16 45.25 55.58 54.75 53.72 56.40 45.45 50.00 44.21 43.80 44.42 47.52 44.42 42.15 42.36 41.94 40.29 45.66 45.45 39.26 35.95 39.26 30.99 35.33 26.86 30.99 33.68 28.31 32.64 30.99 23.76 29.55 19.42 30.99 27.27 27.27 25.21 20.25 25.62 18.18 19.83 21.69 17. 45.87 45.25 40.08 31.20 36.36 30.79 39.05 38.02 37.60 29.34 30.99 25.62 34.71 27.27 25.00 28.93 28.31 27.07 23.35 26.24 28.10 23.55 25.00 19.21 15.08 16.32 Reasoning Models 55.19 58.61 60.98 36.80 35.01 32.94 26.26 29.53 65.24 66.77 63.87 45.73 43.60 39.79 35.98 45.88 Chat Models 42.88 37.54 53.56 44.81 50.00 52.52 50.74 47.18 30.71 45.25 50.89 44.96 45.25 33.09 41.25 35.16 30.71 26.41 36.05 30.27 24.78 22.85 25.96 23.00 30.86 25.37 22.26 18.55 16.32 20.03 17.06 16.91 16.02 16.47 16.91 16.32 13.95 15.88 16.77 13.50 10. 58.84 54.12 60.21 54.12 55.34 53.81 52.90 51.07 45.88 54.27 54.12 47.87 49.24 45.88 44.66 44.05 41.92 37.04 37.35 41.46 35.06 32.62 30.95 34.45 34.60 30.79 28.51 25.61 24.70 26.68 21.80 28.20 30.49 26.37 22.10 18.45 25.61 21.19 23.02 21.19 13.87 Base Models 28.49 31.31 28.49 34.12 32.94 22.85 30.12 22.55 24.63 23.89 21.81 14.84 18.69 20.33 20.92 17.80 18.40 14.99 15.28 19.73 15.43 13.80 19.14 11.72 11.72 11.42 39.94 44.21 36.89 34.30 33.38 28.96 37.20 30.34 34.45 30.79 26.83 24.24 25.15 27.59 26.98 28.35 26.37 25.46 21.34 22.41 21.95 19.21 19.36 19.21 18.29 12.96 52.45 56.86 55.79 39.44 37.11 36.22 32.22 32.82 42.30 38.31 50.42 44.93 43.20 46.72 45.11 45.23 34.90 43.02 46.30 41.11 43.68 35.08 38.54 39.08 32.76 31.44 36.34 31.62 29.42 24.28 27.57 27.15 30.55 26.85 27.45 22.32 20.53 20.94 19.21 20.70 23.39 17.84 19.57 18.08 18.79 21.12 19.03 16.35 12. 30.91 35.50 28.94 30.79 32.64 27.51 33.65 25.06 30.25 27.27 23.81 20.11 23.21 24.64 21.48 24.40 21.60 21.36 18.79 20.88 17.72 16.41 17.36 15.75 13.84 14.92 63.10 60.28 59.17 56.41 53.83 48.20 45.41 43.37 55.60 50.76 47.57 50.81 41.89 42.83 37.47 47.21 41.12 44.88 38.84 39.66 48.37 33.88 36.44 39.84 38.93 35.87 32.53 37.27 26.72 28.38 25.25 25.67 29.02 21.16 23.24 22.83 21.60 19.07 18.30 23.04 23.10 17.64 18.18 16.52 18.50 17.28 17.64 16.79 9.77 32.70 33.39 30.26 23.61 26.19 24.09 31.87 24.89 27.32 20.67 21.79 19.02 23.59 22.02 19.56 20.50 19.74 19.93 15.43 15.21 16.50 16.37 14.88 12.82 16.26 10.30 57.09 59.68 57.29 51.50 48.50 43.71 40.52 41.32 53.29 52.69 51.30 54.69 47.70 47.31 41.32 48.50 42.32 48.90 45.51 43.31 41.32 46.11 45.51 45.11 39.52 41.52 38.12 39.12 34.93 33.33 30.54 31.54 35.13 26.15 32.14 30.94 25.15 34.13 21.56 31.94 28.74 24.95 21.96 22.95 24.15 23.55 23.15 20.96 15. 40.72 43.51 40.32 34.13 36.73 32.73 37.33 28.54 36.13 30.74 28.94 23.55 30.54 30.14 25.95 27.74 28.14 26.75 21.76 26.15 23.35 18.96 20.76 18.36 14.57 11.78 59.93 60.65 62.25 51.72 50.34 48.09 44.32 43.88 59.13 54.99 49.26 56.37 49.04 52.52 48.82 46.10 45.74 47.08 50.49 43.23 43.77 44.21 43.77 43.41 42.21 36.91 36.95 37.79 31.00 32.60 28.53 29.73 30.53 26.13 27.44 26.82 20.58 30.20 19.27 25.74 23.99 22.58 21.81 17.82 21.89 20.04 17.46 18.91 14.12 38.84 43.12 34.37 29.47 30.96 27.80 34.70 30.56 31.18 25.05 26.06 22.61 23.85 22.50 24.54 22.94 25.41 21.92 17.10 19.96 20.87 17.39 18.73 16.52 14.81 12.23 57.07 58.54 60.49 46.34 45.85 41.46 39.51 40.00 54.15 53.66 59.51 49.27 52.20 52.20 50.73 48.29 45.37 48.29 50.73 48.78 51.22 47.80 46.34 47.32 44.88 38.05 42.44 39.02 39.02 32.68 34.15 33.17 44.39 30.73 34.15 27.32 27.80 34.63 26.83 28.29 28.29 25.37 25.85 23.41 29.27 26.83 22.44 25.85 13. 47.80 46.34 40.00 39.51 40.98 37.56 37.07 31.71 40.49 37.56 32.68 30.24 31.22 28.78 33.17 33.17 30.73 30.73 24.88 25.85 24.88 21.46 22.44 19.02 20.49 16.59 63.11 63.69 61.38 51.01 48.13 44.09 39.48 43.52 61.96 57.06 52.45 56.20 48.41 52.74 45.24 43.23 43.52 45.53 47.84 42.07 45.53 42.94 42.94 43.23 39.19 38.04 37.75 40.63 35.45 34.58 29.68 30.26 32.85 25.94 29.39 27.09 21.33 27.67 19.60 27.09 27.09 27.67 27.38 21.90 25.36 22.19 19.02 21.61 12.68 43.52 42.94 37.75 31.70 36.89 31.70 38.62 36.60 35.45 30.84 27.09 25.94 28.53 24.50 26.80 29.11 29.39 26.80 22.19 26.51 25.65 22.48 22.48 19.60 20.17 15.56 63.69 59.93 61.76 61.72 58.79 53.24 51.09 46.33 55.54 51.57 45.02 47.51 39.80 40.67 35.41 48.30 39.33 43.81 38.41 39.24 50.20 30.04 34.96 38.24 38.24 34.20 30.85 38.87 24.81 27.54 24.17 23.27 26.95 18.70 21.26 21.64 19.70 16.08 17.53 21.23 20.32 16.85 16.39 15.64 17.60 16.18 17.09 15.99 8. 29.45 29.38 26.68 21.47 23.30 21.38 30.08 22.04 23.80 17.87 20.01 17.47 20.86 20.96 16.62 18.39 16.54 17.98 13.16 11.93 14.48 14.48 11.72 11.41 15.44 8.74 67.13 67.13 64.34 46.15 44.06 45.45 41.26 43.36 51.75 53.15 64.34 54.55 49.65 54.55 53.85 55.94 46.15 53.85 53.85 50.35 53.85 48.25 42.66 38.46 39.16 36.36 42.66 41.26 34.27 30.07 32.87 28.67 36.36 30.77 27.97 26.57 23.08 31.47 20.28 30.77 25.17 19.58 24.48 18.18 23.78 20.98 20.98 14.69 12.59 39.86 38.46 36.36 24.48 34.27 30.07 37.76 34.27 37.76 28.67 27.97 18.88 27.97 28.67 23.78 25.87 26.57 23.78 22.38 23.08 28.67 13.99 27.27 12.59 22.38 13.99 Table 14. Detailed Performance Overview on SuperGPQAPivot Table 2. The table presents LLMs performance on different disciplines. The highest score in each column is indicated with ùëèùëúùë• ; the second-best score is in bold, and the third-best score is underlined. K. Ranking of the Top Five Models in Each of the 285 Subfields Table 15. Detailed Listing of the Top Five Models in Each of the 285 Subfields. Model Score Model Score Model Animal Nutrition and Feed Science Applied Optics Pharmaceutics DeepSeek-R1 50.00 DeepSeek-R1 58.06 DeepSeek-R1-Zero DeepSeek-R1-Zero 50.00 o3-mini-2025-01-31-high 57.26 qwen-max-2025-01-25 Score 75.34 69.86 claude-3-5-sonnet48.08 o1-2024-12-17 56.45 Doubao-1.5-pro-32k-250115 68.49 o3-mini-2025-01-31-medium 48.08 o3-mini-2025-01-31-medium 53.23 Doubao-1.5-pro-32k-241225 67.12 Qwen2.5-72B-Instruct 48.08 o3-mini-2025-01-31-low 51.61 DeepSeek-R1 Animal Rearing and Breeding Laser Technology Pharmacology Doubao-1.5-pro-32k49.02 DeepSeek-R1 82.00 DeepSeek-R1-Zero Doubao-1.5-pro-32k-241225 47.06 o3-mini-2025-01-31-high 76.00 DeepSeek-R1 DeepSeek-R 47.06 o1-2024-12-17 70.00 o1-2024-12-17 64.38 56.36 54.55 52. MiniMax-Text-01 45.10 DeepSeek-R1-Zero 70.00 claude-3-5-sonnet-20241022 52.73 DeepSeek-R1-Zero 45.10 o3-mini-2025-01-31-medium 68.00 qwen-max-2025-0152.73 Aquaculture Optoelectronic Technology Epidemiology and Health Statistics DeepSeek-R1 53.57 o3-mini-2025-01-31-medium 53.73 DeepSeek-R 56.63 DeepSeek-R1-Zero 53.57 DeepSeek-V3 50.75 Doubao-1.5-pro-32k-241225 55.42 o1-2024-1246.43 qwen-max-2025-01-25 49.25 DeepSeek-R1-Zero claude-3-5-sonnet-20241022 42.86 o3-mini-2025-01-31-low 47.76 o1-2024-12-17 Doubao-1.5-pro-32k42.86 o3-mini-2025-01-31-high 46.27 qwen-max-2025-01-25 Crop Science Theoretical Optics Health Toxicology and Environmental Health Doubao-1.5-pro-32k-250115 53.10 DeepSeek-R1 63.70 o1-2024-12-17 DeepSeek-R1-Zero 53.10 o3-mini-2025-01-31-high 60.00 Llama-3.1-405B-Instruct DeepSeek-R1 o1-2024-12-17 50.34 DeepSeek-R1-Zero 57.78 o3-mini-2025-01-31-high 49.66 o3-mini-2025-01-31-medium 57.04 gpt-4o-2024-11-20 54. 51.81 51.81 73.75 68.75 67.50 67. qwen-max-2025-01-25 46.90 o1-2024-12-17 54.81 claude-3-5-sonnet-20241022 65.00 Forest Cultivation and Genetic Oil and Gas Field Development and Maternal, Child and Adolescent Breeding Storage & Transportation Health Engineering DeepSeek-R o1-2024-12-17 56.79 DeepSeek-R1 54.32 o1-2024-12-17 59.68 o1-2024-12-17 73.42 56.45 claude-3-5-sonnet72.15 Doubao-1.5-pro-32k-250115 51.85 DeepSeek-R1-Zero 56.45 DeepSeek-R1-Zero 69.62 DeepSeek-R1-Zero 51.85 qwen-max-2025-01-25 51.61 Doubao-1.5-pro-32k-250115 68.35 Doubao-1.5-pro-32k-241225 50.62 o3-mini-2025-01-31-medium 50.00 gpt-4o-2024-11-20 68. Landscape Plants and Ornamental Poromechanics and Reservoir Nutrition and Food Hygiene Horticulture Physics DeepSeek-R1-Zero 68.00 o1-2024-12-17 68.00 DeepSeek-R1-Zero 82.00 DeepSeek-R1 66.00 DeepSeek-R1 68.00 claude-3-5-sonnet72.00 claude-3-5-sonnet-20241022 64.00 DeepSeek-R1-Zero 68.00 o1-2024-12-17 70.00 Continued gpt-4o-2024-05-13 64.00 Doubao-1.5-pro-32k-250115 66.00 o3-mini-2025-01-31-medium 70.00 Mistral-Large-Instruct-2411 62.00 Doubao-1.5-pro-32k64.00 Doubao-1.5-pro-32k-241225 70.00 Veterinary Medicine Engineering Fluid Mechanics Basic Stomatology o1-2024-12DeepSeek-R1 64.00 o3-mini-2025-01-31-medium 71.43 qwen-max-2025-01-25 64.00 DeepSeek-R1 67.86 o1-2024-12-17 54.72 52. Doubao-1.5-pro-32k-241225 58.00 o3-mini-2025-01-31-low 66.67 Doubao-1.5-pro-32k-250115 52.83 Doubao-1.5-pro-32k-250115 58.00 o3-mini-2025-01-31-high 64.29 claude-3-5-sonnet-20241022 49.06 DeepSeek-R1-Zero 58.00 o1-2024-12-17 63.10 gpt-4o-2024-08-06 Economic Statistics Engineering Thermophysics Clinical Stomatology o1-2024-12-17 DeepSeek-R1 80.00 DeepSeek-R1 69.86 o1-2024-1274.00 DeepSeek-R1-Zero 65.07 DeepSeek-R1 47.17 55.70 55.70 o3-mini-2025-01-31-high 72.00 o3-mini-2025-01-31-high 60.96 Doubao-1.5-pro-32k-250115 53.16 o3-mini-2025-01-31-medium 72.00 o1-2024-12-17 60.27 qwen-max-2025-01-25 DeepSeek-R1-Zero 70.00 o3-mini-2025-01-31-medium 55.48 DeepSeek-R1-Zero 51.90 48.10 Finance Fluid Machinery and Engineering Traditional Chinese Health Preservation DeepSeek-R1 68.18 DeepSeek-R1 68.75 o1-2024-12-17 DeepSeek-R1-Zero 68.18 o1-2024-1264.06 DeepSeek-R1-Zero Doubao-1.5-pro-32k-250115 67.61 o3-mini-2025-01-31-high 56.25 DeepSeek-R1 81.36 81. 79.66 o1-2024-12-17 66.48 o3-mini-2025-01-31-medium 56.25 Doubao-1.5-pro-32k-250115 79.66 o3-mini-2025-01-31-high 62.50 gemini-2.0-flash 51.56 qwen-max-2025-01-25 69.49 Industrial Economics Heat Transfer Traditional Chinese Medicine Theory DeepSeek-R1-Zero 66.67 DeepSeek-R1 73.64 DeepSeek-R1-Zero DeepSeek-R1 65.48 o1-2024-12-17 70.54 qwen-max-2025-01Doubao-1.5-pro-32k-250115 65.48 o3-mini-2025-01-31-high 63.57 DeepSeek-R1 Doubao-1.5-pro-32k-241225 64.29 DeepSeek-R1-Zero 63.57 o1-2024-1270.00 67.78 66.67 63.33 qwen-max-2025-01-25 63.10 o3-mini-2025-01-31-medium 61.24 Doubao-1.5-pro-32k60.00 International Trade Internal Combustion Engineering Traditional Chinese Pharmacy DeepSeek-R1 71.01 Doubao-1.5-pro-32k68.00 Doubao-1.5-pro-32k-250115 63.87 DeepSeek-R1-Zero 71.01 gemini-2.0-flash 66.00 DeepSeek-R1-Zero Doubao-1.5-pro-32k69.57 o1-2024-12-17 64.00 DeepSeek-R1 Doubao-1.5-pro-32k-241225 66.67 claude-3-5-sonnet-20241022 64.00 o1-2024-12-17 qwen-max-2025-0162.32 DeepSeek-R1 64.00 qwen-max-2025-01-25 62.18 60.50 57.98 55. Labor Economics Power Machinery and Engineering Military Command and Information Systems DeepSeek-R1 63.51 DeepSeek-R1 46.15 DeepSeek-R1-Zero 58.00 Doubao-1.5-pro-32k-250115 59.46 DeepSeek-R1-Zero 46.15 Doubao-1.5-pro-32k-241225 56.00 DeepSeek-R1-Zero 59.46 o3-mini-2025-01-31-medium 42.31 claude-3-5-sonnet-20241022 54.00 o1-2024-12-17 55.41 Doubao-1.5-pro-32k-250115 42.31 gemini-2.0-flash claude-3-5-sonnet54.05 o3-mini-2025-01-31-high 38.46 Qwen2.5-72B-Instruct 54.00 54.00 89 Continued National and Defense Economics Refrigeration and Cryogenic Military Logistics and Equipment Engineering DeepSeek-R1 o1-2024-1268.00 o3-mini-2025-01-31-medium 48.00 o1-2024-12-17 55.56 66.00 DeepSeek-R1 48.00 claude-3-5-sonnet-20241022 53.70 DeepSeek-R1-Zero 66.00 Doubao-1.5-pro-32k-250115 46.00 gpt-4o-2024-08-06 Doubao-1.5-pro-32k-241225 62.00 DeepSeek-R1-Zero 44.00 gpt-4o-2024-05-13 Doubao-1.5-pro-32k60.00 DeepSeek-V3 42.00 Llama-3.1-405B-Instruct 50.00 50.00 50.00 Public Finance Thermal Energy Engineering Military Management Doubao-1.5-pro-32k-250115 65.00 DeepSeek-R1 63.30 claude-3-5-sonnet-20241022 70. DeepSeek-R1-Zero 64.17 o3-mini-2025-01-31-high 58.72 qwen-max-2024-09-19 Doubao-1.5-pro-32k-241225 60.83 DeepSeek-R1-Zero 55.96 DeepSeek-V 70.00 68.00 DeepSeek-R1 o1-2024-12-17 59.17 Doubao-1.5-pro-32k-250115 55.05 Doubao-1.5-pro-32k68.00 55.00 o1-2024-12-17 54.13 gemini-2.0-flash 66.00 Quantitative Economics Cartography and Geographic Military Thought and History Information Engineering DeepSeek-R1-Zero 67.00 o3-mini-2025-01-31-low 66.00 o1-2024-12-17 DeepSeek-R 66.00 Doubao-1.5-pro-32k-241225 66.00 DeepSeek-R1 o3-mini-2025-01-31-high 65.00 o1-2024-12-17 64.00 DeepSeek-R1-Zero 76. 70.59 70.59 Doubao-1.5-pro-32k-250115 65.00 o3-mini-2025-01-31-high 62.00 Doubao-1.5-pro-32k-250115 62. o1-2024-12-17 64.00 o3-mini-2025-01-31-medium 62.00 claude-3-5-sonnet-20241022 60.78 Economic History Digital Surveying and Remote Ethics Sensing Applications DeepSeek-R1 78.00 DeepSeek-R1 61.76 o1-2024-12-17 DeepSeek-R1-Zero 78.00 o1-2024-1260.29 gpt-4o-2024-11-20 claude-3-5-sonnet-20241022 72.00 DeepSeek-R1-Zero 60.29 qwen-max-2025-01-25 Doubao-1.5-pro-32k-250115 72.00 claude-3-5-sonnet55.88 DeepSeek-R1 63.24 58.82 55.88 55.88 Doubao-1.5-pro-32k68.00 qwen-max-2025-01-25 54.41 Doubao-1.5-pro-32k-241225 54.41 Political Economy Geodesy and Surveying Engineering Logic DeepSeek-R1 60.00 o1-2024-12-17 Doubao-1.5-pro-32k-250115 60.00 DeepSeek-R1 74.00 o1-2024-12-17 74.00 DeepSeek-R 64.29 62.86 Doubao-1.5-pro-32k-241225 58.00 DeepSeek-R1-Zero 72.00 Doubao-1.5-pro-32k-250115 61. DeepSeek-R1-Zero 56.00 o3-mini-2025-01-31-high 70.00 o3-mini-2025-01-31-high DeepSeek-V3 54.00 Doubao-1.5-pro-32k-250115 70.00 DeepSeek-R1-Zero Western Economics Textile Chemistry and Dyeing Philosophical Aesthetics Mistral-Large-Instruct-2411 64.00 DeepSeek-R1 62.00 DeepSeek-R1-Zero DeepSeek-R1-Zero 64.00 claude-3-5-sonnet-20241022 56.00 DeepSeek-R1 Engineering 58.57 55. 61.47 59.63 qwen-max-2025-01-25 58.00 DeepSeek-R1-Zero 56.00 Doubao-1.5-pro-32k-250115 52. DeepSeek-R1 58.00 o1-2024-12-17 52.00 o1-2024-12-17 50.46 Doubao-1.5-pro-32k-250115 58.00 Doubao-1.5-pro-32k52.00 Doubao-1.5-pro-32k-241225 49.54 Educational Technology and Textile Materials Science Philosophy of Science and Principles Technology 90 Continued DeepSeek-R1 61.46 DeepSeek-R1-Zero 80.00 DeepSeek-R1-Zero 80.00 Doubao-1.5-pro-32k-241225 60.42 o1-2024-12-17 78.00 Doubao-1.5-pro-32k-241225 78.00 DeepSeek-R1-Zero 60.42 Doubao-1.5-pro-32k-250115 78.00 Doubao-1.5-pro-32k-250115 76.00 qwen-max-2025-01-25 55.21 qwen-max-2025-01-25 74.00 o1-2024-12Doubao-1.5-pro-32k-250115 54.17 DeepSeek-R1 74.00 gpt-4o-2024-11-20 74.00 70.00 Preschool Education Road and Railway Engineering Religious Studies qwen-max-2025-01-25 68.00 DeepSeek-R1-Zero 56.00 Doubao-1.5-pro-32k-250115 80. gpt-4o-2024-11-20 66.00 DeepSeek-R1 54.00 DeepSeek-R1 DeepSeek-R1-Zero 60.00 qwen-max-2025-01-25 52.00 DeepSeek-R1-Zero MiniMax-Text-01 58.00 Doubao-1.5-pro-32k-241225 50.00 qwen-max-2025-01-25 DeepSeek-R1 58.00 o1-2024-12-17 46.00 phi76.00 76.00 72.00 72.00 Special Education Traffic Information Engineering and Astronomical Observation and Control Technology DeepSeek-R1-Zero 64.00 DeepSeek-R1 56.92 DeepSeek-R1-Zero qwen-max-2024-09-19 62.00 o1-2024-12-17 55.38 MiniMax-Text-01 qwen-max-2025-01-25 62.00 DeepSeek-R1-Zero 52.31 o1-2024-12Qwen2.5-72B 62.00 o3-mini-2025-01-31-high 47.69 o3-mini-2025-01-31-high claude-3-5-sonnet-20241022 60.00 Doubao-1.5-pro-32k-241225 46.15 DeepSeek-V Theory of Curriculum and Transportation Planning and Astrophysics 72.00 66.00 65. 65.00 64.00 Instruction Management DeepSeek-R1-Zero 66.67 o1-2024-1266.28 o3-mini-2025-01-31-medium 60.87 DeepSeek-R1 62.75 DeepSeek-R1-Zero 66.28 o1-2024-12-17 Doubao-1.5-pro-32k-250115 62.75 qwen-max-2025-0165.12 DeepSeek-R1 qwen-max-2025-01-25 58.82 Doubao-1.5-pro-32k-241225 60.47 o3-mini-2025-01-31-high o1-2024-12-17 56.86 DeepSeek-R 59.30 MiniMax-Text-01 Physical Education and Training Vehicle Operation Engineering Cosmology qwen-max-2025-01-25 50.00 o1-2024-1266.00 o3-mini-2025-01-31-high DeepSeek-R1-Zero 50.00 o3-mini-2025-01-31-high 64.00 DeepSeek-R1 59.42 57. 56.52 55.07 71.79 70.51 o1-2024-12-17 48.00 DeepSeek-R 62.00 Doubao-1.5-pro-32k-250115 69.23 o3-mini-2025-01-31-low 46.00 DeepSeek-R1-Zero 62.00 o1-2024-12-17 DeepSeek-R 44.00 gemini-2.0-flash 60.00 qwen-max-2025-01-25 Sports Humanities and Sociology Military Chemistry and Pyrotechnics Solar System Science DeepSeek-R1-Zero 66.00 claude-3-5-sonnet68.00 o3-mini-2025-01-31-high gpt-4o-2024-11-20 60.00 gpt-4o-2024-05-13 68.00 DeepSeek-R1 o1-2024-12-17 56.00 o1-2024-1262.00 o1-2024-12-17 66.67 64.10 69.32 67.05 62. claude-3-5-sonnet-20241022 56.00 gpt-4o-2024-11-20 62.00 o3-mini-2025-01-31-medium 60.23 gpt-4o-2024-08-06 56.00 DeepSeek-R1-Zero 62.00 DeepSeek-R1-Zero 56.82 Sports Science and Medicine Weapon Systems Science and Stellar and Interstellar Evolution Engineering Doubao-1.5-pro-32k72.00 phi-4 58.00 o3-mini-2025-01-31-medium 67.14 DeepSeek-R1-Zero 70.00 o1-2024-12-17 56.00 o1-2024-12-17 Doubao-1.5-pro-32k68.00 gemini-2.0-flash 54.00 DeepSeek-R1 65.71 64.29 91 Continued claude-3-5-sonnet-20241022 66.00 o1-mini-2024-09-12 52.00 DeepSeek-R1-Zero qwen-max-2024-09-19 66.00 gpt-4o-2024-08-06 52.00 o3-mini-2025-01-31-high 64.29 60.00 Psychology Archaeology and Museology Atmospheric Physics and Atmospheric Environment Doubao-1.5-pro-32k-250115 56.32 DeepSeek-R1-Zero 73.08 claude-3-5-sonnet-20241022 55.07 Doubao-1.5-pro-32k-241225 54.02 DeepSeek-R 72.12 Doubao-1.5-pro-32k-250115 52.17 DeepSeek-R1-Zero 52.87 o1-2024-12-17 70.19 Doubao-1.5-pro-32k-241225 50. claude-3-5-sonnet-20241022 50.57 qwen-max-2025-01-25 60.58 DeepSeek-R1-Zero o1-2024-12-17 48.28 claude-3-5-sonnet-20241022 59.62 DeepSeek-R Aeronautical and Astronautical Historical Geography Dynamic Meteorology Science and Technology DeepSeek-R1 65.55 o1-2024-1254.93 DeepSeek-R1 DeepSeek-R1-Zero 57.14 claude-3-5-sonnet-20241022 54.23 o1-2024-12-17 o1-2024-12-17 56.30 Llama-3.1-405B-Instruct 53.52 DeepSeek-R1-Zero 50.72 49.28 72.00 66.00 66. o3-mini-2025-01-31-high 54.62 DeepSeek-R1-Zero 49.30 claude-3-5-sonnet-20241022 64.00 o3-mini-2025-01-31-medium 52.94 gpt-4o-2024-11-20 47.18 Doubao-1.5-pro-32k64.00 Agricultural Environment and World History Meteorology Soil-Water Engineering DeepSeek-R1-Zero 64.81 o1-2024-12-17 60.75 DeepSeek-R1 67.86 65.48 63.64 63. o1-2024-12-17 DeepSeek-R1 57.41 DeepSeek-R1-Zero 58.18 DeepSeek-R1-Zero 55.56 DeepSeek-R1 54.44 claude-3-5-sonnet54.76 MiniMax-Text-01 53.70 gpt-4o-2024-11-20 53.27 Doubao-1.5-pro-32k-250115 54.76 o3-mini-2025-01-31-high 53.70 claude-3-5-sonnet-20241022 51.87 Doubao-1.5-pro-32k-241225 52.38 Agricultural Mechanization Civil and Commercial Law Biochemistry and Molecular Biology Engineering o3-mini-2025-01-31-high 70.00 DeepSeek-R1-Zero 62.71 DeepSeek-R1 68.69 DeepSeek-R o1-2024-12-17 70.00 MiniMax-Text-01 59.32 Doubao-1.5-pro-32k-250115 64.65 66.00 o1-2024-12-17 58.47 o1-2024-12o3-mini-2025-01-31-medium 66.00 DeepSeek-R1 58.47 DeepSeek-R1-Zero DeepSeek-V3 64.00 claude-3-5-sonnet-20241022 57.63 Doubao-1.5-pro-32k-241225 62. Architectural Design and Theory Constitutional and Administrative Biophysics Law qwen-max-2024-09-19 60.00 DeepSeek-R1-Zero 72.00 o1-2024-12-17 Doubao-1.5-pro-32k-250115 60.00 DeepSeek-R1 70.00 DeepSeek-R1 Llama-3.1-405B-Instruct 58.00 claude-3-5-sonnet66.00 DeepSeek-R1-Zero DeepSeek-R1-Zero 58.00 qwen-max-2025-01-25 62.00 o1-mini-2024-09-12 o1-2024-12-17 56.00 Doubao-1.5-pro-32k62.00 DeepSeek-V3 Architectural History Contract Law Botany DeepSeek-R1-Zero 67.74 DeepSeek-R1-Zero 78.00 o1-2024-12-17 DeepSeek-R1 o1-2024-12-17 66.13 o1-2024-12-17 74.00 DeepSeek-R1 61.29 claude-3-5-sonnet70.00 DeepSeek-R1-Zero 72.00 72.00 70.00 68.00 68. 54.82 54.22 53.61 Doubao-1.5-pro-32k-250115 61.29 DeepSeek-R1 70.00 Doubao-1.5-pro-32k49.40 92 Continued qwen-max-2025-01-25 56.45 Llama-3.3-70B-Instruct 70.00 Doubao-1.5-pro-32k46.99 Urban Planning and Design Criminal Law Cell Biology DeepSeek-R1 68.00 DeepSeek-R 68.10 DeepSeek-R1 qwen-max-2025-01-25 64.00 Doubao-1.5-pro-32k-250115 67.24 o1-2024-12-17 DeepSeek-R1-Zero 64.00 DeepSeek-R1-Zero 62.93 o3-mini-2025-01-31-low 59.77 56.32 54.02 Doubao-1.5-pro-32k-250115 60.00 o1-2024-1262.07 Doubao-1.5-pro-32k-250115 52.87 MiniMax-Text-01 58.00 qwen-max-2025-01-25 58.62 DeepSeek-R1-Zero 52. Chemical Transport Engineering International Law Ecology DeepSeek-R1 76.00 DeepSeek-R1-Zero 56.14 o1-2024-12o3-mini-2025-01-31-high 70.00 o1-2024-12-17 50.88 DeepSeek-R1-Zero o1-2024-12-17 66.00 DeepSeek-R1 50.88 DeepSeek-R 56.94 55.56 50.00 o3-mini-2025-01-31-medium 66.00 claude-3-5-sonnet-20241022 47.37 Doubao-1.5-pro-32k-250115 50. gemini-2.0-flash 64.00 Doubao-1.5-pro-32k-241225 47.37 o3-mini-2025-01-31-high 47.22 Elements of Chemical Reaction Law and Social Governance Genetics Engineering o1-2024-12-17 70.09 o1-2024-12-17 74.00 DeepSeek-R1 o3-mini-2025-01-31-high 70.09 qwen-max-2025-01-25 68.00 o1-2024-12-17 DeepSeek-R1 67.29 DeepSeek-R1-Zero 68.00 DeepSeek-R1-Zero 66. 65.22 64.13 DeepSeek-R1-Zero 66.36 gemini-2.0-flash 66.00 Doubao-1.5-pro-32k-250115 63. o3-mini-2025-01-31-medium 64.49 DeepSeek-R1 66.00 o3-mini-2025-01-31-high 61.96 Fluid Flow and Heat Transfer in Legal Theory and Legal History Microbiology Chemical Engineering DeepSeek-R1 62.62 DeepSeek-R1 78.00 o1-2024-12-17 49.69 DeepSeek-R1-Zero 58.88 DeepSeek-R1-Zero 72.00 Doubao-1.5-pro-32k-250115 49.69 Doubao-1.5-pro-32k-250115 54.21 o1-2024-12-17 70.00 DeepSeek-R 49.07 o1-2024-12-17 51.40 claude-3-5-sonnet-20241022 70.00 o3-mini-2025-01-31-medium 48.45 Doubao-1.5-pro-32k-241225 51.40 Llama-3.1-405B-Instruct 68.00 Doubao-1.5-pro-32k-241225 47.20 Mass Transport and Separation Military Law Physiology Process in Chemical Engineering DeepSeek-R1 72.60 DeepSeek-R1-Zero 82.00 o1-2024-12-17 DeepSeek-R1-Zero 71.23 claude-3-5-sonnet-20241022 76.00 DeepSeek-R 61.67 61.67 o1-2024-12-17 65.75 Doubao-1.5-pro-32k-250115 76.00 Doubao-1.5-pro-32k-250115 57. o3-mini-2025-01-31-high 60.96 gpt-4o-2024-11-20 76.00 o3-mini-2025-01-31-high Doubao-1.5-pro-32k-250115 58.90 Llama-3.1-405B-Instruct 76.00 DeepSeek-R1-Zero Bridge and Tunnel Engineering Procedural Law Zoology Doubao-1.5-pro-32k-250115 58.82 o1-2024-12-17 78.00 o1-2024-12Doubao-1.5-pro-32k-241225 54.90 claude-3-5-sonnet-20241022 74.00 DeepSeek-R1 o1-2024-12-17 52.94 DeepSeek-R1 68.00 DeepSeek-R1-Zero 53.33 53.33 57.80 53.21 53.21 DeepSeek-R1-Zero 52.94 DeepSeek-R1-Zero 68.00 Doubao-1.5-pro-32k-241225 47.71 DeepSeek-R1 50.98 gpt-4o-2024-11-20 62.00 Doubao-1.5-pro-32k47.71 Geotechnical Engineering Political Science Analytical Chemistry DeepSeek-R1 60.34 DeepSeek-R1-Zero 60.00 DeepSeek-R1 58.33 93 Continued DeepSeek-R1-Zero 51.96 DeepSeek-R 58.46 DeepSeek-R1-Zero 55.56 Doubao-1.5-pro-32k-250115 49.72 gpt-4o-2024-11-20 55.38 Doubao-1.5-pro-32k-250115 54. o1-2024-12-17 49.16 o1-2024-12-17 53.85 o1-2024-12-17 claude-3-5-sonnet-20241022 46.93 DeepSeek-V3 53.85 o3-mini-2025-01-31-high Structural Engineering Broadcasting and Television Art Electrochemistry DeepSeek-R1 56.14 o1-2024-12-17 66.00 o3-mini-2025-01-31-high Doubao-1.5-pro-32k-250115 54.39 DeepSeek-R1-Zero 64.00 o1-2024-12-17 Doubao-1.5-pro-32k-241225 52.63 gpt-4o-2024-08-06 62.00 DeepSeek-R DeepSeek-R1-Zero 52.63 gpt-4o-2024-05-13 62.00 DeepSeek-R1-Zero 54.04 52.27 50. 48.65 47.75 47.30 o1-2024-12-17 43.86 Mistral-Large-Instruct-2411 60.00 Doubao-1.5-pro-32k46.85 Urban Infrastructure Engineering Dance Studies Inorganic Chemistry DeepSeek-R1-Zero 61.97 o1-2024-1246.00 o1-2024-12-17 claude-3-5-sonnet-20241022 52.11 gpt-4o-2024-08-06 46.00 DeepSeek-R1 qwen-max-2025-01-25 52.11 claude-3-5-sonnet42.00 o3-mini-2025-01-31-high Qwen2.5-72B-Instruct 50.70 gpt-4o-2024-05-13 42.00 o3-mini-2025-01-31-low 56.52 55. 51.45 49.28 DeepSeek-R1 49.30 DeepSeek-R1-Zero 40.00 Doubao-1.5-pro-32k-250115 47. Advanced Programming Languages Design Arts Organic Chemistry o1-2024-12-17 82.00 DeepSeek-R1 46.77 DeepSeek-R o3-mini-2025-01-31-high 78.00 o1-2024-12-17 45.16 DeepSeek-R1-Zero o3-mini-2025-01-31-medium 76.00 claude-3-5-sonnet-20241022 45.16 o3-mini-2025-01-31-high DeepSeek-R1-Zero 76.00 DeepSeek-R1-Zero 45.16 o1-2024-12-17 57.31 56.73 54.39 52. o3-mini-2025-01-31-low 74.00 Mistral-Large-Instruct-2411 40.32 o3-mini-2025-01-31-medium 49.71 Computer Architecture Drama and Opera Studies Physical Chemistry o1-2024-12-17 72.00 DeepSeek-R1 58.54 DeepSeek-R1-Zero DeepSeek-R1-Zero 72.00 DeepSeek-R1-Zero 58.54 o3-mini-2025-01-31-high DeepSeek-R1 QwQ 64.00 o1-2024-12-17 57.32 o1-2024-12-17 62.00 claude-3-5-sonnet-20241022 54.88 DeepSeek-R 47.31 46.46 46.18 45.04 qwen-max-2025-01-25 60.00 Doubao-1.5-pro-32k53.66 Doubao-1.5-pro-32k-250115 44.48 Computer Networks Film Studies Polymer Chemistry and Physics DeepSeek-R o1-2024-12-17 64.41 DeepSeek-R1-Zero 65.82 DeepSeek-R1 67.11 62.71 o1-2024-12-17 60.13 o3-mini-2025-01-31-medium 55. MiniMax-Text-01 59.32 DeepSeek-R1 56.33 DeepSeek-R1-Zero o3-mini-2025-01-31-low 59.32 claude-3-5-sonnet-20241022 55.06 o1-2024-12o3-mini-2025-01-31-medium 57.63 DeepSeek-V3 54.43 o3-mini-2025-01-31-high Computer Software and Theory Fine Arts Radiochemistry DeepSeek-R o1-2024-12-17 56.96 claude-3-5-sonnet-20241022 61.69 o3-mini-2025-01-31-high 55.70 o1-2024-12-17 58.21 o1-2024-12-17 claude-3-5-sonnet53.16 DeepSeek-R1-Zero 56.22 DeepSeek-R1 55.26 53.95 53.95 60. 58.33 58.33 o3-mini-2025-01-31-high 51.90 gpt-4o-2024-08-06 53.23 o3-mini-2025-01-31-medium 55.00 DeepSeek-R1-Zero 51.90 gpt-4o-2024-11-20 53.23 DeepSeek-R1-Zero 55.00 Data Structures Communication and Broadcasting Human Geography DeepSeek-R1 65.66 o1-2024-12-17 62.07 gpt-4o-2024-11-20 80.00 94 Continued o3-mini-2025-01-31-high 62.63 DeepSeek-R1-Zero 51.72 DeepSeek-R1-Zero o1-2024-12-17 59.60 gemini-2.0-flash 46.55 o1-2024-12o3-mini-2025-01-31-medium 57.58 gpt-4o-2024-11-20 46.55 gpt-4o-2024-08-06 80.00 72.00 72.00 DeepSeek-R1-Zero 56.57 DeepSeek-V3 43.10 Doubao-1.5-pro-32k-241225 72.00 Databases History and Theory of Journalism Physical Geography and Media Management DeepSeek-R1 66.88 DeepSeek-R1-Zero 54.24 DeepSeek-R1-Zero qwen-max-2025-01-25 64.97 DeepSeek-R DeepSeek-R1-Zero 64.97 o1-2024-12-17 52.54 o1-2024-12-17 50.85 DeepSeek-R1 56.63 55. 55.42 o3-mini-2025-01-31-high 63.69 qwen-max-2025-01-25 50.85 claude-3-5-sonnet-20241022 53.01 Doubao-1.5-pro-32k62.42 MiniMax-Text-01 45.76 DeepSeek-V3 Formal Languages Journalism and News Practice Geochemistry o3-mini-2025-01-31-high 69.23 o1-2024-12-17 58.89 gpt-4o-2024-05-13 o3-mini-2025-01-31-medium 65.38 DeepSeek-R1-Zero 55.56 o1-2024-12-17 o1-2024-12-17 DeepSeek-R 61.54 gpt-4o-2024-05-13 52.22 gpt-4o-2024-08-06 61.54 claude-3-5-sonnet-20241022 51.11 DeepSeek-R1 DeepSeek-R1-Zero 59.62 gpt-4o-2024-1151.11 Llama-3.3-70B-Instruct 46.99 64.00 62.00 62.00 62. 62.00 Operating Systems Classical Chinese Literature Mineralogy, Petrology, and Economic Geology DeepSeek-R1-Zero 63.53 DeepSeek-R1-Zero 68.00 o1-2024-12-17 qwen-max-2025-01-25 60.00 Doubao-1.5-pro-32k-241225 58.00 DeepSeek-R1-Zero o1-2024-1258.82 Doubao-1.5-pro-32k-250115 58.00 DeepSeek-R1 57.85 56.20 54.55 o3-mini-2025-01-31-high 58.82 DeepSeek-R1 56.00 Doubao-1.5-pro-32k-241225 52.07 o3-mini-2025-01-31-medium 58.82 DeepSeek-V3 48.00 qwen-max-2025-01-25 50. Pattern Recognition French Language and Literature Paleontology and Stratigraphy o1-2024-12-17 82.00 gemini-2.0-flash 64.00 o3-mini-2025-01-31-high 46.00 claude-3-5-sonnet-20241022 80.00 o1-2024-12-17 60.00 o3-mini-2025-01-31-medium 46.00 Mistral-Large-Instruct-2411 80.00 Llama-3.1-405B-Instruct 60.00 qwen-max-2025-01-25 46.00 Doubao-1.5-pro-32k-250115 80.00 gpt-4o-2024-08-06 58.00 Doubao-1.5-pro-32k-250115 46. Llama-3.1-405B-Instruct 80.00 Mistral-Large-Instruct-2411 58.00 QwQ 46.00 Principles of Computer Organization Linguistics and Applied Linguistics Principles of Seismic Exploration DeepSeek-R1 67.07 claude-3-5-sonnet-20241022 70.00 DeepSeek-R1-Zero DeepSeek-R1-Zero 65.85 gpt-4o-2024-11-20 64.00 o1-2024-1268.00 62.00 Doubao-1.5-pro-32k-250115 63.41 Llama-3.1-405B-Instruct 64.00 Doubao-1.5-pro-32k-250115 62. claude-3-5-sonnet-20241022 60.98 o1-2024-12-17 62.00 claude-3-5-sonnet-20241022 60.00 o3-mini-2025-01-31-medium 60.98 gpt-4o-2024-08-06 62.00 qwen-max-2025-0158.00 Control Theory and Control Literary History Structural Geology Engineering DeepSeek-R 83.15 DeepSeek-R1-Zero 71.01 DeepSeek-R1 o3-mini-2025-01-31-high 82.02 Doubao-1.5-pro-32k-250115 62.32 o1-2024-12-17 o3-mini-2025-01-31-medium 77.53 o1-2024-1260.87 DeepSeek-R1-Zero 60.00 54.29 54.29 DeepSeek-R1-Zero 77.53 DeepSeek-R 60.87 Doubao-1.5-pro-32k-241225 51.43 95 Continued o1-2024-12-17 76.40 Doubao-1.5-pro-32k50.72 Doubao-1.5-pro-32k-250115 50.00 Guidance, Navigation and Control Literary Theory Solid Earth Geophysics DeepSeek-R 74.51 DeepSeek-R1 68.75 o3-mini-2025-01-31-high DeepSeek-R1-Zero 72.55 DeepSeek-R1-Zero 65.62 o1-2024-12-17 o1-2024-1266.67 o1-2024-12-17 60.94 qwen-max-2025-01-25 82.00 76.00 74.00 o3-mini-2025-01-31-high 66.67 Doubao-1.5-pro-32k-241225 60.94 o3-mini-2025-01-31-medium 72.00 o1-mini-2024-09-12 62.75 claude-3-5-sonnet-20241022 59.38 o3-mini-2025-01-31-low 72. Operations Research and Modern and Contemporary Chinese Space physics Cybernetics Literature o3-mini-2025-01-31-medium 86.00 DeepSeek-R1-Zero 58.00 o1-2024-12-17 o3-mini-2025-01-31-high 84.00 Doubao-1.5-pro-32k-241225 54.00 o3-mini-2025-01-31-high DeepSeek-R1 o1-2024-1282.00 Doubao-1.5-pro-32k-250115 54.00 Qwen2.5-72B-Instruct 78.00 DeepSeek-R1 52.00 gemini-2.0-flash DeepSeek-R1-Zero 74.00 o1-2024-1248.00 DeepSeek-R1 Electrical Theory and New Philology and Bibliography Advanced Algebra Technologies DeepSeek-R 50.00 DeepSeek-R1-Zero 72.00 DeepSeek-R1-Zero o3-mini-2025-01-31-high 45.26 Doubao-1.5-pro-32k-250115 64.00 DeepSeek-R1 DeepSeek-R1-Zero 45.26 qwen-max-2025-01-25 60.00 o3-mini-2025-01-31-high o1-2024-12-17 44.74 claude-3-5-sonnet-20241022 58.00 o1-mini-2024-09-12 56. 54.00 54.00 50.00 50.00 84.16 82. 81.19 77.72 Doubao-1.5-pro-32k-241225 43.68 MiniMax-Text-01 58.00 o3-mini-2025-01-31-medium 77.72 High Voltage and Insulation Russian Language and Literature Combinatorial Mathematics Technology DeepSeek-R1 47.73 claude-3-5-sonnet-20241022 50.88 o3-mini-2025-01-31-high 78.01 qwen-max-2025-01-25 46.59 DeepSeek-R1 50.88 o3-mini-2025-01-31-medium 73.30 DeepSeek-R1-Zero 46.59 o1-2024-1249.12 DeepSeek-R1 o1-2024-12-17 DeepSeek-V3 45.45 DeepSeek-R1-Zero 49.12 o1-2024-12-17 45.45 Llama-3.1-405B-Instruct 47.37 o1-mini-2024-09-12 72.77 71.20 64.40 Power Electronics and Electrical Composition Computational Mathematics Drives DeepSeek-R1 58.79 o3-mini-2025-01-31-high 56.00 o3-mini-2025-01-31-high DeepSeek-R1-Zero 56.04 o1-2024-12-17 54.00 DeepSeek-R1 72.00 72.00 o3-mini-2025-01-31-high 50.00 DeepSeek-R1-Zero 50.00 o3-mini-2025-01-31-medium 70.00 o3-mini-2025-01-31-medium 48.90 DeepSeek-V3 48.00 o3-mini-2025-01-31-low o1-2024-12-17 47.80 o3-mini-2025-01-31-medium 48.00 o1-2024-12-17 Power Systems and Automation Harmony Cryptography DeepSeek-R1-Zero 55.21 DeepSeek-R1 51.67 o1-2024-12-17 DeepSeek-R o1-2024-12-17 54.17 o1-2024-12-17 48.33 o3-mini-2025-01-31-high 41.67 DeepSeek-R1-Zero 48.33 DeepSeek-V3 70. 68.00 78.00 76.00 76.00 qwen-max-2025-01-25 40.62 MiniMax-Text43.33 o3-mini-2025-01-31-medium 76.00 o3-mini-2025-01-31-high 38.54 o3-mini-2025-01-31-medium 43.33 DeepSeek-R1 76.00 Circuits and Systems Instrumentation and Performance Discrete Mathematics 96 Continued DeepSeek-R1 67.59 o1-2024-12-17 61.54 o3-mini-2025-01-31-high 80.90 o3-mini-2025-01-31-high 61.11 DeepSeek-R1 55.38 o3-mini-2025-01-31-medium 76.40 DeepSeek-R1-Zero 61.11 gemini-2.0-flash 52.31 o1-2024-12-17 o1-2024-12-17 59.26 DeepSeek-R1-Zero 50.77 DeepSeek-R1 o3-mini-2025-01-31-medium 57.41 gpt-4o-2024-11-20 49.23 o3-mini-2025-01-31-low 74.16 73.03 67.42 Electromagnetic Field and Music History, Education, and Functions of Complex Variables Microwave Technology Technology DeepSeek-R1 81.82 o1-2024-12-17 62.07 DeepSeek-R1 o3-mini-2025-01-31-high 78.41 DeepSeek-R1-Zero 55.86 o3-mini-2025-01-31-high 86.07 81.97 DeepSeek-R1-Zero 77.27 gpt-4o-2024-1153.10 o3-mini-2025-01-31-medium 81.97 o1-2024-12-17 76.14 gpt-4o-2024-08-06 51.03 DeepSeek-R1-Zero o3-mini-2025-01-31-medium 71.59 DeepSeek-R1 51.03 o1-mini-2024-0980.33 77.87 Microelectronics and Solid-State Musical Forms and Analysis Functions of Real Variables Electronics DeepSeek-R1 o1-2024-12-17 76.00 claude-3-5-sonnet-20241022 56.00 o1-2024-12-17 68.00 o1-2024-12-17 52.00 o3-mini-2025-01-31-high gemini-2.0-flash 68.00 o3-mini-2025-01-31-high 52.00 DeepSeek-R1 79.10 77.61 77. o3-mini-2025-01-31-high 66.00 DeepSeek-R1 52.00 o3-mini-2025-01-31-medium 76.12 Doubao-1.5-pro-32k-250115 66.00 Qwen2.5-72B-Instruct 52.00 o1-mini-2024-0974.63 Environmental Engineering Pitch and Scales Fundamental Mathematics DeepSeek-R1 67.42 DeepSeek-R1-Zero 48.21 DeepSeek-R1 DeepSeek-R1-Zero 65.17 o3-mini-2025-01-31-high 42.86 o3-mini-2025-01-31-high 83.76 80. o1-2024-12-17 60.67 Llama-3.1-405B-Instruct 42.86 o3-mini-2025-01-31-medium 80.71 o3-mini-2025-01-31-high 56.18 DeepSeek-R1 41.07 o1-2024-12Doubao-1.5-pro-32k-241225 55.06 o1-2024-12-17 39.29 DeepSeek-R1-Zero Environmental Science Business and Accounting Fuzzy Mathematics DeepSeek-R1-Zero 78.00 DeepSeek-R1-Zero 58.70 o3-mini-2025-01-31-high o1-2024-12-17 DeepSeek-R1 76.00 o1-2024-1253.26 DeepSeek-R1 74.00 Doubao-1.5-pro-32k-241225 53.26 DeepSeek-R1-Zero Management 78.68 77. 82.00 78.00 78.00 Doubao-1.5-pro-32k-250115 74.00 Doubao-1.5-pro-32k-250115 52.17 o3-mini-2025-01-31-medium 74. qwen-max-2025-01-25 72.00 DeepSeek-R1 50.00 o3-mini-2025-01-31-low 74.00 Environmental and Resource Tourism Management and Geometry and Topology Protection Technological Economics Management claude-3-5-sonnet-20241022 64.00 o1-2024-1256.00 o3-mini-2025-01-31-high o1-2024-12-17 62.00 Doubao-1.5-pro-32k-250115 56.00 DeepSeek-R1 gpt-4o-2024-05-13 62.00 o3-mini-2025-01-31-medium 54.00 o1-2024-1275.47 71.32 69.43 Doubao-1.5-pro-32k-250115 62.00 qwen-max-2025-01-25 54.00 o3-mini-2025-01-31-medium 68. DeepSeek-V3 60.00 o3-mini-2025-01-31-high 52.00 o1-mini-2024-09-12 63.77 Food Biochemistry Information Management Science Graph Theory o1-2024-12-17 88.00 qwen-max-2025-01-25 34.00 o3-mini-2025-01-31-high 68.63 Continued Doubao-1.5-pro-32k-241225 86.00 DeepSeek-R1-Zero 34.00 o3-mini-2025-01-31-medium 66.67 DeepSeek-R1 86.00 Qwen2.5-32B-Instruct 32.00 DeepSeek-R1 Doubao-1.5-pro-32k-250115 86.00 Qwen2.5-72B-Instruct 32.00 o1-2024-12-17 DeepSeek-R1-Zero 86.00 MiniMax-Text30.00 DeepSeek-V3 Food Processing and Storage Information Management and Group Theory Engineering Communication Doubao-1.5-pro-32k-250115 54.24 o1-2024-12-17 92.00 DeepSeek-R1 DeepSeek-R1 52.54 claude-3-5-sonnet-20241022 84.00 o3-mini-2025-01-31-high 62.75 58.82 54.90 68.00 60.00 Doubao-1.5-pro-32k50.85 DeepSeek-V3 84.00 o3-mini-2025-01-31-medium 58.00 DeepSeek-R1-Zero 50.85 qwen-max-2025-01-25 84.00 DeepSeek-R1-Zero o1-2024-1247.46 DeepSeek-R1 84.00 o1-2024-12-17 Forest Engineering Library and Archival Science Mathematical Analysis o1-2024-1266.00 o3-mini-2025-01-31-high 58.00 o3-mini-2025-01-31-high gpt-4o-2024-08-06 62.00 qwen-max-2025-01-25 52.00 DeepSeek-R1 o3-mini-2025-01-31-medium 62.00 DeepSeek-R1-Zero 52.00 o1-2024-12-17 58.00 56.00 87.50 86.11 82. qwen-max-2025-01-25 62.00 o1-2024-12-17 48.00 o3-mini-2025-01-31-medium 82.29 o3-mini-2025-01-31-high 58.00 o3-mini-2025-01-31-medium 48.00 DeepSeek-R1-Zero 80. Wood Science and Technology Management Science and Number Theory Engineering o1-2024-12-17 72.00 DeepSeek-R1-Zero 70.69 o3-mini-2025-01-31-high 90.00 claude-3-5-sonnet-20241022 66.00 DeepSeek-R1 68.97 o3-mini-2025-01-31-medium 88.18 o3-mini-2025-01-31-high 66.00 o1-2024-12-17 62.07 o1-2024-12-17 o3-mini-2025-01-31-medium 66.00 o3-mini-2025-01-31-high 62.07 DeepSeek-R1 DeepSeek-R1-Zero 66.00 Doubao-1.5-pro-32k62.07 o3-mini-2025-01-31-low Geological Resources and Geological Education Economics, Management Numerical Analysis Engineering and Social Security gemini-2.0-flash 66.00 DeepSeek-R1 66.00 DeepSeek-R1 DeepSeek-R1-Zero 66.00 DeepSeek-R1-Zero 60.00 o1-2024-12o1-2024-12-17 64.00 o1-2024-12-17 56.00 o3-mini-2025-01-31-high 86.82 83.18 74. 85.07 74.63 74.63 claude-3-5-sonnet-20241022 64.00 Doubao-1.5-pro-32k-241225 56.00 o3-mini-2025-01-31-medium 74. DeepSeek-R1 62.00 MiniMax-Text-01 54.00 DeepSeek-R1-Zero 73.13 Hydraulics and Hydrology Land Resource Management and Ordinary Differential Equations Administrative Management DeepSeek-R1 66.91 DeepSeek-R1-Zero 66.67 o3-mini-2025-01-31-high Doubao-1.5-pro-32k62.50 qwen-max-2025-01-25 58.82 DeepSeek-R1 82.50 81.25 DeepSeek-R1-Zero 61.03 DeepSeek-R 58.82 o3-mini-2025-01-31-medium 80.62 o1-2024-12-17 59.56 o1-2024-12-17 56.86 o1-2024-12-17 o3-mini-2025-01-31-high 58.82 DeepSeek-V 52.94 DeepSeek-R1-Zero 78.75 78.12 Water conservancy and Hydropower Social Medicine and Health Polynomials and Series Expansions Engineering Management DeepSeek-R1 53.66 qwen-max-2025-01-25 70.00 o3-mini-2025-01-31-high DeepSeek-R1-Zero 50.00 o1-2024-12-17 68.00 DeepSeek-R1 82.12 82.12 98 Continued o1-mini-2024-09-12 47.56 DeepSeek-R1 68.00 o3-mini-2025-01-31-medium 79.89 o3-mini-2025-01-31-high 46.34 MiniMax-Text-01 64.00 DeepSeek-R1-Zero o1-2024-12-17 45.12 qwen-max-2024-09-19 64.00 o1-2024-12-17 Antenna and Radio Communication Forensic Medicine Probability and Statistics DeepSeek-R1 o1-2024-12-17 73.68 o1-2024-12-17 68.00 DeepSeek-R1 69.30 qwen-max-2025-01-25 62.00 o3-mini-2025-01-31-high o3-mini-2025-01-31-high 69.30 gemini-2.0-flash 60.00 DeepSeek-R1-Zero o3-mini-2025-01-31-medium 69.30 DeepSeek-R1 60.00 o1-2024-12-17 DeepSeek-R1-Zero 68.42 gpt-4o-2024-11-20 60.00 o1-mini-2024-09-12 Communication Principles Human Anatomy and Special Number Theory Histology-Embryology DeepSeek-R1 75.86 o1-2024-12-17 DeepSeek-R1-Zero 68.10 DeepSeek-R1 61.90 DeepSeek-R1 60.32 o1-2024-12o3-mini-2025-01-31-high 66.38 DeepSeek-R1-Zero 59.79 o3-mini-2025-01-31-high o3-mini-2025-01-31-medium 63.79 Doubao-1.5-pro-32k-250115 59.26 o1-mini-2024-09-12 79. 76.54 82.14 80.36 76.79 76.34 72. 86.00 80.00 78.00 68.00 o1-2024-12-17 61.21 qwen-max-2025-0153.97 o3-mini-2025-01-31-medium 68.00 Communication and Information Immunology Stochastic Processes Systems DeepSeek-R o1-2024-12-17 71.01 Doubao-1.5-pro-32k-250115 56.52 o1-2024-12-17 66.67 o1-2024-12-17 53.62 o3-mini-2025-01-31-high 88. 88.00 DeepSeek-R1-Zero 66.67 DeepSeek-R1 53.62 o3-mini-2025-01-31-medium 88.00 Doubao-1.5-pro-32k-250115 59.42 Llama-3.1-405B-Instruct 52.17 o3-mini-2025-01-31-low o3-mini-2025-01-31-high 56.52 DeepSeek-R1-Zero 52.17 DeepSeek-R1 Optical Fiber Communication Pathogen Biology Hydrogeology o3-mini-2025-01-31-medium 84.00 o1-2024-12-17 DeepSeek-R1 82.00 DeepSeek-R1 59.57 o1-2024-12-17 59.57 DeepSeek-R 88.00 88.00 78.00 76.00 Doubao-1.5-pro-32k-250115 82.00 DeepSeek-R1-Zero 58.51 Doubao-1.5-pro-32k-250115 76.00 o3-mini-2025-01-31-high 80.00 Doubao-1.5-pro-32k-241225 54.26 o3-mini-2025-01-31-high 74. o1-2024-12-17 76.00 qwen-max-2025-01-25 53.19 Doubao-1.5-pro-32k-241225 72.00 Signal and Information Processing Pathology and Pathophysiology Marine Biology DeepSeek-R1 81.29 o1-2024-12-17 66.09 qwen-max-2025-01-25 o3-mini-2025-01-31-high 78.06 Doubao-1.5-pro-32k64.35 Yi-Lighting DeepSeek-R1-Zero 78.06 Doubao-1.5-pro-32k-241225 60.87 gpt-4o-2024-11-20 90.00 88. 88.00 o1-2024-12-17 74.19 DeepSeek-R1 55.65 Doubao-1.5-pro-32k-250115 86.00 o3-mini-2025-01-31-medium 72.26 qwen-max-2025-0154.78 Llama-3.1-70B-Instruct 86.00 Instrument Science and Technology Radiation Medicine Marine Chemistry o1-2024-12DeepSeek-R1 66.00 o1-2024-12-17 86.00 Doubao-1.5-pro-32k-250115 72.00 66.00 Doubao-1.5-pro-32k-241225 84.00 claude-3-5-sonnet70.00 DeepSeek-R1-Zero 60.00 qwen-max-2025-01-25 84.00 Llama-3.1-70B-Instruct o3-mini-2025-01-31-low 52.00 DeepSeek-R1-Zero 84.00 MiniMax-Text-01 qwen-max-2025-01-25 52.00 Doubao-1.5-pro-32k-250115 82.00 Mistral-Large-Instruct-2411 Materials Physics and Chemistry Anesthesiology Underwater Acoustics 70.00 68.00 68.00 99 Continued DeepSeek-R1 65.33 DeepSeek-R1 74.00 o1-2024-12-17 o3-mini-2025-01-31-high 57.79 DeepSeek-R1-Zero 74.00 DeepSeek-R DeepSeek-R1-Zero 57.29 o1-2024-12-17 72.00 o3-mini-2025-01-31-high o1-2024-12-17 56.78 o3-mini-2025-01-31-medium 68.00 DeepSeek-R1-Zero 78. 76.00 70.00 68.00 o3-mini-2025-01-31-medium 53.27 o3-mini-2025-01-31-low 68.00 o3-mini-2025-01-31-medium 64.00 Materials Processing Engineering Clinical Laboratory Diagnostics Physical Oceanography DeepSeek-R1-Zero 63.33 o1-2024-12-17 70.00 o1-2024-12-17 70. DeepSeek-R1 62.22 o3-mini-2025-01-31-high 66.00 o3-mini-2025-01-31-medium 70.00 Doubao-1.5-pro-32k-250115 61.11 DeepSeek-R1 66.00 DeepSeek-R o1-2024-12-17 58.89 o3-mini-2025-01-31-medium 64.00 DeepSeek-R1-Zero 68.00 66.00 Doubao-1.5-pro-32k-241225 55.56 o3-mini-2025-01-31-low 62.00 claude-3-5-sonnet-20241022 64.00 Manufacturing Automation Dermatology and Venereology Acoustics DeepSeek-R 72.22 o3-mini-2025-01-31-low 74.24 o3-mini-2025-01-31-high Doubao-1.5-pro-32k-250115 70.63 o1-2024-12-17 71.21 DeepSeek-R1-Zero DeepSeek-R1-Zero 70.63 o3-mini-2025-01-31-medium 68.18 DeepSeek-R1 Doubao-1.5-pro-32k-241225 69.05 DeepSeek-R1 68.18 o1-2024-12-17 55.92 55. 51.84 51.43 o1-2024-12-17 68.25 o1-mini-2024-09-12 66.67 o3-mini-2025-01-31-medium 47.76 Mechatronic Engineering Emergency Medicine Atomic and Molecular Physics o1-2024-12-17 DeepSeek-R1 64.00 o3-mini-2025-01-31-medium 60.61 DeepSeek-R1 62.00 DeepSeek-R 60.61 o1-2024-12-17 Doubao-1.5-pro-32k-250115 62.00 Doubao-1.5-pro-32k-250115 60.61 o3-mini-2025-01-31-high gemini-2.0-flash 60.00 o1-2024-1259.09 DeepSeek-R1-Zero 56.19 53.33 52.86 51.90 DeepSeek-R1-Zero 60.00 o3-mini-2025-01-31-high 59.09 o3-mini-2025-01-31-medium 51.43 Fundamentals of Dynamics and Geriatric Medicine Electrodynamics Control o3-mini-2025-01-31-medium 47.55 o1-2024-12-17 78.00 DeepSeek-R1 o3-mini-2025-01-31-high 46.69 o3-mini-2025-01-31-high 74.00 o3-mini-2025-01-31-high 58. 57.46 DeepSeek-R1 45.82 DeepSeek-R1 72.00 o3-mini-2025-01-31-medium 55.40 Doubao-1.5-pro-32k-250115 45.82 DeepSeek-R1-Zero 72.00 o1-2024-12-17 o1-2024-12-17 45.53 DeepSeek-V3 68.00 DeepSeek-R1-Zero Rigid Body Mechanics Imaging and Nuclear Medicine Fluid Physics o1-2024-12-17 52.60 DeepSeek-R1 50.75 o3-mini-2025-01-31-high o3-mini-2025-01-31-high 50.29 o1-2024-1247.76 o1-2024-12-17 DeepSeek-R1-Zero 46.82 o3-mini-2025-01-31-high 47.76 DeepSeek-R1 54.72 53. 59.70 54.48 54.48 DeepSeek-R1 46.24 o3-mini-2025-01-31-medium 47.76 Doubao-1.5-pro-32k-250115 53. o3-mini-2025-01-31-medium 42.77 Doubao-1.5-pro-32k-250115 46.27 DeepSeek-R1-Zero 53.73 Solid Mechanics Internal Medicine Particle and Nuclear Physics DeepSeek-R1 o1-2024-12-17 61.29 Doubao-1.5-pro-32k-250115 57.92 o3-mini-2025-01-31-medium 62.67 59.14 o1-2024-12-17 55.45 DeepSeek-R o3-mini-2025-01-31-medium 59.14 Doubao-1.5-pro-32k-241225 53.47 o1-2024-12-17 o3-mini-2025-01-31-high 56.99 qwen-max-2025-01-25 53.47 o3-mini-2025-01-31-high DeepSeek-R1-Zero 55.91 DeepSeek-R1-Zero 52.97 DeepSeek-R1-Zero 100 62.22 61.33 60. 59.11 Theoretical Fluid Mechanics Continued Neurology Polymer Physics DeepSeek-R o1-2024-12-17 77.86 o1-2024-12-17 72.86 DeepSeek-R1 59.79 DeepSeek-R1 59.79 DeepSeek-R1-Zero o3-mini-2025-01-31-high 72.14 DeepSeek-R1-Zero 57.67 o1-2024-12-17 Doubao-1.5-pro-32k-250115 72.14 gpt-4o-2024-05-13 57.14 o3-mini-2025-01-31-high 69. 61.47 60.55 60.55 DeepSeek-R1-Zero 72.14 Llama-3.3-70B-Instruct 55.56 o3-mini-2025-01-31-medium 59. Theoretical Mechanics Nursing and Rehabilitation Quantum Mechanics Medicine o3-mini-2025-01-31-high 58.71 qwen-max-2025-0164.00 o3-mini-2025-01-31-high DeepSeek-R1 56.13 DeepSeek-R1 64.00 DeepSeek-R1 DeepSeek-R1-Zero 56.13 Doubao-1.5-pro-32k64.00 o1-2024-12-17 55.83 55.83 54.85 o1-2024-12-17 53.55 o1-2024-1262.00 o3-mini-2025-01-31-medium 54.85 o3-mini-2025-01-31-medium 53.55 claude-3-5-sonnet-20241022 58.00 Doubao-1.5-pro-32k-250115 54.85 Iron and Steel Metallurgy Obstetrics and Gynecology Relativity DeepSeek-R1 50.48 DeepSeek-R1-Zero 58.82 o3-mini-2025-01-31-high DeepSeek-R1-Zero 49.52 Doubao-1.5-pro-32k56.86 DeepSeek-R1 o3-mini-2025-01-31-high 43.81 Doubao-1.5-pro-32k-250115 56.86 o1-2024-12-17 72.15 70. 69.62 Doubao-1.5-pro-32k-250115 42.86 o1-2024-12-17 54.90 Doubao-1.5-pro-32k-250115 69.62 o1-2024-1240.95 qwen-max-2025-01-25 54.90 o3-mini-2025-01-31-medium 68.35 Non-ferrous Metallurgy Oncology Semiconductor Physics o1-2024-1260.00 o1-2024-12-17 63.79 DeepSeek-R1 DeepSeek-R1-Zero 60.00 Doubao-1.5-pro-32k-250115 62.07 o3-mini-2025-01-31-high DeepSeek-R 58.00 Doubao-1.5-pro-32k-241225 58.62 o1-2024-12-17 Doubao-1.5-pro-32k-250115 56.00 DeepSeek-R1-Zero 58.62 DeepSeek-R1-Zero 60. 55.74 54.10 54.10 qwen-max-2025-01-25 52.00 o3-mini-2025-01-31-high 56.90 o3-mini-2025-01-31-medium 47. Physical Chemistry of Metallurgical Ophthalmology Solid State Physics Process DeepSeek-R1-Zero 68.00 o3-mini-2025-01-31-medium 68.00 DeepSeek-R o1-2024-12-17 DeepSeek-R1 64.00 DeepSeek-R1-Zero 62.00 o1-2024-12-17 64.00 o3-mini-2025-01-31-high 60.00 o3-mini-2025-01-31-high Doubao-1.5-pro-32k-250115 64.00 gpt-4o-2024-11-20 60.00 DeepSeek-R1-Zero 61.90 58.50 57. 56.46 o3-mini-2025-01-31-high 62.00 gpt-4o-2024-05-13 58.00 o3-mini-2025-01-31-medium 53.74 Principles of Metallurgy Otorhinolaryngology Statistical Mechanics 84.00 80.00 Doubao-1.5-pro-32k-250115 76.00 o1-2024-12-17 70.00 DeepSeek-R DeepSeek-R1 o1-2024-12-17 72.00 o3-mini-2025-01-31-low 68.00 o3-mini-2025-01-31-high 70.00 o3-mini-2025-01-31-high 66.00 o3-mini-2025-01-31-medium 78. gpt-4o-2024-11-20 70.00 o3-mini-2025-01-31-medium 66.00 DeepSeek-R1-Zero o1-mini-2024-09-12 68.00 DeepSeek-R1-Zero 66.00 o1-2024-12-17 76. 74.00 Mineral Processing Engineering Pediatrics Subatomic and Atomic Physics qwen-max-2025-01-25 74.00 o1-2024-1272.00 o3-mini-2025-01-31-high 72.55 Doubao-1.5-pro-32k-250115 74.00 qwen-max-2025-01-25 72.00 o3-mini-2025-01-31-medium 72.55 o1-2024-1266.00 Doubao-1.5-pro-32k-250115 72.00 DeepSeek-R1 72.55 101 Continued DeepSeek-R1-Zero 66.00 Doubao-1.5-pro-32k-241225 70.00 Doubao-1.5-pro-32k-250115 72.55 Doubao-1.5-pro-32k-241225 62.00 DeepSeek-R1 68.00 DeepSeek-R1-Zero 72.55 Mining and Safety Engineering Psychiatry and Mental Health Thermodynamics DeepSeek-R1-Zero 70.00 qwen-max-2025-0176.00 o1-2024-12-17 DeepSeek-R1 68.00 gpt-4o-2024-08-06 72.00 DeepSeek-R1 Doubao-1.5-pro-32k-241225 66.00 gpt-4o-2024-0572.00 o3-mini-2025-01-31-high qwen-max-2025-01-25 66.00 DeepSeek-R1-Zero 72.00 DeepSeek-R1-Zero 56.74 55. 53.95 52.56 Doubao-1.5-pro-32k-250115 64.00 claude-3-5-sonnet-20241022 70.00 o3-mini-2025-01-31-medium 50.70 Marine Engineering Surgery Thermodynamics and Statistical Physics qwen-max-2025-01-25 52.00 qwen-max-2025-01-25 54.41 DeepSeek-R DeepSeek-R1-Zero 52.00 o1-2024-12-17 52.94 o3-mini-2025-01-31-high o1-2024-12-17 DeepSeek-R1 50.00 DeepSeek-R1-Zero 52.94 o1-2024-12-17 50.00 Doubao-1.5-pro-32k-250115 51.47 DeepSeek-R1-Zero 54.53 53.40 52. 52.08 MiniMax-Text-01 48.00 DeepSeek-R1 50.00 o3-mini-2025-01-31-medium 51.89 Ship Mechanics and Design Medicinal Chemistry Systems Science Principles qwen-max-2025-01-25 56.82 o1-2024-12-17 o1-2024-12-17 53.41 DeepSeek-R 64.00 o1-2024-12-17 64.00 DeepSeek-R1 DeepSeek-R1-Zero 52.27 DeepSeek-R1-Zero 64.00 DeepSeek-R1-Zero Doubao-1.5-pro-32k51.14 qwen-max-2025-01-25 60.00 o3-mini-2025-01-31-high 76.00 72.00 72.00 70. DeepSeek-R1 48.86 o3-mini-2025-01-31-medium 56.00 o3-mini-2025-01-31-medium 70.00 Nuclear Energy and Reactor Microbiology and Biochemical Demography and Anthropology Technology Pharmacy DeepSeek-R1 70.18 o1-2024-12-17 60.00 DeepSeek-R1-Zero o3-mini-2025-01-31-high 63.16 Doubao-1.5-pro-32k60.00 o1-2024-12-17 72.00 70.00 DeepSeek-R1-Zero 63.16 o3-mini-2025-01-31-high 56.00 claude-3-5-sonnet70.00 o1-2024-12-17 61.40 o3-mini-2025-01-31-medium 54.00 DeepSeek-R1 o3-mini-2025-01-31-medium 59.65 DeepSeek-R1 52.00 qwen-max-2025-01-25 70. 64.00 Radiation Protection and Nuclear Pharmaceutical Analysis Social and Folklore Studies Technology Applications o1-2024-1266.00 DeepSeek-R1 68.00 DeepSeek-R1 o3-mini-2025-01-31-high 64.00 DeepSeek-R1-Zero 68.00 DeepSeek-R1-Zero DeepSeek-R 64.00 claude-3-5-sonnet-20241022 66.00 o1-2024-12-17 65.59 64.52 61.29 DeepSeek-R1-Zero 62.00 Doubao-1.5-pro-32k-250115 66.00 claude-3-5-sonnet-20241022 61.29 claude-3-5-sonnet-20241022 60.00 o1-2024-12-17 64.00 DeepSeek-V 53."
        },
        {
            "title": "Back to Section Start",
            "content": "Back to Table of Contents 102 L. Detailed Scores of Each Discipline for All Evaluated Models List of Model Score Tables 1. DeepSeek-R1 . . . . 2. DeepSeek-R1-Zero . 3. o1-2024-12-17 . . . . . . . . . . . . . 4. o3-mini-2025-01-31-high . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 5. Doubao-1.5-pro-32k-250115 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 6. o3-mini-2025-01-31-medium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 7. Doubao-1.5-pro-32k-241225 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8. qwen-max-2025-01-25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 9. claude-3-5-sonnet-20241022 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10. o3-mini-2025-01-31-low . 11. gemini-2.0-flash . 12. DeepSeek-V3 . . . . . . 13. o1-mini-2024-09-12 . 14. MiniMax-Text-01 . 15. gpt-4o-2024-11-20 . 16. QwQ . . . . . . . . . . . . . . . . . . . . . . . 17. Llama-3.1-405B-Instruct 18. gpt-4o-2024-08-06 . . . 19. Qwen2.5-72B-Instruct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143 20. Mistral-Large-Instruct-2411 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 103 21. qwen-max-2024-09-19 . 22. gpt-4o-2024-05-13 . . . 23. Qwen2.5-32B-Instruct . . . 24. Llama-3.3-70B-Instruct . 25. phi-4 . . . . . . . . . . 26. Qwen2.5-14B-Instruct . . 27. Llama-3.1-70B-Instruct . 28. Qwen2.5-72B . 29. Yi-Lighting . . . 30. Qwen2.5-32B . . . . . . . . . . 31. DeepSeek-V3-Base . 32. Qwen2.5-14B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 33. Mixtral-8x22B-Instruct-v0.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171 34. Qwen2.5-7B-Instruct . 35. Yi-1.5-34B . . . . . 36. gemma-2-27b-it . 37. Llama-3.1-70B . 38. Yi-1.5-34B-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 39. Mistral-Small-Instruct-2409 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183 40. Qwen2.5-7B . . . 41. Llama-3.1-405B . 42. gemma-2-27b . 43. gemma-2-9b-it . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 104 44. Qwen2.5-3B-Instruct . 45. Yi-1.5-9B-Chat . 46. Yi-1.5-9B . . . 47. gemma-2-9b . 48. K2-Chat . . . . . . . . . . . . . . . . . . 49. Mixtral-8x22B-v0.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50. Mixtral-8x7B-Instruct-v0.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205 51. Mixtral-8x7B-v0.1 . 52. K2 . . . . . . . . . . . . . . 53. granite-3.1-8b-instruct 54. Llama-3.1-8B-Instruct 55. Yi-1.5-6B . . . 56. Qwen2.5-3B . 57. Llama-3.1-8B . . . . . . . 58. Mistral-7B-v0.3 . 59. Yi-1.5-6B-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . 60. Qwen2.5-1.5B-Instruct . . . . . . . . . . . 61. OLMo-2-1124-13B-Instruct 62. gemma-2-2b-it . . . . . 63. granite-3.1-2b-instruct . . . . 64. Mistral-7B-Instruct-v0.3 . 65. Qwen2.5-1.5B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235 66. MAP-Neo-7B-Instruct-v0.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 67. OLMo-2-1124-7B-Instruct 68. granite-3.1-2b-base . 69. OLMo-2-1124-13B . 70. MAP-Neo-7B . . . . . 71. granite-3.1-8b-base . 72. OLMo-2-1124-7B . 73. gemma-2-2b . . . . . . . . . . . . . . . . . . 74. Qwen2.5-0.5B-Instruct . 75. Qwen2.5-0.5B . . . . . . Back to Table of Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255 Table 16. Model Scores Across Three Levels of Disciplines: DeepSeek-R1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 107 Table 16. Continued: Model Scores Across Three Levels of Disciplines: DeepSeek-R1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 108 Table 17. Model Scores Across Three Levels of Disciplines: DeepSeek-R1-Zero."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 109 Table 17. Continued: Model Scores Across Three Levels of Disciplines: DeepSeek-R1-Zero."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 110 Table 18. Model Scores Across Three Levels of Disciplines: o1-2024-12-17."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 111 Table 18. Continued: Model Scores Across Three Levels of Disciplines: o1-2024-12-17."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 112 Table 19. Model Scores Across Three Levels of Disciplines: o3-mini-2025-01-31-high."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 113 Table 19. Continued: Model Scores Across Three Levels of Disciplines: o3-mini-2025-01-31-high."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 114 Table 20. Model Scores Across Three Levels of Disciplines: Doubao-1.5-pro-32k-250115."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 115 Table 20. Continued: Model Scores Across Three Levels of Disciplines: Doubao-1.5-pro-32k-250115."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 116 Table 21. Model Scores Across Three Levels of Disciplines: o3-mini-2025-01-31-medium."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 117 Table 21. Continued: Model Scores Across Three Levels of Disciplines: o3-mini-2025-01-31-medium."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 118 Table 22. Model Scores Across Three Levels of Disciplines: Doubao-1.5-pro-32k-241225."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 119 Table 22. Continued: Model Scores Across Three Levels of Disciplines: Doubao-1.5-pro-32k-241225."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 120 Table 23. Model Scores Across Three Levels of Disciplines: qwen-max-2025-01-25."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 121 Table 23. Continued: Model Scores Across Three Levels of Disciplines: qwen-max-2025-01-25."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 122 Table 24. Model Scores Across Three Levels of Disciplines: claude-3-5-sonnet-20241022."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 123 Table 24. Continued: Model Scores Across Three Levels of Disciplines: claude-3-5-sonnet-20241022."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 124 Table 25. Model Scores Across Three Levels of Disciplines: o3-mini-2025-01-31-low."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 125 Table 25. Continued: Model Scores Across Three Levels of Disciplines: o3-mini-2025-01-31-low."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 126 Table 26. Model Scores Across Three Levels of Disciplines: gemini-2.0-flash."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 127 Table 26. Continued: Model Scores Across Three Levels of Disciplines: gemini-2.0-flash."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 128 Table 27. Model Scores Across Three Levels of Disciplines: DeepSeek-V3."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 129 Table 27. Continued: Model Scores Across Three Levels of Disciplines: DeepSeek-V3."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 130 Table 28. Model Scores Across Three Levels of Disciplines: o1-mini-2024-09-12."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 131 Table 28. Continued: Model Scores Across Three Levels of Disciplines: o1-mini-2024-09-12."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 132 Table 29. Model Scores Across Three Levels of Disciplines: MiniMax-Text-01."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 133 Table 29. Continued: Model Scores Across Three Levels of Disciplines: MiniMax-Text-01."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 134 Table 30. Model Scores Across Three Levels of Disciplines: gpt-4o-2024-11-20."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 135 Table 30. Continued: Model Scores Across Three Levels of Disciplines: gpt-4o-2024-11-20."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 136 Table 31. Model Scores Across Three Levels of Disciplines: QwQ."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 137 Table 31. Continued: Model Scores Across Three Levels of Disciplines: QwQ."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 138 Table 32. Model Scores Across Three Levels of Disciplines: Llama-3.1-405B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 139 Table 32. Continued: Model Scores Across Three Levels of Disciplines: Llama-3.1-405B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 140 Table 33. Model Scores Across Three Levels of Disciplines: gpt-4o-2024-08-06."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 141 Table 33. Continued: Model Scores Across Three Levels of Disciplines: gpt-4o-2024-08-06."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 142 Table 34. Model Scores Across Three Levels of Disciplines: Qwen2.5-72B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 143 Table 34. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-72B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 144 Table 35. Model Scores Across Three Levels of Disciplines: Mistral-Large-Instruct-2411."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 145 Table 35. Continued: Model Scores Across Three Levels of Disciplines: Mistral-Large-Instruct-2411."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 146 Table 36. Model Scores Across Three Levels of Disciplines: qwen-max-2024-09-19."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 147 Table 36. Continued: Model Scores Across Three Levels of Disciplines: qwen-max-2024-09-19."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 148 Table 37. Model Scores Across Three Levels of Disciplines: gpt-4o-2024-05-13."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 149 Table 37. Continued: Model Scores Across Three Levels of Disciplines: gpt-4o-2024-05-13."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 150 Table 38. Model Scores Across Three Levels of Disciplines: Qwen2.5-32B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 151 Table 38. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-32B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 152 Table 39. Model Scores Across Three Levels of Disciplines: Llama-3.3-70B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 153 Table 39. Continued: Model Scores Across Three Levels of Disciplines: Llama-3.3-70B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 154 Table 40. Model Scores Across Three Levels of Disciplines: phi-4."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 155 Table 40. Continued: Model Scores Across Three Levels of Disciplines: phi-4."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 156 Table 41. Model Scores Across Three Levels of Disciplines: Qwen2.5-14B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 157 Table 41. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-14B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 158 Table 42. Model Scores Across Three Levels of Disciplines: Llama-3.1-70B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 159 Table 42. Continued: Model Scores Across Three Levels of Disciplines: Llama-3.1-70B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 160 Table 43. Model Scores Across Three Levels of Disciplines: Qwen2.5-72B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 161 Table 43. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-72B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 162 Table 44. Model Scores Across Three Levels of Disciplines: Yi-Lighting."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 163 Table 44. Continued: Model Scores Across Three Levels of Disciplines: Yi-Lighting."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 164 Table 45. Model Scores Across Three Levels of Disciplines: Qwen2.5-32B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 165 Table 45. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-32B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 166 Table 46. Model Scores Across Three Levels of Disciplines: DeepSeek-V3-Base."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 167 Table 46. Continued: Model Scores Across Three Levels of Disciplines: DeepSeek-V3-Base."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 168 Table 47. Model Scores Across Three Levels of Disciplines: Qwen2.5-14B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 169 Table 47. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-14B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 170 Table 48. Model Scores Across Three Levels of Disciplines: Mixtral-8x22B-Instruct-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 171 Table 48. Continued: Model Scores Across Three Levels of Disciplines: Mixtral-8x22B-Instruct-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 172 Table 49. Model Scores Across Three Levels of Disciplines: Qwen2.5-7B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 173 Table 49. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-7B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 174 Table 50. Model Scores Across Three Levels of Disciplines: Yi-1.5-34B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 175 Table 50. Continued: Model Scores Across Three Levels of Disciplines: Yi-1.5-34B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 176 Table 51. Model Scores Across Three Levels of Disciplines: gemma-2-27b-it."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 177 Table 51. Continued: Model Scores Across Three Levels of Disciplines: gemma-2-27b-it."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 178 Table 52. Model Scores Across Three Levels of Disciplines: Llama-3.1-70B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 179 Table 52. Continued: Model Scores Across Three Levels of Disciplines: Llama-3.1-70B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 180 Table 53. Model Scores Across Three Levels of Disciplines: Yi-1.5-34B-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 181 Table 53. Continued: Model Scores Across Three Levels of Disciplines: Yi-1.5-34B-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 182 Table 54. Model Scores Across Three Levels of Disciplines: Mistral-Small-Instruct-2409."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 183 Table 54. Continued: Model Scores Across Three Levels of Disciplines: Mistral-Small-Instruct-2409."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 184 Table 55. Model Scores Across Three Levels of Disciplines: Qwen2.5-7B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 185 Table 55. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-7B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 186 Table 56. Model Scores Across Three Levels of Disciplines: Llama-3.1-405B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 187 Table 56. Continued: Model Scores Across Three Levels of Disciplines: Llama-3.1-405B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 188 Table 57. Model Scores Across Three Levels of Disciplines: gemma-2-27b."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 189 Table 57. Continued: Model Scores Across Three Levels of Disciplines: gemma-2-27b."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 190 Table 58. Model Scores Across Three Levels of Disciplines: gemma-2-9b-it."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 191 Table 58. Continued: Model Scores Across Three Levels of Disciplines: gemma-2-9b-it."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 192 Table 59. Model Scores Across Three Levels of Disciplines: Qwen2.5-3B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 193 Table 59. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-3B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 194 Table 60. Model Scores Across Three Levels of Disciplines: Yi-1.5-9B-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 195 Table 60. Continued: Model Scores Across Three Levels of Disciplines: Yi-1.5-9B-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 196 Table 61. Model Scores Across Three Levels of Disciplines: Yi-1.5-9B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 197 Table 61. Continued: Model Scores Across Three Levels of Disciplines: Yi-1.5-9B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 198 Table 62. Model Scores Across Three Levels of Disciplines: gemma-2-9b."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 199 Table 62. Continued: Model Scores Across Three Levels of Disciplines: gemma-2-9b."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 200 Table 63. Model Scores Across Three Levels of Disciplines: K2-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 201 Table 63. Continued: Model Scores Across Three Levels of Disciplines: K2-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 202 Table 64. Model Scores Across Three Levels of Disciplines: Mixtral-8x22B-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 203 Table 64. Continued: Model Scores Across Three Levels of Disciplines: Mixtral-8x22B-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 204 Table 65. Model Scores Across Three Levels of Disciplines: Mixtral-8x7B-Instruct-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 205 Table 65. Continued: Model Scores Across Three Levels of Disciplines: Mixtral-8x7B-Instruct-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 206 Table 66. Model Scores Across Three Levels of Disciplines: Mixtral-8x7B-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 207 Table 66. Continued: Model Scores Across Three Levels of Disciplines: Mixtral-8x7B-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 208 Table 67. Model Scores Across Three Levels of Disciplines: K2."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 209 Table 67. Continued: Model Scores Across Three Levels of Disciplines: K2."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 210 Table 68. Model Scores Across Three Levels of Disciplines: granite-3.1-8b-instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 211 Table 68. Continued: Model Scores Across Three Levels of Disciplines: granite-3.1-8b-instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 212 Table 69. Model Scores Across Three Levels of Disciplines: Llama-3.1-8B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 213 Table 69. Continued: Model Scores Across Three Levels of Disciplines: Llama-3.1-8B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 214 Table 70. Model Scores Across Three Levels of Disciplines: Yi-1.5-6B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 215 Table 70. Continued: Model Scores Across Three Levels of Disciplines: Yi-1.5-6B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 216 Table 71. Model Scores Across Three Levels of Disciplines: Qwen2.5-3B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 217 Table 71. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-3B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 218 Table 72. Model Scores Across Three Levels of Disciplines: Llama-3.1-8B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 219 Table 72. Continued: Model Scores Across Three Levels of Disciplines: Llama-3.1-8B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 220 Table 73. Model Scores Across Three Levels of Disciplines: Mistral-7B-v0.3."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 221 Table 73. Continued: Model Scores Across Three Levels of Disciplines: Mistral-7B-v0.3."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 222 Table 74. Model Scores Across Three Levels of Disciplines: Yi-1.5-6B-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 223 Table 74. Continued: Model Scores Across Three Levels of Disciplines: Yi-1.5-6B-Chat."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 224 Table 75. Model Scores Across Three Levels of Disciplines: Qwen2.5-1.5B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 225 Table 75. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-1.5B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 226 Table 76. Model Scores Across Three Levels of Disciplines: OLMo-2-1124-13B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 227 Table 76. Continued: Model Scores Across Three Levels of Disciplines: OLMo-2-1124-13B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 228 Table 77. Model Scores Across Three Levels of Disciplines: gemma-2-2b-it."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 229 Table 77. Continued: Model Scores Across Three Levels of Disciplines: gemma-2-2b-it."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 230 Table 78. Model Scores Across Three Levels of Disciplines: granite-3.1-2b-instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 231 Table 78. Continued: Model Scores Across Three Levels of Disciplines: granite-3.1-2b-instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 232 Table 79. Model Scores Across Three Levels of Disciplines: Mistral-7B-Instruct-v0.3."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 233 Table 79. Continued: Model Scores Across Three Levels of Disciplines: Mistral-7B-Instruct-v0.3."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 234 Table 80. Model Scores Across Three Levels of Disciplines: Qwen2.5-1.5B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 235 Table 80. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-1.5B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 236 Table 81. Model Scores Across Three Levels of Disciplines: MAP-Neo-7B-Instruct-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 237 Table 81. Continued: Model Scores Across Three Levels of Disciplines: MAP-Neo-7B-Instruct-v0.1."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 238 Table 82. Model Scores Across Three Levels of Disciplines: OLMo-2-1124-7B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 239 Table 82. Continued: Model Scores Across Three Levels of Disciplines: OLMo-2-1124-7B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 240 Table 83. Model Scores Across Three Levels of Disciplines: granite-3.1-2b-base."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 241 Table 83. Continued: Model Scores Across Three Levels of Disciplines: granite-3.1-2b-base."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 242 Table 84. Model Scores Across Three Levels of Disciplines: OLMo-2-1124-13B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 243 Table 84. Continued: Model Scores Across Three Levels of Disciplines: OLMo-2-1124-13B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 244 Table 85. Model Scores Across Three Levels of Disciplines: MAP-Neo-7B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 245 Table 85. Continued: Model Scores Across Three Levels of Disciplines: MAP-Neo-7B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 246 Table 86. Model Scores Across Three Levels of Disciplines: granite-3.1-8b-base."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 247 Table 86. Continued: Model Scores Across Three Levels of Disciplines: granite-3.1-8b-base."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 248 Table 87. Model Scores Across Three Levels of Disciplines: OLMo-2-1124-7B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 249 Table 87. Continued: Model Scores Across Three Levels of Disciplines: OLMo-2-1124-7B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 250 Table 88. Model Scores Across Three Levels of Disciplines: gemma-2-2b."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 251 Table 88. Continued: Model Scores Across Three Levels of Disciplines: gemma-2-2b."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 252 Table 89. Model Scores Across Three Levels of Disciplines: Qwen2.5-0.5B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 253 Table 89. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-0.5B-Instruct."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 254 Table 90. Model Scores Across Three Levels of Disciplines: Qwen2.5-0.5B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents 255 Table 90. Continued: Model Scores Across Three Levels of Disciplines: Qwen2.5-0.5B."
        },
        {
            "title": "Back to List of Models",
            "content": "Back to Table of Contents"
        }
    ],
    "affiliations": [
        "2077.AI",
        "ByteDance.Inc"
    ]
}