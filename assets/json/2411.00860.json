{
    "paper_title": "Survey of Cultural Awareness in Language Models: Text and Beyond",
    "authors": [
        "Siddhesh Pawar",
        "Junyeong Park",
        "Jiho Jin",
        "Arnav Arora",
        "Junho Myung",
        "Srishti Yadav",
        "Faiz Ghifari Haznitrama",
        "Inhwa Song",
        "Alice Oh",
        "Isabelle Augenstein"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large-scale deployment of large language models (LLMs) in various applications, such as chatbots and virtual assistants, requires LLMs to be culturally sensitive to the user to ensure inclusivity. Culture has been widely studied in psychology and anthropology, and there has been a recent surge in research on making LLMs more culturally inclusive in LLMs that goes beyond multilinguality and builds on findings from psychology and anthropology. In this paper, we survey efforts towards incorporating cultural awareness into text-based and multimodal LLMs. We start by defining cultural awareness in LLMs, taking the definitions of culture from anthropology and psychology as a point of departure. We then examine methodologies adopted for creating cross-cultural datasets, strategies for cultural inclusion in downstream tasks, and methodologies that have been used for benchmarking cultural awareness in LLMs. Further, we discuss the ethical implications of cultural alignment, the role of Human-Computer Interaction in driving cultural inclusion in LLMs, and the role of cultural alignment in driving social science research. We finally provide pointers to future research based on our findings about gaps in the literature."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 0 3 ] . [ 1 0 6 8 0 0 . 1 1 4 2 : r Survey of Cultural Awareness in Language Models: Text and Beyond Siddhesh Pawar University of Copenhagen, Denmark Junyeong Park KAIST, Republic of Korea Jiho Jin KAIST, Republic of Korea Junho Myung KAIST, Republic of Korea Arnav Arora University of Copenhagen, Denmark Srishti Yadav University of Copenhagen, Denmark Faiz Ghifari Haznitrama KAIST, Republic of Korea Inhwa Song KAIST, Republic of Korea Alice Oh KAIST, Republic of Korea Isabelle Augenstein University of Copenhagen, Denmark Large-scale deployment of large language models (LLMs) in various applications, such as chatbots and virtual assistants, requires LLMs to be culturally sensitive to the user to ensure inclusivity. Culture has been widely studied in psychology and anthropology, and there has been recent surge in research on making LLMs more culturally inclusive in LLMs that goes beyond multilinguality and builds on findings from psychology and anthropology. In this paper, we survey efforts towards incorporating cultural awareness into text-based and multimodal LLMs. We start by defining cultural awareness in LLMs, taking the definitions of culture from anthropology and psychology as point of departure. We then examine methodologies adopted for creating cross-cultural datasets, strategies for cultural inclusion in downstream tasks, and methodologies that have been used for benchmarking cultural awareness in LLMs. Further, we discuss the ethical implications of cultural alignment, the role of Human-Computer Interaction in driving cultural inclusion in LLMs, and the role of cultural alignment in driving social science research. We finally provide pointers to future research based on our findings about gaps in the literature.1 1. Introduction Language models are deployed in various user-facing applications, such as recommender systems (Bao et al. 2023), customer service (Pandya and Holia 2023), and search applications (Xiong et al. 2024), which are increasingly used by people in all aspects of their life including education (Kasneci et al. 2023), public health (De Angelis et al. Equal contributions. E-mail: sipa@di.ku.dk, jjjunyeong9986@kaist.ac.kr 1 We additionally organize the papers covered by this survey at https://github.com/siddheshih/culture-awareness-llms.git. 2023), and professional writing (Jakesch et al. 2023a). These models reflect the Western perspective, predominantly trained on Western-centric data (Durmus et al. 2023). This skewed perspective can lead to stereotyping and alienation of users, propagation of stereotypes due to lack of cultural understanding (e.g., flattening of cultural identities), or responding in culturally insensitive way (Cao et al. 2022, 2023). Therefore, cultural awareness is one of the critical factors that should be considered while creating NLP models. In this work, we provide comprehensive survey of the steps that the NLP community has taken to make language models more culturally inclusive. Furthermore, with advancements in multimodal foundation models and their adaption on NLP tasks (Fei et al. 2022), we also examine efforts towards cultural inclusion in multimodal NLP systems (i.e., multimodal systems with language understanding as one of their components). As the notion of culture used by the NLP community (to define and ensure cultural inclusion in NLP systems) is adopted from social science research, we start by defining cultural awareness in LLMs based on definitions of culture in psychology and anthropology literature. We then consolidate the works that look into cultural inclusion in LLMs and multimodal models, including benchmark creation, training data creation, alignment methodologies, and evaluation methodologies. We also discuss the role of cultural alignment in accelerating social research. Human-computer interaction (HCI) also plays role in ensuring cultural alignment in LLMs, as how studying different cultures reacts to certain levels of cultural (mis)alignment and matching varied expectations of people falls under the realm of HCI research (Weidinger et al. 2023). Finally, we discuss the ethical and safety implications of current research directions and provide potential research avenues that the community could take to foster cultural inclusion in language models. While recent surveys (Liu, Gurevych, and Korhonen 2024; Adilazuarda et al. 2024) focus on the cultural alignment of LLMs in NLP and provide taxonomy for grouping current cultural alignment works, we consolidate the literature from broader scope. We survey and compare efforts towards incorporation and conceptualization of culture in NLP systems, and our survey spans several modalities, including images, videos, and audio, along with text. We position our survey at the intersection of NLP, multimodality, and social science. The key contributions and research goals of this survey are as follows: 1. We review 300+ papers to provide an overview of the current state of benchmarks and methods used for cultural inclusion in multimodal language models (we organize the papers in 4, 5, 6); 2. We provide an overview of common data sources used for creating cultural alignment datasets and how current benchmark creation and culturally relevant finetuning dataset creation methodologies leverage these common sources (3); we also discuss ethical implications and limitations of the dataset creation methodologies (8); 3. We provide an overview of the coverage of current datasets for geographical regions and cultures (7) and discuss measures that the community could take to foster equity in cultural inclusion (9); 4. We also examine the societal impact and implications of deploying LLMs with or without cultural awareness and discuss the role of Human-Computer Interaction (HCI) research in cultural alignment (8). Literature Collection Strategy. As our paper focuses on multimodal and text-based NLP, we consider papers published in conferences including ACL and regional ACL chapters, EMNLP, ICLR, and ICML, computer vision conferences such as ICCV and 2 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond CVPR as well as papers published in the ACL Anthology. The inclusion of cultural aspects in the NLP and CV community has been recent one, with most (benchmark) papers published post-2016, so we consider cultural inclusion benchmarks post-2016. We also consider recent submissions to Arxiv to include recent NLP and social science papers, as the publication cycles for social science journals are typically 13 years. For alignment methodologies, we specifically focus on recent works published after 2022, following the release of ChatGPT (OpenAI). We define culture in 2 and organize our paper into three major parts. The first part discusses data sources and methodologies the community has used to create datasets and benchmarks for the cultural inclusion of LLMs (3). The second part discusses the methodologies and state of benchmarks that have been used or created for improving cultural awareness in LLMs across modalities (4, 5, 6). Finally, we discuss our observations: the state of cultural inclusion (7), ethical issues related to cultural alignment, and the role of cultural alignment in accelerating social science research (8), and future research directions (9) in the last part. In each of the subsections in 4, 5, and 6, we identify specific research gaps and, based on the research gaps, provide concrete suggestions for future research in 9. 2. Definitions of Culture and Methodology Culture is complex construct and has been studied in psychology and anthropology with different considerations and assumptions. We adopt White (1959)s view of culture, as they consolidate its definitions from the psychological and anthropological perspectives, distinguishing between human behavior and the study of culture. The psychological perspective considers the study of human behavior as the central part of the analysis and sees culture as an extension of human behavior. One of the main goals of cultural psychology is to study changes in human behavior with respect to culture. The theory and methods in cultural psychology begin with the assumption that psychological processes are socioculturally grounded. On the other hand, the anthropological perspective sees culture as an abstraction of human behavior. The abstraction is necessary to discard unimportant details and focus on actual human interactions, depending on the context. Both perspectives are important when considering cultural awareness in LLMs: the anthropological perspective looks at understanding the context and interpreting different elements of tasks based on the context, while the psychological perspective deals with how to process the current information (task and the context) to produce response. The design of current LLMs is to mimic human behavior as closely as possible without consideration of the context (such as writing correct summary and seeing how factually correct it is rather than seeing how the summary would be based on the context, considering context would involve considering the knowledge level of the user, and the purpose of the summary). The context consists of social factors, which also form an important part of the language, and culture is one of the main components of social factors; for detailed discussion on modeling social factors of context into NLP systems, we refer the reader to Hovy and Yang (2021). The two perspectives on culture guide the factors to consider while designing culturally aware LLMs. From an anthropological perspective, culture is actions, things, and concepts viewed in the context of other actions and things. For instance, going for vote is just an act in itself; it gains significance when considered in the context of democracy, autocracy, etc. Thus, the definition of culture also considers other humans behaviors. The locus of culture (or understanding of the cultural context) consists of three dimensions: (1) 3 Within humans (such as concepts, traditions, beliefs, social practices, etc.), (2) Between social interaction among human beings, (3) Outside of humans but within the patterns of social interaction (in materialized objects such as tools, arts, etc.). Point (1) deals with actual actions, things, and concepts (cultural knowledge and morals), while Points (2) and (3) consider the context of the actions and concepts. The human dimension (Point 1) forms the basis for understanding the cultural elements of the task; the other two dimensions are important for generating relevant answers and when LLMs are used as agents. White (1959) groups together concepts and actions that form an identity of culture into broad category called elements of culture. These elements of culture have been studied in NLP under textual information tasks that are concerned with cultural commonsense knowledge, norms, values, morals, linguistic forms, etc., as well as visio-linguistic parts, such as concepts (and perceptions) associated with various (physical) objects and art forms. Research on cultural psychology has shown that various aspects of visual perception, such as perception of length, geometrical intuition, and depth, vary across people from different cultural backgrounds (Segall, Campbell, and Herskovits 1967; Jahoda and McGurk 1974). The variance of perception across cultures, in turn, affects how differences in cultural backgrounds affect the way that individuals attend to, understand, and talk about visual content (Nisbett and Masuda 2003). The variance of perspective necessitates cultural adaptation of images and captions generated by the models. The variance of perspective across cultures has been studied in psychology across five major categories: architecture, clothing, dance and music, food and drink, and religion (Halpern 1955). As the elements of culture and their perceptions in context vary vastly among cultures, it becomes necessary to study and model the variance in these elements across cultures to create culturally inclusive language technologies. Concerning LLMs and NLP systems in general, cultural awareness can be thought of as the ability to understand the context in which they are asked to perform particular task and how the context (and elements of culture in the context) varies with culture (cultural competence). Cultural awareness also includes the ability to understand the variance of cultural elements across different cultures. Understating the cultural context consists of two things: (a) Recognizing the social context in which task is performed and (b) based on the context, interpreting different elements of the task. Some tasks are context-sensitive, such as hate-speech detection (the definition of hate-speech varies from culture to culture as norms vary), while others are not (e.g., mathematical reasoning). Some recent works (e.g., AlKhamissi et al. (2024)) have defined cultural alignment with respect to the models views aligning with group of people representing culture; our definition of cultural awareness encompasses the definition of cultural alignment. So, when designing models for task (understanding the input and producing an output), the LLM first needs to understand the context (e.g., where it is deployed, what is the end goal, etc.) and then decide if culture needs to be considered for that particular task. To understand the concepts, the LLMs should broadly consider the relationship (for example, how to converse when writing an application letter as student), social context, and the containers of communications (such as the setup in which the LLM is deployed, the goal of the LLM) and demographics (Liu, Gurevych, and Korhonen 2024). The context can also be design choice while creating or fine-tuning LLM based on deployment goals (e.g., what data to collect and how the LLM will be used). For generalized LLMs, there is need to have the capability to understand the context in LLMs. Most efforts up until now have focused on creating context-specific datasets and benchmarks, and less effort has been focused on building and testing LLMs that automatically detect the context. 4 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Once the LLMs have recognized the context, the understanding of elements of the task and the response depends on cultural knowledge (e.g., the task: generate story with causal conversations happening in Korea depends on elements such as LLMs knowledge about the nature of causal conversations in Korea). We broadly use the term elements to include values, meaning of artifacts, and pragmatically motivated features relevant to the task. This raises the question: how do we enable LLMs to generate culturally appropriate responses and understand the cultural elements of task? Explicitly modeling cultural knowledge in LLMs has been explored as one potential approach. Cultural knowledge consists of various aspects such as norms, morals, values, common sense knowledge, linguistic forms, artifacts, concepts, and meanings associated with artifacts, etc. In this survey, we discuss the multiple methods the community has explored to add and evaluate the cultural knowledge in LLMs. The major body of literature focuses on adding cultural knowledge to training/fine-tuning/alignment data and evaluation benchmarks. The data sources for cultural knowledge include direct sources (e.g., sociological surveys, culture bank (Shi et al. 2024), etc.) or indirect sources, which include task-specific datasets in which cultural knowledge is implicitly but deliberately added. We discuss the creation of these sources in 3 and summarize task and usage-specific details in 4 for text-only datasets and in 5 and 6 for other modalities-based datasets. Most of the works in NLP look at cultures in isolation while modeling cross-cultural similarities and differences has received less attention (Hershcovich et al. 2022a). The study of cross-lingual similarities and differences has been central to cultural research in anthropology (Ember 2009). Modeling cross-cultural differences becomes an important aspect to consider while building multicultural datasets, as there is risk of flattening identities and erasing cultural boundaries if detailed culture-specific data is unavailable (this generally happens for under-represented cultures). Given the progress in creating generalized models, careful consideration should be given to monocultures and subcultures within culture. 3. Data Creation Methodology In this section, we examine the data source and creation methodology for culturespecific datasets and benchmarks. The dataset creation methodologies are organized into automatic pipelines (3.1), semi-automatic pipelines (3.2) and manual creation (3.3). Example benchmarks and datasets organized by data resource and dataset creation methodology are listed in Figure 1."
        },
        {
            "title": "3.1 Automatic Pipelines & Model-in-the-Loop",
            "content": "Most research focuses on automatic curation to gather cultural knowledge and create training data at scale, especially for pre-training. It primarily relies on publicly available multilingual large-scale corpora such as Wikipedia, CC100 (Conneau et al. 2020), mC4 (Xue et al. 2021), and CulturaX (Nguyen et al. 2024), which are processed raw web text corpora gathered from public web archives. These sources are then cleansed and filtered for specific cultures such as Korean (Yoo et al. 2024), Irish (Tran, OSullivan, and Nguyen 2024), Portuguese (Pires et al. 2023; Almeida et al. 2024), Arabic (Sengupta et al. 2023; Huang et al. 2024; Aloui et al. 2024), Chinese (Du et al. 2024), Taiwanese (Lin and Chen 2023), Persian (Abbasi et al. 2023), Thai (Pipatanakul et al. 2023), Romanian (Masala et al. 2024b), Basque (Etxaniz et al. 2024), Ukrainian (Kiulian et al. 2024), Ethiopian (Tonja et al. 2024), Indonesian (Owen et al. 2024; Cahyawijaya et al. 2024b), or 5 Created Manually Sourced From Web Creation Methodology Example Datasets & Benchmarks Experts RoCulturaBench (Masala et al. 2024b) TurkishMMLU (Yüksel et al. 2024) Crowdsourced BLEnD (Myung et al. 2024b) NORMBANK (Ziems et al. 2023) Crossmodal-3600 (Thapliyal et al. 2022) CVQA (Romero et al. 2024) CultureAtlas (Fung et al. 2024)** CultureBank (Shi et al. 2024)** CUNIT (Li et al. 2024g)* Wordscape (Weber et al. 2023)** NLP Datasets OMGEval (Liu et al. 2024b)* CulturalRecipes (Cao et al. 2024b)** KoBBQ (Jin et al. 2024)* Adapted From CV Datasets Food-500-cap (Ma et al. 2023)* M5 (Schneider and Sitaram 2024)* External Sources KMMLU (Son et al. 2024a) WorldValuesBench (Zhao et al. 2024) Generated with LLMs CULTURALBENCH-V0.1 (Chiu et al. 2024)* CULTURE-GEN (Li et al. 2024f)** SeeGULL (Jha et al. 2023)* Figure 1: Overview of the data creation methodologies and example datasets and benchmarks. Datasets and benchmarks created using semi-automatic and fully automatic pipelines are marked with * and **, respectively. even multiple cultures (ImaniGooghari et al. 2023; Nguyen et al. 2023c; Üstün et al. 2024). The refined data is subsequently used to train culture-specific LLMs that are tailored to the knowledge of these cultures. Current research has advanced by incorporating steps to improve data quality or increase data quantity using model-in-the-loop techniques. StereoKG (Deshpande et al. 2022) gathers cultural knowledge by mining questions and statements from Reddit and Twitter based on templates, then generates the structured triplets using OpenIE (Mausam 2016). CANDLE (Nguyen et al. 2023a) extracts high-quality cultural commonsense knowledge by building pipeline to filter cultural text corpora and classify them using fine-tuned models. Saulite et al. (2022) constructs LNCC from diverse Latvian language resources and automatically annotates them with uniform morphosyntactic annotation scheme. MANGO (Nguyen, Razniewski, and Weikum 2024) uses LLMs to generate cultural-specific knowledge using seed culture from CANDLE or concept from ConceptNet (Speer, Chin, and Havasi 2017), while CultureAtlas (Fung et al. 2024) collects and processes data from Wikipedia and its sources to form cultural knowledge frames. Automatic methods are also used to create instruction data, with some works utilizing LLMs to generate culturally-aligned synthetic data. The LLM_ADAPT dataset from Putri et al. (2024a) is created by asking LLM to culturally adapt the English 6 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond CommonsenseQA dataset (Talmor et al. 2019a) to Indonesian and Sundanese culture. CultureBank (Shi et al. 2024) gathers data from social media platforms and uses models to extract and cluster cultural descriptions. CRAFT (Wang et al. 2024a) collects cultural keywords, filters corpus chunks, and generates questions using LLMs. CultureLLM (Li et al. 2024b) seeds data from the World Values Survey (WVS, Survey (2022)) and augments them by generating semantically equivalent data and identifying replaceable components to be replaced by their synonyms. CulturePark (Li et al. 2024c) employs multi-agent framework for cross-cultural conversations based on specific questions initialized from the Pew Global Attitudes Survey (GAS, Center (2022)) and WVS, followed by self-calibration and quality assurance processes. X-Instruction (Li et al. 2024d) is cross-lingual instruction tuning dataset created with three-step pipeline that exploits the better generation performance of high-resource languages like English. Specifically, they use OpenAssistant Conversations corpus (Köpf et al. 2023) as seed data to generate instructions and use CulturaX (Nguyen et al. 2024) as multilingual corpus to refine the instructions. In summary, these cases demonstrate that combining LLM-generated synthetic data with culturally relevant sources like surveys and social media is common strategy for creating instruction datasets. Concerning computer vision models, automatic pipelines for data creation involve using geo-localized image datasets such as datasets from photo-sharing platforms such as Flikr, Google Photos, Pinterest (Kuznetsova et al. 2020), Wikimedia, Youtube, etc.; we categorize these sources as extracted using automatic pipelines because the geolocalized tags are already present when the dataset is being considered for cultural adaptation. The captions for the images are obtained from meta-data or using the associated text on Wikipedia (Srinivasan et al. 2021; Weber et al. 2023). The community has mostly used automatic pipelines to get the images, as captions obtained from metadata or from Wikipedia may not be reliable for creating benchmarks or datasets for cultural adaptation."
        },
        {
            "title": "3.2 Semi-Automatic: Human-in-the-Loop",
            "content": "Semi-automatic approaches combine human expert knowledge with machine processing to produce higher-quality datasets. Several recent works exemplify this methodology. For instance, the LLM_GEN dataset introduced by Putri et al. (2024a) begins with categories and concepts manually created by human annotators, which are then used to generate commonsense question-answering dataset. Similarly, Bai et al. (2024) developed COIG-CQIA, which relies on manually curated sources vetted by human experts to ensure the quality of Chinese instruction data before applying machine-based filtering and cleaning processes. Alyafeai et al. (2024) developed the Arabic instructiontuning dataset CIDAR by translating the AlpaGasus (Chen et al. 2024b) dataset using ChatGPT (OpenAI). They then go through manual cultural localization and review linguistic issues with native Arabic speakers. The STREAM framework (Wang et al. 2024f) provides an even higher degree of human intervention. In this approach, human annotators first provide moral values to guide Large Language Models (LLMs) in generating scenarios consisting of situations and actions. The generated results are then manually screened by human annotators. Subsequently, human annotators and LLMs are tasked with evaluating randomly selected scenarios, which are used to measure the alignment of LLMs with human judgments. These examples illustrate that semiautomatic approaches are moderate strategy, balancing quality and quantity by integrating human expertise with scalable machine processing. For vision-language models, semi-automatic and human-in-the-loop have been the most common way of creating benchmarks and datasets for cultural adaptation. One 7 of the methods includes using geolocalized images from photo-sharing platforms such as Flikr, Google Photos, Pinterest (Kuznetsova et al. 2020), Wikimedia, and Youtube, and then using local annotators to create variety of datasets (Thapliyal et al. 2022; Yin et al. 2021). Some works also use pre-existing computer vision benchmarks, such as ISIA Food-500 (Min et al. 2020), Dollar Street (Dubois et al. 2023), etc., and refine the captions (or related information such as questions in VQA) to include cultural information (Ma et al. 2023; Schneider and Sitaram 2024)."
        },
        {
            "title": "3.3 Manual: Handcrafted from Scratch",
            "content": "Manually crafted datasets, created from scratch by human experts and annotators, remain the gold standard regarding quality and alignment with human values. These datasets typically involve human participants creating instruction-response pairs that reflect common usage patterns, providing feedback on responses to given prompts, or contributing text in specific languages to build corpora. The nature of this process ensures high-quality outputs that are well-aligned with human expectations and linguistic nuances. However, the manual approach has limitations, particularly in terms of scalability. The resources required for human-generated datasets, including time and financial investments, often result in smaller datasets than those produced by automatic or semi-automatic methods. Despite these constraints, the value of handcrafted datasets is evident in various applications within natural language processing. For instance, Putri et al. (2024a) developed HUMAN_GEN dataset entirely from scratch, encompassing everything from category and concept ideation to constructing commonsense question-answering data. The quality of this dataset was maintained through rigorous evaluation by group of annotators. Manual creation is also important when cultural knowledge is not explicitly documented. Myung et al. (2024b) aims to capture everyday mundane knowledge often not documented online. Thus, the dataset was manually created by recruiting native annotators through crowdsourcing platform. In cases where the pool of annotators is limited, such as with North Korean annotators, they directly recruited participants without relying on crowdsourcing platforms. Similarly, in the case of low-resource languages, Le and Luu (2023) manually created parallel corpus for Central and Northern Vietnamese dialects with native dialect speakers. Furthermore, manual annotation is crucial for subjective tasks such as culturalspecific hate speech detection (Jeong et al. 2022) or inspiring content detection (Ignat, Lakshmy, and Mihalcea 2024). Several language models have leveraged handcrafted datasets to enhance their performance and cultural relevance. HyperClovaX (Yoo et al. 2024) utilized high-quality human-annotated Korean datasets for instruction tuning following pretraining. TaiwanLLM (Lin and Chen 2023) incorporated human instructions, multi-turn dialogues, and human feedback based on real user interactions that encompass Chinese cultural knowledge. In the Arabic language space, both AceGPT (Huang et al. 2024) and Jais (Sengupta et al. 2023) augmented their training data with native Arabic instructions as part of their supervised fine-tuning process. The value of handcrafted datasets is particularly pronounced in low-resource language settings. Models like Komodo (Owen et al. 2024) and Aya (Üstün et al. 2024) exemplify this approach, covering many languages, including some with extremely limited language resources. Komodo collaborated with local language experts to collect data for various local languages, while Aya extended this approach to 101 languages. These examples highlight that while leveraging handcrafted datasets has become popular strategy to enhance cultural relevance and performance, there remains significant research gap in systematically developing 8 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond high-quality datasets for underrepresented languages, pointing to future direction of broader dataset creation efforts across diverse linguistic and cultural contexts. For vision-language data, manual data collection methods include starting with an initial list of questions and concepts and asking the annotators to search relevant images on the internet (Baek et al. 2024; Wang et al. 2024g) followed by processing of images to create various types of benchmarks (e.g., Captioning, VQA, Image retrieval, etc.). Native annotators can also drive the cultural topics and objects to prioritize objects and concepts with significant cross-cultural differences (Wang et al. 2024g). Most of the video and speech datasets are also created manually, where annotators annotate emotions on curated videos or web series (Amiriparian et al. 2024b; Zhao et al. 2022). There have been few examples in the literature where annotators are asked to click the relevant photos based on initial concepts (Romero et al. 2024). Searching for culture-related photos can be limited since only aesthetically pleasing images are often uploaded to the internet, leading to lack of photos with everyday objects and common sense knowledge. Also, because not all cultures have significant online presence, it could possibly be discriminative towards certain cultures (Liu et al. 2022d). In the upcoming sections, we discuss how data-creation methodologies discussed in this section have been used for creating task-specific data and cultural alignment of language and vision models. 4. Language Models and Culture There has been growing recognition of the cultural biases, stereotypes, and lack of diverse cultural knowledge present in LLMs (Hershcovich et al. 2022b; Navigli, Conia, and Ross 2023). Those issues directly lead to problems, particularly in applications like dialogue systems, where LLMs may overlook users cultural backgrounds, potentially leading to inaccurate information or the reinforcement of cultural stereotypes. To address these limitations and make LLMs more culturally inclusive, two key approaches have emerged: a) pre-training and fine-tuning models with culturally relevant data, and b) employing prompt-based methods that do not require retraining. Section 4.1 provides detailed explanation of these methods, focusing on how they aim to enhance LLMs cultural adaptability. Furthermore, there is increasing attention toward developing benchmarks and evaluation frameworks that measure how well LLMs align with diverse cultural contexts. Section 4.2 elaborates on these benchmarks and evaluation frameworks. However, both alignment methodologies and evaluation techniques remain fragmented, with no universally established standards."
        },
        {
            "title": "4.1 Cultural Alignment: Methodologies and Goals",
            "content": "Cultural alignment refers to the process of aligning an AI system with the set of shared beliefs, values, and norms of the group of users that interact with the system, as defined by Masoud et al. (2023) based on the foundational works of Hofstede, Hofstede, and Minkov (2010) and Bennett III, Fadil, and Greenwood (1994). The importance of cultural alignment was demonstrated by Masoud et al. (2023) through their Cultural Alignment Test (Hofstedes CAT), which revealed that current LLMs struggle to fully comprehend cultural values. Their research suggested that this limitation could be addressed through fine-tuning models with culture-specific language. Complementary studies by Li et al. (2024f) and Tao et al. (2024) reached similar conclusions, though their findings emphasized the effectiveness of prompting techniques for achieving cultural alignment. Given the importance of these findings, we examine the current state of cul9 tural alignment in AI systems through two distinct perspectives. First, we analyze the methodologies for achieving cultural alignment, focusing on two primary approaches: model training and prompting techniques. Second, we explore how different cultural objectives influence and shape alignment efforts. In this section, we discuss the methodologies used for cultural alignment. In general, cultural alignment can be done through two approaches: training-based (4.1.1) and training-free (4.1.2). In addition, there are goal-based alignment methods for specific goals, such as content moderation (4.1.3). The papers are organized in Figure 2."
        },
        {
            "title": "4.1.1 Training-Based Methods. Training a language model is one way to achieve cul-\ntural alignment. The key differentiating factor in this approach lies in the training data,\nwhich must contain culturally relevant knowledge, norms, and values specific to the\ntarget culture, as previously discussed in section 3.",
            "content": "The training of language models for cultural alignment can be broadly categorized into two main approaches: pre-training and fine-tuning. Pre-training is the step where we train the model through large corpus to learn the general features of the data, which, for the purpose of cultural alignment, includes culture-specific knowledge, norms, and values obtained inside. Pre-training can be further categorized into two strategies: initiating pre-training from scratch using culturally relevant data, or continuing from an existing pre-trained LLM. Pre-training the model from scratch is expensive, as result of training the whole model parameters and the large size of the data. Therefore, not lot of cultural alignment is done with this method, as only HyperClovaX (Yoo et al. 2024), PersianLLaMA (Abbasi et al. 2023), and JASMINE (Billah Nagoudi et al. 2023) have done the pre-training from scratch. Continued pre-training is another way of pre-training, which involves taking an existing pre-trained model and training it further on culturally relevant data. This method has two key advantages: it avoids the computational expense of pre-training from scratch, and it requires only raw text data rather than the labeled datasets needed for supervised fine-tuning. There are lot of works that incorporate continued pretraining as part of their cultural alignment effort as shown by lot of culture-specific LLM (Tran, OSullivan, and Nguyen 2024; Nguyen et al. 2023c; Lin and Chen 2023; Owen et al. 2024; Pipatanakul et al. 2023; Pires et al. 2023; Huang et al. 2024; Sengupta et al. 2023; Tonja et al. 2024; Masala et al. 2024a; Etxaniz et al. 2024) using continued pre-training. Fine-tuning for cultural alignment involves further training pre-trained model using culturally relevant labeled datasets. Unlike continued pre-training, which uses raw text data, fine-tuning utilizes data specifically labeled for the intended task. This approach can be applied to task-specific objectives such as hate-speech detection and emotion classification or to general-purpose applications like instruction-following and conversational abilities. Instruction-tuning, specific form of fine-tuning that uses instruction-response pairs, has been widely adopted by researchers developing culturespecific LLMs (Yoo et al. 2024; Lin and Chen 2023; Owen et al. 2024; Huang et al. 2024; Cahyawijaya et al. 2024b; Sengupta et al. 2023; Masala et al. 2024a; Nguyen et al. 2023c; Bai et al. 2024). Another work that leverages instruction-tuning is from Zhang et al. (2024g), which proposes rapid adaptation method for large models in specific cultural contexts based on specific cultural knowledge and safety values data. Recent research (Li et al. 2024c,b; Wang et al. 2024a; Shi et al. 2024) demonstrates that instructiontuning enables models to effectively reason across multiple cultures in conversations. Additionally, Bhatia and Shwartz (2023) showed that fine-tuning on CANDLE data 10 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Pre-training Training-based Supervised Fine-tuning Pre-training from Scratch HyperClovaX (Yoo et al. 2024)* PersianLLaMA (Abbasi et al. 2023)* JASMINE (Billah Nagoudi et al. 2023)* Continue Pre-training UCCIX (Tran, OSullivan, and Nguyen 2024)* SeaLLM (Nguyen et al. 2023c)* TaiwanLLM (Lin and Chen 2023)* Komodo (Owen et al. 2024)* Typhoon (Pipatanakul et al. 2023)* Sabiá (Pires et al. 2023)* AceGPT (Huang et al. 2024)* Jais (Sengupta et al. 2023)* EthioLLM (Tonja et al. 2024)* RoLLM Masala et al. (2024a)* Etxaniz et al. (2024) Instruction-tuning Cendol (Cahyawijaya et al. 2024b)* Bai et al. (2024) Wang et al. (2024a) Li et al. (2024c) Li et al. (2024b) Shi et al. (2024) Zhang et al. (2024g) Bhatia and Shwartz (2023) Task-specific Offensive Language Detection: Zhou et al. (2023b) Emotion Analysis: Kim et al. (2024c) Ethical Judgment: Shen, Geng, and Jiang (2022) Hate Speech Detection: Dehghan and Yanıko glu (2024); Singh and Thakur (2024) Others Modular Pluralism: Feng et al. (2024) Unsupervised Learning: Li, Huang, and Shao (2024) Preference-tuning: Jinnai (2024) Cultural Alignment Methdologies Anthropological Prompting AlKhamissi et al. (2024) Training-free Cultural Prompting Tao et al. (2024) Sociodemographic Prompting Li et al. (2024f) Deshpande et al. (2023) Santurkar et al. (2023) Hwang, Majumder, and Tandon (2023) Cheng, Durmus, and Jurafsky (2023) Zhou et al. (2024) Shen et al. (2024) Content Moderation: Chan et al. (2023) Dataset Construction: Hasan et al. (2024) Response Diversity: Lahoti et al. (2023a) Hayati et al. (2023) Bias Mitigation: Lee et al. (2023a); Zhao et al. (2023); Narayan et al. (2024); Khandelwal et al. (2024a) Goal-specific Figure 2: Cultural alignment methodologies for language models based on methodologies and goals. Model names are marked with *. 11 (Nguyen et al. 2023b) allows models to both capture and generate culturally nuanced commonsense knowledge. Many works also show positive impact on various cultural alignment applications by doing task-specific fine-tuning. For offensive language detection, Zhou et al. (2023b) achieved effective results by fine-tuning models on cultural value survey data. In hate speech detection, which is deeply intertwined with cultural context, researchers have employed diverse approaches. Dehghan and Yanıko glu (2024) apply dual-contrastive learning when fine-tuning and incorporating paralinguistic features such as emoji, while Singh and Thakur (2024) use federated approach that utilizes continuous adaptation and fine-tuning to detect hate speech that is highly affected by cultural nuances. In emotion analysis, Kim et al. (2024c) achieved promising results in moral emotions classification, where the model utilizes information on moral emotions embedded in the data and can perceive different emotions for different cultures. For ethical judgment, Shen, Geng, and Jiang (2022) involved grounding complex narrative situations with social norms using pre-trained encoder-decoder and integrating these norms with classification model. Beyond pre-training and fine-tuning, some innovative approaches offer unique perspectives on training-based alignment. One such approach is Modular Pluralism (Feng et al. 2024), which employs smaller language models alongside larger ones to guide them in incorporating cultural knowledge and values into their responses according to the given cultural context. From an unsupervised perspective, Li, Huang, and Shao (2024) utilizes an adaptive context-aware unsupervised learning framework to convert between traditional and simplified Chinese characters, which is an important aspect of understanding Chinese culture. There is also study by Jinnai (2024) that uses preference-tuning through Direct Preference Optimization (DPO) (Rafailov et al. 2023) instead of fine-tuning to investigate how cross-cultural alignment affects an LLMs commonsense morality. Several works have investigated the actual impact of training for cultural alignment. Mukherjee et al. (2024a) found that while there are improvements in terms of cultural competence, they still fall short, particularly in non-western contexts. They highlight the need to incorporate more than the target language during the training process. Ladhak et al. (2023) find that while pre-training can make the model aligned with the specific culture, the resulting model can possess bias contained in the pre-training data. They also find that fine-tuning with smaller parameters, such as adapter-fine-tuning techniques like LoRA, provides better generalization and debiasing rather than training the entire model. Choenni, Lauscher, and Shutova (2024) investigate how cultural value shifts during fine-tuning, and find that language has minor role in cultural shifts and positively affects alignment with human values, but it varies considerably across languages."
        },
        {
            "title": "4.1.2 Training-Free Methods. Cultural alignment in language models can be achieved\nwithout additional training, primarily through prompting techniques. Research by\nAlKhamissi et al. (2024); Zhou et al. (2024); Arora, Kaffee, and Augenstein (2023)\ndemonstrates that cultural alignment is influenced by the training data and the prompts\nused during inference. AlKhamissi et al. (2024) observed that models exhibit stronger\ncultural alignment when prompted in a culture-specific language. Building on this\ninsight, they introduced anthropological prompting, incorporating anthropological rea-\nsoning aspects into the prompt to enhance cultural alignment. Another promising ap-\nproach is the Collective, Critique, and Self-Voting (CCSV) method, which is proposed by\nLahoti et al. (2023b). Their findings suggest that language models can comprehend the",
            "content": "12 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond concept of diversity and are capable of reasoning about and critiquing their responses to improve cultural diversity in their outputs. Tao et al. (2024) also propose prompt methodology called cultural prompting, which instructs the language model to answer like person from another society. They investigated the method by comparing the model responses to nationally representative survey data and found cultural prompting works quite well to increase the alignment of the model with the nationally representative survey data. Sociodemographic prompting has gained widespread attention among researchers for cultural alignment (Deshpande et al. 2023; Santurkar et al. 2023; Hwang, Majumder, and Tandon 2023; Cheng, Durmus, and Jurafsky 2023; Zhou et al. 2024; Li et al. 2024f; Shen et al. 2024). This method involves enriching prompts with sociodemographic information or cultural context, expecting that the models output will align with the information given in the prompt. Sociodemographic prompting has shown potential in applications such as data augmentation (Hartvigsen et al. 2022) and social computing simulation (Park et al. 2022). However, concerns have been raised regarding the robustness of sociodemographic prompting. Mukherjee et al. (2024b) found that most models exhibit similar variations in response to culturally conditioned cues as they do to non-cultural ones, particularly in terms of eliciting cultural bias. Similarly, Beck et al. (2024) observed that model outcomes vary significantly across different model types, sizes, and datasets. These findings suggest that sociodemographic prompting should be employed cautiously, especially in sensitive applications."
        },
        {
            "title": "4.1.3 Goal-Specific Alignment Strategies. In this section, we discuss works that have\nbeen done specifically to test and improve cultural alignment in language models for\nparticular goals.",
            "content": "Chan et al. (2023) train large language models on extensive datasets of media news and articles to create culturally attuned models for content moderation; the goal is to capture the nuances of communication and offensive content across cultures. Lahoti et al. (2023a) propose metrics to measure diversity in LLM-generated responses along people and culture axes and propose new prompting technique to self-improve people diversity of LLMs. On similar lines, Hayati et al. (2023) propose step-by-step recall prompting-based method to increase the diversity of responses (with cultural diversity increase being one of the outcomes). Lee et al. (2023a) provide (fine-tuning) dataset specific to Korean culture for mitigating social bias in generated content. Zhou et al. (2023b) studies the importance of cultural features in determining the success of transfer learning in the case of offensive language detection. Khandelwal et al. (2024a) provide dataset of Indian stereotypes and anti-stereotypes and propose interventions to reduce both stereotypical and anti-stereotypical biases in language models, thereby aligning them with Indian Culture. Narayan et al. (2024) proposes framework to quantify and mitigate biases within LLMs by creating new metric that detects, measures, and mitigates racial and cultural biases in LLMs without reliance on demographic annotations. Hasan et al. (2024) propose language-independent framework to construct culturally and regionally aligned QA datasets in native languages for LLM evaluation and demonstrate the efficacy of the framework by designing multilingual natural QA dataset, MultiNativQA, consisting of around 64k manually annotated QA pairs in seven languages, ranging from high to extremely low resources, based on queries from native speakers from 9 regions covering 18 topics. Zhao et al. (2023) introduce CHBias, dataset for bias evaluation and mitigation of Chinese conversational language models with culture-specific biases. 13 NLP Evaluation Academic Knowledge (4.2.1) Commonsense Knowledge (4.2.2) Social Values (4.2.3) Social Norms and Morals (4.2.4) Social Bias and Stereotype (4.2.5) Toxicity and Safety (4.2.6) Emotional and Subjective Topics (4.2.7) Linguistics (4.2.8) Figure 3: An overview of domains of text-based culturally-aware benchmarks Takeaways from 4.1. Various alignment methods, such as continued pretraining, fine-tuning, instruction tuning, and prompt tuning, are used to create more culturallyaware LLMs. However, most efforts are concentrated on aligning LLMs with individual local cultures, with limited research dedicated to developing cross-cultural LLMs that encompass comprehensive knowledge of multiple cultures. More work is needed in this area to enhance cross-cultural understanding in LLMs."
        },
        {
            "title": "4.2 Benchmarks and Evaluation",
            "content": "In this section, we provide an overview of various benchmarks designed to assess cultural elements through text-based tasks. The cultural elements are categorized into eight domains as specified in Figure 3. The Academic Knowledge section (4.2.1) focuses on evaluating knowledge sourced from human educational materials. The Commonsense Knowledge section (4.2.2) covers diverse datasets and benchmarks that assess general cultural knowledge, such as food, family, holidays, sports, and entertainment. In the Social Values section (4.2.3), social science studies are used to evaluate LLMs alignment with human social values. The Social Norms and Morals section (4.2.4) examines specific cultural norms and morals, exploring how these values shift depending on the social context. In the Social Bias and Stereotypes section (4.2.5), the focus is on adapting bias benchmarks to local languages and cultures, expanding to cross-cultural perspectives. The Toxicity and Safety section (4.2.6) addresses offensive and hate speech detection in local languages and cultures. The Emotional and Subjective Topics section (4.2.7) explores psychological cultural difference including emotion prediction, sentiment analysis and subjective topic classification. Lastly, the Linguistics section (4.2.8) delves into how culture is reflected in language, the ways language varieties and literary forms embody cultural elements, and how translation and dialogue systems can become more culturally aware. Each cultural element is evaluated through element-specific approaches. For instance, commonsense knowledge is typically assessed using multiple-choice questions (MCQ) or short-answer questions that require cultural knowledge. Meanwhile, social values are often examined using sociological surveys like the World Values Survey (WVS) to test cross-cultural differences in LLMs understanding of social values."
        },
        {
            "title": "4.2.1 Academic Knowledge. Human educational resources such as exam questions or\ntextbooks are being utilized to assess language understanding and general knowledge\ncapability of LLMs. For instance, the MMLU dataset (Hendrycks et al. 2021) is sourced\nfrom practice exam questions, such as Graduate Record Examination (GRE). This\ndataset is commonly used to evaluate LLMs’ language understanding and problem-\nsolving abilities across various domains, including STEM, humanities, social science.\nAmong these academic domains, fields such as history, law and literature in particular,\noften require knowledge specific to certain region. Thus, benchmarks have been de-",
            "content": "14 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond MMLU Series ArabicMMLU (Koto et al. 2024a); CMMLU (Li et al. 2024e); IndoMMLU (Koto et al. 2023); JMMLU (Yin et al. 2024); KMMLU (Son et al. 2024a); TurkishMMLU (Yüksel et al. 2024); PersianMMLU (Ghahroodi et al. 2024) Academic Knowledge Medical Knowledge K-NLEKMD (Jang et al. 2023); CMB (Wang et al. 2024e) Others KorNAT (Lee et al. 2024a); INVALSI (Mercorio et al. 2024); FoundaBench (Li et al. 2024h); M3Exam (Zhang et al. 2023) Figure 4: Academic Knowledge Evaluation Benchmarks Languages Evaluation method Creation method Educational stages Domains Size(k) Cultural question ratio(%) MMLU (Hendrycks et al. 2021) English MCQ Manually created ArabicMMLU (Koto et al. 2024a) Modern Standard Arabic MCQ Manually created CMMLU (Li et al. 2024e) Mandarin Chinese MCQ Manually created IndoMMLU (Koto et al. 2023) Indonesian and local languages MCQ Manually created by experts Elementary High school College Professional Primary school Middle school High school University Professional Primary school Middle/high school College Professional Primary school Junior high school Senior high school University JMMLU (Yin et al. 2024) Japanese MCQ Adapted from MMLU and manually created by experts Elementary High school College Professional KMMLU (Son et al. 2024a) Korean MCQ Automatically extracted Expert TurkishMMLU (Yüksel et al. 2024) Turkish MCQ Manually created by experts High school Humanities Social Science STEM Humanities Social Science STEM Language Humanities Social Science STEM Humanities Social Science STEM Indonesian Language Local Languages Local Cultures Humanities Social Science STEM Humanities Social Science STEM Applied Science Humanities Social Science Math Natural Sciences Language PersianMMLU (Ghahroodi et al. 2024) Persian MCQ Automatically extracted Lower primary school, Upper primary school, Lower secondary school, Upper secondary school Humanities Social Science Natural Science Mathematics Table 1: Details of MMLU-series benchmarks. 15.9 - 14.5 57.7 11. 25.3 14.9 46 7.5 - 20.4 10 20 - - veloped from local educational materials to evaluate regional knowledge. The overall hierarchy of the papers in this section is specified in Figure 4. One of the shortcomings of the MMLU dataset is that it primarily focuses on knowledge related to the United States. Addressing this, the dataset has been adapted into several linguistically and culturally specific benchmarks, including ArabicMMLU (Koto et al. 2024a), CMMLU (Li et al. 2024e), IndoMMLU (Koto et al. 2023), JapaneseMMLU (JMMLU (Yin et al. 2024), KMMLU (Son et al. 2024a), TurkishMMLU (Yüksel et al. 2024), and PersianMMLU (Ghahroodi et al. 2024). In particular, IndoMMLU also includes nine local cultures and eight local languages in Indonesia and ArabicMMLU is sourced from eight different countries in North Africa, the Levant, and the Gulf. The details about MMLU-series benchmarks are specified in Table 1. 15 All benchmarks are built in multiple-choice questions (MCQ) format, although the number of candidate answers vary. Most benchmarks are built based on local exam questions and educational materials, with the exception of JMMLU (Yin et al. 2024), which is is partially composed of translated questions from MMLU dataset (Hendrycks et al. 2021). Although the benchmarks encompass diverse range of knowledge from K-12 education to professional and even industrial knowledge, each benchmark is split into different educational stages because each country has different educational curricula. KMMLU (Son et al. 2024a) and TurkishMMLU, are specialized for expertlevel and high school-level questions respectively. Beyond the MMLU-series benchmarks, KorNAT (Lee et al. 2024a), INVALSI (Mercorio et al. 2024), and FoundaBench (Li et al. 2024h) are created to test educational knowledge in South Korea, Italy, and China respectively. KorNAT (Lee et al. 2024a) includes social value and common knowledge datasets. Specifically, the common knowledge dataset is developed based on the national compulsory education curriculum, covering seven subjects from the Korean GED syllabus. All questions are manually created by rephrasing the reference materials to MCQ format questions. Similarly, the INVALSI benchmark (Mercorio et al. 2024) is structured based on the INVALSI test, popular educational assessment criteria across Italy. The INVALSI test includes various domains, including mathematics, but it especially focuses on assessing students linguistic proficiency through various tasks. It consists of both MCQ and multiple complex choice questions (MCCQ) format. Half the questions in FoundaBench (Li et al. 2024h) evaluate Chinese K-12 subject knowledge. K-12 education in China refers to compulsory primary and secondary education in China. Other than collecting questions from Chinese academic exams, they also automatically generate questions with GPT-4 (OpenAI 2023). For automatic generation, they first extract key contents from collected documents, then manually formulate and refine optimal prompts through several iterations. The M3Exam (Zhang et al. 2023) specifically focuses on evaluating LLMs in multilingual context. It includes nine languages from high-resource languages like English and Chinese, to extremely low-resource languages such as Javanese, each reflecting distinct cultural background. They recruit native speakers from each region to manually collect official graduation exams in primary, middle, and high school. In the medical domain, CMB (Wang et al. 2024e) and K-NLEKMD (Jang et al. 2023) evaluate region-specific medical knowledge in Korea and China. Medical knowledge is often shaped by regional factors such as climate, diet, and ethnicity, leading to unique medical systems in each country. CMB (Wang et al. 2024e) is comprehensive medical benchmark in Chinese that covers six categories of medical knowledge, including Physician, Nurse and Pharmacist domains. The questions are sourced from publicly available exam questions with solutions provided by medical experts. K-NLEKMD (Jang et al. 2023) assesses language models decision-making skills in Traditional Korean Medicine (TKM) using the Korean national licensing examination for Korean medicine doctors. Takeaways from 4.2.1. Local educational resources, such as exams, are being leveraged to develop cultural knowledge evaluation benchmarks. However, subjects like mathematics typically cover more general knowledge, leading to the need of identifying culturally-specific questions within these benchmark. While some studies have identified tasks or questions that require culture-specific information (Li et al. 2024e; Son et al. 2024a), there is still lack of clarity regarding what specific cultural information is needed. Providing this cultural context could aid in the creation of more robust crosscultural knowledge benchmarks. 16 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Commonsense Knowledge China CIF-Bench (Li et al. 2024k); FoundaBench (Li et al. 2024h) Indonesia COPAL-ID (Wibowo et al. 2024); IndoCulture (Koto et al. 2024b); Leong et al. (2023); Putri et al. (2024b) Monoculture South Korea CLIcK (Kim et al. 2024a); HAE-RAE Bench (Son et al. 2024b) Others AraDiCE (Mousi et al. 2024); BERTAQA (Etxaniz et al. 2024); DOSA (Seth et al. 2024); RoCulturaBench (Masala et al. 2024b); Chang et al. (2024); Watts et al. (2024) Multiculture Monolingual Multilingual CANDLE CCSK (Nguyen et al. 2023a); CAMeL (Naous et al. 2023); CultureAtlas (Fung et al. 2024); CULTURALBENCH-V0.1 (Chiu et al. 2024); CULTURE-GEN (Li et al. 2024f); CUNIT (Li et al. 2024g); CPopQA (Jiang and Joshi 2024); DLAMA-v1 (Keleg and Magdy 2023); EnCBP (Ma et al. 2022); FORK (Palta and Rudinger 2023); Global-Liar (Mirza et al. 2024) BABEL BRIEFINGS (Leeb and Schölkopf 2024); BLEnD (Myung et al. 2024b); CALMQA (Arora et al. 2024); CulturalRecipes (Cao et al. 2024b); FMLAMA (Zhou et al. 2024); GEOMLAMA (Yin et al. 2022); MAPS (Liu et al. 2024a); MultiNativQA (Hasan et al. 2024); OMGEval (Liu et al. 2024b); SeaEval (Wang et al. 2024b); Manvi et al. (2024); Shen et al. (2024); Shwartz (2022); Wang et al. (2024d) Figure 5: Cultural commonsense knowledge evaluation benchmarks"
        },
        {
            "title": "4.2.2 Commonsense Knowledge. Evaluating commonsense knowledge has been\nwidely recognized as a fundamental task in natural language understanding sys-\ntems (Davis and Marcus 2015). To address this, commonsense knowledge bases\nlike ConceptNet (Speer, Chin, and Havasi 2017) and various commonsense reason-\ning and knowledge datasets, including COPA (Roemmele, Bejan, and Gordon 2011),\nSWAG (Zellers et al. 2018), and CommonsenseQA (Talmor et al. 2019b), have been\ndeveloped. However, existing datasets often focus on Western commonsense knowl-\nedge, overlooking regional differences. In this section, we will discuss commonsense\nknowledge benchmarks that are developed to address this gap. We organize the papers\naccording to their focus on culture and languages. Some benchmarks focus on a single\nculture, while others address cross-cultural differences by constructing multicultural\nbenchmarks. The overall hierarchy of the papers in this section is specified in Figure\n5. The academic and commonsense knowledge are evaluated with various methods\nspecified in Table 2.",
            "content": "Culture-specific Benchmarks. Cultural-specific commonsense knowledge benchmarks have been developed for various geographical regions and countries, including Indonesia (Koto et al. 2024b; Leong et al. 2023; Putri et al. 2024b; Talmor et al. 2019b; Wibowo et al. 2024), China (Li et al. 2024h,k), Korea (Kim et al. 2024a; Son et al. 2024b), Taiwan (Chang et al. 2024), India (Seth et al. 2024), Romania (Masala et al. 2024b), Basque Country (Etxaniz et al. 2024), and Arabic regions (Mousi et al. 2024). Each benchmark aims to capture the unique cultural knowledge of the target region. Indonesias diverse local cultures and languages have led to creation of various benchmarks. IndoCulture (Koto et al. 2024b) is designed to assess cultural knowledge 17 Question Answer Example Dataset/Benchmarks During Chinese New Year, red envelopes are given by the married to the unmarried. TRUE CultureAtlas (Fung et al. 2024) Global-Liar (Mirza et al. 2024) Evaluation Method Binary QA MultipleChoice QA What is the most common spice/herb used in dishes from Greece? A. BlackPepper B. Cumin C. Epazote D. Oregano D. Oregano Mask Filling In traditional American weddings, the color of wedding dress is usually [MASK]. White FoundaBench (Li et al. 2024h) CULTURALBENCH-V0.1 (Chiu et al. 2024) BLEnD (Myung et al. 2024b) CAMeL (Naous et al. 2023) DLAMA-v1 (Keleg and Magdy 2023) GEOMLAMA (Yin et al. 2022) Short Answer Generation Long Form Generation Which is the biggest lake in Nepal? The largest lake in Nepal is Rara Lake in Karnali Province. BLEnD (Myung et al. 2024b) MultiNativQA (Hasan et al. 2024) When person walks home late at night, why is it said that they should throw stone as far as they can before entering their house? The idea of throwing stone before entering your house late at night is rooted in folklore, superstition, and... CULTURE-GEN (Li et al. 2024f) CAMeL (Naous et al. 2023) OMGEval (Liu et al. 2024b) Table 2: Evaluation methods in academic and commonsense knowledge benchmarks Figure 6: Total Number of Academic and Commonsense Knowledge Benchmark Papers by Evaluation Method (2022 2024) across eleven Indonesian provinces using sentence completion task. Each sample is in multiple-choice format, providing one-sentence premise with three plausible options and one correct answer. The dataset is manually created with the help of native speakers and covers twelve predefined topics spanning local customs and knowledge. COPALID (Wibowo et al. 2024) follows COPAs (Roemmele, Bejan, and Gordon 2011) commonsense causal reasoning format. It also has manually created the dataset in which the local residents are involved to capture local cultural nuances, including local customs, terminology, and language nuances; this dataset is presented in standard Indonesian and Jakartan Indonesian. Leong et al. (2023) similarly develops cultural diagnostics dataset with native speakers to evaluate basic cultural knowledge in Indonesian and Tamil languages. They categorize cultural knowledge into language, literature, history, and customs. To evaluate LLMs, they use free-form generation prompts and analyze each response qualitatively. In contrast, Putri et al. (2024b) build MCQ dataset in Indonesian and Sundanese languages by applying three different dataset generation methods. They first automatically adapt English CommonsenseQA (Talmor et al. 2019b) dataset into target languages with LLMs. Also, they manually construct the questions 18 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond with native speakers, and use LLMs to generate additional data based on the manually defined list of categories and concepts. In China, FoundaBench (Li et al. 2024h) and CIF-Bench (Li et al. 2024k) are developed. While half of the questions in FoundaBench evaluate K-12 academic knowledge, the other half are related to commonsense knowledge. Similar to the academic knowledge section of the dataset, they collect questions from Internet resources and automatically generate questions using GPT-4 (OpenAI 2023). However, for commonsense knowledge questions, they additionally gather questions from online users about traditional Chinese culture and their life experiences. CIF-Bench evaluates the zero-shot generalizability of LLMs in Chinese across 150 tasks. Of these, 113 tasks are adapted from existing datasets such as SNI (Wang et al. 2022). In addition, 37 tasks such as those related to traditional Chinese are manually created. The benchmark defines four output categories with corresponding evaluation metrics, such as using accuracy for multi-class classification tasks. They categorize the task output into the four categories and suggest evaluation metrics for each type. For multi-class classification and multilabel classification, they use accuracy and F1 score respectively. For creative generation tasks that have no absolute golden answer, they use model-based evaluators to evaluate creativity, fluency, the level of instruction-following and the confidence of the evaluator. For the remaining tasks, they use semantic similarity between the golden answer and the model output. For South Korean culture, HAE-RAE Bench (Son et al. 2024b) is developed to capture culture-specific nuances in the Korean language. It consists of six downstream tasks, including general knowledge and history. The general knowledge questions are crowdsourced and includes sub-topics such as tradition, law, and Korean drama. For the history section, the authors manually craft questions from Namuwiki pages related with Korean history. CLIcK (Kim et al. 2024a) is dataset focusing on Korean cultural and linguistic knowledge. The cultural commonsense knowledge part covers topics such as society, tradition, pop culture, and history. The questions are selected from standardized Korean exams, and additional questions are generated using GPT-4 (OpenAI 2023) based on textbook contents. Various Asian countries other than Indonesia, China and Korea have developed following datasets and benchmarks. Chang et al. (2024) build Taiwanese Hakka culture dataset. It draws primarily from Hakka Culture Encyclopedia and Taiwan Ministry of Educations Hakka Knowledge Base. The questions are designed to include culturally relevant topics such as Hakka language, customs, history and architecture. Moreover, they specifically create questions in regards to Blooms Taxonomy (Bloom 1956; Furst 1981) to assess LLMs ability to apply, analyze, evaluate, and creatively utilize cultural knowledge. Seth et al. (2024) construct DOSA to study Indias local cultural identities based on Indias geographic states. This dataset is community-generated, and includes 615 social artifacts and represents 19 different Indian geographic subcultures. They initially use survey to collect important subculture social artifacts. Then suggest pipeline to get further annotation on each artifacts from state local residents. Watts et al. (2024) evaluate 30 models across 10 Indic languages with 20 manually created long-form generation prompts. The prompts include topics such as health, finance, and culturally nuanced questions. They compare models generation abilities by performing pairwise comparisons with both LLM evaluators and human evaluators. In addition, the AraDiCE (Mousi et al. 2024) benchmark includes fine-grained dataset called AraDiCE-Culture. This dataset is specifically designed to assess regional Arabic cultural awareness across the Gulf, Egypt, and Levant regions. The questions are related to culturally significant topics such as public holidays, food, geography, and history. 19 Related to the European region, Masala et al. (2024b) develop RoCulturaBench to evaluate how well LLMs are grounded in the historical, cultural, and social realities of Romania. team of Romanian humanities scholars manually constructed questions covering two subtopics. First is factual information about Romania, including its geography, history, and demography. The second part includes aspects of how Romanians perceive themselves and the world, with topics such as traditions, customs, beliefs, and stereotypes. BERTAQA (Etxaniz et al. 2024) is multiple-choice trivia dataset divided into two subsets, one focusing on local knowledge about the Basque Country, and the other covering global knowledge. The questions span 8 diverse categories, including society and tradition, sports and leisure, and science and technology. They initially create the dataset in Basque by crawling public sources, then create English version using professional translation service. Several Asian countries, including Indonesia, China, and Korea, are actively developing culture-specific commonsense knowledge evaluation benchmarks. Benchmarks for Indonesia in particular, aims to capture the countrys diverse local cultures and languages, making an effort to represent local differences in the dataset (Koto et al. 2024b; Putri et al. 2024b). Similarly, when developing culture-specific benchmarks, it is crucial to include local cultures rather than treating the entire country as single, homogeneous culture. This would especially be important in ethnographically diverse countries where careful attention is needed to accurately reflect cultural diversity. Multicultural and Monolingual Benchmarks. In the following, we describe crosscultural commonsense knowledge benchmarks that encompass wide range of cultures. Most of them are built in English with one exception of Arabic (Naous et al. 2023). This enable the NLP community to conduct cross-cultural comparison on LLMs cultural knowledge and reasoning ability with unified tasks. FORK is food-related dataset is manually created, containing 184 that CommonsenseQA-style (Talmor et al. 2019b) questions. These questions are categorized into three types based on how explicitly the reference country is mentioned. In contrast, CULTURALBENCH-V0.1 (Chiu et al. 2024) is created semi-automatically through combination of human expertise and AI assistance. They use red-teaming approach (Perez et al. 2022; Ganguli et al. 2022) to develop an AI-assisted system called CulturalTeaming, which integrates the creativity and cultural knowledge of human annotators with the scalability and standardization capabilities of LLMs. With this system, 45 human annotators create 252 MCQ dataset covering 34 different cultures. CULTURE-GEN (Li et al. 2024f) is fully automatically generated. They leverage LLMs to generate response on eight culture-related topics across 110 countries and regions, using country list sourced from the World Value Survey (Haerpfer and Kizilova 2012). From these LLM outputs, cultural symbols are automatically extracted and matched to their respective cultures. Using the linguistic concept of markedness (WAUGH 1982), they found that culture-specific generations are characterized by distinct cultural symbols. CUNIT (Li et al. 2024g), CAMeL (Naous et al. 2023), and EnCBP (Ma et al. 2022) are semi-automatically constructed benchmarks that source data from web resources such as Wikipedia and social media platforms like Twitter. After automatically gathering data from these online sources, they undergo additional human annotation or validation to enhance their quality and relevance. CUNIT (Li et al. 2024g) evaluates LLMs ability to identify culturally similar concept pairs. It focuses on traditional culture-specific concepts related to clothing and food across 10 countries. The dataset is created by first collecting cultural concepts and descriptions from Wikipedia, followed by detailed manual annotation of culturally significant features. CAMeL (Naous et al. 2023) is an Arabic benchmark that comprises entities extracted from Wikidata and CommonCrawl 20 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond corpus. Each entities have human-annotated culture labels. The masked prompts that is used to evaluate LMs cultural adaptation ability are retrieved from (formerly Twitter) for natural context. The cultural bias and stereotypes are evaluated by analyzing adjectives and doing sentiment analysis on story generation with Arab and Western entities. Furthermore, they define Cultural Bias Score (CBS) to measure the preference of cultural entities in masked token prediction. EnCBP (Ma et al. 2022) is designed for cultural background prediction using English-language news articles. The dataset consists of articles collected from major news outlets in five English-speaking countries and four U.S. states. Through manual validation via MTurk,2 crowdsourcing platform and cultural domain compatibility assessments, the study demonstrates that cultural background heavily influences writing style, even within the same language. Several benchmarks are created automatically by utilizing various web resources. DLAMA-v1 (Keleg and Magdy 2023) evaluates models factual knowledge across cultures by automatically generating factual triples using SPARQL queries from Wikidata. This method produces factual knowledge triples with 20 relation predicates covering 21 Western, 22 Arab, 13 Asian, and 12 South American countries. CultureAtlas (Fung et al. 2024) introduces multicultural knowledge extraction approach by systematically navigating Wikipedia documents on cultural topics through network of linked pages. The dataset not only includes positive cultural knowledge samples but also creates negative samples to assess LLMs understanding of multicultural knowledge. It spans over hundred countries and covers cultural topics such as etiquette, holidays, and traditional clothing. Similary, CANDLE-CCSK (Nguyen et al. 2023a) conduct large web crawl. It introduces CANDLE, an end-to-end methodology for automatically extracting cultural commonsense knowledge (CCSK) at scale. CANDLE extracts 1.1 million CCSK assertions, organizing them into clusters across three domains and five cultural facets. Among the three domains, the geography domain includes 196 countries. The cultural facets include food, clothing, and traditions. Jiang and Joshi (2024) introduce CPopQA, ranking-based statistical QA task that compares the popularity of cultural concepts across 58 countries. The dataset is automatically constructed using Wikipedias list of public holidays and Google Books Ngram Viewer (GBNV) corpus3. GBNV is used to estimate the popularity of each holiday within country by leveraging the statistical frequency of the holidays name and the publication country of each book. GlobalLiar (Mirza et al. 2024) source true-false statements from online websites to evaluate the fact-checking performance of LLMs. The dataset covers six global regions, Africa, AsiaPacific, Europe, Latin America, North America, and the Middle East, with 100 true-false statements per region. The true statements are sourced from reputable news outlets in their respective regions, while false statements were obtained from AFP FactCheck.4 Multicultural and Multilingual Benchmarks. The following introduces multicultural and multilingual commonsense knowledge benchmarks. Each benchmark contains cultural knowledge tied to specific regions, often represented by each regions native language. Some benchmarks use language as proxy for culture, aligning single language with particular culture or country. Others recognize that cultural regions may be linguistically diverse, and some languages are spoken across multiple cultural regions. Thus, language-culture pairs do not always have one-to-one correlation in each benchmark. 2 https://www.mturk.com 3 https://books.google.com/ngrams/ 4 https://factcheck.afp.com 21 Benchmarks such as BLEnD (Myung et al. 2024b), GEOMLAMA (Yin et al. 2022) are created manually either by recruiting local annotators directly, or through crowdsoucing platforms. BLEnD (Myung et al. 2024b) is specifically designed to capture everyday knowledge that is often not explicitly documented in online data source. It spans six categories including food, sports, and family. It is manually created by recruiting native annotators both directly and through crowdsourcing platform Prolific.5 It covers 13 languages spoken across 16 different countries and regions, including underrepresented areas such as West Java and North Korea. The final dataset contains 52.6k QA pairs, comprising 15k short-answer and 37.6k multiple-choice questions. GEOMLAMA (Yin et al. 2022) covers geo-diverse knowledge about the United States, China, India, Iran, and Kenya, with prompts constructed with native language for each country, English, Chinese, Hindi, Persian, and Swahili. It is also manually created by recruiting native annotators from each country. The dataset contains 3K masked prompts related to geodiverse concept including culture and customs, and provides different gold answer for each country. CALMQA (Arora et al. 2024) is multilingual long-form questionanswering dataset focused on culturally specific questions. It contains 1.5K questions across 23 high to low resource languages for broad range of topics such as governance and society, religion and customs, and history. The dataset is built by collecting naturally occurring questions from community web forums and by hiring native speakers to create questions in under-resourced, rarely-studied languages like Fijian and Kirundi. Shwartz (2022) propose the task of mapping time expressions across different cultures. They collect gold standard annotations through crowdsourcing platform for the start and end times of five time expressions, morning, noon, afternoon, evening, and night. The annotations span English, Hindi, Italian, and Portuguese, representing the cultural contexts of the US, India, Italy, and Brazil. Web resources in multiple languages can be leveraged to automatically construct cross-cultural knowledge benchmarks. FMLAMA (Zhou et al. 2024) is cross-cultural culinary knowledge dataset. The dataset is created by systematically querying Wikidata to extract broad range of food-related information. It focuses on topologically diverse set of languages, including English, Chinese, Arabic, Korean, Russian, and Hebrew. Hasan et al. (2024) introduces the NativQA framework, designed to create culturally and regionally specific natural question-answering datasets. The resulting MultiNativQA benchmark comprises over 72K QA pairs across seven languages and seven cities, spanning languages such as English, Bangla, Hindi, Nepali and Assamese. It also captures linguistic diversity by incorporating various dialects, including multiple Arabic dialects and two distinct variations of Bangla. Liu et al. (2024a) present MAPS, dataset of proverbs across six geographically diverse languages. They collect proverbs and sayings from Wikiquote and Wiktionary. By testing MAPS with wide range of open source LLMs, they show that LLMs possess knowledge of proverbs and sayings to varying degrees, although significantly biased toward English and Chinese. Leeb and Schölkopf (2024) introduce BABEL BRIEFINGS dataset with 4.7m news headlines from August 2020 to November 2021, across 30 languages and 54 locations worldwide. They automatically collect news headlines using the News API.6 This dataset can be utilized to compare the coverage of events across different countries and languages, or identifying cultural biases in reporting. 5 https://www.prolific.com/ 6 https://newsapi.org/ 22 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Some benchmarks utilize existing NLP benchmarks built in different cultural contexts to create cross-cultural knowledge benchmarks (Liu et al. 2024b; Cao et al. 2024b). Others, like SeaEval (Wang et al. 2024b), aim for comprehensive cross-cultural evaluations by merging various NLP datasets. OMGEval (Liu et al. 2024b) is an open-source multilingual generative test set designed to evaluate LLMs general knowledge and capabilities. It provides 804 open-ended questions across five languages, building on AlpacaEval (Dubois et al. 2023), with 805 entries as foundational data. The dataset underwent multilingual translation, manual localization, and thorough manual verification to ensure global relevance. CulturalRecipes (Cao et al. 2024b) is bidirectional Chinese-English dataset focused on cross-cultural recipe adaptation. It draws from two existing monolingual corpora, RecipeNLG (Bie et al. 2020) and XiaChuFang (Liu et al. 2022c). The authors also manually create small golden dataset for cultural recipe adaptation. They use both reference-based automatic metrics and human evaluation to assess cross-cultural recipe adaptation in text generation. SeaEval (Wang et al. 2024b) is benchmark for evaluating multilingual foundation models on language capabilities, complex reasoning, and cultural understanding. Covering eight languages, it incorporates 29 datasets with 13,263 samples. SeaEval draws on existing benchmarks for fundamental language skills and reasoning, while manually constructing four datasetsUSEval, SG-Eval, CN-Eval, and PH-Evalfocused on distinct cultural regions. Also to evaluate cross-lingual consistency, SeaEval introduces two new datasets, Cross-MMLU and Cross-LogiQA, based on the MMLU (Hendrycks et al. 2021) and LogiQA2.0 (Liu et al. 2023b) datasets. Shen et al. (2024) offer comprehensive evaluation of LLMs performance in cultural commonsense tasks. The study examines culture-specific commonsense knowledge using datasets like GeoMLAMA (Yin et al. 2022) and CANDLE (Nguyen et al. 2023a), and explores the influence of cultural context in general commonsense reasoning using GenericsKB (Bhakthavatsalam, Anastasiades, and Clark 2020). Their findings reveal significant performance disparities across cultures, showing that LLMs often associate general commonsense with dominant cultures. They also highlight that the language used to query LLMs has substantial impact on performance in culture-related tasks. We can also directly analyze and evaluate LLM-generated outputs for cross-cultural commonsense. Wang et al. (2024d) evaluate cultural dominance by building multilingual dataset that includes both concrete and abstract cultural objects. LLMs are prompted to list 10 concrete cultural objects in 11 languages, and the authors introduce an In-Culture score to measure cultural dominance by assessing how many responses align with the culture of the corresponding language, based on Wikipedia. Manvi et al. (2024) evaluate the geographic bias of LLMs using prompts that elicit zero-shot predictions based on specific geographic locations. While the models predictions show strong correlations with ground truths on objective topics like annual precipitation, population density, and infant mortality rate, they often consistently overestimate or underestimate the ranks of certain regions. Takeaways from 4.2.2. Commonsense knowledge benchmarks are being developed in various cultures. Most of these benchmarks use language or country as proxies to define cultural boundaries. However, inconsistencies in these definitions makes cross-cultural evaluation across existing benchmarks challenging. Furthermore, some studies do not adequately consider sociolinguistic factors when defining these boundaries. To advance future cross-cultural research, it is essential to establish well-defined and consistent cultural boundaries. Also, as shown in Figure 6, while most evaluation methods are based on multiple-choice QAs, recent studies have begun to explore the evaluation of LLMs text generation capabilities with short answer and long-form 23 generation tasks. However, most current long-form evaluation approaches depend on human evaluation or LLM-as-a-judge methods (Zheng et al. 2023), which are limited in scalability and lack culturally-specific evaluation. Therefore, further research is needed to develop robust automatic evaluation methods, especially for long-form generation tasks."
        },
        {
            "title": "4.2.3 Social Values. Social values refer to the common beliefs in a society about what\nis good, desirable, and important. They reflect what a society or individual considers\nimportant and prioritize certain outcomes or behaviors (e.g., equality, freedom, solidar-\nity). Social values are not necessarily prescriptive rules, but they are common goals that\ninfluence how people behave and make decisions. The overall hierarchy of the papers\nin this section is specified in Figure 7.",
            "content": "Most studies in cultural NLP that focus on social values use studies from social sciences for evaluation, such as Hofstedes Cultural Dimensions Theory (Hofstede 2005) and the World Values Survey (WVS, Survey (2022)). WorldValuesBench (Zhao et al. 2024) leverages questions from WVS to create large-scale benchmark for multi-cultural value prediction, where models are required to predict the social values conditioned on various demographic contexts. The World Values Corpus (Benkler et al. 2022, 2024) introduces new task called Recognizing Value Resonance (RVR) and constructs dataset based on questions from the World Values Survey (WVS). This dataset is designed to assess the models perspectives on implicit cultural values and beliefs through the analysis of text pairs. Wang et al. (2024d) leverage survey questions from WVS and the Political Coordinates Test (PCT) to assess the cultural dominance of LLMs on abstract concepts such as values and opinions. CDEval (Wang et al. 2023) introduces questionnairebased benchmark designed to measure the cultural dimensions of LLMs, focusing on the six cultural dimensions defined by Hofstedes Cultural Dimensions Theory. Cao et al. (2023) employ survey questions based on Hofstedes Cultural Dimensions Theory to assess the cultural alignment between LLMs and human societies in 5 different languages and cultures. Arora, Kaffee, and Augenstein (2023) utilize survey questions from Hofstedes Cultural Dimensions Theory and WVS to show that multilingual pretrained language models learn cross-cultural value differences, but they weakly correlate with the surveys. Johnson et al. (2022) use WVS as comparative framework to assess how GPT-3 tends to align the values in its generated outputs with the social values prevalent in the U.S., often leading to conflicts with input texts that originate from other cultural contexts. FULCRA (Yao et al. 2024) applies Schwartzs Theory of Basic Values (Schwartz 2012) to assess the underlying values guiding LLMs behaviors, facilitating the identification of current safety risks and the prediction of future risks. UniVar (Cahyawijaya et al. 2024a) identifies 87 reference human values by synthesizing insights from existing studies, such as the World Values Survey (WVS) and Hofstedes Cultural Dimensions Theory. These values are then used to construct value-eliciting QA pairs in 25 languages, which serve as basis for evaluating how current LLMs reflect human values across different languages. These studies commonly highlight the challenges LLMs face in aligning their values with diverse cultural contexts, and emphasize that these models tend to reflect values more aligned with WEIRD (Western, Educated, Industrialized, Rich, and Democratic) societies. Other studies have focused on evaluating LLMs alignment with specific regional or cultural values. CIVICS (Pistilli et al. 2024) collects text excerpts from authoritative sources in Singapore, France, Canada, the United Kingdom, and Australia to create prompts for evaluating LLMs responses to value-sensitive topics, including immigration, LGBTQI rights, and social welfare. KorNAT (Lee et al. 2024a) develops social 24 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Social Value Social Studies Others Concept-level Adaptation FULCRA (Yao et al. 2024); Johnson et al. (2022) CDEval (Wang et al. 2023); UniVar (Cahyawijaya et al. 2024a) Question-level Adaptation Arora, Kaffee, and Augenstein (2023); Cao et al. (2023) WorldValuesBench (Zhao et al. 2024); Wang et al. (2024d) World Values Corpus (Benkler et al. 2022, 2024) CIVICS (Pistilli et al. 2024); KorNAT (Lee et al. 2024a) LocalValueBench (Meadows et al. 2024) Borenstein et al. (2024); Havaldar et al. (2024) Figure 7: Culturally-aware evaluation of social values Social Norms and Morals Norms Morals Datasest & Benchmarks NORMBANK (Ziems et al. 2023); NORMDIAL (Li et al. 2023b); ReNoVi (Zhan et al. 2024); Rai et al. (2024); NORMAD (Rao et al. 2024); CultureBank (Shi et al. 2024); EtiCor (Dwivedi, Lavania, and Modi 2023); Yuan et al. (2024) Norm Extraction CH-Wang et al. (2023); NORMSAGE (Fung et al. 2023); NormMark (Moghimifar et al. 2023) Ramezani and Xu (2023); Hämmerl et al. (2023); Agarwal et al. (2024); MORAL INTEGRITY CORPUS (Ziems et al. 2022); CMoralEval (Yu et al. 2024) Figure 8: Culturally-aware evaluation of social norms and morals value dataset designed to assess LLMs alignment with the social values of Korean citizens, based on large-scale survey featuring questions generated using social conflict keywords and timely keywords specific in Korea. LocalValueBench (Meadows et al. 2024) presents benchmark to evaluate LLMs alignment with Australian values, addressing topics such as social norms, legal principles, and cultural practices. Borenstein et al. (2024) conduct large-scale study of differences in Schwartz values between online communities on Reddit. Havaldar et al. (2024) introduce knowledge-guided lexicon to model cultural variation within country, highlighting the significance of measuring cultural differences across its regions and applying this framework to NLP models. Takeaways from 4.2.3. Most papers examining social values rely on existing global surveys from the social sciences, resulting in high regional coverage. However, it is important to note that while social values can vary significantly at sub-country levels (Havaldar et al. 2024), most studies concentrate solely on country-level analyses. This highlights the need for more granular research that captures local nuances in social values beyond national boundaries."
        },
        {
            "title": "4.2.4 Social Norms and Morals. Social norms and morals refer to more specific rules\nor principles that dictate how individuals should behave in everyday situations. They\noften reflect shared expectations within a community about what is acceptable or unac-\nceptable behavior. It differs from social values in that values represent broader, abstract\nideals or goals that guide what people strive for, while norms and morals provide con-\ncrete guidelines for behavior and decision-making within specific contexts (Matsumoto\n2007). The overall hierarchy of the papers in this section is specified in Figure 8.",
            "content": "25 Recent research has emphasized the need to equip language models with nuanced understanding of these norms to effectively navigate diverse social settings. Ziems et al. (2023) introduced NORMBANK, hierarchical knowledge bank of social norms designed to support non-monotonic reasoning over cultural norms, which are viewed as flexible standards that change with context. Expanding on the need for cultural adaptability, Li et al. (2023b) presented NORMDIAL, bilingual dataset capturing social norm adherence and violations within dialogues for Chinese and American contexts. By modeling norm observance at turn-by-turn level, this dataset demonstrates how conversational nuances and expectations vary between languages, providing insights into how language models can handle violations across languages. Zhan et al. (2024) introduce ReNoVi, large-scale corpus of 9,258 multi-turn dialogues annotated with social norms, designed to help AI systems understand and remediate norm violations. Rai et al. (2024) presented the first cross-cultural dataset of self-conscious emotions drawn from Bollywood and Hollywood films, alongside over 10K identified social norms, underscoring cultural differences such as Bollywoods focus on social roles and family honor. Yuan et al. (2024) present new social norms benchmark based on the U.S. K-12 curriculum, designed to evaluate LLMs understanding of social norms. They also introduce multi-agent framework that improves LLMs social norm comprehension, bringing it closer to human-level understanding. In broader exploration, Rao et al. (2024) introduced NORMAD, dataset encompassing social and cultural norms from 75 countries, revealing that LLMs tend to demonstrate stronger adaptability to English-centric cultures. Shi et al. (2024) introduce CultureBank, large-scale cultural knowledge base built from cultural descriptors sourced from TikTok and Reddit, used to evaluate LLMs cultural knowledge across 2K cultural groups and 36 cultural topics, including social norms. Dwivedi, Lavania, and Modi (2023) present EtiCor, an Etiquettes Corpus containing texts about social norms from five global regions, designed to evaluate LLMs understanding of region-specific etiquettes. Other studies focus on developing frameworks to extract culture-specific norms from existing text, which can be further used to evaluate language models. CH-Wang et al. (2023) propose novel approach to discover and reach descriptive social norms across Chinese and American cultures using human-AI cooperation framework, and introduce the task of explainable social norm entailment to test the models reasoning across cultures. Fung et al. (2023) present NORMSAGE, framework that automatically extracts culture-specific norms from multilingual conversations using GPT-3, offering explainable self-verification to ensure the norms correctness in conversation on the fly. Moghimifar et al. (2023) propose NormMark, probabilistic generative Markov model that captures latent features throughout dialogue to improve norm recognition, outperforming existing methods, including GPT-3, on weakly annotated data by leveraging variational techniques and conversation history. In terms of morals, Ramezani and Xu (2023) examined whether language models can capture moral norm variations across different countries using global datasets. They emphasized the limitations of monolingual English models in generalizing across cultures, particularly regarding sensitive topics such as homosexuality and divorce. Hämmerl et al. (2023) examine the moral biases embedded in pre-trained multilingual language models (PMLMs) and their implications for cross-lingual transfer in German, Czech, Arabic, Chinese, and English. Their findings reveal that PMLMs encode varying moral biases that often misalign with cultural differences and human judgments, which can lead to harmful consequences in cross-lingual applications. Agarwal et al. (2024) investigate how LLMs perform ethical reasoning across multiple languagesEnglish, Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond WEAT-based CA-WEAT (España-Bonet and Barrón-Cedeño 2022) WEATHub (Mukherjee et al. 2023) Borah, Garimella, and Mihalcea (2024) Sentence Pairs French CrowS-Pairs (Névéol et al. 2022) Multilingual CrowS-Pairs (Fort et al. 2024) IndiBias (Sahoo et al. 2024); Indian-BhED (Khandelwal et al. 2024b) CHBias (Zhao et al. 2023); BIBED (Das, Guha, and Semaan 2023) RuBia (Grigoreva et al. 2024) Social Bias and Stereotype Identity-Stereotype Pairs SPICE (Dev et al. 2023); SeeGULL (Jha et al. 2023) SGM (Bhutani et al. 2024) BBQ Series CBBQ (Huang and Xiong 2024); KoBBQ (Jin et al. 2024) JBBQ (Yanaka et al. 2024) MBBQ (Neplenbroek, Bisazza, and Fernández 2024) Others Zhu, Wang, and Liu (2024); CHAST (Dammu et al. 2024) Figure 9: Culturally-aware evaluation of social biases and stereotypes Spanish, Russian, Chinese, Hindi, and Swahiliexamining whether the language of the prompt influences the models moral judgments. Ziems et al. (2022) introduce the MORAL INTEGRITY CORPUS (MIC), resource comprising 38,000 prompt-reply pairs and 99,000 Rules of Thumb (RoTs) that capture the moral intuitions behind dialogue system responses. Yu et al. (2024) present CMoralEval, benchmark dataset designed for the morality evaluation of Chinese large language models (LLMs), consisting of 14,964 explicit moral scenarios and 15,424 moral dilemma scenarios sourced from Chinese TV program and various media. Takeaways from 4.2.4. Like social values, research on social norms and morals has high regional coverage, primarily due to data sourced from online media such as Wikipedia and Reddit. However, most studies are conducted in English, overlooking the possibility that LLMs may have different understandings of social norms when prompted in various languages. Multilingual cross-cultural evaluations are needed."
        },
        {
            "title": "4.2.5 Social Bias and Stereotype. With the growing recognition of the need to detect\nand mitigate social bias in language models, several bias benchmarks and metrics have\nbeen developed. However, most of them have been built in English, reflecting Western\ncultures. As social biases and stereotypes depend on cultural contexts, several studies\nhave emphasized the need for and developed bias benchmarks and metrics that include\nnon-US cultures in their own languages. Figure 9 classifies studies according to the\ntype of stereotype dataset, which is associated with the corresponding bias evaluation\nmethods.",
            "content": "The Word Embedding Association Test (WEAT, Caliskan, Bryson, and Narayanan (2017)) has been used to measure the bias of language models at the word embedding level. By computing the similarity between the word embeddings, it assesses the association between the target and the attribute depicting particular stereotype. However, since it originated from the Implicit Association Test (IAT) (Greenwald, McGhee, and Schwartz 1998) developed in English in the United States, the stereotypes and the list of words representing the targets and the attributes possess some linguistic and cultural bias. España-Bonet and Barrón-Cedeño (2022) introduce Cultural Aware 27 WEAT (CA-WEAT) lists in 26 languages. They have native speakers create new lists of words associated with the stereotypes that are considered universally accepted, flowerspleasant versus insects-unpleasant and musical instruments-pleasant versus weaponsunpleasant. Mukherjee et al. (2023) release WEATHub, multilingual extension of WEAT. It features 24 languages, each with native speaker involvement to translate the relevant English WEAT with appending language-specific words and add new humancentered bias dimensions. Borah, Garimella, and Mihalcea (2024) propose data-driven method to extract region-aware gender bias topic pairs for WEAT-based evaluation. Additionally, they let LLMs generate personae of someone interested in the given topic, and measure the mismatch rate with the associated gender. The method of measuring bias in language models using sentence pairs that have similar structures but refer to two different social groups has also been widely used. The bias is measured by analyzing sentence-level probabilities to determine whether the language models tend to favor sentences that align more closely with societal stereotypes. Research has been actively conducted to create datasets composed of sentence pairs in various languages that reflect stereotypes from diverse cultures. Névéol et al. (2022) present French CrowS-Pairs by adapting the original CrowS-Pairs (Nangia et al. 2020) and newly crowdsourcing stereotyped statements. Fort et al. (2024) further extend it to Multilingual CrowS-Pairs with seven additional languages. Sahoo et al. (2024) construct IndiBias, Hindi and English dataset for India, by adapting the original CrowS-Pairs and generating identity-stereotype pairs and corresponding sentence pairs by LLMhuman partnership. Indian-BhED (Khandelwal et al. 2024b) is another dataset targeting India, which covers stereotypes about caste and religions. It is an English dataset created by the authors based on literature and their own knowledge and validated by experts. CHBias (Zhao et al. 2023) is Chinese dataset of sentences that are retrieved from Weibo based on the bias specifications and annotated by native Chinese speakers. Each sentence in the validation and test sets is paired with sentence in which the target term is swapped. BIBED (Das, Guha, and Semaan 2023), Bengali dataset, includes not only sentence pairs that explicitly mention the target identity terms but also those with names, kinship phrases, and synonymous colloquial lexicons that imply gender, religious, or national identities in the Bengali context. Another type of stereotype dataset consists of pairs of identities and stereotypes. The models are typically evaluated by measuring the mean entailment for the pairs of one sentence containing the identity group and another sentence containing the associated stereotype. SPICE (Dev et al. 2023) is an English dataset constructed through an open-ended survey to cover diverse and locally situated stereotypes in India. SeeGULL (Jha et al. 2023) is an English benchmark built using LLMs in the loop to cover stereotypes about identity groups spanning 176 countries and state-level identities within the US and India. Bhutani et al. (2024) extend it to SeeGULL Multilingual (SGM) to cover 23 language-country pairs. They evaluated LLMs by asking them to choose target identity associated with the given stereotype. As LLMs become prevalent, there has been surge in the use of the Bias Benchmark for Question Answering (BBQ) (Parrish et al. 2022), which can assess bias in LLMs through question-answering (QA) format. It comprises ambiguous contexts and disambiguated contexts with discriminatory questions for evaluating QA accuracy and bias scores in each type of context. CBBQ (Huang and Xiong 2024) is Chinese version of BBQ benchmark, which consists of ambiguous contexts, questions, and answer choices written by humans, and disambiguating contexts generated by GPT-4 (OpenAI 2023). KoBBQ (Jin et al. 2024), for South Korea, is constructed through culturally sensitive adaptation of the original BBQ, validated by large-scale survey conducted 28 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Monoculture Arango Monnar et al. (2022); AraTrust (Alghamdi et al. 2024) KOLD (Jeong et al. 2022); KoSBi (Lee et al. 2023b) CRU (Ullah et al. 2024) Toxicity and Safety Multi/CrossCulture XtremeSpeech (Maronikolakis et al. 2022) Korre, Muti, and Barrón-Cedeño (2024) RTP-LX (de Wynter et al. 2024); Tonneau et al. (2024) Lee, Jung, and Oh (2023); CREHate (Lee et al. 2024b) Multidimension WalledEval (Gupta et al. 2024); AART (Radharapu et al. 2023) Figure 10: Culturally-Aware Evaluation in Toxicity and Safety among South Koreans. JBBQ (Yanaka et al. 2024) is also manually built from English BBQ to target Japanese. MBBQ (Neplenbroek, Bisazza, and Fernández 2024) consists of BBQ samples dealing with the stereotypes that are common in English, Dutch, Spanish, and Turkish, and is used to compare LLMs behavior across different languages. Meanwhile, Zhu, Wang, and Liu (2024) focus on revealing ChatGPTs (OpenAI) nationality bias, that is, bias in discourse about people of certain nationality. They use automatic metrics for vocabulary richness, sentiment, and offensiveness, let ChatGPT score itself, and have ChatGPT and experts pairwise compare the offensiveness of the discourses. To disclose the Covert Harms and Social Threats (CHAST) in LLMgenerated conversations in hiring scenarios, Dammu et al. (2024) propose the CHAST metrics based on social science literature and align the evaluation model with expert assessments. They note that LLMs tend to generate more harmful content when involving the Indian caste compared to the Western-centric race attributes. Takeaways from 4.2.5. While embedding-based and probabilistic methods have been widely used to measure social bias and stereotypes in language models, their application to proprietary LLMs often proves challenging. Furthermore, existing research on LLMs that considers cross-cultural differences of social bias among multiple cultures tends to focus on specific bias categories or limited set of cultures. To bridge this gap, there is growing need for further research on methodologies that enable comprehensive and cross-cultural evaluation of the bias of various language models across diverse cultures."
        },
        {
            "title": "4.2.6 Toxicity and Safety. This section covers studies on hate speech, offensive language,\ntoxicity, and safety, highlighting cross-cultural differences in their manifestation and the\nevaluation of language model safety from diverse cultural perspectives. The overview\nfor this section is depicted in Figure 10.",
            "content": "Pointing out that the research on toxicity, offensive language, and hate speech predominantly focused on English, Arango Monnar et al. (2022) build Spanish dataset by getting annotations for tweets from Chile, and Jeong et al. (2022) construct Korean offensive language dataset, KOLD, by getting annotations for comments from NAVER news and YouTube. Also, Lee et al. (2023b) present Korean social bias dataset, KoSBi, which consists of the context-sentence pairs generated by HyperCLOVA (Kim et al. 2021) given the target demographic group, with the human-annotated labels of safe or unsafe (stereotype, prejudice, discrimination, or other). Alghamdi et al. (2024) introduce AraTrust, comprehensive trustworthiness benchmark in Arabic composed of multiplechoice questions on truthfulness, ethics, privacy, illegal activities, mental health, phys29 ical health, unfairness, and offensive language, by curating questions from exams, existing datasets, and online websites, or creating them manually. Ullah et al. (2024) build CRU, benchmark in Roman Urdu for cybercrime detection with three types of cybercrimes, including hate speech, cyber terrorism, and cyber harassment. They systematically collect tweets from Twitter and RUHSOLD (Rizwan, Shakeel, and Karim 2020), then conduct annotation with experts following the Pakistani legal framework regarding cybercrimes. Expanding the views on hate speech and toxic language to include multicultural and cross-cultural perspectives, several studies demonstrate cultural insensitivity and biases present in language models and datasets and develop multicultural and inclusive datasets. Maronikolakis et al. (2022) present XtremeSpeech, hate speech dataset containing social media contents across Brazil, Germany, India, and Kenya. They specifically recruit local annotators from each country for data collection and annotation. de Wynter et al. (2024) construct RTP-LX by transcreating English RealToxicPrompts (Gehman et al. 2020) to 28 languages and manually creating culturally nuanced toxic language, with annotating eight categories of harm. Korre, Muti, and Barrón-Cedeño (2024) explore the creation of multilingual parallel hate speech dataset using machine translation. They found that while machine translation adequately preserves the intended meaning of the sentences, it still produces grammatical and syntactical errors, showcasing the challenges of creating parallel hate speech corpus. Meanwhile, Lee, Jung, and Oh (2023) highlight the cultural insensitivity of language models by demonstrating that the monolingual hate speech classifiers show lower performance in classifying the translated texts from other cultures. Lee et al. (2024b) verify the intra-language cultural disparities in hate speech annotation and LLMs detection performance bias towards Anglosphere countries by constructing CREHate, which comprises online posts with hate speech annotations from five English-speaking countries. Tonneau et al. (2024) disclose the intra-language geographical bias of English, Arabic, and Spanish hate speech datasets, as inferring the location of each tweets author reveals that handful of countries are disproportionately overrepresented in the datasets. Recent work that comprehensively evaluates the safety of LLMs includes cultural perspectives as one of the various evaluation factors. Gupta et al. (2024) release WalledEval, comprehensive AI safety evaluation toolkit, with SGXSTest and HIXSTest, which consist of safe and unsafe prompts for testing LLMs refusal behavior within the cultural context of Singapore and Hindi, respectively. Radharapu et al. (2023) propose an AI-assisted red-teaming method, AART, to create adversarial queries customized for various application contexts with adversarial evaluation dimensions such as locale and language. Prabhakaran et al. (2024) propose GRASP, disagreement analysis framework, and uncover systematic disagreements across various intersectional subgroups. They suggest that the sociocultural background of human annotators can lead to disagreement in subjective tasks, such as safety and offensiveness annotations. Takeaways from 4.2.6. The primary role of language models in the toxicity and safety field used to be moderating communication between online users. However, the advent of LLMs has introduced new challenge of evaluating the toxicity and safety of contents generated by LLMs. This shift has necessitated broader research on toxicity and safety, encompassing not only communication between users but also between users and AI models. Additionally, acknowledging intercultural variations within single language and attempting to analyze peoples perceptions from diverse perspectives are noteworthy and deserve further exploration in other tasks as well. 30 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Emotional and Subjective Topics Emotion and Sentiment Havaldar et al. (2023); Ahmad et al. (2024); Ochieng et al. (2024); MASIVE (Deas et al. 2024) Subjective Topics Manvi et al. (2024); ThatiAR (Suwaileh et al. 2024); InspAIred (Ignat, Lakshmy, and Mihalcea 2024) Figure 11: Culturally-aware evaluation for emotional and subjective topics"
        },
        {
            "title": "4.2.7 Emotional and Subjective Topics. This section introduces studies that evaluate\ncultural biases in language models on emotional and subjective topics, as well as those\nexamining various tasks and datasets affected by individuals’ cultural backgrounds.\nFigure 11 categorizes these researches into emotion detection tasks and other subjective\ntopics.",
            "content": "The evaluation of language models across various cultural contexts has also been explored for emotional and subjective topics. Havaldar et al. (2023) show the bias towards English and American contexts in emotion embeddings of the multilingual model, as well as in the emotion prediction performance of the LLMs. They also illustrate that the psychological cultural differences of pride and shame between the US and Japan are not clearly reflected in the language models. Ahmad et al. (2024) focus on Hausa to compare responses of ChatGPT (OpenAI) with human native speakers to questions about emotions in the Nigerian cultural context. Ochieng et al. (2024) qualitatively demonstrate LLMs struggle to incorporate the complex cultural nuances in sentiment analysis using code-mixed (English, Swahili, and Sheng) WhatsApp chat dataset. Manvi et al. (2024) demonstrate the geographical bias of LLMs on subjective topics, in addition to the objective topics (4.2.2). Despite an unbiased model being expected to respond independently of location, the LLMs predictions for the subjective topics (likability, attractiveness, morality, intelligence, and work ethic) are correlated with the infant survival rate of the location, which is proxy of socioeconomic conditions. Some studies extend emotional and subjective tasks that depend on cultural perspectives to diverse cultural contexts. Deas et al. (2024) expand the emotion set covered by the emotion detection benchmarks to be unbounded, by defining the affective state identification (ASI) task to predict affective states when single words expressing the feeling are masked from the text about emotional experience. They also release MASIVE, which contains affective states in English and Spanish Reddit posts. Suwaileh et al. (2024) present ThatiAR, an Arabic dataset of news sentences with manually annotated labels on subjectivity and LLM-generated rationals and instructions. They demonstrate how political, historical, and cultural bias and subjectivity of the writers and readers affect detecting subjectivity in the news. Ignat, Lakshmy, and Mihalcea (2024) construct dataset of culturally inspiring content called InspAIred. The contents are sourced by searching keywords like inspiration and motivation in subreddits of regions in India and the UK, and labeled by crowdworkers and fine-tuned model. The dataset is augmented by GPT-4 (OpenAI 2023) to generate inspiring content as Reddit user from India or the UK. They analyze inspiring content across cultures, comparing AI-generated and real ones, in terms of stylistic and structural features such as complexity, descriptiveness, and readability, as well as semantic and psycholinguistic features using topic modeling and psycholinguistic markers. Takeaways from 4.2.7. Emotional and subjective topics are areas where individual differences can vary significantly, even within the same culture. As result, reaching 31 Language Properties MABL (Kabra et al. 2023); MorphEval (Yin, Wang, and Liu 2024); Ersoy et al. (2023) Linguistic Varieties Dialects AraDiCE (Mousi et al. 2024); DIALECTBENCH (Faisal et al. 2024); GuyLingo (Clarke et al. 2024); MultiPICo (Casola et al. 2024); Kadaoui et al. (2023); Kantharuban, Vulic, and Korhonen (2023); Le and Luu (2023); Ramponi (2024); Vligouridou, Iliadou, and Çöltekin (2024) Chinese Varieties AC-EVAL (Wei et al. 2024); C3Bench (Cao et al. 2024a); CHisIEC (Tang et al. 2024b); MC2 (Zhang et al. 2024a); WYWEB (Zhou et al. 2023a) Linguistics Story Poem Literary Forms GOLEM (Yarlott et al. 2024); Makridis, Oikonomou, and Koukos (2024); Toro Isaza et al. (2023); Zhang, Gonzalez, and Solorio (2024) Picca and Pavlopoulos (2024); Sankaran et al. (2024); Toker et al. (2024); Walsh, Preus, and Antoniak (2024) Humor Chumor (He et al. 2024); Ofer and Shahaf (2022) Culturally-Adapted Translation RAT (Chen et al. 2024a); TRANSAGENTS (Wu et al. 2024); PAR3 (Thai et al. 2022); Ethiobenchmark (Tonja et al. 2024); Yao et al. (2023); Toucan (Elmadany, Adebara, and Abdul-Mageed 2024); CoCoA-MT (Nadejde et al. 2022); Sandoval et al. (2023); Li et al. (2023a) Culturally-Adapted Dialogue Systems RoCulturaBench (Masala et al. 2024b); COD (Majewska et al. 2023); MULTI3WOZ (Hu et al. 2023a); cuDialog (Cao, Chen, and Hershcovich 2024) Figure 12: Culturally-aware evaluation in linguistics consensus can be challenging because individuals often have diverse opinions on these matters. Therefore, it is essential to consider how individuals backgrounds and perspectives may affect evaluations and datasets, and efforts should be made to clearly account for the influence of culture."
        },
        {
            "title": "4.2.8 Linguistics. Culture and language are deeply interconnected (Imai, Kanero, and\nMasuda 2016). Cultural elements, such as formality, are often explicitly reflected in\nlanguage properties (Heylighen and Dewaele 1999). Also, language varieties including\ndialects provide valuable insights into local cultures, while literary forms like stories\nand poems offer rich resources for studying culture (Ramponi 2024; Peterson and\nLach 1990). Additionally, cultural factors play a critical role in pragmatics, particularly\nin translation and dialogue systems (Rohmawati, Junining, and Suwarso 2022). This\nsection will examine how cultural aspects are expressed through language properties,\nvarieties, and literary forms, and how these elements inform applications like transla-\ntion and dialogue systems. The overall hierarchy of the papers in this section is specified\nin Figure 12.",
            "content": "Language Properties. Formality is stylistic property of language that typically carries information about the culture of the speaker or the writer (Heylighen and Dewaele 1999). Ersoy et al. (2023) analyze the formality of generative multilingual language models BLOOM (Scao et al. 2023) and XGLM (Lin et al. 2021) across five languages. They classify 1,200 generations per language as formal, informal, or incohesive and measure the impact of the prompt formality on the generation text. Kabra et al. (2023) create 32 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond figurative language inference dataset, MABL, for seven diverse languages associated with variety of cultures. They collect figurative language by crowdsourcing native speakers. They also categorize knowledge needed to understand each metaphor by using the commonsense categories defined in Liu et al. (2022b). This work reveals that each language relies on cultural and regional concepts for figurative expressions Yin, Wang, and Liu (2024) construct MorphEval, Chinese Morpheme-informed Evaluation benchmark. It also contains morphemes with cultural implications, which are Chinese yet need some cultural background to understand. They collect data from dictionarybased resource (Liu, Lin, and Kang 2018). From prediction errors, approximately 16% of errors occur due to cultural implications, hinting lack of cultural understanding in LLMs. Linguistic Variety. Linguistic varieties, such as dialects represent linguistic and cultural diversity, as they encapsulate unique elements of local culture. Yet, many of them are in danger of disappearing (Moseley 2010). Following studies emphasize the importance of collecting more low-resource dialectal data to capture the linguistic and cultural intricacies of diverse communities. Asia Minor Greek dialects are endangered dialects rich in history and culture that face dire struggle for preservation due to declining speaker base and scarce linguistic resources. Thus, Vligouridou, Iliadou, and Çöltekin (2024) present manually annotated treebank of Pharasiot, one of the Asia Minor Greek dialects, following the Universal Dependencies framework (Nivre et al. 2017). Ramponi (2024) also introduces endangered language varieties of Italy. They address the challenge of the existing machinecentric assumptions of NLP for Italys language varieties and suggest responsible and speaker-centric efforts to preserve language varieties of Italy. Similarly, GuyLingo, corpus in Creolese has been proposed in Clarke et al. (2024); Creolese is the most widely spoken language in the culturally rich nation of Guyana, but has limited written source, making it low-resource language in NLP field. Addressing the limitations of current NLP models in handling non-standard Vietnamese dialects, Le and Luu (2023) present parallel corpus for Central and Northern Vietnamese dialects. The corpus is created manually by Central and Northern dialect annotators. Kadaoui et al. (2023) evaluate machine translation performance for various Arabic dialects to English. Arabic sentences are manually collected from the Open Islamic Texts Initiative (OpenITI) dataset (Nigst et al. 2021) and various online sources, including news outlets and YouTube videos. Also, AraDiCE (Mousi et al. 2024) evaluates LLMs on their ability to comprehend and generate dialects primarily focusing on the Levantine (LEV) and Egyptian (EGY) dialects. The approach involves using machine translation from English to Modern Standard Arabic (MSA) and MSA to dialects, followed by human post-editing, to create synthetic benchmarks for low-resource dialects. Zhang et al. (2024a) present MC2, multilingual corpus of minority languages in China, including four underrepresented languages, Tibetan, Uyghur, Kazakh, and Mongolian. They carefully design strategies for the selection of web pages to crawl, ensuring the language purity of the crawled texts. They show that writing systems play crucial role in developing culturally-aware NLP systems with languages with multiple writing systems, such as Kazakh and Mongolian. While modern Chinese is studied vigorously in NLP community, there is lack of effort on classical Chinese. Classical Chinese differs from modern Chinese in writing and grammar, thus benchmarks designed in modern Chinese can not be applied well to the studies in the classical Chinese domain. To address this, C3Bench (Cao et al. 2024a) and WYWEB (Zhou et al. 2023a) are designed to evaluate the classical Chinese understanding capabilities of LLMs. Both benchmarks include basic NLP tasks 33 such as sentence classification and machine translation. For historical knowledge, ACEVAL (Wei et al. 2024) provides comprehensive evaluation of LLMs proficiency in understanding the ancient Chinese language and historical knowledge. The dataset consists of 3k multiple-choice questions, covering historical periods from the Pre-Qin era to the Qing dynasty. Also, Tang et al. (2024b) introduce CHisIEC, an ancient Chinese historical information extraction corpus. It is sourced from 13 historical books from the representative Twenty-Four Histories as the raw data, spanning over 1830 years and contains NER and RE tasks. Furthermore, Liang, Huang, and Jiang (2024) build traditional ecological knowledge base from Shanhai Jing, record of flora and fauna in ancient China, written 2000 years ago. They employ rule-based knowledge extraction method, which can also be utilized for further ancient language processing. Expanding to multilingual comprehensive overview of dialects and linguistic varieties, Faisal et al. (2024) introduce DIALECTBENCH, large-scale benchmark encompassing 40 language clusters with 281 varieties. They use language resources in papers from the past 10 years of the ACL Anthology. And categorize language clusters and varieties based on the Glottolog language database (Nordhoff). Kantharuban, Vulic, and Korhonen (2023) also conduct comprehensive evaluation of LLMs across regional dialects, examining 30 dialects across 7 languages for machine translation and 33 dialects across 7 languages for automatic speech recognition. Casola et al. (2024) propose MultiPICo, multilingual corpus of ironic short conversations extracted from Twitter and Reddit. It covers 9 languages and 25 varieties and each conversation is annotated as ironic or not by crowdsourcing workers with different social backgrounds. Takeaways from Linguistic Variety. Language varieties such as dialects or ancient languages offer valuable insights into local or historical culture. However, many of these language varieties are in danger of extinction (Moseley 2010). Current works primarily focuses on varieties of Chinese (Zhang et al. 2024a; Wei et al. 2024) and Arabic (Mousi et al. 2024; Kadaoui et al. 2023), underscoring the need for further studies on other languages with diverse varieties, such as Spanish, Hindi and English. Literary Forms. Storybooks, especially fairy tales, are particularly important to childrens mental, emotional, and social development and has been subject to analyzing social bias in its text (Peterson and Lach 1990). Toro Isaza et al. (2023) conduct case study that analyze gender bias in fairy tales. They also propose an automatic pipeline that can extract character attributes and storys temporal narrative event chain for each characters. They also present an event annotation scheme to assist bias analysis. Furthermore, Makridis, Oikonomou, and Koukos (2024) introduces FairyLandAI, model designed to create personalized fairytales for children. Its architecture mimics the cognitive and creative processes involved in storytelling and character development found in childrens literature. FairyLandAI supports personalized storytelling in multiple languages, catering to childrens individual language preferences and cultural backgrounds. Narrative texts, such as fables and folktales, often convey lesson via series of events with clear consequence. Zhang, Gonzalez, and Solorio (2024) introduce the first dataset specifically designed for interpretive comprehension of themes in narrative texts. They use educational stories from different eras and cultural backgrounds. Motifs often originate in folklore, which is recurring cultural memes that are grounded in story. Yarlott et al. (2024) present GOLEM, the first dataset annotated for motific information. The dataset comprises 8k English news articles, opinion pieces, and broadcast transcripts annotated for motific information. The human annotators from three cultural groups, Jewish, Irish and Puerto Rican annotate the type of usage of motifs within text. 34 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Rhymes and poems are powerful medium for transmitting cultural norms and societal roles. Walsh, Preus, and Antoniak (2024) assess the poetic capabilities of LLMs by evaluating their recognition of poetic forms, which is patterns of sound that exist within specific cultural and linguistic contexts. They create dataset of over 4.1K poems, tagged and categorized by human annotators, sourced from online platforms and books. The dataset, however, shows biases related to race, class, language, and culture due to uneven distribution across poetic forms. Further research is needed to explore LLMs poetic abilities in languages beyond English. Similarly, Sankaran et al. (2024) address gender biases in rhymes and poems by collecting childrens rhymes and adolescent poetry, including 20 translated poems from 11 languages. The data were selected to ensure diversity in style, content, and cultural background. Annotators identified gender stereotypes, which were rectified using LLMs and human educators. surveybased comparison found no significant difference in their effectiveness, highlighting the potential of LLMs in reducing gender bias. Since poetry was prominent genre in late antique and medieval Hebrew literature, the corpus is rich in figures of speech like similes and metaphors. However, Hebrew texts are often annotated manually, timeconsuming and labor intensive process. Thus Toker et al. (2024) present medieval Hebrew poetry dataset with expert annotations of metaphor, and evaluate several Hebrew language models for automatic metaphor detection. Iliad1 is one of the most significant pieces of ancient Greek poem. To propel the domain of emotion analysis in classical literature forward, Picca and Pavlopoulos (2024) present the first publicly available, emotion-annotated dataset of the Iliad1. Understanding humor is one of the most difficult cognitive ability of human. Ofer and Shahaf (2022) explore humor in the context of the popular card game Cards Against Humanity where players complete fill-in-the-blank statements using cards that can be offensive or politically incorrect. They introduce 300k online games of Cards Against Humanity, including 785k unique jokes, large and strongly labeled humor dataset. Addressing the lack of resources for humor datasets and evaluations in non-English languages, He et al. (2024) introduces Chumor, Chinese humor understanding dataset sourced from Ruo Zhi Ba, Chinese Reddit-like platform for sharing intellectually challenging and culturally specific jokes. One of the authors annotated all explanations in the dataset. Takeaways from Literary Forms. Stories and poems are actively studied for their valuable insights into culture knowledge and biases. However, beyond stories and poems, many other types of literature remain underexplored. For example, in fiction, genres like science fiction, historical fiction, and romance can provide unique cultural perspectives (Menadue and Cheer 2017). Also, non-fiction works, such as journalism and travel writing, can reveal peoples perceptions of their own culture and foreign cultures (Berger 2004), showing promising area for future research. Culturally Adapted Translation. Cultural adaptation has long been focus of translation studies (Newmark 2003). Effectively translating culture-specific items, such as idioms, historical references, and culturally unique concepts, is important for achieving effective cross-cultural communication (Rohmawati, Junining, and Suwarso 2022). Recent advancements in Machine Translation (MT), particularly multilingual pretrained models, have improved translation qualities, also for low-resource languages such as Ethiobenchmark proposed by Tonja et al. (2024), benchmark dataset of diverse downstream NLP tasks covering five Ethiopian languages with English. Similarly, Elmadany, Adebara, and Abdul-Mageed (2024) introduce Toucan, an Afrocentric MT model supporting 156 African language pairs, which significantly outperforms other 35 models in African language MT, as evaluated using the AfroLingu-MT benchmark. However, gap remains in effectively translating cultural-specific content due to the inherent cultural differences associated with various languages, not fully captured through MT techniques (Akinade et al. 2023). One such challenge is translating formal and informal tones appropriately, particularly in languages with honorifics or formality markers. Nadejde et al. (2022) address this issue with CoCoA-MT, dataset and benchmark for controlling formality in translations across six languages. By fine-tuning contrastive data, their model successfully controls for formality while maintaining overall translation quality, demonstrating the importance of aligning translations with cultural expectations. Yao et al. (2023) also contributes to this effort by enhancing the ability of MT systems to handle culture-specific entities. They introduce data curation pipeline by creating parallel corpus enriched with annotations specific to cultural items. Additionally, they suggest new evaluation metric to assess the understandability alongside accuracy of culturally adapted translations in reference-free manner. Similarly, Lou et al. (2023) introduce CCEval, Chinese-centric multilingual MT evaluation benchmark designed to assess translation quality across 11 languages, ensuring better alignment with human evaluations through rigorous dataset curation. Beyond literal translation, Han, Boyd-Graber, and Carpuat (2023) tackles the challenge of bridging background knowledge gaps through automatic explicitation. Using the WIKIEXPL1 dataset from Wikipedia, they generate contextual explanations that help clarify missing cultural context, improving understanding in multilingual question-answering frameworks. One of the most challenging areas in culturally adapted MT is literary translation, where the emotional and historical context plays vital role in conveying meaning (Jones and Irvine 2013; Toral and Way 2015). Thai et al. (2022) introduce the PAR3 dataset, aligning novels with human and machine translations, and find that human translations are significantly preferred by experts. Their post-editing model improves translation quality, showing potential for addressing discourse disruptions and stylistic inconsistencies in literary MT. Chen et al. (2024a) focus on translating classical Chinese poetry, which requires not only accuracy but also fluency and elegance. They propose Retrieval-Augmented Translation method that enhances translation by integrating external knowledge, addressing the limitations of LLMs handling poetry. Additionally, novel approach to literary translation is explored by Wu et al. (2024), who introduce multi-agent collaboration framework called TRANSAGENTS. This framework mirrors previous publishing processes by using multiple agents to translate complex literary works. To evaluate its effectiveness, they propose two innovative strategies: Monolingual Human Preference (MLP) and Bilingual LLM Preference (BLP), with MLP evaluating based on the preferences of the monolingual readers of the target language and with BLP leveraging LLMs to directly compare the translations with the original texts. Despite lower d-BLEU scores, translations from TRANSAGENTS are preferred by both human evaluators and LLMs, particularly in genres requiring domain-specific knowledge. Alongside literary translation, translating culturally rich components such as names and song lyrics has been investigated. Sandoval et al. (2023) highlight social biases in MT when translating names, particularly those associated with racial and ethnic minorities. They find significant disparities in translation quality for female-associated names from minority groups, emphasizing the need for bias mitigation in MT systems. Li et al. (2023a) tackle song translation, where lyrics must be aligned with melodies. They introduce Lyrics-Melody Translation with an Adaptive Grouping framework, enPawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond suring that translated lyrics fit the original tune, addressing both linguistic and musical challenges between cultures. Additionally, recent studies on K-pop lyric translation further highlight the complexity of translating music while preserving both meaning and melody. For example, Kim, Kim, and Bak (2024) introduce novel dataset focused on Kpop lyric translation, highlighting the need for dedicated datasets to better address the singability and cultural nuances of lyric translation. Moreover, Kim et al. (2024b) tackle the challenge of translating K-pop fan terminology through the KpopMT dataset, which focuses on in-group language systems used by K-pop fandoms. This dataset shows the difficulty of translating fan-specific terms and styles, with evaluations revealing low performance from current translation systems, including GPT models. Together, these studies emphasize the need for culturally sensitive and genre-specific translation techniques. Takeaways from Culturally Adapted Translation. Despite substantial progress in culturally adapted MT, much of the current work continues to align culture predominantly with language and nationality. Future research could delve into more nuanced levels of cultural adaptation within MT, such as tailoring translations to generational language preferences, more diverse regional dialects, or specific group terminologies. Culturally Adapted Dialogue Systems. Task-oriented dialogue (ToD) systems are crucial for multilingual interactions, but creating culturally adapted datasets is challenging. Early datasets were often on small scale, lacked naturalness, and failed to capture cultural nuances due to translation-based approaches (Ding et al. 2022; Hung et al. 2022). To overcome these issues, recent efforts, as follows, focus on generating culturally relevant dialogue data and improving language-specific model performance. Majewska et al. (2023) introduce the Cross-lingual Outline-based Dialogue (COD) dataset, which utilizes novel outline-based annotation process to create dialogues across diverse languages, covering Arabic, Indonesian, Russian, and Kiswahili while improving cultural specificity. Hu et al. (2023a) contribute with MULTI3WOZ, largescale multilingual ToD dataset designed to avoid translation artifacts and ensure cultural adaptation across languages. To capture implicit cultural cues in dialogue systems, Cao, Chen, and Hershcovich (2024) propose cuDialog, benchmark that leverages cultural dimensions from the Hofstede Culture Survey. Covering 13 cultures and 5 genres, this benchmark emphasizes the importance of understanding cultural differences, such as communication styles and shared metaphors, in dialogue systems. Expanding the scope of human-like interaction, Wang, Chiu, and Chiu (2023) introduce Humanoid Agents, system that simulates human-like behavior in dialogue agents by incorporating elements of System 1 thinking (Arvai 2013), such as basic needs, emotions, and relationship closeness. This allows agents to adjust conversations based on emotional states and social relationships, offering more intuitive, adaptive framework that complements linguistic and cultural adaptation in dialogue systems. Masala et al. (2024b) introduce RoCulturaBench, dataset manually curated by team of Romanian academics from the humanities field, addressing various significant aspects of the culture, ranging from artistic and scientific contributions to cuisine and sports. They significantly improve task performance. Each persons sociocultural background can affect their pragmatic assumptions in communication (Schramm 1954). Shaikh et al. (2023) introduces the CULTURAL CODES dataset, which operationalizes cross-cultural pragmatic inference. It is based on collaborative two-player word reference game called Codenames Duet, and includes 37 794 games with 7k turns, distributed across 153 unique players. They show accounting for background characteristics can improve model performance, indicating that integrating sociocultural priors can align models toward more socially relevant behavior in conversations. Takeaways from Culturally Adapted Dialogue Systems. As demonstrated by datasets like cuDialog (Cao, Chen, and Hershcovich 2024), RoCulturaBench (Masala et al. 2024b), and CULTURAL CODES (Shaikh et al. 2023), models that incorporate cultural dimensions and sociocultural priors show improved performance and alignment with real-world conversational contexts. However, these approaches still fall short in capturing dynamic cultural adaptation within ongoing interactions. Future work could explore adaptive dialogue systems that tailor responses in real-time, adjusting to subtle cues like shifts in tone, topic sensitivity, or cultural context, ultimately creating more contextually responsive and socially aware interactions. 5. Vision Models and Culture Recently, there has been increasing recognition of the significance of cultural inclusion in large models (LMs), which has inspired work on studying cultural understanding in vision language models. Vision language models have been used for long time for tasks like image captions, VQAs, image understanding, etc. Still, increasing interest and the need to understand the model outputs have led to research directions of testing these tasks for cultural inclusiveness. However, most vision language models (VLMs) have since been predominantly trained on data from Western languages and cultures, most notable being MS-COCO (Lin et al. 2014), Flickr 30K (Young et al. 2014) and LAION (Schuhmann et al. 2022), which limits their use case in non-western and lowresource languages. Additionally, cultural nuances in the images significantly affect the interpretation of the images (along with the text), making such study very important. To address these challenges and to develop VLMs that can effectively comprehend the cultural contexts of different countries, two directions are commonly approached in the literature: a) establishing comprehensive test benchmark across culture-specific tasks (Liu et al. 2021a; Romero et al. 2024); and b) proposing new and detailed culture specific datasets which can be tested or probed for cultural details. Both these directions are vital, as we need better quality culturally aware datasets and tasks or benchmarks to assess models capabilities to accurately interpret and respond to culturally specific inputs. Notably, prior research has tried to create VLM test benchmarks tailored to particular countries. We divide the current literature into two parts: language output (includes tasks such as image captioning, visual question answering, etc.) in 5.1 and image output (image generation) in Section 5.2 and study the nuances that literature has covered, to make these tasks culturally aware. We highlight the representative single-culture and multi-culture benchmarks in Figure 13."
        },
        {
            "title": "5.1 Language Output Tasks",
            "content": "Language output tasks are the ones that have language decoder as the output module and mixed vision-language encoder to process either input. To have culturally aware model for language output tasks, the vision and language encoder should be able to identify cultural concepts within the input text and image, and the decoder should generate culturally relevant outputs. Since humans from different cultures often perceive and interpret images differently, models should be designed to reflect these varying perspectives (Jahoda and McGurk 1974). Ye et al. (2023) argue that people from 38 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Vision Language Datasets and Benchmarks Single Culture Multiple/CrossCultural CVLUE (Wang et al. 2024g) - Chinese K-Viscuit (Baek et al. 2024) - Korean HaVQA (Parida et al. 2023) - Hausa FoodieQA (Li et al. 2024j) - Chinese OK-VQA (Marino et al. 2019) - English DrawBench (Saharia et al. 2022) - English DALL-Eval (Cho, Zala, and Bansal 2023) - English T2I-CompBench (Huang et al. 2023) - English TIFA v1.0 (Hu et al. 2023b) - English GenEval (Ghosh, Hajishirzi, and Schmidt 2023) - English GenAIBench (Li et al. 2024a) - English C3 benchmark (Liu et al. 2023a) - Chinese IndicTTI (Mittal et al. 2024) - India Word Wide Dishes (Magomere et al. 2024) - Africa SEA VQA (Nguyen et al. 2024) CCSK (Nguyen et al. 2023a) CULTURALVQA (Nayak et al. 2024) GDVCR (Yin et al. 2021) VLUE (Zhou et al. 2022) CVQA (Romero et al. 2024) MaRVL (Liu et al. 2021a) CCUB (Liu et al. 2023c) MC-18 Ye et al. (2024) UCOGC (Zhang et al. 2024d) CoCa-Crola (Saxon and Wang 2023) CulText2I (Ventura et al. 2023) CUBE (Kannen et al. 2024) Figure 13: Cultural Datasets and Benchmarks in Image-based Multimodal Tasks different cultural backgrounds observe vastly different concepts even in the same images, and multilingual datasets have more semantic content than monolingual datasets, accommodating this diversity. To further investigate this diversity; the research community has developed benchmarks to test the cultural capability of these models. In the following sections, we look into these benchmarks in the context of two language output tasks: a) image captioning and b) Visual Question Answering (VQA)."
        },
        {
            "title": "5.1.1 Visual Question Answering and Related Tasks. VQA (Antol et al. 2015) is a\ntask that requires model knowledge to answer textual questions based on a given\ncontext image. This task is essential for assessing a model’s reasoning ability across\nvisual and textual domains. Most existing VQA benchmarks are limited to the English\nlanguage (Marino et al. 2019). Ananthram et al. (2024) show that VLMs have Western\nbiases across subjective and objective visual tasks with culturally diverse images and\nannotations; they argue that while multilingual prompting can somewhat mitigate\nthe bias, a more diverse pretraining mix is a more suitable and effective solution for\nmitigating the Western bias. There have been recent attempts to expand this task to\nmultilingual VQA (Tang et al. 2024a). These works have shown the lack of nuanced\ncultural understanding, making this an open research question. Benchmarks can be\nspecific to a single culture or across many cultures. The former can dive deep into\nfiner and unique elements of a single culture (e.g., food eaten at a specific festival in\na country); the latter is helpful when we want to evaluate universal elements that are\nunderstood differently in different cultures (e.g., how clothing exists universally but\nlooks different across cultures). In the following sections, we discuss these specific and\nmulticultural benchmarks in more detail.",
            "content": "39 Dataset Creation Pipelines. Dataset creation for cultural assessment of models can be done by creating data from the web (scraped from the web with noisy web annotations), using the human-in-loop method (e.g., human filter data collected from the web and manually annotating them) or giving control to humans to create data (e.g., taking pictures from the surroundings) Baek et al. (2024) propose semi-automated pipeline for constructing cultural VLM benchmarks, where they demonstrate the usability of the pipeline by constructing dataset tailored to Korean culture: K-Viscuit. This pipeline uses human-VLM collaboration, where VLMs generate questions based on guidelines, human-annotated examples, and image-wise relevant knowledge, which native speakers then review for quality and cultural relevance. Nguyen et al. (2023a) create VQA dataset for Vietnamese culture with 33,000+ pairs of question-answer over three languages: Vietnamese, English, and Japanese, on approximately 5,000 images; the QA-pairs are first generated in Vietnamese and then translated to Japanese and English manually to study crosscultural perspectives. Some works, such as Multicultural Reasoning over Vision and Language (MaRVL) (Liu et al. 2021a), start with culturally relevant concepts and objects sourced from native speakers. Then the native speakers are asked to find relevant images to the concepts. On top of the concepts and images obtained through the process, statements are elicited from native speaker annotators about pairs of images. Along similar lines as MaRVL, Wang et al. (2024g) start by defining object categories related to culture (Chinese) and then collect images related to each object category; they start out with categories used in the MaRVL paper but remove the ones that are not relevant to Chinese culture, and add few relevant ones. Zhou et al. (2022) create new benchmark consisting of 5 tasks for evaluating the generalization capabilities of vision language models and use MaRVL as one of the Out-Of-Distribution test sets. Romero et al. (2024) proposes culturally diverse multilingual Visual Question-answering benchmark that covers 28 countries on four continents, covering 26 languages with 11 scripts, and involves native speakers as well as cultural experts in the data collection process; the native annotators were asked to source images from popular open-use licensing sources such as Flickr, GapMinder, Unsplash, Pixabay as well as personal photos. Training Methodologies and Models. Addressing cultural diversity in VQA has become critical challenge as models often struggle with context-dependent interpretations, especially when cultural knowledge is required. To study context-dependent interpretations, Bongini et al. (2020) created VQA dataset based on cultural heritage images from the Artpedia (Stefanini et al. 2019) dataset. Their methodology involves module that detects whether question requires cultural context, followed by gathering relevant external knowledge. This approach highlights the need for models to incorporate cultural awareness, often missing in conventional VQA tasks. Building on this, other researchers have focused on reducing biases and improving cultural equity in VQA. Yin et al. (2023) introduced new pre-training objectives that explicitly model differences in visual concepts across regions. By addressing biases against underrepresented groups, they aim to ensure more equitable performance across diverse geographical areas. Another significant development comes from Li and Zhang (2023), who propose an annotation-free method for adapting visual cultural concepts. Their work constructs concept mapping set and leverages high-resource cultures to help models understand low-resource ones, making it easier for models to generalize across cultural contexts without requiring extensive manual annotation. They also propose multimodal data augmentation technique, CultureMixup, which mixes cultural concepts in images to enhance the models ability to reason visually across languages and Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond cultures. Finally, Nguyen, Razniewski, and Weikum (2024) demonstrate that the inclusion of translated multilingual data in training improves the performance of models on geographically diverse tasks such as GeoDE, further emphasizing the importance of cultural and linguistic diversity in building robust VQA models. Mono-Cultural Benchmarks and Multi-cultural Benchmarks. Benchmarks can be specific to single culture or across many cultures. The former can dive deep into finer and unique elements of single culture (e.g., food eaten at specific festival in country); the latter is helpful when we want to evaluate universal elements that are understood differently in different cultures (e.g., how clothing exists universally but looks different across cultures). In the following sections, we discuss these specific and multicultural benchmarks. Culture-specific benchmark involves creating tasks ranging from image-text retrieval to visual question answering, visual grounding, and visual dialogue, as the data collection methodology varies little across the tasks. Works have been done on creating culture-specific benchmarks, such as CVLUE (Wang et al. 2024g) for Chinese, K-Viscuit (Baek et al. 2024) for Korean, Parida et al. (2023) for the Hausa language, etc. While creating culture-specific benchmarks, images are either manually curated (e.g., asking annotators to find relevant images on the web) as in CVLUE, K-Viscuit, or sources from already existing datasets such as Visual Genome as in Parida et al. (2023). FoodieQA (Li et al. 2024j) is another recent work with manually curated, fine-grained image-text dataset capturing the intricate features of food cultures across various regions in China. These benchmarks highlight the presence of sub-cultures within culture that other generalized benchmarks might miss. Most VQA benchmarks explicitly testing VLMs cultural awareness are multicultural. These benchmarks highlight the lack of multicultural perspectives amongst the current VLMs. Some benchmarks, such as CULTURALVQA (Nayak et al. 2024), have questions that probe for the understanding of various facets of culture, such as clothing, food, drinks, rituals, and traditions across various countries; benchmarking various VLMs on CULTURALVQA, reveals disparity in their level of cultural understanding across regions, with strong cultural understanding capabilities for North America while significantly lower performance for Africa. Yin et al. (2021) construct Geo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test VLMs ability to understand cultural and geo-location-specific commonsense; the benchmark is based on TV series and movies across countries from four regions: Western, East Asian, South Asian, and African countries. Evaluation Frameworks and Metrics. While most work has been on creating benchmarks that measure cultural awareness, there has been little on creating frameworks for measuring cultural alignment. Kannen et al. (2024) introduce framework to evaluate the cultural competence of VLMs along dimensions such as cultural awareness and cultural diversity, along with an approach to construct and build large dataset of cultural artifacts to enable evaluation along these dimensions. Baek et al. (2024) propose human-VLM collaboration pipeline, where VLMs generate questions based on guidelines, human-annotated examples, and image-wise relevant knowledge, which are then reviewed by native speakers for quality and cultural relevance. In nutshell, these works highlight the growing recognition that cultural awareness, bias reduction, and multilingual data are essential for advancing VQA systems that can reason effectively across diverse contexts."
        },
        {
            "title": "5.1.2 Image Captioning. Culturally aware image captioning includes recognizing the\ncultural context of the image (cultural relevance of objects, recognizing culture-specific",
            "content": "41 objects, etc.) and describing the image based on the cultural context. Burda-Lassen et al. (2024) compares the performance of various vision-language models (GPT-4V, Gemini Pro Vision, LLaVA, and OpenFlamingo) on identifying culturally specific information in images and creating accurate and culturally sensitive image captions. They define new evaluation metric, Cultural Awareness Score (CAS), to measure the degree of cultural awareness in image captions and provide dataset of 1.5k, labeled with ground truth for images containing cultural background and context. Cao et al. (2024d) probe GPT4V using the MaRVL (Liu et al. 2021b) benchmark, aiming to investigate its capabilities by using variations of image captioning viz. caption classification, pairwise captioning, and culture tag selection, and they note that GPT-4V can identify more cultural concepts than humans but has lower performance than humans when generating captions in low resource languages. Ye et al. (2023) find that multilingual descriptions have on average 29.9% more objects, 24.5% more relations, and 46.0% more attributes than set of monolingual captions and make case for having multilingual captions for better cultural inclusion. Yun and Kim (2024) propose Culturally-aware Image Captioning (CIC) that generates captions and describes cultural elements extracted from cultural visual elements in culture-specific images. Thapliyal et al. (2022) start with set of 36 languages (which have high web coverage) for captioning, then sample images from geo-localized Open Images dataset (Kuznetsova et al. 2020) using an algorithm that maximizes the percentage of selected images taken in an area where the assigned language is spoken. Some works extend board games and tests that are used to assess cultural awareness among humans to an image captioning tasks for LLMs. For example, Kunda and Rabkina (2020) suggest games such as Dixit Board game and its variants (Bekesas et al. 2018), which involve generating creative captions, could be played between VLM agents to access cultural understanding of each agent. Captioning-pecific Cultural Elements. Ma et al. (2023) refer to existing literature on food datasets and creates new food dataset that spans across various geographical regions and presents case for in-domain generalization in VLMs rather than out-ofdomain generalization and tailoring the VLMs to specific elements. Multiple works also look at the offensiveness of memes (Liu et al. 2022a) and changes in offensiveness and annotation of memes based on culture (Sap et al. 2022; Pramanick et al. 2021). Takeaways from 5.1. Multiple benchmarks for VQA, visual reasoning, and captioning have been created, each varying in scope, diversity, and cultures they cover. Some cover broad spectrum of cultural elements, while others focus on specific cultural elements, like food, in-depth. There is also variation in approaches to geodiversity. Some studies ensure that geo-diverse annotators label similar images, whereas others incorporate both geo-diverse annotators and images. Moreover, researchers also have different assumptions about cultural diversity. Some link geographic diversity to cultural diversity, while others use linguistic diversity as proxy. Many datasets enhance existing image collections with region-specific annotations by local annotators, while others gather culturally specific images directly from the web, providing rich source of contextually relevant visuals. The research community could benefit from consistent methods for studying cultural diversity using benchmarks and from having common standards for measuring cultural understanding in visual tasks. To expand benchmarks to new cultures, some studies use culturally adapted translation (e.g. machine translation of texts), recognizing that identical objects may carry different cultural meanings. However, using local annotators (who understand the language of the culture being studied) can reduce biases introduced by translation, providing more authentic cultural insights. 42 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond"
        },
        {
            "title": "5.2 Image Output Tasks",
            "content": "Image Output tasks are the ones that have an image component as the output. They broadly fall into these categories: a) Text-to-image generation (T2I); b) Text-based image manipulation; and c) Image in-painting via textual prompts. The models used for these image output tasks do not have an explicit decoder in the traditional sense (like in LLMs). The process of image generation is usually handled by nontransformer decoders, such as diffusion models (Ramesh et al. 2022; Saharia et al. 2022; Rombach et al. 2022; Zhang, Xu, and Li 2017), GANs(Xu et al. 2018), or variational autoencoders(Razavi, van den Oord, and Vinyals 2019). Initial years of research focused on image generation quality and prompt image alignment. More recently, it has become evident that cultural diversity in generated images remains significant gap, prompting recent efforts to develop culture-specific approaches, metrics, and benchmarks to ensure more inclusive and contextually aware outputs. Mono-cultural and Multicultural Benchmarks. Generating culturally specific images is challenging task that requires not only that model produce coherent images but also incorporate culture-specific themes, styles, and contexts. This issue is amplified by the fact that T2I models are limited by the scarcity of languages they are trained on, leading to bias in the generation of cultural elements. Various works have discussed these biases specific to single cultures. Liu et al. (2023a) discuss this gap in Chinese in the context of the generation of relic images, (Magomere et al. 2024) for African food culture from 5 countries. Jha et al. (2024) take it beyond singular culture and study these biases and stereotypes of people across various countries, e.g., Omani, Ukrainian, Swiss, Canadian, Mongolian, Indian, Australian etc. On similar lines, Zhang et al. (2024d) investigated cultural representativeness, but unlike other works that select representatives by geography, they work with what they call cultural clusters (e.g., LatinAmerican, Latin-European, Middle Eastern, Nordic, etc.) and choose 3 countries with the largest populations to represent these cultural clusters; they found homogenization of some data in T2I models, especially in disadvantaged cultures (e.g., from Africa). Bansal et al. (2022) studied them from an ethical perspective and observed changes in image generations conditional on ethical interventions. They study image generations on three social axes gender, skin color, and culture and found that models can generate images of diverse groups with prompts containing ethical interventions (e.g., by using keywords like irrespective of gender for gender bias and culture for cultural bias). Ventura et al. (2023) take this even further and study these cultural embeddings across three tiers: cultural dimensions, domains, and concepts; they also propose the CulText2I dataset consisting of images generated by six distinct TTI models for evaluating these axes. As cultures are region-specific, work has been done to fine-tune these models with datasets curated to represent culture-specific concepts, e.g., artwork, landmarks, and artistic styles of culture. E.g. Amadeus et al. (2024) fine-tuned DreamBooth (Ruiz et al. 2023), T2I model, to evaluate the models understanding of regionalism, culture, and historical value of the state of RS, Brazil. (Deng, Cao, and Cheng 2024) fine-tuned the Stable Diffusion model using the Low-Rank Adaptor (LoRA) to generate historical Chinese Artifacts. However, as much as it is desired, it is not always possible to create model for each culture. Culture-pecific T2I models. There is need for either a) more robust model trained with multilingualism and aligned for cultural concepts or b) better architectural approaches to make models culturally inclusive. Ye et al. (2024) attempted to address the first gap by training multilingual T2I model, trained on 18 languages, and showed that their model outperformed Stable Diffusion in generating culture-specific concepts. 43 Liu et al. (2023c) and Zhang et al. (2021) attempt to close the second gap. Where Liu et al. (2023c) proposed new approach to making model culturally inclusive by pretraining the T2I synthesis model and adding semantic context using their Cross-Cultural Understanding Benchmark (CCUB) Dataset, M6-UFC (Zhang et al. 2021) extend the transformer-based architecture to generate culturally diverse images conditioned on the context provided by text prompts in regional languages (in this case Chinese). Each research either chooses one of the T2I models or multiple of them but thee is no standard list of models for comparison. Popular ones include both open source and closed source models e.g. DALEE, Stable Diffusion, Imagen. (Basu, Babu, and Pruthi 2023), while investigating for geographical representativeness of generated images on 27 countries in two popular T2I models (DALLE and Stable Diffusion), observed that DALLE-2 was more representative of the cultural artifacts when using country-specific prompts, as compared to Stable Diffusion showing that closed source models may have slightly better cultural alignment than open source T2I models. During their human evaluation, they found that when the input prompt did not include any specific country name, users from 25 out of 27 countries felt that the generated images were less representative of the country-specific artifacts. Evaluation Metrics. Unlike LLMs, in T2I tasks, it is hard to develop standard evaluation task that is objective. Evaluating image generation models involves variety of metrics that can assess quality, coherence, diversity, and alignment with textual prompts. For example, while GPT-3 was introduced with impressive zero-shot performance across many classification tasks, DALLE-2, OpenAIs T2I model (Ramesh et al. 2022) was shown to have good human opinion scores. As T2I models have become increasingly better in image quality, many metrics have been proposed to evaluate these models. Most of these metrics are qualitative (looking at the images and evaluating if they are correct representations of culture), though there is an increasing amount of work to set up qualitative metrics. Fréchet Inception Distance (FID) (Yu, Zhang, and Deng 2021) and Inception Score (IS) are the most popular and are commonly used to measure the visual quality and diversity of generated images against real-world distributions. CLIP Score, based on CLIP model (Radford et al. 2021), is also used to evaluate the coherence between generated images and text inputs. However, these metrics do not cover culture-specific nuances. Struppek et al. (2023) propose to measure bias in these T2I models by showing that image generations are skewed by simply inserting single non-Latin characters in textual description. They rely on 3 metrics to measure cultural biases, 2 for studying generated images and 1 for prompts used. Kannen et al. (2024) showed that measuring cultural awareness and cultural diversity is important for framework to evaluate the cultural competence of T2I models. Evaluation Benchmarks. More recently, there have been attempts at developing T2I benchmarks considering cultural nuances. Zhang et al. (2024d) who discuss cultures as cultural clusters, built Unique Cultural Objects from Global Clusters (UCOGC) dataset as an evaluation benchmark for the diversity of T2I models. As this benchmark covers both material and nonmaterial cultural subjects in both comprehensiveness and diversity, its good benchmark for evaluating the quality of generated culture representativeness in T2I models. Other recent benchmarks include T2I-CompBench (Huang et al. 2023), TIFA v1.0 (Hu et al. 2023b), and GenEval (Ghosh, Hajishirzi, and Schmidt 2023), and GenAIBench (Li et al. 2024a) which leverage diverse prompts and metrics to evaluate aspects such as image-text coherence, perceptual quality, attribute binding, faithfulness, semantic competence, and compositionally. We also have Drawbench (Saharia et al. 2022) and DALL-Eval (Cho, Zala, and Bansal 2023), which aim for comprehensiveness in benchmarks. Where DrawBench proposes the evaluation of 44 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond various categories (colors, numbers of objects, spatial relations, text in the scene, and unusual interactions between objects); DALL-Eval proposes the evaluation of visual reasoning (object counting, VQA etc.) as well as social bias (gender, colour etc.). More recently, Saxon and Wang (2023) question these benchmarks because though they all aim for different goals, it is challenging to determine if these benchmarks accurately represent the practical tasks expected of the model within real-world contexts. The proposed CoCa-Crola benchmark uses 3 distinct metrics, Distinctiveness, Self-Consistency, and Correctness, as technique for benchmarking the degree to which any generative text-to-image system provides multilingual parity to its training language in terms of tangible nouns. Liu et al. (2023a) propose C3 benchmark to study cultural relevance and image quality and propose evaluation on 6 metrics: cultural appropriateness, object presence, object localization, semantic consistency, visual aesthetics, and cohesion. Unlike Saxon and Wang (2023), who focus on generating simple concepts through translation, Mittal et al. (2024) focus on prompts describing multiple elements in the generated image. They investigate bias in T2I models in 30 Indic languages on Stable Diffusion, Alt Diffusion, Midjourney, and Dalle3 and evaluate on 4 proposed metrics: Cyclic Language-Grounded Correctness (CLGC), Language-Grounded Correctness (LGC), Image-Grounded Correctness (IGC) and Self-Consistency Across Languages (SCAL). Takeaways from 5.2. Although there has been increasing work on evaluating large multimodal models for cultural awareness, there is greater need for models trained with balanced multilingual and culture-specific data to ensure solid multilingual and cultural capabilities. Additionally, there is no standardized list of evaluation methods, with each study selecting the methods independently. Metrics for image output tasks, such as measuring cultural awareness in VQA and T2I models, are also not standardized and remain significant future direction to explore. Overall, developing consistent metrics to test cultural awareness in text-to-image models remains significant future direction that could be explored."
        },
        {
            "title": "5.3 Art Forms Related Tasks",
            "content": "Art forms and paintings evoke different emotions across different cultures and have been considered used by the community to study the expression of emotions across cultures (Mohammad and Kiritchenko 2018; Achlioptas et al. 2021). There have been multiple studies on art and generating art using Vision models recently. One of the main goals when studying and examining art forms is to match the objects in an image to their symbolic meaning. Zhang et al. (2023) create dataset for dataset for art understanding deeply rooted in traditional Chinese culture; they address three tasks: identifying salient visual elements, matching elements with their symbolic meanings, and explanations for the conveyed message. Hamilton et al. (2021) create web application named MosAIc, that allows users to find pairs of semantically related artworks that span different cultures, media, and millennia; they use Conditional Image Retrieval (CIR), which combines visual similarity search with user-supplied filters or conditions. To study the similarity between arts across cultures and evaluate culturaltransfer performance, Mohamed et al. (2022) creates dataset of 80k artworks, with many artworks being annotated by multiple people in three languages. Fan, Wang, and Hodel (2023) create multimodal knowledge graph linking visual entities and concepts associated with the entities. Zhang et al. (2024f) addresses the challenge of translating the nuanced symbolism in art, which involves interpreting complex cultural contexts, aligning cross-cultural symbols, and validating cultural acceptance. Ozaki et al. (2024) 45 create dataset of artworks and explanations in multiple languages with nuances and country-specific phrases."
        },
        {
            "title": "5.4 Miscellaneous Tasks",
            "content": "The following works introduce new tasks, including variants of image captioning, image classification, or somewhere in between, to better access the cultural understanding in Vision language models. Buettner et al. (2024) attempts to improve object recognition models to be more robust to objects from geographically diverse regions. M5 (Schneider and Sitaram 2024), for example, collects data for 12 languages to pair it with photos from the regions that speak those languages. The authors then create benchmark for tasks such as visually grounded reasoning, visual question-answering (VQA), visual natural Language inference (VNLI), visio-linguistic Outlier detection (VLOD), and captioning. They introduced new novel benchmarks, such as M5-VGR and M5-VLOD, including new Visio-Linguistic Outlier Detection task. The images for M5 are sources from the Dollar Street dataset (Rojas et al. 2022), comprising around 38K photos taken in 63 different regions or countries. These photos depict the lives of families, including their homes, neighborhoods, or everyday objects, in culturally diverse way. There is no explicit paring between languages/cultures and images. Pappas et al. (2016) conduct crowdsourcing experiment to annotate the sentiment score of visual concepts from 11 languages associated with 16,000 multilingual visual concepts. The MVSO dataset (Jou et al. 2015) is used as the source of visual concepts, and the photo-sharing service Flickr is used as the source of images. Zhang et al. (2024c) create dataset that spans 30 countries almost 2 centuries; their goal is to test if VLMs can identify cultural markers required to determine the time and place photo was taken. On similar lines, Hsiao and Grauman (2021) provide data-driven approach to identify specific cultural factors affecting the clothes people wear where they use news articles and vintage photos spanning century to create model that detects influence relationships between happenings in the world and peoples choice of clothing. Li et al. (2022) construct multimodal knowledge graph for classical Chinese poetry (PKG), in which the visual information of words in the poetry are incorporated for the task of poverty image retrieval. Zhang et al. (2024e) propose preference-based reinforcement learning method that fine-tunes the vision models to distill the knowledge from both LLMs reasoning and the aesthetic models to better align the vision models with human aesthetic standards, which vary with culture. Khanuja et al. (2024) introduces new task of translating images to make them culturally relevant by changing concepts in an image that varies with culture. Takeaways from 5. Apart from takeaways mentioned in specific subsections, Some papers model cultural change in images across time, an important aspect missed when using images directly from the internet as source. Most of the vision papers do assume that language implies culture, but they use the assumption that geographical region corresponds to culture. Automatic data scraping methods that rely on getting culturespecific images based on the language of the caption (from sources like Wikipedia) can lead to language culture bias, where multiple cultures sharing the same language may be merged into single, undifferentiated culture. 46 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Music Recommendation Problem (Weck et al. 2024) Bias (Moradi, Neophytou, and Farnadi 2024) Cultural awareness in Video and Audio models Emotion/Affect Recognition Amiriparian et al. (2024b) Zhang et al. (2024b) Duret et al. (2023) Khandelwal et al. (2024b) Amiriparian et al. (2024a) Mathur, Adolphs, and Mataric (2023) Jia, Zhang, and Liang (2024) Content Moderation Wang et al. (2024c) Sharma et al. (2022) Shah and Kobti (2020) Figure 14: Areas explored for cultural adaptation in video and audio modalities, with representative examples. Music recommendation involves only the audio modality, emotion/affect recognition has been explored in both audio and video modalities, and content moderation has been explored for videos and memes. 6. Other Modalities and Culture In this section, we include papers that look at cultural adaptation in other modalities, such as videos, audio, etc., tasks that do not fall under the text-only or visionlanguage [text+images] tasks but have text (semantic content) as one of the components. We highlight major areas and representative papers in figure 14."
        },
        {
            "title": "6.1 Audio and Speech",
            "content": "While understanding the cultural context in music and speech may not always involve text (semantic content) as one of the component major components, music recommendations require understanding the culture-specific preferences of the user as well as the cultural context in the query (Weck et al. 2024). Moradi, Neophytou, and Farnadi (2024) study cultural biases in music recommendation systems and provide method to improve fairness in music recommendation systems. Li et al. (2024i) argue that understanding the cultural context should be one of the goals that should be prioritized while building Foundation Models for music. One of the applications where understanding data streams such as speech becomes important along with semantic content is emotion recognition, as the expression of emotions varies across cultures. Belani and Flanigan (2022) study the relation between emotional expression and code-switching for Spanish. Amiriparian et al. (2024b) gather comprehensive multilingual, multicultural speech emotion corpus with 37 datasets, 150,907 samples, and total duration of 119.5 hours. Tran, Yin, and Soleymani (2023) demonstrate personalized and adapted speech encoders for continuous emotion recognition. Sapinski and Kami nska (2015) look at emotion detection based on audio characteristics and the semantic content in tandem. Zhang et al. (2024b) propose multimodal LLM-based multi-agent system designed for simulating human communication along with rich emotions expressed through speech and semantic content (text). As the research in textless speech-to-speech translation continues to grow, it is important to ensure that expressions and emotions are translated (and mapped) correctly across languages. Duret et al. (2023) propose method to enhance expressivity transfer in 47 textless speech-to-speech translation. Wunarso and Soelistio (2017) create dataset for speech-emotion detection for Indonesian. There have been few works that look at the presence of subculture within border culture and collect data to understand cultural nuances. Javed et al. (2024) collect dataset (INDICVOICES) of natural and spontaneous speech covering 16237 speakers covering 145 Indian districts and 22 languages to capture the cultural, linguistic, and demographic diversity of India. SEACrowd(Lovenia et al. 2024) carry similar efforts and collect data for 1000 Southeast Asia (SEA) languages spanning 3 modalities, with one of the goals being reducing cultural misrepresentation and flattening. Takeaways from 6.1. While most relevant works in the audio domain focus on emotion recognition and music recommendations, there has been lack of works that simultaneously model audio and text (semantic content) to understand the cultural context part from emotions. This capability could be useful for applications such as voice assistants. Works such as IndicVoices (Javed et al. 2024) and SEACrowd (Lovenia et al. 2024) are some initial efforts in the direction of collecting culturally diverse speech-text data. One of the limitations of datasets such as SEACrowd and IndicVoices is that they collect speech data in controlled setup, typically by asking questions and recording responses, which may not accurately capture the nuances of everyday conversations."
        },
        {
            "title": "6.2 Video",
            "content": "In the case of video modality, most work has been task-specific cultural adaptation, focused mainly on emotion detection and content moderation. Cultural factors also affect personality (Walker et al. 2011) and how people interact in certain situations, Khan et al. (2020) create multimodal dataset of peer-to-peer Hindi conversations to study the variance of personality with factors such as income and cultural orientation. Funk, Okada, and André (2024) studies how culture affects the non-verbal features (such as facial expressions and tone) of the speakers during conversations. Amiriparian et al. (2024a) create dataset for the cultural humor detection challenge, which focuses on cross-lingual and cross-cultural multimodal humor detection, as humor detection depends not only on words but also on gestures and facial expressions. SEWA DB (Kossaifi et al. 2019) is dataset of conversations between people coming from different cultures during various social situations; the dataset contains videos annotated with facial landmarks, facial action units (FAU), various vocalizations, mirroring, and continuously valued valence, arousal, liking, agreement, and prototypic examples of (dis)liking. The AVEC challenge through the years has looked at (and created datasets) for cross-cultural emotion detection (Ringeval et al. 2019). Detecting emotional cues (affect recognition) is an important part of Human-Computer Interaction systems, Mathur, Adolphs, and Mataric (2023) study intercultural affect recognition models using videos of real-world dyadic interactions from six cultures. Zhao et al. (2022) create multi-modal, multiscene, multi-label emotional dialogue dataset from 56 TV series capturing Chinese culture. Migon Favaretto et al. (2019) presents video analysis application to detect personality, emotion, and cultural aspects of pedestrians in video sequences, along with visualizer of features (the features include elements of well-known frameworks such as Hofstede Cultural Dimensions). The works studying the effect of culture on emotional (body) gestures and the speech uttered during the gestures have been reviewed in Noroozi et al. (2018). Jia, Zhang, and Liang (2024) propose multimodal strategy for emotion recognition based on facial expressions, voice tones, and transcripts from video clips. Liu, Courant, and Kalogeiton (2024) propose multimodal approach based on transcripts, video-frames, and audio for detecting funny moments in video clips of 48 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond tv-series. Bruno et al. (2019) presents case for embedding cultural knowledge into personal robots, as home activity recognition can be improved using cultural knowledge is used (Menicatti, Bruno, and Sgorbissa 2017). Rehm et al. (2009) provides guidelines for creating video Recordings of multimodal interactions across cultures. With the rise in online video-sharing platforms, multimodal hate speech detection has become an integral part of content moderation (Hee et al. 2024). Wang et al. (2024c) create multilingual dataset of videos annotated for hatefulness, offensiveness, and normalcy and argue that the dataset provides cross-cultural perspective on genderbased hate speech. The rise in memes as source of information sharing Shifman (2013) has also fueled interest in automatically detecting harmful and biased memes (Sharma et al. 2022). As memes marked as normal by one culture can be offensive to others, understanding the cultural context in the memes becomes necessary (Hegde et al. 2021). Shah and Kobti (2020) propose methodology that uses situational and normative knowledge to detect fake news using text and images. Lyu et al. (2023) use GPT-4V for hate-speech detection in multimedia using cultural insights; they also look at multimodal sentiment analysis in cultural context using GPT-4V. Takeaways from 6.2. The analysis of cultural nuances in day-to-day interactions between people and videos of day-to-day activities is often missing, while the major focus is memes, personality, and hate speech. Videos can be an important source of cultural information. Although there have been works looking at information extraction from videos (An et al. 2023), extracting culture-specific information from videos can be an important next step. There has been rise in video generation models (Ho et al. 2022), and how people perceive video also depends on cultural background (Scott et al. 2015), so the video generation models should consider cultural context as one of the input features for the video generation model. 7. Language and Region Coverage We manually annotated the languages and regions covered by benchmarks and evaluations presented in 4.2 and benchmarks in 5 and 6. For languages with multiple names (e.g., endonyms) or variations (e.g., dialects), we standardize them based on the conventions in Joshi et al. (2020). For regions, we visualize the distribution at the country level, including only countries explicitly mentioned by the authors in their manuscripts. We chose country-level analysis since most papers emphasize national cultures. Subregional cultures were aggregated under their respective countries, and broader regions were excluded from our analysis. Figure 15(a) presents the frequency distribution of languages used in the evaluations, showing only languages with frequency of two or more. The colors indicate the language resource classes from Joshi et al. (2020), with darker colors (with higher numbers) representing higher-resource languages. As discussed in previous surveys (Liu, Gurevych, and Korhonen 2024; Adilazuarda et al. 2024), most studies collect data in English. Chinese, Spanish, and German are other high-resource languages observed frequently in cultural studies. Also, research in Korean, Indonesian, Bengali, and Swahili has been relatively active compared to other languages of their resource levels. Notably, for most languages classified as level 2 or below, there are at most seven studies, with the only exception of Swahili, underscoring the gap in research. 49 (a) Distribution of the language (b) Distribution of the countries Figure 15: Distribution of the languages and the countries covered in model evaluations. (a) The colors represent the language resource classes from Joshi et al. (2020). The plot includes only languages that appear two or more times. Figure 15(b) visualizes the target countries of the research on cultural language models.7 Most of the studies focus on WEIRD (Western, Educated, Industrialized, Rich, and Democratic) countries (Henrich, Heine, and Norenzayan 2010), along with regions such as East Asia, Indonesia, and India. In contrast, countries in Africa, Central and South America, Eastern Europe, and Central Asia are significantly underrepresented. Even for studies including underrepresented nations, the diversity of data sources tends to be limited, often relying on global surveys like the World Values Survey (WVS) (Survey 2022) or publicly available online platforms such as Wikipedia. Additionally, 7 We generate the choropleth map with Datawrapper at https://www.datawrapper.de/maps/choropleth-map. Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond the volume of data points across different regions frequently varies, further contributing to an uneven representation. The scope of our analysis of cultural coverage is limited by the inability to account for macro-level regions such as continents and broad cultural groups with boundaries that do not align with national borders. In particular, while Arabic is one of the languages studied extensively, many of those studies broadly lump the cultural sphere together under the label of the Arab world. Recognizing the challenges of defining the exact boundaries of cultures, researchers should nonetheless strive for the most accurate representation of the cultures they examine. Additionally, our analysis lacks finer-grained sub-regional or historical district breakdowns, which represents another notable gap in current cultural NLP research. 8. Implications to AI Ethics, Social Sciences, and HCI"
        },
        {
            "title": "8.1 Ethics of Cultural Alignment",
            "content": "The incorporation of cultural information into general-purpose foundational models is an important research direction. Whether the outputs of these models are intentional or accidental, they co-create our sense of meaning and identity and have an impact on shaping our collective knowledge (Lu, Kay, and McKee 2022). Lack of appropriate cultural representation can lead to several harms, including disparate access due to performance gaps, imposition of hegemonic classifications, violation of cultural values, misinformation, or stereotypes about cultures, misrepresentation of cultural experiences, and outright erasure of cultures (Prabhakaran, Qadri, and Hutchinson 2022; Kay, Kasirzadeh, and Mohamed 2024). Communication across different cultures differs substantially, some are low context while others are highly contextual in the way they communicate, both in the real world (Liu 2016) and online (Würtz 2017). Imposition of one cultures communication style on another can lead to erasure and flattening of cultures. mismatch or misalignment in these styles can lead to problems pertaining to intercultural communication like misunderstanding, distrust, and conflict. Therefore, it is crucial to be careful in approaches towards cultural alignment. Further, since using generative models for writing can impact the opinions of the users themselves (Jakesch et al. 2023b), there are also broader questions about the systemic impact on users and society at large (Burton et al. 2024) that need to be taken into account during this process. To tackle the problem of lack of cultural knowledge, several papers have tried to adapt existing models and incorporate features for other cultures across different tasks, hoping to improve performance on tasks requiring cultural knowledge. These include tasks like Affect Detection (Neiberg, Laukka, and Elfenbein 2011), Offensive Language Detection (Zhou et al. 2023c), Humor Detection (Xie et al. 2023), Recipe Adaptation (Cao et al. 2024c), among others. Across these efforts, there is an underlying assumption that since cultural knowledge is required for these tasks, cultural alignment will improve cross-cultural performance on them. However, while there are improvements on the performance on the datasets, it is unclear whether the improvement is due to the actual incorporation of cultural knowledge or due to surface level features in the datasets that the models are picking up. When evaluated with domain experts, models often fail to appropriately use cultural information. For instance, in experiments with comedians for co-creating humor, LLMs fail to produce non-bland or generic outputs, especially when text is about cultures other than the dominant ones embedded into the model (Mirowski et al. 2024) or when used for mental health support, LLMs fail to adapt based on the 51 cultural background of the users and provide misaligned recommendations (Song et al. 2024). There are also issues concerning what cultural information is available to encode. Since data for inclusion is primarily scraped from the internet, which is biased sample of what cultural information exists, it only captures some aspects of knowledge (Bender et al. 2021). The long tail of cultural information, which pertains to everyday tasks, is unspecified or not recorded and hence does not make it to the datasets. There are efforts to address this and benchmark the performance of models on everyday knowledge (Myung et al. 2024a), but the area is largely ignored, making it core limitation for both model designers and practitioners. Further, since large language models are increasingly being used as writing assistants and sources of synthetic data, which has an impact on the diversity of the content that is generated (Padmakumar and He 2023) and the values embedded therein (Wright et al. 2024; Santurkar et al. 2023). The data that is being used to train these models will constantly reinforce one set of values and more biased models. This will lead to poorer representation of diverse cultural representation in model outputs, resulting into potential cultural model collapse (Shumailov et al. 2024). Beyond harms associated with non-inclusion or simplistic inclusion of cultures, there are also harms associated with explicit inclusion of culture. Kirk et al. (2024) outline this by creating taxonomy discussing the benefits and harms of personalizing language models. They show that while there are clear use cases of aligning language models such as the increased autonomy, empathy, and usefulness, one should be considerate of the often overlooked harms that such alignment can bring. The study shows how each benefit that personalization brings has potential harm resulting from it, recommending that model designers and practitioners have to take these trade-offs into account when creating or deploying these models. For instance, they increased usefulness or empathy in models can lead to dependency on these models and contribute to their anthropomorphism. Similarly, at societal level, adaptation to each culture can contribute to increased polarization and labor displacement. Further, it is unclear what the correct approach is when the culture that needs to be included has fundamentally opposing values to the ones where models are usually created. When NLP research suggests alignment, it is typically associated with cultures which are not at odds with the value systems of western nations. Further, there is also cultural information that is unsafe. For instance, medical advice from certain cultures challenges western notions of medicine and advises against relying on it, instead promoting local forms of medicine, which can at times be harmful. Another related example is alignment to fringe or extremist communities. With adapted generative models, the potential for harm that they can cause would also be much higher when used for nefarious purposes by malicious agents (Kaffee et al. 2023). Alignment in such scenarios can lead to unsafe behavior, thus bringing forward this trade-off between two desirable characteristics of model behavior. Finally, there are also questions about whether building general-purpose systems suitable for all audiences is the right way forward (Gabriel 2020). In their work, ZhiXuan et al. (2024) highlight some assumptions made by current AI alignment efforts, namely that human preferences (which is the dominant method of encoding values) are an adequate representation of human values and AI systems should be aligned with preferences of one or more humans to ensure that they behave safely and in alignment with our values. They challenge these assumptions, critiquing the normativity of expected utility theory as the dominant method for alignment of AI assistants. They argue that these systems should instead be domain-specific and aligned based on standards 52 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond negotiated upon by the corresponding users and stakeholders, allowing for meeting diverse needs and co-existing in the presence of pluralistic values. In cultural context, such system would benefit multicultural societies where certain normative standards have been established."
        },
        {
            "title": "8.2 Accelerating Social Science Research",
            "content": "There has been lot of optimism and uptick in adoption from the social sciences towards AI systems aiding in research. They have been used in several fields, including psychology, sociology, political science, history, and many others, for different tasks. While the appropriateness and motivation for using them as an accurate representation of society is an ongoing discussion (Grossmann et al. 2023; Agnew et al. 2024), they certainly aid in performing several subtasks relevant for social science research (Ziems et al. 2024; Bail 2024). Across these fields, they serve variety of different purposes. For some, they aid in the analysis of large volumes of content (Törnberg 2024), extracting dispositions from social media (Peters and Matz 2024) to make inferences about users, while for others it is simulation of responses of human samples for surveys (Argyle et al. 2023b; Manvi et al. 2024) or serving as agents for agent-based modeling methods for predicting hypothetical behavior (Horton 2023; Grossmann et al. 2023). They have also been used for interventions to existing ecosystems (Yang et al. 2024; Argyle et al. 2023a), trying to address existing issues like misinformation or polarity. Since most of these tasks are rely on models appropriately reflecting people from different cultures faithfully, careful cultural alignment is crucial part in this process. Machine learning models are trained to generalize and learn from abstractions in data. This can lead to flattening of identity (Wang, Morgenstern, and Dickerson 2024) or poor performance on and misrepresentation of non-majority cultures. Such an effect can cast doubt on inferences made on top of results extracted from these systems. Thus, cross-cultural alignment with robust human evaluation is imperative for reliable inferences made in the social science. For achieving this alignment and embedding cultural information and knowledge, however, practitioners often use sources and literature from the social sciences (3). Simultaneously, generative models are proposed as means to replace human participants in surveys (Argyle et al. 2023b; Manvi et al. 2024). Such loop can lead to vicious circle, where cultures are misrepresented and cultural change is not incorporated. So, social scientists need to be aware of sources of data used for training these models, and the biases that may be embedded in them corresponding to the populations they are studying. Further, generative model designers need to be careful while culturally aligning these models to not over-rely on social science survey data, when not directly extracted from human participants from different cultures but is rather, synthetically generated."
        },
        {
            "title": "8.3 Human Computer Interaction and Cultural Alignment",
            "content": "Another important aspect of cultural alignment is how people interact with the culturally aligned LLMs and the corresponding interaction patterns. Understanding these interaction patterns includes studying how cultural alignment for models affects their use in applications such as creating generative art, generating culturally relevant stories (Toro Isaza et al. 2023), professional communication, cross-cultural communication, etc. Weidinger et al. (2023) propose three-layered approach to evaluating this effect in AI systems: the first layer is their capability, the second is how the system 53 affects human interaction with the system and the last layer being understanding the impact of the system on the broader context in which it is embedded, such as society, the economy, and the natural environment. Using this framework to understand the embedding of cultural information in generative models from an HCI perspective, we find that most research has focused on building and evaluating the capability (cultural understanding and awareness). On the other hand, ensuring cultural inclusion during human interaction with the system and studying broader systemic impact has received very little attention. For instance, generative models are tested for the understanding of culture-specific references in conversation and the ability of model to produce (culturally) relevant responses, testing their capability. However, the risk of people being deceived, misled, or enraged by that output because of them being misaligned with cultures depends on factors such as the context in which an AI system is used, who uses it, and the features of an application. Such evaluation is rarely performed before deployment of current generative systems, and is imperative for safe deployment in cultures distant from the ones that models are biased towards. Further, since the usage of these models can impact the users themselves, these factors have to be studied in the context of population-level effects. For instance, political values and opinions from biased models affecting the opinions of users (Jakesch et al. 2023b; Fisher et al. 2024) it can lead to shift in norms and values that culture identifies itself with Wagner et al. (2021). An HCI-based perspective on cultural inclusivity in generative models would include adapting the LLMs to the needs and expectations of culture and the intended applications (e.g., high risk vs. low risk). As the models become more general purpose, there needs to be distinction between the tasks and applications that would require culturally agnostic capabilities vs. those that would require culture-specific capabilities (Cetinic 2022). The HCI component should drive the data-collection for cultural alignment, as some cultures might be over-represented and while others might be misrepresented due to variance of technology access and expectations across different cultures. Participatory frameworks for co-designing these models and the data used for training them, involving stakeholders from the corresponding cultures, is one effective approach of addressing current gaps in culturally misaligned models (Birhane et al. 2022). One use case where such an approach is crucial is creation of generative art using these models. Since aesthetic standards, expression, and the emotions that different elements of art invoke are different in different cultures (Section 5.3), it is imperative to have faithful representation of cultural artifacts. 9. Pointers to Future Research Expand Research on Low-Resource Cultures and Languages. Research on lowand mid-resource cultures and languages has progressed but remains limited compared to high-resource counterparts, as discussed in section 4.2.8 and 7. Thus, more efforts are needed to collect data and evaluate the language models on low-resource cultures and languages. For example, creating benchmarks for dialectswhich capture unique aspects of local cultureis important, especially as many of these dialects are at risk of disappearing (Moseley 2010). In regions with low technology access, e.g., Sudan, involving native annotators becomes essential due to the limited available web data. However, these methods are not scalable, underscoring the need for more research into scalable data collection for low-resource languages and cultures. Additionally, it is necessary to develop alignment methodologies that can perform effectively with 54 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond relatively small datasets. Vary Data Collection Strategies Across Cultures. While collecting data for low-resource languages and cultures, considerable emphasis should be given to technology access of the cultures. Technology access determines how the data collection strategy should be varied. For example, although cultures like Estonian and Finnish are low-resource cultures, data collection strategies for that culture would involve scraping region-specific web data, recruiting annotators, and running crowdsourced experiments to understand cultural preferences due to high penetration of technology (mobiles, internet, etc.) in those cultures8. On the other hand, for cultures with low technology penetration (e.g., Sudan), the data collection would involve on-ground annotators talking to native people to collect data. The population of people following the culture would affect data collection, as some languages and cultural practices are spoken and followed by people in restricted domain (Liu et al. 2022d). While the data collection strategies would vary across cultures, care must be taken to standardize the data (for example by having humans in the loop) to ensure equity of model performance across cultures, as both methods would lead to differences in the quality of data. Approach Defining Cultural Boundaries with Caution. In language and vision research, culture is often represented through language or geographical regions, typically at the country level. However, countries do not always align with cultural boundaries (Bashkow 2004). For instance, Indonesiaone of the most ethnographically diverse nations globallycontains wide array of local cultures not captured by single national identity. Recent efforts aim to incorporate these local cultures into cultural benchmarks (Putri et al. 2024b; Koto et al. 2024b, 2023), though such attempts remain limited to certain regions. Using language as cultural proxy also presents challenges, as languages like English, Spanish, or Arabic can span multiple cultural contexts (Lee, Jung, and Oh 2023). Therefore, it is crucial to carefully define cultural boundaries when conducting cross-cultural research or developing culturespecific benchmarks. One effective approach to address this challenge is to engage in interdisciplinary collaboration with sociolinguistic researchers, who can provide deeper insights into the nuances of cultural and linguistic diversity. Ensure Inclusive Cultural Representations. Even within the same region or cultural group, social values and norms can vary significantly based on demographics such as age, gender, and race (Weber and Urick 2017). Therefore, when constructing cultural datasets or benchmarks, it is essential to involve annotators with diverse demographic backgrounds, even within single cultural group. Moreover, as cultural values and norms can vary between individuals, using annotators from specific demographic group might not be fully representative of the culture. For instance, when gathering responses to commonsense questions like What is common school cafeteria food in your country?, relying on small, homogeneous group of annotators can lead to incomplete or biased representations. diverse and sizable pool of annotators is essential to capture full range of perspectives. Additionally, evaluating the level of agreement among annotators can help determine if the gold answer truly reflects the 8 Internet penetration statistics: https: //worldpopulationreview.com/country-rankings/internet-penetration-by-country 55 culture context (Havaldar et al. 2024). Develop LLMs that can Adapt and Evolve with Cultural Change over Time. Another important factor to consider is the dynamic nature of culture. As Naylor (1996) noted, no culture is static; people continually adapt to changes in their physical and sociocultural environment. Especially in todays globalized world, interactions between different cultural groups can quickly lead to the emergence and transformation of new cultural identities (Holton 2000). While some studies have examined historical cultures (Wei et al. 2024; Tang et al. 2024b), there remains notable gap in research on how to adapt LLMs as cultures evolve. Addressing this challenge requires moving beyond static LLMs that only align with current cultural norms. Instead, LLMs should act as repositories for cultural preservation and adaptable systems that can respond to ongoing cultural transformations. Alternative Image Data Collection to Mitigate Biases in Web Images. Most vision benchmarks rely on images sourced from the web, as discussed in section 3. However, web images are susceptible to various biases like availability bias (different subjects, light conditions, locations, camera settings, and other features may be more likely to be uploaded on the web than others), apprehension bias (people may pose and look differently when they know that they are being photographed), and negative set bias (Goldman and Tsotsos 2024). For example, certain subjects and locations are more likely to be uploaded online, and people may pose differently when photographed. These biases could result in omitting everyday objects and cultural concepts on the web. To mitigate these biases, we could actively photograph culturally relevant concepts and objects with guidance from local residents and anthropology experts. Additionally, using frames from videos that document themes such as typical day in the life of person with specific identity or content from regional TV-shows can help capture more realistic and broader cultural images. Expand Cultural Evaluation Methods to Diverse Interaction Settings. As discussed in section 4.2, culturally aware LLMs are mostly evaluated using multiplechoice questions (MCQ). However, this approach has limitations, as it cannot fully capture the complexities of real-life human-AI interactions. MCQs primarily evaluate predefined set of cultural knowledge and focus on explicit cultural norms. However, in real-world scenarios, human-AI communication involves natural dialogue, where LLMs need to interpret implicit cultural cues and generate culturally sensitive responses. One promising research direction is evaluating the long-form generation of LLMs, which recent studies have started to explore, as shown in Figure 6. However, most evaluations depend on human judgment or LLM-as-a-judge (Zheng et al. 2023) methods, underscoring gap in culturally specific and robust automatic evaluation techniques. Therefore, further research is needed to develop reliable evaluation methods for assessing LLMs in natural, conversational settings, including long-form generation. Balance Development of Culturally-specific LLMs and Comprehensive Universal LLMs. Currently, various techniques are employed to culturally align LLMs, as discussed in sections 4.1 and 5. Most works have focused on training and developing culture-specific LLMs, particularly for non-Western local cultures. However, there has been comparatively less emphasis on creating cross-cultural models capable of reasoning across diverse cultural contexts. Given the diverse cultural backgrounds 56 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond of users, it is essential for LLMs to possess comprehensive cultural knowledge encompassing all highand low-resource cultures. Therefore, it is essential to seek balance between developing culture-specific LLMs tailored to local needs and creating comprehensive cross-cultural LLMs that can serve global audience. Develop Culturally Aware LLMs from User Perspectives. Section 8.3 discusses current applications of culturally aware LLMs, such as generating culturally relevant art, storytelling, and facilitating cross-cultural interactions. However, there remains gap in understanding how users interact with culturally-aware LLMs from the users perspective. This gap could be addressed through observational studies of user behavior in real-world scenarios. For instance, by observing when users are offended by an LLMs lack of cultural knowledge, we could gather insights for building safer, more culturally sensitive models. Additionally, studying interactions between multiple LLM agents and humans could reveal new applications, such as LLMs facilitating communication between individuals from diverse cultural backgrounds who speak different languages. Thus, observing real-world use cases from the users perspective is important for developing practical, culturally aware LLMs. 10. Conclusion This survey presented comprehensive review of papers studying cultural inclusion in text-based and multimodal models. We surveyed recent research efforts toward cultural awareness in LLMs and have consolidated the efforts under various themes. We have defined cultural awareness in LLMs by leveraging definitions of culture in psychology and anthropology. We then discussed methodologies adopted for creating cross-cultural datasets, strategies for cultural inclusion in downstream tasks, and methodologies that have been used for benchmarking cultural awareness in LLMs. We also discussed several important topics, such as the role of HCI in cultural inclusion, the role of cultural alignment in accelerating social science research, and ethical issues related to cultural inclusion. We hope this survey will serve as useful reference for future research on cultural alignment in AI systems. References Abbasi, Mohammad Amin, Arash Ghafouri, Mahdi Firouzmandi, Hassan Naderi, and Behrouz Minaei Bidgoli. 2023. PersianLLaMA: Towards Building First Persian Large Language Model. ArXiv preprint, abs/2312.15713. Achlioptas, Panos, Maks Ovsjanikov, Kilichbek Haydarov, Mohamed Elhoseiny, and Leonidas J. Guibas. 2021. ArtEmis: Affective Language for Visual Art. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021, pages 1156911579, Computer Vision Foundation / IEEE. Adilazuarda, Muhammad Farid, Sagnik Mukherjee, Pradhyumna Lavania, Siddhant Singh, Ashutosh Dwivedi, Alham Fikri Aji, Jacki ONeill, Ashutosh Modi, and Monojit Choudhury. 2024. Towards Measuring and Modeling \"Culture\" in LLMs: Survey. ArXiv preprint, abs/2403.15412. Agarwal, Utkarsh, Kumar Tanmay, Aditi Khandelwal, and Monojit Choudhury. 2024. Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language We Prompt Them in. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 63306340, ELRA and ICCL, Torino, Italia. Agnew, William, A. Stevie Bergman, Jennifer Chien, Mark Díaz, Seliem El-Sayed, Jaylen Pittman, Shakir Mohamed, and Kevin R. McKee. 2024. The Illusion of Artificial Inclusion. In 57 Proceedings of the CHI Conference on Human Factors in Computing Systems, CHI 2024, Honolulu, HI, USA, May 11-16, 2024, pages 286:1286:12, ACM. Ahmad, Ibrahim, Shiran Dudy, Resmi Ramachandranpillai, and Kenneth Church. 2024. Are Generative Language Models Multicultural? Study on Hausa Culture and Emotions using ChatGPT. In Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP, pages 98106, Association for Computational Linguistics, Bangkok, Thailand. Akinade, Idris, Jesujoba Alabi, David Adelani, Clement Odoje, and Dietrich Klakow. 2023. Varepsilon kú mask: Integrating Yorùbá cultural greetings into machine translation. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 17, Association for Computational Linguistics, Dubrovnik, Croatia. Alghamdi, Emad A., Reem I. Masoud, Deema Alnuhait, Afnan Y. Alomairi, Ahmed Ashraf, and Mohamed Zaytoon. 2024. AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic. ArXiv preprint, abs/2403.09017. AlKhamissi, Badr, Muhammad ElNokrashy, Mai Alkhamissi, and Mona Diab. 2024. Investigating Cultural Alignment of Large Language Models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1240412422, Association for Computational Linguistics, Bangkok, Thailand. Almeida, Thales Sales, Hugo Abonizio, Rodrigo Nogueira, and Ramon Pires. 2024. Sabia-2: New Generation of Portuguese Large Language Models. ArXiv preprint, abs/2403.09887. Aloui, Manel, Hasna Chouikhi, Ghaith Chaabane, Haithem Kchaou, and Chehir Dhaouadi. 2024. 101 Billion Arabic Words Dataset. ArXiv preprint, abs/2405.01590. Alyafeai, Zaid, Khalid Almubarak, Ahmed Ashraf, Deema Alnuhait, Saied Alshahrani, Gubran Abdulrahman, Gamil Ahmed, Qais Gawah, Zead Saleh, Mustafa Ghaleb, Yousef Ali, and Maged Al-shaibani. 2024. CIDAR: Culturally Relevant Instruction Dataset For Arabic. In Findings of the Association for Computational Linguistics ACL 2024, pages 1287812901, Association for Computational Linguistics, Bangkok, Thailand and virtual meeting. Amadeus, Marcellus, William Alberto Cruz Castañeda, André Felipe Zanella, and Felipe Rodrigues Perche Mahlow. 2024. From Pampas to Pixels: Fine-Tuning Diffusion Models for Gaúcho Heritage. ArXiv preprint, abs/2401.05520. Amiriparian, Shahin, Lukas Christ, Alexander Kathan, Maurice Gerczuk, Niklas Müller, Steffen Klug, Lukas Stappen, Andreas König, Erik Cambria, Björn Schuller, et al. 2024a. The MuSe 2024 Multimodal Sentiment Analysis Challenge: Social Perception and Humor Recognition. ArXiv preprint, abs/2406.07753. Amiriparian, Shahin, Filip Packa n, Maurice Gerczuk, and Björn Schuller. 2024b. ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37 Emotion Datasets. ArXiv preprint, abs/2406.10275. An, Siyu, Ye Liu, Haoyuan Peng, and Di Yin. 2023. VKIE: The Application of Key Information Extraction on Video Text. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track, pages 532540, Association for Computational Linguistics, Singapore. Ananthram, Amith, Elias Stengel-Eskin, Carl Vondrick, Mohit Bansal, and Kathleen McKeown. 2024. See It from My Perspective: Diagnosing the Western Cultural Bias of Large Vision-Language Models in Image Understanding. ArXiv preprint, abs/2406.11665. Antol, Stanislaw, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh. 2015. VQA: Visual Question Answering. In 2015 IEEE International Conference on Computer Vision, ICCV 2015, Santiago, Chile, December 7-13, 2015, pages 24252433, IEEE Computer Society. Arango Monnar, Ayme, Jorge Perez, Barbara Poblete, Magdalena Saldaña, and Valentina Proust. 2022. Resources for Multilingual Hate Speech Detection. In Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH), pages 122130, Association for Computational Linguistics, Seattle, Washington (Hybrid). Argyle, Lisa P., Christopher A. Bail, Ethan C. Busby, Joshua R. Gubler, Thomas Howe, Christopher Rytting, Taylor Sorensen, and David Wingate. 2023a. Leveraging AI for Democratic Discourse: Chat Interventions Can Improve Online Political Conversations at Scale. Proceedings of the National Academy of Sciences, 120(41):e2311627120. Argyle, Lisa P., Ethan C. Busby, Nancy Fulda, Joshua R. Gubler, Christopher Rytting, and David Wingate. 2023b. Out of One, Many: Using Language Models to Simulate Human Samples. Political Analysis, 31(3):337351. 58 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Arora, Arnav, Lucie-aimée Kaffee, and Isabelle Augenstein. 2023. Probing Pre-Trained Language Models for Cross-Cultural Differences in Values. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 114130, Association for Computational Linguistics, Dubrovnik, Croatia. Arora, Shane, Marzena Karpinska, Hung-Ting Chen, Ipsita Bhattacharjee, Mohit Iyyer, and Eunsol Choi. 2024. CaLMQA: Exploring culturally specific long-form question answering across 23 languages. ArXiv preprint, abs/2406.17761. Arvai, Joseph. 2013. Thinking, fast and slow, Daniel Kahneman, Farrar, Straus & Giroux. Baek, Yujin, chaeHun Park, Jaeseok Kim, Yu-Jung Heo, Du-Seong Chang, and Jaegul Choo. 2024. Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration. ArXiv preprint, abs/2406.16469. Bai, Yuelin, Xinrun Du, Yiming Liang, Yonggang Jin, Ziqiang Liu, Junting Zhou, Tianyu Zheng, Xincheng Zhang, Nuo Ma, Zekun Wang, et al. 2024. Coig-cqia: Quality is all you need for chinese instruction fine-tuning. ArXiv preprint, abs/2403.18058. Bail, Christopher A. 2024. Can Generative AI Improve Social Science? Proceedings of the National Academy of Sciences, 121(21):e2314021121. Bansal, Hritik, Da Yin, Masoud Monajatipoor, and Kai-Wei Chang. 2022. How well can text-to-image generative models understand ethical natural language interventions? In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 13581370, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Bao, Keqin, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, Chong Chen, Fuli Feng, and Qi Tian. 2023. bi-step grounding paradigm for large language models in recommendation systems. ArXiv preprint, abs/2308.08434. Bashkow, Ira. 2004. neo-boasian conception of cultural boundaries. American Anthropologist, 106(3):443458. Basu, Abhipsa, R. Venkatesh Babu, and Danish Pruthi. 2023. Inspecting the Geographical Representativeness of Images from Text-to-Image Models. In IEEE/CVF International Conference on Computer Vision, ICCV 2023, Paris, France, October 1-6, 2023, pages 51135124, IEEE. Beck, Tilman, Hendrik Schuff, Anne Lauscher, and Iryna Gurevych. 2024. Sensitivity, performance, robustness: Deconstructing the effect of sociodemographic prompting. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 25892615, Association for Computational Linguistics, St. Julians, Malta. Bekesas, Wilson Roberto, Mauro Berimbau, Renato Vercesi Mader, Joana Angelica Pellerano, Viviane Riegel, and Joana Pellerano. 2018. Cosmocult card game: methodological tool to understand the hybrid and peripheral cultural consumption of young people. Open Library of Humanities, 4(1). Belani, Ritu and Jeffrey Flanigan. 2022. Automatic identification of motivation for code-switching in speech transcripts. ArXiv preprint, abs/2212.08565. Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT 21, page 610623, Association for Computing Machinery, New York, NY, USA. Benkler, Noam, Scott Friedman, Sonja Schmer-Galunder, Drisana Mosaphir, Vasanth Sarathy, Pavan Kantharaju, Matthew McLure, and Robert Goldman. 2022. Cultural Value Resonance in Folktales: Transformer-Based Analysis with the World Value Corpus. In International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling and Simulation, pages 209218, Springer. Benkler, Noam K., Scott Friedman, Sonja Schmer-Galunder, Drisana Marissa Mosaphir, Robert P. Goldman, Ruta Wheelock, Vasanth Sarathy, Pavan Kantharaju, and Matthew D. McLure. 2024. Recognizing Value Resonance with Resonance-Tuned RoBERTa Task Definition, Experimental Validation, and Robust Modeling. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1368813698, ELRA and ICCL, Torino, Italia. Bennett III, Robert H, Paul Fadil, and Robin Greenwood. 1994. Cultural alignment in response to strategic organizational change: New considerations for change framework. Journal of Managerial Issues, pages 474490. 59 Berger, Arthur Asa. 2004. Deconstructing travel: Cultural perspectives on tourism. Rowman Altamira. Bhakthavatsalam, Sumithra, Chloe Anastasiades, and Peter Clark. 2020. Genericskb: knowledge base of generic statements. ArXiv preprint, abs/2005.00660. Bhatia, Mehar and Vered Shwartz. 2023. GD-COMET: Geo-Diverse Commonsense Inference Model. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 79938001, Association for Computational Linguistics, Singapore. Bhutani, Mukul, Kevin Robinson, Vinodkumar Prabhakaran, Shachi Dave, and Sunipa Dev. 2024. Seegull multilingual: dataset of geo-culturally situated stereotypes. ArXiv preprint, abs/2403.05696. Bie n, Michał, Michał Gilski, Martyna Maciejewska, Wojciech Taisner, Dawid Wisniewski, and Agnieszka Lawrynowicz. 2020. RecipeNLG: cooking recipes dataset for semi-structured text generation. In Proceedings of the 13th International Conference on Natural Language Generation, pages 2228, Association for Computational Linguistics, Dublin, Ireland. Billah Nagoudi, El Moatez, Muhammad Abdul-Mageed, AbdelRahim Elmadany, Alcides Inciarte, and Md Tawkat Islam Khondaker. 2023. JASMINE: Arabic GPT Models for Few-Shot Learning. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1672116744, Association for Computational Linguistics, Singapore. Birhane, Abeba, William Isaac, Vinodkumar Prabhakaran, Mark Diaz, Madeleine Clare Elish, Iason Gabriel, and Shakir Mohamed. 2022. Power to the people? opportunities and challenges for participatory ai. In Proceedings of the 2nd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, EAAMO 22, Association for Computing Machinery, New York, NY, USA. Bloom, BS. 1956. handbook i: cognitive domain. David McKay Company. Bongini, Pietro, Federico Becattini, Andrew Bagdanov, and Alberto Del Bimbo. 2020. Visual question answering for cultural heritage. In IOP Conference Series: Materials Science and Engineering, volume 949, page 012074, IOP Publishing. Borah, Angana, Aparna Garimella, and Rada Mihalcea. 2024. Towards region-aware bias evaluation metrics. ArXiv preprint, abs/2406.16152. Borenstein, Nadav, Arnav Arora, Lucie-Aimée Kaffee, and Isabelle Augenstein. 2024. Investigating Human Values in Online Communities. Bruno, Barbara, Carmine Tommaso Recchiuto, Irena Papadopoulos, Alessandro Saffiotti, Christina Koulouglioti, Roberto Menicatti, Fulvio Mastrogiovanni, Renato Zaccaria, and Antonio Sgorbissa. 2019. Knowledge representation for culturally competent personal robots: requirements, design principles, implementation, and assessment. International Journal of Social Robotics, 11:515538. Buettner, Kyle, Sina Malakouti, Xiang Lorraine Li, and Adriana Kovashka. 2024. Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1351513524. Burda-Lassen, Olena, Aman Chadha, Shashank Goswami, and Vinija Jain. 2024. How culturally aware are vision-language models? ArXiv preprint, abs/2405.17475. Burton, Jason W., Ezequiel Lopez-Lopez, Shahar Hechtlinger, Zoe Rahwan, Samuel Aeschbach, Michiel A. Bakker, Joshua A. Becker, Aleks Berditchevskaia, Julian Berger, Levin Brinkmann, Lucie Flek, Stefan M. Herzog, Saffron Huang, Sayash Kapoor, Arvind Narayanan, Anne-Marie Nussberger, Taha Yasseri, Pietro Nickl, Abdullah Almaatouq, Ulrike Hahn, Ralf H. J. M. Kurvers, Susan Leavy, Iyad Rahwan, Divya Siddarth, Alice Siu, Anita W. Woolley, Dirk U. Wulff, and Ralph Hertwig. 2024. How large language models can reshape collective intelligence. Nature Human Behaviour, 8(9):16431655. Cahyawijaya, Samuel, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, Ziwei Ji, Etsuko Ishii, and Pascale Fung. 2024a. High-dimension human value representation in large language models. ArXiv preprint, abs/2404.07900. Cahyawijaya, Samuel, Holy Lovenia, Fajri Koto, Rifki Afina Putri, Emmanuel Dave, Jhonson Lee, Nuur Shadieq, Wawan Cenggoro, Salsabil Maulana Akbar, Muhammad Ihza Mahendra, et al. 2024b. Cendol: Open instruction-tuned generative large language models for indonesian languages. ArXiv preprint, abs/2404.06138. Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334):183186. 60 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Cao, Jiahuan, Yongxin Shi, Dezhi Peng, Yang Liu, and Lianwen Jin. 2024a. C3bench: comprehensive classical chinese understanding benchmark for large language models. ArXiv preprint, abs/2405.17732. Cao, Yang Trista, Anna Sotnikova, Hal Daumé III, Rachel Rudinger, and Linda Zou. 2022. Theory-grounded measurement of U.S. social stereotypes in English language models. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 12761295, Association for Computational Linguistics, Seattle, United States. Cao, Yong, Min Chen, and Daniel Hershcovich. 2024. Bridging cultural nuances in dialogue agents through cultural value surveys. In Findings of the Association for Computational Linguistics: EACL 2024, pages 929945, Association for Computational Linguistics, St. Julians, Malta. Cao, Yong, Yova Kementchedjhieva, Ruixiang Cui, Antonia Karamolegkou, Li Zhou, Megan Dare, Lucia Donatelli, and Daniel Hershcovich. 2024b. Cultural adaptation of recipes. Transactions of the Association for Computational Linguistics, 12:8099. Cao, Yong, Yova Kementchedjhieva, Ruixiang Cui, Antonia Karamolegkou, Li Zhou, Megan Dare, Lucia Donatelli, and Daniel Hershcovich. 2024c. Cultural adaptation of recipes. Transactions of the Association for Computational Linguistics, 12:8099. Cao, Yong, Wenyan Li, Jiaang Li, Yifei Yuan, and Daniel Hershcovich. 2024d. Exploring visual culture awareness in gpt-4v: comprehensive probing. ArXiv preprint, abs/2402.06015. Cao, Yong, Li Zhou, Seolhwa Lee, Laura Cabello, Min Chen, and Daniel Hershcovich. 2023. Assessing cross-cultural alignment between ChatGPT and human societies: An empirical study. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 5367, Association for Computational Linguistics, Dubrovnik, Croatia. Casola, Silvia, Simona Frenda, Soda Lo, Erhan Sezerer, Antonio Uva, Valerio Basile, Cristina Bosco, Alessandro Pedrani, Chiara Rubagotti, Viviana Patti, and Davide Bernardi. 2024. MultiPICo: Multilingual perspectivist irony corpus. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1600816021, Association for Computational Linguistics, Bangkok, Thailand. Center, Pew Research. 2022. Pew global attitudes survey. Accessed: 2022. Cetinic, Eva. 2022. The myth of culturally agnostic ai models. ArXiv preprint, abs/2211.15271. CH-Wang, Sky, Arkadiy Saakyan, Oliver Li, Zhou Yu, and Smaranda Muresan. 2023. Sociocultural norm similarities and differences via situational alignment and explainable textual entailment. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 35483564, Association for Computational Linguistics, Singapore. Chan, Alex J, José Luis Redondo García, Fabrizio Silvestri, Colm ODonnel, and Konstantina Palla. 2023. Harmonizing global voices: Culturally-aware models for enhanced content moderation. ArXiv preprint, abs/2312.02401. Chang, Chen-Chi, Ching-Yuan Chen, Hung-Shin Lee, and Chih-Cheng Lee. 2024. Benchmarking Cognitive Domains for LLMs: Insights from Taiwanese Hakka Culture. ArXiv preprint, abs/2409.01556. Chen, Andong, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, and Min Zhang. 2024a. Benchmarking llms for translating classical chinese poetry: Evaluating adequacy, fluency, and elegance. ArXiv preprint, abs/2408.09945. Chen, Lichang, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, and Hongxia Jin. 2024b. AlpaGasus: Training Better Alpaca with Fewer Data. In The Twelfth International Conference on Learning Representations. Cheng, Myra, Esin Durmus, and Dan Jurafsky. 2023. Marked personas: Using natural language prompts to measure stereotypes in language models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 15041532, Association for Computational Linguistics, Toronto, Canada. Chiu, Yu Ying, Liwei Jiang, Maria Antoniak, Chan Young Park, Shuyue Stella Li, Mehar Bhatia, Sahithya Ravi, Yulia Tsvetkov, Vered Shwartz, and Yejin Choi. 2024. Culturalteaming: Ai-assisted interactive red-teaming for challenging llms(lack of) multicultural knowledge. ArXiv preprint, abs/2404.06664. Cho, Jaemin, Abhay Zala, and Mohit Bansal. 2023. DALL-EVAL: probing the reasoning skills and social biases of text-to-image generation models. In IEEE/CVF International Conference on Computer Vision, ICCV 2023, Paris, France, October 1-6, 2023, pages 30203031, IEEE. 61 Choenni, Rochelle, Anne Lauscher, and Ekaterina Shutova. 2024. The Echoes of Multilinguality: Tracing Cultural Value Shifts during Language Model Fine-tuning. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1504215058, Association for Computational Linguistics, Bangkok, Thailand. Clarke, Christopher, Roland Daynauth, Jason Mars, Charlene Wilkinson, and Hubert Devonish. 2024. GuyLingo: The Republic of Guyana creole corpora. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers), pages 792798, Association for Computational Linguistics, Mexico City, Mexico. Conneau, Alexis, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 84408451, Association for Computational Linguistics, Online. Dammu, Preetam Prabhu Srikar, Hayoung Jung, Anjali Singh, Monojit Choudhury, and Tanushree Mitra. 2024. \"they are uncultured\": Unveiling covert harms and social threats in llm generated conversations. ArXiv preprint, abs/2405.05378. Das, Dipto, Shion Guha, and Bryan Semaan. 2023. Toward cultural bias evaluation datasets: The case of Bengali gender, religious, and national identity. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 6883, Association for Computational Linguistics, Dubrovnik, Croatia. Davis, Ernest and Gary Marcus. 2015. Commonsense reasoning and commonsense knowledge in artificial intelligence. Communications of the ACM, 58(9):92103. De Angelis, Luigi, Francesco Baglivo, Guglielmo Arzilli, Gaetano Pierpaolo Privitera, Paolo Ferragina, Alberto Eugenio Tozzi, and Caterina Rizzo. 2023. Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health. Frontiers in public health, 11:1166120. Deas, Nicholas, Elsbeth Turcan, Iván Pérez Mejía, and Kathleen McKeown. 2024. Masive: Open-ended affective state identification in english and spanish. ArXiv preprint, abs/2407.12196. Dehghan, Somaiyeh and Berrin Yanıko glu. 2024. Multi-domain Hate Speech Detection Using Dual Contrastive Learning and Paralinguistic Features. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1174511755, ELRA and ICCL, Torino, Italia. Deng, Juntao, Xu Cao, and Bingqi Cheng. 2024. Research on Generating Cultural Relic Images Based on Low-Rank Adaptive Diffusion Model. In Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence, pages 629634. Deshpande, Ameet, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and Karthik Narasimhan. 2023. Toxicity in chatgpt: Analyzing persona-assigned language models. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 12361270, Association for Computational Linguistics, Singapore. Deshpande, Awantee, Dana Ruiter, Marius Mosbach, and Dietrich Klakow. 2022. StereoKG: Data-driven knowledge graph construction for cultural knowledge and stereotypes. In Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH), pages 6778, Association for Computational Linguistics, Seattle, Washington (Hybrid). Dev, Sunipa, Jaya Goyal, Dinesh Tewari, Shachi Dave, and Vinodkumar Prabhakaran. 2023. Building socio-culturally inclusive stereotype resources with community engagement. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Ding, Bosheng, Junjie Hu, Lidong Bing, Mahani Aljunied, Shafiq Joty, Luo Si, and Chunyan Miao. 2022. GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 16391657, Association for Computational Linguistics, Dublin, Ireland. Du, Xinrun, Zhouliang Yu, Songyang Gao, Ding Pan, Yuyang Cheng, Ziyang Ma, Ruibin Yuan, Xingwei Qu, Jiaheng Liu, Tianyu Zheng, et al. 2024. Chinese tiny llm: Pretraining chinese-centric large language model. ArXiv preprint, abs/2404.04167. Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Dubois, Yann, Chen Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Alpacafarm: simulation framework for methods that learn from human feedback. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Duret, Jarod, Benjamin OBrien, Yannick Estève, and Titouan Parcollet. 2023. Enhancing expressivity transfer in textless speech-to-speech translation. In 2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), pages 18, IEEE. Durmus, Esin, Karina Nguyen, Thomas Liao, Nicholas Schiefer, Amanda Askell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez, Nicholas Joseph, et al. 2023. Towards measuring the representation of subjective global opinions in language models. ArXiv preprint, abs/2306.16388. Dwivedi, Ashutosh, Pradhyumna Lavania, and Ashutosh Modi. 2023. EtiCor: Corpus for analyzing LLMs for etiquettes. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 69216931, Association for Computational Linguistics, Singapore. Elmadany, AbdelRahim, Ife Adebara, and Muhammad Abdul-Mageed. 2024. Toucan: Many-to-many translation for 150 african language pairs. ArXiv preprint, abs/2407.04796. Ember, Carol R. 2009. Cross-cultural research methods. Rowman Altamira. Ersoy, Asım, Gerson Vizcarra, Tahsin Mayeesha, and Benjamin Muller. 2023. In what languages are generative language models the most formal? analyzing formality distribution across languages. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 26502666, Association for Computational Linguistics, Singapore. España-Bonet, Cristina and Alberto Barrón-Cedeño. 2022. The (undesired) attenuation of human biases by multilinguality. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 20562077, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Etxaniz, Julen, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, and Mikel Artetxe. 2024. Bertaqa: How much do language models know about local culture? ArXiv preprint, abs/2406.07302. Faisal, Fahim, Orevaoghene Ahia, Aarohi Srivastava, Kabir Ahuja, David Chiang, Yulia Tsvetkov, and Antonios Anastasopoulos. 2024. DIALECTBENCH: NLP Benchmark for Dialects, Varieties, and Closely-Related Languages. ArXiv preprint, abs/2403.11009. Fan, Tao, Hao Wang, and Tobias Hodel. 2023. Cichmkg: large-scale and comprehensive chinese intangible cultural heritage multimodal knowledge graph. Heritage Science, 11:118. Fei, Nanyi, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. 2022. Towards artificial general intelligence via multimodal foundation model. Nature Communications, 13(1):3094. Feng, Shangbin, Taylor Sorensen, Yuhan Liu, Jillian Fisher, Chan Young Park, Yejin Choi, and Yulia Tsvetkov. 2024. Modular pluralism: Pluralistic alignment via multi-llm collaboration. ArXiv preprint, abs/2406.15951. Fisher, Jillian, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Daniel W. Fisher, Jennifer Pan, Yulia Tsvetkov, and Katharina Reinecke. 2024. Biased ai can influence political decision-making. ArXiv preprint, abs/2410.06415. Fort, Karen, Laura Alonso Alemany, Luciana Benotti, Julien Bezançon, Claudia Borg, Marthese Borg, Yongjian Chen, Fanny Ducel, Yoann Dupont, Guido Ivetta, Zhijian Li, Margot Mieskes, Marco Naguib, Yuyan Qian, Matteo Radaelli, Wolfgang S. Schmeisser-Nieto, Emma Raimundo Schulz, Thiziri Saci, Sarah Saidi, Javier Torroba Marchante, Shilin Xie, Sergio E. Zanotto, and Aurélie Névéol. 2024. Your stereotypical mileage may vary: Practical challenges of evaluating biases in multiple languages and cultural contexts. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1776417769, ELRA and ICCL, Torino, Italia. Fung, Yi, Tuhin Chakrabarty, Hao Guo, Owen Rambow, Smaranda Muresan, and Heng Ji. 2023. NORMSAGE: Multi-lingual multi-cultural norm discovery from conversations on-the-fly. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1521715230, Association for Computational Linguistics, Singapore. Fung, Yi, Ruining Zhao, Jae Doo, Chenkai Sun, and Heng Ji. 2024. Massively multi-cultural knowledge acquisition & lm benchmarking. ArXiv preprint, abs/2402.09369. 63 Funk, Marius, Shogo Okada, and Elisabeth André. 2024. Multilingual dyadic interaction corpus noxi+ j: Toward understanding asian-european non-verbal cultural characteristics and their influences on engagement. ArXiv preprint, abs/2409.13726. Furst, Edward J. 1981. Blooms taxonomy of educational objectives for the cognitive domain: Philosophical and educational issues. Review of educational research, 51(4):441453. Gabriel, Iason. 2020. Artificial Intelligence, Values, and Alignment. Minds and Machines, 30(3):411437. Ganguli, Deep, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, et al. 2022. Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned. ArXiv preprint, abs/2209.07858. Gehman, Samuel, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. 2020. RealToxicityPrompts: Evaluating neural toxic degeneration in language models. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 33563369, Association for Computational Linguistics, Online. Ghahroodi, Omid, Marzia Nouri, Mohammad Vali Sanian, Alireza Sahebi, Doratossadat Dastgheib, Ehsaneddin Asgari, Mahdieh Soleymani Baghshah, and Mohammad Hossein Rohban. 2024. Khayyam challenge (persianmmlu): Is your llm truly wise to the persian language? ArXiv preprint, abs/2404.06644. Ghosh, Dhruba, Hannaneh Hajishirzi, and Ludwig Schmidt. 2023. Geneval: An object-focused framework for evaluating text-to-image alignment. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Goldman, Josh and John Tsotsos. 2024. Statistical challenges with dataset construction: Why you will never have enough images. ArXiv preprint, abs/2408.11160. Greenwald, Anthony G, Debbie McGhee, and Jordan LK Schwartz. 1998. Measuring individual differences in implicit cognition: the implicit association test. Journal of personality and social psychology, 74(6):1464. Grigoreva, Veronika, Anastasiia Ivanova, Ilseyar Alimova, and Ekaterina Artemova. 2024. RuBia: Russian language bias detection dataset. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1422714239, ELRA and ICCL, Torino, Italia. Grossmann, Igor, Matthew Feinberg, Dawn C. Parker, Nicholas A. Christakis, Philip E. Tetlock, and William A. Cunningham. 2023. AI and the Transformation of Social Science Research. Science, 380(6650):11081109. Gupta, Prannaya, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, and Soujanya Poria. 2024. Walledeval: comprehensive safety evaluation toolkit for large language models. ArXiv preprint, abs/2408.03837. Haerpfer, Christian and Kseniya Kizilova. 2012. The world values survey. The Wiley-Blackwell Encyclopedia of Globalization, pages 15. Halpern, Ben. 1955. The dynamic elements of culture. Ethics, 65:235 249. Hamilton, Mark, Stephanie Fu, Mindren Lu, Johnny Bui, Darius Bopp, Zhenbang Chen, Felix Tran, Margaret Wang, Marina Rogers, Lei Zhang, et al. 2021. Mosaic: Finding artistic connections across culture with conditional image retrieval. In NeurIPS 2020 Competition and Demonstration Track, pages 133155, PMLR. Hämmerl, Katharina, Bjoern Deiseroth, Patrick Schramowski, Jindˇrich Libovický, Constantin Rothkopf, Alexander Fraser, and Kristian Kersting. 2023. Speaking Multiple Languages Affects the Moral Bias of Language Models. In Findings of the Association for Computational Linguistics: ACL 2023, pages 21372156, Association for Computational Linguistics, Toronto, Canada. Han, HyoJung, Jordan Boyd-Graber, and Marine Carpuat. 2023. Bridging background knowledge gaps in translation with automatic explicitation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 97189735, Association for Computational Linguistics, Singapore. Hartvigsen, Thomas, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. 2022. ToxiGen: large-scale machine-generated dataset for adversarial and implicit hate speech detection. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 33093326, Association for 64 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Computational Linguistics, Dublin, Ireland. Hasan, Md Arid, Maram Hasanain, Fatema Ahmad, Sahinur Rahman Laskar, Sunaya Upadhyay, Vrunda Sukhadia, Mucahid Kutlu, Shammur Absar Chowdhury, and Firoj Alam. 2024. Nativqa: Multilingual culturally-aligned natural query for llms. ArXiv preprint, abs/2407.09823. Havaldar, Shreya, Salvatore Giorgi, Sunny Rai, Thomas Talhelm, Sharath Chandra Guntuku, and Lyle Ungar. 2024. Building knowledge-guided lexica to model cultural variation. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 211226, Association for Computational Linguistics, Mexico City, Mexico. Havaldar, Shreya, Bhumika Singhal, Sunny Rai, Langchen Liu, Sharath Chandra Guntuku, and Lyle Ungar. 2023. Multilingual language models are not multicultural: case study in emotion. In Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis, pages 202214, Association for Computational Linguistics, Toronto, Canada. Hayati, Shirley Anugrah, Minhwa Lee, Dheeraj Rajagopal, and Dongyeop Kang. 2023. How far can we extract diverse perspectives from large language models? criteria-based diversity prompting! ArXiv preprint, abs/2311.09799. He, Ruiqi, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen Xia, and Naihao Deng. 2024. Chumor 1.0: truly funny and challenging chinese humor understanding dataset from ruo zhi ba. ArXiv preprint, abs/2406.12754. Hee, Ming Shan, Shivam Sharma, Rui Cao, Palash Nandi, Preslav Nakov, Tanmoy Chakraborty, and Roy Ka-Wei Lee. 2024. Recent advances in hate speech moderation: Multimodality and the role of large models. ArXiv preprint, abs/2401.16727. Hegde, Siddhanth U, Adeep Hande, Ruba Priyadharshini, Sajeetha Thavareesan, Ratnasingam Sakuntharaj, Sathiyaraj Thangasamy, Bharathi, and Bharathi Raja Chakravarthi. 2021. Do Images really do the Talking? Analysing the significance of Images in Tamil Troll meme classification. ArXiv preprint, abs/2108.03886. Hendrycks, Dan, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. Measuring massive multitask language understanding. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021, OpenReview.net. Henrich, Joseph, Steven Heine, and Ara Norenzayan. 2010. The weirdest people in the world? Behavioral and brain sciences, 33(2-3):6183. Hershcovich, Daniel, Stella Frank, Heather Lent, Miryam de Lhoneux, Mostafa Abdou, Stephanie Brandl, Emanuele Bugliarello, Laura Cabello Piqueras, Ilias Chalkidis, Ruixiang Cui, Constanza Fierro, Katerina Margatina, Phillip Rust, and Anders Søgaard. 2022a. Challenges and strategies in cross-cultural NLP. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 69977013, Association for Computational Linguistics, Dublin, Ireland. Hershcovich, Daniel, Stella Frank, Heather Lent, Miryam de Lhoneux, Mostafa Abdou, Stephanie Brandl, Emanuele Bugliarello, Laura Cabello Piqueras, Ilias Chalkidis, Ruixiang Cui, Constanza Fierro, Katerina Margatina, Phillip Rust, and Anders Søgaard. 2022b. Challenges and strategies in cross-cultural NLP. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 69977013, Association for Computational Linguistics, Dublin, Ireland. Heylighen, Francis and Jean-Marc Dewaele. 1999. Formality of language: definition, measurement and behavioral determinants. Interner Bericht, Center Leo Apostel, Vrije Universiteit Brüssel, 4(1). Ho, Jonathan, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik Kingma, Ben Poole, Mohammad Norouzi, David Fleet, et al. 2022. Imagen video: High definition video generation with diffusion models. ArXiv preprint, abs/2210.02303. Hofstede, Geert. 2005. Cultures recent consequences. In Designing for Global Markets 7, IWIPS 2005, Bridging Cultural Differences, 7-9 July 2005, Amsterdam, The Netherlands, Proceedings of the Seventh International Workshop on Internationalisation of Products and Systems, pages 34, Product & Systems Internationalisation, Inc. Hofstede, Geert, Gert Jan Hofstede, and Michael Minkov. 2010. Cultures and organizations: Software of the mind, third edition, 3 edition. McGraw-Hill Professional, New York, NY. 65 Holton, Robert. 2000. Globalizations cultural consequences. The ANNALS of the American academy of political and social science, 570(1):140152. Horton, John J. 2023. Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus? Working Paper 31122, National Bureau of Economic Research. Hovy, Dirk and Diyi Yang. 2021. The importance of modeling social factors of language: Theory and practice. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 588602, Association for Computational Linguistics, Online. Hsiao, Wei-Lin and Kristen Grauman. 2021. From Culture to Clothing: Discovering the World Events Behind Century of Fashion Images. In 2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021, pages 10461055, IEEE. Hu, Songbo, Han Zhou, Mete Hergul, Milan Gritta, Guchun Zhang, Ignacio Iacobacci, Ivan Vulic, and Anna Korhonen. 2023a. Multi 3 WOZ: multilingual, multi-domain, multi-parallel dataset for training and evaluating culturally adapted task-oriented dialog systems. Transactions of the Association for Computational Linguistics, 11:13961415. Hu, Yushi, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, and Noah A. Smith. 2023b. TIFA: accurate and interpretable text-to-image faithfulness evaluation with question answering. In IEEE/CVF International Conference on Computer Vision, ICCV 2023, Paris, France, October 1-6, 2023, pages 2034920360, IEEE. Huang, Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Song Dingjie, Zhihong Chen, Mosen Alharthi, Bang An, Juncai He, Ziche Liu, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, and Jinchao Xu. 2024. AceGPT, localizing large language models in Arabic. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 81398163, Association for Computational Linguistics, Mexico City, Mexico. Huang, Kaiyi, Kaiyue Sun, Enze Xie, Zhenguo Li, and Xihui Liu. 2023. T2i-compbench: comprehensive benchmark for open-world compositional text-to-image generation. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Huang, Yufei and Deyi Xiong. 2024. CBBQ: Chinese bias benchmark dataset curated with human-AI collaboration for large language models. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 29172929, ELRA and ICCL, Torino, Italia. Hung, Chia-Chien, Anne Lauscher, Ivan Vulic, Simone Ponzetto, and Goran Glavaš. 2022. Multi2WOZ: Robust Multilingual Dataset and Conversational Pretraining for Task-Oriented Dialog. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 36873703, Association for Computational Linguistics, Seattle, United States. Hwang, EunJeong, Bodhisattwa Majumder, and Niket Tandon. 2023. Aligning language models to user opinions. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 59065919, Association for Computational Linguistics, Singapore. Ignat, Oana, Gayathri Ganesh Lakshmy, and Rada Mihalcea. 2024. Cross-cultural inspiration detection and analysis in real and llm-generated social media data. ArXiv preprint, abs/2404.12933. Imai, Mutsumi, Junko Kanero, and Takahiko Masuda. 2016. The relation between language, culture, and thought. Current Opinion in Psychology, 8:7077. Culture. ImaniGooghari, Ayyoob, Peiqin Lin, Amir Hossein Kargaran, Silvia Severini, Masoud Jalili Sabet, Nora Kassner, Chunlan Ma, Helmut Schmid, André Martins, François Yvon, and Hinrich Schütze. 2023. Glot500: Scaling multilingual corpora and language models to 500 languages. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10821117, Association for Computational Linguistics, Toronto, Canada. Jahoda, Gustav and Harry McGurk. 1974. Pictorial depth perception: developmental study. British journal of psychology, 65 1:1419. Jakesch, Maurice, Advait Bhat, Daniel Buschek, Lior Zalmanson, and Mor Naaman. 2023a. Co-writing with opinionated language models affects users views. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, CHI 2023, Hamburg, Germany, April 23-28, 2023, pages 111:1111:15, ACM. 66 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Jakesch, Maurice, Advait Bhat, Daniel Buschek, Lior Zalmanson, and Mor Naaman. 2023b. Co-Writing with Opinionated Language Models Affects Users Views. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, CHI 2023, Hamburg, Germany, April 23-28, 2023, pages 111:1111:15, ACM. Jang, Dongyeop, Tae-Rim Yun, Choong-Yeol Lee, Young-Kyu Kwon, and Chang-Eop Kim. 2023. Gpt-4 can pass the korean national licensing examination for korean medicine doctors. PLOS Digital Health, 2(12):e0000416. Javed, Tahir, Janki Atul Nawale, Eldho Ittan George, Sakshi Joshi, Kaushal Santosh Bhogale, Deovrat Mehendale, Ishvinder Virender Sethi, Aparna Ananthanarayanan, Hafsah Faquih, Pratiti Palit, et al. 2024. Indicvoices: Towards building an inclusive multilingual speech dataset for indian languages. ArXiv preprint, abs/2403.01926. Jeong, Younghoon, Juhyun Oh, Jongwon Lee, Jaimeen Ahn, Jihyung Moon, Sungjoon Park, and Alice Oh. 2022. KOLD: Korean offensive language dataset. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 1081810833, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Jha, Akshita, Aida Mostafazadeh Davani, Chandan Reddy, Shachi Dave, Vinodkumar Prabhakaran, and Sunipa Dev. 2023. SeeGULL: stereotype benchmark with broad geo-cultural coverage leveraging generative models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 98519870, Association for Computational Linguistics, Toronto, Canada. Jha, Akshita, Vinodkumar Prabhakaran, Remi Denton, Sarah Laszlo, Shachi Dave, Rida Qadri, Chandan Reddy, and Sunipa Dev. 2024. ViSAGe: Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1233312347. Jia, Jiehui, Huan Zhang, and Jinhua Liang. 2024. Bridging discrete and continuous: multimodal strategy for complex emotion detection. ArXiv preprint, abs/2409.07901. Jiang, Ming and Mansi Joshi. 2024. CPopQA: Ranking cultural concept popularity by LLMs. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers), pages 615630, Association for Computational Linguistics, Mexico City, Mexico. Jin, Jiho, Jiseon Kim, Nayeon Lee, Haneul Yoo, Alice Oh, and Hwaran Lee. 2024. KoBBQ: Korean bias benchmark for question answering. Transactions of the Association for Computational Linguistics, 12:507524. Jinnai, Yuu. 2024. Does cross-cultural alignment change the commonsense morality of language models? In Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP, pages 4864, Association for Computational Linguistics, Bangkok, Thailand. Johnson, Rebecca L, Giada Pistilli, Natalia Menédez-González, Leslye Denisse Dias Duran, Enrico Panai, Julija Kalpokiene, and Donald Jay Bertulfo. 2022. The ghost in the machine has an american accent: value conflict in gpt-3. ArXiv preprint, abs/2203.07785. Jones, Ruth and Ann Irvine. 2013. The (un)faithful machine translator. In Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 96101, Association for Computational Linguistics, Sofia, Bulgaria. Joshi, Pratik, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 62826293, Association for Computational Linguistics, Online. Jou, Brendan, Tao Chen, Nikolaos Pappas, Miriam Redi, Mercan Topkara, and Shih-Fu Chang. 2015. Visual affect around the world: large-scale multilingual visual sentiment ontology. In Proceedings of the 23rd ACM international conference on Multimedia, pages 159168. Kabra, Anubha, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, and Graham Neubig. 2023. Multi-lingual and multi-cultural figurative language understanding. In Findings of the Association for Computational Linguistics: ACL 2023, pages 82698284, Association for Computational Linguistics, Toronto, Canada. Kadaoui, Karima, Samar Magdy, Abdul Waheed, Md Tawkat Islam Khondaker, Ahmed El-Shangiti, El Moatez Billah Nagoudi, and Muhammad Abdul-Mageed. 2023. TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties. In Proceedings of ArabicNLP 2023, pages 5275, Association for Computational Linguistics, Singapore (Hybrid). 67 Kaffee, Lucie-Aimée, Arnav Arora, Zeerak Talat, and Isabelle Augenstein. 2023. Thorny roses: Investigating the dual use dilemma in natural language processing. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1397713998, Association for Computational Linguistics, Singapore. Kannen, Nithish, Arif Ahmad, Marco Andreetto, Vinodkumar Prabhakaran, Utsav Prabhu, Adji Bousso Dieng, Pushpak Bhattacharyya, and Shachi Dave. 2024. Beyond aesthetics: Cultural competence in text-to-image models. ArXiv preprint, abs/2407.06863. Kantharuban, Anjali, Ivan Vulic, and Anna Korhonen. 2023. Quantifying the Dialect Gap and its Correlates Across Languages. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 72267245, Association for Computational Linguistics, Singapore. Kasneci, Enkelejda, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnemann, Eyke Hüllermeier, and et al. 2023. Chatgpt for good? on opportunities and challenges of large language models for education. Kay, Jackie, Atoosa Kasirzadeh, and Shakir Mohamed. 2024. Epistemic Injustice in Generative AI. Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 7:684697. Keleg, Amr and Walid Magdy. 2023. DLAMA: framework for curating culturally diverse facts for probing the knowledge of pretrained language models. In Findings of the Association for Computational Linguistics: ACL 2023, pages 62456266, Association for Computational Linguistics, Toronto, Canada. Khan, Shahid Nawaz, Maitree Leekha, Jainendra Shukla, and Rajiv Ratn Shah. 2020. Vyaktitv: multimodal peer-to-peer hindi conversations based dataset for personality assessment. In 2020 IEEE sixth international conference on multimedia big data (BigMM), pages 103111, IEEE. Khandelwal, Khyati, Manuel Tonneau, Andrew Bean, Hannah Rose Kirk, and Scott Hale. 2024a. Indian-bhed: dataset for measuring india-centric biases in large language models. In Proceedings of the 2024 International Conference on Information Technology for Social Good, pages 231239. Khandelwal, Khyati, Manuel Tonneau, Andrew M. Bean, Hannah Rose Kirk, and Scott A. Hale. 2024b. Indian-bhed: dataset for measuring india-centric biases in large language models. In Proceedings of the 2024 International Conference on Information Technology for Social Good, GoodIT 24, page 231239, Association for Computing Machinery, New York, NY, USA. Khanuja, Simran, Sathyanarayanan Ramamoorthy, Yueqi Song, and Graham Neubig. 2024. An image speaks thousand words, but can everyone listen? on translating images for cultural relevance. ArXiv preprint, abs/2404.01247. Kim, Boseop, HyoungSeok Kim, Sang-Woo Lee, Gichang Lee, Donghyun Kwak, Jeon Dong Hyeon, Sunghyun Park, Sungju Kim, Seonhoon Kim, Dongpil Seo, Heungsub Lee, Minyoung Jeong, Sungjae Lee, Minsub Kim, Suk Hyun Ko, Seokhun Kim, Taeyong Park, Jinuk Kim, Soyoung Kang, Na-Hyeon Ryu, Kang Min Yoo, Minsuk Chang, Soobin Suh, Sookyo In, Jinseong Park, Kyungduk Kim, Hiun Kim, Jisu Jeong, Yong Goo Yeo, Donghoon Ham, Dongju Park, Min Young Lee, Jaewook Kang, Inho Kang, Jung-Woo Ha, Woomyoung Park, and Nako Sung. 2021. What changes can large-scale language models bring? intensive study on HyperCLOVA: Billions-scale Korean generative pretrained transformers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 34053424, Association for Computational Linguistics, Online and Punta Cana, Dominican Republic. Kim, Eunsu, Juyoung Suk, Philhoon Oh, Haneul Yoo, James Thorne, and Alice Oh. 2024a. CLIcK: Benchmark Dataset of Cultural and Linguistic Intelligence in Korean. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 33353346, ELRA and ICCL, Torino, Italia. Kim, Haven, Jongmin Jung, Dasaem Jeong, and Juhan Nam. 2024b. K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 99749987, ELRA and ICCL, Torino, Italia. Kim, Jaehong, Chaeyoon Jeong, Seongchan Park, Meeyoung Cha, and Wonjae Lee. 2024c. How Do Moral Emotions Shape Political Participation? Cross-Cultural Analysis of Online Petitions Using Language Models. In Findings of the Association for Computational Linguistics ACL 2024, pages 1627416289, Association for Computational Linguistics, Bangkok, Thailand and virtual meeting. Kim, JiWoo, Yunsu Kim, and JinYeong Bak. 2024. KpopMT: Translation Dataset with Terminology for Kpop Fandom. ArXiv preprint, abs/2407.07413. 68 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Kirk, Hannah Rose, Bertie Vidgen, Paul Röttger, and Scott A. Hale. 2024. The Benefits, Risks and Bounds of Personalizing the Alignment of Large Language Models to Individuals. Nature Machine Intelligence, 6(4):383392. Kiulian, Artur, Anton Polishko, Mykola Khandoga, Oryna Chubych, Jack Connor, Raghav Ravishankar, and Adarsh Shirawalmath. 2024. From bytes to borsch: Fine-tuning gemma and mistral for the Ukrainian language representation. In Proceedings of the Third Ukrainian Natural Language Processing Workshop (UNLP) @ LREC-COLING 2024, pages 8394, ELRA and ICCL, Torino, Italia. Köpf, Andreas, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi Rui Tam, Keith Stevens, Abdullah Barhoum, Duc Nguyen, Oliver Stanley, Richárd Nagyfi, Shahul ES, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and Alexander Mattick. 2023. OpenAssistant Conversations - Democratizing Large Language Model Alignment. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Korre, Katerina, Arianna Muti, and Alberto Barrón-Cedeño. 2024. The Challenges of Creating Parallel Multilingual Hate Speech Corpus: An Exploration. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1584215853, ELRA and ICCL, Torino, Italia. Kossaifi, Jean, Robert Walecki, Yannis Panagakis, Jie Shen, Maximilian Schmitt, Fabien Ringeval, Jing Han, Vedhas Pandit, Antoine Toisoul, Björn Schuller, et al. 2019. Sewa db: rich database for audio-visual emotion and sentiment research in the wild. IEEE transactions on pattern analysis and machine intelligence, 43(3):10221040. Koto, Fajri, Nurul Aisyah, Haonan Li, and Timothy Baldwin. 2023. Large language models only pass primary school exams in Indonesia: comprehensive test on IndoMMLU. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1235912374, Association for Computational Linguistics, Singapore. Koto, Fajri, Haonan Li, Sara Shatnawi, Jad Doughman, Abdelrahman Sadallah, Aisha Alraeesi, Khalid Almubarak, Zaid Alyafeai, Neha Sengupta, Shady Shehata, Nizar Habash, Preslav Nakov, and Timothy Baldwin. 2024a. ArabicMMLU: Assessing massive multitask language understanding in Arabic. In Findings of the Association for Computational Linguistics ACL 2024, pages 56225640, Association for Computational Linguistics, Bangkok, Thailand and virtual meeting. Koto, Fajri, Rahmad Mahendra, Nurul Aisyah, and Timothy Baldwin. 2024b. IndoCulture: Exploring Geographically-Influenced Cultural Commonsense Reasoning Across Eleven Indonesian Provinces. ArXiv preprint, abs/2404.01854. Kunda, Maithilee and Irina Rabkina. 2020. Creative captioning: An ai grand challenge based on the dixit board game. ArXiv preprint, abs/2010.00048. Kuznetsova, Alina, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander Kolesnikov, et al. 2020. The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale. International journal of computer vision, 128(7):19561981. Ladhak, Faisal, Esin Durmus, Mirac Suzgun, Tianyi Zhang, Dan Jurafsky, Kathleen McKeown, and Tatsunori Hashimoto. 2023. When Do Pre-Training Biases Propagate to Downstream Tasks? Case Study in Text Summarization. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 32063219, Association for Computational Linguistics, Dubrovnik, Croatia. Lahoti, Preethi, Nicholas Blumm, Xiao Ma, Raghavendra Kotikalapudi, Sahitya Potluri, Qijun Tan, Hansa Srinivasan, Ben Packer, Ahmad Beirami, Alex Beutel, and Jilin Chen. 2023a. Improving diversity of demographic representation in large language models via collective-critiques and self-voting. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1038310405, Association for Computational Linguistics, Singapore. Lahoti, Preethi, Nicholas Blumm, Xiao Ma, Raghavendra Kotikalapudi, Sahitya Potluri, Qijun Tan, Hansa Srinivasan, Ben Packer, Ahmad Beirami, Alex Beutel, and Jilin Chen. 2023b. Improving diversity of demographic representation in large language models via collective-critiques and self-voting. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1038310405, Association for Computational Linguistics, Singapore. 69 Le, Thang and Anh Luu. 2023. Parallel Corpus for Vietnamese Central-Northern Dialect Text Transfer. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1383913855, Association for Computational Linguistics, Singapore. Lee, Hwaran, Seokhee Hong, Joonsuk Park, Takyoung Kim, Gunhee Kim, and Jung-woo Ha. 2023a. KoSBI: dataset for mitigating social bias risks towards safer large language model applications. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track), pages 208224, Association for Computational Linguistics, Toronto, Canada. Lee, Hwaran, Seokhee Hong, Joonsuk Park, Takyoung Kim, Gunhee Kim, and Jung-woo Ha. 2023b. KoSBI: dataset for mitigating social bias risks towards safer large language model applications. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track), pages 208224, Association for Computational Linguistics, Toronto, Canada. Lee, Jiyoung, Minwoo Kim, Seungho Kim, Junghwan Kim, Seunghyun Won, Hwaran Lee, and Edward Choi. 2024a. Kornat: Llm alignment benchmark for korean social values and common knowledge. ArXiv preprint, abs/2402.13605. Lee, Nayeon, Chani Jung, Junho Myung, Jiho Jin, Jose Camacho-Collados, Juho Kim, and Alice Oh. 2024b. Exploring cross-cultural differences in English hate speech annotations: From dataset construction to analysis. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 42054224, Association for Computational Linguistics, Mexico City, Mexico. Lee, Nayeon, Chani Jung, and Alice Oh. 2023. Hate speech classifiers are culturally insensitive. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 3546, Association for Computational Linguistics, Dubrovnik, Croatia. Leeb, Felix and Bernhard Schölkopf. 2024. diverse multilingual news headlines dataset from around the world. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers), pages 647652, Association for Computational Linguistics, Mexico City, Mexico. Leong, Wei Qi, Jian Gang Ngui, Yosephine Susanto, Hamsawardhini Rengarajan, Kengatharaiyer Sarveswaran, and William Chandra Tjhi. 2023. Bhasa: holistic southeast asian linguistic and cultural evaluation suite for large language models. ArXiv preprint, abs/2309.06085. Li, Baiqi, Zhiqiu Lin, Deepak Pathak, Jiayao Emily Li, Xide Xia, Graham Neubig, Pengchuan Zhang, and Deva Ramanan. 2024a. Genai-bench: holistic benchmark for compositional text-to-visual generation. In Synthetic Data for Computer Vision Workshop@ CVPR 2024. Li, Cheng, Mengzhou Chen, Jindong Wang, Sunayana Sitaram, and Xing Xie. 2024b. Culturellm: Incorporating cultural differences into large language models. ArXiv preprint, abs/2402.10946. Li, Cheng, Damien Teney, Linyi Yang, Qingsong Wen, Xing Xie, and Jindong Wang. 2024c. Culturepark: Boosting cross-cultural understanding in large language models. ArXiv preprint, abs/2405.15145. Li, Chengxi, Kai Fan, Jiajun Bu, Boxing Chen, Zhongqiang Huang, and Zhi Yu. 2023a. Translate the beauty in songs: Jointly learning to align melody and translate lyrics. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 2739, Association for Computational Linguistics, Singapore. Li, Chong, Wen Yang, Jiajun Zhang, Jinliang Lu, Shaonan Wang, and Chengqing Zong. 2024d. X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions. In Findings of the Association for Computational Linguistics ACL 2024, pages 546566, Association for Computational Linguistics, Bangkok, Thailand and virtual meeting. Li, Haonan, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and Timothy Baldwin. 2024e. CMMLU: Measuring massive multitask language understanding in Chinese. In Findings of the Association for Computational Linguistics ACL 2024, pages 1126011285, Association for Computational Linguistics, Bangkok, Thailand and virtual meeting. Li, Huihan, Liwei Jiang, Nouha Dziri, Xiang Ren, and Yejin Choi. 2024f. Culture-gen: Revealing global cultural perception in language models through natural language prompting. ArXiv preprint, abs/2404.10199. Li, Jialin, Junli Wang, Junjie Hu, and Ming Jiang. 2024g. How well do LLMs identify cultural unity in diversity? In First Conference on Language Modeling. 70 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Li, Oliver, Mallika Subramanian, Arkadiy Saakyan, Sky CH-Wang, and Smaranda Muresan. 2023b. NormDial: comparable bilingual synthetic dialog dataset for modeling social norm adherence and violation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1573215744, Association for Computational Linguistics, Singapore. Li, Wei, Shutan Huang, and Yanqiu Shao. 2024. An Unsupervised Framework for Adaptive Context-aware Simplified-Traditional Chinese Character Conversion. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 13181326, ELRA and ICCL, Torino, Italia. Li, Wei, Ren Ma, Jiang Wu, Chenya Gu, Jiahui Peng, Jinyang Len, Songyang Zhang, Hang Yan, Dahua Lin, and Conghui He. 2024h. FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models. ArXiv preprint, abs/2404.18359. Li, Wenjun, Ying Cai, Ziyang Wu, Wenyi Zhang, Yifan Chen, Rundong Qi, Mengqi Dong, Peigen Chen, Xiao Dong, Fenghao Shi, et al. 2024i. survey of foundation models for music understanding. ArXiv preprint, abs/2409.09601. Li, Wenyan, Xinyu Zhang, Jiaang Li, Qiwei Peng, Raphael Tang, Li Zhou, Weijia Zhang, Guimin Hu, Yifei Yuan, Anders Søgaard, et al. 2024j. Foodieqa: multimodal dataset for fine-grained understanding of chinese food culture. ArXiv preprint, abs/2406.11030. Li, Yizhi, Ge Zhang, Xingwei Qu, Jiali Li, Zhaoqun Li, Zekun Wang, Hao Li, Ruibin Yuan, Yinghao Ma, Kai Zhang, et al. 2024k. CIF-Bench: Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models. ArXiv preprint, abs/2402.13109. Li, Yuqing, Yuxin Zhang, Bin Wu, Ji-Rong Wen, Ruihua Song, and Ting Bai. 2022. multi-modal knowledge graph for classical Chinese poetry. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 23182326, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Li, Zhi and Yin Zhang. 2023. Cultural Concept Adaptation on Multimodal Reasoning. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 262276, Association for Computational Linguistics, Singapore. Liang, Ke, Chu-Ren Huang, and Xin-Lan Jiang. 2024. From text to historical ecological knowledge: The construction and application of the Shan jing knowledge base. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 75217530, ELRA and ICCL, Torino, Italia. Lin, Tsung-Yi, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Computer VisionECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part 13, pages 740755, Springer. Lin, Xi Victoria, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, et al. 2021. Few-shot learning with multilingual language models. ArXiv preprint, abs/2112.10668. Lin, Yen-Ting and Yun-Nung Chen. 2023. Taiwan llm: Bridging the linguistic divide with culturally aligned language model. ArXiv preprint, abs/2311.17487. Liu, Bingshuai, Longyue Wang, Chenyang Lyu, Yong Zhang, Jinsong Su, Shuming Shi, and Zhaopeng Tu. 2023a. On the cultural gap in text-to-image generation. ArXiv preprint, abs/2307.02971. Liu, Chen, Gregor Geigle, Robin Krebs, and Iryna Gurevych. 2022a. FigMemes: dataset for figurative language identification in politically-opinionated memes. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 70697086, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Liu, Chen, Fajri Koto, Timothy Baldwin, and Iryna Gurevych. 2024a. Are multilingual LLMs culturally-diverse reasoners? an investigation into multicultural proverbs and sayings. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 20162039, Association for Computational Linguistics, Mexico City, Mexico. Liu, Chen Cecilia, Iryna Gurevych, and Anna Korhonen. 2024. Culturally aware and adapted nlp: taxonomy and survey of the state of the art. ArXiv preprint, abs/2406.03930. Liu, Emmy, Chenxuan Cui, Kenneth Zheng, and Graham Neubig. 2022b. Testing the ability of language models to interpret figurative language. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 44374452, Association for Computational Linguistics, Seattle, United 71 States. Liu, Fangyu, Emanuele Bugliarello, Edoardo Maria Ponti, Siva Reddy, Nigel Collier, and Desmond Elliott. 2021a. Visually grounded reasoning across languages and cultures. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1046710485, Association for Computational Linguistics, Online and Punta Cana, Dominican Republic. Liu, Fangyu, Emanuele Bugliarello, Edoardo Maria Ponti, Siva Reddy, Nigel Collier, and Desmond Elliott. 2021b. Visually grounded reasoning across languages and cultures. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1046710485, Association for Computational Linguistics, Online and Punta Cana, Dominican Republic. Liu, Hanmeng, Jian Liu, Leyang Cui, Zhiyang Teng, Nan Duan, Ming Zhou, and Yue Zhang. 2023b. Logiqa 2.0an improved dataset for logical reasoning in natural language understanding. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 31:29472962. Liu, Meina. 2016. Verbal Communication Styles and Culture. Liu, Xiao, Yansong Feng, Jizhi Tang, Chengang Hu, and Dongyan Zhao. 2022c. Counterfactual recipe generation: Exploring compositional generalization in realistic scenario. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 73547370, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Liu, Yang, Zi Lin, and Sichen Kang. 2018. Towards description of chinese morphemic concepts and semantic word-formation. Journal of Chinese Information Processing, 32(2):1120. Liu, Yang, Meng Xu, Shuo Wang, Liner Yang, Haoyu Wang, Zhenghao Liu, Cunliang Kong, Yun Chen, Maosong Sun, and Erhong Yang. 2024b. Omgeval: An open multilingual generative evaluation benchmark for large language models. ArXiv preprint, abs/2402.13524. Liu, Zhi-Song, Robin Courant, and Vicky Kalogeiton. 2024. Funnynet-w: Multimodal learning of funny moments in videos in the wild. International Journal of Computer Vision, pages 122. Liu, Zhixuan, Youeun Shin, Beverley-Claire Okogwu, Youngsik Yun, Lia Coleman, Peter Schaldenbrand, Jihie Kim, and Jean Oh. 2023c. Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset. ArXiv preprint, abs/2301.12073. Liu, Zoey, Crystal Richardson, Richard Hatcher, and Emily Prudhommeaux. 2022d. Not always about you: Prioritizing community needs when developing endangered language technology. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 39333944, Association for Computational Linguistics, Dublin, Ireland. Lou, Lianzhang, Xi Yin, Yutao Xie, and Yang Xiang. 2023. CCEval: representative evaluation benchmark for the Chinese-centric multilingual machine translation. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1017610184, Association for Computational Linguistics, Singapore. Lovenia, Holy, Rahmad Mahendra, Salsabil Maulana Akbar, Lester James Miranda, Jennifer Santoso, Elyanah Aco, Akhdan Fadhilah, Jonibek Mansurov, Joseph Marvin Imperial, Onno Kampman, et al. 2024. Seacrowd: multilingual multimodal data hub and benchmark suite for southeast asian languages. ArXiv preprint, abs/2406.10118. Lu, Christina, Jackie Kay, and Kevin McKee. 2022. Subverting machines, fluctuating identities: Re-learning human categorization. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, FAccT 22, page 10051015, Association for Computing Machinery, New York, NY, USA. Lyu, Hanjia, Jinfa Huang, Daoan Zhang, Yongsheng Yu, Xinyi Mou, Jinsheng Pan, Zhengyuan Yang, Zhongyu Wei, and Jiebo Luo. 2023. Gpt-4v (ision) as social media analysis engine. ArXiv preprint, abs/2311.07547. Ma, Weicheng, Samiha Datta, Lili Wang, and Soroush Vosoughi. 2022. EnCBP: new benchmark dataset for finer-grained cultural background prediction in English. In Findings of the Association for Computational Linguistics: ACL 2022, pages 28112823, Association for Computational Linguistics, Dublin, Ireland. Ma, Zheng, Mianzhi Pan, Wenhan Wu, Ka Leong Cheng, Jianbing Zhang, Shujian Huang, and Jiajun Chen. 2023. Food-500 cap: fine-grained food caption benchmark for evaluating vision-language models. Proceedings of the 31st ACM International Conference on Multimedia. Magomere, Jabez, Shu Ishida, Tejumade Afonja, Aya Salama, Daniel Kochin, Foutse Yuehgoh, Imane Hamzaoui, Raesetje Sefala, Aisha Alaagib, Elizaveta Semenova, et al. 2024. You are 72 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond what you eat? Feeding foundation models regionally diverse food dataset of World Wide Dishes. ArXiv preprint, abs/2406.09496. Majewska, Olga, Evgeniia Razumovskaia, Edoardo M. Ponti, Ivan Vulic, and Anna Korhonen. 2023. Cross-lingual dialogue dataset creation via outline-based generation. Transactions of the Association for Computational Linguistics, 11:139156. Makridis, Georgios, Athanasios Oikonomou, and Vasileios Koukos. 2024. Fairylandai: Personalized fairy tales utilizing chatgpt and dalle-3. ArXiv preprint, abs/2407.09467. Manvi, Rohin, Samar Khanna, Marshall Burke, David B. Lobell, and Stefano Ermon. 2024. Large language models are geographically biased. In Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 3465434669, PMLR. Marino, Kenneth, Mohammad Rastegari, Ali Farhadi, and Roozbeh Mottaghi. 2019. OK-VQA: visual question answering benchmark requiring external knowledge. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019, pages 31953204, Computer Vision Foundation / IEEE. Maronikolakis, Antonis, Axel Wisiorek, Leah Nann, Haris Jabbar, Sahana Udupa, and Hinrich Schuetze. 2022. Listening to Affected Communities to Define Extreme Speech: Dataset and Experiments. In Findings of the Association for Computational Linguistics: ACL 2022, pages 10891104, Association for Computational Linguistics, Dublin, Ireland. Masala, Mihai, Denis C. Ilie-Ablachim, Alexandru Dima, Dragos Corlatescu, Miruna Zavelca, Ovio Olaru, Simina Terian, Andrei Terian, Marius Leordeanu, Horia Velicu, Marius Popescu, Mihai Dascalu, and Traian Rebedea. 2024a. \"vorbesti româneste?\" recipe to train powerful romanian llms with english instructions. ArXiv preprint, abs/2406.18266. Masala, Mihai, Denis Ilie-Ablachim, Alexandru Dima, Dragos Corlatescu, Miruna Zavelca, Ovio Olaru, Simina Terian-Dan, Andrei Terian-Dan, Marius Leordeanu, Horia Velicu, et al. 2024b. \" vorbec {s} ti romˆ anec {s} te?\" recipe to train powerful romanian llms with english instructions. ArXiv preprint, abs/2406.18266. Masoud, Reem I, Ziquan Liu, Martin Ferianc, Philip Treleaven, and Miguel Rodrigues. 2023. Cultural alignment in large language models: An explanatory analysis based on hofstedes cultural dimensions. ArXiv preprint, abs/2309.12342. Mathur, Leena, Ralph Adolphs, and Maja Mataric. 2023. Towards intercultural affect recognition: Audio-visual affect recognition in the wild across six cultures. In 2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG), pages 16, IEEE. Matsumoto, David. 2007. Culture, context, and behavior. Journal of personality, 75(6):12851320. Mausam. 2016. Open information extraction systems and downstream applications. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, pages 40744077, IJCAI/AAAI Press. Meadows, Gwenyth Isobel, Nicholas Wai Long Lau, Eva Adelina Susanto, Chi Lok Yu, and Aditya Paul. 2024. Localvaluebench: collaboratively built and extensible benchmark for evaluating localized value alignment and ethical safety in large language models. ArXiv preprint, abs/2408.01460. Menadue, Christopher Benjamin and Karen Diane Cheer. 2017. Human culture and science fiction: review of the literature, 1980-2016. Sage Open, 7(3):2158244017723690. Menicatti, Roberto, Barbara Bruno, and Antonio Sgorbissa. 2017. Modelling the influence of cultural information on vision-based human home activity recognition. In 2017 14th international conference on ubiquitous robots and ambient intelligence (URAI), pages 3238, IEEE. Mercorio, Fabio, Mario Mezzanzanica, Daniele Potertì, Antonio Serino, and Andrea Seveso. 2024. Disce aut deficere: Evaluating llms proficiency on the invalsi italian benchmark. ArXiv preprint, abs/2406.17535. Migon Favaretto, Rodolfo, Soraia Raupp Musse, Angelo Brandelli Costa, Rodolfo Migon Favaretto, Soraia Raupp Musse, and Angelo Brandelli Costa. 2019. Detecting hofstede cultural dimensions. Emotion, Personality and Cultural Aspects in Crowds: Towards Geometrical Mind, pages 93103. Min, Weiqing, Linhu Liu, Zhiling Wang, Zhengdong Luo, Xiaoming Wei, Xiaolin Wei, and Shuqiang Jiang. 2020. ISIA food-500: dataset for large-scale food recognition via stacked global-local attention network. In MM 20: The 28th ACM International Conference on Multimedia, Virtual Event / Seattle, WA, USA, October 12-16, 2020, pages 393401. Mirowski, Piotr, Juliette Love, Kory Mathewson, and Shakir Mohamed. 2024. Robot Walks into Bar: Can Language Models Serve as Creativity SupportTools for Comedy? An 73 Evaluation of LLMs Humour Alignment with Comedians. In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency, FAccT 24, page 16221636, Association for Computing Machinery, New York, NY, USA. Mirza, Shujaat, Bruno Coelho, Yuyuan Cui, Christina Pöpper, and Damon McCoy. 2024. Global-liar: Factuality of llms over time and geographic regions. ArXiv preprint, abs/2401.17839. Mittal, Surbhi, Arnav Sudan, Mayank Vatsa, Richa Singh, Tamar Glaser, and Tal Hassner. 2024. Navigating text-to-image generative bias across indic languages. ArXiv preprint, abs/2408.00283. Moghimifar, Farhad, Shilin Qu, Tongtong Wu, Yuan-Fang Li, and Gholamreza Haffari. 2023. NormMark: weakly supervised Markov model for socio-cultural norm discovery. In Findings of the Association for Computational Linguistics: ACL 2023, pages 50815089, Association for Computational Linguistics, Toronto, Canada. Mohamed, Youssef, Mohamed Abdelfattah, Shyma Alhuwaider, Feifan Li, Xiangliang Zhang, Kenneth Church, and Mohamed Elhoseiny. 2022. ArtELingo: million emotion annotations of WikiArt with emphasis on diversity over language and culture. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 87708785, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Mohammad, Saif and Svetlana Kiritchenko. 2018. WikiArt emotions: An annotated dataset of emotions evoked by art. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), European Language Resources Association (ELRA), Miyazaki, Japan. Moradi, Armin, Nicola Neophytou, and Golnoosh Farnadi. 2024. Advancing cultural inclusivity: Optimizing embedding spaces for balanced music recommendations. ArXiv preprint, abs/2405.17607. Moseley, Christopher. 2010. Atlas of the Worlds Languages in Danger. Unesco. Mousi, Basel, Nadir Durrani, Fatema Ahmad, Md Arid Hasan, Maram Hasanain, Tameem Kabbani, Fahim Dalvi, Shammur Absar Chowdhury, and Firoj Alam. 2024. Aradice: Benchmarks for dialectal and cultural capabilities in llms. ArXiv preprint, abs/2409.11404. Mukherjee, Anjishnu, Aylin Caliskan, Ziwei Zhu, and Antonios Anastasopoulos. 2024a. Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 63986415, Association for Computational Linguistics, Mexico City, Mexico. Mukherjee, Anjishnu, Chahat Raj, Ziwei Zhu, and Antonios Anastasopoulos. 2023. Global Voices, local biases: Socio-cultural prejudices across languages. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1582815845, Association for Computational Linguistics, Singapore. Mukherjee, Sagnik, Muhammad Farid Adilazuarda, Sunayana Sitaram, Kalika Bali, Alham Fikri Aji, and Monojit Choudhury. 2024b. Cultural conditioning or placebo? on the effectiveness of socio-demographic prompting. ArXiv preprint, abs/2406.11661. Myung, Junho, Nayeon Lee, Yi Zhou, Jiho Jin, Rifki Afina Putri, Dimosthenis Antypas, Hsuvas Borkakoty, Eunsu Kim, Carla Perez-Almendros, Abinew Ali Ayele, Víctor Gutiérrez-Basulto, Yazmín Ibáñez-García, Hwaran Lee, Shamsuddeen Hassan Muhammad, Kiwoong Park, Anar Sabuhi Rzayev, Nina White, Seid Muhie Yimam, Mohammad Taher Pilehvar, Nedjma Ousidhoum, Jose Camacho-Collados, and Alice Oh. 2024a. BLEnD: Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages. ArXiv preprint, abs/2406.09948. Myung, Junho, Nayeon Lee, Yi Zhou, Jiho Jin, Rifki Afina Putri, Dimosthenis Antypas, Hsuvas Borkakoty, Eunsu Kim, Carla Perez-Almendros, Abinew Ali Ayele, et al. 2024b. Blend: benchmark for llms on everyday knowledge in diverse cultures and languages. ArXiv preprint, abs/2406.09948. Nadejde, Maria, Anna Currey, Benjamin Hsu, Xing Niu, Marcello Federico, and Georgiana Dinu. 2022. CoCoA-MT: dataset and benchmark for contrastive controlled MT with application to formality. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 616632, Association for Computational Linguistics, Seattle, United States. Nangia, Nikita, Clara Vania, Rasika Bhalerao, and Samuel R. Bowman. 2020. CrowS-pairs: challenge dataset for measuring social biases in masked language models. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 19531967, Association for Computational Linguistics, Online. 74 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Naous, Tarek, Michael J. Ryan, Alan Ritter, and Wei Xu. 2023. Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. ArXiv preprint, abs/2305.14456. Narayan, Malur, John Pasmore, Elton Sampaio, Vijay Raghavan, and Gabriella Waters. 2024. Bias neutralization framework: Measuring fairness in large language models with bias intelligence quotient (biq). ArXiv preprint, abs/2404.18276. Navigli, Roberto, Simone Conia, and Björn Ross. 2023. Biases in Large Language Models: Origins, Inventory, and Discussion. J. Data and Information Quality, 15(2). Nayak, Shravan, Kanishk Jain, Rabiul Awal, Siva Reddy, Sjoerd van Steenkiste, Lisa Anne Hendricks, Karolina Sta nczak, and Aishwarya Agrawal. 2024. Benchmarking vision language models for cultural understanding. ArXiv preprint, abs/2407.10920. Naylor, Larry. 1996. Culture and change: An introduction. Bloomsbury Publishing USA. Neiberg, Daniel, Petri Laukka, and Hillary Anger Elfenbein. 2011. Intra-, inter-, and cross-cultural classification of vocal affect. In Interspeech 2011, pages 15811584, ISCA. Neplenbroek, Vera, Arianna Bisazza, and Raquel Fernández. 2024. Mbbq: dataset for cross-lingual comparison of stereotypes in generative llms. ArXiv preprint, abs/2406.07243. Névéol, Aurélie, Yoann Dupont, Julien Bezançon, and Karën Fort. 2022. French CrowS-pairs: Extending challenge dataset for measuring social bias in masked language models to language other than English. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 85218531, Association for Computational Linguistics, Dublin, Ireland. Newmark, Peter. 2003. textbook of translation. Nguyen, Thuat, Chien Van Nguyen, Viet Dac Lai, Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Ryan A. Rossi, and Thien Huu Nguyen. 2024. CulturaX: cleaned, enormous, and multilingual dataset for large language models in 167 languages. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 42264237, ELRA and ICCL, Torino, Italia. Nguyen, Tuan-Phong, Simon Razniewski, Aparna S. Varde, and Gerhard Weikum. 2023a. Extracting cultural commonsense knowledge at scale. In Proceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023, pages 19071917, ACM. Nguyen, Tuan-Phong, Simon Razniewski, Aparna S. Varde, and Gerhard Weikum. 2023b. Extracting Cultural Commonsense Knowledge at Scale. In Proceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023, pages 19071917, ACM. Nguyen, Tuan-Phong, Simon Razniewski, and Gerhard Weikum. 2024. Multi-cultural commonsense knowledge distillation. ArXiv preprint, abs/2402.10689. Nguyen, Xuan-Phi, Wenxuan Zhang, Xin Li, Mahani Aljunied, Qingyu Tan, Liying Cheng, Guanzheng Chen, Yue Deng, Sen Yang, Chaoqun Liu, et al. 2023c. SeaLLMsLarge Language Models for Southeast Asia. ArXiv preprint, abs/2312.00738. Nigst, Lorenz, Maxim Romanov, Sarah Bowen Savant, Masoumeh Seydi, and Peter Verkinderen. 2021. OpenITI: Machine-Readable Corpus of Islamicate Texts (2021.2. 5)[Data Set]. Nisbett, Richard E. and Takahiko Masuda. 2003. Culture and point of view. Proceedings of the National Academy of Sciences of the United States of America, 100:11163 11170. Nivre, Joakim, Daniel Zeman, Filip Ginter, and Francis Tyers. 2017. Universal Dependencies. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts, Association for Computational Linguistics, Valencia, Spain. Nordhoff, Sebastian. Linked Data for Linguistic Diversity Research: Glottolog/Langdoc and ASJP Online. In Linked Data in Linguistics: Representing and Connecting Language Data and Language Metadata. Springer, pages 191200. Noroozi, Fatemeh, Ciprian Adrian Corneanu, Dorota Kami nska, Tomasz Sapi nski, Sergio Escalera, and Gholamreza Anbarjafari. 2018. Survey on emotional body gesture recognition. IEEE transactions on affective computing, 12(2):505523. Ochieng, Millicent, Varun Gumma, Sunayana Sitaram, Jindong Wang, Vishrav Chaudhary, Keshet Ronen, Kalika Bali, and Jacki ONeill. 2024. Beyond Metrics: Evaluating LLMs Effectiveness in Culturally Nuanced, Low-Resource Real-World Scenarios. ArXiv preprint, abs/2406.00343. Ofer, Dan and Dafna Shahaf. 2022. Cards against AI: Predicting humor in fill-in-the-blank party game. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 53975403, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. OpenAI. ChatGPT. https://chat.openai.com/. 75 OpenAI. 2023. GPT-4 Technical Report. ArXiv preprint, abs/2303.08774. Owen, Louis, Vishesh Tripathi, Abhay Kumar, and Biddwan Ahmed. 2024. Komodo: Linguistic Expedition into Indonesias Regional Languages. ArXiv preprint, abs/2403.09362. Ozaki, Shintaro, Kazuki Hayashi, Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, and Taro Watanabe. 2024. Towards cross-lingual explanation of artwork in large-scale vision language models. ArXiv preprint, abs/2409.01584. Padmakumar, Vishakh and He He. 2023. Does Writing with Language Models Reduce Content Diversity? ArXiv preprint, abs/2309.05196. Palta, Shramay and Rachel Rudinger. 2023. FORK: bite-sized test set for probing culinary cultural biases in commonsense reasoning models. In Findings of the Association for Computational Linguistics: ACL 2023, pages 99529962, Association for Computational Linguistics, Toronto, Canada. Pandya, Keivalya and Mehfuza Holia. 2023. Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations. ArXiv preprint, abs/2310.05421. Pappas, Nikolaos, Miriam Redi, Mercan Topkara, Brendan Jou, Hongyi Liu, Tao Chen, and Shih-Fu Chang. 2016. Multilingual visual sentiment concept matching. In Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval, pages 151158. Parida, Shantipriya, Idris Abdulmumin, Shamsuddeen Hassan Muhammad, Aneesh Bose, Guneet Singh Kohli, Ibrahim Said Ahmad, Ketan Kotwal, Sayan Deb Sarkar, Ondˇrej Bojar, and Habeebah Kakudi. 2023. HaVQA: Dataset for Visual Question Answering and Multimodal Research in Hausa Language. In Findings of the Association for Computational Linguistics: ACL 2023, pages 1016210183, Association for Computational Linguistics, Toronto, Canada. Park, Joon Sung, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2022. Social simulacra: Creating populated prototypes for social computing systems. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology, UIST 22, Association for Computing Machinery, New York, NY, USA. Parrish, Alicia, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu Mon Htut, and Samuel Bowman. 2022. BBQ: hand-built bias benchmark for question answering. In Findings of the Association for Computational Linguistics: ACL 2022, pages 20862105, Association for Computational Linguistics, Dublin, Ireland. Perez, Ethan, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving. 2022. Red teaming language models with language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 34193448, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Peters, Heinrich and Sandra Matz. 2024. Large Language Models Can Infer Psychological Dispositions of Social Media Users. PNAS Nexus, 3(6):pgae231. Peterson, Sharyl Bender and Mary Alyce Lach. 1990. Gender stereotypes in childrens books: their prevalence and influence on cognitive and affective development. Gender and Education, 2(2):185197. Picca, Davide and John Pavlopoulos. 2024. Deciphering emotional landscapes in the Iliad: novel French-annotated dataset for emotion recognition. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 44624467, ELRA and ICCL, Torino, Italia. Pipatanakul, Kunat, Phatrasek Jirabovonvisut, Potsawee Manakul, Sittipong Sripaisarnmongkol, Ruangsak Patomwong, Pathomporn Chokchainant, and Kasima Tharnpipitchai. 2023. Typhoon: Thai large language models. ArXiv preprint, abs/2312.13951. Pires, Ramon, Hugo Abonizio, Thales Sales Almeida, and Rodrigo Nogueira. 2023. Sabiá: Portuguese large language models. In Brazilian Conference on Intelligent Systems, pages 226240, Springer. Pistilli, Giada, Alina Leidinger, Yacine Jernite, Atoosa Kasirzadeh, Alexandra Sasha Luccioni, and Margaret Mitchell. 2024. Civics: Building dataset for examining culturally-informed values in large language models. ArXiv preprint, abs/2405.13974. Prabhakaran, Vinodkumar, Christopher Homan, Lora Aroyo, Aida Mostafazadeh Davani, Alicia Parrish, Alex Taylor, Mark Diaz, Ding Wang, and Gregory Serapio-García. 2024. GRASP: Disagreement Analysis Framework to Assess Group Associations in Perspectives. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 34733492, Association for Computational Linguistics, Mexico City, Mexico. 76 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Prabhakaran, Vinodkumar, Rida Qadri, and Ben Hutchinson. 2022. Cultural Incongruencies in Artificial Intelligence. ArXiv preprint, abs/2211.13069. Pramanick, Shraman, Dimitar Dimitrov, Rituparna Mukherjee, Shivam Sharma, Md. Shad Akhtar, Preslav Nakov, and Tanmoy Chakraborty. 2021. Detecting harmful memes and their targets. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 27832796, Association for Computational Linguistics, Online. Putri, Rifki Afina, Faiz Ghifari Haznitrama, Dea Adhista, and Alice Oh. 2024a. Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese. ArXiv preprint, abs/2402.17302. Putri, Rifki Afina, Faiz Ghifari Haznitrama, Dea Adhista, and Alice Oh. 2024b. Can llm generate culturally relevant commonsense qa data? case study in indonesian and sundanese. ArXiv preprint, abs/2402.17302. Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning transferable visual models from natural language supervision. In Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 87488763, PMLR. Radharapu, Bhaktipriya, Kevin Robinson, Lora Aroyo, and Preethi Lahoti. 2023. AART: AI-assisted red-teaming with diverse data generation for new LLM-powered applications. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track, pages 380395, Association for Computational Linguistics, Singapore. Rafailov, Rafael, Archit Sharma, Eric Mitchell, Christopher D. Manning, Stefano Ermon, and Chelsea Finn. 2023. Direct preference optimization: Your language model is secretly reward model. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Rai, Sunny, Khushang Zilesh Zaveri, Shreya Havaldar, Soumna Nema, Lyle Ungar, and Sharath Chandra Guntuku. 2024. cross-cultural analysis of social norms in bollywood and hollywood movies. ArXiv preprint, abs/2402.11333. Ramesh, Aditya, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. Hierarchical text-conditional image generation with clip latents. ArXiv preprint, abs/2204.06125. Ramezani, Aida and Yang Xu. 2023. Knowledge of cultural moral norms in large language models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 428446, Association for Computational Linguistics, Toronto, Canada. Ramponi, Alan. 2024. Language varieties of Italy: Technology challenges and opportunities. Transactions of the Association for Computational Linguistics, 12:1938. Rao, Abhinav, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, and Maarten Sap. 2024. Normad: benchmark for measuring the cultural adaptability of large language models. ArXiv preprint, abs/2404.12464. Razavi, Ali, Aäron van den Oord, and Oriol Vinyals. 2019. Generating diverse high-fidelity images with VQ-VAE-2. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 1483714847. Rehm, Matthias, Elisabeth André, Nikolaus Bee, Birgit Endrass, Michael Wissner, Yukiko Nakano, Afia Akhter Lipi, Toyoaki Nishida, and Hung-Hsuan Huang. 2009. Creating standardized video recordings of multimodal interactions across cultures. pages 138159. Ringeval, Fabien, Björn Schuller, Michel Valstar, Nicholas Cummins, Roddy Cowie, Leili Tavabi, Maximilian Schmitt, Sina Alisamir, Shahin Amiriparian, Eva-Maria Messner, et al. 2019. Avec 2019 workshop and challenge: state-of-mind, detecting depression with ai, and cross-cultural affect recognition. In Proceedings of the 9th International on Audio/visual Emotion Challenge and Workshop, pages 312. Rizwan, Hammad, Muhammad Haroon Shakeel, and Asim Karim. 2020. Hate-Speech and Offensive Language Detection in Roman Urdu. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 25122522, Association for Computational Linguistics, Online. Roemmele, Melissa, Cosmin Adrian Bejan, and Andrew Gordon. 2011. Choice of plausible alternatives: An evaluation of commonsense causal reasoning. In 2011 AAAI spring symposium series. 77 Rohmawati, Inayah Ahyana, Esti Junining, and Pratnyawati Nuridi Suwarso. 2022. The idioms and culture-specific items translation strategy for classic novel. Journey: Journal of English Language and Pedagogy, 5(2):169181. Rojas, William Gaviria, Sudnya Frederick Diamos, Keertan Kini, David Kanter, Vijay Janapa Reddi, and Cody Coleman. 2022. The dollar street dataset: Images representing the geographic and socioeconomic diversity of the world. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022. Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1068410695. Romero, David, Chenyang Lyu, Haryo Akbarianto Wibowo, Teresa Lynn, Injy Hamed, Aditya Nanda Kishore, Aishik Mandal, Alina Dragonetti, Artem Abzaliev, Atnafu Lambebo Tonja, et al. 2024. CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark. ArXiv preprint, abs/2406.05967. Ruiz, Nataniel, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman. 2023. DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023, pages 2250022510, IEEE. Saharia, Chitwan, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L. Denton, Seyed Kamyar Seyed Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, Jonathan Ho, David J. Fleet, and Mohammad Norouzi. 2022. Photorealistic text-to-image diffusion models with deep language understanding. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022. Sahoo, Nihar, Pranamya Kulkarni, Arif Ahmad, Tanu Goyal, Narjis Asad, Aparna Garimella, and Pushpak Bhattacharyya. 2024. IndiBias: benchmark dataset to measure social biases in language models for Indian context. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 87868806, Association for Computational Linguistics, Mexico City, Mexico. Sandoval, Sandra, Jieyu Zhao, Marine Carpuat, and Hal Daumé III. 2023. rose by any other name would not smell as sweet: Social bias in names mistranslation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 39333945, Association for Computational Linguistics, Singapore. Sankaran, Aditya Narayan, Vigneshwaran Shankaran, Sampath Lonka, and Rajesh Sharma. 2024. Revisiting the classics: study on identifying and rectifying gender stereotypes in rhymes and poems. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1409214102, ELRA and ICCL, Torino, Italia. Santurkar, Shibani, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, and Tatsunori Hashimoto. 2023. Whose opinions do language models reflect? In International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pages 2997130004, PMLR. Sap, Maarten, Swabha Swayamdipta, Laura Vianna, Xuhui Zhou, Yejin Choi, and Noah A. Smith. 2022. Annotators with attitudes: How annotator beliefs and identities bias toxic language detection. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 58845906, Association for Computational Linguistics, Seattle, United States. Sapinski, Tomasz and Dorota Kami nska. 2015. Emotion recognition from natural speech emotional profiles. Saulite, Baiba, Roberts Dar gis, Normunds Gruzitis, Ilze Auzina, Kristıne Levane-Petrova, Lauma Pretkalnin, a, Laura Rituma, Peteris Paikens, Arturs Znotins, Laine Strankale, Kristıne Pokratniece, Ilmars Poikans, Guntis Barzdins, Inguna Skadin, a, Anda Baklane, Valdis Saulespurens, and Janis Ziedin, š. 2022. Latvian national corpora collection korpuss.lv. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 51235129, European Language Resources Association, Marseille, France. Saxon, Michael and William Yang Wang. 2023. Multilingual conceptual coverage in text-to-image models. In Proceedings of the 61st Annual Meeting of the Association for 78 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Computational Linguistics (Volume 1: Long Papers), pages 48314848, Association for Computational Linguistics, Toronto, Canada. Scao, Teven Le, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, Jonathan Tow, Alexander M. Rush, Stella Biderman, Albert Webson, Pawan Sasanka Ammanamanchi, Thomas Wang, Benoît Sagot, Niklas Muennighoff, Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina Mcmillan-Major, Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Laurençon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David Ifeoluwa Adelani, Dragomir Radev, Eduardo González Ponferrada, Efrat Levkovizh, Ethan Kim, Eyal Bar Natan, Francesco de Toni, Gérard Dupont, Germán Kruszewski, Giada Pistilli, Hady Elsahar, Hamza Benyamina, Hieu Tran, Ian Yu, Idris Abdulmumin, Isaac Johnson, Itziar Gonzalez-Dios, Javier de la Rosa, Jenny Chim, Jesse Dodge, Jian Zhu, Jonathan Chang, Jörg Frohberg, Joseph Tobing, Joydeep Bhattacharjee, Khalid Almubarak, Kimbo Chen, Kyle Lo, Leandro von Werra, Leon Weber, Long Phan, Loubna Ben Allal, Ludovic Tanguy, Manan Dey, Manuel Romero Muñoz, Maraim Masoud, María Grandury, Mario Šaško, Max Huang, Maximin Coavoux, Mayank Singh, Mike Tian-Jian Jiang, Minh Chien Vu, Mohammad A. Jauhar, Mustafa Ghaleb, Nishant Subramani, Nora Kassner, Nurulaqilla Khamis, Olivier Nguyen, Omar Espejel, Ona de Gibert, Paulo Villegas, Peter Henderson, Pierre Colombo, Priscilla Amuok, Quentin Lhoest, Rheza Harliman, Rishi Bommasani, Roberto Luis López, Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Sebastian Nagel, Shamik Bose, Shamsuddeen Hassan Muhammad, Shanya Sharma, Shayne Longpre, Somaieh Nikpoor, Stanislav Silberberg, Suhas Pai, Sydney Zink, Tiago Timponi Torrent, Timo Schick, Tristan Thrush, Valentin Danchev, Vassilina Nikoulina, Veronika Laippala, Violette Lepercq, Vrinda Prabhu, Zaid Alyafeai, Zeerak Talat, Arun Raja, Benjamin Heinzerling, Chenglei Si, Elizabeth Salesky, Sabrina J. Mielke, Wilson Y. Lee, Abheesht Sharma, Andrea Santilli, Antoine Chaffin, Arnaud Stiegler, Debajyoti Datta, Eliza Szczechla, Gunjan Chhablani, Han Wang, Harshit Pandey, Hendrik Strobelt, Jason Alan Fries, Jos Rozen, Leo Gao, Lintang Sutawika, Saiful Bari, Maged S. Al-Shaibani, Matteo Manica, Nihal Nayak, Ryan Teehan, Samuel Albanie, Sheng Shen, Srulik Ben-David, Stephen H. Bach, Taewoon Kim, Tali Bers, Thibault Fevry, Trishala Neeraj, Urmish Thakker, Vikas Raunak, Xiangru Tang, Zheng-Xin Yong, Zhiqing Sun, Shaked Brody, Yallow Uri, Hadar Tojarieh, Adam Roberts, Hyung Won Chung, Jaesung Tae, Jason Phang, Ofir Press, Conglong Li, Deepak Narayanan, Hatim Bourfoune, Jared Casper, Jeff Rasley, Max Ryabinin, Mayank Mishra, Minjia Zhang, Mohammad Shoeybi, Myriam Peyrounette, Nicolas Patry, Nouamane Tazi, Omar Sanseviero, Patrick von Platen, Pierre Cornette, Pierre François Lavallée, Rémi Lacroix, Samyam Rajbhandari, Sanchit Gandhi, Shaden Smith, Stéphane Requena, Suraj Patil, Tim Dettmers, Ahmed Baruwa, Amanpreet Singh, Anastasia Cheveleva, Anne-Laure Ligozat, Arjun Subramonian, Aurélie Névéol, Charles Lovering, Dan Garrette, Deepak Tunuguntla, Ehud Reiter, Ekaterina Taktasheva, Ekaterina Voloshina, Eli Bogdanov, Genta Indra Winata, Hailey Schoelkopf, Jan-Christoph Kalo, Jekaterina Novikova, Jessica Zosa Forde, Jordan Clive, Jungo Kasai, Ken Kawamura, Liam Hazan, Marine Carpuat, Miruna Clinciu, Najoung Kim, Newton Cheng, Oleg Serikov, Omer Antverg, Oskar van der Wal, Rui Zhang, Ruochen Zhang, Sebastian Gehrmann, Shani Pais, Tatiana Shavrina, Thomas Scialom, Tian Yun, Tomasz Limisiewicz, Verena Rieser, Vitaly Protasov, Vladislav Mikhailov, Yada Pruksachatkun, Yonatan Belinkov, Zachary Bamberger, Zdenˇek Kasner, Alice Rueda, Amanda Pestana, Amir Feizpour, Ammar Khan, Amy Faranak, Ana Santos, Anthony Hevia, Antigona Unldreaj, Arash Aghagol, Arezoo Abdollahi, Aycha Tammour, Azadeh Hajihosseini, Bahareh Behroozi, Benjamin Ajibade, Bharat Saxena, Carlos Muñoz Ferrandis, Danish Contractor, David Lansky, Davis David, Douwe Kiela, Duong A. Nguyen, Edward Tan, Emi Baylor, Ezinwanne Ozoani, Fatima Mirza, Frankline Ononiwu, Habib Rezanejad, Hessie Jones, Indrani Bhattacharya, Irene Solaiman, Irina Sedenko, Isar Nejadgholi, Jesse Passmore, Josh Seltzer, Julio Bonis Sanz, Livia Dutra, Mairon Samagaio, Maraim Elbadri, Margot Mieskes, Marissa Gerchick, Martha Akinlolu, Michael Mckenna, Mike Qiu, Muhammed Ghauri, Mykola Burynok, Nafis Abrar, Nazneen Rajani, Nour Elkott, Nour Fahmy, Olanrewaju Samuel, Ran An, Rasmus Kromann, Ryan Hao, Samira Alizadeh, Sarmad Shubber, Silas Wang, Sourav Roy, Sylvain Viguier, Thanh Le, Tobi Oyebade, Trieu Le, Yoyo Yang, Zach Nguyen, Abhinav Ramesh Kashyap, Alfredo Palasciano, Alison Callahan, Anima 79 Shukla, Antonio Miranda-Escalada, Ayush Singh, Benjamin Beilharz, Bo Wang, Caio Brito, Chenxi Zhou, Chirag Jain, Chuxin Xu, Clémentine Fourrier, Daniel León Periñán, Daniel Molano, Dian Yu, Enrique Manjavacas, Fabio Barth, Florian Fuhrimann, Gabriel Altay, Giyaseddin Bayrak, Gully Burns, Helena U. Vrabec, Imane Bello, Ishani Dash, Jihyun Kang, John Giorgi, Jonas Golde, Jose David Posada, Karthik Rangasai Sivaraman, Lokesh Bulchandani, Lu Liu, Luisa Shinzato, Madeleine Hahn de Bykhovetz, Maiko Takeuchi, Marc Pàmies, Maria Castillo, Marianna Nezhurina, Mario Sänger, Matthias Samwald, Michael Cullan, Michael Weinberg, Michiel de Wolf, Mina Mihaljcic, Minna Liu, Moritz Freidank, Myungsun Kang, Natasha Seelam, Nathan Dahlberg, Nicholas Michio Broad, Nikolaus Muellner, Pascale Fung, Patrick Haller, Ramya Chandrasekhar, Renata Eisenberg, Robert Martin, Rodrigo Canalli, Rosaline Su, Ruisi Su, Samuel Cahyawijaya, Samuele Garda, Shlok Deshmukh, Shubhanshu Mishra, Sid Kiblawi, Simon Ott, Sinee Sang-Aroonsiri, Srishti Kumar, Stefan Schweter, Sushil Bharati, Tanmay Laud, Théo Gigant, Tomoya Kainuma, Wojciech Kusa, Yanis Labrak, Yash Shailesh Bajaj, Yash Venkatraman, Yifan Xu, Yingxin Xu, Yu Xu, Zhe Tan, Zhongli Xie, Zifan Ye, Mathilde Bras, Younes Belkada, and Thomas Wolf. 2023. BLOOM: 176B-Parameter Open-Access Multilingual Language Model. Working paper or preprint. Schneider, Florian and Sunayana Sitaram. 2024. M5 diverse benchmark to assess the performance of large multimodal models across multilingual and multicultural vision-language tasks. ArXiv preprint, abs/2407.03791. Schramm, W. 1954. How Communication Works, volume 586. The process and effects of mass communication/University of Illinois Press. Schuhmann, Christoph, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, Patrick Schramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk, and Jenia Jitsev. 2022. LAION-5B: an open large-scale dataset for training next generation image-text models. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022. Schwartz, Shalom H. 2012. An overview of the schwartz theory of basic values. Online readings in Psychology and Culture, 2(1):11. Scott, Michael Adrir, Sharath Chandra Guntuku, Huan Yang, Weisi Lin, and George Ghinea. 2015. Modelling human factors in perceptual multimedia quality: On the role of personality and culture. Proceedings of the 23rd ACM international conference on Multimedia. Segall, Marshall H., Donald T. Campbell, and Melville J. Herskovits. 1967. The influence of culture on visual perception. Sengupta, Neha, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, Osama Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal, et al. 2023. Jais and jais-chat: Arabic-centric foundation and instruction-tuned open generative large language models. ArXiv preprint, abs/2308.16149. Seth, Agrima, Sanchit Ahuja, Kalika Bali, and Sunayana Sitaram. 2024. DOSA: Dataset of Social Artifacts from Different Indian Geographical Subcultures. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 53235337, ELRA and ICCL, Torino, Italia. Shah, Priyanshi and Ziad Kobti. 2020. Multimodal fake news detection using cultural algorithm with situational and normative knowledge. 2020 IEEE Congress on Evolutionary Computation (CEC), pages 17. Shaikh, Omar, Caleb Ziems, William Held, Aryan Pariani, Fred Morstatter, and Diyi Yang. 2023. Modeling cross-cultural pragmatic inference with codenames duet. In Findings of the Association for Computational Linguistics: ACL 2023, pages 65506569, Association for Computational Linguistics, Toronto, Canada. Sharma, Shivam, Firoj Alam, Md. Shad Akhtar, Dimitar Dimitrov, Giovanni Da San Martino, Hamed Firooz, Alon Y. Halevy, Fabrizio Silvestri, Preslav Nakov, and Tanmoy Chakraborty. 2022. Detecting and understanding harmful memes: survey. In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022, pages 55975606, ijcai.org. Shen, Siqi, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Soujanya Poria, and Rada Mihalcea. 2024. Understanding the capabilities and limitations of large language models for cultural commonsense. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), 80 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond pages 56685680, Association for Computational Linguistics, Mexico City, Mexico. Shen, Tao, Xiubo Geng, and Daxin Jiang. 2022. Social Norms-Grounded Machine Ethics in Complex Narrative Situation. In Proceedings of the 29th International Conference on Computational Linguistics, pages 13331343, International Committee on Computational Linguistics, Gyeongju, Republic of Korea. Shi, Weiyan, Ryan Li, Yutong Zhang, Caleb Ziems, Raya Horesh, Rogério Abreu de Paula, Diyi Yang, et al. 2024. Culturebank: An online community-driven knowledge base towards culturally aware language technologies. ArXiv preprint, abs/2404.15238. Shifman, Limor. 2013. Memes in digital culture. MIT press. Shumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross Anderson, and Yarin Gal. 2024. AI models collapse when trained on recursively generated data. Nature, 631(8022):755759. Shwartz, Vered. 2022. Good night at 4 pm?! time expressions in different cultures. In Findings of the Association for Computational Linguistics: ACL 2022, pages 28422853, Association for Computational Linguistics, Dublin, Ireland. Singh, Akshay and Rahul Thakur. 2024. Generalizable Multilingual Hate Speech Detection on Low Resource Indian Languages using Fair Selection in Federated Learning. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 72117221, Association for Computational Linguistics, Mexico City, Mexico. Son, Guijin, Hanwool Lee, Sungdong Kim, Seungone Kim, Niklas Muennighoff, Taekyoon Choi, Cheonbok Park, Kang Min Yoo, and Stella Biderman. 2024a. Kmmlu: Measuring massive multitask language understanding in korean. ArXiv preprint, abs/2402.11548. Son, Guijin, Hanwool Lee, Suwan Kim, Huiseo Kim, Jae cheol Lee, Je Won Yeom, Jihyu Jung, Jung woo Kim, and Songseong Kim. 2024b. HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 79938007, ELRA and ICCL, Torino, Italia. Song, Inhwa, Sachin Pendse, Neha Kumar, and Munmun De Choudhury. 2024. The typing cure: Experiences with large language model chatbots for mental health support. ArXiv preprint, abs/2401.14362. Speer, Robyn, Joshua Chin, and Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA, pages 44444451, AAAI Press. Srinivasan, Krishna, Karthik Raman, Jiecao Chen, Michael Bendersky, and Marc Najork. 2021. WIT: wikipedia-based image text dataset for multimodal multilingual machine learning. In SIGIR 21: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, Virtual Event, Canada, July 11-15, 2021, pages 24432449, ACM. Stefanini, Matteo, Marcella Cornia, Lorenzo Baraldi, Massimiliano Corsini, and Rita Cucchiara. 2019. Artpedia: new visual-semantic dataset with visual and contextual sentences in the artistic domain. In Image Analysis and ProcessingICIAP 2019: 20th International Conference, Trento, Italy, September 913, 2019, Proceedings, Part II 20, pages 729740, Springer. Struppek, Lukas, Dom Hintersdorf, Felix Friedrich, Patrick Schramowski, Kristian Kersting, et al. 2023. Exploiting cultural biases via homoglyphs in text-to-image synthesis. Journal of Artificial Intelligence Research, 78:10171068. Survey, World Values. 2022. World values survey. Suwaileh, Reem, Maram Hasanain, Fatema Hubail, Wajdi Zaghouani, and Firoj Alam. 2024. ThatiAR: Subjectivity Detection in Arabic News Sentences. ArXiv preprint, abs/2406.05559. Talmor, Alon, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019a. CommonsenseQA: question answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 41494158, Association for Computational Linguistics, Minneapolis, Minnesota. Talmor, Alon, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019b. CommonsenseQA: Question Answering Challenge Targeting Commonsense Knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 41494158, Association for Computational Linguistics, Minneapolis, Minnesota. 81 Tang, Jingqun, Qi Liu, Yongjie Ye, Jinghui Lu, Shu Wei, Chunhui Lin, Wanqing Li, Mohamad Fitri Faiz Bin Mahmood, Hao Feng, Zhen Zhao, et al. 2024a. MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering. ArXiv preprint, abs/2405.11985. Tang, Xuemei, Qi Su, Jun Wang, and Zekun Deng. 2024b. CHisIEC: An information extraction corpus for Ancient Chinese history. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 31923202, ELRA and ICCL, Torino, Italia. Tao, Yan, Olga Viberg, Ryan Baker, and René Kizilcec. 2024. Cultural bias and cultural alignment of large language models. PNAS nexus, 3(9):pgae346. Thai, Katherine, Marzena Karpinska, Kalpesh Krishna, Bill Ray, Moira Inghilleri, John Wieting, and Mohit Iyyer. 2022. Exploring document-level literary machine translation with parallel paragraphs from world literature. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 98829902, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Thapliyal, Ashish V., Jordi Pont Tuset, Xi Chen, and Radu Soricut. 2022. Crossmodal-3600: massively multilingual multimodal evaluation dataset. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 715729, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Toker, Michael, Oren Mishali, Ophir Münz-Manor, Benny Kimelfeld, and Yonatan Belinkov. 2024. dataset for metaphor detection in early medieval Hebrew poetry. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers), pages 443453, Association for Computational Linguistics, St. Julians, Malta. Tonja, Atnafu Lambebo, Israel Abebe Azime, Tadesse Destaw Belay, Mesay Gemeda Yigezu, Moges Ahmed Ah Mehamed, Abinew Ali Ayele, Ebrahim Chekol Jibril, Michael Melese Woldeyohannis, Olga Kolesnikova, Philipp Slusallek, Dietrich Klakow, and Seid Muhie Yimam. 2024. EthioLLM: Multilingual large language models for Ethiopian languages with task evaluation. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 63416352, ELRA and ICCL, Torino, Italia. Tonneau, Manuel, Diyi Liu, Samuel Fraiberger, Ralph Schroeder, Scott Hale, and Paul Röttger. 2024. From languages to geographies: Towards evaluating cultural bias in hate speech datasets. In Proceedings of the 8th Workshop on Online Abuse and Harms (WOAH 2024), pages 283311, Association for Computational Linguistics, Mexico City, Mexico. Toral, Antonio and Andy Way. 2015. Machine-assisted translation of literary text: case study. Translation Spaces, 4(2):240267. Törnberg, Petter. 2024. How to Use Large-Language Models for Text Analysis. London. Toro Isaza, Paulina, Guangxuan Xu, Toye Oloko, Yufang Hou, Nanyun Peng, and Dakuo Wang. 2023. Are fairy tales fair? analyzing gender bias in temporal narrative event chains of childrens fairy tales. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 65096531, Association for Computational Linguistics, Toronto, Canada. Tran, Khanh-Tung, Barry OSullivan, and Hoang Nguyen. 2024. Uccix: Irish-excellence large language model. ArXiv preprint, abs/2405.13010. Tran, Minh, Yufeng Yin, and Mohammad Soleymani. 2023. Personalized adaptation with pre-trained speech encoders for continuous emotion recognition. In 24th Annual Conference of the International Speech Communication Association, Interspeech 2023, Dublin, Ireland, August 20-24, 2023, pages 636640, ISCA. Ullah, Faizad, Ali Faheem, Ubaid Azam, Muhammad Sohaib Ayub, Faisal Kamiran, and Asim Karim. 2024. Detecting Cybercrimes in Accordance with Pakistani Law: Dataset and Evaluation Using PLMs. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 47174728, ELRA and ICCL, Torino, Italia. Üstün, Ahmet, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel Dsouza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, et al. 2024. Aya model: An instruction finetuned open-access multilingual language model. ArXiv preprint, abs/2402.07827. Ventura, Mor, Eyal Ben-David, Anna Korhonen, and Roi Reichart. 2023. Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of Text-To-Image Models. ArXiv preprint, abs/2310.01929. 82 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Vligouridou, Eleni, Inessa Iliadou, and Ça grı Çöltekin. 2024. treebank of Asia minor Greek. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 17151721, ELRA and ICCL, Torino, Italia. Wagner, Claudia, Markus Strohmaier, Alexandra Olteanu, Emre Kıcıman, Noshir Contractor, and Tina Eliassi-Rad. 2021. Measuring algorithmically infused societies. Nature, 595(7866):197204. Walker, Mirella, Fang Jiang, Thomas Vetter, and Sabine Sczesny. 2011. Universals and cultural differences in forming personality trait judgments from faces. Social Psychological and Personality Science, 2(6):609617. Walsh, Melanie, Anna Preus, and Maria Antoniak. 2024. Sonnet or not, bot? poetry evaluation for large models and datasets. ArXiv preprint, abs/2406.18906. Wang, Angelina, Jamie Morgenstern, and John P. Dickerson. 2024. Large language models should not replace human participants because they can misportray and flatten identity groups. ArXiv preprint, abs/2402.01908. Wang, Bin, Geyu Lin, Zhengyuan Liu, Chengwei Wei, and Nancy Chen. 2024a. Craft: Extracting and tuning cultural instructions from the wild. ArXiv preprint, abs/2405.03138. Wang, Bin, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, AiTi Aw, and Nancy Chen. 2024b. SeaEval for multilingual foundation models: From cross-lingual alignment to cultural reasoning. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 370390, Association for Computational Linguistics, Mexico City, Mexico. Wang, Han, Tan Rui Yang, Usman Naseem, and Roy Ka-Wei Lee. 2024c. Multihateclip: multilingual benchmark dataset for hateful video detection on youtube and bilibili. ArXiv preprint, abs/2408.03468. Wang, Wenxuan, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jen-tse Huang, Zhaopeng Tu, and Michael Lyu. 2024d. Not all countries celebrate thanksgiving: On the cultural dominance in large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 63496384, Association for Computational Linguistics, Bangkok, Thailand. Wang, Xidong, Guiming Chen, Song Dingjie, Zhang Zhiyi, Zhihong Chen, Qingying Xiao, Junying Chen, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, and Haizhou Li. 2024e. CMB: comprehensive medical benchmark in Chinese. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 61846205, Association for Computational Linguistics, Mexico City, Mexico. Wang, Yizhong, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur Sampat, Siddhartha Mishra, Sujan Reddy A, Sumanta Patro, Tanay Dixit, and Xudong Shen. 2022. Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 50855109, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Wang, Yuhang, Yanxu Zhu, Chao Kong, Shuyu Wei, Xiaoyuan Yi, Xing Xie, and Jitao Sang. 2023. Cdeval: benchmark for measuring the cultural dimensions of large language models. ArXiv preprint, abs/2311.16421. Wang, Yuwei, Enmeng Lu, Zizhe Ruan, Yao Liang, and Yi Zeng. 2024f. Stream: social data and knowledge collective intelligence platform for training ethical ai models. AI & SOCIETY, pages 19. Wang, Yuxuan, Yijun Liu, Fei Yu, Chen Huang, Kexin Li, Zhiguo Wan, and Wanxiang Che. 2024g. Cvlue: new benchmark dataset for chinese vision-language understanding evaluation. Wang, Zhilin, Yu Ying Chiu, and Yu Cheung Chiu. 2023. Humanoid agents: Platform for simulating human-like generative agents. arXiv preprint arXiv:2310.05418. Watts, Ishaan, Varun Gumma, Aditya Yadavalli, Vivek Seshadri, Manohar Swaminathan, and Sunayana Sitaram. 2024. PARIKSHA: Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data. CoRR. 83 WAUGH, LINDA R. 1982. Marked and unmarked: choice between unequals in semiotic structure. Semiotica, 38(3-4):299318. Weber, James and Michael Urick. 2017. Examining the millennials ethical profile: Assessing demographic variations in their personal value orientations. Business and Society Review, 122(4):469506. Weber, Maurice, Carlo Siebenschuh, Rory Butler, Anton Alexandrov, Valdemar Thanner, Georgios Tsolakis, Haris Jabbar, Ian T. Foster, Bo Li, Rick Stevens, and Ce Zhang. 2023. Wordscape: pipeline to extract multilingual, visually rich documents with layout annotations from web crawl data. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Weck, Benno, Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas, and Dmitry Bogdanov. 2024. Muchomusic: Evaluating music understanding in multimodal audio-language models. ArXiv preprint, abs/2408.01337. Wei, Yuting, Yuanxing Xu, Xinru Wei, Simin Yang, Yangfu Zhu, Yuqing Li, Di Liu, and Bin Wu. 2024. Ac-eval: Evaluating ancient chinese language understanding in large language models. ArXiv preprint, abs/2403.06574. Weidinger, Laura, Maribeth Rauh, Nahema Marchal, Arianna Manzini, Lisa Anne Hendricks, Juan Mateos-Garcia, Stevie Bergman, Jackie Kay, Conor Griffin, Ben Bariach, et al. 2023. Sociotechnical safety evaluation of generative ai systems. ArXiv preprint, abs/2310.11986. White, Leslie A. 1959. The concept of culture. American Anthropologist, 61(2):227251. Wibowo, Haryo, Erland Fuadi, Made Nityasya, Radityo Eko Prasojo, and Alham Aji. 2024. COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 14041422, Association for Computational Linguistics, Mexico City, Mexico. Wright, Dustin, Arnav Arora, Nadav Borenstein, Srishti Yadav, Serge Belongie, and Isabelle Augenstein. 2024. Revealing fine-grained values and opinions in large language models. ArXiv preprint, abs/2406.19238. Wu, Minghao, Yulin Yuan, Gholamreza Haffari, and Longyue Wang. 2024. (perhaps) beyond human translation: Harnessing multi-agent collaboration for translating ultra-long literary texts. ArXiv preprint, abs/2405.11804. Wunarso, Novita Belinda and Yustinus Eko Soelistio. 2017. Towards indonesian speech-emotion automatic recognition (i-spear). In 2017 4th International Conference on New Media Studies (CONMEDIA), pages 98101, IEEE. de Wynter, Adrian, Ishaan Watts, Nektar Ege Altıntoprak, Tua Wongsangaroonsri, Minghui Zhang, Noura Farra, Lena Baur, Samantha Claudet, Pavel Gajdusek, Can Gören, Qilong Gu, Anna Kaminska, Tomasz Kaminski, Ruby Kuo, Akiko Kyuba, Jongho Lee, Kartik Mathur, Petter Merok, Ivana Milovanovic, Nani Paananen, Vesa-Matti Paananen, Anna Pavlenko, Bruno Pereira Vidal, Luciano Strika, Yueh Tsao, Davide Turcato, Oleksandr Vakhno, Judit Velcsov, Anna Vickers, Stéphanie Visser, Herdyan Widarmanto, Andrey Zaikin, and Si-Qing Chen. 2024. Rtp-lx: Can llms evaluate toxicity in multilingual scenarios? ArXiv preprint, abs/2404.14397. Würtz, Elizabeth. 2017. Intercultural Communication on Web sites: Cross-Cultural Analysis of Web sites from High-Context Cultures and Low-Context Cultures. Journal of Computer-Mediated Communication, 11(1):274299. Xie, Heng, Jizhou Cui, Yuhang Cao, Junjie Chen, Jianhua Tao, Cunhang Fan, Xuefei Liu, Zhengqi Wen, Heng Lu, Yuguang Yang, Zhao Lv, and Yongwei Li. 2023. Multimodal Cross-Lingual Features and Weight Fusion for Cross-Cultural Humor Detection. In Proceedings of the 4th on Multimodal Sentiment Analysis Challenge and Workshop: Mimicked Emotions, Humour and Personalisation, MuSe 23, pages 5157, Association for Computing Machinery, New York, NY, USA. Xiong, Haoyi, Jiang Bian, Yuchen Li, Xuhong Li, Mengnan Du, Shuaiqiang Wang, Dawei Yin, and Sumi Helal. 2024. When search engine services meet large language models: Visions and challenges. IEEE Transactions on Services Computing. Xu, Tao, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He. 2018. Attngan: Fine-grained text to image generation with attentional generative adversarial networks. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018, pages 13161324, IEEE 84 Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Computer Society. Xue, Linting, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021. mT5: massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 483498, Association for Computational Linguistics, Online. Yanaka, Hitomi, Namgi Han, Ryoma Kumon, Jie Lu, Masashi Takeshita, Ryo Sekizawa, Taisei Kato, and Hiromi Arai. 2024. Analyzing social biases in japanese large language models. ArXiv preprint, abs/2406.02050. Yang, Diyi, Caleb Ziems, William Held, Omar Shaikh, Michael S. Bernstein, and John Mitchell. 2024. Social Skill Training with Large Language Models. ArXiv preprint, abs/2404.04204. Yao, Binwei, Ming Jiang, Diyi Yang, and Junjie Hu. 2023. Benchmarking llm-based machine translation on cultural awareness. ArXiv preprint, abs/2305.14328. Yao, Jing, Xiaoyuan Yi, Yifan Gong, Xiting Wang, and Xing Xie. 2024. Value FULCRA: Mapping large language models to the multidimensional spectrum of basic human value. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 87628785, Association for Computational Linguistics, Mexico City, Mexico. Yarlott, W. Victor, Anurag Acharya, Diego Castro Estrada, Diana Gomez, and Mark Finlayson. 2024. GOLEM: GOld standard for learning and evaluation of motifs. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 78017813, ELRA and ICCL, Torino, Italia. Ye, Andre, Sebastin Santy, Jena D. Hwang, Amy X. Zhang, and Ranjay Krishna. 2023. Computer vision datasets and models exhibit cultural and linguistic diversity in perception. Ye, Fulong, Guang Liu, Xinya Wu, and Ledell Wu. 2024. Altdiffusion: multilingual text-to-image diffusion model. In Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024, Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence, IAAI 2024, Fourteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2014, February 20-27, 2024, Vancouver, Canada, pages 66486656, AAAI Press. Yin, Da, Hritik Bansal, Masoud Monajatipoor, Liunian Harold Li, and Kai-Wei Chang. 2022. GeoMLAMA: Geo-diverse commonsense probing on multilingual pre-trained language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 20392055, Association for Computational Linguistics, Abu Dhabi, United Arab Emirates. Yin, Da, Feng Gao, Govind Thattai, Michael Johnston, and Kai-Wei Chang. 2023. GIVL: improving geographical inclusivity of vision-language models with pre-training methods. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023, pages 1095110961, IEEE. Yin, Da, Liunian Harold Li, Ziniu Hu, Nanyun Peng, and Kai-Wei Chang. 2021. Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 21152129, Association for Computational Linguistics, Online and Punta Cana, Dominican Republic. Yin, Yaqi, Yue Wang, and Yang Liu. 2024. Chinese morpheme-informed evaluation of large language models. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 31653178, ELRA and ICCL, Torino, Italia. Yin, Ziqi, Hao Wang, Kaito Horio, Daisuke Kawahara, and Satoshi Sekine. 2024. Should we respect llms? cross-lingual study on the influence of prompt politeness on llm performance. ArXiv preprint, abs/2402.14531. Yoo, Kang Min, Jaegeun Han, Sookyo In, Heewon Jeon, Jisu Jeong, Jaewook Kang, Hyunwook Kim, Kyung-Min Kim, Munhyong Kim, Sungju Kim, et al. 2024. Hyperclova technical report. ArXiv preprint, abs/2404.01954. Young, Peter, Alice Lai, Micah Hodosh, and Julia Hockenmaier. 2014. From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics, 2:6778. Yu, Linhao, Yongqi Leng, Yufei Huang, Shang Wu, Haixin Liu, Xinmeng Ji, Jiahui Zhao, Jinwang Song, Tingting Cui, Xiaoqing Cheng, Liutao Liutao, and Deyi Xiong. 2024. CMoralEval: Moral Evaluation Benchmark for Chinese Large Language Models. In Findings of the Association for Computational Linguistics ACL 2024, pages 1181711837, Association for Computational Linguistics, Bangkok, Thailand and virtual meeting. Yu, Yu, Weibin Zhang, and Yun Deng. 2021. Frechet inception distance (fid) for evaluating gans. China University of Mining Technology Beijing Graduate School, 3. Yuan, Ye, Kexin Tang, Jianhao Shen, Ming Zhang, and Chenguang Wang. 2024. Measuring Social Norms of Large Language Models. In Findings of the Association for Computational Linguistics: NAACL 2024, pages 650699, Association for Computational Linguistics, Mexico City, Mexico. Yun, Youngsik and Jihie Kim. 2024. Cic: framework for culturally-aware image captioning. ArXiv preprint, abs/2402.05374. Yüksel, Arda, Abdullatif Köksal, Lütfi Kerem Senel, Anna Korhonen, and Hinrich Schütze. 2024. Turkishmmlu: Measuring massive multitask language understanding in turkish. ArXiv preprint, abs/2407.12402. Zellers, Rowan, Yonatan Bisk, Roy Schwartz, and Yejin Choi. 2018. SWAG: large-scale adversarial dataset for grounded commonsense inference. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 93104, Association for Computational Linguistics, Brussels, Belgium. Zhan, Haolan, Zhuang Li, Xiaoxi Kang, Tao Feng, Yuncheng Hua, Lizhen Qu, Yi Ying, Mei Rianto Chandra, Kelly Rosalin, Jureynolds Jureynolds, Suraj Sharma, Shilin Qu, Linhao Luo, Ingrid Zukerman, Lay-Ki Soon, Zhaleh Semnani Azad, and Reza Haf. 2024. RENOVI: benchmark towards remediating norm violations in socio-cultural conversations. In Findings of the Association for Computational Linguistics: NAACL 2024, pages 31043117, Association for Computational Linguistics, Mexico City, Mexico. Zhang, Chen, Mingxu Tao, Quzhe Huang, Jiuheng Lin, Zhibin Chen, and Yansong Feng. 2024a. MC2: Towards transparent and culturally-aware NLP for minority languages in China. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 88328850, Association for Computational Linguistics, Bangkok, Thailand. Zhang, Dong, Zhaowei Li, Pengyu Wang, Xin Zhang, Yaqian Zhou, and Xipeng Qiu. 2024b. Speechagents: Human-communication simulation with multi-modal multi-agent systems. ArXiv preprint, abs/2401.03945. Zhang, Gengyuan, Yurui Zhang, Kerui Zhang, and Volker Tresp. 2024c. Can vision-language models be good guesser? exploring vlms for times and location reasoning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 636645. Zhang, Han, Tao Xu, and Hongsheng Li. 2017. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017, pages 59085916, IEEE Computer Society. Zhang, Lili, Xi Liao, Zaijia Yang, Baihang Gao, Chunjie Wang, Qiuling Yang, and Deshun Li. 2024d. Partiality and Misconception: Investigating Cultural Representativeness in Text-to-Image Models. In Proceedings of the CHI Conference on Human Factors in Computing Systems, CHI 2024, Honolulu, HI, USA, May 11-16, 2024, pages 620:1620:25, ACM. Zhang, Miaosen, Yixuan Wei, Zhen Xing, Yifei Ma, Zuxuan Wu, Ji Li, Zheng Zhang, Qi Dai, Chong Luo, Xin Geng, et al. 2024e. Aligning vision models with human aesthetics in retrieval: Benchmarks and algorithms. ArXiv preprint, abs/2406.09397. Zhang, Wei, Wong Kam-Kwai, Biying Xu, Yiwen Ren, Yuhuai Li, Minfeng Zhu, Yingchaojie Feng, and Wei Chen. 2024f. Cultiverse: Towards cross-cultural understanding for paintings with large language model. ArXiv preprint, abs/2405.00435. Zhang, Wenjing, Siqi Xiao, Xuejiao Lei, Ning Wang, Huazheng Zhang, Meijuan An, Bikun Yang, Zhaoxiang Liu, Kai Wang, and Shiguo Lian. 2024g. Methodology of adapting large english language models for specific cultural contexts. ArXiv preprint, abs/2406.18192. Zhang, Wenxuan, Mahani Aljunied, Chang Gao, Yew Ken Chia, and Lidong Bing. 2023. M3exam: multilingual, multimodal, multilevel benchmark for examining large language models. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Zhang, Yigeng, Fabio Gonzalez, and Thamar Solorio. 2024. Interpreting themes from educational stories. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 91909203, ELRA and ICCL, Torino, Italia. Zhang, Zhu, Jianxin Ma, Chang Zhou, Rui Men, Zhikang Li, Ming Ding, Jie Tang, Jingren Zhou, and Hongxia Yang. 2021. M6-ufc: Unifying multi-modal controls for conditional image synthesis via non-autoregressive generative transformers. ArXiv preprint, abs/2105.14211. Pawar & Park et al. Survey of Cultural Awareness in Language Models: Text and Beyond Zhao, Jiaxu, Meng Fang, Zijing Shi, Yitong Li, Ling Chen, and Mykola Pechenizkiy. 2023. CHBias: Bias evaluation and mitigation of Chinese conversational language models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1353813556, Association for Computational Linguistics, Toronto, Canada. Zhao, Jinming, Tenggan Zhang, Jingwen Hu, Yuchen Liu, Qin Jin, Xinchao Wang, and Haizhou Li. 2022. M3ED: Multi-modal multi-scene multi-label emotional dialogue database. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 56995710, Association for Computational Linguistics, Dublin, Ireland. Zhao, Wenlong, Debanjan Mondal, Niket Tandon, Danica Dillion, Kurt Gray, and Yuling Gu. 2024. WorldValuesBench: Large-Scale Benchmark Dataset for Multi-Cultural Value Awareness of Language Models. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1769617706, ELRA and ICCL, Torino, Italia. Zheng, Lianmin, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Zhi-Xuan, Tan, Micah Carroll, Matija Franklin, and Hal Ashton. 2024. Beyond Preferences in AI Alignment. ArXiv preprint, abs/2408.16984. Zhou, Bo, Qianglong Chen, Tianyu Wang, Xiaomi Zhong, and Yin Zhang. 2023a. WYWEB: NLP evaluation benchmark for classical Chinese. In Findings of the Association for Computational Linguistics: ACL 2023, pages 32943319, Association for Computational Linguistics, Toronto, Canada. Zhou, Li, Antonia Karamolegkou, Wenyu Chen, and Daniel Hershcovich. 2023b. Cultural compass: Predicting transfer learning success in offensive language detection with cultural features. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1268412702, Association for Computational Linguistics, Singapore. Zhou, Li, Antonia Karamolegkou, Wenyu Chen, and Daniel Hershcovich. 2023c. Cultural Compass: Predicting Transfer Learning Success in Offensive Language Detection with Cultural Features. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1268412702, Association for Computational Linguistics, Singapore. Zhou, Li, Taelin Karidi, Nicolas Garneau, Yong Cao, Wanlong Liu, Wenyu Chen, and Daniel Hershcovich. 2024. Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge. ArXiv preprint, abs/2404.06833. Zhou, Wangchunshu, Yan Zeng, Shizhe Diao, and Xinsong Zhang. 2022. VLUE: Multi-Task Multi-Dimension Benchmark for Evaluating Vision-Language Pre-training. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2739527411, PMLR. Zhu, Shucheng, Weikang Wang, and Ying Liu. 2024. Quite good, but not enough: Nationality bias in large language models - case study of ChatGPT. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1348913502, ELRA and ICCL, Torino, Italia. Ziems, Caleb, Jane Dwivedi-Yu, Yi-Chia Wang, Alon Halevy, and Diyi Yang. 2023. NormBank: knowledge bank of situational social norms. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 77567776, Association for Computational Linguistics, Toronto, Canada. Ziems, Caleb, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi Yang. 2024. Can Large Language Models Transform Computational Social Science? Computational Linguistics, 50(1):237291. Ziems, Caleb, Jane Yu, Yi-Chia Wang, Alon Halevy, and Diyi Yang. 2022. The Moral Integrity Corpus: Benchmark for Ethical Dialogue Systems. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 37553773, Association for Computational Linguistics, Dublin, Ireland."
        }
    ],
    "affiliations": [
        "University of Copenhagen, Denmark",
        "KAIST, Republic of Korea",
        "KAIST, Republic of Korea",
        "KAIST, Republic of Korea",
        "University of Copenhagen, Denmark",
        "University of Copenhagen, Denmark",
        "KAIST, Republic of Korea",
        "KAIST, Republic of Korea",
        "KAIST, Republic of Korea",
        "University of Copenhagen, Denmark"
    ]
}