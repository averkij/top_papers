{
    "paper_title": "The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation",
    "authors": [
        "Ho Kei Cheng",
        "Alexander Schwing"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Minibatch optimal transport coupling straightens paths in unconditional flow matching. This leads to computationally less demanding inference as fewer integration steps and less complex numerical solvers can be employed when numerically solving an ordinary differential equation at test time. However, in the conditional setting, minibatch optimal transport falls short. This is because the default optimal transport mapping disregards conditions, resulting in a conditionally skewed prior distribution during training. In contrast, at test time, we have no access to the skewed prior, and instead sample from the full, unbiased prior distribution. This gap between training and testing leads to a subpar performance. To bridge this gap, we propose conditional optimal transport C^2OT that adds a conditional weighting term in the cost matrix when computing the optimal transport assignment. Experiments demonstrate that this simple fix works with both discrete and continuous conditions in 8gaussians-to-moons, CIFAR-10, ImageNet-32x32, and ImageNet-256x256. Our method performs better overall compared to the existing baselines across different function evaluation budgets. Code is available at https://hkchengrex.github.io/C2OT"
        },
        {
            "title": "Start",
            "content": "5 2 0 2 3 1 ] . [ 1 6 3 6 0 1 . 3 0 5 2 : r The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation Ho Kei Cheng Alexander Schwing University of Illinois Urbana-Champaign {hokeikc2,aschwing}@illinois.edu Unconditonal With discrete conditions With continuous conditions (target coordinates) 6.2320. 0.0720.025 2.5730.112 0.4830.059 0.0480.010 0.7320.052 8.2766. 0.0770.024 s 1 - u i d 0.1200.045 FM 0.0500.040 OT 0.0590.029 FM 0.4620.025 OT 0.0180.006 C2OT (ours) 0.0280.010 FM 2.1431.993 OT 0.0130.003 C2OT (ours) Figure 1. We visualize the flows learned by different algorithms using the 8gaussiansmoons dataset. We compare flow matching (FM), minibatch optimal transport FM (OT), and our proposed conditional optimal transport FM (C2OT) using one Euler step and an adaptive ODE solver, respectively. Below each plot, we show the 2-Wasserstein distance (lower is better; meanstd over 10 runs). For unconditional generation, OT achieves significantly straighter flows, outperforming FM. However, paradoxically, OT performs worse when conditions are introduced. This paper analyzes this degradation and finds that it occurs because optimal transport disregards conditions, leading to train-test gap. To address this, we propose simple fix (C2OT) that outperforms FM and OT in conditional generation. Abstract Minibatch optimal transport coupling straightens paths in unconditional flow matching. This leads to computationally less demanding inference as fewer integration steps and less complex numerical solvers can be employed when numerically solving an ordinary differential equation at test time. However, in the conditional setting, minibatch optimal transport falls short. This is because the default optimal transport mapping disregards conditions, resulting in conditionally skewed prior distribution during training. In contrast, at test time, we have no access to the skewed prior, and instead sample from the full, unbiased prior distribution. This gap between training and testing leads to subpar performance. To bridge this gap, we propose conditional optimal transport (C2OT) that adds conditional weighting term in the cost matrix when computing the optimal transport assignment. Experiments demonstrate that this simple fix works with both discrete and continuous conditions in 8gaussiansmoons, CIFAR-10, ImageNet-3232, and ImageNet-256256. Our method performs better overall compared to the existing baselines across different function evaluation budgets. Code is available at hkchengrex.github.io/C2OT. 1. Introduction We focus on flow-matching-based conditional generative models, i.e., generation guided by an input condition.1 Examples of such conditions include class labels, text, or video. Recently, flow matching has been applied in many areas of computer vision, including text-to-image/video [10, 35], vision-language applications [3], image restoration [32], and video-to-audio [4]. However, these methods can be slow at 1We use condition to denote an input condition, not to be confused with the condition in conditional flow matching (CFM) [27] (where the second in our acronym comes from), which refers to data sample. To avoid ambiguity, we refer to CFM simply as flow matching (FM) in this paper. 1 test-time obtaining solution requires numerically integrating the flow with an ODE solver, typically involving many steps, each requiring deep network forward pass. Naïvely reducing the number of steps degrades performance, as the underlying flow is often curved (Figure 1, leftmost column), necessitating small step size for accurate numerical integration. One way to address this issue is by straightening the flow. In the context of unconditional generation, Tong et al. [42] and Pooladian et al. [36] concurrently proposed minibatch optimal transport (OT), which deterministically couples data and samples from the prior within minibatch via optimal transport (replacing random coupling) to minimize flow path lengths and to straighten the flow. While OT improves unconditional generation, we find that it paradoxically and consistently harms conditional generation (Figure 1). This occurs because OT disregards the conditions when computing the coupling. As result, during training, OT samples from prior distribution that is skewed by the condition, as we show in Section 3.2. However, at test time, we have no access to this skewed distribution and instead sample from the full prior distribution. This mismatch creates gap between training and testing, leading to performance degradation. To bridge this gap, we propose conditional optimal transport FM (C2OT) which introduces simple yet effective condition-aware weighting term when computing the cost matrix for OT. Additionally, we propose two techniques: adaptive weight finding to simplify hyperparameter tuning and efficient oversampling of OT batches to counteract the reduced effective OT batch size introduced by the weighting term. We conduct extensive experiments on both twodimensional synthetic data and high-dimensional image data, including CIFAR-10, ImageNet-3232, and ImageNet256256. The results demonstrate that our method performs well across different condition types (discrete and continuous), datasets, network architectures (UNets and transformers), and data spaces (image space and latent space). C2OT achieves better overall performance than the existing baselines across different inference computation budgets, including with few-steps Eulers method and with an adaptive ordinary differential equation (ODE) solver [9]. 2. Related Works Flow Matching. Recently, flow matching [1, 2, 27] has become popular choice for generative modeling, in part due to its simple training objective and ability to generate highquality samples. However, at test time, flow-based methods typically require many computationally expensive forward passes through deep net to numerically integrate the flow. This is because the underlying flow is usually curved and therefore cannot be approximated well with few integration steps. Optimal Transport Coupling. To straighten the flow, in the context of unconditional generation, Tong et al. [42] and Pooladian et al. [36] concurrently proposed minibatch optimal transport (OT). While OT has proven effective in the unconditional setting, we show in Section 3.2 that it skews the prior distribution and fails in the conditional setting if used naively. Our method, C2OT, specifically addresses this failure, aiming to extend the success of OT in unconditional generation to conditional generation. Note, OT has also been used in equivariant flow matching [22, 41], which exploits domain-specific data symmetry (e.g., in molecules). In contrast, our method targets general data. Further, Hui et al. [17] find mixing of OT and independent coupling improves shape completion, which is an orthogonal contribution to this paper. Straightening Flow Paths. Other methods of straightening flow paths exist. Reflow [30] achieves this by retraining flow matching network multiple times, at the cost of additional training overhead. Variational flow matching [13] reduces flow ambiguity with latent variable and hierarchical flow matching [47] straightens flows by modeling higher-order flows. These approaches are orthogonal to our focus on prior-data coupling and, in principle, can be combined with our method. Learning the Prior Distribution. An alternative approach to improving flow is to jointly learn prior distribution with the flow matching network. However, these methods [26, 29, 39] typically rely on variational autoencoder (VAE) [16, 21] to learn the prior. This introduces yet another density In this estimation problem, which complicates training. work, we focus on improving training-free coupling plans without learning new prior. Consistency Models. Consistency models [40] have been proposed to accelerate diffusion model sampling, and can be extended to flow matching [45]. Recent advancements have improved training efficiency [12], stability [31], and quality [19]. These methods are orthogonal to our contribution, which focuses on improving prior-data coupling, and can be integrated, as demonstrated by Silvestri et al. [39] in their combination of consistency models with OT. In this paper, we focus on the base form of flow matching to avoid distractions from other formulations. 3. Method 3.1. Preliminaries Flow Matching (FM). We base our discussion on FM [27, 42] (also called rectified flow [30]) for generative modeling and refer readers to [30, 42] for details. At test-time, sample x1 is characterized by an ordinary differential equation (ODE) with an initial boundary value specified via noise x0, randomly drawn from prior distribution (e.g., the standard Figure 2. We visualize the coupling during training and the learned flow from = 0 to = 1 during testing for FM, OT, and our proposed method C2OT. The prior is defined as q(x0) = (0, 1), while the target distribution is given by q(x1) = 1 2 q(x1c = 1)) = 1 2 (2, 0.5). Note, FM results in curved flows during testing, while OT degenerates due to skewed training samples (q(x0c) = q(x0)). In contrast, our method successfully learns straight flows without degeneration. 2 q(x1c = 0) + 1 2 (2, 0.5) + 1 normal). To compute the sample x1, this ODE is commonly solved by numerically integrating from time = 0 to time = 1 learned flow/velocity field vθ, where θ denotes the set of trainable deep net parameters. For conditional generation, we additionally obtain condition c, e.g., class label from user input, which adjusts the flow. We use vθ,c to denote this conditional flow. At training time, we find the deep net parameters θ by minimizing the objective Et,(x0,x1,c)π(x0,x1,c)vθ,c(t, xt) u(xtx0, x1)2, (1) where is uniformly drawn from the interval [0, 1], and where π(x0, x1, c) denotes the joint distribution of the prior and the training data. In practice, often, independent coupling is used, i.e., the prior and the training data are sampled independently, such that π(x0, x1, c) = q(x0)q(x1, c). Further, xt = tx1 + (1 t)x0 (2) (3) defines linear interpolation between noise and data, and u(xtx0, x1) = x1 x0 (4) denotes its corresponding flow velocity at xt. Note, simply dropping the condition leads to the unconditional flow matching formulation. Although rectified flow matching is trained with straight paths, the learned flow is often curved (Figure 1, bottomleft) since there are many possible paths induced by the independently sampled couplings x0, x1 through any xt at time [36]. Curved paths require more numerical integration and network evaluation steps, which is not ideal. Optimal Transport (OT) Coupling. To address this issue for unconditional generation, Tong et al. [42] and Pooladian et al. [36] concurrently proposed to use minibatch optimal transport to deterministically couple the sampled prior and sampled batch of the data. This minimizes flow path lengths and straightens the flow. Concretely, given minibatch of e-dimensional samples, an OT coupling seeks permutation matrix such that the squared Euclidean distance is minimized, i.e., min X0 X12 2. (5) Here, X0, X1 Rbe are matrices containing minibatch of samples from the prior and the data. Instead of an independent coupling, in the unconditional setting we then optimize variant of Equation (1) using the coupled tuple (X0, X1). Note that this algorithm corresponds to sampling tuples (x0, x1) from joint distribution πot(x0, x1). Importantly, for unconditional generation, i.e., when using the joint distribution πot(x0, x1), the marginals remain unchanged from independent coupling (see [42]): (cid:90) (cid:90) πot(x0, x1)q(x0) dx0 = q(x1), and πot(x0, x1)q(x1) dx1 = q(x0). (6) Hence, during test-time, we can sample from the prior q(x0) and integrate the flow vθ to simulate data from the data distribution q(x1). Unfortunately, as shown in the next section, this does not hold for conditional generation. Said differently, naively extending the unconditional joint distribution πot(x0, x1) to conditional joint distribution πot(x0, x1, c) by using the coupled tuple (X0, X1, C), where Rbh is batch of h-dimensional conditions, does not maintain marginals and leads to gap between training time and test time. We discuss this next. 3 3.2. OT Coupling Skews The Prior Intuition. Consider the one-dimensional example illustrated in Figure 2: the prior distribution q(x0) follows Gaussian distribution, and the target distribution q(x1) consists of mixture of two Gaussians translated left and right, with the translation direction indicated by binary condition c. When training with πot(x0, x1, c) that represents the coupled tuple (X0, X1, C), samples from the prior and the sampled conditions become correlated through the OT coupling samples from the left half of the prior distribution are always associated with = 0, while those from the right half always correspond to = 1. As result, the model overfits on data pairs (x0, c) where either (x0 < 0, = 0) or (x0 > 0, = 1). However, during testing, this skewed distribution is no longer accessible, and instead, x0 and are sampled independently. Consequently, the model encounters previously unseen data pairs, i.e., (x0 > 0, = 0) and (x0 < 0, = 1) leading to failure. similar phenomenon can be observed in the two-dimensional example illustrated in Figure 1. Skewed Prior. Formally, imagine that we consider the most general OT coupling joint distribution πot(x0, x1, c) at training time. At test time, the user wants to specify condition c1 to obtain samples from the conditional distribution q(x1c = c1). What is the prior distribution that we need to sample from such that we arrive at the correct conditional distribution q(x1c = c1)? To compute this, imagine, we are given an arbitrary condition c1, i.e., we look at the induced distribution πot(x0, x1, cc = c1). Marginalizing this induced distribution over x1 yields (cid:90) (cid:90) πot(x0, x1, cc = c1) dx1 = πot(x0, x1c = c1) dx1 = q(x0c = c1), (7) which implies that the prior required to arrive at the conditional distribution q(x1c = c1) is q(x0c = c1) distribution that we cannot access at test time. In general, the prior that we need to sample from, given condition c, is skewed from q(x0) to q(x0c) which is inaccessible at test time. As result, accurately capturing q(x1c) at test time becomes infeasible unless q(x0) and q(c) are independent, i.e., if q(x0c) = q(x0). However, this condition is generally not satisfied by the most general OT coupling for instance, in Figure 2, clearly q(x0c) = q(x0). To address this issue, we propose method C2OT to unskew the prior. We discuss this in the next section. ensures that at test time, we can sample from the full prior q(x0), irrespective of the condition c. Importantly, at the same time, we also aim to preserve the straight flow paths provided by OT. Conceptually, we construct prior distribution independently for each condition, i.e., q(x0c1) = q(x0c2) = q(x0), c1, c2. This can be achieved by sampling from the prior and computing OT independently for each condition, as shown in Figure 2 (right). Formally, we construct the joint distribution as πc2ot(x0, x1, c) := q(x0)q(c)πot(x1x0, c). (8) Here, the prior q(x0) and the condition q(c) are sampled independently, while the data x1 is conditioned on x0 (via OT) and (via the dataset construction). Different from independent coupling in Equation (2), x1 and x0 are associated through OT and therefore lead to straighter flow paths. Also different from the most general OT coupling πot(x0, x1, c), we explicitly enforce the independence between x0 and c. To see that this joint distribution provides an unskewed prior, imagine we are given an arbitrary input condition c1, marginalizing over x1 yields (cid:90) (cid:90) = q(x0)q(cc = c1)πot(x1x0, = c1) dx q(x0)πot(x1x0, = c1) dx1 = q(x0). (9) This implies that, at test time, we can sample from the entire prior q(x0), regardless of the condition c, to arrive at the desired data distribution q(x1c). During training, in practice, we sample from πc2ot by modifying the optimal transport cost function in Equation (5). This process is exact for discrete conditions (Section 3.3.2) and approximate for continuous conditions (Section 3.3.3). Specifically, given minibatch of e-dimensional samples and minibatch of h-dimensional conditions Rbh, C2OT seeks permutation matrix that minimizes the following cost function: min X0 X12 2 + (cid:88) i=1 (Ci, [P C]i), (10) where is symmetric, non-negative cost function satisfying the property (c, c) = 0 c. The key differences between independent coupling, OT coupling, and C2OT coupling are highlighted in Algorithms 1 to 3. In the following two sections, we discuss our choice of for both discrete and continuous conditions. 3.3. Conditional Optimal Transport FM 3.3.2. Discrete Conditions 3.3.1. Formulation We propose conditional optimal transport FM (C2OT) to unskew the prior q(x0c) such that q(x0c) = q(x0). This For discrete conditions, we assume the conditions correspond to class labels from finite, discrete set, i.e., {0, 1, . . . , 1}. For example, in Figure 2, the labels 0 and 1 represent the left and right groups in the target distribution, 4 Algorithm 1 Independent Coupling 1: function INDEPENDENT(X1, C) 2: 3: X0 Sample from prior Algorithm 2 OT Coupling 1: function OT(X1, C) X0 2: Cost pairwise_dist(X0, X1) 3: Sample from prior Algorithm 3 C2OT Coupling (Ours) 1: function C2OT(X1, C) 2: 3: X0 Sample from prior Cost pairwise_dist(X0, X1) + pairwise_dist(C, C) 4: 5: return X0, X1, 4: 5: i, Hungarian_matching(Cost) return X0[i], X1[j], C[j] 4: 5: i, Hungarian_matching(Cost) return X0[i], X1[j], C[j] respectively. We define = fd such that no transport is allowed to modify the conditions (i.e., = C). This is achieved via fd(c1, c2) = (cid:40) , c1 = c2, 0, otherwise. (11) As result, the unordered set of prior samples for any given condition remains unchanged: {X0ici = c} iid q(x0). This formulation samples exactly from our ideal (Equation (8)), as OT is computed independently within each class, and the data sample from each class is exposed to the full prior without skew. This effect is illustrated in Figure 1 (middle) and Figure 2 (right). Note that, as expected, the results differ from FMs curved flow paths and OTs inability to properly capture the target distribution. It is important to note that enforcing = does not necessarily imply = since we can still swap row and in as long as ci = cj. Setting = would correspond to degeneration back to independent coupling in Equation (2) and forfeit the benefits of straightened flow provided by OT. Unfortunately, using fd with continuous conditions leads to exactly this degeneration, since, in general, no ci = cj unless = j. Hence, in the next section, we devise relaxed cost for handling continuous conditions. 3.3.3. Continuous Conditions For continuous conditions, the condition is typically feature embedding, e.g., computed from text prompt. Directly applying fd in Equation (11) leads to degeneration back to independent coupling as discussed earlier. To avoid this, we propose relaxed penalty function fc based on the cosine distance: (cid:18) fc(c1, c2) = 1 (cid:19) c1 c2 c1c2 = cdist(c1, c2). (12) Here, > 0 is scaling hyperparameter. Note, when = 0, this formulation degenerates to regular OT; when , this formulation approaches Equation (11), i.e., independent coupling if no two conditions are equal. The right section of Figure 1 illustrates an example where the x-coordinate of the target data point serves as the condition. Notably, C2OT preserves straight flow paths without exhibiting OTs apparent degradation. Finding w. The optimal is highly dependent on the data distribution and the magnitude of features. To alleviate the need for tuning the hyperparameter w, we propose to find adaptively for each minibatch. For this, we develop ratio r(w) which measures the proportion of samples that are considered potential optimal transport candidates, i.e., r(w) = 1 B2 (cid:88) i,j 1 (cid:0)X0i X1j2 2 + cdist(ci, cj) X0i X1i2 2 (cid:1) , (13) where 1() is an indicator function that evaluates to one if the condition is satisfied and to zero otherwise. Then, we introduce hyperparameter rtar as the target ratio and find such that r(w) rtar. Note that setting rtar is invariant to the scaling of distances between x0 and x1. Namely, if X0i X1j2 2 is scaled by s, can also be scaled by to preserve the same rtar. This invariance is particularly useful when transitioning to new dataset, such as changing image resolutions in image generation tasks. In our implementation, we search for in two steps: first with exponential search to establish the upper/lower bounds, then with binary search to locate precise value. The final is used as the initial value in the subsequent minibatch. In practice, we observe differs very little between minibatches (<1%) and the search converges quickly within 10 iterations with negligible overhead. Next, we introduce oversampling, simple technique to obtain more accurate OT couplings. 3.3.4. Oversampling OT Batches OT vs. Deep Net Batch Sizes. Typically, the OT batch size used to compute optimal transport is set equal to the deep net batch size bn used to compute forward/backward passes of the deep net [36, 42]. While the OT batch size controls the dynamics of prior-to-data assignments, the deep net batch size affects gradient variances, training efficiency, and memory usage. There is no reason why setting them equal should be optimal. Particularly, with our proposed C2OT, the effective OT batch size is reduced since we restrict transport between samples with divergent conditions, which calls for an increased OT batch size b. At the same time, keeping the deep net batch size bn unchanged prevents unwarranted side effects in other aspects of training. Reduced Effective OT Batch Size. In the case of discrete conditions, OT is effectively performed within 5 Table 1. Results on the 8gaussiansmoons dataset with different training coupling methods and different conditioning. Note that our method C2OT does not apply in the unconditional setting. Method Unconditional Euler-1 (W 2 2 ) Adaptive (W 2 2 ) NFE FM OT Binary conditions 6.2320.186 0.0720.025 2.5730.112 FM 0.4830.059 OT C2OT (ours) 0.0480.010 Continuous conditions 0.1200.045 0.0500.040 93.221.81 36.082. 0.0590.029 0.4620.025 0.0180.006 91.102.77 32.890.95 58.881.48 0.7320.052 FM 8.2766.510 OT C2OT (ours) 0.0770.024 0.0280.010 2.1431.993 0.0130.003 93.861.76 42.072.59 89.871.53 {X0i, X1ici = c} for each condition c. With classes, the expected effective OT batch size is reduced to E({ici = c}) = b/k. Empirically, we find that using much larger OT batch size than the network batch size bn is helpful. This observation motivates oversampling. Efficiency. natural concern with increasing is the computational overhead, since we compute optimal transport with Hungarian matching [24] which has time complexity of O(b3). However, Since each OT batch can be used across (b/bn) forward/backward passes, the amortized cost per minibatch reduces to O(b2bn). We offload OT computation from the main process to the data loading processes, enabling data preparation on the CPU in parallel with forward/backward passes on the GPU. With modest choice of 8 data workers per GPU, we observe no wall-clock overhead for OT batch sizes up to 6,400 when training on CIFAR-10 and ImageNet, as data preparation is completed faster than the GPU can process batches. 4. Experiments We experimentally verify our proposed method C2OT in two sections: first on the two-dimensional synthetic dataset 8gaussiansmoons, and then on high-dimensional image data, including CIFAR-10 [23] and ImageNet-1K [7]. For ImageNet-1K, we conduct experiments on both 3232 images in image space and 256256 images in latent space. Implementation details are provided in the appendix. 4.1. Two-Dimensional Data The two-dimensional 8gaussiansmoons dataset maps mixture of eight Gaussian distributions to two interleav6 ing half-circles, as visualized in Figure 1. We consider three conditioning scenarios: (a) unconditional; (b) binary class conditions, where each class corresponds to one of the half-circles; and (c) continuous conditions, where the x-coordinate of the desired target point is given as the condition. For (b), we apply our setup for discrete conditions (Section 3.3.2); for (c), we apply our setup for continuous conditions (Section 3.3.3) with rtar = 0.01. Metrics. We report the 2-Wasserstein distance (W 2 2 ) (following [42]) between 10K generated data points and 10K samples from the ground-truth moons distribution. We experiment with single-step Eulers method (Euler-1) and the adaptive DormandPrince method [9] (dopri5, referred to as adaptive) for numerical integration. Additionally, we report the number of function evaluations (NFE) in the adaptive method, which is the number of forward passes through the neural network. All experiments are averaged over ten training runs with ten different random seeds, and we report meanstd. Results. The results are summarized in Table 1 and visualized in Figure 1. In the unconditional setting, OT produces straighter flows, leading to better distribution matching with fewer NFEs, and our method does not apply. However, in the conditional setting, OT degrades and performs worse than regular FM in the adaptive setting due to the aforementioned train-test gap in OT coupling. Our method, C2OT, effectively models the target distribution with both Euler-1 and the adaptive method, improving upon the baselines. 4.2. High-Dimensional Image Data We conduct experiments on CIFAR-10 [23] (image space, class-conditioned), ImageNet-3232 [7] (image space, caption-conditioned), and ImageNet-256256 [7] (latent space, caption-conditioned). For ImageNet, we use the captions provided by [25] and encode text features using CLIP [37]-like DFN [11] text encoder as input conditions. Our results are summarized in Table 2. More implementation details can be found in the appendix. Metrics. We report Fréchet inception distance (FID) [15] and the number of function evaluations (NFE) in the adaptive solver for all three datasets. To assess how well the generations adhere to the input conditions, we additionally compute condition adherence metrics. For CIFAR-10, we run pretrained classifier [5] on the generated images to obtain logits and report the average cross entropy (CE) with the input class label. For ImageNet, we compute CLIP features [37] using SigLIP-2 [43] from the generated images and the input captions respectively, and report the average cosine similarities (CLIP). CIFAR-10. We base our UNet architecture on Tong et al. [42], with details provided in the appendix. The CIFAR-10 training set contains 50,000 3232 color images across 10 Table 2. Results of different training algorithms on image generation tasks. We bold the best-performing entry and underline the second-best. Our proposed method, C2OT, achieves the best overall performance better than FM with few sampling steps and better than OT with more sampling steps. In cases where C2OT performs second, our performance is often comparable to the best entry. Additionally, C2OT has the most stable performance, with the smallest deviations across runs in most entries. Variations in CLIP scores are minimal. CIFAR-10 Class-Conditioned Generation Method Euler-2 Euler-5 Euler-10 EulerEuler-50 Euler-100 Adaptive NFE FM OT C2OT (ours) 105.4811.619 21.9680.400 10.4790.237 5.6400.117 4.1280.069 3.4290.054 2.9220.039 124.02.5 64.4170.434 18.1940.409 10.7780.270 6.8210.186 5.3680.113 4.6710.066 4.1440.018 125.70.4 9.7620.136 5.6440.081 4.1520.061 3.4470.049 2.9040.035 127.70.7 64.6940.379 17.5650. FM OT C2OT (ours) 3.3430.022 2.5290.010 2.2640.022 0.5460.020 0.6240.012 0.4750.009 0.3230.007 0.2720.004 0.2670.002 0.2690.003 0.2760.004 124.02.5 0.4260.005 0.3690.004 0.3630.004 0.3640.005 0.3720.005 125.70.4 0.3220.004 0.2760.005 0.2710.003 0.2720.003 0.2790.004 127.70.7 ImageNet 3232 Caption-Conditioned Generation 113.2500.793 23.0150.123 11.1410.051 7.1650.087 6.1420.085 5.6730.074 5.3580.059 146.93.5 FM 81.3170.369 20.7630.154 11.3600.089 7.8540.077 6.8990.079 6.4690.071 6.2200.065 137.70.2 OT C2OT (ours) 102.3800.279 21.9650.035 10.8970.033 7.0690.027 6.0840.016 5.6380.018 5.3500.017 134.21.4 FM OT C2OT (ours) 0.0670.000 0.0670.000 0.0680.000 0.0760.000 0.0710.000 0.0750.000 0.0740.000 0.0710.000 0.0710.000 0.0700.000 0.0690.000 146.93.5 0.0700.000 0.0680.000 0.0680.000 0.0670.000 0.0670.000 137.70.2 0.0730.000 0.0710.000 0.0700.000 0.0700.000 0.0690.000 134.21.4 ImageNet 256256 Caption-Conditioned Generation in Latent Space 203.3550.075 31.7400.100 10.0880.020 3.8980.016 5.2250.011 3.4740.008 3.4840.014 133.510.9 FM 190.8930.213 46.5100.140 18.2210.078 7.4770.045 9.3330.046 7.6300.020 7.1810.022 115.915.3 OT C2OT (ours) 201.0100.067 30.5780.124 10.0320.007 3.7020.017 5.0750.013 3.3350.010 3.2900.012 126.712.7 FM OT C2OT (ours) 0.0270.000 0.0310.000 0.0290.000 0.1200.000 0.1010.000 0.1200.000 0.1330.000 0.1380.000 0.1370.000 0.1390.000 0.1390.000 133.510.9 0.1140.000 0.1180.000 0.1170.000 0.1180.000 0.1180.000 115.915.3 0.1330.000 0.1380.000 0.1370.000 0.1390.000 0.1380.000 126.712.7 object classes. During testing, we generate 50,000 images evenly distributed among classes and assess FID against the training set following [42]. Each model is trained five times with different random seeds and the results are reported as meanstd. We use an OT batch size of 640 and ratio rtar of 0.01. Compared to FM, our method achieves better performance (FID and CE) in few-steps settings and comparable performance in many-steps settings. Compared to OT, our method significantly outperforms in the manystep setting. Although OT achieves slightly better FID in Euler-2, it performs worse in CE, indicating that it fails to follow the condition. ImageNet 3232. We base our UNet architecture on Pooladian et al. [36], with details provided in the appendix. We train and evaluate on the face-blurred version [44] of ImageNet, following[36]. In contrast to prior works that assess FID against the training set, we assess FID against the validation set (49,997 images) to mitigate overfitting, as the fine-grained nature of captions may lead to overfitting on the training set. Each model is trained three times with different random seeds and the results are reported as meanstd. Compared to CIFAR-10, there are much more variations in this dataset (e.g., 1000 classes vs. 10 classes in CIFAR-10). Thus, we adopt larger OT batch size of 6400 while keeping the same target ratio rtar 0.01 as before. Similar to our findings in CIFAR-10, our method performs better or is comparable to FM; in few-steps settings, OT achieves better FID but worse condition following (CLIP). Our method strikes the best overall balance. ImageNet 256256 in Latent Space. Here, we explore latent flow matching models [38]. During training, the flow matching model learns to generate data in the latent space, which is encoded from images. At test-time, the generated latents are decoded into images using pretrained decoder. We base our experiment on recent transformer-based model, LightningDiT [46], demonstrating that our method is effective across different network architectures and data spaces. We use the officially provided 64 epochs configuration for all experiments (due to computational constraints), which is not directly comparable to methods that are trained with 800 epochs. We follow the same evaluation protocol as ImageNet-3232, and adopt the same OT batch size of 6400 and the target ratio rtar of 0.01. Each model is evaluated three times with different random seeds and the results are reported as meanstd. Again, C2OT has the best overall performance compared to both FM and OT. We visualize the generated images in Figure 3 and provide additional uncurated samples in the appendix. 7 2 - u 70 65 60 55 50 3. 2.97 2.94 2.91 2.88 2.85 e p A OT (Euler-2) FM (adaptive) Ours, Euler-2 Ours, adaptive 128 640 1, 2,560 6,400 OT batch size Figure 4. Changes in FID with respect to varying OT batch sizes b. We plot meanstd over three runs and represent std with shaded region. OT (adaptive) and FM (Euler-2) perform worse than all other results in this plot, hence results are not shown (full plot in the appendix). 2 - u 110 105 100 95 90 80 Ours, Euler-2 Ours, adaptive FM (Euler-2) FM (adaptive) OT (Euler-2) 0.0005 0.001 0. 0.01 0.005 Target ratio rtar 0.02 0.05 0.1 5. 5.77 5.64 5.51 5.38 5.25 e p A Figure 5. Changes in FID with respect to varying target ratio rtar. We plot meanstd over three runs and represent std with shaded region. OT (adaptive) performs worse than all other results in this plot, hence results are not shown (full plot in the appendix). 0 and the method approaches OT (Section 3.3.3). Our findings are similar to those in Section 4.3.1: as we approach true OT, whether by increasing OT batch size or increasing rtar), FID improves in the few-step setting and worsens in the adaptive setting. 5. Conclusion Figure 3. Visual comparisons of 256256 images generated by the baselines and our approach with different amounts of sampling steps. Our approach converges faster and produces cleaner outputs. The input caption is small dog sitting on carpet. 4.3. Ablation Studies 4.3.1. Varying OT Batch Size Here, we analyze the effect of varying the OT batch size b. We conduct these experiments on the CIFAR-10 dataset, training each model three times with different random seeds for every choice of b. We plot the results in Figure 4. Increasing the OT batch size clearly improves FID in the fewsampling-steps setting (Euler-2). This is intuitive, because larger OT batch size enables the coupling to approach the true OT results, i.e., dataset-level optimal transport. In turn, this leads to straighter paths. However, in the adaptive setting, increasing the OT batch size slightly worsens FID, though the effect is much less significant (the range of the blue y-axis is much smaller than the range of the red y-axis). We think this occurs because more accurate OT coupling reduces variations in the training data (similar to having less data augmentations) which harms performance as the benefit of straighter flows diminishes in the adaptive setting. This observation aligns with the findings of Pooladian et al. [36]: computing OT coupling across GPUs (i.e., having larger effective OT batch size) slightly harms results. In contrast to Pooladian et al. [36], though, we seek to counteract the reduced effective OT batch size induced by conditional optimal transport (as discussed in Section 3.3.4), and we do find reasonably large (640 for CIFAR, 6400 for ImageNet) OT batch sizes useful while not adding wall-clock overhead. 4.3.2. Varying Target Ratio rtar Here, we analyze the effects of varying the target ratio rtar, as defined in Equation (13). We conduct these experiments on the ImageNet-3232 dataset, training each model three times with different random seeds for every choice of rtar. We plot the results in Figure 5. Recall that when 0, and the method approaches FM; when 0.52, 2There is 0.5 chance that the distance between random prior-data pair is closer to that of another random prior-data pair. We first investigate and formalize the struggle of minibatch optimal transport in conditional generation. Based on the findings, we propose C2OT, simple yet effective addition that corrects the degeneration of OT while maintaining straight integration paths. Extensive experiments ranging from simple two-dimensional synthetic data with MLPs to high-dimension 256256 image generation in latent space with transformers verify the effectiveness of our method. We believe that this simple technique will be broadly useful in future flow-based conditional generative tasks. 8 Acknowledgment. This work is supported in part by NSF grants 2008387, 2045586, 2106825, NIFA award 202067021-32799, and OAC 2320345. References [1] Michael Albergo and Eric Vanden-Eijnden. Building normalizing flows with stochastic interpolants. In Proc. ICLR, 2023. 2 [2] Michael Albergo, Nicholas Boffi, and Eric Vanden-Eijnden. Stochastic interpolants: unifying framework for flows and diffusions. arXiv preprint arXiv:2303.08797, 2023. 2 [3] Kevin Black, Noah Brown, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Lachy Groom, Karol Hausman, Brian Ichter, et al. pi0: vision-languageaction flow model for general robot control. arXiv, 2024. [4] Ho Kei Cheng, Masato Ishii, Akio Hayakawa, Takashi Shibuya, Alexander Schwing, and Yuki Mitsufuji. Taming multimodal joint training for high-quality video-to-audio synthesis. CVPR, 2025. 1 [5] chenyaofo. Pytorch cifar models. https://github. com/chenyaofo/pytorch-cifar-models, 2023. 6 [6] Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter. downsampled variant of imagenet as an alternative to the cifar datasets. arXiv, 2017. 14 [7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: large-scale hierarchical image database. In CVPR, 2009. 6, 14 [8] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. NeurIPS, 2021. 14 [9] John Dormand and Peter Prince. family of embedded runge-kutta formulae. Journal of computational and applied mathematics, 1980. 2, [10] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for high-resolution image synthesis. In ICML, 2024. 1 [11] Alex Fang, Albin Madappally Jose, Amit Jain, Ludwig Schmidt, Alexander Toshev, and Vaishaal Shankar. Data filtering networks. ICLR, 2024. 6, 14 [12] Zhengyang Geng, Ashwini Pokle, William Luo, Justin Lin, and Zico Kolter. Consistency models made easy. ICLR, 2025. 2 [13] Pengsheng Guo and Alexander Schwing. Variational rectified flow matching. arXiv, 2025. 2 [14] Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (gelus). arXiv, 2016. 12 [15] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by two time-scale update rule converge to local nash equilibrium. NeurIPS, 2017. 6 [16] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with constrained variational framework. In ICLR, 2017. 2 [17] Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, and Arash Vahdat. Not-so-optimal transport flows for 3d point cloud generation. arXiv, 2025. 2 [18] Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon, Nicholas Carlini, Rohan Taori, Achal Dave, Vaishaal Shankar, Hongseok Namkoong, John Miller, Hannaneh Hajishirzi, Ali Farhadi, and Ludwig Schmidt. Openclip, 2021. If you use this software, please cite it as below. 14 [19] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Murata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki Mitsufuji, and Stefano Ermon. Consistency trajectory models: Learning probability flow ode trajectory of diffusion. ICLR, 2024. [20] Diederik Kingma and Jimmy Ba. Adam: method for stochastic optimization. ICLR, 2015. 12, 13 [21] Diederik Kingma, Max Welling, et al. Auto-encoding variational bayes. In ICLR, 2014. 2 [22] Leon Klein, Andreas Krämer, and Frank Noé. Equivariant flow matching. NeurIPS, 36, 2023. [23] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images, 2009. 6 [24] Harold W. Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly, 1955. 6 [25] Visual Layer. https : //huggingface.co/datasets/visuallayer/ imagenet-1k-vl-enriched, 2024. 6, 14 Imagenet-1k-vl-enriched. [26] Sangyun Lee, Beomsu Kim, and Jong Chul Ye. Minimizing trajectory curvature of ode-based generative models. In ICML, 2023. 2 [27] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative modeling. ICLR, 2023. 1, 2, 13 [28] Yaron Lipman, Marton Havasi, Peter Holderrieth, Neta Shaul, Matt Le, Brian Karrer, Ricky TQ Chen, David Lopez-Paz, Heli Ben-Hamu, and Itai Gat. Flow matching guide and code. arXiv, 2024. 14 [29] Qihao Liu, Xi Yin, Alan Yuille, Andrew Brown, and Mannat Singh. Flowing from words to pixels: framework for crossmodality evolution. arXiv preprint arXiv:2412.15213, 2024. 2 [30] Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. ICLR, 2023. 2 [31] Cheng Lu and Yang Song. Simplifying, stabilizing and scaling continuous-time consistency models. ICLR, 2024. 2 [32] Ségolène Martin, Anne Gagneux, Paul Hagemann, and Gabriele Steidl. Pnp-flow: Plug-and-play image restoration with flow matching. ICLR, 2025. [33] Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu. On aliased resizing and surprising subtleties in gan evaluation. In CVPR, 2022. 14 [34] Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama, Jinkyoo Park, and Stefano Ermon. Torchdyn: Implicit models and neural numerical methods in pytorch. Physical Reasoning and Inductive Biases for the Real World at NeurIPS, 2021. 12 9 and dense features. arXiv preprint arXiv:2502.14786, 2025. 6, 14 [44] Kaiyu Yang, Jacqueline Yau, Li Fei-Fei, Jia Deng, and Olga Russakovsky. study of face obfuscation in imagenet. In ICML, 2022. 7, 14 [45] Ling Yang, Zixiang Zhang, Zhilong Zhang, Xingchao Liu, Minkai Xu, Wentao Zhang, Chenlin Meng, Stefano Ermon, and Bin Cui. Consistency flow matching: Defining straight flows with velocity consistency. arXiv, 2024. [46] Jingfeng Yao and Xinggang Wang. Reconstruction vs. generation: Taming optimization dilemma in latent diffusion models. CVPR, 2025. 7, 14 [47] Yichi Zhang, Yici Yan, Alex Schwing, and Zhizhen Zhao. Towards hierarchical rectified flow. ICLR, 2025. 2 [35] Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, Apoorv Vyas, Bowen Shi, ChihYao Ma, Ching-Yao Chuang, David Yan, Dhruv Choudhary, Dingkang Wang, Geet Sethi, Guan Pang, Haoyu Ma, Ishan Misra, Ji Hou, Jialiang Wang, Kiran Jagadeesh, Kunpeng Li, Luxin Zhang, Mannat Singh, Mary Williamson, Matt Le, Matthew Yu, Mitesh Kumar Singh, Peizhao Zhang, Peter Vajda, Quentin Duval, Rohit Girdhar, Roshan Sumbaly, Sai Saketh Rambhatla, Sam Tsai, Samaneh Azadi, Samyak Datta, Sanyuan Chen, Sean Bell, Sharadh Ramaswamy, Shelly Sheynin, Siddharth Bhattacharya, Simran Motwani, Tao Xu, Tianhe Li, Tingbo Hou, Wei-Ning Hsu, Xi Yin, Xiaoliang Dai, Yaniv Taigman, Yaqiao Luo, Yen-Cheng Liu, Yi-Chiao Wu, Yue Zhao, Yuval Kirstain, Zecheng He, Zijian He, Albert Pumarola, Ali Thabet, Artsiom Sanakoyeu, Arun Mallya, Baishan Guo, Boris Araya, Breena Kerr, Carleigh Wood, Ce Liu, Cen Peng, Dimitry Vengertsev, Edgar Schonfeld, Elliot Blanchard, Felix Juefei-Xu, Fraylie Nord, Jeff Liang, John Hoffman, Jonas Kohler, Kaolin Fire, Karthik Sivakumar, Lawrence Chen, Licheng Yu, Luya Gao, Markos Georgopoulos, Rashel Moritz, Sara K. Sampson, Shikai Li, Simone Parmeggiani, Steve Fine, Tara Fowler, Vladan Petrovic, and Yuming Du. Movie gen: cast of media foundation models. arXiv, 2024. 1 [36] Aram-Alexandre Pooladian, Heli Ben-Hamu, Carles Domingo-Enrich, Brandon Amos, Yaron Lipman, and Ricky TQ Chen. Multisample flow matching: Straightening flows with minibatch couplings. ICML, 2023. 2, 3, 5, 7, 8, 13, 14 [37] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, 2021. [38] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022. 7 [39] Gianluigi Silvestri, Luca Ambrogioni, Chieh-Hsin Lai, Yuhta Takida, and Yuki Mitsufuji. Training consistency models with variational noise coupling. arXiv preprint arXiv:2502.18197, 2025. 2 [40] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. In ICML, 2023. 2 [41] Yuxuan Song, Jingjing Gong, Minkai Xu, Ziyao Cao, Yanyan Lan, Stefano Ermon, Hao Zhou, and Wei-Ying Ma. Equivariant flow matching with hybrid probability transport for 3d molecule generation. NeurIPS, 36, 2023. 2 [42] Alexander Tong, Kilian Fatras, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang, Jarrid Rector-Brooks, Guy Wolf, and Yoshua Bengio. Improving and generalizing flow-based generative models with minibatch optimal transport. TMLR, 2024. 2, 3, 5, 6, 7, 12, 13, [43] Michael Tschannen, Alexey Gritsenko, Xiao Wang, Muhammad Ferjad Naeem, Ibrahim Alabdulmohsin, Nikhil Parthasarathy, Talfan Evans, Lucas Beyer, Ye Xia, Basil Mustafa, et al. Siglip 2: Multilingual vision-language encoders with improved semantic understanding, localization, 10 Table of Contents 1 Introduction 2 Related Works 3 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.1 Preliminaries . 3.2 OT Coupling Skews The Prior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3 Conditional Optimal Transport FM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.1 3.3.2 Discrete Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.3 Continuous Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.4 Oversampling OT Batches . . . . . . . . . . . . . . . . . . . . . . . . . . . . Formulation . . . . . 4 Experiments . . 4.1 Two-Dimensional Data . 4.2 High-Dimensional Image Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Ablation Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3.1 Varying OT Batch Size . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3.2 Varying Target Ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Conclusion Extended Plots Data Coupling in 8 Gaussiansmoons Implementation Details C.1 Two-Dimensional Data . . C.2 CIFAR-10 . . . C.3 ImageNet-32 . . C.4 ImageNet-256 . . . . . . . . . . . . . . Additional Generated Images . . . D.1 CIFAR-10 . . D.2 ImageNet-32 . D.3 ImageNet-256 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DeltaAI Acknowledgment 11 1 2 2 2 4 4 4 4 5 6 6 6 8 8 8 8 . . . . . . . . . . . . 12 12 . 12 . 13 . 14 . 14 14 . 15 . 16 . 17 19 A. Extended Plots Figures A1 and A2 extend Figures 5 and 6 of the main paper to include all data points. 2 - u 110 105 100 95 90 80 75 70 65 60 50 OT (adaptive) FM (Euler-2) Ours, Euler-2 Ours, adaptive OT (Euler-2) 640 1,280 2,560 6,400 FM (adaptive) OT batch size 4.85 4.68 4.52 4.35 4.18 4. 3.85 3.68 3.52 3.35 3.18 3. 2.85 e p I 2 - u 115 110 100 95 90 85 80 FM (Euler-2) OT (adaptive) Ours, Euler-2 Ours, adaptive FM (adaptive) OT (Euler-2) 0.0005 0.001 0. 0.01 0.005 Target ratio rtar 0.02 0.05 0.1 6. 6.16 6.01 5.87 5.73 5.58 5. 5.29 5.15 e p Figure A1. Changes in FID with respect to varying OT batch sizes b. We plot meanstd over three runs and represent std with shaded region. Figure A2. Changes in FID with respect to varying target ratio rtar. We plot meanstd over three runs and represent std with shaded region. B. Data Coupling in 8 Gaussiansmoons Figure A3 extends Figure 1 with an additional row that shows coupling during training. Clearly, OT samples form biased distribution at training time in conditional generation as discussed. Since we cannot sample from this biased distribution at test-time, we obtain gap between training and testing. This gap degrades the performance of OT. C. Implementation Details C.1. Two-Dimensional Data Data. Following the implementation of Tong et al. [42], we generate the moons data using the torchdyn library [34], and the 8 Gaussians using torchcfm [42]. Network. We employ simple multi-layer perceptron (MLP) network for this dataset. Initially, the two-dimensional input (x and coordinates) and the flow timestep (a scalar uniformly sampled from [0, 1]) are projected into the hidden dimension using individual linear layers. When an input condition is provided, it is similarly projected into the hidden dimension. Discrete conditions are encoded as -1 or +1, while continuous conditions are represented by the x-coordinate of the target data point. After projection, all input features are summed and processed through network comprising three MLP modules. Each MLP module consists of two linear layers, where the first layer uses an expansion ratio of 4, and is followed by GELU activation function [14]. We use residual connection to incorporate the output of each MLP block. Finally, another linear layer projects the features to two dimensions to produce the output velocity. The hidden dimension is set to 128. Training. We train each network for 20,000 iterations with the Adam [20] optimizer, learning rate of 3e-4 without weight decay, and deep net batch size of 256 for computing forward/backward passes/gradient updates. We use an OT batch size of 1024 and target ratio rtar of 0.01. 12 Unconditonal With discrete conditions With continuous conditions (target coordinates) 6.2320.186 0.0720. 2.5730.112 0.4830.059 0.0480.010 0.7320.052 8.2766.510 0.0770. i r t 1 - u i d 0.1200.045 FM 0.0500.040 OT 0.0590.029 FM 0.4620.025 OT 0.0180.006 C2OT (ours) 0.0280.010 FM 2.1431.993 OT 0.0130.003 C2OT (ours) Figure A3. We visualize the flows learned by different algorithms using the 8gaussiansmoons dataset. Below each plot, we show the 2-Wasserstein distance (lower is better; meanstd over 10 runs). Compared to Figure 1, we have added first row illustrating the prior-data coupling during training. Note that the OT coupled paths during training (first row) do cross. This is expected the commonly referred to no-crossing property of OT coupling refers to the uniqueness of the pair (x0, x1) given and at the same timestep t, no two paths may cross at (see Proposition 3.4 in Tong et al. [42] and Theorem D.2 in Pooladian et al. [36]). Since we plot all timesteps simultaneously in this figure, there are apparent crossings. However, the intersecting paths do not share the same timestep at the point of intersection. CIFAR-10 ImageNet-32 128 Channels 2 Depth 1, 2, 2, 2 Channels multiple 4 Heads 64 Heads channels 16 Attention resolution 0.0 Dropout True Use scale shift norm 128 Batch size / GPU 2 GPUs 256 Effective batch size 100k Iterations 2.0e4 Learning rate Learning rate scheduler Warmup then constant Warmup then linear decay 5k Warmup steps 640 OT batch size (per GPU) 256 3 1, 2, 2, 2 4 64 4 0.0 True 128 4 512 300k 1.0e4 20k 6400 Table A1. Hyperparameter settings for training on CIFAR-10 and ImageNet-32. C.2. CIFAR-10 In CIFAR-10, we employ the UNet architecture used by Tong et al. [42]. We list our hyperparameters in Table A1, following the format in [27, 36, 42]. To accelerate training, we use bf16. We use the Adam [20] optimizer with the following parameters: β1 = 0.9, β2 = 0.95, weight decay=0.0, and ϵ = 1e8. For learning rate scheduling, we linearly increase the learning rate from 1.0e8 to 2.0e4 over 5,000 iterations and then keep the learning rate constant. The use scale shift norm denotes 13 employing adaptive layer normalization to incorporate the input condition, as implemented in [8]. To stabilize training, we clip the gradient norm to 1.0. We report the results using an exponential moving average (EMA) model with decay factor of 0.9999. For FID computation, we use the clean_fid library [33] in legacy_tensorflow mode following [42]. C.3. ImageNet-32 Data. We use face-blurred ImageNet-1K [7, 44] following [28], and apply the downsampling script from [6]. Images are downsampled to 3232 using the box algorithm, and reference FID statistics are computed with respect to the downsampled validation set images. For text input, we use the captions provided by [25]. Network and Training. We largely follow the training pipeline described in Appendix C.2. We use larger network following [36] and list our hyperparameters in Table A1. To encode text input, we use the openclip library [18] and the text encoder of the DFN5B-CLIP-ViT-H-14 checkpoint [11], pretrained CLIP-like model. CLIP feature vectors are normalized to unit norm before being used as input conditions. For learning rate scheduling, after the initial warmup phase, we linearly decay the learning rate to 1.0e8 over time. Evaluation. As stated in the main paper, we use 49,997 images from the validation set to compute FID. This is because the fine-grained nature of image captions might lead to overfitting, i.e., memorizing the training set. For CLIP score computation, we evaluate the cosine similarity between the input caption and the generated image using SigLIP-2 [43], with the ViT-SO400M-16-SigLIP2-256 checkpoint via the openclip library [18]. C.4. ImageNet-256 For this dataset, we use the open-source implementation of LightningDiT [46] and train the models under the 64 epochs setting with minimal modifications to change the network from class-conditioned to caption-conditioned. In addition to integrating the coupling algorithms (OT and C2OT, while the original LightningDiT [46] already employs FM), our modifications include: 1. Changing the input conditional mapping layer from an embedding layer (that takes class label as input) to linear layer (that takes CLIP features as input). 2. Adjusting the classifier-free guidance (CFG) scale. We find that the model benefits from higher CFG scale when using caption conditioning. Specifically, we increase the CFG scale from 10.0 to 17.0, and adjust the CFG interval start parameter from 0.11 to 0.10. For data and evaluation, we follow the same setup as described in Appendix C.3. D. Additional Generated Images We present additional image generation results in this section. All showcased images are uncurated, meaning they were sampled completely at random. For consistency and direct comparison, we used the same random seed for each generation across different methods. 14 D.1. CIFAR-10 Euler-10 Adaptive O ) o ( 2 Figure A4. Uncurated generations in CIFAR-10, 10-per-class. We compare FM, OT, and C2OT with both 10-step Eulers method and an adaptive solver for test-time numerical integration. 15 D.2. ImageNet-32 Euler-10 Adaptive T ) o ( 2 Figure A5. Uncurated generations in ImageNet-32. We compare FM, OT, and C2OT with both 10-step Eulers method and an adaptive solver for test-time numerical integration. 16 D.3. ImageNetFigure A6. Uncurated generations in ImageNet-256. We compare FM, OT, and C2OT with different amounts of sampling steps. 17 O ) o ( 2 Figure A7. Uncurated generations in ImageNet-256. We compare FM, OT, and C2OT with an adaptive solver for test-time numerical integration. 18 E. DeltaAI Acknowledgment This work used the DeltaAI system at the National Center for Supercomputing Applications through allocation CIS250008 from the Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS) program, which is supported by National Science Foundation grants 2138259, 2138286, 2138307, 2137603, and 2138296."
        }
    ],
    "affiliations": [
        "University of Illinois Urbana-Champaign"
    ]
}