{
    "paper_title": "BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring",
    "authors": [
        "Rajan Das Gupta",
        "Md Kishor Morol",
        "Nafiz Fahad",
        "Md Tanzib Hosain",
        "Sumaya Binte Zilani Choya",
        "Md Jakir Hossen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As the global burden of Alzheimer's disease (AD) continues to grow, early and accurate detection has become increasingly critical, especially in regions with limited access to advanced diagnostic tools. We propose BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address this challenge. This novel system harnesses the powerful reasoning capabilities of Large Language Models (LLMs) for Alzheimer's detection and monitoring. BRAINS features a dual-module architecture: a cognitive diagnostic module and a case-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on cognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain volume metrics -- to perform structured assessments of Alzheimer's risk. Meanwhile, the Case Retrieval Module encodes patient profiles into latent representations and retrieves similar cases from a curated knowledge base. These auxiliary cases are fused with the input profile via a Case Fusion Layer to enhance contextual understanding. The combined representation is then processed with clinical prompts for inference. Evaluations on real-world datasets demonstrate BRAINS effectiveness in classifying disease severity and identifying early signs of cognitive decline. This system not only shows strong potential as an assistive tool for scalable, explainable, and early-stage Alzheimer's disease detection, but also offers hope for future applications in the field."
        },
        {
            "title": "Start",
            "content": "BRAINS: Retrieval-Augmented System for Alzheimers Detection and Monitoring Rajan Das Gupta1,4 Md Kishor Morol4, Nafiz Fahad2,4 Md Tanzib Hosain1,4 Sumaya Binte Zilani Choya4,4 Md Jakir Hossen2,4, 1American International University-Bangladesh 3George Mason University 4ELITE Research Lab 2Multimedia University 5 2 0 2 4 ] . [ 1 0 9 4 2 0 . 1 1 5 2 : r 18-36304-1@student.aiub.edu, kishormorol@ieee.org nafiz.fahad@student.mmu.edu.my, 20-42737-1@student.aiub.edu schoya@gmu.edu, jakir.hossen@mmu.edu.my AbstractAs the global burden of Alzheimers disease (AD) continues to grow, early and accurate detection has become increasingly critical, especially in regions with limited access to advanced diagnostic tools. We propose BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address this challenge. This novel system harnesses the powerful reasoning capabilities of Large Language Models (LLMs) for Alzheimers detection and monitoring. BRAINS features dual-module architecture: cognitive diagnostic module and case-retrieval module. The Diagnostic Module utilises LLMs fine-tuned on cognitive and neuroimaging datasetsincluding MMSE, CDR scores, and brain volume metricsto perform structured assessments of Alzheimers risk. Meanwhile, the Case Retrieval Module encodes patient profiles into latent representations and retrieves similar cases from curated knowledge base. These auxiliary cases are fused with the input profile via Case Fusion Layer to enhance contextual understanding. The combined representation is then processed with clinical prompts for inference. Evaluations on real-world datasets demonstrate BRAINS effectiveness in classifying disease severity and identifying early signs of cognitive decline. This system not only shows strong potential as an assistive tool for scalable, explainable, and early-stage Alzheimers disease detection, but also offers hope for future applications in the field. Index TermsAlzheimers Disease, Retrieval Augmented Generation (RAG), Cognitive Decline Detection, Clinical Decision Support I. INTRODUCTION Alzheimers disease (AD), the most common form of dementia, represents complex and progressive neurodegenerative disorder that significantly impairs memory, cognition, and behaviour [1]. According to the World Health Organization (WHO), over 55 million people worldwide are currently living with dementia, with Alzheimers disease accounting for up to 70% of these cases. Alarmingly, this number is projected to rise to 139 million by 2050, driven primarily by ageing populations and delayed diagnoses [2]. As noted by the National Institute on Aging (NIA), Alzheimers is currently among the leading causes of disability and dependency among older adults. However, it remains vastly underdiagnosed, parCorresponding author ticularly in low-resource settings where access to specialized neurological assessment is limited [3]. Despite decades of research, early and reliable detection of Alzheimers disease remains critical challenge. Traditional diagnostic methods, including neuropsychological testing, MRI-based brain volume analysis [4], and clinical rating scales such as the Mini-Mental State Examination (MMSE) [5], are resourceand Clinical Dementia Rating (CDR) intensive and require domain expertise [6]. Moreover, access to neuroimaging and specialized interpretation remains scarce in economically disadvantaged regions, leading to disparities in early diagnosis and care delivery [7], [8]. Diagnosing and managing Alzheimers disease is further complicated by the brains structural complexity and the heterogeneity of cognitive decline patterns. Small morphological changes, such as cortical thinning or hippocampal atrophy, are often difficult to quantify and interpret, even for experienced clinicians [9]. Additionally, real-world assessment data, such as brain volume estimates (eTIV, nWBV), MMSE/CDR scores, and demographic information (Table I), are inherently variable and incomplete across populations [10][12]. These challenges underscore the need for intelligent systems integrating heterogeneous, multimodal data to aid early detection and disease monitoring [13][15]. Recent advances in artificial intelligence (AI) particularly large language models (LLMs) offer transformative potential for assisting clinicians in synthesizing such complex data. While previous AI systems in neurology have relied on rigid feature engineering or domain-specific heuristics, LLMs [16] [20] provide generalizable, prompt-driven framework for reasoning over structured clinical input. However, most current systems lack case-based contextual reasoning, interpretability, and robustness to real-world data variability."
        },
        {
            "title": "To address",
            "content": "these limitations, we introduce BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening)a novel, retrieval-augmented diagnostic framework that leverages the reasoning capabilities of LLMs alongside case-based retrieval and neurocognitive data fusion. BRAINS adopts dual-phase architecture: the DiagFeature MMSE CDR eTIV nWBV Hippocampal Volume Amygdala Volume Ventricular Volume Temporal Thickness WMH Age Education Level Gender APOE Genotype MoCA Score GDS Score TABLE I: Key Features for Alzheimers Disease Diagnosis Clinical Relevance Global cognitive function Dementia severity rating Intracranial volume normalization Brain atrophy indicator Memory-related region atrophy Emotion processing region Enlarged in AD progression Cortical atrophy biomarker Marker for vascular pathology Primary risk factor Reflects cognitive reserve Influences disease manifestation Genetic predisposition (ϵ4 allele) MCI screening alternative Screens comorbid depression nostic Module is pre-trained with neurocognitive assessment records to encode foundational knowledge of Alzheimers progression. In contrast, the Case Retrieval Module encodes input features to retrieve semantically relevant historical cases from clinical knowledge base. These auxiliary cases are integrated through Case Fusion Layer, enabling contextaware reasoning that enhances interpretability and prediction accuracy. We construct and validate BRAINS on real-world dataset comprising MMSE, CDR, brain volumetric measures (eTIV, nWBV), and demographic variables to evaluate the systems practical utility. Our experiments demonstrate that BRAINS achieves superior performance in detecting and staging Alzheimers disease compared to baseline models, while also providing explainable outputs aligned with clinical insights. We argue that BRAINS not only contributes robust technical advancement but also represents scalable solution for dementia screening in both high-resource hospitals and underserved settings where early intervention is most critical. II. METHODOLOGY In this section, we introduce BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening), system designed to support Alzheimers disease diagnosis by leveraging clinical guidelines in neurocognitive assessment and brain imaging. We begin by describing our dataset, which includes demographic, cognitive, and neuroanatomical features such as MMSE, CDR, eTIV, and nWBV. We then present the architecture of BRAINS, which combines Diagnostic Module for cognitive evaluation with Case Retrieval Module that integrates relevant patient histories. These components are fused via Case Fusion Layer, enabling context-aware, explainable predictions aligned with real-world clinical workflows. A. Data Preparing The objective of pre-training is to equip the foundational model with prior domain knowledge by exposing it to broad corpus of relevant information. This stage involves training on large volume of unlabeled text to help the model internalize domain-specific concepts before fine-tuning on structured diagnostic tasks. In our case, we aim for the BRAINS model to acquire baseline understanding of Alzheimers-related terminology, cognitive scoring systems, and clinical reasoning prior to task-specific adaptation. To support this, we curated pre-training dataset consisting of textual reports and summaries derived from relevant Alzheimers disease report [4], [7], [21], neurocognitive evaluations (e.g., MMSE, CDR) [22], and structured annotations from clinical databases such as NACC and ADNI [23], [24]. Since the model is not designed to process images directly, we applied regularization by removing sentences that referenced visual elements. Specifically, we filtered out any sentences containing terms like Figure or see image to ensure consistency in textual input. This pre-training phase enhances the models ability to reason over structured brain health data in subsequent diagnostic tasks. B. Alzheimers Disease Dataset To support the diagnosis and staging of Alzheimers disease, we curated further clinical dataset with 1105 patient records collected from medical institutions. Each subject is categorized as 1. Early-Onset Alzheimers Disease, 2. LateOnset Alzheimers Disease, 3. Familial Alzheimers Disease, 4. Sporadic Alzheimers Disease, 5. Atypical Alzheimers Disease based on MMSE, CDR, and neuroimaging-derived metrics. The dataset includes features: MMSE, CDR, eTIV, nWBV, age, gender, handedness, education, and socioeconomic status. All entries were pre-processed by normalization, encoding, and outlier removal to ensure quality and consistency for downstream modeling with BRAINS. C. Model Architecture As illustrated in Figure 1, the proposed BRAINS framework consists of two core components: the Diagnostic Module and the Case Retrieval Module. Upon receiving new patient casecomprising neurocognitive scores (e.g., MMSE, CDR), demographic data, and structural brain metrics (e.g., nWBV, eTIV)the Case Retrieval Module first encodes the input and Fig. 1: BRAINS architecture for Alzheimers diagnosis. The input case is encoded and used to retrieve similar neurocognitive records. Retrieved cases are fused with the input via the Case Fusion Layer, replacing the <RAGHere> token in the prompt. The fused representation is then passed to the LLM for inference and explanation. retrieves the top-KKK most clinically relevant auxiliary cases from curated knowledge base. These retrieved cases are then paired with the input as (T, R)(T, R)(T, R), where TTT represents the target case and RRR denotes the reference cases. This case pair is subsequently passed to the Diagnostic Module, which performs reasoning over the joint representation to assess the likelihood and stage of Alzheimers disease. By integrating contextual information from similar historical cases, BRAINS enhances interpretability and diagnostic robustness. The following sections detail each modules architecture and operational flow. D. Case Retrieval Module To enhance the precision and contextual awareness of Alzheimers disease diagnosis, the proposed BRAINS system integrates retrieval-augmented inference by leveraging structured memory of historical neurocognitive cases. Rather than relying solely on generalizable reasoning from pre-trained knowledge, BRAINS employs Case Retrieval Module to dynamically fetch semantically similar patient profiles from vectorized clinical case database. This augmentation facilitates nuanced decision-making, especially in the presence of heterogeneous or borderline cognitive features. The Case Retrieval Module comprises two core components: curated neurocognitive case database and high-dimensional text encoder. Each entry in the training datasetincluding features such as MMSE, CDR, age, eTIV, nWBV, and educationis first tokenized and encoded using clinical-domain-adapted text encoder. The resulting hidden representation w[CLS], which summarizes the input case, is stored in FAISS-based vector database [25]. During training and inference, the input case is encoded into its hidden representation and queried against the FAISS vector store using cosine similarity. The top 1K most similar historical cases are retrieved, followed by reranking module that reorders them based on fine-tuned scoring mechanism. The highest scoring auxiliary cases = {r0, r1, . . . , rK1} are then selected to form case pair (T, R), where the target case is jointly reasoned over with the retrieved support cases R. This approach allows BRAINS to directly incorporate population-level cognitive trends and structural brain biomarkers into its diagnostic inference, ultimately improving robustness and explainability in clinical settings. E. Diagnostic Module Upon retrieval, the BRAINS framework forms case pair (T, R), where represents the input patient profile and = {r0, r1, ..., rK1} denotes the top-K semantically relevant neurocognitive cases retrieved from the clinical memory. The Diagnostic Module consists of two key components: the Case Fusion Layer and the Inference LLM. To overcome the context-length limitations of large language models, the Case Fusion Layer aggregates representations of the retrieved cases. Each auxiliary case ri is encoded TABLE II: Performance comparison of LLaMA2-13B, RAG variants, and the proposed BRAINS system across all, single, double, and triple case types. Model LLaMA2-13B Five-shot Fine-tuning w/o standard RAG RAG-1 RAG-2 BRAINS All Correct Prec. 0.335 0.600 0.454 0.712 0.727 0.773 0.339 0.538 0.376 0.731 0.755 0.819 0.000 0.657 0. 0.766 0.790 0.784 Single Recall 0.000 0.728 0.513 0.540 0.572 0.731 F1 Prec. Double Recall F1 Prec. 0.000 0.692 0.571 0.619 0.664 0.740 0.299 0.468 0. 0.703 0.660 0.711 0.719 0.474 0.500 0.824 0.921 0.875 0.423 0.471 0.361 0.802 0.769 0.810 0.421 0.643 0. 0.774 0.727 0.931 Triple Recall 0.980 0.281 0.063 0.981 0.975 0.911 F1 0.591 0.391 0. 0.863 0.842 0.929 into hidden vectors wi = {w[CLS]i, w1i, . . . , wni}, and the input case is encoded as = {t[CLS], t1, . . . , tn}. crossattention mechanism, based on the standard Transformer formulation [26], is employed to align and integrate contextual information across the retrieved examples: Attn(Q, K, ) = softmax (cid:18) QK dk (cid:19) (1) where = WQt[CLS], = WKA, = WKA, and denotes the concatenated matrix of retrieved case vectors: = [w[CLS]0 , w10, . . . , wn0, w[CLS]1, . . . , wn(K1)]"
        },
        {
            "title": "The resulting case fusion vector",
            "content": "replaces the special <RAGHere> token within the prompt embedding sequence = {p<s>, pSystem, . . . , p<RAGHere>, . . . , p</s>}. The fused sequence is then passed to the Inference LLM for prediction. During pre-training, we adopt next-token prediction strategy to enable the model to acquire foundational neurocognitive knowledge. Fine-tuning is conducted with supervised objectives, where the loss is computed solely on the assistants response, refining the models focus and performance in Alzheimers disease prediction tasks. III. EXPERIMENTS In this section, we present the experimental framework employed to evaluate the efficacy of our proposed system. This framework is grounded in clinically relevant neurocognitive datasets, with focus on early-stage Alzheimers disease detection and multi-faceted cognitive impairment classification. The experimental design is meticulously structured to probe retrieval-augmented reasoning performance and generalization across single-clue, dual-clue, and complex multi-clue diagnostic cases. Implementation details, data preprocessing strategies, and evaluation protocols are aligned with established neuroscience benchmarks [27] to ensure reproducibility and relevance. The results provide quantitative insight into the systems diagnostic accuracy and interpretability under variable cognitive load conditions. A. Pre-training Setting We adopt the LLaMA2-13B [20] model as our foundational large language model, further fine-tuned on clinically curated neurocognitive corpora involving Alzheimers disease, mild cognitive impairment (MCI), and related neurodegenerative conditions. Training is conducted over 10 epochs with batch size of 64, using the AdamW optimizer [28] and learning rate set to 1 104. To ensure stable convergence, we apply 1,000 warm-up steps. The token block size is fixed at 2048 to accommodate high-resolution case narratives that integrate structured cognitive assessments (e.g., MMSE, CDR), neuroimaging-derived biomarkers (e.g., hippocampal atrophy, cortical thinning), and demographic variables (e.g., age, gender, education). This fine-tuning strategy equips the model with domain-specific reasoning capabilities necessary for downstream neurodiagnostic inference. B. Fine-tuning Setting Building upon prior foundational training, we repurpose the pretrained neurodiagnostic language model as the backbone for inference. To ensure alignment between retrieval and reasoning, the same model architecture is deployed as the text encoder within the Case Retrieval Module, thereby preserving representational consistency. For reranking retrieved support cases, we integrate the bge-reranker-large [29] to refine case relevance via dense semantic scoring. At inference time, we retrieve the top-K = 5 neurocognitive profiles from the vector database, grounded in prior subjects exhibiting comparable biomarker and cognitive test signatures. To promote positional robustness and mitigate overfitting to fixed retrieval slots, we introduce dynamic masking strategy during training, where [0, 4] auxiliary cases are randomly masked in each training iteration. The model is trained for 15 epochs with batch size of 4 using the AdamW optimizer [28] and learning rate of 1 105. To improve training efficiency and parameter efficiency, we adopt Low-Rank Adaptation (LoRA) [30], configured with α = 32 and = 8, enabling scalable fine-tuning within computational constraints while retaining high domain-specific fidelity. IV. RESULTS As presented in Table II, the efficacy of the proposed BRAINS model is validated through rigorous empirical evaluation within the domain of neurocognitive disorder inference. In the baseline setting using LLaMA2-13B, the Five-shot prompting paradigm can generate plausible outputs, yet it fails to yield reliable diagnostic accuracy in complex multi-label neurocognitive cases. Upon fine-tuning the model on structured clinical texts enriched with cognitive metrics such as MMSE, CDR, and volumetric MRI-derived featuresa substantial improvement of 26.50% in accuracy is observed. The absence of these standardized neuro-biomarkers during input leads to pronounced degradation in model performance, especially in complex classification settings involving co-occurring conditions. Further gains are achieved by incorporating retrievalaugmented generation (RAG), where one or more relevant cases are retrieved to assist inference. With single retrieved case (RAG-1), accuracy increases from 60.00% to 71.20%, and additional retrieved profiles provide incremental benefits. However, retrieving more than two cases leads to token length constraints that inhibit reasoning due to limited context window sizes. This bottleneck is effectively overcome by the BRAINS models case fusion mechanism, which supports the integration of up to five auxiliary cases, achieving an accuracy of 77.30%. Under the Five-shot configuration, the model achieves high recall (98.00%) in multi-pathology scenarios but suffers from low F1 (59.10%) due to poor precision. In contrast, singlelabel prediction tasks reveal complete breakdown (F1 = 0.00%), suggesting an overly conservative decision boundary. This highlights the limitations of zeroor Five-shot generalization for complex neurological inference. Fine-tuning improves this imbalance, while the BRAINS model surpasses both token and reasoning limitations, delivering robust and interpretable predictions across varying levels of diagnostic complexity. V. CONCLUSION This study introduces BRAINS, novel foundation model architected specifically for early-stage alzheimers disorder screening. Tailored for the analysis of core neurological report datasuch as cognitive assessments (e.g., MMSE, CDR), speech and behaviour logs, and structural brain imaging summariesBRAINS is designed to support clinical reasoning, particularly for less experienced practitioners in neurology and geriatric medicine. By integrating retrieval-augmented generation (RAG) mechanisms, BRAINS substantially improves diagnostic precision for multi-morbidity inference tasks. In our benchmark evaluation on mild cognitive impairment and Alzheimer-type dementia classification, BRAINS achieves an accuracy of 77.30%, significantly outperforming the baseline large language model, which attains only 45.40%. We posit that BRAINS represents foundational shift in scalable, interpretable, and data-efficient brain health modelling, with the potential to generalise across broad spectrum of neurological diagnostic domains."
        },
        {
            "title": "REFERENCES",
            "content": "[1] B. P. Imbimbo, S. Ippati, M. Watling, and C. Balducci, Accelerating alzheimers disease drug discovery and development: Whats the way forward?, Expert Opinion on Drug Discovery, 2021. [2] S. Miller, Astrocyte heterogeneity in the adult central nervous system, Frontiers in Cellular Neuroscience, vol. 12, p. n/a, 2018. [3] R. C. Petersen et al., Alzheimers disease neuroimaging initiative (adni): Clinical characterization, Neurology, vol. 74, no. 3, pp. 201209, 2010. [4] D. S. Marcus, T. H. Wang, J. Parker, et al., Open access series of imaging studies (oasis): Cross-sectional mri data in young, middle aged, nondemented, and demented older adults, Journal of Cognitive Neuroscience, vol. 19, no. 9, pp. 14981507, 2007. [5] J. C. Morris, The clinical dementia rating (cdr): Current version and scoring rules, Neurology, vol. 43, no. 11, pp. 24122414, 1993. [6] C. R. Jack, D. A. Bennett, K. Blennow, et al., Nia-aa research framework: Toward biological definition of alzheimers disease, Alzheimers & Dementia, vol. 14, no. 4, pp. 535562, 2018. [7] M. W. Weiner, D. P. Veitch, P. S. Aisen, et al., 2014 update of the alzheimers disease neuroimaging initiative: review of papers published since its inception, Alzheimers & Dementia, vol. 11, no. 6, pp. e1e120, 2015. [8] M. F. Folstein, S. E. Folstein, and P. R. McHugh, Mini-mental state: practical method for grading the cognitive state of patients for the clinician, Journal of Psychiatric Research, vol. 12, no. 3, pp. 189198, 1975. [9] A. Reuben, A. Caspi, H. Harrington, et al., Predicting dementia from structured health records using machine learning, JAMA Network Open, vol. 4, no. 7, p. e2118854, 2021. [10] Z. Yang, X. Lin, et al., Knowledge-enhanced language models in medical domains, Briefings in Bioinformatics, 2023. [11] K. Singhal, S. Azizi, et al., Towards expert-level medical question answering with prompt-augmented llms, Nature, 2023. [12] R. Luo, Y. Zhang, et al., Clinicalt5: Retrieval-enhanced clinical summarization with task-adaptive pretraining, Findings of ACL, 2024. [13] A. Zeng, X. Ma, and K. Yu, Long-context modeling for medical report understanding using sparse transformers, Proceedings of ACL, 2024. [14] C. Gao, L. Zhang, et al., Reta: Retrieval-augmented transformer for clinical note understanding, arXiv preprint arXiv:2303.02252, 2023. [15] Y. Zhang, K. Sun, et al., Cogagent: generalist foundation model for multimodal tasks, arXiv preprint arXiv:2403.11295, 2024. [16] M. Chen, R. Zhou, et al., Pmc-llama: Towards open-source medical llms, arXiv preprint arXiv:2401.05509, 2024. [17] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., Palm: Scaling language modeling with pathways, Journal of Machine Learning Research, vol. 24, no. 240, pp. 1113, 2023. [18] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al., Gpt-4 technical report, arXiv preprint arXiv:2303.08774, 2023. [19] S. Li, K. Singhal, et al., Med-palm: Large language models for medicine, arXiv preprint arXiv:2305.09617, 2023. [20] H. Touvron, T. Lavril, G. Izacard, et al., Llama: Open and efficient foundation language models, arXiv preprint arXiv:2302.13971, 2023. [21] G. B. Frisoni, N. C. Fox, C. R. Jack Jr, P. Scheltens, and P. M. Thompson, The clinical use of structural mri in alzheimer disease, Nature reviews neurology, vol. 6, no. 2, pp. 6777, 2010. [22] J. C. Morris, The clinical dementia rating (cdr) current version and scoring rules, Neurology, vol. 43, no. 11, pp. 24122412, 1993. [23] N. A. C. C. (NACC), National alzheimers coordinating center (nacc) data. https://www.alz.washington.edu/, 2023. Accessed: 2025-07-28. [24] A. D. N. I. (ADNI), Alzheimers disease neuroimaging initiative (adni). https://adni.loni.usc.edu/, 2023. Accessed: 2025-07-28. [25] M. Douze, A. Guzhva, C. Deng, J. Johnson, G. Szilvasy, P.-E. Mazare, M. Lomeli, L. Hosseini, and H. Jegou, The faiss library, 2025. [26] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, Attention is all you need, Advances in neural information processing systems, vol. 30, 2017. [27] J. Guo, X. Shan, G. Wang, D. Chen, R. Lu, and S. Tang, Heart: Heart expert assistant with retrieval-augmented, in AAAI 2024 Spring Symposium on Clinical Foundation Models, 2024. [28] I. Loshchilov and F. Hutter, Decoupled weight decay regularization, arXiv preprint arXiv:1711.05101, 2017. [29] H. Xiao, R. Ren, et al., Bge-reranker: strong baseline for passage reranking, arXiv preprint arXiv:2309.11664, 2023. [30] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen, et al., Lora: Low-rank adaptation of large language models., ICLR, vol. 1, no. 2, p. 3, 2022."
        }
    ],
    "affiliations": [
        "American International University-Bangladesh",
        "ELITE Research Lab",
        "George Mason University",
        "Multimedia University"
    ]
}