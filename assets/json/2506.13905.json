{
    "paper_title": "Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems",
    "authors": [
        "Zhongzhi Yu",
        "Mingjie Liu",
        "Michael Zimmer",
        "Yingyan Celine Lin",
        "Yong Liu",
        "Haoxing Ren"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Despite recent progress in generating hardware RTL code with LLMs, existing solutions still suffer from a substantial gap between practical application scenarios and the requirements of real-world RTL code development. Prior approaches either focus on overly simplified hardware descriptions or depend on extensive human guidance to process complex specifications, limiting their scalability and automation potential. In this paper, we address this gap by proposing an LLM agent system, termed Spec2RTL-Agent, designed to directly process complex specification documentation and generate corresponding RTL code implementations, advancing LLM-based RTL code generation toward more realistic application settings. To achieve this goal, Spec2RTL-Agent introduces a novel multi-agent collaboration framework that integrates three key enablers: (1) a reasoning and understanding module that translates specifications into structured, step-by-step implementation plans; (2) a progressive coding and prompt optimization module that iteratively refines the code across multiple representations to enhance correctness and synthesisability for RTL conversion; and (3) an adaptive reflection module that identifies and traces the source of errors during generation, ensuring a more robust code generation flow. Instead of directly generating RTL from natural language, our system strategically generates synthesizable C++ code, which is then optimized for HLS. This agent-driven refinement ensures greater correctness and compatibility compared to naive direct RTL generation approaches. We evaluate Spec2RTL-Agent on three specification documents, showing it generates accurate RTL code with up to 75% fewer human interventions than existing methods. This highlights its role as the first fully automated multi-agent system for RTL generation from unstructured specs, reducing reliance on human effort in hardware design."
        },
        {
            "title": "Start",
            "content": "Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems Zhongzhi Yu Nvidia Research Austin, TX zhongzhiy@nvidia.com Mingjie Liu Nvidia Research Austin, TX Michael Zimmer Cadence San Jose, CA mingjiel@nvidia.com zimmerm@cadence.com Yingyan (Celine) Georgia Institute of Technology Atlanta, GA celine.lin@gatech.edu Yong Liu Cadence San Jose, CA yongl@cadence.com Haoxing Ren Nvidia Research Austin, TX haoxingr@nvidia.com integrates three key enablers: AbstractDespite recent progress in generating hardware register transfer level (RTL) code with large language models (LLMs), existing solutions still suffer from substantial gap between practical application scenarios and the requirements of real-world RTL code development. Prior approaches either focus on overly simplified hardware descriptions or depend on extensive human guidance to process complex specifications, limiting their scalability and automation potential. In this paper, we address this gap by proposing an LLM agent system, termed Spec2RTLAgent, designed to directly process complex specification documentation and generate corresponding RTL code implementations, advancing LLMbased RTL code generation toward more realistic application settings. To achieve this goal, Spec2RTL-Agent introduces novel multi-agent collaboration framework that (1) reasoning and understanding module that translates specifications into structured, step-by-step implementation plans; (2) progressive coding and prompt optimization module that iteratively refines the code across multiple representations (pseudocode, Python, and C++) to enhance correctness and synthesisability for RTL conversion; and (3) an adaptive reflection module that identifies and traces the source of errors during generation, ensuring more robust code generation flow. Instead of directly generating RTL from natural language, our system strategically generates synthesizable C++ code, which is then optimized for high-level synthesis (HLS). This agent-driven refinement ensures greater correctness and compatibility compared to naive direct RTL generation approaches. We evaluate Spec2RTL-Agent on benchmark of three specification documents, demonstrating its effectiveness in generating accurate RTL code with as much as 75% fewer human interventions compared to existing approaches. These results underscore Spec2RTL-Agents role as the first fully automated multi-agent system for RTL generation from unstructured specification documents, reducing the reliance on human effort and expertise in hardware design. Index TermsRTL Code Generation, Large Language Model, Agent"
        },
        {
            "title": "System",
            "content": "I. INTRODUCTION In recent years, Large Language Models (LLMs) have demonstrated remarkable performance across diverse range of tasks, fundamentally transforming human activities and work pipelines [1] [3]. Given the labor-intensive nature of hardware code implementation, particularly at the Register Transfer Level (RTL), there is compelling motivation to leverage advanced LLM technologies [4] [6]. Deploying LLMs for RTL code generation offers promising approach to enhance design automation productivity, reduce reliance on extensive human intervention, and accelerate the development cycle [6][9]. However, existing LLM-based RTL generation approaches struggle to handle real-world hardware design tasks. Hardware specifications are often lengthy, contain unstructured multi-modal information (e.g., tables, figures, equations), and require deep contextual Fig. 1. Overview of the hardware implementation flow and the comparison between the capability of existing LLM-based approaches in automating hardware code generation and the achieved automated hardware code generation with our proposed Spec2RTL-Agent. understanding beyond simple text-based instructions. Prior works, such as VerilogEval [5] and GPT4AIGChip [4], focus on either generating isolated RTL components or simplifying the specification input, thereby limiting their applicability to complex, multi-stage hardware designs. For instance, generating an RTL implementation for an encryption module requires not only extracting constraints and defining submodules but also iteratively refining the design based on verificationtasks that existing single-pass LLM methods fail to automate. As illustrated in Fig. 1, current LLM-based RTL generation approaches can be categorized into two groups: (1) methods that target simplified scenarios, such as generating standalone RTL functions from structured natural language descriptions [5], [6], [10], [11], or automating only specific sub-parts of the hardware design pipeline [4], [12], and (2) approaches that integrate LLMs into human-in-the-loop workflows, where engineers remain responsible for specification interpretation, task decomposition, and iterative debugging [7], [13]. While the latter category benefits from human expertise, it still demands extensive manual intervention, preventing full automation. To address these limitations, we propose Spec2RTL-Agent, an LLM-based multi-agent system designed to automate RTL code generation directly from unstructured specification documents. Unlike previous approaches that either generate RTL directly or rely on extensive human preprocessing, Spec2RTL-Agent follows structured, iterative process that mirrors the conventional human-driven hardware design workflow. Our framework systematically processes specification documents, refines code generation through multiple abstraction levels, and iteratively verifies outputs to improve correctness. Inspired by the way human engineers approach hardware design, Spec2RTL-Agent operates in three critical stages: (1) Understand5 2 0 2 6 1 ] . [ 1 5 0 9 3 1 . 6 0 5 2 : r ing, analyzing the specification to extract constraints and structure implementation plans, ensuring clarity and correctness from the outset, (2) Coding, progressively refining the implementation by first generating structured high-level code before transforming it into synthesizable C++ for High-Level Synthesis (HLS), and (3) Reflection, iteratively verifying, debugging, and refining intermediate outputs through an adaptive refinement mechanism to enhance robustness. This structured workflow aligns with traditional hardware development methodologies [14][16], allowing LLM agents to not only generate code but also engage in high-level reasoning, optimization, and error correction, reducing reliance on human intervention. The contributions of this paper are summarized as follows: We introduce the first LLM-based system, dubbed the Spec2RTL-Agent, that emulates the human hardware implementation process to enable end-to-end RTL code generation directly from real-world complex specification documents. This development marks significant advancement in LLM-based RTL code generation, moving towards more practical and realistic applications by enhancing the productivity of hardware implementations and facilitating more agile development process. Spec2RTL-Agent integrates three key enablers, each replicating critical stage of the human-driven RTL implementation process, including (1) an iterative understanding and reasoning module to enhance the comprehension of documentation and facilitate strategic implementation planning, (2) progressive coding and prompt optimization module that improves the efficiency and effectiveness of the coding process, and (3) an adaptive reflection module that enables adaptively debugging throughout the whole implementation flow, ensuring robust and reliable code generation process. Experiments conducted on benchmark containing three representative specification documents published by the National Institute of Standards and Technology (NIST) and their corresponding implementations validate the effectiveness of our proposed Spec2RTL-Agent in directly generating RTL implementations from specification documentation with limited human intervention. Notably, Spec2RTL-Agent achieves as much as 75% fewer human interventions compared to existing methods. These results underscore Spec2RTL-Agent as practical solution for real-world RTL code generation applications, significantly reducing the human labor typically required in the hardware implementation process. II. BACKGROUND A. LLM-Based RTL Code Generation Recent work has applied LLMs to RTL code generation, enabling synthesis from textual descriptions [5], [6], [8], [10], [17][19]. Methods such as ChipAlign [20], MG-Verilog [18], and CraftRTL [10] generate RTL directly but struggle with unstructured inputs, requiring human oversight for refinement and validation. RTLCoder [21] improves generation quality, achieving state-of-the-art performance tools. Other studies integrate LLMs into among non-commercial human-in-the-loop workflows [4], [7], [13], where engineers iteratively guide the model, enhancing correctness but limiting scalability. In contrast, Spec2RTL-Agent reduces human intervention through structured reasoning and iterative refinement within multi-agent framework. Another line of work targets synthesizable C++ for HLS, offering higher level of abstraction [22], [23]. However, these methods assume well-structured inputs and lack iterative correction, making Fig. 2. Visualization of representative specification document used as input for our target problem. The expected specification document consists of multi-modal information (e.g., tables, figures, and equations) in lengthy and unstructured manner. them less suitable for raw specifications. Spec2RTL-Agent improves automation robustness by refining intermediate representations prior to synthesis. B. LLM Agents Recent advances in LLMs have enabled multi-agent systems for complex tasks such as code generation, mathematical proof, and story writing [24][28]. Multi-agent collaboration has been shown to outperform single-agent reasoning [24], [28]. AgentCoder [29] iteratively refines code through agent interactions, and AutoSafeCoder [30] enhances security with static analysis and fuzz testing. In the RTL domain, VerilogCoder [11] introduces graph-based planning and syntax-tree tracing, while ChatCPU [13] uses human-LLM collaboration to accelerate complex designs. These methods still rely heavily on human input, motivating our development of fully autonomous LLM-agent system for RTL code generation. C. Automated Hardware Design Methods Beyond LLMs, RTL design has been explored via heuristic and search-based techniques, including genetic algorithms and reinforcement learning [31][33]. MCTS has been combined with LLMs to address synthesis failures and improve power, performance, and area (PPA) metrics [34]. However, such methods typically depend on structured constraints and fixed inputs. Spec2RTL-Agent instead couples language-driven reasoning with iterative refinement, enabling robust automation from unstructured specifications. A. Problem Definition III. PRELIMINARY The goal of this work is to develop an end-to-end framework that generates functionally correct RTL implementations directly from hardware specification documents while minimizing human intervention. Unlike structured benchmarks such as VerilogEval [5], realworld hardware specifications contain unstructured, multi-modal information, making them difficult for existing LLM-based approaches to process effectively. These methods either rely on structured inputs or operate in single-pass manner, leading to errors that require extensive human debugging [11], [13]. We define the key aspects of this problem as follows: Goal: The system should automate RTL generation from raw specification documents, significantly reducing human effort in hardware design while ensuring correctness and consistency. Input: hardware specification document in its original form, without manual simplifications. These documents typically contain extensive, unstructured content, including figures, tables, and equations  (Fig. 2)  , making them fundamentally different from structured prompts used in prior LLM-based RTL generation benchmarks. Output: functionally correct RTL implementation that satisfies the constraints and functional requirements specified in the input document. Expected Level of Automation: The system should autonomously perform the majority of RTL development tasks, requiring minimal human intervention, with each intervention limited to high-level guidance or addressing cases beyond the models reasoning capabilities. Additionally, it should summarize key issues encountered during the process, reducing the burden on human developers and minimizing the need for extensive manual corrections across multiple iterations. B. Identified Challenges Given the capability of current LLMs, we identify the following challenges that must be addressed to tackle the problem defined above: Challenge 1: Understanding and Reasoning. fundamental challenge is the comprehensive understanding of complex, unstructured, and multi-modal information presented in specification documents and translating this into structured, actionable implementation plans. Current LLM-based approaches typically perform single LLM inference pass, which is insufficient for handling the intricacies of such data, resulting in heavy reliance on human intervention for guidance during the implementation process [7], [13], [35]. Challenge 2: Multi-Module Code Generation: The complexity of generating complete RTL implementations in single attempt exceeds the current capabilities of LLMs, particularly due to their limitations in producing long output sequences [36], [37]. Therefore, it is essential to develop method that enables controlled, stepwise generation of multi-module implementations, while ensuring logical consistency and seamless integration across these modules. Challenge 3: Error Detection and Correction: The multimodule and multi-step generation approach significantly complicates error detection, critical aspect of the RTL implementation process. This is because errors may not only arise from the current segment of the code but also from previously implemented functions or even the initial implementation plan. Existing methods typically focus on error debugging within simplified, single-module scenarios [9], [11], [38], proving inadequate for managing the complexities inherent in comprehensive RTL designs. IV. THE PROPOSED SPEC2RTL-AGENT SYSTEM A. Overview To address the challenges outlined in Sec. III-B, we propose Spec2RTL-Agent, novel multi-agent framework designed to automate RTL generation directly from complex, unstructured specification documents. Unlike prior methods that either generate RTL in single step [5], [11] or assume well-structured high-level descriptions for HLS [22], Spec2RTL-Agent introduces an iterative processing pipeline that systematically refines RTL implementations through multi-stage reasoning, code generation, and error correction. As illustrated in Fig. 3, Spec2RTL-Agent operates through three key enablers: 1) Iterative Understanding and Reasoning Module (Sec. IV-B): Initially, the specification document undergoes analysis by the iterative understanding and reasoning module, which features propose-and-verify-based collaboration document understanding and reasoning pipeline. This module systematically decomposes the target function into multiple sub-functions, each formatted in an LLM-friendly manner to effectively address Challenge 1: Understanding and Reasoning. 2) Progressive Coding and Prompt Optimization Module (Sec. IV-C): Following the plan, the system sequentially implements each sub-function using the progressive coding and prompt optimization module. This module utilizes cross-level code referencing and prompt revision techniques to enable structured and efficient multi-module implementation, thereby alleviating Challenge 2: Multi-Module Code Generation. 3) Adaptive Reflection Module (Sec. IV-D): As module implementation progresses, the limited availability of test cases for each sub-function complicates the verification of correctness. The adaptive reflection module dynamically identifies and addresses sources of errors across all generated sub-functions and even within the instructions, aiming to ensure robust and error-free generation process as outlined in Challenge 3: Error Detection and Correction. 4) Code Optimization and Conversion (Sec. IV-E): Upon completing all sub-functions, code optimization agent reformats the implementation for compatibility with the HLS tool. The system then utilizes the HLS tool to convert the processed implementation into the target RTL code. We will introduce each key module in the following sections. B. Iterative Understanding and Reasoning Module The iterative understanding and reasoning module is designed to transform the original, lengthy, unstructured, and LLM-unfriendly specification document into concise, structured, and LLM-friendly implementation plan. This transformation is facilitated by multiagent collaboration pipeline, which iteratively verifies and refines the content to gradually convert and organize the necessary information in structured format. The process within this module consists of three stages: Summarization: Firstly, we aim to alleviate the burden on subsequent agents in directly processing the entirety of the lengthy specification document by condensing the information contained in each section. Summarization Agent is employed to generate concise summaries for each section of the document, thereby simplifying the initial comprehension process and reducing the complexity for further processing. Decomposition: Building on the summarized information, we initiate the reasoning process by breaking down the complex target function into manageable sub-functions. Decomposer Agent receives both the summarized data and the original document, tasked with organizing the target implementation into sequence of implementable sub-functions. Information Augmentation: The final stage aims to supplement each decomposed sub-function with the necessary details to Fig. 3. Overview of our proposed Spec2RTL-Agent system. facilitate direct implementation by subsequent modules, without the need to refer back to the original document. This task is accomplished through the cooperative efforts of Description Agent and Verifier.The Description Agent uses the original document, the summaries provided, and specific sub-function requirements as inputs to collate and format the necessary information into structured dictionary. This dictionary includes key elements such as inputs, outputs, functionality, and pertinent references from the original document. The Verifier then reviews this dictionary, providing feedback to enhance the quality and accuracy of the information. This collaborative approach ensures that each sub-function is equipped with complete and precise implementation details. Upon completion of these stages, the iterative understanding and reasoning module forwards the refined decomposition plan and the associated information for each sub-module to the subsequent Progressive Coding and Prompt Optimization Module to start code implementation. C. Progressive Coding and Prompt Optimization Module The progressive coding and prompt optimization module is responsible for implementing the code based on the decomposition plan and associated information generated from the iterative understanding and reasoning module. This module sequentially constructs each subfunction and integrates them into comprehensive implementation. Within this module, we have developed two innovative techniques to enhance accuracy and efficiency: Progressive Coding: Inspired by the varying proficiency levels of LLMs in handling different programming languages, from high-level to low-level code, we leverage higher-level code as reference to guide the generation of corresponding lower-level implementations. The process involves sequentially generating pseudocode, Python, and C++ code. For each sub-function, Coder first drafts the code and Verifier then assesses its accuracy, suggesting necessary revisions or complete regeneration when needed. The Verifier either derives test cases from the specification document or utilizes those created from previously implemented higher-level code. In scenarios where external test cases are unavailable, the Verifier performs self-validation by directly comparing the implementation against the original specifications. Prompt Optimization: The iterative interaction between the Coder and Verifier, involving repeated code generation and revisions for each sub-function, may lead to inefficiencies. To streamline this process and enhance cost-effectiveness, we introduce Prompt Optimizer Agent. This agent analyzes the implementation log for the current sub-function, extracts learnings, and refines the prompts used by the Coder to enhance the accuracy and efficiency of subsequent coding attempts. D. Adapative Reflection Module Despite the effectiveness of the progressive coding and prompt optimization module, the absence of sub-function-specific test cases can hinder the accurate identification of implementation errors. This often results in scenarios where newly implemented sub-function fails to pass test cases due to errors in previously implemented sub-functions. To address this challenge and enhance the robustness and error-tolerance of the implementation pipeline, we introduce the adaptive reflection module. The adaptive reflection module operates in two primary stages: Error Source Analysis: An Analysis Agent first reviews the entire generation trajectory to summarize the completed work and propose potential areas where errors may reside. Error Resolution Direction: Following this analysis, Reflection Agent evaluates the summarized information and potential error sources. It then determines the most appropriate course of action from four possible strategies: If the error originates from incorrect instructions, the agent redirects the issue to the iterative understanding and reasoning module to revise the instructions for the affected sub-function. If the error stems from previous sub-functions, the Reflection Agent returns to the identified sub-functions to make necessary revisions, using the current failing test cases as guidance. If the error is confined to the current sub-function and unrelated to previous outputs, the Reflection Agent restarts the generation of this sub-function within the progressive coding and prompt optimization module, providing targeted feedback to the Coder to avoid repeating the error. If the error source remains unclear, the agent escalates the issue for human intervention, summarizing the situation and requesting guidance on corrective measures. E. Code Optimization and Conversion Module Upon the completion of all sub-functions as per the implementation plan, the next critical step involves converting the implemented C++ code into RTL using leading commercial HLS tool, Stratus HighLevel Synthesis (Stratus HLS) [39]. To ensure compatibility with the HLS tool, which has specific coding format requirements, we introduce Code Optimizer Agent. This agent adapts the C++ code to meet the HLS tools constraints based on guidelines extracted from the tutorial of this HLS tool. Key adaptations include conforming to data format restrictions and optimizing for static memory usage. The TABLE BENCHMARKING SPEC2RTL-AGENT WITH BASELINE SOLUTIONS ON DIFFERENT FIPS DOCUMENTS. Method Correct # Intervention # Coding Human Single-Shot W/o Understand Naive Coding W/o Reflection Spec2RTL-Agent 3/3 20 20 0/ / / 2/3 18.67 15.53 3/ 9.00 17.46 3/3 6.33 13.20 3/ 4.33 9.11 Code Optimizer Agent systematically applies these rules to prepare the code for efficient and error-free high-level synthesis. A. Evaluation Setting V. EXPERIMENTS Benchmark: To evaluate the effectiveness of our Spec2RTL-Agent framework, we have chosen subset of three standard specification documents from the Federal Information Processing Standards (FIPS) developed by NIST. These documents include the Advanced Encryption Standard (AES) [40], Digital Signature Standard (DSS) [41], and Keyed-Hash Message Authentication Code (HMAC) [42]. This selection aims to provide robust evaluation across set of representative RTL generation scenarios. Evaluation Metrics: To comprehensively assess the performance of our RTL generation system, we consider the following metrics: (1) Correct: Functional correctness of the generated RTL implementation, (2) # Intervention: Number of human interventions required to achieve correct functionality, and (3) # Coding: Average number of code generation and revision attempts needed per sub-function. Baselines: Given that our proposed Spec2RTL-Agent is pioneering system for automating end-to-end RTL generation from specification documents, direct baselines are scarce. Therefore, we have established the following baselines to benchmark its performance: (1) Single-Shot: The entire specification document is input into an LLM, which is tasked with generating the target RTL in single attempt. (2) Human: Mirroring approaches like that in [7], human handles the understanding and reflection phases while delegating code implementation to an LLM based on provided instructions. (3) W/o Understand: This variation of our pipeline omits the iterative understanding and reasoning module, directly feeding the entire document into the coding module to complete the implementation. (4) Naive Coding: This configuration removes the progressive coding and prompt optimization module, replacing it with naive C++ coding module. This module directly generates the C++ code for each target sub-function using the information provided, without iterative enhancements or optimizations. (5) W/o Reflection: This configuration bypasses the adaptive reflection module. Errors must be addressed by the LLM within the current sub-function without the capability to revisit previously implemented sub-functions or instructions. Implementation Details: In our study, we use GPT-4o [43] as the core architecture for all agents, with agent interactions and tool usage managed via the AutoGen framework [26]. Due to LLMs limitations text using PyPDF and capture in processing PDFs, we extract screenshots for figures and tables. All extracted data is compiled and fed into the LLM. During code generation, the full target code often exceeds LLMs generation limits, making it impractical to regenerate the entire file for every sub-function update. To address this, agents generate only the modified sub-function, mark it with 20 asterisks (*), and label its start with the sub-function name. rule-based approach then locates and replaces the corresponding sub-function in the code file. We use Stratus HLS [39] as our HLS tool. B. Benchmarking Spec2RTL-Agent on Specification Documents We evaluated Spec2RTL-Agent against baseline approaches using selected benchmark specification documents. As shown in Table I, TABLE II PERFORMANCE OF SPEC2RTL-AGENT ACROSS DIFFERENT DOCUMENTS."
        },
        {
            "title": "HMCA",
            "content": "# Intervention 4 6 3 # Coding 8. 9.31 9.52 Spec2RTL-Agent consistently outperformed baselines across various metrics. The Single-Shot approach, which directly prompts LLMs to generate implementations, failed in all three test cases, underscoring the complexity of the task. In contrast, Spec2RTL-Agent transformed an otherwise ineffective process into an efficient pipeline for generating complex RTL implementations. Regarding human effort reduction, Spec2RTL-Agent significantly lowered the need for intervention compared to the Human baseline, where humans handle understanding, reasoning, and reflection while LLMs only implement code [7]. Specifically, Spec2RTL-Agent reduced human interventions by approximately 75%, easing the burden of RTL implementation and enhancing development efficiency. detailed performance breakdown across specification documents is shown in Table II. Despite document diversity, Spec2RTL-Agent effectively implemented RTL with around five human interventions and fewer than ten code revision attempts per sub-function. To further validate its RTL generation quality, we compared the achievable latency, throughput, and area of our generated AES engine with modified open-source AES solutions, ensuring HLS compatibility. Using Stratus HLS [39] across multiple configurations, our solution achieved comparable performance metrics. C. Ablation Study on the Effectiveness of Each Module To assess the contributions of individual modules in Spec2RTLAgent, we benchmarked against three baselines, each omitting system module. As shown in Table I, removing the iterative understanding and reasoning module (W/o Understanding) led to more than fourfold increase in human interventions, underscoring its importance in planning. Compared to W/o Reflection and Naive Coding, our full Spec2RTL-Agent reduced human interventions by 51.9% and 31.6%, and coding iterations by 47.8% and 31.0%, respectively. These results confirm the effectiveness of each module in improving code accuracy. D. Ablation Study on the Robustness to Generation Noise During the extended generation process, previously generated content may contain errors that propagate through subsequent stages. To assess Spec2RTL-Agents robustness against generation noise, we systematically introduce controlled semantic errors at different implementation levels. After each stage, we prompt the LLM to revise its output while embedding subtle but critical logical flaws: Revise the generated implementation while introducing subtle but impactful mistake. The mistake should not be syntax error but rather semantic flaw that could lead to functional misbehavior. Ensure that the revised implementation remains coherent and well-structured. We evaluate the impact of these errors across the implementation plan and three levels of code refinement. As shown in Table III, Spec2RTLAgent demonstrates strong resilience, consistently generating correct implementations while maintaining stable efficiency in #Intervention TABLE III ABLATE ON ROBUSTNESS TO GENERATION NOISE. Python Understanding Pseudocode None Noise Loc. Correct # Intervention # Coding 3/ 4.33 9.11 3/3 6.00 11.42 3/ 4.67 9.31 3/3 4.67 9.42 C++ 3/3 5.33 9.88 Fig. 4. Visualization of the generated information dictionary cipher function in the AES implementation. and #Coding metrics. These results highlight the systems ability to recover from local inconsistencies and maintain high-quality output despite intentional perturbations. E. Visualization on the Generation Process To elucidate the generation process of our proposed Spec2RTLAgent, we present the following visualizations, offering insights into its operational workflow. Information Dictionary. We visualize the generated information dictionary for sub-functions within the AES cipher function, as shown in Fig. 4. Through the iterative understanding and reasoning module in Spec2RTL-Agent, unstructured and complex information from the specification document is transformed into structured representations. These representations explicitly define key attributes for each subfunction, such as inputs, outputs, and functionality, while referencing the original text. The effectiveness of this module is demonstrated in Table I, highlighting its role in organizing and clarifying essential details to enhance the generation process. Prompt Optimization. To illustrate the impact of prompt optimization, we depict its process and outcomes in Fig. 5. Initially, concise base prompt is supplemented with sub-function-specific prompt (upper half of Fig. 5) to generate sub-function implementations. However, repeated failures to pass test cases prompt the optimizer agent to iteratively refine its strategy by analyzing errors and adjusting the prompt accordingly. As shown in the lower half of Fig. 5, the AddRoundKey() function often exhibits interface mismatches with the higher-level cipher function, particularly in input-output dimensions. Recognizing these patterns, the optimizer integrates input-output compatibility details into the revised prompt, improving alignment with test case requirements. This adaptive Fig. 5. Visualizing the prompt used to generate Python code for the AddRoundKey() function before and after prompt optimization. Fig. 6. Visualizing two representation cases that human intervention is needed. approach demonstrates the systems ability to enhance generation quality through iterative self-supervised adjustments. Human Intervention Scenarios. We also visualize cases where human intervention is needed based on the reflection agent. As shown in Fig. 6, when the reflection agent observes that an issue cannot be resolved, it provides its observations, attempts to solve the problem, and the questions it wants to ask human for intervention. Specifically, we observe that scenarios requiring human intervention typically fall into one of two categories: (1) an inaccurate description in the specification document (i.e., scenario 1 in Fig. 6) or (2) the need for more advanced debugging technique, as the generated test case cannot effectively identify the error (i.e., scenario 2 in Fig. 6). Moreover, we find that even when the reflection agent cannot determine proper solution and requires human intervention, it often provides good understanding of the situation. For instance, in scenario 2, the agent identifies that the error originates from previous sub-function but, due to the limited test cases, cannot pinpoint the exact sub-function responsible. This demonstrates the effectiveness of the adaptive reflection module in analyzing and identifying the source of errors, despite its relatively simple design. Performance Evaluation For comparison, we modified some open-source implementations of AES for compatibility with HLS and compared the performance to our generated code. Our generated code achieved comparable latency, throughput, and area under multiple HLS configurations. We recognized that further optimization could be done at our agent level to improve the performance of the generated code further. We will leave that to future work. VI. CONCLUSION AND FUTURE WORKS We present Spec2RTL-Agent, an LLM-based agent system for end-to-end RTL code generation from complex specifications with minimal human intervention. By integrating iterative understanding and reasoning, progressive coding and prompt optimization, and adaptive reflection, Spec2RTL-Agent significantly enhances automation and efficiency, offering promising pathway to boost hardware design productivity and support agile development. Despite its significant progress, Spec2RTL-Agent has limitations and points to future directions: (1) Reducing Human Intervention: While it minimizes manual is still required for input, some involvement optimal RTL implementation (see Fig. 6). Further advancements in automation could enable fully autonomous RTL code generation. (2) Improving Efficiency: Spec2RTL-Agent requires 10 iterations per sub-function, which consumes nontrivial number of tokens and can cause inefficiencies. Strategies to optimize token economy can be considered in further innovations. [23] S. Swaroopa, R. Mukherjee, A. Debnath, and R. S. Chakraborty, Evaluating large language models for automatic register transfer logic generation via high-level synthesis, arXiv preprint arXiv:2408.02793, 2024. [24] G. Chen, S. Dong, Y. Shu, G. Zhang, J. Sesay, B. F. Karlsson, J. Fu, and Y. Shi, Autoagents: framework for automatic agent generation, arXiv preprint arXiv:2309.17288, 2023. [25] S. Yuan, K. Song, J. Chen, X. Tan, D. Li, and D. Yang, Evoagent: Towards automatic multi-agent generation via evolutionary algorithms, arXiv preprint arXiv:2406.14228, 2024. [26] Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang, S. Zhang, J. Liu et al., Autogen: Enabling next-gen llm applications via multi-agent conversations, in First Conference on Language Modeling. [27] Y. Talebirad and A. Nadiri, Multi-agent collaboration: Harnessing the power of intelligent llm agents, arXiv preprint arXiv:2306.03314, 2023. [28] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei, and H. Ji, Unleashing cognitive synergy in large language models: task-solving agent through multipersona selfcollaboration. arxiv 2023, arXiv preprint arXiv:2307.05300. [29] D. Huang, J. M. Zhang, M. Luck, Q. Bu, Y. Qing, and H. Cui, Agentcoder: Multi-agent-based code generation with iterative testing and optimisation, arXiv preprint arXiv:2312.13010, 2023. [30] A. Nunez, N. T. Islam, S. K. Jha, and P. Najafirad, Autosafecoder: multi-agent framework for securing llm code generation through static analysis and fuzz testing, arXiv preprint arXiv:2409.10737, 2024. [31] A. Sohrabizadeh, C. H. Yu, M. Gao, and J. Cong, Autodse: Enabling software programmers to design efficient fpga accelerators, ACM Transactions on Design Automation of Electronic Systems (TODAES), vol. 27, no. 4, pp. 127, 2022. [32] R. Alur, R. Bodik, G. Juniwal, M. M. Martin, M. Raghothaman, S. A. Seshia, R. Singh, A. Solar-Lezama, E. Torlak, and A. Udupa, Syntax-guided synthesis. IEEE, 2013. [33] T. Chen, Z. He, and M. Ciocarlie, Hardware as policy: Mechanical and computational co-optimization using deep reinforcement learning, arXiv preprint arXiv:2008.04460, 2020. [34] M. DeLorenzo, A. B. Chowdhury, V. Gohil, S. Thakur, R. Karri, S. Garg, and J. Rajendran, Make every move count: Llm-based high-quality rtl code generation using mcts, arXiv preprint arXiv:2402.03289, 2024. [35] K. Chang, Y. Wang, H. Ren, M. Wang, S. Liang, Y. Han, H. Li, and X. Li, Chipgpt: How far are we from natural language hardware design, arXiv preprint arXiv:2305.14019, 2023. [36] G. Xiao, Y. Tian, B. Chen, S. Han, and M. Lewis, Efficient streaming language models with attention sinks, arXiv preprint arXiv:2309.17453, 2023. [37] G. Xiao, J. Tang, J. Zuo, J. Guo, S. Yang, H. Tang, Y. Fu, and S. Han, Duoattention: Efficient long-context llm inference with retrieval and streaming heads, arXiv preprint arXiv:2410.10819, 2024. [38] K. Xu, J. Sun, Y. Hu, X. Fang, W. Shan, X. Wang, and Z. Jiang, Meic: Re-thinking rtl debug automation using llms, arXiv preprint arXiv:2405.06840, 2024. [39] Cadence Design Systems, Inc., Stratus High-Level Synthesis, Accessed 2024, high-level synthesis tool for designing hardware systems. [Online]. Available: https://www.cadence.com [40] National Institute of Standards and Technology (NIST), Advanced encryption standard (aes), FIPS PUB 197, November 2001. [Online]. Available: https://doi.org/10.6028/NIST.FIPS.197 [41] , Digital signature standard (dss), FIPS PUB 186-5, February 2023. [Online]. Available: https://doi.org/10.6028/NIST.FIPS.186-5 The [42] , FIPS https://doi.org/10.6028/NIST.FIPS.198-1 keyed-hash message 198-1, PUB July authentication code 2008. [Online]. (hmac), Available: [43] OpenAI, Gpt-4, https://platform.openai.com/docs/models/gpt-4, (Accessed on 04/10/2023)."
        },
        {
            "title": "REFERENCES",
            "content": "[1] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, and E. P. Xing, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. [Online]. Available: https://lmsys.org/blog/202303-30-vicuna/ [2] OpenAI, Gpt-3.5, https://platform.openai.com/docs/models/gpt-3-5, (Accessed on 04/10/2023). [3] GitHub, Inc., Github copilot, 2021, accessed: date-of-access. [Online]. Available: https://copilot.github.com [4] Y. Fu, Y. Zhang, Z. Yu, S. Li, Z. Ye, C. Li, C. Wan, and Y. Lin, Gpt4aigchip: Towards next-generation ai accelerator design automation via large language models, arXiv preprint arXiv:2309.10730, 2023. [5] M. Liu, N. Pinckney, B. Khailany, and H. Ren, Verilogeval: Evaluating large language models for verilog code generation, arXiv preprint arXiv:2309.07544, 2023. [6] Y. Lu, S. Liu, Q. Zhang, and Z. Xie, Rtllm: An open-source benchmark for design rtl generation with large language model, arXiv preprint arXiv:2308.05345, 2023. [7] J. Blocklove, S. Garg, R. Karri, and H. Pearce, Chip-chat: Challenges and opportunities in conversational hardware design, arXiv preprint arXiv:2305.13243, 2023. [8] Z. He, H. Wu, X. Zhang, X. Yao, S. Zheng, H. Zheng, and B. Yu, Chateda: large language model powered autonomous agent for eda, arXiv preprint arXiv:2308.10204, 2023. [9] H. Huang, Z. Lin, Z. Wang, X. Chen, K. Ding, and J. Zhao, Towards llm-powered verilog rtl assistant: Self-verification and self-correction, arXiv preprint arXiv:2406.00115, 2024. [10] M. Liu, Y.-D. Tsai, W. Zhou, and H. Ren, Craftrtl: High-quality synthetic data generation for verilog code models with correct-byconstruction non-textual representations and targeted code repair, arXiv preprint arXiv:2409.12993, 2024. [11] C.-T. Ho, H. Ren, and B. Khailany, Verilogcoder: Autonomous verilog coding agents with graph-based planning and abstract syntax tree (ast)- based waveform tracing tool, arXiv preprint arXiv:2408.08927, 2024. [12] P. Xu, X. Zhang, C. Hao, Y. Zhao, Y. Zhang, Y. Wang, C. Li, Z. Guan, D. Chen, and Y. Lin, Autodnnchip: An automated DNN chip predictor and builder for both fpgas and asics, CoRR, vol. abs/2001.03535, 2020. [Online]. Available: https://arxiv.org/abs/2001.03535 [13] X. Wang, G.-W. Wan, S.-Z. Wong, L. Zhang, T. Liu, Q. Tian, and J. Ye, Chatcpu: An agile cpu design and verification platform with llm, in Proceedings of the 61st ACM/IEEE Design Automation Conference, 2024, pp. 16. [14] nAO.Design, Key stages of hardware product development, https://nao.design/blog/key-stages-of-hardware-product-development, 2024, accessed: 2024-11-18. [15] EnCata, Overview of the hardware product development stages: Poc, https://www.encata.net/blog/overview-of-the-hardware-productdevelopment-stages-explained-poc-evt-dvt-pvt, n.d., accessed: 2024-1118. [16] Dynedge, of https://dynedge.com/key-phases-hardware-product-development/, accessed: 2024-11-18. development, n.d., hardware product phases Key [17] C. Deng, Y.-D. Tsai, G.-T. Liu, Z. Yu, and H. Ren, Scalertl: Scaling llms with reasoning data and test-time compute for accurate rtl code generation, arXiv preprint arXiv:2506.05566, 2025. [18] Y. Zhang, Z. Yu, Y. Fu, C. Wan, and Y. C. Lin, Mg-verilog: Multigrained dataset towards enhanced llm-assisted verilog generation, in 2024 IEEE LLM Aided Design Workshop (LAD). IEEE, 2024, pp. 15. [19] M. Liu, T.-D. Ene, R. Kirby, C. Cheng, N. Pinckney, R. Liang, J. Alben, H. Anand, S. Banerjee, I. Bayraktaroglu et al., Chipnemo: Domainadapted llms for chip design, arXiv preprint arXiv:2311.00176, 2023. [20] C. Deng, Y. Bai, and H. Ren, Chipalign: Instruction alignment in large language models for chip design via geodesic interpolation, arXiv preprint arXiv:2412.19819, 2024. [21] S. Liu, W. Fang, Y. Lu, J. Wang, Q. Zhang, H. Zhang, and Z. Xie, Rtlcoder: Fully open-source and efficient llm-assisted rtl code generation technique, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2024. [22] C. Xiong, C. Liu, H. Li, and X. Li, Hlspilot: Llm-based high-level synthesis, arXiv preprint arXiv:2408.06810, 2024."
        }
    ],
    "affiliations": [
        "Cadence San Jose, CA",
        "Georgia Institute of Technology Atlanta, GA",
        "Nvidia Research Austin, TX"
    ]
}