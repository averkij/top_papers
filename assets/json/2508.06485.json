{
    "paper_title": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion",
    "authors": [
        "Sofiane Bouaziz",
        "Adel Hafiane",
        "Raphael Canals",
        "Rachid Nedjai"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Urbanization, climate change, and agricultural stress are increasing the demand for precise and timely environmental monitoring. Land Surface Temperature (LST) is a key variable in this context and is retrieved from remote sensing satellites. However, these systems face a trade-off between spatial and temporal resolution. While spatio-temporal fusion methods offer promising solutions, few have addressed the estimation of daily LST at 10 m resolution. In this study, we present WGAST, a Weakly-Supervised Generative Network for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra MODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning framework designed for this task. It adopts a conditional generative adversarial architecture, with a generator composed of four stages: feature extraction, fusion, LST reconstruction, and noise suppression. The first stage employs a set of encoders to extract multi-level latent representations from the inputs, which are then fused in the second stage using cosine similarity, normalization, and temporal attention mechanisms. The third stage decodes the fused features into high-resolution LST, followed by a Gaussian filter to suppress high-frequency noise. Training follows a weakly supervised strategy based on physical averaging principles and reinforced by a PatchGAN discriminator. Experiments demonstrate that WGAST outperforms existing methods in both quantitative and qualitative evaluations. Compared to the best-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves SSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and effectively captures fine-scale thermal patterns, as validated against 33 ground-based sensors. The code is available at https://github.com/Sofianebouaziz1/WGAST.git."
        },
        {
            "title": "Start",
            "content": "1 5 2 0 2 8 ] . [ 1 5 8 4 6 0 . 8 0 5 2 : r WGAST: Weakly-Supervised Generative Network for Daily 10 Land Surface Temperature Estimation via Spatio-Temporal Fusion Sofiane Bouaziz, Adel Hafiane, Raphael Canals, Rachid Nedjai AbstractUrbanization, climate change, and agricultural stress are increasing the demand for precise and timely environmental monitoring. Land Surface Temperature (LST) is key variable in this context and is retrieved from remote sensing satellites. However, these systems face trade-off between spatial and temporal resolution. While spatio-temporal fusion methods offer promising solutions, few have addressed the estimation of daily LST at 10 resolution. In this study, we present WGAST, Weakly-Supervised Generative Network for Daily 10 LST Estimation via Spatio-Temporal Fusion of Terra MODIS, Landsat 8, and Sentinel-2. WGAST is the first endto-end deep learning framework designed for this task. It adopts conditional generative adversarial architecture, with generator composed of four stages: feature extraction, fusion, LST reconstruction, and noise suppression. The first stage employs set of encoders to extract multi-level latent representations from the inputs, which are then fused in the second stage using cosine similarity, normalization, and temporal attention mechanisms. The third stage decodes the fused features into high-resolution LST, followed by Gaussian filter to suppress high-frequency noise. Training follows weakly supervised strategy based on physical averaging principles and reinforced by PatchGAN discriminator. Experiments demonstrate that WGAST outperforms existing methods in both quantitative and qualitative evaluations. Compared to the best-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves SSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and effectively captures fine-scale thermal patterns, as validated against 33 ground-based sensors. The code is available at https://github.com/Sofianebouaziz1/WGAST.git. Index TermsSpatio-temporal fusion, land surface temperature, spatial resolution, temporal resolution, generative adversarial networks. I. INTRODUCTION LIMATE change, rapid urbanization, and increasing environmental pressures are reshaping the dynamics of our planet with unprecedented speed [1]. Cities are expanding both in size and density, which makes issues like the Urban Heat Island (UHI) effect even worse [2]. At the same time, unpredictable weather patterns and changing ecosystems demand consistent attention and monitoring [3]. These phenomena are spatially and temporally complex, and tackling This work was carried out as part of the CHOISIR project funded by Orleans Metropole, and Region Centre-Val de Loire. (Corresponding author: Sofiane Bouaziz). Sofiane Bouaziz and Adel Hafiane are with INSA Centre Val de Loire, Universite dOrleans, PRISME UR 4229, Bourges, 18022, Centre Val de Loire, France (e-mail: sofiane.bouaziz@insa-cvl.fr; adel.hafiane@insa-cvl.fr). Sofiane Bouaziz and Raphael Canals are with Universite dOrleans, INSA CVL, PRISME UR 4229, Orleans, 45067, Centre Val de Loire, France (e-mail: raphael.canals@univ-orleans.fr). Rachid Nedjai is with Universite dOrleans, CEDETE, UR 1210, Orleans, 45067, Centre Val de Loire, France (e-mail: rachid.nedjai@univ-orleans.fr). information them requires reliable, fine-grained geospatial with dense temporal frequency [4]. Detecting, monitoring, and predicting these challenges is essential to support sustainable urban planning [5], public health interventions [6], disaster response [7], and climate adaptation [8]. In this context, access to high-resolution environmental data is not only beneficial but crucial for making timely and informed decisions [9]. Land Surface Temperature (LST) is one of the most important geophysical variables for understanding and analyzing diverse environmental challenges. It is defined as the radiative skin temperature of the land surface, representing the complex interactions among incoming solar radiation, land cover, and atmospheric conditions [10]. LST is widely used across various domains, including climate change analysis [11], natural resource management [12], and urban planning [13]. It is regarded as critical component of Earth system data by NASA [14], and is also identified as one of the ten essential climate variables by the Global Climate Observing System [15]. Remote sensing (RS) satellites remain the primary means for monitoring LST at regional to global scales [16]. These satellites retrieve LST through thermal infrared (TIR) sensors that measure the emitted radiation from the Earths surface, which is then processed to estimate LST [17]. However, current RS satellites face trade-off between spatial and temporal resolution. Spatial resolution refers to the level of surface detail captured within each pixel of an LST measurement [17], while temporal resolution indicates how frequently LST data are acquired for the same geographic area over time [18]. For instance, Terra MODIS provides daily LST data at moderate 1 km resolution, whereas Landsat 8 offers finer 30 resolution but revisits the same area every 16 days. Figure 1 illustrates this trade-off over the same geographic area. Figure 1.a shows how differences in spatial resolution affect the level of detail. is visible For example, on Landsat 8 LST but not distinguishable on Terra MODIS LST. Figure 1.b highlights temporal resolution differences by showing that 16 daily Terra MODIS LST acquisitions occur between two Landsat 8 observations. Achieving high spatial and temporal resolution simultaneously remains challenging, but crucial to accurately capturing dynamic phenomena. the Loire River, Frances longest, To overcome this trade-off, Spatio-Temporal Fusion (STF) techniques have emerged as promising solution. These methods generate high spatial resolution satellite observations at finer temporal frequencies by combining data from different RS satellites with varying spatial and temporal characteristics [19]. Typically, one data source offers high spatial but low temporal resolution (HSLT), while the other provides"
        },
        {
            "title": "Among recent",
            "content": "trends, generative adversarial networks (GANs) [30] have demonstrated notable success in image generation, including STF. In this setting, the generator learns to produce high-resolution fused images. At the same time, the discriminator is trained to distinguish between fused and real high-resolution samples, thus improving the realism and fidelity of the fusion output. Several GAN-based STF approaches have been proposed in the literature. For example, STFGAN [31] frames the STF task as super-resolution problem. GAN-STFM [32] extends this approach by introducing conditional constraints, which enable more flexible and context-aware fusion process. CycleGAN-STF [33] treats STF as data augmentation task and selects the most informative image from cycle-consistent outputs as the final fusion result. MLFF-GAN [34] adopts multilevel strategy by using conditional GAN (cGAN), which models spatiotemporal dependencies across different levels. However, these methods have been primarily designed and validated using SR datasets. Applying them directly to LST is challenging due to the unique characteristics of thermal data [9]. As result, adapting existing GAN-based STF methods to LST requires careful architectural adjustments and methodological considerations to ensure reliable performance. All of the aforementioned STF methods generate fused LST observations at the minimum spatial resolution of the input satellites, which, at best, is 30 m. This resolution is provided by Landsat 8, the satellite offering the finest TIR band available in RS satellite products [35]. While this level of detail is sufficient for certain applications, it falls short in contexts where very high spatial precision is crucial. For example, studies focused on UHI require thermal observations at finer resolutions, such as 10 m, to capture intraurban temperature variations, and resolve narrow urban features like streets and small green spaces [36], [37]. Some recent studies have attempted to generate 10 spatial resolution LST products while maintaining daily temporal frequency. For instance, [38] combines Terra MODIS and Sentinel-2 data using robust least squares regression to produce daily 10 LST. Similarly, [39] introduced mDTSG, which employs convolutionbased moving window to perform the STF between Terra MODIS and Sentinel-2. However, both approaches fall into the category of traditional STF methods and rely on the same linearity assumptions discussed earlier. These assumptions limit their ability to model the complex and spatiotemporal characteristics of LST. Also, the transition in spatial resolution from 1 km Terra MODIS to 10 Sentinel-2 represents 100 increase in detail which is extremely large. Performing fusion directly between these two sources without an intermediate resolution step introduces significant challenges as it amplifies noise and inconsistencies, and may generate unrealistic spatial patterns. Despite this, learning-based STF fusion methods, especially those utilizing DL, to generate daily 10 LST observations remain largely unexplored. The only attempt, FuseTen [40], uses hybrid model that combines cGAN with linear regression by embedding linear model within the generator, which can introduce artifacts and noise in the generated LST. Fig. 1. LST resolution comparison over Orleans Metropole, France. (a) Spatial resolution difference between Terra MODIS and Landsat 8 on 13 Aug 2022. (b) Temporal resolution illustrated by their revisit frequencies. low spatial but high temporal resolution (LSHT) [20]. STF methods were originally developed for producing fine spatiotemporal resolution surface reflectance (SR) imagery [19], [21], but empirical investigations have consistently demonstrated their strong performance when applied to LST estimation [9]. Existing STF approaches can be broadly classified into two main categories: traditional and learning-based methods. Traditional methods include three subtypes: weightedbased, unmixing-based, and hybrid methods. Among these, weighted-based methods are the most widely used. They predict fine spatio-temporal resolution images by leveraging data from spectrally similar neighboring pixels. well-known example is STARFM [22], which incorporates moving windows and spatial similarity to estimate high-resolution observations. Its enhanced version, ESTARFM [23], improves the fusion by distinguishing between mixed and pure pixels. Although initially designed for SR data, these methods have also been adapted for LST. For instance, [24] applied STARFM to fuse Terra MODIS and ASTER data and generate ASTER-like LST products, while [25] employed ESTARFM to blend Terra MODIS and Landsat observations for producing LST at 100 resolution. However, these traditional approaches rely on the key assumption that surface changes follow linear trend over time. This assumption may hold for SR, but fails to accurately capture the non-linear and highly dynamic nature of LST [26]. Consequently, traditional methods often struggle to model the spatio-temporal variability of LST with sufficient accuracy. Learning-based methods eliminate the linear assumption by leveraging data-driven models to capture complex spatiotemporal relationships directly from data. These models are trained using existing datasets to map the interactions between LSHT and HSLT LST. With deep learning (DL) advances, these models have become the most widely used approaches for STF. For example, [27] proposed STTFN, residual multiscale convolutional neural network to estimate fine-resolution LST. [28] utilized conditional variational autoencoder framework to generate fine-resolution LST. More recently, [29] developed two-stage hierarchical fusion model based on the Swin Transformer for enhanced LST estimation. In this work, we address the identified research gap by introducing WGAST, weakly-supervised generative network designed for daily 10 LST estimation via STF. WGAST represents novel deep generative framework and, to the best of our knowledge, is the first non-linear end-to-end DL model that simultaneously fuses Terra MODIS, Landsat 8, and Sentinel-2 observations to produce daily LST estimates at 10 resolution. Our key contributions are summarized as follows: We propose the first non-linear generative model specifically tailored for STF of LST, enabling accurate daily estimation at 10 resolution by integrating coarse 1 km Terra MODIS data with complementary spectral information from Landsat 8 and Sentinel-2. We introduce Landsat 8 as an effective intermediate resolution bridge between Sentinel-2 and Terra MODIS, overcoming the extreme resolution gap and avoiding the direct, error-prone fusion from 1 km to 10 m. We design novel, physically motivated weak supervision strategy that leverages 30 Landsat-derived LST as proxy ground truth, to bypass the challenge of missing ground truth data at 10 resolution. We eliminate the dependence on future observations for predicting the current time step by relying solely on previous reference date. We generate 10 LST with significantly fewer cloudinduced gaps than 30 Landsat 8 by leveraging cloudresilient Terra MODIS observations at the target time. We rigorously validate WGAST on two data sources, satellite and in-situ measurements, and both demonstrate its superiority in quantitative and qualitative evaluations compared to existing methods. II. PROBLEM FORMULATION The STF problem for estimating daily 10 LST can be formulated as follows. Let X1, X2, and X3 denote RS satellites offering complementary spatial and temporal characteristics. We define rs() as the spatial resolution function where lower values indicate finer spatial detail, and rt() as the temporal resolution function where lower values indicate more frequent acquisitions. Let TIR() be predicate function returning true if the RS satellite provides TIR bands. The conditions defined in Equation 1 must be satisfied. rs(X1) > rs(X2) > rs(X3) rt(X1) < rt(X2) rs(X3) = 10 m, rt(X1) = 1 day TIR(X1) = TIR(X2) = true (1) In our setup, X1 corresponds to Terra MODIS, which provides daily LST at 1 km spatial resolution, X2 refers Landsat 8, which offers LST at 30 with 16-day revisit cycle, and X3 denotes Sentinel-2, which delivers SR data at 10 with 5day revisit. These choices satisfy the conditions in Equation 1 and are summarized in Table I. Note that this formulation remains general and can be extended to any other RS missions as long as the conditions in Equation 1 are met. 3 TABLE COMPARISON OF REPRESENTATIVE RS SATELLITES WITH THEIR THERMAL SENSORS, SPATIAL AND TEMPORAL RESOLUTIONS. Satellite Thermal sensor Spatial resolution Temporal resolution Terra Landsat 8 Sentinel-2 MODIS TIRS / 1 km 30 10 1 day 16 days 5 days Given target date t2, the goal is to estimate LST at 10 resolution, denoted as ˆX3(s, t2, LST, r3), where r3 = 10 m. To achieve this, we rely on the Terra MODIS LST observation X1(s, t2, LST, r1) with r1 = 1 km, as well as pervious reference date t1 < t2 chosen such that all three satellites X1, X2, X3 provide minimal cloud coverage observations over geographic region s. At this reference date, we construct prior triple T1 composed of the following observations: Sentinel-2 spectral X3(s, t1, NDVI, r3), X3(s, t1, NDBI, r3). spectral 8 X2(s, t1, NDVI, r2), X2(s, t1, NDBI, r2). Landsat indices at r3 = X3(s, t1, NDWI, r3), 10 m: and indices at r2 = X2(s, t1, NDWI, r2), 30 m: and Landsat 8 LST at r2 = 30 m:X2(s, t1, LST, r2). Terra MODIS LST at r1 = 1 km: X1(s, t1, LST, r1). Where NDVI, NDWI, and NDBI refer to spectral indices that characterize vegetation, water, and built-up surfaces, respectively. Their mathematical formulations are summarized in Table II. These indices are widely used in LST-related studies due to their strong correlation with land surface thermal behavior [41], [42]. While many other indices could be considered, we intentionally limit our selection to these three to ensure diverse yet concise representation of surface types. This prevents introducing redundancy and avoids overloading the model with excessive input features, which could complicate training and hinder convergence. TABLE II FORMULATIONS OF SPECTRAL INDICES FOR LANDSAT 8 AND SENTINEL-2. NIR: NEAR-INFRARED, SWIR: SHORTWAVE INFRARED, RED AND GREEN REFER TO VISIBLE BANDS. Bi DENOTES THE i-TH BAND OF THE CORRESPONDING SATELLITE SENSOR. Index Equation Landsat Sentinel-2 NDVI NDBI NDWI NIRRed NIR+Red SWIRNIR SWIR+NIR GreenNIR Green+NIR B5B4 B5+B4 B6B5 B6+B5 B3B5 B3+B5 B8B4 B8+B4 B11B8 B11+B8 B3B8 B3+B8 Thus, given the prior triple T1 and the Terra MODIS LST at t2, X1(s, t2, LST, r1), the STF task is formulated as the learning of DL network , parameterized by W, to estimate the target LST at 10 resolution, as defined in Equation 2. ˆX3(s, t2, LST, r3) = (T1, X1(s, t2, LST, r1) W) . (2) Here, T1 reflects the spatial and spectral context at the reference time t1, while X1(s, t2, LST, r1) provides the coarse time t2. The resolution thermal information at the target function thus learns to integrate this information and project it into high-resolution thermal estimates ˆX3(s, t2, LST, r3). Note that WGAST relies solely on previous date t1, and thus eliminates the need to wait for future overlapping period. III. METHODOLOGY In this section, we first briefly review the basic structure of GANs and their conditional variant cGAN, as they form the foundation of our proposed approach. We then present the overall architecture WGAST. Finally, we describe in detail its main components: the generator, the weakly supervised learning strategy, and the discriminator. A. Generative Adversarial Networks GANs were first introduced by [30] and are widely regarded as powerful class of deep generative models. They are based on two-player adversarial game between two neural networks: generator and discriminator [43]. The generator aims to synthesize realistic data samples that mimic the distribution of real observations, while the discriminator attempts to distinguish between real data pdata and generated ones G(z), where pz is sampled from latent prior distribution [44]. The discriminator outputs probability map that indicates the likelihood that each input pixel is real or generated. It is optimized to maximize its classification accuracy, as expressed in Equation 3. LD = max Expdata[log D(x)] + Ezpz [log(1 D(G(z)))] (3) In contrast, the generator attempts to produce samples that fool the discriminator into classifying them as real. Its loss is defined in Equation 4. L(G) = min [log D(x) + log(1 D(G(z)))] (4) The overall GAN training can be formulated as minimax optimization problem as expressed in Equation 5. = min max [log D(x) + log(1 D(G(z)))] (5) During training, the generator and discriminator engage in an adversarial interplay, as the generator improves its ability to produce convincing samples, the discriminator must also enhance its capacity to distinguish them from real ones. This iterative process drives both models to co-evolve and become increasingly competent. Theoretically, this dynamic converges to Nash equilibrium [45], where the generator has learned the true data distribution so well that the discriminator can no longer reliably differentiate real from fake. cGANs [46] extend the standard GAN framework by providing additional input information, known as the condition. This condition can take the form of class labels, images, or other contextual data, which guide the generator to produce outputs that are explicitly dependent on this information. As result, cGANs enable more targeted, controllable, and contextaware generation, which is especially valuable for tasks where the output needs to be aligned with specific input modality. B. Overall Architeture The overall architecture of WGAST is illustrated in Figure 2. Our framework is based on cGAN, where the generation process is explicitly conditioned on the Terra MODIS LST observation at the target time. The objective is to estimate the LST at fine spatial resolution of 10 for given geographical region at target time t2. The generated output is denoted as ˆX3(s, t2, LST, r3), where r3 = 10 m. Fig. 2. Overview of the WGAST framework. WGAST consists of generator that fuses data from Terra MODIS (r1 = 1 km), Landsat 8 (r2 = 30 m), and Sentinel-2 (r3 = 10 m) to produce high-resolution LST estimate at 10 m. discriminator ensures the quality of the generated LST by comparing it with the reference Landsat 8 LST at 30 resolution. the target The WGAST framework begins by identifying the overlapping timestep between the three RS satellites, as discussed in Section II, to extract the triple T1. This triple, along with time t2, the Terra MODIS LST observation at X1(s, t2, LST, r1) where r1 = 1 km, is used as input to the generator module. The generator is designed to capture relevant spatio-spectral and spatio-temporal features from the inputs to produce fine-resolution LST observation at 10 for the target date t2. Since no ground-truth LST data at 10 resolution are available, we adopt weakly-supervised strategy motivated by physical principles. Specifically, the generated LST is averaged using 3 3 window to approximate 30 resolution. This output is then fed to the discriminator, which receives both the downsampled generated LST and reference Landsat 8 30 LST, each conditioned on the Terra MODIS LST observation at time t2. Each component of the WGAST is detailed in the following subsections. C. Generator The generator module of WGAST consists of four main stages: feature extraction, feature fusion, LST reconstruction, and noise suppression. 1) Feature extraction: This stage employs set of encoders composed of convolutional layers with downsampling and residual blocks, which are specifically designed to capture spatial and temporal features from the inputs. Batch Normalization layers are intentionally omitted from the residual blocks, as they degrade image synthesis quality in GANs [47]. 5 Fig. 3. Overall architecture of the WGAST Generator composed of four main stages: feature extraction, feature fusion, LST reconstruction, and noise suppression, with r1 = 1 km, r2 = 30 m, and r3 = 10 m. The extracted features are encoded into compact latent representations that enable the fusion stage to operate on the most informative abstractions. Specifically, five encoders are used, each producing multi-level set of features as follows: Encoder 1: 10 Sentinel-2 indices (NDVI, NDBI, NDWI) features at t1, denoted as L1 r3 Encoder 2: 30 Landsat 8 indices (NDVI, NDBI, NDWI) features at t1, denoted as L1 r2 Encoder 3: 30 Landsat 8 LST features at t1, denoted = (cid:8)L1 (cid:9)N r3,i i=0 = (cid:8)L1 (cid:9)N r2,i i= . . Encoder 4: 1 km MODIS LST features at t1, denoted as Encoder 5: 1 km MODIS LST features at t2, denoted as as F1 r2 = (cid:8)F (cid:9)N . r2,i i=0 F1 r1 F2 = (cid:8)F1 (cid:9)N r1,i i=0 = (cid:8)F2 (cid:9)N r1,i i=0 . . Here, denotes the number of multi-level features produced by each encoder. Each feature group captures spatial or temporal characteristics at different levels of abstraction. Based on empirical evaluation, we fixed = 5 to ensure good balance between feature richness and computational efficiency. 2) Feature fusion: The feature fusion process consists of three operations: cosine similarity, normalization, and temporal attention. The first operation, cosine similarity, is defined as follows. Given two feature vectors u, RC, their cosine similarity is computed as expressed in Equation 6. cosinesimilarity(u, v) = u2 v2 (6) Where .2 denotes the L2 norm. This metric measures the cosine of the angle between the two vectors, with values ranging from 1 to 1. value of 1 indicates that the vectors are perfectly aligned in direction, 0 indicates no similarity, and -1 indicates that the vectors are completely dissimilar in opposite directions. In the context of image feature maps, this operation is applied element-wise across the feature space. The goal is to compute similarity score between the multilevel features of Sentinel-2 indices at time t1, L1 r3, and the multi-level features of Landsat 8 indices at the same time, L1 r2 . This score is then used to spatially refine the Landsat 8 LST features F1 r2 , to produce 10 features approximation (cid:110) of LST at time t1, denoted as (cid:101)F1 = , where each r3 level is computed as in Equation 7. (cid:101)F1 (cid:111)N r3,i i=0 (cid:101)F1 r3,i = r2,i cos sim(L1 r2,i, L1 r3,i) (7) Unlike linear models that assume global linear relationship between indices and LST values, cosine similarity is nonlinear measure that captures local, level-wise structural correspondences between feature maps at different resolutions. This allows the refinement process to emphasize features that are both semantically meaningful and spatially aligned, leading to more accurate and context-aware estimations. In the second operation, we employ Adaptive Instance Normalization (AdaIN) [48] to harmonize the statistical distributions between spatially detailed and temporally consistent features. Specifically, we align the structural content of the 10 LST features extracted from the previous step, (cid:101)F1 r3, with the style characteristics of the Terra MODIS LST features at time t2, F2 r1. AdaIN proceeds in two steps. First, each level of (cid:101)F1 r3 is normalized by removing its mean and standard deviation. Then, it is rescaled and shifted using the statistics of the style features (cid:101)F r3 . The operation is expressed in Equation 8. (cid:101)F2 r3 = AdaIN((cid:101)F1 r3 , F2 r1,i) = σ(F2 r1,i) (cid:101)F1 r3 µ((cid:101)F1 r3 σ((cid:101)F1 ) r3 ) (8) +µ(F2 r1,i) Where µ() and σ() denote the mean and standard deviation of feature map level i. temporal attention, r1 and F2 learns how temporal The final step, feature variations, F1 r1 , influence the spatial feature structure. Its goal is to integrate this temporal information into 2 the AdaIN-normalized spatial features r3. This is achieved through spatially adaptive attention mechanism that estimates set of attention weights θ = {θi}N i=0, where each θi [0, 1] represents the relative importance of temporal features at level i. These weights are learned dynamically during training and control the influence of temporal variations in synthesizing the final 10 feature representation at time t2. Specifically, 1 1 convolution followed by batch normalization is applied to the Terra MODIS LST features at time t1 and t2. This transformation projects the features into more compact and discriminative space without altering their spatial resolution, making them more suitable for temporal comparison. It then computes the difference between these features to capture temporal variations. This difference is processed through another 1 1 convolutional layer and sigmoid activation to generate an attention mask. Finally, the mask is used to adaptively fuse the normalized spatial features with the temporal features at t2. The full procedure is detailed in Algorithm 1. 3) LST Reconstruction: The reconstruction stage mirrors the encoder using symmetric U-Net-like architecture with upsampling layers, transposed convolutions, and residual blocks to reconstruct the 10 LST at time t2. It takes as input the temporally-attended spatial features F2 r3 and the original MODIS LST features F2 r1 , concatenated along the channel dimension. Reintroducing F2 r1 at this stage helps preserve large-scale temperature patterns that may have been weakened during earlier fusion and normalization stages steps. The combined features are jointly decoded and progressively refined to produce the 10 LST output, denoted as X3(s, t2, LST, r3). r1: Terra MODIS LST features at time t1 Algorithm 1: Temporal attention-based fusion Input: 1 2 (cid:101)F 2 Output: r1: Terra MODIS LST features at time t2 r3: Normalized spatial features at time t2 2 r3 : 10 LST features at time t2 2 r3 [.] foreach = 1, . . . , do /* Apply convolution with batch normalization to both Terra MODIS features at t1 and F 1 Conv1x1 BN(F 1 r1 2 Conv1x1 BN(F 2 r1 /* Compute the difference between [i]) [i]) the temporal features 1 2 /* Generate attention mask via convolution, BN, and sigmoid activation θi Sigmoid(Conv1x1 BN(F )) /* Compute the weighted sum of spatial features [i] 2 r1 [i] θi + (cid:101)F 2 r3 [i] (1 θi) 2 r3 */ */ */ */ return 2 4) Noise Suppresion: The noise suppression module in the reconreduces high-frequency artifacts present structed LST output X3(s, t2, LST, r3), to produce more spatially and temporally coherent result, denoted as ˆX3(s, t2, LST, r3). This step is essential, as LST in geophysical contexts exhibits smooth, spatially continuous patterns resulting from heat diffusion, rather than abrupt variations or isolated spikes. However, generators, especially those with multiple upsampling layers and skip connections, can unintentionally amplify pixel-level noise and produce unrealistic highfrequency textures that deviate from the expected physical smoothness of LST. To address this, we apply classical Gaussian filter, which smooths the image by convolving it with Gaussian kernel, thereby attenuating local fluctuations while preserving the essential spatial structure and coherence of LST. The Gaussian kernel is defined in Equation 9. (cid:18) (cid:19) x2 + y2 2σ2 G(x, y; σ) = 1 2πσ2 exp where σ is the standard deviation that controls the degree of smoothing. The higher the value of σ, the stronger the smoothing effect. This kernel is centered at the origin and has mean of zero. In WGAST, σ is fixed to 1. (9) , The noise suppression is then carried out by applying Gaussian smoothing filter to the predicted LST through depthwise convolution with fixed kernel as defined in Equation 10. ˆX3(s, t2, LST, r3) = Conv2D(X3(s, t2, LST, r3), G(x, y; τ )), (10) Where G(x, y; τ ) is the two-dimensional Gaussian kernel defined in Equation 9. The kernel size is computed as = 2 3σ + 1. Reflective padding is employed to mitigate boundary artifacts. D. Weakly Supervised Learning In the absence of ground-truth LST data at 10 resolution, we adopt weakly supervised learning strategy guided by physical principles. Prior studies have demonstrated that LST at coarser spatial resolutions can often be approximated by local averages of finer resolution values [49]. Specifically, under the assumption of limited thermal variability within small areas, 30 LST value can be approximated by averaging 3 3 neighborhood of 10 pixels. Leveraging this insight, we apply 3 3 average pooling operation to the generators output ˆX3(s, t2, LST, r3) to produce 30 estimate, as shown in Equation 11. This is then compared to the corresponding upsampled output Landsat 8 LST observation at time t2, X2(s, t2, LST, r2). The Landsat 8 LST is used solely during training. This enables the model to rely exclusively on the temporally frequent Terra MODIS inputs at inference time, thus preserving the 1-day revisit temporal resolution. ˆX3(s, t2, LST, r2)(m, n) = 2 (cid:88) 2 (cid:88) 1 9 i=0 j=0 ˆX3(s, t2, LST, r3)(3m + i, 3n + j) (11) E. Discriminator WGAST discriminator is based on the PatchGAN architecture [30]. Unlike traditional GANs that distinguish real from fake images, here the discriminators task is to differentiate between observed LST data and fused LST outputs. The discriminator receives as input the LST image conditioned on the corresponding Terra MODIS observation X1(s, t2, LST, r1), which provides reliable thermal context at 1 km resolution. This conditioning enhances the discriminators ability to assess whether the target LST image aligns with physically plausible thermal patterns reflected by the MODIS data. The final layer applies softmax function to output probabilities. During training, the discriminator should output probability close to 1 when fed with the observed Landsat 8 LST X2(s, t2, LST, r2) alongside the Terra MODIS input, indicating real LST data. Conversely, it is expected to output probability close to 0 when presented with the fused LST output ˆX3(s, t2, LST, r2) paired with the Terra MODIS LST. F. Loss Functions 1) Discriminator Loss: The discriminator is trained to distinguish between real LST observations and the generated fused LST outputs. The discriminator loss, denoted as LD, is defined in Equation 12. For brevity, we use the notation ˆX3(LST, r2) to represent ˆX3(s, t2, LST, r2), and similarly for X2 and X1. 7 Fig. 4. WGAST discriminator based on the PatchGAN architecture. (cid:20)(cid:16) (cid:17)(cid:17)2(cid:21) + 1 2 1 2 LD = EX2,X1 ˆX3,X1 (cid:16) ˆX3(LST, r2) X1(LST, r2) (cid:104)(cid:0)D (cid:0)X2(LST, r2) X1(LST, r2)(cid:1) 1(cid:1)2(cid:105) (12) Where D() denotes the discriminator. The loss adopts the least-squares GAN formulation [50], which penalizes the discriminator for assigning values far from 0 for fake generated LST and far from 1 for real LST, thereby stabilizing training and mitigating vanishing gradients. The expectations denote averages taken over training samples. 2) Generator Loss: The generator loss, denoted by LG, combines adversarial image-based losses to ensure both realism and fidelity in the fused output. The full loss formulation is given in Equation 13. feedback with several LG = α ˆX3,X1 (cid:124) (cid:20)(cid:16) (cid:17) (cid:16) ˆX3(LST, r2) X1(LST, r2) (cid:123)(cid:122) LGAN (cid:17)2(cid:21) 1 (cid:125) + β (cid:88) k=1 1 (cid:124) (cid:12) (cid:12) (cid:12) (cid:12) ˆX3(LST, r2) X2(LST, r2) (cid:12) (cid:12) (cid:123)(cid:122) Lcontent (cid:125) + γ 1 (cid:124) ˆX3(LST, r2), X2(LST, r2) ˆX3(LST, r2)2 X2(LST, r2)2 (cid:125) (cid:123)(cid:122) Lspectrum + δ 1 MS-SSIM (cid:17) (cid:16) ˆX3(LST, r2), X2(LST, r2) (cid:124) (cid:123)(cid:122) Lvision (cid:125) (13) Where, the adversarial loss LGAN encourages the generator to produce fused LST outputs ˆX3(s, t2, LST, r2) that the discriminator cannot distinguish from real high-resolution LST observations, conditioned on the corresponding low-resolution image X1(s, t2, LST, r1). The content loss Lcontent is computed as the pixel-wise L1 distance between the generated and real high-resolution LST outputs, which promotes numerical accuracy. The spectrum loss Lspectrum, defined as one minus the cosine similarity, preserves the overall spatial variation and temperature distribution. Lastly, the vision loss Lvision is derived from the Multiscale Structural Similarity Index (MSSSIM) and captures perceptual and structural coherence across multiple spatial scales. IV. EXPERIMENTAL RESULTS A. Region of Interest The region of interest (ROI) is located within Orleans Metropole, France. As illustrated in Fig. 5(a1), the ROI is geographically situated between latitudes 475041.77N and 47541.74N, and longitudes 1506.98E and 15936.36E, covering an area of approximately 114 km2. It is traversed by the Loire River, Frances longest river, which plays prominent geographical and thermal role in the region (Fig. 5(a2)). This ROI presents rich mosaic of land cover types, including dense urban areas, open water bodies, natural forests, industrial zones, and crop fields (Fig. 5(b1)(b5)). Such heterogeneity introduces wide range of radiative, thermal, and textural surface characteristics, which pose challenges for accurate LST prediction. Consequently, this makes it suitable benchmark for evaluating the spatial adaptability and generalization capacity of WGAST, particularly in heterogeneous urban settings where LST can vary sharply over short distances. Fig. 5. Geographic overview of the ROI. (a1) Position of the ROI within France. (a2) High-resolution satellite image of the ROI. (b1)(b5) Representative examples of key land cover categories observed in the ROI: urban, water, forest, industrial, and agricultural zones. B. Datasets 1) Satellite Data: The RS satellite data X1, X2, and X3 were obtained from the Google Earth Engine (GEE) platform [51]. Terra MODIS data were accessed from the MOD11A1 (Collection 6.1) daily 1 km product on GEE, which provides atmospherically corrected LST values through the LST Day 1km band, with reported RMSE within 2 for most land cover types [52]. Landsat 8 data were retrieved from the USGS Level-2 Collection 2 Tier 1 dataset on GEE. The thermal band ST B10 was used to obtain LST, which is estimated using single-channel algorithm based on Band 10, with an accuracy of approximately 1.5 [53]. NDVI, NDWI, and NDBI were computed from the SR bands SR B3, SR B4, SR B5, and SR B6. Sentinel-2 imagery was collected from the Harmonized MSI Level-2A collection, which is also atmospherically corrected. NDVI, NDWI, and NDBI were calculated using SR bands B2, B3, B4, B8, and B11. Table III presents the 11 selected samples, each consisting of pervious reference date t1 and target date t2. At t1, we ensured spatial and temporal overlap among Terra MODIS, Landsat 8, and Sentinel-2 acquisitions. At t2, WGAST uses only Terra MODIS LST data as input, while Landsat 8 LST is reserved for evaluation purposes. As an illustrative example, consider the prediction task for 23 Feb 2018. To estimate the 10 LST at this date (t2), WGAST takes as input the Terra MODIS LST at t2, along with the triple T1 extracted from the previous reference date 09 April 2017 (t1). The model then generates fused LST at 10 resolution, which is then upsampled and compared against the Landsat 8 LST acquired on 23 Feb 2018. Notably, the acquisition times of the RS satellites are closely aligned, with maximum time difference of approximately 1 hour and 15 minutes. These overpasses occur within the midmorning window between 10:00 and 12:00 local time, period typically characterized by stable surface and atmospheric conditions. As result, variations in both LST and SR are minimal. This tight temporal alignment further reinforces the suitability of the fusion process. Each observation has resolution of 12001200 pixels for Sentinel-2, which corresponds to 400400 pixels for Landsat-8. All selected samples exhibit cloud contamination levels below 20%. Missing values caused by cloud cover or technical issues were filled using an adaptive spatial interpolation. Specifically, for each missing pixel, local mean filter was applied within 3 3 window centered on the pixel. If no valid neighbors were found, the window size was progressively expanded in steps of 2 until at least one valid neighboring pixel was included. The first 7 samples were used for training, with patch size of 96 96 and stride of 24 for Sentinel-2 (respectively, 32 32 and stride of 8 for Landsat 8), resulting in total of 15, 463 training patches. The remaining 4 samples were reserved for testing. To avoid temporal data leakage and ensure that the model learns meaningful generalization patterns, no overlap was allowed between the reference and target dates across different training samples. Specifically, the reference date t1 of sample was not permitted to match the target date t2 of sample i1, and vice versa. For testing, such constraints were not necessary since each test sample is treated as fully independent from the others. WGAST was trained with learning rate of 2 104 and batch size of 32 on physical server equipped with an NVIDIA RTX A6000 GPU. 2) In-situ Measurement: To validate WGAST under realworld conditions, we leveraged network of 33 ground-based sensors distributed across the ROI, each recording ambient air temperature (Ta) at height of 2.10 meters following standard meteorological protocols. The validation period spanned from 1 April 2025 to 30 May 2025, during which 25 cloudfree Terra MODIS LST images were acquired. Accordingly, WGAST was applied to generate 25 10 LST observations corresponding to these dates. Figure 6 illustrates the spatial distribution of the sensors. It is worth emphasizing that, during the same period, only two Landsat 8 LST acquisitions were available, on 01 May 2025 and 17 May 2025, both of which were partially affected by cloud contamination. Moreover, no usable Landsat 8 data were available for April due to persistent cloud cover and technical issues. In stark contrast, our apTABLE III SUMMARY OF THE 11 SELECTED SAMPLES, EACH CONSISTING OF REFERENCE TIME STEP (t1) AND CORRESPONDING TARGET TIME STEP (t2) USED FOR PREDICTION. Sample No. Reference Date t1 Target Date t2 Date Terra MODIS Landsat Sentinel-2 Date Terra MODIS Landsat 8 1 2 3 4 5 6 7 8 9 10 11 09 Apr 2017 21 Oct 2018 06 Sep 2019 22 Jul 2020 06 Mar 2022 13 Aug 2022 28 May 2023 12 Apr 2024 19 Sep 2024 19 Sep 2024 19 Sep 11:54 11:54 11:54 11:54 11:48 11:42 11:10 10:35 10:00 10:00 10:00 10:40 10:41 10:41 10:41 10:41 10:41 10:40 10:40 10:41 10:41 10:41 11:05 11:06 11:07 11:07 10:57 10:57 11:07 11:07 11:07 11:07 11:07 23 Feb 2018 26 Feb 2019 01 Apr 2020 07 Aug 2020 22 Mar 2022 29 Aug 2022 13 Jun 2023 19 Sep 2024 05 Oct 2024 21 Oct 2024 01 May 2025 11:54 11:54 11:54 11:54 11:48 11:42 10:36 10:00 10:48 10:06 09:30 10:40 10:40 10:40 10:41 10:41 10:41 10:40 10:41 10:41 10:41 10: proach successfully generated 25 cloud-free LST observations at 10 resolution over the same timeframe. Although Ta and LST are fundamentally distinct physical quantities, they are known to exhibit strong radiative coupling, particularly under clear-sky and daytime conditions. This coupling makes air temperature reliable proxy for indirectly assessing the consistency and physical realism of WGASTs fused LST outputs. Field observations revealed that Ta measured by the ground sensors remains relatively stable within 10 spatial window. This stability makes it highly comparable to the 10 resolution LST maps generated by WGAST. Thus, we extracted the exact geographic coordinates of each sensor location from the fused LST maps and assigned the corresponding 10 10 pixel value as the representative LST. This resulted in spatially aligned dataset of paired Ta and LST values. which is expected since the generator has not yet learned the complex spatio-spectral and spatio-temporal relationships within the input data. As training progresses and the generator improves its ability to produce more realistic fused LST images, this loss steadily decreases, reaching around 0.58 by the end of training. In contrast, the discriminator starts with very low loss of about 0.07, which indicates that distinguishing between real and generated LST data is relatively easy at the beginning of training, since the fused LST images are still of low quality. However, as the generator improves and the quality of fused LST images increases, the discriminators task becomes more challenging, resulting in gradual increase in its loss. This opposing behavior reflects the adversarial nature of cGANs. Ultimately, both the generator and discriminator losses tend to stabilize and approach the Nash equilibrium, which indicates that the training process is converging. Fig. 6. Spatial distribution of sensors across the ROI. The central map displays the overall sensor locations marked with orange dots. At the same time, the zoomed-in insets highlight the detailed placement of selected sensors (Sensor 03, Sensor 06, Sensor 13, Sensor 17, Sensor 21, and Sensor 31) within their immediate surroundings. C. Quantitative Assessment Fig. 7. Evolution of generator and discriminator losses during WGATs training. The generator loss decreases steadily as it learns to produce more realistic fused LST, while the discriminator loss increases as its task becomes more challenging. Both losses eventually stabilize. 1) Convergence Analysis: Figure 7 presents the training evolution of both the generator and discriminator losses throughout the adversarial training process. Initially, the generator loss is relatively high, starting at approximately 2.53, 2) Model Performance Analysis: The evaluation of WGAST was conducted over four distinct dates using six well-established metrics. Two of these are error assessment metrics: Root Mean Square Error (RMSE) and Error Relative 10 TABLE IV QUANTITATIVE COMPARISON OF WGAST AGAINST BICUBICI, TEN-ST-GEE [38], AND FUSETEN [40] OVER FOUR DATES. Metric BicubicI Ten-ST-GEE FuseTen WGAST BicubicI Ten-ST-GEE FuseTen WGAST RMSE () SSIM () PSNR () SAM () CC () ERGAS () RMSE () SSIM () PSNR () SAM () CC () ERGAS () 3.637 0.640 15.357 4.841 0.572 4. 2.150 0.770 18.450 3.930 0.494 3.315 19 Sep 2024 05 Oct 2024 3.934 0.526 14.503 6.168 -0.025 4.983 3.220 0.798 18.552 3.865 0.814 3.944 21 Oct 2.342 0.837 24.592 4.689 0.120 3.610 1.905 0.867 21.748 3.033 0.896 2.937 2.609 0.813 21.416 5.410 0.748 3.297 1.482 0.893 25.338 3.650 0.887 2.285 2.451 0.666 17.765 3.162 0.571 4.190 4.724 0.538 16.186 5.823 0.538 4. 2.583 0.621 17.310 6.158 0.113 4.447 1.050 0.863 25.657 2.823 0.901 1.795 01 May 2025 5.340 0.707 21.281 7.625 0.095 5.515 3.234 0.790 19.476 3.918 0.840 3.300 1.384 0.910 24.992 3.579 0.861 2. 2.318 0.838 23.080 3.885 0.826 2.364 Global Dimensionless Synthesis (ERGAS), which quantify the pixel-wise discrepancies between the generated and reference LST. The remaining four are quality assessment metrics: Structural Similarity Index Measure (SSIM), Peak Signal-toNoise Ratio (PSNR), Spectral Angle Mapper (SAM), and Correlation Coefficient (CC), all of which evaluate the perceptual, spectral, and structural fidelity of the results. For performance evaluation, the predicted 10 LSTs were averaged within 33 window to match the 30 resolution, and then validated against the Landsat 8 LST. We compare our approach against three existing methods. The first is BicubicI, which performs straightforward bicubic interpolation to upscale Terra MODIS LST data to Sentinel-2 resolution, in order to produce daily LST at 10 m. The second is Ten-ST-GEE [38], which assumes linear relationship for the fusion task and employs robust least squares fusion of Terra MODIS and Sentinel-2 data within the GEE framework to generate daily LST at 10 resolution. The third is FuseTen [40], which employs hybrid model combining cGAN with linear regression. Table IV presents the quantitative results obtained across the four evaluation dates and the six performance metrics. Note that the task of generating daily 10 LST using full DL model has not been previously addressed in the literature. FuseTen represents the only existing attempt at this spatial resolution by employing hybrid linearDL model. Most existing methods focus on producing daily LST at 30 resolution, and thus were not included in our comparison, as they are not directly applicable to the finer 10 spatial scale targeted by WGAST. On 19 Sep 2024, WGAST outperforms all competing methods across most metrics, with the exception of SAM and CC. Compared to FuseTen, WGAST reduces the RMSE by 18.98%, indicating more accurate pixel-wise LST estimates. It also achieves 1.88% increase in SSIM, which reflects better preservation of spatial structure and textures. In terms of radiometric quality, PSNR improves by 15.44%, and ERGAS decreases by 16.40%, highlighting enhanced global spectral fidelity. Although WGAST shows slightly higher SAM and marginally lower CC than FuseTen, these results can be attributed to its focus on preserving local spatial details and structural sharpness, occasionally at the expense of global angular alignment and correlation. When compared to Ten-STGEE, the improvements are even more pronounced. WGAST achieves 33.68% reduction in RMSE, 54.56% increase in SSIM, 47.67% gain in PSNR, and 33.84% decrease in ERGAS. On 05 Oct 2024, WGAST demonstrates performance comparable to that of FuseTen, though it does not surpass it across all metrics. For example, WGAST achieves an RMSE of 1.384, which is only 0.334 higher than the 1.050 obtained by FuseTen. Similar patterns are observed in PSNR, SAM, CC, and ERGAS. Nevertheless, WGAST improves the SSIM by 5.45% compared to FuseTen. On 21 Oct 2024, WGAST delivers strong performance across all evaluation metrics. it achieves 22.20% reduction in Compared to FuseTen, RMSE, 3.00% increase in SSIM, 16.50% gain in PSNR, and 22.20% decrease in ERGAS. In comparison to TenST-GEE, WGAST achieves 36.73% reduction in RMSE, 6.69% improvement in SSIM, 3.03% increase in PSNR, and 36.70% reduction in ERGAS. On 01 May 2025, despite the large temporal gap from the reference date at t1 (19 Sep 2024), WGAST maintains strong performance, while other methods show notable accuracy degradation. For instance, compared to FuseTen, WGAST achieves 28.32% improvement in RMSE, 6.08% gain in SSIM, 18.50% increase in PSNR, 0.84% decrease in SAM, and 28.36% reduction in ERGAS. On average across all test dates, as described in Table V, compared to FuseTen, WGAST reduces RMSE by 17.18%, improves SSIM by 4.10%, increases PSNR by 11.00%, and decreases ERGAS by 13.90%. When compared to the best linear method, the improvements are even more substantial, with 39.90% reduction in RMSE, 28.38% increase in SSIM, 22.06% gain in PSNR, and 36.70% decrease in ERGAS. This demonstrates consistent superiority across evaluation metrics. 3) In-situ Measurement: LST and air temperature (Ta) are fundamentally distinct physical quantities. However, under clear-sky and daytime conditions, they exhibit strong radiative 11 TABLE AVERAGE QUANTITATIVE COMPARISON OF ALL METHODS. TABLE VI PCC AND SRCC BETWEEN FUSED LST AND GROUND AIR TEMPERATURE Ta ACROSS SENSORS Metric BicubicI Ten-ST-GEE FuseTen WGAST RMSE () SSIM () PSNR () SAM () CC () ERGAS () 3.241 0.654 16.940 4.439 0.544 4.073 Average 3.550 0.673 19.422 6.160 0.076 4.645 2.352 0.830 21.358 3.410 0.863 2.994 1.948 0.864 23.707 4.131 0.831 2. coupling due to energy exchanges between the land surface and the atmosphere. This often leads to coherent spatial and temporal patterns, even though their absolute values may differ. Accordingly, high correlation between the fused 10 LST and ground-based Ta is meaningful indicator of the physical realism and internal consistency of the predicted LST. To quantify this relationship, we employed two correlation metrics: the Pearson correlation coefficient (PCC) and the Spearman rank correlation coefficient (SRCC). PCC quantifies the strength and direction of linear relationship between two continuous variables [54]. Its value ranges from 1 to 1, where 1 denotes perfect positive linear correlation, 1 denotes perfect negative linear correlation, and 0 indicates no linear dependence. Given two variables and b, PCC is defined as shown in Equation 14, where cov(a, b) denotes the covariance between and b, and σa, σb are their standard deviations. PCC = cov(a, b) σaσb (14) SRCC measures the strength and direction of monotonic relationship between two variables [55]. Unlike PCC, it operates on rank-transformed values rather than raw measurements, where each value is replaced by its position in the sorted list. This makes SRCC well-suited for ordinal or non-linear monotonic relationships. Given two variables and v, with ranks R(u) and R(v), SRCC ρ is defined in Equation 15. SRCC = 1 6 (cid:80)m i=1 d2 m(m2 1) (15) where di = R(ai) R(bi) is the difference between the ranks of the i-th values of the two variables, and is the total number of paired data. SRCC ranges from 1 to 1, with values near either extreme indicating strong monotonic relationships. Table VI presents the PCC and SRCC results between the WGASTs 10 pixel-wise generated LST and the corresponding ground-based air temperature (Ta) measurements across 33 sensors. The results reveal consistently strong correlations, with PCC values ranging from 0.80 to 0.95 and SRCC values from 0.80 to 0.94. These high correlations indicate strong and statistically meaningful relationship between generated LST and (Ta), which supports the physical realism and consistency of WGASTs fused 10 LST. Notably, even the lowest values exceed commonly accepted thresholds, which highlights the methods robustness across diverse sensor locations and urban conditions. Overall, this performance underscores Sensor 2 3 4 5 6 8 9 PCC 0.93 0.92 0.93 0.90 0.95 0.91 0.91 0.88 0.88 SRCC 0.94 0.93 0.89 0.85 0.94 0.91 0.88 0.85 0.87 Sensor 10 12 13 14 15 16 18 PCC 0.80 0.89 0.90 0.91 0.90 0.91 0.90 0.95 0.91 SRCC 0.80 0.88 0.88 0.93 0.90 0.92 0.87 0.93 0.94 Sensor 19 20 22 23 24 25 26 PCC 0.88 0.89 0.88 0.90 0.90 0.86 0.91 0.88 0.88 SRCC 0.85 0.86 0.85 0.87 0.88 0.88 0.91 0.85 0.85 Sensor 28 29 30 32 33 Average PCC 0.93 0.90 0.90 0.91 0.89 0.93 SRCC 0.91 0.85 0.87 0.87 0.91 0.93 0.90 0.89 WGASTs ability to reliably capture spatio-temporal variations in LST at fine spatial resolution. Figure 8 displays scatter plots comparing WGASTs 10 fused LST with ground-based air temperature (Ta) from nine randomly selected sensors during the evaluation period. These plots demonstrate strong correspondence between LST and Ta, which confirms that the fused LST product reliably captures the physical trends observed at ground level. The temporal evolution of LST and Ta shows clear and synchronized pattern across all sensors. In almost every case, both LST and Ta exhibit the same monotonic behavior, with LST rising as Ta increases and following the same downward trend as Ta decreases. Even during periods of sharp thermal fluctuation, WGASTs LST closely tracks Ta by accurately detecting peaks and valleys across variety spatial settings. Since the selected sensors span diverse land cover types, these results underscore the models robustness and generalizability across diverse environments. Overall, the analysis validates the proposed methods ability to produce temporally coherent and physically realistic LST estimates in strong agreement with ground truth observations. D. Qualitative Assessment Figure 9 presents qualitative comparison on 21 Oct 2024 between the 1 km Terra MODIS LST, the reference 30 Landsat 8 LST, the 10 LST generated by FuseTen and WGAST, and the corresponding high-resolution satellite image for visual context. We do not include other linear baselines, as their performance, evaluated through the visual metrics in Table V, was significantly inferior. Including them in this comparison would not provide meaningful insights. In Figure 9.a, WGAST generates an LST distribution that aligns more closely with the reference Landsat 8 LST than FuseTen. WGAST preserves spatial coherence while enhancing fine details, particularly in capturing temperature gradients around urban hotspots (highlighted in red). Notably, the rivers shape is sharply defined, with smooth yet well-preserved 12 Fig. 8. Scatter plots comparing WGASTs 10 LST with ground-based Ta from nine randomly selected sensors over the evaluation period. The plots illustrate the strong correlation and synchronized temporal dynamics between the generated LST and Ta. thermal transition zones along its edges. In contrast, FuseTen tends to oversmooth these boundaries, resulting in the loss of critical spatial and thermal features, especially near the riverbanks. WGAST stands out by simultaneously maintaining fine structural edges and producing continuous, physically realistic thermal patterns, which are essential for accurately characterizing the UHI effect. Figure 9.b focuses on the Loire river as it passes through semi-urban corridor of mixed built-up and vegetated areas. WGAST outperforms FuseTen by recovering the rivers cool thermal signature and faithfully preserving its curved geometry along with the surrounding landscape features. The bridge crossing the river (highlighted in red) is sharply delineated in the WGAST LST, whereas it appears only faintly in the Landsat 8 LST and is practically invisible in FuseTen LST because of oversmoothing. FuseTen also underestimates the cooling effect of the water, yielding flatter temperature field along the riverbanks. WGAST additionally excels in capturing the secondary river, Loiret (highlighted in blue), where the riverbanks are sharply delineated and correctly represented with cooler temperatures compared to the surrounding urban landscape. This thermal and structural contrast is hardly visible in the Landsat 8 LST reference. Figure 9.c focuses on densely forested region in the Orleans Forest, the largest forest in France. WGAST delivers remarkably detailed reconstruction of the thermal structure of the forest by accurately capturing subtle intracanopy temperature variations and preserving crisp spatial textures throughout the scene. The dense vegetation results in generally lower LST, and WGAST reflects this distribution with high fidelity. Notably, vegetated zone exhibiting slightly elevated LST values compared to the rest of the forest (highlighted in red) is correctly reconstructed by WGAST, in alignment with the Landsat 8 LST reference. In contrast, FuseTen assigns temperature to this area that is indistinguishable from surrounding forest regions thereby overlooking this zone. Figure 9.d depicts one of the most active industrial zones in Orleans Metropole, characterized by dense configuration of industrial facilities, road networks, and fragmented green spaces. WGAST outperforms FuseTen by accurately capturing the thermal hotspots, particularly the regions highlighted in red. These areas align closely with the Landsat 8 LST reference. In contrast, FuseTen exhibits excessive smoothing, merging key thermal patterns, and diminishing the distinction between industrial and non-industrial zones. The area marked in blue corresponds to elevated LST values over cluster of buildings, which WGAST successfully reconstructs by assigning significantly higher temperatures compared to the adjacent vegetated surfaces. However, FuseTen fails to emphasize this contrast, assigning nearly uniform temperatures that obscure the underlying land-use differences. Figure 9.e 13 Fig. 9. Qualitative comparison of WGAST and FuseTen across six representative regions in Orleans Metropole on 21 Oct 2024: (a) the Orleans Metropole, (b) semi-urban corridor along the Loire River, (c) the Orleans Forest, (d) major industrial area, (e) the city center of Orleans, and (f) mixed residential and vegetated neighborhood traversed by the Loiret River. Each row displays the high-resolution satellite view alongside the Terra MODIS LST, the Landsat 8 LST reference, and the predictions from FuseTen and WGAST. presents the city center of Orleans Metropole, densely built urban environment traversed by the Loire river, along with numerous roads and bridge-like structures. WGAST demonstrates strong performance in preserving urban morphology and accurately capturing the elevated LST values typically associated with urban cores, as indicated in the region highlighted in blue. These temperature patterns are consistent with the Landsat 8 LST reference. In contrast, FuseTen not only underestimates the urban LST but also fails to reproduce the structural layout of the urban fabric. WGAST further restores linear features such as roads and bridges with sharp detail, highlighted in red, while maintaining their thermal contrast relative to adjacent surfaces. The river itself remains clearly defined in the WGAST output, both spatially and thermally. However, FuseTen struggles to reconstruct this key feature. Figure 9.f depicts heterogeneous urban landscape composed of small residential areas, streets, and open vegetated spaces, all intersected by the Loiret River. WGAST accurately reflects the spatial diversity of the scene, clearly separating cool vegetated zones from warmer surfaces. In the red highlighted area, WGAST successfully reconstructs localized hotspot that is noticeably oversmoothed in FuseTen. Similarly, in the blue highlighted region, which corresponds to the river and its immediate surroundings, FuseTen assigns nearly uniform temperatures, failing to distinguish between water and adjacent land. In contrast, WGAST preserves the expected thermal gradient by accurately differentiating the cooler river from the warmer urban surfaces. Overall, WGAST produces more physically coherent and realistic LST compared to FuseTen. It not only preserves fine spatial structures and thermal gradients, but also generates detailed daily 10 LST that surpasses the 30 Landsat reference, all from the much coarser 1 km Terra MODIS input. Moreover, we observe that WGAST effectively addresses the issue of cloud gaps commonly found in Landsat 8 LST products, as shown in Figure 10. This is primarily due to its reliance solely on the Terra MODIS LST at the target time. Terra MODIS is less affected by persistent cloud cover compared to Landsat 8. As result, WGAST can generate 10 resolution LST that are not only temporally aligned with the Terra MODIS acquisition time but are also largely free from the cloud missing data that plagues Landsat 8 LST. Figure 10 highlights how WGAST successfully reconstructs physically plausible and high-resolution temperature fields in areas where Landsat 8 data are unavailable due to cloud contamination. V. CONCLUSION In this work, we introduced WGAST, Weakly-supervised Generative Network designed for daily 10 LST estimation via STF of Terra MODIS, Landsat 8, and Sentinel-2. To the best of our knowledge, WGAST is the first fully DL-based model developed specifically for this task. The framework is built upon cGAN, where the generator follows four-stage pipeline: feature extraction, feature fusion, LST reconstruction, and noise suppression. key contribution is the use of cosine similarity to guide the fusion by transferring relevance scores from Landsat 8 and Sentinel-2 spectral features to the Landsat 8 LST features. Training is guided by weakly-supervised strategy based on physical averaging principles, where the generated 10 LST is upsampled to 30 and compared to Landsat 8 LST. It requires only Terra MODIS LST at the target time and prior triplet T1 combining Terra MODIS, Landsat 8, and Sentinel-2, thus preserving the daily temporal resolution. WGAST outperforms existing methods both quantitatively and qualitatively. Compared to FuseTen, on average, it achieves 17.18% reduction in RMSE, 4.10% improvement in SSIM, 11.00% increase in PSNR, and 13.90% reduction in ERGAS, with even greater gains over traditional linear methods. It also preserves fine spatial details such as temperature gradients near rivers and bridges, variations around buildings, and structural patterns in industrial and agricultural areas. Additionally, by time, relying solely on Terra MODIS LST at WGAST overcomes cloud-induced gaps in Landsat 8 LST by producing complete, high-resolution, and physically consistent LST maps. Its reliability is further supported by the strong agreement between the generated 10 LST maps and in situ measurements from 33 ground-based sensors across the ROI. the target Fig. 10. WGAST reconstruction of cloud-covered regions in Landsat 8 LST on 21 Oct 2024. The comparison shows Landsat 8 LST (left column) and the corresponding WGAST predictions (right column) over three different regions. Zoomed-in areas highlight regions with missing data in Landsat due to clouds, which are reconstructed by WGAST. Despite WGASTs strong performance, its current training strategy is region-specific and may not generalize well to unseen areas with varying climatic zones. Future work will focus on developing an inference and transfer learning approach to enable automatic adaptation to unseen regions without full retraining. This would make the model more adaptable and suitable for large-scale and real-world deployment. REFERENCES [1] C. Folke, S. Polasky, J. Rockstrom, V. Galaz, F. Westley, M. Lamont, M. Scheffer, H. Osterblom, S. R. Carpenter, F. S. Chapin et al., Our future in the anthropocene biosphere, Ambio, vol. 50, pp. 834869, 2021. [2] P. Singh, N. Kikon, and P. Verma, Impact of land use change and urbanization on urban heat island in lucknow city, central india. remote sensing based estimate, Sustainable cities and society, vol. 32, pp. 100 114, 2017. [3] B. D. Sparrow, W. Edwards, S. E. Munroe, G. M. Wardle, G. R. Guerin, J.-F. Bastin, B. Morris, R. Christensen, S. Phinn, and A. J. Lowe, Effective ecosystem monitoring requires multi-scaled approach, Biological Reviews, vol. 95, no. 6, pp. 17061719, 2020. [4] Y. Chu, M. Ye, and Y. Qian, Fine-grained image recognition methods and their applications in remote sensing images: review, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2024. [5] F. Li, T. Yigitcanlar, M. Nepal, K. Nguyen, and F. Dur, Machine learning and remote sensing integration for leveraging urban sustainability: review and framework, Sustainable Cities and Society, vol. 96, p. 104653, 2023. [6] V. V. Estrela, J. Aroma, R. Sroufer, K. Raimond, A. C. Intorne, A. Deshpande, A. A. Laghari, and L. P. Oliveira, Remote sensing applications in disease mapping and public health analysis, in Intelligent Healthcare Systems. CRC Press, 2023, pp. 185202. [7] N. Kerle, Disasters: Risk assessment, management, and post-disaster studies using remote sensing, in Remote Sensing Handbook, Volume VI. CRC Press, 2024, pp. 153198. [8] B. Sirmacek and R. Vinuesa, Remote sensing and ai for building climate adaptation applications, Results in Engineering, vol. 15, p. 100524, 2022. [9] S. Bouaziz, A. Hafiane, R. Canals, and R. Nedjai, Deep learning for spatio-temporal fusion in land surface temperature estimation: comprehensive survey, experimental analysis, and future trends, arXiv preprint arXiv:2412.16631, 2024. [10] G. C. Hulley, D. Ghent, F. M. Gottsche, P. C. Guillevic, D. J. Mildrexler, and C. Coll, 3 - land surface temperature, in Taking the Temperature of the Earth, G. C. Hulley and D. Ghent, Eds. Elsevier, 2019, pp. 57127. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/B9780128144589000034 [11] D. K. Hall, J. C. Comiso, N. E. DiGirolamo, C. A. Shuman, J. R. Key, and L. S. Koenig, satellite-derived climate-quality data record of the clear-sky surface temperature of the greenland ice sheet, Journal of Climate, vol. 25, no. 14, pp. 47854798, 2012. [12] S. Luyssaert, M. Jammet, P. C. Stoy, S. Estel, J. Pongratz, E. Ceschia, G. Churkina, A. Don, K. Erb, M. Ferlicoq et al., Land management and land-cover change have impacts of similar magnitude on surface temperature, Nature Climate Change, vol. 4, no. 5, pp. 389393, 2014. [13] M. Maimaitiyiming, A. Ghulam, T. Tiyip, F. Pla, P. Latorre-Carmona, U. Halik, M. Sawut, and M. Caetano, Effects of green space spatial pattern on land surface temperature: Implications for sustainable urban planning and climate change adaptation, ISPRS Journal of Photogrammetry and Remote Sensing, vol. 89, pp. 5966, 2014. [14] M. King, EOS Science Plan: The State of Science in the EOS Program. National Aeronautics and Space Administration, 1999, available at: https://books.google.fr/books?id=PS9RAAAAMAAJ. [15] R. Hollmann, C. J. Merchant, R. Saunders, C. Downy, M. Buchwitz, A. Cazenave, E. Chuvieco, P. Defourny, G. de Leeuw, R. Forsberg et al., The esa climate change initiative: Satellite data records for essential climate variables, Bulletin of the American Meteorological Society, vol. 94, no. 10, pp. 15411552, 2013. [16] Z.-L. Li, B.-H. Tang, H. Wu, H. Ren, G. Yan, Z. Wan, I. F. Trigo, and J. A. Sobrino, Satellite-derived land surface temperature: Current status and perspectives, Remote sensing of environment, vol. 131, pp. 1437, 2013. [17] J. Zhang and J. Li, Chapter 11 - spacecraft, in Spatial Cognitive Engine Technology, J. Zhang and J. Li, Eds. Academic Press, 2023, pp. 129162. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/B9780323951074000044 [18] P. Gibson, Chapter 1 - systematic view of remote sensing (second edition), in Advanced Remote Sensing, S. Liang and J. Wang, Eds. Academic Press, 2020, pp. 157. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/B9780128158265000015 [19] X. Zhu, F. Cai, J. Tian, and T. K.-A. Williams, Spatiotemporal fusion of multisource remote sensing data: Literature survey, taxonomy, principles, applications, and future directions, Remote Sensing, vol. 10, no. 4, p. 527, 2018. [20] H. Song, Q. Liu, G. Wang, R. Hang, and B. Huang, Spatiotemporal satellite image fusion using deep convolutional neural networks, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 11, no. 3, pp. 821829, 2018. [21] R. Swain, A. Paul, and M. D. Behera, Spatio-temporal fusion methods for spectral remote sensing: comprehensive technical review and comparative analysis, Tropical Ecology, vol. 65, no. 3, pp. 356375, 2024. [22] F. Gao, J. Masek, M. Schwaller, and F. Hall, On the blending of the landsat and modis surface reflectance: Predicting daily landsat surface reflectance, IEEE Transactions on Geoscience and Remote sensing, vol. 44, no. 8, pp. 22072218, 2006. [23] X. Zhu, J. Chen, F. Gao, X. Chen, and J. G. Masek, An enhanced spatial and temporal adaptive reflectance fusion model for complex heterogeneous regions, Remote Sensing of Environment, vol. 114, no. 11, pp. 26102623, 2010. 15 [24] H. Liu and Q. Weng, Enhancing temporal resolution of satellite imagery for public health studies: case study of west nile virus outbreak in los angeles in 2007, Remote Sensing of environment, vol. 117, pp. 5771, 2012. [25] Y. Ma, S. Liu, L. Song, Z. Xu, Y. Liu, T. Xu, and Z. Zhu, Estimation of daily evapotranspiration and irrigation water efficiency at landsat-like scale for an arid irrigation area using multi-source remote sensing data, Remote Sensing of Environment, vol. 216, pp. 715734, 2018. [26] B. Mohamadi, S. Chen, T. Balz, K. Gulshad, and S. C. McClure, Normalized method for land surface temperature monitoring on coastal reclaimed areas, Sensors, vol. 19, no. 22, p. 4836, 2019. [27] Z. Yin, P. Wu, G. M. Foody, Y. Wu, Z. Liu, Y. Du, and F. Ling, Spatiotemporal fusion of land surface temperature based on convolutional neural network, IEEE Transactions on Geoscience and Remote Sensing, vol. 59, no. 2, pp. 18081822, 2020. [28] Y. Chen, Y. Yang, X. Pan, X. Meng, and J. Hu, Spatiotemporal fusion network for land surface temperature based on conditional variational autoencoder, IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 113, 2022. [29] P. Hu, X. Pan, Y. Yang, Y. Dai, and Y. Chen, two-stage hierarchical spatiotemporal fusion network for land surface temperature with transformer, IEEE Transactions on Geoscience and Remote Sensing, 2025. [30] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, Generative adversarial nets, Advances in neural information processing systems, vol. 27, 2014. [31] H. Zhang, Y. Song, C. Han, and L. Zhang, Remote sensing image spatiotemporal fusion using generative adversarial network, IEEE Transactions on Geoscience and Remote Sensing, vol. 59, no. 5, pp. 42734286, 2020. [32] Z. Tan, M. Gao, X. Li, and L. Jiang, flexible reference-insensitive spatiotemporal fusion model for remote sensing images using conditional generative adversarial network, IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 113, 2021. [33] J. Chen, L. Wang, R. Feng, P. Liu, W. Han, and X. Chen, Cycleganstf: Spatiotemporal fusion via cyclegan-based image generation, IEEE Transactions on Geoscience and Remote Sensing, vol. 59, no. 7, pp. 58515865, 2020. [34] B. Song, P. Liu, J. Li, L. Wang, L. Zhang, G. He, L. Chen, and J. Liu, Mlff-gan: multilevel feature fusion with gan for spatiotemporal remote sensing images, IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 116, 2022. [35] D. P. Roy, M. A. Wulder, T. R. Loveland, C. E. Woodcock, R. G. Allen, M. C. Anderson, D. Helder, J. R. Irons, D. M. Johnson, R. Kennedy et al., Landsat-8: Science and product vision for terrestrial global change research, Remote sensing of Environment, vol. 145, pp. 154 172, 2014. [36] H. Shi, G. Xian, R. Auch, K. Gallo, and Q. Zhou, Urban heat island and its regional impacts using remotely sensed thermal dataa review of recent developments and methodology, Land, vol. 10, no. 8, p. 867, 2021. [37] D. Zhou, J. Xiao, S. Bonafoni, C. Berger, K. Deilami, Y. Zhou, S. Frolking, R. Yao, Z. Qiao, and J. A. Sobrino, Satellite remote sensing of surface urban heat islands: Progress, challenges, and perspectives, Remote Sensing, vol. 11, no. 1, p. 48, 2018. [38] M. Mhawej and Y. Abunnasr, Daily ten-st-gee: An open access and fully automated 10-m lst downscaling system, Computers & Geosciences, vol. 168, p. 105220, 2022. [39] D. Xiang, Y. Sun, H. Zhu, J. Wang, S. Huang, S. Zhang, F. Zhang, and H. Zhang, Comparative analysis of prediction models for trawling grounds of the argentine shortfin squid illex argentinus in the southwest atlantic high seas based on vessel position and fishing log data, Biology, vol. 14, no. 1, p. 35, 2025. [40] S. Bouaziz, A. Hafiane, R. Canals, and R. Nedjai, Fuseten: generative model for daily 10 land surface temperature estimation from spatiotemporal satellite observations, arXiv preprint arXiv:2507.23154, 2025. [41] S. Guha, H. Govil, A. K. Taloor, N. Gill, and A. Dey, Land surface indices: seasonal study of raipur city, temperature and spectral Geodesy and Geodynamics, vol. 13, no. 1, pp. 7282, 2022. [42] A. J. Abdalkadhum, M. M. Salih, and O. Z. Jasim, The correlation among land cover spectral indices and surface temperature using remote sensing techniques, in IOP Conference Series: Materials Science and Engineering, vol. 1090, no. 1. IOP Publishing, 2021, p. 012024. [43] P. Sharma, M. Kumar, H. K. Sharma, and S. M. Biju, Generative adversarial networks (gans): Introduction, taxonomy, variants, limitations, and applications, Multimedia Tools and Applications, pp. 148, 2024. 16 Raphael Canals received the Dipl.Ing. degree in electrical engineering and the Ph.D. degree in electronics from the University of ClermontFerrand, France, in 1989 and 1993, respectively. In 1993, he was Postdoctoral Fellow at the Computer Science Department, CNRC, Ottawa, ON, Canada. In 1994, he joined the Polytechnic School, University of Orleans, France, as Teacher. He is currently Researcher with Laboratory PRISME, University of Orleans-INSA CVL. He is also an Associate Professor with the University of Orleans. In 2015, he was introduced at the AgreenTech Valley Cluster dedicated to digital technologies for plant industry. His current interests are in biomedical imaging, innovation for agriculture, the IoT, and AI. Rachid Nedjai is professor in limnology and geomatics at the University of Orleans, where he also leads the Masters program in Geographic Information Systems (GAED). He obtained his Ph.D. in geochemistry of lacustrine waters and paleoenvironmental reconstruction from the University of Grenoble 1. His research focuses on environmental data simulation, hydrogeology, and geomatics applications for water resource management. He has contributed to numerous international projects, including the redesign of Algerias judicial map and spatial data infrastructure for water management in Africa. He has supervised multiple theses on hydrology, water resource management, and environmental risk assessment, with many of his students successfully entering the professional world. His expertise in geomatics and water resource management has made him key contributor to advancing sustainable practices in the field. [44] Y. Hong, U. Hwang, J. Yoo, and S. Yoon, How generative adversarial networks and their variants work: An overview, ACM Computing Surveys (CSUR), vol. 52, no. 1, pp. 143, 2019. [45] Y.-P. Hsieh, C. Liu, and V. Cevher, Finding mixed nash equilibria of generative adversarial networks, in International Conference on Machine Learning. PMLR, 2019, pp. 28102819. [46] M. Mirza and S. Osindero, Conditional generative adversarial nets, arXiv preprint arXiv:1411.1784, 2014. [47] B. Lim, S. Son, H. Kim, S. Nah, and K. Mu Lee, Enhanced deep residual networks for single image super-resolution, in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, 2017, pp. 136144. [48] X. Huang and S. Belongie, Arbitrary style transfer in real-time with adaptive instance normalization, in Proceedings of the IEEE international conference on computer vision, 2017, pp. 15011510. [49] L. Gao, W. Zhan, F. Huang, J. Quan, X. Lu, F. Wang, W. Ju, and J. Zhou, Localization or globalization? determination of the optimal regression window for disaggregation of land surface temperature, IEEE Transactions on Geoscience and Remote Sensing, vol. 55, no. 1, pp. 477490, 2016. [50] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. Paul Smolley, Least squares generative adversarial networks, in Proceedings of the IEEE international conference on computer vision, 2017, pp. 27942802. [51] N. Gorelick, M. Hancher, M. Dixon, S. Ilyushchenko, D. Thau, and R. Moore, Google earth engine: Planetary-scale geospatial analysis for everyone, Remote sensing of Environment, vol. 202, pp. 1827, 2017. [52] S.-B. Duan, Z.-L. Li, H. Li, F.-M. Gottsche, H. Wu, W. Zhao, P. Leng, X. Zhang, and C. Coll, Validation of collection 6 modis land surface temperature product using in situ measurements, Remote sensing of environment, vol. 225, pp. 1629, 2019. [53] J. C. Jimenez-Munoz, J. A. Sobrino, D. Skokovic, C. Mattar, and J. Cristobal, Land surface temperature retrieval methods from landsat8 thermal infrared sensor data, IEEE Geoscience and remote sensing letters, vol. 11, no. 10, pp. 18401843, 2014. [54] I. Cohen, Y. Huang, J. Chen, J. Benesty, J. Benesty, J. Chen, Y. Huang, and I. Cohen, Pearson correlation coefficient, Noise reduction in speech processing, pp. 14, 2009. [55] J. H. Zar, Spearman rank correlation: overview, Wiley StatsRef: Statistics Reference Online, 2014. Sofiane Bouaziz is PhD Student at INSA Centre Val de Loire (INSA CVL) and the PRISME Laboratory. He received his Masters and Engineering degrees in Computer Science and Artificial Intelligence from Ecole Nationale Superieure dInformatique, Algiers, Algeria in 2023. His current research focuses on using Artificial Intelligence and Computer Vision to tackle challenges in remote sensing. Adel Hafiane received the M.S. degree in embedded systems and information processing, and the Ph.D. degree from the University of Paris-Saclay, in 2002 and 2005, respectively. After that, he embarked on teaching and research, spending year at ParisSaclay and subsequently another year at INSA Centre Val de Loire (INSA CVL). He was postdoctoral fellow at the computer science department, University of Missouri, from 2007 to 2008. Since September 2008, as an assistant professor, then as an associate professor. He is head of the Image and Vision group at PRISME Laboratory of University of Orleans and INSA CVL. He was an invited researcher at the University of Missouri on multiple periods, from 2009 to 2013. His research interests include theory and methods of machine learning and computer vision for different applications. He coordinated several research projects and co-authored more than 90 papers and 3 patents. He has also served as an associate editor for several special issues in remote sensing."
        }
    ],
    "affiliations": [
        "INSA Centre Val de Loire, Universite d'Orleans, PRISME UR 4229, Bourges, 18022, Centre Val de Loire, France",
        "Universite d'Orleans, CEDETE, UR 1210, Orleans, 45067, Centre Val de Loire, France",
        "Universite d'Orleans, INSA CVL, PRISME UR 4229, Orleans, 45067, Centre Val de Loire, France"
    ]
}