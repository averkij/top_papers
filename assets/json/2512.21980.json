{
    "paper_title": "A 58-Addition, Rank-23 Scheme for General 3x3 Matrix Multiplication",
    "authors": [
        "A. I. Perminov"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "This paper presents a new state-of-the-art algorithm for exact $3\\times3$ matrix multiplication over general non-commutative rings, achieving a rank-23 scheme with only 58 scalar additions. This improves the previous best additive complexity of 60 additions without a change of basis. The result was discovered through an automated search combining ternary-restricted flip-graph exploration with greedy intersection reduction for common subexpression elimination. The resulting scheme uses only coefficients from $\\{-1, 0, 1\\}$, ensuring both efficiency and portability across arbitrary fields. The total scalar operation count is reduced from 83 to 81."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 2 ] . [ 1 0 8 9 1 2 . 2 1 5 2 : r 58-ADDITION, RANK-23 SCHEME FOR GENERAL 33 MATRIX MULTIPLICATION PREPRINT Andrew I. Perminov Research Center for TAI Institute for System Programming Moscow perminov@ispras.ru December 29,"
        },
        {
            "title": "ABSTRACT",
            "content": "This paper presents new state-of-the-art algorithm for exact 33 matrix multiplication over general non-commutative rings, achieving rank-23 scheme with only 58 scalar additions. This improves the previous best additive complexity of 60 additions [1] without change of basis. The result was discovered through an automated search combining ternary-restricted flip-graph exploration with greedy intersection reduction for common subexpression elimination. The resulting scheme uses only coefficients from {1, 0, 1}, ensuring both efficiency and portability across arbitrary fields. The total scalar operation count is reduced from 83 to 81. Keywords Fast matrix multiplication Additive complexity Ternary coefficients set"
        },
        {
            "title": "Introduction",
            "content": "The computational complexity of matrix multiplication remains fundamental problem in theoretical computer science and numerical linear algebra. Since Strassens discovery of sub-cubic time algorithm [2], the search for practical, low-complexity schemes for small matrix formats has been persistent research direction. For 33 matrices, the lowest known rank (in non-commutative case) is 23 [3]. Any scheme of this rank requires 23 essential multiplications of linear combinations of input elements. However, the total number of scalar additions (and subtractions) needed to form these combinations is crucial practical metric, as it directly impacts the efficiency of software implementations like the Basic Linear Algebra Subprograms (BLAS). Significant effort has focused on reducing the additive complexity of rank-23 schemes. Ladermans original construction used 98 additions [3]. Recent advances have dramatically lowered this count: Schwartz and Vaknin achieved 61 additions using change of basis [4], Mårtensson and Wagner achieved 62 [5], and Stapleton recently set new record of 60 additions without change of basis [1]. This work reports further reduction to 58 additions, achieved without change of basis. The result is obtained through parallel heuristic search algorithm based on an extension of the flip-graph approach with ternary restrictions [6] and greedy intersection reduction strategy [7]. The main result is new rank-23 scheme using only 58 additions and employing exclusively ternary coefficients {1, 0, 1}. This ensures the schemes portability and efficiency across arbitrary fields."
        },
        {
            "title": "2 Methodology",
            "content": "2.1 Matrix Multiplication Schemes matrix multiplication scheme for multiplying matrices Fnn and Fnn over field with rank is defined by three coefficient tensors Frnn, Frnn and Frnn. It computes intermediate scalar products: 58-Addition, Rank-23 Scheme for General 33 Matrix Multiplication m1 = (u(1) 11 a11 + + u(1) 11 b11 + + v(1) nn bnn) mr = (u(r) 11 a11 + + u(r) 11 b11 + + v(r) nn bnn), nnann) (v(1) ... nnann) (v(r) and reconstructs the result matrix C, where = AB, as: cij = w(1) ij m1 + + w(r) ij mr. The tensors U, V, must satisfy the Brent equations [8]. This work focuses on the = 3, = 23 case where all coefficients in U, V, are restricted to the set {1, 0, 1}. 2.2 Ternary Flip-Graph Search The search operates on the space of valid 33 multiplication schemes of varying rank. This space is navigated using an extension of the flip-graph approach [9], constrained by ternary restrictions [6]. flip is local transformation applied to the tensors U, V, . It modifies the coefficients while preserving the correctness of the scheme (i.e., satisfaction of the Brent equations) and maintaining its current rank. Flips enable traversal between different schemes with equal rank. The ternary restriction enforces that all coefficients in U, V, remain within the set {1, 0, 1} throughout the search. This constraint focuses the exploration on schemes that are directly implementable over any field. Many existing flip-graph methods [9, 10] first search for schemes over the binary field Z2, which is computationally efficient, and later attempt to \"lift\" the found coefficients to integer or rational values to ensure validity over rings such as or Q. The ternary approach avoids this lifting step entirely by working directly with the target coefficient set. The core discovery process is random walk on this ternary flip graph. To escape irreducible states where no applicable flip can improve the scheme, plus operator is used. This operator, defined in [11], increases the rank of scheme by one while preserving correctness and the ternary coefficient property. After its application, the flip-graph walk continues, often enabling further optimization that can later reduce the rank back to the target value. 2.3 Greedy Intersection Reduction After obtaining candidate rank-23 scheme, its additive complexity is minimized using common subexpression elimination (CSE) algorithm [7]. During the main search loop, the CSE step uses single heuristic randomly chosen from collection of strategies, including the Greedy-Intersections method. The algorithm identifies all candidate subexpressions of the form xi xj within the linear forms defined by the , and tensors. heuristic scoring function evaluates every identified candidate. The subexpression with the highest score is selected, replaced by fresh variable, and eliminated throughout the entire scheme. After each substitution, the algorithm identifies all new candidate subexpressions in the updated scheme and selects the next best one. The process continues until no remaining candidate subexpression would reduce the total addition count."
        },
        {
            "title": "3 Discovery Algorithm",
            "content": "The discovery algorithm integrates the ternary flip-graph search and greedy intersection reduction into three-phase iterative process. The search begins by initializing naive scheme for 33 matrix multiplication. This naive scheme has rank of 27 and uses only coefficients from {0, 1} (the standard matrix multiplication algorithm). The core procedure then executes the continuous loop described in Algorithm 1. 2 58-Addition, Rank-23 Scheme for General 33 Matrix Multiplication Algorithm 1: Search loop for low-addition schemes Input: naive 33 multiplication scheme with coefficients {0, 1} and rank 27. Output: scheme with minimal addition count discovered during search. while search not manually stopped do // flip to target rank while rank(S) = 23 do lip(S); if no flip is possible or random() < 0.05 then plus(S); // reduce additions with greedy intersection Execute greedy intersection reduction algorithm on S; Check for improvements in addition count; // random change lip(S); while rank(S) < 25 and random() < 0.05 do plus(S); Phase 1 (flip to target rank): the algorithm uses random flips to change the scheme until it reaches rank 23. Each flip converts the scheme to another scheme. If flip creates tensor component with all zero coefficients, the rank of the scheme is reduced by one. If no useful flip is possible, or with 5% chance even if flip is possible, the plus operator is used. This operator increases the rank by one, which helps to continue the search when stuck. Phase 2 (reduce additions with greedy intersection): after reaching rank 23, the greedy intersection reduction algorithm runs. It finds common subexpressions in the formulas from the , and tensors. These common parts are replaced with new variables. This step repeats, choosing the best replacement each time, to lower the total number of additions. Phase 3 (random change): to keep searching new options and avoid getting stuck, random flip is applied to change the scheme bit. Also, with 5% chance, the plus operator is used if the current rank is less than 25. This creates small changes that can lead to better schemes later. The three phases execute in continuous loop. The search runs indefinitely until manually stopped, allowing for exhaustive exploration of the solution space. This design balances targeted optimization (Phase 2) with broader exploration (Phases 1 and 3) to systematically navigate toward schemes with minimal addition counts. 3 58-Addition, Rank-23 Scheme for General 33 Matrix Multiplication"
        },
        {
            "title": "4 Discovered 58-Addition Scheme",
            "content": "The discovered algorithm for exact 33 matrix multiplication is presented below. It requires 23 multiplications and achieves an additive complexity of 58. The scheme was derived from an initial, unreduced algorithm requiring 120 naive additions. Through common subexpression elimination, 20 fresh intermediate variables were introduced: 4 for linear combinations of matrix (u1u4), 8 for matrix (v1v8), and 8 for combining the products (w1w8). The complete algorithm is constructed from these intermediates, which are computed once and reused. notable feature of the scheme is that all expressions are defined without variable inversions (the first non-zero coefficient in each defining equation is +1). The 58 additive operations consist of 34 additions and 24 subtractions. = (cid:35) (cid:34)a11 a12 a13 a21 a22 a23 a31 a32 a33 = (cid:34)b11 b21 b12 b22 b32 (cid:35) b13 b23 b33 u1 = a31 + a33 u2 = a21 + a22 u3 = a13 + u1 u4 = a32 u2 v1 = b22 + b32 v2 = b31 v1 v3 = b12 + v2 v4 = b11 v3 v5 = b33 + v1 v6 = b21 b23 v7 = b12 v5 v8 = v4 v6 w1 = m5 + m12 w2 = m1 + w1 w3 = m8 + w2 w4 = m3 m23 w5 = m2 + w4 w6 = w3 + w5 w7 = m10 w6 w8 = m17 + m1 = u1 v5 m2 = u2 (v2 + v6) m3 = a32 b23 m4 = a31 (b13 + v7) m5 = u3 v7 m6 = (a32 a33) b22 m7 = a23 b33 m8 = (u1 u2) v2 m9 = (a12 a13) b22 m10 = (u3 a21) v3 m11 = (a13 + a33) (v1 b12) m12 = a13 b33 m13 = (a31 + u4) v4 m14 = a11 b13 m15 = (a11 + u3) b12 m16 = (a13 + a23) b31 m17 = (a22 a32) (v4 b21) m18 = (a11 + a21) b11 m19 = a12 b23 m20 = (a12 + a22) b21 m21 = a21 (b13 v8) m22 = (a22 a23) (b31 b32) m23 = u4 v8 = (cid:34)m18 + m20 + w8 m16 w8 m11 + m13 + w6 m9 + m15 w2 m16 + m22 + w3 m10 m6 + m11 + w2 m12 + m14 + m19 m7 + m21 + w4 m17 m3 + m4 m11 w1 (cid:35)"
        },
        {
            "title": "5 Discussion",
            "content": "The discovery of 58-addition scheme advances the state of the art for practical 33 matrix multiplication. The search that found this scheme required approximately 30 minutes of computation on standard laptop CPU (Intel Core i7-9750H), demonstrating that state-of-the-art results can be achieved without specialized high-performance computing resources. Reducing the addition count from 60 to 58 directly lowers the operation cost in performance-critical applications like computer graphics and scientific computing, where such multiplications are performed repeatedly. 4 58-Addition, Rank-23 Scheme for General 33 Matrix Multiplication The schemes use of only ternary coefficients {1, 0, 1} is significant practical strength, ensuring it consists solely of cheap additions and subtractions, making it portable and efficient across different hardware and numerical fields. This result validates the effectiveness of the combined flip-graph and heuristic search methodology. It demonstrates that focused, resource-efficient strategies can achieve top results in this domain. The success stems from two key choices: restricting the search to ternary coefficients to maintain practicality, and applying greedy heuristic capable of finding deep optimizations in additive complexity. The progression from Ladermans 98 additions to 58 shows that substantial optimization remains possible even for long-studied algorithms. Looking forward, it remains an open question whether 58 additions is the minimum possible for rank-23 scheme. The presented methodology can be applied to search for optimizations in other small matrix formats. valuable next step would be to implement this scheme in production BLAS library to measure its real-world performance improvement."
        },
        {
            "title": "6 Conclusion",
            "content": "This work presented new algorithm for 33 matrix multiplication that achieves rank of 23 with only 58 scalar additions. This result improves the previous state-of-the-art additive complexity of 60 additions, established without change of basis. Combined with the 23 essential multiplications, the total number of scalar operations is reduced from 83 to 81. The scheme uses coefficients exclusively from the set {1, 0, 1}, ensuring efficiency and portability across hardware architectures and numerical fields. The scheme was discovered through an automated search methodology that combines ternary-restricted flip-graph walk with greedy intersection reduction heuristic. This approach demonstrates that effective exploration of the algorithm space can yield significant improvements through structured combinatorial search. The new scheme offers direct path to performance gains in low-level numerical libraries. Future work may focus on establishing lower bound for the additive complexity of rank-23 schemes, applying the search methodology to other matrix formats, and implementing this algorithm in production BLAS software for practical benchmarking."
        },
        {
            "title": "A Python verification Script",
            "content": "The scheme was verified through symbolic and numerical methods. Symbolically, all intermediate variables were substituted to obtain the original linear forms. This process reconstructed the full coefficient tensors , and , which were confirmed to satisfy the Brent equations. This proves the algorithms correctness for all 3 3 matrices over any field. Numerically, Python script executed the algorithm on 10,000 random matrix pairs. All results matched standard multiplication in each test. import numpy as np def t y _ 3 3 _ k 2 3 _ 5 8 i n ( : np . ndarray , : np . ndarray ) -> np . ndarray : a11 , a12 , a13 , a21 , a22 , a23 , a31 , a32 , a33 = . ravel () b11 , b12 , b13 , b21 , b22 , b23 , b31 , b32 , b33 = . ravel () u1 = a31 + a33 u2 = a21 + a22 u3 = a13 + u1 u4 = a32 - v1 = b22 + b32 v2 = b31 - v1 v3 = b12 + v2 v4 = b11 - v3 v5 = b33 + v1 v6 = b21 - b23 v7 = b12 - v5 v8 = v4 - v6 m1 = u1 * v5 m2 = u2 * ( v2 + v6 ) m3 = a32 * b23 m4 = a31 * ( b13 + v7 ) 5 58-Addition, Rank-23 Scheme for General 33 Matrix Multiplication m5 = u3 * v7 m6 = ( a32 - a33 ) * b22 m7 = a23 * b33 m8 = ( u1 - u2 ) * v2 m9 = ( a12 - a13 ) * b22 m10 = ( u3 - a21 ) * v3 m11 = ( a13 + a33 ) * ( v1 - b12 ) m12 = a13 * b33 m13 = ( a31 + u4 ) * v4 m14 = a11 * b13 m15 = ( a11 + u3 ) * b12 m16 = ( a13 + a23 ) * b31 m17 = ( a22 - a32 ) * ( v4 - b21 ) m18 = ( a11 + a21 ) * b11 m19 = a12 * b23 m20 = ( a12 + a22 ) * b21 m21 = a21 * ( b13 - v8 ) m22 = ( a22 - a23 ) * ( b31 - b32 ) m23 = u4 * v8 w1 = m5 + m12 w2 = m1 + w1 w3 = m8 + w2 w4 = m3 - m23 w5 = m2 + w4 w6 = w3 + w5 w7 = m10 - w6 w8 = m17 + c11 = m18 + m20 + w8 c12 = m9 + m15 - w2 c13 = m12 + m14 + m19 c21 = m16 - w8 c22 = m16 + m22 + w3 - m10 c23 = m7 + m21 + w4 - m17 c31 = m11 + m13 + w6 c32 = m6 + m11 + w2 c33 = m3 + m4 - m11 - w1 return np . array ([[ c11 , c12 , c13 ] , [ c21 , c22 , c23 ] , [ c31 , c32 , c33 ]]) def validate ( : int ) : for _ in range ( ) : = np . random . randint ( -100 , 101 , size =(3 , 3) ) = np . random . randint ( -100 , 101 , size =(3 , 3) ) assert np . array_equal ( t y _ 3 3 _ k 2 3 _ 5 8 i n (a , ) , @ ) print ( \" Tests passed \" ) if __name__ == \" __main__ \" : validate (10000) Listing 1: Python script for numerical validation of the 58-addition scheme"
        },
        {
            "title": "References",
            "content": "[1] Joshua Stapleton. 60-addition, rank-23 scheme for exact 3x3 matrix multiplication. arXiv preprint arXiv:2508.03857, 2025. [2] Volker Strassen. Gaussian elimination is not optimal. Numerische mathematik, 13(4):354356, 1969. 6 58-Addition, Rank-23 Scheme for General 33 Matrix Multiplication [3] Julian David Laderman. noncommutative algorithm for multiplying 3x3 matrices using 23 multiplications. Bulletin of the American Mathematical Society, 82:126128, 1976. URL https://api.semanticscholar. org/CorpusID:121295009. [4] Oded Schwartz and Noa Vaknin. Pebbling game and alternative basis for high performance matrix multiplication. SIAM Journal on Scientific Computing, 45(6):C277C303, 2023. [5] Erik Mårtensson and Paul Stankovski Wagner. The number of the beast: Reducing additions in fast matrix multiplication algorithms for dimensions up to 666. In 2025 Proceedings of the Conference on Applied and Computational Discrete Algorithms (ACDA), pages 4760. SIAM, 2025. [6] Andrew Perminov. Fast matrix multiplication via ternary meta flip graphs. arXiv preprint arXiv:2511.20317, 2025. URL https://arxiv.org/abs/2511.20317. [7] Andrew Perminov. Parallel heuristic exploration for additive complexity reduction in fast matrix multiplication. arXiv preprint arXiv:2512.13365, 2025. URL https://arxiv.org/abs/2512.13365. [8] Richard Brent. Algorithms for matrix multiplication. Technical report, Stanford University Stanford, 1970. [9] Manuel Kauers and Jakob Moosbauer. Flip graphs for matrix multiplication. In Proceedings of the 2023 International Symposium on Symbolic and Algebraic Computation, pages 381388, 2023. [10] Jakob Moosbauer and Michael Poole. Flip graphs with symmetry and new matrix multiplication schemes. In Proceedings of the 2025 International Symposium on Symbolic and Algebraic Computation, pages 233239, 2025. [11] Yamato Arai, Yuma Ichikawa, and Koji Hukushima. Adaptive flip graph algorithm for matrix multiplication. In Proceedings of the 2024 International Symposium on Symbolic and Algebraic Computation, pages 292298, 2024."
        }
    ],
    "affiliations": [
        "Research Center for TAI Institute for System Programming Moscow"
    ]
}