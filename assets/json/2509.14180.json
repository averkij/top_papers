{
    "paper_title": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs",
    "authors": [
        "Akhil Theerthala"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Personalized financial advice requires consideration of user goals, constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on support systems for investors and financial planners. Simultaneously, numerous recent studies examine broader personal finance tasks, including budgeting, debt management, retirement, and estate planning, through agentic pipelines that incur high maintenance costs, yielding less than 25% of their expected financial returns. In this study, we introduce a novel and reproducible framework that integrates relevant financial context with behavioral finance studies to construct supervision data for end-to-end advisors. Using this framework, we create a 19k sample reasoning dataset and conduct a comprehensive fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test split and a blind LLM-jury study, we demonstrate that through careful data curation and behavioral integration, our 8B model achieves performance comparable to significantly larger baselines (14-32B parameters) across factual accuracy, fluency, and personalization metrics while incurring 80% lower costs than the larger counterparts."
        },
        {
            "title": "Start",
            "content": "Synthesizing Behaviorally-Grounded Reasoning Chains: Data-Generation Framework for Personal Finance LLMs"
        },
        {
            "title": "Akhil Theerthala\nPerfios Software Solutions",
            "content": "5 2 0 2 7 1 ] . [ 1 0 8 1 4 1 . 9 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Personalized financial advice requires consideration of user goals, constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on support systems for investors and financial planners. Simultaneously, numerous recent studies examine broader personal finance tasks, including budgeting, debt management, retirement, and estate planning, through agentic pipelines that incur high maintenance costs, yielding less than 25% of their expected financial returns. In this study, we introduce novel and reproducible framework that integrates relevant financial context with behavioral finance studies to construct supervision data for end-toend advisors. Using this framework, we create 19k sample reasoning dataset and conduct comprehensive fine-tuning of the Qwen-3-8B model on the dataset. Through held-out test split and blind LLM-jury study, we demonstrate that through careful data curation and behavioral integration, our 8B model achieves performance comparable to significantly larger baselines (14-32B parameters) across factual accuracy, fluency, and personalization metrics while incurring 80% lower costs than the larger counterparts. Keywords: Financial Datasets; Personal Finance; Reasoning Models; Large Language Models"
        },
        {
            "title": "Introduction",
            "content": "Legal counseling, healthcare, and finance are among the numerous high-stakes domains in which personalized advice is essential. However, the development of this personalized advice is fraught with obstacles, requiring substantial investments and years of human expertise. Recent research efforts have thoroughly investigated automated decision support systems in various areas, emphasizing their cost-effectiveness. In the financial sector, variety of support systems have been investigated, with particular emphasis on asset recommendations and investment predictions. (Sanz-Cruzado 1 et al., 2024; Luo et al., 2025; Takayanagi et al., 2023) Recent advances in large language models (LLMs) have shown effective performance in acting as decision support systems for investors (Gupta, 2023) and financial planners (Huang et al., 2024). The core advantage of natural language generation presents these automated support systems with unique advantage that was never available in previous applications. This advantage has repeatedly shown its power in linguistic tasks such as streamlining complex financial narratives from extensive documents, corporate discourses, news sources, and social media.(Gueta et al., 2025; Lee and Lay-Ki, 2024) The utility of these models is also being explored in Time series (Liu and Jia, 2025) and Financial reasoning applications (Liu et al., 2025). Notwithstanding this capability, recent research indicates that no model excels across all financial task categories, which include text summarization, sentiment analysis, causal analysis, forecasting, It and text classification (Matlin et al., 2025). has been demonstrated that attaining robust performance frequently necessitates the utilization of large, expensive models, thereby constraining the practicality of these solutions. Due to these inherent limitations and the complexity of financial advisory, many studies focusing on broader financial decision systems have preferred an agentic approach over training financial domain-specific language models. (Okpala et al., 2025; Joshi, 2025; Takayanagi et al., 2025a) Although the initial agentic frameworks focused on answering simple inquiries,(Lakkaraju et al., 2023) recent studies have accelerated the development of these systems to provide practical and actionable advice to the end user (Takayanagi et al., 2025b; Okpala et al., 2025). These agents can now dynamically interact with users and can assist in various tasks such as recommendation, question answering, search, and customer profiling. (Li et al., 2024; Takayanagi et al., 2025a; Han et al., 2024) Although agentic systems demonstrate potential in providing tailored financial advice, their efficacy is hindered by considerable constraints, including the integration with legacy systems, compliance with data security regulations, and high inference (Cemri et al., 2025; Wang et al., 2025). costs. In support of these concerns, recent study by (Meimandi et al., 2025) illustrates that confluence of technical and cost-related factors hinders these applications from realizing even 25% of their anticipated returns. This research also establishes an important differentiation: success in benchmarks does not necessarily equate to success in deployment. In practical terms, these proactive financial advisors frequently encounter swift deterioration in performance within matter of months following their implementation, attributable to the inherent volatility of real-world conditions. Concurrently, studies show that the extent of personalization is often limited by the volume of context and information that can be supplied to an agent, impacting the overall performance. (Zhou et al., 2025; Winder et al., 2024) One of the direct ways to address these limitations is to tune model with domain-specific context that integrates financial, behavioral, and psychological information. This work aims to close this gap by providing reproducible framework to generate financial advice through well-structured chain-of-thought. In particular, the framework constructs supervision data to train models to (a) provide personalized guidance for users financial dilemmas, (b) reliably apply core financial knowledge, and (c) recognize and mitigate user-side behavioral biases by integrating behavioral and historical evidence. To address these limitations, we propose novel, data-centric framework for synthesising behaviorally-grounded reasoning chains. Rather than relying on complex agentic architectures, our approach directly bakes financial, behavioural, and psychological knowledge into the training data itself. Crucially, we treat the inference of the users psychological state not as an afterthought, but as standalone, foundational phase in the reasoning chain. This design choice is directly motivated by recent findings that users trust and engagement are heavily influenced by the persona of the advisor (Takayanagi et al., 2025a), not just the raw accuracy of its advice. By isolating and explicitly modelling this psychological dimension, our framework ensures that personalisation and empathetic framing are intrinsic to the models reasoning process, leading to more effective and trustworthy financial guidance. It should also be considered that although recent agentic frameworks respond based on realtime knowledge; most of these knowledge sources need to be manually curated (Aggarwal and Singh, 2024). In addition to this, we should note that most of the recommendations needed for general financial advice do not require real-time financial knowledge. Instead, this advice needs an agent that can inherently retrieve the relevant information from its memory. We address this problem by carefully crafting chain-of-thought section to retrieve the financial context relevant to the query. Recent studies have shown that inherent biases often limit users ability to make many wealthmaking financial decisions. (Baker et al., 2017; Agrawal, 2012) These biases are highly variable and often depend on the age, experience and location of the user. Many financial agents do not directly address these biases when providing financial advice to the user. In this study, we have tried to integrate these biases into the reasoning models natural chain-of-thought to tune the final responses towards acknowledging and addressing these biases. Each stage of chain-of-thought generation is verified by set of Large Language Model juries that rank various generations and pick the best version suitable for the user queries. We used this framework to generate 19k sample dataset, which is used to finetune Qwen-3-8B model. This model is then compared to models of similar sizes to determine the impact of this framework. This paper introduces principled, data-centric framework as step toward smaller, more trustworthy personal finance LLMs, and we outline its use as backbone policy within agentic workflows to thin planning chains and lower orchestration costan evaluation we defer to future work."
        },
        {
            "title": "2 Related Works",
            "content": "The application of automated systems to financial advice is not new undertaking. Prior to the widespread adoption of large language models, research focused on applying classic techniques such as collaborative filtering and case-based reasoning to well-defined domains such as loan and insurance 2 policy recommendation, as surveyed by Zibriczky (2016). However, the advent of powerful LLMs has opened new frontiers and presented distinct set of challenges and approaches. Much of the recent literature has focused on benchmarking the capabilities of general-purpose LLMs on range of isolated financial tasks. For instance, comprehensive study by Hean et al. (2025) evaluated leading models such as ChatGPT and Claude against standardized financial literacy questionnaires covering diverse topics from mortgages to taxes. While their findings show that newer models are consistently improving and can achieve high accuracy on specific topics, they also reveal significant limitations, concluding that LLMs still struggle to provide accurate responses for complex financial queries. This highlights critical performance gap: off-the-shelf models are often insufficient for the nuanced demands of holistic financial advice. To overcome the limitations of single models and address more complex, multi-step planning, significant body of research has shifted towards developing sophisticated agentic workflows. recent survey by Ding et al. (2024) provides comprehensive overview of this landscape, categorizing these systems into distinct architectural patterns such as reflection-driven and debate-driven agents. clear example is the work of Okpala et al. (2025), who designed \"agentic crews\" composed of multiple specialized LLM agents, such as data scientists and compliance checkers, to automate the entire financial modelling and risk management pipeline. While powerful, such multi-agent systems demonstrate significant architectural complexity and high maintenance costs. Furthermore, research into these conversational agents has revealed significant risks; Takayanagi et al. (2025a) found in user study that participants often placed more trust in confident, \"extroverted\" agent even when it provided lower-quality advice, highlighting the potential for these complex systems to mislead inexpert users. We argue, however, that the primary bottleneck is not architectural complexity, but the inherent irrationality of the models themselves, necessitating data-centric approach. This need is rooted in the tendency of LLMs to amplify human cognitive biases. The groundbreaking work of Zhou et al. (2025) introduced comprehensive framework based on behavioral finance to demonstrate that LLMs exhibit significant financial biases, such as anchoring and overconfidence. Their crucial finding that fine-tuning on financial data can sometimes exacerbate these irrational tendencies underscores the profound risks of using uncurated data. This is supported by empirical studies exposing significant \"product bias\" in leading LLMs (Zhi et al., 2025) and by findings that LLM-generated advice systematically increases portfolio risk by reinforcing investment biases such as geographical concentration and trend chasing (Winder et al., 2024). Taken together, these findings reveal that models pre-trained knowledge is an unreliable and potentially risky foundation for financial advice. Therefore, our work addresses critical gap. While large-scale financial language models like FinGPT, which continuously ingest real-time market data to update and adapt the underlying model (Yang et al., 2023; Wang et al., 2023; Zhang et al., 2023; Liu et al., 2023), have been proposed, our approach differs fundamentally in its core contribution. Whereas such work focuses on scaling model capacity and live data ingestion, our work introduces novel and reproducible methodology for creating the supervision data itself. By integrating the relevant financial context with behavioral finance studies, we construct high-quality reasoning dataset designed to train smaller, more efficient end-to-end advisors that are grounded in sound, unbiased principles from their inception."
        },
        {
            "title": "3 Dataset construction",
            "content": "3.1 Data Collection and Processing Our first step was to collect large pool of realworld finance questions. Reddit (Reddit, [2025]) proved ideal as source of complex scenarios that span the breadth of personal finance domainsfrom debt consolidation and retirement planning to tax optimization and insurance decisions. The platforms subreddits, particularly r/personalfinance, which receives hundreds of thousands to millions of user queries, contain authentic scenarios that capture the intricate, multi-faceted nature of real financial decision-making, providing the scenario diversity essential for training comprehensive advisory models. To comply with Reddits terms and conditions, we exclusively utilized publicly available archived data from posts prior to June 2023, ensuring all collected queries were ethically sourced and properly de-identified. After ingestion, we filtered the raw corpus in two 3 Table 1: detailed breakdown of the dataset generated via our proposed framework. This table presents the distribution of approximately 19k samples across eight distinct categories of personal finance. Each category includes key metrics, such as the average token count for the initial query, the generated chain-of-thought delineating the reasoning steps, and the final answer. Category Description Debt Management & Credit Retirement Planning Tax Planning & Optimization Investing & Wealth Building Strategies for debt reduction (e.g. snowball, avalanche), credit-score improvement, and loan analysis. Strategies, income-needs analysis, benefits optimization (e.g. 401(k), pensions) and withdrawal strategies. Tax-minimization strategies, understanding deductions and credits, and investment-tax implications. Investment strategies based on risk tolerance, diversification, asset allocation, and long-term growth. Budgeting & Cash-Flow Management Creating budgets, Insurance & Risk Management Savings & Emergency Funds Estate Planning & Legacy tracking expenses, managing income streams, and improving cash flow. Assessing insurance needs (life, health, property), understanding policies, and managing financial risks. Strategies for building savings, establishing emergency funds, and goal-based saving. Wills, trusts, inheritance considerations, and minimising estate taxes (accounting for regional variations). Count 5175 Avg. Query Tokens 215.76 Avg. CoT Tokens 628.30 Avg. Response Tokens 393. 3286 198.10 648.28 407.02 3019 182. 630.20 397.81 2994 200.16 653.54 402. 2503 221.53 628.71 394.47 1035 213. 621.53 389.65 638 177.18 652.25 382. 196 216.90 653.47 409.06 stages: Topical validity retained posts that contained an explicit, answerable personal finance question (e.g., budgeting, credit, retirement), discarding generic news, advertisements, or off-topic commentary. Contextual clustering grouped semantically similar posts and removed nearduplicates to reduce noise. This pipeline yielded 405k unique questions. We sampled 19k representative queries that span eight thematic categories. Table 1 contains the detailed description of the final dataset generated using the framework. The entire 405k-item corpus remains available for future scaling. Details about prompt templates and specific instructions used in each phase of the generation framework are presented in Appendix A.1. 3.2 Generation methodology On high level, the dataset generation framework can be divided into two parts: (i) chain-of-thought generation and (ii) response generation. Our chain-of-thought generation is divided into four major phases, as illustrated in Fig. 1. This modular approach helps us focus on developing an independent rubric for each phase while giving the ability to stitch them together as coherent chain-of-thought. 3.2.1 Query Analysis The issue with natural language inquiries is the potential inconsistency of the information supplied to the model. There may be significant redundancy, or essential information may be hidden at times. Thus, the initial stage of answer creation, the question analysis phase, serves as fundamental step in which the users question is deconstructed into its essential components. This is required to ascertain the (i) primary conflict from the users input; (ii) the principal players in the dilemma; and (iii) the essential financial facts to address the inquiry. This facilitates the optimization of subsequent cognitive processes while remaining aligned with the users inquiry. 3.2.2 Context Analysis Context analysis (Modular RAG). After intent parsing, we assemble compact evidence pack via modular RAG framework (Gao et al., 2024) built on two self-curated corpora snapshotted through February 2025: (i) financial corpus of 600k 4 Figure 1: Dataset generation pipeline. Four modular chain-of-thought phases feed into final response generation. Each phase includes LLM-jury validation (not shown) to ensure quality. tokenspractical sources such as Investopedia and Bogleheads snapshot (Investopedia, 2025; Bogleheads, 2025) covering core concepts (e.g., retirement accounts, debt-repayment strategies), plus curated summaries of policy changes for major U.S. credit-card products and other consumerpolicy/market updates; and (ii) behavioral corpus of 300k tokensresearch and practitioner write-ups spanning psychology of risk, investor behavior, behavioral portfolio theory, behavioral asset pricing, psychological effects of debt, and generational differences. are chunks Candidate retrieved with text-embeddings-3-large (OpenAI, 2025b) re-ranked with all-MiniLM-L12-v2 (top-25), (Sentence-Transformers, 2021), and the top-15 are condensed by gemini-2.0-flash (Google, 2025; Team et al., 2025a) to remove residual noise and unify terminology. The streamlined context and the user query then feed the downstream reasoning stage. Further details are provided in Appendix B. 3.2.3 Psychological Cue identification In parallel to context identification, psychological cue identification module is run to identify cues from the text. We extract the overall sentiment of the text, the primary emotions identifiable from the choice of words in the query, and the level of certainty present in the information. Using these cues, we try to generalize set of communicative intents that might be behind the users query. By breaking down the assessment into four distinct categories, the process ensures comprehensive evaluation of the users intent. This intent is utilized to direct the final response into tone that is most suitable for the user, rather than directly providing them monotonous response. To operate the cue-identification at scale, and in line with the prior studies which demonstrate that state-of-the-art large language models outperform human annotators in judgment tasks(Bojic et al., 2025; OLeary, 2025), we adopt an LLM-based framework for cue identification similar to the other stages in the framework. 3.2.4 Response Formulation The final phase of the chain-of-thought is distinct response formulation phase, in which we synthesize set of instructions, consolidating information from all preceding phases. This produces set of directives that must be adhered to throughout the response-generation phase. 3.3 Response generation conclusive response is formulated to address the users inquiry, utilizing the previously optimized stages of information. This concluding comment is based on the financial context presented and is articulated in suitable tone for the user. 3.4 Data Validation Given that various open and proprietary LLMs automate numerous generations, there is clear necessity to assess and authenticate their outputs. We employed series of juries, specifically gemini-2.0flash and o4-mini (OpenAI, 2025a), to evaluate and rank various generations for each phase. Each juror assessed the created information within threeshot evaluation framework, ultimately selecting the highest-ranked response for subsequent generation jobs."
        },
        {
            "title": "4 Evaluation",
            "content": "To test whether our dataset enables practical decision support, we fine-tune Qwen-3-8B (Yang et al., 2025) for five epochs and compare it with baselines of similar size. We perform an additional assessment of the performance using two separate held-out datasets. We employ these methods to assess the quality of the responses through both quantitative and qualitative measures. 4.1 Quantitative Evaluation To assess the quantitative performance of the models, we utilize held-out dataset comprising 500 distinct queries across various categories of personal finance. Ground truths were produced by the generation framework presented in Section 3.2 (not the fine-tuned model) prior to training and validated by independent jurors. Following the ground-truth generation, we calculate the BERTScore (Zhang et al., 2020) using the Qwen-3-8B-embeddings (Zhang et al., 2025) model to assess the semantic accuracy of the responses. We also calculate the BLEURT (Sellam et al., 2020) score to assess the fluency (or) human-likeness of the responses, respectively. The quantitative scores of various models utilized in this evaluation are detailed in Table 2. Our 8B model achieves semantic accuracy comparable to leading baselines, including Gemma327B/12B and Mistral-24B. In particular, our model surpasses these larger models by approximately 35% in human-likeness and fluency. This indicates reduced deviation from ground-truth data and enhanced fluency signals compared to models twice its size. 4.2 Qualitative Evaluation To complement reference-based metrics and, critically, to assess the models generalization capabilities, we run list-wise blind LLM-jury ranking on 504 queries that were entirely held out and unseen during the training phase. These test queries were collected from subsequent time period to ensure no data contamination. Meanwhile, all the candidates were zero-shot generated in their respective Model BERTScore BLEURT Gemma3-27B-IT (Team et al., 2025b) Gemma3-12B-IT Mistral-24B-2501 (MistralAI, 2025b) QWQ-32B (Qwen, 2025) (reasoning) 0.7142 0. 0.7139 0.4390 0.7133 0.4464 0.7069 0. DeepSeek-Qwen-14B (reasoning) (DeepSeekAI, 2025) Ours (8 B) Llama-3 8B (Meta, 2024) Mistral-7B v0.3 (MistralAI, 2025a) 0.7069 0.7000 0.6881 0.4513 0.4600 0.4547 0.6650 0.4501 Table 2: Automatic evaluation on the 500-query test set. Bold marks the best score in each column; higher is better. default inference settings to get their best performance. This setup allows us to evaluate whether our fine-tuned model has merely learned to mimic the training data or if it has successfully internalized generalizable framework for the response generation that can be applied to novel user problems. To mitigate familial bias and leakage, we excluded judges from model families used anywhere in our pipeline. In particular, Gemini models were omitted because they were used during dataset generation/validation, and Qwen-family judges were omitted because the system under test is Qwen-8B. few otherwise suitable judges were also excluded for cost reasons. The final judge pool comprises models from unrelated families; none overlapped with training or data-creation components. For each query, every judge sees all anonymized candidates simultaneously (no ground truth and no model identities) and returns full ranking; candidate order is uniformly randomized per replicate. We use two main judges, namely DeepSeek-V3-0324 (DeepSeek-AI et al., 2025) and Kimi-k2 (AI, 2025). Kimi-k2 is run three times, and DeepSeek-v3-0324 is run five times on independently shuffled anonymized candidate orders for each query to reduce possible biases. These judges were chosen in order to avoid same-family bias prevalent in modern LLM-judge studies. 6 Table 3: Rank correlations between judge sets (higher is better). τ measures how often the judges agree with > B, and ρ measures how closely the full rank lists track. Metric Kendalls τ Spearmans ρ Plausibility Accuracy Relevance Overall 0.6183 0.6183 0.6910 0. 0.7711 0.7635 0.8264 0.7904 are The rankings converted to Borda points(Saari, 2023) and averaged across judges and replicates to obtain the representative score of response. We receive the ranking judgments according to three criteria, namely their financial accuracy, plausibility, and relevance to the query, and report the aggregate Borda scores in Fig.2. Whereas Appendix C.1 presents the in-depth analysis of the evaluation results. To examine rank consistency between the judge sets, we compute Kendalls τ and Spearmans ρ over per-query model ranks. Kendalls τ assesses pairwise order agreement (do both judges prioritize model above model B?). Spearmans ρ assesses how closely the complete ranked lists move together and penalizes significant rank differences. We observe τ 0.62-0.69 and ρ 0.76-0.83 (overall τ = 0.64, ρ = 0.79), indicating substantial agreement. The consistently higher ρ than τ suggests disagreements are mostly local swaps rather than wholesale reorderings. Relevance demonstrates the strongest alignment (τ = 0.691, ρ = 0.826). Table 3 shows τ and ρ for each metric and overall. Our experimental results demonstrate that wellcurated, behavior-tuned finance dataset can elevate an 8B open model to achieve performance parity with models two to three times its size, thus validating the practical utility of our framework. Details about the entire training environment and settings are presented in Appendix D. 4.3 Qualitative Analysis and Error Patterns Analysis of the 504 held-out responses reveals consistent patterns across the three evaluation dimensions. When models produce inaccurate responses, they typically also exhibit degraded reasoning qualityaccuracy and plausibility failures often cooccur. However, relevance remains relatively independent; responses can stay on-topic and address Figure 2: LLM-jury evaluation on 504 unseen subreddit queries: stacked bars show Borda-average scores for accuracy (blue), plausibility (orange), and relevance (green); taller bars indicate stronger overall preference. Our 8 system (fourth from left) outperforms all other sub-14 models and approaches the 27 B32 leaders. The y-axis represents the average Borda points model has received. user constraints even when containing factual errors or poor reasoning. Strengths. The model consistently produces well-structured responses with clear headers, sequential action steps, and appropriate empathetic framing. It reliably extracts user-specific details (monetary amounts, timelines, constraints) and incorporates them into tailored advice. Responses typically acknowledge emotional context before providing practical guidancea pattern that enhances perceived helpfulness. Failure Modes. The primary weakness is factual hallucination, particularly for jurisdiction-specific regulations and tax details. The model occasionally generates plausible-sounding but incorrect specifics (e.g., non-existent grant programs, outdated tax brackets). These errors are most frequent in regulation-heavy domains (taxes, insurance) and least common in general planning tasks (budgeting, debt management). Implications. While the model maintains strong structural and empathetic qualities across all responses, factual grounding remains the key bottleneck. This suggests that adding targeted retrieval for regulatory information and calculation verification would yield the highest marginal improvement. Even with current limitations, the models consistent task alignment and user-responsive framing provide practical utility for non-critical advisory scenarios. 4.4 Cost Analysis Beyond performance metrics, practical deployment requires careful cost consideration. Table 4 presents comprehensive cost analysis of the model produced by our framework against several baselines, comparing hosting infrastructure, inference latency, and total operational expenses. Our data-centric approach delivers exceptional cost efficiency in the personal finance domain. By enabling compact 8B model to achieve performance competitive with much larger systems, our method facilitates at least an 80% reduction in operational costs when compared to baselines with over 12B parameters. This dramatic cost reduction stems from targeted behavioral integration and principled data construction, rather than sheer computational scale. The efficiency translates to practical deployment advantages: at hosting cost of $0.8 per hour and an average inference time of 34.15 seconds, our model enables responsive financial advisory services without prohibitive infrastructure requirements. These results validate the effectiveness of our novel data generation framework. They demonstrate that by carefully integrating financial and behavioral signals into training data, it is possible to create competent, domain-specific models that are also economically viable. This presents compelling approach for developing production-ready financial advisory tools that do not rely solely on expensive, large-scale models."
        },
        {
            "title": "5 Future Works",
            "content": "We will advance this research by first determining the optimal path for global scaling: either finalizing US-optimized pipeline for systematic market porting orcontingent on high-precision detection of regional signals (e.g., currency symbols, policy terminology, and spelling conventions)implementing Mixture-of-Experts (MoE) framework. In the latter case, shared backbone model will process universal financial logic while lightweight regional experts handle localized nuances. This core model will deploy as backbone policy within thin agentic stack, minimizing latency and cost by resolving queries internally and invoking external tools (e.g., regulatory databases or fact-checking APIs) only for uncertainty resolution. We will rigorously measure resulting costlatency trade-offs across regions. Rather than additional supervised fine-tuning, we will treat financial advice generation as an alignment problem, testing preference-based optimization (e.g., DPO/IPO) to refine outputs and deploying rule-based compliance layers to enforce regulatory fidelity, bias mitigation, and tone consistency. Success will be quantified through targeted evaluations of safety, compliance adherence, and user trust metrics."
        },
        {
            "title": "6 Conclusion",
            "content": "Our research establishes data-centric framework that enables an 8B-parameter model to achieve semantic fidelity and human-likeness on par with, and sometimes exceeding, 2732B baselines in our held-out evaluations and blind LLM-jury study. On 500-query test, the model outperforms Gemma327B by 5% on BLEURT and is competitive on BERTScore, with only 2% difference; jury rankings show the 8B system approaching the 2732B leaders. These gains stem from three synergistic components: explicit psychological cues, retrievalaugmented grounding, and thin agentic execution layer. The modular design supports incremental extension (e.g., regional experts with minimal retraining). While geographic scope, behavioral depth, and privacy safeguards remain limitations, this work offers cost-aware backbone for standalone personal-finance assistants and viable alternative to monolithic cloud deploymentsleaving precise cost/latency audit to future work."
        },
        {
            "title": "Limitations",
            "content": "Several aspects of our work leave room for future improvements. First, our study is limited to inquiries sourced solely from Reddit, which may overlook other demographics and query formats, suggesting need for more diverse data sources. Second, our 19k sample dataset, though sufficient for proof-of-concept, lacks the scale and diversity needed to cover the full spectrum of real-world personal finance scenarios. Future work should expand the corpus with varied sources beyond Reddit to improve generalization. Third, our psychological analysis remains rudimentary, deriving only basic sentiment from phrases rather than incorporating enhanced psychological indicators such as risk tolerance or financial stress through specialized surveys or transfer learning from clinical datasets. Finally, our frameworks scope excludes tasks beyond core natural language processing, particularly multi-modal data processing and reasoning capabilities, which represent critical areas for future 8 Table 4: Cost and Inference Performance Analysis for Deployment. Total costs reflect the expense to infer 504 queries from the test set, with each model benchmarked using four concurrent requests. Model Size (GB) Endpoint Cost GPU Inference Time Total Time Total Cost ($/h) 3.8 2.5 1.8 0.8 3.8 1.8 0.8 0.8 4xL4 1xA100 1xL40S 1xL4 1xA100 1xL40S 1xL4 1xL4 (s/query) 167.86 64.34 58.26 34.15 37.99 54.18 33.58 29. (h) 5.82 2.23 2.02 1.19 1.32 1.88 1.17 1.01 ($) 22.33 5.63 3.67 0.96 5.05 3.41 0.94 0.82 QWQ-32B Gemma3-27B Gemma3-12B Ours (8B) Mistral-24B-2501 DeepSeek-Qwen-14B Llama3-8B Mistral-7B 65.0 46.4 20.0 16.4 46.1 29.5 16.1 14. research expansion."
        },
        {
            "title": "Acknowledgements",
            "content": "I want to express my sincere gratitude to Raghu Ram Theerthala (KPIT Technologies) for his valuable contributions to the related works section and insightful discussions during the brainstorming sessions that helped shape this research. am grateful to Prathyusha Akundi, Syed Md. Bilal, Ashish Kubade, and Sai Narayan for their careful review of the manuscript and constructive feedback that improved the clarity and quality of this work. This research was supported by Perfios Software Solutions, which sponsored the computational costs and infrastructure required for model training and evaluation. Data & Code Availability The dataset, model, and code artifacts described in this paper are publicly available on Hugging Face. All data has been de-identified following the ethical guidelines described in Section 6, with personally identifiable information removed from Reddit sources. The resources are released under the Apache 2.0 license to facilitate reproducibility and future research in behavioral finance and LLM applications. The following resources are available: Model: Fine-tuned Qwen-3-8B model at https://huggingface.co/ Akhil-Theerthala/Kuvera-8B-qwen3-v0. 2. Dataset: 19k sample reasoning dataset at https://huggingface.co/ datasets/Akhil-Theerthala/ Kuvera-PersonalFinance-V2."
        },
        {
            "title": "Ethical Considerations",
            "content": "We curate data from publicly available Reddit posts and aggressively de-identify them: user- (e.g., names/links/metadata are removed, PII names, emails, phone numbers, addresses, IDs) is scrubbed, and queries are lightly rephrased so only the financial situation remains; no raw identifiers are stored or released. The system is for educational use onlynot fiduciary or personalized financial adviceand our prompts/filters forbid unsafe guidance (e.g., evasion, guaranteed returns). Evaluation uses multiple LLM judges; we report inter-judge agreement and run judge-swap checks to limit model-family bias."
        },
        {
            "title": "References",
            "content": "Rohit Aggarwal and Harpreet Singh. 2024. Overcoming limitations of ai agents: Integrating tacit knowledge through inferred latent themes. Available at SSRN 4843878. Khushbu Agrawal. 2012. conceptual framework of behavioral biases in finance. IUP Journal of Behavioral Finance. Moonshot AI. 2025. Kimi-k2-instruct (revision 2f7e011). Kent Baker, Greg Filbeck, and Victor Ricciardi. 2017. How behavioural biases affect finance professionals. The European Financial Review, pages 2529. Bogleheads. 2025. Bogleheads - investing advice inspired by john bogle. Ljubiša Bojic, Olga Zagovora, Asta Zelenkauskaite, Vuk Vukovic, Milan ˇCabarkapa, Selma Veseljevic Jerkovic, and Ana Jovanˇcevic. 2025. Comparing large language models and human annotators in latent content analysis of sentiment, political leaning, emotional intensity and sarcasm. nature briefing. Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, Kannan Ramchandran, Matei Zaharia, Joseph E. Gonzalez, and Ion Stoica. 2025. Why do multi-agent llm systems fail? Preprint, arXiv:2503.13657. DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, and 181 others. 2025. Deepseek-v3 technical report. Preprint, arXiv:2412.19437. DeepSeekAI. 2025. deepseek-ai/deepseek-r1-distillqwen-14b. Han Ding, Yinheng Li, Junhao Wang, and Hang Chen. 2024. Large language model agent in financial trading: survey. Preprint, arXiv:2408.06361. Yunfan Gao, Yun Xiong, Meng Wang, and Haofen Wang. 2024. Modular rag: Transforming rag systems into lego-like reconfigurable frameworks. Preprint, arXiv:2407.21059. Google. 2025. Gemini 2.0 flash. https://cloud. google.com/vertex-ai/generative-ai/docs/ model-reference/inference. Almog Gueta, Amir Feder, Zorik Gekhman, Ariel Goldstein, and Roi Reichart. 2025. Can llms learn macroeconomic narratives from social media? Preprint, arXiv:2406.12109. Udit Gupta. 2023. Gpt-investar: Enhancing stock investment strategies through annual report analyarXiv preprint sis with large language models. arXiv:2309.03079. Xuewen Han, Neng Wang, Shangkun Che, Hongyang Yang, Kunpeng Zhang, and Sean Xin Xu. 2024. Enhancing investment analysis: Optimizing aiagent collaboration in financial research. Preprint, arXiv:2411.04788. Oudom Hean, Utsha Saha, and Binita Saha. 2025. Can ai help with your personal finances? Applied Economics, page 19. Zengyi Huang, Chang Che, Haotian Zheng, and Chen Li. 2024. Research on generative artificial intelligence for virtual financial robo-advisor. Academic Journal of Science and Technology, 10(1):7480. Investopedia. 2025. Investopedia. https://www. investopedia.com/. Satyadhar Joshi. 2025. comprehensive review of gen ai agents: Applications and frameworks in finance, investments and risk domains. International Journal of Innovative Science and Research Technology, pages 13391355. Kausik Lakkaraju, Sara Jones, Sai Krishna Revanth Vuruma, Vishal Pallagani, Bharath Muppasani, and Biplav Srivastava. 2023. Llms for financial advisement: fairness and efficacy study in personal decision making. In Proceedings of the Fourth ACM International Conference on AI in Finance, ICAIF 23, page 100107, New York, NY, USA. Association for Computing Machinery. Meisin Lee and Soon Lay-Ki. 2024. finance wizard at the finllm challenge task: Financial text summarization. Preprint, arXiv:2408.03762. Jinzheng Li, Jingshu Zhang, Hongguang Li, and Yiqing Shen. 2024. An agent framework for real-time financial information searching with large language models. Preprint, arXiv:2502.15684. Xiao-Yang Liu, Guoxuan Wang, Hongyang Yang, and Daochen Zha. 2023. Data-centric fingpt: Democratizing internet-scale data for financial large language models. NeurIPS Workshop on Instruction Tuning and Instruction Following. Zhaowei Liu, Xin Guo, Fangqi Lou, Lingfeng Zeng, Jinyi Niu, Zixuan Wang, Jiajie Xu, Weige Cai, Ziwei Yang, Xueqian Zhao, Chao Li, Sheng Xu, Dezhi Chen, Yun Chen, Zuo Bai, and Liwen Zhang. 2025. Fin-r1: large language model for financial reasoning through reinforcement learning. Preprint, arXiv:2503.16252. Zian Liu and Renjun Jia. 2025. Llm4fts: Enhancing large language models for financial time series prediction. Preprint, arXiv:2505.02880. Yichen Luo, Yebo Feng, Jiahua Xu, Paolo Tasca, and Yang Liu. 2025. Llm-powered multi-agent system for automated crypto portfolio management. arXiv preprint arXiv:2501.00826. Glenn Matlin, Mika Okamoto, Huzaifa Pardawala, Yang Yang, and Sudheer Chava. 2025. Finance Preprint, language model evaluation (flame). arXiv:2506.15846. Kiana Jafari Meimandi, Gabriela Aránguiz-Dias, Grace Ra Kim, Lana Saadeddin, and Mykel J. Kochenderfer. 2025. The measurement imbalance in agentic ai evaluation undermines industry productivity claims. Preprint, arXiv:2506.02064. Meta. 2024. meta-llama/llama-3.1-8b-instruct. MistralAI. 2025a. mistralai/mistral-7b-instruct-v0.3. MistralAI. 2025b. mistralai/mistral-small-24b-instruct2501. Izunna Okpala, Ashkan Golgoon, and Arjun Ravi Kannan. 2025. Agentic ai systems applied to tasks in financial services: Modeling and model risk management crews. Preprint, arXiv:2502.05439. 10 Daniel E. OLeary. 2025. Editorial: Analysis of sentiment estimates and cognitive fallacies in large lanIntelligent Systems in Accounting, guage models. Finance and Management, 32(3):e70010. E70010 9691779. 2025a. OpenAI. card. 2221c875-02dc-4789-800b-e7758f3722c1/ o3-and-o4-mini-system-card.pdf. system https://cdn.openai.com/pdf/ o4-mini and OpenAI. 2025b. Openai text-embeddings-3. Qwen. 2025. Qwen/qwq-32b. Reddit. [2025]. Reddit: The heart of the internet. https://www.reddit.com. Donald G. Saari. 2023. Selecting voting method: the case for the borda count. Constitutional Political Economy, 34(3):357366. Javier Sanz-Cruzado, Edward Richards, and Richard McCreadie. 2024. Far-ai: modular platform for investment recommendation in the financial domain. In Advances in Information Retrieval, pages 267271, Cham. Springer Nature Switzerland. Thibault Sellam, Dipanjan Das, and Ankur P. Parikh. 2020. Bleurt: Learning robust metrics for text generation. Preprint, arXiv:2004.04696. Sentence-Transformers. 2021. all-minilm-l12-v2. Takehiro Takayanagi, Kiyoshi Izumi, Atsuo Kato, Naoyuki Tsunedomi, and Yukina Abe. 2023. Personalized stock recommendation with investors attention and contextual information. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 23, page 33393343, New York, NY, USA. Association for Computing Machinery. Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Rivière, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Etienne Pot, Ivo Penchev, and 197 others. 2025b. Gemma 3 technical report. Preprint, arXiv:2503.19786. Kesen Wang, Daulet Toibazar, Abdulrahman Alfulayt, Abdulaziz S. Albadawi, Ranya A. Alkahtani, Asma A. Ibrahim, Haneen A. Alhomoud, Sherif Mohamed, and Pedro J. Moreno. 2025. Multi-agent interactive question generation framework for long document understanding. Preprint, arXiv:2507.20145. Neng Wang, Hongyang Yang, and Christina Dan Wang. 2023. Fingpt: Instruction tuning benchmark for opensource large language models in financial datasets. NeurIPS Workshop on Instruction Tuning and Instruction Following. Philipp Winder, Christian Hildebrand, and Jochen Hartmann. 2024. Biased echoes: Generative ai models reinforce investment biases and increase portfolio risks of private investors. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, and 41 others. 2025. Qwen3 technical report. Preprint, arXiv:2505.09388. Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. 2023. Fingpt: Open-source financial large language models. FinLLM Symposium at IJCAI 2023. Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu. 2023. Instruct-fingpt: Financial sentiment analysis by instruction tuning of general-purpose large language models. FinLLM Symposium at IJCAI 2023. Takehiro Takayanagi, Kiyoshi Izumi, Javier SanzCruzado, Richard McCreadie, and Iadh Ounis. 2025a. Are generative ai agents effective personalized financial advisors? Preprint, arXiv:2504.05862. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Preprint, Evaluating text generation with bert. arXiv:1904.09675. Takehiro Takayanagi, Masahiro Suzuki, Kiyoshi Izumi, Javier Sanz-Cruzado, Richard McCreadie, and Iadh Ounis. 2025b. Finpersona: An llm-driven conversational agent for personalized financial advising. In Advances in Information Retrieval, pages 1318, Cham. Springer Nature Switzerland. Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, Fei Huang, and Jingren Zhou. 2025. Qwen3 embedding: Advancing text embedding and reranking through foundation models. Preprint, arXiv:2506.05176. Gemini Team, Rohan Anil, Sebastian Borgeaud, JeanBaptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou, and 1332 others. 2025a. Gemini: family of highly capable multimodal models. Preprint, arXiv:2312.11805. Yuhan Zhi, Xiaoyu Zhang, Longtian Wang, Shumin Jiang, Shiqing Ma, Xiaohong Guan, and Chao Shen. 2025. Exposing product bias in llm investment recommendation. Preprint, arXiv:2503.08750. Yuhang Zhou, Yuchen Ni, Zhiheng Xi, Zhangyue Yin, Yu He, Gan Yunhui, Xiang Liu, Zhang Jian, Sen Liu, Xipeng Qiu, Yixin Cao, Guangnan Ye, and Hongfeng Chai. 2025. Are LLMs rational investors? study on the financial bias in LLMs. In Findings of the Association for Computational Linguistics: ACL 2025, pages 2413924173, Vienna, Austria. Association for Computational Linguistics. 10 11 12 13 14 --- ** Inputs **: { inputs } --- ** Your Response **: \"\"\" David Zibriczky. 2016. Recommender systems meet finance: literature review. In International Workshop on Personalization & Recommender Systems in Financial Services. A.1.2 Individual Phases 1. Classification:"
        },
        {
            "title": "A Prompting Guidelines followed for the\ngeneration and evaluation stages",
            "content": "A.1 Guidelines followed in the generation stage. This section focuses on outlining the guidelines followed in crafting the prompts for each phase of generating and evaluating the outputs. A.1.1 Overarching principles There are three core principles followed for the process of crafting the prompts: a. Modularity b. Deconstruction c. Personification The goal of the overall prompt crafting is to keep the overall structure of the prompts similar and swappable depending on the task at hand. As with the framework, where the complex task of generating suitable response is broken down into individual phases, the prompts are broken down to make sure the structure of the instructions given to the model remains the same. Each stage of the prompting had unique, suitable persona (e.g., linguistic analysis expert, expert financial reasoning engine). This role-playing technique primes the model to access relevant knowledge, adopt the appropriate tone, and constrain its behavior to the specific requirements of the task. The generic structure of the prompt is as follows: \"\"\" You are { persona }, whose task is to { task_details }. ### INSTRUCTION ### { instructions_for_the_task } ### Key Points ### { key_points_to_keep_in_mind } 1 2 3 4 5 6 7 8 9 12 a. The primary goal of this stage is to classify incoming user queries into suitable categories of personal finance. The prompt constrains the model by forcing single-label classification (ONE of the following) based on PRIMARY INTENT, which prevents ambiguity and ensures decisive output for downstream routing. b. Each category has Scope and an example that the model uses to make its decisions. If the query does not fall into any of the categories, the query is labeled Not_Applicable. 2. Query Analysis: a. The primary goal of this prompt is to direct the model to break down the user query into more specific and manageable pieces of information. b. Since most of the user queries on Reddit and in general are often filled with unrelated noise, this stage directs the model to distil the users query into essential semantic elements, eliminating the conversational distractions and concentrating on actionable concerns and their impact on the key stakeholders. 3. Context Analysis: a. The context analysis is one of the key prompts that influences the quality of the output by the framework. The prompt directs the final model to generate actionable and insightful contextual summaries that are placed into the models natural chain-of-thought. b. The prompt explicitly asks for Concise chain-of-thought Analysis Block and instructs the model that this is an internal reasoning step, not the final answer. This step forces the model to externalise its reasoning process, exploring multiple scenarios and their consequences before concluding. c. By requiring the model to detail the Stakeholder Impact for each approach, the prompt ensures holistic analysis that considers the financial and emotional consequences for all relevant parThis ties mentioned in the query. scenario-based analysis moves the responses beyond simple fact-based analysis to more human-centred form of reasoning. 4. Psychological analysis a. The goal of this prompt is to direct the model and extract the key information about the users state of mind when asking the query. b. The prompt demands that every conclusion about sentiment, emotion, or intent be justified by referencing specific words or phrases. This approach grounds the analysis in textual evidence, preventing the model from making unfounded psychological assumptions and improving the explainability of its affective understanding. c. This analysis is separate step from the financial reasoning (Context Analysis). This deliberate separation prevents the users emotional state from biasing the objective financial analysis, and viceversa, allowing for final response that can synthesise both aspects without compromising either. 5. Response Rubric a. This stage consolidates all the previously collected information and creates complete rubric that can direct the model into generating the final response. 1 2 3 4 5 6 7 8 9 b. The key information from the previ10 ous stages gets highlighted while being 11 linked to different parts of the user query for easier reference and understanding. 12 13 14 15 16 17 a. This final stage synthesises all preced18 ing analyses into coherent, user-facing 19 response. 20 6. Response Generation b. The prompt provides the model with all previous outputs (the original query and the comprehensive chain-of-thought) and explicitly instructs it to integrate both factual accuracy and emotional intelligence seamlessly. It acts as final \"assembly\" instruction, guiding the model on how to combine the rational and affective components. c. The use of clear positive (Do) and negative (Do not) instructions creates strict behavioral boundaries. For instance, \"Do not reference the chain-of-thought analysis\" ensures the final output is natural and user-friendly, hiding the complex underlying cognitive architecture from the enduser. These instructions create helpful response without being robotic or transparent about its inner workings. d. These responses are generated in way that ensure the ability to train nonreasoning models from the same dataset. A.2 Prompt Guidelines for Evaluation through LLM-as-a-Judge The goal of the evaluation is to determine which responses are naturally ranked better than the others. Since this is list-wise ranking with high room for confusion or hallucination, the evaluation criterion are strictly defined. The overall prompt structure for each of the case are as follows: \"\"\" You are a{ persona }. Your task is to rank financial advice responses from best to worst based * solely * on the strict definition of { target_aspect }. ### ** Evaluation Criteria ** { Evaluation Criterion } #### ** I. Primary Criteria ( What to look for ) :** { primary_set_of_instructions } #### ** II . Explicit Penalties ( What to penalize ) :** { penalizing_instructions } #### ** III . Key Points to note :** { additional_instructions } --- ** Query :** { query } ** Responses to Rank :** 13 21 { anonymized_shuffled_model_responses } \"\"\" 1. Accuracy: a. The goal of this prompt is to direct the model to review the search results and the query to estimate the accuracy of the output. b. The responses are penalized if and only if the responses demonstrate wrong/harmful advice (or) inappropriate financial concepts to the query. c. The model is specifically instructed not to penalise on the style or relevance of the response and solely focus on the accuracy of the financial concepts provided in the text. This guides the model to rank solely based on the accuracy of the financial concepts present in the response. 2. Plausibility: a. response is defined to be plausible if it sounds reasonable and believable to typical user. Some of the key characteristics include Logical flow and coherent reasoning structure Sensible approach to the problem b. response is penalized if it contains unnecessarily verbose or contain excessive detail. The responses are also penalized if they contain complex or hard-to-follow reasoning. c. The model is specifically instructed not to penalise on the accuracy or relevance of the responses."
        },
        {
            "title": "B Modular RAG for Context Analysis",
            "content": "Goal. Given user query, the context-analysis phase assembles compact, high-signal context pack from two specialized corpora: (i) Behavioral insights (behavioral economics and psychology) and (ii) Financial concepts (mainstream personal finance knowledge). The context pack is then passed to the response generator. Corpora. Behavioral insights are sourced from peer-reviewed research and reputable psychology venues, complemented by carefully selected psychology blogs for practitioner framing. Financial concepts are drawn from practical, high-visibility sources such as Investopedia, Bogleheads, and other widely cited personal-finance viewpoints. All raw pages are converted to Markdown with headers and section structure preserved to retain document semantics. Preprocessing and indexing. Scraping & normalization: We scrape public pages (respecting robots/terms), remove boilerplate (nav, ads), and normalize to Markdown with stable headings. Semantic chunking: Documents are segmented into modular chunks along header/semantic boundaries to keep each chunk topically coherent; we attach metadata (source, URL or handle, snapshot time, section path, corpus tag: behavioral or financial). Dense indexing: Each chunk is embedded with text-embeddings-large-003 and stored in vector databsase (ChromaDB). Retrieval and re-ranking (per query). 1. Dual retrieval: From each index, retrieve the top-k candidates (k=25) using the query embedding. 3. Relevance: a. response is considered relevant if it address every component of the users query. relevant response should incorporate the specific figures, constraints, and details mentioned in the users query, and answer the questions immediately without generic introductions. b. Any partial relevance or additional context not relevant to the query is penalized. 2. Cross-encoder re-ranking: Concatenate candidates from both corpora and re-rank with lightweight cross-encoder (sentence-transformers/all-minilm-l12-v2); keep top-m (m=15). 3. LLM synthesis/filter: fast LLM (gemini-2.0flash) receives {top-m chunks, query} and (a) extracts salient facts, definitions, and decision criteria; (b) discards residual off-topic spans; (c) emits streamlined, source-attributed context. 14 Assembly and handoff. The streamlined context (with inline source attributions and corpus tags) is passed, together with the user input, to the final LLM that completes the context-analysis phase. Behavioral vs. financial module roles. The behavioral module surfaces cognitive-bias descriptors, debiasing tactics, and user-state cues (e.g., loss aversion framing, present bias prompts). The financial module surfaces actionable rules of thumb, definitions, procedures, and typical constraints (e.g., contribution limits, insurance concepts, payoff ordering heuristics). Both modules contribute to the same context pack; behavioral cues guide how advice is framed, while financial chunks ground what advice is provided. Limitations. (1) Coverage and staleness depend on the snapshot of public sources; (2) blogs can introduce style bias despite re-ranking; (3) the synthesis step may over-prioritize well-structured sources. We mitigate these by preserving source attributions, tracking snapshot timestamps, and prompting synthesis to prefer higher-priority sources when conflicts arise."
        },
        {
            "title": "C Deeper Evaluation Results",
            "content": "C.1 Score Definitions and Rationale We evaluate responses along three orthogonal axesAccuracy, Plausibility, and Relevanceto separate factual correctness, reasoning quality, and task alignment. This decomposition avoids single scalar that can reward fluent but unsafe answers or penalize terse yet correct ones, and it enables targeted error analysis and ablations. Accuracy (financial correctness). Objective. Judge reviews the response against the query and retrieved evidence and scores only the validity of financial concepts, calculations, and advice. Penalties. Deductions occur iff the answer contains wrong or harmful guidance, or misapplies financial concepts to the users situation. Non-considerations. Style, tone, verbosity, and even partial coverage are not penalized; the judge is instructed to focus exclusively on correctness. Plausibility (reasoning quality). Objective. Assess whether the answer reads as reasonable and believable to typical useri.e., it exhibits clear logical flow and coherent problem-solving structure. Penalties. Overly verbose, needlessly complex, or hard-to-follow chains of reasoning are penalized. Non-considerations. Factual correctness and topical coverage are not scored here; the lens is purely rhetorical/structural. Relevance (task alignment). Objective. Verify that the response directly addresses every component of the users query, incorporates the users numbers, constraints, and context, and answers without generic preambles. Penalties. Partial coverage, tangential content, or extra context not pertinent to the query is penalized. Non-considerations. Factual accuracy and stylistic polish are ignored for this axis. C.2 Borda Points Definition. For listwise ranking of systems, the item placed at rank (r = 1 is best) receives Borda score = r, so the top entry gets 1 points and the last gets 0. Motivation. Borda aggregation is wellsuited to LLM-as-a-judge experiments where relative quality matters more than absolute scores: Full-order utilisation: every position contributes signal, ensuring that small but consistent advantages are captured rather than discarded by winner-takes-all rules. Cardinal comparability: with fixed candidate set, raw points can be averaged across queries and judges without normalisation, giving stable, interpretable mean. Robustness to mild noise: swapping adjacent middle ranks changes the total by only 1, so individual judge idiosyncrasies exert limited influence on the final average. Interpretation. Higher mean Borda points indicate that system outranks its peers more often. The maximum possible mean is 1; the gap to this ceiling offers an intuitive sense of head-room. Limitations. Rank-reversal: inserting or removing candidate can change every systems score, complicating longitudinal comparisons. Independence of Irrelevant Alternatives (IIA) violation: judges relative preference between two systems can affect, and be affected by, ranks assigned to others. Equal-interval assumption: the method treats the gap between successive ranks as uniform, ignoring situations where judges perceive larger quality jumps near the top. Strategic susceptibility: if human judges know what influences the aggregation, they could inflate or deflate lower ranks to benefit favored system. C.3 LLM-Jury Protocol LLM-based judging scales across topics, is inexpensive, and achieves strong agreement with human raters when rubrics are explicit and task context is provided. It also captures holistic qualities (e.g., coherence, task fit) that single-number similarity metrics may miss. It should be noted that zero-shot judging is vulnerable to position bias (earlier items rank higher), same-family bias (preference for outputs from the judges own family), and prompt/leniency variance. We therefore (i) use multi-shot prompts to anchor criteria, (ii) evaluate with listwise ranking on independently shuffled candidate lists, and (iii) diversify judges across model families to minimize correlated bias. Judge pool and prompting. We employ two main heterogeneous judges: DeepSeek-v3-0324 (5shot), Kimi-k2 (3-shot). For each query and criterion (Accuracy, Plausibility, Relevance), judges rank anonymized model outputs in single list. Few-shot exemplars are held constant within run and varied across repeats to reduce overfitting to any one demonstration set. subsample of these rankings were further validated by o4-mini model to consolidate the relative performance. Scoring and aggregation (per criterion). For each query, judges perform multi-shot listwise ranking over anonymized outputs using the rubrics in Sec. C. Ranks are converted to raw Borda points = r. We then: 1. average across shuffles/repeats for each judge; 2. average across the judges to obtain per-query, per-criterion score for each model; 3. average across all queries within category (e.g., the overall set or PF subcategory) to obtain the models criterion-wise mean in that category. The stacked bars in Fig. 2 display these criterionwise means (Accuracy, Plausibility, Relevance) for each model. For single category-level number, we also report the unweighted average of the three criterion-wise means as the models final representation score in that category. C.4 Overall Category Scores (Accuracy, Plausibility, Relevance) We report criterion-wise means derived from the raw Borda points assigned by the LLM jury (Sec. C.3). For each criterion and model, scores are averaged across judges and queries within the overall set. Higher is better. Accuracy. Figure 3 shows size-tilted pattern: QwQ-32B (reasoning) leads, followed by Gemma327B-it and Gemma3-12B-it. Mistral-Small-24B sits between this top cluster and the rest. The proposed 8B model is mid-packbehind the leaders and the 24B baseline, but ahead of several 714B baselines. This points to factual calibration and retrieval/verification as the primary levers to close the gap, rather than rewriting or stylistic tuning. Plausibility. As shown in Fig. 4, QwQ-32B ranks first, with Gemma3-27B-it next. The proposed 8B clusters near the front: it exceeds the Mistral-Small24B baseline but trails Gemma3-12B-it. This suggests that the dataset structure and few-shot conditioning induce coherent reasoning steps and sensible flow even at mid scale. Relevance. Figure 5 indicates strong task alignment at the top end (QwQ-32B, Gemma3-27B-it, Gemma3-12B-it). The proposed 8B ranks next (4/8), ahead of the remaining baselines, suggesting it reliably maps user constraints and addresses all parts of the query without drifting into generic preambles. The residual gap likely reflects cases that require exhaustive edge handling (e.g., niche eligibility rules) rather than broad intent recognition. Cross-criterion takeaway. Across criteria, the proposed 8B model is plausibility and relevancecompetitive while lagging most on accuracy. The 16 Figure 3: Accuracy (mean raw Borda points per query, averaged over judges). size-driven lead is visible; the proposed 8B is mid-pack, indicating factual calibration as the primary improvement lever. Figure 4: Plausibility (mean raw Borda points). The proposed 8B clusters near the front and matches or exceeds several larger baselines, reflecting strong logical flow and coherent reasoning. next steps of improvement is therefore to prioritize factual grounding and numeric checking: adding targeted retrieval, rule tables, and lightweight calculation guards should yield the largest absolute gains relative to effort. C.5 Parameter Efficiency: Category-wise Borda per Billion Parameters To evaluate parameter efficiency rather than absolute quality, we compute per-parameter utility for each criterion. For model with Pi billion parameters and mean raw Borda points bi,c on criterion {Accuracy, Plausibility, Relevance} (averaged over judges and queries within the category), we define ei,c = bi,c Pi (Borda points per billion parameters). This ratio captures the marginal productivity of capacity: how much judged quality is obtained per parameter, holding the evaluation protocol fixed. It is not substitute for absolute scores (Sec. C.4), but complementary lens for cost-, latency-, and memory-constrained deployments. Relevance efficiency. Figure 6 shows the proposed 8B model with the highest Borda-perparameter in Relevance, followed by Gemma3-12Bit, then Mistral-7B-v0.3 and Llama3-8B. Large reasoning models (e.g., QwQ-32B, Gemma3-27B-it) trail on this per-parameter metric despite strong absolute relevance  (Fig. 5)  , indicating diminishing returns in alignment per unit capacity at larger scales. Plausibility efficiency. As shown in Fig. 7, the proposed 8B again leads, with Mistral-7B-v0.3 and Gemma3-12B-it close behind (virtually tied), followed by Llama3-8B. This suggests that the dataset structure and few-shot conditioning yield coherent reasoning with high utility densityquality per parameter. In Fig. 8, the proposed 8B Accuracy efficiency. tops Accuracy per parameter, followed by Mistral7B-v0.3 and Gemma3-12B-it (near-tie). Models that dominate absolute accuracy (Sec. C.4) deliver lower accuracy per parameter, implying that targeted grounding and calculation checks can be more cost-effective than increasing model size. (1) The proposed 8B is Takeaways and caveats. the most parameter-efficient across all three criteria, reinforcing the central claim that careful supervision can substitute for scale in personalfinance tasks. (2) Efficiency does not equal absolute quality; it informs deployment decisions where memory/latency are binding. (3) The ratio ignores runtime constants (KV-cache bandwidth, batch scheduling) and training cost; it should be read alongside absolute Borda results and systemlevel latency/memory budgets. 17 Figure 5: Relevance (mean raw Borda points). The proposed 8B ranks immediately behind the top three, ahead of other baselines, indicating consistent mapping from user constraints to concrete answers. Figure 6: Relevance efficiency: mean raw Borda points per billion parameters (higher is better). The proposed 8B leads, followed by Gemma3-12B-it and Llama3-8B. C.6 Qualitative Category-wise Evaluations We analyze twelve personal-finance subdomainsAuto, Budgeting, Credit, Debt, Employment, Housing, Insurance, Investing, Planning, Retirement, Saving, Taxes. For each, we report criterion-wise means derived from normalized Borda points (Sec. C.3). The dashed horizontal line in each panel marks the cohort-wide mean for orientation. Please note that the category-based evaluations in this appendix use raw Reddit post flairs, which differ from the eight thematic categories curated for the main analysis. C.6.1 Relevance by Subdomain Relevance captures task alignment: covering all parts of the users request, using their numbers/constraints, and answering without generic preambles (Sec. C.1). consistent top cluster is formed by larger reasoning-aligned models. The proposed 8B model sits immediately behind this cluster in most categories and hovers around the cohort mean. Strengths are most visible in Budgeting, Employment, Planning (and close-to-mean in Insurance/Retirement). Wider gaps appear in Auto, Housing, Credit (and occasionally Investing/Taxes), where localityand rule-heavy edge cases require more exhaustive coverage. C.6.2 Accuracy by Subdomain Accuracy isolates financial correctness: advice and calculations must be right for the stated scenario; style and coverage are ignored (Sec. C.1). Absolute leaders are the larger models across most subdomains. The proposed 8B model is mid-pack overall, with competitive accuracy in Debt, Planning, Employment, and notably larger gaps in Housing, Insurance, Taxes (and Credit). This pattern suggests targeted grounding (policy/limit tables, calculators) is higher-leverage fix than stylistic tuning for closing the remaining gap. C.6.3 Plausibility by Subdomain Plausibility measures reasoning flow and readability: clear structure, sensible steps, and absence of unnecessary complexity (Sec. C.1). The proposed 8B clusters close to the leaders across most subdomains, with stronger relative showings in Debt and Planning; margins are lower in Taxes and Retirement. Lower margins in regulation-dense areas mirror the accuracy pattern: where facts are brittle, judges penalize circuitous explanations. Figure 7: Plausibility efficiency: mean raw Borda points per billion parameters. The proposed 8B ranks first; compact 78B baselines are competitive, while very large models show lower utility density. Figure 8: Accuracy efficiency: mean raw Borda points per billion parameters. The proposed 8B tops the cohort, indicating that factual calibration gains can be achieved more cheaply than by scaling parameters alone. C.7 Overall Summary, Limitations, and Next Steps Summary. Taken together, the results tell simple story. On absolute scores (Sec. C.4), the largest baselines lead across Accuracy, Plausibility, and Relevance, as expected. The proposed 8B model sits just behind this front cluster on Relevance and Plausibility and lands mid-pack on Accuracy. When we switch to parameter-efficiency lens (Sec. C.5), the picture reverses: the 8B model delivers the highest Borda-per-parameter across all three metrics, indicating unusually high utility density for its size. The subdomain breakdown (Sec. C.6) is consistent with both views: the 8B model is steady or above-mean in everyday tasks such as Budgeting, Planning, Employment (and shows strong plausibility in Debt), while gaps widen in regulationand table-heavy areas such as Housing, Insurance, Taxes, Credit (and occasionally Auto/Investing). In short, scale drives absolute peaks, but careful supervision yields competitive qualityand superior efficiencyat mid-scale. These results suggest prioritizing minimal, highleverage grounding over further size increases: include compact, versioned rule/limit tables for regulation-intensive domains (e.g., taxes, insurance, credit), add lightweight calculators/unit-tests for numeric steps, sharpen supervision with contrastive edge cases in brittle areas (tax/retirement), diversify judge checks (agreement and judge-swap), and extend evaluation to short multi-turn interactions that reward clarifying questions."
        },
        {
            "title": "D Training Details",
            "content": "We fine-tuned the 8B parameter Qwen-3 model with AdamW optimizer on bfloat16 precision and training split containing 15.6K samples and validation set containing 2.6k samples. We trained the model for four epochs using an optimal batch size of 256, resulting in around 220 steps overall. The model underwent training on solitary A100 GPU within the Runpod cloud GPU infrastructure for 3 hours. We preserved three checkpoints per epoch, with the optimal validation loss attained at step 101. The training used cosine learning rate schedule with maximum learning rate of 5 105, 10% linear warm-up period of 21 steps (a warmup ratio of 10%), and minimum learning rate of 5 106. Gradients were constrained to global norm of 1, weight decay was established at 0.01, and all other parameters adhered to the default conventions of the Hugging Face Trainer."
        },
        {
            "title": "E Sample Model Responses",
            "content": "To provide qualitative assessment of our models capabilities, this appendix details three comparative case studies. Each case is structured around real-world user query, presenting the abridged responses from our model (Ours-8B) alongside two baseline models of different sizes (Baseline-L and 19 Figure 9: Category-wise Relevance. The proposed 8B model typically sits just behind the leading cluster and near the cohort mean; gaps are largest in edge-case, rule-dense areas (e.g., Auto, Housing, Credit). 20 Figure 10: Category-wise Accuracy. Larger models lead overall; the proposed 8B is mid-pack with smaller gaps in everyday planning tasks and larger gaps where year-/jurisdiction-specific rules dominate (e.g., Housing, Insurance, Taxes). Figure 11: Category-wise Plausibility. The proposed 8B delivers coherent reasoning near the leading cluster, with smaller margins in routine planning tasks and larger ones in regulation-dense areas (e.g., Taxes, Retirement). 22 Baseline-S). For each case, we outline the query, summarize the context provided to the models, display the generated responses, and conclude with judges final ranking and rationale based on the core principles of accuracy, relevance, and plausibility. Case C1 (Comparative) Budgeting & Early Investing at 18 Query (Abridged) Im 18 with about $40k in checking. run business (will reinvest some), have very low expenses, and my parents cover college/housing. What should do so its not just sitting idle? Context Titles (Summary) Emergency fund (36 months of spend) Roth/SEP-IRA basics Low-cost index funds Business reinvestment discipline Abridged Model Responses Ours8B hear the mix of excitement and confusion. . . Since you run business, reinvest portion. For the rest, open Roth IRA (after-tax, long-horizon growth) and taxable brokerage with low-cost index funds. Before investing, hold 36 months of expenses in high-yield savings account. Then allocate across business, Roth IRA, and brokerage based on comfort with risk. Baseline-L (32B) Secure an emergency fund in high-yield account; consider reinvesting in the business with written plan. As self-employed, consider SEP-IRA and Roth/Traditional IRA. After that, diversify via brokerage with index ETFs (e.g., S&P 500). Includes sample split: emergency fund, business, retirement accounts, and ETFs. Baseline-S (7B) Ten generic ideas: emergency fund, pay off debt, invest in stocks/bonds/real estate, retirement savings, education, charity, travel, start side business, enjoy life. (Not tailored to the user; repeats start side business. Reasoning: Baseline-L is the most accurate and relevant: it adds specifics for the self-employed (SEP-IRA), provides concrete allocation sketch, and outlines clear sequence (EF tax-advantaged brokerage). Ours8B is strong, empathetic, and practical but more high-level. Baseline-S is generic and poorly targeted. Case C2 (Comparative) Full Roth Conversion with Mixed Positions Query (Abridged) Early 50s, Trad. IRA has two near-worthless positions and one large gainer. Full Roth conversion would push income in the 3235% bracket. Convert all at once or phase it? Context Titles (Summary) Roth conversion taxation; Form 8606 reporting Bracket management and timing; liquidity to pay tax Selling losers post-conversion; marketvolatility risk Abridged Model Responses Ours8B Full conversion now makes strong sense. Convert entire Trad. IRA, then immediately sell all three holdings inside the Roth and reallocate to diversified funds. Steps: compute tax; execute direct conversion; sell & reallocate; file taxes: report as non-deductible contribution (Form 8606). Baseline-L (32B) Explains that taxes are based on total IRA value; losses cant offset gains here. Lays out full vs. phased conversion, bracket creep, irreversibility, and liquidity (use outside funds for tax). Emphasizes ability to liquidate losers tax-free in Roth and notes market-drop risk post-conversion. Provides actionable steps (run scenarios, convert losers first if phasing). Baseline-S (7B) High-level overview of Roth conversion basics; repeats general advice; defers to an advisor; no bracket modelling or concrete steps. Analysis Analysis Judge Outcome: Baseline-L > Ours8B > Judge Outcome: Baseline-L > Ours8B > Baseline-S Baseline-S 23 Reasoning: Baseline-L is most accurate and relevant: it answers am missing better option? with structured comparison, concrete trade-offs, and clear next steps. Ours8B is strong and user-aligned but single-track (HYSA only), offering less educational depth for alternatives. Baseline-S is accurate but generic and light on decision guidance. Conclusion These case studies culminate in clear, yet nuanced, conclusion about the trade-offs between model scale, architecture, and performance. The consistent top ranking of the 32B Baseline-L underscores the value of large-scale reasoning model for generating superior, detailed financial guidance. However, the most compelling finding emerges from an efficiency perspective. Our 8B non-reasoning model showed consistent performance at just quarter of the size of Baseline-L. It is, in essence, punching significantly above its weight class, offering powerful balance of quality and resource economy. The key differentiators were BaselineLs ability to handle multi-step, nuanced reasoning and maintain factual integrity, an area where our model faltered in Case C2. Reasoning: Baseline-L is most accurate and relevant: covers bracket spillover, irrevocability, external cash for taxes, and volatility risk, with clear options (full vs. phased) and steps. Ours8B is confident and practical but contains material filing error (mislabels conversion as non-deductible contribution on Form 8606), reducing Accuracy. BaselineS is generic and least helpful. Case C3 (Comparative) Liquidity & Safety with Uncertain Horizon Query (Abridged) Life changes ahead (move/career/school). have $25,000 and may need it anytime. Worried about market dips. Is high-yield savings account (HYSA) the right place, or am missing better option? Context Titles (Summary) HYSA basics and FDIC/coverage; money market accounts Short CDs and ladders; T-bills; short-term bond funds Liquidity vs. yield trade-offs; rate monitoring Abridged Model Responses Ours8B Given immediate-access needs and principal safety, parking the entire $25k in HYSA is optimal. HYSAs pay better than regular savings, allow anytime withdrawals, and avoid CD penalties. Verify competitive APY and keep the funds fully flexible. Baseline-L (32B) Validates HYSA for immediate access, then compares liquid, low-risk alternatives: money market accounts, short CD laddering, T-bills, and short-term bond funds. Outlines pros/cons, insurance/volatility notes, and actionable steps (open HYSA; optionally ladder small slice; monitor rates; named providers/tickers as examples). Baseline-S (7B) Confirms HYSA could be good, mentions inflation in general terms, lists money market and short CDs, but remains generic and defers to an advisor without comparison framework. Analysis Judge Outcome: Baseline-L > Ours8B > Baseline-S"
        }
    ],
    "affiliations": []
}