{
    "paper_title": "C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor",
    "authors": [
        "Haoquan Lu",
        "Hanzhe Liang",
        "Jie Zhang",
        "Chenxi Hu",
        "Jinbao Wang",
        "Can Gao"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "3D Anomaly Detection (AD) has shown great potential in detecting anomalies or defects of high-precision industrial products. However, existing methods are typically trained in a class-specific manner and also lack the capability of learning from emerging classes. In this study, we proposed a continual learning framework named Continual 3D Anomaly Detection (C3D-AD), which can not only learn generalized representations for multi-class point clouds but also handle new classes emerging over time.Specifically, in the feature extraction module, to extract generalized local features from diverse product types of different tasks efficiently, Kernel Attention with random feature Layer (KAL) is introduced, which normalizes the feature space. Then, to reconstruct data correctly and continually, an efficient Kernel Attention with learnable Advisor (KAA) mechanism is proposed, which learns the information from new categories while discarding redundant old information within both the encoder and decoder. Finally, to keep the representation consistency over tasks, a Reconstruction with Parameter Perturbation (RPP) module is proposed by designing a representation rehearsal loss function, which ensures that the model remembers previous category information and returns category-adaptive representation.Extensive experiments on three public datasets demonstrate the effectiveness of the proposed method, achieving an average performance of 66.4%, 83.1%, and 63.4% AUROC on Real3D-AD, Anomaly-ShapeNet, and MulSen-AD, respectively."
        },
        {
            "title": "Start",
            "content": "C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor Haoquan Lu1, Hanzhe Liang2,3, Jie Zhang4, Chenxi Hu2, Jinbao Wang5,6, Can Gao1,6 1College of Computer Science and Software Engineering, Shenzhen University 2Shenzhen Audencia Financial Technology Institute, Shenzhen University 3Ningbo Institute of Digital Twin, Eastern Institute of Technology 4Faculty of Applied Sciences, Macao Polytechnic University 5School of Artificial Intelligence, Shenzhen University 6Guangdong Provincial Key Laboratory of Intelligent Information Processing 5 2 0 2 2 ] . [ 1 1 1 3 1 0 . 8 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "3D Anomaly Detection (AD) has shown great potential in detecting anomalies or defects of high-precision industrial products. However, existing methods are typically trained in class-specific manner and also lack the capability of learning from emerging classes. In this study, we proposed continual learning framework named Continual 3D Anomaly Detection (C3D-AD), which can not only learn generalized representations for multi-class point clouds but also handle new classes emerging over time. Specifically, in the feature extraction module, to extract generalized local features from diverse product types of different tasks efficiently, Kernel Attention with random feature Layer (KAL) is introduced, which normalizes the feature space. Then, to reconstruct data correctly and continually, an efficient Kernel Attention with learnable Advisor (KAA) mechanism is proposed, which learns the information from new categories while discarding redundant old information within both the encoder and decoder. Finally, to keep the representation consistency over tasks, Reconstruction with Parameter Perturbation (RPP) module is proposed by designing representation rehearsal loss function, which ensures that the model remembers previous category information and returns category-adaptive representation. The proposed method is the first attempt to address 3D anomaly detection in class-incremental manner, providing the capabilities of multi-class and continual anomaly detection. Extensive experiments on three public datasets demonstrate the effectiveness of the proposed method, achieving an average performance of 66.4%, 83.1%, and 63.4% AUROC on Real3D-AD, Anomaly-ShapeNet, and MulSen-AD, respectively. Introduction 3D Anomaly Detection has garnered significant attention in identifying industrial product defects (Tu et al. 2025; Rudolph et al. 2023). To detect anomalies effectively, feature-embedding methods and reconstruction-based methods have been proposed in recent years (Liu et al. 2024b). These methods extract features that are highly relevant for anomaly detection (Horwitz and Hoshen 2023; Tu et al. 2025; Liang et al. 2025a), leverage complementary modality information to enhance performance (Rudolph et al. 2023; We have provided the code for C3D-AD with checkpoints and BASELINE at this link: https://github.com/hzzzzzhappy/CL3AD . Figure 1: Difference between class-specific model and C3DAD. (a) Single-class anomaly detection. (b) Multi-class and continual anomaly detection. Gu et al. 2024), reconstruct point cloud to allow greater generalization across data distribution (Chen et al. 2023; Zhou et al. 2025), and enhance the capability of multi-class anomaly detection (Wang et al. 2025; Cheng et al. 2025). The performance of anomaly detection methods has steadily improved, and the application scenarios have become increasingly close to reality. However, real-world environments present more complex challenge, e.g., the continuous emergence of new object categories requires detection. In this context, class-specific models are inefficient as they necessitate complete retraining for each new class. Unified models, while more efficient, are susceptible to catastrophic forgetting, causing the degradation of performance on previously learned tasks. Hence, strategies to mitigate this problem are crucial, which leads to the paradigm of Continual Learning (CL). CL aims to develop models able to learn sequentially from new data without forgetting previously acquired knowledge, as shown in Figure 1. Continual learning has been applied to 2D anomaly detection. The rehearsal-based methods, e.g., CAD (Li et al. 2022) and ReplayCAD (Hu et al. 2025), store the information of the Gaussian distribution and parameter of the diffusion model, respectively. The regularization-based methods constrain the parameters to be less sensitive to the new training data. For example, CDAD (Li et al. 2025b) constrains the gradients orthogonal to previous feature representations. Tang et al. (Tang et al. 2025) used semantic compression strategy to maximize the space margin from different tasks. However, due to high-resolution inputs and class-specific models, the methods based on continual learning cannot be directly applied to 3D point clouds. Motivated by the observations above, we propose Continual 3D Anomaly Detection (C3DAD), novel framework designed to address the challenges of sequential anomaly detection in point cloud data. Specifically, we introduce Kernel Attention with random feature Layer (KAL) to extract generalized features. Rather than directly encoding raw point-level information, KAL extracts the spatial context of the point cloud and mines local structure in the unified kernel space. To efficiently preserve and update multi-class data cache across tasks and reconstruct data correctly and continually, we further propose Kernel Attention with learnable Advisor (KAA) mechanism for the Encoder-Decoder module. Hence, the module can learn the information from new categories and discard redundant information. Moreover, to mitigate catastrophic forgetting and keep the representation consistent, we proposed the Reconstruction with Parameter Perturbation (RPP) module. This module encourages the model returns category-adaptive representations across all sequential tasks. The main contributions are as follows: We introduce novel layer named KAL to normalize the feature space while extracting features. Leveraging KAL, features are extracted from the unified kernel space, which is significant to continual 3D AD. By extracting local structure information, our method significantly enhances the models ability for continual learning. We proposed novel network KAA for continual learning. To address the limitations of fixed-capacity networks in continual learning, we propose novel encoderdecoder architecture with learnable advisors that reduces redundant information from previous knowledge while learning new knowledge. Traditional attention mechanisms often encounter O(n2) complexity, leading to computational bottlenecks. To overcome it, KAA with linear O(n) complexity updates advisors without compromising effectiveness. We present new hypothesis constraint in continual learning. The network in its current state should retain satisfactory performance on past data when revisited. To enforce this, the networks future outputs are predicted and constrained between current outputs by RPP, preserving the models continual learning abilities over time."
        },
        {
            "title": "Related Work",
            "content": "3D Anomaly Detection 3D anomaly detection is computer vision task focused on detecting and scoring anomalous points within 3D data, such as point clouds (Liu et al. 2023; Li et al. 2024, 2025a), to identify product defects in industrial manufacturing. This is achieved through two main methods. (1) Feature-embedding methods (Horwitz and Hoshen 2023; Kruse et al. 2024; Liang et al. 2025a) extract embeddings from 3D data and measure similarity to normal data. Specifically, Student-Teacher networks (Rudolph et al. 2023; Bergmann and Sattlegger 2023; Qin et al. 2023; Gu et al. 2024) effectively assess output differences to indicate anomaly levels. In contrast, (2) reconstruction-based methods evaluate errors by comparing outputs to original inputs (Chen et al. 2023; Liang et al. 2025b), allowing greater generalization across data distributions. Researchers have explored various reconstruction frameworks; for example, Masuda et al. (Masuda et al. 2021) proposed an unsupervised anomaly detection framework based on VAE (Kingma and Welling 2022), and Chen et al. (Chen et al. 2023) introduced novel encoder-decoder for multi-scale and multimodal data. R3D-AD (Zhou et al. 2025), based on diffusion (Ho, Jain, and Abbeel 2020), obscures anomalous geometry for global anomaly detection. Recently, the unified model MC3D-AD (Cheng et al. 2025) demonstrated significant performance improvements for multi-class data, highlighting the value of one-for-all approach. However, existing methods struggle to generalize in classincreasing settings. To address this, we propose novel continual learning framework (C3D-AD) that enables multiclass and continual anomaly detection. Continual Learning Continual learning (CL) is machine learning paradigm that enables models to learn continuously from evolving data streams, adapting to dynamic scenarios without full retraining. It provides lifelong learning capabilities while addressing catastrophic forgetting through three main methods (Mallya, Davis, and Lazebnik 2018). (1) Regularization-based methods constrain parameter updates to preserve crucial knowledge (Rebuffi et al. 2017). For instance, Elastic Weight Consolidation uses the Fisher Information Matrix to identify critical parameters, while Learning without Forgetting employs knowledge distillation (Batra and Clark 2024). The STAR method constrains gradient updates using buffered samples (Eskandar et al. 2025). (2) Rehearsal-based methods store and reuse past samples, effectively mitigating catastrophic forgetting (Riemer et al. 2019). LiDER enhances network smoothness by optimizing Lipschitz constants (Bonicelli et al. 2022). (3) Architecture-based methods allocate specific parameters for each task (Mallya and Lazebnik 2018). The LPS algorithm by Wang et al. partitions the network into task-specific sections to retain information from new tasks (Wang et al. 2020). CL has been successfully applied to 2D anomaly detection (Barusco et al. 2025). For example, Li et al. (Li et al. 2025b) proposed CDAD, which projects gradients into subspace orthogonal to previous feature representations, while Tang et al. (Tang et al. 2025) used semantic compression strategy to retain essential memories. CAD (Li et al. 2022) and ReplayCAD (Hu et al. 2025) utilize rehearsals of statistical information from previous distributions. Additionally, Liu et al. introduced continual prompt module in UCAD (Liu et al. 2024a) for task adaptation. However, due to high-resolution inputs and class-specific models, these methods cannot be directly applied to 3D data, necessitating retraining when encountering new categories. The development of unified model for 3D anomaly detection in class-incremental manner has yet to be explored. Therefore, we propose C3D-AD to facilitate the reconstruction of multi-class data and the continual detection of anomalies."
        },
        {
            "title": "Method",
            "content": "train 2 train = (i = j), where Problem Statement The task of continual 3D AD is to find model to detect data from new categories while avoiding catastrophic forgetting. Considering the real application, the model can access only the training data of the current task and memory bank, precluding the storage or revisiting of full data from previous tasks. Hence, the available data arrives sequentially in train multiple tasks, i.e., Ptrain = 1 train and train i train denotes the training data from the t-th task containing point cloud samples from specific categories and only having normal samples, and is the total number of tasks. In the testing phase, the data to be detected includes both normal and anomalous point cloud samples from all encountered tasks, i.e., 1 test = Ptest. Our objective is to train unified model that can detect anomalies across all encountered tasks while avoiding catastrophic forgetting of previously learned detection capabilities, which minimizes the cost of training the model. test test 2 Preliminary In this paper, vectors, matrices, and sets are denoted by the bold lowercase letters (e.g., p), bold uppercase letters (e.g., P), and calligraphic fonts (e.g., P). Given the point cloud set P, each point is represented as pi R3, (i = 1, . . . , ). The point cloud is organized into feature matrix RN 3. Points cloud from can be encoded into tokens, yielding token feature matrix Rnd with tokens. Rdr is linear projection matrix. Overview Framework The key challenge in continual 3D anomaly detection is constraining models to avoid catastrophic forgetting of past detection capabilities when facing new data. To this end, we propose novel Continual 3D Anomaly Detection (C3DAD). The overall framework is illustrated in Figure 2, comprising three main components: Kernel Attention with random feature Layer (KAL), Kernel Attention with learnable Advisor (KAA), and Reconstruction with Parameter Perturbation (RPP). Kernel Attention with random feature Layer Feature extraction is used to improve the performance of the downstream tasks. In the continual learning paradigm, it is essential to extract generalized features. These features aim to minimize the feature space differences across different tasks, mitigating catastrophic forgetting. In the scenario of 3D AD, point clouds suffer from poor structure and weak semantic information due to the organization as triplets in the form of RN 3. Hence, firstly, the local structure features are extracted for the generalized representation of the point clouds. Specifically, is sampled into centers group Pcenter by the Furthest Point Sampling (FPS) (Charles et al. 2017). After sampling center points from the point cloud, the neighborhood point set of center point pi can be expressed as: Nr(pi) = {pj pi pj2 r}. (1) Due to varying point cloud scales across different classes, the radius is adaptively adjusted using the following equation: = η Pcenter (cid:88) pj Pcenter pi pj2, (2) where η is the scaling factor of radius. Secondly, the features should be mapped into unified space. To tokenize the point cloud data, an encoder is employed. Without loss of generality, let q, k, and denote the query, key, and value vectors, respectively. The traditional self-attention mechanism utilized in encoders is: ol = (cid:88) exp(q ki) exp(q kj) (cid:80)n vi. (3) the output Without considering the softmax activation function and is the optimum of minO scaling, QKV , where and can be viewed as feature extraction and reconstruction matrix. The following kernel attention is proposed to capture nonlinear relationships among features: ol = (cid:88) κ(ql, ki) κ(ql, kj) (cid:80)n vi, (4) where κ(Q, K)lj = κ(ql, kj) is the kernel function. κ(ql, kj) represents the inner product ϕ(ql), ϕ(kj), where ϕ() is mapping to the unified Hilbert space. If the space spanned by ϕ(K) is approximately unified, it can extract global generalized features in the continual learning paradigm. The output of the attention layer is: ol = (cid:88) ϕ(ql)ϕ(ki) ϕ(ql)ϕ(ki) (cid:80)n vi. (5) However, the overall computational complexity is quadratic. To address this, it can be: viϕ(ki)(cid:1) ϕ(ql) (cid:0)(cid:80)n (cid:80)n ϕ(kj)ϕ(ql) ol = (6) , which is O(n) computational complexity in matrix form. The mapping ϕ can be defined by the random feature, e.g., Figure 2: The pipeline of C3D-AD. The training point cloud data is aggregated into groups according to the center points. Feature tokens are generated by extracting features from both group centers and point groups, utilizing the Kernel Attention with random feature Layer (KAL) module in linear complexity. Then, feature tokens are input into the Encoder-Decoder, employing Kernel Attention with learnable Advisor (KAA) mechanism, which can memorize new class information and discard redundant information. Finally, the feature tokens are reconstructed again via Reconstruction with Parameter Perturbation (RPP) module, which can help the model review past samples and avoid catastrophic forgetting. Anomalies are detected according to the anomaly score by comparing the differences between feature tokens and reconstruction tokens. Positive Random Feature (Choromanski et al. 2021): Given the learning rate β, the update rule is: x2 2 2 ϕ(x) = (cid:104) ew 1 x, , ew mx(cid:105) St = St1 βSLkaa , (7) = St1 β(St1ϕ(k)ϕ(k) (1 + α)ϕ(k)v). (9) where the projection wi (0, Id). Usually, is set to small enough value. is sampled i.i.d. from wi In this way, KAL not only captures the local spatial context of the point cloud but also learn the generalized nonlinear structural information across inter-group point clouds. Kernel Attention with learnable Advisor After extracting generalized representations of point clouds locally and globally via the KAL, it is essential to introduce an advisor within the encoder-decoder architecture to mitigate catastrophic forgetting during continual learning. To address this, we introduce novel continual learning attention mechanism with linear O(n) complexity, named Kernel Attention with learnable Advisor (KAA), which enables the model to learn new information efficiently while preserving previously acquired information. Rewrite Eq. (6) by ignoring the denominator, and it becomes ol = Sϕ(ql). Rdm is continually learnable advisor. The following objective function (8) is proposed to train the advisor S: 1 2 min Lkaa(S) = min Sϕ(k) v2 α Tr(vSϕ(k)), (8) where the advisor guides the key ϕ(k) close to the value and aligns their directions. Getting the derivative of the function Lkaa w.r.t. and setting it to zero, the update gradient can be derived as SLkaa = Sϕ(k)ϕ(k)(1+α)ϕ(k)v. = St1ϕt(k) and vnew Let vold then Eq. (9) becomes: = (1β)vold +β(1+α)vt, ϕ St = St1 vold ϕ (k) + vnew where vold (k) represents that reduces redundant information from previous tasks and vnew ϕ (k) is to learn new information. Hence, the output of attention in the t-th task is: ϕ (k), (10) Ot = ϕ(Qt)S , (11) where l-th row of ϕ(Qt) is ϕ(ql). Storing historical point cloud information in preserves KAAs continual learning capability. It eliminates the need to maintain set of past samples. Furthermore, due to its linear complexity, the proposed method is resource-efficient. Reconstruction with Parameter Perturbation KAA is to learn new information while reducing previous one for the Encoder-Decoder. In this section, the Reconstruction with Parameter Perturbation (RPP) mechanism is proposed to reconstruct data from the view of the future. To ensure that the model converges globally to hypothesis space that is optimal across all tasks, the gradient of the models parameters must be continually constrained to optimize within the intersection of the optimal hypotheses for each task. This strategy aims to prevent catastrophic forgetting. According to the objective, the model should maintain high similarity for the same batch of data at time and time + t, > 0. Consequently, this is formulated as the following minimization of loss: Lrpp = h(θt, x) h(θt+t, x)2 2. (12) where h(θt, ) is the hypothesis at time t. However, it is impossible to obtain the hypothesis h(θt+t, ) at time t. Hence, the state after must be predicted based on the current model weights. To this end, we approximate the hypothesis after as h(θt + δ), where the initial perturbation δ is sampled from normal distribution and constrained by δ2 ϵ. Within the parameter space, the perturbation is searched to induce the worst-case deviation upon addition, thereby simulating the most adverse future scenario. Motivated by this, the optimization problem is proposed: Lrpp(θt, Pt) = max h(θt, Pt) h(θt + δ, Pt)2 2 δ s.t. δ2 ϵ. (13) To find local optimum of this objective function, gradient ascent is employed. Generalization Error Bound of RPP Loss To assess the generalization error incurred by the objective function when using limited point cloud data to converge the model to the concept set, the generalization bound is derived for Lrpp. Theorem 1. Let = {g : (cid:55) h(θ, x) h(θ + δ, x)2 2 δ2 ϵ} be the class of function induced by bounded perturbations δ. For all and any input x, with probability at least 1 ξ over the random draw of training sample of size from the underlying distribution D, the following holds: ˆLrpp(θ) Lrpp(θ) + 2ϵ2L2 θ R(ψ) + 3 (cid:114) log(2/ξ) 2N . (14) the perturbation constraint ϵ According to Theorem 1, should not be excessively large to avoid significant increase in the generalization error. More details can be found in the Supplemental Materials."
        },
        {
            "title": "Experimental setting",
            "content": "Datasets. The Real3D-AD (Liu et al. 2023) is benchmark for 3D AD, comprising 1,254 large-scale, highresolution samples from 12 object categories. The training set for each category consists of only 4 normal samples, and the test set contains both normal samples and various anomalies. The Anomaly-ShapeNet (Li et al. 2024) is large-scale synthetic dataset for AD. It comprises 1,600 samples distributed across 40 object categories, posing significant challenge due to its high inter-class diversity. MulSen-AD (Li et al. 2025a) is the high-resolution multisensor anomaly detection data set. It consists of 2,035 samples from 15 industrial object categories, which are split into training set of 1,391 normal samples and test set comprising 150 normal and 494 anomalous samples. Comparing baselines. We selected classical 3D anomaly detection methods: BTF (Horwitz and Hoshen 2023), M3DM (Wang et al. 2023), Patchcore (Roth et al. 2022), CPMF (Cao, Xu, and Shen 2024), Reg3D-AD (Liu et al. 2023), IMRNet (Li et al. 2024), R3D-AD (Zhou et al. 2025), MC3D-AD (Cheng et al. 2025), PLANE (Wang et al. 2025), and PO3AD (Ye et al. 2024) to demonstrate that C3D-AD is effective in anomaly detection. Moreover, we modified three baseline methods adapted for continual learning for fair comparison: Continual-PatchCore, Continual-MC3DAD, and Continual-Reg3D-AD. Complete implementation details are provided in the Supplementary Materials. Continual Learning Setting To estimate the models performance in class-incremental 3D Anomaly Detection, we partitioned each dataset into series of sequential tasks. For the Real3D-AD dataset, we divide the training set into 4 disjoint tasks based on categories. The test sets are constructed cumulatively, i.e., 1 test. Following this, Anomaly-ShapeNet and MulSen-AD datasets are divided into 4 and 3 tasks, respectively. To evaluate the performance of the model, we adopt metrics at the object level. For object-level AD, the AUROC () is employed. To ensure fair comparison across all categories, the mean AUROC and average ranking of each method () are reported. Code would be available upon acceptance of the paper. test 4 Implementation Details. PointMAE (Pang et al. 2022) with the KAL is pre-trained on ModelNet408K (Wu et al. 2015) for feature extraction. The α and β of KAA are both set to 0.7, and is set to 10. The sample scaling factor η is 10 to cover the whole point cloud. The ϵ is scanned in the range [0.01, 10], determining the generalization error. The AdamW optimizer is employed in the training process with initial learning rate 0.0001 and rate 0.00001 after 800 epochs. The number of stacked encoder-decoder blocks is set to 4. Our experiments were conducted on machine with PyTorch 1.13.0, CUDA 11.7, and an NVIDIA A100-PCIE40GB GPU."
        },
        {
            "title": "Performance on Continual Anomaly Detection",
            "content": "The experimental results of C3D-AD and other methods in the continual learning paradigm are shown in Table 1. C3D-AD has demonstrated state-of-the-art (SOTA) performance in 3D Anomaly Detection across various tasks and datasets. Unlike memory-bank-based methods, e.g., continual-Reg3D-AD and continual-PatchCore, C3D-AD achieves superiority by unifying the feature space via KAL, while minimizing reconstruction error via RPP. Hence, C3D-AD outperform these two method by 14.3%, 31.2%, and 5.4% on three dataset. Furthermore, while the unified model MC3D-AD implicitly maintains previous information, C3D-AD performs better. The gaps, which are 3.9%, 3.4%, and 3.0%, are attributed to the lack of mechanisms like KAA encoding past information into the models parameters and the RPP module for information rehearsal. The experiments also demonstrate that C3D-AD can be applied in class-incremental AD. Real3D-AD Anomaly-ShapeNet MulSen-AD task id 2 3 4 1 2 4 1 2 3 Continual-Reg3D-AD Continual-PatchCore (FPFH) Continual-MC3D-AD C3D-AD 0.598 0.566 0.767 0. 0.527 0.527 0.650 0.658 0.505 0.500 0.629 0.666 0.521 0.518 0.625 0.664 0.522 0.567 0.829 0.854 0.544 0.541 0.803 0.848 0.501 0.510 0.833 0. 0.519 0.494 0.797 0.831 0.602 0.491 0.623 0.698 0.599 0.549 0.626 0.650 0.580 0.524 0.604 0.634 Table 1: The mean O-AUROC () performance of different methods across multiple tasks of datasets. The best results are bold. Method cap0 cap3 helmet3 cup0 bowl4 vase headset1 eraser0 vase8 cap4 vase2 vase helmet0 bucket1 BTF(Raw) BTF(FPFH) M3DM Patchcore(FPFH) Patchcore(PointMAE) CPMF Reg3D-AD IMRNet R3D-AD MC3D-AD PLANE PO3AD C3D-AD 0.668 0.618 0.557 0.580 0.589 0.601 0.693 0.737 0.822 0.793 0.944 0.877 0.678 0.527 0.522 0.423 0.453 0.476 0.551 0.725 0.775 0.730 0.701 0.954 0.859 0.800 0.526 0.444 0.374 0.404 0.424 0.520 0.367 0.573 0.707 0.979 0.721 0.754 0. 0.403 0.586 0.539 0.600 0.610 0.497 0.510 0.643 0.776 0.743 0.805 0.871 0.929 0.664 0.609 0.464 0.494 0.501 0.683 0.663 0.676 0.744 0.911 0.893 0.981 0.626 0.717 0.699 0.439 0.449 0.460 0.582 0.650 0.700 0.742 0.761 0.782 0.821 0.791 0.515 0.490 0.617 0.637 0.627 0.458 0.610 0.676 0.795 0.886 0.776 0.923 0.752 0.525 0.719 0.627 0.657 0.677 0.689 0.343 0.548 0.890 0.776 1.000 0.995 0.843 0.424 0.668 0.663 0.662 0.663 0.529 0.620 0.630 0.721 0.670 0.964 0.739 0. 0.468 0.520 0.777 0.757 0.727 0.553 0.643 0.652 0.681 0.835 0.730 0.792 0.884 0.410 0.546 0.737 0.721 0.741 0.582 0.605 0.614 0.752 0.929 0.971 0.952 0.919 0.425 0.510 0.476 0.506 0.516 0.514 0.500 0.524 0.630 0.876 0.773 0.675 0.836 0.553 0.571 0.526 0.546 0.556 0.555 0.600 0.597 0.757 0.672 0.704 0.762 0.870 0.321 0.633 0.501 0.551 0.561 0.601 0.752 0.771 0.756 0.784 0.968 0.787 0."
        },
        {
            "title": "Method",
            "content": "bottle3 vase0 bottle0 tap1 bowl0 bucket vase5 vase1 vase9 ashtray0 bottle1 tap phone cup1 BTF(Raw) BTF(FPFH) M3DM Patchcore(FPFH) Patchcore(PointMAE) CPMF Reg3D-AD IMRNet R3D-AD MC3D-AD PLANE PO3AD C3D-AD 0.568 0.322 0.541 0.572 0.650 0.405 0.525 0.640 0.781 0.756 0.994 0.926 0.857 0.531 0.342 0.423 0.455 0.447 0.451 0.533 0.533 0.788 0.821 0.896 0.858 0.888 0.597 0.344 0.574 0.604 0.513 0.520 0.486 0.552 0.733 0.795 0.843 0.900 0. 0.573 0.546 0.739 0.766 0.538 0.697 0.641 0.696 0.900 0.970 0.652 0.681 0.844 0.564 0.509 0.634 0.504 0.523 0.783 0.671 0.681 0.819 0.930 0.963 0.922 0.919 0.617 0.401 0.309 0.469 0.593 0.482 0.610 0.580 0.683 0.898 0.981 0.853 0.822 0.585 0.409 0.317 0.417 0.579 0.618 0.520 0.676 0.757 0.976 0.690 0.852 0.795 0.549 0.219 0.427 0.423 0.552 0.345 0.702 0.757 0.729 0.857 0.771 0.742 0.938 0.564 0.268 0.663 0.660 0.629 0.609 0.594 0.594 0.718 0.736 0.592 0.830 0. 0.578 0.420 0.577 0.587 0.591 0.353 0.597 0.671 0.833 0.962 0.905 1.000 0.752 0.510 0.546 0.637 0.667 0.601 0.482 0.695 0.700 0.737 0.709 0.814 0.933 0.740 0.525 0.560 0.754 0.753 0.458 0.359 0.676 0.676 0.736 0.945 0.467 0.745 0.955 0.563 0.671 0.357 0.388 0.488 0.509 0.414 0.755 0.762 0.919 1.000 0.776 0.938 0.521 0.610 0.556 0.586 0.556 0.499 0.538 0.757 0.757 0.952 0.705 0.833 0."
        },
        {
            "title": "Method",
            "content": "vase7 helmet2 cap5 shelf0 bowl5 bowl helmet1 bowl1 headset0 bag0 bowl2 jar"
        },
        {
            "title": "Mean",
            "content": "A. R. BTF(Raw) BTF(FPFH) M3DM Patchcore(FPFH) Patchcore(PointMAE) CPMF Reg3D-AD IMRNet R3D-AD MC3D-AD PLANE PO3AD C3D-AD 0.448 0.518 0.657 0.693 0.650 0.397 0.462 0.635 0.771 0.938 0.938 0.966 0.900 0.602 0.542 0.623 0.425 0.447 0.462 0.614 0.641 0.633 0.609 1.000 0.869 0.745 0.373 0.586 0.639 0.790 0.538 0.697 0.467 0.652 0.670 0.761 0.870 0.670 0.811 0.164 0.609 0.564 0.494 0.523 0.685 0.688 0.603 0.696 0.841 0.759 0.573 0. 0.417 0.699 0.409 0.558 0.593 0.685 0.593 0.710 0.656 0.754 0.800 0.849 0.944 0.385 0.490 0.617 0.537 0.579 0.658 0.348 0.599 0.767 0.885 0.706 0.881 0.793 0.349 0.719 0.427 0.484 0.552 0.589 0.381 0.600 0.720 1.000 0.543 0.961 0.971 0.264 0.668 0.663 0.639 0.629 0.639 0.525 0.702 0.778 0.978 0.907 0.829 0.711 0.378 0.520 0.577 0.583 0.591 0.643 0.537 0.720 0.738 0.862 0.782 0.808 0.827 0.410 0.546 0.537 0.571 0.601 0.643 0.706 0.660 0.720 0.805 0.914 0.833 0. 0.525 0.510 0.684 0.615 0.458 0.625 0.490 0.685 0.741 0.719 0.956 0.833 0.822 0.420 0.424 0.441 0.472 0.483 0.610 0.592 0.780 0.838 0.971 1.000 0.866 0.924 0.493 0.528 0.552 0.568 0.562 0.559 0.572 0.661 0.749 0.842 0.836 0.839 0.846 10.68 9.98 9.73 9.25 9.35 9.25 9.30 6.73 4.63 3.05 3.18 2.88 2.78 Table 2: The O-AUROC () performance of different methods across 40 categories of Anomaly-ShapeNet. The best, secondbest, and third-best are bold, underline, and italics, respectively. A. R. represents the average ranking of each method. Performance on Multi-class Anomaly Detection The capability of C3D-AD for continual 3D AD indicates that it has the intrinsic ability to learn from various data classes. To access the baseline of C3D-AD, multi-class anomaly detection is conducted, which is not on continual learning paradigm. The experimental results are shown = AUROC Inf. T. (s) Memory (GB) 101 0.802 0.281 4.431 0.828 0.311 4.650 103 5103 0.842 0.393 5.680 0.819 1.109 9.400 Table 5: Analysis of on Anomaly-ShapeNet. The inference time (Inf. T.) and the GPU Memory usage are reported. Figure 4: Inference time (s) and memory usage (GB) vs. #Groups for C3D-AD on Anomaly-ShapeNet. the previous and new information. As shown in Figure 3, α and β are set to 0.7, which can achieve satisfactory performance. In addition, ϵ is an important hyperparameter of RPP. According to Theorem 1, ϵ should not be too large, which is demonstrated as shown in Table 4. The hyperparameter in KAL and KAA is usually small value. As shown in Table 5, the computational complexity w.r.t. is O(m). However, larger m, which is the attribute of the advisor, may not lead to better performance. To leverage the performance and efficiency, of KAL and KAA can be set from 101 to 103. Empirical Computational Complexity Analysis Due to the linear computational complexity of Kernel Attention in KAL and KAA, C3D-AD is efficient in anomaly detection. Figure 4 shows that the inference time and GPU peak memory increase linearly with respect to the group number, which is relevant to the number of tokens. The performance can be satisfactory by setting the number to 4096. Hence, C3D-AD is tailored for industrial continual 3D AD due to its O(n) complexity and performance. Conclusions The continuous emergence of new object categories poses significant challenge for 3D Anomaly Detection. To address this, in this study, we propose continual learning framework named C3D-AD. Firstly, we introduce Kernel Attention with random feature Layer to extract generalized features. Then, to reconstruct feature tokens while avoiding catastrophic forgetting, Kernel Attention with learnable Advisor module is designed within the encoderdecoder to learn new information while discarding redundant one. Furthermore, to maintain representation consisFigure 3: Sensitivity of α and β on Anomaly-ShapeNet. in Table 2. Compared to other methods, C3D-AD has the superiority on average AUROC, improving 0.4% than MC3DAD. In addition, C3D-AD achieves the top average ranking in 40 classes. This demonstrates its satisfactory performance in multi-class anomaly detection scenarios. Ablation Study To demonstrate the effectiveness of our proposed modules, ablation studies are conducted on KAL, KAA, and RPP. The experimental results, as presented in Table 3, show that the model achieves its best performance on continual 3D AD only when all three components are integrated. Based on the results across the datasets, KAL and RPP show more significant performance. This suggests that extracting generalized features and maintaining feature consistency are key to enhancing the continual 3D AD. Furthermore, the information from the advisor is also significant for the model to learn new data and avoid catastrophic forgetting continually. KAL KAA RPP R. A. M. 0.534 0.565 0.529 0.791 0.814 0.798 0.612 0.607 0.557 0. 0.831 0.634 Table 3: Results of ablation study on Real3D-AD (R.), Anomaly-ShapeNet (A.), and MulSen-AD (M.). ϵ = 102 10 100 101 102 103 AUROC 0.801 0. 0.787 0.809 0.780 0.769 Table 4: Sensitivity analysis of ϵ on Anomaly-ShapeNet. Sensitivity of Parameters The sensitivity experiments evaluate the value of hyperparameters. In KAA, α is to align the direction of information from the advisor and the value vector, and β is to leverage tency across tasks, the tokens are reconstructed again using Reconstruction with Parameter Perturbation, which aligns the models current and future outputs. Experiments on benchmark datasets demonstrate our methods superiority in continual 3D AD, achieving state-of-the-art performance with satisfactory efficiency. For future work, further research is needed to explore how to effectively constrain the advisor to achieve better performance in continual 3D AD. References Barusco, M.; DAntoni, L.; Pezze, D. D.; Borsatti, F.; and Susto, G. A. 2025. Memory Efficient Continual Learning for Edge-Based Visual Anomaly Detection. arXiv:2503.02691. Batra, H.; and Clark, R. 2024. EVCL: Elastic Variational Continual Learning with Weight Consolidation. arXiv:2406.15972. Bergmann, P.; and Sattlegger, D. 2023. Anomaly Detection in 3D Point Clouds Using Deep Geometric Descriptors. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 26132623. Bonicelli, L.; Boschini, M.; Porrello, A.; Spampinato, C.; and Calderara, S. 2022. On the Effectiveness of LipschitzDriven Rehearsal in Continual Learning. In Oh, A. H.; Agarwal, A.; Belgrave, D.; and Cho, K., eds., Advances in Neural Information Processing Systems. Cao, Y.; Xu, X.; and Shen, W. 2024. Complementary pseudo multimodal feature for point cloud anomaly detection. Pattern Recognition(PR), 156: 110761. Charles, R. Q.; Su, H.; Kaichun, M.; and Guibas, L. J. 2017. PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 7785. Chen, R.; Xie, G.; Liu, J.; Wang, J.; Luo, Z.; Wang, J.; and Zheng, F. 2023. EasyNet: An Easy Network for 3D Industrial Anomaly Detection. arXiv:2307.13925. Cheng, J.; Gao, C.; Zhou, J.; Wen, J.; Dai, T.; and Wang, J. 2025. MC3D-AD: Unified Geometry-aware Reconstruction Model for Multi-category 3D Anomaly Detection. arXiv:2505.01969. Choromanski, K. M.; Likhosherstov, V.; Dohan, D.; Song, X.; Gane, A.; Sarlos, T.; Hawkins, P.; Davis, J. Q.; Mohiuddin, A.; Kaiser, L.; Belanger, D. B.; Colwell, L. J.; and Weller, A. 2021. Rethinking Attention with Performers. In International Conference on Learning Representations. Eskandar, M.; Imtiaz, T.; Hill, D.; Wang, Z.; and Dy, J. 2025. STAR: Stability-Inducing Weight Perturbation for Continual In The Thirteenth International Conference on Learning. Learning Representations. Gu, Z.; Zhang, J.; Liu, L.; Chen, X.; Peng, J.; Gan, Z.; Jiang, G.; Shu, A.; Wang, Y.; and Ma, L. 2024. Rethinking Reverse Distillation for Multi-Modal Anomaly Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 38(8): 84458453. Ho, J.; Jain, A.; and Abbeel, P. 2020. Denoising Diffusion Probabilistic Models. In Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.; and Lin, H., eds., Advances in Neural Information Processing Systems, volume 33, 68406851. Curran Associates, Inc. Horwitz, E.; and Hoshen, Y. 2023. Back to the feature: classical 3d features are (almost) all you need for 3d anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 29682977. Hu, L.; Gan, Z.; Deng, L.; Liang, J.; Liang, L.; Huang, S.; and Chen, T. 2025. ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection. arXiv preprint arXiv:2505.06603. Kingma, D. P.; and Welling, M. 2022. Auto-Encoding Variational Bayes. arXiv:1312.6114. Kruse, M.; Rudolph, M.; Woiwode, D.; and Rosenhahn, B. 2024. SplatPose & Detect: Pose-Agnostic 3D Anomaly DeIn Proceedings of the IEEE/CVF Conference on tection. Computer Vision and Pattern Recognition (CVPR) Workshops, 39503960. Li, W.; Xu, X.; Gu, Y.; Zheng, B.; Gao, S.; and Wu, Y. 2024. Towards Scalable 3D Anomaly Detection and Localization: Benchmark via 3D Anomaly Synthesis and In Proceedings of Self-Supervised Learning Network. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2220722216. Li, W.; Zhan, J.; Wang, J.; Xia, B.; Gao, B.-B.; Liu, J.; Wang, C.; and Zheng, F. 2022. Towards Continual Adaptation in Industrial Anomaly Detection. In Proceedings of the 30th ACM International Conference on Multimedia, 28712880. Association for Computing Machinery. Li, W.; Zheng, B.; Xu, X.; Gan, J.; Lu, F.; Li, X.; Ni, N.; Tian, Z.; Huang, X.; Gao, S.; and Wu, Y. 2025a. Multi-Sensor Object Anomaly Detection: Unifying Appearance, Geometry, and Internal Properties. In Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR), 99849993. Li, X.; Tan, X.; Chen, Z.; Zhang, Z.; Zhang, R.; Guo, R.; Jiang, G.; Chen, Y.; Qu, Y.; Ma, L.; and Xie, Y. 2025b. Onefor-More: Continual Diffusion Model for Anomaly Detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 47664775. Liang, H.; Xie, G.; Hou, C.; Wang, B.; Gao, C.; and Wang, J. 2025a. Look Inside for More: Internal Spatial Modality Perception for 3D Anomaly Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 39(5): 51465154. Liang, H.; Zhang, J.; Dai, T.; Shen, L.; Wang, J.; and Gao, C. 2025b. Taming Anomalies with Down-Up Sampling Networks: Group Center Preserving Reconstruction for 3D Anomaly Detection. arXiv:2507.03903. Liu, J.; Wu, K.; Nie, Q.; Chen, Y.; Gao, B.-B.; Liu, Y.; Wang, J.; Wang, C.; and Zheng, F. 2024a. Unsupervised Continual Anomaly Detection with Contrastively-Learned Prompt. Proceedings of the AAAI Conference on Artificial Intelligence, 38(4): 36393647. Liu, J.; Xie, G.; Chen, R.; Li, X.; Wang, J.; Liu, Y.; Wang, C.; and Zheng, F. 2023. Real3D-AD: Dataset of Point Cloud Anomaly Detection. In Oh, A.; Naumann, T.; Globerson, A.; Saenko, K.; Hardt, M.; and Levine, S., eds., Advances in Wang, Y.; Peng, J.; Zhang, J.; Yi, R.; Wang, Y.; and Wang, C. 2023. Multimodal Industrial Anomaly Detection via Hybrid Fusion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 80328041. Wang, Z.; Jian, T.; Chowdhury, K.; Wang, Y.; Dy, J.; and Ioannidis, S. 2020. Learn-Prune-Share for Lifelong Learning. In 2020 IEEE International Conference on Data Mining (ICDM), 641650. Wu, Z.; Song, S.; Khosla, A.; Yu, F.; Zhang, L.; Tang, X.; and Xiao, J. 2015. 3D ShapeNets: Deep Representation for Volumetric Shapes. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Ye, J.; Zhao, W.; Yang, X.; Cheng, G.; and Huang, K. 2024. PO3AD: Predicting Point Offsets toward Better 3D Point Cloud Anomaly Detection. arXiv:2412.12617. Zhou, Z.; Wang, L.; Fang, N.; Wang, Z.; Qiu, L.; and Zhang, S. 2025. R3D-AD: Reconstruction via Diffusion for 3D Anomaly Detection. In Computer Vision ECCV 2024, 91 107. Neural Information Processing Systems, volume 36, 30402 30415. Liu, J.; Xie, G.; Wang, J.; Li, S.; Wang, C.; Zheng, F.; and Jin, Y. 2024b. Deep industrial image anomaly detection: survey. Machine Intelligence Research, 21(1): 104135. Mallya, A.; Davis, D.; and Lazebnik, S. 2018. Piggyback: Adapting Single Network to Multiple Tasks by Learning to Mask Weights. In Proceedings of the European Conference on Computer Vision (ECCV). Mallya, A.; and Lazebnik, S. 2018. PackNet: Adding Multiple Tasks to Single Network by Iterative Pruning. arXiv:1711.05769. Masuda, M.; Hachiuma, R.; Fujii, R.; Saito, H.; and Sekikawa, Y. 2021. Toward Unsupervised 3d Point Cloud Anomaly Detection Using Variational Autoencoder. In 2021 IEEE International Conference on Image Processing (ICIP), 31183122. Pang, Y.; Wang, W.; Tay, F. E.; Liu, W.; Tian, Y.; and Yuan, L. 2022. Masked autoencoders for point cloud selfIn Computer VisionECCV 2022: supervised learning. 17th European Conference, Tel Aviv, Israel, October 2327, 2022, Proceedings, Part II, 604621. Springer. Qin, J.; Gu, C.; Yu, J.; and Zhang, C. 2023. Teacherstudent network for 3D point cloud anomaly detection with few normal samples. Expert Systems with Applications, 228: 120371. Rebuffi, S.-A.; Kolesnikov, A.; Sperl, G.; and Lampert, C. H. iCaRL: Incremental Classifier and Representation 2017. Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Riemer, M.; Klinger, T.; Bouneffouf, D.; and Franceschini, M. 2019. Scalable recollections for continual lifelong learning. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence. AAAI Press. Roth, K.; Pemula, L.; Zepeda, J.; Scholkopf, B.; Brox, T.; and Gehler, P. 2022. Towards Total Recall in Industrial Anomaly Detection. arXiv:2106.08265. Rudolph, M.; Wehrbein, T.; Rosenhahn, B.; and Wandt, B. 2023. Asymmetric Student-Teacher Networks for Industrial Anomaly Detection. In Winter Conference on Applications of Computer Vision (WACV). Tang, J.; Lu, H.; Xu, X.; Wu, R.; Hu, S.; Zhang, T.; Cheng, T. W.; Ge, M.; Chen, Y.-C.; and Tsung, F. 2025. An Incremental Unified Framework for Small Defect Inspection. In Computer Vision ECCV 2024, 307324. Tu, Y.; Zhang, B.; Liu, L.; Li, Y.; Zhang, J.; Wang, Y.; Wang, C.; and Zhao, C. 2025. Self-supervised Feature Adaptation for 3D Industrial Anomaly Detection. In Computer Vision ECCV 2024, 7591. Wang, J.; Xu, H.; Chen, X.; Xu, H.; Huang, Y.; Ding, X.; and Tu, X. 2025. Exploiting Point-Language Models with DualPrompts for 3D Anomaly Detection. arXiv:2502.11307."
        }
    ],
    "affiliations": [
        "College of Computer Science and Software Engineering, Shenzhen University",
        "Faculty of Applied Sciences, Macao Polytechnic University",
        "Guangdong Provincial Key Laboratory of Intelligent Information Processing",
        "Ningbo Institute of Digital Twin, Eastern Institute of Technology",
        "School of Artificial Intelligence, Shenzhen University",
        "Shenzhen Audencia Financial Technology Institute, Shenzhen University"
    ]
}