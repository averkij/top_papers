{
    "paper_title": "MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective Search and Data Curation",
    "authors": [
        "Zhenwen Liang",
        "Linfeng Song",
        "Yang Li",
        "Tao Yang",
        "Feng Zhang",
        "Haitao Mi",
        "Dong Yu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Automated Theorem Proving (ATP) in formal languages remains a formidable challenge in AI, demanding rigorous logical deduction and navigating vast search spaces. While large language models (LLMs) have shown promising performance, existing stepwise provers often suffer from biased search guidance, leading to inefficiencies and suboptimal proof strategies. This paper introduces the Multi-Perspective Search Prover (MPS-Prover), a novel stepwise ATP system designed to overcome these limitations. MPS-Prover incorporates two key innovations: a highly effective post-training data curation strategy that prunes approximately 40% of redundant training data without sacrificing performance, and a multi-perspective tree search mechanism. This search integrates a learned critic model with strategically designed heuristic rules to diversify tactic selection, prevent getting trapped in unproductive states, and enhance search robustness. Extensive evaluations demonstrate that MPS-Prover achieves state-of-the-art performance on multiple challenging benchmarks, including miniF2F and ProofNet, outperforming prior 7B parameter models. Furthermore, our analyses reveal that MPS-Prover generates significantly shorter and more diverse proofs compared to existing stepwise and whole-proof methods, highlighting its efficiency and efficacy. Our work advances the capabilities of LLM-based formal reasoning and offers a robust framework and a comprehensive analysis for developing more powerful theorem provers."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 1 ] . [ 1 2 6 9 0 1 . 5 0 5 2 : r a"
        },
        {
            "title": "Technical Report",
            "content": "MPS-Prover: Advancing Stepwise Theorem Proving by MultiPerspective Search and Data Curation Zhenwen Liang1, Linfeng Song1, Yang Li2, Tao Yang2, Feng Zhang2, Haitao Mi1, Dong Yu1 1Tencent AI Lab 2Tencent LLM Department Abstract Automated Theorem Proving (ATP) in formal languages remains formidable challenge in AI, demanding rigorous logical deduction and navigating vast search spaces. While large language models (LLMs) have shown promising performance, existing stepwise provers often suffer from biased search guidance, leading to inefficiencies and suboptimal proof strategies. This paper introduces the Multi-Perspective Search Prover (MPS-Prover), novel stepwise ATP system designed to overcome these limitations. MPS-Prover incorporates two key innovations: highly effective post-training data curation strategy that prunes approximately 40% of redundant training data without sacrificing performance, and multi-perspective tree search mechanism. This search integrates learned critic model with strategically designed heuristic rules to diversify tactic selection, prevent getting trapped in unproductive states, and enhance search robustness. Extensive evaluations demonstrate that MPS-Prover achieves state-of-the-art performance on multiple challenging benchmarks, including miniF2F and ProofNet, outperforming prior 7B parameter models. Furthermore, our analyses reveal that MPSProver generates significantly shorter and more diverse proofs compared to existing stepwise and whole-proof methods, highlighting its efficiency and efficacy. Our work advances the capabilities of LLM-based formal reasoning and offers robust framework and comprehensive analysis for developing more powerful theorem provers."
        },
        {
            "title": "Introduction",
            "content": "Automated Theorem Proving (ATP) is the task of automatically generating formal proofs for given mathematical or logical statements. By transforming problems into theorems in formal language (e.g., Lean (Moura & Ullrich, 2021) or Isabelle (Paulson, 1994)) and recursively interacting with the proof assistants engine to construct full proofs, an ATP system generates machine-verified proofs that guarantee strict logical correctness. This verifiability makes ATP indispensable for formal verification of solutions and proofs, where each reasoning step must be checked rigorously. ATP has long been viewed as foundational and challenging problem in both AI and mathematics, as such systems can leverage massive computational power, potentially aiding mathematicians in evaluating new hypotheses and even solving open mathematical problems. The rapid progress of large language models (LLMs) has significantly advanced automated theorem proving (ATP), exemplified by AlphaProofs silver medal performance at IMO 2024 (AlphaProof & Teams, 2024). Recent research tackles these challenges by combining the reasoning abilities of LLMs with feedback from proof checkers (e.g., the Lean compiler). Two main approaches have emerged. One is wholeproof generation (Wang et al., 2024c; Xin et al., 2024; Lin et al., 2025; Zhang et al., 2025; Wang et al., 2025), where the LLM attempts to output an entire proof script in one shot. This leverages the models ability to plan with high-level view but forgoes intermediate verification, making it prone to failures on long or intricate proofs. The second, and the focus of this paper, is stepwise formal proof generation (Wu et al., 2024; Li et al., 2024b; Xin et al., 2025). Here, an LLM iteratively proposes the next proof step (a formal tactic) given the current proof state. After each step, formal proof assistant verifies the result, ensuring the proof stays on correct path and providing an updated Email: zhenwzliang@global.tencent.com"
        },
        {
            "title": "Technical Report",
            "content": "Figure 1: Common failure patterns in step-based theorem provers. (a) Repetitive steps caused by critique model over-preference for specific tactics. (b) Unprovable states resulting from incorrect tactic choices that overly simplify conditions. (c) Ineffective tactic applications that fail to make progress. proof state as feedback. This step-by-step strategy offers several advantages: it allows for continuous interaction with the proof engine, enables progressive simplification of the search target, offers higher fault tolerance (errors only require backtracking to the previous step, not restarting the entire proof), and naturally lends itself to tree search methods that explore different proof paths. However, stepwise LLM-based provers face their own key challenges, as illustrated in Figure 1. First, the critic model guiding node selection in tree search can become biased. This bias often stems from the high frequency of certain safe or broadly applicable tactics (e.g., have, or general-purpose simplifiers like aesop and simp all when part of successful sequence) in the training data. These tactics, while often part of valid proofs and less prone to immediate errors, may not always lead to the most efficient or even correct overall proof path if the model over-relies on them, leading to stalled progress from similar tactic suggestions (Figure 1a). Second, incorrect tactic applications can lead to unprovable states by oversimplifying conditions (Figure 1b). Third, powerful but conditionally effective tactics (e.g., aesop, simp all) might be applied ineffectively. LLMs may propose these due to their frequent appearance in the training data or their ability to produce local simplifications that seem promising, yet they can make no progress or even obscure the path forward when the state is not genuinely suitable for such simplification (Figure 1c). While Best-First Search (BFS)-based methods (Li et al., 2024b; Xin et al., 2025) have shown promise in navigating this search space, their typical reliance on single critic score for node expansion can still render them vulnerable to these failure modes, particularly the biases inherent in learned critics. In this paper, we introduce the Multi-Perspective Search Prover (MPS-Prover), novel approach designed to overcome these limitations and significantly enhance stepwise proving performance. Our first contribution is carefully designed post-training data curation strategy. Unlike existing expert iteration approaches that uniformly add all newly proved problems, we introduce explicit rules to filter out approximately 40% of redundant or low-value training examples, focusing the model on learning more complex reasoning patterns. This curates higher-quality training set, leading to improved model accuracy and mitigating overfitting, especially when augmented with natural language reasoning datasets. Our second core contribution, building upon Best-First Search (BFS) methodologies (Li et al., 2024b; Xin et al., 2025), is multi-perspective tree search enhanced with strategically devised heuristic critiques. These critiques diversify tactic selection, reducing the risk of becoming trapped in repetitive, unproductive, or unprovable states by encouraging broader exploration during proof search. Our experiments demonstrate that MPS-Prover achieves state-of-the-art performance across multiple ATP benchmarks, including miniF2F and the more challenging ProofNet. On miniF2F, MPS-Prover surpasses previous stepwise provers. Furthermore, on ProofNet, within the 7B model class, MPSProver outperforms all baselines, including those employing CoT reasoning. Our analyses also"
        },
        {
            "title": "Technical Report",
            "content": "reveal that MPS-Prover generates significantly shorter and more diverse proofs compared to both BFS-based stepwise provers (under equivalent computational budgets) and leading whole-proof provers, highlighting the efficiency and efficacy of our multi-perspective search strategy. More specifically, the average solution length produced by MPS-Prover is only 3.44, compared to 15.91 and 52.16 for Kimina-Prover and Deepseek-Prover V2, respectively. These findings illustrate key advantages of our enhanced stepwise approach and suggest promising directions for future hybrid prover development. The primary contributions of this paper are: 1. novel post-training data curation strategy for stepwise provers, effectively eliminating approximately 40% of redundant training data while achieving superior performance. 2. The Multi-Perspective Search Prover (MPS-Prover), an innovative tree search method with heuristic critiques to enhance tactic diversity, prevent critique model bias, and improve search robustness. 3. Demonstration of state-of-the-art performance by MPS-Prover on multiple benchmarks, including miniF2F and ProofNet, along with analyses showing generation of shorter and more diverse proofs."
        },
        {
            "title": "2.1 Expert Iteration on Tactic Generation",
            "content": "Most recent Automated Theorem Proving (ATP) systems utilize an expert iteration (Polu & Sutskever, 2020) process to collect training data, which consists of several key steps: (1) autoformalization of natural language problems into formal proofs; (2) attempting proofs or disproofs using the model trained in the previous iteration; and (3) integrating newly proved theorems and the proofing steps into subsequent training iterations. We follow previous work to collected public available natural language problems and formal theorems and their proofs, including the Lean Workbook (Ying et al., 2024), Numina (Li et al., 2024a) and AoPS-Instruct (Mahdavi et al., 2025) for expert iteration. After formalizing the natural language problems, we conducted 26 iterative rounds of expert iteration. This process yielded over 30,000 proven theorems and approximately 6 million individual proving (state, step) pairs that can be used to train our prover."
        },
        {
            "title": "2.2 Training Data Curation",
            "content": "Filtering Short Proofs. To focus the models learning on these more complex reasoning patterns and reduce its reliance on simple tactics, we exclude theorems from the training set that can be proven in 3 steps or fewer. The number 3 is determined by grid search on {2, 3, 4, 5}.Our analysis indicated that these very short proofs predominantly rely on limited set of elementary tactics (e.g., l, simp all, or nlinarith) and thus offer minimal insight into advanced problem-solving techniques. By removing these overly simplistic examples, we reduced our initial training dataset by approximately 40%. It is important to note that filtering these simple proofs is not expected to degrade the models ability to solve easy problems. This is because the training data for step-wise prover inherently includes vast number of late-stage proof steps. These steps, taken when proof is already well underway and nearing completion, often resemble the states encountered in simpler problems. Consequently, the model still receives ample exposure to simpler reasoning contexts through these intermediate steps of complex proofs. Removing Ineffective Tactics. We additionally filter out the training data where the step does not meaningfully advance the proof state. Certain tactics intended for simplification occasionally do not bring any change to the proof state, such as aesop, all goals, and simp all. After evaluating our dataset, we identified and removed about 5% of such ineffective tactics. This targeted pruning encourages the model to better discern when these simplification tactics should be applied, reducing overreliance and improving proof efficiency."
        },
        {
            "title": "Technical Report",
            "content": "Figure 2: Search-strategy comparison in Lean-based proving. (a) Best-First Search follows the single branch favoured by learned critic; when that critics inherent bias selects an unprovable state or an ineffective tactic, the entire proof attempt terminates in failure. (b) Multi-Perspective Search (MPS) evaluates each expansion step from heuristics as well as the critic, preserving more diverse set of promising Lean 4 states and steering the prover around dead ends and toward successful proof."
        },
        {
            "title": "2.3 Multi-Perspective Tree Search",
            "content": "As illustrated in Figure 2, the traditional BFS approach selects nodes based solely on the best critic scores. Following Li et al. (2024b), our critic model is trained using hierarchical, tree-based distance prediction method to enhance its guidance capabilities during proof searches. The output from the critic model guides the proof search tree by indicating proximity to the completion of the proofthe smaller the predicted distance, the closer the node is to successful proof. While the critic model significantly enhances decision-making during most search steps, it can sometimes fail, resulting in unprovable states and reduced search efficiency. For instance, the proof-by-contradiction tactic, although powerful, can substantially alter the proof goal and make the theorem unprovable if misapplied. Additionally, sometimes critic models tend to frequently propose similar tactics, creating repetitive and ineffective local minima. As illustrated in Figure 2(a), the proof search is guided by the critic model to reach an intermediate node where the state becomes unprovable, leading to wasted effort on subsequent steps and ultimately resulting in failed proof attempt. To enhance the diversity of the guiding signals, we introduce three heuristic selection rules: Tactic Effectiveness Scoring. We assign different scores to tactics based on their perceived efficacy in advancing the proof. Generally, tactics that introduce new, substantive assumptions or significantly restructure the proof goal, such as rcases, intro, contrapose, induction, or proof by contradiction (when appropriately applied), are assigned higher scores. These are often tactics that can unlock new reasoning pathways or simplify the problem by breaking it down. Conversely, auxiliary tactics or those focused on more localized simplifications, like norm num and simp all, receive lower scores. While tactics like proof by contradiction can be problematic if misapplied by the critic model alone (as noted earlier), its inclusion with high score in this heuristic perspective ensures it remains viable option for exploration when potentially beneficial. These scores are manually assigned based on human expert experience in Lean theorem proving. detailed table of these tactic scores is provided in Appendix B. Minimizing Case Splits. We select tactics that result in the fewest occurrences of case within the state string. While tactics like induction, constructor, and split are beneficial under specific circumstances, excessive case splitting complicates proof states. This heuristic encourages simpler, more manageable proof states."
        },
        {
            "title": "Technical Report",
            "content": "Shortest State Preference. We prioritize tactics leading to shorter Lean 4 state strings. Similar to minimizing cases, this heuristic favors simpler, more straightforward states, facilitating more efficient proof completion. As shown in Figure 2, our tree search maintains up to four nodes for each expansion step. Specifically, from the set of nodes selected in the previous iteration, we generate Nsamples candidate tactics for each using the LLM. This results in larger pool of potential next states (e.g., if 4 nodes were selected and Nsamples = 8, wed have 4 8 = 32 candidate next states). From this expanded pool: 1. One node is selected based on the critic models prediction (i.e., the one with the smallest predicted distance to completion). 2. Three additional nodes are selected based on our heuristic rules. Each heuristic rule evaluates all candidate next states and picks the one that best satisfies its criterion. If different perspectives select the same node, we only retain it once, meaning that in such cases, fewer than four unique nodes might be carried forward to the next search iteration. We acknowledge that each heuristic rule, including the critic model, has inherent biases and limitations, favoring certain proof tactics or states. However, by concurrently applying these criteria, we substantially enhance the diversity of each search layer, ensuring promising nodes are retained rather than overlooked due to single-criterion bias."
        },
        {
            "title": "3 Experiment",
            "content": "Benchmarks To comprehensively evaluate our prover, we utilize two widely recognized benchmarks. 1. miniF2F (Zheng et al., 2022): This is the standard benchmark in the ATP community. The problems are sourced from mathematics competitions (AMC, AIME, IMO) as well as high-school and undergraduate curricula. We use the latest version available from the Huggingface Numina repository1, which corrects eight errors identified in the original dataset. 2. ProofNet (Azerbayev et al., 2023): This benchmark consists of 371 problems, characteristic of undergraduate-level mathematics. We report performance on its test split. Supervised Fine-tuning We employ supervised fine-tuning (SFT) on Qwen2.5-Math-7B-base. The SFT dataset is composition of: (1) step-by-step proof data generated during expert iteration and curated by our proposed filtering techniques; (2) whole proof data, formed by concatenating the accepted proof steps; and (3) data for training the distance critic model for our search algorithm. This aggregated dataset amounts to approximately 3.5 million question-answer pairs after applying our training data filtering method. The model was trained for 3 epochs using cosine learning rate scheduler with maximum learning rate of 2 105. We utilized cumulative batch size of 256. The training was performed on 8 * H20 80G GPUs, with total training duration of about 3 days. Evaluation Setup All evaluations are conducted using Lean version 4.16.0. For interaction between the LLM and the Lean proof assistant, we utilize the repl tool2, which facilitates step-by-step execution. To ensure the rigorous correctness of generated proofs, especially since repl might occasionally misinterpret certain erroneous steps as valid during step-wise execution, we perform final verification. This involves concatenating all generated steps to form complete proof script, which is then checked by the Lean compiler. The timeout for executing whole search is set to 3600 seconds, while the per-step tactic execution timeout is 60 seconds. Our search budget per problem is defined by the total number of tactic candidates explored. This is given by Npass Nperspectives Nmax iter Nsamples, where Npass is the number of independent search trials for problem (e.g., for pass@k, Npass = k), Nperspectives = 4, Nmax iter = 800 (maximum search iteration), and Nsamples = 8 (LLM samples per selected node). The accumulative search strategy, following Xin et al. (2025) (BFS-Prover), denotes an incremental evaluation protocol to assess the models maximum potential. In this setup, we keep searching and each search iteration focuses exclusively on problems that were not solved in prior iterations. 1https://huggingface.co/datasets/AI-MO/miniF2F_test 2https://github.com/leanprover-community/repl"
        },
        {
            "title": "Technical Report",
            "content": "Table 1: Comparison of Whole-Proof and Step-level Provers on miniF2F-test."
        },
        {
            "title": "Method",
            "content": "Large Whole-Proof Provers Kimina-Prover-Preview (Wang et al., 2025) DeepSeek-Prover-V2 (non-CoT) (Ren et al., 2025) DeepSeek-Prover-V2 (CoT) (Ren et al., 2025) Small Whole-Proof Provers Leanabell-Prover-GD-RL (Zhang et al., 2025) Goedel-Prover-SFT (Lin et al., 2025) STP (Dong & Ma, 2025) Kimina-Prover-Preview-Distill (Wang et al., 2025) DeepSeek-Prover-V2 (Distilled, non-CoT) (Ren et al., 2025) DeepSeek-Prover-V2 (Distilled, CoT) (Ren et al., 2025) Step-level Provers InternLM2.5-StepProver + BFS + CG (Wu et al., 2024) HunyuanProver + BFS + DC (Li et al., 2024b) BFS-Prover (Xin et al., 2025) BFS-Prover (Xin et al., 2025) MPS-Prover (Ours)"
        },
        {
            "title": "Sample Budget Accuracy",
            "content": "72B 671B 671B 7B 7B 7B 7B 7B 7B 7B 7B 7B 7B 7B 8192 8192 8192 128 25600 25600 1024 8192 256 32 600 600 8 400 2048 2 600 Accumulative 1 4 800 8 4 4 800 8 16 4 800 8 64 4 800 8 Accumulative 80.74% 78.30% 88.90% 61.1% 64.7% 67.6% 70.8% 75.0% 82.0% 65.9% 68.4% 70.83% 72.54% 67.62% 68.44% 70.08% 72.54% 75.82% We conduct extensive experiments to evaluate MPS-Prover against state-of-the-art methods on standard benchmarks. Our primary results on miniF2F are summarized in Table 1, with baseline details in Appendix C. Our method achieves the best performance among all step-level solvers evaluated. Specifically on miniF2F, MPS-Prover successfully proves 185 out of 244 problems (75.82% accuracy), demonstrating significant improvement over the previous state-of-the-art step-prover, BFS-prover. When considering all models within the 7B parameter class (both whole-proof and step-wise), our models performance is only surpassed by DeepSeek-Prover-V2 (Distilled, CoT). We posit this is expected, as their 7B model is distilled from significantly larger model, process known to often yield performance exceeding that of models trained natively at the smaller scale (Guo et al., 2025). In contrast, our model is trained directly via iterative refinement at the 7B scale. This comparison highlights the strong performance achieved by our method and suggests substantial potential for further improvement by leveraging larger base models or incorporating techniques like Chain-of-Thought (CoT) reasoning during tactic generation. Table 2: ProofNet-test performance of different 7B models (max budget). Another noteworthy finding is the strong performance of MPS-Prover even under constrained search budgets. At the minimum search budget evaluated, our model achieves pass rate of 67.62% on miniF2F, significantly outperforming InternLM (50.7%) and Hunyuan Prover (59.84%) under similar minimal conditions. Impressively, this base performance already exceeds the maximum reported performance of several strong baselines, such as Goedel-prover and InternLM2.5-StepProver. This inGoedel-Prover-SFT (Lin et al., 2025) STP (Dong & Ma, 2025) Deepseek-Prover-V1.5-RL (Xin et al., 2024) DeepSeek-Prover-V2 (non-CoT) (Ren et al., 2025) DeepSeek-Prover-V2 (CoT) (Ren et al., 2025) 15.6% 26.9% 25.3% 24.7% 29.6% Method (7B models) MPS-Prover (Ours)"
        },
        {
            "title": "Performance",
            "content": "32.97%"
        },
        {
            "title": "Technical Report",
            "content": "dicates that our approach exhibits excellent stability and efficiency, capable of achieving competitive results without necessitating exhaustive search efforts. We also evaluate the performance of MPS-Prover on the ProofNet benchmark, which is generally considered more challenging than miniF2F, featuring undergraduate-level mathematics problems that demand more intricate reasoning. Table 2 presents comparison of our method against other state-of-the-art 7B parameter models that have reported results on the ProofNet-test split. For fair comparison, all models, including ours, were evaluated using their respective maximum reported sampling budgets. As can be observed, MPS-Prover achieves success rate of 32.97%, surpassing all other 7B baseline models. Notably, our approach outperforms even DeepSeek-Prover-V2 with Chain-of-Thought (CoT) reasoning."
        },
        {
            "title": "3.2 Comparison under Fixed Budgets",
            "content": "A crucial aspect of evaluating search algorithms is their performance relative to computational resources. Our Multi-Perspective Search (MPS) inherently explores more branches per iteration compared to standard Best-First Search (BFS) with tree-based distance prediction as critic (Li et al., 2024b). Specifically, MPS expands four nodes (one from the critic model and three from heuristic rules) for each selected state in pass, whereas BFS typically expands only the single best node according to its criterion. Therefore, to ensure fair comparison under approximately equivalent computational budgets, we compare the performance of MPS at pass@k against BFS at pass@4k. As shown in Figure 3, MPS consistently outperforms BFS when allocated similar computational resources. At the lowest budget (MPS pass@1 vs. BFS pass@4), MPS achieves success rate of 67.62% (165/244), slightly edging out BFSs 66.39% (162/244). This advantage becomes more pronounced as the budget increases. This consistent gap highlights the effectiveness of the diverse exploration strategy employed by MPS. By considering multiple perspectives (critic score + heuristics) at each step, MPS is less prone to getting stuck in local optima compared to the single-criterion approach of BFS, leading to higher accuracy within given computational budget."
        },
        {
            "title": "3.3 Ablation Study",
            "content": "To understand the contribution of each component in our proposed MPS-Prover, we conduct comprehensive ablation study. We evaluate the performance of our system by systematically removing or altering key components while keeping the total computational budget fixed. This budget is equivalent to our full methods pass@64 setting (i.e., 64 4 800 8). The experiments are performed on the miniF2F benchmark, and the results are presented in Table 3. The ablation study reveals several key insights. First, removing our post-training data curation strategy results in marginal decrease in performance, with our model solving one fewer problem. Thus, it offers substantial savings in training time and computational resources (40% less training data) with negligible impact on the final proving capability. Second, when the critic models score-based guidance is replaced with random selection of nodes for expansion, there is drastic performance degradation (e.g., from 177 to 164 problems solved). This indicates that the learned critic model is effective in navigating the vast search space and guiding the prover towards promising proof paths. Finally, ablating each of our three heuristic rules for multi-perspective search by replacing their specific selection criteria with random choices also results in noticeable performance drops. In these variations (w/o Tactic Eff. Heuristic, w/o Min. Cases Heuristic, w/o Short. State Heuristic), the specific heuristic rule is deactivated, and its slot in the multi-perspective selection is filled by random choice from the Nsamples candidate next states generated by the LLM for the current expansion. This demonstrates that without these heuristic rules diversifying tactic selection and guiding search, the prover is more susceptible to the inherent biases of the critic model alone. It becomes more likely to fall into local minima, explore unproductive tactic sequences, or even reach unprovable states."
        },
        {
            "title": "Technical Report",
            "content": "Figure 3: Performance comparison under equivalent computational budgets."
        },
        {
            "title": "3.4 Proof Length and Diversity Analysis",
            "content": "Table 3: Ablation study on miniF2F. Performance is problems proved (out of 244) under fixed budget (MPS pass@64 equivalent). w/o indicates removing the specified component or replacing its guidance with random selection for heuristics."
        },
        {
            "title": "Method Variation",
            "content": "Proved (n/244) MPS-Prover (Full Method) w/o Data Curation w/o Critic Model w/o Tactic Eff. w/o Min. Cases w/o Short. State 177/244 176/ 164/244 174/244 173/244 172/244 To further investigate the characteristics of the proofs generated by different search strategies, we conduct quantitative comparison between our Multi-Perspective Search (MPS) and standard Best-First Search (BFS) with tree-based distance prediction as critic. We ensure fair comparison by using the identical LLM backbone and analyzing only the set of problems successfully proven by both MPS and BFS, guaranteeing analysis on the same theorems. Figure 4a shows the distribution of proof lengths, measured as the number of tactic steps (grouped into categories 1-9 and 10+). It is evident that proofs generated by MPS are significantly shorter on average than those found by BFS, as indicated by the mean values (dashed lines). MPS produces higher frequency of proofs with fewer steps, while BFS exhibits longer tail of lengthier proofs. This suggests that the diverse guidance signals in MPS help avoid unproductive tactic sequences or local optima, leading to more concise solutions. Figure 4b illustrates the distribution of proof tactic diversity. We define diversity as the number of unique tactics used in proof divided by its total length (number of steps). score closer to 1 indicates wider variety of tactics relative to length. The results clearly show that MPS-generated proofs possess considerably higher average diversity scores compared to BFS proofs (see mean lines). While both methods generate proofs with maximal diversity (score = 1.0, detailed in the annotation), BFS yields much larger proportion of proofs with very low diversity scores. This highlights MPSs effectiveness in promoting exploration and leveraging broader range of tactics, whereas BFS, guided solely by the critic model, is more prone to repetitive tactic usage."
        },
        {
            "title": "3.5 MPS-Prover vs. Whole-Proof Provers: Proof Length",
            "content": "We further analyze proof characteristics by comparing the length of proofs generated by our MPS-Prover against two leading whole-proof provers, Kimina-Prover-Preview and DeepSeekProver-V2. This comparison uses 170 commonly solved miniF2F problems and measures proof length in Lean tactic steps. Table 4 reveals that MPS-Prover generates substantially shorter proofs (mean length 3.44 steps) compared to Kimina (15.91) and DeepSeek-Prover-V2 (52.16). Some examples of their proofs can be found in our Appendix D."
        },
        {
            "title": "Min\nMax\nMean\nMedian\nStd Dev",
            "content": "Table 4: Proof length statistics (Lean steps) on 170 common miniF2F problems. Statistic DeepSeek-V2 Kimina MPS-Prover 3 698 52.16 33.0 66.47 1 186 15.91 6.0 24.19 1 37 3.44 2.0 4.64 We attribute this to the operational differences: stepwise provers like MPS-Prover benefit from frequent interactions with the Lean engine. Each tactic execution updates the proof state, allowing"
        },
        {
            "title": "Technical Report",
            "content": "(a) Proof length distribution (steps) for commonly solved problems. Dashed lines indicate mean length. (b) Proof diversity score distribution for commonly solved problems. Dashed lines indicate mean score. Figure 4: Quantitative analysis of proof characteristics for commonly solved problems by BFS (pass@256) and MPS (pass@64). the prover to adaptively refine its strategy by treating the new state as sub-problem. This iterative process, combined with tactic-level search prioritizing impactful steps, facilitates the discovery of more direct solutions. In contrast, whole-proof systems often plan the entire proof initially, with limited dynamic adaptation, potentially leading to longer, albeit correct, proof scripts. We believe this analysis highlights key advantage of step provers in producing more efficient proofs."
        },
        {
            "title": "4 Related Work",
            "content": "Earlier Methods in Automated Theorem Proving Early automated theorem provers relied on symbolic search algorithms and hand-crafted heuristics. Systems like Vampire (Riazanov & Voronkov, 2001) (a first-order logic prover) and SMT solvers like Z3 (de Moura & Bjørner, 2008) achieved impressive results using resolution, paramodulation, and DPLL-based search without learning. Some researchers apply premise selection in learning. Given large library of axioms or lemmas, the goal is to predict which ones are relevant to new theorem. Irving et al. (2016) pioneered deep learning for premise selection with the DeepMath system, using sequence models to rank premises for target theorem. Similarly, Wang et al. (2017) used graph embeddings of knowledge bases to select premises, treating theorem proving as graph traversal problem. Neural networks were also used to guide proof search directly inside automated provers. Loos et al. (2017) integrated deep network into the theorem prover, training the network to predict which inference step to pursue. LLM-based Whole-Proof Methods. Recent advances have seen LLMs directly generating complete formal proofs without iterative search, exploiting their powerful sequence modeling capabilities. Early examples include the Draft, Sketch, and Prove (DSP) system (Jiang et al., 2023), which uses informal natural language proofs as guidance, significantly improving prover accuracy; Baldur (First et al., 2023) generates proofs for Isabelle theorems and employs repair mechanism leveraging failure feedback, achieving state-of-the-art results. LEGO-Prover (Wang et al., 2024b) enhances whole-proof generation by hierarchically proving and reusing lemmas, effectively managing intermediate results. Similarly, POETRY (Wang et al., 2024a) employs recursive proof decomposition, systematically breaking complex theorems into solvable subgoals. Additionally, curriculum learning strategies (Polu et al., 2022) and reinforcement learning (Dong et al., 2024; Xin et al., 2024) have been employed to optimize LLM performance. Goedel-Prover (Lin et al., 2025) and leanabell (Zhang et al., 2025) perform continual training with cognitive behavior data and RL outcomes from Lean 4 compiler. Kimina-Prover (Wang et al., 2025) demonstrates superior results (80.7% on miniF2F pass@8192) through structured reasoning patterns and RL training. DeepSeek-Prover-V2 (Ren et al., 2025) is"
        },
        {
            "title": "Technical Report",
            "content": "trained via recursive subgoal decomposition pipeline using DeepSeek-V3. By integrating CoT-style reasoning with formal proving, it achieves an impressive 88.9% accuracy on miniF2F. LLM-based Step-level Tactic Generation Methods. Stepwise methods integrate LLMs into iterative proof searches, proposing individual proof steps and navigating search trees. GPT-f (Polu & Sutskever, 2020) pioneered this approach, proposing tactics that are verified incrementally, laying the groundwork for subsequent systems. HyperTree Proof Search (HTPS) (Lample et al., 2022) utilized an AlphaZero-inspired algorithm, exploring multiple proof branches simultaneously, significantly outperforming earlier methods through sophisticated search heuristics. LeanDojos ReProver (Yang et al., 2023) incorporates premise retrieval, selecting relevant lemmas at each proof step, enhancing efficiency on Lean benchmarks. SubgoalXL (Zhao et al., 2024) employs expert-guided iterative training, optimizing subgoal generation strategies. ProofAug (Liu et al., 2025) further develops hybrid integration by alternately invoking neural suggestions, symbolic ATP calls, and recursive prover applications for efficient verification. Recent models like InternLM2.5-StepProver (Wu et al., 2024) utilized expert iteration with large-scale datasets. HunyuanProver (Li et al., 2024b) further enhanced data synthesis and guided tree search algorithms. BFS-Prover (Xin et al., 2025) demonstrated the efficacy of simpler Best-First Search methods, incorporating direct preference optimization from compiler feedback, and length normalization."
        },
        {
            "title": "5 Discussion",
            "content": "In this work, we present the Multi-Perspective Search Prover (MPS-Prover), novel stepwise automated theorem proving system that significantly advances the state of the art. By introducing principled post-training data curation strategy and multi-perspective tree search mechanism enhanced with heuristic critics, MPS-Prover effectively addresses common failure modes in existing stepwise provers, such as biased search and exploration of unproductive proof paths. Our extensive experiments demonstrate that MPS-Prover not only achieves superior success rates on challenging benchmarks like miniF2F and ProofNet but also generates proofs that are more concise and diverse. For the broader ATP research community, our findings comfirms the strengths of stepwise proving, particularly in generating efficient proofs. Looking ahead, several promising avenues for future work emerge. One key direction is the development of hybrid systems that integrate the global planning capabilities of whole-proof methods with the adaptive, fine-grained search of stepwise provers like MPS-Prover. Another exciting prospect involves combining MPS-Prover with reinforcement learning (RL) techniques to further refine the critic model and search heuristics from self-play or direct feedback from the proof assistant. We believe that these future directions will continue to drive progress towards increasingly powerful and reliable automated theorem proving systems."
        },
        {
            "title": "References",
            "content": "DeepMind AlphaProof and AlphaGeometry Teams. Ai achieves silver-medal standard solving international mathematical olympiad problems.25 july 2024, 2024. Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward Ayers, Dragomir Radev, and Jeremy Avigad. Proofnet: Autoformalizing and formally proving undergraduate-level mathematics. arXiv preprint arXiv:2302.12433, 2023. Leonardo Mendonca de Moura and Nikolaj Bjørner. Proofs and refutations, and z3. In LPAR Workshops, volume 418, pp. 123132. Doha, Qatar, 2008. Kefan Dong and Tengyu Ma. Stp: Self-play llm theorem provers with iterative conjecturing and proving. arXiv e-prints, pp. arXiv2502, 2025. Kefan Dong, Arvind Mahankali, and Tengyu Ma. Formal theorem proving by rewarding llms to decompose proofs hierarchically. arXiv preprint arXiv:2411.01829, 2024."
        },
        {
            "title": "Technical Report",
            "content": "Emily First, Markus Rabe, Talia Ringer, and Yuriy Brun. Baldur: Whole-proof generation and repair with large language models. In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 12291241, 2023. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. Geoffrey Irving, Christian Szegedy, Alexander Alemi, Niklas Een, Francois Chollet, and Josef Urban. Deepmath-deep sequence models for premise selection. Advances in neural information processing systems, 29, 2016. Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou, Timothee Lacroix, Jiacheng Liu, Wenda Li, Mateja Jamnik, Guillaume Lample, and Yuhuai Wu. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. In The Eleventh International Conference on Learning Representations, 2023. Guillaume Lample, Timothee Lacroix, Marie-Anne Lachaux, Aurelien Rodriguez, Amaury Hayat, Thibaut Lavril, Gabriel Ebner, and Xavier Martinet. Hypertree proof search for neural theorem proving. Advances in neural information processing systems, 35:2633726349, 2022. Jia Li, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi, Shengyi Huang, Kashif Rasul, Longhui Yu, Albert Jiang, Ziju Shen, et al. Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions. Hugging Face repository, 13:9, 2024a. Yang Li, Dong Du, Linfeng Song, Chen Li, Weikang Wang, Tao Yang, and Haitao Mi. Hunyuanprover: scalable data synthesis framework and guided tree search for automated theorem proving. arXiv preprint arXiv:2412.20735, 2024b. Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, et al. Goedel-prover: frontier model for open-source automated theorem proving. arXiv preprint arXiv:2502.07640, 2025. Haoxiong Liu, Jiacheng Sun, Zhenguo Li, and Andrew Yao. Efficient neural theorem proving via fine-grained proof structure analysis. arXiv preprint arXiv:2501.18310, 2025. Sarah Loos, Geoffrey Irving, Christian Szegedy, and Cezary Kaliszyk. Deep network guided proof search. arXiv preprint arXiv:1701.06972, 2017. Sadegh Mahdavi, Muchen Li, Kaiwen Liu, Christos Thrampoulidis, Leonid Sigal, and Renjie Liao. Leveraging online olympiad-level math problems for llms training and contamination-resistant evaluation. arXiv preprint arXiv:2501.14275, 2025. Leonardo de Moura and Sebastian Ullrich. The lean 4 theorem prover and programming language. In Automated DeductionCADE 28: 28th International Conference on Automated Deduction, Virtual Event, July 1215, 2021, Proceedings 28, pp. 625635. Springer, 2021. Lawrence Paulson. Isabelle: generic theorem prover. Springer, 1994. Stanislas Polu and Ilya Sutskever. Generative language modeling for automated theorem proving. arXiv preprint arXiv:2009.03393, 2020. Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, and Ilya Sutskever. Formal mathematics statement curriculum learning. arXiv preprint arXiv:2202.01344, 2022. ZZ Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, et al. Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition. arXiv preprint arXiv:2504.21801, 2025."
        },
        {
            "title": "Technical Report",
            "content": "Alexandre Riazanov and Andrei Voronkov. Vampire 1.1. In Automated Reasoning: First International Joint Conference, IJCAR 2001 Siena, Italy, June 1822, 2001 Proceedings 1, pp. 376380. Springer, 2001. Haiming Wang, Huajian Xin, Zhengying Liu, Wenda Li, Yinya Huang, Jianqiao Lu, Zhicheng Yang, Jing Tang, Jian Yin, Zhenguo Li, et al. Proving theorems recursively. arXiv preprint arXiv:2405.14414, 2024a. Haiming Wang, Huajian Xin, Chuanyang Zheng, Zhengying Liu, Qingxing Cao, Yinya Huang, Jing Xiong, Han Shi, Enze Xie, Jian Yin, et al. Lego-prover: Neural theorem proving with growing libraries. In 12th International Conference on Learning Representations (ICLR 2024). International Conference on Learning Representations, ICLR, 2024b. Haiming Wang, Mert Unsal, Xiaohan Lin, Mantas Baksys, Junqi Liu, Marco Dos Santos, Flood Sung, Marina Vinyes, Zhenzhe Ying, Zekai Zhu, et al. Kimina-prover preview: Towards large formal reasoning models with reinforcement learning. arXiv preprint arXiv:2504.11354, 2025. Mingzhe Wang, Yihe Tang, Jian Wang, and Jia Deng. Premise selection for theorem proving by deep graph embedding. Advances in neural information processing systems, 30, 2017. Ruida Wang, Jipeng Zhang, Yizhen Jia, Rui Pan, Shizhe Diao, Renjie Pi, and Tong Zhang. Theoremllama: Transforming general-purpose llms into lean4 experts. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 1195311974, 2024c. Zijian Wu, Suozhi Huang, Zhejian Zhou, Huaiyuan Ying, Jiayu Wang, Dahua Lin, and Kai Chen. Internlm2. 5-stepprover: Advancing automated theorem proving via expert iteration on large-scale lean problems. arXiv preprint arXiv:2410.15700, 2024. Huajian Xin, ZZ Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, et al. Deepseek-prover-v1. 5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search. arXiv preprint arXiv:2408.08152, 2024. Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, and Kai Shen. Bfs-prover: Scalable best-first tree search for llm-based automatic theorem proving. arXiv preprint arXiv:2502.03438, 2025. Kaiyu Yang, Aidan Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, and Animashree Anandkumar. Leandojo: Theorem proving with retrieval-augmented language models. Advances in Neural Information Processing Systems, 36:2157321612, 2023. Huaiyuan Ying, Zijian Wu, Yihan Geng, JIayu Wang, Dahua Lin, and Kai Chen. Lean workbook: large-scale lean problem set formalized from natural language math problems. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024. Jingyuan Zhang, Qi Wang, Xingguang Ji, Yahui Liu, Yang Yue, Fuzheng Zhang, Di Zhang, Guorui Zhou, and Kun Gai. Leanabell-prover: Posttraining scaling in formal reasoning. arXiv preprint arXiv:2504.06122, 2025. Xueliang Zhao, Lin Zheng, Haige Bo, Changran Hu, Urmish Thakker, and Lingpeng Kong. Subgoalxl: Subgoal-based expert learning for theorem proving. arXiv preprint arXiv:2408.11172, 2024. Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. minif2f: cross-system benchmark for formal olympiad-level mathematics. In ICLR, 2022."
        },
        {
            "title": "A Limitation",
            "content": "While our MPS-Prover demonstrates significant advancements in stepwise automated theorem proving, it is important to acknowledge certain inherent limitations of the stepwise paradigm itself, particularly when compared to whole-proof generation approaches."
        },
        {
            "title": "Technical Report",
            "content": "A primary limitation of current stepwise provers, including MPS-Prover, lies in their handling of tactics that introduce complex, nested proof obligations, such as new lemmas that require their own sub-proofs. Whole-proof systems, like DeepSeek-Prover-V2 (Guo et al., 2025), can generate entire proof scripts that include have statements to introduce and subsequently prove auxiliary lemmas within the main proof structure. The verifier then processes the complete script. However, for purely stepwise prover interacting with the Lean 4 engine, if tactic attempts to introduce an unproven lemma or complex structure requiring an immediate, unfulfilled sub-proof (e.g., via have, or certain intricate uses of induction or calc blocks that dont immediately resolve to simpler goals), the Lean engine will typically raise an error and halt that proof path. The prover cannot easily pause the main proof, prove the lemma in isolation, and then resume, all within single interactive step. This means that MPS-Prover, like other current step-provers, is less adept at autonomously discovering and utilizing complex intermediate lemmas that are not already present in the context or standard libraries. While our multi-perspective search can find efficient paths using existing tactics, it does not inherently support the generation and in-line proving of new, non-trivial lemmas in the same way whole-proof generator might plan for. This restricts the provers ability to break down very complex problems into more manageable, lemma-dependent sub-problems in self-contained manner during the stepwise search. Addressing this limitation is key direction for future work. As mentioned in our conclusion, exploring hybrid approaches that combine the stepwise search capabilities of MPS-Prover with the global planning and lemma-handling strengths of whole-proof generation methods could offer promising path towards overcoming this challenge and further expanding the scope of theorems that can be automatically proven."
        },
        {
            "title": "B Tactic Effectiveness Scoring",
            "content": "The Tactic Effectiveness Scoring heuristic in MPS-Prover assigns numerical score to potential next steps based on the tactic used. These scores are designed to prioritize tactics that are generally more impactful or transformative in the proof process, while giving lower scores to auxiliary or very general-purpose tactics that might be applied speculatively. The scores are based on common patterns observed in mathematical proofs and expert experience with the Lean theorem prover. The goal is to guide the search towards more direct and structured proofs by favoring steps that represent significant logical advancements. Below is the scoring table used. Tactics are grouped by score, with higher scores indicating stronger preference. Note that regular expressions are used for some tactic patterns (e.g., simp?? matches simp and simp?). Table 5: Tactic Effectiveness Scores Score Tactics / Patterns 6 4 3 2 1 0 exact, refine, rintro, rcases, induction, revert, by contra, contrapose rw, rw .* at, convert, apply, subst, linarith, congr, ring nf ring, field simp, group, aesop simp??, simp all, simp only norm cast, push cast, clear norm num, swap, all goals have = (without subsequent by block for proof)"
        },
        {
            "title": "Technical Report",
            "content": "Below is the rationale for Scoring Tiers: Score 6 (Highly Transformative/Goal-Closing): This tier includes tactics that often conclude proof branch directly (e.g., exact, re ine), introduce crucial case distinctions or structural changes (e.g., induction, rcases), or fundamentally alter the goals form (e.g., bycontra, contrapose, revert). These are typically strong indicators of significant progress. Score 5 (Strong Rewriting/Application): Tactics like rw (rewrite), apply (apply hypothesis/lemma), and convert (change goal to definitionally equal one) are powerful for making targeted changes. Algebraic simplification tools like linarith and ring also fall here as they can often solve subgoals involving arithmetic or ring structures. Score 4 (Domain-Specific Solvers/Automated Tactics): This includes more specialized solvers like ring (for ring equalities) and ield simp (for field simplifications), group (for group theory), as well as general automated tactics like aesop. While powerful, aesop is placed slightly lower than the top tier as it can sometimes be black box and its success is highly conditional. Score 3 (General Simplification): The simp family of tactics (simp, simp all, simponly) are generalpurpose simplification tools. They are very useful but are scored moderately because they can sometimes be applied excessively or ineffectively, leading to many unproductive steps. For tactics that are excluded in the table, we assign default score of 3. Score 2 (Normalization/Cleanup): Tactics like norm cast (normalize casts), push cast (push casts inwards/outwards), and clear (remove unused hypotheses) are important for maintaining clean and manageable proof state but dont usually represent major logical steps forward. Score 1 (Auxiliary/Low Impact): This includes very basic numerical normalization (normnum), reordering goals (swap), or meta-level tactic combinators (all goals) which are generally supportive rather than primary drivers of proof progress. Score 0 (Potentially Redundant have): havex = statement without an accompanying by block to prove it (implying it might be proved by trivial step, or is simply renaming) is given the lowest score. The intent here is to penalize the simple act of stating trivial equality without further justification as standalone step. This heuristic scoring aims to complement the learned critic model by providing stable, experiencebased bias towards tactics that are historically effective in structuring and advancing mathematical proofs."
        },
        {
            "title": "C Baselines",
            "content": "We compare MPS-Prover against comprehensive set of state-of-the-art automated theorem provers. For whole-proof generation methods, we include Kimina-Prover-Preview (Wang et al., 2025), which employs interleaved natural language reasoning and Lean code blocks along with reinforcement learning (RL). Another strong contender is DeepSeek-prover V2 (Ren et al., 2025), notable for its use of subgoal decomposition to break down complex problems and subsequent proof generation, also enhanced with RL. Goedel prover (Lin et al., 2025) represents methods focused on extensive data collection, having curated large formalized mathematics dataset for expert iteration training. Leanabell-Prover (Zhang et al., 2025) similarly combines expert iteration with RL techniques. Additionally, STP (Dong & Ma, 2025) utilizes dual-role architecture with conjecturer and prover, where each component provides training signals for the other. For stepwise proof generation methods, we select InternLM-StepProver (Wu et al., 2024), one of the pioneers in applying LLMs to step-level ATP. Hunyuan prover (Li et al., 2024b) advanced this line by designing improved critic models and integrating Monte Carlo Tree Search (MCTS). The most recent and leading baseline in"
        },
        {
            "title": "Technical Report",
            "content": "this category is BFS-prover (Xin et al., 2025), which combines Supervised Fine-tuning (SFT) with Direct Preference Optimization (DPO) and incorporates length normalization during its Best-First Search, representing the previous state-of-the-art for step-provers."
        },
        {
            "title": "D Case Studies",
            "content": "To provide more nuanced understanding of the differences in proof strategies and generated solutions, we conduct case studies on specific theorems. We compare proofs generated by our MPS-Prover with those from Kimina-Prover and DeepSeek-Prover V2 for two commonly solved problems, and additionally showcase problem uniquely solved by MPS-Prover. D.1 Analysis of Commonly Solved Problem: algebra absapbon1pabsapbleqsumabsaon1pabsa The theorem algebra absapbon1pabsapbleqsumabsaon1pabsa states that for any real numbers and b, 1+b . All three provers successfully found proof for this theorem, but their approaches and the resulting proof scripts differ significantly in length and style. 1+a+b 1+a + a+b Our MPS-Prover generates remarkably concise proof of only 8 lines. Key steps include leveraging rw for rewriting goals based on non-negativity, using by cases for case analysis (e.g., = 0), and then efficiently using ield simp with relevant hypotheses like abs nonneg and mul nonneg. The proof concludes with call to re ine combined with div nonneg and powerful finishers like nlinarith and positivity. Each step appears to make substantial progress, often simplifying the goal significantly or discharging parts of it by effectively utilizing built-in Mathlib lemmas and tactics. This conciseness stems from MPS-Provers ability to explore and select tactics that yield significant progress at each step, guided by the multi-perspective search. In contrast, the solution from Kimina-Prover for the same problem is considerably longer, spanning approximately 40 lines. It primarily relies on sequence of have statements to introduce intermediate lemmas (e.g., h1 : abs(a + b) absa + absb, h2 : . . . , h3 : . . . ). Each of these lemmas is then proven using combination of more granular tactics like apply, linarith, nlinarith, and ield simp. While logically sound, this approach of explicitly stating and proving multiple intermediate steps results in more verbose proof. This suggests strategy that might break down the problem based on an initial plan but does not necessarily find the most direct path available through more powerful, combined tactics. The proof generated by DeepSeek-Prover V2 is the longest, around 60 lines. Similar to KiminaProver, it also extensively uses have to introduce and prove series of lemmas. However, the proof of those lemmas, and its subsequent applications, are broken down into many fine-grained steps involving positivity, nlinarith, linarith, and rw[div le div . . . ]. While demonstrating sophisticated understanding by identifying and proving this general property, the overall proof becomes quite lengthy due to the detailed, step-by-step derivation of each component. This is characteristic of whole-proof systems that might formulate high-level plan (e.g., prove and use the monotonicity of (x) = x/(1 + x)) and then meticulously fill in the details, which may not always be the most compact way to express the proof in Lean. These comparisons highlight that MPS-Prover, through its stepwise search and selection of highprogress tactics, tends to produce more concise proofs by effectively leveraging powerful built-in Mathlib functionalities. Whole-proof systems, while capable of complex reasoning and planning, may generate longer proofs due to their tendency to break down problems into many simpler, explicitly stated intermediate steps, potentially constrained by an initial, possibly more verbose, plan. -- Solution to algebra_absapbon1pabsapbleqsumabsaon1pabsa by our MPS-Prover import Mathlib 1 2"
        },
        {
            "title": "Technical Report",
            "content": "import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat theorem algebra_absapbon1pabsapbleqsumabsaon1pabsa (a : R) : abs (a + b) / (1 + abs (a + b)) abs / (1 + abs a) + abs / (1 + abs b) := by rw [ sub_nonneg, sub_nonneg, sub_nonneg] by_cases h1 : = 0 all_goals field_simp [abs_of_nonneg, abs_of_pos, *] have h2 : 0 := abs_nonneg <;> have h3 : 0 := abs_nonneg <;> field_simp [h1, h2, h3] have h4 : 0 + := abs_nonneg (a + b) <;> have h5 : 0 * := mul_nonneg h3 h2 <;> field_simp [h1, h2, h3, h4, h5] refine' div_nonneg (by nlinarith [abs_mul b, abs_add b]) (by positivity) -- Solution to algebra_absapbon1pabsapbleqsumabsaon1pabsa by Kimina-Prover import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat theorem algebra_absapbon1pabsapbleqsumabsaon1pabsa (a : R) : abs (a + b) / (1 + abs (a + b)) abs / (1 + abs a) + abs / (1 + abs b) := by have h1 : abs (a + b) abs + abs := by apply abs_add have h2 : abs (a + b) / (1 + abs (a + b)) (abs + abs b) / (1 + abs + abs b) := by have h2a : abs (a + b) abs + abs := by apply abs_add have h2b : 0 abs (a + b) := abs_nonneg (a + b) have h2c : 0 abs + abs := by apply add_nonneg apply abs_nonneg apply abs_nonneg have h2d : 0 (1 + abs (a + b)) := by linarith [abs_nonneg (a + b)] have h2e : 0 (1 + abs + abs b) := by linarith [abs_nonneg a, abs_nonneg b] have h2f : abs (a + b) / (1 + abs (a + b)) (abs + abs b) / (1 + abs + abs b) := (cid:44) by apply (div_le_div_iff (by linarith) (by linarith)).mpr nlinarith [abs_nonneg (a + b), abs_nonneg a, abs_nonneg b, h2a] exact h2f have h3 : (abs + abs b) / (1 + abs + abs b) abs / (1 + abs a) + abs / (1 + (cid:44) abs b) := by have h3a : 0 (1 + abs + abs b) := by linarith [abs_nonneg a, abs_nonneg b] have h3b : 0 (1 + abs a) := by linarith [abs_nonneg a] have h3c : 0 (1 + abs b) := by linarith [abs_nonneg b] 16 5 6 7 8 9 11 12 13 14 15 17 18 19 20 21 1 2 3 4 5 7 8 9 10 11 13 14 15 16 17 19 20 21 22 23 25 26 27 28 29 31 32 33 34"
        },
        {
            "title": "Technical Report",
            "content": "37 38 39 40 41 43 44 45 46 47 49 50 51 52 53 55 56 57 58 59 61 62 63 64 65 67 1 2 3 4 6 7 8 9 10 12 13 14 15 16 18 19 20 21 have h4 : (abs + abs b) / (1 + abs + abs b) abs / (1 + abs a) + abs / (1 + (cid:44) abs b) := by have h4a : abs 0 := abs_nonneg have h4b : abs 0 := abs_nonneg have h4c : 1 + abs + abs > 0 := by linarith [abs_nonneg a, abs_nonneg b] have h4d : 1 + abs > 0 := by linarith [abs_nonneg a] have h4e : 1 + abs > 0 := by linarith [abs_nonneg b] have h5 : abs / (1 + abs a) + abs / (1 + abs b) - (abs + abs b) / (1 + abs + (cid:44) abs b) 0 := by have h5a : abs / (1 + abs a) + abs / (1 + abs b) - (abs + abs b) / (1 + abs (cid:44) + abs b) = (abs * (1 + abs b) * (1 + abs + abs b) + abs * (1 + abs a) * (1 + abs + abs b) - (abs + abs b) * (1 + abs a) * (1 + abs b)) / ((1 + abs a) * (1 + abs b) * (1 + abs + abs b)) := by field_simp <;> ring rw [h5a] have h5b : 0 (abs * (1 + abs b) * (1 + abs + abs b) + abs * (1 + abs a) * (1 + abs + abs b) - (abs + abs b) * (1 + abs a) * (1 + abs b)) := by nlinarith [sq_nonneg (abs a), sq_nonneg (abs b), mul_nonneg (abs_nonneg a) (cid:44) (abs_nonneg b)] have h5c : 0 < (1 + abs a) * (1 + abs b) * (1 + abs + abs b) := by apply mul_pos apply mul_pos linarith [abs_nonneg a] linarith [abs_nonneg b] linarith [abs_nonneg a, abs_nonneg b] apply div_nonneg linarith nlinarith [abs_nonneg a, abs_nonneg b] linarith [h5] linarith [h4] linarith [h2, h3] -- Solution to algebra_absapbon1pabsapbleqsumabsaon1pabsa by Deepseek-Prover V2 import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat /-- Show that for any real numbers and b, frac{a+b}{1+a+b}leq (cid:44) theorem algebra_absapbon1pabsapbleqsumabsaon1pabsa (a : R) : frac{a}{1+a}+frac{b}{1+b}.-/ abs (a + b) / (1 + abs (a + b)) abs / (1 + abs a) + abs / (1 + abs b) := by have h1 : abs (a + b) abs + abs := by calc abs (a + b) abs + abs := by -- Use the triangle inequality for absolute values. exact abs_add _ = abs + abs := by rfl have h2 : (x : R), 0 / (1 + x) / (1 + y) := by intro hx hxy"
        },
        {
            "title": "Technical Report",
            "content": "22 23 24 25 26 28 29 30 31 32 34 35 36 37 38 40 41 42 43 44 46 47 48 49 50 52 53 54 55 56 58 59 60 61 62 64 65 66 67 68 70 71 72 73 74 have h3 : 0 := hx have h4 : := hxy have h5 : 0 := by linarith have h6 : 0 1 + := by linarith have h7 : 0 1 + := by linarith have h8 : 0 < 1 + := by linarith have h9 : 0 < 1 + := by linarith -- Use the division inequality to compare the fractions. have h10 : / (1 + x) / (1 + y) := by rw [div_le_div_iff (by positivity) (by positivity)] -- Simplify the inequality to form that can be handled by linear arithmetic. nlinarith [mul_nonneg h3 (sub_nonneg.mpr h4), mul_nonneg h5 h3, mul_nonneg h5 (sub_nonneg.mpr h4)] exact h10 have h3 : abs (a + b) / (1 + abs (a + b)) (abs + abs b) / (1 + (abs + abs b)) := (cid:44) by have h4 : 0 abs (a + b) := abs_nonneg (a + b) have h5 : 0 abs + abs := by positivity have h6 : abs (a + b) abs + abs := h1 have h7 : 0 1 + abs (a + b) := by positivity have h8 : 0 1 + (abs + abs b) := by positivity have h9 : 0 < 1 + abs (a + b) := by positivity have h10 : 0 < 1 + (abs + abs b) := by positivity -- Use the fact that the function / (1 + x) is increasing for 0. have h11 : abs (a + b) / (1 + abs (a + b)) (abs + abs b) / (1 + (abs + abs b)) (cid:44) := by have h12 : abs (a + b) / (1 + abs (a + b)) (abs + abs b) / (1 + (abs + abs b)) (cid:44) := by -- Apply the increasing property of the function. have h13 : 0 abs (a + b) := by positivity have h14 : abs (a + b) abs + abs := h1 have h15 : 0 abs + abs := by positivity have h16 : 0 < 1 + abs (a + b) := by positivity have h17 : 0 < 1 + (abs + abs b) := by positivity -- Use the previously proven lemma. have h18 : abs (a + b) / (1 + abs (a + b)) (abs + abs b) / (1 + (abs + abs (cid:44) b)) := by apply h2 <;> try norm_num <;> linarith exact h18 exact h12 exact h11 have h4 : (abs + abs b) / (1 + (abs + abs b)) abs / (1 + abs a) + abs / (1 + (cid:44) abs b) := by have h5 : 0 abs := abs_nonneg have h6 : 0 abs := abs_nonneg have h7 : 0 abs + abs := by positivity have h8 : 0 < 1 + abs := by positivity have h9 : 0 < 1 + abs := by positivity have h10 : 0 < 1 + (abs + abs b) := by positivity have h11 : (abs + abs b) / (1 + (abs + abs b)) = abs / (1 + (abs + abs b)) + (cid:44) abs / (1 + (abs + abs b)) := by field_simp [h8, h9, h10] <;> ring <;> field_simp [h8, h9, h10] <;> ring"
        },
        {
            "title": "Technical Report",
            "content": "75 76 77 78 79 81 82 83 84 85 87 88 89 90 91 93 94 95 96 97 99 100 101 102 103 105 106 107 108 109 111 rw [h11] have h12 : abs / (1 + (abs + abs b)) abs / (1 + abs a) := by have h13 : 0 abs := abs_nonneg have h14 : 0 < 1 + abs := by positivity have h15 : 0 < 1 + (abs + abs b) := by positivity have h16 : 0 < 1 + abs + abs := by positivity -- Use the fact that 1 + abs 1 + (abs + abs b) to show the inequality have h17 : 1 + abs 1 + (abs + abs b) := by nlinarith [h6] -- Use the division inequality to prove the result have h18 : abs / (1 + (abs + abs b)) abs / (1 + abs a) := by apply div_le_div_of_le_left (by positivity) (by positivity) <;> nlinarith exact h18 have h13 : abs / (1 + (abs + abs b)) abs / (1 + abs b) := by have h14 : 0 abs := abs_nonneg have h15 : 0 < 1 + abs := by positivity have h16 : 0 < 1 + (abs + abs b) := by positivity have h17 : 0 < 1 + abs + abs := by positivity -- Use the fact that 1 + abs 1 + (abs + abs b) to show the inequality have h18 : 1 + abs 1 + (abs + abs b) := by nlinarith [h5] -- Use the division inequality to prove the result have h19 : abs / (1 + (abs + abs b)) abs / (1 + abs b) := by apply div_le_div_of_le_left (by positivity) (by positivity) <;> nlinarith exact h19 have h20 : abs / (1 + (abs + abs b)) + abs / (1 + (abs + abs b)) abs / (1 (cid:44) + abs a) + abs / (1 + abs b) := by linarith linarith have h5 : abs (a + b) / (1 + abs (a + b)) abs / (1 + abs a) + abs / (1 + abs b) := (cid:44) by calc abs (a + b) / (1 + abs (a + b)) (abs + abs b) / (1 + (abs + abs b)) := h3 _ abs / (1 + abs a) + abs / (1 + abs b) := h4 exact h5 D.2 Analysis of Commonly Solved Problem: imo 1962 p2 The theorem imo 1962 p2 is another problem successfully solved by all three provers, allowing for comparison of proof styles for different type of problem involving inequalities and square roots. Our MPS-Prover again produces very short proof. It effectively uses re ine to structure the proof for the conjunction, then leverages sequence of powerful rewriting and simplification tactics like rw, ield simp, norm num, and nlinarith, often chained or applied with specific hypotheses. This demonstrates an ability to quickly simplify complex algebraic expressions and discharge goals using arithmetic reasoning. Kimina-Provers solution is also structured around proving the two conjuncts separately using constructor. It uses have to establish intermediate inequalities and then applies tactics like linarith, sq lt sq, rw[Real.sq sqrt], and nlinarith. The steps are logical and clear but involve more explicit intermediate assertions compared to MPS-Prover. DeepSeek-Prover V2s proof is the most detailed. It also uses constructor (implicitly, by proving h3 and h11 separately for the conjuncts) and introduces many intermediate facts with have. The"
        },
        {
            "title": "Technical Report",
            "content": "reasoning involves careful manipulation of inequalities, squaring both sides (e.g., gcongr), and algebraic simplification, often broken down into very small, verifiable steps. While demonstrating thoroughness, this level of granularity contributes to the proofs length. This case again illustrates MPS-Provers tendency towards conciseness by selecting powerful, progress-making tactics. The whole-proof methods, while effective, often produce more verbose proofs due to their strategy of explicit lemma introduction and detailed, step-by-step derivations. -- Solution to imo_1962_p2 by our MPS-Prover import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat theorem imo_1962_p2 (x : R) (h0 : 0 3 - x) (h1 : 0 + 1) (h2 : 1 / 2 < Real.sqrt (3 - x) - Real.sqrt (x + 1)) : -1 < 1 - Real.sqrt 31 (cid:44) / 8 := by refine' _, _ nlinarith [Real.sq_sqrt h0, Real.sq_sqrt h1] rw [lt_sub_iff_add_lt] at h2 rw [lt_sqrt (by positivity)] at h2 rw [ sub_pos] at h2 ring_nf ring_nf at h0 h1 h2 field_simp at h2 <;> ring_nf at h2 <;> norm_num [h0, h1, h2] rw [Real.sqrt_lt (by linarith)] <;> norm_num <;> nlinarith [Real.sqrt_nonneg (1 + x), Real.sq_sqrt h1] -- Solution to imo_1962_p2 by Kimina-Prover import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat theorem imo_1962_p2 (x : R) (h0 : 0 3 - x) (h1 : 0 + 1) (h2 : 1 / 2 < Real.sqrt (3 - x) - Real.sqrt (x + 1)) : -1 < 1 - Real.sqrt 31 (cid:44) / 8 := by constructor linarith [h1] have h3 : Real.sqrt (3 - x) - Real.sqrt (x + 1) > 1 / 2 := by linarith have h4 : Real.sqrt (3 - x) > Real.sqrt (x + 1) + 1 / 2 := by linarith have h5 : Real.sqrt (x + 1) 0 := Real.sqrt_nonneg (x + 1) have h6 : Real.sqrt (3 - x) 0 := Real.sqrt_nonneg (3 - x) have h7 : Real.sqrt (3 - x) > 0 := by linarith [h6, h5] have h8 : (Real.sqrt (3 - x)) ^ 2 > (Real.sqrt (x + 1) + 1 / 2) ^ 2 := by apply sq_lt_sq' all_goals linarith [h4, h5, h7] have h9 : (Real.sqrt (3 - x)) ^ 2 = 3 - := by rw [Real.sq_sqrt] linarith have h10 : (Real.sqrt (x + 1) + 1 / 2) ^ 2 = (Real.sqrt (x + 1)) ^ 2 + Real.sqrt (x + (cid:44) 1) + 1 / 4 := by 20 1 2 3 4 6 7 8 9 10 12 13 14 15 16 18 19 20 21 1 3 4 5 6 7 9 10 11 12 13 15 16 17 18 19 21 22 23 24 25 27 28 29 30 31 33 34 35 36 37 39 40 1 2 3 5 6 7 8 9 11 12 13 14 15 17 18 19 20 21 23 24 25 26 27 29 30 31 32"
        },
        {
            "title": "Technical Report",
            "content": "ring_nf <;> simp [Real.sqrt_nonneg] rw [h9, h10] at h8 have h11 : (Real.sqrt (x + 1)) ^ 2 = + 1 := by rw [Real.sq_sqrt] linarith have h12 : Real.sqrt (x + 1) < 7 / 4 - 2 * := by nlinarith [h8, h11, (cid:44) have h13 : < 1 - Real.sqrt 31 / 8 := by Real.sqrt_nonneg (x + 1)] have h14 : Real.sqrt (x + 1) + 2 * < 7 / 4 := by linarith [h12] have h15 : Real.sqrt 31 ^ 2 = 31 := by rw [Real.sq_sqrt] norm_num nlinarith [h14, Real.sq_sqrt (show 0 + 1 by linarith), Real.sq_sqrt (show 0 3 (cid:44) - by linarith), Real.sqrt_nonneg (3 - x), Real.sqrt_nonneg (x + 1), Real.sq_sqrt (show 0 (31 : R) by norm_num), Real.sq_sqrt (show 0 (8 : R) by norm_num)] (cid:44) (cid:44) linarith [h13] -- Solution to imo_1962_p2 by Deepseek-Prover V2 import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat theorem imo_1962_p2 (x : R) (h0 : 0 3 - x) (h1 : 0 + 1) (h2 : 1 / 2 < Real.sqrt (3 - x) - Real.sqrt (x + 1)) : -1 < 1 - Real.sqrt 31 (cid:44) / 8 := by have h3 : -1 := by linarith have h4 : Real.sqrt (3 - x) - Real.sqrt (x + 1) > 1 / 2 := by linarith have h5 : Real.sqrt (3 - x) > Real.sqrt (x + 1) + 1 / 2 := by linarith have h6 : 3 - > + 1 + Real.sqrt (x + 1) + 1 / 4 := by have h61 : Real.sqrt (3 - x) > Real.sqrt (x + 1) + 1 / 2 := h5 have h62 : 0 Real.sqrt (x + 1) := Real.sqrt_nonneg (x + 1) have h63 : 0 Real.sqrt (3 - x) := Real.sqrt_nonneg (3 - x) have h64 : 0 Real.sqrt (x + 1) * (1 / 2) := by positivity have h65 : 0 Real.sqrt (3 - x) := Real.sqrt_nonneg (3 - x) have h66 : 0 Real.sqrt (x + 1) := Real.sqrt_nonneg (x + 1) have h67 : (Real.sqrt (x + 1) + 1 / 2) 0 := by positivity have h68 : Real.sqrt (3 - x) > Real.sqrt (x + 1) + 1 / 2 := h5 have h69 : (Real.sqrt (x + 1) + 1 / 2) ^ 2 < (Real.sqrt (3 - x)) ^ 2 := by gcongr <;> nlinarith [Real.sq_sqrt (show 0 + 1 by linarith), Real.sq_sqrt (show 0 3 (cid:44) - by linarith)] have h610 : (Real.sqrt (x + 1) + 1 / 2) ^ 2 = (x + 1) + Real.sqrt (x + 1) + 1 / 4 := (cid:44) by nlinarith [Real.sq_sqrt (show 0 + 1 by linarith), Real.sq_sqrt (show 0 3 - (cid:44) by linarith), 21 36 37 39 40 41 42 43 45 46 47 48 49 51 52 53 54 55 57 58 59 60 61 63 64 65 66 67 69 70 71 72 73 75 76 77 78 79 81 82 83 84"
        },
        {
            "title": "Technical Report",
            "content": "sq_nonneg (Real.sqrt (x + 1) - 1 / 2)] have h611 : (Real.sqrt (3 - x)) ^ 2 = 3 - := by rw [Real.sq_sqrt] <;> linarith nlinarith [Real.sq_sqrt (show 0 + 1 by linarith), Real.sq_sqrt (show 0 3 - by (cid:44) linarith)] have h7 : 7 - 8 * > 4 * Real.sqrt (x + 1) := by have h71 : 3 - > + 1 + Real.sqrt (x + 1) + 1 / 4 := h6 have h72 : 0 Real.sqrt (x + 1) := Real.sqrt_nonneg (x + 1) nlinarith [Real.sqrt_nonneg (x + 1)] have h8 : < 7 / 8 := by by_contra have h81 : 7 / 8 := by linarith have h82 : 7 - 8 * 0 := by linarith have h83 : 4 * Real.sqrt (x + 1) 0 := by positivity linarith have h9 : 0 Real.sqrt 31 := by positivity have h10 : 64 * ^ 2 - 128 * + 33 > 0 := by have h101 : 7 - 8 * > 4 * Real.sqrt (x + 1) := h7 have h102 : 0 Real.sqrt (x + 1) := Real.sqrt_nonneg (x + 1) have h103 : 0 7 - 8 * := by linarith have h104 : 0 Real.sqrt (x + 1) := Real.sqrt_nonneg (x + 1) have h105 : 0 7 - 8 * := by linarith have h106 : (7 - 8 * x) ^ 2 > (4 * Real.sqrt (x + 1)) ^ 2 := by gcongr have h107 : (4 * Real.sqrt (x + 1)) ^ 2 = 16 * (x + 1) := by nlinarith [Real.sq_sqrt (show 0 + 1 by linarith), sq_nonneg (Real.sqrt (x + 1) - (cid:44) 2)] have h108 : (7 - 8 * x) ^ 2 > 16 * (x + 1) := by linarith nlinarith [Real.sq_sqrt (show 0 + 1 by linarith), sq_nonneg (x - 1)] have h11 : < 1 - Real.sqrt 31 / 8 := by by_contra have h111 : 1 - Real.sqrt 31 / 8 := by linarith have h112 : 64 * ^ 2 - 128 * + 33 0 := by have h113 : 1 - Real.sqrt 31 / 8 := h111 have h114 : 1 + Real.sqrt 31 / 8 := by by_contra h114 have h115 : > 1 + Real.sqrt 31 / 8 := by linarith have h116 : 64 * ^ 2 - 128 * + 33 > 0 := h10 have h117 : < 7 / 8 := h8 nlinarith [Real.sqrt_nonneg 31, Real.sq_sqrt (show 0 31 by norm_num)] nlinarith [Real.sqrt_nonneg 31, Real.sq_sqrt (show 0 31 by norm_num), sq_nonneg (x - (1 - Real.sqrt 31 / 8)), sq_nonneg (x - (1 + Real.sqrt 31 / 8))] linarith [h10] exact h3,"
        },
        {
            "title": "Technical Report",
            "content": "D.3 Analysis of Problem Uniquely Solved by MPS-Prover: amc12a 2020 p7 The problem amc12a 2020 p7 involves evaluating sum based on sequence defined by specific values of a(k)3. This problem was solved by our MPS-Prover, while both Kimina-Prover and DeepSeek-Prover V2 failed to find solution. The MPS-Prover solution employs induction as key initial step. This is followed by extensive use of simp all (often with con ig := {decide := true}) to simplify goals after instantiating terms of the sequence (a(0) through a(6)) derived from the hypotheses h0 through h6. The proof also uses interval cases to handle natural number variables within certain ranges derived from nlinarith. The final steps involve further simplification with Nat.cast properties. The success here suggests that MPS-Provers search was able to identify productive high-level strategy (induction) and then effectively use simplification and case analysis tactics to manage the resulting subgoals. The ability to find this particular combination of tactics, especially the crucial induction and effective use of interval cases, within the search budget highlights the strength of our multi-perspective approach in navigating complex search spaces where other methods might falter. The other provers might have struggled to identify the correct induction variable or effectively simplify the numerous concrete arithmetic subgoals that arise. This case study highlights MPS-Provers ability to find solutions to problems that prove difficult for other leading systems. Such successes can be attributed to the robust search paradigm of stepwise provers, which allows for exploration of various proof strategies, selection of effective tactics, and crucial backtracking capabilities. These features, amplified by our multi-perspective enhancements, enable the discovery of solutions even when the reasoning path is intricate or non-obvious. -- problem solved by our MPS-Prover, where Kimina-Prover and Deepseek-Prover both fail (cid:44) to solve. import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat (cid:44) theorem amc12a_2020_p7 (a : N) (h0 : (a 0)^3 = 1) (h1 : (a 1)^3 = 8) (h2 : (a 2)^3 = 27) (h3 : (a 3)^3 = 64) (h4 : (a 4)^3 = 125) (h5 : (a 5)^3 = 216) (h6 : (a 6)^3 = 343) : in Finset.range 7, (6 * (a k)^2) - (2 * in Finset.range 6, (a k)^2) = 658 := by (cid:44) (cid:44) induction' 4 <;> simp_all [Finset.sum_range_succ, pow_succ] have h7 : 1 8 := by nlinarith interval_cases 1 <;> simp_all (config := {decide := true}) have h7 : 2 * 2 * 2 = 27 := by assumption have h8 : 3 * 3 * 3 = 64 := h3 <;> try simp_all [Nat.mul_comm, Nat.mul_assoc, Nat.mul_left_comm] have h9 : 4 * 4 * 4 = 125 := by nlinarith all_goals have : 2 6 := by nlinarith interval_cases 2 <;> simp_all (config := {decide := true}) have h10 : 5 * 5 * 5 = 216 := by nlinarith have h12 : 6 = 7 := by nlinarith simp_all all_goals have : 4 12 := by nlinarith interval_cases 4 <;> simp_all (config := {decide := true}) have h14 : 5 = 6 := by nlinarith simp_all [Nat.cast_add, Nat.cast_mul, Nat.cast_pow] have h11 : 3 8 := by nlinarith interval_cases 3 <;> simp_all 23 1 2 3 5 6 7 8 9 11 12 13 14 15 17 18 19 20 21 23 24 25 26"
        }
    ],
    "affiliations": [
        "Tencent AI Lab",
        "Tencent LLM Department"
    ]
}