{
    "paper_title": "API Agents vs. GUI Agents: Divergence and Convergence",
    "authors": [
        "Chaoyun Zhang",
        "Shilin He",
        "Liqun Li",
        "Si Qin",
        "Yu Kang",
        "Qingwei Lin",
        "Dongmei Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have evolved beyond simple text generation to power software agents that directly translate natural language commands into tangible actions. While API-based LLM agents initially rose to prominence for their robust automation capabilities and seamless integration with programmatic endpoints, recent progress in multimodal LLM research has enabled GUI-based LLM agents that interact with graphical user interfaces in a human-like manner. Although these two paradigms share the goal of enabling LLM-driven task automation, they diverge significantly in architectural complexity, development workflows, and user interaction models. This paper presents the first comprehensive comparative study of API-based and GUI-based LLM agents, systematically analyzing their divergence and potential convergence. We examine key dimensions and highlight scenarios in which hybrid approaches can harness their complementary strengths. By proposing clear decision criteria and illustrating practical use cases, we aim to guide practitioners and researchers in selecting, combining, or transitioning between these paradigms. Ultimately, we indicate that continuing innovations in LLM-based automation are poised to blur the lines between API- and GUI-driven agents, paving the way for more flexible, adaptive solutions in a wide range of real-world applications."
        },
        {
            "title": "Start",
            "content": "API Agents vs. GUI Agents: Divergence and Convergence Chaoyun Zhang, Shilin He, Liqun Li, Si Qin, Yu Kang, Qingwei Lin and Dongmei Zhang Microsoft 5 2 0 2 4 1 ] A . [ 1 9 6 0 1 1 . 3 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have evolved beyond simple text generation to power software agents that directly translate natural language commands into tangible actions. While API-based LLM agents initially rose to prominence for their robust automation capabilities and seamless integration with programmatic endpoints, recent progress in multimodal LLM research has enabled GUI-based LLM agents that interact with graphical user interfaces in human-like manner. Although these two paradigms share the goal of enabling LLMdriven task automation, they diverge significantly in architectural complexity, development workflows, and user interaction models. This paper presents the first comprehensive comparative study of API-based and GUIbased LLM agents, systematically analyzing their divergence and potential convergence. We examine key dimensions and highlight scenarios in which hybrid approaches can harness their complementary strengths. By proposing clear decision criteria and illustrating practical use cases, we aim to guide practitioners and researchers in selecting, combining, or transitioning between these paradigms. Ultimately, we indicate that continuing innovations in LLMbased automation are poised to blur the lines between APIand GUI-driven agents, paving the way for more flexible, adaptive solutions in wide range of real-world applications."
        },
        {
            "title": "Introduction",
            "content": "The advent of large language models (LLMs) (Zhao et al., 2023) has ushered in new era of artificial intelligence, enabling advanced natural language understanding and generation across wide range of domains. While LLMs have long been recognized for their ability to produce coherent text, recent developments have led to LLM-based agents capable of mapping language inputs to real actions in digital environments (Wang et al., 2024a). By grounding 1 LLMs in tangible operations, these agents can interact with various software systems, execute commands, and have practical impact on the software ecosystems they inhabit. Initially, software LLM agents were predominantly Application Programming Interface (API)- centric, interacting with external tools, functions, or services through well-defined programmatic interfaces (Du et al., 2024). This approach allowed agents to orchestrate microservices, query search engines, or even control third-party applications via documented APIs, with automated and efficient manner. Products such as Microsofts Copilot exemplify how API-based LLM agents have become mainstream (Stratton, 2024), rapidly transitioning from research prototypes to widely adopted industrial solutions. The traction of these agents, both in academia and industry, underscores their capacity to streamline tasks through automation while maintaining robust scalability and interoperability. Concurrently, with multimodal capabilities gaining prominence in LLM research, new class of agents has emerged: Graphical User interfaces (GUIs)-based LLM agents (Zhang et al., 2024a). These agents interact not only through APIs but also by observing and manipulating graphical user interfaces of software, be they on desktop, mobile, or web applications. Projects such as UFO (Zhang et al., 2024b), CogAgent (Hong et al., 2024), and OpenAI Operator (OpenAI, 2025) illustrate how GUI-based agents can bring richer user experiences, improved accessibility, and provide more general automated control of software. By integrating vision or screen-based understanding with text-based reasoning, these agents push the boundaries of human-computer interaction, showcasing how AI can seamlessly blend with intuitive, visual workflows. Despite the promise of both paradigms, APIbased and GUI-based LLM agents exhibit significant differences in their architectures, development Figure 1: The difference between an API agent and GUI agent in completing the task Schedule 1-hour meeting on Google Calendar for LLM Agent at 4:00 PM on March 8. methodologies, and user interaction models (Zhang et al., 2024a). For example, as illustrated in Figure 1, an API-based agent scheduling Google Calendar meeting could make single call provided the proper endpoint and authentication, to instantly create the event. In contrast, GUI-based agent would open the web interface, navigate through the calendar visually, fill in relevant fields, and click buttons to finalize the meeting details. While the API-based approach tends to be faster and more resource-efficient, it depends on well-defined endpoints and reliable infrastructure. Conversely, GUIbased agents can interface with applications front end but typically require multiple user-like steps (mouse clicks, keyboard inputs), which can be slower and more error-prone (Song et al., 2024). These trade-offs underscore the fundamental divergence between APIand GUI-based agents and have sparked vigorous discussions regarding their relative merits, overlap, and even necessity. Although they may appear to compete, many believe that thorough examination of both differences and shared attributes is crucial. Indeed, no unified framework or comparative analysis has yet offered clear guidelines on when one approach might outperform the otheror if hybrid strategy could combine the strengths of both. To address this gap, this paper systematically examines both the divergence and potential convergence of API-based and GUI-based LLM agents in software automation. We begin by clarifying the conceptual foundations of each paradigm, followed by an in-depth comparative analysis across key dimensions. We then explore how ongoing innovations in LLM-based interactions are increasingly blurring the lines between API and GUI agents, and discuss hybrid approach that leverages their respective strengths while mitigating their shortcomings. By outlining clear decision criteria, we aim to guide practitioners and researchers in selecting the most suitable agent type based on project requirements, resource constraints, and user experience objectives. Ultimately, this work serves as comprehensive resource for academics and industry professionals, offering insights into how these agent types differ, where they converge, and how they may evolve to address emerging challenges."
        },
        {
            "title": "2 Background",
            "content": "LLM agents are designed to accept natural language requests from users and execute tasks in real or virtual environments. While they share the common goal of translating language into actionable commands, two distinct paradigms have emerged based on how these agents interact with their underlying systems: API-first and GUI-first LLM agents. Below, we provide an overview of each paradigm, highlighting their core principles and operational differences."
        },
        {
            "title": "2.1 API-Based LLM Agents",
            "content": "An API-first LLM agent can be defined as 2 Intelligent agents that operate within GUI environments, leveraging LLMs as their core inference and cognitive engine to generate, plan, and execute actions in flexible and adaptive manner. GUI-based agents primarily rely on visual or multimodal inputs, such as application screenshots and textual representations (e.g., accessibility trees or metadata). Instead of calling API endpoints, these agents navigate and manipulate on-screen elements using actions akin to human interactions, such as mouse clicks and keyboard inputs (Wang et al., 2024b), as shown in Figure 2. This human-like operational flow means that the agent must interpret visual layouts, locate relevant controls, and execute sequences of clicks, drags, or keypresses to accomplish tasks. The rapid evolution of multimodal LLM (Hong et al., 2024; Zheng et al., 2025) capabilities has sparked considerable interest in GUI-based agents, leading to range of prototypes, frameworks, and commercial products. Use cases include automated software testing, workflow automation, and accessibility enhancements. Ongoing research aims to address the inherent challenges of screen parsing, error handling, and robust action planning, areas where GUI-based LLM agents continue to evolve. Together with API-first LLM agents, this GUIbased paradigm forms complementary, but often contrasting approach to building intelligent systems that bridge natural language understanding and realworld task execution. As subsequent sections will illustrate, understanding both paradigms is crucial for selecting or designing an agent architecture suited to specific project goals and constraints."
        },
        {
            "title": "Agents",
            "content": "Although both API-based and GUI-based agents aim to automate tasks using natural language instructions, they diverge significantly in various perspectives. This section presents comparative analysis across several key dimensions: Modality, Reliability, Efficiency, Availability, Flexibility, Security, Transparency, Human-Like Interaction, and Maintainability. By examining these factors, we can better understand the foundational distinctions between the two paradigms and their impact on real-world applications. Figure 2: The difference between an API agent and GUI agent in input and output. Intelligent agents that leverage LLMs as their cognitive engine to invoke one or more predefined APIs in order to fulfill user requests automatically. In this paradigm, the agents capabilities are bounded by predefined set of tools, plugins, or function callscollectively referred to as APIs (Shen, 2024), as shown in Figure 2. This constrained set of functions not only ensures reliability and safety but also simplifies the agents decision space. Rather than generating full program code, the agent identifies which API to call for each step and populates the required parameters based on user intent. Relevant API information, such as function names, descriptions, parameters, and schemas, is included in the LLMs prompt. When user issues natural language request, the LLM agent interprets the intent and chooses the most suitable API to perform the task. This approach has been widely adopted in many state-of-the-art models and frameworks, including function-call modes in GPT4 (Hurst et al., 2024) and the plugin-only mode in TaskWeaver (Qiao et al., 2023)."
        },
        {
            "title": "2.2 GUI-Based LLM Agents",
            "content": "In contrast to the API-first paradigm, GUI-based LLM agents operate by interacting directly with GUIs rather than invoking predefined functions. As defined in (Zhang et al., 2024a), these agents can be described as: 3 Table 1: Comparison of API vs. GUI agents across key dimensions. Dimension Modality Reliability Efficiency Availability Flexibility Security Maintainability Transparency Human-Like Interaction API Agents Rely on text-based API calls Generally higher with well-defined endpoints Achieve complex tasks in single call Limited to published or pre-defined APIs Constrained by existing APIs Manageable via granular endpoint controls Stable if APIs remain versioned Often hidden, back-end driven Purely programmatic GUI Agents Depend on screenshots or accessibility trees Lower due to visual parsing and layout changes Require multiple user-like actions Can operate on any visible UI element Highly adaptable to new or unexposed features Riskier due to broad access to UI elements Prone to breakage on UI redesigns Step-by-step, visually traceable Simulates user actions on screen"
        },
        {
            "title": "3.1 Modality",
            "content": "The most evident difference lies in the way each agent perceives and interacts with software. API agents rely on textual specifications for each available endpoint. They interpret the users request, map it to the relevant function, and provide the necessary parameters for execution. By contrast, GUI agents process visual or multimodal inputs, such as screenshots or accessibility trees, and then navigate and manipulate user interface elements. Since GUI agents operate on actual interface controls, accurate visual grounding and interpretation become essential (Lu et al., 2024). While accessibility trees can offer some structured information, image-based comprehension remains central to the agents interaction in GUI environment."
        },
        {
            "title": "3.2 Efficiency",
            "content": "Efficiency covers both the time and computational resources required to complete task. API agents can generally handle complex tasks in single function call, minimizing latency and reducing the inference costs. In contrast, GUI agents frequently must perform series of user-like actionsopening menus, typing text, clicking buttonsto accomplish the same goal. Even routine operations, such as navigating through application panes, can require multiple steps. This user-level approach, while intuitive, can slow task execution and increase operational overhead compared to welldesigned API (Zhang et al., 2024a). If completing task takes significantly longer than it would for human, it can hinder adoption of GUI agents and limit their practical applicability."
        },
        {
            "title": "3.3 Reliability",
            "content": "Reliability often stems from the complexity of the underlying interaction model. API agents typically exhibit robust performance when they can access stable, well-defined endpoints. Such endpoints are easily maintained, versioned, and tested, leading to predictable outcomes. GUI agents, however, encounter challenges whenever application layouts or screen elements change unexpectedly. This is because GUIs are primarily designed for human interaction, often containing redundant elements and potential distractions that can disrupt automated workflows (McKay, 2013). These changes introduce uncertainties in the agents visual parsing and planning, making GUI-based approaches more prone to errors. In addition, the multi-step decision-making process of GUI agents can compound errors at each step, ultimately reducing overall accuracy. As result, GUI agents often require ongoing refinements and are still not as production-ready as their APIbased counterparts in many scenarios."
        },
        {
            "title": "3.4 Availability",
            "content": "Availability depends on how readily an agent can access the functionality necessary to fulfill users request. API agents are constrained by the endpoints or functions that developers have defined 4 and exposed. If desired feature is omitted, the agent cannot invoke it directly. This is particularly common in mobile applications, where developers often restrict external API access to maintain control over their private ecosystems. Conversely, GUI agents can interact with virtually any application that presents graphical user interface, without requiring explicit API definitions. The universality of GUI-based interaction can be an advantage in environments where no formal APIs exposed, but it also demands more sophisticated interpretation and error handling to manage diverse or evolving UIs. 3.5 Flexibility In addition to availability, flexibility denotes how easily the agent can adapt to new or modified use cases. API agents can call only the APIs that have been developed, documented, and integrated in advance. Expanding their functionality depends on creating and deploying additional endpoints. GUI agents, on the other hand, can theoretically operate on any visible element within an interface, thereby offering higher degree of freedom. This freedom, however, requires advanced computer-vision or multimodal reasoning capabilities to locate and interact with UI objects consistently."
        },
        {
            "title": "3.6 Security",
            "content": "Security plays crucial role in deciding which paradigm to adopt. API agents typically offer more granular protection, as each endpoint can be individually secured with authentication, access control, or rate limiting. GUI agents may inadvertently access parts of the interface that perform privileged or destructive operations, raising the risk of unintended consequences. Since graphical interfaces are designed primarily for human users, enforcing comprehensive security policies on automated, mouse-and-keyboard-like interactions can be challenging. As result, GUI-based agents may require additional safeguards to avoid unauthorized operations or misuse (Zhang et al., 2024b)."
        },
        {
            "title": "3.7 Maintainability",
            "content": "An other dimension relates to how easily the agents functionality can be maintained and updated over time. API agents benefit from versioned, standardized interfaces. As long as the underlying endpoints remain stable, the agent logic remains mostly intact. New APIs can be seamlessly integrated into the agent by simply adding their descriptions to the prompt, ensuring easy maintenance. By contrast, GUI agents are highly susceptible to interface redesigns, pop-up windows, layout shifts, and element renaming or relocation (Zhang et al., 2024c), all of which can break the automation if the GUI agent is unfamiliar with the change. This fragility can substantially increase the cost and frequency of maintenance, especially in applications subject to frequent UI updates. 3.8 Transparency From users perspective, transparency refers to the clarity of observing how the agent fulfills task. API agents often execute operations behind the scenes, providing limited visibility into the step-bystep process. Users typically see the final outcome without knowing which endpoints were invoked. In contrast, GUI agents replicate user-level interactions, making each click and text entry visible as it unfolds. Rather than operating invisibly in the background like API calls, GUI agents offer visible and interactive execution process, allowing users to observe, intervene, or adjust the workflow as needed. This design can be particularly beneficial in scenarios requiring step-by-step verification, training simulations, or automation of tasks where visual confirmation is necessary. This improves the interpretability of the workflow, allowing human observers to track and validate the agents progress more intuitively."
        },
        {
            "title": "3.9 Human-Like Interaction",
            "content": "Closely linked to transparency is the notion of simulating human behavior. API agents employ purely programmatic approach, executing function calls directly without mimicking user interactions. They are optimized for efficiency, reliability, and scalability, but they lack any visual or interactive representation of the task execution. In contrast, GUI agents replicate the exact steps human user would takenavigating through menus, filling in forms, and interacting with interface elements in natural, sequential manner. This human-like execution enhances interpretability, making it easier for users to follow and understand the agents actions, thereby fostering trust and more intuitive user experience. This introduces novel paradigm for human-computer interaction by bridging AI automation with user-centric workflows (Lin et al., 2025). 5 Figure 3: An example of API wapper over GUI workflow. 3.10 Summary In summary, these dimensions illustrate the fundamental ways in which API-based and GUI-based agents diverge in practice. API agents provide efficiency, security, and reliability when backed by robust endpoints, but they are bounded by the limited set of exposed functions. GUI agents offer broad applicability and user-like workflows, yet they must overcome challenges in visual parsing, interface changes, and slower task execution. As the complexity of software ecosystems grows, understanding these divergent properties is essential for selecting the most suitable approachor for designing hybrid solutions that combine the best attributes of both paradigms."
        },
        {
            "title": "Approach",
            "content": "Although API-based and GUI-based agents have traditionally been studied as separate paradigms, their conceptual foundations are not mutually exclusive. In practice, there are numerous scenarios where these approaches intersect or complement one another, leading to an emerging hybrid model. By drawing on the strengths of both API and GUI paradigms, this hybrid approach can achieve broader coverage of use cases, higher efficiency, and more human-like interaction style. While still in its early stages, the potential for these convergent solutions to reshape how agents operate is becoming increasingly evident."
        },
        {
            "title": "4.1 API Wrappers Over GUI Workflow",
            "content": "Some vendors transform GUI-based applications into quasi-API services by introducing headless mode or scripting interface that accepts function calls. This approach effectively abstracts GUI interactions into structured commands, allowing applications originally designed for human navigation to be automated in more programmatic and scalable manner. For example, specialized accounting ap6 Figure 4: An example of unified orchestrator to manage both API and GUI actions. plication may traditionally require users to navigate through multiple dialog boxes and menus to generate financial report. However, in headless or scripted version, the same application could expose function such as GenerateReport(startDate, endDate), enabling direct execution without requiring manual UI navigation. This is conceptually similar to Robotic Process Automation (RPA) bots (Wornow et al., 2024), which mimic user actions but can also be optimized for backend workflows. Although these wrappers still rely on GUI workflows under the hood, they present an API-like interface to developers, simplifying integration into broader automation pipelines. This transformation represents subtle yet impactful form of convergence: an application originally designed for direct GUI interactions is reinterpreted as an API service, reducing the need for dedicated GUI agent while retaining compatibility with existing software ecosystems. By bridging GUI automation with structured API-like interfaces, this approach enhances efficiency, scalability, and ease of integration, particularly in enterprise environments where legacy applications must be incorporated into modern automation frameworks."
        },
        {
            "title": "4.2 Unified Orchestration Tools",
            "content": "Enterprise-grade automation frameworks and process orchestration tools increasingly offer single, unified environment where developers or operators can build high-level workflows without delving into the underlying agent mechanisms. Consider, for example, large financial institution automating its loan approval process. Within an orchestration tool, user could design flowchart that checks customers credit score (using secure API endpoint), then updates Customer relationship management (CRM) system if the credit score meets certain threshold. If no relevant API exists for updating Table 2: Examples of convergence paths in hybrid agent systems. Approach API Wrappers Over GUI Tools Unified Orchestration Tools Low-Code / No-Code Solutions Key Benefit Provides quasi-API experience for GUI-only software Hides agent-type details from the user Simplifies design of advanced workflows Primary Challenge Still relies on underlying GUI elements that may change Complex logic to choose between API and GUI in real time May introduce hidden dependencies and abstractions the CRM, the platform can seamlessly switch to GUI-based agent that navigates through the CRMs web interface in user-like fashion. Thus, the tool automatically determines whether an API call or GUI interaction is most suitable for each task. We show such an example in Figure 4. By shielding users from these low-level decisions, orchestration platforms reduce complexity and streamline the development of sophisticated automation pipelines. UFO (Zhang et al., 2024b) exemplifies this design by providing an interface that allows each application to integrate its dedicated APIs, prioritizing their use whenever available. However, if no suitable API exists, the system seamlessly falls back on GUI-based interactions. This approach delegates decision-making to the unified LLM Orchestrator, which dynamically selects the most appropriate methodAPI or GUIbased on the task requirements and system capabilities."
        },
        {
            "title": "4.3 Low-Code / No-Code Solutions",
            "content": "Low-code and no-code platforms abstract many technical details behind visual interfaces, enabling non-experts (often referred to as citizen developers) to construct applications or automations through drag-and-drop components (Tang et al., 2025). As illustrated in Figure 5, each block in this order-processing workflow represents distinct task: the user drags Payment Gateway block into the designer to handle transactions, configures it visually,while behind the scenes an API agent automatically constructs and sends calls to the payment endpoint. It then connects to Shipping Service block for fulfillment. Behind the scenes, the platform typically issues API calls to the payment and shipping services, allowing the user to focus on the workflows logical sequence rather than on lower-level protocols. Conversely, if given step calls for GUI-based verificationfor instance, checking specific user interface element on legacy systemthe platform can seamlessly insert GUI agent, simulating human interactions with the software. This combination of API-based and GUI-driven actions makes it straightforward to build end-to-end automations, blending the speed and scalability of APIs with the accessible, visual nature of GUI-centric operations. 4.4 Summary These strategies illustrate how the once-distinct boundaries between API-based and GUI-based agents are gradually merging. The hybrid approach harnesses the flexibility and universality of GUI-driven interfaces alongside the reliability and performance of direct API calls. This convergence allows for more comprehensive automation, catering to diverse scenarios that range from rapid data processing to intricate user-interface validation, meeting varied requirements, whether efficiency, user-centric validation, or rapid development. Although further research and refinement are needed, these converging paradigms foreshadow future in which agent-based automation is both wide-ranging and intelligent, adapting seamlessly to the evolving complexities of modern software ecosystems."
        },
        {
            "title": "Considerations",
            "content": "While the preceding sections have contrasted APIand GUI-based LLM agents in terms of architecture, reliability, efficiency, and potential convergence, many practical deployments hinge on more fundamental question: which paradigm should be employed under various real-world conditions? This section provides guidance on selecting the most suitable strategy, discussing scenarios where one approach clearly outperforms the other, as well as circumstances in which hybrid model may offer the greatest flexibility. 7 Figure 5: One example of no-code platform to create workflows integrating both API calls and GUI agents. Table 3: Strategic criteria for selecting agent paradigms. wellScenario Stable, documented APIs Performance-critical operations Controlled access to applications Legacy or proprietary software Visual validation or UI testing Interactive or graphical manipulation Partial API coverage Recommended Approach API Agents API Agents API Agents"
        },
        {
            "title": "Hybrid",
            "content": "Future-proofing"
        },
        {
            "title": "Hybrid",
            "content": "Rationale Exploit robust endpoints for speed and reliability Reduce latency and overhead via direct function calls Ensure safety and security Automate tasks without requiring new backend integration Verify on-screen text or elements directly Seamlessly replicate human-like interactions with visual elements Combine UI-based steps where APIs are unavailable with direct calls for dataheavy tasks Facilitate switching from GUI to API as endpoints evolve"
        },
        {
            "title": "5.1 When to Favor API Agents",
            "content": "API-based agents tend to be the most compelling choice when well-defined programmatic interfaces exist. Official, stable APIs typically come with rigorous documentation and versioning, enabling strong error handling and consistent performance. In such an environment, developers can harness the inherent speed and reliability of API calls to execute tasks efficiently, thereby minimizing system overhead and latency. This approach is especially advisable when applications are designed for backend integrations, or when enterprise-level reliability is paramount for mission-critical workflows. By leveraging stable endpoints, API-based agents can also reduce long-term maintenance burdens, as changes in the system often entail versioned updates rather than complete interface overhauls. In addition, API agents provide controlled access to applications, restricting functionality to predefined and manageable scope. This is crucial consideration in agent-based systems, where safety and security are paramount. In such cases, API agents are ideal, as their actions are confined to constrained set of operations, ensuring predictable and secure interactions."
        },
        {
            "title": "5.2 When to Favor GUI Agents",
            "content": "GUI-based agents become particularly relevant in scenarios where no direct API exists, or the available APIs provide only partial coverage of the required automation tasks. This is especially evident in mobile applications, where each app operates as an isolated environment, restricting external API access. Furthermore, system-level operations on mobile devices often require root access, further limiting API usability and necessitating GUI-based automation as viable alternative."
        },
        {
            "title": "Another key advantage of GUI agents is their",
            "content": "8 ability to perform visual validation, which is essential in workflows that require confirming onscreen text, UI element positioning, or interface consistency before taking action. In such cases, GUI agent, which interacts with software much like human user, offers clear benefits over an APIbased approach. Similarly, legacy or proprietary systems that lack extensible backend services can leverage GUI-driven automation, allowing agents to navigate existing interfaces without requiring modifications to the underlying codebase or the development of new APIs. This makes GUI agents particularly valuable in enterprise environments where implementing and maintaining new API integrations would be impractical or cost-prohibitive. Moreover, GUI agents are inherently well-suited for applications that rely on interactive or graphical manipulation. Tasks such as creating animations, drawing in Photoshop, or interacting with complex design tools are best executed through direct visual interactions rather than API commands. In these cases, GUI-based automation closely mirrors the natural way humans interact with such applications, making it the preferred choice over an API-driven approach."
        },
        {
            "title": "5.3 When to Consider a Hybrid Approach",
            "content": "A hybrid strategy combines the strengths of both paradigms, providing unified workflow that can accommodate wide range of requirements. This approach is particularly advantageous when some aspects of the task map neatly onto existing APIs, while other components remain exclusively accessible through graphical interface. In such cases, using an API-based agent for data-intensive or programmatically streamlined operations preserves performance, while GUI agent handles specialized front-end interactions or visual validations. Moreover, adopting hybrid solution offers flexibility for future system evolution; as new APIs become available, tasks initially managed via the GUI can be seamlessly transitioned to API calls, avoiding major re-architectures."
        },
        {
            "title": "5.4 Summary",
            "content": "In summary, the strategic considerations for deploying API-based versus GUI-based agents depend on the nature of the target software, the level of integration or validation required, and long-term sustainability concerns. API agents excel when stable, documented endpoints exist, offering reliable and performant mode of automation. GUI agents are advantageous in contexts where interfaces are the only means of access or where visual confirmation is essential. Finally, hybrid approaches strike balance between these strengths, allowing organizations to adapt as their software ecosystems evolve. By taking these factors into account, decision-makers can ensure they select the agent paradigmAPI, GUI, or boththat best aligns with their specific requirements."
        },
        {
            "title": "6 Conclusion & Looking Forward",
            "content": "Automation in computing has long history, but the advent of LLM-based agents represents significant leap forward. These agents embody two core paradigms: one centered on well-defined programmatic interfaces (API agents) and one rooted in human-like interactions with graphical interfaces (GUI agents). By design, these paradigms differ in their operational principles, leading to divergence in architectural choices, performance profiles, and real-world applicability. However, they also exhibit complementary strengthsAPI agents excel at speed, security, and reliability, while GUI agents offer flexibility, broad applicability, and transparencymaking them poised for future of hybridization and convergence. Looking Ahead. The ongoing maturation of LLM technologies will likely reinforce both strands of agent development. On one hand, increasingly capable coding assistants promise to simplify the creation and maintenance of APIs, thereby enhancing the scalability of API agents. On the other hand, the rise of powerful multimodal models will expand the scope of GUI-based agents, enabling more robust visual understanding and sophisticated manipulation of GUIs. These trends point to an evolving ecosystem in which API-centric and GUI-centric approaches become increasingly interwoven. Looking forward, the seamless integration of these agent types may give rise to entirely new forms of softwaretools that automatically generate or refine APIs for efficient back-end operations and also dynamically orchestrate user-interface elements for transparent front-end interactions. This confluence of paradigms has the potential to transform human-computer interaction, blurring the boundaries between what is generated by code and what is experienced through visual interface. In the long term, it could reshape how we conceive of software development, user experience, and the broader workflows that underlie digital ecosystems. 9 Lu Wang, Fangkai Yang, Chaoyun Zhang, Junting Lu, Jiaxu Qian, Shilin He, Pu Zhao, Bo Qiao, Ray Huang, Si Qin, et al. 2024b. Large action models: From inception to implementation. arXiv preprint arXiv:2412.10047. Michael Wornow, Avanika Narayan, Krista OpsahlOng, Quinn McIntyre, Nigam Shah, and Christopher Re. 2024. Automating the enterprise with foundation models. Proceedings of the VLDB Endowment, 17(11):28052812. Chaoyun Zhang, Shilin He, Jiaxu Qian, Bowen Li, Liqun Li, Si Qin, Yu Kang, Minghua Ma, Qingwei Lin, Saravan Rajmohan, et al. 2024a. Large language model-brained gui agents: survey. arXiv preprint arXiv:2411.18279. Chaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin, Saravan Rajmohan, et al. 2024b. Ufo: uifocused agent for windows os interaction. arXiv preprint arXiv:2402.07939. Yanzhe Zhang, Tao Yu, and Diyi Yang. 2024c. Attacking vision-language computer agents via pop-ups. arXiv preprint arXiv:2411.02391. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. survey of large language models. arXiv preprint arXiv:2303.18223, 1(2). Jiani Zheng, Lu Wang, Fangkai Yang, Chaoyun Zhang, Lingrui Mei, Wenjie Yin, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, and Qi Zhang. 2025. Vem: Environment-free exploration for training gui agent with value environment model. arXiv preprint arXiv:2502.18906."
        },
        {
            "title": "References",
            "content": "Yu Du, Fangyun Wei, and Hongyang Zhang. 2024. Anytool: Self-reflective, hierarchical agents for largescale api calls. arXiv preprint arXiv:2402.04253. Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxiao Dong, Ming Ding, et al. 2024. Cogagent: visual language model for gui agents. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1428114290. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. 2024. Gpt-4o system card. arXiv preprint arXiv:2410.21276. Ziyue Lin, Siqi Shen, Zichen Cheng, Cheok Lam Lai, and Siming Chen. 2025. Carbon and silicon, coexist or compete? survey on human-ai interactions in agent-based modeling and simulation. arXiv preprint arXiv:2502.18145. Yadong Lu, Jianwei Yang, Yelong Shen, and Ahmed Awadallah. 2024. Omniparser for pure vision based gui agent. arXiv preprint arXiv:2408.00203. Everett McKay. 2013. UI is communication: How to design intuitive, user centered interfaces by focusing on effective communication. Newnes. OpenAI. 2025. Operator system card. Released on January 23, 2025. Bo Qiao, Liqun Li, Xu Zhang, Shilin He, Yu Kang, Chaoyun Zhang, Fangkai Yang, Hang Dong, Jue Taskweaver: Zhang, Lu Wang, et al. 2023. arXiv preprint code-first agent framework. arXiv:2311.17541. Zhuocheng Shen. 2024. Llm with tools: survey. arXiv preprint arXiv:2409.18807. Yueqi Song, Frank Xu, Shuyan Zhou, and Graham Neubig. 2024. Beyond browsing: Api-based web agents. Jess Stratton. 2024. An introduction to microsoft copilot. In Copilot for Microsoft 365: Harness the Power of Generative AI in the Microsoft Apps You Use Every Day, pages 1935. Springer. Jiabin Tang, Tianyu Fan, and Chao Huang. 2025. Metachain: fully-automated and zero-code arXiv preprint framework for arXiv:2502.05957. llm agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2024a. survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):186345."
        }
    ],
    "affiliations": [
        "Microsoft"
    ]
}