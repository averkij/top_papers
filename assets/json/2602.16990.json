{
    "paper_title": "Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation",
    "authors": [
        "Yan Wang",
        "Yi Han",
        "Lingfei Qian",
        "Yueru He",
        "Xueqing Peng",
        "Dongji Feng",
        "Zhuohan Xie",
        "Vincent Jim Zhang",
        "Rosie Guo",
        "Fengran Mo",
        "Jimin Huang",
        "Yankai Chen",
        "Xue Liu",
        "Jian-Yun Nie"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Most recommendation benchmarks evaluate how well a model imitates user behavior. In financial advisory, however, observed actions can be noisy or short-sighted under market volatility and may conflict with a user's long-term goals. Treating what users chose as the sole ground truth, therefore, conflates behavioral imitation with decision quality. We introduce Conv-FinRe, a conversational and longitudinal benchmark for stock recommendation that evaluates LLMs beyond behavior matching. Given an onboarding interview, step-wise market context, and advisory dialogues, models must generate rankings over a fixed investment horizon. Crucially, Conv-FinRe provides multi-view references that distinguish descriptive behavior from normative utility grounded in investor-specific risk preferences, enabling diagnosis of whether an LLM follows rational analysis, mimics user noise, or is driven by market momentum. We build the benchmark from real market data and human decision trajectories, instantiate controlled advisory conversations, and evaluate a suite of state-of-the-art LLMs. Results reveal a persistent tension between rational decision quality and behavioral alignment: models that perform well on utility-based ranking often fail to match user choices, whereas behaviorally aligned models can overfit short-term noise. The dataset is publicly released on Hugging Face, and the codebase is available on GitHub."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 9 1 ] . [ 1 0 9 9 6 1 . 2 0 6 2 : r Conv-FinRe: Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation Yan Wang The Fin AI USA wy2266336@gmail.com"
        },
        {
            "title": "Jimin Huang\nThe Fin AI\nUSA",
            "content": "Yankai Chen McGill University MBZUAI Canada yankaichan3@gmail.com Xue (Steve) Liu McGill University MBZUAI Canada Jian-Yun Nie University of Montreal Canada"
        },
        {
            "title": "Abstract",
            "content": "Most recommendation benchmarks evaluate how well model imitates user behavior. In financial advisory, however, observed actions can be noisy or short-sighted under market volatility and may conflict with users long-term goals. Treating what users chose as the sole ground truth, therefore, conflates behavioral imitation with decision quality. We introduce Conv-FinRe, conversational and longitudinal benchmark for stock recommendation that evaluates LLMs beyond behavior matching. Given an onboarding interview, step-wise market context, and advisory dialogues, models must generate rankings over fixed investment horizon. Crucially, ConvFinRe provides multi-view references that distinguish descriptive behavior from normative utility grounded in investor-specific risk preferences, enabling diagnosis of whether an LLM follows rational analysis, mimics user noise, or is driven by market momentum. We build the benchmark from real market data and human decision trajectories, instantiate controlled advisory conversations, and evaluate suite of state-of-the-art LLMs. Results reveal persistent tension between rational decision quality and behavioral alignment: models that perform well on utility-based ranking often fail to match user choices, whereas behaviorally aligned models can overfit short-term noise. The dataset is publicly released on Hugging Face1, and the codebase is available on GitHub2. 1https://huggingface.co/collections/TheFinAI/conv-finre 2https://github.com/The-FinAI/Conv-FinRe Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference acronym XX, Woodstock, NY 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/2018/06 https://doi.org/XXXXXXX.XXXXXXX CCS Concepts Information systems Recommender systems; Similarity measures; Language models; Human-centered computing User centered design; Computing methodologies Natural language processing."
        },
        {
            "title": "Keywords",
            "content": "Personality Stock Recommendation, Conversational Benchmark, Utility Function, Rerank, Large Language Models ACM Reference Format: Yan Wang, Yi Han, Lingfei Qian, Yueru He, Xueqing Peng, Dongji Feng, Zhuohan Xie, Vincent Jim Zhang, Rosie Guo, Fengran Mo, Jimin Huang, Yankai Chen, Xue (Steve) Liu, and Jian-Yun Nie. 2018. Conv-FinRe: Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation. In Proceedings of Make sure to enter the correct conference title from your rights confirmation email (Conference acronym XX). ACM, New York, NY, USA, 7 pages. https://doi.org/XXXXXXX.XXXXXXX"
        },
        {
            "title": "1 Introduction",
            "content": "Large language models (LLMs) have achieved remarkable progress across diverse application domains, demonstrating strong performance in language understanding [24, 43], reasoning [25, 44], and structured problem-solving [39, 40]. These capabilities have motivated their adoption as assistants for decision-making and recommendation tasks [7, 9, 15, 18, 19]. In most recommendation benchmarks, personalization is primarily measured by behavioral imitation: recommendation is deemed correct if it matches what user would click, rate, or choose [6, 14, 16, 28]. This behavior-centric paradigm is effective in many consumer domains, where feedback is reliable proxy for utility. Financial recommendation is different. Investor actions are often affected by short-term market noise, emotions, and shifting constraints, and may deviate from stable risk tolerance or long-term objectives [1, 22]. As result, matching historical choices alone cannot tell whether an advisor is providing good financial guidance. faithful mimic of noisy actions may be misaligned with the users Conference acronym XX, June 0305, 2018, Woodstock, NY Yan et al. representative user-centric Table 1: Comparison of recommendation benchmarks. Dynamic indicates timeconditioned signals; Utility refers to relevance grounded in user-dependent decision utility; Multi-view indicates multiple, potentially conflicting ranking views; Dialogue denotes conversational interactive setting. Work Domain Dynamic Utility Multi-view Dialogue REASONER [6] FairEval [28] PerFairX [27] CEREAL [14] LLM-REDIAL [16] RecBench [18] FAR-Trans [29] Ours Video Music Movie&Music Movie Movie General Finance Finance (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:34) (cid:34) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:34) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:34) (cid:37) (cid:37) (cid:37) (cid:34) (cid:34) (cid:37) (cid:37) (cid:34) underlying goals, while purely rational advisor may ignore user intent and preferences. Existing benchmarks, as summarized in Table 1, therefore struggle with three issues: behavior-as-truth, utility blindness, and singleview evaluation. Most user-centric benchmarks rely on relevance signals (clicks/ratings) [6, 18] without utility grounding, while finance datasets often emphasize prediction or trading objectives rather than user-specific decision quality [29]. Consequently, they cannot diagnose whether an LLM advisor is reasoning about risksensitive utility, blindly chasing market trends, or simply overfitting user noise. To address this gap, we introduce Conv-FinRe, the first conversational and longitudinal benchmark that formulates financial recommendation as multi-view alignment problem. Rather than evaluating whether an LLM simply matches user choices, the benchmark assesses model rankings against four complementary reference views, such as user choice (ğ‘¦ğ‘¢ğ‘ ğ‘’ğ‘Ÿ ), rational utility (ğ‘¦ğ‘¢ğ‘¡ğ‘–ğ‘™ ), market momentum (ğ‘¦ğ‘šğ‘œğ‘š), and risk sensitivity (ğ‘¦ğ‘ ğ‘ğ‘“ ğ‘’ ), enabling diagnosis of whether model relies on rational analysis, behavioral imitation, or short-term market signals. To support such evaluation, userspecific risk preferences are inferred from longitudinal decision trajectories via inverse optimization and used to construct utilityand risk-based reference rankings, without exposing the latent utility function to the model. Operationally, Conv-FinRe instantiates the task through onboarding interviews and step-wise advisory dialogues, where an LLM must reconcile competing advisory principles over time. We evaluate diverse set of state-of-the-art LLMs under ConvFinRe and reveal fundamental tension between rational decision quality and behavioral alignment. While some models achieve strong utility-based rankings, they often conflate long-term risk with short-term market momentum; conversely, domain-specialized models tend to overfit noisy user actions, mistaking transient behavior for stable preferences. Together, these results motivate ConvFinRe as benchmark for multi-view, utility-grounded evaluation. We make the following contributions: (1) We introduce ConvFinRe, conversational and longitudinal benchmark for stock recommendation that evaluates LLMs beyond behavioral imitation by grounding assessment in investor-specific utility. (2) We formulate financial recommendation evaluation as multi-view alignment problem and provide diagnostic framework, supported by inverse optimization, that disentangles behavioral alignment from rational decision quality. (3) We conduct systematic evaluation of stateof-the-art LLMs under Conv-FinRe, identifying distinct advisory behavior patterns under competing market signals and user noise."
        },
        {
            "title": "2 Related Works",
            "content": "Personalized recommendation benchmarks are well studied in consumer domains such as e-commerce and media, where personalization is typically modeled from interaction histories or coarse user traits and supervision relies on single relevance signal like ratings or clicks [6, 42]. Recent work enriches this setting by introducing structured explanations [6] and by evaluating LLMs either as representation enhancers or as end-to-end recommenders under point-wise, pair-wise, or list-wise protocols [7, 9, 18, 19], with further analysis of fairness, bias, and sequential alignment [17, 28]. In contrast, personalized stock recommendation poses additional challenges due to non-stationary assets and investor objectives constrained by risk tolerance and returnrisk trade-offs [29, 34], with evidence that risk preferences evolve and must be inferred from behavior rather than static profiles [5]. While conversational and LLM-based financial advisors enable iterative preference elicitation [10, 23, 30, 33, 35, 36], existing benchmarks rarely evaluate recommendation quality using investor-specific utility as the core supervision signal, limiting their ability to assess true decision alignment."
        },
        {
            "title": "3 Conv-FinRe",
            "content": "Figure 1 illustrates the overall pipeline of Conv-FinRe, from data collection and user profiling to multi-view conversation simulation and evaluation. The framework models longitudinal advisory interactions by integrating market signals, inferred user preferences, and competing expert recommendations, enabling fine-grained analysis of LLM alignment in personalized financial decision-making. Figure 1: Overview of Conv-FinRe benchmark."
        },
        {
            "title": "3.1 Task Formulation\nWe define the Multi-view Longitudinal Stock Recommenda-\ntion task, which simulates iterative interactions between a per-\nsonalized investment advisor and a user over a fixed investment",
            "content": "Conv-FinRe: Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY horizon ğ‘‡ . Unlike conventional recommendation benchmarks that rely on single \"gold-standard\" label, our task evaluates LLM alignment across four complementary reference views: User Choice (ğ‘¦ğ‘¢ğ‘ ğ‘’ğ‘Ÿ ), representing the empirical selections made by the human participant; Rational Utility (ğ‘¦ğ‘¢ğ‘¡ğ‘–ğ‘™ ), an idealized ranking derived from calibrated utility function that represents the theoretically optimal balance between return and risk; Market Momentum (ğ‘¦ğ‘šğ‘œğ‘š), profit-oriented ranking based purely on recent cumulative returns; and Risk Sensitivity (ğ‘¦ğ‘ ğ‘ğ‘“ ğ‘’ ), conservative ranking that isolates the users specific risk-avoidance component by penalizing volatility and downside risk according to their inferred sensitivity. In this setting, the LLM acts as Personalized Investment Advisor whose objective is not explicitly specified. Instead, the model must infer the users latent financial preferences over time and reconcile conflicting advisory principles. At each decision step, the model is presented with the current market context, historical interaction trajectory, and recommendations from panel of three specialized advisors grounded in ğ‘¦ğ‘¢ğ‘¡ğ‘–ğ‘™ , ğ‘¦ğ‘šğ‘œğ‘š, and ğ‘¦ğ‘ ğ‘ğ‘“ ğ‘’ . The core challenge for the LLM is to synthesize these heterogeneous signals to produce final ranking that reflects its inferred understanding of the users underlying financial objectives. This multi-view design enables us to diagnose whether an LLMs misalignment with actual user behavior stems from an over-reliance on market momentum or miscalculation of the users specific risk thresholds. Formally, for the user ğ‘– at step ğ‘¡, given candidate stock set Sğ‘¡ ğ‘¡ , the recommendation process is defined as: and decision context Iğ‘– ğœ‹ğ‘–,ğ‘¡ = ğ‘“ğœƒ (Iğ‘– ğ‘¡ , Sğ‘¡ ), (1) where ğ‘“ğœƒ denotes the evaluated LLM-based advisor, ğœ‹ğ‘–,ğ‘¡ is the reranked list from the Sğ‘¡ . Specifically, the decision context Iğ‘– ğ‘¡ is shown below: ğ‘¡ = (cid:0)ğ‘ƒğ‘–, ğ‘– Iğ‘– , Mğ‘¡ (cid:1) , 1:ğ‘¡ (2) where ğ‘ƒğ‘– denotes the onboarding dialogue, multi-turn introductory interaction used to elicit the user ğ‘–s background, financial goals, and initial risk tolerance. Mğ‘¡ = {vğ‘ ,ğ‘¡ , xğ‘ ,ğ‘¡ }ğ‘  Sğ‘¡ represents the current market state. Here, vğ‘ ,ğ‘¡ = (ğœ‡ğ‘ , ğœ 2 ğ‘  , Drawdownğ‘  ) denotes the vector of raw performance metrics used for preference grounding, while xğ‘ ,ğ‘¡ comprises the verbalized market signals (e.g., price trends, percentage returns, and volatility) presented to the LLM advisor. The term ğ‘– 1:ğ‘¡ 1 encapsulates the longitudinal interaction trajectory, consisting of multi-turn dialogues between the user and the three specialized advisors (Rational Utility, Market Momentum, and Risk Sensitivity). This history provides the model with both the users previous decision patterns and the conflicting advisory signals previously encountered."
        },
        {
            "title": "Optimization",
            "content": "The task itself does not assume access to the users true utility function. Instead, to enable principled analysis of advisory behaviors, we construct latent preference signal that serves as reference representation of each users underlying risk attitude. This preference signal is used to characterize advisory objectives within the benchmark, rather than being exposed to the model. We assume that user ğ‘–s decision-making process is governed , which balances expected return by latent utility function ğ‘ˆ (ğ‘  ) ğ‘–,ğ‘¡ against volatility and downside risk [20, 26, 38]. For user ğ‘– and stock ğ‘  Sğ‘¡ at step ğ‘¡, the utility is defined as: ğ‘ˆ (ğ‘  ) ğ‘–,ğ‘¡ = ğœ‡ğ‘ ,ğ‘¡ ğœ†ğ‘– ğœ 2 ğ‘ ,ğ‘¡ ğ›¾ğ‘– Drawdownğ‘ ,ğ‘¡ , (3) ğ‘ ,ğ‘¡ , and where ğœ‡ğ‘ ,ğ‘¡ , ğœ 2 Drawdownğ‘ ,ğ‘¡ denote the cross-sectionally standardized mean return, variance, and maximum drawdown of stock ğ‘  over 7-day window preceding step ğ‘¡. (ğœ†ğ‘–, ğ›¾ğ‘– ) are the user-specific parameters, which are assumed to be time-invariant and capture the users sensitivity to volatility and downside risk. We estimate (ğœ†ğ‘–, ğ›¾ğ‘– ) via Inverse Optimization [3, 4] using the users longitudinal behavioral trajectory ğ» ğ‘– 1:ğ‘‡ . Assuming rational choice model with Gumbel-distributed noise, the probability that user ğ‘– selects stock ğ‘  at step ğ‘¡ follows Multinomial Logit model [32]: ğ‘ƒ (ğ‘  ğœ†ğ‘–, ğ›¾ğ‘–, Mğ‘¡ ) = exp (cid:17) (cid:16) ğ‘ˆ (ğ‘  ) ğ‘–,ğ‘¡ (cid:16) ğ‘ˆ (ğ‘  ) ğ‘–,ğ‘¡ (cid:205)ğ‘  Sğ‘¡ exp , (cid:17) (4) The global parameters are obtained by minimizing the Regularized Negative Log-Likelihood [2, 21] over the interaction horizon: Lğ‘– (ğœ†ğ‘–, ğ›¾ğ‘– ) = ğ‘‡ ğ‘¡ = log ğ‘ƒ (cid:0)ğ‘  ğ‘–,ğ‘¡ ğœ†ğ‘–, ğ›¾ğ‘–, Mğ‘¡ (cid:1) + ğ›¼ (ğœ†ğ‘–, ğ›¾ğ‘– )2 2 , (ğœ†ğ‘–, ğ›¾ğ‘– ) = arg min ğœ†ğ‘– ,ğ›¾ğ‘– Lğ‘– . (5) (6) ğ‘–,ğ‘¡ is the stock actually chosen by user ğ‘– at step ğ‘¡, and ğ›¼ where ğ‘  controls the strength of regularization. Once (ğœ†ğ‘–, ğ›¾ğ‘– ) are estimated, we construct the reference views for evaluation. Specifically, the Rational Utility view (ğ‘¦ğ‘¢ğ‘¡ğ‘–ğ‘™ ) is ranked by the full utility ğ‘ˆ (ğ‘  ) , while the Risk Sensitivity view ğ‘–,ğ‘¡ (ğ‘¦ğ‘ ğ‘ğ‘“ ğ‘’ ) is ranked by the personalized risk penalty term: ğ‘… (ğ‘  ) ğ‘–,ğ‘¡ = ğœ†ğ‘– ğœ 2 Drawdownğ‘ ,ğ‘¡ . ğ‘ ,ğ‘¡ + ğ›¾ğ‘–"
        },
        {
            "title": "Simulation",
            "content": "3.3.1 Data Collection. Market Data. We construct compact stock universe from S&P 500 constituents using stratified sampling to ensure coverage of all eleven GICS sectors and balanced exposure to systematic risk. Candidate stocks are grouped by market beta, computed from five-year monthly returns, into low (ğ›½ < 1), moderate (ğ›½ 1), and high (ğ›½ > 1) risk regimes, with approximately equal representation from each group. The resulting universe comprises ten representative stocks  (Table 2)  , enabling controlled longitudinal evaluation. For each stock, we collect daily and intraday price data over 30-day horizon (Aug. 6Sep. 17, 2025) via the Yahoo Finance API3, which defines the market state in the simulation environment. 3https://pypi.org/project/yfinance/ Conference acronym XX, June 0305, 2018, Woodstock, NY Yan et al. Table 2: Summary of the stock universe used in Conv-FinRe. Stocks are grouped by volatility tier based on market beta to ensure balanced exposure to systematic risk. GICS Sector Beta Market Cap Procter & Gamble Merck & Co., Inc. Verizon Communications Inc. Communication Services Consumer Staples Health Care Ticker Company Low Volatility (ğ›½ < 1) PG MRK VZ Moderate Volatility (ğ›½ 1) Linde plc LIN XOM Exxon Mobil Corporation High Volatility (ğ›½ > 1) JPM AMZN Amazon.com, Inc. MMM 3M Company SPG TSLA Simon Property Group, Inc. Tesla, Inc. JPMorgan Chase & Co. 0.36 0.38 0.36 0.95 0.55 1.13 1.31 1.10 1.53 2.07 $353B $274B $188B $213B $596B $841B $2.6T $81B $62B $1.4T Materials Energy Financials Information Technology Industrials Real Estate Consumer Discretionary User Interaction Data. User interaction data are collected through two-stage protocol. First, we obtain static user profiles from 10 participants via structured questionnaire4 capturing investor demographics, financial capacity, investment experience, and risk attitudes. The questionnaire design follows regulatory suitability guidelines (MiFID II Article 255; FINRA Rule 21116) and is informed by Betterments approach7 on investor risk preferences and financial decision-making; and industry examples, such as JPMorgan Financial Health Check8, Charles Schwab Investor Risk Profile9, Vanguard Investor Financial Profile10, and Financial Group Plan11. Second, we collect longitudinal decision trajectories using custom asset simulation tool. Participants interact with fixed universe of ten stocks over 30-day horizon, observing daily and intraday price movements. At each step, users make incremental buy decisions and receive portfolio-level feedback, including realized returns and volatility, which is logged together with their actions to form temporally ordered interaction trace. The simulation tool is publicly released for reproducibility12. 3.3.2 Conversation Simulation. Conversation Generation. Building on the collected user interaction data, we construct structured conversation simulation to instantiate the proposed longitudinal advisory task in languagebased setting. Rather than collecting free-form dialogues from participants, we transform each users observed profile and behavioral trajectory into coherent multi-turn advisory conversation, enabling controlled and reproducible evaluation of LLMs. Each user trajectory is organized into two phases: an onboarding interview and longitudinal advisory dialogue over fixed horizon ğ‘‡ . The onboarding phase verbalizes the static user profile obtained from the questionnaire. Using the users survey responses as grounding signals, we generate four-turn advisoruser dialogue that captures the users financial background, constraints, investment 4https://forms.gle/g7GnwqByq7mCoJgTA 5https://eur-lex.europa.eu/eli/dir/2014/65/oj/ 6https://www.finra.org/rules-guidance/rulebooks/finra-rules/2111 7https://d-nb.info/116404222X 8https://am.jpmorgan.com/content/dam/jpm-am-aem/asiapacific/hk/en/literature/ account-forms/healthcheck_corporate.pdf 9https://www.studocu.vn/vn/document/royal-melbourne-institute-of-technologyvietnam/international-trade/charles-schwab-investor-risk-profile/100562992 10https://sustainableinvest.com/wp-content/uploads/Investor-Financial-ProfileQuestionnaire.pdf 11https://financialgroup.com/risk-profile-bq 12https://huggingface.co/spaces/TheFinAI/LetYourProfitsRun Table 3: Structural statistics of Conv-FinRe benchmark. Token counts are computed using the cl100k_base tokenizer. Scale Users Steps / User Total Instances Dialogue Min Turns / Instance Max Turns / Instance Avg Turns / Instance 10 23 230 4 26 15 Turn Accounting Unique Turns Prefix-Expanded Turns Token Status 270 Min Tokens / Instance 3,450 Max Tokens / Instance Avg Tokens / Instance 1,818 7,252 4,320.2 goals, and emotional reactions to risk. The generated language is constrained to match the users reported financial literacy, ensuring that preference signals are conveyed implicitly through natural expression rather than explicit financial terminology. This onboarding dialogue serves as the conversational realization of ğ‘ƒğ‘– in the decision context Iğ‘– ğ‘¡ . Following onboarding, the longitudinal advisory phase reflects the users sequential decision-making behavior observed in the asset simulation. At each step ğ‘¡, the conversation conditions on the historical interaction trajectory ğ‘– 1:ğ‘¡ 1 and the current market state Mğ‘¡ , represented by 7-day market snapshot derived from the simulation environment. panel of three specialized advisors provides recommendations based on the heterogeneous principles defined in our multi-view framework: Rational-Utility, MarketMomentum, and Risk-Sensitivity strategies. The user then finalizes choice, potentially deviating from advisor suggestions and providing subjective justification consistent with their observed behavior in the simulation. All advisor messages and user responses are appended to the conversation history, yielding temporally ordered dialogue aligned with the underlying interaction trace. Overall, as shown in Table 3, the benchmark contains 10 users and 230 prefix-conditioned instances. Dialogue context grows from 4 to 26 turns (15 on average), yielding 270 unique turns that expand to 3,450 prefix-conditioned turns. Each instance contains 1,8187,252 tokens (4,320.2 on average), highlighting the substantial longitudinal context complexity required for evaluation. Conversation Quality Validation. We validate the quality of the simulated conversations from both preference-grounding and conversational realism perspective. User Preference Consistency Validation: For each user ğ‘–, the inferred latent parameters (ğœ†ğ‘–, ğ›¾ğ‘– ) represent the users sensitivity to volatility and downside risk. To assess whether these parameters meaningfully capture the users true investment psychology, financial experts translate each parameter pair into concise naturallanguage summary of the users risk tolerance. Users are then asked to rate, on 09 Likert scale (0 = not at all accurate, 9 = perfectly accurate), how well the summary reflects their own reasoning and emotions when making stock selection decisions. Across users, the summaries receive high average agreement score of 7.8, with low inter-user variance, indicating that the inferred preferences are largely consistent with users decision-making behavior. Conversational Plausibility Validation: We further assess the realism of the simulated advisory dialogues. To avoid over-counting highly correlated interactions within the same user trajectory, we adopt user-level sampling strategy. Specifically, for each of the 10 users, we randomly sample one decision step from the 23-step Conv-FinRe: Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY longitudinal conversation, resulting in 10 representative dialogue instances. Each sampled conversation is independently evaluated by three domain experts with backgrounds in finance and conversational systems. Experts rate each dialogue on 09 Likert scale along four dimensions: role consistency, linguistic naturalness, behavioral plausibility of user responses, and cross-turn coherence. The final plausibility score for each conversation is computed as the average across the four dimensions and across experts. Overall, the simulated dialogues achieve mean plausibility score of 8.1, indicating that the generated conversations closely resemble realistic financial advisory interactions rather than scripted or artificial exchanges."
        },
        {
            "title": "3.4 Evaluation Metrics\nUtility-based NDCG (uNDCG): We first evaluate whether model-\ngenerated rankings align with the userâ€™s latent, utility-grounded\npreference structure. For user ğ‘– at step ğ‘¡, we compute uNDCG using\nthe calibrated utility ğ‘ˆ (ğ‘  )\nğ‘–,ğ‘¡ as relevance. Given a ranking ğœ‹ğ‘–,ğ‘¡ over\ncandidate set Sğ‘¡ , the discounted cumulative gain is:",
            "content": "DCGğ‘–,ğ‘¡ = Sğ‘¡ ğ‘˜=1 ğ‘ˆ (ğœ‹ğ‘–,ğ‘¡ [ğ‘˜ ] ) ğ‘–,ğ‘¡ log2 (ğ‘˜ + 1) , and the utility-based NDCG is defined as: DCGğ‘–,ğ‘¡ IDCGğ‘–,ğ‘¡ uNDCGğ‘–,ğ‘¡ = , (7) (8) where IDCGğ‘–,ğ‘¡ is computed from the utility-optimal ranking. MRR and Hit Rate: To assess recovery of the users observed choice, let ğ‘  ğ‘–,ğ‘¡ denote the stock selected by user ğ‘– at step ğ‘¡, and let ğœ‹ğ‘–,ğ‘¡ (ğ‘  ğ‘–,ğ‘¡ ) be its position in ğœ‹ğ‘–,ğ‘¡ . The reciprocal rank is RRğ‘–,ğ‘¡ = 1 ğœ‹ğ‘–,ğ‘¡ (ğ‘  ğ‘–,ğ‘¡ ) , (9) ğ‘–,ğ‘¡ ) ğ¾ (cid:3) , with Mean Reciprocal Rank (MRR) obtained by averaging across users and steps. We additionally report Hit Rate at top-ğ¾: HR@ğ¾ğ‘–,ğ‘¡ = I(cid:2)ğœ‹ğ‘–,ğ‘¡ (ğ‘  (10) and focus on ğ¾ {1, 3}, where I[] denotes the indicator function. Expert Alignment Score (EAS): To analyze how models resolve competing advisory principles, we measure alignment with three expert rankings: Rational Utility, Market Momentum, and Risk Sensitivity. For model ğ‘š, we compute step-wise alignment using Kendalls ğœ: ğ‘–,ğ‘¡ (ğ‘š) = ğœ (cid:0)ğœ‹ğ‘š (11) where ğ‘’ denotes the expert type. Final scores are obtained by averaging over all users and steps: ğ‘–,ğ‘¡, ğœ‹ğ‘’ ğ‘–,ğ‘¡ EAS(ğ‘’ ) (cid:1) , (ğ‘’ ) (ğ‘š) = EAS 1 ğ‘ğ‘‡ ğ‘ ğ‘‡ ğ‘–=1 ğ‘¡ =1 EAS(ğ‘’ ) ğ‘–,ğ‘¡ (ğ‘š). (12)"
        },
        {
            "title": "3.5 Evaluation Models",
            "content": "Our goal is to assess the capabilities and limitations of contemporary LLMs in conversational, personality-grounded longitudinal stock recommendation under the Conv-FinRe benchmark. To this end, we evaluate diverse set of state-of-the-art LLMs, covering both proprietary and open-source families. Specifically, we include two closedsource general-purpose models, GPT-5.2 [31] and GPT-4o [13]. Table 4: Overall performance on the longitudinal stock advisory task. The Random baseline is computed by averaging over 1,000 uniform random permutations per instance, serving as sanity-check lower bound. Model Random GPT-5.2 GPT-4o DeepSeek-V3.2 Qwen3-235B-A22B-Instruct Qwen2.5-72B-Instruct Llama-3.3-70B-Instruct Llama3-XuanYuan3-70B-Chat uNDCG 0.73 0.00 0.94 0.03 0.94 0.00 0.92 0.00 0.94 0.00 0.92 0.01 0.97 0.00 0.92 0.00 MRR 0.29 0.01 0.46 0.02 0.56 0.03 0.51 0.03 0.47 0.02 0.63 0.03 0.52 0.03 0.65 0.03 HR@1 0.10 0.01 0.29 0.03 0.42 0.03 0.37 0.03 0.30 0.03 0.50 0.03 0.36 0.03 0.54 0. HR@3 0.30 0.01 0.51 0.03 0.60 0.03 0.55 0.03 0.52 0.03 0.69 0.03 0.59 0.03 0.69 0.01 We further evaluate range of open-source general models with strong reasoning and instruction-following capabilities, including DeepSeek-V3.2 [8], Qwen3-235B-A22B-Instruct [37], Qwen2.572B-Instruct [41], and Llama-3.3-70B-Instruct [12], and one financial domain conversational model: Llama3-XuanYuan3-70BChat13. All models are evaluated using the LM Evaluation Harness [11] under unified interface. Proprietary models are accessed via official APIs, while open-source models are executed locally. Across all experiments, we standardize the maximum input context length to 8,192 tokens and constrain the maximum generation length to 126 tokens, ensuring fair and consistent comparison across models."
        },
        {
            "title": "4 Experiments and Results\n4.1 Overall Performance",
            "content": "Table 4 shows that most models achieve high uNDCG scores (0.920.97), indicating strong baseline for ranking assets according to the Rational Utility. However, high uNDCG does not always translate into better recovery of the User Choice. While Llama-3.3-70B-Instruct leads in uNDCG (0.97), it shows lower Hit Rates, suggesting it prioritizes an \"idealized\" rational recommendation that balances long-term risk and return. In contrast, Qwen2.5-72B-Instruct and Llama3-XuanYuan3-70BChat excel in MRR and HR@K, indicating they are more effective at mimicking the users realized, and often noisy, decision-making patterns. This gap reveals fundamental trade-off: ğ‘¦ğ‘¢ğ‘¡ğ‘–ğ‘™ acts as financially robust reference to align with the users latent psychology, whereas ğ‘¦ğ‘¢ğ‘ ğ‘’ğ‘Ÿ captures the empirical behavior which may deviate from pure rationality. The results suggest that models must navigate the tension between providing the most rational advice and maintaining empathetic behavioral alignment."
        },
        {
            "title": "4.2 Expert Alignment Analysis",
            "content": "Table 5 reveals how models resolve competing advisory principles. prominent trend is the strong coupling between Rational Utility and Market Momentum alignment, which stems from the contextual collinearity of these signals during trending markets where high-momentum assets often dominate utility calculations. Llama3.3-70B-Instruct exemplifies this trend by achieving the highest alignment with both Utility and Momentum, yet its sharp decline in Risk alignment proves that it struggles to decouple downside protection from growth-oriented signals. 13https://huggingface.co/Duxiaoman-DI/Llama3-XuanYuan3-70B-Chat Conference acronym XX, June 0305, 2018, Woodstock, NY Yan et al. Table 5: Alignment of model-generated rankings with heterogeneous advisory principles. Model Random GPT-5.2 GPT-4o DeepSeek-V3.2 Qwen3-235B-A22B-Instruct Qwen2.5-72B-Instruct Llama-3.3-70B-Instruct Llama3-XuanYuan3-70B-Chat ğœ(Utility) 0.00 0.01 0.59 0.02 0.60 0.02 0.51 0.02 0.56 0.02 0.52 0.02 0.74 0.02 0.47 0.02 ğœ(Momentum) 0.00 0.01 0.56 0.02 0.60 0.02 0.49 0.02 0.55 0.02 0.49 0.02 0.73 0.01 0.46 0.02 ğœ(Risk) 0.00 0.01 0.28 0.02 0.20 0.02 0.26 0.02 0.26 0.02 0.22 0.02 0.17 0.02 0.15 0.02 In contrast, DeepSeek-V3.2 demonstrates the most balanced profile across all evaluated models. By maintaining stable and relatively high alignment with Safety while avoiding extreme bias toward return-driven metrics, DeepSeek-V3.2 shows superior ability to integrate conflicting advisory signals into compromise recommendation. The GPT series also exhibits similar balanced characteristics, though with slightly less consistency than DeepSeek in the safety dimension. The behavior of Llama3-XuanYuan3-70B-Chat is particularly noteworthy given its background as domain-specific LLM finetuned on financial corpora. Despite its lower expert alignment scores, it achieves high behavioral hit rates in Table 4, suggesting that its financial expertise manifests as empathetic alignment with User Choices rather than strict adherence to idealized mathematical formulas. XuanYuan3 acts as seasoned human consultant who prioritizes the pragmatic, albeit noisy, preferences of real-world investors over rigid algorithmic consistency."
        },
        {
            "title": "4.3 Preference Discovery Dynamics\nFigure 2 illustrates the step-wise gain (Î” uNDCG) in utility-based\nalignment when conversational history is accessible. While gains\nare observed for several models, the dynamics are highly hetero-\ngeneous. Models like GPT-5.2 and DeepSeek-V3.2 show signifi-\ncant positive improvements in early to middle stages (steps 1â€“10),\nsuggesting they successfully extract informative signals about the\nuserâ€™s latent risk preferences from initial interactions. The sub-\nsequent fluctuations and general plateauing across most models\nindicate that while LLMs can form a coarse preference representa-\ntion early on, the inherent \"noise\" in longitudinal financial decisions\nmakes consistent, long-term preference tracking challenging.",
            "content": "Figure 2: Step-wise improvement in utility-based alignment from conversational history. From financial advisory perspective, these gains suggest that conversation history allows models to gauge baseline investment styles, identifying whether user is inherently risk-averse or returnsensitive. However, the plateauing suggests that the marginal utility of additional historical context diminishes once stable \"investor persona\" is established, at which point ranking performance becomes more contingent on the immediate market context Mğ‘¡ than on further preference refinement. Figure 3 provides finer-grained diagnostic by comparing average utility alignment with and without longitudinal context. Based on the relative shifts from the diagonal, we identify three archetypes. Adaptive Advisors (GPT-5.2, DeepSeek-V3.2, Qwen3-235B) show clear improvements when history is available, indicating effective cross-turn preference integration and progressive alignment with the users latent risk profile. Transaction-driven Analysts (GPT-4o, Llama-3.3-70B) remain close to the diagonal, achieving strong utility rankings but exhibiting limited gains from conversational context, suggesting reliance on contemporaneous market signals rather than personalization. Behavioral Overfitters (Qwen2.5-72B, Llama3-XuanYuan3) experience degraded utility alignment when history is introduced, implying over-sensitivity to noisy user actions and tendency to prioritize behavioral mimicry over stable preference inference. The results reveal non-uniform preference discovery and highlight the need to separate surface imitation from genuine decisionutility alignment, as evidenced by XuanYuans performance drop. Figure 3: Average utility alignment with and without conversational history."
        },
        {
            "title": "5 Conclusion",
            "content": "We introduce Conv-FinRe, conversational and longitudinal benchmark that shifts financial recommendation from surface-level behavioral matching to utility-grounded decision alignment. Through inverse optimization of latent risk preferences, it supports multiview evaluation that separates rational decision quality from observed user behavior. Our results reveal persistent tension between utility-based ranking and behavioral alignment: generalpurpose LLMs often optimize utility more effectively, while domainspecific models tend to overfit transient user actions. These findings expose the limits of behavior-only evaluation and motivate benchmarks that disentangle long-term investor preferences from short-term market noise. Conv-FinRe: Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation Conference acronym XX, June 0305, 2018, Woodstock, NY References [1] Arran. 2023. Behavioral finance: The psychology behind financial decisionmaking. Business Studies Journal 15, 5 (2023), 12. [2] Bertero. 2006. Regularization methods for linear inverse problems. In Inverse Problems: Lectures given at the 1st 1986 Session of the Centro Internazionale Matematico Estivo (CIME) held at Montecatini Terme, Italy, May 28June 5, 1986. Springer, 52112. [3] Dimitris Bertsimas, Vishal Gupta, and Ioannis Ch Paschalidis. 2012. Inverse optimization: new perspective on the Black-Litterman model. Operations research 60, 6 (2012), 13891403. [4] Dimitris Bertsimas, Vishal Gupta, and Ioannis Ch Paschalidis. 2015. Data-driven estimation in equilibrium using inverse optimization. Mathematical Programming 153, 2 (2015), 595633. [5] Agostino Capponi and Zhaoyu Zhang. 2020. Risk Preferences and Efficiency of Household Portfolios. arXiv preprint arXiv:2010.13928 (2020). [6] Xu Chen, Jingsen Zhang, Lei Wang, Quanyu Dai, Zhenhua Dong, Ruiming Tang, Rui Zhang, Li Chen, Xin Zhao, and Ji-Rong Wen. 2023. REASONER: an explainable recommendation dataset with comprehensive labeling ground truths. Advances in Neural Information Processing Systems 36 (2023), 1449714515. [7] Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, and Jun Xu. 2023. Uncovering chatgpts capabilities in recommender systems. In Proceedings of the 17th ACM Conference on Recommender Systems. 11261132. [8] DeepSeek-AI. 2025. DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models. [9] Dario Di Palma, Giovanni Maria Biancofiore, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia, and Eugenio Di Sciascio. 2023. Evaluating chatgpt as recommender system: rigorous approach. arXiv preprint arXiv:2309.03613 (2023). [10] Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten De Rijke, and Tat-Seng Chua. 2021. Advances and challenges in conversational recommender systems: survey. AI open 2 (2021), 100126. [11] Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noach, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. 2024. The Language Model Evaluation Harness. doi:10.5281/zenodo. [12] Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 (2024). [13] Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. 2024. Gpt-4o system card. arXiv preprint arXiv:2410.21276 (2024). [14] Jiyoon Lee, Joonghoon Kim, and Pilsung Kang. 2026. CEREAL: personality-driven LLM-based conversational recommendation dataset with contextually-enriched and realistic user interactions. Multimedia Tools and Applications 85, 2 (2026), 47. [15] Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, Kp Subbalakshmi, Jimin Huang, et al. 2025. Investorbench: benchmark for financial decision-making tasks with llm-based agent. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 25092525. [16] Tingting Liang, Chenxin Jin, Lingzhi Wang, Wenqi Fan, Congying Xia, Kai Chen, and Yuyu Yin. 2024. LLM-REDIAL: large-scale dataset for conversational recommender systems created from user behaviors with llms. In Findings of the Association for Computational Linguistics ACL 2024. 89268939. [17] Jiayi Liao, Sihang Li, Zhengyi Yang, Jiancan Wu, Yancheng Yuan, and Xiang Wang. 2023. Llara: Aligning large language models with sequential recommenders. CoRR (2023). [18] Qijiong Liu, Jieming Zhu, Lu Fan, Kun Wang, Hengchang Hu, Wei Guo, Yong Liu, and Xiao-Ming Wu. 2025. Benchmarking LLMs in Recommendation Tasks: Comparative Evaluation with Conventional Recommenders. arXiv preprint arXiv:2503.05493 (2025). [19] Hanjia Lyu, Song Jiang, Hanqing Zeng, Yinglong Xia, Qifan Wang, Si Zhang, Ren Chen, Chris Leung, Jiajie Tang, and Jiebo Luo. 2024. Llm-rec: Personalized recommendation via prompting large language models. In Findings of the Association for Computational Linguistics: NAACL 2024. 583612. [20] Malik Magdon-Ismail and Amir Atiya. 2004. Maximum drawdown. Risk Magazine 17, 10 (2004), 99102. [21] Daniel McFadden. 1972. Conditional logit analysis of qualitative choice behavior. (1972). [22] Khalid Mehraj and Vinay Kumar. 2025. Psychological Biases in Investment Decisions: Behavioral Finance Approach. (2025). [23] Andreas Oehler and Matthias Horn. 2024. Does ChatGPT provide better advice than robo-advisors? Finance Research Letters 60 (2024), 104898. [24] Xueqing Peng, Lingfei Qian, Yan Wang, Ruoyu Xiang, Yueru He, Yang Ren, Mingyang Jiang, Jeff Zhao, Huan He, Yi Han, et al. 2025. MultiFinBen: Multilingual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation. arXiv preprint arXiv:2506.14028 (2025). [25] Lingfei Qian, Weipeng Zhou, Yan Wang, Xueqing Peng, Han Yi, Yilun Zhao, Jimin Huang, Qianqian Xie, and Jian yun Nie. 2025. Fino1: On the Transferability of Reasoning-Enhanced LLMs and Reinforcement Learning to Finance. arXiv:2502.08127 [cs.CL] https://arxiv.org/abs/2502.08127 [26] Mark Rubinstein. 2002. Markowitzs\" portfolio selection\": fifty-year retrospective. The Journal of finance 57, 3 (2002), 10411045. [27] Chandan Kumar Sah and Xiaoli Lian. 2025. PerFairX: Is There Balance Between Fairness and Personality in Large Language Model Recommendations?. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 27502759. [28] Chandan Kumar Sah, Xiaoli Lian, Tony Xu, and Li Zhang. 2025. FairEval: Evaluating Fairness in LLM-Based Recommendations with Personality Awareness. arXiv preprint arXiv:2504.07801 (2025). [29] Javier Sanz-Cruzado, Nikolaos Droukas, and Richard McCreadie. 2024. FAR-Trans: An Investment Dataset for Financial Asset Recommendation. arXiv preprint arXiv:2407.08692 (2024). [30] Suraj Sharma, Joseph Brennan, and Jason Nurse. 2021. StockBabble: conversational financial agent to support stock market investors. In Proceedings of the 3rd Conference on Conversational User Interfaces. 15. [31] Aaditya Singh, Adam Fry, Adam Perelman, Adam Tart, et al. 2025. OpenAI GPT-5 System Card. arXiv:2601.03267 [cs.CL] https://arxiv.org/abs/2601.03267 [32] Ying So and Warren Kuhfeld. 1995. Multinomial logit models. In SUGI 20 conference proceedings, Vol. 1995. 12271234. [33] Yueming Sun and Yi Zhang. 2018. Conversational recommender system. In The 41st international acm sigir conference on research & development in information retrieval. 235244. [34] Takehiro Takayanagi, Chung-Chi Chen, and Kiyoshi Izumi. 2023. Personalized dynamic recommender system for investors. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. 22462250. [35] Takehiro Takayanagi, Kiyoshi Izumi, Javier Sanz-Cruzado, Richard McCreadie, and Iadh Ounis. 2025. Are generative AI agents effective personalized financial advisors?. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval. 286295. [36] Takehiro Takayanagi, Masahiro Suzuki, Kiyoshi Izumi, Javier Sanz-Cruzado, Richard McCreadie, and Iadh Ounis. 2025. FinPersona: An LLM-Driven Conversational Agent for Personalized Financial Advising. In European Conference on Information Retrieval. Springer, 1318. [37] Qwen Team. 2025. Qwen3 Technical Report. arXiv:2505.09388 [cs.CL] https: //arxiv.org/abs/2505. [38] Amos Tversky and Daniel Kahneman. 1992. Advances in prospect theory: Cumulative representation of uncertainty. Journal of Risk and uncertainty 5, 4 (1992), 297323. [39] Yan Wang, Lingfei Qian, Xueqing Peng, Yang Ren, Keyi Wang, Yi Han, Dongji Feng, Fengran Mo, Shengyuan Lin, Qinchuan Zhang, Kaiwen He, Chenri Luo, Jianxing Chen, Junwei Wu, Chen Xu, Ziyang Xu, Jimin Huang, GuoFinTagjun Xiong, Xiao-Yang Liu, Qianqian Xie, and Jian-Yun Nie. 2026. ging: Benchmarking LLMs for Extracting and Structuring Financial Information. arXiv:2505.20650 [cs.CL] https://arxiv.org/abs/2505.20650 [40] Yan Wang, Keyi Wang, Shanshan Yang, Jaisal Patel, Jeff Zhao, Fengran Mo, Xueqing Peng, Lingfei Qian, Jimin Huang, Guojun Xiong, Xiao-Yang Liu, and JianYun Nie. 2025. FinAuditing: Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs. arXiv:2510.08886 [cs.CL] https://arxiv.org/abs/ 2510.08886 [41] An Yang, Baosong Yang, Binyuan Hui, et al. 2024. Qwen2 Technical Report. arXiv preprint arXiv:2407.10671 (2024). [42] Qi Yang, Sergey Nikolenko, Alfred Huang, and Aleksandr Farseev. 2022. Personality-driven social multimedia content recommendation. In Proceedings of the 30th ACM International Conference on Multimedia. 72907299. [43] Tong Yu, Yongcheng Jing, Xikun Zhang, Wentao Jiang, Wenjie Wu, Yingjie Wang, Wenbin Hu, Bo Du, and Dacheng Tao. 2025. Benchmarking reasoning robustness in large language models. arXiv preprint arXiv:2503.04550 (2025). [44] Yilun Zhao, Yitao Long, Hongjun Liu, Ryo Kamoi, Linyong Nan, Lyuhao Chen, Yixin Liu, Xiangru Tang, Rui Zhang, and Arman Cohan. 2024. DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Long and Specialized Documents. arXiv:2311.09805 [cs.CL] https://arxiv.org/abs/2311."
        }
    ],
    "affiliations": [
        "MBZUAI",
        "McGill University",
        "The Fin AI USA",
        "University of Montreal"
    ]
}