{
    "paper_title": "AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use",
    "authors": [
        "Yaotian Yang",
        "Yiwen Tang",
        "Yizhe Chen",
        "Xiao Chen",
        "Jiangjie Qiu",
        "Hao Xiong",
        "Haoyu Yin",
        "Zhiyao Luo",
        "Yifei Zhang",
        "Sijia Tao",
        "Wentao Li",
        "Qinghua Zhang",
        "Yuqiang Li",
        "Wanli Ouyang",
        "Bin Zhao",
        "Xiaonan Wang",
        "Fei Wei"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers a potential source of structural data, converting these images into simulation-ready formats remains labor-intensive and error-prone, creating a bottleneck for model training and validation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that automatically transforms scanning transmission electron microscopy (STEM) images into atomic crystal structures and predicts their physical properties. AutoMat combines pattern-adaptive denoising, physics-guided template retrieval, symmetry-aware atomic reconstruction, fast relaxation and property prediction via MatterSim, and coordinated orchestration across all stages. We propose the first dedicated STEM2Mat-Bench for this task and evaluate performance using lattice RMSD, formation energy MAE, and structure-matching success rate. By orchestrating external tool calls, AutoMat enables a text-only LLM to outperform vision-language models in this domain, achieving closed-loop reasoning throughout the pipeline. In large-scale experiments over 450 structure samples, AutoMat substantially outperforms existing multimodal large language models and tools. These results validate both AutoMat and STEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic simulation in materials science.The code and dataset are publicly available at https://github.com/yyt-2378/AutoMat and https://huggingface.co/datasets/yaotianvector/STEM2Mat."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 1 ] . [ 1 0 5 6 2 1 . 5 0 5 2 : r AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use Yaotian Yang1 Yiwen Tang2,3* Yizhe Chen1* Xiao Chen1 Jiangjie Qiu1 Hao Xiong Haoyu Yin1 Zhiyao Luo1 Yifei Zhang1 Sijia Tao1 Wentao Li1 Qinghua Zhang1 Yuqiang Li2 Wanli Ouyang Bin Zhao2,3 Xiaonan Wang1 Fei Wei1 1Department of Chemical Engineering, Tsinghua University, Beijing, China 2Shanghai Artificial Intelligence Laboratory, Shanghai, China 3School of Computer Science, Northwestern Polytechnical University, Xian, China"
        },
        {
            "title": "Abstract",
            "content": "Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers potential source of structural data, converting these images into simulationready formats remains labor-intensive and error-prone, creating bottleneck for model training and validation. We introduce AutoMat, an end-to-end, agentassisted pipeline that automatically transforms scanning transmission electron microscopy (STEM) images into atomic crystal structures and predicts their physical properties. AutoMat combines pattern-adaptive denoising, physics-guided template retrieval, symmetry-aware atomic reconstruction, fast relaxation and property prediction via MatterSim, and coordinated orchestration across all stages. We propose the first dedicated STEM2Mat-Bench for this task and evaluate performance using lattice RMSD, formation energy MAE, and structure-matching success rate. By orchestrating external tool calls, AutoMat enables text-only LLM to outperform vision-language models in this domain, achieving closed-loop reasoning throughout the pipeline. In large-scale experiments over 450 structure samples, AutoMat substantially outperforms existing multimodal large language models and tools. These results validate both AutoMat and STEM2Mat-Bench, marking key step toward bridging microscopy and atomistic simulation in materials science.The code and dataset are publicly available at https://github.com/yyt-2378/AutoMat and https://huggingface.co/datasets/yaotianvector/STEM2Mat"
        },
        {
            "title": "Introduction",
            "content": "Machine learning (ML) interatomic potentials and force fields now approach ab initio accuracy in predicting atomic energies and forces[15] but remain limited by experimentally validated crystal * Equal contribution.Contact: yangyt22@mails.tsinghua.edu.cn; stutangyw@gmail.com; chenyizh23@mails.tsinghua.edu.cn Corresponding authors: chenx123@tsinghua.edu.cn;bin@nwpu.edu.cn; wangxiaonan@tsinghua.edu.cn; wf-dce@tsinghua.edu.cn Preprint. Under review. Figure 1: Overview of AutoMat. The left part shows an LLM agent how to manage four modulespattern-adaptive denoising, template selection, atomic reconstruction (STEM2CIF), and ML-based property prediction. The right panel presents line chart and radar plot comparing different models in terms of energy and structural errors. structures. Meanwhile, scanning transmission electron microscopy (STEM) can image atoms individually at sub-ångström resolution[69], yet translating them into quantitative crystal structures still relies on expert-driven, time-consuming annotation. This disconnect creates critical gap between structural representation and theoretical validation in materials science[10, 11]. Although recent advances in STEM image analysis have shown promise, most existing studies focus on individual components like denoising[1215], atom localization[1618], reconstruction[1921] and phase classification[22, 23]. These approaches remain fragmented and are not integrated into end-to-end systems. Conventional image denoising techniques suppress noise and improve contrast at the pixel level but cannot yield periodic or chemically meaningful crystal structures[24, 25, 15, 12]. Atomic detection models can localize atomic peaks but cannot infer complete lattices3 or identify atomic species. General-purpose multimodal models like GPT-4.1mini[26] and Qwen2.5-VL[27] exhibit basic image understanding but lack the ability to produce simulation-ready formats such as crystallographic file(CIF). Even domain-specific tools like AtomAI[28] can only predict atomic coordinates in minimal systems and do not support full structure reconstruction or property prediction. Meanwhile, public datasets (e.g., JARVIS-STM) mainly target STM( Scanning Tunneling Microscopy) images, lack DFT-level energy labels, and are unsuitable for benchmarking structureproperty pipelines. As result, the field still lacks fully automated end-to-end system that can convert raw STEM images into reconstructed structures and simulated properties, along with the standardized benchmark for comprehensive evaluation. To address this gap, as shown in Fig. 1, we introduce AutoMat, the first agent-coordinated framework linking STEM imaging with atomistic simulation, along with benchmark tailored to the task. The AutoMat pipeline comprises four key stages: 1) Pattern-Adaptive STEM Image denoising: We apply pattern-adaptive mixture-of-experts network, MOE-Denoising Inference Variational Autoencoder Super-Resolution[12](MOE-DIVAESR), to denoise and enhance raw iDPC-STEM4 3In crystallography, lattice refers to the periodic arrangement of atoms in crystal structure. 4iDPC-STEM stands for integrated Differential Phase Contrast Scanning Transmission Electron Microscopy, technique that enhances light element contrast in atomic-resolution imaging. 2 images. The ResNet-18-based gating network elects the most suitable expert network for each input image based on its estimated noise level, enabling joint denoising, inpainting, and super-resolution. 2) Physics-Guided Template Retrieval: Enhanced images are matched to large-scale library of simulated STEM projections. Top candidate structures are retrieved using pixel similarity and filtered by elemental contrast patterns to produce strong structural priors. 3) Symmetry-Constrained Structure Reconstruction: Atomic peaks are detected via unsupervised clustering. We fit the lattice under symmetry constraints, assign atomic species based on the candidate, and generate the standard CIF file representing the periodic crystal structure. 4) Energy Evaluation via Machine-Learned Potential: The reconstructed structure is relaxed using the pretrained MatterSim potential to predict formation energy. language agent coordinates the all stages and automatically retries failed stages based on quality checks. To support rigorous evaluation, we curated 2,143 high-quality monolayer structures from C2DB[29], Materials Project[30], and OpenCrystal[31], and simulated their corresponding iDPC-STEM images with abTEM[32]. From this pool we selected 450 representative imagestructure pairs, which constitute our STEM2Mat benchmark and are used for all subsequent evaluations. Our evaluation metrics include projected lattice RMSD, formation energy MAE, and atom-wise structure matching success rate. Additionally, we introduce three fine-grained indicators to assess reconstruction quality (e.g., atomic recall/precision), robustness across noise levels, and computational efficiency. On this benchmark, AutoMat achieves projected RMSD of 0.11 0.03 Å, energy MAE below 350 meV/atom, and an atomic correspondence total success rate of 83.2%, outperforming GPT-4.1mini, Qwen-VL, LLama4V, ChemVLM[33], and AtomAI by an order of magnitude. These results demonstrate AutoMat as reproducible and accurate end-to-end solution for microscopy-driven materials modeling. The contributions of this paper are summarized as follows: Agent-driven end-to-end pipeline. AutoMat proposes an automated agent integrating patternadaptive denoising, physics-informed template retrieval, symmetry-constrained reconstruction, and ML-based relaxation, enabling the conversion of raw STEM images into material property predictions. Algorithmic advancements. We design MOE-DIVAESR as pattern-adaptive denoiser for diverse STEM images, enabling efficient noise reduction, defect correction, and detail enhancement. We also develop STEM2CIF to reconstruct crystal structures by identifying the minimal repeating unit using symmetry heuristics and physical constraints, then converting the result into standard CIF format. STEM2Mat benchmark & evaluation suite. We release dataset of 2,143 distinct supercell structures used to simulate large-field STEM images. In addition, we provide 450-case test split with DFT-calculated energies and establish unified metrics to evaluate lattice reconstruction accuracy, energy fidelity, robustness, and computational efficiency. State-of-the-art results with open access. AutoMat outperforms leading large multimodal models by an order of magnitude. All code, data, and evaluation tools are publicly released to support reproducibility and future development."
        },
        {
            "title": "2 Related Work",
            "content": "Automated Microscopy Image Analysis. In recent years, deep learning methods have been extensively applied to electron microscopy and scanning probe microscopy data analysis[1217, 1921]. Current approaches range from unsupervised defect detection to supervised atomic column identification. AtomAI [28], for example, integrates microscopy images with computational simulations, but primarily focuses on atom segmentation and identification. It lacks fully automated, agent-based framework that coordinates tool usage to directly recover crystal structures and predict material properties. STEM Image to Structure Reconstruction. Existing methods for reconstructing crystal structures from STEM images typically rely on multiple images, prior structural information, or are limited to single-element systems. For instance, De Backer et al [19] employed Bayesian genetic algorithms for 3D reconstruction, but their approach was demonstrated only for simple single-element systems. Currently, few methods can directly generate standard crystallographic information files (CIF) from single experimental images, especially for complex multi-element two-dimensional crystals[20]. 3 Vision-Language Models in Chemistry. Recently, multimodal large language models (such as ChemVLM[33], GPT-4.1mini[26], and Qwen-VL[27]) have started to be explored in chemistry and materials science. However, these models generally lack the capability to accurately handle detailed spatial structure tasks. Existing chemical agent tools (e.g., ChemCrow[34] and Chemagents[35]) are limited to text-based descriptions and cannot process image-based inputs, significantly restricting their applicability in microscopy-based analyses. Material Property Prediction Models. Advances in machine learning-based interatomic potentials (such as MatterSim[1], M3GNet[36], and MACE[37]) have significantly improved the accuracy of computational property predictions. Combining these models with experimental imaging provides novel, digital twin-like approach for validating structural reconstructions. However, existing benchmarks predominantly evaluate models using theoretical datasets, lacking end-to-end assessments starting from experimental image inputs. In summary, these approaches highlight progress and limitations in microscopy image analysis, structure reconstruction, multimodal modeling, and property prediction. AutoMat addresses these gaps by integrating an automated agent from STEM images to material property prediction and establishes the STEM2Mat benchmark for evaluating the robustness and scalability of automated material characterization."
        },
        {
            "title": "3 Dataset Construction",
            "content": "3.1 Composition and Taxonomy Our benchmark focuses on two-dimensional (2D) materials, whose atomic-scale thickness allows STEM to resolve individual columns with minimal multiple-scattering artifacts. Starting from nearly 10,000 candidate structures harvested from C2DB, Materials Project, and OpenCrystal,5 we followed two-stage curation process. First, automated filters removed non-stoichiometric, partially occupied, or 3D bulk entries. Second, domain experts inspected symmetry, cleavage energy, and substrate feasibility, yielding 2,143 high-confidence monolayer crystals. The collection spans six chemical families (Fig. ??): (i) classic 2D materialsgraphene, MoS2, h-BN, black phosphorus; (ii) emergent allotropes, e.g. silicene, borophene; (iii) conductive MXenes (23 distinct formulas); (iv) intrinsic 2D magnets such as CrI3 and Fe3GeTe2; (v) Janus structures typified by MoSSe; and (vi) RuddlesdenPoppertype 2D perovskites. Elemental diversity is broad: 67 unique elements appear, producing 76 unary 1,409 binary, and 658 ternary systems. Each structure is stored as CIF file with validated lattice vectors and fractional atomic coordinates. 3.2 Image Simulation and Data Augmentation 2 To simulate realistic large-field STEM imaging conditions, We generated synthetic iDPC-STEM micrographs using the open-source abTEM simulation engine. For each structure, random 12 12 to 16 16 supercell was constructed and projected at 0.1 Å/pixel resolution. Five electron-dose settings (16 104 e/Å ) and realistic lens aberrations were sampled to mimic experimental conditions. Poisson detector noise was injected to match reported signal-to-noise ratios. To study model robustness, we applied Gaussian blurring and dose-specific shot noise to simulate additional imaging imperfections. Ground-truth atomic coordinates were rendered into Gaussian atom masks to enable supervised training of localisation models. Each sample thus forms an imagestructure property triplet: (i) the noisy STEM projection, (ii) the corresponding ground-truth CIF, and (iii) DFT-level formation energy (along with band gap and magnetic moment, if available). We conducted principal component analysis (PCA) on structural fingerprints, which revealed clear clustering patterns. Subsequently, k-means clustering (k=2, 6) was used to ensure balanced train/validation/test splits across the chemical diversity of the dataset. 3.3 STEM2Mat Benchmark Split and Tiering To construct representative and tractable benchmark dataset for STEM-based crystal modeling, we applied stringent geometric and chemical screening criteria to the 2,143 collected 2D material structures, ensuring their suitability for monolayer imaging and end-to-end reconstruction. Specifically, 5All sources were queried in April 2025 using identical monolayer filters. 4 Figure 2: Overview of the STEM2Mat Benchmark design, illustrating the tiered classification of STEM samples by material complexity and imaging dose, which systematically stratifies reconstruction difficulty from simple unary to complex ternary compounds. we retained only structures containing no more than three distinct elements. For those with multiple elements, we required minimum atomic-number span of ten, i.e., max(Zi) min(Zi) 10, to ensure sufficient imaging contrast between heavy and light atoms. To guarantee monolayer geometry, we limited the z-axis thickness to no more than 3 Å. Each structures atomic coordinates were then projected onto the (x, y) plane, discretized onto 1 Å grid, and evaluated for overlapping projections. Only structures with projected duplication ratio below 10%, i.e., Number of overlapping grid points 0.1, were retained to avoid ambiguity in atomic interpretation. Total grid points Following this multi-criteria filtering process, we retained 450 well-defined, unambiguous monolayer structures21% of the original datasetfor blind end-to-end evaluation. The remaining 1,693 samples were split into training (80%) and validation (20%) sets to support model training and tuning. To analyze model performance as function of task difficulty, we stratified the test set into three tiers based on material composition and imaging noise (see Fig. 2): Tier 1 Unary materials acquired under high electron doses (56 104 e/Å high contrast, low noise, and represent the easiest cases (35 samples). 2 ); these images are Tier 2 Binary materials or moderate electron dose conditions (34 104 e/Å intermediate complexity in both noise level and atomic diversity (456 samples). 2 ); these represent Tier 3 Ternary compounds imaged at low dose (12 104 e/Å noise, complex contrast, and are the most challenging to reconstruct (79 samples). ); these samples exhibit high While the tier sizes are imbalanced, this hierarchical structure reveals clear gradient of reconstruction difficulty, establishing principled ladder for evaluating robustness and scalability. With the STEM2Mat-Bench tiers defined, we now specify the quantitative metrics used throughout the paper. For detailed definitions and formulae of the evaluation metrics, see evaluation metrics 3.4. 3.4 Evaluation Metrics To compare methods reproducibly, we report two primary metricsenergy error and lattice error and two holistic metrics that reflect chemical and structural validity. Mean Absolute Error (MAE). Average difference between predicted and DFT formation energies: MAE = 1 N (cid:88) (cid:12) (cid:12)Epred Eref (cid:12) (cid:12) [meV/atom] i=1 (1) Projected Lattice RMSD. Deviation of in-plane lattice constants: RMSDxy = (cid:114) (cid:104) 1 2 (apred aref)2 + (bpred bref) (cid:105) (2) Composition Correctness (C.C.). 1 if elemental types and counts match the reference; 0 otherwise. Structure Success Rate (S.S.). prediction is successful when it satisfies both chemistry and geometry. First define 2-D spatial similarity Sspatial = exp(cid:0)MSE2D where MSE2D is the mean-squared error of projected atomic positions after optimal element-wise matching. Then (cid:1), (3) S.S. ="
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) i=1 (cid:104) (cid:105) S(i) spatial 0.8 100%. (4)"
        },
        {
            "title": "4 Overview of AutoMat",
            "content": "4.1 Limitations of Existing Large Multimodal Models and Domain Tools Most current large multimodal models (e.g., GPT-4.1mini, LLama4V, Qwen2.5-VL, ChemVLM) focus on general-purpose image understanding tasks such as scene recognition, OCR, and molecular structure identification, but exhibit limited capability in interpreting scientific images like electron microscopy (EM). Domain-specific chemistry agents (e.g., ChemAgent[35], ChemCrow[34]) remain predominantly text-based, executing tool calls for predefined tasks without closed-loop visual reasoning or image-guided decision-making. Specialized STEM data toolkits (e.g., AtomAI) provide atomic coordinate extraction and segmentation, yet their applicability is largely restricted to single-element nanoparticles and fail with complex, multi-element STEM images. To date, no agent autonomously generates simulation-ready CIFs and predicts formation energies from single real STEM image, thus completing generalizable structureproperty pipeline. To bridge this gap, we introduce AutoMat, modular agent framework with advanced reasoning, enabling end-to-end modeling from pixel-level inputs to material property predictions. 4.2 Tool Pool AutoMat integrates specialized suite of intelligent tools to bridge electron microscopy characterization and material modeling. Its core comprises four modulesMOE-DIVAESR, Image Template Matching, STEM2CIF, and MatterSimfor image denoising, template matching, structure reconstruction, and property prediction, respectively(see Appendix ?? and ?? for full implementation details). MOE-DIVAESR is structure-pattern-adaptive mixture-of-experts (MoE) model for STEM image denoising. Trained on an augmented STEM dataset, it includes multiple expert networks, each targeting distinct structural patterns. gating network dynamically selects the optimal experts based on the features of the input image. This architecture enables MOE-DIVAESR to perform denoising, defect correction, and fine-grained detail enhancement, yielding sharply resolved atomic columns as high-quality inputs for downstream reconstruction. Image Template Matching compares the enhanced image to pre-stored or externally mounted database of structural templates or known materials. Using image features and elemental cues, it narrows the candidate structures and selects the one most consistent with the observed features. STEM2CIF combines the selected structural template and enhanced image to reconstruct highfidelity atomic model. The module identifies atomic column positions, infers lattice parameters, and determines atomic species. It also incorporates crystallographic symmetry heuristics and physical constraints to reduce the structure to its minimal repeating unit, outputting crystallographic CIF file. MatterSim is pretrained machine-learning interatomic potential model for rapid structural relaxation and property evaluation. Trained on large-scale DFT datasets, MatterSim achieves near-DFT accuracy 6 Figure 3: AutoMats LLM agent orchestrates four stagesdenoising, template matching, structure reconstruction, and property predictionfrom STEM image to relaxed crystal with properties. for energy and property predictions. Integrated with ASE, it enables structure optimization and rapid assessment of properties such as total energy, formation energy, and elastic moduli, providing fast and accurate alternative to conventional DFT. 4.3 LLM-Orchestrated End-to-End Pipeline Based on the aforementioned tool pool, AutoMat deploys an LLM agent based on DeepSeekV3 to dynamically coordinate the end-to-end tool execution process, as illustrated in Figure 3. The large language model agent is responsible for chaining the four sequential stages, managing inter-stage data flow, and making iterative decisions throughout. The process starts from raw STEM image. The agent first chooses to call MOE-DIVAESR to perform denoising and structural enhancement on the image. After obtaining clearer image, the agent determines that Image Template Matching needs to be executed to retrieve candidate templates from the structure database based on atomic geometry and elemental contrast. After selecting the best-matching structure, the process proceeds to the STEM2CIF tool for structure reconstruction. This module localizes atomic peaks, fits lattice parameters, assigns elements, and finally generates standard CIF file. To calculate the physical properties of the material, MatterSim is automatically called at the end to relax the structure and predict total energy, formation energy, and other properties. Throughout the entire process, the agent monitors the quality of intermediate results in real time and performs rollback and retries if failures occur. Logic-driven orchestration enables AutoMat to complete closed-loop automated material modeling workflow from image to property prediction under varying input conditions. 7 Table 1: Formation-energy MAE (meV/atom) across tiers. indicates lower is better; indicates the method does not provide an energy prediction. Method GPT-4.1 Vision Qwen-VL (32B) LLama4V (17B) ChemVLM (8B) AtomAI AutoMat (Ours) Upper Bound Tier 1 2521.9 3488.6 2549.8 3961.1 343.59 57.377 Tier 2 2657.4 2673.9 2898.3 4237.5 320.21 47.227 Tier 3 2817.7 4113.9 3662.6 5090.3 333.49 30.945 Avg. 2657.3 2763.5 2931.7 4237.6 321.57 48.105 Table 2: Structural-accuracy metrics for methods that output atomic models. RMSDxy: in-plane lattice root-mean-square deviation (lower is better); C.C.: composition correctness; S.S.: structure success rate. Tier Method 2 3 AtomAI AutoMat (Ours) Upper Bound AtomAI AutoMat (Ours) Upper Bound AtomAI AutoMat (Ours) Upper Bound RMSDxy (Å) 43.960.31 0.110.02 0 (def.) N/A 0.110.03 0 (def.) N/A 0.110.03 0 (def.) C.C. (%) S.S. (%) 2.70 88.9 0.0 85.9 100 0.0 73.1 100 0.0 85.0 100 0.0 84.0 100 0.0 73.1 100 Figure 3 summarizes the process, showing how the agent integrates image, structure, and properties. The final output is stable atomic model with predicted properties, achieving AutoMats goal of automated reasoning from STEM images to materials insights."
        },
        {
            "title": "5 Experiments and Results",
            "content": "5.1 Quantitative Evaluation Baseline Overview To evaluate AutoMat, we compare it against three baselines targeting reasoning, reconstruction, and oracle performance: VisionLanguage Models (VLM). GPT-4.1mini, Qwen2.5-VL (32B), LLama4V (17B) and ChemVLM (8B) receive fixed prompt, composition hints, and STEM image to infer material properties, assessing multimodal reasoning. AtomAI. AtomAIs segmentation network detects atomic centers; relative coordinates plus image resolution are used to fit the lattice. This baseline measures reconstruction quality only. Ground-Truth CIF + MLIP (Oracle Upper Bound). The true CIF is fed directly to the MatterSim MLIP to benchmark formation-energy error under perfect-structure assumptions. We summarize the performance of these baselines and our AutoMat system on the test set in Tables 1 and 2, which together cover samples across Tier 13 difficulty levels. Discussion of Results. In energy prediction, AutoMat achieves mean formation energy MAE of 332 12 meV/atom, with tier-wise results of 343.59, 320.21, and 333.49 meV/atom for Tier 13. While this is higher than the MLIP oracle lower bound of 57 meV/atom, it remains significantly better than the multi-eV errors produced by visionlanguage models. As task difficulty increases, MAE in VL baselines rises accordingly, validating our tiered benchmark design. These results suggest that AutoMats residual error is mainly due to reconstruction rather than MLIP limitations, and that the predicted structures are reliable for downstream property evaluation.Figure 4 illustrates two representative examples from Tier 2 and Tier 3, comparing AutoMat with GPT-4.1mini and 8 Figure 4: Case studies on Tier 2 and Tier 3 samples comparing AutoMat, GPT-4.1mini and Llama-4Maverick: enhanced images, best-matched templates, reconstructed unit cells and predicted energies. LLaMA4. The figure highlights AutoMats superior ability to reconstruct structures and predict energy accurately, even under low-dose and multi-element conditions. For structural reconstruction, AutoMat achieves an average projected RMSDxy of approximately 0.11 Å, two orders of magnitude lower than AtomAI (4344 Å), with most deviation correctable through final relaxation. For composition correctness, AutoMat achieves 83% on average across tiers (88.9%, 85.9%, 73.1%), while AtomAI achieves less than 2.7%, only in simple Tier 1 cases. For structure success rate, which considers both spatial and compositional agreement, AutoMat achieves 83.2% overall (Tier-wise: 85.0%, 84.0%, 73.1%), whereas AtomAI rarely produces valid structures. In summary, AutoMat not only outperforms all existing baselines but also maintains high performance in challenging Tier 3 scenarios involving multi-element compositions and low imaging doses, demonstrating its robustness and generalizability across the full benchmark spectrum. 5.2 Error Analysis To better understand the failure modes of AutoMat, we conducted detailed analysis of representative failure cases across all three tiers. Two primary error types were identified: (1) Template retrieval failure (39.3%): In these cases, AutoMat failed to retrieve the correct structure from the template database, resulting in mismatches in atomic arrangements and element types. This led to cascading errors in structure, composition, and property predictions. Incorrect atom counts further caused large energy estimation errors. For example, in Tier 3 case, true structure containing U, F, and was mismatched with P-based template, causing severe atomic misalignment and an energy_per_atom error of up to 3.13 eV. (2) Downstream failure despite correct template (60.7%): Even with the correct template, downstream steps failed due to projection ambiguity or elemental confusion. In 40% of these cases, atoms appeared too close in the 2D projection, and the lack of z-axis information led to poor relaxation and inaccurate energy estimates. In 20.7%, elements with similar atomic numbers (e.g., and O) exhibited indistinguishable contrast, causing misclassification and full breakdowns in lattice fitting and CIF generation. For instance, in Tier 2 case, closely spaced and atoms were confused, leading to complete loss of atoms and reconstruction failure. 9 These findings highlight two key directions for improving AutoMat: (i) improving retrieval robustness via uncertainty-aware or multi-candidate matching; and (ii) overcoming 2D projection limits through 3D-aware modeling [3840] and enhanced modality integration. Together, these efforts can greatly improve structural fidelity and prediction reliability in complex systems."
        },
        {
            "title": "6 Conclusion",
            "content": "We proposed AutoMat, an end-to-end agent system that automatically reconstructs material structures and predicts properties from STEM images. By integrating pattern-adaptive vision models, symmetryconstrained reconstruction, and LLM-driven orchestration, AutoMat achieves accurate alignment between microscopy data and atomic modeling, significantly outperforming existing methods in structural and energetic evaluation. Meanwhile, we propose STEM2Mat-Bench for this task. AutoMat advances autonomous materials research and AI-driven experimentation. Future work will focus on strengthening its role as bridge between experimental characterization and theoretical computation."
        },
        {
            "title": "References",
            "content": "[1] Han Yang, Chenxi Hu, Yichi Zhou, Xixian Liu, Yu Shi, Jielan Li, Guanzhi Li, Zekun Chen, Shuizhou Chen, Claudio Zeni, Matthew Horton, Robert Pinsler, Andrew Fowler, Daniel Zügner, Tian Xie, Jake Smith, Lixin Sun, Qian Wang, Lingyu Kong, Chang Liu, Hongxia Hao, and Ziheng Lu. Mattersim: deep learning atomistic model across elements, temperatures and pressures, 2024. URL https://arxiv.org/abs/2405.04967. [2] Ilyes Batatia, Philipp Benner, Yuan Chiang, Alin M. Elena, Dávid P. Kovács, Janosh Riebesell, Xavier R. Advincula, Mark Asta, Matthew Avaylon, William J. Baldwin, Fabian Berger, Noam Bernstein, Arghya Bhowmik, Samuel M. Blau, Vlad Carare, James P. Darby, Sandip De, Flaviano Della Pia, Volker L. Deringer, Rokas Elijošius, Zakariya El-Machachi, Fabio Falcioni, Edvin Fako, Andrea C. Ferrari, Annalena Genreith-Schriever, Janine George, Rhys E. A. Goodall, Clare P. Grey, Petr Grigorev, Shuang Han, Will Handley, Hendrik H. Heenen, Kersti Hermansson, Christian Holm, Jad Jaafar, Stephan Hofmann, Konstantin S. Jakob, Hyunwook Jung, Venkat Kapil, Aaron D. Kaplan, Nima Karimitari, James R. Kermode, Namu Kroupa, Jolla Kullgren, Matthew C. Kuner, Domantas Kuryla, Guoda Liepuoniute, Johannes T. Margraf, Ioan-Bogdan Magdau, Angelos Michaelides, J. Harry Moore, Aakash A. Naik, Samuel P. Niblett, Sam Walton Norwood, Niamh ONeill, Christoph Ortner, Kristin A. Persson, Karsten Reuter, Andrew S. Rosen, Lars L. Schaaf, Christoph Schran, Benjamin X. Shi, Eric Sivonxay, Tamás K. Stenczel, Viktor Svahn, Christopher Sutton, Thomas D. Swinburne, Jules Tilly, Cas van der Oord, Eszter Varga-Umbrich, Tejs Vegge, Martin Vondrák, Yangshuai Wang, William C. Witt, Fabian Zills, and Gábor Csányi. foundation model for atomistic materials chemistry, 2024. URL https://arxiv.org/abs/2401.00096. [3] Johannes Gasteiger, Florian Becker, and Stephan Günnemann. Gemnet: Universal directional graph neural networks for molecules. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, volume 34, pages 67906802. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper_files/paper/2021/file/ 35cf8659cfcb13224cbd47863a34fc58-Paper.pdf. [4] Yi-Lun Liao, Brandon Wood, Abhishek Das, and Tess Smidt. Equiformerv2: Improved equivariant transformer for scaling to higher-degree representations, 2024. URL https:// arxiv.org/abs/2306.12059. [5] Shuqi Lu, Zhifeng Gao, Di He, Linfeng Zhang, and Guolin Ke. Highly accurate quantum chemical property prediction with uni-mol+, 2023. URL https://arxiv.org/abs/2303. 16982. [6] Daliang Zhang, Yihan Zhu, Lingmei Liu, Xiangrong Ying, Chia-En Hsiung, Rachid Sougrat, Kun Li, and Yu Han. Atomic-resolution transmission electron microscopy of electron beamsensitive crystalline materials. Science, 359(6376):675679, 2018. ISSN 0036-8075. 10 [7] Hui Zhang, Guanxing Li, Jiaxing Zhang, Daliang Zhang, Zhen Chen, Xiaona Liu, Peng Guo, Yihan Zhu, Cailing Chen, and Lingmei Liu. Three-dimensional inhomogeneity of zeolite structure and composition revealed by electron ptychography. Science, 380(6645):633638, 2023. ISSN 0036-8075. [8] Qing Zhang, Alvaro Mayoral, Junyan Li, Juanfang Ruan, Viveka Alfredsson, Yanhang Ma, Jihong Yu, and Osamu Terasaki. Electron microscopy studies of local structural modulations in zeolite crystals. Angewandte Chemie, 132(44):1957119581, 2020. ISSN 0044-8249. [9] Volkan Ortalan, Alper Uzun, Bruce Gates, and Nigel Browning. Direct imaging of single metal atoms and clusters in the pores of dealuminated hy zeolite. Nature nanotechnology, 5(7): 506510, 2010. ISSN 1748-3387. [10] Sergei Kalinin, Colin Ophus, Paul Voyles, Rolf Erni, Demie Kepaptsoglou, Vincenzo Grillo, Andrew Lupini, Mark Oxley, Eric Schwenker, and Maria KY Chan. Machine learning in scanning transmission electron microscopy. Nature Reviews Methods Primers, 2(1): 11, 2022. ISSN 2662-8449. [11] Sergei Kalinin, Debangshu Mukherjee, Kevin Roccapriore, Benjamin Blaiszik, Ayana Ghosh, Maxim Ziatdinov, Anees Al-Najjar, Christina Doty, Sarah Akers, Nageswara Rao, et al. Machine learning for automated experimentation in scanning transmission electron microscopy. npj Computational Materials, 9(1):227, 2023. [12] Yaotian Yang, Hao Xiong, Zirong Wu, Zhiyao Luo, Xiao Chen, Xiaonan Wang, and Fei Wei. Deep learning-enabled stem imaging for precise single-molecule identification in zeolite structures. Advanced Science, 12(6):2408629, 2025. doi: https://doi.org/10.1002/advs. 202408629. URL https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/ advs.202408629. [13] Ruoqian Lin, Rui Zhang, Chunyang Wang, Xiao-Qing Yang, and Huolin Xin. Temimagenet and atomsegnet deep learning training library and models for high-precision atom segmentation, localization, denoising, and super-resolution processing of atom-resolution scanning tem images. arXiv e-prints, page arXiv: 2012.09093, 2020. [14] Ruoqian Lin, Rui Zhang, Chunyang Wang, Xiao-Qing Yang, and Huolin Xin. Temimagenet training library and atomsegnet deep-learning models for high-precision atom segmentation, localization, denoising, and deblurring of atomic-resolution images. Scientific reports, 11(1): 5386, 2021. ISSN 2045-2322. [15] Feng Wang, Trond Henninen, Debora Keller, and Rolf Erni. Noise2atom: unsupervised denoising for scanning transmission electron microscopy images. Applied Microscopy, 50(1): 23, 2020. ISSN 2287-4445. [16] M. Ziatdinov, O. Dyck, A. Maksov, X. Li, X. Sang, K. Xiao, R. R. Unocic, R. Vasudevan, S. Jesse, and S. V. Kalinin. Deep learning of atomically resolved scanning transmission electron microscopy images: Chemical identification and tracking local transformations. ACS Nano, 11 (12):1274212752, 2017. ISSN 1936-086X (Electronic) 1936-0851 (Linking). doi: 10.1021/ acsnano.7b07504. URL https://www.ncbi.nlm.nih.gov/pubmed/29215876. Ziatdinov, Maxim Dyck, Ondrej Maksov, Artem Li, Xufan Sang, Xiahan Xiao, Kai Unocic, Raymond Vasudevan, Rama Jesse, Stephen Kalinin, Sergei eng Research Support, Non-U.S. Govt 2017/12/08 ACS Nano. 2017 Dec 26;11(12):12742-12752. doi: 10.1021/acsnano.7b07504. Epub 2017 Dec 14. [17] Ishraque Zaman Borshon, Marco Ragone, Abhijit Phakatkar, Lance Long, Reza ShahbazianYassar, Farzad Mashayek, and Vitaliy Yurkiv. Predicting column heights and elemental composition in experimental transmission electron microscopy images of high-entropy oxides using deep learning. npj Computational Materials, 10(1):275, 2024. [18] Henrik Eliasson and Rolf Erni. Localization and segmentation of atomic columns in supported nanoparticles for fast scanning transmission electron microscopy. npj Computational Materials, 10(1):168, 2024. 11 [19] Annick De Backer, Sandra Van Aert, Christel Faes, Ece Arslan Irmak, Peter Nellist, and Lewys Jones. Experimental reconstructions of 3d atomic structures from electron microscopy images using bayesian genetic algorithm. npj Computational Materials, 8(1):216, 2022. [20] Tom Stoops, Annick De Backer, Ivan Lobato, and Sandra Van Aert. Obtaining 3d atomic reconstructions from electron microscopy images using bayesian genetic algorithm: Possibilities, insights, and limitations. Microscopy and Microanalysis, 31(1):ozae090, 2025. [21] Wenqiang Huang, Yucheng Jin, Zhemin Li, Lin Yao, Yun Chen, Zheng Luo, Shen Zhou, Jinguo Lin, Feng Liu, Zhifeng Gao, et al. Auto-resolving the atomic structure at van der waals interfaces using generative model. Nature Communications, 16(1):2927, 2025. [22] J. Li, M. Telychko, J. Yin, Y. Zhu, G. Li, S. Song, H. Yang, J. Li, J. Wu, J. Lu, and X. Wang. Machine vision automated chiral molecule detection and classification in molecular imaging. Am Chem Soc, 143(27):1017710188, 2021. ISSN 1520-5126 (Electronic) 0002-7863 (Linking). doi: 10.1021/jacs.1c03091. URL https://www.ncbi.nlm.nih.gov/pubmed/34227379. Li, Jiali Telychko, Mykola Yin, Jun Zhu, Yixin Li, Guangwu Song, Shaotang Yang, Haitao Li, Jing Wu, Jishan Lu, Jiong Wang, Xiaonan eng Research Support, Non-U.S. Govt 2021/07/07 Am Chem Soc. 2021 Jul 14;143(27):10177-10188. doi: 10.1021/jacs.1c03091. Epub 2021 Jul 6. [23] Artem Maksov, Ondrej Dyck, Kai Wang, Kai Xiao, David Geohegan, Bobby Sumpter, Rama Vasudevan, Stephen Jesse, Sergei Kalinin, and Maxim Ziatdinov. Deep learning analysis of defect and phase evolution during electron beam-induced transformations in ws2. npj Computational Materials, 5(1):12, 2019. ISSN 2057-3960. [24] Laura Gambini, Tiarnan Mullarkey, Lewys Jones, and Stefano Sanvito. Machine-learning approach for quantified resolvability enhancement of low-dose stem data. Machine Learning: Science and Technology, 4(1), 2023. ISSN 2632-2153. doi: 10.1088/2632-2153/acbb52. [25] Shiro Ihara, Hikaru Saito, Mizumo Yoshinaga, Lavakumar Avala, and Mitsuhiro Murayama. Deep learning-based noise filtering toward millisecond order imaging by using scanning transmission electron microscopy. Scientific reports, 12(1):13462, 2022. ISSN 2045-2322. [26] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. [27] Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, et al. Qwen2. 5-vl technical report. arXiv preprint arXiv:2502.13923, 2025. [28] Maxim Ziatdinov, Ayana Ghosh, Chun Yin Wong, and Sergei Kalinin. Atomai framework for deep learning analysis of image and spectroscopy data in electron and scanning probe microscopy. Nature Machine Intelligence, 4(12):11011112, 2022. [29] Sten Haastrup, Mikkel Strange, Mohnish Pandey, Thorsten Deilmann, Per Schmidt, Nicki Hinsche, Morten Gjerding, Daniele Torelli, Peter Larsen, Anders Riis-Jensen, et al. The computational 2d materials database: high-throughput modeling and discovery of atomically thin crystals. 2D Materials, 5(4):042002, 2018. [30] Anubhav Jain, Shyue Ping Ong, Geoffroy Hautier, Wei Chen, William Davidson Richards, Stephen Dacek, Shreyas Cholia, Dan Gunter, David Skinner, Gerbrand Ceder, et al. Commentary: The materials project: materials genome approach to accelerating materials innovation. APL materials, 1(1), 2013. [31] Antanas Vaitkus, Andrius Merkys, Thomas Sander, Miguel Quirós, Paul A. Thiessen, Evan E. Bolton, and Saulius Gražulis. workflow for deriving chemical entities from crystallographic data and its application to the Crystallography Open Database. Journal of Cheminformatics, 15(1), Dec 2023. doi: 10.1186/s13321-023-00780-2. URL https://doi.org/10.1186/ s13321-023-00780-2. [32] Jacob Madsen and Toma Susi. abtem: Ab initio transmission electron microscopy image simulation. Microscopy and Microanalysis, 26(S2):448450, 2020. 12 [33] Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Yaotian Yang, Xinrui Xiong, et al. Chemvlm: Exploring the power of multimodal large language models in chemistry area. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 415423, 2025. [34] Andres Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew White, and Philippe Schwaller. Chemcrow: Augmenting large-language models with chemistry tools, 2023. URL https://arxiv.org/abs/2304.05376. [35] Xiangru Tang, Tianyu Hu, Muyang Ye, Yanjun Shao, Xunjian Yin, Siru Ouyang, Wangchunshu Zhou, Pan Lu, Zhuosheng Zhang, Yilun Zhao, Arman Cohan, and Mark Gerstein. Chemagent: Self-updating library in large language models improves chemical reasoning, 2025. URL https://arxiv.org/abs/2501.06590. [36] Chi Chen and Shyue Ping Ong. universal graph deep learning interatomic potential for the periodic table. Nature Computational Science, 2(11):718728, 2022. [37] Ilyes Batatia, Dávid Péter Kovács, Gregor N. C. Simm, Christoph Ortner, and Gábor Csányi. Mace: Higher order equivariant message passing neural networks for fast and accurate force fields, 2023. URL https://arxiv.org/abs/2206.07697. [38] Zoey Guo, Yiwen Tang, Ray Zhang, Dong Wang, Zhigang Wang, Bin Zhao, and Xuelong Li. Viewrefer: Grasp the multi-view knowledge for 3d visual grounding. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1537215383, 2023. [39] Yiwen Tang, Ray Zhang, Jiaming Liu, Zoey Guo, Bin Zhao, Zhigang Wang, Peng Gao, Hongsheng Li, Dong Wang, and Xuelong Li. Any2point: Empowering any-modality large models for efficient 3d understanding. In European Conference on Computer Vision, pages 456473. Springer, 2024. [40] Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, et al. Exploring the potential of encoder-free architectures in 3d lmms. arXiv preprint arXiv:2502.09620, 2025."
        }
    ],
    "affiliations": [
        "Department of Chemical Engineering, Tsinghua University, Beijing, China",
        "School of Computer Science, Northwestern Polytechnical University, Xian, China",
        "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
    ]
}