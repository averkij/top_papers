{
    "paper_title": "Benchmarking Temporal Reasoning and Alignment Across Chinese Dynasties",
    "authors": [
        "Zhenglin Wang",
        "Jialong Wu",
        "Pengfei LI",
        "Yong Jiang",
        "Deyu Zhou"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Temporal reasoning is fundamental to human cognition and is crucial for various real-world applications. While recent advances in Large Language Models have demonstrated promising capabilities in temporal reasoning, existing benchmarks primarily rely on rule-based construction, lack contextual depth, and involve a limited range of temporal entities. To address these limitations, we introduce Chinese Time Reasoning (CTM), a benchmark designed to evaluate LLMs on temporal reasoning within the extensive scope of Chinese dynastic chronology. CTM emphasizes cross-entity relationships, pairwise temporal alignment, and contextualized and culturally-grounded reasoning, providing a comprehensive evaluation. Extensive experimental results reveal the challenges posed by CTM and highlight potential avenues for improvement."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 2 ] . [ 1 2 2 9 6 1 . 2 0 5 2 : r a"
        },
        {
            "title": "Benchmarking Temporal Reasoning and Alignment Across Chinese\nDynasties",
            "content": "Zhenglin Wang*, Jialong Wu, Pengfei Li, Yong Jiang, Deyu Zhou School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, China Tongyi Lab, Alibaba Group {zhenglin, jialongwu, d.zhou}@seu.edu.cn"
        },
        {
            "title": "Abstract",
            "content": "Temporal reasoning is fundamental to human cognition and is crucial for various real-world applications. While recent advances in Large Language Models have demonstrated promising capabilities in temporal reasoning, existing benchmarks primarily rely on rule-based construction, lack contextual depth, and involve limited range of temporal entities. To address these limitations, we introduce Chinese Time Reasoning (CTM), benchmark designed to evaluate LLMs on temporal reasoning within the extensive scope of Chinese dynastic chronology. CTM emphasizes cross-entity relationships, pairwise temporal alignment, and contextualized and culturally-grounded reasoning, providing comprehensive evaluation. Extensive experimental results reveal the challenges posed by CTM and highlight potential avenues for improvement."
        },
        {
            "title": "Introduction",
            "content": "究天人之际通古今之变 司马迁史记报任安书 Figure 1: QA pair from script error correction task and an instance of the Timeline Ito Game with fruit size theme from CTM. 2 Understanding time is fundamental to human cognition and plays pivotal role in shaping our perception and interaction with the world (Islakoglu and Kalo, 2025). Recently, Large Language Models (LLMs)have shown promising abilities in temporal reasoning (Chu et al., 2024; Su et al., 2024). Previous benchmarks, which rely on rule-based constructed methods, lack contextualization and involve limited number of entities in temporal relation evaluation. The core principle in assessing temporal reasoning lies in evaluating whether the model has clear understanding of the event * Equal Contribution. The work was partially done during Jialongs internship at Alibaba Group. Corresponding Author. 1Code and dataset are available at https://github.com/ Linking-ai/ctm_bench 2The English translation is presented in App. B.2. time within temporal coordinate system. Compared to other temporal coordinate systems, the Chinese dynastic chronology spans significantly longer historical scope and encompasses broader range of culturally-grounded and historical knowledge (Sun et al., 2024; Li et al., 2024b; Yuan et al., 2024; Lu et al., 2024). It serves as well-suitable background for temporal reasoning, as real-world applications can be found in various media, including films, short dramas, and novel writing, all of which rely on it. Therefore, we introduce Chinese Time Reasoning (CTM) benchmark in this study. The comparison between CTM and other benchmarks is shown in Table 1. CTM focuses on contextualization, cross-entity relationships, and pair-wise temporal alignment capability. As shown in Figure 1, anTable 1: Comparison between CTM and other benchmarks. Detailed discussion is presented in Appendix A."
        },
        {
            "title": "Temporal Alignment Complex Aspects",
            "content": "TIMEQA (2021) TEMPLAMA (2022) TEMPREASON (2023) SITUATEDGEN (2023) COTEMPQA (2024) TIMEBENCH (2024) TRAM (2024) CHRONOSENSE (2025) CTM"
        },
        {
            "title": "En\nEn\nEn\nEn\nEn\nEn\nEn\nEn\nZh",
            "content": "Rule-based Rule-based Rule-based LLM-based Rule-based - Rule-based Rule-based LLM-based 13672018 20102020 6342023 - - - - - -21001912 swering this question requires clear temporal understanding of four entities, 李白 (701 to 762), 白居易 (772 to 826), 古琴 (Since Pre-Qin), and 辣椒 (Since Ming). In addition, we develop the Timeline Ito Game to evaluate the LLMs ability to align entities across temporal and other dimensions, requiring pairwise order perception of different entities. The CTM benchmark is built upon curated and authoritative Chinese cultural entity repository, which encompasses over 4,700 entities, spanning from figures, places, allusions, ingredients, and intangible cultural heritage. We evaluate the performance of the CTM benchmark using various mainstream LLMs, including both closed-source and open-sourced from diverse perspectives. We conduct experiments under both zero-shot and chain-of-thought (CoT) settings (Wei et al., 2022), respectively. Further analysis shows the challenge of CTM and provides empirical insights into enhancing LLMs temporal reasoning abilities and alignment across Chinese dynasties. The contributions of this work are as follows: 1). We construct an interesting and challenging benchmark CTM, comprising 8,750 QA pairs and 60 instances of Timeline Ito Games. 2). We conduct extensive empirical experiments with various LLMs, which show that the proposed tasks are challenging. 3). Analysis of the experiments further reveals potential directions for addressing temporal reasoning tasks."
        },
        {
            "title": "2.1 Task Definition",
            "content": "Question-Answering We design the below eight challenging tasks using the Question-Answering format: (i) Entity-based Dynasty Determination (EDD): infer the historical dynasty of given entity based on contextual information. (ii) Plausibility Judgment (PJ): assess whether described historical scenario is plausible by reasoning about temporal and factual consistency. (iii) Temporal Order Understanding (TOU): understand and compare the chronological order of historical events or figures. (iv) Relation Reasoning (RR): reason about the historical relationships between entities, such as their spatial, temporal, or functional connections. (v) Script Error Correction (SEC): identify and correct historical inaccuracies in visual or textual narratives. (v) Entity Evolution Understanding (EEU): track and understand the evolution of entity names or attributes across different historical periods. (vi) Time Interval Calculation (TIC): calculate the temporal gap between historical entities or events. (vii) Temporal Entity Selection (TES): select the correct historical entity based on temporal and contextual constraints. viii Long Script Error Correction (LSEC): identify and correct complex historical inaccuracies in long narratives by reasoning across extended contexts. The key aspect of these task designs is to examine LLMs ability to accurately perceive and reason about temporal relationships in structured manner.3 Timeline Ito Game Our developed Timeline Ito Game is collaborative reasoning game where agents infer the chronological order of historical entities within dynasty timeline using thematic metaphors. As shown in Figure 1, the rules can be divided into the following steps: Step1: Describe Card: Agents describe their assigned historical entity using given theme without explicit temporal references. Step2: Infer Rank: Agents collaboratively deduce their relative positions in the timeline based on shared contexts. Step3: Determine Order: Each Agent sequentially predicts their position in the timeline relative to the others, and the teams final order is based on these individual predictions. The game ends when the teams predicted order matches the true chronological sequence or when the maximum number of rounds, K, is reached. 3Each tasks examples are presented in App. F.1. 4We present running case in App. F.2. 2 Table 2: Main results on QA tasks within CTM benchmark. The best results among all backbones are bolded, and the second-best results are underlined. Method = 1 (EDD) = 2 = 4 4L (LSEC) PJ TOU RR SEC EEU TIC TES Avg. Cross Temp Count Question Type Closed-Sourced LLMs GPT-4o + CoT 56.52 51.12 44.76 26.10 67.40+10.88 58.08+6.96 49.24+4.48 29.60+3. 53.60 31.60-22.0 58.64 38.42 57.26 36.15 40. 15.36 59.31 48.08 64.10+5.46 44.71+6.29 59.62+2.36 47.09+10.94 44.06+3.48 17.70+2.34 61.68+2.37 54.21+6.13 Qwen-max + CoT 60. 53.12 50.54 30.80 69.56+9.08 59.32+6.20 54.48+3.94 31.90+1.10 62.00 39.60-22.40 64. 42.55 59.10 40.71 46.38 20.87 60. 52.27 63.29-1.10 48.58+6.03 63.75+4.65 55.77+15.06 53.91+7.53 15.19-5.68 63.14+2.92 57.24+4.97 o1-preview 52.80 46.56 49. 32.70 67.20 58.28 44.28 53.01 43. 40.87 11.02 56.02 48.24 Open-Sourced LLMs LLaMA3.18b + CoT 33.04 16.86 15.60 9.10 35.05+2.01 26.44+9.58 19.96+4.36 10.70+1.60 10.80 12.40+1. 19.66 12.95 18.65 7.37 0.87 2. 37.04 20.14 26.48+6.82 19.55+6.60 23.20+4.55 20.02+12.65 15.70+14.83 5.51+3.50 34.37-2.67 24.91+4.77 ChatGLM36b + CoT 38.40 21. 16.04 5.80 37.24-1.16 22.72+1.12 15.28-0.76 8.20+2.40 4.80 4.00-0.80 21.40 12. 22.67 12.25 12.75 1.84 35.58 22. 20.32-1.08 15.92+3.64 20.12-2.55 14.98+2.73 16.52+3.77 3.01+1.17 29.74-5.84 22.61+0.09 InternLM2.57b + CoT 60.64 47.32 39.36 21. 61.44+0.80 51.40+4.08 39.36+0.00 20.20-1.40 Qwen2.57b + CoT Qwen2.514b + CoT Qwen2.532b + CoT Qwen2.572b + CoT 51. 39.88 35.96 12.40 59.96+8.16 47.60+7.72 36.64+0.68 18.30+5.90 54.36 51. 42.56 23.80 57.92+3.56 45.44-5.72 41.24-1.32 22.50-1.30 56.28 52.78 46. 26.90 60.80+4.52 49.32-3.46 45.32-0.92 24.80-2.10 58.20 48.76 46.84 31. 69.00+10.80 57.24+8.48 49.88+3.04 32.50+1.20 42.00 38.00-4.00 30.00 30.80+0.80 42.00 30.80-11.20 46.40 31.20-15.20 60.80 46.00-14. 51.39 30.16 48.64 45.78 42.61 11. 50.18 45.75 51.70+0.31 31.45+1.29 49.47+0.83 52.86+7.08 44.19+1.58 11.52+0.33 48.54-1.64 46.90+1.15 46.28 26.38 46. 24.14 36.23 7.35 52.01 38.76 52.46+6.18 29.95+3.57 52.18+5.90 34.13+9.99 40.58+4.35 8.18+0.83 49.64-2.37 44.22+5. 57.44 36.86 51.83 36.90 39.07 18. 58.58 46.32 52.73-4.71 34.36-2.50 46.52-5.31 42.57+5.67 36.81-2.26 10.02-8.24 51.82-6.76 44.89-1.43 60.66 38.54 56. 39.12 43.77 20.10 60.04 48.83 50.67-9.99 40.65+2.11 51.12-5.67 43.40+4.28 40.29-3.48 17.03-3.07 57.12-2.92 48.14-0. 61.38 40.77 54.31 36.62 42.03 11. 62.23 49.30 61.50+0.12 45.01+4.24 61.51+7.20 50.18+13.56 49.86+7.83 17.53+6.01 59.85-2.38 55.39+6.09 Deepseek-R1 70.84 67. 60.64 45.50 72.40 76.63 58.17 67. 59.69 61.16 24.37 67.70 64.02 Figure 2: Statistic of CTM."
        },
        {
            "title": "2.2 Data Collection",
            "content": "Source We construct comprehensive entity information repository by collecting diverse data from multiple authoritative sources, e.g., Gushiwen , CBDB , CHGIS , Wikipedia , and Ihchina . The historical dynasties are simplified into ten major periods based on Allhistory and CHINATimeline of Historical Periods, specifically: 先秦, 汉, 六朝, 隋, 唐, 五代, 宋, 元, 明, 清. The entity repository contains 1,652 figures (with attributes such as birth address, birth year, death year, and associated books or sentences), 2,907 places (including 990 primary administrative regions and 1,917 subordinate localities), 93 allusions, 49 ingredients, and 44 intangible cultural heritage items. Annotation Process The annotation process is structured into three key steps to ensure systematic and high-quality data generation: seed prompt creation, entity-aware data generation, and validation and quality control.5 The process sysFigure 3: Average performance of Itos Guessing Game. Detailed results can be found in Appendix I. tematically generates annotated data while aligning with the repositorys structured knowledge. The statistics of CTM on the task are shown in Figure 2."
        },
        {
            "title": "2.3 Evaluation",
            "content": "We use the accuracy metric to evaluate the QA tasks while Pass@K is used to evaluate Itos Guessing Game. Due to the varying lengths of LLM-generated text, it is challenging to perform exact match evaluation. We use GPT-4o as the evaluator6, which determines the correctness of responses by comparing the prediction with the ground truth using the CoT (Wei et al., 2022). Pass@K measures whether the sequential alignment is achieved within attempts, we set to 3 and 8."
        },
        {
            "title": "3 Experiments",
            "content": "Backbones We evaluate twelve mainstreaming LLMs, the complete list of models is in App. G. 5The details of each step are provided in the App. E. 6The prompt for the evaluator is provided in Appendix H. 3 Figure 4: Accuracy across entity inter-dynastic intervals under direct prompting setting. The detailed results are shown in Figure 23, Figure 24 and Figure 25."
        },
        {
            "title": "3.1 Main Results",
            "content": "Table 2 and Figure 2 present the experimental results of QA and Itos Guessing Game, respectively. We observe the following empirical findings: (I) The more entities considered, the worse the performance, and Time Interval Calculation (TIC) is the most challenging task. The former requires identifying the temporal information of multiple entities, while the latter demands more (II) precise assessment of specific timestamps. CoT can enhance performance, however, when the LLM is very small or the context is excessively long, it can even negatively impact temporal reasoning tasks. This aligns with the conclusions of work (Chu et al., 2024) and may be attributed to the knowledge sensitivity inherent in temporal reasoning. (III) InternLM2.5 demonstrates strong performance among small open-source models, which may be attributed to the quality and composition of its training data. (IV) The reasoning model demonstrates remarkably strong performance. (V) Temporal alignment is highly challenging, and even powerful model GPT-4o fail to exceed 40 on the Pass@8 metric. (VI) Small LLMs cannot align entities across different dimensions, and the Pass@K performance for LLMs smaller than 32B does not exceed 10. Figure 5: Performance in the close-book and open-book settings. Detailed results can be found in App. J. In the open-book setting, temporal reasoning performance can be moderately improved. To obtain more precise temporal information about entities, we can leverage search engines to retrieve relevant information from the web, enhancing the specificity of entity details (Wu et al., 2025). In the open-book setting, we use the titles and snippets of the Top-10 webpages retrieved via Google search as retrieval-augmented information. As shown in Figure 5, it can be observed that performance improves after incorporating the retrieved content, except for Qwen2.5-7B, possibly due to its weaker longe contextual understanding."
        },
        {
            "title": "3.2 Analysis",
            "content": "The shorter the time interval between the entities, the greater the difficulty. As illustrated in Figure 4, we evaluate performance across various models based on entity inter-dynastic intervals. For example, an interval of 1 indicates adjacent dynasties, while an interval of 0 represents the same dynasty. As the interval decreases, performance declines. This is because reasoning in QA tasks requires clear understanding of the temporal relationships between entities, with closer intervals demanding more precise examination. We introduce CTM, benchmark designed to evaluate LLMs on temporal reasoning and alignment across Chinese dynasties. CTM benchmark emphasizes contextualization, cross-entity relationships, and temporal alignment. Empirical evaluations on various LLMs reveal the challenges posed by CTM, demonstrating that existing LLMs struggle with nuanced temporal understanding. These findings through analysis suggest the need for improved pretraining, structured knowledge integration, and refined reasoning mechanisms. CTM provides culturally rich resource for advancing temporal reasoning research."
        },
        {
            "title": "Limitations",
            "content": "Prompt Design and Evaluation Settings This study evaluates the performance of LLMs on CTM using various prompts, including the most common settings of direct prompting and chain-of-thought (CoT). However, it is acknowledged that the effectiveness of these prompts may vary across different tasks and models. Future work could explore the possibility of dynamically adapting prompt designs to better suit specific temporal reasoning tasks, as well as expanding to more diverse few-shot and zero-shot settings. As LLMs continue to evolve, it will be crucial to periodically update prompt strategies to ensure robust and comprehensive evaluation. Dataset Scale and Coverage While CTM currently includes diverse range of Chinese temporal reasoning tasks, there is significant potential for expanding both its size and coverage. With 8,750 examples already developed, the dataset can be further enriched with larger and more complex temporal scenarios, as well as longer historical events and broader range of question types. Additionally, the timeline Ito game data could be expanded to incorporate more intricate details and interesting themes, providing greater challenges for models and revealing their strengths and limitations."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Ting Bai, Jiazheng Kang, and Jiayang Fan. 2024. Baijia: large scale role-playing agent corpus of chinese historical charcaters. arXiv preprint arXiv:2412.20024. Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, et al. 2024. Internlm2 technical report. arXiv preprint arXiv:2403.17297. Wenhu Chen, Xinyi Wang, and William Yang Wang. 2021. dataset for answering timeIn Thirty-fifth Conference on sensitive questions. Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Haotian Wang, Ming Liu, and Bing Qin. 2024. TimeBench: comprehensive evaluation of temporal reasoning abilities in large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12041228, Bangkok, Thailand. Association for Computational Linguistics. Bhuwan Dhingra, Jeremy R. Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, and William W. Cohen. 2022. Time-aware language models as temporal knowledge bases. Transactions of the Association for Computational Linguistics, 10:257 273. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Dan Zhang, Diego Rojas, Guanyu Feng, Hanlin Zhao, et al. 2024. Chatglm: family of large language models from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793. Duygu Sezen Islakoglu and Jan-Christoph Kalo. 2025. Chronosense: Exploring temporal understanding in large language models with time intervals of events. arXiv preprint arXiv:2501.03040. Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and Timothy Baldwin. 2024a. CMMLU: Measuring massive multitask language understanding in Chinese. In Findings of the Association for Computational Linguistics: ACL 2024, pages 1126011285, Bangkok, Thailand. Association for Computational Linguistics. Wenyan Li, Crystina Zhang, Jiaang Li, Qiwei Peng, Raphael Tang, Li Zhou, Weijia Zhang, Guimin Hu, Yifei Yuan, Anders Søgaard, Daniel Hershcovich, and Desmond Elliott. 2024b. FoodieQA: multimodal dataset for fine-grained understanding of Chinese food culture. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 1907719095, Miami, Florida, USA. Association for Computational Linguistics. Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, and Huajun Chen. 2024. Benchmarking chinese knowledge rectification in large language models. arXiv preprint arXiv:2409.05806. Dan Shi, Chaobin You, Jiantao Huang, Taihao Li, and Deyi Xiong. 2024. Corecode: common sense annotated dialogue dataset with benchmark tasks for chinese large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 1895218960. Zhaochen Su, Juntao Li, Jun Zhang, Tong Zhu, Xiaoye Qu, Pan Zhou, Yan Bowen, Yu Cheng, and Min Zhang. 2024. Living in the moment: Can large language models grasp co-temporal reasoning? In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1301413033, Bangkok, Thailand. Association for Computational Linguistics. 5 Jiaxing Sun, Weiquan Huang, Jiang Wu, Chenya Gu, Wei Li, Songyang Zhang, Hang Yan, and Conghui He. 2024. Benchmarking Chinese commonsense reasoning of LLMs: From Chinesespecifics to reasoning-memorization correlations. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1120511228, Bangkok, Thailand. Association for Computational Linguistics. Qingyu Tan, Hwee Tou Ng, and Lidong Bing. 2023. Towards benchmarking and improving the temporal reasoning capability of large language models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1482014835, Toronto, Canada. Association for Computational Linguistics. Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford_alpaca. Yuqing Wang and Yun Zhao. 2024. TRAM: Benchmarking temporal reasoning for large language models. In Findings of the Association for Computational Linguistics: ACL 2024, pages 63896415, Bangkok, Thailand. Association for Computational Linguistics. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837. Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Deyu Zhou, Pengjun Xie, and Fei Huang. 2025. Webwalker: Benchmarking llms in web traversal. arXiv preprint arXiv:2501.07572. An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. 2024. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115. Jiahao Yuan, Zixiang Di, Shangzixin Zhao, and Usman Naseem. 2024. Cultural palette: Pluralising culture alignment via multi-agent palette. arXiv preprint arXiv:2412.11167. Yunxiang Zhang and Xiaojun Wan. 2023. Situatedgen: Incorporating geographical and temporal contexts into generative commonsense reasoning. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track."
        },
        {
            "title": "A Related Works",
            "content": "Chinese Cultural Understanding in LLMs Recent advancements in LLMs have shown promise in cultural understanding tasks, with some studies specifically evaluating their performance in Chinese culture, including assessments of commonsense knowledge (Shi et al., 2024; Sun et al., 2024; Li et al., 2024a), foodie culture (Li et al., 2024b), and historical knowledge (Bai et al., 2024). As one of the worlds longest-standing cultures, Chinese culture spans vast historical timeline, with each dynasty rich in historical figures, anecdotes, and cultural narratives. Its strong cultural attributes also allow for effective contextualization. This makes dynastic timelines particularly well-suited for temporal reasoning and alignment in our work. Temporal Reasoning in LLMs Temporal reasoning is critical capability for LLMs, with existing benchmarks focusing on factual temporal grounding (Chen et al., 2021; Dhingra et al., 2022), complex temporal logic (Tan et al., 2023; Su et al., 2024), and multi-granular temporal awareness (Chu et al., 2024; Islakoglu and Kalo, 2025). As shown in Table 1, these benchmarks are primarily English-based and rely on rule-based dataset construction, which limits contextualization and diversity. In contrast, CTM is grounded in Chinese culture and leverages LLM-based question generation, resulting in more flexible and contextually relevant questions. Our benchmark also features broader range of tasks to access the reasoning and alignment of LLMs and ensures more accurate entity assessments that require nuanced temporal understanding."
        },
        {
            "title": "B English Translations",
            "content": "The following is scene description containing one or more anachronisms that do not align with historical accuracy. Please identify them: 李白在创作将进酒时白居易在一旁 吟诗同时桌上摆着一盘辣椒旁边还有 一位乐师在演奏古琴 While Li Bai is composing Bring in the Wine, Bai Juyi is reciting poetry beside him. On the table, there is plate of chili peppers, and musician is playing the guqin art nearby. A. 穿帮内容: Anachronisms: 1. 李白去世时762 CE白居易还未出 生772 CE两人不可能同时在场 When Li Bai passed away (762 CE), Bai Juyi had not yet been born (772 CE), making it impossible for them to be present together. 2. 古琴艺术在唐朝时已非常成熟符合 历史背景 Guqin Art was already well-developed during the Tang Dynasty, which aligns with the historical context. 3. 辣椒在明朝才传入中国不可能出现 在唐朝 Chili peppers were not introduced to China until the Ming Dynasty, so they could not have appeared during the Tang Dynasty."
        },
        {
            "title": "C Statistics of CTM",
            "content": "The statistics of CTM on tasks are shown in Table 3. Table 3: The statistics of CTM. Question-Answering B.1 Ten Major Dynasties and Corresponding Statistic EDD PJ TOU # Sample 2500 1117 RR 847 SEC EEU TIC TES LSEC 841 345"
        },
        {
            "title": "Period",
            "content": "先 秦(Pre-Qin) (-2100 to -206), 汉(Han) (- 206 to 220), 六 朝 (Six Dynasties) (220 to 589), 隋Sui (581 to 618), 唐(Tang) (618 to 906), 五 代(Five Dynasties) (907 to 960), 宋(Song) (960 to 1279), 元(Yuan) (1279 to 1368), 明(Ming) (1368 to 1644), 清(Qing) (1644 to 1912). Cross Temp Count 1 2, 3, 4..10 Statistic # Sample Cross Temp Count Agent Num Easy 20 3 Timeline Ito Game Medium Hard 20 4 20"
        },
        {
            "title": "D Entity Repository",
            "content": "250 4..15 B.2 Translated QA Pair Q. 以下是一段镜头描述其中有一处或多 处不遵循真实历史背景的穿帮内容请指 出: Figure 6, Figure 7, Figure 8, Figure 9 and Figure 10 show the case of historical figure, place, event, ingredient and intangible cultural heritage, respectively. 7 Historical Figure ## JSON Format { \"屈原\": { \"dynasty\": \"先秦\", \"address\": \"楚国丹阳秭归今湖北宜 昌\", \"year_birth\": \"-340\", \"year_death\": \"-278\", \"book_and_sentences\": [ { \"sentence\": \"身既死兮神以灵 魂魄毅兮为鬼雄\", \"book\": \"国殇\" }, { \"sentence\": \"路曼曼其修远兮 吾将上下而求索\", \"book\": \"离骚\" }, # ... ] }, # ... } Intangible Cultural Heritage ## JSON Format { \"昆曲\": { \"dynasty\": \"明\", \"place\": \"北京, 上海, 江苏省, 浙江 省, 湖南省\", \"type\": \"表演艺术\" }, # ... } Figure 10: JSON-format case for intangible cultural heritage entity."
        },
        {
            "title": "E Annotation",
            "content": "Figure 6: JSON-format case for historical figure entity. Place ## JSON Format { \"巴州\": { \"dynasty\": \"唐\", \"id\": \"hvd_111423\", \"begin\": \"758\", \"end\": \"762\", \"pre_address\": \"四川省巴中市\", \"subordinate_units\": [ { \"begin_year\": \"758\", \"end_year\": \"762\", \"child_id\": \"hvd_44640\", \"name\": \"七盘县\", \"pre_address\": \"今四川巴中县西北一 百二十里今旺苍县东南\" }, # ... ] } #... } Figure 7: JSON-format case for place entity. Event ## JSON Format { \"司马迁写史记\": { \"id\": \"070\", \"dynasty\": \"汉\", \"main_figures\": \"司马迁\" }, # ... } Step1: Seed Prompt Creation: For each entity type, we manually design seed prompts (Taori et al., 2023) to guide the selfinstruct-based data generation process. These prompts serve as templates to ensure diversity and relevance in the generated data. Step2: Entity-Aware Data Generation: During LLM-based generation, the LLMs dynamically incorporate entity descriptions sampled from the pre-constructed entity information repository. This ensures that the generated content is contextually grounded in the repositorys structured knowledge, enhancing control over entity-related information. Step3: Validation and Quality Control: After generation, each data point undergoes validation step, where the temporal entities mentioned in the output are cross-referenced with the repository. This ensures the accuracy and consistency of the entities, aligning the generated data with the repositorys constraints."
        },
        {
            "title": "F Cases",
            "content": "Figure 8: JSON-format case for event entity. F.1 Cases in Question-Answering Ingredient ## JSON Format { \"水稻\": { \"dynasty\": \"先秦\", \"origin\": \"中国\" }, # ... } Figure 9: JSON-format case for ingredient entity. 8 Figure 11, Figure 12, Figure 13, Figure 14, Figure 15, Figure 16, Figure 17, Figure 18, and Figure 19 show the Entity-based Dynasty Determination, Plausibility Judgment, Temporal Order Understanding, Relation Reasoning, Script Error Correction, Entity Evolution Understanding, Time Interval Calculation, Temporal Entity Selection and Long Script Error Correction tasks in JSON-format, respectively. Entity-based Dynasty Determination (EDD) Entity Evolution Understanding (EEU) ## JSON Format { \"type\": \"根据食材确定传入朝代\", \"question\": \"假设你穿越到某个朝代听商 贩说辣椒是最近几年才有的食材你能推测你 穿越到了哪个朝代吗\", \"temporal_entities\": [\"辣椒\"], \"construct_explanation\": \"这个问题通过 穿越情境让提问者推测辣椒的引入时间辣 椒最早于明朝从美洲传入中国因此问题涉 及1个时空实体-朝代关系辣椒传入中国的朝 代是明\", \"answer\": \"明\" } ## JSON Format { \"type\": \"实体名称变迁\", \"question\": \"在唐朝的浈州内今日的四会 县在当时名为何\", \"temporal_entities\": [\"浈州\", \"四会县\"], \"construct_explanation\": \"唐朝时期存在 的 浈 州 公 元634年 至638年 包 含 今 日 的 四 会县根据历史资料此时四会县作为浈州 的下属地方在唐朝已经是现名四会县因 此问题涉及2个时空实体-地方名称关系浈 州-唐 及四会县-唐从历史上来看当时 的四会县没有变更过名称\", \"answer\": \"四会县\" } Figure 11: JSON-format case in EDD type of QA. Figure 15: JSON-format case in EEU type of QA. Plausibility Judgment (PJ) ## JSON Format { \"type\": \"合理性判断\", \"question\": \"苏轼是眉州人眉州是今四川 眉山市而四川以麻辣闻名那么苏轼是否 吃辣\", \"temporal_entities\": [\"苏轼\", \"眉州\", \"辣 椒\"], \"construct_explanation\": \"苏轼生活在宋 代约公元1037年-1101年辣椒最早于明朝 传入中国因此问题涉及3个时空实体-朝代关 系苏轼-宋眉州-宋和辣椒-明通过 时间线推理苏轼生活的时代不可能接触到辣 椒\", \"answer\": \"否\" } Relation Reasoning (RR) ## JSON Format { \"type\": \"关系判断\", \"question\": \"虞州和河东郡在历史上有什么 关系\", \"temporal_entities\": [\"虞州\", \"河东郡\"], \"construct_explanation\": \"虞州和河东郡 在历史上的行政区划大致对应现在的山西运 城河东郡是古代的一个重要行政区划虞州 则是后来的行政区划因此问题涉及2个时空实 体-朝代关系虞州-隋和河东郡-先秦两 者在地理位置上与现代的山西运城有较高的重 合度\", \"answer\": \"都为现山西运城\" } Figure 12: JSON-format case in PJ type of QA. Figure 14: JSON-format case in RR type of QA. Temporal Order Understanding (TOU) ## JSON Format { \"type\": \"时间顺序理解\", \"question\": \"请将以下实体按时间顺序排 列屈原李白白居易辣椒古琴艺术 石榴\", \"temporal_entities\": [\"屈原\", \"李白\", \"白 居易\", \"辣椒\", \"古琴艺术\", \"石榴\"], \"construct_explanation\": \"屈原生活在先 秦 约 公 元 前340年-公 元 前278年 李 白 生 活在唐代约公元701年-762年白居易生活 在唐代约公元772年-846年辣椒在明朝传 入中国约公元16世纪古琴艺术起源于先 秦约公元前11世纪石榴在汉代传入中国 约公元前2世纪因此问题涉及6个时空实 体-朝 代 关 系 屈 原-先 秦李 白-唐白 居易-唐辣椒-明古琴艺术-先秦和石 榴-汉按时间顺序排列为古琴艺术屈原 石榴李白白居易辣椒\", \"answer\": \"古琴艺术屈原石榴李白 白居易辣椒\" } Figure 13: JSON-format case in TOU type of QA. 9 Time Interval Calculation (TIC) ## JSON Format { \"type\": \"时间差计算\", \"question\": \"从屈原投江到李白出生再到 苏轼出生中间经历了多少年\", \"temporal_entities\": [\"屈原\", \"李白\", \"苏 轼\"], \"construct_explanation\": \"屈原投江发生 在约公元前278年李白出生于公元701年苏 轼出生于公元1037年因此问题涉及3个时空实 体-朝 代 关 系 屈 原-先 秦李 白-唐和苏 轼-宋 通 过 计 算 时 间 差 屈 原 到 李 白 相 差 约979年李白到苏轼相差约336年总共相差 约1315年\", \"answer\": \"约1315年\" } Figure 17: JSON-format case in TIC type of QA. Script Error Correction (SEC)"
        },
        {
            "title": "A Running Example of Timeline Ito Game",
            "content": "## JSON Format { \"type\": \"穿帮镜头指正\", \"question\": \"以下是一段镜头描述其中 有一处不遵循真实历史背景的穿帮内容请指 出: 在唐代的朗州一位表演者正在用昆曲演 绎盛唐的繁华而高粱酒则是当场招待贵宾的 饮品\", \"temporal_entities\": [\"昆曲\", \"朗州\", \"高 粱\"], \"construct_explanation\": \"1. 朗州存在 于唐代从621年到741年之间2. 昆曲起源于明 代与唐代不重叠3. 高粱传入中国的时间更 为久远早在先秦时期便已存在因此可用于 唐代饮品制作因此使用昆曲演绎显然是历 史穿帮\", \"answer\": \"昆曲在唐代的朗州出现是穿帮内 容因昆曲起源于明代\" } Figure 16: JSON-format case in SEC type of QA. Temporal Entity Selection (TES) ## JSON Format { \"type\": \"选出对应时空实体\", \"question\": \"以 下 四 个 实 体 中 哪 个 属 于唐朝n(A) 李白 n(B) 苏轼 n(C) 屈 原 n(D) 曹操\", \"temporal_entities\": [\"李白\", \"苏轼\", \"屈 原\", \"曹操\"], \"construct_explanation\": \"李 白 生 活 在 唐代约公元701年-762年苏轼生活在宋 代 约 公 元1037年-1101年 屈 原 生 活 在 先 秦 约 公 元 前340年-公 元 前278年 曹 操 生 活在汉代约公元155年-220年因此问题 涉及4个时空实体-朝代关系李白-唐苏 轼-宋屈 原-先 秦和曹 操-汉 通 过 朝 代 背景推理李白属于唐朝\", \"answer\": \"李白\" } Figure 18: JSON-format case in TES type of QA. ----------------------------------------- 真实顺序{\"屈原\": 1, \"李白\": 2, \"苏轼\": 3} 初始化 Agent P1: \"李白\" Agent P2: \"屈原\" Agent P3: \"苏轼\" ----------------------------------------- Agent P3 prediction in Round 1: { \"分析\": \"根据对xxx的了解xxx是宋朝时期 的一位著名诗人因此时间实体对应的朝代 是宋根据历史朝代时间线宋朝在十个朝代 中居中偏后的位置结合水果大小的主题应 该选择稍大一些但不是最大的水果在已提供 的选择中西瓜是最大的蓝莓是最小的对 应最前的朝代选择朝代在居中偏后的主题实 体是桃子\", \"理由\": \"我的时间实体对应的朝代居中偏 后\", \"主题实体\": \"桃子\" } ----------------------------------------- ###=== Round 1 === 当前主题: 水果大小 Agent P1: 我的时间实体对应的朝代居中偏 前. 因此我选择橙子 Agent P2: 我的时间实体对应的朝代最前. 因 此我选择蓝莓 Agent P3: 我的时间实体对应的朝代居中偏 后. 因此我选择桃子 本轮排序结果: {'P1': 2, 'P2': 1, 'P3': 2} 本轮排序错误错误的玩家P3 ###=== Round 2 === 当前主题: 书本厚度 Agent P1: 我的时间实体对应的朝代居中. 因 此我选择字典 Agent P2: 我的时间实体对应的朝代最前. 因 此我选择书签 Agent P3: 我的时间实体对应的朝代居中偏 后. 因此我选择百科全书 本轮排序结果: {'P1': 2, 'P2': 1, 'P3': 3} 游戏结束所有玩家的排序正确"
        },
        {
            "title": "G LLM Backbone List",
            "content": "F.2 Running Example of Timeline Ito Game Timeline Ito Game running example given the fruit size theme is below. 10 We validate the total number of twelve models, including both closed-sourced and open-sourced ones (Achiam et al., 2023; Dubey et al., 2024; Yang et al., 2024; Cai et al., 2024; GLM et al., 2024). The complete list of evaluated LLMs is shown in Table 4. Long Script Error Correction (LSEC) ## JSON Format { \"type\": \"剧本穿帮问题指正_长上下文\", \"question\": \"以下是一段剧本描述请指出其中不符合历史背景的穿帮内容nn背景设定在东汉末 年名将曹操正在洛阳的一座文人聚会酒楼中与手下谋士们讨论政治大计酒楼内弥漫着美酒的香气 桌上的菜肴色香俱全包括蜜饯杏仁红烧鹿肉以及一盘山药炖鸡曹操端起酒杯起身与众人敬酒话 题转向了当前国家的局势突然酒楼的门外传来一阵欢声笑语几位文人相伴走入酒楼他们是当时知 名的诗人王之涣和杜牧王之涣手捧一卷登鹳雀楼的诗稿热衷地与杜牧讨论诗句的对仗工整两位 诗人落座后曹操也邀请他们一起品酒作诗nn就在此时一位穿着朴素的商人走了进来自称是商贸 使者张衡他向酒楼的主人要求提供一些来自西南的特产并推荐了其中的一种热带水果草莓酒楼老 板随即呈上了这一新鲜水果几人尝过后纷纷表示口感非常独特直言这是一种他们从未品尝过的美味 与此同时另一位年轻的学者走进酒楼他正是历史学者班固他从洛阳的学府赶来听到酒楼内的喧闹 声不禁走入与众人交谈nn随着酒楼里的谈话逐渐深入众人讨论的议题转向了国家的未来王之涣 对曹操表示若有朝一日可以恢复汉朝的光辉他愿意为之创作更多诗篇而杜牧则提到诗词创作对于 平定民心具有重要作用他们的对话引发了在座每个人的深思nn此时酒楼外突然传来一阵马蹄声 一位身穿铠甲的将军匆匆走进酒楼向曹操报告前线战况这位将军正是夏侯他刚从许都赶来带来了 最新的军情曹操听后眉头紧锁立即召集众人商议对策夏侯提议联合孙权共同对抗袁绍但曹操却认 为应当先稳固内部再图外敌nn就在众人争论不休时酒楼的门再次被推开一位身穿道袍的老者走 了进来他自称是华佗手中捧着一瓶刚刚炼制的麻沸散华佗向曹操献上药物声称服用后可缓解头 痛曹操接过药物若有所思地看了看众人随后将药物放入怀中nn酒楼的氛围逐渐热烈起来众人 一边饮酒一边讨论着国家的未来突然一位年轻的乐师走到酒楼中央开始演奏一曲短歌行琴声 悠扬众人纷纷停下手中的酒杯静静地聆听乐师演奏完毕后曹操起身鼓掌称赞其技艺高超并邀 请他加入自己的幕府nn随着夜幕降临酒楼内的灯火逐渐点亮众人继续畅谈曹操举起酒杯高声 说道今日与诸位相聚实乃幸事愿我们共同努力恢复汉室荣光众人纷纷举杯响应酒楼内充满 了欢声笑语\", \"temporal_entities\": [\"曹操\", \"王之涣\", \"杜牧\", \"张衡\", \"草莓\", \"班固\", \"夏侯\", \"华佗\"], \"construct_explanation\": \"剧 本 中 出 现 的 多 个 历 史 人 物 和 食 材 存 在 不 符 合 历 史 背 景 的 穿 帮 内 容nn1. 王之涣和杜牧不可能同时出现在东汉末年王之涣生活在唐朝杜牧则生活在唐朝晚期 二人不可能与曹操同时存在n2. 张衡生活在东汉时期他是著名的天文学家和文学家但剧本中将他错 误地设定为商贸使者这一身份与历史背景不符n3. 草莓直到清朝才传入中国剧本中的草莓出现在东 汉末年不符合历史事实n4. 班固作为东汉时期的历史学者他比曹操年长不少因此不可能与曹操同时 出现在剧本中班固应当是年老之际无法与年轻的曹操同时活跃\", \"answer\": \"1. 王之涣和杜牧不可能同时出现在东汉末年n2. 张衡不可能作为商贸使者与曹操同时出 现n3. 草莓在东汉末年未传入中国属于不合时宜的食材n4. 班固的年纪和身份不应与曹操的同时期 相关\" } Figure 19: JSON-format case in LSEC type of QA. Full Name Open Source? Model Size"
        },
        {
            "title": "Prompt for CoT Prediction",
            "content": "Models GPT-4o Qwen-max o1-preview LLaMA3.18b ChatGLM36b InternLM2.57b Qwen2.57b Qwen2.514b Qwen2.532b Qwen2.572b DeepSeek-R1 gpt-4o-2024-08-06 qwen-max o1-preview Meta-Llama-3.1-8B-Instruct chatglm3-6b internlm2_5-7b-chat qwen2.5-7b-instruct qwen2.5-14b-instruct qwen2.5-32b-instruct qwen2.5-14b-instruct deepseek-r1 - - - 8B 6B 7B 7B 14B 32B 72B 671B Table 4: LLMs evaluated in our experiments"
        },
        {
            "title": "Prompt for Direct Prediction",
            "content": "请回答以下问题 {question} Figure 20: Prompt for Direct Prediction 11 请按照以下步骤一步一步思考并回答问题 1. {question} 2. 思考并详细分析问题然后得到结论及简要 理由如果理由比较复杂请分条简要列出 3. 请以 JSON 格式返回结果格式如下 { \"思考\": \"请在这里填写详细的思考过程\", \"回答\": \"请在这里填写结论及理由\" } Figure 21: Prompt for CoT Prediction."
        },
        {
            "title": "I Timeline Ito Game Performance",
            "content": "The detailed performance across difficulty levels is shown in Table 5. The difficulty level is determined based on the number of entities, where 3 corresponds to easy, 4 to medium, and 5 to hard. This number also represents the number of agents."
        },
        {
            "title": "Prompt of Evaluator",
            "content": "你是一个专业的问答系统评估员请根据以下信息评估答案的质量并输出详细的思考过程 **问题类型**{question_type} **问题**{question} **参考答案**{reference} {answer} **待评估答案**{prediction} **评估步骤** 1. 判断问题类型 - 如果问题是是否问题进入步骤 2 - 如果问题不是是否问题进入步骤 3 2. 对于是否问题 - 检查待评估答案是否正确回答了是/否 - 检查待评估答案的原因是否与参考答案一致 - 如果两者都正确评估结果为1否则评估结果为0 3. 对于非是否问题 - 检查待评估答案是否**完全覆盖**参考答案中的所有关键点 - 检查待评估答案中的每个点是否与参考答案**完全一致**包括事实逻辑和时间线等 - 检查朝代是否宽松匹配 - 比较待评估答案中的朝代范围与参考答案的朝代范围允许评估答案使用细分的朝代划分 - 参 考 答 案 中 的 朝 代 范 围 先 秦 -2100-206 汉 -206220 六 朝 220589 隋 581618 唐 618906 五 代 907960 宋 9601279 元 12791368 明 13681644清16441912 - 秦朝以前的朝代范围夏商周春秋战国等都属于先秦六朝和五代的朝代范围分别为东晋宋 齐梁陈后周和后梁后唐后晋后汉后周 - 允许待评估答案中的细分朝代在参考答案的朝代范围内进行宽松匹配 - 如果待评估答案**完全覆盖且完全一致**评估结果为1否则返回评估结果为0 **思考过程** - 详细分析待评估答案与参考答案的异同 - 重点关注跨时空推理的历史时间线和逻辑一致性 - 判断多个时空实体之间及与朝代之间的关系 **请以 JSON 格式返回结果** { \"思考\": \"请在这里填写详细的思考过程\", \"评估结果\": \"请在这里填写0或1\" } Figure 22: JSON-format case in intangible cultural heritage entity. Table 5: Main results on Timeline Ito Game within CTM benchmark."
        },
        {
            "title": "Method",
            "content": "Pass@3 Pass@8 Pass@3 Pass@8 Pass@3 Pass@8 Pass@3 Pass@8 GPT-4o 55.00 80.00 20.00 30. 5.00 10.00 26.67 40.00 Qwen-max 25. 35.00 10.00 10.00 10.00 15.00 15. 20.00 LLaMA3.18b ChatGLM36b InternLM2.57b Qwen2.57b 0. 5.00 5.00 0.00 0.00 5.00 15. 15.00 Qwen2.514b 15.00 20.00 Qwen2.532b 40. 50.00 0.00 0.00 0.00 5.00 0. 5.00 0.00 0.00 0.00 5.00 0. 15.00 Qwen2.572b 40.00 55.00 10.00 10. 0.00 0.00 0.00 0.00 0.00 0. 0.00 0.00 0.00 0.00 0.00 0. 0.00 5.00 0.00 1.67 1.67 1. 5.00 0.00 1.67 5.00 6.67 6. 15.00 21.67 16.67 23.33 Open-Book Performance Detailed results across tasks and entity numbers ars shown in Table 6. 12 Prompt For Step1 of Timeline Ito Game 你 是 一 个 玩 家 参 与 了 一 个 叫 做命 悬 一 线 ito的 游 戏 现 在 你 收 到 一 个 时 间 实 体'{self.entity}' 1. 首先需要推理得出该时间实体所属的朝代朝代时间线为 先秦-2100-206汉-206220六朝220589隋581618唐618906五代 907960宋9601279元12791368明13681644清16441912 2. 主题与朝代的对应规则如果主题是水果大小则水果越小对应朝代越早如果是书本厚度 则书本越薄对应朝代越早如果是船只大小则船只越小对应朝代越早如果是电子产品大小 则电子产品越小对应朝代越早如果是行星大小则行星越小对应朝代越早如果是动物大小则 动物越小对应朝代越早如果是建筑高度则建筑越矮对应朝代越早如果是水的温度则水越 冷对应朝代越早 本轮的主题是{theme}主题实体的个数与朝代个数对应你需要在{theme_entities}中选择1个对应主题 实体在主题的顺序来代表你的时间实体的朝代在朝代时间线中的位置返回你认为最能代表你的时 间实体的朝代的1个主题实体 3. 以下是之前的交流记录排序相关判断可作为参考其余的不作参考(如果这里是空的就不参考) {public_memory_str} 4. 分析你的时间实体在朝代时间线中的位置输出分析过程分析内容中你的时间实体和你推理出的朝 代用xxx代替只能出现主题实体的名称可以用朝代偏前或偏后等表达请注意你的分析过程 需要符合主题与朝代的对应规则 结合分析给出一句话表达你的推理理由我的时间实体对应的朝代最前/偏前/居中/偏后/最后等理由 中不要出现名称 5. 请根据上述信息返回如下JSON格式 { \"分析\":\"请在这里填写分析\", \"理由\":\"我的时间实体对应的朝代最前/偏前/居中/偏后/最后等\", \"主题实体\": \"请在这里填写主题实体\" } Prompt For Step2 of Timeline Ito Game 基于之前的交流记录{public_memory_str} 我的ID是Agent {self.agent_id}请分析我选择的实体在所有Agent中的排序 如果在上一轮中本轮排序错误错误的玩家后不包含我的ID则我的排序值维持上一轮的排序值 1. 如果主题是水果大小则水果越小排序越小如果是书本厚度则书本越薄排序越小如果 是船只大小则船只越小排序越小如果是电子产品大小则电子产品越小排序越小如果是行 星大小则行星越小排序越小如果是动物大小则动物越小排序越小如果是建筑高度则建筑 越矮排序越小如果是水的温度则水越冷排序越小 本轮的主题是{theme}返回我的主题实体在该主题下在所有Agent中的排序排序值为整数最小 为1 2. 之前轮次我的个人记忆这部分不公开大家互相猜测对齐 {self.memory} 3. 请根据上述信息返回如下JSON格式 { \"我的排序\": \"请在这里填写排序\" } Figure 23: Accuracy across entity inter-dynastic intervals under COT prompting setting. Table 6: Detailed results under the open-book setting."
        },
        {
            "title": "Method",
            "content": "= 1 (EDD) = 2 = 3 4 4L (LSEC) PJ GPT-4o + Openbook 57.76+1.24 53.40+2.28 45.52+0.76 26.90+0.80 56. 51.12 26.10 44.76 Qwen2.57b + Openbook 51.80 39. 35.96 12.40 48.64-3.16 39.92+0.04 31.88-4.08 17.90+5.50 Qwen2.514b + Openbook 54.36 51. 42.56 23.80 54.32-0.04 51.28+0.12 41.76-0.80 23.60-0.20 Qwen2.532b + Openbook 57.92+1.64 53.32+0.54 46.16-0.08 26.80-0.10 26.90 52. 56.28 46.24 Qwen2.572b + Openbook 58.20 48.76 46. 31.30 57.96-0.24 52.00+3.24 48.04+1.20 30.60-0.70 53.60 56.80+3.20 30.00 31.60+1.60 42.00 44.40+2.40 46.40 50.80+4. 60.80 63.60+2."
        },
        {
            "title": "TOU",
            "content": "38.42 RR"
        },
        {
            "title": "SEC",
            "content": "57.26 36."
        },
        {
            "title": "EEU",
            "content": "40."
        },
        {
            "title": "TES",
            "content": "Avg. 15.36 59.31 46.20 58.64 59.00+0.36 38.72+0.30 54.66-2.60 45.30+9.15 42.61+2.03 17.20+1.84 58.39-0.92 49.41+3. 46.28 26.38 46.28 24.14 36.23 7. 52.01 38.76 47.63+1.35 27.89+1.51 42.15-4.13 26.04+1.90 31.88-4.35 5.84-1.51 44.53-7.48 37.39-1.37 57.44 36.86 51. 36.90 39.07 18.26 58.58 46.32 58.82+1.38 36.48-0.38 51.83+0.00 39.95+3.05 39.71+0.64 13.86-4.40 52.92-5.66 46.14-0. 60.66 38.54 56.79 39.12 43.77 20. 60.04 48.83 61.15+0.49 39.93+1.39 55.61-1.18 40.67+1.55 45.22+1.45 16.86-3.24 58.21-1.83 49.51+0.68 61.38 40.77 54. 36.62 42.03 11.52 62.23 49.30 62.67+1.29 42.86+2.09 54.07-0.24 41.26+4.64 44.64+2.61 18.03+6.51 56.75-5.48 50.51+1. 14 Figure 24: Accuracy across entity inter-dynastic intervals under direct prompting setting on GPT-4o and Qwen2.5-7B. Figure 25: Accuracy across entity inter-dynastic intervals under CoT prompting setting on GPT-4o and Qwen2.5-7B."
        }
    ],
    "affiliations": [
        "School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, China",
        "Tongyi Lab, Alibaba Group"
    ]
}