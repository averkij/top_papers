{
    "paper_title": "Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia",
    "authors": [
        "Chenxi Wang",
        "Tianle Gu",
        "Zhongyu Wei",
        "Lang Gao",
        "Zirui Song",
        "Xiuying Chen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Human readers can efficiently comprehend scrambled words, a phenomenon known as Typoglycemia, primarily by relying on word form; if word form alone is insufficient, they further utilize contextual cues for interpretation. While advanced large language models (LLMs) exhibit similar abilities, the underlying mechanisms remain unclear. To investigate this, we conduct controlled experiments to analyze the roles of word form and contextual information in semantic reconstruction and examine LLM attention patterns. Specifically, we first propose SemRecScore, a reliable metric to quantify the degree of semantic reconstruction, and validate its effectiveness. Using this metric, we study how word form and contextual information influence LLMs' semantic reconstruction ability, identifying word form as the core factor in this process. Furthermore, we analyze how LLMs utilize word form and find that they rely on specialized attention heads to extract and process word form information, with this mechanism remaining stable across varying levels of word scrambling. This distinction between LLMs' fixed attention patterns primarily focused on word form and human readers' adaptive strategy in balancing word form and contextual information provides insights into enhancing LLM performance by incorporating human-like, context-aware mechanisms."
        },
        {
            "title": "Start",
            "content": "Word Form Matters: LLMs Semantic Reconstruction under Typoglycemia Chenxi Wang Tianle Gu Zhongyu Wei Lang Gao Zirui Song Xiuying Chen(cid:66) Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) Fudan University {chenxi.wang, xiuying.chen}@mbzuai.ac.ae 5 2 0 2 3 ] . [ 1 4 1 7 1 0 . 3 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Human readers can efficiently comprehend scrambled words, phenomenon known as Typoglycemia, primarily by relying on word form; if word form alone is insufficient, they further utilize contextual cues for interpretation. While advanced large language models (LLMs) exhibit similar abilities, the underlying mechanisms remain unclear. To investigate this, we conduct controlled experiments to analyze the roles of word form and contextual information in semantic reconstruction and examine LLM attention patterns. Specifically, we first propose SemRecScore, reliable metric to quantify the degree of semantic reconstruction, and validate its effectiveness. Using this metric, we study how word form and contextual information influence LLMs semantic reconstruction ability, identifying word form as the core factor in this process. Furthermore, we analyze how LLMs utilize word form and find that they rely on specialized attention heads to extract and process word form information, with this mechanism remaining stable across varying levels of word scrambling. This distinction between LLMs fixed attention patterns primarily focused on word form and human readers adaptive strategy in balancing word form and contextual information provides insights into enhancing LLM performance by incorporating human-like, context-aware mechanisms1."
        },
        {
            "title": "Introduction",
            "content": "User: Do you undretsand Typoglycemia? LLM: Yes! Typoglycemia is phenomenon where people can still read word or sentence even when the middle letters of the words are scrambled, ... Humans exhibit remarkable adaptability in reading, even when the internal character order of words is scrambled, as long as the first and last 1https://github.com/Aurora-cx/TypoLLM. (cid:66): Corresponding Author. letters remain intact. This phenomenon, Typoglycemia, raises fundamental question: Why do humans and LLMs understand scrambled words? Research shows that humans recognize words primarily through holistic shape matching (Larson, 2004), relying on contextual prediction when shape cues are insufficient (binti Ahmad Sabri, 2015). In extreme scrambling, higher-order regions like the prefrontal cortex enable retrospective reasoning to infer words from context (Rayner et al., 2006). Similarly, LLMs exhibit robustness to character scrambling. (Cao et al., 2023) found they maintain high accuracy despite disrupted tokenization, while (Yu et al., 2024) showed strong Typoglycemia task performance. These findings suggest LLMs, like humans, leverage contextual reasoning to reconstruct scrambled words. However, key question remains unanswered: How do LLMs internally process scrambled text? Do they employ mechanisms similar to humans? To investigate this, we designed series of controlled experiments to systematically analyze the effects of word form and contextual information on LLMs semantic reconstruction. We constructed standardized dataset by carefully controlling key linguistic variables and evaluated LLaMA-3.2 (1B, 3B)-Instruct and LLaMA-3.3 (70B)-Instruct (Dubey et al., 2024) to analyze their internal mechanisms underlying this capability. We define the Semantic Reconstruction Score (SemRecScore) as the cosine similarity between the representation of the original words token and the representation of the final subword token of the scrambled word at each layer of the LLM. This metric serves as reliable measure of semantic reconstruction. Our results show that LLMs progressively recover word meaning across layers. However, as the degree of word form perturbation increases, semantic reconstruction quality gradually declines. At lower perturbation levels, words achieve near-complete semantic alignment with their original form, whereas at higher perturbation levels, only partial alignment is retained. In the final layers of the models, SemRecScores exhibit significant differences across different perturbation levels. In contrast, even when contextual information is entirely removed, its impact on semantic reconstruction remains minimal. Given that LLMs primarily rely on word form for semantic reconstruction, we further investigate how attention mechanisms facilitate this process. Our analysis reveals that attention allocation to word form follows cyclic pattern across layers. Moreover, as word form perturbation increases, LLMs allocate progressively more attention to word form across all layers, suggesting that reconstructing highly scrambled words requires greater computational resources. Additionally, attention is not uniformly distributed; instead, LLMs rely on specific form-sensitive attention heads dedicated to processing word form information. As perturbation severity increases, more of these specialized attention heads are activated, yet their distribution remains stable, indicating structured approach to leveraging word form information. These findings underscore key distinction between LLMs and humans: while humans adaptively adjust their reliance on word form and contextual cues based on the degree of perturbation, LLMs primarily rely on word form and exhibit relatively fixed yet structured attention allocation pattern. Our contributions can be summarized as follows: (1) We introduce new perspective on LLM interpretability by investigating their internal mechanisms under character-level perturbations and propose SemRecScore as reliable metric for quantifying LLMs semantic reconstruction ability. (2) Through systematic experiments, we demonstrate that word form is the primary factor in semantic reconstruction, while contextual information has minimal impact, and we reveal the key role of formsensitive attention heads in this process. (3) We further uncover fundamental divergence between LLMs and human cognition, providing insights for improving LLMs semantic adaptability."
        },
        {
            "title": "2 Related Work",
            "content": "Mechanisms Underlying Human Typoglycemia. Humans Typoglycemia ability suggests that word recognition does not strictly depend on letter order but involves higher-level cognitive mechanisms. Research in cognitive science and psychology suggests that word recognition primarily relies on word form rather than letter-by-letter decoding (Shillcock et al., 2000). Eye-tracking studies (Johnson et al., 2007; White et al., 2008) show that fluent readers process words holistically rather than focusing on each letter. As long as the first and last letters remain intact, recognition remains stable (Rayner et al., 2006; Johnson and Eisler, 2012). Beyond word shape, contextual priming further speeds up recognition (Plummer et al., 2014). For example, in The nurse gave the patient a. . . , words like doctor or medicine are automatically activated (binti Ahmad Sabri, 2015), helping readers reconstruct scrambled words more efficiently. These findings suggest that human readers flexibly adapt between word form and context. LLM-Based Typoglycemia. Some recent studies have explored Typoglycemia and its impact on LLM robustness, but their analyses remain at surface level, lacking systematic investigation of internal mechanisms. For instance, Cao et al. (2023) demonstrated that GPT-4 and other advanced LLMs maintain strong language understanding under extreme character perturbations, accurately reconstructing scrambled words. However, their study was limited to input-output comparisons without examining how LLMs internally process scrambled text. Expanding on this, Yu et al. (2024) evaluated multiple LLMs on Typoglycemia tasks and found them remarkably robust. Yet, their focus remained on task-level performance rather than the underlying representations and attention mechanisms driving word recovery. Thus, while these works show that LLMs can handle Typoglycemia, they offer only observational insights. Our study fills this gap by analyzing LLMs internal processing under Typoglycemia perturbations. Robustness to Word Order Perturbations and Contextual Dependencies. Pham et al. (2021) and Sinha et al. (2021) found that BERT-based models maintain high accuracy in NLU tasks even when word order is shuffled, indicating reliance on lexical co-occurrence patterns rather than syntactic structures. Similarly, Gupta et al. (2021) observed that BERT struggles to detect unnatural inputs, often making high-confidence predictions despite severe word order disruption. However, these studies focus on masked language models and do not extend to generative LLMs or character-level perturbations. Zhu et al. (2024) and Hu et al. (2024) found that pretrained models underperform fine-tuned models in complex reasoning and exhibit overconfidence in long-range dependencies, particularly benefiting from content words and N-grams. Additionally, Hackmann et al. (2024) and Eisenschlos et al. (2023) showed that LLMs primarily rely on statistical correlations rather than explicit syntax and face limitations when acquiring new words beyond their training data. However, these studies do not address how LLMs process and reconstruct text under character-level perturbations. Building on this work, we systematically analyze the ability of generative LLMs to reconstruct semantics under typoglycemia-style character perturbations, investigating their reliance on word forms and contextual cues while revealing structured attention allocation patterns."
        },
        {
            "title": "3 Problem Formulation",
            "content": "To systematically investigate how LLMs deal with Typoglycemia, we define word semantic reconstruction in LLMs as the internal process through which model gradually recovers the original meaning of word from an input with scrambled character order. We further break down this problem into two key influencing factors: (1) Scramble Ratio. Definition: The extent of character perturbation within word, ranging from slight reordering of internal characters (excluding the first and last letters) to extreme scrambling. Research Question: Does increasing scrambling gradually degrade semantic reconstruction across LLM layers? (2) Context Integrity. Definition: The completeness of contextual information available to the LLM for semantic reconstruction, ranging from full sentence to no context at all. Research Question: Does LLM semantic reconstruction primarily rely on word shape or context? If context integrity decreases, is the models semantic recovery ability significantly affected? To explore LLMs processing of scrambled words, we apply the following methods to analyze semantic reconstruction. (1) Attention Distribution Analysis. Objective: To study how LLMs distribute attention between word shape information and contextual information across different layers, and whether there are hierarchical shifts. Research Questions: Does LLM adjust its attention patterns based on the degree of word scrambling? Is there dynamic weighting shift from word shape reliance to contextual reliance as scrambling increases? (2) Role of Specialized Attention Heads. Objective: To identify whether specific attention heads are specialized for processing word shape or context and analyze their behavioral patterns across different layers. Research Questions: Under different scrambling degrees, which attention heads remain highly focused on word shape information? Which attention heads continue to function effectively under extreme scrambling conditions?"
        },
        {
            "title": "4 Dataset",
            "content": "We selected SQuAD (Rajpurkar et al., 2016) as our base dataset for its extensive use in evaluating LLMs natural language understanding. Its long, well-structured texts enable analysis across linguistic structures while ensuring clear semantics and controlled scrambling, enhancing reproducibility and comparability. 4.1 Variables Definition In this study, we control two key variables, Scramble Ratio (SR) and Context Integrity (CI), to construct an SR CI matrix experimental design, enabling systematic investigation of LLMs semantic reconstruction ability under different linguistic structure variations. Scramble Ratio (SR). SR quantifies the degree to which the internal characters of word (excluding the first and last letters) have been scrambled. It is defined as: SR = Nscrambled Ncandidate , where Nscrambled is the number of scrambled characters, and Ncandidate is the total number of characters eligible for scrambling within the word. higher SR indicates more disrupted word structure. We define five SR levels: 0, 0.25, 0.5, 0.75, and 1. Context Integrity (CI). CI measures the completeness of contextual information provided for given word. It is defined as: CI = Ncontext_preserved Ntotal_context , where Ncontext_preserved is the number of preserved context words, and Ntotal_context is the total number of words in the original sentence. higher CI indicates more complete contextual environment. We define five CI levels: 0, 0.25, 0.5, 0.75, and 1. 4.2 Data Standardization and Control To ensure the reliability of the experimental data, we performed standardization on the dataset. Word Scrambling. All target words are at least 10 characters long to avoid short words affecting results. Based on the SR value, we extract, shuffle, and reinsert continuous substring from the candidate characters, ensuring the modified sequence differs from the original. This keeps the word shape intact at the beginning and end, making it easier to quantify. To ensure control and reproducibility, we select only words that remain intact after tokenization, avoiding subword splitting. Context Masking. To study LLMs semantic reconstruction under context loss, we control CI. Unlike BERT, LLaMA models lack mask token and was not trained with masked language modeling, making direct word removal problematic as it alters sentence length and disrupts syntax. To maintain sentence structure and prevent tokenization issues, we replace masked words with _. Masked words are selected based on CI values, ensuring systematic coverage. To reduce noise from masking key contextual words, we generate multiple masked datasets using different random seeds. However, results remain stable across seeds, as large-scale sampling offsets individual sample noise. Data Examples. We selected 20,000 samples from the base dataset and, after standardization, obtained 7,556 qualified samples. Below is an example with SR = 0.5: The original word relationship was scrambled into relatinioshp, while keeping the first and last letters unchanged. Below is an example with CI = 0.5: [Original Sentence] ...During Francos regime, however, the blaugrana team was granted profit due to its good relatinioshp with the dictator at management level, even giving two awards to him... [Processed Sentence (SR = 0.5, CI = 0.5)] ...During Francos regime, _ the blaugrana _ _ _ profit _ _ _ _ relatinioshp with the _ _ management _ even _ _ _ to him..."
        },
        {
            "title": "Reconstruction",
            "content": "In this section, we introduce Semantic Reconstruction Score (SemRecScore) to quantify semantic reconstruction across LLM layers. To validate its effectiveness, we propose Negative Correlation Rate (NegCorrRate), which measures how increased SemRecScore aligns with greater consistency in completion probability. We evaluate NegCorrRate across three LLMs (LLaMA-3.2(1B, 3B)-Instruct, LLaMA-3.3(70B)- Instruct) and all samples, empirically supporting SemRecScores effectiveness. 5.1 Semantic Reconstruction Score We define SemRecScore as metric to quantify the degree of semantic reconstruction for scrambled words across different layers of an LLM. Since scrambled words rarely exist in the tokenizers vocabulary, they are typically split into multiple subword tokens, dispersing their representation across embeddings. The model must integrate these fragments to reconstruct meaning. Prior studies suggest that in subword tokenization, the last token in sequence carries the most integrated semantic representation (Meng et al., 2022; Geva et al., 2023; Yang et al., 2024),. Based on this, we define SemRecScore by comparing the original words token representation with the last token in the scrambled words subword sequence. Formally, let x(L) be the representation of the original words token at layer L, and let x(L) be the representation of the last subword token in the scrambled sequence at the same layer. Then, SemRecScore at layer is defined as: SemRecScore(L) = x(L) x(L) x(L) x(L) , where x(L) x(L) denotes the dot product between the two vectors, and x(L) represent their respective Euclidean norms. The resulting cosine similarity ranges from -1 to 1, with higher values indicating stronger semantic alignment. and x(L) SemRecScore provides insights into how well an LLM reconstructs the semantics of word when its subword structure is disrupted. higher SemRecScore suggests that the model retains the semantic meaning despite scrambling, while lower score indicates loss of semantic integrity. 5.2 Validating SemRecScore To evaluate whether SemRecScore effectively captures semantic reconstruction, we analyze its relationship with the consistency of the models behavior in generating completions. Specifically, we introduce Negative Correlation Rate (NegCorrRate), global statistical measure that quantifies whether an increase in SemRecScore corresponds to greater consistency in the models completion probability we compute the average NegCorrRate across all target words for different values of SR. The results for three LLaMA models are shown in Figure 1. At SR = 0, NegCorrRate is 0, as comparing word with itself introduces no behavioral difference. As SR increases, greater scrambling differences lead to larger semantic reconstruction gaps, increasing the number of negatively correlated sample pairs. Consequently, NegCorrRate rises, reinforcing the negative correlation between SemRecScore and KL divergence. Figure 1 shows sharp increase in NegCorrRate for small SR, indicating that even mild scrambling disrupts semantic reconstruction. As SR nears 1.0, NegCorrRate approaches 1.0, suggesting nearly universal negative correlation across samples. These results provide empirical support that SemRecScore effectively reflects the degree of semantic reconstruction, as its correlation with completion consistency remains robust across different scrambling intensities."
        },
        {
            "title": "6 How Word Form and Contextual",
            "content": "Information Influence LLMs Semantic Reconstruction To quantitatively assess the impact of word form and contextual information on LLMs semantic reconstruction, we conduct experiments on three instruction-tuned models: LLaMA-3.2(1B, 3B)- Instruct and LLaMA-3.3(70B)-Instruct. We design 5 5 experimental matrix with five levels of Scramble Ratio (SR) and five levels of Context Integrity (CI), yielding 25 distinct settings. Analyzing semantic reconstruction across all layers, we find that word form plays dominant role, while contextual information, though initially expected to be key, has surprisingly limited effect on LLMs typoglycemia capabilities (Figure 2). The following sections explore the influence of word form first, then contextual information. 6.1 Impact of Word Form on Semantic Reconstruction To assess word forms impact, we analyze Figures 2(a)-(c) for 1B, 3B, and 70B models with CI=1. Across all models, when SR = 0, no reconstruction is needed, and SemRecScore remains near 1 across layers, confirming token embeddings align with original words. When SR > 0, Layer 0 representations are unrelated to the original forms, regardless of scrambling severity. Reconstruction Figure 1: Relationship between SR and Average NegCorrScore across LLaMA models of different scales. The increasing trend of NegCorrScore with SR validates SemRecScore as reliable measure of semantic reconstruction. distribution. This section details the formulation of NegCorrRate and its empirical trends. Formulation. NegCorrRate is designed to measure the extent to which higher SemRecScore is associated with lower KL divergence between the completion probability distributions of prompts containing scrambled and original words. Formally, given word with multiple Scramble Ratio (SR) levels, we denote the final-layer SemRecScore at SR level as SRScore(final) , and the KL divergence between the completion probability distributions of prompts containing the scrambled word at SR level and those containing the original word as KLdivi. For any two SR levels and such that = SR, where SR is predefined scrambling difference, we compute: Ci,j = (SRScore(final) SRScore(final) ) (KLdivi KLdivj). < SRScore(final) Ci,j indicates whether decrease in final-layer SemRecScore (SRScore(final) ) corresponds to an increase in KL divergence (KLdivi > KLdivj), supporting the expectation that lower semantic reconstruction leads to greater inconsistency in completion behavior. NegCorrRate is then defined as the proportion of sample pairs where this term is negative: NegCorrRate = 1 (cid:80) (i,j)P 1(Ci,j < 0), where is the set of all valid SR level pairs (i, j) corresponding to fixed SR, and 1() is the indicator function that returns 1 when the condition inside holds and 0 otherwise. Empirical Analysis. To understand how the relationship between SemRecScore and model consistency evolves with increasing scrambling severity, Figure 2: Semantic reconstruction performance across different Scramble Ratios (SR) and Context Integrity (CI) levels. The top row (a-d) presents SemRecScore trends under varying SR values for 1B, 3B, and 70B models. The bottom row (e-h) illustrates SemRecScore evolution for fixed SR values while varying CI. Across all models, word form plays dominant role, with context integrity having minimal impact on reconstruction performance. improves with depth but depends on SRlower SR values recover more effectively. By the final layer, SR = 0.25 reaches near-perfect reconstruction, while SR = 1 lags by 30% and only achieves final SemRecScore of 0.5, indicating incomplete reconstruction. The widening gap between SR levels at deeper layers highlights word forms critical role in semantic recovery. Figure 2(c) reveals 70B model anomalyunlike 1B and 3B, which show monotonic increase, highly scrambled words in the 70B model decline in later layers. This suggests larger models reinterpret highly perturbed words as semantically unrelated rather than reconstructing them, revealing scale-dependent phenomenon where extreme perturbations are disregarded rather than forced into alignment. Figure 2(d) examines the 3B model with no context (CI=0), showing similar SemRecScore trends as CI=1. Despite context removal, final reconstruction quality aligns with SR-based expectations, indicating minimal contextual impactwords are reconstructed regardless. These findings demonstrate that word form dominates LLMs typoglycemia capabilities, with lower SR aiding recovery, while context plays minimal role. Additional results for intermediate CI values are in the Appendix A.1. and (g), which correspond to the 1B, 3B, and 70B models under SR=0.25. Notably, we observe that the curves for different CI levels are almost overlapping, indicating that under the same scramble ratio, the completeness of contextual information has minimal impact on semantic reconstruction. The only exception is when CI=0, where slight drop in reconstruction performance is visible when no context is retained. Further, Figure 2(h) shows the 3B models reconstruction trends at SR=1, where all internal characters are scrambled except the first and last. Interestingly, even under this extreme perturbation, the trends for different CI values remain nearly identical, indicating that LLMs do not increase their reliance on contextual information when processing highly scrambled words. This reinforces the observation that contextual integrity does not significantly affect the models ability to reconstruct word meaning. However, when comparing Figure 2(h) (SR=1) with Figure 2(f) (SR=0.25), we observe clear decline in reconstruction performance, highlighting that word form, rather than context, is the primary determinant of semantic recovery. Additional results for intermediate SR values are in the Appendix A.2. 6.2 Impact of Contextual Information on Semantic Reconstruction"
        },
        {
            "title": "Information",
            "content": "To assess the role of contextual information in semantic reconstruction, we analyze Figures 2(e), (f), Building on the findings from Section 6, we have established that word form is the primary factor influencing LLMs reconstruction of words original meaning in typoglycemia scenarios. In this section, we further investigate how LLMs utilize word form information. Specifically, in Section 7.1, we analyze the overall attention distribution across different scrambling levels and how it evolves across model layers. In Section 7.2, we identify specific attention heads responsible for processing word form, revealing the most fine-grained mechanisms through which LLMs leverage form-based cues. 7.1 Attention Allocation to Word Form Since context integrity (CI) has minimal impact on semantic reconstruction, we mainly analyze the models attention patterns under CI=1, where the surrounding context remains intact, which aligns with realistic setting for typoglycemia. Definition of AttentionSelf. To quantify how LLMs allocate attention to word form, we define AttentionSelf, which measures the total attention assigned to all tokens in subword sequence by its final token, aggregated across all attention heads. Formally, we define AttentionSelf as: AttentionSelf = (cid:80) hH (cid:80) tT Ah(tlast, t), where represents all attention heads, is the set of tokens within the scrambled subword sequence, and Ah(tlast, t) denotes the attention weight assigned by head from the final token tlast to token in the sequence. We compute the mean AttentionSelf across set of samples at each layer, as shown in Figures 3. Attention Allocation Pattern. Across all models, we observe consistent trend in which AttentionSelf increases with SR across all layers, with the SR=1 curve consistently the highest and SR=0 significantly lower than the rest. This ordering remains consistent across all three models, with curves ranked from top to bottom according to SR, indicating that higher scrambling severity leads to stronger attention to word form. Notably, even from Layer 0, LLMs allocate substantial attention to scrambled words (SR > 0), suggesting that word reconstruction begins at the earliest processing stages. This finding aligns with Section 6, where semantic reconstruction was observed to start from the lowest layers. In contrast, when SR=0, the model assigns minimal attention to word form at the lower layers, with AttentionSelf remaining consistently lower in the initial processing stages. This suggests that LLMs do not explicitly attend to word form in the early layers unless perturbation occurs. Across all three models, AttentionSelf exhibits clear upward trend in the higher layers, indicating that LLMs increasingly refocus on word form at deeper layers. In the 1B and 3B models, we observe cyclic pattern in attention allocation, suggesting that attention to word form fluctuates across layers rather than following strictly monotonic trend. In the 70B model, while similar cyclic pattern appears in the first half of the network, the latter half maintains prolonged period of low AttentionSelf before final sharp increase at the highest layers. Notably, this final surge in AttentionSelf does not correspond to continued rise in SemRecScore, which instead plateaus before slightly declining in the last two layers. This behavior is unique to the 70B model; in contrast, the 1B and 3B models exhibit late-stage increase in both AttentionSelf and SemRecScore, indicating continued refinement of semantic reconstruction. The prolonged low AttentionSelf in the second half of the 70B model aligns with the plateau in SemRecScore observed in Section 6, suggesting that the model deprioritizes word form processing for substantial depth range before ultimately refocusing on it in the final layers. Rather than continuously refining the reconstructed semantics, the 70B model appears to reallocate processing resources toward other representational objectives, leading to deviation from the trends observed in smaller models. Additionally, we analyze AttentionSelf when CI=0, where all contextual information is removed for the 3B model. As shown in Figure 3, even with no surrounding context, the models attention to word form remains structured and consistent with the pattern observed in Figure 3(b), where full context is present. This suggests that LLMs attention allocation to word form is fixed process rather than an adaptive response to available context. 7.2 Form-Sensitive Attention Heads To further analyze how LLMs utilize word form information, we examine the attention allocation of individual attention heads across all layers and samples. As shown in Figure 4, the x-axis represents the Attention Head ID, while the y-axis denotes the Layer ID. The color intensity of each cell corresponds to AttentionSelfi, which quantifies the atFigure 3: Attention allocation to word form under varying Scramble Ratios (SR). Subplots (a-c) show AttentionSelf trends for 1B, 3B, and 70B models with full context (CI=1), while (d) presents the 3B model without context (CI=0). Higher SR values consistently elicit stronger attention to word form, and the cyclic attention pattern remains unchanged even without context, suggesting that LLMs process word form independently of contextual information. Figure 4: Heatmaps of attention allocation to word form in the LLaMA-1B-Instruct across Scramble Ratios (SR). The x-axis denotes attention heads, and the y-axis denotes layers. Specific heads consistently focus on word form, with higher SR activating more form-sensitive heads, indicating structured and stable processing mechanism. tention allocated to word form by the attention head i. Figure 3 presents the LLaMA-3.2-1B-Instruct models attention distribution under different SR values, while heatmaps for the 3B and 70B models can be found in Appendix B. In Section7.1, we observed that all models exhibit an increase in overall attention to word form at the highest layers. Here, Figure 4 reveals that, across all SR values, attention heads H14, H24, and H25 in the final layer consistently focus on word form. This suggests that certain attention heads are specifically responsible for processing word form information at the models top layers. When SR=0, the lower layers show minimal attention to word form, which aligns with our previous observation that LLMs do not explicitly attend to word form in early layers unless perturbation occurs. However, when SR>0, even at the lowest layer, H2 and H3 consistently allocate attention to word form, indicating that the model begins reconstructing scrambled words from the very first processing stages. The cyclic attention pattern observed in Section 7.1 appears to be primarily driven by H12 and H26 in the middle layers, reinforcing the idea that certain attention heads exhibit periodic fluctuations in their focus on word form. Additionally, heatmaps for the 3B and 70B models (see Appendix B) confirm that form-sensitive attention heads are consistently present across model scales. As SR increases, more such attention heads are activated, and their distribution remains stable across different SR levels. LLMs utilization of word form is primarily carried out by these specific attention heads rather than being distributed uniformly across the model. These findings suggest that LLMs possess specialized attention heads dedicated to processing word form, which become increasingly engaged as word scrambling severity increases."
        },
        {
            "title": "8 Conclusion and Future Work",
            "content": "Our findings reveal that LLMs primarily rely on word form for typoglycemia-style semantic reconstruction, with contextual information playing minimal role. We further demonstrate that attention allocation to word form follows structured pattern across layers, with cyclic fluctuations and specialized attention heads dedicated to word form processing. Future work should explore broader range of model architectures and languages, as well as assess the practical impact of LLMs word form utilization on real-world NLP tasks. the AAAI conference on artificial intelligence, volume 35, pages 1294612954."
        },
        {
            "title": "9 Limitations",
            "content": "While our study offers valuable insights into how LLMs utilize word form for semantic reconstruction, it has several limitations. First, our experiments are confined to the LLaMA model family, leaving open the question of whether these mechanisms generalize to other architectures. Second, we focus specifically on typoglycemia-style scrambling, whereas other perturbations, such as deletions or phonetic errors, may lead to different reconstruction patterns. Finally, our analysis is limited to English, and it remains uncertain whether morphologically rich languages exhibit similar dependencies on word form. Future work could explore broader model architectures, diverse perturbation types, and cross-linguistic analyses to provide more comprehensive understanding of LLMs semantic reconstruction mechanisms."
        },
        {
            "title": "References",
            "content": "Nazreen Farina binti Ahmad Sabri. 2015. Typoglycemia: The ability to read transposed letters in word with different languages. Technical report, Cañada College. Qi Cao, Takeshi Kojima, Yutaka Matsuo, and Yusuke Iwasawa. 2023. Unnatural error correction: Gpt-4 can almost perfectly handle unnatural scrambled text. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 88988913. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Julian Martin Eisenschlos, Jeremy R. Cole, Fangyu Liu, and William W. Cohen. 2023. WinoDict: Probing language models for in-context word acquisition. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 94102, Dubrovnik, Croatia. Association for Computational Linguistics. Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. 2023. Dissecting recall of factual associations in auto-regressive language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1221612235. Ashim Gupta, Giorgi Kvernadze, and Vivek Srikumar. 2021. Bert & family eat word salad: Experiments with text understanding. In Proceedings of Stefan Hackmann, Haniyeh Mahmoudian, Mark Steadman, and Michael Schmidt. 2024. Word importance explains how prompts affect language model outputs. Preprint, arXiv:2403.03028. Yutong Hu, Quzhe Huang, Kangcheng Luo, and Yansong Feng. 2024. What kinds of tokens benefit from distant text? an analysis on long context language modeling. Preprint, arXiv:2406.11238. Rebecca Johnson and Morgan Eisler. 2012. The importance of the first and last letter in words during sentence reading. Acta psychologica, 141(3):336 351. Rebecca Johnson, Manuel Perea, and Keith Rayner. 2007. Transposed-letter effects in reading: evidence from eye movements and parafoveal preview. Journal of Experimental psychology: Human perception and performance, 33(1):209. Kevin Larson. 2004. The science of word recognition. Advanced Reading Technology, Microsoft Corporation. Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2022. Locating and editing factual associations in gpt. Advances in Neural Information Processing Systems, 35:1735917372. Thang Pham, Trung Bui, Long Mai, and Anh Nguyen. 2021. Out of order: How important is the sequential order of words in sentence in natural language understanding tasks? In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 11451160, Online. Association for Computational Linguistics. Patrick Plummer, Manuel Perea, and Keith Rayner. 2014. The influence of contextual diversity on eye movements in reading. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(1):275. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 23832392, Austin, Texas. Association for Computational Linguistics. Keith Rayner, Sarah White, and SP Liversedge. 2006. Raeding wrods with jubmled lettres: There is cost. Richard Shillcock, Mark Ellison, and Padraic Monaghan. 2000. Eye-fixation behavior, lexical storage, and visual word recognition in split processing model. Psychological Review, 107(4):824. Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau, Adina Williams, and Douwe Kiela. 2021. Masked language modeling and the distributional hypothesis: Order word matters pre-training for little. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 28882913, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. Sarah White, Rebecca Johnson, Simon Liversedge, and Keith Rayner. 2008. Eye movements when reading transposed text: the importance of Journal of Experimental word-beginning letters. Psychology: Human Perception and Performance, 34(5):1261. Sohee Yang, Elena Gribovskaya, Nora Kassner, Mor Geva, and Sebastian Riedel. 2024. Do large language models latently perform multi-hop reasoning? In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Miao Yu, Junyuan Mao, Guibin Zhang, Jingheng Ye, Junfeng Fang, Aoxiao Zhong, Yang Liu, Yuxuan Liang, Kun Wang, and Qingsong Wen. 2024. Mind scramble: Unveiling large language model psychology via typoglycemia. Preprint, arXiv:2410.01677. Yilun Zhu, Joel Ruben Antony Moniz, Shruti Bhargava, Jiarui Lu, Dhivya Piraviperumal, Site Li, Yuan Zhang, Hong Yu, and Bo-Hsiang Tseng. 2024. Can large language models understand context? In Findings of the Association for Computational Linguistics: EACL 2024, pages 20042018, St. Julians, Malta. Association for Computational Linguistics."
        },
        {
            "title": "A Semantic reconstruction performance",
            "content": "A.1 Performance across different CI levels In the main text, we have presented the layer-wise Semantic Reconstruction Performance across different LLM scales for various SR values when CI = 1. In this appendix section, Figure 5 illustrates the results for CI = 0 and CI = 0.25, while Figure 6 presents the results for CI = 0.5 and CI = 0.75. The similarity of the curves confirms that Contextual Information has minimal impact on semantic reconstruction. A.2 Performance across different SR levels In the main text, we have presented the layer-wise Semantic Reconstruction Performance across different LLM scales for various CI values when SR = 0.25. In this appendix section, Figure 7 illustrates the results for SR = 0 and SR = 0.5, while Figure 8 presents the results for SR = 0.75 and SR = 1. The noticeable decline in the curves as SR increases confirms that Word Form plays dominant role in semantic reconstruction."
        },
        {
            "title": "B Heatmap of attention allocaton",
            "content": "In the main text, we presented how different attention heads in LLaMA-3.2-1B-Instruct allocate attention to word forms. This section provides heatmaps of attention distribution for the remaining two models. Figure 9 presents the attention distribution heatmap for LLaMA-3.2-3B-Instruct, while Figure 10 shows the heatmap for LLaMA-3.3-7BInstruct. Across different SR levels, consistent pattern emerges: certain layers and specific attention heads consistently allocate more attention to word forms. This observation suggests that the models primarily rely on Form-Sensitive Attention Heads to utilize word form information. Figure 5: Semantic Reconstruction Performance across Different LLM Scales and Context Integrity Levels. The plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various SR values across different LLaMA models (1B, 3B, and 70B). The top row represents CI = 0, while the bottom row represents CI = 0.25. The legend indicates different SR conditions, including the Completely Scrambled setting. The similarity of the curves across different CI values suggests that Context Integrity (CI) has minimal impact on semantic reconstruction performance. Figure 6: Semantic Reconstruction Performance across Different LLM Scales and Context Integrity Levels. The plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various SR values across different LLaMA models (1B, 3B, and 70B). The top row represents CI = 0.25, while the bottom row represents CI = 0.75. The legend indicates different SR conditions, including the Completely Scrambled setting. The similarity of the curves across different CI values suggests that Context Integrity (CI) has minimal impact on semantic reconstruction performance. Figure 7: Semantic Reconstruction Performance across Different LLM Scales and Scramble Ratio Levels. The plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various CI values across different LLaMA models (1B, 3B, and 70B). The top row represents SR = 0, while the bottom row represents CI = 0.5. The legend indicates different CI conditions.The close alignment of curves across different CI values suggests that Context Integrity has limited impact on semantic reconstruction. Figure 8: Semantic Reconstruction Performance across Different LLM Scales and Scramble Ratio Levels. The plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various CI values across different LLaMA models (1B, 3B, and 70B). The top row represents SR = 0.75, while the bottom row represents CI = 1. The legend indicates different CI conditions.The close alignment of curves across different CI values suggests that Context Integrity has limited impact on semantic reconstruction. In the rows with higher SR, all curves are noticeably lower, confirming that Word Form plays crucial role in semantic reconstruction. Figure 9: Heatmaps of attention allocation to word form in the LLaMA-3.2-3B-Instruct across Scramble Ratios (SR). The x-axis denotes attention heads, and the y-axis denotes layers. Specific heads consistently focus on word form, with higher SR activating more form-sensitive heads, indicating structured and stable processing mechanism. Figure 10: Heatmaps of attention allocation to word form in the LLaMA-3.3-70B-Instruct across Scramble Ratios (SR). The x-axis denotes attention heads, and the y-axis denotes layers. Specific heads consistently focus on word form, with higher SR activating more form-sensitive heads, indicating structured and stable processing mechanism."
        }
    ],
    "affiliations": [
        "Fudan University",
        "Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)"
    ]
}