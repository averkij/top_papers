{
    "paper_title": "Alchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation",
    "authors": [
        "Shaonan Wu",
        "Shuai Lu",
        "Yeyun Gong",
        "Nan Duan",
        "Ping Wei"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Formal proofs are challenging to write even for experienced experts. Recent progress in Neural Theorem Proving (NTP) shows promise in expediting this process. However, the formal corpora available on the Internet are limited compared to the general text, posing a significant data scarcity challenge for NTP. To address this issue, this work proposes Alchemy, a general framework for data synthesis that constructs formal theorems through symbolic mutation. Specifically, for each candidate theorem in Mathlib, we identify all invocable theorems that can be used to rewrite or apply to it. Subsequently, we mutate the candidate theorem by replacing the corresponding term in the statement with its equivalent form or antecedent. As a result, our method increases the number of theorems in Mathlib by an order of magnitude, from 110k to 6M. Furthermore, we perform continual pretraining and supervised finetuning on this augmented corpus for large language models. Experimental results demonstrate the effectiveness of our approach, achieving a 5% absolute performance improvement on Leandojo benchmark. Additionally, our synthetic data achieve a 2.5% absolute performance gain on the out-of-distribution miniF2F benchmark. To provide further insights, we conduct a comprehensive analysis of synthetic data composition and the training paradigm, offering valuable guidance for developing a strong theorem prover."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 1 2 ] . [ 1 8 4 7 5 1 . 0 1 4 2 : r ALCHEMY: AMPLIFYING THEOREM-PROVING CAPABILITY THROUGH SYMBOLIC MUTATION Shaonan Wu 1,2, Shuai Lu 3, Yeyun Gong 3, Nan Duan 3, Ping Wei 1,2, 1 National Key Laboratory of Human-Machine Hybrid Augmented Intelligence 2 Institute of Artificial Intelligence and Robotics, Xian Jiaotong University 3 Microsoft Research Asia {shaonanwu@stu.,pingwei@}xjtu.edu.cn, {shuailu,yegong,nanduan}@microsoft.com"
        },
        {
            "title": "ABSTRACT",
            "content": "Formal proofs are challenging to write even for experienced experts. Recent progress in Neural Theorem Proving (NTP) shows promise in expediting this process. However, the formal corpora available on the Internet are limited compared to the general text, posing significant data scarcity challenge for NTP. To address this issue, this work proposes Alchemy, general framework for data synthesis that constructs formal theorems through symbolic mutation. Specifically, for each candidate theorem in Mathlib, we identify all invocable theorems that can be used to rewrite or apply to it. Subsequently, we mutate the candidate theorem by replacing the corresponding term in the statement with its equivalent form or antecedent. As result, our method increases the number of theorems in Mathlib by an order of magnitude, from 110k to 6M. Furthermore, we perform continual pretraining and supervised finetuning on this augmented corpus for large language models. Experimental results demonstrate the effectiveness of our approach, achieving 5% absolute performance improvement on Leandojo benchmark. Additionally, our synthetic data achieve 2.5% absolute performance gain on the out-of-distribution miniF2F benchmark. To provide further insights, we conduct comprehensive analysis of synthetic data composition and the training paradigm, offering valuable guidance for developing strong theorem prover."
        },
        {
            "title": "INTRODUCTION",
            "content": "Nowadays, some pioneer mathematicians are attempting to verify their proofs using the proof assistant Lean (de Moura et al., 2015; Tao, 2023). Writing proofs for formal statements demands mastery of formal language and domain-specific mathematical knowledge. To mitigate the complexity associated with completing proofs, several research efforts (Polu & Sutskever, 2020; Polu et al., 2023; Trinh et al., 2024) seek to automatically generate formalized proof through neural model, known as Neural Theorem Proving (NTP). NTP represents long-standing challenge for machine learning-based methods (Li et al., 2024), highlighting the limitations in the reasoning abilities of neural models. Prevalent Large Language Models (LLMs) (Brown et al., 2020; Dubey et al., 2024) still struggle with theorem-proving, despite excelling in related reasoning-intensive scenarios such as math reasoning (Reid et al., 2024) or code generation (Guo et al., 2024). The key challenge of theorem-proving lies in data scarcity (Li et al., 2024; Trinh et al., 2024). Due to the difficulties associated with the manual formalization of theorems, formal corpora available on the Internet are relatively scarce compared to the general text (Azerbayev et al., 2023). Synthetic data has shown promise in alleviating the data scarcity problem. Some works propose to directly create theorems in symbolic space. For instance, Wang & Deng (2020) attempts to train neural theorem generator on human-written formal theorems for the low-weighted formal system Metamath. Other efforts focus on generating theorems based on symbolic rules (Wu et al., 2021; Trinh et al., 2024), which are restricted to specific domain of mathematics, such as inequality theorems Work done during internship at Microsoft Research Asia. corresponding author. 1 and 2D geometry. Additionally, there are endeavors focused on autoformalization (Xin et al., 2024; Ying et al., 2024), which typically translates natural language mathematical problems into formalized statements, samples correct proofs, and retrains the theorem prover iteratively. Autoformalization has yielded promising results in competition-level theorem-proving tasks through the use of large autoformalized datasets. However, the process of formalizing problems and retrieving proofs is labor-intensive and cost-prohibitive. The distribution of formalized theorems is constrained by the pool of human-collected natural language problems and the intrinsic capabilities of the model. Compared to autoformalization, synthesizing theorems in symbolic space is more direct process without intermediate translation, and is also easier to scale up to large, cost-effective CPU units. Building upon the advanced Lean theorem prover, we introduce general method that synthesizes theorems directly in symbolic space. We analogize theorem synthesis to constructing functions in general programming language and adopt an up-to-down approach. Initially, new statement (function declaration) is constructed for each candidate theorem. Specifically, with the mathematical library of Lean Mathlib41 as seed data, we aim to find symbolic manipulation Φ between two existing statements. We posit that Leans tactics serve as suitable candidates for manipulation Φ because of their efficacy in handling symbolic expressions. {rw, apply} are basic tactics frequently used in theorem proving and capable of handling the equality and implication relationship between terms. We assign both tactics to the set of manipulations Φ and retrieve the invocable theorems for each candidate theorem by executing predefined list of instructions in an interactive Lean environment. Then we mutate the candidate statement by replacing its components with their corresponding equivalent forms or logical antecedents. Ultimately, we construct the corresponding proof (function body) based on the existing proof and verify its correctness using Lean. The worked example shown in Fig 1 illustrates the entire procedure of our algorithm. This algorithm is executed on large CPUonly computing unit for several days. Our method increases the number of theorems in Mathlib by an order of magnitude from 110,657 to 6,326,679. This significant increase in the number of theorems demonstrates the potential of creating theorems in symbolic space. We pre-train the LLMs on the combination of Mathlib theorems and their mutated variants. Then we fine-tune the models on the extracted state-tactic pairs, composing both the training split of Mathlib and additional synthesized state-tactic pairs. We demonstrate the effectiveness of our method by evaluating the theorem-proving capability of these provers on the challenging Leandojo benchmark. Our synthetic data improve the performance by around 5% (over 70 theorems) on the novel premises split. Furthermore, the synthesized data exhibit promise in enhancing the outof-distribution theorem-proving ability of LLMs, as evidenced by performance increase of about 2.5% on the competition-level miniF2F benchmark. Our main contributions are as follows. 1) To the best of our knowledge, this work represents the first general data synthesis framework in the symbolic space for the Lean theorem prover, effectively complementing mainstream autoformalization-based methods. Notably, our synthesis pipeline increases the number of theorems in Mathlib4 by an order of magnitude. 2) The synthesized data and associated code will be made open-source to facilitate further research in data synthesis for formal systems. Also, the synthesized theorems can serve as valuable supplement to Mathlib. 3) We conduct comprehensive evaluation on both in-distribution and out-of-distribution benchmarks, providing empirical insights to enhance the theorem-proving capabilities of LLMs."
        },
        {
            "title": "2 RELATED WORK",
            "content": "Neural Theorem Proving Proof assistants such as Lean (de Moura et al., 2015), Isabelle (Paulson, 1994) or Coq (Barras et al., 1997) are gaining traction within the mathematical community. These tools help mathematicians in interactively formalizing and checking the correctness of proofs (Tao, 2024). Neural networks have shown promise in lowering the barrier of using specific formal language for mathematicians, serving as copilot (Song et al., 2024; Welleck & Saha, 2023). Polu & Sutskever (2020) propose to prove theorems automatically by training decoder-only transformer to predict the next proofstep and construct the entire proof through predefined search tragedy. Then series of works seek to enhance the efficiency of this framework by incorporating auxiliary training objectives (Han et al., 2022), conducting reinforcement learning (Polu et al., 2023; Xin et al., 2024), improving proof search tragedy (Lample et al., 2022; Wang et al., 2023; Xin et al., 2024), refining 1https://github.com/leanprover-community/mathlib4 2 Figure 1: The overview of our synthesis pipeline. At the theorem level, we find invocable theorems that can be used to rewrite or apply to the assumptions or assertion of the candidate statement, such as the iff and implication rules about the Coprime. Then, we construct the new statements by replacing the specific component with its equivalent form or antecedent. At the proof tree level, our method merges two existing proof trees. the premise-selection (Mikula et al., 2023; Yang et al., 2023) and so on. Our work follows the framework proposed by Polu & Sutskever (2020), using proofstep prediction as the objective and best-first-search as the search tragedy. Synthetic Theorem Creation Data scarcity is main challenge for NTP (Li et al., 2024). Synthetic data can effectively alleviate this problem alongside manual data collection (Wu et al., 2024). The current approach for synthesizing theorems diverges into two pathways. For autoformalizationbased methods, the prevalent statement-level autoformalization is to translate set of natural language problems into formal statements, followed by expert iteration to sample collection of proofs for these statements (Wu et al., 2022; Xin et al., 2024; Ying et al., 2024). The proof-level autoformalization (Jiang et al., 2023; Huang et al., 2024) leverages LLM to generate proof sketch, which is completed by symbolic engines such as Sledgehammer (Bohme & Nipkow, 2010). In contrast, the second pathway focuses on synthesizing theorems in formal space. Wang & Deng (2020) propose to train neural theorem generator to synthesize theorems on low-weight formal system, Metamath (Megill & Wheeler, 2019) which has only one tactic substitute. Wu et al. (2021) sequentially edits the seed expression according to predefined set of axioms and an axiom order to create new statement, concatenating the implications from all steps to build complete proof. This method is used to create theorems on domains grounded in well-established axioms, such as inequality theorems and ring algebra (Polu & Sutskever, 2020). Beyond these works, AlphaGeometry (Trinh et al., 2024) can solve olympiad geometry without human demonstrations by constructing statements and proofs in symbolic space from scratch, using carefully designed deduction engine and large-scale computing resources. Our method aims to directly synthesize theorems in symbolic space on the advanced Lean theorem prover, fully utilizing the power of computing. 3 Benchmarks for Theorem Proving Most neural theorem provers based on Lean are primarily trained on Leans mathematical library, Mathlib. It encompasses broad spectrum of mathematical subjects (e.g., algebra and analysis), composed of over 120,000 theorems along with their respective axioms and definitions. Researchers test the capability of neural models to prove in-distribution theorems on held-out set of Mathlib (Polu & Sutskever, 2020; Han et al., 2022; Polu et al., 2023). Yang et al. (2023) creates challenging data split of Mathlib (novel premise split) which requires testing proofs to use at least one premises not seen in the training stage and mitigates the overestimated phenomena in the traditional setting of evaluation (random split). Another widely-used benchmark, miniF2F, (Zheng et al., 2022) is cross-system benchmark and includes competitionlevel problems as well as IMO-level problems in the domain of algebra and number theory."
        },
        {
            "title": "3 METHOD",
            "content": "Theorems written in Lean can be viewed as special form of code, where declarations and function bodies possess precise mathematical meanings. The initial step in creating new theorem involves formulating theorem statement (function declaration) that defines the essence of the theorem. Then, one must verify its correctness by generating proof block (function body) and submitting it to the proof assistant for validation. The resulting theorems that pass type checking can serve as supplementary data for training neural theorem prover. 3.1 STATEMENT GENERATION Find invocable theorems Constructing new statement is the first step in creating Lean theorem. The candidate theorem has statement denoted as s. In the corresponding Lean repository, there exists set of potentially invocable theorems Tp = {ti}N i=0. We assume that the challenge in creating new theorem involves effectively leveraging the possibly invocable theorem ti to mutate the candidate statement s. This understanding arises from two perspectives. Each theorem in Lean can be represented in the form of proof tree as presented in Fig 1. The leaf nodes represent the assumptions, and the root node signifies the assertion. At the tree level, the task of generating new Lean theorem with existing theorems is equivalent to defining operations Φ that combine the proof trees of ti and t. To streamline this process, our focus is solely on establishing the connection between the root node of ti and the leaf node (or root node) of the candidate theorem t. From mathematical standpoint, we can transform target formula into an equal variant or break it down into multiple subformulas that suffice to prove the original formula, by employing the equality or only if relationship between formulas. The mathematical interconnections between formulas provide heuristic insights on how to mutate to create new theorem. Similarly, we can substitute the terms in with their equivalent forms or logical antecedents. For instance, consider the statement + > + d, > 0 m(a + b) > m(c + d) and the known theorems > ea > eb and > c, > = a+b > c+d. From these, we can derive new theorems: + > + d, > 0 em(a+b) > em(c+d), and > c, > d, > 0 = m(a + b) > m(c + d). In summary, identifying operations Φ that use ti to modify the assumptions or assertion of is the primary step in constructing new statements. With their intrinsic mathematical meanings and proficiency in manipulating terms within Lean, tactics are promising candidates for the operations Φ. Following the preceding discussion, we choose two frequently used basic tactics, rw and apply to formulate Φ. rw The rewriting tactic rw is mostly used to replace some terms in the target expression with their equivalent forms according to the given identity or iff (a.k.a., if and only if) rules2. In the presence of an identity : = or an iff rule : Q, rw [h] substitutes all occurrences of term on the left side of equality in the proof goal with term on the right side. The direction of substitution can be reversed by adding back arrow in the bracket (rw [ h]). The target of rewriting can also be changed using at, e.g. rw [h] at h1, where h1 is an arbitrary assumption of the current proof state. apply The apply tactic is suffice-to tactic. Given an implication, it will match the consequent with the proof goal. If matched, it will transform the goal into the antecedent 2Strictly speaking, the rw tactic is used to handling equality in Lean, the identity and iff are just some kinds of equality. 4 Table 1: Templates for instructions designed to be executed in Lean environment. We determine if theorem is invocable by running the specific instruction. Tactic Instruction Template Description Equality invocable theorem : = or rw apply rw [invocable theorem] rw [invocable theorem] rw [invocable theorem] at assumption rw [invocable theorem] at assumption replace all as in goal with replace all bs in goal with replace all as in assumption with replace all bs in assumption with Implication invocable theorem : = have assumption := by apply invocable theorem set assumption as current proof goal, and try to argue backwards of the implication. With an implication rule : = and proof goal Q, then apply [h] will reduce the goal to proving , which means that proving suffices to prove by implication. Similarly, apply can be used to modify the assumption by deducing the implication forward. With assumption h1 : , then apply [h] at h1 will change h1 into Q, which means If is true, then we can assert is true by the implication. Algorithm 1 Find invocable theorems Input: candidate statement s, potential invocable theorems Tp, instruction templates Output: invocable theorems Ti (env, init state) INIT(s) Ti for in Tp do Ti : {(init state, next state, instruction) } initialize gym-like environment and retrieve initial state for in do for each instruction template instruction inst FORMAT(t, i) next state RUN TAC(env, init state, inst) run tactic specified by instruction and theorem if VALID(next state) then Add (init state, next state, inst) to Ti if return valid proof state end if end for end for To generate new statement, we need to find the relationship between the candidate statement and the potentially invocable theorems Tp. The pseudocode outlined in Algorithm 1 describes the main procedure to find invocable theorems. The process involves initializing gym-like environment to interact with Lean and extracting the initial proof state for the candidate statement. Then, the algorithm iteratively tests whether one theorem can be used to rewrite or apply to the candidate theorem leveraging the instruction templates shown in Table 1. Suppose the feedback from the interactive environment is deemed valid according to predefined criteria, the algorithm adds the proof states before and after the tactic running together with the respective instruction to the set of invocable theorems Ti. More information about this process is described in Appendix C.2. Mutate statements After obtaining the initial set of invocable theorems, we applied some filtering rules to Ti to improve the quality of the data and lower the complexity of mutating statements. With filtered invocable theorems Ti, we construct new statements by replacing the components with their equivalent forms or antecedents. Since we use tactics in Lean to formulate the operations Φ, most symbolic manipulations are bypassed to the Lean proof assistant. What remains is just parsing and replacing. Specifically, for the candidate statement and instruction i, we utilize its abstract syntax tree to pinpoint the exact location within the code that requires modification. Then we replace the corresponding parts with mutants parsing from the subsequent proof state generated by the execution of specific tactic. The details of our algorithm and helpful source code are described in C.3."
        },
        {
            "title": "3.2 PROOF GENERATION AND THEOREM VERIFICATION",
            "content": "Mutated statements can serve as useful lemmas for theorem-proving only if we can construct proofs that pass the verification of the proof assistant. We construct the entire proof using symbolic rules. Although neural provers and other automated theorem proving (ATP) tools (e.g., hammer) can generate more natural and diverse proofs than rule-based methods, they are compute-intensive and do not guarantee the correctness of the generated proofs. The idea of building proof block is intuitive. Given that we only make one-step modification to the statement, transforming the original proof state to mutated proof state, logical approach is to reverse the mutation and utilize the original proof to complete the remaining proving process. We use have tactic to restore the modified part of statement (the original assumption or assertion) by introducing lemma. have The have tactic enables users to introduce new assumption into the current proof state if they can prove it. Given an assumption h1 : and an implication rule h2 : = Q, new assumption : can be added by have h: := by apply h2 at h1; exact h1. This tactic is usually used to introduce helpful lemmas when proving theorem. In addition to its ability to introduce new assumptions into the proof state, have can be used in both tactic-style proof and term-style proof, which enlarges the margin for theorems to which our method can be applied. Apart from this, the additional have instruction transforms the mutated complex proof state into canonical proof state. To some extent, this transformation is analogous to constructing an auxiliary point in geometry problems, which we assume will be beneficial for theorem proving in the general domain. Subsequently, we combine the original proof with this lemma to build the proof for the new statement. The details of the implementation of proof generation are depicted in the Appendix C.3. We construct the proof block for each mutated theorem. Then we submit the synthesized theorems to the Lean theorem prover for verification and remove the wrong ones. Details of the verification process are provided in Appendix C.4. Finally, we obtain set of variants = {vi}n i=0 defined by the keyword example for each candidate theorem. 3.3 MODEL TRAINING Regarding the synthetic data, we have two observations. At the theorem level, the synthetic data comprises numerous theorems, each with statement distinct from existing theorems. At the statetactic level, the process of constructing proofs introduces additional state-tactic pairs, primarily centered on rw and apply. Based on these insights, we assume that the synthetic data can serve as an augmented corpus for continual pretraining and supervised finetuning. Specifically, we fine-tune LLMs using the proofstep prediction objective proposed by Polu & Sutskever (2020), utilizing statetactic pairs derived from both seed theorems and synthetic theorems. Given the current proof state, the model is required to predict the next tactic sequence that contributes to the proving of the target theorem. We utilize the prompt template used by Welleck (2023), as shown in Fig.2. Figure 2: Prompt template"
        },
        {
            "title": "4 EXPERIMENTS",
            "content": "We implement the data-synthesis pipeline described in Section 3 for rw and apply, constructing set of variants for each candidate theorem in Mathlib. We train the LLMs on mixture of humanwritten theorems and synthetic ones. To examine the effectiveness of synthetic data, we evaluate the theorem prover on two benchmarks that are widely adopted by the research community: 1) Test split of Mathlib, which shares the same distributional characteristics as the seed theorems; 2) miniF2F, challenging benchmark focusing on competition-level problems that exhibits distinct distribution compared to seed data. The experimental results derived from both benchmarks demonstrate the potential efficacy of our approach. 4."
        },
        {
            "title": "IMPLEMENTATION DETAILS",
            "content": "Data-Synthesis We choose Mathlib43 which contains 116,695 theorems as the seed data for datasynthesis. Our synthesis pipeline is built upon Leandojo4 (Yang et al., 2023), Python module that enables tracing specific Lean repository, extracting the state-tactic pairs and abstract syntax trees (ASTs), and interacting with the Lean environment5 (run tac API). Finding invocable theorems is the most time-consuming step of our pipeline. For rw, the time overhead amounts to 14 days using 4,096 CPU cores6. For apply, it takes 7 days at this stage using 2,048 CPU cores with one-hour timeout for each theorem. The substantial time cost is attributed to the O(n2) complexity of our algorithm and the memory-intensive characteristics of Leandojo. We believe this overhead could be greatly reduced through more meticulous implementation. After retrieving the invocable theorems, we construct new statements and proofs for the target theorems in approximately an hour using 24 CPU cores. We then write back the mutated theorems and compile the enlarged repository through lake build, utilizing 2,048 CPU cores. We retrieve the error messages returned by Lean, which can be parsed to locate the wrong theorems. Finally, we trace the enlarged repository on 96-core machine for 3 days, obtaining the additional state-tactic pairs by parsing the AST of each file. Model Training We select Llama-3-8B (Dubey et al., 2024) and deepseek-coder-base-v1.57B (Guo et al., 2024) as our base models. We conduct continual pretraining with the next-token prediction objective for one epoch. Then we fine-tune the models with the proofstep prediction objective (Polu & Sutskever, 2020) for two epochs. All experiments are conducted on 8 H100 GPUS. We employ linear learning rate scheduler with 3% warm-up period and maximum learning rate of 2e-5. We set the global batch size to 256 and the cutoff length to 2,048. All models are trained using Deepspeed ZeRO Stage3 (Rajbhandari et al., 2021) and Flash-Attention 2 (Dao, 2023). We utilize the open-sourced codebase Llama-Factory (Zheng et al., 2024) for all training experiments. Evaluation We follow the evaluation setting used in Azerbayev et al. (2023). We use the frequently used best-first-search as our search tragedy and set 10-minute timeout. The search budget can be represented as , where denotes the number of attempts, denotes the number of generated tactics per iteration, and denotes the maximum number of generations. Following Azerbayev et al. (2023), we set = 1, = 32 and = 100. Our evaluation script is modified from an open-source implementation (Welleck, 2023) which is based on vLLM (Kwon et al., 2023) and Leandojo (Yang et al., 2023). We utilize Leandojo Benchmark (Yang et al., 2023) which contains 2,000 theorems as the test split of Mathlib4 and report the results on both the random split and the novel premises split. We remove the subsets of theorems for both splits that can not be initialized by Leandojo. There remain 1,929 theorems in random split and 1,659 theorems in novel premises split. We upgrade the tool-chain version of miniF2F (Zheng et al., 2022) to v4.6.0 rc1. 4.2 ANALYSIS OF SYNTHETIC DATA We separately run the synthesis pipeline for these two tactics. For rw, we choose Mathlib theorems as candidate theorems. Additionally, candidate theorems for apply should have at least one explicit 3commit: 2iufd 3c307701fa7e9acbdc0680d7f3b9c9fed9081740 4version: 1.7.1 5lean-toolchain: v4.6.0 rc1 6512 CPU nodes, each node has 8 cores and 56GB RAM 7 Table 2: Number of theorems. Stage one: the number of invocable instructions for all candidate theorems. Stage two: the number of theorems that pass the verification of the Lean theorem prover. Tactic Candidate theorems Stage one Stage two Expansion Conversion Ratio rw apply 110,657 78,871 5,081,544 9,483,504 2,830,817 3,495,832 25 44 56% 37% assumption. In practice, the synthesis process is divided into two stages. In the first stage, we find the potential invocable theorems for each candidate theorem by running specific tactic. In the second stage, we construct the new theorems and verify their correctness using the Lean theorem prover. Table 2 shows the number of theorems of different stages. For both tactics, we increase the number of theorems by an order of magnitude (25 for rw and 44 for apply). The conversion ratios from the potential invocable theorems to the outcomes are primarily determined by the method used to construct the new statements and proofs. We believe that finer implementation could greatly improve the conversion ratio. Figure 3 shows the dynamics of the distribution of mathematical subjects. The rw tactic increases the percentages of Analysis, Ring Algebra, Number Theory, and so on. The apply tactic mainly contributes to the fields of Analysis and Topology. Further information about synthetic data can be found in the Appendix D. Figure 3: Distribution of mathematical subjects. For each employed tactic, we mix the generated variants with the original theorems. a) The distribution of Mathlib. b) The distribution of Mathlib + rw. c) The distribution of Mathlib + apply. Our method synthesizes large collection of new theorems utilizing each tactic. Then we combine them with the theorems in Mathlib as the training data for continual pre-training. Our approach also introduces new state-tactic pairs during the theorem-construction process. We write the variants to corresponding lean files and extract additional state-tactic pairs using Leandojo. The synthesized data are categorized primarily based on the employed tactic, specifically rw and apply. Variants and their corresponding state-tactic pairs that appear in the test split of the Leandojo benchmark are removed. Furthermore, the extracted state-tactic pairs are deduplicated according to the invocable theorem (i.e., premise) used in the tactic instruction. Finally, we obtain about 30k data points for each tactic. We combine them with the training set of Leandojo (Mathlib-train) that composes over 200k data points to form the SFT dataset. detailed description of the deduplication process and training data are presented in the Appendix D.3. 4.3 EXPERIMENTAL RESULTS 4.3.1 MAIN RESULTS We conduct continual pretraining on the augmented lean corpus. Then we fine-tune the LLMs on the mixture of Mathlib-train and additional state-tactic pairs. The training data are grouped by the tactic employed in the additional state-tactic pairs. We evaluate the effectiveness of our method on the challenging Leandojo benchmark and report results on different mixtures of data. As shown in Table 3: Results on Mathlib. tidy: tactic in Mathlib that uses heuristics to complete proof. We select the performance of each model solely fine-tuned using Mathlib-train as the main baseline. Mathlib-train + x: the performance of the model pre-trained and fine-tuned on mixture of Mathlibtrain and additional data about x. random novel premises Search Budget Methods tidy GPT-4 Reprover (Yang et al., 2023) w/ retrieval llmstep (Pythia 2.8b) (Welleck & Saha, 2023) Llama3-8b Mathlib-train + rw Mathlib-train + apply Mathlib-train + rw + apply 23.8 29.0 47.6 51.2 47.6 50.1 58. 5.3 7.4 23.2 26.3 - - 38.52 59.62 (+1.40) 58.84 (+0.62) 59.82 (+1.60) 42.13 (+3.62) 41.29 (+2.77) 43.22 (+4.70) deepseek-coder-7b-base-v1.5 57. 39.24 Mathlib-train + rw Mathlib-train + apply Mathlib-train + rw + apply 59.25 (+1.55) 58.68 (+0.98) 60.39 (+2.69) 42.98 (+3.74) 40.51 (+1.27) 43.46 (+4.22) - 1 35 1 64 1 64 1 32 2 32 1 1 32 1 32 1 32 1 32 1 32 1 32 1 32 Table 3, our synthetic data consistently improve the theorem-proving capabilities of LLMs. Compared with solely finetuning on the training split of Mathlib, data augmentation for single tactic demonstrates beneficial effect on the theorem-proving ability of LLMs. Moreover, the positive impacts of each tactic can be cumulative. Training on the combination of rw variants and apply variants results in significant performance improvement in the challenging novel premises split of Leandojo benchmark, where the model is required to use at least one new premise to prove the target theorem (+4.7%, 78 theorems for Llama3-8b; +4.22%, 70 theorems for deepseek-coder-7bbase-v1.5). Our synthetic data still make certain improvement on the random split, where the performance of models is over-estimated by allowing it to prove many theorems through memorization. In conclusion, the results of the experiment show that simply mutating the seed theorems and introducing state-tactic pairs of single tactic can relieve the data scarcity problem and enhance the theorem-proving ability of LLMs. 4.3.2 EFFECTIVENESS OF CONTINUAL PRETRAINING To examine the necessity of continual pretraining, we assess and contrast the performance of the LLM on Leandojo benchmark when the pretraining stage is included versus when it is excluded from the experimental setup. We use models fine-tuned on various combinations of state-tactic pairs as our baselines and present the results of pretraining on the augmented corpus. As shown in Table 4, the continual pretraining stage demonstrates positive influence on the performance of LLMs across diverse supervised fine-tuning settings. The experimental results indicate that continual pretraining before the supervised finetuning stage is also beneficial to the theorem-proving ability of the LLM. 4.3.3 INFLUENCE OF THE QUANTITY OF SFT DATASET We deduplicate the synthesized state-tactic pairs of each tactic by the invocable theorem (i.e., premise). Then we obtain about 30k data points for each tactic. To examine the influence of the quantity of the SFT dataset, we compare the performance of Llama-3-8B, trained on different quantities of additional data points, on novel premises split of Leandojo benchmark. As shown in Fig 4, the selected quantity (30k) achieves relatively optimal compromise between the performance and overhead. The experimental results also reveal that enlarging the quantity of state-tactic pairs of single tactic tends to lead to rapid saturation. We assume that the key to continually improving the theorem-proving ability lies in keeping the diversity of tactics during the process of scaling the synthetic data. More details are presented in Appendix D.3.4. 9 Table 4: Effectiveness of continual pre-training. We grouped the dataset for CPT and SFT by the tactic employed in the additional state-tactic pairs. Methods random novel premises random novel premises Llama3-8b deepseek-coder-base-7b-v1. sft: mathlib-train w/o cpt rw apply rw + apply 58.22 59.56 (+1.35) 58.42 (+0.21) 59.72 (+1.50) 38.52 42.56 (+4.04) 41.29 (+2.77) 42.19 (+3.68) 57.70 58.74 (+1.04) 58.58 (+0.88) 59.67 (+1.97) 39.24 40.69 (+1.45) 40.02 (+0.78) 41.65 (+2.41) sft: mathlib-train + rw w/o cpt rw 57.85 59.62 (+1.76) 41.59 42.13 (+0.54) 58.63 59.25 (+0.62) 41.05 42.98 (+1.93) sft: mathlib-train + apply w/o cpt apply 56.71 58.84 (+2.13) 40.02 41.29 (+1.27) 57.96 58.68 (+0.73) 41.17 40.51 (-0.66) sft: mathlib-train + rw + apply w/o cpt rw + apply 58.53 59.82 (+1.30) 41.95 43.22 (+1.27) 58.37 60.39 (+2.02) 42.92 43.46 (+0.54) Figure 4: Influence of the quantity of synthesized data points. 4.3.4 ANALYSIS OF OUT-OF-DISTRIBUTION PERFORMANCE We evaluate Llama-3-8b using the competition-level theorem proving benchmark miniF2F. As shown in Table 5, our synthesized data still helps to improve the theorem-proving ability of LLMs on the out-of-distribution benchmark. The magnitude of this improvement is comparatively smaller than that observed on the in-distribution benchmark. We attribute this discrepancy to the divergence between synthesized tactics and the preferred tactics to prove competition-level problems. Through manual inspection of the correct proofs generated by various LLMs trained on Mathlib-train, we identify tendency to favor advanced and automated tactics (e.g., simp, omega, linarith, norm num, etc.). Additionally, we analyze the distribution of tactics used in proved theorems across different data compositions and make the following observations. 1) Data augmentation on single tactic will increase the models preference for the specific tactic. 2) Adjusting the distribution of different tactics within the dataset is promising to improve the theorem-proving ability of LLMs. The entire analysis process is illustrated in Appendix E.2. Table 5: Results on miniF2F. We evaluate the performance across different data compositions and list the ratio of rw, apply, norm num and linarith used by Llama3-8b to prove these theorems. Methods miniF2F-test Correct/Total rw apply norm num linarith Mathlib-train Mathlib-train + rw Mathlib-train + apply Mathlib-train + rw + apply 34.01 35.24 36.07 36.48 (+2.47) 83/244 86/244 88/244 89/ 16.10 18.75 8.87 12.31 0.00 0.78 2.42 0.77 27.12 14.84 20.16 26.92 16.95 21.88 15.63 16."
        },
        {
            "title": "5 CONCLUSION",
            "content": "We have presented general data-synthesis framework for the Lean theorem prover, which amplifies the theorem-proving capability of the LLM through symbolic mutation. Our algorithm increases the number of theorems in Mathlib by an order of magnitude and achieves promising results in improving the theorem-proving ability of the LLM. We discuss the limitations of our method in Appendix B. Synthesizing formal theorems is an inherently challenging problem. Our approach, much like ancient alchemy, involves experimenting with substantial number of theorems in the hope of uncovering valuable gold. We aspire for our algorithm and data to serve as foundation for further research, advancing theorem synthesis from alchemy to chemistry."
        },
        {
            "title": "REFERENCES",
            "content": "Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Albert Q. Jiang, Jia Deng, Stella Biderman, and Sean Welleck. Llemma: An open language model for mathematics. CoRR, abs/2310.10631, 2023. doi: 10.48550/ARXIV.2310.10631. URL https://doi.org/10.48550/arXiv.2310.10631. Bruno Barras, Samuel Boutin, Cristina Cornes, Judicael Courant, Jean-Christophe Filliatre, Eduardo Gimenez, Hugo Herbelin, Gerard Huet, Cesar Munoz, Chetan Murthy, et al. The Coq proof assistant reference manual: Version 6.1. PhD thesis, Inria, 1997. Sascha Bohme and Tobias Nipkow. Sledgehammer: Judgement day. In Jurgen Giesl and Reiner Hahnle (eds.), Automated Reasoning, 5th International Joint Conference, IJCAR 2010, Edinburgh, UK, July 16-19, 2010. Proceedings, volume 6173 of Lecture Notes in Computer Scidoi: 10.1007/978-3-642-14203-1 9. URL https: ence, pp. 107121. Springer, 2010. //doi.org/10.1007/978-3-642-14203-1_9. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901, 2020. Tri Dao. Flashattention-2: Faster attention with better parallelism and work partitioning. CoRR, abs/2307.08691, 2023. doi: 10.48550/ARXIV.2307.08691. URL https://doi.org/10. 48550/arXiv.2307.08691. Leonardo Mendonca de Moura, Soonho Kong, Jeremy Avigad, Floris van Doorn, and Jakob von Raumer. The lean theorem prover (system description). In Amy P. Felty and Aart Middeldorp (eds.), Automated Deduction - CADE-25 - 25th International Conference on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings, volume 9195 of Lecture Notes in Computer Science, pp. 378388. Springer, 2015. doi: 10.1007/978-3-319-21401-6 26. URL https://doi.org/10.1007/978-3-319-21401-6_26. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, and Wenfeng Liang. Deepseek-coder: When the large language model meets programming - the rise of code intelligence. CoRR, abs/2401.14196, 2024. doi: 10.48550/ARXIV.2401.14196. URL https://doi.org/10.48550/arXiv. 2401.14196. Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W. Ayers, and Stanislas Polu. Proof artifact co-training for theorem proving with language models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview.net/forum?id=rpxJc9j04U. Yinya Huang, Xiaohan Lin, Zhengying Liu, Qingxing Cao, Huajian Xin, Haiming Wang, Zhenguo Li, Linqi Song, and Xiaodan Liang. MUSTARD: mastering uniform synthesis of theorem and proof data. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/ forum?id=8xliOUg9EW. Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou, Timothee Lacroix, Jiacheng Liu, Wenda Li, Mateja Jamnik, Guillaume Lample, and Yuhuai Wu. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/forum?id=SMa9EAovKMC. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with pagedattention. In Jason Flinn, Margo I. Seltzer, Peter Druschel, Antoine Kaufmann, 11 and Jonathan Mace (eds.), Proceedings of the 29th Symposium on Operating Systems Principles, SOSP 2023, Koblenz, Germany, October 23-26, 2023, pp. 611626. ACM, 2023. doi: 10.1145/ 3600006.3613165. URL https://doi.org/10.1145/3600006.3613165. Guillaume Lample, Timothee Lacroix, Marie-Anne Lachaux, Aurelien Rodriguez, Amaury Hayat, Thibaut Lavril, Gabriel Ebner, and Xavier Martinet. Hypertree proof search for neural theorem proving. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh (eds.), Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/ hash/a8901c5e85fb8e1823bbf0f755053672-Abstract-Conference.html. Zhaoyu Li, Jialiang Sun, Logan Murphy, Qidong Su, Zenan Li, Xian Zhang, Kaiyu Yang, and Xujie Si. survey on deep learning for theorem proving. CoRR, abs/2404.09939, 2024. doi: 10.48550/ ARXIV.2404.09939. URL https://doi.org/10.48550/arXiv.2404.09939. Norman Megill and David Wheeler. Metamath: computer language for mathematical proofs. Lulu. com, 2019. Maciej Mikula, Szymon Antoniak, Szymon Tworkowski, Albert Qiaochu Jiang, Jin Peng Zhou, Christian Szegedy, Lukasz Kucinski, Piotr Milos, and Yuhuai Wu. Magnushammer: transformer-based approach to premise selection. CoRR, abs/2303.04488, 2023. doi: 10.48550/ ARXIV.2303.04488. URL https://doi.org/10.48550/arXiv.2303.04488. Lawrence C. Paulson. Isabelle - Generic Theorem Prover (with contribution by T. Nipkow), volume 828 of Lecture Notes in Computer Science. Springer, 1994. ISBN 3-540-58244-4. doi: 10.1007/BFB0030541. URL https://doi.org/10.1007/BFb0030541. Stanislas Polu and Ilya Sutskever. Generative language modeling for automated theorem proving. CoRR, abs/2009.03393, 2020. URL https://arxiv.org/abs/2009.03393. Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, and Ilya In The Eleventh International Sutskever. Formal mathematics statement curriculum learning. Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/forum?id=-P7G-8dmSh4. Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith, and Yuxiong He. Zero-infinity: Breaking the GPU memory wall for extreme scale deep learning. CoRR, abs/2104.07857, 2021. URL https://arxiv.org/abs/2104.07857. Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jeanbaptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024. Peiyang Song, Kaiyu Yang, and Anima Anandkumar. Towards large language models as copilots for theorem proving in lean. CoRR, abs/2404.12534, 2024. doi: 10.48550/ARXIV.2404.12534. URL https://doi.org/10.48550/arXiv.2404.12534. Terence Tao, 2023. URL https://teorth.github.io/pfr/blueprint.pdf. Terence Tao. Machine assisted proof. Notices of the American Mathematical Society, to appear, 2024. Trieu H. Trinh, Yuhuai Wu, Quoc V. Le, He He, and Thang Luong. Solving olympiad geometry without human demonstrations. Nat., 625(7995):476482, 2024. doi: 10.1038/S41586-023-06747-5. URL https://doi.org/10.1038/s41586-023-06747-5. Haiming Wang, Ye Yuan, Zhengying Liu, Jianhao Shen, Yichun Yin, Jing Xiong, Enze Xie, Han Shi, Yujun Li, Lin Li, Jian Yin, Zhenguo Li, and Xiaodan Liang. Dt-solver: Automated theorem proving with dynamic-tree sampling guided by proof-level value function. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, 12 Toronto, Canada, July 9-14, 2023, pp. 1263212646. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.ACL-LONG.706. URL https://doi.org/10.18653/v1/ 2023.acl-long.706. Haiming Wang, Huajian Xin, Chuanyang Zheng, Zhengying Liu, Qingxing Cao, Yinya Huang, Jing Xiong, Han Shi, Enze Xie, Jian Yin, Zhenguo Li, and Xiaodan Liang. Lego-prover: Neural theorem proving with growing libraries. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/forum?id=3f5PALef5B. Mingzhe Wang and Jia Deng. Learning to prove theorems by learning to generate theorems. In Hugo Larochelle, MarcAurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/ d2a27e83d429f0dcae6b937cf440aeb1-Abstract.html. Sean Welleck."
        },
        {
            "title": "Neural",
            "content": "theorem proving tutorial ii. https://github.com/cmu-l3/ ntptutorial-II, 2023. Sean Welleck and Rahul Saha. CoRR, abs/2310.18457, 2023. doi: 10.48550/ARXIV.2310.18457. URL https://doi.org/10. 48550/arXiv.2310.18457. LLMSTEP: LLM proofstep suggestions in lean. Yuhuai Wu, Albert Q. Jiang, Jimmy Ba, and Roger Baker Grosse. INT: an inequality benchmark for evaluating generalization in theorem proving. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id=O6LPudowNQm. Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus N. Rabe, Charles Staats, Mateja Jamnik, and Christian Szegedy. Autoformalization with large language models. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh (eds.), Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/ d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html. Zijian Wu, Jiayu Wang, Dahua Lin, and Kai Chen. Lean-github: Compiling github LEAN repositories for versatile LEAN prover. CoRR, abs/2407.17227, 2024. doi: 10.48550/ARXIV.2407. 17227. URL https://doi.org/10.48550/arXiv.2407.17227. Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, and Chong Ruan. Deepseek-prover-v1.5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search. CoRR, abs/2408.08152, 2024. doi: 10. 48550/ARXIV.2408.08152. URL https://doi.org/10.48550/arXiv.2408.08152. Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Leandojo: Theorem provSaad Godil, Ryan J. Prenger, and Animashree Anandkumar. ing with retrieval-augmented language models. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine (eds.), Advances in Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, URL http://papers.nips.cc/paper_files/paper/2023/ 2023, hash/4441469427094f8873d0fecb0c4e1cee-Abstract-Datasets_and_ Benchmarks.html. Information Processing Systems 36: Annual Conference on Neural 2023. Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, and Kai Chen. Lean workbook: large-scale lean problem set formalized from natural language math problems. arXiv preprint arXiv:2406.03847, 2024. 13 Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. minif2f: cross-system benchmark In The Tenth International Conference on Learning for formal olympiad-level mathematics. Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview.net/forum?id=9ZPegFuFTFv. Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, and Yongqiang Ma. Llamafactory: Unified efficient fine-tuning of 100+ language models. CoRR, abs/2403.13372, 2024. doi: 10.48550/ARXIV.2403.13372. URL https://doi.org/10.48550/arXiv.2403. 13372."
        },
        {
            "title": "CONTENTS",
            "content": "A Background on Lean Limitations Detailed Information of Synthesizing Algorithms C.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.2 Find Invocable Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.3 Construct New Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.3.1 rw tactic . . . C.3.2 apply tactic . C.4 Verify the Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.5 Limitations of Synthesis Pipeline . . . . . . . . . . . . . . . . . . . . . . . . . . . Deeper Analysis of Synthetic Dataset D.1 Numerical Analysis . D.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.3 Details of Training Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.3.1 Examples of Training Data . . . . . . . . . . . . . . . . . . . . . . . . . . D.3.2 Preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.3.3 Classification of Extracted Tactics . . . . . . . . . . . . . . . . . . . . . . D.3.4 Influence of the Quantity of SFT Dataset . . . . . . . . . . . . . . . . . . Additional Experiments E.1 Effectiveness of Different Tactics . . . . . . . . . . . . . . . . . . . . . . . . . . . E.2 Analysis of the Tactics to Prove miniF2F Theorems . . . . . . . . . . . . . . . . . E.2.1 Preference in Used Tactics . . . . . . . . . . . . . . . . . . . . . . . . . . E.2.2 Influence of Additional Tactics . . . . . . . . . . . . . . . . . . . . . . . . 16 16 17 17 17 18 20 21 22 23 23 23 23 24 24 27 27 27 27"
        },
        {
            "title": "A BACKGROUND ON LEAN",
            "content": "Lean is functional programming language and interactive theorem prover based on dependent type theory. As one of the most popular formal systems, Lean aids mathematicians in formalizing statements and proofs in semi-auto style and enables them to verify the correctness of each proof step through rigorous type-checking. Theorem in Lean To some extent, theorems in Lean can be seen as special variant of functions in general-purpose programming languages. theorem consists of statement and corresponding proof. In Lean, the keyword theorem, example or lemma is used to define the function, sometimes followed by specific function name. The assumption of statement can be formatted as implicit or explicit arguments, while the assertion of the statement specifies the return type of the function. The proof of the statement can be viewed as the function body, which constructs proof term with the type specified by the assertion. There are two main proof styles in Lean: term-style and tactic-style. In term-style proofs, theorems are proven using constructive methods. On the other hand, tactic-style proofs sequentially decompose the proof goal using specific tactics. Although tactic-style proofs are less readable, they tend to have shorter proof lengths. Most machine learningbased theorem-proving systems focus on tactic-style proof. The synthesis method proposed by our paper can be applied to both styles. Tactic Lean offers various advanced tactics for theorem proving, which set it apart from other formal systems (e.g., Coq, Isabelle). In handwritten proofs, authors tend to guide the reader on building the proof through instructions such as apply the previous lemma, invoke the principle of mathematical induction, or simplify the expression. Similarly, tactics in Lean are used to describe how to construct proof term incrementally. They help users decompose the proof goal step by step, allowing users to focus on only one proof goal at time. Mathlib Mathlib7 is comprehensive mathematical library for Lean, largely maintained by the community, which encompasses broad spectrum of mathematical subjects (e.g., algebra and analysis) and consists of over 120,000 theorems along with their respective axioms and definitions. This extensive knowledge base serves as the primary corpus for neural theorem provers."
        },
        {
            "title": "B LIMITATIONS",
            "content": "Our method exhibits some limitations that remain to be addressed in future endeavors. Data Diversity and Quality We only define two symbolic rules (using two tactics) to synthesize new theorems. The implementation of the synthesis pipeline is over general and utilizes little domain knowledge, which affects the diversity and quality of synthetic data. The Cost of Synthesizing Despite the CPU-only nature of our algorithm, the cost of synthesizing remains huge. We believe the overhead can be significantly reduced with finer implementation and more specialized tools to interact with the Lean theorem prover. Single-Round v.s. Multi-Round Theoretically speaking, our algorithms can be iteratively executed by adding the synthesized theorems into seed theorems. Conversely, the synthesized repository is very heavy, which makes it hard to interact with Lean using Leandojo and deploy our algorithm on existing hardware. Theorem-level or Term-level Our method synthesizes theorems from top to bottom and introduces additional state-tactic pairs of specific tactics. Synthesizing formal data at the theorem level Ideally, we is not efficient and not consistent with the step-by-step nature of theorem-proving. anticipate that we can synthesize formal data directly at the term level, which aligns with the characteristics of interactive theorem proving. 7https://github.com/leanprover-community/mathlib 16 Up-to-down v.s. Down-to-up We synthesize theorems in an up-to-down fashion. We construct the new statements first and then retrieve the correct proofs. The up-to-down fashion depends on specific set of seed theorems, which restricts the diversity of synthetic data. more fundamental idea is that we can sample some terms in the symbolic space directly, merge them using symbolic manipulations, and then find the corresponding goals for this new theorem. This AlphaGeometrystyle idea is hard to implement in Lean and requires large amount of domain knowledge and engineering endeavors. Symbolic Synthesis in Conjunction with Other Techniques Our proposed method demonstrates significant potential for integration with other techniques to enhance the theorem-proving capabilities of LLMs. We posit that theorem synthesis in the symbolic space serves as valuable complement to prevailing auto-formalization methods. For instance, it may contribute to the expansion of autoformalized datasets. Besides, our approach generates substantial quantity of new proven statements which can be utilized as comprehensive database for Retrieval-Augmented Generation (RAG) (Yang et al., 2023; Wang et al., 2024). Our objective is to amalgamate these methodologies to develop robust theorem prover in the future."
        },
        {
            "title": "C DETAILED INFORMATION OF SYNTHESIZING ALGORITHMS",
            "content": "C.1 OVERVIEW As discussed in Section 3, the entire algorithm is composed of four steps. 1) Find invocable theorems for the candidate theorem by executing specific tactic and retrieving the resulting proof state. 2) Construct new statements, where we parse the resulting proof state and mutate the old statement with the help of AST. 3) Establish the entire proof by inserting have tactic and integrating it with the old proof to build the whole proof for this new statement. 4) Verify the correctness of generated theorems in Lean theorem prover. In practice, we separately run the time-consuming first step on hundreds of 8-core CPU nodes and unify step 2) and step 3) together to construct the new theorem. Then we will write back synthetic theorems and run lake build to verify the generated theorems. C.2 FIND INVOCABLE THEOREMS For each candidate theorem, we check whether other theorems can be used to rewrite or apply to it by executing tactics. We use the run tac API provided by Leandojo to run specific tactic and extract the valid proof state according to predefined criteria. The instruction templates for each tactic are listed in Table1. Here is the code snippet that illustrates this process. 1 args: 2 dojo: interactive environment init_state: initial proof state of target theorem theorem: possible invocable theorem hypos: the assumptions of the target theorem (extracted by parsing the AST) 6 7 def is_invocable_theorem( 8 9 ): 10 name = theorem.full_name if mode == \"rw\": dojo, init_state, theorem, hypos, mode=\"rw\" # e.g. rw [name] at hypo_name insts = get_rw_insts(name, hypos) elif mode == \"apply\": # e.g. have hypo_str := by apply name insts = get_apply_insts(name, hypos) res = [] for i, inst in enumerate(insts): try: next_state = dojo.run_tac(init_state, inst) except Exception as e: ... else: state_info = { \"init_state\": init_state.pp, # pp means pretty-printed 3 4 5 11 12 14 15 16 17 18 20 21 22 23 24 25 26 } 28 29 30 31 32 \"next_state\": next_state.error if isinstance(next_state, LeanError) else next_state.pp, \"rule\": inst if isinstance(next_state, LeanError): if mode == \"implication\" and \"unsolved goals\" in next_state.error: res.append(state_info) elif isinstance(next_state, TacticState): res.append(state_info) return res Listing 1: Find invocable theorems by running tactics. We set different validation criteria for each tactic. For the rw tactic, if the resulting state is TacticState, we annotate this theorem as invocable. In contrast, for the apply tactic, the resulting state should be unsolved goals. Additionally, we filter the resulting invocable theorems to simplify the problem of constructing new theorems. Specifically, we remove the invocable theorems whose next state contains meta-variables (e.g.,?a, ?m123) for the rw tactic and unnamed meta-variables (e.g.,?e12384) for the apply tactic. Ultimately, we retrieve the invocable theorems for each candidate theorem. One example of invocable theorems is shown in Fig 5. The experiments run on large collection of CPUs (5128-core for the rw tactic and 2568-core for apply). The substantial CPU requirement is largely due to the memory-intensive nature of Leandojo, which hinders multiprocessing on single node. We anticipate significant reduction in the cost of our experiments by implementing lighter interface for Lean interaction. The operation of apply is more complex and time-consuming than rw. We set one-hour timeout for each dojo environment to reduce the time cost. When running specific tactic, we do not add additional imports to the dojo environment to avoid introducing human preferences in the process of synthesis. This setting may narrow the scope of theorems that the tactic can access and lower the variety of invocable theorems. In summary, finding invocable theorems constitutes the most time-consuming and computationally intensive stage of our algorithm, entailing trade-offs among cost, time, and generated data volume. C.3 CONSTRUCT NEW THEOREMS To create new theorem, we construct the new statement using the invocable theorems returned by Section C.2 and then establish the entire proof through have tactic. Our symbolic engine is built upon Leandojo API, utilizing the extracted AST and some string manipulations. To facilitate the detailed explanation of algorithms, we will delineate the implementation of these two tactics separately in the following pseudocode or source code. C.3.1 rw TACTIC The logic of constructing new statement for rw tactic is simple. We just identify whether specific assumption or assertion has been rewritten by parsing invocable instructions with regular expressions. Then we parse the AST node of the candidate statement to locate the corresponding part that should be mutated. Finally, we extract the new assumption or assertion from the next proof state and replace the old one with the new one. The main procedure is shown in Algorithm 2. Algorithm 2 Construct new statement for rw tactic Input: candidate statement s, invocable theorem Output: mutated statement sm node EXTRACT AST(s) , next state, inst flag IDENTIFY(i) location PARSE(node, i, lag) should to be mutated CONSTRUCT(next state) new statement sm REPLACE(s, m, l) extract the AST of candidate statement get the next state and instruction flag specifies whether the assumption or assertion should be mutated parse AST node and locate the corresponding part that parse the next proof state and construct the target string 18 Figure 5: Examples of invocable theorems for apply After creating new statement, we should insert have tactic to construct the whole proof. If the assumption is modified, then we just restore it to the old one by reversing the direction of rw within have instruction and then concatenate it with the original proof. If the assertion is mutated, the have tactic can be used to prove the original assertion with initial proof block. Then we just rewrite the old proof goal to the new one to construct the whole proof. Here is simplified code snippet that illustrates this process. 1 def proof_generation_rw( 2 invocable_inst, flag, proof_str, conc_or_hypo_old=None, is_tactic_style=False ): 3 4 6 7 8 9 10 inst = invocable_inst[\"rule\"] if flag == \"hypo\": hypo_name = parse(inst, flag) # find the delimiter for proof str(e.g. := by or :=)(simplified version) 19 12 14 15 16 17 18 20 21 22 23 24 26 27 28 29 30 32 33 34 35 36 38 39 40 41 42 if is_tactic_style: delimiter = \":= by\" else: delimiter = \":=\" splits = proof_str.split(delimiter) proof_seqs = delimiter.join(splits[1:]) if flag == \"hypo\": rev_inst = reverse_rw(invocable_inst) have_template = \"have {subgoal} := by {proof_seqs}\" have_inst = have_template.format( subgoal=conc_or_hypo_old, proof_seqs=rev_inst) have_inst += f;exact {hypo_name} end_inst = proof_seqs elif flag == \"conclusion\": have_template = \"have : {subgoal} {delimiter} {proof_seqs}\" have_inst = have_template.format( subgoal=conc_or_hypo_old, delimiter=delimiter, proof_seqs=proof_seqs) head = \"by \" if not is_tactic_style else \"\" _suffix = \" at this;exact this\" end_inst = head + inst + _suffix # do indentation have_inst = indent_code(delimiter, proof_str, have_inst, indent_level =...) end_inst = indent_code(delimiter, proof_str, end_inst, indent_level =...) # concat the different parts of proof prefix = splits[0] + delimiter + suffix = end_inst if end_inst.startswith(n) else + end_inst new_proof = prefix + have_inst + suffix return new_proof Listing 2: Build the whole proof for rw tactic C.3. apply TACTIC Algorithm 3 Construct new statement for apply tactic Input: candidate statement s, invocable instruction Output: mutated statement sm node EXTRACT AST(s) , next state, inst M, PARSE(next state) for do initialize the set of new assumptions extract the AST of candidate statement get the next state and instruction get the set of metavaribales and other subgoals Assigning metavariables Add ASSIGN(m, next state) to end for for do Add ASSIGN(g, next state, ) to Fill the other subgoals depending on meta-varibales end for HANDLE NAMING CONFLICTS(H) new assumption hm CONCAT(H) location PARSE(node, i) mutated sm REPLACE(s, hm, l) parse AST node and locate the old assumption that needs to be Constructing new statements for apply tactic is more complex than rw. Applying theorem may introduce some metavariables and new subgoals into the local context for the resulting proof state as shown in Fig 5. We assign values to the metavariables by parsing the next state and then retrieve all subgoals containing metavariables as new assumptions. For each new assumption, we can extract its name and type from the proof state. To avoid naming conflicts, we define set of rules to rename the variable according to the naming conversion of Mathlib8. Ultimately, we concatenate all new assumptions and replace the old assumption with them. This procedure is shown in Algorithm 3. Similarly, we can construct the entire proof for the new statement by inserting have lemma. The simplified code snippet illustrates this process. 1 def proof_generation_apply(cases_goals, inst, proof_str, is_tactic_style) : if len(cases_goals) == 1: lemma = inst + \"; assumption\" elif len(cases_goals) > 1: lemma = inst + \"<;> assumption\" else: raise Exception(\"no available case and corresponding goal\") if is_tactic_style: delimiter = \":= by\" else: delimiter = \":=\" splits = proof_str.split(delimiter) proof_seqs = delimiter.join(splits[1:]) lemma = indent_code(delimiter, proof_str, lemma, indent_level=...) prefix = splits[0] + delimiter + suffix = proof_seqs if proof_seqs.startswith(n) else + proof_seqs new_proof = prefix + lemma + suffix return new_proof Listing 3: Build the whole proof for apply tatic 2 3 5 6 7 8 9 11 12 13 14 15 17 18 19 20 . C.4 VERIFY THE THEOREMS Our method creates set of variants for each candidate theorem in Mathlib4. We write the variants back to the original file and execute lake build for verification. We remove the wrong lines for each file by parsing the error message returned by Lean. Then, we will rebuild the repo to ensure the effectiveness of verification. We remove the files that cause errors in the rebuilding process. Specifically, for each 8-core CPU node, we only build one .lean file each time to speed up this process and simplify the logic of parsing. The whole experiment runs on 2,048 CPUs (2568-core). The code snippets illustrate the procedure for each CPU node. After verifying the correctness of the synthesized theorem, we extract the state-tactic pairs from our augmented Mathlib repository using Leandojo. For rw or apply, it takes three days for 96-core CPU machine to trace the enlarged repository. In practice, we split the modified lean files into several portions, separately write them into multiple lean repositories, and trace the repos on several 96-core CPU machines. 1 # single 8-core CPU node 2 res = [] 3 for idx, file in enumerate(files): 4 file { # for each modified file 5 7 8 9 10 11 13 file_name: \"name of the lean file\", text: \"the content of this file after writing synthesized variants into this file\" \"loc\": {\"theorem_name\": [(start_line_nb, end_line_nb)...]} } tmp = { loc: file[loc], file_name: file[file_name], text: file[text] } 8https://leanprover-community.github.io/contribute/naming.html 21 14 15 17 18 19 20 21 23 24 25 26 27 29 30 31 32 33 35 36 37 38 39 41 42 43 44 45 47 48 49 50 51 53 54 55 56 57 59 60 61 62 63 file_name = file[file_name] file_path = os.path.join(mathlib_package_path, file_name) # extract the old content of this file with open(file_path, \"r\") as f: old_str = f.read() # replace the old content with new content with open(file_path, \"w\") as f: f.write(file[text]) # change the build target to current file with open(LIBRARY_ROOT_FILE, w) as f: Mathlib.lean # LIBRARY_ROOT_PATH: module_name = file_name.replace(/, .).replace(.lean, ) f.write(f\"import {module_name}\") if have_variants(file): ## lake build the new mathlib project wd = os.getcwd() result = lake_build(mathlib_package_path) #a helper function os.chdir(wd) ## parse the output # subprocess error if result == None: tmp[valid_loc] = [\"No variants\"] elif result == 0: tmp[valid_loc] = tmp[loc] print(successful build) # timeout error elif result == -1: tmp[valid_loc] = [\"No variants\"] else: # find the error locations(line numbers) pattern = fr\"({file_name}):(d+):(d+): error:\" errors = re.findall(pattern, result) if len(errors) == 0: tmp[valid_loc] = [\"No variants\"] # parse exception else: # extract line numbers from errors error_line_nbs = ... # get the locations of all variants intervals = ... # drop the error ones and write back valid_locs = diff(intervals, error_line_nbs) write_back(valid_locs, file[text]) ## rebuilt the project if causes error then remove this wd = os.getcwd() result = lake_build(mathlib_package_path) os.chdir(wd) if result != 0: tmp[valid_loc] = [\"No variants\"] # file rebuild error else: # pass the rebuilding process tmp[valid_loc] = valid_locs else: tmp[valid_loc] = [No variants] # write back the original content with open(file_path, \"w\") as f: f.write(old_str) res.append(tmp) Listing 4: Verify the correctness of generated theorems C.5 LIMITATIONS OF SYNTHESIS PIPELINE Our synthesis pipeline is mainly based on the advanced Leandojo tool. We use it to interact with Lean, parse abstract syntax trees and trace state-tactic pairs. However, this tool has the following weaknesses. 1) It will generate significant number of temporary files that consume substantial disk space when initializing dojo environment. The memory-intensive nature of this tool hinders our 22 ability to effectively implement multiprocessing. 2) Moreover, it lacks native support for tracing local Lean repository, so we must first upload our data to GitHub. 3) We encounter challenges when tracing repository of scale significantly larger than that of Mathlib, which makes it hard to do multi-round synthesis. We aspire to enhance the functionality of the Leandojo tool to tackle more demanding scenarios in our forthcoming endeavors. In addition, the process of constructing statements and proofs plays an important role in data volume and diversity. Our implementation involves parsing the abstract syntax tree for localization and conducting various string manipulations, which is straightforward but struggles with sophisticated situations such as coercion, naming conflicts, and other corner cases. We are looking forward to refactoring our modification logic with the metaprogramming API of lean 9 in the future, which is more robust and easier to extend."
        },
        {
            "title": "D DEEPER ANALYSIS OF SYNTHETIC DATASET",
            "content": "D.1 NUMERICAL ANALYSIS The histogram of the number of variants synthesized by each tactic is shown in Figure 6. Figure 6: The distribution of the number of variants (only 99% of the data are visualized). For each tactic, we also list the top 20 theorems with the highest number of variants in Figure 7. D.2 EXAMPLES Due to the large volume of synthetic data, it is challenging to display all the data in the appendix. We only display subset of demo theorems for reference. The proof lengths of these theorems range from 1 to 3 lines. To explore further details, please examine our dataset. The synthesized theorems of rw tactic are displayed in Fig 8. The synthesized theorems of apply are displayed in Fig 9. D.3 DETAILS OF TRAINING DATA D.3.1 EXAMPLES OF TRAINING DATA As shown in Fig 10, we synthesize series of variants for each candidate theorem by employing different tactic instructions to mutate existing theorems. We simply combine these additional theorems with the original theorems in Mathlib and train LLMs on this augmented corpus. In addition to synthesizing variants for each candidate theorem, symbolic manipulations to construct new theorems also introduce some new state-tactic pairs. What should be noted is that the state-tactic pairs 9https://leanprover-community.github.io/lean4-metaprogramming-book/ 23 Figure 7: The top20 theorems for rw and apply. are extracted by Leandojo rather than manually designed symbolic rules. We have not performed any post-processing on the extracted state-tactic pairs. We group the extracted theorems by the employed tactics (rw, apply, have). The examples of rw and apply are shown in Fig 11. The examples of have are shown in Fig 12. D.3.2 PREPROCESSING The synthesized variants of theorems and corresponding state-tactic pairs appearing in the test split of Leandojo benchmark are removed. During the data synthesis process, an invocable theorem may be used to rewrite or apply to different candidate theorems. Thus, many data points extracted from the augmented Mathlib repository share the same tactic and invocable theorem (i.e., premise), such as premise in rw [A] or apply A. These data points have similar changes in the proof state. We keep one state-tactic pair for each used premise in the synthesized state-tactic pairs and obtain about 30k data points for each tactic. D.3.3 CLASSIFICATION OF EXTRACTED TACTICS The types of extracted state-tactic pairs are mainly determined by the symbolic manipulations to construct the theorems. We construct the proof by inserting have instruction and integrating it with the original proof. As result, we manually introduce tactics centered on rw, apply or have. The traced data predominantly features these tactics. The style of the seed theorem (tactic-style or term-style) and the implementation of the tracing tool are also key factors for the traced data. To see more details of this process, it is good choice to trace the synthesized repository in person. Being familiar with the tracing process will offer some valuable guidance in designing symbolic rules to modify the proof. The extracted state-tactic pairs can also be post-processed (e.g., split the chained tactics into single ones), which has not been explored by our work. D.3. INFLUENCE OF THE QUANTITY OF SFT DATASET We assess the impact of varying quantities of additional state-tactics pairs for each tactic under several conditions. 1) Mathlib-train with no additional data points; 2) Downsampling with ratio of 0.25, resulting in 7.5k additional data points; 3) Downsampling with ratio of 0.5, resulting in 15k additional data points; 4) Our setting with deduplication threshold of 1, resulting in 30k additional data points; 5) Deduplication with threshold of 50, resulting in 500k additional data points; and 24 Figure 8: Examples of synthesized theorems for rw 6) No deduplication, resulting in 3M additional data points. We fine-tune Llama-3-8b on these different mixtures of data and evaluate their performance on random split of Leandojo Benchmark. The experimental results are shown in Fig 4, demonstrating that our setting achieves relatively optimal balance between overhead and performance. Figure 9: Examples of synthesized theorems for apply 26 Figure 10: Examples of data for pretraining"
        },
        {
            "title": "E ADDITIONAL EXPERIMENTS",
            "content": "E.1 EFFECTIVENESS OF DIFFERENT TACTICS We evaluate the effectiveness of different tactics by combining additional state-tactic pairs of specific tactic with Mathlib-train and fine-tuning the LLMs using this mixture. The experimental results are shown in Table 6. We observe that state-tactic pairs of rw and apply are beneficial for the theorem-proving ability of the LLM. And the highest improvement is achieved by the combination of these two tactics. For the state-tactic pairs of have, we assume that these data will teach the model to introduce lemmas in the process of proving theorem, helping them to prove the theorems in multiple steps. However, experimental data show that have has complex effects on the proving capacity of LLMs. The performance on mixture of have and other tactics shows poorer results compared to that on single tactic. We hope to investigate the effectiveness of have tactic soon. E.2 ANALYSIS OF THE TACTICS TO PROVE MINIF2F THEOREMS E.2.1 PREFERENCE IN USED TACTICS To see the preference for the tactics used to prove competition-level problems, we perform comprehensive analysis of the theorems proved by different LLMs. Specifically, we fine-tune different LLMs with the random train-split of Leandojo benchmark and gather all theorems proved by these models. The collection of these models proves 100 theorems out of 244 theorems (41%) on the test split of miniF2F benchmark. The average length of the proofs generated by these models is 1.38. And the distribution of these proved theorems is shown in Fig 14. We have the following observations. 1) About half of the theorems in the miniF2F test split can be proven with only 1-2 line proofs. 2) Most of the theorems are proved with advanced and automatic tactics in Lean (e.g., norm num, linarith, omega, simp, etc.). We assume that these tactics play an important role in the theorem-proving ability of LLMs to prove competition-level problems. From the above observations, we assume that synthesizing advanced tactic data points rather than basic data points featuring rw and apply is promising to improve the performance of proving competition-level problems. E.2. INFLUENCE OF ADDITIONAL TACTICS We analyze the distribution of used tactics in proven miniF2F problems across different data compositions. The dynamics of distribution changes are shown in Fig. 15. We assume that increasing 27 Table 6: The effectiveness of different tactics Methods Llama3-8b Mathlib-train rw tactic Mathlib-train + rw Mathlib-train + have Mathlib-train + rw + have apply tactic Mathlib-train + apply Mathlib-train + have Mathlib-train + apply + have both tactic mathlib-train + rw + apply deepseek-coder-7b-base-v1.5 Mathlib-train rw tactic Mathlib-train + rw Mathlib-train + have Mathlib-train + rw + have apply tactic Mathlib-train + apply Mathlib-train + have Mathlib-train + apply + have both tactic Mathlib-train + rw + apply random novel premises Search Budget 58.22 38. 57.85 (-0.37) 58.27 (+0.05) 57.96 (-0.26) 41.59 (+3.07) 41.29 (+2.77) 41.53 (+3.01) 56.71 (-1.51) 57.44 (-0.78) 57.23 (-0.99) 40.02 (+1.51) 39.24 (+0.72) 38.34 (-0.18) 1 32 1 32 1 32 1 1 32 1 32 1 32 58.53 (+0.31) 41.95 (+3.44) 1 32 57.7 39. 58.63 (+0.93) 58.11 (+0.41) 58.74 (+1.04) 41.05 (+1.81) 39.06 (-0.18) 40.57 (+1.33) 57.96 (+0.26) 57.02 (-0.68) 58.16 (+0.46) 41.17 (+1.93) 39.66 (+0.42) 39.78 (+0.54) 1 32 1 32 1 32 1 1 32 1 32 1 32 58.37 (+0.67) 42.92 (+3.68) 1 32 Table 7: The results of miniF2F for different LLMs. We fine-tune each model with the random train-split of Leandojo benchmark and evaluate their performance on miniF2F benchmark. Methods miniF2F-test Llama-3-8b deepseek-coder-base-7b-v1.5 deepseek-math-7b-base llemma-7b mistral-7b internlm2-math-7b Combination 34.01 37.70 34.42 32.38 32.38 36.06 40.98 the diversity of synthesized tactics and adjusting the tactic distribution will be beneficial to enhance the theorem-proving ability of LLMs. 28 Figure 11: Examples of rw and apply data points for finetuning 29 Figure 12: Examples of have data points for finetuning 30 Figure 13: The performance of models fine-tuned on different SFT datasets on novel premises split. a) Mathlib-train; b) Mathlib-train + rw; c) Mathlib-train + apply; d) Mathlib-train + rw + apply. Figure 14: a) The distribution of theorems proved by different LLMs; b) The distribution of tactics used in the proved theorems. 31 Figure 15: The distribution of used tactics for Llama-3-8b fine-tuned on different SFT datasets to prove miniF2F. a) Mathlib-train; b) Mathlib-train + rw; c) Mathlib-train + apply; d) Mathlib-train + rw + apply."
        }
    ],
    "affiliations": [
        "Institute of Artificial Intelligence and Robotics, Xian Jiaotong University",
        "Microsoft Research Asia",
        "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence"
    ]
}