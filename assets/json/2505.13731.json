{
    "paper_title": "GeoRanker: Distance-Aware Ranking for Worldwide Image Geolocalization",
    "authors": [
        "Pengyue Jia",
        "Seongheon Park",
        "Song Gao",
        "Xiangyu Zhao",
        "Yixuan Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Worldwide image geolocalization-the task of predicting GPS coordinates from images taken anywhere on Earth-poses a fundamental challenge due to the vast diversity in visual content across regions. While recent approaches adopt a two-stage pipeline of retrieving candidates and selecting the best match, they typically rely on simplistic similarity heuristics and point-wise supervision, failing to model spatial relationships among candidates. In this paper, we propose GeoRanker, a distance-aware ranking framework that leverages large vision-language models to jointly encode query-candidate interactions and predict geographic proximity. In addition, we introduce a multi-order distance loss that ranks both absolute and relative distances, enabling the model to reason over structured spatial relationships. To support this, we curate GeoRanking, the first dataset explicitly designed for geographic ranking tasks with multimodal candidate information. GeoRanker achieves state-of-the-art results on two well-established benchmarks (IM2GPS3K and YFCC4K), significantly outperforming current best methods."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 1 ] . [ 1 1 3 7 3 1 . 5 0 5 2 : r GeoRanker: Distance-Aware Ranking for Worldwide Image Geolocalization Pengyue Jia1,2, Seongheon Park2, Song Gao2, Xiangyu Zhao1, Yixuan Li2, 1Department of Data Science, City University of Hong Kong, 2Department of Computer Sciences, University of Wisconsin-Madison jia.pengyue@my.cityu.edu.hk,sharonli@cs.wisc.edu"
        },
        {
            "title": "Abstract",
            "content": "Worldwide image geolocalizationthe task of predicting GPS coordinates from images taken anywhere on Earthposes fundamental challenge due to the vast diversity in visual content across regions. While recent approaches adopt twostage pipeline of retrieving candidates and selecting the best match, they typically rely on simplistic similarity heuristics and point-wise supervision, failing to model spatial relationships among candidates. In this paper, we propose GeoRanker, distance-aware ranking framework that leverages large vision-language models to jointly encode querycandidate interactions and predict geographic proximity. In addition, we introduce multi-order distance loss that ranks both absolute and relative distances, enabling the model to reason over structured spatial relationships. To support this, we curate GeoRanking, the first dataset explicitly designed for geographic ranking tasks with multimodal candidate information. GeoRanker achieves state-of-the-art results on two well-established benchmarks (IM2GPS3K and YFCC4K), significantly outperforming current best methods."
        },
        {
            "title": "Introduction",
            "content": "Worldwide geolocalization [1, 2] refers to the task of predicting the GPS coordinates of images captured anywhere on Earth. Unlike approaches constrained to specific cities or regions [3, 4, 5, 6, 7], global geolocalization poses significantly greater challenges due to the immense diversity in visual content, ranging from natural landscapes and climatic variations to architectural differences and cultural markers [8, 9, 10]. Despite these complexities, accurate global geolocalization holds broad practical relevance, with wide range of applications including criminal investigations [11], navigation systems [12], and environmental monitoring [13]. Figure 1: Accuracy at 1km error threshold for G3 (Current SOTA) vs. the best candidate Recent state-of-the-art approaches [8, 9, 10, 14] typically follow within top-k retrieved results. two-stage pipeline: (1) retrieving and generating set of candidates based on global database, and (2) selecting the top match as the predicted geolocation. As shown in Figure 1, although the current SOTA model (G3 [14], which ranks candidates via GPS locationimage embedding similarity) achieves 16.7% accuracy at 1km error threshold on IM2GPS3K, better candidates often exist among the top-k retrieved results. This suggests that one can retrieve reasonably high-quality candidates, yet the final prediction accuracy hinges on the second stagethe models ability to compare spatial relevance and select the most plausible candidate. Currently, the candidate selection is often limited by naïve heuristics such as cosine similarity [8, 14], which generally encode the query image and candidates independently, without modeling their mutual spatial relationships or allowing rich interactions. As result, these methods frequently struggle to distinguish between Preprint. visually similar yet geographically distant scenes. Furthermore, existing training objectives primarily focus on point-wise similarity between individual images and locations [8, 9, 15], overlooking the rich spatial relationships among candidatessuch as the spatial dependence (i.e., Toblers First Law of Geography [16]) and relative distances between themwhich are crucial for geolocalization. To address these limitations, we propose GeoRanker, distance-aware ranking framework designed to model spatial relationships among candidate locations. Rather than relying on independent similarity scores, GeoRanker models the interaction between the query image and each candidate through large vision-language model (LVLM), which captures rich spatial semantics via crossmodal alignment, and learns scalar distance score that reflects their geographic proximity. Central to our approach is multi-order distance optimization objective that ranks not only the absolute distances between the query and individual candidates (first-order supervision), but also the relative differences between candidate distances (second-order supervision). This formulation allows the model to learn both which candidate is closest and how much closer it is compared to others, capturing rich spatial structure that naïve heuristics overlook. Through this design, GeoRanker transforms the geolocalization task from one of isolated similarity matching to one of structured spatial reasoning. To support this training paradigm, we construct GeoRanking, new dataset that provides spatially diverse candidate sets for each query. Each candidate is annotated with GPS coordinates, textual descriptions (e.g., city, country), and image data. To the best of our knowledge, this is the first ranking dataset specifically designed for modeling spatial relationships among geographic entities. We believe this effort will significantly contribute to advancing research in related domains. We validate the effectiveness of GeoRanker through extensive experiments on two widely used benchmarks: IM2GPS3K [17] and YFCC4K [18]. GeoRanker achieves state-of-the-art performance across all geographic thresholds. For example, on IM2GPS3K, it improves street-level (1km) accuracy by +12.9% over the current best method [14], and on YFCC4K, it yields an +37.3% improvement at the same threshold. Our model also consistently outperforms existing approaches at coarser scales (25km, 200km, 750km, 2500km), highlighting its robustness across granularities. Ablation studies confirm that both components of our multi-order distance lossfirst-order and secondorder supervisioncontribute to improved accuracy. We also conduct comprehensive ablations to understand the impact of various hyperparameter choices, leading to an improved understanding of our framework. Our key contributions are summarized as follows: 1. We introduce GeoRanker, distance-aware ranking framework that models spatial relationships among candidate locations using multi-order distance loss and large vision-language models. 2. We construct GeoRanking, the first dataset tailored for spatial ranking tasks, with rich multimodal annotations spanning GPS coordinates, textual descriptions, and image datafacilitating future research in related fields. 3. We achieve state-of-the-art performance on two well-established public geolocalization benchmarks, with substantial gains at fine-grained localization levels, and demonstrate the effectiveness of our approach through comprehensive ablations."
        },
        {
            "title": "2 Related Work",
            "content": "Image Geolocalization. Worldwide geolocalization lies at the intersection of geography and computer vision, and is core topic in GeoAI [19, 20, 21] and spatial data mining [22, 23]. Existing methods for worldwide geolocalization can be grouped into three main categories: classification-based, retrievalbased, and RAG-based approaches. (1) Classification-based methods [24, 15, 25, 26, 9] approach the task by partitioning the Earths surface into discrete Geo-grids and predicting the index of the grid that contains the image location. The final output is typically the center coordinate of the predicted grid. While these methods offer scalability, they may incur large errors when the true location lies far from the grid center, even if the grid prediction is correct. (2) Retrieval-based methods [27, 28, 29, 30, 31, 32] cast geolocalization as similarity search problem. These methods either use database of geotagged images [33, 27, 34, 35, 36] or gallery of GPS points [8], returning the coordinates of the most similar entries to the input image as the prediction. However, these methods fail to capture the complex spatial relationships between the query image and candidate locations, making it difficult to reliably identify the most accurate match from the candidate pool. (3) RAG-based methods [10, 14] first retrieve set of candidate locations similar to the query image from the database, then construct prompt that integrates both the query and candidate information. 2 Figure 2: Overview of the Distance-aware Ranking frameworkGeoRanker. This prompt is passed to an LVLM to generate plausible GPS location. In contrast to the above approaches, our proposed Distance-Aware Ranking framework, GeoRanker, focuses specifically on the candidate ranking stage. By explicitly modeling the complex spatial relationships between the query image and candidate geographic entities, an aspect overlooked by prior work, our approach offers more reliable candidate selection and leads to improved geolocalization performance at the global scale. Learning to Rank. Learning-to-rank [37] (LTR) is fundamental research direction in information retrieval [38] and recommender systems [39], primarily used to train ranking models that refine the order of retrieved candidates based on given query [40]. Depending on their modeling and optimization strategies, LTR methods are typically categorized into three types: pointwise, pairwise, and listwise approaches. Pointwise methods [41, 42] take the ranking task as regression or classification problem by assigning relevance score or label to each querycandidate pair independently. This approach is simple and straightforward, yet overlooks the relative relationships among candidates. Pairwise methods [43, 44, 45] model the relative preferences between pairs of candidates for the same query. Pairwise methods encourage the model to assign higher scores to positive candidates while penalizing negative ones, learning the relative preferences between different candidates. Listwise methods [46, 47, 37, 48] can be seen as an extension of pairwise approaches, as they consider the entire list of candidates associated with query and optimize loss function that directly reflects the overall quality of the ranking. Our approach builds on the LTR foundation but adapts it to spatial ranking by explicitly modeling and optimizing distance-aware relationships between candidates."
        },
        {
            "title": "3 Methodology",
            "content": "In this section, we introduce GeoRanker, Distance-aware Ranking method for geolocalization. An overview of the framework is illustrated in Figure 2, which consists of two main phases: training and inference. The training phase begins with dataset construction, detailed in Section 3.1, where we describe how the GeoRanking dataset is built to support the training of GeoRanker. We then present the model architecture and optimization strategy of GeoRanker in Section 3.2 and Section 3.3. Finally, during inference, GeoRanker selects the most appropriate candidate as the prediction by scoring the spatial relationships between the query image and set of candidates (Section 3.4). 3.1 GeoRanking Dataset Construction Database. Following prior work [14], we adopt the MP16-Pro multimodal dataset [14] as our database and encode each sample into vectors. Each candidate entry includes GPS, textual descriptions (city, country, etc.), and image data. In candidate database = {c1, c2, c3, , cM }, each candidate cm is (cgps encoded into feature vector vcm = concat(Encodergps )), where cgps represent the GPS, textual, and image modalities of the m-th candidate and Encodergps , Encoderimg are their corresponding modality-specific encoders. ), Encoderimg(cimg , cimg , ctext , Encodertext ), Encodertext (ctext 3 gps() and fimg Retrieval. Since the input query image is single modality (image), we design its representation to be compatible with the multimodal candidate vectors for similarity matching. The query image is text(Encoderimg(q)), Encoderimg(q)), where encoded as: vq = concat(fimg fimg text() are adapter layers that project the visual features into the GPS and textual embedding spaces, respectively. These adapters, along with the GPS encoder, are trained using an InfoNCE loss [49] to align the query and candidate representations, as in G3 [14]. The remaining encoders are initialized with pretrained weights and kept frozen during training. To retrieve candidates for the query image, we compute the cosine similarity between vq and each candidates representation vcm , and select the top-N candidates with the highest similarity scores to form the candidate set: gps(Encoderimg(q)), fimg (cid:1) (cid:1) (cid:1) (cid:1) = {c 1, 2, . . . , sim(q, 1) sim(q, 2) sim(q, )}, where the similarity function is defined as sim(q, cm) = (vq vcm )/(vqvcm ). The query image, along with the retrieved candidates will be used for training the GeoRanker, which we described next. 3.2 GeoRanker Figure 2 (b) shows the overview of GeoRanker. Existing methods [8, 14] typically model the query image and candidate geographic entities separately, embedding them into shared representation space via independent encoders. The final prediction is based on similarity scores between these representations. However, such designs fail to capture the rich spatial interactions between the query and candidates, resulting in decoupled modeling process that limits the accuracy of worldwide geolocalization. To address this issue, we propose GeoRanker, distance-aware ranking model designed to capture the spatial relationships between querycandidate pairs. Specifically, the query and candidates are assembled into prompt following predefined template. These inputs are then processed by an LVLM to model the complex interactions between the query and candidate. Finally, linear value head maps the hidden states to scalar score that reflects the geographic distance between the query image and the candidate location. GeoRanking dataset and prompt construction. To support the ranking model training, we select the top-k1 candidates from the candidate set as ranking candidates, denoted by Crc = {c }. We then take the last k2 candidates in to form the negative set Cneg, which provides additional contextual diversity and helps the model understand the relative relevance of candidate locations. Thus, each sample in the GeoRanking dataset is represented as triplet: {q, Crc, Cneg}, where is the query image, Crc contains the candidates to be ranked, and Cneg provides hard negatives to enhance ranking discrimination. Each triplet is formatted using structured prompt template: 2, . . . , k1 1, {query image} How far is this place from latitude: {candidate latitude}, longitude: {candidate longitude}, {candidate textual descriptions}, {candidate image}? Negative examples: {negative information}. The construction process can be formalized as: = Prompt(q, Crc, Cneg, p), where denotes the prompt template. Note that, to reduce GPU memory consumption, we represent negative samples using only their textual GPS coordinates and textual descriptions. Model architecture. The constructed input is fed into LVLM to encode both visual and textual modalities and to capture the spatial interactions between the query and candidate. To enhance the models representation capacity while maintaining training efficiency, we insert LoRA (Low-Rank Adaptation) [50] modules into the intermediate layers of the LVLM backbone during training. We use the hidden states corresponding to the final position token as the joint representation of the input. lightweight value head, implemented as single linear layer without bias, is then applied to map this representation to scalar score. This score serves as the estimated geographic distance between the query image and the candidate location: = whfinal, where hfinal = LVLM(x)[1] (1) where denotes the final score, Rdim and hfinal Rdim are the weight matrix of the value head and the final position tokens representation, dim is the dimension of the last hidden states. In addition, LVLM() denotes the large vision-language model used to encode the input x. 4 3.3 GeoRanker: Optimization with Multi-Order Distance Objective Existing geolocalization training methods typically focus on point-wise image-to-location similarity, without modeling the spatial relationships among candidate locations. To address this limitation, we propose multi-order distance optimization objective to train GeoRanker. Our objective incorporates both the first-order distances between the query and each candidate, and the second-order relationships, defined as the relative differences between first-order distances, to guide the model during training. First-order distance loss. We optimize the first-order distance ranking using partial Plackett-Luce (PL) loss [51, 52]. Given k1 candidates with predicted scores {s1, s2, . . . , sk1 }, we first sort the corresponding geodesic distances {d1, d2, . . . , dk1 } in ascending order to obtain an index permutation π such that dπ(1) < dπ(2) < < dπ(k1). We then use the reordered scores {sπ(1), sπ(2), . . . , sπ(k1)} to compute the loss. Let (1) k1 be hyperparameter controlling how many top-ranked candidates are included in the objective. For each sample, the partial Plackett-Luce loss is defined as: L(1) PL ="
        },
        {
            "title": "1\nK (1)",
            "content": "K(1) (cid:88) i=1 log exp(sπ(i)) j=i exp(sπ(j)) (cid:80)k1 (2) Second-order distance loss. To capture the relative spatial differences among candidates, we introduce second-order distance loss based on pairwise distance gaps. This objective supervises the ranking of first-order distance differences, encouraging the model to assign higher score differences to candidate pairs that are more distant in geolocation. Specifically, we first compute all pairwise first-order differences in distances and predicted scores: di,j = dπ(i) dπ(j), si,j = sπ(i) sπ(j), for 1 < k1 (3) This results in = k1(k11) pairs. We sort the distance differences di,j in ascending order (so larger spatial gaps appear earlier), and apply the same permutation to the score differences si,j, resulting in an ordered sequence s(1), . . . , s(P ). Let (2) be hyperparameter that specifies the number of top-ranked pairs included in the loss. We define (2) = [(k11)+(k1K(1))]K(1) , which ensures that the second-order loss focuses on candidate pairs where at least one candidate is involved in the first-order loss computation. The second-order partial PL loss is then computed as: K(2) (cid:88) 2 L(2) PL = 1 (2) log exp(s(i)) j=i exp(s(j)) (cid:80)P i=1 (4) This formulation encourages the model to preserve the ordering of spatial gaps in the score space, so that larger geographic differences lead to larger score gaps. Joint optimization. We jointly optimize the model with both the first-order and second-order objectives. The total loss is defined as weighted sum of the two components: (5) where λ is the weighting coefficient that balances the contribution of the first-order and second-order distance losses, respectively. We will ablate the impact of key hyperparameters in Section 4.3. Ltotal = λ L(1) PL + (1 λ) L(2) PL 3.4 Inference During inference, GeoRanker integrates both retrieved candidates from database and generated candidates from LVLM, following prior work [10, 14]. Given query image q, we first retrieve set of candidates Cr and collect contextual negative samples Cneg. Simultaneously, the query is passed through an LVLM to generate new set of candidates Cg, referred to as generated candidates. The prompt for generating candidates is detailed in Appendix A. We then form querycandidate pairs by combining with each candidate Cr Cg, and feed these inputs into GeoRanker to obtain set of distance scores: (6) Finally, we select the candidate with the highest score and use its GPS coordinates as the prediction: (7) sc = GeoRanker(q, c), Cr Cg ˆc = arg max cCrCg sc It is worth noting that the generated candidates typically lack additional modalities such as textual descriptions and images. As result, we use only their GPS coordinates during inference."
        },
        {
            "title": "4 Expeirments",
            "content": "4.1 Setup Dataset and evaluation metrics. We use MP16-Pro from prior work [14] as our database in constructing the GeoRanking dataset. For evaluation, we follow previous work [8, 10, 14] and assess performance on two widely used public benchmarks IM2GPS3K [17] and YFCC4K [18]. The evaluation metric reports the percentage of predictions whose geodesic distance to the ground-truth coordinates falls within set of thresholds: 1km, 25km, 200km, 750km, and 2500km. GeoRanking dataset. In this work, we construct the first ranking dataset for modeling distances between geographic entities. Specifically, for each query image, we retrieve set of candidates based on embedding similarity. Each candidate is associated with GPS coordinates, textual descriptions (e.g., city, country), and image data. These candidates serve as input for subsequent ranking models. In total, we construct 100k samples, resulting in 2 million querycandidate pairs. By releasing this dataset, we aim to support progress in geolocalization and related research areas such as GeoAI, information retrieval, and LVLM. Example entries are provided in the Appendix for reference. Implementation details. During training, we retrieve 20 candidates from the database for each query. The top-7 are used as retrieval candidates, while the bottom-5 serve as negative samples. The vision encoder and text encoder are pretrained models from CLIP [53]. The GPS encoder is initialized with weights from GeoCLIP [8] and then fine-tuned. We use Qwen2-VL-7b-Instruct 1 as the LVLM backbone in GeoRanker. For LoRA fine-tuning, we target the q_proj, k_proj, and v_proj modules, with rank of 16, scaling factor of 32, and LoRA dropout of 0.05. GeoRanker is fine-tuned with AdamW [54] optimizer with learning rate of 1e-4, batch size of 4, and for 1 epoch. For joint optimization, we set the weighting coefficient λ = 0.7, and (1) = 1. All experiments are conducted using Pytorch on 4 NVIDIA L40S GPUs. During inference, following [10, 14], we use GPT4V 2 as the LVLM for candidate generation. We use Cr = 12 retrieved candidates and Cg = 3 generated candidates for IM2GPS3K and Cr = 14, Cg = 5 for YFCC4K. Additional details regarding the training environment and runtime are provided in Appendix C. Baselines. To evaluate the effectiveness of our approach, we conduct comprehensive experiments and compare it against 11 baselines: [L]kNN, sigma=4 [1], PlaNet [15], CPlaNet [15], ISNs [55], Translocator [25], GeoDecoder [26], GeoCLIP [8], Img2Loc [10], PIGEON [9], G3 [14], including the state-of-the-art. detailed description of each baseline is provided in Appendix D. 4.2 Main Results As shown in Table 1, GeoRanker achieves state-of-the-art performance across all evaluation thresholds. For example, on IM2GPS3K, it improves the most challenging street-level accuracy by 12.9% over the best baseline G3, and on YFCC4K, it achieves an 37.3% relative gain at the same threshold. Among the baselines, GeoCLIP [8], Img2Loc [10], PIGEON [9], and G3 [14] exhibit relatively strong performance due to classification-based methods are limited by systemic biases from fixed candidate grids. Compared to these stronger baselines, our method GeoRanker achieves superior results by explicitly modeling the spatial relationship between each querycandidate pair using multi-order distance optimization objective. This enables the model to accurately identify the geographically closest candidate as the prediction, further enhancing geolocalization accuracy. In summary, our approach achieves state-of-the-art performance across all datasets and metrics, demonstrating its effectiveness and superiority. Furthermore, Appendix presents representative examples across various error thresholds to offer intuitive insights into the distribution of query images at different localization accuracies. 4.3 Ablation Study To better understand the contribution of each component, we conduct ablation studies by sysPL . Our method without secondtematically varying key modules of our approach. (2) w/o Cneg. Our method without negative information in order distance loss in training. (1) w/o L(2) 1https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct 2https://openai.com/ Table 1: Main results on IM2GPS3K and YFCC4K. For all metrics, higher is better. The bestperforming results are highlighted in bold, while the second-best results are underlined. represents the relative improvement of our method over the best baseline. IM2GPS3K Region 200km Country 750km Continent 2500km YFCC4K Region 200km Country 750km Continent 2500km Methods [L]kNN, sigma=4 [1] PlaNet [24] CPlaNet [15] ISNs [55] Translocator [25] GeoDecoder [26] GeoCLIP [8] Img2Loc [10] PIGEON [9] G3 [14] ICCV17 ECCV16 ECCV18 ECCV18 ECCV22 ICCV23 NeurIPS23 SIGIR24 CVPR24 NeurIPS GeoRanker Rel. Improvement Ours Street 1km 7.2 8.5 10.2 10.5 11.8 12.8 14.11 15.34 11.3 16.65 City 25km 19.4 24.8 26.5 28 31.1 33.5 34.47 39.83 36.7 40. 26.9 34.3 34.6 36.6 46.7 45.9 50.65 53.59 53.8 55.56 38.9 48.4 48.6 49.7 58.9 61 69.67 69.7 72.4 71.24 55.9 64.6 64.6 66 80.1 76.1 83.82 82.78 85.3 84.68 89.29 4.7% Street 1km 2.3 5.6 7.9 6.5 8.4 10.3 9.59 19.78 10.4 23. City 25km 5.7 14.3 14.8 16.2 18.6 24.4 19.31 30.71 23.7 35.89 18.79 76.31 12.9% 10.0% 10.7% 5.4% 45.05 61. 32.94 69.79 37.3% 21.3% 15.6% 8.6% 43.54 54.32 11 22.2 21.9 23.8 27 33.9 32.63 41.4 40.6 46.98 23.5 36.4 36.4 37.4 41.1 50 55 58.11 62.2 64. 42 55.8 55.5 55 60.4 68.7 74.69 74.07 77.7 78.15 82.45 5.5% (3) w/o ctext Methods City 25km Street 1km Region 200km Country 750km (4) w/o cimg Table 2: Ablation study on IM2GPS3K. (5) w/o Cg. Our method without generated candidates in inference. . Our method without textual descriptions of candidates . Our method without image data of candidates in training and inference. in training and inference. training and inference. Table 2 presents an ablation study on the IM2GPS3K dataset, and the results for YFCC4K are illustrated in Appendix F. From Table 2 we draw several key insights: (1) All components in our framework contribute positively to the final performance, demonstrating the effectiveness of our design. (2) Comparing our full model with the variant without second-order distance loss (L(2) PL ), we observe more substantial improvements at coarse-grained levels (e.g., country and continent). This highlights the benefit of modeling second-order spatial relationships among candidates, which enables finer-grained ranking and enhances geolocalization accuracy. (3) Removing any of the modality-aware prompt componentssuch as negative candidates (Cneg), textual descriptions (ctext )leads to performance drops, confirming that incorporating multi-modal cues into the prompt is beneficial. Among these, visual information yields the most significant gain, underscoring the importance of image semantics. (4) Finally, the variant without generated candidates (Cg) underperforms our method, showing that generated candidates provide complementary value. This is especially important in scenarios where the retrieval database lacks relevant examples, and generation can introduce novel, informative candidates that enhance the overall candidate pool. ), or image data (cimg w/oL(2) PL w/o Cneg w/o ctext w/o cimg w/o Cg 88.28 88.28 88.62 88.35 88.75 44.61 44.51 43.91 41.77 43.47 75.61 76.37 76.61 75.40 75. 60.96 60.82 60.19 59.15 59.69 18.48 17.35 18.02 15.58 18.21 Continent 2500km 76.31 61.49 18. 45.05 89.29 Ours 4.4 Hyperparameter Analysis To better understand the impact of key hyperparameters, we conduct systematic ablation study by varying each at time while keeping others fixed. The hyperparameters considered include: (1) Number of retrieval candidates in training Crc. (2) Number of retrieval candidates during inference Cr. (3) Number of generated candidates during inference Cg. (4) Weighting coefficient λ. (5) Number of top elements involved in the first-order loss (K (1)). Unless otherwise specified, we use the following default values: Crc = 5, Cr = 10, Cg = 5, λ1 = 0.7, and Figure 3: Hyperparameter analysis at the region level on IM2GPS3K. Trends observed at the region level are representative across different geographic levels. Results for all hyperparameters across all levels can be found in Appendix G. 7 Table 3: Comparison with other ranking baselines. Methods Random Top1 Prompting Street 1km 10.04 13.31 16. City 25km 29.72 34.03 40.21 Ours 18.79 45.05 IM2GPS3K Region 200km Country 750km Continent 2500km 42.17 45.48 54.55 61.49 57.82 61.56 70. 76.31 75.24 78.04 83.24 89.29 Figure 4: Time efficiency. (1) = 1. Empirically, we find that the trends of each hyperparameter remain largely consistent across all levels, indicating the stability and robustness of our model under varying geolocalization granularities. For clarity and brevity, we present results at the region level as representative example in Figure 3, while full results for all levels are provided in Appendix G. Impact of candidate scales in training and inference: (1) Increasing Crc initially improves performance, followed by plateau. This suggests that increasing the number of candidates moderately raises task difficulty, which in turn provides more supervision signals and benefits model training. (2) The number of retrieval candidates used during inference Cr also exhibits rising-then-stabilizing trend. larger pool of retrieval candidates increases the likelihood of including the correct candidate, and the consistent performance gain further demonstrates the effectiveness of our GeoRanker, which can robustly identify the most relevant one from diverse set. (3) The model shows relatively flat performance when varying Cg, indicating that even small number of generated candidates is sufficient to yield competitive performance. Impact of hyperparameters in multi-order distance objective: (1) As the weighting factor λ increases, performance first improves and then declines. This highlights trade-off between the firstand second-order objectivesoverweighting the former can reduce the benefit of modeling relative spatial relationships. (2) (1) shows consistent downward trend. Larger values introduce more candidate combinations in the partial PL loss during training, which may deviate from the candidate distribution at inference and lead to train-test mismatch. This weakens the supervision signal and degrades performance. 4.5 Comparison with Other Ranking Baselines To demonstrate the superiority of GeoRanker in ranking ability, we conduct comparative experiments with the following ranking baselines. (1) Random: Randomly sampling one candidate from Cr Cg as prediction. (2) Top-1: Using embedding similarity to rank candidates and select the top-1 as prediction. The embedding model is fine-tuned following G3 [14] with multi-modal information. (3) Prompting: The query image, candidate information, and negative samples are incorporated into the prompt, using LVLM to select the most appropriate candidate as the final prediction. We use Qwen2-VL-7b-Instruct for fair comparison. From Table 3, we can find that our approach (GeoRanker) outperforms all baselines, achieving the highest performance across all metrics. This is because GeoRanker leverages large vision-language models to jointly encode query-candidate interactions and learns fine-grained distance representation through multi-order distance loss during training, enabling it to effectively select accurate predictions from pool of candidates. 4.6 Efficiency Analysis Beyond accuracy, efficiency is critical for real-world deployment. We evaluate our approach along two dimensions: time efficiency, measuring inference latency, and data efficiency, assessing the effectiveness of data usage. Time efficiency. Figure 4 compares the inference time of GeoRanker with the prompting-based method (introduced in Section 4.5) across varying numbers of candidate inputs. As expected, inference time increases for both methods as the number of candidates grows, due to additional scoring iterations required for GeoRanker and longer prompts for the prompting baseline. Notably, GeoRanker consistently achieves substantially lower inference latency compared to prompting. Within the 1-10 candidate size range, GeoRanker takes less than half the time required by prompting. It is also worth highlighting that GeoRanker naturally supports parallel computation over candidate 8 Figure 5: Data efficiency analysis. Figure 7: Case study illustrating the effectiveness of GeoRanker in re-ranking candidates. scoring, enabling substantial reductions in inference latency for large-scale deployment. In contrast, Prompting suffers from longer and sequential input construction, which limits such optimization. Data efficiency. Figure 5 illustrates the performance of GeoRanker at different geographic scales when fine-tuned with varying amounts of data. The x-axis represents the number of samples (in units of 10K), and the y-axis shows the corresponding accuracy. From Figure 5, we observe the following: (1) GeoRanker exhibits stable and consistent improvement in accuracy as the training data size increases across all geographic levels, demonstrating strong scalability and generalization capacity. (2) For comparison, we also plot the performance of the state-of-the-art method G3. Remarkably, GeoRanker surpasses G3 across all levels even when fine-tuned on just 10% samples, highlighting its data efficiencythe ability to achieve strong performance with limited supervision. 4. Impact of Backbone Scale To investigate the impact of backbone model scale on performance, we conduct experiments using llava-onevision [56] (0.5B) and Qwen2-VL models [57] with 2B and 7B parameters. As shown in Figure 6, and results across all geographic levels in Appendix H, GeoRankers performance consistently improves as the backbone model size increases on both IM2GPS3K and YFCC4K. These results indicate that GeoRanker benefits from more powerful LVLM backbones and follows the scaling law, suggesting that its upperbound performance can be further improved with larger models. 4.8 Case Study Figure 6: Impact of Backbone Scale on Region Level. To intuitively demonstrate the effectiveness of GeoRanker, we present qualitative case study in Figure 7. As shown on the left, the top-5 candidates retrieved are not well ordered by geographic proximity; visually similar but geographically distant images (e.g., 870 KM away) appear at the top ranks. After reranking with GeoRanker, the candidates are successfully reordered by their true geographic distances, with the closest image (0.44 km away) ranked at the top and the farthest ones pushed lower in the list. This result highlights GeoRankers ability to model complex spatial relationships through querycandidate interactions, further improving the geolocalization accuracy."
        },
        {
            "title": "5 Conclusion",
            "content": "In this paper, we propose GeoRanker, distance-aware ranking framework built upon LVLM. To enhance training, we introduce novel multi-order distance loss that captures both absolute distances and relative spatial relationships among candidate locations. To support this framework, we construct GeoRanking, the first dataset specifically designed for spatial ranking tasks. Extensive experiments on IM2GPS3K and YFCC4K demonstrate the effectiveness of GeoRanker over baselines."
        },
        {
            "title": "Acknowledgements",
            "content": "The authors would like to thank Leitian Tao for the valuable feedback on the work."
        },
        {
            "title": "References",
            "content": "[1] Nam Vo, Nathan Jacobs, and James Hays. Revisiting im2gps in the deep learning era. In Proceedings of the IEEE international conference on computer vision, pages 26212630, 2017. [2] Daniel Wilson, Xiaohan Zhang, Waqas Sultani, and Safwan Wshah. Visual and object geolocalization: comprehensive survey. arXiv preprint arXiv:2112.15202, 2021. [3] Hyeonwoo Noh, Andre Araujo, Jack Sim, Tobias Weyand, and Bohyung Han. Large-scale image retrieval with attentive deep local features. In Proceedings of the IEEE international conference on computer vision, pages 34563465, 2017. [4] Bingyi Cao, Andre Araujo, and Jack Sim. Unifying deep local and global features for image search. In Computer VisionECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part XX 16, pages 726743. Springer, 2020. [5] Fuwen Tan, Jiangbo Yuan, and Vicente Ordonez. Instance-level image retrieval using reranking transformers. In proceedings of the IEEE/CVF international conference on computer vision, pages 1210512115, 2021. [6] Seongwon Lee, Hongje Seong, Suhyeon Lee, and Euntai Kim. Correlation verification for image retrieval. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 53745384, 2022. [7] Shihao Shao, Kaifeng Chen, Arjun Karpur, Qinghua Cui, André Araujo, and Bingyi Cao. Global features are all you need for image retrieval and reranking. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1103611046, 2023. [8] Vicente Vivanco Cepeda, Gaurav Kumar Nayak, and Mubarak Shah. Geoclip: Clip-inspired alignment between locations and images for effective worldwide geo-localization. Advances in Neural Information Processing Systems, 36:86908701, 2023. [9] Lukas Haas, Michal Skreta, Silas Alberti, and Chelsea Finn. Pigeon: Predicting image geolocations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1289312902, 2024. [10] Zhongliang Zhou, Jielu Zhang, Zihan Guan, Mengxuan Hu, Ni Lao, Lan Mu, Sheng Li, and Gengchen Mai. Img2loc: Revisiting image geolocalization using multi-modality foundation models and image-based retrieval-augmented generation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 27492754, 2024. [11] Yi Liu, Junchen Ding, Gelei Deng, Yuekang Li, Tianwei Zhang, Weisong Sun, Yaowen Zheng, Jingquan Ge, and Yang Liu. Image-based geolocation using large vision-language models. arXiv preprint arXiv:2408.09474, 2024. [12] Neel Jay, Hieu Minh Nguyen, Trung Dung Hoang, and Jacob Haimes. Evaluating precise geolocation inference capabilities of vision language models. arXiv preprint arXiv:2502.14412, 2025. [13] Zhiqiang Wang, Dejia Xu, Rana Muhammad Shahroz Khan, Yanbin Lin, Zhiwen Fan, and Xingquan Zhu. Llmgeo: Benchmarking large language models on image geolocation in-the-wild. arXiv preprint arXiv:2405.20363, 2024. [14] Pengyue Jia, Yiding Liu, Xiaopeng Li, Xiangyu Zhao, Yuhao Wang, Yantong Du, Xiao Han, Xuetao Wei, Shuaiqiang Wang, and Dawei Yin. G3: an effective and adaptive framework for worldwide geolocalization using large multi-modality models. Advances in Neural Information Processing Systems, 37:5319853221, 2024. 10 [15] Paul Hongsuck Seo, Tobias Weyand, Jack Sim, and Bohyung Han. Cplanet: Enhancing image geolocalization by combinatorial partitioning of maps. In Proceedings of the European Conference on Computer Vision (ECCV), pages 536551, 2018. [16] Harvey Miller. Toblers first law and spatial analysis. Annals of the association of American geographers, 94(2):284289, 2004. [17] James Hays and Alexei Efros. Im2gps: estimating geographic information from single image. In 2008 ieee conference on computer vision and pattern recognition, pages 18. IEEE, 2008. [18] Bart Thomee, David Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):6473, 2016. [19] Gengchen Mai, Weiming Huang, Jin Sun, Suhang Song, Deepak Mishra, Ninghao Liu, Song Gao, Tianming Liu, Gao Cong, Yingjie Hu, et al. On the opportunities and challenges of foundation models for geoai (vision paper). ACM Transactions on Spatial Algorithms and Systems, 10(2):146, 2024. [20] Krzysztof Janowicz, Song Gao, Grant McKenzie, Yingjie Hu, and Budhendra Bhaduri. Geoai: spatially explicit artificial intelligence techniques for geographic knowledge discovery and beyond, 2020. [21] Ling Li, Yu Ye, Bingchuan Jiang, and Wei Zeng. Georeasoner: Geo-localization with reasoning in street views using large vision-language model. In Forty-first International Conference on Machine Learning, 2024. [22] Senzhang Wang, Jiannong Cao, and Yu Philip. Deep learning for spatio-temporal data mining: survey. IEEE transactions on knowledge and data engineering, 34(8):36813700, 2020. [23] Yuxuan Liang, Haomin Wen, Yutong Xia, Ming Jin, Bin Yang, Flora Salim, Qingsong Wen, Shirui Pan, and Gao Cong. Foundation models for spatio-temporal data science: tutorial and survey. arXiv preprint arXiv:2503.13502, 2025. [24] Tobias Weyand, Ilya Kostrikov, and James Philbin. Planet-photo geolocation with convolutional neural networks. In Computer VisionECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VIII 14, pages 3755. Springer, 2016. [25] Shraman Pramanick, Ewa Nowara, Joshua Gleason, Carlos Castillo, and Rama Chellappa. Where in the world is this image? transformer-based geo-localization in the wild. In European Conference on Computer Vision, pages 196215. Springer, 2022. [26] Brandon Clark, Alec Kerrigan, Parth Parag Kulkarni, Vicente Vivanco Cepeda, and Mubarak Shah. Where we are and what were looking at: Query based worldwide image geo-localization using hierarchies and scenes. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2318223190, 2023. [27] Sijie Zhu, Mubarak Shah, and Chen Chen. Transgeo: Transformer is all you need for cross-view image geo-localization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11621171, 2022. [28] Jinliang Lin, Zhedong Zheng, Zhun Zhong, Zhiming Luo, Shaozi Li, Yi Yang, and Nicu Sebe. Joint representation learning and keypoint detection for cross-view geo-localization. IEEE Transactions on Image Processing, 31:37803792, 2022. [29] Xiaohan Zhang, Xingyu Li, Waqas Sultani, Yi Zhou, and Safwan Wshah. Cross-view geolocalization via learning disentangled geometric layout correspondence. In Proceedings of the AAAI conference on artificial intelligence, volume 37, pages 34803488, 2023. [30] Scott Workman, Richard Souvenir, and Nathan Jacobs. Wide-area image geolocalization with aerial reference imagery. In Proceedings of the IEEE International Conference on Computer Vision, pages 39613969, 2015. 11 [31] Liu Liu and Hongdong Li. Lending orientation to neural networks for cross-view geolocalization. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 56245633, 2019. [32] Sijie Zhu, Taojiannan Yang, and Chen Chen. Vigor: Cross-view image geo-localization beyond one-to-one retrieval. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 36403649, 2021. [33] Hongji Yang, Xiufan Lu, and Yingying Zhu. Cross-view geo-localization with layer-to-layer transformer. Advances in Neural Information Processing Systems, 34:2900929020, 2021. [34] Yicong Tian, Chen Chen, and Mubarak Shah. Cross-view image matching for geo-localization in urban environments. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 36083616, 2017. [35] Yujiao Shi, Xin Yu, Dylan Campbell, and Hongdong Li. Where am looking at? joint location and orientation estimation by cross-view matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 40644072, 2020. [36] Sijie Zhu, Linjie Yang, Chen Chen, Mubarak Shah, Xiaohui Shen, and Heng Wang. R2former: In Proceedings of the Unified retrieval and reranking transformer for place recognition. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1937019380, 2023. [37] Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. Learning to rank: from pairwise approach to listwise approach. In Proceedings of the 24th international conference on Machine learning, pages 129136, 2007. [38] Tie-Yan Liu et al. Learning to rank for information retrieval. Foundations and Trends in Information Retrieval, 3(3):225331, 2009. [39] Alexandros Karatzoglou, Linas Baltrunas, and Yue Shi. Learning to rank for recommender systems. In Proceedings of the 7th ACM Conference on Recommender Systems, pages 493494, 2013. [40] Md Ahsanul Kabir, Mohammad Al Hasan, Aritra Mandal, Daniel Tunkelang, and Zhe Wu. survey on e-commerce learning to rank. arXiv preprint arXiv:2412.03581, 2024. [41] Anthony Bell, Prathyusha Senthil Kumar, and Daniel Miranda. The title says it all: title term weighting strategy for ecommerce ranking. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pages 22332241, 2018. [42] Siamak Zamani Dadaneh, Shahin Boluki, Mingyuan Zhou, and Xiaoning Qian. Arsm gradient estimator for supervised learning to rank. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 31573161. IEEE, 2020. [43] Yukihiro Tagami, Shingo Ono, Koji Yamamoto, Koji Tsukamoto, and Akira Tajima. Ctr prediction for contextual advertising: Learning-to-rank approach. In Proceedings of the Seventh International Workshop on Data Mining for Online Advertising, pages 18, 2013. [44] Mattia Cerrato, Marius Köppel, Alexander Segner, Roberto Esposito, and Stefan Kramer. Fair pairwise learning to rank. In 2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA), pages 729738. IEEE, 2020. [45] Yiling Jia, Huazheng Wang, Stephen Guo, and Hongning Wang. Pairrank: Online pairwise learning to rank by divide-and-conquer. In Proceedings of the web conference 2021, pages 146157, 2021. [46] Christopher JC Burges. From ranknet to lambdarank to lambdamart: An overview. Learning, 11(23-581):81, 2010. [47] Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. Listwise approach to learning to rank: theory and algorithm. In Proceedings of the 25th international conference on Machine learning, pages 11921199, 2008. 12 [48] Jun Xu and Hang Li. Adarank: boosting algorithm for information retrieval. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 391398, 2007. [49] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018. [50] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora: Low-rank adaptation of large language models. ICLR, 1(2):3, 2022. [51] Robin Plackett. The analysis of permutations. Journal of the Royal Statistical Society Series C: Applied Statistics, 24(2):193202, 1975. [52] Duncan Luce et al. Individual choice behavior, volume 4. Wiley New York, 1959. [53] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 87488763. PmLR, 2021. [54] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017. [55] Eric Muller-Budack, Kader Pustu-Iren, and Ralph Ewerth. Geolocation estimation of photos using hierarchical model and scene classification. In Proceedings of the European conference on computer vision (ECCV), pages 563579, 2018. [56] Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei Liu, et al. Llava-onevision: Easy visual task transfer. arXiv preprint arXiv:2408.03326, 2024. [57] Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, et al. Qwen2-vl: Enhancing vision-language models perception of the world at any resolution. arXiv preprint arXiv:2409.12191, 2024."
        },
        {
            "title": "Table of Contents",
            "content": "A Prompts GeoRanking Data Entries More Information on Training and Inference Baseline Method Details Query Images with Different Error Thresholds Complete experimental results on ablation study Hyperparameter Analysis with All Geographic Levels Complete Experimental Results on Backbone Model Scale Limitations 15 15 16 17 18 18 19 14 Figure 8: Examples of GeoRanking Data Entries."
        },
        {
            "title": "A Prompts",
            "content": "Prompting for generating candidates Cg. Following previous work [14], we use the following prompt template for generating candidates: {query image} Suppose you are an expert in geolocalization. You have the ability to give two number GPS coordinates given an image. Please give me the location of the given image. Your answer should be in the following JSON format without any other information: {\"latitude\": float,\"longitude\": float}."
        },
        {
            "title": "B GeoRanking Data Entries",
            "content": "Figure 8 illustrates example entries from the GeoRanking dataset. Specifically, each query image is associated with 20 candidates, and each candidate contains GPS coordinates, textual descriptions, and image data. In total, GeoRanking includes 100K samples and 2 million querycandidate pairs. To the best of our knowledge, GeoRanking is the first dataset specifically designed for modeling distance-aware ranking between geographic entities. We release the dataset publicly and hope it will foster future research in areas such as GeoAI, information retrieval, and vision-language modeling. 15 Table 4: More Details on Training and Inference. Parameter Setting GPU Training Time Total params Trainable params Dataset Samples Batch Size Batch Size per Device Training GPU Memory Consumption VLM Backbone Deepspeed NVIDIA L40S * 4 16 hours / epoch 8,298,256,896 6,881,280 (0.083%) 100K 4 1 30 GB / GPU Huggingface Qwen2-VL-7b-Instruct Stage"
        },
        {
            "title": "C More Information on Training and Inference",
            "content": "In this section, we provide additional details regarding the training and inference setup. Table 4 summarizes the key hyperparameters used during these phases. Most experiments were conducted on four NVIDIA L40S GPUs. We also performed tests on two NVIDIA H200 GPUs, where training took approximately 7.5 hours per epoch with batch size of 4, consuming around 90 GB of GPU memory per device with the gradient checkpointing off."
        },
        {
            "title": "D Baseline Method Details",
            "content": "In this section, we will give introductions to the baselines: [L]kNN, σ = 4 [1]. kNN first retrieves the top-k nearest neighbor images and aggregates their coordinates to form the final prediction. As the decreases, the aggregation process becomes more focused. When euqals 1, the method turns to the NN. PlaNet [24]. PlaNet is the first work to formulate the worldwide geolocalization task as classification problem. It partitions the Earths surface into large number of geographical cells and trains convolutional neural network to predict the correct cell for each image. Unlike previous approaches that primarily rely on landmark recognition or approximate matching with global image descriptors, PlaNet effectively integrates multiple visible cues within the image to enhance localization accuracy. CPlaNet [15]. CPlaNet follows PlaNet and propose combinatorial partitioning, which generates fine-grained output class by intersecting larger partitions. ISNs [55]. ISNs enhance the input image information by extracting additional scene context features, such as indoor, natural, or urban environments, alongside the original image content. By incorporating these richer contextual cues, ISNs achieves improved localization performance. Translocator [25]. Translocator designs dual-branch transformer framework that simultaneously ingests the original image and its semantic segmentation map. This architecture enables the extraction of fine-grained spatial cues and the construction of more robust feature representations for geolocalization. GeoDecoder [26]. GeoDecoder identifies that earlier methods insufficiently leverage hierarchical spatial information. It addresses this by proposing cross-attention mechanism that explicitly captures relationships across heterogeneous features, enhancing the models ability to interpret complex location-dependent features. GeoCLIP [8]. GeoCLIP extends the CLIP architecture by introducing GPS encoder, aligning geographic coordinates with image and GPS embeddings. This enhancement enables more effective modeling of worldwide geolocalization tasks by incorporating spatial information directly into the learned feature space. Img2Loc [10]. Img2Loc advances geolocalization by integrating RAG pipeline. It first retrieves visually similar candidates, then formulates prompt incorporating these candidates coordinates, guiding vision-language model to generate final prediction. 16 Figure 9: Example query images fall in different error thresholds. PIGEON [9]. PIGEON introduces an innovative framework that combines semantic geocell partitioning, multi-task contrastive pretraining, and novel loss function. By clustering candidate locations semantically and refining predictions through targeted retrieval, PIGEON significantly boosts localization accuracy. G3 [14]. G3 proposes three-stage framework comprising Geo-alignment, Geo-diversification, and Geo-verification. Geo-alignment aligns GPS coordinates, textual descriptions, and visual data into unified multi-modal representation to strengthen retrieval capabilities. Subsequently, Geodiversification and Geo-verification are integrated within RAG framework to robustly generate and select candidate geolocations."
        },
        {
            "title": "E Query Images with Different Error Thresholds",
            "content": "Figure 9 presents example query images under different error thresholds (1km, 25km, 200km, 750km, and 2500km). We observe that images with errors within 1km often contain distinctive location cues, such as landmark buildings, which facilitate accurate geolocalization. This is partly because retrieval candidates are more likely to retrieve visually similar images from the database due to the popularity of such locations. Additionally, generated candidates tend to produce more reliable predictions in these cases, as the locations are well-represented in the world knowledge embedded 17 Table 5: Complete ablation study on IM2GPS3K and YFCC4K. YFCC4K IM2GPS3K Methods w/oL(2) PL w/o Cneg w/o ctext w/o cimg w/o Cg Street 1km 18.48 17.35 18.02 15.58 18.21 City 25km 44.61 44.51 43.91 41.77 43.47 Region 200km Country 750km Continent 2500km Street 1km 60.96 60.82 60.19 59.15 59.69 61.49 75.61 76.37 76.61 75.40 75.47 76. 88.28 88.28 88.62 88.35 88.75 89.29 31.97 31.57 31.70 15.81 32.60 City 25km 43.12 43.06 43.06 27.86 43.03 Region 200km Country 750km Continent 2500km 53.53 53.62 54.03 41.31 53.43 54.32 69.03 69.09 69.42 61.39 69.77 69. 81.19 81.67 82.07 77.66 82.71 82.45 Ours 18.79 45.05 32. 43.54 Figure 10: Hyperparameter analysis with all geographic levels on IM2GPS3K. in large vision-language models. In contrast, query images with large geolocalization errors (e.g., 2500km) typically lack informative visual cuessuch as images depicting open oceans or vast grasslandsmaking it extremely challenging to infer their true locations. In such cases, neither retrieval nor generation is likely to yield useful candidates."
        },
        {
            "title": "F Complete experimental results on ablation study",
            "content": "Table 5 presents the complete ablation results on both IM2GPS3K and YFCC4K. Consistent with the findings discussed in the main text, we observe that each component in our framework contributes positively to overall performance. Moreover, different types of contextual information incorporated into the promptsuch as visual cues, textual descriptions, and negative examplesall help improve both model training and inference. Finally, generated candidates are shown to complement retrievalbased candidates effectively. This is particularly beneficial for rare or long-tail query images, where retrieval candidates alone may fail to provide sufficient clues for accurate geolocation."
        },
        {
            "title": "G Hyperparameter Analysis with All Geographic Levels",
            "content": "Figure 10 shows the impact of different hyperparameters on GeoRanker across all geographic levels. As observed, the trends of each hyperparameter remain largely consistent across levels, highlighting the stability and robustness of our model under varying localization granularities. 18 Figure 11: Impact of Backbone Scale across All Levels."
        },
        {
            "title": "H Complete Experimental Results on Backbone Model Scale",
            "content": "Figure 11 shows the effect of backbone model size across all geographic levels. Consistent performance improvements are observed on both IM2GPS3K and YFCC4K datasets as the backbone scales from 0.5B to 7B parameters, further confirming GeoRankers scalability and compatibility with stronger LVLM."
        },
        {
            "title": "I Limitations",
            "content": "Our method achieves notable improvements in geolocalization accuracy over existing baselines. In addition, it demonstrates superior time efficiency compared to LVLM prompting methods, and its data efficiency allows strong performance even with relatively limited supervision. However, compared to direct embedding-based retrieval approaches, GeoRanker introduces an additional ranking stage, which leads to increased computational overhead during inference. One solution is to analyze the retrieval results: if the top-k candidates are already geographically concentrated, the ranking step can be skipped without significant loss in accuracy, thereby reducing the overall inference time. In addition, GeoRanker supports parallel scoring of candidates during large-scale deployment, which can significantly improve runtime and computational efficiency."
        }
    ],
    "affiliations": [
        "Department of Computer Sciences, University of Wisconsin-Madison",
        "Department of Data Science, City University of Hong Kong"
    ]
}