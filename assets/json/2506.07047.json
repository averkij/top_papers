{
    "paper_title": "Mathesis: Towards Formal Theorem Proving from Natural Languages",
    "authors": [
        "Yu Xuejun",
        "Jianyuan Zhong",
        "Zijin Feng",
        "Pengyi Zhai",
        "Roozbeh Yousefzadeh",
        "Wei Chong Ng",
        "Haoxiong Liu",
        "Ziyi Shou",
        "Jing Xiong",
        "Yudong Zhou",
        "Claudia Beth Ong",
        "Austen Jeremy Sugiarto",
        "Yaoxi Zhang",
        "Wai Ming Tai",
        "Huan Cao",
        "Dongcai Lu",
        "Jiacheng Sun",
        "Qiang Xu",
        "Shen Xin",
        "Zhenguo Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent advances in large language models show strong promise for formal reasoning. However, most LLM-based theorem provers have long been constrained by the need for expert-written formal statements as inputs, limiting their applicability to real-world problems expressed in natural language. We tackle this gap with Mathesis, the first end-to-end theorem proving pipeline processing informal problem statements. It contributes Mathesis-Autoformalizer, the first autoformalizer using reinforcement learning to enhance the formalization ability of natural language problems, aided by our novel LeanScorer framework for nuanced formalization quality assessment. It also proposes a Mathesis-Prover, which generates formal proofs from the formalized statements. To evaluate the real-world applicability of end-to-end formal theorem proving, we introduce Gaokao-Formal, a benchmark of 488 complex problems from China's national college entrance exam. Our approach is carefully designed, with a thorough study of each component. Experiments demonstrate Mathesis's effectiveness, with the autoformalizer outperforming the best baseline by 22% in pass-rate on Gaokao-Formal. The full system surpasses other model combinations, achieving 64% accuracy on MiniF2F with pass@32 and a state-of-the-art 18% on Gaokao-Formal."
        },
        {
            "title": "Start",
            "content": "Mathesis: Towards Formal Theorem Proving from Natural Languages Xuejun Yu1,*, Jianyuan Zhong2,3,*, Zijin Feng2,*, Pengyi Zhai1, Roozbeh Yousefzadeh2, Wei Chong Ng1, Haoxiong Liu2, Ziyi Shou1, Jing Xiong2, Yudong Zhou1, Claudia Beth Ong1, Austen Jeremy Sugiarto1, Yaoxi Zhang1, Wai Ming Tai1, Huan Cao1, Dongcai Lu1, Jiacheng Sun2, Qiang Xu3, Xin Shen1, , and Zhenguo Li2, 1Huawei Celia Team 2Huawei Noahs Ark Lab 3The Chinese University of Hong Kong"
        },
        {
            "title": "Abstract",
            "content": "Recent advances in large language models show strong promise for formal reasoning. However, most LLM-based theorem provers have long been constrained by the need for expert-written formal statements as inputs, limiting their applicability to real-world problems expressed in natural language. We tackle this gap with Mathesis, the first end-to-end theorem proving pipeline processing informal problem statements. It contributes Mathesis-Autoformalizer, the first autoformalizer using reinforcement learning to enhance the formalization ability of natural language problems, aided by our novel LeanScorer framework for nuanced formalization quality assessment. It also proposes Mathesis-Prover, which generates formal proofs from the formalized statements. To evaluate the real-world applicability of end-to-end formal theorem proving, we introduce Gaokao-Formal, benchmark of 488 complex problems from Chinas national college entrance exam. Our approach is carefully designed, with thorough study of each component. Experiments demonstrate Mathesiss effectiveness, with the autoformalizer outperforming the best baseline by 22% in pass-rate on Gaokao-Formal. The full system surpasses other model combinations, achieving 64% accuracy on MiniF2F with pass@32 and state-of-the-art 18% on Gaokao-Formal. 5 2 0 2 8 ] . [ 1 7 4 0 7 0 . 6 0 5 2 : r Figure 1: Performance of end-to-end theorem proving on the MiniF2F test set. Each configuration pairs an autoformalizer, which formalizes informal statements to formal ones, with prover that generates formal proofs. Results reports pass@32 accuracy for all autoformalizer-prover combinations. * Equal Contribution Correspondence to: Zhenguo Li <Li.Zhenguo@huawei.com> and Xin Shen <shenxin19@huawei.com>. Preprint. Under review."
        },
        {
            "title": "Introduction",
            "content": "The emergence of reasoning abilities in large language models (LLMs) has opened new frontiers in automated mathematics [1]. Recent automatic theorem provers (ATPs) leverage formal verification systems, such as Lean [2], Isabelle [3], and Coq [4], to enable formal reasoning. Formal reasoning starts with clear formal problem statement, followed by the generation of mechanically verifiable proofs in formal languages. This approach ensures greater reliability and verifiability. Notable models in this field, including Deepseek-Prover-V2 [5], Kimina-Prover [6], and Goedel-Prover [7], have advanced the state-of-the-art on benchmarks: MiniF2F [8], proofNet [9], and putnamBench [10], where the input problem statements are already formalized by human experts. However, real-world mathematical problems are typically written in natural language, which prohibits the direct use by ATPs. Traditionally, manual formalization ensures faithful translation of problems but requires significant effort and expertise before ATPs can solve them. In this paper, we study automatic end-to-end theorem proving from natural languages. The task begins with given natural language (NL) problem statement and entails its automatic translation into formal language (FL), followed by the generation of formal proof. critical step in the end-to-end task is autoformalizationthe process of automatically translating informal mathematics into formal language [11]which can significantly impact the success of proving due to errors introduced during formalization. Figure 2 illustrates two common examples, highlighting how improper formalization can yield misleading proof successes or render problems unprovable. Despite its importance, the task remains underdeveloped in terms of benchmarking, evaluation, and the availability of powerful autoformalizer. Existing benchmarks such as MiniF2F are not designed to evaluate autoformalization. Some human-authored formal statements in existing benchmarks subtly deviate from the original NL intent by simplification, while others exclude problems that are hard to formalize, such as those involving geometry, combinatorics[8], and word problems[9]. fine-grained method to assess autoformalization quality also remains lacking, hindering systematic assessment. Existing works often use MiniF2F, proofNet [9], and Numina [12], as benchmark datasets, relying primarily on binary compilation checks in Lean 4 and basic LLM judgments [7], which fail to capture nuanced errors. In terms of LLM-based autoformalization training, recent methods [13, 11, 14, 7] fine-tune LLMs on paired informal and formal statements (referred to as parallel statements [13, 14]) for higher quality, with Kimina-Autoformalizer [6] achieving state-of-the-art performance via expert iteration. However, these training approaches lack dynamic learning from direct feedback on both syntactic and semantic correctness. In this paper, we present Mathesis-Autoformalizer (Multi-domain Autoformalization Through Heuristic-guided Syntactic and Semantic Learning), the first autoformalization framework trained via online reinforcement learning (RL) combined with novel Hierarchical Preference Optimization (HPO) mechanism. By incorporating Lean compilation and semantic verification into the RL reward function while learning prover preferences through HPO, Mathesis significantly enhances formalization quality and achieves state-of-the-art performance. To advance end-to-end theorem proving and establish robust evaluation paradigm for autoformalization, we introduce GaokaoFormal, benchmark comprising 488 proof problems from Chinas National Higher Education Entrance Examination (Gaokao) spanning diverse mathematical domains, alongside LeanScorer, novel evaluation framework for nuanced formalization assessment. Furthermore, we develop Mathesis-Prover to support end-to-end theorem proving. Our key contributions are as follows. We release Mathesis-Autoformalizer, pioneered through online reinforcement learning with rewards for both syntactic validity and semantic correctness, as well as novel hierarchical preference optimization (HPO) process. It achieves 22% improvement in pass rate on Gaokao-Formal and 5% on MiniF2F compared to the state-of-the-art baseline KiminaAutoformalizer. We introduce Gaokao-Formal benchmark, challenging set of 488 Gaokao problems with parallel English and human-verified formal statements, aimed at advancing end-to-end formal reasoning research. We propose LeanScorer, novel evaluation method combining LLM-based analysis with Sugeno Fuzzy Integral for nuanced formalization assessment. It achieves 0.92 F1 score on Gaokao-Formal, outperforming the prior methods LLM-as-a-Judge by 7 percentage points and re-informalization by 27 points. 2 Informal Statement: Let Sn denote the sum of the first terms of the sequence an. Given that 2Sn {an} is an arithmetic sequence. + = 2an + 1, prove that Two Formal Statement Cases: theorem case_goal_as_assumption_error (a : R) (ha : d, n, (n + 1) = + d) Erroneously includes the desired goal in assumptions (h : n, 2 * ((cid:80) in Finset.range n, i) / + = 2 * + 1) : d, n, (n + 1) = + := by sorry theorem case_definition_error (a : R) (S : R) (hS : (n : N), 1, = (cid:80) in Finset.range n, k) (cid:80) in Finset.Icc 1 n, (h : (n : N), 1, 2 * / (n : R) + (n : R) = 2 * + 1) : (d : R), (n : N), 1, (n + 1) = + := by sorry Figure 2: Illustrative example of incorrect formalizations by Kimina-Autoformalizer. The first mistakenly includes the goal as an assumption, resulting in circular yet technically provable formalization that is mathematically invalid. The second mistranslates the summation range, leading to an incorrect formal statement that is both unprovable and misaligned with the informal input. We study end-to-end theorem proving, critical yet underexplored task for LLM-based formal theorem provers to solve practical mathematical problems directly from natural language. Extensive experiments shows the effectiveness of our end-to-end pipeline, achieving state-of-the-art performance 18% on Gaokao-Formal."
        },
        {
            "title": "2 Related work",
            "content": "Formal Reasoning Recent advancements have produced powerful LLM-based Automated Theorem Provers for proof assistants like Lean 4, including DeepSeek-Prover-V2 [5], Kimina-Prover [6], and Goedel-Prover [7], and motivated many advanced algorithms for proof search or finding [1519]. These systems demonstrate strong formal-to-formal (F2F) reasoning capabilities, where both input statements and proofs are in formal language. Correspondingly, prominent benchmarks such as MiniF2F [8] and ProofNet [9] focus on evaluating F2F proving capabilities using already wellformalized problem statements. However, this leaves significant gap in assessing the critical informal-to-formal (I2F) formalization and the full end-to-end proving pipeline from the informal statement. Our work addresses this by proposing an end-to-end proving pipeline, introducing Gaokao-Formal, diverse benchmark for evaluating I2F and end-to-end performance, and developing LeanScorer for nuanced I2F evaluation. While some other works [2022], such as Lego-Prover [21], also target I2F, require an additional informal proof sketch as input. In contrast, our work focuses on fully automatic end-to-end proving, starting from informal statements to whole-proof generation [23], making direct comparisons inappropriate. Autoformalization Autoformalization, the process of formalizing informal mathematics into formal language [24, 13], is essential for bridging the NL-FL gap. Prior work includes prompting pretrained LLMs [24, 9] and fine-tuning models on static NL-FL pairs [13, 11, 14], with systems like Kimina-Autoformalizer [6] achieving notable success. However, these approaches often lack dynamic learning from direct feedback on syntactic and semantic correctness, and their evaluation has typically relied on binary compilation checks or basic LLM judgments [7, 14], which may not capture nuanced errors. To address these limitations, we introduce Mathesis-Autoformalizer, which, to our knowledge, is the first autoformalizer for Lean to leverage online reinforcement learning for improved accuracy and robustness. Concurrently, our LeanScorer framework provides more fine-grained evaluation of autoformalization quality, moving beyond simple pass/fail metrics. Reinforcement Learning Fine-Tuning (RLFT) Reinforcement learning has proven highly effective for enhancing LLM capabilities in complex reasoning [25, 26]. The autoformalization task is wellsuited for RL, as syntactic validity (from Lean verifier) and semantic equivalence (e.g., assessed by an LLM judge or LeanScorer) can serve as direct reward signals. Despite this clear potential, the application of outcome-based RL techniques to specifically optimize these syntactic and semantic properties in autoformalization models has been largely underexplored in the literature. Our MathesisAutoformalizer pioneers this direction by employing Group Relative Policy Optimization [27] with carefully designed composite reward function (in Section 3.1). This approach allows the model to iteratively refine its ability to generate syntactically correct and semantically faithful formalizations, addressing key gap in existing autoformalization methodologies. 3 Figure 3: Overview of our end-to-end theorem proving pipeline."
        },
        {
            "title": "3 End-to-End Theorem Proving",
            "content": "The core objective of this paper is to tackle the end-to-end theorem proving task (defined in Section 1) by enabling automated theorem proving directly from informal natural language inputs. To this end, as illustrated in Figure 3, we propose structured, multi-stage pipeline consisting of three major stages: autoformalization, validation, and proving. The pipeline begins with given NL problem statement, which is first processed by an autoformalizer to generate certain number of candidate formal statements in Lean 4. This stage is handled by our Mathesis-Autoformalizer, model that performs best-in-class formalizations (to be described in Section 3.1). These candidates are then subjected to the validation stage, which includes syntactic check by the Lean compiler and semantic assessment by an LLM-based scoring system. For this purpose, we introduce the Gaokao-Formal benchmark and the LeanScorer evaluation framework (described in Section 3.2). The formal statement that passes the Lean compiler and receives the highest semantic assessment score is then passed to an automated theorem prover and generates complete, machine-verifiable proof in Lean. 3.1 Mathesis-Autoformalizer: Advancing Autoformalization with Reinforcement Learning The cornerstone of our end-to-end theorem proving pipeline (Figure 3) is Mathesis-Autoformalizer, novel system designed to translate informal mathematical problem statements from NL into formal Lean 4 [2] code. Unlike prior autoformalization approaches that predominantly rely on supervised fine-tuning (SFT) on static datasets, Mathesis-Autoformalizer leverages reinforcement learning (RL) to dynamically improve its translation accuracy based on direct feedback regarding both the syntactic validity and semantic correctness of its generated formalizations. GRPO was chosen over other RL methods due to its efficacy in optimizing policies based on the relative quality of multiple candidate generations and its mechanism for stable learning by regularizing against reference policy. To our knowledge, it is the first autoformalization model for Lean employing Group Relative Policy Optimization (GRPO) [27] for this purpose. 3.1.1 Composite Rewards for Autoformalization Let πθ represents the translator LLM policy parameterized by θ, and πref be fixed reference policy (typically the SFT model). For given natural language input , the policy πθ(x) generates group of candidate formal Lean 4 statements (outputs) {o1, ..., oG}. The optimization objective is to adjust θ to maximize the likelihood of generating higher-reward outputs relative to lower-reward ones within the group, while regularizing against large deviations from the reference policy. We construct composite reward function based on two criteria. For generated statement oi derived from input x: Semantic Equivalence Reward (Rsem) This binary reward assesses whether oi preserves the semantic meaning of x, determined by an auxiliary LLM judge (Jsem). Rsem(x, oi) = (cid:40) 1 0 if Jsem(x, oi) judges \"Appropriate\" otherwise . (1) Verification Reward (Rver) This binary reward indicates whether oi is syntactically correct and type-valid via Lean 4 verifier (Vlean), checked up to := by sorry. if Vlean(oi) succeeds otherwise Rver(oi) = (cid:40) 1 0 (2) . The overall reward ri for an output oi is computed as combination of these components: ri = R(x, oi, oref ) = Rsem + Rver. We find that this simple yet effective summation strategy indeed leads to state-of-the-art performance. We then leverage the GRPO objective to update πθ(x). Training Data Curation To effectively identify samples for training, our data curation process employs topic modeling with BERTopic [28] to the natural language informal statements of problems from pset [7] and our in-house Gaokao dataset. BERTopic was selected for its ability to generate coherent topics by leveraging contextual embeddings and clustering, allowing for effective categorization of problems based on their semantic content; this approach is also significantly faster and more cost-effective than using large language models for the same categorization task. We generated embeddings for each statement, performed dimensionality reduction and clustering, and then mapped the resulting topics to predefined mathematical categories in Section 4. The categorized data from two sources were then merged. To optimize Reinforcement Learning (RL) training efficiency with (GRPO), we employed our base model (pre-RL) to perform rollouts (k=14) on each problem, filtering out those yielding rewards with zero standard deviation across the rollouts. The remaining problems demonstrating reward variance were combined with 8,000 problems randomly sampled from the Lean Workbook [29], resulting in final training dataset of approximately 32k problems. 3.1.2 Hierarchical Preference Optimization for End-to-End Theorem Proving GRPO provides reward-maximizing initialization, aligning the autoformalizer with local objectives of syntactic correctness and semantic validity. In the context of end-to-end theorem proving, the autoformalizer formalizes natural language into formal statements aimed at facilitating successful proof generation by the prover. To enhance this, we further fine-tune the autoformalizer using Direct Preference Optimization (DPO) [30], where preferences are derived from the global success of the downstream proof generation. We refer to this combined approach as Hierarchical Preference Optimization, which integrates local alignment via GRPO and global alignment via DPO. DPO Training Data Generation During the data generation phase, for each natural language statement x, group of candidate formal statements yi are sampled from the autoformalizer πθ(x), where indexes the candidates. Each yi undergo syntactic and semantic validation, and those that pass are forwarded to the prover, which attempts to generate proofs zi. Preferences are assigned based on the successful completion of the proof verified by Lean, yielding data tuple {x, yi w} for successful cases, and {x, yi } for failed attempts. w, zi , zi DPO Training The training configuration employs single epoch with learning rate of 1 105. The KL regularization coefficient β is set to 0.1, penalizing deviations from the reference model. Optimization is applied to full parameters, with warmup ratio of 0.05. To manage memory usage efficiently, training is conducted using DeepSpeed zero3 offload. DPO fine-tuning enhances alignment with task-grounded outputs, thereby mitigating mismatches between reward function and actual task objectives. Compared to GRPO, DPO is more sampleefficient and stable alternative that performs offline preference learning and eliminates the need for separate reward model [30, 31]. However, its effectiveness heavily relies on strong base model to generate meaningful candidate outputs and better exploit preference signals [3234]. To this end, we first apply GRPO to establish strong initialization before proceeding with DPO fine-tuning. 3.2 LeanScorer: Nuanced Evaluation of Autoformalization Correctness Standard evaluations of auto-formalized statements often rely on binary syntactic checks or basic semantic judgments. To enable more fine-grained and reliable assessment, we propose LeanScorer, novel framework yielding continuous correctness score (0 to 1). This score allows for dynamic adjustment of decision thresholds according to task-specific precision/recall requirements. LeanScorer employs two-stage process (as shown in Figure 4): Subtask Decomposition and LLM-based Evaluation An LLM first deconstructs the NL problem into discrete subtasks (premises and conclusions). Another LLM then evaluates the formalization of each subtask by comparing it to the original NL expression, assigning one of three ratings: \"Perfectly Match\", \"Minor Inconsistency\", or \"Major Inconsistency\". The three-tiered rating system introduces necessary flexibility for borderline cases, avoiding the excessive rigidity of binary classification. Our empirical observations demonstrate clear differentiation patterns: the model consistently labels natural language-formal language (NL-FL) pairs with mathematical inequivalence or missing condi5 Figure 4: Overview of our LeanScorer evaluation method. tions as \"Major Inconsistency,\" while classifying cases with mathematical equivalence but divergent expressions or detailed math difference (e.g., omitted function domain definitions) as \"Minor Inconsistency.\" This intermediate category also serves to accommodate potential LLM evaluation errors. The three-tiered rating system thereby capitalizes on the LLMs capacity for nuanced assessment while minimizing evaluation bias. The prompts for the two stages are demonstrated in appendix B.5. Sugeno Fuzzy Integral Aggregation These categorical ratings are aggregated into composite score using the Sugeno Fuzzy Integral [35]. As useful method in multi-criteria decision-making (MCDM) [36], the Sugeno Fuzzy Integral provides robust framework for aggregating multiple categorical ratings into composite score. By designing the fuzzy measure, we enable the system to tolerate subtle inaccuracies in the LLMs judgments while enforcing strict criteria: it rejects any formalization containing \"Major Inconsistency\", awards full marks for formalization with all \"Perfectly Match\", and imposes incremental penalties for multiple \"Minor Inconsistency\". This approach balances flexibility with rigorous standards, accounting for the probabilistic nature of LLMs while ensuring robust formalization quality. Let = {0, 1, 2, ..., 1} denote the set of subtasks, with tasks in total. Let = {e0, e1, ..., en1} denote the evaluation set, where ei {A, B, C} (for simplicity, we use represents Perfectly Match, represents Minor Inconsistency and represents Major Inconsistency). Let : [0, 1] be an evaluation mapping function, in our experiments, we set (A) = 1.0, (B) = 0.5, (C) = 0. Our fuzzy measure µ(M ) for subset of tasks , where is the set of subtasks is designed to handle uncertainty and inter-task interactions, notably by applying progressive penalties for multiple \"Minor Inconsistencies\" and veto mechanism where any \"Major Inconsistency\" yields zero score. perfect score of 1 requires all subtasks to be \"Perfectly Match.\" The fuzzy measure is defined as: µ(M ) = (1 0.2 MB), 0} (1 0.1 MB) 1 max{ MA MA 0 if = and M, ei = if MB 2 if MB = 1 if M, ei = , (3) where A, B, represent the ratings, and MA, MB are counts of and ratings in . The overall LeanScore S(f ) = maxn i=1 min(f (eπ(i)), µ(Ai)), for sorted evaluations (eπ(i)) and corresponding index sets Ai. Users can decide on decision threshold 0 < α < 1 when it is necessary to perform binary classification. 3.3 Mathesis-Prover Our formal mathematical reasoning framework, Mathesis-Prover, builds upon the Qwen2.5-Math-7B architecture [37] through an expert iteration paradigm. This approach establishes self-improving cycle where the prover enhances its capabilities by learning from both initial training examples and newly verified solutions to formalized problems. The training process for Mathesis-Prover proceeds through iterative refinement cycles. In each iteration, we employ the current prover model (we employ DeepSeek-Prover-V2-7B [5] in the first round) to generate complete proof attempts for questions from open-source datasets Goedel-Pset-v1 [7]. To ensure appropriate training difficulty, we specifically include problems that cannot be solved within four attempts (pass@4) by Goedel-Prover but are successfully verified when processed by our trained prover model using the Lean 4 proof assistant. 6 Benchmark MiniF2F Gaokao-Formal FL NL Problem NL If and are positive integers for which 2x3y = 1296, prove that x+y = 8. theorem amc12b_2004_p3 (x : N) (h0 : 2 ^ * 3 ^ = 1296) : + = 8 := by sorry Let be positive integer, and let a1, a2, , a4m+2 be an arithmetic If two terms ai and aj sequence with non-zero common difference. (i < j) are removed from the sequence such that the remaining 4m terms can be evenly divided into groups, and each group of 4 numbers forms an arithmetic sequence, then the sequence a1, a2, , a4m+2 is called an (i, j)separable sequence. For 3, prove that the sequence a1, a2, , a4m+2 is (2, 13)separable sequence theorem gaokaoformal_g4 (m : N) (hm : 1 m) (a : R) (ha: (d:R), = 0 ( (n:N), (n 1 4*m+1) (n+1) = + d)) (sep: (N N) Prop) (h_sep: (i j:N), (i 1 i<j 4*m+2) sep (i,j) = ( (f : N), ( (h:N), (h 1 4*m+2 h=i h=j) (f 1 m)) ( (g:N), let := h:N 1 4*m+2 = = = g; (g 1 m) (Nat.card = 4 ( (p: S), ( (k l:N), (k 1 4 1 4 = l) = l) ( (d:R), (k:N), (k 1 3) (p (k+1)) = (p k) + d)))))) : 3 sep (2,13) := by sorry FL Figure 5: Comparison of the complexity of the problems in MiniF2F v.s. Gaokao-Formal"
        },
        {
            "title": "4 The Gaokao-formal benchmark",
            "content": "To advance autoformalization and end-to-end theorem proving from natural language, we introduce the Gaokao-Formal benchmark. Unlike existing benchmarks that focus primarily on formal-to-formal proving or simplifying complexities of the NL mathematical problems, Gaokao-Formal specifically targets the difficulties of auto-formalizing diverse and intricate NL mathematical statements. This benchmark consists of 488 proof problems from Chinas National Higher Education Entrance Examination (Gaokao, 2008-2024), often segmented into sub-questions. Each instance includes the original Chinese problem statement, an English translation, and human-expert verified Lean 4 formal statement. comparative overview is provided in Table 2, highlighting its key distinctions in terms of domain coverage and task focus. Table 2: Comparison of Gaokao-Formal with Existing Mathematical Reasoning Benchmarks. Gaokao-Formal MiniF2F ProofNet PutnamBench Inclusion Geometry Inclusion Comb. Complex Formalization Primary Task Focus Size (Problems/Stmts) Yes Yes Included End2End 488 Limited Limited Excluded Proving 244 Less Emphasis Less Emphasis Excluded Autoformal. & Proving 371 Yes Yes N/A Proving 645 Table 1: Gaokao-Formal Benchmark Category Summary. Category Diversity Unlike Problem-Type that may filter out benchmarks problem types with less developed theorem libraries (e.g., geometry, Gaokao-Formal combinatorics), includes all such problems as they appear in the Gaokao exams. This encourages broader model capabilities and contributes to the expansion of Lean 4s Mathlib [2]. The problems are categorized into seven domains (functions, sequences/series, inequality, analytic trigonometry, geometry, probability/combinatorics, and comprehensive questions) to facilitate targeted evaluation. Functions Sequences and series Inequality Trigonometry Analytic geometry Probability and combinatorics Comprehensive questions Number of Questions 167 150 28 22 71 4 46 Autoformalization Complexity Many existing benchmarks simplify or exclude problems where the primary challenge lies in the NL-to-Formal Language (NL2FL) translation. Gaokao-Formal deliberately retains these, especially in its \"comprehensive questions\" category, which features problems with multi-domain concepts, novel definitions, or complex linguistic structures, thereby rigorously testing LLM abstraction capabilities. We provide an example of this kind of question, comparing it with one MiniF2F question in Figure 5."
        },
        {
            "title": "5 Experiments",
            "content": "We conduct series of experiments to validate our contributions. First, we evaluate the reliability of our proposed semantic consistency checker, LeanScorer. Second, we assess the performance of our autoformalization model, Mathesis-Autoformalizer, against state-of-the-art baselines. Finally, we measure the impact of improved autoformalization on the success rate of the complete end-to-end theorem proving pipeline. 5.1 Experimental Setup Datasets We primarily use our newly proposed Gaokao-Formal benchmark (Section 4) for evaluating autoformalization from complex NL and end-to-end proving. We also report results on the widely used MiniF2F-test set [8] for comparison. Models Training details of the both our autoformalizer and prover are in A. We evaluate our autoformalization models, Mathesis-Autoformalizer, against strong baselines including API-based models (Claude-3.5, GPT-o3-mini, GPT-4o, Doubao-1.5, Gemini-2.0, Deepseek-V3, Deepseek-R1) and open-source fine-tuned models (Herald-7B [11], Kimina-7B [6]). For end-to-end evaluation, we use several provers: Goedel-Prover-SFT-7B [7], Kimina-Prover-Preview-Distill-7B [6], DeepSeekProver-V2 (7B version) [5], and our Mathesis-Prover. Auxiliary models like Deepseek-V3 [38] are used for LLM-as-a-Judge and re-informalization baselines. Evaluation Metrics We assess autoformalization quality using: (1) Lean Check (LC), measuring syntactic validity (pass@k); (2) LeanScorer Semantic Check (LSC), providing nuanced semantic assessment. The LeanScorer is evaluated via Precision, Recall, and F1 against human labels. Success rate@k, defined in Equation B.1, is used for LC and LSC over samples. End-to-end performance is measured by the proving success rate of prover given an auto-formalized statement. Implementation Details For autoformalization quality assessment  (Table 4)  , we report success rate@k for = 1 and = 6. For end-to-end proving  (Table 5)  , we use search budget of 32 attempts per problem for all provers as it is reasonable budget for real applications. Experiments were conducted on relevant hardware resources. Prompts are detailed in Appendix B.5. 5.2 Evaluating Semantic Consistency Checkers Goal Reliable semantic evaluation is crucial for developing and assessing autoformalization models beyond simple syntactic checks. We first validate the effectiveness of LeanScorer compared to common baseline methods. Table 3: Performance Comparison of Semantic Consistency Checkers. The evaluation measures how faithfully each checkers predicted labels align with human-annotated ground truth on the Gaokao dataset. Precision and recall are reported in percentages (%). Method Methodology We compared LeanScorer (with threshold setting as α = 0.6) with other ground truth free\" semantic check methods: standard LLM-as-a-Judge approach [7], and Re-informalization & Semantic Similarity baseline [29], against human annotations on subset of Gaokao-Formal (with some wrong LLM formalized statement kept for evaluation). All the LLM roles utilize Deepseek-V3 with prompts in Appendix B.5. Performance was measured using Precision, Recall, and F1 score. LLM-as-a-Judge Re-informalization LeanScorer (Ours) Precision (%) Recall (%) 0.85 0.65 0.92 100 50 89 73 93 94 F1 Results & Analysis The results in Table 3 compellingly demonstrate LeanScorers superior ability to discern semantic consistency in autoformalization. Achieving remarkable 94% precision, 89% recall, and F1 0.92 scores, LeanScorer significantly outstrips both the LLM-as-a-Judge (F1 0.85) and the Re-informalization baseline (F1 0.65). While the LLM-as-a-Judge exhibits perfect recall, its lower precision indicates higher rate of false positives. Conversely, Re-informalization, despite its high precision, suffers from low recall, missing substantial number of inconsistencies. LeanScorers balanced and high performance across both precision and recall underscores its effectiveness as 8 robust and reliable tool for nuanced semantic evaluation, crucial for advancing the development of accurate autoformalization models. Table 4: Quality assessment of the formalized statement generated by single model. Each column highlights one top score for sample budget 1 (bold) and one for sample 6 (underlined). Gaokao-Formal MiniF2F-Test Sample Model API Models Claude-3.5 GPT-o3-mini GPT-4o Doubao-1.5 Gemini-2. Deepseek-V3 Deepseek-R1 Open-Source Models Herald-7B Kimina-7B Ours Mathesis-Autoformalizer Mathesis-Autoformalizer-HPO Budget LC LC+LSC LC LC+LSC 1 6 1 6 1 6 1 6 1 6 1 1 6 1 6 1 6 1 6 1 6 71% 74% 58% 87% 50% 80% 48% 77% 56% 80% 76% 91% 54% 86% 80% 95% 83% 100% 92% 100% 99% 100% 56% 41% 69% 58% 45% 38% 77% 70% 36% 20% 65% 48% 40% 19% 70% 45% 41% 36% 71% 66% 61% 54% 84% 69% 44% 45% 76% 81% 41% 56% 69% 78% 61% 50% 91% 91% 69% 88% 95% 98% 79% 93% 96% 98% 30% 49% 25% 54% 13% 28% 15% 32% 22% 47% 36% 56% 30% 57% 14% 27% 21% 49% 45% 67% 50% 71% 5.3 Autoformalization Performance Goal We evaluated the core performance of our Mathesis-Autoformalizer in formalizing NL problems into syntactically correct and semantically faithful Lean 4 statements, comparing with SOTA models. Methodology We compared Mathesis-Autoformalizer against various API and open-source baseline autoformalizers on the MiniF2F-test and Gaokao-Formal benchmarks. Performance was measured using Lean Check success rate@k (LC@k) and the combined Lean Check + LeanScorer Semantic Check success rate@k (LC+LSC@k) for k=1 and k=6. Results & Analysis Table 4 presents the detailed autoformalization results. Our MathesisAutoformalizer-HPO models consistently achieve state-of-the-art performance, particularly on the challenging Gaokao-Formal benchmark. For instance, Mathesis-Autoformalizer achieves an LC+LSC@6 score of 71%, representing substantial improvement over the strong Kimina baselines 49%. This constitutes 22% absolute increase and relative increase of approximately 44.9%, validating the effectiveness of our GRPOand HPO-based reinforcement learning approach combined with the composite reward function in generating both syntactically valid and semantically accurate formalizations. The results highlight the advantage of dynamic learning from semantic and syntactic feedback, especially for complex NL problems prevalent in Gaokao-Formal. 5.4 End-to-End Theorem Proving Performance Goal The ultimate test is the impact of the autoformalizer on the success rate of the complete end-to-end NL-to-Proof pipeline. We evaluate how using formal statements generated by MathesisAutoformalizer affects the performance of downstream theorem provers. 9 Table 5: Performance of different provers on formal problem statements generated by various autoformalizers from natural language inputs. Underlines (bold) indicate top (second) scores per column among LLM-based autoformalizers. Model Gaokao-Formal Autoformalizer MiniF2F-Test Goedel-Prover-SFT-7B Kimina-Prover-Preview-Distill-7B DeepSeek-Prover-V2-7B (non-COT) Mathesis-Prover-7B Human Herald Kimina Mathesis Mathesis-HPO Human Herald Kimina Mathesis Mathesis-HPO Human Herald Kimina Mathesis Mathesis-HPO Human Herald Kimina Mathesis Mathesis-HPO Search Budget Accuracy Search Budget Accuracy 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 57.6% 26.6% 49.6% 52.4% 52.8% 63.1% 35.7% 57.8% 60.2% 63.1% 68.0% 42.2% 59.4% 61.9% 63.9% 69.2% 34.8% 59.4% 63.5% 64.3% 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 10.0% 5.7% 8.8% 11.2% 11.6% 12.1% 6.3% 11.9% 13.9% 16.1% 15.2% 7.2% 11.1% 14.9% 16.8% 13.7% 7.2% 11.7% 15.6% 18.0% Methodology We generated formal statements for MiniF2F-test and Gaokao-Formal using different autoformalizers: Human-provided, Herald, Kimina, and our Mathesis-Autoformalizer. These formal statements were then fed as input to various provers: Goedel-Prover-SFT-7B, Kimina-Prover-PreviewDistill-7B, DeepSeek-Prover-V2-7B non-COT, and our Mathesis-Prover. We measured the proving success rate (Accuracy) with fixed search budget of 32. Results & Analysis From Table 5, we draw two key observations. First, our end-to-end pipeline incorporating both Mathesis-Autoformalizer and Mathesis-Prover achieves pioneer performance among 7B parameter provers and existing autoformalizers, attaining success rates of 64.3% on MiniF2F and 18.0% on Gaokao-Formal. These results not only demonstrate the effectiveness of our GRPO-HPO training strategy but also validate Gaokao-Formal as rigorous benchmark for evaluating end-to-end formal reasoning systems. Second, our analysis reveals significant performance gains from component improvements. On MiniF2F, upgrading the prover yields an 11.5% absolute improvement (from 52.8% to 64.3%), while enhancing the autoformalizer produces more substantial 29.5% gain (from 34.8% to 64.3%). The Gaokao-Formal benchmark, which presents greater formalization challenges, shows similar trends: prover improvements lead to 6.4% increase (11.6% to 18.0%), while autoformalizer enhancements nearly double performance with an 11.2% improvement (7.2% to 18.4%). These comparative results underscore the critical role of high-quality autoformalization in end-to-end theorem proving systems. It was observed that the model occasionally surpassed human-written formalizations in the GaokaoFormal benchmark. This observation can be attributed to two key factors. First, in the benchmark construction, human formalizations rigorously stated all premises with maximal precision, for instance, explicitly declaring domains when defining functions or sequences (see Figure 5). In contrast, LLM-generated formalizations may not be in this style which leads to provers training data bias so that provers show difficulty proving these questions. Second, while LeanScorer achieves 94% verification precision (Section 5.2), residual false positives in the verification pipeline could partially account for this performance discrepancy. Additionally, we identified edge cases where autoformalizers and provers circumvented Lean syntactic checks. For instance, both Deepseek-prover-v2 and Mathesis-Prover occasionally produced proofs ending with apply?, which were technically verifiable but lacked substantive reasoning; these were excluded from success metrics. Similarly, Kimina-Autoformalizer and Mathesis-Autoformalizer generated statements concluding with : True := by sorry, where the proof goal merely restated 10 premise. While syntactically valid and occasionally passing LeanScorers semantic check (due to the presence of conditions and conclusions), such formulations failed to capture the original problems logical structure and were thus excluded from end-to-end evaluation."
        },
        {
            "title": "6 Real-World Application: Gaokao Problem Solving System in Huawei Celia",
            "content": "In this section, we present practical implementation of our end-to-end formal reasoning framework through its integration into Huawei Celia, the AI assistant for Huawei products. We demonstrate how combining formal and informal reasoning can enhance model reasoning performance on Chinas National Higher Education Entrance Examination (Gaokao). Gaokao is the most crucial academic assessment in China that determines university admissions for millions of students annually. Gaokao questions demand advanced logical reasoning and mathematical proficiency, making them an ideal testbed for evaluating how formal reasoning can augment LLM capabilities. As Gaokao problems typically consist of multiple interrelated sub-questions (which exceed the capacity of standalone provers), our system first employs an LLM to automatically decompose each question into atomic sub-problems. These are then processed through our end-to-end theoremproving pipeline (Section 3). To further enhance performance, we developed an interactive formalinformal framework that enables bidirectional communication between formal and informal reasoning components. We integrated both pipelines (the end-to-end theorem-proving system and this interactive framework) into Huaweis Celia AI assistant. Our comprehensive evaluation employs Gaokao problems from the past five years, comparing three approaches: (1) baseline informal reasoning using the state-of-the-art DeepSeek-R1 (671B) model, (2) our end-to-end theorem-proving pipeline, and (3) the complete Celia Gaokao problem-solving system incorporating both the theorem-proving pipeline and interactive framework. From the segmented sub-questions, we identified 95 proof-related items, categorized in Table 6. Figure 6 demonstrates that the end-to-end theorem-proving pipeline showed particular strength in Functions and Inequality problems, and the full Celia system achieved improvements across all categories. The overall accuracy increased from baseline of 65.3% to 69.4% using just the theoremproving pipeline (with Mathesis-Autoformalizer and Mathesis-Prover), while the complete Celia system reached 84.2% accuracy. By case studies, we found that informal reasoning often fails in cases involving complex logical inferences or intricate mathematical computations, and occasionally, the model does not employ sufficiently rigorous reasoning methods (e.g., enumerating specific cases rather than providing proper proof). An example in Appendix B.4 highlights scenario in which informal reasoning leads to logical errors, whereas formal reasoning efficiently resolves the problem using Lean 4s built-in tactic nlinarith. Our observations suggest that formal reasoning can significantly enhance the logical and computational rigor of LLMs. Future research could explore whether formal reasoning capabilities can be leveraged to augment the informal reasoning ability of models. Additionally, improving the readability of formal reasoning represents another critical direction for future investigation."
        },
        {
            "title": "7 Limitation",
            "content": "While the proposed end-to-end pipeline demonstrates significant progress, there remains considerable room for improvement. On one hand, each of the three componentsautoformalization, theorem proving, and scoring and evaluation, can be further refined. On the other hand, future work could integrate these capabilities into unified model, extending its scope from natural language input to formal language proof generation. We leave this direction for future research and anticipate further advancements in this field."
        },
        {
            "title": "8 Conclusion",
            "content": "This paper investigates the potential of large language models in formal reasoning and proposes pipeline to enhance this specific capability into an end-to-end framework for real-world applications. By training the Mathesis-Autoformalizer and the Mathesis-Prover, as well as designing the LeanScorer, we advance end-to-end formal reasoning to achieve state-of-the-art performance. Additionally, this work introduces the Gaokao-Formal benchmark, which highlights the challenges of autoformalization and promotes formal reasoning across diverse domains. This paper investigates the potential of large language models in formal reasoning and proposes pipeline to enhance this specific capability into an end-to-end framework for real-world applications. By training the Mathesis11 Table 6: Sub-questions by Category Category Total Questions Analytic geometry Comprehensive questions Function Inequalities Sequences and series Trigonometry Total 12 6 38 12 23 4 95 Figure 6: Performance improvement by category. Autoformalizer and the Mathesis-Prover, as well as designing the LeanScorer, we advance end-to-end formal reasoning to achieve state-of-the-art performance. Additionally, this work introduces the Gaokao-Formal benchmark, which highlights the challenges of autoformalization and promotes formal reasoning across diverse domains."
        },
        {
            "title": "References",
            "content": "[1] Kaiyu Yang, Gabriel Poesia, Jingxuan He, Wenda Li, Kristin Lauter, Swarat Chaudhuri, and Dawn Song. Formal mathematical reasoning: new frontier in AI. In Proceedings of the International Conference on Machine Learning, 2025. [2] The mathlib Community. The lean mathematical library. In Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs, POPL 20. ACM, January 2020. [3] Lawrence Paulson. Isabelle: generic theorem prover. Springer, 1994. [4] Gérard Huet, Gilles Kahn, and Christine Paulin-Mohring. The coq proof assistant tutorial. Rapport Technique, 178:113, 1997. [5] ZZ Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, et al. Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition. arXiv preprint arXiv:2504.21801, 2025. [6] Haiming Wang, Mert Unsal, Xiaohan Lin, Mantas Baksys, Junqi Liu, Marco Dos Santos, Flood Sung, Marina Vinyes, Zhenzhe Ying, Zekai Zhu, et al. Kimina-prover preview: Towards large formal reasoning models with reinforcement learning. arXiv preprint arXiv:2504.11354, 2025. [7] Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, et al. Goedel-prover: frontier model for open-source automated theorem proving. arXiv preprint arXiv:2502.07640, 2025. [8] Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. Minif2f: cross-system benchmark for formal olympiad-level mathematics. arXiv preprint arXiv:2109.00110, 2021. [9] Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward Ayers, Dragomir Radev, and Jeremy Avigad. Proofnet: Autoformalizing and formally proving undergraduate-level mathematics. arXiv preprint arXiv:2302.12433, 2023. [10] George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Amitayush Thakur, and Swarat Chaudhuri. Putnambench: Evaluating neural theorem-provers on the putnam mathematical competition. arXiv preprint arXiv:2407.11214, 2024. [11] Guoxiong Gao, Yutong Wang, Jiedong Jiang, Qi Gao, Zihan Qin, Tianyi Xu, and Bin Dong. Herald: natural language annotated lean 4 dataset. arXiv preprint arXiv:2410.10878, 2024. [12] Jia Li, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi, Shengyi Huang, Kashif Rasul, Longhui Yu, Albert Jiang, Ziju Shen, et al. Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions. Hugging Face repository, 13:9, 2024. [13] Albert Jiang, Wenda Li, and Mateja Jamnik. Multilingual mathematical autoformalization. arXiv preprint arXiv:2311.03755, 2023. [14] Xiaoyang Liu, Kangjie Bao, Jiashuo Zhang, Yunqi Liu, Yu Chen, Yuntian Liu, Yang Jiao, and Tao Luo. Atlas: Autoformalizing theorems through lifting, augmentation, and synthesis of data. arXiv preprint arXiv:2502.05567, 2025. [15] Zhenwen Liang, Linfeng Song, Yang Li, Tao Yang, Feng Zhang, Haitao Mi, and Dong Yu. Mps-prover: Advancing stepwise theorem proving by multi-perspective search and data curation. arXiv preprint arXiv:2505.10962, 2025. [16] Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, and Kai Shen. Bfs-prover: Scalable best-first tree search for llm-based automatic theorem proving. arXiv preprint arXiv:2502.03438, 2025. [17] Yang Li, Dong Du, Linfeng Song, Chen Li, Weikang Wang, Tao Yang, and Haitao Mi. Hunyuanprover: scalable data synthesis framework and guided tree search for automated theorem proving. arXiv preprint arXiv:2412.20735, 2024. 13 [18] Haoxiong Liu, Jiacheng Sun, Zhenguo Li, and Andrew Yao. Efficient neural theorem proving via fine-grained proof structure analysis. arXiv preprint arXiv:2501.18310, 2025. [19] Xiao-Wen Yang, Zhi Zhou, Haiming Wang, Aoxue Li, Wen-Da Wei, Hui Jin, Zhenguo Li, and Yu-Feng Li. Carts: Advancing neural theorem proving with diversified tactic calibration and biasresistant tree search. In The Thirteenth International Conference on Learning Representations, 2025. [20] Xueliang Zhao, Wenda Li, and Lingpeng Kong. Decomposing the enigma: Subgoal-based demonstration learning for formal theorem proving. arXiv preprint arXiv:2305.16366, 2023. [21] Haiming Wang, Huajian Xin, Chuanyang Zheng, Lin Li, Zhengying Liu, Qingxing Cao, Yinya Huang, Jing Xiong, Han Shi, Enze Xie, et al. Lego-prover: Neural theorem proving with growing libraries. arXiv preprint arXiv:2310.00656, 2023. [22] Albert Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, and Guillaume Lample. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. arXiv preprint arXiv:2210.12283, 2022. [23] Huajian Xin, ZZ Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, et al. Deepseek-prover-v1. 5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search. arXiv preprint arXiv:2408.08152, 2024. [24] Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus Rabe, Charles Staats, Mateja Jamnik, and Christian Szegedy. Autoformalization with large language models. Advances in Neural Information Processing Systems, 35:3235332368, 2022. [25] Anthropic. The Claude 3 model family: Opus, Sonnet, Haiku. Model Card, March 2024. [26] DeepSeek-AI and Anonymous Contributors. DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning, 2025. [27] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y.K. Li, Y. Wu, and Daya Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024. [28] Maarten Grootendorst. Bertopic: Neural topic modeling with class-based tf-idf procedure. arXiv preprint arXiv:2203.05794, 2022. [29] Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, and Kai Chen. Lean workbook: large-scale lean problem set formalized from natural language math problems. arXiv preprint arXiv:2406.03847, 2024. [30] Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher Manning, Stefano Ermon, and Chelsea Finn. Direct preference optimization: Your language model is secretly reward model. Advances in Neural Information Processing Systems, 36:5372853741, 2023. [31] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35:2773027744, 2022. [32] Songjun Tu, Jiahao Lin, Xiangyu Tian, Qichao Zhang, Linjing Li, Yuqian Fu, Nan Xu, Wei He, Xiangyuan Lan, Dongmei Jiang, et al. Enhancing llm reasoning with iterative dpo: comprehensive empirical investigation. arXiv preprint arXiv:2503.12854, 2025. [33] Tianduo Wang, Shichen Li, and Wei Lu. Self-training with direct preference optimization improves chain-of-thought reasoning. arXiv preprint arXiv:2407.18248, 2024. [34] Junshu Pan, Wei Shen, Shulin Huang, Qiji Zhou, and Yue Zhang. Pre-dpo: Improving data utilization in direct preference optimization using guiding reference model. arXiv preprint arXiv:2504.15843, 2025. 14 [35] Michio Sugeno. Theory of fuzzy integrals and its applications. Doctoral Thesis, Tokyo Institute of Technology, 1974. [36] Jonata Wieczynski, Giancarlo Lucca, Eduardo Borges, Asier Urio-Larrea, Carlos López Molina, Humberto Bustince, and Graçaliz Dimuro. Application of the sugeno integral in fuzzy rule-based classification. Applied Soft Computing, 167:112265, 2024. [37] An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, Keming Lu, Mingfeng Xue, Runji Lin, Tianyu Liu, Xingzhang Ren, and Zhenru Zhang. Qwen2.5-math technical report: Toward mathematical expert model via self-improvement. arXiv preprint arXiv:2409.12122, 2024. [38] DeepSeek-AI. Deepseek-v3 technical report, 2024. [39] Kimi Authors. Kimi k1.5: Scaling reinforcement learning with LLMs, 2025. [40] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations (ICLR), 2022. [41] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Conference on Learning Representations (ICLR), 2019. [42] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-theArt natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 3845, Online, October 2020. Association for Computational Linguistics. [43] Leandro von Werra, Lewis Schmid, Thomas Wolf, and Lewis Tunstall. Trl: Transformer reinforcement learning. https://github.com/huggingface/trl, 2020-2024. [44] Lukas Biewald. Experiment tracking with weights and biases. https://wandb.ai, 2020. Software available from wandb.com."
        },
        {
            "title": "A Model Training Details",
            "content": "A.1 Training Details for Mathesis-Autoformalizer The training of our Mathesis-Autoformalizer model, which employs Group Relative Policy Optimization (GRPO), involves several key hyperparameters and implementation choices as briefly mentioned in Section 3.1.1. The policy πθ is initialized from Kimina-Autoformalizer [39]. We employ Parameter-Efficient Fine-Tuning (PEFT) via Low-Rank Adaptation (LoRA) [40], configured with rank = 16 and α = 32. LoRA is applied to the attention projection layers of the base model. The optimization is performed using the AdamW optimizer [41] with learning rate of 1 106 and gradient checkpointing to manage memory usage. For the GRPO algorithm itself, we sample = 14 candidate formal statements per input natural language problem x. The Kullback-Leibler (KL) divergence coefficient β, which regularizes the policy updates against the reference SFT policy, is set to 0.04. The policy model πθ is updated once per sampling/exploration phase (i.e., µ = 1, meaning updates occur after each group of generations for given input is processed and rewarded). To enhance efficiency, reward computations (syntactic verification via Lean and semantic assessment) are parallelized using Pythons asyncio library. The overall training pipeline is managed using the Hugging Face transformers [42] and trl [43] libraries. Experiment progress and results are logged using Weights & Biases [44]. A.2 Training Details for Mathesis-Prover For the SFT phase, we conduct hyperparameter optimization exploring learning rates of 5 105 with training durations of 2 epochs. All training runs are executed on Huawei Atlas 800T A2 servers, with each iterations verified proofs augmenting the training set for subsequent refinement cycles. This methodology ensures continuous improvement while maintaining rigorous verification standards throughout the training process."
        },
        {
            "title": "B Experiments Details and Case Study",
            "content": "B.1 Sucess Rate @ For both the Lean Syntax Check and the LLM Semantic Check, the success rate@k is reported for the check. Specifically, the success rate@k refers to the rate in which given natural language statement is formalized times, and at least one of the formulations passes the lean syntax check. The rate is formally defined as: (cid:104) success rate@k = (cid:104) = (cid:16) (cid:95) i=1 (cid:16) 1 (cid:17)(cid:105) si = 1 1 (cid:17)k(cid:105) , Binomial(k, p) (4) where si {0, 1} is be an indicator variable for whether the i-th formalization passes the check, is the number of correct formalizations among k, and = is the probability that single formalization passes the check. B.2 Sample Lean4 Proof Code With \"Apply?\" That Can Pass Lean Verifier Lean Proof 1 import Mathlib 2 import Aesop 3 4 set_option maxHeartbeats 0 5 6 open BigOperators Real Nat Topology Rat 16 8 /-- Prove that the number $sum^n_{k=0}binom{2n+1}{2k+1}2^{3k}$ is not divisible by $5$ for any integer $nge0.$-/ 9 theorem imo_1974_p3 (n : N) : 5 (cid:80) in Finset.range (n + 1), Nat.choose (2 * + 1) (2 * + 1) * 2 ^ (3 * k) := by intro have rw [Nat.dvd_iff_mod_eq_zero] at have := : ((cid:80) in Finset.range (n + 1), Nat.choose (2 * + 1) (2 * + 1) * 2 ^ (3 * k)) % 5 = 0 := by -- We will show that the sum modulo 5 is never 0 by examining the terms and their contributions. have : ((cid:80) in Finset.range (n + 1), Nat.choose (2 * + 1) (2 * + 1) * 2 ^ (3 * k)) % 5 = 2 := by -- This is placeholder for the actual proof, which would involve detailed combinatorial arguments. rw [ Cardinal.natCast_inj] apply? omega omega 10 11 12 13 15 16 17 18 19 21 22 B.3 Sample Lean4 Proof Code With \"True\" That Can Pass Lean Verifier Lean Proof 1 import Mathlib 2 import Aesop 3 4 set_option maxHeartbeats 0 5 6 open BigOperators Real Nat Topology Rat 7 8 /-Let $f(x)=x - ae^{x}(ain R)$, $xin R$. It is known that the function $y = f(x)$ has two zeros $x_1$, $x_2$, with $x_1 < x_2$. Prove that $frac{x_2}{x_1}$ increases as $a$ decreases.-/ 9 theorem question (f : R) (hf : = fun => - * Real.exp x) (x1 x2 : R) (hx1 : a, (x1 a) = 0) (hx2 : a, (x2 a) = 0) (h1 : a, x1 < x2 a) (h2 : a, b, < x2 / x1 < x2 / x1 b) : True := by 11 12 B.4 Informal and Formal Reasoning Case Study 17 Illustrative Example Question: Real numbers and satisfy + 3. Prove that 2a2 + 2b2 > + b. Informal Reasoning: Since + 3, by the Cauchy-Schwarz Inequality: That is: Thus: Given + 3, it follows that: Therefore: Meanwhile, since + 3: Hence: Formal Reasoning: (a2 + b2)(1 + 1) (a + b)2 2(a2 + b2) (a + b)2 2a2 + 2b2 (a + b)2 (a + b)2 2a2 + 2b2 9 2a2 + 2b2 9 > 3 + 2a2 + 2b2 > + 1 theorem question_example ( : R) ( : + 3) : 2* ^2 + 2* ^2 > + := by 2 3 4 nlinarith [ sq_nonneg ( - ) , sq_nonneg ( + - 3) , sq_nonneg ( + - 1) , sq_nonneg ( - 1) , sq_nonneg ( - 1) ] B.5 Prompt Templates Prompt for Autoformalization (used by Herald and Mathesis-Autoformalizer) [Question]: {statement} You are an expert in formal mathematics. Your task is to convert the above [question] to lean 4 theorems by completing the following lean 4 code: lean4 import Mathlib import Aesop set-option maxHeartbeats 0 set-option pp.numericTypes true set-option pp.coercions true set-option pp.letVarTypes true set-option pp.structureInstanceTypes true set-option pp.instanceTypes true set-option pp.mvars.withType true set-option pp.coercions true set-option pp.funBinderTypes true set-option pp.piBinderTypes true open BigOperators Real Nat Topology Rat {informal-comment} Prompt for Autoformalization (used by all baseline models excepts Herald) You are an expert in formal mathematics. Your task is to translate the given natural language mathematical statement into formal Lean 4 theorem. [Natural language statement]: {statement} Please convert this statement into precise formal Lean 4 theorem. Follow these guidelines: Start with \"theorem\" followed by unique name or the provided ID if avail1. able 2. Define the types of all variables (e.g., : for real numbers) 3. Use appropriate mathematical symbols and notation 4. End with \":= by sorry\" to indicate the proof will be completed later 5. Your formalization must exactly capture the mathematical meaning of the statement Formal Lean 4 theorem: Prompt for Mathesis-Prover Complete the following Lean 4 code: ```lean4 {formal statement} Prompt for LLM Semantic Check You will receive natural language math problem statement, along with its formal statement in LEAN 4 and, in some cases, description of mathematical terms. Please evaluate whether the formal LEAN statement appropriately translates the natural language statement based on the following criteria. They are considered different if any of the criteria are not satisfied. 1. Key Elements: The fundamental mathematical components, constants, operations, domain, and codomain are correctly represented in LEAN code. 2. Mathematical Accuracy: The mathematical relationships and expressions should be interpreted consistently during translation. 3. Structural Fidelity: The translation aligns closely with the original problem, maintaining its structure and purpose. 4. Comprehensiveness: All conditions, constraints, and objectives stated in the natural language statement are mathematically included in the LEAN translation. including variables, When doing evaluation, break down each problem statement into components, match the components, and evaluate their equivalence. Think step-by-step and explain all of your reasonings. Your answer should be in the following format: Thought: [Your Answer] Judgement: [Your Answer, one of Appropriate, Inappropriate] 19 Prompt for LeanScorer (Subtask Decomposition) Help me list the conditions and conclusions in this problem (using specific mathematical formulas), without solving it: Here is an example: [Problem]: The sequence {an} satisfies a1 = 1, a2 = 2, an+2 = 2an+1 an + 2. Let bn = an+1 an. Prove that {bn} is an arithmetic sequence. [Conditions and Conclusions]: Conditions: 1. a1 = 1 2. a2 = 2 3. 1, an+2 = 2an+1 an + 2 4. 1, bn = an+1 an Conclusion: - {bn} is an arithmetic sequence, i.e., R, 1, bn+1 bn = d. Now, please help me extract the conditions and conclusions for this problem in the same way (using specific mathematical formulas), without solving it: [Problem]: {informal statement} [Conditions and Conclusions]: Prompt for LeanScorer (LLM-based Evaluation) Here is math question and lean 4 statement. Compare the conditions and conclusions in this code with the mathematical ones, matching them one by one to see if the formal statement is an appropriate translation of the mathematical condition by assigning one of three tags (Perfectly match; Minor inconsistency; Major inconsistency). Then, audit for missing/implicit conditions. Judge with extremely strict standardsany minor inconsistency will be considered mismatch. Special attention to triangle angle-side correspondence. If the question explicitly mentions \"opposite angles/sides\", this correspondence must be clearly stated and correct. **Stop immediately** after evaluating all pairs. Do **not** summarize or analyze further. Output Format: {one-shot example} Question: {informal statement} Mathematical conditions and conclusions: {math conditions} Lean 4 formal statement: {formal statement} Output: 20 One-shot Example for LeanScorer (LLM-based Evaluation) Lets compare the mathematical conditions and conclusions with the Lean 4 formal statement one by one: 1. **q is natural number greater than 1**: - Math: N, > 1. - Lean: (hq : 1 < q). - Match: box{Perfectly match}. 2. **n is natural number greater than 1**: - Math: N, > 1. - Lean: (hn : 1 < n). - Match: box{Perfectly match}. 3. **Set = {0, 1, 2, , 1}**: - Math: is explicitly defined as this set. - Lean: (M : Finset := Finset.range q). - Detailed interpretation: Finset.range is 0, 1, ..., - 1. - Match: box{Perfectly match}. i=1 xiqi1, xi inM }. 4. **Set definition**: - Math: = {xx = (cid:80)n - Lean: : Set := {x (x_vec : N), ( i, x_vec M) = (cid:80) in Finset.range n, x_vec(i + 1) * ^i}. - Detailed interpretation: In Lean, x_vec is indexed from 1 to (since + 1 ranges from 1 to n), but the math defines xi for = 1, 2, , n. This is actually consistent, but the Lean representation is slightly more general (allowing x_vec to be function on all naturals, but only using x_vec (i + 1) for in Finset.range n). The Lean definition is technically correct but slightly more abstract than the math. However, it captures the same idea. - Match: box{Minor inconsistency}. i=1 aiqi1, = (cid:80)n i=1 biqi1, with ai, bi . 5. **s, with specific expansions**: - Math: = (cid:80)n - Lean: = (cid:80) in Finset.range n, (i + 1) * ^i, = (cid:80) in Finset.range n, (i + 1) * ^i, with i, M and i, M. - Detailed interpretation: The Lean version uses (i + 1) and (i + 1) to match the indexing in the sum, which is equivalent to the math but slightly indirect. The math directly uses ai for = 1, . . . , n, while Lean uses i for all but only evaluates at + 1. The Lean version is correct but not literal translation. - Match: box{Minor inconsistency}. 6. **an < bn**: - Math: an < bn. - Lean: (hab : < n). - Match: box{Perfectly match}. 7. **Conclusion < t**: - Math: < t. - Lean: <= t. - Match: box{Major inconsistency}. ### Check for missing conditions / implicit conditions: - No missing conditions / implicit conditions - Match: box{Perfectly match}."
        }
    ],
    "affiliations": [
        "Huawei Celia Team",
        "Huawei Noahs Ark Lab",
        "The Chinese University of Hong Kong"
    ]
}