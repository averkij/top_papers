{
    "paper_title": "Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery",
    "authors": [
        "Jiaqi Liu",
        "Songning Lai",
        "Pengze Li",
        "Di Yu",
        "Wenjie Zhou",
        "Yiyang Zhou",
        "Peng Xia",
        "Zijun Wang",
        "Xi Chen",
        "Shixiang Tang",
        "Lei Bai",
        "Wanli Ouyang",
        "Mingyu Ding",
        "Huaxiu Yao",
        "Aoran Wang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Automated discovery of physical laws from observational data in the real world is a grand challenge in AI. Current methods, relying on symbolic regression or LLMs, are limited to uni-modal data and overlook the rich, visual phenomenological representations of motion that are indispensable to physicists. This \"sensory deprivation\" severely weakens their ability to interpret the inherent spatio-temporal patterns within dynamic phenomena. To address this gap, we propose VIPER-R1, a multimodal model that performs Visual Induction for Physics-based Equation Reasoning to discover fundamental symbolic formulas. It integrates visual perception, trajectory data, and symbolic reasoning to emulate the scientific discovery process. The model is trained via a curriculum of Motion Structure Induction (MSI), using supervised fine-tuning to interpret kinematic phase portraits and to construct hypotheses guided by a Causal Chain of Thought (C-CoT), followed by Reward-Guided Symbolic Calibration (RGSC) to refine the formula structure with reinforcement learning. During inference, the trained VIPER-R1 acts as an agent: it first posits a high-confidence symbolic ansatz, then proactively invokes an external symbolic regression tool to perform Symbolic Residual Realignment (SR^2). This final step, analogous to a physicist's perturbation analysis, reconciles the theoretical model with empirical data. To support this research, we introduce PhysSymbol, a new 5,000-instance multimodal corpus. Experiments show that VIPER-R1 consistently outperforms state-of-the-art VLM baselines in accuracy and interpretability, enabling more precise discovery of physical laws. Project page: https://jiaaqiliu.github.io/VIPER-R1/"
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 2 ] . [ 1 0 8 3 7 1 . 8 0 5 2 : r MIMICKING THE PHYSICISTS EYE : VLM-CENTRIC APPROACH FOR PHYSICS FORMULA DISCOVERY Jiaqi Liu1,3 Songning Lai2 Pengze Li3,4 Di Yu3,5 Wenjie Zhou6,9 Yiyang Zhou1 Peng Xia1 Zijun Wang7 Xi Chen4 Shixiang Tang8 Lei Bai3 Wanli Ouyang3,8 Mingyu Ding1 Huaxiu Yao1 Aoran Wang3 1 UNCChapel Hill 2 HKUST (Guangzhou) 3 Shanghai Artificial Intelligence Laboratory 4 Fudan University 5 Tsinghua University 6 Nankai University 7 UC Santa Cruz 8 The Chinese University of Hong Kong 9 Shanghai Innovation Institute {jqliu@cs.unc.edu, wangaoran@pjlab.org.cn} Figure 1: Overview of VIPER-R1, multimodal framework for physics formula discovery. The model is trained via Motion Structure Induction (MSI) with Causal CoT supervision and RewardGuided Symbolic Calibration (RGSC) for structural refinement. During inference, VIPER-R1 acts agentically by invoking an external symbolic regression tool for Symbolic Residual Realignment (SR²), reconciling symbolic hypotheses with empirical data. The model achieves state-of-the-art performance in both structural and accuracy scores on the PhysSymbol dataset."
        },
        {
            "title": "ABSTRACT",
            "content": "Automated discovery of physical laws from observational data in the real world is grand challenge in AI. Current methods, relying on symbolic regression or LLMs, are limited to uni-modal data and overlook the rich, visual phenomenological representations of motion that are indispensable to physicists. This sensory deprivation severely weakens their ability to interpret the inherent spatiotemporal patterns within dynamic phenomena. To address this gap, we propose VIPER-R1, multimodal model that performs Visual Induction for Physicsbased Equation Reasoning to discover fundamental symbolic formulas. It methodically integrates visual perception, trajectory data, and symbolic reasoning to simulate the scientific discovery process. The model is trained via curriculum of Motion Structure Induction (MSI), using supervised fine-tuning to interpret kinematic phase portraits and construct hypotheses guided by Causal Chain of Thought (C-CoT), followed by Reward-Guided Symbolic Calibration (RGSC) to purify the formulas structure with reinforcement learning. During inference, the Corresponding author 1 trained VIPER-R1 acts as an agent: it first posits high-confidence symbolic ansatz, then proactively invokes an external symbolic regression tool to perform Symbolic Residual Realignment (SR²). This final step, analogous to physicists perturbation analysis, reconciles the theoretical model with empirical data. To support this research, we introduce PhysSymbol, new 5,000-instance multimodal corpus. Experiments show that VIPER-R1 consistently outperforms stateof-the-art VLM baselines in accuracy and interpretability, enabling more precise discovery of physical laws1."
        },
        {
            "title": "INTRODUCTION",
            "content": "The automated discovery of fundamental physical laws in the form of equations from observational data stands as grand challenge at the intersection of artificial intelligence and the natural sciences (Udrescu & Tegmark, 2020; Wang et al., 2023a). This endeavor is pivotal for augmenting human scientific intuition and accelerating the pace of discovery by uncovering novel principles within vast, high-dimensional datasets (Lu et al., 2024; Reddy & Shojaee, 2025). Recent advances have established two parallel yet distinct research tracks: sophisticated symbolic regression (SR) algorithms that navigate immense combinatorial spaces to identify fitting equations (La Cava et al., 2021; Cranmer, 2023), and the emergence of Large Language Models (LLMs) demonstrating remarkable ability to perform in-context symbolic reasoning from textual data (Ma et al., 2024a; Grayeli et al., 2024; Shojaee et al., 2025a). While both approaches have laid critical foundations, they share disconnect with the actual process of human scientific inquiry, operating without key perceptual faculty that is central to human discovery. This limitation can be seen as form of sensory deprivation, where reliance on uni-modal symbolic data blinds models to the rich visual representations that physicists routinely exploit. Human scientific reasoning is inherently multimodal: physicists interpret visual patterns in phase portraits to infer conservation laws, recognize decay envelopes to hypothesize damping forces, and identify superposition effects to constrain theoretical possibilities (Strogatz, 2001). Such visual intuition provides powerful pre-symbolic heuristics for navigating the vast space of candidate theories. Recent advances in LLM-based scientific discovery partly address these issues. LLM-SR (Shojaee et al., 2025a) generates equation hypotheses from embedded scientific knowledge, while frameworks like Scientific Generative Agents (Ma et al., 2024a) pair LLM-based generation with simulation validation. Yet these methods still suffer from sensory deprivation, lacking the ability to incorporate visual evidence. Furthermore, concerns about memorization versus genuine discovery (Wu et al., 2024; Shojaee et al., 2025b) underscore the need for approaches that perform authentic data-driven reasoning rather than recalling known formulas. By neglecting the crucial visual perceptual channel, existing methods are fundamentally constrained. They often resort to computationally expensive searches through vast equation spaces (Virgolin & Pissis, 2022), exhibit brittle token-matching behaviors, and fail to achieve the intuitive leaps that characterize human scientific breakthroughs. This limitation becomes particularly pronounced when dealing with complex dynamical systems where visual patterns in phase space and temporal evolution provide crucial insights that are difficult to extract from purely numerical data. To bridge the gap between raw perception and abstract formalism, we introduce VIPER-R1, Visual Induction model for Physics-based Equation Reasoning. Rather than mere pattern matcher, VIPER-R1 acts as computational phenomenologist, grounding symbolic reasoning in visual evidence by integrating plots, trajectory data, and symbolic logic to autonomously derive governing laws of motion. Our framework draws inspiration from human scientific reasoning and follows two-stage pipeline. In the first stage, Motion Structure Induction (MSI), the model undergoes Supervised FineTuning (SFT), learning to interpret kinematic evidence under joint supervision of Chain-of-Thought (CoT) rationales and ground-truth equations, before producing initial symbolic hypotheses guided by causal CoT prompts. In the second stage, Reward-Guided Symbolic Calibration (RGSC), reinforcement learning with Group Relative Policy Optimization (GRPO) (Shao et al., 2024) refines these hypotheses using structural reward function that favors topological correctness over 1Project in: https://jiaaqiliu.github.io/VIPER-R1/ 2 Figure 2: The performance of different SOTA VLMs on physics formula discovery tasks. coefficient matching. Finally, the model invokes an external symbolic regression tool for Symbolic Residual Realignment (SR²), aligning theoretical expressions with empirical details to yield interpretable, precise formulas. To support this research, we also release PhysSymbol, large-scale multimodal corpus of 5,000 instances designed for training and evaluating models on physics formula discovery. Our contributions can be summarized as follows: We propose VIPER-R1, multimodal framework that simulates the scientific reasoning process by deeply integrating visual perception with symbolic derivation. two-step training and inference strategy is designed, Motion Structure Induction (MSI) for hypothesis generation and Reward-Guided Symbolic Calibration (RGSC) for structural refinement. We introduce an agentic refinement stage, Symbolic Residual Realignment (SR²), where the VLM proactively utilizes external tools to harmonize its theoretical hypotheses with empirical data, aligning with modern agent-based AI paradigms. We introduce PhysSymbol, large-scale benchmark of 5,000 multimodal physics instances, created to advance research in vision-grounded scientific discovery."
        },
        {
            "title": "2 RELATED WORK",
            "content": "2.1 SYMBOLIC REGRESSION FOR SCIENTIFIC DISCOVERY Symbolic regression (SR) aims to discover mathematical expressions from data, field founded on techniques like genetic programming (Koza, 1994). Modern methods have significantly advanced this area, with physics-inspired recursive algorithms like AI Feynman (Udrescu & Tegmark, 2020) and high-performance evolutionary tools like PySR (Cranmer, 2023). Recent deep learning approaches leverage Transformer architectures to map numerical data directly to symbolic expressions (Biggio et al., 2021; Kamienny et al., 2022), while hybrid systems combine neural networks with methods like reinforcement learning (Petersen et al., 2019), Monte Carlo tree search (Sun et al., 2023), and guided genetic programming (Mundhenk et al., 2021; Meidani et al., 2023). Despite these advances, SR faces the persistent, NP-hard challenge (Virgolin & Pissis, 2022; Shojaee et al., 2025a) of navigating vast search space without strong priors, often leading to computationally expensive searches for physically implausible equations (Virgolin & Pissis, 2022). Our work confronts this 3 by using VLM to generate strong, visually-grounded prior, transforming SR from blind search into targeted refinement."
        },
        {
            "title": "2.2 LLMS FOR SCIENTIFIC DISCOVERY",
            "content": "The advent of LLMs has created transformative possibilities for automating science (Wang et al., 2023a; Lu et al., 2024). Several recent frameworks now leverage LLMs for equation discovery by generating equation skeletons (Shojaee et al., 2025a), using in-context learning (Merler et al., 2024), implementing bilevel optimization with simulators (Ma et al., 2024a), and building libraries of scientific concepts (Grayeli et al., 2024). key concern in this area is the models tendency to memorize formulas, an issue addressed by specialized benchmarks (Wu et al., 2024; Mirzadeh et al., 2024; Shojaee et al., 2025b). Concurrently, LLMs are being explored as powerful optimization and evolution engines (Lehman et al., 2023; Romera-Paredes et al., 2024; Lange et al., 2024b) for tasks such as prompt optimization (Guo et al., 2023; Lange et al., 2024a), neural architecture search (Chen et al., 2023; Zheng et al., 2023a), and heuristic discovery. While LLMs also demonstrate remarkable capabilities in general scientific hypothesis generation and reasoning (Zheng et al., 2023b; Qi et al., 2023; Wang et al., 2023b; Majumder et al., 2024a; Li et al., 2024; Wang et al., 2024; Ma et al., 2024b), their uni-modal nature renders them blind to the holistic visual patterns apparent to human scientists. Our work bridges this sensory gap. 2.3 MULTIMODAL MODELS FOR SCIENTIFIC DISCOVERY VLMs are increasingly being applied in scientific domains for their ability to reason about visual content (Zhang et al., 2024b; Su et al., 2025), from interpreting research figures (Lu et al., 2022; Zhang et al., 2024a) to general scientific understanding with models like GPT-4V (OpenAI, 2024), Qwen-VL (Bai et al., 2023), and Gemini (Google, 2025). Pioneering work has utilized Multimodal LLMs to discover governing equations from video data by first identifying intrinsic coordinates and then performing symbolic reasoning (Li et al., 2025). Our work addresses different and complementary aspect of the scientific workflow; we focus on the 2D graphical representations (e.g., phase plots) that scientists create for analysis. The VLMs role is not coordinate discovery but direct visual reasoning on these plots to hypothesize functional forms, mimicking physicist who recognizes patterns like damped oscillation and sketches initial formulas. While many scientific benchmarks exist (La Cava et al., 2021; Matsubara et al., 2022; Majumder et al., 2024b; Wang et al., 2025), they often face memorization issues with LLMs (Shojaee et al., 2025b). Our approach is the first to leverage fine-tuned VLM for direct, plot-based hypothesis generation in physics, more closely emulating the human observation-and-reasoning cycle."
        },
        {
            "title": "3 METHODOLOGY",
            "content": "Our proposed framework consists of two-stage pipeline, as illustrated in Figure 3. The first stage involves two-step Motion Structure Induction with CoT reasoning that activates the models reasoning potential and the ability of formula structure induction. At stage 2, RL-based refinement method is employed to help the model further calibrate the symbolic solution. When inferencing, symbolic regression module is design as optimal parameter searching tool to refine this hypothesis. 3.1 PROBLEM DEFINITION The automated discovery of physical laws from multimodal empirical data can be formally defined as learning mapping from set of observations to the underlying symbolic law that governs the system. This process seeks to infer an interpretable symbolic expression from diverse set of empirical evidence E. The mapping can be represented as: where: πθ : E, = {V, D} represents the complete set of Empirical Evidence, comprising both visual and numerical data modalities. 4 Figure 3: Framework of VIPER-R1. VIPER-R1 introduces two-phase training framework for visual formula discovery and reasoning. First, two-step curriculum, called Motion Structure Induction (MSI), is designed to imbue the VIPER-R1 with the ability to deduce the latent symbolic structure of systems dynamics at stage 1. Subsequently, in stage 2, we employ reinforcement learning to anneal the models generation policy, sharpening its focus on producing topologically correct physical laws. = {V1, V2, . . . } is set of visual representations of the systems dynamics. For instance, in the context of the kinematic systems studied in this work, typically includes phasespace portrait (Iphase) and time-series trajectory plot (Itrajectory). More broadly, could encompass video frames of real-world experiment, heatmaps of field distribution, or other scientific visualizations. = {D1, D2, . . . } is set of quantitative measurements of the systems state variables. For the mechanical systems we investigate, consists of time-series data of position, velocity, and acceleration, i.e., {(ti, x(ti), v(ti), a(ti))}. is the target output: an interpretable symbolic expression representing the governing physical law. πθ is the parameterized model (in our case, the VIPER-R1) that we aim to train. Through this mapping, our system integrates both visual information from dynamic plots and structured motion data to emulate the observation-and-reasoning workflow of physicists."
        },
        {
            "title": "3.2 MOTION STRUCTURE INDUCTION (MSI)",
            "content": "The foundational stage of our framework is Motion Structure Induction (MSI), specialized twostep curriculum designed to imbue the VIPER-R1 with the ability to deduce the latent symbolic structure of systems dynamics from its visual phenomenological representations. This process explicitly emulates the cognitive progression from qualitative observation to quantitative hypothesis. 3.2.1 STEP 1: JOINT INDUCTION OF CAUSAL REASONING AND SYMBOLIC STRUCTURE The initial stage mirrors physicists first encounter with new phenomenon: concurrently observing, reasoning, and formulating preliminary idea. Here, the VIPER-R1 is trained to jointly generate both Causal Chain of Thought (C-CoT) and an initial Symbolic Ansatz. The input is the complete set of Empirical Evidence = (V, D). The models objective is to maximize the likelihood of the entire structured output, which comprises the reasoning chain followed by the symbolic law S. This joint objective is crucial; it compels the VIPER-R1 to ground its symbolic output in an explicit, physically-motivated reasoning process. The model must learn not just what the governing law is, but why it takes that form, based on visual cues within the evidence. Formally, we define the training 5 objective for this stage by maximizing the log-probability of the target sequence = (C, S): LMSI-1 = E(E,Y )Dphys (cid:88) t=1 log πθ(yt E, y<t), (1) where is our PhysSymbol Corpus, = (y1, ..., yY ) is the concatenated sequence of the C-CoT and the symbolic law, and πθ is the policy of the VIPER-R1."
        },
        {
            "title": "3.2.2 STEP 2: C-COT-GUIDED SYMBOLIC FORMULATION",
            "content": "The second stage of our curriculum refines the VIPER-R1s ability to translate well-formed physical argument into precise symbolic form. This is analogous to physicist taking their detailed notes and meticulously composing the final equation. In this stage, the model is provided with both the empirical evidence and the ground-truth C-CoT, C, and is tasked only with generating the correct symbolic law S. By conditioning on an ideal reasoning chain, we allow the model to dedicate its full representational capacity to mastering the complex syntax and semantics of physical formalisms. This decouples the task of reasoning from the task of formulation. The loss is computed exclusively on the tokens of the symbolic law S: LMSI-2 = E(E,C,S)Dphys (cid:88) t=1 log πθ(st E, C, s<t). (2) The two-stage MSI curriculum is designed with two key considerations. First, by decoupling the complex cognitive task of causal reasoning from the intricate syntactic task of symbolic formulation, it enhances both the stability and the effectiveness of learning. Second, this curriculum reflects hierarchical abstraction process: it encourages the model to first construct high-level qualitative understanding through C-CoT, and only then proceed to generate low-level, precise symbolic outputthereby mirroring effective human problem-solving strategies. Upon completion of MSI, the resulting model, πVIPER, possesses robust, physically-grounded foundation, ready for the subsequent Reward-Guided Symbolic Calibration stage. 3.3 REWARD-GUIDED SYMBOLIC CALIBRATION (RGSC) Following the foundational MSI phase, the VIPER-R1 possesses the ability to generate plausible symbolic hypotheses. However, to further enhance the structural purity and reliability of these hypotheses, we introduce refinement phase: Reward-Guided Symbolic Calibration (RGSC). This stage employs reinforcement learning to anneal the models generation policy, sharpening its focus on producing topologically correct physical laws. We select the Group Relative Policy Optimization (GRPO) algorithm (Shao et al., 2024) for this task, as it is highly efficient for large-scale models and circumvents the need for separate, computationally expensive value network. GRPOs design, which computes advantages relative to batch of sampled actions, is exceptionally well-suited for our task where direct, analytical reward can be computed for any generated symbolic expression. Sampling Distribution of Symbolic Hypotheses. For each instance of Empirical Evidence = (V, D) from our PhysSymbol Corpus, we sample group of candidate symbolic expressions {S1, S2, . . . , SG} from the current policy πθ, which is initialized from the model fine-tuned during MSI. This sampling process is defined as: Si πθ(S E), for = 1, 2, . . . , G. (3) This strategy encourages exploration within the vast space of possible physical theories, allowing the model to discover and reinforce more robust and accurate symbolic structures. Formulating the Structural Reward. Each sampled ansatz Si is evaluated and assigned reward R(Si). Our reward function is designed to align with the central goal of discovering structurally correct physical laws, regardless of specific coefficient values. It consists of three weighted components: Format Reward (Rformat), our novel Parameter-Agnostic Structural Reward (Rstructural), and an Exact Match Accuracy Reward (Raccuracy). R(Si) = wf Rformat(Si) + wsRstructural(Si, SGT) + waRaccuracy(Si, SGT). (4) Format Reward (Rformat): This binary reward component ensures the models output adheres strictly to the predefined <think>...<answer> template, which is crucial for interpretability and reliable parsing. It awards 1 for correct formatting and 0 otherwise. Parameter-Agnostic Structural Reward (Rstructural): This is the core of our reward mechanism, evaluating the fundamental correctness of the generated laws structure. As detailed in Appendix B.3, it calculates the Jaccard similarity between the structural skeletons of the generated ansatz and the canonical equation. This metric rewards topological correctness over superficial coefficient matching, aligning the optimization objective with the VIPER-R1s primary role. Exact Match Accuracy Reward (Raccuracy): This component provides the strictest evaluation, awarding binary reward of 1 only if the generated formula Si is symbolically identical to the ground truth SGT. This encourages ultimate precision of the models output. Policy Update with Relative Advantage. The rewards {r1, r2, . . . , rG} for the group of sampled hypotheses are normalized to compute their relative advantages, preventing instability from highvariance rewards. The relative advantage Ai for each ansatz Si is defined as: Ai = ri mean(r1, . . . , rG) std(r1, . . . , rG) + ϵ . (5) The policy πθ is then updated to increase the likelihood of generating hypotheses with positive advantages. This process is further regularized by KullbackLeibler divergence penalty between the updated policy and the original reference policy from the MSI stage, ensuring stable learning and preventing the model from deviating too far from its physically-grounded foundation. 3.4 AGENTIC REFINEMENT VIA SYMBOLIC RESIDUAL REALIGNMENT (SR²) Upon completing its internal calibration, the VIPER-R1 has produced high-confidence Symbolic Ansatz, denoted as S0. This expression represents robust, first-order approximation of the systems dynamics. In the final stage of our framework, the VIPER-R1 transitions into an agentic role. It recognizes that while its ansatz predicts target variable ˆaVLM, discrepancy or residual field may exist between this theoretical model and the precise empirical evidence. To characterize and correct for this residual, the VIPER-R1 agentically invokes an external tool: high-performance symbolic regression engine (Cranmer, 2023). We term this sophisticated tool-use process Symbolic Residual Realignment (SR²). This technique mirrors physicist performing perturbation analysis to account for higher-order effects, thereby realigning their theory with empirical reality. The SR² Process. The core principle of SR² is to dramatically simplify the task for the symbolic regression tool. Instead of tasking it with searching the entire, near-infinite space of possible physical laws, we constrain its search to the much smaller, well-behaved space of the residual error. The process unfolds as follows: Step 1: Residual Field Calculation: The residual field, r(t), is computed as the difference between the ground-truth target values from the empirical data, aGT(t), and the prediction from the VIPER-R1s Symbolic Ansatz: r(t) = aGT(t) ˆaVLM(x, v, t). (6) Step 2: Symbolic Regression on the Residual: The SR engine is then deployed with the explicit goal of finding parsimonious and accurate symbolic expression, Sresidual, that best models the residual field r(t). This focused task allows the SR tool to operate with maximum efficiency. aresidual(x, v, t) SR(x, v, t, r(t)). (7) 7 Step 3: Theory Realignment: The final, empirically-realigned Law of Motion, Sfinal, is constructed by composing the VIPER-R1s initial ansatz with the discovered residual expression. This yields complete and highly accurate model of the systems dynamics. afinal(x, v, t) = ˆaVLM(x, v, t) + aresidual(x, v, t). (8) The whole process of SR² is summarized in Algorithm 2."
        },
        {
            "title": "4.1 EXPERIMENTAL SETUP",
            "content": "Dataset. To avoid data contamination, where models might have seen common benchmarks during pre-training, we adopt the strategy of constructing new synthetic dataset, as advocated in prior work such as LLM-SR (Shojaee et al., 2025a). All experiments are conducted on our purposebuilt PhysSymbol corpus, which contains 5,000 multimodal instances (a pair of kinematic plots and trajectory data files) each representing unique, complex physical system. Further details on data generation and statistics are provided in Appendix C. Models and Baselines. Our primary models, VIPER-R1-3B and VIPER-R1-7B, are based on the Qwen-VL-2.5 3B and 7B architectures, respectively. We compare against diverse set of state-ofthe-art MLMs, including GPT-5 (OpenAI, 2025a), GPT-5 mini (OpenAI, 2025a), GPT-4o mini (OpenAI, 2025b), GPT-4o (OpenAI, 2024), Grok 3 (xAI, 2025), GPT-o3 (OpenAI, 2025b), Claude-4 Sonnet (Anthropic, 2024), Claude-3.7 Sonnet (Anthropic, 2025), Qwen-VL-Max (Bai et al., 2023), Qwen-VL-2.5-72B-Instruct (Bai et al., 2025b), and Gemini 2.5 Pro (Google, 2025). Evaluation Metrics. We evaluate the models across several dimensions to capture different aspects of performance: Structural Score (Sstruct): This is our primary metric for the VLMs hypothesis generation capability. It is the parameter-agnostic Jaccard similarity between the terms of the generated formula and the canonical equation. score of 1.0 indicates perfect structural match. Accuracy Score (Sacc): stricter metric that measures the rate of exact symbolic matches between the generated formula and the canonical equation. Post-SR² MSE: The final Mean Squared Error of the complete, realigned formula after the SR² stage. This measures the end-to-end performance of the entire framework. lower value is better. Further experimental details, including model architectures, training procedures, and evaluation protocols, are provided in Appendix B. 4.2 MAIN RESULTS AND ANALYSIS To validate the effectiveness of our approach, we benchmarked VIPER-R1 against comprehensive suite of SOTA VLMs. The main results, as shown in Table 1, show that our framework outperforms other general-purpose VLMs. Superiority in Initial Hypothesis Generation. The first two metrics, Structural Score (Sstruct) and Accuracy Score (Sacc), evaluate the quality of the initial formula generated by the model before any symbolic refinement. Our specialized models demonstrate commanding lead in this crucial first step. Our VIPER-R1-7B achieves an Sstruct of 0.812, representing 56.7% relative improvement over the best-performing baseline, Claude-4-Sonnet. Similarly, its Sacc of 0.487 surpasses the top zero-shot model by over 45.4%. These results shows that while capable of broad multimodal tasks, they lack the specialized reasoning abilities required to interpret the nuanced patterns of physical phenomena. Our two-stage training curriculum successfully imbues the model with this domainspecific, physicist-like intuition. Excellence in Final Law Discovery. The ultimate goal is to find the most accurate physical law, performance captured by the final Post-SR² MSE. high-quality initial hypothesis from the VLM 8 Figure 4: Quantitative comparison of model performance on the PhysSymbol test set. We report three metrics: structural score , accuracy score, and post-symbolic-regression MSE. VIPER-R1 (ours) outperforms all VLM baselines across all metrics, demonstrating significant improvements in both symbolic structure induction and predictive accuracy. is critical, as it provides much better starting point for the symbolic regression tool to find the true global optimum. Our results confirm this synergy. The superior initial guesses from VIPER-R1 lead to significantly more accurate final discoveries. VIPER-R1-7B model achieves final MSE of only 0.032, an error rate nearly three times lower than the best baseline result of 0.091. It is noteworthy that even our smaller 3B model, with final MSE of 0.081, outperforms all other SOTA VLMs. Table 1: Main results comparing VIPER-R1 against SOTA VLMs on the PhysSymbol test set. Our method achieves the highest structural and accuracy scores, leading to the lowest final error. Category Method Structural Score (Sstruct) Accuracy Score (Sacc) Post-SR² MSE VLMs GPT-5 GPT-5-mini GPT-4o mini GPT-4o Grok 3 GPT-o3 Claude-4-Sonnet Claude-3.7-Sonnet Qwen-VL-Max Qwen-VL-2.5-72B-Instruct Gemini 2.5 Pro Ours VIPER-R1-3B VIPER-R1-7B"
        },
        {
            "title": "5 CONCLUSION",
            "content": "0.494 0.455 0.463 0.449 0.026 0.502 0.518 0.485 0.493 0.466 0.302 0.728 0.812 0.363 0.350 0.235 0.274 0.019 0.335 0.257 0.294 0.285 0.284 0.237 0.488 0.487 0.192 0.154 0.109 0.286 0.177 0.234 0.091 0.136 0.210 0.198 0.107 0.081 0. We introduced VIPER-R1, multimodal framework that grounds symbolic reasoning in visual perception, emulating the scientific workflow. Through Motion Structure Induction and Reward-Guided Symbolic Calibration, the model generates robust symbolic hypotheses, while Symbolic Residual Realignment enables agentic refinement via external tools. Experiments on the PhysSymbol benchmark show that our multi-stage approach outperforms state-of-the-art VLMs, and traditional methods. Future directions include scaling to larger datasets, including chaotic systems and partial differential equations (PDEs), and extending from simulated plots to real experimental videos."
        },
        {
            "title": "REFERENCES",
            "content": "Anthropic. Introducing claude 4. https://www.anthropic.com/news/claude-4, 2024. Anthropic. Claude 3.7 sonnet and claude code. https://www.anthropic.com/news/ claude-3-7-sonnet, 2025. Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. Qwen-VL: versatile vision-language model for understanding, localization, text reading, and beyond. arXiv preprint arXiv:2309.16609, 2023. Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, et al. Qwen2. 5-vl technical report. arXiv preprint arXiv:2502.13923, 2025a. Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, et al. Qwen2.5-VL technical report. arXiv preprint arXiv:2502.13923, 2025b. Luca Biggio, Tommaso Bendinelli, Alexander Neitz, Aurelien Lucchi, and Giambattista Parascandolo. Neural symbolic regression that scales. In International Conference on Machine Learning, pp. 936945. Pmlr, 2021. Angelica Chen, David Dohan, and David So. Evoprompting: Language models for code-level neural architecture search. volume 36, pp. 77877817, 2023. Miles Cranmer. Interpretable machine learning for science with pysr and symbolicregression.jl, May 2023. Google. Gemini 2.5: Our most intelligent ai model. https://blog.google/ technology/google-deepmind/gemini-model-thinking-updates-march2025/#gemini-2-5-thinking, 2025. Arya Grayeli, Atharva Sehgal, Omar Costilla Reyes, Miles Cranmer, and Swarat Chaudhuri. Symbolic regression with learned concept library. Advances in Neural Information Processing Systems, 37:4467844709, 2024. Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang. Connecting large language models with evolutionary algorithms yields powerful prompt optimizers. arXiv preprint arXiv:2309.08532, 2023. Huggingface. open-r1: Fully open reproduction of deepseek-r1. https://github.com/ huggingface/open-r1, 2025. [Online; accessed: 2025-01-24]. Pierre-Alexandre Kamienny, Stephane dAscoli, Guillaume Lample, and Francois Charton. End-toend symbolic regression with transformers. volume 35, pp. 1026910281, 2022. John Koza. Genetic programming as means for programming computers by natural selection. Statistics and computing, 4:87112, 1994. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with pagedattention. In ACM SIGOPS 29th Symposium on Operating Systems Principles, 2023. William La Cava, Patryk Orzechowski, Bogdan Burlacu, Fabrıcio Olivetti de Franca, Marco Virgolin, Ying Jin, Michael Kommenda, and Jason Moore. Contemporary symbolic regression methods and their relative performance. In Advances in Neural Information Processing Systems Datasets and Benchmarks Track, 2021. Robert Lange, Yingtao Tian, and Yujin Tang. Large language models as evolution strategies. In Proceedings of the Genetic and Evolutionary Computation Conference Companion, pp. 579582, 2024a. 10 Robert Tjarko Lange, Yingtao Tang, and Yujin Tian. Large language models as evolution strategies. In Genetic and Evolutionary Computation Conference, pp. 13321340, 2024b. Joel Lehman, Jonathan Gordon, Shawn Jain, Kamal Ndousse, Cathy Yeh, and Kenneth Stanley. Evolution through large models. In Handbook of evolutionary machine learning, pp. 331366. Springer, 2023. Michael Li, Emily Fox, and Noah Goodman. Automated statistical model discovery with language models. arXiv preprint arXiv:2402.17879, 2024. Ruikun Li, Yan Lu, Shixiang Tang, Biqing Qi, and Wanli Ouyang. Mllm-based discovery of intrinsic coordinates and governing equations from high-dimensional data, May 2025. Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. The AI scientist: Towards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292, 2024. Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via thought chains for science question answering. Advances in Neural Information Processing Systems, 35:25072521, December 2022. Pingchuan Ma, Tsun-Hsuan Wang, Minghao Guo, Zhiqing Sun, Joshua B. Tenenbaum, Daniela Rus, Chuang Gan, and Wojciech Matusik. LLM and simulation as bilevel optimizers: new paradigm to advance physical scientific discovery. In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp (eds.), Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pp. 3394033962, 2127 Jul 2024a. URL https: //proceedings.mlr.press/v235/ma24m.html. Pingchuan Ma, Tsun-Hsuan Wang, Minghao Guo, Zhiqing Sun, Joshua Tenenbaum, Daniela Rus, Chuang Gan, and Wojciech Matusik. Llm and simulation as bilevel optimizers: new paradigm to advance physical scientific discovery. arXiv preprint arXiv:2405.09783, 2024b. Bodhisattwa Prasad Majumder, Harshit Surana, Dhruv Agarwal, Sanchaita Hazra, Ashish Sabharwal, and Peter Clark. Data-driven discovery with large generative models. arXiv preprint arXiv:2402.13610, 2024a. Bodhisattwa Prasad Majumder, Harshit Surana, Dhruv Agarwal, Bhavana Dalvi Mishra, Abhijeetsingh Meena, Aryan Prakhar, Tirth Vora, Tushar Khot, Ashish Sabharwal, and Peter Clark. Discoverybench: Towards data-driven discovery with large language models. arXiv preprint arXiv:2407.01725, 2024b. Yoshitomo Matsubara, Naoya Chiba, Ryo Igarashi, and Yoshitaka Ushiku. Rethinking symbolic regression datasets and benchmarks for scientific discovery. arXiv preprint arXiv:2206.10540, 2022. Kazem Meidani, Parshin Agarwal, Mohammad Taha Bahadori, Jayant Liang, and Amir Barati Farimani. SNIP: Bridging mathematical symbolic and numeric realms with unified pre-training. In International Conference on Learning Representations, 2023. Matteo Merler, Mirko Nanni, and Fabrizio Silvestri. In-context symbolic regression: leveraging language models for function discovery. arXiv preprint arXiv:2404.19094, 2024. Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models. arXiv preprint arXiv:2410.05229, 2024. Nathan Mundhenk, Mikel Landajuela, Ruben Glatt, Claudio Santiago, Daniel Faissol, and Brenden Petersen. Symbolic regression via deep reinforcement learning enhanced genetic programming seeding. In Advances in Neural Information Processing Systems, pp. 2491224923, 2021. 11 OpenAI. Gpt-4o system card, 2024. URL https://arxiv.org/abs/2410.21276. OpenAI. 2025a. Introducing gpt-5. https://openai.com/index/introducing-gpt-5/, OpenAI. Introducing openai o3 and o4-mini. introducing-o3-and-o4-mini/, 2025b. https://openai.com/index/ Brenden Petersen, Mikel Landajuela, Nathan Mundhenk, Claudio Santiago, Soo Kim, and Joanne Kim. Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients. arXiv preprint arXiv:1912.04871, 2019. Biqing Qi, Kaiyan Zhang, Haoxiang Li, Kai Tian, Sihang Zeng, Zhang-Ren Chen, and Bowen Zhou. Large language models are zero shot hypothesis proposers. arXiv preprint arXiv:2311.05965, 2023. Chandan Reddy and Parshin Shojaee. Towards scientific discovery with generative ai: Progress, opportunities, and challenges. 39(27):2860128609, 2025. Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan Ellenberg, Pengming Wang, Omar Fawzi, et al. Mathematical discoveries from program search with large language models. volume 625, pp. 468475. Nature Publishing Group UK London, 2024. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024. Parshin Shojaee, Kazem Meidani, Shashank Gupta, Amir Barati Farimani, and Chandan K. Reddy. Llm-sr: Scientific equation discovery via programming with large language models, March 2025a. Parshin Shojaee, Ngoc-Hieu Nguyen, Kazem Meidani, Amir Barati Farimani, Khoa D. Doan, and Chandan K. Reddy. Llm-srbench: new benchmark for scientific equation discovery with large language models, June 2025b. Steven Strogatz. Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering (studies in nonlinearity). 1, 2001. Zhaochen Su, Peng Xia, Hangyu Guo, Zhenhua Liu, Yan Ma, Xiaoye Qu, Jiaqi Liu, Yanshu Li, Kaide Zeng, Zhengyuan Yang, et al. Thinking with images for multimodal reasoning: Foundations, methods, and future frontiers. arXiv preprint arXiv:2506.23918, 2025. Fangzhao Sun, Yang Liu, Jianxun Hao, and George Em Karniadakis. Symbolic physics learner: In International Conference on Discovering governing equations via monte carlo tree search. Learning Representations, 2023. Silviu-Marian Udrescu and Max Tegmark. Ai feynman: physics-inspired method for symbolic regression, April 2020. Marco Virgolin and Solon P. Pissis. Symbolic regression is NP-hard. Transactions on Machine Learning Research, 2022. Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, et al. Scientific discovery in the age of artificial intelligence. Nature, 620(7972):4760, 2023a. Lintao Wang, Encheng Su, Jiaqi Liu, Pengze Li, Peng Xia, Jiabei Xiao, Wenlong Zhang, Xinnan Dai, Xi Chen, Yuan Meng, et al. Physunibench: An undergraduate-level physics reasoning benchmark for multimodal models. arXiv preprint arXiv:2506.17667, 2025. Qingyun Wang, Doug Downey, Heng Ji, and Tom Hope. Scimon: Scientific inspiration machines optimized for novelty. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 279299, 2024. Ruocheng Wang, Eric Zelikman, Gabriel Poesia, Yewen Pu, Nick Haber, and Noah Goodman. Hypothesis search: Inductive reasoning with language models. arXiv preprint arXiv:2309.05660, 2023b. Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyurek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, and Yoon Kim. Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. Association for Computational Linguistics, 2024. xAI. Grok 3 beta the age of reasoning agents. https://x.ai/news/grok-3, 2025. Jingyi Zhang, Jiaxing Huang, Sheng Jin, and Shijian Lu. Vision-language models for vision tasks: survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024a. Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, and Jiawei Han. comprehensive survey of scientific large language models and their applications in scientific discovery. arXiv preprint arXiv:2406.10833, 2024b. Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen Qian, Chang Xu, and Samuel Albanie. Can gpt-4 perform neural architecture search? arXiv preprint arXiv:2304.10970, 2023a. Yizhen Zheng, Huan Yee Koh, Jiaxin Ju, Anh TN Nguyen, Lauren May, Geoffrey Webb, and Shirui Pan. Large language models for scientific synthesis, inference and explanation. arXiv preprint arXiv:2310.07984, 2023b."
        },
        {
            "title": "A APPENDIX",
            "content": "This supplementary material provides additional details on the proposed method and experimental results that could not be included in the main manuscript due to page limitations. Specifically, this appendix is organized as follows. Sec. outlines the models, training processes, and more evaluation details, providing more detailed experimental specifics. Sec. provides more details about PhysSymbol and discusses how we collected, filtered, and reconstructed high-quality dataset. Sec. includes more visualization cases."
        },
        {
            "title": "B DETAILS OF TRAINING AND EVALUATION",
            "content": "B.1 TRAINING SETTINGS We utilize Qwen2.5-VL-3B and Qwen2.5-VL-7B (Bai et al., 2025a) as the backbone models for our experiments. Our implementation is built on the open-source frameworks Open-R1 (Huggingface, 2025) and vLLM (Kwon et al., 2023), ensuring reproducibility and scalability. All experiments were conducted on cluster of servers, each equipped with 8A800 GPUs. During MSI(SFT) stage, we train model for 5 epoch at each step. At RL refinement stage, the model is trained for 2 epoch. B.2 SYSTEM PROMPTS The behavior and reasoning process of VIPER-R1 are carefully guided by series of structured system prompts tailored to each stage of our training and inference pipeline. These prompts define the models role as scientific assistant and establish the expected format for its reasoning and final output. This structured approach is crucial for decoupling complex tasks and progressively building the models capability for scientific discovery. Below, we detail the specific prompts used in each phase. B.2.1 PROMPT FOR MSI STEP 1 In the initial MSI step, as shown in Figure 5, the goal is to teach the model to perform end-to-end reasoning, connecting raw visual phenomena directly to final governing equation. The prompt instructs the model to act as scientific assistant, verbalize its step-by-step analysis, and provide conclusive answer in structured format. System Prompt You are helpful scientific assistant. Given trajectory images and motion data from physical system, reason step-by-step to explain the observed behavior, then output the governing equation. Wrap your reasoning process in <think> </think> and your final equation in <answer> </answer>. Figure 5: System prompt for the first SFT stage (MSI). B.2.2 PROMPT FOR MSI STEP 2 In the second step of MSI, as shown in Figure 6, we decouple the task: the model is provided with the pre-computed reasoning chain (C-CoT) and is tasked only with translating this analysis into precise symbolic equation. This prompt focuses the models training on the final, crucial step of symbolic formulation."
        },
        {
            "title": "System Prompt",
            "content": "You are helpful scientific assistant. Given the reasoning steps for physical system and its trajectory images, output the corresponding governing equation. The reasoning is provided in <think> </think> tags, and your answer should be placed in <answer> </answer> tags. Figure 6: System prompt for the second SFT stage (CoT-Aware). B.2.3 PROMPT FOR RGSC During the reinforcement learning phase, as shown in Figure 7, the prompt is refined to encourage more abstract and generalized symbolic reasoning. It explicitly asks the model to use symbolic placeholders for unknown parameters, which is essential for discovering general physical laws rather than fitting to specific numerical instances. This prompt guides the generation of hypotheses that are then evaluated by our reward function. System Prompt The user provides visual and trajectory data of physical phenomenon. The Assistants task is to act as physicist. First, think step-by-step about the underlying physical principles in <think> tags. Then, derive and state the final governing equation in <answer> tags. The equation should use symbolic placeholders for unknown parameters (e.g., k, c, F) and standard variables for the system (x, v, t). Figure 7: System prompt for the RGSC stage. B.3 DETAILED REWARD FUNCTION FORMULATION FOR RGSC The total reward signal R(Si) used during the Reward-Guided Symbolic Calibration (RGSC) stage is weighted sum of three distinct components. Each component is designed to evaluate specific aspect of the generated Symbolic Ansatz Si, allowing for balanced and effective policy optimization. The composite reward is defined as: R(Si) = wf Rformat(Si) + wsRstructural(Si, SGT) + waRaccuracy(Si, SGT), (9) where SGT is the Canonical Governing Equation, and wf , ws, wa are hyperparameters that weight the contribution of each reward component. Below, we detail the formulation of each component. Format Reward (Rformat). The primary purpose of this reward is to enforce consistent and parsable output structure, which is crucial for both interpretability and automated evaluation. We use regular expressions to verify that the models output strictly adheres to our predefined template, which requires reasoning process enclosed within <think>...</think> tags followed by final symbolic formula within <answer>...</answer> tags. This is binary reward: (cid:26)1 0 if format is correct otherwise Rformat(Si) = (10) Parameter-Agnostic Structural Reward (Rstructural). This is the most critical component for our It task, designed to assess the fundamental topological correctness of the posited physical law. rewards the model for identifying the correct basis functions and their relationships (e.g., x, v), irrespective of the specific values or symbols used for the coefficients (e.g., k, c). The calculation involves two steps: 1. Both the generated ansatz Si and the ground truth SGT are parsed into symbolic expressions. We then decompose each expression into set of constituent terms. For additive expressions, these are the terms separated by addition. For non-additive expressions, the term is the expression itself. 2. Each term is then normalized into structural skeleton by replacing all numerical coefficients and symbolic parameters with signed unit (i.e., +1 or 1), while preserving the core physical variables (x, v, t) and mathematical operators. The final reward is the Jaccard similarity between the set of skeletonized terms from the generated formula (Tgen) and the ground truth (TGT). This provides fine-grained score between 0 and 1. Rstructural(Si, SGT) = Tgen TGT Tgen TGT (11) Exact Match Accuracy Reward (Raccuracy). This component provides the strictest evaluation, rewarding the model only if its generated symbolic formula is mathematically identical to the ground truth. This encourages ultimate precision, especially for formulas where parameters are also represented symbolically (e.g., using instead of number). We leverage the sympy library to perform robust symbolic comparison. Both the generated answer and the ground truth are parsed into symbolic expressions, and we check if their simplified difference is zero. This is also binary reward: Raccuracy(Si, SGT) = (cid:26)1 0 if sympy.simplify(Si SGT) = 0 otherwise (12) By combining these three reward signals, we create rich and nuanced optimization landscape. The model is primarily guided by the structural reward (ws is typically the largest weight) to learn the correct physics, while also being encouraged to produce well-formatted and, when possible, exactly correct symbolic expressions. B.4 ALGORITHM PSEUDOCODE To provide comprehensive and reproducible overview of our methodology, we present the detailed pseudocode for our frameworks two primary components: the end-to-end training process and the inference-time refinement procedure. Algorithm 1 outlines the complete training framework for the VIPER-R1. This algorithm details the two primary phases through which the model is forged: first, the supervised Motion Structure Induction curriculum, which teaches the model to form hypotheses from visual data; and second, the subsequent reinforcement learning phase of Reward-Guided Symbolic Calibration, which purifies the models symbolic generation policy. Following this, Algorithm 2 describes the inference procedure. This algorithm formalizes the Agentic Refinement via Symbolic Residual Realignment process, wherein the fully trained VIPER-R1 generates an initial hypothesis and then proactively invokes an external symbolic regression tool to produce final, empirically-realigned physical law. B.5 EVALUATION METRICS To provide holistic assessment of our frameworks performance, we employ suite of distinct metrics, each designed to capture different facet of success, from high-level structural correctness to final empirical accuracy. Structural Score (Sstruct) This is our primary metric for evaluating the core capability of the VIPER-R1: its ability to generate topologically correct symbolic hypothesis. This score measures the structural similarity between the generated formula and the canonical equation, intentionally ignoring numerical coefficients to focus purely on the underlying physical structure. 16 Algorithm 1: VIPER-R1 Training Framework: MSI and RGSC Inputs : The PhysSymbol Corpus D, Initial model parameters θ0 from pre-trained VLM, Number of MSI steps NMSI-1, NMSI-2, Number of RGSC steps NRGSC, GRPO group size G, Reward weights wf , ws, wa Outputs: The final, calibrated VIPER-R1 policy πRGSC // Phase 1: Motion Structure Induction (MSI) 1 πθ InitializeModel(θ0); // Step 1.1: Joint Induction of C-CoT and Symbolic Structure 2 for = 1 to NMSI-1 do 3 Sample batch (E, ) D, where = (C, S); Update θ by descending the gradient of LMSI-1 w.r.t. Eq. equation 1; 4 5 end // Step 1.2: C-CoT-Guided Symbolic Formulation 6 for = 1 to NMSI-2 do 7 Sample batch (E, C, S) D; Update θ by descending the gradient of LMSI-2 w.r.t. Eq. equation 2; 8 9 end 10 πMSI πθ // Phase 2: Reward-Guided Symbolic Calibration (RGSC) 11 πθ πMSI; πref πMSI 12 for = 1 to NRGSC do 13 Sample batch of Empirical Evidence D; for = 1 to do 14 15 16 17 18 20 Sj πθ(S E); end for = 1 to do rj wf Rformat(Sj) + wsRstructural(Sj, SGT) + waRaccuracy(Sj, SGT); end Normalize(r1, . . . , rG); Update θ using advantages and KL penalty against πref; 21 22 end 23 πRGSC πθ; 24 return πRGSC; Accuracy Score (Sacc) To measure the exactness of the generated formulas, we use strict symbolic accuracy score. This metric evaluates whether the generated formula is mathematically identical to the canonical equation. It serves as challenging measure of the models ultimate precision. Post-SR² Mean Squared Error (MSE) This metric evaluates the end-to-end performance of the entire VIPER-R1 framework by measuring how well the final, refined formula fits the observed data. It quantifies the empirical accuracy after the SR² stage has been completed. Calculation: Let Sfinal be the final symbolic law produced by our framework. This expression is converted into callable function afinal(x, v, t). The MSE is then computed over the data points in the test sets trajectory data: MSE = 1 (cid:88) i=1 (aGT(ti) afinal(xi, vi, ti))2 , (13) where aGT(ti) is the ground-truth acceleration at time ti. lower MSE indicates better fit to the observed physical reality and thus more successful discovery. 17 Algorithm 2: Agentic Refinement via Symbolic Residual Realignment (SR²) Inputs : Trained VIPER-R1 policy πVIPER-R1, Empirical Evidence = (I, D), Symbolic Regression engine SR Outputs: The final, realigned Law of Motion Sfinal // Stage 1: VLM Hypothesis Generation 1 S0 GenerateAnsatz(πVIPER-R1, E); 2 aVLM CompileFunction(S0) // Stage 2: Residual Field Calculation 3 aGT(x, v, t) ExtractData(E.D) aGT ˆaVLM(x, v, t) // Stage 3: Tool-Using for Residual Modeling 4 Sresidual SR(inputs = (x, v, t), target = r) // Stage 4: Theory Realignment 5 Sfinal S0 + Sresidual 6 return Sfinal; B.6 ABLATION STUDIES To dissect and quantify the contribution of each core component of our framework, we conducted series of ablation studies on both the 3B and 7B model sizes. We systematically evaluate the performance of: (i) the base Qwen-VL-2.5 model, (ii) the model after only the SFT-based Motion Structure Induction stage, and (iii) our full model, which includes the subsequent RL-based RewardGuided Symbolic Calibration stage. The results are presented in Table 2. The results in Table 2 reveal several findings. First, applying MSI alone yields substantial performance boost over the base modelimproving structural scores by over 40 points, which confirms that our two-stage SFT process effectively grounds symbolic reasoning in visual perception and physical intuition. Second, the addition of RGSC further elevates performance across both metrics. For instance, the 7B models structural score improves from 0.554 (MSI-only) to 0.812 after applying RGSC, and its accuracy score increases from 0.399 to 0.487. Similar trends are observed in the 3B model. These improvements highlight the importance of RL-based symbolic calibration: by optimizing outputs through reward-guided refinement, the model learns to produce more structurally sound and numerically accurate symbolic expressions. Table 2: Ablation study on the contribution of MSI and RGSC stages for both 3B and 7B models. Each stage provides significant performance boost. Model Size Model Version Structural Score (Sstruct) Accuracy Score (Sacc) 7B 3B Qwen-VL-2.5 (Base) + MSI (SFT only) + MSI + RGSC (Ours) Qwen-VL-2.5 (Base) + MSI (SFT only) + MSI + RGSC (Ours) 0.096 0.554 0.812 0.043 0.474 0. 0.179 0.399 0.487 0.100 0.350 0.488 PHYSSYMBOL: COMPREHENSIVE MULTIMODAL DATASET FOR"
        },
        {
            "title": "PHYSICS FORMULA DISCOVERY",
            "content": "C.1 DATASET OVERVIEW AND MOTIVATION To train and evaluate our proposed VIPER-R1 framework, we constructed PhysSymbol, largescale synthetic multimodal dataset that systematically emulates the analytical workflow of physicists studying complex dynamical systems. The dataset addresses critical gap in existing benchmarks 18 Figure 8: (a) Ablation results show that integrating symbolic regression (+SR²) and our full VIPERR1 pipeline progressively improves structural and accuracy scores. (b) VIPER-R1 achieves significant relative improvements over zero-shot VLM baselines across all evaluation metrics. by providing paired visual-symbolic representations that capture the phenomenological patterns essential for scientific reasoning. PhysSymbol comprises 5,000 instances, each containing complete multimodal representation of physical system: (1) dual trajectory visualizations (phase-space and temporal plots), (2) highresolution numerical trajectory data, (3) ground-truth governing equations, and (4) expert-level causal reasoning annotations. This comprehensive design enables our framework to learn the crucial mapping from visual observations to symbolic mathematical expressions that characterizes human scientific discovery. C.2 PHYSICS TERM LIBRARY AND FORMULA GENERATION The foundation of PhysSymbol lies in carefully designed physics term library that encompasses the fundamental mechanisms commonly encountered in classical mechanics and nonlinear dynamics. Our term library includes 11 distinct categories of physical phenomena: Linear and Nonlinear Restoring Forces: Linear elasticity: kx with [0.1, 10] Cubic nonlinearity: βx3 with β [0.01, 5] Quintic nonlinearity: δx5 with δ [0.001, 1] Velocity-Dependent Damping: Linear damping: cv with [0.01, 2] Cubic velocity damping: αv3 with α [0.01, 5] Quintic velocity damping: ηv5 with η [0.001, 1] External and Coupling Forces: Temporal periodic forcing: sin(ωt) with [0.1, 5], ω [0.5, 5] Spatial periodic forcing: sin(ωx) with parameters in similar ranges Position-velocity coupling: γxv with γ [0.01, 5] Specialized Nonlinear Terms: Trigonometric nonlinearity: cos(x), sin(x) (parameter-free) Stochastic perturbations: σN (0, 1) with σ [0.01, 0.5] 19 The formula generation process employs structured combinatorial approach. Each governing equation is constructed by sampling 2-5 terms from the library, with mandatory linear restoring force to ensure physical stability. Parameters are sampled uniformly from their respective ranges, and the resulting symbolic expression is converted into an executable function for numerical integration. C.3 HIGH-FIDELITY TRAJECTORY SIMULATION For each generated governing equation of the form = (x, x, t), we perform highintegration using the adaptive Runge-Kutta method implemented in resolution numerical scipy.integrate.solve ivp. The simulation protocol follows these specifications: Temporal Parameters: Integration duration: = 20 time units Sampling resolution: = 1000 uniformly spaced points Time step: = 0.02 (adaptive refinement as needed) Initial Conditions: Initial position x0 and velocity v0 are independently sampled from uniform distributions over [1, 1] to ensure diversity in trajectory patterns while maintaining numerical stability. Data Output: Each simulation yields trajectory dataset {(ti, xi, vi, ai)}N i=1 containing temporal evolution of position, velocity, and acceleration. This data is exported as CSV files with full numerical precision for downstream analysis. C.4 DUAL VISUALIZATION STRATEGY key innovation of PhysSymbol is its systematic generation of complementary visualizations that capture different aspects of system dynamics, mirroring the analytical tools used by practicing physicists: Phase-Space Portraits (v vs x): These plots encode the kinematic structure and stability properties of the dynamical system. Phase portraits reveal crucial qualitative features such as: Closed orbits indicating conservative dynamics Spiral trajectories suggesting damped oscillations Multiple attractors or limit cycles in nonlinear systems Geometric signatures of different restoring force types Temporal Trajectories (x vs t): These plots emphasize the time-domain behavior and temporal patterns: Oscillation frequencies and amplitude modulation Exponential growth or decay envelopes Periodic forcing signatures and resonance effects Transient dynamics and approach to steady states Both visualizations are rendered as high-resolution PNG images (300 DPI) with consistent styling, axis labeling, and grid structures to ensure visual uniformity across the dataset. C.5 EXPERT-LEVEL REASONING ANNOTATION key challenge in automated scientific discovery lies in bridging the gap between raw visual observation and symbolic reasoning. To address this, the PhysSymbol corpus incorporates detailed Causal Chain-of-Thought (C-CoT) annotations, designed to emulate the step-by-step reasoning of human physicist. These annotations are generated through carefully engineered prompting strategy with GPT-4o, implemented in physics cot generator.py, ensuring both consistency and expert-level interpretability. For each physical system, the annotation protocol provides GPT-4o with both trajectory visualizations and the ground-truth governing equation, along with structured prompt that explicitly requests analysis of visual-symbolic correspondences. This setup enables the model to reason not only about the equation itself, but also about how its individual terms manifest within the observed dynamical patterns. The resulting C-CoT traces follow systematic analytical framework. They begin with visual pattern recognition, identifying salient geometric and temporal features in the trajectory and phasespace plots. This is followed by physical interpretation, where observed patterns are linked to underlying mechanisms such as oscillations, damping, or nonlinear effects. The annotations then provide term-by-term analysis, explaining how each component of the governing equation contributes to specific visual signatures. Building on this, they articulate hypothesis formation step, reasoning about which terms could be posited from visual evidence alone. Finally, the traces include layer of validation logic, explicitly connecting the proposed symbolic structure back to empirical observations for plausibility checking. By design, these annotations capture expert-level reasoning that mirrors how human physicists transition from qualitative observation to quantitative formulation. They not only provide supervision for training multimodal models, but also serve as valuable benchmark for evaluating whether models can perform reasoning that is genuinely interpretable and scientifically grounded. C.6 DATASET ASSEMBLY AND MULTI-FORMAT GENERATION The final dataset assembly process, implemented in build dataset json.py, integrates all components into unified multimodal format suitable for different training stages: Data Instance Structure: Each complete instance follows the tuple format: (Images: Iphase, Itrajectory, Trajectory Data: M, Ground-Truth Formula: E, C-CoT Reasoning: C) Multi-Stage Training Variants: To support our three-stage training pipeline, the assembly process generates three dataset variants: 1. Stage 1 (MSI-Joint): Full format requiring both reasoning generation and formula prediction 2. Stage 2 (MSI-Guided): C-CoT provided as input, only formula prediction required 3. Stage 3 (RGSC): Streamlined format for reinforcement learning with structural rewards Data Preprocessing: To ensure computational efficiency, trajectory data is intelligently subsampled to 100 uniformly spaced points while preserving essential dynamical characteristics. This balances information retention with processing speed during training. C.7 DATASET STATISTICS AND QUALITY ASSURANCE The PhysSymbol corpus consists of 5,000 complete multimodal instances, each pairing symbolic formulas with corresponding trajectory data and kinematic plots. The formulas exhibit controlled complexity, ranging from two to five terms with an average of 3.2 terms per equation. To ensure comprehensive coverage, parameters for all term types are fully sampled within their defined ranges. On the visual side, the dataset encompasses diverse set of phase portrait topologies, capturing wide variety of dynamical behaviors. To guarantee reliability and usability, we apply series of quality control measures. Each generated equation undergoes numerical stability verification to avoid degenerate or divergent solutions. Representative samples are visually inspected to confirm the clarity and readability of the plots. The accompanying Causal Chain-of-Thought (C-CoT) rationales are validated through automated keyword analysis to ensure coherence with the underlying formulas. Finally, file integrity checks are conducted across all multimodal components, ensuring that the dataset is complete, consistent, and ready for large-scale experimentation."
        },
        {
            "title": "D CASE ANALYSIS",
            "content": "In this section, we present detailed qualitative results for several challenging physical systems to provide more intuitive understanding of the VIPER-R1 frameworks capabilities. We first provide an in-depth analysis of complex non-linear system (Case 1) and then present the visual results for three additional, distinct cases. D.1 IN-DEPTH ANALYSIS: NON-LINEAR DAMPING WITH STOCHASTIC NOISE To showcase our methods full capabilities, we first examine complex system governed by linear restoring force, non-linear damping term, and stochastic noise. The canonical governing equation is of the form a(t) = kx cv3 + η(t), where η(t) represents random noise component. This type of system is particularly challenging as it requires identifying and integrating components with fundamentally different mathematical and physical characteristics. As illustrated in Figure 9, our VIPER-R1 leverages its C-CoT process to perform sophisticated, physicist-like workflow. It correctly identifies distinct visual cues from the provided plots and maps each one to its underlying physical term. Figure 9: Case 1 Reasoning Process: The VIPER-R1 infers the governing equation of non-linear dynamical system. Given the x(t) and v(x) plots, the model performs structured visual reasoning to identify key dynamics, including the linear restoring force, non-linear damping, and stochastic noise, before outputting an interpretable symbolic equation. The models internal reasoning, extracted from its output, is as follows: <think> To analyze the given dynamical system, we consider both the x(t) plot and the v(x) phase-space plot. Key visual features: Oscillatory Behavior in x(t): Suggests linear restoring force (k x). 22 Distorted, Spiraling Attractor in v(x): Indicates non-linear damping term, likely dependent on higher power of velocity (c v3). Irregular, High-Frequency Fluctuations in x(t): Points to stochastic noise term. Conclusion: The system likely combines linear restoring force, non-linear damping (v3), and stochastic noise. </think> This detailed analysis leads the model to propose hypothesis that is not only structurally correct but also quantitatively close to the true solution, providing an excellent starting point for the subsequent SR² stage. The quantitative success of this process is detailed in Figure 10 and Figure 11, which show the improvements at both the signal and system levels. Figure 10: Case 1 Acceleration Signal Evaluation: Comparison of the predicted acceleration signals before (VLM-only) and after (VLM + SR²) symbolic refinement. The refined result demonstrates significantly improved alignment with the ground truth, as shown by the reduced residuals and errors. 23 Figure 11: Case 1 System-Level Trajectory Comparison: The phase-space, position, velocity, and energy trajectories generated by the final (VLM + SR²) model show much closer adherence to the ground truth dynamics compared to the raw VLM predictions, indicating physically consistent longterm behavior. 24 D.2 ADDITIONAL QUALITATIVE RESULTS To further demonstrate the robustness of our framework, we present the results for three additional cases, each representing different class of physical system. Figure 12: Case 2 Reasoning: system with linear restoring forces. Figure 13: Case 2 Acceleration Signal Evaluation. 25 Figure 14: Case 2 System-Level Trajectory Comparison. 26 Figure 15: Case 3 Reasoning: system with sinusoidal driving forces. Figure 16: Case 3 Acceleration Signal Evaluation. 27 Figure 17: Case 3 System-Level Trajectory Comparison. 28 Figure 18: Case 4 Reasoning: system with external periodic forcing. Figure 19: Case 4 Acceleration Signal Evaluation. Figure 20: Case 4 System-Level Trajectory Comparison."
        }
    ],
    "affiliations": [
        "Fudan University",
        "HKUST (Guangzhou)",
        "Nankai University",
        "Shanghai Artificial Intelligence Laboratory",
        "Shanghai Innovation Institute",
        "The Chinese University of Hong Kong",
        "Tsinghua University",
        "UC Santa Cruz",
        "UNC Chapel Hill"
    ]
}