{
    "paper_title": "AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages",
    "authors": [
        "Shamsuddeen Hassan Muhammad",
        "Idris Abdulmumin",
        "Abinew Ali Ayele",
        "David Ifeoluwa Adelani",
        "Ibrahim Said Ahmad",
        "Saminu Mohammad Aliyu",
        "Nelson Odhiambo Onyango",
        "Lilian D. A. Wanzare",
        "Samuel Rutunda",
        "Lukman Jibril Aliyu",
        "Esubalew Alemneh",
        "Oumaima Hourrane",
        "Hagos Tesfahun Gebremichael",
        "Elyas Abdi Ismail",
        "Meriem Beloucif",
        "Ebrahim Chekol Jibril",
        "Andiswa Bukula",
        "Rooweither Mabuya",
        "Salomey Osei",
        "Abigail Oppong",
        "Tadesse Destaw Belay",
        "Tadesse Kebede Guge",
        "Tesfa Tegegne Asfaw",
        "Chiamaka Ijeoma Chukwuneke",
        "Paul Röttger",
        "Seid Muhie Yimam",
        "Nedjma Ousidhoum"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Hate speech and abusive language are global phenomena that need socio-cultural background knowledge to be understood, identified, and moderated. However, in many regions of the Global South, there have been several documented occurrences of (1) absence of moderation and (2) censorship due to the reliance on keyword spotting out of context. Further, high-profile individuals have frequently been at the center of the moderation process, while large and targeted hate speech campaigns against minorities have been overlooked. These limitations are mainly due to the lack of high-quality data in the local languages and the failure to include local communities in the collection, annotation, and moderation processes. To address this issue, we present AfriHate: a multilingual collection of hate speech and abusive language datasets in 15 African languages. Each instance in AfriHate is annotated by native speakers familiar with the local culture. We report the challenges related to the construction of the datasets and present various classification baseline results with and without using LLMs. The datasets, individual annotations, and hate speech and offensive language lexicons are available on https://github.com/AfriHate/AfriHate"
        },
        {
            "title": "Start",
            "content": "AfriHate: Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages Shamsuddeen Hassan Muhammad1,2*, Idris Abdulmumin3, Abinew Ali Ayele4,21, David Ifeoluwa Adelani5, Ibrahim Said Ahmad2,6, Saminu Mohammad Aliyu2, Nelson Odhiambo Onyango7, Lilian D. A. Wanzare7, Samuel Rutunda8, Lukman Jibril Aliyu9, Esubalew Alemneh10, Oumaima Hourrane11, Hagos Tesfahun Gebremichael4, Elyas Abdi Ismail10, Meriem Beloucif12, Ebrahim Chekol Jibril13, Andiswa Bukula14, Rooweither Mabuya14, Salomey Osei15, Abigail Oppong16, Tadesse Destaw Belay17,23, Tadesse Kebede Guge18, Tesfa Tegegne Asfaw4, Chiamaka Ijeoma Chukwuneke19, Paul Röttger20, Seid Muhie Yimam21, Nedjma Ousidhoum22 1Imperial College London, 2Bayero University Kano, 3DSFSI, University of Pretoria, 4Bahir Dar University, 5Mila, McGill University & Canada CIFAR AI Chair, 6Northeastern University, 7Maseno University, 8Digital Umuganda, 9HausaNLP, 10Haramaya University, 11Al Akhawayn University, 12Uppsala University, 13Istanbul Technical University, 14SADiLaR, 15University of Deusto, 16Independent Researcher, 17Instituto Politécnico Nacional, 18Addis Ababa University, 19Lancaster University, 20Bocconi University, 21University of Hamburg, 22Cardiff University, 23Wollo University Contact: s.muhammad@imperial.ac.uk, seid.muhie.yimam@uni-hamburg.de"
        },
        {
            "title": "Abstract",
            "content": "Hate speech and abusive language are global phenomena that need socio-cultural background knowledge to be understood, identified, and moderated. However, in many regions of the Global South, there have been several documented occurrences of (1) absence of moderation and (2) censorship due to the reliance on keyword spotting out of context. Further, highprofile individuals have frequently been at the center of the moderation process, while large and targeted hate speech campaigns against minorities have been overlooked. These limitations are mainly due to the lack of high-quality data in the local languages and the failure to include local communities in the collection, annotation, and moderation processes. To address this issue, we present AfriHate: multilingual collection of hate speech and abusive language datasets in 15 African languages. Each instance in AfriHate is annotated by native speakers familiar with the local culture. We report the challenges related to the construction of the datasets various classification baseline results with and without using LLMs.1 Content Warning: This paper contains representative examples of hate speech and offensive language."
        },
        {
            "title": "Introduction",
            "content": "No one is born hating another person because of the color of his skin, or his *Equal contribution 1The datasets, individual annotations, and hate speech and offensive language lexicons are available on https:// github.com/AfriHate/AfriHate background, or his religion. People must learn to hate, and if they can learn to hate, they can be taught to love, for love comes more naturally to the human heart than its opposite. (Mandela, 1994) Hate speech and abusive language are global phenomena that highly depend on specific sociocultural contexts. Although hate speech and abusive language deviate from the norm on social media, they quickly attract significant attention, spread among online communities (Mathew et al., 2019), and incite harm or violence on individuals in real life (Saha et al., 2019). Tangible efforts to address these problems must take social and cultural contexts into account (Shahid and Vashistha, 2023). However, in the absence of high-quality data or when excluding local voices from the collection and annotation processes, one may fail to build assistive tools that help address the problem and moderate such content. Collecting hate speech and offensive language datasets is complex and time-consuming as researchers typically rely on keywords, hashtags, or user accounts to build datasets (Ousidhoum et al., 2020). They may need further insights from both moderators (Arora et al., 2023) and affected communities (Maronikolakis et al., 2022). Further, resources in languages other than English are scarce, especially for low-resource languages. To bridge the current gap in the area, we present AFRIHATE collection of new hate speech and abusive language datasets in 15 languages spo5 2 0 2 4 1 ] . [ 1 4 8 2 8 0 . 1 0 5 2 : r Table 1: Examples of hateful and abusive instances in AfriHate. All hateful posts are assigned targets. ken in various African regions: Algerian Arabic, Amharic, Igbo, Kinyarwanda, Hausa, Moroccan Arabic, Nigerian Pidgin, Oromo, Somali, Swahili, Tigrinya, Twi, isiXhosa, Yorùbá, and isiZulu. The datasets are annotated by native speakers and include three classes: hate, abusive/offensive, or neutralneither hateful nor abusive. The targets of the hateful tweets were further labeled based on six common attributes used to discriminate against people: ethnicity, politics, gender, disability, religion, or other. Table 1 shows sample of the datasets in various languages. We report the data collection and annotation strategies and challenges when building AfriHate, present various classification baselines with and without using LLMs, and discuss the results. We find that the performance highly depends on the language and that multilingual models can help us boost the performance in low-resource settings. We publicly release the datasets, and individual labels, in addition to manually curated hate speech and offensive language lexicons. These provide valuable foundation for the research community interested in hate speech and abusive language, African languages, and researchers interested in studying disagreements."
        },
        {
            "title": "2 Related Work",
            "content": "The fast-spreading nature of hate speech and abusive language have been at the center of significant amount of NLP work in recent years (Talat and Hovy, 2016; Vigna et al., 2017; Basile et al., 2019; Mansur et al., 2023). However, as there is no unanimous definition of hate speech, researchers in the area have adopted different ones when building resources. For instance, some studies define hate speech as any speech that can cause danger or harm to disadvantaged groups (Davidson et al., 2017), others focus on whether the speech is intended to promote hatred (Gitari et al., 2015), or whether it dehumanises protected groups (Vidgen et al., 2021), which leads to various challenges such as the lack of generalisability (Yin and Zubiaga, 2021). Despite Africa being home to more than 2,000 languages and the increasing interest in building hate speech and offensive languages resources for non-English languages (Ousidhoum et al., 2019; Madeddu et al., 2023; Röttger et al., 2022), few datasets focus on African languages, such as Amharic (Ayele et al., 2024, 2022), Afaan Oromo (Ababu and Woldeyohannis, 2022), Yorùbá (Ilevbare et al., 2024), Hausa (Vargas et al., 2024; Adam et al., 2023), and Nigerian Pidgin (Ndabula et al., 2023; Ilevbare et al., 2024; Aliyu et al., 2022; Tonneau et al., 2024). Moreover, most resources adopt binary labeling scheme (hate/offensive) and do not include normal class (e.g., (Aliyu et al., 2022)), or do not add the target attributes (e.g., (Ilevbare et al., 2024)). Other work (Tonneau"
        },
        {
            "title": "Script",
            "content": "Algerian Arabic/Darja Amharic Hausa Igbo Kinyarwanda Moroccan Arabic/Darija Nigerian Pidgin Oromo Somali Swahili Tigrinya Twi Xhosa Yorùbá Zulu arq North Africa amh East Africa hau West Africa ibo West Africa kin East Africa ary North Africa pcm West Africa orm East Africa som East Africa swa East Africa tir East Africa twi West Africa tso yor West Africa zul"
        },
        {
            "title": "Southern Afric",
            "content": "Arabic Algeria Ethiopic Ethiopia, Eritrea Latin Northern Nigeria, Niger, Ghana, and Cameroon, Latin Southeastern Nigeria Latin Rwanda Arabic/Latin Morocco Latin Nigeria, Ghana, Cameroon, Latin Ethiopia, Kenya, Somalia Somalia, Ethiopia, Djibouti, Kenya Latin Kenya, Tanzania, Uganda, DR Congo, Rwanda, Burundi, Mozambique Latin Ethiopia, Eritrea Ghana"
        },
        {
            "title": "Ethiopic\nLatin\nLatin\nLatin\nLatin",
            "content": "Southern Africa Mozambique, South Africa, Zimbabwe, Eswatini Southwestern and Central Nigeria, Benin, and Togo Southern Africa Table 2: Information about the AfriHate languages: their ISO codes, subregions, countries in which they are mainly spoken, and the writing scripts included in AfriHate. et al., 2024) relies on active learning for annotating some data instances, which is not ideal when labeling hate speech for under-resourced African languages or when focusing on underrepresented cultures (Lee et al., 2023, 2024). Similarly, limited number of studies involve African communities in the dataset creation process (Adelani et al., 2021; Maronikolakis et al., 2022; Abdulmumin et al., 2024). We take step forward in addressing this problem by developing 15 new datasets for hate and offensive speech in various languages spoken across the African continent."
        },
        {
            "title": "3 Creating AfriHate",
            "content": "AfriHate covers 15 languages from various African regions. In Table 2, we report the scripts of these languages and the main regions where they are spoken. The collection includes tweets from 2012 to 2023 collected using the Academic API before the suspension of free academic access. The API allowed us to collect up to 10 million tweets per month, and Twitter/X is commonly used platform in African countries with documented cases of hate speech propagation (Adjai and Lazaridis, 2013; Egbunike et al., 2015; Oriola and Kotzé, 2020; Ridwanullah et al., 2024; Raborife et al., 2024)."
        },
        {
            "title": "3.1 Data Collection",
            "content": "Except for Amharic and Tigrinya, the Twitter API does not support African languages, which makes the data collection challenging. We, therefore, follow strategies adopted by previous work such as Muhammad et al. (2022, 2023) and use various heuristics based on hate speech and abusive language keywords, user handles, stopwords, hashtags, and locations. Table 3 shows the number of keywords used for data collection in each language. Since interpreting hate and abusive content heavily depends on understanding political and socio-cultural contexts, we have adopted languagedependent collection and annotation strategies. As previous work relied on specific keywords to collect data (e.g., Talat and Hovy, 2016; Basile et al., 2019), we follow similar strategy by using larger set of keywords. Similarly to Ousidhoum et al. (2019), our keywords include culturespecific controversial topics and are of various sizes (see Table 3). However, for some languages such as Nigerian-Pidgin and Hausa, an initial preannotation phase revealed limited number of hateful tweets. We therefore used additional strategies to collect more tweets: 1) keyword crowdsourcing, 2) manual data collection, and 3) using existing datasets, as we explain in the following. Crowdsourcing Keywords To crowdsource additional keywords, we first asked native speakers to provide us with list of hateful, abusive, or controversial keywords. To further diversify our lists, we contacted social media influencers, who asked their followers to share abusive or hateful keywords in their local languages by filling in form created for anonymous collection. This strategy resulted in broader vocabulary as the followers come from various backgrounds. Moreover, we used off-the-shelf curated hate speech lexicons amh arq ary"
        },
        {
            "title": "Hate\nAbusive",
            "content": "88 74 62 40 41 0 hau 36 149 ibo 46 118 kin 264 362 oro 126 159 pcm som swa tir twi 23 26 45 24 12 58 66 20 86 xho 42 177 yor 68 109 zul 31 118 Table 3: Number of keywords used for data collection. For Algerian Arabic (arq), the collection includes controversial topics that are neither hateful nor offensive. from the PeaceTech Lab2 and the Hatebase.3 The lists were post-processed by native speakers prior to the collection of the tweets. Manual Data Collection For Kinyarwanda and Twi, native speakers manually collected all the tweets using combination of keywords and user handles. We curated list of user handles of public figures who frequently post hateful or abusive content, and collected tweets from their profiles. Using Existing Datasets For Nigerian Pidgin, we used an additional existing hate speech dataset from Tonneau et al. (2024). Since some instances in this dataset were annotated using active learning, we re-annotated those labeled as hateful or offensive only. Similarly, for Swahili, we selected instances from the sentiment analysis dataset by Muhammad et al. (2023)4, the misinformation dataset by Amol et al. (2023), and the hate speech one by Ombui et al. (2019). These instances were re-annotated into our predefine classes (hate, offensive and normal). We further labeled the targets of the tweets based on our pre-defined target attributes, i.e., disability, ethnicity, gender, politics, religion, and others."
        },
        {
            "title": "3.2 Data Processing",
            "content": "We further cleaned the collected tweets and removed retweets, tweets containing less than three invisible characters, words, duplicates, URLs, and redundant white spaces. We converted the tweets written in Latin script to lowercase and anonymized the tweets by replacing @mentions with placeholder @user."
        },
        {
            "title": "3.3 Language Identification",
            "content": "We collected the tweets using location and keywords. This is particularly challenging for African languages since people within one location can speak different languages. That is, keywords and 2https://www.peacetechlab.org/ the-peacetech-toolbox 3https://hatebase.org 4We selected only negative instances, as they may contain hateful or abusive content. hashtags may appear in more than one language, which makes the data selection more difficults Although ptudies have use (Muhammad et al., 2022, 2023) open-source and closed-source language identification (LID) tools, these often show low accuracy in African languages, especially when used in social media posts. This is largely due to the unique linguistic characteristics of these languages, such as the common usage of codemixing and digraphia, i.e., language can be written in more than one script. To address these limitations, we built LID model that improves identification performance for social media text data in our target languages through continued pretraining of AfroXLMR model (Alabi et al., 2022) on Glot500-c corpus which covers 511 predominantly low-resource languages (Imani et al., 2023). We further finetuned the model on AfriSenti-LID dataset, which focuses on social media data and covers most of the languages included in AfriHate and similar Twitter-sphere. Our LID tool and its documentation can be found on our project page."
        },
        {
            "title": "3.4.1 Pre-Annotation and Data Selection\nWe randomly sampled tweets in each language\nand conducted a pilot annotation, which showed\na large class imbalance despite collecting tweets\nusing abusive and hateful keywords. For instance,\nmost tweets in Hausa were neutral (neither hateful\nnor abusive) due to keywords carrying multiple\nmeanings depending on the region where the word\nis used, i.e., it can have a neutral connotation in\nsome parts of Nigeria. For example, the word\nAboki means “friend” in Northern Nigeria, while it\ncan be an insult in the Southern part of the country.\nAs this would have led to an insufficient number of\ninstances in each target class, we included a pre-\nannotation phase to ensure each class covered a\nreasonable percentage of the data.",
            "content": "During the pre-annotation, we provided the annotators with distinct pool of tweets and asked 5https://github.com/hausanlp/AfriLID"
        },
        {
            "title": "Language",
            "content": "Manually Collected Pre-Annotation"
        },
        {
            "title": "Total Annotators\nAnnotators per Instance",
            "content": "amh arq ary hau ibo kin oro pcm som swa tir twi xho yor zul 11 4 7 3 3 3 3 3 6 3 3 3 9 4 3 3 7 4 5 3 8 4 3 3 3 3 4 4 3 3 Free-Marginal Multirater Kappa 0.63 0. 0.61 0.75 0.80 0.81 0.63 0. 0.46 0.55 0.46 0.75 0.62 0. 0.81 Table 4: Collection and annotation details for the AfriHate dataset. The table shows if the data was manually collected, whether pre-annotation step was conducted, the total number of annotators, the number of annotators per instance, and the inter-annotator agreement (Free-Marginal Multirater Kappa)."
        },
        {
            "title": "Hate\nAbusive\nNeutral",
            "content": "amh ary arq hau ibo kin oro pcm som swa tir twi xho yor zul 2,246 1,353 1,359 162 778 310 674 2,270 1, 343 2,336 3,965 251 3,510 1,242 1,268 1,146 2,308 2,293 667 2,072 1,177 5,238 4,184 388 1,404 2, 3,974 7,708 9,410 2,940 1,070 1,062 443 3,278 180 210 1,550 1,923 150 2,655 2,074 147 1,839 2, Table 5: Number of instances per class in each dataset. them to select those likely to be hateful or abusive. We then aggregated the pre-selected tweets, and multiple annotators labeled them. Table 4 indicates the languages for which we conducted pre-annotation step, i.e., only those for which we observed significantly high imbalance during the pilot annotation."
        },
        {
            "title": "3.4.2 Recruiting Annotators",
            "content": "The unavailability of annotators for African languages on common platforms like Amazon Mechanical Turk and Prolific makes traditional crowdsourcing methods impractical. As Kirk et al. (2023) demonstrated that trained annotators achieve higher quality results, we trained native speakers and recruited them as annotators. For each language, we also recruited native speaker as language lead who would control for the quality of the annotations. We used Label Studio as an annotation platform6 and an adapted version of the Potato annotation tool7."
        },
        {
            "title": "3.4.3 Annotation Task",
            "content": "Labels We provided the annotators with thorough guidelines (see Figure 1 in the Appendix). We asked the annotators to choose one of three categories: Hate, Abusive/Offensive, or Neutral. The latter means that the tweet is neither hateful nor abusive. Tweets spotted in language different from the target one were labeled Indeterminate and were later excluded from the final dataset. Similarly to Ayele et al. (2024); Ousidhoum et al. (2019); Fortuna et al. (2019), annotators had to 6https://labelstud.io/ 7https://github.com/davidjurgens/potato select the target(s) of the hateful tweets. That is, the common attribute(s) based on which the tweet is discriminating against people: Ethnicity, Politics, Gender, Disability, Religion, or Other. We do not include targets offensive and abusive tweets as these can often be generic and directed towards an individual as previously reported by Zampieri et al. (2019) (e.g., see the Algerian Arabic example in Table 1). Details about the targets can be found in Figure 1 in the Appendix. For some languages such as Hausa, we asked the annotators to spot which words made them label the tweet hateful or abusive. Final label selection As shown in Table 4, for languages where we conducted pre-annotation step, each tweet was annotated by 3 annotators, leading to total of 4 labels per tweet with the pre-annotation label counting as one. On the other hand, for instances in datasets for which we did not carry pre-annotation step, 3 to 4 annotators were assigned to each tweet, and the final gold label was determined by majority voting, i.e., two out of three labels or three out of four labels. Table 5 and Table 6 show the final number of instances per class and the target distributions for all the languages. Inter-Annotator Agreement"
        },
        {
            "title": "3.4.4\nTo assess the inter-annotator agreement (IAA), we\ncomputed the free marginal Randolph’s Kappa\nscore (Randolph, 2005) for each of the datasets.\nWe chose this metric as it is suitable for tasks in-\nvolving multiple annotators.",
            "content": "Table 4 shows the IAA scores for all the datasets, the total number of annotators in each, and the"
        },
        {
            "title": "Hate Target",
            "content": "amh"
        },
        {
            "title": "Disability\nEthnicity\nGender\nPolitics\nReligion\nOthers",
            "content": "0 902 15 1,247 130 199 arq 0 269 2 118 6 0 ary 26 150 6 63 207 0 hau 0 32 2 0 38 0 ibo 0 383 3 6 0 0 kin oro 6 94 24 1,096 10 0 462 12 1,550 31 767 pcm 1 537 50 87 105 15 som 0 74 17 703 19 208 swa tir 112 2,799 117 233 336 501 0 573 0 2,251 16 85 twi 32 245 12 32 14 14 xho 3 94 111 0 0 0 yor 2 103 13 33 22 76 zul 0 241 0 0 0 12 Table 6: Data distribution of hate speech targets in AfriHate."
        },
        {
            "title": "Split",
            "content": "amh ary arq hau ibo kin oro pcm som swa tir twi xho yor zul Train 3,467 Dev 744 Test 747 3,240 695 699 716 211 4,566 1,029 1,049 3,419 774 821 3,302 706 714 3,517 763 759 7,416 1,590 1,593 3,174 741 14,760 3,164 3,168 3,547 760 765 2,564 639 698 2,502 559 622 3,336 724 819 2,940 640 Table 7: Number of instances included in the training (train), development (dev), and test splits of the different datasets. number of annotators per instance. The IAA scores range from 0.46 to 0.81, indicating medium to high agreement levels. The highest agreement scores are reported for kin, and twi, which can be due to the manual collection of only potentially abusive and hateful tweets. For other languages such as hau and zul, the high agreement can be attributed to the pre-annotation step, which helped us filter tweets that were later annotated"
        },
        {
            "title": "3.5 Dataset Statistics",
            "content": "As shown in Table 5, most datasets are imbalanced, and the hate class includes fewer instances in 9 out of 15 languages. The variations in the class distributions are due to the differences between the languages and the data collection techniques. Further, the target distributions also differ because of socio-cultural characteristics related to local politics, social dynamics, and an unavoidable degree of selection bias (Ousidhoum et al., 2020). Data Splits We split the AfriHate datasets based on the various label distributions. As reported in Table Table 7, each test set includes minimum of 100 instances in each class (i.e., hate, abusive, and normal). This guarantees more robust evaluation of the different models."
        },
        {
            "title": "4.1 Setup",
            "content": "We compare the performance of three main sets of approaches on the AfriHate datasets: 1. Fine-tuning BERT-based pre-trained language model (PLM), 2. Few-shot learning with SetFit with BERTbased PLM (Tunstall et al., 2022): few-shot approach using BERT-like PLMs, 3. Prompting large language models (LLMs) in zero and few-shot settings."
        },
        {
            "title": "4.1.1 Fine-tuning PLMs",
            "content": "We use four widely adopted Africa-centric PLMs that have been shown to consistently perform better than massively multilingual PLMs such as XLM-R (Conneau et al., 2020). The models are AfriBERTa-large (Ogueji et al., 2021), AfriTeVa V2 base (Oladipo et al., 2023), AfroXLMR (Alabi et al., 2022) and AfroXLMR-76L (Adelani et al., 2024). Each model was trained for 20 epochs over 5 runs with batch size of 32, maximum sequence length of 128, and learning rate of 5e 5 except for AfroXLMR-76L where we used learning rate of 3e 5. The rest of the hyperparameters were the default values set in the HuggingFace fine-tuning pipeline for text classification."
        },
        {
            "title": "4.1.2 SetFit Few-shot Learning",
            "content": "SetFit is few-shot learning approach based on sentence-transformer models like LabSE (Feng et al., 2022). It works by, first, fine-tuning pretrained sentence transformer model on few examples in contrastive manner. Then, the resulting model is used to generate rich text embeddings, which are used to train classification head. We used LaBSE to train classifiers with the following configurations: 1. for zero-shot learning, we trained the transformers for one epoch using the dummy dataset generated by the framework (2 [This sentence is {Label}, ...]), where {Label} can be Neutral, Abusive or Hate; 2. for few-shot learning, we trained each model"
        },
        {
            "title": "Model",
            "content": "amh ary arq hau ibo kin oro pcm som swa tir twi xho yor zul avg."
        },
        {
            "title": "Monolingual",
            "content": "AfriBERTa 69.54 AfriTeVa V2 73.91 AfroXLMR 70.65 AfroXLMR-76L 74.36 67.93 76.71 80.16 80.05 30.48 25.25 61.18 53.52 82.28 79.06 81.93 82.78 89.53 83.95 89.30 89.59 79.43 77.60 80.72 79. 73.43 71.61 72.11 76.63 66.90 68.69 67.98 68.38 65.52 69.65 66.84 71.09 91.36 90.68 91.44 91.72 73.07 72.36 74.52 76.27 74.54 64.96 77.17 76. 81.07 54.67 82.49 84.40 72.37 79.88 72.15 72.35 83.75 69.05 83.44 84.65 72.33 68.73 76.15 76."
        },
        {
            "title": "Multilingual",
            "content": "AfroXLMR-76L 75.25 80.76 63.31 82.20 89.85 79. 77.62 69.20 72.26 91.22 77.55 78. 86.83 74.32 86.81 78.16 Table 8: Model performances after fine-tuning BERT-based LMs. The best performance for each language is highlighted in bold. for three epochs using 5, 10, and 20 shots. All the classifiers were trained using batch size of 32."
        },
        {
            "title": "4.1.3 Prompting LLMs",
            "content": "We prompt one closed model (GPT-4o) and nine open models of various model sizes (0.4B to 70B). The open models are: InkubaLM-0.4B (Tonja et al., 2024), mT0-small (Muennighoff et al., 2023), BLOOMZ 7B (Scao et al., 2022), Mistral 7B (Jiang et al., 2023), Aya-23-35B (Aryabumi et al., 2024), LLaMa 3.1 {8B & 70B} (Dubey et al., 2024), and Gemma 2 {9B & 27B} (Team et al., 2024). All the models were prompted using five prompt templates with clear definitions of the Abusive, Hate, and Neutral categories. For hate speech, we used the definition adopted by the United Nations and another one from the Merriam Websters dictionary. We report the average scores across all the templates in the results Section. The full prompts can be found in Appendix A.1."
        },
        {
            "title": "4.2.1 Monolingual vs. Multilingual",
            "content": "Fine-tuning We compare monolingual fine-tuning where we train on language and evaluate on the same language to multilingual fine-tuningwhere we combine the training data of all the languages and evaluate the results for each. Table 8 shows the results of the fine-tuning experiments. We find that encoder-only models perform better than the T5-style models, i.e., AfriTeVa V2. On average, AfroXLMR-76L achieved the best performance, most likely due to the fact that it was pre-trained on all the languages included in AfriHate. While AfroXLMR was not pre-trained on some languages such as Tigrinya (tir) and Twi (twi), it still achieves performance that is comparable to AfroXLMR-76L. AfriBERTa generally struggles with Arabic dialects such as Algerian Darja (arq) and Moroccan Darija (ary) as the Arabic script was not included in its pre-training. Overall, multilingual training of single model leads to the best results on 11 out of 14 languages, and comparable results on the remaining languages except for Yorùbá (yor), where AfriBERTa led to the best result because of its Africa-centric tokenizer. Table 9 shows the per-class accuracy across different languages. Overall, multilingual models perform better for languages with low percentage of the hate category in the training data (e.g., < 200) such as ary, xho, yor, and zul with an F-score improvement of +1.7, +5.7, +4.9, and +10.8, respectively."
        },
        {
            "title": "4.2.2 Zero-shot vs. Few-shot Settings",
            "content": "Table 10 shows the results of both zero-shot and few-shot experiments. SetFit performs slightly better than all open LLMs in zero-shot settings (36.9), and GPT-4o leads to the best overall performance with 61.9 F1 points. When considering the few-shot settings, 5-shot models show the biggest boost in performance, where Gemma 2 9B and other bigger models (Gemma 2 27B and LLaMa 3.1 70B) improve by about +20 points. The performance boost with additional 10 and 20 shots is more limited for LLMs (+3.0 improvement), whereas SetFit consistently benefits from additional examples. The best results reached for closed models are at 20-shots, where GPT-4o achieved an overall F1-score of 70.8 while Gemma 2 27B achieved the best overall results for any open model with an F1-score of 57.2. In our performance analysis per different classes shown in Table 9, GPT-4o generally performs worse than full fine-tuning in monolingual or multilingual settings. However, we find that it achieves significantly better performance for hate detection in few languages such as arq (+44.0), som (+14.9), and yor (+46.1) compared to monolinLang. amh ary arq hau ibo kin orm pcm som swa tir twi xho yor zul Monolingual AfroXLMR-76L Multilingual AfroXLMR-76L GPT-4o Macro F1 Abuse Hate Neutral Macro F1 Abuse Hate Neutral Macro F1 Abuse Hate Neutral 73.83 78.01 57.05 81.53 88.00 77.96 70.07 65.40 59.53 88.00 72.32 58.30 79.37 57.36 80. 70.20 86.81 77.35 77.60 92.18 70.09 47.19 71.09 67.00 92.18 72.29 91.45 86.33 84.24 87.54 77.27 66.98 27.42 80.45 91.18 80.87 81.17 52.82 30.77 91.18 82.60 61.40 66.23 6.90 68.79 74.02 80.25 66.38 86.54 80.64 82.90 81.86 72.31 80.83 80.64 62.07 22.05 85.53 80.95 86.57 75.55 79.05 68.99 78.05 88.33 77.11 69.93 63.71 60.91 89.50 74.45 63.66 81.57 59.41 84.34 71.92 86.59 78.29 76.45 92.41 70.00 48.89 69.66 68.81 89.35 75.23 91.04 85.14 84.03 85.46 78.18 68.66 55.95 72.83 91.18 78.90 80.11 49.10 32.94 88.33 84.97 60.18 71.95 11.76 79. 76.54 81.91 72.73 84.88 81.40 82.43 80.78 72.39 81.00 90.83 63.16 39.76 87.63 82.44 88.01 65.70 75.93 73.67 59.44 76.85 74.27 65.30 63.53 62.94 83.29 56.23 62.64 57.74 71.48 70.63 59.21 84.29 77.63 70.61 84.13 65.45 44.12 57.38 63.85 85.48 51.73 85.90 70.82 81.56 74.60 67.91 61.09 71.43 40.77 75.37 82.01 72.78 56.67 44.91 80.49 64.38 54.45 38.46 53.01 67.78 70.00 82.43 71.96 66.95 71.04 75.37 79.00 76.54 80.05 83.91 52.59 47.58 63.94 79.88 69.51 Table 9: Macro F1 scores per class for monolingual and multilingual AfroXLMR-76L [only one run] vs. GPT-4o [prompt template 1; 20 shots]. The best performance for each language is highlighted in bold."
        },
        {
            "title": "SetFit",
            "content": "Mistral-7B-v0.1 aya-23-35B Gemma-2-9B Gemma-2-27B Llama-3.1-70B GPT-4o Lang. avg. 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 0 5 10 20 0 5 10 20 - # Shots amh ary arq hau ibo kin oro pcm som swa tir twi xho yor zul 33.79 44.89 49.42 50.13 21.18 37.68 39.68 36.64 17.04 37.78 38.50 38.10 27.42 56.60 57.84 60.96 41.78 59.62 60.70 62. 36.34 58.52 61.18 60.38 61.78 66.73 67.94 68.08 46.54 33.82 35.81 40.49 17.46 31.60 36.50 35.46 19.20 56.40 53.96 52.90 28.36 57.68 61.08 59. 41.24 64.14 61.36 59.86 43.34 66.24 64.46 61.36 66.41 73.53 75.54 76.16 27.4 36.07 46.55 54.24 11.98 44.54 50.56 52.94 17.20 57.00 61.82 63. 25.46 61.14 61.72 64.38 41.12 65.62 64.88 65.80 42.64 62.88 62.20 63.80 73.75 77.33 77.54 78.69 23.57 49.93 49.72 55.40 6.84 34.90 37.82 38. 20.34 39.70 44.42 46.14 14.48 49.98 56.62 55.90 28.96 54.62 58.90 59.60 35.64 52.86 56.40 57.40 56.91 55.44 58.15 58.34 36.90 51.52 39.31 65. 8.04 36.84 36.94 38.98 14.04 42.70 45.80 46.52 15.00 48.12 53.78 54.56 31.36 56.14 56.84 58.76 32.52 52.88 55.10 53.80 68.82 76.73 80.08 80. 25.29 55.35 53.10 57.35 15.18 46.98 45.72 52.28 21.34 48.78 52.82 57.62 24.08 60.26 63.54 64.14 42.08 61.08 64.86 66.06 38.52 58.14 59.00 62. 62.53 72.27 75.07 74.86 26.26 36.56 39.10 40.91 20.82 39.46 39.02 39.24 20.38 39.24 42.16 42.26 23.74 45.10 45.78 44.70 33.46 46.76 46.96 48. 31.54 45.50 46.60 49.02 60.01 70.94 72.27 72.33 43.46 53.28 57.00 59.09 6.76 50.00 52.10 54.60 20.02 57.90 59.26 61.68 24.74 60.30 60.54 62. 49.78 61.78 61.60 63.24 48.66 64.38 63.58 63.18 65.94 66.29 67.14 65.41 32.18 48.09 42.29 48.95 8.16 34.12 31.82 33.28 18.56 38.72 37.60 38. 10.92 46.42 51.72 52.22 31.10 54.12 52.86 52.90 31.14 52.72 54.40 51.82 63.42 59.33 62.75 66.44 44.38 54.90 62.64 74.93 18.88 58.58 63.18 66. 34.04 69.84 74.10 75.68 37.12 74.78 78.16 79.24 59.88 81.18 81.94 82.98 60.14 75.76 78.74 80.02 73.66 80.95 84.19 84.61 49.30 35.36 39.16 40. 25.62 35.64 35.84 37.42 17.10 35.68 35.88 38.12 25.52 48.40 45.48 44.94 30.84 52.12 49.82 53.36 27.08 44.42 49.62 53.90 45.75 61.11 57.52 59. 51.13 33.23 45.76 53.72 8.38 32.04 30.82 30.44 10.68 40.24 39.92 38.54 19.50 46.50 48.16 48.92 27.74 47.26 50.86 50.34 25.54 43.90 45.76 47. 52.72 73.21 72.28 75.86 37.38 47.49 43.52 46.92 9.72 34.24 32.64 34.12 20.32 36.76 36.18 37.74 13.40 35.82 38.82 39.02 25.64 40.48 41.90 43. 28.98 39.02 39.04 40.34 58.92 60.45 65.75 66.08 48.46 34.36 49.73 56.54 8.22 41.04 42.90 46.40 17.48 48.88 48.44 51.52 21.66 55.96 60.22 60. 41.46 61.72 59.66 59.10 40.64 58.08 57.96 57.94 75.21 76.98 76.74 77.11 35.08 33.18 40.33 50.67 8.92 32.54 32.46 35.00 20.24 44.58 45.00 44. 12.52 46.60 52.58 53.68 28.02 54.28 56.94 56.88 35.50 55.24 55.74 56.36 54.47 59.34 65.05 71.36 Avg. 37.41 43.20 46.23 52. 13.08 39.35 40.53 42.10 19.20 46.28 47.72 48.92 21.59 52.91 55.74 56.38 36.96 57.39 58.01 58.88 37.21 55.37 56.65 57.29 62.69 68.71 70.53 71. 48.32 50.74 54.04 44.91 47.79 52. 43.18 54.44 43.10 67.53 41.95 42. 39.06 51.25 44.18 48.39 Table 10: Model performance (Macro F1-score) for zeroand-few shot classifiers across the different languages in AfriHate. The best performance for each language is highlighted in bold. This is an average over 5 prompt templates. gual fine-tuning. For languages without enough training data for the hate category such as Yorùbá, prompting LLMs might provide better detection of this class compared to fine-tuning BERT-like PLMs."
        },
        {
            "title": "4.2.3 Overall Results",
            "content": "Overall, our results show that fine-tuning multilingual models leads to better performance for the majority of the AfriHate languages. That is, AfroXLMR-76L achieves an average macro F1 score of 78.16. As for zero-shot and few-shot settings, GPT-4o outperformed other models, with average F1 scores of 61.89 and 70.79 in zero-shot and 20-shot settings, respectively. Overall, these results highlight the advantages of multilingual and context-specific models in hate and abusive language detection for African languages."
        },
        {
            "title": "5 Conclusion",
            "content": "We introduced AfriHate, the first large-scale collection of hate and abusive language datasets in 15 African languages: Algerian Arabic, Amharic, Igbo, Kinyarwanda, Hausa, Moroccan Arabic, Nigerian Pidgin, Oromo, Somali, Swahili, Tigrinya, Twi, Xhoza, Yorùbá, and Zulu. The datasets were annotated by native speakers as hate speech, abusive, or neutral. We discussed our data collection strategies and highlighted the challenges faced during the data collection and annotation. We then reported baseline experiments using Africacentric pre-trained language models as well as prompted open and closed LLMs showing large gap in the performance across languages. AfriHate is first step towards building highquality hate speech resources for African languages. We publicly release all the datasets, scripts, models, and lexicons to the research community."
        },
        {
            "title": "6 Limitations",
            "content": "While we collected AfriHate using large sets of keywords, we acknowledge the unavoidable presence of selection bias (Ousidhoum et al., 2020) as no dataset can capture the full range of hate speech contexts across various languages and cultures. In addition, although we recruited annotators who come from different socio-cultural backgrounds, hate speech remains subjective task and one cannot include all possible perspectives of what constitutes hate speech or abuse. We mitigate the problem by sharing the individual annotations with the research community studying the problem. Further, when using language identification to collect data, challenges due to code-mixing and digraphia, make the task non-trivial given the common usage of multilinguality in African languages. We address the problem by asking the annotators to flag any tweet that is not in the target language. We acknowledge, nevertheless, instances that may have been missed by our annotators. Finally, we report on the various dataset statistics and model features. However, given the fact that we use some closed models in our experiments, and the class imbalance problem which is inherent to hate speech datasets, we do not claim that our results are fully replicable or generalisable."
        },
        {
            "title": "7 Ethical Considerations",
            "content": "Annotators The annotators involved in this study were compensated for their work by more than the minimum wage and any demographic information about them was shared with consent. We acknowledge the difficulty of annotating hate speech and abusive language on peoples wellbeing. Therefore, the annotators could reach out to us and were allowed to quit at any time. Language Use Our datasets focus on hate speech and abusive languages in 15 African languages. However, we do not claim that our datasets represent the full usage of these languages. We further acknowledge the socio-cultural biases that can come with the data as views on hate highly differ from one person to another and those shared by our annotators cannot include all possible perspectives. Intended uses and potential misuses Our datasets focus on hate speech and abusive language. They present first step towards studying the phenomenon in some low-resource African languages. However, as malicious data actors can misuse our resources, we follow the suggestions made by Schlichtkrull et al. (2023) for automated fact-checking researchers and clearly state the following: Models built using our datasets should not be used for automated removal. Our data subjects are social media users. Our data actors and model owners should be users, moderators, experts, and researchers with background knowledge in the field, especially on the limitations of automated hate speech and abusive language detection models. Given the sensitivity of the task and the high risk of false positives, any constructed or deployed model using our data should be human-in-the-loop with the humans being native or near-native speakers."
        },
        {
            "title": "Acknowledgments",
            "content": "We are grateful for the work and insights shared by our annotators. This work was carried out with support from Lacuna Fund, an initiative co-founded by The Rockefeller Foundation, Google.org, and Canadas International Development Research Centre. The views expressed herein do not necessarily represent those of Lacuna Fund, its Steering Committee, its funders, or Meridian Institute. We thank Label Studio for providing the academic version annotation tool used in this project. We also thank OpenAI for providing API credits to Masakhane. Shamsuddeen acknowledges the support of Google DeepMind. Paul was supported by MUR FARE 2020 initiative under grant agreement Prot. R20YSMBZ8S (INDOMITA) and the European Research Council (ERC) under the European Unions Horizon 2020 research and innovation program (No. 949944, INTEGRATOR). Abinew acknowledges the support of LT group, University of Hamburg."
        },
        {
            "title": "References",
            "content": "Teshome Mulugeta Ababu and Michael Melese Woldeyohannis. 2022. Afaan oromo hate speech detection and classification on social media. In Proceedings of the thirteenth language resources and evaluation conference, pages 66126619. Idris Abdulmumin, Sthembiso Mkhwanazi, Mahlatse Mbooi, Shamsuddeen Hassan Muhammad, Ibrahim Said Ahmad, Neo Putini, Miehleketo Mathebula, Matimba Shingange, Tajuddeen Gwadabe, and Vukosi Marivate. 2024. Correcting flores evaluation dataset for four african languages. arXiv preprint arXiv:2409.00626. Fatima Muhammad Adam, Abubakar Yakubu Zandam, and Isa Inuwa-Dutse. 2023. Detection of offensive and threatening online content in low resource language. arXiv preprint arXiv:2311.10541. David Adelani, Hannah Liu, Xiaoyu Shen, Nikita Vassilyev, Jesujoba Alabi, Yanke Mao, Haonan Gao, and En-Shiun Lee. 2024. SIB-200: simple, inclusive, and big evaluation dataset for topic classification in 200+ languages and dialects. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 226245, St. Julians, Malta. Association for Computational Linguistics. David Ifeoluwa Adelani, Jade Abbott, Graham Neubig, Daniel Dsouza, Julia Kreutzer, Constantine Lignos, Chester Palen-Michel, Happy Buzaaba, Shruti Rijhwani, Sebastian Ruder, Stephen Mayhew, Israel Abebe Azime, Shamsuddeen H. Muhammad, Chris Chinenye Emezue, Joyce NakatumbaNabende, Perez Ogayo, Aremu Anuoluwapo, Catherine Gitau, Derguene Mbaye, Jesujoba Alabi, Seid Muhie Yimam, Tajuddeen Rabiu Gwadabe, Ignatius Ezeani, Rubungo Andre Niyongabo, Jonathan Mukiibi, Verrah Otiende, Iroro Orife, Davis David, Samba Ngom, Tosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi, Gerald Muriuki, Emmanuel Anebi, Chiamaka Chukwuneke, Nkiruka Odu, Eric Peter Wairagala, Samuel Oyerinde, Clemencia Siro, Tobius Saul Bateesa, Temilola Oloyede, Yvonne Wambui, Victor Akinode, Deborah Nabagereka, Maurice Katusiime, Ayodele Awokoya, Mouhamadane MBOUP, Dibora Gebreyohannes, Henok Tilaye, Kelechi Nwaike, Degaga Wolde, Abdoulaye Faye, Blessing Sibanda, Orevaoghene Ahia, Bonaventure F. P. Dossou, Kelechi Ogueji, Thierno Ibrahima DIOP, Abdoulaye Diallo, Adewale Akinfaderin, Tendai Marengereke, and Salomey Osei. 2021. MasakhaNER: Named Entity Recognition for African Languages. Transactions of the Association for Computational Linguistics, 9:11161131. Carol Adjai and Gabriella Lazaridis. 2013. Migration, xenophobia and new racism in post-apartheid south africa. International journal of social science studies, 1:192205. Jesujoba O. Alabi, David Ifeoluwa Adelani, Marius Mosbach, and Dietrich Klakow. 2022. Adapting pretrained language models to African languages via multilingual adaptive fine-tuning. In Proceedings of the 29th International Conference on Computational Linguistics, pages 43364349, Gyeongju, Republic of Korea. International Committee on Computational Linguistics. Saminu Mohammad Aliyu, Gregory Maksha Wajiga, Muhammad Murtala, Shamsuddeen Hassan Muhammad, Idris Abdulmumin, and Ibrahim Said Ahmad. 2022. Herdphobia: dataset for hate speech against fulani in nigeria. arXiv preprint arXiv:2211.15262. Cynthia Amol, Lilian Wanzare, and James Obuhuma. 2023. Politikweli: swahili-english code-switched twitter political misinformation classification dataset. In International Conference on Speech and Language Technologies for Low-resource Languages, pages 317. Springer. Arnav Arora, Preslav Nakov, Momchil Hardalov, Sheikh Muhammad Sarwar, Vibha Nayak, Yoan Dinkov, Dimitrina Zlatkova, Kyle Dent, Ameya Bhatawdekar, Guillaume Bouchard, et al. 2023. Detecting harmful content on online platforms: what platforms need vs. where research efforts go. ACM Computing Surveys, 56(3):117. Viraat Aryabumi, John Dang, Dwarak Talupuru, Saurabh Dash, David Cairuz, Hangyu Lin, Bharat Venkitesh, Madeline Smith, Kelly Marchisio, Sebastian Ruder, Acyr F. Locatelli, Julia Kreutzer, Nick Frosst, Phil Blunsom, Marzieh Fadaee, A. Ustun, and Sara Hooker. 2024. Aya 23: Open weight releases to further multilingual progress. ArXiv, abs/2405.15032. Abinew Ali Ayele, Skadi Dinter, Tadesse Destaw Belay, Tesfa Tegegne Asfaw, Seid Muhie Yimam, and Chris Biemann. 2022. The 5js in ethiopia: Amharic hate speech data annotation using toloka crowdsourcing platform. In 2022 International Conference on Information and Communication Technology for Development for Africa (ICT4DA), pages 114120. IEEE. Abinew Ali Ayele, Esubalew Alemneh Jalew, Adem Chanie Ali, Seid Muhie Yimam, and Christian Biemann. 2024. Exploring boundaries and intensities in offensive and hate speech: Unveiling the complex spectrum of social media discourse. ArXiv, abs/2404.12042. Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana Patti, Francisco Manuel Rangel Pardo, Paolo Rosso, and Manuela Sanguinetti. 2019. Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter. In Proceedings of the 13th international workshop on semantic evaluation, pages 5463. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440 8451, Online. Association for Computational Linguistics. Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated hate speech detection and the problem of offensive language. In Proceedings of the 11th International AAAI Conference on Web and Social Media, ICWSM 17, pages 512515. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, and et al. 2024. The llama 3 herd of models. ArXiv, abs/2407.21783. Nwachukwu Andrew Egbunike, Noel A. Ihebuzor, and Ngozi Joy Onyechi. 2015. Nature of tweets in the 2015 nigerian presidential elections. Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. 2022. Language-agnostic bert sentence embedding. arXiv preprint. Paula Fortuna, Joao Rocha da Silva, Leo Wanner, Sérgio Nunes, et al. 2019. hierarchically-labeled portuguese hate speech dataset. In Proceedings of the third workshop on abusive language online, pages 94104. Njagi Dennis Gitari, Zhang Zuping, Hanyurwimfura Damien, and Jun Long. 2015. lexicon-based approach for hate speech detection. International Journal of Multimedia and Ubiquitous Engineering, 10(4):215230. Comfort Eseohen Ilevbare, Jesujoba Alabi, David Ifeoluwa Adelani, Firdous Damilola Bakare, Oluwatoyin Bunmi Abiola, and Oluwaseyi Adesina Adeyemo. 2024. Ekohate: Abusive language and hate speech detection for code-switched political arXiv preprint discussions on nigerian twitter. arXiv:2404.18180. Ayyoob Imani, Peiqin Lin, Amir Hossein Kargaran, Silvia Severini, Masoud Jalili Sabet, Nora Kassner, Chunlan Ma, Helmut Schmid, André Martins, François Yvon, and Hinrich Schütze. 2023. Glot500: Scaling multilingual corpora and language models to 500 languages. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10821117, Toronto, Canada. Association for Computational Linguistics. Albert Qiaochu Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lelio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023. Mistral 7b. ArXiv, abs/2310.06825. Hannah Rose Kirk, Wenjie Yin, Bertie Vidgen, and Paul Röttger. 2023. Semeval-2023 task 10: Explainable detection of online sexism. arXiv preprint arXiv:2303.04222. Nayeon Lee, Chani Jung, Junho Myung, Jiho Jin, Jose Camacho-Collados, Juho Kim, and Alice Oh. 2024. Exploring cross-cultural differences in English hate speech annotations: From dataset construction to analysis. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 42054224, Mexico City, Mexico. Association for Computational Linguistics. Nayeon Lee, Chani Jung, and Alice Oh. 2023. Hate speech classifiers are culturally insensitive. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 3546, Dubrovnik, Croatia. Association for Computational Linguistics. Marco Madeddu, Simona Frenda, Mirko Lai, Viviana Patti, and Valerio Basile. 2023. Disaggreghate it corpus: disaggregated italian dataset of hate speech. In Italian Conference on Computational Linguistics. Nelson Mandela. 1994. Long Walk to Freedom: The Autobiography of Nelson Mandela. Little, Brown and Company. Zainab Mansur, Nazlia Omar, and Sabrina Tiun. 2023. Twitter hate speech detection: systematic review of methods, taxonomy analysis, challenges, and opportunities. IEEE Access, 11:1622616249. Antonis Maronikolakis, Axel Wisiorek, Leah Nann, Haris Jabbar, Sahana Udupa, and Hinrich Schütze. 2022. Listening to affected communities to define extreme speech: Dataset and experiments. In Findings of the Association for Computational Linguistics: ACL 2022, pages 10891104. Binny Mathew, Ritam Dutt, Pawan Goyal, and Animesh Mukherjee. 2019. Spread of hate speech in online social media. In Proceedings of the 10th ACM conference on web science, pages 173182. Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel. 2023. Crosslingual generalization through multitask finetuning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1599116111, Toronto, Canada. Association for Computational Linguistics. Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Abinew Ali Ayele, Nedjma Ousidhoum, David Ifeoluwa Adelani, Seid Muhie Yimam, Ibrahim Said Ahmad, Meriem Beloucif, Saif Mohammad, Sebastian Ruder, et al. 2023. Afrisenti: twitter sentiment analysis benchmark for african languages. In Proceedings of EMNLP. Shamsuddeen Hassan Muhammad, David Ifeoluwa Adelani, Sebastian Ruder, Ibrahim Said Ahmad, Idris Abdulmumin, Bello Shehu Bello, Monojit Choudhury, Chris Chinenye Emezue, Saheed Salahudeen Abdullahi, Anuoluwapo Aremu, Alipio Jeorge, and Pavel Brazdil. 2022. Naijasenti: nigerian twitter sentiment corpus for multilingual sentiment analysis. Preprint, arXiv:2201.08277. Joseph Nda Ndabula, Oyenike Mary Olanrewaju, and Faith Echobu. 2023. Detection of hate speech code mix involving english and other nigerian languages. Journal of Information Systems and Informatics, 5(4):14161431. Kelechi Ogueji, Yuxin Zhu, and Jimmy Lin. 2021. Small data? no problem! exploring the viability of pretrained multilingual language models for lowresourced languages. In Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 116126, Punta Cana, Dominican Republic. Association for Computational Linguistics. Akintunde Oladipo, Mofetoluwa Adeyemi, Orevaoghene Ahia, Abraham Owodunni, Odunayo Ogundepo, David Adelani, and Jimmy Lin. 2023. Better quality pre-training data and t5 models for African languages. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 158168, Singapore. Association for Computational Linguistics. Edward Ombui, Lawrence Muchemi, and Peter Wagacha. 2019. Hate speech detection in code-switched text messages. In 2019 3rd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT), pages 16. IEEE. Oluwafemi Oriola and Eduan Kotzé. 2020. Evaluating machine learning techniques for detecting offensive and hate speech in south african tweets. IEEE Access, 8:2149621509. Nedjma Ousidhoum, Zizheng Lin, Hongming Zhang, Yangqiu Song, and Dit-Yan Yeung. 2019. Multilingual and multi-aspect hate speech analysis. arXiv preprint arXiv:1908.11049. Nedjma Ousidhoum, Yangqiu Song, and Dit-Yan Yeung. 2020. Comparative evaluation of label-agnostic selection bias in multilingual hate speech datasets. In Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP), pages 25322542. Mpho Raborife, Blessing Ogechi Ogbuokiri, and Kehinde D. Aruleba. 2024. The role of social media in xenophobic attack in south africa. Journal of the Digital Humanities Association of Southern Africa (DHASA). Justus Randolph. 2005. Free-marginal multirater kappa (multirater [free]): An alternative to fleiss fixed-marginal multirater kappa. Online submission. Abdulhameed Olaitan Ridwanullah, Sulaiman Yau Sule, Bashiru Usman, and Lauratu Umar Abdulsalam. 2024. Politicization of hate and weaponization of twitter/x in polarized digital space in nigeria. Journal of Asian and African Studies, page 00219096241230500. Paul Röttger, Haitham Seelawi, Debora Nozza, Zeerak Talat, and Bertie Vidgen. 2022. Multilingual HateCheck: Functional tests for multilingual hate speech detection models. In Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH), pages 154169, Seattle, Washington (Hybrid). Association for Computational Linguistics. Koustuv Saha, Eshwar Chandrasekharan, and Munmun De Choudhury. 2019. Prevalence and psychological effects of hateful speech in online college communities. Proc ACM Web Sci Conf, 2019:255264. Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagne, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, Jonathan Tow, Alexander M. Rush, Stella Biderman, Albert Webson, Pawan Sasanka Ammanamanchi, Thomas Wang, Benoît Sagot, Niklas Muennighoff, Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Laurenccon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa Etxabe, Alham Fikri Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris C. Emezue, Christopher Klamm, Colin Leong, Daniel Alexander van Strien, David Ifeoluwa Adelani, Dragomir R. Radev, Eduardo Gonzalez Ponferrada, and et al. 2022. Bloom: 176b-parameter open-access multilingual language model. ArXiv, abs/2211.05100. pages 16671682, Online. Association for Computational Linguistics. Fabio Del Vigna, Andrea Cimino, Felice DellOrletta, Marinella Petrocchi, and Maurizio Tesconi. 2017. Hate me, hate me not: Hate speech detection on facebook. In Italian Conference on Cybersecurity. Wenjie Yin and Arkaitz Zubiaga. 2021. Towards generalisable hate speech detection: review on obstacles and solutions. PeerJ Computer Science, 7:e598. Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019. Predicting the type and target of offensive In Annual Conference of posts in social media. the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics (ACL). Michael Schlichtkrull, Nedjma Ousidhoum, and Andreas Vlachos. 2023. The intended uses of automated fact-checking artefacts: Why, how and who. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 86188642. Farhana Shahid and Aditya Vashistha. 2023. Decolonizing content moderation: Does uniform global community standard resemble utopian equality or western power hegemony? In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pages 118. Zeerak Talat and Dirk Hovy. 2016. Hateful symbols or hateful people? predictive features for hate speech detection on twitter. In North American Chapter of the Association for Computational Linguistics. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Leonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Rame, Johan Ferret, Peter Liu, Pouya Dehghani Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, and et al. 2024. Gemma 2: Improving open language models at practical size. ArXiv, abs/2408.00118. Atnafu Lambebo Tonja, Bonaventure F. P. Dossou, Jessica Ojo, Jenalea Rajab, Fadel Thior, Eric Peter Wairagala, Aremu Anuoluwapo, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, and Benjamin Rosman. 2024. Inkubalm: small language model for low-resource african languages. ArXiv, abs/2408.17024. Manuel Tonneau, Pedro Quinta De Castro, Karim Lasri, Ibrahim Farouq, Lakshmi Subramanian, Victor Orozco-Olvera, and Samuel Fraiberger. 2024. NaijaHate: Evaluating hate speech detection on Nigerian Twitter using representative data. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 90209040, Bangkok, Thailand. Association for Computational Linguistics. Lewis Tunstall, Nils Reimers, Unso Eun Seo Jo, Luke Bates, Daniel Korat, Moshe Wasserblat, and Oren Pereg. 2022. Efficient few-shot learning without prompts. ArXiv, abs/2209.11055. Francielle Alves Vargas, Samuel Guimarães, Shamsuddeen Hassan Muhammad, Diego Alves, Ibrahim Said Ahmad, Idris Abdulmumin, Diallo Mohamed, Thiago Alexandre Salgueiro Pardo, and Fabrício Benevenuto. 2024. Hausahate: an expert annotated corpus for hausa hate speech detection. In Proceedings. Bertie Vidgen, Tristan Thrush, Zeerak Waseem, and Douwe Kiela. 2021. Learning from the worst: Dynamically generated datasets to improve online hate detection. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),"
        },
        {
            "title": "A Example Appendix",
            "content": "Prompt 3 A.1 Prompt templates Text: tweet. Read the following text and definitions: Prompt 1 am providing you with the definition of Hate speech, Abusive language, and Neutral tweets. Hate speech is language content that expresses hatred towards particular group or individual based on their political affiliation, race, ethnicity, religion, gender, sexual orientation, or other characteristics. It also includes threats of violence. Neutral language does not contain any bad language. Which category does the tweet above belong to: Hate, Abuse, or Neutral? Pick exactly one category. Dont give any additional context, just classify the tweet. Tweet: text Category: Prompt 2 Read the following label definitions and provide label without any explanations. Hate: Hate speech is public speech that expresses hate or encourages violence towards person or group based on something such as race, religion, gender, ethnicity, sexual orientation or other characteristics. Abusive: Abusive and offensive language means verbal messages that use words in an inappropriate way and may include but is not limited to swearing, name-calling, or profanity. Offensive language may upset or embarrass people because it is rude or insulting Neutral: Neutral language is neither hateful nor abusive or offensive. It does not contain any bad language. Text: tweet Label: Definitions: Hate: Hate speech is public speech that expresses hate or encourages violence towards person or group based on something such as race, religion, gender, ethnicity, sexual orientation or other characteristics. Abuse: Abusive and offensive language means verbal messages that use words in an inappropriate way and may include but is not limited to swearing, name-calling, or profanity. Offensive language may upset or embarrass people because it is rude or insulting Neutral: Neutral language is neither hateful nor abusive or offensive. It does not contain any bad language. Which of these definitions (hate, abuse, neutral) apply to this tweet? Prompt 4 Read the following definitions and text to categorize: Definitions: Hate: Hate speech is public speech that expresses hate or encourages violence towards person or group based on something such as race, religion, gender, ethnicity, sexual orientation or other characteristics. Abuse: Abusive and offensive language means verbal messages that use words in an inappropriate way and may include but is not limited to swearing, name-calling, or profanity. Offensive language may upset or embarrass people because it is rude or insulting Neutral: Neutral language is neither hateful nor abusive or offensive. It does not contain any bad language. Text: tweet. Which of these definitions (hate, abuse, neutral) apply to this tweet? Prompt 5 You will be given text snippet and 3 category definitions. Your task is to choose which category applies to this text. Your text snippet is: tweet Your category definitions are: HATE category definition: Hate speech is public speech that expresses hate or encourages violence towards person or group based on something such as race, religion, gender, ethnicity, sexual orientation or other characteristics. ABUSE category definition: Abusive and offensive language means verbal messages that use words in an inappropriate way and may include but is not limited to swearing, name-calling, or profanity. Offensive language may upset or embarrass people because it is rude or insulting NEUTRAL category definition: Neutral language is neither hateful nor abusive or offensive. It does not contain any bad language. Does the text snippet belong to the HATE, ABUSIVE, or the NEUTRAL category? Thinking step by step answer HATE, ABUSIVE, or NEUTRAL capitalizing all the letters. Explain your reasoning FIRST, then output HATE, ABUSIVE, or NEUTRAL. Model SetFit 0 5 10 20 InkubaLM-0.4B 0 5 10 20 mt0-small bloomz-7b1-mt Mistral-7B-v0.1 aya-23-35B Gemma-2-9B Gemma-2-27B Llama-3.1-8B Llama-3.1-70B GPT-4o Lang. avg. 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 20 - # Shots amh ary arq hau ibo kin oro pcm som swa tir twi xho yor zul 33.79 44.89 49.42 50.13 22.96 28.04 27.00 27. 18.86 26.38 27.38 26.28 17.18 22.74 27.86 25.46 21.18 37.68 39.68 36.64 17.04 37.78 38.50 38.10 27.42 56.60 57.84 60.96 41.78 59.62 60.70 62. 17.36 38.08 42.04 47.74 36.34 58.52 61.18 60.38 61.78 66.73 67.94 68.08 46.54 33.82 35.81 40.49 19.38 24.70 26.46 26.42 16.98 25.76 23.72 23. 21.86 21.40 21.06 19.92 17.46 31.60 36.50 35.46 19.20 56.40 53.96 52.90 28.36 57.68 61.08 59.94 41.24 64.14 61.36 59.86 19.34 40.88 43.10 40. 43.34 66.24 64.46 61.36 66.41 73.53 75.54 76.16 27.40 36.07 46.55 54.24 18.14 20.06 23.92 24.60 13.42 21.66 20.40 19.86 21.86 25.88 25.88 24. 11.98 44.54 50.56 52.94 17.20 57.00 61.82 63.76 25.46 61.14 61.72 64.38 41.12 65.62 64.88 65.80 18.82 51.68 54.76 57.92 42.64 62.88 62.20 63. 73.75 77.33 77.54 78.69 23.57 49.93 49.72 55.40 20.02 21.78 24.48 24.30 12.22 19.94 20.94 21.60 18.60 23.10 24.40 24.96 6.84 34.90 37.82 38. 20.34 39.70 44.42 46.14 14.48 49.98 56.62 55.90 28.96 54.62 58.90 59.60 24.36 36.78 37.78 41.64 35.64 52.86 56.40 57.40 56.91 55.44 58.15 58. 36.90 51.52 39.31 65.15 18.42 21.98 23.52 23.86 9.72 21.28 22.36 22.14 18.42 27.88 27.90 27.72 8.04 36.84 36.94 38.98 14.04 42.70 45.80 46. 15.00 48.12 53.78 54.56 31.36 56.14 56.84 58.76 12.70 35.90 37.78 37.76 32.52 52.88 55.10 53.80 68.82 76.73 80.08 80.81 25.29 55.35 53.10 57. 22.44 25.78 27.22 26.96 17.40 23.04 21.08 21.18 21.98 25.36 22.54 24.18 15.18 46.98 45.72 52.28 21.34 48.78 52.82 57.62 24.08 60.26 63.54 64. 42.08 61.08 64.86 66.06 23.90 38.78 43.02 48.86 38.52 58.14 59.00 62.48 62.53 72.27 75.07 74.86 26.26 36.56 39.10 40.91 26.16 26.86 29.14 28. 20.68 27.78 27.94 28.16 19.38 26.22 27.86 26.64 20.82 39.46 39.02 39.24 20.38 39.24 42.16 42.26 23.74 45.10 45.78 44.70 33.46 46.76 46.96 48. 22.56 31.24 35.92 39.78 31.54 45.50 46.60 49.02 60.01 70.94 72.27 72.33 43.46 53.28 57.00 59.09 16.86 19.08 23.68 23.76 12.40 25.98 25.58 25. 21.60 26.66 26.24 26.82 6.76 50.00 52.10 54.60 20.02 57.90 59.26 61.68 24.74 60.30 60.54 62.54 49.78 61.78 61.60 63.24 20.10 52.38 53.88 55. 48.66 64.38 63.58 63.18 65.94 66.29 67.14 65.41 32.18 48.09 42.29 48.95 20.76 25.06 25.98 25.88 15.16 21.40 19.88 19.96 16.74 23.54 25.48 25. 8.16 34.12 31.82 33.28 18.56 38.72 37.60 38.68 10.92 46.42 51.72 52.22 31.10 54.12 52.86 52.90 24.86 30.62 32.98 30.26 31.14 52.72 54.40 51. 63.42 59.33 62.75 66.44 44.38 54.90 62.64 74.93 20.74 20.48 24.58 24.64 14.07 20.30 16.93 20.05 25.10 27.03 19.83 24.50 10.64 49.58 54.34 55. 21.20 56.32 61.08 73.68 32.12 72.88 76.50 77.56 54.54 77.96 80.04 81.18 20.82 58.10 64.96 69.38 49.36 73.48 76.50 77.72 73.66 80.95 84.19 84. 49.30 35.36 39.16 40.04 25.10 29.26 27.92 30.04 19.30 26.20 26.62 28.04 16.92 25.64 28.58 28.48 25.62 35.64 35.84 37.42 17.10 35.68 35.88 38. 25.52 48.40 45.48 44.94 30.84 52.12 49.82 53.36 14.18 30.20 31.92 37.12 27.08 44.42 49.62 53.90 45.75 61.11 57.52 59.55 51.13 33.23 45.76 53. 17.44 24.50 24.02 23.32 8.56 12.66 12.08 13.44 17.70 28.34 28.50 28.84 8.38 32.04 30.82 30.44 10.68 40.24 39.92 38.54 19.50 46.50 48.16 48. 27.74 47.26 50.86 50.34 9.02 34.82 34.52 33.60 25.54 43.90 45.76 47.50 52.72 73.21 72.28 75.86 37.38 47.49 43.52 46.92 20.58 23.04 24.68 23. 14.20 19.96 18.56 19.12 19.24 23.26 23.56 23.24 9.72 34.24 32.64 34.12 20.32 36.76 36.18 37.74 13.40 35.82 38.82 39.02 25.64 40.48 41.90 43. 21.42 29.22 28.20 27.84 28.98 39.02 39.04 40.34 58.68 60.45 65.75 66.08 48.46 34.36 49.73 56.54 19.26 20.98 23.68 23.14 12.04 17.72 19.90 19. 22.36 24.80 24.16 25.28 8.22 41.04 42.90 46.40 17.48 48.88 48.44 51.52 21.66 55.96 60.22 60.50 41.46 61.72 59.66 59.10 18.60 40.42 38.98 42. 40.64 58.08 57.96 57.94 75.21 76.98 76.74 77.11 35.08 33.18 40.33 50.67 20.38 21.68 25.06 25.20 13.62 19.50 18.88 18.50 19.80 22.62 23.92 23. 8.92 32.54 32.46 35.00 20.24 44.58 45.00 44.52 12.52 46.60 52.58 53.68 28.02 54.28 56.94 56.88 21.94 30.90 30.72 29.12 35.50 55.24 55.74 56. 54.47 59.34 65.05 71.36 Avg. 37.41 43.20 46.23 52.97 20.58 23.55 25.42 25.42 14.58 21.97 21.48 21.77 19.92 24.96 25.18 25. 12.53 38.75 39.94 41.41 18.34 45.38 46.86 48.79 21.26 52.78 55.63 56.26 36.61 57.18 57.88 58.76 19.33 38.67 40.70 42.66 36.50 55.22 56.50 57. 62.67 68.71 70.53 71.71 40.80 41.73 44.47 37.60 39. 43.51 37.59 44.99 36.16 51.01 36. 35.05 33.03 41.56 36.43 39.97 Table 11: Model performance (Macro F1-score) for zeroand few shot classifiers across the 14 languages in AfriHate. Best performance for each language is highlighted in bold. model"
        },
        {
            "title": "SetFit",
            "content": "0 5 10 20 InkubaLM-0.4B 0 5 10 20 mt0-small bloomz-7b1-mt Mistral-7B-v0.1 aya-23-35B Llama-3.1-8B Gemma-2-9B Gemma-2-27B Llama-3.1-70B GPT-4o Lang. avg. 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 20 0 5 10 0 5 10 20 0 5 10 20 0 5 10 20 - #shots amh ary arq hau ibo kin oro pcm som swa tir twi xho yor zul Avg. 33.20 45.11 49.26 50.33 39.74 39.12 37.20 37.64 38.14 36.70 37.40 36. 34.62 32.36 35.16 33.16 42.26 37.92 40.42 39.48 34.54 42.20 45.74 46.76 29.14 41.50 45.16 50.20 48.26 61.10 61.26 64.14 53.40 61.40 62.44 64. 46.28 59.10 61.36 60.72 61.70 66.69 67.09 67.22 42.92 35.91 37.05 40.92 23.62 23.72 29.52 29.18 23.36 24.90 25.74 25.98 34.38 37.34 36.96 35. 30.62 43.46 46.68 45.08 32.76 61.86 61.22 59.70 34.10 50.12 51.70 50.56 37.78 63.62 63.78 61.86 46.38 66.00 64.76 63.60 49.84 68.32 67.80 65. 56.05 73.26 75.12 76.05 26.63 31.89 44.27 53.25 30.26 31.88 32.64 32.68 31.76 34.12 35.06 35.08 33.08 46.74 45.92 44.18 17.28 57.14 60.66 61. 28.52 64.38 69.00 71.40 36.04 63.90 66.04 67.92 26.88 65.72 65.98 67.90 44.10 69.40 69.74 70.24 52.30 67.12 67.70 69.48 66.45 71.03 73.81 75. 24.02 50.81 50.43 54.34 22.66 25.28 38.38 38.64 28.70 29.18 26.36 26.20 32.66 37.52 37.72 37.88 10.52 51.96 56.38 56.98 37.76 55.32 59.78 59. 55.82 46.56 47.72 48.18 17.60 55.20 60.64 60.26 33.62 60.44 64.70 65.74 51.26 58.96 63.00 64.00 45.90 53.24 55.28 56.08 38.61 50.30 40.80 65. 23.04 34.36 27.74 28.70 17.02 29.48 33.44 34.50 29.18 62.56 62.40 63.12 13.00 58.42 61.74 65.10 18.66 56.42 63.98 68.30 22.60 64.48 66.12 66. 16.24 62.84 66.38 69.38 31.08 68.30 70.62 72.84 43.72 66.88 68.78 70.02 44.21 74.23 78.02 78.17 21.29 51.26 48.60 57.28 30.96 32.60 37.58 37. 35.56 31.36 28.30 28.44 36.20 30.88 27.74 29.12 27.62 50.40 50.00 55.64 41.04 56.56 58.66 62.06 48.60 42.24 44.60 48.50 34.34 63.24 64.60 65. 49.02 63.26 66.22 67.72 50.38 60.90 61.50 65.08 44.92 72.39 74.47 74.85 28.72 36.50 42.56 43.08 41.14 44.88 43.26 43.06 43.74 41.10 40.46 40. 37.30 31.96 33.06 31.82 45.42 45.70 46.70 48.82 42.48 49.96 52.30 54.14 42.96 34.94 39.16 44.10 46.86 56.34 56.40 57.24 50.82 56.34 56.24 59. 48.30 54.24 55.86 58.78 44.93 65.30 66.97 66.01 39.23 52.54 56.87 58.44 19.84 23.74 28.82 28.98 22.70 32.06 31.98 31.54 32.76 48.14 47.10 47. 11.14 59.32 60.42 61.22 30.34 61.12 62.08 65.44 39.84 61.22 62.70 64.28 26.68 63.36 64.08 64.50 54.20 64.44 64.22 66.06 56.50 67.20 66.62 67. 49.67 55.93 56.47 50.33 29.26 49.93 40.27 48.86 28.30 30.86 41.26 41.34 31.34 25.26 24.00 23.86 33.90 33.90 35.04 34.78 13.86 52.64 51.50 54. 40.76 57.46 56.98 57.78 55.00 39.08 36.90 38.70 16.22 54.46 57.28 58.62 38.16 62.34 61.24 63.20 46.38 61.20 63.38 64.46 38.50 56.19 58.34 61. 35.26 54.83 62.88 74.68 27.02 25.62 31.22 31.37 27.47 27.90 23.37 23.40 38.53 40.97 36.97 37.93 18.88 58.58 63.18 64.28 34.04 69.84 74.10 75. 49.04 63.88 68.54 72.00 37.12 74.78 78.16 79.24 59.88 80.18 81.94 82.98 60.14 75.76 78.74 80.02 57.24 79.02 72.83 84.14 47.32 31.63 39.74 38. 47.24 48.12 45.84 48.88 42.80 42.56 43.04 44.76 35.82 36.68 38.70 38.72 55.02 41.36 44.88 51.38 35.84 45.70 51.08 56.90 23.18 35.80 39.88 48. 57.98 62.12 61.20 62.98 55.58 59.90 59.52 64.44 43.64 45.18 50.48 56.40 46.01 57.64 56.50 56.91 52.15 38.40 49.28 55.87 23.16 43.96 32.90 32. 14.66 16.20 15.88 17.08 28.88 68.50 67.94 68.84 14.28 69.52 70.26 70.04 14.40 63.86 69.58 71.20 15.20 68.12 69.84 70.40 27.20 65.44 69.76 70. 31.34 64.34 70.82 73.28 35.68 66.18 68.34 72.52 33.90 61.36 61.11 51.67 37.62 46.14 42.60 46.78 27.30 28.14 34.22 33.82 28.32 33.04 31.32 31. 31.94 39.36 38.56 38.14 16.36 47.50 46.40 48.64 35.42 48.96 49.06 51.72 46.18 43.66 43.20 42.72 18.20 46.24 49.66 50.02 29.66 51.36 53.18 56. 42.64 50.18 52.04 53.50 36.72 51.81 61.61 62.78 41.27 31.62 49.21 53.85 23.70 26.88 31.54 30.84 23.16 28.38 29.72 28.92 33.70 48.86 47.66 49. 13.44 57.72 60.50 64.94 28.22 63.48 66.50 70.54 38.02 58.14 60.88 62.24 22.96 70.14 73.02 73.96 45.96 75.60 75.34 76.50 51.34 72.60 73.22 74. 48.62 69.65 70.78 72.22 35.03 35.71 42.03 51.10 27.38 27.52 35.76 36.12 27.62 32.86 32.00 32.30 32.24 39.64 39.44 39.08 14.54 45.96 46.42 50. 35.96 51.14 52.44 56.12 47.42 43.30 42.68 43.16 16.58 52.12 54.74 56.00 31.90 56.24 59.16 61.18 47.00 57.30 58.92 61.26 36.34 58.45 65.12 61. 35.50 42.84 46.39 52.89 29.02 32.45 35.19 35.43 29.09 31.01 30.54 30.70 33.68 42.36 42.02 41.90 22.95 51.84 53.74 55.83 32.72 56.55 59.50 61. 38.88 50.46 52.34 54.54 30.06 61.11 63.13 64.15 43.67 63.97 65.34 67.14 48.36 62.07 63.85 65.59 47.41 64.41 66.23 66.35 47. 47.15 51.73 45.76 51.10 48.39 47. 49.50 44.74 56.22 47.65 50.37 42. 51.59 43.85 48.30 Table 12: Model Performances (Accuracy) for Zero and Few shot Learning Figure 1: Annotation Guidelines and Definitions"
        }
    ],
    "affiliations": [
        "Addis Ababa University",
        "Al Akhawayn University",
        "Bahir Dar University",
        "Bayero University Kano",
        "Bocconi University",
        "Cardiff University",
        "DSFSI, University of Pretoria",
        "Digital Umuganda",
        "Haramaya University",
        "HausaNLP",
        "Imperial College London",
        "Independent Researcher",
        "Instituto Politécnico Nacional",
        "Istanbul Technical University",
        "Lancaster University",
        "Maseno University",
        "Mila, McGill University & Canada CIFAR AI Chair",
        "Northeastern University",
        "SADiLaR",
        "University of Deusto",
        "University of Hamburg",
        "Uppsala University",
        "Wollo University"
    ]
}