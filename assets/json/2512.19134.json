{
    "paper_title": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
    "authors": [
        "Dehai Min",
        "Kailin Zhang",
        "Tongtong Wu",
        "Lu Cheng"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate hallucinations in large language models (LLMs). However, existing methods rely on model-internal signals (e.g., logits, entropy), which are fundamentally unreliable because LLMs are typically ill-calibrated and often exhibit high confidence in erroneous outputs. We propose QuCo-RAG, which shifts from subjective confidence to objective statistics computed from pre-training data. Our method quantifies uncertainty through two stages: (1) before generation, we identify low-frequency entities indicating long-tail knowledge gaps; (2) during generation, we verify entity co-occurrence in the pre-training corpus, where zero co-occurrence often signals hallucination risk. Both stages leverage Infini-gram for millisecond-latency queries over 4 trillion tokens, triggering retrieval when uncertainty is high. Experiments on multi-hop QA benchmarks show QuCo-RAG achieves EM gains of 5--12 points over state-of-the-art baselines with OLMo-2 models, and transfers effectively to models with undisclosed pre-training data (Llama, Qwen, GPT), improving EM by up to 14 points. Domain generalization on biomedical QA further validates the robustness of our paradigm. These results establish corpus-grounded verification as a principled, practically model-agnostic paradigm for dynamic RAG. Our code is publicly available at https://github.com/ZhishanQ/QuCo-RAG."
        },
        {
            "title": "Start",
            "content": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation Dehai Min1, Kailin Zhang2, Tongtong Wu3, Lu Cheng1 1University of Illinois at Chicago, 2New York University, 3Monash University dmin10@uic.edu, kz2739@nyu.edu, tongtong.wu@monash.edu, lucheng@uic.edu 5 2 0 2 2 ] . [ 1 4 3 1 9 1 . 2 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate hallucinations in large language models (LLMs). However, existing methods rely on model-internal signals (e.g., logits, entropy), which are fundamentally unreliable because LLMs are typically ill-calibrated and often exhibit high confidence in erroneous outputs. We propose QuCo-RAG, which shifts from subjective confidence to objective statistics computed from pre-training data. Our method quantifies uncertainty through two stages: (1) before generation, we identify low-frequency entities indicating long-tail knowledge gaps; (2) during generation, we verify entity co-occurrence in the pre-training corpus, where zero co-occurrence often signals hallucination risk. Both stages leverage Infini-gram for millisecond-latency queries over 4 trillion tokens, triggering retrieval when uncertainty is high. Experiments on multi-hop QA benchmarks show QuCoRAG achieves EM gains of 512 points over state-of-the-art baselines with OLMo-2 models, and transfers effectively to models with undisclosed pre-training data (Llama, Qwen, GPT), improving EM by up to 14 points. Domain generalization on biomedical QA further validates the robustness of our paradigm. These results establish corpus-grounded verification as principled, practically model-agnostic paradigm for dynamic RAG1."
        },
        {
            "title": "Introduction",
            "content": "Retrieval-Augmented Generation (RAG) (Lewis et al., 2020; Gao et al., 2023b) mitigates LLM hallucinations by grounding generation in external evidence. Early RAG systems employ static strategies with single retrieval step before generation (Karpukhin et al., 2020; Shi et al., 2024; Min et al., 2025), but fall short for complex multi-step 1Our code is publicly available at https://github.com/ ZhishanQ/QuCo-RAG. 1 Figure 1: Comparison of retrieval triggering mechanisms. (a) DRAGIN relies on model-internal signals, incorrectly assigning high uncertainty to Il (a token from the question) while showing low uncertainty on the hallucinated director name. (b) QuCo-RAG correctly detects the hallucination through zero entity co-occurrence in the pre-training corpus. tasks where information needs emerge dynamically during generation (Su et al., 2025; Wang et al., 2025, 2023). This has driven the emergence of Dynamic RAG methods that adaptively determine when and what to retrieve based on the generation process (Jiang et al., 2023; Asai et al., 2024). Current dynamic RAG methods predominantly rely on quantifying uncertainty through modelinternal signals such as token probability (Jiang et al., 2023) or entropy (Su et al., 2024; Li et al., 2025a). However, these methods assume internal signals reliably indicate generation correctness an assumption that is fundamentally flawed (Li et al., 2024b). As illustrated in Figure 1(a), the notable work DRAGIN (Su et al., 2024) exhibits low uncertainty when generating the incorrect director name Mario Camerini, yet assigns high uncertainty to Ila token from the question. This failure reflects well-documented problem: LLMs are poorly calibrated (Guo et al., 2017; Kadavath et al., 2022; Achiam et al., 2023)their confidence scores fail to correlate with actual prediction accuracy. This miscalibration leads to confident hallucinations, where models produce incorrect content with high confidence (Tian et al., 2023). Furthermore, post-training techniques such as SFT (Dong et al., 2024) and Reinforcement Learning (Ouyang et al., 2022; Guo et al., 2025) often exacerbate this by encouraging decisive answers. More fundamentally, recent theoretical work (Kalai and Vempala, 2024) further shows that for rarely-seen facts, even perfectly calibrated models must hallucinate to maintain statistical consistency. To bypass the limitations, we propose QuCoRAG, framework that determines when to retrieve by Quantifying uncertainty via pre-training Corpus statistics, shifting from subjective internal confidence to objective external evidence. Our key insight is that an LLMs factual knowledge is fundamentally shaped by its pre-training corpus (Balepur et al., 2025): low-frequency entities correspond to long-tail knowledge that models struggle to memorize reliably, while zero co-occurrence between entity pairs indicates the model has no evidential basis for claims relating them. Based on this insight, QuCo-RAG operates through two-stage detection: (1) Pre-Generation Knowledge Assessment: We query entity frequencies in the pretraining corpus, triggering retrieval when entities are low-frequency (long-tail knowledge risks). (2) Runtime Claim Verification: We extract knowledge triplets from each generated sentence and verify entity co-occurrence; zero co-occurrence triggers retrieval and regeneration. Both stages leverage Infini-gram (Liu et al., 2024) for millisecondlatency queries over trillion-token corpora. To validate our approach, we first evaluate QuCoRAG on multi-hop QA benchmarks using the OLMo-2 model family (7B, 13B, 32B) (OLMo et al., 2024), which provides full access to its 4trillion token pre-training corpus for precise statistical verification. Results show QuCo-RAG achieves 512 point improvements on Exact Match (EM) over state-of-the-art baselines across all model scales, while maintaining competitive efficiency. Beyond this matched-corpus setting, we demonstrate QuCo-RAGs broad applicability through two additional dimensions of evaluation. First, for cross-model transferability, we show that corpus statistics computed from OLMo-2s pretraining corpus serve as effective proxies for models with undisclosed training data. Leveraging the substantial overlap of web-scale pre-training corpora, QuCo-RAG yields up to 14 EM improvements on Llama-3, Qwen2.5, and GPT-4.1/5 series. Second, for domain generalization, we evaluate on PubMedQA (Jin et al., 2019), biomedical QA benchmark requiring specialized knowledge. QuCo-RAG achieves the best accuracy while internal-signal methods either trigger excessive retrievals or fail to improve over no-retrieval baselines, demonstrating that our framework generalizes robustly without domain-specific tuning."
        },
        {
            "title": "2 Related Work",
            "content": "Dynamic Retrieval-Augmented LLM Dynamic RAG methods have evolved to address the limitations of static retrieval approaches by adaptively determining when and what to retrieve during generation (Xu et al., 2024; Yu et al., 2024; Yang et al., 2025). FLARE (Jiang et al., 2023) pioneered this direction by triggering retrieval when encountering low-probability tokens. Self-RAG (Asai et al., 2024) extended this paradigm by training models to generate special reflection tokens that assess retrieval necessity and response quality, though requiring additional fine-tuning. More recent approaches (Ma et al., 2025) construct more sophisticated uncertainty metrics: DRAGIN (Su et al., 2024) integrates multiple model-internal signals including entropy and attention weights, ETC (Li et al., 2025a) considers firstand second-order entropy differences to capture uncertainty trends, and SeaKR (Yao et al., 2025) extracts self-aware uncertainty from LLMs internal FFN states. However, these methods all rely on model-internal signals, which may not reliably indicate correctness. Reusing LLM Pre-Training Data at Inference Time Recent work explores unlocking additional value from pre-training corpora at inference time. Fang et al. (2025) showed that retrieving from the models own pre-training data yields performance gains equivalent to 5 increase in pretraining compute. Efficient infrastructure has emerged to support trillion-scale corpus access. Infini-gram (Liu et al., 2024) provides millisecondlatency n-gram counting via suffix arrays, while Infini-gram mini (Xu et al., 2025) reduces index size to 44% of the corpus via FM-index (Ferragina and Manzini, 2000). OLMoTrace (Liu et al., 2025) enables real-time tracing of LLM output back to verbatim matches in training documents. Our work leverages this infrastructure for distinct purpose: 2 Figure 2: Overview of QuCo-RAG Framework. using pre-training corpus statistics to quantify uncertainty and trigger retrieval, enabling reliable hallucination detection and mitigation."
        },
        {
            "title": "3 Methodology",
            "content": "3.1 Problem Formulation We formalize the dynamic RAG problem as follows. Let denote an LLM, represent an external knowledge base for retrieval (e.g., Wikipedia), and denote the pre-training corpus used to train M. Given an input question Q, the model generates response = (s1, s2, . . . , sN ), where si is the i-th generated sentence. dynamic RAG system makes two critical decisions during generation: (1) When to retrieve. At each step i, determine whether to trigger retrieval: δi = ftrigger(Q, s<i; Θ) {0, 1}, (1) where Θ denotes the source of uncertainty signals. Unlike prior methods that rely on internal model states (i.e., Θ = M), we ground the decision in pre-training corpus statistics (i.e., Θ = P). (2) What to retrieve. When δi = 1, construct query qi = fquery(Q, s<i) and retrieve related documents Di = Retrieve(qi, C), where fquery is the query formulation function. Binary Nature of Retrieval Decisions. Note that the retrieval decision δi {0, 1} is inherently binary: the system either retrieves or not. This observation motivates our design: rather than estimating continuous confidence scores from model-internal signals to infer uncertainty, whose thresholds lack clear semantic grounding, we directly leverage discrete corpus statistics to determine whether the model faces high uncertainty (retrieve) or low uncertainty (proceed without retrieval). Specifically, we consider two high-uncertainty scenarios: (1) Input uncertainty: the question contains entities rarely seen during pre-training, indicating insufficient knowledge coverage; (2) Output uncertainty: the generated claim relates entities that never co-occur in the corpus, indicating lack of evidential support. Both signals are grounded in corpus statistics, as illustrated in Figure 2. 3.2 Pre-Generation Knowledge Assessment To quantify input uncertainty, we employ precheck mechanism before generation begins. We first use lightweight entity extractor to identify set of key entities EQ = {e1, e2, . . . , em} from the input question Q. For each entity EQ, we query its frequency in the pre-training corpus P, denoted as freq(e; P). We posit that entities with low frequency in represent long-tail knowledge risks, where the model is likely to hallucinate. Retrieval is triggered if the average entity frequency falls below predefined threshold: δpre = (cid:0)AvgeEQfreq(e; P) < τentity (cid:1) . (2) We set τentity = 103 as the default threshold; results remain stable across wide range (103 to 107) as shown in Appendix A.2. If δpre = 1, we use the original question as the search query to retrieve relevant documents D0, which are prepended to the models context before generation starts. 3.3 Runtime Claim Verification To quantify output uncertainty, QuCo-RAG continuously monitors each generated sentence si by 3 verifying whether the claimed facts have evidential support in the pre-training corpus. For generated sentence si, we extract set of knowledge triplets = {(h, r, t)}, where h, r, represent the head entity, relation, and tail entity, respectively. We quantify the evidential support for each triplet by computing the co-occurrence frequency of the head and tail entities within defined window ω (e.g., document or paragraph) in P: cooc(h, t; P) = {ω : ω ω}. (3) We compute cooc(h, t) rather than cooc(h, r, t) because relational predicates exhibit high lexical variability (e.g., employed by vs. worked at), while named entities are more lexically stable (Galárraga et al., 2014). Retrieval is triggered if the co-occurrence count falls below threshold τcooc (default set to 1): (cid:18) (cid:19) δi = min (h,r,t)T cooc(h, t; P) < τcooc . (4) The rationale for τcooc = 1 is intuitive: if two entities never co-occur in the pre-training corpus, the generated claim lacks evidential support and likely constitutes hallucination (Mallen et al., 2023; Kandpal et al., 2023). Notably, co-occurrence evidence is asymmetric: while cooc(h, t; P) > 0 does not guarantee correctness (entities may co-occur with different relations or in unrelated contexts), cooc(h, t) = 0 strongly indicates hallucination risk (Gao et al., 2023a; Ravichander et al., 2025). When retrieval is triggered (δi = 1), we construct Semantic-Oriented Query using the head entity and relation (q = r) to retrieve supporting documents and regenerate the sentence. 3.4 Implementation Details Corpus Statistics via Infini-gram. We leverage Infini-gram (Liu et al., 2024), suffix array-based engine that supports millisecond-latency queries over trillion-token corpora, enabling real-time computation during generation. Lightweight Triplet Extraction. To minimize overhead while ensuring extraction quality, we distill specialized 0.5B model from GPT-4omini (Hurst et al., 2024). Specifically, we construct 40K annotated examples using in-context learning, then perform full-parameter supervised fine-tuning on Qwen2.5-0.5B-Instruct (Team, 2024). Representative training examples are provided in Appendix A.3."
        },
        {
            "title": "4 Experimental Setup",
            "content": "4.1 Datasets and Implementation We evaluate on two widely adopted knowledgeintensive multi-hop QA benchmarks: 2WikiMultihopQA (Ho et al., 2020) and HotpotQA (Yang et al., 2018). Following Su et al. (2024), we sample the first 1,000 validation examples from each as our test sets and report Exact Match (EM) and token-level F1 score as evaluation metrics, which are well-suited for these benchmarks as answers are short-form entities that can be reliably extracted and matched. Prior work (Li et al., 2025a) has shown that EM/F1 conclusions align with LLM-as-judge (Li et al., 2025b) evaluations on these datasets. For retrieval, we employ BM25 (Robertson et al., 2009) over the Wikipedia dump from Karpukhin et al. (2020) as our external corpus C, retrieving top-3 documents per query. We also verify robustness with dense retrievers in Appendix A.4. In our experiments, we query entity frequencies and co-occurrences via the Infini-gram API2, which hosts the full OLMo-2 pre-training corpus index. We set the co-occurrence window size to 1,000 tokens, roughly matching passage-level context length. More detailed LLM generation settings and the full prompt template are provided in Appendix A.1. All experiments are conducted on NVIDIA H200 GPUs (141GB HBM3e). 4.2 Baselines No Retrieval: Wo-RAG generates answers directly without any external retrieval, serving as the lower bound to measure RAG benefits. Static Retrieval: Single-Round RAG (SR-RAG): performs one-time retrieval using the input question before generation begins. Fixed-Sentence RAG (FS-RAG) (Trivedi et al., 2023) triggers retrieval after every generated sentence, using the last sentence as the query. Dynamic Retrieval: FLARE (Jiang et al., 2023) triggers retrieval on low-probability tokens. DRAGIN (Su et al., 2024) combines entropy, attention, and semantic signals. ETC (Li et al., 2025a) models firstand second-order entropy differences. SeaKR (Yao et al., 2025) leverages internal FFN states for uncertainty estimation. All baseline results are reproduced using their released code. 2API Endpoint Documentation: https://infini-gram. readthedocs.io/en/latest/api.html. The Infini-gram index supports local deployment for offline environments, requiring primarily CPU and disk storage rather than GPU resources. Table 1: Performance comparison on multi-hop QA benchmarks across OLMo-2 model scales. Bold: best; underline: second-best. Improv.: absolute gain over best baseline. 2Wiki: 2WikiMultihopQA. OLMo-2-7B OLMo-2-13B OLMo-2-32B 2Wiki HotpotQA 2Wiki HotpotQA 2Wiki HotpotQA Method EM F1 EM Wo-RAG SR-RAG FS-RAG FLARE DRAGIN ETC SeaKR 20.1 23.7 21.1 22.9 22.8 23.4 25.3 26.4 30.7 28.3 28.9 29.0 29.8 32.7 22.6 29.7 14.5 20.3 17.5 25.1 24.8 31.6 40.7 20.7 28.4 24.7 34.7 35.0 EM 28.5 28.9 28.8 26.2 28.5 29.7 29.6 F1 EM F1 EM F1 34.5 35.7 35.1 31.5 33.9 35.9 34.6 24.4 29.7 14.6 15.3 19.5 29.3 26. 33.6 39.5 21.9 21.9 27.6 39.5 37.3 33.3 37.4 34.6 32.0 33.3 36.0 30.2 40.3 46.5 41.0 39.3 40.2 43.6 38.2 EM 22.0 29.5 13.9 28.3 17.7 30.8 28.7 31.3 40.4 19.5 39.8 24.3 42.2 40.4 QuCo-RAG 32.7 Improv. 54.2 +7.4 +8.4 +5.6 +5.4 +12.0 +13.2 +5.3 +7.3 +9.4 +9.7 +10.8 +12.0 41.1 46.8 46. 41.6 46.1 35.3 56.2 35.0 41. 49.1 4.3 Models Primary Models (Matched Corpus). We use the OLMo-2-Instruct family (OLMo et al., 2024) (7B, 13B, and 32B) as our primary evaluation targets. OLMo-2 achieves performance competitive with mainstream models like Qwen2.5 while providing publicly available training data, code, and recipes. The pre-training corpus3 comprises about 4 trillion tokens from diverse sources. This transparency enables precise computation of entity frequencies and co-occurrence statistics, making OLMo-2 ideal for validating our method. Transferability Models (Proxy Corpus). key advantage of QuCo-RAG is its applicability to LLMs with undisclosed pre-training data. Given that web-scale pre-training corpora share substantial overlap (Soldaini et al., 2024), statistics derived from transparent and comprehensive corpus can serve as effective proxies for other models. We demonstrate this by using the OLMo-2 corpus as proxy for Llama-3-8B-Instruct (Grattafiori et al., 2024), Qwen2.5-32B-Instruct (Team, 2024), and proprietary models (GPT-4.1 (OpenAI, 2025a), GPT-5-chat (OpenAI, 2025b)). For GPT models, we additionally compare against their built-in agentic web search, where the model autonomously invokes web search via the Responses API."
        },
        {
            "title": "5 Experimental Results",
            "content": "We design experiments to answer three core research questions: RQ1: How does corpus-based uncertainty compare to model-internal signals? (5.1) 3https://huggingface.co/datasets/allenai/ olmo-mix-1124 RQ2: How well does QuCo-RAG transfer to models with undisclosed training data? (5.2) RQ3: What is the efficiency-performance tradeoff of QuCo-RAG? (5.3) 5.1 Main Results (RQ1) Table 1 presents the main results on OLMo-2 models across both benchmarks. QuCo-RAG Achieves Significant Improvements over Baselines. Across all model scales and datasets, QuCo-RAG consistently outperforms the strongest baselines by significant margins. On OLMo-2-7B, QuCo-RAG achieves 32.7 EM on 2WikiMultihopQA and 35.3 EM on HotpotQA, surpassing the best baseline by +7.4 and +5.6 points respectively. The improvements become even more pronounced with larger models: OLMo-2-13B shows gains of +12.0 EM on 2WikiMultihopQA, while OLMo-2-32B achieves +10.8 EM improvements on HotpotQA. These results demonstrate that grounding retrieval decisions in corpus statistics provides fundamentally more reliable signal than model-internal uncertainty measures. Internal-Signal Methods Show Inconsistent Performance. Methods relying on model-internal signals (FLARE, DRAGIN, ETC, SeaKR) show highly variable results across settings. For instance, ETC achieves second-best performance in some configurations, yet underperforms even simple SRRAG in others. DRAGIN achieves only 17.519.5 EM on HotpotQA across all model sizes, substantially underperforming SR-RAG. This inconsistency stems from the fundamental unreliability of internal uncertainty signals. detailed case study is provided in Appendix A.5. 5 Figure 3: Efficiency-performance trade-off analysis on HotpotQA with OLMo-2-13B-Instruct. (a) EM score versus Token consumption. (b) EM score versus LLM calls. (c) Performance versus Retrieval frequency. QuCo-RAG achieves the highest EM with moderate token usage and LLM calls. Table 2: Transferability to other model families (EM scores). HPQA: HotpotQA. - indicates the method is not applicable due to API limitations. Full results with F1 score are in Appendix A.6. Qwen2.5-32B Llama-3-8B Method 2Wiki HPQA 2Wiki HPQA Wo-RAG SR-RAG FS-RAG FLARE DRAGIN ETC SeaKR 26.4 23.0 35.9 26.4 28.8 31.5 22. QuCo-RAG Improv. 50.0 +14.1 21.6 31.0 38.6 24.1 22.2 21.7 26.7 41.6 +3.0 29.5 12.9 28.8 26.6 27.9 29.9 33.5 38.4 +4. 20.3 22.7 27.0 22.2 20.0 24.1 33.5 36.2 +2.7 GPT-4.1 GPT-5-chat Method 2Wiki HPQA 2Wiki HPQA Wo-RAG SR-RAG FS-RAG FLARE Web-Tool QuCo-RAG Improv. 54.7 60.0 59.5 49.8 42.9 64.6 +4.6 40.1 38.8 25.9 38.7 8.9 48.2 +8. 50.1 51.0 47.3 - 48.3 59.7 +8.7 37.7 42.9 19.0 - 19.8 48.4 +5.5 5.2 Transferability to Other Models (RQ2) critical question for corpus-based methods is whether they generalize to models whose training data is proprietary or undisclosed. We evaluate QuCo-RAG on Qwen2.5, Llama-3, and GPT model families, using the OLMo-2 corpus as proxy corpus for their knowledge distributions  (Table 2)  . Effectiveness Across Model Families. QuCoRAG demonstrates remarkable transferability, consistently outperforming all baselines across model families. On open-weight models, it achieves substantial gains; notably, for Qwen2.5-32B on 2WikiMultihopQA, our method obtains +14.1 EM im6 provement over the strongest baseline. This trend extends to proprietary models: QuCo-RAG improves GPT-5-chat by +8.7 EM on 2WikiMultihopQA and +5.5 EM on HotpotQA. Conversely, GPT models with agentic web search perform substantially worse than even the no-retrieval baseline, likely due to noisy web results not optimized for complex retrieval demands. Why Proxy Corpus Works. The effectiveness of cross-model transfer validates our hypothesis that web-scale pre-training corpora share substantial overlap (Soldaini et al., 2024; Li et al., 2024a). Factual knowledge is largely drawn from common sources such as Common Crawl, Wikipedia, and curated web text, making frequency and cooccurrence statistics from one comprehensive corpus reliable proxy for others. This property renders QuCo-RAG practically model-agnostic. 5.3 Efficiency Analysis (RQ3) Figure 3 illustrates the efficiency-performance trade-off on HotpotQA. QuCo-RAG achieves the highest EM (35.0) while consuming only 87 tokens and 1.84 LLM calls on average, both the lowest among dynamic RAG methods. FS-RAG and DRAGIN consume 24 more tokens yet achieve substantially lower performance, while SeaKR incurs excessive LLM calls (10.28) due to repeated hidden-state uncertainty estimation. As shown in Figure 3(c), QuCo-RAG triggers only 1.70 retrievals per question on average, demonstrating precise corpus-grounded detection. Notably, no baseline falls in the green region (higher EM with fewer retrievals than QuCo-RAG), while methods like FLARE and FS-RAG fall in the red region, performing worse than Wo-RAG despite frequent retrieval. Regarding runtime, Figure 4 shows that LLM generation dominates (5574%), while corpus-based detection introduces modest overhead, demonstrating favorable scaling for deployment. Table 3: Ablation study on two-stage detection (2WikiMultihopQA, OLMo-2-7B). #Ret.: average retrieval count per question. Configuration EM F1 #Ret. QuCo-RAG (Full) w/o Initial Check w/o Runtime Check 32.7 30.2-2.5 27.6-5.1 41.1 38.0-3.1 35.6-5.5 Baselines SR-RAG Wo-RAG 23.7 20.1 30.7 26. 2.61 1.82 0.76 1.00 0.00 abstracts and medical textbooks (Jin et al., 2020) as the retrieval corpus and report accuracy following the standard benchmark setup (Wu et al., 2025). Notably, we retain the same OLMo-2 pre-training corpus as the statistical signal source P, without any domain-specific adaptation. As shown in Table 4, QuCo-RAG achieves the best accuracy (66.4%) while maintaining high efficiency (0.93 retrievals, 54.9 tokens per question). Internal-signal methods exhibit two failure modes in this specialized domain: over-retrieval and under-retrieval. FLARE suffers from overretrieval, averaging 2.79 retrievals per question (significantly higher than its typical 12 in generaldomain QA), achieving decent accuracy but at massive token cost. Conversely, DRAGIN and ETC suffer from under-retrieval, performing no better than Wo-RAGlikely because their internalsignal formulations fail to transfer across domains. QuCo-RAG avoids both pitfalls: large-scale pretraining corpora provide broad coverage of biomedical knowledge, and zero co-occurrence reliably indicates hallucination risks. Table 4: Domain generalization on PubMedQA (OLMo2-7B). Acc: improvement over Wo-RAG; #Tok.: average token consumption per question. Method Acc Acc #Ret. #Tok. Wo-RAG FS-RAG FLARE DRAGIN ETC 55.2 61.1 63.4 55.2 55.0 0.0 +5.9 +8.2 0.0 -0. QuCo-RAG 66.4 +11.2 0.00 5.74 2.79 1.69 0.25 0.93 40.3 436.1 516.8 139.0 58.8 54. Figure 4: Average runtime breakdown per question for QuCo-RAG components across OLMo-2 model sizes on 2WikiMultihopQA."
        },
        {
            "title": "6 Analysis and Discussion",
            "content": "We provide additional analyses including ablation studies, domain generalization, and performance breakdown by entity frequency. Threshold sensitivity analysis is provided in Appendix A.2. 6.1 Ablation Studies Table 3 examines the contribution of each detection stage. Removing Pre-Generation Knowledge Assessment (w/o Initial Check) reduces EM by 2.5 points, confirming that identifying rare entities in the question is valuable for the initial response. Removing Runtime Claim Verification (w/o Runtime Check) causes larger drop of 5.1 EM points, demonstrating that co-occurrence verification is the more critical component. Interestingly, even w/o Runtime Check (Initial Check only) outperforms SR-RAG by 3.9 EM while triggering fewer retrievals (0.76 vs. 1.00). This suggests that selective retrieval based on entity frequency can be more effective than always-retrieve strategies at the pregeneration stagenot all questions benefit equally from retrieval, and frequency-based detection provides useful signal for prioritizing retrieval. 6.2 Domain Generalization To evaluate generalization beyond open-domain QA, we test on PubMedQA (Jin et al., 2019), biomedical QA benchmark where models answer research questions based on biomedical literature. Following Xiong et al. (2024), we use PubMed 6.3 Performance Across Entity Frequency To understand how different methods handle knowledge of varying prevalence, we group questions by how often their entities appear in the pre-training corpus. Figure 5 shows EM scores and retrieval 7 Enabling Trustworthy AI Applications. Our experiments establish that corpus statistics offer more reliable uncertainty measure than internal signals. This reliability is critical not only for RAG but also for broader safety-critical tasks, such as selective answering, where models can decline to answer when evidential support is absent, and correctness prediction, where corpus statistics provide well-grounded confidence scores for generated claims. From Inference-Time Intervention to DataCentric AI. Our corpus statistics analysis precisely identifies the models knowledge gaps. This signal can inform training data curation: rather than only compensating for gaps at inference time via retrieval, developers can proactively collect data for low-frequency entities during continued pretraining or post-training. Similarly, corpus statistics can guide synthetic data filtering, where LLMgenerated training examples are verified against corpus statistics before inclusion, and model editing by distinguishing facts that require targeted injection from those already reliably learned. Extensions of the Paradigm. Several directions merit exploration: (1) multilingual verification through cross-lingual statistics; (2) temporal dynamics via time-stamped corpora for evolving knowledge; (3) extension beyond entities to events, relations, and numerical claims; and (4) integration into agentic systems as self-verification tool that agents invoke before acting on generation. Theoretical Foundations. Our transferability results raise fundamental questions: why do proxy corpora work across model families? Can we formalize information-theoretic bounds on hallucination probability given corpus statistics? These questions connect to broader debates on memorization versus generalization in LLMs."
        },
        {
            "title": "7 Conclusion",
            "content": "We propose QuCo-RAG, dynamic RAG framework that quantifies uncertainty from pre-training corpus statistics rather than poorly calibrated model-internal signals. QuCo-RAG achieves stateof-the-art performance on multi-hop QA benchmarks while maintaining superior efficiency, transfers effectively to models with undisclosed training data (Llama, Qwen, GPT), and generalizes robustly to biomedical QA. These results establish corpusgrounded verification as principled, practically model-agnostic paradigm for dynamic RAG. Figure 5: Performance stratified by entity frequency bins on 2WikiMultihopQA (OLMo-2-7B). counts across frequency bins. Full numerical results are provided in Appendix Table 10. Overall, all methods perform worse in low-frequency bins, confirming that entity frequency correlates In low-frequency bins with model reliability. (010), QuCo-RAG demonstrates dominant performance, outperforming Wo-RAG by 1017 EM points, while DRAGIN and FLARE achieve nearly identical performance to Wo-RAG despite triggering retrievals, suggesting that models lack sufficient signal to recognize uncertainty on rare entities. In mid-frequency bins (111k), the gap narrows as internal-signal methods become competitive, likely because mid-frequency entities place models in partially learned state where entropy-based uncertainty is better calibrated. In high-frequency bins (>1k), an interesting divergence emerges: baselines exhibit performance degradation while QuCo-RAG continues to improve. For internal-signal methods, the decline is likely due to overconfidence, failing to trigger retrieval even when generating wrong claims. In contrast, QuCo-RAG benefits from richer knowledge coverage: high-frequency entities have more thoroughly documented relationships in the corpus, making co-occurrence statistics more reliable for uncertainty quantification. 6.4 Broader Impact and Future Directions Our work establishes corpus statistics as an objective alternative to model-internal uncertainty signals; while this paper focuses on retrieval triggering in RAG systems, the paradigm shift opens several promising avenues in AI safety and robustness."
        },
        {
            "title": "Limitations",
            "content": "(1) Lexical Matching Constraints. Our cooccurrence verification relies on exact lexical matching of entity surface forms. This may lead to false positive retrieval triggers when two genuinely related entities co-occur in the corpus under alternative names or aliases (e.g., NYC vs. New York City), yet show zero co-occurrence for the specific surface forms extracted from the generated text. However, we argue this limitation is acceptable in practice due to the asymmetric risk inherent in RAG systems: the cost of an unnecessary retrieval (slightly increased latency) is far lower than that of an undetected hallucination (incorrect output). Our conservative strategy, triggering retrieval when in doubt, thus errs on the side of caution. Moreover, given the massive scale of the pre-training corpus, genuinely related entities typically co-occur in some form, mitigating alias-induced false alarms. Future work could incorporate entity linking (Xin et al., 2025) or canonicalization techniques (Hu et al., 2025) to further reduce unnecessary retrievals. (2) Temporal Limitations of Static Corpora. Our approach inherits the temporal limitations of static pre-training corpora (Ding, 2025). corpus indexed at particular point in time cannot provide meaningful statistics for entities or events that emerge afterward (e.g., 2024 corpus cannot verify claims about 2025 sports results or newly founded organizations). This limitation can be addressed through periodic corpus updates and index maintenance."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, and 1 others. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2024. Self-RAG: Learning to retrieve, generate, and critique through self-reflection. In The Twelfth International Conference on Learning Representations. Nishant Balepur, Feng Gu, Abhilasha Ravichander, Shi Feng, Jordan Lee Boyd-Graber, and Rachel Rudinger. 2025. Reverse question answering: Can an llm write question so hard (or bad) that it cant answer? In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers), pages 4464. Huiyi Chen, Jiawei Peng, Kaihua Tang, Xin Geng, and Xu Yang. 2025. Enhancing multimodal in-context learning for image classification through coreset optimization. In Proceedings of the 33rd ACM International Conference on Multimedia, MM 25, page 51305139, New York, NY, USA. Association for Computing Machinery. Zifeng Ding. 2025. Inductive representation learning and natural language question answering on temporal knowledge graphs. Ph.D. thesis, lmu. Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, and Jingren Zhou. 2024. How abilities in large language models are affected by supervised fine-tuning data composition. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 177198. Alex Fang, Thomas Voice, Ruoming Pang, Ludwig Schmidt, and Tom Gunter. 2025. Reusing pretraining data at test time is compute multiplier. arXiv preprint arXiv:2511.04234. Paolo Ferragina and Giovanni Manzini. 2000. OpporIn Protunistic data structures with applications. ceedings 41st annual symposium on foundations of computer science, pages 390398. IEEE. Luis Galárraga, Geremy Heitz, Kevin Murphy, and Fabian Suchanek. 2014. Canonicalizing open knowledge bases. In Proceedings of the 23rd acm international conference on conference on information and knowledge management, pages 16791688. Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen. 2023a. Enabling large language models to generate text with citations. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 64656488, Singapore. Association for Computational Linguistics. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yixin Dai, Jiawei Sun, Haofen Wang, and Haofen Wang. 2023b. Retrievalaugmented generation for large language models: survey. arXiv preprint arXiv:2312.10997, 2(1). Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad AlDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, and 1 others. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Weinberger. 2017. On calibration of modern neural networks. In International conference on machine learning, pages 13211330. PMLR. 9 Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, and 1 others. 2025. Deepseek-r1: Incentivizing reasoning capability in arXiv preprint llms via reinforcement learning. arXiv:2501.12948. Matthew Ho, Chen Si, Zhaoxiang Feng, Fangxu Yu, Yichi Yang, Zhijian Liu, Zhiting Hu, and Lianhui Qin. 2025. Arcmemo: Abstract reasoning composition with lifelong llm memory. arXiv preprint arXiv:2509.04439. Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa. 2020. Constructing multihop QA dataset for comprehensive evaluation of reasoning steps. In Proceedings of the 28th International Conference on Computational Linguistics, pages 66096625, Barcelona, Spain (Online). International Committee on Computational Linguistics. Yujia Hu, Tuan-Phong Nguyen, Shrestha Ghosh, and Simon Razniewski. 2025. Enabling llm knowledge analysis via extensive materialization. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1618916202. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, and 1 others. 2024. Gpt-4o system card. arXiv preprint arXiv:2410.21276. Zhengbao Jiang, Frank Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023. Active retrieval augmented generation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 79697992, Singapore. Association for Computational Linguistics. Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. 2020. What disease does this patient have? large-scale open domain question answering dataset from medical exams. arXiv preprint arXiv:2009.13081. Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu. 2019. Pubmedqa: dataset for biomedical research question answering. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 25672577. Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, and 1 others. 2022. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221. Adam Tauman Kalai and Santosh Vempala. 2024. Calibrated language models must hallucinate. In Proceedings of the 56th Annual ACM Symposium on Theory of Computing, pages 160171. Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 2023. Large language models struggle to learn long-tail knowledge. In International conference on machine learning, pages 1569615707. PMLR. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for opendomain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 67696781, Online. Association for Computational Linguistics. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, and 1 others. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems, 33:9459 9474. Bo Li, Tian Tian, Zhenghua Xu, Hao Cheng, Shikun Zhang, and Wei Ye. 2025a. Modeling uncertainty trends for timely retrieval in dynamic rag. arXiv preprint arXiv:2511.09980. Dawei Li, Bohan Jiang, Liangjie Huang, Alimohammad Beigi, Chengshuai Zhao, Zhen Tan, Amrita Bhattacharjee, Yuxuan Jiang, Canyu Chen, Tianhao Wu, and 1 others. 2025b. From generation to judgment: Opportunities and challenges of llm-as-a-judge. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pages 27572791. Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Yitzhak Gadre, Hritik Bansal, Etash Guha, Sedrick Scott Keh, Kushal Arora, and 1 others. 2024a. Datacomp-lm: In search of the next generation of training sets for language models. Advances in Neural Information Processing Systems, 37:1420014282. Siheng Li, Cheng Yang, Taiqiang Wu, Chufan Shi, Yuji Zhang, Xinyu Zhu, Zesen Cheng, Deng Cai, Mo Yu, Lemao Liu, Jie Zhou, Yujiu Yang, Ngai Wong, Xixin Wu, and Wai Lam. 2024b. survey on the honesty of large language models. arXiv preprint arXiv:2409.18786. Yu Li, Zhe Yang, Yi Huang, Xin Liu, and Guilin Qi. 2025c. C3TG: Conflict-aware, composite, and collaborative controlled text generation. arXiv preprint arXiv:2511.09292. Jiacheng Liu, Taylor Blanton, Yanai Elazar, Sewon Min, Yen-Sung Chen, Arnavi Chheda-Kothary, Huy Tran, Byron Bischoff, Eric Marsh, Michael Schmitz, and 1 others. 2025. Olmotrace: Tracing language model outputs back to trillions of training tokens. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pages 178188. 10 Jiacheng Liu, Sewon Min, Luke Zettlemoyer, Yejin Choi, and Hannaneh Hajishirzi. 2024. Infini-gram: Scaling unbounded n-gram language models to In First Conference on Language trillion tokens. Modeling. Huan Ma, Jingdong Chen, Joey Tianyi Zhou, Guangyu Wang, and Changqing Zhang. 2025. Estimating arXiv preprint llm uncertainty with evidence. arXiv:2502.00290. Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023. When not to trust language models: Investigating effectiveness of parametric and non-parametric memories. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 98029822, Toronto, Canada. Association for Computational Linguistics. Dehai Min, Zhiyang Xu, Guilin Qi, Lifu Huang, and Chenyu You. 2025. UniHGKR: Unified instructionaware heterogeneous knowledge retrievers. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 45774594, Albuquerque, New Mexico. Association for Computational Linguistics. Niklas Muennighoff. 2022. Sgpt: Gpt sentence embeddings for semantic search. arXiv preprint arXiv:2202.08904. Team OLMo, Pete Walsh, Luca Soldaini, Dirk Groeneveld, Kyle Lo, Shane Arora, Akshita Bhagia, Yuling Gu, Shengyi Huang, Matt Jordan, and 1 others. 2024. 2 olmo 2 furious. arXiv preprint arXiv:2501.00656. OpenAI. 2025a. GPT-4.1 Release Information. https: //openai.com/index/gpt-4-1/. OpenAI. 2025b. GPT-5 Release Information. https: //openai.com/index/introducing-gpt-5/. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, and 1 others. 2022. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35:2773027744. Abhilasha Ravichander, Shrusti Ghela, David Wadden, and Yejin Choi. 2025. HALoGEN: Fantastic LLM hallucinations and where to find them. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14021425, Vienna, Austria. Association for Computational Linguistics. Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Richard James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2024. Replug: Retrievalaugmented black-box language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 83718384. Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur, Ben Bogin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar, and 1 others. 2024. Dolma: An open corpus of three trillion tokens for language model pretraining research. In Proceedings of the 62nd annual meeting of the association for computational linguistics (volume 1: long papers), pages 1572515788. Weihang Su, Qingyao Ai, Yueyue Wu, Anzhe Xie, Changyue Wang, Yixiao Ma, Haitao Li, Zhijing Wu, Yiqun Liu, and Min Zhang. 2025. Pre-training for legal case retrieval based on inter-case distinctions. ACM Trans. Inf. Syst., 43(5). Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, and Yiqun Liu. 2024. DRAGIN: Dynamic retrieval augmented generation based on the real-time information needs of large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1299113013, Bangkok, Thailand. Association for Computational Linguistics. Qwen Team. 2024. Qwen2.5: party of foundation models. Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher Manning. 2023. Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 54335442, Singapore. Association for Computational Linguistics. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2023. Interleaving retrieval with chain-of-thought reasoning for knowledgeIn Proceedings of intensive multi-step questions. the 61st annual meeting of the association for computational linguistics (volume 1: long papers), pages 1001410037. Keheng Wang, Feiyu Duan, Peiguang Li, Sirui Wang, and Xunliang Cai. 2025. Llms know what they need: Leveraging missing information guided framework to empower retrieval-augmented generation. In Proceedings of the 31st International Conference on Computational Linguistics, pages 23792400. Stephen Robertson, Hugo Zaragoza, and 1 others. 2009. The probabilistic relevance framework: Bm25 and beyond. Foundations and Trends in Information Retrieval, 3(4):333389. Yile Wang, Peng Li, Maosong Sun, and Yang Liu. 2023. Self-knowledge guided retrieval augmentation for large language models. In Findings of the Association for Computational Linguistics: EMNLP 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2702227043. Fangxu Yu, Hongyu Zhao, and Tianyi Zhou. 2025. Ts-reasoner: Aligning time series foundation arXiv preprint models with llm reasoning. arXiv:2510.03519. Tian Yu, Shaolei Zhang, and Yang Feng. 2024. Auto-rag: Autonomous retrieval-augmented generation for large language models. arXiv preprint arXiv:2411.19443. Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, and 1 others. 2025. Qwen3 embedding: Advancing text embedding and reranking through foundation models. arXiv preprint arXiv:2506.05176. 2023, pages 1030310315, Singapore. Association for Computational Linguistics. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, and 1 others. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824 24837. Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu, Filippo Menolascina, Yueming Jin, and Vicente Grau. 2025. Medical graph RAG: Evidence-based medical large language model via graph retrievalaugmented generation. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 28443 28467, Vienna, Austria. Association for Computational Linguistics. Amy Xin, Yunjia Qi, Zijun Yao, Fangwei Zhu, Kaisheng Zeng, Bin Xu, Lei Hou, and Juanzi Li. 2025. Llmael: Large language models are good context augmenters for entity linking. In Proceedings of the 34th ACM International Conference on Information and Knowledge Management, pages 35503559. Guangzhi Xiong, Qiao Jin, Zhiyong Lu, and Aidong Zhang. 2024. Benchmarking retrieval-augmented generation for medicine. In Findings of the Association for Computational Linguistics ACL 2024, pages 62336251, Bangkok, Thailand and virtual meeting. Association for Computational Linguistics. Hao Xu, Jiacheng Liu, Yejin Choi, Noah A. Smith, and Hannaneh Hajishirzi. 2025. Infini-gram mini: Exact n-gram search at the Internet scale with FMindex. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pages 2495524980, Suzhou, China. Association for Computational Linguistics. Zhipeng Xu, Zhenghao Liu, Yibin Liu, Chenyan Xiong, Yukun Yan, Shuo Wang, Shi Yu, Zhiyuan Liu, and Ge Yu. 2024. Activerag: Revealing the treasures of knowledge via active learning. CoRR. Diji Yang, Linda Zeng, Jinmeng Rao, and Yi Zhang. 2025. Knowing you dont know: Learning when to continue search in multi-round rag through selfpracticing. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 13051315. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. HotpotQA: dataset for diverse, explainable multi-hop question answering. In Conference on Empirical Methods in Natural Language Processing (EMNLP). Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Liu Weichuan, Lei Hou, and Juanzi Li. 2025. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. In Proceedings of the"
        },
        {
            "title": "A Appendix",
            "content": "A.1 Additional Implementation Details Generation Settings and Prompts. In our experiments, all open-source models use greedy decoding with 128-token generation limit per step, and GPT models use default parameters via API calls. For generation, we employ 6-to-8-shot Chain-ofThought prompting (Wei et al., 2022), adopting templates from Trivedi et al. (2023) and Jiang et al. (2023). We use 6 few-shot examples for 2WikiMultihopQA and 8 for HotpotQA, consistent with prior work. The full prompt template is provided in Table 5. We use the Wikipedia dump from Karpukhin et al. (2020) as our external corpus C, which contains approximately 21 million passages. Few-shot Examples: Question: When did the director of film Hypocrite (Film) die? Answer: The film Hypocrite was directed by Miguel Morayta. Miguel Morayta died on 19 June 2013. So the answer is 19 June 2013. [... 57 more demonstrations ...] Retrieved Context (if available): Background information that may be potentially useful in addressing your question: [1] <retrieved document 1> [2] <retrieved document 2> [3] <retrieved document 3> Instruction: the following questions. Please answer The format of the answers should be the same as the examples given before. Specifically, you need to think through the answer to this question step by step. Each sentence should only present fact statement. Avoid using pronouns like He/She/It or possessive pronouns like His/Her/Its, but instead use specific names. At the end of your answer, use So the answer is to provide your answer. Question: <input question> Table 5: Prompt template used for multi-hop QA experiments. Retrieved context is prepended when retrieval is triggered. A.2 Threshold Sensitivity We examine the robustness of QuCo-RAG to its the entity frequency two key hyperparameters: threshold τentity and the co-occurrence threshold τcooc. As illustrated in Figure 6(a), EM remains stable (32.232.7) across wide range of τentity from 13 Figure 6: Threshold sensitivity analysis on 2WikiMultihopQA with OLMo-2-7B. 103 to 107, with retrieval count also staying consistent (2.52.6), demonstrating strong robustness to this hyperparameter. For τcooc, as shown in Figure 6(b), increasing the threshold imposes stricter verification standard (requiring more evidential support in the corpus), leading to monotonic increase in retrieval frequency (from 2.61 to 3.23). While higher thresholds (e.g., τcooc = 20) yield marginal EM improvements (reaching 34.3 EM), they incur significantly higher retrieval overhead. We adopt τcooc = 1 (i.e., triggering on zero co-occurrence) as our default for its clear interpretability: if two entities never co-occur in the pre-training corpus, the generated claim lacks evidential support and is likely hallucinated. A.3 Triplet Extractor Training Examples The quality and diversity of training data are particularly important for robust model training (Li et al., 2025c; Yu et al., 2025). Table 6 shows representative examples from our triplet extractor training data. Each example consists of an input sentence and the extracted output. If the input sentence contains meaningful factual knowledge, the output consists of knowledge triplets in the format (head entity, relation, tail entity); otherwise, the output is empty. We prioritize extracting triplets where the tail entity is named entity (person, location, organization, date) rather than generic descriptors, as Table 6: Examples of triplet extractor training data. The model extracts factual triplets from declarative sentences, partial triplets from questions (since the answer is unknown), and returns empty for non-factual statements. Input Sentence Extracted Output Declarative sentences with factual knowledge: Kumbasaram was released in 2017. [[\"Kumbasaram\", \"released in\", \"2017\"]] Beowulf & Grendel was directed by Sturla Gunnarsson. [[\"Beowulf & Grendel\", \"directed by\", \"Sturla Gunnarsson\"]] Coulson Wallops father, Nigel Wallop, studied at Eton College. [[\"Coulson Wallop\", \"father\", \"Nigel Wallop\"], [\"Nigel Wallop\", \"studied at\", \"Eton College\"]] Questions (answer unknown, extract partial triplets): Which film came out first, Kumbasaram or Mystery Of The 13th Guest? [[\"Kumbasaram\", \"came out\"], [\"Mystery of the 13th Guest\", \"came out\"]] Where did Diane Meyer Simons husband graduate from? [[\"Diane Meyer Simon\", \"husband\"]] Non-factual statements (reasoning conclusions): Thus, Kumbasaram came out first. Therefore, Robert Enrico, the director of The Woman Thou Gavest Me, was born first. [] [] these are more amenable to corpus co-occurrence verification. Non-factual statements such as reasoning conclusions (e.g., sentences starting with \"Thus\" or \"Therefore\") return empty outputs since they do not introduce new verifiable facts. Figure 7: Performance comparison of QuCo-RAG with different retrievers (Qwen3-Embedding, SGPT, and BM25) on 2WikiMultihopQA using OLMo-2-7B. A.4 Effect of Different Retrievers To verify that QuCo-RAG is robust to retriever choice, we compare BM25 with dense retrievers SGPT (Muennighoff, 2022) and Qwen3Embedding-0.6B (Zhang et al., 2025). As shown in Figure 7, QuCo-RAG achieves robust performance across all three retrievers, with EM scores ranging from 27.5 to 32.7 and F1 from 34.3 to 41.1. BM25 achieves the best results (32.7 EM, 41.1 F1), align14 ing with prior findings that sparse retrieval remains highly competitive for RAG tasks (Su et al., 2024). Importantly, even with different retriever backends, QuCo-RAG consistently outperforms baselines (cf. Table 1), confirming that our corpus-based uncertainty quantification mechanism is orthogonal to the choice of retrieval system. A.5 Case Study Table 9 presents detailed case study demonstrating how QuCo-RAG quantifies uncertainty through corpus statistics to detect and correct hallucinations that baseline methods miss. In this multi-hop question, all baselines fail for distinct reasons: WoRAG hallucinates without any correction mechanism; SR-RAG retrieves correct director information but cannot perform follow-up retrieval for the mother; FLARE and DRAGIN both detect some uncertainty but their queries contain the hallucinated director name Igor Maslennikov, leading to retrieval of irrelevant documents that reinforce the error. Notably, DRAGINs internal signals mark this completely fabricated director as low uncertainty, exemplifying the confident hallucination problem. In contrast, QuCo-RAG succeeds through the coordination of two stages: Stage 1 identifies Polish-Russian War as low-frequency entity, triggering initial retrieval that grounds the model to generate the correct director Xawery Zuławski. Stage 2 then catches the hallucinated mother Anna Zuławski via zero co-occurrence, Table 7: Comparison of different RAG methods on 2WikiMultihopQA and HotpotQA benchmarks. 2Wiki HotpotQA Method EM F1 EM F1 Qwen2.5-32B-Instruct 26.4 Wo-RAG 23.0 SR-RAG 35.9 FS-RAG 26.4 FLARE 28.8 DRAGIN 31.5 ETC 22.4 SeaKR QuCo-RAG 50.0 33.6 31.8 45.3 33.3 36.9 40.2 31.3 58.9 Llama-3-8B-Instruct 29.5 Wo-RAG 12.9 SR-RAG 28.8 FS-RAG 26.6 FLARE 27.9 DRAGIN 29.9 ETC SeaKR 33.5 QuCo-RAG 38.4 GPT-4.1 54.7 Wo-RAG 60.0 SR-RAG 59.5 FS-RAG 49.8 FLARE 42.9 Web-Tool QuCo-RAG 64. GPT-5-chat 50.1 Wo-RAG 51.0 SR-RAG 47.3 FS-RAG Web-Tool 48.3 QuCo-RAG 59.7 37.7 29.2 36.8 35.1 36.7 39.2 40.4 46.6 69.9 72.6 73.8 67.9 63.2 74.8 67.0 70.1 63.3 69.8 73.3 21.6 31.0 38.6 24.1 22.2 21.7 26.7 41. 20.3 22.7 27.0 22.2 20.0 24.1 33.5 36.2 40.1 38.8 25.9 38.7 8.9 48.2 37.7 42.9 19.0 19.8 48.4 32.4 41.7 49.6 33.5 32.4 32.0 37.5 55.1 31.4 35.4 38.5 31.5 31.9 35.1 46.0 48.7 56.1 54.2 36.5 52.1 16.8 62. 54.5 58.6 31.3 33.6 62.6 triggering targeted retrieval with hallucinationfree query Xawery Zuławski mother that yields the correct answer. A.6 Full Results for Transferability Experiments Transferability across different models is crucial for practical deployment (Ho et al., 2025; Chen et al., 2025). Table 7 presents the complete results (EM and F1) for the transferability experiments discussed in Section 5.2. The main paper reports only EM scores for brevity. Across all model families (Qwen2.5-32B, Llama-3-8B, GPT-4.1, and GPT-5chat), QuCo-RAG consistently achieves the best performance on both metrics. The F1 improvements follow similar patterns to EM, confirming Table 8: Efficiency comparison of RAG methods across OLMo-2 model sizes. #Tok.: average number of tokens used; #Call: average number of LLM calls; #Ret.: average number of retrieval operations. 2WikiMultihopQA HotpotQA Method #Tok. #Call #Ret. #Tok. #Call #Ret. OLMo-2-7B 58.62 Wo-RAG 49.23 SR-RAG 306.09 FS-RAG 132.90 FLARE 114.09 DRAGIN 124.48 ETC SeaKR 99.89 QuCo-RAG 107. OLMo-2-13B 53.63 Wo-RAG 70.65 SR-RAG 234.42 FS-RAG 129.67 FLARE 134.78 DRAGIN 126.00 ETC SeaKR 78.42 QuCo-RAG 105.83 OLMo-2-32B 54.72 Wo-RAG 64.61 SR-RAG 266.70 FS-RAG 116.19 FLARE 103.53 DRAGIN 116.85 ETC SeaKR 91.08 QuCo-RAG 116.29 1.00 1.00 4.96 2.33 2.58 3.25 11.91 2.44 1.00 1.00 4.36 2.01 2.78 3.23 9.42 2. 1.00 1.00 5.02 2.10 2.69 3.15 14.26 2.43 0.00 1.00 4.96 1.03 1.27 1.25 1.39 2.61 0.00 1.00 4.36 0.93 1.27 1.22 1.01 2.50 0.00 1.00 5.02 1.01 1.26 1.19 2.46 2.49 54.15 69.04 417.77 436.37 387.54 83.69 100.22 128.20 54.59 69.57 464.35 284.34 254.14 100.26 92.11 87. 76.19 91.31 593.71 270.10 554.09 106.24 79.43 98.09 1.00 1.00 6.91 6.89 6.52 2.38 10.95 3.23 1.00 1.00 6.48 3.42 4.26 2.56 10.28 1.84 1.00 1.00 8.59 3.20 7.49 2.61 12.72 1.90 0.00 1.00 6.91 3.39 3.24 0.79 1.29 4.47 0.00 1.00 6.48 1.69 1.96 0.85 1.29 1. 0.00 1.00 8.59 1.59 3.71 0.91 1.97 1.99 that QuCo-RAGs gains are robust. A.7 Detailed Efficiency Metrics Table 8 presents the complete efficiency comparison across all OLMo-2 model sizes on both datasets. We report three metrics: average token consumption (#Tok.), LLM calls (#Call), and retrieval operations (#Ret.) per question. QuCo-RAG maintains competitive efficiency across all settings. Notably, on HotpotQA with OLMo-2-32B, QuCoRAG achieves the highest EM (41.6, see Table 1) while using only 98 tokens and 1.90 LLM calls, compared to FS-RAG which consumes 594 tokens and 8.59 calls yet achieves only 13.9 EM. SeaKR consistently incurs the highest number of LLM calls (914 per question) due to its iterative hiddenstate uncertainty estimation. A.8 Detailed Performance Breakdown by Entity Frequency Bin Table 10 presents the full performance breakdown by entity frequency. Entity frequency is defined Table 9: Case study comparison. Red indicates hallucinated/incorrect content; green indicates correct content. Only QuCo-RAG produces the correct answer through corpus-grounded uncertainty quantification. Question: Who is the mother of the director of film Polish-Russian War? Ground Truth: Małgorzata Braunek (Polish-Russian War (film) Director: Xawery Zuławski Mother: Małgorzata Braunek) Method Initial Generation Uncertainty Signal Retrieval Query Final Answer Analysis Wo-RAG SR-RAG FLARE DRAGIN by Igor ...directed Maslennikov. His mother is Natalia Maslennikova. ...directed by Xawery Zuławski. No information about his mother. N/A N/A Natalia Maslennikova N/A (retrieves once before generation) Original question unknown by Igor ...directed Maslennikov. His mother is Svetlana. Triggered at sentencelevel (probability below threshold) by Igor ...directed Maslennikov. His mother is Natalia Maslennikova. Triggered at token Natalia (entropy-based); wrong director marked as low uncertainty Igor Maslennikov... unknown Igor Maslennikov mother Natalia Maslennikova QuCo-RAG S1: ...directed by Xawery Zuławski. S2: Zuławski. ...mother is Anna Stage 1: Low entity freq. retrieval Stage 2: Co-occurrence = 0 high uncertainty Małgorzata Braunek Stage 1: Original question Stage 2: ery mother XawZuławski No retrieval mechanism to correct hallucinated director. Single-round retrieval insufficient for multi-hop reasoning. Query included hallucinated director; retrieved irrelevant documents. Confident hallucination: internal signals failed to flag the wrong director; query contained error, reinforcing mistake. Stage 1 ensured correct director via initial retrieval; Stage 2 caught hallucinated mother via zero cooccurrence. Table 10: Detailed performance breakdown by entity frequency on 2WikiMultihopQA (OLMo-2-7B). Entity frequency is defined as the average appearance count of all entities in the question within the OLMo-2 pre-training corpus. Freq. Bin Count Wo-RAG EM #Ret. SR-RAG EM #Ret. FS-RAG EM #Ret. FLARE EM #Ret. DRAGIN EM #Ret. QuCo-RAG EM #Ret. 0 1-10 11-50 51-100 101-500 501-1k 1k-5k >5k 180 117 119 66 198 71 141 12.8 11.1 13.4 27.3 23.2 29.6 24.1 25.9 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 13.9 20.5 25.2 18.2 21.2 40.8 29.1 29.6 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 14.4 15.4 18.5 16.7 23.7 29.6 24.8 27.8 4.52 4.62 4.79 5.15 4.94 5.13 5.38 5. 11.1 13.7 17.6 25.8 28.3 33.8 31.2 27.8 0.97 0.87 0.84 1.17 0.97 0.89 1.23 1.37 12.2 13.7 15.1 36.4 23.7 35.2 31.9 29.6 1.26 1.31 1.32 1.18 1.29 1.24 1.28 1.25 Overall 19.9 0.00 23.5 1.00 21.0 4. 22.8 1.03 22.9 1.27 22.8 28.2 26.9 34.8 32.8 39.4 41.8 42.6 32. 2.25 2.41 2.67 2.91 2.76 2.90 2.81 2.48 2.61 as the average occurrence count of all entities in the question within the OLMo-2 pre-training corpus. QuCo-RAG achieves the best EM in 6 out of 8 frequency bins, with particularly large gains on low-frequency entities (frequency < 50) where internal-signal-based methods (FLARE, DRAGIN) perform similarly to Wo-RAG. This validates our core hypothesis that entity frequency in the pretraining corpus serves as an effective indicator of knowledge gaps."
        }
    ],
    "affiliations": [
        "Monash University",
        "New York University",
        "University of Illinois at Chicago"
    ]
}