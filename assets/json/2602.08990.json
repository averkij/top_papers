{
    "paper_title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
    "authors": [
        "Shiyang Feng",
        "Runmin Ma",
        "Xiangchao Yan",
        "Yue Fan",
        "Yusong Hu",
        "Songtao Huang",
        "Shuaiyu Zhang",
        "Zongsheng Cao",
        "Tianshuo Peng",
        "Jiakang Yuan",
        "Zijie Guo",
        "Zhijie Zhong",
        "Shangheng Du",
        "Weida Wang",
        "Jinxin Shi",
        "Yuhao Zhou",
        "Xiaohan He",
        "Zhiyin Yu",
        "Fangchen Yu",
        "Qihao Zheng",
        "Jiamin Wu",
        "Mianxin Liu",
        "Chi Zhang",
        "Shaowei Hou",
        "Shuya Li",
        "Yankai Jiang",
        "Wenjie Lou",
        "Lilong Wang",
        "Zifu Wang",
        "Jiong Wang",
        "Wanghan Xu",
        "Yue Deng",
        "Dongrui Liu",
        "Yiheng Wang",
        "Wenlong Zhang",
        "Fenghua Ling",
        "Shufei Zhang",
        "Xiaosong Wang",
        "Shuangjia Zheng",
        "Xun Huang",
        "Siqi Sun",
        "Shuyue Hu",
        "Peng Ye",
        "Chunfeng Song",
        "Bin Wang",
        "Conghui He",
        "Yihao Liu",
        "Xin Li",
        "Qibin Hou",
        "Tao Chen",
        "Xiangyu Yue",
        "Bin Wang",
        "Liang He",
        "Dahua Lin",
        "Bowen Zhou",
        "Bo Zhang",
        "Lei Bai"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 9 ] . [ 1 0 9 9 8 0 . 2 0 6 2 : r InternAgent-1.5: Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery InternScience Team, Shanghai Artificial Intelligence Laboratory https://github.com/InternScience/InternAgent Artificial intelligence is rapidly emerging as powerful engine for scientific discovery. Modern machine learning and large language models support literature analysis, hypothesis generation, experimental planning, and data interpretation across biology, chemistry, and earth science. These advances have inspired AI Scientist systems that coordinate computational modeling, laboratory experimentation, and cross disciplinary reasoning to accelerate scientific progress. However, existing AI Scientist systems remain limited by domain specific designs, incomplete reasoning abilities, naive optimization pipelines, and insufficient support for long horizon autonomous operation. We introduce InternAgent-1.5, unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides general and scalable framework for autonomous scientific discovery."
        },
        {
            "title": "2.4.1 Strategy-Procedural Memory",
            "content": "3 5 5 6 7 7 7 9 9 10 10 11 11 12 1 2.4.2 Task-Episodic Memory 2.4.3 Semantic-Knowledge Memory 3 Experiments 3.1 Experiments Setup 3.1.1 General Scientific Reasoning Abilities 3.1.2 Algorithm Discovery 3.1.3 Empirical Discovery 3.2 Evaluating Agentic Reasoning Abilities 3.3 Results for Algorithm Discovery Tasks 3.3.1 Scientific Algorithm 3.3.2 AI Algorithm 3.4 Discoveries of Scientific Mechanism 3.4.1 Earth Science 3.4.2 Life Science 3.4.3 Biological Science 3.4.4 Physical Science 3.5 Effectiveness of Structured Cognitive Memory"
        },
        {
            "title": "A Appendix",
            "content": "A.1 Contributions and Acknowledgments A.2 Earth Science example 13 13 13 13 13 14 15 16 18 18 20 21 21 23 25 25 27 28 28 29 29 29 35 35 36 2 1. Introduction Table 1 Comparison with state-of-the-art frameworks for autonomous scientific discovery. Method Domains Capabilities Algorithm Discovery Empirical Discovery Deep Research Solution Refinement Wet Lab Persistence Running AI Scientist [1, 2] AlphaEvolve [3] AI Co-Scientist [4] Robin [5] Kosmos [6] InternAgent 1.0 [7] InternAgent 1.5 Artificial intelligence is rapidly reshaping the landscape of scientific research, giving rise to the emerging paradigm of AI for Science [8, 9]. Recent progress in machine learning has driven advances across biology [10, 11, 12], chemistry [13, 5], and the physical and environmental sciences [14]. Large language models have expanded this frontier by supporting literature analysis [15, 16], hypothesis generation [17, 18, 7], experimental planning [7, 19, 20], and data interpretation [21, 22]. These capabilities have motivated shift toward autonomous scientific systems capable of coordinating complex workflows that span computational modeling, wet-lab experimentation, and cross-disciplinary reasoning. series of recent systems have demonstrated the potential of automated scientific agents. In algorithm optimization, AI Scientist [1, 2] and AlphaEvolve [3] integrate literature analysis, coding, and experimental evaluation into end-to-end research loops. In biomedicine, AI Co-Scientist [4] generates hypotheses and designs therapeutic experiments. In chemistry, systems such as ChemCrow [13] and Robin [5] connect large language models with domain specific toolchains for synthesis planning and molecular design. In earth science, EarthLink [14] integrates multisphere data and literature to support mechanism level reasoning. These systems have shown impressive domain-specific performance but operate as isolated verticals with architectures that embed strong domain assumptions. To move beyond single domain expertise, systems such as Kosmos [6] introduce structured scientific world models to organize research across metabolomics, materials science, and genetics. Despite substantial progress, current systems of AI4S exhibit several characteristics that limit their ability to support autonomous cross-disciplinary discovery: Domain-Specific Architectures: Many systems are organized around discipline-focused designs, which makes it difficult to perform unified reasoning across scientific fields. Partial Foundational Capabilities: Existing frameworks vary in their support for the use of heterogeneous dry-lab and wet-lab experiments, leading to uneven coverage of core scientific competencies. Linear Optimization Pipelines: Optimization procedures are often based on trajectory-local updates and therefore do not integrate information across broader search processes when refining scientific proposals. Limited Long-Horizon Operation: Most systems do not maintain persistent memory over 3 Figure 1 Performance comparison of InternAgent-1.5 across GAIA [25], GPQA [26], HLE-full [27], and FrontierScience [28]. Figure 2 Overview of InternAgent-1.5 that summarizes its foundational capabilities, unified discovery pipeline, and supported scientific tasks in high-level manner. extended research cycles, which restricts iterative refinement and long-term autonomous operation. comparative overview of existing systems is presented in Table 1, which summarizes these characteristics across domains and foundational capabilities. To address these challenges, we adopt an epistemological perspective grounded in the philosophy of science [23, 24] and categorize tasks into two fundamental domains: Algorithm Discovery, which transforms objectives into solutions in formal systems, and Empirical Discovery, which transforms observations into generalizations about the physical world. framework capable of supporting both domains requires unified architectural principles, strong foundational capabilities, long-horizon iterative optimization, and the ability to operate across computational and experimental environments. Building on InternAgent 1.0 [7], we introduce InternAgent-1.5, unified system designed for end-toend scientific discovery. The system follows the observation that scientific inquiry across domains can be organized into common structure that includes literature based hypothesis construction, methodological evaluation, and evidence driven refinement. InternAgent-1.5 operationalizes these processes through three coordinated subsystems, namely Generation, Verification, and Evolution. Each subsystem is driven by foundational capability: deep research supports the Generation subsystem, solution refinement supports the Verification subsystem, and long horizon memory supports the Evolution subsystem. This design moves beyond structures restricted to single domain algorithm discovery and establishes general framework suitable for both computational and empirical scientific tasks. high level overview of InternAgent-1.5, including its core capabilities, subsystem organization, and supported discovery tasks, is presented in Fig. 2. InternAgent-1.5 is evaluated across standard benchmarks and open ended scientific discovery tasks. The system attains leading performance on agentic reasoning abilities, demonstrating the effectiveness of the foundational capabilities that drive the Generation and Verification subsystems. These capabilities, together with long horizon memory in the Evolution subsystem, support stable extended operation and enable consistent iterative refinement throughout long discovery cycles. Building on this capability structure, InternAgent-1.5 further performs competitively in both algorithm discovery and empirical discovery tasks, indicating that the unified framework scales from benchmark level reasoning to practical scientific workflows. In summary, the main contributions of this work are as follows: Unified Architecture for End-to-end Scientific Discovery: InternAgent-1.5 organizes the scientific discovery process into three coherent subsystems for Generation, Verification, and Evolution. These subsystems support the full cycle of hypothesis formulation, methodological evaluation, and evidence driven refinement through foundational capabilities for deep research, solution refinement, and long horizon memory. This organization provides robust basis for reliable and scalable scientific discovery. State-of-the-Art Foundational Capabilities: InternAgent-1.5 delivers strong foundational capabilities in deep research and solution refinement, supported by structured long horizon memory. Across benchmarks that measure cross disciplinary retrieval, structured reasoning, and scientifically grounded problem solving, the system achieves leading performance on HLE [27], GAIA [25], GPQA [26], FrontierScience [28], and SGI bench [29]. These results confirm that the foundational capabilities of InternAgent-1.5 are sufficiently reliable to support complex scientific workflows. Sustained Autonomous Optimization: InternAgent-1.5 integrates structured memory architecture with an iterative optimization process centered on the Verification and Evolution subsystems. This design supports the accumulation of contextual knowledge, the sustained refinement of hypotheses, and the stable improvement of methodological plans across many discovery cycles, moving toward scientific agents capable of extended self-improvement. Breakthroughs in Algorithmic and Empirical Discovery: InternAgent-1.5 demonstrates strong performance in both algorithm discovery and empirical scientific discovery. It produces competitive algorithmic solutions in domains such as reinforcement learning and test time methodology, and generates high quality outputs for data oriented scientific tasks. In empirical settings, the system executes complete experimental workflows and identifies new insights in fields that include biology and earth sciences. These results illustrate the generality and practical effectiveness of the framework across computational and physical scientific environments. With these capabilities and results, we now present the design principles and technical foundations that enable InternAgent-1.5 to operate as unified system for scientific discovery. 2. InternAgent-1.5 2.1. System Overview In this section, we present the system overview of InternAgent-1.5 as illustrated in Fig. 3. The system automates the full research cycle by integrating hypothesis formulation, methodological evaluation, and evidence driven refinement into unified and continuously improving process. Its operation relies on foundational capabilities that support deep research, solution refinement, and long horizon memory. These capabilities are realized through agent driven reasoning and system level infrastructure and allow the system to maintain contextual continuity across iterations. With this capability structure, 5 Figure 3 Overview of InternAgent-1.5, illustrating its unified scientific discovery pipeline organized around the Generation, Verification, and Evolution subsystems. The system operates through foundational capabilities for deep research, solution refinement, and long horizon memory, which together enable sustained autonomous scientific discovery. InternAgent-1.5 coordinates multiple subsystems to support autonomous, scalable, and sustained scientific discovery. 2.1.1. Architecture The architecture of InternAgent-1.5 is organized into three core subsystems, namely the Generation, the Verification, and the Evolution. These subsystems form an integrated and iterative workflow. The Generation subsystem formulates hypotheses and methodological plans, the Verification subsystem evaluates these plans through computational or empirical procedures, and the Evolution subsystem incorporates the resulting evidence to update internal knowledge, strategies, and long term memory. This organization maintains coherent flow of information and enables multi cycle autonomous operation. Generation: The Generation subsystem constructs the conceptual foundation of scientific inquiry. It follows the generation and reflection paradigm of InternAgent 1.0 [7] and is driven by the foundational capability of deep research. It conducts large scale literature analysis, scientific reasoning, and contextual integration and may invoke scientific tools when processing domain specific data. It produces structured hypotheses and methodological plans and records key reasoning traces for subsequent processing. Verification: The Verification subsystem evaluates the hypotheses and methodological plans produced by the Generation subsystem. Its operation is driven by the foundational capability of solution refinement, which structures the iterative search for improved procedures. It performs computational analyses, simulations, and laboratory style assessments as needed and uses historical information to guide evaluation choices. It supports parallel assessment of methodological variants and generates structured evidence for downstream refinement. Evolution: The Evolution subsystem refines system understanding and long term strategies based on outcomes from the Generation and Verification subsystem. It is driven by the foundational capability of memory and unifies analytical feedback with persistent knowledge manage6 ment. It interprets verification results, identifies methodological limitations, updates procedural, episodic, and semantic information, and produces refined priors that guide subsequent cycles of the Generation and Verification subsystem. These subsystems rely on the foundational capabilities introduced above in order to function coherently across extended discovery horizons. The next section presents these capabilities in detail and describes the technical methods that implement them. 2.1.2. Foundational Capabilities The operation of InternAgent-1.5 relies on set of foundational capabilities that allow the Generation, Verification, and Evolution subsystems to function coherently across extended discovery cycles. These capabilities support literature based hypothesis construction, methodological evaluation, iterative refinement, and long horizon continuity. They are implemented through the technical methods introduced in Sections 2.2 to 2.4 and provide the requirements for end-to-end scientific discovery. The first capability is deep research. It supports the Generation subsystem by enabling large scale retrieval, integration, and structuring of cross disciplinary scientific knowledge. Section 2.2 introduces the search mechanisms and structured representations that realize this capability. The second capability is solution refinement. It supports the Verification subsystem by guiding the refinement of methodological plans and structuring the multi round search for improved procedures. Section 2.3 presents the optimization strategies that implement this capability. Scientific tools may be invoked within this subsystem when computational or empirical assessment is required. The third capability is long horizon memory. It supports the Evolution subsystem by maintaining persistent storage and retrieval of contextual information, reasoning traces, and experimental outcomes. Section 2.4 describes its structured organization and interaction rules. Across these capabilities, InternAgent-1.5 maintains the continuity, adaptability, and scalability needed for reliable and continuously improving scientific discovery. 2.2. Cross Disciplinary Graph Construction and Knowledge Capturing Deep Research Capability within the Generation Subsystem To enable cross disciplinary knowledge construction and utilization, our design operates on both data and methodological levels. On the data side, the system integrates diverse scientific sources with the assistance of domain specific tools to parse, normalize, and structure scientific information into large scale multidisciplinary knowledge graph. On the methodological side, it identifies relations and dependencies across domains through structured extraction workflow that combines model driven analysis with tool assisted processing of specialized scientific data, enabling deep and effective cross disciplinary knowledge integration. 2.2.1. Cross-Disciplinary Knowledge Graph To support accurate and comprehensive deep research, we maintain cross-disciplinary knowledge graph (KG). Notably, it differs from traditional KGs [30, 31], which represent knowledge as triples including simple entities and relations; our KG instead captures richer set of scientific elements. Graph Construction From parsed outputs of papers, survey articles, technical reports, and domain notes, we construct heterogeneous graph with nodes representing documents, key concepts, methods, datasets, empirical settings, and problem statements. The parsing process incorporates domain specific scientific tools to assist in identifying specialized entities and scientific attributes that are difficult 7 Figure 4 The illustration for our cross-disciplinary knowledge graph. to extract through general text analysis alone. Edges encode typed relations such as cites and by product. This design lets single research idea sit at the intersection of multiple methodological and application communities and converts flat corpus into structured map where cross field dependencies emerge as paths rather than isolated points. For example, given the text Esterification generally refers to the reaction of an alcohol with carboxylic acid to give an ester and water. Common fats are esters; they can be hydrolysed back to alcohol and acid. typical fat is triacylglycerol, formed from glycerol (propane 1,2,3 triol) and fatty acids (alkanoic acids containing 428 carbon atoms). the corresponding structured representation is shown in Fig. 4. Figure 5 The illustration for our flow graph. Knowledge Extraction and Retrieval We employ schema-guided extraction workflow to build knowledge graph from noisy, cross-domain text. First, candidate entities are identified via domainagnostic named entity recognition and noun-phrase mining, and document-level co-citation and co-usage relations are used to establish initial concept links. subsequent consolidation step refines node types and edge semantics, aligning textual evidence with citation evidence into compact cross-disciplinary graph. To answer deep research queries, we integrate graph search with dense vector retrieval: graph search uncovers the nodes and paths that connect the query to relevant methods and domains, while dense retrieval captures semantically related items not directly linked in the graph. Finally, ranking step merges these results and outputs path-structured evidence chains, which the deep research module then analyzes to reveal cross-disciplinary connections. 8 2.2.2. Flow Graph In real scientific deep research tasks, knowledge often exhibits highly non-linear and dynamic dependencies. Conventional sequential research process struggle to capture these relationships effectively, which can lead to redundant information, over-reliance on early hypotheses, and inflexible reasoning processes. To address these challenges, we introduce Dynamic Structured Knowledge Flow as core principle of deep research system, enabling systematic and adaptive organization of knowledge throughout the research process. Specifically, we capture the knowledge in research process as directed acyclic graph (DAG) that explicitly represents tasks, subtasks, and their dependencies. Structured Knowledge Flow The research process is organized as directed graph, which provides structured representation of the reasoning process. Formally, the research process is defined as: ùê∫ = (ùëâ, ùê∏), (1) where ùëâ denotes the set of nodes and ùê∏ denotes the set of directed edges encoding dependencies among nodes. Each node ùë£ùëñ ùëâ corresponds to subtask or key conceptual unit arising during the reasoning process. To explicitly capture its functional role and execution status, each node is represented as tuple: ùë£ùëñ = (ùë°ùëñ, ùëëùëñ, ùë†ùëñ, ùëêùëñ), (2) where ùë°ùëñ {search, solve, answer} specifies the task type associated with the node, ùëëùëñ describes the task content, ùë†ùëñ tracks the execution state of the node, and ùëêùëñ stores the resulting knowledge context upon successful completion of the task. Directed edges in the graph encode structural dependencies or reasoning constraints between nodes. Specifically, each edge is defined as: ùëíùëñ ùëó = (ùë£ùëñ, ùë£ ùëó, ùëüùëñ ùëó) ùê∏, (3) where ùëíùëñ ùëó indicates directed relationship from node ùë£ùëñ to node ùë£ùëó, and ùëüùëñ ùëó characterizes the type of dependency between the two nodes, such as requires result from, provides evidence for, or constrains reasoning of. These relational edges ensure that information and intermediate results are propagated in dependency-aware manner throughout the reasoning graph. Dynamic planning and refinement The knowledge flow is constructed incrementally: starting from root query node, planner identifies nodes that require further decomposition or context enrichment, generates successor nodes, and updates dependency edges accordingly. This iterative expansion continues until the flow sufficiently covers all subproblems necessary to address the research objective. This design not only enables efficient multi-agent collaboration but also supports adaptive refinement of the knowledge flow as new evidence emerges, ensuring coherent, systematic, and verifiable reasoning throughout the research process. 2.2.3. Graph-Guided Output Synthesis Building upon the dynamically constructed knowledge flow, we describes how the abstract graph structure is instantiated into concrete research outputs. Once the planner completes the incremental construction of the flow graph, executable nodes are activated according to their dependency states and progressively populated with domain knowledge and intermediate reasoning results. Through iterative node execution, state updating, and context propagation along graph edges, the system refines the structured knowledge flow and synthesizes the final research answer. Cross-Disciplinary Knowledge Collector. To facilitate cross disciplinary insight, the Knowledge Collector gathers information from diverse set of sources across multiple domains. These sources include outputs obtained through scientific tools and remote resources accessed via the Science Context Protocol (SCP) [32]. By integrating multi domain knowledge, the system can uncover unexpected connections and inspire ideas that may not emerge within single discipline. Executable nodes with satisfied dependencies are assigned to agents, which decompose each subtask into sequential reasoning and information retrieval process, iteratively assembling the knowledge required to resolve it. After node is executed, its state is updated and the resulting knowledge context is propagated to dependent nodes, ensuring that subsequent reasoning benefits from the most up to date and contextually rich information. This design enables structured, adaptive, and collaborative knowledge acquisition throughout the research process. Reasoning capability enhancement We adopt reasoning capability enhancement strategy that enables reasoning along multiple complementary pathways. For given query, the model generates three forms of responses: direct answer based solely on the input, search augmented answer that incorporates evidence retrieved from external sources and scientific tools, and self driven answer obtained through internal retrieval and refinement. These complementary outputs are aggregated to form the final response, balancing intrinsic reasoning, external evidence, and self consistency. This multi path strategy improves answer completeness and factual reliability while reducing reliance on any single reasoning pathway. 2.3. Experiment Execution and Multi-round Parallel Optimization Solution Refinement Capability within the Verification Subsystem The transformation of refined methodology into verifiable scientific result requires an efficient and reliable validation loop. In both computational algorithm design and physical wet-lab experimentation, the search space of possible configurations is extremely large, and linear trial-and-error procedures often converge prematurely. This section introduces the multi-round parallel experiment optimization and execution framework, which enables InternAgent-1.5 to explore this space autonomously and progressively converge toward high-quality experimental proposals. 2.3.1. Generative Design for Experimental Optimization Efficiently exploring large and unstructured design space is central challenge in automated scientific experimentation. Traditional strategies [33, 34] based on linear refinement or tree-structured search often face three fundamental limitations: Isolated Trajectories arise when insights discovered in one search path cannot inform parallel explorations. Unexploited Search History occurs when informative patterns across longer trajectories are not captured or reused. Limited Idea Composition restricts the integration of promising elements from different branches into improved solutions. We formalize the experimental optimization problem as identifying the optimal solution within search space S, where each candidate solution ùë† represents complete experimental proposal, including code logic, parameter configurations, and physical operation protocols. The objective is to find: ùë† = arg max ùë† ‚Ñé(T , ùë†), (4) where ‚Ñé(T , ùë†) denotes the evaluation metric of solution ùë† on given task . To address the limitations of conventional search, InternAgent-1.5 adopts Graph-Augmented Monte Carlo Search framework. This approach preserves the explorationexploitation balance of Monte Carlo Tree Search while replacing its rigid tree structure with dynamic solution graph that aggregates information across all prior experiments. The search still follows the classical loop of selection, expansion, simulation, and backpropagation, but its effectiveness comes from strengthened expansion phase powered by four graph-based operators: Primary Expansion. Generates new proposal using only its immediate parent. It performs localized adjustments such as parameter refinement or correction of logical inconsistencies, creating the core backbone of parent and child edges used in credit assignment. Intra-branch Evolution. Conditions proposal generation on both the parent and the historical trajectory of ancestors within the same branch. By analyzing recent successes and failures, it reinforces productive design changes and avoids repeatedly exploring unpromising strategies, formalizing localized form of self-reflection. Cross-branch Reference. Introduces targeted transfer of design elements across different branches. When branch stagnates, the system identifies high-performing nodes elsewhere in the solution graph and uses them as references, allowing the new proposal to incorporate robust structural patterns or methodological modules discovered in parallel explorations. Multi-branch Aggregation. Synthesizes complementary strengths from multiple top-performing nodes across the solution graph. By decomposing these proposals into their essential components and recombining them, the operator produces hybrid designs that integrate successful ideas from previously independent search trajectories. Once new proposal is generated through one of these operators, it is executed in the corresponding environment, either computational simulator or physical experimental system, to obtain an evaluation score. This score is backpropagated through the proposals ancestral path to guide subsequent exploration. By integrating graph-based information flow into the Monte Carlo search process, InternAgent-1.5 transforms experimental design into collaborative and cumulative optimization pipeline, enabling rapid convergence toward high-quality scientific solutions. 2.3.2. Scenario Code Opimization for Algorithm Discovery In algorithm discovery tasks, each proposal is an executable program specifying data-processing steps, model components, and evaluation settings. The search module generates new variants by refining computational logic or integrating effective structures identified in other branches. Each candidate is executed in controlled environment that compiles the code and evaluates its performance on benchmark datasets. Quantitative metrics such as accuracy, runtime, and resource usage are returned to the optimization module and backpropagated through the proposals lineage, enabling systematic refinement of algorithmic designs. Experimental Optimization for Empirical Discovery In empirical discovery tasks, each proposal specifies full experimental procedure that may be executed either through computational simulation or on physical laboratory systems. The search process refines these procedures by adjusting parameters, modifying operational steps, or incorporating effective sub-protocols identified across branches. When proposal is simulated, domain models predict experimental outcomes such as reaction yield or protein stability. When it is executed physically, SCP [32] coordinates automated devices to perform the protocol and collect measurements such as fluorescence intensity or assay signal quality. All quantitative results, whether simulated or physically measured, are returned to the optimization module for backpropagation, enabling iterative improvement of empirical workflows. 2.4. Structured Cognitive Memory for Long Horizon Scientific Discovery Long Horizon Memory Capability within the Evolution Subsystem To support adaptive, efficient, and long horizon scientific discovery, InternAgent-1.5 incorporates hierarchical memory subsystem referred to as Structured Cognitive Memory. This subsystem is Figure 6 The illustration for our Structured Cognitive Memory. engaged throughout the entire discovery loop and maintains continuity across cycles, allowing the agent to operate coherently over extended durations. It consolidates procedural, episodic, and semantic information into unified structure that enables short term refinement, mid term adaptation, and long term conceptual development. The overall framework of Structured Cognitive Memory is shown in Fig. 6. 2.4.1. Strategy-Procedural Memory Strategy Procedural Memory (SPM) supports the deep research capability that InternAgent-1.5 invokes throughout the entire scientific discovery process whenever complex analytical reasoning is required. This capability involves integrating literature evidence, synthesizing contextual knowledge, constructing coherent multi-step reasoning plans, correcting failed strategies from earlier research workflows, and analyzing the root causes behind those failures. Instead of storing raw trajectories, the system distills reusable procedural structures from past reasoning processes, including both validated effective patterns and lessons learned from unsuccessful attempts. These procedural structures capture the key decision pivots, organizational patterns that have proven effective across earlier research workflows, as well as the diagnostic insights into failed strategies and their underlying reasons, serving as strategic priors that can be applied flexibly at different stages of the pipeline to avoid recurring pitfalls and optimize reasoning paths. Given historical trajectory ùëá, SPM constructs compact representation as follows: which captures essential procedural states extracted from the full execution trace. When new deep research query ùëû arrives, InternAgent-1.5 retrieves trajectories with procedurally aligned structures: zùëá = ùëìproc(ùëá), (5) S(ùëû) = topk ùëá MSPM sim(cid:0) ùëìproc(ùëû), zùëá (cid:1) . (6) These retrieved strategic priors guide the planner toward globally coherent reasoning graphs, while constraining the executor to avoid redundant execution steps and unnecessary tool calls, thereby providing stable and efficient procedural foundation for the downstream discovery process. 12 2.4.2. Task-Episodic Memory Task Episodic Memory (TEM) supplies fine grained, within trajectory evidence that enables rapid adaptation during iterative experimentation. After each experiment, the system stores an episodic unit containing the attempted method ùëö, extracted metrics ùë¶, and an improvement judgment. Each unit is encoded using hybrid representation that combines semantic embeddings with sparse lexical features to support both conceptual and literal alignment. During hypothesis refinement, relevant episodes are retrieved through the following formula: (ùëû) = topk ùëí sim( ùëìenc(ùëû), ùëìenc(ùëí)) , (7) where ùëû denotes the current hypothesis. The retrieved episodes are injected directly into the generation context, helping the system avoid unsuccessful methodological directions, exploit successful ones, and refine hypotheses efficiently within each research trajectory. 2.4.3. Semantic-Knowledge Memory Semantic Knowledge Memory (SKM) consolidates conceptual information across sessions and supports the long horizon evolution of research objectives. It consists of Long Term Experience Library, which stores distilled methodological insights, and an Idea Graph that tracks the semantic topology of previously explored research directions.Specifically, upon the end of each experimental batch, the system employs pairwise combination strategy for the generated methods to maximize the utilization of existing information. By leveraging contrastive learning between each combination according to their methods and experimental results, InternAgent-1.5 extracts both high-level methodological principles and low-level experimental heuristics to construct Long-term Experience Library. Given research goal ùê∫, long term knowledge entries are retrieved via the following formula: (ùê∫) = topk ùëò sim( ùëìenc(ùê∫), ùëìenc(ùëò)) . To promote continued exploration, each candidate objective ùëê is assigned novelty score: nov(ùëê) = 1 max ùë• sim( ùëìenc(ùëê), ùëìenc(ùë•)) , (8) (9) which encourages the selection of objectives that extend beyond previously explored conceptual regions. In this way, SKM provides the semantic continuity and innovation pressure required for sustained multi-session scientific discovery. 3. Experiments To evaluate InternAgent-1.5s capabilities in the full process of scientific discovery from multiple aspects, we verify its effectiveness through cross-disciplinary benchmarks, autonomous algorithm development, and scientific mechanism discovery, as elaborated in Sec. 3.2, 3.3, and 3.4, respectively. In Sec. 3.4, InternAgent-1.5 demonstrates its applications in scenarios such as Earth Science 3.4.1, Life Science 3.4.2, Biological Science 3.4.3, and Physical Science Tasks 3.4.4. 3.1. Experiments Setup 3.1.1. General Scientific Reasoning Abilities SGI-Bench [29]. SGI-Bench is scientist-aligned benchmark for Scientific General Intelligence (SGI), defined as the ability of an AI system to autonomously navigate the full scientific inquiry cycle of Deliberation, Conception, Action, and Perception. It operationalizes this goal with four task families spanning 10 scientific disciplines and 1,000+ expert-curated samples: Scientific Deep Research, Idea Generation, Dry/Wet Experiments, and Experimental Reasoning. Our results are reported on the DeepResearch and IdeaGeneration subsets. GAIA [25]. GAIA is benchmark of real-world tasks that require coordinated abilities in reasoning, multimodal understanding, web navigation, and tool use. We report results on its 165-question validation set. HLE [27]. Humanitys Last Exam (HLE) is large-scale multimodal benchmark of 2,500 expertwritten questions covering mathematics, humanities, and the natural sciences. It is designed to probe frontier-level academic reasoning, where current LLMs still fall far short of human performance. Frontier Science [28]. FrontierScience is benchmark that evaluates whether AI systems can perform expert-level scientific tasks, including study design, data interpretation, and hypothesis assessment. Following the protocol in the original paper, our results are averaged over 20 runs on the Olympiad subset and 30 runs on the Research subset using its standard evaluation set. GPQA-diamond [26]. GPQA is collection of 448 expert-written multiple-choice questions in biology, chemistry, and physics, designed to test deep scientific reasoning rather than surface knowledge. We use its 198-question GPQA-diamond subset for evaluation. 3.1.2. Algorithm Discovery Scientific Algorithm. To validate the ability of InternAgent-1.5 to discover algorithms in scientific data domains and to demonstrate its improvements over InternAgent-1.0 [7], we conducted experiments on six scientific data oriented algorithm discovery tasks. Notably, due to the limited capabilities of the coding agent in InternAgent-1.0 [7], the baseline repositories for all tasks were first manually consolidated into single-file implementations before being optimized by our system. In contrast, InternAgent-1.5 supports an end-to-end algorithm optimization workflow directly on the original codebases. AutoRYP: The AutoRYP task is built on the SuzukiMiyaura reaction dataset containing 5,760 reaction entries [35]. LoRA-finetuned LLaMA3-8B embedding model [36] with an MLP predictor serves as the baseline. Model performance is assessed using the coefficient of determination (R2). AutoTPPR: The AutoTPPR task operates on the Perturb-seq single-cell transcription-response dataset [37]. GEARS [38], GNNand MLP-based framework for multi-omics representation learning, is adopted as the baseline. The Top-20 DE MSE is used as the evaluation metric. AutoPower: The AutoPower task relies on the IEEE 39-Bus benchmark for power-flow estimation [39]. SenseFlow [40], physics-informed self-ensembling model, serves as the baseline method. Evaluation is performed using RMSE on PQ nodes. AutoTSF: The AutoTSF task is defined on the ETTh1 multivariate time-series dataset from the ETT benchmark [41]. DLinear [42], an MLP-based decomposition and forecasting model, is used as the baseline. Mean Absolute Error (MAE) averaged over horizons 96, 192, 336, 720 serves as the metric. AutoMD: The AutoMD task uses the MD17 dataset [43], which provides molecular energies and forces for seven small organic molecules. VisNet [44], an equivariant geometry-enhanced GNN, is adopted as the baseline. Force-MAE is used as the evaluation metric. AutoEAP: The AutoEAP task is constructed from the UMI-STARR-seq enhancer-activity dataset [45]. DeepSTARR [46] provides the baseline for sequence-based enhancer-activity prediction. Housekeeper Pearson Correlation Coefficient (HK-PCC) is used for evaluation. 14 AI Algorithm. To further evaluate the capabilities of InternAgent-1.5 on AI algorithm discovery, we assembled diverse suite of tasks that span model training pipelines, memory optimization strategies, reinforcement learning methods, and data processing routines, which collectively represent several of the most active directions in current AI algorithm research. For each domain, we selected papers accepted by top AI conferences in 2025 as comparative baselines to validate whether InternAgent-1.5 can outperform the latest AI algorithms. AutoTTS: The AutoTTS task is constructed on benchmark evaluating test-time scaling strategies for enhancing LLM reasoning. Atom [47], Markov-structured test-time scaling framework that refines reasoning through iterative candidate exploration and denoising, serves as the baseline. Model performance is assessed using standard accuracy-based reasoning metrics defined by the benchmark. AutoMem: The AutoMem task is defined on long-term interaction and memory-management benchmarks for LLM agents. A-MEM [48], an agentic memory system inspired by the Zettelkasten method and designed for dynamic note construction, semantic linking, and memory evolution, serves as the baseline. Evaluation focuses on long-horizon agent performance using metrics such as retrieval accuracy, contextual relevance, and behavioral consistency under extended interaction. AutoLM: The AutoLM task examines self-distillation based data synthesis for mathematical reasoning. For comparison, we implement complete self-distillation pipeline that performs synthetic question creation through few-shot prompting, reasoning-trajectory generation, and answer verification through majority voting. The resulting synthetic data are then used to train Intern-S1-mini [49]. The evaluation measures the mathematical-reasoning ability of the resulting model, using standard question-answering accuracy as the primary metric. AutoTTRL: The AutoTTRL task is designed to autonomously discover reinforcement learning algorithms that do not require ground truth annotations on reasoning tasks (i.e., AIME 2024 [50]). We employ Test-Time Reinforcement Learning (TTRL) [51] as the baseline method, which utilizes majority voting mechanism to provide effective reward estimation. Following TTRL, we generate 16 responses per question and calculate the average pass rate pass@1 = 1 ùëñ=1 ùëùùëñ ùëò for evaluation, where ùëùùëñ denotes the correctness of the ùëñ-th response. (cid:205)ùëò 3.1.3. Empirical Discovery Earth Science. To evaluate InternAgent-1.5 in the Earth Science domain, which involves petabytescale, multi-dimensional datasets and complex physical processes, we constructed two representative tasks: Automated Climate Diagnostics: This task assesses the systems ability to integrate multisource knowledge for data analysis. The benchmark utilizes historical Surface Air Temperature (TAS) data (19702010) from 20 Global Climate Models (GCMs) in the CMIP6 archive [52] (including ACCESS-ESM1-5, CanESM5, etc.) and the ERA5 reanalysis dataset [53] as the observational ground truth. The goal is to autonomously identify global warming trends and regional biases. Climate Downscaling Optimization: This task evaluates the systems ability to innovate scientific methods. The objective is to enhance surface-temperature fields over China from coarse-resolution NCEP-NCAR-R1 data (2) [54] to fine-scale ERA5 resolution (0.25). We employ standard Kriging interpolation [55] and linear Bias-Corrected Spatial Disaggregation (BCSD) [56] as baselines to test if the system can autonomously design superior deep-learningbased solution. Life Science. To demonstrate the broad applicability of InternAgent-1.5 in early-stage drug discovery, we evaluate its capabilities to therapeutic target identification, domain characterized by heterogeneous multi-omics evidence, complex disease mechanisms, and strong requirements for mechanistic interpretability and experimental verifiability. We construct two representative target-discovery tasks that stress graph-structured planning, multi-modal tool orchestration, and iterative reflection: Automated Biological Evidence Synthesis: The agent orchestrates end-to-end analyzes (expression, genomic alteration, survival, pathway, and tractability) by integrating resources such as TCGA [57], OpenTargets [58] and KEGG [59], and synthesizes coherent evidence chain. We reproduce OriGenes discovery of GPR160 as an HCC target. Hypothesis Generation and Target Prioritization: The agent constructs multi-modal evidence graph (cohorts, proteomics, annotations, pathways, and literature) and iteratively refines mechanistic hypotheses to rank actionable candidates. We reproduce the identification of ARG2 as mechanistically grounded target in CRC, together with experiment-ready validation suggestions. Biological Sciences. As key capability in the Biological Sciences domain, the fluorescent-protein engineering task targets the improvement of existing fluorescent proteins for imaging applications. The system identifies the parent sequence and relevant structural context through literature-driven analysis, then performs dry-lab design by combining sequence inspection, folding prediction with ESMFold [60], and mutational-effect evaluation using sequencefunction and stability predictors such as ProSST [61] to generate candidate variants. These designs are translated into wet-lab protocols through SCP [32], which coordinates automated DNA assembly, expression, purification, and fluorescence-intensity measurement. The resulting data are analyzed and fed back into the design layer, producing structured experimental report that integrates predictions, protocols, and measured performance. Physical Science. To evaluate InternAgent-1.5 in chemical synthesis and drug discovery, we define two tasks requiring the integration of physical constraints and structural design: Automated Reaction Outcome Prediction: Evaluated on the ChemCoTBench [62] forward prediction dataset, this task requires the agent to predict both the target major product and stoichiometric by-products. The system must analyze reactant properties and strictly apply atomic conservation logic. To ensure rigorous evaluation, we explicitly revised 26 problematic entries in this benchmark, providing corrected ground truth for synthesis planning. Generative Scaffold Hopping: This task aims to discover novel molecular entities that circumvent patent barriers while preserving bioactivity. The agent is tasked with replacing the core scaffold of molecule while maintaining key 3D shape and electrostatic features. The system must employ generative algorithms to propose bioisosteres and filter candidates based on medicinal chemistry metrics, such as Synthetic Accessibility and LogP, to ensure the proposed analogs are viable drug candidates. 3.2. Evaluating Agentic Reasoning Abilities SGI-Bench. As shown in Table 2, InternAgent-1.5 (Gemini-3-pro+o4-mini) achieves the best performance on two SGI-Bench tracks, Deep Research and Idea Generation, significantly outperforming strong frontier models. On Deep Research track, InternAgent-1.5 reaches 37.74%, surpassing the second-best Gemini-3-pro 18.48%) by large margin (+19.26%). On Idea Generation, InternAgent1.5 attains 58.11%, exceeding the prior best GPT-5 55.40% (+2.71%). Overall, these results suggest that InternAgent-1.5s iterative deep-research workflow that integrate structured planning, targeted 16 Table 2 Performance comparison on SGI-bench. The best results are bolded and the second best results are underlined. Method Deep Research Idea Generation Gemini-3-pro [63] GPT-5 [64] Claude-Sonnet-4.5 [65] Qwen3-Max [66] o4-mini [67] InternAgent-1.5 (Gemini-3-pro+o4-mini) 18.48 14.47 13.84 15.38 11.95 37.74 39.68 55.40 43.20 39.83 40.78 58.11 Table 3 Performance comparison on GAIA and HLE benchmarks. The best results are bolded and the second best results are underlined. Results not reported in the original papers are denoted as - \". GAIA val HLE Agent Base Model Level 1 Level 2 Level 3 Avg. Text only All React Model with Tools WebDancer [68] WebShaper [69] MiroThinker [70] MiroThinker [70] Tongyi-DR [71] QwQ-32B Qwen2.5-72B MiroThinker-v1.5-30B MiroThinker-v1.5-235B Tongyi-DR-30B 61.5 69.2 - - - 50.0 63.4 - - - 25.0 16.6 - - - 51.5 60.1 72.0 80.8 70.9 - - 31.0 39.2 32.9 - - - - DeepResearch Agents OpenAI DR [72] ChatGPT-Agent [64] Kimi-Researcher [73] Manus [74] Gemini DR [75] OWL [76] Our Method InternAgent-1.5 InternAgent-1.5 InternAgent-1.5 - - - - - Gemini 2.5 Pro 74.29 - - 86.50 - 84.90 69.06 - - 70.10 - 68.60 47.60 67. - - - - 57.70 73.30 - - 42.30 69. - - - - - - 26.60 41.60 26.90 - 26.90 - Qwen3-235B o4-mini 30.77 58.79 69.81 61.54 80.61 88.68 Gemini-3-pro+o4-mini 92.45 89.53 61.54 86.06 60.47 81.39 15.04 36.10 40. 14.84 34.52 40.00 information gathering, and refinement yields substantial gains in evidence-driven research capability while also improving creative yet grounded idea generation. GAIA. As shown in Table 3, InternAgent-1.5 outperforms both closed-source Manus (73.30%) and leading open-source agentic models Mirothinker (80.8%) and Tongyi-DR (70.9%), even though they are specifically trained and evaluated only on the GAIA text-only subset. InternAgent-1.5 also shows strong robustness on Level 3 questions (61.54%). These results indicate that InternAgent-1.5s iterative workflow combining knowledge planning, collection, and refinement is particularly effective for multi-hop and compositional reasoning. HLE. As shown in Table 3 and 4, InternAgent-1.5 achieves the best overall performance among It reaches 40.87% accuracy in the text-only setting and 40.00% on the all compared systems. full benchmark, outperforming strong baselines such as Gemini-3-pro-preview and GPT-5. The 17 Table 4 Domain-wise performance comparison on the Humanitys Last Exam (HLE). The best results are bolded and the second best results are underlined. Humanitys Last Exam Setting Model Math Bio/Med CS/AI Physics Human. Chem. Engineer. Other Avg. Text-Only All-Set Deepseek-R1 [77] 9.30 Gemini-3-pro-preview [63] 45.08 48.96 InternAgent-1.5 19.00 o4-mini [67] GPT-5 [64] 31.00 Gemini-3-pro-preview [63] 44.76 48.09 InternAgent-1.5 8.60 26.13 30.63 11.40 22.10 27.14 30.36 5.80 7.40 26.79 32.67 29.46 34.16 11.00 44.04 44. 5.60 34.65 30.69 12.90 12.60 24.90 21.70 29.05 31.30 30.71 33.04 12.70 9.10 20.60 16.40 42.92 40.00 34.55 42.47 10.30 29.69 28.13 12.60 14.40 32.43 30.63 7.50 8.60 32.39 38.00 37.50 40. 6.90 14.30 18.00 24.80 34.33 38.04 38.63 40.00 Table 5 Performance comparison on FrontierScience of olympiad and research tasks across bio, chem, and phy domains. The best results are bolded and the second best results are underlined. Olympiad (avg N=20) Research (avg N=30) Method Bio Chem Phy All Bio Chem Phy All 47.0014.90 65.006.40 53.404.50 57.403.30 9.675.47 8.174.37 0.832.27 6.202.54 o4-mini [67] 17.0012.69 52.884.05 50.403.88 48.052.84 4.504.35 11.003.74 2.673.35 6.062.30 InternS1-235B [78] 22.864.52 69.647.49 54.863.18 57.573.66 8.176.39 8.506.21 5.834.10 7.503.77 Mirothinker-v1.5-30B-A3B [70] 26.507.26 72.253.25 66.302.63 64.702.41 2.503.10 16.334.64 1.402.70 6.841.88 DeepSeek-V3.2-Thinking [79] Qwen3-235B-A22B-Thinking [66] 24.009.17 61.136.05 57.104.79 55.403.68 10.175.08 10.006.32 1.582.41 7.343.37 2.003.32 0.701.79 1.411.52 Qwen3-30B-A3B-Thinking [66] 13.509.10 47.254.47 42.703.65 41.602.94 1.502.93 Our Method InternAgent-1.5 46.008.00 85.503.67 76.802.99 77.203.06 10.334.64 22.006.00 3.672.87 12.002. improvements are consistent across most HLE sub-domains, highlighting the robustness of InternAgent1.5 on long-horizon, cross-disciplinary reasoning tasks. FrontierScience. Table 5 compares the performance of various methods on Olympiad and Research tasks across biology, chemistry, and physics domains. InternAgent-1.5 achieves the best overall results in both Olympiad (77.20%) and Research (12.00%) settings, with particularly strong performance in Chemistry and Physics. It outperforms all baselines, including DeepSeek-V3.2-Thinking (64.70% Olympiad) and Mirothinker-v1.5 (7.50% Research), demonstrating its superiority in both structured problem-solving and open-ended scientific reasoning. GPQA. As shown in Table 6, InternAgent-1.5 achieves state-of-the-art performance on the GPQAdiamond benchmark with an average accuracy of 87.37%. It outperforms both strong base models and prior tool-augmented agents, with particularly strong results in Chemistry and Physics. These results demonstrate the effectiveness of our method for expert-level scientific reasoning. 3.3. Results for Algorithm Discovery Tasks 3.3.1. Scientific Algorithm We evaluated InternAgent-1.5 across six scientific domains and compared it against our previous work [7, 21], and state-of-the-art domain-specific baselines. As summarized in Table 7, InternAgent1.5 consistently achieves superior performance across all tasks and demonstrates the efficacy of our architectural improvements. Chemical and Molecular Analysis. In the domain of chemical synthesis, the model demonstrates strong capacity to interpret structured reaction information. For the AutoRYP task on the SuzukiMiyaura dataset, InternAgent-1.5 achieves an ùëÖ2 of 36.6. This result significantly outperforms the LoRA finetuned LLaMA3 baseline of 27.6 and the Dolphin score of 31.8. Similarly, for the AutoMD 18 Table 6 Performance comparison on GPQA-diamond benchmark. The best results are bolded and the second best results are underlined. Results not reported in the original papers are denoted as - \". Agent Bio Chem Phys Avg. GPQA-diamond Base Models Qwen-3-8B [66] Qwen3-32B [66] Qwen3-235B [66] Intern-S1 [78] Deepseek-R1 [77] o4-mini [67] GPT-5 [64] - - - 89.47 63.16 78.95 84.21 - - - 59.49 76.34 63.44 76. - - - 93.02 91.86 94.19 95.35 44.44 49.49 47.47 78.26 82.32 78.28 85.35 React Model with Tools WebShaper [69] MiroThinker [80] Tongyi DR [71] 47.37 84.21 78.95 52.69 75.27 67.74 81.40 95.35 95. 64.65 84.85 80.30 Our Method InternAgent-1.5 84.21 79.57 96.51 87. Table 7 Performance comparison across six types of scientific algorithm tasks. Tasks Method AutoRYP AutoTPPR AutoPower AutoTSF AutoMD AutoEAP Baseline Dolphin [21] InternAgent-1.0 [7] InternAgent-1.5 ùëÖ2 27.6 31.8 35.4 36.6 MSE 0.197 0.173 0.146 0.143 RMSE MAE Energy-MAE HK-PCC 0.00473 0.00455 0.00426 0.00318 0.438 0.463 0.433 0.423 0.158 0.152 0.148 0.114 0.65 0.76 0.79 0. task regarding Molecular Dynamics, our model effectively captures geometric features. It reduces the Energy MAE to 0.114 compared to 0.158 achieved by the equivariant GNN baseline VisNet. Physics and Engineering Systems. Our framework exhibits robust performance in modeling complex physical systems and temporal dependencies. In the AutoPower task for Power Flow Estimation, InternAgent-1.5 achieves an RMSE of 0.00318 on the IEEE 39-Bus dataset. This surpasses the physics informed SenseFlow model score of 0.00473. For the AutoTSF task involving Time Series Forecasting, the DLinear baseline proves to be strong competitor with an MAE of 0.4382. Our method further reduces the error to 0.423 and demonstrates effective handling of multivariate trends in the ETTh1 dataset. Biological and Genomic Prediction. The most substantial improvements are observed in computational biology tasks. In the AutoTPPR task for Transcription Prediction, the model achieves an MSE of 0.143. This outperforms the GNN based GEARS framework score of 0.197. Notably, in the AutoEAP task for Enhancer Activity Prediction, InternAgent-1.5 reaches Pearson Correlation Coefficient of 0.91. This constitutes drastic improvement over the DeepSTARR baseline of 0.65 and highlights the exceptional ability of the agent to map DNA sequences to quantitative activity levels. 19 Table 8 Results on complicated scientific algorithm design tasks. Note that our previous version Dolphin [21] and InternAgent-1.0 [7] cannot address these complicated tasks listed in the table."
        },
        {
            "title": "AutoTTRL AutoLM",
            "content": "Baseline InternAgent 1."
        },
        {
            "title": "Acc",
            "content": "70.9 72.5 F1 0.23380.3452 0.27850."
        },
        {
            "title": "Acc",
            "content": "23.3 23."
        },
        {
            "title": "Acc",
            "content": "0.880 0.904 3.3.2. AI Algorithm Test-time Scaling. On the MMLU-CF dataset [81], we evaluate the reasoning capability using the architecture proposed by [47]. Our approach attains score of 72.5, exceeding the baseline score of 70.9. This improvement indicates that InternAgent-1.5effectively enhances performance in knowledge-intensive tasks, demonstrating robust reasoning capabilities and superior adaptability in complex domain scenarios. Memory Mechanism. On the Locomo dataset [82], we evaluate under the AutoMem setup using Qwen2.5-3B [66] as the base model to ensure alignment with the A-MEM [48] baseline. Using F1 as the evaluation metric, our approach attains an F1 of 0.2785, exceeding the baseline score of 0.2338. This improvement indicates that the proposed memory architecture and interaction mechanism enable more reliable long-horizon retention, retrieval, and integration of accumulated information. Reinforcement Learning. On the AutoRL task, we evaluate our approach across the reinforcement-learning control and decision-making benchmarks used in prior work. Using the same environments and return-based metrics as the TTRL baseline, our method achieves consistently higher returns and improved training stability. These results indicate that the proposed framework provides more effective trajectory refinement and decision-making guidance across diverse RL settings. Large Language Model. On the AutoLM task, we apply the full self distillation pipeline and fine tune Intern-S1-mini [78] on the synthesized mathematical reasoning data. To validate algorithmic performance under minimal system configuration, all experiments are conducted with 16k token context. We evaluate our approach on the MATH500 reasoning benchmark used in prior work. Accuracy improves from 0.880 to 0.904, indicating that the enhanced self distillation pipeline produces higher quality trajectories and verified answers, providing effective supervision for strengthening the models mathematical reasoning ability. 20 3.4. Discoveries of Scientific Mechanism 3.4.1. Earth Science Figure 7 Automated Climate Analysis - Temperature Trends. InternAgent-1.5 autonomously generated this diagnostic for 20 CMIP6 models against ERA5 (1970-2010), showing the ranked bar chart of global-mean temperature trends (C/decade). Building on the setup described in Sec. 3.1, we demonstrate how InternAgent-1.5 addresses the dual challenges of knowledge integration and high-fidelity modeling in Earth Science. Automated Data Analysis and Knowledge Integration. In the Automated Climate Diagnostics task, the system was prompted to evaluate CMIP6 climate model simulations against the ERA5 reanalysis. Rather than simply calculating statistics, InternAgent-1.5 employed its Knowledge Flow Planner to integrate climate modeling literature and physical reasoning. Guided by widely adopted diagnostic conventions, the system selected key evaluation metrics, including global-mean surface temperature trends (C decade1) and modelobservation biases, and constructed an end-to-end analysis pipeline encompassing data retrieval, temporal alignment, and statistical estimation. The system successfully processed the multi model ensemble and generated ranked bar chart in Fig. 7 that contextualizes model performance. To further assess the physical consistency of the simulated trends, InternAgent-1.5 also produced spatial maps of linear temperature change in Fig. 8, which enable interpretation at the regional scale. These diagnostics reveal canonical large scale warming patterns, including enhanced high latitude trends that match established characteristics of observed and simulated climate change. Taken together, the results show that InternAgent-1.5 supports climate analysis not only by automating computation but also by organizing diagnostics in manner that aligns with domain specific interpretability. 21 (a) (b) Figure 8 (a) Automated Climate Analysis - Spatial Patterns. Spatial maps of linear temperature trends generated by InternAgent-1.5, identifying regional warming patterns across different CMIP6 models. (b) Precipitation downscaling compariso across different methods. Algorithmic Innovation and Optimization. For the Climate Downscaling Optimization task, InternAgent-1.5 addressed known limitations of widely used baseline methods, including Kriging [55] and BCSD [56], which can struggle to represent non-stationary biases and fine-scale spatial variability in surface temperature fields. 22 The system autonomously conducted literature review, recognizing that standard linear assumptions are insufficient for non-stationary biases. It proposed deep-learning-based approach designed to capture complex spatial dependencies, generated the implementation code, and refined the architecture through iterative validation. As shown in Fig. 8 and summarized in Table 9, the model optimized by InternAgent-1.5 achieves improved performance relative to established statistical baselines. While the baseline Kriging and BCSD methods yielded RMSEs of 3.1658 and 0.9049 respectively, our systems solution reduced the RMSE to 0.8488. Beyond improvements in bulk error statistics, qualitative comparison of spatial fields indicates that bilinear interpolation and kriging introduce substantial spatial smoothing and attenuate high-intensity precipitation cores. In contrast, the InternAgent-1.5 more faithfully reproduces fine-scale spatial gradients and localized convective maxima present in the ERA5 reference data. This suggests that the model effectively captures nonlinear and scale-interactive processes that are not resolved by conventional interpolation or stationary bias-correction methods. Collectively, these results confirms that InternAgent-1.5 can independently conceive and optimize new scientific tools rather than merely applying existing ones. Table 9 Performance Comparison on Climate Downscaling Task. The deep learning method proposed and implemented by InternAgent-1.5 outperforms both traditional interpolation and statistical correction baselines in reconstructing high-resolution (0.25) surface temperature fields."
        },
        {
            "title": "Type",
            "content": "Kriging Interpolation BCSD InternAgent-1.5 Traditional Spatial Statistical Correction AI-Optimized Deep Learning"
        },
        {
            "title": "RMSE",
            "content": "3.1658 0.9049 0.8488 3.4.2. Life Science We present two representative case studies to illustrate how InternAgent-1.5 supports therapeutic target discovery in realistic biomedical scenarios. Automated Biological Evidence Synthesis. As case study, we reproduced the discovery of GPR160 as novel therapeutic target in hepatocellular carcinoma (HCC) reported by OriGene [83]. We prompted InternAgent-1.5 to identify understudied yet mechanistically promising druggable targets in HCC using multi-modal evidence. Using the Knowledge Flow Planner, the system autonomously decomposed the task into differential expression analysis, mutation and copy-number evaluation, survival association testing, pathway enrichment, and tractability assessment. It queried canonical resources including GEPIA, TCGA, GEO, and OpenTargets to generate an initial pool of 125 candidate genes, which was progressively narrowed to GPR160 through multi-round evidence compression and reflection. The system further produced expression profiles, KaplanMeier survival curves, and KEGG pathway maps, revealing tumor-specific overexpression of GPR160, its association with poor recurrence-free survival, and its potential involvement in immune-related signaling. This case demonstrates InternAgent-1.5s ability to translate open-ended biomedical questions into structured and mechanistically grounded evidence chains. Figure 9 Mitochondrial Arg2 immunometabolic pathway and therapeutic intervention points Hypothesis Generation and Target Prioritization. We further reproduced the identification of ARG2 as an overlooked yet mechanistically grounded target in colorectal cancer (CRC). The system constructed multi-modal evidence graph integrating TCGA cohorts, Human Protein Atlas proteomics, UCSC genome annotations, pathway knowledge, and literature-derived molecular mechanisms. Built upon domain-specific reasoning templates, InternAgent-1.5 executed structured reasoning steps including disease gene consistency checks, pathwayphenotype alignment, pharmacological tractability analysis, and clinical differential expression testing. Through iterative reflection cycles, ARG2 emerged as the top-ranked candidate, accompanied by mechanistic explanations involving metabolic reprogramming and immunosuppressive microenvironment remodeling. As illustrated in Fig. 9, which is automatically generated by InternAgent-1.5, mitochondrial ARG2-driven arginine depletion reduces nitric oxide (NO) availability, impairs T-cell effector function, and promotes tumor proliferation via enhanced polyamine biosynthesis, providing unified metabolicimmunological rationale for therapeutic intervention. The complete report is released in our open-source repository. InternAgent-1.5 further generated experiment-ready recommendations, including doseresponse assays, patient-derived organoid (PDO) validation, and immune profiling protocols, consistent with those used in the original study. Notably, ARG2 inhibition exhibited dose-dependent anti-tumor effects in HCT116 cells and multiple CRC PDO models, supporting the validity of the generated hypotheses. Together, these case studies show that InternAgent-1.5 can support end-to-end target discovery, bridging multi-omics evidence integration, mechanistic hypothesis generation, and experimental guidance. 3.4.3. Biological Science Figure 10 The engineering evolution from eGFP to sfGEP The experimental began with targeted literature search by InternAgent-1.5 to identify fluorescent protein variants with strong brightness and folding stability. Evidence from peer reviewed studies pointed to sfGFP as suitable candidate. This information, combined with predefined performance objectives, guided the design of the computational analyses and the experimental validation plan. To evaluate these candidates, series of dry lab and wet lab procedures were carried out using tools and devices coordinated through SCP [32]. The workflow included fluorescence assays, stability measurements, and quality control checks, paired with dry lab predictions of structural stability and sequence function relationships. The results show that sfGFP achieves high functional brightness and reliable folding efficiency, consistent with findings reported in the literature. Based on all data returned by SCP coordinated tools and instruments, InternAgent-1.5 generated final experimental report that summarizes the empirical outcomes and identifies variants appropriate for downstream use. Figure 10, which is automatically generated by InternAgent-1.5, presents an intermediate reasoning artifact automatically produced by InternAgent-1.5, which outlines how evidence from the literature is transformed into an engineering rationale and target selection for sfGFP, and the complete report is available in our open source repository. 3.4.4. Physical Science Building on the setup described in Sec. 3.1, we demonstrate how InternAgent-1.5 addresses the dual challenges of strict atomic conservation and vast chemical search spaces in Physical Science. We report quantitative metrics on reaction prediction benchmarks and qualitative case studies in generative drug design. 25 Table 10 Performance on Forward Major Product (Fwdmajor) and By-product Prediction (Fwdby). Top-1 accuracy and Fingerprint Tanimoto Similarity (FTS) are reported. Models Fwdmajor Fwdby Top-1 FTS Top-1 FTS GPT-5.2 Claude4.5-sonnet-think o3-mini Gemini-3-Pro-Thinking InternAgent-1.5 59 0.74 0.55 0.81 0.86 0.79 0.90 0.74 0.91 0.94 45 0.49 0.47 0.45 0.62 0.40 0.43 0.47 0.36 0.42 Automated Reaction Outcome Prediction. We evaluated the system on the ChemCoTBench [62] forward prediction task. Unlike standard language models that treat molecular strings as mere text [84], InternAgent-1.5 adopts physicochemical-aware approach by proactively invoking RDKit [85] to compute critical molecular descriptors (e.g., LogP, TPSA) and standardize SMILES representations. This descriptor-guided reasoning allows the system to accurately deduce the main product while simultaneously employing atomic conservation logic to infer by-products such as water or halides. As detailed in Table 10, InternAgent-1.5 achieves Top-1 accuracy of 0.86 and Fingerprint Tanimoto Similarity (FTS) of 0.94 for major product prediction. These results significantly outperform recent reasoning-enhanced models such as o3-mini (Top-1 0.55) and Gemini-3-Pro-Thinking (Top-1 0.81). Furthermore, in the challenging by-product prediction task (Fwdby), our system achieves the highest Top-1 accuracy of 0.62, confirming its robustness in capturing complete reaction stoichiometry. Figure 11 Automated scaffold hopping and hit to lead optimization using InternAgent-1.5. The workflow begins by identifying the core scaffold in red from DprE1 inhibitor hit. Through coordinated agent interaction, the system proposes structurally diverse bioisosteres and prioritizes piperidinopyrimidine variants shown in green. It then conducts focused optimization step to address physicochemical limitations and generates final candidate highlighted in blue, which features modified heterocycle and fluorination. The resulting trajectory follows established medicinal chemistry practice and demonstrates the systems ability to support rational drug design. In the drug design domain, InternAgent-1.5 employs generative Generative Scaffold Hopping. multi-agent workflow that prioritizes 3D shape and electrostatic alignment over simple 2D topology. 26 Crucially, the system integrates agent reasoning to refine candidates based on calculated metrics including Synthetic Accessibility (SA), Tanimoto Similarity, and LogP. When applied to DprE1 inhibitor template known for solubility limitations [86], the agent successfully navigated away from the original pyrrolothiadiazole core, proposing plausible bioisosteres based on piperidinopyrimidine scaffolds (Figure 11, Outputs 1st3rd). Notably, the agent autonomously simulated hit-to-lead optimization phase. It replicated expert-driven evolution by replacing the lipophilic piperidine side chain with polar morpholine ring and introducing fluorine atom at the para-position of the phenyl ring (Output), modifications critical for enhancing metabolic stability and solubility [86]. 3.5. Effectiveness of Structured Cognitive Memory Figure 12 Experimental validation of memory effectiveness on algorithm discovery tasks. Figure 13 The evolution process of research objectives on the AutoTSF task. Our system is designed to operate continuously over extended periods, and the Structured Cognitive Memory subsystem is core component that enables sustained improvement across diverse scientific discovery tasks. To isolate how each module contributes to long-horizon capability, we evaluate Task-Episodic Memory (TEM), Semantic-Knowledge Memory (SKM), and Strategy-Procedural Memory (SPM) using modalities aligned with their functional roles. Task-Episodic Memory. We analyze TEM through performance trajectories over iterative research steps. With TEM active, curves rise smoothly, indicating stable short-horizon adaptation. Retrieved episodes provide fine-grained evidence from earlier trials, helping the model avoid ineffective methodological choices and refine hypotheses efficiently. Removing TEM yields irregular or stagnant progression, with frequent revisiting of unproductive strategies due to missing within-session outcomes. This contrast shows episodic grounding is critical for robust, sample-efficient adaptation during sustained operation. Fig.12 further presents long-horizon optimization experiments on scientific-discovery tasks, illustrating how TEM supports stable and persistent iterative improvement. 27 Table 11 Ablation study on the strategy-procedural memory on the GAIA benchmark. We report accuracy and the average of tool calls to evaluate both performance and efficiency. Agent Level 1 Level 2 Level 3 Avg. GAIA Accuracy (%) Avg. # Tool Calls Level 1 Level 2 Level 3 InternAgent 1.5 w/o SPM 92.45 92.45 InternAgent 1.5 84.88 89. 53.85 61.54 82.42 86.06 12.06 9.13 23.51 21.22 55.65 37.33 Avg. 22.69 18.52 Semantic-Knowledge Memory. To assess SKM, we use prompt-based case studies where the system proposes new research directions after multiple exploration batches. With SKM enabled, objectives reflect accumulated understanding of successful and unsuccessful methodological patterns. Retrieved long-term knowledge helps avoid saturated conceptual regions while preserving semantic continuity and measurable novelty. Fig. 13 illustrates iterative evolution of research objectives from an initial seed, showing that SKM maintains cross-batch coherence while allowing strategic redundancy to deepen promising sub-domains, balancing exploration breadth with exploitation depth. Strategy-Procedural Memory. As shown in Table 11, we evaluate SPM on benchmark tasks requiring multi-step reasoning and coordinated planning. The full system achieves higher success rates and more coherent plans than the SPM-ablated baseline. SPM provides procedural priors that improve planning structure and execution-level tool selection, reducing unnecessary branching and redundant calls. Without SPM, plans become longer and fragmented, with error propagation and imprecise tool-call parameters. Overall, SPM supports transferable procedural structure and improves planning efficiency and execution rigor. Overall, TEM, SKM, and SPM provide complementary support across short-term adaptation, long-term knowledge accumulation, and efficient reasoning execution for sustained improvement. 4. Related Work 4.1. Agentic AI for Scientific Discovery Recent progress in agentic AI has produced systems capable of carrying out increasingly autonomous forms of scientific reasoning. The AI Scientist [1] line of work demonstrates early examples of end to end research automation, with the initial system coordinating hypothesis generation and experiment design, and the later version [2] replacing fixed templates with search based procedure that allows broader exploration of methodological space. AlphaEvolve [3]approaches scientific discovery from an evolutionary perspective by using language models to generate candidate algorithms and iteratively refine them through performance guided optimization. Other recent systems emphasize multi agent coordination within real scientific workflows. AI Co-Scientist [4] distributes literature analysis, hypothesis refinement, and methodological planning across specialized agents directed by central model, while Robin integrates planning, data analysis, and validation into closed loop system capable of discovering new compound candidates without manual intervention. Kosmos [6] further advances this direction by unifying literature retrieval, experiment design, and theory development into continuously running discovery engine. Overall, these efforts illustrate the rapid emergence of autonomous scientific discovery systems and highlight the importance of long horizon reasoning, iterative experimentation, and persistent state management. These themes directly motivate the structured memory mechanisms developed in our work. 28 4.2. Deep Research Agents Recent advances in Deep Research (DR) agents extend LLMs from retrieval-augmented generation to dynamic, tool-driven research workflows. Early systems such as WebGPT [87] and Toolformer [88] explored web and API integration, demonstrating how models can reason over retrieved information while selectively invoking external tools. Building on these ideas, industrial solutions e.g., OpenAI DR [72], Gemini DR [75], Grok DR [89], and Perplexity DR [90], incorporate adaptive planning, iterative retrieval, and multimodal reasoning to support long-horizon research tasks. Recently, singleagent designs (e.g., Search-o1 [91], WebDancer [68], Tongyi DeepResearcher [92], MiroThinker [70]) enable end-to-end optimization within unified reasoning loop, while multi-agent architectures (e.g., AI Scientist [1], Agent Laboratory [93], and InternAgent [7]) offer greater modularity and scalability, which are particularly beneficial for complex research settings. Recent studies, e.g., GeAR [94] and PANGU DeepDiver [95], further demonstrate the value of explicit structures and self-evolving mechanisms for multi-hop reasoning. 4.3. Memory Mechanism Agent memory has become central component of modern agent systems, enabling long-horizon reasoning, continual adaptation, and interaction with complex environments [96]. Recent advances cover token-level mechanisms [97] that extend contextual retention, parametric approaches that internalize accumulated experience into model parameters, and latent-memory systems [98] that store structured trajectories to guide future decisions. In parallel, short-term interaction memory has been explored in conversational and agent-simulation settings, where systems maintain ephemeral contextual traces to support local reasoning over brief episodes [99]. Long-term episodic memory has also been investigated through architectures that accumulate environment interactions across extended horizons and retrieve them for subsequent decisions [48], providing persistent records of agent experience. These techniques enhance an agents mechanisms for incorporating prior information, although they are typically designed for interaction settings with limited temporal scope and therefore remain orthogonal to the multi-stage workflows considered in scientific discovery. 5. Conclusion In this work, we presented InternAgent-1.5, unified system for end-to-end scientific discovery. The framework integrates generation, verification, and evolution into coherent architecture supported by foundational capabilities for deep research, solution refinement, and long horizon memory. This design enables consistent information flow across stages and provides general substrate for cross-disciplinary scientific workflows. Comprehensive evaluations demonstrate that InternAgent-1.5 achieves exhibits strong performance in structured scientific reasoning. The system autonomously produces competitive algorithmic solutions, optimizes experimental proposals over extended trajectories, and executes multi-step computational and empirical workflows. Across algorithmic and empirical domains, InternAgent-1.5 consistently generates outputs that align with established scientific principles and reproduce findings observed in real scientific studies. Future work includes strengthening the coupling between computational reasoning and experimental validation, and accelerating the transition from generated hypotheses to verifiable results. Advancing these directions will further improve the efficiency and reliability of cross-disciplinary scientific discovery."
        },
        {
            "title": "References",
            "content": "[1] Chris Lu et al. The ai scientist: Towards fully automated open-ended scientific discovery. In: arXiv preprint arXiv:2408.06292 (2024). [2] Yutaro Yamada et al. The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search. In: arXiv preprint arXiv:2504.08066 (2025). [3] Alexander Novikov et al. AlphaEvolve: coding agent for scientific and algorithmic discovery. In: arXiv preprint arXiv:2506.13131 (2025). Juraj Gottweis et al. Towards an AI co-scientist. In: arXiv preprint arXiv:2502.18864 (2025). [5] Ali Essam Ghareeb et al. Robin: multi-agent system for automating scientific discovery. In: [4] arXiv preprint arXiv:2505.13400 (2025). [6] Ludovico Mitchener et al. Kosmos: An AI Scientist for Autonomous Discovery. In: arXiv preprint arXiv:2511.02824 (2025). [7] NovelSeek Team et al. NovelSeek: When Agent Becomes the ScientistBuilding Closed-Loop System from Hypothesis to Verification. In: arXiv preprint arXiv:2505.16938 (2025). [8] Hanchen Wang et al. Scientific discovery in the age of artificial intelligence. In: Nature 620.7972 (2023), pp. 4760. [9] Richard Van Noorden and Jeffrey Perkel. AI and science: what 1,600 researchers think. In: [10] [11] Nature 621.7980 (2023), pp. 672675. Josh Abramson et al. Accurate structure prediction of biomolecular interactions with AlphaFold 3. In: Nature 630.8016 (2024), pp. 493500. John Jumper et al. Highly accurate protein structure prediction with AlphaFold. In: nature 596.7873 (2021), pp. 583589. [12] Mihaly Varadi et al. AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models. In: Nucleic acids research 50.D1 (2022), pp. D439D444. [13] Andres M. Bran et al. Augmenting large language models with chemistry tools. In: Nature Machine Intelligence 6.5 (2024), pp. 525535. [14] Zijie Guo et al. EarthLink: Self-Evolving AI Agent for Climate Science. In: arXiv preprint arXiv:2507.17311 (2025). [15] Bernard Jansen, Soon-gyo Jung, and Joni Salminen. Employing large language models in survey research. In: Natural Language Processing Journal 4 (2023), p. 100020. [16] Xiangchao Yan et al. Surveyforge: On the outline heuristics, memory-driven generation, and multi-dimensional evaluation for automated survey writing. In: Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2025, pp. 1244412465. [17] Biqing Qi et al. Large language models are zero shot hypothesis proposers. In: arXiv preprint arXiv:2311.05965 (2023). [18] Biqing Qi et al. Large language models as biomedical hypothesis generators: comprehensive evaluation. In: arXiv preprint arXiv:2407.08940 (2024). [19] Shangheng Du et al. AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents. In: arXiv preprint arXiv:2510.08511 (2025). [20] Yusong Hu et al. FlowSearch: Advancing deep research with dynamic structured knowledge flow. In: arXiv preprint arXiv:2510.08521 (2025). 30 [21] Jiakang Yuan et al. Dolphin: moving towards closed-loop auto-research through thinking, practice, and feedback. In: Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2025, pp. 2176821789. [22] Adib Bazgir, Yuwen Zhang, et al. Agentichypothesis: survey on hypothesis generation using llm systems. In: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation (2025). [23] Mario Bunge. Scientific Research. 2 Volumes. 1967. [24] Tony Hey, Stewart Tansley, Kristin Michele Tolle, et al. The fourth paradigm: data-intensive scientific discovery. Vol. 1. Microsoft research Redmond, WA, 2009. [25] Gr√©goire Mialon et al. Gaia: benchmark for general ai assistants. In: International Conference on Learning Representations (ICLR). 2023. [26] David Rein et al. Gpqa: graduate-level google-proof q&a benchmark. In: First Conference on Language Modeling. 2024. [27] Long Phan et al. Humanitys last exam. In: arXiv preprint arXiv:2501.14249 (2025). [28] OpenAI. FrontierScience: Evaluating AIs Ability To Perform Expert-level Scientific Tasks. https: //openai.com/index/frontierscience/. 2026. [29] Wanghan Xu et al. Probing Scientific General Intelligence of LLMs with Scientist-Aligned [30] Workflows. In: arXiv preprint arXiv:2512.16969 (2025). Ines Chami et al. Low-Dimensional Hyperbolic Knowledge Graph Embeddings. In: Annual Meeting of the Association for Computational Linguistics. 2020, pp. 69016914. [31] Zongsheng Cao et al. DiffusionE: Reasoning on Knowledge Graphs via Diffusion-based Graph Neural Networks. In: ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024, pp. 222230. [32] Yankai Jiang et al. SCP: Accelerating Discovery with Global Web of Autonomous Scientific Agents. In: arXiv preprint arXiv:2512.24189 (2025). [33] Paul Gauthier and Aider-AI Contributors. Aider: AI pair programming in your terminal. https: //github.com/Aider-AI/aider. Accessed: 2025-05-07. 2023. url: https://github. com/Aider-AI/aider. [34] Yixin Ou et al. AutoMind: Adaptive Knowledgeable Agent for Automated Data Science. In: arXiv preprint arXiv:2506.10974 (2025). [35] Damith Perera et al. platform for automated nanomole-scale reaction screening and micromole-scale synthesis in flow. In: Science 359.6374 (2018), pp. 429434. [36] Abhimanyu Dubey et al. The llama 3 herd of models. In: arXiv e-prints (2024), arXiv2407. [37] Thomas Norman et al. Exploring genetic interaction manifolds constructed from rich single-cell phenotypes. In: Science 365.6455 (2019), pp. 786793. [38] Yusuf Roohani, Kexin Huang, and Jure Leskovec. Predicting transcriptional outcomes of novel multigene perturbations with GEARS. In: Nature Biotechnology 42.6 (2024), pp. 927935. [39] Ray Daniel Zimmerman, Carlos Edmundo Murillo-S√°nchez, and Robert John Thomas. MATPOWER: Steady-state operations, planning, and analysis tools for power systems research and education. In: IEEE Transactions on power systems 26.1 (2010), pp. 1219. [40] Zhen Zhao et al. SenseFlow: Physics-Informed and Self-Ensembling Iterative Framework for Power Flow Estimation. In: arXiv preprint arXiv:2505.12302 (2025). 31 [41] Haoyi Zhou et al. Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting. In: The Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Virtual Conference. Vol. 35. 12. AAAI Press, 2021, pp. 1110611115. [42] Ailing Zeng et al. Are transformers effective for time series forecasting? In: Proceedings of the AAAI conference on artificial intelligence. Vol. 37. 9. 2023, pp. 1112111128. [43] Stefan Chmiela et al. Machine learning of accurate energy-conserving molecular force fields. In: Science advances 3.5 (2017), e1603015. [44] Yusong Wang et al. Enhancing geometric representations for molecules with equivariant vector-scalar interactive message passing. In: Nature Communications 15.1 (2024), p. 313. [45] Cosmas Arnold et al. Genome-wide quantitative enhancer activity maps identified by STARR-seq. In: Science 339.6123 (2013), pp. 10741077. [46] Bernardo de Almeida et al. DeepSTARR predicts enhancer activity from DNA sequence and enables the de novo design of synthetic enhancers. In: Nature genetics 54.5 (2022), pp. 613 624. [47] Fengwei Teng et al. Atom of Thoughts for Markov LLM Test-Time Scaling. In: The Thirty-ninth Annual Conference on Neural Information Processing Systems. 2025. [48] Wujiang Xu et al. A-Mem: Agentic Memory for LLM Agents. In: The Thirty-ninth Annual Conference on Neural Information Processing Systems. 2025. url: https://openreview. net/forum?id=FiM0M8gcct. [49] Zheng Cai et al. InternLM2 Technical Report. 2024. arXiv: 2403.17297 [cs.CL]. [50] Jia Li et al. Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions. In: Hugging Face repository 13.9 (2024), p. 9. [51] Yuxin Zuo et al. TTRL: Test-Time Reinforcement Learning. In: The Thirty-ninth Annual Conference on Neural Information Processing Systems. 2025. url: https://openreview.net/ forum ? id = VuVhgEiu20 & referrer = %5Bthe % 20profile % 20of % 20Bowen % 20Zhou % 5D(%2Fprofile%3Fid%3DBowen_Zhou8). [52] Veronika Eyring et al. Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization. In: Geoscientific Model Development 9.5 (2016), pp. 19371958. [53] Hans Hersbach et al. ERA5 monthly averaged data on single levels from 1979 to present. In: Copernicus Climate Change Service (C3S) Climate Data Store (CDS) 10 (2019), pp. 252266. [54] Eugenia Kalnay et al. The NCEP/NCAR 40-year reanalysis project. In: Renewable energy. Routledge, 2018, Vol1_146Vol1_194. [55] Tomislav Hengl, Gerard BM Heuvelink, and David Rossiter. About regression-kriging: From equations to case studies. In: Computers & geosciences 33.10 (2007), pp. 13011315. [56] Andrew Wood et al. Long-range experimental hydrologic forecasting for the eastern United States. In: Journal of Geophysical Research: Atmospheres 107.D20 (2002), ACL6. [57] Katarzyna Tomczak, Patrycja Czerwi≈Ñska, and Maciej Wiznerowicz. Review The Cancer Genome Atlas (TCGA): an immeasurable source of knowledge. In: Contemporary Oncology/Wsp√≥≈Çczesna Onkologia 2015.1 (2015), pp. 6877. [58] Denise Carvalho-Silva et al. Open Targets Platform: new developments and updates two years on. In: Nucleic acids research 47.D1 (2019), pp. D1056D1065. [59] Minoru Kanehisa. The KEGG database. In: In silicosimulation of biological processes: Novartis Foundation Symposium 247. Vol. 247. Wiley Online Library. 2002, pp. 91103. 32 [60] Alexander Rives et al. Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences. In: PNAS (2019). doi: 10.1101/622803. url: https://www.biorxiv.org/content/10.1101/622803v4. [61] Mingchen Li et al. ProSST: Protein Language Modeling with Quantized Structure and Disentangled Attention. In: The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024. [62] Hao Li et al. Beyond Chemical QA: Evaluating LLMs Chemical Reasoning with Modular Chemical Operations. In: arXiv preprint arXiv:2505.21318 (2025). [63] Gemini 3 Pro - Google DeepMind. url: https://deepmind.google/models/gemini/ pro/. [64] OpenAI. ChatGPT (GPT-5). 2025. url: https://chat.openai.com/. [65] Introducing Claude Sonnet 4.5. en. url: https://www.anthropic.com/news/claudesonnet-4-5. [66] An Yang et al. Qwen3 technical report. In: arXiv preprint arXiv:2505.09388 (2025). [67] Introducing OpenAI o3 and o4-mini. en-US. url: https : / / openai . com / index / introducing-o3-and-o4-mini/. Jialong Wu et al. WebDancer: Towards Autonomous Information Seeking Agency. In: arXiv preprint arXiv:2505.22648 (2025). [68] [69] Zhengwei Tao et al. Webshaper: Agentically data synthesizing via information-seeking formalization. In: arXiv preprint arXiv:2507.15061 (2025). [70] MiroMind Team et al. MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling. In: arXiv preprint arXiv:2511.11793 (2025). [71] Tongyi DeepResearch Team et al. Tongyi DeepResearch Technical Report. In: arXiv preprint arXiv:2510.24701 (2025). [72] OpenAI. Deep Research System Card. https : / / cdn . openai . com / deep - research - system-card.pdf. 2025. [73] Moonshot AI. Kimi-Researcher: End-to-End Reinforcement Learning for Emerging Agentic Capabilities. https://moonshotai.github.io/Kimi-Researcher/. Accessed: 2025-XX-XX. 2025. [74] Manus. https://manus.im/. 2025. [75] Google. Introducing Gemini Deep Research. https://blog.google/products/gemini/ google-gemini-deep-research/. 2024. [76] Mengkang Hu et al. OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation. 2025. arXiv: 2505.23885 [cs.AI]. [77] Daya Guo et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. In: arXiv preprint arXiv:2501.12948 (2025). [78] Lei Bai et al. Intern-s1: scientific multimodal foundation model. In: arXiv preprint arXiv:2508.15763 (2025). [79] Aixin Liu et al. Deepseek-v3. 2: Pushing the frontier of open large language models. In: arXiv preprint arXiv:2512.02556 (2025). [80] MiroMind AI Team. MiroFlow: High-Performance Open-Source Research Agent Framework. https://github.com/MiroMindAI/MiroFlow. 2025. 33 [81] Qihao Zhao et al. Mmlu-cf: contamination-free multi-task language understanding benchmark. In: Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2025, pp. 1337113391. [82] Adyasha Maharana et al. Evaluating very long-term conversational memory of llm agents. In: arXiv preprint arXiv:2402.17753 (2024). [83] Zhongyue Zhang et al. OriGene: Self-Evolving Virtual Disease Biologist Automating Therapeutic Target Discovery. In: bioRxiv (2025). [84] David Weininger. SMILES, chemical language and information system. 1. Introduction to methodology and encoding rules. In: Journal of chemical information and computer sciences 28.1 (1988), pp. 3136. [85] Greg Landrum. Rdkit documentation. In: Release 1.1-79 (2013), p. 4. [86] Ondrej Kovar et al. Scaffold Hopping in Tuberculosis Drug Discovery: Principles, Applications, and Case Studies. In: Journal of Medicinal Chemistry 68.20 (2025), pp. 2090320929. [87] Reiichiro Nakano et al. Webgpt: Browser-assisted question-answering with human feedback. In: arXiv preprint arXiv:2112.09332 (2021). [88] Timo Schick et al. Toolformer: Language models can teach themselves to use tools. In: [89] Advances in Neural Information Processing Systems (NeurIPS) (2023). xAI. Grok-3 DeepSearch: Synthesizing Key Information to Distill Clarity from Complexity. https: //x.ai/news/grok-3. 2025. [90] Perplexity. Perplexity Deep Research. https://www.perplexity.ai/. 2025. [91] Xiaoxi Li et al. Search-o1: Agentic search-enhanced large reasoning models. In: arXiv preprint arXiv:2501.05366 (2025). [92] Zile Qiao et al. WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents. In: arXiv preprint arXiv:2509.13309 (2025). [93] Samuel Schmidgall et al. Agent laboratory: Using llm agents as research assistants. In: arXiv preprint arXiv:2501.04227 (2025). [94] Zhili Shen et al. GeAR: Graph-enhanced Agent for Retrieval-augmented Generation. In: arXiv preprint arXiv:2412.18431 (2024). [95] Wenxuan Shi et al. Pangu DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning. In: arXiv preprint arXiv:2505.24332 (2025). [96] Yuyang Hu et al. Memory in the Age of AI Agents. In: arXiv preprint arXiv:2512.13564 (2025). [97] Yuhuai Wu et al. Memorizing Transformers. In: International Conference on Learning Representations. [98] Weizhi Wang et al. Augmenting language models with long-term memory. In: Advances in [99] Neural Information Processing Systems 36 (2023), pp. 7453074543. Joon Sung Park et al. Generative agents: Interactive simulacra of human behavior. In: Proceedings of the 36th annual acm symposium on user interface software and technology. 2023, pp. 122. 34 A. Appendix A.1. Contributions and Acknowledgments Lead Authors Shiyang Feng1, Runmin Ma1, Xiangchao Yan Core Authors Yue Fan1, Yusong Hu1,6, Songtao Huang1,2, Shuaiyu Zhang1,2, Zongsheng Cao1, Tianshuo Peng1,4, Jiakang Yuan1,2, Zijie Guo1,2, Zhijie Zhong1, Shangheng Du1,5, Weida Wang1,2, Jinxin Shi1,5, Yuhao Zhou1 Contributors Xiaohan He, Zhiyin Yu, Fangchen Yu, Bihao Zhan, Qihao Zheng, Jiamin Wu, Mianxin Liu, Chi Zhang, Shaowei Hou, Shuya Li, Yankai Jiang, Wenjie Lou, Lilong Wang, Zifu Wang, Jiong Wang, Wanghan Xu, Yue Deng, Dongrui Liu, Yiheng Wang Scientific Directors Wenlong Zhang1, Fenghua Ling1, Shufei Zhang1, Xiaosong Wang1, Shuangjia Zheng3, Xun Huang3, Siqi Sun1,2, Shuyue Hu1, Peng Ye1,4, Chunfeng Song1, Bin Wang1, Conghui He1, Yihao Liu1, Xin Li1, Qibin Hou6, Tao Chen2, Xiangyu Yue1,4, Bin Wang2, Liang He1,5, Dahua Lin1, Bowen Zhou1 Corresponding Authors Bo Zhang1, zhangbo@pjlab.org.cn Lei Bai1, bailei@pjlab.org.cn"
        },
        {
            "title": "Main Affiliations",
            "content": "1 Shanghai Artificial Intelligence Laboratory 2 Fudan University 3 Lingang Laboratory 4 The Chinese University of Hong Kong 5 East China Normal University 6 Nankai University 35 A.2. Earth Science example Report Generated All by InternAgent-1.5 36 38 39 40 41 42 44 45 46 47 48 50 51 52 53 54 56 57 58 59 60 62"
        }
    ],
    "affiliations": [
        "Shanghai Artificial Intelligence Laboratory"
    ]
}