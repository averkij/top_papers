{
    "paper_title": "ELTEX: A Framework for Domain-Driven Synthetic Data Generation",
    "authors": [
        "Arina Razmyslovich",
        "Kseniia Murasheva",
        "Sofia Sedlova",
        "Julien Capitaine",
        "Eugene Dmitriev"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We present ELTEX (Efficient LLM Token Extraction), a domain-driven framework for generating high-quality synthetic training data in specialized domains. While Large Language Models (LLMs) have shown impressive general capabilities, their performance in specialized domains like cybersecurity remains limited by the scarcity of domain-specific training data. ELTEX addresses this challenge by systematically integrating explicit domain indicator extraction with dynamic prompting to preserve critical domain knowledge throughout the generation process. We demonstrate ELTEX's effectiveness in the context of blockchain-related cyberattack detection, where we fine-tune Gemma-2B using various combinations of real and ELTEX-generated data. Our results show that the ELTEX-enhanced model achieves performance competitive with GPT-4 across both standard classification metrics and uncertainty calibration, while requiring significantly fewer computational resources. We release a curated synthetic dataset of social media texts for cyberattack detection in blockchain. Our work demonstrates that domain-driven synthetic data generation can effectively bridge the performance gap between resource-efficient models and larger architectures in specialized domains."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 1 ] . [ 1 5 5 0 5 1 . 3 0 5 2 : r ELTEX: Framework for Domain-Driven Synthetic Data Generation Arina Razmyslovich1, Kseniia Murasheva1, Sofia Sedlova2, Julien Capitaine2, Eugene Dmitriev1 1Distributed Networks Institute (DNI), 2 Technologies Mésozoïques Correspondence: arina.razmyslovich@dn.institute"
        },
        {
            "title": "Abstract",
            "content": "We present ELTEX (Efficient LLM Token Extraction), domain-driven framework for generating high-quality synthetic training data in specialized domains. While Large Language Models (LLMs) have shown impressive general capabilities, their performance in specialized domains like cybersecurity remains limited by the scarcity of domain-specific training data. ELTEX addresses this challenge by systematically integrating explicit domain indicator extraction with dynamic prompting to preserve critical domain knowledge throughout the generation process. We demonstrate ELTEXs effectiveness in the context of blockchain-related cyberattack detection, where we fine-tune Gemma2B using various combinations of real and ELTEX-generated data. Our results show that the ELTEX-enhanced model achieves performance competitive with GPT-4 across both standard classification metrics and uncertainty calibration, while requiring significantly fewer computational resources. We release curated synthetic dataset of social media texts for cyberattack detection in blockchain. Our work demonstrates that domain-driven synthetic data generation can effectively bridge the performance gap between resource-efficient models and larger architectures in specialized domains."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) have achieved state-of-the-art performance across various tasks, extending beyond traditional language processing (MMLU-Pro (Wang et al., 2024), LiveCodeBench; (Jain et al., 2024)), yet adapting them to specialized domains remains challenging (Ling et al., 2024). This limitation is particularly evident in cybersecurity, where benchmarks such as CyberBench (Liu et al., 2024) reveal that even state-of-the-art LLMs (e.g., GPT-4) struggle with domain-specific tasks, including cyber-threat named entity recognition and risk mitigation planning. 1 Early signals of emerging cyberattacks frequently appear in unstructured natural language channels: social media platforms, dark web forums, and technical communities, long before they are formally documented in vulnerability databases (Paladini et al., 2024; Almukaynizi et al., 2017; Khandpur et al., 2017). This makes NLP crucial in cyber threat intelligence, as it enables the collection and analysis of evidence-based indicators of compromise to identify and mitigate emerging attacks (Arazzi et al., 2023; Sufi, 2023). While social media platforms provide abundant cybersecurity-related data, recent studies highlight significant challenges in data quality, including duplicate content (Mu et al., 2024), inconsistent labeling (Zong et al., 2019), and limited coverage of diverse attack types (Almahmoud et al., 2023). In response, LLM-based synthetic data generation, has emerged as promising solution (Li et al., 2023), offering potential for overcoming data quality issues while preserving privacy and domain validity. Existing approaches to synthetic data generation have primarily relied on implicit knowledge transfer through few-shot examples or post-generation validation (Patil and Gudivada, 2024). Recent advances have introduced more sophisticated methodologies: UniGen (Wu et al., 2024) implements attribute-guided generation with RAG-based validation, while CRAFT (Ziegler et al., 2024) employs corpus-based retrieval with few-shot learning. Despite these advances, these methods still face challenges in extracting and preserving domain-specific knowledge. We address this gap with Efficient LLM Token Extraction (ELTEX), domain-driven framework that systematically integrates explicit domain indicator extraction with dynamic prompting. ELTEX preserves critical domain nuances throughout the generation process. While we demonstrate ELTEXs effectiveness through text classification of blockchain-related cyberattack discussions on social media, the frameworks methodology is potentially generalizable to other specialized domains. To validate ELTEX, we fine-tune Gemma-2B (Team et al., 2024b) using various combinations of real and ELTEX-generated data. We demonstrate that our domain-driven approach enables this lightweight model to achieve performance competitive with GPT-4o (OpenAI, 2023) across both standard classification metrics and uncertainty calibration measured by the Brier score (Brier, 1950), while requiring significantly fewer computational resources. Our main contributions are as follows: 1. Domain-Driven Synthetic Data Generation. We propose ELTEX, framework that systematically integrates explicit domain indicator extraction with dynamic prompt refinement to generate high-fidelity, context-grounded synthetic data. 2. Downstream Evaluation. Through finetuning experiments on Gemma-2B, we demonstrate that domain-driven synthetic data can bridge the performance gap between resourceefficient models and larger architectures in specialized domains. 3. Released Synthetic Dataset. We release carefully curated synthetic dataset of 11,448 social media texts for cyberattack detection in blockchain."
        },
        {
            "title": "2.1 Domain-Adapted Small Models",
            "content": "While large-scale models (e.g., GPT-4) offer strong general performance, recent benchmarks such as CyberBench (Liu et al., 2024) reveal that finetuned, smaller models can rival or even surpass their larger counterparts in cybersecurity-specific tasks. For instance, Llama-2-13B fine-tuned with CyberInstruct surpasses GPT-4 in certain metrics (e.g., 72.6 vs. 63.0 for common vulnerabilities and exposures accuracy). These findings demonstrate that domain-adapted smaller models can match larger ones, motivating our choice to explore more compact models capabilities through Gemma-2B. Smaller domainadapted models offer practical advantages for deployment, particularly when enhanced with techniques like LoRA for domain adaptation. This 1The dataset is available on HuggingFace approach addresses key requirements in cybersecurity applications where privacy constraints and real-time monitoring demands necessitate efficient, local inference capabilities. 2.2 LLMs for Cyber Threat Intelligence LLMs have recently attracted attention for automated threat intelligence, vulnerability detection, and anomaly analysis (Perrina et al., 2023; Cheshkov et al., 2023; Karlsen et al., 2024). Despite their potential, three interrelated obstacles hinder their deployment in cybersecurity: 1. Rapid Domain Drift: Emerging cyber threats can render previously trained models obsolete (Cremer et al., 2022). Attack vectors evolve faster than in many other NLP settings, forcing frequent re-training or advanced domainadaptation strategies to maintain relevance. 2. Data Volume and Velocity: The sheer scale of social media demands computationally efficient real-time analysis (Zhou et al., 2024). High-volume API-based LLM inference can lead to unsustainable costs and latency issues. 3. Privacy and Proprietary Constraints: Third-party LLM APIs pose privacy risks (Yan et al., 2024), making local or on-premise solutions appealing for many organizations. However, smaller local models may initially underperform without domain-specific adaptation. Recent research tackles these barriers through two complementary approaches: (i) high-fidelity synthetic data generation to alleviate domainspecific data scarcity and keep pace with emerging threats (Ferrag et al., 2024), and (ii) compact model architectures (e.g., Microsofts phi-3-mini (Abdin et al., 2024)), which can be deployed locally to reduce inference costs, preserve privacy, and facilitate real-time monitoring."
        },
        {
            "title": "2.3 LLM-based Synthetic Data Generation",
            "content": "for Domain-Specific Tasks The effectiveness of domain adaptation and small models heavily depends on the quality and availability of training data. Social media sources complicate this need: duplicated content, inconsistent terminology, and topical imbalances frequently undermine data reliability (Mu et al., 2024; Zong et al., 2019; Almahmoud et al., 2023). Coupled 2 with the rapid evolution of cyber threats, manual dataset curation and continuous updates become prohibitively difficult. LLM-based synthetic data generation offers promising workaround by producing privacy-preserving samples rich in domainspecific details. Conventional approaches rely on heuristic prompts that combine task specifications, generation conditions, and in-context examples to drive LLM output (Long et al., 2024). For more intricate datasets, multi-step generation techniques decompose the process into manageable subtasks. Frameworks, such as UniGen (Wu et al., 2024) and CRAFT (Ziegler et al., 2024), have aimed to streamline synthetic data generation, though each faces distinct challenges in knowledge-intensive domains. UniGen provides unified approach to generating diverse datasets. CRAFT leverages corpus retrieval and LLM augmentation to synthesize task-specific data from few-shot examples, demonstrating success in QA and summarization tasks. However, these frameworks face limitations in knowledge-intensive domains: UniGen struggles with specialized knowledge retention, and CRAFTs reliance on public web corpora limits its efficacy for cybersecurity where domain-specific data is scarce and sensitive. Our proposed ELTEX framework builds on these foundations and bridges the gap by systematically extracting and integrating explicit domain knowledge, particularly benefiting knowledge-intensive applications where existing approaches fall short."
        },
        {
            "title": "3 ELTEX Framework",
            "content": "ELTEX, as illustrated in Figure 1, consists of five main components: (1) sample data collection and deduplication, (2) token extraction prompt construction, (3) synthetic data generation, (4) final deduplication and (5) post-generation quality assurance (QA)."
        },
        {
            "title": "3.1 Data Collection",
            "content": "Data Sources and Collection Our research focused on creating dataset specifically for the classification of social media messages related to cyberattacks in the blockchain industry. By utilizing the official API (v2) provided by (formerly known as Twitter) (X, 2025), we obtained data on cyberattacks and general topics from the past three years within the blockchain ecosystem. We curated list of documented cyberattacks on various blockchain participants to systematically target relevant events. Figure 1: Efficient LLM Token Extraction Pipeline For each entry in this list, we defined search window around the reported start date to capture discussions that potentially reflect early indicators or live commentary on the attack (see 4.1 for attack types distribution). Overall, we retrieved 1,766 real data samples (see Table 1 for detailed statistics throughout the pipeline). This initial dataset captures both highsignal messages linked to specific attacks and broader blockchain discussions that do not pertain to cyberattacks."
        },
        {
            "title": "All data collection procedures were conducted",
            "content": "according to ethical guidelines (see Section 6). Annotation Process Collected messages underwent two-stage annotation process: 1. Preliminary Annotation: GPT-4o (version August 6, 2024) generated classification scores ranging from 0 to 1 using the predefined prompt. 2. Human Review: In-house annotators refined labels, guided by model-provided scores. The full annotation process, including the prompt and validation methods, is detailed in Appendix B. Deduplication Process To ensure data diversity, annotated messages were deduplicated using similarity threshold of 0.9 (See Section 3.6). This 3 threshold was selected based on experimental results (detailed in Appendix D) to balance diversity preservation with duplicate removal. The process reduced cyberattack messages by 11.8% and general messages by 5.2% (see Table 1). 3.2 Token Extraction Prompt Construction To effectively guide GPT-4o (version August 6, 2024) in generating domain-relevant tokens for early cyberattack detection, we designed specialized extraction prompt. The prompt integrates instructions on the expected output format, along with curated lists of potential cyberattack indicators and concise examples of social media messages. Our approach is inspired by recent work on training data extraction from language models (Yu et al., 2023), which demonstrates that carefully engineered prompts can coax latent training information from model. Building on these insights, we focused on extracting key domain-specific tokens for cyberattacks in blockchain. Indicator Generation and Validation The process of generating and validating indicators consists of the following steps: 1. Initial Indicator Compilation: Query multiple LLMs (e.g., GPT-4o, Claude 3.5 (Anthropic, 2023), Gemini 1.5 (Team et al., 2024a)) to generate broad list of candidate indicators, such as suspicious transaction volume spikes or compromised private keys. Using multiple models ensures comprehensive coverage, as each model may introduce unique terminology or previously overlooked signals. 2. Summarization and Refinement: Iteratively summarize and consolidate the initial indicator list to merge semantically similar items and remove redundancies. This process leverages LLMs to distill the most relevant indicators while reducing noise, minimizing the need for extensive human expert review. 3. Stabilization and Validation: Perform two to three summarization iterations until the indicator list stabilizes. The final set is then reviewed for relevance and accuracy, ensuring alignment with domain-specific requirements. Final Prompt Construction We structured the final prompt to include: 1. Task Description & Critical Instructions: Outlining the goal of generating early warning messages for potential cyberattacks and specifying constraints (e.g., anonymizing nongovernment entities). 2. Indicators List: condensed set of validated attack indicators, guiding the models attention to relevant signals. 3. In-Context Examples: Real, anonymized social media messages. By leveraging these elements within the ELTEX pipeline, we reduce reliance on time-consuming expert consultations and systematically incorporate both broad linguistic knowledge from LLMs and domain-specific insights. detailed example of the constructed prompt, along with broader discussion of indicator generation and multi-LLM fusion, is provided in Appendix A."
        },
        {
            "title": "3.3 Synthetic Data Generation",
            "content": "We employed the GPT-4o (version August 6, 2024) model via the Azure OpenAI API (version 2024-0501-preview) (Microsoft, 2025) to generate domainrelevant synthetic data for early cyberattack detection. While GPT-4o was selected for its status as flagship LLM at the time, ELTEX is designed to be compatible with any large-scale language model that offers high-quality generation and recent knowledge cut-off date, allowing users to choose the most suitable provider and model based on their specific needs. Batching and Prompting The generation process began by shuffling and batching real data samples into groups of 10 messages. Each batch was paired with predefined ELTEX prompt, and for every API request, the model was configured to generate 100 synthetic messages. Due to the stochastic nature of LLM generation, the actual number of messages per request could slightly vary. To ensure efficient downstream processing, we utilized the APIs structured output feature (OpenAI, n.d.), receiving the synthetic results in JSON array. This process resulted in approximately 16,030 initial synthetic samples. For more detailed insights into this process, refer to Appendix A. Temperature Settings The models generation temperature was set to 0.8. Although varying the 3.5 Post-generation QA We performed an additional QA step using NotebookLM (Google, 2025) to eliminate misclassified messages. NotebookLM was chosen for its advanced RAG capabilities, which effectively filter out irrelevant messages. Specifically, we uploaded the generated synthetic dataset to NotebookLM and instructed the LLM to identify and flag any contextually irrelevant content to its respective topic. The flagged messages were iteratively removed until no further content was detected that deviated from the predefined criteria. This approach can be adapted to any domain by specifying custom irrelevant text patterns. The final synthetic dataset contained 11,448 entries, as shown in Table 1. Dataset Real (Initial) Real (Dedup) Synthetic (Initial)* Synthetic (Dedup) Synthetic (Final) Cyberattack General 688 652 6,520 4,524 4,507 1,078 951 9,510 6,941 6,941 Total 1,766 1,603 16,030 11,465 11, Table 1: Datasets statistics throughout the pipeline. *Initial synthetic count is approximate due to the stochastic nature of LLM generation. cost analysis of the GPT-4o-based synthetic data generation pipeline, including token usage, is provided in Appendix F. Clustering Analysis We performed semantic clustering using the k-means algorithm (MacQueen, 1967) on the embeddings of cyberattackrelated messages. The optimal number of clusters (k = 10) was determined through silhouette score optimization, although the smooth elbow curve suggested no distinct natural clustering tendency in the embedding space. This indicates that the selection of should be viewed as an analytical convenience rather than reflection of inherent semantic boundaries. We visualized the resulting clusters using UMAP. In the real dataset, clusters were distinct and often aligned with specific incidents (e.g., Euler Finance exploit, Poloniex hack). Prominent keywords such as million, hack, and platformspecific terms suggested strong event alignment, though some overlap reflected the semantically rich nature of real data. In the synthetic dataset, clusters were more diffuse, with overlap and elongated structures, indicating broad but less incidentspecific coverage. Keyword analysis highlighted Figure 2: Comparison of Self-BLEU Scores between Generated and Original Data. temperature between 0.0 and 1.0 resulted in only moderate changes in the overall diversity of generated messages, the deduplication process revealed important practical implications. At lower temperatures (0.00.6), applying 0.9 similarity threshold reduced the final dataset by 50% or more, risking the loss of important thematic signals. In contrast, higher temperatures (0.91.0) often produced outputs that deviated from the desired format. Therefore, temperature of 0.8 was selected to retain sufficiently large and diverse dataset. Detailed results, including retention rates at different temperature settings, are provided in Appendix D."
        },
        {
            "title": "3.4 Deduplication Process",
            "content": "All newly generated messages underwent deduplication step based on embedding similarity before storage in database (See Section 3.6). We adopted similarity threshold of 0.9, with messages exceeding this threshold considered duplicates or near-duplicates. Experiments exploring alternative thresholds (e.g., 0.8) are detailed in Appendix D. While lower thresholds increase lexical and semantic diversity, they may inadvertently remove valuable linguistic nuances. Striking an optimal balance between diversity and utility remains subject for future research. After applying the 0.9 threshold, we retained 11,465 messages (approximately 71.5% of the initially generated data). The synthetic data exhibits self-BLEU scores (µ = 0.2831, σ = 0.1791) comparable to the original messages, demonstrating ELTEXs ability to generate diverse outputs while maintaining domain relevance (see Figure 2) (Zhu et al., 2018). 5 additional abstract indicators such as transaction, breach, alert, and phishing not common in real data. While these broader terms captured potential cyberattacks, they lacked the event-specific nuance of the real dataset. These findings suggest real data preserves detailed, incident-specific features, whereas synthetic data captures wider array of abstract indicators. hybrid dataset could combine these strengths, motivating our fine-tuning of Gemma-2B on combined real and synthetic samples for enhanced cybersecurity domain adaptation. Complete clustering results and visualizations are provided in Appendix D. 3.6 Deduplication Methodology Our deduplication pipeline (details in Appendix E) employs two-stage process to ensure data quality and diversity. First, exact-match filtering removes verbatim duplicates within each batch. Next, each message is embedded using the BGE-base-en-v1.5 model (Xiao et al., 2023) and compared against existing embeddings via cosine similarity. Messages are retained only if their highest similarity score falls below set threshold (e.g., 0.9). This strategy effectively filters near-duplicates while preserving meaningful variations without incurring excessive computational costs."
        },
        {
            "title": "4.1 Dataset Construction",
            "content": "Our training pipeline leverages the dataset of 1,603 real-world social media messages, which we first split into training (80%) and validation (20%) sets. Using ELTEX, we expanded only the training portion into synthetic dataset of 8,892 messages (5,530 cyberattack, 3,362 general), with generated classification scores ranging from 0 to 1. We maintained the original classdistribution while introducing diverse attack scenarios. This approach ensures no data leakage between the validation set and synthetic data generation. models generalization capabilities, we curated training and and test datasets that maintain temporal separation and cover diverse attack vectors. In total, we collected an independent test set of 398 real-world messages (206 labeled as cyberattack and 192 as general), drawn from entirely distinct attack events not present in our training data. Table 2 shows the distribution of primary attack types across both training and test sets, illustrating our focus on broad range of scenarios (e.g., DeFi exploits, wallet breaches, social engineering) to ensure robust evaluation 4.2 Task Complexity Our setup addresses two key challenges in realworld blockchain security monitoring. First, the model must process multiple messages simultaneously, outputting batch classifications of 10 messages to support high-throughput monitoring scenarios. Second, the model produces calibrated risk scores between 0 and 1, rather than discrete classification, enabling evaluation via Brier score to assess both discrimination and calibration. These scores are returned in structured JSON format (e.g., {\"1\": 0.9, \"2\": 0.1}). 4.3 Fine-Tuning and Deployment We fine-tuned Gemma-2B using PEFT (Mangrulkar et al., 2022) via LoRA (Hu et al., 2022) while maintaining high computational efficiency through quantization (see Appendix for full finetuning and deployment specifications)."
        },
        {
            "title": "5 Results",
            "content": "This section presents our evaluation of various models on the cybersecurity implication detection task, where each model classifies social media messages for potential blockchain attack relevance using 0-1 scoring system. We first analyze overall performance across standard metrics, then examine the effectiveness of synthetic data, and finally provide comparative analysis with models designed for different objectives. Table 3 summarizes the performance metrics for all evaluated models: the base Gemma-2B model, fine-tuned variants (on real data, synthetic data, and hybrid approach), and comparative benchmarks including GPT-4o, the general-purpose reasoning model Granite-3.2-2B (IBM, 2025), and cybersecurity-focused LLMs fine-tuned on the Primus dataset (Yu et al., 2025)."
        },
        {
            "title": "5.1 Overall Performance Analysis",
            "content": "Our results show significant performance improvements through fine-tuning, with the hybrid approach (combining synthetic and real data) achieving the best results among our Gemma-2B variants. The base Gemma-2B model shows limited effectiveness (0.51 accuracy, 0.30 F1), while the hybrid model achieves performance (0.82 accuracy, 0.81 F1) competitive with the much larger GPT-4o (0.84 accuracy, 0.81 F1). 6 Primary Attack Type Training Set (Pre-May 2024) Test Set (May 24Jan 25) Social Engineering & Phishing Credential theft, wallet phishing Email compromise, custodian impersonation Smart Contract Exploits Token claim vulnerabilities, flash loans Token sale exploits, parameter manipulation Exchange Security Breaches Hot wallet compromises, key theft System access exploits, API vulnerabilities DeFi Protocol Attacks Liquidity pool manipulation, bridge exploits Cross-chain vulnerabilities, protocol exploits Table 2: Distribution of primary attack types across training (1,603 messages) and test (398 messages) sets. Model Performance Metrics Error Rates Acc. Brier Recall F1 ROC False Pos. False Neg. Gemma-2b-it Gemma-2b-Real Gemma-2b-Synth Gemma-2b-Hybrid Granite-3.2-2b-Instruct Llama-Primus-Instruct Llama-Primus-Merged GPT-4o 0.51 0.65 0.77 0.82 0.74 0.71 0.76 0.84 0.43 0.31 0.16 0.14 0.39 0.29 0.23 0.10 0.30 0.47 0.78 0.79 0.58 0.43 0.59 0.71 0.30 0.61 0.76 0.81 0.68 0.58 0.70 0.81 0.44 0.73 0.85 0.88 0.73 0.69 0.76 0.94 0.24 0.03 0.13 0.08 0.06 0.03 0.04 0. 0.25 0.32 0.11 0.10 0.20 0.27 0.19 0.14 Table 3: Performance on social media cyberattack detection. Metrics reflect model ability to score messages (0-1) for blockchain attack relevance. Best scores in bold, second-best underlined. The Brier score, which measures both calibration and accuracy of probabilistic predictions (lower is better), shows that synthetic-trained models (0.140.16) are better calibrated than other variants in our evaluation (0.23-0.43). This suggests that our synthetic data approach improves classification accuracy and helps models produce more reliable confidence estimates, which is crucial for applications requiring well-calibrated risk assessments. For context, the Brier score represents the mean squared difference between predicted probabilities and actual outcomes, with perfect predictions scoring 0 and worst possible predictions scoring 1."
        },
        {
            "title": "5.2 Synthetic Data Effectiveness",
            "content": "Domain Adaptation The substantial improvement from the base Gemma-2b (0.51 accuracy) to the hybrid model (0.82 accuracy) demonstrates synthetic datas value for adapting models to informal cybersecurity discourse. Our ELTEX-generated examples appear to help models recognize patterns characteristic of social media discussions about blockchain security, including veiled threats and technical jargon that may indicate potential attack vectors. trade-offs. Models trained solely on real data show low false positive rates (0.03) but miss many actual threats (0.32 false negative rate). In contrast, synthetic-trained models show improved threat detection (0.10-0.11 false negative rates) at the expense of slightly higher false positives (0.08-0.13). This suggests synthetic data helps capture wider range of threat expressions, potentially beneficial for early warning systems where failing to detect threats carries higher costs than false alarms. Complementary Training Effects The hybrid approach combining synthetic and real data achieves the best overall performance (0.82 accuracy, 0.14 Brier score), outperforming both individual training approaches. This finding aligns with recent research by Li et al. (2024), who observed that combining synthetic and real data often improves both performance and training stability. The complementary nature of these data sources likely helps the model generalize across both common and rare threat expressions while maintaining reasonable precision."
        },
        {
            "title": "Model Types",
            "content": "Error Profile Analysis The different error profiles across training approaches reveal important"
        },
        {
            "title": "We include results from models with different\ndesign objectives to contextualize our approach",
            "content": "7 within the broader language model landscape. These comparisons are not intended as direct competitive benchmarks but rather to understand how different model architectures and training approaches perform on this specialized task. GPT-4o serves as performance ceiling (0.84 accuracy, 0.10 Brier score), demonstrating whats achievable with state-of-the-art large-scale model. Notably, our hybrid Gemma-2B model achieves the same F1 score (0.81) as GPT-4o despite having significantly fewer parameters, suggesting that targeted fine-tuning can partially compensate for model scale on specialized tasks. The cybersecurity-focused Primus models (0.710.76 accuracy) provide context on how domainspecific training transfers to our particular task. While these models show strong general cybersecurity knowledge, their performance on social media threat detection suggests that domain knowledge alone is insufficient without task-specific tuning. Similarly, Granite-3.2-2B (0.74 accuracy, 0.39 Brier score), known for cybersecurity capabilities, performs reasonably well on classification accuracy but shows poorer calibration. This indicates that general cybersecurity abilities provide some transfer to specialized tasks, but well-calibrated confidence estimates may require more targeted training. These results suggest that for specialized applications like blockchain threat detection in social media, combination of targeted synthetic data generation and fine-tuning can enable smaller models to achieve performance comparable to much larger general-purpose models on key metrics."
        },
        {
            "title": "6 Conclusion",
            "content": "We introduced ELTEX, domain-driven framework for generating synthetic training data that enables effective adaptation of smaller language models to specialized domains. Our results highlight three key findings: (1) ELTEXs systematic token extraction approach produces high-quality synthetic data that captures diverse attack patterns while maintaining domain validity, (2) the integration of domain-specific indicators in synthetic data generation leads to better coverage of potential threats, reducing false negatives without significantly increasing false positives, and (3) our domain-driven approach enables resource-efficient models to achieve performance competitive with larger architectures while maintaining strong calibration."
        },
        {
            "title": "Limitations",
            "content": "While ELTEX demonstrates promising results in domain adaptation for cybersecurity and offers unique advantages through synthetic data generation particularly in providing comprehensive topic coverage and modernizing historical data several important limitations warrant discussion: Data Dependencies and Scalability ELTEX requires an initial corpus of high-quality, real-world data to seed the synthetic data generation process. Consequently, the quality and diversity of the synthetic output are inherently tied to the representativeness of this seed data, which may limit ELTEXs applicability in domains where even minimal real data is challenging to obtain or validate. Moreover, while our experiments confirm ELTEXs effectiveness at moderate scales, its performance and computational efficiency have not been validated on significantly larger datasets (e.g., exceeding 100,000 samples). The multi-stage token extraction and deduplication processes could exhibit non-linear increases in computational cost, potentially hindering scalability in high-volume applications. Model Dependencies and Reproducibility The current implementation of ELTEX heavily leverages GPT-4o for synthetic data generation. This introduces several concerns: Version Dependencies: Updates or changes in GPT-4o could alter generation patterns, complicating reproducibility and longitudinal studies. Access Constraints and Costs: API access limitations and associated costs may restrict the frameworks broader adoption, particularly in resource-constrained settings. Propagation of Biases: Any inherent biases or limitations present in GPT-4o can be transferred to the synthetic data, potentially affecting downstream model performance. Classification Score Granularity: While GPT-4o generates continuous classification scores (0 to 1), our human verification process only validates binary labels. This discrepancy means we may lose potentially valuable nuance in the models confidence levels, and the 8 relationship between continuous scores and final binary classifications warrants further investigation. Although ELTEX is designed to be model-agnostic, our current evaluation has not systematically compared alternative large language models, leaving open questions regarding the generalizability of the synthetic data quality across different generation backends. QA Scalability The human-in-the-loop QA step plays critical role in maintaining data integrity. However, this process poses significant scalability challenges as the dataset size increases. Even with the assistance of tools like NotebookLM, manual verification remains resource-intensive and demands substantial domain expertise. This bottleneck may impede rapid dataset expansion and could lead to inconsistent QA outcomes when applied across different subdomains or technical areas. Evaluation Our evaluation focuses on specific aspect of cybersecurity, detecting potential blockchain attack signals in social media messages. This task represents just one facet of the broader cybersecurity domain, and model performance should be interpreted within this limited context. The Primus models, being developed for general cybersecurity applications, may offer advantages in areas not measured by our specific task. Their different performance characteristics on our social media task should not be interpreted as reflecting their overall cybersecurity capabilities. Similarly, Granites performance without task-specific tuning may indicate how general-purpose reasoning models can be applied to specialized security monitoring tasks, rather than representing their full capabilities. These results suggest that synthetic data generation may be useful approach for adapting models to specific cybersecurity detection tasks, particularly in domains where labeled data is limited. Domain Generalization While our case study validates ELTEX in the context of cybersecurity in blockchain, its generalizability to other specialized domains remains untested. Adapting the token extraction and dynamic prompt construction methodologies to domains with different linguistic characteristics or technical complexities may require substantial modifications. Future work should explore these adaptations and evaluate the frameworks performance across broader range of domains. These limitations highlight several promising avenues for future research, including the exploration of alternative or hybrid data sources, the development of more scalable and automated QA methodologies, and rigorous testing of ELTEXs applicability and performance in diverse specialized domains."
        },
        {
            "title": "Ethical Considerations",
            "content": "Our research adheres to strict ethical guidelines to ensure the responsible collection and use of data from social media platforms. The following measures were implemented to address potential ethical concerns: Compliance with Terms of Service and Privacy Policies All data collection procedures were conducted in accordance with Xs official API (v2) terms of service and privacy policies (X, 2025). We ensured that our data acquisition methods did not violate any platform-specific rules or regulations. Data Anonymization To protect user privacy, we anonymized the collected data by removing all usernames and user mentions. This step ensures that individual users cannot be identified from the dataset."
        },
        {
            "title": "References",
            "content": "Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, et al. 2024. Phi-3 technical report: highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219. Zaid Almahmoud, Paul Yoo, Omar Alhussein, Ilyas Farhat, and Ernesto Damiani. 2023. holistic and proactive approach to forecasting cyber threats. Scientific Reports, 13(1):8049. Mohammed Almukaynizi, Alexander Grimm, Eric Nunes, Jana Shakarian, and Paulo Shakarian. 2017. Predicting cyber threats through hacker social networks in darkweb and deepweb forums. In Proceedings of the 2017 International Conference of The Computational Social Science Society of the Americas, pages 17. Anthropic. 2023. Claude. Accessed: 2025-01-22. Marco Arazzi, Dincy R. Arikkat, Serena Nicolazzo, Antonino Nocera, Rafidha Rehiman K. A., Vinod P., and Mauro Conti. 2023. Nlp-based techniques for cyber threat intelligence. Preprint, arXiv:2311.08807. Glenn Brier. 1950. Verification of forecasts expressed in terms of probability. Monthly weather review, 78(1):13. on Empirical Methods in Natural Language Processing, pages 1044310461, Singapore. Association for Computational Linguistics. Anton Cheshkov, Pavel Zadorozhny, and Rodion Levichev. 2023. Evaluation of chatgpt model for vulnerability detection. Preprint, arXiv:2304.07232. Cloudflare. 2023. Workers AI: Serverless GPUhttps://developers. powered inference. cloudflare.com/workers-ai/. Frank Cremer, Barry Sheehan, Michael Fortmann, Arash Kia, Martin Mullins, Finbarr Murphy, and Stefan Materne. 2022. Cyber risk and cybersecurity: systematic review of data availability. The Geneva papers on risk and insurance. Issues and practice, 47(3):698. Mohamed Amine Ferrag, Fatima Alwahedi, Ammar Battah, Bilel Cherif, Abdechakour Mechri, and Norbert Tihanyi. 2024. Generative ai and large language models for cyber security: All insights you need. arXiv preprint arXiv:2405.12750. Google. 2025. Notebooklm: notebook ai assistant. Accessed: January 28, 2025. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations. IBM. 2025. Granite-3.2-2b-instruct. Accessed: 202503-18. Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando SolarLezama, Koushik Sen, and Ion Stoica. 2024. Livecodebench: Holistic and contamination free evaluation of large language models for code. arXiv preprint arXiv:2403.07974. Egil Karlsen, Xiao Luo, Nur Zincir-Heywood, and Malcolm Heywood. 2024. Benchmarking large language models for log analysis, security, and interpretation. Journal of Network and Systems Management, 32(3):59. Rupinder Paul Khandpur, Taoran Ji, Steve Jan, Gang Wang, Chang-Tien Lu, and Naren Ramakrishnan. 2017. Crowdsourcing cybersecurity: Cyber attack detection using social media. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, pages 10491057. Yinheng Li, Rogerio Bonatti, Sara Abdali, Justin Wagle, and Kazuhito Koishida. 2024. Data generation using large language models for text classification: An empirical case study. Preprint, arXiv:2407.12813. Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming Yin. 2023. Synthetic data generation with large language models for text classification: Potential and limitations. In Proceedings of the 2023 Conference Chen Ling, Xujiang Zhao, Jiaying Lu, Chengyuan Deng, Can Zheng, Junxiang Wang, Tanmoy Chowdhury, Yun Li, Hejie Cui, Xuchao Zhang, Tianjiao Zhao, Amit Panalkar, Dhagash Mehta, Stefano Pasquali, Wei Cheng, Haoyu Wang, Yanchi Liu, Zhengzhang Chen, Haifeng Chen, Chris White, Quanquan Gu, Jian Pei, Carl Yang, and Liang Zhao. 2024. Domain specialization as the key to make large language models disruptive: comprehensive survey. Preprint, arXiv:2305.18703. Zefang Liu, Jialei Shi, and John Buford. 2024. Cyberbench: multi-task benchmark for evaluating large language models in cybersecurity. AAAI-24 Workshop on Artificial Intelligence for Cyber Security (AICS). Lin Long, Rui Wang, Ruixuan Xiao, Junbo Zhao, Xiao Ding, Gang Chen, and Haobo Wang. 2024. On LLMs-driven synthetic data generation, curation, and evaluation: survey. In Findings of the Association for Computational Linguistics: ACL 2024, pages 1106511082, Bangkok, Thailand. Association for Computational Linguistics. Ilya Loshchilov and Frank Hutter. 2018. Decoupled weight decay regularization. In International Conference on Learning Representations. MacQueen. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability/University of California Press. Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Bossan. 2022. Peft: State-of-the-art parameter-efficient fine-tuning methods. URL: https://github. com/huggingface/peft. Microsoft. 2025. Azure openai service rest api reference. https://learn.microsoft.com/en-us/ azure/ai-services/openai/reference. Accessed: 2025-01-16. Yida Mu, Mali Jin, Xingyi Song, and Nikolaos Aletras. 2024. Enhancing data quality through simple de-duplication: Navigating responsible computational social science research. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 1247712492, Miami, Florida, USA. Association for Computational Linguistics. OpenAI. 2023. Chatgpt. OpenAI. n.d. Structured outputs. https://platform. openai.com/docs/guides/structured-outputs. Accessed: 2025-01-15. 10 Tommaso Paladini, Lara Ferro, Mario Polino, Stefano Zanero, and Michele Carminati. 2024. You might have known it earlier: Analyzing the role of underground forums in threat intelligence. In Proceedings of the 27th International Symposium on Research in Attacks, Intrusions and Defenses, pages 368383. Rajvardhan Patil and Venkat Gudivada. 2024. review of current trends, techniques, and challenges in large language models (llms). Applied Sciences, 14(5):2074. Filippo Perrina, Francesco Marchiori, Mauro Conti, and Nino Vincenzo Verde. 2023. Agir: Automating cyber threat intelligence reporting with natural language generation. In 2023 IEEE International Conference on Big Data (BigData), pages 30533062. Fahim Sufi. 2023. new social media-driven cyber threat intelligence. Electronics, 12(5):1242. Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, and Wenhu Chen. 2024. Mmlu-pro: more robust and challenging multi-task language understanding benchmark. Preprint, arXiv:2406.01574. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 3845, Online. Association for Computational Linguistics. Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, et al. 2024a. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530. Siyuan Wu, Yue Huang, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Xiangliang Zhang, Jianfeng Gao, Chaowei Xiao, and Lichao Sun. 2024. Unigen: unified framework for textual dataset generation using large language models. Preprint, arXiv:2406.18966. Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, Léonard Hussenot, Pier Giuseppe Sessa, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex CastroRos, Ambrose Slone, Amélie Héliou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai, Bobak Shahriari, Charline Le Lan, Christopher A. Choquette-Choo, Clément Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, Justin Mao-Jones, Katherine Lee, Kathy Yu, Katie Millican, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon, Machel Reid, Maciej Mikuła, Mateo Wirth, Michael Sharman, Nikolai Chinaev, Nithum Thain, Olivier Bachem, Oscar Chang, Oscar Wahltinez, Paige Bailey, Paul Michel, Petko Yotov, Rahma Chaabouni, Ramona Comanescu, Reena Jana, Rohan Anil, Ross McIlroy, Ruibo Liu, Ryan Mullins, Samuel Smith, Sebastian Borgeaud, Sertan Girgin, Sholto Douglas, Shree Pandya, Siamak Shakeri, Soham De, Ted Klimenko, Tom Hennigan, Vlad Feinberg, Wojciech Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Gong, Tris Warkentin, Ludovic Peran, Minh Giang, Clément Farabet, Oriol Vinyals, Jeff Dean, Koray Kavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral, Fernando Pereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and Kathleen Kenealy. 2024b. Gemma: Open models based on gemini research and technology. Preprint, arXiv:2403.08295. X. 2025. api documentation. https://developer. January 16, x.com/en/docs/x-api. Accessed: 2025. Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff. 2023. C-pack: Packaged resources to advance general chinese embedding. Preprint, arXiv:2309.07597. Biwei Yan, Kun Li, Minghui Xu, Yueyan Dong, Yue Zhang, Zhaochun Ren, and Xiuzhen Cheng. 2024. On protecting the data privacy of large language models (llms): survey. arXiv preprint arXiv:2403.05156. Weichen Yu, Tianyu Pang, Qian Liu, Chao Du, Bingyi Kang, Yan Huang, Min Lin, and Shuicheng Yan. 2023. Bag of tricks for training data extraction from language models. In International Conference on Machine Learning, pages 4030640320. PMLR. Yao-Ching Yu, Tsun-Han Chiang, Cheng-Wei Tsai, Chien-Ming Huang, and Wen-Kwang Tsao. 2025. Primus: pioneering collection of open-source datasets for cybersecurity llm training. Preprint, arXiv:2502.11191. Zixuan Zhou, Xuefei Ning, Ke Hong, Tianyu Fu, Jiaming Xu, Shiyao Li, Yuming Lou, Luning Wang, Zhihang Yuan, Xiuhong Li, et al. 2024. survey on efficient inference for large language models. arXiv preprint arXiv:2404.14294. Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong Yu. 2018. Texygen: benchmarking platform for text generation models. In The 41st international ACM SIGIR conference on research & development in information retrieval, pages 10971100. 11 Ingo Ziegler, Abdullatif Köksal, Desmond Elliott, and Hinrich Schütze. 2024. Craft your dataset: Taskspecific synthetic dataset generation through corarXiv preprint pus retrieval and augmentation. arXiv:2409.02098. Shi Zong, Alan Ritter, Graham Mueller, and Evan Wright. 2019. Analyzing the perceived severity of cybersecurity threats reported on social media. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 13801390, Minneapolis, Minnesota. Association for Computational Linguistics."
        },
        {
            "title": "A ELTEX System Details",
            "content": "Task Description Example A.1 Overview This appendix provides an in-depth overview of the ELTEX methodology used for relevant token extraction from LLMs. The included example aim to enhance the quality, diversity, and relevance of synthetic datasets, particularly within the context of cybersecurity in the blockchain industry. While the examples focus on this domain, the ELTEX approach is adaptable to other domains by modifying task-specific instructions and indicators. A.2 ELTEX Prompt Design Workflow The ELTEX pipeline integrates the following key steps to maximize the utility of prompts in extracting meaningful tokens and generating high-fidelity synthetic data: 1. Data Preparation: Collect real-world data samples and deduplicate them using vector similarity search to ensure uniqueness and variety. 2. Prompt Construction: Design prompts that combine task descriptions, critical instructions, domain-relevant indicators, and real data samples. 3. Synthetic Data Generation: Generate synthetic data using the LLM and apply deduplication to maintain data quality. A.2.1 Task Description and Critical"
        },
        {
            "title": "Instructions",
            "content": "A well-crafted task description and critical instructions are essential components of the prompt design that ensure the LLM generates relevant and high-quality synthetic data. These elements provide clear guidance to the model, outlining the objectives and constraints of the data generation task. Task Description The task description defines the primary objective of the synthetic data generation process. It specifies what the model is expected to produce and the context in which the data will be used. Your task is to generate list of social media platform messages to be used as early warning signals for identifying cyberattack on blockchain industry participant. Below are two lists. The \"Cyberattack Indicators\" list contains signals that can lead to financial or reputational loss. The \"Social Media Messages\" list contains social media platform messages about cyberattacks on blockchain industry that happened in the past. Use the \"Cyberattack Indicators\" and \"Social Media Messages\" to generate 100 new social media platform messages that could imply cyberattack on blockchain ecosystem participant, including very early stages of it. Critical Instructions Critical instructions provide specific guidelines to ensure the generated data adheres to desired standards and mitigates potential biases."
        },
        {
            "title": "Critical Instructions Example",
            "content": "Critical: Use modern vocabulary and writing style. Leave Law Enforcement and Government Regulators names unchanged, but replace other named entities (organizations, persons, locations) with fictional, yet plausible and modern ones. The output must be list of 100 newly generated social media platform messages without any explanations. Implementation Considerations When designing task descriptions and critical instructions, consider the following to enhance effectiveness: Clarity and Specificity: Clearly define the scope and objectives to avoid ambiguous outputs. Bias Mitigation: Explicitly instruct the model on handling sensitive information and named entities to prevent unintended biases. Adaptability: Ensure that instructions are 13 adaptable to changes in domain standards or emerging trends. Batch Size Management: Optimize the number of messages generated per batch to balance quality and computational efficiency. A.3 Indicators This section outlines the process of creating and refining indicators, which are crucial for guiding the LLM in generating relevant synthetic data. Indicators Generation A.3.1 Indicators serve as compact prompt section listing concepts relevant to given use case, fulfilling several crucial purposes: Focuses the LLMs attention: Concentrates on highly distilled collection of relevant tokens. Highlights model features: Emphasizes aspects not well-pronounced in the data samples. Compensates for biases: Mitigates biases and deficiencies in the data samples. Although subject-matter expert can manually define this section, relying solely on human expertise may be impractical, as finding domain specialists can be challenging. To mitigate this dependence, we propose leveraging LLMs to generate and refine indicators. By employing the following techniques, we enhance both efficiency and accuracy: Leverage multiple models: Use LLMs trained on diverse datasets to capture broad spectrum of perspectives and avoid biases inherent to single model. Prioritize models with recent knowledge: Prefer models with the latest knowledge cutoff dates, especially for fast-changing industries and emergent topics. Use different LLM service implementations: Different implementations might have varying optimizations and safeguards, enhancing the diversity of indicators. Reference public knowledge: Ground indicators in real-world contexts by incorporating historical events that LLMs are likely familiar with. Use educational resources: Incorporate resources that would be used to teach manual classification to ensure comprehensive coverage. Indicator Generation Prompt Example Your task is to generate list of Blockchain Ecosystem Cyberattack Indicators that could be spotted by looking at social media chatter, including very early stages of the attack. Blockchain ecosystem participants could include centralized and decentralized products, exchanges, protocols, wallets, smart contracts, bridges, oracles, developers, key people, etc. Information included below could help you reason about useful signals for monitoring reports on social media. General Knowledge: <article text 1 article text 2 ... article text n> Historical Events: <date 1 - named entity 1 date 2 - named entity 2 ... date - named entity n>"
        },
        {
            "title": "Indicator Summarization",
            "content": "A.3.2 The outputs from the indicator generation stage often include verbose descriptions with semantic duplicates. It is essential to consolidate and refine the AI-generated content into concise, nonredundant list of indicators that can be validated by subject-matter expert. Key points to consider during summarization include: Use frontier model: Select models with large context windows, strong reasoning capabilities, and low-temperature settings. Ensure alignment: Aim for consistency between your understanding of important indicators and the models output. Avoid manual additions: Focus on improving the indicator generation prompts rather than manually adding information. Compare multiple models: Use outputs from different models to ensure no critical information is omitted. Indicator Summarization Prompt Example A.6 Final Prompt Template Below is the ELTEX prompt template designed for generating synthetic data. ELTEX Prompt Template for Synthetic Data Generation <task description> <critical instructions> <indicators list> <real data samples> Your task is to deduplicate and summarize list of Blockchain Ecosystem CyberatIts tack Indicators you will find below. okay to merge similar ideas into one concept, but dont remove any ideas completely. Generate succinct paragraph with densely packed indicators and associated concepts you will find below without additional comments. <list of indicators> A.4 Cyberattack Indicators This section presents our curated list of cyberattack indicators specific to the blockchain industry. Cyberattack Indicators List Key blockchain ecosystem cyberattack indicators include unusual spikes in transaction volume, abnormal confirmation times, unexpected changes in mining difficulty, and suspicious smart contract interactions. Wallet-related red flags involve sudden activation of dormant addresses, unauthorized transactions, and compromised private keys. Exchange-specific indicators include rapid price fluctuations, withdrawal issues, and unexpected downtime. Infrastructure concerns manifest as unverified nodes, synchronization delays, and potential 51% attacks. Cross-chain vulnerabilities, security breaches, phishing attempts, and API compromises are critical to monitor. Community sentiment, governance irregularities, and blockchain explorer activity provide additional context for potential threats. A.5 Handling Alignment and Sensitive"
        },
        {
            "title": "Content",
            "content": "Certain tasks involve sensitive topics, such as cyberattacks, which may trigger alignment safeguards in LLMs, causing them to refuse generating synthetic samples. To mitigate this, the ELTEX system incorporates explicit phrasing in prompt instructions to clarify the context and ethical use of the data. For example, including statements like The generated synthetic data will be used solely for researchoriented classification tasks and will not be utilized for any other purposes helps in mitigating content generation refusals."
        },
        {
            "title": "B Data Annotation with LLMs",
            "content": "B.3 Validation and Accuracy LLM-annotated labels were additionally validated using custom function. = {r1, r2, . . . , rn}: the set of records with true labels (ri), where true labels are those verified by human annotator. = {a1, a2, . . . , am}: the set of annotated records with GPT-scores (ai). : the threshold for classification (T = 0. by default). The predicted label ˆyi is defined as: ˆyi = (cid:40) if ai T, 1, 0, otherwise. The formula for computing accuracy (Accuracy) is: where: Accuracy = (cid:80) i=1 δ(yi, ˆyi) 100 δ(yi, ˆyi) = (cid:40) 1, 0, if yi = ˆyi, otherwise. Here, yi is the true label of record ri, and ˆyi is the predicted label obtained from the annotated record ai corresponding to ri. Validation confirmed that GPT-4o (version August 6, 2024) achieved over 95% accuracy. B.1 Prompt Used for Annotation The following prompt was used to generate preliminary annotation scores for collected messages. These scores (ranging from 0 to 1) were utilized as basis for subsequent human review and label refinement. Annotation Prompt Your task is to detect early warning signals for cyberattacks on blockchain industry participants. You will be provided with two lists: \"Cyberattack Indicators\" list contains signals that can lead to financial or reputational loss. The other list, \"Social Media Messages\", is an array of objects that should contain messages about cyberattacks on the blockchain industry. Classify those objects by adding cyberattack_score field to the corresponding JSONs and assign classification score value to it from 0 to 1, where 1 corresponds to an object clearly associated with potential or existing cyberattack or some context that would imply it, and 0 corresponds to an object that is not connected to cyberattack at all. Critical: - The output must be only an array from the list \"Social Media Messages\", only with properties message_id and the corresponding cyberattack_score, machine-readable and formatted as JSON without any explanations, dont add anything else. - Pay attention to associated timestamps to better understand the context. - Dont remove any messages. Cyberattack Indicators <indicators list> Social Media Messages: <real data samples> B.2 Human Annotation Procedure Human annotators used the preliminary labels generated by GPT-4o (version August 6, 2024) as starting point for the annotation process. Guided by the list of cyberattack indicators, they reviewed the assigned cyberattack_score and adjusted the final labels accordingly. This approach leverages the efficiency of LLM-generated insights while ensuring high annotation quality."
        },
        {
            "title": "C Experimental Setup Details",
            "content": "This appendix provides detailed information about our data, batching strategy, and model configurations. We train three variants of the model: Real, Synthetic, and Hybrid, each with unique data compositions but sharing consistent validation procedures. C.1 Batching Strategy and Overall Approach All training and inference is conducted in fixed batches of 10 messages. Although this reduces the total effective number of parameter-update steps, it aligns with real-world, high-throughput requirements where messages often arrive in bursts. Processing messages in such fixed-size batches simplifies the pipeline and keeps training and inference behavior consistent. C.2 Dataset Statistics We utilize two primary corpora: real-world dataset and synthetic dataset derived exclusively from the real training set. The hybrid variant merges these two datasets. In addition, we collect test set of entirely new attack events that do not appear in the real dataset, to rigorously assess out-of-distribution performance. Real Dataset The deduplicated real-world dataset contains 1,603 total messages. We split these into training and validation sets using an 80/20 ratio before generating synthetic data: Training set (80%): 1,283 messages 761 cyberattack-related (59.3%) 522 general (40.7%) Validation set (20%): 320 messages 190 cyberattack-related (59.4%) 130 general (40.6%) After dividing into fixed batches of 10 messages, these total to: Training set: 128 effective batches Validation set: 32 effective batches Synthetic Dataset We generated 8,892 synthetic messages (5,530 cyberattack-related and 3,362 general) from the real training set only. This approach avoids data leakage into the validation/test sets. Since we do not create separate synthetic validation set, the real validation set of 320 messages serves as consistent benchmark for both synthetic and real training scenarios. The fixed batch size of 10 yields 888 effective training batches in the synthetic-only case. Hybrid Dataset For our hybrid variant, we combine the entire real training set (1,283 messages) with all synthetic messages (8,892), producing total of 10,175 training messages. Consequently, the hybrid training set has 1,017 effective batches (10,175 / 10), while the validation set remains the same 320 real messages (32 effective batches). This ensures direct comparability of performance across the real-only, synthetic-only, and hybrid approaches. Test Set We curated an additional real-world test set of 398 messages, consisting of 206 cyberattackrelated and 192 general messages. Crucially, these messages come from cyberattack events not present in the original training data, ensuring an independent, out-of-distribution evaluation. This isolated test set allows us to assess how well the model generalizes to novel attack patterns and contexts. C.3 Training Configurations We tailor batch sizes, epochs, and gradient accumulation to each data scenario. C.3.1 Real-Only Model Configuration Because the real dataset comprises only 128 effective training batches, we adopt small per-step batch size and accumulate gradients to maintain stable updates: Batch size: 1 Gradient accumulation steps: 16 (Effective batch size: 16) Learning rate: 2 104 Max epochs:"
        },
        {
            "title": "This setup limits gradient variance and reduces",
            "content": "overfitting risks when data is sparse. C.3.2 Synthetic-Only and Hybrid Model"
        },
        {
            "title": "Configuration",
            "content": "Both synthetic-only (888 effective training batches) and hybrid (1,017 effective batches) allow more standard batch settings: Batch size: 4 17 Final evaluation: Conducted on separate held-out test set of distinct cybersecurity events By emphasizing the Brier score, we ensure wellcalibrated probabilities, crucial in cyberattack scenarios where both false positives and false negatives carry real-world risks. Gradient accumulation steps: (Effective batch size: 32) Learning rate: 2 104 Max epochs: 5 Since these datasets provide substantially more training examples, larger effective batch size stabilizes training, and fewer epochs (5) suffice to attain convergence without overfitting. C. Implementation Details All models share the following technical setup: Framework: Hugging Face Transformers (Wolf et al., 2020) and PEFT (Mangrulkar et al., 2022) Base model: Gemma-2B Precision: Mixed precision (bfloat16) Hardware: NVIDIA A100 GPU (80GB VRAM) LoRA rank: = 8 Quantization: 4-bit with bfloat16 compute Optimizer: AdamW (Loshchilov and Hutter, 2018) Input format: Batches of 10 tokenized messages (Gemma tokenizer) Output format: JSON-structured risk scores"
        },
        {
            "title": "Deployments",
            "content": "run on Cloudflare Workers AI (Cloudflare, 2023), exporting LoRA adapter weights in safetensors format. Inference likewise processes incoming messages in batches of 10, returning per-message risk scores as JSON. C.5 Model Selection and Evaluation We apply consistent validation scheme and selection criteria: Validation strategy: Monitoring training/validation losses and Brier score to balance discrimination and calibration Early stopping: Triggered if no metric improvement after 3 consecutive epochs Checkpointing: We store the best model by validation Brier score"
        },
        {
            "title": "D Additional ELTEX Experiments",
            "content": "D.2 Temperature Experiments for Synthetic Data Generation D.2.1 Retention Trends Synthetic data generation experiments assessed the impact of temperature settings (0.0 to 1.0) on data retention. Retention percentages for different temperatures are illustrated in Figure 3. This appendix summarizes additional experiments conducted within the ELTEX framework to optimize synthetic data generation. We evaluate key parameters including deduplication thresholds and temperature settings and perform clustering analysis to assess semantic diversity and overall data quality for cybersecurity applications. D.1 Deduplication Experiments with Real Messages D.1.1 Reduction Statistics Deduplication experiments were performed on real messages using similarity thresholds of 0.9 and 0.8. The results are summarized in Table 4. Type Cyberattack Cyberattack General General Threshold Original Reduced 1,078 1,078 688 688 951 413 652 446 0.9 0.8 0.9 0.8 Table 4: Reduction Statistics for Cyberattack and General Messages D.1.2 Clustering Analysis on Real Data Clustering analysis was conducted using DBSCAN to evaluate the semantic coherence of the deduplicated datasets at thresholds of 0.9 and 0.8. The analysis revealed key differences in the impact of each threshold: Threshold 0.8: This more aggressive threshold removed substantial number of messages, resulting in datasets with less semantic overlap but also reduced topical coverage. Messages retained under this threshold often lacked sufficient context for meaningful clustering, as many subtle variations were eliminated during the deduplication process. Threshold 0.9: more moderate approach, this threshold preserved higher proportion of messages, maintaining greater semantic diversity. The retained dataset better represented nuanced variations in language use, enabling more coherent clustering into distinct topical groups. This balance allowed for the identification of meaningful patterns within both cyberattack-related and general messages. (a) Cyberattack Messages (b) General Messages Figure 3: Retention percentage across different temperature settings and similarity thresholds (0.8, 0.9, 1.0). Note that even with threshold 1.0, exact duplicates are still removed by the deduplication service."
        },
        {
            "title": "Key Observations",
            "content": "Higher Temperatures (0.71.0): These settings produced more diverse outputs, resulting in higher retention rates. Lower Temperatures (0.00.6): These settings generated repetitive messages, leading to lower retention rates. Optimal Balance: temperature of 0.8 provided balance, yielding both high retention 19 The UMAP visualization (Figure 4) reveals different clustering patterns between real and synthetic data. Real data shows some well-separated clusters alongside overlapping ones, while synthetic data displays more uniform overlap and elongated structures. This suggests that real data contains both distinct security events and related incident types, whereas synthetic data forms more continuous semantic space. Tables 5 and 6 present the most representative clusters from each dataset, highlighting their distinct semantic organization. The keyword analysis shows that real data clusters form around specific security incidents (e.g., the Euler Finance exploit), characterized by concrete terms (\"million\", \"hack\") and named entities. In contrast, synthetic data clusters represent broader cyberattack categories (e.g., network anomalies, market manipulation), employing more general terminology (\"potential\", \"unusual\", \"alert\"). This pattern aligns with our generation approach: synthetic messages were created to cover broad spectrum of potential indicators rather than specific incidents. While this results in wider coverage of possible cyberattack scenarios, it comes at the cost of reduced event-specific detail. This tradeoff suggests that combining real and synthetic data might provide both concrete incident coverage and broad indicator diversity. rates and semantically diverse messages without sacrificing coherence. Interpretation and Insights The experiments suggest that temperature settings have moderate influence on the diversity of synthetic data. Higher temperatures tend to introduce more variation in the generated messages, while lower temperatures result in more consistent but potentially repetitive outputs. For cybersecurity datasets, temperature of 0.8 struck practical balance, maintaining sufficient variation in generated messages. Note on Generation Variability Due to the stochastic nature of LLM-based generation and our prompt construction methodology, we observed some variation in retention rates across different generation runs at the same temperature setting. Following our approach, real messages were randomly shuffled before being grouped into sets of 10 examples per prompt, resulting in slightly different prompt compositions across generation runs. This, combined with the inherent randomness in the generation process, led to variations in retention rates. For instance, at temperature 0.8 with similarity threshold of 0.9, retention rates varied between 60-70% across different generation sessions. This variability is expected and reflects both the randomized prompt construction and the stochastic nature of LLM outputs. Despite these fluctuations, the relative trends and optimal temperature recommendations remain consistent. D.3 Clustering Analysis on Synthetic Data We performed semantic clustering analysis on the BGE-base-en-v1.5 embeddings (Xiao et al., 2023) of both real and synthetic messages. The technical details of our implementation include: Clustering Algorithm: k-means (MacQueen, 1967) with = 10 and k-means++ initialization (random_state = 42) Dimensionality Reduction: UMAP visualization with parameters: n_components = 2 metric = cosine random_state = 42 Dataset Sizes: Real cyberattack messages: 994 Synthetic cyberattack messages: 6,941 20 (a) Real Data (b) Synthetic Data Figure 4: UMAP Visualization of K-means Clustering Results Cluster Top Keywords (frequency) Euler Finance Poloniex/HTX Bridge Exploit Atomic Wallet finance (129), million (89), defi (60), protocol (59), exploit (55), attack (38), euler (37), exploited (35), curve (32) poloniex (63), exchange (58), htx (53), million (42), justin (32), sun (32), crypto (30), hack (30), hacker (24) bridge (51), multichain (40), orbit (38), chain (31), million (29), hack (27), exploit (18), protocol (14), hacked (11) wallet (73), atomic (68), users (21), hack (19), security (14), funds (11), crypto (10), million (9) Table 5: Representative Clusters in Real Data (Event-Specific Organization) Cluster Network Wallet Market Governance Top Keywords (frequency) transaction (366), attack (274), network (269), potential (260), mining (250), blockchain (216), unusual (202), alert (174) dormant (245), wallet (96), addresses (81), activation (77), activity (73), suddenly (62), sudden (54), wallets (53) price (368), manipulation (230), market (207), exchange (172), rapid (171), fluctuations (90), trading (85) governance (333), community (206), sentiment (86), irregularities (79), proposal (73), manipulation (63), voting (49) Table 6: Representative Clusters in Synthetic Data (Category-Based Organization)"
        },
        {
            "title": "E Deduplication Methodology",
            "content": "E.1 Deduplication Process Overview To ensure the quality and diversity of synthetic data, we implemented two-stage deduplication pipeline that combines exact match filtering with semantic similarity analysis. This methodology effectively eliminates duplicate or near-duplicate messages, maintaining the integrity and variability of the dataset. Initial Deduplication E.1.1 The first stage implements the exact content matching using set operations to eliminate identical entries. Given batch of messages = {m1, m2, . . . , mn}, we construct set of unique content: = {content(m) } (1) where content(m) represents the textual content of message m. This operation reduces the computational overhead for subsequent semantic analysis by eliminating exact duplicates early in the pipeline. E.1.2 Embedding Similarity Analysis The second stage employs embeddings to identify and filter semantically similar content. For each unique message, we generate vector representations using the BAAI BGE base model (BGEbase-en-v1.5) (Xiao et al., 2023) deployed through Cloudflare Workers AI (Cloudflare, 2023). Given message m, its embedding e(m) Rd is computed through the model: e(m) = BGE(content(m)) (2) where represents the embedding dimension. To determine similarity between messages, we employ cosine distance: similarity(m1, m2) = 1 cosine_distance(e(m1), e(m2)) (3) Messages are processed in batches of size (where = 100 in our implementation) to optimize computational efficiency while maintaining reasonable memory usage. For each new message m, we compute its maximum similarity score against existing entries in the database D: message is considered sufficiently unique and retained if its maximum similarity score falls below configurable threshold ε: is_unique(m) max_similarity(m) < ε (5) E.2 Implementation Details The deduplication process is implemented using scalable and efficient algorithms to handle large volumes of data. Specific implementation details, including parameter settings and optimization techniques, are provided below: Similarity Threshold (ε): We set the threshold ε = 0.9 to balance between removing duplicates and preserving unique variations. Experiments with alternative thresholds (e.g., 0.8) are detailed in Appendix C. Batch Processing: Messages are processed in batches to enhance computational efficiency and manage memory usage effectively. Embedding Generation: The BAAI BGE base model is chosen for its robustness in generating high-quality embeddings suitable for semantic similarity tasks. Integration with Database: The deduplication system is integrated with our database to maintain clean and diverse dataset, facilitating accurate model training and evaluation. E.3 Deduplication Service Features The system maintains separate tables for different data categories (production, research, and scraped data) while preserving metadata such as: Topic Classification: Assigning messages to predefined topics. Industry Categorization: Grouping messages based on industry relevance. Timestamp Information: Ensuring chronological consistency. Source Metadata: Capturing platformspecific attributes. Message Identifiers: Ensuring uniqueness max_similarity(m) = max{similarity(m, d) D} using hashed IDs. (4) E.4 Monitoring and Performance Metrics"
        },
        {
            "title": "F Costs Analysis",
            "content": "To ensure real-time quality control, the deduplication pipeline tracks the following metrics: 1. Total Messages Received: Number of messages processed. 2. Messages Retained: Count of messages passing deduplication. 3. Messages Filtered: Number of duplicates removed. 4. Insertion Rate: Ratio of retained to received messages. These metrics enable continuous monitoring of data quality and diversity throughout the collection process. Our synthetic data generation relied on the GPT-4o (version August 6, 2024) model served via Azure OpenAI. The pricing structure was as follows: Input tokens: $2.50 per million tokens Output tokens: $10.00 per million tokens Request Configuration: Each request consisted of: shared extraction prompt containing up to ten real examples Generation settings configured to output 100 synthetic messages Token Usage: Per single request: Input tokens: approximately 500-800 tokens Output tokens: approximately 1,500-2,100 tokens Cost Breakdown: Cost per request: approximately $0.016- $0.023 Cost per synthetic message: approximately $0.00016-$0.00023 Total cost for 16,030 samples: approximately $3-$ Additional Costs: Message embedding using the cf/baai/bge-base-en-v1.5 model ($0.008 per million tokens) added negligible costs (<$1) to the total budget, as each message required only few dozen tokens for embedding."
        }
    ],
    "affiliations": [
        "Distributed Networks Institute (DNI)",
        "Technologies Mésozoïques"
    ]
}