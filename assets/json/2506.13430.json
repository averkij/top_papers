{
    "paper_title": "Uncertainty-Aware Remaining Lifespan Prediction from Images",
    "authors": [
        "Tristan Kenneweg",
        "Philip Kenneweg",
        "Barbara Hammer"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Predicting mortality-related outcomes from images offers the prospect of accessible, noninvasive, and scalable health screening. We present a method that leverages pretrained vision transformer foundation models to estimate remaining lifespan from facial and whole-body images, alongside robust uncertainty quantification. We show that predictive uncertainty varies systematically with the true remaining lifespan, and that this uncertainty can be effectively modeled by learning a Gaussian distribution for each sample. Our approach achieves state-of-the-art mean absolute error (MAE) of 7.48 years on an established Dataset, and further improves to 4.79 and 5.07 years MAE on two new, higher-quality datasets curated and published in this work. Importantly, our models provide well-calibrated uncertainty estimates, as demonstrated by a bucketed expected calibration error of 0.62 years. While not intended for clinical deployment, these results highlight the potential of extracting medically relevant signals from images. We make all code and datasets available to facilitate further research."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 1 ] . [ 1 0 3 4 3 1 . 6 0 5 2 : r Uncertainty-Aware Remaining Lifespan Prediction from Images Tristan Kenneweg1, Philip Kenneweg1, and Barbara Hammer1 University of Bielefeld Abstract. Predicting mortality-related outcomes from images offers the prospect of accessible, noninvasive, and scalable health screening. We present method that leverages pretrained vision transformer foundation models to estimate remaining lifespan from facial and whole-body images, alongside robust uncertainty quantification. We show that predictive uncertainty varies systematically with the true remaining lifespan, and that this uncertainty can be effectively modeled by learning Gaussian distribution for each sample. Our approach achieves state-of-the-art mean absolute error (MAE) of 7.48 years on an established Dataset, and further improves to 4.79 and 5.07 years MAE on two new, higherquality datasets curated and published in this work. Importantly, our models provide well-calibrated uncertainty estimates, as demonstrated by bucketed expected calibration error of 0.62 years. While not intended for clinical deployment, these results highlight the potential of extracting medically relevant signals from images. We make all code and datasets available to facilitate further research."
        },
        {
            "title": "1\nIn this paper, we address the problem of remaining lifespan prediction from\nimages, which we consider interesting for two major reasons:",
            "content": "First, it is unclear how well this task can be solved in the informationtheoretic limit. If we had perfect predictor, what level of precision could we achieve? Intuitively, one might expect only low maximum precision, since not all information relevant for remaining life prediction is likely to be present in single image. However, this intuition is challenged by the related task of chronological age prediction. The mean absolute error in the MORPH Album 2 dataset, which provides facial images along with the age of each individual, is reported to be less than 2.5 years [1,2]. In contrast, using DNA methylation markers for the prediction of chronological age, the landmark 2013 paper [3] reported median error of 3.6 years. In this related task, images demonstrate even greater predictive power than complex DNA methylation measurements. Whether similar success is possible for other medical prediction tasks is unclear. Second, if high predictive precision can be achieved, this would indicate that substantial health information about an individual can be inferred from images. An atypically low remaining lifespan prediction could serve as an indicator for initiating further medical investigations. Subsequently, predictors that detect specific conditions or estimate laboratory values could be developed. As images are ubiquitous, consistently extracting medically relevant data from them would greatly benefit preventive medicine. In this work, we propose significantly improved approach to remaining lifespan prediction from images by combining powerful pre-trained vision transformers with regression head that models prediction uncertainty as Gaussian distribution. We show that such models produce well-calibrated uncertainty estimates, enabling better interpretation and downstream decision-making. Our contributions are as follows: We show that strong predictive performance can be achieved in remaining lifespan prediction tasks using pre-trained foundation models such as DINOv2, without extensive architectural tuning. We model prediction uncertainty using the Gaussian negative log-likelihood and demonstrate calibration with the bucketed Expected Calibration Error (ECE) adapted to regression. We curate and publish cleaned and improved versions of an existing mortality dataset, leveraging vision-language models to automatically filter samples. We report state-of-the-art performance with an MAE of 4.79 years and an average calibration error of 0.62 years on the cleaned dataset. Although our approach is not intended for clinical deployment, it underscores the hidden potential of simple images as first-line screening tool and highlights scalable opportunities for uncertainty-aware health modeling using publicly available visual data. The code and datasets are publicly available at: github.com/TKenneweg/RLPredictionWithUncertainty. 2 Related Work Epigenetic clocks and biological ageing. Estimating individual ageing rates from molecular data has been major focus since Horvaths seminal pan-tissue DNA-methylation clock [3]. Second-generation clocks such as DNAm PhenoAge [4] and DNAm GrimAge [5] improve correlations with disease burden and all-cause mortality, and are now widely used in geroscience studies. Crucially, however, these clocks are optimized for hazard ratios or risk scores rather than for point estimates of the time remaining to an individual, which limits their interpretability for person-centric counseling. Image-based age and risk prediction. Computer-vision research on facial images initially targeted chronological age regression, achieving mean absolute errors below 2.5 years on the MORPH dataset [1,2]. Fekrazad [6] collected corpus of 24,000 Wikipedia portraits and trained convolutional models to regress remaining lifespan, reporting an MAE of 8.3 years. More recently, Bontempi et al. introduced FaceAge, deep model that estimates biological age from single headshot and enhances survival prediction in oncology cohorts [7]. While FaceAge improves survival hazard modeling, it does not produce calibrated estimates of absolute years of life remaining. Other imaging modalities. Beyond faces, retinal fundus photographs [8], optical-coherence-tomography volumes [9], and chest radiographs [10,11] have also been used to forecast longevity-related outcomes. Most of these pipelines feed image embeddings from CNN (or Vision Transformer) into Cox proportionalhazards lossthe classical survival-analysis objective that learns log-linear function producing hazard ratioor its deep-learning analogue DeepSurv, which replaces the linear layer with an MLP while maintaining the same partiallikelihood formulation. Both objectives optimize the relative risk of death over time rather than predicting concrete number of years left. Consequently, their outputs are survival curves or risk scores, underscoring that hazard modeling addresses related, but distinct, question from the remaining-lifespan regression tackled in the present work. Uncertainty-aware prediction. Reliable confidence estimates are indispensable for clinical deployment. Bayesian neural networks [12] and deep ensembles [13] have been proposed, but calibration for image-based lifespan prediction remains under-explored. Our Gaussian meanvariance head follows the mean-variance estimation paradigm [14,15] and is, to our knowledge, the first to quantify uncertainty in image-based lifespan regression. 3 Dataset (a) Problematic images from the Legacy Dataset. The image on the bottom right depicts painting. (b) The first six random images of the newly created Faces Dataset. Fig. 1: Dataset Images We base our dataset on the one published by Fekrazad [6], henceforth referred to as the Legacy Dataset. The Legacy Dataset contains facial images of people scraped from Wikipedia and Wikidata who died between 1990 and 2022. When no unnatural cause was given, death was presumed to be from natural causes. For details on the scraping process, we refer to the original paper. While overall well-constructed, we identified several quality issues in the Legacy Dataset: Many images are of extremely low resolution and do not contain color information. We expect fine details and color to be especially important for the task at hand. Examples of inadequate data points can be seen in Figure 1a. Some of the images are not photographs of real people, but rather drawings, paintings, or other non-photographic representations. Death dates were recorded as integer years, introducing substantial noise in the remaining lifespan targets. To address these issues, we performed an extensive data cleaning process. We retained data points only if they met the following criteria: Resolution and Color: The facial image must have minimum resolution of 200200 pixels and contain color information. Content: The image must be photograph of real person, not drawing, painting, or photo of sculpture. Availability: The full version of the image, including more than just the face, must be downloadable from Wikidata. We used the multimodal GPT-4o-mini API to automatically determine whether an image contains color and is photograph of real person. Additionally, we queried the Wikidata API to retrieve more precise death dates, recorded as floating-point numbers. Finally, we downloaded the corresponding full images from Wikidata (the Legacy Dataset contains only the cropped faces). After filtering, we retained 5,672 data points, with an average remaining lifespan of 11.57 years and standard deviation of 11.9 years. During manual inspection of the first 200 images, we found no incorrectly included images, indicating that GPT-4o-mini was able to reliably filter non-photographic samples. We created two datasets: Faces Dataset, which contains the cropped facial images, and Whole Images Dataset, which contains the full Wikidata images, usually depicting part or most of the body. We also retain the Legacy Dataset, which contains 24,167 data points, with mean remaining lifespan of 29.99 years and standard deviation of 22.04 years. For comparison, we also report results on the Legacy Dataset. Figure 2 shows the target remaining lifespan distribution in the newly created dataset. We observe high prevalence of relatively small values, which is expected when scraping images from Wikipedia, since many images have been updated relatively recently prior to or following persons death."
        },
        {
            "title": "4 Methodology\nRemaining lifespan prediction from images is a complex task involving high-\ndimensional input data, requiring deep neural networks to achieve good perfor-\nmance. However, we are working with a relatively small dataset that cannot be\nused to train a deep network from scratch. Thus, we turn to large pre-trained\nvision transformers, which we use to produce semantically powerful embeddings\nthat can be further processed by a regression head. We compared the perfor-\nmance of three possible backbones, without fine-tuning: DINOv2 [16] (with\nlearned register tokens), I-JEPA [17], and CoAtNet [18]. The largest version\nof DINOv2, with more than 1 billion parameters, yielded clearly superior per-\nformance and was therefore used in all subsequent experiments.",
            "content": "The data in remaining lifespan prediction exhibits heteroskedasticity, meaning that the larger the true or predicted lifespan, the higher the expected error. This is not failure of the underlying model, but rather an inherent uncertainty Fig. 2: Histogram of target values in the newly created datasets. in the problem. If person has larger remaining lifespan, more factors can potentially influence longevity over timefor example, changes in body composition. The mean absolute error as metric can thus be misleading, as the uncertainty for single data point may vary greatly depending on the actual prediction. To mitigate this issue, we constructed regression head with two output layers: one predicting the mean value µ (the remaining lifespan prediction), and one predicting the log variance, log σ2. We train the regression head using the negative log-likelihood (GNLL) loss for Gaussian distribution [14]: = 1 2N (cid:18) (cid:88) log(σ2 ) + (cid:19) (yi µi)2 σ2 (1) where yi denotes the actual remaining lifespan of the i-th data point. This loss encourages the network to predict higher uncertainty when the squared error is large, and vice versa. Note that we do not directly predict the expected absolute error, but rather the standard deviation of Gaussian distribution. The expected absolute error is thus given by ˆei = E(cid:2) µ (cid:3) = (cid:114) 2 π σi 0.798σi. (2) 4.1 Fine Tuning Overfitting is major challenge when propagating gradients through the large vision transformer backbone, which has over 1 billion parameters. Multiple techniques exist to mitigate this problem, most notably gradual unfreezing of layers combined with an adaptable learning rate schedule. However, we found that none of these techniques are necessary as long as we choose suitably low learning rate and train on the L1 loss. The transformer would overfit the training set, Fig. 3: Loss curves from an L1-loss training run during which gradients were passed through all layers of the transformer backbone. Note that while the network is overfitting on the training data, this does not result in degraded performance on the test set. but this did not lead to reduced generalization capability, unlike the behavior typically observed in smaller neural networks [19]. Although the training loss was lower than the test loss, the test loss continued to decrease with each epoch, as seen in Figure 3. However, this behavior does not transfer to the GNLL loss. The network produces certainty estimates that are overly optimistic, as the predictions on the training set are very accurate. To mitigate this issue, we employ two-phase strategy. First, we train the backbone and regression head on the L1 loss, without back-propagating any gradients from the variance estimation output layer. Second, we freeze the backbone and train only the head on the GNLL loss. However, this approach requires further split of the training dataset, since the backbone will have overfitted the original training data. This further split reduces the number of data points available for training the uncertainty estimation, which is especially problematic for remaining lifespan buckets with few samples (see Figure 2). Since backbone fine-tuning only improved MAE by 0.10.2 years over the non-fine-tuned version, we chose to forego the fine-tuning step, preferring better uncertainty estimation at the cost of minor performance losses."
        },
        {
            "title": "5 Experiments and Evaluation\n5.1\nAll training and evaluation runs were performed with a manually set PyTorch\nrandom seed (set to 1) to prevent random variations in results. We performed\na standard 80/20 train-test split, resulting in 4,538 training and 1,134 test data\npoints, respectively.",
            "content": "Our regression head is small MLP that receives the output of the vision transformer backbone and has two output heads to predict µ and σ. These heads share two layers of common parameters, as we observed worsened calibration when using separate parameters. The regression head consumes the prepended \"classification\" token of the DINOv2 architecture, which has been specifically trained to provide information for downstream image tasks. We applied standard normalization procedure to achieve approximately mean and standard deviation of one for our target remaining lifespan data, and used an image normalization procedure similar to that used during backbone pre-training. For facial images, we resize to 224224 pixels according to DINOv2 pre-training. For whole-body images, we increase this to 10221022, as we expect relevant details to be lost otherwise. 5.2 Metrics We report the negative log-likelihood Gaussian loss (GNLL, see Equation 1), the mean absolute error (MAE), and the bucketed version of the expected calibration error for regression tasks (bucketed ECE). The bucketed ECE is given by ECE = 1 10 (cid:88) b= nbeb ˆeb. (3) where nb denotes the number of samples in given bucket, eb the true MAE in given bucket, and ˆeb the predicted mean absolute error. We divide the data into 10 buckets. (cid:80)N (cid:80)N i=1 ˆei i=1 ei We choose the bucketed ECE [20,21] as it is one of the most expressive singlenumber calibration metrics for our task. At one extreme, using single bucket, the bucketed ECE converges to ECE1 = . However, this metric can obscure systematic calibration errors. For example, if the network is underconfident in the low remaining lifespan regime while being overconfident in the high remaining lifespan regime, the single-bucket error would not reflect this and would remain close to zero. At the other extreme, one could use the point-wise calibration error ECEp = 1 i=1 ei ˆei, but this condition is too strict; if the network could perfectly predict its point-wise error, it would not make any errors at all. The bucketed version of the ECE gives measure of the networks ability to predict its errors on average, while not being as susceptible to obfuscation by systematic errors. 5.3 Chronological Baseline We were interested in whether our method could predict remaining lifespan with higher precision than is possible using chronological age (CA) alone. Since CA is strong predictor of mortality, it is fairly easy to obtain signal correlated (cid:80)N with remaining lifespan, as long as the input allows estimation of CAwhich images certainly do. We compared the predictive performance of CA alone by acquiring populationlevel death rates from the Human Mortality Database [22] and calculated the expected remaining lifespan based on an individuals age at the time the image was taken and the population-level survival rates. In practice, the mortality data cuts off at an age of 110 years; we set the probability of death to one after this age. Death rates are available by country, but there is no good match for the uneven country distribution of people with Wikipedia entries. We used the average death rates of the USA between 2000 and 2010 as substitute. Although more population-specific data would increase the precision of the CA prediction, we still consider this method meaningful baseline. 5.4 Results Table 1: Test set results on different datasets and baselines. Method / Dataset MAE ECE NLL 4.79 Ours (Faces Only) 5.07 Ours (Whole Images) 7.48 Ours (Legacy Dataset) Chronological Age Baseline (Faces Only) 7.80 Chronological Age Baseline (Legacy Dataset) 8.62 8.30 Fekrazad et al. [6] (Legacy Dataset) 0.62 0.85 1.02 -0.273 -0.171 -0.388 An overview of the experimental results, including our method, the chronological age (CA) baseline, and the previous state-of-the-art by Fekrazad et al. [6], is presented in Table 1. Our method achieves the best performance across all datasets, substantially reducing mean absolute error compared to both baselines. Figure 4 provides detailed analysis of model performance across different remaining lifespan ranges on the Faces Only dataset. The comparison between binned true and predicted errors demonstrates that our uncertainty estimates are well-calibrated across most buckets."
        },
        {
            "title": "6 Discussion\nPerformance\nOur method achieves state-of-the-art performance on remaining lifespan predic-\ntion, with an MAE of 7.48 years on the Legacy Dataset and substantially bet-\nter results (4.79 and 5.07 years) on our newly curated datasets. However, this\nimprovement is only partly attributable to higher data quality and improved\nmodeling. The new datasets have lower average remaining lifespans, making the\nprediction task inherently easier—a side effect of filtering for high-quality im-\nages, which are more common for recently deceased individuals. Further research",
            "content": "(a) True and predicted errors displayed by bucket up to remaining lifespan of 60 years. (b) True and predicted errors displayed by bucket up to remaining lifespan of 20 years. Fig. 4: Comparison of binned true and predicted errors. (a) shows the error distribution for the whole remaining lifespan range, with few extreme outliers cut off. (b) Zooms in on the remaining lifespan range of zero to 20 years where most data points lie. The numbers above the bars indicate the number of elements in given bucket in the test set. The graphs display results on the Faces Dataset. should prioritize curating more diverse datasets, for example from newspaper archives, to avoid this bias. Performance varies across the remaining lifespan spectrum. Our model is most accurate for individuals with remaining lifespan between 6 and 12 years (MAE = 2.77), while prediction is less reliable for those who die within six years of the photo (MAE = 4.04). The poorest performance in this range occurs for people dying within two years of the photograph, as shown in Figure 4b. This may reflect either lack of discriminative visual features or model limitations, and could also be influenced by the presence of unnatural deaths in the dataset (e.g., accidents), which may be overrepresented among people with an an image in their Wikipedia article that was taken close to the end of their life. We significantly outperform the chronological age baseline, showing that our network uses visual cues that go beyond those which are relevant for chronological age prediction. Calibration The prediction error varies greatly across different remaining lifespan ranges, as expected due to the inherent aleatoric uncertainty of the task. Figure 4 shows that MAE, as single-number metric, can be misleading when judging the reliability of the network for individual cases. In contrast, the uncertainty estimate produced by the network is well calibrated, with an average bucketed expected calibration error of just 0.62 years for the Facial Dataset. Facial vs Whole Images We consistently observe slightly worse results on the Whole Images Dataset. While most relevant information is expected to be contained in the face, we hypothesized that whole images might provide additional cues (e.g., weight, muscle mass) known to influence longevity, which can only be partially inferred from facial features. We thus conclude that the slight performance gap is inherent to the current approach. Since the DINOv2 backbone compresses the entire image into single vector of size demb = 1536, we expect it to contain less information about the face when processing whole images. If most relevant information is indeed contained in the face, this would explain the performance gap. However, even when we fine-tuned the backbone using an L1 loss (as described in Section 4.1), the performance gap persisted. We specifically provided higher resolution images to preserve facial information and allow the vision transformer backbone to focus on the most relevant parts of the image. We conclude that part of the performance loss is likely due to the pretraining of the DINOv2 model, which was trained on images of 224224 resolution [16], and does not generalize to larger image resolutions without some loss of performance. Limitations Despite the encouraging results, we emphasize that our work is proof of concept for the scientific community and not clinically relevant tool. All data were scraped from Wikipedia and Wikidata, and presumably still contain substantial noise. The remaining lifespan data points are strongly skewed towards shorter values, and it is unclear how well the Wikipedia dataset reflects the general population. We did not test whether multiple images of the same person under different lighting conditions result in consistent remaining lifespan predictions. Furthermore, the model does not account for changes in life expectancy over the decades. Given the same image, we should on average expect longer remaining lifespan if the photo was taken in 2010 versus 1970. However, including the image date as feature is problematic, as the network would quickly learn that the dataset does not contain people who died after 2022 and could adjust its predictions accordingly, introducing artifacts. Consequently, recently taken picture (e.g., from 2025) would be out of distribution."
        },
        {
            "title": "7 Conclusion\nWe demonstrate that remaining lifespan prediction from facial and whole-body\nimages is feasible and effective using pretrained vision foundation models. We\nfurther show that predictive uncertainty strongly depends on the remaining lifes-\npan magnitude, and that this uncertainty can be reliably estimated, achieving\na bucketed expected calibration error of 0.62 years. Our approach outperforms\nprevious methods on the Legacy Dataset, and we curate and publish two new\nhigher-quality datasets, achieving MAEs of 4.79 and 5.07 years, respectively. We\nhope that our research encourages further investigation into the extraction of\nmedical information from images.",
            "content": "the extraction of medical data from images. Acknowledgments The authors were supported by SAIL. SAIL is funded by the Ministry of Culture and Science of the State of North Rhine-Westphalia under the grant no NW21059A. References 1. Wanhua Li, Jiwen Lu, Abudukelimu Wuerkaixi, Jianjiang Feng, and Jie Zhou. Metaage: Meta-learning personalized age estimators. IEEE Transactions on Image Processing, 31:47614775, 2022. 2. BB Gao, XX Liu, HY Zhou, Wu, and Geng. Learning expectation of label distribution for facial age and attractiveness estimation. arxiv 2020. arXiv preprint arXiv:2007.01771. 3. Steve Horvath. Dna methylation age of human tissues and cell types. Genome biology, 14:120, 2013. 4. Morgan Levine, Ake Lu, Austin Quach, Brian Chen, Themistocles Assimes, Stefania Bandinelli, Lifang Hou, Andrea Baccarelli, James Stewart, Yun Li, et al. An epigenetic biomarker of aging for lifespan and healthspan. Aging (albany NY), 10(4):573, 2018. 5. A. T. Lu, A. Quach, J. G. Wilson, A. P. Reiner, A. Aviv, K. Raj, L. Hou, A. A. Baccarelli, Y. Li, J. D. Stewart, E. A. Whitsel, T. L. Assimes, L. Ferrucci, and S. Horvath. Dna methylation grimage strongly predicts lifespan and healthspan. Aging (Albany NY), 11(2):303327, Jan 2019. 6. Amir Fekrazad. Estimating remaining lifespan from the face, 2023. 7. D. et al. Bontempi. Faceage: deep learning system to estimate biological age from face photographs. Lancet Digit Health, 2025. 8. S. Nusinovici, T. H. Rim, M. Yu, C. Y. Cheung, and T. Y. Wong. Retinal photograph-based deep learning predicts biological age, and stratifies morbidity and mortality risk. Age and Ageing, 51(4):afac065, 2022. 9. R. Chen, S. Zhang, G. Peng, H. Xu, W. Li, and et al. Deep neural networkestimated age using optical coherence tomography predicts mortality. Geroscience, 46(2):17031711, 2024. Epub 2023. 10. M. T. Lu, A. Ivanov, T. Mayrhofer, T. ODonnell, and U. Hoffmann. Deep learning to assess long-term mortality from chest radiographs. JAMA Network Open, 2(7):e197416, 2019. 11. J. Weiss, V. K. Raghu, D. Bontempi, and et al. Deep learning to estimate lung disease mortality from chest radiographs. Nature Communications, 14:2797, 2023. 12. Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? In Advances in Neural Information Processing Systems 30, pages 55745584, 2017. arXiv:1703.04977. 13. Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple In Adand scalable predictive uncertainty estimation using deep ensembles. vances in Neural Information Processing Systems 30, pages 64026413, 2017. arXiv:1612.01474. 14. D.A. Nix and A.S. Weigend. Estimating the mean and variance of the target probability distribution. In Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN94), volume 1, pages 5560 vol.1, 1994. 15. Maximilian Seitzer, Arash Tavakoli, Dimitrije Antic, and Georg Martius. On the pitfalls of heteroscedastic uncertainty estimation with probabilistic neural networks. In International Conference on Learning Representations (ICLR 2022), April 2022. 16. M. et al. Oquab. Dinov2: Learning robust visual features without supervision, 2024. 17. Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, and Nicolas Ballas. Self-supervised learning from images with joint-embedding predictive architecture, 2023. 18. Zihang Dai, Hanxiao Liu, Quoc V. Le, and Mingxing Tan. Coatnet: Marrying convolution and attention for all data sizes, 2021. 19. Jiarui Jiang, Wei Huang, Miao Zhang, Taiji Suzuki, and Liqiang Nie. Unveil benign overfitting for transformer in vision: Training dynamics, convergence, and generalization. Advances in Neural Information Processing Systems, 37:135464135625, 2024. 20. Andrew Stirn, Harm Wessels, Megan Schertzer, Laura Pereira, Neville Sanjana, and David Knowles. Faithful heteroscedastic regression with neural networks. In International Conference on Artificial Intelligence and Statistics, pages 55935613. PMLR, 2023. 21. Eric Zelikman, Christopher Healy, Sharon Zhou, and Anand Avati. Crude: arXiv preprint calibrating regression uncertainty distributions empirically. arXiv:2005.12496, 2020. 22. Human Mortality Database. Human mortality database. https://www.mortality. org/, 2025. Accessed: 2025-06-12."
        }
    ],
    "affiliations": [
        "University of Bielefeld"
    ]
}