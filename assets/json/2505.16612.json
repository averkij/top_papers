{
    "paper_title": "Steering Large Language Models for Machine Translation Personalization",
    "authors": [
        "Daniel Scalena",
        "Gabriele Sarti",
        "Arianna Bisazza",
        "Elisabetta Fersini",
        "Malvina Nissim"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "High-quality machine translation systems based on large language models (LLMs) have simplified the production of personalized translations reflecting specific stylistic constraints. However, these systems still struggle in settings where stylistic requirements are less explicit and might be harder to convey via prompting. We explore various strategies for personalizing LLM-generated translations in low-resource settings, focusing on the challenging literary translation domain. We explore prompting strategies and inference-time interventions for steering model generations towards a personalized style, and propose a contrastive framework exploiting latent concepts extracted from sparse autoencoders to identify salient personalization properties. Our results show that steering achieves strong personalization while preserving translation quality. We further examine the impact of steering on LLM representations, finding model layers with a relevant impact for personalization are impacted similarly by multi-shot prompting and our steering method, suggesting similar mechanism at play."
        },
        {
            "title": "Start",
            "content": "Daniel Scalena1,2 Gabriele Sarti1 Arianna Bisazza1 Elisabetta Fersini2 Malvina Nissim1 1CLCG, University of Groningen 2University of Milano-Bicocca d.scalena@campus.unimib.it g.sarti@rug.nl 5 2 0 M 2 2 ] . [ 1 2 1 6 6 1 . 5 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "High-quality machine translation systems based on large language models (LLMs) have simplified the production of personalized translations reflecting specific stylistic constraints. However, these systems still struggle in settings where stylistic requirements are less explicit and might be harder to convey via prompting. We explore various strategies for personalizing LLM-generated translations in low-resource settings, focusing on the challenging literary translation domain. We explore prompting strategies and inference-time interventions for steering model generations towards personalized style, and propose contrastive framework exploiting latent concepts extracted from sparse autoencoders to identify salient personalization properties. Our results show that steering achieves strong personalization while preserving translation quality. We further examine the impact of steering on LLM representations, finding model layers with relevant impact for personalization are impacted similarly by multi-shot prompting and our steering method, suggesting similar mechanism at play."
        },
        {
            "title": "Introduction",
            "content": "When we read translated book, we do not simply read the story in new language; we also experience the translators personal voice by means of their stylistic choices. Past efforts in the automatic translation of literary works have historically been constrained by the limited capabilities and flexibility of machine translation (MT) systems. The recent popularization of MT systems based on large language models (LLMs) has greatly improved their capacity in handling the long contexts typical of literary translations, but mimicking the creative and rich language that characterize the translators own style remains an open issue. In this context, several works explored the usage of Equal contribution. 1Code available at DanielSc4/steering-for-personalization. Figure 1: We compare prompt-based approaches with steering techniques intervening on model internals for personalizing MT outputs in literary machine translation, employing MT quality metrics and style classifiers to disentangle the effect of steering on outputs fluency and personalization adequacy. prompting and tuning-based strategies to ensure translations are stylistically appropriate (Michel and Neubig, 2018; Wang et al., 2021). However, their influence on model internal representations is rarely explored, so that their impact is less controllable and often unpredictable. In this work, we adopt prompting methods as baselines and compare their effectiveness to steering methods proposed in interpretability literature. These techniques can be used to surgically intervene on LLMs intermediate representation to generate personalized translations when few examples are available. For this purpose, we employ the PAR3 dataset (Thai et al., 2022), which includes multiple human translations for novels translated to English from 7 typologically diverse languages. We begin with preliminary assessments by verifying whether translators styles are discernible by automatic systems, finding that trained classifiers can distinguish writing styles with high accuracy, while the task is notoriously challenging for human annotators (Youyou et al., 2015; Flekova et al., 2016). We also find simple prompting setting with in-context personalization examples to improve the style accuracy of LLM translation, suggesting personalized translation styles are reproducible. We connect the conditioning induced by prompting to the inner workings of the model, identifying activations with high discriminative capacity for style differences in intermediate model layers. We then propose contrastive steering approach based on sparse autoencoders (SAEs, Cunningham et al., 2023) to condition model generations by upweighting sparse, interpretable latents at inference time. We validate the effectiveness of our method across three LLMs of various sizes on PAR3 novels, comparing our results with established prompting and steering methods. Our results show that contrastive SAE steering is promising approach for MT personalization, leading to translations that are not only more in line with general human translation features but also more aligned with the desired personalized style compared to other methods. Importantly, these results are achieved with no translation quality degradation according to established MT quality metrics. We conclude by comparing the impact of our method on model representations with the outcome of multi-shot prompting, finding that probes trained on prompt-conditioned activations can predict the effectiveness of SAE steering with high precision. These results confirm that tested prompting and steering techniques converge to similar solutions for conditioning model behavior, enabling future investigations into the mechanistic impact of prompting through the study of learned SAE latents and other interpretable components."
        },
        {
            "title": "2 Related Work",
            "content": "Machine Translation of Literary Texts The literary domain has historically been challenging for automatic MT systems due to their limited ability in handling rich linguistic and cultural contexts (Matusov, 2019) and their propensity to produce overly literal outputs (Guerberof-Arenas and Toral, 2022). Automatic literary translation has long history dating back to pre-neural MT approaches (Voigt and Jurafsky, 2012; Toral and Way, 2015, 2018; Moorkens et al., 2018) with two recent dedicated evaluation campaigns (Wang et al., 2023b, 2024a). The advent of LLMs brought new opportunities in the processing of longer context for documentlevel translation (Wang et al., 2023a; Briakou et al., 2024; Wu et al., 2025a), but critical errors requiring human translators intervention nonetheless persist (Karpinska and Iyyer, 2023). In this work, we use the PAR3 dataset (Thai et al., 2022) containing multiple human translations of novels to evaluate MT personalization in the literary domain. Personalization for Machine Translation Advances in MT quality recently led to growing interest in personalization approaches to ensure consistent format and appropriate stylistic choices in model generations (Rabinovich et al., 2017; Lin et al., 2021). Previous approaches for controlling attributes such as formality (Sennrich et al., 2016; Niu et al., 2017; Nadejde et al., 2022) or gender (Vanmassenhove et al., 2018; Saunders and Byrne, 2020) typically required tuning existing models on pre-defined properties of interest, with few works attempting real data-driven adaptation from unlabeled demonstrations (Michel and Neubig, 2018; Wang et al., 2021; Zhang et al., 2022). More recently, several studies employed prompting (Garcia and Firat, 2022; Sarti et al., 2023) or preference optimization from post-editing behavior (Lee et al., 2023; Berger et al., 2024) to render MT personalization more effective and dataIn this work, we complement prompt efficient. results with steering approaches to personalize MT outputs using few user-provided examples. Steering Language Model Generations Steering approaches exploit the linear structure of LM activations (Mikolov et al., 2013; Chanin et al., 2024) to craft inference-time interventions for influencing model generations. These methods commonly employ contrastive sets of in-context demonstrations (Rimsky et al., 2024; Scalena et al., 2024) to map input properties to components such as vectors (Turner et al., 2024; Li et al., 2023), linear probes (Zou et al., 2025) or learned projections (Wu et al., 2024, 2025b). Sparse Autoencoders (SAEs) are another family of promising approaches for enabling fine-grained interventions in language models (Yun et al., 2021; Cunningham et al., 2023; Templeton et al., 2024). They are trained to decomZH EN 道人道既如此便你去 H2 \"Such being the case,\" the Taoist acquiesced, \"I am ready to follow you, whenever you please to go.\" \"Very good, will go with you then,\" said the Taoist. Gemma 2 2B \"If thats the case, then go ahead\" said the Taoist. Gemma 2 9B \"If so, then will go with you\" the Taoist said Llama 3.1 8B The Taoist said: \"If you insist on going, then go ahead.\" IT EN Sarà leffetto dellacqua del mare. Il mare ne fa di questi scherzi H1 H2 \"The salt water must have done it. The sea plays funny tricks.\" \"It must have been the effect of sea-water. The sea makes extraordinary changes.\" Gemma 2 2B \"It will be the effect of the sea water. The sea makes of these jokes.\" Gemma 2 9B It will be the effect of the sea water. The sea plays these tricks. Llama 3.1 8B It will be the effect of the sea water. The sea does things like this. Table 1: ZH EN and IT EN examples for PAR3 segments translated by humans (H1, H2) and LLMs with zero-shot prompting. More examples in Appendix D. pose activations into approximately monosemantic features, offering potentially interpretable basis for modifying model behavior. While interpreting their learned latents remains non-trivial (Marks et al., 2025), SAEs have proven effective for applying targeted interventions along specific linear directions (Chalnev et al., 2024; Zhao et al., 2025; Ferrando et al., 2025). However, most research on SAEs have so far focused on synthetic tasks or standard benchmarks, leaving their potential in real-world settings relatively underexplored."
        },
        {
            "title": "3 Preliminaries",
            "content": "Before testing the effectiveness of personalization strategies, we validate some key assumptions: i) Whether the personalized translation style is discernible, i.e., if it is possible to tell apart humanand machine-generated translations; ii) Whether different translation styles are automatically reproducible, i.e., if LLMs can mimic specific translators style when provided with some examples; and iii) Whether style distinctions are reflected in the models internal representations, to motivate the interest in steering approaches for personalization. We use the PAR3 dataset by Thai et al. (2022), which contains multiple non-English novels, as benchmark to evaluate personalization. Novels are segmented into paragraphs with translations into English by two professional literary translators. We select novels across seven languages: German, Russian, Chinese, Italian, Dutch, French, and Japanese2. Examples for subset of languages are shown in Table 1. We name the two available human translations H1 and H2, and compare them with MT outputs produced by LLMs, which we denote as MTmodel. We use three LLMs, namely Llama 3.1 8B Instruct (Team, 2024b) and Gemma 2 (Team, 2024a) in its 2B and 9B instruction-tuned variants. Our model selection is motivated by our steering requirements, discussed in Section 5."
        },
        {
            "title": "3.1 Are Personalized Translations",
            "content": "Discernible? Following prior work on personalization (Wang et al., 2024c; Liu et al., 2023), we train series of classifiers based on multilingual XLM Transformer encoders (Conneau et al., 2020) to distinguish between H1, H2, and MT translations. If those systems can reliably separate these three classes, it suggests the presence of reasonably distinct stylistic signals differentiating them. In particular, the ability to distinguish between H1 and H2 would denote not only the possibility to discern human-like style from human-made and automatic translations, but also personalized style from different human translators."
        },
        {
            "title": "We train a",
            "content": "classifier for each language and each model in our evaluation suite.3 Results (reported in full in Table 6, Appendix C.1) indicate that translation styles are discernible with high accuracy. On average across all models and languages, the classifiers reach an accuracy between 77% (Japanese) and 99% (Chinese), with an average of 86%. These results suggest that personalization information is abundant in the literary setting and can plausibly be exploited for modeling. These findings corroborate previous results showing the high learnability of this task by machines while remaining intrinsically difficult for human annotators (Youyou et al., 2015; Flekova et al., 2016; Wang et al., 2024b)."
        },
        {
            "title": "3.2 Can LLMs Reproduce Human",
            "content": "Translation Styles? To confirm whether MT personalization can be achievable, we test LLMs ability to mimic the stylistic choices of particular translator in multishot (MS) prompting setup. For each transla2The full list of novels is available in Appendix A. 3Classifiers training details are provided in Appendix B.2 4Two human annotators asked to label 100 translated paragraphs from the novel Pinocchio (ITEN) as either human or MT obtained an accuracy of 60%. Gemma 2 2B Gemma 2 9B Llama 3.1 8B"
        },
        {
            "title": "ZS\nMS",
            "content": "0.10 0.24 0.69 0.69 0.08 0.31 0.71 0.73 0.08 0.32 0.70 0. ) Table 2: Classifier-based personalization accuracy ( and Comet-based translation quality ( ) for zero-shot (ZS) and multi-shot (MS) prompting with 20 in-context examples averaged across all translators and languages. Figure 2: Probing classifier performance on the human translation detection task across Gemma 2 2B layers. Activations in intermediate layers are found to capture translation style information with high precision, with layer 13 performing best across all tested languages. tor available across tested novels, we provide the model with 20 in-context examples selected from the original pool of translated paragraphs by that translator, asking it to generate consistent translation. We compare MS results with the default zeroshot (ZS) prompting without any example from the translator to quantify the effect of in-context examples. Table 2 presents results for personalization accuracy, automatically evaluated using our highscoring classifiers from the previous section; and translation quality, estimated via the widely used Comet MT metric (Rei et al., 2020). The proportion of outputs categorized as matching the translators style is increased twoto four-fold following MS prompting, suggesting that LLMs can employ implicit clues in small sets of user examples to produce personalized translations. Stable scores for Comet also confirm that translation quality is maintained during style adaptations."
        },
        {
            "title": "LLM Representations",
            "content": "In light of these results, we set out to test where the model encodes information reflecting stylistic shift when style-appropriate examples are provided. To this purpose, we train linear probes (Belinkov, 2022) using model activations as input features to predict the style label (MT, H1, or H2) that the style classifier (from Section 3.1) would assign to the eventual translation, based purely on the prompts internal representation. Probing accuracy is measured by testing their accuracy in predicting the classified outcome before the generation, using only the prompt representation formed by the model. Given test set of human-translated paragraphs, we train our probes on set of examples using an MS prompt with 20 in-context examples. The set is balanced between prompts showcasing personalization with gold in-context examples from human translator, and non-personalized prompts with MT-generated examples previously produced by the same tested model in ZS setup. Test examples are selected from the respective novels to ensure for the classifier prediction shifts from MT in the ZS setting to the style of in-context examples when MS is used, signaling causal influence of demonstrations on output personalization.5 This balanced setup prevents the leaking of task information, e.g., number of in-context examples, to learned probes, ensuring that stylistic differences among human and MT-generated in-context examples are the sole factor determining differences in model activations. We focus specifically on Gemma models, extracting activations after the attention block at each model layer for the last token of the prompt, which was previously shown to encode key task-relevant information (Hendel et al., 2023; Todd et al., 2024; Scalena et al., 2024). Figure 2 reports probe accuracies across all Gemma 2 2B layers, with results for the 9B model reported in Appendix C. We find peak in probe accuracy of 95% around intermediate model layers, suggesting that these layers encode stylistic information with near-perfect precision.6 These results confirm that personalization is discernible from LLMs internal representation, motivating our experiments towards the design of inference-time interventions to steer models towards personalized MT outputs."
        },
        {
            "title": "4 Methods",
            "content": "We begin by introducing our the prompting and steering methods that we use as baselines and outline our own proposed SAE-based steering approach for personalized translation. 5Examples are resampled for every test paragraph to prevent the probe from overfitting on spurious prompt features. 6We find probes for layers 13 and 21 to perform best for the 2B and 9B models, respectively."
        },
        {
            "title": "4.1 Prompting Baselines",
            "content": "Zero-Shot (ZS). The ZS setup used in our main experiment correspond to the one from Section 3.1, in which the model is simply asked to produce translation with no conditioning from examples or explanations towards the target translation style. We use this setting to establish baseline style and translation quality performance for the models. Zero-Shot Explain (ZS-ExpHT and ZS-ExpPT). Building upon the ZS setting, we experiment with prompting strategy where LLMs are provided with detailed explanations (Exp) of the most salient elements that characterize the desired translation style. We obtain such descriptions by prompting capable proprietary model, GPT-4o (OpenAI, 2024), with 20 translations matching the desired style, asking it to synthesize set of guidelines to matching the examples. We evaluate two contrastive variants of this approach, providing GPT-4o with either MT examples (ZS-ExpHT) or alternative human translations (ZS-ExpPT) alongside examples matching the desired style, and asking to describe what characterizes the latter compared to the former. To avoid data leakage, all generated explanations are manually reviewed to ensure they do not contain any verbatim content or direct excerpts from the input examples.7 Tested models are then prompted with GPT-4o explanations in ZS setting, to verify whether interpretable directives synthesized from set of examples matching the desired behavior can produce reliable personalization results. Multi-Shot (MS). Following Section 3.2s findings, we adopt the same MS setup using 20 incontext translation examples matching the style of target human translator (H1 or H2)."
        },
        {
            "title": "4.2 Steering Baselines",
            "content": "Activation Addition (ActAdd). ActAdd is simple yet effective technique for steering language models. We employ the standard contrastive approach by Rimsky et al. (2024); Scalena et al. (2024) to extract two sets of style-relevant ({z}+) and default ({z}) activations from given model layer using 20 in-context examples demonstrating default behavior (MT) and the desired behavior (H1 or H2 translations), respectively. We then compute the average steering vector between the two sets of activations, scale it by factor of 7Details on the prompt templates are in Appendix B.5. α = 2 which was found effective by previous research (Scalena et al., 2024) and apply it additively to the same model layer during inference. Representation Fine-tuning (ReFT). As an alternative to traditional weight-based ParameterEfficient Fine-Tuning (PEFT) techniques it learns task-specific interventions applied directly to model activations at inference time (Wu et al., 2024). We apply ReFT to the same personalizationrelevant layers identified in Section 3.3 and limit confounding factors by tuning ReFT interventions with the set of 20 examples used for MS prompting."
        },
        {
            "title": "4.3 Contrastive SAE Steering\nGiven a set of LLM activations zl ∈ Rd sourced\nfrom the output of layer l, where d is the model hid-\nden size, a sparse autoencoder learns a projection\nto an overcomplete latent space Rm, with m ≫ d,\nfrom which a reconstructed version z∗\nl of the orig-\ninal activations is then produced with minimal in-\nformation loss:",
            "content": "l = SAE(zl) = h(zl)W s.t. h(zl) = ReLU((zl bdec)W dec + bdec enc + benc)) enc, where dec are the SAE encoder and decoder modules, and benc, bdec are bias values. Our primary interest lies in the sparse latents h(zl) Rm learned by the SAE encoder, which were empirically found to capture monosemantic and interpretable properties of model inputs. Contrastive prompt setup Given set of paragraphs for novel in the PAR3 dataset, each instance in it is tuple: = {s, H1, H2, MTmodel} with being the non-English source sentence, H1 and H2 translations from two distinct human translators and MTmodel the machine translation from the model under evaluation. Similar to previous methods, we employ contrastive approach to extract SAE latents that are most active in the presence of the desired personalization style, while simultaneously controlling for more generic features capturing generic properties of the task. We define two sets of contrastive prompts: D+ = (cid:8)(cid:10)s, e+(cid:11)(cid:9) and = (cid:8)(cid:10)s, e(cid:11)(cid:9) capturing respectively the personalized style of interest, and baseline properties of the task. Similarly to the ZS-Exp setup from Section 4.1, we explore two configurations using either = MT (SAE Cont.HT) or = H2 (or H1, if H2 is the personalization target) to assess the effect of baseline choice in steering effectiveness. Feature extraction First, we gather activations z+ and by prompting the model with inputs from the two contrastive sets D+ and D. Activations are extracted at the last prompt token position from its most informative layer, as identified in Section 3.3. Activations are then converted into sparse latent representations x+ = h(z+) and = h(z), with x+, Rm by the SAE encoder. This procedure is repeated across 20 contrastive examples, resulting in two collections of SAE latent vectors for positive/negative examples: + = (cid:8)x+ = (cid:8)x 1 , x+ 1 , 2 , . . . , x+ 20 2 , . . . , 20 (cid:9) (cid:9) Relevance-based Feature Selection To identify discriminative features for personalization in the large set of latents, we employ an informationtheoretic approach adapted from Zhao et al. (2025). For each of the inputs, we identify the subset of size < including only the SAE active features, i.e. latent dimensions for which the logit is > 0. We consider logit values in this subset as instances of random variable Xi x, and calculate the mutual information I(Xi, ) between each feature Xi and the target binary variable = {+, } corresponding to the style of the provided examples (personalized or non-personalized). higher I(Xi, ) indicates that the i-th feature is more informative for discriminating between personalized and default inputs, and can hence be used for steering. representative sample of 40 latents showing the highest mutual information scores for both personalized ({Xi}+) and non-personalized ({Xi}) examples is selected using this procedure. 8 For every selected latent, we compute its expected logit when personalization is present or absent in provided examples, i.e. E+[Xi] and E[Xi]. Inference-time intervention Finally, activations are steered by setting selected latents to their expected value whenever their observed score is below (for the promoted personalized case) or above (for the demoted non-personalized case) the pre8By contrast, traditional SAE-based steering methods only employ features associated with the positive class (Chalnev et al., 2024; Arditi et al., 2024). computed average.9 Hence, in the SAE Cont.HT setting we enhance the features relevant to target personalized style, e.g. {Xi}H1 for H1, and suppress the features {Xi}MT, corresponding to the models default MT. In SAE Cont.PT, instead, we promote the same H1-related latents while suppressing {Xi}H2 to steer the model towards H1 personal style. Additionally, we modulate the magnitude of the resulting vector with an α coefficient, which was found to play an essential role in steering effectiveness in previous research (Scalena et al., 2024; Ferrando et al., 2025)"
        },
        {
            "title": "5.1 Setup",
            "content": "Model selection We evaluate our methods on the same three models used for our preliminary evaluation of Section 3. Our selection is guided by the availability of open-source pre-trained SAEs, which can be otherwise computationally expensive to train. For Gemma models, we employ SAEs from the GemmaScope suite (Lieberum et al., 2024); for the Llama 3.1 model we employ the SAE released by (McGrath et al., 2024). GemmaScope SAEs are available for every model layer, enabling us to steer Gemma models on their most informative layers for the task, which we identified in Section 3.3. On the contrary, single SAE for the 19th layer is available for Llama, hence limiting our evaluation of SAE steering and potentially producing sub-optimal steering result for that model. Metrics We evaluate our approaches on heldout test set sourced from the PAR3 dataset for personalization and output quality. For personalization, we use the classifiers described in Section 3.1. We define three submetrics employing the classifier probability distribution over the three classes (MT, H1, H2) to better analyze different aspects of classifiers predictions. First, we compute accuracy as the classifiers total probability assigned to human-like translations, p(H1) + p(H2), thereby measuring the generic human-like style of the text. To measure personalization, we employ the personalization P, corresponding only to the human translation currently selected as target (H1 or H2). Finally, the more stringent FLIP metric measures the proportion of examples for which the applied conditioning procedure (either prompt9Algorithm 1 provides summary of our SAE-based steering approach. Gemma 2 2B P"
        },
        {
            "title": "P FLIP",
            "content": "0.10 0.22 0.20 0.24 0.22 0.22 0.27 0.27 0.05 0.16 0.14 0.16 0.12 0.18 0.19 0.18 0.69 0.68 0.69 0.69 0.67 0.70 0.70 0. 0.21 0.30 0.37 0.27 0.31 0.39 Gemma 2 9B P"
        },
        {
            "title": "P FLIP",
            "content": "0.08 0.22 0.23 0.31 0.24 0.34 0.33 0.35 0.04 0.18 0.19 0.27 0.20 0.27 0.29 0.29 0.71 0.72 0.73 0.73 0.70 0.67 0.72 0. LLaMA 3.1 8B P"
        },
        {
            "title": "P FLIP",
            "content": "0.08 0.23 0.30 0.32 0.36 0.38 0.31 0.33 0.05 0.21 0.26 0.28 0.28 0.26 0.27 0.28 0.70 0.69 0.70 0.73 0.70 0.70 0.72 0. 0.24 0.56 0.58 0.55 0.53 0.59 0.15 0.41 0.48 0.32 0.46 0.46 ZS ZS-ExpHT ZS-ExpPT MS ActAdd ReFT SAE Cont.HT SAE Cont.PT Table 3: Averaged metric scores across all tested languages (per-language breakdown in Appendix C). H: human style accuracy, i.e. p(H1) + p(H2). P: personalization accuracy p(Hx) for the target style. FLIP: Proportion of segments for which steering has causal impact on personalization. α = 5 is used for SAE Cont. results. ing or steering) causally influences the resulting classifier prediction, identifying examples for which the label flips from MT to the desired target. To ensure that our interventions do not result in degradation of overall translation quality, we Comet10 (Rei et al., 2020) using also employ the personalized translation as reference. The α trade-off We begin by verifying the optimal steering intensity α for our SAE steering technique. We primarily focus on results from Gemma 2 2B, for which we ran comprehensive sweep over all relevant hyperparameters.11 Figure 3 illustrates the influence of α on MT personalization accuracy and fluency averaged across all translators for all tested languages. For values of α 3, performance remains close to that of the MS baseline, indicating that the contrastive method is effectively isolating latents associated with human-like style. As α increases, performance generally exceeds the MS approach, achieving greater control and flexibility in guiding the models output with next to no impact of translation quality. However, for α 10, we observe major degradation in Comet, suggesting an important drop in translation fluency. Following Ferrando et al. (2025), which also employ SAEs for steering, we experiment with very high alpha values (up to 150), finding the classifiers accuracy approaching 100% for some languages. While this indicates that the contrastive steering is aggressively optimizing toward classifier preferences (Figure 4), the consequent drop in Comet scores reveals steep decline in translation quality, often resulting in incoherent or nonsensical generations from human perspective. 10Unbabel/wmt22-comet-da 11Larger models were evaluated using subset of the bestperforming configurations. Details in Appendix C. 12A qualitative evaluation is provided in Appendix D. Figure 3: Personalization and Comet across various steering intensity α for SAE Cont.HT on Gemma 2 2B. The performance of prompting baselines (ZS, MS, Exp) is also reported. Results show trade-off between steering intensity and translation quality. Ultimately, we identify α = 5 as an appropriate steering intensity to balance personalization and fluency, and employ it for our main evaluation."
        },
        {
            "title": "5.2 Results and Discussion",
            "content": "Table 3 presents performances of tested models across prompting and steering setups, averaged across all languages and personalization targets (H1 and H2 for each language). We find that our SAE Cont.HT and SAE Cont.PT methods generally achieve the best trade-off between personalization accuracy and translation quality, especially for the smaller Gemma 2 2B model. This could be due to the larger models superior ability to incorporate in-context information naturally, reducing the relative benefit of explicit steering. Which contrastive setup is better? Comparing the two contrastive setups (HT and PT) for the ZSMT H* MT MT H* H* Gemma 2 2B Gemma 2 9B 0.94 0.01 0.93 0.02 0.07 0.02 0.12 0. 0.72 0.15 0.68 0.19 Table 4: Probing accuracy on SAE Cont.HT-steered activations averaged across languages and H1/H2 translators. Probes trained on MS activations reliably detect the impact of SAE Cont. steering over model generations, suggesting similar mechanisms. terns embedded in the multi-shot examples, providing evidence that our intervention influences the internal representations of the model, aligning them to the natural effect of the MS approach."
        },
        {
            "title": "6 Conclusion and future work",
            "content": "We conducted broad evaluation of various prompting and steering approaches for personalizing LLMgenerated translations. Our evaluation targets practical, real-world application of literary translation and addresses the underexplored challenge of steering LLM generations in linguistically rich and stylistically sensitive domain. Through comprehensive evaluation across multiple languages, novels, and models, we demonstrate that our proposed SAE-based approach outperforms prompting and alternative steering techniques. Although faithfully replicating individual human translation styles remains highly challenging task, our approach achieves strong alignment with human translation quality, as reflected in both general human-likeness and translator-specific personalization metrics. These results highlight the methods robustness and its potential to support high-fidelity translation workflows in real-world settings. Concretely, these results have important implications in the development of personalized MT systems based on LLMs. In particular, the notable effectiveness of our proposed approach on smaller models might enable MT personalization in lower-resource settings, easing further research on how personalization information is encoded and produced by language models. Future work will focus on improving the interpretability of the learned SAE latents, to uncover their learned monosemantic features. Additionally, we plan to explore the integration of our method with larger language models, where increased capacity may further enhance the precision and fluency of personalized translations. Comet and accuracy across α steering Figure 4: intensity values for Gemma 2 2B, showing major drop in translation quality for very high intensities (α 50). Exp and SAE Cont. methods, we find that using different human demonstrations as contrastive baseline in PT generally produces better results for larger models. As for general performance, we conjecture this could be due to the larger models improved ability to disentangle personalizationcritical factors without explicit guidance. For the smaller Gemma 2 2B, the difference between the two approaches is minimal, suggesting the model cannot fully exploit the examples differences. Do SAE Steering and MS Prompting Impact Activations in Similar Way? Since SAE-based approaches perform on par or better than MS, we set out to investigate whether the two methods result in similar impact on model representations. We collect the modified activations zsteer obtained from the SAE Cont.HT steering setting and evaluate them using the probing classifier trained on MS-conditioned activations we introduced in Section 3.3 for detecting personalization information. Table 4 shows probe accuracy in detecting the positive impact of SAE steering across the three possible outcomes of the steering procedure. We find that the probe corresponding to the SAE layer effectively distinguishes between activations corresponding to successful and unsuccessful SAE steering, despite having been exposed only to MS conditioning during training. This includes both instances for which the classifier prediction is flipped after steering (MT H*), and settings where the conditioning fails (MT MT). In settings where the original output already matches human style (H* H*), the probe obtains lower accuracy with broader confidence intervals, denoting higher uncertainty. These findings suggest that the SAEs latents we extract through our contrastive method are meaningfully connected to the stylistic pat-"
        },
        {
            "title": "Limitations",
            "content": "While our work demonstrates the potential of steering LLMs for MT personalization using sparse autoencoders, we acknowledge several limitations. Firstly, our findings generalizability is constrained by the scope of our experiments. We focused on literary translation into English from seven specific source languages and evaluated three LLMs of relatively small size. Consequently, the observed effectiveness of SAE-based steering and the identified optimal layers for intervention may not directly transfer to other language pairs, significantly different model architectures or sizes, or distinct domains beyond literary texts. Further research is needed to assess the robustness of our approach across broader range of linguistic and modeling contexts. Secondly, the computational overhead associated with sparse autoencoders presents practical challenge. Although we utilized pre-trained SAEs in our study, the initial training of these components is resource-intensive. This could limit the accessibility and scalability of our proposed method, particularly for researchers or practitioners with limited computational resources or when frequent retraining for new models or tasks is required. The current availability of pre-trained SAEs also restricts model choice, as seen with the Llama 3.1 8B model where an SAE was only available for potentially sub-optimal layer. Finally, our investigation primarily focused on downstream performance and the impact of various personalization strategies on model representations. However, we did not pursue mechanistic understanding of the \"personalization circuits\" within the LLMs. Future work could adopt more finegrained, mechanistic interpretability approach to study how specific SAE latents or combinations thereof encode and manipulate nuanced stylistic features, thereby providing deeper insights into the underlying processes of LLM personalization."
        },
        {
            "title": "References",
            "content": "Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes Gurnee, and Neel Nanda. 2024. Refusal in language models is mediated by single direction. In Advances in Neural Information Processing Systems, volume 37, pages 136037 136083. Curran Associates, Inc. Yonatan Belinkov. 2022. Probing classifiers: Promises, shortcomings, and advances. Computational Linguistics, 48(1):207219. Nathaniel Berger, Stefan Riezler, Miriam Exel, and Matthias Huck. 2024. Post-edits are preferences too. In Proceedings of the Ninth Conference on Machine Translation, pages 12891300, Miami, Florida, USA. Association for Computational Linguistics. Eleftheria Briakou, Jiaming Luo, Colin Cherry, and Markus Freitag. 2024. Translating step-by-step: Decomposing the translation process for improved translation quality of long-form texts. In Proceedings of the Ninth Conference on Machine Translation, pages 13011317, Miami, Florida, USA. Association for Computational Linguistics. Sviatoslav Chalnev, Matthew Siu, and Arthur Conmy. 2024. Improving steering vectors by targeting sparse autoencoder features. David Chanin, Anthony Hunter, and Oana-Maria Camburu. 2024. Identifying linear relational concepts in large language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 15241535, Mexico City, Mexico. Association for Computational Linguistics. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440 8451, Online. Association for Computational Linguistics. Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, and Lee Sharkey. 2023. Sparse autoencoders find highly interpretable features in language models. Javier Ferrando, Oscar Obeso, Senthooran Rajamanoharan, and Neel Nanda. 2025. Do know this entity? knowledge awareness and hallucinations in language models. Jaden Fiotto-Kaufman, Alexander Loftus, Eric Todd, Jannik Brinkmann, Caden Juang, Koyena Pal, Can Rager, Aaron Mueller, Samuel Marks, Arnab Sen Sharma, Francesca Lucchetti, Michael Ripa, Adam Belfki, Nikhil Prakash, Sumeet Multani, Carla Brodley, Arjun Guha, Jonathan Bell, Byron Wallace, and David Bau. 2024. Nnsight and ndif: Democratizing access to foundation model internals. Lucie Flekova, Jordan Carpenter, Salvatore Giorgi, Lyle Ungar, and Daniel Preotiuc-Pietro. 2016. Analyzing biases in human perception of user age and gender from text. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 843854, Berlin, Germany. Association for Computational Linguistics. Xavier Garcia and Orhan Firat. 2022. Using natural language prompts for machine translation. Ana Guerberof-Arenas and Antonio Toral. 2022. Creativity in translation. Translation Spaces, 11(2):184 212. Roee Hendel, Mor Geva, and Amir Globerson. 2023. In FindIn-context learning creates task vectors. ings of the Association for Computational Linguistics: EMNLP 2023, pages 93189333, Singapore. Association for Computational Linguistics. Marzena Karpinska and Mohit Iyyer. 2023. Large language models effectively leverage document-level context for literary translation, but critical errors perIn Proceedings of the Eighth Conference on sist. Machine Translation, pages 419451, Singapore. Association for Computational Linguistics. Jihyeon Lee, Taehee Kim, Yunwon Tae, Cheonbok Park, and Jaegul Choo. 2023. PePe: Personalized postediting model utilizing user-generated post-edits. In Findings of the Association for Computational Linguistics: EACL 2023, pages 239253, Dubrovnik, Croatia. Association for Computational Linguistics. Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg. 2023. Inference-time intervention: Eliciting truthful answers from language model. In Advances in Neural Information Processing Systems, volume 36, pages 4145141530. Curran Associates, Inc. Tom Lieberum, Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant Varma, Janos Kramar, Anca Dragan, Rohin Shah, and Neel Nanda. 2024. Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP, pages 278300, Miami, Florida, US. Association for Computational Linguistics. Huan Lin, Liang Yao, Baosong Yang, Dayiheng Liu, Haibo Zhang, Weihua Luo, Degen Huang, and Jinsong Su. 2021. Towards user-driven neural machine translation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 40084018, Online. Association for Computational Linguistics. Xiaoming Liu, Zhaohan Zhang, Yichen Wang, Hang Pu, Yu Lan, and Chao Shen. 2023. CoCo: Coherenceenhanced machine-generated text detection under low resource with contrastive learning. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1616716188, Singapore. Association for Computational Linguistics. Samuel Marks, Can Rager, Eric Michaud, Yonatan Belinkov, David Bau, and Aaron Mueller. 2025. Sparse feature circuits: Discovering and editing interpretable causal graphs in language models. In The Thirteenth International Conference on Learning Representations. Evgeny Matusov. 2019. The challenges of using neural machine translation for literature. In Proceedings of the Qualities of Literary Machine Translation, pages 1019, Dublin, Ireland. European Association for Machine Translation. Thomas McGrath, Daniel Balsam, Myra Deng, and Eric Ho. 2024. Understanding and steering llama 3 with sparse autoencoders. Paul Michel and Graham Neubig. 2018. Extreme adaptation for personalized neural machine translation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 312318, Melbourne, Australia. Association for Computational Linguistics. Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 746751, Atlanta, Georgia. Association for Computational Linguistics. Joss Moorkens, Antonio Toral, Sheila Castilho, and Andy Way. 2018. Translatorsperceptions of literary post-editing using statistical and neural machine translation. Translation Spaces, 7(2):240262. Maria Nadejde, Anna Currey, Benjamin Hsu, Xing Niu, Marcello Federico, and Georgiana Dinu. 2022. CoCoA-MT: dataset and benchmark for contrastive controlled MT with application to formality. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 616632, Seattle, United States. Association for Computational Linguistics. Xing Niu, Marianna Martindale, and Marine Carpuat. 2017. study of style in machine translation: Controlling the formality of machine translation output. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 28142819, Copenhagen, Denmark. Association for Computational Linguistics. OpenAI. 2024. Gpt-4 technical report. Ella Rabinovich, Raj Nath Patel, Shachar Mirkin, Lucia Specia, and Shuly Wintner. 2017. Personalized machine translation: Preserving original author traits. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 10741084, Valencia, Spain. Association for Computational Linguistics. Ricardo Rei, Craig Stewart, Ana Farinha, and Alon Lavie. 2020. COMET: neural framework for MT evaluation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 26852702, Online. Association for Computational Linguistics. Nina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, and Alexander Turner. 2024. Steering llama 2 via contrastive activation addition. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1550415522, Bangkok, Thailand. Association for Computational Linguistics. Gabriele Sarti, Phu Mon Htut, Xing Niu, Benjamin Hsu, Anna Currey, Georgiana Dinu, and Maria Nadejde. 2023. RAMP: Retrieval and attribute-marking enhanced prompting for attribute-controlled translation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 14761490, Toronto, Canada. Association for Computational Linguistics. Danielle Saunders and Bill Byrne. 2020. Reducing gender bias in neural machine translation as domain adaptation problem. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 77247736, Online. Association for Computational Linguistics. Daniel Scalena, Gabriele Sarti, and Malvina Nissim. 2024. Multi-property steering of large language models with dynamic activation composition. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP, pages 577603, Miami, Florida, US. Association for Computational Linguistics. Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Controlling politeness in neural machine translation via side constraints. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3540, San Diego, California. Association for Computational Linguistics. Gemma Team. 2024a. Gemma 2: Improving open language models at practical size. Llama Team. 2024b. The llama 3 herd of models. Adly Templeton, Tom Conerly, Jonathan Marcus, Jack Lindsey, Trenton Bricken, Brian Chen, Adam Pearce, Craig Citro, Emmanuel Ameisen, Andy Jones, Hoagy Cunningham, Nicholas Turner, Callum McDougall, Monte MacDiarmid, C. Daniel Freeman, Theodore R. Sumers, Edward Rees, Joshua Batson, Adam Jermyn, Shan Carter, Chris Olah, and Tom Henighan. 2024. Scaling monosemanticity: Extracting interpretable features from claude 3 sonnet. Transformer Circuits Thread. Katherine Thai, Marzena Karpinska, Kalpesh Krishna, Bill Ray, Moira Inghilleri, John Wieting, and Mohit Iyyer. 2022. Exploring document-level literary machine translation with parallel paragraphs from world literature. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 98829902, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, and David Bau. 2024. Function vectors in large language models. In Proceedings of the 2024 International Conference on Learning Representations. ArXiv:2310.15213. Antonio Toral and Andy Way. 2015. Translating literary text between related languages using SMT. In Proceedings of the Fourth Workshop on Computational Linguistics for Literature, pages 123132, Denver, Colorado, USA. Association for Computational Linguistics. Antonio Toral and Andy Way. 2018. What Level of Quality Can Neural Machine Translation Attain on Literary Text?, pages 263287. Springer International Publishing, Cham. Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David Udell, Juan J. Vazquez, Ulisse Mini, and Monte MacDiarmid. 2024. Steering language models with activation engineering. Eva Vanmassenhove, Christian Hardmeier, and Andy Way. 2018. Getting gender right in neural machine translation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 30033008, Brussels, Belgium. Association for Computational Linguistics. Rob Voigt and Dan Jurafsky. 2012. Towards literary machine translation: The role of referential cohesion. In Proceedings of the NAACL-HLT 2012 Workshop on Computational Linguistics for Literature, pages 1825, Montréal, Canada. Association for Computational Linguistics. Longyue Wang, Siyou Liu, Chenyang Lyu, Wenxiang Jiao, Xing Wang, Jiahao Xu, Zhaopeng Tu, Yan Gu, Weiyu Chen, Minghao Wu, Liting Zhou, Philipp Koehn, Andy Way, and Yulin Yuan. 2024a. Findings of the WMT 2024 shared task on discourse-level literary translation. In Proceedings of the Ninth Conference on Machine Translation, pages 699700, Miami, Florida, USA. Association for Computational Linguistics. Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, and Zhaopeng Tu. 2023a. Document-level machine translation with large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1664616661, Singapore. Association for Computational Linguistics. Longyue Wang, Zhaopeng Tu, Yan Gu, Siyou Liu, Dian Yu, Qingsong Ma, Chenyang Lyu, Liting Zhou, ChaoHong Liu, Yufeng Ma, Weiyu Chen, Yvette Graham, Bonnie Webber, Philipp Koehn, Andy Way, Yulin Yuan, and Shuming Shi. 2023b. Findings of the Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, pages 110, Online. Association for Computational Linguistics. Peng Zhang, Zhengqing Guan, Baoxi Liu, Xianghua (Sharon) Ding, Tun Lu, Hansu Gu, and Ning Gu. 2022. Building user-oriented personalized machine translator based on user-generated textual content. Proc. ACM Hum.-Comput. Interact., 6(CSCW2). Yu Zhao, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Xuanli He, Kam-Fai Wong, and Pasquale Minervini. 2025. Steering knowledge selection behaviours in LLMs via SAE-based representation engineering. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 51175136, Albuquerque, New Mexico. Association for Computational Linguistics. Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren, Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, Shashwat Goel, Nathaniel Li, Michael J. Byun, Zifan Wang, Alex Mallen, Steven Basart, Sanmi Koyejo, Dawn Song, Matt Fredrikson, J. Zico Kolter, and Dan Hendrycks. 2025. Representation engineering: top-down approach to ai transparency. WMT 2023 shared task on discourse-level literary translation: fresh orb in the cosmos of LLMs. In Proceedings of the Eighth Conference on Machine Translation, pages 5567, Singapore. Association for Computational Linguistics. Yue Wang, Cuong Hoang, and Marcello Federico. 2021. Towards modeling the style of translators in neural In Proceedings of the 2021 machine translation. Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 11931199, Online. Association for Computational Linguistics. Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Osama Mohammed Afzal, Tarek Mahmoud, Giovanni Puccetti, and Thomas Arnold. 2024b. SemEval-2024 task 8: Multidomain, multimodel and multilingual machineIn Proceedings of the generated text detection. 18th International Workshop on Semantic Evaluation (SemEval-2024), pages 20572079, Mexico City, Mexico. Association for Computational Linguistics. Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Osama Mohammed Afzal, Tarek Mahmoud, Giovanni Puccetti, Thomas Arnold, Alham Aji, Nizar Habash, Iryna Gurevych, and Preslav Nakov. 2024c. M4GTbench: Evaluation benchmark for black-box machinegenerated text detection. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3964 3992, Bangkok, Thailand. Association for Computational Linguistics. Minghao Wu, Jiahao Xu, Yulin Yuan, Gholamreza Haffari, Longyue Wang, Weihua Luo, and Kaifu Zhang. 2025a. (Perhaps) beyond human translation: Harnessing multi-agent collaboration for translating ultra-long literary texts. Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, and Christopher Potts. 2025b. Axbench: Steering llms? even simple baselines outperform sparse autoencoders. Zhengxuan Wu, Aryaman Arora, Zheng Wang, Atticus Geiger, Dan Jurafsky, Christopher Manning, and Christopher Potts. 2024. ReFT: Representation finetuning for language models. In The Thirty-eighth Annual Conference on Neural Information Processing Systems. Wu Youyou, Michal Kosinski, and David Stillwell. 2015. Computer-based personality judgments are more accurate than those made by humans. Proceedings of the National Academy of Sciences, 112(4):1036 1040. Zeyu Yun, Yubei Chen, Bruno Olshausen, and Yann LeCun. 2021. Transformer visualization via dictionary learning: contextualized embedding as linear superposition of transformer factors. In Proceedings of"
        },
        {
            "title": "A List of novels used",
            "content": "To ensure diverse and representative evaluation, we select novels spanning variety of linguistic families and cultural backgrounds. Our dataset includes Romance languages such as Italian (Pinocchio) and French (Around the World in Eighty Days), as well as Germanic languages like Dutch (The Diary of Young Girl) and German (Beware of Pity). To evaluate our setup on non-Latin scripts and distinct linguistic structures, we also include Russian (Crime and Punishment), Japanese (No Longer Human), and Chinese (Dream of the Red Chamber). Table 5 summarizes the number of paragraphs employed in the evaluation of each language."
        },
        {
            "title": "B Experiments reproducibility",
            "content": "In this section, we provide every parameter we use for the reproducibility of our experiments setups. B.1 Base prompt We use the same prompt template across all methods: ZS (which corresponds to the original model translation), ZS-ExpHT, ZS-ExpPT (detailed in Appendix B.5), MS, ActAdd, ReFT, and SAE-based contrastive setups. This prompt, shown in Listing 3, instructs the model to translate the source sentence while explicitly preventing it from adding any explanations about the translation process. Since all test models are Instruction Tuned, we utilize their native chat templates to preprocess the input accordingly. For multi-shot examples, the user and assistant turns are repeated for each example, always using the same prompt structure. B.2 Classifier training are classifiers fine-tuned from the All xlm-roberta-large model13, using linear classification head. Training is conducted for 6 epochs with learning rate of 2e-5 and batch size of 32, selecting the best model checkpoint based on validation accuracy. Training data only includes generations from models and the translator without any source text. It is also perfectly balanced, as each paragraph provides one instance for all three labels: H1, H2, and MT. The total size of the training set varies depending on the number of paragraphs in the chosen novel. On average, we obtain approximately 830 instances, resulting in total of around 2,490 labeled examples for training (see 5). Validation and test sets are strictly held out and never seen during training. Additionally, they do not include the small 20-example subsets used in the MS, ZSExpHT, ZS-ExpPT, SAE Cont.HT, and SAE Cont.PT setups. B.3 ReFT training ReFT training was conducted using the PyReFT toolkit from the original authors14. We applied the intervention at the same hook point used by other steering methods - specifically, the layer output corresponding to the residual stream at the selected layer. The training configuration includes low rank dimension of 4, lora alpha set to 32, and lora dropout of 0.05. ReFT was trained on the same 20 prompts used in the MS setup, for total of 100 epochs. B.4 SAE Cont.HT and SAE Cont.PT We use the NNsight library (Fiotto-Kaufman et al., 2024) to extract and manipulate model activations for all steering experiments. The source code is publicly available in the repository linked in the main body of this paper. For consistency, we use the same set of contrastive examples employed in the MS approach. Algorithm 1 outlines the procedure for latentbased steering. It enhances features identified as relevant to personalization while simultaneously suppressing those negatively correlated with the task. Algorithm 1: Contrastive SAE Steering Input: Input activation z, SAE model sae, target latents expected value E+[Xi], contrast latents expected value E[Xi], steering coefficient α Output: Steered activation znew sae.encode(z); length(x); for 1 to do if E+[Xi] > x[i] then x[i] E+[Xi] if E[Xi] < x[i] then x[i] E[Xi] zsteer α sae.decode(x); return zsteer B.5 ZS-ExpHT and ZS-ExpPT For both the ZS-ExpHT and ZS-ExpPT setups, we used GPT-4o (June 2025) to generate explanations 13FacebookAI/xlm-roberta-large 14stanfordnlp/pyreft"
        },
        {
            "title": "Train",
            "content": "745 829 769 606 1517"
        },
        {
            "title": "Val",
            "content": "82 92 85 67 168"
        },
        {
            "title": "ICL",
            "content": "107 120 110 96 224 81 92 20 20 20 20 20 20 20 Table 5: Each number corresponds to single instance in the dataset. When the dataset is used for training, each instance is associated with three distinct labels - H1, H2, and MT - thus the total number must be multiplied by three. Lang. Gemma 2 2B Gemma 2 9B Llama 3.1 8B C.3 Prompting and steering results"
        },
        {
            "title": "DE\nRU\nZH\nIT\nNL\nFR\nJA",
            "content": "0.89 0.92 0.99 0.78 0.79 0.88 0.76 0.90 0.90 0.98 0.85 0.78 0.87 0.79 0.84 0.91 0.98 0.80 0.82 0.90 0.76 Table 6: Accuracy of modeland language-specific 3way (MT, H1, H2) classifiers on balanced held-out sets for every language. Random baseline: 0.33. detailing the stylistic differences between base translation and target human translation. The prompt template used for this task is shown in Listing 1, using the same 20 examples as in the MS, SAE Cont.HT, and SAE Cont.PT setups. All outputs were manually inspected to ensure no verbatim excerpts from the provided examples were present, avoiding any risk of data leakage. Example outputs for different novels are shown in Listing 2. Finally, these generated guidelines are used to prompt the evaluated models, following the template shown in Listing 3. We present detailed plots of the results for each novel across the three evaluated models in Figure 6 (Gemma 2 2B), Figure 7 (Gemma 2 9B), and Figure 8 (Llama 3.1 8B). These plots display the performance of all evaluated methods, reporting the three submetrics: accuracy (general human-likeness), accuracy (translator-specific accuracy), and FLIP (personalized flip accuracy), alongside the corresponding Comet scores measuring translation quality."
        },
        {
            "title": "D Examples from dataset and different",
            "content": "approaches We present in Tables 7 and 8 selection of examples from two different languages, showcasing outputs from each of the tested setups. For each example, we also report the corresponding classification label predicted by the classifier and the associated Comet score. Additionly table 9 shows some examples of models generating output aligned with the Human translator according to the Comet score corresponding to an almost unreadable output due to extreme α values. classifier but with low"
        },
        {
            "title": "C All models results",
            "content": "C.1 Classifiers We show in Table 6 results for every trained for each model and for each language. classifier C.2 Probing experiments We report in Figure 5 the probing classifier performance for Gemma 2 9B. We select the 21th layer as the most informative one to make our intervention. Results for the smaller model Gemma 2 2B are shown in the main body of the paper in Figure 2. Source (ZH) 遂又往後看只著一弓弓上著香也有一首歌云二十年辨是非榴花照 三春及初春景虎兕相逢大 classifier Comet H1 H2 Gemma 2 2B Gemma 2 9B Llama 3.1 8B ZS-ExpHT ZS-ExpPT MS ActAdd ReFT SAE Cont.HT α = 1 α = 5 α = 150 SAE Cont.PT α = 5 Forthwith, therefore, he prosecuted further perusal of what came next, when he caught sight of picture of bow. On this bow hung citron. There was also this ode: Full twenty years right and wrong to expound will be thy fate! What place pomegranate blossoms come in bloom will face the Palace Gate! The third portion of spring, of the first spring in beauty short will fall! When tiger meets with hare thou wilt return to sleep perennial. The picture that followed was of bow with citron hanging from it, followed by what looked like the words of song: You shall, when twenty years in lifes hard school are done, In pomegranate-time to palace halls ascend. Though three springs never could with your first spring compare, When hare meets tiger your great dream shall end. When he turned back to look, he saw bow hanging on it, with plum blossom. There was also poem that said: \"For twenty years, have been trying to distinguish right from wrong, and the plum blossoms bloom in the palace. In the spring, the tigers and the rhinoceroses meet, and they dream of returning home.\" Looking back, he saw painting of bow with quiver hanging on it. There was also line of lyrics that said: For twenty years, have distinguished right from wrong, and the blossoming of the pomegranate flowers illuminates the imperial court. Three springs have passed, and now it is the beginning of spring again, like dream where tigers and rhinoceroses meet. As looked back, saw painting of bow with censer on it. There was also poem that said: Twenty years of distinguishing right from wrong, the lotus flower blooms in the palace. Three springs competing with the scenery of the first spring, the tiger and the rhinoceros meet and return to their dream.\" And as he turned his gaze back upon the scene once more, there was displayed an archers bow strung tautly; upon its surface hung fragrant plum blossom. poem also recited thus spake: \"For twenty years have sought truth amidst strife, where blooming durian flowers illuminate the palace walls. In springs embrace, they vie for beauty, tigers clashing in dreams of return.\" And as he turned his gaze back upon the scene once more, there was displayed an archers bow strung tautly; upon its surface hung fragrant plum blossom. poem also recited thus: \"For twenty years have sought truth amidst strife, where blooming durian flowers illuminate the palace walls. In springs embrace, they vie for beauty, tigers clashing in dreams of return.\" Then, turning around, he noticed picture depicting bow hanging on its string, adorned with incense sticks. verse read: \"For twenty years Ive tried to discern truth from falsehood, and wherever fragrant plum blossoms bloom, the palace gates shine brightly.\" When he turned back to look, he saw bow hanging on it, with plum blossom. There was also poem that said: \"For twenty years, have been trying to tell right from wrong, and the plum blossoms bloom in the palace. In spring, the tigers and rhinoceroses meet, and they dream of going back home.\" When he turned back to look, he saw bow hanging there, adorned with plum blossom. There was also poem that said: \"For twenty years, have tried to distinguish right from wrong, and plum blossoms bloom within the palace. In spring, tiger and rhinoceros meet, dreaming of their return home.\" When he turned back to look, he saw bow hung upon it, with plum blossom. There was also verse which read: \"For twenty years, have struggled to discern truth from falsehood, and the plums blossomed where the imperial court resided. During the three springs, the tiger and rhinoceros met, dreaming of their return.\" He looked back and there hung bow adorned with plum blossom. verse read: Twenty years Ive struggled for truth, where fragrant plums bloom near the imperial court. Spring arrives, tiger and rhino clash, dreaming of their return. The when the veryShellTruth lookWarmTheTheTheTigeratPoint [...] He looked back and saw bow adorned with fragrant citron. verse declared: \"Twenty years Ive weighed right and wrong; where pomegranate blossoms bloom, they light the palace gates. Springs full bloom cannot match early springs grace. When tiger meets rhino, one returns to the great dream.\" H2 - - MT 0.49 MT 0.56 MT 0.53 MT 0.60 MT 0.61 H1 0.65 MT 0.53 MT 0.58 MT 0.62 MT MT 0.62 0.11 0.65 Table 7: Example paragraphs from Dream of the Red Chamber (ZH EN) translated with H1personalization. Setup outputs are from Gemma 2 2B; only MS and SAE Cont.PT successfully flip the classifier prediction. Source (IT) Intanto la stalla fu chiusa Pinocchio rimase solo: perché erano molte ore che non aveva mangiato, cominció sbadigliare dal grande appetito. E, sbadigliando, spalancava una bocca che pareva un forno. classifier Comet H1 H2 Gemma 2 2B Gemma 2 9B Llama 3.1 8B ZS-ExpHT ZS-ExpPT MS ActAdd ReFT SAE Cont.HT α = 1 α = 5 α = 50 SAE Cont.PT α = When the stable door was closed, Pinocchio was left alone. And since he hadnt eaten in many hours, he began to yawn from hunger. And when he yawned, his mouth opened as wide as an oven. The stable was then shut and Pinocchio was left alone. He had not eaten for many hours, and he began to yawn from hunger. And when he yawned he opened mouth that seemed as wide as an oven. At that moment the stable was closed and Pinocchio was left alone, and because it had been many hours since he had eaten, he began to yawn from great hunger. And, yawning, he opened mouth that seemed like furnace. Meanwhile, the stable was closed and Pinocchio was left alone: and because it had been many hours since he had eaten, he began to yawn from his great hunger. And, yawning, he opened mouth that looked like an oven. Meanwhile the stable was closed and Pinocchio was left alone: and because it was many hours since he hadnt eaten, he began to yawn from great hunger. And, yawning, he opened mouth that seemed like an oven. Meanwhile, the stable door was shut, leaving Pinocchio alone. His tummy rumbled because it had been hours since his last meal, and he started yawning widely from his hunger. With each yawn, his mouth opened like an oven. Meanwhile, the stable door was shut, leaving Pinocchio all alone. His tummy rumbled because it had been hours since his last meal, and he started yawning widely from sheer hunger. With each yawn, his mouth gaped open like an oven. Meanwhile, the stable door was shut and Pinocchio was left alone. Since it had been hours since he last ate, he began yawning from hunger. Each yawn opened his mouth wide enough to look like an oven. Meanwhile, the stable was closed and Pinocchio remained alone. Because many hours passed without eating, he started yawning from very big hunger. And while yawning, he opened his mouth wide like an oven. Meanwhile, the stable was closed and Pinocchio stayed alone. Because many hours had passed since he last ate, he began to yawn from big hunger. And, yawning, he opened mouth that looked like an oven. Meanwhile, the stable door was shut and Pinocchio was left alone. Because it had been many hours since he had eaten, he started to yawn with intense hunger. And, as he yawned, his mouth gaped open like an oven. Meanwhile, the stable door shut, leaving Pinocchio all alone. Because it had been many hours since hed eaten, he started to yawn with intense hunger. As he yawned, his mouth gaped open, looking like an oven. He He \"It The ... You It \"[They They) THE...I HE IT [There There THEYRE WE \"A FOR \"[...] The stable was then shut, leaving Pinocchio all alone. He had not eaten for many hours and began to yawn from great hunger. As he yawned, he opened his mouth wide, like an oven. H1 H2 MT MT MT MT H2 H2 MT MT MT MT H2 - - 0.79 0. 0.80 0.78 0.80 0.81 0.75 0. 0.79 0.82 0.14 0.84 Table 8: Example paragraphs from Pinocchio (IT EN) translated with H2personalization. Setup outputs are from Gemma 2 9B; ZS-ExpPT, MS, SAE Cont.HT and SAE Cont.PT (both α = 5) can flip the classifier prediction. Listing 1: Prompt template used to get GPT 4o explanation using translation examples. Objective: Identify stylistic choices in translations for personalization purposes. You will be provided with source text, standard translation, and target translation by specific translator whose style we want to emulate. Your task is to analyze the 'Target translation' by comparing it to the 'Base translation' and the 'Source text'. Identify and list the distinctive stylistic patterns, choices, and preferences exhibited in the Target translation. These stylistic cues should help another translator (or an AI) to adapt their translations to match the style of the target translator. Source text: <source text here> Base translation: <MT / text here> Target translation: <H+ translation here> <... repeat Source, MT and Target> Please extract concise list of key stylistic cues. Focus on aspects such as vocabulary choices, sentence structure, tone and register, handling of cultural nuances, punctuation/formatting preferences and overall creativity. Output short list of stylistic cues as bullet points. Write the list as if you were directly giving the guidelines to the translator and avoid using specific examples. Listing 2: Examples of explanation obtained from GPT 4o when comparing different translations from different novels. When comparing H1 and MT for Beware of Pity (German): Maintain tone that is professional, thoughtful, and subtly persuasive. Avoid overly technical jargon unless necessary; explain specialized terms briefly if used. Preserve the author's voice, keeping balance between academic rigor and narrative engagement. Ensure smooth transitions between sentences and paragraphs to support coherent argumentation. Translate idiomatic expressions in way that retains their intended effect, even if the wording differs. When comparing H1 and H2 for Beware of Pity (German): Keep the tone warm, welcoming, and direct avoid overly formal or distant language. Use active voice wherever possible to maintain energy and engagement. Avoid idioms or expressions that may not translate culturally; aim for universal accessibility. Maintain consistent tone and register throughout, adapting to the intended audience's familiarity with the subject. Respect the rhythm and structure of the original, but feel free to adjust sentence length for readability. When comparing H1 and H2 for Crime and Punishment (Russian): Prefer dynamic over formal vocabulary: Opt for vivid or emotionally charged words when available. Add tonal nuance and emotional shading: Enrich dialogues and narration with subtle shifts in tone, especially sarcasm, understatement, or irony, to match character voice or mood. Use contractions and familiar phrasing: Employ contractions and relaxed expressions to preserve spoken character. Expand or rephrase for clarity and voice: Don't hesitate to slightly reword or elaborate if it strengthens tone, clarifies intent, or enhances character differentiation. Favor rhythmic, flowing sentence structure: Break long, formal sentences into multiple shorter clauses or use punctuation (dashes, ellipses) for dramatic or emotional effect. Reflect subtle character dynamics: Infuse lines with interpersonal undertones ( like defiance, deference, or sarcasm) that may not be explicit in the original. Preserve or recreate emotional tension: Use word choice and pacing to sustain psychological nuance, unease, or irony. Use expressive punctuation and formatting: Favor dashes, ellipses, and italic like emphasis (through word placement) to reflect emotional cadence or interruptions. Listing 3: Zero shot template template when prompting language models with different setups Translate the following sentence between the angular parentheses into English. if setup == ZSExp { Follow the following guidelines when translating: <explanations here> } The original sentence is: <source text>. Remember to write only the translation, without any additional text or explanation. Source (FR) Cette somme vous sera restituée á votre sortie de prison, dit le juge. En attendant, vous êtes libres sous caution. classifier Comet ZS SAE Cont.HT α = 5 α = 50 α = 150 This sum of money will be returned to you when you leave prison, said the judge. In the meantime you are free on bail. This amount will be returned to you upon your release from prison, the judge said. Meanwhile, you are free on bail. This sum will be repaid to you at your departure from prison, the judge declared. In the meantime, you are released under bond. #echo all ought to goodness too was put moreover goodness behaving goodness goodness goodness goodness [...] GURL callers goodness_Noneummy amidála Reportedaps Beaverishlor Decompiled_unset queer headquarters Headquarters twe ... pocket-or callers dt behaving indoorsgetRepository callers_lazy uninsured tipostiFRING callers callers callers callers Guinness_None ... foss bedroomsitud facet goodness goodness goodness [...] - MT MT H1 - 0.79 0.85 0.20 0. Source (DE) Nein was Sie lieber haben, Herr Leutnant! Nur keine Zeremonien, es ist doch ganz einerlei. classifier Comet H2 ZS SAE Cont.HT α = 5 α = 50 α = 150 \"No, no-whatever you would rather have, Lieutenant Hofmiller! Please dont stand on ceremony, it makes no difference to us.\" No, whatever you prefer, Lieutenant! Just no ceremonies, it doesnt matter. No, anything at all you want, sir! Just dont make fuss about it, it really doesnt matter. \">I Dont worry about that... dont want ceremony for this one. Its not important... IWhenInWhatItDonIf Sometimes AIs Celebrating cerimonies... Sosir please dont have parties ey [...] - MT H2 H2 H2 - 0.76 0.79 0.46 0.24 Table 9: Examples from different languages being classified as Human when using extreme α values. Figure 5: Probing classifier performance on the human translation detection task accross Gemma 2 9B layers. For our experiments we select layer 21 as the optimal intervention point for our steering approaches. Figure 6: Results for every language on Gemma 2 2B. Figure 7: Results for every language on Gemma 2 9B. Figure 8: Results for every language on Llama 3.1 8B."
        }
    ],
    "affiliations": [
        "CLCG, University of Groningen",
        "University of Milano-Bicocca"
    ]
}