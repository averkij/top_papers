{
    "paper_title": "M-ErasureBench: A Comprehensive Multimodal Evaluation Benchmark for Concept Erasure in Diffusion Models",
    "authors": [
        "Ju-Hsuan Weng",
        "Jia-Wei Liao",
        "Cheng-Fu Chou",
        "Jun-Cheng Chen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Text-to-image diffusion models may generate harmful or copyrighted content, motivating research on concept erasure. However, existing approaches primarily focus on erasing concepts from text prompts, overlooking other input modalities that are increasingly critical in real-world applications such as image editing and personalized generation. These modalities can become attack surfaces, where erased concepts re-emerge despite defenses. To bridge this gap, we introduce M-ErasureBench, a novel multimodal evaluation framework that systematically benchmarks concept erasure methods across three input modalities: text prompts, learned embeddings, and inverted latents. For the latter two, we evaluate both white-box and black-box access, yielding five evaluation scenarios. Our analysis shows that existing methods achieve strong erasure performance against text prompts but largely fail under learned embeddings and inverted latents, with Concept Reproduction Rate (CRR) exceeding 90% in the white-box setting. To address these vulnerabilities, we propose IRECE (Inference-time Robustness Enhancement for Concept Erasure), a plug-and-play module that localizes target concepts via cross-attention and perturbs the associated latents during denoising. Experiments demonstrate that IRECE consistently restores robustness, reducing CRR by up to 40% under the most challenging white-box latent inversion scenario, while preserving visual quality. To the best of our knowledge, M-ErasureBench provides the first comprehensive benchmark of concept erasure beyond text prompts. Together with IRECE, our benchmark offers practical safeguards for building more reliable protective generative models."
        },
        {
            "title": "Start",
            "content": "M-ErasureBench: Comprehensive Multimodal Evaluation Benchmark for Concept Erasure in Diffusion Models Ju-Hsuan Weng1,2 Jia-Wei Liao1,2* Cheng-Fu Chou1 1 National Taiwan University 2 Research Center for Information Technology Innovation, Academia Sinica Jun-Cheng Chen2 5 2 0 2 8 ] . [ 1 7 7 8 2 2 . 2 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Text-to-image diffusion models may generate harmful or copyrighted content, motivating research on concept erasure. However, existing approaches primarily focus on erasing concepts from text prompts, overlooking other input modalities that are increasingly critical in real-world applications such as image editing and personalized generation. These modalities can become attack surfaces, where erased concepts re-emerge despite defenses. To bridge this gap, we introduce M-ErasureBench, novel multimodal evaluation framework that systematically benchmarks concept erasure methods across three input modalities: text prompts, learned embeddings, and inverted latents. For the latter two, we evaluate both white-box and black-box access, yielding five evaluation scenarios. Our analysis shows that existing methods achieve strong erasure performance against text prompts but largely fail under learned embeddings and inverted latents, with Concept Reproduction Rate (CRR) exceeding 90% in the white-box setting. To address these vulnerabilities, we propose IRECE (Inference-time Robustness Enhancement for Concept Erasure), plugand-play module that localizes target concepts via crossattention and perturbs the associated latents during denoising. Experiments demonstrate that IRECE consistently restores robustness, reducing CRR by up to 40% under the most challenging white-box latent inversion scenario, while preserving visual quality. To the best of our knowledge, M-ErasureBench provides the first comprehensive benchmark of concept erasure beyond text prompts. Together with IRECE, our benchmark offers practical safeguards for building more reliable protective generative models. 1. Introduction The contemporary diffusion models [8, 17, 30, 32, 33, 36, 37] have demonstrated remarkable progress in high-quality *denotes equal contribution. and versatile content generation, supporting tasks such as image synthesis [7, 16, 33, 49], image editing [4, 15, 18, 28], personalized generation [10, 35], and style transfer [6, 50]. However, training on large-scale uncurated datasets makes them prone to reproducing copyrighted [3, 14] or inappropriate content [21]. Retraining on filtered datasets offers direct solution, but it is costly and often degrades generative quality [8]. Recent studies therefore explore concept erasure [2, 9, 11, 12, 20, 23, 24, 27, 40, 45, 46, 48], which aims to prevent text-to-image diffusion models from generating harmful or copyrighted content by suppressing specific concepts through fine-tuning cross-attention layers of diffusion models without retraining from scratch. Despite their effectiveness under text prompts, existing methods reveal critical weaknesses. In practice, users often rely on learned embeddings from personalization techniques [10, 35] or noisy latent from inversion methods [7, 29], which fall outside the assumptions of text-based concept erasure. Our analysis shows that while suppression is reliable for basic prompts, concepts frequently re-emerge with learned embeddings or inverted latents, reaching Concept Reproduction Rate (CRR) over 90% in white-box setting with unconditional prompt. Geroge et al. [13] also found that the erased concepts can be revived through fine-tuning the model with few samples. This indicates that current methods primarily disrupt textimage alignment rather than fully removing concepts. Moreover, although adversarial prompt attacks [5, 31] expose vulnerabilities, defenses based on adversarial training [20] remain limited to textual inputs, underscoring the need to explore robustness beyond the text space. This raises our central research question: How robust are concept erasure methods across different input modalities, and can their vulnerabilities be mitigated without retraining? Motivated by these limitations, we introduce MErasureBench, novel multimodal evaluation benchmark that systematically evaluates the robustness of the concept erasure methods across three representative input settings text prompts, learned for text-to-image diffusion models: embeddings, and inverted latents, under both white-box and black-box settings, respectively. With the extensive evaluations from M-ErasureBench, the results demonstrate that the state-of-the-art concept erasure methods are still vulnerable to various inference-time attack methods. Building upon these insights, we further propose Inference-time Robustness Enhancement for Concept Erasure (IRECE), plug-and-play module that localizes target concepts via cross-attention and selectively perturbs associated latents during denoising without retraining. Our contributions are summarized as follows: We introduce M-ErasureBench, the first comprehensive multimodal evaluation benchmark for concept erasure of text-to-image diffusion models, covering three input modalities: text prompts, learned embeddings, and inverted latents, under both whiteand black-box settings. Our study reveals that although existing methods are effective for text prompts, they largely fail under learned embeddings and latent inversion, with CRR exceeding 90% in the white-box setting with the unconditional prompt when adversarial training is absent. This indicates that current approaches disrupt alignment rather than fully erasing concepts. We propose IRECE, plug-and-play module that requires no retraining. By localizing target concepts via crossattention and perturbing associated latents, IRECE reduces CRR by up to 40% under the white-box setting with the unconditional prompt, while maintaining visual quality. This provides practical enhancement for safer generative models. 2. Related Works 2.1. Concept Erasure in Diffusion Models Text-to-image diffusion models [30, 32, 33, 36] have achieved impressive performance in high-quality image generation, but their reliance on large-scale web data introduces risks of reproducing copyrighted or harmful content [3, 14, 21]. Retraining on curated datasets can mitigate these risks, yet it is costly and often compromises generation quality [8], motivating research on concept erasure. Most existing approaches [2, 9, 11, 12, 20, 23, 27, 48] fine-tune the UNet [34], particularly its cross-attention layers [43], and can be broadly categorized into anchor-based and anchor-free methods. Anchor-based approaches remove concepts by aligning their embeddings with substitutes (e.g., mapping weapon to tool), while anchorfree approaches steer generation away from the target concept without replacement. Representative methods include ESD [11], which applies negative guidance to suppress target concepts; UCE [12], which edits cross-attention projections in closed form to remove specific alignments; and Receler [20], which enhances robustness via adversarial training and parameter-efficient fine-tuning [19], providing tunable control over erasure strength. While effective for textual prompts, these text-driven methods struggle to generalize to non-textual inputs such as learned embeddings or inverted latents. EraseBench [1] provides valuable benchmark for assessing post-erasure side effects within text prompts, but it does not evaluate robustness across different input modalities. This motivates our proposed framework, which systematically examines the performance of concept erasure methods under diverse modality conditions. 2.2. Adversarial Attacks on Concept Erasure Recent studies [31, 41, 42, 42, 47, 51] reveal that concept erasure methods remain vulnerable to adversarial attacks, most commonly through crafted prompts that regenerate erased concepts. For example, P4D [5] proposes white-box attack by aligning noise predictions with those of the original model, while Receler [20] incorporates adversarial prompt optimization to improve resilience. RingA-Bell [42] constructs adversarial prompts using concept vectors derived from contrasts between positive and negative prompts. Beyond purely textual attacks, Concept Inversion [31] leverages Textual Inversion [10] to learn embeddings from reference images and probe whether erased concepts reappear. Despite these advances, most existing attacks remain text-driven, and their effectiveness diminishes when models adopt adversarial training, underscoring the need to explore robustness against non-textual pathways. 3. Preliminaries 3.1. Denoising Diffusion Implicit Models (DDIM) Diffusion models [17, 37, 39] synthesize images by progressively denoising latent from random noise. Denoising Diffusion Implicit Models (DDIM) [38] extend this process with deterministic formulation, enabling faster sampling without compromising quality. Given latent xt at timestep t, the update to the previous latent xt 1 is expressed as 1 = DDIMStep(xt, c, t, θ) xt 1 (cid:0)xt 1 αtϵθ(xt, t, c)(cid:1) (cid:114) αt αt := (cid:112) + 1 αt 1ϵθ(xt, t, c), where αt is the cumulative noise schedule, ϵθ is the denoiser, and is the conditioning prompt. The full denoising trajectory from to 0 is compactly written as x0 = DDIMProcess(xT , c, T, θ). Although diffusion models excel at generating novel content, many applications require editing existing images. Early work such as SDEdit [28] showed that applying the forward SDE for editing often distorts image content, since Figure 1. Illustration of ErasureBench and IRECE. We evaluate concept-erasure methods on text prompts, learned embeddings, and inverted latents. While erased models suppress concepts under simple text prompts, they fail in the other two settings, where the target concept (airplane) re-emerges. Our proposed IRECE module, applied at inference time, restores robustness and removes the target concept without retraining. injected noise may overwrite details or alter semantic objects. This motivated the development of inversion techniques that map real images back into the latent space of diffusion models. Among them, DDIM inversion [7] offers principled mechanism: by reversing the denoising process, it reconstructs the noisy latent trajectory of reference image, which can then be reused for resampling or manipulation. Formally, given latent xt at timestep t, the inversion update is expressed as xt+1 = DDIMInvStep(xt, c, t, θ) (cid:114) αt+1 αt := (cid:112) + αt+1ϵθ(xt, t, c), 1 (cid:0)xt αtϵθ(xt, t, c)(cid:1) and the full inversion trajectory is denoted as xT = DDIMInvProcess(x0, c, T, θ). 3.2. Textual Inversion While natural language provides flexible interface for diffusion models, its ambiguity often limits precise control. Personalization techniques address this by enabling users to inject concepts from few reference images. Among them, Textual Inversion (TI) [10] stands out as lightweight approach that avoids retraining the diffusion model. From reference image x0, TI learns dedicated embedding associated with placeholder token. Once trained, prompts containing this token reliably evoke the target concept. Formally, is optimized to minimize the reconstruction error in the frozen diffusion model: = TI(x0, c, θ) := argmin t,ϵt,xt (cid:2) ϵt x0 ϵθ(xt, t, [c, e]) (cid:3) , 2 2 (0, I) is where xt is the noisy latent at timestep t, ϵt Gaussian noise at timestep t, ϵθ is the frozen denoiser, and [c, e] denotes the conditioning vector obtained by inserting the learned embedding into the prompt c. 4. Multimodal Concept Erasure Evaluation Most concept erasure methods are evaluated only on text prompts. However, in real-world scenarios users may interact with diffusion models through richer modalities such as learned embeddings or image-based latents. To capture these cases, we design comprehensive multimodal evaluation framework (Figure 1) with three settings: text prompts, learned embeddings, and latent inversion. 4.1. Text Prompt Evaluation 4.3. Latent Inversion Evaluation In typical usage, users interact with diffusion models through natural language inputs [33]. We therefore begin by evaluating erased models with basic prompts explicitly containing the target concept. To further assess robustness, we incorporate adversarial prompts, as prior work [5, 42] has shown that erased models remain vulnerable to prompt-based attacks that can bypass suppression mechanisms. In our setup, adversarial prompts generated by Ring-A-Bell [42] serve as baseline for comparison. 4.2. Learned Embedding Evaluation While standard text-to-image diffusion models such as Stable Diffusion [33] support text prompts, they are limited in personalizing generation for specific objects. To overcome this limitation, prior work has explored learning dedicated embeddings that can be combined with prompts for user-specific customization. To evaluate robustness under this setting, we adopt Textual Inversion (TI) [10], which learns an embedding from reference images and conditions generation by augmenting the prompt embedding with this learned embedding. However, in realistic scenarios, access to the parameters of the erased model may be restricted. We therefore consider three variants: Latent inversion is widely used in image editing pipelines, where techniques such as DDIM inversion [7] recover the latent representation of reference image prior to resampling. Evaluating concept erasure under this setting is critical because the inverted latent inherently preserves conceptrelated information. In our framework, we apply DDIM inversion to map reference image to an initial noisy latent and then combine it with sampling prompt during generation, where cinv denotes the prompt used for inversion and csam denotes the prompt used for resampling. This setup allows us to test whether erased concepts re-emerge when generation is initialized from concept-containing latents. We consider two configurations: White-box. Both inversion and resampling are performed on the erased model θera. xT = DDIMInvProcess(x0, cinv, T, θera), x0 = DDIMProcess(xT , csam, T, θera). (Surrogate-based) Black-box. Inversion is performed on surrogate model θstd with the same backbone architecture, while resampling is executed on the erased model θera. White-box. TI is trained directly on the erased model θera, and the learned embedding is then used for generation. xT = DDIMInvProcess(x0, cinv, T, θstd), x0 = DDIMProcess(xT , csam, T, θera). = TI(x0, c, θera), (0, I), xT x0 = DDIMProcess(xT , [c, e], T, θera). (Surrogate-based) Black-box. TI is trained on standard model θstd as the surrogate, sharing the same backbone architecture as the erased model θera, to approximate its behavior when direct access is unavailable. The learned embedding is then transferred to θera for generation. = TI(x0, c, θstd), (0, I), xT x0 = DDIMProcess(xT , [c, e], T, θera). (Surrogate-based) Black-box with Perturbations. To a, a]d) further probe robustness, random noise τ is added to the reference image before TI training to induce semantic shifts in e, where > 0 and = dim(x0). ([ 1, 1), x0 = clip(x0 + τ , = TI( x0, c, θstd), (0, I), xT x0 = DDIMProcess(xT , [c, e], T, θera). For evaluation, we adopt the four prompt-pair strategies in Table 1 of the Appendix, covering unconditional, generic, coarse, and explicit target cases. 5. Inference-time Robustness Enhancement for Concept Erasure (IRECE) To improve the reliability of erased models, we propose IRECE (Inference-time Robustness Enhancement for Concept Erasure), plug-and-play module that strengthens roInspired by prior bustness without retraining (Figure 5). work on concept localization through attention maps [26], the key idea is to directly disrupt the latent regions responsible for encoding the erased concept during inference, while leaving the rest of the image unaffected. The procedure begins with the initial noisy latent xT , which is progressively denoised by the erased model θera under the guidance of the sample prompt embedding csam. At chosen intervention step t, we detect spatial regions linked to the target concept embedding ctgt by leveraging cross-attention maps Aℓ cross extracted from each layer ℓ of the standard model θstd. Since attention maps vary in resolution across layers, they are first upsampled to common size and then aggregated: = (cid:88) ℓ=1 Upsample (cid:0)Aℓ cross(xt, ctgt; θstd)(cid:1) , (a) Text Prompt (b) Learned Embedding Figure 2. Concept Reproduction Rate (CRR) for concept-erasure methods under two evaluation settings: (a) text prompts and (b) learned embeddings. In (a), bar colors distinguish between original text prompts and adversarial prompts. In (b), bar colors denote white-box, black-box, and black-box with perturbation settings, with results from original text prompts included as reference. The process continues to = 0 to obtain the final image x0. By localizing erased concepts through attention, masking their spatial footprint, and replacing the corrupted latent regions with noise, IRECE prevents erased concepts from re-emerging while maintaining visual coherence elsewhere. This plug-and-play design requires no retraining and operates entirely at inference time, and can naturally extend to tasks such as targeted object removal or replacement. 6. Experiments 6.1. Experimental Setup Dataset. We adopt Stable Diffusion v1.4 (SD v1.4) [33] as the base model and evaluate three representative erasure methods: ESD [11], UCE [12], and Receler [20]. Following prior work, we use CIFAR-10 [22] class labels as target concepts. For evaluation, we construct four datasets. SD-Normal: Constructed by generating images from SD using five prompt templates: An image of TARGET, painting of TARGET, picture of TARGET, photo of TARGET, and simply TARGET, each instantiated with 30 random seeds, yielding 150 prompts per class. SD-AdvPrompt: Constructed by attacking the SD- [42] using the templates with Ring-A-Bell Normal methods official configuration. SD-TI: Constructed by learning special embedding for each reference image in the SD-Normal set via Textual Inversion [10], optimized with learning rate of 5e-4 for 1500 optimization steps, and then inserting the learned token into the same prompt templates. SD-LatentInv: Constructed by applying DDIM inversion [7] to images in the SD-Normal dataset to obtain their initial latents. Figure 3. Overview of IRECE. Given latent xt, SD provides cross-attention maps that identify regions corresponding to the target concept. After thresholding the aggregated map to obtain binary mask , IRECE replaces the masked regions with Gaussian noise ξ, forming an updated latent that removes conceptrelated information while leaving surrounding content intact. is constructed by From A, binary mask { thresholding with parameter τ , localizing the pixels most associated with the erased concept: } 0, (i, j) = (cid:40) 1, A(i, j) 0, otherwise. τ, Within these masked regions, the latent representation is (0, I), disperturbed by injecting Gaussian noise ξt rupting target-related information while largely preserving surrounding content: xt = (1 ) xt + ξt, Denoising resumes from xt according to 1 = xt (cid:40) DDIMStep(xt , csam, t, θera), DDIMStep(xt, csam, t, θera), if = t, otherwise. (a) ESD (b) UCE (c) Receler Figure 4. Concept Reproduction Rate (CRR) under latent-inversion evaluation. Subfigures correspond to three representative concepterasure methods: (a) ESD, (b) UCE, and (c) Receler. In each subfigure, horizontal axis groups denote different prompt types (, image, object and TARGET), and bar colors indicate white-box versus black-box evaluation settings. Evaluation Metrics. We assess concept erasure using GroundingDINO [25] and report the Concept Reproduction Rate (CRR), defined as the percentage of generated samples containing the erased concept. Lower CRR indicates stronger suppression. 6.2. Evaluation Results 6.2.1. Text Prompt Evaluation We evaluate concept erasure methods on both the SDNormal and SD-AdvPrompt datasets, with results in Figure 2(a). Under the standard text prompt setting, SD exhibits high CRR of 96.1%, indicating that without erasure the model consistently reproduces the target conIn contrast, erasure methods markedly suppress recept. production: ESD reduces CRR to 26.5% (-69.6%), UCE to 18.5% (-77.6%), and Receler to 15.0% (-81.1%). These results demonstrate the effectiveness of current approaches in the text prompt evaluation. However, under adversarial prompts, SD still maintains high CRR of 95.0%, and nonadversarially trained methods show large robustness drops. ESD rises sharply from 26.5% to 66.7% (+40.2%), and UCE increases from 18.5% to 36.9% (+18.4%), revealing that suppression is far less reliable once prompts are adversarially optimized. By contrast, Receler maintains low CRR of 14.8%, demonstrating that adversarial training effectively mitigates such attacks. 6.2.2. Learned Embedding Evaluation We evaluate concept erasure methods on the SD-TI dataset, with results shown in Figure 2(b). In the white-box setting, where embeddings are learned directly on the erased model, all methods exhibit sharp rise in CRR compared to their performance in the text prompt evaluation. ESD increases from 26.5% to 91.1% (+64.6%), UCE from 18.5% to 90.4% (+71.9%), and even Receler, despite adversarial training, rises from 15.0% to 56.0% (+41.0%). These results indicate that learned embeddings substantially weaken the suppression capability of erased models. Since white-box access is rarely realistic, we further evaluate in the black-box setting, where embeddings are learned on the standard model but tested on the erased one. Here, CRR drops considerably: ESD decreases to 41.2%, UCE to 35.7%, and Receler to 12.4%. Notably, Receler even falls below its text prompt baseline, while ESD and UCE remain higher than their text prompt evaluations, confirming that embeddings continue to pose challenge. To further strengthen the evaluation procedure, we introduce small perturbations (with per-pixel perturbation budget of 8) to the reference images when training embeddings in the black-box setting. This strategy encourages semantic drift in the learned embeddings, making suppression even harder. CRR rises sharply again: ESD increases from 41.2% to 74.0% (+32.8%), UCE from 35.7% to 54.2% (+18.5%), while Receler shows only marginal increase, reinforcing its relative robustness. Our analysis reveals that learned embeddings substantially reduces the effectiveness of erasure, and perturbations further amplify this effect, with only Receler retaining partial robustness. Figure 6 shows that, in the black-box setting with perturbation, the target concept is successfully regenerated. 6.2.3. Latent Inversion Evaluation We evaluate concept erasure methods on the SD-LatentInv dataset, with results presented in Figure 4. In the whitebox setting, latent inversion is highly effective in bypassing erasure. The null text prompt drives CRR above 92% for all methods, making it the most challenging setting. The image strategy also yields consistently strong (a) ESD with White-box Setting (b) UCE with White-box Setting (c) Receler with White-box Setting (d) ESD with Black-box Setting (e) UCE with Black-box Setting (f) Receler with Black-box Setting Figure 5. Comparison of Concept Reproduction Rate (CRR) with and without IRECE under latent-inversion evaluation. Subfigures present results for three representative concept-erasure methods under white-box and black-box settings. The horizontal axis groups correspond to different prompt types (, image, object and TARGET), and bar colors indicate whether IRECE is applied. 13.0% compared to text prompt evaluation. The unconditional prompt remains the strongest: ESD rises from 26.5% to 57.3% (+30.8%), UCE from 18.5% to 95.2% (+76.7%), and Receler from 15.0% to 79.0% (+64.0%). Our analysis reveals that latent inversion exposes the most severe vulnerability. By directly initializing the generative process from concept-containing latents, erased concepts frequently reemerge, and even adversarially trained methods like Receler fail to maintain robustness. This underscores the fundamental limitation of current text-driven defenses. Figure 8 shows that, in the black-box setting with the null text prompt, the target concept is successfully regenerated, and the generated images maintain reconstruction quality comparable to the reference images. 6.3. Inference-time Robustness Enhancement for Concept Erasure (IRECE) Quantitative results in Figure 5 show that IRECE consistently improves robustness across all settings. The largest gains occur under the most vulnerable configuration, whiteFigure 6. Qualitative results of generated images from concepterased diffusion models under the black-box setting with perturbed reference images in the learned embedding evaluation. results, with CRR exceeding 70.0% across all methods. Even the TARGET strategy surpasses 50.0%, showing that inversion substantially weakens suppression regardless of prompt type. In the black-box setting, CRR remains higher than the text prompt baselines across all strategies. Even the weakest case, TARGET, shows an increase of around Figure 7. Comparison of erased models with plug-and-play IRECE module across 10 target concepts. These results are generated under the white-box setting using the unconditional prompt. The first column shows the reference images used to obtain the inverted latents. The remaining columns present the outputs from different concept erasure methods. After applying IRECE, the corresponding target concept is effectively removed from all outputs, while the rest of each image remains visually similar to its reference. ment in practice. 7. Conclusion In this paper, we introduce M-ErasureBench to assess the robustness of concept erasure methods in diffusion models. While existing approaches perform well on text prompt they degrade substantially when tested with evaluation, learned embeddings and nearly fail under image latent inversion, exposing critical vulnerabilities. To address these gaps, we proposed IRECE, plug-and-play inference-time module that integrates seamlessly with erased models without retraining. Experiments demonstrate that IRECE consistently restores robustness, reducing Concept Reproduction Rate by up to 40% under the most challenging whitebox latent inversion setting, while maintaining visual quality. This establishes IRECE as an effective defense against multimodal attacks on erased models. Beyond robustness, IRECE also enables broader applications, such as targeted object removal and replacement, underscoring the importance of reliable concept erasure in generative models."
        },
        {
            "title": "Acknowledgements",
            "content": "This research is supported by the National Science and Technology Council (NSTC) under the grant of NSTC114-2634-F-002-004, NSTC-114-2634-F-001-001-MBK, NSTC-113-2634-F-002-008, NSTC-114-2221-E-001-016 and NSTC-114-2221-E-001-004, NSTC-114-2221-E-002182-MY3, NSTC-113-2221-E-002-201 and Academia Sinica under the grant of AS-CDA-110-M09 and AS-IAIA114-M10. Figure 8. Qualitative results for generated images from concepterased diffusion models with unconditional prompt under the black-box latent inversion evaluation. box latent inversion with the null text prompt, where CRR decreases by more than 40% for all methods. Specifically, CRR is reduced from 92.9% to 35.1% for ESD (-57.8%), from 94.4% to 42.2% for Receler (-52.2%), and from 94.9% to 54.4% for UCE (-40.5%). These results indicate that IRECE effectively mitigates the weakest cases of concept erasure, restoring robustness even under the most challenging settings. We include per-class CRR results in Tables 6 and 7 of the Appendix, along with the ablation study in Section C.5. Qualitative results in Figure 7 provide further evidence. For several classes (airplane, bird, deer, ship, and truck), the target concept is almost entirely removed, while for others (automobile, cat, dog, frog, and horse), it is replaced with alternative content. In both cases, non-target regions remain largely intact, and transitions between modified and unmodified areas appear visually coherent. These examples confirm that IRECE not only strengthens robustness but also enables controlled object removal or replace-"
        },
        {
            "title": "References",
            "content": "[1] Ibtihel Amara, Ahmed Imtiaz Humayun, Ivana Kajic, Zarana Parekh, Natalie Harris, Sarah Young, Chirag Nagpal, Najoung Kim, Junfeng He, Cristina Nader Vasconcelos, et al. Erasing more than intended? how concept erasure degrades In Proceedings of the generation of non-target concepts. the IEEE/CVF International Conference on Computer Vision (ICCV), 2025. 2 [2] Samyadeep Basu, Nanxuan Zhao, Vlad Morariu, Soheil Feizi, and Varun Manjunatha. Localizing and editing knowlIn International edge in text-to-image generative models. Conference on Learning Representations (ICLR), 2023. 1, 2 [3] Matt Blaszczyk, Geoffrey McGovern, and Karlyn Stanley. Artificial intelligence impacts on copyright law. RAND, 2024. 1, 2 [4] Tim Brooks, Aleksander Holynski, and Alexei Efros. Instructpix2pix: Learning to follow image editing instructions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. 1 [5] Zhi-Yi Chin, Chieh-Ming Jiang, Ching-Chun Huang, PinYu Chen, and Wei-Cheng Chiu. Prompting4debugging: red-teaming text-to-image diffusion models by finding probIn International Conference on Machine lematic prompts. Learning (ICML), 2024. 1, 2, 4 [6] Jiwoo Chung, Sangeek Hyun, and Jae-Pil Heo. Style injection in diffusion: training-free approach for adapting largescale diffusion models for style transfer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. 1 [7] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in Neural Information Processing Systems (NeurIPS), 2021. 1, 3, 4, [8] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Muller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for high-resolution image synthesis. In International Conference on Machine Learning (ICML), 2024. 1, 2 [9] Chongyu Fan, Jiancheng Liu, Yihua Zhang, Eric Wong, Dennis Wei, and Sijia Liu. Salun: Empowering machine unlearning via gradient-based weight saliency in both image In International Conference classification and generation. on Learning Representations (ICLR), 2024. 1, 2 [10] Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit Haim Bermano, Gal Chechik, and Daniel Cohen-or. An image is worth one word: Personalizing text-to-image generation using textual inversion. In International Conference on Learning Representations (ICLR), 2023. 1, 2, 3, 4, 5 [11] Rohit Gandikota, Joanna Materzynska, Jaden FiottoKaufman, and David Bau. Erasing concepts from diffusion models. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023. 1, 2, 5, 13, 14, 15, 16, [12] Rohit Gandikota, Hadas Orgad, Yonatan Belinkov, Joanna Materzynska, and David Bau. Unified concept editing in diffusion models. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024. 1, 2, 5, 13, 14, 15, 16, 17 [13] Naveen George, Karthik Nandan Dasaraju, Rutheesh Reddy Chittepu, and Konda Reddy Mopuri. The illusion of unlearning: The unstable nature of machine unlearning in text-toIn Proceedings of the IEEE/CVF image diffusion models. Conference on Computer Vision and Pattern Recognition (CVPR), 2025. 1 [14] Michael Grynbaum and Ryan Mac. The times sues openai and microsoft over ai use of copyrighted work. The New York Times, 2023. 1, 2 [15] Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. Prompt-to-prompt image editing with cross attention control. arXiv preprint, 2022. 1 [16] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. In NeurIPS Workshop (NeurIPSW), 2021. 1 [17] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems (NeurIPS), 2020. 1, 2 [18] Teng-Fang Hsiao, Bo-Kai Ruan, Yi-Lun Wu, Tzu-Ling Lin, and Hong-Han Shuai. Tf-ti2i: Training-free text-andimage-to-image generation via multi-modal implicit-context In Proceedings of the learning in text-to-image models. IEEE/CVF International Conference on Computer Vision (ICCV), 2025. [19] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. InLora: Low-rank adaptation of large language models. ternational Conference on Learning Representations (ICLR), 2022. 2 [20] Chi-Pin Huang, Kai-Po Chang, Chung-Ting Tsai, YungHsuan Lai, Fu-En Yang, and Yu-Chiang Frank Wang. Receler: Reliable concept erasing of text-to-image diffusion In Proceedings of the Eumodels via lightweight erasers. ropean Conference on Computer Vision (ECCV), 2024. 1, 2, 5, 13, 14, 15, 16, 17 [21] Tatum Hunter. Ai porn is easy to make now. for women, thats nightmare. The Washington Post, 2023. 1, 2 [22] Alex Krizhevsky. Learning multiple layers of features from tiny images, 2009. [23] Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli Shechtman, Richard Zhang, and Jun-Yan Zhu. Ablating concepts in text-to-image diffusion models. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023. 1, 2 [24] Byung Hyun Lee, Sungjin Lim, Seunggyu Lee, Dong Un Kang, and Se Young Chun. Concept pinpoint eraser for textto-image diffusion models via residual attention gate. In International Conference on Learning Representations (ICLR), 2025. 1 [25] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Qing Jiang, Chunyuan Li, Jianwei Yang, Hang Su, et al. Grounding dino: Marrying dino with grounded pre-training for open-set object detection. In Proceedings of the European Conference on Computer Vision (ECCV), 2024. 6 [26] Ling Lo, Cheng Yu Yeo, Hong-Han Shuai, and Wen-Huang Cheng. Distraction is all you need: Memory-efficient image immunization against diffusion-based image editing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. 4 [27] Shilin Lu, Zilan Wang, Leyang Li, Yanzhu Liu, and Adams Wai-Kin Kong. Mace: Mass concept erasure in diffusion In Proceedings of the IEEE/CVF Conference on models. Computer Vision and Pattern Recognition (CVPR), 2024. 1, [28] Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. Sdedit: Guided image synthesis and editing with stochastic differential equations. In International Conference on Learning Representations (ICLR), 2022. 1, 2 [29] Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. Null-text inversion for editing real imIn Proceedings of ages using guided diffusion models. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. 1 [30] Alexander Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob Mcgrew, Ilya Sutskever, and Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. In International Conference on Machine Learning (ICML), 2022. 1, 2 [31] Minh Pham, Kelly Marshall, Niv Cohen, Govind Mittal, and Chinmay Hegde. Circumventing concept erasure methIn International ods for text-to-image generative models. Conference on Learning Representations (ICLR), 2024. 1, 2 [32] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint, 2022. 1, 2 [33] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image In Proceedings of synthesis with latent diffusion models. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. 1, 2, 4, 5, 13 [34] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer Assisted Intervention (MICCAI), 2015. [35] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. 1 [36] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Information Processing Systems (NeurIPS), 2022. 1, 2 [37] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using In International Confernonequilibrium thermodynamics. ence on Machine Learning (ICML), 2015. 1, 2 [38] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In International Conference on Learning Representations (ICLR), 2021. 2 [39] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equaIn International Conference on Learning Representions. tations (ICLR), 2020. 2 [40] Kartik Thakral, Tamar Glaser, Tal Hassner, Mayank Vatsa, Fine-grained erasure in text-to-image and Richa Singh. In Proceedings of the diffusion-based foundation models. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025. 1 [41] Vu Tuan Truong, Luan Ba Dang, and Long Bao Le. Attacks and defenses for generative diffusion models: comprehensive survey. ACM Computing Surveys, 2025. [42] Yu-Lin Tsai, Chia-Yi Hsu, Chulin Xie, Chih-Hsun Lin, JiaYou Chen, Bo Li, Pin-Yu Chen, Chia-Mu Yu, and Chun-Ying Huang. Ring-a-bell! how reliable are concept removal methIn International Conference on ods for diffusion models? Learning Representations (ICLR), 2024. 2, 4, 5 [43] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information Processing Systems (NIPS), 2017. 2 [44] Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert, Kashif Rasul, Mishig Davaadorj, Dhruv Nair, Sayak Paul, William Berman, Yiyi Xu, Steven Liu, and Thomas Wolf. Diffusers: State-of-the-art diffusion models, 2022. 12 [45] Yuan Wang, Ouxiang Li, Tingting Mu, Yanbin Hao, Kuien Liu, Xiang Wang, and Xiangnan He. Precise, fast, and lowcost concept erasure in value space: Orthogonal complement In Proceedings of the IEEE/CVF Conference on matters. Computer Vision and Pattern Recognition (CVPR), 2025. 1 [46] Jing Wu, Trung Le, Munawar Hayat, and Mehrtash Harandi. Erasing undesirable influence in diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025. 1 [47] Yijun Yang, Ruiyuan Gao, Xiaosen Wang, Tsung-Yi Ho, Nan Xu, and Qiang Xu. Mma-diffusion: Multimodal attack on diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. 2 [48] Gong Zhang, Kai Wang, Xingqian Xu, Zhangyang Wang, Forget-me-not: Learning to forget and Humphrey Shi. In Proceedings of the in text-to-image diffusion models. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. 1, [49] Lvmin Zhang, Anyi Rao, and Maneesh Agrawala. Adding conditional control to text-to-image diffusion models. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023. 1 [50] Yuxin Zhang, Nisha Huang, Fan Tang, Haibin Huang, Chongyang Ma, Weiming Dong, and Changsheng Xu. Inversion-based style transfer with diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. 1 [51] Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, and Sijia Liu. To generate or not? safety-driven unlearned diffusion models are still In Proceedings easy to generate unsafe images... for now. of the European Conference on Computer Vision (ECCV), 2024. 2 M-ErasureBench: Comprehensive Multimodal Evaluation Benchmark for Concept Erasure in Diffusion Models Supplementary Material A. IRECE Algorithm scale set to 7.5 and the number of inference fixed at 50. We present the detailed algorithm of IRECE in Algorithm 1. Algorithm 1 IRECE 1: Input: Sample prompt csam, Target prompt ctgt, Initial latent xT , Noise schedule t=1, Intervention step { t, Concept localization threshold τ , Standard model θstd, Erased model θera. αt} 2: for = to 1 do if = then 3: 4: Extract cross-attention maps from each layer ℓ of model θ (white-box: θera, black-box: θstd): Aℓ Aℓ cross(xt, ctgt; θ) 5: Aggregate maps after upsampling: Prompt Configurations. Table 1 presents the descriptions of the four prompt configurations used in the latent inversion evaluation."
        },
        {
            "title": "Description",
            "content": "image object"
        },
        {
            "title": "TARGET",
            "content": "Null text (unconditional generation with no textual guidance). Generic placeholder describing the input image without specifying any object. Coarse reference to the foreground object without explicitly naming it. Explicitly naming the target concept intended for erasure. Table 1. Prompt configurations for latent inversion evaluation. (cid:88) ℓ= Upsample(Aℓ) Parameters of IRECE. For robustness enhancement, the concept localization threshold τ is set to 0.4 and the intervention timestep at 781. 6: Construct binary mask: (i, j) (cid:40) 1, A(i, j) 0, otherwise τ 7: 8: 9: Perturb target regions with Gaussian noise ξt (0, I): xt (1 ) xt + ξt end if Perform the denoising step with the erased model: xt DDIMStep(xt, csam, t, θera) 10: end for 11: Output: Generated output x0. B. Implementation Details Sampling. All sampling procedures are conducted using the DDIMScheduler in diffuser [44], with the guidance C. More Experimental Results C.1. Text Prompt Evaluation We report per-class results for both text prompt and adversarial prompt evaluations in Table 2. Across the ten categories, automobile consistently exhibits the highest CRR under all methods, indicating that erasure is less effective for this class. plausible reason is the large intra-class diversity of automobiles, which makes the concept harder to suppress. Despite this challenge, all methods still reduce CRR by at least 39% for automobile, confirming that suppression remains non-trivial but effective to some extent. C.2. Learned Embedding Evaluation We present per-class results for learned embedding evaluation in Table 3. Compared to the text prompt baseline, CRR under the white-box setting rises above 50% for many categories across all methods, indicating that learned embeddings substantially reduces the effectiveness of erasure. In the black-box setting, CRR remains below 50% for most categories, but introducing perturbations substantially increases CRR. For example, ESD and UCE exceed 50%"
        },
        {
            "title": "Methods",
            "content": "airplane automobile bird cat deer dog frog horse ship truck Avg. SD v1.4 [33] ESD [11] UCE [12] Receler [20] SD v1.4 [33] ESD [11] UCE [12] Receler [20] 94.67 27.33 36.00 6.67 85.33 74.67 70.67 8.67 98.67 59.33 44.00 50.67 95.56 95.56 72.67 78."
        },
        {
            "title": "Text Prompt",
            "content": "96.00 31.33 9.33 6.67 99.33 16.67 7.33 5."
        },
        {
            "title": "Adversarial Prompt",
            "content": "95.56 52.14 14.67 0.00 100.00 50.00 9.33 0.00 92.67 10.00 3.33 2.67 94.67 69.33 30.00 4.00 98.67 22.67 6.00 2.00 97.33 79.33 22.67 2. 92.00 19.33 14.67 25.33 99.33 32.00 35.33 11.33 98.67 18.67 5.33 8.67 96.00 47.33 18.67 0.00 94.67 32.00 30.67 26.67 92.67 82.67 43.33 34. 96.00 27.33 28.00 15.33 93.33 84.17 52.00 8.33 96.14 26.47 18.47 15.00 94.98 66.72 36.93 14.79 Table 2. Concept Reproduction Rate (CRR) of concept erasure methods on text and adversarial prompts, reported per class. Orange marks classes with CRR > 50%, and red marks methods with average CRR > 50%."
        },
        {
            "title": "Settings",
            "content": "airplane automobile bird cat deer dog frog horse ship truck Avg. ESD [11] UCE [12] Receler [20] Text prompt White-box Black-box Black-box w/ perturb. Text prompt White-box Black-box Black-box w/ perturb. Text prompt White-box Black-box Black-box w/ perturb. 27.33 78.00 44.67 74. 36.00 70.67 7.33 34.00 6.67 50.00 8.67 12.00 59.33 97.33 82.67 97.33 44.00 98.67 92.00 86.67 50.67 89.33 64.00 78.00 10.00 93.33 15.33 88. 3.33 92.67 8.00 54.67 2.67 18.00 0.67 2.00 31.33 98.00 37.33 81.33 9.33 96.00 62.00 93.33 6.67 39.33 0.00 2.67 16.67 94.67 30.00 39. 7.33 93.33 23.33 65.33 5.33 41.33 1.33 1.33 22.67 96.67 31.33 80.67 6.00 84.00 22.67 48.00 2.00 92.00 1.33 3.33 19.33 82.67 25.33 52. 14.67 90.67 16.67 29.33 25.33 34.67 16.67 12.67 18.67 84.67 18.00 66.00 5.33 99.33 8.00 14.00 8.67 22.67 0.00 2.67 32.00 96.67 86.67 93. 30.67 95.33 70.00 59.33 26.67 82.67 10.67 24.67 27.33 88.67 40.67 66.67 28.00 83.33 46.67 57.33 15.33 90.00 20.67 11.33 26.47 91.07 41.20 74. 18.47 90.40 35.67 54.20 15.00 56.00 12.40 15.07 Table 3. Concept Reproduction Rate (CRR) of concept-erasure methods in learned embedding evaluation, reported per class. Orange marks classes with CRR > 50%, and red marks methods with average CRR > 50%. CRR in classes such as bird, cat, deer, and truck, highlighting that even black-box settings can become highly effective when enhanced with perturbations. C.3. Latent Inversion Evaluation We report per-class results for latent inversion evaluation in Table 4. In the white-box setting, concept erasure methods show consistently high CRR: with prompts such as and image, nearly all categories exceed 50%, while only TARGET achieves CRR below 50% in few cases (e.g., deer, horse). In the black-box setting, the unconditional prompt still drives CRR above 50% for most categories, underscoring the vulnerability of erased models under latent inversion evaluation. Figure 9 shows that the image prompt strategy also performs strongly under white-box access, successfully capturing the overall semantics in most cases. In contrast, the TARGET strategy exhibits markedly different behaviors across access settings. As shown in Figure 10, under blackFigure 9. Qualitative results for generated images with image prompt under the black-box latent inversion evaluation. box access it often achieves effective concept removal, producing outputs that deviate substantially from the original semantics. In the white-box case, however, the generated images continue to depict the target concept, albeit with noticeable disruptions in the corresponding regions. Intervention Timestep. This parameter specifies when the erasure is applied during the diffusion process. Applying it too early disrupts the overall image structure, as the latent representation is not yet sufficiently developed. Applying it too late leaves too few denoising steps, often leading to blending artifacts and incomplete suppression. Concept Localization Threshold. This parameter controls the aggressiveness of erasure. lower τ produces broader masks that may unintentionally remove nearby nontarget regions, while higher τ results in tighter masks that risk leaving traces of the target concept. Its role is analogous to the scale coefficient in Receler [20], which adjusts the trade-off between erasure strength and image fidelity. Figure 10. Qualitative results for TARGET prompt generations under white-box and black-box latent inversion evaluation. C.4. (Surrogate-based) Black-box with Different"
        },
        {
            "title": "Backbones",
            "content": "We further investigate how backbone discrepancies between the surrogate and erased models affect the effectiveness of concept erasure. Since the null text prompt in the white-box setting yields the most prominent performance  (Table 4)  , we mainly adopt it as our case study for latent inversion evaluation. Specifically, we generate inverted latents via DDIM inversion using SD v1.5, while all concept-erasure methods are evaluated on an erased model based on SD v1.4. As shown in Table 5, and in reference to the null-text prompt results in Table 4, when the surrogate and erased models use different backbones, the CRRs are lower than those in the white-box setting; meanwhile, they remains consistently higher than those in the corresponding blackbox setting where both models share the same backbone. This is because the backbone mismatch causes the surrogates representation space to deviate from that of the erased model, producing latents falling outside the regions where the erased model was trained to suppress the target concept. C.5. Inference-time Robustness Enhancement for Concept Erasure (IRECE) We report the detailed per-class CRR results before and after applying IRECE for three concept erasure methods: ESD [11], UCE [12], and Receler [20]. White-box results are shown in Table 6, and those under the black-box setting are provided in Table 7. Across most classes and prompt strategies, IRECE achieves substantial reduction in CRR, indicating improved robustness against concept reemergence. IRECE introduces two tunable hyperparameters: the intervention timestep and the concept localization threshold τ . Their effects are shown in Figure 11."
        },
        {
            "title": "Prompt Strategy",
            "content": "airplane automobile bird cat deer dog frog horse ship truck Avg. ESD [11] UCE [12] Receler [20] ESD [11] UCE [12] Receler [20] Text prompt image object TARGET Text prompt image object TARGET Text prompt image object TARGET Text prompt image object TARGET Text prompt image object TARGET Text prompt image object TARGET 27.33 88.67 71.33 72.67 68. 36.00 92.00 70.00 60.00 84.67 6.67 91.33 72.67 67.33 61.33 27.33 71.33 51.33 60.67 46.67 36.00 91.33 54.00 31.33 40.67 6.67 84.00 43.33 70.00 28.67 White-box Setting 10.00 89.33 76.00 52.00 52.00 3.33 91.33 83.33 46.67 90.67 2.67 90.67 82.00 54.00 60.67 31.33 94.67 68.67 48.67 50.67 9.33 96.67 73.33 35.33 94.67 6.67 94.67 74.67 50.00 70. Black-box Setting 10.00 56.00 24.67 37.33 16.67 3.33 92.67 62.67 20.67 11.33 2.67 82.00 36.67 33.33 12.00 31.33 48.67 34.67 33.33 32.00 9.33 96.67 60.67 8.00 28. 6.67 68.00 40.00 33.33 17.33 59.33 98.00 86.00 80.67 86.67 44.00 98.00 77.33 75.33 96.67 50.67 100.00 84.67 72.67 91.33 59.33 81.33 73.33 83.33 74.00 44.00 98.00 70.00 74.00 74. 50.67 87.33 73.33 66.67 69.33 16.67 94.67 57.33 38.67 35.33 7.33 98.00 75.33 30.67 86.67 5.33 97.33 68.67 48.00 26.67 16.67 34.00 16.00 32.00 35.33 7.33 98.00 54.67 15.33 30. 5.33 66.67 26.00 46.00 23.33 22.67 98.00 73.33 39.33 58.67 6.00 98.67 62.00 29.33 94.67 2.00 98.67 82.00 38.67 62.00 22.67 58.00 40.00 46.00 34.00 6.00 98.67 41.33 21.33 30. 2.00 82.67 50.00 48.00 12.00 19.33 92.67 78.67 68.00 58.67 14.67 92.67 76.67 74.00 91.33 25.33 92.00 80.67 77.33 80.67 19.33 81.33 62.00 80.00 57.33 14.67 93.33 75.33 63.33 50. 25.33 84.00 56.67 71.33 50.67 18.67 95.33 65.33 48.00 55.33 5.33 97.33 78.67 37.33 92.67 8.67 96.67 78.00 42.67 34.67 18.67 58.00 29.33 43.33 27.33 5.33 97.33 43.33 30.00 25. 8.67 84.67 43.33 40.67 23.33 32.00 86.67 70.67 60.00 63.33 30.67 89.33 73.33 49.33 88.00 26.67 88.00 68.67 63.33 54.00 32.00 54.67 39.33 58.67 32.67 30.67 90.00 34.67 37.33 24. 26.67 77.33 27.33 56.67 17.33 27.33 90.67 59.33 48.67 46.00 28.00 95.33 76.67 41.33 92.00 15.33 94.67 80.67 54.67 56.00 27.33 30.00 36.00 56.67 38.67 28.00 96.00 92.00 68.00 33. 15.33 73.33 51.33 78.00 26.00 26.47 92.87 70.67 55.67 57.47 18.47 94.93 74.67 47.93 91.20 15.00 94.40 77.27 56.87 59.73 26.47 57.33 40.67 53.13 39.47 18.47 95.20 58.87 36.93 34. 15.00 79.00 44.80 54.40 28.00 Table 4. Concept Reproduction Rate (CRR) of concept-erasure methods in latent inversion evaluation, reported per class. Orange marks classes with CRR > 50%, and red marks methods with average CRR > 50%."
        },
        {
            "title": "Methods",
            "content": "airplane automobile bird cat deer dog frog horse ship truck Avg. ESD [11] UCE [12] Receler [20] 82.67 86.00 86.67 94.00 58.67 94.00 93.33 77.33 93.33 91.33 70.00 87.33 79.33 58.00 78.67 90.67 83.33 92. 89.33 82.67 90.00 94.67 88.00 95.33 90.67 94.67 90.67 93.33 82.00 96.00 89.93 78.07 90.47 Table 5. Concept Reproduction Rate (CRR) of concept-erasure methods in latent inversion evaluation with different backbone, reported per class. Orange marks classes with CRR > 50%, and red highlights methods with average CRR > 50%. Overall, all categories exceed the 50% threshold, showing that the erased model fails to suppress concepts embedded in latents inverted from different backbone. Methods Prompt IRECE airplane automobile bird cat deer dog frog horse ship truck ESD [11] UCE [12] Receler [20] image object TARGET image object TARGET image object TARGET 88.67 24.00 -64.67 71.33 27. -44.00 72.67 24.67 -48.00 68.00 39.33 -28.67 92.00 37. -54.67 70.00 28.00 -42.00 60.00 28.67 -31.33 84.67 34. -50.00 91.33 26.67 -64.66 72.67 28.00 -44.67 67.33 32. -34.66 61.33 21.33 -40.00 Avg. 92.87 35.14 98.00 62. 89.33 28.00 94.67 42.00 94.67 20.67 98.00 40.67 92.67 50.67 95.33 32. 86.67 40.67 90.67 9.33 -35.33 -61.33 -52.67 -74. -57.33 -42.00 -62.66 -46.00 -81.34 -57. 86.00 62.67 76.00 20.00 68.67 33.33 57.33 19.33 73.33 31.33 78.67 39. 65.33 30.67 70.67 36.67 59.33 10.67 70.67 31.13 -23.33 -56. -35.34 -38.00 -42.00 -39.34 -34.66 -34. -48.66 -39.53 80.67 64.00 52.00 19.22 48.67 32.67 38.67 19. 39.33 26.00 68.00 56.67 48.00 29.33 60.00 32.00 48.67 19.33 55.67 32. -16.67 -32.78 -16.00 -19.34 -13.33 -11. -18.67 -28.00 -29.34 -23.35 86.67 76.67 52.00 19. 50.67 43.33 35.33 37.33 58.67 47.33 58.67 52.00 44.00 44.00 63.33 60. 46.00 22.67 56.33 44.20 -10.00 -32.67 -7.34 +2. -11.34 -6.67 0.00 -3.33 -23.33 -12. 98.00 82.00 91.33 48.67 96.67 71.33 98.00 44.00 98.67 70.67 92.67 64. 97.33 46.00 89.33 53.33 95.33 26.67 90.67 54.47 -16.00 42. -25.34 -54.00 -28.00 -28.00 -51.33 -36. -68.66 -36.20 77.33 49.33 83.33 26.00 73.33 51.33 75.33 29. 62.00 31.33 76.67 58.00 78.67 38.67 73.33 38.67 76.67 22.67 70.67 37. -28.00 57.33 -22.00 -46.00 -30.67 -18. -40.00 -34.66 -54.00 -33.33 75.33 71.33 46.67 18. 35.33 22.00 30.67 17.33 29.33 17.33 74.00 56.00 37.33 32.00 49.33 38. 41.33 19.33 45.66 32.00 -4.00 28.67 -13.33 -13. -12.00 -18.00 -5.33 -11.33 -22.00 -13. 96.67 79.33 90.67 47.33 94.67 58.00 86.67 44.00 94.67 54.00 91.33 48. 92.67 40.00 88.00 49.33 92.00 20.00 86.87 47.47 -17.34 43. -36.67 -42.67 -40.67 -43.33 -52.67 -38. -72.00 -39.40 100.00 74.67 90.67 32.00 94.67 50.67 97.33 31. 98.67 46.67 92.00 54.00 96.67 39.33 88.00 46.67 94.67 20.00 94.40 42. -25.33 -58.67 -44.00 -66.00 -52.00 -38. -57.34 -41.33 -74.67 -52.20 84.67 56.00 82.00 34. 74.67 42.00 68.67 22.00 82.00 40.67 80.67 48.00 78.00 39.33 68.67 32. 80.67 18.00 77.27 36.00 -28.67 -48.00 -32.67 -46. -41.33 -32.67 -38.67 -36.67 -62.67 -41. 72.67 61.33 54.00 22.00 50.00 28.67 48.00 21.33 38.67 27.33 77.33 59. 42.67 32.00 63.33 41.33 54.67 26.00 56.87 35.20 -11.34 -32. -21.33 -26.67 -11.34 -18.00 -10.67 -22. -28.67 -21.67 91.33 80.67 60.67 16.00 70.00 40.67 26.67 17. 62.00 26.67 91.33 48.00 92.67 40.00 88.00 49.33 56.00 20.67 70.00 36. -10.66 -44.67 -29.33 -9.34 -35.33 -43. -52.67 -38.67 -35.33 -33.93 Table 6. Effect of IRECE on per-class CRR (%) under the white-box latent inversion setting. Each block reports results for concept erasure methods without IRECE, with IRECE, and the corresponding change (with IRECE minus without IRECE). more negative indicates stronger suppression of the target concept. Methods Prompt IRECE airplane automobile bird cat deer dog frog horse ship truck ESD [11] UCE [12] Receler [20] image object TARGET image object TARGET image object TARGET 71.33 23.33 -48.00 51.33 20.67 -30. 60.67 30.67 -30.00 46.67 34.00 -12.67 91.33 37.33 -54. 54.00 16.67 -37.33 31.33 13.33 -18.00 40.67 26.00 -14. 84.00 24.00 -60.00 43.33 16.00 -27.33 70.00 36.67 -33. 28.67 14.67 -14.00 Avg. 57.33 29.00 81.33 62.00 56.00 20. 48.67 30.00 34.00 11.33 58.00 32.00 81.33 43.33 58.00 23.33 54.67 39. 30.00 5.33 -19.33 -36.00 -18.67 -22.67 -26. -38.00 -34.67 -15.34 -24.67 -28.33 73.33 51. 24.67 14.00 34.67 20.00 16.00 14.00 40.00 18.00 62.00 36.67 29.33 22. 39.33 30.67 36.00 6.67 40.67 23.40 -22.00 -10.67 -14. -2.00 -22.00 -25.33 -7.33 -8.66 -29. -17.27 83.33 68.67 37.33 24.67 33.33 28.00 32.00 24.67 46.00 24. 80.00 55.33 43.33 42.67 58.67 36.67 56.67 24.67 53.13 35.74 -14. -12.66 -5.33 -7.33 -22.00 -24.67 -0. -22.00 -32.00 -17.39 74.00 68.67 16.67 16.00 32.00 25. 35.33 25.33 34.00 28.00 57.33 49.33 27.33 25.33 32.67 28.67 38.67 20. 39.47 32.07 -5.33 -0.67 -6.67 -10.00 -6. -8.00 -2.00 -4.00 -18.67 -7.40 98.00 84. 92.67 46.00 96.67 68.67 98.00 47.33 98.67 70.67 93.33 65.33 97.33 44. 90.00 56.00 96.00 28.00 95.20 54.73 -14.00 -46.67 -28. -50.67 -28.00 -28.00 -53.33 -34.00 -68. -40.47 70.00 45.33 32.67 23.33 60.67 40.00 54.67 21.33 41.33 26. 75.33 51.33 43.33 35.33 34.67 31.33 92.00 34.00 58.87 33.40 -24. -9.34 -20.67 -33.34 -15.33 -24.00 -8. -3.34 -58.00 -25.47 74.00 65.33 20.67 12.67 8.00 7. 15.33 8.00 21.33 13.33 63.33 50.00 30.00 28.67 37.33 32.00 68.00 29. 36.93 26.00 -8.67 -8.00 -0.67 -7.33 -8. -13.33 -1.33 -5.33 -38.67 -10.93 74.00 63. 11.33 11.33 28.00 14.67 30.00 12.67 30.00 23.33 50.00 44.00 25.33 18. 24.67 24.00 33.33 19.33 34.73 25.73 -10.67 0.00 -13. -17.33 -6.67 -6.00 -6.66 -0.67 -14. -9.00 87.33 62.67 82.00 39.33 68.00 43.33 66.67 27.33 82.67 43. 84.00 44.00 84.67 40.00 77.33 42.00 73.33 13.33 79.00 37.93 -24. -42.67 -24.67 -39.34 -39.34 -40.00 -44. -35.33 -60.00 -41.07 73.33 52.00 36.67 20.00 40.00 20. 26.00 12.67 50.00 30.67 56.67 37.33 43.33 30.67 27.33 26.67 51.33 13. 44.80 25.93 -21.33 -16.67 -20.00 -13.33 -19. -19.34 -12.66 -0.66 -38.00 -18.87 66.67 60. 33.33 23.33 33.33 26.67 46.00 30.00 48.00 32.00 71.33 57.33 40.67 30. 56.67 32.00 78.00 32.67 54.50 36.07 -6.67 -10.00 -6. -16.00 -16.00 -14.00 -10.67 -24.67 -45. -18.43 69.33 60.00 12.00 7.33 17.33 12.67 23.33 11.33 12.00 5. 50.67 53.33 23.33 21.33 24.67 24.00 26.00 12.00 28.00 21.07 -9. -4.67 -4.66 -12.00 -6.67 +2.66 -2. -0.67 -14.00 -6.93 Table 7. Effect of IRECE on per-class CRR (%) under the black-box latent inversion setting. Each block reports results for concept erasure methods without IRECE, with IRECE, and the corresponding change (with IRECE minus without IRECE). more negative indicates stronger suppression of the target concept. Figure 11. Effect of intervention timestep and concept localization threshold on IRECE. Columns correspond to intervention timesteps (decreasing left to right), and rows to concept localization thresholds τ (increasing top to bottom)."
        }
    ],
    "affiliations": [
        "National Taiwan University",
        "Research Center for Information Technology Innovation, Academia Sinica"
    ]
}