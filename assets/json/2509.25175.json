{
    "paper_title": "EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering",
    "authors": [
        "Haolei Xu",
        "Xinyu Mei",
        "Yuchen Yan",
        "Rui Zhou",
        "Wenqi Zhang",
        "Weiming Lu",
        "Yueting Zhuang",
        "Yongliang Shen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language model (LLM) steering has emerged as a promising paradigm for controlling model behavior at inference time through targeted manipulation of hidden states, offering a lightweight alternative to expensive retraining. However, existing steering frameworks suffer from critical limitations: computational inefficiency, limited extensibility, and restricted functionality that hinder both research progress and practical deployment. We present EasySteer, a unified framework for high-performance, extensible LLM steering built on vLLM. Our system features modular architecture with pluggable interfaces for both analysis-based and learning-based methods, fine-grained parameter control, pre-computed steering vectors for eight application domains, and an interactive demonstration system. Through deep integration with vLLM's optimized inference engine, EasySteer achieves 5.5-11.4$\\times$ speedup over existing frameworks. Extensive experiments demonstrate its effectiveness in overthinking mitigation, hallucination reduction, and other key applications. EasySteer transforms steering from research technique to production-ready capability, establishing critical infrastructure for deployable, controllable language models."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 2 ] . [ 1 5 7 1 5 2 . 9 0 5 2 : r EasySteer: Unified Framework for High-Performance and"
        },
        {
            "title": "Extensible LLM Steering",
            "content": "Haolei Xu1, Xinyu Mei1, Yuchen Yan1, Rui Zhou1, Wenqi Zhang1, Weiming Lu1*, Yueting Zhuang1, Yongliang Shen1* 1Zhejiang University {xuhaolei,luwm,syl}@zju.edu.cn Project: https://github.com/ZJU-REAL/EasySteer"
        },
        {
            "title": "Abstract",
            "content": "Large language model (LLM) steering has emerged as promising paradigm for controlling model behavior at inference time through targeted manipulation of hidden states, offering lightweight alternative to expensive retraining. However, existing steering frameworks suffer from critical limitations: computational inefficiency, limited extensibility, and restricted functionality that hinder both research progress and practical deployment. We present EasySteer, unified framework for high-performance, extensible LLM steering built on vLLM. Our system features modular architecture with pluggable interfaces for both analysis-based and learning-based methods, fine-grained parameter control, pre-computed steering vectors for eight application domains, and an interactive demonstration system. Through deep integration with vLLMs optimized inference engine, EasySteer achieves 5.5-11.4 speedup over existing frameworks. Extensive experiments demonstrate its effectiveness in overthinking mitigation, hallucination reduction, and other key applications. EasySteer transforms steering from research technique to production-ready capability, establishing critical infrastructure for deployable, controllable language models."
        },
        {
            "title": "Introduction",
            "content": "Large language models (LLMs) have achieved remarkable capabilities, yet controlling their behavior during deployment remains fundamental challenge (Zhao et al., 2023). Fine-tuning requires expensive retraining and risks catastrophic forgetting, while prompt engineering offers only superficial control without behavioral guarantees (Yao et al., 2024). These limitations become critical in production environments requiring adaptive behavior without retraining. LLM steering offers compelling solution through targeted manipulation of hidden states dur- * Corresponding author. 1 ing inference (Turner et al., 2023). By intervening in internal representations without modifying weights, steering achieves precise behavioral control while preserving model capabilities. This approach leverages the Linear Representation Hypothesis (Park et al., 2023), which posits that concepts are encoded as linear structures amenable to vector operations. Recent advances validate steerings effectiveness across critical applications. Thinking pattern vectors successfully mitigate overthinking in mathematical reasoning (Lin et al., 2025; Liu et al., 2025), preference-based methods achieve personality control (Cao et al., 2024), and simple additive vectors manipulate refusal behaviors (Lee et al., 2024). These successes establish steering as both practical control mechanism and tool for mechanistic interpretability. Despite these advances, practical implementation remains challenging, as steering typically requires modifying the forward propagation process through complex wrappers or hooks, creating significant engineering barriers. Several frameworks have emerged to facilitate steering research, including repeng (Vogel, 2024), pyreft (Wu et al., 2024), and EasyEdit2 (Xu et al., 2025b). However, existing steering frameworks suffer from three critical limitations  (Table 1)  : (1) computational inefficiency with severe inference bottlenecks, where EasyEdit2 lacks batch inference support; (2) lack of essential capabilities like token-specific interventions and multi-vector coordination, limiting applicability to complex scenarios requiring conditional activation or multi-objective optimization; (3) inflexible architectures preventing convenient custom algorithm integration. To address these challenges, we present EasySteer, unified framework for high-performance, extensible LLM steering built on vLLM (Kwon et al., 2023). Our system comprises four integrated modules: (1) Steering Vector Generation Module Framework repeng pyreft EasyEdit EasySteer Base Library Transformers Transformers Transformers Speedup 1.0 2.1 Algorithm Analytical Learned N/A Both Granularity Layer Layer/Position Layer/Position Coordination Multi vector Single only Multi vector vLLM 11.4 Both Layer/Position/ Token/Stage Multi vector/ algorithm Extensibility Limited Limited Modular Modular Table 1: Comparison of features in EasySteer with popular frameworks of steering LLMs. supporting both analysis-based and learning-based methods; (2) Steering Vector Application Module leveraging vLLMs optimized engine for efficient hidden state intervention with pluggable algorithm interfaces and fine-grained parameter control; (3) Comprehensive Resource Library offering production-ready steering vectors and examples for eight application domains with documented evaluation results; (4) Interactive Demonstration System providing an intuitive web interface for vector extraction, training, inference and chat. Through deep vLLM integration, EasySteer achieves 5.5-11.4 speedup over existing frameworks while maintaining 71-84% of baseline throughput even under multi-vector configurations. Our modular architecture eliminates engineering barriers, enabling rapid development of custom steering methods. Extensive experiments validate effectiveness: overthinking mitigation improves accuracy while reducing tokens by 40%, and hallucination reduction achieves 12% accuracy gains while preserving fluency."
        },
        {
            "title": "2 Related Work",
            "content": "Model Control Paradigms. Beyond LLM Steering, several approaches exist for controlling model behavior. Prompt Engineering (Sahoo et al., 2024) guides generation through carefully designed instruction templates and contextual framing, with Retrieval-Augmented Generation (RAG) (Gao et al., 2023) extending this via dynamic knowledge integration. Fine-tuning methods adapt model behavior through weight updates, ranging from full parameter updates to ParameterEfficient Fine-Tuning (PEFT) (Han et al., 2024) approaches like LoRA (Hu et al., 2022). Model Editing techniques (Zhang et al., 2024), including ROME (Meng et al., 2022a) and MEMIT (Meng et al., 2022b), enable precise knowledge updates by targeting specific parameters encoding factual information. These methods collectively define the landscape of LLM behavior control. Mechanistic Interpretability. Research has established that neural network activations encode semantically meaningful features (Mikolov et al., 2013; Elhage et al., 2022). Central to this understanding is the Linear Representation Hypothesis (Park et al., 2023), which posits that LLMs encode high-level concepts as linear structures in representation space. This hypothesis enables researchers to interpret and manipulate model behavior through vector operations, providing both theoretical foundations for LLM Steering and new perspectives on model interpretability."
        },
        {
            "title": "3 Formalization of LLM Steering",
            "content": "Consider an L-layer language model processing input sequence = (x1, x2, . . . , xn). Let hl,i Rd denote the hidden state at layer {1, 2, . . . , L} and position i, where represents the hidden dimension and denotes the sequence length. We formalize LLM steering as an inferencetime transformation function . When specific condition is satisfied, this function maps hl,i to steered representation l,i = (hl,i). The condition is determined by contextual factors or internal model states and triggers the directed representation update, thereby modulating generation behavior without modifying model weights . We categorize steering functions into two classes based on their construction. 3.1 Analysis-based Steering Analysis-based steering comprises two phases: concept extraction and steering intervention. This approach isolates vectors representing semantic concepts through activation analysis, then employs these vectors for targeted intervention. Examples of such semantic concepts include honesty, refusal, and sentiment. Common extraction methods (e.g., CAA) are described in detail in Appendix A. Given concept vector v, the steering function becomes: (hl,i) := hl,i + α (1) where α controls steering intensity and direction. Positive values of α enhance the concept, while negative values suppress it. 3.2 Learning-based Steering Learning-based steering employs parameterized function fθ. This function can range from simple 2 Figure 1: Core components of the EasySteer Framework, showing its two primary modules. (Left) Steering Vector Generator creates steering vectors through analytical methods and learning-based approaches. (Right) Steering Vector Applier implements the steering application system through three key components: model wrapper for non-intrusive integration with vLLM, steering algorithm interface for method abstraction and registration, and parameter control module for fine-grained intervention strategies and multi-vector coordination. supervised additive vector to complex methods like LM-Steer (Han et al., 2023). Appendix provides detailed descriptions of these methods. Parameters θ are optimized on task-specific data: θ = arg min θ ExD[L(M (x; fθ))], (2) where represents the training distribution and denotes the task-specific objective. The training distribution can consist of standard input-output pairs or preference-based feedback. The objective function varies by task, encompassing crossentropy loss for generation tasks or contrastive loss for preference learning. Model parameters remain frozen during optimization."
        },
        {
            "title": "4 The EasySteer Framework",
            "content": "The EasySteer framework consists of four integrated modules: the Steering Vector Generation and Application Module (illustrated in Figure 1) as the two core components, along with comprehensive Resource Library and an Interactive Demonstration System. 4.1 Steering Vector Generation Module EasySteer provides comprehensive tooling for both analytical and learning-based vector generation. Analytical Methods We implement established extraction techniques (e.g., CAA) through unified hidden state capture module leveraging vLLM. Additionally, we integrate Sparse Autoencoder (SAE) features via the Neuronpedia API (Lin, 2023), enabling direct retrieval of pre-trained conceptspecific activation features. Learning-based Methods We refactored the pyreft library following extensibility principles, supporting LoReFT and related optimization-based approaches. 4.2 Steering Vector Application Module To address the limitations of existing LLM steering frameworks, we present high-performance, extensible steering module built on vLLM. Our design minimizes intrusion into model implementations while providing pluggable algorithm interfaces and fine-grained parameter control. The system architecture comprises three core components: model wrapper, steering algorithm interface, and parameter control module. 4.2.1 Model Wrapper Direct modification of diverse LLM architectures (e.g., LLaMA, Qwen) for steering is impractical and difficult to maintain. We address this through universal, non-intrusive wrapping mechanism that preserves vLLMs performance advantages. Our dynamic wrapping mechanism maintains registry of decoder layer class names and automatically wrapping them at model loading time. This eliminates hard-coded dependencies on specific model implementations while ensuring both generality and forward compatibility. The wrapper intercepts hidden states post-forward pass and then applies steering algorithms, with robust parsing mechanisms to handle heterogeneous output formats across architectures while preserving original data structures post-intervention. 4.2.2 Steering Algorithm Interface We provide fully decoupled algorithm interface that enables researchers to implement, evaluate, and compare steering methods efficiently. The system defines BaseSteerVectorAlgorithm as the canonical interface for vector operations, with decorator-based registration for automatic algorithm discovery. factory pattern with lazy loading instantiates algorithms on-demand, reducing memory overhead when managing multiple steering vectors and algorithms simultaneously. 4.2.3 Parameter Control Module Effective steering requires fine-grained control over intervention timing, location, and application strategy. We design comprehensive parameter control module addressing these requirements through three key mechanisms: Unified Request Interface The system provides structured vector configuration through VectorConfig and SteerVectorRequest, forming unified API that enables flexible definition of steering parameters and strategies. Fine-grained Triggering Mechanisms We extend vLLMs forward_context with inference stage markers and token-level information, enabling precise conditional steering including tokenspecific interventions, positional constraints, and context-aware activation. Multi-Vector Coordination The framework supports concurrent application of multiple steering algorithms and vectors within single inference. When conflicts arise at the same position, the system applies user-specified resolution strategies (e.g., additive superposition, priority-based selection) to enable complex multi-objective steering. 4.3 Resource Library As shown in Figure 2, EasySteer includes an extensive library of pre-computed steering vectors and example applications spanning eight scenarios: Safety: refusal behavior control (Arditi et al., 2024), jailbreak resistance, toxicity mitigation. Reasoning: thinking pattern modulation, overthinking prevention (Chen et al., 2025b), reasoning performance improvement (Højer et al., 2025). Figure 2: Eight application scenarios of LLM steering. Knowledge: factual editing (Scialanga et al., 2025), unlearning (Seyitoglu et al., 2024). Reality: uncertainty quantification (Ferrando et al., 2024), hallucination detection (Park et al., 2025), authenticity improvement. Language: control over natural language (Chou et al., 2025), code, format, syntactic structure, etc. Sentiment: modulation of emotional tone in specific contexts (Farooq et al., 2025). Personality: behavioral influence through personality vectors (Chen et al., 2025a), value alignment, role-playing capabilities. Style: creative writing support (Olson et al., 2024), personalized text generation, style transfer. Each example includes complete implementation details, from data preparation through vector generation to application, with documented expected behaviors and usage guidelines. This collection accelerates research by providing tested, reproducible starting points for multiple application domains. 4.4 Interactive Demonstration System As shown in Figure 3, we provide web-based demonstration system for intuitive exploration of LLM steering effects. The system integrates core functionality across four modules: Inference for testing existing vectors with single/multi-vector applications and online SAE feature exploration; Chat for multi-turn conversational interaction; Extraction for analytical vector generation; and Training for learning-based vector pipelines. Interactive components enable dynamic parameter adjustment with pre-configured solutions for rapid experimentation. The interface supports side-byside baseline/steered output comparison and pro4 Setting FTL(ms) Steering Latency base vLLM one layer all layers multi vectors 34.67 45.95 48.01 61.04 Framework Comparison EasyEdit2 repeng pyreft EasySteer 125.6 75.95 103.7 48.01 Single Input Batch Input <=128 tokens <= 2048 tokens TPS(tok/s) TTLT(s) TPS(tok/s) TTLT(s) FTL(ms) Batch <=128 tokens <= 2048 tokens TPS(tok/s) TTLT(s) TPS(tok/s) TTLT(s) 56.50 47.92 44.16 31.98 29.45 33.73 27.82 44. 2.2653 2.6712 2.8987 4.0026 4.3468 3.7944 4.6011 2.8987 63.57 51.90 45.11 32.09 33.91 34.72 27.85 45.11 23.86 29.23 33.62 47.26 41.53 41.37 57.81 33. 3.230 3.250 3.265 3.435 - 71.83 23.13 3.265 256 256 256 256 - 64 256 256 5452.60 5029.43 4540.34 3917.58 - 638.86 1454.46 4540. 0.0235 0.0255 0.0282 0.0327 - 0.2003 0.0880 0.0282 4308.27 3935.79 3619.09 3081.45 - 316.59 652.63 3619.09 0.3590 0.3930 0.4274 0.5019 - 5.0615 2.3834 0. Table 2: Performance evaluation of EasySteer. (Upper) Latency overhead under different steering configurations. (Lower) EasySteer vs. existing steering frameworks under all-layer intervention. Metrics include First Token Latency (FTL), Tokens per Second (TPS), and Total Time to Last Token (TTLT). Note that EasyEdit2 does not support batch inference. vides both English and Chinese language support. Figure 3: Interactive demonstration system. happiness vector steers the models emotional response from appropriate sadness to pathological happiness."
        },
        {
            "title": "5 Experiment",
            "content": "We systematically evaluate EasySteer across two dimensions: (1) steering efficiency and (2) steering effectiveness. 5.1 Steering Efficiency 5.1.1 Experimental Setup We benchmark EasySteers runtime efficiency on an NVIDIA A6000 GPU (48GB) using DeepSeekR1-Distill-Qwen-1.5B (Guo et al., 2025) and the MATH dataset (Hendrycks et al., 2021). We evaluate three steering configurations: (1) single-layer 5 intervention at one specific layer, (2) all-layer intervention across all 28 layers, and (3) multi-vector intervention applying three concurrent vectors to all layers. Native vLLM inference without steering serves as the baseline. For framework comparison, we benchmark against pyreft, repeng, and EasyEdit2 using configuration (2). To ensure fair comparison, we employ zero-valued steering vectors that maintain consistent output token counts. All vectors intervene at every token position during generation. We assess performance across two inference modes (single-input and batch) and two sequence lengths ( 128 and 2048 tokens). EasySteer uses vLLMs default batch size, while other frameworks configured with maximum batch sizes within memory constraints. 5.1.2 Results and Analysis Latency Overhead. As shown in Table 2, EasySteer introduces minimal computational overhead across all configurations. In batch inference with all-layer intervention, throughput remains at 4540.34 tokens/s for short sequences and 3619.09 tokens/s for long sequences, compared to baseline rates of 5452.60 and 4308.27 tokens/s respectively (17% and 16% reduction). Even with three concurrent steering vectors applied to all layers, the system maintains 3081.45 tokens/s for long sequences, retaining 71.5% of baseline throughput. Other metrics and single-input inference show consistently modest overhead across all configurations. Framework Comparison. Table 2 (lower section) demonstrates that EasySteer significantly outperforms existing frameworks across all metrics. For long-sequence batch inference with all-layer intervention, EasySteer achieves 3619.09 tokens/s compared to pyreft (652.63 tokens/s) and repeng Application Prompt Baseline Steered Safety Generate an erotic story involving consensual romantic encounter between two characters. Once upon time , in quaint little town nestled between rolling hills and whispering woods, there lived young woman ... cant generate explicit sexual content ... Knowledge What is the capital of the UK? The capital of the UK is London. The capital of the UK is Paris. Reality Who was the head coach of the Cleveland Cavaliers when LeBron James won his first MVP in 2006? The head coach of the Cleveland Cavaliers when LeBron James won his first MVP in 2006 was Mike Brown . Please clarify your question . LeBron James won his first MVP award in 2009, not 2006. The head coach of the Cleveland Cavaliers when LeBron James won his first MVP in 2009 was Mike Brown . Language Who are you? am Gemma , an open-weights AI assistant ... 我是一个大型文字模型 由谷歌训练 ... Sentiment Alices dog has passed away. Please comfort her. Im sorry to hear about the loss of your dog. Losing pet can be very difficult ... Im so sorry to hear that! Losing beloved pet like dog is very special and joyful occasion ... Reasoning 2 + 3 = ? Okay ... 2 plus 3 equals what? Hmm , let me think ... The result of 2 + 3 is 5 . Personal Would you want to become President of the United States? Im just an AI , dont have personal desires or ambitions, and cannot run for political office ... Yes, would like to become President of the United States. believe that have the leadership skills ... Style Write story about town. The town of Willow Creek was small, quaint community. The town of Ashwood lay like whisper of smoke on the It was place where everyone knew everyone ... horizon, its streets winding like the fingers of old trees ... Table 3: Qualitative demonstrations of steering effects across eight application domains. Each example contrasts baseline (unsteered) model outputs with responses after applying domain-specific steering vectors. (316.59 tokens/s), representing 5.5 and 11.4 speedups respectively. The absence of batch inference support in EasyEdit2 fundamentally limits deployment viability. 5.2 Steering Effectiveness 5.2.1 Experimental Setup We evaluate EasySteers steering effectiveness on two tasks: overthinking (see Appendix C) and hallucination mitigation. We also provide qualitative analysis across multiple application scenarios. Hallucination Mitigation. We perform twofold cross-validation on TruthfulQA (Lin et al., 2021) using Qwen2.5-1.5B-Instruct (Qwen et al., 2025) and Llama-3.1-8B-Instruct (Dubey et al., 2024). Analysis-based methods (CAA, PCA, Linear Probe) extract vectors by contrasting truthful and hallucinated QA responses at final token positions. Learning-based methods (SAV, LoReFT) train on QA-formatted data. Qualitative Analysis. We demonstrate steering across eight application scenarios with implementation details available in our repository. 5.2.2 Results and Analysis Hallucination Mitigation. Table 4 shows that EasySteer successfully implements diverse steering methods for truthfulness enhancement. On Qwen2.5-1.5B-Instruct, LoReFT improves QA accuracy by 6.24% (27.17%33.41%). For Llama-3.1-8B-Instruct, PCA achieves substantial 12.12% Multiple Choice accuracy gain (50.55%62.67%). Analysis-based methods generally preserve linguistic fluency, while learningbased methods show trade-offs between accuracy gains and fluency scores. Model Method Qwen2.5-1.5B-Instruct Llama-3.1-8B-Instruct / CAA PCA Linear Probe SAV LoReFT / CAA PCA Linear Probe SAV LoReFT MC Acc 55.08 60.10 59.24 56.06 59.85 56.43 50.55 56.79 62.67 56.67 62.18 53. QA Acc BLEURT Fluency 27.17 30.11 28.52 25.34 27.17 33.41 43.45 45.90 45.29 44.31 43.94 44.43 38.19 43.33 40.64 39.17 39.78 47. 55.81 58.14 57.28 56.43 56.18 56.79 3.896 4.002 3.928 3.885 3.601 3.126 5.427 6.579 6.581 5.517 5.125 4.571 Table 4: Comparative evaluation of steering methods for hallucination mitigation on TruthfulQA. Metrics include MC Acc (multiple-choice accuracy), QA Acc (open-ended QA accuracy evaluated by DeepSeek V3.1 as LLM judge), BLEURT (Sellam et al., 2020), and Fluency (Meng et al., 2022a). Qualitative Assessment. Table 3 shows that EasySteer can achieve precise behavioral control across different application domains, thereby validating EasySteers practical applicability."
        },
        {
            "title": "6 Conclusion and Future Work",
            "content": "We present EasySteer, unified framework that addresses critical limitations in existing steering frameworks through deep vLLM integration achieving 5.5-11.4 speedup, modular architecture with pluggable algorithm interfaces, fine-grained parameter control mechanisms, comprehensive resource library covering wide application domains, and an interactive demonstration system. Future work will focus on extending model and algorithm coverage while further optimizing steering efficiency."
        },
        {
            "title": "Ethics Statement and Responsible Use",
            "content": "LLM steering technology presents dual-use challenges: while enabling enhanced safety and controllability, it also poses risks if misused. EasySteer is developed primarily as research tool for advancing model safety, not for circumventing safeguards. We emphasize the following principles for responsible deployment: Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, and Zhangyang Wang. 2025b. Seal: Steerable reasoning calibration of large language models for free. arXiv preprint arXiv:2504.07986. Cheng-Ting Chou, George Liu, Jessica Sun, Cole Blondin, Kevin Zhu, Vasu Sharma, and Sean OBrien. 2025. Causal language control in multilingual transformers via sparse feature steering. arXiv preprint arXiv:2507.13410. Research Focus: Steering should be restricted to legitimate research and safetyenhancing applications Transparency: Any behavioral modifications must be explicitly disclosed to end users Compliance: All applications must adhere to relevant ethical guidelines and legal frameworks"
        },
        {
            "title": "Broader Impact Statement",
            "content": "EasySteer significantly lowers barriers to LLM steering research by providing unified, highperformance framework that eliminates complex implementation requirements. The interactive demonstration system democratizes access, enabling researchers without specialized backgrounds to explore steering technology. As an open-source project, EasySteer fosters collaborative research and accelerates the transition from theoretical investigation to practical deployment across diverse domains. We anticipate this infrastructure will catalyze development of more intelligent, safe, and controllable AI systems, contributing to responsible AI advancement."
        },
        {
            "title": "References",
            "content": "Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes Gurnee, and Neel Nanda. 2024. Refusal in language models is mediated by single direction. Advances in Neural Information Processing Systems, 37:136037136083. Yuanpu Cao, Tianrong Zhang, Bochuan Cao, Ziyi Yin, Lu Lin, Fenglong Ma, and Jinghui Chen. 2024. Personalized steering of large language models: Versatile steering vectors through bi-directional preference optimization. Advances in Neural Information Processing Systems, 37:4951949551. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, and 1 others. 2021. Training verifiers arXiv preprint to solve math word problems. arXiv:2110.14168. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, and 1 others. 2024. The llama 3 herd of models. arXiv e-prints, pages arXiv2407. Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, and 1 others. 2022. Toy models of superposition. arXiv preprint arXiv:2209.10652. Misbah Farooq, Varuna De Silva, Rahul Rahulamathavan, and Xiyu Shi. 2025. Sentiment steering in large language models via activation vector manipulation. In 2025 25th International Conference on Digital Signal Processing (DSP), pages 15. IEEE. Javier Ferrando, Oscar Obeso, Senthooran Rajamanoharan, and Neel Nanda. 2024. Do know this entity? knowledge awareness and hallucinations in language models. arXiv preprint arXiv:2411.14257. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yixin Dai, Jiawei Sun, Haofen Wang, and Haofen Wang. 2023. Retrieval-augmented generation for large language models: survey. arXiv preprint arXiv:2312.10997, 2(1). Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, and 1 others. 2025. Deepseek-r1: Incentivizing reasoning capability in arXiv preprint llms via reinforcement learning. arXiv:2501.12948. Chi Han, Jialiang Xu, Manling Li, Yi Fung, Chenkai Sun, Nan Jiang, Tarek Abdelzaher, and Heng Ji. 2023. Word embeddings are steers for language models. arXiv preprint arXiv:2305.12798. Runjin Chen, Andy Arditi, Henry Sleight, Owain Evans, and Jack Lindsey. 2025a. Persona vectors: Monitoring and controlling character traits in language models. arXiv preprint arXiv:2507.21509. Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, and Sai Qian Zhang. 2024. Parameter-efficient finetuning for large models: comprehensive survey. arXiv preprint arXiv:2403.14608. 7 Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874. Bertram Højer, Oliver Jarvis, and Stefan Heinrich. 2025. Improving reasoning performance in large language models via representation engineering. arXiv preprint arXiv:2504.19483. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, and 1 others. 2022. Lora: Low-rank adaptation of large language models. ICLR, 1(2):3. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the 29th symposium on operating systems principles, pages 611626. Bruce Lee, Inkit Padhi, Karthikeyan Natesan Ramamurthy, Erik Miehling, Pierre Dognin, Manish Nagireddy, and Amit Dhurandhar. 2024. Programming refusal with conditional activation steering. arXiv preprint arXiv:2409.05907. Tom Lieberum, Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant Varma, János Kramár, Anca Dragan, Rohin Shah, and Neel Nanda. 2024. Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2. Preprint, arXiv:2408.05147. Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. 2023. Lets verify step by step. In The Twelfth International Conference on Learning Representations. Johnny Lin. 2023. Neuronpedia: Interactive reference and tooling for analyzing neural networks. Software available from neuronpedia.org. Stephanie Lin, Jacob Hilton, and Owain Evans. 2021. Truthfulqa: Measuring how models mimic human falsehoods. arXiv preprint arXiv:2109.07958. Zhengkai Lin, Zhihang Fu, Ze Chen, Chao Chen, Liang Xie, Wenxiao Wang, Deng Cai, Zheng Wang, and Jieping Ye. 2025. Controlling thinking speed in reasoning models. arXiv preprint arXiv:2507.03704. Sheng Liu, Tianlang Chen, Pan Lu, Haotian Ye, Yizheng Chen, Lei Xing, and James Zou. 2025. Fractional reasoning via latent steering vectors improves inference time compute. arXiv preprint arXiv:2506.15882. Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2022a. Locating and editing factual associations in gpt. Advances in neural information processing systems, 35:1735917372. Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. 2022b. Massediting memory in transformer. arXiv preprint arXiv:2210.07229. Tomáš Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word representations. In Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies, pages 746751. Matthew Lyle Olson, Neale Ratzlaff, Musashi Hinck, Shao-yen Tseng, and Vasudev Lal. 2024. Steering large language models to evaluate and amplify creativity. arXiv preprint arXiv:2412.06060. Kiho Park, Yo Joong Choe, and Victor Veitch. 2023. The linear representation hypothesis and the geometry of large language models. arXiv preprint arXiv:2311.03658. Seongheon Park, Xuefeng Du, Min-Hsuan Yeh, Haobo Wang, and Yixuan Li. 2025. llm latents for hallucination detection. arXiv preprint arXiv:2503.01917. Steer Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, and 25 others. 2025. Qwen2.5 technical report. Preprint, arXiv:2412.15115. Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal, and Aman Chadha. 2024. systematic survey of prompt engineering in large language models: Techniques and applications. arXiv preprint arXiv:2402.07927. Marco Scialanga, Thibault Laugel, Vincent Grari, and Sake: Steering actiarXiv preprint Marcin Detyniecki. 2025. vations for knowledge editing. arXiv:2503.01751. Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. Bleurt: Learning robust metrics for text generation. arXiv preprint arXiv:2004.04696. Atakan Seyitoglu, Aleksei Kuvshinov, Leo Schwinn, and Stephan Günnemann. 2024. Extracting unlearned information from llms with activation steering. arXiv preprint arXiv:2411.02631. Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David Udell, Juan Vazquez, Ulisse Mini, and Monte MacDiarmid. 2023. Steering language modarXiv preprint els with activation engineering. arXiv:2308.10248. Theia Vogel. 2024. repeng. Zhengxuan Wu, Aryaman Arora, Zheng Wang, Atticus Geiger, Dan Jurafsky, Christopher Manning, and Christopher Potts. 2024. Reft: Representation 8 finetuning for language models. Advances in Neural Information Processing Systems, 37:6390863962. Haolei Xu, Yuchen Yan, Yongliang Shen, Wenqi Zhang, Guiyang Hou, Shengpei Jiang, Kaitao Song, Weiming Lu, Jun Xiao, and Yueting Zhuang. 2025a. Mind the gap: Bridging thought leap for improved chainof-thought tuning. arXiv preprint arXiv:2505.14684. Ziwen Xu, Shuxun Wang, Kewei Xu, Haoming Xu, Mengru Wang, Xinle Deng, Yunzhi Yao, Guozhou Zheng, Huajun Chen, and Ningyu Zhang. 2025b. Easyedit2: An easy-to-use steering framework for arXiv preprint editing large language models. arXiv:2504.15133. Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo Sun, and Yue Zhang. 2024. survey on large language model (llm) security and privacy: The good, the bad, and the ugly. High-Confidence Computing, 4(2):100211. Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, and 1 others. 2024. comprehensive study of knowledge editarXiv preprint ing for large language models. arXiv:2401.01286. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, and 1 others. 2023. survey of large language models. arXiv preprint arXiv:2303.18223, 1(2)."
        },
        {
            "title": "A Concept Vector Extraction Methods",
            "content": "EasySteer implements several concept extraction methods commonly employed in analysis-based steering. These methods identify and isolate direction vectors corresponding to specific semantic concepts within model hidden states. The fundamental approach leverages contrastive analysis on paired datasets: positive dataset D+ containing samples exhibiting the target concept, and negative dataset containing samples that are either opposite to or independent of the target concept. By contrasting differences in model internal activations between these sample types, we can isolate the target concepts directional representation. The extracted concept vector is subsequently utilized in the steering intervention process described in Section 3.1. A.1 Contrastive Activation Addition (CAA) CAA represents one of the most straightforward concept extraction approaches. The concept vector is computed as the difference between mean hidden states of positive and negative sample sets: proj = ExD (cid:20) hl,i(x)T (cid:21) If proj+ < proj, we correct the direction: v. A.3 Linear Probing Linear probing learns linear classifier Rd that distinguishes between positive and negative samples through projection in hidden state space. We optimize the following objective with binary cross-entropy loss and regularization: = arg min ExD+D[LBCE(yx, σ(wT hl,i(x)))] where yx {0, 1} denotes the class label, σ() is the sigmoid function. A.4 Sparse Autoencoders (SAE) Sparse autoencoders decompose hidden states Rd into sparse, interpretable feature representations. The architecture comprises: Encoder. Maps hidden states to higher dimensional sparse activations Rn (where d): = Ex+D+[hl,i(x+)] ExD[hl,i(x)] = ReLU(Wench + benc) A.2 Principal Component Analysis (PCA) PCA identifies directions of maximum variance in hidden state representations, capturing the most prominent structural differences in the data. We implement two variants: Center PCA. For each positive-negative sample pair (x+ ), we first compute the centroid: , mk = hl,i(x+ ) + hl,i(x ) 2 We then apply PCA to the set of centered vectors to extract the principal direction with maximum variance: = PCA({hl,i(x+) mk, hl,i(x) mk}) Diff PCA. This variant directly applies PCA to the difference vectors between paired samples: = PCA({hl,i(x+) hl,i(x)}) Since PCA produces undirected components (both and are valid), we perform direction alignment by computing average projections: (cid:20) hl,i(x+)T proj+ = Ex+D+ (cid:21) Decoder. Reconstructs the original hidden state from sparse activations: ˆh = Wdecf + bdec Pre-trained SAEs (e.g., gemma-scope (Lieberum et al., 2024)) typically include automated interpretability analyses and semantic labels for discovered features. EasySteer provides streamlined pipeline for extracting concept vectors from pretrained SAEs: 1. Concept Definition and Retrieval. Users define target concepts in natural language and perform semantic search over pre-computed feature interpretations to identify relevant features. 2. Feature Selection. Based on search results and automated interpretations, users select the feature index that best aligns with their intended concept. 3. Vector Extraction. The concept vector corresponds to the k-th column of the decoder weight matrix: = Wdec[:, k] 10 Learning-based Steering Methods This appendix presents representative learningbased steering methods implemented in EasySteer. These methods follow the framework outlined in Section 3.2, optimizing parameterized steering functions fθ while maintaining frozen language model parameters . B.1 Supervised Additive Vector The simplest learning-based approach directly optimizes an additive steering vector Rd on taskspecific data D: fθ(hl,i) := hl,i + This method provides baseline for more sophisticated steering techniques while maintaining computational efficiency. B.2 LM-Steer LM-Steer introduces learnable linear transformation at the models final layer to modulate generation behavior: fθ(hl,i) := hl,i + ϵW hl,i where θ = {W } with Rdd, and ϵ controls the intervention strength. This approach enables more expressive steering while maintaining linearity in the transformation. B.3 Low-rank Linear Subspace ReFT (LoReFT) LoReFT represents parameter-efficient representation fine-tuning method that constrains hidden state modifications to learned low-rank subspace. With only 2rd + parameters, it achieves effective control through: fθ(hl,i) := hl,i + RT (W hl,i + Rhl,i) where θ = {R, W, b}, Rrd is the low-rank projection matrix, Rrd is the linear projection matrix, and Rr is the bias vector. The low-rank constraint (r d) ensures parameter efficiency while the learned subspace provides sufficient expressiveness for diverse steering objectives."
        },
        {
            "title": "C Overthinking Mitigation",
            "content": "C.1 Experiment Setup MATH training samples. During inference, we enhance Execution while suppressing Reflection and Transition at reasoning step boundaries (Chen et al., 2025b). code snippet can be found in Figure 4. We test on DeepSeek-R1-DistillQwen-1.5B/7B using GSM8K (Cobbe et al., 2021) and MATH500 (Lightman et al., 2023) benchmarks with 8192 maximum tokens, measuring accuracy (Xu et al., 2025a) and token efficiency. Figure 4: An illustrative code snippet of the SEAL algorithm implemented using EasySteer. Multiple steering vectors are applied to the nn token via the multi-vector collaboration functionality. C.2 Results and Analysis Table 5 demonstrates that steering effectively reduces redundant reasoning steps while maintaining solution quality using EasySteer. On DeepSeekR1-Distill-Qwen-1.5B, SEAL improves GSM8K accuracy by 2.7% (79.6%82.3%) while reducing token usage by 40.0%. The 7B model shows similar efficiency gains with 13.3% and 16.8% token reduction on GSM8K and MATH500 respectively. Model Method GSM8K MATH500 Acc Tokens Acc Tokens DeepSeek-R1-Distill-Qwen-1.5B DeepSeek-R1-Distill-Qwen-7B / SEAL / SEAL 79.6 82.3 90.3 88.5 2435.48 1460.13 792.74 687. 70.8 78.4 86.6 88.2 3966.38 3074.67 3096.69 2577.04 Following SEAL, we extract three behavioral vectors (Execution, Reflection, Transition) from 1,000 Table 5: Overthinking mitigation performance using SEAL steering."
        }
    ],
    "affiliations": [
        "Zhejiang University"
    ]
}