{
    "paper_title": "Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning",
    "authors": [
        "Junhong Lin",
        "Xinyue Zeng",
        "Jie Zhu",
        "Song Wang",
        "Julian Shun",
        "Jun Wu",
        "Dawei Zhou"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have achieved remarkable success in complex reasoning tasks, but their inference remains computationally inefficient. We observe a common failure mode in many prevalent LLMs, overthinking, where models generate verbose and tangential reasoning traces even for simple queries. Recent works have tried to mitigate this by enforcing fixed token budgets, however, this can lead to underthinking, especially on harder problems. Through empirical analysis, we identify that this inefficiency often stems from unclear problem-solving strategies. To formalize this, we develop a theoretical model, BBAM (Bayesian Budget Allocation Model), which models reasoning as a sequence of sub-questions with varying uncertainty, and introduce the $E^3$ metric to capture the trade-off between correctness and computation efficiency. Building on theoretical results from BBAM, we propose Plan-and-Budget, a model-agnostic, test-time framework that decomposes complex queries into sub-questions and allocates token budgets based on estimated complexity using adaptive scheduling. Plan-and-Budget improves reasoning efficiency across a range of tasks and models, achieving up to +70% accuracy gains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it elevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger model (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close performance gaps without retraining. Our code is available at anonymous.4open.science/r/P-and-B-6513/."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 2 ] . [ 1 2 2 1 6 1 . 5 0 5 2 : r Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning Junhong Lin MIT CSAIL junhong@mit.edu Xinyue Zeng Virginia Tech xyzeng@vt.edu Jie Zhu Virginia Tech jiez19@vt.edu Song Wang University of Virginia sw3wv@virginia.edu Julian Shun MIT CSAIL jshun@mit.edu Jun Wu Michigan State University wujun4@msu.edu Dawei Zhou Virginia Tech zhoud@vt.edu"
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have achieved remarkable success in complex reasoning tasks, but their inference remains computationally inefficient. We observe common failure mode in many prevalent LLMs, overthinking, where models generate verbose and tangential reasoning traces even for simple queries. Recent works have tried to mitigate this by enforcing fixed token budgets, however, this can lead to underthinking, especially on harder problems. Through empirical analysis, we identify that this inefficiency often stems from unclear problemsolving strategies. To formalize this, we develop theoretical model, BBAM (Bayesian Budget Allocation Model), which models reasoning as sequence of sub-questions with varying uncertainty, and introduce the 3 metric to capture the trade-off between correctness and computation efficiency. Building on theoretical results from BBAM, we propose PLAN-AND-BUDGET, model-agnostic, testtime framework that decomposes complex queries into sub-questions and allocates token budgets based on estimated complexity using adaptive scheduling. PLANAND-BUDGET improves reasoning efficiency across range of tasks and models, achieving up to +70% accuracy gains, 39% token reduction, and +187.5% improvement in 3. Notably, it elevates smaller model (DS-Qwen-32B) to match the efficiency of larger model (DS-LLaMA-70B)demonstrating PLAN-ANDBUDGETs ability to close performance gaps without retraining. Our code is available at anonymous.4open.science/r/P-and-B-6513/."
        },
        {
            "title": "Introduction",
            "content": "Large Language Models (LLMs) exhibit strong generalization capabilities, enabling them to perform wide range of taskssuch as mathematical problem solving [1, 15], scientific question answering [12, 20], and structured reasoning [8, 33]without task-specific retraining. Recent advances in test-time computation like Chain-of-Thought (CoT) prompting [33], self-consistency [29], and tool-augmented inference [3] have significantly enhanced their performance on complex, multi-step reasoning tasks. These enhancements have paved the way for LLMs to be increasingly deployed in high-stakes domains such as education [6], finance [37], law [16], and scientific research [25], where robust reasoning at inference time is critical. Despite these advances, deploying LLMs in real-world settings introduces new challengesparticularly in scenarios requiring deliberative reasoning under strict compute and time Equal contribution. Preprint. Under review. Figure 1: Illustration of REASONING MISCALIBRATION. Vanilla reasoning overthinks and wastes tokens; global budgeting underthinks and fails. Our method combines planning and local budgeting to guide structured, efficient reasoning, achieving the correct answer with fewer tokens. constraints. One prominent issue is the lack of calibrated reasoning behavior during inference. Although LLMs are proficient in multi-step reasoning, they often struggle to regulate how much reasoning effort is appropriate for given task. This miscalibration manifests in two major failure modes: overthinking [24, 2, 28], where models generate unnecessarily long and tangential reasoning pathseven for simple queriesincurring excessive computational cost without improving accuracy; and underthinking [32, 33], where models terminate reasoning prematurely, sacrificing correctness to conserve resources. Recent methods [18, 36, 10] have attempted to mitigate overthinking by introducing hard token constraints (e.g., using fewer than tokens in the prompt). While these strategies may be effective on simpler tasks, they often degrade performance on complex queries by inducing underthinkinghighlighting the limitations of fixed, non-adaptive approaches. To the best of our knowledge, there is limited work that has systematically addressed both overthinking and underthinking within unified framework. In this paper, we take the first step toward closing this gap. With comprehensive empirical study of test-time reasoning behavior in state-of-the-art LLMs ranging from 32B to 200B parameters, we uncover pervasive phenomenon we term REASONING MISCALIBRATIONa failure mode where models exhibit unregulated inference depth during reasoning. This miscalibration manifests as either overthinking, where the model engages in unnecessary and tangential reasoning, or underthinking, where reasoning terminates prematurely. Our study reveals that reasoning miscalibration is frequently triggered by two types of queries: (1) Trivial-but-ambiguous queries, which elicit diffuse token distributions and lead to speculative reasoning; and (2) Hard-and-rare queries, where models engage in shallow trial-and-error without meaningful convergence. These findings raise central research question: How can we characterize the internal reasoning and inference mechanisms of LLMs, and how can we guide them to allocate computation adaptively based on task complexity? To answer this, we analyze reasoning miscalibration through the lens of uncertaintyquantified by the entropy of the models marginal next-token distribution at each step. This distribution reflects the models belief over possible continuations, where higher entropy indicates greater indecision or ambiguity. We find that high entropy often correlates with unnecessarily deep reasoning (i.e., overthinking), while low entropy observed at early steps often leads to premature truncation of reasoning (i.e., underthinking). These insights suggest that uncertainty can serve as valuable signal for dynamically adjusting reasoning depth. Motivated by this, we introduce the Bayesian Budget Allocation Model (BBAM), theoretical resource allocation model that aligns computation with uncertainty. BBAM conceptualizes reasoning as sequence of sub-problems, each characterized by varying degrees of uncertainty, and allocates greater computational budget to sub-questions with higher uncertaintyenabling more calibrated and efficient inference. From this perspective, we derive two key principles for effective reasoning: (1) Reasoning should be structured: Decomposing complex queries into smaller, targeted sub-questions helps reduce speculative exploration; and (2) Computation should be adaptive: Early reasoning steps typically bear higher uncertainty and thus merit greater computational focus. 2 Building on these principles, we propose novel compute-efficient reasoning strategy, called PLANAND-BUDGET, which consists of two stagesPlan and Budget. In the Plan Step, the model decomposes the original query into sequence of sub-questions, providing soft scaffold for structured reasoning. In the Budget Step, we apply simplified decay-based scheduling strategies that dynamically assign token budgets to each sub-question, guided by its uncertainty pattern, following the BBAM principle. To evaluate our approach, we introduce 3, namely the EfficiencyAware Effectivenss Evaluation Score that captures the trade-off between reasoning accuracy and computational cost. Unlike conventional efficiency metrics that overlook output quality, 3 offers more robust, holistic measure of inference performance. We evaluate our method through extensive experiments across four state-of-the-art LLMs, including DeepSeek-R1 Distill-Qwen-32B (DS-Qwen-32B) [8], QwQ-32B [26], DeepSeek-R1 Distill-Llama70B (DS-LLaMA-70B) [8], and OpenAI o4-mini [22] on three representative task domains: mathematical reasoning, instruction following, and agentic planning. Our method is model-agnostic: it requires no retraining or fine-tuning, relying only on prompting and lightweight planning. Despite this simplicity, PLAN-AND-BUDGET consistently improves all LLMs across all benchmarks. We observe downstream accuracy gains of up to +70%, token usage reductions of up to 39%, and combined efficiency improvements (as measured by 3) of up to +187.5% over strong baselines. An especially notable case comes from the agentic planning task domain, where smaller DS-Qwen-32B improves from low 3 of 0.16 to 0.46 using PLAN-AND-BUDGETclosing the gap with the larger DS-LLaMA-70B model (E 3 = 0.50) without planning. This demonstrates that uncertainty-guided planning and budgeting can act as inference-time equalizers, boosting the efficiency and competitiveness of smaller models without retraining. Together, these findings underscore the promise of principled compute allocation for more calibrated, efficient, and accessible LLM inference."
        },
        {
            "title": "2 Related Works and Preliminary",
            "content": "2.1 Related Works Scaling Laws. Recent work has explored how test-time computation affects LLM performance, showing that an increased inference budget can reduce failure rates but often suffers from diminishing returns [23, 34]. Methods like MCTS-Judge [31] and EAG [21] demonstrate the benefits of adaptive compute in tasks like code evaluation and multi-hop reasoning. Unlike prior work focusing on simply increasing compute, we investigate how to allocate it efficiently through structured planning and uncertainty-aware budgeting. Uncertainty. Quantifying uncertainty in deep models is often framed through epistemic vs. aleatoric components [13], with techniques like MC Dropout [5], ensembles [17], and evidential learning [11]. Recent work extends these ideas to LLMs via consistency checks and parameter-efficient ensembles [27, 9]. Our work builds on this by using uncertainty decomposition to guide token allocation at inference time, offeringg novel application of uncertainty for test-time efficiency. 2.2 Preliminary We begin by summarizing previous work and introducing the key notations used throughout this work. Table 1 lists the symbols relevant to our reasoning formulation. Reasoning Miscalibration in LLMs. While LLMs excel at complex reasoning tasks, they often struggle to regulate how much inference effort is appropriate per query. We refer to this phenomenon as REASONING MISCALIBRATION. It describes mismatch between task complexity and the depth of reasoning model performs at test time. Table 1: Notation Summary Symbol Description xi sij bij βij πi wij γ, ϵ, cij Number of sub-questions i-th query j-th sub-question of query xi Tokens allocated to sub-question sij Complexity of sub-questionsij Total token budget per query Decomposition plan for query xi Normalized complexity weight for sij Decay scheduler hyperparameters Parameter characterizing epistemic uncertainty reduction This miscalibration presents itself in two primary modes: (1) Overthinking [24, 2, 28], where the model engages in excessively verbose or tangential reasoning even for simple queries, 3 incurring unnecessary computational cost and introducing noise or contradictions; and (2) Underthinking [32, 33], where the model prematurely stops reasoning to conserve budget, often yielding incomplete or incorrect answers. Contrary to the common belief that allocating more decoding tokens leads to better performance, we observe that excessive generation can degrade quality. In our empirical analysis, we show that longer outputs can lead models to wander within the solution space, becoming verbose, redundant, or self-inconsistent. Our findings suggest that REASONING MISCALIBRATION does not stem from lack of knowledge or model capacity, but rather from the models inability to dynamically align reasoning effort with querys evolving informational needsparticularly in response to uncertainty at each step. We leverage foundational concept of predictive uncertainty [14] which decomposes the total uncertainty U(x) for given input into two distinct components: U(x) = Uepistemic(x) + Ualeatoric(x), where Uepistemic(x) captures uncertainty due to incomplete knowledge (and is reducible through targeted computation), while Ualeatoric(x) accounts for irreducible ambiguity or noise in the input. Recent work by Falck et al. [4] extends this decomposition to LLMs, revealing that LLMs display dynamic uncertainty profiles throughout inference. These evolving patterns offer valuable insights into both the models reasoning processes and the quality of their generated outputs. We further demonstrate the validity of this decomposition in the LLM setting through formal analysis in Appendix A. Problem Definition. In multi-step reasoning, this decomposition reveals crucial insight: REASONING MISCALIBRATION arises from unregulated computational effort across sub-questions with varying uncertainty levels. Some sub-problems demand greater inference depth to reduce epistemic uncertainty, while othersdominated by aleatoric uncertaintybenefit from early termination or concise solutions. Yet current LLMs lack mechanism to adaptively allocate computation across these stages. This misalignment leads to inefficiency and degraded reasoning quality. The goal is to improve efficiency while mitigating REASONING MISCALIBRATION. Efficiency-Aware Effectiveness Evaluation: 3 Score. We introduce the 3 index as an efficiencyaware metric that jointly captures reasoning quality and computational cost. Rather than treating token usage and accuracy as separate concerns, the 3 directly quantifies their trade-off: A2 . = 3 = Here, denotes the average accuracy achieved across set of queries, and represents the average number of decoding tokens used per query. By squaring the accuracy term, the 3 emphasizes correctness more heavily, discouraging degenerate strategies that reduce token usage at the expense of output quality. In doing so, it reflects how well model aligns its computational effort with task complexityrewarding those that invest more where needed and conserve resources otherwise. Thus, the 3 provides principled evaluation framework for assessing whether model mitigates REASONING MISCALIBRATION while maximizing reasoning efficiency. To address this, we now formalize our target problem as follows: Problem 1. LLM Reasoning Calibration Given: (1) set of complex queries {x1, . . . , xn}, where each xi can be decomposed into sequence of sub-questions; and (2) total token budget Bi for each query xi. Find: computation strategy that maximizes the efficiency-aware score 3 = A2 , subject to the constraint Bi for each query. The objective is to allocate inference effort in way that prioritizes correctness under limited computational resources."
        },
        {
            "title": "3 Bayesian Budget Allocation Model (BBAM)",
            "content": "To address reasoning miscalibration as outlined in Problem 1, we need principled method for allocating computation across sub-questions with varying uncertainty. As established by Falck et al. [4], effective reasoning requires focusing effort where epistemic uncertainty is high, and limiting it where aleatoric noise dominates. However, existing methods lack formal mechanism for this adaptive allocation. They often treat all reasoning steps uniformly, leading to inefficient budget use and exacerbating reasoning miscalibration. To bridge this gap, we introduce the Bayesian Budget Allocation Model (BBAM)a theoretical framework that models token allocation as uncertainty 4 reduction under fixed budget. Grounded in Bayesian principles, BBAM provides the foundation for our adaptive reasoning strategy presented in Section 4. To distribute finite token budget Bi across the sub-questions of xi, we adopt Bayesian decisiontheoretic formulation that aims to maximize reasoning utility by minimizing total uncertainty. We assume an inverse power law governs epistemic uncertainty reduction for sub-question sij with token allocation bij: Uepistemic(sij bij) = cij bβij ij , (1) where cij > 0 reflects the initial epistemic uncertainty and βij 1 captures the complexity of reducing that uncertainty (where higher βij corresponds to being easier to reduce the uncertainty). We model total uncertainty as the sum of the epistemic and aleatoric components: U(sij bij) = cij bβij ij + Ualeatoric(sij). (2) Here, we treat Ualeatoric as constant with respect to bij, since it reflects irreducible uncertainty that cannot be mitigated through additional inference effort. proof of the decomposition of total uncertainty in LLM is provided in Appendix A. We define the utility of successfully resolving sub-question sij as inversely proportional to its uncertainty: where α is model/task-based scaling factor. The total utility for query xi is then: r(sij bij) = α (1 U(sij bij)) , Rtotal = (cid:88) j=1 r(sij bij). (3) (4) The optimal budget allocation solves the following constrained optimization problem: max bi1,...,bim (cid:32) α 1 (cid:88) j= cij bβij ij (cid:33) Ualeatoric(sij) s.t. (cid:88) j= bij Bi. (5) By introducing Lagrange multiplier λ to handle the budget constraint and solving the resulting Lagrangian, we arrive at the optimality principle: bij = Bi (cijβij) k(cikβik) (cid:80) 1 βij +1 1 βik +1 . (6) This allocation rule reveals unimodal relationship between bij and βij, i.e., token budget increases with complexity up to the peak, then decreases as further effort yields diminishing returns. This relationship is key to mitigating reasoning miscalibration: moderately difficult sub-questions receive more tokens to avoid underthinking, while overly difficult ones receive fewer to prevent overthinking. BBAM thus provides principled, self-regulating mechanism for aligning inference effort with reasoning value. detailed proof of the Lagrange optimization is provided in Appendix and C."
        },
        {
            "title": "4 Reasoning Calibration Framework: PLAN-AND-BUDGET",
            "content": "While BBAM offers principled approach for optimal token allocation, estimating its parameterssuch as the complexity of reducing that uncertainty across sub-questionsis challenging in practice. To bridge this gap between theoretical insight and practical application, we introduce PLAN-AND-BUDGET, structured reasoning framework that approximates BBAMs principle in Equation 6 using lightweight, decay-based budget schedulers. PLAN-AND-BUDGET enables LLMs to perform efficient multi-step reasoning under constrained budgets by coupling adaptive token allocation with an evaluation metric that jointly considers effectiveness and cost. 5 4.1 Plan Step: Question Decomposition as Guided Scaffold Inspired by human problem-solving strategies, we use query decomposition as reasoning scaffold to improve efficiency and focus. Our planning process has two phases: Phase 1: Automatic Planning. lightweight planning function decomposes xi into an ordered sequence of sub-questions πi and their estimated complexity scores Di: P(xi) (πi, Di), πi = si1, si2, . . . , sim, Di = di1, di2, . . . , dim. Here, πi denotes the decomposition plana sequence of sub-questionswhere each sij is natural language prompt targeting specific sub-problem of the query xi. The vector Di = di1, di2, . . . , dim contains corresponding complexity scores, with each dij R>0 reflecting the estimated complexity of solving sij based on LLM confidence, problem structure, or other heuristics. The decomposition plan πi is not unique or guaranteed to be optimal, but acts as soft scaffolda plausible high-level reasoning path to guide the main LLM. The planning function can be implemented via applying decomposition prompt in lightweight LLM (see Appendix G). The resulting complexity scores dij reflect epistemic uncertainty and help estimate the computational effort required for each sub-question. These scores are then normalized into weight vector wi: wij = dij k=1 dik (cid:80)m . This normalized weight wij represents the proportion of the total complexity of the query that is attributed to the j-th sub-question. This weight vector then plays key role in the subsequent budget allocation mechanism, determining how the total token budget Bi is distributed across the individual sub-questions. Phase 2: Guided Reasoning. After decomposing xi into sub-questions si1, . . . , sim and allocating token budgets bi1, . . . , bim, the main reasoning LLM sequentially answers each sij within its budget bij, producing responses aij as follows: aij = fLLM(sij, bij), where fLLM denotes the budget-constrained generation process. This constraint mitigates reasoning miscalibration by preventing excessive token use on individual steps. After all sub-questions are answered, synthesis function aggregates the responses, which answers the original query xi: yi = S(ai1, . . . , aim). 4.2 Budget Step: Decay-Based Budget Allocation While our Bayesian formulation offers an optimal allocation strategy based on sub-question-specific uncertainty parameters (cij and βij), estimating these values reliably in practice is often infeasible. To bridge this gap, we introduce family of decay-based scheduling functions that approximate uncertainty-aware budget allocation in lightweight and practical manner. These functions allocate more tokens to early sub-questions, based on the observation that epistemic uncertainty is typically highest at the start of reasoningwhen foundational understanding and strategy formation occur. Early token investment yields greater uncertainty reduction, consistent with the power law behavior of epistemic uncertainty in Equation 1. In contrast, later steps are generally narrower in scope or more deterministic, and over-allocating tokens at these stages risks wasting inference effort, as additional computation cannot reduce the irreducible aleatoric uncertainty and yields diminishing returns in epistemic gain. Thus, decay functions offer principled heuristic for prioritizing the budget where it is most valuable. (cid:22) bij = Given the normalized complexity weight vector wi = {wi1, . . . , wim} for query xi and the total token budget Bi, we allocate tokens using wij dij k=1 wik dik where dij = schedule(j, m) assigns positional priority to sub-question in sequence of length m, reflecting the belief that earlier steps often carry higher epistemic uncertainty and merit more budget. (cid:80)m Bi (7) (cid:23) , Figure 2: Visualization of decay functions. We take = 100, = 2, γ = 0.9, and 5 subquestions with the same complexity level as an example. Table 2: Decay-based scheduling strategies for token budget allocation. Strategy Formula of dij Description Non-decay Linear decay Polynomial decay Exponential decay 1 (m j)p γj Cosine annealing (cid:16) 0.5 1 + cos (cid:17)(cid:17) (cid:16) πj + ϵ Equal priority for all sub-questions; budget follows wij. Decreases priority linearly with j; emphasizes early steps. Stronger emphasis on early steps; steeper with higher > 1. Exponentially favors earlier sub-questions; controlled by γ (0, 1). Smooth decay with mid-sequence flexibility; ϵ adds stability. Experimental Scheduling Strategy. We explore several decay strategies  (Table 2)  , each encoding distinct prioritization schema over sub-question positions. Each strategy offers flexible way to encode task-specific preferences. For instance, polynomial decay aggressively front-loads the budget, which may be beneficial in highly ambiguous tasks. Exponential decay offers more balanced approach for problems with both early and mid-sequence challenges. Ultimately, these decay functions serve as practical surrogates to our Bayesian-optimal allocation by heuristically targeting the most epistemically impactful stages of reasoning. Figure 2 shows that different decay strategies yield distinct allocation patterns even under uniform complexity, with polynomial decay and cosine annealing favoring early steps, linear offering gradual decline, and exponential decay providing balanced distributiondemonstrating that decay-based scheduling flexibly adapts token emphasis to match the structure of reasoning tasks."
        },
        {
            "title": "5 Experiments",
            "content": "We conduct extensive experiments across three types of reasoning-intensive downstream tasks to evaluate the effectiveness and efficiency of PLAN-AND-BUDGET. We assess performance in terms of raw accuracy and compute-aware reasoning efficiency using our proposed 3 metric. In particular, we aim to answer the following questions: Q1: Does Plan-and-Budget improve reasoning efficiency without sacrificing accuracy, compared to the baseline of using no planning (Vanilla) or applying fixed budget (Global Budget)? Q2: How does local, uncertainty-aware budgeting perform across models, datasets, and task types, relative to uniform or global strategies? Q3: Which scheduling strategies yield the best efficiencyaccuracy tradeoff? 5.1 Experiment Setup Datasets. We evaluate PLAN-AND-BUDGET on three representative benchmarks (see Table 6 in Appendix): (1) MATH-500 [19], 500 math problem dataset requiring multi-step symbolic reasoning, evaluated by accuracy; (2) NaturalInstructions [30], diverse instruction-following benchmark, evaluated using ROUGE score; and (3) TravelPlanner [35], challenging agentic planning task evaluated by hard constraint pass rate in tool-free setting. This benchmark reflects the challenge of long-horizon, constraint-satisfying reasoning, with GPT-4-Turbo achieving 22.2% at best. Models. We test our methods on four state-of-the-art, publicly available reasoning-tuned LLMs: DeepSeek-R1-Distill-Qwen-32B (DS-Qwen-32B) [8], QwQ-32B [26], DeepSeek-R1-DistillLLaMA-70B (DS-LLaMA-70B) [8], and OpenAI o4-mini [22]. These models balance performance and accessibility and are specifically optimized for complex reasoning. For planning and budgeting, we use non-reasoning LLM, LLaMA-3.3-70B-Instruct [7]. To ensure that it does not inadvertently contribute to final answer quality, we evaluate its standalone performance on the three benchmarks and find that it underperforms specialized models: 75.20.68 on MATH-500, 41.460.41 on NaturalInstructions, and 28.752.1 on TravelPlanner. This confirms its role as neutral planner. Evaluation Metrics. We report the following metrics: (1) Score (%), the original evaluation metric used in each dataset; (2) Avg. Tokens, the average number of billed completion tokens per query, including reasoning and output tokens (for open-source models, tokens before </think> and final outputs; for o4-mini, the sum of reasoning and output tokens as reported in OpenAI documentation [22]); and (3) 3 Metric, which captures the balance between correctness and computational cost. Baselines. We compare our proposed framework against several baselines: (1) Vanilla. The query is given to the LLM without planning or token constraint; (2) Global Budget. Same as Vanilla but with token limit prompt (e.g., use less than Bi tokens); (3) Planned Vanilla / Global Budget. Same as above, but with the original query and its decomposed sub-questions provided; and (4) PLAN7 Table 3: Experiment results across different reasoning models on MATH-500. Acc denotes accuracy. Models DeepSeek-R1-Distill-Qwen-32B QwQ-32B DeepSeek-R1-Distill-Llama-70B o4-mini Methods Acc (%) Avg. Tok. 3 Acc (%) Avg. Tok. 3 Acc (%) Avg. Tok. 3 Acc (%) Avg. Tok. 3 i Vanilla 89.760.26 2105.1231.94 Global Budget 89.600.88 1526.1510.09 Vanilla 90.120.39 1633.0043.75 Global Budget 89.640.43 1377.9522.21 a E B + Linear + Uniform 89.440.52 1319.2322.30 + Weighted 89.400.73 1320.3140.66 88.960.59 1294.3848.75 + Exponential 89.120.58 1348.3837.14 + Polynomial 89.760.41 1263.1628.74 89.161.28 1304.7448.53 + Cosine - - P 3. 5.26 4.97 5.83 6.06 6.05 6. 5.89 6.38 6.09 84.881.18 3523.7297.42 2.04 90.440.61 2286.6326.42 90.560.33 2565.1837.10 3.20 90.800.62 1810.8351.64 85.561.37 2635.9634.61 2.78 90.440.71 1799.4836.42 87.481.08 2291.7945.92 3.34 89.440.67 1527.3718.04 87.720.63 1982.1164.25 3.88 90.120.63 1513.8443.93 88.480.87 2041.1638.86 3.84 89.920.30 1513.5960.18 87.600.72 1986.5322.58 3.86 89.761.31 1480.7831.96 88.120.66 2006.3825.92 3.87 90.040.54 1472.0141.92 88.240.61 2025.3450.02 3.84 89.720.58 1467.0035.92 88.840.75 2009.6819.24 3.93 90.000.62 1462.9043. 3.58 4.55 4.55 5.24 5.36 5. 5.44 5.51 5.49 5.54 93.160.89 711.208.31 12.20 91.840.48 636.418.14 13.25 91.081.05 534.9217.66 15.51 91.040.74 578.994.86 14. 90.560.38 518.3917.87 15.82 90.440.62 535.175.51 15.28 89.760.38 525.2312.06 15.34 90.680.61 522.6111.85 15.73 89.960.67 525.0010.33 15.41 91.120.67 520.697.31 15.95 Table 4: Experiment results across different reasoning models on NaturalInstructions. Models DeepSeek-R1-Distill-Qwen-32B QwQ-32B DeepSeek-R1-Distill-Llama-70B o4-mini Methods ROUGE (%) Avg. Tokens 3 ROUGE (%) Avg. Tokens 3 ROUGE (%) Avg. Tokens 3 ROUGE (%) Avg. Tokens 3 r e l G B - - P Vanilla 43.470.52 Global Budget 42.810.39 968.1744.78 787.2558.17 Vanilla Global Budget + Uniform + Weighted + Linear + Exponential + Polynomial + Cosine 42.270.41 42.680.70 42.100.54 42.320.65 42.220.49 42.821.09 42.450.20 41.960.46 844.4048.01 711.1523.50 657.5021. 620.5245.63 646.4245.63 645.4720.51 630.6214.45 637.0916.98 1. 2.33 2.12 2.56 2.70 2.89 2. 2.84 2.86 2.76 43.161.12 44.770.73 1818.3424.99 1.02 43.130.76 1360.49101.64 1.47 43.801.28 894.4650. 772.9847.44 44.240.67 45.130.56 1426.7452.92 1.37 43.220.58 1265.7833.23 1.61 42.690.43 799.1618.86 672.3815.38 44.470.35 44.400.61 44.220.66 43.990.22 44.660.68 44.530. 996.9131.31 1.98 42.150.33 1025.0224.91 1.92 43.140.84 1003.2426.23 1.95 42.620.59 1026.898.51 1.88 43.070.84 995.9514.43 2.00 42.450.38 1000.6417.85 1.98 42.860.41 663.5119.51 654.4929.22 648.9018.14 656.7321.19 641.3916. 663.7413.38 2.08 2.48 2.34 2.71 2. 2.84 2.80 2.82 2.81 2.77 47.240.31 45.391. 44.060.54 43.860.26 44.240.50 44.000.77 44.170.32 43.880.96 44.410.64 44.200.73 460.9911.31 4.84 422.2056.78 4.88 346.998.78 5.59 354.8014.31 5. 348.468.45 5.62 363.857.65 5.32 364.658.99 5.35 362.8112.50 5.31 362.9610.62 5.43 365.658.00 5. AND-BUDGET. Our methodsthe query, sub-questions, and local budget prompts are given. We explore several scheduling strategies for local allocation: (a) Uniform, equal tokens per sub-question; (b) Weighted, proportional to the estimated difficulty; and (c) Linear, Polynomial, Exponential, Cosine, weighted by difficulty with additional decay (we use = 2 and γ = 0.9). hard cutoff of 8192 tokens is applied to prevent runaway generations. We report the average and standard deviation over 5 runs for all models and baselines. 5.2 Results We now address the questions introduced earlier by analyzing results across datasets and models. Tables 35 summarize our main findings. Across all datasets and model scales, PLANAND-BUDGET consistently outperforms both the Vanilla and Global Budget baselines, achieving up to 187.5% improvement in 3, while maintaining comparable or even higher accuracy. To further illustrate this, Figure 3 shows answer pass rates of QwQ-32B on TravelPlanner, grouped by difficulty level. While global budget constraints reduce token usage, they also degrade pass rates across all levels. In contrast, PLAN-AND-BUDGET achieves both higher pass rates and lower token usage, especially on harder queries, highlighting its ability to scale reasoning adaptively with problem complexity. On MATH-500, our method improves 3 consistently by over 20%for instance, from 3.20 3.93 (+22.8%) on QwQ-32B and from 13.25 15.95 (+20.3%) on o4-mini. Importantly, this is achieved without compromising the accuracy. While the Global Budget baseline reduces token usage, its gains are limited due to lack of uncertaintyFigure 3: Answer pass rate grouped by the question difficulty level in TravelPlanner. The global budget limit hurts the pass rate on all levels, while our method not only achieves higher pass rate but also enjoys lower token usage. Overall pass rate and average token usage are shown in the legend. Table 5: Experiment results on TravelPlanner. Rate denotes the hard constraint pass rate. Models DeepSeek-R1-Distill-Qwen-32B QwQ-32B DeepSeek-R1-Distill-Llama-70B o4-mini Methods Rate (%) Avg. Tokens 3 Rate (%) Avg. Tokens 3 Rate (%) Avg. Tokens 3 Rate (%) Avg. Tokens 3 r D n Vanilla 14.332.17 1430.1443.73 Global Budget 13.781.20 1158.8120.23 Vanilla 21.222.56 1379.6058.31 Global Budget 21.441.65 1215.4136. d + Linear + Weighted + Uniform 23.112.47 1237.6147.96 22.893.48 1208.5468.78 21.892.53 1241.5516.59 + Exponential 22.221.11 1182.3036.35 + Polynomial 23.442.82 1194.2556.38 22.222.00 1164.7739.57 o + n + Cosine 0.14 0.16 0.33 0.38 0. 0.43 0.39 0.42 0.46 0.42 34.893.20 3432.3378.66 0.35 26.221.82 1361.3747.93 30.782.06 2530.0440.87 0.37 24.332.30 1215.2935. 34.783.90 3691.57159.20 0.33 33.113.39 1392.1417.92 34.222.65 3080.2859.47 0.38 34.220.84 1248.5649.10 36.783.39 2668.10110.02 0.51 30.442.02 1149.6332.45 32.561.15 2777.3054.72 0.38 30.222.44 1202.0732.48 35.562.69 2531.6954.93 0.50 30.001.11 1162.2245.53 32.892.50 2568.0758.46 0.42 31.562.13 1156.4330.26 33.671.60 2504.9253.37 0.45 33.003.03 1142.5425.70 37.112.65 2446.0452.80 0.56 31.003.78 1115.8622.65 0.50 0.49 0.79 0. 0.81 0.76 0.77 0.86 0.95 0. 11.582.15 8.331.71 1559.658.84 0.086 1248.5326.97 0.056 12.002.62 1610.3651.42 0.089 1380.1124.49 0.034 6.892.50 10.781.60 1314.8651.88 0.088 10.673.08 1333.5928.09 0.085 11.111.71 1299.0653.41 0.095 1315.8743.68 0.069 9.561.54 11.331.08 1268.1132.39 0.101 1268.0644.75 0.074 9.671.78 awareness. Notably, we find that planning alone (Planned Global Budget) already boosts efficiency by 415%, validating our first key principle: reasoning should be structured. This scaffolding greatly reduces speculative exploration. Moreover, 3 enables easy comparison across modelse.g., o4-mini consistently achieves the highest 3, despite having similar accuracy to other models, because it uses the fewest tokens. This underscores the importance of 3 as practical efficiency metric. A1: We achieve substantial efficiency gains with comparable accuracy. On NaturalInstructions, PLAN-AND-BUDGET improves 3 by 16.836.3%. For example, on QwQ-32B, it improves from 1.47 2.00 (+36%), and on o4-mini, from 4.88 5.62 (+15%). Although these tasks are more instruction-oriented, PLAN-AND-BUDGET remains beneficial. On TravelPlanner, the most openended and challenging benchmark, we observe the most dramatic gains: 3 improves from 0.16 0.46 (+187.5%) on DS-Qwen-32B, from 0.49 0.95 (+93.8%) on DS-LLaMA-70B, and 0.056 0.101 (+80.3%) on o4-mini. These results highlight that the more complex the task, the greater the benefit of structure and adaptivity. A2: Local budgeting consistently improves efficiency. While structured planning alone improves efficiency, adding local budgeting yields significant additional gains. For example, we can observe that on MATH-500, QwQ-32B improves 3 from 3.34 3.93 (+17.6%); on NaturalInstructions, from 1.61 2.00 (+24.2%); and on TravelPlanner, from 0.38 0.56 (+47.3%). These results confirm the importance of adapting the budget to the sub-question, rather than applying global allocation. A3: Front-loaded scheduling performs best on complex tasks. Among local budget schedulers, polynomial decay and cosine annealing consistently deliver the highest 3 on mathematical and long-form planning tasks. These strategies front-load computationallocating more budget to early, uncertain steps where reasoning direction is established. This pattern is particularly effective on MATH-500 and TravelPlanner, where clarity at the beginning of the reasoning is crucial. In contrast, on NaturalInstructions, weighted or uniform schedules usually perform best, suggesting that smooth, evenly paced reasoning suffices for tasks with clearer structure and less ambiguity. A4: Bridging the gap between small and large Models. Our method is model-agnostic: it requires no retraining or fine-tuning, relying only on prompting and lightweight planning. We observe consistent improvements across model sizesfrom small models like QwQ-32B to large models like DeepSeek-R1-70B and o4-mini. An especially notable result comes from TravelPlanner, where compact model (DS-Qwen-32B) originally achieved only 3 = 0.16, but reached 3 = 0.46 after applying PLAN-AND-BUDGETon par with larger model with no planning (DS-LLaMA-70B, 3 = 0.50). This demonstrates that planning and budgeting can serve as powerful inference-time equalizers, closing the gap between small and large models through better compute utilization."
        },
        {
            "title": "6 Conclusion",
            "content": "We propose PLAN-AND-BUDGET, lightweight test-time framework that improves LLM reasoning efficiency by combining structured planning with uncertainty-aware token budgeting. Built on our BBAM, PLAN-AND-BUDGET models reasoning as sequence of sub-questions and adaptively allocates computation based on estimated difficulty. Experiments on three different reasoning tasks show that PLAN-AND-BUDGET achieves significant improvements in compute efficiency over strong baselines, without compromising accuracy. Although effective, our method currently requires an 9 additional LLM call to generate the decomposition plan. In future work, we aim to fine-tune and develop dedicated planner LLM to internalize the plan-and-budget strategy, enabling end-to-end, efficient reasoning within single model."
        },
        {
            "title": "References",
            "content": "[1] J. Ahn, R. Verma, R. Lou, D. Liu, R. Zhang, and W. Yin. Large language models for mathematical reasoning: Progresses and challenges. In The 18th Conference of the European Chapter of the Association for Computational Linguistics, page 225, 2024. [2] X. Chen, J. Xu, T. Liang, Z. He, J. Pang, D. Yu, L. Song, Q. Liu, M. Zhou, Z. Zhang, et al. Do not think that much for 2+ 3=? on the overthinking of o1-like llms. arXiv preprint arXiv:2412.21187, 2024. [3] Z. Chen, K. Zhou, B. Zhang, Z. Gong, X. Zhao, and J.-R. Wen. ChatCoT: Tool-augmented chain-of-thought reasoning on chat-based large language models. In H. Bouamor, J. Pino, and K. Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1477714790, Singapore, Dec. 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-emnlp.985. URL https://aclanthology.org/2023.findings-emnlp.985/. [4] F. Falck, Z. Wang, and C. Holmes. Is in-context learning in large language models bayesian? martingale perspective, 2024. URL https://arxiv.org/abs/2406.00793. [5] Y. Gal and Z. Ghahramani. Dropout as bayesian approximation: Representing model uncertainty in deep learning. In International Conference on Machine Learning (ICML), pages 10501059. PMLR, 2016. [6] B. Golshan and K. Academy. Khanmigo: An ai-powered assistant for education, 2023. URL https: //www.khanmigo.ai/. Accessed: 2025-05-14. [7] A. Grattafiori, A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Vaughan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. [8] D. Guo, D. Yang, H. Zhang, J. Song, R. Zhang, R. Xu, Q. Zhu, S. Ma, P. Wang, X. Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. [9] M. Halbheer, D. J. Mühlematter, A. Becker, D. Narnhofer, H. Aasen, K. Schindler, and M. O. Turkoglu. Lora-ensemble: Efficient uncertainty modelling for self-attention networks, 2024. URL https://arxiv. org/abs/2405.14438. [10] T. Han, Z. Wang, C. Fang, S. Zhao, S. Ma, and Z. Chen. Token-budget-aware llm reasoning. arXiv preprint arXiv:2412.18547, 2024. [11] Z. Huang, H. Lam, and H. Zhang. Quantifying epistemic uncertainty in deep learning, 2023. URL https://arxiv.org/abs/2110.12122. [12] Z. Huang, Z. Wang, S. Xia, X. Li, H. Zou, R. Xu, R.-Z. Fan, L. Ye, E. Chern, Y. Ye, et al. Olympicarena: Benchmarking multi-discipline cognitive reasoning for superintelligent ai. Advances in Neural Information Processing Systems, 37:1920919253, 2024. [13] E. Hüllermeier and W. Waegeman. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Machine learning, 110(3):457506, 2021. [14] E. Hüllermeier and W. Waegeman. Aleatoric and epistemic uncertainty in machine learning: an introduction ISSN 1573-0565. doi: to concepts and methods. Machine Learning, 110(3):457506, Mar. 2021. 10.1007/s10994-021-05946-3. URL http://dx.doi.org/10.1007/s10994-021-05946-3. [15] S. Imani, L. Du, and H. Shrivastava. Mathprompter: Mathematical reasoning using large language models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track), pages 3742, 2023. [16] D. M. Katz, M. J. Bommarito, S. Gao, and P. Arredondo. GPT-4 passes the bar exam. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 382(2270): 20230254, Apr 2024. doi: 10.1098/rsta.2023.0254. Epub 2024 Feb 26. [17] B. Lakshminarayanan, A. Pritzel, and C. Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in Neural Information Processing Systems (NeurIPS), 30, 2017. 10 [18] A. Lee, E. Che, and T. Peng. How well do llms compress their own chain-of-thought? token complexity approach. arXiv preprint arXiv:2503.01141, 2025. [19] H. Lightman, V. Kosaraju, Y. Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman, I. Sutskever, and K. Cobbe. Lets verify step by step. In International Conference on Learning Representations (ICLR), 2024. [20] P. Lu, S. Mishra, T. Xia, L. Qiu, K.-W. Chang, S.-C. Zhu, O. Tafjord, P. Clark, and A. Kalyan. Learn to explain: Multimodal reasoning via thought chains for science question answering. Advances in Neural Information Processing Systems, 35:25072521, 2022. [21] L. Mei, S. Liu, Y. Wang, B. Bi, Y. Ge, J. Wan, Y. Wu, and X. Cheng. a1: Steep test-time scaling law via environment augmented generation. arXiv preprint arXiv:2504.14597, 2025. [22] OpenAI. Introducing o3 and o4-mini, Apr. 2025. introducing-o3-and-o4-mini/. Accessed: 2025-05-12. URL https://openai.com/index/ [23] C. Snell, J. Lee, K. Xu, and A. Kumar. Scaling llm test-time compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314, 2024. [24] Y. Sui, Y.-N. Chuang, G. Wang, J. Zhang, T. Zhang, J. Yuan, H. Liu, A. Wen, S. Zhong, H. Chen, et al. Stop overthinking: survey on efficient reasoning for large language models. arXiv preprint arXiv:2503.16419, 2025. [25] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. Hartshorn, E. Saravia, A. Poulton, V. Kerkez, and R. Stojnic. Galactica: large language model for science, 2022. URL https://arxiv.org/abs/2211. 09085. [26] Q. Team. Qwq-32b: Embracing the power of reinforcement learning, March 2025. URL https:// qwenlm.github.io/blog/qwq-32b/. [27] F. Tonolini, N. Aletras, J. Massiah, and G. Kazai. Bayesian prompt ensembles: Model uncertainty estimation for black-box large language models. In L.-W. Ku, A. Martins, and V. Srikumar, editors, Findings of the Association for Computational Linguistics: ACL 2024, pages 1222912272, Bangkok, Thailand, Aug. 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.728. URL https://aclanthology.org/2024.findings-acl.728/. [28] M. Turpin, J. Michael, E. Perez, and S. R. Bowman. Language models dont always say what they think: Unfaithful explanations in chain-of-thought prompting, 2023. URL https://arxiv.org/abs/2305. 04388. [29] X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang, A. Chowdhery, and D. Zhou. Selfconsistency improves chain of thought reasoning in language models. In International Conference on Learning Representations (ICLR), 2023. [30] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S. Dhanasekaran, A. Arunkumar, D. Stap, et al. Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 50855109, 2022. [31] Y. Wang, P. Ji, C. Yang, K. Li, M. Hu, J. Li, and G. Sartoretti. Mcts-judge: Test-time scaling in llm-as-ajudge for code correctness evaluation. arXiv preprint arXiv:2502.12468, 2025. [32] Y. Wang, Q. Liu, J. Xu, T. Liang, X. Chen, Z. He, L. Song, D. Yu, J. Li, Z. Zhang, et al. Thoughts are all over the place: On the underthinking of o1-like llms. arXiv preprint arXiv:2501.18585, 2025. [33] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems (NeurIPS), 35:2482424837, 2022. [34] Y. Wu, Z. Sun, S. Li, S. Welleck, and Y. Yang. Inference scaling laws: An empirical analysis of computeoptimal inference for llm problem-solving. In International Conference on Learning Representations (ICLR), 2025. [35] J. Xie, K. Zhang, J. Chen, T. Zhu, R. Lou, Y. Tian, Y. Xiao, and Y. Su. Travelplanner: benchmark for real-world planning with language agents. In Proceedings of the 41st International Conference on Machine Learning, pages 5459054613, 2024. 11 [36] S. Xu, W. Xie, L. Zhao, and P. He. Chain of draft: Thinking faster by writing less. arXiv preprint arXiv:2502.18600, 2025. [37] H. Yang, X.-Y. Liu, and C. D. Wang. Fingpt: Open-source financial large language models, 2023. URL https://arxiv.org/abs/2306.06031."
        },
        {
            "title": "A Proof of Uncertainty Decomposition for LLMs",
            "content": "Let θ denote the parameters of an LLM (e.g., transformer weights), and let be the test-time input with corresponding output y. Under Bayesian treatment, the predictive distribution is given by: p(yx, D) = (cid:90) p(yx, θ)p(θD) dθ, and is often approximated via Monte Carlo sampling: p(yx, D)"
        },
        {
            "title": "1\nM",
            "content": "M (cid:88) m=1 p(yx, θm), θm p(θD). We define the total predictive uncertainty as the Shannon entropy of this marginal predictive distribution: U(x) = [p(yx, D)] = p(yx, θ)p(θD)dθ . (cid:20)(cid:90) (cid:21) To derive the decomposition, we apply the law of total entropy, which relates the entropy of the marginal to the expected entropy of the conditionals and the mutual information: H[yx, D] = Ep(θD)[H[yx, θ]] + I(y; θx, D). Step-by-step Derivation: Let: - p(yx, θ) the conditional predictive distribution. - p(yx, D) the marginal (Bayesian averaged) predictive distribution. The total predictive uncertainty is: U(x) = [p(yx, D)] = p(yx, D) log p(yx, D). (cid:88) Define aleatoric uncertainty as the expected conditional entropy: Ualeatoric(x) = Ep(θD)[H[p(yx, θ)]] = (cid:90) (cid:32) p(θD) (cid:88) p(yx, θ) log p(yx, θ) dθ. (cid:33) Then define epistemic uncertainty as the mutual information: Uepistemic(x) = I(y; θx, D) = H[yx, D] Ep(θD)[H[yx, θ]]. Combining the above, we obtain: U(x) = Ualeatoric(x) + Uepistemic(x). Interpretation: Ualeatoric(x): Irreducible uncertainty present in each individual model prediction, even if θ were known. Uepistemic(x): Captures model uncertainty due to limited data, reflected in disagreement across posterior samples. 12 In practice, following [14], we approximate this decomposition using Monte Carlo estimation. Drawing samples θ1, . . . , θM from p(θD), we compute: U(x) (cid:34)"
        },
        {
            "title": "1\nM",
            "content": "M (cid:88) m=1 (cid:35) p(yx, θm) , (cid:88) Ualeatoric(x)"
        },
        {
            "title": "1\nM\nUepistemic(x∗) ≈ U(x∗) − Ualeatoric(x∗).",
            "content": "H [p(yx, θm)] , m=1 Thus, the uncertainty decomposition holds in both exact Bayesian inference and its Monte Carlo approximation, validating its use in practical LLM reasoning pipelines."
        },
        {
            "title": "B Proof of Lagrange Optimality",
            "content": "Proof. We aim to maximize the total utility: Rtotal = (cid:88) j=1 r(sij bij) = (cid:32) α 1 (cid:88) j=1 cij bβij ij (cid:33) Ualeatoric(sij) . (8) Since α and Ualeatoric(sij) are constants with respect to bij, maximizing the total utility is equivalent to minimizing the following: (cid:88) j= cij bβij ij subject to (cid:88) j=1 bij = Bi. Step 1: Form the Lagrangian. We define the Lagrangian: L({bij}, λ) = (cid:88) j=1 cij bβij ij + λ (cid:88) bij Bi . j= Taking the partial derivative with respect to bij and setting it to zero: bij = cijβijb(βij +1) ij + λ = 0 λ = cijβijb(βij +1) ij . Solving for bij gives: bβij +1 ij = cijβij λ bij = (cid:18) cijβij λ (cid:19) 1 βij +1 . Step 2: Apply the budget constraint. Substitute into the constraint (cid:80) bij = Bi: (cid:88) j=1 (cid:18) cijβij λ (cid:19) 1 βij +1 = Bi. Let Aj := (cijβij) 1 βij +1 , so that bij = λ1/(βij +1)Aj. Then the constraint becomes: (cid:88) j=1 λ1/(βij +1)Aj = Bi. 13 (9) (10) (11) (12) (13) (14) This expression has closed-form solution for λ only when all βij = β (i.e., homogeneous difficulty). In that case: bij = (cid:19) 1 β+1 (cid:18) cijβ λ (cid:19) β+1 (cid:18) cijβ λ (cid:88) = Bi λ = 1 β+ (cid:33)β+1 (cid:32) (cid:80) j(cijβ) . (15) Substituting back yields: ij = Bi 1 β+1 (cijβ) k(cikβ) (cid:80) . 1 β+ In the general case of heterogeneous βij, the normalized form can still be written as: ij = Bi (cijβij) k(cikβik) (cid:80) 1 βij +1 , 1 βik +1 which satisfies the budget constraint (cid:80) bij = Bi, thus completing the proof. Analysis of the Relationship Between bij and βij We examine the behavior of the allocation function in Equation 6: bij = Bi (cijβij) k(cikβik) (cid:80) 1 βij +1 . 1 βik +1 To analyze the relationship between bij and βij, we focus on the numerator: Let us define: (β) := (βc) 1 β+1 = exp (cid:18) log(βc) β + 1 (cid:19) . g(β) := log(βc) β + 1 , so that (β) = eg(β). We now study the behavior of (β) through the derivative of g(β): g(β) = = 1 β 1 β + 1 1 β(β + 1) log(βc) (β + 1)2 log(βc) (β + 1)2 . (16) (17) (18) (19) (20) (21) (22) The sign of g(β) depends on β, and it is not monotonic. The function g(β) increases initially, reaches maximum, and then decreases. Consequently, g(β) is unimodel, and since (β) = eg(β), (β) is also unimodal."
        },
        {
            "title": "D Broader Impacts",
            "content": "Our work proposes lightweight test-time framework that improves the efficiency of LLM reasoning through structured planning and uncertainty-aware computation. This has potential positive societal impacts by reducing computational costs, improving energy efficiency, and making advanced LLM capabilities more accessibleparticularly in resource-constrained settings. By narrowing the performance gap between small and large models, our method may also promote more equitable access to language technologies. However, as with any LLM inference technique, risks remain if deployed without careful oversight. More efficient reasoning pipelines could accelerate LLM integration into high-stakes applications (e.g., legal or medical decision-making) where accuracy, fairness, and robustness are critical. Our method does not modify model internals and inherits any limitations or biases present in the base models. Mitigation strategies include model-level auditing, task-specific evaluation, and responsible deployment practices."
        },
        {
            "title": "E Additional Experimental Details",
            "content": "E.1 Dataset Descriptions and Evaluation Metrics To evaluate the general applicability of our framework, we select three reasoning-heavy benchmarks spanning symbolic math, instruction following, and long-horizon planning. MATH-500. curated 500-problem subset from the full MATH dataset, designed to test symbolic, multi-step math reasoning. Each problem requires the model to interpret, manipulate, and solve high-school level mathematical expressions. Performance is measured using exact-match accuracy against gold answers. Table 6: Dataset Statistics. LLaMA 3.370B sole performance is also provided. MATH-500 Natural Instructions Travel Planner Task QA Pairs Metrics Math Reasoning Instruction Following Agentic Planning 500 500 180 Accuracy ROUGE Pass rate LLaMA 3.3-70B Performance 75.20.68 41.460.41 28.752.1 NaturalInstructions. broad instruction-following benchmark consisting of over 1600 tasks covering question answering, classification, transformation, and reasoning. We randomly sample 500 test queries from the public split for evaluation. Since answers are open-ended and linguistic, we use ROUGE score to measure semantic overlap with the reference answers. TravelPlanner. challenging planning benchmark that simulates real-world itinerary construction under hard constraints (e.g., timing, location compatibility) and soft commonsense preferences. We focus on the sole-planning setting where all relevant knowledge is embedded in the prompt, and no tool use is required. We evaluate on the validation set using the hard constraint pass rate, measuring whether the generated plan satisfies the minimal feasibility constraints (e.g., no overlaps or missing connections). We omit the stricter full success rate (which includes commonsense and preference matching) to isolate planning competence. Notably, even GPT-4-Turbo only achieves 22.2% under this setting, highlighting the datasets difficulty. E.2 Licenses for Existing Assets All models and datasets used in this work are publicly available and used in accordance with their respective licenses: DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-LLaMA-70B [8] are released under the DeepSeek open-source model license available at https://github.com/ deepseek-ai/DeepSeek-LLM/blob/main/LICENSE-MODEL. QwQ-32B [26] is licensed under the Apache License 2.0. OpenAI o4-mini [22] is accessed via the OpenAI API under the terms of service and usage policies listed at https://openai.com/policies/terms-of-use. No model weights are released or modified. LLaMA-3.3-70B-Instruct is used via OpenRouter and follows Metas LLaMA 3 license available at https://ai.meta.com/llama/license/. All datasets (MATH-500, NaturalInstructions, TravelPlanner) are publicly available and properly cited. They are used for evaluation purposes under academic and research-friendly terms of use. E.3 Compute Resources All experiments were conducted using API-accessible large language models, including OpenAIs o4mini and models hosted via OpenRouter (e.g., DeepSeek-R1-Distill-Qwen-32B). Since our method operates entirely at inference time through prompting, the computational cost is directly proportional to the number of tokens generated. We report token usage for each setting in the main paper, which can be used to estimate wall-clock runtime given model-specific generation rates (typically 5080 tokens/sec depending on the provider) and the parallelism used. All data preprocessing, prompt generation, and evaluation were performed on cloud-based virtual machine equipped with an Intel Xeon E5-2698 CPU and 500GB of main memory. No model training or fine-tuning was involved, and the overall compute requirements are modest and accessible."
        },
        {
            "title": "F Additional Results",
            "content": "In addition to the answer pass rates discussed in the main results, we also examine the token usage distribution across queries of varying difficulty. Figure 4 presents the average token usage and corresponding pass rates on TravelPlanner, grouped by difficulty level. Figure 4: Token usage and pass rate analysis across difficulty levels on TravelPlanner. (Left) Token usage distributions. (Right) Answer pass rate by difficulty level. As expected, we observe that token usage increases with query difficulty across all modelsmore complex tasks naturally require deeper reasoning and longer responses. However, methods using global budget constraints exhibit consistently higher token usage across all difficulty levels compared to our approach (Planned Local). This suggests that global budgeting fails to adapt to query complexity, resulting in inefficient allocation of compute. Moreover, global methods not only over-consume tokens but also suffer reduced answer pass rates at every difficulty level. This inefficiency leads to lower overall 3, further reinforcing the advantage of our uncertainty-aware local budgeting strategy. In contrast, PLAN-AND-BUDGET adapts compute based on sub-question difficulty, achieving better calibration of reasoning effort across simple and complex queries alike."
        },
        {
            "title": "G Prompt Templates",
            "content": "Prompt Templates for Question Decomposition -GoalYou are an experienced expert in domain and exam question designer. Your role is to help students break down challenging math problems into series of simpler, high-level sub-questions. We dont want too many detailed sub-questions, which are not beneficial for testing students ability in an exam. Each sub-question should build on the previous one so that, once all have been answered, the complete solution is clear. Your output should be list of sub-questions with brief hints explaining the purpose of each step, but you should not reveal your internal chain-of-thought either the final solution. Instructions for Decomposition: First, analyze the problem and identify the key ideas needed to solve it. Then, generate series of 2 to 5 sub-questions that lead the student step by step to the complete solution. The difficulty level of the problem is presented out of 5, wher 1 is easy, and 5 is hard. Please adjust the number of sub-questions based on the level. Ideally, we want fewer sub-questions for easy problems and more sub-questions for challenging problems. 16 DO NOT perform reasoning, directly output those sub-questions based on your gut feelings; only output the list of sub-questions with brief hints for each. Your answer should be list of numbered sub-questions. Each sub-question should have brief accompanying hint that explains what the student will achieve by answering that part. Example Decomposition: **Problem:** Find the remainder when (9 99 999 99 9 (cid:124) (cid:123)(cid:122) (cid:125) 999 9s **Level:** 3 out of 5 ) is divided by 1000. **Decomposed Sub-questions:** 1. Compute the product modulo 8. Hint: Simplify each term using (10 2 mod 8), noting that (10k 0 mod 8) for 3, leading to terms of (1 mod 8). 2. Compute the product modulo 125. Hint: Recognize (103 0 mod 125), so terms for (k 3) become (1 mod 125). Calculate the product of the first two terms and combine with the remaining terms. 3. Solve the system of congruences using the Chinese Remainder Theorem. Hint: Combine the results from modulo 8 and modulo 125 to find common solution modulo 1000. student has presented you with the following math problem: Problem: <problem> Level: <level> out of 5 **REMEMBER**, you are not allowed to think about it, please directly generate the answer in the following: Decomposed Sub-questions: Prompt Templates for Question Decomposition You are an experienced expert in <domain> and exam question designer. Your task is to evaluate the difficulty level of given exam problem and its sub-questions by comparing it against set of benchmark questions of known levels. Based on their levels, you will need to assign each subquestion portion of the credits (assuming the total credit points is 100 for the whole problem). Each level reflects increasing complexity from 1 (easiest) to 5 (most challenging). Evaluate based on the conceptual depth, steps involved in solving, required knowledge, and potential for misdirection. Use the following benchmark examples as references: <benchmarks> 1. You will be provided question and its subquestions. You will evaluate the difficulty level of the problem and its sub-questions. Assuming the whole problem is worth 100 points, you assign each sub-question portion of the score points. - Adhere to the given subquestions, and DO NOT make new subquestions. - Sum of each subquestions credits MUST EQUAL to 100. 2. You must return the result in structured JSON format: { 17 \"problem\": {\"reason\": \"...\", \"evaluated_level\": level_q} \"1\": {\"reason\": \"...\", \"evaluated_level\": level_1, \"credit\": credit_1}, \"2\": {\"reason\": \"...\", \"evaluated_level\": level_2, \"credit\": credit_2}, ...} where - \"reason\": short explanation (up to 50 words) of your level assessment. - \"evaluated_level\": an integer from 1 to 5 indicating your judgment. - \"credit\": an integer between 1 to 100 indicating when the question is solved correctly, how many credit can be given. Evaluate the level of the following question: Problem: <problem> Sub-questions: <steps> Output: Prompt Templates for Vanilla Model < dataset-specific instruction> Please reason step by step, and conclude your answer in the following format: <dataset specific output format> Question: <query> Reference: <reference>(only applicable to TravelPlanner) Output: <think> Prompt Templates for Global Budget Model < dataset-specific instruction> Please reason step by step, and conclude your answer in the following format: <dataset specific output format> Question: <query> Reference: <reference>(only applicable to TravelPlanner) Lets think step by step and use less than <budget> tokens. Output: <think> Prompt Templates for Planned Vanilla Model <dataset-specific instruction> The problem is given by an overall description, difficulty level out of 5, followed by series of sub-questions as hint. All the credit is given when you provide correct final answer for the overall problem. Please solve the question efficiently and clearly to achieve as much credit as possible. Lets start the exam. You are being given this math problem: **Problem (100pt):** <query> **Reference:** <reference>(only applicable to TravelPlanner) **Level:** <level> out of 5 18 You may think following these sub-questions or feel free to use other methods that works the best towards getting the final answer: <decomposed> Please provide your final answer in the following format: <dataset specific output format> Output: <think> Prompt Templates for Planned Global Budget Model <dataset-specific instruction> The problem is given by an overall description, difficulty level out of 5, followed by series of sub-questions as hint. All the credit is given when you provide correct final answer for the overall problem. Please solve the question efficiently and clearly to achieve as much credit as possible. Lets start the exam. You are being given this math problem: **Problem (100pt):** <query> **Reference:** <reference>(only applicable to TravelPlanner) **Level:** <level> out of 5 You may think following these sub-questions or feel free to use other methods that works the best towards getting the final answer: <decomposed> Please provide your final answer in the following format: <dataset specific output format> Lets think step by step and use less than <budget> tokens. Output: <think> Prompt Templates for Planned Local Budget Model (Ours) <dataset-specific instruction> The problem is given by an overall description, difficulty level out of 5, followed by series of sub-questions as hint. All the credit is given when you provide correct final answer for the overall problem. Please solve the question efficiently and clearly to achieve as much credit as possible. Lets start the exam. You are being given this math problem: **Problem (100pt):** <query> **Reference:** <reference>(only applicable to TravelPlanner) **Level:** <level> out of 5 You may think following these sub-questions or feel free to use other methods that works the best towards getting the final answer: <decomposed> (For each decomposed subquestion:) Please only think little, and directly solve it using up to <budget> words. Please provide your final answer strictly following the format: <dataset specific output format> 19 Output: <think>"
        }
    ],
    "affiliations": [
        "MIT CSAIL",
        "Michigan State University",
        "University of Virginia",
        "Virginia Tech"
    ]
}