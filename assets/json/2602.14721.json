{
    "paper_title": "WebWorld: A Large-Scale World Model for Web Agent Training",
    "authors": [
        "Zikai Xiao",
        "Jianhong Tu",
        "Chuhang Zou",
        "Yuxin Zuo",
        "Zhi Li",
        "Peng Wang",
        "Bowen Yu",
        "Fei Huang",
        "Junyang Lin",
        "Zuozhu Liu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce \\textbf{WebWorld} series, the first open-web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages a scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For intrinsic evaluation, we introduce WebWorld-Bench with dual metrics spanning nine dimensions, where WebWorld achieves simulation performance comparable to Gemini-3-Pro. For extrinsic evaluation, Qwen3-14B trained on WebWorld-synthesized trajectories improves by +9.2\\% on WebArena, reaching performance comparable to GPT-4o. WebWorld enables effective inference-time search, outperforming GPT-5 as a world model. Beyond web simulation, WebWorld exhibits cross-domain generalization to code, GUI, and game environments, providing a replicable recipe for world model construction."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 6 1 ] . [ 1 1 2 7 4 1 . 2 0 6 2 : r 2026-02WebWorld: Large-Scale World Model for Web Agent Training Zikai Xiao1,2,, Jianhong Tu1, Chuhang Zou, Yuxin Zuo1, Zhi Li1, Peng Wang1, Bowen Yu1,, Fei Huang1,, Junyang Lin1, Zuozhu Liu2, 1Qwen Team, Alibaba Group, 2Zhejiang University https://github.com/QwenLM/WebWorld"
        },
        {
            "title": "Abstract",
            "content": "Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce WebWorld series, the first open-web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For intrinsic evaluation, we introduce WebWorld-Bench with dual metrics spanning nine dimensions, where WebWorld achieves simulation performance comparable to Gemini-3-Pro. For extrinsic evaluation, Qwen3-14B trained on WebWorld-synthesized trajectories improves by +9.2% on WebArena, reaching performance comparable to GPT-4o. WebWorld enables effective inference-time search, outperforming GPT-5 as world model. Beyond web simulation, WebWorld exhibits cross-domain generalization to code, GUI, and game environments, providing replicable recipe for world model construction. Figure 1: Overview of WebWorld. WebWorld is large-scale world model for the open web, trained on over 1M real-world trajectories. It supports long-horizon, multi-format simulation, enabling agents trained with its data to achieve significant performance gains. Work done during the internship at Qwen. * Corresponding authors: feihu.hf@alibaba-inc.com, zuozhuliu@intl.zju.edu.cn."
        },
        {
            "title": "Introduction",
            "content": "Autonomous web agents based on large language models (LLMs) are widely used for various web tasks, as they can leverage strong language priors to reason and plan. However, their ability to reliably execute actions in real-world browser environments remains limited. In the experience era (Silver & Sutton, 2025), continuous interaction with the environment is key to building more robust and action-oriented agents (Yang et al., 2025; Xi et al., 2025; Huang et al., 2025; Hui et al., 2024). Nevertheless, scaling web agents for large-scale real-world interactions remains difficult. Collecting trajectories is slow due to network latency, page loading times, and rate limits, and many websites employ anti-crawling or access restrictions. Moreover, interactions require careful safety considerations, as some actions (e.g., submitting sensitive forms or initiating transactions) may be irreversible (Ram, 2025; Bonagiri et al.). Therefore, web world models provide potential solution by enabling agents to train in simulated environments (Anonymous, 2025a; Feng et al., 2025; Song et al., 2026). Recent work demonstrates the effectiveness of LLM-based world models to produce large quantities of synthetic trajectories, substantially improving agent learning (Team et al., 2025; DeepSeek-AI, 2024). In web scenarios, while prompting proprietary frontier LLMs as world model (Wang et al., 2025; Li et al., 2025b) has shown initial promise for agent training, more recent efforts have focused on training web world model (Chae et al., 2025; Chen et al., 2025; Gao et al., 2025). However, existing models exhibit poor generalization because the data pipeline is not easily scalable. First, they rely on narrow set of agent tasks, resulting in datasets restricted to around 10k trajectories. Furthermore, because data is collected from sandboxes or closed environments for benchmarking purposes, the resulting trajectories lack diversity. These limitations often confine models to single-turn predictions and restricted input formats, while precluding explicit reasoning capabilities, see Table 1. Table 1: Comparison of World Models for Web Agents. We categorize existing approaches into APIbased prompting methods and trained world models. Unlike proprietary API-based simulators or prior open-weights models restricted to closed web environments, WebWorld is generalist world model trained on large-scale (1M+) real-world trajectories, supporting internal reasoning, long-horizon consistency, and open-web generalization. Model Size Open Access Model Data Data Source Type Scale Formats Model Capabilities Open-Web Reason Long-Horizon API-Based Prompting Methods UI-Simulator (Wang et al., 2025) GPT-4o-mini Simia (Li et al., 2025b) o4-mini Trained World Models DreamGym (Chen et al., 2025) WebEvolver (Fang et al., 2025) WMA (Chae et al., 2025) Word2World (Li et al., 2025a) WebSynthesis (Gao et al., 2025) 8B 70B 8B 8B 7B WebWorld (Ours) 8B/14B/32B - - - - Prompting Prompting - - A11y Text Benchmarks 14K 5K Self-Gen Benchmarks 14K Benchmarks 70k Benchmarks 4K Text A11y Text Text A11y Real-world 1.06M Multi Full Traj. Single-step Single-step Full Traj. Single-step Open-Web: Generalizes to diverse real-world websites beyond limited benchmarks (e.g., WebArena). Reason: CoT to explain state transitions before prediction. Long-Horizon: Supports long-horizon interaction history (up to 30 turns) for consistent simulation. Full Traj.: Uses complete trajectory history. Single-step: Only uses the most recent state. Multi Formats: Supports Text, A11y, HTML, XML, and Markdown. Self-Gen: Generated by an agent exploring live websites based on benchmark queries. Note: Word2World utilizes simplified, flattened text for state representation, distinct from A11y Tree. We introduce WebWorld ( Figure 2), large-scale open-web world model series (8B, 14B, and 32B) trained on 1M+ real-world trajectories (100 more than prior work) that supports reasoning, longhorizon simulation (30+ turns), and multiple input formats (A11y Tree, HTML, etc.). To ensure generalization, we build scalable, hierarchical data pipeline that expands coverage over prior work. The data pipeline ( Figure 1.c) first uses rule-based crawlers on websites from pre-training corpora to scalably collect massive amounts of trajectories aligned with the models pre-training prior (43.3% of total data). Then, agents autonomously explore diverse websites by generating their own tasks, producing large-scale natural interaction data (20.4%). Finally, agents execute predefined tasks to collect taskoriented trajectories (16.1%). This pipeline collects 1M trajectories that inject knowledge into the model. Since real-world trajectories rarely include explicit reasoning, we further fine-tune on 1K synthesized 2 Figure 2: WebWorld Example. Left: Agent. Right: WebWorld. CoT samples (0.09%) to inject causal reasoning patterns. Experiments validate that the knowledge-thenreasoning-pattern injection recipe is essential for world models ( Table 7). To holistically assess WebWorld, we introduce WebWorld-Bench, an intrinsic benchmark that evaluates models using Factuality and Web Turing Scores across nine dimensions, from long-horizon simulation to multi-format robustness. WebWorld achieves performance on par with Claude-Opus-4.1 and Gemini-3-Pro, maintaining consistently high scores across all metrics. Furthermore, we validate WebWorlds utility through two extrinsic scenarios. First, we synthesize 8,000 diverse trajectories using WebWorld with an Abstract-and-Instantiate strategy. Fine-tuning Qwen3-8B on these trajectories achieves +9.9% gains on MiniWob++ and +10.9% on WebArena, with the fine-tuned 14B model reaching performance comparable to GPT-4o. Second, for inference-time lookahead search, we use WebWorld to simulate the next state for action selection, and it outperforms GPT-5 as world model. We also observe that WebWorld adheres to predictable scaling laws, with performance consistently improving across model sizes without saturation. Finally, beyond web simulation, WebWorld exhibits strong cross-domain generalization to code, GUI, and game environments, validating the web as general foundation for other world model adaptation. Our contributions are three-fold: (1) We propose WebWorld, the large-scale web simulator trained on 1M+ real-world trajectories with scalable hierarchical data pipeline. (2) We introduce WebWorld-Bench, comprehensive evaluation framework with dual metrics across nine dimensions. (3) We demonstrate that agents trained on WebWorld-synthesized data achieve significant performance gains."
        },
        {
            "title": "2 Related Work",
            "content": "Web world models have been considered as potential approach for web agent training. Early work focused on prompting proprietary LLMs as world models. For instance, UI-Simulator (Wang et al., 2025) uses Retrieval-Augmented Simulation, employing world models to systematically synthesize trajectories in controlled manner, specifically targeting the agents weaknesses for its training. Simia (Li et al., 3 2025b) generates trajectories from tool specifications, enhancing both offline data synthesis and online reinforcement learning. These approaches highlight the potential of world models for agent training. Recent research has shifted from prompting to training world models in closed environments. DreamGym (Chen et al., 2025) uses offline trajectories from WebArena and WebShop to train models through experience replay and retrieval-augmented generation (RAG). More advanced agent-driven synthesis methods, including those from Li et al. (2025a) and Gao et al. (2025), employ Monte Carlo Tree Search (MCTS) to explore. WMA (Chae et al., 2025) leverages synthetic tasks and agent exploration to collect trajectories, while WebEvolver (Fang et al., 2025) fine-tunes both world models and agents alternately using co-evolution, where agent-collected data further enhances the models. While these works still predominantly rely on closed, benchmark environments for data collection, WebWorld targets the open web to improve generalization. By employing scalable hierarchical collection strategy, WebWorld efficiently captures diverse real-world dynamics."
        },
        {
            "title": "3.1 Overview",
            "content": "We model the browser world as an autoregressive simulator. Given an instruction and history ht = (s0, a0, . . . , st, at) of states and actions, it predicts the next state: st+1 Pθ( I, ht). We instantiate Pθ with causal LLM and train it by maximum likelihood on trajectories τ = (I, s0, a0, . . . , sT): (1) L(θ) = τD T1 t= log Pθ(st+1 I, ht). (2) To ensure the model generalizes, we align the data source with the pre-training corpus. Specifically, we extract target URLs directly from the metadata of large-scale pre-training corpora and employ scalable hierarchical collection strategy to harvest trajectories (Section 3.2). The collected data is filtered using rule-based checks and LLM-based verification to ensure quality (Section 3.3). Subsequently, we apply data augmentation (Section 3.4) to enable multi-format prediction. Finally, we adopt two-stage training curriculum: after initial large-scale dynamics training, we continue fine-tuning with CoT data (Section 3.5) to explicitly activate the models reasoning capabilities."
        },
        {
            "title": "3.2 Data Construction Pipeline",
            "content": "Data Format We adopt the A11y Tree as our primary state representation due to its universal applicability across web and GUI environments, high information density, and LLM-friendly structure (Zhou et al., 2023). We extract A11y Trees using the Playwright API from BrowserGym (de Chezelles et al., 2025). To prevent overfitting to single format, we augment training data by converting trajectories into multiple web representations via post-hoc conversion and natural language page descriptions via LLM. Details of data formats can be found in Appendix G. Data Source. For URL sources, We primarily extract target URLs from large-scale pre-training corporaFineWeb (Penedo et al., 2024) (English, 618k URLs) and quality-filtered subset of CCI 3.0 (Wang et al., 2024) (Chinese, 64k URLs)ensuring alignment between the world models training distribution and the base LLMs pretraining priors. We added curated lists of high-traffic English and Chinese websites (e.g., e-commerce, social media, news portals). For task-oriented execution data (described later in our hierarchical pipeline), we synthesize task-oriented queries by sampling seed tasks from the Mind2Web training set (Deng et al., 2023) and generating diverse variants via LLM. Auxiliary data: We incorporate open-source agent trajectories (Xu et al., 2025) by reformatting trajectories into (st, at, st+1) tuples, and mix in general instruction-following data (Ding et al., 2023) to preserve conversational abilities. Scalable Hierarchical Data Collection. Existing methods rely on task-directed execution, which ensures relevance but limits scalability. We propose scalable, three-level (hierarchical) pipeline ( Figure 1.c) that maintains task relevance through: randomized exploration (breadth), autonomous discovery (realism), and task synthesis (task-alignment). Level 1: Randomized Crawling. To scalably harvest large-scale interaction data, we deploy randomized crawlers on websites extracted from pre-training corpora (FineWeb, CCI 3.0). The crawlers randomly sample executable actions from the current pages A11y Tree (such as clicking buttons, filling forms, or selecting dropdowns) and execute 310 step trajectories per website. This ensures the training distribution 4 aligns with the models linguistic priors from pre-training, maximizing the activation of its innate web understanding. This stage yields 293K diverse trajectories spanning the breadth of the open web. Level 2: Autonomous Exploration. To capture realistic agentenvironment interaction dynamics, we deploy LLM-based agents that autonomously explore websites by generating their own exploratory objectives. We steer trajectory patterns through prompt design. Prompts encode targeted behavioral priors that induce the interaction patterns desired for world model learning (Appendix N.4). Concretely, we implement four complementary exploration strategies: (i) Self-proposed Taskthe prompt instructs the agent to infer concrete user intent from the current page and execute it; (ii) Long-horizon dependencythe prompt forces the agent to produce trajectories where later states depend on earlier actions; (iii) Composite Action interactionthe prompt requires multi-action (type/select/click) to avoid trivial navigation-only behavior; (iv) Curiosity discoverythe prompt encourages systematic coverage of major sections and features to maximize breadth. Each trajectory spans up to 30 steps, and agents naturally terminate upon exhausting discoverable content or hitting step limits. This stage produces 38K long-horizon trajectories that reflect realistic agent behaviors. Level 3: Task-Oriented Execution. To ensure the model masters task-oriented dynamics, we synthesize explicit web tasks through three-stage generation pipeline: (i) Seed extractionan LLM analyzes website and proposes feasible user intents (e.g., book flight); (ii) Task diversificationfor each seed, we generate multiple task variants by perturbing parameters while maintaining executability on the same website; (iii) Paraphrasewe generate semantically similar but linguistically diverse phrasings of each task. Agents then execute these tasks on the corresponding websites, and we retain only successful trajectories. This yields 94K high-quality execution traces where every action is purposeful and goaldirected, capturing the state transitions essential for complex agentic workflows. Across all levels, we represent page states using A11y Tree, which provides structured, LLM-friendly abstraction of interactable elements while filtering out rendering noise. The final dataset combines these levels with enriched data (subsection 3.4), totaling 1.06M trajectories ( Table 11)."
        },
        {
            "title": "3.3 Filtering",
            "content": "To ensure high data quality and safety, we implement rigorous dual-stage filtering pipeline applied to both the source URLs and the collected trajectories. We first employ script-based heuristics to verify website reachability and filter out content containing banned keywords (e.g., pornography, gambling, violence). The initial filtering for website reachability leaves 15.7% of the original URLs, of which 85.2% subsequently pass the keyword check. Subsequently, we utilize an LLM to score the remaining sites across four dimensions: accessibility, content suitability, interactivity, and engineering quality. Sites scoring below the average or triggering safety violations are discarded. The details of LLM-based URL filtering are illustrated in Figure 6. For the collected trajectory, we apply keyword filtering to eliminate unsafe content. We further prune transitions where an action results in no observable state change (e.g., due to network latency or page loading failures) and discard trajectories exceeding 30k tokens or 30 turns. To avoid introducing the inductive bias of specific model, we rely exclusively on rule-based trajectory filtering and do not employ LLMs for judgment at this stage."
        },
        {
            "title": "3.4 Data Enrichment",
            "content": "Although our collected trajectories provide rich multi-page interactions in A11y Tree format, relying solely on this representation limits model versatility and risks catastrophic forgetting. To address this, we construct multi-dimensional instruction tuning dataset covering five paradigms, as detailed in Table 2. In the Web Domain, we implement the Multi-Format Simulator by transpiling trajectories into other formats (Appendix G). We further synthesize Web Generation data (mapping user queries to web pages) and Descriptive Simulation data (converting state changes into textual summaries). In the General Domain, we reformat general QA data into world model prediction tasks. Finally, we mix in general chat data to prevent catastrophic forgetting."
        },
        {
            "title": "3.5 CoT Synthesis",
            "content": "To activate explicit reasoning capabilities, we randomly sample transitions from the 1.06M corpus and synthesize CoT rationales. Given (I, st, at), the model generates intermediate reasoning stepsanalyzing page structure, interpreting user intent, predicting changesfollowed by the next state st+1. We adopt two-stage curriculum: Stage 1 trains on the full dataset to learn web dynamics; Stage 2 continues training with small amount of CoT-augmented data to externalize reasoning patterns. As shown in Table 7, 5 Table 2: Data Enrichment Tasks. Overview of the five auxiliary tasks across Web and General domains. Notation: represents structured web states (A11y, HTML, XML, Markdown); denotes natural language text; indicates agent actions. Domain Task Input Output Description Web 1. Multi-Format Simulator St + At 2. Web Generation 3. Descriptive Simulator Tintent St + At St+1 Spage Tdesc Predict next state in A11y, HTML, XML, or Markdown. Generate full webpage structure from user requirements. Interpret visual changes and output text summary. General 4. General World Model 5. General Chat Tt + At Tquery Tt+1 Tresponse Simulate state transitions purely in natural language. Standard dialogue to preserve conversational capabilities. our robust pre-trained dynamics enable effective reasoning activation with only 1,000 samples, achieving performance that surpasses the base model trained on 10x more CoT data."
        },
        {
            "title": "3.6 Dataset Statistics",
            "content": "We present the dataset statistics in Figure 3. The domain distribution demonstrates balanced coverage across diverse categories, with detailed source breakdowns provided in Figure 5. Furthermore, the dataset exhibits significant variance in complexity, featuring context lengths up to 30k tokens and longhorizon trajectories reaching 30 turns, ensuring the model generalizes effectively to both simple and extended web interactions. (a) Overall Domain Distribution (b) Token Length Distribution (c) Trajectory Turns Distribution Figure 3: Statistics of the WebWorld Dataset. (a) Diverse coverage across domains like Lifestyle, Tech, and Education. (b) Token distribution showing the models exposure to varying context lengths. (c) Interaction turns distribution confirming the inclusion of long-horizon tasks (up to 30+ steps)."
        },
        {
            "title": "4 Benchmarking Web World Model",
            "content": "Existing intrinsic evaluation metrics for world models fall into two categories. Structural metrics (Fang et al., 2025) measure DOM tree similarity and element-level alignment, while semantic metrics (Chae et al., 2025) use information coverage (ROUGE/BERTScore) between predicted and actual state change descriptions. ViMo (Anonymous, 2025b) extends this with visual similarity and functional availability for mobile GUIs. However, these approaches struggle with open-ended web tasks: structural metrics produce uniformly low scores due to HTMLs high variance, while semantic metrics fail to differentiate model capabilities when state changes are complex (Appendix for detailed analysis). To address this, we construct WebWorld-Bench with two complementary metrics: Factuality Score employs pointwise evaluation, where an LLM judge scores whether the predicted state correctly reflects the functional effect of the action, capturing factual correctness on continuous scale; Web Turing Score uses pairwise comparison, where the judge attempts to distinguish simulated states from real ones, assessing perceptual realism through adversarial discrimination. Together, these metrics provide both objective verification and subjective plausibility assessment. We also validate practical utility through extrinsic evaluation, measuring downstream agent performance when trained on WebWorld-synthesized data (Section 5.1). 6 Table 3: Performance comparison across nine evaluation dimensions. Each dimension reports both Factuality Score (Fact.) and Web Turing Score (Tur.) in paired columns. Models are categorized into Proprietary and Open-source. The best results in each metric are bolded. All scores are normalized to [0, 1], with higher values indicating better performance. Model Long-Horizon Base Sem. Fine-grain Multi-tab Multi-format Robustness Web2NAL Average (Consistency) (Semantics) (Sensitivity) (Multi-page) XML HTML Markdown Playwright (Nat. Lang.) (All) Fact. Tur. Fact. Tur. Fact. Tur. Fact. Tur. Fact. Tur. Fact. Tur. Fact. Tur. Fact. Tur. Fact. Tur. Fact. Tur. Proprietary LLMs GPT-4o Claude-Sonnet-4.5 Claude-Opus-4.1 Gemini-3-Pro Open-source LLMs WebSynthesis-8B WMA-8B Word2World-8B Qwen3-8B Qwen3-14B Qwen3-32B Ours 69.2 78.1 82.9 78.7 24.2 15.2 8.5 41.4 49.4 52.9 25.0 37.0 34.0 39.4 13.0 11.0 1.0 18.0 25.0 21. 55.3 43.0 60.4 42.0 72.1 53.0 67.2 40.8 8.0 6.9 6.0 9.4 6.5 0.5 18.5 15.0 31.7 23.0 34.9 26.0 81.0 81.1 79.4 80.3 22.5 18.8 13.5 60.4 71.2 71.2 30.0 34.0 35.0 34.3 4.0 5.0 0.8 19.0 25.0 23. 69.9 68.8 79.3 81.3 73.2 7.5 4.5 34.0 51.7 47.7 32.0 31.0 43.0 42.0 33.0 4.0 1.0 11.0 13.0 19.0 63.5 25.0 47.3 22.0 64.1 36.0 51.3 44.0 60.4 31.0 42.4 20.0 63.3 34.0 51.7 36.0 76.4 42.0 68.8 47.0 77.5 54.0 75.5 56.0 76.4 37.9 59.5 40.8 75.5 41.0 78.6 62.6 6.8 1.0 5.4 2.0 3.0 0. 0.4 0.0 10.5 9.8 1.2 1.0 4.0 2.5 0.0 4.0 3.0 0.0 16.8 11.0 11.5 5.0 19.8 12.0 11.2 20.0 30.3 14.0 25.9 12.0 31.2 18.0 17.4 24.0 32.5 15.0 22.3 11.0 46.3 21.0 23.0 23.0 9.0 7.0 0.0 2.6 4.5 3.5 34.2 31.4 29.4 35.4 3.4 28.5 17.0 28.8 33.0 29. 62.0 61.0 63.0 49.5 7.0 39.0 2.0 46.0 50.0 48.0 59.5 35.4 59.7 36.2 71.3 47.4 70.3 43.2 16.7 8.8 11.1 8.7 7.0 0.6 26.9 17.4 38.0 22.7 40.1 23.0 76.7 76.1 77.0 WebWorld-8B WebWorld-14B WebWorld-32B Fact.: Factuality Score (measures functional correctness of state transitions). Tur.: Web Turing Score (measures perceptual realism via adversarial discrimination). Scores are presented as percentages (0100) for readability. 70.3 41.0 65.9 39.0 75.5 44.0 72.7 51.0 73.3 45.0 62.7 41.0 71.4 47.0 73.2 49.0 73.0 45.5 63.0 40.5 73.0 48.0 74.0 50.0 68.0 42.0 74.0 50.0 74.5 51.0 82.2 79.8 79.0 45.0 41.0 40.0 81.7 87.7 87.0 43.0 44.0 44. 37.6 38.1 38.5 41.0 49.0 54.0 34.0 36.0 37.0 70.1 42.2 70.7 44.7 71.0 45."
        },
        {
            "title": "4.1 Metrics",
            "content": "To provide holistic assessment of the world models capabilities, we evaluate performance across nine dimensions using two metrics. Both metrics utilize GPT-4o as judge to automate the evaluation process. Factuality Score. This metric evaluates the functional correctness of the state transitions via pointwise scoring. Given the interaction history and the ground-truth next state, the judge assesses whether the models predicted observation accurately reflects the causal effect of the action (e.g., button click triggering pop-up). The complete judge prompt is provided in Appendix 13. The score quantifies how well the model avoids hallucinations and aligns with the deterministic dynamics of the real web, focusing on semantic consistency rather than pixel-perfect matching. Web Turing Score. This metric evaluates the world model through pairwise comparison. We present the judge with two anonymized observationsone generated by WebWorld and one from the real browser environmentand ask it to identify the more realistic webpage (see Appendix 14 for the full prompt). higher score indicates that the models generated states are indistinguishable from, or even deemed more plausible than, real-world data."
        },
        {
            "title": "4.2 Evaluation Dimensions",
            "content": "We constructed WebWorld-Bench, comprehensive evaluation suite comprising nine distinct dimensions. The evaluation data were generated using the same hierarchical data curation pipeline as our training set to ensure domain alignment, but were strictly held out to prevent data contamination. Long-Horizon Consistency evaluates context retention in extended interactions. We select trajectories exceeding 10 steps and provide the full interaction history as input. Fine-Grained Sensitivity challenges the models precision by focusing on localized state updates. We employ an LLM to specifically filter for actions that trigger minimal changessuch as expanding dropdown menu or toggling checkboxrequiring the model to accurately localize updates without hallucinating global shifts. Conversely, Base Semantics assesses performance on macroscopic page transitions. Finally, to ensure the model learns generalized dynamics rather than specific syntax, we evaluate Format Robustness across multiple representations (HTML, XML, Markdown) and Web2NAL, which tests the models ability to verbally describe state changes in natural language."
        },
        {
            "title": "4.3 Result on WebWorld-Bench",
            "content": "Table 3 shows that WebWorld-32B achieves 71.0% average Factuality Score, matching Claude-Opus-4.1 (71.3%), with particularly strong long-horizon consistency (77.0%) and multi-format robustness (7075% across formats). The notably low scores of open-source baselines reflect output format misalignment rather than model deficiency; detailed analysis is provided in Appendix C. 7 Table 4: Judge Consistency. We evaluate the consistency of model rankings using two state-of-the-art judges: GPT-4o and Claude-Opus-4.1. Despite variations in absolute strictness, the relative ranking remains robust across different evaluators. Model Proprietary GPT-4o Claude-Sonnet-4.5 Gemini-3-Pro Open-weights Qwen3-8B Qwen3-14B Qwen3-32B Ours WebWorld-8B GPT-4o Claude-Opus-4.1 Average Fact. Turing Fact. Turing Fact. Turing 59.5 59.7 70.3 26.9 38.0 40. 70.1 35.4 36.2 43.2 17.4 22.7 23.0 42.2 51.6 59.9 72.8 27.3 35.3 37. 67.6 21.0 31.9 36.5 11.7 15.8 16.2 31.7 55.6 59.8 71.6 27.1 36.7 38. 68.9 28.2 34.1 39.9 14.6 19.3 19.6 37."
        },
        {
            "title": "4.4 Judge Consistency",
            "content": "To ensure that the performance ranking in WebWorld is robust across different judge models, we conduct consistency analysis using different LLMs as judges. We measure the Total Score across the test set for each judge. As shown in Table 4, while absolute scores may vary, the relative ranking of models remains consistent. Table 5: Downstream Performance. Comparison of the base Qwen3-8B and Qwen3-14B models versus the models fine-tuned on WebWorld-synthesized trajectories. We report Success Rate (SR %), Standard Error (Std), and Average Steps. The symbols and indicate that higher and lower values are better, respectively. For WebArena, we detail performance across sub-domains. Model GPT-4o Qwen3-8B (Base) Qwen3-8B + WebWorld (Ours) Improvement (8B) Qwen3-14B (Base) Qwen3-14B + WebWorld (Ours) Improvement (14B) MiniWob++ WebArena SR (%) 64.3 49.4 59.3 +9.9% 54.9 63.2 +8.3% Std () 0.019 0.020 0.020 - 0.020 0.019 - Steps SR (Avg) 4.12 4.88 4.39 -0.49 4.55 4.28 -0. (%) 26.6 9.8 20.7 +10.9% 15.1 24.3 +9.2% Std () Steps Domain Breakdown (SR %) (Avg) E-Comm GitLab Reddit Others 0.016 11. 26.8 27.5 24.5 25.3 0.018 0.014 - 0.013 0.015 - 15.24 19.25 +4.01 16.12 17.11 +0.99 17.1 20.7 +3.6% 15.4 24.0 +8.6% 9.4 21.4 18.2 5.0 23.3 17.5 +12.0% +18.3% -0.7% 15.4 32.7 18.3 6.3 21.0 17.6 +17.3% +14.7% -0.7%"
        },
        {
            "title": "5.1 Trajectory Synthesis for Agents",
            "content": "We evaluate whether synthetic data from WebWorld improves real-world agent benchmarks. We implement an Abstract-and-Instantiate data synthesis pipeline to scale up training examples, generating 8,000 trajectories. The pipeline works as follows: Starting with concrete seed tasks (e.g., Book flight to London on March 15th), we use an LLM to abstract them into underspecified goals (e.g., Book flight to somewhere on sometime). The agent then executes actions in WebWorld following these abstract goals. For each execution trajectory, we instantiate it back into concrete task. Finally, the agent conducts the concrete task, and we apply rejection sampling to retain only successful trajectories. We fine-tuned Qwen3-8B on this synthetic dataset. As shown in Table 5, the model achieves significant improvements over the base model, with 9.9% gain on MiniWob++ and 10.9% gain on WebArena. Reddit and GitLab show strong gains of 18.3% and 12.0%."
        },
        {
            "title": "5.2 Inference-Time Search with World Models",
            "content": "We implement the lookahead search to validate WebWorlds utility, following Gu et al. (2025) and Chae et al. (2025). At each step, the agent proposes candidate actions. For each candidate, WebWorld 8 Table 6: Inference-Time Lookahead Search on MiniWob. Fmt: NL = Natural Language, A11y = A11y Tree. Scoring: Point = Pointwise, Pair = Pairwise. Alg: BoN = Best-of-N. Model & Search Configuration Result World Model Value Model Fmt Score Alg (k) Reward Baselines - GPT-4o - GPT-4o - A11y - Point Greedy BoN (3) Impact of Scoring & Value Model Ours (WebWorld) GPT-5 Ours (WebWorld) Ours (WebWorld) GPT-4o GPT-4o GPT-4o GPTFormat & Context Trade-off Ours (WebWorld) Ours (WebWorld) Ours (WebWorld) GPT-4o GPT-4o GPT-4o Advanced Search Strategy Ours (WebWorld) Ours (WebWorld) GPT-4o GPT-4o A11y A11y A11y A11y NL NL A11y A11y A11y Point Pair Pair Pair Pair Pair Pair Pair Pair BoN (3) BoN (3) BoN (3) BoN (3) BoN (3) BoN (5) BoN (2) MCTS (3) Hybrid (3) 64.3 63.8 64.8 64.5 65.5 67.5 65.2 65.9 65.7 65.4 65.5 - -0.5% +0.5% +0.2% +1.2% +3.2% +0.9% +1.6% +1.4% +1.1% +1.2% simulates the next state. value model then evaluates these simulated states for task utility, and the agent executes the action with the highest score. As detailed in Table 6, our WebWorld as world model achieves better performance than GPT-5. For the value model, shifting from pointwise to pairwise evaluation yields substantial gains. For the output format, natural language outputs enable deeper planning (k = 5) while full HTML is restricted to shallow depths (k = 2) by context limits. For search strategy, advanced MCTS or hybrid search (which only triggers look-ahead when actions are uncertain) offer marginal improvement. Consequently, the bounded gains from inference-time search suggest that world models are more valuable for synthesizing training data, aligning with Qian et al. (2026)s observation that current agents derive limited benefit from inference-time search. Figure 4: Scaling Law of WebWorld. Larger models achieve lower eval loss. Stars indicate predictions for the 72B model, suggesting continued performance gains with model scaling."
        },
        {
            "title": "6.1 Scaling Law of WebWorld",
            "content": "We trained the WebWorld across 6 model sizes using identical settings. Figure 4 shows that larger models consistently achieve lower evaluation loss. The relationship between the final evaluation loss and compute (measured in FLOPs) follows power-law. We extrapolate predictions for 72B models (marked with stars in Figure 4). The predicted losses suggest substantial performance improvements are achievable through further scaling, with no signs of saturation."
        },
        {
            "title": "6.2 Ablation of Reasoning Activation",
            "content": "We test the impact of different amounts of CoT data on model performance. As shown in Table 7, minimal dataset of just 1,000 samples is sufficient to activate the reasoning pattern, yielding Total Score of 0.561surpassing direct reasoning tuning on Qwen3-8B with 10 more data (0.510). We observe that excessive CoT data can degrade performance, thus we recommend combining large-scale real-world training with small, carefully curated amount of CoT data for optimal results. Table 7: Reasoning Activation Ablation. Comparison under varying reasoning data scales. WebWorld8B achieves superior performance with only 1k samples."
        },
        {
            "title": "Total Score",
            "content": "From Qwen3-8B (Direct Reasoning Tuning) Qwen3-8B 500 1k 2k 10k 0.502 0.511 0.541 0.625 From Stage 1 Model (1.06M Transition Modeling) 0.668 Ours 0.701 Ours 0.686 Ours 0.692 Ours 500 1k 2k 10k 0.277 0.296 0.319 0.394 0.402 0.422 0.388 0.413 0.390 0.403 0.430 0.510 0.535 0.561 0.537 0."
        },
        {
            "title": "6.3 Cross-Environment Generalization",
            "content": "We evaluate WebWorlds adaptation capability ( Table 8) by fine-tuning on open-source agent trajectories from API services, code development, games, and GUI desktops, converted into (st, at, st+1) transition tuples (Tables 14 and 15), using the same Factuality and Web Turing metrics from WebWorld-Bench. Results show that WebWorld consistently outperforms the baseline, demonstrating strong transferability across other environments. Table 8: Cross-Environment Adaptation. WebWorld demonstrates strong adaptation capability across unseen environments. Environment API Services Code Game GUI Average 1,500 Samples (Total Score) 3,000 Samples (Total Score) Qwen3 Ours Gain () Qwen3 Ours Gain () 0.088 0.147 0.253 0.322 0.176 0.299 0.396 0.473 0.705 0.400 +0.211 +0.249 +0.220 +0. +0.224 0.258 0.196 0.374 0.511 0.298 0.292 0.471 0.522 0.719 0.463 +0.034 +0.275 +0.148 +0. +0."
        },
        {
            "title": "7 Conclusions and Limitations",
            "content": "In this paper, we introduced WebWorld, browser simulator trained on over one million real-world interaction trajectories. WebWorld enables efficient agent training in simulation, significantly improving performance on downstream tasks. WebWorld has limitations. It exhibits sycophancy by generating overly optimistic outcomes that cater to the agents action. Additionally, WebWorld struggles to generate high-quality, detailed content, such as scientific articles."
        },
        {
            "title": "Impact Statement",
            "content": "This paper presents WebWorld, large-scale world model designed to simulate web environments for training autonomous agents. Our work aims to advance the field of machine learning by enabling scalable, offline training that circumvents the latency, safety constraints, and rate-limiting issues inherent to real-world web interaction. The primary societal benefit of this work is the democratization of web agent research. By providing an open, high-fidelity simulator trained on diverse real-world trajectories, we lower the barrier to entry for developing capable web agents, which can improve digital productivity, automate repetitive tasks, and enhance web accessibility for users with disabilities. Moreover, training in simulation mitigates safety risks: agents can explore without triggering irreversible real-world consequences such as unintended purchases, form submissions, or data modifications. We acknowledge that more capable web agents introduce dual-use concerns. Malicious actors could leverage such agents for automated phishing campaigns, credential stuffing, or large-scale scraping that violates terms of service. Additionally, our training data is sourced from web crawls (FineWeb, CCI 3.0), whichdespite rigorous keyword and LLM-based filteringmay inadvertently contain personally identifiable information (PII), toxic content, or demographic biases reflected in public web data. While we strictly adhere to robots.txt protocols and apply safety heuristics, residual risks remain. We also observe sycophancy bias in the models predictions, where simulated outcomes can be overly optimistic or cater to agent expectations, potentially hindering robust policy learning. To address these concerns, we release WebWorld with comprehensive documentation and ethical guidelines. We encourage the community to build on this work by developing PII scrubbing techniques, adversarial robustness mechanisms, and alignment methods to reduce sycophancy. We recommend that practitioners apply additional domain-specific safety checks before deploying agents trained on WebWorld in high-stakes environments. By open-sourcing both the model and training pipeline, we aim to foster transparent, reproducible research that prioritizes safety alongside capability advancement."
        },
        {
            "title": "References",
            "content": "Anonymous. Internalizing world models via self-play finetuning for agentic RL. In Submitted to The Fourteenth International Conference on Learning Representations, 2025a. URL https://openreview.n et/forum?id=K8wCGMzeuY. under review. Anonymous. Vimo: generative visual GUI world model for app agents. In Submitted to The Fourteenth International Conference on Learning Representations, 2025b. URL https://openreview.net/forum ?id=mWoMyDEfbM. under review. Vamshi Krishna Bonagiri, Ponnurangam Kumaraguru, Khanh Xuan Nguyen, and Benjamin Plaut. Check yourself before you wreck yourself: Selectively quitting improves llm agent safety. In NeurIPS 2025 Workshop on Regulatable ML. Hyungjoo Chae, Namyoung Kim, Kai Tzu iunn Ong, Minju Gwak, Gwanwoo Song, Jihoon Kim, Sunghwan Kim, Dongha Lee, and Jinyoung Yeo. Web agents with world models: Learning and leveraging environment dynamics in web navigation. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=moWiYJuSGF. Zhaorun Chen, Zhuokai Zhao, Kai Zhang, Bo Liu, Qi Qi, Yifan Wu, Tarun Kalluri, Sara Cao, Yuanhao Xiong, Haibo Tong, Huaxiu Yao, Hengduo Li, Jiacheng Zhu, Xian Li, Dawn Song, Bo Li, Jason Weston, and Dat Huynh. Scaling agent learning via experience synthesis, 2025. URL https://arxiv.org/ abs/2511.03773. Thibault Le Sellier de Chezelles, Maxime Gasse, Alexandre Lacoste, Massimo Caccia, Alexandre Drouin, Leo Boisvert, Megh Thakkar, Tom Marty, Rim Assouel, Sahar Omidi Shayegan, Lawrence Keunho Jang, Xing Han `u, Ori Yoran, Dehan Kong, Frank F. Xu, Siva Reddy, Graham Neubig, Quentin Cappart, 11 Russ Salakhutdinov, and Nicolas Chapados. The browsergym ecosystem for web agent research. Transactions on Machine Learning Research, 2025. ISSN 2835-8856. URL https://openreview.net/f orum?id=5298fKGmv3. Expert Certification. DeepSeek-AI. Deepseek-v3 technical report, 2024. URL https://arxiv.org/abs/2412.19437. Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. Mind2web: Towards generalist agent for the web. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2023. URL https://openreview.net/forum?i d=kiYqbO3wqw. Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. Enhancing chat language models by scaling high-quality instructional conversations. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 30293051, 2023. Tianqing Fang, Hongming Zhang, Zhisong Zhang, Kaixin Ma, Wenhao Yu, Haitao Mi, and Dong Yu. Webevolver: Enhancing web agent self-improvement with coevolving world model, 2025. URL https://arxiv.org/abs/2504.21024. Jichen Feng, Yifan Zhang, Chenggong Zhang, Yifu Lu, Shilong Liu, and Mengdi Wang. Web world models, 2025. URL https://arxiv.org/abs/2512.23676. Yifei Gao, Junhong Ye, Jiaqi Wang, and Jitao Sang. Websynthesis: World-model-guided mcts for efficient webui-trajectory synthesis, 2025. URL https://arxiv.org/abs/2507.04370. Yu Gu, Kai Zhang, Yuting Ning, Boyuan Zheng, Boyu Gou, Tianci Xue, Cheng Chang, Sanjari Srivastava, Is your llm secretly world model of the internet? Yanan Xie, Peng Qi, Huan Sun, and Yu Su. model-based planning for web agents. Transactions on Machine Learning Research, 2025. Yuchen Huang, Sijia Li, Zhiyuan Fan, Minghao LIU, Wei Liu, and Yi R. Fung. Scaling environments for LLM agents: Fundamentals, approaches, and future directions. In Workshop on Scaling Environments for Agents, 2025. URL https://openreview.net/forum?id=9axZcDTiJm. Binyuan Hui, Jian Yang, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Lei Zhang, Tianyu Liu, Jiajun Zhang, Bowen Yu, Kai Dang, et al. Qwen2. 5-coder technical report. arXiv preprint arXiv:2409.12186, 2024. Yixia Li, Hongru Wang, Jiahao Qiu, Zhenfei Yin, Dongdong Zhang, Cheng Qian, Zeping Li, Pony Ma, Guanhua Chen, Heng Ji, and Mengdi Wang. From word to world: Can large language models be implicit text-based world models?, 2025a. URL https://arxiv.org/abs/2512.18832. Yuetai Li, Huseyin Inan, Xiang Yue, Wei-Ning Chen, Lukas Wutschitz, Janardhan Kulkarni, Radha Poovendran, Robert Sim, and Saravan Rajmohan. Simulating environments with reasoning models for agent training, 2025b. URL https://arxiv.org/abs/2511.01824. Guilherme Penedo, Hynek Kydlıˇcek, Leandro von Werra, and Thomas Wolf. Fineweb, 2024. URL https://huggingface.co/datasets/HuggingFaceFW/fineweb. Cheng Qian, Emre Can Acikgoz, Bingxuan Li, Xiusi Chen, Yuji Zhang, Bingxiang He, Qinyu Luo, Dilek Hakkani-T ur, Gokhan Tur, Yunzhu Li, and Heng Ji. Current agents fail to leverage world model as tool for foresight, 2026. URL https://arxiv.org/abs/2601.03905. Aravilli Atchuta Ram. From vision to action: Enabling real-world agentic VLMs. In 1st Workshop on VLM4RWD @ NeurIPS 2025, 2025. URL https://openreview.net/forum?id=QnXb8mc1pR. David Silver and Richard Sutton. Welcome to the era of experience. Google AI, 1, 2025. Xiaoshuai Song, Haofei Chang, Guanting Dong, Yutao Zhu, Zhicheng Dou, and Ji-Rong Wen. Envscaler: Scaling tool-interactive environments for llm agent via programmatic synthesis. arXiv preprint arXiv:2601.05808, 2026. Kimi Team, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru Chen, Yuankun Chen, Yutian Chen, Zhuofu Chen, Jialei Cui, Hao Ding, Mengnan Dong, Angang Du, Chenzhuang Du, Dikang Du, Yulun Du, Yu Fan, Yichen Feng, Kelin Fu, Bofei Gao, Hongcheng Gao, Peizhong Gao, Tong Gao, Xinran Gu, Longyu Guan, Haiqing Guo, Jianhang Guo, Hao Hu, Xiaoru Hao, Tianhong He, Weiran He, Wenyang He, Chao Hong, Yangyang Hu, Zhenxing Hu, Weixiao Huang, Zhiqi Huang, Zihao Huang, Tao Jiang, Zhejun Jiang, Xinyi Jin, Yongsheng Kang, Guokun Lai, Cheng Li, Fang Li, Haoyang Li, Ming Li, Wentao Li, Yanhao Li, Yiwei Li, Zhaowei Li, Zheming Li, Hongzhan Lin, Xiaohan Lin, Zongyu Lin, Chengyin Liu, Chenyu Liu, Hongzhang Liu, Jingyuan Liu, Junqi Liu, Liang Liu, Shaowei Liu, T. Y. Liu, Tianwei Liu, Weizhou Liu, Yangyang Liu, Yibo Liu, Yiping Liu, Yue 12 Liu, Zhengying Liu, Enzhe Lu, Lijun Lu, Shengling Ma, Xinyu Ma, Yingwei Ma, Shaoguang Mao, Jie Mei, Xin Men, Yibo Miao, Siyuan Pan, Yebo Peng, Ruoyu Qin, Bowen Qu, Zeyu Shang, Lidong Shi, Shengyuan Shi, Feifan Song, Jianlin Su, Zhengyuan Su, Xinjie Sun, Flood Sung, Heyi Tang, Jiawen Tao, Qifeng Teng, Chensi Wang, Dinglu Wang, Feng Wang, Haiming Wang, Jianzhou Wang, Jiaxing Wang, Jinhong Wang, Shengjie Wang, Shuyi Wang, Yao Wang, Yejie Wang, Yiqin Wang, Yuxin Wang, Yuzhi Wang, Zhaoji Wang, Zhengtao Wang, Zhexu Wang, Chu Wei, Qianqian Wei, Wenhao Wu, Xingzhe Wu, Yuxin Wu, Chenjun Xiao, Xiaotong Xie, Weimin Xiong, Boyu Xu, Jing Xu, Jinjing Xu, L. H. Xu, Lin Xu, Suting Xu, Weixin Xu, Xinran Xu, Yangchuan Xu, Ziyao Xu, Junjie Yan, Yuzi Yan, Xiaofei Yang, Ying Yang, Zhen Yang, Zhilin Yang, Zonghan Yang, Haotian Yao, Xingcheng Yao, Wenjie Ye, Zhuorui Ye, Bohong Yin, Longhui Yu, Enming Yuan, Hongbang Yuan, Mengjie Yuan, Haobing Zhan, Dehao Zhang, Hao Zhang, Wanlu Zhang, Xiaobin Zhang, Yangkun Zhang, Yizhi Zhang, Yongting Zhang, Yu Zhang, Yutao Zhang, Yutong Zhang, Zheng Zhang, Haotian Zhao, Yikai Zhao, Huabin Zheng, Shaojie Zheng, Jianren Zhou, Xinyu Zhou, Zaida Zhou, Zhen Zhu, Weiyu Zhuang, and Xinxing Zu. Kimi k2: Open agentic intelligence, 2025. URL https://arxiv.org/abs/2507.20534. Liangdong Wang, Bo-Wen Zhang, Chengwei Wu, Hanyu Zhao, Xiaofeng Shi, Shuhao Gu, Jijie Li, Quanyue Ma, TengFei Pan, and Guang Liu. Cci3.0-hq: large-scale chinese dataset of high quality designed for pre-training large language models, 2024. URL https://arxiv.org/abs/2410.18505. Yiming Wang, Da Yin, Yuedong Cui, Ruichen Zheng, Zhiqian Li, Zongyu Lin, Di Wu, Xueqing Wu, Chenchen Ye, Yu Zhou, and Kai-Wei Chang. Llms as scalable, general-purpose simulators for evolving digital agent training, 2025. URL https://arxiv.org/abs/2510.14969. Zhiheng Xi, Jixuan Huang, Chenyang Liao, Baodai Huang, Honglin Guo, Jiaqi Liu, Rui Zheng, Junjie Ye, Jiazheng Zhang, Wenxiang Chen, Wei He, Yiwen Ding, Guanyu Li, Zehui Chen, Zhengyin Du, Xuesong Yao, Yufei Xu, Jiecao Chen, Tao Gui, Zuxuan Wu, Qi Zhang, Xuanjing Huang, and Yu-Gang Jiang. Agentgym-rl: Training llm agents for long-horizon decision making through multi-turn reinforcement learning, 2025. URL https://arxiv.org/abs/2509.08755. Yiheng Xu, Dunjie Lu, Zhennan Shen, Junli Wang, Zekun Wang, Yuchen Mao, Caiming Xiong, and Tao Yu. Agenttrek: Agent trajectory synthesis via guiding replay with web tutorials. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum ?id=EEgYUccwsV. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Zhangchi Feng, and Yongqiang In Proceedings of the Ma. Llamafactory: Unified efficient fine-tuning of 100+ language models. 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), Bangkok, Thailand, 2024. Association for Computational Linguistics. URL http://arxiv.org/ab s/2403.13372. Shuyan Zhou, Frank Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: realistic web environment for building autonomous agents. arXiv preprint arXiv:2307.13854, 2023. URL https://webarena.dev."
        },
        {
            "title": "Appendix Contents",
            "content": "Experimental Setup A. World Model Training Details B. API Models C. Baseline Implementation Data & Representation D. Training Data Composition E. Domain Distribution Statistics F. Action Space Definition G. Format Conversion Pipeline H. URL Filtering with LLMs I. Cross-Environment Data Evaluation & Analysis J. World Model Evaluation Taxonomy K. Generation Length Analysis"
        },
        {
            "title": "Design Rationale",
            "content": "L. Multimodality Discussion Reproducibility M. Prompt Templates Ethics N. Ethical Considerations"
        },
        {
            "title": "A World Model Training Details",
            "content": "We utilize LLaMA-Factory (Zheng et al., 2024) for the supervised fine-tuning (SFT) of our LLM-based world model. We employ full fine-tuning with DeepSpeed ZeRO-3 (Qwen3-32B) and ZeRO-2 (others), enabling Liger Kernel and Unsloth garbage collection for memory efficiency. We apply sequence packing with maximum cutoff length of 20,000 tokens to optimize data throughput. The training process runs for 1 epoch with cosine learning rate scheduler. The detailed hyperparameters are in Table 9, which provides side-by-side comparison of the hyperparameters used in our two-stage training curriculum. Table 9: Comparison of Hyperparameters Across Training Stages. Stage 1 focuses on large-scale dynamics learning with aggressive data throughput, while Stage 2 refines reasoning capabilities with conservative fine-tuning to prevent forgetting. Training times are reported for three model scales on NVIDIA A100 GPUs. Hyperparameter Stage 1: Transition Modeling Stage 2: Reasoning Activation Training Configuration Objective Data Source Initialization Finetuning Type Precision Optimization Learning Rate Schedule Base Learning Rate Scheduler Type Warmup Ratio Number of Epochs Batch Configuration Per-Device Batch Size Gradient Accumulation Effective Batch Size Data Processing Max Sequence Length Sequence Packing History Masking Learn (st, at) st+1 1.06M real-world trajectories Qwen3 Base Checkpoint Full Parameter BF16 DeepSpeed ZeRO-2 Learn (st, at) thought st+1 1K CoT samples Stage 1 Checkpoint Full Parameter BF16 DeepSpeed ZeRO-2 2.0 105 Cosine with Warmup 0.1 8.0 106 ( 2.5) Cosine with Warmup 0.1 5 ( 5) 2 2 steps 64 (2 devices) 20,000 tokens Enabled Disabled 2 2 steps 32 (1 device) 20,000 tokens Enabled Enabled (CoT-only loss) 8A100 (80GB) 110 steps 2:02:54 (8A100) 2:25:03 (8A100) 3:07:03 (8A100) Training Resources (WebWorld-8B) Hardware Configuration Total Training Steps 16A100 (80GB) 7,215 steps Training Time by Model Scale WebWorld-8B WebWorld-14B WebWorld-32B 4 days, 1:12:13 (16A100) 7 days, 21:50:56 (16A100) 12 days, 20:20:06 (16A100) We utilize the Qwen3 series (Yang et al., 2025) as the primary backbone for our LLM-based world models. To systematically study the impact of model scale on world modeling capabilities, we train Qwen3 models across three varying parameter sizes: 8B, 14B, and 32B."
        },
        {
            "title": "B API Models",
            "content": "We evaluate our methods using state-of-the-art proprietary models. The specific API models and their corresponding versions used in our experiments are listed in Table 10."
        },
        {
            "title": "C Baseline Implementation Details",
            "content": "WMA Baseline Construction. For the WMA baseline (Chae et al., 2025), the official release provides only LoRA adapter compatible with Meta-Llama-3.1-8B-Instruct, which precludes direct architectural comparison with our Qwen3-based models. To ensure fair evaluation controlled for the base model, we utilized the official WMA dataset1. We reformatted this data to align with our unified 1https://huggingface.co/datasets/LangAGI-Lab/world_model_for_wa_desc_with_tao_form atted_w_cot 15 Table 10: API models and versions used for evaluations."
        },
        {
            "title": "Version",
            "content": "GPT-4o Claude-Sonnet-4.5 Claude-Opus-4.1 Gemini-3-Pro GPT-5 gpt-4o-2024-11-20 claude-sonnet-4-5-20250929 claude-opus-4-1-20250805 Gemini-3-Pro-preview gpt-5-2025-08-07 training schema and performed fine-tuning on Qwen3-8B using the converted dataset. This approach allows us to evaluate the efficacy of the data and training objective independently of the underlying foundation model. WMAs core objective is predicting free-form natural language descriptions of state changes rather than structured state representations. WebSynthesis Baseline Construction. For the WebSynthesis baseline (Gao et al., 2025), as the pre-trained world model weights were not publicly released, we reproduced the model using their official opensource dataset2. Specifically, we utilized the world-model-training-data-27k.json subset. We reformatted these samples to match our unified training template and fine-tuned Qwen3-8B under the exact same hyperparameters as our main experiments. This ensures that the comparison isolates the impact of the training data distribution and quality. WebSynthesis is optimized for sparse, multi-page transitions characteristic of WebArena (e.g., post-form-submission page loads). Word2World Baseline Construction. For the Word2World baseline (Li et al., 2025a), we utilized the open-weights checkpoint WorldModel-Webshop-Llama3.1-8B3. Word2World adopts simplified, flattened text stream representation with custom separators, which is structurally distinct from the standard A11y Tree or HTML formats. To benchmark its performance, we evaluated the model in zero-shot setting on WebWorld-Bench. As expected, the significant format misalignmentspecifically the lack of standard A11y or natural language outputsresulted in near-zero performance across structural and semantic metrics, highlighting the necessity of format-aligned training for robust web simulation. Word2Worlds proprietary WebShop format is not transferable to open-domain evaluation."
        },
        {
            "title": "D Training Data Composition",
            "content": "We provide comprehensive statistics of all datasets used in Stage 1 training (Real-World Transition Modeling) in Table 11. The table details each datasets category, original source, language distribution (English/Chinese/Multilingual), scale, and key attributes. Table 11: Statistics of the Constructed WebWorld Training Data. Attributes indicate if data is from Realworld websites, contains Long-horizon sequences (>10 steps), or supports Multi-format (HTML/A11y). Category Source Lang. Scale Attributes # Traj. Size Real-World Long-Seq. Multi-Fmt. Randomized Crawling CCI 3.0 (Filtered) FineWeb Subset Subtotal CN EN - 57,837 235,674 17.67G 4.33G 293,511 22.0G Autonomous Exploration FineWeb (LLM-Driven) High-Freq Sites Mixed Mixed 36,474 1,882 9.9G 0.5G Subtotal - 38,356 10.4G Task-Oriented Execution Benchmarks (Synthetic) Mixed 94, Open Source Multi-format Interaction AgentTrek / OS Gen / Etc. EN 37, HTML / XML / Playwright Ultrachat / QA / Web2NAL 47,855 547,758 8.2G 0.7G 4.0G 5.6G Total All Combined 1,059,348 50.9 - - - - - 2https://huggingface.co/datasets/yifeigao/WebSynthesis 3https://huggingface.co/X1AOX1A/WorldModel-Webshop-Llama3.1-8B"
        },
        {
            "title": "E Domain Distribution Statistics",
            "content": "The chart illustrates the distribution of domains and data sources in our dataset of over one million trajectories, as shown in Figure 5. The colors represent different semantic domains (e.g., Technology, E-Commerce), showing that our data collection pipelines significantly contribute to the diversity of open-domain topics compared to traditional web generation methods. Figure 5: Domain and Source Distribution of WebWorld Training Data. The chart illustrates the composition of our trajectory dataset, which contains over one million samples, across 15 distinct data sources. The colors represent different semantic domains (e.g., Technology, E-Commerce), showing that our data collection pipelines significantly contribute to the diversity of open-domain topics compared to traditional web generation methods."
        },
        {
            "title": "F Action Space Definition",
            "content": "To enable the agent to interact effectively across diverse web environmentsranging from DOM-based websites to coordinate-sensitive mini-gameswe define unified action space represented as Pythonstyle function calls. The action space is hybrid, supporting both high-level semantic interactions via element identifiers (A11y Tree IDs, denoted as bid) and low-level control via Cartesian coordinates ((x, y)). Element-based actions allow precise manipulation of form fields, buttons, and dropdowns, while coordinate-based primitives (e.g., mouse move, mouse click) enable the agent to handle canvas elements or drag-and-drop tasks. Additionally, the agent possesses browser-level controls for navigation and tab management, as well as meta-actions to communicate with the user or terminate the trajectory. The complete set of supported action primitives is detailed in Table 12 and Table 13."
        },
        {
            "title": "G Format Conversion Pipeline",
            "content": "To train robust and generalizable browser world model, we design unified data format that balances structural fidelity, token efficiency, and cross-domain transferability. Our format choice is driven by three core principles: universal applicability, LLM compatibility, and multi-format robustness. 17 Table 12: The unified action space available to the agent. Actions are categorized by interaction type. Parameters include element IDs (bid), coordinates (x, y), textual input (text), and navigation deltas. Category Action Primitives click(bid, button, mods) fill(bid, text, auto) select option(bid, opts) hover(bid) Description Click specific DOM element identified by bid. Input text into focused field (supports autocomplete). Select single or multiple options from dropdown/combobox. Hover the cursor over specific element. Element Interactions Coordinate & Mouse Keyboard Browser & Nav. Meta & Control mouse move(x, y) mouse click(x, y, button) Click at specific coordinate (supports double click). mouse {down, up}(x, y) Move cursor to absolute screen coordinates. Hold or release mouse button (enables drag-and-drop). keyboard press(key) keyboard type(text) Press specific physical key (e.g., Enter, Tab). Type string of text sequentially. scroll(dx, dy) goto(url), go {back, fwd} tab {new, close, focus} Scroll the viewport horizontally or vertically. Navigate to URL or traverse history stack. Manage browser tabs (open, close, or switch focus). send msg to user(text) noop(wait), infeasible Output message to the user (e.g., for clarification). Wait for duration or declare the task impossible. Table 13: Action Distribution by Category Category Action Primitive Percentage Category Action Primitive Percentage Element Interactions Coordinate & Mouse Keyboard click fill select option hover Subtotal mouse move mouse click mouse down mouse up Subtotal keyboard press keyboard type Subtotal 77.29% 5.12% 0.96% 0.06% 83.43% 0.42% 0.35% 0.18% 0.18% 1.13% 0.55% 0.62% 1.17% Browser & Navigation Meta & Control scroll goto go back go fwd tab new tab close tab focus Subtotal send msg to user noop infeasible Subtotal 0.88% 10.06% 0.24% 0.15% 0.22% 0.19% 0.15% 11.89% 1.34% 0.74% 0.30% 2.38% Total (20 actions): 100.00% 18 A11y Tree as Primary Representation. We adopt the A11y Tree as our primary state representation for browser interactions. Unlike raw HTML, which contains rendering noise (CSS, scripts, layout metadata), the A11y Tree provides structured, hierarchical abstraction of interactable UI elements with high information density. This format has proven effective across diverse digital environments, including not only web tasks but also GUI automation on Android, macOS, and Linux systems (de Chezelles et al., 2025). Empirically, A11y Tree achieves decent token compression compared to raw HTML while preserving all action-critical semantics, making it the de facto standard for text-based web agent research (Zhou et al., 2023; Deng et al., 2023). We extract A11y Trees using the Playwright API from the BrowserGym framework (de Chezelles et al., 2025), which exposes browser accessibility layers in consistent format across Chromium, Firefox, and WebKit engines. Each node in the tree encodes its role (e.g., button, textbox), properties (e.g., focused, required), and unique identifier (bid) for action grounding. Representation Transformation Process The conversion pipeline employs two-stage parse-thengenerate architecture to transform web A11y Tree into multiple target representations. In the parsing stage, the AccessibilityTreeParser converts the indentation-based textual format into canonical nested dictionary structure by applying regular expressions to extract node attributes (role, name, ID, properties) and utilizing stack-based algorithm to reconstruct the hierarchical parent-child relationships from indentation levels. This intermediate representation serves as the single source of truth for all subsequent transformations. In the generation stage, format-specific generators (XMLGenerator, HTMLGenerator, PlaywrightGenerator, MarkdownGenerator) traverse the parsed tree structure and apply domain-specific mapping rulessuch as ARIA-to-HTML semantic mapping, XML name sanitization, or Playwright reference ID assignmentto produce target-format outputs. The entire process operates on JSONL conversation files by identifying A11y Tree segments delimited by markers (\"Initial Page State:\" and \"First Action:\"), transforming only the extracted tree content while preserving surrounding conversational context, thereby enabling efficient batch preprocessing of web interaction datasets for downstream tasks such as UI automation testing, agent training, and accessibility analysis."
        },
        {
            "title": "H URL Filtering with LLMs",
            "content": "To ensure high-quality and safe data sources, we apply LLM-based filtering to candidate URLs extracted from pre-training corpora. As shown in Figure 6, we evaluate each URL across four dimensions: accessibility (page reachability), content suitability (absence of unsafe content), interactivity (presence of actionable elements), and engineering quality (HTML structural soundness). An LLM judge assigns scores (01) for each dimension. Low-scoring URLs are filtered out, retaining 85.2% of the candidates that passed initial rule-based checks. Cross-Environment Generalization Data Since no standardized world model benchmarks exist for non-web environments, we construct training and test sets for four domains (API services, code, games, GUI) by collecting open-source agent trajectories and converting them into (st, at, st+1) transition tuples following WebWorlds data format. Dataset statistics are provided in Tables 14 and 15."
        },
        {
            "title": "J World Model Evaluation Taxonomy",
            "content": "Existing work on world models for web and GUI agents can be categorized based on their evaluation strategies: intrinsic evaluation approaches that explicitly measure world model quality, and extrinsic evaluation approaches that assess world models through downstream task performance. Intrinsic Evaluation. WebEvolver (Fang et al., 2025) evaluates world models along three dimensions: structural correctness, content similarity, and functional/semantic consistency between predicted and actual web states. Similarly, WMA (Chae et al., 2025) adopts an information coverage metric, measuring the overlap between predicted state change descriptions and ground truth using ROUGE and BERTScore. These approaches collect training data in the WebArena environment, with WebEvolver using MCP Playwright to gather A11y Tree pairs (A11yt, A11yt+1), while WMA employs GPT-4o to collect high-quality trajectories and uses the Hungarian algorithm for DOM diffing, subsequently converting diffs to natural language descriptions via LLM. ViMo (Anonymous, 2025b), focusing on mobile app GUIs, proposes more comprehensive evaluation framework with four metrics: visual similarity (sgc), instruction accuracy (sia), functional availability (sar), and user studies. The work leverages existing large-scale GUI interaction datasets such as AITW. Extrinsic Evaluation. WebDreamer (Gu et al., 2025) and WebSynthesis (Gao et al., 2025) evaluate 19 Figure 6: LLM-based URL Filtering Pipeline. We evaluate candidate URLs across four dimensionsaccessibility, content suitability, interactivity, and engineering qualityusing an LLM judge. The chart shows the distribution of scores and the filtering threshold (red dashed line), which retains only the top 32% of URLs for data collection. Table 14: Overview of the Training Set in Cross-Environment Data (training set). Category Rank Dataset Name Project Source Environment Type Samples A. Code & Development B. GUI & Desktop C. Game & Simulation D. API & Services 1 5 8 21 24 13 7 9 10 26 6 15 12 wm intercode sql.jsonl wm full sft.jsonl wm train-00005-of-00012.jsonl SWE-agent-trajectories wm train-00002-of-00012.jsonl SWE-agent-trajectories wm full sft.jsonl wm full sft.jsonl Neulab/agenttuning db Neulab/agenttuning os AgentBank/intercode sql code/IDE, API Neulab/swe-smith terminal/shell, code/IDE terminal/shell, code/IDE terminal/shell, code/IDE code/IDE, API terminal/shell wm agentnet win mac 18k.jsonl AgentNet GUI/desktop wm alfworld sft.jsonl wm sciworld sft.jsonl wm alfworld.jsonl wm sciworld sft.jsonl Agent-ETO Agent-ETO AgentBank/alfworld Agent-ETO game game, simulation game, simulation game, interactive sim wm train-00001-of-00003.jsonl Agent-Ark/Toucan wm toolbench react 10p.jsonl wm full sft.jsonl Agent-FLAN Neulab/agenttuning kg API, KB query API, terminal/shell API, task-based Total 14 Datasets 4,522 17,380 6,665 6,661 527 195 17,625 3,119 1,483 3,321 1, 4,281 2,288 305 69,855 Table 15: Overview of the Training Set in Cross-Environment Data (test set). Category Rank Dataset Name Project Source Environment Type Samples A. Code & Development B. GUI & Desktop C. Game & Simulation D. API & Services Unused 27 25 2 16 29 19 4 28 wm train-00001-of-00001.2.jsonl SWE-agent-trajectories wm mbpp before.jsonl AgentBank/mbpp before code/IDE terminal/shell, code wm agentnet ubuntu 5k.jsonl AgentNet GUI, application wm rearrange.jsonl wm alfworld sft.jsonl wm db.jsonl AgentBank/rearrange Agent-ETO game, GUI/desktop game AgentInstruct API, database wm full sft.jsonl wm train-00006-of-00001.2.jsonl SWE-agent-trajectories Neulab/openhands code/IDE, game... terminal/shell, code Total 6 Datasets (+2 Unused) 20 6,660 5,000 299 3,119 538 121 6,664 16,323 world models extrinsically through end-to-end task success rates. WebDreamer randomly explores real-world websites and uses vision-language models (VLMs) to synthesize descriptive labels for (screenshotbe ore, action, screenshota ter) triplets. WebSynthesis collects (A11yt1, Actiont, A11yt) triplets in WebArena through random exploration, integrating the world model into Monte Carlo Tree Search (MCTS) where model quality is reflected in final agent performance. While extrinsic evaluation provides practical insights into world model utility, it conflates world model quality with other agent components, making it difficult to isolate the specific contributions of world modeling."
        },
        {
            "title": "K Generation Length Analysis",
            "content": "To better understand how our two-stage training strategy affects model behavior, we analyze the distribution of output token lengths across different training phases. Figure 7 shows the comparison between the Real-World Transition Modeling baseline (Stage 1) and the Reasoning Activation phase (Stage 2) under varying data scales. We observe substantial shift in generation patterns between the two stages. The Real-World Transition Modeling stage (grey dashed line) produces considerably longer outputs, as the model attempts to capture comprehensive web state details from raw interaction data. Notably, after applying Reasoning Activation, the average output length decreases by approximately 49.4% despite the introduction of reasoning. This suggests that Stage 2 training does more than add reasoning tokensit fundamentally restructures the models prediction pattern. By training on high-quality distilled data, the world model shifts from verbose state reconstruction to concise state prediction, effectively filtering redundant information while preserving essential semantic changes. The curve stabilizes after approximately 1,000 samples, indicating that this behavioral shift is both sample-efficient and robust. Figure 7: Impact of Reasoning Activation on Output Token Length. The plot compares the average tokens of answer between the Real-World Transition Modeling baseline (grey dashed line) and the Reasoning Activation stage (blue solid line). The introduction of reasoning data leads to 49.4% reduction in output length, indicating shift from verbose raw state prediction to more concise and structured simulation pattern."
        },
        {
            "title": "L Multimodality Discussion",
            "content": "While visual perception is an emerging direction for web agents, WebWorld deliberately adopts textcentric representation (A11y Tree and HTML) to ensure precision and compatibility. This aligns with the prevailing paradigms in both standard benchmarks (e.g., WebArena, Mind2Web) and concurrent world model research, which predominantly rely on structural text representations as the ground truth for reasoning. Furthermore, incorporating visual simulation faces fundamental limitations in current generative capabilities: state-of-the-art image or video generation models often struggle with fine-grained text rendering, resulting in blurry interfaces where crucial textual details are unreadable or hallucinated. For agent training, the primary objective is to model the causal dynamics of interactionhow an action logically alters the environment staterather than achieving pixel-perfect rendering. The text-based world model efficiently captures these dynamics, avoiding the computational overhead and semantic noise associated with visual generation."
        },
        {
            "title": "M Ethical Considerations",
            "content": "We strictly adhere to data compliance standards and prioritize content safety. Our autonomous crawler respects the robots.txt protocol to ensure data is collected only from permitted sources. We utilize the FineWeb dataset, licensed under ODC-By v1.0, and the CCI 3.0 dataset, subject to its official usage agreement, in full accordance with their respective terms. To mitigate the risk of toxic content, we implemented rigorous filtering pipeline using LLM-generated bilingual blocklists (English and Chinese) covering sensitive categories, which were iteratively refined through human verification. Regarding privacy, while our data is derived exclusively from publicly accessible webpages, we did not apply additional automated PII redaction or utilize synthetic personas for form-filling actions; consequently, we acknowledge the potential presence of personal information in the raw text and advise against deploying the model in privacy-critical applications without further mitigation."
        },
        {
            "title": "N Prompt Templates",
            "content": "In this section, we provide the full prompt templates used in our pipeline. N.1 Core Model Prompts We present the prompts for the three core components of our system: the WebWorld model (Figure 8), the Actor agent (Figure 9), and the Value model for task evaluation (Figure 10). # System Instruction You are web world model. sequence of actions. Strictly maintain the original format. explanations, code, or truncation. will provide you with an initial page state and For each action, predict the resulting page state. Output only the full page state without # Step Prediction Template Continue the trajectory. after this action. {action} Action: Next Page State: Given the previous state, predict the next page state Figure 8: Template for the WebWorld. N.2 Data Synthesis Prompts We show the prompts used in our two-stage agent data synthesis pipeline: abstract goal generation from seed goals (Figure 11) and specific goal instantiation from exploration traces (Figure 12). N.3 Evaluation Prompts We provide the prompts for evaluating world model predictions on WebWorld-Bench: the Factuality Score metric (Figure 13) and the Web Turing Test (Figure 14). N.4 Data Collection Prompts We present the prompts for our Level 2 data collection strategies, including self-proposed task exploration (Figure 15), long-horizon dependency collection (Figure 16), composite action interaction (Figure 17), and curiosity-driven baseline exploration (Figure 18). 22 Your answer will be interpreted [bid] is the unique alpha-numeric identifier at the beginning of lines You are an agent trying to solve web task based on the content of the page and user instructions. You can interact with the page and explore, and send messages to the user. Each time you submit an action it will be sent to the browser and you will receive new page. # Instructions Review the current state of the page and all other information to find the best possible next action to accomplish your goal. and executed by program, make sure to follow the formatting instructions. ## Goal: {goal} # Observation of current step: Note: for each element in the A11y Tree. actions. tag is not present, the element is not visible on the page. {observation} # History of interaction with the task: {history} # Action space: Note: of 15 actions: Only single action can be provided at once. True) # Abstract Example <reason> Think step by step... <action> One single action to be executed. Always use bid to refer to elements in your If the \"visible\" This action set allows you to interact with your environment... You can only interact with visible elements. noop, click, fill, scroll, etc...] fill(b534, Montre, </reason> </action> Example: Note: [...List Figure 9: Prompt for the Web Agent. ## Goal You are judge evaluating web task completion. {goal} ## Initial Page State {initial obs} ## Action History {actions str} ## Current Page State {current obs} ## Instructions 1. Goal based on the action history. tags. [SUCCESS/FAILURE/ONGOING]\". Example Output: click action. SUCCESS Lets think step by step. 2. First, analyze step-by-step whether the Current Page State satisfies the Then, output the final determination strictly in the format: \"Status: You MUST enclose your reasoning in <think> <think> The user wanted to click the button. The current page shows success message. </think> Status: The history shows Figure 10: Prompt for the Value Model to evaluate task completion (inference-time lookahead search). will provide you with specific You are an expert Web Agent Strategist. \"Seed Goal\" and the \"Initial Page State\". Your task is to extract high-level FUNCTIONAL strategy. For example, If the seed goal is: You will need to generate the high-level functional strategy, like: Interact with the flight form by filling in valid but random city pairs for Origin and Destination, toggle the trip type parameters, and submit the form to verify search results functionality. Here is the information, # Seed Goal: {seed goal} # Initial Page State: {initial obs} Output ONLY the abstract logic pattern in 1-2 sentences. Book one-way flight from New York to London Figure 11: Generating abstract goal from seed goals (Agent Data Synthesis, Stage 1) 23 {initial obs} {action history} Thumbs down the top 5 posts ever in technology. You are inferring detailed users questions to form the web interactions. The questions are like: 1. How much time does it take from Pittsburgh to Philadelphia by car? # Trajectory Context: Initial: Actions: Final: # Special Cases: - If the trajectory is purely exploratory with no clear outcome \"NONE\" - If actions are repetitive without semantic progress \"NONE\" - If the final state is identical to the initial state \"NONE\" Output ONLY the detailed users question or \"NONE\" without any explanation: {final obs} ... 2. Figure 12: Instantiating specific goal from exploration traces (Agent Data Synthesis, Stage 2). Ignore minor Web Action Effect Evaluator Your goal is to judge if the predicted next observation exhibits Role: Task: the main and most direct expected effect of the given action, based on the current trajectory. Focus only on whether the core and intended causal change triggered by the action is clearly and correctly reflected. differences in content, formatting, or auxiliary UI elements that do not relate to the actions main effect. You are provided with the ground truth next observation as reference for what the correct next state should look like. # Input Data <current trajectory> {trajectory str} </current trajectory> <action> {action} </action> <predicted next observation> {predicted} </predicted next observation> <ground truth next observation> {ground truth} </ground truth next observation> # Evaluation Steps 1. 2. happen? 3. should be. 4. 5. # Scoring Rubric - 1.0: - 0.7: - 0.4: wrong. - 0.0: # Output Format Respond ONLY with single JSON object in this format: \"<your analysis>\", \"action effect accuracy score\": Main effect present and unambiguous, ignore small differences. Main effect mostly present, but some clear incompleteness. Action applied to the right kind of element, but the effect is largely Justify your answer briefly, referring to the main user-visible change. Assign score based on the rubric. Identify the action and its intended main effect on the page. Compare the prediction with the current trajectory: Reference the ground truth to better understand what the correct outcome Main effect not present. Did the main effect {\"reasoning\": <score>} Figure 13: Prompt for Factuality Score (WebWorld-Bench). Dont be afraid to choose complex observation if Web Turing Test Judge One of the following observations (A or B) is from real browser Role: Task: session, the other is generated by an AI. Based on the action taken on the current trajectory, you must decide which observation is more believable and realistic. # Evaluation Mindset - believable outcome should be logical and complete consequence of the action. - Real websites are complex. it seems more true to life. - Pay close attention to details. consistent? Are there any strange artifacts or nonsensical repetitions? # Input Data <current trajectory> {trajectory str} </current trajectory> <action> {action} </action> <observation A> {option A} </observation A> <observation B> {option B} </observation B> # Evaluation Steps 1. weaknesses? 2. 3. browser observation, and why. # Output Format Respond ONLY with single JSON object in this format: {\"reasoning\": \"<your analysis>\", \"choice\": \"<A or B>\"} Analyze B: Same as above for B. Compare & Decide: Clearly state which one is more likely to be the real Analyze A: Is it plausible outcome? What are its strengths and Does the content make sense? Is the layout Figure 14: Prompt for Web Turing Test (WebWorld-Bench). Plan & Act: Observe & Analyze: Formulate & State Goal: Based on the current page content, you should Carefully inspect the current pages A11y Tree to Goal-Driven Autonomous Web Explorer (Random Exploration Emphasis) You simulate real user. Role: Task: randomly and autonomously propose clear, concrete goal, then take sequence of actions to accomplish it. # Core Execution Loop 1. understand its structure, content, and interactive elements. Ask: What is this page about? What might real user want to do here? 2. specific, actionable user goal. 3. step should serve the goal you set. 4. re-observe the page, propose new goal, and continue. # Behavioral Rules & Safety Constraints (Must Follow) - Strictly Forbidden: payments). - Think Before You Act: the current goal. # Stopping Conditions Stop when you reach the step limit, or when all major site functionalities and content sections have been explored via concrete goals. Iterate: After completing goal, or if the goal cannot be completed, Any high-risk or privacy-sensitive operations (e.g., Based on your analysis, explicitly propose Choose the action that best advances your current goal. Every Always choose the action that maximizes progress toward Figure 15: Prompt for Level 2 Data Collection: Self-proposed Task. 25 Role: Task: that learns to predict changes: Web World Model Data Collector (Long-Term Dependency) Your only goal is to collect high-quality data to train web world model (current page, action) (next page) This models biggest weaknesses are context forgetting and loss of UI state. Your job is to actively create interaction sequences that expose these weaknesses. # Core Data Collection Heuristics 1. State-Building > Navigation: Prioritize actions that change the current page state (e.g., type, select, check) rather than actions that load brand-new page (e.g., clicking navigation links). Value judgment: than clicking three unrelated news titles. 2. Proactively design multi-step sequences where later outcomes strongly depend on earlier inputs. Actiont. Example: to cart. 3. When sequence leads to dead end (e.g., filters yield no results), do not give up. Logically backtrack by undoing your most recent action to generate valuable tuples like: The goal is for changes in Statet+3 to be traceable back to On an e-commerce site: select size select blue add Filling three-step form is worth orders of magnitude more This is far more valuable than three independent actions. Systematic Backtracking: Create Causal Chains: (State, Backtrack Action, Reverted State) # Exploration Motto Modify, build state, then backtrack. guaranteed to fail. Create data where memoryless model is Figure 16: Prompt for Level 2 Data Collection: Long-horizon Dependency. Advanced-Feature Web Explorer (Composite Interaction) You simulate an intentional user who deeply uses websites features Role: Task: by proposing and executing composite task that requires multiple interaction types (e.g., type, select, click), not just single click. # Core Execution Loop 1. components. Focus on advanced elements beyond clicks (e.g., input boxes, dropdowns, checkboxes) that enable search, filtering, sorting, customization, etc. 2. propose concrete goal that requires combination of interaction actions. Propose & State Composite Task (Most Important): Based on your analysis, Inspect the A11y Tree to understand all interactive Observe & Analyze: -- Avoid trivial tasks: e.g., click Contact Us. (Single-click tasks have low value.) -- Encourage composite tasks: e.g., type smartwatch in search, then filter Plan & Act: Break the composite task into steps and choose the best next Iterate: After finishing composite task (or if it becomes impossible), waterproof and black or on product page, set size to M, then add to cart. 3. action to advance it. 4. re-observe and propose new composite task. # Behavioral Rules & Safety Constraints (Must Follow) - Depth-First: quickly jumping to new pages. - Strictly Forbidden: high-risk privacy actions. - Think Before You Act: the current composite task. # Stopping Conditions Stop when you reach the step limit, or when all major feature combinations on the site have been explored via composite tasks. Payments or any real personal sensitive information / Prefer completing deep composite task on the current page over Always choose the action that most effectively advances Figure 17: Prompt for Level 2 Data Collection: Composite Action Interaction. 26 navigation bars, menus, tabs, Without performing destructive Curiosity-Driven Web Explorer (Task-Driven Baseline) Explore the website out of curiosity. Role: Task: actions, explore the sites structure and functionality randomly and as comprehensively as possible. # Requirements - Prioritize traversing global entry points: sections, sidebars, footers, etc. - Try expanding collapsible regions and using interactions like hover / more / ..., and open internal links. - When appropriate, use on-site search or category filters to explore different topics. - Avoid repeatedly clicking redundant or low-value areas; try to cover new functionality and pages. - Do not submit forms, post content, pay, delete, register, log in, or perform other privacy/security-sensitive actions. - Observe before acting at every step; choose actions that maximize newly gained information. # Stopping Conditions Stop when you reach the step limit or when there are no obvious new entry points/content left to explore. Figure 18: Prompt for Level 2 Data Collection: Curiosity Discovery."
        }
    ],
    "affiliations": [
        "Alibaba Group",
        "Zhejiang University"
    ]
}