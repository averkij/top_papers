{
    "paper_title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios",
    "authors": [
        "Yuanzhe Shen",
        "Zisu Huang",
        "Zhengyuan Wang",
        "Muzhao Tian",
        "Zhengkang Guo",
        "Chenyang Zhang",
        "Shuaiyu Zhou",
        "Zengjie Hu",
        "Dailin Li",
        "Jingwen Xu",
        "Kaimin Wang",
        "Wenhao Liu",
        "Tianlong Li",
        "Fengpeng Yue",
        "Feng Hong",
        "Cao Liu",
        "Ke Zeng"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \\textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\\% success on the easy split, with performance dropping below 10\\% on hard subsets. We further propose \\textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training."
        },
        {
            "title": "Start",
            "content": "TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Yuanzhe Shen * 1 2 Zisu Huang * 2 Zhengyuan Wang * 2 Muzhao Tian * 2 Zhengkang Guo 2 Chenyang Zhang 3 Shuaiyu Zhou 4 Zengjie Hu 4 Dailin Li 5 Jingwen Xu 2 Kaimin Wang 2 Wenhao Liu 6 Tianlong Li 1 Fengpeng Yue 1 Feng Hong 1 Cao Liu 1 Ke Zeng"
        },
        {
            "title": "Abstract",
            "content": "1. Introduction 6 2 0 2 2 ] . [ 1 5 7 6 1 0 . 2 0 6 2 : r As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce TRIP-Bench, long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requireIt ments, and supports automated evaluation. includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50% success on the easy split, with performance dropping below 10% on hard subsets. We further propose GTPO, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.532B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIPBench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training. *Equal contribution 1LongCat Interaction Team, Meituan, Shanghai, China 2School of Computer Science, Fudan University, Shanghai, China 3Wuhan University, Wuhan, China 4Peking University, Beijing, China 5Dalian University of Technology, Dalian, China 6Xiaohongshu Inc., Shanghai, China. Correspondence to: Feng Hong <hongfeng03@meituan.com>, Yuanzhe Shen <yzshen25@m.fudan.edu.cn>. Preprint. February 3, 2026. 1 In recent years, Large Language Models (LLMs) have advanced in reasoning, planning, and tool use (DeepSeek-AI et al., 2025; Bai et al., 2025; Zeng et al., 2025), accelerating the deployment of LLM-based agents in real applications (Hager et al., 2024; Cheng et al., 2025). As agents shift from answering questions to completing tasks, they must produce executable and revisable action sequences and sustain progress toward long-horizon goalsraising requirements for reasoning depth, planning quality, and crossturn decision consistency. Real deployments further impose predefined rules, workflow and compliance constraints (Qi et al., 2025), while user instructions and preferences evolve through interaction and are rarely fully specified upfront. Consequently, agents must align local decisions with global constraints and remain consistent and controllable throughout multi-turn, dynamic processes. These realities make multi-turn task completion central dimension of agent evaluation, motivating benchmarks beyond static singleturn settings toward interactive, sequential decision-making paradigms (Mohammadi et al., 2025). Based on these observations, we argue that comprehensive agent benchmark should reflect real deployments along three dimensions: task complexity (long-horizon, multi-step objectives), tool complexity (reasonable tool interfaces and coordinated tool use), and interaction complexity (diverse user behaviors and behavioral attributes)). Accordingly, evaluation should emphasize two central capabilities: (1) robust multi-turn instruction following with preference tracking under global constraints, and (2) long-horizon planning and reasoning with effective tool orchestration. However, existing benchmarks still fall short. First, many focus on single-turn tasks (Li et al., 2025; Luo et al., 2025), or add multi-turn interaction without systematically modeling complex rule constraints (systemor user-level) that are essential in deployment (Liu et al., 2025b). Second, even in interaction-oriented benchmarks such as τ 2-Bench (Barres et al., 2025), turn-level queries are often simple and solvable with only few tool calls (often < 3), yielding shallow reasoning and short execution chains that underTRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Table 1. Comparison of representative user interaction benchmarks and travel planning benchmarks. The table indicates whether each trait is fully addressed (), partially addressed (), or not addressed (). Detailed explanations for each trait are provided in Appendix A. Benchmark Instruction Following Planning & Reasoning Task Complexity Tool Complexity Interaction Complexity Scalable TravelPlanner (Xie et al., 2024) TripTailor (Wang et al., 2025) LLMs Get Lost (Laban et al., 2025) UserBench (Qian et al., 2025a) τ -Bench (Yao et al., 2024) τ 2-Bench (Barres et al., 2025) COMPASS (Qin et al., 2025) VitaBench (He et al., 2025) Constraint Adherence Preference Alignment Information Integration Goal Management TRIP-Bench(ours) Max Tool Calls & Avg Turns [15,15] [5,5] [0,5] [1,20] [1,40] [1,60] [15,50] [5,75] [50,150] Appropriateness N/A InterDependency N/A Behavior Attributes Behavioral Diversity Trainable represent long-horizon planning, iterative refinement, and error correction. More importantly, benchmarks such as VitaBench (He et al., 2025) and COMPASS (Qin et al., 2025) often present instructions and context in segmented fragments. Even when intent ambiguity is introduced (e.g., intent-obfuscating rewrites in UserBench (Qian et al., 2025a)), prolonged interaction behaviorssuch as revisions, rollbacks, and version controlremain under-modeled, limiting coverage of complex and dynamic real-world interaction patterns. To address these limitations, we propose TRIP-Bench, real-world benchmark based on travel planning that systematically evaluates agent capabilities along four dimensions: long-horizon Tasks, complex Rules, diverse multiturn Interactions, and reasoning-driven Planning. TRIP-Bench is large-scale travel-planning benchmark built on expanded and cleaned TripTailor data (Wang et al., 2025). It provides 18 tools and covers nearly 40 travel-need categories with 80+ natural-language formulations, enabling scalable multi-turn evaluation and training under complex constraints. Beyond simple instruction sharding (Laban et al., 2025), TRIP-Bench models nine categories of user behaviors and supports difficulty-controlled splits. The hard split includes four challenging interaction subsetsLIT, FIT, AIS, and PMRcapturing long dialogs, feasibility transitions, ambiguous intent, style shifts, and version control. In the hardest cases, dialogs can reach 15 turns with over 150 tool calls and total context beyond 200k tokens, making TRIP-Bench rigorous testbed for long-horizon planning, reasoning, and interaction robustness. Experiments show that most models score below 10% in strict mode, and even in loose mode, the best-performing modelGPT5.2reaches only 45%, posing substantial challenge. Beyond benchmark construction, we further propose GTPO (Group Relative Turn-level Policy Optimization), an online multi-turn reinforcement learning method to improve longhorizon interaction and reasoning. GTPO includes: (1) turn-level reward normalization, (2) global-instruction normalization, and (3) turn-level reward differencing, aiming to stabilize long-horizon decisions under dynamic interactions. Results on TRIP-Bench shows that GTPO-trained Qwen2.5-32B-Instruct outperforms the SFT model by over 10 pp under the loose setting and over 5 pp under the strict setting, and exceeds the base model by over 20 pp under the loose setting. Overall, our main contributions are as follows: We build large-scale, tool-augmented simulation environment with modular data generation and validation, enabling scalable benchmarking and multi-turn training/evaluation under complex constraints and dynamic user behaviors. We conduct extensive experiments and in-depth analyses to systematically uncover the limitations of existing models under long-horizon reasoning, multi-turn diverse user behaviors, and global constraint adherence. We propose GTPO, an online multi-turn RL method that improves stable adherence to global rules and adaptation to dynamic preferences. After training with GTPO, Qwen2.532B-Instruct outperforms Gemini-3-Pro on TRIP-Bench. 2. Related Work Agent-user interaction benchmarks. Agent benchmarks have evolved from early single-turn, single-step tool-use settings (Huang et al., 2023; Qin et al., 2023) to more challenging single-turn, multi-step benchmarks such as TravelPlanner (Xie et al., 2024) and MCP Universe (Luo et al., 2025). Multi-turn interactive benchmarks (e.g., ToolTalk (Farn & Shin, 2023) and BFCL (Patil et al., 2025)) further support conversational tool execution, but their reliance on predefined dialogue trajectories limits agent autonomy and behavioral diversity. UserBench (Qian et al., 2025a) introduces intention ambiguity yet focuses on relatively simple tasks. Broader frameworks (e.g., τ 2-Bench) evaluate instruction-following under verbose policy constraints in online customer-service environments. Recent efforts such as VitaBench (He et al., 2025) and COMPASS (Qin et al., 2025) enhance specific aspects, including tool diversity, dynamic interactions, and longer horizons. Still, no existing TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Figure 1. Overview of TRIP-Bench. Left: data construction via rubric-to-constraint generation, progressive modification-chain synthesis, and complexity-conditioned task curation. Right: long-horizon evaluation pipeline where travel agent iteratively plans with unified suite of tools and is assessed by rule-based and turn-level metrics under diverse user-simulator interactions. benchmark provides unified evaluation that simultaneously stresses complex instruction-following, long-horizon reasoning, and diverse useragent interaction behaviors. TRIPbench addresses this gap by introducing long-horizon tasks with complex rules and rich multi-turn interactions requiring spatiotemporal planning and reasoning. Multi-turn Reinforcement Learning. Tool use is increasingly studied through reinforcement learning with outcomedriven rewards, enabling agents to autonomously explore and improve tool-calling strategies in interactive environments (Jin et al., 2025; Singh et al., 2025). However, most work targets single-turn multi-step tasks, treating the user query as fixed context and optimizing primarily for single response (Xue et al., 2025; Xi et al., 2025). For multi-turn dialogue, common simplification concatenates prior turns into long context, ignoring the distributional shift in conversation histories as the policy changes. REFUEL (Gao et al., 2024) shows this induces covariate shift: training uses static offline histories, whereas deployment observes histories generated by the evolving policy, with mismatch compounding over turns. Methods such as MUA-RL (Zhao et al., 2025) and UserRL (Qian et al., 2025b) mitigate this by integrating dynamic user simulation into the RL loop to optimize for genuine multi-turn interactions. Nonetheless, these approaches largely focus on direct userLLM dialogue rather than long-chain tool invocation, leaving multi-turn tool use in dynamic settings an open challenge. 3. TRIP-Bench 3.1. Environment and Tools We extend the Triptailor (Wang et al., 2025) dataset by enriching POI attributes (e.g., hotel room types, restaurant set menus) and fixing formatting, logic, and consistency issues to support reliable task generation and evaluation. The final dataset covers 40 cities with 6k+ attractions, 80k+ hotels, 400k+ restaurants, and 1M+ distinct products. We further build unified tool interface and implement 18 tools for transportation, attractions, restaurants, hotels, and general utilities. Tools provide field-based filtering, sorting, and result-size control, enabling systematic evaluation of tool invocation, constraint understanding, and compositional decision-making. See Appendix B.1 for details. 3.2. Task Synthesis Meta-information Synthesis. We sample all twoand three-city combinations among the 40 cities and generate candidate itineraries by assigning distance-based stays (27 days) and sampling departure dates and group sizes. Transportation tools are used to filter out infeasible candidates. For three-city cases, we retain only itineraries where either two cities are within 500 km or the three cities are roughly collinear, matching typical travel routes. The resulting seeds include 6k two-city and 4k three-city itineraries, which define the itinerary meta-information. 3 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Rubric and Constraint Construction. We collect approximately 40 common requirement categories from real-world travel planning scenarios and curate over 80 diverse natural language expressions. For each expression e, we define two paired functions: the generator G(e) (i.e., generate), which produces the fine-grained selection range and the corresponding feasible ID set ( Figure 1, left (1)), and the validator (e, i) (i.e., validate), which checks whether given single ID satisfies the expression. The complete rubric, detailed explanations, and additional examples are provided in Appendix B.2. Modification Chain Construction. As shown in Figure 1, left (2), we provide meta-information and rubric-specific candidate set, and prompt the model to generate modification chain of up to three steps that becomes progressively more restrictive, mirroring iterative user refinement. To reduce redundancycases where earlier constraints already entail later oneswe use two strategies: (1) trajectory-based trimming, which samples trajectories and checks whether earlier constraints satisfy later ones, discarding the prefix of the chain and retaining only its suffix; and (2) rubriclevel adjustment, which shortens the target chain length for rubrics prone to redundancy. This increases the share of chains in which each new constraint induces substantive change, while preserving some redundancy for realism. Task Generation. As shown in Figure 1, left (3), we first partition tasks into three difficulty tiers (easy, mid, hard) based on trip length (days), number of cities, number of constraints, and the difficulty of simulated user behaviors. Detailed criteria are given in Appendix B.3. We then sample rubrics along four dimensionstransportation, attractions, restaurants, and hotelstargeting an approximately uniform distribution over rubric counts. For each sampled rubric, we set the number of modification steps to match the desired modification-chain length. Given set of constraint expressions E, we derive an initially filtered candidate set C0 = (cid:84) eE Fe, where (Re, Fe) = G(e). Because subset/- containment constraints (e.g., must include one or more restaurants of certain types) may not fully filter candidates or certify solvability, we further verify feasibility by defining = {i C0 : E, (e, i) = 1}. Finally, we require (410) the trip length (days) to ensure sufficient flexibility for itinerary construction. This produces base task set spanning all difficulty levels. Building on the hard subset, we combine user behaviors to create four more challenging evaluation sets: LIT (Long Interaction Task): LIT increases dialogue turns by using fewer initial constraints and smaller per-turn updates in the user simulator. FIT (FeasibleInfeasible Transition): FIT selects chains that are infeasible at the current step but become feasible after rolling back one step (equivalent to deletion when the chain length is 1). It then composes 24 infeasible requirements (thus requiring 24 rollbacks) and dynamically injects rollback instructions during executionwhen the agent declares infeasibility, at simulator-chosen moments, or at the endso that the final requirements are feasible. AIS (Ambiguous Intent Shifts): AIS introduces ambiguous constraints throughout the dialogue and reveals explicit preferences/corrections only when the model errs or proactively asks clarifying questions, using five interaction styles to better capture user interaction patterns. PMR (Plan Merge Redirect): PMR constructs two similar itineraries that share 69 modification chains but differ elsewhere, and inserts trigger nodes that prompt the simulator to switch between itineraries, optionally roll back after several turns, or merge the two plans. 3.3. Quality Control Although each component in our pipeline is solvable on its own, combining them can produce unrealistic cases (e.g., preferencebudget mismatches). We address this with prompt-based model scoring plus manual review. Because travel plans have spatiotemporal dependencieslocal feasibility doesnt ensure global feasibilitywe sample full plans, evaluate them, and manually check whether flagged issues are repairable. This two-stage validation keeps tasks practical and globally feasible. 3.4. User Simulation Unlike VitaBench (He et al., 2025) and UserBench (Qian et al., 2025a), which provide full instruction block and let the model respond freely, or COMPASS (Qin et al., 2025), which relies on fully predefined scripts where the model only renders dialogue style, we introduce user dialogue graph and maintain per-turn list of active user preferences. At each turn, we dynamically update the user simulator prompt and vary behavioral diversity based on the difficulty level. We constrain the update pipeline by ensuring later changes are not visible to earlier steps, and by switching preferences only at small set of key nodes. This balances autonomy, diversity, and controllability in user simulation. 3.5. Evaluation metrics We define 12 general constraints for the task: 4 for basic feasibility and 8 for planning soundness (see Appendix B.4). As user queries contain varying numbers of user constraints, we report two aggregate metrics: OverallStrict = I(Ffeas = 0 Fsound = 0 Fuser = 0) and OverallLoose = I(Ffeas = 0 Fsound 2 Fuser 1), where the loose criterion keeps feasibility strict while allowing up to two soundness violations and one user-constraint violation; Ffeas, Fsound, and Fuser denote the numbers of violated feasibility, 4 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Figure 2. Overview of our training pipeline. Left: 120k trajectories are sampled from synthesized prompts, repaired with three rounds of error feedback, and filtered to obtain high-quality rollouts for SFT. Right: GTPO optimizes on groups of multi-turn rollouts by (i) global instruction-wise normalization, (ii) turn-wise reward differencing, and (iii) per-turn reward normalization. soundness, and user constraints, respectively. 4. Method 4.1. Data Construction SFT. We synthesize 120k samples for SFT sampling using DeepSeek-v3.2 (no-think). Due to the task difficulty, only 500 fully correct trajectories are obtained. Notably, many incorrect trajectories still exhibit reasonable tool use and coherent reasoning. We therefore fix the tools and outputs and provide only error feedback for three rounds of repair, producing 9k trajectories that pass evaluation (Figure 2, left). To mitigate potential hacking risks, we further keep only trajectories with full reasoning and planning scores, yielding 3k trajectories, which are combined with Toucan (Xu et al., 2025) data for SFT cold-start training. RL. We sample once over the same 120k inputs using the SFT-trained model and retain trajectories that satisfy relaxed criterion, Ffeas = 0 (Fsound + Fcons 5), yielding 7,040 samples for RL training. 4.2. GTPO: Group Turn-level Preference Optimization 4.2.1. PRELIMINARY Given dialogue context (prompt) x, we sample group of multi-turn rollouts from the current policy πθ: τ (k) = {(u1, a(k) 1 ), . . . , (uTk , a(k) Tk )}, = 1, . . . , K, (1) 5 where ut and a(k) at turn t, and Tk is the number of turns in rollout k. are the user input and assistant response Raw Reward. At turn t, each constraint It yields binary score c(k) t,i {0, 1}, and basic feasibility is hard gate I(k,t) feas = 0). The (pre-GTPO) turn reward is feas = I(F (k,t) t,raw = I(k,t) r(k) feas 1 It (cid:88) iIt c(k) t,i . (2) 4.2.2. KEY COMPONENTS OF GTPO Global Instruction Normalization. For each constraint i, let Ti be the turns where applies. Within each rollout k, we apply z-score normalization over the sequence {c(k) t,i }tTi: µ(k) = 1 Ti (cid:88) tTi t,i , σ(k) c(k) = (cid:115) 1 Ti (cid:88) (cid:16) t,i µ(k) c(k) (cid:17)2 , tTi (3) t,i µ(k) c(k) σ(k) + ϵ The globally normalized turn reward is then aggregated as: ˆc(k) t,i = Ti. (4) , = I(k,t) r(k) feas 1 It (cid:88) iIt ˆc(k) t,i . (5) Turn-wise Reward Differencing. As later turns are strongly influenced by earlier turns, slightly worse turn may still receive higher reward due to inherited structure. To emphasize relative improvement, we apply turn-wise TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Table 2. Performance comparison of different models under loose and strict evaluation across difficulty levels. Models Easy Mid Hard LIT Hard FIT Hard AIS Hard PMR Overall loose strict loose strict loose strict loose strict loose strict loose strict loose strict Non-thinking Models Kimi-K2-0905-Preview Qwen3-235B-A22B-Instruct-2507 GPT-5.2 (w/o thinking) GLM-4.7 (w/o thinking) Claude-Sonnet-4.5 (w/o thinking) Gemini-3-Flash (w/o thinking) Gemini-3-Pro (w/o thinking) DeepSeek-V3.2 (w/o thinking) 13.0 0.0 0.0 16.0 2.0 5.0 24.0 2.0 14.0 20.0 34.0 0.0 18.0 7.0 36.0 36.0 22.0 11.0 44.0 12.0 9.0 20.0 5.0 39. 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 0.0 0.0 10.0 6.0 10.0 8.0 12.0 16.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 0.0 2.0 6.0 0.0 6.0 6.0 4.0 8.0 Thinking Models Qwen3-235B-A22B-Thinking-2507 Kimi-K2-Thinking Gemini-3-Pro (w/ thinking) GLM-4.7 (w/ thinking) Gemini-3-Flash (w/ thinking) Claude-Sonnet-4.5 (w/ thinking) DeepSeek-V3.2 (w/ thinking) GPT-5.2 (w/ thinking) 0.0 0.0 0.0 0.0 0.0 0.0 4.0 35.0 8.0 5.0 0.0 0.0 42.0 11.0 16.0 0.0 0.0 38.0 16.0 29.0 0.0 0.0 44.0 25.0 25.0 10.0 6.0 58.0 27.0 31.0 71.0 31.0 41.0 14.0 9.0 66.0 49.0 55.0 13.0 44.0 14.0 18.0 0.0 0.0 16.0 10.0 10.0 28.0 36.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 8.0 0.0 10.0 16.0 12.0 2. 0.0 0.0 18.0 0.0 26.0 22.0 26.0 20.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6.0 0.0 4.0 14.0 10.0 4.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.3 5.8 13.3 14.8 17.3 17.3 18.0 18. 0.0 0.5 0.5 0.0 1.8 5.5 3.0 2.3 0.0 0.0 0.0 0.0 0.0 2.0 2.0 0.0 0.0 0.0 2.3 10.8 0.0 2.8 20.0 10.0 4.0 20.3 18.0 6.3 23.3 12.0 32.0 8.5 18.0 20.0 40.0 10.5 36.0 10.0 45.0 18.5 reward differencing d(k) (cid:40) , which is defined as: 4.2.3. FINAL OBJECTIVE d(k) = r(k) 1 , r(k) r(k) t1, = 1, 2. (6) We optimize the policy parameters θ by maximizing the following GTPO objective: If turn (t1) is infeasible, we subtract rmax group instead of r(k) t1, where t1 within the same rmax t1 = max kKt1 r(k) t1. (7) Thus, for 2, 1 + ϵ(cid:1) A(k) (cid:17) = r(k) d(k) I(k,t1) feas (cid:16) r(k) t1 1 I(k,t1) feas (cid:17) rmax t1 . (8) JGTPO(θ) = x,{τ (k)}K k=1 (cid:34) 1 (cid:88) k=1 1 Tk Tk(cid:88) t=1 1 Lk,t Lk,t (cid:88) j=1 m(k) t,j (cid:16) (cid:16) min t,j (θ) A(k) ρ(k) , clip(cid:0)ρ(k) t,j (θ), 1 ϵ, (cid:35) (cid:1)(cid:17) β DKL (cid:0)πθπref ; h(k) t,j . (11) Turn-level Reward Normalization. For each turn t, let Kt be the set of rollouts that complete and are evaluable at turn t. To stabilize per-turn normalization statistics, we only normalize turns with sufficient samples, requiring Kt K/2, and mask turns that exceed the context budget in the loss. We normalize {d(k) }kKt across the group via z-score: µt = 1 Kt (cid:88) d(k) , kKt σt = (cid:115) 1 Kt (cid:88) (cid:16) d(k) µt (cid:17)2 . kKt (9) The turn-level advantage is then A(k) = d(k) µt σt + ϵ , Kt. (10) Importantly, A(k) tage and advantages do not propagate across turns. is turn-local: each turn has its own advant t,j {0, 1} is the token-level mask, A(k) where m(k) is the turn-level advantage defined in Eq. (10), and ρ(k) t,j (θ) = πθ(a(k) t,j ) is the PPO import,j tance ratio, with clip(, 1 ϵ, 1 + ϵ) using threshold ϵ. DKL(πθπref ; h(k) t,j ) denotes the per-token KL divergence to the reference policy πref , weighted by β. t,j )/πθold(a(k) h(k) h(k) t,j 5. Experiments 5.1. Settings Models. We evaluate collection of recent large language models, including Kimi-K2 (Bai et al., 2025), Qwen3-235BA22B (Yang et al., 2025), GLM-4.7, DeepSeek-V3.2 (Liu et al., 2025a), Gemini-3 (Flash and Pro), GPT-5.2, and Claude-Sonnet-4.5. For models that support different rea6 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Figure 3. Left: Performance vs resource use. Three scatter plots: performance vs #turns (left), output tokens per 10k (middle), and avg reasoning cost (USD, log; right). Models: thinking vs non-thinking; openvs closed-source by marker shape; dashed lines are trend fits. soning behaviors, we conduct evaluations under two configurations: with explicit reasoning disabled and with the default reasoning strength enabled. Implementation Details. During evaluation, all models use their default temperature settings; when unspecified, the temperature is set to 0.7. We employ DeepSeek-V3.2 as the user simulator with temperature of 0.7. Training is conducted on Qwen2.5-14B-Instruct and Qwen2.5-32BInstruct. For the trained models, evaluation is performed only on the easy and mid subsets, as the hard subset often requires context lengths exceeding 128k tokens, which is beyond the maximum context length supported by the models. Additional training details are provided in Appendix D.1. 5.2. Main Results TRIP-bench poses significant challenge. As shown in Table 2, TRIP-bench is highly challenging under both strict and loose evaluation. Under the strict metric, performance is extremely poor even on the Easy subset, with many models near zero accuracy and the best score reaching only 18.5. This difficulty persists under relaxed evaluation, where the highest loose score is still limited to 45, indicating that errors arise not only from strict verification but from fundamental reasoning limitations. These results highlight two key challenges. First, TRIP-bench requires long-horizon, multiconstraint reasoning, where satisfying individual constraints is insufficient. Second, performance degrades sharply on more difficult behavioral subsets: FIT remains unsolved under strict evaluation, and PMR shows only marginal improvements while consistently lagging behind LIT. Overall, the results reveal substantial limitations of current models in handling complex and behaviorally demanding scenarios, even under relaxed criteria. Thinking dramatically improves performance under both loose and strict evaluation, but remains insufficient for fully satisfying Hard cases. Enabling thinking yields consistent and substantial gains across easier splits, improving both accuracy and robustness. For instance, on Easy-strict, performance rises from 5.0 to 31.0an absolute gain of 26 percentage pointsand the Overall-strict score increases from 2.3 to 10.5. Similar improvements are also observed on the Hard sets under loose evaluation (often by more than 15 points), suggesting that reasoning augmentation helps models reach partially correct or near-complete solutions. However, Hard-strict performance remains uniformly low across models, indicating that current thinking mechanisms still fall short of producing comprehensive, fully correct, and verifiable outcomes when faced with the most challenging user behaviors and strict checking. GTPO better aligns training with dynamic user interaction and multi-constraint reasoning, with gains that scale to stronger models. As shown in Table 3, GTPO consistently outperforms SFT and GRPO under both loose and strict evaluation, yielding more stable and balanced improvements. When scaled to Qwen2.5-32B-Instruct, GTPO substantially strengthens performance on harder settings, achieving 40 on Mid-loose and 21 on Easy-strict, and notably surpassing Gemini-3 Pro under the same evaluation. These results indicate that GTPO provides more effective training signal for long-horizon, multi-constraint reasoning under dynamic user interaction. Our training curves are shown in Figure 6. 6. In-Depth Analysis Model performance improvements increasingly depend on deeper reasoning and longer token generation, but these gains incur substantial marginal costs. As illustrated in Fig. 3, performance scales approximately linearly with the number of output tokens. However, due to the additional input-token overhead introduced by multi-step reasoning, the relationship between performance gains and inference cost is closer to logarithmic. Notably, DeepSeekV3.2 Thinking demonstrates exceptional cost-effectiveness: under the Loose evaluation regime, it achieves performance comparable to GPT-5.2 at only about 10% of the cost (approximately $0.25). Although clear gap remains under the stricter Strict metric, this result indicates that for errortolerant applications, DeepSeek-V3.2 offers highly economical alternative without pursuing peak performance at all costs. Finally, aside from the limited catch-up trend exhibited by DeepSeek-V3.2, pronounced generational gap persists between current open-source models and leading 7 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Figure 4. Left: Breakdown of the top-15 highest-error constraints by domain and constraint type (Global vs. Pointwise) in the multi-turn setting. Right: DeepSeek-V3.2-Thinking score rates per rubric under single-turn and multi-turn (regular vs. no-issue) settings. Table 3. Performance on Easy/Mid. ST denotes single-turn training; MT denotes multi-turn training where only the final-turn reward is used. In GTPO, we ablate three key components: Global Instruction Normalization (GIN), Turn-wise Reward Differencing (TRD), and Turn-level Reward Normalization (TRN) (see 4.2.2). GTPO (w/o X) removes component(s) from the full setup. Models Easy Mid loose strict loose strict Base: Qwen2.5-14B-Instruct Base +SFT +GRPO (ST) +GRPO (MT) +GTPO (w/o GIN, TRD) +GTPO (w/o TRD) +GTPO (full) 0 16 29 30 32 34 35 0 4 0 4 12 10 13 Base: Qwen2.5-32B-Instruct Base +SFT +GTPO (full) 0 32 0 3 21 0 8 12 16 16 20 18 0 5 40 0 0 0 0 0 0 0 0 0 5 closed-source systems, with open-source models maintaining significantly lower overall performance baseline. Multi-turn interactions often degrade on complex tasks as global consistency gradually erodes, whereas singleturn interactions more reliably satisfy strict global constraints in single pass. As shown in Fig. 4, under strong global constraintssuch as validating POI opening hours or optimizing attraction sequencessingle-turn accuracy exceeds multi-turn by roughly 10 percentage points on average. Together with Table 5, this gap widens substantially in the Hard subset: on the two most challenging evaluation sets, multi-turn performance under the Loose metric falls more than 20 percentage points behind single-turn. These results suggest that complex user behaviors coupled with strong global constraints make multi-turn systems more prone to global mismatch. In contrast, multi-turn interactions remain competitive on local constraints (e.g., hotel cancellation policies or specific cuisine requirements), which change infrequently and can be corrected via feedback. By incrementally incorporating constraints and rectifying errors, multi-turn refinement enables progressive convergence, outperforming single-turn on localized, point-specific tasks. Ablation Study of GTPO. Table 3 reveals the impact of each GTPO component. While Turn-level Reward Normalization (TRN) stabilizes training and improve performance, the lack of global constraint balancing and turn-by-turn objectives limits its performance. Adding Global Instruction Normalization (GIN) improves average rewards by calibrating constraint satisfaction across dialogue history, though the reward inheritance issue continues to hinder the complete pass rate (strict metric). Finally, Turn Reward Differencing (TRD) yields the best results; by using the previous turns reward as baseline, it prioritizes incremental gains, substantially boosting the complete pass rate while maintaining high overall rewards. Reliability of the user simulator. We conducted manual evaluation of the user simulator. We randomly sampled 20 trajectories (104 turns in total) and verified whether the issued instruction ID was consistently reflected in subsequent queries, achieving 98% reliability. In addition, we sampled 10 trajectories in AIS (62 turns total) and rated the simulator on whether the intended ambiguity was properly captured and whether the style simulation was faithful, obtaining an average score of 4.7/5. See Appendix for details. Exploration vs. reliability. As shown in Figure 5, pass@k increases with more samples, indicating non-trivial exploratory ability, but pass@1 remains low and strict evaluaTRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios tion is substantially worse, highlighting limited single-try reliability under hard constraints. Meanwhile, avgk stays stable across k, suggesting the stability of our bench. 7. Conclusion We present TRIP-Bench, long-horizon interactive benchmark for realistic travel planning. It tests global constraint adherence, long-term planning, multi-tool use, and dynamic user behavior. Results show even strong models struggleespecially on harder interactionshighlighting gaps in cross-turn consistency and meeting global constraints. We also propose GTPO, an online multi-turn RL method with global instruction normalization and turn-level reward shaping, delivering consistent gains over strong baselines."
        },
        {
            "title": "Impact Statement",
            "content": "TRIP-Bench is introduced to advance research on reliable long-horizon interactive agents, especially for settings that require maintaining global constraints, coordinating multitool execution, and adapting to evolving user preferences over many turns. Parts of the environment are constructed from publicly available data (e.g., travel-related information), and any included content does not represent the authors viewpoints. To foster reproducible progress, we plan to release the benchmark, evaluation scripts, and supporting resources, and we will also release our trained models to facilitate follow-up research in training and evaluation."
        },
        {
            "title": "References",
            "content": "Bai, Y., Bao, Y., Chen, G., Chen, J., Chen, N., Chen, R., Chen, Y., Chen, Y., Chen, Y., et al. Kimi k2: Open agentic intelligence. CoRR, abs/2507.20534, 2025. Barres, V., Dong, H., Ray, S., Si, X., and Narasimhan, K. τ 2bench: Evaluating conversational agents in dual-control environment. CoRR, abs/2506.07982, 2025. Cheng, X., Zeng, K., Cao, Z., Dai, L., Gao, W., Han, F., Jian, A., Hong, F., Hu, W., Huang, Z., et al. Higher satisfaction, lower cost: technical report on how llms revolutionize meituans intelligent interaction systems. arXiv preprint arXiv:2510.13291, 2025. DeepSeek-AI, Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R., Zhu, Q., Ma, S., et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. CoRR, abs/2501.12948, 2025. Farn, N. and Shin, R. Tooltalk: Evaluating tool-usage in conversational setting. arXiv preprint arXiv:2311.10775, 2023. Gao, Z., Zhan, W., Chang, J. D., Swamy, G., Brantley, K., Lee, J. D., and Sun, W. Regressing the relative future: Efficient policy optimization for multi-turn rlhf. arXiv preprint arXiv:2410.04612, 2024. Hager, P., Jungmann, F., Holland, R., Bhagat, K., Hubrecht, I., Knauer, M., Vielhauer, J., Makowski, M., Braren, R., Kaissis, G., et al. Evaluation and mitigation of the limitations of large language models in clinical decisionmaking. Nature medicine, 30(9):26132622, 2024. He, W., Sun, Y., Hao, H., Hao, X., Xia, Z., Gu, Q., Han, C., Zhao, D., Su, H., Zhang, K., et al. Vitabench: Benchmarking llm agents with versatile interactive tasks in realworld applications. arXiv preprint arXiv:2509.26490, 2025. Huang, Y., Shi, J., Li, Y., Fan, C., Wu, S., Zhang, Q., Liu, Y., Zhou, P., Wan, Y., Gong, N. Z., et al. Metatool benchmark for large language models: Deciding whether to use tools and which to use. arXiv preprint arXiv:2310.03128, 2023. Jin, B., Zeng, H., Yue, Z., Yoon, J., Arik, S., Wang, D., Zamani, H., and Han, J. Search-r1: Training llms to reason and leverage search engines with reinforcement learning. arXiv preprint arXiv:2503.09516, 2025. Laban, P., Hayashi, H., Zhou, Y., and Neville, J. Llms arXiv preprint get lost in multi-turn conversation. arXiv:2505.06120, 2025. Li, J., Zhao, W., Zhao, J., Zeng, W., Wu, H., Wang, X., Ge, R., Cao, Y., Huang, Y., Liu, W., et al. The tool decathlon: Benchmarking language agents for diverse, realistic, and long-horizon task execution. arXiv preprint arXiv:2510.25726, 2025. Liu, A., Mei, A., Lin, B., Xue, B., Wang, B., Xu, B., Wu, B., Zhang, B., Lin, C., Dong, C., et al. Deepseek-v3. 2: Pushing the frontier of open large language models. arXiv preprint arXiv:2512.02556, 2025a. Liu, W., Guo, Z., Xie, M., Xu, J., Huang, Z., Tian, M., Xu, J., Wu, M., Wang, X., Lv, C., et al. Recast: Strengthening llms complex instruction following with constraintverifiable data. arXiv preprint arXiv:2505.19030, 2025b. Luo, Z., Shen, Z., Yang, W., Zhao, Z., Jwalapuram, P., Saha, A., Sahoo, D., Savarese, S., Xiong, C., and Li, J. Mcp-universe: Benchmarking large language models with real-world model context protocol servers. arXiv preprint arXiv:2508.14704, 2025. Mohammadi, M., Li, Y., Lo, J., and Yip, W. Evaluation and benchmarking of llm agents: survey. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2, pp. 61296139, 2025. TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Xue, Z., Zheng, L., Liu, Q., Li, Y., Zheng, X., Ma, Z., and An, B. Simpletir: End-to-end reinforcement learning for multi-turn tool-integrated reasoning. arXiv preprint arXiv:2509.02479, 2025. Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. Yao, S., Shinn, N., Razavi, P., and Narasimhan, K. τ -bench: benchmark for tool-agent-user interaction in real-world domains. CoRR, abs/2406.12045, 2024. Zeng, A., Lv, X., Zheng, Q., Hou, Z., Chen, B., Xie, C., Wang, C., Yin, D., Zeng, H., Zhang, J., et al. Glm-4.5: Agentic, reasoning, and coding (arc) foundation models. CoRR, abs/2508.06471, 2025. Zhao, W., Wang, X., Ma, C., Kong, L., Yang, Z., Tuo, M., Shi, X., Zhai, Y., and Cai, X. Mua-rl: Multi-turn userinteracting agent reinforcement learning for agentic tool use. arXiv preprint arXiv:2508.18669, 2025. Patil, S. G., Mao, H., Yan, F., Ji, C. C.-J., Suresh, V., Stoica, I., and Gonzalez, J. E. The berkeley function calling leaderboard (bfcl): From tool use to agentic evaluation of large language models. In Forty-second International Conference on Machine Learning, 2025. Qi, Y., Peng, H., Wang, X., Xin, A., Liu, Y., Xu, B., Hou, L., and Li, J. Agentif: Benchmarking instruction following of large language models in agentic scenarios. arXiv preprint arXiv:2505.16944, 2025. Qian, C., Liu, Z., Prabhakar, A., Liu, Z., Zhang, J., Chen, H., Ji, H., Yao, W., Heinecke, S., Savarese, S., Xiong, C., and Wang, H. Userbench: An interactive gym environment for user-centric agents. CoRR, abs/2507.22034, 2025a. Qian, C., Liu, Z., Prabhakar, A., Qiu, J., Liu, Z., Chen, H., Kokane, S., Ji, H., Yao, W., Heinecke, S., et al. Userrl: Training interactive user-centric agent via reinforcement learning. arXiv preprint arXiv:2509.19736, 2025b. Qin, T., Bai, F., Hu, T.-Y., Vemulapalli, R., Koppula, H. S., Xu, Z., Jin, B., Cemri, M., Lu, J., Wang, Z., et al. Compass: multi-turn benchmark for tool-mediated planning & preference optimization. arXiv preprint arXiv:2510.07043, 2025. Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., Lin, Y., Cong, X., Tang, X., Qian, B., et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789, 2023. Singh, J., Magazine, R., Pandya, Y., and Nambi, A. Agentic reasoning and tool integration for llms via reinforcement learning. arXiv preprint arXiv:2505.01441, 2025. Wang, K., Shen, Y., Lv, C., Zheng, X., and Huang, X.- J. Triptailor: real-world benchmark for personalized travel planning. In Findings of the Association for Computational Linguistics: ACL 2025, pp. 97059723, 2025. Xi, Z., Huang, J., Liao, C., Huang, B., Guo, H., Liu, J., Zheng, R., Ye, J., Zhang, J., Chen, W., et al. Agentgymrl: Training llm agents for long-horizon decision making through multi-turn reinforcement learning. arXiv preprint arXiv:2509.08755, 2025. Xie, J., Zhang, K., Chen, J., Zhu, T., Lou, R., Tian, Y., Xiao, Y., and Su, Y. Travelplanner: benchmark for real-world planning with language agents. In Proceedings of the 41st International Conference on Machine Learning, pp. 5459054613, 2024. Xu, Z., Soria, A. M., Tan, S., Roy, A., Agrawal, A. S., Poovendran, R., and Panda, R. Toucan: Synthesizing 1.5 tool-agentic data from real-world mcp environments. arXiv preprint arXiv:2510.01179, 2025. TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios A. Detailed Explanations for Comparison Traits Constraint Adherence: Strictly comply with all constraints explicitly specified in the system prompt, including explicit rule requirements, special-case handling logic, system boundary conditions, and operational/runtime limitations. Preference Alignment: Accurately satisfy the users explicitly stated needs while maintaining consistency and continuity of preferences across multi-turn interactions. When user preferences change or conflict, identify the discrepancy, reconcile it, and resolve it reasonably to avoid inconsistent responses. Information Integration: Integrate temporal, spatial, and commonsense information, and incorporate environmental context and state changes to reason systematically about the problem, producing solutions that are logically consistent, context-aware, and aligned with the current state. Goal Management: When user goals are unclear or information is incomplete, progressively refine vague requirements into clear, executable, and verifiable task objectives through clarifying questions, contextual inference, and iterative reasoning. In complex tasks, handle multiple interdependent goals and constraints (e.g., cost, time, risk, resources) simultaneously by balancing trade-offs, coordinating dependencies, and dynamically adjusting plans to achieve globally optimal or satisfactory solution rather than locally optimal one. Execution Complexity: Tasks may require multi-step execution, persistent state tracking, or conditional branching decisions, increasing the depth of planning and execution. Complexity can be reflected by observable indicators such as the maximum number of tool calls within single reasoning step and the average number of tool calls across the overall interaction; these indicators also capture execution overhead and the risk of error accumulation. Appropriateness: Tool usage should maintain clear functional boundaries and consistent semantic definitions. Outputs should focus on core information and remain low-noise, using appropriate parameters and filtering mechanisms to reduce redundancy rather than accumulating irrelevant content in context. Inter-Dependency: When tools exhibit sequential dependencies, result passing, or cascading invocation relationships, the depth of reasoning and orchestration complexity increases significantly, placing higher demands on overall planning capability and state management. Behavior Attributes: Model different users behavioral attributes, including emotional states (e.g., impatience, anxiety), interaction styles (e.g., detail-oriented, model-reliant), and engagement levels that change with model performance (e.g., reduced willingness to respond after repeatedly receiving similar answers). Behavioral Diversity: Cover wide range of realistic user behavior changes, including adding, modifying, deleting, or reverting instructions during the conversation; redirecting intent; merging multiple goals; making partial edits to model-generated content; pointing out model errors; requesting further clarification; or seeking advice in an exploratory mannerdemonstrating the systems ability to adapt to complex and dynamic interactive behaviors. B. TRIP-Bench Construction B.1. Environment and Tools B.1.1. ATTRACTION TOOLS func: search attractions DESCRIPTION: Search attractions in city with flexible filtering, ranking, and pagination support. PARAMETERS: city (str), attraction name (opt), categories (opt), longitude/latitude (opt), distance threshold (opt), rating (opt), sight level (opt), comment count (opt), free only (bool), sort key (opt), sort order (opt), page, page size. RETURNS: ranked list of attractions with metadata (location, rating, popularity, opening hours, price, distance). func: get attraction detail with products DESCRIPTION: Retrieve detailed information of specific attraction and its ticket products. PARAMETERS: poi id (str). RETURNS: Full attraction profile including categories, ratings, opening hours, features, and purchasable tickets. func: get attraction coordinates DESCRIPTION: Obtain geographic coordinates of given attraction. TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios PARAMETERS: poi id (str). RETURNS: Latitude and longitude of the specified attraction. B.1.2. HOTEL TOOLS func: search hotels DESCRIPTION: Search hotels in specified city for stay window, with multi-criteria filtering (price, distance, ratings, amenities, room types, cancellation policy) plus sorting and pagination. PARAMETERS: city (str), check in date (YYYY-MM-DD), check out date (YYYY-MM-DD), price min/max (opt), longitude/latitude (opt), distance threshold (opt), hotel type (opt), stars (opt), review count (opt), good remarks rate (opt), product/environment/service rating (opt), room types (opt), cancel policy (opt), is pet friendly (opt), has breakfast (opt), sort key (opt), sort order (opt), page, page size. RETURNS: ranked list of hotels with key metadata (type, price, rating, review count, coordinates, distance). func: get hotel detail with products DESCRIPTION: Retrieve hotel profile and its bookable room products for given dates, with product-level filtering and affordability/occupancy-aware ranking. PARAMETERS: hotel id (str), check in date (YYYY-MM-DD), check out date (YYYY-MM-DD), room num (opt), person num (opt), room type (opt), min breakfast per room (opt), cancel policy (opt), has window (opt), page, page size. RETURNS: Hotel summary followed by paginated product lines (room type, occupancy, breakfast, cancellation, window, nightly price); products that do not satisfy occupancy/room-count constraints are clearly separated. func: get hotel coordinates DESCRIPTION: Obtain geographic coordinates of hotel by its ID. PARAMETERS: hotel id (str). RETURNS: Latitude and longitude of the specified hotel, or failure message if not found. B.1.3. FLIGHT TOOLS func: search flights DESCRIPTION: Search available flights between two cities on specific date with time-window filtering, sorting, and pagination. PARAMETERS: departure city (str), arrival city (str), date (YYYY-MM-DD), dep period (opt), arr period (opt), sort key (opt: time/price), sort order (opt), page, page size. RETURNS: ranked list of flight options with schedule, airline, airports, and minimum available price. func: get flight detail with products DESCRIPTION: Retrieve detailed flight information and purchasable ticket products for given date. PARAMETERS: flight id (str), date (YYYY-MM-DD), source platform (opt), seat type (opt). RETURNS: Flight summary with punctuality statistics, followed by available ticket products including platform, seat class, and price. func: get airport coordinates DESCRIPTION: Obtain geographic coordinates of an airport via exact or fuzzy name matching. PARAMETERS: airport name (str). RETURNS: Latitude and longitude of the matched airport, or failure message if not found. B.1.4. TRAIN TOOLS func: search trains DESCRIPTION: Search trains between departure/arrival city pair with time-window filtering, optional price/time ranking, and pagination (accelerated via pre-built (dep, arr) index). PARAMETERS: departure city (str), arrival city (str), date str (YYYY-MM-DD), dep period (opt), arr period (opt), sort key (opt), sort order (opt), page, page size. RETURNS: ranked list of trains with key fields (train id/number, schedule, stations, minimum price) plus summary line. func: get train detail with products DESCRIPTION: Retrieve specific train and enumerate purchasable ticket products filtered by seat type and platform. 12 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios PARAMETERS: train id (str), date str (YYYY-MM-DD), source platform (opt), seat type (opt). RETURNS: train summary line followed by matched product lines (product id, seat type, platform, price); or an error message if not found / no products. func: get station coordinates DESCRIPTION: Obtain station coordinates using exact match first, then fuzzy match over the station name index. PARAMETERS: station name (str). RETURNS: Latitude/longitude of the best-matched station in summary-style string, or failure message. B.1.5. RESTAURANT TOOLS func: search restaurants DESCRIPTION: Search restaurants in city with category/price/rating/reservability constraints, optional distance filtering using city-center prior (or user coordinates), ranking, and pagination (accelerated via pre-built city index). PARAMETERS: city (str), longitude/latitude (opt), distance threshold (opt), price min/price max (opt), stars (opt), review count (opt), product rating (opt), environment rating (opt), service rating (opt), categories (opt), reservable (opt), sort key (opt), sort order (opt), page, page size. RETURNS: ranked list of restaurants with metadata (id, name, category, average price, rating, review count, opening hours, coordinates, distance) plus summary line. func: get restaurant detail with products DESCRIPTION: Retrieve restaurant profile and enumerate its purchasable set-meal products (if any). PARAMETERS: restaurant id (str). RETURNS: restaurant summary (category, avg price, ratings, reservability, opening hours, location) followed by product lines (product id, people, price, available time ranges); if no products exist, returns an order-on-site message. func: get restaurant coordinates DESCRIPTION: Obtain geographic coordinates of given restaurant by ID lookup. PARAMETERS: restaurant id (str). RETURNS: Latitude/longitude of the specified restaurant in summary-style string, or not-found message. B.1.6. GENERAL TOOLS func: get route estimate DESCRIPTION: Public interface that returns formatted summary of straight-line distance and estimated travel time. PARAMETERS: origin lat (float), origin lng (float), destination lat (float), destination lng (float). RETURNS: summary string: distance: X.XX km, estimated travel time: min. func: get city center coords DESCRIPTION: Look up citys center coordinates from lowercase city-to-(lon,lat) table. PARAMETERS: city name (str). RETURNS: formatted longitude/latitude string, or not-found message. func: get date after DESCRIPTION: Compute the date that is days after given YYYY-MM-DD date. PARAMETERS: date str (str), days (int). RETURNS: YYYY-MM-DD formatted date string. B.2. Rubrics and Examples B.2.1. ATTRACTION RUBRICS rubric: INCLUDE CATEGORIES DESCRIPTION: The itinerary must include attractions from specified categories. rubric: EXCLUDE CATEGORIES DESCRIPTION: The itinerary must not include attractions from specified categories. rubric: INCLUDE ATTRACTIONS DESCRIPTION: The itinerary must include the specified attractions. 13 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios rubric: EXCLUDE ATTRACTIONS DESCRIPTION: The itinerary must not include the specified attractions. rubric: HEAT SCORE DESCRIPTION: Constrain included attractions by popularity level (either require certain popularity bands or exclude them). rubric: COMMENT SCORE DESCRIPTION: Constrain included attractions by review score level (either require high-rated ranges or exclude low-rated ranges). rubric: PRICE ATTRACTION DESCRIPTION: Constrain attraction ticket price (e.g., only free attractions or only attractions below price threshold). rubric: DISTANCE DESCRIPTION: Constrain attractions by maximum distance (within certain distance from the hotel or city center). rubric: CATEGORY PRIORITY DESCRIPTION: The itinerary should prioritize attractions from specified categories in order of preference. rubric: COMMENT COUNT DESCRIPTION: Constrain included attractions by minimum/maximum review count (e.g., more-than or fewer-than thresholds). rubric: SIGHT LEVEL DESCRIPTION: The itinerary should include attractions of specified official sight level (e.g., 5A or at least 4A). B.2.2. HOTEL RUBRICS rubric: COST DESCRIPTION: Constrain hotel price by budget rules, including thresholds (less/more), approximate targets (around), or bounded ranges, applied at different aggregation levels (per night per room/person, per-night total, per-person total, or overall total). rubric: HOTEL TYPE DESCRIPTION: Constrain the allowed hotel tier/type, either requiring the selected hotel to be within specified level(s) or explicitly excluding certain level(s). rubric: REVIEW COUNT HOTEL DESCRIPTION: Require the hotel to have at least minimum number of user reviews. rubric: GOOD RATE DESCRIPTION: Require the hotels positive review rate to be at least specified threshold. rubric: STAR DESCRIPTION: Require the hotels star rating to be at least specified minimum. rubric: ASPECT RATING DESCRIPTION: Require the hotels aspect ratings (product, environment, service) to meet minimum thresholds, either jointly for all three aspects or individually for specific aspect. rubric: CANCEL POLICY DESCRIPTION: Require the hotels cancellation policy to be at least as flexible as given free-cancellation deadline. rubric: PET FRIENDLY DESCRIPTION: Require the hotel to be pet friendly. rubric: BREAKFAST NUMBER DESCRIPTION: Constrain the number of breakfasts provided per day, either exactly specified count or at least specified minimum. rubric: HAS WINDOW DESCRIPTION: Require the hotel room to have window. rubric: LOCATION DESCRIPTION: Constrain hotel location by proximity, requiring hotels to be within specified distance of the city center, and/or enforcing that all nights except the final night satisfy the city-center constraint (with the final night handled separately, e.g., near an airport/train station). 14 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios B.2.3. RESTAURANT RUBRICS rubric: PRICE DESCRIPTION: Constrain each selected restaurants per-person per-meal cost, including less-than, more-than, around, or within-range budget rules. rubric: RATING DESCRIPTION: Only recommend restaurants whose overall star rating is at least specified threshold. rubric: REVIEW COUNT DESCRIPTION: Prefer restaurants that have at least specified minimum number of reviews. rubric: INCLUDE CUISINE DESCRIPTION: Ensure the plan includes restaurants serving specified cuisines. rubric: EXCLUDE CUISINE DESCRIPTION: Avoid restaurants that focus on specified cuisines. rubric: OPEN DESCRIPTION: Apply reservation-availability constraints, either preferring reservable restaurants when possible or excluding restaurants that require mandatory advance reservations. rubric: SUBRATING FOOD DESCRIPTION: Prefer restaurants where the food quality subrating is at least specified threshold. rubric: SUBRATING ENVIRONMENT DESCRIPTION: Prefer restaurants where the environment/ambience subrating is at least specified threshold. rubric: SUBRATING SERVICE DESCRIPTION: Prefer restaurants where the service subrating is at least specified threshold. B.2.4. TRANSPORTATION RUBRICS rubric: TIME DEPART DESCRIPTION: Constrain outbound (depart/arrive) timing, supporting broad time periods, specific time windows, and before/after cutoff constraints. rubric: TIME RETURN DESCRIPTION: Constrain return (depart/arrive) timing, supporting broad time periods, specific time windows, and before/after cutoff constraints. rubric: COST TRANSPORT DESCRIPTION: Constrain transportation budget via upper bounds on one-way per-person cost, round-trip per-person cost, or total transportation cost. rubric: PLATFORM DESCRIPTION: Constrain where tickets are booked by specifying allowed booking platform(s) or excluding certain platform(s). rubric: ONTIME DESCRIPTION: Constrain schedule reliability by requiring minimum on-time performance rate and/or maximum allowed delay. rubric: AIRLINE DESCRIPTION: Exclude specified airlines from flight bookings. B.2.5. GENERAL RUBRICS rubric: TIME DEPART DESCRIPTION: Constrain outbound (depart/arrive) timing, supporting broad time periods, specific time windows, and before/after cutoff constraints. rubric: TIME RETURN DESCRIPTION: Constrain return (depart/arrive) timing, supporting broad time periods, specific time windows, and before/after cutoff constraints. rubric: COST TRANSPORT DESCRIPTION: Constrain transportation budget via upper bounds on one-way per-person cost, round-trip per-person cost, TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios or total transportation cost. rubric: PLATFORM DESCRIPTION: Constrain where tickets are booked by specifying allowed booking platform(s) or excluding certain platform(s). rubric: ONTIME DESCRIPTION: Constrain schedule reliability by requiring minimum on-time performance rate and/or maximum allowed delay. rubric: AIRLINE DESCRIPTION: Exclude specified airlines from flight bookings. B.3. Task Difficulty Classification Nine Typical User Behaviors in Multi-turn Dialogue (Behavioral Diversity): Instruction Appending: While preserving the original goal, the user introduces new constraints, preferences, or sub-goals. Instruction Modification: The user replaces or updates part of the previous instructions without rejecting the overall task, aiming only to adjust specific parameter. Intent Redirection: The task objective fundamentally changes, requiring re-planning of the solution path, while inheriting some previously stated instructions. Instruction Deletion / Rollback: The user explicitly requests canceling prior requirement or reverting to historical state (version). Plan Comparison and Integration: The user provides multiple goals that are unrelated or conflicting, and ultimately wants them merged into single comprehensive plan. Local Revision: The user proposes targeted edits to specific part of the content (typically produced by the model). Error Reporting: The user points out that the model made mistake, misunderstood something, or misinterpreted the requirement, and asks for correction. Clarification and Explanation: The user requests further explanation of the models output or the models interpretation. Exploratory Inquiry: The user proactively seeks suggestions or possible solutions from the model, and may or may not adopt them in the end. B.4. Evaluation Metrics B.4.1. BASIC FEASIBILITY Structural validity. The output must be parseable as valid JSON with consistent schema, correct field naming, and properly formatted parameters (e.g., YYYY-MM-DD HH:mm). POI validity. All referenced POIs (restaurants/attractions/hotels) must exist in the sandbox inventory and belong to the intended planning city/cities. Information completeness. The plan must specify correct trip dates and party size, include the required city stays and intercity transport legs, cover essential daily POIs (at least one restaurant and one attraction on non-transfer days), and include hotels for all nights except the return day. 16 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Table 4. Dataset difficulty levels by trip length, city structure, constraint count, and user interaction behaviors. Difficulty Trip Length City Structure # Constraints Easy 25 days Two cities 26 (04 in the first turn) Mid 37 days Two cities / Three cities 710 (47 in the first turn) Hard 310 days Two cities / Three cities 1114 (typically 811 in the first turn) User Instruction & Interaction Characteristics Only includes: instruction additions, instruction modifications, deletion/rollback (deletions only within feasible items), and issue pointing. Includes: instruction additions, modifications, deletion/rollback (deletions only within feasible items), issue pointing, content corrections, clarification/explanations, and exploratory questions. Includes all Mid behaviors, plus four highdifficulty composite behaviors: Hard LIT, Hard FIT, Hard AIS, and Hard PMR. B.4.2. PLANNING SOUNDNESS Temporal reasonableness. The schedule should be feasible with no overlaps, no excessive idle gaps (except transfer days), reasonable daily start/end bounds, plausible attraction/meal durations, visits within opening hours, compliant intercity buffers (flight 1.52.5h; train 1530min), and local transfers with realistic travel times. Spatial logic. The POI ordering should form sensible route, avoid unnecessary long-distance movement, and keep restaurant-to-adjacent-activity distance typically within 10 km (up to 20 km tolerated). Experience diversity. The itinerary should avoid repeated visits to the same attraction or restaurant. Product consistency. Required tickets/reservations should be reflected in products; restaurant quantities and hotel room capacity must satisfy party-size requirements. C. Additional Experiments Table 5 shows the detailed performance of DeepSeek-V3.2 under three different settings: single-turn, multi-turn w/ issue reporting and multi-turn w/o issue reporting. Table 5. Comparison of DeepSeek-V3.2 under single, multi, and multi (no issue) inference settings."
        },
        {
            "title": "Hard LIT Hard FIT Hard AIS Hard PMR Overall",
            "content": "loose strict loose strict loose strict loose strict loose strict loose strict loose strict 0.14 0.00 0.32 0.00 0.30 0.04 0.463 0.100 DeepSeek-V3.2 (single) 0.14 0.00 0.26 0.00 0.20 0.02 0.400 0.108 DeepSeek-V3.2 (multi) DeepSeek-V3.2 (no issue) 0.68 0.12 0.32 0.04 0.25 0.083 0.00 0.00 0.25 0.00 0.00 0.00 0.313 0.050 0.79 0.27 0.53 0.10 0.30 0.71 0.31 0.41 0.09 0.36 0.02 0.02 C.1. PassK Performance We provide the pass-k evaluation results in Figure 5. D. GTPO D.1. Training Details We present the full detailed training settings fot GTPO in Table 6. 17 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Figure 5. Pass-k Performance Results. Figure 6. Training Curve. E. Manual Evaluation Protocol for User Simulator Reliability Consistency in subsequent queries. We check whether the issued instruction ID is consistently reflected in subsequent user queries within the same trajectory. turn is marked as consistent if it satisfies: (i) Constraint retention: key constraints implied by the instruction (e.g., budget, time, city, POI type) remain present; (ii) No contradiction: the query does not negate or conflict with earlier constraints unless an explicit revision is stated; (iii) Specificity stability: constraints are neither dropped nor silently over-specified into different requirement. Accuracy is computed as the turn-level pass rate, Acc = #consistent turns #evaluated turns , aggregated over all evaluated turns. Ambiguity & style fidelity in AIS. For AIS trajectories, we assess whether (i) the intended ambiguity is properly captured and (ii) the style simulation is faithful. We evaluate: (i) Ambiguity: the query remains genuinely underspecified (e.g., vague preferences, flexible time ranges) rather than fully resolved; (ii) Constraint expressiveness: despite being ambiguous, the query still clearly conveys essential constraints and does not hide key requirements; (iii) Style fidelity: tone and wording match the target user profile and remain stable across turns. Annotators assign two 15 ratings per turn (ambiguity and style); the turn score is their average, and the overall score is the mean turn score across all evaluated AIS turns. Annotators. Five volunteer annotators, motivated by personal interest, participated in the manual labeling. Each annotator spent approximately 3 hours on annotation on average, following the criteria above. F. Key Prompts In this section, we provide all key prompts used in our work, including the prompt for the travel agent and the user-simulator. F.1. Agent (cid:7) You must answer in English . You are structured travel planning assistant . You may only create itineraries based on ** real data returned by the external tools provided by the system ** (e.g., attraction search , hotel search , restaurant search , intercity transportation search , in - city transportation time estimation via get_route_estimate ). You must ** not fabricate ** any locations , products , IDs , or transportation schedules . (cid:4) 18 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Table 6. GTPO Training Hyperparameters"
        },
        {
            "title": "Parameter\nadv estimator\nuse kl in reward\ntrain batch size\nmax prompt length\nlr\nppo mini batch size\nppo micro batch size per gpu\nuse kl loss\nkl loss coef\nkl loss type\nentropy coeff\nenable gradient checkpointing\nenable activation offload\nenable param offload\nenable optimizer offload\nulysses sequence parallel size\nname\ntensor model parallel size\ngpu memory utilization\nn\ntemperature\nmax model len\nresponse length one turn\nlog prob micro batch size per gpu\nnnodes\nn gpus per node",
            "content": "Value grpo False 32 9300 1e-6 32 1 True 0.05 low var kl 0 True True True True 8 sglang 8 0.5 8 1 32768 8192 2 4 8 When generating or modifying an itinerary , you must output ** complete JSON ( trip_plan ) ** in one response , following the required format . Do ** not ** split the output across multiple responses . If the user requirements cannot be fully satisfied , you must propose the most feasible alternative and explain which parts cannot be met and why . If key information is missing , you must proactively request it . Key information includes : departure city , destination city , departure date , return date or trip length ( at least one of the two ) , number of travelers . --- ## I. Overall Itinerary Requirements * The itinerary must include : complete intercity transportation ( outbound , return , and multi - city connections ) , in - city transportation , daily attractions , daily meals , and nightly hotels ( except the return day ). * Activity times must not overlap . Unless intercity transportation constraints prevent scheduling , gaps between activities must not exceed two hours . * Daytime should include main activities ; night arrangements may be flexible . --- ## II . Transportation Rules * Flights : Schedule 1.5 -2.5 hour \" Flight Check - in \" activity to be completed before departure , with no additional buffer time added . * Example :* dedicated \" Flight Check - in \" activity is scheduled from 08:30 -10:30 , immediately followed by the flight at 10:30: {\" time \":\"08:30 -10:30\" ,\" type \":\" Flight Check - in \" ,\" description \":\" Check in for flight JL223 at Tokyo Haneda Airport .\"} ,{\" time \":\"10:30 -11:50\" ,\" type \":\" Intercity Transportation \" ,\" id \":\" T_FLT_01 \" ,\" products \":[{\" id \":\" T_FLT_01_P01 \" ,\" quantity \":4}] ,\" description \":\" Flight JL223 from Tokyo Haneda to Osaka Itami .\"} * Trains : Plan to arrive at the station 15 -30 minutes before departure as buffer time only , and do not create separate check - in activity . * Example :* Arrival at Shin - Osaka Station at 13:45 via local transportation allows 15 - minute buffer before the 14:00 Shinkansen departure , without separate check - in activity : {\" time \":\"13:00 -13:45\" ,\" type \":\" Local Transportation \" ,\" description \":\" From Tempozan to Shin - Osaka Station .\"} ,{\" time \":\"14:00 -16:30\" ,\" type \":\" Intercity Transportation \" ,\" id \":\" T_SHN_01 \" ,\" products \":[{\" id \":\" T_SHN_01_P01 \" ,\" quantity \":4}] ,\" description \":\" Take Shinkansen Nozomi from 19 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Shin - Osaka to Tokyo .\"} * By default , trains are assumed to have no delays ; flight delays / cancellations must follow the external tool returned information ( if available ) . * If the user does not specify times , outbound trips default to morning ; return trips default to night or evening . * Local Transportation : * As long as the activity locations differ , you must schedule Local Transportation and call get_route_estimate . * Activity duration must match the tool returned values ( less than 20 minutes deviation ). * Except for the return day , the last activity of each day must be returning to the hotel via Local Transportation or performing Hotel Check - in ( first arrival ). --- ## III . Hotel Rules * Except for the return day , every night must include hotel stay ; if staying multiple days in one city , try to keep the same hotel . * First arrival of each day requires Hotel Check - in . --- ## IV . Attraction Rules * An attraction can only be assigned to single time slot and cannot be scheduled multiple times ( unless explicitly requested by the user ). * Duration must be more than 30 minutes ; the stay duration should generally follow the recommendation , with allowable adjustments of no more than 1.5 hours earlier or later . * Attraction visit time should ideally fall entirely within opening hours . buffer of up to 30 minutes from opening hours is allowed when needed ( i.e . , the start time may be up to 30 minutes before opening , and the end time may be up to 30 minutes after closing ) , but schedules should prefer staying fully within opening hours whenever possible . * If the attraction requires tickets or reservations , include them in products ( quantity = number of travelers ). If free and no proof required , products = []. * If staying at single attraction for the whole day and it covers lunchtime , separate lunch arrangement may be omitted , and the description must state \" Lunch will be handled inside the attraction .\" Dinner arrangements , however , should generally not be omitted . --- ## V. Restaurant Rules * No repeated restaurants ; maintain cuisine diversity . * Prefer restaurants within 10 km of previous / next activity location ( expand to 20 km if none available ; should not exceed 20 km unless necessary to meet user requirements ). * Meal duration must be 45 -90 minutes and should ideally fall entirely within opening hours . buffer of up to 30 minutes from opening hours is allowed when needed (i.e., the start time may be up to 30 minutes before opening , and the end time may be up to 30 minutes after closing ) , but schedules should prefer staying fully within opening hours whenever possible . * If set menus exist , recommend suitable set menu matching the number of travelers and include it in products . If no suitable set menu , products = [] and note \" Order on site .\" * Breakfast is assumed to be handled at the hotel or independently ; do not arrange separately . * If meal arrangements conflict significantly with attraction visits or intercity travel , you may omit the meal and explain an alternative ( e. g. , \" Quick meal at the station / airport \" or \" Choose any dining options inside the attraction area \") . --- ## VI . Output Format Requirements for Itinerary Planning 1. Basic Requirements * When \" generating \" or \" modifying \" an itinerary , the reply must contain complete JSON with the top - level key trip_plan . * Field names must strictly match the specification ; no additions , deletions , or renaming . 2. Structure Description Top - level : * trip_plan * start_date ( YYYY - MM - DD ) * end_date ( YYYY - MM - DD ) * number_of_people ( integer ) * daily_schedule ( array , sorted by date ) Each daily_schedule object : * date ( YYYY -MM - DD ) * cities ( cities involved that day or intercity direction , e.g., \" Tokyo \" or \" Tokyo -> Osaka \") * hotel ( required except return day ; repeated even for continuous stays ) * activities ( array sorted by time ) hotel : 20 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios * id ( real hotel ID ) * products : [{ id ( room type ID ) , room_num }] Number of rooms must satisfy traveler needs . Each activity requires : * time ( HH :MM - HH :MM , with no >2 - hour gaps ) * type ( Flight Check - in / Intercity Transportation / Local Transportation / Hotel Check - in / Attraction / Restaurant ) * description ( explaining location or additional details ) Optional fields : * id : must be provided for Intercity Transportation , Attraction , and Restaurant ; must not be provided for other types * products : must be provided for Intercity Transportation , Attraction , and Restaurant ; if no suitable products exist , this field must be set to [] and must not be omitted ; must not be provided for other types 3. Example JSON Output Format json {\" trip_plan \":{\" start_date \":\"2025 -05 -02\" ,\" end_date \":\"2025 -05 -04\" ,\" number_of_people \":4 ,\" daily_schedule \":[{\" date \":\"2025 -05 -02\" ,\" cities \":\" Tokyo -> Osaka \" ,\" hotel \":{\" id \":\" H_OSA_01 \" ,\" products \":[{\" id \":\" H_OSA_01_P01 \" ,\" room_num \":1} ,{\" id \":\" H_OSA_01_P02 \" ,\" room_num \":1}]} ,\" activities \":[{\" time \":\"08:30 -10:30\" ,\" type \":\" Flight Check - in \" ,\" description \":\" Check in for flight JL223 at Tokyo Haneda Airport .\"} ,{\" time \":\"10:30 -11:50\" ,\" type \":\" Intercity Transportation \" ,\" id \":\" T_FLT_01 \" ,\" products \":[{\" id \":\" T_FLT_01_P01 \" ,\" quantity \":4}] ,\" description \":\" Flight JL223 from Tokyo Haneda to Osaka Itami .\"} ,{\" time \":\"11:50 -12:30\" ,\" type \":\" Local Transportation \" ,\" description \":\" Transfer from Osaka Itami Airport to hotel in Umeda .\"} ,{\" time \":\"12:30 -13:00\" ,\" type \":\" Hotel Check - in \" ,\" description \":\" Check in at Osaka Umeda hotel . Have quick lunch nearby before heading to Osaka Castle .\"} ,{\" time \":\"13:00 -13:30\" ,\" type \":\" Local Transportation \" ,\" description \":\" Travel from hotel to Osaka Castle .\"} ,{\" time \":\"13:30 -16:30\" ,\" type \":\" Attraction \" ,\" id \":\" A_OSA_D1_05 \" ,\" products \":[] ,\" description \":\" Visit Osaka Castle and nearby park ; the attraction is free and no tickets are required .\"} ,{\" time \":\"16:30 -17:00\" ,\" type \":\" Local Transportation \" ,\" description \":\" From Osaka Castle to Dotonbori .\"} ,{\" time \":\"17:00 -18:30\" ,\" type \":\" Restaurant \" ,\" id \":\" R_OSA_01 \" ,\" products \":[{\" id \":\" R_OSA_01_P01 \" ,\" quantity \":1}] ,\" description \":\" Dinner at Dotonbori with takoyaki and okonomiyaki .\"} ,{\" time \":\"18:30 -19:00\" ,\" type \":\" Local Transportation \" ,\" description \":\" Return from Dotonbori to hotel .\"}]} ,{\" date \":\"2025 -05 -03\" ,\" cities \":\" Osaka \" ,\" hotel \":{\" id \":\" H_OSA_01 \" ,\" products \":[{\" id \":\" H_OSA_01_P01 \" ,\" room_num \":1} ,{\" id \":\" H_OSA_01_P02 \" ,\" room_num \":1}]} ,\" activities \":[{\" time \":\"08:00 -09:00\" ,\" type \":\" Local Transportation \" ,\" description \":\" From hotel to Universal Studios Japan .\"} ,{\" time \":\"09:00 -19:30\" ,\" type \":\" Attraction \" ,\" id \":\" A_OSA_D2_02 \" ,\" products \":[{\" id \":\" A_OSA_D2_02_P01 \" ,\" quantity \":4}] ,\" description \":\" Full day at Universal Studios Japan . Lunch will be arranged inside the park at any convenient restaurant .\"} ,{\" time \":\"19:30 -20:00\" ,\" type \":\" Local Transportation \" ,\" description \":\" From USJ to Universal CityWalk Osaka .\"} ,{\" time \":\"20:00 -21:30\" ,\" type \":\" Restaurant \" ,\" id \":\" R_OSA_02 \" ,\" products \":[{\" id \":\" R_OSA_02_P01 \" ,\" quantity \":1}] ,\" description \":\" Dinner at Universal CityWalk Osaka .\"} ,{\" time \":\"21:30 -22:00\" ,\" type \":\" Local Transportation \" ,\" description \":\" Return from CityWalk to hotel .\"}]} ,{\" date \":\"2025 -05 -04\" ,\" cities \":\" Osaka -> Tokyo \" ,\" activities \":[{\" time \":\"08:30 -09:00\" ,\" type \":\" Local Transportation \" ,\" description \":\" From hotel to Osaka Aquarium Kaiyukan .\"} ,{\" time \":\"09:00 -11:30\" ,\" type \":\" Attraction \" ,\" id \":\" A_OSA_D3_02 \" ,\" products \":[{\" id \":\" A_OSA_D3_02_P01 \" ,\" quantity \":4}] ,\" description \":\" Visit Osaka Aquarium Kaiyukan .\"} ,{\" time \":\"11:30 -12:10\" ,\" type \":\" Local Transportation \" ,\" description \":\" From Kaiyukan to Tempozan Harbor Village for lunch .\"} ,{\" time \":\"12:10 -13:00\" ,\" type \":\" Restaurant \" ,\" id \":\" R_OSA_03 \" ,\" products \":[] ,\" description \":\" Seafood lunch at Tempozan ( no suitable set menu for the current group size ; order on site and pay at the restaurant ) .\"} ,{\" time \":\"13:00 -13:45\" ,\" type \":\" Local Transportation \" ,\" description \":\" From Tempozan to Shin - Osaka Station .\"} ,{\" time \":\"14:00 -16:30\" ,\" type \":\" Intercity Transportation \" ,\" id \":\" T_SHN_01 \" ,\" products \":[{\" id \":\" T_SHN_01_P01 \" ,\" quantity \":4}] ,\" description \":\" Take Shinkansen Nozomi from Shin - Osaka to Tokyo .\"}]}]}} --- ## VII . Rules for Itinerary Modifications ( All -or - Nothing Output ) * The returned JSON must always represent complete trip_plan . * If any modification is detected ( including additions , deletions , or adjustments ) , the response must output the full daily_schedule for all dates , not just the affected ones . * If no changes are needed after evaluation , then daily_schedule = [] , but start_date , end_date , and number_of_people must always be included . * An empty daily_schedule is allowed only when no modifications are made . ## Example : User asks whether the first day can be changed to train ( only if faster ) Logic check : * Train is slower than flight , Does not satisfy \" change to train only if faster \". * No modifications needed . Return example ( daily_schedule empty ): json {\" trip_plan \":{\" start_date \":\"2025 -05 -02\" ,\" end_date \":\"2025 -05 -04\" ,\" number_of_people \":4 ,\" daily_schedule \":[]}} (cid:6) F.2. User Simulation (cid:7) You must answer in English . You are now playing the role of real user of travel - planning product . Your task is : based on the content in the instruction section and the conversation history , generate the next round of natural and reasonable user queries or (cid:5) (cid:4) 21 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios replies to the assistant . You must strictly follow the specifications below . ======================== Final Output Format Requirements Your final answer must contain the following JSON : json { \" instruction_ids \": [\" id1 \", \" id2 \" , ...] , \" user_query \": \" What you want to say to the assistant \" } Notes : * \" instruction_ids \": All instruction IDs used in this round ( from all blocks in the instruction section ). * If no ID is used , you must output an empty array []. * \" user_query \": The content you will say to the assistant . It must be natural , conversational , and coherent . ======================== Instruction Section All IDs below may be used in instruction_ids . Only the selected instructions need to be reflected in the user_query . 1. ** Currently effective instruction section ( history ) ** {{ HISTORY }} 2. ** New instruction section ( new ) ** {{ NEW }} 3. ** Original instruction modification section ( modify ) ** {{ MODIFY }} 4. ** Issue - reporting section ( issue ) ** {{ ISSUE }} 5. ** Special Instructions ** * ** ContentMod ** ( ID : ContentMod ) Used to propose localized modifications to the assistant generated content . Must not conflict with the content of history / new / modify . * ** ClarifyExp ** ( ID : ClarifyExp ) Used to request the assistant to explain , clarify , or elaborate on the meaning , background , or logic of some generated content . * ** ExploreQues ** ( ID : ExploreQues ) Used to ask exploratory questions , express potential preferences , or provide groundwork for future formal instructions . Its content must not copy formal instructions . ======================== Instruction Selection Constraints 1. The total number of selected IDs from these sections in single round must be ** no more than 4** , simulating gradual exposure of instructions . 2. Instructions not selected in instruction_ids must NOT be referenced or used . 3. The content of special instructions must be written by yourself and must not conflict with history / new / modify . 4. Instructions in the \" Currently effective instruction section \" do not need to be selected or used by default . Unless the assistant explicitly asks you to confirm or rely on them , you should avoid choosing instructions from this section , as they have already been addressed in previous rounds . 5. The \" modify \" section contains instruction updates (i.e., change - history instructions ). If you select any IDs from MODIFY , they override and replace the corresponding instructions in HISTORY that they modify . ======================== Information Handling Rules 1. If the assistant asks you question , You must answer immediately . 2. If you do not have the information , You must answer with something like \"I don remember / don know / haven decided / Let the model decide ,\" or use the instruction section to generate new query . 3. You must NOT create new facts not present in the instruction content . ( For ExploreQues , you may express tentative or hypothetical preferences without asserting them as facts .) 4. You may paraphrase or polish instruction content in natural language , but may not change its meaning or add new information . 5. If the assistant tries to persuade you to change your needs , You must stick to the instructions . 6. If the assistant asks the same question already answered within the last 3 rounds , You must show impatience and refuse to answer . 7. You must always behave like real user and must not reveal that you are model . ======================== Conversation History Messages 22 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios {{ HISTORY_MESSAGES }} (cid:6) (cid:5) 23 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios G. Conversation Trajectory User [2] Im planning solo 4-day trip to Wuxi, leaving Fuzhou on October 24th, 2025, and coming back on October 27th. Could you help me put together an itinerary? Id like to visit well-rated attractions, making sure to include Yixing Ceramic Museum, China, and the Best Scenic Spot of Taihu Lake. Im especially interested in Ecology, Flora & Fauna Zones, and Nightlife & Live Shows. For food, Im hoping for restaurants with at least 4.5 stars that serve Barbecue, Home-style Cooking, and Korean Cuisine. Also, please keep the one-way transportation cost under 400, and need hotel located within 10 kilometers of the city center. Assistant [3] Tool Calls (1): Tool 1: search flights Arguments: {\"departure city\": \"Fuzhou\", \"arrival city\": \"Wuxi\", \"date str\": \"2025-10-24\", \"sort key\": \"price\", \"sort order\": \"asc\"} Tool Call/Response [4] Tool Response: No matching flights found. Assistant [5] Tool Calls (1): Tool 1: search trains Arguments: {\"departure city\": \"Fuzhou\", \"arrival city\": \"Wuxi\", \"date str\": \"2025-10-24\", \"sort key\": \"price\", \"sort order\": \"asc\"} Tool Call/Response [6] Tool Response: Showing 1-3 of 3 results. Train id: Train 00001629 D3142/D3143 9:48-16:54 Fuzhou South Railway Station Wuxi Station minimum price: 337.0 Train id: Train 00000894 D2282 14:42-22:10 Fuzhou South Railway Station Wuxi Station minimum price: 348.0 Train id: Train 00001561 D3136/D3137 11:25-19:04 Fuzhou South Railway Station Wuxi Station minimum price: 348.0 Assistant [7] Tool Calls (1): Tool 1: search trains Arguments: {\"departure city\": \"Wuxi\", \"arrival city\": \"Fuzhou\", \"date str\": \"2025-10-27\", \"sort key\": \"price\", \"sort order\": \"asc\"} Tool Call/Response [8] Tool Response: Showing 1-4 of 4 results. Train id: Train 00001523 D3135/D3138 9:43-17:24 Wuxi New District Station Fuzhou South Railway Station minimum price: 299.0 Train id: Train 00000845 D2281 9:09-16:35 Wuxi Station Fuzhou South Railway Station minimum price: 300. 24 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Train id: Train 00001517 D3135/D3138 9:33-17:24 Wuxi Station Fuzhou South Railway Station minimum price: 303.0 Train id: Train 00001594 D3141/D3144 12:23-19:28 Wuxi Station Fuzhou South Railway Station minimum price: 348.0 Omitted Turns Turns [986] omitted for brevity Intermediate tool calls/responses suppressed Assistant [87] Tool Calls (1): Tool 1: get date after Arguments: {\"date str\": \"2025-10-24\", \"days\": \"3\"} Tool Call/Response [88] Tool Response: 2025-10-27 Assistant [89] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.555366\", \"origin lng\": \"120.302786\", \"destination lat\": \"31.512471\", \"destination lng\": \"120.281905\"} Tool Call/Response [90] Tool Response: distance: 5.15 km, estimated travel time: 20 min Assistant [91] Day 1 (2025-10-24): Fuzhou Wuxi Hotel: Hotel 00040911 [09:33-09:48] Intercity Transportation (ID: Train 00001629) Description: Take train D3142/D3143 from Fuzhou South Railway Station to Wuxi Station. Arrive at the station 15 minutes before departure. [16:54-17:15] Local Transportation Description: Transfer from Wuxi Station to Zhe Fei Hotel (approx. 17 min). [17:15-17:30] Hotel Check-in Description: Check in at Zhe Fei Hotel (single room with breakfast). [17:30-17:50] Local Transportation Description: Travel from hotel to Wang Steak barbecue restaurant (approx. 20 min). [18:00-19:00] Restaurant (ID: restaurant 3689704) Description: Dinner at Wang Steak (Barbecue, 4.5 stars). No solo set menu available; order on site. [19:00-19:20] Local Transportation Description: Return from restaurant to hotel (approx. 20 min). Day 2 (2025-10-25): Wuxi . . . [omitted for clarity] TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Day 3 (2025-10-26): Wuxi . . . [omitted for clarity] Day 4 (2025-10-27): Wuxi Fuzhou [08:20-08:37] Local Transportation Description: Travel from hotel to Wuxi Station (approx. 17 min). [09:09-16:35] Intercity Transportation (ID: Train 00000845) Description: Take train D2281 from Wuxi Station to Fuzhou South Railway Station. Assistant [93] Tool Calls (1): Tool 1: search attractions Arguments: {\"city\": \"Wuxi\", \"attraction name\": \"pottery\", \"rating\": \"4.0\", \"page size\": \"10\"} Tool Call/Response [94] Tool Response: No attractions found. Assistant [95] Tool Calls (1): Tool 1: get city center coords Arguments: {\"city name\": \"Yixing\"} Tool Call/Response [96] Tool Response: No city center coordinates found for the given city name: Yixing. Assistant [97] Tool Calls (1): Tool 1: search attractions Arguments: {\"city\": \"Wuxi\", \"attraction name\": \"museum\", \"rating\": \"4.0\", \"page size\": \"20\"} Tool Call/Response [98] Tool Response: Showing 1-2 of 2 results. POI ID: 86783 Wuxi Wuxi Museum level: 4A longitude: 120.305988, latitude: 31.54976 distance: 6.53km rating: 4.5 (145 comments) popularity Score: 4.0 opening hours: 09:00 { 17:00 reference visit time: 1-2 hours ticket price: Free POI ID: 98904 Wuxi China Clay Figurine Museum level: None longitude: 120.281806, latitude: 31.588246 distance: 11.15km rating: 4.4 (62 comments) popularity Score: 2.8 opening hours: 00:00 { 23:59 reference visit time: 1-2 hours ticket price: Free Omitted Turns Turns [99132] omitted for brevity Intermediate tool calls/responses suppressed 26 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Assistant [133] Tool Calls (1): Tool 1: get restaurant detail with products Arguments: {\"restaurant id\": \"restaurant 500297\"} Tool Call/Response [134] Tool Response: Restaurant id: restaurant 500297 Jiangnan University Second Cafeteria category: Home-style Cooking avg price: 22.5 stars: 4.0/5 review count: 86 longitude: 120.266144, latitude: 31.489489 open hours: 11:30-14:30, 17:30-22:30 product rating: 8.0 environment rating: 8.7 service rating: 8.2 reservable: False must reserve: False product id: Pb853fe186fb3 people: 2 price: 44.1 available time ranges: 11:30-14:30, 17:30-22:30 product id: P371d7466ca56 people: 4 price: 83.97 available time ranges: 11:30-14:30, 17:30-22:30 Assistant [135] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.54976\", \"origin lng\": \"120.305988\", \"destination lat\": \"31.512471\", \"destination lng\": \"120.281905\"} Tool Call/Response [136] Tool Response: distance: 4.73 km, estimated travel time: 19 min Assistant [137] Day 1 (2025-10-24): Fuzhou Wuxi Hotel: Hotel 00040911 [09:33-09:48] Intercity Transportation (ID: Train 00001629) Description: Take train D3142/D3143 from Fuzhou South Railway Station to Wuxi Station. Arrive at the station 15 minutes before departure. [16:54-17:15] Local Transportation Description: Transfer from Wuxi Station to Zhe Fei Hotel (approx. 17 min). [17:15-17:30] Hotel Check-in Description: Check in at Zhe Fei Hotel (single room with breakfast). [17:30-17:50] Local Transportation Description: Travel from hotel to Wang Steak barbecue restaurant (approx. 20 min). [18:00-19:00] Restaurant (ID: restaurant 3689704) Description: Dinner at Wang Steak (Barbecue, 4.5 stars). No solo set menu available; order on site. [19:00-19:20] Local Transportation Description: Return from restaurant to hotel (approx. 20 min). Day 2 (2025-10-25): Wuxi . . . [omitted for clarity] Day 3 (2025-10-26): Wuxi . . . [omitted for clarity] Day 4 (2025-10-27): Wuxi Fuzhou [08:20-08:37] Local Transportation Description: Travel from hotel to Wuxi Station (approx. 17 min). [09:09-16:35] Intercity Transportation (ID: Train 00000845) 27 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Description: Take train D2281 from Wuxi Station to Fuzhou South Railway Station. User [138] Okay, understand that Yixing Ceramic Museum isnt available in the system, so lets just cancel that requirement. Also, if including all three specific cuisines is causing problems, you can drop that requirement too. For the hotel, Id actually prefer it to be even closer within 3 kilometers of the city center, not 10. Before we finalize, could you explain the reasoning behind the specific train timings youve chosen for the intercity travel? Are those the only/best options that meet the cost and schedule criteria? Assistant [139] Tool Calls (1): Tool 1: search trains Arguments: {\"departure city\": \"Fuzhou\", \"arrival city\": \"Wuxi\", \"date str\": \"2025-10-24\", \"sort key\": \"time\", \"sort order\": \"asc\", \"page size\": \"10\"} Tool Call/Response [140] Tool Response: Showing 1-3 of 3 results. Train id: Train 00001629 D3142/D3143 9:48-16:54 Fuzhou South Railway Station Wuxi Station minimum price: 337.0 Train id: Train 00001561 D3136/D3137 11:25-19:04 Fuzhou South Railway Station Wuxi Station minimum price: 348.0 Train id: Train 00000894 D2282 14:42-22:10 Fuzhou South Railway Station Wuxi Station minimum price: 348.0 Assistant [141] Tool Calls (1): Tool 1: search trains Arguments: {\"departure city\": \"Wuxi\", \"arrival city\": \"Fuzhou\", \"date str\": \"2025-10-27\", \"sort key\": \"time\", \"sort order\": \"asc\", \"page size\": \"10\"} Tool Call/Response [142] Tool Response: Showing 1-4 of 4 results. Train id: Train 00000845 D2281 9:09-16:35 Wuxi Station Fuzhou South Railway Station minimum price: 300.5 Train id: Train 00001517 D3135/D3138 9:33-17:24 Wuxi Station Fuzhou South Railway Station minimum price: 303.0 Train id: Train 00001523 D3135/D3138 9:43-17:24 Wuxi New District Station Fuzhou South Railway Station minimum price: 299.0 Train id: Train 00001594 D3141/D3144 12:23-19:28 Wuxi Station Fuzhou South Railway Station minimum price: 348.0 Assistant [143] Tool Calls (1): Tool 1: search hotels Arguments: {\"city\": \"Wuxi\", \"check in date\": \"2025-10-24\", \"check out date\": \"2025-10-27\", \"longitude\": \"120.311889\", \"latitude\": \"31.491064\", \"distance threshold\": \"3\", \"sort key\": \"stars\", \"sort order\": \"desc\", \"page size\": \"10\"} TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Tool Call/Response [144] Tool Response: Showing 1-10 of 36 results. Hotel id: Hotel 00040967 Wuxi Xuntang Shuxiang Mansion Hotel type: Upscale price: 1385.69+ stars: 5.0/5 review count: 107 longitude: 120.317599, latitude: 31.479502 distance: 1.39km Hotel id: Hotel 00041418 Worldhotel Grand Juna Wuxi type: Luxury price: 510.6+ stars: 5.0/5 review count: 721 longitude: 120.320327, latitude: 31.477452 distance: 1.71km Hotel id: Hotel 00040914 Hanjin Hotel type: Midscale price: 367.47+ stars: 4.5/5 review count: 200 longitude: 120.284699, latitude: 31.499521 distance: 2.75km Hotel id: Hotel 00040977 Wuxi Kailai Hotel type: Luxury price: 820.1+ stars: 4.5/5 review count: 254 longitude: 120.327029, latitude: 31.504266 distance: 2.05km Hotel id: Hotel 00041390 Home Inn (Luoxia Yuan Branch, Nanhu Jiayuan Subway Station, Binhu Development Zone, Wuxi) type: Economy price: 274.96+ stars: 4.5/5 review count: 65 longitude: 120.329619, latitude: 31.50817 distance: 2.54km Hotel id: Hotel 00041401 Jinshi Business Hotel type: Upscale price: 324.87+ stars: 4.5/5 review count: 127 longitude: 120.29294, latitude: 31.489492 distance: 1.81km Hotel id: Hotel 00041419 Wuxi the Taihu Lake Huayi Hotel type: Luxury price: 838.41+ stars: 4.5/5 review count: 150 longitude: 120.306911, latitude: 31.479883 distance: 1.33km Hotel id: Hotel 00041318 Wuxi Zhanmei Boutique Hotel type: Upscale price: 402.85+ stars: 4.0/5 review count: 274 longitude: 120.295741, latitude: 31.487359 distance: 1.59km Hotel id: Hotel 00042376 Liangtang Business Hotel type: Economy price: 251.44+ stars: 4.0/5 review count: 29 longitude: 120.317151, latitude: 31.517725 distance: 3.0km Hotel id: Hotel 00040997 Hualiang Hotel type: Economy price: 173.81+ stars: 3.5/5 review count: 7 longitude: 120.28638, latitude: 31.477258 distance: 2.87km Omitted Turns Turns [145156] omitted for brevity Intermediate tool calls/responses suppressed Assistant [157] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.499521\", \"origin lng\": \"120.284699\", \"destination lat\": \"31.584891\", \"destination lng\": \"120.235333\"} Tool Call/Response [158] Tool Response: distance: 10.56 km, estimated travel time: 31 min Assistant [159] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.489489\", \"origin lng\": \"120.266144\", \"destination lat\": \"31.499521\", \"destination lng\": \"120.284699\"} Tool Call/Response [160] Tool Response: distance: 2.08 km, estimated travel time: 14 min 29 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Assistant Price: 348 Notes: Arrives late evening, limiting Price: 337 Notes: **Selected** earliest arrival, Price: 348 Notes: Arrives very late, essentially wasting [161] **Train Timing Rationale** For your **outbound trip (Oct 24)**, three trains meet the 400 budget: Train: D3142/D3143 Departure: 09:48 Arrival: 16:54 maximizes your first evening in Wuxi Train: D3136/D3137 Departure: 11:25 Arrival: 19:04 dinner/activity options Train: D2282 Departure: 14:42 Arrival: 22:10 the first day The **09:48 departure** was chosen because it provides reasonable morning start from Fuzhou, arrives in Wuxi by late afternoon, and leaves enough time for hotel check-in, dinner, and brief evening activity. For the **return trip (Oct 27)**, four trains meet the budget: Train: D2281 Departure: 09:09 Arrival: 16:35 to Fuzhou, departs from convenient Wuxi Station Train: D3135/D3138 Departure: 09:33 Arrival: 17:24 Train: D3135/D3138 Departure: 09:43 Arrival: 17:24 **Wuxi New District Station** (less central) Train: D3141/D3144 Departure: 12:23 Arrival: 19:28 The **09:09 departure** offers the earliest return to Fuzhou while keeping you on convenient morning schedule. The marginally cheaper option (299) uses different station that would require extra travel time on your last morning. **Conclusion:** The selected trains provide the best balance of **cost (400), schedule efficiency, and convenience**. **Revised Itinerary with Closer Hotel** Ive switched your hotel to **Hanjin Hotel** (4.5 stars), located **2.75 km from the city center** (within your 3 km requirement). All transportation times have been recalculated based on the new hotel location. Day 1 (2025-10-24): Fuzhou Wuxi Hotel: Hotel 00040914 Price: 303.0 Notes: Slightly later arrival Price: 299.0 Notes: Cheapest, but departs from Price: 300.5 Notes: **Selected** earliest arrival back Price: 348.0 Notes: Later departure & arrival [09:33-09:48] Intercity Transportation (ID: Train 00001629) Description: Take train D3142/D3143 from Fuzhou South Railway Station to Wuxi Station. Arrive at the station 15 minutes before departure. [16:54-17:30] Local Transportation Description: Transfer from Wuxi Station to Hanjin Hotel (approx. 30 min). [17:30-17:45] Hotel Check-in Description: Check in at Hanjin Hotel (single room). [17:45-18:00] Local Transportation Description: Travel from hotel to Wang Steak barbecue restaurant (approx. 13 min). [18:00-19:00] Restaurant (ID: restaurant 3689704) Description: Dinner at Wang Steak (Barbecue, 4.5 stars). No solo set menu; order on site. [19:00-19:15] Local Transportation Description: Return from restaurant to hotel (approx. 13 min). Day 2 (2025-10-25): Wuxi . . . [omitted for clarity] Day 3 (2025-10-26): Wuxi . . . [omitted for clarity] Day 4 (2025-10-27): Wuxi Fuzhou [08:15-08:45] Local Transportation Description: Travel from hotel to Wuxi Station (approx. 30 min). [09:09-16:35] Intercity Transportation (ID: Train 00000845) Description: Take train D2281 from Wuxi Station to Fuzhou South Railway Station. 30 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios User [162] Thanks for the detailed explanation on the trains, that makes sense. have few more points to add for the hotel and restaurants. First, dont need breakfast included at the hotel, so please make sure the booking is for zero breakfasts. Second, Id prefer restaurants where can just walk in without needing to make mandatory reservation in advance. Also, Im bringing my dog along, so the hotel must be pet friendly. Lastly, could you clarify something? For the Ecology, Flora & Fauna Zones priority, does classical garden like Li Garden truly count as primary Flora & Fauna Zone, or should the itinerary focus more on dedicated nature reserves or wildlife parks first? Assistant [163] Tool Calls (1): Tool 1: search attractions Arguments: {\"city\": \"Wuxi\", \"attraction name\": \"park\", \"rating\": \"4.0\", \"page size\": \"10\"} Tool Call/Response [164] Tool Response: Showing 1-10 of 10 results. POI ID: 61116204 Wuxi Wuxi Sunac Amusement Park level: None longitude: 120.271041, latitude: 31.450076 distance: 5.98km rating: 4.4 (4295 comments) popularity Score: 5.8 opening hours: 10:30 { 20:30 reference visit time: 0.5-1 day ticket price: 88.0 POI ID: 61116205 Wuxi WuxiSunac Ocean Park level: None longitude: 120.272148, latitude: 31.448296 distance: 6.06km rating: 4.4 (2109 comments) popularity Score: 5.2 opening hours: 10:00 { 17:00 reference visit time: 2-3 hours ticket price: 180.0 POI ID: 10524099 Wuxi Wuxi Zoo,Taihu Lake Amusement Park level: None longitude: 120.235333, latitude: 31.584891 distance: 12.69km rating: 4.6 (3982 comments) popularity Score: 4.7 opening hours: 08:30 { 16:30 reference visit time: 0.5-1 day ticket price: 100.0 POI ID: 10536146 Wuxi Lihu Park level: None longitude: 120.269494, latitude: 31.520571 distance: 5.19km rating: 4.6 (134 comments) popularity Score: 3.9 opening hours: 00:00 { 24:00 reference visit time: 3-4 hours ticket price: Free POI ID: 52285296 Wuxi Wuxi Xihui Park level: None longitude: 120.270922, latitude: 31.577575 distance: 10.35km rating: 4.5 (16 comments) popularity Score: 3.6 opening hours: 08:00 { 17:00 reference visit time: 1-2 hours ticket price: 70.0 POI ID: 87859 Wuxi Ebi Zui Park (Goose Nose Park) level: None longitude: 120.271458, latitude: 31.934248 distance: 49.29km rating: 4.4 (352 comments) popularity Score: 3.1 opening hours: 00:00 { 23:59 reference visit time: 1-2 hours ticket price: Free POI ID: 91749 Wuxi Lihu Lake Central Park level: None longitude: 120.248784, latitude: 31.521683 distance: 6.89km rating: 4.5 (113 comments) popularity Score: 3.0 opening hours: 06:30 { 22:00 reference visit time: 2-3 hours ticket price: Free POI ID: 10519872 Wuxi Xuelang Mountain Ecological Park level: None longitude: 120.260155, latitude: 31.464848 distance: 5.71km rating: 4.4 (481 comments) popularity Score: 2.9 opening hours: 07:30 { 19:00 reference visit time: 0.5-1 day ticket price: 35.0 POI ID: 39525057 Wuxi Jingui Park level: None longitude: 120.311146, latitude: 31.495871 distance: 0.54km rating: 4.8 (44 comments) popularity Score: 2.6 opening hours: 00:00 { 24:00 reference visit time: 1-3 hours ticket price: Free POI ID: 10519612 Wuxi Zhongshan Park level: None longitude: 120.271892, latitude: 31.907716 distance: 46.35km rating: 4.6 (64 comments) popularity Score: 2.2 opening hours: 00:00 { 24:00 reference visit time: 1-2 hours ticket price: Free 31 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Assistant [165] Tool Calls (1): Tool 1: get attraction detail with products Arguments: {\"poi id\": \"10519872\"} Tool Call/Response [166] Tool Response: POI ID: 10519872 Wuxi Xuelang Mountain Ecological Park level: N/A longitude: 120.260155, latitude: 31.464848 categories: Ecology, Flora & Fauna Zones, Family & Kids Friendly, Outdoor Adventure & Sports rating: 4.4 (481 comments) popularity score: 2.9 opening hours: 07:30 { 19:00 reference visit time: 0.5-1 day features: Agricultural production, popular science education product id: 10519872 1 Adult price: 35.0 product id: 10519872 2 Student price: 24.5 product id: 10519872 3 Senior price: 21.0 product id: 10519872 4 Child price: 17.5 product id: 10519872 5 Family Package (2 Adults + 1 Child) price: 77. Assistant [167] Tool Calls (1): Tool 1: get attraction detail with products Arguments: {\"poi id\": \"10536146\"} Tool Call/Response [168] Tool Response: POI ID: 10536146 Wuxi Lihu Park level: N/A longitude: 120.269494, latitude: 31.520571 categories: Natural Scenery, City Sightseeing & Landmarks, Photo Spots & Instagrammable, Leisure, Wellness & Resort, Family & Kids Friendly rating: 4.6 (134 comments) popularity score: 3.9 opening hours: 00:00 { 24:00 reference visit time: 3-4 hours features: None product id: 10536146 1 Free Ticket price: 0 Omitted Turns Turns [169174] omitted for brevity Intermediate tool calls/responses suppressed Assistant [175] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.514576\", \"origin lng\": \"120.279077\", \"destination lat\": \"31.489207\", \"destination lng\": \"120.299003\"} Tool Call/Response [176] Tool Response: distance: 3.39 km, estimated travel time: 17 min 32 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Assistant [177] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.489207\", \"origin lng\": \"120.299003\", \"destination lat\": \"31.499521\", \"destination lng\": \"120.284699\"} Tool Call/Response [178] Tool Response: distance: 1.78 km, estimated travel time: 14 min Assistant [179] **Clarification on Ecology, Flora & Fauna Zones** You raise valid point. classical garden like Li Garden, while containing flora, is not dedicated **ecological zone or wildlife park**. To better match your priority, have replaced Li Garden with **Xuelang Mountain Ecological Park** an attraction that explicitly lists Ecology, Flora & Fauna Zones as its primary category. This is dedicated ecological park with agricultural production and education, offering more authentic nature experience. **Other Adjustments Made:** 1. **Pet-friendly hotel** Hanjin Hotel (Hotel 00040914) is marked pet friendly: True. 2. **Zero-breakfast room** The selected product 00760382 has breakfast num: 0. 3. **No mandatory reservations** The Korean restaurant on Day 2 (restaurant 7471268) required mandatory reservation. It has been replaced with **Zhang Liang malatang** (restaurant 3903050), which has must reserve: False (5.0 stars, Korean cuisine). **Updated Itinerary** Day 1 (2025-10-24): Fuzhou Wuxi Hotel: Hotel [09:33-09:48] Intercity Transportation (ID: Train 00001629) Description: Take train D3142/D3143 from Fuzhou South Railway Station to Wuxi Station. Arrive at the station 15 minutes before departure. [16:54-17:30] Local Transportation Description: Transfer from Wuxi Station to Hanjin Hotel (approx. 30 min). [17:30-17:45] Hotel Check-in Description: Check in at Hanjin Hotel (single room, no breakfast). [17:45-18:00] Local Transportation Description: Travel from hotel to Wang Steak barbecue restaurant (approx. 13 min). [18:00-19:00] Restaurant (ID: restaurant 3689704) Description: Dinner at Wang Steak (Barbecue, 4.5 stars). No solo set menu; order on site. No mandatory reservation required. [19:00-19:15] Local Transportation Description: Return from restaurant to hotel (approx. 13 min). Day 2 (2025-10-25): Wuxi . . . [omitted for clarity] Day 3 (2025-10-26): Wuxi . . . [omitted for clarity] Day 4 (2025-10-27): Wuxi Fuzhou [08:15-08:45] Local Transportation Description: Travel from hotel to Wuxi Station (approx. 30 min). [09:09-16:35] Intercity Transportation (ID: Train 00000845) Description: Take train D2281 from Wuxi Station to Fuzhou South Railway Station. 33 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios User [180] Thanks for making those changes, the new ecological park and the pet-friendly, no-reservation options look much better. Ive been thinking about few more specifics. For the return flight, please make sure you dont book with 9 Air. Also, when picking restaurants, Id really prefer ones that have lot of reviews, like at least 1000, as they seem more reliable. And for the hotel, can you ensure it has at least 100 reviews as well? Oh, and changed my mind about breakfast - Id actually like the hotel to include at least one breakfast for me. Assistant [181] Tool Calls (1): Tool 1: search hotels Arguments: {\"city\": \"Wuxi\", \"check in date\": \"2025-10-24\", \"check out date\": \"2025-10-27\", \"longitude\": \"120.311889\", \"latitude\": \"31.491064\", \"distance threshold\": \"3\", \"is pet friendly\": \"true\", \"review count\": \"100\", \"sort key\": \"stars\", \"sort order\": \"desc\", \"page size\": \"10\"} Tool Call/Response [182] Tool Response: Showing 1-4 of 4 results. Hotel id: Hotel 00041418 Worldhotel Grand Juna Wuxi type: Luxury price: 510.6+ stars: 5.0/5 review count: 721 longitude: 120.320327, latitude: 31.477452 distance: 1.71km Hotel id: Hotel 00040914 Hanjin Hotel type: Midscale price: 367.47+ stars: 4.5/5 review count: 200 longitude: 120.284699, latitude: 31.499521 distance: 2.75km Hotel id: Hotel 00040977 Wuxi Kailai Hotel type: Luxury price: 820.1+ stars: 4.5/5 review count: 254 longitude: 120.327029, latitude: 31.504266 distance: 2.05km Hotel id: Hotel 00041318 Wuxi Zhanmei Boutique Hotel type: Upscale price: 402.85+ stars: 4.0/5 review count: 274 longitude: 120.295741, latitude: 31.487359 distance: 1.59km Assistant [183] Tool Calls (1): Tool 1: get hotel detail with products Arguments: {\"hotel id\": \"Hotel 00041418\", \"check in date\": \"2025-10-24\", \"check out date\": \"2025-10-27\", \"room num\": \"1\", \"person num\": \"1\", \"page size\": \"10\"} Tool Call/Response [184] Tool Response: Hotel id: Hotel 00041418 Wuxi type: Luxury stars: 5.0/5 review count: 721.0 longitude: 120.320327 latitude: 31.477452 product rating: 9.0 environment rating: 9.1 service rating: 9.2 pet friendly: True Showing 1-10 of 12 products. product id: 00769371 room type: single maximum occupancy per room: 1 breakfast num: 0 cancel policy: 3 (Non-cancellable) has window: False avg price per night per room: 510.6 product id: 00769372 room type: single maximum occupancy per room: 1 breakfast num: 1 cancel policy: 3 (Non-cancellable) has window: True avg price per night per room: 582.19 product id: 00769373 room type: large maximum occupancy per room: 2 breakfast num: 0 cancel policy: 3 (Non-cancellable) has window: False avg price per night per room: 612.72 product id: 00769374 room type: large maximum occupancy per room: 2 breakfast num: 1 cancel policy: 3 (Non-cancellable) has window: False avg price per night per room: 626.09 product id: 00769375 room type: large maximum occupancy per room: 2 breakfast num: 2 cancel policy: 3 (Non-cancellable) has window: False avg price per night per room: 639.45 product id: 00769378 room type: double maximum occupancy per room: 2 breakfast num: 2 cancel policy: 3 (Non-cancellable) has window: False avg price per night per room: 792.63 product id: 00769376 room type: double maximum occupancy per room: 2 breakfast num: 0 cancel policy: 3 (Non-cancellable) has window: True avg price per night per room: 851.0 product id: 00769377 room type: double maximum occupancy per room: 2 breakfast num: 1 cancel policy: 3 (Non-cancellable) has window: True avg price per night per room: 865.85 product id: 00769379 room type: family maximum occupancy per room: 3 breakfast num: 0 cancel policy: 34 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios 3 (Non-cancellable) has window: True avg price per night per room: 1021.2 product id: 00769380 room type: family maximum occupancy per room: 3 breakfast num: 1 cancel policy: 3 (Non-cancellable) has window: True avg price per night per room: 1036.05 Assistant [185] Tool Calls (1): Tool 1: search restaurants Arguments: {\"city\": \"Wuxi\", \"categories\": \"[\"Korean Cuisine\"]\", \"stars\": \"4.5\", \"review count\": \"1000\", \"sort key\": \"review count\", \"sort order\": \"desc\", \"page size\": \"10\"} Tool Call/Response [186] Tool Response: Showing 1-3 of 3 results. Restaurant id: restaurant 6455324 Wang Steak category: Korean Cuisine avg price: 141.0 stars: 4.5/5 review count: 2236 open hours: 11:00-22:00 longitude: 120.281903, latitude: 31.512466 distance: 3.71km Restaurant id: restaurant 7471268 Korean Bucket House BBQ Restaurant category: Korean Cuisine avg price: 160.5 stars: 5.0/5 review count: 2013 open hours: 11:00-22:30 longitude: 120.296028, latitude: 31.487779 distance: 1.55km Restaurant id: restaurant 7832802 Find Charcoal Barbecue Original Seoul Charcoal barbecue category: Korean Cuisine avg price: 151.5 stars: 4.5/5 review count: 1140 open hours: 11:00-23:00 longitude: 120.284334, latitude: 31.5157 distance: 3.78km Omitted Turns Turns [187204] omitted for brevity Intermediate tool calls/responses suppressed Assistant [205] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.514576\", \"origin lng\": \"120.279077\", \"destination lat\": \"31.512466\", \"destination lng\": \"120.281903\"} Tool Call/Response [206] Tool Response: distance: 0.36 km, estimated travel time: 4 min Assistant [207] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.525381\", \"origin lng\": \"120.272061\", \"destination lat\": \"31.48857\", \"destination lng\": \"120.30286\"} Tool Call/Response [208] Tool Response: distance: 5.02 km, estimated travel time: 20 min TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Assistant [209] **Clarification on Transportation** Your itinerary uses **trains**, not flights. There are no flights between Fuzhou and Wuxi in the system for your dates, so no airline (including 9 Air) is involved. The selected trains are the most costand time-effective options meeting your <400 one-way budget. **Changes Made to Meet Your New Requests** Request: **Hotel with 100 reviews & breakfast** How Addressed: Changed to **Worldhotel Grand Juna Wuxi** (5 stars, 721 reviews, pet-friendly). Room product includes **1 breakfast** per night. Request: **Restaurants with 1000 reviews, no mandatory reservation** How Addressed: Day 1: Wang Steak (Barbecue, 1200 reviews) already met. Day 2: Wang Steak (Korean Cuisine, 2236 reviews) solo set menu available, no mandatory reservation. Day 3: Oven fish (Barbecue, 4579 reviews) no mandatory reservation. Request: **Home-style Cooking requirement** How Addressed: Dropped because no restaurant in this category has 1000 reviews. Replaced with high-review Barbecue. Request: **Pet-friendly hotel** How Addressed: Worldhotel Grand Juna Wuxi is marked pet friendly: True. **Updated Itinerary** All transportation times have been recalculated from the new hotel location. Day 1 (2025-10-24): Fuzhou Wuxi Hotel: Hotel 00041418 [09:33-09:48] Intercity Transportation (ID: Train 00001629) Description: Take train D3142/D3143 from Fuzhou South Railway Station to Wuxi Station. Arrive at the station 15 minutes before departure. [16:54-17:30] Local Transportation Description: Transfer from Wuxi Station to Worldhotel Grand Juna Wuxi (approx. 32 min). [17:30-17:45] Hotel Check-in Description: Check in at Worldhotel Grand Juna Wuxi (single room with breakfast). [17:45-18:06] Local Transportation Description: Travel from hotel to Wang Steak barbecue restaurant (approx. 21 min). [18:06-19:06] Restaurant (ID: restaurant 3689704) Description: Dinner at Wang Steak (Barbecue, 4.5 stars, 1200 reviews). No solo set menu; order on site. No mandatory reservation. [19:06-19:27] Local Transportation Description: Return from restaurant to hotel (approx. 21 min). Day 2 (2025-10-25): Wuxi . . . [omitted for clarity] Day 3 (2025-10-26): Wuxi . . . [omitted for clarity] Day 4 (2025-10-27): Wuxi Fuzhou [08:15-08:47] Local Transportation Description: Travel from hotel to Wuxi Station (approx. 32 min). [09:09-16:35] Intercity Transportation (ID: Train 00000845) Description: Take train D2281 from Wuxi Station to Fuzhou South Railway Station. User [210] Thanks for the updates, the new hotel and restaurants look great. have one more request for the return trip: Id like the train to depart after 08:00. Also, could you clarify something for me? The itinerary mentions solo set menu at the Korean restaurant on Day 2. What does that actually include? Is it fixed course meal, and does it offer good value compared to ordering `a la carte? TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Assistant [211] **Clarifications** 1. **Return train timing**: Your return train (D2281) departs at **09:09**, which is after 08:00, so this requirement is already satisfied. 2. **Solo set menu at Wang Steak (Korean Cuisine)**: - **What it includes**: The product Pfd09d3861615 is **fixed-course meal for one person** priced at **132.68**. While the exact dishes are not listed in the database, set menus at Korean barbecue restaurants typically include selection of marinated meats, side dishes (banchan), rice, soup, and sometimes beverage. - **Value comparison**: The average price per person at this restaurant is 141.00. The set menu costs 132.68, which is **about 6% below the average**, suggesting it offers slight discount compared to ordering the same items `a la carte`. Moreover, set menu ensures balanced meal without the hassle of choosing individual dishes. Since your request for return departure after 08:00 is already met, no modifications to the itinerary are needed. User [212] Alright, thanks for the clarification on the set menu. noticed the itinerary says the daily schedule is empty, but can see the detailed plan you provided in your response. Is there technical issue on my end, or was that just note at the end of your message? Also, regarding the return train timing, Id like to update my preference: please make sure the departure is after 10:00, not 08:00. Finally, you mentioned earlier that some train timings might be inconsistent. Could you double-check that the arrival and departure times for both the inbound and outbound trains in this plan are accurate and properly aligned? Assistant [213] Tool Calls (1): Tool 1: search trains Arguments: {\"departure city\": \"Wuxi\", \"arrival city\": \"Fuzhou\", \"date str\": \"2025-10-27\", \"sort key\": \"time\", \"sort order\": \"asc\", \"page size\": \"10\"} Tool Call/Response [214] Tool Response: Showing 1-4 of 4 results. Train id: Train 00000845 D2281 9:09-16:35 Wuxi Station Fuzhou South Railway Station minimum price: 300.5 Train id: Train 00001517 D3135/D3138 9:33-17:24 Wuxi Station Fuzhou South Railway Station minimum price: 303.0 Train id: Train 00001523 D3135/D3138 9:43-17:24 Wuxi New District Station Fuzhou South Railway Station minimum price: 299.0 Train id: Train 00001594 D3141/D3144 12:23-19:28 Wuxi Station Fuzhou South Railway Station minimum price: 348.0 Assistant [215] Tool Calls (1): Tool 1: get train detail with products Arguments: {\"train id\": \"Train 00001594\", \"date str\": \"2025-10-27\"} Tool Call/Response [216] Tool Response: Train id: Train 00001594 D3141/D3144 12:23-19:28 Wuxi Station Fuzhou South Railway Station product id: 00018969 Second class ctrip price: 348.0 product id: 00018970 Second class alitrip price: 348.0 37 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios product id: 00018971 Second class qunar price: 348.0 product id: 00018972 Second class direct price: 348.0 Assistant [217] Tool Calls (1): Tool 1: get train detail with products Arguments: {\"train id\": \"Train 00001629\", \"date str\": \"2025-10-24\"} Tool Call/Response [218] Tool Response: Train id: Train 00001629 D3142/D3143 9:48-16:54 Fuzhou South Railway Station Wuxi Station product id: 00019389 Second class ctrip price: 337.0 product id: 00019390 Second class alitrip price: 337.0 product id: 00019391 Second class qunar price: 337.0 product id: 00019392 Second class direct price: 337.0 Assistant [219] Tool Calls (1): Tool 1: get attraction detail with products Arguments: {\"poi id\": \"39525057\"} Tool Call/Response [220] Tool Response: POI ID: 39525057 Wuxi Jingui Park level: N/A longitude: 120.311146, latitude: 31.495871 categories: Natural Scenery, Leisure, Wellness & Resort, Photo Spots & Instagrammable, Family & Kids Friendly rating: 4.8 (44 comments) popularity score: 2.6 opening hours: 00:00 { 24:00 reference visit time: 1-3 hours features: Construction highlights the characteristics of blending mountains and rivers product id: 39525057 1 Free Ticket price: Assistant [221] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.477452\", \"origin lng\": \"120.320327\", \"destination lat\": \"31.495871\", \"destination lng\": \"120.311146\"} Tool Call/Response [222] Tool Response: distance: 2.22 km, estimated travel time: 14 min Assistant [223] Tool Calls (1): Tool 1: get route estimate Arguments: {\"origin lat\": \"31.495871\", \"origin lng\": \"120.311146\", \"destination lat\": \"31.588048\", \"destination lng\": \"120.306376\"} 38 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Tool Call/Response [224] Tool Response: distance: 10.23 km, estimated travel time: 30 min Assistant [225] Day 1 (2025-10-24): Fuzhou Wuxi Hotel: Hotel [09:33-09:48] Intercity Transportation (ID: Train 00001629) Description: Take train D3142/D3143 from Fuzhou South Railway Station to Wuxi Station. Arrive at the station 15 minutes before departure. [16:54-17:30] Local Transportation Description: Transfer from Wuxi Station to Worldhotel Grand Juna Wuxi (approx. 32 min). [17:30-17:45] Hotel Check-in Description: Check in at Worldhotel Grand Juna Wuxi (single room with breakfast). [17:45-18:06] Local Transportation Description: Travel from hotel to Wang Steak barbecue restaurant (approx. 21 min). [18:06-19:06] Restaurant (ID: restaurant 3689704) Description: Dinner at Wang Steak (Barbecue, 4.5 stars, 1200 reviews). No solo set menu; order on site. No mandatory reservation. [19:06-19:27] Local Transportation Description: Return from restaurant to hotel (approx. 21 min). Day 2 (2025-10-25): Wuxi Hotel: Hotel 00041418 [08:00-08:22] Local Transportation Description: Travel from hotel to Xuelang Mountain Ecological Park (approx. 22 min). [08:30-12:00] Attraction (ID: 10519872) Description: Visit Xuelang Mountain Ecological Park (dedicated Ecology, Flora & Fauna Zones, 3.5 hours). [12:00-12:26] Local Transportation Description: Travel from Xuelang Mountain to Best Scenic Spot of Taihu Lake (approx. 26 min). [12:30-15:00] Attraction (ID: 56807028) Description: Visit Best Scenic Spot of Taihu Lake (natural scenery, 2.5 hours). [15:00-15:28] Local Transportation Description: Travel from Taihu Lake to Wuxi Museum (approx. 28 min). [15:30-17:00] Attraction (ID: 86783) Description: Visit Wuxi Museum (cultural attraction, 1.5 hours). [17:00-17:19] Local Transportation Description: Travel from museum to Wuxi Grand Theatre (approx. 19 min). [17:20-19:20] Attraction (ID: 18567012) Description: Visit Wuxi Grand Theatre (nightlife & live shows, 2 hours). [19:20-19:24] Local Transportation Description: Travel from theatre to Wang Steak Korean restaurant (approx. 4 min). [19:30-20:30] Restaurant (ID: restaurant 6455324) Description: Dinner at Wang Steak (Korean Cuisine, 4.5 stars, 2236 reviews). Solo set menu included. No mandatory reservation. [20:30-20:51] Local Transportation Description: Return from restaurant to hotel (approx. 21 min). Day 3 (2025-10-26): Wuxi Hotel: Hotel 00041418 [08:30-09:04] Local Transportation Description: Travel from hotel to Wuxi Zoo, Taihu Lake Amusement Park (approx. 34 min). [09:10-16:40] Attraction (ID: 10524099) Description: Full day at Wuxi Zoo (wildlife park, ecology & fauna). Lunch will be handled inside the attrac39 TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios tion. [16:40-17:05] Local Transportation Description: Travel from zoo to Star of Taihu Ferris Wheel (approx. 25 min). [17:10-18:10] Attraction (ID: 33190543) Description: Visit Star of Taihu Ferris Wheel (night views & night tours, 0.5-1 hour). [18:10-18:30] Local Transportation Description: Travel from ferris wheel to Oven fish restaurant (approx. 20 min). [18:30-19:30] Restaurant (ID: restaurant 9134254) Description: Dinner at Oven fish (Barbecue, 4.5 stars, 4579 reviews). No solo set menu; order on site. No mandatory reservation. [19:30-19:44] Local Transportation Description: Return from restaurant to hotel (approx. 14 min). Day 4 (2025-10-27): Wuxi Fuzhou [08:30-09:00] Hotel Check-in Description: Breakfast at hotel and check out. [09:00-09:14] Local Transportation Description: Travel from hotel to Jingui Park (approx. 14 min). [09:15-10:45] Attraction (ID: 39525057) Description: Visit Jingui Park (natural scenery, free, 1.5 hours). [10:45-11:15] Local Transportation Description: Travel from Jingui Park to Wuxi Station (approx. 30 min). [12:23-19:28] Intercity Transportation (ID: Train 00001594) Description: Take train D3141/D3144 from Wuxi Station to Fuzhou South Railway Station."
        }
    ],
    "affiliations": [
        "University 1",
        "University 2",
        "University 3",
        "University 4",
        "University 5",
        "University 6"
    ]
}