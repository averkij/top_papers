{
    "paper_title": "Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations",
    "authors": [
        "Dongming Jiang",
        "Yi Li",
        "Songtao Wei",
        "Jinxin Yang",
        "Ayushi Kishore",
        "Alysa Zhao",
        "Dingyi Kang",
        "Xu Hu",
        "Feng Chen",
        "Qiannan Li",
        "Bingzhe Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems remain fragile: existing benchmarks are often underscaled, evaluation metrics are misaligned with semantic utility, performance varies significantly across backbone models, and system-level costs are frequently overlooked. This survey presents a structured analysis of agentic memory from both architectural and system perspectives. We first introduce a concise taxonomy of MAG systems based on four memory structures. Then, we analyze key pain points limiting current systems, including benchmark saturation effects, metric validity and judge sensitivity, backbone-dependent accuracy, and the latency and throughput overhead introduced by memory maintenance. By connecting the memory structure to empirical limitations, this survey clarifies why current agentic memory systems often underperform their theoretical promise and outlines directions for more reliable evaluation and scalable system design."
        },
        {
            "title": "Start",
            "content": "Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations Dongming Jiangα, Yi Liα, Songtao Weiα, Jinxin Yangα, Ayushi Kishoreβ, Alysa Zhaoγ, Dingyi Kangα, Xu Huα, Feng Chenα, Qiannan Liβ and Bingzhe Liα, αUniversity of Texas at Dallas βUniversity of California, Davis γTexas A&M University {dongming.jiang, yi.li3, songtao.wei, jinxin.yang, dingyi.kang, xu.hu, feng.chen, bingzhe.li}@utdallas.edu {aykishore, qnli}@ucdavis.edu; alysazhao111@tamu.edu Corresponding author GitHub Repo 6 2 0 2 2 2 ] . [ 1 0 2 3 9 1 . 2 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems remain fragile: existing benchmarks are often underscaled, evaluation metrics are misaligned with semantic utility, performance varies significantly across backbone models, and system-level costs are frequently overlooked. This survey presents structured analysis of agentic memory from both architectural and system perspectives. We first introduce concise taxonomy of MAG systems based on four memory structures. Then, we analyze key pain points limiting current systems, including benchmark saturation effects, metric validity and judge sensitivity, backbone-dependent accuracy, and the latency and throughput overhead introduced by memory maintenance. By connecting the memory structure to empirical limitations, this survey clarifies why current agentic memory systems often underperform their theoretical promise and outlines directions for more reliable evaluation and scalable system design."
        },
        {
            "title": "Introduction",
            "content": "Large language model (LLM) agents are increasingly expected to operate over long time horizons, maintaining user preferences, accumulating task-relevant knowledge, etc. (Brown et al., 2020; Achiam et al., 2023; Wei et al., 2022). However, fixed context windows fundamentally limit their ability to retain and manipulate persistent state (Brown et al., 2020; Beltagy et al., 2020; Liu et al., 2024; Press et al., 2021). To address this constraint, Memory-Augmented Generation (MAG) extends memory beyond the prompt, enabling agents to store, retrieve, and update information across interactions (Xu et al., 2025c; Nan et al., 2025; Chhikara et al., 2025; Jiang et al., 2026a; Liu et al., 2026). While this paradigm has rapidly evolved from lightweight semantic stores to entity-centric, reflective, and hierarchical designs, empirical understanding remains limited: reported gains are inconsistent across benchmarks, highly backbone-dependent, and lack principled guidance on evaluation and system-level cost. These challenges stem in part from underspecified design trade-offs and inadequate evaluation. Benchmarks are often underscaled relative to modern context windows, metrics emphasize surface overlap over semantic utility, and system-level costs such as latency and throughput degradation are rarely measured. As result, complex memory systems are frequently tested in settings where simpler full-context or retrieval baselines suffice, obscuring their true benefits and limitations. In this paper, we provide structured analysis of agentic memory systems from both architectural and empirical perspectives. 1) We introduce concise taxonomy of Memory-Augmented Generation organized around four memory structures: Lightweight Semantic, Entity-Centric and Personalized, Episodic and Reflective, and Structured and Hierarchical. Defined by how memory is organized and manipulated, this taxonomy establishes principled basis for analyzing system behavior. 2) Building on this framework, we identify key bottlenecks limiting reliability and scalability, including benchmark saturation, metric misalignment (e.g., F1 vs. semantic correctness), prompt sensitivity in LLM-as-a-judge evaluation, backbone dependence, and system-level costs such as retrieval latency, update overhead, and throughput degradation. By linking memory structures to empirical limitations, this survey clarifies why current agentic memory systems often fall short of their theoretical promise. Rather than advocating single best design, we provide diagnostic framework to explain when specific memory structures are effective, Table 1: Comparison with related surveys on memory for LLM-based agents. indicates the topic is systematically discussed; () indicates partial or brief coverage; indicates the topic is not addressed. Survey Taxonomy Focus The AI Hippocampus (Jia et al., 2026) Brain-inspired: implicit, explicit, agentic Memory in the Age of AI Agents (Hu et al., 2025) Formsfunctionsdynamics Toward Efficient Agents (Yang et al., 2026c) Efficiency-focused: memory, tool learning, planning Rethinking Memory Mechanisms (Huang et al., 2026) Substratecognitionsubject From Storage to Experience (Luo et al., 2026) Evolutionary: storagereflectionexperience Graph-based Agent Memory (Yang et al., 2026a) Graph-oriented lifecycle Taxonomy and Empirical Analysis (Ours) Structural + Empirical analysis Memory Mgmt. & Policy Benchmark Saturation Metric Validity Backbone Sensitivity System Cost & Latency () () () () () when they fail, and what trade-offs they entail. Our analysis offers guidance for designing more robust benchmarks, more reliable evaluation protocols, and more scalable agentic memory systems. Difference from other surveys: While existing surveys (Jia et al., 2026; Hu et al., 2025; Yang et al., 2026c,a; Luo et al., 2026; Huang et al., 2026) primarily operate at the theoretical level by cataloguing architectures, defining conceptual taxonomies, and drawing cognitive science analogies, our survey bridges the gap from theory to practice. Our taxonomy is structure-oriented, not only discussing various memory structure designs, but also highlighting the memory management frameworks and optimization strategies. In addition, we provide comprehensive evaluations across multiple benchmarks. Specifically, we conduct systematic analyses of agentic memory systems on benchmark saturation, metric validity, backbone sensitivity, and maintenance overhead, overlooked in prior surveys yet critical for understanding why current MAG systems often fall short of their theoretical promise. detailed comparison is presented in Table 1."
        },
        {
            "title": "2 Background",
            "content": "Agentic memory extends retrieval-based generation by introducing persistent, writable memory that evolves across interactions, enabling an LLM agent to store, update, and reuse information over time. Formally, at step t, the agent conditions on observations ot and an external memory state Mt: (cid:16) yt fθ ϕ(ot, st) ψ(Mt; qt) (cid:17) , (1) where yt denotes the output, st additional agent state, and ψ(Mt; qt) retrieves memory given query qt. The operator represents integration (e.g., prompt concatenation or structured fusion). Crucially, memory affects behavior through the explicit retrieval term ψ(Mt; qt) rather than updates to θ. Two coupled processes are operated in agentic memory: inference-time recall and memory update. At each step, the agent retrieves relevant information from an external memory store to condition its decision, and subsequently writes, updates, or consolidates memory to maintain useful long-term state. Unlike parametric learning, this mechanism influences behavior through explicit readwrite operations over an evolving memory state rather than by modifying model weights. formalization of these operations including query generation, utility-aware retrieval, and memory actions such as store, summarize, link, and delete is provided in Appendix B."
        },
        {
            "title": "3 Taxonomy of Agentic Memory",
            "content": "We introduce concise taxonomy of MemoryAugmented Generation organized around four memory structures: Lightweight Semantic, EntityCentric and Personalized, Episodic and Reflective, and Structured and Hierarchical. Each category is further split into subcategories as shown in Figure 1 in Appendix A. 3.1 Lightweight Semantic Memory Lightweight Semantic Memory is the simplest and most widely used form of MAG, where memory consists of independent textual units embedded in vector space and retrieved via top-k similarity search. Entries are typically append-only or minimally filtered, with no explicit structural relations between them. RL-Optimized Semantic Compression: These schemes treat memory as fixed-size semantic store and apply RL to optimize how information is compressed, retained, or overwritten under context constraints (Wang et al., 2025b; Yan et al., 2025; Yuan et al., 2025). Memory remains largely unstructured and textual, with learning focused on efficient content selection. For example, MemAgent (Yu et al., 2025) trains latent token-level memory using multi-conversation RL to manage ultra-long contexts, while MemSearcher (Yuan et al., 2025) formulates multi-turn search and memory updates as an end-to-end RL problem, iteratively compressing semantic memory to enable scalable multi-hop reasoning without relying on full dialogue history. Heuristic / Prompt-Optimized: These approaches manage memory through prompt design or heuristic rewriting with flat, compressed textual summary of prior steps generated via engineered instructions, reducing context length but remaining unstructured. Similar prompt-driven compression strategies appear in prior work (Zhao et al., 2025; Wu and Li, 2025; Liu et al., 2026; Li et al., 2026b). For example, ACON (Kang et al., 2025d) learns natural-language compression guidelines to selectively summarize long interaction histories, reducing context by up to 54% without RL or fine-tuning, while CISM (Liu et al., 2025c) condenses each reasoning and action step into compact semantic representations to enable long-horizon execution under context constraints without explicit external memory retrieval. Context Window Management: This category manages the models working context within single task, without accumulating memory across sessions. Prior interactions are folded, summarized, or reorganized to fit within bounded window, prioritizing local reasoning efficiency over long-term storage or reuse (Zhu et al., 2025; Sakib et al., 2025). For example, AgentFold (Ye et al., 2025) treats context as dynamic workspace and learns multi-scale folding operations to condense long trajectories, while Context-Folding Agent (Sun et al., 2025b) trains an RL-based policy that branches sub-tasks and compresses completed segments. Token-Level Semantic Memory: This category encodes memory at the token level using dedicated memory tokens or compressed latent panels. These representations primarily capture semantic content, aiming to improve long-context handling with minimal overhead (Wu et al., 2025b; Zhang et al., 2025c; Yang et al., 2024b). Memory entries are independent and inexpensive to store or retrieve, making them suitable for shortto medium-horizon recall, but limited for precise state tracking or longterm reasoning. For example, MemGen (Zhang et al., 2025c) augments frozen LLM with ondemand latent token memory via an RL-trained trigger and LoRA-based weaving, while TokMem (Wu et al., 2025b) replaces lengthy procedural prompts with trainable memory tokens to enable constantsize context management and scalable skill reuse. 3.2 Entity-Centric and Personalized Memory Entity-centric and personalized memory organizes information around explicit entities such as users, tasks, or preferences, using structured records or attributevalue pairs. predefined schema governs how information is stored, updated, and retrieved. Entity-Centric Memory: Entity-centric memory organizes information around explicit entities and their attributes, maintaining structured, persistent records rather than raw dialogue (Modarressi et al., 2023; Liu et al., 2021, 2025a). For example, A-MEM (Xu et al., 2025c) builds interconnected knowledge notes with structured attributes and LLM-generated links; Memory-R1 (Yan et al., 2025) formulates entity memory management as an RL problem over persistent entityfact bank. Personalized Memory: Personalized memory maintains persistent user profiles that integrate shortand long-term preferences to support adaptive, identity-consistent behavior across sessions (Zhong et al., 2024; Li et al., 2025a; Kwon et al., 2025; Liu et al., 2025a; Mao et al., 2026; Su et al., 2026). For example, PAMU (Sun et al., 2025a) combines sliding windows with moving averages to track evolving preferences, EgoMem (Yao et al., 2025) constructs lifelong multimodal profiles with conflict-aware updates, and MemOrb (Huang et al., 2025a) stores compact reflective memories for continual improvement. 3.3 Episodic and Reflective Memory Episodic and reflective memory adds temporal abstraction by organizing interactions into episodes or higher-level summaries. These systems periodically consolidate experience through summarization or reflection, producing compact representations of salient events over time. Episodic Buffer w/ Learned Control: memory in these work consists of episodic interaction records maintained in bounded buffer and dynamically inserted, retained, or deleted through learned policies (Du et al., 2025a; Zhang et al., 2025f; Icarte et al., 2020). For example, MemR3 (Du et al., 2025a) models retrieval as closed-loop retrievereflectanswer process; and the Act of Remembering (Icarte et al., 2020) formulates remembering as control problem in POMDPs with fixed-capacity episodic buffer. Episodic Recall for Exploration: These methods leverage episodic memory to improve exploration and credit assignment in partially observable or long-horizon settings. Past experiences are stored and selectively retrieved to guide decisionmaking (Na et al., 2024; Adamyan et al., 2025). For example, EMU (Na et al., 2024) maintains largecapacity episodic memories indexed by learned embeddings to accelerate cooperative MARL exploration, while SAM2RL (Adamyan et al., 2025) uses visual memory bank as an episodic buffer and trains PPO policy to manage memory replacement, outperforming heuristic updates under challenging conditions. Episodic Reflection & Consolidation: This subcategory reflects and consolidates episodic experiences into compact representations (Tan et al., 2025b; Kim et al., 2025; Ouyang et al., 2025; Dong et al., 2025; Lee et al., 2024). The objective is to balance memory capacity with longterm reasoning utility. For example, MemP (Fang et al., 2025b) distills trajectories into procedural abstractions for continual refinement and transfer; LEGOMem (Han et al., 2025) constructs modular, role-aware procedural memories for multi-agent coordination; and TiMem (Li et al., 2026a) introduces temporal-hierarchical memory tree for structured consolidation and scalable long-horizon personalization without RL or fine-tuning. Episodic Utility Learning: Episodic memories in these setting are augmented with learned value or utility signals that evolve over time, enabling selective retention and retrieval based on both semantic relevance and estimated long-term usefulness (Zhou et al., 2025a; Cao et al., 2025). For example, MemRL (Zhang et al., 2026b) associates utility Q-values with intentexperience pairs and updates them online to balance stability and plasticity without fine-tuning, while Memory-T1 (Du et al., 2025b) learns temporal-aware retrieval policy via GRPO to optimize accuracy, grounding, and chronological consistency in long-context dialogue. 3.4 Structured and Hierarchical Memory Structured and hierarchical memory systems impose explicit organization over stored information. Hierarchical designs partition memory into multiple tiers (e.g., shortand long-term stores), while structured approaches encode relationships among memory elements using graphs or other formal relational representations. Graph-Structured Memory: Graph-structured memory represents information as nodes and edges capturing semantic, temporal, causal, or entitylevel relations, enabling reasoning over structured subgraphs (Zhang et al., 2025b,d; Jiang et al., 2026b; Tao et al., 2026; Zhang et al., 2026c; Hu et al., 2026b). This design supports multi-hop inference, provenance tracking, and coherent longhorizon reasoning. For example, MAGMA (Jiang et al., 2026a) organizes memory across semantic, temporal, causal, and entity graphs; Zep (Rasmussen et al., 2025) constructs bi-temporal knowledge graph with episodic and semantic layers; SGMem (Wu et al., 2025a) models dialogue as sentence-level graphs; and LatentGraphMem (Zhang et al., 2026c) integrates latent graph encoding with compact symbolic subgraph to balance stability, efficiency, and interpretability. OS-Inspired & Hierarchical Memory: OSinspired and hierarchical memory systems organize information into multi-tier storage layers (e.g., short-term, episodic, long-term), dynamically moving and consolidating data to balance scalability, retention, and adaptive forgetting (Xu, 2025; Ouyang, 2025; Zhang et al., 2025e; Jia et al., 2025; Li et al., 2026a). For example, MemGPT (Packer et al., 2023) enables LLM-driven memory paging across tiers; MemoryOS (Kang et al., 2025a) implements modular three-level hierarchy; EverMemOS (Hu et al., 2026a) and HiMem (Zhang et al., 2026a) consolidate episodic and semantic traces for longhorizon adaptation; and MeMAD (Ling et al., 2025) stores structured debate experiences for reusable reasoning. Policy-Optimized Memory Management: Policyoptimized memory management treats storage, update, consolidation, and deletion as learnable decisions, using reinforcement learning or hybrid training to optimize long-horizon rewards (Liu et al., 2025b; Xu et al., 2025b; Kang et al., 2025c; Du et al., 2025b). For example, MEM1 (Zhou et al., 2025b) learns to maintain compact internal state with constant-memory operations; and Mem-α (Wang et al., 2025b) trains an RL policy to manage multi-component external memory under ultra-long contexts; and AtomMem (Huo et al., 2026) decomposes memory into CRUD actions to learn task-aligned control strategies. While enabling adaptive and scalable management, these approaches introduce greater system complexity and nontrivial maintenance overhead. 3.5 Discussion The four categories described above capture the dominant memory structures used in contemporary MAG systems. While individual systems may combine multiple mechanisms, each can typically be characterized by primary memory organization that governs its behavior. This structure-first taxonomy provides foundation for understanding how design choices in agentic memory influence accuracy, efficiency, and reliability. In the next section, we build on this taxonomy to analyze the empirical limitations and pain points that arise across current MAG systems."
        },
        {
            "title": "4 Evaluation and Pain Points",
            "content": "In this section, we move beyond taxonomy to empirically analyze the practical bottlenecks hindering robust deployment. While theoretical architectures are promising, real world utility is strictly constrained by evaluation validity, system efficiency, and backbone reliability. We dissect these challenges across four critical dimensions: 1. Benchmark Validity: Are we testing memory or just context length? 2. Metric Reliability: Can lexical metrics capture semantic coherence? 3. System Efficiency: The Agency Tax of latency and cost. 4. Backbone Sensitivity: The Silent Failure of memory operations in open-weight models. 4.1 Experimental Setup We evaluate representative MAG systems spanning the four taxonomy categories introduced in Section 3. Five memory architectures are selected: LOCOMO (Maharana et al., 2024), AMem (Xu et al., 2025c), MemoryOS (Kang et al., 2025b), Nemori (Nan et al., 2025), and MAGMA (Jiang et al., 2026a) as shown in Table 8 of Appendix E. All systems are configured to follow their default or recommended settings, except where modifications are required to ensure comparability. We employ suite of Large Language Models (LLMs) to serve as the agent controller including gpt-4o-mini (Achiam et al., 2023) and Qwen-2.5-3B (Yang et al., 2024a). 4.2 Benchmark Scalability: The Context Saturation Risk key motivation for agentic memory is to support reasoning beyond models finite context window. Yet as LLM windows expand (e.g., 128k to 1M tokens), many benchmarks risk context saturation, where all relevant information fits within single prompt, making external memory seemingly unnecessary. In this section, rather than comparing performance, we examine the intrinsic properties of existing datasets to evaluate their continued validity in the long-context era. 4.2.1 Dimensions of Limitation First, we evaluate benchmark scalability along three structural axes: volume, interaction depth, and entity diversity, to assess their saturation risk under long-context LLMs as shown in Table 2. Volume (Total Token Load). This dimension captures the aggregate information size model must process. Benchmarks such as HotpotQA (1k tokens) and MemBench (100k tokens) fall within 128k context window, implying high theoretical saturation risk. LoCoMo (20k tokens) similarly remains comfortably in-window for modern models. Only datasets that substantially exceed the active window (e.g., LongMemEval-M at >1M tokens) structurally require external memory. Interaction Depth (Temporal Structure). Beyond raw volume, scalability depends on how information unfolds across sessions. Single-turn QA (e.g., HotpotQA) imposes minimal temporal dependency, whereas multi-session settings (e.g., LoCoMo with 35 sessions) introduce longitudinal reasoning. However, unless cross-session dependencies exceed the active window or require persistent state tracking beyond prompt capacity, such datasets may still be solvable through direct incontext aggregation rather than true memory management. Entity Diversity (Relational Complexity). This axis measures how many distinct entities or conceptual threads must be tracked simultaneously. Low-diversity benchmarks permit near-isolated retrieval, while higher-diversity settings (e.g., LoCoMo, LongMemEval) increase interference and relational reasoning demands. Nevertheless, if entity interactions remain bounded within context limits, structured external memory may not be strictly necessary. Discussion: Taken together, these dimensions show that saturation risk is determined not by surface difficulty but by whether benchmarks structural properties exceed the representational capacity of long-context LLMs. Table 2: Scalability and saturation risk. Benchmarks are analyzed based on their intrinsic statistics rather than model performance. Saturation Risk estimates the likelihood that long-context LLM (128k+) can solve the benchmark without external memory. High risk implies the benchmark may be invalid for testing agentic memory. Benchmark Scalability Dimensions Avg. Volume Interaction Depth Entity Diversity Theoretical Saturation Risk HotpotQA (Yang et al., 2018) LoCoMo (Maharana et al., 2024) LongMemEval-S (Wu et al., 2024) LongMemEval-M (Wu et al., 2024) MemBench (Tan et al., 2025a) 1k Tokens 20k Tokens 103k Tokens >1M Tokens 100k Tokens Single Turn 35 Sessions 5 Core Abilities 5 Core Abilities Fact/Reflection Low High High High Medium High (Trivial for Context Window) Moderate (Requires Reasoning) Moderate (Borderline) Low (Requires External Memory) High (Fits in 128k Window) 4.2.2 The Proposed \"Saturation Test\" Protocol To address these limitations, we propose that future evaluations explicitly quantify the Context Saturation Gap (), defined as the performance difference between Memory-Augmented Agent (MAG) and brute-force Full-Context baseline: = ScoreMAG ScoreFullContext (2) benchmark meaningfully evaluates agentic memory only when 0, indicating that the task exceeds the models effective context or attention capacity (e.g., true out-of-memory or lost-in-themiddle regimes), such that external memory provides structural advantage. Table 2 summarizes the saturation risk of existing benchmarks based on their statistical scale and structural properties. Datasets with limited volume and shallow complexity exhibit high saturation risk, suggesting they are increasingly inadequate for evaluating next-generation memory systems. 4.3 LLM-as-a-Judge Evaluation Traditional lexical metrics (e.g., F1, BLEU) emphasize surface-level token overlap, which is insufficient for agentic memory tasks where the goal is accurate retrieval and coherent synthesis rather than exact phrasing. To better capture semantic correctness, we adopt an LLM-based evaluator (gpt4o-mini) as proxy for human judgment. In this section, we assess the reliability of this protocol by analyzing the misalignment between lexical and semantic metrics and demonstrating the stability of our system rankings across competitive evaluation settings. 4.3.1 The Misalignment Gap Do lexical metrics correctly identify the best memory system? To examine this, we compared system rankings produced by F1-score with those generated by an LLM-based judge across five representative architectures on the LoCoMo dataset. Table 3 (Left) reveals significant disconnect. Lexical metrics often fail to capture the strengths of abstractive memory systems. For example, AMem achieves solid semantic performance (Rank 4 across prompts) due to its logical coherence, yet it is heavily penalized by F1 (Rank 5, Score 0.116) because it does not rely on verbatim overlap. In contrast, SimpleMem receives relatively higher F1 score (0.268) despite demonstrating limited ability to synthesize complex answers (semantic score < 0.30). This divergence indicates that optimizing solely for F1 may favor surface-level memorization over genuine reasoning and memory integration. 4.3.2 Semantic Judge Robustness Across Prompts common concern with LLM-as-a-judge is prompt overfitting, where system appears strong only under specific grading instruction. To ensure fairness and generality, we evaluated all architectures using three distinct prompt protocols derived from different sources (details in Appendix D.3). As shown in Table 3 (Right), compared with F1based rankings, the semantic judge exhibits strong robustness: the relative ordering of architectures remains highly consistent across different rubrics. While absolute scores fluctuate due to variations in grading strictness and prompt formulation, the comparative conclusions remain stable. 4.3.3 Discussion Lexical metrics provide convenient baseline but systematically diverge from semantic judgments due to two core failure modes: the Paraphrase Penalty, where correct abstractive answers are penalized for low token overlap, and the Negation Trap, where high overlap masks factual errors. Detailed examples are provided in Appendix F. In contrast, the semantic judge demonstrates greater stability: architecture rankings remain consistent across different grading rubrics, suggesting it better reflects underlying memory quality rather Table 3: Robustness of system ranking across evaluation protocols. We compare Lexical metrics (F1) against LLM-based semantic evaluation using three distinct prompt sources: MAGMA, Nemori, and SimpleMem. Method Lexical Metric F1-Score Rank Prompt 1 (MAGMA) Prompt 2 (Nemori) Prompt 3 (SimpleMem) Semantic Judge Score (Rank) AMem (Xu et al., 2025c) MemoryOS (Kang et al., 2025a) Nemori (Nan et al., 2025) MAGMA (Jiang et al., 2026a) SimpleMEM (Liu et al., 2026) 0.116 0.413 0.502 0.467 0.268 5 3 1 2 4 0.480 (4) 0.553 (3) 0.602 (2) 0.670 (1) 0.294 (5) 0.512 (4) 0.589 (3) 0.781 (1) 0.741 (2) 0.298 (5) 0.482 (4) 0.552 (3) 0.649 (2) 0.665 (1) 0.289 (5) than surface phrasing. Although absolute scores vary with prompt strictness and some models show rubric-aligned specialization, the relative ordering is robust. Table 4: Backbone Sensitivity Analysis. Frequency of recoverable format deviations during memory operations is used. Higher values indicate greater reliance on fallback parsing due to inconsistent structured outputs. Overall, these results support LLM-as-a-judge as more reliable evaluation protocol for agentic memory, while highlighting the importance of careful prompt design. Backbone Method Answer Score Format Error gpt-4o-mini Qwen-2.5-3B SimpleMem Nemori SimpleMem Nemori 0.289 0.781 0.102 0.447 1.20% 17.91% 4.82% 30.38% 4.4 Backbone Sensitivity and Format Stability Agentic memory requires the backbone model to both answer queries and execute structured memory operations (e.g., updates and consolidation). Long-term stability thus depends on reliable adherence to strict output formats. To evaluate this Stability Gap, we compare representative memory architectures using an API model (gpt-4o-mini) and an open-weight model (Qwen-2.5-3B). Table 4 reveals clear divergence driven by invalid structured outputs (e.g., malformed JSON, hallucinated keys) during memory maintenance: 1) Instruction Following vs. Reasoning: While Qwen-2.5-3B demonstrates basic capability in conversational reasoning, it experiences noticeable drop in End-Task Answer Scores and exhibits significantly higher format error rate during memory updates compared to gpt-4o-mini. This Silent Failure implies that while the agent can converse fluently in the short term, its long-term memory becomes corrupted due to failed write operations. 2) Method Sensitivity: The impact of the backbone varies by architecture complexity. Appendonly systems are relatively robust, as they require minimal structured generation. In contrast, graphbased and episodic architectures are highly sensitive: extracting entities, constructing relations, and performing logical deduplication significantly increase format errors under weaker backbones, often leading to structural instability or collapse in memory maintenance. 4.5 System Performance Evaluation While accuracy is critical, the practical viability of agentic memory is constrained by latency and cost. Unlike read-only RAG systems, agentic memory introduces continuous writeconsolidate lifecycle. We decompose system load into three phases: retrieval (Tread), covering search and traversal; generation (Tgen), including context processing and token decoding; and maintenance (Twrite), involving memory extraction and updates. In this section, we quantify user-facing latency (Tread + Tgen) and overall scalability using Table 5, and discuss the often-overlooked overhead introduced by maintenance operations. 4.5.1 Latency and Maintenance Trade-offs in MAG We analyze the end-to-end user-perceived latency (Tread+Tgen) alongside the often-overlooked maintenance overhead (Twrite). Although Full Context eliminates retrieval cost, it incurs the highest generation latency (Tgen 1.73s), confirming that large pre-fill computation increases timeto-first-token. Lightweight systems such as SimpleMem and LOCOMO achieve sub-second latency (< 1.1s) through efficient indexing, while MAGMA maintains balanced profile ( 1.46s), adding modest overhead for graph traversal. In contrast, MemoryOS emerges as clear bottleneck, with latency exceeding 32 seconds, suggesting that strict hierarchical paging (e.g., STMLTM recursion) is impractical for interactive settings. Beyond user-facing latency, the maintenance Table 5: The \"Agency Tax\": Efficiency Profiling. We evaluate the trade-off between runtime user latency and offline construction cost. User Latency(Tread + Tgen) dictates the interactive experience, while Construction Cost reflects the scalability and economic feasibility of the system. Note that Maintenance Cost is omitted as it is often handled asynchronously. Method User-Facing Latency (per turn) Construction Cost (Offline) Retrieval (Tread) Generation (Tgen) Total (s) Time (h) Tokens (k) Full Context LOCOMO (Maharana et al., 2024) AMem (Xu et al., 2025c) MemoryOS (Kang et al., 2025a) Nemori (Nan et al., 2025) MAGMA (Jiang et al., 2026a) SimpleMem (Liu et al., 2026) N/A 0.415 0.062 31.247 0.254 0.497 0.009 1.726 0.368 1.119 1.125 0.875 0.965 1.048 1.726 0.783 1.181 32.372 1.129 1.462 1.057 N/A 0.86 15.00 7.83 3.25 7.28 3.45 N/A 1,623 1,486 4,043 7,044 2,725 1,308 phase (Twrite) introduces hidden scalability constraint. Append-only systems incur minimal update cost, whereas structured architectures (e.g., MAGMA, AMem) require graph restructuring and LLM-driven consolidation after each interaction. Although often asynchronous, excessive maintenance time risks throughput collapse, where updates lag behind user interactions and memory becomes stale. Thus, while structured memory improves reasoning quality, it demands robust asynchronous infrastructure to remain viable at scale. 4.5.2 Offline Scalability: Time and Token Economics Beyond online latency, we evaluate the offline cost of building the memory index. AMem requires approximately 15 hours for construction far slower than other baselines, suggesting super-linear update complexity (e.g., pairwise consolidation) that limits scalability on large datasets. Token consumption further exposes cost tradeoffs. Nemori uses over 7.04M tokens during index construction, nearly five times that of SimpleMem (1.3M). Although this yields strong accuracy, it reflects substantial intelligence tax, where improved memory quality incurs significantly higher operational cost. In comparison, MAGMA achieves more favorable Pareto balance, delivering robust performance with moderate token usage (2.7M)."
        },
        {
            "title": "5 Conclusion and Future Directions",
            "content": "Our analysis suggests that the main bottlenecks of agentic memory lie less in architectural novelty and more in evaluation validity and system scalability. We highlight two key directions for progress. 1. Rethinking Benchmark and Evaluation Design. Many current benchmarks fail to stress the structural necessity of memory. As context windows expand, tasks increasingly fall into saturation regime where full-context baselines suffice. Future benchmarks should be saturation-aware: task volume, temporal depth, and entity diversity must exceed what can be solved within single prompt. The proposed Context Saturation Gap () provides principled test of whether external memory offers real structural benefit. Evaluation should also move beyond lexical overlap. F1-style metrics poorly capture semantic correctness and structural coherence. Although LLM-as-a-judge is more aligned with semantic quality, prompt calibration and multi-rubric robustness checks are essential to avoid bias. Ultimately, benchmarks must test whether memory is necessary, not just whether answers are fluent. 2. Designing Scalable and Robust Agentic Memory Systems. Agentic memory involves tradeoffs among accuracy, latency, cost, and reliability. Structured memory enhances reasoning but increases maintenance overhead and format sensitivity, while lightweight approaches favor efficiency with limited abstraction. Future systems must optimize across these axes. Memory operations should be backbone-aware, with constrained decoding or validation layers to reduce silent corruption. Maintenance throughput and write latency must be explicitly modeled to prevent system overload. Finally, memory schemas should become adaptive rather than fixed, enabling evolution across domains. In short, the future of agentic memory lies in balancing reasoning power with operational sustainability, treating memory design as joint optimization of accuracy, cost, and stability."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, and 1 others. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Alen Adamyan, Tomáš ˇCížek, Matej Straka, Klara Janouskova, and Martin Schmid. 2025. Sam2rl: Towards reinforcement learning memory control arXiv preprint in segment anything model 2. arXiv:2507.08548. Iz Beltagy, Matthew Peters, and Arman Cohan. 2020. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, and 1 others. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901. Linyue Cai, Yuyang Cheng, Xiaoding Shao, Huiming Wang, Yong Zhao, Wei Zhang, and Kang Li. 2025. scenario-driven cognitive approach arXiv preprint to next-generation ai memory. arXiv:2509.13235. Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, and Hai Zhao. 2025. Remember me, refine me: dynamic procedural memory framework for experience-driven agent evolution. arXiv preprint arXiv:2512.10696. Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, and 1 others. 2025. Iterresearch: Rethinking long-horizon agents via markovian state reconstruction. arXiv preprint arXiv:2511.07327. Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh, and Deshraj Yadav. 2025. Mem0: Building production-ready ai agents with scalable long-term memory. arXiv preprint arXiv:2504.19413. Cody Dong, Qihong Lu, Kenneth Norman, and Sebastian Michelmann. 2025. Towards large language models with human-like episodic memory. Trends in Cognitive Sciences. Xingbo Du, Loka Li, Duzhen Zhang, and Le Song. 2025a. MemR3: Memory retrieval via reflecarXiv preprint tive reasoning for LLM agents. arXiv:2512.20237. Yiming Du, Baojun Wang, Yifan Xiang, Zhaowei Wang, Wenyu Huang, Boyang Xue, Bin Liang, Xingshan Zeng, Fei Mi, Haoli Bai, and 1 others. 2025b. Memory-t1: Reinforcement learning for temporal reasoning in multi-session agents. arXiv preprint arXiv:2512.20092. Wenzhe Fan, Ning Yan, and Masood Mortazavi. 2025. Evomem: Improving multi-agent planning with dualevolving memory. arXiv preprint arXiv:2511.01912. Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu, Shumin Deng, Yunzhi Yao, Mengru Wang, Shuofei Qiao, and 1 others. 2025a. Lightmem: Lightweight and efficient arXiv preprint memory-augmented generation. arXiv:2510.18866. Runnan Fang, Yuan Liang, Xiaobin Wang, Jialong Wu, Shuofei Qiao, Pengjun Xie, Fei Huang, Huajun Chen, and Ningyu Zhang. 2025b. Memp: Exploring agent procedural memory. arXiv preprint arXiv:2508.06433. Dongge Han, Camille Couturier, Daniel Madrigal Diaz, Xuchao Zhang, Victor Rühle, and Saravan Rajmohan. 2025. Legomem: Modular procedural memory for multi-agent llm systems for workflow automation. arXiv preprint arXiv:2510.04851. Chuanrui Hu, Xingze Gao, Zuyi Zhou, Dannong Xu, Yi Bai, Xintong Li, Hui Zhang, Tong Li, Chong Zhang, Lidong Bing, and 1 others. 2026a. Evermemos: self-organizing memory operating system for structured long-horizon reasoning. arXiv preprint arXiv:2601.02163. Yuyang Hu, Jiongnan Liu, Jiejun Tan, Yutao Zhu, and Zhicheng Dou. 2026b. Memory matters more: Eventcentric memory as logic map for agent searching and reasoning. arXiv preprint arXiv:2601.04726. Yuyang Hu, Shichun Liu, Yanwei Yue, Guibin Zhang, Boyang Liu, Fangyi Zhu, Jiahang Lin, Honglin Guo, Shihan Dou, Zhiheng Xi, and 1 others. 2025. Memory in the age of ai agents. arXiv preprint arXiv:2512.13564. Wei-Chieh Huang, Weizhi Zhang, Yueqing Liang, Yuanchen Bei, Yankai Chen, Tao Feng, Xinyu Pan, Zhen Tan, Yu Wang, Tianxin Wei, and 1 others. 2026. Rethinking memory mechanisms of foundation agents in the second half. arXiv preprint arXiv:2602.06052. Yizhe Huang, Yang Liu, Ruiyu Zhao, Xiaolong Zhong, Xingming Yue, and Ling Jiang. 2025a. Memorb: plug-and-play verbal-reinforcement memory layer for e-commerce customer service. arXiv preprint arXiv:2509.18713. Zhengjun Huang, Zhoujin Tian, Qintian Guo, Fangyuan Zhang, Yingli Zhou, Di Jiang, Zeying Xie, and Xiaofang Zhou. 2025b. Licomemory: Lightweight and cognitive agentic memory for efficient long-term reasoning. arXiv preprint arXiv:2511.01448. Yupeng Huo, Yaxi Lu, Zhong Zhang, Haotian Chen, and Yankai Lin. 2026. Atommem: Learnable dynamic agentic memory with atomic memory operation. arXiv preprint arXiv:2601.08323. Rodrigo Toro Icarte, Richard Valenzano, Toryn Klassen, Phillip Christoffersen, Amir-massoud Farahmand, and Sheila McIlraith. 2020. The act of remembering: study in partially observable reinforcement learning. arXiv preprint arXiv:2010.01753. Shian Jia, Ziyang Huang, Xinbo Wang, Haofei Zhang, and Mingli Song. 2025. Pisa: pragmatic psychinspired unified memory system for enhanced ai agency. arXiv preprint arXiv:2510.15966. Zixia Jia, Jiaqi Li, Yipeng Kang, Yuxuan Wang, Tong Wu, Quansen Wang, Xiaobo Wang, Shuyi Zhang, Junzhe Shen, Qing Li, and 1 others. 2026. The ai hippocampus: How far are we from human memory? arXiv preprint arXiv:2601.09113. Dongming Jiang, Yi Li, Guanpeng Li, and Bingzhe Li. 2026a. Magma: multi-graph based agentic memory architecture for ai agents. arXiv preprint arXiv:2601.03236. Hanqi Jiang, Junhao Chen, Yi Pan, Ling Chen, Weihang You, Yifan Zhou, Ruidong Zhang, Yohannes Abate, and Tianming Liu. 2026b. Synapse: Empowering llm agents with episodic-semantic memory via spreading activation. arXiv preprint arXiv:2601.02744. Jiazheng Kang, Mingming Ji, Zhe Zhao, and Ting Bai. 2025a. Memory os of ai agent. arXiv preprint arXiv:2506.06326. Jiazheng Kang, Mingming Ji, Zhe Zhao, and Ting Bai. 2025b. Memory os of ai agent. arXiv preprint arXiv:2506.06326. Jikun Kang, Wenqi Wu, Filippos Christianos, Alex James Chan, Fraser David Greenlee, George Thomas, Marvin Purtorab, and Andrew Toulis. 2025c. Lm2: Large memory models for long context reasoning. In Workshop on Reasoning and Planning for Large Language Models. Minki Kang, Wei-Ning Chen, Dongge Han, Huseyin Inan, Lukas Wutschitz, Yanzhi Chen, Robert Sim, and Saravan Rajmohan. 2025d. Acon: Optimizing context compression for long-horizon llm agents. arXiv preprint arXiv:2510.00615. Sangyeop Kim, Yohan Lee, Sanghwa Kim, Hyunjong Kim, and Sungzoon Cho. 2025. Pre-storage reasoning for episodic memory: Shifting inference burden to memory for personalized dialogue. arXiv preprint arXiv:2509.10852. Kuang-Huei Lee, Xinyun Chen, Hiroki Furuta, John Canny, and Ian Fischer. 2024. human-inspired reading agent with gist memory of very long contexts. arXiv preprint arXiv:2402.09727. Haichang Li. 2025. Memory as service (maas): Rethinking contextual memory as service-oriented modules for collaborative agents. arXiv preprint arXiv:2506.22815. Hao Li, Chenghao Yang, An Zhang, Yang Deng, Xiang Wang, and Tat-Seng Chua. 2025a. Hello again! llm-powered personalized agent for long-term dialogue. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 5259 5276. Kai Li, Xuanqing Yu, Ziyi Ni, Yi Zeng, Yao Xu, Zheqing Zhang, Xin Li, Jitao Sang, Xiaogang Duan, Xuelei Wang, and 1 others. 2026a. Timem: Temporal-hierarchical memory consolidation for long-horizon conversational agents. arXiv preprint arXiv:2601.02845. Yi Li, Lianjie Cao, Faraz Ahmed, Puneet Sharma, and Bingzhe Li. 2026b. Hippocampus: An efficient and scalable memory module for agentic ai. Preprint, arXiv:2602.13594. Zhiyu Li, Chenyang Xi, Chunyu Li, Ding Chen, Boyu Chen, Shichao Song, Simin Niu, Hanyu Wang, Jiawei Yang, Chen Tang, and 1 others. 2025b. Memos: memory os for ai system. arXiv preprint arXiv:2507.03724. Zouying Cao Li Yu, Jiaji Deng. 2025. Agentscopereme: Memory management kit for agents. Shuai Ling, Lizi Liao, Dongmei Jiang, and Weili Guan. 2025. Memad: Structured memory of debates for enhanced multi-agent reasoning. In Second Conference on Language Modeling. Genglin Liu, Shijie Geng, Sha Li, Hejie Cui, Sarah Zhang, Xin Liu, and Tianyi Liu. 2025a. Webcoach: Self-evolving web agents with cross-session memory guidance. arXiv preprint arXiv:2511.12997. Jiaqi Liu, Yaofeng Su, Peng Xia, Siwei Han, Zeyu Zheng, Cihang Xie, Mingyu Ding, and Huaxiu Yao. 2026. Simplemem: Efficient lifelong memory for llm agents. arXiv preprint arXiv:2601.02553. Taeyoon Kwon, Dongwook Choi, Hyojun Kim, Sunghwan Kim, Seungjun Moon, Beong-woo Kwak, KuanHao Huang, and Jinyoung Yeo. 2025. Embodied agents meet personalization: Investigating challenges and solutions through the lens of memory utilization. arXiv preprint arXiv:2505.16348. Jun Liu, Zhenglun Kong, Changdi Yang, Fan Yang, Tianqi Li, Peiyan Dong, Joannah Nanjekye, Hao Tang, Geng Yuan, Wei Niu, and 1 others. 2025b. Rcrrouter: Efficient role-aware context routing for multiagent llm systems with structured memory. arXiv preprint arXiv:2508.04903. Chris Latimer, Nicoló Boschi, Andrew Neeser, Chris Bartholomew, Gaurav Srivastava, Xuan Wang, and Naren Ramakrishnan. 2025. Hindsight is 20/20: Building agent memory that retains, recalls, and reflects. arXiv preprint arXiv:2512.12818. Nelson Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024. Lost in the middle: How language models use long contexts. Transactions of the Association for Computational Linguistics, 12:157173. Xinxin Liu, Weizhen Li, Weichen Sun, Xinlong Yang, Tianrui Qin, Xitong Gao, and Wangchunshu Zhou. 2025c. Compressed step information memory for end-to-end agent foundation models. Nazmus Sakib, Protoy Barai, Sifat Ishmam Parisa, and Anindya Iqbal. 2025. Memagent: cache-inspired framework for augmenting conversational web agents with task-specific information. Yaoyao Liu, Bernt Schiele, and Qianru Sun. 2021. Rmm: Reinforced memory management for classincremental learning. Advances in neural information processing systems, 34:34783490. Jinghao Luo, Yuchen Tian, Chuxue Cao, Ziyang Luo, Hongzhan Lin, Kaixin Li, Chuyi Kong, Ruichao Yang, and Jing Ma. 2026. From storage to experience: survey on the evolution of llm agent memory mechanisms. Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, and Yuwei Fang. 2024. Evaluating very long-term converarXiv preprint sational memory of llm agents. arXiv:2402.17753. Wenyu Mao, Haosong Tan, Shuchang Liu, Haoyang Liu, Yifan Xu, Huaxiang Ji, and Xiang Wang. 2026. Bi-mem: Bidirectional construction of hierarchical memory for personalized llms via inductive-reflective agents. arXiv preprint arXiv:2601.06490. Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, and Hinrich Schütze. 2023. Ret-llm: Towards general read-write memory for large language models. arXiv preprint arXiv:2305.14322. Hyungho Na, Yunkyeong Seo, and Il-chul Moon. 2024. Efficient episodic memory utilization of cooperative multi-agent reinforcement learning. arXiv preprint arXiv:2403.01112. Jiayan Nan, Wenquan Ma, Wenlong Wu, and Yize Chen. 2025. Nemori: Self-organizing agent memory inspired by cognitive science. arXiv preprint arXiv:2508.03341. Leyi Ouyang. 2025. Can memory-augmented llm agents aid journalism in interpreting and framarXiv preprint ing news for diverse audiences? arXiv:2507.21055. Siru Ouyang, Jun Yan, Hsu, Yanfei Chen, Ke Jiang, Zifeng Wang, Rujun Han, Long Le, Samira Daruki, Xiangru Tang, and 1 others. 2025. Reasoningbank: Scaling agent self-evolving with reasoning memory. arXiv preprint arXiv:2509.25140. Charles Packer, Vivian Fang, Shishir_G Patil, Kevin Lin, Sarah Wooders, and Joseph_E Gonzalez. 2023. Memgpt: Towards llms as operating systems. Ofir Press, Noah Smith, and Mike Lewis. 2021. Train short, test long: Attention with linear biases enables input length extrapolation. arXiv preprint arXiv:2108.12409. Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, and Daniel Chalef. 2025. Zep: temporal knowledge graph architecture for agent memory. arXiv preprint arXiv:2501.13956. Miao Su, Yucan Guo, Zhongni Hou, Long Bai, Zixuan Li, Yufei Zhang, Guojun Yin, Wei Lin, Xiaolong Jin, Jiafeng Guo, and 1 others. 2026. Beyond dialogue time: Temporal semantic memory for personalized llm agents. arXiv preprint arXiv:2601.07468. Haoran Sun, Zekun Zhang, and Shaoning Zeng. 2025a. Preference-aware memory update for long-term llm agents. arXiv preprint arXiv:2510.09720. Weiwei Sun, Miao Lu, Zhan Ling, Kang Liu, Xuesong Yao, Yiming Yang, and Jiecao Chen. 2025b. Scaling long-horizon llm agent via context-folding. arXiv preprint arXiv:2510.11967. Haoran Tan, Zeyu Zhang, Chen Ma, Xu Chen, Quanyu Dai, and Zhenhua Dong. 2025a. Membench: Towards more comprehensive evaluation on the memory of llm-based agents. arXiv preprint arXiv:2506.21605. Zhen Tan, Jun Yan, I-Hung Hsu, Rujun Han, Zifeng Wang, Long Le, Yiwen Song, Yanfei Chen, Hamid Palangi, George Lee, and 1 others. 2025b. In prospect and retrospect: Reflective memory management for long-term personalized dialogue agents. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 84168439. Xiangru Tang, Tianrui Qin, Tianhao Peng, Ziyang Zhou, Daniel Shao, Tingting Du, Xinming Wei, He Zhu, Ge Zhang, Jiaheng Liu, and 1 others. Agent kb: hierarchical memory framework for cross-domain agentic problem solving. In ICML 2025 Workshop on Collaborative and Federated Agentic Workflows. Dehao Tao, Guoliang Ma, Yongfeng Huang, and Minghu Jiang. 2026. Membox: Weaving topic continuity into long-range memory for llm agents. arXiv preprint arXiv:2601.03785. He Wang, Wenyilin Xiao, Songqiao Han, and Hailiang Huang. 2025a. Stockmem: An event-reflection memory framework for stock forecasting. arXiv preprint arXiv:2512.02720. Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and Ming Zhou. 2020. Minilm: Deep selfattention distillation for task-agnostic compression of pre-trained transformers. Advances in neural information processing systems, 33:57765788. Yu Wang and Xi Chen. 2025. Mirix: Multi-agent memory system for llm-based agents. arXiv preprint arXiv:2507.07957. Yu Wang, Ryuichi Takanobu, Zhiqi Liang, Yuzhen Mao, Yuanzhe Hu, Julian McAuley, and Xiaojian Wu. 2025b. Mem-{alpha}: Learning memory construction via reinforcement learning. arXiv preprint arXiv:2509.25911. Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, and Yiming Gan. 2025c. Karma: Augmenting embodied ai agents with long-and-short term memory systems. In 2025 IEEE International Conference on Robotics and Automation (ICRA), pages 18. IEEE. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, and 1 others. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824 24837. Chao Wu and Gang Li. 2025. Enhancing generative agents in social simulations: Bridging memory, emotion, and governance for realistic social simuIn Intelligent Systems Conference, pages lations. 5059. Springer. Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, and Dong Yu. 2024. Longmemeval: Benchmarking chat assistants on long-term interactive memory. arXiv preprint arXiv:2410.10813. Yaxiong Wu, Yongyue Zhang, Sheng Liang, and Yong Liu. 2025a. Sgmem: Sentence graph memory for arXiv preprint long-term conversational agents. arXiv:2509.21212. Zijun Wu, Yongchang Hao, and Lili Mou. 2025b. Tokmem: Tokenized procedural memory for large language models. arXiv preprint arXiv:2510.00444. Derong Xu, Yi Wen, Pengyue Jia, Yingyi Zhang, Yichao Wang, Huifeng Guo, Ruiming Tang, Xiangyu Zhao, Enhong Chen, Tong Xu, and 1 others. 2025a. From single to multi-granularity: Toward long-term memory association and selection of conversational agents. arXiv preprint arXiv:2505.19549. Haoran Xu, Jiacong Hu, Ke Zhang, Lei Yu, Yuxin Tang, Xinyuan Song, Yiqun Duan, Lynn Ai, and Sedm: Scalable self-evolving Bill Shi. 2025b. arXiv preprint distributed memory for agents. arXiv:2509.09498. Jiexi Xu. 2025. Memory management and contextual consistency for long-running low-code agents. arXiv preprint arXiv:2509.25250. Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, and Yongfeng Zhang. 2025c. A-mem: Agentic memory for llm agents. arXiv preprint arXiv:2502.12110. Sikuan Yan, Xiufeng Yang, Zuchao Huang, Ercong Nie, Zifeng Ding, Zonggen Li, Xiaowen Ma, Kristian Kersting, Jeff Pan, Hinrich Schütze, and 1 others. 2025. Memory-r1: Enhancing large language model agents to manage and utilize memories via reinforcement learning. arXiv preprint arXiv:2508.19828. An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, and 1 others. 2024a. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115. Chang Yang, Chuang Zhou, Yilin Xiao, Su Dong, Luyao Zhuang, Yujing Zhang, Zhu Wang, Zijin Hong, Zheng Yuan, Zhishang Xiang, and 1 others. 2026a. Graph-based agent memory: Taxonomy, techniques, and applications. arXiv preprint arXiv:2602.05665. Chengyuan Yang, Zequn Sun, Wei Wei, and Wei Hu. 2026b. Beyond static summarization: Proactive memory extraction for llm agents. arXiv preprint arXiv:2601.04463. Hongkang Yang, Zehao Lin, Wenjin Wang, Hao Wu, Zhiyu Li, Bo Tang, Wenqiang Wei, Jinbo Wang, Zeyun Tang, Shichao Song, and 1 others. 2024b. memory3: Language modeling with explicit memory. arXiv preprint arXiv:2407.01178. Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu, Yuchen Fan, Qianshan Wei, Rui Ye, Li Kang, Yiran Qin, and 1 others. 2026c. Toward efficient agents: Memory, tool learning, and planning. arXiv preprint arXiv:2601.14192. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher Manning. 2018. Hotpotqa: dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 conference on empirical methods in natural language processing, pages 23692380. Yiqun Yao, Naitong Yu, Xiang Li, Xin Jiang, Xuezhi Fang, Wenjia Ma, Xuying Meng, Jing Li, Aixin Sun, and Yequan Wang. 2025. Egomem: Lifelong memory agent for full-duplex omnimodal models. arXiv preprint arXiv:2509.11914. Rui Ye, Zhongwang Zhang, Kuan Li, Huifeng Yin, Zhengwei Tao, Yida Zhao, Liangcai Su, Liwen Zhang, Zile Qiao, Xinyu Wang, and 1 others. 2025. Agentfold: Long-horizon web agents with arXiv preprint proactive context management. arXiv:2510.24699. Hongli Yu, Tinghong Chen, Jiangtao Feng, Jiangjie Chen, Weinan Dai, Qiying Yu, Ya-Qin Zhang, WeiYing Ma, Jingjing Liu, Mingxuan Wang, and 1 others. 2025. Memagent: Reshaping long-context llm with multi-conv rl-based memory agent. arXiv preprint arXiv:2507.02259. Qianhao Yuan, Jie Lou, Zichao Li, Jiawei Chen, Yaojie Lu, Hongyu Lin, Le Sun, Debing Zhang, and Xianpei Han. 2025. Memsearcher: Training llms to reason, search and manage memory via end-to-end reinforcement learning. arXiv preprint arXiv:2511.02805. Dell Zhang, Yue Feng, Haiming Liu, Changzhi Sun, Jixiang Luo, Xiangyu Chen, and Xuelong Li. 2025a. Conversational agents: From rag to ltm. In Proceedings of the 2025 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region, pages 447452. Zijian Zhou, Ao Qu, Zhaoxuan Wu, Sunghwan Kim, Alok Prakash, Daniela Rus, Jinhua Zhao, Bryan Kian Hsiang Low, and Paul Pu Liang. 2025b. Mem1: Learning to synergize memory and reasoning for efficient long-horizon agents. arXiv preprint arXiv:2506.15841. Yuanjie Zhu, Liangwei Yang, Ke Xu, Weizhi Zhang, Zihe Song, Jindong Wang, and Philip Yu. 2025. Llm-memcluster: Empowering large language models with dynamic memory for text clustering. arXiv preprint arXiv:2511.15424. Guibin Zhang, Muxin Fu, Guancheng Wan, Miao Yu, Kun Wang, and Shuicheng Yan. 2025b. G-memory: Tracing hierarchical memory for multi-agent systems. arXiv preprint arXiv:2506.07398. Guibin Zhang, Muxin Fu, and Shuicheng Yan. 2025c. Memgen: Weaving generative latent memory for selfevolving agents. arXiv preprint arXiv:2509.24704. Kai Zhang, Xinyuan Zhang, Ejaz Ahmed, Hongda Jiang, Caleb Kumar, Kai Sun, Zhaojiang Lin, Sanat Sharma, Shereen Oraby, Aaron Colak, and 1 others. 2025d. Assomem: Scalable memory qa with multi-signal associative retrieval. arXiv preprint arXiv:2510.10397. Ningning Zhang, Xingxing Yang, Zhizhong Tan, Weiping Deng, and Wenyong Wang. 2026a. Himem: Hierarchical long-term memory for llm long-horizon agents. arXiv preprint arXiv:2601.06377. Shengtao Zhang, Jiaqian Wang, Ruiwen Zhou, Junwei Liao, Yuchen Feng, Weinan Zhang, Ying Wen, Zhiyu Li, Feiyu Xiong, Yutao Qi, and 1 others. 2026b. Memrl: Self-evolving agents via runtime reinforcement learning on episodic memory. arXiv preprint arXiv:2601.03192. Xin Zhang, Kailai Yang, Hao Li, Chenyue Li, Qiyu Wei, and Sophia Ananiadou. 2026c. Implicit graph, explicit retrieval: Towards efficient and interpretable long-horizon memory for large language models. arXiv preprint arXiv:2601.03417. Yiran Zhang, Jincheng Hu, Mark Dras, and Usman Naseem. 2025e. Cogmem: cognitive memory architecture for sustained multi-turn reasoning in large language models. arXiv preprint arXiv:2512.14118. Yuxiang Zhang, Jiangming Shu, Ye Ma, Xueyuan Lin, Shangxi Wu, and Jitao Sang. 2025f. Memory as action: Autonomous context curation for long-horizon agentic tasks. arXiv preprint arXiv:2510.12635. Xinkui Zhao, Qingyu Ma, Yifan Zhang, Hengxuan Lou, Guanjie Cheng, Shuiguang Deng, and Jianwei Yin. 2025. Ame: An efficient heterogeneous agentic memory engine for smartphones. arXiv preprint arXiv:2511.19192. Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. 2024. Memorybank: Enhancing large language models with long-term memory. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 1972419731. Huichi Zhou, Yihang Chen, Siyuan Guo, Xue Yan, Kin Hei Lee, Zihan Wang, Ka Yiu Lee, Guchun Zhang, Kun Shao, Linyi Yang, and 1 others. 2025a. Memento: Fine-tuning llm agents without fine-tuning llms. arXiv preprint arXiv:2508.16153. Sizhe Zhou and Jiawei Han. 2025. simple yet strong baseline for long-term conversational memory of llm agents. arXiv preprint arXiv:2511.17208."
        },
        {
            "title": "A Taxonomy of Agentic Memory",
            "content": "Figure 1 provides comprehensive visual taxonomy of recent advancements in MemoryAugmented Generation (MAG). Given the rapid proliferation of memory architectures for LLM agents, this tree diagram categorizes contemporary literature into four distinct structural paradigms:"
        },
        {
            "title": "B Agentic Memory Background",
            "content": "B.1 Memory Operations in Agentic Systems We characterize agentic memory as an external, non-parametric subsystem that interacts with an agent through two coupled processes: inferencetime recall (reading memory to condition decisions) and memory update (writing, consolidating, and forgetting to maintain useful long-term store). Let fθ denote frozen foundation model (or policy model) with parameters θ, and let Mt denote the external memory state at step t. Given an observation ot (e.g., user input, tool output, sensor data) and agent state st (e.g., goals, plans, tool traces), the agent first produces query qt and recalls relevant memory: qt = Query(ot, st), rt = Read(Mt, qt). (3) (4) The retrieved content rt is then integrated into the model input to produce an action or response: (cid:17) (cid:16) at πθ(ot, rt, st) = fθ ϕ(ot, st) ψ(rt) , (5) where ϕ() formats current context, ψ() formats retrieved memory, and denotes an integration operator (e.g., concatenation, schema-based slots, or cross-modal fusion). This abstraction makes explicit that agentic memory influences behavior through an external recall term rather than by updating θ. Inference-time retrieval as approximate utility optimization. External memory retrieval typically selects items {mi}N i=1 from Mt using scoring function (dense similarity, sparse matching, or reranking). common instantiation is top-k recall: rt = TopK (cid:16) {mi}N i=1; score(qt, mi), (cid:17) . (6) However, in agentic settings, the ideal relevance is not purely semantic but decision-conditional. One can express an idealized retrieval objective as selecting memory that maximizes downstream utility: = arg max rMt E(cid:2) (at ot, r, st) (cid:3), (7) where () denotes agent utility (e.g., task success, efficiency, robustness). Practical systems approximate (7) using similarity search, learned rerankers, multi-hop retrieval, planner-guided recall, or retrieval policies trained to better align score() with utility. Memory update as explicit memory actions. After producing an action at (and possibly observing its outcome), the agent updates external memory through write function: Mt+1 = Write(Mt, ot, at, st). (8) It is often useful to make updates explicit as memory actions. Let ut denote memory action such as STORE, UPDATE, SUMMARIZE, LINK, EVICT, or DELETE. Then: ut = g(ot, at, st), Mt+1 = (Mt, ut), (9) where g() may be rule-based, model-driven, or learned, and applies the chosen action to the memory store. This view connects naturally to RLguided memory, where g() can be optimized as policy over memory actions."
        },
        {
            "title": "C Related Work",
            "content": "Several recent surveys have examined memory mechanisms for Agentic AI systems, each from distinct vantage point. The AI Hippocampus (Jia et al., 2026) presents broad synthesis organized around brain-inspired trichotomy of implicit memory, explicit memory, and agentic memory, further extending the analysis to multimodal settings involving vision, audio, and embodied interaction. Memory in the Age of AI Agents (Hu et al., 2025) proposes formsfunctionsdynamics framework that categorizes agent memory along three orthogonal axes: architectural form, functional role, and lifecycle dynamics, providing comprehensive conceptual vocabulary for the rapidly fragmenting landscape of agent memory research. Toward Efficient Agents (Yang et al., 2026c) shifts the focus from architectural expressiveness to deployment cost, surveying efficiency-oriented techniques across three core agent components: memory, tool learning, and planning. In addition, this ) ( t n e m - m RL-Optimized Semantic Compression MemAgent (Yu et al., 2025), MemSearcher (Yuan et al., 2025), Mem-α (Wang et al., 2025b), Memory-R1 (Yan et al., 2025) Lightweight Semantic Memory Context Window Management Heuristic / Prompt-Optimized AgentFold (Ye et al., 2025), Context-Folding Agent (Sun et al., 2025b), LLMMemCluster (Zhu et al., 2025), MemAgent-Cache (Sakib et al., 2025), Lightmem (Fang et al., 2025a), Lm2 (Kang et al., 2025c), RCR-Router (Liu et al., 2025b) SimpleMem (Liu et al., 2026), ACON (Kang et al., 2025d), CISM (Liu et al., 2025c), AME (Zhao et al., 2025), CogMem (Zhang et al., 2025e), Pisa (Jia et al., 2025), Memento (Zhou et al., 2025a) Token-Level Semantic Memory TokMem (Wu et al., 2025b), MemGen (Zhang et al., 2025c), Memory3 (Yang et al., 2024b) Entity-Centric & Personalized Memory Entity-Centric Memory Personalized Memory RET-LLM (Modarressi et al., 2023), A-MEM (Xu et al., 2025c), Memory-R1 (Yan et al., 2025), Mem0 (Chhikara et al., 2025), RMM (Liu et al., 2021), WebCoach (Liu et al., 2025a), MEM1 (Zhou et al., 2025b) PAMU (Sun et al., 2025a), EgoMem (Yao et al., 2025), MemOrb (Huang et al., 2025a), WebCoach (Liu et al., 2025a), MemoryBank (Zhong et al., 2024), Hello Again (Li et al., 2025a), O-Mem (Wang et al., 2025b), Embodied Agents (Kwon et al., 2025), Bi-Mem (Mao et al., 2026), Beyond Dialogue Time (Su et al., 2026) Episodic Buffer with Learned Control MemR3 (Du et al., 2025a), MemAct (Zhang et al., 2025f), Act of Remembering (Icarte et al., 2020) Episodic & Reflective Memory Episodic Reflection & Consolidation In Prospect & Retrospect (Tan et al., 2025b), TiMem (Li et al., 2026a), Memp (Fang et al., 2025b), Pre-Storage Reasoning (Kim et al., 2025), Nemori (Nan et al., 2025), LEGOMem (Han et al., 2025), ReasoningBank (Ouyang et al., 2025), ReadAgent (Lee et al., 2024), ProMem (Yang et al., 2026b), Human-like Episodic Memory (Dong et al., 2025) Episodic Recall for Exploration EMU (Na et al., 2024), SAM2RL (Adamyan et al., 2025) Episodic Utility Learning MemRL (Zhang et al., 2026b), Memory-T1 (Du et al., 2025b), Memento (Zhou et al., 2025a), Remember Me Refine Me (Cao et al., 2025) Graph-Structured Memory Structured & Hierarchical Memory OS-Inspired & Hierarchical Memory Policy-Optimized Memory Management MAGMA (Jiang et al., 2026a), Zep (Rasmussen et al., 2025), SGMem (Wu et al., 2025a), SYNAPSE (Jiang et al., 2026b), LatentGraphMem (Zhang et al., 2026c), LiCoMemory (Huang et al., 2025b), Hindsight (Latimer et al., 2025), Simple Baseline (Zhou and Han, 2025), Multi-Granularity (Xu et al., 2025a), StockMem (Wang et al., 2025a), G-Memory (Zhang et al., 2025b), Membox (Tao et al., 2026), Memory Matters More (Hu et al., 2026b), AssoMem (Zhang et al., 2025d) MemGPT (Packer et al., 2023), MemoryOS (Kang et al., 2025a), EverMemOS (Hu et al., 2026a), HiMem (Zhang et al., 2026a), MeMAD (Ling et al., 2025), Mirix (Wang and Chen, 2025), Scenario-Driven (Cai et al., 2025), ReMe (Li Yu, 2025), LightMem (Fang et al., 2025a), RAG-to-LTM (Zhang et al., 2025a), MemOS (Li et al., 2025b), EvoMem (Fan et al., 2025), AGENT KB (Tang et al.), KARMA (Wang et al., 2025c), MaaS (Li, 2025), CogMem (Zhang et al., 2025e), PISA (Jia et al., 2025), Memory3 (Yang et al., 2024b),MADES (Ouyang, 2025), TiMem (Li et al., 2026a), (Xu, 2025) MEM1 (Zhou et al., 2025b), Mem-α (Wang et al., 2025b), AtomMem (Huo et al., 2026), SEDM (Xu et al., 2025b), Memory-R1 a(Yan et al., 2025), Memory-T1 (Du et al., 2025b), IterResearch (Chen et al., 2025), RCR-Router (Liu et al., 2025b), LM2 (Kang et al., 2025c) Figure 1: Taxonomy of Memory-Augmented Generation (MAG) systems. survey discusses compression, context management, and reinforcement-learning-based reward design as shared principles to reduce latency, token consumption, and interaction steps. More recently, Rethinking Memory Mechanisms (Huang et al., 2026) assembles large-scale survey of over 200 papers, organizing memory along three dimensions: substrate, cognitive mechanism, and subject, while reviewing learning policies over memory operations and cataloguing existing evaluation benchmarks. From Storage to Experience (Luo et al., 2026) offers an evolutionary perspective, formalizing memory development into three progressive stages: storage, reflection, and experience. It also identifies long-range consistency, dynamic environments, and continual learning as the core drivers of this evolution. Graph-based Agent Memory (Yang et al., 2026a) narrows the scope to graph-based memory paradigms of knowledge graphs, temporal graphs, hypergraphs, and hierarchical trees. In addition, it systematically analyzes extraction, storage, retrieval, and evolution along the memory lifecycle."
        },
        {
            "title": "D Prompt Library",
            "content": "This section details the prompt templates used for all experimental evaluations. To ensure reproducibility, we provide the specific instructions for memory construction, query processing, and the varying sensitivities of our evaluation protocols. To provide structured comparison, we classify the prompt designs into three operational stages: Memory Construction (Build), Query Processing (Query), and Response Generation (Answer). Table 6 summarizes the design patterns across the evaluated systems. D.1 Memory Construction and Retrieval Different memory architectures require different construction strategies. This section outlines the prompts used by MAG systems to consolidate raw interaction history into long-term storage and refine user queries. Build Prompts (Memory Indexing) Used by MAG systems to consolidate raw interaction history into long-term storage. The evaluated systems utilize distinct structural representations: Table 6: Taxonomy of System Operation Prompts across Memory Architectures. System Build Strategy (Memory Construction) Query Strategy Answer Strategy (Synthesis) MemoryOS AMem Nemori MAGMA SimpleMem Minimalist/Turn-level Profile-based (User profiling, Knowledge extraction) Flat/Turn-based (Content analysis) Episodic (Boundary detection, Episode generation) Graph-based (Event extraction, Multi-hop reasoning) Multi-hop Entity Parsing N/A (Direct Semantic Search) Role-playing & Profile-enriched LLM Keyword Extraction N/A (Direct Semantic Search) Retrieved Memory Context Episode-based Retrieval Graph Traversal Synthesis Context-based Keyword Generation Profile Based (MemoryOS): Instructs the LLM to extract observable user traits and merge them into an evolving profile. Episodic (Nemori): Segments continuous dialogue into discrete episodes using boundary detection. Graph Based (MAGMA): Translates interactions into relational structures (e.g., event extraction, triplet arrays). [PLACEHOLDER: Insert Build Prompt for memory consolidation, e.g., \"Summarize the following interaction into atomic facts...\"] Query Refinement Prompts While many systems (like Nemori and MemoryOS) bypass explicit refinement in favor of direct semantic search algorithms, systems like AMem and SimpleMem use LLMs to transform user queries into optimized search vectors or keywords. [PLACEHOLDER: Insert Query Prompt, e.g., \"Given the conversation history, rewrite the user query for better retrieval...\"] D.2 Response Generation Answer Generator Prompts The standard templates used by all baselines (RAG, MAG, and FullContext) to produce final responses based on retrieved or provided context. The prompt designs vary based on the context strategy (e.g., profileenriched role-playing for MemoryOS, episodic retrieval for Nemori) and specific constraints (e.g., temporal awareness or multi-hop reasoning for AMem and MAGMA). [PLACEHOLDER: Insert Answer Generator Prompt, e.g., \"You are an assistant with access to the following memory shards. Answer the question based on...\"] D.3 LLM-as-a-Judge Evaluation Protocols We utilize gpt-4o-mini as our backbone judge. To comprehensively evaluate architecture performance across the diverse grading criteria mentioned in Section 4.3.2, we structure our evaluation into two categories: literature-derived baseline prompts and sensitivity rubrics. D.3.1 Literature-Derived Baselines These prompts represent different community standards for \"correctness\" and are sourced directly from existing benchmarks. Prompt 1: MAGMA (Semantic Correctness & Context) Derived from the MAGMA framework (Jiang et al., 2026a), this multi-level scoring protocol prioritizes information integration and reasoning. It emphasizes interpersonal knowledge retrieval and semantic equivalence, with specific guidelines for temporal and factual preservation. Perfect match contains all key Score the answer on scale from 0.0 to 1.0 based on semantic correctness. Scoring Scale: - 1.0: information, semantically equivalent - 0.8: Mostly correct captures main point but may have minor differences - 0.6: Partially correct has some correct info but incomplete - 0.4: Somewhat related touches on topic but misses significant info - 0.2: Barely related answer is mostly incorrect - 0.0: Completely wrong answer is unrelated or contradicts gold answer Instruction: Focus on user-interpersonal knowledge and temporal generosity. Focus on semantic equivalence, not exact wording. Assign partial credit for partially correct answers. Input: Question: {question} Gold answer: {gold_answer} Generated answer: {generated_answer} Output (JSON): { \"score\": 1.0, \"reasoning\": \"...\" } Prompt 2: Nemori (Generous Semantic Matching) Adapted from the Nemori paper (Nan et al., 2025), this is lenient, semantics-oriented evaluation scheme. It emphasizes entity recall and judges whether the generated answer captures the same underlying concept as the ground truth using binary (CORRECT/WRONG) classification, tolerating paraphrasing and verbosity. Your task is to label an answer as CORRECT or WRONG. You will be given: (1) question (2) gold (ground truth) answer (3) generated answer Evaluation Guidelines: - Be generous in grading. - If the generated answer conveys the same meaning or topic as the gold answer, mark it as CORRECT. - Ignore differences in wording, phrasing, or length. - Accept equivalent answers. - accept different formats (e.g., May 7 vs 7 May). Input: Question: {question} Gold Answer: {gold_answer} Generated Answer: {generated_answer} First, provide one-sentence reasoning, then output the result. Output (JSON): { \"label\": \"WRONG\" } semantically time-related \"CORRECT\" } paraphrases { \"label\": questions, and For or Answer information successfully You are an expert Relevance & Accuracy Evaluator. Your task is to determine whether the Predicted retrieves the necessary information to answer the Question, based on the Reference Answer. Input: Question: {question} Reference Answer: {reference} Predicted Answer: {prediction} Evaluation Criteria: 1. Responsiveness to Query The predicted answer must directly address the specific question and remain topically aligned with the users intent. 2. Core Fact Preservation The prediction must capture the key signal or core entity from the reference (e.g., who, what, or outcome). 3. Informational Utility The answer must provide meaningful value. it should convey the Even if concise, essential the question. 4. Variances) You must treat the following variations as valid matches: - Temporal & numerical tolerance (e.g., 12 days, rounded numbers) - Granularity differences (e.g., Afternoon vs. 14:05, Late October vs. Oct 25) - Information sufficient answers) - Synonymy and format variation Grading Logic: - relevant core information OR satisfies robustness conditions above. - Score 0.0 (Fail): Missing core information, irrelevant, or fails to answer the question. Output Format (JSON only): { \"score\": 1.0, \"reasoning\": \"Brief explanation focusing on relevance and core match.\" } (Acceptable Robustness subsetting required Protocol (partial Contains (Pass): Score 1.0 but by"
        },
        {
            "title": "E Baseline Configurations",
            "content": "This section details the hyper-parameter settings and model versions for the evaluated architectures. To ensure fair and objective comparisons, we strictly follow the default configuration settings provided in their respective open-source repositories, with the following standardized modifications applied across all baseline systems: Prompt 3: SimpleMem (Relevance & Accuracy) Adapted from the SimpleMem baseline (Liu et al., 2026), this prompt focuses on retrieval precision and core fact preservation. It explicitly balances relevance, factual grounding, and tolerance to representational variation via Robustness Protocol. Embedding Model: All dense retrieval operations are uniformly configured to use all-MiniLM-L6-v2 (Wang et al., 2020), replacing any system-specific default embedding models to ensure controlled baseline for semantic matching. These observations complement the quantitative findings in Section 4.3.2 and suggest fundamental mismatch: lexical metrics operate on surface form alignment, whereas agentic systems increasingly rely on abstraction, normalization, and compositional reasoning. As result, improvements in reasoning quality may not be reflected and can even be penalized by traditional token-based evaluation. LLM Temperature: The generation temperature is fixed at 0.3 across all backbone LLMs to maintain consistent balance between determinism and reasoning capability. Retrieval Top-k: For final answer synthesis that relies on retrieving raw conversation history or memory chunks, we uniformly set the retrieval scope to top-k = 10. Max Tokens: The maximum token limits for generation and context windows are maintained at their repository-specific defaults to respect the intended design of each architecture. summary of these unified hyper-parameters alongside the specific operational parameters for each evaluated system is provided in Table 7. Case Studies: Why Lexical Metrics Fail To further investigate the ranking discrepancies observed in Section 4.3.2, we conduct qualitative analysis of representative cases where lexical metrics (e.g., F1) disagree with semantic judgments. Rather than presenting isolated examples, we organize these cases into set of recurring failure mechanisms that reflect inherent limitations of token level evaluation. We identify four common patterns: Surface Variation: Correct answers expressed with additional context or alternative phrasing are penalized due to reduced lexical overlap. Semantic Equivalence Gap: Equivalent meanings conveyed through different formats or synonyms result in zero or near-zero scores. Polarity Flip: Minor lexical changes (e.g., negation) invert the semantic meaning while preserving high token overlap. Entity Drift: Incorrect entities or values are substituted within otherwise similar sentence structures, leading to inflated lexical similarity despite factual errors. Table 9 presents representative examples illustrating these failure modes. These cases demonstrate that lexical metrics are not merely noisy, but systematically misaligned with the abstraction, normalization, and reasoning behaviors exhibited by modern LLM-based systems. Table 7: Key hyper-parameter configurations for the evaluated memory architectures. To ensure fair comparison, embedding models, LLM generation temperatures, and final answer retrieval scopes are strictly standardized across all baselines, while structural capacity parameters (e.g., max tokens) follow repository defaults. Method Embedding Model LLM Temp. Final Answer Top-k System-Specific Defaults (Max Tokens & Structure) Full Context LOCOMO AMem MemoryOS Nemori MAGMA SimpleMem N/A MiniLM-L6-v2 MiniLM-L6-v2 MiniLM-L6-v2 MiniLM-L6-v2 MiniLM-L6-v2 MiniLM-L6-v2 0.3 0.3 0.3 0.3 0.3 0.3 0. N/A 10 10 10 10 10 10 Max Tokens: 128k (gpt-4o-mini) Max Tokens: Default; Buffer Size: Default Max Tokens: Default; Keyword Extractor Temp: Default Max Tokens: Default; Update Frequency: Default Max Tokens: Default; Boundary Temp: 0.1 Max Tokens: Default; Consolidation Threshold: Default Max Tokens: Default; Synthesis Strategy: Default Table 8: Overview of memory systems and experimental configurations. We use gpt-4o-mini as the primary controller for all methods in the main benchmark to normalize reasoning costs. Method Memory Structure Update Policy Retrieval Scope A-MEM MemoryOS Linked Node Graph (Atomic Units + Tags) Hierarchical Tiers (STM LTM) Rule-based: Evolutionary: rewriting & dynamic linking Frequency/RecencyLLM-based node Nemori MAGMA Multi-relational Graph + Vector Index Dual Memory (Episodic Tree + Semantic Graph) SimpleMem Hybrid Index (Dense/Sparse) of Compressed Units based promotion Asynchronous: Dual-stream consolidation (Long-term) Gradient-inspired: Contextual memory modification Synchronous: On-the-fly synthesis & deduplication Dense Embedding Similarity (Top-k) Cascading Hierarchy Search Intent-guided Subgraph Traversal Hybrid (Top-k Episodes + Semantic Facts) Planner-guided Search Multi-view Table 9: Mechanism Oriented Failure Cases of Lexical Metrics. Lexical scores (F1) are contrasted with semantic judgments to highlight systematic mismatches. Query & Gold Truth Model Answer Failure Type F1 Judge Analysis Q: What is the duration of the event? Gold: 18 days The total duration was 18 days. Surface Variation 0. 1.00 Additional phrasing lowers lexical precision despite identical meaning. Q: What time does the event start? Gold: 14:00 2 PM Q: Describe the price level. Gold: cheap inexpensive Q: Is the software compatible with Mac? Gold: compatible with Mac not compatible with Mac Semantic Equivalence Gap Semantic Equivalence Gap 0.00 1. Equivalent time representations yield zero token overlap. 0.00 1.00 Synonym substitution is not captured by lexical matching. Polarity Flip 0. 0.00 Negation reverses meaning while preserving token overlap. Q: Who completed the project? Gold: John completed the project Sarah completed the project Entity Drift 0. 0.00 Q: How many items were included? Gold: three items five items Entity Drift 0.50 0. Incorrect entity maintains structure but changes semantics. Numerical substitution is partially rewarded due to shared tokens."
        }
    ],
    "affiliations": [
        "Texas A&M University",
        "University of California, Davis",
        "University of Texas at Dallas"
    ]
}