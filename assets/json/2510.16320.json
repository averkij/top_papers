{
    "paper_title": "Scaling Laws for Deepfake Detection",
    "authors": [
        "Wenhao Wang",
        "Longqi Cai",
        "Taihong Xiao",
        "Yuxiao Wang",
        "Ming-Hsuan Yang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "This paper presents a systematic study of scaling laws for the deepfake detection task. Specifically, we analyze the model performance against the number of real image domains, deepfake generation methods, and training images. Since no existing dataset meets the scale requirements for this research, we construct ScaleDF, the largest dataset to date in this field, which contains over 5.8 million real images from 51 different datasets (domains) and more than 8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we observe power-law scaling similar to that shown in large language models (LLMs). Specifically, the average detection error follows a predictable power-law decay as either the number of real domains or the number of deepfake methods increases. This key observation not only allows us to forecast the number of additional real domains or deepfake methods required to reach a target performance, but also inspires us to counter the evolving deepfake technology in a data-centric manner. Beyond this, we examine the role of pre-training and data augmentations in deepfake detection under scaling, as well as the limitations of scaling itself."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 8 1 ] . [ 1 0 2 3 6 1 . 0 1 5 2 : r a"
        },
        {
            "title": "Scaling Laws for Deepfake Detection",
            "content": "Wenhao Wang1, Longqi Cai2, Taihong Xiao2, Yuxiao Wang2 and Ming-Hsuan Yang2 1University of Technology Sydney, 2Google DeepMind 2025-10-21 This paper presents systematic study of scaling laws for the deepfake detection task. Specifically, we analyze the model performance against the number of real image domains, deepfake generation methods, and training images. Since no existing dataset meets the scale requirements for this research, we construct ScaleDF, the largest dataset to date in this field, which contains over 5.8 million real images from 51 different datasets (domains) and more than 8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we observe power-law scaling similar to that shown in large language models (LLMs). Specifically, the average detection error follows predictable power-law decay as either the number of real domains or the number of deepfake methods increases. This key observation not only allows us to forecast the number of additional real domains or deepfake methods required to reach target performance, but also inspires us to counter the evolving deepfake technology in data-centric manner. Beyond this, we examine the role of pre-training and data augmentations in deepfake detection under scaling, as well as the limitations of scaling itself. Keywords: scaling law, deepfake detection, large-scale dataset 1. Introduction The rapid advancement of deepfake technology poses significant challenges to society, ranging from the dissemination of misinformation to the infringement of personal privacy, thereby necessitating the development of effective detection methods. Within the ongoing arms race\" between generation and detection, central challenge lies in how detection models can generalize to the ever-emerging new forms of forgeries. Increasing the diversity of training data at scale has been considered promising approach to address this issue. However, this raises fundamental question: is there predictable relationship between the improvement of model performance and the growth in data scale? To address this question, we begin by constructing dataset of unprecedented diversity and scale, since the scale of existing datasets is insufficient for our research. Specifically, we introduce ScaleDF, the largest deepfake detection dataset to date, which contains over 5.8 million real images from 51 distinct datasets (domains) and more than 8.8 million fake images generated by 102 different methods, as shown in Fig. 1 (a) and (b). Compared to previous datasets, ScaleDF includes approximately 8 times more real domains and 2 times more deepfake methods, along with larger number of images and videos (Fig. 1 (c)). In collecting real images, we aim to incorporate all publicly available datasets featuring real faces, covering wide range of tasks such as face detection, face recognition, and age estimation. When generating fake images, we categorize deepfake generation methods into five types: Face Swapping (FS), Face Reenactment (FR), Full Face synthesis (FF), Face attribute Editing (FE), and Talking Face generation (TF), with 21, 20, 24, 18, and 19 methods in each category. By introducing ScaleDF, the largest and most diverse deepfake detection dataset to date, we enable the discovery of predictable scaling laws, laying out the foundation for building more robust and generalizable deepfake detection systems. In this work on scaling laws for deepfake detection, we treat the task as binary classification problem and adopt the Vision Transformer (ViT) (Dosovitskiy et al., 2021) as the backbone. We observe that scaling laws, akin to those found in large language models (LLMs) (Kaplan et al., 2020), emerge when varying the number of training real domains or deepfake methods. Corresponding author(s): Longqi Cai <longqic@google.com>. Wenhao Wang is the main contributor of this work. Authors from Google DeepMind only advise on the research. Scaling Laws for Deepfake Detection Figure 1 Illustration of ScaleDF, which is the largest deepfake detection dataset across four dimensions: number of real domains, number of deepfake methods, number of videos, and number of images. To ensure fair comparison, for datasets that do not explicitly provide the number of images, we estimate image counts by sampling one frame per second from the videos. Using this dataset, we present systematic study on scaling laws for deepfake detection and reveal several insights. Specifically, as shown in Fig. 1 (d), the detection error exhibits power-law relationship with respect to the number of real domains or deepfake methods, i.e., 1 AUC = ùê¥ ùëÅ ùõº. More importantly, despite the large number of real domains and deepfake methods, we still see no signs of saturation. By varying the number of training images, we observe scaling laws similar to those found in image classification (Zhai et al., 2022). Specifically, we observe double-saturating power-law scaling with the Scaling Laws for Deepfake Detection format of 1 AUC = ùëê + ùêæ (ùëÅ + ùëÅ0) ùõæ. Empirically, with 46 real domains and 88 deepfake methods used in training, performance gradually saturates once the number of images exceeds 107. However, we expect this saturation threshold to increase if more real domains and deepfake methods are included. With these observed scaling laws, we aim to transform deepfake-detector development from heuristic, trial-and-error art into data-centric engineering discipline. In addition, we investigate the impact of pre-training and data augmentation in the context of scaling. We compare the performance of the model trained on ScaleDF with that trained on relatively smaller datasets. We also discuss the limitations of scaling itself. The key contributions of this work are: We introduce ScaleDF, the largest and most diverse deepfake detection dataset to date. It contains over 5.8 million real images from 51 real domains and over 8.8 million fake images generated by 102 methods, providing foundation for scaling law study and future research in this field. We perform systematic study on scaling laws for deepfake detection, discovering some predictable relationships between data scale and model performance. Specifically, we observe that the detection error follows power-law decay as the number of real domains or deepfake methods increases. We conduct extensive experiments to study the effects of scaling on pre-training and data augmentation, as well as to explore its limitations. With ScaleDF, we also achieve better cross-benchmark generalization over the existing datasets. 2. Related Works Deepfake detection. Deepfake detection aims to distinguish synthesized (or manipulated) faces from real ones. In response to the rapid advancement of face forgery techniques, many effective deepfake detection methods are proposed. For example, DiffusionFake (Chen et al., 2024) leverages diffusion models, while Hitchhikers (Foteinopoulou et al., 2024) utilizes vision-language models (VLMs) to boost detection accuracy. Additionally, several methods focus on artifacts arising from face blending (Sun et al., 2024; Zhou et al., 2024a,b). Frequency-based approaches also gain attention, with works exploring the use of frequency-domain information (Dutta et al., 2025; Gupta et al., 2025; Kashiani et al., 2025; Tan et al., 2024a). More recently, researchers begin exploring the adaptation and fine-tuning of pre-trained vision-language models for deepfake detection (Cui et al., 2025; Yan et al., 2024, 2025b). While promising, most of these methods are trained and tested on small datasets and small number of deepfake generation techniques, which limits their usefulness in real-world scenarios with constantly emerging deepfakes. In contrast, we present systematic scaling study in deepfake detection, aiming to investigate the underlying scaling laws. Furthermore, we are also aware of the watermark approaches such as SynthID (Kohli, 2025) and Stable Signature (Fernandez et al., 2023) for proactive detection. Our work serves as complementary approach before these techniques evolve into universal standards. Scaling laws. Scaling laws play crucial role in guiding the training of modern foundation models (Li et al., 2025). Since their first introduction for language models (Hestness et al., 2017; Kaplan et al., 2020), numerous studies (Aghajanyan et al., 2023; Cherti et al., 2023; Hernandez et al., 2021; Hoffmann et al., 2022; Hu et al., 2024; Tay et al., 2022; Wei et al., 2022) further validate, extend, and refine scaling laws in the context of large language models (LLMs) and multimodal large language models (MLLMs). Beyond these, scaling laws are also observed in other domains, including autonomous driving (Naumann et al., 2025), image generation (Tian et al., 2024), image classification (Zhai et al., 2022), recommendation systems (Ardalani et al., 2022), and dense retrieval (Fang et al., 2024). This paper aims to extend the study of scaling laws to the domain of deepfake detection. Encouragingly, we observe power-law scaling similar to that shown in LLMs. 3 Scaling Laws for Deepfake Detection Figure 2 Statistics of heights and widths of all real faces in the ScaleDF dataset. 3. ScaleDF Dataset Research on scaling laws relies heavily on large and diverse training datasets (Brill, 2024; Jain et al., 2024). However, suitable datasets for this task remain largely absent: the existing datasets either cover only limited range of deepfake generation methods, or are too small in size. More importantly, the real domains covered in these datasets are also very limited. To solve this, this section introduces the ScaleDF dataset, designed to support research on scaling laws for deepfake detection. Specifically, we first detail the curation process of ScaleDF, and then compare it with existing datasets. 3.1. Curating ScaleDF Real datasets collection. Our guiding principle in collecting real face datasets is inclusiveness, i.e., we aim to incorporate all currently publicly available datasets containing real faces. This enables us to study scaling laws with respect to the number of real datasets (domains). Specifically, we collect datasets spanning wide range of tasks, including (1) face detection, (2) identity recognition and verification, (3) age and demographic estimation, (4) facial expression, emotion, and valence analysis, (5) audio-visual speech and speaker recognition, (6) masked-face and occlusion-robust detection, (7) multi-spectral and cross-modal biometrics, (8) talking-head synthesis, (9) spatio-temporal action localization, and (10) fairness and bias evaluation. At the same time, we intentionally exclude most of the datasets that are specifically designed for deepfake detection to prevent overfitting, as the performance of models trained on ScaleDF and evaluated on well-established deepfake detection benchmarks remains trustworthy. The only exception is made for FaceForensics++ (R√∂ssler et al., 2019), which is included in ScaleDF because of its wide usage in training, and we consider it too valuable resource to exclude. Note that we do not include all images or videos from any single dataset, as we consider diversity and balance to be important. For instance, the VGGFace2 dataset (Cao et al., 2018b) contains about 3.31 million face images, of which we randomly include only 0.2 million in ScaleDF. We observe that image overlap and domain similarity between different datasets are inevitable at such scale. Nevertheless, when splitting the training and testing datasets, we endeavor to perform so-called cross-domain\" evaluation by selecting testing datasets that are rarely covered by recent large-scale face datasets. The names, sizes, and download links of all included real datasets are provided in the Appendix  (Table 6)  . The statistics of the heights and widths of all real faces in ScaleDF are shown in Fig. 2. Deepfake generation. Inspired by recent survey (Pei et al., 2024) and benchmark study (Yan et al., 2024), we categorize deepfake generation methods into five types and provide formal definitions: Face Swapping (FS): The face of one person is replaced with the face of another. Face Reenactment (FR): Transfer facial expressions and movements from one person to another. Full Face synthesis (FF): Generate entirely new faces from scratch (without visual reference). Face attribute Editing (FE): Modify one persons specific facial characteristics, such as age, eye, Scaling Laws for Deepfake Detection expression, hair, and nose. Talking Face generation (TF): Synthesize facial movements and lip synchronization from faces. Similar to the collection of real datasets, we aim to include as many deepfake generation methods as possible to facilitate research on scaling laws along the dimension of deepfake methods. Beyond mere quantity, we also recognize the importance of diversity in two key aspects: (1) Architectural diversity. We cover all major architectures used in deepfake generation, including affine mapping, 3D modeling, variational autoencoders (VAE), generative adversarial networks (GANs), diffusion models, flow matching, and autoregressive (AR) models; (2) Category balance. Across the five categories, we collect 21, 20, 24, 18, and 19 methods respectively, ensuring balanced representation across types. We observe that similarity between different deepfake methods is inevitable at such scale. Nevertheless, when splitting training and testing methods, we aim to perform so-called cross-method\" evaluation by selecting testing methods (e.g., GPT-Image-1 (OpenAI, 2025) and SkyReels-A1 (Qiu et al., 2025)) that are not fine-tuned or adapted from any of the training ones. During generation, we use real datasets for methods that require visual references (FS, FR, FE, TF), while for methods that do not (FF), we use either textual prompts from DiffusionDB (Wang et al., 2023b), JourneyDB (Sun et al., 2023b), and VidProM (Wang and Yang, 2024), or direct noise inputs. Note that this process uses training real datasets to generate training deepfakes and testing real datasets to generate testing deepfakes, respectively. Therefore, the ScaleDF dataset features both cross-domain\" and cross-method\" evaluation. For training and testing, we generate about 40, 000 and 2, 000 samples respectively for video-based deepfakes, and about 120, 000 and 6, 000 samples respectively for imagebased deepfakes. The names, categories, architectures, and download links of all included deepfake methods are listed in the Appendix  (Table 11)  . Experimental setup. Although ScaleDF includes both videos and images, we focus on images for training and testing, similar to DF40 (Yan et al., 2024) and DeepfakeBench (Yan et al., 2023), since videos are essentially sequences of images (We acknowledge that temporal artifacts can be helpful for deepfake detection, but this aspect is beyond the scope of this paper.). Specifically, we uniformly sample 3 frames from each generated or real video and use them to represent the video. After that, we follow the standard face detection, alignment, and cropping procedures used in DF40 (Yan et al., 2024) and DeepfakeBench (Yan et al., 2023) to obtain the final processed faces. See Section and in the Appendix for more preprocessing details and visualization of processed faces. Although ScaleDF is large and comprehensive, we remain interested in evaluating the performance of models trained on it when tested in the wild\". This is because, in real-world scenarios, many factors can influence deepfake detection performance: not only novel real domains and deepfake methods, but also image compression, face preprocessing, blending methods, and various perturbations. To this end, we select six well-established benchmarks published between 2019 and 2024, i.e., DeepFakeDetection (Google, 2019), Celeb-DF V2 (Li et al., 2020), WildDeepFake (Zi et al., 2020), ForgeryNet (He et al., 2021), DeepFakeFace (Song et al., 2023), and DF40 (Yan et al., 2024), to report their direct testing performance. We adopt two commonly used evaluation metrics: the Area Under the Receiver Operating Characteristic Curve (AUC) and the Equal Error Rate (EER). 3.2. Comparing ScaleDF with Similar Datasets In Table 1, we compare the proposed ScaleDF dataset with existing deepfake detection datasets. The reasons they are not suitable for scaling laws research are as follows: Lack of training real domains. Most of the current deepfake datasets are sourced from only 1 to 2 real domains. We observe that only 2 large-scale datasets cover more than 3 domains; however, both have their own drawbacks: (1) ForgeryNet (He et al., 2021): although it covers 4 real domains 5 Scaling Laws for Deepfake Detection Table 1 Compared to existing datasets, ScaleDF includes more real domains, more deepfake methods, and larger number of videos and images, enabling scaling law research in these dimensions. Dataset DF-TIMIT (Korshunov and Marcel, 2018) UADFV (Yang et al., 2019) FaceForensics++ (Rossler et al., 2019) DeepFakeDetection (Google, 2019) Celeb-DF V2 (Li et al., 2020) WildDeepfake (Zi et al., 2020) DFFD (Dang et al., 2020) DeeperForensics-1.0 (Jiang et al., 2020a) DFDC (Dolhansky et al., 2020) ForgeryNet (He et al., 2021) FakeAVCeleb (Khalid et al., 2021) KoDF (Kwon et al., 2021) FFIW (Zhou et al., 2021) LAV-DF (Cai et al., 2022) GFW (Borji, 2022) DF3 (Ju et al., 2023) DeepFakeFace (Song et al., 2023) DF-Platter (Narayan et al., 2023) DiffusionDeepfake (Chaitali et al., 2024) AV-Deepfake1M (Cai et al., 2024) DiFF (Cheng et al., 2024a) DF40 (Yan et al., 2024) ScaleDF (Ours) Real Domains 1 1 1 1 1 N/A 3 1 1 4 1 1 1 1 2 - 1 1 - 1 2+ 6 51 Deepfake Methods 2 1 4 5 1 N/A 8 1 8 15 4 6 3 2 3 6 3 3 2 3 13 40 102 Videos Images 58K+ 0.2M+ Real - - - - - - Fake - - - - - - Fake 640 49 4, 000 3, 068 5, 639 3, 509 3, 000 10K Real 320 49 1, 000 363 590 3, 805 1, 000 50K 23K+ 0.1M+ 99K+ 0.1M+ 1.4M+ 1.4M+ 19.5K 500 62K+ 0.1M+ 10K 36K+ - - - 764 - 10K 99K+ - - - 0.1M+ - - - - - 15K+ 46K+ 90K - 0.1M+ - - - - - 30K - 30K - - - 0.2M+ 0.8M+ - - - - - - 23K+ 0.5M+ 1K+ 1M+ 0.1M+ 0.2M+ 0.9M+ 1.4M+ 5.8M+ 8.8M+ for training, it includes only 15 outdated deepfake methods, i.e., none of the latest diffusion or autoregressive models are included; and (2) DF40 (Yan et al., 2024): although it includes 6 real domains and 40 deepfake methods, only 1 real domain (FaceForensics++ (Rossler et al., 2019)) is actually used for training, and most of the fake training images come from that domain. In contrast, ScaleDF covers 51 real domains, 46 of which are used for training, enabling research of scaling laws across the real domain dimension. Insufficient deepfake methods. The dataset that includes the most deepfake methods so far is DF40 (Yan et al., 2024). In comparison, ScaleDF (1) contains twice as many deepfake generation methods, making scaling law research along the method dimension more convincing; (2) incorporates several recent and widely used methods, such as GPT-Image-1 (OpenAI, 2025) and Step1X-Edit (Liu et al., 2025), making the study of scaling laws more practical. Limited number of images (videos). Given that (1) modern deepfake datasets such as ForgeryNet (He et al., 2021) and DF40 (Yan et al., 2024) contain around 1 2 million images, and (2) prior work in image classification (Zhai et al., 2022) has observed power-law scaling when increasing dataset size from 1 million to 10 million, we are motivated to explore whether similar scaling laws hold for deepfake detection. To this end, we scale the ScaleDF dataset to over 14 million images, i.e.more than 5 the size of the previous largest dataset, ForgeryNet (He et al., 2021). 4. Scaling Law Observations In this section, we present the observed scaling laws by training models on the ScaleDF dataset and evaluating them on seven different test datasets. We report the average AUC across these Scaling Laws for Deepfake Detection Figure 3 Left: observed power-law scaling as the number of training real domains changes; Right: observed power-law scaling as the number of training deepfake methods changes. ùúá represents the mean computed over 10 repetitions and 7 test datasets, while ùúé denotes the variance across the 10 repetitions. datasets, denoted as AUC, here, and present the corresponding scaling laws with average EER (EER) in Appendix (Section C). The complete experimental results can be found in Appendix (Section E). Training configurations. To eliminate the interference from more advanced deepfake detection methods in our scaling laws research, we formulate the deepfake detection task as pure binary classification problem. We use the Vision Transformer (ViT) (Dosovitskiy et al., 2021) as the backbone, defaulting to the ViT-Base (Touvron et al., 2022) model pre-trained on ImageNet-21K (Deng et al., 2009). We perform data augmentation by first applying random image quality compression between 40% and 100%, followed by randomly selected perturbations from AnyPattern (Wang et al., 2024b). description of the selected perturbations and other training details are provided in Appendix (Section and F). Power-law scaling is observed with respect to the number of training real domains and deepfake methods, respectively. To study the scaling law along these dimensions, we randomly sample ùëÅ {5, 8, 11, 16, 23, 32} real domains from total of 46 and ùëÅ {11, 16, 22, 32, 45, 64} deepfake methods from total of 88, respectively. To reduce randomness, each sampling is repeated 10 times. For each sampled set of real domains, we train model using all fake images and the corresponding real images from those domains; while for each sampled set of deepfake methods, we train model using all real images and the corresponding fake images generated by those methods. Each ùúá in Fig. 3 represents the mean computed over 10 repetitions and 7 test datasets, while ùúé denotes the variance across the 10 repetitions. Based on these empirical data points, we observe that the trend of 1 AUC with respect to the number of real domains or deepfake methods (ùëÅ) is best described by power law, which is the same form as originally proposed for LLMs (Kaplan et al., 2020), i.e., 1 AUC = ùê¥ ùëÅ ùõº. Using ordinary least squares (OLS), we estimate the parameters as ùê¥ = 0.729 with ùõº = 0.476 for real domains, and ùê¥ = 0.618 with ùõº = 0.375 for deepfake methods. Meanwhile, we calculate the coefficient of determination ùëÖ2 = 0.9821 and ùëÖ2 = 0.9896, respectively, implying that the fitted power law explains 98.21% and 98.96% of the variance in the observed data, thus providing an excellent description of the scaling relationship. This scaling law suggests that the performance with respect to the number of real domains and deepfake methods is far from saturated. To achieve higher performance, collecting more real domains and deepfake methods proves to be highly effective. Furthermore, the models performance is, to some extent, predictable: for example, to reach an average AUC of 0.95, we may require about 300 real domains or 700 deepfake methods. Scaling Laws for Deepfake Detection Figure 4 Left: observed double-saturating power-law scaling as the number of training images changes; ùúá represents the mean computed over 5 repetitions and 7 test datasets, while ùúé denotes the variance across the 5 repetitions. Right: performance changes with respect to model sizes. The two scaling laws described above are not caused by change in the number of real or fake images. When conducting experiments by randomly sampling real domains, the number of real images changes (while the number of fake images remains fixed); conversely, when randomly sampling deepfake methods, the number of fake images changes (with the number of real images unchanged). natural question is whether the performance changes or the observed scaling laws are caused by changes in the number of real or fake images. Our answer is no. To support this argument, we conduct two experiments: (1) we keep the number of fake images fixed and randomly sample 1/10 of the real images for training; the resulting AUC decreases slightly from 0.886 to 0.879; (2) we keep the number of real images fixed and randomly sample 1/10 of the fake images for training; the resulting AUC drops from 0.886 to 0.876 slightly. We use 1/10 here because, when studying scaling laws, we use more than 1/10 of the real domains or deepfake methods. These small changes in AUC suggest that the observed scaling laws are indeed related to the number of real domains and deepfake methods, rather than the number of real or fake images. Double-saturating power-law scaling is observed with respect to the number of training images. To study the scaling law along this dimension, we randomly sample subsets of the ScaleDF training set at the following proportions: 1/4, 1/10, 1/16, 1/64, 1/100, 1/256, 1/1000. Note that this differs from the previous section, i.e., here we sample real and fake images simultaneously. To reduce randomness, each sampling is repeated 5 times. Each ùúá in Fig. 4 (left) represents the mean computed over 5 repetitions and 7 test datasets, while ùúé denotes the variance across the 5 repetitions. Based on these empirical data points, we observe that the trend of 1 AUC with respect to the number of training images (ùëÅ) is best described by double-saturating power law, which is the same form as originally proposed in image classification (Zhai et al., 2022), i.e., 1 AUC = ùëê + ùêæ (ùëÅ + ùëÅ0) ùõæ. Using ordinary least squares (OLS), we estimate the parameters as ùëê = 0.112, ùêæ = 2.1 104, ùëÅ0 = 1.34 105, and ùõæ = 0.915. Meanwhile, we calculate the coefficient of determination ùëÖ2 = 0.9985, implying that the fitted power law explains 99.85% of the variance in the observed data, thus providing an excellent description of the scaling relationship. This scaling law suggests that, with 46 real domains and 88 deepfake methods, performance gradually saturates once the total number of training images exceeds 107. To further improve performance, blindly collecting more images from the same real domains or generating more from the same deepfake methods may not be effective. However, this does not imply that datasets larger than 107 images offer no further benefit for deepfake detection. Rather, as we scale up the number of real domains and deepfake methods, more training data will still be essential. 8 Scaling Laws for Deepfake Detection Table 2 Comparison of using different pre-training models: similar performance observed. AUC ImageNet CLIP SigLIP 2 DFD 0.793 0.795 0.750 CDF V2 0.915 0.894 0.890 Wild 0.815 0.802 0.785 Forgery. 0.824 0.848 0. DFF 0.909 0.954 0.951 DF40 0.980 0.979 0.986 ScaleDF 0.968 0.981 0.983 Table 3 Effectiveness of image quality compression (QC) and perturbations (PT). AUC N/A QC QC + PT DFD 0.667 0.774 0. CDF V2 0.805 0.914 0.915 Wild 0.781 0.802 0.815 Forgery. 0.756 0.770 0.824 DFF 0.808 0.932 0.909 DF40 0.937 0.978 0.980 ScaleDF 0.975 0.976 0. Mean 0.886 0.893 0.886 Mean 0.818 0.878 0.886 When training on ScaleDF, model size scaling appears to saturate at around 300 million parameters. Beyond the aforementioned scaling laws, we are also interested in scaling along the model size dimension, i.e., how large model ScaleDF can support. Specifically, we select five different model sizes, denoted as ViT-S (21.7M), ViT-M (38.3M), ViT-B (85.8M), ViT-L (303.4M), and ViT-H (630.8M). Each ùúá in Fig. 4 (right) represents the mean computed over 7 test datasets. Performance consistently improves from ViT-S (21.7M) to ViT-L (303.4M), but saturates thereafter, as further scaling to ViT-H (630.8M) yields no gains. This observation does not suggest that models with more than 300M parameters bring no additional gain for the deepfake detection task; rather, it indicates the maximum model size currently supported by the ScaleDF dataset. In the future, as we scale up real domains and deepfake methods, larger models may yield better performance. 5. Additional Observations with Scaling Beyond scaling laws, we identify additional insights as deepfake detection is scaled up. We report AUC results here, with EER presented in Appendix (Section G). Specifically, we observe that: Different pre-trained models exhibit similar performance with the ScaleDF. Several works (Ojha et al., 2023; Yan et al., 2024, 2025a) have reported that, on small-scale datasets, fine-tuning pre-trained vision-language models yields better performance than fine-tuning pre-trained image classification models. Here, we aim to examine whether this claim holds when training on the large-scale ScaleDF dataset, which contains over 14 million images. Our findings indicate that the answer is no. Specifically, we compare three types of pre-trained ViT-Base models: (1) image classification on ImageNet-21K, (2) CLIP (Radford et al., 2021), and (3) SigLIP 2 (Tschannen et al., 2025). Experiments in Table 2 show that there are no significant performance differences (less than 1% in AUC) across different pre-training methods. Nevertheless, we also observe that without pre-training, convergence is very slow, and thus pre-training remains necessary for the ScaleDF. Data augmentation remains important in the context of scaling. In this section, we investigate the importance of data augmentation in training on the large-scale ScaleDF dataset. common understanding is that data augmentation serves as remedy for data scarcity, especially in scenarios where models are data-hungry. For example, DeiT (Touvron et al., 2021) demonstrates that, with appropriate data augmentation, it is possible to achieve competitive performance using only ImageNet1k, compared to models pre-trained on hundreds of millions of images. However, we observe that for the deepfake detection task, data augmentation remains important even when sufficient training data is available. From Table 3, we observe that: (1) random image quality compression can significantly improve performance, for example, increasing the AUC on Celeb-DF V2 (Li et al., 2020) from 0.805 9 Scaling Laws for Deepfake Detection Table 4 Comparison in cross-benchmark setting: with scaling, we achieve the best performance. AUC DFD CDF V2 Wild Forgery. DFF DF40 ScaleDF DFD 0.709 0.643 0.813 0.583 0.587 0.793 CDF V2 0.802 0.757 0.913 0.568 0.800 0.915 Wild 0.738 0.777 0.821 0.552 0.684 0.815 Forgery. 0.610 0.640 0.555 0.578 0.677 0.824 DFF 0.545 0.599 0.489 0.687 0.607 0.909 s n r DF40 0.594 0.665 0.562 0.833 0.669 0.980 ScaleDF 0.524 0.612 0.556 0.657 0.622 0.667 Table 5 Comparison of whether includes FaceForensics++ (R√∂ssler et al., 2019) in the ScaleDF. AUC w/o FF++ FF++ DFD 0.758 0.793 CDF V2 0.868 0.915 Wild 0.796 0.815 Forgery. 0.807 0.824 DFF 0.905 0.909 DF40 0.978 0. ScaleDF 0.969 0.968 Mean 0.869 0.886 to 0.914; and (2) random perturbations enhance robustness on test sets with strong perturbations, such as ForgeryNet (He et al., 2021). These improvements also suggest that deepfake detection relies, to some extent, on low-level features. Scaling proves essential for achieving satisfactory cross-benchmark performance. Unlike previous dataset papers, such as ForgeryNet (He et al., 2021), DF40 (Yan et al., 2024), and DiFF (Cheng et al., 2024a), which mainly focus on proposing new comprehensive benchmarks and conducting extensive evaluations, we emphasize cross-benchmark performance, i.e., training models on ScaleDF and testing them on other well-established benchmarks. This better reflects whether researchers and engineers can train model on the proposed dataset and directly deploy it in real-world production environments. In Table 4, we compare the cross-benchmark capability of the proposed ScaleDF with that of existing datasets. It is observed that: (1) Although recent datasets such as DF40 (Yan et al., 2024) are large-scale and cover many deepfake methods, they still do not perform well in cross-benchmark testing. We infer that this is due to insufficient coverage of real domains. (2) ForgeryNet (He et al., 2021) does not achieve consistently good performance across all datasets, likely because it lacks coverage of some recent deepfake generation methods. (3) As expected, small-scale datasets do not perform well on cross-benchmark settings, as they cover neither wide range of real domains nor diverse deepfake methods. Scaling is important but not all you need, and methodological innovations are still necessary. As an ablation study, we remove FaceForensics++ (R√∂ssler et al., 2019) from ScaleDF, i.e., reducing one real domain and four deepfake methods, and train new model on the modified dataset. From Table 5, we observe performance drop on older benchmarks, while the performance on newer benchmarks remains unchanged. This implies that simply adding more new deepfake methods does not significantly improve performance on fundamentally different, older ones. To enhance performance on such benchmarks, it is necessary to include deepfake methods similar to those used in older datasets (e.g., those found in FaceForensics++). This further implies that, even though ScaleDF includes wide range of deepfake methods, models trained with simple binary classification may not generalize well to totally different ones that could appear in the future. This suggests the need for algorithms that (1) can learn the underlying essence of forgery from large number of deepfake methods, and (2) generalize far beyond what simple binary classification allows. We hope that the ScaleDF dataset provides sufficient resources to explore and develop such algorithms, and we call for efforts from the community. Scaling Laws for Deepfake Detection 6. Conclusion In this paper, we introduce ScaleDF, the most comprehensive deepfake detection dataset to date, spanning 51 real domains, 102 deepfake methods, and more than 14 million face images. Leveraging this unprecedented scale, we conduct systematic study of scaling laws in deepfake detection. Our primary finding is that detection performance follows predictable power-law scaling relationships. Specifically, we show that detection error decreases as power-law function of the number of training real domains or deepfake methods, with no signs of saturation. This discovery shifts the development of deepfake detectors from heuristic-driven process to more predictable, data-centric engineering discipline. We further identify double-saturating power law with respect to the number of training images, suggesting that when the diversity of sources is fixed, the benefit of simply increasing data quantity eventually diminishes. Strategically, we should focus on the diversity and comprehensiveness of the evolving deepfake methods when building such database. In addition, our large-scale experiments yield several practical insights: data augmentation remains crucial for robustness, even with massive datasets, and models trained on ScaleDF achieve better cross-benchmark generalization. However, our work also highlights that scaling alone is not panacea; generalizing to fundamentally novel or unseen forgery types remains challenge, underscoring the need for innovation in detection algorithms. By building ScaleDF, we aim to provide resource for the research community to explore these frontiers and encourage future efforts to develop algorithms capable of learning more fundamental forgery representations from large and diverse dataset. Disclaimer for scaling law research. We emphasize that the scaling laws presented in this work are empirical observations specific to our experimental setup. In the study of scaling laws, fitted parameters and empirical findings are known to vary depending on choices of hyperparameter configurations, optimization methods, model architectures, data quality, and other experimental conditions (Bahri et al., 2024; Cherti et al., 2023). The specific exponents and constants we report are contingent on our use of the ViT architecture, the composition of the ScaleDF dataset, and our chosen training and data augmentation protocols. As such, these laws should be interpreted as descriptive models for deepfake detection scaling within this context, rather than as universal, fundamental constants. The primary value of our findings is the demonstration that predictable scaling is achievable in this domain, providing data-centric framework for future development. Future work exploring different architectures or data compositions would likely yield different scaling coefficients."
        },
        {
            "title": "Ethics Statement",
            "content": "This work aims to advance deepfake detection and foster Generative AI safety. We adhere to the license terms of all data and models in constructing ScaleDF. There are few open issues and important considerations around fairness and bias. Please refer to Appendix (Section H) for detailed discussion."
        },
        {
            "title": "Reproducibility Statement",
            "content": "A detailed description of the dataset curation process is provided in Section 3, along with complete lists and links to all source real datasets  (Table 6)  and deepfake generation methods  (Table 11)  . The data preprocessing pipeline, which includes face detection, alignment, and cropping, is described in Appendix (Section A). All experimental settings, such as model configurations, data augmentation strategies, training hyperparameters, and computational infrastructure, are documented in Section 4 (Training Configurations) and Appendix (Section and F). To support verification of our scaling law findings, we provide complete numerical results for all experiments, including Equal Error Rate (EER) metrics, in Appendix (Section and E). 11 Scaling Laws for Deepfake Detection"
        },
        {
            "title": "References",
            "content": "M. Abdrakhmanova, A. Kuzdeuov, S. Jarju, Y. Khassanov, M. Lewis, and H. A. Varol. Speakingfaces: large-scale multimodal dataset of voice commands with visual and thermal video streams. Sensors, 2021. A. Aghajanyan, L. Yu, A. Conneau, W. Hsu, K. Hambardzumyan, S. Zhang, S. Roller, N. Goyal, O. Levy, and L. Zettlemoyer. Scaling laws for generative mixed-modal language models. In International Conference on Machine Learning, 2023. X. An, X. Zhu, Y. Gao, Y. Xiao, Y. Zhao, Z. Feng, L. Wu, B. Qin, M. Zhang, D. Zhang, et al. Partial fc: Training 10 million identities on single machine. In IEEE/CVF International Conference on Computer Vision, 2021. N. Ardalani, C. Wu, Z. Chen, B. Bhushanam, and A. Aziz. Understanding scaling laws for recommendation models. arXiv preprint arXiv:2208.08489, 2022. B. Azari and A. Lim. Emostyle: One-shot facial expression editing using continuous emotion parameters. In Winter Conference on Applications of Computer Vision, 2024. Y. Bahri, E. Dyer, J. Kaplan, J. Lee, and U. Sharma. Explaining neural scaling laws. National Academy of Sciences, 2024. S. Baliah, Q. Lin, S. Liao, X. Liang, and M. H. Khan. Realistic and efficient face swapping: unified approach with diffusion models. arXiv preprint arXiv:2409.07269, 2024. A. Bansal, A. Nanduri, C. D. Castillo, R. Ranjan, and R. Chellappa. Umdfaces: An annotated face dataset for training deep networks. In International Joint Conference on Biometrics, 2017. B. B. Bilecen, Y. Yalin, N. Yu, and A. Dundar. Reference-based 3d-aware image editing with triplanes. In Conference on Computer Vision and Pattern Recognition, 2025. F. Black. Flux. https://github.com/black-forest-labs/flux, 2024. A. Borji. Generated faces in the wild: Quantitative comparison of stable diffusion, midjourney and dall-e 2. arXiv preprint arXiv:2210.00586, 2022. S. Bounareli, V. Argyriou, and G. Tzimiropoulos. Finding directions in gans latent space for neural face reenactment. arXiv preprint arXiv:2202.00046, 2022. S. Bounareli, C. Tzelepis, V. Argyriou, I. Patras, and G. Tzimiropoulos. Stylemask: Disentangling the style space of stylegan2 for neural face reenactment. Conference on Automatic Face and Gesture Recognition, 2023a. S. Bounareli, C. Tzelepis, V. Argyriou, I. Patras, and G. Tzimiropoulos. Hyperreenact: One-shot reenactment via jointly learning to refine and retarget faces. In IEEE/CVF International Conference on Computer Vision, 2023b. A. Brill. Neural scaling laws rooted in the data distribution. arXiv preprint arXiv:2412.07942, 2024. T. Brooks, A. Holynski, and A. A. Efros. Instructpix2pix: Learning to follow image editing instructions. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023. Z. Cai, K. Stefanov, A. Dhall, and M. Hayat. Do you really mean that? content driven audio-visual In International deepfake dataset and multimodal method for temporal forgery localization. Conference on Digital Image Computing, 2022. 12 Scaling Laws for Deepfake Detection Z. Cai, S. Ghosh, A. P. Adatia, M. Hayat, A. Dhall, T. Gedeon, and K. Stefanov. Av-deepfake1m: large-scale llm-driven audio-visual deepfake dataset. In International Conference on Multimedia, 2024. H. Cao, D. G. Cooper, M. K. Keutmann, R. C. Gur, A. Nenkova, and R. Verma. Crema-d: Crowd-sourced emotional multimodal actors dataset. Transactions on Affective Computing, 2014. J. Cao, Y. Li, and Z. Zhang. Celeb-500k: large training dataset for face recognition. In International Conference on Image Processing, 2018a. Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman. Vggface2: dataset for recognising faces across pose and age. In International Conference on Automatic Face & Gesture Recognition, 2018b. X. Cao, G. Wang, S. Shi, J. Zhao, Y. Yao, J. Fei, and M. Gao. Joyvasa: portrait and animal image animation with diffusion-based audio-driven facial dynamics and head motion generation. arXiv preprint arXiv:2411.09209, 2024. B. Chaitali, H. Wang, F. Zhang, S. Kim, and X. Zhu. Diffusion deepfake. arXiv preprint arXiv:2404.01579, 2024. B. Chen, C. Chen, and W. H. Hsu. Cross-age reference coding for age-invariant face recognition and retrieval. In European Computer Vision Association, 2014. R. Chen, X. Chen, B. Ni, and Y. Ge. Simswap: An efficient framework for high fidelity face swapping. In International Conference on Multimedia, 2020. S. Chen, T. Yao, H. Liu, X. Sun, S. Ding, R. Ji, et al. Diffusionfake: Enhancing generalization in deepfake detection via guided stable diffusion. Conference on Neural Information Processing Systems, 2024. X. Chen, Z. Wu, X. Liu, Z. Pan, W. Liu, Z. Xie, X. Yu, and C. Ruan. Janus-pro: Unified multimodal understanding and generation with data and model scaling. arXiv preprint arXiv:2501.17811, 2025a. Z. Chen, J. Cao, Z. Chen, Y. Li, and C. Ma. Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions. In AAAI Conference on Artificial Intelligence, 2025b. H. Cheng, Y. Guo, T. Wang, L. Nie, and M. Kankanhalli. Diffusion facial forgery detection. In International Conference on Multimedia, 2024a. H. Cheng, L. Lin, C. Liu, P. Xia, P. Hu, J. Ma, J. Du, and J. Pan. Dawn: Dynamic frame avatar with non-autoregressive diffusion framework for talking head video generation. arXiv preprint arXiv:2410.13726, 2024b. K. Cheng, X. Cun, Y. Zhang, M. Xia, F. Yin, M. Zhu, X. Wang, J. Wang, and N. Wang. Videoretalking: Audio-based lip synchronization for talking head video editing in the wild. In Conference and Exhibition on Computer Graphics and Interactive Techniques in Asia, 2022. M. Cherti, R. Beaumont, R. Wightman, M. Wortsman, G. Ilharco, C. Gordon, C. Schuhmann, L. Schmidt, and J. Jitsev. Reproducible scaling laws for contrastive language-image learning. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023. J. S. Chung, A. Nagrani, and A. Zisserman. Voxceleb2: Deep speaker recognition. arXiv preprint arXiv:1806.05622, 2018. 13 Scaling Laws for Deepfake Detection M. Cooke, J. Barker, S. Cunningham, and X. Shao. An audio-visual corpus for speech perception and automatic speech recognition. The Journal of the Acoustical Society of America, 2006. X. Cui, Y. Li, A. Luo, J. Zhou, and J. Dong. Forensics adapter: Adapting clip for generalizable face forgery detection. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2025. Y. Dalva, S. F. Altƒ±ndi≈ü, and A. Dundar. Vecgan: Image-to-image translation with interpretable latent directions. In European Conference on Computer Vision, 2022. H. Dang, F. Liu, J. Stehouwer, X. Liu, and A. K. Jain. On the detection of digital face manipulation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020. deepfakes. faceswap: Deepfakes software for all. https://github.com/deepfakes/faceswap, 2017. J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei. Imagenet: large-scale hierarchical image database. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2009. D. Di, H. Feng, W. Sun, Y. Ma, H. Li, W. Chen, X. Gou, T. Su, and X. Yang. Facevid-1k: large-scale high-quality multiracial human face video dataset. arXiv preprint arXiv:2410.07151, 2024. B. Dolhansky, J. Bitton, B. Pflaum, J. Lu, R. Howes, M. Wang, and C. C. Ferrer. The deepfake detection challenge (dfdc) dataset. arXiv preprint arXiv:2006.07397, 2020. A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021. A. Dutta, A. K. Das, R. Naskar, and R. S. Chakraborty. Wavedif: Wavelet sub-band based deepfake In IEEE/CVF Conference on Computer Vision and Pattern identification in frequency domain. Recognition, 2025. M. Earl. faceswap: Python script to put facial features from one face onto another. https://github. com/matthewearl/faceswap, 2015. E. Eidinger, R. Enbar, and T. Hassner. Age and gender estimation of unfiltered faces. Transactions on Information Forensics and Security, 2014. A. Ephrat, I. Mosseri, O. Lang, T. Dekel, K. Wilson, A. Hassidim, W. T. Freeman, and M. Rubinstein. Looking to listen at the cocktail party: speaker-independent audio-visual model for speech separation. arXiv preprint arXiv:1804.03619, 2018. P. Esser, R. Rombach, and B. Ommer. Taming transformers for high-resolution image synthesis. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021. P. Esser, S. Kulal, A. Blattmann, R. Entezari, J. M√ºller, H. Saini, Y. Levi, D. Lorenz, A. Sauer, F. Boesel, et al. Scaling rectified flow transformers for high-resolution image synthesis. In International Conference on Machine Learning, 2024. Y. Fang, J. Zhan, Q. Ai, J. Mao, W. Su, J. Chen, and Y. Liu. Scaling laws for dense retrieval. In Conference on Research and Development in Information Retrieval, 2024. P. Fernandez, G. Couairon, H. J√©gou, M. Douze, and T. Furon. The stable signature: Rooting watermarks in latent diffusion models. In IEEE/CVF International Conference on Computer Vision, 2023. 14 Scaling Laws for Deepfake Detection T. W. Ford and R. Shao. wikifaces: downloader for named images containing faces from wiki servers. https://pypi.org/project/wikifaces/, 2021. N. M. Foteinopoulou, E. Ghorbel, and D. Aouada. hitchhikers guide to fine-grained face forgery detection using common sense reasoning. Conference on Neural Information Processing Systems, 2024. G. Gao, H. Huang, C. Fu, Z. Li, and R. He. Information bottleneck disentanglement for identity swapping. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021. S. Ge, J. Li, Q. Ye, and Z. Luo. Detecting masked faces in the wild with lle-cnns. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2017. Google. Contributing data to deepfake detection research. https://research.google/blog/ contributing-data-to-deepfake-detection-research/, 2019. Google AI Blog. A. Groshev, A. Maltseva, D. Chesakov, A. Kuznetsov, and D. Dimitrov. Ghosta new face swap approach for image and video domains. IEEE Access, 2022. R. Gross, I. Matthews, J. Cohn, T. Kanade, and S. Baker. Multi-pie. In International Conference on Automatic Face and Gesture Recognition, 2008. C. Gu, C. Sun, D. A. Ross, C. Vondrick, C. Pantofaru, Y. Li, S. Vijayanarasimhan, G. Toderici, S. Ricco, R. Sukthankar, et al. Ava: video dataset of spatio-temporally localized atomic visual actions. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018. J. Guo, D. Zhang, X. Liu, Z. Zhong, Y. Zhang, P. Wan, and D. Zhang. Liveportrait: Efficient portrait animation with stitching and retargeting control. arXiv preprint arXiv:2407.03168, 2024. V. Gupta, V. Srivastava, A. Yadav, D. K. Vishwakarma, and N. Kumar. Freqfacenet: an enhanced transformer architecture with dual-order frequency attention for deepfake detection. Applied Intelligence, 2025. Y. HaCohen, N. Chiprut, B. Brazowski, D. Shalem, D. Moshe, E. Richardson, E. Levin, G. Shiran, N. Zabari, O. Gordon, et al. Ltx-video: Realtime video latent diffusion. arXiv preprint arXiv:2501.00103, 2024. Y. Han, J. Zhu, K. He, X. Chen, Y. Ge, W. Li, X. Li, J. Zhang, C. Wang, and Y. Liu. Face adapter for pretrained diffusion models with fine-grained id and attribute control. arXiv preprint arXiv:2405.12970, 2024. Y. He, B. Gan, S. Chen, Y. Zhou, G. Yin, L. Song, L. Sheng, J. Shao, and Z. Liu. Forgerynet: versatile benchmark for comprehensive forgery analysis. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021. D. Hernandez, J. Kaplan, T. Henighan, and S. McCandlish. Scaling laws for transfer. arXiv preprint arXiv:2102.01293, 2021. J. Hestness, S. Narang, N. Ardalani, G. Diamos, H. Jun, H. Kianinejad, M. M. A. Patwary, Y. Yang, and Y. Zhou. Deep learning scaling is predictable, empirically. arXiv preprint arXiv:1712.00409, 2017. J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. d. L. Casas, L. A. Hendricks, J. Welbl, A. Clark, et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022. 15 Scaling Laws for Deepfake Detection F. Hong and D. Xu. Implicit identity representation conditioned memory compensation network for talking head video generation. In IEEE/CVF International Conference on Computer Vision, 2023. F. Hong, L. Zhang, L. Shen, and D. Xu. Depth-aware generative adversarial network for talking head video generation. IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. S. Hu, Y. Tu, X. Han, C. He, G. Cui, X. Long, Z. Zheng, Y. Fang, Y. Huang, W. Zhao, et al. Minicpm: Unveiling the potential of small language models with scalable training strategies. arXiv preprint arXiv:2404.06395, 2024. G. B. Huang, M. Mattar, T. Berg, and E. Learned-Miller. Labeled faces in the wild: database forstudying face recognition in unconstrained environments. In Workshop on Faces in Real-Life Images, 2008. Z. Huang, F. Tang, Y. Zhang, J. Cao, C. Li, S. Tang, J. Li, and T. Lee. Identity-preserving face swapping via dual surrogate generative models. Transactions on Graphics, 2024. A. Jain, A. Montanari, and E. Sasoglu. Scaling laws for learning with real and surrogate data. arXiv preprint arXiv:2402.04376, 2024. A. Javanmardi, A. Pagani, and D. Stricker. G3fa: Geometry-guided gan for face animation. In British Machine Vision Conference, 2024. L. Jiang, R. Li, W. Wu, C. Qian, and C. C. Loy. Deeperforensics-1.0: large-scale dataset for real-world face forgery detection. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020a. X. Jiang, Y. Zong, W. Zheng, C. Tang, W. Xia, C. Lu, and J. Liu. Dfew: large-scale database for recognizing dynamic facial expressions in the wild. In International Conference on Multimedia, 2020b. Y. Jin, Z. Sun, N. Li, K. Xu, K. Xu, H. Jiang, N. Zhuang, Q. Huang, Y. Song, Y. MU, and Z. Lin. Pyramidal flow matching for efficient video generative modeling. In International Conference on Learning Representations, 2025. Y. Ju, S. Jia, J. Cai, H. Guan, and S. Lyu. Glff: Global and local feature fusion for ai-synthesized image detection. Transactions on Multimedia, 2023. J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020. K. Karkkainen and J. Joo. Fairface: Face attribute dataset for balanced race, gender, and age for bias measurement and mitigation. In Winter Conference on Applications of Computer Vision, 2021. T. Karras, S. Laine, and T. Aila. style-based generator architecture for generative adversarial networks. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019. T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, and T. Aila. Analyzing and improving the image quality of stylegan. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020. T. Karras, M. Aittala, S. Laine, E. H√§rk√∂nen, J. Hellsten, J. Lehtinen, and T. Aila. Alias-free generative adversarial networks. Conference on Neural Information Processing Systems, 2021. H. Kashiani, N. A. Talemi, and F. Afghah. Freqdebias: Towards generalizable deepfake detection via consistency-driven frequency debiasing. In Conference on Computer Vision and Pattern Recognition, 2025. 16 Scaling Laws for Deepfake Detection H. Khalid, S. Tariq, M. Kim, and S. S. Woo. Fakeavceleb: novel audio-video multimodal deepfake dataset. arXiv preprint arXiv:2108.05080, 2021. T. Ki, D. Min, and G. Chae. Float: Generative motion latent flow matching for audio-driven talking portrait. arXiv preprint arXiv:2412.01064, 2024. G. Kim, T. Kwon, and J. C. Ye. Diffusionclip: Text-guided diffusion models for robust image manipulation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. K. Kim, Y. Kim, S. Cho, J. Seo, J. Nam, K. Lee, S. Kim, and K. Lee. Diffface: Diffusion-based face swapping with facial guidance. Pattern Recognition, 2025. D. E. King. Dlib-ml: machine learning toolkit. Journal of Machine Learning Research, 2009. P. Kohli. Synthid detector new portal to help identify ai-generated content. https://blog. google/technology/ai/google-synthid-ai-content-detector/, 2025. Google Blog. D. Kollias and S. Zafeiriou. Expression, affect, action unit recognition: Aff-wild2, multi-task learning and arcface. arXiv preprint arXiv:1910.04855, 2019. Kolors. Kolors: Effective training of diffusion model for photorealistic text-to-image synthesis. HuggingFace preprint, 2024. W. Kong, Q. Tian, Z. Zhang, R. Min, Z. Dai, J. Zhou, J. Xiong, X. Li, B. Wu, J. Zhang, et al. Hunyuanvideo: systematic framework for large video generative models. arXiv preprint arXiv:2412.03603, 2024. P. Korshunov and S. Marcel. Deepfakes: new threat to face recognition? assessment and detection. arXiv preprint arXiv:1812.08685, 2018. J. Kossaifi, G. Tzimiropoulos, S. Todorovic, and M. Pantic. Afew-va database for valence and arousal estimation in-the-wild. Image and Vision Computing, 2017. M. Kowalski. FaceSwap: 3d face swapping implemented in python. https://github.com/ MarekKowalski/FaceSwap, 2016. Kwai. Kolors: IP-Adapter FaceID Plus (code). https://github.com/Kwai-Kolors/Kolors/ tree/master/ipadapter_FaceID, 2024. P. Kwon, J. You, G. Nam, S. Park, and G. Chae. Kodf: large-scale korean deepfake detection dataset. In IEEE/CVF International Conference on Computer Vision, 2021. kyquac. ASIAN CELEB 112X112: Aligned asian celebrity faces (112 112). https://www.kaggle. com/datasets/kyquac/asian-celeb-112x112, 2022. B. Li, Z. Huang, H. Shan, and J. Zhang. Semantic latent decomposition with normalizing flows for face editing. In International Conference on Acoustics, Speech and Signal Processing, 2024a. M. Li, S. Kudugunta, and L. Zettlemoyer. (mis)fitting scaling laws: survey of scaling law fitting techniques in deep learning. In International Conference on Learning Representations, 2025. S. Li, W. Deng, and J. Du. Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2017. T. Li, R. Zheng, M. Yang, J. Chen, and M. Yang. Ditto: Motion-space diffusion for controllable realtime talking head synthesis. arXiv preprint arXiv:2411.19509, 2024b. 17 Scaling Laws for Deepfake Detection Y. Li, X. Yang, P. Sun, H. Qi, and S. Lyu. Celeb-df: large-scale challenging dataset for deepfake forensics. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020. Y. Li, C. Ma, Y. Yan, W. Zhu, and X. Yang. 3d-aware face swapping. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023. Z. Li, J. Zhang, Q. Lin, J. Xiong, Y. Long, X. Deng, Y. Zhang, X. Liu, M. Huang, Z. Xiao, et al. Hunyuandit: powerful multi-resolution diffusion transformer with fine-grained chinese understanding. arXiv preprint arXiv:2405.08748, 2024c. S. Liu, Y. Han, P. Xing, F. Yin, R. Wang, W. Cheng, J. Liao, Y. Wang, H. Fu, C. Han, G. Li, Y. Peng, Q. Sun, J. Wu, Y. Cai, Z. Ge, R. Ming, L. Xia, X. Zeng, Y. Zhu, B. Jiao, X. Zhang, G. Yu, and D. Jiang. Step1x-edit: practical framework for general image editing. arXiv preprint arXiv:2504.17761, 2025. T. Liu, F. Chen, S. Fan, C. Du, Q. Chen, X. Chen, and K. Yu. Anitalker: animate vivid and diverse talking faces through identity-decoupled facial motion encoding. In International Conference on Multimedia, 2024. Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In IEEE/CVF International Conference on Computer Vision, 2015. Z. Liu, M. Li, Y. Zhang, C. Wang, Q. Zhang, J. Wang, and Y. Nie. Fine-grained face swapping via regional gan inversion. arXiv preprint arXiv:2211.14068, 2022. S. R. Livingstone and F. A. Russo. The ryerson audio-visual database of emotional speech and song (ravdess): dynamic, multimodal set of facial and vocal expressions in north american english. PloS one, 2018. I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In International Conference on Learning Representations, 2017. H. Ma, T. Zhang, S. Sun, X. Yan, K. Han, and X. Xie. Cvthead: One-shot controllable head avatar with vertex-feature transformer. Winter Conference on Applications of Computer Vision, 2024a. Y. Ma, S. Zhang, J. Wang, X. Wang, Y. Zhang, and Z. Deng. Dreamtalk: When expressive talking head generation meets diffusion probabilistic models. arXiv preprint arXiv:2312.09767, 2023. Y. Ma, H. Liu, H. Wang, H. Pan, Y. He, J. Yuan, A. Zeng, C. Cai, H. Shum, W. Liu, et al. Follow-your-emoji: Fine-controllable and expressive freestyle portrait animation. arXiv preprint arXiv:2406.01900, 2024b. MahmoudiMA. MMA FACIAL EXPRESSION: Mmafedb large-scale facial-expression images. https: //www.kaggle.com/datasets/mahmoudima/mma-facial-expression, 2020. B. Maze, J. Adams, J. A. Duncan, N. Kalka, T. Miller, C. Otto, A. K. Jain, W. T. Niggel, J. Anderson, J. Cheney, et al. Iarpa janus benchmark-c: Face dataset and protocol. In International Conference on Biometrics, 2018. C. Meng, Y. He, Y. Song, J. Song, J. Wu, J. Zhu, and S. Ermon. Sdedit: Guided image synthesis and editing with stochastic differential equations. arXiv preprint arXiv:2108.01073, 2021. A. Mollahosseini, B. Hasani, and M. H. Mahoor. Affectnet: database for facial expression, valence, and arousal computing in the wild. Transactions on Affective Computing, 2017. Scaling Laws for Deepfake Detection S. Moschoglou, A. Papaioannou, C. Sagonas, J. Deng, I. Kotsia, and S. Zafeiriou. Agedb: the first In Conference on Computer Vision and Pattern manually collected, in-the-wild age database. Recognition Workshops, 2017. MPLab. The MPLab GENKI Database, GENKI-4K Subset, 2009. S. Mukhopadhyay, S. Suri, R. T. Gadde, and A. Shrivastava. Diff2lip: Audio conditioned diffusion models for lip-synchronization. In PWinter Conference on Applications of Computer Vision, 2024. K. Narayan, H. Agarwal, K. Thakral, S. Mittal, M. Vatsa, and R. Singh. Df-platter: Multi-face heterogeneous deepfake dataset. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023. A. Naumann, X. Gu, T. Dimlioglu, M. Bojarski, A. Degirmenci, A. Popov, D. Bisla, M. Pavone, U. Muller, and B. Ivanovic. Data scaling laws for end-to-end autonomous driving. In Conference on Computer Vision and Pattern Recognition Conference, 2025. H. Ng and S. Winkler. data-driven approach to cleaning large face datasets. In International Conference on Image Processing, 2014. Y. Nirkin, Y. Keller, and T. Hassner. FSGAN: Subject agnostic face swapping and reenactment. In IEEE/CVF International Conference on Computer Vision, 2019. Z. Niu, M. Zhou, L. Wang, X. Gao, and G. Hua. Ordinal regression with multiple output cnn for age estimation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2016. U. Ojha, Y. Li, and Y. J. Lee. Towards universal fake image detectors that generalize across generative models. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023. OpenAI. gpt-image-1: Natively multimodal image-generation model. https://platform. openai.com/docs/models/gpt-image-1, 2025. K. Panetta, Q. Wan, S. Agaian, S. Rajeev, S. Kamath, R. Rajendran, S. P. Rao, A. Kaszowska, H. A. Taylor, A. Samani, et al. comprehensive database for benchmarking imaging systems. Transactions on Pattern Analysis and Machine Intelligence, 2018. S. Paul. flux-image-editing: Scripts to teach flux the task of image editing from language. https: //github.com/sayakpaul/flux-image-editing, 2025. G. Pei, J. Zhang, M. Hu, G. Zhai, C. Wang, Z. Zhang, J. Yang, C. Shen, and D. Tao. Deepfake generation and detection: benchmark and survey. arXiv preprint arXiv:2403.17881, 2024. M. Pernu≈°, V. ≈†truc, and S. Dobri≈°ek. Maskfacegan: High-resolution face editing with masked gan latent code optimization. Transactions on Image Processing, 2023. Pika. Pika. https://pika.art, 2024. PixArt. PixArt-XL-2-512x512: Pixart-alpha text-to-image diffusion model. https://huggingface. co/PixArt-alpha/PixArt-XL-2-512x512, 2023. D. Podell, Z. English, K. Lacey, A. Blattmann, T. Dockhorn, J. M√ºller, J. Penna, and R. Rombach. Sdxl: Improving latent diffusion models for high-resolution image synthesis. In International Conference on Learning Representations, 2023. R. Prajwal, K. R. Mukhopadhyay, V. P. Namboodiri, and V. Jawahar, C. lip sync expert is all you need for speech to lip generation in the wild. In International Conference on Multimedia, 2020. 19 Scaling Laws for Deepfake Detection D. Qiu, Z. Fei, R. Wang, J. Bai, C. Yu, M. Fan, G. Chen, and X. Wen. Skyreels-a1: Expressive portrait animation in video diffusion transformers. arXiv preprint arXiv:2502.10841, 2025. A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, 2021. K. Ricanek and T. Tesafaye. Morph: longitudinal image database of normal adult age-progression. In International Conference on Automatic Face and Gesture Recognition, 2006. A. Rochow, M. Schwarz, and S. Behnke. FSRT: Facial scene representation transformer for face reenactment from factorized appearance, head-pose, and facial expression features. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024. R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-resolution image synthesis with latent diffusion models. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. F. Rosberg, E. E. Aksoy, F. Alonso-Fernandez, and C. Englund. Facedancer: Poseand occlusion-aware high fidelity face swapping. In Winter Conference on Applications of Computer Vision, 2023. A. R√∂ssler, D. Cozzolino, L. Verdoliva, C. Riess, J. Thies, and M. Nie√üner. FaceForensics++: Learning to detect manipulated facial images. In IEEE/CVF International Conference on Computer Vision, 2019. A. Rossler, D. Cozzolino, L. Verdoliva, C. Riess, J. Thies, and M. Nie√üner. Faceforensics++: Learning to detect manipulated facial images. In IEEE/CVF International Conference on Computer Vision, 2019. L. Rout, Y. Chen, N. Ruiz, C. Caramanis, S. Shakkottai, and W. Chu. Semantic image inversion and editing using rectified stochastic differential equations. In International Conference on Learning Representations, 2025. A. Sauer, K. Schwarz, and A. Geiger. Stylegan-xl: Scaling stylegan to large diverse datasets. In Conference and Exhibition on Computer Graphics and Interactive Technique, 2022. S. Sengupta, J. Chen, C. Castillo, V. M. Patel, R. Chellappa, and D. W. Jacobs. Frontal to profile face verification in the wild. In Winter Conference on Applications of Computer Vision, 2016. S. Setty, M. Husain, P. Beham, J. Gudavalli, M. Kandasamy, R. Vaddi, V. Hemadri, J. Karure, R. Raju, B. Rajan, et al. Indian movie face database: benchmark for face recognition under wide variations. In National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics, 2013. J. Shen, S. Zafeiriou, G. G. Chrysos, J. Kossaifi, G. Tzimiropoulos, and M. Pantic. The first facial landmark tracking in-the-wild challenge: Benchmark and results. In International Conference on Computer Vision Workshops, 2015. S. Shi, X. Cao, J. Zhao, and G. Wang. Joyhallo: Digital human model for mandarin. arXiv preprint arXiv:2409.13268, 2024. K. Shiohara, X. Yang, and T. Taketomi. Blendface: Re-designing identity encoders for face-swapping. In IEEE/CVF International Conference on Computer Vision, 2023. A. Siarohin, S. Lathuili√®re, S. Tulyakov, E. Ricci, and N. Sebe. First order motion model for image animation. In Conference on Neural Information Processing Systems, 2019. 20 Scaling Laws for Deepfake Detection H. Song, S. Huang, Y. Dong, and W. Tu. Robustness and generalizability of deepfake detection: study with diffusion models. arXiv preprint arXiv:2309.02218, 2023. K. Sun, J. Pan, Y. Ge, H. Li, H. Duan, X. Wu, R. Zhang, A. Zhou, Z. Qin, Y. Wang, et al. Journeydb: benchmark for generative image understanding. Conference on Neural Information Processing Systems, 2023a. K. Sun, J. Pan, Y. Ge, H. Li, H. Duan, X. Wu, R. Zhang, A. Zhou, Z. Qin, Y. Wang, et al. Journeydb: benchmark for generative image understanding. Conference on Neural Information Processing Systems, 2023b. Y. Sun, H. H. Nguyen, C. Lu, Z. Zhang, L. Sun, and I. Echizen. Generalized deepfakes detection with reconstructed-blended images and multi-scale feature reconstruction network. In International Joint Conference on Biometrics, 2024. C. Tan, Y. Zhao, S. Wei, G. Gu, P. Liu, and Y. Wei. Frequency-aware deepfake detection: Improving generalizability through frequency space domain learning. In AAAI Conference on Artificial Intelligence, 2024a. S. Tan, B. Ji, M. Bi, and Y. Pan. Edtalk: Efficient disentanglement for emotional talking head synthesis. In European Conference on Computer Vision, 2024b. J. Tao, S. Gu, W. Li, and L. Duan. Learning motion refinement for unsupervised face animation. In Conference on Neural Information Processing Systems, 2023. Y. Tay, M. Dehghani, S. Abnar, H. W. Chung, W. Fedus, J. Rao, S. Narang, V. Q. Tran, D. Yogatama, and D. Metzler. Scaling laws vs model architectures: How does inductive bias influence scaling? arXiv preprint arXiv:2207.10551, 2022. J. Thies, M. Zollhofer, M. Stamminger, C. Theobalt, and M. Nie√üner. Face2face: Real-time face capture and reenactment of rgb videos. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 23872395, 2016. J. Thies, M. Zollh√∂fer, and M. Nie√üner. Deferred neural rendering: Image synthesis using neural textures. Transactions on Graphics, 2019. K. Tian, Y. Jiang, Z. Yuan, B. Peng, and L. Wang. Visual autoregressive modeling: Scalable image generation via next-scale prediction. Conference on Neural Information Processing Systems, 2024. H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablayrolles, and H. J√©gou. Training data-efficient image transformers & distillation through attention. In International Conference on Machine Learning, 2021. H. Touvron, M. Cord, and H. J√©gou. Deit iii: Revenge of the vit. In European Conference on Computer Vision, 2022. O. Tov, Y. Alaluf, Y. Nitzan, O. Patashnik, and D. Cohen-Or. Designing an encoder for stylegan image manipulation. Transactions on Graphics, 2021. M. Tschannen, A. Gritsenko, X. Wang, M. F. Naeem, I. Alabdulmohsin, N. Parthasarathy, T. Evans, L. Beyer, Y. Xia, B. Mustafa, et al. Siglip 2: Multilingual vision-language encoders with improved semantic understanding, localization, and dense features. arXiv preprint arXiv:2502.14786, 2025. B. Wallace, A. Gokul, and N. Naik. Edict: Exact diffusion inversion via coupled transformations. arXiv preprint arXiv:2211.12446, 2022. 21 Scaling Laws for Deepfake Detection Wan-Team. Wan: Open and advanced large-scale video generative models. arXiv preprint arXiv:2503.20314, 2025. D. Wang. TinyFace: The minimalist face swapping tool that just works. https://github.com/ idootop/TinyFace, 2024. F. Wang, L. Chen, C. Li, S. Huang, Y. Chen, C. Qian, and C. C. Loy. The devil of face recognition is in the noise. In European Conference on Computer Vision, 2018. H. Wang. inswapper: One-click face swapper and restoration powered by insightface. https: //github.com/haofanwang/inswapper, 2023. J. Wang, Z. Tian, X. Wang, X. Zhang, W. Huang, Z. Wu, and Y. Jiang. Simplear: Pushing the frontier of autoregressive visual generation through pretraining, sft, and rl. arXiv preprint arXiv:2504.11455, 2025. K. Wang, Q. Wu, L. Song, Z. Yang, W. Wu, C. Qian, R. He, Y. Qiao, and C. C. Loy. Mead: large-scale audio-visual dataset for emotional talking-face generation. In European Conference on Computer Vision, 2020. Q. Wang, X. Bai, H. Wang, Z. Qin, A. Chen, H. Li, X. Tang, and Y. Hu. Instantid: Zero-shot identitypreserving generation in seconds. arXiv preprint arXiv:2401.07519, 2024a. S. Wang, L. Li, Y. Ding, C. Fan, and X. Yu. Audio2head: Audio-driven one-shot talking-head generation with natural head motion. In International Joint Conference on Artificial Intelligence, 2021a. T. Wang, A. Mallya, and M. Liu. One-shot free-view neural talking-head synthesis for video conferencing. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021b. W. Wang and Y. Yang. Vidprom: million-scale real prompt-gallery dataset for text-to-video diffusion models. In Conference on Neural Information Processing Systems, 2024. W. Wang, Y. Sun, Z. Tan, and Y. Yang. Anypattern: Towards in-context image copy detection. arXiv preprint arXiv:2404.13788, 2024b. Y. Wang, X. Chen, J. Zhu, W. Chu, Y. Tai, C. Wang, J. Li, Y. Wu, F. Huang, and R. Ji. Hififace: 3d shape and semantic prior guided high fidelity face swapping. arXiv preprint arXiv:2106.09965, 2021c. Y. Wang, D. Yang, F. Bremond, and A. Dantcheva. Latent image animator: Learning to animate images via latent space navigation. arXiv preprint arXiv:2203.09043, 2022. Z. Wang, B. Huang, G. Wang, P. Yi, and K. Jiang. Masked face recognition dataset and application. Transactions on Biometrics, Behavior, and Identity Science, 2023a. Z. J. Wang, E. Montoya, D. Munechika, H. Yang, B. Hoover, and D. H. Chau. Diffusiondb: large-scale prompt gallery dataset for text-to-image generative models. In Annual Meeting of the Association for Computational Linguistics, 2023b. H. Wei, Z. Yang, and Z. Wang. Aniportrait: Audio-driven synthesis of photorealistic portrait animation. arXiv preprint arXiv:2403.17694, 2024. J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022. 22 Scaling Laws for Deepfake Detection M. Wei, T. Varanka, X. Jiang, H. Khor, and G. Zhao. Magicface: High-fidelity facial expression editing with action-unit control. arXiv preprint arXiv:2501.02260, 2025a. M. Wei, T. Varanka, Y. Li, X. Jiang, H. Khor, and G. Zhao. Towards consistent and controllable image synthesis for face editing. arXiv preprint arXiv:2502.02465, 2025b. L. Wolf, T. Hassner, and I. Maoz. Face recognition in unconstrained videos with matched background similarity. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2011. C. Xu, J. Zhang, Y. Han, G. Tian, X. Zeng, Y. Tai, Y. Wang, C. Wang, and Y. Liu. Designing one unified framework for high-fidelity face reenactment and swapping. In European Conference on Computer Vision, 2022a. Z. Xu, Z. Hong, C. Ding, Z. Zhu, J. Han, J. Liu, and E. Ding. Mobilefaceswap: lightweight framework for video face swapping. In AAAI Conference on Artificial Intelligence, 2022b. Z. Yan, Y. Zhang, X. Yuan, S. Lyu, and B. Wu. Deepfakebench: comprehensive benchmark of deepfake detection. In Conference on Neural Information Processing Systems, 2023. Z. Yan, T. Yao, S. Chen, Y. Zhao, X. Fu, J. Zhu, D. Luo, C. Wang, S. Ding, Y. Wu, et al. Df40: Toward next-generation deepfake detection. In Conference on Neural Information Processing Systems, 2024. Z. Yan, J. Wang, P. Jin, K. Zhang, C. Liu, S. Chen, T. Yao, S. Ding, B. Wu, and L. Yuan. Orthogonal subspace decomposition for generalizable ai-generated image detection. In International Conference on Machine Learning, 2025a. Z. Yan, J. Wang, P. Jin, K. Zhang, C. Liu, S. Chen, T. Yao, S. Ding, B. Wu, and L. Yuan. Orthogonal subspace decomposition for generalizable ai-generated image detection. In International Conference on Machine Learning, 2025b. C. Yang, K. Yao, Y. Yan, C. Jiang, W. Zhao, J. Sun, G. Cheng, Y. Zhang, B. Dong, and K. Huang. Unlock pose diversity: Accurate and efficient implicit keypoint-based spatiotemporal diffusion for audio-driven talking portrait. arXiv preprint arXiv:2503.12963, 2025a. S. Yang, P. Luo, C. Loy, and X. Tang. Wider face: face detection benchmark. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2016. S. Yang, H. Li, J. Wu, M. Jing, L. Li, R. Ji, J. Liang, and H. Fan. Megactor: Harness the power of raw video for vivid portrait animation. arXiv preprint arXiv:2405.20851, 2024. X. Yang, Y. Li, and S. Lyu. Exposing deep fakes using inconsistent head poses. In International Conference on Acoustics, Speech and Signal Processing, 2019. Z. Yang, J. Teng, W. Zheng, M. Ding, S. Huang, J. Xu, Y. Yang, W. Hong, X. Zhang, G. Feng, D. Yin, Yuxuan.Zhang, W. Wang, Y. Cheng, B. Xu, X. Gu, Y. Dong, and J. Tang. Cogvideox: Text-to-video diffusion models with an expert transformer. In International Conference on Learning Representations, 2025b. C. H. Yap, C. Kendrick, and M. H. Yap. Samm long videos: spontaneous facial micro-and macroexpressions dataset. In International Conference on Automatic Face and Gesture Recognition, 2020. H. Ye, J. Zhang, S. Liu, X. Han, and W. Yang. Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models. In arXiv preprint arxiv:2308.06721, 2023. Z. Ye, T. Zhong, Y. Ren, J. Yang, W. Li, J. Huang, Z. Jiang, J. He, R. Huang, J. Liu, et al. Real3d-portrait: One-shot realistic 3d talking portrait synthesis. arXiv preprint arXiv:2401.08503, 2024. Scaling Laws for Deepfake Detection D. Yi, Z. Lei, S. Liao, and S. Z. Li. Learning face representation from scratch. arXiv preprint arXiv:1411.7923, 2014. Q. Yu, W. Chow, Z. Yue, K. Pan, Y. Wu, X. Wan, J. Li, S. Tang, H. Zhang, and Y. Zhuang. Anyedit: Mastering unified high-quality image editing for any idea. arXiv preprint arXiv:2411.15738, 2024. X. Zhai, A. Kolesnikov, N. Houlsby, and L. Beyer. Scaling vision transformers. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. W. Zhang, X. Cun, X. Wang, Y. Zhang, X. Shen, Y. Guo, Y. Shan, and F. Wang. Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation. arXiv preprint arXiv:2211.12194, 2022. Y. Zhang and W. Deng. Class-balanced training for deep face recognition. In Conference on Computer Vision and Pattern Recognition Workshops, 2020. Y. Zhang, L. Liu, C. Li, and C. C. Loy. Quantifying facial age by posterior of age comparisons. arXiv preprint arXiv:1708.09687, 2017a. Z. Zhang, Y. Song, and H. Qi. Age progression/regression by conditional adversarial autoencoder. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2017b. Z. Zhang, P. Luo, C. C. Loy, and X. Tang. From facial expression recognition to interpersonal relation prediction. International Journal of Computer Vision, 2018. J. Zhao, H. Zhang, and J. Zhao. Thin-plate spline motion model for image animation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. K. Zheng. face-vid2vid: Unofficial implementation of \"one-shot free-view neural talking-head synthesis for video conferencing\". https://github.com/zhengkw18/face-vid2vid, 2021. W. Zheng, J. Teng, Z. Yang, W. Wang, J. Chen, X. Gu, Y. Dong, M. Ding, and J. Tang. Cogview3: Finer and faster text-to-image generation via relay diffusion. arXiv preprint arXiv:2403.05121, 2024. W. Zhong, C. Fang, Y. Cai, P. Wei, G. Zhao, L. Lin, and G. Li. Identity-preserving talking face generation with landmark and appearance priors. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023. J. Zhou, Y. Li, B. Wu, B. Li, J. Dong, et al. Freqblender: Enhancing deepfake detection by blending frequency knowledge. Conference on Neural Information Processing Systems, 2024a. T. Zhou, W. Wang, Z. Liang, and J. Shen. Face forensics in the wild. In Cconference on Computer Vision and Pattern Recognition, 2021. W. Zhou, X. Luo, Z. Zhang, J. He, and X. Wu. Capture artifacts via progressive disentangling and purifying blended identities for deepfake detection. arXiv preprint arXiv:2410.10244, 2024b. Y. Zhou, X. Han, E. Shechtman, J. Echevarria, E. Kalogerakis, and D. Li. Makeittalk: Speaker-aware talking-head animation. Transactions on Graphics, 2020. H. Zhu, W. Wu, W. Zhu, L. Jiang, S. Tang, L. Zhang, Z. Liu, and C. C. Loy. Celebv-hq: large-scale video facial attributes dataset. In European Conference on Computer Vision, 2022. B. Zi, M. Chang, J. Chen, X. Ma, and Y. Jiang. Wilddeepfake: challenging real-world dataset for deepfake detection. In International Conference on Multimedia, 2020. 24 Scaling Laws for Deepfake Detection Table 6 Real datasets included in the ScaleDF, with the testing ones highlighted in . No. Dataset Format Vol. Link No. Dataset Format Vol. Link 0 1 2 3 4 5 6 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 GRID (Cooke et al., 2006) MORPH-2 (Ricanek and Tesafaye, 2006) LFW (Huang et al., 2008) Multi-PIE (Gross et al., 2008) GENKI-4K (MPLab, 2009) YouTubeFaces (Wolf et al., 2011) IMFDB (Setty et al., 2013) Adience (Eidinger et al., 2014) CACD (Chen et al., 2014) CASIA-WebFace (Yi et al., 2014) CREMA-D (Cao et al., 2014) FaceScrub (Ng and Winkler, 2014) 300VW (Shen et al., 2015) CelebA (Liu et al., 2015) AFAD (Niu et al., 2016) CFPW (Sengupta et al., 2016) WIDER FACE (Yang et al., 2016) AffectNet (Mollahosseini et al., 2017) AgeDB (Moschoglou et al., 2017) MAFA (Ge et al., 2017) RAF-DB (Li et al., 2017) UMDFaces (Bansal et al., 2017) UTKFace (Zhang et al., 2017b) AFEW-VA (Kossaifi et al., 2017) MegaAge (Zhang et al., 2017a) AVA (Gu et al., 2018) Video Image 16K+ Link 49K+ Link Image 13K+ Link Image 0.1M+ Link 3.8K+ Link Image Image 0.2M+ Link 10K+ Link Image Image 18K+ Link Image 0.1M+ Link Image 0.2M+ Link 19K+ Link Image 41K+ Link Image Video 0.9K+ Link Image 0.1M+ Link Image 0.1M+ Link 5.5K+ Link Image 20K+ Link Image 30K+ Link Image 15K+ Link Image 0.5K+ Link Image Image 9.8K+ Link Image 0.2M+ Link 23K+ Link Image 22K+ Link Image 40K+ Link 0.1M+ Link Image Video 26 27 28 29 31 32 33 34 35 37 38 39 40 41 43 44 45 46 47 49 50 AVSpeech (Ephrat et al., 2018) Video 0.1M+ Link ExpW (Zhang et al., 2018) Image 67K+ Link IMDb-Face (Wang et al., 2018) Image 0.2M+ Link RAVDESS (Livingstone and Russo, 2018) Video 2.4K+ Link Tufts Face (Panetta et al., 2018) Image 2.9K+ Link VGGFace2 (Cao et al., 2018b) Image 0.2M+ Link Celeb-500K (Cao et al., 2018a) Image 0.2M+ Link IJB-C (Maze et al., 2018) Image 0.2M+ Link VoxCeleb2 (Chung et al., 2018) Video 0.5M+ Link Aff-Wild2 (Kollias and Zafeiriou, 2019) Image 0.1M+ Link FFHQ (Karras et al., 2019) Image 51K+ Link FaceForensics++ (R√∂ssler et al., 2019) Video 1K Link BUPT-CBFace (Zhang and Deng, 2020) Image 0.2M+ Link DFEW (Jiang et al., 2020b) Video 8.1K+ Link MEAD (Wang et al., 2020) Image 0.2M+ Link MMA (MahmoudiMA, 2020) Image 79K+ Link SAMM V3 (Yap et al., 2020) Image 11K+ Link FairFace (Karkkainen and Joo, 2021) Image 79K+ Link Glint360K (An et al., 2021) Image 0.2M+ Link SpeakingFaces (Abdrakhmanova et al., 2021) Image 0.2M+ Link Wiki-Faces (Ford and Shao, 2021) Image 39K+ Link Asian-Celeb (kyquac, 2022) Image 0.2M+ Link CelebV-HQ (Zhu et al., 2022) Video 17K+ Link RMFD (Wang et al., 2023a) Image 22K+ Link FaceVid-1K (Di et al., 2024) Video 0.7K+ Link A. Data Preprocessing Pipeline In this section, we describe the data preprocessing pipeline, which we follow from DF40 (Yan et al., 2024) and DeepfakeBench (Yan et al., 2023), consisting of face detection, alignment, and cropping. Face detection. For each input image, the preprocessing begins with locating the facial region. We utilize the frontal face detector from the Dlib library (King, 2009), widely adopted method based on Histogram of Oriented Gradients (HOG) features. The detector identifies all potential facial bounding boxes in the image. To focus on the primary subject, when multiple faces are detected, we select the one with the largest bounding box area. If no face is detected, the image is discarded. Alignment. Following face detection, facial alignment procedure is applied to standardize the pose and scale of the detected faces. This process involves two key steps: (1) Landmark localization. We employ Dlibs pre-trained 81-point facial landmark predictor to accurately identify key facial features. From the detected landmarks, we select five critical points used for alignment: the centers of the left and right eyes, the tip of the nose, and the left and right corners of the mouth. (2) Transformation estimation. similarity transformation is computed to map the selected landmarks to predefined set of canonical coordinates that represent an ideal, upright facial configuration. Cropping. The final step leverages the alignment information to crop the face from the original image. The computed affine transformation matrix is applied to the full image, simultaneously rotating, scaling, and translating it to center the aligned face within new canvas. scaling parameter, set to 1.3 in our implementation, defines the cropping boundary to avoid overly tight crops and preserve contextual facial regions such as the forehead, chin, and hair. The resulting aligned and cropped 25 Scaling Laws for Deepfake Detection Figure 5 Left Top: observed power-law scaling as the number of training real domains changes; Right Top: observed power-law scaling as the number of training deepfake methods changes; Left Bottom: observed double-saturating power-law scaling as the number of training images changes; Right Bottom: performance changes with respect to model sizes. ùúá represents the mean computed over repetitions and test datasets, while ùúé denotes the variance across repetitions. image is then resized to fixed resolution of 256 256 pixels for subsequent processing. B. Visualization of processed faces As illustrated in Tables 20 to 35, five processed faces are randomly sampled for each real dataset (domain) and deepfake method to provide visual examples. C. Scaling laws with EER In this section, we investigate whether similar scaling laws hold under different evaluation metric, i.e., EER. To this end, we replicate the scaling law analysis presented in the main paper. As shown in Fig. 5, similar scaling laws can also be observed in terms of EER (The complete experimental results can be found in Appendix (Section E)). Specifically, we conclude that: Power-law scaling is observed with respect to the number of training real domains and deepfake methods, respectively. To study the scaling law along these dimensions, we randomly sample ùëÅ {5, 8, 11, 16, 23, 32} real domains from total of 46 and ùëÅ {11, 16, 22, 32, 45, 64} deepfake methods from total of 88, respectively. To reduce randomness, each sampling is repeated 10 times. 26 Scaling Laws for Deepfake Detection For each sampled set of real domains, we train model using all fake images and the corresponding real images from those domains; while for each sampled set of deepfake methods, we train model using all real images and the corresponding fake images generated by those methods. Each ùúá in Fig. 5 (Top) represents the mean computed over 10 repetitions and 7 test datasets, while ùúé denotes the variance across the 10 repetitions. Based on these empirical data points, we observe that the trend of EER with respect to the number of real domains or deepfake methods (ùëÅ) is best described by power law, which is the same form as originally proposed for LLMs (Kaplan et al., 2020), i.e., EER = ùê¥ ùëÅ ùõº. Using ordinary least squares (OLS), we estimate the parameters as ùê¥ = 0.627 with ùõº = 0.316 for real domains, and ùê¥ = 0.552 with ùõº = 0.244 for deepfake methods. Meanwhile, we calculate the coefficient of determination ùëÖ2 = 0.9874 and ùëÖ2 = 0.9928, respectively, implying that the fitted power law explains 98.74% and 99.28% of the variance in the observed data, thus providing an excellent description of the scaling relationship. This scaling law suggests that the performance with respect to the number of real domains and deepfake methods is far from saturated. To achieve higher performance, collecting more real domains and deepfake methods proves to be highly effective. Furthermore, the models performance is, to some extent, predictable: for example, to reach an average EER of 0.10, we may require about 340 real domains or 1100 deepfake methods. The two scaling laws described above are not caused by change in the number of real or fake images. When conducting experiments by randomly sampling real domains, the number of real images changes (while the number of fake images remains fixed); conversely, when randomly sampling deepfake methods, the number of fake images changes (with the number of real images unchanged). natural question is whether the performance changes or the observed scaling laws are caused by changes in the number of real or fake images. Our answer is no. To support this argument, we conduct two experiments: (1) we keep the number of fake images fixed and randomly sample 1/10 of the real images for training; the resulting EER decreases slightly from 0.184 to 0.193; (2) we keep the number of real images fixed and randomly sample 1/10 of the fake images for training; the resulting EER drops from 0.184 to 0.198 slightly. We use 1/10 here because, when studying scaling laws, we use more than 1/10 of the real domains or deepfake methods. These small changes in EER suggest that the observed scaling laws are indeed related to the number of real domains and deepfake methods, rather than the number of real or fake images. Double-saturating power-law scaling is observed with respect to the number of training images. To study the scaling law along this dimension, we randomly sample subsets of the ScaleDF training set at the following proportions: 1/4, 1/10, 1/16, 1/64, 1/100, 1/256, 1/1000. Note that this differs from the previous section, i.e., here we sample real and fake images simultaneously. To reduce randomness, each sampling is repeated 5 times. Each ùúá in Fig. 5 (Left Bottom) represents the mean computed over 5 repetitions and 7 test datasets, while ùúé denotes the variance across the 5 repetitions. Based on these empirical data points, we observe that the trend of EER with respect to the number of training images (ùëÅ) is best described by double-saturating power law, which is the same form as originally proposed in image classification (Zhai et al., 2022), i.e., EER = ùëê + ùêæ (ùëÅ + ùëÅ0) ùõæ. Using ordinary least squares (OLS), we estimate the parameters as ùëê = 0.175, ùêæ = 1.44 103, ùëÅ0 = 1.19 105, and ùõæ = 0.710. Meanwhile, we calculate the coefficient of determination ùëÖ2 = 0.9989, implying that the fitted power law explains 99.89% of the variance in the observed data, thus providing an excellent description of the scaling relationship. This scaling law suggests that, with 46 real domains and 88 deepfake methods, performance gradually saturates once the total number of training images exceeds 107. To further improve performance, blindly collecting more images from the same real domains or generating more from the same deepfake methods may not be effective. However, this does not imply that datasets larger than 107 images offer no further benefit for deepfake detection. Rather, as we scale up the number of real domains and deepfake methods, more training data will still be essential. 27 Scaling Laws for Deepfake Detection When training on ScaleDF, model size scaling appears to saturate at around 300 million parameters. Beyond the aforementioned scaling laws, we are also interested in scaling along the model size dimension, i.e., how large model ScaleDF can support. Specifically, we select five different model sizes, denoted as ViT-S (21.7M), ViT-M (38.3M), ViT-B (85.8M), ViT-L (303.4M), and ViT-H (630.8M). Each ùúá in Fig. 5 (Right Bottom) represents the mean computed over 7 test datasets. Performance consistently improves from ViT-S (21.7M) to ViT-L (303.4M), but saturates thereafter, as further scaling to ViT-H (630.8M) yields no gains. This observation does not suggest that models with more than 300M parameters bring no additional gain for the deepfake detection task; rather, it indicates the maximum model size currently supported by the ScaleDF dataset. In the future, as we scale up real domains and deepfake methods, larger models may yield better performance. D. Used perturbations In this section, we describe how the perturbations from AnyPattern (Wang et al., 2024b) are utilized. AnyPattern is large-scale perturbation dataset containing 100 perturbations. The code for generating each perturbation is available at here. However, since not all of them occur frequently in real-world scenarios, we select 30 common perturbations for training. To demonstrate the effect of the 30 selected perturbations, Fig. 6 shows the original face, while Tables 36, 37, and 38 present example faces with the applied perturbations. During training, for each image, we apply no perturbations with probability of 50%, single perturbation with probability of 25%, and two perturbations with probability of 25%. Figure 6 Used original face. E. Complete experimental results for scaling laws In the main paper, we skip the exact values for each data point used in the scaling law analysis. To improve the reproducibility, we present all experimental results here in full detail. Specifically: (1) Tables 12 and 16 report the exact AUC and EER values for scaling laws with respect to the number of real domains; (2) Tables 13 and 17 report the exact AUC and EER values with respect to the number of deepfake methods; (3) Tables 14 and 18 report the exact AUC and EER values with respect to the number of training images; and (4) Tables 15 and 19 report the exact AUC and EER values with respect to different model sizes. F. Training details We report training details here, basically following the scaling law reproducibility checklist (Li et al., 2025). The generation of ScaleDF required about 20, 000 A100 GPU hours. Training is distributed across 8 NVIDIA A100 40GB NVLink GPUs and 128 AMD EPYC 7742 CPU cores. Each training run requires approximately 160 GPU hours. Before training, all images are resized to resolution of 224 224 pixels. We use batch size of 2, 048 and train for 20 epochs with class balancing. The AdamW optimizer (Loshchilov and Hutter, 2017) is used with cosine-decay learning rate schedule, peak learning rate of 105, and 5 warm-up epochs. G. Additional Observations in EER As shown in Tables 7 to 10, the observations in Section 5 still hold when evaluated with an alternative metric. 28 Scaling Laws for Deepfake Detection Table 7 Comparison of using different pre-training models: similar performance observed. EER ImageNet CLIP SigLIP 2 DFD 0.281 0.278 0.316 CDF V2 0.162 0.179 0.193 Wild 0.268 0.279 0.290 Forgery. 0.260 0.231 0.229 DFF 0.161 0.085 0. DF40 0.063 0.065 0.052 ScaleDF 0.093 0.052 0.052 Table 8 Effectiveness of image quality compression (QC) and perturbations (PT). EER N/A QC QC + PT DFD 0.391 0.302 0.281 CDF V2 0.270 0.164 0. Wild 0.299 0.278 0.268 Forgery. 0.315 0.300 0.260 DFF 0.261 0.130 0.161 DF40 0.136 0.065 0.063 ScaleDF 0.066 0.076 0.093 Mean 0.184 0.167 0. Mean 0.248 0.188 0.184 Table 9 Comparison in cross-benchmark setting: with scaling, we achieve the best performance. EER DFD CDF V2 Wild Forgery. DFF DF40 ScaleDF DFD 0.352 0.396 0.267 0.438 0.439 0.281 CDF V2 0.276 0.309 0.170 0.454 0.267 0. Wild 0.322 0.288 0.275 0.470 0.354 0.268 Forgery. 0.425 0.401 0.462 0.445 0.375 0.260 DFF 0.470 0.419 0.517 0.372 0.421 0.161 s n T DF40 0.428 0.383 0.451 0.251 0.376 0.063 ScaleDF 0.488 0.417 0.462 0.390 0.407 0.352 Table 10 Comparison of whether includes FaceForensics++ (R√∂ssler et al., 2019) in ScaleDF. EER w/o FF++ FF++ DFD 0.319 0.281 CDF V2 0.188 0. Wild 0.276 0.268 Forgery. 0.290 0.260 DFF 0.185 0.161 DF40 0.083 0.063 ScaleDF 0.081 0.093 Mean 0.203 0. H. Ethics Statement We adhere to the license terms of all data and models in constructing ScaleDF. We are committed to responsible research, though there are open issues around fairness and bias. We put some important considerations here for interested readers. H.1. Licenses Our work builds upon numerous publicly available resources. In constructing ScaleDF, we have made every effort to comply with the licenses of all constituent datasets and deepfake generation methods. Full lists of these resources, along with direct links to their original sources, are provided in Table 6 and Table 11 to ensure transparency and enable reproducibility. H.2. Fairness Recognizing that large-scale datasets can inherit and amplify societal biases, we have analyzed the demographic distribution of what the faces appear to be within ScaleDF, using pre-trained models from third parties. While we aimed for inclusiveness, as shown in Fig. 7, our dataset inherits imbalances from the included real domains and deepfake methods, which we document here to ensure transparency and guide future research. 29 Scaling Laws for Deepfake Detection Figure 7 Perceived demographic distribution of faces in ScaleDF. Perceived Monk Skin Tone (MST) Distribution. The dataset shows an imbalance across different MSTs, with strong concentration around MSTs 5, 6, 7, 8 (out of 10). This over-representation may result in performance disparities in detection models. Perceived Age Distribution. There is strong concentration in the 20 29 (about 7.5 million) and 30 39 (about 3.5 million) perceived age groups. Younger and older individuals are underrepresented, with groups like > 70 and 0 2 containing fewer than 0.1 million faces each. This may limit the reliability of detectors for very young or elderly subjects. Perceived Gender Distribution. The perceived gender distribution is more balanced compared with age, but still shows skew. The dataset includes about 8.8 million male faces and 5.8 million female faces. We acknowledge these demographic biases as limitation of ScaleDF. This is the nature of the besteffort data acquisition process from the public domain. We encourage future researchers to apply sampling techniques to promote better fairness outcome. H.3. Broader Impact The primary goal of this research is to advance the capabilities of deepfake detection to combat malicious activities such as the spread of misinformation and the violation of personal privacy. By establishing predictable scaling laws, we provide the research community with valuable knowledge to build more robust and generalizable detectors, thereby strengthening societal defenses against manipulated media. I. LLM Usage We use an LLM-based writing assistant for minor grammar and style edits. All technical content, analyses, and conclusions are authored and verified by the human authors. Scaling Laws for Deepfake Detection Table 11 Deepfake methods included in the ScaleDF, with the testing ones highlighted in . No. Method Cat. Arch. Link No. Method Cat. Arch. Link 0 1 2 3 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 37 38 39 40 41 42 43 44 45 Faceswap (Earl, 2015) FaceSwap (Kowalski, 2016) DeepFakes (deepfakes, 2017) FSGAN (Nirkin et al., 2019) SimSwap (Chen et al., 2020) HifiFace (Wang et al., 2021c) InfoSwap (Gao et al., 2021) UniFace (Xu et al., 2022a) MobileFaceSwap (Xu et al., 2022b) E4S (Liu et al., 2022) GHOST (Groshev et al., 2022) BlendFace (Shiohara et al., 2023) FaceDancer (Rosberg et al., 2023) 3DSwap (Li et al., 2023) Inswapper (Wang, 2023) FaceAdapter (Han et al., 2024) CSCS (Huang et al., 2024) REFace (Baliah et al., 2024) FaceFusion (Wang, 2024) InstantID (Wang et al., 2024a) Diff Face (Kim et al., 2025) Face2Face (Thies et al., 2016) FOMM (Siarohin et al., 2019) NeuralTextures (Thies et al., 2019) OneShot (Wang et al., 2021b) Face-Vid2Vid (Zheng, 2021) TPSMM (Zhao et al., 2022) DaGAN (Hong et al., 2022) LIA (Wang et al., 2022) AMatrix (Bounareli et al., 2022) StyleMask (Bounareli et al., 2023a) MRFA (Tao et al., 2023) HyperReenact (Bounareli et al., 2023b) MCNet (Hong and Xu, 2023) CVTHead (Ma et al., 2024a) FollowYourEmoji (Ma et al., 2024b) LivePortrait (Guo et al., 2024) Megactor (Yang et al., 2024) G3FA (Javanmardi et al., 2024) FSRT (Rochow et al., 2024) SkyReels-A1 (Qiu et al., 2025) StyleGAN2 (Karras et al., 2020) VQGAN (Esser et al., 2021) StyleGAN3 (Karras et al., 2021) StyleGAN-XL (Sauer et al., 2022) SD2.1 (Rombach et al., 2022) SD1.5 (Rombach et al., 2022) 46 SDXL (Podell et al., 2023) 47 48 PixArt-Alpha (PixArt, 2023) 49 Midjourney (Sun et al., 2023a) SD3.5 (Esser et al., 2024) 50 FS FS FS FS FS FS FS FS FS FS FS FS FS FS FS FS FS FS FS FS FS FR FR FR FR FR FR FR FR FR FR FR FR FR FR FR FR FR FR FR FR FF FF FF FF FF FF FF FF FF FF Affine 3D VAE GAN GAN 3D GAN GAN GAN GAN GAN GAN GAN 3D GAN Diff. GAN Diff. GAN Diff. Diff. 3D Affine 3D 3D 3D Affine GAN Affine GAN GAN Affine GAN Affine 3D Diff. 3D Diff. 3D Affine Diff. GAN GAN GAN GAN Diff. Diff. Diff. Diff. N/A Diff. Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 91 93 94 95 96 Code Code Code Source Code 97 98 99 100 101 FLUX.1 [dev] (Black, 2024) CogView4 (Zheng et al., 2024) CogView3 (Zheng et al., 2024) Kolors (Kolors, 2024) Hunyuan-DiT (Li et al., 2024c) LTX-Video (HaCohen et al., 2024) HunyuanVideo (Kong et al., 2024) Pika (Pika, 2024) GPT-Image-1 (OpenAI, 2025) Janus-Pro (Chen et al., 2025a) SimpleAR (Wang et al., 2025) Wan-T2V (Wan-Team, 2025) Pyramid Flow (Jin et al., 2025) CogVideoX (Yang et al., 2025b) SDEdit (Meng et al., 2021) E4E (Tov et al., 2021) EDICT (Wallace et al., 2022) DiffusionCLIP (Kim et al., 2022) VecGAN (Dalva et al., 2022) InstructPix2Pix (Brooks et al., 2023) IP-Adapter (Ye et al., 2023) MaskFaceGAN (Pernu≈° et al., 2023) SDFlow (Li et al., 2024a) EmoStyle (Azari and Lim, 2024) Triplane (Bilecen et al., 2025) FaceID (Kwai, 2024) AnySD (Yu et al., 2024) MagicFace (Wei et al., 2025a) RigFace (Wei et al., 2025b) FluxEdit (Paul, 2025) RFInversion (Rout et al., 2025) Step1X-Edit (Liu et al., 2025) MakeItTalk (Zhou et al., 2020) Wav2Lip (Prajwal et al., 2020) Audio2Head (Wang et al., 2021a) SadTalker (Zhang et al., 2022) Video-Retalking (Cheng et al., 2022) DreamTalk (Ma et al., 2023) IP_LAP (Zhong et al., 2023) Real3DPortrait (Ye et al., 2024) FLOAT (Ki et al., 2024) JoyVASA (Cao et al., 2024) DAWN (Cheng et al., 2024b) AniTalker (Liu et al., 2024) AniPortrait (Wei et al., 2024) EDTalk (Tan et al., 2024b) Diff2Lip (Mukhopadhyay et al., 2024) JoyHallo (Shi et al., 2024) Ditto (Li et al., 2024b) KDTalker (Yang et al., 2025a) Echomimic (Chen et al., 2025b) FF FF FF FF FF FF FF FF FF FF FF FF FF FF FE FE FE FE FE FE FE FE FE FE FE FE FE FE FE FE FE FE TF TF TF TF TF TF TF TF TF TF TF TF TF TF TF TF TF TF TF Diff. Diff. Diff. Diff. Diff. Diff. Diff. N/A N/A AR AR Diff. AR Diff. Diff. GAN Diff. Diff. GAN Diff. Diff. GAN GAN GAN GAN Diff. Diff. Diff. Diff. Diff. Diff. LLM GAN GAN GAN 3D GAN Diff. GAN 3D Flow Diff. Diff. Diff. 3D 3D Diff. Diff. Diff. Diff. Diff. Code Code Code Code Code Code Code Source Source Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code Code 31 Scaling Laws for Deepfake Detection Table 12 Full experimental results measured by AUC for scaling law with varying numbers of real domains. The concluded scaling law is shown in Fig. 3 (Left). AUC 46 32 32 32 32 32 32 32 32 32 32 23 23 23 23 23 23 23 23 23 23 16 16 16 16 16 16 16 16 16 16 11 11 11 11 11 11 11 11 11 11 8 8 8 8 8 8 8 8 8 8 5 5 5 5 5 5 5 5 5 5 DFD 0.793 0.752 0.764 0.779 0.765 0.760 0.780 0.710 0.768 0.737 0.762 0.748 0.723 0.760 0.742 0.713 0.766 0.787 0.743 0.706 0.745 0.734 0.716 0.756 0.758 0.733 0.769 0.717 0.622 0.729 0.639 0.663 0.694 0.720 0.722 0.696 0.714 0.654 0.715 0.680 0.713 0.659 0.550 0.716 0.678 0.674 0.667 0.673 0.690 0.690 0.524 0.586 0.610 0.663 0.592 0.689 0.548 0.627 0.696 0.676 0.713 CDF V2 0.915 0.845 0.917 0.904 0.897 0.904 0.912 0.847 0.903 0.834 0.898 0.890 0.824 0.883 0.905 0.852 0.889 0.886 0.881 0.806 0.879 0.847 0.759 0.879 0.889 0.869 0.867 0.834 0.556 0.875 0.594 0.681 0.851 0.862 0.767 0.777 0.806 0.767 0.823 0.712 0.756 0.623 0.721 0.745 0.794 0.607 0.689 0.730 0.785 0.795 0.480 0.441 0.518 0.686 0.666 0.771 0.475 0.561 0.811 0.686 0.758 Wild 0.815 0.716 0.747 0.727 0.817 0.732 0.728 0.804 0.829 0.805 0.813 0.778 0.793 0.753 0.707 0.760 0.780 0.794 0.804 0.824 0.679 0.665 0.659 0.658 0.722 0.709 0.772 0.772 0.764 0.722 0.666 0.656 0.748 0.746 0.687 0.719 0.644 0.619 0.738 0.721 0.753 0.615 0.608 0.622 0.649 0.617 0.626 0.725 0.546 0.581 0.688 0.636 0.590 0.682 0.718 0.658 0.566 0.633 0.664 0.690 0.565 Forgery. 0.824 0.755 0.818 0.817 0.817 0.811 0.799 0.726 0.790 0.786 0.781 0.808 0.727 0.761 0.762 0.752 0.782 0.758 0.815 0.745 0.781 0.746 0.669 0.749 0.781 0.752 0.760 0.669 0.582 0.736 0.567 0.583 0.724 0.726 0.668 0.732 0.638 0.627 0.721 0.579 0.708 0.588 0.555 0.698 0.704 0.557 0.631 0.688 0.671 0.651 0.488 0.533 0.542 0.598 0.591 0.685 0.542 0.563 0.696 0.615 0. DFF 0.909 0.881 0.907 0.920 0.865 0.863 0.913 0.840 0.903 0.876 0.906 0.843 0.877 0.863 0.864 0.803 0.828 0.895 0.830 0.843 0.852 0.872 0.878 0.881 0.899 0.891 0.899 0.853 0.762 0.888 0.776 0.808 0.763 0.850 0.869 0.760 0.822 0.818 0.813 0.852 0.756 0.783 0.599 0.848 0.664 0.890 0.747 0.781 0.747 0.877 0.595 0.758 0.788 0.854 0.643 0.673 0.744 0.750 0.802 0.651 0.862 DF40 0.980 0.927 0.985 0.981 0.977 0.980 0.977 0.816 0.972 0.919 0.937 0.946 0.890 0.944 0.976 0.936 0.972 0.967 0.980 0.861 0.942 0.926 0.830 0.972 0.977 0.942 0.957 0.830 0.670 0.954 0.758 0.751 0.868 0.890 0.782 0.832 0.796 0.742 0.936 0.744 0.858 0.695 0.692 0.894 0.946 0.735 0.684 0.825 0.918 0.730 0.723 0.662 0.700 0.785 0.857 0.853 0.652 0.659 0.814 0.764 0.898 ScaleDF 0.968 0.966 0.968 0.967 0.960 0.960 0.963 0.911 0.956 0.963 0.963 0.935 0.933 0.960 0.942 0.944 0.950 0.961 0.950 0.916 0.928 0.957 0.909 0.964 0.965 0.963 0.956 0.904 0.778 0.964 0.801 0.814 0.929 0.945 0.898 0.901 0.854 0.822 0.949 0.791 0.835 0.796 0.692 0.875 0.926 0.798 0.806 0.885 0.837 0.827 0.726 0.739 0.765 0.832 0.770 0.689 0.624 0.645 0.834 0.822 0.890 Mean 0.886 0.835 0.872 0.871 0.871 0.859 0.868 0.808 0.874 0.846 0.866 0.850 0.824 0.846 0.843 0.823 0.852 0.864 0.858 0.814 0.829 0.821 0.774 0.837 0.856 0.837 0.854 0.797 0.676 0.838 0.686 0.708 0.797 0.820 0.770 0.774 0.754 0.721 0.814 0.726 0.768 0.680 0.631 0.771 0.766 0.697 0.693 0.758 0.742 0.736 0.603 0.622 0.645 0.728 0.691 0.717 0.593 0.634 0.760 0.701 0.765 32 Scaling Laws for Deepfake Detection Table 13 Full experimental results measured by AUC for scaling law with varying numbers of deepfake methods. The concluded scaling law is shown in Fig. 3 (Right). Wild 0.815 0.776 0.802 0.802 0.796 0.806 0.809 0.823 0.800 0.828 0.819 0.794 0.804 0.748 0.754 0.791 0.800 0.775 0.768 0.809 0.816 0.758 0.799 0.754 0.752 0.740 0.741 0.773 0.819 0.782 0.708 0.733 0.729 0.772 0.744 0.746 0.651 0.710 0.717 0.779 0.771 0.708 0.698 0.755 0.707 0.686 0.766 0.718 0.684 0.684 0.644 0.718 0.689 0.763 0.751 0.723 0.606 0.743 0.594 0.603 0.743 ScaleDF 0.968 0.965 0.955 0.963 0.963 0.965 0.967 0.959 0.960 0.960 0.964 0.954 0.954 0.966 0.946 0.953 0.959 0.958 0.937 0.956 0.955 0.949 0.942 0.947 0.950 0.949 0.931 0.915 0.934 0.952 0.944 0.935 0.924 0.909 0.923 0.909 0.932 0.926 0.929 0.933 0.899 0.923 0.942 0.874 0.893 0.937 0.916 0.912 0.916 0.903 0.893 0.906 0.890 0.880 0.887 0.901 0.865 0.861 0.862 0.898 0.856 Forgery. 0.824 0.815 0.820 0.836 0.823 0.802 0.803 0.795 0.804 0.808 0.819 0.798 0.792 0.802 0.791 0.810 0.774 0.792 0.778 0.811 0.817 0.790 0.751 0.765 0.743 0.762 0.764 0.765 0.768 0.772 0.767 0.791 0.732 0.736 0.726 0.803 0.758 0.744 0.727 0.766 0.763 0.749 0.693 0.804 0.697 0.716 0.778 0.739 0.660 0.699 0.703 0.678 0.720 0.754 0.774 0.756 0.752 0.768 0.714 0.708 0.746 CDF V2 0.915 0.914 0.912 0.917 0.915 0.908 0.853 0.873 0.899 0.894 0.909 0.886 0.906 0.909 0.915 0.904 0.824 0.854 0.897 0.908 0.912 0.794 0.869 0.877 0.839 0.836 0.892 0.845 0.804 0.842 0.910 0.891 0.829 0.836 0.774 0.842 0.813 0.826 0.743 0.801 0.813 0.822 0.728 0.899 0.656 0.674 0.810 0.827 0.674 0.804 0.829 0.662 0.775 0.748 0.814 0.848 0.826 0.756 0.771 0.745 0.806 DFF 0.909 0.874 0.893 0.888 0.888 0.894 0.858 0.818 0.899 0.909 0.891 0.761 0.781 0.772 0.893 0.796 0.882 0.842 0.768 0.829 0.816 0.855 0.856 0.718 0.853 0.870 0.794 0.774 0.722 0.818 0.759 0.663 0.854 0.725 0.857 0.880 0.654 0.858 0.700 0.726 0.618 0.677 0.854 0.724 0.643 0.720 0.634 0.659 0.858 0.722 0.609 0.862 0.656 0.593 0.744 0.519 0.510 0.607 0.537 0.649 0.795 Mean 0.886 0.871 0.874 0.882 0.878 0.874 0.860 0.857 0.874 0.877 0.881 0.849 0.853 0.845 0.861 0.857 0.841 0.839 0.831 0.864 0.869 0.834 0.850 0.814 0.822 0.830 0.830 0.822 0.818 0.840 0.829 0.806 0.813 0.810 0.799 0.840 0.775 0.813 0.765 0.816 0.788 0.780 0.783 0.815 0.731 0.755 0.794 0.783 0.757 0.767 0.752 0.763 0.745 0.770 0.806 0.778 0.736 0.754 0.723 0.728 0. DF40 0.980 0.982 0.978 0.981 0.977 0.978 0.973 0.977 0.977 0.977 0.975 0.975 0.970 0.974 0.967 0.979 0.963 0.976 0.968 0.970 0.969 0.973 0.969 0.959 0.947 0.970 0.952 0.951 0.968 0.969 0.968 0.965 0.959 0.957 0.945 0.966 0.971 0.958 0.957 0.960 0.943 0.956 0.957 0.870 0.956 0.963 0.955 0.968 0.954 0.943 0.907 0.956 0.880 0.942 0.965 0.956 0.910 0.858 0.919 0.905 0.906 DFD 0.793 0.774 0.756 0.790 0.782 0.766 0.755 0.756 0.779 0.766 0.788 0.777 0.766 0.746 0.760 0.763 0.684 0.673 0.701 0.764 0.796 0.720 0.767 0.679 0.669 0.685 0.740 0.734 0.713 0.742 0.748 0.667 0.662 0.736 0.625 0.736 0.648 0.669 0.583 0.744 0.708 0.626 0.609 0.779 0.566 0.590 0.701 0.660 0.556 0.617 0.677 0.555 0.604 0.710 0.706 0.740 0.687 0.686 0.662 0.592 0.742 AUC 88 64 64 64 64 64 64 64 64 64 64 45 45 45 45 45 45 45 45 45 45 32 32 32 32 32 32 32 32 32 32 22 22 22 22 22 22 22 22 22 22 16 16 16 16 16 16 16 16 16 16 11 11 11 11 11 11 11 11 11 11 33 Scaling Laws for Deepfake Detection Table 14 Full experimental results measured by AUC for scaling law with varying numbers of training images. The concluded scaling law is shown in Fig. 4 (Left). AUC 1.4 107 3.7 106 3.7 106 3.7 106 3.7 106 3.7 106 1.4 106 1.4 106 1.4 106 1.4 106 1.4 106 9.3 105 9.3 105 9.3 105 9.3 105 9.3 105 2.3 105 2.3 105 2.3 105 2.3 105 2.3 105 1.4 105 1.4 105 1.4 105 1.4 105 1.4 105 5.8 104 5.8 104 5.8 104 5.8 104 5.8 104 1.4 104 1.4 104 1.4 104 1.4 104 1.4 104 DFD 0.793 0.788 0.778 0.781 0.777 0.785 0.754 0.763 0.761 0.760 0.760 0.725 0.734 0.735 0.726 0.737 0.624 0.628 0.630 0.628 0.614 0.608 0.602 0.605 0.604 0.604 0.551 0.550 0.558 0.553 0.552 0.509 0.507 0.506 0.506 0.508 CDF V2 0.915 0.904 0.903 0.905 0.899 0. 0.873 0.876 0.880 0.878 0.867 0.850 0.845 0.850 0.849 0.854 0.668 0.676 0.673 0.679 0.669 0.654 0.648 0.644 0.655 0.645 0.536 0.545 0.542 0.548 0.542 0.509 0.491 0.492 0.501 0.489 Wild 0.815 0.831 0.827 0.820 0.823 0.820 0.828 0.828 0.824 0.823 0.823 0.805 0.803 0.804 0.801 0.803 0.718 0.716 0.724 0.721 0.727 0.699 0.680 0.698 0.696 0.679 0.570 0.573 0.565 0.579 0.561 0.530 0.539 0.536 0.527 0.535 Forgery. 0.824 0.792 0.790 0.791 0.790 0. 0.756 0.758 0.757 0.756 0.756 0.724 0.727 0.723 0.722 0.726 0.614 0.616 0.617 0.616 0.615 0.596 0.597 0.596 0.599 0.598 0.554 0.555 0.556 0.555 0.550 0.511 0.511 0.513 0.511 0.511 DFF 0.909 0.842 0.840 0.840 0.843 0.838 0.804 0.801 0.805 0.812 0.811 0.776 0.780 0.781 0.776 0.778 0.708 0.714 0.713 0.710 0.713 0.706 0.696 0.699 0.706 0.697 0.652 0.657 0.656 0.651 0.644 0.580 0.581 0.581 0.583 0.586 DF40 0.980 0.964 0.966 0.962 0.967 0. 0.952 0.949 0.948 0.948 0.950 0.941 0.943 0.939 0.936 0.941 0.830 0.843 0.826 0.831 0.830 0.744 0.735 0.732 0.731 0.734 0.464 0.470 0.474 0.464 0.450 0.344 0.335 0.353 0.350 0.339 ScaleDF 0.968 0.949 0.948 0.946 0.950 0.946 0.943 0.941 0.942 0.940 0.939 0.933 0.933 0.932 0.928 0.932 0.848 0.855 0.850 0.851 0.853 0.786 0.782 0.784 0.782 0.787 0.656 0.661 0.659 0.658 0.654 0.548 0.550 0.555 0.555 0.551 Table 15 Full experimental results measured by AUC for varying model sizes. The average performance is shown in Fig. 4 (Right). AUC 21.7M 38.3M 85.8M 303.4M 630.8M DFD 0.785 0.764 0.793 0.803 0.795 CDF V2 0.905 0.905 0.915 0.925 0.911 Wild 0.807 0.812 0.815 0.808 0.797 Forgery. 0.774 0.795 0.824 0.859 0.867 DFF 0.807 0.843 0.909 0.940 0.959 DF40 0.970 0.974 0.980 0.985 0. ScaleDF 0.948 0.953 0.968 0.976 0.982 Mean 0.886 0.867 0.864 0.864 0.864 0.864 0.844 0.845 0.845 0.845 0.844 0.822 0.824 0.824 0.820 0.824 0.716 0.721 0.719 0.719 0.717 0.685 0.677 0.680 0.682 0.678 0.569 0.573 0.573 0.573 0.565 0.504 0.502 0.505 0.505 0.503 Mean 0.856 0.864 0.886 0.900 0.899 Scaling Laws for Deepfake Detection Table 16 Full experimental results measured by EER for scaling law with varying numbers of real domains. The concluded scaling law is shown in Fig. 5 (Left Top). EER 46 32 32 32 32 32 32 32 32 32 32 23 23 23 23 23 23 23 23 23 23 16 16 16 16 16 16 16 16 16 16 11 11 11 11 11 11 11 11 11 11 8 8 8 8 8 8 8 8 8 8 5 5 5 5 5 5 5 5 5 5 DFD 0.281 0.317 0.308 0.293 0.307 0.308 0.291 0.344 0.295 0.330 0.309 0.316 0.331 0.312 0.320 0.351 0.304 0.285 0.327 0.343 0.319 0.335 0.342 0.320 0.311 0.333 0.299 0.342 0.415 0.337 0.404 0.387 0.358 0.331 0.337 0.347 0.337 0.396 0.351 0.374 0.339 0.383 0.469 0.348 0.378 0.376 0.379 0.372 0.370 0.358 0.484 0.438 0.426 0.383 0.435 0.359 0.471 0.408 0.356 0.368 0.339 CDF V2 0.162 0.224 0.162 0.173 0.179 0.173 0.165 0.221 0.170 0.240 0.183 0.192 0.250 0.196 0.174 0.225 0.190 0.189 0.196 0.273 0.199 0.226 0.308 0.200 0.188 0.205 0.198 0.238 0.457 0.201 0.436 0.374 0.229 0.218 0.293 0.294 0.257 0.295 0.250 0.344 0.312 0.421 0.337 0.314 0.278 0.428 0.369 0.336 0.276 0.270 0.514 0.542 0.486 0.374 0.384 0.300 0.516 0.466 0.260 0.369 0.309 Wild 0.268 0.337 0.313 0.326 0.257 0.334 0.336 0.262 0.246 0.268 0.261 0.285 0.288 0.314 0.335 0.310 0.281 0.268 0.272 0.256 0.374 0.355 0.373 0.393 0.335 0.334 0.293 0.295 0.287 0.335 0.388 0.387 0.310 0.308 0.369 0.318 0.402 0.421 0.316 0.323 0.315 0.421 0.410 0.402 0.402 0.406 0.385 0.324 0.464 0.422 0.354 0.397 0.431 0.363 0.337 0.390 0.448 0.389 0.380 0.361 0. Forgery. 0.260 0.310 0.264 0.265 0.269 0.270 0.275 0.336 0.287 0.297 0.287 0.276 0.334 0.306 0.302 0.316 0.294 0.312 0.271 0.327 0.295 0.319 0.378 0.311 0.292 0.314 0.309 0.376 0.444 0.326 0.460 0.447 0.335 0.333 0.377 0.335 0.397 0.412 0.337 0.445 0.354 0.442 0.464 0.353 0.351 0.465 0.406 0.367 0.376 0.393 0.512 0.481 0.476 0.435 0.439 0.371 0.481 0.462 0.356 0.422 0.371 DFF 0.161 0.189 0.162 0.148 0.209 0.210 0.158 0.229 0.166 0.197 0.168 0.227 0.197 0.214 0.209 0.267 0.246 0.176 0.243 0.227 0.228 0.202 0.189 0.190 0.172 0.179 0.172 0.223 0.295 0.182 0.286 0.256 0.300 0.222 0.201 0.299 0.252 0.255 0.255 0.218 0.311 0.292 0.422 0.222 0.384 0.177 0.308 0.282 0.312 0.195 0.427 0.294 0.267 0.220 0.390 0.366 0.326 0.310 0.265 0.396 0.206 DF40 0.063 0.149 0.055 0.063 0.070 0.064 0.069 0.250 0.078 0.158 0.134 0.127 0.194 0.125 0.069 0.136 0.075 0.081 0.065 0.215 0.131 0.156 0.235 0.083 0.064 0.129 0.097 0.250 0.358 0.110 0.293 0.297 0.198 0.191 0.284 0.241 0.280 0.324 0.143 0.313 0.224 0.364 0.359 0.185 0.122 0.317 0.354 0.247 0.155 0.326 0.333 0.373 0.344 0.275 0.217 0.227 0.382 0.385 0.253 0.299 0.176 ScaleDF 0.093 0.092 0.092 0.093 0.105 0.104 0.098 0.152 0.107 0.102 0.102 0.135 0.146 0.105 0.127 0.130 0.123 0.096 0.127 0.170 0.153 0.109 0.165 0.091 0.089 0.093 0.093 0.169 0.312 0.092 0.302 0.282 0.140 0.119 0.158 0.170 0.208 0.254 0.118 0.286 0.237 0.251 0.360 0.180 0.150 0.294 0.268 0.194 0.214 0.222 0.342 0.324 0.311 0.260 0.302 0.369 0.413 0.388 0.242 0.264 0.159 Mean 0.184 0.231 0.194 0.194 0.199 0.209 0.199 0.256 0.193 0.228 0.206 0.223 0.249 0.225 0.220 0.248 0.216 0.201 0.215 0.259 0.243 0.243 0.284 0.227 0.208 0.227 0.209 0.270 0.367 0.226 0.367 0.347 0.267 0.246 0.288 0.286 0.305 0.337 0.253 0.329 0.299 0.367 0.403 0.286 0.295 0.352 0.353 0.303 0.310 0.312 0.424 0.407 0.392 0.330 0.358 0.340 0.434 0.401 0.302 0.354 0.288 Scaling Laws for Deepfake Detection Table 17 Full experimental results measured by EER for scaling law with varying numbers of deepfake methods. The concluded scaling law is shown in Fig. 5 (Right Top). Wild 0.268 0.301 0.279 0.277 0.272 0.278 0.266 0.255 0.274 0.251 0.257 0.276 0.270 0.309 0.309 0.285 0.275 0.292 0.301 0.261 0.265 0.311 0.274 0.309 0.307 0.315 0.317 0.294 0.256 0.293 0.344 0.330 0.325 0.298 0.311 0.317 0.375 0.344 0.333 0.288 0.299 0.345 0.347 0.309 0.352 0.357 0.294 0.331 0.354 0.366 0.390 0.334 0.366 0.302 0.310 0.335 0.420 0.323 0.435 0.434 0.332 ScaleDF 0.093 0.096 0.112 0.099 0.100 0.096 0.094 0.106 0.107 0.106 0.097 0.113 0.118 0.092 0.121 0.114 0.107 0.109 0.139 0.110 0.114 0.122 0.129 0.122 0.123 0.122 0.145 0.164 0.146 0.123 0.130 0.130 0.148 0.168 0.148 0.167 0.135 0.155 0.141 0.147 0.174 0.149 0.132 0.202 0.172 0.126 0.158 0.166 0.163 0.168 0.199 0.177 0.198 0.196 0.182 0.172 0.215 0.210 0.210 0.169 0.217 Forgery. 0.260 0.268 0.264 0.249 0.261 0.278 0.278 0.286 0.278 0.273 0.264 0.282 0.286 0.277 0.287 0.270 0.301 0.286 0.298 0.272 0.268 0.289 0.323 0.309 0.326 0.313 0.310 0.309 0.306 0.303 0.308 0.282 0.335 0.332 0.338 0.278 0.313 0.328 0.336 0.310 0.310 0.315 0.364 0.277 0.355 0.345 0.298 0.326 0.388 0.354 0.358 0.374 0.346 0.315 0.301 0.313 0.317 0.304 0.342 0.346 0.323 CDF V2 0.162 0.165 0.167 0.162 0.162 0.172 0.222 0.208 0.180 0.183 0.169 0.197 0.171 0.171 0.159 0.177 0.251 0.228 0.185 0.172 0.164 0.279 0.216 0.205 0.240 0.241 0.188 0.233 0.272 0.241 0.168 0.194 0.251 0.244 0.300 0.237 0.265 0.252 0.323 0.276 0.262 0.254 0.331 0.181 0.385 0.373 0.268 0.250 0.374 0.273 0.246 0.386 0.295 0.319 0.266 0.234 0.252 0.310 0.297 0.323 0.271 DFF 0.161 0.200 0.175 0.186 0.183 0.178 0.216 0.253 0.173 0.162 0.182 0.304 0.291 0.289 0.180 0.269 0.194 0.230 0.293 0.243 0.262 0.220 0.221 0.340 0.222 0.210 0.282 0.297 0.337 0.260 0.308 0.382 0.222 0.332 0.218 0.192 0.395 0.216 0.354 0.334 0.420 0.372 0.226 0.331 0.405 0.338 0.420 0.389 0.218 0.341 0.421 0.216 0.385 0.440 0.325 0.493 0.501 0.439 0.481 0.402 0. Mean 0.184 0.199 0.196 0.189 0.191 0.196 0.209 0.213 0.197 0.193 0.190 0.221 0.217 0.219 0.207 0.213 0.228 0.228 0.238 0.207 0.205 0.235 0.223 0.250 0.245 0.237 0.240 0.248 0.251 0.232 0.238 0.257 0.253 0.257 0.265 0.230 0.280 0.255 0.291 0.255 0.275 0.278 0.277 0.255 0.318 0.296 0.272 0.277 0.297 0.291 0.307 0.295 0.318 0.293 0.261 0.283 0.318 0.305 0.328 0.325 0.273 DF40 0.063 0.061 0.066 0.064 0.067 0.068 0.077 0.071 0.070 0.070 0.073 0.073 0.080 0.077 0.088 0.067 0.095 0.075 0.086 0.085 0.082 0.081 0.085 0.096 0.117 0.085 0.114 0.112 0.092 0.085 0.089 0.090 0.101 0.100 0.125 0.088 0.081 0.102 0.104 0.105 0.120 0.106 0.109 0.190 0.101 0.092 0.109 0.080 0.115 0.122 0.157 0.111 0.210 0.124 0.091 0.106 0.158 0.191 0.151 0.165 0.160 DFD 0.281 0.299 0.312 0.283 0.293 0.304 0.310 0.314 0.294 0.303 0.287 0.298 0.306 0.318 0.307 0.307 0.372 0.376 0.363 0.307 0.280 0.340 0.312 0.372 0.379 0.370 0.326 0.329 0.345 0.321 0.317 0.390 0.388 0.326 0.413 0.329 0.397 0.386 0.443 0.325 0.344 0.407 0.428 0.294 0.454 0.437 0.355 0.396 0.466 0.416 0.374 0.465 0.426 0.352 0.353 0.328 0.367 0.363 0.382 0.436 0.321 EER 88 64 64 64 64 64 64 64 64 64 64 45 45 45 45 45 45 45 45 45 45 32 32 32 32 32 32 32 32 32 32 22 22 22 22 22 22 22 22 22 22 16 16 16 16 16 16 16 16 16 16 11 11 11 11 11 11 11 11 11 11 36 Scaling Laws for Deepfake Detection Table 18 Full experimental results measured by EER for scaling law with varying numbers of training images. The concluded scaling law is shown in Fig. 5 (Left Bottom). EER 1.4 107 3.7 106 3.7 106 3.7 106 3.7 106 3.7 106 1.4 106 1.4 106 1.4 106 1.4 106 1.4 106 9.3 105 9.3 105 9.3 105 9.3 105 9.3 105 2.3 105 2.3 105 2.3 105 2.3 105 2.3 105 1.4 105 1.4 105 1.4 105 1.4 105 1.4 105 5.8 104 5.8 104 5.8 104 5.8 104 5.8 104 1.4 104 1.4 104 1.4 104 1.4 104 1.4 104 DFD 0.281 0.287 0.294 0.291 0.297 0.289 0.317 0.308 0.310 0.311 0.313 0.340 0.332 0.331 0.339 0.331 0.410 0.408 0.407 0.409 0.419 0.427 0.430 0.429 0.431 0.429 0.470 0.469 0.467 0.468 0.468 0.497 0.498 0.497 0.498 0.497 CDF V2 0. 0.176 0.179 0.176 0.183 0.177 0.211 0.208 0.205 0.205 0.216 0.232 0.238 0.233 0.234 0.228 0.383 0.377 0.378 0.374 0.379 0.390 0.393 0.398 0.390 0.397 0.478 0.470 0.475 0.469 0.473 0.494 0.507 0.506 0.500 0.508 Wild 0.268 0.249 0.253 0.259 0.256 0.259 0.257 0.258 0.259 0.263 0.262 0.278 0.281 0.279 0.282 0.280 0.347 0.347 0.338 0.342 0.338 0.360 0.373 0.362 0.364 0.374 0.446 0.447 0.450 0.442 0.453 0.486 0.479 0.481 0.488 0.482 Forgery. 0. 0.289 0.292 0.289 0.291 0.289 0.318 0.316 0.318 0.318 0.318 0.341 0.339 0.342 0.342 0.340 0.420 0.418 0.417 0.417 0.418 0.431 0.431 0.432 0.429 0.431 0.459 0.458 0.459 0.458 0.462 0.494 0.492 0.491 0.492 0.493 DFF 0.161 0.234 0.236 0.236 0.232 0.236 0.274 0.277 0.273 0.266 0.269 0.300 0.298 0.296 0.300 0.298 0.353 0.349 0.348 0.350 0.349 0.353 0.359 0.358 0.353 0.358 0.390 0.386 0.387 0.390 0.396 0.443 0.441 0.442 0.439 0.437 DF40 0. 0.097 0.096 0.099 0.094 0.099 0.114 0.118 0.118 0.120 0.117 0.128 0.128 0.132 0.135 0.129 0.247 0.234 0.249 0.246 0.246 0.319 0.326 0.329 0.329 0.327 0.525 0.520 0.518 0.525 0.533 0.620 0.624 0.611 0.615 0.624 ScaleDF 0.093 0.126 0.128 0.129 0.125 0.130 0.129 0.132 0.132 0.135 0.136 0.140 0.140 0.141 0.146 0.142 0.240 0.234 0.238 0.236 0.234 0.300 0.302 0.301 0.301 0.299 0.405 0.400 0.400 0.401 0.406 0.473 0.473 0.470 0.469 0.473 Table 19 Full experimental results measured by EER for varying model sizes. The average performance is shown in Fig. 5 (Right Bottom). EER 21.7M 38.3M 85.8M 303.4M 630.8M DFD 0.293 0.309 0.281 0.271 0.270 CDF V2 0.172 0.175 0.162 0.149 0.162 Wild 0.270 0.269 0.268 0.260 0.277 Forgery. 0.304 0.285 0.260 0.225 0.212 DFF 0.264 0.228 0.161 0.114 0. DF40 0.085 0.077 0.063 0.048 0.050 ScaleDF 0.130 0.120 0.093 0.072 0.047 Mean 0.184 0.208 0.211 0.211 0.211 0.211 0.231 0.231 0.231 0.231 0.233 0.251 0.251 0.250 0.254 0.250 0.343 0.338 0.339 0.339 0.340 0.369 0.373 0.373 0.371 0.374 0.453 0.450 0.451 0.450 0.456 0.501 0.502 0.500 0.500 0.502 Mean 0.217 0.209 0.184 0.163 0. 37 Scaling Laws for Deepfake Detection Table 20 Visualization of processed faces in ScaleDF. Name Demo 0 Demo Demo 2 Demo 3 Demo 4 G 2 - O W I - u 4 - E c b o F e i C c e S - 38 Scaling Laws for Deepfake Detection Table 21 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo Demo 4 - E u e W 0 0 3 l D W E R I t ff e A 39 Scaling Laws for Deepfake Detection Table 22 Visualization of processed faces in ScaleDF. Name Demo Demo 1 Demo 2 Demo 3 Demo 4 - s F U a U - A a A c S p e - I D 40 Scaling Laws for Deepfake Detection Table 23 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo a f 2 F K 0 0 5 - e - 2 e V 2 - ff F + + s o a e B - B D 41 Scaling Laws for Deepfake Detection Table 24 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo 4 M M 3 A a a 0 6 3 l s F k S a - W e - s - l F Scaling Laws for Deepfake Detection Table 25 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo Demo 3 Demo 4 1 - c a c a c s F D S w S F fi a f e i a c l M 43 Scaling Laws for Deepfake Detection Table 26 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo 4 4 T G F l c e p D 3 p n t A F S a n u a 44 Scaling Laws for Deepfake Detection Table 27 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo t s c ff c 2 F F r e r t e i 2 - F P N D 45 Scaling Laws for Deepfake Detection Table 28 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo 4 t A a y F c e p e d T j r w o t t e r a A 3 46 Scaling Laws for Deepfake Detection Table 29 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo S 1 - e S 2 e S Q 3 e S - e S . 1 2 5 . 1 X a A - x 47 Scaling Laws for Deepfake Detection Table 30 Visualization of processed faces in ScaleDF. Name Demo Demo 1 Demo 2 Demo 3 Demo 4 r M j 5 . 3 ] [ 1 . F 4 V 3 V C o i - y i V - i d u H P 48 Scaling Laws for Deepfake Detection Table 31 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo 4 1 - m - o - a e i 2 - w d y i d C E 4 I I o ff i 49 Scaling Laws for Deepfake Detection Table 32 Visualization of processed faces in ScaleDF. Name Demo Demo 1 Demo 2 Demo 3 Demo 4 c i 2 t t I t A - A a a l e S e p D c S e c M 50 Scaling Laws for Deepfake Detection Table 33 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo a R E F s n t - 1 S T k i 2 W e 2 u k d n a - V a e Scaling Laws for Deepfake Detection Table 34 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo Demo 3 Demo 4 _ i r 3 R L A J A k n i r n a p 2 ff i a J 52 Scaling Laws for Deepfake Detection Table 35 Visualization of processed faces in ScaleDF. Name Demo 0 Demo 1 Demo 2 Demo 3 Demo 4 i e T c o 53 Table 36 Demonstration of the perturbations used when training models on the ScaleDF dataset. Pert. Elaboration Demo 0 Demo 1 Demo 2 Demo Scaling Laws for Deepfake Detection C s e J o B a i e o a a g a i d l e p i Randomly crop and resize an image to specified size. Randomly change brightness, the contrast, saturation, and hue of an image. Randomly apply blur filter to an image. Pixelate portions image. random an of Randomly rotate an image within given range of degrees. Convert an image into grayscale. Pad an image with colors, random height and width. Add random noise to an image. Flip an image vertically. Flip an image horizontally. 54 Table 37 Demonstration of the perturbations used when training models on the ScaleDF dataset. Pert. Elaboration Demo 0 Demo Demo 2 Demo 3 Scaling Laws for Deepfake Detection a s n e h i Q E p S S x u z a c ff a r i O i o Randomly transform the perspective of an image. shift, Randomly swap, invert or the channel of an image. Randomly encode (reduce) the quality of an image. Randomly enhance the edge contrast an image. of Randomly skew an image by certain angle. Randomly rearrange (shuffle) the pixels within an image. Simulate the effect of an X-ray on an image. Add glass effect onto an image with random extent. View an image through medium that randomly distorts the light. Invert all pixel values above random threshold. 55 Table 38 Demonstration of the perturbations used when training models on the ScaleDF dataset. Pert. Elaboration Demo 0 Demo Demo 2 Demo 3 Scaling Laws for Deepfake Detection m c a E y F t d e N e t e e P m e p a Randomly simulate the effect of zooming in or out. Simulate jellylike distortion of an image. Random use PCA to alter the intensities of the RGB channels. Apply random nonlinear distortions within grid to an image. random Apply camera sensor noise to an image. random value, is multiplied with the pixel values of an image. Randomly reduce the number of bits of each pixel. Alter lumithe nance values of an image by applying power-law function. Randomly create spatter effect on an image. Use different methods to binarize an image."
        }
    ],
    "affiliations": [
        "Google DeepMind",
        "University of Technology Sydney"
    ]
}