{
    "paper_title": "Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media",
    "authors": [
        "Ross Deans Kristensen-McLachlan",
        "Rebecca M. M. Hicke",
        "Márton Kardos",
        "Mette Thunø"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Does the People's Republic of China (PRC) interfere with European elections through ethnic Chinese diaspora media? This question forms the basis of an ongoing research project exploring how PRC narratives about European elections are represented in Chinese diaspora media, and thus the objectives of PRC news media manipulation. In order to study diaspora media efficiently and at scale, it is necessary to use techniques derived from quantitative text analysis, such as topic modelling. In this paper, we present a pipeline for studying information dynamics in Chinese media. Firstly, we present KeyNMF, a new approach to static and dynamic topic modelling using transformer-based contextual embedding models. We provide benchmark evaluations to demonstrate that our approach is competitive on a number of Chinese datasets and metrics. Secondly, we integrate KeyNMF with existing methods for describing information dynamics in complex systems. We apply this pipeline to data from five news sites, focusing on the period of time leading up to the 2024 European parliamentary elections. Our methods and results demonstrate the effectiveness of KeyNMF for studying information dynamics in Chinese media and lay groundwork for further work addressing the broader research questions."
        },
        {
            "title": "Start",
            "content": "Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media Ross Deans Kristensen-McLachlan1,2,*, Rebecca M. M. Hicke1,3, Márton Kardos1 and Mette Thunø4 1Center for Humanities Computing, Aarhus University, Denmark 2Department of Linguistics, Cognitive Science, and Semiotics, Aarhus University, Denmark 3Department of Computer Science, Cornell University, USA 4Department of Global Studies, Aarhus University, Denmark Abstract Does the Peoples Republic of China (PRC) interfere with European elections through ethnic Chinese diaspora media? This question forms the basis of an ongoing research project exploring how PRC narratives about European elections are represented in Chinese diaspora media, and thus the objectives of PRC news media manipulation. In order to study diaspora media efficiently and at scale, it is necessary to use techniques derived from quantitative text analysis, such as topic modelling. In this paper, we present pipeline for studying information dynamics in Chinese media. Firstly, we present KeyNMF, new approach to static and dynamic topic modelling using transformer-based contextual embedding models. We provide benchmark evaluations to demonstrate that our approach is competitive on number of Chinese datasets and metrics. Secondly, we integrate KeyNMF with existing methods for describing information dynamics in complex systems. We apply this pipeline to data from five news sites, focusing on the period of time leading up to the 2024 European parliamentary elections. Our methods and results demonstrate the effectiveness of KeyNMF for studying information dynamics in Chinese media and lay groundwork for further work addressing the broader research questions. Keywords keywords, novelty, contextual topic models, Chinese, information dynamics 1. Introduction number of major elections took place in the West over the course of 2024. Across Europe, citizens took to the polls in early June to elect members to the European Parliament. In France, the election of new Assemblée nationale caused political turmoil, while the United Kingdom voted in Labour government for the first time in 14 years. On the other side of the Atlantic Ocean, the United States of America will vote to determine their new President in November. The fallout of these elections remains to be seen but it seems clear that this year is one of political change and upheaval. CHR 2024: Computational Humanities Research Conference, December 46, 2024, Aarhus, Denmark *Corresponding author. $ rdkm@cc.au.dk (R. D. Kristensen-McLachlan); rmh327@cornell.edu (R. M. M. Hicke); martonkardos@cas.au.dk (M. Kardos); mettethunoe@cas.au.dk (M. Thunø) (cid:128) https://rmatouschekh.github.io (R. M. M. Hicke) (cid:26) 0000-0001-8714-1911 (R. D. Kristensen-McLachlan); 0009-0006-2074-8376 (R. M. M. Hicke); 0000-0001-9652-4498 (M. Kardos); 0000-0001-9410-2363 (M. Thunø) 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). 4 2 0 2 6 1 ] . [ 1 1 9 7 2 1 . 0 1 4 2 : r Much digital ink is spilled on these topics in Western media as the various electorates determine their preferences before elections and digest the fallout afterwards. Moreover, significant part of this media coverage is fundamentally persuasive, aiming to convince voters to bet on the candidate who most closely aligns with the social and economic ideology of the media outlets and their owners [1]. Likewise, coverage of these elections is not limited to European media institutions, with media outlets around the world updating their readership on how these elections impact them. In this context, one particular type of media stands out as especially interesting: ethnic Chinese media targeting diaspora communities in Europe, group which by some estimates comprises around 1.5-3 million individuals. These media outlets are potentially invaluable sources for understanding how the Chinese government and the Chinese Communist Party (CCP) attempt to influence the diaspora. Furthermore, studying these outlets potentially provides unique insights into how China views itself in relation to the West by showing how the PRC presents itself to its diaspora groups. growing body of literature has already begun to address these questions in the context of social media [2, 3] or in terms of digital infrastructure more generally [4, 5]. In ongoing research, our aim is to assess whether Chinese diaspora news sources intend to impact opinions on elections in the West during 2024. We attempt to understand the control of information flow in Chinese diaspora media and how this control is used to set specific agendas during electoral periods: promoting certain political parties or individual candidates, polarizing citizens, and attacking or promoting specific political positions. To pursue this research, we design pipeline for analyzing large amounts of Chinese-language news data. First, we introduce KeyNMF, novel approach to creating context-sensitive topics models via transformer-based encoder models. KeyNMF can be trivially applied across different languages and in data scarce environments, and is shown here to create coherent, humaninterpretable outputs when working with Chinese language data. We then integrate KeyNMF with existing techniques for describing the information dynamics of complex systems which measure the novelty and resonance of information present in system over time. We use this pipeline to perform preliminary analysis on our dataset of Chinese diaspora media, finding clear trends in the novelty and resonance signals which correlate with significant political events. The results presented are thus intended to be both proof of concept and stepping stone towards more meaningful understanding of the dynamics underlying Chinese diaspora media. 2. Related Work 2.1. Information Dynamics The study of information dynamics in complex cultural systems has been central aspect of research in computational humanities and cultural analytics in recent years. One of the most promising approaches to this problem was introduced in [6] which studied the shifting debates which took place during the French Revolution. In this approach, divergence in content between different time slices can be calculated using information-theoretic measures. These measures can then be used to quantify two interrelated values: the novelty of the system, or how much the new time slice diverges from preceding time slices; and the resonance of this information, which describes how information persists over time. Novelty-resonance patterns have been studied in number of different discourse domains. [7] demonstrate their usefulness in identifying so-called trend reservoirs on Reddit. Similar interaction patterns between novelty and resonance have been successfully employed to study the manner in which online news media responded to catastrophic events [8, 9, 10]. In [11], the same fundamental method of analysis demonstrates that novelty-resonance patterns clearly track major social and historical events in the 20th century, using data taken from the front page of Dutch newspapers. Calculating these underlying dynamics requires the creation of some kind of numerical representation of the data. Specifically, the difference between individual windows is computed by finding the windowed relative entropy, in this case calculated using Jensen-Shannon Divergence (JSD). Since JSD computes the distance between probability distributions, the numerical representations of the data are required to take that form. In [12], this was achieved by calculating the probabilities of pre-trained, BERT-based emotion classification model, where the predicted probabilities for each label created distribution over emotions for each document. However, for most purposes, novelty and resonance are calculated based on distributions generated by probabilistic topic model. 2.2. Vanilla LDA Typically, novelty and resonance are calculated from topic probability distributions extracted by Latent Dirichlet Allocation (LDA) [13, 14]. Topic distributions in documents are natural choice for information dynamics, as they are immediately usable with entropy-based measures. LDA is generative bag-of-words model, which assumes that document contains mixture of topics and all words in the document are drawn from this mixture distribution. However, LDA has number of well-known shortcomings. Documents have to be heavily pre-processed for optimal results; otherwise, the topic descriptions produced by the model are often contaminated by noise and stop words [15]. In addition, since LDA makes the bag-ofwords assumption, it cannot utilize contextual and syntactic information, nor general properties of natural language learned from outside sources. Finally, LDA is sensitive to hyperparameter choices and Wallach et al. [16] demonstrate that using symmetric Dirichlet priors, which is the case in canonical implementations [17, 18] and the majority of academic studies, can lead to sub-optimal performance. There have also been challenges to the generalizability of LDA from the perspective of Chinese NLP, as the primary structural and semantic unit of Chinese is the character rather than the word [19, 20]. While these concerns might be overstated, working with Chinese language data causes specific challenges in terms of tokenization and semantics which directly impact the efficacy of traditional LDA approaches to topic modelling. 2.3. Alternatives to LDA major shortcoming of LDA when trying to model change over time is that topics are calculated over all documents, essentially flattening any temporal aspect of the data. This is undesirable, since topics themselves naturally evolve over time, meaning that LDA may not reflect the true dynamics of system. These issue is partly rectified by dynamic topic models [21] which account for temporal changes in topics with state-space model. However, Dynamic LDA models are even more parameter-rich than the vanilla implementation and thus amplify its limitations. Recently, contemporary topic models have shown that it is possible to utilize embeddings from the sentence transformers [22] to infuse contextual information into topic models and to allow for transfer learning [23, 24, 25, 26, 15]. This contextual information can lead to more coherent and semantically interpretable topics. In addition, since these models draw on existing pre-trained language models, they do not require training generative model from scratch. This means that it is possible to train topic models in data scarce contexts where traditional LDA might perform poorly. Among the most popular of these contemporary models is BERTopic [25], which also has dynamic modelling capabilities. In this model, topic-term importances are estimated post-hoc on pre-defined time slices based on one underlying topic model. However, as with LDA, BERTopic is sensitive to pre-processing [15]. Additionally, because BERTopic is clustering topic model, documents are only assigned single topic label. This renders the model impractical in settings where documents are expected to contain multiple topics and means that BERTopic is not suitable for calculating novelty and resonance, since the entropy calculations assume probability distributions over documents. 3. KeyNMF We propose KeyNMF, novel topic modelling approach that utilizes neural text embeddings. KeyNMF builds on the reliability, stability [27], scalability [28], and interpretability of Nonnegative Matrix Factorization (NMF) [29], while mitigating its sensitivity to pre-processing and making use of contextual information in texts. This is achieved by: 1) computing keyword importances from documents with contextual embeddings (similar to KeyBERT [30]); and 2) decomposing those importances with NMF. We release an implementation of KeyNMF as part of the Turftopic Python package.1 3.1. Model Description KeyNMF operationalizes topic extraction as the following steps: 1. For each document 𝑑: a) Let 𝑥𝑑 be the documents embedding produced with an encoder model. b) Let 𝑣𝑤 be the word embedding of word 𝑤 produced with the same encoder model. c) Let 𝐾𝑑 be the set of 𝑁 keywords in 𝑑 with the highest cosine similarity to 𝑑: 𝐾𝑑 = arg max 𝐾* 𝑤𝐾* sim(𝑥𝑑, 𝑣𝑤), where 𝐾𝑑 = 𝑁 and 𝑤 𝑑 1https://x-tabdeveloping.github.io/turftopic/ 2. Arrange the keyword similarities into non-negative keyword matrix 𝑀 . Let 𝑀𝑑𝑤 be the importance of keyword 𝑤 in document 𝑑: 𝑀𝑑𝑤 = {sim(𝑑, 𝑤), 0, if 𝑤 𝐾𝑑 and sim(𝑥𝑑, 𝑣𝑤) > 0 otherwise. 3. Decompose 𝑀 with non-negative matrix factorization: 𝑀 𝑊 𝐻, where 𝑊 is the document-topic matrix, and 𝐻 is the topic-term-matrix. This is achieved with coordinatedescent, minimizing the square loss 𝐿(𝑊, 𝐻) = 𝑋 𝑊 𝐻2. 3.2. Dynamic KeyNMF KeyNMF can be used for modelling topics evolution in corpus over time. This is done by first computing global model over the entire corpus, then calculating time-specific topic-term importances in predefined time slices. Specifically: 1. Compute the keyword matrix 𝑀 for the whole corpus. 2. Decompose 𝑀 with non-negative matrix factorization: 𝑀 𝑊 𝐻. 3. For each time slice 𝑡: a) Let 𝑊𝑡 be subset of 𝑊 and 𝑀𝑡 subset of 𝑀 for the documents in time slice 𝑡. b) Obtain the topic-term-matrix for 𝑡 with NMF while fixing 𝑊𝑡: 𝐻𝑡 = arg min 𝐻 * 𝑀𝑡 𝑊𝑡𝐻 *2 c) The temporal importance of topic 𝑗 is then 𝐼𝑡𝑗 = 𝑑𝑡(𝑊𝑡)𝑑𝑗, where all 𝑑 are documents in time slice 𝑡. We can obtain pseudo-topic distributions in the timeslices by L1-normalizing the temporal importances: 𝑃ˆ 𝑡𝑗 = 𝐼𝑡𝑗 𝑖 𝐼𝑡𝑖 . Since NMF is not probabilistic model, we use temporal pseudo-probabilities as proxy for topic distributions. 3.3. Performance as the To its using effectiveness topic-benchmark demonstrate KeyNMFs performance evaluate the and 15 keywords are paraphrase-multilingual-MiniLM-L12-v2 extracted for each document. Our evaluation procedure is based on that of Kardos et al. [15], but, since our intended use case is Chinese news data, we ran the benchmark using the same corpora and pipeline as in our investigations (see Sections 4 and 5). Additionally, we utilized paraphrase-multilingual-MiniLM for measuring external word embedding coherence, instead of an English Word2Vec model. topic model, we Python 2 embedding model. package 2https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 3This gives Top2Vec an unfair advantage on this metric as it selects descriptive words based on the same criteria as the metric. 𝐶𝑒𝑥 scores on Top2Vec should thus be interpreted with caution. Table 1 KeyNMFs performance on Chinese news data against number of baselines. Topic descriptions were evaluated on diversity (𝑑), internal (𝐶𝑖𝑛) and external (𝐶𝑒𝑥) word embedding coherence. Model KeyNMF S³ Top2Vec BERTopic CTMcombined CTMzeroshot NMF LDA chinanews 𝑑 𝐶in 𝐶ex 0.63 0.29 0.93 0.16 0.47 0.91 0.14 0.71 0.78 0.89 0.31 0.52 0.52 0.99 0.27 0.53 0.28 0.99 0.57 0.27 0.74 0.57 0.19 0.61 ihuawen oushinet xinozhou 𝑑 𝐶in 𝐶ex 𝑑 𝐶in 𝐶ex 𝑑 𝐶in 𝐶ex 0.64 0.17 0.91 0.11 0.47 0.91 0.10 0.70 0.83 0.89 0.26 0.50 0.51 0.99 0.23 0.99 0.50 0.23 0.53 0.18 0.60 0.54 0.16 0.53 0.84 0.23 0.58 0.12 0.83 0.54 0.12 0.73 0.87 0.50 0.23 0.84 0.51 0.21 0.99 0.50 0.99 0.22 0.54 0.18 0.64 0.54 0.13 0.41 0.55 0.26 0.85 0.17 0.55 0.96 0.14 0.71 0.86 0.84 0.26 0.52 0.51 0.25 0.98 0.51 1.00 0.26 0.56 0.18 0.66 0.58 0.14 0.48 yidali-huarenjie 𝐶in 𝐶ex 𝑑 0.57 0.52 0.88 0.46 0.52 0.93 0.46 0.69 0.75 0.91 0.57 0.51 0.49 0.97 0.54 0.97 0.51 0.54 0.54 0.49 0.71 0.54 0.34 0.57 Figure 1: Sensitivity of KeyNMF to the choice of 𝑁 keywords on multiple metrics and news sources. Based on our evaluations, KeyNMFs performance is comparable with state-of-the-art contextual topic models, and performs especially well on external coherence, only rivalled by Top2Vec on most corpora, which explicitly selects words based on their proximity in semantic space (see Table 1). The model represents drastic improvement over classical topic models outperforming both NMF and LDA significantly, indicating that the contextual information infused into the model enhances its performance in meaningful way. 3.3.1. Sensitivity to Number of Keywords We additionally test whether the number of keywords extracted from text influences the models performance on different corpora, which allows us to determine KeyNMFs robustness to hyperparameter choices. We used the same news sources, pipeline, and quantitative metrics for evaluating this property of the model as for previous evaluations and analyses. The number of keywords was varied from 5 to 100 with step size of 5 (see Figure 1). We observed that performance was relatively stable regardless of number of keywords, and converged rather quickly. Only minimal fluctuations are observable with 𝑁 > 25 on most corpora. However, on Xinozhou and Yidali-Huarenjie, lower values of 𝑁 (5-15) resulted in higher coherence scores. We thus deem 15 keywords balanced choice of 𝑁 for further investigations. Figure 2: The total and unique number of articles collected for each news site. 4. Data Having demonstrated the effectiveness of KeyNMF, we use it as the basis for our study of Chinese diaspora media. Our dataset comprises news articles from five sites aimed at Chinese diaspora populations in the EU: Chinanews,4 Ihuawen,5 Yidali Huarenjie,6 Xinouzhou,7 and Oushinet.8 We select these sites because they represent variety of formats, audiences, and perspectives. Oushinet has the largest target audience, with articles in several languages and local journalists writing specifically for the site. In contrast, Xinouzhou reports mostly on Chinese local news, Yidali Huarenjie and Chinanews are community media platforms based in Italy and Scandinavia respectively, and Ihuawen is weekly magazine based in the United Kingdom. Our data collection focuses on articles linked from each sites front page and selection of subpages we deem likely to contain information on international relations, particularly with Europe (listed in Appendix A). We hypothesize that articles linked from these main pages will reflect the topics each news site is attempting to highlight, and will thus provide information on the priorities of the forces backing the media landscape. We scrape all articles linked from each front page and subpage every six hours using custom web scraper. An article is only scraped once per time point, even if it was linked from multiple pages, but can be scraped multiple times if it appears at multiple time points. Data collection from four sites Chinanews, Ihuawen, Xinouzhou, and Oushinet began at 18:15 on April 30, 2024 and collection from the fifth site, Yidali Huarenjie, began at 12:15 on May 7, 2024. Our dataset includes all articles scraped until 6:15 on June 17, 2024, one week after the EU Parliamentary elections took place. Once scraped, we extract the body of each article from the corresponding html file. We attempt to minimize 4http://www.chinanews.se 5https://ihuawen.com 6https://yidali.huarenjie.com 7https://www.xinouzhou.com 8http://www.oushinet.com Figure 3: The number of new articles collected at each time point for each source. An article is new if it did not appear in the collected set of articles from the previous time point. the amount of boilerplate text (e.g. bylines and publication dates) included in the extracted texts; although it is impossible to remove all such text from our dataset, hand analysis of ten random articles from each news site indicates that the amount of junk text included in the final dataset is minimal. The total and unique number of articles collected from each site are reported in Figure 2. It is clear that different sites follow different publication patterns. To further validate this, we examine the number of new articles at each time point for each source, or the number of articles that were not included in the last scrape (Figure 3). We see that some sites, like Xinouzhou and Yidali Huarenjie, frequently refresh the articles displayed on their main pages, leading to larger number of unique articles. In contrast, sites like Ihuawen appear to keep several articles on the main pages for long time, meaning that they display very small number of unique articles overall. These differences likely affect the patterns we see in the information systems for each source. 5. Experimental Design Extracted article texts are embedded with multilingual transformer-based model [31]9 using the Sentence Transformers library.10 The embedding is done entirely on 64-core CPU with 384GB RAM. Each document is embedded once for each time it appears in the dataset. In total, embedding all the documents takes 2 hours. The maximum sequence length of this embedding model is 128 tokens. Thus, any article longer than 128 tokens is truncated and information from later in the piece is not included in the embedding. Although this is limitation, we do not consider it prohibitive, as previous research has shown that the bulk of the content in 9 paraphrase-multilingual-MiniLM-L12-v2 10https://sbert.net news article is presented at the very beginning widely-practiced professional standard for journalistic writing known as the inverted pyramid [32]. Since our primary interest is understanding the evolution of information dynamics in each news site over time, we use Dynamic KeyNMF to find topic proportions for each timeslice. For keyword extraction, we utilize the jieba tokenizer and remove stop-words present in an authoritative list,11 with the retained tokens then encoded using the same multilingual model as was used on the documents [31]. We fit multiple models with 10, 25, and 50 topics respectively in order to investigate topical dynamics at multiple levels of granularity. Separate models are fit for each news site. The plotted topics over time, top keywords for each topic at each timeslice, and topic distributions at each timeslice are extracted from each model and saved for further analysis. We then use the topic pseudo-distributions to measure the novelty and resonance signals for each news site and, following [9] and [12], use windowed relative entropy with Jensen-Shannon divergence to calculate both metrics. For window of size 𝑛, the novelty at time point 𝑡 is the mean entropy of the topic pseudo-distribution at 𝑡 (𝑃ˆ 𝑡) and the 𝑛 previous pseudo-distributions. The transience at time point 𝑡 is the mean entropy of the topic pseudo-distribution at 𝑡 and the 𝑛 subsequent pseudo-distributions. Then, the resonance of time point is the novelty at that point minus the transience. We use window of size 12 when calculating both signals, which is equivalent to three days of data. We apply nonlinear adaptive filtering to smooth the extracted novelty and resonance, again following [9] and [12]. This removes noise from the signals by calculating the value at given time point relative to the surrounding time points. We use span of 56, the same as [12], for smoothing. The code we use for calculating novelty and resonance is adapted from that released alongside [12] and [9]. 6. Results and Discussion We find clear trends in the novelty and resonance signals that correlate to significant events in the EU during the period studied: Xi Jinpings European Tour (May 5-10), Putins state visit to China (May 16-17), and the EU parliamentary elections (June 6-9). Our analysis focuses on the novelty and resonance trends extracted from the KeyNMF models with ten topics as these provide the clearest signals. The results for 25 and 50 topics are included in Appendix C.1. We additionally focus our in depth discussion of the results on the two largest news sources, Xinouzhou and Oushinet, for this preliminary validation of the pipeline. We see spikes in novelty of varying strengths for both Xinouzhou and Oushinet during Xi Jinpings European tour (Figure 4). There are also corresponding dips in resonance before his tour for both sites, followed by increases in resonance during the tour. This indicates that novel information is introduced to the site ecosystems during the tour which replaces previous topics of interest, and which persists in the system for some time. One of the most productive aspects of Dynamic KeyNMF is that it allows us to study topic fluctuations over time. Thus, we explore which topical shifts contribute to changes in the novelty and resonance signals. For example, on Oushinet, the time period during Xi Jinpings 11https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt Figure 4: The novelty and resonance plots for each news site from KeyNMF with ten topics. The three shaded areas represent Xi Jinpings European tour (May 5-10, 2024), Putins state visit to China (May 16-17, 2024), and the EU parliamentary elections (June 6-9, 2024). Note that the y-axis ranges differ for each chart. European tour is associated with high pseudo-probabilities for topic defined by the keywords Paris, France and state visit and topic defined by President, China, and Xi Jinping (Appendix C.2, Figure 9). Towards the end of the tour, topic on diplomacy and bilaterial relations between China and France also gains prominence. For Xinouzhou, this time period contains peak in the pseudo-probabilities for two topics on Hungary and Chinese relations with Hungary, one of the locations on the tour. Similarly, there is noticeable spike in the novelty and resonance for Oushinet directly before Putins state visit to China. This period is marked by relatively high pseudo-probabilities for topic characterized by the terms China, Beijing, Chinese, and Chinese News Service and topic with the keywords Russia, Ukraine, Putin, and Moscow (Appendix C.2, Figure 7). Most significantly for this study, there are fluctuations in novelty and resonance for both sites around the EU parliamentary elections. Specifically, there are peaks in the novelty and resonance signals for Xinouzhou and Oushinet before and after the elections, with troughs throughout much of the election period. We hypothesize that these trends reflect focus on election-related news which begins in early June and continues through the elections and then an introduction of new topics after their end. Again examining the topic distributions, we see that for Oushinet the period before and during the election is marked by high pseudo-probabilities for two topics directly related to the parliamentary elections, one topic surrounding the Spanish prime minister, and two on Russia and Ukraine and the Israel-Palestine war (Appendix C.2, Figure 8). Interestingly, pseudo-probabilities for the topic most directly focused on the elections continued to grow even after the election, suggesting that Oushinet was still discussing the election results during this time. Similarly, for Xinouzhou, three topics focused on the UK elections, Europe broadly, and the Spanish prime minister were comparatively prominent towards the end of May and beginning of June. Overall, we find that this pipeline allows us to effectively locate changes in news ecosystems, correlate these changes to political and cultural events of interest, and further explore possible reasons for these changes via topic models. It reveals differences in media responses both between events and between sites, while also demonstrating the similarities in sites news ecosystems, such as the increased discussion of the Spanish prime minister on both Xinouzhou and Oushinet before the EU parliamentary elections. We believe that the combination of the novelty and resonance metrics with the novel KeyNMF topic model will permit further in-depth analysis of these media sites and facilitate research on other Chinese-language domains. 7. Conclusion In this paper, we present pipeline designed to facilitate research on the underlying information dynamics of Chinese diaspora media published in Europe. This pipeline combines existing information-theoretic methods that model how new information enters and persists in systems with novel topic model, KeyNMF. KeyNMF overcomes some of the weaknesses of previous traditional and contextual topic models, demonstrating high performance on standard benchmarks. We validate this pipeline through preliminary experimentation on our dataset of Chinese diaspora media, finding that it reveals informational trends that correlate with major, newsworthy events in European politics and allows for further analysis of the topical changes that cause those trends. While further qualitative research is required to fully understand these dynamics, we believe that we have presented major step forward in terms of context-sensitive and interpretable topic modelling and information dynamics which can generalize to multilingual and data scarce environments."
        },
        {
            "title": "Acknowledgments",
            "content": "Part of the computation done for this project was performed on the UCloud interactive HPC system, which is managed by the eScience Center at the University of Southern Denmark."
        },
        {
            "title": "References",
            "content": "[1] K. Gatterman, T. M. Meyer, K. Wurzer, Who Won the Election? Explaining News Coverage of Election Results in Multi-Party Systems, European Journal of Political Research 61 (2022) 857877. doi:10.1111/1475-6765.12498. [2] M. Schliebs, H. Bailey, J. Bright, P. N. Howard, Chinas Public Diplomacy Operations: Understanding Engagement and Inauthentic Amplification of PRC Diplomats on Facebook and Twitter, Technical Report, Oxford, UK: Programme on Democracy & Technology, 2021. [3] M. Thunø, K. L. Nielbo, The Initial Digitalization of Chinese Diplomacy (20192021): Establishing Global Communication Networks on Twitter, Journal of Contemporary China 33 (2024) 244266. doi:10.1080/10670564.2023.2195811. [4] V. Brussee, Authoritarian Design: How the Digital Architecture on Chinas Sina Weibo Facilitate Information Control, Asiascape: Digital Asia 9 (2022) 207241. doi:10.1163/ 22142312-bja10033. [5] K. Chan, C. Alden, <Redirecting> the Diaspora: Chinas United Front Work and the Hyperlink Networks of Diasporic Chinese Websites in Cyberspace, Political Research Exchange 5 (2023) 121. doi:10.1080/2474736X.2023.2179409. [6] A. T. J. Barron, J. Huang, R. L. Spang, S. DeDeo, Individuals, Institutions, and Innovation in the Debates of the French Revolution, Proceedings of the National Academy of Sciences 115 (2018) 46074612. doi:10.1073/pnas.1717729115. [7] K. L. Nielbo, P. B. Vahlstrup, A. Bechmann, J. Gao, Trend Reservoir Detection: Minimal Persistence and Resonant Behavior of Trends in Social Media, in: Proceedings of the Workshop on Computational Humanities Research (CHR 2020), Amsterdam, the Netherlands, 2020, pp. 290297. doi:10.48550/arXiv.2109.08589. [8] K. L. Nielbo, R. B. Baglini, P. B. Vahlstrup, K. C. Enevoldsen, A. Bechmann, A. Roepstorff, News Information Decoupling: An Information Signature of Catastrophes in Legacy News Media, in: Proceedings of the 2020 European Association for Digital Humanities Conference, Krasnoyarsk, Russia, 2021, pp. 18. doi:10.48550/arXiv.2101.02956. [9] K. L. Nielbo, F. Haestrup, K. C. Enevoldsen, P. B. Vahlstrup, R. B. Baglini, A. Roepstorff, When No News is Bad News Detection of Negative Events from News Media Content, 2021. doi:10.48550/arXiv.2102.06505. arXiv:2102.06505. [10] K. L. Nielbo, K. Enevoldsen, R. Baglini, E. Fano, A. Roepstorff, J. Gao, Pandemic News Information Uncertainty News Dynamics Mirror Differential Response Strategies to COVID-19, PLOS ONE 18 (2023) e0278098. doi:10.1371/journal.pone.0278098. [11] M. Wevers, J. Kostkan, K. L. Nielbo, Event Flow How Events Shaped the Flow of the News, 1950-1995, in: Proceedings of the Third Conference on Computational Humanities Research, CHR 2021, Amsterdam, the Netherlands, 2021, pp. 6276. doi:10.48550/arXiv. 2109.08589. [12] R. B. Baglini, S. M. Østergaard, S. N. Larsen, K. L. Nielbo, Emodynamics: Detecting and Characterizing Pandemic Sentiment Change Points on Danish Twitter, in: Proceedings of the Fourth Conference on Computational Humanities Research, CHR 2022, Antwerp, Belgium, 2022, pp. 162176. [13] D. M. Blei, A. Y. Ng, M. I. Jordan, Latent Dirichlet Allocation, Journal of Machine Learning Research 3 (2003) 9931022. doi:10.5555/944919.944937. [14] D. M. Blei, Probabilistic Topic Models, Communications of the ACM 55 (2012) 7784. doi:10.1145/2133806.2133826. [15] M. Kardos, J. Kostkan, A.-Q. Vermillet, K. Nielbo, K. Enevoldsen, R. Rocca, 𝑆3 Semantic Signal Separation, 2024. doi:10.48550/arXiv.2406.09556. arXiv:2406.09556. [16] H. M. Wallach, D. Mimno, A. McCallum, Rethinking LDA: Why Priors Matter, in: Advances in Neural Information Processing Systems, Vancouver, Canada, 2009, pp. 19. [17] R. Řehůřek, P. Sojka, Software Framework for Topic Modelling with Large Corpora, in: Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, Valletta, Malta, 2010, pp. 4550. [18] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, E. Duchesnay, Scikit-Learn: Machine Learning in Python, Journal of Machine Learning Research 12 (2011) 28252830. [19] Q. Zhao, Z. Qin, T. Wan, Topic Modeling of Chinese Language Using Character-Word Relations, in: Neural Information Processing, Berlin, Heidelberg, 2011, pp. 139147. [20] Z. Qin, Y. Cong, T. Wan, Topic modeling of chinese language beyond bag-of-words, Computer Speech & Language 40 (2016) 6078. doi:https://doi.org/10.1016/j.csl. 2016.03.004. [21] D. M. Blei, J. D. Lafferty, Dynamic Topic Models, in: Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, Pennsylvania, USA, 2006, pp. 113120. doi:10.1145/1143844.1143859. [22] N. Reimers, I. Gurevych, Sentence-BERT: Sentence Embeddings using Siamese BERTNetworks, in: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, Hong Kong, China, 2019, pp. 39823992. doi:10.18653/v1/D19-1410. [23] F. Bianchi, S. Terragni, D. Hovy, Pre-Training is Hot Topic: Contextualized Document Embeddings Improve Topic Coherence, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), Online, 2021, pp. 759766. doi:10.18653/v1/2021.acl-short.96. [24] F. Bianchi, S. Terragni, D. Hovy, D. Nozza, E. Fersini, Cross-lingual Contextualized Topic Models with Zero-shot Learning, in: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online, 2021, pp. 16761683. doi:10.18653/v1/2021.eacl-main.143. [25] M. Grootendorst, BERTopic: Neural Topic Modeling with Class-Based TF-IDF Procedure, 2022. doi:10.48550/arXiv.2203.05794. arXiv:2203.05794. [26] D. Angelov, Top2Vec: Distributed Representations of Topics, 2020. arXiv:2008.09470. [27] M. Belford, B. Mac Namee, D. Greene, Stability of Topic Modeling via Matrix Factorization, Expert Systems With Applications 91 (2018) 159169. doi:10.1016/j.eswa.2017.08. 047. [28] A. Lefèvre, F. Bach, C. Févotte, Online Algorithms for Nonnegative Matrix Factorization with the Itakura-Saito Divergence, in: 2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), New Paltz, NY, USA, 2011, pp. 313316. doi:10.1109/ASPAA.2011.6082314. [29] A. Cichocki, A.-H. Phan, Fast Local Algorithms for Large Scale Nonnegative Matrix and Tensor Factorizations, IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences E92.A (2009) 708721. doi:10.1587/transfun.E92.A.708. [30] M. Grootendorst, KeyBERT: Minimal Keyword Extraction with BERT, 2020. doi:10.5281/ zenodo.4461265. [31] N. Reimers, I. Gurevych, Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, Online, 2020, pp. 45124525. doi:10.48550/arXiv.2004. 09813. [32] H. Pöttker, News and Its Communicative Quality: the Inverted Pyramid When Journalism Studies 4 (2003) 501511. doi:10.1080/ and Why Did It Appear?, 1461670032000136596. A. News Site Subpages The subpages scraped for each news site are listed below: Xinouzhou: France, Italy, Spain, UK, Germany, Hungary, International Ihuawen: News, Comments & Opinions Oushinet: Europe, Europe: Germany, Europe: Central and Eastern Europe, Europe: Italy, Europe: Spain, Europe: Other, France, Europe and China, Overseas Chinese community, China, International, Opinion on public affairs Chinanews: Nordic headlines, China news, Mutual learning among civilizations, Overseas Chinese community, Nordic Commercial Bridge, Overseas thoughts Yidali Huarenjie: B. NPMI Coherence Since NPMI Coherence has historical significance in topic modeling literature, we also evaluated topic descriptions with this metrics. Due to theoretical and practical limitations[15], however, we do not consider NPMI Coherence good metric for evaluating topic models. For the sake of completeness, we report 𝐶NPMI scores in Table 2. Table 2 𝐶NPMI coherence of different topic models on the studied corpora. Model chinanews ihuawen oushinet xinozhou yidali-huarenjie BERTopic CombinedTM KeyNMF LDA NMF S³ Top2Vec ZeroShotTM 0.06 -0.07 -0.21 -0.02 0.11 -0.37 -0.36 -0.07 0.11 -0.02 -0.23 -0.02 0.08 -0.37 -0.36 -0.03 0.08 -0.07 -0.00 0.02 0.10 -0.22 -0.25 -0.06 0.10 -0.02 -0.04 0.03 0.10 -0.18 -0.22 -0.03 0.08 -0.12 -0.14 0.00 0.10 -0.37 -0.36 -0.11 C. Additional Experimental Results C.1. Novelty and Resonance Ablations Figure 5: The novelty and resonance plots for each news site from KeyNMF with 25 topics. The three shaded areas represent Xi Jinpings European tour (May 5-10, 2024), Putins state visit to China (May 16-17, 2024), and the EU parliamentary elections (June 6-9, 2024). Note that the y-axis ranges differ for each chart. Figure 6: The novelty and resonance plots for each news site from KeyNMF with 50 topics. The three shaded areas represent Xi Jinpings European tour (May 5-10, 2024), Putins state visit to China (May 16-17, 2024), and the EU parliamentary elections (June 6-9, 2024). Note that the y-axis ranges differ for each chart. C.2. Topic Distributions Over Time Figure 7: The distributions over time for two topics with high pseudo-probabilities before Putins state visit to China. These topics are generated by the 10-topic KeyNMF model for Oushinet. Note that the y-axis scale differs for each subplot. Figure 8: The distributions over time for eight topics with high pseudo-probabilities around the EU parliamentary elections. These topics are generated by the 10-topic KeyNMF models for Oushinet and Xinouzhou. Note that the y-axis scale differs for each subplot. Figure 9: The distributions over time for five topics with high pseudo-probabilities during Xi Jinpings European tour. These topics are generated by the 10-topic KeyNMF models for Oushinet and Xinouzhou. Note that the y-axis scale differs for each subplot."
        }
    ],
    "affiliations": [
        "Center for Humanities Computing, Aarhus University, Denmark",
        "Department of Computer Science, Cornell University, USA",
        "Department of Global Studies, Aarhus University, Denmark",
        "Department of Linguistics, Cognitive Science, and Semiotics, Aarhus University, Denmark"
    ]
}