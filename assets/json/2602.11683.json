{
    "paper_title": "ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces",
    "authors": [
        "Xin Xu",
        "Tong Yu",
        "Xiang Chen",
        "Haoliang Wang",
        "Julian McAuley",
        "Saayan Mitra"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence."
        },
        {
            "title": "Start",
            "content": "THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Xin Xu 1 Tong Yu 2 Xiang Chen 2 Haoliang Wang 2 Julian McAuley 1 Saayan Mitra 2 6 2 0 2 2 1 ] . [ 1 3 8 6 1 1 . 2 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, THINKROUTER, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. THINKROUTER routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that THINKROUTER outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that THINKROUTER can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence. 1. Introduction Large language models (LLMs) have demonstrated promising reasoning capabilities to solve complex problems (Huang & Chang, 2023; Wang et al., 2024). key driver <xinxucs@ucsd.edu> 1UC San Diego 2Adobe Research. Correspondence to: Saayan Mitra <smitra@adobe.com>. Preprint. February 13, 2026. 1 is explicit chain-of-thought (CoT), which emulates human thinking by generating intermediate reasoning trajectories in natural language (Wei et al., 2022; Feng et al., 2023; Chu et al., 2024). Recent work uses reinforcement learning (RL) to train LLMs to reason with thinking trajectories before giving answers (Xu et al., 2025a; Li et al., 2025). Such reasoning-intensive training produces large reasoning models (LRMs), e.g., OpenAI o1 (Jaech et al., 2024) and Qwen3 (Yang et al., 2025a), which have demonstrated strong reasoning performance on hard tasks, such as mathematics and coding (Anthropic, 2024; Jimenez et al., 2024; Team, 2025a). While explicit trajectories improve reasoning accuracy and interpretability, they limit models expressive bandwidth (Zhu et al., 2025b). Meanwhile, long thinking chains substantially increase inference cost and response latency (Aggarwal & Welleck, 2025; Chen et al., 2025a). These developments highlight the two goals for efficient reasoning, i.e., improving reasoning accuracy while reducing generation length. To target this goal, recent work has explored LLM reasoning in latent space, shifting reasoning from discrete tokens to latent representations (Chen et al., 2025b). For example, Coconut (Hao et al., 2024), CCoT (Cheng & Durme, 2024), and LightThinker (Zhang et al., 2025b) construct several soft tokens to represent long thoughts to reduce tokens but require tuning, and their effectiveness varies across settings, where they even drop performance in some cases. Soft Thinking (Zhang et al., 2025c), training-free method by calculating token-probability-weighted soft embeddings, is proposed and can raise the performance ceiling (3.1). However, the underlying reason for its effectiveness has not fully explored (Wu et al., 2025). Meanwhile, few works (Shi et al., 2025) study whether hybrid reasoning between latent space and discrete spaces will help efficient reasoning. Therefore, we explore training-free LRM reasoning in hybrid reasoning spaces for efficient reasoning in this work. Since Soft Thinking performs much better than explicit CoT, we first analyze latent-only reasoning through LRM confidence dynamics with Soft Thinking (3.2). The maximum next-token probability is used as the proxy of LRM confidence (Hendrycks & Gimpel, 2017; Guo et al., 2017). We observe that the reasoning trajectories for incorrect answer THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces predictions have fewer low-confidence steps than those for correct answers. We also hypothesize that if the maximum next-token probability is low, the soft embedding is an aggregation of multiple low-confidence incompatible thinking alternatives, introducing representational noise. Such noise may propagate and accumulate across successive latent reasoning steps, leading the model to commit to an inadequately supported solution with high confidence. These observations motivate us to propose new, efficient reasoning solution that prevents LRMs from becoming highly confident and from representational noise. Therefore, we propose THINKROUTER, an inference-time mechanism that routes LRM thinking between the discrete token space and the latent space based on LRM confidence (4). Specifically, for each time step during thinking, when the maximum next-token probability is lower than routing threshold, THINKROUTER routes thinking to the discrete space where one next token is sampled to avoid introducing much noise and mitigate confidence. Otherwise, LRM conducts thinking in the latent space where probability-weighted soft embedding (following Soft Thinking) is calculated. THINKROUTER is evaluated (5) on LRMs with diverse scales (1.5B - 32B) and architectures (Qwen3 (Yang et al., 2025a) and gpt-oss (Agarwal et al., 2025)) and datasets with different domains (STEM reasoning and coding). Extensive experiments illustrate that THINKROUTER outperforms discrete CoT, Soft Thinking, and random routing in accuracy, improving average Pass@1 by up to 19.70 points, while reducing generation length comparably with the baselines. Moreover, we analyze the underlying reason for THINKROUTERs effectiveness. THINKROUTER can correct errors from explicit CoT and Soft Thinking. THINKROUTER can also increase the ratio of low-confidence time steps during thinking, indicating that THINKROUTER can prevent LRMs from becoming highly confident in incorrect solutions to improve accuracy. Meanwhile, we find that the steps immediately preceding the end-of-thinking (EOT) token generation are characterized by sharply declining or relatively low confidence, suggesting that confidence mitigation THINKROUTER brings can accelerate the triggering of the EOT token. As result, THINKROUTER effectively shortens the generation length. Overall, THINKROUTER is simple yet effective method for efficient reasoning. Our contributions in this work are: LRM confidence dynamics under Soft Thinking (latentonly reasoning) is explored. We observe that incorrect predictions involve fewer low-confidence time steps than correct ones during thinking, and hypothesize that soft embeddings aggregated from multiple lowconfidence alternatives are noisy. These motivate us to avoid high confidence and noise to improve reasoning. We introduce THINKROUTER, an inference-time mechanism for efficient reasoning by routing thinking between discrete token space and latent space based on LRM confidence. The extensive experiments show that THINKROUTER outperforms explicit CoT, random routing, and Soft thinking, achieving much accuracy gains across models and tasks, and competitive generation length reduction. Comprehensive analysis reveals that THINKROUTER can perform corrective calibration for errors arising from explicit CoT and latent reasoning with Soft Thinking, and accelerates end-of-thinking token generation by globally lowering model confidence. 2. Related Work Latent Reasoning Recent work explores moving reasoning from discrete CoT tokens to latent thoughts. Coconut (Hao et al., 2024) uses the last hidden states as input embeddings and tunes models to reason with several soft tokens that represent longer reasoning steps to reduce tokens. However, there is mismatch between the last hidden states and the input embeddings. Some works, such as Deng et al. (2023), CCoT (Cheng & Durme, 2024), LaRS (Xu et al., 2024), SoftCoT (Xu et al., 2025b), CODI (Shen et al., 2025), CoT2 (Gozeten et al., 2025), and SIM-COT (Wei et al., 2025), construct mapping or use distillation to learn compressed latent thoughts from discrete chain-of-thoughts to align them and effectively internalize step-by-step traces into dense representations. CoLaR (Tan et al., 2025) and Butt et al. (2025) use RL to optimize latent reasoning behavior. Saunshi et al. (2025); Zhu et al. (2025c) use looped language models to scale latent reasoning by iteratively refining hidden states with shared parameters. These latentreasoning methods improve LRM reasoning efficiency but rely on costly training or distillation. Soft Thinking (Zhang et al., 2025c) tries training-free latent reasoning by calculating next-token-probability-weighted soft embedding. However, few works explore the underlying mechanism of latent reasoning (Zhu et al., 2025a). Hybrid Reasoning Recent work investigates hybrid reasoning, where LLM reasoning performs among different thinking modes. HRPO (Yue et al., 2025) enables switching between latent and discrete reasoning through an RL-learned gating mechanism. In parallel, Thinkless (Fang et al., 2025), AdaptThink (Zhang et al., 2025a; Wan et al., 2025), LHRM (Jiang et al., 2025), Qiao et al. (2025), and MixReasoning (Lu et al., 2025a) learn policies that decide long thinking or non-thinking. However, all of these methods rely on RL or additional training to acquire the hybrid reasoning behaviors. To date, there is few training-free mechanism that can explicitly control whether reasoning is carried out in latent space or discrete space at inference time (Shi et al., 2025). 2 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Figure 1. Ratio of low-confidence time steps (pmax GPQA Diamond. The incorrect predictions are associated with fewer low-confidence thinking time steps than the correct predictions. < τ ) within reasoning trajectories under Soft Thinking (latent-only reasoning) on 3. Preliminary 3.1. LRM Reasoning in Discrete and Latent Spaces Given an input query x1:Q = {x1, x2, . . . , xQ}, large reasoning model first has thinking process by producing reasoning trajectory r1:M = {r1, r2, . . . , rM } until special end-of-thinking (EOT) token is generated. And then it generates final answer y1:N = {y1, y2, . . . , yN }. We denote as the LRMs vocabulary of size V, and RVd as the token embeddings. For each token V, its embedding is E[v] Rd. Reasoning in Discrete Space At each time step within thinking, discrete token rt is sampled from the next-token probability distribution pt (after temperature scaling) over the vocabulary, conditioned on the input and previous generated tokens: rt pt = LRM(E[x1:Q], E[r1:t1]) (1) Reasoning in Latent Space During thinking, soft token embedding et is calculated at each time step t. In this work, we follow Soft Thinking (Zhang et al., 2025c) to calculate probability-weighted soft token embedding using the top-j probabilities: ˆpt = SAMPLE(pt), pt = LRM(E[x1:Q], e1:t1) V1 (2) (3) top-j = Top-J(ˆpt) (cid:88) et = pt[v]E[v] Rd, pt[v] = vV top-j e1:t := e1:t1et ˆpt[v] (cid:80) uV top-j ˆpt[u] (4) (5) where SAMPLE is the sampling operation that applies top-k, top-p, and min-p filtering with renormalization (Appendix B.3), and Top-J(pt) is the set of tokens with top-j highest probabilities under the distribution pt. Unlike reasoning in discrete space, which collapses the probability mass onto one single token, thereby committing to one explicit 3 reasoning path, latent reasoning operates in latent space, allowing LRMs to integrate multiple potential reasoning paths in parallel, thereby maintaining the information over possible thoughts (Hao et al., 2024; Zhang et al., 2025c). After thinking, the model generates final answer with standard decoding in discrete space: yt pt = LRM(E[x1:Q], E[r1:M ], E[y1:t1]) V1 (6) 3.2. Model Confidence with Latent Reasoning We first examine LRM behaviors to figure out the difference between correct and incorrect generations under latentonly reasoning with Soft Thinking, which outperforms explicit CoT. Specifically, we analyze whether LRMs exhibit systematically different confidence patterns within reasoning trajectories when producing correct versus incorrect answers. Two LRMs from different families and scales (Qwen3-8B (Yang et al., 2025a) and gpt-oss-20b (Agarwal et al., 2025)) are evaluated on two representative reasoning tasks spanning different domains: STEM reasoning with GPQA Diamond (Rein et al., 2023) and code generation with HumanEval (Chen et al., 2021). We conduct Soft Thinking and record the next-token probability distribution over the vocabulary at each time step. The maximum next-token probability, i.e. pmax pt[v] as proxy for the model confidence is monitored (Gal & Ghahramani, 2016; Jiang et al., 2020; Vashurin et al., 2025). Figure 1 and 6 report the ratios of low-confidence time steps (pmax < τ ) in reasoning trajectories separately for correct and incorrect answers LRMs generate, where τ [0.1, 0.95] (Appendix A). = max vV From these figures, we observe that when LRMs ultimately produce an incorrect answer, their reasoning trajectories contain fewer low-confidence steps than those ending in correct answer in most cases, especially when τ [0.4, 0.9], indicating an association between unsuccessful reasoning and relatively high confidence. This gives us insights into mitigating high confidence to improve reasoning. Meanwhile, it is found that reasoning trajectories of correct preTHINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Figure 2. Overview of THINKROUTER. During thinking, when the maximum next-token probability pmax is lower than the routing threshold τ , THINKROUTER routes thinking to the discrete token space; otherwise, THINKROUTER routes thinking to the latent space by calculating probability-weighted soft embedding. dictions often maintain steps with relatively low pmax . relatively low pmax indicates that pt assigns comparable probability mass to multiple alternative continuations. In such cases, the soft embedding is formed by aggregating these low-confidence alternatives. However, we hypothesize that these alternatives may correspond to distinct or even mutually incompatible reasoning directions. Aggregating such alternatives may yield representation that is semantically diffuse or poorly grounded, potentially introducing noise (Arora et al., 2017; Yang et al., 2018; Lim et al., 2021; Hao et al., 2023; Wang et al., 2023). We further conjecture that such noise may accumulate over successive latent reasoning steps. As such representations are propagated in the latent space, LRM can drift toward spurious or incoherent reasoning, eventually assigning higher confidence to directions that are not well supported, which provides potential explanation for why LRMs tend to have fewer low-confidence steps in reasoning trajectories of incorrect answers (Bengio et al., 2015; Schmidt, 2019; Huang et al., 2025; Javaji et al., 2025; Kalai et al., 2025; Lu et al., 2025b). Overall, these observations reveal potential failure modes that limit efficient reasoning and motivate us to prevent LRMs from high confidence and avoid integrating multiple low-confidence alternatives. Thinking Space alternatives from being jointly explored in latent space. At each time step within thinking, THINKROUTER determines the reasoning space based on the maximum next-token probability under the next-token probability distribution: Discrete Token Space with rt if pmax < τ, if pmax Latent Space with et τ, (7) If the maximum next-token probability pmax < τ , where τ is routing threshold, indicating that all alternatives are of low confidence, the thinking operates with one discrete token to avoid aggregating multiple incompatible or noisy thinking alternatives and prevent LRMs from becoming highly confident by committing to low-confidence alternative. Conversely, when pmax τ , reasoning proceeds in the latent space where soft token embedding et is calculated to represent mixture of multiple plausible reasoning paths, allowing richer exploration in the latent concept space following Soft Thinking. Overall, LRM reasoning with THINKROUTER is implemented as Algorithm 1 (To facilitate presentation, we omit the case where the model outputs exceed the LRMs maximum generation length). More details, such as COLDSTOP, MULTINOMIALSAMPLE, DECODE, etc., are described in Appendix B.1. 4. THINKROUTER Therefore, we propose THINKROUTER, an inference-time mechanism by routing thinking between discrete and latent spaces based on LRM confidence, as shown in Figure 2. Specifically, THINKROUTER prevent unreliable thinking 5. Experiments and Results 5.1. Setups Datasets and Metrics THINKROUTER is comprehensively evaluated on five reasoning benchmarks in differ4 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Algorithm 1 THINKROUTER Input: Query x1:Q, LRM M, Routing Threshold τ Output: Answer 1: [ ] 2: while true do 3: 4: 5: 6: 7: 8: 9: 10: pt M(E[x1:Q], R) pmax maxvV pt[v] ˆpt SAMPLE(pt) Top-k/Top-p/Min-p Renorm if pmax Discrete Space < τ then rt MULTINOMIALSAMPLE(ˆpt) E[rt] Embeddings Thinking Temperature Scaling Latent Space Eq. (3) else pt[v]E[v] Rd Eq. (4) 11: 12: ˆpt[v] top-j top-j = Top-J(ˆpt) pt[v] = (cid:80) et = (cid:80) et rt arg maxvV ˆpt[v] vV top-j ˆpt[u] uV end if if COLDSTOP(pt) then rt = EOT Token break 13: 14: 15: 16: 17: 18: 19: 20: 21: end if 22: 23: end while 24: DECODE(M, E[x1:Q], R) 25: return end if if rt = EOT Token then break ent domains, including i) STEM reasoning: AIME 2024 (AIME), AIME 2025 (AIME), and GPQA Diamond (Rein et al., 2023), and ii) coding: HumanEval (Chen et al., 2021), and MBPP (Austin et al., 2021). The details are in Appendix B.2. Pass@1 is used as the accuracy of the models generated answers, where Pass@k = 1 (cid:0)nc (cid:1). We set = 1 so that Pass@1= , following Soft Thinking. For each sample, the LRM generates = 3 candidate answers with three seeds {0, 7, 42}. is the number of correct answers. We report the average Pass@1 over all samples in each test set. Meanwhile, we use the token number of thinking trajectories and final answer outputs as the generation length and report the average generation length across all samples in each test set to measure token costs. (cid:1)/(cid:0)n Models We select four large reasoning models, Qwen3- (1.7B, 8B, 32B) (Yang et al., 2025a), and gpt-oss-20b (Agarwal et al., 2025), with different model scales and architectures to evaluate our method, which aims to illustrate the generality and robustness of THINKROUTER. Baselines THINKROUTER are compared with four baselines for evaluation. Following Soft Thinking (Zhang et al., 5 2025c), we apply two baselines in the discrete token space: CoT with the sampling strategies and with greedy decoding. Soft Thinking serves as the baseline in the latent space. We also include Random Routing baseline for sanity check, which randomly selects the thinking space at each time step to assess the effectiveness of the confidence-aware mechanism. More details are described in Appendix B.3. Implementation All experiments are implemented with SGLang (Zheng et al., 2024) and NVIDIA H100 80G GPUs, following Soft Thinking. For the routing threshold τ , we use 10 samples randomly selected from each dataset as validation set and perform grid search within {0.4, 0.5, 0.6, 0.7, 0.8, 0.9} on the validation set to find the optimal τ . Then we conduct evaluation with the optimal τ on the rest samples in each dataset (More details are in Appendix B.4). Tables 1 and 2 report THINKROUTERs performance on STEM reasoning and coding benchmarks, respectively. For each benchmark, the metrics are calculated over the remaining samples after excluding the 10 samples used for grid search. To ensure the robustness of our evaluation, we also report results on all samples of each benchmark in Tables 7 and 8, provided in Appendix B.5. 5.2. Main Results Pass@1 Accuracy Improvement Across almost all benchmarks, THINKROUTER outperforms the baselines. For STEM reasoning as shown in Table 1, THINKROUTER yields notable gains. For example, THINKROUTER improves the average Pass@1 of CoT (sampling) by up to +19.70 points in Qwen3-1.7B. Although Soft Thinking also improves accuracy in some settings, its effectiveness varies between tasks and models. Comparatively, THINKROUTER consistently achieves average Pass@1 gains over Soft Thinking of 9.22, 6.18, 5.63, 13.80 points on Qwen3-1.7B, 8B, 32B, and gpt-oss-20b respectively. Importantly, even in cases where Soft Thinking reduces the accuracy of CoT, THINKROUTER remains much more effective. For instance, for gpt-oss-20b, Soft Thinking degrades the Pass@1 by 3.33 points on the difficult AIME 2025 compared to CoT (sampling), whereas THINKROUTER still achieves 15.00-point improvement, indicating that Soft Thinking can amplify noise in reasoning trajectories, leading to unreliable answers, while confidence-aware routing can avoid such failure mode. similar pattern is observed on coding benchmarks as shown in Table 2. While Soft Thinking causes accuracy drops in most cases, THINKROUTER consistently improves Pass@1. Moreover, we observe an ordering in Pass@1 performance in most cases: THINKROUTER > Random Routing > Soft Thinking, which suggests that routing is beneficial for efficient reasoning, and incorporating confidence into routing is much more effective. Overall, these results show that THINKROUTER yields greater and more THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Table 1. Pass@1 (%) and generation length on STEM reasoning benchmarks for THINKROUTER and the baselines across different models. Blue and red values indicate performance improvements and degradations, respectively, relative to CoT (sampling). Bold values highlight the best-performing baseline within the same model and benchmark setting. AIME 2024 AIME 2025 GPQA Diamond Average AIME 2024 AIME 2025 GPQA Diamond Average Pass@1 (%) Generation Length CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER 46.67 63.33 55.00 60.00 71.67 76.67 86.67 85.00 85.00 86.67 76.67 75.00 91.67 90.00 91.67 78.33 76.67 75.00 93.33 91.67 16.67 8.33 13.33 25.00 10.00 8.33 8.33 10. 1.67 15.00 13.33 15.00 1.67 3.33 15.00 13.33 25.00 26.67 43.33 38.33 51.67 71.67 81.67 75.00 78.33 80.00 78.33 76.67 78.33 80.00 86.67 73.33 73.33 70.00 80.00 88. 1.67 18.33 13.33 26.67 10.00 3.33 6.67 8.33 1.67 0.00 1.67 8.33 0.00 3.33 6.67 15.00 38.48 35.28 43.26 44.33 45.92 59.04 60.64 62.94 65.96 74. 66.67 65.78 72.87 75.18 76.42 64.18 66.84 65.25 65.25 71.63 3.19 4.79 5.85 7.45 1.60 3.90 6.91 15.78 0.89 6.21 8.51 9.75 2.66 1.06 1.06 7. Qwen3-1.7B 5.05 10.48 10.84 19.70 18433.02 19189.85 17424.30 17577.37 15863.13 Qwen3-8B 7.20 5.19 7.30 11.37 14138.82 15474.35 13338.65 14854.15 13661. Qwen3-32B 1.41 7.07 7.84 12.70 12508.73 12809.85 11890.85 11698.17 11810.12 gpt-oss-20b 0.33 1.87 7.58 11.93 10293.37 13524.60 5769.30 6942.24 8624. 36.71 41.76 47.20 47.55 56.42 69.13 76.32 74.31 76.43 80.50 73.89 72.48 80.96 81.73 86.58 71.95 72.28 70.08 79.53 83.88 19146.13 21794.50 18835.50 20223.57 18504.38 20042.08 20388.60 19297.30 19978.65 18756. 17758.15 16162.40 17573.90 18147.18 16208.12 14243.98 17569.45 5381.90 10609.87 12762.00 8601.55 12583.13 9076.58 9134.88 8899.38 8285.81 10605.57 8041.19 8778.94 5470.79 5733.72 8264.37 5671.31 5845.89 5590.69 4265.47 8316.85 3247.56 3116.52 2937. 15393.57 17855.83 15112.13 15645.27 14422.30 14155.57 15489.51 13559.05 14537.25 12629.57 12000.20 12412.21 11712.02 11897.08 11202.97 9600.94 13136.97 4799.59 6889.54 8107.99 16.00% 1.83% 1.64% 6.31% 9.42% 4.21% 2.70% 10.78% 3.43% 2.40% 0.86% 6.64% 36.83% 50.01% 28.24% 15.55% Table 2. Pass@1 (%) and generation length on coding benchmarks for THINKROUTER and the baselines across different models. Pass@1 (%) Generation Length HumanEval MBPP Average HumanEval MBPP Average CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER 78.57 72.73 77.92 77.92 81.82 76.19 71.43 72.73 77.92 79.44 67.32 72.08 69.48 69.91 69.40 75.97 72.73 79.00 78.22 79. 5.84 0.65 0.65 3.25 4.76 3.46 1.73 3.25 4.76 2.16 2.60 2.08 3.25 3.03 2.25 3.25 74.22 71.26 72.87 72.06 75.57 94.06 89.07 91.50 94.60 94. 95.14 95.55 96.36 96.36 96.49 97.17 95.95 94.33 96.22 96.09 76.40 71.99 75.40 74.99 78.70 85.13 80.25 82.11 86.26 86.95 81.23 83.81 82.92 83.13 82.94 86.57 84.34 86.78 87.22 87. 2.97 1.35 2.16 1.35 4.99 2.56 0.54 0.40 0.40 1.21 1.21 1.35 1.21 2.83 0.94 0.92 Qwen3-1.7B 4.41 1.00 1.40 2. 4193.49 5894.18 3729.96 3878.50 4057.11 3901.11 5629.36 4036.15 4011.40 3913.83 4047.30 5761.77 3883.06 3944.95 3985.47 42.36% 4.06% 2.53% 1.53% Qwen3-8B 4.88 3.01 1.14 1. 4066.13 5900.47 3510.87 3823.40 3704.82 3412.00 4975.66 2894.60 3297.15 3162.93 3739.07 5438.06 3202.74 3560.28 3433.88 45.44% 14.34% 4.78% 8.16% Qwen3-32B 2.58 1.69 1.91 1. 3558.52 3662.56 3573.73 3582.90 3511.16 2623.08 2709.68 2419.82 2600.39 2521.86 3090.80 3186.12 2996.78 3091.65 3016.51 3.08% 3.04% 0.03% 2.40% gpt-oss-20b 2.23 0.21 0.65 0. 1054.40 1929.97 958.12 967.73 1017.05 895.63 1433.84 815.64 690.38 781.05 975.02 1681.90 886.88 829.06 899.05 72.50% 9.04% 14.97% 7.79% robust accuracy gains than the baselines. Generation Length Reduction THINKROUTER achieves competitive generation length reduction across all benchmarks and models compared with the baselines. Especially on STEM reasoning benchmarks, THINKROUTER reduces the average generation lengths relative to Soft Thinking by 6 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Table 3. Confusion-like matrix for analyzing calibration behavior in THINKROUTER. TN (Baseline correct THINKROUTER correct) Baseline - Correct Baseline - Incorrect TP (Baseline incorrect THINKROUTER correct) FP (Baseline correct THINKROUTER incorrect) FN (Baseline incorrect THINKROUTER incorrect) THINKROUTER - Correct THINKROUTER - Incorrect -4.56%, -6.86%, -4.35% on Qwen3-1.7B, 8B, 32B, respectively. On coding benchmarks, THINKROUTER exhibits comparable generation length reduction performance with Soft Thinking, consistently reducing generation length relative to CoT. Although Random Routing increases the average generation length in some settings, THINKROUTER always produce shorter outputs than CoT, demonstrating the significance of confidence awareness. 5.3. Error Calibration To better understand where the accuracy gains of THINKROUTER come from, we construct confusion-style matrix as shown in Table 3 to analyze the error calibration capability between the baselines and THINKROUTER. The matrix enumerates all possible combinations of calibration for two reasoning methods on the same samples. We use the following three metrics to measure the error calibration capability of THINKROUTER. Specifically, we use Recall as Fix Rate (= P +F ) to measure error coverage, which is the proportion of baseline errors that are successfully corrected by THINKROUTER. Precision (= P +F ) measures the reliability of calibrations without over-correction. F1 (= 2 PrecisionRecall Precision+Recall ) captures the balance between reliability and coverage. Meanwhile, we define the Error Reduction Rate (ERR = Errors (Baseline)Errors (THINKROUTER) ) quantifies the net proportion of errors eliminated compared with the baseline. We report these metrics in Figure 3. For each test instance, we run inference three times with different random seeds ({0, 7, 42}) and determine the final answers by majority voting (Wang et al., 2023). The results demonstrate that THINKROUTER consistently calibrate incorrect answers across different models and benchmarks. According to Fix Rate, up to 77.3% errors of the baselines are successfully corrected by THINKROUTER. The precision remains consistently high (up to 90.6%), showing that THINKROUTER avoids aggressive over-correction. More importantly, all ERR is 0, illustrating that THINKROUTER can consistently perform corrective calibration without net error amplification. Errors (Baseline) 5.4. Why THINKROUTER Improves Reasoning Performance LRM Confidence To demystify how THINKROUTER works and whether it follows our motivation mentioned in 3.2, we analyze the confidence dynamics as thinking progresses. The details are described in Appendix C.1. (a) Qwen3-8B. (b) gpt-oss-20b. Figure 3. Error calibration of THINKROUTER. Figure 4, 8, 9, and 10 show the ratios of low-confidence time steps for Soft Thinking (latent-only reasoning) and our confidence-aware routing. For Soft Thinking, as thinking progresses, LRMs assign higher pmax to incorrect solutions than correct ones, especially for the last period of thinking. This trend is similar to the observations in 3.2. Comparing THINKROUTER with Soft Thinking, we find that THINKROUTER consistently increases the ratios of low-confidence steps across different models and datasets, especially for the samples LRMs give incorrect answers to, which suggests that THINKROUTER prevents LRMs from prematurely collapsing into thinking with relatively high confidence. Furthermore, across all four figures, we observe that under THINKROUTER, the confidence trajectories of 7 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces (a) Soft Thinking (Latent-only Reasoning). (b) THINKROUTER. Figure 4. Low-confidence time step ratio (%) across generation steps on Qwen3-8B with GPQA Diamond. Figure 5. pmax of last 10 time steps before the end-of-thinking token for Qwen3-8B. correct and incorrect solutions become increasingly closer as generation progresses, compared to Soft Thinking. This indicates that confidence-aware routing stabilizes inferencetime confidence dynamics and mitigates the divergence of incorrect confidence trajectories from correct ones. Overall, by controlling LRM confidence dynamics through these two ways, THINKROUTER improves reasoning accuracy. Thinking Stop We explore why THINKROUTER can reduce the length of reasoning trajectories. We firstly count the thinking stop modes as shown in Table 9, which suggests that THINKROUTER substantially reduces the proportion of thinking courses that terminate via Cold Stop. Since Cold Stop is triggered under sustained overconfident token distributions (Figure 12), this shift indicates that THINKROUTER is effective at mitigating LRM confidence during thinking and promoting earlier, well-formed termination. For further understanding, we examine confidence evolution over the last ten steps preceding EOT token generation. Figure 5 and 11 show that EOT tokens are typically generated when the maximum next-token probability undergoes noticeable drop or remains relatively low. This suggests that THINKROUTER, by lowering and regularizing confidence across thinking, accelerates the conditions under which the EOT token becomes likely, thereby shortening the overall reasoning trajectory. Moreover, comparing samples with correct and incorrect answers reveals that incorrect samples generally exhibit longer reasoning trajectories than correct ones (Figure 13, 14). By improving reasoning accuracy and reducing the fraction of such error-prone trajectories, THINKROUTER further decreases the generation length. 5.5. Reasoning trajectory at Routing Times There are some examples of top-3 next-token probability distributions during thinking in Figures 15, 16, and 17. Inspecting large number of examples, we observe that the time steps when THINKROUTER routes thinking to the discrete space mostly correspond to thinking tokens with low confidence (Qian et al., 2025), which, for example, express i) transitions (e.g., then, but, alternatively), ii) execution (e.g., let, provide, verify, calculate), and iii) taskspecific symbolics (e.g., mathematical LaTeX notations like $ and , units like kcal and mo). According to Qian et al. (2025); Wang et al. (2025), these thinking tokens have mutual information peaks with the gold answers, which are critical to LRMs reasoning performance. THINKROUTER routes such critical time to the discrete token space, suggesting that THINKROUTER does not route thinking arbitrarily, but selectively intervenes at time steps that are both semantically decisive and structurally important for reasoning, thereby improving the reliability of thinking. 8 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces 6. Conclusion In this work, we propose THINKROUTER, an inferencetime mechanism for efficient reasoning that routes thinking between the discrete token space and the latent space based on LRM confidence. Extensive experiments across diverse LRMs and benchmarks demonstrate that THINKROUTER can robustly improve reasoning accuracy and reduce generation length, and highlight the significance of THINKROUTERs confidence awareness. Furthermore, we comprehensively analyze the underlying reasons for the effectiveness of THINKROUTER through LRM confidence dynamics. We observe that THINKROUTER can globally lower model confidence. THINKROUTER can calibrate errors arising from CoT and Soft Thinking and accelerate the trigger of end-of-thinking token generation. We hope our work can provide insights into efficient LRM reasoning and reasoning behaviors in the future."
        },
        {
            "title": "Impact Statement",
            "content": "LLM Usage Two-family open-sourced LLMs, Qwen3 and gpt-oss-20b, are used for experiments (details in Section 5.1 and Appendix B). GPT-4.1 serves as an LLM judge to help with the evaluation of STEM reasoning benchmarks. GPT-5.2 is used to polish the writing. This paper presents work whose goal is to advance the field of machine learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here."
        },
        {
            "title": "References",
            "content": "Agarwal, S., Ahmad, L., Ai, J., Altman, S., Applebaum, A., Arbus, E., Arora, R. K., Bai, Y., Baker, B., Bao, H., Barak, B., Bennett, A., Bertao, T., Brett, N., Brevdo, E., Brockman, G., Bubeck, S., Chang, C., Chen, K., Chen, M., Cheung, E., Clark, A., Cook, D., Dukhan, M., Dvorak, C., Fives, K., Fomenko, V., Garipov, T., Georgiev, K., Glaese, M., Gogineni, T., Goucher, A. P., Gross, L., Guzman, K. G., Hallman, J., Hehir, J., Heidecke, J., Helyar, A., Hu, H., Huet, R., Huh, J., Jain, S., Johnson, Z., Koch, C., Kofman, I., Kundel, D., Kwon, J., Kyrylov, V., Le, E. Y., Leclerc, G., Lennon, J. P., Lessans, S., Casado, M. L., Li, Y., Li, Z., Lin, J., Liss, J., Liu, L., Liu, J., Lu, K., Lu, C., Martinovic, Z., McCallum, L., McGrath, J., McKinney, S., McLaughlin, A., Mei, S., Mostovoy, S., Mu, T., Myles, G., Neitz, A., Nichol, A., Pachocki, J., Paino, A., Palmie, D., Pantuliano, A., Parascandolo, G., Park, J., Pathak, L., Paz, C., Peran, L., Pimenov, D., Pokrass, M., Proehl, E., Qiu, H., Raila, G., Raso, F., Ren, H., Richardson, K., Robinson, D., Rotsted, B., Salman, H., Sanjeev, S., Schwarzer, M., Sculley, D., Sikchi, H., Simon, K., Singhal, K., Song, Y., Stuckey, D., Sun, Z., Tillet, P., Toizer, S., Tsimpourlas, F., Vyas, N., Wallace, E., Wang, X., Wang, M., Watkins, O., Weil, K., Wendling, A., Whinnery, K., Whitney, C., Wong, H., Yang, L., Yang, Y., Yasunaga, M., Ying, K., Zaremba, W., Zhan, W., Zhang, C., Zhang, B., Zhang, E., and Zhao, S. gpt-oss120b & gpt-oss-20b model card. CoRR, abs/2508.10925, 2025. doi: 10.48550/ARXIV.2508.10925. URL https: //doi.org/10.48550/arXiv.2508.10925. Aggarwal, P. and Welleck, S. L1: controlling how long reasoning model thinks with reinforcement learning. CoRR, abs/2503.04697, 2025. doi: 10.48550/ARXIV. 2503.04697. URL https://doi.org/10.48550/arXiv. 2503.04697. AIME. American invitational mathematics examinahttps://artofproblemsolving.com/wiki/ tion. index.php/American_Invitational_Mathematics_ Examination. Anthropic. The claude 3 model family: Opus, sonnet, URL https://www-cdn.anthropic. haiku, 2024. com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/ Model_Card_Claude_3.pdf. Arora, S., Liang, Y., and Ma, T. simple but tough-to-beat baseline for sentence embeddings. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017. URL https:// openreview.net/forum?id=SyK00v5xx. Austin, J., Odena, A., Nye, M. I., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C. J., Terry, M., Le, Q. V., and Sutton, C. Program synthesis with large language models. CoRR, abs/2108.07732, 2021. URL https: //arxiv.org/abs/2108.07732. Bengio, S., Vinyals, O., Jaitly, N., and Shazeer, N. Scheduled sampling for sequence prediction with In Cortes, C., Lawrence, recurrent neural networks. N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pp. 11711179, 2015. URL https: //proceedings.neurips.cc/paper/2015/hash/ e995f98d56967d946471af29d7bf99f1-Abstract. html. Butt, N., Kwiatkowski, A., Labiad, I., Kempe, J., and Ollivier, Y. Soft tokens, hard truths. CoRR, abs/2509.19170, 2025. doi: 10.48550/ARXIV.2509.19170. URL https: //doi.org/10.48550/arXiv.2509.19170. Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., HerbertVoss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021. URL https://arxiv.org/abs/2107.03374. Chen, Q., Qin, L., Liu, J., Peng, D., Guan, J., Wang, P., Hu, M., Zhou, Y., Gao, T., and Che, W. Towards reasoning era: survey of long chain-of-thought for reasoning large language models. CoRR, abs/2503.09567, 2025a. doi: 10.48550/ARXIV.2503.09567. URL https://doi.org/ 10.48550/arXiv.2503.09567. Chen, X., Zhao, A., Xia, H., Lu, X., Wang, H., Chen, Y., Zhang, W., Wang, J., Li, W., and Shen, X. Reasoning beyond language: comprehensive survey on latent chain-of-thought reasoning. CoRR, abs/2505.16782, 2025b. doi: 10.48550/ARXIV.2505.16782. URL https: //doi.org/10.48550/arXiv.2505.16782. Cheng, J. and Durme, B. V. Compressed chain of thought: Efficient reasoning through dense represenCoRR, abs/2412.13171, 2024. doi: 10. tations. 48550/ARXIV.2412.13171. URL https://doi.org/10. 48550/arXiv.2412.13171. Cheng, X., Zeng, W., Dai, D., Chen, Q., Wang, B., Xie, Z., Huang, K., Yu, X., Hao, Z., Li, Y., Zhang, H., Zhang, H., Zhao, D., and Liang, W. Conditional memory via scalable lookup: new axis of sparsity for large language models. CoRR, abs/2601.07372, 2026. URL https: //arxiv.org/pdf/2601.07372. Chu, Z., Chen, J., Chen, Q., Yu, W., He, T., Wang, H., Peng, W., Liu, M., Qin, B., and Liu, T. Navigate through enigmatic labyrinth survey of chain of thought reasoning: Advances, frontiers and future. In Ku, L.-W., Martins, A., and Srikumar, V. (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 11731203, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.65. URL https://aclanthology.org/2024.acl-long.65/. Deng, Y., Prasad, K., Fernandez, R., Smolensky, P., Chaudhary, V., and Shieber, S. M. Implicit chain of thought reasoning via knowledge distillation. CoRR, abs/2311.01460, 2023. doi: 10.48550/ARXIV.2311.01460. URL https: //doi.org/10.48550/arXiv.2311.01460. Fan, A., Lewis, M., and Dauphin, Y. N. Hierarchical neural story generation. In Gurevych, I. and Miyao, Y. (eds.), Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers, pp. 889898. Association for Computational Linguistics, 2018. doi: 10.18653/V1/P18-1082. URL https://aclanthology.org/P18-1082/. Fang, G., Ma, X., and Wang, X. Thinkless: LLM learns when to think. CoRR, abs/2505.13379, 2025. doi: 10. 48550/ARXIV.2505.13379. URL https://doi.org/10. 48550/arXiv.2505.13379. Feng, G., Zhang, B., Gu, Y., Ye, H., He, D., and Wang, L. Towards revealing the mystery behind chain of thought: theoretical perspective. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S. (eds.), Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http: //papers.nips.cc/paper_files/paper/2023/hash/ dfc310e81992d2e4cedc09ac47eff13e-Abstract-Conference. html. Fu, Y., Wang, X., Tian, Y., and Zhao, J. Deep think with confidence. CoRR, abs/2508.15260, 2025. doi: 10.48550/ARXIV.2508.15260. URL https://doi.org/ 10.48550/arXiv.2508.15260. Gal, Y. and Ghahramani, Z. Dropout as bayesian approximation: Representing model uncertainty in deep learning. In Balcan, M. and Weinberger, K. Q. (eds.), Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, volume 48 of JMLR Workshop and Conference Proceedings, pp. 10501059. JMLR.org, 2016. URL http://proceedings.mlr.press/v48/gal16.html. Gozeten, H. A., Ildiz, M. E., Zhang, X., Harutyunyan, H., Rawat, A. S., and Oymak, S. Continuous chain of thought enables parallel exploration and reasoning. CoRR, abs/2505.23648, 2025. doi: 10.48550/ARXIV. 2505.23648. URL https://doi.org/10.48550/arXiv. 2505.23648. Guo, C., Pleiss, G., Sun, Y., and Weinberger, K. Q. On calibration of modern neural networks. In Precup, D. and Teh, Y. W. (eds.), Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pp. 13211330. THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces PMLR, 2017. URL http://proceedings.mlr.press/ v70/guo17a.html. Hao, S., Gu, Y., Ma, H., Hong, J. J., Wang, Z., Wang, D. Z., and Hu, Z. Reasoning with language model is planning with world model. In Bouamor, H., Pino, J., and Bali, K. (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pp. 81548173. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.EMNLP-MAIN.507. URL https: //doi.org/10.18653/v1/2023.emnlp-main.507. Hao, S., Sukhbaatar, S., Su, D., Li, X., Hu, Z., Weston, J., and Tian, Y. Training large language models to reason in continuous latent space. CoRR, abs/2412.06769, 2024. doi: 10.48550/ARXIV.2412.06769. URL https: //doi.org/10.48550/arXiv.2412.06769. Hendrycks, D. and Gimpel, K. baseline for detecting misclassified and out-of-distribution examples in In 5th International Conference on neural networks. Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017. URL https://openreview.net/ forum?id=Hkg4TI9xl. Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/ forum?id=rygGQyrFvH. Huang, J. and Chang, K. C.-C. Towards reasoning in large language models: survey. In Rogers, A., BoydGraber, J., and Okazaki, N. (eds.), Findings of the Association for Computational Linguistics: ACL 2023, pp. 10491065, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/ v1/2023.findings-acl.67. URL https://aclanthology. org/2023.findings-acl.67/. Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., and Liu, T. survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Trans. Inf. Syst., 43(2):42:142:55, 2025. doi: 10.1145/3703155. URL https://doi.org/10.1145/3703155. Jaech, A., Kalai, A., Lerer, A., Richardson, A., El-Kishky, A., Low, A., Helyar, A., Madry, A., Beutel, A., Carney, A., Iftimie, A., Karpenko, A., Passos, A. T., Neitz, A., Prokofiev, A., Wei, A., Tam, A., Bennett, A., Kumar, A., Saraiva, A., Vallone, A., Duberstein, A., Kondrich, A., Mishchenko, A., Applebaum, A., Jiang, A., Nair, A., Zoph, B., Ghorbani, B., Rossen, B., Sokolowsky, B., Barak, B., McGrew, B., Minaiev, B., Hao, B., Baker, B., Houghton, B., McKinzie, B., Eastman, B., Lugaresi, C., Bassin, C., Hudson, C., Li, C. M., de Bourcy, C., Voss, C., Shen, C., Zhang, C., Koch, C., Orsinger, C., Hesse, C., Fischer, C., Chan, C., Roberts, D., Kappler, D., Levy, D., Selsam, D., Dohan, D., Farhi, D., Mely, D., Robinson, D., Tsipras, D., Li, D., Oprica, D., Freeman, E., Zhang, E., Wong, E., Proehl, E., Cheung, E., Mitchell, E., Wallace, E., Ritter, E., Mays, E., Wang, F., Such, F. P., Raso, F., Leoni, F., Tsimpourlas, F., Song, F., von Lohmann, F., Sulit, F., Salmon, G., Parascandolo, G., Chabot, G., Zhao, G., Brockman, G., Leclerc, G., Salman, H., Bao, H., Sheng, H., Andrin, H., Bagherinezhad, H., Ren, H., Lightman, H., Chung, H. W., Kivlichan, I., OConnell, I., Osband, I., Gilaberte, I. C., and Akkaya, I. Openai o1 system card. CoRR, abs/2412.16720, 2024. doi: 10. 48550/ARXIV.2412.16720. URL https://doi.org/10. 48550/arXiv.2412.16720. Javaji, S. R., Gauri, B., and Zhu, Z. Another turn, better output? turn-wise analysis of iterative LLM prompting. CoRR, abs/2509.06770, 2025. doi: 10.48550/ARXIV. 2509.06770. URL https://doi.org/10.48550/arXiv. 2509.06770. Jiang, L., Wu, X., Huang, S., Dong, Q., Chi, Z., Dong, L., Zhang, X., Lv, T., Cui, L., and Wei, F. Think only when you need with large hybrid-reasoning models. CoRR, abs/2505.14631, 2025. doi: 10.48550/ARXIV. 2505.14631. URL https://doi.org/10.48550/arXiv. 2505.14631. Jiang, Z., Xu, F. F., Araki, J., and Neubig, G. How can we know what language models know. Trans. Assoc. Comput. Linguistics, 8:423438, 2020. doi: 10.1162/ TACL_A_00324. URL https://doi.org/10.1162/ tacl_a_00324. Jimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press, O., and Narasimhan, K. R. Swe-bench: Can language models resolve real-world github issues? In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/ forum?id=VTF8yNQM66. Kalai, A. T., Nachum, O., Vempala, S. S., and Zhang, CoRR, doi: 10.48550/ARXIV.2509. URL https://doi.org/10.48550/arXiv. E. Why language models hallucinate. abs/2509.04664, 2025. 04664. 2509.04664. Karan, A. and Du, Y. Reasoning with sampling: Your base model is smarter than you think. CoRR, abs/2510.14901, 2025. doi: 10.48550/ARXIV.2510.14901. URL https: //doi.org/10.48550/arXiv.2510.14901. THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Li, Z., Zhang, D., Zhang, M., Zhang, J., Liu, Z., Yao, Y., Xu, H., Zheng, J., Wang, P., Chen, X., Zhang, Y., Yin, F., Dong, J., Guo, Z., Song, L., and Liu, C. From system 1 to system 2: survey of reasoning large language models. CoRR, abs/2502.17419, 2025. doi: 10.48550/ARXIV. 2502.17419. URL https://doi.org/10.48550/arXiv. 2502.17419. Lim, S. H., Erichson, N. B., Hodgkinson, L., and Mahoney, M. W. Noisy recurrent neural networks. In Ranzato, M., Beygelzimer, A., Dauphin, Y. N., Liang, P., and Vaughan, J. W. (eds.), Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pp. 51245137, 2021. URL https: //proceedings.neurips.cc/paper/2021/hash/ 29301521774ff3cbd26652b2d5c95996-Abstract. html. Liu, Z., Zhang, Y., Li, P., Liu, Y., and Yang, D. Dynamic llmagent network: An llm-agent collaboration framework with agent team optimization. CoRR, abs/2310.02170, 2023. doi: 10.48550/ARXIV.2310.02170. URL https: //doi.org/10.48550/arXiv.2310.02170. Lu, H., Fang, G., Ma, X., Li, Q., and Wang, X. Mixreasoning: Switching modes to think. CoRR, abs/2510.06052, 2025a. doi: 10.48550/ARXIV.2510.06052. URL https: //arxiv.org/abs/2510.06052. Lu, H., Liu, Y., Xu, J., Nan, G., Yu, Y., Chen, Z., and Wang, K. Auditing meta-cognitive hallucinations in reasoning large language models. CoRR, abs/2505.13143, 2025b. doi: 10.48550/ARXIV.2505.13143. URL https://doi. org/10.48550/arXiv.2505.13143. Madaan, L., Didolkar, A., Gururangan, S., Quan, J., Silva, R., Salakhutdinov, R., Zaheer, M., Arora, S., and Goyal, A. Rethinking thinking tokens: Llms as improvement operators. CoRR, abs/2510.01123, 2025. doi: 10.48550/ARXIV.2510.01123. URL https://doi.org/ 10.48550/arXiv.2510.01123. Minh, N. N., Baker, A., Neo, C., Roush, A. G., Kirsch, A., and Shwartz-Ziv, R. Turning up the heat: Min-p samIn The pling for creative and coherent LLM outputs. Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. OpenReview.net, 2025. URL https://openreview. net/forum?id=FBkpCyujtS. Qian, C., Liu, D., Wen, H., Bai, Z., Liu, Y., and Shao, J. Demystifying reasoning dynamics with mutual information: Thinking tokens are information peaks in LLM reasoning. CoRR, abs/2506.02867, 2025. doi: 10.48550/ARXIV.2506.02867. URL https://doi.org/ 10.48550/arXiv.2506.02867. Qiao, S., Qiu, Z., Ren, B., Wang, X., Ru, X., Zhang, N., Chen, X., Jiang, Y., Xie, P., Huang, F., and Chen, H. Agentic knowledgeable self-awareness. In Che, W., Nabende, J., Shutova, E., and Pilehvar, M. T. (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1260112625, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-889176-251-0. doi: 10.18653/v1/2025.acl-long.619. URL https://aclanthology.org/2025.acl-long.619/. Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y., Dirani, J., Michael, J., and Bowman, S. R. GPQA: graduate-level google-proof q&a benchmark. CoRR, abs/2311.12022, 2023. doi: 10.48550/ARXIV. 2311.12022. URL https://doi.org/10.48550/arXiv. 2311.12022. Saunshi, N., Dikkala, N., Li, Z., Kumar, S., and Reddi, S. J. Reasoning with latent thoughts: On the power of looped transformers. In The Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. OpenReview.net, 2025. URL https://openreview.net/forum?id=din0lGfZFd. Schmidt, F. Generalization in generation: closer look at exposure bias. In Birch, A., Finch, A. M., Hayashi, H., Konstas, I., Luong, T., Neubig, G., Oda, Y., and Sudoh, K. (eds.), Proceedings of the 3rd Workshop on Neural Generation and Translation@EMNLP-IJCNLP 2019, Hong Kong, November 4, 2019, pp. 157167. Association for Computational Linguistics, 2019. doi: 10.18653/V1/D19-5616. URL https://doi.org/10. 18653/v1/D19-5616. Shannon, C. E. mathematical theory of communication. Bell Syst. Tech. J., 27(3):379423, 1948. doi: 10.1002/J. 1538-7305.1948.TB01338.X. URL https://doi.org/ 10.1002/j.1538-7305.1948.tb01338.x. Shen, Z., Yan, H., Zhang, L., Hu, Z., Du, Y., and He, Y. CODI: compressing chain-of-thought into continuous space via self-distillation. CoRR, abs/2502.21074, 2025. doi: 10.48550/ARXIV.2502.21074. URL https: //doi.org/10.48550/arXiv.2502.21074. Shi, D., Asi, A., Li, K., Yuan, X., Pan, L., Lee, W., and Xiao, W. Swireasoning: Switch-thinking in latent and explicit for pareto-superior reasoning llms. CoRR, abs/2510.05069, 2025. doi: 10.48550/ARXIV. 2510.05069. URL https://doi.org/10.48550/arXiv. 2510.05069. Tan, W., Li, J., Ju, J., Luo, Z., Luan, J., and Song, R. Think silently, think fast: Dynamic latent compression of LLM reasoning chains. CoRR, abs/2505.16552, 2025. doi: THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces 10.48550/ARXIV.2505.16552. URL https://doi.org/ 10.48550/arXiv.2505.16552. Team, G. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. CoRR, abs/2507.06261, 2025a. doi: 10.48550/ARXIV.2507.06261. URL https: //doi.org/10.48550/arXiv.2507.06261. Team, G. Gemma 3 technical report. CoRR, abs/2503.19786, 2025b. doi: 10.48550/ARXIV.2503.19786. URL https: //doi.org/10.48550/arXiv.2503.19786. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lample, G. Llama: Open and efficient foundation language models. CoRR, abs/2302.13971, 2023. doi: 10.48550/ARXIV.2302.13971. URL https://doi.org/ 10.48550/arXiv.2302.13971. Vashurin, R., Fadeeva, E., Vazhentsev, A., Rvanova, L., Vasilev, D., Tsvigun, A., Petrakov, S., Xing, R., Sadallah, A. B., Grishchenkov, K., Panchenko, A., Baldwin, T., Nakov, P., Panov, M., and Shelmanov, A. Benchmarking uncertainty quantification methods for large language models with lm-polygraph. Trans. Assoc. Comput. Linguistics, 13:220248, 2025. doi: 10.1162/TACL _A_00737. URL https://doi.org/10.1162/tacl_a_ 00737. Wan, X., Wang, W., Xu, W., Yin, W., Song, J., and Sun, M. Adapthink: Adaptive thinking preferences for reasoning language model. CoRR, abs/2506.18237, 2025. doi: 10.48550/ARXIV.2506.18237. URL https://doi.org/ 10.48550/arXiv.2506.18237. Wang, S., Yu, L., Gao, C., Zheng, C., Liu, S., Lu, R., Dang, K., Chen, X., Yang, J., Zhang, Z., Liu, Y., Yang, A., Zhao, A., Yue, Y., Song, S., Yu, B., Huang, G., and Lin, J. Beyond the 80/20 rule: High-entropy minority tokens drive effective reinforcement learning for LLM reasoning. CoRR, abs/2506.01939, 2025. doi: 10.48550/ARXIV. 2506.01939. URL https://doi.org/10.48550/arXiv. 2506.01939. Wang, X., Wei, J., Schuurmans, D., Le, Q. V., Chi, E. H., Narang, S., Chowdhery, A., and Zhou, D. Selfconsistency improves chain of thought reasoning in lanIn The Eleventh International Conferguage models. ence on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/forum?id=1PL1NIMMrw. Wang, Y., Ma, X., Zhang, G., Ni, Y., Chandra, A., Guo, S., Ren, W., Arulraj, A., He, X., Jiang, Z., Li, T., Ku, M., Wang, K., Zhuang, A., Fan, R., Yue, X., and Chen, W. Mmlu-pro: more robust and challenging In multi-task language understanding benchmark. Globersons, A., Mackey, L., Belgrave, D., Fan, A., Paquet, U., Tomczak, J. M., and Zhang, C. (eds.), Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024, 2024. URL http: //papers.nips.cc/paper_files/paper/2024/hash/ ad236edc564f3e3156e1b2feafb99a24-Abstract-Datasets_ and_Benchmarks_Track.html. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E. H., Le, Q. V., and Zhou, D. Chain-ofthought prompting elicits reasoning in large language models. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http: //papers.nips.cc/paper_files/paper/2022/hash/ 9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference. html. Wei, X., Liu, X., Zang, Y., Dong, X., Cao, Y., Wang, J., Qiu, X., and Lin, D. Sim-cot: Supervised implicit chain-of-thought. CoRR, abs/2509.20317, 2025. doi: 10.48550/ARXIV.2509.20317. URL https://doi.org/ 10.48550/arXiv.2509.20317. Wu, C., Lu, J., Ren, Z., Hu, G., Wu, Z., Dai, D., and Wu, H. Llms are single-threaded reasoners: Demystifying the working mechanism of soft thinking. CoRR, abs/2508.03440, 2025. doi: 10.48550/ARXIV. 2508.03440. URL https://doi.org/10.48550/arXiv. 2508.03440. Xu, F., Hao, Q., Zong, Z., Wang, J., Zhang, Y., Wang, J., Lan, X., Gong, J., Ouyang, T., Meng, F., Shao, C., Yan, Y., Yang, Q., Song, Y., Ren, S., Hu, X., Li, Y., Feng, J., Gao, C., and Li, Y. Towards large reasoning models: survey of reinforced reasoning with large language models. CoRR, abs/2501.09686, 2025a. doi: 10.48550/ARXIV.2501.09686. URL https://doi.org/ 10.48550/arXiv.2501.09686. Xu, Y., Guo, X., Zeng, Z., and Miao, C. SoftCoT: Soft chainof-thought for efficient reasoning with LLMs. In Che, W., Nabende, J., Shutova, E., and Pilehvar, M. T. (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2333623351, Vienna, Austria, July 2025b. Association for Computational Linguistics. ISBN 979-8-89176251-0. doi: 10.18653/v1/2025.acl-long.1137. URL https://aclanthology.org/2025.acl-long.1137/. 13 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Xu, Z., Wang, H., Bespalov, D., Wu, X., Stone, P., and Qi, Y. LaRS: Latent reasoning skills for chain-of-thought reasoning. In Al-Onaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 36243643, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024. findings-emnlp.206. URL https://aclanthology. org/2024.findings-emnlp.206/. Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang, C., Lv, C., Zheng, C., Liu, D., Zhou, F., Huang, F., Hu, F., Ge, H., Wei, H., Lin, H., Tang, J., Yang, J., Tu, J., Zhang, J., Yang, J., Yang, J., Zhou, J., Lin, J., Dang, K., Bao, K., Yang, K., Yu, L., Deng, L., Li, M., Xue, M., Li, M., Zhang, P., Wang, P., Zhu, Q., Men, R., Gao, R., Liu, S., Luo, S., Li, T., Tang, T., Yin, W., Ren, X., Wang, X., Zhang, X., Ren, X., Fan, Y., Su, Y., Zhang, Y., Zhang, Y., Wan, Y., Liu, Y., Wang, Z., Cui, Z., Zhang, Z., Zhou, Z., and Qiu, Z. Qwen3 technical report. CoRR, abs/2505.09388, 2025a. doi: 10.48550/ARXIV.2505.09388. URL https://doi.org/ 10.48550/arXiv.2505.09388. Yang, L., Yu, Z., Cui, B., and Wang, M. Reasonflux: Hierarchical LLM reasoning via scaling thought templates. CoRR, abs/2502.06772, 2025b. doi: 10.48550/ARXIV. 2502.06772. URL https://doi.org/10.48550/arXiv. 2502.06772. Yang, Z., Dai, Z., Salakhutdinov, R., and Cohen, W. W. Breaking the softmax bottleneck: high-rank RNN In 6th International Conference on language model. Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018. URL https:// openreview.net/forum?id=HkwZSG-CZ. Yue, Z., Jin, B., Zeng, H., Zhuang, H., Qin, Z., Yoon, J., Shang, L., Han, J., and Wang, D. Hybrid latent reasoning via reinforcement learning. CoRR, abs/2505.18454, 2025. doi: 10.48550/ARXIV.2505.18454. URL https://doi. org/10.48550/arXiv.2505.18454. Zhang, J., Lin, N., Hou, L., Feng, L., and Li, J. AdaptThink: Reasoning models can learn when to think. In Christodoulopoulos, C., Chakraborty, T., Rose, C., and Peng, V. (eds.), Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pp. 37163730, Suzhou, China, November 2025a. Association for Computational Linguistics. ISBN 979-889176-332-6. doi: 10.18653/v1/2025.emnlp-main.184. URL https://aclanthology.org/2025.emnlp-main. 184/. Zhang, J., Zhu, Y., Sun, M., Luo, Y., Qiao, S., Du, L., Zheng, D., Chen, H., and Zhang, N. LightThinker: Thinking 14 step-by-step compression. In Christodoulopoulos, C., Chakraborty, T., Rose, C., and Peng, V. (eds.), Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pp. 1331813339, Suzhou, China, November 2025b. Association for Computational Linguistics. ISBN 979-8-89176-332-6. doi: 10.18653/v1/ 2025.emnlp-main.673. URL https://aclanthology. org/2025.emnlp-main.673/. Zhang, Z., He, X., Yan, W., Shen, A., Zhao, C., Wang, S., Shen, Y., and Wang, X. E. Soft thinking: Unlocking the reasoning potential of llms in continuous concept space. CoRR, abs/2505.15778, 2025c. doi: 10.48550/ARXIV. 2505.15778. URL https://doi.org/10.48550/arXiv. 2505.15778. Zheng, L., Yin, L., Xie, Z., Sun, C., Huang, J., Yu, C. H., Cao, S., Kozyrakis, C., Stoica, I., Gonzalez, J. E., Barrett, C. W., and Sheng, Y. Sglang: Efficient execution of structured language model programs. In Globersons, A., Mackey, L., Belgrave, D., Fan, A., Paquet, U., Tomczak, J. M., and Zhang, C. (eds.), Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024, 2024. URL http: //papers.nips.cc/paper_files/paper/2024/hash/ 724be4472168f31ba1c9ac630f15dec8-Abstract-Conference. html. Zhu, H., Hao, S., Hu, Z., Jiao, J., Russell, S., and Tian, Y. Reasoning by superposition: theoretical perspective on chain of continuous thought. CoRR, abs/2505.12514, 2025a. doi: 10.48550/ARXIV.2505.12514. URL https: //doi.org/10.48550/arXiv.2505.12514. Zhu, R., Peng, T., Cheng, T., Qu, X., Huang, J., Zhu, D., Wang, H., Xue, K., Zhang, X., Shan, Y., Cai, T., Kergan, T., Kembay, A., Smith, A., Lin, C., Nguyen, B., Pan, Y., Chou, Y., Cai, Z., Wu, Z., Zhao, Y., Liu, T., Yang, J., Zhou, W., Zheng, C., Li, C., Zhou, Y., Li, Z., Zhang, Z., Liu, J., Zhang, G., Huang, W., and Eshraghian, J. survey on latent reasoning. CoRR, abs/2507.06203, 2025b. doi: 10.48550/ARXIV.2507.06203. URL https: //doi.org/10.48550/arXiv.2507.06203. Zhu, R., Wang, Z., Hua, K., Zhang, T., Li, Z., Que, H., Wei, B., Wen, Z., Yin, F., Xing, H., Li, L., Shi, J., Ma, K., Li, S., Kergan, T., Smith, A., Qu, X., Hui, M., Wu, B., Min, Q., Huang, H., Zhou, X., Ye, W., Liu, J., Yang, J., Shi, Y., Lin, C., Zhao, E., Cai, T., Zhang, G., Huang, W., Bengio, Y., and Eshraghian, J. Scaling latent reasoning via looped language models. CoRR, abs/2510.25741, 2025c. doi: 10.48550/ARXIV.2510.25741. URL https: //doi.org/10.48550/arXiv.2510.25741. THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces A. Preliminary Experiments Figure 6. Ratio of low-confidence time steps of HumanEval within reasoning trajectories under latent-only reasoning (Soft Thinking). One time step is classified as low-confidence time step if the maximum next-token probability pmax is lower than τ . Figure 6 shows the ratio of low-confidence time steps in reasoning trajectories evaluated on HumanEval. We follow the same setting in 5.1. For each LRM, we run each sample in each dataset three times. We record the next-token distribution at every time step for all three runs, and use the collected next-token distributions from all three runs to construct Figures 1 and 6. Specifically, let denote the set of maximum next-token probabilities from all thinking time steps ending in correct answers, and denote such set for incorrect ones. The ratio of low-confidence time steps for correct samples is 1 t < τ ]. The ratio of low-confidence time steps for correct samples is 1 < τ ]. I[pmax I[pmax (cid:80) pmax (cid:80) pmax B. Main Experiments B.1. More Details in THINKROUTER Algorithm SAMPLE This is renormalization filtering with the sampling strategies, which uses the same sampling parameters of CoT (sampling) in Table 5. MULTINOMIALSAMPLE Following Soft Thinking, we use multinomial sampling with torch.multinomial1 if thinking performs in discrete token space. COLDSTOP We use Cold Stop from Soft Thinking to stop intermediate thinking when the model becomes continuously overconfident. At each time step t, we compute the entropy of the next-token probability over the vocabulary: H(pt) = (cid:88) vV pt[v] log pt[v] (8) Low entropy suggests that the model is of high confidence in its prediction (Shannon, 1948). If H(pt) is lower than an entropy threshold δ, low-entropy step counter increases; otherwise, the counter is reset. When the counter reaches consecutive confident steps, the end-of-thinking token is inserted to stop thinking, and then final answer generation begins. COLDSTOP is applied for THINKROUTER, Random Routing, and Soft Thinking in this work. DECODE After thinking, the LRMs perform the standard autoregressive decoding in discrete token space with the official sampling strategy in Table 5. B.2. Datasets To comprehensively evaluate THINKROUTER, three STEM reasoning benchmarks and two coding benchmarks are used, spanning different domains and scales to assess robustness and generality. STEM Reasoning Benchmarks AIME 2024 and AIME 2025 are challenging mathematical reasoning benchmarks derived from the American Invitational Mathematics Examination (AIME), prestigious U.S. mathematics competition. 1https://docs.pytorch.org/docs/stable/generated/torch.multinomial.html THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Each AIME exam consists of 15 problems requiring an exact integer answer between 000 and 999, with no partial credit, emphasizing precise multi-step reasoning. Due to their high difficulty and strict answer format, AIME 2024 and AIME 2025 are widely adopted to evaluate advanced mathematical reasoning (Fu et al., 2025; Yang et al., 2025b; Madaan et al., 2025). GPQA Diamond (Rein et al., 2023) is the most challenging subset of the GPQA benchmark, consisting of graduate-level, Google-proof multiple-choice questions that require deep domain knowledge (STEM) and multi-step reasoning, and is widely used to stress-test the reasoning robustness of large language models (Team, 2025b). Coding Benchmarks HumanEval (Chen et al., 2021) is widely used code generation benchmark consisting of handwritten Python programming problems that require function-level reasoning and exact-match execution correctness (Karan & Du, 2025; Cheng et al., 2026; Liu et al., 2023). MBPP (Mostly Basic Programming Problems) is also code generation benchmark composed of short Python programming tasks with natural language descriptions and test cases, designed to evaluate basic algorithmic reasoning and functional correctness of large language models (Touvron et al., 2023). The number of samples in each dataset is shown in Table 4. The datasets and the implementation of the evaluation in our experiments follow https://github.com/eric-ai-lab/Soft-Thinking/tree/main. Table 4. The statistic distributions of the datasets. Dataset # Sample AIME 2024 AIME 2025 GPQA Diamond HumanEval MBPP 30 30 198 164 257 B.3. Baselines and Hyper-parameters CoT (sampling) This is standard decoding baseline only in the discrete token space with chain-of-thought thinking and sampling strategies, including top-k (Fan et al., 2018), top-p (Holtzman et al., 2020), and min-p (Minh et al., 2025). We use the official sampling strategies of Qwen3-8B2 and gpt-oss-20b3 for the CoT (sampling) baseline. The specific sampling parameters are shown in Table 5. Table 5. The sampling parameters. Temperature Top-k Top-p Min-p Max output length Qwen3-8B gpt-oss-20b 0.6 1.0 20 20 0.95 1.00 0.0 0. 32,768 32,768 CoT (greedy) This is standard decoding baseline only in the discrete token space with chain-of-thought thinking and greedy decoding. Soft Thinking We use the official code4 to conduct Soft Thinking. Soft Thinking introduce four hyper-parameters: top-j (Equation 3), entropy threshold δ, and maximum consecutive confident step l. Corresponding to the Soft Thinking paper (Zhang et al., 2025c), grid search over these parameters would require evaluating 5 4 4 configurations per model per dataset, leading to substantial computational overhead. Since latent-space reasoning implementation in THINKROUTER directly follows Soft Thinking, the comparison between THINKROUTER and Soft Thinking primarily aims to isolate the effect of confidence-aware hybrid-space reasoning versus latent-only reasoning, rather than to exhaustively optimize Soft Thinking itself. Therefore, hyperparameter tuning for Soft Thinking is not necessary. Instead, we directly adopt the hyperparameter configuration from the official GitHub codebase and apply it uniformly across all models and datasets, 2https://huggingface.co/Qwen/Qwen3-8B 3https://github.com/openai/gpt-oss 4https://github.com/eric-ai-lab/Soft-Thinking/tree/main 16 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces i.e., = 10, δ = 0.01, = 256 without hyperparameter tuning. After thinking, the sampling strategies for generating final answers are same as CoT (sampling). Random Routing For each step during thinking, we uniformly sample binary routing decision from {0, 1} using torch.randint5 to choose between latent space and discrete token space. B.4. THINKROUTER Implementation with Soft Thinking Figure 7. Impact of the routing thresholds τ and random seeds on performance. To facilitate reproduction, in this section we describe in detail the implementation of THINKROUTER. THINKROUTER is implemented on top of Soft Thinking, using SGLang (Zheng et al., 2024) as the inference backend and NVIDIA H100 80GB GPUs. As shown in Figure 7, performance varies primarily with the routing threshold τ . Although different random seeds introduce stochastic fluctuations, the overall performance trend with respect to τ remains consistent. According to this observation, we perform grid search over τ to select the optimal routing threshold, and use multiple random seeds solely to perform repeated runs and average out randomness, reducing the impact of chance outcomes from single run. Three random seeds {0, 7, 42} are used. For each modeldataset pair, we run inference three times with these three seeds, and report Pass@1 with = 3 generations per sample. All hyperparameters except for τ are provided in Appendix B.3 and the scripts in our public codebase after review. To obtain the optimal τ , we randomly sample 10 instances from each model-benchmark pair as small validation set. We perform grid search over τ {0.4, 0.5, 0.6, 0.7, 0.8, 0.9} and compute Pass@1 on these 10 samples. The value of τ that achieves the highest Pass@1 and the shortest generation length is selected as the optimal τ for that model-benchmark pair. Finally, we evaluate THINKROUTER on the remaining test samples of the benchmark on the model, excluding the 10 validation instances, and report Pass@1 and generation length in Table 1 and 2 (τ used in Table 1 and 2 are shown in Table 6.) This protocol ensures that τ selection does not leak test information while keeping the overall procedure lightweight and easy to reproduce. The evaluation implementation follows Soft Thinking, which uses Math-Verify6 and GPT-4.1 for STEM reasoning, and the official code evaluations from the coding benchmarks. Table 6. τ used in Table 1, 2, 7, and 8. τ AIME 2024 AIME 2025 GPQA Diamond HumanEval MBPP Qwen3-1.7B Qwen3-8B Qwen3-32B gpt-oss-20b 0.4 0.8 0.7 0.5 0.9 0.7 0.4 0.9 0.5 0.5 0.5 0. 0.6 0.9 0.5 0.4 0.7 0.9 0.6 0.4 5https://docs.pytorch.org/docs/stable/generated/torch.randint.html 6https://github.com/huggingface/Math-Verify 17 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces B.5. Main Results on Whole Datasets Table 7 and Table 8 report THINKROUTERs performance on the original all samples in each benchmark to ensure the robustness of our evaluation. We observe that for STEM reasoning benchmarks, THINKROUTER outperforms all of the baselines on Pass@1, and has the shortest generation length in most cases. For coding benchmarks, THINKROUTER has the highest Pass@1 accuracy in most cases, even when Soft Thinking drops the accuracy compared with CoT (sampling). Meanwhile, THINKROUTER exhibits competitive performance on reducing generation length with Soft Thinking. All the findings are the same as those concluded from Table 1 and 2 in Section 5.2. Table 7. Pass@1 (%) and generation length on all data from STEM reasoning benchmarks for THINKROUTER and the baselines across different models. AIME 2024 AIME 2025 GPQA Diamond Average AIME 2024 AIME 2025 GPQA Diamond Average Pass@1 (%) Generation Length CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER 45.56 58.89 52.22 55.56 67.78 75.56 81.11 84.44 87.78 88.89 78.89 83.33 91.11 88.89 92.22 82.22 76.67 76.67 93.33 94. 13.33 6.67 10.00 22.22 5.56 8.89 12.22 13.33 4.44 12.22 10.00 13.33 5.56 5.56 11.11 12.22 33.33 37.78 56.67 46.67 62.22 74.44 81.11 80.00 83.33 83. 80.00 77.78 83.33 85.56 92.22 80.00 75.56 73.33 84.44 92.22 4.44 23.33 13.33 28.89 6.67 5.56 8.89 8.89 2.22 3.33 5.56 12.22 4.44 6.67 4.44 12. 38.98 26.86 43.29 44.00 49.50 62.70 63.76 68.63 69.53 82.10 75.56 70.52 75.25 80.12 82.10 72.79 71.23 72.39 73.50 79.98 12.13 4.30 5.01 10.52 1.06 5.93 6.83 19. 5.04 0.31 4.56 6.55 1.56 0.40 0.71 7.19 Qwen3-1.7B 1.88 11.43 9.45 20.54 17954.63 19101.63 17516.83 17255.43 16222.60 Qwen3-8B 4.43 6.79 9.31 13.88 14686.38 16443.03 13823.70 15131.58 14406.19 Qwen3-32B 0.94 5.08 6.71 10.70 12528.44 12681.27 12882.30 11704.17 12291.54 gpt-oss-20b 3.85 4.21 5.42 10.54 9718.70 12557.50 5592.63 6588.63 8269.57 39.29 41.17 50.72 48.74 59.83 70.90 75.33 77.69 80.21 84.77 78.15 77.21 83.23 84.85 88.85 78.34 74.48 74.13 83.76 88. 17684.26 19577.00 16333.40 18237.87 16576.42 18062.92 17630.60 16973.40 17674.14 17497.14 15532.58 14135.13 15011.17 15350.50 11994.26 12224.48 5215.20 15671.90 9076.46 11308.31 8928.78 12877.72 9300.22 9331.43 9196.06 9007.57 11508.81 9015.03 9080.94 8128. 5546.56 8127.01 5278.91 6174.77 5475.92 3471.98 6151.36 2557.33 2571.38 3288.05 14855.89 17185.45 14383.48 14941.58 13998.36 13918.96 15194.15 13270.71 13962.22 13344.04 11202.53 11647.80 11057.46 11076.48 9920.57 8471.72 7974.69 7940.62 6078.82 7621. 15.68% 3.18% 0.58% 5.77% 9.16% 4.66% 0.31% 4.13% 3.97% 1.29% 1.13% 11.44% 5.87% 6.27% 28.25% 10.03% C. Further Analysis We follow the same setting in 5.1. For each LRM, we run each sample in each dataset three times. We record the next-token distribution at every time step for all three runs, and use the collected next-token distributions across all runs to construct all figures in this section. C.1. Low-confidence Steps as Thinking Progresses Since different samples have varying generation lengths, we normalize each samples reasoning trajectory to relative positions and discretize it into 100 bins. For each bin b, we collect all time steps whose relative positions fall within it < τ ] and incorrect samples and calculate the ratio of low-confidence time steps for both correct (cid:80) I[pmax 1 S(b) correct tS(b) correct I[pmax < τ ], where S(b) incorrect and S(b) incorrect denote the sets of time steps from correct and incorrect samples 1 S(b) incorrect (cid:80) tS(b) incorrect falling into bin b, respectively. Figure 4, 8, 9, and 10 show the ratios of low-confidence time steps for Qwen3-8B and gpt-oss-20b evaluated on GPQA Diamond and HumanEval. C.2. Thinking Stops Table 9 compare the thinking stop modes of Soft thinking and THINKROUTER, which illustrates that THINKROUTER can help trigger EOT token generation in most cases. Figure 11 and 12 show the maximum next-token probabilities of the last 18 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Table 8. Pass@1 (%) and generation length on all data from coding benchmarks for THINKROUTERand the baselines across different models. Pass@1 (%) Generation Length HumanEval MBPP Average HumanEval MBPP Average CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER CoT (sampling) CoT (greedy) Soft Thinking Random Routing THINKROUTER 81.27 81.82 81.95 83.06 84.55 76.35 74.29 81.82 81.95 82.07 71.54 78.05 66.32 69.94 75.15 86.15 81.82 86.15 80.59 86. 0.55 0.68 1.79 3.28 2.06 5.47 5.60 5.72 6.51 5.22 1.60 3.61 4.33 0.00 5.56 0.14 79.48 70.84 71.92 71.38 79.51 96.04 92.71 94.33 96.30 96. 96.76 97.03 97.57 97.57 97.66 98.11 97.30 96.22 97.48 98.83 80.38 76.33 76.93 77.22 82.03 86.20 83.50 88.08 89.12 89.19 84.15 87.54 81.95 83.76 86.41 92.13 89.56 91.18 89.04 92. 8.65 7.57 8.11 0.03 3.33 1.71 0.26 0.27 0.27 0.81 0.81 0.90 0.81 1.89 0.63 0.72 Qwen3-1.7B 4.05 3.44 3.16 1. 3853.75 4917.32 3045.71 3548.99 3531.70 3716.10 5727.78 3889.74 3799.67 3652.33 3784.93 5322.55 3467.72 3674.33 3592.01 40.62% 8.38% 2.92% 0.05% Qwen3-8B 2.70 1.88 2.93 2. 3951.80 5559.28 3029.38 3480.59 3445.92 2986.37 3994.14 2609.40 2917.61 2840.10 3469.08 4776.71 2819.39 3199.10 3143.01 37.69% 18.73% 7.78% 9.40% Qwen3-32B 3.39 2.21 0.40 2. 2998.65 3046.14 2922.66 3062.56 2944.79 2291.46 2342.95 2178.35 2313.64 2287.75 2645.06 2694.55 2550.50 2688.10 2616.27 1.87% 3.57% 1.63% 1.09% gpt-oss-20b 2.57 0.94 3.09 0. 842.35 1481.55 842.35 852.17 859.45 739.92 1069.33 659.69 595.03 648.43 791.13 1275.44 751.02 723.60 753.94 61.22% 5.07% 8.54% 4.70% 10 time steps before the EOT token and Cold Stop. Figure 13 and 14 show the generation length distributions. We can find that incorrect predictions generally have longer outputs than correct predictions. Table 9. Comparisons of thinking stop modes. EOT: End-of-thinking. Qwen3-8B gpt-oss-20b GPQA Diamond HumanEval GPQA Diamond HumanEval Latent-only Reasoning (Soft Thinking) EOT Token Cold Stop Reached Maximum Output Length 79.6% 20.4% 0.0% 89.6% 10.4% 0.0% THINKROUTER EOT Token Cold Stop Reached Maximum Output Length 98.8% 1.2% 0.0% 93.9% 6.1% 0.0% 98.5% 0.0% 1.5% 99.2% 0.1% 0.7% 100.0% 0.0% 0.0% 100.0% 0.0% 0.0% C.3. Probability Distributions at Routing Times Here are some examples to show the top-3 next-token probability in pt along 100 time steps during thinking in Figure 15, 16, 17, and 18. THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces (a) Latent-only Reasoning (Soft Thinking). (b) THINKROUTER. Figure 8. Low-confidence time step ratio (%) across generation steps on Qwen3-8B with HumanEval. (a) Latent-only Reasoning (Soft Thinking). (b) THINKROUTER. Figure 9. Low-confidence time step ratio (%) across generation steps on gpt-oss-20b with GPQA Diamond. (a) Latent-only Reasoning (Soft Thinking). (b) THINKROUTER. Figure 10. Low-confidence time step ratio (%) across generation steps on gpt-oss-20b with HumanEval. 20 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Figure 11. pmax of last 10 time steps before the end-of-thinking token. Figure 12. pmax of last 10 time steps before Cold Stop for Qwen3-8B. 21 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Figure 13. Distributions of the generation lengths for Qwen3-8B. Figure 14. Distributions of the generation lengths for gptoss. 22 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Figure 15. pt of Qwen3-8B on GPQA Diamond with THINKROUTER (τ =0.9). Red boxes indicate routing thinking to the discrete token space; otherwise, to the latent space. Figure 16. pt of Qwen3-8B on HumanEval with THINKROUTER (τ =0.6). Red boxes indicate routing thinking to the discrete token space; otherwise, to the latent space. 23 THINKROUTER: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces Figure 17. pt of gpt-oss-20b on GPQA Diamond with THINKROUTER (τ =0.9). Red boxes indicate routing thinking to the discrete token space; otherwise, to the latent space. Figure 18. pt of gpt-oss-20b on HumanEval with THINKROUTER (τ =0.7). Red boxes indicate routing thinking to the discrete token space; otherwise, to the latent space."
        }
    ],
    "affiliations": [
        "Adobe Research",
        "UC San Diego"
    ]
}