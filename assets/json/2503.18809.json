{
    "paper_title": "Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code",
    "authors": [
        "Augusto B. Corrêa",
        "André G. Pereira",
        "Jendrik Seipp"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "In recent years, large language models (LLMs) have shown remarkable capabilities in various artificial intelligence problems. However, they fail to plan reliably, even when prompted with a detailed definition of the planning task. Attempts to improve their planning capabilities, such as chain-of-thought prompting, fine-tuning, and explicit \"reasoning\" still yield incorrect plans and usually fail to generalize to larger tasks. In this paper, we show how to use LLMs to generate correct plans, even for out-of-distribution tasks of increasing size. For a given planning domain, we ask an LLM to generate several domain-dependent heuristic functions in the form of Python code, evaluate them on a set of training tasks within a greedy best-first search, and choose the strongest one. The resulting LLM-generated heuristics solve many more unseen test tasks than state-of-the-art domain-independent heuristics for classical planning. They are even competitive with the strongest learning algorithm for domain-dependent planning. These findings are especially remarkable given that our proof-of-concept implementation is based on an unoptimized Python planner and the baselines all build upon highly optimized C++ code. In some domains, the LLM-generated heuristics expand fewer states than the baselines, revealing that they are not only efficiently computable, but sometimes even more informative than the state-of-the-art heuristics. Overall, our results show that sampling a set of planning heuristic function programs can significantly improve the planning capabilities of LLMs."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 2 ] . [ 1 9 0 8 8 1 . 3 0 5 2 : r Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code Augusto B. Corrêa University of Oxford United Kingdom André G. Pereira Federal University of Rio Grande do Sul Brazil Jendrik Seipp Linköping University Sweden"
        },
        {
            "title": "Abstract",
            "content": "In recent years, large language models (LLMs) have shown remarkable capabilities in various artiﬁcial intelligence problems. However, they fail to plan reliably, even when prompted with detailed deﬁnition of the planning task. Attempts to improve their planning capabilities, such as chain-of-thought prompting, ﬁne-tuning, and explicit reasoning still yield incorrect plans and usually In this paper, we show how to use LLMs to fail to generalize to larger tasks. generate correct plans, even for out-of-distribution tasks of increasing size. For given planning domain, we ask an LLM to generate several domain-dependent heuristic functions in the form of Python code, evaluate them on set of training tasks within greedy best-ﬁrst search, and choose the strongest one. The resulting LLM-generated heuristics solve many more unseen test tasks than state-of-the-art domain-independent heuristics for classical planning. They are even competitive with the strongest learning algorithm for domain-dependent planning. These ﬁndings are especially remarkable given that our proof-of-concept implementation is based on an unoptimized Python planner and the baselines all build upon highly optimized C++ code. In some domains, the LLM-generated heuristics expand fewer states than the baselines, revealing that they are not only efﬁciently computable, but sometimes even more informative than the state-of-the-art heuristics. Overall, our results show that sampling set of planning heuristic function programs can signiﬁcantly improve the planning capabilities of LLMs."
        },
        {
            "title": "1 Introduction",
            "content": "Classical planning is fundamental problem in Artiﬁcial Intelligence (AI), with applications ranging from robotics to game playing [27]. Given the initial state of the world, description of the goal, and set of deterministic actions that can be executed in fully-observable environment, the task is to ﬁnd sequence of actions that transforms the initial state into state that satisﬁes the goal. Nowadays, most classical planners rely on heuristic search algorithms to ﬁnd plans [6, 41, 38, 56, 47, 78, 69]. The efﬁciency of these planners depends on the quality of the heuristic functions used to guide the search. Traditionally, these heuristics have been either domainindependent, offering generality at the expense of accuracy, manually crafted for speciﬁc domains, requiring signiﬁcant human effort and expertise, or learned on domain basis, adding costs and costing resources whenever we want to use new domain. Recent advances in large language models (LLMs) created new ways for automating different aspects of software development and AI tools. In the context of classical planning, LLMs have been used, for example, to plan directly [e.g., 81], to create planning models from natural language [e.g., 32, 26, 50], to compute generalized policies [71], and to create heuristics for numeric planning [80]. In this work, we use LLMs to automatically generate domain-dependent heuristic functions for classical planningplanning with fully-observable states, deterministic actions, discrete state variables. Problem Prompt instructions; PDDL ﬁles; examples from other domains; planner API; data structures; checklist"
        },
        {
            "title": "LLM",
            "content": "Heuristic h1 Heuristic h2 . . ."
        },
        {
            "title": "Training Set\nof PDDL Tasks",
            "content": "Selected Heuristic (e.g., h3) Step 1: Generation Generate multiple candidate heuristic functions Step 2: Evaluation Run GBFS with each candidate heuristic on set of training tasks Step 3: Selection Select best heuristic based on performance on the training set Figure 1: Our pipeline for generating domain-dependent heuristics with LLMs: we prompt the LLM times to generate candidate heuristics, evaluate each of these heuristics on set of training tasks and choose the strongest one. Our hypothesis is that LLMs, given sufﬁcient context and examples, can generate heuristic functions that outperform generic domain-independent heuristics. Our overall pipeline is much simpler than previous work: we simply pass to an LLM the domain description, example planning tasks, example domain-dependent heuristics for other domains, and the relevant planner API. Then we request that the LLM generates heuristic for the given domain. We speciﬁcally request that the LLM generates the code, in Python, to compute the heuristic. We execute the same prompt times to obtain pool of candidate heuristics, evaluate each of them on training set, and select the best one. Figure 1 shows the overall pipeline. This discards the necessity of back-and-forth communication between the planner and the LLM, making the overall procedure straightforward. This idea is similar to what has been done by AlphaCode [45] in the context of code generation, and to parallel sampling [7] for test-time compute [72, 44]. In contrast to the work by Tuisov et al. [80], we do not need to generate heuristics for each task we want to solve. Our approach generates constant number of heuristics per domain, and then use the selected heuristic for any new task of this domain. This amortizes the costs for the LLMs inference, allowing us to save both computational resources and potential API calls. We implement our pipeline on top of Pyperplan [1] as proof of concept, and then evaluate the generated heuristics on the domains of the Learning Track of the International Planning Competition (IPC) 2023. The LLM-generated heuristics outperform state-of-the-art heuristics, such as hFF [41], in terms of solved tasks and are competitive in the number of required state expansions. Despite Pyperplan being much slower compared to state-of-the-art planners [38, 47, 66] due to its Python implementation, our method outperforms hFF also in the standard C++ implementations available in Fast Downward [38]. This is an impressive result, as this implementation is cornerstone of most of the state-of-the-art planners in the literature."
        },
        {
            "title": "2 Background",
            "content": "We consider classical planning, where single agent applies deterministic actions in fullyobservable, discrete environment. Classical planning tasks are usually described using the Planning Domain Deﬁnition Language (PDDL) [49, 36]. To understand our contributions, an informal description of fragment of PDDL is sufﬁcient, and we introduce it alongside examples from simple Logistics domain. PDDL task consists of set of objects (e.g., representing vehicles, boxes and locations); set of predicates representing relations between these objects (e.g., using the at predicate, the ground atom (at car1 city2) represents that object car1 is at city2); set of actions that change the relations (e.g., driving car changes its location); an initial state which is set of ground atoms (e.g., where all boxes and vehicles are initially and which locations are connected) and goal description that lists the ground atoms that must hold at the end of plan (e.g., the desired locations of all boxes). Applying an action changes the current state of the environment by removing or adding ground atoms. The objective of planner is to ﬁnd sequence of actions, called plan, that leads from the initial state to state where all goal atoms hold. 2 PDDL tasks are commonly separated into domain and an task part, where the domain part holds the common actions and predicates, while the task part describes the speciﬁc objects, initial state and the goal. The two parts are typically represented as two separate ﬁles. Most planners nowadays use state-space search to ﬁnd plan. The search is usually guided by heuristic function which maps each state to an estimate h(s) R+ 0 that estimates the cost of reaching the goal state from [53]. In heuristic search algorithmssuch as [35], weightedA [54], and greedy best-ﬁrst search [17]this heuristic guides the search towards promising states and thereby reduces the search effort. The performance of planner is heavily inﬂuenced by the accuracy and computational efﬁciency of the heuristic function. In our work, we assume that all actions have unit cost and we consider satisﬁcing planning, where any plan is acceptable, irrespective of its length. We focus on planners that use greedy best-ﬁrst search (GBFS). While there are lots of search improvements that one could evaluate on top of GBFS [e.g., 41, 47, 55, 58], we limit ourselves to pure GBFS planners as this is the most commonly used version in the classical planning literature [e.g., 16, 23, 40]. However, extending our approach to other search algorithms or techniques on top of GBFS is certainly interesting for future work. We use setup similar to the Learning Track of the International Planning Competition (IPC), where each planner is given domain and set of training tasks from this domain. The planner then uses the training tasks to learn domain-general knowledge that helps to solve new tasks from the same domain. Among other options, this knowledge can take the form of policies [e.g., 25, 75], heuristics [e.g., 73, 11], sketches [e.g., 18, 19], planning programs [e.g., 64, 65], or planner conﬁgurations [e.g., 20, 67]. After the training period (usually maximum of 24 hours), the planner must solve set of unseen test tasks from the same domain that are out-of-distribution of the training tasks."
        },
        {
            "title": "3 Proposed Pipeline",
            "content": "In our pipeline, we give as input to the LLM the PDDL description of our target domain together with some additional information (described below). Then we ask the LLM for domain-dependent heuristic function for the given domain, implemented in Python, which we then inject into the Pyperplan planner [1]. We chose Python because LLMs generate correct code for Python more often than for other languages [45], and because the code injection is simpler in Python due to its ﬂexibility and due to it being an interpreted language. However, we hypothesize that asking for single function is too weak. Instead, we send identical requests to the LLM with the same prompt, collect all returned heuristic functions h1, . . . , hn, and then evaluate them on the training tasks. We automatically select the best heuristic hbest {h1, . . . , hn} and declare it as our ﬁnal heuristic (see below for details on this selection). Figure 1 shows the graphical representation of our method. One potential issue of this approach is that the heuristic functions h1, . . . , hn might be too similar. If all heuristics are similar, then there is little value in querying the LLM so many times. To diversify the pool of heuristics, we increase the temperature parameter of the models. Temperature is often related to the creativity of the model, as it allows for more randomness in the token generation and thus more diversity in the answers. In exploratory experiments, we observed that temperatures above 1.0 tend to improve the results. However, very high temperatures (e.g., 2.0) give less consistent results, despite sometimes yielding the best overall performances. Therefore, we set the temperature to 1.0 in our experiments. This is similar to what Brown et al. [7] report, and in their case, some problems required even larger temperature. To emulate the latest Learning Track setup as closely as possible, we use the IPC 2023 domains and tasks for training and testing. We used disjoint set of ten domains from the Autoscale benchmark set [79] for exploratory experiments while developing our pipeline. This split allowed us to test different prompts, hyperparameters, and models without the risk of overﬁtting to the IPC 2023 benchmark set or causing some LLM APIs to cache our prompts. common issue when using LLMs for planning is that they produce invalid plans [82, 83]. In contrast, our pipeline ensures that all found plans are valid: the underlying search algorithm in Pyperplan only produce correct solutions and the heuristic created by the LLM only inﬂuences how efﬁciently such solution is found."
        },
        {
            "title": "Prompt",
            "content": "Our prompt contains series of input ﬁles that provide context for the LLM. For given domain D, we ask the LLM to create heuristic H. The prompt ﬁrst gives the following instructions: You are highly-skilled professor in AI planning and proﬁcient Python programmer creating domain-dependent heuristic function for the PDDL domain D. The heuristic function you create will be used to guide greedy best-ﬁrst search to solve instances from this domain. Therefore, the heuristic does not need to be admissible. For given state, the heuristic function should estimate the required number of actions to reach goal state as accurately as possible, while remaining efﬁciently computable. The name of the heuristic should be H. The heuristic should minimize the number of expanded nodes during the search. Next, you will receive sequence of ﬁle contents to help you with your task and to show you the deﬁnition of domain D. We then include the following ﬁle contents to the prompt: 1. the PDDL domain ﬁle of domain 2. the smallest PDDL instance of domain in the training set 3. the largest PDDL instance of domain in the training set 4. the PDDL domain ﬁle of the Gripper domain [49] 5. PDDL instance ﬁle of the Gripper domain 6. domain-dependent heuristic for Gripper implemented in Python 7. the PDDL domain ﬁle of the Logistics domain [49] 8. PDDL instance ﬁle of the Logistics domain 9. domain-dependent heuristic for Logistics implemented in Python 10. an example of how each state of domain is represented in Pyperplan 11. an example of how the static information of domain is represented in Pyperplan 12. the Python code from Pyperplan for representing planning task and an action 13. checklist of common pitfalls Items 1, 2, and 3 provide the context about the domain that we are interested in. Providing two examples hits sweet spot because giving only one task sometimes led the LLM to infer wrong patterns about object names and the format of the goal in exploratory experiments. Providing more than two instances needlessly increases the size of the prompt. Items 49 illustrate what domain-dependent heuristics can look like for two example domains [49]. For Gripper, we provide Python function computing the perfect heuristic as input, while for Logistics we encode the simple single visit and load/unload counting heuristic by Paul et al. [52]. These functions show the LLM what heuristic could do, and also illustrate how to manipulate the available data. We include items 1012 to give more context about Pyperplan. Items 10 and 11 are, essentially, what we see when calling print function for state or the static information of task.1 This minimizes the amount of access and data manipulation errors by the LLM. Last, the checklist consists of tips based on our own observations of the LLM responses: (a) The code for extracting objects from facts remembers to ignore the surrounding brackets. (b) The heuristic is 0 only for goal states. (c) The heuristic value is ﬁnite for solvable states. 1Static information refers to all ground atoms that are never modiﬁed by any actionand hence they are static. Planners, including Pyperplan, usually discard static atoms after grounding because they are not needed for domain-independent search algorithms. However, they can be important for domain-dependent search algorithms, such as the ones we obtain with our pipeline. 4 (d) All used modules are imported. (e) The information from static facts is extracted into suitable data structures in the constructor. (f) Provide detailed docstring explaining the heuristic calculation. For this, divide the docstring into sections Summary, Assumptions, Heuristic Initialization and Step-ByStep Thinking for Computing Heuristic. Tips (a), (b), (c), (d), and (e) are self-explanatory and help to avoid common errorse.g., not being aware that an atom in Pyperplan is encoded as (pred obj1 obj2). The ﬁnal tip, (f), directs the LLM to chain-of-thought reasoning."
        },
        {
            "title": "Finding Strong Heuristics",
            "content": "In our approach, we prompt the model times with the input above to generate heuristics. We then run the different heuristics with GBFS on the training set to select the best one. To make the selection quick, we evaluate each heuristic on the training set using 5 minutes time limit per task. The ﬁnal remaining question is how to select the best heuristic. We go with simple approach: we pick the heuristic that solves the largest number of tasks from the training set. If there is tie, we choose the one minimizing the accumulated agile score over the training set. The agile score is common metric from IPCs. The score of heuristic for given task is based on the time the GBFS takes to ﬁnd plan. If the search needs less than 1 second, then the score is 1. If the search runs out of time (in our case, 300 seconds) the score is 0. Intermediate values are interpolated with the logarithmic function 1 log(t) log(300) , where is the run time (in seconds) of the search. The accumulated score is the sum over all training tasks."
        },
        {
            "title": "4 Experimental Results",
            "content": "For running our ﬁnal experiments, we use Downward Lab [68] on AMD EPYC 7742 processors running at 2.25 GHz. We simulate the same setting as the IPC Learning Track 2023: the training phase may use at most 24 hours and 32 GiB per domain, while each planner run on each test task is limited to 30 minutes and 8 GiB. We stick to the same limits, but since the LLMs we use require much more memory, we cannot enforce the memory limit for the training phase. As mentioned, we use Pyperplan [1] for all our conﬁgurations. This allows us to evaluate the different heuristics (domain-independent and LLM-generated ones) in one single framework. We use PyPy 7.3.9 to run Pyperplan, as it proved to be slightly faster than CPython. We use the domains and training/test tasks from the IPC 2023 Learning Track to generate and evaluate heuristics. However, since Pyperplan does not support two of these ten domainsFerry and Satellite, we exclude them from our experiments. The ﬁnal set has 99 training and 90 test tasks for each of the 8 domains. The distribution of tasks in the training and test sets differs: the test tasks are generally much larger than the training ones. In Blocksworld, for example, the largest training task contains 29 blocks, while the largest test task has 488 blocks. Similarly, for Sokoban, the largest training task has 4 boxes in maze measuring 1313, while the largest test task has 79 boxes in maze measuring 9999. In addition to size differences, tasks may also vary in structure. For example, Sokoban mazes can be arranged in different layouts. The full details about the task sets can be found online [63]."
        },
        {
            "title": "Generating Heuristics",
            "content": "In our pipeline, we prompt the LLM times and receive different heuristic functions. But how large should be? We ran pre-training experiment to verify this. We use Gemini 2.0 Flash (stable release 001) in this experiment. Figure 2 shows the average number of solved tasks (the so-called coverage) when increases from 1 to 25. For all domains, the biggest increase in average coverage results from going from 1 to 5 heuristics and after that, we see diminishing returns. However, Childsnack and Transport still beneﬁt from generating 25 instead of 20 heuristics. There are two domains, Childsnack and 5 Gemini 2."
        },
        {
            "title": "Flash",
            "content": "Flash Think. V3 R1 Dist. R1 Estimated Cost (USD) Cost per Heuristic (USD) Cost per Domain (USD) Failure Rate (% heuristics) $0.70 $0.00350 $0.08750 22.0% 12.5% $0.25 $0.00125 $0.03125 14.0% 64.5% $6.12 $0.03060 $0.76500 8.5% Table 1: Cost and failure rate for each LLM variant. Each LLM generates 200 heuristics (25 heuristics for each of the 8 domains). R1 Dist. is the distillation of R1 to Qwen 14B. Since Gemini 2.0 Flash Thinking (Flash Think.) is only available in the free tier API, and R1 Dist. can be run locally but not through the paid API, we do not estimate their prices. We consider generated heuristic failure if it crashes for all training tasks and we do not re-generate such heuristics. a v 80 60"
        },
        {
            "title": "Blocksworld\nChildsnack\nFloortile\nMiconic\nRovers\nSokoban\nSpanner\nTransport",
            "content": "5 10 15"
        },
        {
            "title": "Candidate Heuristics",
            "content": "Figure 2: Average coverage per number of candidate heuristics per domain. Floortile, where the average coverage has not stagnated or hit the limit of 99 tasks for = 25. We tried increasing the number of generated heuristics to 100 for these two domains, but this did not help much. So to reduce computational costs, we generate only 25 heuristics for each of the 8 domains. To generate the heuristics, we use the APIs from two different families of LLMs: Gemini [29, 30], with the models Gemini 2.0 Flash (stable release 001) and Gemini 2.0 Flash Thinking (version 0121); and DeepSeek [14, 15], with the models DeepSeek V3, DeepSeek R1 Distill Qwen 14B, and DeepSeek R1. We include the distilled version to Qwen 14B [3] to evaluate the impact of smaller models in our pipeline. The two Gemini models generate all heuristics for domain in bit over 5 minutes. The DeepSeek models, however, require between 5 to 7 hours per domain. Table 1 shows the estimated cost and failure rate for each model. Our approach is cheaper than the one by Tuisov et al. [80] because their method generates multiple heuristics per task, which increases the costs proportionally to the number of tasks. In our pipeline, however, the costs depend on the number of domains only, which is usually much smaller. As result, all experiments for this paper taken together only cost $7 US. Regarding failure rates, i.e., the percentage of heuristics that crash for all training tasks, the reasoning models (Gemini 2.0 Flash Thinking and DeepSeek R1) are the most robust. The distilled version of DeepSeek R1 has by far the highest failure rate. This is expected, as this model is much smaller than all other models tested. In our experiments, we did not replace the failed candidates, but for future work, it would be interesting to analyze how the performance changes when replacing such heuristics. Selected LLM-Generated Heuristics To illustrate the heuristic functions generated by DeepSeek R1, we brieﬂy discuss the selected heuristic functions for the Blocksworld and Spanner domains, shown in Appendix A. In Blocksworld, stacks of blocks must be rearranged from an initial state to goal condition. The available actions move blocks that are on top of stack onto different stack or the table. In the Spanner domain,"
        },
        {
            "title": "Domain",
            "content": "Blocksworld (90) Childsnack (90) Floortile (90) Miconic (90) Rovers (90) Sokoban (90) Spanner (90) Transport (90) h0 6 9 1 30 12 24 30 8 Gemini 2."
        },
        {
            "title": "DeepSeek",
            "content": "hFF"
        },
        {
            "title": "Flash",
            "content": "Flash Think. V3 R1 Dist. R1 24 17 10 74 28 31 30 29 35 32 4 90 32 31 30 42 37 14 8 88 39 32 30 37 32 4 74 32 30 30 44 34 16 3 30 32 24 30 45 66 22 4 90 32 30 70 59 Sum (720) 120 296 305 283 214 373 Table 2: Coverage of GBFS within Pyperplan using the blind heuristic h0, hFFand our LLMgenerated heuristics. an agent must move through corridor, pick up spanners, and tighten nuts at the gate, using each picked-up spanner at most once. The agent can move in the direction of the gate but not backwards. Thus, moving without ﬁrst picking up required spanner, results in an unsolvable state. Both domains admit polynomial solving strategies: Blocksworld is 2-approximable [33] (by destroying all stacks and then building the goal stacks) and even optimal Spanner plans can be computed in polynomial time (by picking up exactly the ﬁrst spanners). However, these are not the strategies the LLM uses to implement the heuristic function. The heuristic selected for Blocksworld computes for each block mentioned in the goal condition whether is misplaced and, if so, adds 2 to the heuristic value for each block on top of A, plus 1. For this, the heuristic uses an auxiliary function that traverses the stack on top of A. It is easy to see that this heuristic can overestimate the optimal plan length. For Spanner, the heuristic greedily assigns to each loose nut in ﬁxed order, the closest spanner still available. If the spanner has already been picked up, the cost of tightening the nut is the distance from the agent to the nut location plus 1. If not, then the cost is the distance from the agent to the location of the spanner plus the distance from the location of the spanner to the location of the nut plus 2. Each spanner can be used at most once, so if nut has no assigned spanner, the heuristic adds large number to the cost of the state. The heuristic performs breadth-ﬁrst search during the initialization phase to compute the shortest path between all locations. This heuristic can also overestimate the optimal plan length. Arguably, the LLM could have created simpler heuristic if the implicit assumptions of the domain were explicit [31]: the PDDL domain allows for arbitrary connections between locations, but all instances assume one-way corridor. Comparison to Domain-Independent Heuristics in Pyperplan We now compare the LLM-generated heuristics to two baselines: breadth-ﬁrst search (BrFS), which uses no heuristic guidance,2 and GBFS with the hFF heuristic [41], which is one of the most commonly used heuristics for satisﬁcing planning [e.g., 8, 13, 28]. These two baselines are also implemented in Pyperplan, which allows us to evaluate exactly the impact of the generated heuristics. All other Pyperplan ﬁles have not been changed; the only change is the automatic inclusion of the LLMgenerated heuristic. Therefore, the heuristics are evaluated using the exact same code framework. Table 2 shows the coverage (i.e., number of solved tasks) per method for each of the eight domains in our test set. As we can see, all LLM-generated heuristics outperform hFF regarding total coverage, except for the distilled version of DeepSeek R1. In almost all cases, the other LLM-generated heuristics are even preferable to hFF on per-domain basis. DeepSeek R1 heuristics have the highest coverage with 373 solved tasks. Gemini 2.0 Flash Thinking solves 68 fewer tasks (total 305), while the best baseline hFF solves only 234 tasks. DeepSeek R1 2This is identical to running GBFS with the blind heuristic h0, where h0(s) = 0 iff is goal state and h0(s) = 1 otherwise. 7 ) 1 e e ( 1 300 200 100 0 uns. 105"
        },
        {
            "title": "Blocksworld\nChildsnack\nFloortile\nMiconic\nRovers\nSokoban\nSpanner\nTransport",
            "content": "0 100 200 300 101 105 107 uns. hFF (a) Plan length. hFF (b) Expansions. Figure 3: Comparison of plan length and expansions for hFF and the heuristics generated by DeepSeek R1. We only show plan lengths up to 300. heuristics are particularly impressive in the Blocksworld and Spanner domains. In Blocksworld, the R1 heuristic solves almost twice as many tasks as the second best conﬁguration (Gemini 2.0 Flash Thinking); in Spanner the R1 heuristic solves more than twice as many tasks as all other conﬁgurations. As expected, the non-thinking modelsGemini 2.0 Flash and DeepSeek V3perform worse than their thinking counterparts. But this does not hold in every domain. In Childsnack, for example, both non-thinking models solve more tasks than their thinking counterparts. DeepSeek R1 Distill Qwen 14B heuristics are the only LLM-based models that underperform in comparison to hFF. This is expected, as this model already had high failure rate to begin with  (Table 1)  . However, this is mostly due its low coverage in the Miconic domain. In fact, DeepSeek R1 Distill Qwen 14B outperformed hFF in 3 domains, while being outperformed in 4. This shows that the smaller distilled models might be competitive with existing heuristics in some domains, while having the advantage of being more affordable than the original ones. Figure 3a compares the plan lengths obtained with hFF and the heuristics generated by DeepSeek R1. We show only plan lengths up to 300, as only Miconic has plans longer than that. In general, the two methods yield plans with similar lengths. The only domains where one approach has clear edge are Blocksworld, where the DeepSeek R1 plans are consistently shorter, and Miconic, where DeepSeek R1 plans get longer than hFF as the tasks get larger. Interestingly, DeepSeek R1 still achiever higher coverage than hFF in Miconic. In our experiments, hFF never ﬁnds plans that are longer than 800 steps, while DeepSeek R1 ﬁnds multiple plans with up to 1 500 steps (not shown in Figure 3a). Last, we compare the informativeness of the traditional and the LLM-generated heuristics by inspecting the number of expansions the resulting searches need. Ideally, heuristic only expands states traversed by plan. Figure 3b compares expansions between hFF and DeepSeek R1 heuristics. The results vary by domain: DeepSeek R1 has an edge in Blocksworld, Spanner, Transport and in most of the Childsnack tasks, whereas hFF is more informed in Floortile, Rovers and Sokoban. In all the domains where DeepSeek R1 expands fewer states than hFF, it also solves many more tasks than hFF. On the ﬂip side, the only domain where hFF expands fewer states and solves many more tasks than DeepSeek R1 is Floortile. In the Rovers domain, DeepSeek R1 has higher coverage than hFF, while in Sokoban hFF solves only two more tasks. This indicates that despite being less informed in these two domains, the heuristics generated by DeepSeek R1 perform better because they are more efﬁcient to compute. Comparison to State-of-the-Art Heuristics Implemented in C++ Our experimental setup has an obvious ﬂaw: we are using Pyperplan, which is an educational, unoptimized Python planner, while all state-of-the-art planners are implemented in compiled languages such as C++. For example, the winners of all tracks of the last IPC, in 2023, are implemented in C++ [77]. Moreover, all of these planners are implemented on top of the Fast Downward planning system 8 Fast Downward (C++)"
        },
        {
            "title": "Domain",
            "content": "hGC hlmc hFF hcea hcg hadd Blocksworld (90) Childsnack (90) Floortile (90) Miconic (90) Rovers (90) Sokoban (90) Spanner (90) Transport (90) 32 23 3 90 38 42 30 36 39 13 3 90 41 43 30 36 27 25 12 90 34 36 30 41 40 29 10 79 36 33 30 49 34 29 7 90 39 35 30 44 29 14 90 33 33"
        },
        {
            "title": "Pyperplan",
            "content": "hFF hR1 24 17 10 74 28 31 30 29 66 22 4 90 32 30 70 59 hWLF GPR 72 31 2 90 37 38 73 28 Sum (720) 294 295 295 306 318 371 243 373 Table 3: Coverage for different heuristics implemented in Fast Downward, and in Pyperplan. Heuristic hR1 indicates the heuristics generated by DeepSeek R1. [38]. Even though Python runs much slower than C++ and uses more memory, we compare our best method, GBFS in Pyperplan using DeepSeek R1 heuristics, to GBFS in Fast Downward using one of the many satisﬁcing heuristics implemented in the planner: the goal-count heuristic, hGC [24]; the landmark count heuristic, hlmc [57, 9]; the C++ implementation of the FF heuristic, hFF [41]; the context-enhanced additive heuristic, hcea [39]; the causal graph heuristic, hcg [37]; and the additive heuristic, hadd [6]. We also compare it to hWLF GPR [11], which uses statistical learning methods together with the Weisfeiler-Leman algorithm to learn domain-dependent heuristics, and is considered the state-of-the-art in classical planning for heuristic learning. hWLF GPR is also implemented on top of Fast Downward. We denote the heuristics generated by DeepSeek R1 as hR1 from now on. Table 3 shows that GBFS in Pyperplan with hR1 solves more tasks in total than any of the traditional Fast Downward heuristics. It is also competitive with the state-of-the-art, hWLF GPR , and achieves slightly higher total coverage. This is quite an unexpected result, as Pyperplan is not as engineered and receives little attention and maintenance compared to Fast Downward. It indicates that the heuristics generated by DeepSeek R1 are indeed powerful, being capable of surpassing the performance gap between Python and C++ implementations."
        },
        {
            "title": "5 Related Work",
            "content": "The combination of planning and learning to create heuristic functions has long tradition [62, 12, 61, 2]. There are two main paradigms for learning heuristic functions in classical planning: task-dependent [21, 22, 51, 4] and domain-dependent [70, 74, 10, 34]. In this paper, we consider the second paradigm. Currently, the strongest approach in domain-dependent heuristic learning is hWLF GPR [11], which we compare to above. Recently, LLMs entered the picture. Yet, Valmeekam et al. [81] show that LLMs cannot reliably solve even small classical planning tasks when used for end-to-end plan generation. Moreover, techniques such as supervised ﬁne-tuning and chain-of-thought fail to generalize to out-of-distribution tasks [5, 76], and even LLMs explicitly designed for reasoning tasks cannot solve typical planning problems [83]. Nonetheless, Rossetti et al. [60] show that GPT model trained from scratch on solved planning tasks from ﬁxed domain can achieve competitive performance compared to other learning approaches when training and test sets share the same distribution. Additionally, Huang et al. [42] use reinforcement learning with partial rewards to increase the LLM performance in end-to-end plan generation. Furthermore, LLMs can also help to solve classical planning tasks when combined with other techniques. For example, there is an extensive body of work exploring the potential of LLMs to convert problems described in natural language into PDDL tasks [e.g., 32, 26, 50, 48]. The most closely related approaches to ours are those that use LLMs to generate code for solving planning tasks. Katz et al. [43] highlight the high computational cost of using LLMs for end-to-end 9 plan generation, particularly when multiple inferences are required. To address this issue, they propose domain-dependent approach in which an LLM generates Python code for two key operations: successor generation and goal testing. These functions are then integrated into standard search algorithms, such as breadth-ﬁrst, implemented in Python. When the successor generator and goal test are correct, their method is sound and complete while simultaneously being more computationally efﬁcient than direct LLM-based planning. However, their approach has two key limitations. First, human feedback is required when the generated functions are incorrect. Second, because they rely on uninformed search algorithms, their method is limited to solving only small planning tasks. Our approach could address this second limitation by providing heuristic function for an informed search algorithm to improve its scalability. Silver et al. [71] also use LLMs to generate Python code for solving classical planning tasks. However, they focus on generalized planning, where the aim is to ﬁnd strategy that can efﬁciently solve any task of given domain. In their approach, an LLM generates simple Python program that does not rely on search. The key distinction between their approach and ours is that they address different problems. There are many planning domains, such as the Sokoban domain we use above, for which no simple strategy exists to efﬁciently produce plans. For such domains, heuristic functions can be useful. The work by Tuisov et al. [80] is the most similar to ours, and we draw inspiration from their work. They also use LLMs to generate heuristic function code for automated planning. Instead of addressing classical planning, though, their focus is on numeric planning. Moreover, they generate their heuristics via three-step prompting process: domain summarization and heuristic conceptualization; heuristic implementation; and heuristic reﬁnement for speciﬁc planning task. Our approach differs from theirs in three main regards. First, they require manual translation of each PDDL domain into Rust, including the implementation of successor generator and goal test. The cost of translating domains to Rust prevents easy comparisons on all IPC domains. In contrast, our approach generates heuristics directly from the PDDL description with the resulting code integrated into an off-the-shelf planner. Second, their heuristics are task-dependent rather than domain-dependent. While task-dependent heuristics may be more informed, they require LLM inferences for each new task. In contrast, our approach generates heuristic for an entire domain, enabling reuse across multiple tasks without additional LLM queries, and thus reducing costs. Finally, while their approach outperforms all domain-independent heuristics they compare against, their LLM-generated heuristics result in fewer expansions than the baseline domain-independent heuristics for only single task. This suggests that while their heuristics may be computationally faster, they are not necessarily more informative. In our experiments, the LLM-generated heuristics are often more informative than the traditional domain-independent ones. Outside the area of PDDL planning, Romera-Paredes et al. [59] use search in function space to help to solve combinatorial problems. Their algorithm, FunSearch, samples different initial programs, similar to our set of candidate heuristics. However, FunSearch feeds the best initial candidates back into the LLM to improve them. Another recent approach is the one by Ling et al. [46], where an LLM generates set of candidate heuristics which are then evaluated on training set and the best heuristics is returned to the LLM for reﬁnement. In contrast, our pipeline never feeds the Python functions back into the LLM. Although our results are already positive, this feedback loop could further strengthen our results."
        },
        {
            "title": "6 Conclusions",
            "content": "In this paper, we show how to use LLMs to generate domain-dependent heuristics for classical planning domains. Our approach uses LLMs to produce pool of candidate heuristics, which we then evaluate on training set in order to choose the best heuristic from the pool. The selected heuristic is then used for unseen tasks. We provide proof-of-concept implementation of this pipeline in Pyperplan, an educational classical planner written in Python. Comparing the Python-based heuristics, we see that our LLM-generated heuristics outperform state-of-the-art domain-independent heuristic in most of the domains of our benchmark set. In particular, large reasoning models such as DeepSeek R1 show signiﬁcant improvement compared to the domain-independent heuristic. 10 We show that Pyperplan equipped with the heuristics from DeepSeek R1 (hR1) surpasses commonly used heuristics implemented in Fast Downward [38], state-of-the-art planner written in C++. Moreover, hR1 is also competitive with hWLF GPR [11], the state-of-the-art in heuristic learning for classical planning implemented on top of Fast Downward. These results are surprising, as Pyperplan is much less optimized than Fast Downward, and DeepSeek R1 is not trained on speciﬁc domains, while hWLF GPR is. Taken together, our results demonstrate the growing potential of LLM-generated heuristics in classical planning."
        },
        {
            "title": "Acknowledgments",
            "content": "We thank Malte Helmert for giving us access to the cluster of the AI group at the University of Basel. Jendrik Seipp was supported by the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation. André G. Pereira acknowledges support from FAPERGS with project 21/2551-0000741-9. This study was ﬁnanced in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior Brasil (CAPES) Finance Code 001."
        },
        {
            "title": "References",
            "content": "[1] Yusra Alkhazraji, Matthias Frorath, Markus Grützner, Malte Helmert, Thomas Liebetraut, Robert Mattmüller, Manuela Ortlieb, Jendrik Seipp, Tobias Springenberg, Philip Stahl, and Jan Wülﬁng. Pyperplan. https://doi.org/10.5281/zenodo.3700819, 2020. [2] Shahab J. Arfaee, Sandra Zilles, and Robert C. Holte. Learning heuristic functions for large state spaces. Artiﬁcial Intelligence, 175:20752098, 2011. [3] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report. arXiv:2309.16609 [cs.CL], 2023. [4] Rafael Bettker, Pedro Minini, André Pereira, and Marcus Ritt. Understanding sample generation strategies for learning heuristic functions in classical planning. Journal of Artiﬁcial Intelligence Research, 80:243271, 2024. [5] Bernd Bohnet, Azade Nova, Aaron Parisi, Kevin Swersky, Katayoon Goshvadi, Hanjun Dai, Dale Schuurmans, Noah Fiedel, and Hanie Sedghi. Exploring and benchmarking the planning capabilities of large language models. arXiv:2406.13094 [cs.CL], 2024. [6] Blai Bonet and Héctor Geffner. Planning as heuristic search. Artiﬁcial Intelligence, 129(1): 533, 2001. [7] Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher Ré, and Azalia Mirhoseini. Large language monkeys: Scaling inference compute with repeated sampling. arXiv:2407.21787 [cs.LG], 2024. [8] Clemens Büchner, Remo Christen, Augusto B. Corrêa, Salomé Eriksson, Patrick Ferber, Jendrik Seipp, and Silvan Sievers. Fast Downward Stone Soup 2023. In IPC-10 Planner Abstracts, 2023. [9] Clemens Büchner, Salomé Eriksson, Thomas Keller, and Malte Helmert. Landmark progression in heuristic search. In Proc. ICAPS 2023, pages 7079, 2023. [10] Dillon Z. Chen, Sylvie Thiébaux, and Felipe Trevizan. Learning domain-independent heuristics for grounded and lifted planning. In Proc. AAAI 2024, pages 2007820086, 2024. [11] Dillon Z. Chen, Felipe Trevizan, and Sylvie Thiébaux. Return to tradition: Learning reliable heuristics with classical machine learning. In Proc. ICAPS 2024, pages 6876, 2024. 11 [12] Jens Christensen and Richard Korf. uniﬁed theory of heuristic evaluation functions and its application to learning. In Proc. AAAI 1986, pages 148152, 1986. [13] Augusto B. Corrêa, Guillem Francès, Markus Hecher, Davide Mario Longo, and Jendrik Seipp. Scorpion Maidu: Width search in the Scorpion planning system. In IPC-10 Planner Abstracts, 2023. [14] DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J.L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, and Jingchang Chen et al. Deepseek-V3 technical report. arXiv:2412.19437 [cs.CL], 2024. [15] DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z.F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, and Guanting Chen et al. Deepseek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning. arXiv:2501.12948 [cs.CL], 2025. [16] Carmel Domshlak, Jörg Hoffmann, and Michael Katz. Red-black planning: new systematic approach to partial delete relaxation. Artiﬁcial Intelligence, 221:73114, 2015. [17] James E. Doran and Donald Michie. Experiments with the graph traverser program. Proceedings of the Royal Society A, 294:235259, 1966. [18] Dominik Drexler, Jendrik Seipp, and Hector Geffner. Learning sketches for decomposing planning problems into subproblems of bounded width. In Proc. ICAPS 2022, pages 6270, 2022. [19] Dominik Drexler, Jendrik Seipp, and Hector Geffner. Learning hierarchical policies by iteratively reducing the width of sketch rules. In Proc. KR 2023, pages 208218, 2023. [20] Chris Fawcett, Malte Helmert, Holger Hoos, Erez Karpas, Gabriele Röger, and Jendrik Seipp. FD-Autotune: Domain-speciﬁc conﬁguration using Fast Downward. In ICAPS 2011 Workshop on Planning and Learning, pages 1317, 2011. [21] Patrick Ferber, Malte Helmert, and Jörg Hoffmann. Neural network heuristics for classical planning: study of hyperparameter space. In Proc. ECAI 2020, pages 23462353, 2020. [22] Patrick Ferber, Florian Geißer, Felipe Trevizan, Malte Helmert, and Jörg Hoffmann. Neural network heuristic functions for classical planning: Bootstrapping and comparison to other methods. In Proc. ICAPS 2022, pages 583587, 2022. [23] Maximilian Fickert and Jörg Hoffmann. Online relaxation reﬁnement for satisﬁcing planning: On partial delete relaxation, complete hill-climbing, and novelty pruning. Journal of Artiﬁcial Intelligence Research, 73:67115, 2022. [24] Richard E. Fikes and Nils J. Nilsson. STRIPS: new approach to the application of theorem proving to problem solving. Artiﬁcial Intelligence, 2:189208, 1971. [25] Guillem Francès, Blai Bonet, and Hector Geffner. Learning general planning policies from small examples without supervision. In Proc. AAAI 2021, pages 1180111808, 2021. [26] Elliot Gestrin, Marco Kuhlmann, and Jendrik Seipp. NL2Plan: Robust LLM-driven planning from minimal text descriptions. In ICAPS Workshop on Human-Aware and Explainable Planning, 2024. [27] Malik Ghallab, Dana Nau, and Paolo Traverso. Automated Planning: Theory and Practice. Morgan Kaufmann, 2004. 12 [28] Daniel Gnad, Álvaro Torralba, and Alexander Shleyfman. DecStar-2023. In IPC-10 Planner Abstracts, 2023. [29] Gemini Team Google, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, and Timothy Lillicrap et al. Gemini: family of highly capable multimodal models. arXiv:2312.11805 [cs.CL], 2023. [30] Gemini Team Google, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, Soroosh Mariooryad, Yifan Ding, Xinyang Geng, Fred Alcober, Roy Frostig, Mark Omernick, Lexi Walker, Cosmin Paduraru, Christina Sorokin, Andrea Tacchetti, Colin Gaffney, Samira Daruki, Olcan Sercinoglu, Zach Gleicher, and Juliette Love et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv:2403.05530 [cs.CL], 2024. [31] Claudia Grundke, Gabriele Röger, and Malte Helmert. Formal representations of classical planning domains. In Proc. ICAPS 2024, pages 239248, 2024. [32] Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao Kambhampati. Leveraging pre-trained large language models to construct and utilize world models for model-based task planning. In Proc. NeurIPS 2023, pages 7908179094, 2023. [33] Naresh Gupta and Dana S. Nau. On the complexity of blocks-world planning. Artiﬁcial Intelligence, 56(23):223254, 1992. [34] Mingyu Hao, Felipe Trevizan, Sylvie Thiébaux, Patrick Ferber, and Jörg Hoffmann. Guiding GBFS through learned pairwise rankings. In Proc. IJCAI 2024, pages 67246732, 2024. [35] Peter E. Hart, Nils J. Nilsson, and Bertram Raphael. formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, 4(2): 100107, 1968. [36] Patrik Haslum, Nir Lipovetzky, Daniele Magazzeni, and Christian Muise. An Introduction to the Planning Domain Deﬁnition Language, volume 13 of Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning. Morgan & Claypool, 2019. [37] Malte Helmert. planning heuristic based on causal graph analysis. In Proc. ICAPS 2004, pages 161170, 2004. [38] Malte Helmert. The Fast Downward planning system. Journal of Artiﬁcial Intelligence Research, 26:191246, 2006. [39] Malte Helmert and Héctor Geffner. Unifying the causal graph and additive heuristics. In Proc. ICAPS 2008, pages 140147, 2008. [40] Manuel Heusner, Thomas Keller, and Malte Helmert. Understanding the search behaviour of greedy best-ﬁrst search. In Proc. SoCS 2017, pages 4755, 2017. [41] Jörg Hoffmann and Bernhard Nebel. The FF planning system: Fast plan generation through heuristic search. Journal of Artiﬁcial Intelligence Research, 14:253302, 2001. [42] Sukai Huang, Trevor Cohn, and Nir Lipovetzky. Chasing progress, not perfection: Revisiting strategies for end-to-end LLM plan generation. arXiv:2412.10675 [cs.CL], 2024. [43] Michael Katz, Harsha Kokel, Kavitha Srinivas, and Shirin Sohrabi. Thought of search: PlanIn Proc. NeurIPS 2024, pages ning with language models through the lens of efﬁciency. 138491138568, 2024. [44] Dacheng Li, Shiyi Cao, Chengkun Cao, Xiuyu Li, Shangyin Tan, Kurt Keutzer, Jiarong Xing, Joseph E. Gonzalez, and Ion Stoica. S: Test time scaling for code generation. arXiv:2502.14382 [cs.LG], 2025. 13 [45] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson dAutume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. Competitionlevel code generation with AlphaCode. arXiv:2203.07814 [cs.PL], 2022. [46] Hongyi Ling, Shubham Parashar, Sambhav Khurana, Anwesha Basu Blake Olson, Gaurangi Sinha, Zhengzhong Tu, James Caverlee, and Shuiwang Ji. Complex LLM planning via automated heuristics discovery. arXiv:2502.19295 [cs.AI], 2025. [47] Nir Lipovetzky and Hector Geffner. Best-ﬁrst width search: Exploration and exploitation in classical planning. In Proc. AAAI 2017, pages 35903596, 2017. [48] Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. LLM+P: Empowering large language models with optimal planning proﬁciency. arXiv:2304.11477 [cs.CL], 2023. [49] Drew McDermott. The 1998 AI Planning Systems competition. AI Magazine, 21(2):3555, 2000. [50] James T. Oswald, Kavitha Srinivas, Harsha Kokel, Junkyu Lee, Michael Katz, and Shirin Sohrabi. Large language models as planning domain generators. In Proc. ICAPS 2024, pages 423431, 2024. [51] Stefan OToole, Miquel Ramirez, Nir Lipovetzky, and Adrian R. Pearce. Sampling from preimages to learn heuristic functions for classical planning (extended abstract). In Proc. SoCS 2022, pages 308310, 2022. [52] Gerald Paul, Gabriele Röger, Thomas Keller, and Malte Helmert. Optimal solutions to large logistics planning domain problems. In Proc. SoCS 2017, pages 7381, 2017. [53] Judea Pearl. Heuristics: Intelligent Search Strategies for Computer Problem Solving. AddisonWesley, 1984. [54] Ira Pohl. First results on the effect of error in heuristic search. In Bernard Meltzer and Donald Michie, editors, Machine Intelligence 5, pages 219236. Edinburgh University Press, 1969. [55] Silvia Richter and Malte Helmert. Preferred operators and deferred evaluation in satisﬁcing planning. In Proc. ICAPS 2009, pages 273280, 2009. [56] Silvia Richter and Matthias Westphal. The LAMA planner: Guiding cost-based anytime planning with landmarks. Journal of Artiﬁcial Intelligence Research, 39:127177, 2010. [57] Silvia Richter, Malte Helmert, and Matthias Westphal. Landmarks revisited. In Proc. AAAI 2008, pages 975982, 2008. [58] Gabriele Röger and Malte Helmert. The more, the merrier: Combining heuristic estimators for satisﬁcing planning. In Proc. ICAPS 2010, pages 246249, 2010. [59] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J. R. Ruiz, Jordan S. Ellenberg, Pengming Wang, Omar Fawzi, Pushmeet Kohli, and Alhussein Fawzi. Mathematical discoveries from program search with large language models. Nature, 625(7995):468475, 2024. [60] Nicholas Rossetti, Massimiliano Tummolo, Alfonso Emilio Gerevini, Luca Putelli, Ivan Serina, Mattia Chiari, and Matteo Olivato. Learning general policies for planning through GPT models. In Proc. ICAPS 2024, pages 500508, 2024. [61] Mehdi Samadi, Ariel Felner, and Jonathan Schaeffer. Learning from multiple heuristics. In Proc. AAAI 2008, pages 357362, 2008. [62] Arthur Samuel. Some studies in machine learning using the game of checkers. IBM Journal of research and development, 1959. 14 [63] Javier Segovia and Jendrik Seipp. Benchmark repository of IPC 2023 - learning track. https://github.com/ipc2023-learning/benchmarks, 2023. [64] Javier Segovia-Aguas, Sergio Jiménez, and Anders Jonsson. Computing programs for generalized planning using classical planner. Artiﬁcial Intelligence, 272:5285, 2019. [65] Javier Segovia-Aguas, Sergio Jiménez, and Anders Jonsson. Generalized planning as heuristic search: new planning search-space that leverages pointers over objects. Artiﬁcial Intelligence, 330:104097, 2024. [66] Jendrik Seipp. Dissecting Scorpion: Ablation study of an optimal classical planner. In Proc. ECAI 2024, pages 3942, 2024. [67] Jendrik Seipp, Silvan Sievers, Malte Helmert, and Frank Hutter. Automatic conﬁguration of sequential planning portfolios. In Proc. AAAI 2015, pages 33643370, 2015. [68] Jendrik Seipp, Florian Pommerening, Silvan Sievers, and Malte Helmert. Downward Lab. https://doi.org/10.5281/zenodo.790461, 2017. [69] Jendrik Seipp, Thomas Keller, and Malte Helmert. Saturated cost partitioning for optimal classical planning. Journal of Artiﬁcial Intelligence Research, 67:129167, 2020. [70] William Shen, Felipe Trevizan, and Sylvie Thiébaux. Learning domain-independent planning heuristics with hypergraph networks. In Proc. ICAPS 2020, pages 574584, 2020. [71] Tom Silver, Soham Dan, Kavitha Srinivas, Josh Tenenbaum, Leslie Pack Kaelbling, and Michael Katz. Generalized planning in PDDL domains with pretrained large language models. In Proc. AAAI 2024, pages 2025620264, 2024. [72] Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling LLM test-time compute optimally can be more effective than scaling model parameters. arXiv:2408.03314 [cs.LG], 2024. [73] Simon Ståhlberg, Guillem Francès, and Jendrik Seipp. Learning generalized unsolvability heuristics for classical planning. In Proc. IJCAI 2021, pages 41754181, 2021. [74] Simon Ståhlberg, Blai Bonet, and Hector Geffner. Learning general optimal policies with In Proc. ICAPS 2022, graph neural networks: Expressive power, transparency, and limits. pages 629637, 2022. [75] Simon Ståhlberg, Blai Bonet, and Hector Geffner. Learning generalized policies without supervision using GNNs. In Proc. KR 2022, pages 474483, 2022. [76] Kaya Stechly, Karthik Valmeekam, and Subbarao Kambhampati. Chain of thoughtlessness? an analysis of CoT in planning. In Proc. NeurIPS 2024, pages 2910629141, 2024. [77] Ayal Taitler, Ron Alford, Joan Espasa, Gregor Behnke, Daniel Fišer, Michael Gimelfarb, Florian Pommerening, Scott Sanner, Enrico Scala, Dominik Schreiber, Javier Segovia-Aguas, and Jendrik Seipp. The 2023 International Planning Competition. AI Magazine, 45(2):280296, 2024. doi: 10.1002/aaai.12169. [78] Álvaro Torralba, Carlos Linares López, and Daniel Borrajo. Symbolic perimeter abstraction heuristics for cost-optimal planning. Artiﬁcial Intelligence, 259:131, 2018. [79] Álvaro Torralba, Jendrik Seipp, and Silvan Sievers. Automatic instance generation for classical planning. In Proc. ICAPS 2021, pages 376384, 2021. [80] Alexander Tuisov, Yonatan Vernik, and Alexander Shleyfman. LLM-generated heuristics for AI planning: Do we even need domain-independence anymore? arXiv:2501.18784 [cs.AI], 2025. [81] Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao Kambhampati. On the planning abilities of large language models critical investigation. In Proc. NeurIPS 2023, pages 7599376005, 2023. [82] Karthik Valmeekam, Sarath Sreedharan, Matthew Marquez, Alberto Olmo Hernandez, and Subbarao Kambhampati. On the planning abilities of large language models (A critical investigation with proposed benchmark). arXiv:2305.15771 [cs.AI], 2023. [83] Karthik Valmeekam, Kaya Stechly, Atharva Gundawar, and Subbarao Kambhampati. Planning in strawberry ﬁelds: Evaluating and improving the planning and scheduling capabilities of LRM o1. arXiv:2410.02162 [cs.CL], 2024. 16 Generated Heuristics (Selection) A.1 DeepSeek R1 Heuristic for Blocksworld from fnmatch import fnmatch from collections import defaultdict from heuristics.heuristic_base import Heuristic class blocksworld9Heuristic(Heuristic): \"\"\" domain-dependent heuristic for the Blocksworld domain. # Summary This heuristic estimates the number of actions required to achieve the goal by considering the number of blocks that need to be moved and the blocks above them in the current state. For each block not in its goal position, the cost is 2 times the number of blocks above it plus 2. Held blocks not in the goal position add 1 to the cost. certain blocks. # Assumptions - The goal specifies the required 'on' and 'on-table' predicates for - Blocks not mentioned in the goal do not affect the heuristic. - Moving block requires unstacking all blocks above it first. - The arm can only carry one block at time. # Heuristic Initialization - Extract the goal conditions to determine the target positions for - Store the goal parent (block or 'table') for each block mentioned in each block. the goal. # Step-By-Step Thinking for Computing Heuristic 1. Parse the current state to determine the current parent (block or 2. Check if any block is currently being held. 3. For each block mentioned in the goal: 'table') and children (blocks on top) for each block. (putdown or stack). a. If the block is held and not in the goal position, add 1 action b. If the block is not held and not in the goal position, calculate the number of blocks above it and add 2 actions per block (unstack and putdown) plus 2 actions for the block itself. 4. Sum all calculated costs to get the heuristic value. \"\"\" def __init__(self, task): \"\"\"Initialize the heuristic by extracting goal conditions.\"\"\" self.goal_parent = {} for goal in task.goals: parts = goal[1:-1].split() if parts[0] == 'on': block, parent = parts[1], parts[2] self.goal_parent[block] = parent elif parts[0] == 'on-table': block = parts[1] self.goal_parent[block] = 'table' def __call__(self, node): 17 1 2 4 5 6 7 8 10 11 12 13 14 16 17 18 19 20 22 23 24 25 26 28 29 30 31 32 34 35 36 37 38 40 41 42 43 44 46 47 48 49 50 52 53 54 55 56 58 59 60 61 62 64 65 66 67 68 70 71 72 73 74 76 77 78 79 80 82 83 84 85 86 88 89 90 91 92 94 95 96 97 98 \"\"\"Compute the heuristic value for the given state.\"\"\" state = node.state current_parent = {} current_children = defaultdict(list) held_block = None # Parse current state for fact in state: parts = fact[1:-1].split() if parts[0] == 'on': child, parent = parts[1], parts[2] current_parent[child] = parent current_children[parent].append(child) elif parts[0] == 'on-table': block = parts[1] current_parent[block] = 'table' elif parts[0] == 'holding': held_block = parts[1] # Calculate cost cost = 0 # Check held block if held_block is not None and held_block in self.goal_parent: current_pos = 'held' goal_pos = self.goal_parent[held_block] # If held block is not in goal position, add 1 action if (goal_pos == 'table' and current_pos != 'table') or (goal_pos != 'table' and current_pos != goal_pos): cost += 1 # Process each block in the goal for block in self.goal_parent: if block == held_block: continue # Already handled current_parent_block = current_parent.get(block, 'table') goal_parent_block = self.goal_parent[block] if current_parent_block != goal_parent_block: # Calculate number of blocks above the current block def count_above(x): cnt = 0 stack = [x] while stack: current = stack.pop() for child in current_children.get(current, []): cnt += 1 stack.append(child) return cnt above = count_above(block) cost += 2 * (above + 1) return cost 18 2 3 4 5 6 8 9 10 11 12 14 15 16 17 18 20 21 22 23 24 26 27 28 29 30 32 33 34 35 36 38 39 40 41 42 44 45 46 47 48 50 51 A.2 DeepSeek R1 Heuristic for Spanner from fnmatch import fnmatch from collections import defaultdict, deque from heuristics.heuristic_base import Heuristic class spanner10Heuristic(Heuristic): \"\"\" domain-dependent heuristic for the Spanner domain. # Summary Estimates the number of actions required to tighten all loose nuts by considering the minimal path to collect usable spanners and reach each nut's location. used only once. # Assumptions - The man (bob) can carry multiple spanners, but each spanner can be - The shortest path between locations is precomputed using static link - The man's name is 'bob' as per the problem examples. information. # Heuristic Initialization - Extracts static link facts to build directed graph of locations. - Precomputes shortest paths between all pairs of locations using BFS. # Step-By-Step Thinking for Computing Heuristic 1. Identify the man's current location. 2. Collect all loose nuts and their locations. 3. Identify all usable spanners (carried or on the ground). 4. For each loose nut, compute the minimal cost to tighten it using 5. Assign spanners to nuts greedily, marking used spanners to avoid 6. Sum the minimal costs for all nuts to get the heuristic value. \"\"\" the best available spanner. reuse. def __init__(self, task): self.goals = task.goals self.static_links = defaultdict(list) for fact in task.static: parts = fact[1:-1].split() if parts[0] == 'link': start, end = parts[1], parts[2] self.static_links[start].append(end) # Precompute shortest paths between all locations self.shortest_paths = {} all_locations = set(self.static_links.keys()) for ends in self.static_links.values(): all_locations.update(ends) all_locations = list(all_locations) for loc in all_locations: distances = {loc: 0} queue = deque([loc]) while queue: current = queue.popleft() for neighbor in self.static_links.get(current, []): if neighbor not in distances: distances[neighbor] = distances[current] + 1 19 52 53 54 56 57 58 59 60 62 63 64 65 66 68 69 70 71 72 74 75 76 77 78 80 81 82 83 84 86 87 88 89 90 92 93 94 95 96 98 99 100 101 102 104 105 106 107 108 queue.append(neighbor) self.shortest_paths[loc] = distances def __call__(self, node): state = node.state # Find man's location (assumed to be 'bob') man_location = None for fact in state: if fact.startswith('(at bob '): parts = fact[1:-1].split() man_location = parts[2] break if not man_location: return float('inf') # Invalid state # Collect loose nuts and their locations loose_nuts = [] nut_locations = {} for fact in state: if fact.startswith('(loose '): parts = fact[1:-1].split() loose_nuts.append(parts[1]) elif fact.startswith('(at ') and 'nut' in fact: parts = fact[1:-1].split() obj, loc = parts[1], parts[2] nut_locations[obj] = loc # Collect usable spanners and their locations usable_spanners = [] carried_spanners = [] spanner_locations = {} for fact in state: if fact.startswith('(usable '): parts = fact[1:-1].split() usable_spanners.append(parts[1]) if fact.startswith('(carrying bob '): parts = fact[1:-1].split() carried_spanners.append(parts[2]) if fact.startswith('(at ') and 'spanner' in fact: parts = fact[1:-1].split() spanner_locations[parts[1]] = parts[2] # Prepare available spanners (carried or on ground) available_spanners = [] for spanner in usable_spanners: if spanner in carried_spanners: available_spanners.append((spanner, man_location, True)) elif spanner in spanner_locations: available_spanners.append((spanner, spanner_locations[spanner], False)) # Assign spanners to nuts greedily total_cost = 0 used_spanners = set() for nut in loose_nuts: nut_loc = nut_locations.get(nut) if not nut_loc: continue # Skip if nut location not found 110 111 112 113 114 116 117 118 119 120 122 123 124 125 126 128 129 130 131 132 134 135 min_cost = float('inf') best_spanner = None for spanner_info in available_spanners: spanner, s_loc, is_carried = spanner_info if spanner in used_spanners: continue if is_carried: distance = self.shortest_paths[man_location].get(nut_loc, float('inf')) cost = distance + 1 else: float('inf')) d1 = self.shortest_paths[man_location].get(s_loc, d2 = self.shortest_paths[s_loc].get(nut_loc, cost = d1 + 1 + d2 + 1 if d1 != float('inf') and d2 != float('inf') else float('inf') float('inf')) if cost < min_cost: min_cost = cost best_spanner = spanner if best_spanner is not None: total_cost += min_cost used_spanners.add(best_spanner) else: total_cost += 1000000 # Penalize for missing spanner return total_cost"
        }
    ],
    "affiliations": [
        "Federal University of Rio Grande do Sul",
        "Linköping University",
        "University of Oxford"
    ]
}