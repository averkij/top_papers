{
    "paper_title": "Training and Evaluating Language Models with Template-based Data Generation",
    "authors": [
        "Yifan Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The rapid advancement of large language models (LLMs) such as GPT-3, PaLM, and Llama has significantly transformed natural language processing, showcasing remarkable capabilities in understanding and generating language. However, these models often struggle with tasks requiring complex reasoning, particularly in mathematical problem-solving, due in part to the scarcity of large-scale, high-quality, domain-specific datasets necessary for training sophisticated reasoning abilities. To address this limitation, we introduce Template-based Data Generation (TDG), a novel approach that leverages LLMs (GPT-4) to automatically generate parameterized meta-templates, which are then used to synthesize a vast array of high-quality problems and solutions. Leveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset comprising over 7 million synthetically generated grade school math problems--each accompanied by code-based and natural language solutions--with the potential to generate an effectively unlimited number more. This dataset alleviates the scarcity of large-scale mathematical datasets and serves as a valuable resource for pre-training, fine-tuning, and evaluating LLMs in mathematical reasoning. Our method not only enables the generation of virtually infinite data but also elevates data augmentation to a new level by using GPT-4 for meta-template generation, ensuring diverse and high-quality problem structures. The TemplateMath Part I: TemplateGSM dataset is publicly available at https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available at https://github.com/iiis-ai/TemplateMath."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 7 2 ] . [ 1 4 0 1 8 1 . 1 1 4 2 : r Training and Evaluating Language Models with Template-based Data Generation Yifan Zhang1 1IIIS, Tsinghua University zhangyif21@mails.tsinghua.edu.cn"
        },
        {
            "title": "Abstract",
            "content": "The rapid advancement of large language models (LLMs) such as GPT-3, PaLM, and Llama has signiﬁcantly transformed natural language processing, showcasing remarkable capabilities in understanding and generating language. However, these models often struggle with tasks requiring complex reasoning, particularly in mathematical problem-solving, due in part to the scarcity of largescale, high-quality, domain-speciﬁc datasets necessary for training sophisticated reasoning abilities. To address this limitation, we introduce Template-based Data Generation (TDG), novel approach that leverages LLMs (GPT-4) to automatically generate parameterized meta-templates, which are then used to synthesize vast array of high-quality problems and solutions. Leveraging TDG, we create TemplateMath Part I: TemplateGSM, dataset comprising over 7 million synthetically generated grade school math problemseach accompanied by code-based and natural language solutionswith the potential to generate an effectively unlimited number more. This dataset alleviates the scarcity of large-scale mathematical datasets and serves as valuable resource for pre-training, ﬁne-tuning, and evaluating LLMs in mathematical reasoning. Our method not only enables the generation of virtually inﬁnite data but also elevates data augmentation to new level by using GPT-4 for meta-template generation, ensuring diverse and high-quality problem structures. The TemplateMath Part I: TemplateGSM dataset is publicly available at https://huggingface.co/datasets/math-ai/TemplateGSM."
        },
        {
            "title": "1 Introduction",
            "content": "Large language models (LLMs) have revolutionized natural language processing (NLP), exhibiting unprecedented capabilities in language understanding and generation. Models such as GPT3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022), and Llama (Touvron et al., 2023) have achieved remarkable success across various NLP tasks, including machine translation, summarization, and question answering. Despite these advancements, LLMs often struggle with tasks requiring complex reasoning and precise problem-solving skills, particularly in mathematical domains (Hendrycks et al., 2021; Cobbe et al., 2021). Mathematical reasoning poses unique challenges due to its reliance on rigorous logic, structured methodologies, and the necessity for exact solutions. Existing mathematical datasets are limited in both size and diversity, hindering models ability to generalize across wide range of problems (Paster et al., 2023; Azerbayev et al., 2023). The scarcity of large-scale, high-quality mathematical datasets is signiﬁcant barrier to developing LLMs capable of sophisticated mathematical reasoning. 1The code is available at https://github.com/iiis-ai/TemplateMath. To address this challenge, we introduce Template-based Data Generation (TDG), method that systematically generates an extensive variety of mathematical problems and corresponding solutions by leveraging parameterized templates. Crucially, we elevate data augmentation to new level by employing GPT-4 to automatically generate these meta-templates, which serve as foundational structures for problem generation. By utilizing GPT-4s advanced language understanding and generation capabilities, we create diverse set of templates that capture wide range of mathematical problem types. Using TDG, we present TemplateGSM, dataset of over 7 million synthetically generated grade school math problems, each paired with veriﬁed solutions in both code-based and natural language formats. By automating the generation and veriﬁcation of problems and solutions, our approach ensures high-quality data and precise supervision, facilitating the development of LLMs with advanced mathematical reasoning capabilities. Our main contributions are: We introduce TDG, scalable method for generating an effectively inﬁnite amount of highquality, domain-speciﬁc data using parameterized templates generated by GPT-4. By leveraging GPT-4 to create meta-templates, we advance data augmentation to new level, ensuring diverse and rich set of problem structures for data synthesis. We develop TemplateGSM, dataset comprising over 7 million synthetically generated math problems with veriﬁed solutions, addressing the scarcity of large-scale mathematical datasets. We provide insights into how TDG offers precise supervision through code execution and veriﬁcation, promoting the development of models with improved understanding and problem-solving abilities."
        },
        {
            "title": "2 Template-based Data Generation",
            "content": "Template-based Data Generation (TDG) is method designed to systematically produce vast array of mathematical problems along with their corresponding solutions by leveraging parameterized templates. To elevate data augmentation to new level, we employ GPT-4 to generate these meta-templates, capturing wide variety of problem structures and linguistic styles. By varying parameters within these GPT-4-generated templates, TDG ensures both scalability and quality in the generated data. This approach enables the creation of diverse and complex problem sets, which are essential for training and evaluating large language models in mathematical reasoning tasks. 2.1 Methodology The TDG process involves several key components that work together to generate high-quality mathematical datasets: 2.1.1 Generation of Meta-Templates with LLMs We begin by utilizing large language models (LLMs), such as GPT-4, to generate metatemplates (Zhang et al., 2023) that capture the underlying structures of various mathematical problem types. GPT-4s advanced language generation capabilities allow us to produce diverse set of templates encompassing wide range of mathematical concepts and problem types. These templates include placeholders for variable components such as names, items, quantities, dates, and locations. By harnessing GPT-4, we ensure that the templates are linguistically diverse and contextually rich, contributing to the overall quality and diversity of the dataset. 2.1.2 Simultaneous Q&A Generation and Veriﬁcation In single integrated step, we generate speciﬁc problems and their corresponding solutions by substituting parameters into the GPT-4-generated meta-templates. Parameters are carefully selected to satisfy speciﬁc conditions, ensuring the solvability and validity of the problems. This simultaneous generation of questions and answers maintains consistency between the problem statements and their solutions. 2 To guarantee the correctness and reliability of the generated data, we employ reject-samplingbased veriﬁcation process. This involves executing the code-based solutions using code executor and utilizing LLMs for solution veriﬁcation. If problem-solution pair fails veriﬁcationdue to issues like runtime errors, incorrect results, or ill-formed languageit is discarded. Only veriﬁed and runnable templates are retained, ensuring the integrity of the dataset. This iterative process of generation and veriﬁcation continues until sufﬁcient number of highquality problem-solution pairs are obtained. Integrating generation and veriﬁcation into single step streamlines the workﬂow and enhances the efﬁciency of the data generation process."
        },
        {
            "title": "2.2 Process Flowchart",
            "content": "An illustrative overview of our TDG method is presented in Figure 1. The ﬂowchart demonstrates the process starting from the LLM (e.g., GPT-4) generating meta-templates to the ﬁnal dataset creation. After the meta-templates are generated, parameters are substituted to instantiate problems and solutions simultaneously. The generated Q&A pairs undergo veriﬁcation using code execution and LLM-based checks. This loop continues, discarding any invalid pairs, until the dataset is populated with veriﬁed, high-quality data. LLM Generates Meta-Templates Simultaneous Q&A Generation No Veriﬁcation (Code Executor & LLM) Valid Q&A? Yes Add to Dataset Figure 1: Flowchart illustrating the Template-based Data Generation (TDG) process. An LLM generates meta-templates, which are instantiated into Q&A pairs. These pairs undergo veriﬁcation, and only the valid ones are added to the dataset. The process loops until the dataset is sufﬁciently populated. 2.3 Code Implementation Example An illustrative example of our TDG method is presented in Figure 2. The code snippet demonstrates how we generate problems involving sales over two consecutive months. The meta-template for this problem type was generated using GPT-4, capturing realistic scenario that can be varied through parameter substitution. We include lists of random terms such as names, items, months, and locations to create diverse and realistic problem contexts. This randomness introduces variability and prevents the dataset from becoming repetitive, which helps in training models to generalize better. def generate_pro le m_ nd _s lu ti n_ co () : # Lists of random terms months = [ \" January and February \" , ... , \" December and January \" ] # Get initial amount and subsequent ratio initial_amount , subsequent_ratio = get_params_co mb na ti on () # Randomly select terms name = random . choice ( first_names ) + + random . choice ( last_names ) item = random . choice ( items ) month = random . choice ( months ) year = random . randint (2003 , 2023) place = random . choice ( places ) county = random . choice ( us_counties ) county = county [ CountyName ] + \" , \" + county [ \" StateName \" ] # Construct problem statement problem_statemen = \" { name } sold { initial_amount } { item } in { month . split ( and ) [0]} , { year } at { place } in { county }. \" problem_statemen += \" In { month . split ( and ) [1]} , they sold { subsequent_rati *100:.0 }% of the amount sold in the previous month . \" problem_statemen += \" How many { item } did { name } sell in total during { month }? \" # Generate solution code sales_var = \" { item . replace ( , _ ) } _sold_in_ { month . split ( ) [0]} \" ratio_var = \" { item . replace ( , _ ) } _ratio \" total_var = \" total_ { item . replace ( , _ ) } \" solution_code = \"\"\" # Number of { item } sold by { name } in { month . split ( and ) [0]} , { year } { sales_var } = { initial_amount } # Sales ratio for the next month { ratio_var } = { subsequent_rati } # Calculating the amount of { item } sold in { month . split ( and ) [1]} subsequent_ { sales_var } = { sales_var } * { ratio_var } # Calculating the total number of { item } sold during { month } { total_var } = { sales_var } + subsequent_ { sales_var } result = { total_var } \"\"\" # Execute the solution code exec_globals = {} exec ( solution_code , {} , exec_globals ) result = round ( exec_globals [ result ]) # Generate the solution without code solution_wocode = \" { name } sold { initial_amount } { item } in { month . split ( and ) [0]} , { year }. \" solution_wocode += \" In { month . split ( and ) [1]} , they sold { subsequent_rat io *100:.0 }% of the amount sold in the previous month , which is { round ( subsequent_ratio * initial_amount ) } { item }. \" solution_wocode += \" In total , { name } sold { initial_amount } + { int ( subsequent_rati * initial_amount ) } = { result } { item } during { month }. \" return problem_statement , solution_code , result , solution_wocode Figure 2: An example of our TDG method. The code demonstrates how variable parameters are used to generate unique problem statements and corresponding solutions based on GPT-4-generated meta-templates. 2.4 Generated Problem and Solution Example To illustrate the output of our TDG method, consider the following example generated using GPT4-produced template: Problem: Emily has 15 apples. She buys 3 times more apples and then gives away 5 apples to her friend. How many apples does Emily have now? Solution: Emily initially has 15 apples. She buys 3 times more, so she buys 15 3 = 45 apples. Now she has 15 + 45 = 60 apples. She gives away 5 apples, so she is left with 60 5 = 55 apples. Therefore, Emily has 55 apples now. 4 Code-based Solution: # Initial number of apples Emily has initial_apples = 15 # Emily buys 3 times more apples apples_bought = initial_apples * 3 # Total apples after buying more total_apples = initial_apples + apples_bought # Emily gives away 5 apples apples_given_aw ay = 5 # Apples Emily has now apples_now = total_apples - apples_given_a wa result = apples_now # Emily has 55 apples now This problem and solution pair were generated simultaneously and veriﬁed using code execution and LLM checks to ensure correctness."
        },
        {
            "title": "2.5 Advantages of TDG",
            "content": "The TDG method offers several signiﬁcant advantages that make it particularly effective for generating large-scale mathematical datasets: Scalability: TDG enables the generation of an effectively inﬁnite amount of data by varying parameters within GPT-4-generated templates. This scalability is crucial for training large language models that require vast amounts of data. Quality Assurance: By integrating generation and veriﬁcation into single step with rejectsampling and utilizing code execution and LLM veriﬁcation, we ensure that each problemsolution pair is correct and reliable. This precise supervision enhances the quality of the dataset and the performance of models trained on it. Efﬁciency: The iterative process of generating and verifying Q&A pairs streamlines data creation, allowing for efﬁcient accumulation of high-quality data. Diversity: The use of GPT-4 to generate meta-templates introduces wide variety of problem structures and linguistic styles, enhancing the diversity of the dataset. This diversity helps models generalize better to new and unseen problems. Elevated Data Augmentation: By incorporating GPT-4 into the template generation process, we elevate data augmentation to new level, enabling the synthesis of data that is both varied and high-quality."
        },
        {
            "title": "3 TemplateMath Part I: TemplateGSM Dataset",
            "content": "3.1 Dataset Construction Building upon the TDG method, we have developed TemplateGSM, dataset consisting of over 7 million grade school math problems. Each problem is paired with both code-based solution and natural language explanation. The problems cover wide range of mathematical topics suitable for grade school levels, including arithmetic operations, fractions, percentages, and basic algebra. The meta-templates used to generate these problems were created using GPT-4, ensuring rich diversity in problem structures and linguistic expressions. This comprehensive coverage ensures that the dataset can be used to train models on various problem types and difﬁculty levels. 3.2 Dataset Statistics The key statistics of the TemplateGSM dataset are presented in Table 1. With 7,473,000 problems generated from 7,473 unique GPT-4-generated templates, the dataset offers extensive diversity in both problem structures and content. The average lengths of problems and solutions indicate that the dataset provides substantial context and detailed explanations, which are beneﬁcial for training language models to understand and solve complex reasoning tasks. Table 1: Statistics of the TemplateGSM Dataset (o-200k tokenizer)"
        },
        {
            "title": "Metric",
            "content": "Number of source templates Total number of problems Problem length range (tokens) Code solution length range (tokens) Code solution length average (tokens) Natural language solution length range (tokens) Natural language solution length average (tokens)"
        },
        {
            "title": "Value",
            "content": "7,473 7,473,000 [18, 636] [30, 513] 123.43 40.82 [1, 1024] 77.87 33."
        },
        {
            "title": "3.3 Dataset Availability",
            "content": "is publicly TemplateGSM at https://huggingface.co/datasets/math-ai/TemplateGSM. The code used for data generation is also provided at https://github.com/iiis-ai/TemplateMath. By sharing both the dataset and the generation code, we enable researchers and practitioners to reproduce our results, extend the dataset, and apply the TDG method to other domains or problem types. available accessed and can be The TemplateGSM dataset serves as valuable resource for pre-training, ﬁne-tuning, and evaluating large language models in mathematical reasoning tasks. By addressing the data scarcity problem, it facilitates the development of models capable of sophisticated reasoning, such as IBMs Granite Language Model (Granite Team, 2024). The inclusion of GPT-4-generated templates introduces level of diversity and naturalness in problem statements that closely mimic human-crafted problems. We anticipate that TemplateGSM and TemplateMath will contribute to advancements in AI research focused on reasoning and problem-solving."
        },
        {
            "title": "4 Related Work",
            "content": "Mathematical Datasets. The development of mathematical datasets has been pivotal in advancing AI research, particularly in mathematical reasoning and problem-solving. Early datasets like AQUA-RAT (Ling et al., 2017) provided annotated question-answer pairs for arithmetic word problems. The MATH dataset (Hendrycks et al., 2021) comprises over 12,500 challenging competitionlevel problems, serving as benchmark for evaluating mathematical reasoning abilities. However, its limited size restricts its utility for training large models. To expand available resources, Paster et al. (2023) introduced OPENWEBMATH, which ﬁlters web data to collect mathematical content. While it offers larger dataset, quality control remains challenging due to the noisy nature of web data. PROOF-PILE (Azerbayev et al., 2023) aggregates informal mathematical texts but lacks the structured problem-solution pairs necessary for supervised learning. Similarly, Zhang et al. (2024) proposed using language models as generative veriﬁers for data selection and released the AutoMathText dataset, but the data is still in unstructured text format. Our work builds upon these efforts by providing signiﬁcantly larger and more diverse dataset of mathematical problems with veriﬁed solutions, addressing the need for high-quality training data in mathematical reasoning. Training LLMs on Mathematical Tasks. Base LLMs trained on vast corpora have demonstrated impressive language capabilities (Brown et al., 2020; Touvron et al., 2023). However, their performance on mathematical tasks is limited due to the scarcity of domain-speciﬁc training data. Recent studies have explored ﬁne-tuning LLMs on mathematical datasets through continual pre-training (Lewkowycz et al., 2022; Azerbayev et al., 2023) or supervised ﬁne-tuning (SFT) (Yu et al., 2023; Yue et al., 2023; Weng et al., 2023). Continual pre-training involves further training on mathematical texts, enhancing models familiarity with mathematical language but not necessarily improving problem-solving skills. SFT approaches ﬁne-tune models on curated question-answer pairs but are constrained by the availability of highquality datasets. Our TDG method enables the generation of extensive, high-quality problem-solution pairs, providing valuable resource for both pre-training and ﬁne-tuning LLMs, potentially leading to signiﬁcant improvements in mathematical reasoning performance. Data Generation Techniques. Data augmentation and synthetic data generation have been widely used to improve model performance in various domains (Feng et al., 2021). In mathematical problem-solving, methods like problem recombination (Koncel-Kedziorski et al., 2015), question rephrasing (Yu et al., 2023), and iterative question composing (IQC) (Liu et al., 2024) have been explored but on much smaller scale. Our TDG approach differs by offering systematic and scalable method to generate an effectively inﬁnite number of high-quality problems, coupled with precise solution veriﬁcation through code execution."
        },
        {
            "title": "5 Conclusion",
            "content": "We have introduced Template-based Data Generation (TDG), novel approach for generating largescale, high-quality mathematical datasets through parameterized templates generated by GPT-4. Utilizing TDG, we created TemplateGSM, dataset of over 7 million synthetically generated grade school math problems with veriﬁed solutions in both code and natural language formats. Our extensive experiments demonstrate that TemplateGSM signiﬁcantly enhances the mathematical reasoning capabilities of LLMs when used for pre-training and ﬁne-tuning. The precise supervision offered by code execution and veriﬁcation ensures the reliability of the data, fostering the development of models with improved understanding and problem-solving abilities. By leveraging GPT-4 to generate meta-templates, we have elevated data augmentation to new level, introducing greater diversity and richness in the generated data. We believe that TDG and the TemplateGSM dataset will contribute substantially to advancing research in mathematical reasoning with LLMs. By addressing the data scarcity problem, our work opens new avenues for developing models capable of complex reasoning tasks. Limitations. While TDG and TemplateGSM offer substantial beneﬁts, there are limitations. One limitation is template bias, where models may become biased toward the structures present in the GPT-4-generated templates. Additionally, the generated problems are primarily at the grade school level, so extending TDG to higher-level mathematics requires careful template design, reﬂecting challenges in addressing complexity levels. Moreover, although GPT-4 introduces linguistic diversity, the style may still differ from human-authored educational materials, indicating limitation in authenticity. Future Work. Future research directions include expanding template coverage by developing templates for more advanced mathematical topics, potentially leveraging even more sophisticated LLMs or collaborative human-AI template generation. Integrating augmentation techniques, such as using language models to rephrase and compose problems (Liu et al., 2024), can increase linguistic diversity further. Extending TDG to generate problems in multiple languages would create multilingual datasets. Additionally, exploring methods to mitigate template bias and enhance the authenticity of problem statements could improve the utility of the dataset. Conducting studies to assess the quality and educational value of the generated problems through human evaluation would provide valuable insights."
        },
        {
            "title": "References",
            "content": "Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward Ayers, Dragomir Radev, and Jeremy Avigad. Proofnet: Autoformalizing and formally proving undergraduate-level mathematics. arXiv preprint arXiv:2302.12433, 2023. 1, 6 Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901, 2020. 1, 6 7 Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. 1 Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training veriﬁers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021. 1 Steven Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, and Eduard Hovy. survey of data augmentation approaches for nlp. arXiv preprint arXiv:2105.03075, 2021. IBM Granite Team. Granite 3.0 language models, 2024. 6 Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874, 2021. 1, 6 Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena Dumas Ang. Parsing algebraic word problems into equations. Transactions of the Association for Computational Linguistics, 3:585597, 2015. 7 Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Solving quantitative reasoning problems with language models. Advances in Neural Information Processing Systems, 35:38433857, 2022. 6 Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale generation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146, 2017. 6 Haoxiong Liu, Yifan Zhang, Yifan Luo, and Andrew Chi-Chih Yao. Augmenting math word problems via iterative question composing. arXiv preprint arXiv:2401.09003, 2024. 7 Keiran Paster, Marco Dos Santos, Zhangir Azerbayev, and Jimmy Ba. Openwebmath: An open dataset of high-quality mathematical web text. arXiv preprint arXiv:2310.06786, 2023. 1, 6 Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efﬁcient foundation language models. arXiv preprint arXiv:2302.13971, 2023. 1, 6 Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Kang Liu, and Jun Zhao. Large language models are better reasoners with self-veriﬁcation. CoRR, abs/2212.09561, 2023. 6 Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. Metamath: Bootstrap your own mathematical questions for large language models. arXiv preprint arXiv:2309.12284, 2023. 6, Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. Mammoth: Building math generalist models through hybrid instruction tuning. arXiv preprint arXiv:2309.05653, 2023. 6 Yifan Zhang, Yang Yuan, and Andrew Chi-Chih Yao. Meta prompting for agi systems. arXiv preprint arXiv:2311.11482, 2023. 2 Yifan Zhang, Yifan Luo, Yang Yuan, and Andrew Chi-Chih Yao. Autonomous data selection with language models for mathematical texts. arXiv preprint arXiv:2402.07625, 2024."
        }
    ],
    "affiliations": [
        "IIIS, Tsinghua University"
    ]
}