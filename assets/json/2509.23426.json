{
    "paper_title": "Democratizing AI scientists using ToolUniverse",
    "authors": [
        "Shanghua Gao",
        "Richard Zhu",
        "Pengwei Sui",
        "Zhenglun Kong",
        "Sufian Aldogom",
        "Yepeng Huang",
        "Ayush Noori",
        "Reza Shamji",
        "Krishna Parvataneni",
        "Theodoros Tsiligkaridis",
        "Marinka Zitnik"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "AI scientists are emerging computational systems that serve as collaborative partners in discovery. These systems remain difficult to build because they are bespoke, tied to rigid workflows, and lack shared environments that unify tools, data, and analyses into a common ecosystem. In omics, unified ecosystems have transformed research by enabling interoperability, reuse, and community-driven development; AI scientists require comparable infrastructure. We present ToolUniverse, an ecosystem for building AI scientists from any language or reasoning model, whether open or closed. TOOLUNIVERSE standardizes how AI scientists identify and call tools, integrating more than 600 machine learning models, datasets, APIs, and scientific packages for data analysis, knowledge retrieval, and experimental design. It automatically refines tool interfaces for correct use by AI scientists, creates new tools from natural language descriptions, iteratively optimizes tool specifications, and composes tools into agentic workflows. In a case study of hypercholesterolemia, ToolUniverse was used to create an AI scientist to identify a potent analog of a drug with favorable predicted properties. The open-source ToolUniverse is available at https://aiscientist.tools."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 7 2 ] . [ 1 6 2 4 3 2 . 9 0 5 2 : r a"
        },
        {
            "title": "Democratizing AI scientists using ToolUniverse",
            "content": "Shanghua Gao1, Richard Zhu1,2,, Pengwei Sui1,, Zhenglun Kong1,, Sufian Aldogom1,, Yepeng Huang1, Ayush Noori1, Reza Shamji1,2, Krishna Parvataneni3, Theodoros Tsiligkaridis4, Marinka Zitnik1,5,6,7, 1Department of Biomedical Informatics, Harvard Medical School, Boston, MA 2Harvard College, Harvard University, Cambridge, MA 3Massachusetts Institute of Technology, Cambridge, MA 4MIT Lincoln Laboratory, Lexington, MA 5Kempner Institute for the Study of Natural and Artificial Intelligence, Harvard University, Cambridge, MA 6Broad Institute of MIT and Harvard, Cambridge, MA 7Harvard Data Science Initiative, Cambridge, MA Co-second authors Correspondence: marinka@hms.harvard.edu TOOLUNIVERSE web service is at https://aiscientist.tools TOOLUNIVERSE code is at https://github.com/mims-harvard/ToolUniverse TOOLUNIVERSE package is at https://pypi.org/project/tooluniverse AI scientists are emerging computational systems that serve as collaborative partners in discovery. These systems remain difficult to build because they are bespoke, tied to rigid workflows, and lack shared environments that unify tools, data, and analyses into common ecosystem. In omics, unified ecosystems have transformed research by enabling interoperability, reuse, and community-driven development; AI scientists require comparable infrastructure. We present TOOLUNIVERSE, an ecosystem for building AI scientists from any language or reasoning model, whether open or closed. TOOLUNIVERSE standardizes how AI scientists identify and call tools, integrating more than 600 machine learning models, datasets, APIs, and scientific packages for data analysis, knowledge retrieval, and experimental design. It automatically refines tool interfaces for correct use by AI scientists, creates new tools from natural language descriptions, iteratively optimizes tool specifications, and composes tools into agentic workflows. In case study of hypercholesterolemia, TOOLUNIVERSE was used to create an AI scientist to identify potent analog of drug with favorable predicted properties. The open-source TOOLUNIVERSE is available at https://aiscientist.tools."
        },
        {
            "title": "Main",
            "content": "AI scientists hold promise as computational systems that can reason, experiment, and collaborate in discovery [1, 2]. Yet most require one-off implementation, remain constrained by rigid workflows, and lack shared environments for reuse and growth [2, 3]. In contrast, fields such as omics have advanced through ecosystems that integrate tools and standardized analyses into common platforms [46]. Comparable infrastructure is needed to support AI scientists. Here we introduce TOOLUNIVERSE, general ecosystem for constructing AI scientists at scale by combining large language models (LLMs), AI agents, and large reasoning models (LRMs) with an ecosystem 1 of scientific tools, including machine learning models, datasets, and APIs (Figure 1a). Because scientific progress requires interaction with the world rather than reasoning alone [1, 7], TOOLUNIVERSE provides interactive environments where models can invoke tools, run experiments, and incorporate real-world feedback, transforming internal cognition into concrete research actions. By abstracting these capabilities behind unified interface, TOOLUNIVERSE provides an ecosystem that wraps around any AI model, i.e., LLM, AI agent, or LRM, and enables the user to create and refine their own entirely custom AI research assistant (i.e., AI scientist) without the need for additional training or finetuning. TOOLUNIVERSE integrates more than 600 tools that span machine learning models, agents, software utilities, robotics, databases, and APIs (Figure 1b). To overcome incompatibilities between tools, it implements tool specification schema that standardizes tool definitions and enables consistent inference across models. Analogous to the role of HTTP in regulating internet communication (Figure 1c), TOOLUNIVERSE establishes an AI-tool interaction protocol that governs how AI scientists issue tool requests and receive results. The protocol implements two operations (Figure 1d) in TOOLUNIVERSE: Find Tool, which maps natural-language descriptions to tool specifications, and Call Tool, which executes selected tool with arguments and returns structured results such as text, embeddings, or JSON. This unified interface allows AI scientists to integrate tools at scale without bespoke setup. TOOLUNIVERSE is continually expanded with new tools. New tools can be registered locally or remotely and integrated without additional configuration [8]. Tools with complex dependencies or restricted access are supported through remote connections. TOOLUNIVERSE creates new tools from natural language descriptions, optimizes tool specifications iteratively, and composes interoperable tools. It chains tools for sequential or parallel execution so that AI scientists built with TOOLUNIVERSE can orchestrate workflows in self-directed manner."
        },
        {
            "title": "The TOOLUNIVERSE Ecosystem",
            "content": "At the core of TOOLUNIVERSE is the AI-tool interaction protocol that defines tools and standardizes how AI scientist systems interact with them. This protocol comprises three elements: specification schema, an interaction schema, and communication methods. The specification schema provides common format for describing each tools function, parameters, and outputs, enabling any client (whether an LLM, agent, or human user) to invoke tools without knowledge of their internal implementation. The interaction schema defines requests in uniform way, en2 coding function calls with tool names and arguments. This standardization makes diverse tools interchangeable, whether they are local functions, remote machine learning models, or laboratory instruments. Communication protocols manage execution. Local operations run directly in Python, while remote serving uses the Model Context Protocol (MCP) to transmit requests across networks [8]. These abstractions make heterogeneous tools accessible through consistent and extensible interface."
        },
        {
            "title": "Components of TOOLUNIVERSE",
            "content": "TOOLUNIVERSE is powered by core components that enable tool discovery, execution, integration, composition, optimization, and creation. These components support the lifecycle of AI scientists. Tool Finder (Figure 1e). The tool finder identifies relevant tools from over 600 resources using three complementary strategies: keyword search for rapid retrieval, an LLM-based in-context search for semantic understanding, and an embedding search for scalable similarity matching. By combining speed, precision, and depth, AI scientist systems can locate tools to execute user tasks. Tool Caller (Figure 1f). The tool caller executes selected tools through the TOOLUNIVERSE interaction protocol or via MCP requests. It validates inputs against tool specifications, dynamically loads tools on demand, and returns structured outputs, enabling reliable and efficient execution across heterogeneous resources. Tool Manager (Figure 1g). The tool manager integrates local and remote tools through standardized registration. Local tools are added directly with lightweight specifications, while remote tools, including those with specialized dependencies or privacy constraints, connect via the MCP. This approach makes tools function as interchangeable components within the same ecosystem. Tool Composer (Figure 1h). The tool composer constructs composite tools by chaining or orchestrating existing ones. It supports sequential, parallel, and feedback-driven execution, enabling adaptive workflows. For example, it can run multiple literature searches in parallel and then invoke summarization agent, illustrating how tools can be combined into agentic loops for multi-step analysis [9, 10]. Tool Discover (Figure 1i). Tool Discover generates new tools from natural language descriptions. It synthesizes formal specifications, produces executable implementations, validates outputs, and iteratively refines quality. This process ensures that newly created tools are maintainable and can be integrated into TOOLUNIVERSE. Tool Optimizer (Figure 1j). The tool optimizer improves existing tool specifications through iterative refinement. By generating test cases, analyzing executions, and applying feedback from the analyzer agentic tool, it increases usability and removes redundancy in the descriptions of the tool specifications. Optimized specifications increase the composability of tools and ensure the correct use of tools across tasks."
        },
        {
            "title": "Building AI Scientists with TOOLUNIVERSE",
            "content": "TOOLUNIVERSE integrates with LLMs, reasoning models, and agents to create customized AI scientist systems capable of planning, selecting tools, running experiments, and refining hypotheses. Setup requires only three steps: installing TOOLUNIVERSE, connecting it to chosen model, and providing the model with scientific problem. Once configured, the AI scientist can identify relevant tools, execute them, interpret results, and request human feedback when needed. Three main approaches illustrate how TOOLUNIVERSE supports both general-purpose and specialized AI scientists. First, LLMs such as Claude or GPT can be equipped with tool access through simple in-context instructions [11] or lightweight configuration, enabling them to invoke and chain tools during reasoning (Figure 2a). Second, agentic systems such as Gemini CLI can directly use TOOLUNIVERSEs MCP server and Tool Finder to identify and call tools, requiring minimal user setup (Figure 2b). Third, specialized agents, such as TxAgent for medical research [10] and Virtual Lab for nanobody design [12], can integrate with TOOLUNIVERSE at inference and during training. In the latter case, reinforcement learning strengthens their ability to navigate complex, task-specific environments [13, 14]. (Figure 2c)."
        },
        {
            "title": "Therapeutic Discovery Case Study",
            "content": "Figure 2c shows how TOOLUNIVERSE can be applied to therapeutic discovery for hypercholesterolemia by connecting TOOLUNIVERSE with Gemini CLI to create an AI scientist system. The process begins with protein target identification [15, 16]: using its literature-mining, targetprofiling, and tissue expression analysis tools, TOOLUNIVERSE prioritizes HMG-CoA reductase as the most promising candidate while documenting the potential side effects of targeting this enzyme. Then, the AI scientist uses TOOLUNIVERSE to access the DrugBank database and profile existing drugs that target HMG-CoA reductase. This results in the selection of lovastatin as the initial treatment to optimize due to its off-target effects. Next, the AI scientist invokes in silico screening to evaluate existing drugs and novel small molecules [17]. TOOLUNIVERSE integrates structural analog retrieval from ChEMBL with pre4 dictive ML models, including Boltz-2 [18] for binding affinity and ADMET-AI [19] for pharmacological profiling. This combined workflow assesses binding probability, predicted affinity, and blood-brain barrier (BBB) penetrance across candidate compounds. The AI scientist then assesses the novelty of top candidates using patent-mining tools. Through this screening process, the AI scientist identifies pravastatin, drug with lower off-target effects than lovastatin [20]. In addition to reproducing established findings, TOOLUNIVERSE identifies new candidate molecule (CHEMBL2347006/CHEMBL3970138) predicted to bind with higher affinity to HMG-CoA reductase, exhibit reduced blood-brain barrier penetrance, and display improved oral bioavailability and metabolic stability compared with lovastatin. Subsequent evidence confirmed that this compound had been patented for cardiovascular indications. The predicted binding affinity, binding likelihood, and BBB penetrance for all candidates are reported in Table 3. Using TOOLUNIVERSE, the AI scientist system selected, chained, and executed domain-specific tools to progress from hypothesis generation to candidate validation, while incorporating human feedback where needed. The workflow produced two candidates: an FDAapproved statin (pravastatin) and patented small molecule. Both address lovastatins off-target effects due to activity outside the liver, one of its primary limitations. The patented small molecule also has higher predicted binding affinity than lovastatin, suggesting greater potency."
        },
        {
            "title": "TOOLUNIVERSE moves beyond bespoke AI agents by providing an ecosystem for constructing",
            "content": "AI scientist systems. It provides easy-to-use tools and operations, integrates new tools, composes tools into workflows, and incorporates automatic tool discovery and optimization. These capabilities extend any language model, agent, or reasoning model with research functionality tailored to the user: models can retrieve data or run existing scripts, and also identify relevant analysis tools, execute them with user inputs, combine outputs into multi-step workflows, and iteratively refine or even generate new tools when gaps are encountered. TOOLUNIVERSE provides an environment where reasoning models can carry out end-to-end research tasks, from hypothesis generation to experimental validation. It is applicable across scientific domains, and its integration of human-inthe-loop tools provides safeguards against erroneous outputs. For example, an AI scientist might propose several candidate compounds, and human expert could validate tissue-specific expression before advancing them. Looking ahead, TOOLUNIVERSE could support multi-agent collaborations, benchmarking against human research groups, and integration with laboratory systems. 5 TOOLUNIVERSE goes beyond orchestration frameworks such as GPT Agent [21], Gemini CLI [22], Claude Code [23], Qwen Code [24], LangChain [25], Haystack [26], Autogen [27] or CAMEL [28], and beyond communication protocols like MCP [8], which standardize how models access data resources, browsers, and tools. These systems are designed to route queries or connect agents with pre-defined tools, but they do not support the end-to-end lifecycle of creating, refining, and integrating tools into scientific workflows. In contrast, TOOLUNIVERSE can create and optimize tools and integrate them into agentic workflows beyond providing static tool registries. It introduces Tool Discover, which generates new tools from natural language descriptions and transforms them into ready-to-use components, and Tool Optimizer, which iteratively improves tool specifications through feedback from users and other AI systems. These capabilities enable TOOLUNIVERSE to manage and compose heterogeneous resources (Figure 1b) into new tools and expand the scientific toolkit. We established the reliability of tools in TOOLUNIVERSE through multi-step process that combines test example sampling, expert human review, and automated optimization to verify correctness and usability. TOOLUNIVERSE also undergoes regular maintenance with structured bug reporting system that sustains long-term reliability. By drawing on tools from trusted, peerreviewed, and regulatory sources, the ecosystem upholds scientific rigor. useful parallel for TOOLUNIVERSE is the rise of shared platforms in omics, where standardization reshaped how tools, data, and researchers interacted. These platforms created foundation for reuse, reproducibility, and community-driven growth, driving major advances across the field. TOOLUNIVERSE serves similar role for AI scientists by making AI agents broadly accessible and reducing the barriers to their use in research. Data and code availability. The project page and web service of TOOLUNIVERSE are at https: //aiscientist.tools. The code, docs, and demos of TOOLUNIVERSE are at https://github.com/mim s-harvard/ToolUniverse. The Python package of TOOLUNIVERSE is at https://pypi.org/project/t ooluniverse. The case study of TOOLUNIVERSE is at https://zitniklab.hms.harvard.edu/ToolUniv erse/tutorials/tooluniverse case study.html. Acknowledgments. We thank Nicholas Yang and Yuchang Su for their contributions to TOOLUNIVERSE. We gratefully acknowledge the support of NIH R01-HD108794, NSF CAREER 2339524, U.S. DoD FA8702-15-D-0001, ARPA-H Biomedical Data Fabric (BDF) Toolbox Program, Harvard Data Science Initiative, Amazon Faculty Research, Google Research Scholar Program, AstraZeneca Research, Roche Alliance with Distinguished Scientists (ROADS) Program, Sanofi iDEA-iTECH Award, GlaxoSmithKline Award, Boehringer Ingelheim Award, Merck Award, Optum AI Research Collaboration Award, Pfizer Research, Gates Foundation (INV-079038), Chan Zuckerberg Initiative, John and Virginia Kaneb Fellowship at Harvard Medical School, Biswas Computational Biology Initiative in partnership with the Milken Institute, Harvard Medical School Deans Innovation Fund for the Use of Artificial Intelligence, and the Kempner Institute for the Study of Natural and Artificial Intelligence at Harvard University. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funders. Competing interests. The authors declare no competing interests. 7 Figure 1 Figure 1: a) TOOLUNIVERSE: an ecosystem for creating AI scientists. General-purpose LLMs, reasoning models, and agents are connected to the TOOLUNIVERSE ecosystem of over 600 scientific tools, enabling autonomous research workflows across domains. b) Overview of the diverse tool categories supported in TOOLUNIVERSE, including ML models, agents, domain knowledge, experimentation, scientific packages, automation, human feedback, workflows, datasets, APIs, embedding stores, visualization, and retrieval. c-d) Just as HTTP standardizes clientserver communication, TOOLUNIVERSE provides an interaction protocol that regulates how AI models issue tool requests and receive responses. Core operations for AI scientists interacting with TOOLUNIVERSE: Find Tool (mapping natural language to tool specifications) and Call Tool (executing tool and returning structured outputs). e) Tool finder: component for identifying relevant tools using three strategies: keyword search, LLM-based in-context search, and embedding-based similarity search. f) Tool caller: execution engine that validates inputs, dynamically loads tools, dispatches calls through TOOLUNIVERSE.run() or MCP, and returns structured outputs to clients. g) Tool manager: environment for integrating local and remote tools. Local tools are registered via JSON specifications and decorators, while remote tools are added through MCP for privacyor dependency-constrained setups. h) Tool composer: environment for chaining multiple tools into composite workflows. Supports sequential, parallel, and feedback-driven orchestration of heterogeneous tools. i) Tool discover: multi-agent system for generating new tools from natural language requirements. Combines specification synthesis, automated code generation, validation, and iterative refinement to create production-ready tools. j) Tool optimizer: multi-agent system that iteratively refines tool specifications to improve clarity, accuracy, and usability. Integrates test generation, execution analysis, and feedback-driven improvement. 9 Figure 2 10 Figure 2: a) Building AI scientists by connecting LLMs (such as Claude) with specialized tools. By selecting the right tools for each task and providing clear instructions, these LLM-powered AI scientists can effectively carry out scientific tasks. b) Building AI scientists with multi-round tool use and reasoning by connecting TOOLUNIVERSE with AI agents (such as Gemini CLI). These agents leverage tool-finding capabilities to select relevant tools, reason, and use TOOLUNIVERSE iteratively to tackle complex scientific tasks. c) TOOLUNIVERSE be applied to therapeutic discovery for hypercholesterolemia by connecting with Gemini CLI as an AI scientist. This example illustrates how TOOLUNIVERSE enables an AI scientist to select, chain, and use domain-specific tools, moving from hypothesis generation to candidate validation, while maintaining the flexibility to incorporate human feedback when appropriate."
        },
        {
            "title": "1 Overview of TOOLUNIVERSE",
            "content": "TOOLUNIVERSE is an ecosystem that wraps around any open or closed AI model, i.e., large language model (LLM), agent, or large reasoning model (LRM), and enables the user to create and refine their own entirely custom AI research assistant (i.e., AI scientist) without the need for additional training or finetuning. To achieve that, TOOLUNIVERSE connects the user-specified LLM/LRM/agent with scientific toolkit (Supplementary Table 1). While advanced models possess planning and reasoning capabilities, scientific research cannot be conducted through reasoning alone. TOOLUNIVERSE addresses this by providing interactive scientific environments where models can use tools to obtain real-world feedback, effectively transforming internal cognitive processes into tangible research actions. TOOLUNIVERSE features tool specification protocol that makes tools understandable to LLMs, LRMs, and AI agents regardless of their internal mechanisms, and an interaction protocol that allows tool use without the need to manage backend complexities. TOOLUNIVERSE is extensible and allows the tools to be easily added, optimized, or created. It hosts toolkit of over 600 scientific tools. It also supports multi-query specific searches to help users locate relevant tools and is engineered for easy integration with language models, agents, and reasoning models. Current tools in TOOLUNIVERSE include: foundation models, finetuned LLMs, LRMs, and other ML models exposed as callable endpoints; agentic planners and tool routers; domain libraries and simulators; and systems for human-in-the-loop feedback and lab automation with instrument control. TOOLUNIVERSE also provides data and retrieval utilities, such as data sources, knowledge bases, vector search with embedding generators, and complete retrieval-augmented generation (RAG) pipelines. For integration and governance, the ecosystem offers external service connectors, typed API clients, privacy guardrails, safety checklists, compliance controls, and audit logs. TOOLUNIVERSE supports high-level scientific and operational workflows through visualization dashboards, experiment design tools with ELN/LIMS integration, and robust workflow engines and orchestration schedulers. Despite the backend heterogeneity of these tools, which span machine learning models, AI agents, software utilities, robotics, databases, and APIs, all are presented to the AI scientist through unified AI-interaction protocol, which we describe next. AI-Tool Interaction Protocol. TOOLUNIVERSE implements protocol for presenting tool definitions, which makes the backend agnostic to users and simplifies the addition of new tools. This protocol allows the user to equip their AI scientist with tool-use capability without having to handle tool-specific configurations. This protocol has two endpoints: 1) Find Tool, which accepts textual description of desired functionality and retrieves tools from TOOLUNIVERSE that have the desired functionality, and 2) Call Tool, which executes specified tool with its arguments and returns the results. TOOLUNIVERSE connects to an AI model by providing the definitions of these operations within the models context window. This enables the model to leverage its reasoning 12 capabilities to generate the correct arguments for these operations and to autonomously search for and execute tools. Core Components. TOOLUNIVERSE include Tool Discover and Tool Manager for discovering and integrating tools, Tool Finder to search for options from over 600 candidates based on user requirements, and Tool Caller for execution. For complex tasks, the Tool Composer assembles multiple tools into composite workflow. The Tool Optimizer utilizes built-in multi-agent system to refine tool specifications, ensuring they better align with the tools actual behavior. Leveraging these components and the unified AI-tool interaction protocol, TOOLUNIVERSE empowers creating AI scientists: specialized AI models that combine reasoning with access to curated tools to perform complex research tasks."
        },
        {
            "title": "2 Unified AI-Tool Interaction Protocol in TOOLUNIVERSE",
            "content": "TOOLUNIVERSE is designed to support comprehensive ecosystem of tools with exceptionally diverse abilities. Despite the profound backend heterogeneity of these tools, which span machine learning models, AI agents, software utilities, robotics, databases, and APIs, all are presented to the client through unified protocol."
        },
        {
            "title": "2.1 Tool Specification Schema",
            "content": "Supplementary Figure 1 shows the tool specification schema in TOOLUNIVERSE. This protocol exposes every tool via standard specification containing its name; functional description; list of parameters, where each parameter is explicitly defined with its own name, description, data type, and required status; and return schema that shows the data structure of the returned data. An example tool specification is shown in Supplementary Figure 2. The specification is provided to clients such as LLMs, reasoning models, AI agents, and human users to help them understand how to use the tool effectively. For instance, when the client is an LLM, the specification is supplied within its context window, thereby granting it the necessary information to interact with tools from TOOLUNIVERSE."
        },
        {
            "title": "2.2 AI-Tool Interaction Protocol",
            "content": "TOOLUNIVERSE processes requests through standard interaction protocol, illustrated in Supplementary Figure 3. All interactions are formatted as single string that encodes function call, specifying the desired tools name and its input arguments. This protocol provides the foundation for all interactions with TOOLUNIVERSE, enabling suite of core operations including tool search, calling, discovery, optimization, and composition."
        },
        {
            "title": "2.3 AI Communication in TOOLUNIVERSE",
            "content": "TOOLUNIVERSE provides two methods for communication: local and remote. For local communication, operations are executed directly in Python environment using the TOOLUNIVERSE.run() function. To support remote serving, TOOLUNIVERSE also implements the Model Context Proto13 Tool Specification Schema in TOOLUNIVERSE Name: The unique identifier for the tool. Description: clear and concise summary of the tools purpose and functionality. Parameters: list of arguments that the tool accepts. Each argument has the following properties: Argument Name: The name of the parameter. Argument Type: The expected data type for the parameters value (e.g., string, integer, boolean). Argument Description: detailed explanation of what the parameter represents and its purpose. Required: boolean value indicating whether the parameter is mandatory for the tool to execute. Return Schema: description of the structure and data types of the output returned by the tool upon successful execution. Supplementary Figure 1: The tool specification schema in TOOLUNIVERSE. The tool specification schema in TOOLUNIVERSE is consistent across all tools, regardless of their diverse backends. col (MCP), which allows all operations like searching and invoking tools to be communicated with the TOOLUNIVERSE server over network, eliminating the need for local deployment."
        },
        {
            "title": "2.4 Accessing Tools from TOOLUNIVERSE",
            "content": "By leveraging tool specification and interaction protocol, TOOLUNIVERSE provides an interface for human users and AI agents to access tools. The tool can be invoked by executing: tooluniverse.run(tool_call_schema) where tool_call_schema is dictionary following the Interaction Protocol Schema: {name: name of the tool, arguments: parameters required by the tool}. This approach abstracts away backend complexity. Regardless of tools underlying implementation, it is presented to the client (the user of the tool, such as LLMs, reasoning models, AI agents) as specification. To use tool, the client consults this specification to construct request that adheres to the unified AI-tool interaction protocol. This request is then sent to TOOLUNIVERSE via either local interface or remote MCP connection. TOOLUNIVERSE processes the request, executes the specified tool, and returns the results to the client. This eliminates the need for complex configurations, regardless 14 Supplementary Figure 2: One example of tool specification in TOOLUNIVERSE. Interaction schema in TOOLUNIVERSE Name: The name of the tool or operation to be called. Parameters: list of arguments that the tool accepts. Each argument has the following properties: Argument Name: The name of the parameter. Argument Value: The value for the parameter provided by the client. Supplementary Figure 3: The universal interaction schema for all tools and operations within TOOLUNIVERSE. of backend or runtime differences. For example, users can query new database without writing database-specific SQL, run machine learning models without configuring GPUs or environments, or access web-based lab equipment through single, standardized tool call request."
        },
        {
            "title": "3 Core Components of TOOLUNIVERSE",
            "content": "TOOLUNIVERSE operates through set of core components designed for comprehensive tool management. Its capabilities include Tool Discover to discover new tools and Tool Manager to integrate tools into TOOLUNIVERSE, Tool Finder to search for suitable options from over 600 candidates based on user requirements, and Tool Caller for execution. For complex tasks, the Tool Composer assembles multiple tools into new, composite workflow. The Tool Optimizer utilizes built-in multi-agent system to refine tool specifications, ensuring they better align with the tools actual behavior."
        },
        {
            "title": "3.1 Tool Finder",
            "content": "The TOOLUNIVERSE contains large repository of scientific tools. To facilitate the creation of task-specific environment, the tool finder operation is designed to identify and retrieve relevant tools based on user requirements. The input to the tool finder is natural language query from the client, describing the task they wish to achieve or the specific capabilities required from the tools. It employs versatile search architecture featuring three distinct methodologies: keyword search, LLM in-context search, and embedding search. The selection of method allows for strategic trade-off between search precision, semantic understanding, and computational resource consumption. Keyword search. Keyword search operates on sophisticated keyword-based methodology. The process begins by parsing users query through multi-stage pipeline involving tokenization via regular expressions, the removal of over 45 common English stop words, and suffix-based stemming using 20 morphological rules to reduce words to their root form. To capture multi-word concepts, this method also generates n-grams (bigrams and trigrams). These processed keywords and phrases are then matched against pre-built index of tool specifications. which has undergone the same processing. Relevance is scored using term frequency-inverse document frequency (TF-IDF) algorithm, calculated as: Relevance = TF IDF log(1 + QueryFrequency), where TF measures how often term appears in document, IDF reflects how unique the term is across all documents, and QueryFrequency indicates how often the term appears in the users query. The scoring model enhances precision by applying hierarchical bonus structure to the relevance score. Matches found in tools name receive the highest priority with 2.0 bonus multiplier, followed by 1.5 multiplier for exact phrase matches within descriptions. This keyword search approach provides fast and robust search solution that operates independently of machine learning models, ensuring accessibility across different resource levels. LLM in-context search. The LLM in-context search leverages the advanced reasoning capabilities of Large Language Model to interpret user intent more holistically. Rather than relying on simple keyword matching, detailed prompt for tool selection is constructed. This prompt contextualizes the users task description with the tool specifications of candidate set of tools in TOOLUNIVERSE. The LLM is then tasked with analyzing this rich context to infer the optimal tool or sequence of tools required to fulfill the users request. This method excels at interpreting complex, multi-step, or abstract queries that demand logical inference. While its application can be constrained by the finite context window of the model, it offers strong flexibility in understanding abstract goals. The LLM in-context search is powered by the agentic tool implementation in TOOLUNIVERSE. This allows the user to simply provide configuration file that defines the prompt and tool specifications, without needing to manage the backend LLM inference processes. Embedding search. Embedding search is highly scalable method that retrieves tools by matching the semantic similarity between users query and the tools description. To achieve this, we finetune the GTE-Qwen2-1.5B language embedding model using pairs of synthetic user queries 16 Supplementary Figure 4: Code example of tool operation implementation used by the Tool Caller during execution. and augmented tool specifications, training it to understand the connection between users intent and tools function. The process involves two stages. First, in an offline indexing stage, each tools specification is passed through the embedding model to generate semantic vector that captures its meaning. These vectors are then stored and indexed in specialized vector database. Later, during the online querying stage, users natural language query is converted into query vector using the same model. Finally, relevant tools are discovered by calculating the cosine similarity between the users query vector and all the tool vectors in the database, identifying the closest matches."
        },
        {
            "title": "3.2 Tool Caller",
            "content": "The Tool Caller is the primary execution engine in TOOLUNIVERSE. It is responsible for instantiating tools, validating requests, and dispatching calls. Upon initialization, the Tool Caller is configured with manifest of available tools, including their specifications and settings. To mitigate the significant system overhead associated with loading all tools simultaneously, it employs dynamic loading strategy. specific tool is loaded into memory only upon its first request and is then cached for duration to efficiently handle subsequent calls. During this loading process, the Tool Caller injects the necessary configurations, such as API endpoints and authentication keys, into the corresponding tool class. When tool execution request is received, the Tool Caller first parses it to extract the tool name and arguments. It then performs rigorous validation check, ensuring the provided arguments conform to the data types and structural requirements defined in the tools specification. Once validated, the Tool Caller dispatches the arguments to the tools primary execution method, such as run(), as illustrated in Supplementary Figure 4. The resulting output is then returned to the client through the TOOLUNIVERSEs communication protocols. If any step in this process fails, from loading to validation or execution, the system generates and returns descriptive error message. This feedback mechanism helps the client diagnose the issue and revise the request accordingly. 17 Supplementary Figure 5: Example code demonstrating how to register local tool with Tool Manager and add it to TOOLUNIVERSE."
        },
        {
            "title": "3.3 Tool Manager",
            "content": "Tool Manager is designed to simplify the process of adding new tools to TOOLUNIVERSE. Tool local tools and remote tool Manager simplifies the addition of new tools through two modes: integration. For local tools, which require no special dependencies, only JSON specification (including name, descriptions, arguments, and configurations) and corresponding function are needed. The function executes the tool call arguments. For remote tools, which may have special dependencies or cannot be open-sourced, TOOLUNIVERSE offers wrapper that links them as external tools via the MCP. Local Tool Registration. For local tool registration, to add tool to TOOLUNIVERSE, both tool configuration and corresponding tool class are required. The tool configuration is dictionary that specifies the tool according to the Tool Specification Schema of TOOLUNIVERSE and includes the necessary settings for its execution. The tool class defines an initialization function that sets up the tool based on its specification, as well as run function that processes tool call arguments in accordance with the Interaction Protocol Schema of TOOLUNIVERSE. Local tool registration within the Tool Manager is facilitated through an easy-to-use decorator function, register tool(Class name, tool config), which decorates the tool class as illustrated in Supplementary Figure 5. Here, Class name is the string name of the tool class, and 18 Supplementary Figure 6: Example code demonstrating how to register remote tool with Tool Manager and add it to TOOLUNIVERSE. tool config is the configuration containing both the tool specification and required settings. Once registered, the tool is automatically integrated into TOOLUNIVERSE without further manual configuration. This registration process allows users to incorporate custom tools into TOOLUNIVERSE. This enables coordination with other existing tools, thereby empowering the creation of customized AI scientists. Remote Tool Registration. Remote Tool Registration enables the integration of tools that are private, require specialized configurations, or operate within restricted environments, and therefore cannot be made publicly available. Once registered remotely, these tools are added to TOOLUNIVERSE and can be accessed and executed in the same manner as standard tools. To achieve this, the Tool Manager includes an automatic MCP Auto Loader Tool that accepts the address of an MCP server and registers all of its tools into the TOOLUNIVERSEs tool list. After the MCP Auto Loader Tool has loaded the remote tools, they are integrated into the TOOLUNIVERSE with the same functionality as other tools. For the remote side, TOOLUNIVERSE supports two methods for setting up remote tool. The first is building standard tools that support MCP. To 19 further simplify the process and make remote tool registration identical to local registration, the Tool Manager also provides decorator function, register remote tool(Class name, tool config, mcp config). In this function, the Class name and tool config parameters are the same as those used in register tool(Class name, tool config), while mcp config defines the configuration for the MCP server, such as the host address and port used for the service. Supplementary Figure 7: This example demonstrates composable tool, built with the Tool Composer, that runs multiple literature search tools concurrently, followed by summary agent that synthesizes the results. The Tool Composer enables the combination of multiple tools from TOOLUNIVERSE in diverse ways, such as in parallel, sequentially, or in loops, enabling multi-tool collaboration."
        },
        {
            "title": "3.4 Tool Composer",
            "content": "For complex tasks, users can create new composite tools by programmatically combining existing ones. Tool Composer enables the integration of tools with heterogeneous back ends to build end-to-end workflows. Leveraging the Tool Caller for direct in-code execution, Tool Composer generates container function that exposes both the Tool Caller and TOOLUNIVERSE as in-line, executable primitives. The container function, implemented as compose(arguments, tooluniverse, call tool), serves as the execution backbone for Tool Composer. It contains the logic for coordinating different types of tools so they work together in single workflow. The arguments parameter specifies the tool call arguments that follow the interaction protocol schema of TOOLUNIVERSE, the tooluniverse is an instance of TOOLUNIVERSE that provides all available functions that TOOLUNIVERSE can support, and the call tool parameter is callable interface of Tool Caller that abstracts the invocation of individual tools in TOOLUNIVERSE. By integrating these components, the container function enables flexible multi-tool execution patterns, such as chaining outputs between tools, broadcasting single query across multiple tools, and constructing agentic loops that leverage tool feedback for adaptive, multi-step 20 experimental analysis. It can chain the output of one tool into the input of the next, call multiple tools with single query, and build agentic loops that use an agentic tool to generate function calls, execute tools, and incorporate tool feedback for multi-step experimental analysis. As illustrated in Supplementary Figure 7, composed tool can run several literature search tools concurrently and then invoke summarization agent to synthesize the findings, demonstrating heterogeneous workflow construction in which each step is driven by tool execution."
        },
        {
            "title": "3.5 Tool Optimizer",
            "content": "Tool Optimizer is designed to refine tools specifications, ensuring they are clear, accurate, and easily understood by models. Taking advantage of the workflow building of TOOLUNIVERSE using Tool Composer, we build an agentic tool description optimization tool, where the tool description is optimized by an iterative multi-round process that combines automated test case generation, real tool execution analysis, and agentic-powered feedback refinement. Through feedback-driven iterations, the system progressively improves both tool descriptions and parameter specifications, eliminating redundancy between them while ensuring accuracy through empirical validation. The optimization process automatically terminates when quality thresholds are met or maximum iterations are reached, producing specifications that enhances tool usability for AI agents. Core principles and tools. We develop the Tool Optimizer that employs multi-round iterative optimization strategy to automatically enhance tool documentation quality. The optimizer is built on three core principles: (1) test-driven optimization that validates descriptions against actual tool execution results, (2) multi-dimensional quality assessment across six standardized criteria, and (3) feedback-driven improvement that leverages insights from previous optimization rounds to guide subsequent iterations. The optimizer implements compositional architecture consisting of four specialized components working in concert. The TestCaseGenerator creates diverse test scenarios based on tool configurations and adaptively generates targeted test cases in later rounds using feedback from previous iterations. The DescriptionAnalyzer examines the alignment between existing descriptions and actual tool behavior by analyzing test execution results, then generates optimized descriptions that better reflect the tools true functionality. The ArgumentDescriptionOptimizer specifically targets parameter descriptions to ensure consistency with real usage patterns while eliminating redundancy between tool and parameter documentation. Finally, the DescriptionQualityEvaluator provides objective scoring on 0-10 scale across six quality dimensions: clarity, accuracy, completeness, conciseness, user-friendliness, and redundancy avoidance. Optimization process. The optimization process begins with initial test case generation followed by tool execution to gather baseline performance data. The system then enters an iterative optimization loop where each round generates enhanced test cases based on previous feedback, analyzes accumulated test results to propose improved descriptions, optimizes both tool and parameter descriptions, and evaluates quality against predefined thresholds. The process continues until either the satisfaction threshold is met (typically 8.0/10 for production use) or the maximum iteration 21 limit is reached (default: 3 rounds). This adaptive approach ensures comprehensive coverage while maintaining computational efficiency."
        },
        {
            "title": "3.6 Tool Discover",
            "content": "Tool Discover automatically generates new tools, including both specifications and executable code, from high-level natural language descriptions. Leveraging the workflow composition capabilities of TOOLUNIVERSE via Tool Composer, we construct an agentic multi-stage pipeline that transforms plain-text functional request into production-ready tool with minimal human intervention. The process integrates tool discovery, structured specification generation, code implementation, and iterative quality refinement, ensuring that the final tool adheres to functional requirements and ecosystem conventions. Through iterative feedback loops combining search, analysis, and code optimization, the system progressively improves the generated tool until it reaches predefined quality standards. The process terminates when target scores are achieved or iteration limits are reached, producing tools that are robust, maintainable, and ready for deployment. Core principles and architecture. The Tool Discover system is built around four core principles: pattern-guided generation that reuses functional patterns and conventions from existing tools to ensure ecosystem consistency; structured specification synthesis that transforms unstructured requests into tool specifications; automated code generation and validation that produces executable implementations with integrated testing; and iterative refinement that uses feedback from analysis and testing to drive targeted improvements. The system integrates four specialized components. The tool finder locates existing tools with similar functionality using semantic similarity and keyword-based search, ensuring adherence to established conventions. The SpecificationGenerator converts the natural language description into structured specification, including tool name, description, parameter definitions, return schema, and category metadata. The ImplementationGenerator produces code that follows best practices, includes complete dependency handling, integrates with the TOOLUNIVERSE registry, and implements error handling for robust operation. The QualityEvaluator assesses the generated tool across functionality, reliability, maintainability, performance, and test coverage, scoring each dimension from 010 and computing an overall weighted score. Generation process. The generation workflow begins with the discovery stage, which accepts tool description as inputs. It applies multiple search strategies to retrieve similar tools. Results are validated, deduplicated, and compiled into final set of references. Next, the specification stage uses agentic tool to produce complete tool configuration. This includes tool name, descriptions, parameter definitions with type annotations and descriptions, JSON-schema-based return type specification, and other meta data. The output conforms to TOOLUNIVERSE schema requirements and naming conventions, enabling immediate downstream integration. The implementation phase employs template-driven code generation to produce production-ready code, incorporating required imports, type-hinted function signatures, error handling, integration hooks via the @register tool decorator in TOOLUNIVERSE, and deployment-ready module structure. Finally, the system conducts multiple quality assessments, combining code analysis, dynamic testing with auto-generated test cases, and performance profiling. Each dimension is scored, with target minimum of 9/10 for production deployment. An iterative refinement loop applies targeted improvements until the threshold is met. Generated tools are packaged for immediate inclusion in TOOLUNIVERSE, producing JSON configuration file with metadata, source file with the complete implementation, and dependency specifications for reproducible installation."
        },
        {
            "title": "4 Building AI scientists with TOOLUNIVERSE",
            "content": "A customized AI scientist can be developed by integrating TOOLUNIVERSE with LLMs, reasoning models, and AI agents. In this configuration, the LLMs and reasoning models provide the core capabilities for reasoning and tool usage, while TOOLUNIVERSE serves as the scientific environment for interaction and experimentation. The development process typically involves three steps: 1) installing TOOLUNIVERSE with single command (pip install tooluniverse); 2) connecting TOOLUNIVERSE to the chosen model so it can access the tools provided by TOOLUNIVERSE; and 3) instructing the model to use these tools to address given scientific problem. Once the setup is complete, the AI scientist operates as follows: given user instruction or task, it formulates plan or hypothesis, employs the tool finder in TOOLUNIVERSE to identify relevant tools, and iteratively applies these tools to gather information, conduct experiments, verify hypotheses, and request human feedback when necessary. For each required tool call, the AI scientist generates arguments that conform to the TOOLUNIVERSE protocol, after which TOOLUNIVERSE executes the tool and returns the results for further reasoning. The models used to construct AI scientists can include LLMs, reasoning models, and AI agents. LLMs may be API-based, such as GPT, Claude, or Gemini, or open-weight models, such as LLaMA, DeepSeek, or Qwen. Large reasoning models enhance problem-solving capabilities by applying built-in chains of thought to analyze the current step before interacting with TOOLUNIVERSE. Agentic systems, such as Gemini CLI or Claude Code, integrate reasoning models with agentic feedback loops to autonomously manage multi-step problem solving and tool use. In addition to general-purpose agents, TOOLUNIVERSE can be paired with specialized agents trained for specific scientific domains, enabling stronger performance on targeted tasks. The following sections present three examples of building AI scientists using LLMs, agentic systems, and specialized agents."
        },
        {
            "title": "4.1 Building an AI Scientist from an LLM or an LRM",
            "content": "Figure 2(b) illustrates an example of building an AI scientist using an LLM, such as Claude, together with TOOLUNIVERSE. The process involves only three steps. 1. Install TOOLUNIVERSE with single command and install the Claude desktop app. 23 2. Open the Claude Desktop and navigate to Settings Developer Edit Config. Set up the configurations as follows: { \"mcpServers\": { \"tooluniverse\": { \"command\": \"uv\", \"args\": [ \"--directory\", \"path_to_ToolUniverse/src/tooluniverse\", \"run\", \"tooluniverse-mcp-claude\" ] } } } 3. Launch the Claude Desktop, select tools in TOOLUNIVERSE for the desired tasks."
        },
        {
            "title": "4.2 Building an AI Scientist from an AI Agent",
            "content": "We demonstrate how to build an AI scientist using AI Agents, such as the Gemini CLI, together with TOOLUNIVERSE. While AI Agents can automatically leverage TOOLUNIVERSE tool finder to identify the tools required for specific tasks, the process of creating an AI scientist involves just two steps. 1. Install TOOLUNIVERSE with single command and install the Gemini CLI. 2. Open the setting configuration file for Gemini CLI. Set up the configurations as follows: { \"mcpServers\": { \"tooluniverse\": { \"command\": \"uv\", \"args\": [ \"--directory\", \"/path/to/your/gemini_running_env\", \"run\", \"tooluniverse-smcp-stdio\" ] } }, }"
        },
        {
            "title": "4.3 Building an AI Scientist from a Specialized AI Agent",
            "content": "Specialized AI agents are trained on specific types of tasks, allowing them to become experts in particular domains, such as the TxAgent [10] for precision therapeutics, GeneAgent [29] for geneset analysis, and SpatialAgent [30] for spatial biology. In TxAgent [10], TOOLUNIVERSE can be used not only by these specialized AI agents during inference but also as real-world environment for agent training. In training, TOOLUNIVERSE serves as the scientific environment in which TxAgent can interact. Through reinforcement learning, TxAgent learns how to use tools within TOOLUNIVERSE and effectively manage complex therapeutic tasks. Tool category Description ML models Tools that apply machine learning algorithms to tasks like prediction, classification, or generation."
        },
        {
            "title": "AI agents",
            "content": "Scientific software packages Tools that operate autonomously to perceive environments, make decisions, and take actions toward goals. Biomedical software packages engineered to facilitate diverse scientific tasks, experiments, and data analysis workflows."
        },
        {
            "title": "Human expert\nfeedback",
            "content": "Tools that incorporate evaluations or input from human experts into automated or semi-automated processes. Robotics Databases"
        },
        {
            "title": "Embedding\nstores",
            "content": "APIs Tools involving physical or simulated machines capable of sensing, reasoning, and acting in the world. Tools that store, manage, and query structured or semi-structured data efficiently, including relational, tabular, and hierarchical databases. Tools that store and retrieve vectorized representations of data for use in machine learning tasks. Interface tools that allow different software systems or tools to communicate and exchange data. Supplementary Table 1: Types of tools in TOOLUNIVERSE that TOOLUNIVERSE-powered AI scientists can use."
        },
        {
            "title": "ML models",
            "content": "17 boltz2 docking, run TxAgent biomedical reasoning, ADMET predict CYP interactions 25 AI agents 38 Scientific software packages Human expert feedback Robotics 6 1 Databases"
        },
        {
            "title": "Embedding\nstores",
            "content": ""
        },
        {
            "title": "APIs",
            "content": "281 HypothesisGenerator, ExperimentalDesignScorer, MedicalLiteratureReviewer get biopython info, get pyscreener info, get pykalman info consult human expert, get expert response, get expert status communicate with ros robot drugbank get drug pathways and reactions by name, HPA get comprehensive gene details by ensembl id, drugbank full search embedding tool finder, embedding database search, embedding database add FDA get active ingredient info by drug name, PubChem search compounds by substructure, OpenTargets get associated targets by disease efoId Supplementary Table 2: Number of tools and example tools for each category in TOOLUNIVERSE."
        },
        {
            "title": "5 Tools in TOOLUNIVERSE",
            "content": "TOOLUNIVERSE is scientific environment that contains over 600 tools covering essential scientific research domains. TOOLUNIVERSE integrates built-in tool categories that are easy for people to reuse, covering machine learning models, AI agents, software utilities, expert feedback systems, robotics, databases, embedding stores, data archives, and APIs, each serving specific computational and analytical requirements. Agentic tools. Agentic tools operate autonomously to perform complex tasks using LLMs. Each agent is configurable with custom prompts and tool specifications, supporting multiple backend models, including ChatGPT and Gemini. TOOLUNIVERSE includes agentic tools for literature summarization, code analysis, hypothesis generation, experiment planning, and results analysis. By defining the prompts and tool specifications in the configuration file, one can quickly build an agentic tool. Scientific software package tools. To support scientific coding, scientific package tools pro26 vide comprehensive information about Python-based scientific computing libraries such as NumPy, Pandas, and SciPy. These tools offer installation instructions, usage examples, and documentation links, implementing dual-source data retrieval from PyPI APIs with local backup information. Database tools. Database tools manage structured scientific resources such as DrugBank vocabulary datasets, clinical trial records, and molecular databases. They support integrations with tabular, hierarchical, XML-based, and graph-structured data. These tools provide capabilities for text-based search, field-level filtering, configurable result limits, and metadata return schemas. Built-in search, filtering, and indexing features can be reused when incorporating new databases. API integration tools. API integration tools enable communication with external scientific data sources using standard protocols such as RESTful APIs or GraphQL. Through these tools, users can access resources like FDA drug databases, OpenTargets diseasetarget associations, PubChem compound information, and many other databases, all with robust error handling and response validation. New tools can be incorporated by updating the API server URL, provided the common protocol is maintained. Expert feedback tools. Expert feedback tools integrate human expertise directly into the environment, allowing AI scientists to request human suggestions or approval whenever necessary. This tool includes server that connects the system with human experts, along with user interface through which experts can provide responses. When user calls the expert feedback tool, the request is redirected by the tool caller in TOOLUNIVERSE to server, which forwards it to the human expert interface. Human experts can receive the request and provide their own insights and judgments. Their feedback is then sent back through the server as tool response to the user. This approach enables consultation with human experts for complex scientific decisions and interpretations, effectively combining automated analysis with expert validation. Machine learning tools. Machine learning tools apply predictive and generative models to scientific use cases, such as diseasetarget scoring [31], disease-state prediction, gene-gene interaction [32, 33], gene dependency analysis [34], ADMET prediction [19], binding affinity prediction [18], and beyond. Since running environments for machine learning models often require specialized setups and hardware (e.g., GPUs), which can be difficult to deploy, TOOLUNIVERSE uses remote registration scheme. This approach allows models to run on private servers while still being exposed as tools within TOOLUNIVERSE. New machine learning models can be quickly integrated into TOOLUNIVERSE through remote tool registration. Embedding store tools. Embedding store tools manage vectorized representations of scientific data. Scientific data is first transformed into embeddings using embedding models and then stored in database. TOOLUNIVERSE employs FAISS to enable efficient semantic search, similarity matching, and data retrieval over these embedding databases."
        },
        {
            "title": "6 Evaluation of Tools",
            "content": "To ensure the correctness and reliability of tools before their inclusion in TOOLUNIVERSE, we implemented multi-step evaluation process. This evaluation was designed both to validate tool functionality and to ensure scientific utility. The evaluation steps are as follows: InputOutput Sampling. For each tool, we generated diverse sample inputs and recorded corresponding outputs. These samples were constructed to cover typical use cases as well as edge conditions, ensuring broad coverage of tool functionality. Human-in-the-Loop Review. Outputs produced by the tools were subjected to systematic human review. Scientific experts assessed correctness, interpretability, and consistency with expected domain knowledge. This human evaluation provided an additional safeguard against erroneous or misleading outputs. Automated Optimizers and Checkers. Complementing human evaluation, we employed automated optimizer and checker tools. These systems iteratively tested tool specifications against the sampled inputs, refining descriptions and ensuring consistency between declared functionality and observed behavior. This process emphasized correctness and usability, rather than accuracy alone, to promote robust integration within the ecosystem. Regular Maintenance and Bug Reporting. To ensure continued reliability of tools within TOOLUNIVERSE, we perform regular maintenance and monitoring. structured bug reporting system allows issues to be identified by users and promptly addressed by the TOOLUNIVERSE team. These practices provide ongoing quality assurance and safeguard the long-term usability of the ecosystem. Beyond these internal steps, TOOLUNIVERSE prioritizes tools from trusted sources. Many included tools have been published, peer-reviewed, and verified through prior use by established scientific communities, such as the NIH, FDA, and other regulatory or research agencies. By relying on previously validated resources, we reduce the risk of introducing spurious or unverified functionality into the ecosystem. These evaluation measures ensure that tools incorporated into TOOLUNIVERSE meet standards of correctness, reproducibility, and scientific reliability, providing foundation for dependable AI-assisted discovery."
        },
        {
            "title": "7 Further Details on the Case Study of TOOLUNIVERSE",
            "content": "We provide details for the hypercholesterolemia use case shown in Figure 2c, where an AI scientist powered by LLMs connected to TOOLUNIVERSE finds and optimizes statin compounds for hypercholesterolemia. Through this case study, we show how TOOLUNIVERSE can be used for highly interdisciplinary and complex scientific methods like drug development. We demonstrate that TOOLUNIVERSE-enabled AI scientist is able to recover existing research on statins, lending credibility to the research enabled by TOOLUNIVERSE. 28 The AI scientist is constructed by providing all 600+ tools in TOOLUNIVERSE to Gemini CLI (powered by the Gemini-2.5-Pro model). With this current AI scientist, we must prompt the model with high-level prompts to achieve each stage of the case study. We envision that future TOOLUNIVERSE-enabled AI scientists will be knowledgeable enough about TOOLUNIVERSE and the scientific discovery process to require only single high-level prompt and occasional expert feedback to achieve the entire case study. In our case study, the AI scientist is first prompted to conduct target identification for hypercholesterolemia. The AI scientist first calls OpenTargets get disease id description by name (API Tool) and OpenTargets get associated targets by disease efo Id (API Tool), which allow it to identify the top targets associated with the disease. Next, it calls OpenTargets get target tractability by ensemblID (API Tool) and EuropePMC search articles (API Tool) on each protein target. These tools provide diverse information about each proteins potential as target, including the existence of approved drugs for the target, the presence of high-quality binding pocket, and associated literature. After retrieving this information for each target, the AI scientist calls consult human expert (Expert Feedback Tool) to perform scientist-guided selection of the final target based on the existing literature. In this way, the AI scientist identifies eleven protein targets involved in hypercholesterolemia, conducts extensive literature reviews on each, and selects HMG-CoA reductase as the target to take forward due to its history of successful targeting with statins. Next, the AI scientist uses HPA search genes by query (API Tool), HPA get rna expression in specific tissues (API Tool), and HPA get comprehensive gene details by ensembl id (API Tool) to query the Human Protein Atlas and characterize the expression profile of HMG-CoA reductase. Using the atlas data, the AI scientist concluded that there is high expression in the liver (the tissue of interest), but also in locations such as the gastrointestinal tract and brain. It reasoned that this could explain certain off-target effects associated with targeting HMG-CoA reductase, such as neurological side effects. Thus, minimizing off-target binding and side effects is crucial to consider in subsequent screening steps. The AI scientist now conducts an in silico screen and molecular optimization process. It first calls drugbank get drug name and description by target name (Database Tool) and drugbank get drug name and description by indication (Database Tool) to retrieve current statin treatments from the DrugBank database, as statins target HMG-CoA reductase. The AI scientist then profiles each statin with drugbank get pharmacology by drug name or drugbank id (Database Tool). This result in the selection of lovastatin as the statin to optimize. Lovastatin is widely used medication but has off-target binding in non-liver tissues compared to hydrophilic statins. To optimize lovastatin, the AI scientist uses ChEMBL search similar molecules (API Tool) to retrieve molecular candidates from the ChEMBL database that are structural analogs to lovastatin (Tanimoto similarity > 0.80). Then, two TOOLUNIVERSE ML Model Tools (ADMETAI predict admet properties and boltz2 docking) are used to retrieve key pharmaceutical properties for each of the 32 structural analogs, including ADMET properties and binding affinity to HMG-CoA reductase. Of note, though Boltz-2 has strong performance on binding likelihood and affinity predictions, there is variability in the model output given the same input, so Boltz-2 was run four times for each of the structural analog candidates, and the mean and standard deviation of its outputs were calculated. Predictions from the ML Model Tools for select properties are shown in Supplementary Table 3. We focus particularly on binding likelihood, binding affinity, and probability of blood-brain-barrier (BBB) penetrance because the former two assess the molecules ability to act on its target, HMG-CoA reductase, while the latter assesses the molecules probability of penetrating into one of the tissues where its target is highly expressed (brain), which could lead to off-target effects. ChEMBL ID Preferred name Prob. of binding mean () Prob. of binding std. dev. Binding affinity mean Binding affinity std. dev. Prob. of BBB penetrance CHEMBL3349960 CHEMBL2347006 CHEMBL1205793 CHEMBL1515625 CHEMBL3970138 CHEMBL1394089 CHEMBL3186637 CHEMBL152032 CHEMBL1207599 CHEMBL1230589 CHEMBL3349881 CHEMBL4088701 CHEMBL333443 CHEMBL303515 CHEMBL2364554 CHEMBL175236 CHEMBL330439 CHEMBL1206749 CHEMBL1456346 CHEMBL418776 CHEMBL1201373 mevinolin lovastatin sodium lovastatin acid 0.08 0.09 0.04 0.10 0.10 0.10 0.05 0.06 0.05 0.06 0.07 0.04 0.08 0.02 0.05 0.06 0.11 0.05 0.09 0.06 0.08 0.48 0.44 0.43 0.41 0.41 0.40 0.40 0.39 0.38 0.38 0.38 0.37 0.37 0.34 0.34 0.34 0.34 0.34 0.33 0.33 0.31 0.54 -0.18 0.38 0.59 -0.09 0.54 0.02 0.04 0.28 0.71 0.45 0.24 0.60 0.25 0.48 0.15 0.54 0.20 0.40 0.16 0.16 0.41 0.13 0.30 0.12 0.33 0.38 0.11 0.16 0.40 0.03 0.12 0.20 0.26 0.22 0.13 0.24 0.40 0.24 0.37 0.07 0.12 0.58 0.48 0.68 0.59 0.47 0.62 0.73 0.69 0.55 0.64 0.57 0.60 0.58 0.56 0.49 0.54 0.58 0.59 0.55 0.52 0. ChEMBL ID Preferred name Prob. of binding mean () Prob. of binding std. dev. Binding affinity mean Binding affinity std. dev. Prob. of BBB penetrance CHEMBL487721 CHEMBL1317360 CHEMBL5281241 CHEMBL3544685 CHEMBL4076715 CHEMBL1144 CHEMBL3544686 CHEMBL3187243 CHEMBL690 CHEMBL3544781 CHEMBL1617336 pravastatin pravastatin sodium 0.31 0.29 0.29 0.27 0.25 0.24 0.23 0.22 0. 0.22 0.21 0.07 0.15 0.14 0.04 0.10 0.12 0.04 0.04 0.02 0.03 0.04 0.19 0.46 0.44 0.37 0.16 0.44 0.72 0.44 0.55 0.24 0.32 0.14 0.24 0.31 0.18 0.21 0.26 0.28 0.11 0. 0.28 0.13 0.54 0.51 0.47 0.50 0.44 0.48 0.54 0.64 0.43 0.50 0.57 Supplementary Table 3: TOOLUNIVERSE output for all 34 structural analogs of lovastatin. Binding probability and affinity were predicted by Boltz-2, while the probability of blood-brain-barrier (BBB) penetrance was predicted by ADMET AI. For binding affinity, more negative values indicate higher binding affinity. Analogs are ranked in descending order by predicted probability of binding. Mean and standard deviation were calculated across four samples. The two rows highlighted in red indicate the small molecule candidate (CHEM-BL2347006/CHEMBL3970138) that is selected for additional downstream evaluation in the patent literature. The FDA-approved pravastatin and its charged form, pravastatin sodium, appear in the list of structural analogs and, based on the ML model outputs, have lower probability of BBB penetrance compared to lovastatin. This is consistent with pravastatins lower off-target binding outside the liver, thus supporting the AI scientists TOOLUNIVERSE-based optimization protocol for addressing the weaknesses in lovastatin with new therapeutic candidates. Finally, we use the AI scientists outputs to select two structural analogs for further evaluation: CHEM-BL2347006 and CHEMBL3970138. These analogs are in fact the same molecule despite slight differences in their SMILE representation. This molecule places within the top five candidates for highest probability of binding the target (shown in Supplementary Table 3), has the strongest predicted binding affinity, and places within the top five for lowest predicted BBB penetrance. The AI scientist uses TOOLUNIVERSE to evaluate prior art in the patent literature for this candidate drug. It uses PubChem get CID by SMILES (API Tool) and PubChem get assoc iated patents by CID (API Tool) to retrieve URLs to drug-associated patents from PubChem. Then, it uses get webpage text from url (API Tool) to read the text of these 31 patent URLs. Through this, the AI scientist discovered that the small molecule associated with CHEMBL2347006 and CHEMBL3970138 was already patented for use in cardiovascular disease in 2019 and 2021, revealing that another potential treatment for hypercholesterolemia nominated by the AI scientist was confirmed in the literature. This case study demonstrates how TOOLUNIVERSE can be used to conduct flexible, multidomain scientific research. It breaks out of the paradigm of narrowly-focused bioinformatics pipeline; instead, the AI scientist leverages tools and data modalities across chemistry, human biology, and patent literature to retrieve multiple lines of evidence in supporting its final drug candidates. Moreover, by recovering pravastatin, statin with better off-target binding properties compared to the starting compound of lovastatin, the case study demonstrates the ability of TOOLUNIVERSE-mediated research to recoverand therefore advancecurrent science."
        },
        {
            "title": "References",
            "content": "1. Gao, S. et al. Empowering biomedical discovery with AI agents. Cell 187, 61256151 (2024). URL https://doi.org/10.1016/j.cell.2024.09.022. 2. Swanson, K., Wu, W., Bulaong, N. L., Pak, J. E. & Zou, J. The virtual lab of ai agents designs new sars-cov-2 nanobodies. Nature 13 (2025). 3. Boiko, D. A., MacKnight, R., Kline, B. & Gomes, G. Autonomous chemical research with large language models. Nature 624, 570578 (2023). 4. Virshup, I. et al. The scverse project provides computational ecosystem for single-cell omics data analysis. Nature Biotechnology 41, 604606 (2023). 5. Lobentanzer, S. et al. Democratizing knowledge representation with biocypher. Nature Biotechnology 41, 10561059 (2023). 6. Heumos, L. et al. An open-source framework for end-to-end analysis of electronic health record data. Nature Medicine 30, 33693380 (2024). 7. Wang, H. et al. Scientific discovery in the age of artificial intelligence. Nature 620, 4760 (2023). 8. Anthropic. 2024. Introducing the model context protocol (2024). Anthropic blog, November 25 9. Yao, S. et al. React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR) (2023). 10. Gao, S. et al. TxAgent: An ai agent for therapeutic reasoning across universe of tools (2025). URL https://arxiv.org/abs/2503.10970. 2503.10970. 11. Brown, T. et al. Language models are few-shot learners. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. & Lin, H. (eds.) Advances in Neural Information Processing Systems, vol. 33, 18771901 (Curran Associates, Inc., 2020). 12. Swanson, K., Wu, W., Bulaong, N. L., Pak, J. E. & Zou, J. The virtual lab: Ai agents design new sars-cov-2 nanobodies with experimental validation. bioRxiv 202411 (2024). 13. Shao, Z. et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300 (2024). 14. Schulman, J., Wolski, F., Dhariwal, P., Radford, A. & Klimov, O. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347 (2017). 33 15. Schenone, M., Danˇcık, V., Wagner, B. K. & Clemons, P. A. Target identification and mechanism of action in chemical biology and drug discovery. Nature chemical biology 9, 232240 (2013). 16. Ren, F. et al. small-molecule tnik inhibitor targets fibrosis in preclinical and clinical models. Nature Biotechnology 43, 6375 (2025). 17. Lin, X., Li, X. & Lin, X. review on applications of computational methods in drug screening and design. Molecules 25, 1375 (2020). 18. Passaro, S. et al. Boltz-2: Towards accurate and efficient binding affinity prediction. BioRxiv 202506 (2025). 19. Swanson, K. et al. ADMET-AI: machine learning ADMET platform for evaluation of largescale chemical libraries. Bioinformatics 40, btae416 (2024). 20. Botti, R., Triscari, J., Pan, H. & Zayat, J. Concentrations of pravastatin and lovastatin in cerebrospinal fluid in healthy subjects. Clinical neuropharmacology 14, 256261 (1991). 21. OpenAI. Introducing chatgpt agent: Bridging research and action. https://openai.com/index/i ntroducing-chatgpt-agent/ (2025). 22. Gemini CLI Contributors. gemini-cli: An open-source ai agent that brings the power of gemini directly into your terminal. https://github.com/google-gemini/gemini-cli (2025). 23. Claude code. https://claude.com/product/claude-code (2025). 24. QwenLM Contributors. Qwen code. https://github.com/QwenLM/qwen-code (2025). 25. LangChain Contributors. Langchain: framework for developing language model applications. https://github.com/langchain-ai/langchain. 26. Deepset. Haystack: An open-source framework for building nlp-powered search systems. https://github.com/deepset-ai/haystack (2019). 27. Wu, Q. et al. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155 (2023). 28. Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D. & Ghanem, B. Camel: Communicative agents for mind exploration of large language model society. In Thirty-seventh Conference on Neural Information Processing Systems (2023). 29. Wang, Z. et al. Geneagent: self-verification language agent for gene-set analysis using domain databases. Nature Methods 19 (2025). 34 30. Wang, H., He, Y., Paula, C., Bucci, M. & other. Spatialagent: An autonomous ai agent for spatial biology. bioRxiv (2025). URL https://www.biorxiv.org/content/early/2025/04/01/202 4.04.01.646459. 31. Targets, O. 24.09 platform release now live. https://community.opentargets.org/t/24-09-platf orm-release-now-live/1556?ref=blog.opentargets.org (2024). 32. Pearce, J. D. et al. cross-species generative cell atlas across 1.5 billion years of evolution: The transcriptformer single-cell model. bioRxiv (2025). URL https://www.biorxiv.org/conten t/early/2025/04/29/2025.04.25.650731. https://www.biorxiv.org/content/early/2025/04/29/2 025.04.25.650731.full.pdf. 33. Li, M. M. et al. Contextual AI models for single-cell protein biology. Nature Methods 21, 15461557 (2024). URL https://doi.org/10.1038/s41592-024-02341-3. 34. DepMap, B. DepMap 24Q2 Public (2024). URL https://plus.figshare.com/articles/dataset/D epMap 24Q2 Public/25880521."
        }
    ],
    "affiliations": [
        "Broad Institute of MIT and Harvard, Cambridge, MA",
        "Department of Biomedical Informatics, Harvard Medical School, Boston, MA",
        "Harvard College, Harvard University, Cambridge, MA",
        "Harvard Data Science Initiative, Cambridge, MA",
        "Kempner Institute for the Study of Natural and Artificial Intelligence, Harvard University, Cambridge, MA",
        "MIT Lincoln Laboratory, Lexington, MA",
        "Massachusetts Institute of Technology, Cambridge, MA"
    ]
}