{
    "paper_title": "SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and Baseline Models",
    "authors": [
        "Dmitry Nechaev",
        "Alexey Pchelnikov",
        "Ekaterina Ivanova"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Advancing AI in computational pathology requires large, high-quality, and diverse datasets, yet existing public datasets are often limited in organ diversity, class coverage, or annotation quality. To bridge this gap, we introduce SPIDER (Supervised Pathology Image-DEscription Repository), the largest publicly available patch-level dataset covering multiple organ types, including Skin, Colorectal, and Thorax, with comprehensive class coverage for each organ. SPIDER provides high-quality annotations verified by expert pathologists and includes surrounding context patches, which enhance classification performance by providing spatial context. Alongside the dataset, we present baseline models trained on SPIDER using the Hibou-L foundation model as a feature extractor combined with an attention-based classification head. The models achieve state-of-the-art performance across multiple tissue categories and serve as strong benchmarks for future digital pathology research. Beyond patch classification, the model enables rapid identification of significant areas, quantitative tissue metrics, and establishes a foundation for multimodal approaches. Both the dataset and trained models are publicly available to advance research, reproducibility, and AI-driven pathology development. Access them at: https://github.com/HistAI/SPIDER"
        },
        {
            "title": "Start",
            "content": "SPIDER: COMPREHENSIVE MULTI-ORGAN SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS 5 2 0 2 4 ] I . e [ 1 6 7 8 2 0 . 3 0 5 2 : r Dmitry Nechaev*1, Alexey Pchelnikov1, and Ekaterina Ivanova1 1HistAI"
        },
        {
            "title": "ABSTRACT",
            "content": "Advancing AI in computational pathology requires large, high-quality, and diverse datasets, yet existing public datasets are often limited in organ diversity, class coverage, or annotation quality. To bridge this gap, we introduce SPIDER (Supervised Pathology Image-DEscription Repository), the largest publicly available patch-level dataset covering multiple organ types, including Skin, Colorectal, and Thorax, with comprehensive class coverage for each organ. SPIDER provides highquality annotations verified by expert pathologists and includes surrounding context patches, which enhance classification performance by providing spatial context. Alongside the dataset, we present baseline models trained on SPIDER using the Hibou-L foundation model as feature extractor combined with an attention-based classification head. The models achieve state-of-the-art performance across multiple tissue categories and serve as strong benchmarks for future digital pathology research. Beyond patch classification, the model enables rapid identification of significant areas, quantitative tissue metrics, and establishes foundation for multimodal approaches. Both the dataset and trained models are publicly available to advance research, reproducibility, and AI-driven pathology development. Access them at: https://github.com/HistAI/SPIDER."
        },
        {
            "title": "Introduction",
            "content": "Foundation models such as Vision Transformers [1] (ViTs) have revolutionized computer vision by enabling highly effective transfer learning. Unlike traditional end-to-end training, these models leverage two-stage pipeline where extensive pretraining on large-scale datasets extracts universal features, and task-specific fine-tuning adapts the model efficiently to new domains [2]. This approach significantly reduces computational costs, making state-of-the-art models accessible for real-world applications. Similarly, computational pathology (CPath) has increasingly embraced foundation vision models [3], leveraging their ability to efficiently generalize across diverse histopathological tasks. By fine-tuning these models on domain-specific datasets, researchers have achieved significant advancements in cancer subtyping, biomarker discovery, and automated diagnostics [4]. Motivated by these advancements, we sought to explore whether foundation models could also be effectively applied to whole slide image (WSI) analysis, specifically for whole slide image segmentation. One widely explored approach is using unsupervised clustering on the features extracted by these models, with the goal of automatically grouping similar tissue structures without requiring explicit labels [5]. The idea is that foundation models, pretrained on vast datasets, can produce meaningful feature representations that naturally separate different tissue types. In theory, this approach should provide way to segment WSIs without extensive manual annotation, making it an attractive option for large-scale pathology applications. However, our internal experiments revealed significant limitations in practice. dmitry@hist.ai alex@hist.ai kate@hist.ai SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS First, while clustering does create distinct groups, their biological meaning is unclear without expert pathologists manually annotating them. Second, often times multiple clusters may represent the same morphology, leading to redundant groupings. This means additional post-processing is needed to merge similar clusters. But most importantly, the quality of these clusters is often inadequate for real-world diagnostic applications. While simple structures like fat are relatively easy to detect, complex and clinically significant features, such as high-grade adenocarcinoma, are poorly segmented. This limits the usefulness of unsupervised clustering in pathology workflows, especially when precision is critical. Instead, more effective approach is to use foundation models in fully supervised manner. By creating patch-level dataset with expert-annotated labels, we can fine-tune pretrained foundation model without needing an extremely large dataset. Unlike training model from scratch, which requires vast amounts of data and computational power, this method takes advantage of the models existing ability to generalize well. Even with moderately sized dataset, the model can achieve strong performance due to the powerful feature representations learned during pretraining. Building on this approach: We introduce SPIDER, Supervised Pathology Image-DEscription Repository, the largest publicly available patch-level dataset for multiple organ types, including Skin, Colorectal, and Thorax, with comprehensive class coverage for each organ. Annotations were generated using semi-automatic pipeline with every patch being further validated by professional pathologists to ensure accuracy. Additionally, each patch includes context field of view, offering expanded context to enhance classification performance. We present baseline model architecture for patch-level classification, designed around the Hibou-L [6] foundation model. This architecture is capable of both patch classification and Whole Slide Image segmentation, leveraging the comprehensive set of classes which includes all major morphologies per organ. It serves as robust benchmark and starting point for further developments in digital pathology research. We open-source both the dataset and the baseline models to the research community, facilitating collaboration, reproducibility, and the advancement of methodologies in digital pathology."
        },
        {
            "title": "2 Related Work",
            "content": "Several patch-level histopathology image datasets have been introduced for classification tasks, each with different annotation types, scales, and focuses. We review the most relevant datasets and compare their characteristics to the proposed SPIDER dataset. 2.1 Lymph Node Metastasis (Camelyon16/PatchCamelyon) Camelyon16 [7] was one of the earliest large WSI datasets, containing 400 lymph node WSIs for detecting breast cancer metastases. Patches extracted from Camelyon16 form the PatchCamelyon (PCam) dataset [8], which includes 327,680 small image patches (9696 pixels) labeled binary for tumor vs. normal. These labels are derived from expert-annotated tumor regions in the WSIs. PCams strengths are its large scale and simplicity - it provides massive training set for binary classification and is easily trainable on single GPU. It is openly available under permissive license. However, PCam is limited to single binary task (metastasis detection in lymph nodes) with no multi-class differentiation. 2.2 Breast Cancer Histopathology (BreaKHis and BACH) Two prominent patch-level datasets target breast biopsy pathology: BreaKHis [9]: Contains 7,909 microscopic patch images from 82 patients, split into benign vs. malignant tumors (binary) with further 8 subclass labels for specific tumor subtypes. Images in BreaKHis come at four magnifications (40X, 100X, 200X, 400X), each image being approximately 700460 pixels. All images were annotated by pathologists, ensuring expert label quality. BACH (ICIAR 2018) [10]: Contains 400 high-resolution patches (20481536 pixels at 20X magnification) categorized into four classes: normal, benign, in situ carcinoma, and invasive carcinoma. Each images ground truth was confirmed by two expert pathologists, ensuring high annotation quality. BreaKHiss strengths lie in its inclusion of multiple tumor subtypes and expert-validated labels, enabling both binary and multi-class evaluation. Its multi-magnification nature tests model robustness across scales. However, BreaKHis is 2 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS relatively small (only few thousand patches) and focuses only on breast tissue, limiting its diversity. Similarly, BACH images are large and detailed, but the dataset is very small (N=400), making deep learning training challenging without augmentation. Both BreaKHis and BACH are publicly available under open licenses. 2.3 Colorectal Tissue Classification (NCT-CRC-HE-100K) The NCT-CRC-HE-100K (Kather) [11] dataset focuses on colorectal cancer tissue. It consists of 100,000 H&E-stained image patches (224224 pixels) extracted from 86 WSIs, along with an additional 7,180 patches from 50 WSIs as an independent validation set. All patches are labeled into nine tissue categories - including tumor epithelium, stroma, immune cells, and various normal tissues - based on manual region delineations by pathologists. The images were color-normalized for consistency. This datasets strengths include its large size (100k), multi-class granularity (covering tumor and microenvironment classes), and high-quality annotations (expert-drawn regions for each class). It is open access (with Creative Commons license) for easy availability. However, NCT-CRC-HE-100K is focused on single organ (colon). 2.4 Multi-Organ Cancer Datasets (LC25000 and Others) Multi-organ histopathology datasets are still rare. notable example is LC25000 [12], which contains 25,000 images (768768 pixels) equally divided into five classes: lung adenocarcinoma, lung squamous cell carcinoma, benign lung tissue, colon adenocarcinoma, and benign colon tissue. Each class has 5,000 patches, and all images were validated and made HIPAA-compliant for public release. LC25000s strength is its coverage of two organs (lung and colon) and both cancerous and normal tissues, offering simple multi-class classification task with balanced dataset. It is freely available (e.g., on Kaggle) for researchers. LC25000s images are relatively large but fewer in number compared to other datasets, and the number of classes is also limited. 2.5 Significance of the SPIDER Dataset Across existing patch-level datasets, common limitations include: Narrow scope, often only single organ Limited class coverage Modest dataset size The proposed SPIDER dataset overcomes these gaps. It provides diverse multi-class annotations verified by expert pathologists, ensuring high annotation quality. It is large-scale, on the order of hundreds of thousands of patches, making it larger than the biggest current datasets in sheer size. Importantly, SPIDER covers multiple organ types within one unified dataset, and has large class coverage per each which is unprecedented among publicly available patch-level histopathology collections. Moreover, since SPIDER has been annotated on private dataset, it has not been included in the training of existing models, making it particularly valuable for independent validation and benchmarking of such models. Finally, SPIDER is released under permissive open license, ensuring broad accessibility for both academic and clinical AI research. In summary, SPIDERs combination of annotation richness, scale, organ diversity, and availability makes it significant contribution. It enables more comprehensive training and evaluation of pathology classification models, addressing the weaknesses of earlier datasets and pushing the field toward more generalizable and robust histopathology AI systems."
        },
        {
            "title": "3 Dataset",
            "content": "3.1 Dataset description SPIDER is brand-new patch-level dataset curated from proprietary whole slide images (WSIs) with expert pathologist annotations. Each data point includes central 224224 patch captured at 20X magnification, along with class label. Additionally, it comes with 24 surrounding context patches of the same size, together forming composite 11201120 region. This context is important because some patches are difficult or even impossible to classify correctly on their own. simple example is distinguishing between fat tissue and empty background, which is often impossible from 224224 3 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS patch itself. And there are many more intricate cases where the context around the patch is required to correctly classify the patch itself. The importance of this context is further explored in Subsection 4.3. The dataset currently includes three organ types: Skin, Colorectal, and Thorax. We provide train-test split to ensure consistent benchmarking, but users can also merge and re-split the data as needed. The split is done at the slide level, meaning patches from the same WSI do not appear in both the training and test sets. We aim for an 80:20 train-test ratio, though the exact numbers vary slightly across tissue classes. Table 1: Dataset composition across organ types. Each central patch is extracted from WSI and is accompanied by 24 context patches, forming larger 11201120 region. Due to overlaps in context patches, the number of total unique patches is lower than basic estimate of total central patches 25."
        },
        {
            "title": "Skin\nColorectal\nThorax",
            "content": "131,164 63,989 63,319 28,690 13,193 14,988 159,854 77,182 78,307 2,696,987 1,039,150 599,459 3,784 1,719 411 24 14 Table 1 presents the total number of patches for each organ and their train-test split. It also includes the number of WSIs from which the patches were extracted and the total number of classes per organ. detailed breakdown of tissue classes and sample counts is available in Appendix A.1. Figure 1: Dataset preparation pipeline: Raw whole-slide images (WSIs) undergo expert annotation, patch extraction, feature embedding, and similarity-based retrieval. final verification step ensures high-quality labeled patches for training. 3.2 Data Preparation In order to create substantial patch-level dataset of high-quality, manually annotated image patches out of the original unannotated dataset we engage professional pathologists to perform the annotations. The process of creating training dataset for specific organ type involves the following steps: Raw Dataset Creation: We compile raw dataset consisting of H&E stained WSIs of the same organ type. Then with professional pathologists we form list of tissue morphologies relevant to that organ, so that it would cover the key morphologies which exist in that organ. SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS Slide Selection and Initial Annotation: WSIs are selected from the raw dataset based on their diagnosis. Pathologists then use the web-based HistAI CELLDX platform to identify and annotate (draw) regions containing the target morphology within the selected slides. Annotations are created using the polygon or brush tools, which enables pathologists to delineate precise mask regions around the region of interest. Target Mask Patch Generation: Using manual annotations from the initial annotation step, we generate non-overlapping 224224 patches at 20X magnification. Approximately 5001,000 patches per class are obtained at this stage, serving as target patches for the similarity-based patch retrieval step. Patch Extraction and Feature Indexing: Each WSI in the raw dataset is divided into 224224 pixel nonoverlapping patches. White background regions are excluded using Otsu thresholding. Each patch is then processed with the Hibou-L model to extract feature embeddings, which are stored in Faiss index [13] for efficient similarity-based searches. Similarity-Based Patch Retrieval: Utilizing the Faiss index, we perform similarity-based searches to identify patches across slides from raw dataset that closely resemble the target patches. This approach efficiently expands our dataset by identifying visually comparable patches from diverse set of slides. The retrieved patches are then filtered by pathologists. Binary Verification by Pathologists: To ensure data quality, pathologists conduct binary labeling task using HistAI patch annotation platform. Each patch is presented within 20162016 pixel context to provide spatial information. Pathologists determine whether the central patch belongs to the target class (e.g., Nevus), enabling them to verify thousands of patches per hour with high accuracy. Final Dataset Compilation: Upon completing the verification process, sufficiently large curated dataset of annotated patches is obtained. This dataset is then used to train models."
        },
        {
            "title": "4 Model",
            "content": "4.1 Model architecture We design our model architecture with the aim of effectively incorporating context patches surrounding each central patch, improving the classification accuracy of the central patch. Figure 2: Model architecture overview: The classifier processes central patch alongside surrounding context patches. Features are extracted using the Hibou-L model, and an attention-based classification head integrates context information to improve central patch classification. The proposed model consists of two main components: Hibou-L vision foundation model [6] as feature extractor and an attention-based classification head, as shown in Figure 2. 5 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS The input to the model is large patch of size 1120 1120 pixels, which is divided into 5 5 grid of smaller patches, each measuring 224 224 pixels. These smaller patches are processed individually by the feature extractor, generating embeddings for each patch. The central patch in the grid is the primary target for classification and the surrounding patches, known as context patches, provide additional information to help the model capture broader view improving its ability to classify the central patch. The embeddings from all patches (central and context) are stacked together and passed to the attention-based classification head. The attention mechanism enables the model to incorporate information from context patches for class prediction of the central patch. For each organ type, we train separate model on multi-class classification task. The model is optimized using cross-entropy loss function, which is standard method for handling multiple class labels. During training, we keep the Hibou feature extractor frozen and only train the classification head. This ensures that the model relies on the high-quality features learned during pretraining rather than modifying them which reduces overfitting to specific images. 4.2 Results The trained models demonstrate strong performance in the multi-class classification task. Table 2 presents the overall accuracy, precision, and F1 score for each organ on the test set. Detailed per-class metrics can be found in Appendix A.3. detailed description of the training configuration, including hyperparameter settings is provided in Appendix A.2 Table 2: Performance metrics of models across different organs on the test set. Accuracy, Precision, and F1 score are reported. Organ Accuracy Precision F1 Skin Colorectal Thorax 0.940 0.914 0. 0.935 0.917 0.958 0.937 0.915 0.960 4.3 Ablation Study Context patches play crucial role in enhancing model performance. To evaluate impact of the context, we trained models with different context sizes and assessed their accuracy on the test set. As shown in Table 3, reducing the context size leads to decline in model accuracy across all organs. The decrease is more pronounced when context is completely removed, demonstrating the importance of spatial context in model predictions. Table 3: Impact of context size on model accuracy across different organs. Larger context windows improve accuracy, emphasizing the importance of contextual information. Organ Large Context (11201120) Medium Context (672672) No Context (224224) Skin Colorectal Thorax 0.940 0.914 0.962 0.935 0.906 0.960 0.923 0.895 0.956 4.4 Usecases The model was trained on classification task, yet due to comprehensive class coverage in SPIDER, trained models applications go beyond simple patch classification: Rapid Identification and Explainable AI for Pathologists. The patch-level classification predictions can be aggregated into coarse segmentation mask, enabling pathologists to quickly locate potentially malignant or otherwise significant areas in Whole Slide Image (WSI). This visualization serves as heat map overlay, providing an intuitive representation of the models predictions. By highlighting abnormal regions, the model speeds up the review process, reduces the time to diagnosis, and enhances interpretability. Clinicians and researchers can validate AI-driven suggestions more efficiently, improving diagnostic confidence and workflow efficiency. Examples of WSI segmentation can be found at Appendix A.4. Quantitative Metrics for Research and Treatment Planning. Beyond simple detection, the models patchlevel insights enable automatic calculation of proportions such as tumor area, stromal content, and other 6 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS morphological components. These metrics can guide both clinical decisions (e.g., selecting patients for targeted therapies) and research studies (e.g., identifying biomarkers correlated with treatment response). Foundation for Multimodal and More Advanced Models. slide-level mosaic of patch labels yields highly detailed representation of tissue morphology. This labeled output can be used to train or augment multimodal models, including vision-language systems that require large amounts of paired text-image data. By automatically generating such pairs, the approach scales the development of richer AI solutions."
        },
        {
            "title": "5 Discussion",
            "content": "Our work introduces SPIDER, comprehensively annotated multi-organ histopathology dataset that addresses significant limitations in the computational pathology field. Through our experimentation and model development, we have identified several key insights and implications for future research. The Value of Supervised Approaches with Foundation Models Our supervised approach, leveraging foundation models, demonstrates strong performance. By creating an expert-annotated patch-level dataset and fine-tuning pretrained foundation model, we achieved high classification accuracy across multiple tissue types without requiring extremely large datasets. This approach effectively utilizes the generalization capabilities of foundation models. The Critical Role of Contextual Information The ablation study demonstrates that classification accuracy progressively decreases as contextual information is reduced, with the most pronounced effect occurring when context is completely removed. This finding aligns with how pathologists operate in clinical practice; they rarely examine tissue in isolation but consider surrounding structures to make accurate assessments. By incorporating larger 11201120 context window, our model can better mimic the holistic assessment approach used by expert pathologists. 5.1 Limitations and Future Work Despite the promising results, several limitations and opportunities for future work remain. First, while SPIDER covers multiple organ types, expanding to additional organs would further enhance its utility. Second, the current model architecture, while effective, could potentially be improved through more sophisticated attention mechanisms or alternative approaches to incorporating contextual information. Additionally, exploring the integration of clinical metadata with image features could enhance model performance and provide more clinically relevant insights. Future work should also investigate the models generalizability across different scanning systems, staining protocols, and patient populations. While our models demonstrate strong performance on the test set, broader validation across diverse real-world settings would further establish their robustness and clinical utility. 5.2 Conclusion SPIDER represents significant contribution to the field of computational pathology, providing comprehensive, multiorgan dataset with expert-validated annotations and crucial contextual information. Our baseline models demonstrate the effectiveness of combining foundation models with supervised learning approaches and highlight the importance of spatial context in accurate tissue classification. By making both the dataset and models publicly available, we aim to accelerate research in digital pathology and enable the development of more robust, clinically relevant AI tools. The promising results across diverse tissue types suggest that this approach could be extended to other organ systems, potentially transforming pathology workflows and enhancing both diagnostic accuracy and efficiency."
        },
        {
            "title": "Acknowledgements",
            "content": "This work would not have been possible without the dedication and expertise of our incredible team of pathologists: Elena Konovalova, Daria Shushkanova, Antonina Vedinova, Vasilii Fedotov, Galina Makarniaeva, and Aliaksandr Zhurauliou. Your meticulous annotations, patience, and deep knowledge brought SPIDER to life. We are truly grateful for the countless hours you spent ensuring the accuracy and quality of this dataset. Thank you for your hard work, attention to detail, and for making this project reality. 7 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS"
        },
        {
            "title": "References",
            "content": "[1] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale, 2021. URL https://arxiv.org/ abs/2010.11929. [2] Bernard Tomczyk, Plamen Angelov, and D. Kangin. Machine learning within latent spaces formed by foundation models. 2024 IEEE 12th International Conference on Intelligent Systems (IS), pages 110, 2024. doi:10.1109/IS61756.2024.10705264. [3] Hongming Xu, Qi Xu, Fengyu Cong, Jeong-Jin Kang, Chu Han, Zaiyi Liu, A. Madabhushi, and Cheng Lu. IEEE reviews in biomedical engineering, PP, 2023. Vision transformers for computational histopathology. doi:10.1109/RBME.2023.3297604. [4] Dibaloke Chanda, Milan Aryal, Nasim Yahya Soltani, and Masoud Ganji. new era in computational pathology: survey on foundation and vision-language models, 2024. URL https://arxiv.org/abs/2408.14496. [5] Jacob Gildenblat and Ofir Hadar. Segmentation by factorization: Unsupervised semantic segmentation for pathology by factorizing foundation model features, 2024. URL https://arxiv.org/abs/2409.05697. [6] Dmitry Nechaev, Alexey Pchelnikov, and Ekaterina Ivanova. Hibou: family of foundational vision transformers for pathology, 2024. URL https://arxiv.org/abs/2406.05074. [7] Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes van Diest, Bram van Ginneken, Nico Karssemeijer, Geert Litjens, Jeroen A. W. M. van der Laak, , and the CAMELYON16 Consortium. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. JAMA, 318(22): 21992210, 12 2017. ISSN 0098-7484. doi:10.1001/jama.2017.14585. URL https://doi.org/10.1001/ jama.2017.14585. [8] Bastiaan S. Veeling, Jasper Linmans, Jim Winkens, Taco Cohen, and Max Welling. Rotation equivariant cnns for digital pathology, 2018. URL https://arxiv.org/abs/1806.03962. [9] Fabio A. Spanhol, Luiz S. Oliveira, Caroline Petitjean, and Laurent Heutte. dataset for breast cancer histopathological image classification. IEEE Transactions on Biomedical Engineering, 63(7):14551462, 2016. doi:10.1109/TBME.2015.2496264. [10] Guilherme Aresta, Teresa Araújo, Scotty Kwok, Sai Saketh Chennamsetty, Mohammed Safwan, Varghese Alex, Bahram Marami, Marcel Prastawa, Monica Chan, Michael Donovan, Gerardo Fernandez, Jack Zeineh, Matthias Kohl, Christoph Walz, Florian Ludwig, Stefan Braunewell, Maximilian Baust, Quoc Dang Vu, Minh Nguyen Nhat To, Eal Kim, Jin Tae Kwak, Sameh Galal, Veronica Sanchez-Freire, Nadia Brancati, Maria Frucci, Daniel Riccio, Yaqi Wang, Lingling Sun, Kaiqiang Ma, Jiannan Fang, Ismael Kone, Lahsen Boulmane, Aurélio Campilho, Catarina Eloy, António Polónia, and Paulo Aguiar. Bach: Grand challenge on breast cancer histology images. Medical Image Analysis, 56:122139, 2019. ISSN 1361-8415. doi:https://doi.org/10.1016/j.media.2019.05.010. URL https://www.sciencedirect.com/science/article/pii/S1361841518307941. [11] Jakob Nikolas Kather, Niels Halama, and Alexander Marx. 100,000 histological images of human colorectal cancer and healthy tissue, April 2018. URL https://doi.org/10.5281/zenodo.1214456. [12] Andrew A. Borkowski, Marilyn M. Bui, L. Brannon Thomas, Catherine P. Wilson, Lauren A. DeLand, and Stephen M. Mastorides. Lung and colon cancer histopathological image dataset (lc25000), 2019. URL https: //arxiv.org/abs/1912.12142. [13] Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé Jégou. The faiss library. 2024. [14] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization, 2019. [15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding, 2019. URL https://arxiv.org/abs/1810.04805. SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS"
        },
        {
            "title": "A Appendix",
            "content": "A.1 Class distribution in organs Figure A1: Dataset skin class distribution 9 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS Figure A2: Dataset colorectal class distribution SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS Figure A3: Dataset thorax class distribution 11 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS A.2 Training details Table A1: Training hyperparameters Parameter Value Epochs Batch size Loss function Label smoothing Optimizer Learning rate Weight decay Learning rate scheduler Linear warmup + Cosine annealing Warmup epochs Mixed precision 10 256 Cross entropy 0.2 AdamW [14] 4 104 0."
        },
        {
            "title": "1\nFP16",
            "content": "Table A2: Model configuration Parameter Feature extractor Classification head Hidden size Number of hidden layers Number of attention heads Intermediate size Maximum position embeddings Hidden dropout probability Attention dropout probability Head dropout probability Value Hibou-L Bert [15] 128 1 1 128 25 0.5 0.3 0.3 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS A.3 Detailed metrics Class Actinic Keratosis Apocrine Glands Basal Cell Carcinoma Carcinoma In Situ Collagen Epidermis Fat Follicle Inflammation Invasive Melanoma Kaposis Sarcoma Keratin Melanoma In Situ Mercel Cell Carcinoma Muscle Necrosis Nerves Nevus Sebaceous Gland Seborrheic Keratosis Solar Elastosis Squamous Cell Carcinoma Vessels Wart Total Accuracy Precision 0.768 0.999 0.959 0.761 0.989 0.871 0.997 0.942 0.926 0.936 0.990 0.994 0.976 0.887 0.984 0.981 0.999 0.973 0.987 0.929 0.997 0.839 0.991 0. 0.940 0.817 0.999 0.913 0.698 0.992 0.933 0.998 0.953 0.974 0.937 0.906 0.977 0.962 0.998 0.984 0.954 1.000 0.981 0.984 0.914 0.988 0.826 0.991 0.772 0.935 F1 0.792 0.999 0.935 0.728 0.990 0.901 0.997 0.947 0.949 0.937 0.946 0.985 0.969 0.939 0.984 0.967 0.999 0.977 0.985 0.922 0.993 0.832 0.991 0.823 0.937 Table A3: Extended classification metrics for skin model. Class Adenocarcinoma High Grade Adenocarcinoma Low Grade Adenoma High Grade Adenoma Low Grade Fat Hyperplastic Polyp Inflammation Mucus Muscle Necrosis Sessile Serrated Lesion Stroma Healthy Vessels Accuracy Precision 0.861 0.819 0.805 0.915 0.994 0.833 0.978 0.895 0.981 0.977 0.889 0.977 0.961 0.963 0.848 0.762 0.865 0.997 0.866 0.959 0.818 0.970 0.976 0.961 0.970 0.969 F1 0.909 0.833 0.783 0.889 0.995 0.850 0.969 0.855 0.976 0.977 0.924 0.974 0.965 0.915 Total Table A4: Extended classification metrics for colorectal model. 0.914 0.917 13 SPIDER: SUPERVISED PATHOLOGY DATASET AND BASELINE MODELS Class Alveoli Bronchial Cartilage Bronchial Glands Chronic Inflammation + Fibrosis Detritus Fibrosis Hemorrhage Lymph Node Pigment Pleura Tumor Non-Small Cell Tumor Small Cell Tumor Soft Vessel"
        },
        {
            "title": "Total",
            "content": "Accuracy Precision 0.986 1.000 0.995 0.950 0.961 0.932 0.948 0.962 0.935 0.914 0.995 1.000 1.000 0.887 0.962 0.926 1.000 1.000 0.998 0.959 0.918 0.988 0.994 0.863 0.892 0.997 0.993 1.000 0.885 0.958 F1 0.955 1.000 0.998 0.973 0.960 0.925 0.968 0.978 0.898 0.903 0.996 0.996 1.000 0. 0.960 Table A5: Extended classification metrics for thorax model. A.4 Full-slide segmentation examples Figure A4: Example of full slide segmentation. Each color represents separate class."
        }
    ],
    "affiliations": [
        "HistAI"
    ]
}