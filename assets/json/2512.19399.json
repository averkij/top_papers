{
    "paper_title": "Brain-Grounded Axes for Reading and Steering LLM States",
    "authors": [
        "Sandro Andric"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, which can lack external grounding. We propose using human brain activity not as a training signal but as a coordinate system for reading and steering LLM states. Using the SMN4Lang MEG dataset, we construct a word-level brain atlas of phase-locking value (PLV) patterns and extract latent axes via ICA. We validate axes with independent lexica and NER-based labels (POS/log-frequency used as sanity checks), then train lightweight adapters that map LLM hidden states to these brain axes without fine-tuning the LLM. Steering along the resulting brain-derived directions yields a robust lexical (frequency-linked) axis in a mid TinyLlama layer, surviving perplexity-matched controls, and a brain-vs-text probe comparison shows larger log-frequency shifts (relative to the text probe) with lower perplexity for the brain axis. A function/content axis (axis 13) shows consistent steering in TinyLlama, Qwen2-0.5B, and GPT-2, with PPL-matched text-level corroboration. Layer-4 effects in TinyLlama are large but inconsistent, so we treat them as secondary (Appendix). Axis structure is stable when the atlas is rebuilt without GPT embedding-change features or with word2vec embeddings (|r|=0.64-0.95 across matched axes), reducing circularity concerns. Exploratory fMRI anchoring suggests potential alignment for embedding change and log frequency, but effects are sensitive to hemodynamic modeling assumptions and are treated as population-level evidence only. These results support a new interface: neurophysiology-grounded axes provide interpretable and controllable handles for LLM behavior."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 2 ] . [ 1 9 9 3 9 1 . 2 1 5 2 : r Brain-Grounded Axes for Reading and Steering LLM States Sandro Andric sandro.andric@nyu.edu"
        },
        {
            "title": "Abstract",
            "content": "Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, which can lack external grounding. We propose using human brain activity not as training signal but as coordinate system for reading and steering LLM states. Using the SMN4Lang MEG dataset, we construct word-level brain atlas of phase-locking value (PLV) patterns and extract latent axes via ICA. We validate axes with independent lexica and NER-based labels (POS/log-frequency used as sanity checks), then train lightweight adapters that map LLM hidden states to these brain axes without fine-tuning the LLM. Steering along the resulting brain-derived directions yields robust lexical (frequency-linked) axis in mid TinyLlama layer, surviving perplexity-matched controls, and brainvs-text probe comparison shows larger log-frequency shifts (relative to the text probe) with lower perplexity for the brain axis. function/content axis (axis 13) shows consistent steering in TinyLlama, Qwen2-0.5B, and GPT-2, with PPL-matched text-level corroboration. Layer-4 effects in TinyLlama are large but inconsistent, so we treat them as secondary (Appendix). Axis structure is stable when the atlas is rebuilt without GPT embedding-change features or with word2vec embeddings (ğ‘Ÿ = 0.640.95 across matched axes), reducing circularity concerns. Exploratory fMRI anchoring suggests potential alignment for embedding change and log frequency, but effects are sensitive to hemodynamic modeling assumptions and are treated as population-level evidence only. These results support new interface: neurophysiology-grounded axes provide interpretable and controllable handles for LLM behavior."
        },
        {
            "title": "1 Introduction",
            "content": "Most LLM interpretability discovers directions using text-derived labels or optimization objectives. Such directions can be effective yet are rarely grounded in external measurements of human cognition. We ask whether brain activity can define stable, externally grounded coordinate system that enables both reading and steering of LLM representations. Our key idea is to compute brain-derived atlas of semantic activity and use its axes as the target space for LLM projections. We do not optimize the LLM; instead we train lightweight adapter and test whether steering along those axes produces reliable, interpretable shifts in generated text. Contributions: - We build MEG-derived word-level brain atlas of PLV connectivity and extract latent axes with stability/robustness checks. - We show that lightweight adapter can map LLM hidden states into this brain axis space without fine-tuning. - We demonstrate robust steering for frequency-linked axis (TinyLlama L11) and cross-model steering for function/content axis (GPT2, Qwen0.5B, TinyLlama), including PPL-matched and brainvstext probe controls. Preprint."
        },
        {
            "title": "2 Related Work",
            "content": "Prior work aligns neural data with language models for encoding/decoding and representation comparisons [15, 8, 4, 2], uses brain data to interpret NLP models [17], and demonstrates semantic reconstruction from brain recordings [16]. Recent steering methods use activation-addition and contrastive vectors [19, 13]. Our contribution differs in two ways: (1) we derive axes from MEG connectivity geometry rather than textual supervision, and (2) we treat brain axes as fixed interface for reading and steering, not as reward for optimization."
        },
        {
            "title": "3 Dataset",
            "content": "We use SMN4Lang (OpenNeuro ds004078 v1.2.1) [20, 21], synchronized MEG/fMRI dataset of naturalistic story listening. We use preprocessed MEG sensor-level data and word-level timing annotations. The dataset includes 12 subjects and 60 stories."
        },
        {
            "title": "4.1 MEG PLV Atlas",
            "content": "We compute phase-locking value (PLV) in theta band (48 Hz) over sliding windows (2.0 length, 0.5 step) on gradiometer channels [10]. For each window, we compute PLV connectivity and compress the edge vector using PCA to 128 dimensions (edge-PCA). Filtering and analytic phase extraction are implemented with MNE-Python [5]. This yields time-indexed PLV state vector per run. 4.2 Word-Level Brain Atlas We align PLV windows to word-level timing annotations and build word-level atlas using ridge regression [6] with features: embedding change (GPT), word log-frequency, and POS id. Lags of 0.0, 0.5, and 1.0 are included. The model predicts PLV-PCA states per window; each window is assigned to the most recent word onset, and we average predicted PLV vectors by word type to obtain word-level atlas per subject. We use predicted PLV states (rather than single-trial PLV averages) to improve signal-to-noise and stabilize word-level estimates. Subject-level atlases are then averaged across subjects to form cross-subject atlas. To test circularity, we rebuild the atlas with embedding change removed (logfreq+POS only) and with word2vec embeddings [11], then align axes by correlation. Atlas predictions are generated out-of-fold by run (5-fold): for each fold, models are trained on subset of runs and used to predict held-out runs, and the word atlas is built from these OOF predictions (full-data weights are saved for reference). 4.3 Axis Discovery We apply ICA to the averaged word atlas and obtain latent axes [7]. We fix the number of components to 20 priori for stability across runs. We validate axes using independent label sources: CKIP POS/NER for function/content, noun/verb, and animate labels [9] (temporal heuristics used only for exploratory checks) MELD-SCH concreteness [18, 22] and Chinese valence/arousal lexica [24] Permutation tests confirm axis-label alignment. Axis labels in the paper (e.g., function/content, animacy) are assigned by the strongest atlaslabel association and are not selected using steering outcomes. Axis IDs refer to fixed ICA component indices; when comparing across layers or models, we align axis direction by correlation and report signed effects after alignment (orientation is arbitrary). 4.4 LLM Adapter We extract TinyLlama word-level hidden states for all stories [25] and map them to brain axes using ridge regression (standardized, alpha chosen by CV). This yields an adapter ğ‘“(â„) = ğ‘Š â„ + ğ‘ that predicts axis scores per word."
        },
        {
            "title": "4.5 Steering\nWe steer TinyLlama by adding a normalized axis vector to hidden states at selected layers\nduring generation. Concretely, for axis ğ‘˜ we use the corresponding adapter weight vector ğ‘Šğ‘˜\n(scaled back if standardization is used), L2-normalize it, and add ğ›¼ğ‘Šğ‘˜/â€–ğ‘Šğ‘˜â€– to the hidden\nstate at the chosen layer for all positions in each forward pass (prompt and generated tokens).\nWe test strengths {âˆ’5, âˆ’2, âˆ’1, 0, 1, 2, 5} over 50 prompts with 4 samples per strength (256\ntokens each) using batched generation, and evaluate:",
            "content": "Adapter-score shift (pos vs neg, t-test + permutation) Strength correlation Fluency (perplexity) shift Text-level POS/NER metrics We correct for multiple comparisons across layers and axes with FDR [1]."
        },
        {
            "title": "5.1 Axis Validation\nWord-level validation confirms strong axis-label alignment on non-POS lexica:",
            "content": "Animate vs inanimate (confound-controlled): axis 2, residualized ğ‘‘ = 0.53 (logfreq+surprisal+length), matched ğ‘‘ = 0.70 with CI [0.53, 0.86] (n=330) Lexical frequency: axis 15, ğ‘Ÿ = 0.51 with logfreq (n=13,632) Lexica validation: concreteness (axis 2, ğ‘Ÿ = 0.128, ğ‘ = 0.001), valence (axis 15, ğ‘Ÿ = 0.114, ğ‘ = 0.001), arousal (axis 15, ğ‘Ÿ = 0.084, ğ‘ = 0.001). Axis 15 is strongly frequency-linked, so valence/arousal effects are treated as secondary. POS-derived validations (function/content, noun/verb) are reported as sanity checks only (Appendix). Confound control shows that animacy is not driven by logfreq/surprisal/length: axis 2 remains significant after residualization (ğ‘‘ = 0.53, ğ‘ = 7.1 105), while axis 15 attenuates (residualized ğ‘‘ = 0.13, ğ‘ = 0.25). Out-of-fold (OOF) atlas predictions preserve the axis geometry: the best-match correlations for axes 13/19/15/2 are ğ‘Ÿ = 0.820.97 relative to the base atlas. For reproducibility we match OOF axes to the original indices by correlation (23, 1311, 155, 1912) and keep the base labels throughout the paper. in wPLI run (4 subjects, runs 1020, decim=5), the lexicalLeakage-robust control: frequency axis remains robust (ğ‘Ÿ = 0.744), while other axes show weaker correspondence (ğ‘Ÿ 0.350.48), suggesting non-lexical axes are less stable under leakage-robust connectivity at this reduced-data setting. 5.2 Embedding-Change Ablations Rebuilding the atlas without GPT embedding-change features (logfreq+POS only) or with word2vec embeddings yields axes highly correlated with the base atlas (ğ‘Ÿ = 0.820.95 for axes 13/19/15/2 under no-embedding, ğ‘Ÿ = 0.640.93 under word2vec), indicating the axis geometry is not driven by GPT features. Dropping POS features substantially alters the POS-linked axes (ğ‘Ÿ < 0.3), confirming these labels are not independent; we therefore do not treat POS-derived axis validation as primary evidence. Dropping log-frequency features markedly reduces lexical-axis alignment (axis 15 correlation drops to ğ‘Ÿ = 0.19), so we treat this axis as supervised rather than emergent. 5.3 Axis Reliability and Cross-Subject Generalization We ran rigorous reliability analysis with bootstrap confidence intervals and permutation tests across 60 axis-lexicon pairs. After FDR correction, 25/60 tests remain significant (expected 3 by chance). The strongest effects include concreteness (axis 2, ğ‘Ÿ = 0.128 with CI [-0.162, -0.092]), valence (axis 15, ğ‘Ÿ = 0.114 with CI [0.082, 0.141]), and arousal (axis 15, ğ‘Ÿ = 0.084 with CI [0.056, 0.114]). Partial correlations controlling for word length show negligible change for concreteness; axis 15 remains strongly tied to log frequency (ğ‘Ÿ = 0.51). 3 Cross-subject validation (odd vs even splits) shows 12 axis-dimension pairs replicating with ğ‘Ÿ > 0.05. We align axes by correlation and report absolute values to avoid sign ambiguity (ICA orientation is arbitrary). Examples include the matched concreteness axis (test ğ‘Ÿ = 0.079 0.014), valence axis (test ğ‘Ÿ = 0.093 0.023), and arousal axis (test ğ‘Ÿ = 0.083 0.005). This supports stable semantic structure across subjects."
        },
        {
            "title": "5.4 Adapter Transfer to LLM\nThe TinyLlama adapter generalizes to held-out words (9,149 matched words):",
            "content": "Axis 13: ğ‘Ÿ = 0.238 (ğ‘ < 1024) Axis 19: ğ‘Ÿ = 0.499 (ğ‘ < 10115) Axis 15: ğ‘Ÿ = 0.461 (ğ‘ < 1096) Axis 2: ğ‘Ÿ = 0.624 (ğ‘ < 10197) Cross-model transfer (Qwen2-0.5B). Using the same atlas, lightweight adapter trained on Qwen2-0.5B hidden states [23] also predicts brain axes on held-out words (9,149 matched): axis 13 ğ‘Ÿ = 0.264, axis 19 ğ‘Ÿ = 0.528, axis 15 ğ‘Ÿ = 0.435, axis 2 ğ‘Ÿ = 0.637 (all ğ‘ 1030). This supports the interface framing beyond single LLM. Steering in Qwen20.5B shows significant adapter-score shifts at layer 12 for axes 13/15/2 (perm ğ‘ 0.002), with axis 19 weaker (perm ğ‘ = 0.029), and strong axis 13 effect at layer 4. GPT-2 [14] shows consistent axis 13 effect across layers (best L6 ğ‘‘ = 0.30, perm ğ‘ = 0.001), while axis 15 is null in GPT-2. These results provide cross-model steering evidence for axis 13; axis 15 appears model-dependent (present in TinyLlama and Qwen0.5B, absent in GPT2). 5.5 Steering (Primary Evidence) Primary result: lexical frequency-linked (supervised) axis (axis 15) at TinyLlama layer 11 shows robust steering with PPL-matched confirmation and brainvstext probe eï¬€iciency advantage. We treat independent text-level metrics as primary evidence and use adapterscore shifts only as manipulation check. Layers tested: 4, 11, 20 (TinyLlama). In the batched 50-prompt run, axis 15 yields ğ‘‘ = 0.545 (perm ğ‘ = 0.001). Under PPL-matched controls with the same 50-prompt setup, the effect remains (ğ‘‘ = 0.571, perm ğ‘ = 0.001). brain-vs-text probe comparison at the same layer shows that the brain axis produces large log-frequency shifts with lower perplexity (ğ‘‘ = 0.9246; PPL ğ‘‘ = 0.2183), while text-only logfreq probe shifts in the opposite direction and increases PPL (ğ‘‘ = 0.3021; PPL ğ‘‘ = 0.4549). We therefore treat log-frequency as the primary independent outcome for axis 15 and use adapter-score shifts as manipulation check. To benchmark against standard representation engineering, we computed an Activation Addition (ActAdd) baseline using the mean difference between the top/bottom 50 log-frequency words at TinyLlama layer 11. As expected, this supervised ActAdd vector produced larger log-frequency shift (ğ‘‘ = 1.6666, perm ğ‘ = 0.001) [19]. The brain axis remained it significantly improved fluency competitive (ğ‘‘ = 0.9246) and differed in two key ways: (PPL ğ‘‘ = 0.2183, perm ğ‘ = 0.001), while ActAdd had no significant PPL effect (PPL ğ‘‘ = 0.0740, perm ğ‘ = 0.237), and the directions are nearly orthogonal (cosine similarity 0.0104). Across models, axis 13 (function/content) shows consistent steering: TinyLlama L11 (ğ‘‘ = 0.208, perm ğ‘ = 0.001), Qwen-0.5B L4 (ğ‘‘ = 0.436, perm ğ‘ = 0.001), and GPT-2 L6 (ğ‘‘ = 0.300, perm ğ‘ = 0.001). Perplexity-matched controls for axis 13 in TinyLlama L11 and Qwen L4 preserve the effect and yield strong text-level function/content shifts. Other layers and axes show weaker or inconsistent effects; full summaries appear in Appendix (Table 1, Fig. 1). TinyLlama layer 4 shows large raw shifts but sign flips and lower prompt-level consistency across axes; we therefore keep layer-4 effects as secondary evidence. model axis label selected layer Qwen2-0.5B 13 Qwen2-0.5B function_content lexical_freq 4 12 0.436 0.380 perm_p 0.000999 0.000999 model axis label selected layer Qwen2-0.5B 19 Qwen2-0.5B 2 GPT-2 GPT-2 GPT-2 GPT-2 TinyLlama TinyLlama TinyLlama TinyLlama 13 15 19 2 13 15 19 2 noun_verb animacy function_content lexical_freq noun_verb animacy function_content lexical_freq noun_verb animacy 16 12 6 6 3 12 11 11 11 11 0.212 0.181 0.300 -0.032 0.140 0.109 -0.208 0.545 0.316 0.194 perm_p 0.000999 0.002 0.000999 0.57 0.018 0.0509 0.000999 0.000999 0.000999 0. Selected layer per model and axis. For TinyLlama we report the primary layer (11) to avoid unstable layer4 effects. baseline, As (same prompts/strengths/samples/tokens) yields no effect (axis 15 random: ğ‘ = 0.88, ğ‘‘ = 0.02), indicating that arbitrary directions do not produce the observed shifts. matched random-direction steering run at layer 11 Figure 1: Layer 11 axis 15 steering curve (TinyLlama; batched 50 prompts). Adapter-score means are plotted per strength. 5 Figure 2: Eï¬€iciency comparison for brain axis, text probe, and ActAdd steering (TinyLlama L11). Brain-axis steering yields large log-frequency shift with improved perplexity; ActAdd yields larger shift with no significant PPL change. Figure 3: Selected-layer steering effects by model and axis (cell color encodes Cohen d; numbers show values). 5.6 Perplexity-Matched Controls The primary effect (layer 11, axis 15) remains significant under perplexity matching (see above). We also ran PPL-matched controls for axis 13 in TinyLlama L11 and Qwen L4; both preserve adapter-score effects and show strong text-level function/content shifts (Appendix). 5.7 External Text-Level Validation POS/NER metrics show partial external corroboration: Log-frequency mean: significant at layer 11 axis 15 (perm ğ‘ = 0.001; ğ‘‘ = 0.765) 6 Function/content ratio: significant at layer 11 axis 13 (perm ğ‘ = 0.001; ğ‘‘ = 0.739) and under PPL-matched controls in TinyLlama L11 and Qwen L4 (perm ğ‘ = 0.001) Animate rate: significant at layer 11 axis 2 (perm ğ‘ = 0.001; ğ‘‘ = 0.169) Noun ratio: significant at layer 11 axis 19 (perm ğ‘ = 0.001; ğ‘‘ = 0.817) and weaker at layer 4 axis 19 (perm ğ‘ = 0.015; ğ‘‘ = 0.156) These text-level shifts are treated as secondary evidence because adapter-score effects are the primary criterion; we therefore report both to avoid measurement-within-the-loop concerns. POS-based text metrics (function/content, noun ratio) are not independent because POS tags are used in atlas construction and are treated as sanity checks only. 5.8 fMRI Anchoring (Exploratory) We ran an encoding-based fMRI anchoring test (ridge) and varied the HRF. Using 4 peak HRF, pooled permutation tests across subjects and runs (n=240) show weak but significant effects for embedding change (observed mean abs corr 0.0888 vs null 0.0718, perm ğ‘ = 0.001) and log frequency (0.0815 vs 0.0725, perm ğ‘ = 0.009). POS id is not significant (perm ğ‘ = 0.152). Per-subject effects are inconsistent, so we treat fMRI anchoring as populationlevel evidence only; sensitivity analyses are in Appendix."
        },
        {
            "title": "6 Discussion",
            "content": "Brain-derived axes can steer LLM behavior without LLM fine-tuning. Strongest evidence appears for lexical (frequency-linked) axis in mid layer; the animacy axis (axis 2) is robust in the atlas but is not the strongest steering effect. Fluency-controlled analyses confirm the primary effect is not driven by perplexity shifts. External text metrics provide the primary independent validation, while adapter-score shifts are treated as manipulation checks. key concern is circularity: do brain-derived axes simply recover text statistics? The brain-vs-text probe comparison argues against this. The brain axis shifts log-frequency in the intended direction with lower perplexity cost (ğ‘‘ = 0.9246; PPL ğ‘‘ = 0.2183), while text-only logfreq probe shifts in the opposite direction and increases perplexity (ğ‘‘ = 0.3021; PPL ğ‘‘ = 0.4549). This suggests that mapping through neurophysiology can act as functional filter, isolating causal structure that direct text probe does not capture. Baseline comparisons also reveal distinct geometric mechanisms. The frequency axis (axis 15) is nearly orthogonal to the supervised ActAdd vector (cosine similarity 0.0104), yet both steer log-frequency. This suggests multiple frequency-related subspaces: direct statistical direction (ActAdd) and more naturalistic direction derived from the brain atlas. Steering along the brain-derived path significantly improves perplexity, while ActAdd yields no significant PPL change."
        },
        {
            "title": "7 Limitations",
            "content": "The atlas is sensor-space and may include field spread [12, 3]. Text-level metrics are limited by automatic tagging accuracy; we treat them as primary but imperfect evidence and use adapter-score shifts as manipulation checks alongside PPL controls. POS-derived validations are not independent because POS features are used in atlas construction; we report them as sanity checks only. Some axes show sign reversals across layers, reflecting orientation ambiguity or layer-specific encoding. The strongest steering axis is frequency-linked (supervised), so semantic purity is limited; future work should disentangle lexical confounds. Cross-model transfer is shown for adapter readout (Qwen2-0.5B), and cross-model steering is supported for axis 13 in Qwen2-0.5B and GPT-2, but axis 15 is model-dependent (present in TinyLlama/Qwen-0.5B, absent in GPT-2). fMRI anchoring yields weak global with inconsistent per-subject reliability. We do not claim exclusivity; other axes and layers may be steerable but did not meet our strict robustness criteria here."
        },
        {
            "title": "8 Ethics",
            "content": "The work uses public, de-identified neuroimaging data. Steering results are modest and should not be interpreted as mind-reading or behavioral prediction of individuals."
        },
        {
            "title": "9 Reproducibility",
            "content": "Code, configs, and minimal reproduction instructions are available at: https://github.com /sandroandric/Brain-Grounded-Axes-for-Reading-and-Steering-LLM-States.git. The repository documents required inputs and the command-line steps to reproduce all reported results."
        },
        {
            "title": "Layer Axis",
            "content": "ğ‘‘ perm ğ‘ 4 4 4 4 11 11 11 11 20 20 20 20 function_content lexical_freq noun_verb animacy function_content lexical_freq noun_verb animacy function_content lexical_freq noun_verb animacy 0.1922 -0.8490 -0.2726 -0.1227 -0.2079 0.5450 0.3163 0.1936 -0.1128 0.2580 -0.0106 0.1340 0.001998 0.001 0.001 0.03397 0.001 0.001 0.001 0.001998 0.04296 0.001 0.845 0. Full steering summary across layers and axes (TinyLlama, batched 50-prompt run). perm ğ‘ is from permutation tests on adapter-score shift; signs are reported after axis matching (orientation is arbitrary). 10.1 Appendix Baselines Baseline (TinyLlama L11, 50 prompts) logfreq ğ‘‘ logfreq ğ‘ PPL ğ‘‘ PPL ğ‘ Random dir. (axis 15) ActAdd (top/bot 50 logfreq) Brain axis (axis 15) -0.02 1.6666 0.9246 0.88 0.001 0.001 n/a -0.0740 -0.2183 n/a 0.237 0.001 Figure 4: Layer 4 steering effects for the function/content axis (left) and lexical frequency axis (right), aligned to the layer-11 axis orientation. Plots show adapter-score shift across strengths. Perplexity-matched checks for secondary effects: 8 TinyLlama L11, axis 13: adapter shift ğ‘‘ = 0.2355 (perm ğ‘ = 0.001); function/content ratio ğ‘‘ = 0.6086 (perm ğ‘ = 0.001). Qwen L4, axis 13: adapter shift ğ‘‘ = 0.4364 (perm ğ‘ = 0.001); function/content ratio ğ‘‘ = 1.0620 (perm ğ‘ = 0.001)."
        },
        {
            "title": "11 Supplementary fMRI Anchoring Sensitivity",
            "content": "HRF-off anchoring yields significant pooled effects (embedding change ğ‘ = 0.001, logfreq ğ‘ = 0.001, pos_id ğ‘ = 0.006) but with smaller absolute correlations. The default 6 peak HRF shows only marginal pooled effects (embedding change ğ‘ = 0.071, logfreq ğ‘ = 0.082, pos_id ğ‘ = 0.039). These variants reinforce that fMRI anchoring is weak and sensitive to HRF assumptions."
        },
        {
            "title": "References",
            "content": "[1] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: practical and powerful approach to multiple testing. Journal of the Royal Statistical Society: Series B, 57(1):289300, 1995. doi: 10.1111/j.2517-6161.1995.tb02031.x. [2] Charlotte Caucheteux and Jean-Remi King. Brains and algorithms partially converge in natural language processing. Communications Biology, 5:134, 2022. doi: 10.1038/s4 2003-022-03036-1. [3] Gemma L. Colclough, Matthew J. Brookes, Stephen M. Smith, and Mark W. Woolrich. symmetric multivariate leakage correction for meg connectomes. NeuroImage, 117: 439448, 2015. doi: 10.1016/j.neuroimage.2015.03.071. [4] Jon Gauthier and Roger Levy. Linking artificial and human neural representations of language. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 529539, 2019. doi: 10.18653/v1/D19-1050. [5] Alexandre Gramfort et al. Meg and eeg data analysis with mne-python. Frontiers in Neuroscience, 7:267, 2013. doi: 10.3389/fnins.2013.00267. [6] Arthur E. Hoerl and Robert W. Kennard. Ridge regression: biased estimation for nonorthogonal problems. Technometrics, 12(1):5567, 1970. doi: 10.1080/00401706.1 970.10488634. [7] Aapo Hyvarinen and Erkki Oja. Independent component analysis: algorithms and applications. Neural Networks, 13(4-5):411430, 2000. doi: 10.1016/S0893-6080(00)0 0026-5. [8] Shailee Jain and Alexander G. Huth. Incorporating context into language encoding models for fmri. In Advances in Neural Information Processing Systems 31 (NeurIPS 2018), pages 66286637, 2018. [9] CKIP Lab. Ckiptagger: Ckip neural chinese word segmentation, pos tagging, and ner, n.d. URL https://ckip.iis.sinica.edu.tw/service/ckiptagger/. [10] Jean-Philippe Lachaux, Eugenio Rodriguez, Jacques Martinerie, and Francisco J. Varela. Measuring phase synchrony in brain signals. Human Brain Mapping, 8(4): 194208, 1999. doi: 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C. [11] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Eï¬€icient estimation of word representations in vector space, 2013. [12] Guido Nolte, Ou Bai, Lewis Wheaton, Zoltan Mari, S. Vorbach, and Mark Hallett. Identifying true brain interaction from eeg data using the imaginary part of coherency. Clinical Neurophysiology, 115(10):22922307, 2004. doi: 10.1016/j.clinph.2004.04.029. [13] Nina Panickssery, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, and Alexander Matt Turner. Steering llama 2 via contrastive activation addition, 2023. 9 [14] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. OpenAI technical report, 2019. URL https://cdn.openai.com/better-language-models/language_models_are_unsup ervised_multitask_learners.pdf. [15] Martin Schrimpf et al. The neural architecture of language: Integrative modeling converges on predictive processing. PNAS, 118(45):e2105646118, 2021. doi: 10.1073/ pnas.2105646118. [16] Jerry Tang et al. Semantic reconstruction of continuous language from non-invasive brain recordings. Nature Neuroscience, 26:858866, 2023. doi: 10.1038/s41593-02301304-9. [17] Mariya Toneva and Leila Wehbe. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). In Advances in Neural Information Processing Systems (NeurIPS 2019), pages 1495414964, 2019. [18] Yiu-Kei Tsang et al. Meld-sch: megastudy of lexical decision in simplified chinese. Behavior Research Methods, 50:17631777, 2018. doi: 10.3758/s13428-017-0944-0. [19] Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David Udell, Juan J. Vazquez, Ulisse Mini, and Monte MacDiarmid. Steering language models with activation engineering, 2023. [20] Shaonan Wang, Xiaohan Zhang, Jiajun Zhang, and Chengqing Zong. synchronized multimodal neuroimaging dataset for studying brain language processing. Scientific Data, 9:590, 2022. doi: 10.1038/s41597-022-01708-5. [21] Shaonan Wang, Xiaohan Zhang, Jiajun Zhang, and Chengqing Zong. Openneuro ds004078 (smn4lang) v1.2.1, 2023. URL https://openneuro.org/datasets/ds004078. [22] X. Xu and J. Li. Concreteness/abstractness ratings for two-character chinese words in meld-sch. PLOS ONE, 15(6):e0232133, 2020. doi: 10.1371/journal.pone.0232133. [23] An Yang et al. Qwen2 technical report, 2024. [24] Liang-Chih Yu, Lung-Hao Lee, Shuai Hao, Jin Wang, Yunchao He, Jun Hu, K. Robert Lai, and Xuejie Zhang. Building chinese affective resources in valence-arousal dimensions. In Proceedings of NAACL-HLT 2016, pages 540545, 2016. [25] Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. Tinyllama: An opensource small language model, 2024."
        }
    ],
    "affiliations": [
        "New York University"
    ]
}