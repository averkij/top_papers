{
    "paper_title": "GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics",
    "authors": [
        "Modi Jin",
        "Yiming Zhang",
        "Boyuan Sun",
        "Dingwen Zhang",
        "MingMing Cheng",
        "Qibin Hou"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics. To address these issues, we first introduce GeoSeek, a new geolocation dataset comprising CoT data annotated by geographic experts and professional players. We further thoroughly explore the inherent characteristics of geographic tasks and propose a geo-similarity reward and a consistency reward assessed by a consistency agent to assist training. This encourages the model to converge towards correct answers from a geographic perspective while ensuring the integrity and consistency of its reasoning process. Experimental results show that GeoAgent outperforms existing methods and a series of general VLLMs across multiple grains, while generating reasoning that closely aligns with humans."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 3 1 ] . [ 1 7 1 6 2 1 . 2 0 6 2 : r GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics Modi Jin1, Yiming Zhang1, Boyuan Sun1, Dingwen Zhang2, MingMing Cheng1, Qibin Hou 1VCIP, School of Computer Science, Nankai University 2School of Automation, Northwestern Polytechnical University Corresponding author. Abstract: This paper presents GeoAgent, model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics. To address these issues, we first introduce GeoSeek, new geolocation dataset comprising CoT data annotated by geographic experts and professional players. We further thoroughly explore the inherent characteristics of geographic tasks and propose geo-similarity reward and consistency reward assessed by consistency agent to assist training. This encourages the model to converge towards correct answers from geographic perspective while ensuring the integrity and consistency of its reasoning process. Experimental results show that GeoAgent outperforms existing methods and series of general VLLMs across multiple grains, while generating reasoning that closely aligns with humans. Project Page: https://ghost233lism.github.io/GeoAgent-page Code: https://github.com/HVision-NKU/GeoAgent HVision@Nankai"
        },
        {
            "title": "1 Introduction",
            "content": "Geolocation [33, 83, 89] is an important computer vision task that aims to infer the geographical location of the image solely from its visual content [42, 56, 23, 51, 85]. Benefiting from its competitive nature, it attracts large player communities, such as GeoGuesser [2] and TuXun [4]. Early approaches [49] attempted to address geolocation by considering it as classification [44, 6, 5, 72, 66] or retrieval [33, 90, 30, 40, 41]. More recently, benefiting from the advances of large language models (LLMs) , vision large language models (VLLMs) [102, 52, 61, 104, 75] capable of integrating visual signals have demonstrated superior abilities in scene perception and understanding [46, 101, 63] compared to traditional approaches. Some approaches thus employ VLLMs [77] to tackle the geolocation task [47, 41, 22, 31, 74], aiming to achieve better performance in open environments. Particularly, with the emergence of reinforcement learningbased methods [50, 59, 28, 71], some approaches [84, 99] incorporate chain-of-thought (CoT) data [88, 43, 15, 100, 86] and reasoning processes [26, 16, 48] into geolocation. By interpreting visual cues, these methods construct rational and trustworthy logical chains for localization [48, 92], and have achieved breakthroughs in both performance and interpretability. Table 1 Comparison of Geolocation Datasets. CoT: chainof-thought data present. * denotes AI-generated core reasoning process. Location: natural-language place descriptions provided. Global: global geolocation dataset. Sampling: data sampling algorithm to eliminate geographic bias. Dataset CoT Location Global Sampling MP16 [45] OSV-5M [10] GeoGlobe [31] MP16-Pro [40] SF-IAL [93] Georanking [41] MG-GEO [22] MP16-Reason [48] GeoComp [74] GRE30k [84] GeoSeek(Ours) However, existing methods mostly rely on AI-generated CoTs to train the reasoning processes of VLLMs [84, 22], which may not fully align with genuine human reasoning and could potentially amplify the inherent biases of VLLMs. typical case is that traditional geolocation datasets usually provide only GPS coordinates or lack sufficiently finegrained annotations [33, 45, 10]. These annotations differ substantially from the natural language descriptions humans 1 Figure 1 GeoSeek Dataset. We train GeoAgent with GeoSeek, geolocation dataset with bias-reducing sampling and val-bench annotated with locatability and geographic elements. Remarkably, single image may contain multiple geographic elements. typically use to express geographic locations. Moreover, inferring precise locations from limited visual cues requires human-like reasoning, whereas CoTs generated purely by AI may deviate from authentic logical processes. Prior studies [97, 91, 17] have also noted that RL-based VLLMs often learn superficial formatting patterns rather than true reasoning capabilities. To overcome these limitations, we first construct new geolocation dataset, named GeoSeek. We collaborate with large number of geography experts and experienced geolocation game players to annotate the data with three levels of human-understandable reasoning granularity, including country, city, and precise location. These human reasoning processes are then standardized into unified CoT format using GPT-4o [60]. This dataset enables our approach to achieve more fine-grained and interpretable geolocation performance while aligning the reasoning behavior of VLLMs more closely with human cognition. For the training strategy, most RL-based approaches incorporate reward functions that evaluate positioning accuracy based solely on whether the texts are equal [84, 48]. However, this does not align with the characteristics of the geographic task because different natural language descriptions may refer to the same geographic location (e.g., Parvis NotreDame, 4 Place Jean-Paul-II and Notre-Dame de Paris). This reward is unreasonable because it overlooks the models efforts to converge on the correct answer. To solve the issue of non-unique mappings between natural language and geographic locations, we introduce geo-similarity. Specifically, geo-similarity comprises two components: spatial similarity and semantic similarity. Spatial similarity is function related to the distance between actual and predicted locations, while semantic similarity measures the degree of similarity between the prediction and the ground truth from textual perspective step by step. These components encourage the model to converge toward correct answers both physically and semantically. Considering the issue of maintaining the integrity and consistency of CoT, we introduce the consistency agent as means of enhancing the learning process of our GeoAgent. More precisely, the consistency agent attempts to derive answers from GeoAgents CoT without task-specific prior knowledge, thereby incentivizing GeoAgent to generate higher-quality reasoning processes that better support its conclusions. To sum up, the contributions of our research can be concluded as follows. We propose novel geolocation dataset, GeoSeek, that features CoT data labeled by geographic experts and geolocation game players, alongside benchmark obtained through more rational sampling strategy. We propose new RL-based training paradigm incorporating geo-similarity reward to judge predictions and consistency reward computed by dedicated consistency agent to ensure the integrity and consistency of CoT. We propose GeoAgent, method that not only enhances performance on the geolocation but also achieves finer granularity in geographic location output while enhancing CoT quality. 2 Figure 2 Data construction and training pipeline of GeoAgent. GeoSeek-CoT contains 10k high-quality reasoning processes labeled by geography experts and geolocation game players. GeoSeek-Loc includes 20k images for the cold start of GeoAgent-SFT. During the GRPO-based training, based on GeoAgent-SFT, we design the geo-similarity reward to encourage the model to converge towards correct answers both physically and semantically. Also, the consistency reward is introduced to keep the integrity and consistency of CoT."
        },
        {
            "title": "2 Related Work",
            "content": "2."
        },
        {
            "title": "Image Geolocation",
            "content": "Image geolocation is defined as the process of inferring geographic locations by observing geographical information in images. Many traditional approaches define this task as either classification [89, 83, 42] or retrieval [33, 9, 90, 54, 53]. Classification-based methods divide the Earth into grid of cells, assigning images to corresponding labels [44, 6, 5, 72, 66] while retrieval-based methods [103, 98, 18, 12, 64, 35] use images as queries to retrieve results from the database [37, 32, 13, 27, 24]. Recently, some studies have started to enhance this paradigm by adopting CLIP [93, 29, 14, 30] or RAG techniques [40, 41]. However, these approaches conflict with the natural reasoning processes of humans. To solve this problem, recent methods use VLLMs to achieve breakthroughs in both task performance and interpretability [74, 31, 94]. Some other methods also start to prompt VLLMs to output not only geographic locations but also the reasoning process [47, 22]. More recent methods train VLLMs with the GRPO strategy [73, 84, 48]. This RL-based training paradigm has been applied to enhance performance and aligning with human thinking. However, the challenges also exist in AI-generated CoT data and unreasonable training strategies. Based on this, we design novel training strategy from geographic characteristics, encouraging the model to converge toward the correct answer both spatially and semantically while keeping the integrity and consistency of CoT."
        },
        {
            "title": "2.2 Geolocation Dataset",
            "content": "[80, 87, 82, 81], Existing relevant datasets like IMG2GPS [33], suffer from excessive regional bias and low locatability. Although datasets such as MP16 [45, 40], OSV5M [10], GeoGlobe [31], GeoComp [74], and Georanking [41] attempt to alleviate the shortage of high-quality data, the lack of reasoning process makes them incapable of supporting RL-based approaches. More recently, MG-GEO [22], MP16-Reason [48], and GRE30k [84] have made contributions by introducing AI-annotated CoT data. Although they offer performance gains, the absence of fine-grained location annotations along with the biases inherited from VLLMs continues to impede their deployment in open-world settings. To conquer these issues, as shown in Tab. 1, we introduce GeoSeek, novel geolocation dataset, which contains CoT annotations from geographic experts and professional geolocation game players alongside finer-grained addresses. We also employ rational sampling methodology to mitigate regional data distribution biases."
        },
        {
            "title": "3 GeoSeek Dataset",
            "content": "Previous datasets [33, 80] suffer from coarse granularity, AI-generated CoT data, and suboptimal sampling strategies. Most existing datasets only provide city-level location an3 notations [10, 45], limiting the ability of models to learn fine-grained geographic prediction. Furthermore, if GRPObased methods rely solely on AI-generated CoT data, they may inherit biases present in the base models. Additionally, the uniform area-based sampling used in these datasets overlooks the fact that the distribution of street-view images is more strongly correlated with multiple geographic characteristics. To overcome the limitations , we introduce new dataset named GeoSeek, aimed at enhancing reasoning quality, annotation granularity, and sampling balance for geolocation tasks. It is combination of human-labeled CoT, fine-grained locations, and stratified sampling strategy considering population, land area and road mileage."
        },
        {
            "title": "3.1 GeoSeek-CoT",
            "content": "To obtain high-quality CoT data, we establish volunteer platform and invite great number of geographic experts and professional geolocation game players to provide their reasoning processes. Additionally, we obtain verified and publicly available reasoning process data from the GeoGuessr [2] and TuXun [4] communities. This results in 10k CoT data constructed jointly by human experts and experienced players and each entry consists of street-view images, GPS coordinates and three-level location labels with reasoning process. After annotation, we apply GPT-4o [36] for linguistic normalization and structural formatting, forming unified CoT template. Additional details about GeoSeekCoT and the annotation process are provided in the supplementary materials."
        },
        {
            "title": "3.2 GeoSeek-Loc",
            "content": "GeoSeek-Loc is designed for RL-based finetuning, making it crucial to develop well-designed sampling strategy that eliminates geographic bias [57, 76]. Most existing datasets perform uniform or area-based sampling, which neglects the impact of geographic characteristics such as population [8] and road mileage [39], especially given the widespread focus on street-view geolocation within the player community. In contrast, we propose multi-level hierarchical sampling strategy. First, the strategy calculates sampling weights for each country based on population, land area, and highway mileage. Then, each country is divided into equally sized grid cells. Each cell is assigned logarithmically proportional sampling weight to its population to reduce the excessive sampling concentration. The final GeoSeek-Loc contains 20,000 high-resolution street-view samples with global distribution. For the specific sampling formula, please refer to the supplementary materials."
        },
        {
            "title": "3.3 GeoSeek-Val",
            "content": "To evaluate model performance, we adopt the same stratified sampling strategy and extract an additional 3k samples from the OSV5M [10] dataset to form the GeoSeek-Val benchFigure 3 Inconsistent CoT and different descriptions of the same location. Left: incomplete and inconsistent CoT, Right: consistent CoT after training with the consistency agent. Meanwhile, different final answers probably refer to the same location (e.g., Hefei and Hefei City). Therefore, Geo-Similarity is introduced to solve this problem. mark, which emphasizes the evaluation models capability in street-view localization. Each sample is annotated with locatability score automatically assessed by GPT-4o [36], ranging from 0 to 10, where higher scores indicate easier localization. In addition, we categorize scenes based on their geographic elements such as manmade structures, natural landscapes, and other visual cues. Detailed statistics of difficulty and scene categories are presented in Fig. 1."
        },
        {
            "title": "4 Methodology",
            "content": "Our GeoAgent pipeline is illustrated in Fig. 2. It contains two-stage training process. In the first stage, cold start is employed using the high-quality reasoning dataset GeoSeekCoT. During this stage, we fine-tune Qwen2.5-VL-7B [11] for 2 epochs. The second stage involves GRPO [19] reinforcement learning for 1 epoch using the GeoSeek-Loc dataset. This stage enhances the models reasoning process through the geo-similarity reward function, which consists of spatial and semantic similarity, facilitating the convergence of the model toward correct spatial and semantic answers. In addition, we propose the consistency reward assessed by consistency agent , which is designed to direct GeoAgent towards the generation of reasoning processes of higher quality and supporting its conclusions."
        },
        {
            "title": "4.1 Overall Rewards",
            "content": "In GRPO-based approaches, the policy is refined by comparing candidates that are drawn as group. For every query, 4 Figure 4 Discussion of reward functions. The two scatter plots respectively reveal the reasons for the unreasonable directly-judge reward and the positive effect of semantic similarity reward. We also demonstrate the curve of reward value changes over training steps, reflecting the importance of applying consistency reward to enable the model to establish complete reasoning framework. the algorithm first samples batch of candidate replies and scores them with verifiable rewards {Ri}G i=1, thereby enabling intra-group comparison. The normalized advantage of reply is then computed as: Ai = Ri mean(Rj) std(Rj) , (1) which quantifies how much this reply outperforms or underperforms its peers. During optimization, the same advantage Ai is broadcast to every token of reply i, and the policy network is updated with PPO-like objective: JG(θ) = E(cid:2)min(cid:0)ri,tAi, clip(ri,t, 1 ε, 1 + ε)Ai (cid:1)(cid:3) , (2) where ri,t is the importance weight between the new and old policies, and the clipping threshold ε keeps the update conservative for stability. Previous works [48, 84, 96] design reward functions that directly-judge whether texts are equal to enhance models geolocation capabilities. However, this overlooks the characteristics of the geographic task because multiple locations can correspond to the same geographic position. Based on this insight, we develop the geo-similarity reward that measures the similarity between the models response and the correct answer. Specifically, it contains two components: spatial similarity Rspa and semantic similarity Rsem. Additionally, we also design the consistency reward Rcon to maintain the integrity and consistency of CoT. Finally, the reward function can be expressed as: = a1Rspa + a2Rsem + a3Rcon, (3) where a1, a2, a3 are weights controlling the importance of three components, which are 1.5, 1.0 and 0.5, respectively."
        },
        {
            "title": "4.2 Geo-Similarity Reward",
            "content": "Spatial similarity. To overcome the issue of non-unique mapping, we obtain the corresponding latitude ˆλ and longitude ˆϕ for the models predictions through OpenCage [3] inverse geocoding. Then, the spatial distance between the predicted location (ˆλ, ˆϕ) and the corresponding ground truth location (λ, ϕ) is calculated as below [38]: = 2r arcsin (cid:114) sin2 ϕ 2 + cos ˆϕ cos ϕ sin2 λ , (4) where = 6371km denotes the mean Earth radius and is the difference. The spatial similarity reward is defined as: (cid:32) Rspa = exp D(cid:0)(ˆλ, ˆφ), (λ, φ)(cid:1) τ (cid:33) , (5) where τ is temperature parameter controlling the reward sharpness. Rspa exhibits nonlinear relationship with distance, specially increasing more slowly as the distance to the ground truth decreases. This encourages the model to identify broad range of predictions before progressively narrowing it down, which aligns with human thinking. Semantic similarity. To further enhance the models ability to generate standardized address names and improve its robustness against ambiguous or alias geographic names, we introduce the semantic similarity reward [58, 21, 69]. We employ the multilingual semantic encoding model [69, 70] to encode each level of the address into vector representations hpred . Then, we compute the cosine similarity between each pair of embeddings: and hgt si = hpred hpred hgt hgt . (6) To suppress over low-quality results, we apply threshold to filter similarity ˆsi greater than δ. Additionally, hierarchical strategy is employed, which ensures that lower-level address components are only rewarded when higher-level predictions are not entirely wrong. Finally, the semantic similarity reward is computed as: Rsem = 3 (cid:88) i=1 αi ˆsi, (cid:88) αi = 1, (7) 5 Table 2 Zero-shot Geolocation results on IM2GPS3K [33] and GeoSeek-Val. indicates the model is not publicly accessible. , and represent LoRA [34], QLoRA [20] and full fine-tuning, respectively. Best and second-best results are in bold and underlined. Models Dataset Size IM2GPS3K (% @km) GeoSeek-Val (% @km) City Region Country Continent City Region Country Continent Geoscore 25km 200km 750km 2500km 25km 200km 750km 2500km 0-5k GeoDecoder [18] GeoCLIP [14] Translocator [65] PIGEOTTO [30] G3 [40] MP-16 MP-16 MP-16 MP-16 MP-16 4M 33.50 4M 34.47 4M 31.10 4M 36.70 4M 40.94 - - - - - - - - 21.93 23.36 28.53 20.10 Qwen2.5-VL-7B [11] Qwen2.5-VL-32B [11] Gemma3-27B [78] InternVL3-14B [105] GeoReasoner [47] 133K 26.94 GaGA [22] 5M 33.00 GRE-Suite-SFT [84] 20K 29.30 GRE-Suite [84] 30K 35.30 GLOBE [48] 33K 40.18 GeoAgent-SFT (Ours) GeoSeek-CoT 10K 32.77 GeoAgent (Ours) 30K 40.75 GSV MG-Geo GRE-CoT GRE MP-16 Reason GeoSeek 45.90 50.65 46.70 53.80 55.56 29.93 30.35 41.74 27. 36.63 48.00 44.78 51.70 56.19 45.42 58.57 61.00 69.97 58.90 72.40 71.24 43.08 43.46 57.95 40.89 52.27 67.10 62.43 69.30 71.45 62.65 76.21 76.10 83.82 80.10 85.30 84.68 60.68 59.70 73.64 59. 78.65 82.10 78.81 85.67 82.38 81.33 89.90 - 11.82 - - - 3.57 4.06 11.69 3.43 13.55 - - - 10.75 10.36 15.69 - 29.04 - - - 7.95 7.43 25.48 7. 27.86 - - - 21.20 23.84 33.39 - 56.13 - - - 20.03 16.10 49.52 18.69 53.54 - - - 39.17 47.12 60.37 - 79.13 - - - 44.96 39.06 71.79 43. 77.63 - - - 61.44 64.98 81.72 - 3172.3 - - - 1622.0 1413.5 2704.0 1549.1 3083.9 - - - 2412.5 2968.9 3314.1 where αi represents the weight assigned to each level i. The semantic similarity reward effectively compensates for the limitations of spatial similarity in semantic understanding. It enables the model to achieve correct reward signals even in the presence of aliases, abbreviations, or translation variations. This encourages the generation of more standardized and semantically coherent geographic descriptions. Discussion. In Fig. 4, we visualize the correlation between the directly-judge reward proposed by previous methods and our proposed semantic similarity reward and spatial similarity reward under the same dataset. Spatial similarity reward is function directly related to distance difference, reflecting the models geographic positioning capability. Therefore, the reward trend directly impacting the models geolocation capabilities should align with it. However, Fig. 4 (a) clearly demonstrates that directly-judge reward exhibits severe inconsistencies with spatial similarity due to the non-unique mapping between descriptions and locations. Therefore, it is unreasonable to use it to enhance geolocation capabilities, and the results in the Tab. 3 also prove this. In contrast, as shown in Fig. 4 (b), the trends of semantic similarity rewards and spatial similarity rewards are highly consistent. This further explains the positive effect of semantic similarity rewards on the model."
        },
        {
            "title": "4.3 Consistency Reward",
            "content": "As shown in Fig. 13, one possible reason for inconsistent reasoning processes is that the geo-similarity reward represents the relationship between images and geographic locations. Figure 5 GeoScore on GeoSeek-Val. We compare different models in multiple locatabilities and geographic elements. However, we also need to establish the relationship between images and geographic clues. This involves progressively narrowing down potential geographic areas before establishing connection to specific location. Therefore, we propose the consistency reward, assessed by consistency agent that only obtains reasoning processes output by the GeoAgent but not its conclusions, as shown in Fig. 2. The consistency reward Rcon is defined as: (cid:16) (cid:17) (cid:88) (cid:88) Rcon = 1 ˆyi = yi wi pi, wi = 1, (8) 6 Table 3 Ablation study results reported on GeoSeek-Val. Best and second-best results are in bold and underlined. Models SFT COT GRPO Spa. Reward Sem. Reward Con. Reward Qwen2.5-VL-7B [11] GeoAgent-SFT GeoAgent w/o Spa & Con GeoAgent w/o Sem & Con GeoAgent w/o Con GeoAgent w/o Spa & Sem GeoAgent w/o SFT GeoAgent Metrics Region Country 3.36 23.84 26.56 31.51 31. 20.03 23.94 33.39 11.13 47.12 55.55 59.86 60.20 40.43 58.23 60.37 City 1. 10.36 11.99 14.46 14.69 9.08 13.39 15.69 Table 4 Discussion of geo-similarity and directly-judge on GeoSeek-Val. The judge means replacing the geo-similarity reward with directly-judge reward. Models Qwen2.5-VL-7B [11] GeoAgent-SFT GeoAgent-SFT + Judge GeoAgent-SFT + Judge + Con GeoAgent w/o Con GeoAgent Metrics Region Country 3.36 23.84 26.87 26.13 31.39 32.53 11.13 47.12 50.81 51.76 60.20 60. City 1.39 10.36 12.35 11.04 14.69 15.36 where 1[] denotes the indicator function that evaluates to 1 if the models predicted conclusion ˆyi matches the ground-truth conclusion yi, and 0 otherwise. The weight wi corresponds to the importance of the i-th geographic granularity level (i.e., country, region, or precise location). Additionally, pi is penalty term introduced to discourage the model from generating overly simplistic reasoning processes that could evade detection by the consistency agent (such as outputting only final conclusion). This factor is value proportional to the i-th level length ℓi of the reasoning process and can be expressed as: pi = 1 1 + exp (cid:0)λ(ˆℓ µ)(cid:1) , ˆℓ = ℓi min(ℓ) max(ℓ) min(ℓ) , (9) where λ and µ are the parameters of the control curve. The consistency reward models the relationships from images to geographic clues, from clues to layer-by-layer analyses, and finally to geographic locations. This ensures the integrity and consistency of the CoT at each level. Discussion. As shown in Fig. 4, when training progresses, the consistency reward converges first. This enables the model to gradually establish complete and consistent reasoning process. Compared to the model without consistency reward, both spatial and semantic similarity rewards remain lower than the existing model before the consistency reward converges. However, after convergence, these rewards begin to increase and surpass the model without consistency reward. This explains how consistency rewards positively impact the models geolocation capabilities."
        },
        {
            "title": "5.1 Experimental details",
            "content": "Implementation details. GeoAgent is fine-tuned upon Qwen2.5-VL-7B [11] using LoRA [34] with rank of 64 and alpha of 128, while the consistency agent utilizes the GPTQ-INT4 [25] quantized version of Qwen3-32B [95]. Evaluation settings. An evaluation of GeoAgent is conducted using public benchmark IMG2GPS3K [33] and GeoSeek-Val. In accordance with previous studies [48], we employ the City (25km), Region (200km), Country (750km) and Continent (2500km) accuracy on IM2GPS3K [33]. Furthermore, on GeoSeek-Val, we report the GeoScore, widely utilized metric in the geolocation community. The scale ranges from 0 to 5000. The formula is as follows: GeoScore = 5000 exp (cid:18) (cid:19) , 10 dmax (10) where represents the distance between the predicted location and the actual location (in kilometers), while dmax denotes the scale. For global geolocation, dmax is typically set to 18,050 km. We utilize OpenCage [3] for geocoding and inverse geocoding."
        },
        {
            "title": "5.2 Main Results",
            "content": "Performance on Public Benchmarks. We perform comparative analysis of GeoAgent with multiple approaches in Tab. 2, including traditional methods, general VLLMs, and geolocation-specific VLLMs. With only using LoRA [34] fine-tuning (1.91% Paras), GeoAgent achieves considerable performance improvement on the IM2GPS3K [103] 7 Figure 6 Reasoning comparison of six different models (GPT-5 [62], Gemma3 [78], Kimi [79], Qwen2.5-VL-32B [11], GeoAgent and GeoAgent with only SFT). Green: correct reasoning, Yellow: reasoning with certain issues, Red: reasoning that deviates significantly. Notably, brown highlights instances where the reasoning process is incomplete or inconsistent with the result. (e.g., 72.40 76.21 on country accuracy ), surpassing series of full fine-tuning methods. It is also worth noting that GeoAgent demonstrates significantly greater performance improvements at the macro level compared to the fine level. This is because the geographical similarity reward gradually decelerates as distance decreases, prompting the model to first determine coarse-grained location. In fact, in geolocation competition, country-level precision positioning is sufficient to outperform the most exceptional players. Performance on GeoSeek-Val. We compare the accuracy of GeoAgent and other methods on GeoSeek-Val in Tab. 2. Also, we report their GeoScore on splits categorized by locatability and geographic elements in Fig. 5. The results demonstrate that GeoAgent significantly exceeds other models on the street-view geolocation benchmark (e.g., 56.13 60.37 on country accuracy). In addition, the results shown in Fig. 5 demonstrate that GeoAgent surpasses other models across all locatability and geographic element splits. This indicates that GeoAgent possesses superior understanding of various geographic elements. Furthermore, the phenomenon where GeoAgent outperforms other models more significantly on splits with higher locatability suggests that GeoAgents thinking patterns are closer to those of humans. Dataset Quality. As shown in Tab. 2, our GeoAgent with only SFT achieves performance surpassing other methods with only SFT (GeoReasoner [47], GaGA [22] and GREsuite-SFT [84]) despite operating on significantly less data (10K vs 20K, 133K, 5M). This fully demonstrates the high quality of the data annotated by GeoSeek-CoTs geographic experts and geolocation game players."
        },
        {
            "title": "5.3 Ablation Analysis",
            "content": "Ablation study of components. In Tab. 3, we discuss the effectiveness of the reward function we propose. It can be seen that Rspa, Rsem, and Rcon each contribute to performance improvements. Among these, Rspa delivers more significant performance improvement than Rsem. This is primarily because Rspa is distance-dependent function that serves as direct reward signal, whereas Rsem focuses on semantic robustness. When applied independently, Rcon causes slight decrease in performance. This can be attributed to it imposes constraints on consistency rather than directly addressing geolocation capabilities. However, when combined with Rspa and Rsem, it brings noticeable improvements, especially at the regional and city levels, where inconsistencies are more frequent than at the country level. Cold Start. Using GeoSeek-CoT for SFT-based cold start enables the model to establish reasoning framework, which aligns closely with human thinking patterns. The results in Tab. 3 indicate that cold starts can significantly enhance the base models performance (e.g., 11.13 47.12 on country accuracy). At the same time, models lacking cold start capabilities will experience decline in performance. This demonstrates the importance of establishing reasoning framework during the cold start phase. Discussion of Geo-Similarity and Directly-Judge. To demonstrate that the geo-similarity reward function better aligns with the characteristics of geographic tasks, we compare it with reward function that directly-judges whether texts are identical at each level. As shown in Tab. 6, the performance improvement from the directly-judge reward is 8 significantly smaller than that from the geo-similarity reward (e.g., 50.81 and 60.37 on country accuracy). This is because the directly-judge reward is overly strict, overlooking the models efforts when it is not entirely correct but is moving toward the correct answer. Geo-similarity, on the other hand, evaluates the similarity between predictions and answers from both distance and semantic perspectives. It encourages the models positive efforts while mitigating the negative impact of cross-language and aliasing issues on stability in geographic tasks. This underscores the necessity of designing training methods tailored to geographic characteristics for geographic tasks."
        },
        {
            "title": "5.4 Qualitative Comparisons",
            "content": "As shown in Fig. 6, we compare the reasoning processes of GeoAgent, GeoAgent with only SFT, and other general VLLMs to the same image. Compared to other models, GeoAgent exhibits clearer hierarchical reasoning process, enabling it to better capture the relationship between geographic characteristics and geolocation. Notably, after GRPO training, GeoAgent not only enhances its ability to identify geographic features but also overcomes the shortcomings of incomplete and inconsistent reasoning process."
        },
        {
            "title": "6 Conclusions",
            "content": "This paper proposes GeoAgent, model capable of thinking like humans and providing geographic location. We propose GeoSeek, novel dataset with annotated CoT from human geographic experts and geolocation game players. In training, we employ two-stage training combining SFT with GRPO fine-tuning. Considering the non-uniqueness of descriptions and location mappings , we introduce the geo-similarity reward. In addition, we introduce the consistency reward to ensure the consistency of CoT. Experimental results demonstrate that GeoAgent achieves outstanding performance on multiple benchmarks."
        },
        {
            "title": "7 Acknowledgments",
            "content": "This work was supported by NSFC (No. 62225604 and No. 62495061), and the Fundamental Research Funds for the Central Universities (Nankai University) under Grant 070-63253220. We sincerely thank Yue Zhang, H.M., Haowen He, Yuke Jun, and other experts in geography, as well as outstanding geolocation game players, for their valuable guidance, prompt design suggestions, and data support throughout the construction of the GeoSeek dataset. We also thank Zhixiang Wang, Chilin Chen, Jincheng Shi, Liupeng Zhang, Yuan Gu, Yanghang Shao, Jinhua Zhang, Jiachen Zhu, Gucheng Qiuyue, Qingyang Guo, Jingchen Yang, Weilong Kong, Xinyuan Li, and Dawei Xu for their outstanding contributions in providing high-quality reasoning process data."
        },
        {
            "title": "Appendix",
            "content": "In order to provide more complete illustration of the details and capabilities of GeoAgent, comprehensive appendix has been developed. This appendix includes detailed descriptions of the implementation, evaluation benchmarks, our proposed dataset GeoSeek, additional experiments analysis, variety of success or failure cases and the discussion of our model."
        },
        {
            "title": "A More Implementation Details",
            "content": "A.1 Configuration and Hyper-parameters During training, we employ the AdamW [55] optimizer with an initial learning rate of 1e-5 and utilize deepseedzero3 [68, 67] for GPU memory optimization. Training and testing are performed on CentOS 7. For training, we utilize 8 NVIDIA A40 GPUs, while all evaluations are conducted on 2 NVIDIA A40 GPUs. The meanings and specific values of the hyperparameters mentioned in this paper and used in training and evaluation are shown in Tab. 5. A.2 Prompts of Different Stages In Fig. 7, we present the prompts used in the SFT and GRPO stages. In Fig. 8, we present the prompts used for locatability scoring and category annotation. A.3 Introduction to IM2GPS3K The IM2GPS3K dataset is subset of the IM2GPS [33] dataset, comprising 3,000 geo-tagged images commonly used as benchmark dataset for image geolocation. It is extracted from collection of 6 million images sourced from Flickr [1]. This dataset is widely employed in numerous image geolocation studies to evaluate model performance across different geographic thresholds."
        },
        {
            "title": "B Details of GeoSeek",
            "content": "B.1 Sampling Algorithm In contrast to traditional uniform sampling, we propose multi-level hierarchical sampling strategy during the construction of GeoSeek-Loc and GeoSeek-Val. First, the strategy calculates sampling weights for each country based on population [8], land area, and highway mileage [39]. Subsequently, each country is divided into equally sized grid cells. Each cell is assigned logarithmically proportional sampling weight to its population to reduce the excessive sampling concentration. At the country level, the number of 9 Table 5 The values of each hyperparameter. Symbol Description a1 a2 a3 τ α1 α2 α3 δ1 δ2 w1 w2 w3 β weight of Rspa weight of Rsem weight of Rcom Earths radius temperature parameter of Rspa weight of Country level in Rsem weight of Region level in Rsem weight of Precise level in Rsem Country-level threshold in Rsem Region-level threshold in Rsem weight of Country level in Rcon weight of Region level in Rcon weight of Precise level in Rcon Group size of GRP Temperature of GRP KL coefficient of GRP Value 1.5 1.0 0.5 6371km 200 0.1 0.6 0.3 0.7 0.5 0.1 0.6 0.3 8 0.7 0.001 tains 10,000 CoT data points with high-quality human annotations, approximately 6,000 of which originate from our collaborating geographic experts and volunteer geolocation game players. Approximately 4,000 are sourced from publicly available geolocation game guide websites [2, 4, 7]. To ensure regional balance, when constructing GeoSeek-Loc, we combine samples from OSV5M [10] and GeoComp [74] using sampling algorithm proposed in B.1. Specifically, 12,500 samples are drawn from the OSV5M [10] dataset and 7,500 from the GeoComp [74] dataset, both following the aforementioned multi-level hierarchical sampling approach. The final GeoSeek-Loc contains 20,000 highresolution street-view samples with global distribution. Similarly, our evaluation set GeoSeek-Val also adopts the stratified sampling algorithm, selecting 3,000 data samples from OSV5M [10]. Table 6 SFT results of different base models on GeoSeek-Val. B.3 Data Collection and Annotation Process Models Metrics City Region Country Qwen2.5-VL-7B [11] InternVL3-8B [105] Gemma3-12B [78] GeoAgent-SFT InternVL3-8B + SFT [105] Gemma3-12B + SFT [78] GeoAgent 1.39 3.79 10.28 10.36 6.14 13.07 15. 3.36 7.35 22.37 23.84 14.94 27.64 32.53 11.13 16.10 46.51 47.12 32.86 57.67 60.37 In developing GeoSeek-CoT, we collaborate with group of geographic experts and professional geolocation gamer players to build volunteer platform. Volunteers are tasked with providing three-levels geographic resolution for images (country, region, precise location). Country-level resolution was mandatory, while the reasoning behind regional and precise location classifications is left to the volunteers discretion based on the images locatability. Subsequently, reasoning processes are processed through GPT-4o [60] to standardize it into the CoT format shown in Fig. 7. samples mi assigned to each country is defined as: (cid:32) mi = λ"
        },
        {
            "title": "Ri\nj Rj",
            "content": "(cid:80) + λ"
        },
        {
            "title": "Pi\nj Pj",
            "content": "(cid:80) + λ"
        },
        {
            "title": "Ai\nj Aj",
            "content": "(cid:80) (cid:33) , (11) When configuring GeoSeek-Loc, we extract images from the sample set via stratified sampling, integrate the returned results using the OpenCage [3] reverse geocoding service, and obtain structured three-level address. where is the total number of samples, Ri, Pi, and Ai denote the total road length, population, and land area of country i, respectively. The coefficients λi(i = 1, 2, 3) are weight factors, with specific values assigned as λ1 = 0.5, λ2 = 0.2 , and λ3 = 0.3 . Within each country, the globe is divided into 360 180 longitudelatitude grid (each cell spans 1 1). For each grid cell c, the local sampling probability pc is computed as: pc log(1 + Pc), (12) where Pc represents the predicted population within cell c. This logarithmic adjustment enhances coverage of populated regions without oversampling urban clusters. For GeoSeek-Val configuration, in addition to acquiring the address in the same format as mentioned above, we also utilize GPT-4o [60] to analyze the locatability and geographic elements of the images, ultimately integrating them into comprehensive evaluation dataset. B.4 Comparison with AI-annotated Data In Fig. 9, we present the reasoning processes provided by volunteers, the cleaned CoT data formatted to standard specifications, and the CoT data directly annotated by AI. We have highlighted certain errors in the AI-annotated CoT data in red. It is evident that the cleaned data annotated by humans significantly outperforms the AI-annotated data in both accuracy and the soundness of the reasoning process. B.2 Data Sources B.5 More Cases GeoSeek consists of three components which are GeoSeekCoT, GeoSeek-Loc, and GeoSeek-Val. GeoSeek-CoT conIn Fig. 10, we present additional examples of GeoSeekCoT, GeoSeek-Loc, and GeoSeek-Val, with each dataset fields like criminal tracking, emergency response, social media, and cultural dissemination especially when image metadata, particularly GPS data, is unavailable. Simultaneously, geolocation serves as an effective alternative to GNSS, addressing limitations in satellite signal availability. However, the proposed model still has limitations. For instance, since data is sourced from player communities, it primarily focuses on street-view geolocation and performs poorly in indoor scenarios or outdoor environments with minimal geographical cues. Furthermore, the models societal impact warrants consideration, requiring careful use and attention to the potential for geolocation models to infringe on personal privacy. This prevents them from becoming tools that assist criminal activities or violate individual privacy. containing fine-grained geolocation annotations. GeoSeekCoT also includes human-annotated high-quality CoT data, while GeoSeek-Loc contains locatability and geographically annotated clues for localization."
        },
        {
            "title": "C Different Base Models",
            "content": "In Tab. 6, we compare the performance of different base models on GeoSeek-Val after SFT cold start. Experimental results demonstrate that different base models exhibit significant performance improvements after undergoing GeoSeekCoTs SFT-based cold start. This further validates the effectiveness of GeoSeek-CoTs human-annotated CoT data."
        },
        {
            "title": "D Case Study",
            "content": "D.1 More Typical Cases As shown in Fig. 11 and Fig. 12, we present additional typical cases of GeoAgent on the IM2GPS3K [33] and GeoSeekVal evaluation datasets. Qualitative results indicate that GeoAgent can capture more geographically relevant features aligned with human cognition, engage in stepwise reasoning, and ultimately provide fine-grained geographic locations. D.2 Failure Cases In Fig. 13, we illustrate several instances where GeoAgent encountered failures. These failures primarily occurred when there were too few locatable geographic features (such as only plants) or when geographic features could potentially appear in multiple locations. D.3 Robustness of the Model We examine GeoAgents robustness by masking different geographical cues to observe whether the model could still infer locations. As shown in Fig. 14, we mask utility poles, text, shops, and foreground elements respectively. The model continue to infer locations using remaining geographical cues while also discovering new cues to aid inference, fully demonstrating GeoAgents robustness."
        },
        {
            "title": "E Discussion",
            "content": "This paper introduces GeoAgent, model capable of performing hierarchical reasoning based on geographical clues within images to ultimately provide fine-grained geographic locations. The geolocation task itself possesses competitive and recreational attributes, attracting large number of passionate and skilled players who have formed numerous gaming communities, such as Geoguessr [2] and TuXun [4]. The model proposed in this paper not only offers clear guidance for these players but also holds significant practical application value. Image geolocation plays vital role in 11 Figure 7 Prompts in SFT and GRPO. Figure 8 Prompts in locatability scoring and category annotation. 12 Figure 9 Comparison between human-annotated and AI-standardized thought processes versus direct AI annotation. 13 Figure 10 More cases of GeoSeek Dataset. 14 Figure 11 More cases of IM2GPS3K [103]. 15 Figure 12 More cases of GeoSeek-Val. 16 Figure 13 Failure cases of GeoAgent. 17 Figure 14 Robustness of GeoAgent."
        },
        {
            "title": "References",
            "content": "[1] Flickr. Accessed: 2025-11-19. [2] Geoguessr - lets explore the world! Accessed: 2025-10-14. [3] OpenCage Geocoder. Accessed: 2025-10-21. [4] Tuxun:explore the world. Accessed: 2025-10-14. [5] Geolocation Estimation of Photos Using Hierarchical Model and Scene Classification, pages 575592. Springer International Publishing, Cham, 2018. [6] Exploiting the Earths Spherical Geometry to Geolocate Images, pages 319. Springer International Publishing, Cham, 2020. [7] Plonkit, 2025. Accessed: 2025-11-20. [8] The spatial distribution of population in 20152030 at resolution of 30 arc (approximately 1 km at the equator), r2025a version v1, 2025. WorldPop, University of Southampton. DOI: 10.5258/SOTON/WP00845. Accessed: 2025-10-04. [9] Relja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pajdla, and Josef Sivic. Netvlad: Cnn architecture for weakly supervised place recognition, May 2016. [10] Guillaume Astruc, Nicolas Dufour, Ioannis Siglidis, Constantin Aronssohn, Nacim Bouia, Stephanie Fu, Romain Loiseau, Van Nguyen Nguyen, Charles Raude, Elliot Vincent, Lintao XU, Hongyu Zhou, and Loic Landrieu. Openstreetview-5m: The many roads to global visual geolocation, Apr. 2024. [11] Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, et al. Qwen2. 5-vl technical report. arXiv preprint arXiv:2502.13923, 2025. [12] Gabriele Berton, Carlo Masone, and Barbara Caputo. Rethinking visual geo-localization for large-scale applications, Apr. 2022. [13] Gabriele Moreno Berton, Valerio Paolicelli, Carlo Masone, and Barbara Caputo. Adaptive-attentive geolocalization from few queries: hybrid approach. pages 29172926, Jan. 2021. [14] Vicente Vivanco Cepeda, Gaurav Kumar Nayak, and Mubarak Shah. Geoclip: Clip-inspired alignment between locations and images for effective worldwide geolocalization, Nov. 2023. [15] Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, and Wanxiang Che. Towards reasoning era: survey of long chain-of-thought for reasoning large language models. arXiv preprint arXiv:2503.09567, 2025. [16] Zhenfang Chen, Qinhong Zhou, Yikang Shen, Yining Hong, Zhiqing Sun, Dan Gutfreund, and Chuang Gan. Visual chain-of-thought prompting for knowledge-based visual reasoning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 12541262, 2024. [17] Paul Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep reinforcement learning from human preferences. Advances in neural information processing systems, 30, 2017. [18] Brandon Clark, Alec Kerrigan, Parth Parag Kulkarni, Vicente Vivanco Cepeda, and Mubarak Shah. Where we are and what were looking at: Query based worldwide image geo-localization using hierarchies and scenes, Mar. 2023. [19] DeepSeek-AI. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. [20] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms. Advances in neural information processing systems, 36:1008810115, 2023. [21] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers), pages 4171 4186, 2019. [22] Zhiyang Dou, Zipeng Wang, Xumeng Han, Guorong Li, Zhipei Huang, and Zhenjun Han. Gaga: Towards interactive global geolocation assistant, Apr. 2025. [23] Elias Dritsas and Maria Trigka. Remote sensing and geospatial analysis in the big data era: survey. Remote Sensing, 17(3):550, 2025. [24] Nicolas Dufour, David Picard, Vicky Kalogeiton, and Loic Landrieu. Around the world in 80 timesteps: generative approach to global visual geolocation, Dec. 2024. [25] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-training quantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323, 2022. [26] Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, and Tushar Khot. Chain-of-thought hub: continuous effort to measure large language models reasoning performance. arXiv preprint arXiv:2305.17306, 2023. [27] Yixiao Ge, Haibo Wang, Feng Zhu, Rui Zhao, and Hongsheng Li. Self-supervising fine-grained region similarities for large-scale image localization, July 2020. [28] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with stochastic actor. In International conference on machine learning, pages 18611870. Pmlr, 2018. [29] Lukas Haas, Silas Alberti, and Michal Skreta. Learning generalized zero-shot learners for open-domain image geolocalization, Feb. 2023. [30] Lukas Haas, Michal Skreta, Silas Alberti, and Chelsea Finn. Pigeon: Predicting image geolocations. In 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1289312902, Seattle, WA, USA, June 2024. IEEE. [31] Xiao Han, Chen Zhu, Xiangyu Zhao, and Hengshu Zhu. Swarm intelligence in geo-localization: multi-agent large vision-language model collaborative framework, Oct. 2024. [32] Stephen Hausler, Sourav Garg, Ming Xu, Michael Milford, and Tobias Fischer. Patch-netvlad: Multi-scale fusion of locally-global descriptors for place recognition, Mar. 2021. [33] James Hays and Alexei A. Efros. Im2gps: Estimating geographic information from single image. In 2008 IEEE Conference on Computer Vision and Pattern Recognition, pages 18, Anchorage, AK, USA, June 2008. IEEE. 19 [34] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora: Low-rank adaptation of large language models. ICLR, 1(2):3, 2022. [35] Wenmiao Hu, Yichen Zhang, Yuxuan Liang, Xianjing Han, Yifang Yin, Hannes Kruppa, See-Kiong Ng, and Roger Zimmermann. Petalview: Fine-grained location and orientation extraction of street-view images via cross-view local search. In Proceedings of the 31st ACM International Conference on Multimedia, MM 23, page 5666. ACM, Oct. 2023. [36] Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024. [37] Sarah Ibrahimi, Nanne van Noord, Tim Alpherts, and Marcel Worring. Inside out visual place recognition, Nov. 2021. [38] James Inman. Navigation and nautical astronomy: For the use of British seamen. F. and J. Rivington, 1849. [39] International Road Federation (IRF). World Road Statistics Data Warehouse, 2025. Accessed: 2025-11-12. [40] Pengyue Jia, Yiding Liu, Xiaopeng Li, Yuhao Wang, Yantong Du, Xiao Han, Xuetao Wei, Shuaiqiang Wang, Dawei Yin, and Xiangyu Zhao. G3: An effective and adaptive framework for worldwide geolocalization using large multimodality models, Oct. 2024. [41] Pengyue Jia, Seongheon Park, Song Gao, Xiangyu Zhao, and Yixuan Li. Georanker: Distance-aware ranking for worldwide image geolocalization, May 2025. [42] Hyo Jin Kim, Enrique Dunn, and Jan-Michael Frahm. Learned contextual feature reweighting for image geolocalization. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, July 2017. IEEE. [43] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:2219922213, 2022. [44] Giorgos Kordopatis-Zilos, Panagiotis Galopoulos, Symeon Papadopoulos, and Ioannis Kompatsiaris. Leveraging efficientnet and contrastive learning for accurate global-scale location estimation, May 2021. [45] Martha Larson, Mohammad Soleymani, Guillaume Gravier, Bogdan Ionescu, and Gareth JF Jones. The benchmarking initiative for multimedia evaluation: Mediaeval 2016. IEEE MultiMedia, 24(1):9396, 2017. [46] Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei Liu, et al. Llava-onevision: Easy visual task transfer. arXiv preprint arXiv:2408.03326, 2024. [47] Ling Li, Yu Ye, Bingchuan Jiang, and Wei Zeng. Georeasoner: Geo-localization with reasoning in street views using large vision-language model, June 2024. [48] Ling Li, Yao Zhou, Yuxuan Liang, Fugee Tsung, and Jiaheng Wei. Recognition through reasoning: Reinforcing image geo-localization with large vision-language models, June 2025. [49] Xiang Li, Congcong Wen, Yuan Hu, and Nan Zhou. Rs-clip: Zero shot remote sensing scene classification via contrastive vision-language supervision. International Journal of Applied Earth Observation and Geoinformation, 124:103497, 2023. [50] Yuxi Li. Deep reinforcement learning: An overview. arXiv preprint arXiv:1701.07274, 2017. [51] Yujie Li, Wenjia Xu, Guangzuo Li, Zijian Yu, Zhiwei Wei, Jiuniu Wang, and Mugen Peng. Unirs: Unifying multitemporal remote sensing tasks through vision language models. arXiv preprint arXiv:2412.20742, 2024. [52] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances in neural information processing systems, 36:3489234916, 2023. [53] Liu Liu and Hongdong Li. Lending orientation to neural networks for cross-view geo-localization, Mar. 2019. [54] Liu Liu, Hongdong Li, and Yuchao Dai. Stochastic attraction-repulsion embedding for large scale image localization. In 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pages 25702579, Seoul, Korea (South), Oct. 2019. IEEE. [55] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017. [56] Mojgan Madadikhaljan and Michael Schmitt. Geolocationaware deep coding: Infusing geolocation information into deep neural networks for remote sensing. PFGJournal of Photogrammetry, Remote Sensing and Geoinformation Science, 93(1):318, 2025. [57] Mohammad Sultan Mahmud, Joshua Zhexue Huang, Salman Salloum, Tamer Emara, and Kuanishbay Sadatdiynov. survey of data partitioning and sampling methods to support big data analysis. Big Data Mining and Analytics, 3(2):85 101, 2020. [58] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. Advances in neural information processing systems, 26, 2013. [59] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei Rusu, Joel Veness, Marc Bellemare, Alex Graves, Martin Riedmiller, Andreas Fidjeland, Georg Ostrovski, et al. Human-level control through deep reinforcement learning. nature, 518(7540):529533, 2015. [60] OpenAI. Gpt-4o system card, 2024. [61] OpenAI. Gpt-4.1, 2025. Accessed: 2025-05. [62] OpenAI. Introducing GPT-5, 2025. Accessed: 2025-11-07. [63] Chao Pang, Xingxing Weng, Jiang Wu, Jiayu Li, Yi Liu, Jiaxing Sun, Weijia Li, Shuai Wang, Litong Feng, Gui-Song Xia, et al. Vhm: Versatile and honest vision language model for remote sensing image analysis. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 63816388, 2025. [64] Guohao Peng, Yufeng Yue, Jun Zhang, Zhenyu Wu, Xiaoyu Tang, and Danwei Wang. Semantic reinforced attention learning for visual place recognition, Aug. 2021. [65] Shraman Pramanick, Ewa M. Nowara, Joshua Gleason, Carlos D. Castillo, and Rama Chellappa. Where in the world is this image? transformer-based geo-localization in the wild, July 2022. 20 [66] Filip Radenovic, Giorgos Tolias, and Ondˇrej Chum. Finetuning cnn image retrieval with no human annotation, July 2018. [67] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations toward training trillion parameter models. In SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, pages 116. IEEE, 2020. [68] Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, pages 35053506, 2020. [69] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084, 2019. [70] Nils Reimers and Iryna Gurevych. paraphrase-multilingualMiniLM-L12-v2: Multilingual Sentence Transformer Model, 2020. Accessed: 2025-11-12. [71] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017. [72] Paul Hongsuck Seo, Tobias Weyand, Jack Sim, and Bohyung Han. Cplanet: Enhancing image geolocalization by combinatorial partitioning of maps, Aug. 2018. [73] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Yang Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024. [74] Zirui Song, Jingpu Yang, Yuan Huang, Jonathan Tonglet, Zeyu Zhang, Tao Cheng, Meng Fang, Iryna Gurevych, and Xiuying Chen. Geolocation with real human gameplay data: large-scale dataset and human-like reasoning framework, Apr. 2025. [75] Boyuan Sun, Jiaxing Zhao, Xihan Wei, and Qibin Hou. Llava-scissor: Token compression with semantic conarXiv preprint nected components for video llms. arXiv:2506.21862, 2025. [76] Hamed Taherdoost. Sampling methods in research methodology; how to choose sampling technique for research. International journal of academic research in management (IJARM), 5, 2016. [77] Chameleon Team. Chameleon: Mixed-modal early-fusion foundation models. arXiv preprint arXiv:2405.09818, 2024. [78] Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Rivière, et al. Gemma 3 technical report. arXiv preprint arXiv:2503.19786, 2025. [79] Kimi Team, Angang Du, Bohong Yin, Bowei Xing, Bowen Qu, Bowen Wang, Cheng Chen, Chenlin Zhang, Chenzhuang Du, Chu Wei, et al. Kimi-vl technical report. arXiv preprint arXiv:2504.07491, 2025. [80] Bart Thomee, David A. Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):6473, Jan. 2016. [81] Akihiko Torii, Relja Arandjelovic, Josef Sivic, Masatoshi Okutomi, and Tomas Pajdla. 24/7 place recognition by view synthesis. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 18081817, 2015. [82] Akihiko Torii, Josef Sivic, Tomas Pajdla, and Masatoshi Okutomi. Visual place recognition with repetitive structures. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 883890, 2013. [83] Nam Vo, Nathan Jacobs, and James Hays. Revisiting im2gps in the deep learning era, May 2017. [84] Chun Wang, Xiaoran Pan, Zihao Pan, Haofan Wang, and Yiren Song. Gre suite: Geo-localization inference via fine-tuned vision-language models and enhanced reasoning chains, Sept. 2025. [85] Qixuan Wang, Ning Li, Yiheng Chen, and Hainiu Zhu. Multitrans-lc: Multimodal fusion transformer for remote sensing land cover classification. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 48:133138, 2025. [86] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022. [87] Frederik Warburg, Soren Hauberg, Manuel LopezAntequera, Pau Gargallo, Yubin Kuang, and Javier Civera. Mapillary street-level sequences: dataset for lifelong place recognition. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 26232632, Seattle, WA, USA, June 2020. IEEE. [88] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022. [89] Tobias Weyand, Ilya Kostrikov, and James Philbin. Planet - photo geolocation with convolutional neural networks. pages 3755. 2016. [90] Scott Workman, Richard Souvenir, and Nathan Jacobs. Wide-area image geolocalization with aerial reference imagery, Oct. 2015. [91] Rihui Xin, Han Liu, Zecheng Wang, Yupeng Zhang, Dianbo Sui, Xiaolin Hu, and Bingning Wang. Surrogate signals from format and length: Reinforcement learning for solving mathematical problems without ground truth answers. arXiv preprint arXiv:2505.19439, 2025. [92] Chenhui Xu, Fuxun Yu, Michael Bianco, Jacob Kovarskiy, Raphael Tang, Qi Zhang, Zirui Xu, Will LeVine, Brandon Dubbs, Heming Liao, et al. Geo-r1: Unlocking vlm geospatial reasoning with cross-view reinforcement learning. arXiv preprint arXiv:2510.00072, 2025. [93] Shixiong Xu, Chenghao Zhang, Lubin Fan, Gaofeng Meng, Shiming Xiang, and Jieping Ye. Addressclip: Empowering vision-language models for city-wide image address localization, July 2024. [94] Shixiong Xu, Chenghao Zhang, Lubin Fan, Yuan Zhou, Bin Fan, Shiming Xiang, Gaofeng Meng, and Jieping Ye. Addressvlm: Cross-view alignment tuning for image address localization using large vision-language models, 2025. [95] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. [96] Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, and Xiang Yue. Demystifying long chain-of-thought reasoning in llms. arXiv preprint arXiv:2502.03373, 2025. [97] Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Shiji Song, and Gao Huang. Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model? arXiv preprint arXiv:2504.13837, 2025. [98] Xiaohan Zhang, Xingyu Li, Waqas Sultani, Yi Zhou, and Safwan Wshah. Cross-view geo-localization via learning disentangled geometric layout correspondence, June 2023. [99] Zilun Zhang, Zian Guan, Tiancheng Zhao, Haozhan Shen, Tianyu Li, Yuxiang Cai, Zhonggen Su, Zhaojun Liu, Jianwei Yin, and Xiang Li. Geo-r1: Improving few-shot geospatial referring expression understanding with reinforcement finetuning. arXiv preprint arXiv:2509.21976, 2025. [100] Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal chain-ofthought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023. [101] Zilun Zhang, Tiancheng Zhao, Yulong Guo, and Jianwei Yin. Rs5m and georsclip: large scale vision-language dataset and large vision-language model for remote sensing. IEEE Transactions on Geoscience and Remote Sensing, 2024. [102] Jiaxing Zhao, Qize Yang, Yixing Peng, Detao Bai, Shimin Yao, Boyuan Sun, Xiang Chen, Shenghao Fu, Xihan Wei, Liefeng Bo, et al. Humanomni: large vision-speech language model for human-centric video understanding. arXiv preprint arXiv:2501.15111, 2025. [103] Zhongliang Zhou, Jielu Zhang, Zihan Guan, Mengxuan Hu, Ni Lao, Lan Mu, Sheng Li, and Gengchen Mai. Img2loc: Revisiting image geolocalization using multi-modality foundation models and image-based retrieval-augmented generation. pages 27492754, July 2024. [104] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: Enhancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592, 2023. [105] Jinguo Zhu, Weiyun Wang, Zhe Chen, Zhaoyang Liu, Shenglong Ye, Lixin Gu, Hao Tian, Yuchen Duan, Weijie Su, Jie Shao, et al. Internvl3: Exploring advanced training and test-time recipes for open-source multimodal models. arXiv preprint arXiv:2504.10479, 2025."
        }
    ],
    "affiliations": [
        "School of Automation, Northwestern Polytechnical University",
        "VCIP, School of Computer Science, Nankai University"
    ]
}