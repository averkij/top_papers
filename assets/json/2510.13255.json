{
    "paper_title": "Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain",
    "authors": [
        "Jingmin An",
        "Yilong Song",
        "Ruolin Yang",
        "Nai Ding",
        "Lingxi Lu",
        "Yuxuan Wang",
        "Wei Wang",
        "Chu Zhuang",
        "Qian Wang",
        "Fang Fang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) demonstrate human-level or even superior language abilities, effectively modeling syntactic structures, yet the specific computational modules responsible remain unclear. A key question is whether LLM behavioral capabilities stem from mechanisms akin to those in the human brain. To address these questions, we introduce the Hierarchical Frequency Tagging Probe (HFTP), a tool that utilizes frequency-domain analysis to identify neuron-wise components of LLMs (e.g., individual Multilayer Perceptron (MLP) neurons) and cortical regions (via intracranial recordings) encoding syntactic structures. Our results show that models such as GPT-2, Gemma, Gemma 2, Llama 2, Llama 3.1, and GLM-4 process syntax in analogous layers, while the human brain relies on distinct cortical regions for different syntactic levels. Representational similarity analysis reveals a stronger alignment between LLM representations and the left hemisphere of the brain (dominant in language processing). Notably, upgraded models exhibit divergent trends: Gemma 2 shows greater brain similarity than Gemma, while Llama 3.1 shows less alignment with the brain compared to Llama 2. These findings offer new insights into the interpretability of LLM behavioral improvements, raising questions about whether these advancements are driven by human-like or non-human-like mechanisms, and establish HFTP as a valuable tool bridging computational linguistics and cognitive neuroscience. This project is available at https://github.com/LilTiger/HFTP."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 1 ] . [ 1 5 5 2 3 1 . 0 1 5 2 : r Hierarchical Frequency Tagging Probe (HFTP): Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain Jingmin An1, Yilong Song1, Ruolin Yang1, Nai Ding2, Lingxi Lu3 Yuxuan Wang1, Wei Wang4, Chu Zhuang1, Qian Wang1,, Fang Fang1, 1Peking University, 2Zhejiang University, 3Beijing Language and Culture University, 4Beijing Institute for General Artificial Intelligence anjm@stu.pku.edu.cn, {wangqianpsy, ffang}@pku.edu.cn"
        },
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) demonstrate human-level or even superior language abilities, effectively modeling syntactic structures, yet the specific computational modules responsible remain unclear. key question is whether LLM behavioral capabilities stem from mechanisms akin to those in the human brain. To address these questions, we introduce the Hierarchical Frequency Tagging Probe (HFTP), tool that utilizes frequency-domain analysis to identify neuron-wise components of LLMs (e.g., individual Multilayer Perceptron (MLP) neurons) and cortical regions (via intracranial recordings) encoding syntactic structures. Our results show that models such as GPT-2, Gemma, Gemma 2, Llama 2, Llama 3.1, and GLM-4 process syntax in analogous layers, while the human brain relies on distinct cortical regions for different syntactic levels. Representational similarity analysis reveals stronger alignment between LLM representations and the left hemisphere of the brain (dominant in language processing). Notably, upgraded models exhibit divergent trends: Gemma 2 shows greater brain similarity than Gemma, while Llama 3.1 shows less alignment with the brain compared to Llama 2. These findings offer new insights into the interpretability of LLM behavioral improvements, raising questions about whether these advancements are driven by human-like or non-human-like mechanisms, and establish HFTP as valuable tool bridging computational linguistics and cognitive neuroscience. This project is available at https://github.com/LilTiger/HFTP."
        },
        {
            "title": "Introduction",
            "content": "Language is fundamental to human communication, thought, and cultural transmission. According to the framework proposed by Noam Chomsky, language is divided into three key components: semantics (meaning), phonology (sound), and syntax (hierarchical sentence structure) [Chomsky, 1965]. Syntax is particularly crucial as it governs how words combine into meaningful expressions, underpinning the recursive and generative capacity unique to human language. The theory of Universal Grammar proposes that all human languages share innate structural principles [Chomsky, 1980]. Building on this foundation, cognitive neuroscience has shown that syntactic processing recruits mechanisms distinct from other linguistic functions, particularly within the left inferior frontal and posterior temporal regions [Matchin and Wood, 2020, Friederici, 2011]. Moreover, increases in syntactic complexity yield graded activation in left inferior frontal and posterior temporal cortices, consistent with the computation and maintenance of hierarchical dependencies rather than simple lexical associations [Pallier et al., 2011, Nelson et al., 2017]. As our understanding of human 39th Conference on Neural Information Processing Systems (NeurIPS 2025). syntactic computation deepens, artificial intelligence models have increasingly sought to emulate this ability to capture and represent structured language. In recent years, large language models (LLMs) have evolved rapidly, achieving human-level or better performance on range of linguistic benchmarks and professional exams [Achiam et al., 2023]. Their success in understanding, translation, and summarization has led to claims of human-like fluency, particularly in generating text that conforms to surface syntactic regularities [Mahowald et al., 2024, He et al., 2024, Van Veen et al., 2024]. Yet it remains unclear whether such models truly represent the hierarchical sentence structures that characterize human syntax. Some findings indicate that LLMs can implicitly capture and manipulate structural relations [Manning et al., 2020], while others suggest their success can rely on shallow statistical heuristics rather than genuine structural understanding [Linzen et al., 2016, McCoy et al., 2019]. This ongoing debate underscores the need for unified analytic framework capable of directly comparing syntactic representations in human and model systems, which is essential for probing the depth and nature of syntactic alignment between the human brain and artificial models. Ding et al. [Ding et al., 2016] introduced the hierarchical frequency tagging (HFT) technique to uncover how the human brain processes hierarchical linguistic structures during natural speech comprehension. In this paradigm, monosyllabic words are presented at rate of 4 Hz to form phrases at 2 Hz, which combine into sentences at 1 Hz. Using frequency-domain analysis of electrophysiological signals, Ding et al. deconstruct the processing of linguistic structures such as phrases and sentences. Subsequent work has extended the HFT framework along complementary axes. Attention is required to group lower-level inputs into higher-order linguistic units, and diverting attention attenuates wordand phrase-rate tracking [Ding et al., 2018]. MEG source analyses dissociate cortical signatures for wordversus phrase-level rhythms and link phrasal tracking to comprehension [Keitel et al., 2018]. Computational modelling shows that oscillatory architectures can implement hierarchical parsing and reproduce HFT-like spectra [Martin and Doumas, 2017]. Natural-speech EEG reveals endogenous word-rate tracking that interacts with exogenous rhythmic cues [Luo and Ding, 2020]. Naturalistic experiments further indicate that phrase-rate tracking indexes internally generated structure rather than compositional meaning per se, while remaining sensitive to lexicalsyntactic information that enables structure building [Coopmans et al., 2022]. These studies demonstrate the effectiveness of HFT for isolating neural markers of hierarchical language processing. Accordingly, HFTP leverages frequency-domain tagging to separate sentenceand phrase-level structure from lexical and prosodic regularities, and to yield robust spectral markers that can be aligned quantitatively with language-model representations across timescales, thereby providing principled bridge between biological and artificial systems. Building on the HFT paradigm Ding et al. [2016], here we developed the Hierarchical Frequency Tagging Probe (HFTP) to investigate whether specific computational modules within LLMs process hierarchical sentence structures. HFTP offers unified approach to explore internal similarities and systematically examine the alignment of syntactic structure representations between LLMs and the human brain. The key contributions of this paper are: (i) We innovatively employed frequency-domain analysis using HFTP to characterize the syntactic structure representations of every computational module in each layer of LLMs; (ii) HFTP provides simple, universally applicable approach for detecting and aligning syntactic structure representations in LLMs (via neuron-wise probing) and the human brain (via population-level analyses), and extends seamlessly to naturalistic text. (iii) Using syntactic templates derived from HFTP, we identified brain regions highly correlated with LLMs, predominantly located in key language-processing areas of the left hemisphere; (iv) By comparing six LLMs, we observed divergent trends in upgraded versions, with some showing increased similarity to brain representations while others exhibited reduced alignment. In sum, HFTP effectively detects syntactic structure representations in both LLMs and the human brain, providing novel framework for alignment study."
        },
        {
            "title": "2 Related work",
            "content": "Syntactic processing in the human brain In humans, syntactic processing recruits left-dominant fronto-temporal network that supports hierarchical combination from finite elements. Classic lesion and neuroimaging work documents left-hemisphere advantage [Friederici and Brauer, 2009, Hagoort, 2013, Blank et al., 2016], with hemispheric temporal sensitivities aiding speech segmentation [Albouy et al., 2020]. Converging evidence shows that syntactic operations are distributed across frontal and 2 temporal cortex with substantial overlap with semantic integration [Blank et al., 2016, Fedorenko et al., 2020]. Artificial-grammar fMRI further indicates that hierarchically structured strings reliably engage left inferior frontal gyrus and posterior superior temporal regions [Chen et al., 2021]. Overall, these findings demonstrate that syntactic processing is not confined to isolated regions but is part of broad, interconnected network. Syntactic processing in language models Even before the development of LLMs, researchers found that simple LSTM language models could capture syntax-sensitive dependencies, such as subject-verb agreement [Linzen et al., 2016, Kuncoro et al., 2018]. Using technique called structural probing, Manning and colleagues discovered that transformer-based models like BERT can encode hierarchical syntactic trees, enabling such models to implicitly represent complex syntax without direct training [Hewitt and Manning, 2019]. These transformer-based models excel at tracking both local and long-range dependencies through specialized attention mechanisms, distributing syntactic knowledge across layers [Clark, 2019, Tenney et al., 2019, Manning et al., 2020].However, the methods employed in these studies of language models make it challenging to apply findings to the exploration of human brain activity. Alignment between LLMs and the human brain growing body of work shows that sentence-level contextual embeddings from predictive LMs strongly predict cortical responses during comprehension [Sun et al., 2020, Schrimpf et al., 2021]. Disentanglement analyses that factorize activations into lexical, compositional, syntactic, and semantic components indicate distributed contributionsoften with compositional/lexical signals explaining much of the alignment, rather than syntax alone [Caucheteux et al., 2021, Caucheteux and King, 2022]. Neuroimaging manipulations that dissociate semantics from syntax reveal distinct patterns (including frontal engagement) without establishing syntactic dominance [Wang et al., 2020]. Intervention studies that selectively remove linguistic properties from model representations yield reliable drops in brain alignment, with syntactic properties (e.g., tree depth, top constituents) exerting large cross-layer effects [Oota et al., 2023]. These findings are consistent with convergence on shared representational axes across brains and models [Hosseini et al., 2024] and with demonstrations that model-derived stimuli can causally drive or suppress the human language network [Tuckute et al., 2024], while alignment varies systematically across layers as contextual information accrues [Goldstein et al., 2022]. However, despite these advances, methodological inconsistencies still prevent systematic comparison of syntactic structure encoding across models and neural populations, underscoring the need for unified analytical framework."
        },
        {
            "title": "3 Methods",
            "content": "We present the framework of the proposed HFTP methodology (see Figure 1). This framework is organized into four parts: Section 3.1 describes the syntactic corpora used and the LLM architectures; Section 3.2 details the application of HFTP to detect significant sentence and phrase neurons; Section 3.3 explains how the HFTP approach is applied to human intracranial stereo-electroencephalography (sEEG) data; and Section 3.4 correlates syntactic structure representations in LLMs and the human brain by comparing frequency-domain representations and detecting similarities in how syntactic structures are encoded across both systems. 3.1 Data and LLMs We mainly utilized Chinese and English corpora adapted from [Ding et al., 2016], consisting of four-syllable sequences in Chinese or four-word sequences in English, where the first two and last two units form phrases (see Figure 1). Further details regarding the corpus can be found in Appendix H. We also adopt naturalistic text to test the generalizability of our HFTP method (see F). For both the sEEG and modelbrain alignment experiments, we used the same two Chinese corporathe sentence and phrase corporafrom [Sheng et al., 2019]. While these corpora share similar structure to the Chinese syntactic corpus used in the LLM experiments, they differ in content. Guided by evidence that periodic lexical regularities alone can produce peaks at word-, phrase-, and sentence-rate frequencies [Frank and Yang, 2018], we added within-sentence word-orderrandomized control in all experiments: items are permuted across positions so that lexical and part-of-speech categories do not recur at fixed positions and any consistent phraseor sentence-level patterns are prevented, while the lexical set is preserved. This control isolates the syntactic and lexical contribution to 1, 2, and 4 Hz power. 3 Figure 1: framework for Hierarchical Frequency Tagging Probes (HFTP) and an illustration of neurons involved in different levels of hierarchical linguistic processing in both LLMs and the human brain. A, hierarchical linguistic structure in English and Chinese including syllable, phrase, and sentence. B, hierarchical linguistic pattern (1 Hz: sentence feature, 2 Hz: phrase feature) observed both in LLMs and C, human brain. Figure 2: Alignment pipeline between LLMs and the human brain. SRDMs are computed for exclusive sentence/phrase and sentence&phrase MLP neurons and brain channels by comparing cosine similarities across different conditions. Subsequently, RSA (using Spearman correlation) is applied to quantify the similarity between the two SRDMs, thereby assessing the correspondence between model and brain representations. We applied HFTP to six state-of-the-art LLMs: GPT-2, Gemma, Gemma 2, Llama 2, Llama 3.1, and GLM-4, which vary in both architecture and parameter scale (see Table 5). To avoid tokenisation artefacts, we average MLP activations over sub-tokens at the syllable level for Chinese and word level for English before FFT. This ensures that the 1 Hz and 2 Hz spectral components reflect linguistic boundaries rather than tokenisation boundaries, enabling consistent cross-lingual and cross-model comparisons. Notably, the term MLP neuron denotes computational unit in the intermediate hidden layer of the MLP sub-layer within Transformer model. This sub-layer consists of two linear transformations separated by nonlinear activation function. We target MLP neurons because they house localised, interpretable unitsconceptualised as knowledge neurons [Dai et al., 4 2021] that causally control factual recall and lexicalsyntactic concepts [Geva et al., 2022]. This mechanistic specificity provides the discrete, concept-aware handles required by HFTP to robustly localise syntactic structures. 3.2 Syntactic structure probe in LLMs For each LLM, sequences from both the Chinese and English syntactic corpora were concatenated into continuous text to capture neural-like activations. During this process, each Chinese syllable (or English word) outputs an activation value, allowing the signal corresponding to every individual linguistic unit to be traced. These time-domain activations were then transformed into frequencydomain information via fast-fourier transform (FFT). Due to the lack of time-course information inherent to LLM input structures, we artificially defined time scale on which the activation values are output at frequency of 4 Hz, and we also manually constrained the sampling rate to 4 Hz, limiting the observable frequencies to the 0 2 Hz range. This adjustment ensured that the syntactic rhythms analogous to those observed in human brain data could be captured within the model activations. LLMs, with their multiple layers and thousands of MLP neurons per layer, require systematic approach to detect which neurons are responsible for either sentence or phrase processing. HFTP introduces method to detect significant syntactic processing units, applicable to both LLMs and human brain data. For the LLMs, we conducted permutation test, randomizing the model activations derived from the structured input corpus 1000 times. The original frequency bins at 1 Hz and 2 Hz, representing sentence and phrase rhythms respectively (their real parts of amplitudes are denoted as real[amp(1 Hz)], real[amp(2 Hz)]), were compared to the 95% confidence intervals (CI) generated by the distribution of permuted activations. Neurons whose real[amp(1 Hz)] and real[amp(2 Hz)] values exceeded this threshold were classified as significant MLP neurons (see 1), indicating their involvement in syntactic processing with statistical robustness against random noise. Definition 1 (Significant MLP Neurons). For fixed frequency , neuron is significant MLP neuron, if and only if its FFT result satisfies real[amp(f )] / 95% CI of permuted distribution. (1) The set containing all the significant MLP neurons in terms of frequency is denoted as Sf . Since the significant MLP neurons are distributed almost uniformly across all layers, detecting the specific neurons that contribute to sentence and phrase processing requires more objective and systematic method. We then applied z-scores to the FFT amplitudes at 1 Hz and 2 Hz in both the experimental and control groups for all significant MLP neurons across layers. The zscore deviation zf (n) between the experimental and control groups was then calculated for each neuron.This deviation helps minimize semantic confounds by isolating frequency-specific syntactic effects. Sentence and phrase MLP neurons were defined as those whose z-scores deviated by more than two standard deviations from the mean, at 1 Hz and 2 Hz, respectively (see 2). Definition 2 (Sentence MLP Neurons and Phrase MLP Neurons). neuron is defined as sentence/phrase MLP neuron if it satisfies Sf , zf (n) µzf + 2σzf , (2) where zf (n) denotes the z-score deviation of the FFT amplitude between experimental and control groups for neuron at frequency , µzf denotes the mean z-score across all neurons for the frequency , σzf denotes the standard deviation of z-scores across all neurons for the frequency , and the frequency is specified as 1 Hz and 2 Hz for sentence and phrase MLP neuron respectively. Following this, we identified and analysed sentence and phrase MLP neurons across layers and LLMs, with full details provided in Section 4.1. We also conducted bilingual experiments to assess the ability of different LLMs to perceive syntactic structures across Chinese and English (see Appendix C). 3.3 Syntactic structure probe in the human brain We recorded sEEG from 26 native Chinese speakers while they listened to two Chinese auditory corpora. In the sentence corpus, nine four-syllable sentences were concatenated per trial; in the phrase corpus, eighteen two-syllable phrases were concatenated. Each corpus comprised 40 trials per subject. Syllables were 250 ms long, and signals were sampled at 512 Hz (512 Hz for one 5 participant). To minimize onset-related responses, analyses used only the final 32 syllables of each trial. To analyze the sEEG data, we employed inter-trial phase coherence (ITPC), frequency-domain method relatively resistant to noise that quantifies the consistency of phase relationships in oscillatory brain activity across multiple trials [Cohen, 2014]. sEEG Electrode localization was performed similarly to previous studies [Xu et al., 2023, Wang et al., 2024]; all electrodes were mapped to brain regions defined by the Automated Anatomical Labeling (AAL) system. We then grouped certain AAL regions to form 12 brain regions of interest (ROIs) (details in Appendix I). Subsequent experiments were conducted based on brain ROIs. As previously outlined, the proposed HFTP approach is designed to be applicable to both LLMs and human brain data. For the human brain analysis, we employed the same permutation testing procedure on the time-domain sEEG data that captured cortical activity during listening to Chinese corpora. Specifically, ITPC results were randomized 1000 times for each channel in each subject. The original frequency bins, real[amp(1 Hz)] and real[amp(2 Hz)], were then assessed to determine whether they fell within the 95% confidence interval of the permuted ITPC distribution (see 3). Definition 3 (Sentence channels and Phrase channels). channel is defined as sentence/phrase channel if its ITPC result satisfies real[amp(f )] / 95% CI of permuted ITPC, (3) where = 1 Hz for sentence channel and = 2 Hz for phrase channel. Using this probe, we identified and analyzed the distribution of sentence and phrase channels across various brain ROIs, with full details provided in Section 4.2. 3.4 Alignment of syntactic structure representations of LLMs with the human brain To explore syntactic structure representation alignment between LLMs and the human brain, we compared their frequency-domain representations using the same sentence and phrase corpora. For each computational module (a MLP neuron in LLMs or an sEEG electrode channel in the human brain), we extracted amplitude in the frequency spectrum as the feature. This approach creates multidimensional space based on frequency-domain features, where each syntactic structure corresponds to specific point in this space (see Figure 2). We then computed the distances between these points for different syntactic structures within the same computational module using cosine similarity. Through pairwise comparisons, we constructed Structure Representational Dissimilarity Matrices (SRDMs) for each computational module, which are similar to Representational Dissimilarity Matrices (RDMs) but specifically capture the representations of syntactic structures [Cichy et al., 2014, Khaligh-Razavi and Kriegeskorte, 2014]. We then applied Representational Similarity Analysis (RSA) to enable cross-modal comparisons between LLMs and brain data, correlating the representations in both systems [Kriegeskorte et al., 2008]. This approach quantified alignment and used statistical tests to detect significant overlaps. We introduced two key measures: model-brain similarity S(m, b) and model-region similarity S(m, br), to evaluate alignment globally and in specific brain ROI, and used the contribution ratio (CRr) to assess the impact of each region on the alignment. For more details on the alignment pipeline, see Appendix A. The comprehensive discussion of the alignment results can be found in Section 4.3."
        },
        {
            "title": "4 Experiments",
            "content": "We used HFTP to assess structural processing in the human brain and LLMs, and aligned their frequency-domain representations to evaluate their similarity. 4.1 MLP neurons represent sentences and phrases in LLMs Using the HFTP method, we identified neurons in all six models that selectively represent sentences (sentence neurons), phrases (phrase neurons), and neurons that simultaneously represent both (sentence & phrase neurons). In the examples shown, we highlight MLP neurons which display distinct hierarchical frequency patterns. Figure 3 demonstrates four patterns: significant peak at the sentence frequency (fsentence = 1 Hz), significant peak at the phrase frequency (fphrase = 2 Hz), dual 6 peaks at both fsentence and fphrase, and no significant peaks. Frequencies beyond 2 Hz have been artificially set to zero for smoothness in the representation. Figure 3: Hierarchical frequency patterns of MLP neurons selectively represent sentence features, phrase features, shared features of both and non-sensitive feature (from left to the right). Here, experiment\" denotes the original corpus, while random\" indicates the randomized version. Shaded bands show 1 s.e.m. computed across 10 shuffled-input activation partitions. Significant peaks (*p < 0.05, FDR corrected) indicate amplitudes stronger than neighboring frequencies within 0.5 Hz. \"Normalized Amplitude\" represents the curves and bands scaled to range of 0 to 1. (a) GPT-2 (b) Gemma (c) Gemma 2 (d) Llama 2 (e) Llama 3.1 (f) GLMFigure 4: Statistics of exclusive sentence/phrase MLP neurons and sentence & phrase MLP neurons in each layer across six LLMs. For the six LLMs tested, we identified their sentence and phrase neurons using the HFTP method. Figure 4 shows the distribution of exclusive sentence/phrase neurons and those representing both across different layers, based on experiments using the Chinese syntactic corpus. All the models contain neurons dedicated to capturing sentences and phrases, demonstrating their ability to encode the syntactic hierarchies of human language. However, distinct distribution patterns suggest varied syntactic processing strategies: Llama and GLM primarily process syntactic information in later layers, reflecting more integrated approach. GPT, on the other hand, exhibits higher concentrations of sentence and phrase neurons in its middle layers, suggesting balanced intermediate strategy. In contrast, Gemma demonstrates distinct preference for dense concentrations of neurons in the early layers, indicating an emphasis on initial-stage syntactic processing. comparative analysis reveals significant decrease in the maximum proportions of all syntactic neurons in the Llama and Gemma models, dropping from 11% in Llama 2 to 4.5% in Llama 3.1, and from 27% in Gemma to 22% in Gemma 2. As Llama 3.1 and Gemma 2 are updated versions of Llama 2 and Gemma, respectively, this trend suggests potential shift in computational resource allocation. To enhance performance on complex tasks, Llama 3.1 and Gemma 2 may reduce their specialized processing of syntactic structures (sentences and phrases), reallocating neurons to support these advanced capabilities. Additionally, consistent covariant trend between sentence and phrase neurons across layers was observed for all six models, with high statistical correlations, including GPT-2 (r = 0.754), Gemma (r 7 Figure 5: Hierarchical frequency patterns of sEEG channels selectively represent sentence features, phrase features, shared features of both and non-sensitive feature (from left to the right). Here, setence\" denotes the original sentence corpus, while random\" indicates the randomized version. Shaded bands show 1 s.e.m. computed across channels. Significant peaks (*p < 0.05, FDR corrected) indicate amplitudes stronger than neighboring frequencies within 0.5 Hz. \"Normalized ITPC\" represents the curves and bands scaled to range of 0 to 1. = 0.994), Gemma 2 (r = 0.994), Llama 2 (r = 0.912), and Llama 3.1 (r = 0.886), GLM (r = 0.993). This suggests that LLMs share similar underlying mechanisms for sentence and phrase processing. 4.2 Sentences and phrases representations in the human brain Using the HFTP approach, we identified neuron populations in the human brain that selectively represent sentences and phrases. Each sEEG channel captures collective responses from nearby neuron populations, providing high spatio-temporal resolution of neural activity. This allows us to assess sentence and phrase selectivity precisely. As shown in Figure 5, we found channels representing sentences and phrases, as well as channels with shared representations, while some channels did not represent either. These findings align with those observed in LLMs, demonstrating that HFTP effectively investigates the internal representations of syntactic structures in both systems. (a) sEEG channel locations and Brain ROIs (b) Significant sEEG channel distribution Figure 6: (a) Brain ROIs of the left and right hemispheres used in this study. The black electrodes represent the sEEG channel locations across all participants. (b) Distribution of significant exclusive sentence/phrase and sentence & phrase channels (sentence corpus) in different brain ROIs. Similar to our analysis of neuron types in LLM layers, we calculated the proportions of sentence and phrase channels within each brain ROI. As shown in Figure 6, phrase channels decrease from lower layers (A1) to higher layers (e.g., IFG), while sentence channels show the opposite trend, increasing at higher brain layers. This pattern aligns with earlier MEG studies Sheng et al. [2019], supporting distinct processing mechanisms for sentences and phrases. Correlations between sentence and phrase channels across brain ROIs in both hemispheres revealed no significant relationship (left: = -0.169, = 0.870; right: = -0.197, = 0.539), suggesting that sentence and phrase processing operate independently. This contrasts with the behavior of LLMs, implying that while the human brain segregates sentence and phrase processing across different regions, LLMs integrate both syntactic 8 Table 1: Averaged top-100 Spearman correlations between sEEG-channel SRDMs and MLP-neuron SRDMs under the sentence corpus, separated by left (L) and right (R) hemispheres. / indicates that no channels from that hemisphere appear in the top-100 set. The first data row reports the overall modelbrain similarity S(m, b); each subsequent brain ROI row reports the modelregion similarity S(m, br). Bold in the S(m, b) row flags the model with the highest overall alignment, while bold entries within each brain ROI row mark the three regions most strongly correlated for that model. GPT-2 Gemma Gemma 2 Llama Llama 3.1 GLM-4 R L R S(m, b) 0.654 0.442 0.582 0.411 0.644 0.450 0.645 0.439 0.514 0.405 0.630 0.445 A1 STG MTG ITG Insula TPJ Temporal Pole Sensorimotor IFG MFG Hippocampus Amygdala 0.683 0.423 0.642 0.358 0.702 0.333 0.649 0.547 0.514 0.403 0.664 0.374 0.667 0.422 0.593 0.386 0.654 0.410 0.672 0.453 0.507 0.392 0.647 0.412 0.674 0.392 0.584 0.383 0.659 0.411 0.674 0.409 0.521 0.408 0.645 0.397 0.637 0.444 0.578 0.406 0.631 0.448 0.629 0.426 0.509 0.401 0.615 0.439 0.624 0.460 0.551 0.425 0.600 0.476 0.630 0.446 0.518 0.422 0.604 0.475 0.610 0.452 0.566 0.373 0.641 0.410 0.619 0.400 0.518 0.408 0.606 0.438 0.648 0.473 0.556 0.470 0.643 0.558 0.610 0.469 0.494 0.448 0.616 0.483 0.637 0.462 0.567 0.426 0.622 0.448 0.624 0.446 0.505 0.396 0.617 0.463 0.694 0.463 0.603 0.466 0.670 0.496 0.665 0.491 0.513 0.410 0.646 0.490 0.615 0.436 0.557 0.401 0.585 0.489 0.597 0.367 0.510 0.397 0.588 0.473 0.698 0.405 0.553 0.408 0.626 0.428 0.657 0.413 0.534 0.390 0.613 0.434 0. 0.489 0.566 0.454 0.558 0.496 0.377 0.472 / / / / levels within the same model layers. This highlights that the layered representations of LLMs may not align directly with the distinct processing roles observed in brain ROIs. 4.3 Alignment of syntactic structure representations between LLMs and the human brain As the layered representations of LLMs do not correspond directly to the distinct processing functions of different brain ROIs, we sought to investigate whether overall syntactic structure representations in LLMs are comparable to those in the human brain, both globally and across individual brain ROIs. To accomplish this, we employed Searchlight representational alignment at both sentence and phrase levels (see Section for detailed procedures). The alignment results across both sentence and phrase corpus (Tables 1 and 2) revealed consistent patterns of model-brain correspondence. As shown in both tables, we observed that the similarity between LLMs and the left hemisphere is notably higher than that with the right hemisphere across both linguistic granularities. One-way ANOVAs at the brain level confirmed that models differed significantly in explaining neural responses for both sentence-level (F = 59.74, η2 = 0.027, < 0.001) and phrase-level processing (F = 12.10, η2 = 0.018, < 0.001). Region-wise ANOVAs with FDR correction further showed strongly left-lateralized effect at both corpus, concentrated in core language cortex (e.g., STG, MTG, IFG). Examining individual model performance, GPT-2 exhibited the highest average correlation with human brain activity across both sentence (S = 0.654, L) and phrase levels (S = 0.654, L). Gemma 2 (S = 0.644, for sentences; = 0.628, for phrases) consistently outperformed Gemma (S = 0.582, for sentences; = 0.575, for phrases) at both corpora, attributed to architectural improvements [Team et al., 2024a]. Most notably, Llama 3.1 (S = 0.514, for sentences; = 0.522, for phrases) showed consistently lower alignment than Llama 2 (S = 0.645, for sentences; = 0.648, for phrases) across both processing levels. This counterintuitive pattern is explained at the pretraining level: Llama 3.1 was trained on substantially larger corpus emphasizing code, reasoning, and multilingual text, which dilutes language-specific regularities. Additionally, extensive reliance on synthetic data for capability-targeted curation introduces distributional shifts away from naturalistic language statistics [Dubey et al., 2024, Touvron et al., 2023]. These findings echo evidence that scaling alone fails to secure robust predicateargument structureespecially for long-range, boundary-sensitive rolesrevealing persistent humanmodel structural gaps [Cheng et al., 2024]. Additionally, the key brain ROIs for each model, which are primarily located in the left hemisphere, highlighted regions that are critical for syntactic processing at both sentence and phrase levels. These regions include the left A1, STG, MTG, and IFG, with many of the LLMs exhibiting particularly strong correlations in these areas across both linguistic granularities, emphasizing their role in 9 Table 2: Averaged top-100 Spearman correlations between sEEG-channel SRDMs and MLP-neuron SRDMs under the phrase corpus, separated by left (L) and right (R) hemispheres. / indicates that no channels from that hemisphere appear in the top-100 set. The first data row reports the overall modelbrain similarity S(m, b); each subsequent brain ROI row reports the modelregion similarity S(m, br). Bold in the S(m, b) row flags the model with the highest overall alignment, while bold entries within each brain ROI row mark the three regions most strongly correlated for that model. GPT-2 Gemma Gemma Llama 2 Llama 3.1 GLM-4 L R L R S(m, b) 0.654 0.441 0.575 0.416 0.628 0.443 0.648 0.435 0.522 0.404 0.626 0.437 A1 STG MTG ITG Insula TPJ Temporal Pole Sensorimotor IFG MFG Hippocampus Amygdala 0.669 0.420 0.610 0.315 0.665 0.326 0.628 0.576 0.526 0.372 0.627 0.374 0.665 0.415 0.591 0.388 0.643 0.395 0.674 0.447 0.530 0.402 0.649 0.401 0.665 0.391 0.564 0.408 0.645 0.415 0.675 0.415 0.521 0.401 0.641 0.408 0.637 0.447 0.558 0.421 0.611 0.440 0.632 0.421 0.518 0.398 0.621 0.427 0.627 0.468 0.556 0.433 0.596 0.465 0.632 0.453 0.519 0.409 0.602 0.470 0.616 0.442 0.563 0.405 0.608 0.423 0.615 0.384 0.542 0.399 0.588 0.433 0.680 0.453 0.555 0.394 0.626 0.501 0.623 0.456 0.505 0.450 0.583 0.442 0.645 0.475 0.565 0.443 0.607 0.449 0.629 0.442 0.511 0.391 0.613 0.460 0.700 0.450 0.635 0.424 0.656 0.491 0.674 0.488 0.514 0.436 0.636 0.480 0.618 0.409 0.562 0.421 0.583 0.500 0.601 0.365 0.505 0.379 0.577 0.475 0.656 0.398 0.541 0.418 0.602 0.432 0.640 0.398 0.516 0.406 0.566 0.434 0.492 0.552 0.468 0.386 0.483 0.433 0.475 / / / / / syntactic functions. These converging findings across sentence and phrase levels reinforce the robustness of the HFTP approach and suggest its potential as valuable tool for future studies of model-brain alignment."
        },
        {
            "title": "5 Conclusion",
            "content": "This study advances syntactic processing by introducing the Hierarchical Frequency Tagging Probe (HFTP), unified framework for dissecting neuron-wise sentence and phrase representations in LLMs, population-level patterns in the human brain, and generalizing seamlessly to naturalistic text. The results reveal that while LLMs, such as GPT-2, Gemma, Llama 2, and others, exhibit hierarchical syntactic processing and alignment with left-hemisphere brain activity, the mechanisms underlying their representations diverge significantly from those in human cortical regions. Notably, newer models like Gemma 2 demonstrate improved alignment, whereas others, such as Llama 3.1, show weaker human-model correlations despite enhanced task performance. These findings underscore the need to refine LLM architectures for more human-like syntactic processing and establish HFTP as bridge between computational linguistics and cognitive neuroscience. Finally, the societal implications of this work are two-sided: positively, HFTP can support safer, more controllable models and inform non-invasive diagnostics via spectral markers; negatively, the same interpretability could be misused to optimise persuasive manipulation and, if linked with personal neural data, undermine privacy."
        },
        {
            "title": "6 Limitation",
            "content": "Although we applied HFTP to both Chinese and English corpora for LLMs, our sEEG data were collected in China and primarily involve Chinese stimuli. We have preliminary English responses from single Chinese native participant, but deeper cross-linguistic analyses are pending; future work will recruit native English speakers to validate alignment on English and enable rigorous cross-linguistic tests.Additionally, we evaluated only small set of model architectures and parameter scales, so the key universal mechanisms driving modelbrain syntactic alignment remain unclear and warrant further investigation."
        },
        {
            "title": "References",
            "content": "Noam Chomsky. Aspects of the Theory of Syntax. MIT Press, 1965. 10 Noam Chomsky. Rules and Representations. Columbia University Press, 1980. William Matchin and Emily Wood. Syntax-sensitive regions of the posterior inferior frontal gyrus and the posterior temporal lobe are differentially recruited by production and perception. Cerebral cortex communications, 1(1):tgaa029, 2020. Angela Friederici. The brain basis of language processing: from structure to function. Physiological reviews, 91(4):13571392, 2011. Christophe Pallier, Anne-Dominique Devauchelle, and Stanislas Dehaene. Cortical representation of the constituent structure of sentences. Proceedings of the National Academy of Sciences, 108(6): 25222527, 2011. Matthew Nelson, Imen El Karoui, Kristof Giber, Xiaofang Yang, Laurent Cohen, Hilda Koopman, Sydney Cash, Lionel Naccache, John Hale, Christophe Pallier, et al. Neurophysiological dynamics of phrase-structure building during sentence processing. Proceedings of the National Academy of Sciences, 114(18):E3669E3678, 2017. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. Kyle Mahowald, Anna Ivanova, Idan Blank, Nancy Kanwisher, Joshua Tenenbaum, and Evelina Fedorenko. Dissociating language and thought in large language models. Trends in cognitive sciences, 2024. Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, and Xing Wang. Exploring human-like translation strategy with large language models. Transactions of the Association for Computational Linguistics, 12:229246, 2024. Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis, Anna Seehofnerová, et al. Adapted large language models can outperform medical experts in clinical text summarization. Nature medicine, 30(4):11341142, 2024. Christopher Manning, Kevin Clark, John Hewitt, Urvashi Khandelwal, and Omer Levy. Emergent linguistic structure in artificial neural networks trained by self-supervision. Proceedings of the National Academy of Sciences, 117(48):3004630054, 2020. Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg. Assessing the ability of lstms to learn syntaxsensitive dependencies. Transactions of the Association for Computational Linguistics, 4:521535, 2016. Tom McCoy, Ellie Pavlick, and Tal Linzen. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 34283448, 2019. Nai Ding, Lucia Melloni, Hang Zhang, Xing Tian, and David Poeppel. Cortical tracking of hierarchical linguistic structures in connected speech. Nature Neuroscience, 19(1):158164, January 2016. Nai Ding, Xunyi Pan, Cheng Luo, Naifei Su, Wen Zhang, and Jianfeng Zhang. Attention is required for knowledge-based sequential grouping: insights from the integration of syllables into words. Journal of Neuroscience, 38(5):11781188, 2018. Anne Keitel, Joachim Gross, and Christoph Kayser. Perceptually relevant speech tracking in auditory and motor cortex reflects distinct linguistic features. PLoS biology, 16(3):e2004473, 2018. Andrea Martin and Leonidas AA Doumas. mechanism for the cortical computation of hierarchical linguistic structure. PLoS biology, 15(3):e2000663, 2017. Cheng Luo and Nai Ding. Cortical encoding of acoustic and linguistic rhythms in spoken narratives. Elife, 9:e60433, 2020. Cas Coopmans, Helen De Hoop, Peter Hagoort, and Andrea Martin. Effects of structure and meaning on cortical tracking of linguistic units in naturalistic speech. Neurobiology of Language, 3(3):386412, 2022. Angela Friederici and Jens Brauer. Syntactic complexity in the brain. In Functional neuroimaging of syntactic processing, pages 491506. John Benjamins Publishing, 2009. Peter Hagoort. Muc (memory, unification, control) and beyond. Frontiers in Psychology, 4:416, 2013. Idan Blank, Zuzanna Balewski, Kyle Mahowald, and Evelina Fedorenko. Syntactic processing is distributed across the language system. NeuroImage, 127:307323, 2016. Philippe Albouy, Lucas Benjamin, Benjamin Morillon, and Robert Zatorre. Distinct sensitivity to spectrotemporal modulation supports brain asymmetry for speech and melody. Science, 367(6481): 10431047, 2020. Evelina Fedorenko, Idan Asher Blank, Matthew Siegelman, and Zachary Mineroff. Lack of selectivity for syntax relative to word meanings throughout the language network. Cognition, 203:104348, 2020. Luyao Chen, Tomas Goucha, Claudia Männel, Angela Friederici, and Emiliano Zaccarella. Hierarchical syntactic processing is beyond mere associating: Functional magnetic resonance imaging evidence from novel artificial grammar. Human Brain Mapping, 42(10):32533268, 2021. Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom. Lstms can learn syntax-sensitive dependencies well, but modeling structure makes them better. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14261436, 2018. John Hewitt and Christopher D. Manning. structural probe for finding syntax in word representations. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 41294138, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. Kevin Clark. What does bert look at? an analysis of berts attention. arXiv preprint arXiv:1906.04341, 2019. Ian Tenney, Dipanjan Das, and Ellie Pavlick. Bert rediscovers the classical nlp pipeline. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 45934601. ACL, 2019. Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. Neural encoding and decoding with distributed sentence representations. IEEE Transactions on Neural Networks and Learning Systems, 32(2):589603, 2020. Martin Schrimpf, Idan A. Blank, Greta Tuckute, Conrad Kauf, Eliana A. Hosseini, Nancy Kanwisher, Joshua B. Tenenbaum, and Evelina Fedorenko. The neural architecture of language: Integrative modeling converges on predictive processing. Proceedings of the National Academy of Sciences, 118(45):e2105646118, 2021. Charlotte Caucheteux, Alexandre Gramfort, and Jean-Remi King. Disentangling syntax and semantics in the brain with deep networks. In International conference on machine learning, pages 1336 1348. PMLR, 2021. Charlotte Caucheteux and Jean-Rémi King. Brains and algorithms partially converge in natural language processing. Communications biology, 5(1):134, 2022. Shaonan Wang, Jiajun Zhang, Nan Lin, and Chengqing Zong. Probing brain activation patterns by dissociating semantics and syntax in sentences. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 92019208, 2020. 12 SubbaReddy Oota, Manish Gupta, and Mariya Toneva. Joint processing of linguistic properties in brains and language models. Advances in Neural Information Processing Systems, 36:18001 18014, 2023. Eghbal Hosseini, Colton Casto, Noga Zaslavsky, Colin Conwell, Mark Richardson, and Evelina Fedorenko. Universality of representation in biological and artificial neural networks. bioRxiv, pages 202412, 2024. Greta Tuckute, Aalok Sathe, Shashank Srikant, Maya Taliaferro, Mingye Wang, Martin Schrimpf, Kendrick Kay, and Evelina Fedorenko. Driving and suppressing the human language network using large language models. Nature Human Behaviour, 8(3):544561, 2024. Ariel Goldstein, Zaid Zada, Eliav Buchnik, Mariano Schain, Amy Price, Bobbi Aubrey, Samuel Nastase, Amir Feder, Dotan Emanuel, Alon Cohen, et al. Shared computational principles for language processing in humans and deep language models. Nature neuroscience, 25(3):369380, 2022. Jingwei Sheng, Li Zheng, Bingjiang Lyu, Zhehang Cen, Lang Qin, Li Hai Tan, Ming-Xiong Huang, Nai Ding, and Jia-Hong Gao. The cortical maps of hierarchical linguistic structures during speech perception. Cerebral cortex, 29(8):32323240, 2019. Stefan Frank and Jinbiao Yang. Lexical representation explains cortical entrainment during speech comprehension. PloS one, 13(5):e0197304, 2018. Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons in pretrained transformers. arXiv preprint arXiv:2104.08696, 2021. Mor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav Goldberg. Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space. arXiv preprint arXiv:2203.14680, 2022. Michael X. Cohen. Analyzing Neural Time Series Data: Theory and Practice. MIT Press, 2014. Na Xu, Baotian Zhao, Lu Luo, Kai Zhang, Xiaoqiu Shao, Guoming Luan, Qian Wang, Wenhan Hu, and Qun Wang. Two stages of speech envelope tracking in human auditory cortex modulated by speech intelligibility. Cerebral Cortex, 33(5):22152228, 2023. Qian Wang, Lu Luo, Na Xu, Jing Wang, Ruolin Yang, Guanpeng Chen, Jie Ren, Guoming Luan, and Fang Fang. Neural response properties predict perceived contents and locations elicited by intracranial electrical stimulation of human auditory cortex. Cerebral Cortex, 34(2):bhad517, 2024. Radoslaw Martin Cichy, Aditya Khosla, Dimitrios Pantazis, Antonio Torralba, and Aude Oliva. Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence. arXiv preprint arXiv:1406.3284, 2014. Seyed Mohammad Khaligh-Razavi and Nikolaus Kriegeskorte. Deep supervised, but not unsupervised, models may explain it cortical representation. PLoS computational biology, 10(11): e1003915, 2014. Nikolaus Kriegeskorte, Marieke Mur, and Peter Bandettini. Representational similarity analysisconnecting the branches of systems neuroscience. Frontiers in systems neuroscience, 2:4, 2008. Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, et al. Gemma: Open models based on gemini research and technology. arXiv preprint arXiv:2403.08295, 2024a. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023. Ning Cheng, Zhaohui Yan, Ziming Wang, Zhijie Li, Jiaming Yu, Zilong Zheng, Kewei Tu, Jinan Xu, and Wenjuan Han. Potential and limitations of llms in capturing structured semantics: case study on srl. In International Conference on Intelligent Computing, pages 5061. Springer, 2024. Tianyi Tang, Wenyang Luo, Haoyang Huang, Dongdong Zhang, Xiaolei Wang, Xin Zhao, Furu Wei, and Ji-Rong Wen. Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models, February 2024. Zhe Zhao, Hui Chen, Jinbin Zhang, Xin Zhao, Tao Liu, Wei Lu, Xi Chen, Haotang Deng, Qi Ju, and Xiaoyong Du. UER: An Open-Source Toolkit for Pre-training Models. EMNLP-IJCNLP 2019, page 241, 2019. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. Gemma 2: Improving open language models at practical size. arXiv e-prints, pages arXiv2408, 2024b. Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, et al. Chatglm: family of large language models from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793, 2024. Edmund Rolls, Marc Joliot, and Nathalie Tzourio-Mazoyer. Implementation of new parcellation of the orbitofrontal cortex in the automated anatomical labeling atlas. Neuroimage, 122:15, 2015."
        },
        {
            "title": "A Alignment pipeline for syntactic processing between LLMs and the human",
            "content": "brain This appendix we provide the detailed pipeline used to align the syntactic structure representations in LLMs with those in the human brain, focusing on detecting and comparing sentence/phrase representations across both systems. Data and Experimental Setup To maintain consistency between the LLM and human experiments, we used the same two corpora: sentence corpus (four-syllable Chinese sequence) and phrase corpus (two-syllable Chinese sequence). The word-order randomized version of each corpus was used as control condition, as detailed in Section 3.1. Each corpus included 40 trials and each trial contains 36 syllables. For SRDM calculation, the corpora were divided into six experimental conditions, each with 20 trials. Sentence/phrase representations of the last 32 syllables were extracted from both LLMs and human subjects to reduce the strong responses at word onset in both systems. The representations are then transformed into the frequency domain. Frequency-Domain Transformation and Similarity Metrics For the LLMs, neuron activations were transformed using FFT to capture the frequency components of structure processing across the six conditions. From this transformation, we calculated the cosine similarity between each pair of conditions, constructing an SRDM for each MLP neuron. Similarly, for the human brain, we calculated the ITPC to capture frequency-domain representations for each brain channel, producing channel SRDM. To assess the structure alignment between LLMs and the human brain, we computed the Spearman correlation ρ between the SRDM of each LLM layer and the SRDM of each brain channel. We then grouped the model SRDMs at the layer level by averaging the cosine similarity across neurons for fixed layer. The top 100 most relevant brain channels for each model layer were identified based on Spearman correlation, and the overlap of sentence/phrase channels in these top 100 channels was evaluated using chi-square test. significant overlap indicated alignment in structure processing between LLMs and brain ROIs. Model-Brain Similarity and Model-Region Similarity Two key metrics were defined to quantify the structure alignment between LLMs and the human brain. The first, model-brain similarity S(m, b), represents the overall similarity of syntactic processing between an LLM and the human brain b. It is calculated as the average Spearman correlation between the SRDM of each LLM layer and the top 100 most relevant brain channels: S(m, b) = 1 (cid:88) j=1 1 100 100 (cid:88) itop(j) ρ(Lj, Ci), (4) where is the number of layers of an LLM; Lj and Ci denote the model layer and the brain channel with the indices and respectively; top(j) means the indices of top 100 channels in terms of model layer Lj; and ρ(Lj, Ci) denotes the Spearman correlation between the model SRDM at layer Lj and the SRDM for brain channel Ci. The second metric, model-region similarity S(m, br), measures the alignment between LLMs and specific brain ROIs. This is calculated by averaging the Spearman correlation for the top 100 channels within particular brain ROI: S(m, br) = 1 (cid:88) j=1 1 n(j, r) n(j,r) (cid:88) itop(j)Cr ρ(Lj, Ci), (5) where Cr denotes the indices of all channels belonging to the specific region r, and n(j, r) means the total number of indices in top(j) Cr, i.e. the number of channels belonging to region and at the same time within the top 100 channels in terms of model layer Lj."
        },
        {
            "title": "B Predictive encoding control analysis",
            "content": "To provide an orthogonal test of modelbrain alignment that does not depend on representational similarity analysis, we implemented predictive encoding model that asks whether layer-wise features extracted from an LLM can predict the frequencydomain sEEG responses of individual channels. All experimental settings (e.g. sentence/phrase corpora, block structure) were matched to those in the RDMRSA pipeline (Section A). We also adopt the same summary metrics, modelbrain similarity S(m, b) and modelregion similarity S(m, br), so that the predictive encoding results are directly comparable to the SRDM-RSA results reported above. Model features For each model layer Lj we first selected significant neurons using the same procedure as in the SRDM-RSA pipeline. Within given block, the time courses of the significant neurons were averaged to obtain one 32-sample sequence per layer and block (the last 32 syllables). We then applied FFT to this layer-average and retained the complex coefficients within 0.52 Hz. Each retained coefficient was represented by its real part and imaginary part (the canonical cosine and sine components), which we treat as two features at that frequency. With two blocks per corpus, we formed the predictor matrix Xj RN 2 by stacking samples across blocks and frequencies, where denotes the number of frequency bins in 0.52 Hz and = 2K reflects the two blocks times frequencies. Thus each of the samples corresponds to one (block, frequency) pair and is described by two-dimensional feature vector containing the real and imaginary parts of the aligned model coefficient. Brain responses For each sEEG channel Ci, we computed ITPC exactly as in the SRDM-RSA analysis, yielding complex spectrum per block. We then aligned the frequency axes of the model and brain spectra by nearest-neighbor matching (model sampling 4 Hz; sEEG 512 Hz) within the 0.52 Hz band. The target for predictive modeling was the band-limited spectral profile of stimulus-locked synchrony for channel Ci; specifically, we concatenated the ITPC amplitudes across the two blocks and across all frequencies to obtain an observation vector yi RN . This vector summarizes the oscillatory response of channel Ci within the syntactic band while preserving block-specific structure. Predictive model and cross-validation For each pair (Lj, Ci) we fit ridge regression with standardized predictors, ˆβ = arg min β (cid:13)yi Xjβ(cid:13) (cid:13) 2 2 + αβ2 2, (cid:13) (6) using five random splits (train/test = 70/30). The ridge penalty α was chosen only on the training split via inner ridge-CV over logarithmic grid; the fitted model was then evaluated on the held-out test data. Predictive accuracy for split was defined as Spearman correlation ρ between the predicted and observed test targets. We averaged the split-wise correlations to obtain predictive score (Lj, Ci) = Esplits (cid:2)ρ(cid:0)ˆy test , ytest (cid:1)(cid:3), (7) and repeated this procedure independently for left and right hemispheres and for both corpora. Note that feature selection is performed exclusively on the model side; the sEEG data are never used to select features, preventing circularity. Aggregation into alignment metrics To summarize predictive alignment, we follow the exact aggregation used for SRDM-RSA pipeline and therefore reuse the definitions of S(m, b) and S(m, br) introduced in Section A. The only substitution is that SRDM correlations ρ(Lj, Ci) are replaced by the predictive scores (Lj, Ci). Concretely, for each layer Lj we rank channels by (Lj, Ci), take the top 100, and compute S(m, b) and S(m, br) by the same layer-averaging rules as before. For the sentence corpus, we compute these summaries separately for sentence, phrase and sentence & phrase neurons and then report their arithmetic mean to yield single value per model and hemisphere. For the phrase corpus, the selection procedure yields only phrase-selective neurons; consequently no averaging across syntactic neuron types is required. This results in one modelbrain score S(m, b) and one score per ROI S(m, br) for each model in each hemisphere, directly comparable to the SRDM results while relying on predictive encoding rather than RSA. Across both corpora (Tables 3 and 4), one-way ANOVA on layer-averaged top-100 predictive scores revealed reliable between-model differences in brain-level alignment S(m, b) (sentence: = 43.37, < 0.001, η2 = 0.008; phrase: = 13.80, < 0.001, η2 = 0.008), with consistently higher alignment in the left hemisphere. At the region level, FDR-controlled one-way ANOVAs showed significant between-model effects within left-dominant language cortices (e.g., Table 3: Predictive alignment results under the sentence corpus. The first row reports the overall modelbrain similarity S(m, b); subsequent rows report the modelregion similarity S(m, br). Bold in the S(m, b) row marks the single highest value across models/hemispheres; within each model, bold highlights the three highest S(m, br) entries across all ROIs and hemispheres. GPT-"
        },
        {
            "title": "Gemma",
            "content": "Gemma 2 Llama 2 Llama 3.1 GLM-4 L L L S(m, b) 0.487 0.371 0.467 0.364 0.469 0.371 0.472 0.364 0.463 0.365 0.471 0. A1 STG MTG ITG Insula TPJ Temporal Pole Sensorimotor IFG MFG Hippocampus Amygdala 0.515 0.375 0.473 0.368 0.474 0.360 0.470 0.388 0.470 0.360 0.485 0.376 0.499 0.384 0.469 0.357 0.472 0.369 0.480 0.369 0.464 0.373 0.476 0.374 0.487 0.370 0.468 0.366 0.470 0.375 0.475 0.369 0.465 0.366 0.469 0.371 0.479 0.370 0.463 0.361 0.466 0.367 0.466 0.360 0.457 0.362 0.466 0.364 0.486 0.373 0.459 0.368 0.468 0.377 0.476 0.376 0.463 0.363 0.473 0.370 0.474 0.345 0.468 0.349 0.466 0.361 0.463 0.347 0.462 0.347 0.467 0.350 0.484 0.384 0.467 0.362 0.455 0.373 0.475 0.365 0.459 0.362 0.469 0.351 0.491 0.373 0.470 0.363 0.471 0.375 0.470 0.362 0.466 0.366 0.472 0.370 0.480 0.370 0.465 0.365 0.465 0.366 0.466 0.360 0.462 0.359 0.467 0.364 0.475 0.367 0.457 0.374 0.462 0.364 0.466 0.355 0.453 0.373 0.462 0.376 0.481 0.358 0.464 0.365 0.458 0.366 0.462 0.353 0.458 0.360 0.469 0.362 0.472 0.334 0.463 0.345 0.465 0.362 0.452 0.353 0.463 0.358 0.471 0.349 Table 4: Predictive alignment results under the phrase corpus. The first row reports the overall modelbrain similarity S(m, b); each subsequent brain ROI row reports the modelregion similarity S(m, br). Bold in the S(m, b) row marks the single highest value across models/hemispheres; within each model, bold highlights the three highest S(m, br) entries across all ROIs and hemispheres. GLM-4 Llama 3.1 Gemma 2 Llama Gemma GPT-2 R L R S(m, b) 0.454 0.356 0.465 0.362 0.465 0.366 0.446 0.350 0.451 0.354 0.449 0.349 A1 STG MTG ITG Insula TPJ Temporal Pole Sensorimotor IFG MFG Hippocampus Amygdala 0.448 0.351 0.478 0.343 0.482 0.345 0.451 0.365 0.452 0.333 0.443 0.344 0.463 0.363 0.468 0.364 0.470 0.363 0.448 0.356 0.455 0.352 0.458 0.357 0.450 0.357 0.464 0.362 0.462 0.366 0.445 0.363 0.448 0.348 0.445 0.345 0.449 0.348 0.465 0.359 0.460 0.363 0.445 0.346 0.448 0.352 0.448 0.345 0.453 0.360 0.461 0.360 0.462 0.365 0.446 0.348 0.451 0.354 0.452 0.344 0.454 0.350 0.462 0.361 0.460 0.361 0.444 0.343 0.450 0.350 0.448 0.349 0.461 0.371 0.464 0.363 0.464 0.365 0.450 0.347 0.448 0.354 0.452 0.344 0.461 0.371 0.464 0.363 0.464 0.365 0.450 0.347 0.448 0.354 0.452 0.344 0.450 0.351 0.454 0.362 0.453 0.358 0.437 0.343 0.454 0.353 0.448 0.347 0.451 0.328 0.466 0.333 0.460 0.361 0.455 0.330 0.455 0.353 0.457 0.351 0.454 0.354 0.453 0.363 0.463 0.357 0.436 0.344 0.454 0.354 0.434 0.354 0.403 0.361 0.420 0.391 0.450 0.355 0.385 0.349 0.402 0.386 0.389 0. STG, MTG, ITG) for both corpora. These findings align with the SRDMRSA analyses, which likewise demonstrate significant between-model variation at both whole-brain and region-specific levels. Mirroring the SRDMRSA trend, the predictive results exhibit an almost identical trend for model upgrade comparison. In the sentence corpus, the left-hemisphere modelbrain scores reproduce the RSA orderingGemma 2 exceeds Gemma (S(m, b) = 0.469 vs. 0.467, L), while Llama 3.1 falls below Llama 2 (0.463 vs. 0.472, L). In the phrase corpus, the gaps compress: Gemma 2 is essentially tied with Gemma (both S(m, b) = 0.465, L), and Llama 3.1 is slightly higher than Llama 2 (0.451 vs. 0.446, L). This compression likely arises because phrase analyses use only phrase neurons and provide fewer, noisier frequency samples, which together reduce model separability. Taken together, the predictive encoding and SRDMRSA analyses converge on consistent, method-robust conclusion: inter-model differences are statistically reliable at both the brain and region levels, and, at the brain level, model-upgrade trends are essentially identical across methods, with only minor fluctuations. 17 Bilingual sentenceand phrase-level representations in LLMs Previous studies have explored how LLMs handle different languages, concluding that while most neurons are shared across languages, smaller subset of neurons is dedicated to processing specific languages [Tang et al., 2024]. But does this hold true for syntactic structure perception? This appendix provides insights into this question. It is important to note that the GPT-2 model used in this study was pre-trained on Chinese corpus using the Universal Encoder Representations (UER) framework [Zhao et al., 2019], equipping it with the capability to process both Chinese and English text effectively. This stands in contrast to the original GPT-2 model [Radford et al., 2019], which lacks the ability to handle Chinese text. (a) GPT- (b) Gemma (c) Gemma 2 (d) Llama 2 (e) Llama 3.1 (f) GLM-4 Figure 7: Cross-language neural representations extracted from five multilingual models (Gemma, Gemma 2, Llama 2, Llama 3.1, and GLM-4) depicting syntactic processing capabilities. The results in Figure 7 suggest that language-specific syntactic neurons (i.e., exclusive sentence/phrase neurons) tend to cluster toward the final layers of Llama 2, Llama 3.1, and GLM-4, with the proportion of bilingual neurons (Chinese & English) increasing progressively in deeper layers. In contrast, Gemma and Gemma 2 display different patterns. In Gemma, both language-specific and bilingual 18 neurons are found not only in the deeper layers but also in the initial layers, whereas this is only observed in the early layers of Gemma 2. GPT-2, on the other hand, exhibits more balanced distribution, with both language-specific and bilingual neurons present in almost every layer in roughly equal proportions. Furthermore, English-specific neurons are more prominent in the early layers, while Chinese-specific neurons are more concentrated in the later layers. Interestingly, Llama 3.1 shows notably lower count of Chinese-specific neurons compared to English-specific neurons in the final layer, and fewer Chinese & English neurons than the other five LLMs. Although Llama 3.1 was pre-trained on 176 languages [Dubey et al., 2024], it appears to have less specialization in Chinese, which may explain the reduced presence of Chinese-specific neurons and, consequently, fewer bilingual neurons."
        },
        {
            "title": "D Preliminary bilingual HFTP test on native Chinese speakers",
            "content": "As noted above, our HFTP analysis was originally conducted on native Chinese speakers listening to Chinese corpus. To probe cross-linguistic generalization in human sEEG, we constructed bilingual materials by taking the Chinese corpus from [Sheng et al., 2019] and manually translating it into four-word English sequences. We report preliminary results from one native Chinese speaker who listened to both corpora. Hierarchical frequency patterns for the Chinese corpus closely match those in Figure 5, and the corresponding English results are shown in Figure 8. Figure 8: Hierarchical frequency patterns of sEEG channels from one participant, using four-word English sequence, selectively represent sentence features, phrase features, shared features of both and non-sensitive feature (from left to the right). Shaded bands show 1 s.e.m. computed within each channel by bootstrapping across sliding-window ITPC estimates. Notably, the English condition exhibits robust sentence- (1 Hz) and phrase-rate (2 Hz) peaks, mirroring the Chinese condition and indicating alignment to hierarchical syntactic structure beyond the native language of the participant. Building on this convergence, we hypothesize that English speakers who also understand Chinese will likewise exhibit sentenceand phrase-rate peaks under the same experimental setting. The concordance of spectra motivates cross-linguistic interpretation in which the 1 and 2 Hz signature reflects domain-general constraints on chunking and predictive parsing rather than language-specific lexical statistics. Hence cross-linguistic factors such as function-word density may redistribute spectral power but should not abolish the peaks. This view also aligns with Ding et al. [Ding et al., 2016], who showed that the syntactic structure hierarchy is language-general signature of syntactic grouping, independent of word-order typology or writing system."
        },
        {
            "title": "E Contribution Ratios of LLMs",
            "content": "To further investigate the role of specific brain ROIs in syntactic processing, we introduced the contribution ratio (CRr). The contribution ratio highlights which brain ROIs contribute most significantly to the syntactic alignment between LLMs and the human brain. Fixing model layer, this metric quantifies the influence of each brain ROIs by calculating the proportion of channels from given region within the top 100 most relevant channels, normalized by the overall representation of the ROIs (results can be found in Appendix E). The contribution ratio is defined as: CRr(Lj) = top (Lj)/N top /N total total , 19 (8) where top (Lj) is the number of channels in region within the top 100 channels in terms of the LLM layer Lj, top is the total number of top channels, which is specified as 100 in this case, total is the total number of channels in region r, and total is the total number of brain channels. In this appendix we present the contribution ratio results for six LLMs used in this study: GPT-2, Gemma, Gemma 2, Llama 2, Llama 3.1, and GLM-4. Specifically, the contribution ratio for each model was calculated based on the number of top 100 significant channels within each brain ROIs, as described in Appendix A. Below, we present the results for both the left (L) and right (R) hemispheres of each model (See Figures 15, 16, 17, 18, 19 and 20). These figures offer further insights into how different LLMs align with human brain ROIs in terms of syntactic processing. From these figures, we observe that across all LLMs, regions such as A1 and STG in the left hemisphere, and the Insula, Temporal Pole, and Amygdala in the right hemisphere contribute more significantly to the alignment with human brain syntactic processing. These regions are known to be involved in language-specific processes in the human brain, particularly in the left hemisphere, where the STG and A1 are crucial for auditory and syntactic processing. The alignment results suggest that these models may be capturing aspects of hierarchical syntactic structures in ways that are functionally similar to human neural mechanisms. The Insula, Temporal Pole, and Amygdala, though not traditionally highlighted as primary language regions, may also play supporting roles in language comprehension, possibly through emotion and memory-related pathways. This suggests that LLMs might engage both language-specific and auxiliary brain ROIs to process syntax, mirroring the integrated and distributed nature of human brain networks involved in language processing."
        },
        {
            "title": "F HFTP on naturalistic corpus",
            "content": "Apart from validating HFTP with highlycontrolled foursyllable/word sequences, we show that this probe generalises smoothly to naturalistic text drawn from everyday dialogue, news reports, literary excerpts, poetry, etc. In these eightand nine-syllable Chinese corpora and in matched English 8and 9-word corpora (Figures 910, 1112) the method yields four pronounced spectral peaks per condition. For the eight-syllable set, peaks arise at 0.5, 1.0, 1.5 and 2.0 Hz, corresponding to the fullsentence envelope, the canonical 4-character phrase rhythm, an intermediate 23-beat grouping around 1.5 Hz, and the ubiquitous 2-character lexical rhythm, with the English 8-word corpus exhibiting the same four-peak pattern at the corresponding sentence and phrase rates (Figure 11). In nine-syllable sentences the peaks shift to 0.44, 0.89, 1.33, and 1.78 Hz: the lowest peak reflects the whole clause, 1.33 Hz aligns with abundant 3-character phrases, 1.78 Hz captures rapid two-to-three-character alternations, and the 0.89 Hz component indexes prosodic half-sentence breath group of fourtofive characters, and the English 9-word corpus shows the analogous four peaks near these frequencies (Figure 12). We further evaluated HFTP on Chinese and English Wikipedia 8-syllable/word corpora (Figures 1314). In both languages clear sentence peak appears at 0.5 Hz, and phrase-rate peaks persist at 1.0, 1.5, and 2.0 Hz; however, relative to non-Wikipedia corpora the peaks are attenuated, the separation between experiment and random controls is smaller, and the intermediate 1.5 Hz component is more variable. Although sequence length was strictly controlled to eight syllables/words, Wikipedia text is less regular in content: mixed scripts/orthographies (e.g., simplified vs. traditional in Chinese), frequent abbreviations and alphanumeric tokens, bibliographic fragments and formulaic titles, heterogeneous named entities, inconsistent prosodic phrasing, etc. These factors reduce crosssentence periodicity and weaken harmonic reinforcement, thereby weakening tracking at sentenceand phrase-rate rhythms. We speculate that the four dominant frequencies arise from tokenisation statistics and prosodic templating shared across languages: frequent twoand three-token words and binomial/trinomial chunks in English, and abundant 2-/3-character words and 4-character idioms in Chinese; both yield stable 2and 3-beat groupings, while clause-level phrasing produces half-sentence rhythm. Transformer layers further reinforce harmonics of the basic word cycle; in the nine-syllable corpus, 3-beat unit around 1.33 Hz naturally gives rise to higher harmonic near 1.78 Hz. The half-sentence peak at 0.89 Hz emerges because speakers often place prosodic break near the midpoint of ninecharacter or nine-word clauses, creating stable sub-sentence rhythm that the model entrains to. Because the underlying rhythmic structure is shared, we believe HFTP is highly likely to generalise 20 to other character-centric languages (Japanese, Korean) and to space-delimited alphabetic languages (French, German). Figure 9: Hierarchical frequency patterns of MLP neurons, using naturalistic Chinese 8-syllable corpus, selectively represent sentence features, phrase features, shared features of both, and nonsensitive features (from left to right). Figure 10: Hierarchical frequency patterns of MLP neurons, using naturalistic Chinese 9-syllable corpus, selectively represent sentence features, phrase features, shared features of both, and nonsensitive features (from left to right). Figure 11: Hierarchical frequency patterns of MLP neurons, using naturalistic English 8-word corpus, selectively represent sentence features, phrase features, shared features of both, and nonsensitive features (from left to right)."
        },
        {
            "title": "G Model details",
            "content": "In this appendix, we present the details of the LLMs used in this study. Table 5 summarizes key parameters, including model size, number of layers, attention heads, and MLP neurons."
        },
        {
            "title": "H Syntactic corpora",
            "content": "For our HFTP experiments, we employed six corpora: two syntactic setsa Chinese four-syllable corpus  (Table 6)  and an English four-word corpus  (Table 7)  adapted from [Ding et al., 2016]; two human-generated naturalistic Chinese corpora with eight and nine syllables (Tables 8 and 9); 21 Figure 12: Hierarchical frequency patterns of MLP neurons, using naturalistic English 9-word corpus, selectively represent sentence features, phrase features, shared features of both, and nonsensitive features (from left to right). Figure 13: Hierarchical frequency patterns of MLP neurons, using Chinese Wikipedia 8-syllable corpus, selectively represent sentence features, phrase features, shared features of both, and nonsensitive features (from left to right). and two parallel naturalistic English corpora with eight and nine words (Tables 10 and 11). These corpora were used to assess model sensitivity to hierarchical structure. In addition, we constructed Wikipedia-derived Chinese and English 8-syllable/word corpora for out-of-domain validation; these corpora are available on https://github.com/LilTiger/HFTP. For the HFTP experiment in the human brain, we utilized two Chinese corpora: the sentence and phrase corpora. To ensure consistent analysis of syntactic processing across both LLMs and the human brain, the same corpora were applied to the alignment experiment. These corpora originated from [Sheng et al., 2019]. Participants received brief oral instruction to listen carefully to each stimulus, completed 40 trials per condition (sentence, phrase, and random), and were compensated approximately 200 for full participation, with pay prorated if they completed only subset of trials."
        },
        {
            "title": "I Brain ROIs",
            "content": "As discussed in Section 3.3, we reorganized the original sEEG data by grouping the Automated Anatomical Labeling (AAL) annotations into newly defined brain ROIs for our experiments [Rolls et al., 2015]. In this appendix, we provide the full names of AAL regions, the corresponding AAL labels used in the sEEG data, and their mapped brain ROIs in Table 12. 22 Figure 14: Hierarchical frequency patterns of MLP neurons, using English Wikipedia 8-word corpus, selectively represent sentence features, phrase features, shared features of both, and non-sensitive features (from left to right). Table 5: Comparison of model parameters. Model Size Layer Attention head MLP neuron GPT-2 [Radford et al., 2019] Gemma [Team et al., 2024a] Gemma 2 [Team et al., 2024b] Llama 2 [Touvron et al., 2023] Llama 3.1 [Dubey et al., 2024] GLM-4 [GLM et al., 2024] 774M 7B 9B 7B 8B 9B 36 28 42 32 32 40 20 16 16 32 32 32 5120 24576 14336 11008 14336 Table 6: Chinese syntactic corpus. Four-syllable sequences 老牛耕地 朋友请客 厨师做饭 竹鼠啃笋 农民种菜 青草发芽 和尚念经 老师讲课 鲸鱼喷水 绵羊吃草 英雄救火 游客爬山 鸭子划水 蜘蛛结网 祖父下棋 医生看病 护士打针 母鸡下蛋 行人过街 法官判案 狮子吃肉 老鹰捕鱼 蜜蜂采花 小孩读书 司机开车 画家作画 船夫摇桨 诗人吟诗 麻雀筑巢 猴子摘桃 渔夫撒网 骆驼饮水 狐狸捕鼠 海豹顶球 小猫抓鱼 老马拉车 鸽子衔枝 孩童拾贝 雏鸡啄米 山雀捉虫 青鸟啄木 樵夫砍柴 黑熊爬树 土狼挖洞 军鸽传信 燕雀喂仔 野猪拱地 渔民划船 蚯蚓钻土 蚕蛾吐丝 23 Table 7: English syntactic corpus. Four-word sequences fat rat sensed fear gold lamps shine light top chefs cook steak all moms love kids teen apes hunt bugs fun games waste time deaf ears hear you long fight caused hate slim kids like jeans pale hands make bread quiet lamb ate grass black skies show stars iced beer costs cents white cars need gas their store sold cars sharp knife cuts cheese weird clowns wear hats wood shelf holds cans dry fur rubs skin our boss wrote notes new plans give hope rude cats claw dogs pink toys hurt girls his aunt tied shoes dead sharks leak blood sick boys fail tests bad smells fill town soft fork brings food tall guys flee camp old kings gave speech young child closed doors cute cubs drink milk round soap killed germs her sons paint walls tan girls drove trucks sly fox stole eggs two teams plant trees large ants built nests rich cooks brewed tea huge waves hit ships kind words warm hearts smart dogs dig holes rear doors hide cups mad foes smack chefs green frogs miss flies gray goat climb hills blue eyes shed tears thin threads hang plates six farms lost cows loud sound scared mom 今晚一起看电影吗 Table 8: Naturalistic Chinese syntactic corpus. Eight-syllable sequences 列车准点抵达站台 森林火势得到控制 请稍等我来核对价 空调滤网需要更换 中央推出税收优惠 港口货轮密集靠泊 研究论文成功发表 画展现场气氛静谧 他缓缓走入雨巷中 明天早饭想吃啥呢 请问洗手间在哪呀 教育部发布新课程 图书馆今天人较多 古桥石栏苔痕深留 点单吗我们有套餐 快看雨停了出门吧 市场需求逐步回暖 图书销量榜单更新 快递包裹正在派送 雨夜街灯映成河影 服务员来两杯绿茶 警方破获网络诈骗 证券监管再次收紧 春雷滚过江南田畔 同学你借我下笔吧 科研团队揭量子谜 他戴上耳机工作中 学生提交毕业论文 旅行社推出特价游 老师这题怎么写呢 他整理旧照片回忆 海浪轻拍沙滩细岸 亲爱的晚餐想吃啥 喂你现在到哪里了 股市午盘震荡收高 日出染红东海天际 你好咖啡需要糖吗 桂花香飘整条街上 记者现场连线报道 乡村集市热闹开张 月光洒落在城墙上 雨天道路易积水患 数据中心全面升级 航班因雾全部延误 剧院上演经典芭蕾 智能巴士全线运营 博物馆新增夜场票 想不到你如此嚣张 南部遭遇强降雨灾 24 Table 9: Naturalistic Chinese syntactic corpus. Nine-syllable sequences 姐姐这裙子有蓝色吗 软件更新漏洞已修复 临床试验数据公布了 孩子慢点吃别噎到啊 付款可用微信是不是 晚上一起吃寿司如何 校园社团招募新成员 智能家居系统升级中 医护人员彻夜守病房 你好考试时间改了吗 我们有可乐果汁豆浆 高中将设人工智能课 他翻身查看夜空星图 摄影展聚焦城市微光 街角花店玫瑰已售罄 大雨突临烟花秀取消 他低声读完那封旧信 师傅去火车站多少钱 市场监管局突击检查 社区篮球赛今晚开哨 科研数据平台上线啦 疏影横斜暗上书窗敲 木星再添两颗小卫星 晚餐菜单更新完毕了 老板这条鱼再便宜点 卫星成功捕捉极光影 明早七点机场见好吗 他轻扣门板等待回应 电商推广使用绿色包 雨滴敲击玻璃声清脆 服务员账单麻烦拿来 旅行箱在传送带循环 喂你到公司门口了吗 音乐渐缓舞步更轻盈 国家队再夺巴黎首金 凌晨街头灯火渐稀少 新剧首播口碑节节攀 早高峰地铁挤满乘客 灯光映照湿润青石路 请坐这里视线最好哦 你好请填写到访登记 医生这药饭前还是后 请稍候我去取电影票 他轻敲键盘修改代码 咖啡豆飘散焦糖香气 同学笔记本借我一下 志愿者分发食物物资 图书销量排行榜刷新 博主分享无人机航拍 快递无人签收被退回 Figure 15: Contribution ratios for GPT-2: Left hemisphere (top) and Right hemisphere (bottom). Table 10: Naturalistic English 8-word corpus. Eight-word sequences With malice toward none, with charity toward all. man can be destroyed but not defeated. Tonight, shall we watch the meteor shower together? Excuse me, wheres the nearest restroom around here? Market demand seems gradually rebounding during this quarter. Waiter, two cups of hot green tea please. The library felt crowded during rainy examination week. Book sales rankings were refreshed early this morning. Quantum research team unveiled perplexing entanglement results yesterday. He sorted aging photographs, reminiscing about bygone days. Moonlight spilled gently across the ancient city walls. Flights were delayed nationwide due to dense fog. Autonomous buses now operate on every urban route. Southern region suffered severe flooding after Students submitted their final graduate theses by noon. Hello, where are you right now, my friend? Plum blossoms scented the courtyard with delicate sweetness. Central bank announced fresh stimulus to boost economy. He slowly wandered into the rainy narrow alleyway. Education ministry announced updated national Port cranes unloaded containers under brilliant afternoon sky. relentless rain. Please hold on, Ill check your booking details. Ready to order? We have todays special combo. Police dismantled an extensive online fraud network operation. He put on headphones and focused on coding. curriculum guidelines today. Rainy night streetlights shimmered like glowing river. Spring thunder rolled over rice paddies in Jiangnan. Could you use some sugar in your coffee? The data center completed comprehensive system upgrade. never imagined you could be this arrogant. City skyline glittered beneath crisp winter moon. Train whistle echoed across fields drenched with mist. Research findings published in prestigious journal Gentle waves lapped softly against the sandy shoreline. The rural marketplace opened lively at dawn today. The theater staged timeless classical ballet tonight. today. Tomorrow, what would you like for breakfast, friend? Ancient stone bridge retained mossy grooves through Look, the storm passed; lets explore the streets. Financial regulators tightened oversight on speculative securities trading. Travel agency launched discounted spring break tour packages. Darling, what would you like for dinner tonight? Reporter delivered live coverage from bustling downtown square. Museum introduced extended evening hours for visitors convenience. centuries. Parcel delivery is currently out for neighborhood distribution. Hey classmate, may borrow your pen briefly? Teacher, could you explain this problem once more? Osmanthus fragrance drifted along the entire narrow street. On rainy days, roads easily accumulate dangerous puddles. Night market vendors grilled skewers over glowing charcoal. 26 Table 11: Naturalistic English 9-word corpus. Nine-word sequences Clinical trial data were publicly released this morning nationwide. War is peace, freedom is slavery, ignorance is strength. Photography exhibition focuses on citys hidden pockets of light. Scientific data platform finally went live to the public. Jupiter just gained two additional tiny moons last We offer cola, soda, juice, and soy milk today. Shall we share sushi together tonight by the river? Driver, how much is the fare to the station? See you at the airport tomorrow seven sharp, alright? Raindrops drummed against windowpanes in crisp week. Hey, have you reached the company entrance yet today? Morning rush subway overflowed with restless hurried commuters again. Coffee beans release subtle caramel aroma throughout the cafe. Undelivered parcels were returned after nobody signed for them. Child, slow down and chew, avoid choking on food. High school will introduce artificial intelligence elective next year. Sudden downpour forced cancellation of tonights fireworks display completely. Slanting shadows tapped an old window softly at dusk. Ecommerce campaign now promotes sustainable green packaging materials nationwide. National team claimed its first gold medal in Paris. Please sit here; the view remains the best available. Classmate, may borrow your notebook for moment? Software update completed, critical vulnerabilities have been fixed already. Campus club seeks enthusiastic freshmen to join this semester. Corner flower shop sold out all roses before noon. Market supervision bureau conducted an unexpected compliance inspection today. Satellite captured brilliant aurora images above polar orbit yesterday. Please bring the bill, waiter, we are finished here. Lantern glow reflected onto slick cobblestones after evening drizzle. He tapped the keyboard softly, refining his source code. cadence tonight. Early morning city lights gradually faded as traffic intensified. Doctor, should this new medicine be taken before dinner? Book sales leaderboard refreshed, surprising many independent authors today. Sister, does this blue dress come in medium size? Smart home automation system is currently installing new firmware. He rolled over, consulting star chart at midnight. Community basketball tournament tips off under bright evening floodlights. Boss, could this fish be little cheaper please? Luggage carousel kept circling the unattended silver suitcase indefinitely. New drama premiere received soaring reviews across social media. Please wait, will retrieve our cinema tickets now. Influencer shared breathtaking drone footage of mountain sunrise yesterday. Payment through WeChat is available, is that alright sir? Hello, has the final exam schedule been changed recently? He whispered while finishing that fading wartime love letter. Dinner menu has been fully updated for the evening. He gently knocked, waiting patiently for someone to respond. Music slowed, dancers embraced lighter steps beneath dimmed lights. Hello, kindly complete the visitor registration form at reception. Volunteers distributed food supplies to displaced families after flood. 27 Table 12: Automated Anatomical Labeling (AAL) annotations from the original sEEG data, along with their mapped brain ROIs. Note that the regions are distinguished by the left and right hemispheres. AAL Full Name Heschl Gyrus Superior Temporal Gyrus Middle Temporal Gyrus Inferior Temporal Gyrus Parahippocampal Gyrus Fusiform Gyrus Insular Cortex Angular Gyrus Supramarginal Gyrus Inferior Parietal Lobule Superior Temporal Pole Middle Temporal Pole Paracentral Lobule Supplementary Motor Area Rolandic Operculum Precentral Gyrus Postcentral Gyrus Inferior Frontal Gyrus, Opercular part Inferior Frontal Gyrus, Triangular part Inferior Frontal Gyrus, Orbital part Middle Frontal Gyrus Middle Frontal Gyrus, Orbital part Hippocampus Amygdala ROI AAL Label A1 Heschl STG Temporal_Sup MTG Temporal_Mid ITG Temporal_Inf ITG ParaHippocampal ITG Fusiform Insula Insula TPJ Angular TPJ SupraMarginal TPJ Parietal_Inf Temporal_Pole_Sup Temporal_Pole Temporal_Pole_Mid Temporal_Pole Sensorimotor Paracentral_Lobule Sensorimotor Supp_Motor_Area Sensorimotor Rolandic_Oper Sensorimotor Precentral Sensorimotor Postcentral IFG Frontal_Inf_Oper IFG Frontal_Inf_Tri IFG Frontal_Inf_Orb MFG Frontal_Mid MFG Frontal_Mid_Orb Hippocampus Hippocampus Amygdala Amygdala Figure 16: Contribution ratios for Gemma: Left hemisphere (top) and Right hemisphere (bottom). 28 Figure 17: Contribution ratios for Gemma 2: Left hemisphere (top) and Right hemisphere (bottom). Figure 18: Contribution ratios for Llama 2: Left hemisphere (top) and Right hemisphere (bottom). Figure 19: Contribution ratios for Llama 3.1: Left hemisphere (top) and Right hemisphere (bottom). Figure 20: Contribution ratios for GLM-4: Left hemisphere (top) and Right hemisphere (bottom)."
        }
    ],
    "affiliations": [
        "Beijing Institute for General Artificial Intelligence",
        "Beijing Language and Culture University",
        "Peking University",
        "Zhejiang University"
    ]
}