{
    "paper_title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
    "authors": [
        "Keyang Xuan",
        "Pengda Wang",
        "Chongrui Ye",
        "Haofei Yu",
        "Tal August",
        "Jiaxuan You"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic, imperfect settings. To close this gap, we present \\textsc{SocialVeil}, a social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers. Grounded in a systematic literature review of communication challenges in human interaction, \\textsc{SocialVeil} introduces three representative types of such disruption, \\emph{semantic vagueness}, \\emph{sociocultural mismatch}, and \\emph{emotional interference}. We also introduce two barrier-aware evaluation metrics, \\emph{unresolved confusion} and \\emph{mutual understanding}, to evaluate interaction quality under impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45\\% on average, and confusion elevated by nearly 50\\%. Human evaluations validate the fidelity of these simulated barriers (ICC$\\approx$0.78, Pearson r$\\approx$0.80). We further demonstrate that adaptation strategies (Repair Instruction and Interactive learning) only have a modest effect far from barrier-free performance. This work takes a step toward bringing social interaction environments closer to real-world communication, opening opportunities for exploring the social intelligence of LLM agents."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 4 ] . [ 1 5 1 1 5 0 . 2 0 6 2 : r Preprint. Under review. SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers Keyang Xuan1, Pengda Wang2, Chongrui Ye1, Haofei Yu1, Tal August1, Jiaxuan You1 1Siebel School of Computing and Data Science, University of Illinois Urbana-Champaign 2Department of Psychological Sciences, Rice University"
        },
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic, imperfect settings. To close this gap, we present SOCIALVEIL1, social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers. Grounded in systematic literature review of communication challenges in human interaction, SOCIALVEIL introduces three representative types of such disruption, semantic vagueness, sociocultural mismatch, and emotional interference. We also introduce two barrier-aware evaluation metrics, unresolved confusion and mutual understanding, to evaluate interaction quality under impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45% on average, and confusion elevated by nearly 50%. Human evaluations validate the fidelity of these simulated barriers (ICC0.78, Pearson r0.80). We further demonstrate that adaptation strategies (Repair Instruction and Interactive learning) only have modest effect far from barrier-free performance. This work takes step toward bringing social interaction environments closer to real-world communication, opening opportunities for exploring the social intelligence of LLM agents."
        },
        {
            "title": "Introduction",
            "content": "The production of meaning, rather than the production of messages. Barnlund (1970) As this quote demonstrates, communication is inherently dynamic and marked by uncertainty (FeldmanHall & Shenhav, 2019). Rather than simply exchanging facts, communication involves navigating ambiguity, managing relational dynamics, and repairing misunderstandings (e.g., Clark & Brennan, 1991). For example, if it is among close friends, vague or implicit expression of an idea can often still be correctly interpreted based on shared contextual knowledge and prior experience; but among complete strangers, due to the lack of common background and mutual understanding, such vague expressions are more likely to lead to misunderstandings or communication failures (e.g., Grice, 1975). These breakdowns are not merely incidentalthey often arise from deeper, systematic influences that shape how messages are sent and received (Clark & Brennan, 1991; Schegloff et al., 1977). We define these systematic factors that hinder mutual understanding in dialogue as communication barriers (e.g., Lunenburg, 2010). Recognizing their role in shaping agent behavior is essential for socially-aware AI systems operating in complex environments, as communication barriers expose subtle failure modes overlooked by aggregate metrics and provide diagnostic insight for robust and responsible deployment (Song et al., 2025). 1Our code and data are available at https://github.com/ulab-uiuc/social-veil. Preprint. Under review. Figure 1: Existing social benchmarks typically assume idealized conditions. comparison between existing benchmarks scenarios and real-world conversations, highlighting challenges in semantic vagueness, sociocultural mismatch and emotional interference. However, constructing principled framework for simulating communication barriers is challenging due to several aspects: 1) Intractable Taxonomy. Barriers manifest at many levels, from perceptual-level acoustic interference (e.g., Cherry, 1953) to discourse-level breakdowns (e.g., Schegloff et al., 1977). Existing research still lacks well-structured and literature-supported taxonomy to reliably guide systematic investigation (Sap et al., 2019b). 2) RealismControl Tradeoff. Barriers must remain faithful to social practice yet also be instantiated in controlled and reproducible manner (Aher et al., 2023). Naive noise injection often breaks realism, whereas free-form prompts tend to sacrifice consistency and comparability. 3) Metric Insufficiency. The presence of barrier does not always entail failure of social interaction; an agent may still accomplish its goal through brute-force strategies while undermining the relationship or mutual understanding (Brown & Levinson, 1987). Thus, barrier-aware environment must evaluate not only task success but also incorporate metrics that capture the broader effects of barriers. Recent studies have introduced interactive environments and benchmarks to assess agents social intelligence capability (e.g., Chen et al., 2024; Mou et al., 2024; Zhou et al., 2023). These works are typically constructed under highly idealized conditions. Agents are presumed to share the same linguistic assumptions, sociocultural norms, and emotional registers, thereby overlooking the vagueness, misalignment, and disruptions that pervade real interaction. As discussed previously and illustrated in Figure 1, actual conversational settings are far less idealized, where communication barriers often cause misunderstandings or conflicts, creating more dynamic and complex interactional environment. To emulate real-world settings, we introduce SOCIALVEIL, framework for creating interactive social learning environments that evaluates agents social intelligence under communication barriers. Through systematic literature review, we identify three communication barriers rooted in cognitive factors (Sperber & Wilson, 1986): Semantic Vagueness, Sociocultural Mismatch, and Emotional Interference. We construct 180 episodes for each of the three barrier types as well as for barrier-free baseline, resulting in total of four sets of episodes. These scenarios are adapted from SOTOPIA (Zhou et al., 2023). To capture communication barriers impact beyond social interaction task completion, we introduce barrier-aware evaluation protocol and conduct comprehensive evaluation of four frontier LLMs and verify their validity through comprehensive human evaluation. We further implement targeted interventions, such as repair-oriented instruction and the interactive learning framework, to enhance the agents ability to engage in social interactions in barrier scenarios. Main Discoveries. Our analysis demonstrates that communication barriers consistently impair agents social intelligence capabilities. For example, Semantic Vagueness often prevents agents from establishing shared context, leading to substantial declines in mutual understanding (58%), and Emotional Interference often disrupts relationship quality (49%). We further validate the fidelity of simulated barriers and the reliability of our evaluation protocol through human evaluation: annotators have demonstrated strong inter-rater relia2 Preprint. Under review. bility (avg ICC 0.78), were able to accurately identify barrier types (avg Accuracy 68%), and showed strong alignment with automatic metrics (avg Pearsons 0.80). Furthermore, our exploration of potential adaptation strategies reveals that neither static nor dynamic interventions can effectively counteract these barriers, underscoring that SOCIALVEIL presents fundamental challenge that transcends simple heuristic or supervised adjustments. Overall, our contributions are as follows: 1) We introduce SOCIALVEIL, barrier-aware, interactive social learning environment for simulating and evaluating LLM agents social intelligence under barrier scenarios. 2) We propose an automated, barrier-aware evaluation protocol that complements conventional goal-oriented measures by explicitly capturing whether agents can maintain interaction and repair misunderstandings under communication barriers. 3) We demonstrate that barriers simulated in SOCIALVEIL induce effects that align with their real-world counterparts, validating the frameworks fidelity as proxy for studying real-world interaction. 4) We explore adaptation strategies for enhancing agents performance under barriers, showing that while repair instructions are largely ineffective, interactive learning yields steady yet limited improvements, highlighting both the promise of adaptive training and the remaining gap to human-level resilience."
        },
        {
            "title": "2 SocialVeil: A Barrier-Aware Social Learning Environment",
            "content": "To better reflect real-world conditions, we propose barrier-aware, socially interactive environment (SOCIALVEIL) with the following desiderata: 1) Task Agnostic. Barriers should preserve social goals and context. 2) Structured Disruptions. Barriers should be systematically designed to induce specific level of disruption. 3) Barrier-aware Evaluation. Environment must support evaluation beyond goal-oriented dimensions to capture the communication failures induced by the barriers. An overview of SOCIALVEIL is shown in Figure 2. We first introduce the creation of the barrier taxonomy (2.1), followed by their implementation (2.2), simulation setup (2.3) and evaluation protocol (2.4). Barrier Type Definition Real-world Example Theoretical Grounding Semantic Vagueness Sociocultural Mismatch Emotional Interference Explicit referents are substituted with indeterminate pronouns or empty placeholders, leaving interpretation underspecified and prone to ambiguity. Cultural differences in communication styles lead to misaligned interpretations and hinder explicit understanding. Affective intensity overrides informational clarity, displacing task-relevant content with expressive overflow. It might work... you know what mean. Pragmatics (Grice, 1975); Hedges (Lakoff, 1973); Fuzzy logic (Zadeh, 1965) Well think about it. Taken as postponement, but meant as refusal. Politeness (Brown & Levinson, 1987); Context theory (Hall, 1976); Linguistic relativity (Sapir, 1929) Im too upset to explainjust figure it out yourself! Attention (Eysenck et al., 2007); Emotion regulation (Gross, 1998b); Appraisal (Lerner & Keltner, 2000); Table 1: Three types of communication barriers in SOCIALVEIL, theoretically grounded and operationalized to reflect real-world interaction patterns."
        },
        {
            "title": "2.1 Barrier Taxonomy",
            "content": "Although external, physical barriers such as loud noise can obstruct the transmission of information, this study focuses on cognitive factors that hinder understanding, reasoning, and decision-making. Through systematic review of research on interaction and communication, we identified three major categories of communication barriers induced by cognitive factors: Semantic Vagueness, ambiguity from vague pronouns or unspecified placeholders; Sociocultural Mismatch, misaligned interpretations across cultural communication styles; and Emotional Interference, affective intensity that obscures task content and negatively influences performance. Table 1 provides definitions, examples, and theoretical grounding for each barrier (details of the literature review presented in Appendix C). 3 Preprint. Under review."
        },
        {
            "title": "2.2 Barrier Design",
            "content": "In SOCIALVEIL, we instantiate communication barriers unilaterally. Let be the barrier set defined in 2.1; One agent, designated as the barrier agent, communicates under chosen barrier condition, while the partner agent remains in standard settings. Each barrier is instantiated by composing style prompt Pb with parameterization Rb over four operational dimensions: Narrative Stance (overall communication style, e.g., indirectness or emotion-focus), Interaction Tactics (linguistic devices such as vague words, placeholder nouns, indirect refusals), Confusion Mechanisms (behaviors that block understanding, e.g., withholding confirmation), and Exemplar Templates (example patterns for reproducibility). In practice, each barrier is implemented through two-layer design. The style prompt Pb encodes high-level directive (e.g., overuse pronouns and ellipses for semantic vagueness), while the parameterization Rb specifies quantitative cues that render the behavior reproducible. During simulation, Pb and Rb are utilized only for the barrier agent, whereas the partner agent remains unmodified (Pb = , Rb = ), ensuring the barrier is the sole source of disruption and making evaluation controlled and repeatable."
        },
        {
            "title": "2.3 Simulation Setup",
            "content": "Episode Design. An SOCIALVEIL episode is two-agent role-play in which each agent is assigned private social goal and role profile. One agent, designated as the barrier agent, communicates under chosen barrier condition, while the other, the partner agent, remains unmodified. This asymmetric design reflects natural human scenarios: For instance, colleague whose indirect style obscures intent, or teammate whose emotions color their contributions. To construct episodes, we adapt scenarios from existing social benchmarks and apply neutralization step to their public scenario descriptions, which may otherwise leak the agents private goals. Specifically, we use GPT-4o (Hurst et al., 2024) to rewrite each scenario description following fixed instructions (Appendix H.1) to eliminate goalrelated hints. This ensures that both agents share the same public social context but cannot unintentionally infer each others private goals. Formally, an episode is defined as = (Ab, Ap, gb, gp, pp, pb, b), (1) where Ab and Ap denote the barrier and partner agents, gb and gp their respective goals, pb and pp their role profiles, and the injected barrier type. Utterance Generation. At each dialogue turn t, let ht denote the history of all utterances prior to t. Each agent Ai generates an utterance ut,i conditioned on ht, its goal gi, and profile pi. For the barrier agent Ab, the instruction is augmented with the barrier specification b: ut,b πθ( ht, gb, pb, b), (2) The partner agent Ap, by contrast, generates from the unmodified instruction: ut,p πθ( ht, gp, pp, I), (3) This unilateral setup reflects natural conversational asymmetry and enables evaluation of the partner agents performance under impaired communication. Episodes are capped at 20 turns or conclude earlier if an agent chooses to exit."
        },
        {
            "title": "2.4 Evaluation Protocol",
            "content": "A barrier-aware social environment must judge both task success and social competence under impaired communication. Therefore, SOCIALVEIL evaluates social interaction along two complementary aspects: The first aspect focuses on goal-oriented dimensions such as goal completion, relationship quality, and knowledge, which are widely measured in previous social interaction research (Zhou et al., 2023). The second aspect introduces barrieraware dimensions, which directly target the communicative disruptions induced by barriers. Specifically, we introduce 1) Unresolved Confusion to quantify the extent to which ambiguity remains at the end of the dialogue (five-point Likert scale, from incoherent to fully resolved), and 2) Mutual Understanding to capture the degree of convergence on shared context and goals (five-point Likert scale, from complete misalignment to full alignment). The details of the evaluation protocol implementation are shown in Appendix G. 4 Preprint. Under review. Figure 2: Overview of SOCIALVEIL. The pipeline consists of three stages: (Barrier Injection) scenarios are neutralized to remove bias and barriers are systematically injected; (Interaction Simulation) agents engage in multi-turn dialogue under barrier conditions; (Evaluation) agent performance is assessed using automatic metrics (goal achievement, knowledge seeking, believability, relationship quality, confusion, mutual understanding) and human evaluation (alignment analysis and barrier navigation success)."
        },
        {
            "title": "3 Research Questions and Experiment Setup",
            "content": "Our goal is to develop systematic framework for simulating communication barriers and to leverage it as diagnostic tool to investigate the social resilience of language agents. Therefore, we frame our study in three guiding questions: 1) Barrier Validity. Do injected barriers reliably create structured disruptions? 2) Barrier Effects. How do barriers affect the performance of LLM agents in social interaction? 3) Barrier Adaptation. Can agents be improved to handle communication barriers? To answer these questions, we build testbed of 180 episodes for each barrier type (Semantic Vagueness, Sociocultural Mismatch, and Emotional Interference), along with baseline condition without barriers, following the procedure described in 2. All episodes are from SOTOPIA scenarios (Zhou et al., 2023). We follow its difficulty tags and report two splits: All (standard + hard) and Hard (hard-only). We employ GPT-4o-mini as the base model for the barrier agent. To investigate barrier effects, we evaluate four partner agents spanning both proprietary and open-weight model families: GPT-4o-mini (Hurst et al., 2024), Qwen2.5-7B-Instruct, Qwen3-4B-Instruct (Yang et al., 2025), and Mistral-8B-Instruct (AI, 2024). The temperature is set to 0.7 to encourage response diversity. Performance is measured using the evaluation protocol described in 2.4, where we use GPT-4o as the backbone of the evaluator model, with its temperature set to 0 for stable, deterministic judgments. We further validate our barrier and evaluation consistency across alternative backbones in Appendix F. To investigate whether agents can be made more resilient to communication barriers, we implement two adaptation strategies: 1) Repair Instruction. We first examine direct, instruction-based intervention. This approach enhances the partner agents meta-prompt with explicit guidance designed to reduce misunderstandings (e.g., Actively ask clarifying questions and paraphrase to confirm understanding.) 2) Interactive Learning. We adapt an interactive learning framework (e.g., Wang et al., 2024b). The process begins with behavior cloning (BC), where expert trajectories are generated from interactions using GPT-4o as partner agents and filtered for success using our evaluation protocol. The partner agent is initialized by imitating these trajectories through training: )D [log πθ(u L(θ) = ht)] , (ht,u (4) where is the set of high-quality demonstrations and is the expert utterance given history ht. Then, we apply self-reinforcement (SR), the trained agent engages with the fixed barrier agent to produce new dialogues, from which high-quality trajectories are again 5 Preprint. Under review. Sotopia-All Sotopia-Hard Type BEL REL KNO GOAL Conf Mutu BEL REL KNO GOAL Conf Mutu Model GPT-4o-m Base 8.78.11 3.41.21 3.94.18 7.60.22 4.08.15 4.56.10 8.82.12 2.53.15 2.78.11 6.75.21 3.75.14 4.46.11 Sem 7.58.15 1.91.14 2.89.20 5.61.25 1.48.12 1.76.14 7.32.11 1.61.13 2.71.14 5.46.20 1.57.12 1.78.11 7.70.12 1.95.18 2.92.15 5.35.28 1.78.11 2.41.13 7.61.10 1.64.15 2.96.16 5.32.24 1.75.11 2.28.10 Soc Emo 7.76.10 1.61.11 2.97.14 5.25.20 1.51.10 2.03.11 7.42.12 1.03.10 2.93.15 4.96.21 1.46.10 1.89.12 Qwen2.5-7b Base 8.48.12 3.17.21 3.79.25 7.48.26 4.06.14 4.45.12 8.33.14 1.72.12 2.73.11 5.68.20 3.16.12 3.89.11 Sem 7.37.13 1.91.14 2.63.19 5.99.23 1.61.11 1.91.15 6.96.15 1.46.11 2.25.10 5.25.18 1.21.10 1.39.12 7.65.13 2.04.22 2.79.17 5.71.29 1.85.13 2.45.17 7.28.12 1.64.14 2.61.13 5.17.21 1.57.11 1.93.13 Soc Emo 7.56.08 1.57.14 2.64.16 5.47.19 1.63.08 2.16.13 7.28.10 0.89.11 2.28.12 4.75.19 1.39.10 1.78.11 Qwen3-4b Base 8.64.13 3.12.22 3.88.24 7.73.24 3.72.16 4.30.11 8.40.12 1.96.11 2.93.15 6.57.20 3.14.11 4.03.10 Sem 7.80.09 2.03.16 2.85.19 6.81.27 1.97.13 2.42.16 7.61.11 1.32.13 2.28.11 6.04.22 1.68.10 1.86.12 7.89.10 2.04.15 3.10.18 6.45.24 2.26.14 3.02.16 7.64.10 1.28.12 3.03.14 5.96.21 2.03.11 2.64.11 Soc Emo 7.94.08 1.72.14 3.06.14 6.48.28 1.94.07 2.64.11 7.75.08 1.21.11 2.75.11 5.78.23 1.67.09 2.32.10 Mistral-8b Base 7.73.15 2.84.20 3.74.22 6.83.21 3.23.18 3.54.14 7.73.16 2.42.14 3.39.18 6.22.21 2.61.15 3.25.14 Sem 7.01.16 1.56.11 2.41.15 3.91.24 1.07.10 1.13.12 6.81.15 1.32.11 2.25.13 3.50.19 1.01.08 1.00.10 7.81.14 2.28.19 3.02.17 5.31.25 1.52.12 1.85.14 6.45.12 2.07.16 3.07.15 5.07.22 1.21.11 1.43.11 Soc Emo 7.47.12 1.39.10 2.69.14 4.48.21 1.26.10 1.42.11 6.48.09 1.28.11 2.79.11 4.03.14 1.11.09 1.18.10 Table 2: Barriers consistently degrade agent performance compared to the baseline across all models. We observe: 1) Semantic vagueness most severely impairs mutual understanding, 2) Emotional interference disproportionately harms relationships, and 3) Sociocultural mismatch induces persistent confusion. For information on the metrics, see Appendix G. filtered and added to training. This iterative process allows the agent to progressively distill strategies for navigating barriers."
        },
        {
            "title": "4.1 Are the Created Barrier Valid?",
            "content": "In sociolinguistics, barriers are viewed as structured phenomena that systematically distort interactional signals (Clark & Brennan, 1991; Tannen, 2005). Thus, valid simulated barrier should induce structured distribution shifts in communication representations. We tested this by probing the hidden states of Qwen2.5-7B-Instruct in the baseline and three barrier conditions. As shown in Figure 3, barrier conditions form distinct and compact clusters in the t-SNE space, with clear separation from baseline points. This indicates that barriers are encoded in the models internal representations as structured modes of variation, rather than as random noise. Moreover, the three different barrier types also form clearly separated clusters with no overlap, further validating the design rationality of the simulated barriers. This mutual separation suggests that each barrier introduces unique, consistent shift in communicative representation, reflecting distinct interactional distortions."
        },
        {
            "title": "4.2 How do Barriers Affect Social Interaction?",
            "content": "Table 2 summarizes each models performance across both baseline and barrier conditions. From these comprehensive results, we identify the following three key findings: 1) Barriers consistently impair social interaction performance. Across all evaluated models and multiple evaluation dimensions, the presence of barriers leads to significant and consistent performance degradation compared to the baseline. This detrimental effect holds across metrics from both goal-oriented dimensions and barrier-aware dimensions. 2) Barrier types exhibit distinct patterns. Each barrier produces characteristic pattern of degradation. Semantic vagueness most severely disrupts mutual understanding (avg 58%), often preventing agents from converging on shared context. Emotional interference disproportionately damages the quality of the relationship (avg 49%), while sociocultural mismatch induces persistent confusion (avg 49%) with relatively mild relational effects. 3) Social reasoning is more fragile than goal pursuit. Compared to goal completion and knowledge acquisition, which decline moderately under barriers (20 30%), social 6 Preprint. Under review. Model Barrier GOAL Mutu Conf Base Rep BC+SR Base Rep BC+SR Base Rep BC+SR Q2.5-7B Q3-4B Semantic 5.99 6.07 Sociocult. 5.71 5.87 Emotional 5.47 5.74 Semantic 6.81 7.08 Sociocult. 6.45 6.85 Emotional 6.48 6.55 6.02 5.79 5.86 7.13 6.84 6.52 1.91 1.90 2.45 2.50 2.16 2. 1.97 1.98 2.26 2.43 1.94 1.92 2.15 2.60 2.34 2.10 2.49 2.09 1.61 1.66 1.85 1.88 1.63 1.69 2.42 2.48 3.02 3.08 2.64 2.39 1.84 2.16 1. 2.49 3.21 2.46 Table 3. Effectiveness of Mitigation Strategies. While instruction-level repair yields negligible improvements, interactive learning (BC+SR) offers consistent but modest gains. However, neither strategy fully restores agents to baseline proficiency. dimensions suffer substantially greater degradation, with relationship quality dropping by an average of 45% and mutual understanding declining by 52% across all barrier types, which infers barriers primarily disrupt the subtle social reasoning required."
        },
        {
            "title": "4.3 Can Agents Adapt to Communication Barriers?",
            "content": "Table 3 reports the comparison of agent social interaction performance under communication barriers between the default setting and the two adaptation strategies. We can draw three key findings: 1) Repair Instruction yields trivial performance improvements. This result highlights two points. First, overcoming communication barriers is not trivial skill that can be invoked by an instruction-level guidance; it requires agents to detect when breakdowns occur, attribute them to specific distortion, and deploy targeted repair strategies. Second, the failure of this strategy reflects the limitation of static, barrier-agnostic prompting: agents often resort to shallow repetitions or generic clarifications that do not resolve the underlying disruption. Figure 3: t-SNE visualization of the final-layer representations from Qwen2.5-7B-Instruct. 2) Interactive Learning (BC+SR) yields consistent but limited improvements. In contrast, interactive learning produces steady gains across all barrier types and relieves agents struggle with social interaction in barrier cases. Yet the improvements remain modest (avg 10-20%), such that the enhancement over Repair Instruction is incremental rather than dramatic, and performance still falls significantly short of the barrier-free baseline. 3) Both strategies show minimal impact on goal completion. Notably, neither approach improves the GOAL scores relative to the baseline, suggesting that adaptation strategies may guide agents to focus primarily on mitigating barriers rather than social objectives. This indicates potential trade-off where barrier-handling mechanisms divert cognitive resources away from goal-oriented behavior, highlighting the challenge of simultaneously maintaining task performance while addressing communication disruptions."
        },
        {
            "title": "5.1 Analysis: Behavioral Alignment of Simulated Barriers",
            "content": "To further analyze the effects of injected barriers, we move beyond quantitative metrics to conduct behavioral analysis of the conversation trajectory.Inspired by previous work on evaluating the alignment of simulated behaviors (Park et al., 2023; Han et al., 2025; Zou et al., 2024), we design series of in-depth qualitative analyses to study the alignment between our simulated barriers and their real-world counterparts. 7 Preprint. Under review. Linguistic signatures. We first test whether barriers trigger systematic linguistic shifts consistent with real-world communication breakdowns. Empirically, we extracted four linguistic features from conversations: reference pronouns (e.g., it, that) (Ariel, 1990), hedging words (e.g., maybe, could) (Lakoff, 1973), sentiment polarity, and self-focus pronouns (e.g., I, my) (Pennebaker, 2011) and correlated them with evaluation protocol. Figure 4 reveals two patterns: 1) Reference pronouns and self-focus are negatively associated with conversational quality, where they show correlation with higher confusion and lower mutual understanding; and 2) Sentiment polarity serves as positive predictor of smooth interaction, where more positive tone aligns with better relationships and greater goal attainment. Barrier-specific effects. We quantify each barriers unique effect as its deviation from the mean of the other two barriers on the same metric, model, and scenario, with bootstrap 95% confidence intervals (Figure 5). The reFigure 4: Linguistic signal and metrics correlations sults further support that the effect of across four models. *p < .05, **p < .01, ***p < .001. our simulated barriers aligns with their real-world counterparts: For example, semantic barriers most strongly impair Mutual Understanding, while emotional barriers disproportionately erode Relationship Quality, and Cultural barriers uniquely elevate Unresolved Confusion. These effects are consistent across models and statistically significant in the expected directions, demonstrating that the simulated barriers not only alter surface linguistic features but also reproduce distinct interactional disruptions characteristic of their real-world analogs."
        },
        {
            "title": "5.2 Analysis: Human Evaluation",
            "content": "To complement our automated metrics, we conduct human evaluation to validate the models ratings. Detailed procedures for human evaluation are provided in Appendix E. We focus on three key aspects: 1) Inter-rater Reliability. Assessing the consistency and reliability of human annotators; 2) Barrier Identification Accuracy. Evaluating whether human annotators can correctly identify the injected barriers; and 3) Metric Alignment. Examining how well the model-rated results correspond with human judgments. Inter-rater reliability. We calculated Fleisss Kappa for human annotation of barrier types, yielding score of 0.38. Based on the classic interpretive framework of Landis & Koch (1977), this reflects fair agreement, bordering on moderate. Such values are common in complex, subjective multi-class annotation tasks. Prior studies report similar κ ranges: Castro et al. (2019) reported values ranging from 0.23 to 0.59 for sarcasm detection, and Callejas & López-Cózar (2008) reported 0.320.42 for non-acted emotion identification. Thus, our result aligns well with similar findings in the existing literature, further supporting the overall reliability and consistency of our manual annotation process. Figure 5: Signatures of simulated communication barriers. Data are shown as percentage deviations relative to other types *p < .05. For rating metrics, each scenario was rated by three of six annotators. We used oneway random effects model with single-measure ICC(1,k) to assess inter-rater reliability. 8 Preprint. Under review. Unresolved Confusion showed ICC = 0.77, 95% CI [0.68, 0.83], F(119, 240) = 4.26. Mutual Understanding showed ICC = 0.79, 95% CI [0.72, 0.85], F(119, 240) = 4.80. Per Cicchetti (1994), these values fall in the good range, suggesting reliable inter-rater consistency (p < .001). Barrier identification accuracy. We further reported the accuracy of human annotators in identifying barriers. Given that the sample contained only 120 scenarios, we employed cluster bootstrap resampling with replacement at the scenario level, repeated 1000 times, to evaluate the stability of the estimates and to construct 95% percentile-based confidence intervals (95% CI). From Figure 6, the results showed that the overall accuracy of human annotators in barrier identification was 0.68 (95% CI [0.63, 0.73]); with accuracy 0.76 (95% CI [0.67, 0.86]) for baseline barriers, 0.65 (95% CI [0.54, 0.76]) for semantic barriers, 0.63 (95% CI [0.53, 0.73]) for cultural barriers, and 0.67 (95% CI [0.54, 0.78]) for emotional barriers. These results demonstrate that, across all barrier types, annotator accuracy was significantly above the level expected from random guessing, as all lower confidence interval bounds exceeded the binary chance baseline of 0.50. Barrier Human Evaluation Automated Evaluation CONFUSION MUTUAL CONFUSION MUTUAL Mean 95% CI Mean 95% CI Mean 95% CI Mean 95% CI Baseline Semantic Sociocultural Emotional 3.74 1.45 1.94 1.70 [3.48, 4.00] [1.30, 1.62] [1.67, 2.23] [1.53, 1.86] 3.84 1.71 2.25 1. [3.62, 4.07] [1.56, 1.87] [2.01, 2.51] [1.80, 2.11] 3.94 1.54 1.67 1.67 [3.65, 4.24] [1.32, 1.79] [1.50, 1.82] [1.50, 1.84] 4.47 1.81 2.24 2.20 [4.27, 4.67] [1.52, 2.13] [1.96, 2.50] [1.92, 2.50] Table 4: Mean ratings by barrier type with 95% confidence intervals. Our results show strong alignment between human annotators and automated evaluation in rating Mutual Understanding and Unresolved Confusion. Pearson correlation: Confusion r=0.80 (95% CI [0.72, 0.86]), Mutual r=0.79 (95% CI [0.71, 0.85]). n=120. Metric alignment. We further compared the mean values and 95% confidence intervals of Unresolved Confusion and Mutual Understanding between human annotators and the model under different barrier conditions. As shown in Table 4, the models performance was close to the average human ratings, with only small differences in the confidence intervals, indicating high degree of consistency. In addition, the analysis of overall convergent validity revealed statistically strong correlations between human and model scores, with Unresolved Confusion yielding convergent validity of 0.80 (95% CI [0.72, 0.86]) and Mutual Understanding yielding convergent validity of 0.79 (95% CI [0.71, 0.85]). These results offer further support for the models reliability in evaluating the barrier-sensitive dimensions."
        },
        {
            "title": "6 Related Works",
            "content": "The dynamics of interactions among AI agents, as well as between AI and humans, have been examined across disciplines. Our work builds upon existing research in social intelligence, its interactive assessment, agent-based social simulations, and the study of interaction and communication within the social sciences. For more detailed discussion, see Appendix A. Static Benchmarks for Social Intelligence and Their Limitations. To assess the social intelligence of AI systems, researchers have proposed wide range of static benchmarks. These draw inspiration both from clinical and psychological tests as well as from social commonsense reasoning tasks. For instance, ToMi is used to evaluate theory of mind in text comprehension (Le et al., 2019); FauxPas (social faux pas detection) examines models ability to capture others intentions and beliefs (Shapira et al., 2023b); SocialIQA focuses on eventintentionreaction commonsense question answering (Sap et al., 2019a); and SocialIQ evaluates whether models can read people through multimodal video tasks (Zadeh et al., 2019). However, as model performance continues to improve, many of these datasets have reached near-saturation on certain subtasks, prompting the community to design more adversarial and challenging benchmarks (e.g., Shapira et al., 2023a). Still, existing research consistently highlights fundamental limitation: static test items alone cannot capture the 9 Preprint. Under review. complexity and diversity of interactive settings. Consequently, there remains significant gap in evaluating intelligence within real-world social interactions. Interactive Evaluation of Social Intelligence and Agents Simulation. LLMs encode rich knowledge and generate human-like responses in social contexts (e.g., Park et al., 2023; West et al., 2021). Researchers have used them to simulate social interactions, from optimizing social media design (Park et al., 2022) to building agents with credible human behavior (Park et al., 2023) and supporting collaborative software development (Qian et al., 2023). However, most studies emphasize their potential rather than systematically evaluating agent performance in such interactions. To address this, SOTOPIA (Zhou et al., 2023) builds on prior work in social simulation and dialogue systems to propose an open-ended interactive environment. It dynamically evaluates agents across multi-turn social scenarios, measuring their ability to achieve social goals and maintain role consistency, thereby surpassing static benchmarks. Extensions of SOTOPIA further advance interactive evaluation and learning. For example, SOTOPIA-π adds mechanisms for interactive imitation and reinforcement learning, enhancing agents adaptability and strategy (Wang et al., 2024b); LIFELONGSOTOPIA connects events with memory to assess long-term behavioral consistency (Goel & Zhu, 2025); and SOTOPIA-RL incorporates fine-grained reinforcement signals for discourselevel optimization (Yu et al., 2025). Together, these developments position SOTOPIA as benchmark and platform for advancing AI agents social intelligence."
        },
        {
            "title": "7 Conclusion",
            "content": "In this work, we introduce SOCIALVEIL, barrier-aware social interaction environment designed to simulate and evaluate the performance of LLM agents in the presence of communication barriers. Our experiments clearly show that these barriers consistently impair agents social intelligence capabilities. Through human evaluations, we validate both the realism of the simulated barriers and the robustness of the evaluation protocol. We also investigate adaptation strategies, finding that repair instructions are largely ineffective, while interaction-driven learning yields modest but consistent improvements. This work represents crucial step toward more realistic social interaction environments and opens promising new avenues for advancing the social intelligence of LLM agents."
        },
        {
            "title": "Ethics Statement",
            "content": "The development of SOCIALVEIL adheres to strict ethical guidelines for AI research. Our barrier taxonomy and simulation protocols are carefully designed to exclude any hate speech, discriminatory stereotypes, or harmful biases. All human evaluations were conducted with informed consent and fair compensation, ensuring privacy through anonymization. As diagnostic framework, SOCIALVEIL is intended to identify and repair communication failures, thereby fostering the development of socially resilient and aligned agents."
        },
        {
            "title": "References",
            "content": "Gati Aher, Rosa Arriaga, and Adam Tauman Kalai. Using large language models to simulate multiple humans and replicate human subject studies. In International conference on machine learning, pp. 337371. PMLR, 2023. Mistral AI. https://huggingface.co/mistralai/ Ministral-8B-Instruct-2410, 2024. Released under the Mistral Research License; 8B-parameter instruction-tuned model, 128k context window. Ministral-8b-instruct-2410. Mira Ariel. Accessing noun-phrase antecedents. 1990. URL https://api.semanticscholar. org/CorpusID:122469483. Dean C. Barnlund. transactional model of communication. In J. Akin, A. Goldberg, G. Myers, and J. Stewart (eds.), Language Behavior: Book of Readings in Communication. For Elwood Murray on the Occasion of His Retirement, pp. 4361. De Gruyter Mouton, Berlin, Boston, 1970. doi: 10.1515/9783110878752.43. 10 Preprint. Under review. Penelope Brown and Stephen C. Levinson. Politeness: Some Universals in Language Usage. Cambridge University Press, Cambridge, 1987. doi: 10.1017/CBO9780511813085. Zoraida Callejas and Ramón López-Cózar. On the use of kappa coefficients to measure the reliability of the annotation of non-acted emotions. In International Tutorial and Research Workshop on Perception and Interactive Technologies for Speech-Based Systems, pp. 221232. Springer, 2008. Santiago Castro, Devamanyu Hazarika, Verónica Pérez-Rosas, Roger Zimmermann, Rada Mihalcea, and Soujanya Poria. Towards multimodal sarcasm detection (an _Obviously_ perfect paper). In Anna Korhonen, David Traum, and Lluís Màrquez (eds.), Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 46194629, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/ P19-1455. URL https://aclanthology.org/P19-1455/. Mert Cemri, Melissa Pan, Shuyi Yang, Lakshya Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, Kannan Ramchandran, et al. Why do multi-agent llm systems fail? arXiv preprint arXiv:2503.13657, 2025. Hongzhan Chen, Hehong Chen, Ming Yan, Wenshen Xu, Xing Gao, Weizhou Shen, Xiaojun Quan, Chenliang Li, Ji Zhang, Fei Huang, et al. Socialbench: Sociality evaluation of role-playing conversational agents. arXiv preprint arXiv:2403.13679, 2024. EC Cherry. Some experiments on the recognition of speech, with one and two ears: Journal of the acoustic society of america. International journal of intercultural relations, 1953. Domenic Cicchetti. Guidelines, criteria, and rules of thumb for evaluating normed and standardized assessment instruments in psychology. Psychological assessment, 6(4):284, 1994. doi: 10.1037/1040-3590.6.4.284. Herbert Clark and Susan Brennan. Grounding in communication. 1991. doi: 10.1037/ 10096-006. Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms. Advances in neural information processing systems, 36:10088 10115, 2023. Michael Eysenck and Manuel Calvo. Anxiety and performance: The processing efficiency theory. Cognition & emotion, 6(6):409434, 1992. Michael Eysenck, Nazanin Derakshan, Rita Santos, and Manuel Calvo. Anxiety and cognitive performance: attentional control theory. Emotion, 7(2):336, 2007. Oriel FeldmanHall and Amitai Shenhav. Resolving uncertainty in social world. Nature human behaviour, 3(5):426435, 2019. Leon Festiger. theory of cognitive dissonance. Row, Peterson, New York, 1957. doi: 10.1515/9781503620766. Leon Festinger and James Carlsmith. Cognitive consequences of forced compliance. The journal of abnormal and social psychology, 58(2):203, 1959. doi: 10.1037/h0041593. Joseph Forgas. Mood and judgment: the affect infusion model (aim). Psychological bulletin, 117(1):39, 1995. doi: 10.1037/0033-2909.117.1.39. Lyn Frazier and Keith Rayner. Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences. Cognitive psychology, 14(2):178210, 1982. Howard Giles, Nikolas Coupland, and Justine Coupland. Accommodation theory: Communication, context, and consequence. Contexts of accommodation: Developments in applied sociolinguistics, 1:168, 1991. Preprint. Under review. Thomas Gilovich, Dale W. Griffin, and Daniel Kahneman. Heuristics and biases: The psychology of intuitive judgment. 2002. URL https://api.semanticscholar.org/CorpusID: 197652997. Hitesh Goel and Hao Zhu. Lifelong sotopia: Evaluating social intelligence of language agents over lifelong social interactions. arXiv preprint arXiv:2506.12666, 2025. Herbert Grice. Logic and conversation. In Speech acts, pp. 4158. Brill, 1975. doi: 10.1163/ 9789004368811_003. James Gross. Antecedent-and response-focused emotion regulation: divergent consequences for experience, expression, and physiology. Journal of personality and social psychology, 74(1):224, 1998a. doi: 10.1037//0022-3514.74.1.224. James Gross. The emerging field of emotion regulation: An integrative review. Review of general psychology, 2(3):271299, 1998b. Edward Hall. The silent language. Anchor, 1973. Edward Hall. Beyond culture. Anchor, 1976. Pengrui Han, Rafal Kocielnik, Adhithya Saravanan, Roy Jiang, Or Sharir, and Animashree Anandkumar. Chatgpt based data augmentation for improved parameter-efficient debiasing of llms. In Proceedings of the Fourth Workshop on Language Technology for Equality, Diversity, Inclusion, pp. 73105, 2024a. Pengrui Han, Peiyang Song, Haofei Yu, and Jiaxuan You. In-context learning may not elicit trustworthy reasoning: A-not-b errors in pretrained language models. arXiv preprint arXiv:2409.15454, 2024b. Pengrui Han, Rafal Kocielnik, Peiyang Song, Ramit Debnath, Dean Mobbs, Anima Anandkumar, and Michael Alvarez. The personality illusion: Revealing dissociation between self-reports & behavior in llms. arXiv preprint arXiv:2509.03730, 2025. Geert Hofstede. Cultures consequences: Comparing values, behaviors, institutions and organizations across nations. 2001. URL https://api.semanticscholar.org/CorpusID: 145428141. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024. Han Jiang, Pengda Wang, Xiaoyuan Yi, Xing Xie, and Ziang Xiao. The incomplete bridge: How ai research (mis) engages with psychology. arXiv preprint arXiv:2507.22847, 2025. George Lakoff. Hedges: study in meaning criteria and the logic of fuzzy concepts. Journal of philosophical logic, 2(4):458508, 1973. Richard Landis and Gary Koch. The measurement of observer agreement for categorical data. biometrics, pp. 159174, 1977. Matthew Le, Y-Lan Boureau, and Maximilian Nickel. Revisiting the evaluation of theory of mind through question answering. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (eds.), Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 58725877, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1598. URL https://aclanthology. org/D19-1598/. Jennifer Lerner and Dacher Keltner. Beyond valence: Toward model of emotion-specific influences on judgement and choice. Cognition & emotion, 14(4):473493, 2000. Fred C. Lunenburg. Communication: The process, barriers, and improving effectiveness. Schooling, 1, 2010. 12 Preprint. Under review. Xinyi Mou, Jingcong Liang, Jiayu Lin, Xinnong Zhang, Xiawei Liu, Shiyue Yang, Rong Ye, Lei Chen, Haoyu Kuang, Xuanjing Huang, and Zhongyu Wei. Agentsense: Benchmarking social intelligence of language agents through interactive scenarios. arXiv preprint arXiv:2410.19346, 2024. Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael Bernstein. Social simulacra: Creating populated prototypes for social computing systems. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology, pp. 118, 2022. Joon Sung Park, Joseph OBrien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pp. 122, 2023. James Pennebaker. The secret life of pronouns. New Scientist, 211(2828):4245, 2011. Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. Communicative agents for software development. arXiv preprint arXiv:2307.07924, 6(3):1, 2023. Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. Social IQa: Commonsense reasoning about social interactions. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (eds.), Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 44634473, Hong Kong, China, November 2019a. Association for Computational Linguistics. doi: 10.18653/v1/D19-1454. URL https://aclanthology. org/D19-1454/. Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Commonsense reasoning about social interactions. arXiv preprint arXiv:1904.09728, 2019b. Edward Sapir. The status of linguistics as science. language, pp. 207214, 1929. Emanuel Schegloff, Gail Jefferson, and Harvey Sacks. The preference for self-correction in the organization of repair in conversation. Language, 53(2):361382, 1977. Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, and Vered Shwartz. Clever hans or neural theory of mind? stress testing social reasoning in large language models. arXiv preprint arXiv:2305.14763, 2023a. Natalie Shapira, Guy Zwirn, and Yoav Goldberg. How well do large language models perform on faux pas tests? In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Findings of the Association for Computational Linguistics: ACL 2023, pp. 1043810451, Toronto, Canada, July 2023b. Association for Computational Linguistics. doi: 10.18653/ v1/2023.findings-acl.663. URL https://aclanthology.org/2023.findings-acl.663/. Peiyang Song, Pengrui Han, and Noah Goodman. survey on large language model reasoning failures. In 2nd AI for Math Workshop@ ICML 2025, 2025. Dan Sperber and Deirdre Wilson. Relevance: Communication and cognition, volume 142. Harvard University Press Cambridge, MA, 1986. doi: 10.2307/3731158. David Swinney. Lexical access during sentence comprehension:(re) consideration of context effects. Journal of verbal learning and verbal behavior, 18(6):645659, 1979. Deborah Tannen. Conversational style: Analyzing talk among friends. Oxford University Press, 2005. Pengda Wang, Zilin Xiao, Hanjie Chen, and Frederick Oswald. Will the real linda please stand up... to large language models? examining the representativeness heuristic in llms. arXiv preprint arXiv:2404.01461, 2024a. 13 Preprint. Under review. Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Graham Neubig, Yonatan Bisk, and Hao Zhu. Sotopia-π: Interactive learning of socially intelligent language agents. arXiv preprint arXiv:2403.08715, 2024b. Peter West, Chandra Bhagavatula, Jack Hessel, Jena Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, and Yejin Choi. Symbolic knowledge distillation: from general language models to commonsense models. arXiv preprint arXiv:2110.07178, 2021. Benjamin Lee Whorf. Language, thought, and reality: Selected writings of Benjamin Lee Whorf. MIT press, 2012. doi: 10.2307/411163. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen2.5 technical report. arXiv preprint arXiv:2505.09388, 2025. Haofei Yu, Zhengyang Qi, Yining Zhao, Kolby Nottingham, Keyang Xuan, Bodhisattwa Prasad Majumder, Hao Zhu, Paul Pu Liang, and Jiaxuan You. Sotopia-rl: Reward design for social intelligence. arXiv preprint arXiv:2508.03905, 2025. Amir Zadeh, Michael Chan, Paul Pu Liang, Edmund Tong, and Louis-Philippe Morency. Social-iq: question answering benchmark for artificial social intelligence. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 88078817, 2019. Lotfi Zadeh. Fuzzy sets. S0019-9958(65)90241-X. Information and control, 8(3):338353, 1965. doi: 10.1016/ Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, LouisPhilippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, et al. Sotopia: Interactive evaluation for social intelligence in language agents. arXiv preprint arXiv:2310.11667, 2023. Huiqi Zou, Pengda Wang, Zihan Yan, Tianjun Sun, and Ziang Xiao. Can llm\" self-report\"?: Evaluating the validity of self-report scales in measuring personality design in llm-based chatbots. arXiv preprint arXiv:2412.00207, 2024. 14 Preprint. Under review."
        },
        {
            "title": "A Extended Related Works",
            "content": "A.1 From Seamless by Default to Cognitive Bias Induced Barriers Despite recent progress in multi-agent evaluation and social agent simulation, many studies still operate under overly idealized assumptions. Early work often did not even differentiate between agents access to information. Even in frameworks such as SOTOPIA and related research, where agents are designed to have little or no knowledge of one anothers strategies or mental states, the communicative process itself is still frequently treated as seamless by default. In other words, once an utterance is produced, it is assumed to be correctly understood, with cooperative partners always willing to clarify and reach consensus. Such assumptions, however, diverge sharply from messy real-world interactive contexts. In actual humanmachine and machinemachine communication, ambiguity, omission, misunderstanding, and cognitive bias are the norm (Han et al., 2024b;a). Communication is not one-way transmission but dynamic negotiation, shaped by obstacles, repair, and adaptive feedback loops. Traditional dialogue and robotics research have long emphasized miscommunication detection and recovery, addressing challenges such as ambiguous instructions, misinterpretations arising from path or environmental constraints, and strategies for clarification based on situational evidence. This line of work underscores fundamental truth: effective real-world communication does not mean never making errors, but rather possessing the capacity to handle errors once they occur. Importantly, such resilience and repair mechanisms are themselves central manifestations of social intelligence. Recent empirical surveys of multi-agent systems (Cemri et al., 2025) highlight that MAS do not always outperform single-agent systems across all dimensions. Many of these issues are closely tied to communicative misalignment, inconsistent role assumptions, and information loss within and across interaction rounds. These findings call for moving beyond idealized models toward interaction paradigms that explicitly account for communication barriers."
        },
        {
            "title": "B The limitations of SOCIALVEIL and future directions",
            "content": "Although SOCIALVEIL establishes foundational framework for evaluating social intelligence under communication barriers, it opens several promising avenues for future research. First, the current study primarily focuses on text-only interactions. However, real-world communication barriers often arise from non-verbal modalities, such as prosody, facial expressions, and physical gestures, each playing critical role in grounding, coherence, and mutual understanding. We envision SOCIALVEIL evolving into more comprehensive learning environment that incorporates these multimodal challenges. Second, the current SOCIALVEIL scenarios emphasize discrete, short-term interactions. Yet, social intelligence unfolds over time, and the effects of communication barriers are often cumulative and subtle. Future work should extend toward modeling continuous scenario where longterm interactions and evolving barriers are more accurately and holistically represented. Third, while the current evaluation protocol offers multidimensional diagnostic of social intelligence at the episode level, true social competence also involves the ability to mitigate barriers proactively. valuable direction is the development of agents capable of actively restoring the communication channel using meta-cognitive strategies, such as recursive clarification and empathetic grounding. Ultimately, we hope SOCIALVEIL will serve as training platform for developing socially robust LLMs, systems that treat communication breakdowns not as failures, but as opportunities to deepen alignment and understanding."
        },
        {
            "title": "C Barrier Taxonomy Development",
            "content": "We adopted the method of systematic literature review to examine research in the social sciences (e.g., Jiang et al., 2025). Specifically, we focused on interaction/communication barriers caused by cognitive differences. As LLMs have shown the ability to simulate similar cognitive bias (e.g., Wang et al., 2024a). Based on existing psychological and sociological theories related to interaction and communication, we conducted literature search and categorized the findings. Ultimately, we identified three main types of communication 15 Preprint. Under review. barriers induced by cognitive differences: Semantic Vagueness, Sociocultural Mismatch, and Emotional Interference. C.1 Semantic Vagueness Grices theory of conversational implicature and the cooperative principle (Grice, 1975) clearly shows that communication fundamentally relies on shared maxims; when speakers intentionally or unintentionally violate the maxim of manner, interpretive ambiguity easily arises. Swinneys cross-modal lexical priming experiments (Swinney, 1979) compellingly demonstrated that multiple meanings of an ambiguous word are briefly activated in parallel, and without sufficient contextual cues, semantic comprehension quickly becomes confused. Frazier and Rayner (Frazier & Rayner, 1982) found that syntactic ambiguity can often trigger the garden-path effect, requiring substantial and effortful reanalysis by the listener. Zadehs fuzzy set theory (Zadeh, 1965) and Lakoffs work on hedges (Lakoff, 1973) further illustrate how vague linguistic expressions can significantly expand or constrain conceptual boundaries, leading to diverse and sometimes divergent interpretations. C.2 Sociocultural Mismatch The SapirWhorf hypothesis of linguistic relativity (e.g., Sapir, 1929; Whorf, 2012) emphasizes how habitual language use subtly shapes thought patterns, perception, and attentional focus. Halls influential framework of highversus low-context cultures (e.g., Hall, 1973) reveals cross-cultural variation in reliance on explicit verbal information versus shared, implicit contextual cues. Hofstedes cultural dimensions theory (e.g., Hofstede, 2001) highlights how variables such as power distance and individualismcollectivism influence communication styles, interpretive preferences, and behavioral expectations. Brown and Levinsons politeness theory (Brown & Levinson, 1987) and Giles communication accommodation theory (e.g., Giles et al., 1991) demonstrate how differing choices in politeness strategies and speech convergence or divergence across cultures can lead to misattributions of intent, communicative mismatches, and interpersonal friction. C.3 Emotional Interference Festingers cognitive dissonance theory (e.g., Festiger, 1957; Festinger & Carlsmith, 1959) demonstrates how individuals engage in defensive cognitive processing when confronted with conflicting beliefs, attitudes, or information. Grosss influential emotion regulation model (e.g., Gross, 1998a;b) shows that suppression strategies impair processing efficiency and can lead to heightened cognitive load. Lerner and Keltners appraisal tendency framework (e.g., Lerner & Keltner, 2000) emphasizes the carry-over effect of emotions, whereby specific emotional states influence subsequent judgments, evaluations, and decisions beyond their original eliciting context. Eysencks attentional control theory (e.g., Eysenck & Calvo, 1992; Eysenck et al., 2007) argues that anxiety weakens executive control functions, making individuals more susceptible to distraction by emotionally salient or threatening cues during communication. Slovics affect heuristic (Gilovich et al., 2002) and Forgass affect infusion model (Forgas, 1995) demonstrate how emotional states can directly shape both the interpretation of information and the strategies used in decision-making processes."
        },
        {
            "title": "D Experimental Details",
            "content": "D.1 Acronym for experimental settings We summarize the acronyms used in our experimental settings as follows: BC: Behavior Cloning of the language model on dialogue demonstrations. SR: Self-Reinforcement, an offline reinforcement learning method that rates and evaluates its own interactions for training. Preprint. Under review. D.2 Model Information We provide the detailed version number of all the models we used in our experiments. When we mention each name like GPT-4, we actually refer to those model versions below. Such information helps researchers reproduce our results: Mistral-8B: mistralai/Mistral-8B-Instruct Qwen2.5-7B: Qwen/Qwen2.5-7B-Instruct Qwen3-4B: Qwen/Qwen3-4B-Instruct-2507 D.3 Training Details The training on each checkpoint was on 4 A6000 80G GPUs, across 20 epochs. The batch size was 4 and we set the cut-off length to be 4096. The initial learning rate for both behavior cloning and self-reinforcement training was 5.0e-5. The QLoRA Dettmers et al. (2023) rank, alpha, and dropout rate were 8, 16, and 0.05, respectively."
        },
        {
            "title": "E Details of Human Evaluation",
            "content": "This section provides technical details of our human evaluation process. Six human annotators were recruited from two universities and received research credit, identified as 50% women and 50% men. E.1 Human annotation system In the annotation process, every annotator faces two independent parts: the annotation instruction part and the data annotation part. We use interaction records generated by Qwen2.5-7B-Instruct across 120 scenarios (for each barrier type and the non-barrier baseline, we have 30 samples) as the sample set for human annotators to label. Each scenario has been rated by at least three different annotators. Annotation instruction part: Annotators are shown brief instruction page explaining the task: 1) read the scenario, agent profiles, and dialogue; 2) classify the dialogue as semantic, cultural, emotional, or none; 3) rate unresolved confusion (15, higher = no confusion); and 4) rate mutual understanding (15, higher = stronger alignment). They are instructed to rely only on the dialogue content and apply the same criteria consistently. Data annotation part: For the data annotation, the annotators use web interface, as shown in Figure 7, to complete their tasks. Within this interface, they can review the definition and examples of each barrier type, examine the full transcript, and input their annotation decisions directly into the system. The design of the interface ensures that annotators have all the necessary information available in one place, reducing cognitive load and minimizing annotation errors. By providing both reference materials and the annotation workspace side by side, the platform promotes consistency, efficiency, and higher-quality annotations. Figure 6: Barrier type identification accuracy for human evaluation with 95% confidence intervals. 17 Preprint. Under review. Figure 7: Conversation Annotation Tool UI."
        },
        {
            "title": "F Additional Evaluation",
            "content": "F.1 Robustness Across Different Evaluator Backbone Models To ensure our evaluation results are not biased by the specific model used for assessment, we conduct sensitivity analysis by employing an alternative backbone for the automatic evaluator. 18 Preprint. Under review. Specifically, we substitute the default GPT-4o with Llama-3.1-8B-Instruct to verify the consistency of the observed performance degradation. As shown in Table 5, while Llama-3.1-8B exhibits more conservative scoring profile, the declines in social intelligence metrics persist across all barrier types. This qualitative consensus between frontier proprietary model and an open-weights model demonstrates that the evaluative power of SOCIALVEIL is backbone-agnostic. This consistency validates that our metrics capture intrinsic communicative friction rather than artifacts of specific models judgment style, further confirming the robustness of our diagnostic framework. Setting GOAL REL Mutu GPT-4o Llama-3.1 GPT-4o Llama-3.1 GPT-4o Llama-3.1 Baseline Semantic Sociocultural Emotional 7.73 6.81 6.45 6.48 8.54 7.73 7.59 7.35 3.12 2.85 3.10 3.06 3.76 3.56 3.74 2.78 4.03 1.86 2.64 2.32 4.53 4.01 4.46 3.54 Table 5: Robustness of the Evaluation Protocol. Comparison of social intelligence scores across different evaluator backbones. While absolute scoring scales vary, both GPT-4o and Llama-3.1 exhibit consistent relative performance degradation across all barrier types. F.2 Robustness Across Different Barrier Backbone Models To ensure that our evaluation results are not biased by the specific model used to simulate communication barriers, we conduct sensitivity analysis by employing alternative backbone models for the barrier agent. Specifically, we substitute the default backbone with Qwen2.5-7B-Instruct to verify if the observed performance degradation remains consistent. And we also employ Qwen2.5-7B-Instruct as the backbone for the partner agent. As shown in Table 6, the significant declines in social intelligence metrics persist even under this homogeneous model configuration. This consistency demonstrates that the challenges posed by SOCIALVEIL are inherent to the barrier types themselves rather than artifacts of specific models generation style, further validating the robustness of our framework. Barrier Base Semantic Sociocultural Emotional GOAL KNO BEL REL Mutu Conf 7.67 5.75 5.93 4.47 3. 2.55 3.02 2.38 8.15 3.05 7.07 7.57 6.77 1.88 2.83 0.75 4. 2.47 2.63 1.87 3.77 2.18 2.30 1.60 Table 6. Result of Barriers using Qwen2.5-7B as Backbone for Both Agents. The results confirm that social intelligence degrades consistently across all dimensions, even when different model family is used for barrier agent F.3 Generalization of SOCIALVEIL To evaluate the generalizability of the social intelligence captured by SOCIALVEIL, we conduct cross-benchmark transfer study on AgentSense (Mou et al., 2024), an independent interaction benchmark.We apply interactive learning within the SOCIALVEIL framework and evaluate the models on AgentSense in strict zero-shot setting. As shown in Table 7, Qwen2.5-7B and Qwen3-4B exhibit significant improvements in goal completion. This successful transfer demonstrates that SOCIALVEIL fosters general social skills rather than task-specific memorization, confirming the broader utility of our framework. 19 Preprint. Under review. Model Untrained Trained Qwen2.5-7B Qwen3-4B 77.17 82.98 80.31 84.92 Table 7. Zero-shot Transfer Performance on AgentSense."
        },
        {
            "title": "G Details For Evaluation Protocol",
            "content": "In section 2.4, we introduced two complementary layers of evaluation: goal-oriented dimensions and barrier-aware dimensions. Here, we provide the full details of their rubrics. Goal-oriented Dimensions. 1. Goal Completion: [0-10] Reiterate the agent's social goals. Provide comprehensive analysis about the extent to which the agent has managed to achieve these goals. Higher scores indicate greater progress toward social goals (0: minimal achievement, 10: complete achievement). 2. Believability: [0-10] Evaluate if the agent interacts with others in natural and realistic manner. Consider: a. whether the agent is confusing with its own identity b. whether the agent repeats others' words/actions without any reason c. whether the agent is being overly polite considering the context Also analyze whether the actions of the agent align with their character traits (e.g., personality, values, etc.). Higher scores indicate more believable behavior. 3. Relationship: [-5-5] Analyze what relationship the agent has with the other agent(s) before the interaction, and how it changes after. Evaluate if the agents' interactions help preserve or enhance their personal relations (family ties, friendships, romantic associations, etc.). Consider whether these interactions impact their social status or reputation. Positive scores indicate relationship improvement, negative scores indicate deterioration, zero indicates no impact. 4. Knowledge: [0-10] Assess what information the agent has gained through the interaction. Analyze whether the information gained is new to them. Analyze whether the information gained is important to them. Higher scores indicate more new and important knowledge gained. Barrier-aware Dimensions. We introduce two additional metrics to capture communicative disruptions caused by barriers: 1. Unresolved Confusion: [0-5] At the end of the conversation, was there still unresolved confusion or uncertainty regarding the scenario and the agents' goals? 20 Preprint. Under review. 1 = Very High - The conversation is incoherent. Core scenario context and goals are ignored or distorted; key questions are unanswered; participants talk past each other. 2 = High - Major misunderstandings about scenario or goals persist. Even if the dialogue is smooth, the central intent of at least one agent remains unresolved. 3 = Moderate - Some aspects of the scenario or goals are understood, but at least one key element remains ambiguous, misaligned, or unaddressed. 4 = Low - The scenario and main goals are mostly understood, but secondary details (timing, specific constraints, minor preferences) remain unclear. 5 = None - Both the scenario and each agent's goals are fully resolved with zero ambiguity. 2. Mutual Understanding: [0-5] After the conversation ended, is it clear that both participants understand each others viewpoints, intentions, and goals *with respect to the given scenario*? 1 = Very Low Participants are talking past each other or off-topic. They do not recognize or engage with the scenario goals. No shared understanding is achieved. 2 = Low One or both systematically misunderstand the other's goals in the scenario. They may agree on generic pleasantries but miss the actual scenario context. 3 = Moderate They partially grasp each other's scenario-related goals. Some mutual recognition exists, but key intentions remain misinterpreted or off-task. 4 = High Both participants demonstrate an understanding of each other' goals within the scenario, though nuances (emotional tone, secondary motives) may be missed. 5 = Very High Full alignment. Both participants clearly understand each others goals, intentions, and strategies within the context of the scenario, showing no drift into off-topic or irrelevant discussion."
        },
        {
            "title": "H LLM Prompt",
            "content": "For reproducibility, we include the exact prompts used in our design and pipeline. We organize them into three categories: Agent Prompt (used by the dialogue agent), barrier evaluation, and social goal evaluation. H.1 Neutralization Prompt Rewrite the following scenario into ONE short sentence that preserves the general setting, but removes or obscures explicit roles/goals/privileged information of either party. Avoid revealing who is in charge, target prices, amounts, or concrete responsibilities. Keep it natural and specific enough to set context, but ambiguous about who does what. Scenario: {scenario} H.2 Agent Prompt (used by the dialogue agent) Imagine you are {agent_name}, your task is to act/speak as {agent_name} would, keeping in mind {agent_name}'s social goal. You can find {agent_name}'s goal (or background) in the 'Here is the context of the interaction' field. 21 Preprint. Under review. Note that {agent_name}'s goal is only visible to you. You should try your best to achieve {agent_name}'s goal in way that aligns with your character traits and values. Additionally, maintaining the conversation's naturalness and realism is essential (e.g., do not repeat what other people has already said before). {history} Here is the context of this interaction: Scenario: {scenario} {agent_name}'s background: {agent_age} years old {agent_gender} working as { agent_occupation}. Public info: {agent_public_info} {partner_name}'s background: {partner_age} years old {partner_gender} working as {partner_occupation}. Public info: {partner_public_info} {agent_name}'s goal: {agent_goal} {partner_name}'s goal: Unknown {agent_name}'s reason: {agent_reason} {partner_name}'s reason: Unknown IMPORTANT: You have private knowledge that others do not know: { agent_private_knowledge} This private knowledge should influence your strategy, but do not explicitly reveal it unless it serves your goal. You are at Turn #{turn_number}. Your available action types are {action_list} Note: You can \"leave\" this conversation if 1. you have achieved your social goals, 2. this conversation makes you uncomfortable, 3. you find it uninteresting/you lose your patience, 4. or for other reasons you want to leave. Please only generate JSON string including the action type and the argument. Your action should follow the given format: {{\"action_type\": <action_type>, \"argument\": <action_argument>}} H.3 Barrier Evaluation Prompt (used by the evaluator) You are evaluating completed conversation for its episode-level repair outcome quality. Using the full context and transcript, answer these two questions on 15 Likert scale and provide brief reasoning for each. 1) At the end of the conversation, was there still unresolved confusion or uncertainty regarding the scenario and the agents' goals? 1 = Very High The conversation is incoherent. Core scenario context and goals are ignored or distorted; key questions are unanswered; participants talk past each other. 2 = High Major misunderstandings about scenario or goals persist. Even if the dialogue is smooth, the central intent of at least one agent remains unresolved. 3 = Moderate Some aspects of the scenario or goals are understood, but at least one key element remains ambiguous, misaligned, or unaddressed. 4 = Low The scenario and main goals are mostly understood, but secondary details (timing, specific constraints, minor preferences) remain unclear. 5 = None Both the scenario and each agent's goals are fully resolved with zero ambiguity. 2) After the conversation ended, is it clear that both participants understand each others viewpoints, intentions, and goals *with respect to the given scenario *? 1 = Very Low Participants are talking past each other or off-topic. They do not recognize or engage with the scenario goals. No shared understanding is achieved. 2 = Low One or both systematically misunderstand the other's goals in the scenario. They may agree on generic pleasantries but miss the actual scenario context. 22 Preprint. Under review. 3 = Moderate They partially grasp each other's scenario-related goals. Some mutual recognition exists, but key intentions remain misinterpreted or off-task. 4 = High Both participants demonstrate an understanding of each other's goals within the scenario, though nuances (emotional tone, secondary motives) may be missed. 5 = Very High Full alignment. Both participants clearly understand each other goals, intentions, and strategies within the context of the scenario, showing no drift into off-topic or irrelevant discussion. FULL CONTEXT: - Scenario: {scenario} - Agent A's Goal: {agent_a_goal} - Agent B's Goal: {agent_b_goal} CONVERSATION TRANSCRIPT: {transcript} Return the following JSON: {{ \"episode_level\": {{ \"unresolved_confusion\": {{\"score\": <15>, \"reasoning\": \"<why this value>\"}}, \"mutual_understanding\": {{\"score\": <15>, \"reasoning\": \"<why this value>\"}} }} }} H.4 Social Goal Evaluation Prompt (used by the evaluator) You are evaluating conversation between two agents who each have specific social goals and reasons. Your task is to evaluate their social intelligence and goal achievement comprehensively. AGENT 1 GOAL: {goal1} AGENT 1 REASON: {reason1} AGENT 2 GOAL: {goal2} AGENT 2 REASON: {reason2} CONVERSATION TRANSCRIPT: {transcript} Please provide detailed evaluation for each agent across the following dimensions: 1. Believability (BEL) (0-10): Evaluate if the agent interacts with others in natural and realistic manner. Consider: a. whether the agent is confusing with its own identity b. whether the agent repeats others' words/actions without any reason c. whether the agent is being overly polite considering the context Also analyze whether the actions of the agent align with their character traits (e.g., personality, values, etc.). Higher scores indicate more believable behavior. 2. Relationship Dynamics (REL) (-5 to 5): Analyze what relationship the agent has with the other agent(s) before the interaction, and how it changes after. Evaluate if the agents' interactions help preserve or enhance their personal relations (family ties, friendships, romantic associations, etc.). Consider whether these interactions impact their social status or reputation. Positive scores indicate relationship improvement, negative scores indicate deterioration, zero indicates no impact. 3. Knowledge Acquisition (KNO) (0-10): 23 Preprint. Under review. Assess what information the agent has gained through the interaction. Analyze whether the information gained is new to them. Analyze whether the information gained is important to them. Higher scores indicate more new and important knowledge gained. 4. Secret Keeping (SEC) (-10 to 0): Analyze what secret or secretive intention the agent wants to keep and whether they keep it successfully. Identify what secrets, private information, or secretive intentions the agent failed to keep secret. Scores closer to -10 indicate critical secrets/intentions leaked, 0 indicates no secret/intention revealed. 5. Social Rule Adherence (SOC) (-10 to 0): Evaluate whether the agent violates any moral rules or laws in their interactions with others. Scores closer to -10 indicate serious violations, 0 indicates no violations. 6. Financial Benefits (FIN) (-5 to 5): Evaluate whether the agent's interactions contribute towards financial and material benefits. Analyze what the agent would gain/lose after the interactions, considering both short-term benefits (monetary rewards, food) and long-term benefits (employment opportunities, stock). Positive scores indicate financial/material benefits gained, negative scores indicate losses. 7. Goal Completion (GOAL) (0-10): Reiterate the agent's social goals. Provide comprehensive analysis about the extent to which the agent has managed to achieve these goals. Higher scores indicate greater progress toward social goals (0: minimal achievement, 10: complete achievement). Here is the JSON structure to follow: {{ \"agent_1\": {{ \"believability\": {{\"score\": 5, \"reasoning\": \"Your reasoning here\"}}, \"relationship\": {{\"score\": 0, \"reasoning\": \"Your reasoning here\"}}, \"knowledge\": {{\"score\": 3, \"reasoning\": \"Your reasoning here\"}}, \"secret\": {{\"score\": -2, \"reasoning\": \"Your reasoning here\"}}, \"social_rules\": {{\"score\": -1, \"reasoning\": \"Your reasoning here\"}}, \"financial_benefits\": {{\"score\": 0, \"reasoning\": \"Your reasoning here\"}}, \"goal_completion\": {{\"score\": 6, \"reasoning\": \"Your reasoning here\"}}, \"overall_score\": 4 }}, \"agent_2\": {{ \"believability\": {{\"score\": 7, \"reasoning\": \"Your reasoning here\"}}, \"relationship\": {{\"score\": 2, \"reasoning\": \"Your reasoning here\"}}, \"knowledge\": {{\"score\": 4, \"reasoning\": \"Your reasoning here\"}}, \"secret\": {{\"score\": 0, \"reasoning\": \"Your reasoning here\"}}, \"social_rules\": {{\"score\": 0, \"reasoning\": \"Your reasoning here\"}}, \"financial_benefits\": {{\"score\": 1, \"reasoning\": \"Your reasoning here\"}}, \"goal_completion\": {{\"score\": 8, \"reasoning\": \"Your reasoning here\"}}, \"overall_score\": 6 }}, \"interaction_quality\": {{ \"score\": 7, \"reasoning\": \"Your overall reasoning here\" }}, \"key_observations\": [\"Observation 1\", \"Observation 2\", \"Observation 3\"] }} 24 Preprint. Under review. THE USE OF LARGE LANGUAGE MODELS (LLMS) We used ChatGPT as writing assistant to help us write part of the paper. Additionally, we utilize the power of CodePilot to help us code faster. However, all the AI-generated writing and coding components are manually checked and modified. There is no full AI-generated content in the paper."
        }
    ],
    "affiliations": [
        "Department of Psychological Sciences, Rice University",
        "Siebel School of Computing and Data Science, University of Illinois Urbana-Champaign"
    ]
}