{
    "paper_title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
    "authors": [
        "Pan Lu",
        "Bowen Chen",
        "Sheng Liu",
        "Rahul Thapa",
        "Joseph Boen",
        "James Zou"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Solving complex reasoning tasks may involve visual understanding, domain knowledge retrieval, numerical calculation, and multi-step reasoning. Existing methods augment large language models (LLMs) with external tools but are restricted to specialized domains, limited tool types, or require additional training data. In this paper, we introduce OctoTools, a training-free, user-friendly, and easily extensible open-source agentic framework designed to tackle complex reasoning across diverse domains. OctoTools introduces standardized tool cards to encapsulate tool functionality, a planner for both high-level and low-level planning, and an executor to carry out tool usage. We validate OctoTools' generality across 16 diverse tasks (including MathVista, MMLU-Pro, MedQA, and GAIA-Text), achieving substantial average accuracy gains of 9.3% over GPT-4o. Furthermore, OctoTools outperforms AutoGen, GPT-Functions and LangChain by up to 10.6% when given the same set of tools. Through comprehensive analysis and ablations, OctoTools demonstrates advantages in task planning, effective tool usage, and multi-step problem solving."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 1 ] . [ 1 1 7 2 1 1 . 2 0 5 2 : r OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Pan Lu * , Bowen Chen * , Sheng Liu * *Equal contribution , Rahul Thapa , Joseph Boen , James Zou"
        },
        {
            "title": "Stanford University",
            "content": "Website: https://octotools.github.io"
        },
        {
            "title": "Visualization",
            "content": "Figure 1. The framework of OctoTools. (1) Tool cards define tool-usage metadata and encapsulate tools, enabling training-free integration of new tools without additional training or framework refinement. (2) The planner governs both high-level and low-level planning to address the global objective and refine actions step by step. (3) The executor instantiates tool calls by generating executable commands and save structured results in the context. The final answer is summarized from the full trajectory in the context. Furthermore, the task-specific toolset optimization algorithm learns to select beneficial subset of tools for downstream tasks. See Figure 3 for an example."
        },
        {
            "title": "Abstract",
            "content": "Solving complex reasoning tasks may involve visual understanding, domain knowledge retrieval, numerical calculation, and multistep reasoning. Existing methods augment large language models (LLMs) with external tools but are restricted to specialized domains, limited tool types, or require additional training data. In this paper, we introduce OctoTools, training-free, user-friendly, and easily extensible open-source agentic framework designed to tackle complex reasoning across diverse domains. OctoTools introduces standardized tool cards to encapsulate tool functionality, planner for both high-level and low-level planning, and an executor to carry out tool usage. We validate OctoTools generality across 16 diverse tasks (including MathVista, MMLU-Pro, MedQA, and GAIA-Text), achieving substantial average accuracy gains of 9.3% over GPT-4o. Furthermore, OctoTools outperforms AutoGen, GPT-Functions and LangChain by up to 10.6% when given the same set of tools. Through comprehensive analysis and ablations, OctoTools demonstrates advantages in task planning, effective tool usage, and multi-step problem solving. Figure 2. Performance comparison across 16 benchmarks. Our OctoTools framework achieves an average accuracy gain of 9.3% over GPT-4o without function plugins and 7.3% over LangChain, using the same tools under the same configuration. *Equal contribution. PL and RT started the project. PL completed the early framework. PL, BC refined the framework. PL, BC, and SL contributed to experiments and paper writing. Correspondence to: Pan Lu <panlu@stanford.edu>, James Zou <jamesz@stanford.edu>. 1 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning 1. Introduction Large language models (LLMs) (Brown et al., 2020; Chowdhery et al., 2022; OpenAI, 2023b) have made rapid progress on tasks such as summarization, translation (Thoppilan et al., 2022), code generation (Nakano et al., 2021), and math problem solving (Shuster et al., 2022). However, complex reasoning tasks that involve multiple steps, logical decomposition, or specialized domain knowledge remains challenging. For example, solving visual riddle may require fine-grained image understanding and text-based reasoning, while math or chemistry question can require thorough computations or domain expertise. Existing prompting methods often fail to orchestrate these varied processes into coherent chain of reasoning (Yao et al., 2022). promising direction to address these challenges is to augment LLMs with external tools. By offloading specialized subtasks (e.g., web queries, Python-based calculations, and specialized scientific tools) to dedicated modules, LLMs can focus on higher-level planning and synthesis. Several frameworks have explored such tool usage, from those relying on extensive supervised data and fine-tuning (Schick et al., 2023; Liu et al., 2023), to static solutions without refinement (Lu et al., 2023), and those limited to one specialized domain of tools (Nakano et al., 2021; Tao et al., 2023; Hu et al., 2024). Although these methods perform well on specific tasks, they still face challenges that hinder general widespread use. Many require substantial training with curated data, which limits their adaptability to new domains. Others are designed for particular domain (Bran et al., 2023; Kang & Kim, 2024; Li et al., 2024a; Schmidgall et al., 2024) or cannot easily support multi-step problemsolving (Lu et al., 2023), restricting their generality. In this paper, we propose OctoTools, training-free (i.e., it does not require updating model weights), user-friendly, and extensible agentic framework for tackling complex reasoning tasks across diverse domains (Figure 1). key feature of OctoTools is the concept of tool cards, standardized wrappers that encapsulate heterogeneous tools (e.g., Python calculators, web search APIs, and domain-specific modules), along with metadata such as input-output formats, usage constraints, and best practices that delineate ideal use cases. This standardized design enables easy integration, replacement, or expansion of toolsunlike approaches requiring painstaking re-engineering for each new tool (Lu et al., 2023; Hu et al., 2024). Building on these tool cards, OctoTools employs dedicated planner that governs both high-level and low-level planning. Given user query, the planner proposes tentative global plan for how various tools might be employed. At each step, it generates text-based action (including sub-goals and tool selection) conditioned on the evolving context. separate executor instantiates tool calls by converting this textual action into an executable command, running the corresponding tool, and updating the context with the results. By separating strategic planning from command generation, OctoTools reduces errors and increases transparency, making the system more reliable and easier to maintain. An additional challenge in agentic systems is determining which subset of tools to enable for given domain. Although providing many tools can be beneficial, enabling them all may introduce noise or slow performance (Lumer, 2024; Fore et al., 2024; Paramanayakam et al., 2024). To address this, we propose lightweight toolset optimization algorithm that identifies more useful subset of tools for each task based on validation performance, ultimately improving both accuracy and efficiency. While recent general agent frameworks also allow LLMs to use external tools autonomously, they often focus on highlevel abstractions (LangChain, 2024), limited observability of intermediate decisions (OpenAI, 2023a), or multi-agent collaboration features (AutoGen, 2024), with less emphasis on enhancing complex reasoning and quantitatively benchmarking downstream task performance. In contrast, we systematically evaluate the entire agentic workflow of OctoTools across diverse tasks, providing in-depth analyses of when and how tool-based reasoning succeeds or fails in complex reasoning scenarios. We conduct large-scale experiments across 16 diverse reasoning benchmarks, spanning general vision, mathematical, scientific, medical, and agentic domains. As summarized in Figure 2, OctoTools substantially outperforms other baselines, achieving an average accuracy gain of 9.3% over zeroshot prompting by GPT-4o and 7.7% over chain-of-thought (CoT) prompting, as well as up to 10.6% improvement compared to existing agentic frameworks when given the same tools (AutoGen, 2024; OpenAI, 2023a; LangChain, 2024). Detailed analyses show that OctoTools effectively combines multi-step planning and specialized tool usage, with each dimension providing distinct improvements. For tasks requiring intricate calculations or specialized knowledge, we found tool usage is particularly beneficial; for tasks requiring reasoning decomposition, we found multi-step planning offers significant gains. Furthermore, our ablation studies offer insights into OctoToolss performance under different conditions. Overall, the average accuracy tends to improve as the maximum number of steps increases. Without any toolset optimization, simply enabling all tools in the toolset yields 57.4% accuracy, which still surpasses the setup with only the base tool by 3.5%, suggesting degree of generalization as the toolset expands. Learning the optimal toolset for specific tasks raises the overall performance to 58.9%, indicating the benefit of further optimization. Additionally, when using weaker LLM (GPT-4o-mini) as the base engine, OctoTools 2 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Figure 3. The demonstration of self-contained example from Figure 1. We visualize the tool cards for selected tools, the initial plan generated by the planner, and two steps in which the planner and the executor orchestrate low-level planing and tool usage before arriving at the final answer. See F.1 for details and for more examples. An interactive visualization of these examples is available at https://octotools.github.io/#visualization. maintains strong average gain of 7.1% across 16 tasks. Our contributions are as follows: (1) We propose OctoTools, training-free, extensible agentic framework that enables LLMs to call external tools in multiple steps, without the need for additional training or fine-tuning. (2) We introduce comprehensive planner-executor paradigm with standardized tool cards, which can be easily customized or expanded for new domains. (3) We conduct large-scale experiments on 16 diverse benchmarks and show that OctoTools improves performance by sizable margin compared to baseline prompting and other agentic frameworks. (4) We provide in-depth analyses and ablations on how multi-step reasoning and tool usage contribute to performance, offering practical guidance for future agent development. 2. Related Work Tool-Augmented LLMs. promising direction for enhancing large language models (LLMs) involves offloading specialized subtasks to external tools such as search engines (Komeili et al., 2022; Thoppilan et al., 2022; Lazaridou et al., 2022; Shuster et al., 2022; Yao et al., 2022), web browsers (Nakano et al., 2021), calculators (Cobbe et al., 2021; Thoppilan et al., 2022), translation systems (Thoppilan et al., 2022), or Python interpreters (Gao et al., 2023). Broadly, these methods either rely on large-scale fine-tuning or human supervision to teach LLMs how to invoke tools (Schick et al., 2023; Komeili et al., 2022; Nakano et al., 2021; Thoppilan et al., 2022) or use few-shot prompts for single tools in narrowly defined tasks (Yao et al., 2022; Lazaridou et al., 2022; Gao et al., 2023). In contrast, OctoTools is training-free framework that integrates diverse tools through standardized tool cards and employs plannerexecutor paradigm to manage multi-step reasoning. Because new tools can be introduced without re-training, OctoTools offers more extensible and modular approach to tool usage. LLM Agents. growing body of work leverages LLMs as autonomous agents that make decisions and invoke tools in multi-step workflows. Some agents use closed-source models with hand-engineered prompts (Chen et al., 2023; Wang et al., 2024a), while others fine-tune LLMs on curated data that learn when and how to call tools (Liu et al., 2023; Tao et al., 2023; Zhang et al., 2024). These frameworks often face limitations. For example, although specialized agent frameworks achieve strong performance in particular domains (e.g., chemistry (Bran et al., 2023), vision (Li et al., 2024a; Hu et al., 2024), materials science (Kang & Kim, 2024), or medical imaging (Schmidgall et al., 2024)), they typically lack generality across diverse tasks. Additionally, some systems are constrained by narrow capabilities with static planning (Lu et al., 2023) and multi-step reasoning (Hu et al., 2024). Recently, general-purpose agent platforms such as AutoGen (AutoGen, 2024), GPT-Functions (OpenAI, 2023a), and LangChain (LangChain, 2024) have emerged, but they have seen less emphasis on complex reasoning and rigorous benchmarking across diverse downstream tasks. In contrast, OctoTools combines the flexibility of such platforms with dedicated planner and executor to handle multi-step decision-making. Complex Task Reasoning. When faced with multi-step problems, common strategy is to break down question into simpler sub-questions and solve them step by step. 3 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Early work approached decomposition with unsupervised or weakly supervised models (Perez et al., 2020; Khot et al., 2022), and more recent research has explored prompting techniques for step-by-step reasoning, including Chain-ofThought (Wei et al., 2022), Least-to-Most (Zhou et al., 2022), ReAct (Yao et al., 2022), Pearl (Sun et al., 2023), Forest-of-Thought (Bi et al., 2024), and rStar-Math(Guan et al., 2025). While these methods significantly improve LLMs single-model reasoning capabilities, they primarily rely on the latent capacity of an LLM without external validation or targeted tool usage. In contrast, OctoTools systematically combines multi-step decomposition (via an iterative planner) with specialized tools (encapsulated by tool cards) and an executor for reliable, context-aware function calling. This design makes it easy to incorporate domain-specific functionalities and check intermediate steps with external modules, thus improving both correctness and versatility in tackling challenging tasks. 3. The OctoTools Framework We propose OctoTools, an open-source, versatile, and userfriendly agent-toolbox framework for complex reasoning tasks, as illustrated in Figure 1. Given user query and pretrained language model LLMθ(), naive approach would generate an output directly as LLMθ(q), providing single-step response. In contrast, our OctoTools framework introduces structured, multi-step process that leverages external tools to tackle queries effectively. Specifically, OctoTools contains set of tools = {di}n i=1 and associated metadata = {mi}n i=1, where is the number of available tools. Given query, planner (based on language model) first generates tentative plan from high-level perspective, indicating how these tools can be used to address the query, which forms the initial context s0. From this plan, the planner determines the initial action a1 for tool usage, specifying which tool d1 to use, the relevant context, and sub-goal. An executor (also powered by language model) then converts the planners text-based action a1 into machine-executable command ot, which is run to obtain intermediate results r1. These results, along with the original action, update the context to s1 := (a1, o1, r1). This process constitutes one step in our framework. This process repeats, with the planner iteratively refining its actions based on the evolving context until it either finds complete solution or inference limits (e.g., time or steps) are reached. After steps, the framework produces full trajectory (s0, s1, . . . , sT ), which is stored in structured manner in the context. The planner then uses this trajectory to generate the final solution to the original query. OctoTools provides robust and effective framework for solving complex tasks through sub-goal decomposition and systematical tool usage. Standardized tool cards encapsulate functionality (3.1), the planner orchestrates both high-level and low-level task planning (3.2), and the executor instantiates tool calls for each sub-goal (3.3). The following sections detail the logic of each component, with implementation details provided in C. 3.1. Tool Cards To enable seamless interaction among tools, the planner, and the executor, the toolbox serves as fundamental building block of OctoTools. In contrast to previous work (Lu et al., 2023; Hu et al., 2024) that rely on careful adaptions and tuning to support new tools, OctoTools leverages tool cards, which encapsulate tools in modular manner. Each tool card represents tool along its essential metadata (as illustrated in Figure 3). This metadata includes the tools name, input and output types, and command demonstrations. It may also contain additional usage constraints (e.g., user-defined limitations and best practices), which provide developers insights to guide the planner and executor. For example, Image Captioner Tool includes it may make mistakes in complex scenes and consider using other tools for verification (D.4), while Object Detector Tool notes the limitation in detecting objects (E.1). See for details on featured tools. To ensure consistent interactions, every tool card implements two standard functions. The function execute() encapsulates the tools primary functionality, e.g., generating code snippet or performing object detection. Executed results are stored in structured format to support different output types, e.g., generated code, detected objects, stored files (see D). The function get metadata() allows the planner and executor to dynamically evaluate the tools capabilities and understand usage constraints. The design of each tool card is modular relative to the framework, enabling users to integrate diverse tools without modifying the underlying framework or agent logic. New tool cards can be added, replaced, or updated with low effort. Consequently, OctoTools remains robust and extensible, even as tasks grow in complexity or scope. 3.2. Planner Module Planner initialization. The planner inspects the toolbox and loads each tool card as defined in 3.1. Formally, it constructs set {di}n i=1 of available tools, each with metadata that describes its input-output schema and usage constraints. Rather than enabling the full toolset, subset D* = {di}k i=1 may be selected based on expert insights or optimized using small set of examples (See 3.4 and 5.2 for details and experimental study). 4 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Query analysis and action prediction. Given query q, the planner formulates high-level, tentative plan for tool usage based on its initialization. As shown in Figure 1, the high-level plan summarizes the query objective, analyzes the required skills, identifies relevant tools, and includes additional considerations to highlight the need for verification. The high-level task plan provides global perspective on the final objective, ensuring that each subsequent sub-goal remains aligned with the original query. Subsequently, at step t, an action predictor produces an action at that combines the planner-suggested sub-goal (e.g., detect baseballs in the image), the selected tool (e.g. Object Detector), and the relevant context. This lowlevel plan refines and executes each sub-goal in real time, adapting to new information or feedback at each step. Context verification and solution summarization. After each command is executed, context verifier checks whether the problem can be solved given the current context. It verifies completeness (e.g., whether all sub-goals are satisfied) and identifies any ambiguities. If the problem remains incomplete, the planner continues the next iteration of the cycle by predicting the next action at+1. Once the verifier concludes that the query has been solved, separate solution summarizer compiles the final answer from the trajectory (s0, s1, . . . , sT ). This stage integrates intermediate tool outputs, traces reasoning steps, and presents concise, user-friendly summary as the final solution. 3.3. Executor Module Command prediction. Prior work (Lu et al., 2023; Hu et al., 2024) often expects single language model both for planning each step (i.e., which tool to use) and for generating the corresponding executable command. This dual responsibility can overload the model and lead to errors, especially when dealing with complex or environment-specific code (Bran et al., 2023; Li et al., 2024b; Ji et al., 2024). To mitigate these issues, OctoTools introduce command generator that interprets the planners text-based actions and produces executable code. Given the action at predicted by the planner, the command generator (powered by language model) creates lowlevel command ot in the form of an executable Python script, which calls the tool dt with necessary inputs and performs any required data preparation. This step bridges the abstract action specified in at and the concrete tool call. By separating decision-making from code generation, each component of the system can concentrate on its specialized role. systems). Directly coupling execution with planning poses security and maintainability challenges, especially if the planner is not capable of managing code execution details. In OctoTools, an command executor runs the generated command ot in Python environment, obtaining result rt. This may include tool outputs, logs, or error messages. The executor then adds the current context of this step st := (at, ot, rt) to the agents current trajectory (s0, s1, . . . , st1). The trajectory preserves clear history of the actions taken, the code produced, and the results obtained. 3.4. Task-specific Toolset Optimization The OctoTools toolbox contains diverse set of tools covering different modalities and skills. By leveraging structured tool cards and robust planning capabilities, OctoTools demonstrates strong generality when all available tools are enabled across different tasks (see 3.4). However, when small set of validation examples are available for task, configuring task-specific subset of tools can further enhance efficiency and effectiveness. To this end, we propose an automated algorithm to optimize the toolset configuration for each task. Given available tools in the toolbox, the total number of possible subsets is O(2n), which is prohibitively large. To make this tractable, we employ greedy search strategy that reduces the complexity to O(n). Our approach proceeds in three stages. i=1, base toolset Dbase Algorithm 1 Task-specific Toolset Optimization 1: Input: Toolbox = {di}n 2: Output: Optimized toolset 3: # Stage 1: Baseline setup 4: Accbaseline Acc(Dbase) 5: # Stage 2: Individual tool evaluation 6: for each di in such that di / Dbase do 7: Di Dbase {di} Acci Acc(Di) 8: 9: di Acci Accbaseline 10: 11: end if 12: 13: end for 14: # Stage 3: Select optimized toolset 15: Dbeneficial Dbase 16: Return Dbeneficial Dbeneficial {di} if di > 0 then Command execution. Once an executable command is generated, it must be run in an environment that may involve dependencies, external libraries, or resource access (e.g., file Stage 1: Baseline setup. We first establish baseline performance by enabling the base toolset in the toolbox, denoted Dbase. This base set represents minimal starting toolset, which can be pre-defined by the user. 5 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Stage 2: Individual tool evaluation. Next, we measure each candidate tool di by enabling it alongside the base toolset. For each di, we form an augmented subset Di = Dbase {di} and compute the accuracy difference on the set of validation examples di = Acc(cid:0)Di (cid:1) Acc(cid:0)Dbase (cid:1). (1) If di > 0, we consider the tool di beneficial for the target task. Stage 3: Optimized toolset selection. Finally, we aggregate all tools that yield positive improvements and combine them with the default set to form the optimized toolset: = Dbase { di di > 0}. (2) This set contains all tools that individually demonstrate performance gain over the baseline, ensuring customized yet efficient configuration for the downstream task. While this selection does not guarantee global optima, we observe overall improvements over simply using all tools (see 5.2). 4. Experiments 4.1. Experimental Setups To demonstrate the generality of our OctoTools framework, we conduct comprehensive evaluations on 16 diverse benchmarks spanning two modalities, five domains, and four reasoning types, as shown in Table 1. These benchmarks encompass wide range of complex reasoning tasks, including visual understanding, numerical calculation, knowledge retrieval, and multi-step reasoning. For general visual reasoning, we include AlgoPuzzleVQA (Ghosal et al., 2024), Hallusion-VD (Guan et al., 2024), PuzzleVQA (Chia et al., 2024), and VQA 2.0 (Goyal et al., 2017). For mathematical reasoning, we use Game of 24 (Lile, 2024), Omni-MATH (Gao et al., 2024), CLEVR-Math (Lindstrom & Abraham, 2022), and MathVista (Lu et al., 2024b). For scientific reasoning, we adopt GPQA (Rein et al., 2023), MMLU-Pro (Wang et al., 2024b), and SciFIBench (Roberts et al., 2024). To evaluate models in specialized medical domains, we test on MedQA (Jin et al., 2021), PathCLS (Sun et al., 2025), PathVQA (He et al., 2020), and SLAKE (Liu et al., 2021) Additionally, we incorporate GAIA-Text, textual subset of the GAIA (Mialon et al., 2023) benchmark designed to evaluate agentic frameworks with tool-calling capabilities. See A.1 for additional details of these benchmarks. For each benchmark, we sampled 100 examples to construct validation set for toolset optimization (3.4) and ablation studies (5), and set aside held-out test set of 200 examples for final evaluation. For benchmarks with fewer than 300 total samples, the test set consisted of all remaining samples not used for validation. To mitigate randomness, we report the average accuracy with standard deviation across three trials for all experiments, including ablation studies. Details on experimental setups are provided in A. We created diverse array of tools in the toolbox for our experiments. The base toolset consists of Generalist Solution Generator, tool built on top of the base LLM that takes as input specialized prompt generated by the executor, such as Describe the image in detail or Generate stepwise solutions for the math problem. This tool allows for general stepby-step reasoning without requiring external tools but lacks domain specificity. The toolbox also includes image perception tools such as Image Captioner, web search APIs like Google Search, code generator Python Code Generator, and specialized tools like Path Generalist Classifier for pathology image classification. Among them, Relevant Patch Zoomer is unique tool that takes textual query and returns zoomed-in quarter patches, which provide localized details for fine-grained visual reasoning scenarios. See A.2 and for more details. 4.2. Main Results We compare the performance of our framework after toolset optimization (denoted as OctoTools) against three baselines: (1) zero-shot, where the base LLM directly answers queries without additional prompting, (2) chain-of-thought (CoT), where the base LLM is prompted to Think step by step to generate step-by-step reasoning, and (3) OctoToolsbase, which uses only the base tool without external integrations. Unless otherwise specified, all results presented below use gpt-4o-2024-08-06 as the base model. Table 1 and Figure 2 summarize performance across all 16 benchmarks. OctoTools achieves consistent gains, outperforming zero-shot and CoT baselines by 9.3% and 7.7% on average, respectively. OctoToolsbase also demonstrates improvements over zero-shot (4.2%) and CoT (2.6%), indicating that our frameworks step-by-step reasoning contributes significantly to performance, independent of external tool integration. Figure 16 visualizes gains over zero-shot. Detailed analyses of these gains are presented in 4.4. 4.3. Comparisons with Other Agent Frameworks In addition, we compare three commonly used general AI agent frameworks: GPT-Functions (OpenAI, 2023a), LangChain (LangChain, 2024), and AutoGen (AutoGen, 2024). GPT-Functions enables GPT-4o to call user-specified tools via function calling. LangChain is framework providing multi-agent collaboration, long-term memory, and tool usage. AutoGen is recent agentic framework that creates multiple autonomous agents with tool usage. 6 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning CoT OctoToolsbase OctoTools (0-shot) (CoT) Datasets Modality Domain AlgoPuzzleVQA Hallusion-VD PuzzleVQA VQA 2.0 Game of 24 Omni-MATH CLEVR-Math MathVista GPQA MMLU-Pro SciFIBench MedQA PathCLS PathVQA SLAKE GAIA-Text Average (%) Vision Vision Vision Vision Text Text Vision Vision Text Text Vision Text Vision Vision Vision Text - General General General General Mathematical Mathematical Mathematical Mathematical Scientific Scientific Scientific Medical Medical Medical Medical Agentic - - - - 0-shot 41.3 0.3 52.0 1.0 52.2 1.0 50.3 1.0 22.2 2.5 27.0 0.0 64.5 3.0 59.3 0.8 53.7 1.9 71.7 0.3 72.5 0.0 84.5 1.0 36.0 0.9 32.0 1.8 59.3 1.0 8.7 0. 42.7 1.0 53.3 2.1 54.0 1.3 48.7 0.3 33.3 1.5 29.3 1.3 75.2 1.5 59.5 1.5 52.3 2.0 70.3 0.6 75.0 0.9 84.8 0.6 37.5 1.8 27.8 1.8 60.3 0.6 44.0 0.9 59.0 0.0 59.3 0.8 47.2 0.8 37.8 3.3 30.2 0.6 68.8 0.8 63.0 1. 53.7 2.5 71.5 1.3 77.3 0.8 92.8 0.6 37.0 1.8 43.5 2.6 59.2 1.8 8.4 0.5 9.7 0.9 - 49. 50.8 53.4 48.7 0.3 63.3 2.9 61.0 0.5 54.5 0.0 44.7 2.8 32.2 0.8 79.0 0.9 64.3 1.0 54.7 1.3 73.7 1.3 78.3 0.6 91.5 1.8 58.2 1.3 49.2 1.2 63.8 1. 18.4 1.2 58.5 +7.4 +11.3 +8.8 +4.2 +22.5 +5.2 +14.5 +5.0 +1.0 +2.0 +5.8 +7.0 +22.2 +17.2 +4. +9.7 +9.3 +6.0 +10.0 +7.0 +5.8 +11.4 +2.9 +3.8 +4.8 +2.4 +3.4 +3.3 +6.7 +20.7 +21.4 +3. +10.0 +7.7 ), numerical calculation ( Table 1. Main results across 16 benchmarks spanning different modalities, domains, and required reasoning skills: visual understand- ). OctoToolsbase uses only the base tool ing ( (Generalist Solution Generator), while OctoTools uses the optimal toolset. Performance gains () are computed for OctoTools relative to both zero-shot (0-shot) and chain-of-thought (CoT) baselines, with OctoTools achieving 58.5% average accuracy and improvements of 9.3% and 7.7% respectively. All results show average accuracy and standard deviation (gray) over three trials. ), and multi-step reasoning ( ), knowledge retrieval ( Datasets AutoGen GPT-Functions LangChain OctoTools AlgoPuzzleVQA 44.0 1.0 52.7 4.7 Hallusion-VD 40.0 2.3 Puzzle VQA 46.0 1.0 VQA 2.0 Game of 24 Omni-MATH CLEVR-Math MathVista GPQA MMLU-Pro SciFIBench MedQA PathCLS PathVQA SLAKE 24.2 2.4 28.5 1.3 69.5 3.9 24.7 2.5 48.7 2.9 65.0 2.5 70.0 2.2 83.7 2.8 58.0 1.3 42.7 0.8 62.2 1.8 44.5 0.5 57.0 1.7 52.5 2.8 45.5 0.9 34.5 2.3 22.8 1.8 71.2 1.0 54.5 2.0 45.8 2.6 65.8 2.4 68.8 3. 84.8 0.3 58.2 0.6 42.8 2.3 59.7 1.9 42.7 2.8 53.7 3.1 53.5 7.8 54.0 1.0 18.3 4.1 29.7 0.6 69.2 4.6 55.7 0.3 52.2 1.2 70.3 1.2 77.0 0.5 73.7 0.6 56.3 1.3 45.7 4.4 59.3 0.8 48.7 0.3 63.3 2.9 61.0 0.5 54.5 0. 44.7 2.8 32.2 0.8 79.0 0.9 64.3 1.0 54.7 1.3 73.7 1.3 78.3 0.6 91.5 1.8 58.2 1.3 49.2 1.2 63.8 1.4 GAIA-Text 6.3 0.8 7.9 0. 7.6 1.2 18.4 1.2 Average (%) 47.9 51.0 51. 58.5 Table 2. Comparison with other agent frameworks using the same underlying toolbox. OctoTools achieves superior performance with an average accuracy of 58.5%, outperforming the next best baseline by 7.3%. Results are averaged over three trials. For standardized comparison of each systems ability to plan and use tools over multiple steps, we configure all agent frameworks, including OctoTools, to use the same underlying model (GPT-4o) and hyperparameters. They share the same toolset (with the same implementations of tools), maximum reasoning budget of 10 steps, and time budget of 300 seconds. See for further details. Table 2 and Figure 10 show the performance of OctoTools compared to other agent frameworks across all 16 benchmarks. Overall, OctoTools outperforms other agent frameworks, achieving an average accuracy gain of 10.6% over AutoGen, 7.5% over GPT-Functions, and 7.3% over LangChain. See 4.4 for detailed analysis. 4.4. Analysis of Performance Gains Our agent framework includes three aspects for improvement in complex reasoning: task planning, external tool calling, and multi-step problem solving. We include an analysis to disentangle added benefits of each of these aspects. Tool usage distribution. Figure 4 (a) shows the tool usage distribution for OctoTools and the agent baselines, averaged over 16 tasks. OctoTools takes advantages of task planning by calling both base tool to decompose the query into subtasks (32.2%) and external specialized tools (67.8%) for reasoning skills such as fine-grained image understanding, domain knowledge access, precise calculation, and other domain-specific tasks. In contrast, the other agent baselines exhibit limitations in task planning for external tool usage, with external tool usage rates of 10.6% for AutoGen, 23.3% for GPT-Functions, and 10.7% for LangChain. Figure 4 (b) illustrates the tool usage distribution of OctoTools across the 16 tasks. OctoTools adapts to each task by selecting the most suitable tools. For instance, OctoTools employs five different tools to address the diverse challenges in GAIA-Text. In MathVista, benchmark featuring multiple diagram-based and mathematical reasoning problems, it uses Relevant Patch Zoomer for local vision perception, Google Search for web queries, and 7 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Figure 4. a. Tool usage distribution in our OctoTools framework and agent baselines by averaging results from 16 tasks. b. Tool usage distribution across 16 tasks in OctoTools. OctoTools takes advantage of different external tools to address task-specific challenges. Gains from decompositions v.s. tool usage. To assess the performance gains from tool calling, we compute for each benchmark the difference between OctoTools, i.e., with external tools, and OctoToolsbase, i.e., without external tools: tools = AccOctoTools AccOctoToolsbase. Similarly, to assess the performance gains from decomposing the problem into multiple steps, we compute the difference between OctoToolsbase and the 0-shot baseline: decom = AccOctoToolsbase Acc0-shot. For each benchmark, the performance gains from these two dimensions are visualized in Figure 6. We observe that the tasks can be broadly categorized into three groups: (1) Tasks far above the = diagonal benefit more from step decomposition, and specialized tool is either not needed or not available. (2) Tasks far below the diagonal benefit more from one or more specialized tools that are well-suited for the task, while multi-step reasoning is less critical. (3) Tasks along the diagonal benefit from both aspects. This analysis highlights that AI agent frameworks can improve performance in different ways depending on the specific skills demanded by each task, and that OctoTools is versatile framework for achieving such improvements across diverse set of tasks. 5. Ablation Study This section explores several factors that affect OctoToolss performance, using validation set of 100 samples. 5.1. Number of Maximum Allowed Steps We explore how the behavior and performance of OctoTools change under different maximum step limits. We report the average over three trials, with results summarized in Figure 5. Benchmark distribution across average number of steps and fraction of external tool usage (tools that exclude the base tool Generalist Solution Generator) in OctoTools. Python Code Generator for precise calculations. External tool usage v.s. multiple steps. Figure 5 shows how tasks are distributed based on the average number of steps and the fraction of external tool usage in OctoTools. Tasks with high average number of steps indicates that multi-step problem solving is valuable, while high proportion of external tool usage highlight the benefits of external tool calling. Notably, two tasks score highly on both dimensions: Game of 24, which frequently calls Python Code Generator to explore and verify arithmetic expressions that evaluate to 24, and GAIA-Text, which requires multiple tools to address variety of underlying skills. 8 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning i.e., (1) OctoToolsbase, the setup with only the base Generalist Solution Generator tool, (2) OctoTools with the full toolset, where all possible tools are enabled, and (3) OctoTools with the optimized toolset. Figure 8 presents results across all 16 tasks and different reasoning categories. On average, the optimized toolset achieves 58.9% accuracy, outperforming the OctoToolsbase (53.9%) by 5.0%. Meanwhile, simply enabling all tools yields 57.4% accuracy, which still outperforms OctoToolsbase by 3.5%. Although toolset optimization provides the higher overall performance, our framework is sufficiently versatile that enabling all tools also offers substantial improvement, helping ensure generalization as we scale up the toolset. While enabling all available tools might appear advantageous, prior work (Lumer, 2024; Fore et al., 2024; Paramanayakam et al., 2024) has shown that it can sometimes degrade performance. Our findings suggest that external feedback (e.g., performance on validation set or expert insights) helps identify when certain tool improves performance. Additionally, selectively enabling tools avoids unnecessary overhead and improves efficiency. promising next step is to explore query-based approach that dynamically refines the toolset for each query. Figure 6. Benchmark distribution across two dimensions. Tasks that show high improvement from task decomposition likely require multi-step reasoning, while tasks that show high improvement from specialized tools likely require specialized skills. Figure 7. Overall, performance tends to improve as the maximum number of steps increases, highlighting the benefit of longer chains of multi-step reasoning. Detailed results and analysis for individual tasks are provided in B. Additionally, we found that averaged across 16 tasks, running OctoTools with GPT-4o typically takes less than $5 for 100 queries with 10 maximum allowed steps. Figure 7. Average accuracy across 16 benchmarks with respect to maximum allowed reasoning steps in OctoTools. 5.2. Toolset Optimization To investigate the benefits of our toolset optimization algorithm (presented in 3.4 and Algorithm 1), we evaluate OctoTools under three toolset strategies: 9 Figure 8. Performance under three toolset strategies in OctoTools across all 16 tasks and various categories (the number in parentheses indicates the number of tasks in each category). 5.3. Using Weaker LLM Additionally, we evaluate our framework using weaker LLM (GPT-4o-mini) as the base engine. Similar to the analysis with GPT-4o, we compare OctoTools against the zero-shot and CoT baselines on the validation sets of 16 benchmarks. As shown in Figure 9, OctoTools generally outperforms the baselines across all 16 tasks and various categories. Task-specific analyses are provided in B. OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning"
        },
        {
            "title": "References",
            "content": "AutoGen. Autogen. https://github.com/ microsoft/autogen, 2024. Bi, Z., Han, K., Liu, C., Tang, Y., and Wang, Y. Forestof-thought: Scaling test-time compute for enhancing llm reasoning. arXiv preprint arXiv:2412.09078, 2024. Bran, A. M., Cox, S., Schilter, O., Baldassari, C., White, A. D., and Schwaller, P. Chemcrow: Augmenting largelanguage models with chemistry tools. arXiv preprint arXiv:2304.05376, 2023. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in Neural Information Processing Systems (NeurIPS), 33:18771901, 2020. Caron, M., Touvron, H., Misra, I., Jegou, H., Mairal, J., Bojanowski, P., and Joulin, A. Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF international conference on computer vision, pp. 96509660, 2021. Chen, W.-G., Spiridonova, I., Yang, J., Gao, J., and Li, C. Llava-interactive: An all-in-one demo for image chat, segmentation, generation and editing. arXiv preprint arXiv:2311.00571, 2023. Chia, Y. K., Han, V. T. Y., Ghosal, D., Bing, L., and Poria, S. PuzzleVQA: Diagnosing multimodal reasoning challenges of language models with abstract visual patterns. arXiv preprint arXiv:2403.13315, 2024. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. PaLM: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021. Fore, M., Singh, S., and Stamoulis, D. Geckopt: Llm system efficiency via intent-based tool selection. In Proceedings of the Great Lakes Symposium on VLSI 2024, pp. 353 354, 2024. Gao, B., Song, F., Yang, Z., Cai, Z., Miao, Y., Dong, Q., Li, L., Ma, C., Chen, L., Xu, R., et al. Omni-MATH: universal olympiad level mathematic benchmark for large language models. arXiv preprint arXiv:2410.07985, 2024. Figure 9. Performance of OctoTools on 16 tasks and various categories using weaker LLM, GPT-4o-mini, as the base engine. OctoToolsbase is the configuration in which only the base Generalist Solution Generator tool is enabled. The number in parentheses indicates # tasks in each category. 6. Conclusion In this paper, we introduced OctoTools, training-free, extensible agentic framework for complex reasoning. OctoTools employs standardized tool cards to facilitate seamless integration of diverse tools and dedicated planner-executor workflow that separates high-level planning over multiple steps from low-level planning and command generation within each step. Through extensive experiments on 16 diverse benchmarks, OctoTools consistently outperforms baselines, achieving average accuracy gains of up to 9.3% over GPT-4o and up to 10.6% over strong agentic frameworks. Our in-depth analysis shows that OctoTools improvements stem from dynamic task planning, effective tool usage, and multi-step problem decomposition. Ablation studies highlight the benefits of allowing more step, refining the toolset, and demonstrate the robustness when deployed with weaker LLM. By streamlining the integration of new or specialized modules through tool cards, OctoTools readily adapts to broad range of tasks. We believe our findings open new ecosystems for building next-generation AI agents that are more transparent, modular, and effective at solving real-world problems. Future work includes test-time inference at the query level, extending multi-agent collaboration, and exploring specialized domains."
        },
        {
            "title": "Acknowledgments",
            "content": "This work is partially supported by the Hoffman-Yee Research Grants program at Stanford HAI and Chan Zuckerberg Initiative. We thank members of the Zou group for helpful discussions and insightful feedback. 10 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., and Neubig, G. Pal: Program-aided language models. In International Conference on Machine Learning, pp. 1076410799. PMLR, 2023. Ghosal, D., Han, V. T. Y., Ken, C. Y., and Poria, S. Are language models puzzle prodigies? algorithmic puzzles unveil serious challenges in multimodal reasoning. arXiv preprint arXiv:2403.03864, 2024. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the in vqa matter: Elevating the role of image understanding in visual question answering. In Proceedings of the IEEE Conference on Computer Vision and pattern Recognition, pp. 69046913, 2017. Guan, T., Liu, F., Wu, X., Xian, R., Li, Z., Liu, X., Wang, X., Chen, L., Huang, F., Yacoob, Y., et al. HallusionBench: an advanced diagnostic suite for entangled language hallucination and visual illusion in large vision-language models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 14375 14385, 2024. Guan, X., Zhang, L. L., Liu, Y., Shang, N., Sun, Y., Zhu, Y., Yang, F., and Yang, M. rstar-math: Small llms can master math reasoning with self-evolved deep thinking. arXiv preprint arXiv:2501.04519, 2025. He, X., Zhang, Y., Mou, L., Xing, E., and Xie, P. PathVQA: 30000+ questions for medical visual question answering. arXiv preprint arXiv:2003.10286, 2020. Hu, Y., Shi, W., Fu, X., Roth, D., Ostendorf, M., Zettlemoyer, L., Smith, N. A., and Krishna, R. Visual sketchpad: Sketching as visual chain of thought arXiv preprint language models. for multimodal arXiv:2406.09403, 2024. Ji, Z., Wu, D., Ma, P., Li, Z., and Wang, S. Testing and understanding erroneous planning in llm agents through synthesized user inputs. arXiv preprint arXiv:2404.17833, 2024. Jin, D., Pan, E., Oufattole, N., Weng, W.-H., Fang, H., and Szolovits, P. What disease does this patient have? large-scale open domain question answering dataset from medical exams. Applied Sciences, 11(14):6421, 2021. Kang, Y. and Kim, J. Chatmof: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models. Nature Communications, 15(1):4705, 2024. Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P., and Sabharwal, A. Decomposed prompting: modular approach for solving complex tasks. arXiv preprint arXiv:2210.02406, 2022. Komeili, M., Shuster, K., and Weston, J. Internet-augmented dialogue generation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 84608478, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.579. URL https:// aclanthology.org/2022.acl-long.579. LangChain, I. LangChain. https://github.com/ langchain-ai/langchain, 2024. Lazaridou, A., Gribovskaya, E., Stokowiec, W., and Grigorev, N. Internet-augmented language models through few-shot prompting for open-domain question answering. arXiv preprint arXiv:2203.05115, 2022. Li, B., Yan, T., Pan, Y., Luo, J., Ji, R., Ding, J., Xu, Z., Liu, S., Dong, H., Lin, Z., et al. Mmedagent: Learning to use medical tools with multi-modal agent. arXiv preprint arXiv:2407.02483, 2024a. Li, Z., Hua, W., Wang, H., Zhu, H., and Zhang, Y. Formal-LLM: Integrating formal language and natural language for controllable llm-based agents. arXiv preprint arXiv:2402.00798, 2024b. Lile, N. Math twenty four (24s game) dataset. https:// huggingface.co/datasets/nlile/24-game, 2024. Lindstrom, A. D. and Abraham, S. S. CLEVR-Math: dataset for compositional language, visual and mathematical reasoning. arXiv preprint arXiv:2208.05358, 2022. Liu, B., Zhan, L.-M., Xu, L., Ma, L., Yang, Y., and Wu, X.- M. SLAKE: semantically-labeled knowledge-enhanced dataset for medical visual question answering. In 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI), pp. 16501654. IEEE, 2021. Liu, S., Cheng, H., Liu, H., Zhang, H., Li, F., Ren, T., Zou, X., Yang, J., Su, H., Zhu, J., et al. Llava-plus: Learning to use tools for creating multimodal agents. arXiv preprint arXiv:2311.05437, 2023. Lu, M. Y., Chen, B., Williamson, D. F., Chen, R. J., Liang, I., Ding, T., Jaume, G., Odintsov, I., Le, L. P., Gerber, G., et al. visual-language foundation model for computational pathology. Nature Medicine, 30:863874, 2024a. Lu, P., Peng, B., Cheng, H., Galley, M., Chang, K.-W., Wu, Y. N., Zhu, S.-C., and Gao, J. Chameleon: Plug-andplay compositional reasoning with large language models. Advances in Neural Information Processing Systems, 35, 2023. 11 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Lu, P., Bansal, H., Xia, T., Liu, J., Li, C., Hajishirzi, H., Cheng, H., Chang, K.-W., Galley, M., and Gao, J. MathVista: Evaluating mathematical reasoning of foundation models in visual contexts. In International Conference on Learning Representations (ICLR), 2024b. Lumer, E. Toolshed: Scale tool-equipped agents with advanced rag-tool fusion and tool knowledge bases. arXiv preprint arXiv:2410.14594, 2024. Mialon, G., Fourrier, C., Swift, C., Wolf, T., LeCun, Y., and Scialom, T. GAIA: benchmark for general ai assistants. arXiv preprint arXiv:2311.12983, 2023. Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021. OpenAI. Function calling - openai. https: //platform.openai.com/docs/guides/ function-calling, 2023a. OpenAI. GPT-4 technical report. arXiv preprint arXiv:2303.08774, 2023b. Paramanayakam, V., Karatzas, A., Anagnostopoulos, I., and Stamoulis, D. Less is more: Optimizing function calling for llm execution on edge devices. arXiv preprint arXiv:2411.15399, 2024. Perez, E., Lewis, P., Yih, W.-t., Cho, K., and Kiela, D. Unsupervised question decomposition for question answering. arXiv preprint arXiv:2002.09758, 2020. Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y., Dirani, J., Michael, J., and Bowman, S. R. GPQA: graduate-level google-proof q&a benchmark. arXiv preprint arXiv:2311.12022, 2023. Ren, T., Chen, Y., Jiang, Q., Zeng, Z., Xiong, Y., Liu, W., Ma, Z., Shen, J., Gao, Y., Jiang, X., Chen, X., Song, Z., Zhang, Y., Huang, H., Gao, H., Liu, S., Zhang, H., Li, F., Yu, K., and Zhang, L. Dino-x: unified vision model for open-world object detection and understanding, 2024. URL https://arxiv.org/abs/2411.14347. Schmidgall, S., Ziaei, R., Harris, C., Reis, E., Jopling, J., and Moor, M. Agentclinic: multimodal agent benchmark to evaluate ai in simulated clinical environments. arXiv preprint arXiv:2405.07960, 2024. Shuster, K., Xu, J., Komeili, M., Ju, D., Smith, E. M., Roller, S., Ung, M., Chen, M., Arora, K., Lane, J., et al. Blenderbot 3: deployed conversational agent that continually learns to responsibly engage. arXiv preprint arXiv:2208.03188, 2022. Sun, S., Liu, Y., Wang, S., Zhu, C., and Iyyer, M. Pearl: Prompting large language models to plan and execute actions over long documents. arXiv preprint arXiv:2305.14564, 2023. Sun, Y., Wu, H., Zhu, C., Zheng, S., Chen, Q., Zhang, K., Zhang, Y., Wan, D., Lan, X., Zheng, M., et al. PathMMU: massive multimodal expert-level benchmark for understanding and reasoning in pathology. In European Conference on Computer Vision, pp. 5673. Springer, 2025. Tao, H., TV, S., Shlapentokh-Rothman, M., Hoiem, D., and Ji, H. Webwise: Web interface control and sequential exploration with large language models. arXiv preprint arXiv:2310.16042, 2023. Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H. S., Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen, D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhao, V., Zhou, Y., Chang, C.-C., Krivokon, I., Rusch, W., Pickett, M., Srinivasan, P., Man, L., Meier-Hellstern, K., Morris, M. R., Doshi, T., Santos, R. D., Duke, T., Soraker, J., Zevenbergen, B., Prabhakaran, V., Diaz, M., Hutchinson, B., Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R., Butryna, A., Lamm, M., Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E., and Le, Q. Lamda: Language models for dialog applications, 2022. URL https://arxiv.org/abs/2201.08239. Roberts, J., Han, K., Houlsby, N., and Albanie, S. SciFIBench: Benchmarking large multimodal models for scientific figure interpretation. arXiv preprint arXiv:2405.08807, 2024. Wang, J., Xu, H., Ye, J., Yan, M., Shen, W., Zhang, J., Huang, F., and Sang, J. Mobile-agent: Autonomous multi-modal mobile device agent with visual perception. arXiv preprint arXiv:2401.16158, 2024a. Schick, T., Dwivedi-Yu, J., Dess`ı, R., Raileanu, R., Lomeli, M., Hambro, E., Zettlemoyer, L., Cancedda, N., and Scialom, T. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36:6853968551, 2023. Wang, Y., Ma, X., Zhang, G., Ni, Y., Chandra, A., Guo, S., Ren, W., Arulraj, A., He, X., Jiang, Z., et al. MMLU-Pro: more robust and challenging multi-task language understanding benchmark. arXiv preprint arXiv:2406.01574, 2024b. 12 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022. Zhang, Y., Chen, J., Wang, J., Liu, Y., Yang, C., Shi, C., Zhu, X., Lin, Z., Wan, H., Yang, Y., et al. Toolbehonest: multi-level hallucination diagnostic benchmark for tool-augmented large language models. arXiv preprint arXiv:2406.20015, 2024. Zhou, D., Scharli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Cui, C., Bousquet, O., Le, Q., et al. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022. 13 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning"
        },
        {
            "title": "A Experimental Details",
            "content": "A.1 Benchmark Datasets . . . . . . A.2 Tools Used in Our Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.3 Additional Tools for Exploration Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "C Configurations in OctoTools",
            "content": "C.1 Query Analyzer . C.2 Action Predictor . . . . . C.3 Command Predictor . C.4 Context Verifier . . . C.5 Solution Summarizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Tool Cards in OctoTools D.1 ArXiv Paper Searcher Tool . . . . . D.2 Generalist Solution Generator Tool . D.3 Google Search Tool . . D.4 Image Captioner Tool . . . . . . . . . D.5 Path Generalist Classifier Tool D.6 Pubmed Search Tool . . . . D.7 Python Code Generator Tool D.8 Relevant Patch Zoomer Tool D.9 Text Detector Tool . . . D.10 URL Text Extractor Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.11 Wikipedia Knowledge Searcher Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Additional Tool Cards in OctoTools E.1 Object Detector Tool . . . . . . E.2 Advanced Object Detector Tool . E.3 Nature News Fetcher Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Experimental Examples F.1 Demonstration Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.2 Example for Multi-step Mathematical Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.3 Example for Agentic Reasoning . F.4 Example for Medical Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 16 16 17 17 24 24 25 26 29 31 31 34 35 37 41 43 45 48 51 55 55 58 60 62 67 71 77 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.5 Example for Pathology Diagnosis . F.6 Example for Scientific Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.7 Example for Fine-grained Visual Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.8 Exploration Example for Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 82 85 88 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning A. Experimental Details A.1. Benchmark Datasets Here, we report further details of each of the 16 benchmark we used in this study. Unless specified otherwise, validation set of 100 examples and test set of 200 examples were sampled from each dataset. No additional preprocessing was performed for open-ended questions. For multiple choice questions, choices were enumerated using capital letters and each concatenated to the question following new line character. Any subsetting of the original datasets are also described below. A.1.1. GENERAL DOMAIN BENCHMARKS AlgoPuzzleVQA (Ghosal et al., 2024) is set of geometric puzzles that require both visual understanding, language understanding, and complex algorithmic reasoning that are difficult for base VLMs. Hallusion-VD is subset of HallusionBench (Guan et al., 2024), benchmark to test visual understanding through optical and geometric illusions. For our experiments we use the Visual Dependent subset of HallusionBench, consisting of questions where the visual context is required to give definitive answer. PuzzleVQA (Chia et al., 2024) is dataset of puzzle instances based on abstract, geometric patterns that test understanding and reasoning based on colors, numbers, sizes, and shapes. VQA 2.0 (Goyal et al., 2017) consists of open-ended questions about images that require fine-grained visual understanding. A.1.2. MATHEMATICAL BENCHMARKS Game of 24 (Lile, 2024) is based on the classic arithmetic game of 24 (also known as 24, the 24 numbers game, etc.). The puzzle involves using four numbers and basic arithmetic operations (addition, subtraction, multiplication, division) to construct an expression that evaluates to 24. For example, given the numbers 4, 9, 10, and 13, one valid solution is (10 - 4) (13 - 9) = 24. Solving the puzzle requires numerical calculation skills as well as multiple attempts to verify proposed solutions. Each puzzle is presented as open-ended questions. Omni-MATH (Gao et al., 2024) is text-only mathematical benchmark consisting of open-ended competition-level problems at the Olympiad level, requiring advanced mathematical knowledge and reasoning. CLEVR-Math (Lindstrom & Abraham, 2022) consists of multimodal math word problems involving addition and subtraction. Each problem contains textual description and an image illustrating the scenario. combination of language, visual, and mathematical reasoning is required to solve these word problems. MathVista (Lu et al., 2024b) is benchmark designed to combine challenges from diverse mathematical and visual tasks. The queries are mix of multiple choice and open-ended questions and require numerical computation, fine-grained visual understanding, and multi-step reasoning. A.1.3. SCIENTIFIC BENCHMARKS GPQA or Graduate Level Google-Proof Q&A Benchmark (Rein et al., 2023) is set of challenging text-only multiple choice questions written by domain experts in biology, physics, and chemistry designed to be extremely difficult. MMLU-Pro (Wang et al., 2024b) is text-only benchmark consisting of challenging, reasoning-focused multiple choice questions that require general scientific knowledge and complex reasoning. SciFIBench (Roberts et al., 2024) is benchmark of multiple choice questions for scientific figure interpretation. Queries involve understanding and extracting information from scientific figures. A.1.4. MEDICAL BENCHMARKS MedQA (Jin et al., 2021) consists of text-only multiple choice questions curated from professional medical board exams. Questions cover general medical and clinical knowledge and reasoning. PathCLS is subset of PathMMU (Sun et al., 2025) that consists of multiple choice questions based on hematoxylin and eosin (H&E)-stained histopathology microscopy images reformulated from well-known pathology classification datasets. These questions generally involve disease diagnosis based on histopathology images. 16 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning PathVQA (He et al., 2020) is visual question-answering dataset curated from pathology-related image-caption pairs sourced from textbooks, spanning multiple tissue types and stains. All questions were treated as open-ended in our evaluation. SLAKE or Semantically-Labeled Knowledge-Enhanced Dataset (Liu et al., 2021) is radiology visual question-answering dataset. The associated images span X-ray images, computed tomography (CT) scans, and magnetic resonance imaging (MRI). All questions were treated as open-ended in our evaluation. Though the authors of the dataset released object detection labels and segmentation masks for each image, these were excluded in our evaluation for the purpose of increasing difficulty. A.1.5. AGENTIC BENCHMARK GAIA-Text (Mialon et al., 2023) is benchmark specifically designed to evaluate general AI assistants and agents, requiring abilities such as multi-step reasoning, web browsing, and generally tool-use proficiency. The questions are designed to be difficult for base LLMs. We use the text-only subset of this dataset in our experiments. A.2. Tools Used in Our Experiments We implemented 11 tools in the toolbox for our experiments. Here, we provide detailed descriptions of each tool. See for the complete tool cards of each tool and usage examples. Arxiv Paper Searcher (D.1) searches arXiv1, an open-access pre-print repository, for abstracts and links that match given query. Generalist Solution Generator (D.2) is an instance of the OctoTools base LLM and acts as the default reasoning engine if the agent decides not to use an external tool. Google Search (D.3) uses the Google custom search API2 to search the web and return links and summary of each result. Image Captioner (D.4) is an instance of the base LLM prompted for generating text descriptions of input images. Path Generalist Classifier (D.5) is tool for performing general classification of H&E-stained pathology microscopy images. The tool relies on CONCH (Lu et al., 2024a), pretrained vision-language foundation model for pathology, for performing zero-shot classification of pathology image patches. Pubmed Search (D.6) retrieves relevant article abstracts from PubMed based on text query. The retrieval is performed using the PubMed and NCBI APIs3. Python Code Generator (D.7) generates and executes Python code given query and returns the execution result. The code generation is performed by an instance of the base LLM prompted for Python code generation. Relevant Patch Zoomer (D.8) is an instance of the base LLM that, given query, decides which regions of the image to zoom into (among the four quadrants and the center patch) and saves the zoomed patches. Text Detector (D.9) detects multilingual text within an image by calling the EasyOCR tool for text detection4. URL Text Extractor (D.10) visits web pages given the URL and returns the text content of the page. Wikipedia Knowledge Searcher (D.11) searches Wikipedia using the MediaWiki API5 and returns articles matching given query. A.3. Additional Tools for Exploration Study We also provide several additional tools for exploration, as follows: Object Detector (E.1) performs object detection on an image given list of object labels to detect, using the Grounding 1https://arxiv.org/ 2https://developers.google.com/custom-search/v1/introduction 3https://www.ncbi.nlm.nih.gov/books/NBK25501/ 4https://github.com/JaidedAI/EasyOCR 5https://www.mediawiki.org/wiki/API 17 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning DINO model (Caron et al., 2021). Due to the standardized design of tool cards, this tool can be upgraded to the Advanced Object Detector (E.2), which uses DINO-X (Ren et al., 2024), more recent version powered by API calls.6 Nature News Fetcher (E.3) retrieves the latest news articles from the science journal Nature.7 An example in F.8 demonstrates how this tool can be used to obtain the latest research trends for given topic. B. Experimental Results Optimized tool sets. Table 3 shows the optimized tool sets across 16 tasks from Algorithm 1. The toolset optimization method in OctoTools is able to find diverse optimal tool sets for different tasks. In general, the Image Captioner and Relevant Patch Zoomer tools are very commonly used in vision benchmarks, with the former being used in all vision benchmarks and the latter being used in 6 out of the 10. The Python Code Generator is represented in 3 out of the 4 mathematical domain benchmarks. The Wikipedia Knowledge Searcher is represented in all the scientific domain benchmarks. We also see that highly domain-specific tools are represented in their corresponding use cases, such as Pubmed Search in general medical benchmark (Jin et al., 2021) and Path Generalist Classifier in pathology classification benchmark (Sun et al., 2025). t n o l s r G Benchmarks Modality Domain AlgoPuzzleVQA Hallusion-VD PuzzleVQA VQA 2.0 Game of 24 Omni-MATH CLEVR-Math MathVista GPQA MMLU-Pro SciFIBench MedQA PathCLS PathVQA SLAKE GAIA-Text Vision Vision Vision Vision Text Text Vision Vision Text Text Vision Text Vision Vision Vision Text General General General General Mathematical Mathematical Mathematical Mathematical Scientific Scientific Scientific Medical Medical Medical Medical Agentic h e d o i i r e t o r t L c S g o e e n y c S a X e s C l n t h e m e Z a t e e t e I Table 3. Optimized tool sets for each benchmark following our Algorithm1. indicates that the tool is used for that benchmark. Steps taken for different tasks. Figure 17 shows the distribution of the number of steps taken. OctoTools is able to adapt to each task by applying different sets of tools and constructing chains of reasoning as needed. 6https://github.com/IDEA-Research/DINO-X-API 7https://www.nature.com/latest-news 18 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Figure 10. Performance ours vs. other agents. Our framework consistently outperforms agent baselines across all benchmarks. Bar values represent accuracy and error bars represent standard deviation. Figure 11. Performance with vs. without tool selection. While toolset optimization increases performance over using the full toolset in most tasks, even without it, our framework achieves similar performance by naively enabling all possible tools. Bar values represent accuracy and error bars represent standard deviation. Figure 12. Performance on weaker LLM (GPT-4o-mini). We observe similar trends using OctoTools with weaker base LLM. Bar values represent accuracy and error bars represent standard deviation. 19 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Figure 13. Distribution of tools usage. Frequency of tools used by the AutoGen agent for each benchmark. Figure 14. Distribution of tools usage. Frequency of tools used by the GPT-Functions agent for each benchmark. 20 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Figure 15. Distribution of tools usage. Frequency of tools used by the LangChain agent for each benchmark. Figure 16. Performance gains across different benchmarks from our OctoTools framework over the base GPT-4o model. 21 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Figure 17. Distribution of number of steps used. OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Figure 18. Accuracy vs number of maximum steps. The change in accuracy from maximum step of 1 is plotted. Most benchmarks improve in performance with the number of allowed steps. 23 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning C. Configurations in OctoTools C.1. Query Analyzer"
        },
        {
            "title": "Prompt for Query Analyzer",
            "content": "Task: Analyze the given query with accompanying inputs and determine the skills and tools needed to address it effectively. Available tools: {self.available tools} Metadata for the tools: {self.toolbox metadata} Image: {image info} Query: {question} Instructions: 1. Carefully read and understand the query and any accompanying inputs. 2. Identify the main objectives or tasks within the query. 3. List the specific skills that would be necessary to address the query comprehensively. 4. Examine the available tools in the toolbox and determine which ones might relevant and useful for addressing the query. Make sure to consider the user metadata for each tool, including limitations and potential applications (if available). 5. Provide brief explanation for each skill and tool youve identified, describing how it would contribute to answering the query. Your response should include: 1. concise summary of the querys main points and objectives, as well as content in any accompanying inputs. 2. list of required skills, with brief explanation for each. 3. list of relevant tools from the toolbox, with brief explanation of how each tool would be utilized and its potential limitations. 4. Any additional considerations that might be important for addressing the query effectively. Please present your analysis in clear, structured format. 24 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning C.2. Action Predictor"
        },
        {
            "title": "Prompt for Action Predictor",
            "content": "Task: Determine the optimal next step to address the given query based on the provided analysis, available tools, and previous steps taken. Query: {question} Image: {image} Query Analysis: {query analysis} Available Tools: {self.available tools} Tool Metadata: {self.toolbox metadata} Previous Steps and Their Results: {memory.get actions()} Current Step: {step count} in {max step count} steps Remaining Steps: {max step count - step count} Instructions: 1. Analyze the context thoroughly, including the query, its analysis, any image, available tools and their metadata, and previous steps taken. 2. Determine the most appropriate next step by considering: - Key objectives from the query analysis - Capabilities of available tools - Logical progression of problem-solving - Outcomes from previous steps - Current step count and remaining steps 3. Select ONE tool best suited for the next step, keeping in mind the limited number of remaining steps. 4. Formulate specific, achievable sub-goal for the selected tool that maximizes progress towards answering the query. Output Format: <justification>: detailed explanation of why the selected tool is the best choice for the next step, considering the context and previous outcomes. <context>: MUST include ALL necessary information for the tool to function, structured as follows: * Relevant data from previous steps * File names or paths created or used in previous steps (list EACH ONE individually) * Variable names and their values from previous steps results * Any other context-specific information required by the tool <sub goal>: specific, achievable objective for the tool, based on its metadata and previous outcomes. It MUST contain any involved data, file names, and variables from Previous Steps and Their Results that the tool can act upon. <tool name>: MUST be the exact name of tool from the available tools list. Rules: - Select only ONE tool for this step. - The sub-goal MUST directly address the query and be achievable by the selected tool. - The Context section MUST include ALL necessary information for the tool to function, including ALL relevant file paths, data, and variables from previous steps. - The tool name MUST exactly match one from the available tools list: {self.available tools}. - Avoid redundancy by considering previous steps and building on prior results. Example (do not copy, use only as reference): <justification>: [Your detailed explanation here] <context>: Image path: \"example/image.jpg\", Previous detection results: [list of objects] <sub goal>: Detect and count the number of specific objects in the image \"example/image.jpg\" <tool name>: Object Detector Tool 25 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning C.3. Command Predictor"
        },
        {
            "title": "Prompt for Command Predictor",
            "content": "Task: Generate precise command to execute the selected tool based on the given information. Query: {question} Image: {image} Context: {context} Sub-Goal: {sub goal} Selected Tool: {tool name} Tool Metadata: {tool metadata} Instructions: Instructions: 1. Carefully review all provided information: the query, image path, context, sub-goal, selected tool, and tool metadata. 2. Analyze the tools input types from the metadata to understand required and optional parameters. 3. Construct command or series of commands that aligns with the tools usage pattern and addresses the sub-goal. 4. Ensure all required parameters are included and properly formatted. 5. Use appropriate values for parameters based on the given context, particularly the Context field which may contain relevant information from previous steps. 6. If multiple steps are needed to prepare data for the tool, include them in the command construction. Output Format: <analysis>: step-by-step analysis of the context, sub-goal, and selected tool to guide the command construction. <explanation>: detailed explanation of the constructed command(s) and their parameters. <command>: the Python code to execute the tool, which can be one of the following types: a. single line command with execution = tool.execute(). b. multi-line command with complex data preparation, ending with execution = tool.execute(). c. Multiple lines of execution = tool.execute() calls for processing multiple items. python <your command here> Rules: 1. The command MUST be valid Python code and include at least one call to tool.execute(). 2. Each tool.execute() call MUST be assigned to the execution variable in the format execution = tool.execute(...). 3. For multiple executions, use separate execution = tool.execute() calls for each execution. 4. The final output MUST be assigned to the execution variable, either directly from tool.execute() or as processed form of multiple executions. 5. Use the exact parameter names as specified in the tools input types. 6. Enclose string values in quotes, use appropriate data types for other values (e.g., lists, numbers). 7. Do not include any code or text that is not part of the actual command. 8. Ensure the command directly addresses the sub-goal and query. 9. Include ALL required parameters, data, and paths to execute the tool in the command itself. 10. If preparation steps are needed, include them as separate Python statements before the tool.execute() calls. 26 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Prompt for Command Prediction (Continued) Examples (Not to use directly unless relevant): Example 1 (Single line command): <analysis>: The tool requires an image path and list of labels for object detection. <explanation>: We pass the image path and list containing baseball as the label to detect. <command>: python execution = tool.execute(image=\"path/to/image\", labels=[\"baseball\"]) Example 2 (Multi-line command with data preparation): <analysis>: The tool requires an image path, multiple labels, and threshold for object detection. <explanation>: We prepare the data by defining variables for the image path, labels, and threshold, then pass these to the tool.execute() function. <command>: python image = \"path/to/image\" labels = [\"baseball\", \"football\", \"basketball\"] threshold = 0.5 execution = tool.execute(image=image, labels=labels, threshold=threshold) Example 3 (Multiple executions): <analysis>: We need to process multiple images for baseball detection. <explanation>: We call the tool for each image path, using the same label and threshold for all. <command>: python execution = tool.execute(image=\"path/to/image1\", labels=[\"baseball\"], threshold=0.5) execution = tool.execute(image=\"path/to/image2\", labels=[\"baseball\"], threshold=0.5) execution = tool.execute(image=\"path/to/image3\", labels=[\"baseball\"], threshold=0.5) 27 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Prompt for Command Predictor (Continued) Some Wrong Examples: <command>: python execution1 = tool.execute(query=\"...\") execution2 = tool.execute(query=\"...\") Reason: only execution = tool.execute is allowed, not execution1 or execution2. <command>: python urls = [ \"https://example.com/article1\", \"https://example.com/article2\" ] execution = tool.execute(url=urls[0]) execution = tool.execute(url=urls[1]) Reason: The command should process multiple items in single execution, not separate executions for each item. Remember: Your <command> field MUST be valid Python code including any necessary data preparation steps and one or more execution = tool.execute() calls, without any additional explanatory text. The format execution = tool.execute must be strictly followed, and the last line must begin with execution = tool.execute to capture the final output. 28 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning C.4. Context Verifier"
        },
        {
            "title": "Prompt for Verifier",
            "content": "Task: Thoroughly evaluate the completeness and accuracy of the memory for fulfilling the given query, considering the potential need for additional tool usage. Query: {question} Image: {image info} Available Tools: {self.available tools} Toolbox Metadata: {self.toolbox metadata} Initial Analysis: {query analysis} Memory (tools used and results): {memory.get actions()} Detailed Instructions: 1. Carefully analyze the query, initial analysis, and image (if provided): - Identify the main objectives of the query. - Note any specific requirements or constraints mentioned. - If an image is provided, consider its relevance and what information it contributes. 2. Review the available tools and their metadata: - Understand the capabilities and limitations and best practices of each tool. - Consider how each tool might be applicable to the query. 3. Examine the memory content in detail: - Review each tool used and its execution results. - Assess how well each tools output contributes to answering the query. 4. Critical Evaluation (address each point explicitly): a) Completeness: Does the memory fully address all aspects of the query? - Identify any parts of the query that remain unanswered. - Consider if all relevant information has been extracted from the image (if applicable). b) Unused Tools: Are there any unused tools that could provide additional relevant information? - Specify which unused tools might be helpful and why. c) Inconsistencies: Are there any contradictions or conflicts in the information provided? - If yes, explain the inconsistencies and suggest how they might be resolved. d) Verification Needs: Is there any information that requires further verification due to tool limitations? - Identify specific pieces of information that need verification and explain why. e) Ambiguities: Are there any unclear or ambiguous results that could be clarified by using another tool? - Point out specific ambiguities and suggest which tools could help clarify them. 5. Final Determination: Based on your thorough analysis, decide if the memory is complete and accurate enough to generate the final output, or if additional tool usage is necessary. Response Format: <analysis>: Provide detailed analysis of why the memory is sufficient. Reference specific information from the memory and explain its relevance to each aspect of the task. Address how each main point of the query has been satisfied. <stop signal>: Whether to stop the problem solving process and proceed to generating the final output. * \"True\": if the memory is sufficient for addressing the query to proceed and no additional available tools need to be used. If ONLY manual verification without tools is needed, choose \"True\". * \"False\": if the memory is insufficient and needs more information from additional tool usage. 29 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning C.5. Solution Summarizer"
        },
        {
            "title": "Prompt for Solution Summarizer",
            "content": "Task: Generate the final output based on the query, image, and tools used in the process. Query: {question} Image: {image info} Actions Taken: {memory.get actions()} Instructions: 1. Review the query, image, and all actions taken during the process. 2. Consider the results obtained from each tool execution. 3. Incorporate the relevant information from the memory to generate the step-by-step final output. 4. The final output should be consistent and coherent using the results from the tools. Output Structure: Your response should be well-organized and include the following sections: 1. Summary: - Provide brief overview of the query and the main findings. 2. Detailed Analysis: - Break down the process of answering the query step-by-step. - For each step, mention the tool used, its purpose, and the key results obtained. - Explain how each step contributed to addressing the query. 3. Key Findings: - List the most important discoveries or insights gained from the analysis. - Highlight any unexpected or particularly interesting results. 4. Answer to the Query: - Directly address the original question with clear and concise answer. - If the query has multiple parts, ensure each part is answered separately. 5. Additional Insights (if applicable): - Provide any relevant information or insights that go beyond the direct answer to the query. - Discuss any limitations or areas of uncertainty in the analysis. 6. Conclusion: - Summarize the main points and reinforce the answer to the query. - If appropriate, suggest potential next steps or areas for further investigation. 30 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D. Tool Cards in OctoTools D.1. ArXiv Paper Searcher Tool ArXiv Paper Searcher Tool: Metadata tool_name=\"ArXiv_Paper_Searcher_Tool\", tool_description=\"A tool that searches arXiv for papers based on given query.\", input_types={ \"query\": \"str - The search query for arXiv papers.\", \"size\": \"int - The number of results per page (25, 50, 100, or 200). If None, use 25.\", \"max_results\": \"int - The maximum number of papers to return (default: 25). Should be less than or equal to 100.\" }, output_type=\"list - list of dictionaries containing paper information.\", demo_commands=[ { }, { }, { \"command\": execution = tool.execute(query=\"tool agents with large language models\"), \"description\": \"Search for papers about tool agents with large language models.\" \"command\": execution = tool.execute(query=\"quantum computing\", size=100, max_results=50), \"description\": \"Search for quantum computing papers, with 100 results per page, returning maximum of 50 papers.\" \"command\": execution = tool.execute(query=\"machine learning\", max_results=75), \"description\": \"Search for machine learning papers, returning maximum of 75 papers.\" }, ], user_metadata={ \"valid_sizes\": [25, 50, 100, 200], \"base_url\": \"https://arxiv.org/search/\" } OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning ArXiv Paper Searcher Tool: Example 1 Input (query): enhance mathematical reasoning with large language models Output (article 1, search date: Jan 14, 2025): Title: Enhancing Reasoning through Process Supervision with Monte Carlo Tree Search Authors: Shuangtao Li, Shuaihao Dong, Kexin Luan, Xinhan Di, Chaofan Ding Abstract: Large language models (LLMs) have demonstrated their remarkable capacity across variety of tasks. ... Furthermore, models trained on one dataset also exhibit improved performance on the other, showing the transferability of the enhanced reasoning ability. Link: https://arxiv.org/abs/2501.01478 Output (article 2, search date: Jan 14, 2025): Title: Open Eyes, Then Reason: Fine-grained Visual Mathematical Understanding in MLLMs Authors: Shan Zhang, Aotian Chen, Yanpeng Sun, Jindong Gu, Yi-Yu Zheng, Piotr Koniusz, Kai Zou, Anton van den Hengel, Yuan Xue Abstract: Current multimodal large language models (MLLMs) often underperform on mathematical problem-solving tasks that require fine-grained visual understanding. ... Our findings emphasize the importance of incorporating fine-grained visual understanding into MLLMs and provide promising direction for future research. Link: https://arxiv.org/abs/2501.06430 Output (structured result): [ { \"title\": \"Enhancing Reasoning through Process Supervision with Monte Carlo Tree Search\", \"authors\": \"Shuangtao Li, Shuaihao Dong, Kexin Luan, Xinhan Di, Chaofan Ding\", \"abstract\": \"Large language models (LLMs) have demonstrated their remarkable capacity across variety of tasks. ... Furthermore, models trained on one dataset also exhibit improved performance on the other, showing the transferability of the enhanced reasoning ability.\", \"link\": \"https://arxiv.org/abs/2501.01478\" \"title\": \"Open Eyes, Then Reason: Fine-grained Visual Mathematical Understanding in MLLMs\", \"authors\": \"Shan Zhang, Aotian Chen, Yanpeng Sun, Jindong Gu, Yi-Yu Zheng, Piotr Koniusz, Kai Zou, Anton van den Hengel, Yuan Xue\", \"abstract\": \"Current multimodal large language models (MLLMs) often underperform on mathematical problem-solving tasks that require fine-grained visual understanding. ... Our findings emphasize the importance of incorporating fine-grained visual understanding into MLLMs and provide promising direction for future research.\", \"link\": \"https://arxiv.org/abs/2501.06430\" }, { } ] 32 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning ArXiv Paper Searcher Tool: Example 2 Input (query): automated scientific discovery Output (article 1, search date: Jan 14, 2025): Title: BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discover Authors: Kanishk Gandhi, Michael Y. Li, Lyle Goodyear, Louise Li, Aditi Bhaskar, Mohammed Zaman, Noah D. Goodman Abstract: Understanding the world and explaining it with scientific theories is central aspiration of artificial intelligence research. Proposing theories, designing experiments to test them, and then revising them based on data are fundamental to scientific discovery. ... We find that augmenting the LLM-based agent with an explicit statistical model does not reliably improve these results. Link: https://arxiv.org/abs/2501. Output (article 2, search date: Jan 14, 2025): Title: Automating the Search for Artificial Life with Foundation Models Authors: Akarsh Kumar, Chris Lu, Louis Kirsch, Yujin Tang, Kenneth O. Stanley, Phillip Isola, David Ha Abstract: With the recent Nobel Prize awarded for radical advances in protein discovery, foundation models (FMs) for exploring large combinatorial spaces promise to revolutionize many scientific fields. ... This new paradigm promises to accelerate ALife research beyond what is possible through human ingenuity alone. Link: https://arxiv.org/abs/2412.17799 Output (structured result): [ { \"title\": \"BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery\", \"authors\": \"Kanishk Gandhi, Michael Y. Li, Lyle Goodyear, Louise Li, Aditi Bhaskar, Mohammed Zaman, Noah D. Goodman\", \"abstract\": \"Understanding the world and explaining it with scientific theories is central aspiration of artificial intelligence research. ... We find that augmenting the LLM-based agent with an explicit statistical model does not reliably improve these results.\", \"link\": \"https://arxiv.org/abs/2501.01540\" \"title\": \"Automating the Search for Artificial Life with Foundation Models\", \"authors\": \"Akarsh Kumar, Chris Lu, Louis Kirsch, Yujin Tang, Kenneth O. Stanley , Phillip Isola, David Ha\", \"abstract\": \"With the recent Nobel Prize awarded for radical advances in protein discovery, foundation models (FMs) for exploring large combinatorial spaces promise to revolutionize many scientific fields. ... This new paradigm promises to accelerate ALife research beyond what is possible through human ingenuity alone.\", \"link\": \"https://arxiv.org/abs/2412.17799\" }, { } ] 33 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.2. Generalist Solution Generator Tool Generalist Solution Generator Tool: Metadata tool_name=\"Generalist_Solution_Generator_Tool\", tool_description=\"A generalized tool that takes query from the user as prompt, and answers the question step by step to the best of its ability. It can also accept an image.\", input_types={ \"prompt\": \"str - The prompt that includes query from the user to guide the agent to generate response (Examples: Describe this image in detail).\", \"image\": \"str - The path to the image file if applicable (default: None).\", }, output_type=\"str - The generated response to the original query prompt\", demo_commands=[ { }, { }, { }, { \"command\": execution = tool.execute(prompt=\"Summarize the following text in few lines\"), \"description\": \"Generate short summary given the prompt from the user.\" \"command\": execution = tool.execute(prompt=\"Explain the mood of this scene.\", image=\"path/to/image1.png\"), \"description\": \"Generate caption focusing on the mood using specific prompt and image.\" \"command\": execution = tool.execute(prompt=\"Give your best coordinate estimate for the pacemaker in the image and return (x1, y1, x2, y2)\", image=\"path/to/ image2.png\"), \"description\": \"Generate bounding box coordinates given the image and prompt from the user. The format should be (x1, y1, x2, y2).\" \"command\": execution = tool.execute(prompt=\"Is the number of tiny objects that are behind the small metal jet less than the number of tiny things left of the tiny sedan?\", image=\"path/to/image2.png\"), \"description\": \"Answer question step by step given the image.\" } ], user_metadata = { \"limitation\": \"The Generalist_Solution_Generator_Tool may provide hallucinated or incorrect responses.\", \"best_practice\": \"Use the Generalist_Solution_Generator_Tool for general queries or tasks that dont require specialized knowledge or specific tools in the toolbox. For optimal results:nn\" \"1) Provide clear, specific prompts.n\" \"2) Use it to answer the original query through step by step reasoning for tasks without complex or multi-step reasoning.n\" \"3) For complex queries, break them down into subtasks and use the tool multiple times.n\" \"4) Use it as starting point for complex tasks, then refine with specialized tools .n\" \"5) Verify important information from its responses.n\" \"6) For image-related tasks, ensure the image path is correct and the prompt is relevant to the image content.\" } 34 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Generalist Solution Generator Tool: Example 1 Input (query): Describe the image in detail. Input (image): \"baseballs.png\" Output (response): The image shows four blue buckets, each containing five baseballs. The baseballs are white with red stitching, and the buckets have handles on the sides. The arrangement of the baseballs within each bucket is slightly different, but each bucket consistently holds five baseballs. The background is plain, emphasizing the buckets and their contents. Output (structured result): { } \"The image shows four blue buckets, each containing five baseballs. The baseballs are white with red stitching, and the buckets have handles on the sides. The arrangement of the baseballs within each bucket is slightly different, but each bucket consistently holds five baseballs. The background is plain, emphasizing the buckets and their contents.\" D.3. Google Search Tool Google Search Tool: Metadata tool_name=\"Google_Search_Tool\", tool_description=\"A tool that performs Google searches based on given text query.\", input_types={ \"query\": \"str - The search query to be used for the Google search.\", \"num_results\": \"int - The number of search results to return (default: 10).\", }, output_type=\"list - list of dictionaries containing search result information.\", demo_commands=[ { }, { }, ] \"command\": execution = tool.execute(query=\"Python programming\"), \"description\": \"Perform Google search for Python programming and return the default number of results.\" \"command\": execution = tool.execute(query=\"Machine learning tutorials\", num_results=5), \"description\": \"Perform Google search for Machine learning tutorials and return 5 results.\" OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Google Search Tool: Example 1 Input (query): nobel prize winners in chemistry 2024 Output (result 1, search date: Jan 14, 2025): Title: Nobel Prize in Chemistry Laureates URL: https://www.nobelprize.org/prizes/chemistry/ Snippet: The Nobel Prize in Chemistry 2024 was awarded with one half to David Baker for computational protein design and the other half jointly to Demis Hassabis and ... Output (result 2, search date: Jan 14, 2025): Title: NSF congratulates laureates of the 2024 Nobel Prize in chemistry ... URL: https://new.nsf.gov/news/nsf-congratulates-laureates-2024-nobel-prize-chemistry Snippet: Oct 9, 2024 ... The U.S. National Science Foundation congratulates David Baker, Demis Hassabis and John Jumper on being awarded the 2024 Nobel Prize in ... Output (result 3, search date: Jan 14, 2025): Title: Press release: The Nobel Prize in Chemistry 2024 - NobelPrize.org URL: https://www.nobelprize.org/prizes/chemistry/2024/press-release/ Snippet: Oct 9, 2024 ... David Baker has succeeded with the almost impossible feat of building entirely new kinds of proteins. Demis Hassabis and John Jumper have ... Output (structured result): [ { \"title\": \"Nobel Prize in Chemistry Laureates\", \"url\": \"https://www.nobelprize.org/prizes/chemistry/\", \"snippet\": \"The Nobel Prize in Chemistry 2024 was awarded with one half to David Baker for computational protein design and the other half jointly to Demis Hassabis and ...\" \"title\": \"NSF congratulates laureates of the 2024 Nobel Prize in chemistry ...\", \"url\": \"https://new.nsf.gov/news/nsf-congratulates-laureates-2024-nobel-prizechemistry\", \"snippet\": \"Oct 9, 2024 ... The U.S. National Science Foundation congratulates David Baker, Demis Hassabis and John Jumper on being awarded the 2024 Nobel Prize in ...\" \"title\": \"Press release: The Nobel Prize in Chemistry 2024 - NobelPrize.org\", \"url\": \"https://www.nobelprize.org/prizes/chemistry/2024/press-release/\", \"snippet\": \"Oct 9, 2024 ... David Baker has succeeded with the almost impossible feat of building entirely new kinds of proteins. Demis Hassabis and John }, { }, { Jumper have ...\" } ] 36 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.4. Image Captioner Tool Image Captioner Tool: Metadata tool_name=\"Image_Captioner_Tool\", tool_description=\"A tool that generates captions for images using OpenAIs multimodal model.\", input_types={ \"image\": \"str - The path to the image file.\", \"prompt\": \"str - The prompt to guide the image captioning (default: Describe this image in detail.).\", }, output_type=\"str - The generated caption for the image.\", demo_commands=[ { }, { } ], \"command\": execution = tool.execute(image=\"path/to/image.png\"), \"description\": \"Generate caption for an image using the default prompt and model.\" \"command\": execution = tool.execute(image=\"path/to/image.png\", prompt=\"Explain the mood of this scene.\"), \"description\": \"Generate caption focusing on the mood using specific prompt and model.\" user_metadata = { \"limitation\": \"The Image_Captioner_Tool provides general image descriptions but has limitations: 1) May make mistakes in complex scenes, counting, attribute detection, and understanding object relationships. 2) Might not generate comprehensive captions, especially for images with multiple objects or abstract concepts. 3) Performance varies with image complexity. 4) Struggles with culturally specific or domain-specific content. 5) May overlook details or misinterpret object relationships. For precise descriptions, consider: using it with other tools for context/verification, as an initial step before refinement, or in multi-step processes for ambiguity resolution. Verify critical information with specialized tools or human expertise when necessary.\" } 37 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Image Captioner Tool: Example 1 Input (image): \"baseballs.png\" Output (caption): The image shows four blue buckets, each containing five baseballs. The buckets are arranged in grid pattern with two on the top row and two on the bottom row. Each bucket has handle on the side, and the baseballs inside are white with red stitching, typical of standard baseballs. The background is plain white, emphasizing the buckets and their contents. Output (structured result): { } \"The image shows four blue buckets, each containing five baseballs. The buckets are arranged in grid pattern with two on the top row and two on the bottom row. Each bucket has handle on the side, and the baseballs inside are white with red stitching, typical of standard baseballs. The background is plain white, emphasizing the buckets and their contents.\" OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.5. Path Generalist Classifier Tool Path Generalist Classifier Tool: Metadata tool_name=\"Path_Generalist_Classifier_Tool\", tool_description=\"A tool for answering multiple choice questions about H&E microscopy images. Do NOT use for open-ended questions. Do NOT use for images that are not H&E -stained.\", input_types={ \"image\": \"str - The path to the histopathology image.\", \"options\": \"list[str] - list of options to classify the image against.\" }, output_type=\"str - The classification result.\", demo_commands=[ { }, { \"command\": execution = tool.execute(image=\"path/to/image.jpg\", options=[\"lung adenocarcinoma\", \"lung squamous cell carcinoma\"]), \"description\": \"Classify the image into one of the given options.\" \"command\": execution = tool.execute(image=\"path/to/image.png\", options=[\"debris\" \"cancer-associated stroma\", \"adipose\", \"normal colon mucosa\", \"colorectal adenocarcinoma epithelium\", \"none of the above\"]), \"description\": \"Classify the image into one of the given options.\" } ], user_metadata={ \"limitations\": \"This tool is designed for answering classification questions about &E-stained microscopy images. This tool is not suitable for open ended questions. Do NOT use this tool if the input is natural image, medical image of other domains (such as IHC, CT, MRI, or X-ray images), or raw whole slide image (i.e ., svs, ndpi, czi, etc). This tool is not always reliable and the result should be cross-referenced by other tools or your own knowledge.\", \"best_practice\": \"Provide clear and specific options for classification. This tool is ideal for classification tasks where the options are well-defined and specific to histopathology (H&E) images.\" } 39 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Path Generalist Classifier Tool: Example 1 Input (query): [\"Non-tumor\", \"Necrotic tumor\", \"Viable tumor\"] Input (image): \"tissue.png\" Output (type): Viable tumor Output (structured result): { } \"result\": \"Viable tumor\" OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.6. Pubmed Search Tool Pubmed Search Tool: Metadata tool_name=\"Pubmed_Search_Tool\", tool_description=\"A tool that searches PubMed Central to retrieve relevant article abstracts based on given list of text queries. Use this ONLY if you cannot use the other more specific ontology tools.\", input_types={ \"queries\": \"list[str] - list of queries terms for searching PubMed.\" }, output_type=\"list - List of items matching the search query. Each item consists of the title, abstract, keywords, and URL of the article. If no results found, string message is returned.\", demo_commands=[ { }, { \"command\": execution = tool.execute(queries=[\"scoliosis\", \"injury\"]), \"description\": \"Search for PubMed articles mentioning scoliosis OR injury.\" \"command\": execution = tool.execute(queries=[\"COVID\", \"vaccine\", \"occupational health\"]), \"description\": \"Search for PubMed articles mentioning COVID OR vaccine OR occupational health.\" } ], user_metadata={ \"limitations\": \"Try to use shorter and more general search queries.\" } 41 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Pubmed Search Tool: Example 1 Input (query): COVID occupational health Output (result 1): Title: COVID-19 workplace countermeasures that occupational physicians... Abstract: BACKGROUND: During the COVID-19 pandemic, information and circumstances changed from moment to moment... Keywords: COVID-19, Japan, Occupational health,... URL: https://ncbi.nlm.nih.gov/pubmed/39780108 Output (result 2): Title: Rapid COVID-19 Testing of Symptomatic Health Care Personnel... Abstract: Determine performance characteristics and safety outcomes of two rapid COVID-19 screening methods ... Keywords: URL: https://ncbi.nlm.nih.gov/pubmed/39739739 Output (result 3): Title: Satisfaction and Workload as Predictors of Psychological Distress in Professionals of Psychosocial Care Centers During the COVID-19 Pandemic. Abstract: BACKGROUND AND AIMS: The COVID-19 pandemic significantly impacted the mental health of healthcare professionals... Keywords: COVID-19, health personnel, job satisfaction,... URL: https://ncbi.nlm.nih.gov/pubmed/39728651 Output (structured result): [ { \"title\": \"COVID-19 workplace countermeasures that occupational physicians...\", \"abstract\": \"BACKGROUND: During the COVID-19 pandemic, information and circumstances changed from moment to moment...\", \"keywords\": [\"COVID-19\", \"Japan\", \"Occupational health\", ...], \"url\": \"https://ncbi.nlm.nih.gov/pubmed/39780108\" \"title\": \"Rapid COVID-19 Testing of Symptomatic Health Care Personnel...\", \"abstract\": \"Determine performance characteristics and safety outcomes of two rapid COVID-19 screening methods...\", \"keywords\": [], \"url\": \"https://ncbi.nlm.nih.gov/pubmed/39739739\" \"title\": \"Satisfaction and Workload as Predictors of Psychological Distress in Professionals of Psychosocial Care Centers During the COVID-19 Pandemic.\", \"abstract\": \"BACKGROUND AND AIMS: The COVID-19 pandemic significantly impacted the mental health of healthcare professionals...\", \"keywords\": [\"COVID-19\", \"health personnel\", \"job satisfaction\", ...], \"url\": \"https://ncbi.nlm.nih.gov/pubmed/39728651\" }, { }, { } ] 42 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.7. Python Code Generator Tool Python Code Generator Tool: Metadata tool_name=\"Python_Code_Generator_Tool\", tool_description=\"A tool that generates and executes simple Python code snippets for basic arithmetical calculations and math-related problems. The generated code runs in highly restricted environment with only basic mathematical operations available.\", input_types={ \"query\": \"str - clear, specific description of the arithmetic calculation or math problem to be solved, including any necessary numerical inputs.\"}, output_type=\"dict - dictionary containing the generated code, calculation result, and any error messages.\", demo_commands=[ { }, { }, { }, ], \"command\": execution = tool.execute(query=\"Calculate the factorial of 5\"), \"description\": \"Generate Python code snippet to calculate the factorial of 5.\" \"command\": execution = tool.execute(query=\"Find the sum of prime numbers up to 50\"), \"description\": \"Generate Python code snippet to find the sum of prime numbers up to 50.\" \"command\": query=\"Given the list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], calculate the sum of squares of odd numbers\"nexecution = tool.execute(query=query), \"description\": \"Generate Python function for specific mathematical operation on given list of numbers.\" 43 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Python Code Generator Tool: Metadata (Continued) user_metadata = { \"limitations\": [ \"Restricted to basic Python arithmetic operations and built-in mathematical functions.\", \"Cannot use any external libraries or modules, including those in the Python standard library.\", \"Limited to simple mathematical calculations and problems.\", \"Cannot perform any string processing, data structure manipulation, or complex algorithms.\", \"No access to any system resources, file operations, or network requests.\", \"Cannot use import statements.\", \"All calculations must be self-contained within single function or script.\", \"Input must be provided directly in the query string.\", \"Output is limited to numerical results or simple lists/tuples of numbers.\" ], \"best_practices\": [ \"Provide clear and specific queries that describe the desired mathematical calculation.\", \"Include all necessary numerical inputs directly in the query string.\", \"Keep tasks focused on basic arithmetic, algebraic calculations, or simple mathematical algorithms.\", \"Ensure all required numerical data is included in the query.\", \"Verify that the query only involves mathematical operations and does not require any data processing or complex algorithms.\", \"Review generated code to ensure it only uses basic Python arithmetic operations and built-in math functions.\" ] } Python Code Generator Tool: Example 1 Input (query): Given the number list: [1, 2, 3, 4, 5], calculate the sum of all the numbers in the list. Output (code): numbers = [1, 2, 3, 4, 5] result = sum(numbers) print(fThe sum is: {result}) Output (structured result): { } \"generated_code\": \"\"\" numbers = [1, 2, 3, 4, 5] result = sum(numbers) print(fThe sum is: {result}) \"\"\", \"execution_result\": \"The sum is: 15\", \"error\": None OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.8. Relevant Patch Zoomer Tool Relevant Patch Zoomer Tool: Metadata tool_name=\"Relevant_Patch_Zoomer_Tool\", tool_description=\"A tool that analyzes an image, divides it into 5 regions (4 quarters + center), and identifies the most relevant patches based on question. The returned patches are zoomed in by factor of 2.\", input_types={ \"image\": \"str - The path to the image file.\", \"question\": \"str - The question about the image content.\", }, output_type=\"dict - Contains analysis text and list of saved zoomed patch paths.\", demo_commands=[ { } ], \"command\": execution = tool.execute(image=\"path/to/image.jpg\", question=\"What is the color of the car?\"), \"description\": \"Analyze image and return relevant zoomed patches that show the cars color.\" user_metadata = { \"best_practices\": [ \"It might be helpful to zoom in on the image first to get better look at the object(s).\", \"It might be helpful if the question requires close-up view of the object(s), symbols, texts, etc.\", \"The tool should be used to provide high-level analysis first, and then use other tools for fine-grained analysis. For example, you can use Relevant_Patch_Zoomer_Tool first to get zoomed patch of specific objects, and then use Image_Captioner_Tool to describe the objects in detail.\" ] } 45 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Relevant Patch Zoomer Tool: Example Input (query): What is the color of the car? Input (image): \"car.png\" Output (analysis): The image shows red car on curvy road with green hills and blue sky with clouds in the background. Here is what is visible in each region: (A) Top-left quarter: Contains the blue sky, clouds, and small part of green hills. No car is visible here. (B) Top-right quarter: Contains the sky, clouds, and the tops of the green hills. The car is not visible. (C) Bottom-left quarter: Shows part of the road and guardrail. The car is partially visible. (D) Bottom-right quarter: Contains the road, guardrail, and most of the car, including its rear view. (E) Center region: Overlaps with parts of the road, hills, and car. The cars rear is partially visible. The task is to identify the color of the car. Regions (D) and (E) are relevant as they show the car, but region (D) contains the full view of the car, making region (E) unnecessary. Output (patch region): (D) bottom-right quarter Output (patch image): \"car bottom-right zoomed 2x.png\" Output (structured result): { \"analysis\": \"The image shows red car on curvy road with green hills and blue sky with clouds in the background. ... The task is to identify the color of the car. Regions (D) and (E) are relevant as they show the car, but region (D) contains the full view of the car, making region (E) unnecessary.\", \"patches\": { \"path\": \"car_bottom-right_zoomed_2x.png\", \"description\": \"The bottom-right region of the image: car.png.\" } } 46 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Relevant Patch Zoomer Tool: Example 2 Input (query): What is the color of the car? Input (image): \"car.png\" Output (analysis): The image depicts red car driving on curved road surrounded by green trees. Heres breakdown of the five regions: (A) Top-left quarter: Contains part of the road and green trees in the background. No car is visible. (B) Top-right quarter: Includes trees in the background and part of the road. The rear portion of the car is partially visible. (C) Bottom-left quarter: Shows the road with no visible car. (D) Bottom-right quarter: Displays clear view of the rear part of the red car, along with some of the road and green surroundings. (E) Center region: Contains the clearest and most focused view of the rear of the red car. To answer the question, What is the color of the car?: The most relevant region is (E), as it contains the clearest depiction of the cars color without including unnecessary background or less visible parts of the car. Output (patch region): (E) center quarter Output (patch image): \"car bottom-right zoomed 2x center zoomed 2x.png\" Output (returned result): { \"analysis\": \"The image depicts red car driving on curved road surrounded by green trees. ... To answer the question, What is the color of the car?: The most relevant region is (E), as it contains the clearest depiction of the cars color without including unnecessary background or less visible parts of the car.\", \"patches\": { \"path\": \"car_bottom-right_zoomed_2x_center_zoomed_2x.png\", \"description\": \"The center region of the image: car_bottom-right_zoomed_2x.png. \" } } 47 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.9. Text Detector Tool Text Detector Tool: Metadata tool_name=\"Text_Detector_Tool\", tool_description=\"A tool that detects text in an image using EasyOCR.\", input_types={ \"image\": \"str - The path to the image file.\", \"languages\": \"list - list of language codes for the OCR model.\", \"detail\": \"int - The level of detail in the output. Set to 0 for simpler output, 1 for detailed output.\" }, output_type=\"list - list of detected text blocks.\", demo_commands=[ { }, { }, { }, ], \"command\": execution = tool.execute(image=\"path/to/image.png\", languages=[\"en\"]) , \"description\": \"Detect text in an image using the default language (English).\" \"command\": execution = tool.execute(image=\"path/to/image.png\", languages=[\"en\", \"de\"]), \"description\": \"Detect text in an image using multiple languages (English and German).\" \"command\": execution = tool.execute(image=\"path/to/image.png\", languages=[\"en\"], detail=0), \"description\": \"Detect text in an image with simpler output (text without coordinates and scores).\" user_metadata={ \"frequently_used_language\": { \"ch_sim\": \"Simplified Chinese\", \"ch_tra\": \"Traditional Chinese\", \"de\": \"German\", \"en\": \"English\", \"es\": \"Spanish\", \"fr\": \"French\", \"hi\": \"Hindi\", \"ja\": \"Japanese\", } } 48 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Text Detector Tool: Example 1 Input (image): \"english.png\" Output (detected text): [[[[231, 32], [674, 32], [674, 64], [231, 64]], \"Reduce your risk of coronavirus infection:\", 0.84], [[[326, 98], [598, 98], [598, 124], [326, 124]], \"Clean hands with soap and water\", 0.96], [[[328, 124], [542, 124], [542, 148], [328, 148]], \"or alcohol-based hand rub\", 0.89], [[[246, 169], [595, 169], [595, 196], [246, 196]], \"Cover nose and mouth when coughing and\", 1.0], [[[245, 194], [546, 194], [546, 222], [245, 222]], \"sneezing with tissue or flexed elbow\", 0.96], [[[320, 240], [624, 240], [624, 266], [320, 266]], \"Avoid close contact with anyone with\", 0.86], [[[318, 266], [528, 266], [528, 292], [318, 292]], \"cold or flu-like symptoms\", 0.77], [[[248, 322], [510, 322], [510, 348], [248, 348]], \"Thoroughly cook meat and eggs\", 0.72], [[[332, 370], [640, 370], [640, 396], [332, 396]], \"No unprotected contact with live wild\", 0.83], [[[334, 396], [464, 396], [464, 420], [334, 420]], \"or farm animals\", 0.72], [[[595, 427], [683, 427], [683, 447], [595, 447]], \"World Health\", 1.0], [[[595, 445], [685, 445], [685, 463], [595, 463]], \"Organization\", 1.0]] Output (structured result): { \"[[[[231, 32], [674, 32], [674, 64], [231, 64]], Reduce your risk of coronavirus infection:, 0.84], [[[326, 98], [598, 98], [598, 124], [326, 124]], Clean hands with soap and water, 0.96], [[[328, 124], [542, 124], [542, 148], [328, 148]], or alcohol-based hand rub, 0.89], [[[246, 169], [595, 169], [595, 196], [246, 196]], Cover nose and mouth when coughing and, 1.0], [[[245, 194], [546, 194], [546, 222], [245, 222]], sneezing with tissue or flexed elbow, 0.96], [[[320, 240], [624, 240], [624, 266], [320, 266]], Avoid close contact with anyone with, 0.86], [[[318, 266], [528, 266], [528, 292], [318, 292]], cold or flu-like symptoms, 0.77], [[[248, 322], [510, 322], [510, 348], [248, 348]], Thoroughly cook meat and eggs, 0.72], [[[332, 370], [640, 370], [640, 396], [332, 396]], No unprotected contact with live wild, 0.83], [[[334, 396], [464, 396], [464, 420], [334, 420]], or farm animals, 0.72], [[[595, 427], [683, 427], [683, 447], [595, 447]], World Health, 1.0], [[[595, 445], [685, 445], [685, 463], [595, 463]], Organization, 1.0]]\" } 49 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Text Detector Tool: Example 2 Input (image): \"chinese.jpg\" Output (detected text): { } [([[86, 80], [134, 80], [134, 128], [86, 128]], \"西\", 0.81), ([[189, 75], [469, 75], [469, 165], [189, 165]], \"愚园路\", 0.96), ([[517, 81], [565, 81], [565, 123], [517, 123]], \"东\", 0.99), ([[78, 126], [136, 126], [136, 156], [78, 156]], \"315\", 1.0), ([[514, 126], [574, 126], [574, 156], [514, 156]], \"309\", 1.0), ([[79, 173], [125, 173], [125, 213], [79, 213]], \"W\", 0.32), ([[226, 170], [414, 170], [414, 220], [226, 220]], \"Yuyuan Rd.\", 0.86), ([[529, 173], [569, 173], [569, 213], [529, 213]], \"E\", 0.56)] Output (structured result): { } \"[[[[86, 80], [134, 80], [134, 128], [86, 128]], u897f, 0.81], [[[189, 75], [469, 75], [469, 165], [189, 165]], u611au56edu8def, 0.96], [[[517, 81], [565, 81], [565, 123], [517, 123]], u4e1c, 0.99], [[[78, 126], [136, 126], [136, 156], [78, 156]], 315, 1.0], [[[514, 126], [574, 126], [574, 156], [514, 156]], 309, 1.0], [[[79, 173], [125, 173], [125, 213], [79, 213]], W, 0.32], [[[226, 170], [414, 170], [414, 220], [226, 220]], Yuyuan Rdu3002, 0.86], [[[529, 173], [569, 173], [569, 213], [529, 213]], E, 0.56]]\" 50 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.10. URL Text Extractor Tool URL Text Extractor Tool: Metadata tool_name=\"URL_Text_Extractor_Tool\", tool_description=\"A tool that extracts all text from given URL.\", input_types={ \"url\": \"str - The URL from which to extract text.\", }, output_type=\"dict - dictionary containing the extracted text and any error messages.\" , demo_commands=[ { }, { }, ] \"command\": execution = tool.execute(url=\"https://example.com\"), \"description\": \"Extract all text from the example.com website.\" \"command\": execution = tool.execute(url=\"https://en.wikipedia.org/wiki/Python_( programming_language)\"), \"description\": \"Extract all text from the Wikipedia page about Python programming language.\" URL Text Extractor Tool: Example 1 Input (query): https://example.com Output (text): Example Domain Example Domain This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission. More information... Output (structured result): { } \"url\": \"https://example.com\", \"extracted_text\": \"Example DomainnExample DomainnThis domain is for use in illustrative examples in documents. You may use thisn domain in literature without prior coordination or asking for permission.nMore information...\" 51 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning URL Text Extractor Tool: Example 2 Input (query): https://arxiv.org/abs/1706.03762 Output (text): [1706.03762] Attention Is All You Need ... [Submitted on 12 Jun 2017 ( v1 ), last revised 2 Aug 2023 (this version, v7)] Title: Attention Is All You Need Authors: Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N. Gomez , Lukasz Kaiser , Illia Polosukhin ... Abstract: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. ... Output (structured result): { } \"url\": \"https://arxiv.org/abs/1706.03762\", \"extracted_text\": \"[1706.03762] Attention Is All You Neednn...nn[Submitted on 12 Jun 2017 (nv1n), last revised 2 Aug 2023 (this version, v7)]nnTitle: nAttention Is All You NeednnAuthors:nAshish Vaswanin,nNoam Shazeern, nNiki Parmarn,nJakob Uszkoreitn,nLlion Jonesn,nAidan N. Gomezn,nLukasz Kaisern,nIllia Polosukhinnn...nnAbstract:nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.nn...\" 52 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning D.11. Wikipedia Knowledge Searcher Tool Wikipedia Knowledge Searcher Tool: Metadata tool_name=\"Wikipedia_Knowledge_Searcher_Tool\", tool_description=\"A tool that searches Wikipedia and returns web text based on given query.\", input_types={ \"query\": \"str - The search query for Wikipedia.\", }, output_type=\"dict - dictionary containing the search results, extracted text, and any error messages.\", demo_commands=[ { }, { }, { }, ] \"command\": execution = tool.execute(query=\"Python programming language\"), \"description\": \"Search Wikipedia for information about Python programming language.\" \"command\": execution = tool.execute(query=\"Artificial Intelligence\"), \"description\": \"Search Wikipedia for information about Artificial Intelligence\" \"command\": execution = tool.execute(query=\"Theory of Relativity\"), \"description\": \"Search Wikipedia for the full article about the Theory of Relativity.\" 53 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Wikipedia Knowledge Searcher Tool: Example 1 Input (query): kidney Output (type): Search results for kidney: 1. Kidney 2. Kidney disease 3. Kidney failure 4. Kidney dialysis 5. Kidney transplantation 6. Kidney bean 7. Kidney cancer 8. Nephrology 9. Ectopic kidney 10. Kidney dish Extracted text: In humans, the kidneys are two reddish-brown bean-shaped blood-filtering organs that are multilobar, multipapillary form of mammalian kidneys, usually without signs of external lobulation. They are located on the left and right in the retroperitoneal space, and in adult humans are about 12 centimetres (4+12 inches) in length. They receive blood from the paired renal arteries; blood exits into the paired renal veins. Each kidney is attached to ureter, tube that carries excreted urine to the bladder. ... Output (structured result): { } \"output\": \"Search results for kidney:n1. Kidneyn2. Kidney diseasen3. Kidney failuren4. Kidney dialysisn5. Kidney transplantationn6. Kidney beann7. Kidney cancern8. Nephrologyn9. Ectopic kidneyn10. Kidney dishnnExtracted text:nIn humans, the kidneys are two reddish-brown bean-shaped blood-filtering organs that are multilobar, multipapillary form of mammalian kidneys, usually without signs of external lobulation. They are located on the left and right in the retroperitoneal space, and in adult humans are about 12 centimetres (4+1u20442 inches) in length. They receive blood from the paired renal arteries; blood exits into the paired renal veins. Each kidney is attached to ureter, tube that carries excreted urine to the bladder. ...\" 54 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning E. Additional Tool Cards in OctoTools E.1. Object Detector Tool Object Detector Tool: Metadata tool_name=\"Object_Detector_Tool\", tool_description=\"A tool that detects objects in an image using the Grounding DINO model and saves individual object images with empty padding.\", input_types={ \"image\": \"str - The path to the image file.\", \"labels\": \"list - list of object labels to detect.\", \"threshold\": \"float - The confidence threshold for detection (default: 0.35).\", \"model_size\": \"str - The size of the model to use (tiny or base, default: tiny ).\", \"padding\": \"int - The number of pixels to add as empty padding around detected objects (default: 20).\" }, output_type=\"list - list of detected objects with their scores, bounding boxes, and saved image paths.\", demo_commands=[ { }, { \"command\": execution = tool.execute(image=\"path/to/image.png\", labels=[\"baseball \", \"basket\"]), \"description\": \"Detect baseball and basket in an image, save the detected objects with default empty padding, and return their paths.\" \"command\": execution = tool.execute(image=\"path/to/image.png\", labels=[\"car\", \" person\"], threshold=0.5, model_size=\"base\", padding=15), \"description\": \"Detect car and person in an image using the base model, save the detected objects with 15 pixels of empty padding, and return their paths.\" } ], user_metadata={ \"limitation\": \"The model may not always detect objects accurately, and its performance can vary depending on the input image and the associated labels. It typically struggles with detecting small objects, objects that are uncommon, or objects with limited or specific attributes. For improved accuracy or better detection in certain situations, consider using supplementary tools or image processing techniques to provide additional information for verification.\" } 55 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Object Detector Tool: Example 1 Input (image): \"example.png\" Input (label): [\"baseball\"] Output (detected objects): Output (structured result): [ { \"label\": \"baseball\", \"confidence score\": 0.69, \"box\": [558, 48, 615, 107], \"saved_image_path\": \"example_baseball_1.png\" \"label\": \"baseball\", \"confidence score\": 0.69, \"box\": [614, 137, 671, 191], \"saved_image_path\": \"example_baseball_2.png\" \"label\": \"baseball\", \"confidence score\": 0.65, \"box\": [86, 335, 143, 393], \"saved_image_path\": \"example_baseball_19.png\" \"label\": \"baseball\", \"confidence score\": 0.63, \"box\": [336, 95, 393, 153], \"saved_image_path\": \"example_baseball_20.png\" }, { }, ... { }, { } ] 56 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Object Detector Tool: Example 2 Input (image): \"example.png\" Input (label): [\"basket\"] Output (detected objects): Output (structured result): [ { \"label\": \"basket\", \"confidence score\": 0.59, \"box\": [252, 2, 468, 215], \"saved_image_path\": \"example_basket_1.png\" \"label\": \"basket\", \"confidence score\": 0.55, \"box\": [503, 2, 717, 215], \"saved_image_path\": \"example_basket_2.png\" \"label\": \"basket\", \"confidence score\": 0.54, \"box\": [2, 2, 217, 215], \"saved_image_path\": \"example_basket_3.png\" \"label\": \"basket\", \"confidence score\": 0.5, \"box\": [2, 242, 217, 455], \"saved_image_path\": \"example_basket_4.png\" }, { }, { }, { } ] 57 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning E.2. Advanced Object Detector Tool Advanced Object Detector Tool: Metadata tool_name=\"Advanced Object Detector Tool\", tool_description=\"A tool that detects objects in an image using the Grounding DINO-X model and saves individual object images with empty padding.\", input_types={ \"image\": \"str - The path to the image file.\", \"labels\": \"list - list of object labels to detect.\", \"threshold\": \"float - The confidence threshold for detection (default: 0.35).\", \"padding\": \"int - The number of pixels to add as empty padding around detected objects (default: 20).\" }, output_type=\"list - list of detected objects with their scores, bounding boxes, and saved image paths.\", demo_commands=[ { }, { \"command\": execution = tool.execute(image=\"path/to/image.png\", labels=[\"baseball \", \"basket\"]), \"description\": \"Detect baseball and basket in an image, save the detected objects with default empty padding, and return their paths.\" \"command\": execution = tool.execute(image=\"path/to/image.png\", labels=[\"car\", \" person\"], threshold=0.5, model_size=\"base\", padding=15), \"description\": \"Detect car and person in an image using the base model, save the detected objects with 15 pixels of empty padding, and return their paths.\" } ], user_metadata={ \"limitation\": \"The model may not always detect objects accurately, and its performance can vary depending on the input image and the associated labels. It typically struggles with detecting small objects, objects that are uncommon, or objects with limited or specific attributes. For improved accuracy or better detection in certain situations, consider using supplementary tools or image processing techniques to provide additional information for verification.\" } OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Advanced Object Detector Tool: Example 1 Input (image): \"example.png\" Input (label): [\"baseball\"] Output (detected objects): Output (structured result): [ { \"label\": \"baseball\", \"confidence score\": 0.73, \"box\": [614, 137, 671, 191], \"saved_image_path\": \"example_baseball_1.png\" \"label\": \"baseball\", \"confidence score\": 0.73, \"box\": [114, 377, 171, 431], \"saved_image_path\": \"example_baseball_2.png\" \"label\": \"baseball\", \"confidence score\": 0.66, \"box\": [535, 111, 592, 169], \"saved_image_path\": \"example_baseball_19.png\" \"label\": \"baseball\", \"confidence score\": 0.66, \"box\": [337, 95, 393, 153], \"saved_image_path\": \"example_baseball_20.png\" }, { }, ... { }, { } ] OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning E.3. Nature News Fetcher Tool Nature News Fetcher Tool: Metadata tool_name=\"Nature_News_Fetcher_Tool\", tool_description=\"A tool that fetches the latest news articles from Nature.\", input_types={ \"num_articles\": \"int - The number of articles to fetch (default: 100).\", \"max_pages\": \"int - The maximum number of pages to fetch (default: 5).\", }, output_type=\"list - list of dictionaries containing information about the latest Nature news articles.\", demo_commands=[ { }, { }, ] \"command\": execution = tool.execute(), \"description\": \"Fetch the latest 100 news articles from Nature.\" \"command\": execution = tool.execute(num_articles=50, max_pages=3), \"description\": \"Fetch the latest 50 news articles from Nature, searching up to 3 pages.\" OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Nature News Fetcher Tool: Example 1 Output (article 1, search date: Jan 14, 2025): Title: Has Bluesky replaced for scientists? Take Natures poll URL: https://www.nature.com/articles/d41586-025-00037-y Description: The research community has flocked to the social-media platform Bluesky. Tell us about your experien... Authors: No authors found Date: 2025-01-14 Image URL: https://media.springernature.com/w290h158/magazine-assets/d41586-025-00037-y/ d41586-025-00037-y_50440812.jpg Output (article 2, search date: Jan 14, 2025): Title: How should we test AI for human-level intelligence? OpenAIs o3 electrifies quest URL: https://www.nature.com/articles/d41586-025-00110-6 Description: Experimental models record-breaking performance on science and maths tests wows researchers.... Authors: Nicola Jones Date: 2025-01-14 Image URL: https://media.springernature.com/w290h158/magazine-assets/d41586-025-00110-6/ d41586-025-00110-6_50469004.jpg Output (structured result): [ { \"title\": \"Has Bluesky replaced for scientists? Take Natureu2019s poll\", \"url\": \"https://www.nature.com/articles/d41586-025-00037-y\", \"description\": \"The research community has flocked to the social-media platform Bluesky. Tell us about your experience.\", \"authors\": [ \"No authors found\" ], \"date\": \"2025-01-14\", \"image_url\": \"https://media.springernature.com/w290h158/magazine-assets/d41586 -025-00037-y/d41586-025-00037-y_50440812.jpg\" \"title\": \"How should we test AI for human-level intelligence? OpenAIu2019s o3 electrifies quest\", \"url\": \"https://www.nature.com/articles/d41586-025-00110-6\", \"description\": \"Experimental modelu2019s record-breaking performance on science and maths tests wows researchers.\", \"authors\": [ \"Nicola Jones\" ], \"date\": \"2025-01-14\", \"image_url\": \"https://media.springernature.com/w290h158/magazine-assets/d41586 -025-00110-6/d41586-025-00110-6_50469004.jpg\" }, { } ] 61 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F. Experimental Examples F.1. Demonstration Example Below is an example from MathVista (Lu et al., 2024b), which demonstrates the detailed steps in our OctoTools framework. The base GPT-4o model fails to provide correct answer due to its limited visual perception of abstract scenes."
        },
        {
            "title": "The Query",
            "content": "Image path: baseball.png Question: How many baseballs are there? Ground truth: 20 Wrong Prediction from GPT-4o There are total of 19 baseballs across the four buckets: - The first bucket (top left) contains 4 baseballs. - The second bucket (top right) contains 5 baseballs. - The third bucket (bottom left) contains 4 baseballs. - The fourth bucket (bottom right) contains 6 baseballs. Adding them together: 4 + 5 + 4 + 6 = 19 baseballs. In contrast, OctoTools decomposes the query into two steps by calling two vision tools to enhance visual perception. First, it calls the Image Captioner Tool to provide general description of the associated image. Then, it uses the Object Detector Tool to detect and count the baseballs. These two steps provide consistent information about the number of baseballs, thus resulting in correct answer. Step 0: Initial Plan from Query Analyzer Concise summary: The query asks, How many baseballs are there? accompanied by an image showing several buckets containing baseballs. The objective is to determine the total number of baseballs present in the image. Required skills: 1. Image Analysis: Understanding and interpreting visual content. 2. Tool Operation: Ability to operate and execute commands using the provided tools. 3. Critical Thinking: Evaluating tool outputs and making decisions based on them. Relevant tools: 1. Image Captioner Tool: Used to generate description of the image, which can provide context and identify objects present. 2. Object Detector Tool: Used to detect and count the number of baseballs in the image, providing specific object identification and quantification. Additional considerations: Consider the limitations of each tool, such as potential inaccuracies in complex scenes or object detection. Verify results if possible, and be aware of the need for potential manual verification or supplementary tools for precise counting. OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Action from Action Predictor Justification: The Image Captioner Tool is the best choice for the first step because it provides general description of the image, which can help identify the presence of baseballs and other relevant objects. This initial step is crucial for understanding the context of the image before proceeding to count specific objects using the Object Detector Tool. Context: Image path: baseball.png Sub-goal: Generate detailed description of the image located at \"baseball.png\" to identify the presence of baseballs and other relevant objects. Tool name: Image Captioner Tool Step 1: Command from Command Generator Analysis: The task requires two steps: first, using the Image Captioner Tool to generate caption for the image, and second, using the Object Detector Tool to count the number of baseballs. The current focus is on the first step, which involves generating descriptive caption for the image located at baseball.png. The Image Captioner Tool requires an image path and optionally prompt. The default prompt is sufficient for generating general description of the image. Explanation: The command uses the Image Captioner Tool to generate caption for the image. The image path is provided as baseball.png, and the default prompt is used to describe the image. This step is necessary to provide context for the subsequent object detection task. Command: execution = tool.execute(image=\"baseball.png\") Step 1: Result from Command Executor Result: The image shows four blue buckets, each containing five baseballs. The buckets are arranged in grid with three on the top row and one on the bottom left. Each bucket is depicted from top-down perspective, and the baseballs inside are white with red stitching. The buckets have handles on the sides. The background is plain white, emphasizing the buckets and baseballs. Step 1: Verification from Context Verifier Completeness: The memory addresses the query by using the Image Captioner Tool to describe the image, which mentions that there are four buckets, each containing five baseballs. This provides total count of 20 baseballs. However, the Object Detector Tool has not been used yet to verify this count, which is requirement of the task. Unused Tools: The Object Detector Tool is available and should be used to count the baseballs as per the task description. This tool is specifically designed to detect and count objects, which is necessary to fulfill the query accurately. Inconsistencies: There are no inconsistencies in the information provided by the Image Captioner Tool. However, the task requires verification using the Object Detector Tool, which has not been done. Verification needs: The count of baseballs needs verification using the Object Detector Tool due to the tasks explicit requirement to use this tool for counting. OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Verification from Context Verifier (Continued) Ambiguities: There are no ambiguities in the current description, but Object Detector Tool suggests that the count should be confirmed using this tool. the tasks requirement to use the Final determination: The memory is not complete as it lacks the use of the Object Detector Tool to count the baseballs, which is critical part of the task. Therefore, additional tool usage is necessary to fulfill the query accurately. Conclusion: CONTINUE Step 2: Action from Action Predictor Justification: The next logical step is to use the Object Detector Tool to count the number of baseballs in the image. The Image Captioner Tool has already provided detailed description indicating the presence of baseballs in buckets. The Object Detector Tool is specifically designed to detect and quantify objects, making it the most suitable choice for counting the baseballs accurately. This step directly addresses the querys requirement to determine the number of baseballs, leveraging the tools capability to identify and count specific objects within an image. Context: Image path: baseball.png Previous description: The image shows four blue buckets, each containing five baseballs. The buckets are arranged in grid with two on the top row and two on the bottom row. Each bucket has handle on the side, and the baseballs inside are white with red stitching. The background is plain white, emphasizing the buckets and baseballs. Sub-goal: Use the Object Detector Tool to detect and count the number of baseballs in the image located at \"baseball.png\". Tool name: Object Detector Tool Step 2: Command from Command Generator Analysis: The task requires detecting and counting the number of baseballs in given image using the Object Detector Tool. The image path is provided, and the context suggests that the image contains baseballs. The tools metadata indicates that it requires an image path and list of labels to detect. The label relevant to our task is baseball. The tool also allows setting confidence threshold, model size, and padding, but these are optional. For this task, we will use the default values for these optional parameters. Explanation: The command is constructed to use the Object Detector Tool to detect baseballs in the specified image. We provide the image path and list containing the label baseball to focus the detection on baseballs. The default values for threshold, model size, and padding are used, as they are not specified in the task requirements. This setup will allow the tool to detect and count the baseballs in the image. Command: execution = tool.execute(image=\"baseball.png\", labels=[\"baseball\"]) OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 2: Result from Command Executor [ { \"label\": \"baseball\", \"confidence score\": 0.69, \"box\": \"(558, 48, 615, 107)\", \"saved_image_path\": \"solver_cache/baseball_1.png\" }, ... { \"label\": \"baseball\", \"confidence score\": 0.63, \"box\": \"(336, 95, 393, 153)\", \"saved_image_path\": \"solver_cache/baseball_20.png\" } ] Step 2: Verification from Context Verifier Completeness: The memory addresses the query by using both the Image Captioner Tool and the Object Detector Tool. The Image Captioner Tool provided detailed description of the image, stating that there are four blue buckets, each containing five baseballs, which totals to 20 baseballs. This description aligns with the tasks requirement to identify the presence of baseballs. The Object Detector Tool was then used to count the baseballs, detecting 20 baseballs in the image. This matches the description provided by the Image Captioner Tool, confirming the count. Unused Tools: All relevant tools have been used. The Image Captioner Tool provided context, and the Object Detector Tool confirmed the count of baseballs. Inconsistencies: There are no inconsistencies between the outputs of the two tools. Both tools indicate the presence of 20 baseballs. Verification Needs: The results from both tools are consistent, reducing the need for further verification. The Object Detector Tools output aligns with the Image Captioner Tools description, providing confidence in the accuracy of the count. Ambiguities: There are no ambiguities in the results. The tools have provided clear and consistent information regarding the number of baseballs. Final Determination: The memory is complete and accurate enough to generate the final output. The use of both tools has provided consistent and verified count of the baseballs, fulfilling the querys requirements. Conclusion: STOP OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning"
        },
        {
            "title": "Full Trajectory in the Context after Two Steps",
            "content": "\"Action Step 1\": { \"tool_name\": \"Image_Captioner_Tool\", \"sub_goal\": \"Generate descriptive caption for the image located at \"baseball. png\" to provide context for subsequent object detection.\", \"command\": \"execution = tool.execute(image=\"baseball.png\")\", \"result\": [ \"The image shows four blue buckets, each containing five baseballs. The buckets are arranged in grid with three on the top row and one on the bottom left . Each bucket is depicted from top-down perspective, and the baseballs inside are white with red stitching. The buckets have handles on the sides. The background is plain white, emphasizing the buckets and baseballs.\" ] }, \"Action Step 2\": { \"tool_name\": \"Object_Detector_Tool\", \"sub_goal\": \"Use the Object_Detector_Tool to detect and count the number of baseballs in the image located at \"baseball.png\".\", \"command\": \"execution = tool.execute(image=\"baseball_113.png\", labels=[\" baseball\"])\", \"result\": [ [ { \"label\": \"baseball\", \"confidence score\": 0.69, \"box\": \"(558, 48, 615, 107)\", \"saved_image_path\": \"solver_cache/baseball_1.png\" \"label\": \"baseball\", \"confidence score\": 0.63, \"box\": \"(336, 95, 393, 153)\", \"saved_image_path\": \"solver_cache/0/baseball_20.png\" }, ... { } ] ] } The final answer is summarized by the solution summarizer in the planner, given the full trajectory in the context described above. This two-step flow overcomes the base GPT-4o models limitation in visual perception. Final Answer Detailed analysis: Step 1: Image Captioner Tool Result: The image contains four blue buckets, each with five baseballs, arranged in grid pattern. Step 2: Object Detector Tool Result: Detected 20 baseballs with varying confidence scores. Key findings: The image contains total of 20 baseballs, distributed evenly across four buckets. Each bucket contains five baseballs, as confirmed by both tools. Answer to the query: The image shows four blue buckets, each containing five baseballs. Therefore, there are total of 20 baseballs. Additional insights: The consistent results from both tools reinforce the accuracy of the analysis. The arrangement of the buckets and baseballs is clear and well-organized, aiding in accurate detection. 66 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.2. Example for Multi-step Mathematical Reasoning"
        },
        {
            "title": "The Query",
            "content": "Question: Using the numbers [1, 1, 6, 9], create an expression that equals 24. You must use basic arithmetic operations (+, -, , /) and parentheses. Example: for [1, 2, 3, 4], one solution is (1+2+3)4. Wrong Prediction from GPT-4o One possible expression using the numbers [1, 1, 6, 9] to make 24 is: (9 + 1) (6/2) Breaking it down: - 9 + 1 = 10 - 6/2 = 3 - 10 3 = 24 This satisfies the conditions using basic arithmetic operations and parentheses. Wrong Prediction from GPT-4o with another attempt One possible solution using the numbers [1, 1, 6, 9] to make 24 is: (6/(1 1) + 9) 1 However, (1 - 1) equals 0, which makes division by zero undefined. So we must try another approach. correct solution is: (6/1) (9/1) = 6 9 = 54 This exceeds 24. Lets adjust: valid expression that equals 24 is: This correctly uses all four numbers and results in 24. (6 9)/(1 + 1) = 54/2 = 24 Step 0: Initial Plan from Query Analyzer Required skills: 1. Mathematical Problem Solving: Ability to manipulate numbers and operations to achieve specific result. 2. Arithmetic Operations: Proficiency in using addition, subtraction, multiplication, and division. 3. Logical Reasoning: Skill in applying logical steps to combine numbers and operations effectively. Relevant tools: 1. Python Code Generator Tool: This tool can be used to generate and test different combinations of arithmetic operations on the given numbers to find an expression that equals 24. It is suitable for simple arithmetic calculations and can help automate the trial-and-error process. 2. Generalist Solution Generator Tool: Although not specifically designed for arithmetic problems, it can provide step-by-step approach to solving the problem by suggesting possible combinations and reasoning through them. OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Action from Action Predictor Justification: The Python Code Generator Tool is the most suitable choice for this task because it is specifically designed to handle arithmetic calculations and can automate the process of testing different combinations of the given numbers and operations to achieve the target result of 24. ... Sub-goal: Generate and test different arithmetic expressions using the numbers [1, 1, 6, 9] to find combination that equals 24. Tool name: Python Code Generator Tool Step 1: Command from Command Generator Command: create an expression that equals 24 using basic arithmetic operations (+, -, *, /) and parentheses.\") execution = tool.execute(query=\"Using the numbers [1, 1, 6, 9], Step 1: Result from Command Executor Generated Python code: # Define the numbers numbers = [1, 1, 6, 9] # Calculate the expression # Using the expression: result = 6 / (1 - (9 / 1)) 6 / (1 - (9 / 1)) = # Print the result with descriptive message print(f\"The result of the expression using the numbers {numbers} is: {result}\") Execution: The result of the expression using the numbers [1, 1, 6, 9] is: -0.75 Step 1: Verification from Context Verifier Justification: The memory does not fully address the query as the expression found does not equal 24. The task requires finding valid arithmetic expression using the numbers [1, 1, 6, 9] that results in 24, which has not been achieved. There are no contradictions in the information provided, but the result is incorrect, indicating need for further exploration of possible solutions. The incorrect result from the Python Code Generator Tool suggests that further verification and exploration of different expressions are necessary. This could involve manually testing different combinations or using the Generalist Solution Generator Tool to explore potential solutions. Conclusion: CONTINUE Step 2: Action from Action Predictor Justification: The previous attempt using this tool resulted in an incorrect expression, indicating that further exploration of possible combinations is needed. By refining the query and focusing on generating valid expressions, we can efficiently utilize the tools capabilities to find solution that equals 24. Sub-goal: Generate and test additional arithmetic expressions using the numbers [1, 1, 6, 9] to find valid combination that equals 24, ensuring the use of parentheses to alter operation precedence. Tool name: Python Code Generator Tool 68 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 2: Command from Command Generator Command: create an expression that equals 24 using basic arithmetic operations (+, -, *, /) and parentheses.\") execution = tool.execute(query=\"Using the numbers [1, 1, 6, 9], Step 2: Result from Command Executor Generated Python code: # Step 1: inner_division = 9 / 1 Calculate the inner division # Step 2: subtraction_result = 1 - inner_division Subtract the result from 1 # Step 3: final_result = 6 / subtraction_result Divide 6 by the result of step 2 # Print the final result with descriptive message print(\"The result of the expression (6 / (1 - (9 / 1))) is:\", final_result) Execution: The result of the expression (6 / (1 - (9 / 1))) is: -0.75 Step 2: Verification from Context Verifier Justification: The memory is insufficient to generate the final output as it does not provide correct expression that equals 24. Additional tool usage, specifically the Generalist Solution Generator Tool, is necessary to explore other possible solutions and fulfill the query. Conclusion: Continue Step 3: Action from Action Predictor Justification: The Python Code Generator Tool is the most suitable choice for this step because it is specifically designed to handle arithmetic calculations and can automate the process of testing different combinations of operations and parentheses. Previous attempts using this tool have not yet found solution, but it remains the best option for systematically exploring possible expressions. The Generalist Solution Generator Tool, while capable of providing step-by-step reasoning, is not optimized for generating and testing multiple arithmetic expressions efficiently. Given the need to find valid expression that equals 24, the Python Code Generator Tool can be used to continue testing new combinations, leveraging its ability to quickly execute and evaluate arithmetic expressions. Sub-goal: Generate and test new arithmetic expressions using the numbers [1, 1, 6, 9] with different combinations of operations and parentheses to find valid expression that equals 24. Tool name: Python Code Generator Tool Step 3: Command from Command Generator Command: execution = tool.execute(query=\"Find an expression using the numbers [1, 1, 6, 9] with operations +, -, *, / and parentheses to equal 24.\") 69 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 3: Result from Command Executor Generated Python code: from itertools import permutations, product # Define the numbers and target numbers = [1, 1, 6, 9] target = 24 operations = [+, -, *, /] # Function to evaluate an expression safely def evaluate_expression(expr): try: return eval(expr) except ZeroDivisionError: return None # Generate all permutations of numbers for num_perm in permutations(numbers): # Generate all combinations of operations for ops in product(operations, repeat=3): # Generate different parenthesized expressions expressions = [ f\"({num_perm[0]} {ops[0]} {num_perm[1]}) {ops[1]} ({num_perm[2]} {ops[2]} { num_perm[3]})\", f\"(({num_perm[0]} {ops[0]} {num_perm[1]}) {ops[1]} {num_perm[2]}) {ops[2]} { num_perm[3]}\", f\"({num_perm[0]} {ops[0]} ({num_perm[1]} {ops[1]} {num_perm[2]})) {ops[2]} { num_perm[3]}\", f\"{num_perm[0]} {ops[0]} (({num_perm[1]} {ops[1]} {num_perm[2]}) {ops[2]} { num_perm[3]})\", f\"{num_perm[0]} {ops[0]} ({num_perm[1]} {ops[1]} ({num_perm[2]} {ops[2]} { num_perm[3]}))\" ] # Evaluate each expression for expr in expressions: if evaluate_expression(expr) == target: print(f\"Expression that equals {target}: {expr}\") break Execution: Expression that equals 24: ((1 + 1) * 9) + 6 ... Expression that equals 24: 6 + ((1 + 1) * 9) ... Step 3: Verification from Context Verifier Justification: The memory provides comprehensive solution to the query of creating an expression using the numbers [1, 1, 6, 9] that equals 24. The Python Code Generator Tool was used effectively to explore various combinations of arithmetic operations and parentheses. The final result includes multiple valid expressions that satisfy the query, such as: ((1 + 1) * 9) + 6, 6 + ((1 + 1) * 9). Conclusion: STOP Final Answer The expression (1+1)9+6 successfully uses the numbers [1, 1, 6, 9] with basic arithmetic operations and parentheses to equal 24. 70 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.3. Example for Agentic Reasoning Below is challenging example from GAIA-Text (Mialon et al., 2023) that involves multiple steps, specialized domain knowledge, and rigorous reasoning. Solving it requires understanding the Babylonian number system, recognizing the cuneiform symbols, and performing careful calculations and conversions. The incorrect prediction illustrates limitation of the base GPT-4o model."
        },
        {
            "title": "The Query",
            "content": "Question: Consider the following symbols: This is number written using the Mesopotamian/Babylonian number system and represented with Sumerian cuneiform. Convert this number into Arabic numerals as decimal number. Ground truth: 536 Annotated solution (for response validation only): Annotated solution (for response validation only): 1. Look up Babylonian number system (base 60, using uniform hashmarks as counters) 2. Converted the Cuniform to Arabic ( 3. Since Babylonian is base 60 system, converted the 60s place to decimal (8*60=480) 4. Added 56 to 480 (536). 56) 8 Wrong Prediction from GPT-4o The given symbols are written in Sumerian cuneiform and follow the Babylonian number system, which is . : This symbol represents 60 in the Babylonian numeral system. Lets analyze the symbols: 1. 2. : represents 10. represents 2. - - - Together, represents 12. Now, interpreting the full number: - In positional system, the leftmost symbols represent higher powers of 60. - - = 60 (this is in the 601 place). = 12 (this is in the 600 place). Compute the decimal equivalent: (60 1) + (12 1) = 60 + 12 = 72 Thus, the number written in Arabic numerals is 72. By contrast, in its initial three steps, OctoTools attempts to gather information on the Babylonian system and Sumerian cuneiform symbols via Wikipedia and Google searches, although these initial efforts do not yield useful results. The planner in OctoTools then suggests more general search approach; at Step 4, OctoTools conducts broader Google search for general resources, and at Step 5, it obtains the crucial information by visiting one of the returned URLs. 71 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 0: Initial Plan from Query Analyzer Required skills: 1. Knowledge of Ancient Number Systems: Understanding the Mesopotamian/Babylonian number system and Sumerian cuneiform symbols is crucial for interpreting the given symbols. 2. Historical Linguistics: Ability to translate ancient scripts into modern numerical systems. 3. Research Skills: Ability to find reliable sources or references that explain the conversion process from cuneiform to Arabic numerals. Relevant tools: 1. Google Search Tool: This tool can be used to search for resources or references on the Mesopotamian/Babylonian number system and Sumerian cuneiform symbols, which are necessary for understanding and converting the symbols. 2. Wikipedia Knowledge Searcher Tool: This tool can be used to find detailed articles on the Babylonian number system and Sumerian cuneiform, providing background information and conversion methods. Additional considerations: The task requires deep understanding of ancient numeral systems, which may not be directly supported by the available tools. Therefore, the tools should be used to gather information and resources that can aid in manual conversion. Additionally, verifying the accuracy of the conversion with multiple sources is recommended to ensure correctness. Step 1: Action from Action Predictor Justification: The query requires converting Sumerian cuneiform symbols into Arabic numerals, which involves understanding the Babylonian number system. The Wikipedia Knowledge Searcher Tool is ideal for this task as it can provide detailed articles and resources on ancient number systems, including the Babylonian system and Sumerian cuneiform. Context: Convert the Sumerian cuneiform symbols into Arabic numerals as decimal number. Sub-goal: Search for information on the Babylonian number system and Sumerian cuneiform symbols to understand their numerical values and conversion methods. Tool name: Wikipedia Knowledge Searcher Tool Step 1: Command from Command Generator Command: cuneiform symbols \") execution = tool.execute(query = \"Babylonian number system Sumerian Step 1: Result from Command Executor Execution: No results found for the given query. Step 1: Verification from Context Verifier Justification: The memory is insufficient to generate the final output. Additional tool usage, specifically the Google Search Tool, is necessary to gather more information on the Babylonian number system and Sumerian cuneiform symbols to perform the conversion accurately. Conclusion: CONTINUE 72 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 2: Action from Action Predictor Justification: The previous attempt to use the Wikipedia Knowledge Searcher Tool did not yield any results for the specific cuneiform symbols. To progress, we need broader search that can provide resources or references on the Mesopotamian/Babylonian number system and Sumerian cuneiform symbols. The Google Search Tool is well-suited for this task as it can perform wide-ranging search across the internet, potentially finding more diverse sources that explain the conversion process from cuneiform to Arabic numerals. Sub-goal: Perform Google search to find resources or references on the Mesopotamian/Babylonian number system and Sumerian cuneiform symbols, focusing on conversion methods to Arabic numerals. Tool name: Google Search Tool Step 2: Command from Command Generator Command: execution = tool.execute(query=\"Mesopotamian Babylonian number system Sumerian cuneiform conversion \") Step 2: Result from Command Executor Execution: { } \"title\": \"New Capabilities, New Risks? - Evaluating Agentic General ...\", \"link\": \"https://www.lesswrong.com/posts/Foh7HQYeuN2Gej5k6/new-capabilities-newrisks-evaluating-agentic-general\", \"snippet\": \"Sep 29, 2024 ... ... ud809udc1c ud809udc10ud809udc1a This is number written using the Mesopotamian/Babylonian number system and represented with Sumerian cuneiform. Convert this numberu00a0...\" Step 2: Verification from Context Verifier Justification: The Wikipedia and Google searches did not provide relevant results or conversion methods. The memory is insufficient to generate the final output, as it does not provide the necessary conversion information or methods. Additional tool usage, particularly more targeted search or reasoning process, is required to address the query fully. Conclusion: Continue Step 3: Action from Action Predictor Justification: The previous steps attempted to gather information on the Babylonian number system and Sumerian cuneiform symbols using Wikipedia and Google searches, but they did not yield useful results. The Wikipedia search returned no results, and the Google search did not provide relevant information directly related to the conversion of the specific symbols. Given the need for detailed and specific information about these ancient symbols, the Wikipedia Knowledge Searcher Tool is suitable choice for the next step. Sub-goal: Search Wikipedia for detailed information on the Babylonian number system and Sumerian cuneiform, focusing on the conversion of the symbols to Arabic numerals. and Tool name: Wikipedia Knowledge Searcher Tool 73 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 3: Command from Command Generator Command: cuneiform execution = tool.execute(query=\"Babylonian number system Sumerian \") Step 3: Result from Command Executor Execution: No results found for the given query. Step 3: Verification from Context Verifier Justification: The memory is insufficient to generate the final output as it does not provide the necessary conversion of the cuneiform symbols to Arabic numerals. Additional tool usage, particularly more focused search or an attempt to reason through the problem with the Generalist Solution Generator Tool, is necessary to address the query. Conclusion: Continue Step 4: Action from Action Predictor Justification: Given the lack of direct results from previous searches using the Wikipedia Knowledge Searcher Tool and the Google Search Tool, the next logical step is to use the Google Search Tool again. This tool can provide broader range of resources and references that might not be available on Wikipedia. The goal is to find specific resources or articles that explain the conversion of Sumerian cuneiform symbols to Arabic numerals, which is crucial for solving the query. The previous Google search did not yield useful results, possibly due to the specificity of the query. more general search might yield better results. Context: Previous Google search query: conversion . Mesopotamian Babylonian number system Sumerian cuneiform Sub-goal: Perform Google search to find general resources or articles on converting Sumerian cuneiform symbols to Arabic numerals, focusing on understanding the Babylonian number system. Tool name: Google Search Tool Step 4: Command from Command Generator Command: execution = tool.execute(query=\"Mesopotamian Babylonian number system Sumerian cuneiform conversion\") Step 4: Result from Command Executor Execution: [ { \"title\": \"Babylonian Numerals Converter - Online Number System Calculator\", \"link\": \"https://www.dcode.fr/babylonian-numbers\", \"snippet\": \"babylonian, mesopotamian, sumerian, numeral, 60, sexagesimal, babylon, cuneiform, writing, civilization, tablet, clay, wedge, bracket, pipe, bar. Source code.\" }, ... ] 74 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 4: Verification from Context Verifier Justification: The memory is insufficient to generate final output as it lacks the specific conversion information needed. Additional tool usage, particularly more targeted searches or expert consultation, is necessary to obtain the required conversion details. Conclusion: Continue Step 5: Action from Action Predictor and Justification: The previous steps attempted to find information on the Babylonian number system and Sumerian cuneiform symbols using both Google and Wikipedia searches, but they did not yield specific results for the symbols . However, the Google search did return links to resources that might contain the necessary conversion information. The Babylonian Numerals Converter - Online Number System Calculator and Babylonian Numbers Converter links seem promising for directly converting the symbols to Arabic numerals. Therefore, the next logical step is to use the URL Text Extractor Tool to extract text from these URLs, which may contain the conversion information needed. Context: URL: https://www.dcode.fr/babylonian-numbers Sub-goal: Extract converting Babylonian cuneiform symbols to Arabic numerals. text from the URL https://www.dcode.fr/babylonian-numbers to find information on Tool name: URL Text Extractor Tool Step 5: Command from Command Generator Command: execution = tool.execute(url=\"https://www.dcode.fr/babylonian-numbers\") Step 5: Result from Command Executor Execution: ... What are babylonian numbers? (Definition) Babylonian numeration is numbering system used by the ancient Babylonians/Sumerians in Mesopotamia to represent numbers. In mesopotamian/babylonian/sumerian number system, numbers are written in cuneiform style with (pipe or nail) and < (corner wedge or bracket), written in base 60 (sexagesimal). How to write babylonian numbers? The number is written in base 60, the 60 digits are broken down into vertical bars (often noted ) which are worth one unit (1) and chevrons (often noted <) which are worth ten (10) in base 10. ... Since Unicode 5 (2006) cuneiform symbols can be represented on compatible browsers, here is the table of characters used by dCode: ... 75 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 5: Verification from Context Verifier Justification: The memory provides comprehensive analysis of the query, which involves converting number written in the Mesopotamian/Babylonian number system using Sumerian cuneiform symbols into Arabic numerals. The initial analysis correctly identifies the need for understanding ancient numeral systems and suggests using the Google Search Tool and Wikipedia Knowledge Searcher Tool to gather relevant information. The memory shows that multiple attempts were made to find information on the Babylonian number system and Sumerian cuneiform symbols using both the Wikipedia Knowledge Searcher Tool and Google Search Tool. However, the specific query with the symbols did not yield direct results. and Despite this, successful extraction from the URL https://www.dcode.fr/babylonian-numbers provided detailed information on Babylonian numerals, including the values of the symbols (50), which are crucial for conversion. (8) and Conclusion: Continue Final Answer into Arabic numerals, we need to understand the and To convert the given Sumerian cuneiform symbols Babylonian number system, which is base-60 (sexagesimal) system. Heres step-by-step breakdown of the conversion process: 1. Identify the Symbols: - - - represents the number 8. represents the number 50. represents the number 6. 2. Understand the Structure: - Babylonian numbers are written in positional system similar to our decimal system but based on 60. Each position represents power of 60. 3. Analyze the Given Symbols: - The symbols are written as positional values. 4. Convert Each Group: . This suggests two separate groupings, which can be interpreted as two different - The first symbol - The second group (8) is in the higher position, so it represents 8 60 = 480. (50 + 6) represents 56. 5. Calculate the Total: - Add the values from each group: 480 + 56 = 536. Therefore, the Sumerian cuneiform symbols convert to the Arabic numeral 536. 76 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.4. Example for Medical Reasoning"
        },
        {
            "title": "The Query",
            "content": "Image path: source.jpg Question: What is the organ on the left side of this image? Ground truth: Lung Wrong Prediction from GPT-4o The organ on the left side of this MRI image is the heart. OctoTools decomposes the query into three steps. First, it calls the Relevant Patch Zoomer Tool to select salient patch from the image for more fine-grained analysis. Then, it uses the Image Captioner Tool to describe the selected zoomed-in image. Note that in the combination of the first and second step is not helpful and yields an incorrect response, but OctoTools is able to verify with separate tool due to specified limitations in the tool card and then corrects the reasoning trajectory. Step 0: Initial Plan from Query Analyzer Required skills: 1. Image Analysis: Ability to interpret and analyze medical images to identify organs. 2. Medical Knowledge: Understanding of human anatomy to accurately identify organs in medical images. Relevant tools: 1. Image Captioner Tool: This tool can generate description of the image, which might help in identifying the organ on the left side. However, it may have limitations in complex medical images. 2. Relevant Patch Zoomer Tool: This tool can zoom into specific areas of the image, which might help in focusing on the left side to better identify the organ. Step 1: Action from Action Predictor Justification: The Relevant Patch Zoomer Tool is the best choice for the next step because it allows us to focus specifically on the left side of the image, which is where the organ in question is located... Context: Image path: source.jpg Sub-goal: Zoom into the left side of the image to focus on the organ located there... Tool name: Relevant Patch Zoomer Tool Step 1: Command from Command Generator Command: organ on the left side of the image?\") execution = tool.execute(image=\"source.jpg\", question=\"What is the 77 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Result from Command Executor Analysis: The image appears to be cross-sectional scan, likely an MRI or CT scan, of the thoracic region. - (A) Top-left quarter: This region shows part of the thoracic cavity, likely including lung tissue and possibly part of the heart or other structures. ... To identify the organ on the left side of the image, the most relevant region is (A) Top-left quarter, as it contains the left side of the thoracic cavity. Zoomed-in Patch: source top-left zoomed 2x.png Step 1: Verification from Context Verifier Ambiguities: The result is ambiguous as it does not clearly identify the organ. Using the Image Captioner Tool could help clarify this. Final determination: Given these points, additional tool usage is necessary to accurately identify the organ on the left side of the image. Conclusion: CONTINUE Step 2: Action from Action Predictor Justification: The Image Captioner Tool is the best choice for the next step because it can generate detailed description of the zoomed-in image patch, which is focused on the left side of the thoracic cavity. Tool name: Image Captioner Tool Step 2: Command from Command Generator Command: execution = tool.execute(image=\"source top-left zoomed 2x.png\") Step 2: Result from Command Executor Result: The image shows cross-sectional view of the human brain, likely from an MRI scan. 78 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 2: Verification from Context Verifier Final determination: There is clear inconsistency between the initial analysis (suggesting thoracic region) and the Image Captioner Tools result (identifying the brain). This needs resolution to ensure accurate identification of the organ. The memory is insufficient due to the inconsistency in organ identification. Additional tool usage, specifically the Generalist Solution Generator Tool, is necessary to resolve the ambiguity and verify the organs identity. Conclusion: CONTINUE Step 3: Action from Action Predictor Justification: The Image Captioner Tool has already been used to generate description of the zoomed-in image patch, which identified the organ as part of the brain. To ensure accuracy and specificity, it is important to verify this result with medical expert. Since the Generalist Solution Generator Tool can provide step-by-step reasoning and potentially refine the understanding of the image content, it is suitable for generating more detailed analysis or hypothesis about the organ based on the current findings. This tool can help bridge the gap between the image analysis and medical knowledge required to accurately identify the organ. Tool name: Generalist Solution Generator Tool Step 3: Command from Command Generator Command: execution = tool.execute(prompt=\"Analyze the image and determine the organ on the left side, considering it is cross-sectional view of the human brain.\", image=\"source.jpg\") Step 3: Result from Command Executor Result: The image provided is not cross-sectional view of the human brain. It appears to be cross-sectional MRI of the thorax, showing the chest area. The organs visible in this image are likely the lungs and the heart, not brain structures. Step 3: Verification from Context Verifier Ambiguities: The ambiguity arises from the Image Captioner Tools incorrect description. Generalist Solution Generator Tool provides more accurate context. The Final determination: The memory is mostly sufficient, but due to the initial misidentification, manual verification by medical expert is recommended to ensure accuracy. No additional tool usage is necessary, as the Generalist Solution Generator Tool has provided plausible correction. Conclusion: STOP The final answer is summarized by the solution summarizer in the planner, given the trajectory above. Note that in the third step, OctoTools was able to correct subpar usage of tools in the first two steps, eventually reaching correct answer. Final Answer The image is cross-sectional MRI of the thorax. In this orientation, the left side of the image represents the right side of the patient due to standard medical imaging conventions. The organ on the left side of the image is likely the right lung. OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.5. Example for Pathology Diagnosis"
        },
        {
            "title": "The Query",
            "content": "Image path: tissue.jpg Question: This is hematoxylin and eosin (H&E) stained osteosarcoma histology image of: A) Non-tumor B) Necrotic tumor C) Viable tumor Choose the correct option. Ground truth: B) Necrotic tumor Wrong Prediction from GPT-4o C) Viable tumor The image shows dense cellular area with viable tumor cells, typical of viable osteosarcoma. In contrast, OctoTools decomposes the query into two steps by calling two vision tools to enhance visual perception. First, it calls the Image Captioner Tool to provide general description of the associated image. Then, it uses the Object Detector Tool to detect and count the baseballs. These two steps provide consistent information about the number of baseballs, thus resulting in correct answer. Step 0: Initial Plan from Query Analyzer Required skills: 1. Histopathology Knowledge: Understanding of osteosarcoma and its histological features. 2. Image Analysis: Ability to interpret H&E stained images. 3. Classification Skills: Ability to categorize images based on visual features. Relevant tools: 1. Path Generalist Classifier Tool: This tool is suitable for classifying histopathology images into predefined categories. It can be used to determine whether the image is of non-tumor, necrotic tumor, or viable tumor. Additional considerations: Ensure the options provided for classification are clear and specific. Cross-reference the tools output with expert knowledge if possible, as the tool may not always be reliable. Step 1: Action from Action Predictor Justification: The task is to classify histology image of osteosarcoma into one of three categories: Non-tumor, Necrotic tumor, or Viable tumor. The Path Generalist Classifier Tool is specifically designed for classifying histopathology images into predefined categories, making it the most suitable tool for this task. Context: Image path: tissue.jpg Sub-goal: Classify the histology image into one of the categories: Non-tumor, Necrotic tumor, or Viable tumor using the provided image path. Tool name: Path Generalist Classifier Tool 80 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Command from Command Generator Analysis: The task is to classify histology image of osteosarcoma into one of three categories: Non-tumor, Necrotic tumor, or Viable tumor. The selected tool, Path Generalist Classifier Tool, is designed to classify histopathology images based on provided options. The tool requires two inputs: the path to the image and list of classification options. The image path is provided in the context, and the classification options are specified in the query. The tools metadata confirms that it is suitable for this type of classification task, as it is designed for histopathology images and multiple-choice questions. Command: \"Necrotic tumor\", \"Viable tumor\"]) execution = tool.execute(image=\"tissue.jpg\", options=[\"Non-tumor\", Step 1: Result from Command Executor Result: Necrotic tumor Step 1: Verification from Context Verifier Completeness: The memory addresses the query by using the Path Generalist Classifier Tool to classify the histology image into one of the specified categories: Non-tumor, Necrotic tumor, or Viable tumor. The tools output indicates that the image is classified as Necrotic tumor. This directly answers the query, fulfilling the main objective of classifying the image. Inconsistencies: There are no inconsistencies in the information provided. The classification result is clear and aligns with the querys requirements. Verification needs: The Path Generalist Classifier Tool has limitations and may not always be reliable. However, the classification of Necrotic tumor seems plausible given the context. If further verification is needed, consulting histopathology expert or using additional histopathology-specific tools could be considered. Ambiguities: There are no ambiguities in the result. The classification is straightforward and matches one of the provided options. Final determination: The memory is complete and accurate enough to generate the final output. The classification tool has provided clear answer to the query, and no additional tool usage is necessary. Conclusion: STOP The final answer is summarized by the solution summarizer in the planner, given the full trajectory in the context described above. When highly specialized tool is present for its corresponding domain, in this case histopathology classification, OctoTools is able to leverage the specialized tool directly to reach the answer. Final Answer The histology image of osteosarcoma stained with hematoxylin and eosin (H&E) has been classified using the Path Generalist Classifier Tool. Based on the analysis, the image is identified as a: B) Necrotic tumor 81 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.6. Example for Scientific Reasoning"
        },
        {
            "title": "The Query",
            "content": "Question: Which of the following describes the fallacy of appeal to indignation? A) presenting two options as the only possible ones when more options exist B) attacking an argument by exaggerating, misrepresenting, or even completely fabricating parts of it C) arguing against position only based on personal feelings toward the position D) responding to charges of wrongdoing by saying other people do the same thing E) arguing that claim is true because it has not been proven false F) responding to an argument with an expression of derision instead of counter argument G) making claim based on popularity or majority opinion instead of evidence H) attacking the character or background of someone making an argument instead of his or her evidence and reasoning I) making claim seem true or false based on irrelevant information or associations Choose the correct option. Ground truth: Wrong Prediction from GPT-4o F) The fallacy of appeal to indignation involves responding to an argument with an expression of derision or outrage instead of providing logical counterargument. This fallacy focuses on expressing strong emotions rather than addressing the substance of the argument itself. In contrast, OctoTools decomposes the query into two steps by calling the knowledge retrieval tool and reasoning tool to answer the question. First, it calls the Wikipedia Knowledge Searcher Tool to retrieve related knowledge. Then it uses Generalist Solution Generator Tool to perform reasoning over the query and the knowledge retrieved. Step 0: Initial Plan from Query Analyzer Required skills: 1. Critical Thinking: To analyze and understand the descriptions of logical fallacies and identify the correct one. 2. Knowledge of Logical Fallacies: To accurately recognize and differentiate between various logical fallacies, including the appeal to indignation. 3. Decision Making: To choose the correct option from the given list based on the analysis. Relevant tools: 1. Wikipedia Knowledge Searcher Tool: This tool can be used to search for information on logical fallacies, including the appeal to indignation, to verify the correct description. It provides factual information from Wikipedia, which can be cross-referenced with the options provided. 2.Generalist Solution Generator Tool: This tool can be used to generate step-by-step analysis of each option to determine which one describes the fallacy of appeal to indignation. However, it may provide incorrect responses, so verification is necessary. considerations: the the final Additional Generalist Solution Generator Tool may provide hallucinated responses. Cross-referencing with reliable sources is recommended to confirm the correct description of the fallacy. accuracy, verified answer Ensure that for as is 82 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Action from Action Predictor Justification: The Wikipedia Knowledge Searcher Tool is the best choice for this step because it provides factual information from reliable source, which is crucial for accurately identifying the description of the fallacy of appeal to indignation. This tool can search for and retrieve specific information about logical fallacies, ensuring that the selected option is verified against authoritative content. Sub-goal: Search Wikipedia for information on the fallacy of appeal to indignation to verify which option correctly describes it. Tool name: Wikipedia Knowledge Searcher Tool Step 1: Command from Command Generator Analysis: The task is to identify which option describes the fallacy of appeal to indignation. The sub-goal is to search Wikipedia for information on this fallacy to verify the correct option. The selected tool is the Wikipedia Knowledge Searcher Tool, which requires query string as input. The query should be related to the fallacy of appeal to indignation to retrieve relevant information from Wikipedia. Command: execution = tool.execute(query=\"appeal to indignation fallac\") Step 1: Result from Command Executor Result: The fallacy of appeal to indignation refers to an argument tactic where someone tries to persuade others by provoking anger or outrage instead of presenting logical evidence, essentially using strong emotions like indignation to sway opinion rather than reasoned facts; it is considered form of appeal to emotion fallacy where the emotion being exploited is anger or outrage. Step 1: Verification from Context Verifier Completeness: The memory addresses the main objective of identifying the correct description of the fallacy. The Generalist Solution Generator Tools output aligns with the understanding of the fallacy as it involves emotional reactions rather than logical reasoning. Inconsistencies: There are no direct inconsistencies in the information provided Verification needs: The information regarding the appeal to indignation fallacy needs further verification as the current memory does not provide definitive answer. Ambiguities: The ambiguity lies in the lack of direct information about the appeal to indignation fallacy. Using the Generalist Solution Generator Tool could help clarify which option best fits the description of this fallacy. Final determination: The memory is insufficient to generate the final output as it requires reasoning over the information on the appeal to indignation fallacy. Conclusion: CONTINUE 83 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 2: Action from Action Predictor Justification: The previous attempts to use the Wikipedia Knowledge Searcher Tool did not yield direct answer to the query. The next logical step is to use the Generalist Solution Generator Tool. This tool can analyze the provided options and use its general knowledge to identify which option best describes the fallacy of appeal to indignation. Sub-goal: Use the Generalist Solution Generator Tool to analyze the provided options and determine which one best describes the fallacy of appeal to indignation. Tool name: Generalist Solution Generator Tool Step 2: Command from Command Generator Analysis: The task is to identify which option describes the fallacy of appeal The Generalist Solution Generator Tool is selected to analyze the options and determine the correct one. The tool requires prompt as input, which should include the query and options for analysis. The context provided includes the query and options, which will be used to construct the prompt for the tool. to indignation. Command: the fallacy of appeal to indignation?...\" execution = tool.execute(prompt=\"Which of the following describes Step 2: Result from Command Executor Result: The fallacy of appeal to indignation is best described by option C: arguing against position only based on personal feelings toward the position. This fallacy involves rejecting an argument or claim not because of its merits or evidence, but because of an emotional reaction or personal feelings about it. Step 2: Verification from Context Verifier Completeness: The memory does not fully address the query as the search results did not provide direct description of the appeal to indignation fallacy. The correct option from the list remains unidentified. Inconsistencies: There are no direct inconsistencies in the information provided. Verification needs: The information regarding the appeal to indignation fallacy needs further verification as the current memory does not provide definitive answer. Ambiguities: There are no significant ambiguities in the results that require further clarification. output, Final Generalist Solution Generator Tool has provided plausible and logical answer to the query. determination: The memory sufficient generate final the to is as the Conclusion: STOP When knowledge retrieval tool is present for retrieving relevant knowledge, OctoTools is able to leverage the retrieved knowledge directly to reach the answer. Final Answer Based on the analysis, option is the correct description of the fallacy of appeal to indignation, as it involves arguing against position based on personal feelings. 84 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.7. Example for Fine-grained Visual Reasoning"
        },
        {
            "title": "The Query",
            "content": "Image path: rotting kiwi.jpg Question: You are given 3 3 grid in which each cell can contain either no kiwi, one fresh kiwi, or one rotten kiwi. Every minute, any fresh kiwi that is 4-directionally adjacent to rotten kiwi also becomes rotten. What is the minimum number of minutes that must elapse until no cell has fresh kiwi? Ground truth: 4 minutes Wrong Prediction from GPT-4o To solve this, we need to track how the rot spreads from the rotten kiwi to the fresh ones: 1. Minute 1: The rotten kiwi in the bottom left corner will rot the fresh kiwi directly above it (middle left cell). 2. Minute 2: The newly rotten kiwi in the middle left cell will rot the fresh kiwi directly above it (top left cell) and the fresh kiwi to its right (middle center cell). 3. Minute 3: The rotten kiwi in the middle center cell will rot the fresh kiwi directly above it (top center cell). After 3 minutes, all fresh kiwis will be rotten. In contrast, OctoTools addresses the query by first calling Image Captioner Tool to provide general description of the associated image. This step is essential as the mistake from the GPT-4o is because of the wrong perception of the image, with the Image Captioner Tool, the reasoning over the rotting process is also based on the detailed description of the image, resulting in correct answer. Step 0: Initial Plan from Query Analyzer Required skills: 1. Image Analysis: To interpret the grid and identify the state of each kiwi (fresh or rotten). 2. Logical Reasoning: To simulate the process of fresh kiwis becoming rotten over time and determine the minimum time required. 3. Problem Solving: To apply the rules and constraints effectively to reach the correct answer. Relevant tools: 1. Image Captioner Tool: To generate description of the image, identifying the state of each kiwi, which aids in understanding the initial setup. 2. Generalist Solution Generator Tool: To simulate the process of kiwis turning rotten and calculate the minimum time required, using logical reasoning based on the image description. Additional considerations: Ensure the image is accurately interpreted to correctly identify the initial state of each kiwi. Logical reasoning should be applied carefully to simulate the process over time. Verify the final answer against the provided choices. 85 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Action from Action Predictor Justification: The Image Captioner Tool is the most appropriate choice for the next step because it can generate detailed description of the image, which is crucial for understanding the initial state of the kiwis in the grid. This understanding is necessary to simulate the process of fresh kiwis becoming rotten and to determine the minimum time required. The tools ability to describe the image will provide the foundational information needed for logical reasoning in subsequent steps. Context: Image path: rotting kiwi.jpg Sub-goal: Generate detailed description of the image rotting kiwi.jpg to identify the initial state of each kiwi in the 3x3 grid. Tool name: Image Captioner Tool Step 1: Command from Command Generator Analysis: The task requires generating detailed description of an image to identify the initial state of each kiwi in 3x3 grid. The selected tool, Image Captioner Tool, is designed to generate captions for images. The tools input requires an image path and an optional prompt. The context provides the image path, which is rotting kiwi.jpg. The sub-goal is to generate detailed description of this image, which aligns with the tools capability to describe images in detail. Therefore, the command will use the image path and prompt to guide the captioning process. Explanation: The command uses the Image Captioner Tool to generate detailed description of the image. The image path is provided directly from the context, and prompt is used to ensure the tool focuses on describing the initial state of each kiwi in the grid. This setup aligns with the tools input requirements and the tasks sub-goal. Command: the initial state of each kiwi in the 3x3 grid in detail.) execution = tool.execute(image=rotting kiwi.jpg, prompt=Describe Step 1: Result from Command Executor Result: The 3x3 grid contains the following kiwis: Top Row: Left: Empty Middle: Empty Right: kiwi with brown outer skin and green interior with black seeds. Middle Row: Left: kiwi with brown outer skin and green interior with black seeds. Middle: kiwi with brown outer skin and green interior with black seeds. Right: kiwi with brown outer skin and green interior with black seeds. Bottom Row: Left: kiwi with brown outer skin and green interior with black seeds, marked with red X. Middle: Empty Right: Empty 86 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Step 1: Verification from Context Verifier The memory provides detailed description of the initial state of each kiwi in the 3x3 grid. The top row has one fresh kiwi, the middle row has three fresh kiwis, and the bottom row has one rotten kiwi. The task is to determine how many minutes it will take for all fresh kiwis to become rotten.The memory is complete and accurate, and no additional tool usage is necessary to determine the answer. Conclusion: STOP The final answer is summarized by the solution summarizer in the planner, given the full trajectory in the context described above. This two-step flow overcomes the base GPT-4o models limitation in visual perception."
        },
        {
            "title": "Final Answer",
            "content": "Detailed analysis: To solve the problem, we need to determine how many minutes it takes for all fresh kiwis to become rotten, given the initial state of the grid."
        },
        {
            "title": "Initial Grid Analysis",
            "content": "Top Row: Left: Empty Middle: Empty Right: Fresh Kiwi Middle Row: Left: Fresh Kiwi Middle: Fresh Kiwi Right: Fresh Kiwi Bottom Row: Left: Rotten Kiwi Middle: Empty Right: Empty Process 1. Minute 1: The rotten kiwi at the bottom left will cause the fresh kiwi directly above it (middle row, left) to become rotten. 2. Minute 2: The newly rotten kiwi (middle row, left) will cause the adjacent fresh kiwis (middle row, middle) to become rotten. The fresh kiwi in the top row, right, is not adjacent to any rotten kiwi yet. 3. Minute 3: The rotten kiwi (middle row, middle) will cause the adjacent fresh kiwi (middle row, right) to become rotten. The fresh kiwi in the top row, right, is still not adjacent to any rotten kiwi. 4. Minute 4: The rotten kiwi (middle row, right) will cause the fresh kiwi in the top row, right, to become rotten. Conclusion: It takes 4 minutes for all fresh kiwis to become rotten. 87 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning F.8. Exploration Example for Literature Review"
        },
        {
            "title": "The Query",
            "content": "Question: What are the research trends in tool agents with large language models for scientific discovery? Please consider the latest literature from ArXiv, PubMed, Nature, and news sources. Final Answer (Test date: Jan 30 2025) 1. Summary: The query sought to identify the latest research trends in tool agents with large language models (LLMs) for scientific discovery, drawing from sources like ArXiv, PubMed, Nature, and related news outlets. The analysis revealed growing interest in integrating LLMs with various domains, emphasizing their role in enhancing scientific research, education, healthcare, and more. 2. Detailed Analysis: Step 1: ArXiv Paper Search - Tool Used: ArXiv Paper Searcher Tool - Purpose: To find recent academic papers on tool agents with LLMs. - Key Results: - Papers discussed the application of LLMs in multi-agent systems, UAVs, education, REST API testing, and more. - Notable papers include AI Agent for Education, UAVs Meet LLMs, and Reasoning Language Models: Blueprint. - Contribution: Provided comprehensive view of how LLMs are being utilized across different fields, highlighting their versatility and potential for innovation. Step 2: PubMed Article Search - Tool Used: Pubmed Search Tool - Purpose: To identify recent articles on LLMs in scientific discovery. - Key Results: - Articles focused on LLMs in healthcare, such as mental health support and vaccination information. - Highlighted the integration of LLMs in educational tools and their potential biases. - Contribution: Offered insights into the application of LLMs in healthcare and education, emphasizing the need for accuracy and equity. Step 3: Nature News Fetch - Tool Used: Nature News Fetcher Tool - Purpose: To gather recent news articles on LLMs and tool agents. - Key Results: - Articles discussed the development of AI models like DeepSeek and their impact on scientific research. - Highlighted the role of AI in various scientific advancements and societal impacts. - Contribution: Provided context on the broader implications of LLMs in scientific research and public perception. 3. Key Findings: - LLMs are increasingly being integrated into multi-agent systems, enhancing capabilities in fields like education, healthcare, and UAV operations. - There is significant focus on improving the reasoning and problem-solving abilities of LLMs, as seen in the development of reasoning language models. - The application of LLMs in healthcare is promising but requires careful consideration of biases and accuracy. - News articles highlight the rapid advancements in AI models and their potential to transform scientific research. 88 OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning Final Answer (Continued) 4. Answer to the Query: The latest research trends in tool agents with large language models for scientific discovery include: - The integration of LLMs into multi-agent systems to enhance collaborative problem-solving and decision-making. - The use of LLMs in healthcare for tasks like mental health support and vaccination information, with focus on ensuring accuracy and equity. - The development of advanced reasoning models to improve the problem-solving capabilities of LLMs. - The exploration of LLMs in educational contexts to support personalized learning and cognitive development. 5. Additional Insights: - While LLMs offer significant potential, there are challenges related to computational overhead, biases, and the need for domain-specific adaptations. - The ethical implications of LLMs, particularly in healthcare and education, require ongoing attention to ensure equitable access and outcomes. 6. Conclusion: The integration of large language models into tool agents is rapidly evolving field with significant implications for scientific discovery. These models are enhancing capabilities across various domains, from healthcare to education, while also presenting challenges that need to be addressed. Future research should focus on optimizing these models for specific applications, ensuring ethical use, and exploring their full potential in scientific innovation."
        }
    ],
    "affiliations": [
        "Stanford University"
    ]
}