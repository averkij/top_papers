{
    "paper_title": "Learning Heterogeneous Mixture of Scene Experts for Large-scale Neural Radiance Fields",
    "authors": [
        "Zhenxing Mi",
        "Ping Yin",
        "Xue Xiao",
        "Dan Xu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent NeRF methods on large-scale scenes have underlined the importance of scene decomposition for scalable NeRFs. Although achieving reasonable scalability, there are several critical problems remaining unexplored, i.e., learnable decomposition, modeling scene heterogeneity, and modeling efficiency. In this paper, we introduce Switch-NeRF++, a Heterogeneous Mixture of Hash Experts (HMoHE) network that addresses these challenges within a unified framework. It is a highly scalable NeRF that learns heterogeneous decomposition and heterogeneous NeRFs efficiently for large-scale scenes in an end-to-end manner. In our framework, a gating network learns to decomposes scenes and allocates 3D points to specialized NeRF experts. This gating network is co-optimized with the experts, by our proposed Sparsely Gated Mixture of Experts (MoE) NeRF framework. We incorporate a hash-based gating network and distinct heterogeneous hash experts. The hash-based gating efficiently learns the decomposition of the large-scale scene. The distinct heterogeneous hash experts consist of hash grids of different resolution ranges, enabling effective learning of the heterogeneous representation of different scene parts. These design choices make our framework an end-to-end and highly scalable NeRF solution for real-world large-scale scene modeling to achieve both quality and efficiency. We evaluate our accuracy and scalability on existing large-scale NeRF datasets and a new dataset with very large-scale scenes ($>6.5km^2$) from UrbanBIS. Extensive experiments demonstrate that our approach can be easily scaled to various large-scale scenes and achieve state-of-the-art scene rendering accuracy. Furthermore, our method exhibits significant efficiency, with an 8x acceleration in training and a 16x acceleration in rendering compared to Switch-NeRF. Codes will be released in https://github.com/MiZhenxing/Switch-NeRF."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 ] . [ 1 5 0 0 2 0 . 5 0 5 2 : r JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 1 Learning Heterogeneous Mixture of Scene Experts for Large-scale Neural Radiance Fields Zhenxing Mi, Ping Yin, Xue Xiao, and Dan Xu Member, IEEE AbstractRecent Neural Radiance Field (NeRF) methods on large-scale scenes have demonstrated promising results and underlined the importance of scene decomposition for scalable NeRFs. Although these methods achieved reasonable scalability, there are several critical problems remaining unexplored in the existing large-scale NeRF modeling methods, i.e., learnable decomposition, modeling scene heterogeneity, and modeling efficiency. In this paper, we introduce Switch-NeRF++, Heterogeneous Mixture of Hash Experts (HMoHE) network that addresses these challenges within unified framework. Our framework is highly scalable NeRF that learns heterogeneous decomposition and heterogeneous Neural Radiance Fields efficiently for large-scale scenes in an end-to-end manner. In our framework, gating network learns to decomposes scenes into partitions and allocates 3D points to specialized NeRF experts. This gating network is co-optimized with the experts, by our proposed Sparsely Gated Mixture of Experts (MoE) NeRF framework. Our network architecture incorporates hash-based gating network and distinct heterogeneous hash experts. The hash-based gating efficiently learns the decomposition of the large-scale scene. The distinct heterogeneous hash experts consist of hash grids of different resolution ranges. This enables effective learning of the heterogeneous representation of different decomposed scene parts within large-scale complex scenes. These design choices make our framework an end-to-end and highly scalable NeRF solution for real-world large-scale scene modeling to achieve both quality and efficiency. We evaluate our accuracy and scalability on existing large-scale NeRF datasets. Additionally, we also introduce new dataset with very large-scale scenes (> 6.5km2) from UrbanBIS. Extensive experiments demonstrate that our approach can be easily scaled to various large-scale scenes and achieve state-of-the-art scene rendering accuracy. Furthermore, our method exhibits significant efficiency gains, with an 8x acceleration in training and 16x acceleration in rendering compared to the best-performing competitor Switch-NeRF. The codes and trained models will be released in https://github.com/MiZhenxing/Switch-NeRF. Index TermsNeural Radiance Fields; Mixture of Experts; Large-scale 3D reconstruction; Novel view synthesis"
        },
        {
            "title": "1 INTRODUCTION",
            "content": "Neural Radiance Fields (NeRF) [1] have shown the powerfulness for high-fidelity 3D scene modeling. Recent methods [2], [3], [4] have scaled NeRF to large-scale scenes with thousands of high-resolution images. The scalability of them essentially comes from the decomposition of the 3D scenes. Several sub-NeRF-networks handle different partitions of large scene. Mega-NeRF [2] and Block-NeRF [3] both incorporate hand-crafted decomposition rules for different scenes. They decompose 3D scenes by clustering based on 3D physical distances or street blocks. Despite the promising performances achieved by current large-scale NeRF methods, several critical challenges remain unexplored. Firstly, design universal decomposition rule is extremely challenging for different large-scale scenes. The real-world large-scale scenes tend to have very different and complex scene structures. Hand-crafted rules will inevitably brings adaptation issues for distinct scenarios. Moreover, the non-learnable nature of hand-crafted decomposition restricts the networks ability to optimize the scene decomposition and radiance fields together within an end-to-end framework. To handle this problem, we need learnable decomposition method to automatically learn different decomposition for different scenes and we can optimize the Zhenxing Mi and Dan Xu are with the Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR. E-mail: zmiaa@connect.ust.hk, danxu@cse.ust.hk Ping Yin and Xue Xiao are with Inspur Cloud Information Technology Co, Ltd. E-mail: yinping@inspur.com, xiaoxue@inspur.com decomposition together with the scene representation. Secondly, large-scale scene is typically irregular and complex, with different scene parts exhibiting diverse appearance and geometry distributions, which requires heterogeneous modeling capabilities to produce high-quality scene representation. However, current large-scale NeRF methods often employ identical networks, such as Multilayer Perceptrons (MLPs), for different parts of the scene, lacking explicit designs for heterogeneous modeling. Thirdly, the long training time and high GPU memory usage of existing methods is severe bottleneck that limits their scalability when dealing with much larger scenes. Although several methods such as Instant-NGP [5] have been proposed to enhance the NeRF representation and accelerate the NeRF training on smalland large-scale scenes [6], [7], [8], [9], they still attempt to fit an entire scene into single global network, overlooking the crucial aspect of heterogeneous scene representation from distinct scene decompositions. Consequently, these methods suffer from clear limitations in scalability and representation effectiveness, particularly when dealing with very large scenes. In this paper, to simultaneously tackle these critical challenges, we propose novel and highly scalable Heterogeneous Mixture of Hash Experts framework for NeRF, coined as Switch-NeRF++. The fundamental designs of SwitchNeRF++ are fourfold. 1) An end-to-end framework to learn scene decomposition in trainable manner, together with the scene representation. 2) An efficient hash-based gating network to learn scene decompositions. 3) heterogeneous JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2 Fig. 1: The birds-eye view of scene in UrbanBIS [10], rendered using INGP [5] and our Switch-NeRF++, showcasing the impressive scalability of our approach. This scene contains 13k high-quality images, capturing an urban region of around 6.5km2. Experiments on this scene demonstrate the superiority of our method in scaling to large-scale urban scenes with exceptional rendering quality. modeling of scene decomposition and each decomposed scene part. 4) highly scalable and efficient learning framework that can handle extremely large-scale scenes. With these key designs, Switch-NeRF++ can handle large-scale complex scenes and ensure high modeling performance in terms of scalability, representation quality, and efficiency. More specifically, in Switch-NeRF++, we design: An sparse framework for unified optimization of scene decomposition and neural radiance fields. We introduce an end-to-end sparse framework that unifies optimization of scene decomposition and Neural Radiance Fields by learnable gating mechanism. It employs trainable gating network to dynamically select and sparsely activate specialized sub-networks for individual 3D points. The whole network is trained end-to-end without heuristic supervision and priors of the 3D scene shape or the distribution of scene images. This enables scalable and generic modeling of large-scale scenes. critical challenge of training our network end-to-end lies in the discrete selection operation of sub-networks. This operation is not differentiable and the gradients cannot be back-propagated through it into the gating network. Inspired by Sparsely-Gated Mixture-of-Experts (MoE) [11], we address this problem by multiply gate values to the expert outputs, adding connection between the gating network and experts. For the scene representation, distinct scene regions are handled by different NeRF experts (sub-networks). The gating network routes 3D points to relevant experts based on gate values. unified output head is designed to unify the prediction of multiple NeRF experts. This head impose feature alignment among the implicit features of NeRF experts, resolving inconsistencies among different partitions. Heterogeneous Mixture of Hash Experts (HMoHE) to model heterogeneous scene representations. Previous large-scale NeRF methods typically use the same network structure for different sub-networks. However, different parts of the large-scale scenes have heterogeneous and diverse distributions, which need heterogeneous representations. In our framework, the learned decomposition of the entire scene are represented by mixture of heterogeneous hash experts (HMoHE). Each decomposed scene part is handled by distinct expert network. To ensure the diversity and flexibility of representation, we design the hash experts as heterogeneous. We make the experts exploit diverse resolution ranges, allowing our network to select suitable resolution range for each scene part. hash-based gating network to effectively learn the scene decomposition. The gating network dispatches 3D points into different hash-encoding experts, enabling each expert to specialize in representing distinct decomposed partition of the scene and to achieve stronger representation. The hashbased gating network is more efficient than MLP-based gating [12] to make the training of gating align well with our hash-encoding experts. The hash-based gating network and HMoHE together achieve accurate and efficient heterogeneous scene representations for large-scale scenes. Effcient implement of hash-based gating and dispatching. To implement HMoHE more efficiently, we seamlessly integrate the dispatching of 3D points into the CUDA implementation of hash. We merge the hashing and dispatching of points together and avoid extra allocation of memories. This ensures that the point dispatching does not significantly impact the training efficiency. Moreover, apart from existing challenging large-scale datasets, we adapt very large scene from UrbanBIS [10]. This scene enables us to assess the scalability of our approach more comprehensively. Our results show that Switch-NeRF++ achieves remarkably higher rendering quality than existing best-performing methods. These results clearly verify the effectiveness and high scalability of our method for large-scale scenes. This paper significantly extends our previous ICLR version, i.e. Switch-NeRF [4]. Specifically, this work introduces brand new design of Heterogeneous Mixture of Hash framework. We redesign the gating network and experts in Switch-NeRF exploiting highly efficient hash networks. We propose to learn heterogeneous decomposition and representation with the hash gating network and heterogeneous experts. For the point dispatching, we integrate it into the hash operation. We also adapt new large-scale scene for better evaluation. Comparing to Switch-NeRF, our new framework effectively models the heterogeneous representation of large-scale scenes, and significantly improves the accuracy and efficiency. The proposed method achieves an 8x acceleration in training and 16x acceleration in rendering compared to Switch-NeRF. Our contributions are summarized below: We introduce novel framework for large-scale neural radiance fields (NeRF). It integrates learnable decomposition, heterogeneous scene decomposition and representaJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST tion, and efficient modeling in an end-to-end NeRF model, which is general applicable and does not need handcrafted decomposition and composition rules. We design an efficient hash-based gating network to automatically learn efficient scene decomposition, and model scene partitions by the proposed Heterogeneous Mixture of Hash Experts (HMoHE). The hash-based gating and HMoHE are jointly learned to achieve heterogeneous and highly scalable NeRF representations of large-scale scenes. We present efficient implementation of the framework to make it highly scalable and efficient learning framework that can handle extremely large-scale scenes. We adapt new dataset for benchmarking highly scalable NeRF scene modeling. Our NeRF framework achieves significant improvement in terms of scalability, accuracy, and efficiency compared to the best-performing methods such as SwitchNeRF."
        },
        {
            "title": "2 RELATED WORK\n3D reconstruction from multiple images. 3D reconstruction\nfrom multiple images has been a long-standing research\ntopic in computer vision. A classic pipeline contains sev-\neral steps. The first step is to extract feature points from\nmultiple images by methods such as SIFT [13] and match\ncorresponding points across different images [14], [15], [16].\nThen the corresponding points are used in Structure-from-\nmotion (SFM) methods [17], [18], [19] to recover the camera\nposes. After recovering camera poses, Multi-view Stereo\n(MVS) methods can be applied on the images and cam-\neras to recover the dense geometry of the scene, using\noptimization-based methods [20], [21], [22] or deeplearning-\nbased methods [23], [23], [24], [25], [26], [27].\nNeural Radiance Fields. Neural Radiance Fields method\n(NeRF) [1] are proposed to encode a 3D scene into an MLP\nnetwork for novel view synthesis, with the multiple images\nand their cameras as input. The implicit framework of\nNeRF is very simple and effective, which have been widely\napplied to many 3D reconstruction tasks.",
            "content": "Some NeRF variants apply NeRF on more challenging scenes. NeRF++ [28] extends NeRF to unbounded scenes by separating scene into foreground and background, and applying the inverted sphere parameterization on the background. NeRF in the wild [29] attaches an appearance embedding to each image. It conditions the NeRF network with these appearance embeddings to model the appearance variation in each image in the wild environment. MipNeRF [30] and Mip-NeRF 360 [31] address sampling and aliasing of bounded and 360 degree scenes by designing new scale-aware positional encoding. DSNeRF [32] uses sparse depth from colmap to regularize and speed up NeRF training. SPARF [33] and CVT-xRF [34] largely reduce the view number used in NeRF training and produce highquality NeRF with sparse image inputs. Although the original NeRF targets novel view synthesis, it is flexible 3D representation encoding 3D geometry. Several methods have focus on improving the geometry quality of NeRF for accurate 3D surface reconstruction [35], [36]. NeuS [35] represents surface as signed distance function (SDF) and learns SDF field by volume rendering. Neuralangelo [36] recovers high-quality surface details by 3 higher-order derivatives and coarse-to-fine optimization on the hash grids. NeRF methods typically need camera parameters as input. These cameras are usually predicted by SFM methods such as Colmap [37]. Several methods try to estimate camera parameters together with the neural radiance fields. NeRF [38] treats camera parameters as trainable model parameters and jointly cameras in NeRF training. BARF [39] finds that use coarse-to-fine positional encoding in training helps the convergence of camera parameters. The training and inference speed of NeRF are critical in real-world application. Many methods have been proposed for fast training and real-time rendering of NeRF. PlenOctrees [40], FastNeRF [41] and Kilo-NeRF [42] mainly speed up inference of NeRF. There are also methods speed up both the training and rendering of NeRF, such as the DVGO [6], Plenoxels [43], Instant-NGP [5], TensoRF [8] and 3D Gaussian Splatting [44]. Instant-NGP uses multiresolution hash encoding to encode scene into set of hash maps by interpolating trainable hash features. TensoRF [8] represents 3D radiance field using trainable 2D plane features and 1D feature vectors. Different from typical NeRF methods using volume rendering, 3D Gaussian Splatting (3DGS) [44] used 3D Gaussians to represent 3D scene. It renders images by projection and α-blending, which is very fast and support high-resolution real-time rendering. 3DGS needs point cloud from SfM or random initialization to initialize 3D Gaussians. The original NeRF needs to be trained on each scene and cannot generalize across different scenes. Pixel-NeRF [45] proposes to include image features as an additional condition and trains the model on set of different scenes. MVSNeRF [46], NerfingMVS and IBRNet [47] et. al. handle unsupervised Multi-view Stereo problem by combining the volume rendering and Multi-view Stereo together. These methods take single view or Multi-view image features as input and can generalize to different scenes. The flexible NeRF representation have been applied to 3D generation [48], [49], [50] and editing tasks [51], [52]. EG3D [48] simplify the NeRF network into triplane feature maps, which has regular shapes and is easy for generation. LRM [49] propose to use large transformer to generate triplanes from single image. The above mentioned reconstruction methods typically works on small scale scenes. Our method targets to scale NeRF methods to large-scale scenes and handle the problems of learnable decomposition, and heterogeneous, scalable and efficient scene modeling for large-scale NeRF. Large-scale Neural Radiance Fields. When applying on large-scale NeRF, critical problem of NeRF is that handling large data volume needs scalable framework and more network parameters. Recent large-scale NeRF methods mainly focus on decompose large-scale scene into several parts and handle each part by sub-network. Mega-NeRF [2] and Block-NeRF [3] successfully scale NeRF to urban-scale scenes sparsely by scene decomposition. Although achieving impressive accuracy, their scene decomposition is mainly conducted by heuristic hand-crafted rules. Mega-NeRF [2] places several centroids in scene and divides the 3D points in the scene by 3D distances to these centroids. Block-NeRF [3] divides the training images JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 4 Fig. 2: Large-scale NeRFs with different decomposition methods. Dotted lines indicate non-differentiable operations, while solid lines represent differentiable operations that can back-propagate gradients in training. Mega-NeRF [2] divides scene by clustering image pixels by 3D distances. Block-NeRF [3] divide images sets according to street blocks, which is actually based on camera distributions. In both kinds of methods, the decomposition are hand-crafted heuristics rules and not trainable. They require separate training for their sub-networks. Switch-NeRF introduces unified framework where scene decomposition is learned automatically via gating network, enabling end-to-end training of the entire framework. However, Switch-NeRF designs homogeneous experts (MLPs) with the same structures, which learns homogeneous representation of the scene. In contrast, Switch-NeRF++ employs efficient hash network as the gate network and designs heterogeneous hash experts to learn heterogeneous decomposition and representation of large-scale scene. into several subsets according to street blocks. These two methods train the sub-networks separately. Therefore, they need composition strategies such as distance-based weights to merge the rendering results. Different from methods using handcrafted decomposition methods, Switch-NeRF [4] firstly proposes an large-scale NeRF framework that automatically learns scene decomposition together with the Neural Radiance Fields in an end-to-end manner. It designs sparse network structure containing gating network and several NeRF experts, base on the mechanism of Mixture of Experts (MoE) [11]. It requires no prior knowledge of scene structures and decomposition rules. Our method extends from Switch-NeRF with brand-new designs of the hashbased network, heterogeneous experts and efficient hash dispatching. Our method remarkably improving the scalability, efficiency and accuracy of large-scale NeRFs compared to best-performing methods. Some other methods [9], [53] also use plane features and hash encodings on large-scale scenes. However, they still encode large-scale scene into global network so their scalability is still limited. The Gaussian splatting [54] has inspired large-scale NeRFs such as the Hierarchical-3DGaussians [55], CityGaussian [56], DoGaussian [57], VastGaussian [58], PyGS [59], etc. due to its efficiency. The Hierarchical-3D-Gaussians [55] uses divide-and-conquer method that trains very large scenes in independent chunks. It organizes the chunks into hierarchy and provides an efficient Level-of-Detail (LOD) rendering. CityGaussian [56] and VastGaussian [58] also use divide-andconquer method to manually divides the scene into smaller cells. In this paper, our method focuses on scaling to largescale scenes by learning efficient scene decomposition and representations. Our method explores the better use of the multi-scale nature of grids to adaptively model the multiscale nature of 3D scenes. Mixture of Experts (MoE). The methodology of Mixture of Experts has long history for scaling the model size [60], [61]. Recent applications of MoE in deeplearning mainly follow the design of [11]. It replaces the feed-forward networks in language model by Mixture-of-Experts layers. The experts are activated sparsely by Top-k gating network. Each sample will only be dispatched to experts while is typically set as 2 and is much smaller that the total number of experts. In order to avoids imbalanced training and training collapse, it regularize gate values by an gate loss which can make the training of different experts more balanced. The MoE network is extensively applied for Natural Language Processing (NLP) [12], [62] and Vision [63], [64] tasks to scale the capacity and capability of neural networks. GShard [62] standardize the dispatching operations by Einops [62], [65]. It supports local dispatching and parallel gating by designing simpler balancing loss and defining the capacity factor for experts. The value of in MoE gating directly influence the sparsity, efficiency and accuracy of MoE. Top-2 typically can get good accuracy while maintaining sparsity [11], [62]. Switch Transformer [12] has investigated into the training recipes of MoE in NLP tasks. It concludes that under carefully designed training setting, Top-2 operation in MoE is not necessary. Top-1 in MoE can already get high accuracy while largely decrease the cost of computation and communication for sample dispatching. Several MoE methods have investigated different JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 Fig. 3: The framework overview of Switch-NeRF and Switch-NeRF++ for large-scale scene modeling. 3D scene point is first fed into the gating network to obtain feature encoding fg. fg is then sent to small MLP head to predict gating values. The Top-1 index of the gate values is used in 3D point dispatching that determines which hash expert should be selected for the input point. In this way, the entire scene can be decomposed into different partitions. Then is dispatched into its corresponding expert to encode its distinct distribution into an expert encoding Ei(x). Then we multiply the gate value Gi(x) on Ei(x) and obtain the final expert output ˆEi(x), which is further fed into small MLP head to predict the point density σ and point color c. The spherical harmonics encoding (i.e., SH) of direction d, and the appearance embedding (i.e., AE) are used for view-dependent prediction of color c. In Switch-NeRF, the gating network and the NeRF experts are all MLP-based networks, which learns homo. In contrast, in Switch-NeRF++, we leverage the efficient Hash-based Gating Network to dispatch 3D points. Furthermore, we design heterogeneous hash Heterogeneous Hash experts which have different scale ranges, to explicitly model the heterogeneous distribution of the large-scale scene. gating mechanisms, such as Hash Routing [66], BASE [67] and Expert Choice Routing [68]. Since MoE is typically used to scale up deep learning models, it is often trained on large number of GPUs. This poses challenges to the efficient implementation of MoE and the designs of large-scale training system. Mesh-TensorFlow [69] provides multiple node implementation of MoE base on TensorFlow. Deepspeed [70] uses their efficient inference and training system to train MoE at scale and proposes residual MoE design. Tutel [71] introduces optimized parallelism strategies and CUDA kernels to train large-scale MoE systems. The dispatching operation of Switch-NeRF is based on Tutel kernels while Switch-NeRF designs the full dispatching operation to improve the model accuracy. In Switch-NeRF++, we innovatively merge the dispatching into the hash operation and largely decrease the computation and memory cost of our MoE system. Fig. 3a and Fig. 3b show the structure of Switch-NeRF and Switch-NeRF++ respectively. Let denote 3D point and denote its direction. is fed into gating network G. In Switch-NeRF, is an MLP network to map point features into gate values G(x) for point x. In Switch-NeRF++, is multi-resolution hash encoding [5]. It looks up feature encoding fg in the hash encoding by computing hash value of x. small MLP uses fg to predict gating values G(x) for point x. According to G(x), we use Top-1 operation to select an expert and send into E, which is an larger MLP network in Switch-NeRF and multi-resolution hash encoding with distinct resolution range in SwitchNeRF++. computes feature fe for point x, which is then passed to small MLP head to predict the point density σ and point color c. We add additional appearance embedding AE [2], [29] to capture view-dependent appearance when predicting the color."
        },
        {
            "title": "3 SWITCH-NERF++",
            "content": "Our Switch-NeRF++ learns to encode large-scale scene into heterogeneous, efficient and scalable Mixture of Hash Experts. Fig. 3 is the overview of the framework in which"
        },
        {
            "title": "3.1 Trainable Gating Network\nThe gating network G is pivotal to our method, as it learns\nthe scene decomposition in training. Different previous MoE\nmethods [11], [62] that employs different gating networks in\ndifferent network layers, our network only leverages one",
            "content": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 6 Fig. 4: (a) detailed illustration of the MLP-based gating network with an MLP expert in Switch-NeRF. (b) detailed illustration of the hash-based gating network and hash expert in Switch-NeRF++. An input first goes through the gating network. Then it goes through selected expert and the small prediction heads. gating network. This design choice stems from the fact that applying more gating networks on massive volume of 3D points in NeRF optimization will largely increase the memory and computation cost. Our experiments also show that more gating networks are not necessary for better decomposition and reconstruction accuracy. Switch-NeRF employs an MLP network as its gating network. In contrast, Switch-NeRF++ leverages multiresolution hash encoding [5] as G, which is powerful 3D network that can map 3D point into gate values G(x) and learn the scene decomposition more efficiently. Specifically, in Switch-NeRF++, the gating network consists of hash operation Hash(). For an input 3D point x, it first computes hash index h(x) for and fetches feature fg for from the hash encoding via the index. small MLP is used to predict gate values G(x) from fg. The gate values G(x) are normalized into an n-dimensional probability distribution via Softmax, with each scalar component G(x)i indicating the likelihood of activating the i-th NeRF expert. We derive the hash expert index corresponding to the chosen expert by applying Top-1 operation on this distribution. is then dispatched into the hash expert Ei. The gating procedure of in Switch-NeRF is: i, G(x)i = Top-1(Softmax(MLP(x))), (1) The gating procedure of in Switch-NeRF++ is: i, G(x)i = Top-1(Softmax(MLP(Hash(x)))), (2) where is the selected expert index, and G(x)i is the corresponding gate value. The input is routed to the chosen expert Ei, where it is processed to produce the output Ei(x). In this way, the gating network can perform decomposition of the scene into partitions, and each partition can be represented by distinct expert. The experts final output E(x) is computed by multiplying the output of Ei with its corresponding gate value: E(x) = G(x)iEi(x). (3) This multiplication facilitates the gradient flowing through the gating network, enabling joint optimization of both the experts and the gating network during backpropagation. Consequently, the framework can inherently learn scene decomposition through direct gradient-based training. The use of hash encoding as the gating network in Switch-NeRF++ instead of pure MLP can provide us with two advantages. The first is that it is much more efficient than wide MLP head used in previous works [11]. The second is that it is more consistent with our hash experts and the training of gating aligns well with the hash experts. It also produces clearly higher accuracy."
        },
        {
            "title": "3.2 Experts for Large Scene Representations",
            "content": "MLP-based NeRF Expert Network. Switch-NeRF employs collection of MLP experts{Ei}n i=1, which provide main network parameters to encode scene representation. As illustrated in Fig. 4a, these experts in Switch-NeRF adopt deep MLP structure with skip connection, aligning with the core structure design of the vanilla NeRF. The gating network dynamically assigns subsets of 3D points to individual experts. For each 3D point in an expert E, the resulting feature E(x) is generated by the experts MLP output multiplied by the corresponding gate value. This feature is then passed unfied prediction head to drive predictions for both the density σ and the color of x. Hash-based NeRF Expert Network. In Switch-NeRF++, we efficiently learn the representation of large-scale scene by our heterogeneous mixture of hash experts (HMoHE). The detailed network structure of the hash expert is shown in Fig. 4b. The hash experts are set of hash encodings {Ei}n i=1 with different resolution ranges, and they are the main networks to learn representation of large-scale 3D scene. For 3D point x, we use the gating network to obtain its corresponding expert Ei and gating value Gi. Then, is input into Ei to extract feature encoding. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 7 experts by setting minimum and maximum resolutions for each expert. Unified Head. After generating features of 3D samples from experts, we employ unified prediction head to predict the density and color for all the samples. Fig. 4a and Fig. 4b depict the detailed architectures of the unified head in Switch-NeRF and Switch-NeRF++, respectively. The unified head facilitates the sparse framework to encode consistent and unified representations for the different partitions in the entire scene. In the prediction head, small MLP network is employed to precess the expert output E(x) and predict σ and color c. The E(x) is augmented by concatenating trainable appearance embedding AE, to model photometric and environmental variations across training images [29]."
        },
        {
            "title": "3.3 Joint Optimization Losses",
            "content": "We jointly learn the hash-based gating network and HMoHE scene representation with several losses. Rendering loss. Our large-scale NeRF framework uses the rendering loss for NeRF optimization [1] as primary loss. For training pixel, we sample points {xi}N i=1 along its viewing ray and predict the density σi and color ci for each point xi by our network. The final color ˆC(r) is predicted by the volume rendering [1] along the ray as ˆC(r) = (cid:80)N j=1 σjδj), where δi is the distance between neighboring points along r. Let be the set of rays in training batch. The rendering loss Lr is the Mean Squared Error (MSE) between ˆC(r) and the ground truth C(r): i=1 Ti(1 exp(σiδi))ci, with Ti = exp( (cid:80)i1 Lr = (cid:88) rR (cid:13) ˆC(r) C(r) (cid:13) (cid:13) (cid:13) 2 (cid:13) (cid:13) 2 . (4) Gating balance loss. Together with Lr, we also employ the gating balance loss commonly used in MoE methods [62]. This loss encourages the balanced dispatching of points into different hash experts in order to balance the expert training and utilization. Let be the expert number and fi be the fraction of points dispatched into an expert Ei. We have (cid:80) fi = 1. Then, if (cid:80) 2 is minimized, the gating is ideally balanced. In order to make (cid:80) 2 differentiable for training, as in [62], we replace fi with soft version pi which is the fraction of gate values dispatched to Ei. The gating balance loss Lb is defined as Lb = (cid:80) figi. Lb is minimized as 1 if the gating is balanced. Let λ be the weight for the gating balance loss, the overall loss Lo is: Lo = Lr + λLb. (5)"
        },
        {
            "title": "3.4 Unbounded Scene",
            "content": "Real-world large-scale scenes are usually unbounded, which poses challenges in point sampling and grid definition. For MLP-based Switch-NeRF, we use method similar to NeRF++ [28] and Mega-NeRF [2] to divide largescale scene into foreground and background. In the foreground region, we use cascade sampling similar in NeRF [1]. In the background region, we use the inverse sphere parameterization similar in NeRF++ [28] to handling arbitrary and large depth ranges. For hash-based Switch-NeRF++, the hash encodings are defined on grid in bounded 3D space. In the foreground Fig. 5: detailed illustration of our pyramid design of resolution ranges of the heterogeneous experts in SwitchNeRF++. Different experts have different grid resolution ranges from coarse to fine, making the network cover wide range of resolutions to capture the diverse data distributions. The ranges are controlled by setting the minimum and maximum resolutions for the hash grids in each expert. The final output of the hash expert ˆEi(x) can be written as: ˆEi(x) = GiEi(x), where Gi is used to help train the hash-based gating network. The hash experts are sparse because we only select one expert for 3D point. This can decouple the network capacity from the computation needed for each point. Since each expert is designed to have different resolution ranges, it can capture the details of regions of quite different distributions. The capacity of the whole network can be easily scaled by adjusting the NeRF expert number n. Therefore, our Switch-NeRF++ is highly scalable to model various scales without large increase in computation. Pyramid heterogeneous expert design. In Switch-NeRF, the MLP experts are pure implicit networks that are irrelevant to the actual scene geometry. However, in Swhtch-NeRF++, the hash experts that have multi-resolution grids are highly related to local scene scale. This gives us the possibility to explicitly model the heterogeneity of large-scale scenes by hash experts. Fig. 5 shows the design of the heterogeneity of our hash experts. The hash experts are all multi-resolution hash encodings. Instead of using identical experts as other MoE methods [4], [11], our different experts have different grid resolution ranges. Each expert has several levels of hash grids. The resolution of each hash grid determines the mapping granularity from 3D point to hash index. Experts with coarser hash grids capture more general distributions of the large-scale scene, while those with finer resolutions capture more distinct distributions. To effectively model large-scale scenes, it is crucial to make the network cover wide range of resolutions to capture the appearance and geometry distribution of the scene accurately. As depicted in Fig. 5, our heterogeneous experts cover pyramid of resolutions, enabling the gating network to select experts from diverse resolutions, which enhances the representation power and scalability. We control the resolution ranges of JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 8 region, we use the normal hash grids. The background uses contraction method in Mip-NeRF 360 [72] to map the unbounded space into bounded space. In the contraction, we normalize the scene into unit sphere with the scene bound, and then apply the contraction on 3D point x. If 1, we do not change its value. If > 1, we (cid:17) (cid:16) transform by . This contraction function maps the background 3D points into bounded scene without affecting the 3D points in the foreground. The hash grids for the background are defined in the contracted space. (cid:16) 2 1 (cid:17)"
        },
        {
            "title": "3.5 Point dispatching",
            "content": "In the gating operation, after we obtain the expert indexes for the input points, we need to dispatch them into different experts. The MLP-based gating and Hash-based gating are different from each other in the network operation. Therefore, we have different dispatching designs for different gating network to maximum their efficiency."
        },
        {
            "title": "3.5.1 Point dispatching in MLP-based gating.\nCapacity factor for training. In MLP-based gating, it is\nimportant to efficiently reorganize and send a large number\nof 3D points into different experts. The dispatching method\nusing Einops-based operations [62] usually struggles with\nmemory overflow due to the massive volume of 3D points.\nIn the training of Switch-NeRF, we adopt the optimized\nCUDA dispatch operation [71] for training efficiency. We\nintroduce a capacity factor Cf that limits the input sample\nnumber per NeRF expert in the training, following the\nsetting of previous MoE methods [62]. This ensures uniform\ntensor dimensions, balanced computation and predictable\ncommunication overheads. Given a total batch size B, n\nNeRF experts, the maximum number of sample points per\nNeRF expert is Be = ceil( kBCf\nn ), where k is the number of\nchosen experts for each sample.",
            "content": "This uniform dispatch with capacity factor is depict in Fig. 6. The figure shows that, when Cf = 1.0, overflow points for an expert are dropped and if the expert capacity is not fully used, it will be zero-padded, ensuring uniform tensor shapes. Increasing Cf will decreases the dropping ratio but raises memory and computation cost. In the training of Switch-NeRF, we empirically set Cf to 1.0 to avoid consuming extra memory. To further mitigate performance loss from lower capacities, we integrate the Batch Prioritized Routing [63] method, which refines training by prioritizing critical samples. Full dispatch in inference. While existing MoE methods [12], [62] typically employ the uniform dispatch for both training and testing, this uniform approach may inevitably drops sample points in NeRF inference. In Switch-NeRFs MLP-based architecture, we find that the uniform dispatch works well in the training but introduces notable accuracy degradation during inference due to dropped sample points. We attribute this to our design of using only one gate network instead of stacked MoE layers and skip connections to maintain the network efficiency. This may make our MoE structure less robust to point dropping in inference. Our solution addressing this problem in inference is to introduce an optimized full dispatch strategy leveraging Pytorch, CUDA, and Tutel. This efficient strategy dispatches all the Fig. 6: The comparison between the uniform dispatch and full dispatch in Switch-NeRF. In training, the uniform dispatch is utilized for better computation and communication efficiency. The input tensor of each expert has the same shapes. To maintain the shape, it will drop overflow tokens or pad tokens if necessary. In inference, the full dispatch is employed to make sure each point will be processed by an expert, avoiding accuracy decrease. If the uniform dispatch is used in inference, the rendered images will have artifacts. input points to their corresponding expert with marginal memory overhead, as illustrated in Fig. 6. This strategy yields significant accuracy improvements in final model inference."
        },
        {
            "title": "3.5.2 Efficient hash dispatching in hash operation gating\nnetwork.",
            "content": "The MLP gating network use in Switch-NeRF needs extra memory and computation for dispatching because it performs matrix multiplication on features. Different from this, the hash-based gating network fetches features from the hash tables without matrix operations. It first compute hash index for each 3D points. Then it compute hash table offsets by the hash index and fetch features from hash tables. In our implementation, we find it is very straightforward to we integrate the dispatching into this hash operation. We directly pass the expert indexes into the hash function and use them to compute the hash table offset, which adds only minimal computation and does not require extra memory to reorganize the inputs. We do not need any explicit rearrange of the input features and do not need to consider capacity factor. Our implementation of hash-based dispatching can further boost the efficiency of our SwitchNeRF++ framework."
        },
        {
            "title": "4 EXPERIMENTS\n4.1 Datasets and Metrics",
            "content": "Datasets. To thoroughly assess the scalability, accuracy, and efficiency of our method, we conduct experiments on four large-scale datasets, i.e., Mega-NeRF [2], Block-NeRF [3], an JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 adapted version of UrbanBIS [10] and the MatrixCity [73]. The Mega-NeRF dataset comprises 5 scenes (Building, Rubble, Residence, Sci-Art, and Campus), each with 2k to 6k images of 4k to 5k resolution, covering areas from 0.15 to 1.3 km2. The Block-NeRF dataset includes scene with 12k images at 1k 1k resolution, covering an 1km Urban street. To fully validate the scalability of our method, we adapt much larger scene (Longhua) from UrbanBIS [10] with 13k images at 8k 5k resolution, covering 6.5km2 Urban area. We estimate camera parameters by colmap [37] and downsample the UrbanBIS images by 4. The MatrixCity [73] aerial dataset contains 5 blocks, each with thousands of high-resolution synthetic images. These scenes are very challenging due to the huge image data and the coverage of large-scale regions, suitable for evaluating the scalability of our method. Metrics. The standard metrics such as PSNR, SSIM [74] (both higher is better) and LPIPS [75] (lower is better) the same as Mega-NeRF [2] are used to evaluate the rendering accuracy. Visualization. In addition to visualizing the rendered 2D images, we also employ 3D visualization strategy to directly visualize the 3D radiance fields. 3D points are sampled along pixel rays and merged into 3D point cloud. Each 3D point uses the α = 1 exp(σiδi) as its opacity. we leverage the Point Cloud Library [76] to render both the color and opacity of these 3D points to visualize the radiance fields."
        },
        {
            "title": "4.2 Implement Details",
            "content": "In the MLP-based Switch-NeRF, the foreground network contains 8 NeRF experts configured with Top-1 gating network and capacity factor Cf = 1.0, while the background is represented by single NeRF network. Each NeRF expert is structured as 7-layers MLP with 256 channels per layer. In training and inference, 256 coarse and 512 fine points are sampled per ray for the foreground network, whereas 128 coarse and 256 fine samples for the background network. The training utilizes 8 NVIDIA RTX 3090 GPUs, with global batch size of 8192 rays in each iteration. The models are optimized by 500k iterations for each large-scale scene and then evaluated on validation images. In our Switch-NeRF++ framework, We utilizes multiresolution hash encoding with 16 levels, each level with 2 feature channels. The maximum hash map size is 219. For the Mega-NeRF and Matrixcity datasets, we use the same hash experts. For the larger Block-NeRF dataset and UrbanBIS dataset, we validate our design of heterogeneous mixture of hash experts (HMoHE) using both the same hash experts and heterogeneous hash experts. The hash gating network includes multi-resolution hash encoding and 3layer MLP with 64 channels. We set 8 hash experts in our experiments for the foreground and one hash encoding for the background. The σ prediction head is 2-layer MLP and the color prediction head is 3-layer MLP, both with 64 channels. We conduct our experiments on 4 NVIDIA RTX 3090 GPUs, with batch size of 16384 rays per GPU. We use larger batch sizes to fully use the computation power of the GPUs since our network uses much less memory than MLP-based NeRF methods. We use coarse-to-fine sampling 9 similar to Mega-NeRF, sampling 128 coarse samples and 128 fine samples along ray in the foreground and half of them in the background. We use Adam optimizer to train Switch-NeRF and Switch-NeRF++ with learning rate of 5 104 that exponentially decreases. The weight λ of balance loss Lb is set as 5 104 for all experiments. We also use half-precision training and testing similar to Mega-NeRF. Baseline. We compare our method with the large-scale NeRF method Mega-NeRF [2]. We also adapt the InstantNGP [5] into large-scale setting, named INGP. We use foreground and background network in the baseline. Each of them consists of one multi-resolution hash encoding and prediction heads. We set the hash map size as 222 in the foreground network so it has the same network capacity as our method. The sampling strategy is the same as our Switch-NeRF++."
        },
        {
            "title": "4.3 Overall Benchmark Results",
            "content": "Mega-NeRF dataset. We evaluate the accuracy and efficiency of our framework on Mega-NeRF [2] dataset. The accuracy and training time are reported in Table 1. The results of Mega-NeRF is quoted from their papers. In Table 1, Mega-NeRF and Switch-NeRF are trained with about 30h and 44h respectively for 500k steps. Instant-NGP (INGP) [5] is trained with about 10h for 100k steps. Switch-NeRF++* is our method trained with 5.5h for 50k steps. Switch-NeRF++ is our method trained with 11h for 100k steps. The results show that our MLP-based Switch-NeRF can clearly outperform its counterpart Mega-NeRF, validating the effectiveness of our learnable decomposition and Mixture of Experts. Switch-NeRF++* trained with only 5.5 hours can already achieve state-of-the-art results on almost all the metrics. This is an acceleration of 8 compared to Switch-NeRF and 5 compared to Mega-NeRF, proving the superior efficiency and accuracy of our method. Our Switch-NeRF++ clearly outperforms INGP with less training time, showing the great scalability of our Switch-NeRF++ framework. The training time of our method is comparable to INGP with the same steps. One reason is that we implement an efficient dispatching method by integrating point dispatching into the hash operation. Another reason is that we set similar number of parameters in INGP as our network. We provide qualitative results in Fig. 7. Our method can render images of higher quality with cleaner and sharper details. The main results on the Mega-NeRF dataset clearly demonstrate that our Switch-NeRF++ can achieve better accuracy with superior efficiency comparing to Mega-NeRF, Switch-NeRF and INGP. UrbanBIS dataset. We evaluate the accuracy and scalability of our method on the very large UrbanBIS [10] dataset. Table 2 demonstrate that our heterogeneous hash experts (Heter.) significantly outperform all the compared methods. Notably, our heterogeneous version shows substantial improvements over our homogeneous version (Homo.) across all metrics (PSNR, SSIM, and LPIPS), emphasizing the importance of considering scene heterogeneity when scaling to larger scenes. These experiments strongly support the scalability of our design of HMoHE in Switch-NeRF++ when applied to very large-scale scenes. Fig. 8(a) illustrates JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 10 Fig. 7: qualitative comparison of rendered images of the INGP [5], Mega-NeRF [2], Switch-NeRF [4], and our SwitchNeRF++ on Mega-NeRF dataset. Our Switch-NeRF++ framework can render cleaner and sharper details compared to the state-of-the-art methods. TABLE 1: The benchmark performances of our Switch-NeRF++ on the Mega-NeRF [2] dataset. In this table, the INGP is the Instant-NGP [5] trained with 100k steps. HMoHE* is trained with 50k steps and HMoHE is trained with 100k steps. Our method can achieve state-of-the-art results with only about training time of 5.5h, which is an 8x acceleration compared to Switch-NeRF [4] and 5x acceleration compared to Mega-NeRF [2]. Dataset Metrics Building Rubble Residence Sci-Art Campus PSNR SSIM LPIPS PSNR SSIM LPIPS PSNR SSIM LPIPS PSNR SSIM LPIPS PSNR SSIM LPIPS Time INGP Mega-NeRF Switch-NeRF Switch-NeRF++* Switch-NeRF++ 20.59 20.93 21.54 21.27 21.79 0.555 0.547 0.579 0.595 0.622 0.480 0.504 0.474 0.447 0.424 24.95 24.06 24.31 25.11 25.55 0.627 0.553 0.562 0.642 0.668 0.443 0.516 0.496 0.424 0. 22.22 22.08 22.57 22.79 23.25 0.679 0.628 0.654 0.704 0.725 0.422 0.489 0.457 0.403 0.382 24.52 25.60 26.52 25.65 26.17 0.778 0.770 0.795 0.807 0.821 0.379 0.390 0.360 0.348 0. 23.50 23.42 23.62 23.54 23.94 0.567 0.537 0.541 0.565 0.584 0.568 0.618 0.609 0.570 0.545 10.3h 31.4h 43.0h 5.50h 11.0h that our method produces images with enhanced sharpness and details. TABLE 2: The benchmark performance of Switch-NeRF++ on UrbanBIS [10] and Block-NeRF [3] dataset. SwitchNeRF++ (Heter.) achieves significant improvements over all compared methods across all metrics, including our homogeneous version (Homo.). The results highlight the good scalability of our method and the importance of heterogeneous modeling for achieving scalability. Dataset Metrics Switch-NeRF INGP Switch-NeRF++ (Homo.) Switch-NeRF++ (Heter.) UrbanBIS Block-NeRF PSNR SSIM LPIPS PSNR SSIM LPIPS 19.49 0.412 0.714 23.86 0.762 0. 19.58 0.427 0.695 22.10 0.757 0.490 20.42 0.458 0.655 23.90 0.790 0.454 20.76 0.480 0.628 24.11 0.795 0. Block-NeRF dataset. We evaluate the accuracy and scalability of our method on the large-scale Block-NeRF dataset [3]. Quantitative results are in Table 2. Our Switch-NeRF++, employing heterogeneous hash experts (Heter.), outperforms INGP [5] and Switch-NeRF [4] by considerable margins, particularly in terms of SSIM and LPIPS. This highlights its potential for high-fidelity scene reconstruction. Moreover, TABLE 3: PNSR on MatrixCity [73] dataset. Switch-NeRF++ achieves an overall 1.75-point improvement in PSNR. The results of other methods are quoted from the MatrixCity paper. Please note that INGP also uses 222 entries, whose number of parameters align with our network. These experiments demonstrate that our method can handle different types of scenes. Block Block Block Block Block Overall NeRF INGP MipSwitch-NeRF++ 23.15 27.21 26.64 28.15 +0.94 22.94 25.45 24.80 27.47 +2.01 22.15 23.21 24. 26.72 +2.52 23.09 26.24 26.45 27.56 +1.11 23.53 26.36 26.54 27.50 +0.96 22.97 25.69 25. 27.48 +1.75 our heterogeneous design of hash experts consistently outperforms the homogeneous version (Homo.), showing the importance of heterogeneous modeling of very large scenes. MatrixCity dataset. Our method on MatrixCity [73] in Table 3 achieves an overall 1.75-point improvement in PSNR. The results of NeRF [1], Instant-NGP (INGP) [5] and Mip360 [72] are quoted from the MatrixCity. Note that the parameters of INGP in MatrixCity aligned with our network, JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 using 222 entries as indicated in MatrixCitys supplementary file. These experiments demonstrate superior accuracy and general applicability of our method across different types of scenes. TABLE 4: Ablation studies of our key designs in SwitchNeRF++. The MLP-gating does not perform as well as our proposed hash-based gating network. With 2 experts, our method produces good accuracy, but it is lower than the accuracy of the one with 8 experts. The Top-2 operation can obtain comparable results to the Top-1 operation. Dataset Residence Sci-Art Metrics PSNR SSIM LPIPS PSNR SSIM LPIPS MLP-Gate 2 Experts Top-2 Top-1 22.03 22.62 23.33 23.25 0.658 0.683 0.731 0.725 0.443 0.429 0.374 0. 24.00 25.61 26.08 26.17 0.761 0.799 0.819 0.821 0.399 0.362 0.328 0.329 TABLE 5: Comparison to GP-NeRF [53]. Switch-NeRF++ consistently outperforms GP-NeRF, especially on the very large UrbanBIS [10] dataset. GP-NeRF [53] uses hash encodings together with 2D ground plane features without scene decomposition. Our learnable heterogeneous decomposition on large-scale scenes better exploits network parameters. Dataset Metrics GP-NeRF Switch-NeRF++ Dataset Metrics GP-NeRF Switch-NeRF++ UrbanBIS Building PSNR SSIM LPIPS PSNR SSIM LPIPS 19.51 0.426 0.695 21.42 0.602 0.450 20.76 0.480 0.628 21.79 0.622 0. Rubble Residence PSNR SSIM LPIPS PSNR SSIM LPIPS 24.84 0.611 0.448 22.84 0.703 0. 25.55 0.668 0.400 23.25 0.725 0."
        },
        {
            "title": "4.4 Model Analysis",
            "content": "Effect of heterogeneous mixture of hash experts. We validate our heterogeneous hash design on Block-NeRF [3] and UrbanBIS [10] datasets. The scene in Block-NeRF dataset covers 1km street. The scene in UrbanBIS dataset covers 6.5km2 region. Both scenes are very large to evaluate the scalability of our heterogeneous design. The results in Table 2 clearly demonstrate the superior performance of our heterogeneous design compared to our homogeneous version (Homo.), particularly on UrbanBIS. Each of the experts in Switch-NeRF++ (Homo.) uses the default setting of the encodings in Instant-NGP [5]. In contrast, SwitchNeRF++ (Heter.) incorporates experts with varying resolution ranges, with minimum resolutions of the experts exponentially increasing from 16 to 512 and maximum resolutions exponentially increasing from 2048 to 16384. The ablation results strongly emphasize the significance of considering scene heterogeneity when scaling to larger scenes and provide clear evidence for the scalability of our method. Fig. 8(b) visualize the decomposition of the radiance field of UrbanBIS dataset of Switch-NeRF++ (Homo.). and SwitchNeRF++ (Heter.). These visualizations further validate that our heterogeneous design can effectively capture the different distributions of the large-scale scene. Gating network design in Switch-NeRF. We analyze different designs of the MLP-based gating network in SwitchNeRF [4]. Table 8 compares three configurations. The first TABLE 6: Comparison of the memory and time for testing and training between the efficient hash dispatching in Switch-NeRF++ and MoE dispatching. Our dispatching uses 5 fewer hours and less GPU memory in training, and only half of the time for rendering. 11 Method Test Train Mem. Time Mem. Time MoE disp. Hash disp. 2981M 13.5s 2857M 6.65s 10386M 15.2h 8707M 10.7h TABLE 7: Comparison to Instant-NGP [5] with MegaNeRF [2] (Mega-NGP) and 3D Gaussian spaltting (3DGS) [44] by PSNR. Switch-NeRF++ demonstrates superior accuracy than Mega-NGP and 3D-GS on large-scale scenes. Building Rubble Residence Sci-Art Campus 3D-GS Mega-NGP Switch-NeRF++ 19.04 20.22 21.79 25.06 24.46 25. 21.37 21.55 23.25 21.65 24.15 26.17 18.74 22.19 23. is using Linear gating, which processes the positional encoding PE(x) by only trainable linear layer. The second is removing the LayerNorm in the gating network. The third is training the network without the gating loss Lb. As shown in the table, the Linear gating underperforms due to insufficient network capacity, validating that the MLP+Norm design in our gating network can substantially improves reconstruction accuracy. Notably, removing the gating loss Lb prevents the training to converge, highlighting that Lb is necessary for stabilizing the optimization of our sparse MoE system. This finding aligned with prior works [11], [62]. Full dispatch in Switch-NeRF. We compare the inference accuracy of using uniform dispatch or using our full dispatch proposed in Sec. 3.5.1 on the trained Switch-NeRF. The Batch Prioritized Routing [63] and capacity factor Cf of 2.0 or 4.0 are used in the inference of the uniform dispatch. As shown in Table 12, uniform dispatch with Cf = 2.0 suffers significant quality degradation. While increasing Cf to 4.0 partially improves the quality, it remains substantially inferior to full dispatch. Meanwhile, larger Cf introducing extra computational overhead due to zero padding. Visual comparisons in Fig. 6 further highlight that the uniform dispatch renders images with much more artifacts, whereas our full dispatch produces complete and higher-quality outputs. This validates the effectiveness of using full dispatch in inference of Switch-NeRF. Effect of the hash-based gating network. We replace the hash-based gating network in Switch-NeRF++ with an MLP gating network similar to that in Switch-NeRF [4] which consists of 4 linear layers with width of 256. The input of the MLP gating network is the positional encoding [1]. We train them with 100k steps. As shown in Table 4, the accuracy drops by large margin with the MLP gating network. This may be because the MLP suffers slow converging speed, and the representation power of the MLP gating network is inconsistent with the hash experts in SwitchNeRF. This experiment further confirms the importance of our design of the hash-based gating network. Effect of the number of experts. We analyze the effect JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 12 Fig. 8: (a) Rendered images of INGP [5], Switch-NeRF [4], and our Switch-NeRF++ on UrbanBIS. Ours can render images with notably higher quality compared to other methods. (b) visualization of our decomposition of the radiance field of the UrbanBIS dataset. Different experts of Ours (Heter.) capture quite different distributions of the scene, from coarser grounds to finer buildings. Different experts in Ours (Homo.) handle similar distributions. This figure shows that Ours (Heter.) can learn to capture heterogeneous representations effectively. TABLE 8: Different gating network designs in Switch-NeRF on Sci-Art scene. PSNR SSIM LPIPS Linear w/o Norm w/o Lb Switch-NeRF 20.75 21.39 15.32 21. 0.532 0.577 0.363 0.579 0.524 0.474 0.769 0.474 TABLE 12: The testing time and accuracy of uniform dispatch with Cf = 2.0 and 4.0 and full dispatch. Using the full dispatch can achieves much better performance with less time usage. Dispatch PSNR SSIM LPIPS Time (s) Uniform 2.0 Uniform 4.0 Full 17.82 20.07 21. 0.410 0.521 0.579 0.563 0.507 0.474 131 182 110 TABLE 9: Comparison of Switch-NeRF and Mega-NeRF with different sub-networks on accuracy, test time, test memory and network parameters numbers. Switch-NeRF demonstrates better scalability than Mega-NeRF, increasing performance without large increase of test memory and time. Model PSNR SSIM LPIPS Mem. Time Param. TABLE 13: Impact of different number of gating operations on accuracy and efficiency in Switch-NeRF. Despite maintaining the same number of expert layers, Switch-NeRF with two gating operations fails to enhance rendering accuracy compared to the model with single gating operation, while requiring increased memory usage and longer training and inference times. Switch-4 Mega-8 Switch-8 Mega-16 Switch21.00 20.93 21.54 21.47 22.49 0.547 0.547 0.579 0.590 0.625 0.504 0.504 0.474 0.462 0.429 5825M 106s 6935M 87.9s 110s 5847M 101s 8042M 118s 5876M 2.78M 10.8M 4.53M 21.6M 8.05M Gating number PSNR SSIM LPIPS Train Test Mem. Time Mem. Time 1 2 21.54 21.55 0.579 0.574 0.474 0. 10182M 42.5h 15315M 56.2h 5847M 110s 5838M 152s TABLE 10: The ablation results of Switch-NeRF using different Top-1, Top-2 and capacity factors. larger Cf or employing Top-2 operation in the gating network in training can improve the accuracy slightly while consuming more training time and memory. Top-k 1 1 2 Capacity 1.0 1.5 1.0 PSNR 21.54 21.70 21. SSIM 0.579 0.594 0.590 LPIPS Mem. 0.474 0.463 0.465 Time 10182M 42.5h 12271M 47.4h 14548M 58.7h TABLE 11: The ablation results comparing Switch-NeRF [4] and Mega-NeRF [2] on parameter number, time, memory and FLOPs. Although using slightly more training time and memory, Switch-NeRF consumes less memory in testing and has much less parameters while achieving better accuracy. Method Test Train Mem. Time Mem. Time Param. FLOPs Mega-NeRF Switch-NeRF 6935M 87.9s 110s 5847M 5124M 30.7h 10182M 42.5h 10.8M 4.53M 0.79M 0.99M of the number of NeRF experts in both Switch-NeRF [4]. Table 9 reveals that even using 4 experts, Switch-NeRF already matches the accuracy of Mega-NeRF with 8 subnetworks. Scaling Switch-NeRF to 16 experts yields significant performance gains compared to 8 experts, while while incurring minimal additional computational and memory overhead during inference. This contrasts to the Mega-NeRF with 16 sub-networks, where Switch-NeRF not only scales much better and achieves higher accuracy, but also reduces parameters and memory usage. The results demonstrate the superior scalability of Switch-NeRF in balancing model capacity and resource demands. Effect of Top-1 and Top-2 gating. In Switch-NeRF [4] and Switch-NeRF++, we only choose one expert for 3D scene point to perform scene decomposition. However, similar to MoE methods [4], [11], we can also use Top-2 operation to select 2 experts for each sample point. The final expert output is the weighted sum of the two expert outputs by the predicted gating values. As shown in Table 4 and Table 10, using 2 experts can achieve comparable results to JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 the Top-1 selection. This shows that using only one expert for each sample is already sufficient for good results. Using more experts for sample without increasing the network capacity does not necessarily produce better results. Effect of training steps. Fig. 9 shows the PSNR, SSIM, and LPIPS of Switch-NeRF and Switch-NeRF++ compared to other methods on the Rubble scene in different training steps. Our Switch-NeRF++ can already obtain state-ofthe-art results with 50k-100k steps and clearly outperform Switch-NeRF. The accuracy can continue to improve lot with more training steps. This means that given more computation, Switch-NeRF++ can produce better results, which enables our network to fit flexibly into different application scenarios, and we can flexibly make good trade-off between the accuracy and the computation overhead. Plane features without decomposition. The GP-NeRF [53] augments hash encodings with 2D ground plane features. It does not perform scene decomposition. The comparing results are shown in Table 5. Switch-NeRF++ consistently outperform GP-NeRF, especially on the very large UrbanBIS [10] dataset. These experiments validate the importance of our learnable heterogeneous decomposition on largescale scenes to better exploit network parameters. Manual decomposition. In Table 7, we integrate INGP into the manual decomposition method Mega-NeRF [2] as MegaNGP. It manually divides the scene into multiple parts according to 3D distances. Each part is handled by typical INGP network. Switch-NeRF++ significantly outperforms Mega-NGP, indicating that the spatial decomposition in Mega-NeRF is not well-suited for hash grids. In contrast, our method is designed to learn the heterogeneous decomposition and representation of large-scale scenes, which has been proven more generally applicable and accurate. Vanilla Gaussian splatting. We compare with the vanilla Gaussian splatting method (3D-GS) [44] in Table 7by applying 3D-GS on large-scale datasets. The results demonstrate that the vanilla 3D-GS struggles on large-scale scenes. It relies on point cloud for initialization, while point clouds in large-scale scenes are typically noisy, contain outliers, and have significantly varying densities. The original 3DGS has no special designs for these problems, resulting in poor initialization and training. Our method incorporates the learnable heterogeneous decomposition specially designed for large-scale scenes and can get much better results. Moreover, our method does not need any point clouds for initialization, making it more suitable for various large-scale reconstruction tasks. Fig. 9: The accuracy of our Switch-NeRF++ and other methods with respect to training steps. Our method continues to improve with more training steps. TABLE 14: Rendering time and memory. Our method speed up rendering by 16x compared to Switch-NeRF [4] and by 13x compared to Mega-NeRF [2] with much less memory. 13 Mega-NeRF Switch-NeRF Switch-NeRF++ Mem. Time 6935M 87.9s 5847M 110s 2857M 6.65s"
        },
        {
            "title": "4.5 Efficiency Analysis",
            "content": "Efficiency of Switch-NeRF. Table 11 compare the efficiency of Switch-NeRF [4] and Mega-NeRF. With only half network parameters, Switch-NeRF attains superior accuracy than Mega-NeRF. Each sub-network in Mega-NeRF employs foreground and background NeRF and set of appearance embeddings (AE), which results in more network parameters. In contrast, Switch-NeRF designs an end-to-end framework which needs only one background NeRF and one set of AE for the whole scene, largely decreasing the parameters while getting better accuracy. Since Switch-NeRF has an extra gating network comparing to Mega-NeRF, it uses slightly more floating point operations (FLOPs) for each point, resulting in slightly more memory and time usage for training. However, Switch-NeRF consumes around 20% less testing memory than Mega-NeRF while only increase minor testing time. These results demonstrate that SwitchNeRF can achieve much better accuracy with large influencing the efficiency, validating the efficiency and wide applicability of our sparse MoE structure on large-scale scene modeling. Efficient hash dispatching. We analyze the time and memory efficiency of the hash dispatching of Switch-NeRF++ compared to the optimized dispatching operation in the MoE method [4], [71] in Switch-NeRF. As shown in Table 6, when trained with 100k steps, the MoE dispatching uses 5 more hours and more GPU memory. When rendering images, our method uses only 6.65s to render 1152 864 image, while the MoE dispatching costs 13.5s. These results show that our efficient dispatching can save time and memory for both training and testing by large margin compared to the MoE dispatching. The memory is calculated by the Pytorch APIs. Time and memory overhead for rendering of SwitchNeRF++. In this experiment, we evaluate the time and memory overhead of Switch-NeRF++ for rendering images. As highlighted in Table 14, our Switch-NeRF++ can render 1152864 image with only 6.65s, which is 16x acceleration compared to Switch-NeRF and 13x acceleration compared to Mega-NeRF. The memory used by our method is even less than half of these two methods. This experiment clearly verifies the superior efficiency of our method. The efficiency enables our method to be applied to real-world, challenging and large-scale scenes."
        },
        {
            "title": "5 CONCLUSION",
            "content": "We propose Switch-NeRF++, novel framework for highly scalable Neural Radiance Field (NeRF) modeling. It simultaneously addresses the challenges of leanable decomposition, heterogeneity and efficiency in large-scale NeRF by incorporating the Heterogeneous Mixture of Hash Experts JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 (HMoHE) architecture. Extensive experiments show the superior accuracy and scalability of our method compared to the best-performing methods. Our framework emerges as practical solution for applying NeRF in real-world largescale scenes with flexible scalability and high efficiency."
        },
        {
            "title": "REFERENCES",
            "content": "[1] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi, and R. Ng, Nerf: Representing scenes as neural radiance fields for view synthesis, in ECCV, 2020. [2] H. Turki, D. Ramanan, and M. Satyanarayanan, Mega-nerf: Scalable construction of large-scale nerfs for virtual fly-throughs, in CVPR, 2022. [3] M. Tancik, V. Casser, X. Yan, S. Pradhan, B. Mildenhall, P. P. Srinivasan, J. T. Barron, and H. Kretzschmar, Block-nerf: Scalable large scene neural view synthesis, in CVPR, 2022. [4] Z. MI and D. Xu, Switch-neRF: Learning scene decomposition with mixture of experts for large-scale neural radiance fields, in ICLR, 2023. [5] T. Müller, A. Evans, C. Schied, and A. Keller, Instant neural graphics primitives with multiresolution hash encoding, ACM Trans. Graph., vol. 41, no. 4, pp. 102:1102:15, 2022. [6] C. Sun, M. Sun, and H. Chen, Direct voxel grid optimization: Super-fast convergence for radiance fields reconstruction, in CVPR, 2022. S. Fridovich-Keil, A. Yu, M. Tancik, Q. Chen, B. Recht, and A. Kanazawa, Plenoxels: Radiance fields without neural networks, in CVPR, 2022. [7] [8] A. Chen, Z. Xu, A. Geiger, J. Yu, and H. Su, Tensorf: Tensorial radiance fields, in ECCV, 2022. [9] L. Xu, Y. Xiangli, S. Peng, X. Pan, N. Zhao, C. Theobalt, B. Dai, and D. Lin, Grid-guided neural radiance fields for large urban scenes, in CVPR, 2023. [10] G. Yang, F. Xue, Q. Zhang, K. Xie, C.-W. Fu, and H. Huang, Urbanbis: large-scale benchmark for fine-grained urban building instance segmentation, in SIGGRAPH, 2023. [11] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. V. Le, G. E. Hinton, and J. Dean, Outrageously large neural networks: The sparsely-gated mixture-of-experts layer, in ICLR, 2017. [12] W. Fedus, B. Zoph, and N. Shazeer, Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity, JMLR, 2022. [13] D. G. Lowe, Object recognition from local scale-invariant features, in ICCV, vol. 2, pp. 11501157, IEEE, 1999. [14] J. Cech, J. Matas, and M. Perdoch, Efficient sequential correspondence selection by cosegmentation, TPAMI, vol. 32, no. 9, pp. 15681581, 2010. [15] J. L. Schönberger, T. Price, T. Sattler, J.-M. Frahm, and M. Pollefeys, vote-and-verify strategy for fast spatial verification in image retrieval, in ACCV, pp. 321337, Springer, 2017. [16] P.-E. Sarlin, D. DeTone, T. Malisiewicz, and A. Rabinovich, Superglue: Learning feature matching with graph neural networks, in CVPR, pp. 49384947, 2020. [17] N. Snavely, S. M. Seitz, and R. Szeliski, Photo tourism: exploring photo collections in 3d, in SIGGRAPH, pp. 835846, 2006. [18] D. Crandall, A. Owens, N. Snavely, and D. Huttenlocher, Discrete-continuous optimization for large-scale structure from motion, in CVPR, pp. 30013008, IEEE, 2011. [19] J. L. Schonberger and J.-M. Frahm, Structure-from-motion revisited, in CVPR, pp. 41044113, 2016. [20] Y. Furukawa and J. Ponce, Accurate, dense, and robust multiview stereopsis, IEEE TPAMI, vol. 32, no. 8, pp. 13621376, 2009. [21] J. L. Schönberger, E. Zheng, J.-M. Frahm, and M. Pollefeys, Pixelwise view selection for unstructured multi-view stereo, in ECCV, pp. 501518, Springer, 2016. [22] Q. Xu and W. Tao, Multi-scale geometric consistency guided multi-view stereo, in CVPR, pp. 54835492, 2019. [23] Z. Mi, C. Di, and D. Xu, Generalized binary search network for highly-efficient multi-view stereo, in CVPR, pp. 1299113000, 2022. [24] Y. Yao, Z. Luo, S. Li, T. Fang, and L. Quan, Mvsnet: Depth inference for unstructured multi-view stereo, in ECCV, pp. 767 783, 2018. [25] R. Chen, S. Han, J. Xu, and H. Su, Point-based multi-view stereo network, in ICCV, pp. 15381547, 2019. 14 [26] X. Gu, Z. Fan, S. Zhu, Z. Dai, F. Tan, and P. Tan, Cascade cost volume for high-resolution multi-view stereo and stereo matching, in CVPR, pp. 24952504, 2020. [27] Q. Xu and W. Tao, Learning inverse depth regression for multiview stereo with correlation cost volume, in AAAI, vol. 34, pp. 1250812515, 2020. [28] K. Zhang, G. Riegler, N. Snavely, and V. Koltun, Nerf++: Analyzing and improving neural radiance fields, arXiv preprint arXiv:2010.07492, 2020. [29] R. Martin-Brualla, N. Radwan, M. S. Sajjadi, J. T. Barron, A. Dosovitskiy, and D. Duckworth, Nerf in the wild: Neural radiance fields for unconstrained photo collections, in CVPR, 2021. [30] J. T. Barron, B. Mildenhall, M. Tancik, P. Hedman, R. MartinBrualla, and P. P. Srinivasan, Mip-nerf: multiscale representation for anti-aliasing neural radiance fields, in ICCV, 2021. [31] J. T. Barron, B. Mildenhall, D. Verbin, P. P. Srinivasan, and P. Hedman, Mip-nerf 360: Unbounded anti-aliased neural radiance fields, in CVPR, pp. 54705479, 2022. [32] K. Deng, A. Liu, J.-Y. Zhu, and D. Ramanan, Depth-supervised NeRF: Fewer views and faster training for free, in CVPR, June 2022. [33] P. Truong, M.-J. Rakotosaona, F. Manhardt, and F. Tombari, Sparf: Neural radiance fields from sparse and noisy poses, CVPR, 2023. [34] Y. Zhong, L. Hong, Z. Li, and D. Xu, Cvt-xrf: Contrastive in-voxel transformer for 3d consistent radiance fields from sparse inputs, in CVPR, 2024. [35] P. Wang, L. Liu, Y. Liu, C. Theobalt, T. Komura, and W. Wang, Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction, NeurIPS, 2021. [36] Z. Li, T. Müller, A. Evans, R. H. Taylor, M. Unberath, M.-Y. Liu, and C.-H. Lin, Neuralangelo: High-fidelity neural surface reconstruction, in CVPR, 2023. [37] J. L. Schönberger and J.-M. Frahm, Structure-from-motion revisited, in CVPR, 2016. [38] Z. Wang, S. Wu, W. Xie, M. Chen, and V. A. Prisacariu, Nerf: Neural radiance fields without known camera parameters, arXiv preprint arXiv:2102.07064, 2021. [39] C.-H. Lin, W.-C. Ma, A. Torralba, and S. Lucey, Barf: Bundleadjusting neural radiance fields, in IEEE International Conference on Computer Vision (ICCV), 2021. [40] A. Yu, R. Li, M. Tancik, H. Li, R. Ng, and A. Kanazawa, PlenOctrees for real-time rendering of neural radiance fields, in ICCV, 2021. [41] S. J. Garbin, M. Kowalski, M. Johnson, J. Shotton, and J. Valentin, Fastnerf: High-fidelity neural rendering at 200fps, in ICCV, 2021. [42] C. Reiser, S. Peng, Y. Liao, and A. Geiger, Kilonerf: Speeding up neural radiance fields with thousands of tiny mlps, in ICCV, 2021. [43] S. Fridovich-Keil, A. Yu, M. Tancik, Q. Chen, B. Recht, and A. Kanazawa, Plenoxels: Radiance fields without neural networks, in CVPR, pp. 55015510, June 2022. [44] B. Kerbl, G. Kopanas, T. Leimkühler, and G. Drettakis, 3d gaussian splatting for real-time radiance field rendering, ACM Transactions on Graphics, 2023. [45] A. Yu, V. Ye, M. Tancik, and A. Kanazawa, pixelnerf: Neural radiance fields from one or few images, in CVPR, pp. 45784587, 2021. [46] A. Chen, Z. Xu, F. Zhao, X. Zhang, F. Xiang, J. Yu, and H. Su, Mvsnerf: Fast generalizable radiance field reconstruction from multi-view stereo, in Proceedings of the IEEE/CVF international conference on computer vision, pp. 1412414133, 2021. [47] Q. Wang, Z. Wang, K. Genova, P. P. Srinivasan, H. Zhou, J. T. Barron, R. Martin-Brualla, N. Snavely, and T. Funkhouser, Ibrnet: Learning multi-view image-based rendering, in CVPR, 2021. [48] E. R. Chan, C. Z. Lin, M. A. Chan, K. Nagano, B. Pan, S. De Mello, O. Gallo, L. J. Guibas, J. Tremblay, S. Khamis, et al., Efficient geometry-aware 3d generative adversarial networks, in CVPR, pp. 1612316133, 2022. [49] Y. Hong, K. Zhang, J. Gu, S. Bi, Y. Zhou, D. Liu, F. Liu, K. Sunkavalli, T. Bui, and H. Tan, Lrm: Large reconstruction model for single image to 3d, in ICLR, 2024. [50] S. Dong, L. Ding, Z. Huang, Z. Wang, T. Xue, and D. Xu, Interactive3d: Create what you want by interactive 3d generation, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 49995008, 2024. [51] A. Mirzaei, T. Aumentado-Armstrong, K. G. Derpanis, J. Kelly, M. A. Brubaker, I. Gilitschenski, and A. Levinshtein, SPIn-NeRF: JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 Multiview segmentation and perceptual inpainting with neural radiance fields, in CVPR, 2023. [52] Y. Wang, Q. Wu, G. Zhang, and D. Xu, Gscream: Learning 3d geometry and feature consistent gaussian splatting for object removal, in ECCV, 2024. [53] Y. Zhang, G. Chen, and S. Cui, Efficient large-scale scene representation with hybrid of high-resolution grid and plane features, arXiv preprint arXiv:2303.03003, 2023. [54] B. Kerbl, G. Kopanas, T. Leimkühler, and G. Drettakis, 3d gaussian splatting for real-time radiance field rendering, ToG, pp. 1 14, 2023. [55] B. Kerbl, A. Meuleman, G. Kopanas, M. Wimmer, A. Lanvin, and G. Drettakis, hierarchical 3d gaussian representation for realtime rendering of very large datasets, ACM ToG, vol. 43, no. 4, 2024. [56] Y. Liu, H. Guan, C. Luo, L. Fan, N. Wang, J. Peng, and Z. Zhang, Citygaussian: Real-time high-quality large-scale scene rendering with gaussians, arXiv preprint arXiv:2404.01133, 2024. [57] Y. Chen and G. H. Lee, Dogaussian: Distributed-oriented gaussian splatting for large-scale 3d reconstruction via gaussian consensus, arXiv preprint arXiv:2405.13943, 2024. [58] J. Lin, Z. Li, X. Tang, J. Liu, S. Liu, J. Liu, Y. Lu, X. Wu, S. Xu, Y. Yan, and W. Yang, Vastgaussian: Vast 3d gaussians for large scene reconstruction, in CVPR, 2024. [59] Z. Wang and D. Xu, Pygs: Large-scale scene representation with pyramidal 3d gaussian splatting, arXiv preprint arXiv:2405.16829, 2024. [60] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton, Adaptive mixtures of local experts, Neural computation, vol. 3, no. 1, pp. 7987, 1991. [61] M. I. Jordan and R. A. Jacobs, Hierarchical mixtures of experts and the em algorithm, Neural computation, vol. 6, no. 2, pp. 181 214, 1994. [62] D. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen, Gshard: Scaling giant models with conditional computation and automatic sharding, in ICLR, 2021. [63] C. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton, A. S. Pinto, D. Keysers, and N. Houlsby, Scaling vision with sparse mixture of experts, in NeurIPS, 2021. [64] H. Ye and D. Xu, Taskexpert: Dynamically assembling multi-task representations with memorial mixture-of-experts, in ICCV, 2023. [65] A. Rogozhnikov, Einops: Clear and reliable tensor manipulations with einstein-like notation, in ICLR, 2021. [66] S. Roller, S. Sukhbaatar, J. Weston, et al., Hash layers for large sparse models, NeurIPS, 2021. [67] M. Lewis, S. Bhosale, T. Dettmers, N. Goyal, and L. Zettlemoyer, Base layers: Simplifying training of large, sparse models, in ICML, pp. 62656274, PMLR, 2021. [68] Y. Zhou, T. Lei, H. Liu, N. Du, Y. Huang, V. Zhao, A. M. Dai, Q. V. Le, J. Laudon, et al., Mixture-of-experts with expert choice routing, Advances in Neural Information Processing Systems, vol. 35, pp. 71037114, 2022. [69] N. Shazeer, Y. Cheng, N. Parmar, D. Tran, A. Vaswani, P. Koanantakool, P. Hawkins, H. Lee, M. Hong, C. Young, et al., Meshtensorflow: Deep learning for supercomputers, NeurIPS, 2018. [70] S. Rajbhandari, C. Li, Z. Yao, M. Zhang, R. Y. Aminabadi, A. A. Awan, J. Rasley, and Y. He, Deepspeed-moe: Advancing mixtureof-experts inference and training to power next-generation AI scale, in ICML, 2022. [71] C. Hwang, W. Cui, Y. Xiong, Z. Yang, Z. Liu, H. Hu, Z. Wang, R. Salas, J. Jose, P. Ram, et al., Tutel: Adaptive mixture-of-experts at scale, arXiv preprint arXiv:2206.03382, 2022. [72] J. T. Barron, B. Mildenhall, D. Verbin, P. P. Srinivasan, and P. Hedman, Mip-nerf 360: Unbounded anti-aliased neural radiance fields, in CVPR, 2022. [73] Y. Li, L. Jiang, L. Xu, Y. Xiangli, Z. Wang, D. Lin, and B. Dai, Matrixcity: large-scale city dataset for city-scale neural rendering and beyond, arXiv e-prints, pp. arXiv2308, 2023. [74] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, Image quality assessment: from error visibility to structural similarity, TIP, 2004. [75] R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang, The unreasonable effectiveness of deep features as perceptual metric, in CVPR, 2018. [76] R. B. Rusu and S. Cousins, 3d is here: Point cloud library (pcl), in ICRA, IEEE, 2011."
        }
    ],
    "affiliations": [
        "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR",
        "Inspur Cloud Information Technology Co, Ltd"
    ]
}