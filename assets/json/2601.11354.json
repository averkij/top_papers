{
    "paper_title": "AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems",
    "authors": [
        "Weiyi Wang",
        "Xinchi Chen",
        "Jingjing Gong",
        "Xuanjing Huang",
        "Xipeng Qiu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 6 1 ] . [ 1 4 5 3 1 1 . 1 0 6 2 : r AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems Weiyi Wang1,3, Xinchi Chen1,3, Jingjing Gong2,3 Xuanjing Huang1 Xipeng Qiu1,2,3, 1Fudan University 2Shanghai Innovation Institute 3OpenMOSS Team"
        },
        {
            "title": "Abstract",
            "content": "ecent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained realworld domains underexplored. We introduce AstroReason-Bench, comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReasonBench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides unified agent-oriented interaction protocol. Evaluating on range of state-of-the-art openand closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers challenging and diagnostic testbed for future agentic research. Repository: https://github.com/Mtrya/astro-reason"
        },
        {
            "title": "Introduction",
            "content": "Recent progress in large language models has given rise to agentic systems that integrate natural language reasoning with planning, tool use, and iterative decision-making. These systems are increasingly viewed as generalist planners, capable of addressing diverse tasks without task-specific algorithm design, ranging from software engineering and web automation to scientific reasoning and decision support. Despite these advances, the evaluation of agentic systems remains limited. Existing benchmarks primarily focus on symbolic, text-based, or weakly grounded environmentssuch as web navigation, code synthesis, or synthetic games [11, 25, 38]. While valuable for assessing reasoning and tool orchestration, these settings abstract away hard physical constraints, long-horizon planning requirements, and irreversible feasibility boundaries. Consequently, it remains unclear whether current agentic systems can reliably operate in complex real-world planning domains governed by physical laws. Space Planning Problems (SPP) offer uniquely challenging and underexplored testbed for generalist planning. SPP encompass heterogeneous objectives, strict physical and temporal constraints, large combinatorial action Visiting Student at Fudan University Corresponding authors 1 Figure 1 Transition from disparate algorithms to unified agentic framework: (a) illustrates the conventional methodology where tasks are isolated and optimized using disparate algorithms; (b) presents our unified agentic system, where central intelligent agent leverages toolkit to manage disparate scheduling tasks in an integrated manner. spaces, and long-horizon decision-making. These challenges arise across structurally distinct sub-problems, including ground station communication scheduling, agile Earth observation planning, and deep-space network allocation. Historically, each of these problems has been tackled using highly specialized optimization techniques, such as mixed-integer programming [4, 7], heuristic search [24, 36], or reinforcement learning [8, 18, 23]. While benchmarks and simulators exist for individual SPP sub-problems, they are typically developed in isolation, with incompatible assumptions, interfaces, and evaluation metrics. As result, they are well-suited for assessing specialized solvers but ill-suited for evaluating whether single agentic system can adapt its reasoning and tool usage across multiple, structurally diverse planning environments. To address this gap, we introduce AstroReason-Bench, comprehensive, physics-aligned benchmark suite for evaluating agentic planning in SPP. AstroReason-Bench integrates multiple representative SPP sub-problems under unified, agent-oriented interaction and evaluation protocol, treating them as family of heterogeneous environments that collectively stress-test the adaptability and robustness of generalist planners. We evaluate AstroReason-Bench using range of state-of-the-art openand closed-source agentic LLM systems, including DeepSeek V3.2, Claude Sonnet 4.5, Gemini 3 Flash, etc. To enable zero-shot operation, we provide minimal set of task-relevant tools via the Model Context Protocol (MCP), allowing agents to observe environment states, invoke simulators, and execute scheduling decisions. Our empirical results reveal substantial performance gap between current agentic systems and specialized optimization methods, highlighting the challenges posed by strict physical constraints. We argue that this gap underscores the realism and diagnostic value of AstroReason-Bench, which serves both as rigorous evaluation platform and as foundation for future research in agentic planning, transfer, and learning for space planning problems. Our contributions are summarized as follows: We introduce AstroReason-Bench, the first unified benchmark suite for evaluating agentic planning across diverse space planning problems. We provide standardized, agent-oriented interfaces and metrics enabling consistent evaluation across heterogeneous SPP tasks. We present comprehensive evaluation of state-of-the-art agentic LLM systems, revealing key limitations and open challenges in physics-grounded planning."
        },
        {
            "title": "2.2 Agentic Planning and Reasoning",
            "content": "LLMs are evolving from static models to agentic planners capable of tool use and reasoning [15, 29, 30]. While benchmarks like PlanBench [27] and TravelPlanner [32] evaluate symbolic reasoning, they often lack the high-fidelity physical constraints of engineering domains. Recent interactive agent benchmarks (e.g., ğœ-bench [35]) further evaluate tool use and execution feedback, but similarly abstract away domain-specific physical dynamics. Agents offer promising universal interface for physical systems, acting as co-pilots that translate natural language into executable plans or API calls [19, 21, 28]. Unlike rigid specialized solvers, agentic systems can potentially handle nuanced constraints zero-shot. This work benchmarks this capability within the rigorous constraints of space mission planning."
        },
        {
            "title": "3 The AstroReason-Bench Suite",
            "content": "We introduce AstroReason-Bench, comprehensive evaluation suite designed to evaluate autonomous agents under high-fidelity orbital, resource and temporal constraints. It integrates the legacy SatNet environment [6] with four novel, procedurally generated mission profiles."
        },
        {
            "title": "3.1 Simulation Environment & Constraints",
            "content": "The engine uses the Simplified General Perturbations 4 (SGP4) model [9, 26], standard analytical propagator for consistency with real-world Two-Line Element (TLE) data, standardized format for encoding the orbital elements of Earth-orbiting objects [26]. The simulation enforces three primary constraint classes: Resource Constraints Agents must manage two coupled resource buffers. Energy (ğ¸(ğ‘¡)): Modeled as an integral of power generation ğ‘ƒğ‘”ğ‘’ğ‘› (solar) minus power consumption ğ‘ƒğ‘ğ‘œğ‘›. ğ‘ƒğ‘”ğ‘’ğ‘› is conditional on the satellites eclipse status (computed via conical shadow projection). The constraint requires ğ¸(ğ‘¡) = ğ¸(0) + ğ‘¡ (ğ‘ƒğ‘”ğ‘’ğ‘›(ğ‘¡) ğ‘ƒğ‘ğ‘œğ‘›(ğ‘¡)) 0, ğ‘¡. 0 Data Storage (ğ·(ğ‘¡)): Modeled as buffer with inflow from observations and outflow from downlinks. Agents must schedule ground station passes to prevent buffer overflows (ğ·(ğ‘¡) ğ·ğ‘šğ‘ğ‘¥) where ğ·ğ‘šğ‘ğ‘¥ is the maximum onboard storage of satellite. Kinematic Constraints For Earth observation tasks, satellites are modeled as agile bodies requiring attitude maneuvers. maneuver between target ğ‘– and target ğ‘— is valid only if the temporal gap Î”ğ‘¡ğ‘–ğ‘— satisfies Î”ğ‘¡ğ‘–ğ‘— ğ‘¡ğ‘ ğ‘™ğ‘’ğ‘¤ + ğ‘¡ğ‘ ğ‘’ğ‘¡ğ‘¡ğ‘™ğ‘’ . While the settling time ğ‘¡ğ‘ ğ‘’ğ‘¡ğ‘¡ğ‘™ğ‘’ is modeled as constant, the slew time ğ‘¡ğ‘ ğ‘™ğ‘’ğ‘¤ is derived from trapezoidal velocity profile based on the angular displacement Î”ğœƒğ‘–ğ‘— = 2 arccos qğ‘– qğ‘—, where denotes the unit quaternion. Given maximum angular velocity ğœ”ğ‘šğ‘ğ‘¥ and acceleration ğ›¼ğ‘šğ‘ğ‘¥, ğ‘¡ğ‘ ğ‘™ğ‘’ğ‘¤ is defined as: ğ‘¡ğ‘ ğ‘™ğ‘’ğ‘¤ = (cid:113) Î”ğœƒğ‘–ğ‘— ğ›¼ğ‘šğ‘ğ‘¥ 2 Î”ğœƒğ‘–ğ‘— ğœ”ğ‘šğ‘ğ‘¥ + ğœ”ğ‘šğ‘ğ‘¥ ğ›¼ğ‘šğ‘ğ‘¥ if Î”ğœƒğ‘–ğ‘— < ğœ”2 ğ‘šğ‘ğ‘¥ ğ›¼ğ‘šğ‘ğ‘¥ otherwise (1) In contrast, link terminals (Downlink/Inter-Satellite Link) are gimbaled and Concurrency Constraints rotationally independent. They do not induce attitude constraints and can operate concurrently with observations. Link validity is checked solely against terminal capacity ğ‘ğ‘¡ğ‘’ğ‘Ÿğ‘š (maximum simultaneous links) and resource budgets, ignoring slew dynamics."
        },
        {
            "title": "3.2 Benchmark Tasks",
            "content": "AstroReason-Bench unifies five distinct planning challenges. While the first is an adaptation of an existing standard, the latter four are novel contributions generated procedurally. Benchmark 1: SatNet (DSN Scheduling) We incorporate the SatNet environment [6], standard benchmark for Deep Space Network (DSN) scheduling. The objective is to minimize the unsatisfied time of resource allocation across competing requests. Using the original metrics, we define the unsatisfied ratio for mission ğ‘š â„³ as ğ‘ˆğ‘š = (ğ‘‡ ğ‘š are the total requested and allocated durations for mission ğ‘š, ğ‘Ÿğ‘’ ğ‘, where ğ‘‡ ğ‘š ğ‘Ÿğ‘’ ğ‘ and ğ‘‡ ğ‘š ğ‘Ÿğ‘’ ğ‘ ğ‘‡ ğ‘š )/ğ‘‡ ğ‘š ğ‘ğ‘™ğ‘™ğ‘œğ‘ ğ‘ğ‘™ğ‘™ğ‘œğ‘ and â„³ is the set of missions. The primary metrics are the RMS unsatisfied ratio ğ‘ˆğ‘Ÿğ‘šğ‘  = and the max unsatisfied ratio ğ‘ˆğ‘šğ‘ğ‘¥ = maxğ‘šâ„³ ğ‘ˆğ‘š. (cid:113) 1 â„³ (cid:205)ğ‘šâ„³(ğ‘ˆğ‘š)2 Benchmark 2: Revisit Optimization Monitoring Targets: Let ğ’¯ğ‘šğ‘œğ‘› be the set of targets requiring continuous observation. We minimize the Revisit Gap, defined as the time interval between consecutive observations. Let Î”ğ‘– be the set of gaps for target ğ‘–. The primary metric is the global average gap: ğ‘€ğ‘”ğ‘ğ‘ = 1 ğ’¯ğ‘šğ‘œğ‘› (cid:213) ğ‘–ğ’¯ğ‘šğ‘œğ‘› mean(Î”ğ‘–) (2) Mapping Targets: Require fixed quota of observations. Success is measured by the Coverage Ratio (ğ‘€ğ‘šğ‘ğ‘), the percentage of quotas fulfilled. Benchmark 3: Regional Coverage Designed for satellites capable of strip-imaging modes, such as SKYSAT3 and ICEYE4, this task requires maximizing the area covered within polygons. Unlike point targets, this requires the agent to plan continuous swaths to maximize the coverage of complex polygonal regions. Let ğ’« = {ğ‘1, ğ‘2, . . . , ğ‘ğ‘›} be the set of non-overlapping target polygons, and ğ’® = (cid:208)ğ‘— ğ‘†ğ‘— represent the union of 3https://earth.esa.int/eogateway/missions/skysat 4https://www.iceye.com/ all scheduled observation strips ğ‘†ğ‘—. The coverage performance is evaluated using Area-based Recall (AR), defined as the ratio of the captured target area to the total required area: ğ‘€ğ‘ğ‘œğ‘£ = Area (cid:16) ğ’® (cid:16)(cid:208)ğ‘ğ’« ğ‘ (cid:205)ğ‘ğ’« Area(ğ‘) (cid:17) (cid:17) (3) Benchmark 4: Stereo Imaging This task simulates high-value missions requiring 3D reconstruction. Unlike standard acquisitions, stereo product is only valid if target is captured as doublet of observations that satisfies strict geometric and temporal synchronization. These constraints ensure sufficient parallax for depth estimation while minimizing radiometric changes between images. doublet is valid if it satisfies the following system: ğ‘ğ‘§ ğœƒğ‘ğ‘§,1 ğœƒğ‘ğ‘§,2 Î”ğœƒğ‘šğ‘ğ‘¥ Î”ğœƒğ‘šğ‘–ğ‘› ğ‘¡1 ğ‘¡2 ğ‘‡ğ‘šğ‘ğ‘¥ min(ğœƒğ‘’ğ‘™,1, ğœƒğ‘’ ğ‘™,2) ğœƒğ‘šğ‘–ğ‘› ğ‘ğ‘§ ğ‘’ ğ‘™ (4) where ğœƒğ‘ğ‘§ and ğœƒğ‘’ğ‘™ represent the azimuth and elevation angles, respectively. The constraint on Î”ğœƒğ‘ğ‘§ and ğœƒğ‘’ğ‘™ ensure an appropriate geometric baseline for stereo reconstruction. Specifically, in multi-pass scenarios, the temporal component of azimuth separation serves as determinant for metadata error correlation; accounting for this correlation is essential for accurate vertical error prediction [5]. Benchmark 5: Latency-Optimization This task models Low Earth Orbit (LEO) mega-constellation providing Integrated Sensing and Communications (ISAC) services, such as QIANFAN5. The agent must manage the inherent resource contention between high-priority communication links and opportunistic Earth observation. Communication Services: The objective is to maintain persistent connectivity between ground-station pairs. Performance is quantified by Availability (ğ‘€ğ‘ğ‘£ğ‘ğ‘–ğ‘™), the fraction of time steps where at least one valid routing path exists, and Mean Latency (ğ‘€ğ‘™ğ‘ğ‘¡). We define ğ‘€ğ‘™ğ‘ğ‘¡ as the time-averaged propagation delay of the shortest path available at each epoch: ğ‘€ğ‘™ğ‘ğ‘¡ = 1 ğ’¯ğ‘£ğ‘ğ‘™ğ‘–ğ‘‘ (cid:213) ğ‘¡ğ’¯ğ‘£ğ‘ğ‘™ğ‘–ğ‘‘ delay(ğ‘) min ğ‘ğ’«ğ‘¡ (5) where ğ’«ğ‘¡ is the set of all feasible paths at time ğ‘¡, and ğ’¯ğ‘£ğ‘ğ‘™ğ‘–ğ‘‘ denotes the set of time steps with non-zero availability. Opportunistic Mapping: Simultaneously, the fleet must fulfill fixed observation quota for mapping targets ğ’¯ğ‘šğ‘ğ‘, as defined in Benchmark 2. This requires the agent to exploit idle time-frequency resources or satellite overflights that do not compromise the primary communication backhaul. The metric is the Coverage Ratio (ğ‘€ğ‘šğ‘ğ‘), representing the percentage of completed quotas."
        },
        {
            "title": "3.3 Procedural Dataset Generation",
            "content": "The generation process ensures diversity and physical validity. Constellation Sampling: We sample specific constellation archetypes (e.g., QIANFAN for communications, mixtures of SPOT/PLEIADES for stereo imaging) to preserve realistic orbital distributions. From these families, we subsample 10 to 100 satellites using archived TLE data. 5https://en.wikipedia.org/wiki/Qianfan 5 Figure 2 The Environment and Interface Architecture. The architecture is organized into four layers: (1) The Physics Layer handles stateless physics computation; (2) The Scenario Layer manages session state; (3) The Interface Layer provides access to the environment via semantic MCP tools and Python API; and (4) The Cognitive Layer hosts the LLM agent. Target Distribution: Ground targets are sampled from global database of 40,000+ cities. To ensure feasibility, targets are dynamically filtered based on the average inclination of the selected constellation, ensuring they fall within accessible latitude bands. Temporal Horizon: All generated scenarios span fixed 4-day planning horizon (2025-07-17T12:00:00 to 2025-07-21T12:00:00). This interval was chosen to align with the epoch of our TLE dataset, minimizing propagation errors while providing sufficiently long horizon to test long-term resource management and periodic revisit patterns. Problem Scaling: We control difficulty by maintaining specific Resource-to-Request ratios. For example, Revisit Optimization typically maintains about 4:1 satellite-to-target ratio, whereas Stereo Imaging enforces about tighter 1:1 ratio to induce high resource contention. All generated scenarios are serialized into standard JSON/YAML format, ensuring that the benchmark is reproducible and model-agnostic."
        },
        {
            "title": "4 Environment and Interface Design",
            "content": "Existing benchmarks for agentic software engineering rely on standard compilers and interpreters (e.g., GCC, Python) as their execution environment. In the domain of space planning, while high-fidelity simulators exist (e.g., STK6, Basilisk [14]), they are primarily designed for human experts via GUIs or complex scripting environments, lacking standardized interfaces accessible to autonomous agents. AstroReason-Bench addresses this by establishing system architecture that wraps physics models into agent-ready tools. 6https://www.ansys.com/products/missions/ansys-stk"
        },
        {
            "title": "4.1 Layer 1: Physics Engine (Stateless)",
            "content": "This layer serves as the immutable laws of physics for the environment, integrating three core models: (1) SGP4 Propagation: high-precision orbital propagation provides ground truth for satellite states and geometric visibility; (2) Slew Kinematics: trapezoidal velocity model simulates slew maneuvers for agile satellites, enforcing settling time constraints; and (3) Resource Modeling: resource event manager models power generation (solar) and consumption (action), while handling storage inflow/outflow dynamics for observation and downlink activities."
        },
        {
            "title": "4.2 Layer 2: Scenario Manager (Stateful)",
            "content": "This layer acts as the session controller, maintaining the scenario state. It manages three critical components: (1) Inventory Database: read-only registry of satellites, targets, and stations loaded from external catalogs; (2) Action Registry: mutable timeline tracking all staged actions validating against the mission schema; and (3) State Persistence: file-backed mechanism guarded by advisory locks. To ensure consistency across both interfaces in Layer 3, this locking mechanism enforces atomic updates, preventing race conditions between the semantic and programmatic modalities."
        },
        {
            "title": "4.3 Layer 3: Interface Abstraction",
            "content": "This layer provides the critical bridge between the agent and the physics kernel, exposing the environment through the two complementary modalities: (1) Semantic MCP: the MCP is designed for exploration and interactive debugging. It exposes the environment state as human-readable JSON summaries optimized for the LLMs context window. Key capabilities include state inspection, action staging/unstaging, and rich semantic feedback on constraint violations; (2) Programmatic Python API: to address the arithmetic limitations of LLMs, we expose Python API distributed as local repository. This allows agents to write and execute scripts for batch computation and custom heuristic implementation."
        },
        {
            "title": "5 Experiments",
            "content": "We evaluate range of state-of-the-art LLM-based agentic systems on the AstroReason-Bench suite along two dimensions: (1) quantitative benchmarking against traditional optimization baselines, and (2) qualitative case studies analyzing the reasoning behaviors of agentic workflows (Section 5.3)."
        },
        {
            "title": "5.1 Experiment Setup",
            "content": "We conducted large-scale evaluation evolving 150 full mission simulations across five benchmark categories. Each simulation involves an LLM agent operating autonomously within sandboxed environment, querying orbital mechanics APIs, staging actions, and committing final plans subject to physical validation. Models Our model suite includes six frontier LLM agents: Claude Sonnet 4.5, Gemini 3 Flash, DeepSeek V3.2 [22], Qwen3 Coder [33], DeepSeek V3.1 Nex N1 [2] and Kat Coder Pro [37]. Each model completed 5 cases per benchmark (25 runs per model), with 2-hour timeout per case. Computation was restricted to 16GB memory and 8 CPU cores (AMD Ryzen 7 9700X), representing constrained but realistic deployment scenario. 7https://docs.anthropic.com/en/docs/agents-and-tools/claude-code 7 Baselines For SatNet, we compare against four published baselines: (1) Unweighted and (2) Randomized, two greedy heuristics that schedule activities in order of duration or randomly, proposed by Guillaume et al. [7]; (3) Î”-MILP, Mixed-Integer Linear Programming solver [4]; and (4) RL (PPO), reinforcement learning approach trained via Proximal Policy Optimization [6]. These results are cited from the respective publications. For our novel benchmarks (Revisit Optimization, Regional Coverage, Latency Optimization, Stereo Imaging), we implement two traditional algorithms: Greedy Heuristics: domain-aware greedy scheduler that scores candidate windows using benchmarkspecific heuristics (e.g., gap-since-last-observation for Revisit Optimization, azimuth separation for Stereo Imaging) and stages the highest-scoring valid action at each step. Simulated Annealing (SA): metaheuristic that represents solutions as binary masks over candidate windows, uses neighbor generation (add/remove/swap operations), and accepts worse solutions probabilistically via the Metropolis criterion to escape local minima. These baselines serve as reference implementations rather than optimized solvers. Key limitations include: (1) hyperparameters and heuristics are not carefully tuned for individual benchmarks; (2) the implementation is not optimized for high-throughput computation; and (3) each baseline run is limited to 20 minutes. Given additional computation, baseline performance would likely improve; for reference, MILP solutions in prior work required 20 hours of optimization [4]."
        },
        {
            "title": "5.2 Main Results",
            "content": "5.2.1 Benchmark 1: SatNet (Deep Space Network Scheduling) Method Unweighted [7] Randomized [7] Î”-MILP [4] RL (PPO) [6] Claude Sonnet 4.5 Gemini 3 Flash DeepSeek V3.2 Qwen3 Coder DeepSeek V3.1 Nex N1 Kat Coder Pro Umax Urms 1.00 1.00 0.67 0.77 1.00 1.00 1.00 1.00 1.00 1.00 0.87 0.89 0.30 0. 0.55 0.53 0.57 0.56 0.58 0.59 Table 1 SatNet Results. ğ‘ˆğ‘šğ‘ğ‘¥: maximum unsatisfied ratio (lower is better); ğ‘ˆğ‘Ÿğ‘šğ‘  : RMS unsatisfied ratio (lower is better). LLM agents outperform simple heuristics but lag behind specialized optimizers (MILP, RL). On SatNet, all LLM agents achieve ğ‘ˆğ‘Ÿğ‘šğ‘  scores between 0.530.59, substantially improving over unweighted/randomized baselines (0.870.89) but falling short of specialized approaches. The Î”-MILP solver achieves ğ‘ˆğ‘Ÿğ‘šğ‘  = 0.30 through exhaustive combinatorial optimization, while RL (PPO) reaches 0.32 via thousands of training episodes. LLM agents, operating zero-shot without domain-specific training, demonstrate reasonable scheduling intuition but lack the systematic search capabilities of purpose-built optimizers. 5.2.2 Benchmark 2: Revisit Optimization Analysis SA achieves the best overall performance (ğ‘€ğ‘”ğ‘ğ‘ = 13.65h) by iteratively optimizing fitness function that directly measures gap statistics. Among LLM agents, Claude Sonnet 4.5 leads with ğ‘€ğ‘”ğ‘ğ‘ = 18.83h, demonstrating effective gap-aware scheduling while maintaining full mapping coverage. The Greedy baselines poor mapping coverage (ğ‘€ğ‘šğ‘ğ‘=0.32) reveals critical failure mode: its heuristic assigns low priority to downlink windows relative to observations, causing satellites to exhaust onboard storage Method Greedy Heuristic SA Claude Sonnet 4.5 Gemini 3 Flash DeepSeek V3.2 Qwen3 Coder DeepSeek V3.1 Nex N1 Kat Coder Pro Mmap Mgap(h) 0.32 1.00 1.00 0.86 0.64 0.29 0.61 0. 42.27 13.65 18.83 24.96 29.89 38.58 26.78 22.46 Table 2 Revisit Optimization Results. ğ‘€ğ‘šğ‘ğ‘: average mapping target coverage ratio (higher is better); ğ‘€ğ‘”ğ‘ğ‘: average mean revisit gap in hours (lower is better). SA outperforms all agents. before completing required observations. This illustrates how nearsighted scheduling without resource lifecycle awareness leads to cascading constraint violations. Weaker agents (Qwen3 Coder at ğ‘€ğ‘”ğ‘ğ‘ = 0.29) exhibit similar storage management failures, suggesting that resource planning (balancing data acquisition against downlink capacity) is key differentiator among LLM agents. 5.2.3 Benchmark 3: Regional Coverage Method Greedy Heuristic SA Claude Sonnet 4.5 Gemini 3 Flash DeepSeek V3.2 Qwen3 Coder DeepSeek V3.1 Nex N1 Kat Coder Pro Mcov 0.00 0.03 0.00 0.11 0.05 0.03 0.06 0.03 Table 3 Regional Coverage Results. ğ‘€ğ‘ğ‘œğ‘£ : mean polygon coverage ratio (higher is better). All methods achieve low coverage. Analysis Regional coverage proves challenging for all approaches, with even the best agent (Gemini 3 Flash) achieving only 11% coverage. This benchmark requires fundamentally different strategy: instead of scheduling point observations, agents must decompose polygons into strips (continuous swaths) according to satellite ground tracks before scheduling observations. We identify two primary failure modes: 1. Strip orientation mismatch: Agents typically register strips blindly at mission start without querying satellite ground tracks to understanding constellation geometry. Strips perpendicular to satellite velocity vectors yield near-zero valid observation windows. 2. Storage exhaustion: Strip observations consume substantial storage. Agents that fail to schedule sufficient downlinks cannot complete planned acquisitions. 5.2.4 Benchmark 4: Stereo Imaging Analysis Both baselines achieve 0% stereo coverage, while LLM agents reach up to 18% (Qwen3 Coder). This significant performance gap highlights the agents superior ability to handle compound constraints. The greedy heuristics fail because they optimize for single attributes without looking ahead to satisfy the coupled requirement of second, geometrically distinct observation. In contrast, successful agents explicitly Method Greedy Heuristic SA Claude Sonnet 4.5 Gemini 3 Flash DeepSeek V3.2 Qwen3 Coder DeepSeek V3.1 Nex N1 Kat Coder Pro Mcov 0.00 0.00 0.05 0.06 0.12 0.18 0.03 0.06 Table 4 Stereo Imaging Results. ğ‘€ğ‘ğ‘œğ‘£: stereo pair coverage ratio (higher is better). Baselines completely fail; LLM agents achieve modest success through constraint-aware scheduling. reasoned about the request as stereo pair. They utilized the API interface with Python scripts to search for temporal doublets that satisfied all constraints and then staged both actions simultaneously. This capability to reason about interdependent actions represents key advantage of the agentic paradigm over simple constructive heuristics. 5.2.5 Benchmark 5: Latency Optimization Analysis Latency optimization is the most demanding benchmark, requiring agents to establish real-time, multi-hop relay chains between geographically distant ground stations. This is not store-and-forward; the entire chain station satellite satellite station must be active simultaneously. Method Greedy Heuristic SA Claude Sonnet 4.5 Gemini 3 Flash DeepSeek V3.2 Qwen3 Coder DeepSeek V3.1 Nex N1 Kat Coder Pro (ms) Mmap 0.01 0.30 Mavail 0.00 0.00 0.58 0.20 0.14 0.48 0.09 0.18 0.00 0.00 0.00 0.00 0.00 0.07 Mlat / / / / / / / 58.4 Table 5 Latency Optimization Results. ğ‘€ğ‘šğ‘ğ‘: average mapping target coverage ratio; ğ‘€ğ‘ğ‘£ğ‘ğ‘–ğ‘™: average availability; ğ‘€ğ‘™ğ‘ğ‘¡ : mean latency in milliseconds. Only Kat Coder Pro establishes any valid inter-station connections. As shown in Table 5, nearly all agents fail completely on connection coverage (ğ‘€ğ‘ğ‘œğ‘š = 0). Analysis of agent traces reveal common misconception: agents attempt to find single satellite visible to both stations simultaneously, ignoring that Earths curvature and station separation make this geometrically impossible. Kat Coder Pro is the sole exception, achieving ğ‘€ğ‘ğ‘œğ‘š = 0.07 with ğ‘€ğ‘™ğ‘ğ‘¡ = 58.4 ms. This agent correctly recognized that inter-continental links require multi-hop ISL routing and scheduled coordinated satellite-tosatellite handoffs successfully in two out of five cases. 5.2.6 Summary of Findings Table 6 reveals clear pattern. On benchmarks requiring exhaustive combinatorial search (SatNet, Revisit Optimization), specialized solvers dominate; agents lack the systematic exploration needed to compete. Conversely, on benchmarks where baselines completely fail (Stereo Imaging, Latency Optimization), agents achieve modest but non-trivial success by reasoning about compound constraints and network topology. This suggests that the agentic paradigms strength lies not in raw optimization power, but in its capacity to recognize and adapt to novel problem structures zero-shot. 10 Benchmark Best Baseline Best Agent MILP (0.30) SatNet SA (13.65h) Revisit Optimization SA (3%) Regional Coverage Stereo Imaging Latency Optimization Gemini (0.53) Claude (18.83h) Gemini (11%) Qwen3 (18%) Kat-Coder (7%) Table 6 Capability Summary. Each benchmark isolates distinct planning competency."
        },
        {
            "title": "5.3 Case Studies",
            "content": "To understand why agents succeed or fail, we present qualitative analyses of agent behavior across three representative failure and intervention scenarios. Each case study reveals distinct cognitive limitations and potential mitigation strategies. 5.3.1 Reasoning About Physical Impossibility Phenomenon In latency optimization, where agents control 90 satellites from the QIANFAN constellation, nearly all agents (except Kat Coder Pro) achieved 0% connection coverage. Trace analysis revealed consistent misconception: agents attempted to establish communication by finding single satellite simultaneously visible to both ground stations, which is geometrically impossible in most scenarios due to Earths curvature and LEO orbital altitudes. Example failing agent (e.g., DeepSeek V3.2) queried satellites access windows to both stations, and when this returned no common windows, the agent concluded the task was infeasible rather than considering multi-hop relay chains. Contrast One of Kat Coder Pros successful runs explicitly computed inter-satellite link (ISL) windows and staged an ISL backbone between QIANFAN-1, QIANFAN-7 and QIANFAN-10, enabling end-to-end connectivity, at least to minimal extent. This conceptual leap from seeking common view to constructing network path is illustrated in Figure 3. Implication Agents struggle to recognize the geometrical or physical infeasibility of naive solutions and therefore fail to pivot toward alternatives. This suggests deficits in spatial reasoning ability. 5.3.2 The Exploration-Exploitation Gap Phenomenon In Regional Coverage, agents consistently achieved near-zero coverage despite the benchmark being theoretically solvable. Analysis revealed common pattern: agents registered observation strips almost immediately after reading the mission brief, without first querying satellite ground tracks to understand orbital geometry. In representative Claude Sonnet 4.5 run in regional coverage case 1, where the agent is required Example to plan observations for three polygons (Amazon Basin, Gulf of Mexico, Bay of Bengal) with 15 satellites in SKYSAT8 constellation, the agents first action after querying satellites and stations was to register 5 strips within Bay of Bengal, as shown in Figure 4. These randomly-oriented strips are highly inefficient and do not align with satellites ground tracks, leading to limited access windows. Intervention We re-ran the first case in Regional Coverage using Claude Sonnet 4.5 with Plan Mode manually enabled and an additional hint Analyze available tools and reason about polygon decomposition strategy. 8https://earth.esa.int/eogateway/missions/skysat 11 (A) (B) Figure 3 Single-Hop vs Multi-Hop Communication Strategies. (A) Failed approach: Agents attempt to find single satellite simultaneously visible to both ground stations, which is geometrically impossible due to Earths curvature. (B) Successful approach: Kat Coder Pro constructs multi-hop ISL relay chain, enabling end-to-end connectivity across intercontinental distances. Outcome The agent produced detailed planning document that correctly reasoned about orbital dynamics: Near-polar orbits (9798 inclination) produce ground tracks that are predominantly N-S oriented, maximizing strip coverage efficiency. Strip spacing = 5.0 km (12% overlap buffer for edge effects). [...] This led to N-S oriented strips aligned with satellite velocity vectors, which is correct decomposition strategy, as shown in Figure 4. The final plan achieved 8% coverage, modest improvement over the baseline run (0%). However, the agent still did not query actual ground tracks via get_ground_track(), instead relying on general orbital knowledge. The remaining gap to optimal performance stems from (1) imprecise strip placement without ground track data, and (2) storage exhaustion from aggressive observation scheduling. Implication Structured reasoning phases can unlock latent domain knowledge, but agents exhibit persistent action bias, preferring to reason from memory rather than actively exploring the environment. Access to tools alone is insufficient; agents must be prompted to use exploratory tools before committing to strategies. 5.3.3 RAG-Enhanced Planning Hypothesis Providing agents with domain-specific academic literature may improve strategic planning by exposing effective algorithm patterns. Experiment We re-ran the case of SatNet Week 40 (W40_2018), the most difficult case characterized by extreme oversubscription [4], using Claude Sonnet 4.5. We injected markdown versions of relevant academic papers into the workspace and appended the prompt with Note: The related_works/ folder contains research papers that may provide useful insights and approaches. We compared two conditions: default mode (autonomous) and plan mode (needs manual triggering and plan approval). 12 (A) (B) Figure 4 Polygon Decomposition Strategies for Bay of Bengal. (A) Default mode: The agent registers 5 randomlyoriented strips without querying satellite ground tracks, resulting in limited access windows. (B) Plan mode: The agent correctly reasons about near-polar orbits and produces N-S aligned strips, improving coverage efficiency. In default mode, the agent exhibited strong action bias, skimming only fragments of one to Outcome two papers before acting. This often degraded performance: reading about the problems difficulty led to early resignation while reading about the high baseline scores led to brute-force retries without strategic improvement. The related_works effectively became noise. However, in plan mode, the agent engaged deeply with the literature, synthesizing hybrid strategy from multiple sources. It correctly identified that Systematic backtracking works for small regions but MILP with randomization is needed for full schedules. It proposed and implemented nuanced algorithm: 1. Use MILP randomization for initial schedule (fairness + quality); 2. Apply backtracking to resolve conflicts [...] 3. Use greedy extension for unused antenna time. This RAG+Plan approach yielded significantly better scores (ğ‘ˆğ‘Ÿğ‘šğ‘  0.50) than default runs. Implication Access to knowledge is insufficient; agents need structured workflows instead of raw ReAct loop to consume it."
        },
        {
            "title": "6 Conclusions",
            "content": "In this work, we introduced AstroReason-Bench, the first comprehensive benchmark designed to evaluate generalist agentic planners on heterogeneous space planning problems. By unifying diverse mission profiles under shared physics engine and agent-oriented interface, we exposed both the potential and the current limitations of LLM-based agents. Our evaluation reveals that while agents demonstrate remarkable zero-shot adaptability and the ability to reason about compound constraints, they still lag behind specialized logic in resource management and long-horizon spatial reasoning. AstroReason-Bench provides the necessary testbed to bridge this gap, fostering the development of agents that can reliably operate in the unforgiving environment of space."
        },
        {
            "title": "Limitations",
            "content": "While AstroReason-Bench provides rigorous baseline for agentic space planning, several constraints bound the current study. First, our evaluation focuses on Flash-class models within standard ReAct scaffolding. While this allows for cost-effective analysis of long-horizon interactions, it likely represents lower bound on performance; larger reasoning-intensive models (e.g., Gemini 3 Pro or Claude Opus 4.5) and more sophisticated agentic workflows involving explicit planning or self-correction may yield superior results. Second, the stochastic nature of LLM-based tool use and the limited number of scenarios per mission mean that our reported averages may not fully capture the variance inherent in these workflows. Future iterations will require expanded episode counts and formal confidence intervals to better characterize performance stability. Furthermore, our comparison between generalist agents and specialized optimizers is not compute-matched. Specialized solvers often benefit from extensive offline training, whereas our agents operate under fixed online interaction budgets. Our results should therefore be viewed as diagnostic of adaptability and deployment feasibility rather than claim of absolute optimality. Finally, the current scope of the benchmark is centered on operational scheduling and resource management. Extending AstroReason-Bench to include architectural system design and deep-space trajectory planning remains necessary step toward comprehensive suite for autonomous space systems engineering."
        },
        {
            "title": "Ethics Statement",
            "content": "Research Scope and Data Privacy AstroReason-Bench is diagnostic suite for evaluating LLM agentic planning in physics-constrained Space Planning Problems. It identifies planning failure modes rather than proposing deployment-ready autonomy. The benchmark utilizes publicly available Two-Line Elements and procedurally generated scenarios, containing no personally identifiable information or sensitive geographic attributes. All code and datasets will be released under documented upstream licenses. Compliance and Safety Mitigation We involve no human subjects; all evaluations are automated, sandboxed agent-environment interactions. We comply with all model licenses, reporting aggregate metrics to ensure scientific transparency without disclosing proprietary internals. To mitigate dual-use risks, the suite abstracts spacecraft operations into high-level scheduling and resource allocation, intentionally excluding low-level control or operational procedures for real-world infrastructure. AI-Assistance AI-assisted tools were used for code and language polishing, with all outputs manually reviewed for accuracy and security. Environmental Impact To minimize environmental impact, we employ fixed evaluation budgets (timeouts and resource caps) and report these settings to facilitate fair, cost-aware reproducibility."
        },
        {
            "title": "References",
            "content": "[1] Marco Bagnardi, Pablo GonzÃ¡lez, and Andrew Hooper. High-resolution digital elevation model from tri-stereo pleiades-1 satellite imagery for lava flow volume estimates at fogo volcano. Geophysical Research Letters, 43(12): 62676275, 2016. [2] Yuxuan Cai, Lu Chen, Qiaoling Chen, Yuyang Ding, Liwen Fan, Wenjie Fu, Yufei Gao, Honglin Guo, Pinxue Guo, Zhenhua Han, et al. Nex-n1: Agentic models trained via unified ecosystem for large-scale environment construction. arXiv preprint arXiv:2512.04987, 2025. [3] Xiaoli Cao, Yitao Li, Xingzhong Xiong, and Jun Wang. Dynamic routings in satellite networks: An overview. Sensors, 22(12):4552, 2022. [4] Thomas Claudet, Ryan Alimo, Edwin Goh, Mark Johnston, Ramtin Madani, and Brian Wilson. ğ›¿-milp: Deep space network scheduling via mixed-integer linear programming. IEEE Access, 10:4133041340, 2022. [5] JT Dolloff and HJ Theiss. Temporal correlation of metadata errors for commercial satellite images: Representation and effects on stereo extraction accuracy. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 39:215223, 2012. [6] Edwin Goh, Hamsa Shwetha Venkataram, Bharathan Balaji, Brian Wilson, and Mark Johnston. Satnet: benchmark for satellite scheduling optimization. In AAAI-22 Workshop on Machine Learning for Operations Research (ML4OR), 2021. [7] Alexandre Guillaume, Seugnwon Lee, Yeou-Fang Wang, Hua Zheng, Robert Hovden, Savio Chau, Yu-Wen Tung, and Richard Terrile. Deep space network scheduling using evolutionary computational methods. In 2007 IEEE Aerospace Conference, pages 16. IEEE, 2007. [8] Adam Herrmann and Hanspeter Schaub. Reinforcement learning for the agile earth-observing satellite scheduling problem. IEEE Transactions on Aerospace and Electronic Systems, 59(5):52355247, 2023. [9] Felix Hoots and Ronald Roehrich. Models for propagation of norad element sets. 1980. [10] Xiaoxuan Hu, Waiming Zhu, Huawei Ma, Bo An, Yanling Zhi, and Yi Wu. Orientational variable-length strip covering problem: branch-and-price-based algorithm. European Journal of Operational Research, 289(1):254269, 2021. [11] Carlos Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models resolve real-world github issues? In The Twelfth International Conference on Learning Representations. [12] Mark Johnston and Bradley Clement. Automating deep space network scheduling and conflict resolution. In Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems, pages 14831489, 2006. [13] Mark Johnston, Daniel Tran, Belinda Arroyo, and Chris Page. Request-driven scheduling for nasas deep space network. 2009. [14] Patrick Kenneally, Scott Piggott, and Hanspeter Schaub. Basilisk: flexible, scalable and modular astrodynamics simulation framework. Journal of aerospace information systems, 17(9):496507, 2020. [15] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:2219922213, 2022. [16] Soung Sub Lee, Jong Pil Kim, Eungnoh You, Jae-Hyuk Youn, and Ho-Hyun Shin. Satellite constellation method to achieve desired revisit performance for multiple targets. Journal of Applied Remote Sensing, 18(2):024509024509, 2024. [17] Michel LemaÃ®tre, GÃ©rard Verfaillie, Frank Jouhaud, Jean-Michel Lachiver, and Nicolas Bataille. Selecting and scheduling observations of agile satellites. Aerospace Science and Technology, 6:367381, 2002. [18] Tianzuo Li and Guangyuan Wang. scheduling method for real-time multi-fold regional coverage based on meo constellations. Advances in Space Research, 2025. 15 [19] Wei Li, Xin Zhang, Zhongxin Guo, Shaoguang Mao, Wen Luo, Guangyue Peng, Yangyu Huang, Houfeng Wang, and Scarlett Li. Fea-bench: benchmark for evaluating repository-level code generation for feature implementation. arXiv preprint arXiv:2503.06680, 2025. [20] XM Li. Two-archive2 algorithm for large-scale polygon targets observation scheduling problem. In 2017 2nd International Conference on Information Technology and Management Engineering, pages 16, 2017. [21] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Pete Florence, Andy Zeng, et al. Code as policies: Language model programs for embodied control. In Workshop on Language and Robotics at CoRL 2022. [22] Aixin Liu, Aoxue Mei, Bangcai Lin, Bing Xue, Bingxuan Wang, Bingzheng Xu, Bochao Wu, Bowei Zhang, Chaofan Lin, Chen Dong, et al. Deepseek-v3. 2: Pushing the frontier of open large language models. arXiv preprint arXiv:2512.02556, 2025. [23] Yifeng Lyu, Han Hu, Rongfei Fan, Zhi Liu, Jianping An, and Shiwen Mao. Dynamic routing for integrated satellite-terrestrial networks: constrained multi-agent reinforcement learning approach. IEEE Journal on Selected Areas in Communications, 42(5):12041218, 2024. [24] MartÃ­nez Contreras Johana Milena, Pantoja Benavides GermÃ¡n Fernando, Astrid Xiomara RodrÃ­guez, John Willmer Escobar, and David Ãlvarez-MartÃ­nez. Exact and heuristic algorithms for convex polygon decomposition. Mathematics, 13(24):4038, 2025. [25] Davide Paglieri, BartÅ‚omiej CupiaÅ‚, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Åukasz KuciÅ„ski, Lerrel Pinto, Rob Fergus, et al. Balrog: Benchmarking agentic llm and vlm reasoning on games. In The Thirteenth International Conference on Learning Representations. [26] David Vallado, Paul Crawford, and Richard Hujsak. Revisiting spacetrack report# 3. In AIAA/AAS astrodynamics specialist conference and exhibit, page 6753. [27] Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change. Advances in Neural Information Processing Systems, 36:3897538987, 2023. [28] Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao Kambhampati. On the planning abilities of large language models-a critical investigation. Advances in Neural Information Processing Systems, 36:7599376005, 2023. [29] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. Transactions on Machine Learning Research. [30] Hui Wei, Zihao Zhang, Shenghua He, Tian Xia, ShÄ³ia Pan, and Fei Liu. Plangenllms: modern survey of llm planning capabilities. arXiv preprint arXiv:2502.11221, 2025. [31] Ke Wu, Yasser Bigdeli, Seyed Ali Keivaan, Jie Deng, and Pascal Burasa. Integrated sensing and communication (isac) transceiver: Hardware architectures, enabling technologies, and emerging trends. IEEE Journal of Selected Topics in Electromagnetics, Antennas and Propagation, 2025. [32] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, and Yu Su. Travelplanner: benchmark for real-world planning with language agents. In International Conference on Machine Learning, pages 5459054613. PMLR, 2024. [33] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. [34] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In The eleventh international conference on learning representations. [35] Shunyu Yao, Noah Shinn, Pedram Razavi, and Karthik Narasimhan. tau-bench: benchmark for tool-agent-user interaction in real-world domains. arXiv preprint arXiv:2406.12045, 2024. [36] LU Zezhong, Xin Shen, LI Deren, Dilong Li, Yaxin Chen, Di Wang, and Shuai Shen. Multiple super-agile satellite collaborative mission planning for area target imaging. International Journal of Applied Earth Observation and Geoinformation, 117:103211, 2023. 16 [37] Zizheng Zhan, Ken Deng, Jinghui Wang, Xiaojiang Zhang, Huaixi Tang, Minglei Zhang, Zhiyi Lai, Haoyang Huang, Wen Xiang, Kun Wu, et al. Kat-coder technical report. arXiv preprint arXiv:2510.18779, 2025. [38] Shuyan Zhou, Frank Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, et al. Webarena: realistic web environment for building autonomous agents. In The Twelfth International Conference on Learning Representations."
        }
    ],
    "affiliations": [
        "Fudan University",
        "OpenMOSS Team",
        "Shanghai Innovation Institute"
    ]
}