{
    "paper_title": "miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward",
    "authors": [
        "Azim Ospanov",
        "Farzan Farnia",
        "Roozbeh Yousefzadeh"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We perform a thorough analysis of the formal and informal statements in the miniF2F benchmark from the perspective of an AI system that is tasked to participate in a math Olympiad consisting of the problems in miniF2F. In such setting, the model has to read and comprehend the problems in natural language, formalize them in Lean language, then proceed with proving the problems, and it will get credit for each problem if the formal proof corresponds to the original informal statement presented to the model. Our evaluation results reveal that the best accuracy of such pipeline can be about 36% using the SoTA models in the literature, considerably lower than the individual SoTA accuracies, 97% and 69% reported in the autoformalization and theorem proving literature. Analyzing the failure modes, we trace back a considerable portion of this drop to discrepancies between the formal and informal statements for more than half of the problems in miniF2F. We proceed with correcting all the errors, discrepancies and simplifications in formal and informal statements, and present the miniF2F-v2 with fully verified formal and informal statements and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to the best accuracy of 70%, a significant improvement from the 40% on the original miniF2F, yet indicating considerable misalignment between the autoformalization models and theorem provers. Our deep analysis suggests that a higher quality benchmark can help the community better evaluate progress in the field of formal reasoning and also better diagnose the failure and success modes of autoformalization and theorem proving models. Our dataset is available at https://github.com/roozbeh-yz/miniF2F_v2."
        },
        {
            "title": "Start",
            "content": "5 2 0 8 0 1 3 0 . 1 1 5 2 : r miniF2F-Lean Revisited: Reviewing Limitations and Charting Path Forward Azim Ospanov aospanov9@cse.cuhk.edu.hk Farzan Farnia farnia@cse.cuhk.edu.hk Roozbeh Yousefzadeh roozbeh.yz@gmail.com"
        },
        {
            "title": "Abstract",
            "content": "We perform thorough analysis of the formal and informal statements in the miniF2F benchmark from the perspective of an AI system that is tasked to participate in math Olympiad consisting of the problems in miniF2F. In such setting, the model has to read and comprehend the problems in natural language, formalize them in Lean language, then proceed with proving the problems, and it will get credit for each problem if the formal proof corresponds to the original informal statement presented to the model. Our evaluation results reveal that the best accuracy of such pipeline can be about 36% using the SoTA models in the literature, considerably lower than the individual SoTA accuracies, 97% and 69% reported in the autoformalization and theorem proving literature. Analyzing the failure modes, we trace back considerable portion of this drop to discrepancies between the formal and informal statements for more than half of the problems in miniF2F. We proceed with correcting all the errors, discrepancies and simplifications in formal and informal statements, and present the miniF2F-v2 with fully verified formal and informal statements and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to the best accuracy of 70%, significant improvement from the 40% on the original miniF2F, yet indicating considerable misalignment between the autoformalization models and theorem provers. Our deep analysis suggests that higher quality benchmark can help the community better evaluate progress in the field of formal reasoning and also better diagnose the failure and success modes of autoformalization and theorem proving models. Our dataset is available at https://github.com/roozbeh-yz/miniF2F_v2."
        },
        {
            "title": "Introduction",
            "content": "Automated reasoning with computers has long and rich history [1], and with the rise of AI, it has had major advancements in the past decades, notably DeepBlue [2], AlphaGo [3], etc. Shortly after the rise of Large Language Models (LLMs), [4] showed the remarkable ability of these models to learn the language of formal verification systems such as Lean [5] and automatically prove mathematical theorems in formal language, building on prior work such as [6]. This gave rise to the subfield of Automated Theorem Proving (ATP) in the machine learning literature which has seen considerable advancements in the past few years [7]. The shared progress in this field was partly made possible by the miniF2F benchmark [8] which consists of 488 theorems in formal and informal languages drawn from prestigious mathematical competitions and Olympiads. Writing mathematical proofs in formal language makes the verification of proofs automated and reliable, however, learning and writing the language of formal verification systems is not easy for humans nor for the LLMs. For human, it might take 10 times longer to write proof in formal language compared to an informal one. LLMs, on the other hand, are likely to excel at learning these Huawei Hong Kong Research Center Department of Computer Science & Engineering, The Chinese University of Hong Kong 39th Conference on Neural Information Processing Systems (NeurIPS 2025). Figure 1: High-level overview of formal math prover system operating in Math Olympiad setting. formal languages, and combined with other automated reasoning tools, they may help automate the process of mathematical reasoning. This has given rise to one of the main goals of the community: developing AI systems that can compete with humans in major mathematical Olympiads [9]. For example, in 2024, AlphaProof was able to reach the level of silver medal at the International Math Olympiad (IMO) [10]. Reaching that level of automated reasoning requires model to automatically read mathematical problem in informal language, formalize it in formal verification language, and generate correct formal proof that can pass the verification system. Such automated system would fail if it changes the original problem statement and proves an altered version of the competition problem, the same way that if human participant proves simplified version of problem will likely get no, or at the most, partial credit not sufficient for medal. Therefore, having models that can correctly translate to formal language is crucial, otherwise, there will be need for human in the loop to perform the formalizations. This translation, known as autoformalization in the literature, has seen major advancements on the miniF2F benchmark [11]. While the miniF2F benchmark has enabled advancements both in ATP and in autoformalization, over the years, it has also been reported to have certain limitations, such as wrong formalizations, unprovable theorems, etc. Most recently, [12] reported fixing errors in 5 theorems of miniF2F which had made them unprovable. The community on autoformalization has also reported certain inconsistencies between the formal and informal statements in miniF2F [13]. This motivates us to conduct deep analysis of this benchmark from the holistic perspective described above. In this framework, an AI system is tasked with participating in miniF2F competition. The system must prove all 488 theorems in the benchmark from their informal statements, with the goal of producing correct proofs for the original formulations. Figure 1 illustrates the stages at which failures can prevent an AI system from arriving at correct solution in Math Olympiad setting: 1. Autoformalization failure: The autoformalizer fails to write formal statement that passes the formal verification compiler, e.g., Lean. In this case, the output of the autoformalizer cannot be passed to the prover, and the AI pipeline fails automatically. 2. Translation failure: The autoformalizer produces formal statement that passes the compiler error-free. However, the formal statement does not match the informal one, i.e., the translation is not accurate. Such formal statement will then be passed to the prover model. If the prover model fails to prove the problem, the pipeline automatically fails. However, if the prover model succeeds in proving such formal statement, the judge will not give credit to the proof because it does not correspond to the original problem in the Olympiad. This is the case most prone to being neglected and inaccurately counted toward the success of AI models without human expert examining the final proof. 2 3. Prover failure: The prover fails to prove, leading to the automatic failure of the AI pipeline. If the autoformalized statement is correct translation of the informal one, this failure can be interpreted as shortcoming of the prover model. However, it may be the case that the formal statement is incorrectly translated by the autoformalizer, making it unprovable or more difficult than the original problem, and such mistranslation may be the root cause of the provers failure. In the latter case, the failure of the end-to-end pipeline may be attributed to the autoformalizer. In this work, we build such an automated pipeline by using the SoTA models for autoformalization and for theorem proving. While the accuracy of the best autoformalization model on miniF2F is reported to be about 97% [14], and the accuracy of Kimina Prover on miniF2F is 70.8% [12], the combined accuracy of these models leads to an accuracy of 34.8% after comparing the final proofs with the original problem statements in informal language. This significant drop in accuracy comes from several sources which we will examine in detail, two of which account for most of the failures. Our extensive human evaluation of autoformalization results, across five models, reveals that their autoformalization accuracy is not as high as the ones reported in the literature, because those reported accuracies are often evaluated by LLMs and not by human familiar with the formal language. The other reason for this major drop is that the formal statements in miniF2F, i.e., the starting point of the automated system, are often significantly simplified compared to the informal statements, and hence, when more faithful translations are given to ATPs, the theorems turn out to be more difficult, making the ATPs more likely to fail. Therefore, we observe disconnect between the ATP literature and the autoformalization literature. We analyze every failure mode of an end-to-end formal reasoning pipeline on the miniF2F benchmark and correct over 300 Lean 4 statements to eliminate errors and simplifications. Since our starting point is the original miniF2F, we take two steps to modify it, leading to two variations: miniF2F-v2s and miniF2F-v2c. For miniF2F-v2s, where stands for simplified, we only correct the mistakes in the informal statements and then modify the formal statements to exactly match the informal ones. This version is closer to miniF2F-v1, yet all theorems are correct and provable, and there are no discrepancies between the informal and formal statements. For all the problems where the formal statement contains the solution, we make sure the informal statements reflect the solutions as well. We then take another step which leads to miniF2F-v2c where stands for competition. Here, we change the informal statements to reflect the exact statements in the original competitions for all the problems from IMO and AMC. If problem has multiple choices, we keep all the choices in the informal statement and also include the choices in the formal one. Hence, the model has to first choose the correct choice and then prove it, adding an extra level of difficulty to the theorems. When original informal statement does not provide solution and asks for the participant to first find the solution and then prove it, we also do not provide the solution in the informal and formal statements. Our contributions are as follows: We release two corrected versions of miniF2F benchmark (both test and validation sets): simplified and competition-level. All the informal and formal statements are manually checked to exactly correspond to each other. We perform thorough evaluation of autoformalization models on miniF2F-v1, v2s, and v2c, demonstrating the current shortcomings in the evaluation practices in the autoformalization literature as well as the benefits of miniF2F-v2s and v2c. We perform thorough evaluation of miniF2F-v2s and v2c for the task of ATP reporting that the accuracy of SoTA models drop significantly on the problems that were excessively simplified, yet their accuracy increases on the subset of problems that were previously unprovable because of formalization errors. We further evaluate complete automated pipeline of SoTA models on the task of theorem proving starting from informal statements and report their accuracy both on the original version of miniF2F and miniF2F-v2 demonstrating the better accuracy of such pipelines on miniF2F-v2."
        },
        {
            "title": "2 Reviewing the miniF2F in detail",
            "content": "In this section, we detail various types of changes that we made in the original miniF2F benchmark for both formal and informal statements. Detailed information about the distribution of made changes can be found in Appendix H. 3 Figure 2: Correction example of amc12b_2021_p3 problem in miniF2F across versions 1, 2s and 2c. 2.1 Errors in informal statements Incomplete statements. There are problems that do not provide enough information or do not mention the type of variables. There are also instances where the informal statement differs from the original problem statement presented in the competitions such as IMO. In all such cases, we use the original informal statements. Unprovable problems. These set of problems miss critical hypotheses to prove the goal; therefore, making them unprovable. Multiple choices in the statement. In miniF2F-v2s, we filtered the informal statements from multiple choice style answers to reflect only the final goal to be proved. In miniF2F-v2c, we added all the choices to the formal statements. Figure 2 illustrates an example. In v2c, we remove the correct answer from the informal statement so that it matches the original AMC statement, and introduce the multiple-choice options in the formal statement. In v2s, we omit the multiple-choice options from the informal description so that it matches the formal statement leading to simplified problem where the solution is known. Additional examples can be found in the Appendix. Wrong given solution. Another subset of incorrect informal statements provide wrong or inconsistent solution that deviates from the original problem statement and solution. No given solution. Some of the informal statements do not provide solution after the problem description, yet the formal statements contain the solution. For miniF2F-v2s, we add the solution to the informal statements. For miniF2F-v2c, we remove the solution from the formal statement and provide sorry for the ATP model to find and prove. 2.2 Errors in formal statements Excessively simplifying the problem by changing the goals or changing the conditions. This subset of problems aim to prove simpler goals compared to the original informal description. These problems do not reflect the original difficulty of the problem; therefore, making the LLMs task easier. We segregate these problems into two categories: simplified and excessively simplified. The common culprits behind simplification are omitting part of the informal statement, simplifying the goals, adding helpful assumptions, wrong type declarations (e.g., proving goal for non-negative real numbers instead of all real numbers, or using equivalences instead of functions). Excessive simplification cases are those where the goal is significantly altered. Not using the correct functions/expressions in Lean. Another subset of formal errors are incorrect declaration of functions and expressions. In some cases, informal statements describe conditions, functions, etc, whereas the formalized version does not declare them. We fix these inconsistencies in our revised versions of miniF2F. 4 Table 1: Comparison of effective accuracy across different autoformalizers and theorem provers. Effective accuracy refers to final accuracy after autoformalizer formalizes the problem statements and theorem prover attempts to prove them. Experiments are performed with @128 for translators and @32 for theorem provers. Numbers in blue are gains in accuracy as result of higher quality benchmark. Numbers in red are drop in accuracy as result of increased difficulty compared to the simplified problems in miniF2F-v1. miniF2F Verification Setting Theorem prover accuracy (%) excessively simplified proofs DeepseekProverV1.5-RL GoedelProverSFT KiminaProverDistill-7B DeepSeekProverV2-7B GoedelV2-7B full score 34.4 37.7 41.0 50.8 54.1 34.0 (-0.4) 37.7 (0) 42.2 (+1.2) 47.5 (-3.3) 53.3 (-0.8) 33.2 (-1.2) 36.9 (-0.8) 39.3 (-1.7) 43.4 (-7.4) 48.4 (-5.7) no score (Olympiad setting4) 21.7 31.1 (+9.4) 30.3 (+8.6) 24.2 34.8 (+10.6) 34.0 (+9.8) 27.5 38.9 (+11.4) 36.5 (+9.0) 33.2 44.7 (+11.5) 40.6 (+7.4) 36.9 50.0 (+13.1) 44.7 (+7.8) ver. v1 v2s t v2c v1 v2s v2c r l r a H z m o a K l i full score no score (Olympiad setting) v1 v2s v2c v1 v2s v2c v1 full score v2s e v2c v1 v2s v2c 43.0 47.1 50.0 62. 64.3 43.0 (0) 46.3 (-0.8) 50.0 (0) 58.6 (-4.1) 59.4 (-4.9) 41.4 (-1.6) 43.4 (-3.7) 46.3 (-3.7) 52.9 (-9.8) 53.3 (-11) 31. 34.4 36.9 44.7 46.7 40.2 (+8.6) 43.4 (+10) 47.1 (+10.2) 55.7 (+11) 56.1 (+9.4) 38.5 (+6.9) 40.6 (+6.2) 43.4 (+6.5) 50.0 (+5.3) 51.2 (+4.5) 42.2 48.0 60.2 69. 77.5 43.9 (+1.7) 47.6 (-0.4) 62.3 (+2.1) 63.5 (-6.2) 74.2 (-3.3) 40.6 (-1.6) 46.7 (-1.3) 56.1 (-4.1) 55.7 (-14) 65.6 (-11.9) no score (Olympiad setting) 24.2 41.8 (+17.6) 38.1 (+13.9) 27.9 47.5 (+19.6) 44.3 (+16.4) 35.2 58.6 (+23.4) 52.0 (+16.8) 40.2 60.2 (+20) 52.5 (+12.3) 49.2 69.7 (+20.5) 61.5 (+12.3) v2s v2c v1 v2s v2c a d v full score no score (Olympiad setting) 52.0 55.3 64. 75.4 78.7 51.6 (-.4) 52.8 (-2.5) 65.6 (+0.8) 72.1 (-3.3) 74.6 (-4.1) 47.5 (-4.5) 52.0 (-3.3) 60.7 (-4.1) 63.5 (-11.9) 66.4 (-12.3) 38.1 40.6 46.7 51.2 54.9 48.0 (+9.9) 52.0 (+11.4) 61.1 (+14.4) 68.4 (+17.2) 70.1 (+15.2) 43.9 (+5.8) 48.4 (+7.8) 56.6 (+9.9) 60.2 (+9) 62.3 (+7.4) Unprovable statements. We identified total of 16 problems across test and validation sets that do not have solution in their current form, which is critical factor when it comes to reliable evaluation of theorem provers. The errors come from improper translation of the informal statement to formal counterpart, such as missing brackets or using wrong function from the Mathlib library. 3In this setting, simplification is rewarded and encouraged. If LLM, proves an excessively simplified modification of problem, it still gets full credit. This is the setting that is perhaps inadvertently being used to evaluate the accuracy of formal reasoning models. 4Each Olympiad, or competition, may have different rules on giving partial scores, and these rules might even change year by year. To make our evaluation clear, we opted for the choice of giving no credit for excessively 5 Table 2: Comparison of autoformalization accuracy of Herald and Kimina translators at @128 between LLM and human evaluators. Back translation and LLM equivalence check pipeline is adopted from [14]. Translator Evaluator miniF2F-v1 miniF2F-v2s miniF2F-v2c test valid test valid test valid Herald Kimina Heralds automated judge Human 97.5% 97.1% 96.7% 97.5% 95.1% 97.1% 62.7% 69.7% 66.0% 68.9% 54.1% 60.2% Heralds automated judge Human 98.4% 98.4% 99.6% 98.8% 98.4% 98.8% 90.6% 88.1% 91.0% 88.1% 75.4% 76.6%"
        },
        {
            "title": "3 Evaluation of complete formal reasoning pipelines starting from informal",
            "content": "statements This section presents our experiments with an end-to-end pipeline that aims to prove informal theorems with the aid of formal theorem prover systems. The setting is motivated by Math Olympiadstyle problems, where the task is to produce correct solution for given informal statement. We selected every original problem used to construct the miniF2F benchmark and employed them to evaluate how well state-of-the-art autoformalizers can work with SoTA theorem provers. For each problem we begin by feeding the informal statement to an autoformalizer; we keep the first formal output that both passes REPL verification and remains semantically faithful to the source, which is judged by human experts. We then attempt to prove the resulting goal with several theorem provers, and finally we compare the derived theorem with the original problem, recording any discrepancies. We refer to final accuracy of autoformalizer and theorem prover collaboration as \"effective accuracy\". Table 1 summarizes our end-to-end results on miniF2F-v1 and miniF2F-v2. For each pair of autoformalization and theorem provers, we report two effective accuracy metrics: (i) the percentage of proofs that pass REPL verification giving credit to all proofs even for the ones that are excessively simplified compared to the original informal statements, and (ii) the percentage of proofs that both pass verification and align with the original problem statement, i.e., the Olympiad setting. This table highlights the impact of having high quality and error-free benchmark where all theorems are provable, and all the formal and informal statements match each other. For all pairs of autoformalization and theorem provers, effective accuracy is considerably higher on miniF2F-v2s and v2c compared to v1 when the pair of models are evaluated in the Olympiad setting\". This gain in accuracy is despite the fact that v2 versions of miniF2F are more difficult. In the full score\" setting, however, where the LLMs get full credit for proving excessively simplified problems, the accuracy on v2 versions of miniF2F are considerably lower. More detailed analysis of these results are explained in the following sections where we evaluate the accuracy autoformalizers and theorem provers separately on each version of miniF2F."
        },
        {
            "title": "4 Evaluation of autoformalization models",
            "content": "This section evaluates the performance of autoformalizers on miniF2F-v1, v2s and v2c. The most notable observation of this section is that the reported accuracy of autoformalization models in the literature are largely inflated as those evaluations are typically performed by LLMs. For example, when we perform human review of the outputs of Herald @128 that LLM has marked as 97% correct, we arrive at much lower accuracy of 66%. And the same observations hold for Kimina autoformalizer. We consider two specialized autoformalization systems, Herald translator [14] and Kimina autoformalizer [12], and one general-purpose model, o4-mini [15]. All experiments use sampling budget of @1 or @128 for the dedicated autoformalizer models and @10 (with intermediate compiler simplified proofs while giving full credit for the simplified proofs. In most Olympiads, an excessively simplified proof will get zero or close to zero score. 6 Table 3: Comparison of autoformalization accuracy of Herald translator, Kimina autoformalizer and o4-mini on the original version of miniF2F (miniF2F-v1) and miniF2F-v2. The o4-mini translation has sample budget up to @10, but the generation stops at the first correctly compiled attempt, while other models are evaluated with @1. miniF2F ver. split verified by Model Formalization Accuracy (%) Herald translator Kimina autoformalizer o4 mini v1 v1 v2s v2s v1 v1 v2s v2s test test test test valid valid valid valid LLM human LLM human LLM human LLM human 49.6% 55.3% 49.2% 51.6% 51.2% 59.4% 50.4% 48.0% 58.6% 88.1% 54.5% 79.5% 57.8% 82.0% 51.6% 78.7% - 46.3% - 51.6% - 47.1% - 52.5% feedback) for o4-mini. We note that although o4-mini has different sample budget, we stop at the first successful compilation attempt, which puts it on par with @1 Herald translator and Kimina autoformalizer models. We exclude any autoformalization outputs that fail to pass the Lean compiler to ensure syntax correctness. Lean compiler of choice is Lean REPL [16]. To evaluate Herald translator, Gao et al. [14] used InternLM2-Math-Plus-7B [17] for back-translation and DeepSeek Chat v2.5 [18] for equivalence verification. As observed by Ye et al. [19], using an LLM as judge reduces verification overhead but can diverge from human judgments. In our experiments, we did not change back-translation model; however we used Deepseek-V3 [20], instead of Deepseek-V2.5 for natural language validation. To present accurate results aligned with the human grasp of presented problems, we manually verified every translation and report both LLM-based and human-verified accuracies. All human verifications were conducted by Lean experts. For the @128 setting, human evaluation is performed only on the first translation that successfully passes the Lean compiler, rather than on all 128 translations. Table 2 compares the accuracy of the LLM evaluator with human verification on both versions of miniF2F, using the Herald translator and Kimina autoformalizer with sampling budget of @128. The LLM tends to produce false positives and therefore reports much higher accuracy than human evaluator. In many cases, it treats small discrepancies between statements as negligible even though they significantly affect the meaning of the statements; as shown in Section 3, these differences accumulate and reduce the practicality of full informal-to-formal pipelines. Consequently, autoformalizations should be evaluated with great care, and semantic alignment must remain strict. To broaden our study, we conducted @1 experiments with Herald translator, Kimina autoformalizer, and o4-mini. Here, the opposite pattern appears: the LLM evaluator assigns lower accuracies than the human evaluator. We hypothesize that with larger sampling budget the LLM has higher chance of hallucinating and assigning incorrect labels, whereas at @1 it behaves more conservatively. Moreover, while human evaluation at @128 shows only 1015% improvement over @1, the LLM evaluation suggests almost double the gains. Kimina Autoformalizer attains higher accuracy than Herald Translator under both LLM-based and human verification, with accuracies ranging from 78% to 88% across both versions of miniF2F. However, when evaluating on miniF2F-v1 against miniF2F-v2, both Herald Translator and Kimina Autoformalizer exhibit performance decline, whereas o4-mini improves on the corrected dataset. This finding suggests that current autoformalizers may suffer from data contamination. We also present the failure modes of each autoformalization model by topic in Appendix I. This analysis highlights the types of mathematical domains where current autoformalizers struggle the most, providing guidance for future works."
        },
        {
            "title": "5 Evaluation of theorem provers on formal statements",
            "content": "In this section we conduct series of experiments only with whole-proof generation LLMs starting from the formal statements in the miniF2F-v1, v2s, and v2c. This is to provide insights about the 7 Table 4: Comparison of whole-proof generation models accuracy on the original version of miniF2F and miniF2F-v2. Dataset v1-test v2s-test v2c-test v1-valid v2s-valid v2c-valid Deepseek-ProverV1.5-RL Goedel-ProverSFT Kimina-ProverDistill-7B 50.0% 41.0% 38.1% 63.9% 55.3% 52.0% 58.2% 48.4% 46.3% 68.9% 59.8% 57.8% 65.2% 59.0% 57.0% 73.0% 68.0% 67.6% DeepSeekProverV2-7B GoedelV2 73.4% 68.1% 64.4% 79.4% 73.4% 70.5% 82.0% 74.2% 72.5% 83.6% 77.9% 73.4% Table 5: Comparison of whole-proof generation models accuracy on the subset of problems in miniF2F-v2 that were previously unprovable on the original version of miniF2F. Unprovable subset Deepseek-ProverV1.5-RL GoedelProverSFT KiminaProverDistill-7B DeepseekProverV2-7B GoedelV2 miniF2f-v2s-test (out of 13) miniF2f-v2s-valid (out of 3) 4 (30.8%) 4 (30.8%) 5 (38.5%) 5 (38.5%) 8 (61.5%) 1 (33.3%) 1 (33.3%) 1 (33.3%) 1 (33.3%) 1 (33.3%) differences in the formal statements of the two versions of miniF2F while ablating the effect of autoformalizers. Following the literature, we use sampling budget of @32 in all runs. DeepseekProver-V1.5-RL [21], Goedel-Prover-SFT [22] and Deepseek-Prover-V2-7B [23] are evaluated under Lean v4.9.0, matching the versions used in their original papers, whereas Kimina-Prover-Distill7B [12] is tested with the newer Lean v4.17.0. All experiments were performed on eight NVIDIA A5000 GPUs with 128 CPU cores. Performance of theorem provers on miniF2F-v2. Table 4 reports the accuracy of selected theorem provers on miniF2F-v1, v2s, and v2c. Notably, the accuracy of every theorem prover is lower on miniF2F-v2, since many simplifications made in miniF2F were reverted back, and theorems became more challenging. The proposed dataset poses greater challenge to state-of-the-art LLMs. We observe that increased difficulty of v2c leads to 11.2% drop in accuracy for Deepseek-Prover-V2-7B, and many failure cases come from Math Olympiad level problems that are especially hard to prove. Performance of theorem provers on the modified problems in miniF2F-v2. Although the overall accuracy declines on miniF2F-v2, it is important to note that this version corrects sixteen statements that were unprovable in the original benchmark. All theorem provers can now solve subset of these repaired problems, which raises their accuracy on this specific group of tasks. The results are reported Table 6: Comparison of whole-proof generation models accuracy on the subset of problems in miniF2F-v2 that were simplified in the original version of miniF2F. KiminaProverDistill-7B Deepseek-ProverV1.5-RL DeepseekProverV2-7B GoedelProverSFT Simplified subset GoedelV2 miniF2F-v1-test (out of 40) miniF2f-v2s-test (out of 40) miniF2F-v1-valid (out of 48) miniF2f-v2s-valid (out of 48) 29 (72.5%) 30 (75.0%) 31 (77.5%) 36 (90.0%) 37 (92.5%) 23 (57.5%) 24 (60.0%) 25 (62.5%) 29 (72.5%) 33 (82.5%) 27 (56.2%) 29 (60.4%) 30 (62.5%) 34 (70.8%) 38 (79.2%) 25 (52.1%) 25 (52.1%) 27 (56.2%) 31 (64.6%) 35 (72.9%) Table 7: Comparison of whole-proof generation models accuracy on the subset of problems in miniF2F-v2 that were excessively simplified in the original version of miniF2F. Excessively Simplified subset Deepseek-ProverV1.5-RL GoedelProverSFT KiminaProverDistill-7B DeepseekProverV2-7B GoedelV2 miniF2F-v1-test (out of 45) miniF2f-v2s-test (out of 45) miniF2F-v1-valid (out of 36) miniF2f-v2s-valid (out of 36) 21 (46.7%) 33 (73.3%) 33 (73.3%) 37 (82.2%) 42 (93.3%) 10 (22.2%) 13 (28.9%) 24 (53.3%) 27 (60.0%) 36 (80.0%) 26 (72.2%) 26 (72.2%) 28 (77.8%) 29 (80.6%) 31 (86.1%) 7 (19.4%) 9 (25.0%) 17 (47.2%) 17 (47.2%) 19 (52.8%) in Table 5. Since we provide the formal proofs for all problems in miniF2F-v2, one can be sure that all theorems are provable. To further assess the impact of our revisions, we compare prover accuracy on the previously defined simplified and excessively simplified subsets. Table 6 shows that theorems in the simplified group pose only modest challenge: accuracy falls for every model, yielding 15-18 % drop on the test set, while the validation set experiences an even smaller decline. The picture changes significantly for the excessively simplified subset. Here, every model struggles: test-set accuracy decreases by more than 20%, and the validation set loses over 30%. Deepseek-Prover-V1.5-RL and Goedel-Prover-SFT suffer the largest losses, in some cases up to 4050%. In contrast, Kimina-Prover-Distill-7B remains comparatively robust, proving 53.3% of the test problems and 47.2% of the validation problems, indicating strong generalization. Deepseek-Prover-V2-7B also struggles with more challenging counterparts and exhibits 22.2% drop in test set and 33.4% drop in validation set. By making the subset of problems closer to the intended difficulty, we see that each LLM struggles at least with some of the new theorems. This indicates the importance of the renewed version of miniF2F with scaled difficulty."
        },
        {
            "title": "6 Related Works",
            "content": "Autonomous AI systems excelling in reasoning and scientific discovery. With the rise of generative models, we have seen their success in scientific discoveries [24]. For example, FunSearch [25] succeeded in writing bin-packing algorithm that is faster than any human written algorithm. These systems, usually consisting LLM at their core, have shown remarkable ability in automated reasoning. For example, AlphaGeometry [26] was able to reach gold-medal level in solving geometry problems at IMO. AlphaProof [10], similarly reached silver-medal level in proving IMO problems in number theory and algebra. Other examples include AlphaCode [27] and AlphaEvolve [28]. Silver and Sutton [29] suggest that we will see new generation of AI agents that will reach unprecedented abilities predominantly by learning from experience. This argument largely draws not just from recent successes of AI systems, but also looks back at the successes of systems such as AlphaGo which was able to learn the game of Go merely by playing with an automated adversary, and ultimately reaching the level of expertise to beat the human champion. When the same algorithm was transformed to play the Japanese chess, it also passed the best human performance while the model developers had no familiarity with the Japanese chess. Indeed, the strategies utilized by the model were known to fail by human champions, yet the models devised them in ways that were able to beat those same champions. The idea here is that to make new discoveries or to arrive at models that can find better ways of playing game or can excel at proving mathematical theorems, the models have to be given the space to explore the possibilities by themselves with no or minimal human intervention. From this perspective, fully automated pipeline for mathematical reasoning would be preferable to pipeline that needs human in the loop for formalization, etc. Hence, in this work, we suggest fully automated pipeline to evaluate AI systems for formal reasoning. 9 Automated Theorem Proving. Automatically proving mathematical theorems has rich history including SAT and SMT solvers. In recent years, LLMs have shown remarkable capability to generate formal proofs by themselves [30, 31, 30, 32, 33, 34, 12] or with help from other automated systems such as retrieval-based and/or search methods [35, 34, 36, 37, 38, 10, 39]. Before the release of Kimina Prover, SoTA LLMs on the task of theorem proving were only able to prove theorems with relatively short proofs in formal language [40], heavily relying on automated solvers in Lean such as nlinarith. The longest proof written by Goedel Prover on miniF2F consisted of 10 lines. Kimina Prover, however, increased this limit to few hundred lines using longer context length. Autoformalization. This can be viewed as translation task [41, 42] where statements from informal language are translated to the language of formal verification system such as Lean. Informalization is the reverse translation from formal language to an informal one which is considered an easier task. LLMs have shown remarkable ability in translation tasks especially when large corpus of text are available in two or more languages. Similarly LLMs are good at writing code in languages such as Python and C++ [43]. We also have seen gradual improvements in the accuracy of LLMs in autoformalization [11, 34]. Herald [14], the current state-of-the-art in the literature, reports an accuracy of 97% on the miniF2F while its accuracy is measured by an LLM and not verified by human familiar with Lean. There are generally two difficulties in the field of autoformalization. First, high quality data paired in formal and informal languages is scarce. Second, there are no automated systems that can reliably verify the correctness of translation [44], and as we will see, LLMs may not be reliable in evaluating whether translation is correct. Even when the ground truth is available in formal language, it may not be easy, for human nor LLM, to evaluate whether freshly generated formal statement is equivalent to the ground truth. There has been considerable work in this domain trying to automate the evaluation of equivalent formal statements [45, 46]. Benchmarks for formal reasoning. Over the past few years, the community has introduced several formal-mathematics benchmarks of varying difficulty. ProofNet [47] focuses on undergraduatelevel mathematics, while PutnamBench [48] collects problems from the William Lowell Putnam Competition (19622023). NuminaMath [49] and miniCTX [50] target advanced theorems drawn from Lean projects and textbooks. Recently proposed, Con-NF [44] is specifically designed for an autoformalization task. In this work, we concentrate on the miniF2F dataset [51], which consists of 488 problems sourced from textbooks and competitions such as IMO, AIME, and AMC. Reliability of mathematical benchmarks. Ensuring the reliability of LLM benchmarks is critical concern for the research community. To accurately assess model capabilities, benchmarks must be both comprehensive and error-free. Vendrow et al. [52] evaluated numerous datasets across various tasks and introduced the concept of platinum benchmarks, i.e. those containing minimal errors and verified by human experts. The integrity of these benchmarks is essential for measuring progress in formal reasoning. Accordingly, we dedicate our efforts to exhaustively verify the miniF2F dataset."
        },
        {
            "title": "7 Limitations",
            "content": "This work only covers Lean language, even though miniF2F is available for other languages, too. Our corrections to the informal statements are applicable to all users of miniF2F."
        },
        {
            "title": "8 Conclusion",
            "content": "We introduced miniF2F-v2, revised version of the miniF2F benchmark. Hundreds of theorems were re-verified and changed to match the difficulty of their source problems, and the sixteen unprovable statements in the original dataset were fixed. To recreate realistic setting of math Olympiad competitions, using the SoTA models in the literature, we built completely automated pipeline of theorem proving starting from natural language statements. Our evaluation results show that in such setting the accuracy of current models will significantly drop on miniF2F-v1. However, when we do the same evaluation on miniF2F-v2, some of the lost accuracy is gained back because of the higher quality of the revised dataset. We further compared LLM evaluation of the outputs of autoformalization models with expert human verification and observed substantial gap: LLMs marked many formalizations as correct even though they differed from the intended statements. By our evaluation, the accuracy of SoTA autoformalization model on miniF2F-v1 is 66%, not the reported 97%. We hope that miniF2F-v2 will serve as clearer and more demanding benchmark and will guide future progress in both autoformalization and formal theorem proving."
        },
        {
            "title": "Acknowledgments",
            "content": "The work of Farzan Farnia is partially supported by grant from the Research Grants Council of the Hong Kong Special Administrative Region, China, Project 14209920, and is partially supported by CUHK Direct Research Grants with CUHK Project No. 4055164 and 4937054. The authors also thank the anonymous reviewers for their helpful feedback and constructive suggestions."
        },
        {
            "title": "References",
            "content": "[1] Alan Turing. Intelligent machinery, heretical theory. Philosophia Mathematica, 4(3), 1948. [2] Bruce Pandolfini. Kasparov and Deep Blue: The historic chess match between man and machine. Simon and Schuster, 1997. [3] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of Go without human knowledge. Nature, 550(7676):354359, 2017. [4] Stanislas Polu and Ilya Sutskever. Generative language modeling for automated theorem proving. arXiv preprint arXiv:2009.03393, 2020. [5] Leonardo de Moura and Sebastian Ullrich. The lean 4 theorem prover and programming language. In Automated Deduction CADE 28: 28th International Conference on Automated Deduction, Virtual Event, July 1215, 2021, Proceedings, page 625635, Berlin, Heidelberg, 2021. Springer-Verlag. [6] Kaiyu Yang and Jia Deng. Learning to prove theorems via interacting with proof assistants. In International Conference on Machine Learning, pages 69846994. PMLR, 2019. [7] Kaiyu Yang, Gabriel Poesia, Jingxuan He, Wenda Li, Kristin Lauter, Swarat Chaudhuri, and Dawn Song. Formal mathematical reasoning: new frontier in AI. In Proceedings of the International Conference on Machine Learning, 2025. [8] Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. miniF2F: cross-system benchmark for formal Olympiad-level mathematics. In International Conference on Learning Representations, 2021. [9] The AIMO Prize: Airtificial Intelligence Mathematical Olympiad. https://aimoprize.com/. [10] Google DeepMind. olympiad ematical ai-solves-imo-problems-at-silver-medal-level/, 2024. 08. AI achieves silver-medal standard solving international mathproblems. https://deepmind.google/discover/blog/ 2025-05Accessed: [11] Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus Rabe, Charles Staats, Mateja Jamnik, and Christian Szegedy. Autoformalization with large language models. Advances in Neural Information Processing Systems, 35, 2022. [12] Haiming Wang, Mert Unsal, Xiaohan Lin, Mantas Baksys, Junqi Liu, Marco Dos Santos, Flood Sung, Marina Vinyes, Zhenzhe Ying, Zekai Zhu, Jianqiao Lu, Hugues de Saxcé, Bolton Bailey, Chendong Song, Chenjun Xiao, Dehao Zhang, Ebony Zhang, Frederick Pu, Han Zhu, Jiawei Liu, Jonas Bayer, Julien Michel, Longhui Yu, Léo Dreyfus-Schmidt, Lewis Tunstall, Luigi Pagani, Moreira Machado, Pauline Bourigault, Ran Wang, Stanislas Polu, Thibaut Barroyer, Wen-Ding Li, Yazhe Niu, Yann Fleureau, Yangyang Hu, Zhouliang Yu, Zihan Wang, Zhilin Yang, Zhengying Liu, and Jia Li. Kimina-Prover Preview: Towards large formal reasoning models with reinforcement learning, 2025. [13] Xiaoyang Liu, Kangjie Bao, Jiashuo Zhang, Yunqi Liu, Yu Chen, Yuntian Liu, Yang Jiao, and Tao Luo. Atlas: Autoformalizing theorems through lifting, augmentation, and synthesis of data, 2025. 11 [14] Guoxiong Gao, Yutong Wang, Jiedong Jiang, Qi Gao, Zihan Qin, Tianyi Xu, and Bin Dong. Herald: natural language annotated lean 4 dataset. In The Thirteenth International Conference on Learning Representations, 2025. [15] OpenAI. Introducing openai o3 and o4-mini. https://openai.com/index/ introducing-o3-and-o4-mini/, April 2025. [16] Lean FRO. read-eval-print-loop for Lean 4. https://github.com/ leanprover-community/repl, 2023. [17] Huaiyuan Ying, Shuo Zhang, Linyang Li, Zhejian Zhou, Yunfan Shao, Zhaoye Fei, Yichuan Ma, Jiawei Hong, Kuikun Liu, Ziyi Wang, Yudong Wang, Zijian Wu, Shuaibin Li, Fengzhe Zhou, Hongwei Liu, Songyang Zhang, Wenwei Zhang, Hang Yan, Xipeng Qiu, Jiayu Wang, Kai Chen, and Dahua Lin. Internlm-math: Open math large language models toward verifiable reasoning, 2024. [18] DeepSeek-AI. Deepseek-v2: strong, economical, and efficient mixture-of-experts language model, 2024. [19] Jiayi Ye, Yanbo Wang, Yue Huang, Dongping Chen, Qihui Zhang, Nuno Moniz, Tian Gao, Werner Geyer, Chao Huang, Pin-Yu Chen, Nitesh Chawla, and Xiangliang Zhang. Justice or prejudice? quantifying biases in LLM-as-a-judge. In The Thirteenth International Conference on Learning Representations, 2025. [20] DeepSeek-AI. Deepseek-v3 technical report, 2024. [21] Huajian Xin, ZZ Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, et al. Deepseek-prover-v1.5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search. arXiv preprint arXiv:2408.08152, 2024. [22] Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, et al. Goedel-Prover: frontier model for open-source automated theorem proving. arXiv preprint arXiv:2502.07640, 2025. [23] Z. Z. Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, Z. F. Wu, Zhibin Gou, Shirong Ma, Hongxuan Tang, Yuxuan Liu, Wenjun Gao, Daya Guo, and Chong Ruan. Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition, 2025. [24] Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, et al. Scientific discovery in the age of artificial intelligence. Nature, 620(7972):4760, 2023. [25] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan Ellenberg, Pengming Wang, Omar Fawzi, et al. Mathematical discoveries from program search with large language models. Nature, pages 13, 2023. [26] Trieu Trinh, Yuhuai Wu, Quoc Le, He He, and Thang Luong. Solving Olympiad geometry without human demonstrations. Nature, 625(7995):476482, 2024. [27] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with Alphacode. Science, 378(6624):10921097, 2022. [28] Can Cui, Wei Wang, Meihui Zhang, Gang Chen, Zhaojing Luo, and Beng Chin Ooi. Alphaevolve: learning framework to discover novel alphas in quantitative investment. In Proceedings of the 2021 International conference on management of data, pages 22082216, 2021. [29] David Silver and Richard Sutton. Welcome to the era of experience. Google AI, 2025. 12 [30] Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, and Chong Ruan. Deepseek-prover-v1.5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search, 2024. [31] Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, and Chi Jin. Goedel-Prover: frontier model for open-source automated theorem proving, 2025. [32] Jingyuan Zhang, Qi Wang, Xingguang Ji, Yahui Liu, Yang Yue, Fuzheng Zhang, Di Zhang, Guorui Zhou, and Kun Gai. Leanabell-Prover: Posttraining scaling in formal reasoning, 2025. [33] Kefan Dong and Tengyu Ma. STP: Self-play LLM theorem provers with iterative conjecturing and proving. arXiv preprint arXiv:2502.00212, 2025. [34] Zijian Wu, Suozhi Huang, Zhejian Zhou, Huaiyuan Ying, Jiayu Wang, Dahua Lin, and Kai Chen. Internlm2.5-stepprover: Advancing automated theorem proving via expert iteration on large-scale lean problems, 2024. [35] Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, and Ilya Sutskever. Formal mathematics statement curriculum learning, 2022. [36] Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, and Kai Shen. BFS-Prover: Scalable best-first tree search for llm-based automatic theorem proving, 2025. [37] Guillaume Lample, Marie-Anne Lachaux, Thibaut Lavril, Xavier Martinet, Amaury Hayat, Gabriel Ebner, Aurélien Rodriguez, and Timothée Lacroix. Hypertree proof search for neural theorem proving. In Proceedings of the 36th International Conference on Neural Information Processing Systems, pages 2633726349, 2022. [38] Haiming Wang et al. DT-Solver: Automated theorem proving with dynamic-tree sampling In Proceedings of the 61st Annual Meeting of the guided by proof-level value function. Association for Computational Linguistics (Volume 1: Long Papers), pages 1263212646, 2023. [39] Yang Li, Dong Du, Linfeng Song, Chen Li, Weikang Wang, Tao Yang, and Haitao Mi. HunyuanProver: scalable data synthesis framework and guided tree search for automated theorem proving, 2025. [40] Roozbeh Yousefzadeh, Xuenan Cao, and Azim Ospanov. Lean dataset for International Math Olympiad: Small steps towards writing math proofs for hard problems. Transactions on Machine Learning Research, 2025. [41] Qingxiang Wang, Cezary Kaliszyk, and Josef Urban. First experiments with neural translation of informal to formal mathematics. In Intelligent Computer Mathematics: 11th International Conference, pages 255270. Springer, 2018. [42] Christian Szegedy. promising path towards autoformalization and general artificial intelligence. In Intelligent Computer Mathematics: 13th International Conference, CICM 2020, Bertinoro, Italy, July 2631, 2020, Proceedings 13, pages 320. Springer, 2020. [43] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. Advances in Neural Information Processing Systems, 36:2155821572, 2023. [44] Qi Liu, Xinhao Zheng, Xudong Lu, Qinxiang Cao, and Junchi Yan. Rethinking and improving autoformalization: towards faithful metric and dependency retrieval-based approach. In The Thirteenth International Conference on Learning Representations, 2025. [45] Zenan Li, Yifan Wu, Zhaoyu Li, Xinming Wei, Xian Zhang, Fan Yang, and Xiaoxing Ma. Autoformalize mathematical statements by symbolic equivalence and semantic consistency. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. 13 [46] Logan Murphy, Kaiyu Yang, Jialiang Sun, Zhaoyu Li, Anima Anandkumar, and Xujie Si. In Forty-first International Conference on Machine Autoformalizing euclidean geometry. Learning, 2024. [47] Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward Ayers, Dragomir Radev, and Jeremy Avigad. ProofNet: Autoformalizing and formally proving undergraduate-level mathematics. arXiv preprint arXiv:2302.12433, 2023. [48] George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Amitayush Thakur, and Swarat Chaudhuri. Putnam Bench: Evaluating neural theorem-provers on the Putnam mathematical competition. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024. [49] Jia Li, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi, Shengyi Costa Jiang, Ziju Shen, Zihan Qin, Bin Numinahttps://github.com/project-numina/aimo-progress-prize/blob/main/ Huang, Kashif Rasul, Longhui Yu, Albert Dong, Li Zhou, Yann Fleureau, Guillaume Lample, and Stanislas Polu. math. report/numina_dataset.pdf, 2024. GitHub repository. [50] Jiewen Hu, Thomas Zhu, and Sean Welleck. miniCTX: Neural theorem proving with (long-) contexts. In The Thirteenth International Conference on Learning Representations, 2025. [51] Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. miniF2F: cross-system benchmark for formal Olympiad-level mathematics, 2022. [52] Joshua Vendrow, Edward Vendrow, Sara Beery, and Aleksander Madry. Large language model benchmarks do not test reliability. In NeurIPS Safe Generative AI Workshop 2024, 2024. [53] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford. Datasheets for datasets. Communications of the ACM, 64(12):8692, 2021. [54] Keiran Paster, Marco Dos Santos, Zhangir Azerbayev, and Jimmy Ba. OpenWebMath: An open dataset of high-quality mathematical web text. In The Twelfth International Conference on Learning Representations, 2023."
        },
        {
            "title": "A Datasheet",
            "content": "Following the framework of [53] and [54], Table 8 provides the additional information about our dataset. Table 8: Datasheet for our dataset Questions Answers Motivation For what purpose was the dataset created? To correct uncovered errors and inconsistencies within miniF2F dataset [8] and to further facilitate challenging benchmark for LLM-based theorem provers and autoformalization models. The authors of this paper. Who created the dataset and on behalf of which entity? Who funded the creation of the dataset? Any other comment? The company where the authors work. None. Composition What do the instances that comprise the dataset represent? How many instances are there in total? Does the dataset contain all possible instances or is it sample of instances from larger set? What data does each instance consist of? Is there label or target associated with each instance? Is any information missing from individual instances? Are relationships between individual instances made explicit? Are there recommended data splits? Are there any errors, sources of noise, or redundancies in the dataset? Is the dataset self-contained, or does it link to or otherwise rely on external resources? Does the dataset contain data that might be considered confidential? Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? miniF2F theorems, each consisting of 4 components: informal statement and informal proofs in English, formal statements and formal proofs in Lean 4. 488 theorems Yes, we present all instances of the miniF2F dataset. formal theorem in Lean with its formal proof and its informal description and informal proof. Only informal prefix. No. Not applicable. The dataset follows the same split as the original version, i.e. 244 test instances and 244 validation instances. No, there are no errors in the proposed dataset to the best of our knowledge. Every formal statement and formal proof compiles with no error in Lean4. All the informal statements and proofs are checked by human. The dataset is self-contained corrected version of miniF2F. No. No. Collection Process Continued on next page 15 How was the data associated with each instance acquired? What mechanisms or procedures were used to collect the data? If the dataset is sample from larger set, what was the sampling strategy? Who was involved in the data collection process and how were they compensated? Over what time frame was the data collected? Were any ethical review processes conducted? No. All 488 instances originate from the miniF2F dataset and further augmented to correct mistakes and inconsistencies. Every theorem has corresponding entry in the source dataset. The theorems were taken from miniF2F. Original problem statements were taken from official web pages of mathematical competitions such as IMO, AMC, AIME. No, there is one to one match between this dataset and the original miniF2F dataset. The dataset was taken from open-source miniF2F dataset. Dataset was taken directly from miniF2F work. Preprocessing/cleaning/labeling Was any preprocessing/cleaning/labeling of the data done? Was the raw data saved in addition to the preprocessed/cleaned/labeled data? Is the software that was used to preprocess/- clean/label the data available? Any other comments? Yes, we performed post processing of the dataset manually to uncover incorrect, misleading, inconsistent or wrong statements. The raw data is open-source and available to the public. We used Lean compiler to type check the formal statements. No. Uses Has the dataset been used for any tasks already? We evaluated numerous theorem proving models such as Deepseek-Prover-V1.5-RL, GoedelProver-SFT, Kimina-Prover-Distill-7B to evaluate the dataset. Additionally, we performed autoformalization experiments with Herald translator, Kimina autoformalizer and OpenAI o4mini models. Public GitHub and HuggingFace links will be provided at later date. The dataset may be used for benchmarking theorem provers and autoformalization models. Other tasks may involve incorporating the dataset into informal-formal theorem proving environments. We do not anticipate future issues emerging from the proposed benchmark dataset. Is there repository that links to any or all papers or systems that use the dataset? What (other) tasks could the dataset be used for? Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? Are there tasks for which the dataset should not be used? Any other comments? The test set, and preferably validation set, should not be used to train the theorem provers and autoformalizers. No. Distribution Will the dataset be distributed to third parties outside of the entity on behalf of which the dataset was created? How will the dataset will be distributed? Yes, we will release the dataset on public platforms such as GitHub and HuggingFace at later date. GitHub, HuggingFace. Continued on next page 16 When will the dataset be distributed? Will the dataset be distributed under copyright or other intellectual property license, and/or under applicable terms of use? Have any third parties imposed IP-based or other restrictions on the data associated with the instances? Do any export controls or other regulatory restrictions apply to the dataset or to individual instances? Any other comments? The dataset will be distributed along with the camera-ready version of the submission. Yes, the dataset will be released under the MIT license. No. No. No. Maintenance Who will be supporting/hosting/maintaining the dataset? How can the owner/curator/manager of the dataset be contacted? Is there an erratum? Will the dataset be updated? If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances? Will older versions of the dataset continue to be supported/hosted/maintained? If others want to extend/augment/build on/contribute to the dataset, is there mechanism for them to do so? Any other comments? The last author of the submission. The manager of the dataset may be reached through an email or any other public means, such as GitHub profile. Formal statements do not require erratum, and corrected informal statements are an erratum of the original informal statements sourced from the miniF2F benchmark. Yes, we plan to periodically update the dataset as new versions of Lean become available. Not applicable. Yes. Yes, since we release coupled informal and formal statements, others may expand the dataset to other formal languages, such as Isabelle. Informal statements can also be translated to other languages such as Chinese. The problems may be formalized further to cover more formal theorem proving languages. No."
        },
        {
            "title": "B Effect of a clearly structured informal proof as opposed to a vague one",
            "content": "A failure case of Kimina prover is aime_1987_p5. However, when we provide more clear informal proof for this theorem, Kimina Prover succeeds in proving it. This indicates the positive effect of better informal proof on the existing theorem provers, and the higher quality of miniF2F-v2. aime_1987_p5 with informal proofs miniF2F-v1 miniF2F-v2(s/c) Find 3x2y2 if and are integers such that y2 + 3x2y2 = 30x2 + 517. Show that it is 588. Find 3x2y2 if and are integers such that y2 + 3x2y2 = 30x2 + 517. Show that 3x2y2 is 588. /-Formal Statement-/ theorem aime_1987_p5 (x : Z) (h0 : ^ 2 + 3 * (x ^ 2 * ^ 2) = 30 * ^ 2 + 517) : 3 * (x ^ 2 * ^ 2) = 588 := by sorry Informal proof: If we move the x2 term to the left side, it is [[SFFTfactorable]]: (3x2 + 1)(y2 10) = 517 10 507 is equal to 3 132. Since and are integers, 3x2 + 1 cannot equal multiple of three. 169 doesnt work either, so 3x2 + 1 = 13, and x2 = 4. This leaves y2 10 = 39, so y2 = 49. Thus, 3x2y2 = 3 4 49 = 588. Informal proof: From the equation y2 + 3x2y2 = 30x2 + 517 we first rewrite it as 3x2y2 = 30x2 + 517 y2. Since squares are nonnegative this forces y2 517, hence 22 22. There are only finitely many integer choices for in this range, so we check each one: for each fixed y, the rewritten equation becomes concrete quadratic in which can be checked by direct computation to yield 3x2y2 = 588. Thus in all cases the desired conclusion holds."
        },
        {
            "title": "C Wrong formalization because of unfamiliarity with the mathematical",
            "content": "definitions in Mathlib Another failure case of Kimina Prover is algebra_cubrtrp1oncubrtreq3_rcubp1onrcubeq5778 (algebra_5778 in short). The informal statement for this theorem relies upon simple definition of cube root common in precollege math. However, in Mathlib, the nth root, via the rpow function, is defined using more advanced definition that is compatible with broader network of definitions including the real roots of negative complex numbers and the continuity of roots of negative real numbers. The definition of nth root in Mathlib does not correspond to the common definition in precollege math, and therefore, the formalization of this problem in miniF2F is wrong and unprovable. In other words, the rpow function in Mathlib is not equivalent to the definition of cube root as stated in the informal statement for this theorem and the use of rpow in this formalization makes this theorem unprovable in Lean. In fact, we write formal proof giving counterexample for the case when the variable is negative, proving that this theorem is unprovable in Lean as it appears in miniF2F-v1, i.e., formal proof for unprovability of this theorem. As alternative, in the below diagram, we show three correct formalizations of this problem. The first version still relies on the definition of nth root in Lean, but makes the variable nonnegative avoiding any conflict with lemma: Real.rpow_def _of _neg in Mathlib. The second version defines new nth root function corresponding to precollege math. The third formalization excludes the only possible negative root of equation h0. After correcting the formal statement, Kimina Prover successfully proves this theorem. The proofs of the correct formalization and the proof of counterexample for the incorrect statement in miniF2F wil be released with the paper. Informal Statement: Let be real number such that 1 3 + 1 1 3 = 3. Show that r3 + 1 r3 = 5778. Incorrect Formalization [miniF2F-v1] theorem algebra5778 (r : R) (h0 : r(1/3:R) + 1/r(1/3:R) = 3 : r3 + 1/r3 = 5778 := by Correct Formalization #2 [miniF2Fv2(s/c)] theorem algebra5778 (r : R) (qpow : R) (hq : qpow = un (cid:55) if 0 then x.rpow( a) else (x).rpow( a)) (h0 : qpow (1/3) + 1/qpow (1/3) = 3) : r3 + 1/r3 = 5778 := by Correct Formalization #1 theorem algebra5778 (r : R) (h0 : r(1/3:R) + 1/r(1/3:R) = 3) (h1 : 0 r) : r3 + 1/r3 = 5778 := by Correct Formalization #3 theorem algebra5778 (r : R) (h0 : r(1/3:R) + 1/r(1/3:R) = 3) (h1 : r(1/3:R) = (1/2)(r)(1/3:R)) : r3 + 1/r3 = 5778 := by Examples of autoformalizer outputs on miniF2F v1 and v2 In this section, we present three examples of modified problems and analyze their impact on autoformalization models. We show that supplying corrected miniF2F informal statements can significantly affect model performance, and that the specific nature of each formalization error drives different model behaviors. D.1 mathd_algebra_31 The original informal statement of mathd_algebra_31 omits several critical details and is defined ambiguously. In particular, it denotes limit by . . ., leaving the definition ambiguous. When tasked with this problem, both Herald and Kimina attempt to encode the underlying recursive function explicitly, and fail. To fix these issues, we provide clearly specified version of the problem with an explicit recursive definition. After this revision, Kimina successfully produces correct autoformalization although Herald still fails. These results demonstrate that clearly written (i.e., higher quality) informal statements improves the reliability of autoformalization benchmarks, and it can improve the accuracy of existing models, too. D.2 imo_1960_p2 The original informal statement does not specify the solution to the question, i.e., the proof goal. In other words, the question asks the the examinees to first find the solution and then prove its correctness. With such an informal statement, autoformalization models should also leave the goal undefined using an additional sorry within the formal statement. This is what we do in our miniF2F-v2c. In miniF2F-v2s, however, we amend the informal statement with the answer so that it matches the formal statement. Clearly, the formal and informal statements in miniF2F-v2c are more difficult both for translation and for proving. At the same time, with our modification of informal statement in miniF2F-v2s for this problem, both Herald and Kimina successfully produce correct formalizations. Although better informal-formal match increases the complexity for automated provers, our results demonstrate that faithful, detailed translations improve some autoformalization attempts. Interestingly, since o4-mini is an advanced reasoning model, it automatically finds the solution for the statement in miniF2F-v2c and incorporates the answer as the goal in its formal translation. This additional step that o4-mini takes, however, simplifies the problem along the way of translation and makes its formal proof much easier. This may or may not be desirable in various contexts. As explained earlier in the paper, simplifying problem during translation does not receive credit in our evaluation setting. D.3 amc12b_2003_p In this example, the informal statement is correct. However, the formal statement is not correct translation of it. The formal statement asks for an extra solution, and drops the intricate detail of \"a possible solution\" in the informal statement. This can be considered mismatch between the informal and formal statements. Despite the fact that each of them is correct and provable, the formal and informal statements in the original miniF2F do not translate to each other. One possible approach is to keep the correct informal statement and change the formal statement to correspond to it which we do in miniF2F-v2c. In miniF2F-v2s, however, we chose to change the formal statement so that it corresponds to the formal one. After this update, both Herald and o4-mini correctly autoformalize the problem in miniF2F-v2s. For miniF2F-v2c, we changed the formal statement to reflect the multiple-choice nature of the question. All options are equivalent except for the numerical solutions they correspond to. To preserve space, we replaced repeating blocks with \"...\". Only o4-mini was able to correctly autoformalize given statement. 20 Correction of mathd_algebra_31 with autoformalization outputs miniF2F-v1 miniF2F-v2(s/c) (cid:114) (cid:113) + If Show that it is 72. + (cid:112) + + = 9, find x. /-Formal statement-/ theorem mathd_algebra_31_minif2f_v1 (x : NNReal) (u : NNReal) (h0 : n, (n + 1) = NNReal.sqrt (x + n)) (h1 : Filter.Tendsto Filter.atTop (nhds 9)) : 9 = NNReal.sqrt (x + 9) := by sorry Consider nonnegative real number x, and recursive function from natural numbers to real numbers. For all natural numbers, we have u(n + 1) = (cid:112)x + u(n). Assume that the as reaches infinity in its limit, u(n) goes to 9. What is the value of x? Show that it is 72. /-Formal statement-/ theorem mathd_algebra_31_minif2f_v2 (x : R) (hx : 0 x) (u : R) (h0 : n, (n + 1) = Real.sqrt (x + n)) (h1 : Filter.Tendsto Filter.atTop (nhds 9)) : = 72 := by sorry /-Kimina Formalized - miniF2F-v1-/ theorem mathd_algebra_31_kimina {x : R} (hx : 0 x) (h : sqrt(x + sqrt(x + sqrt(x + sqrt(x + sqrt(x + 0))))) = 9) : = 72 := by sorry /-Kimina Formalized - miniF2F-v2s-/ theorem mathd_algebra_31_kimina (x : R) (hx : 0 x) (u : R) (hu : n, (n + 1) = sqrt (x + n)) (h : Tendsto atTop (nhds 9)) : = 72 := by sorry /-Herald Formalized - miniF2F-v1-/ theorem mathd_algebra_31_herald : sqrt(x + sqrt(x + sqrt(x + sqrt(x + 9)))) = 9 = 72 := by sorry /-Herald Formalized - miniF2F-v2s-/ theorem mathd_algebra_31_herald (x : R) (h : 0 < x) (hx : Σ : N, (Real.sqrt (x + (Real.sqrt (x + (Real.sqrt (x + (Real.sqrt (x + 0)))))))) = 9) : = 72 := by sorry /-o4-mini Formalized - miniF2F-v1-/ theorem mathd_algebra_31_o4mini (x : R) (h1 : = Real.sqrt (x + y)) (h2 : = 9) : = 72 := by /-o4-mini Formalized - miniF2F-v2s-/ theorem mathd_algebra_31_o4mini {x : R} (h : 9 = Real.sqrt (x + 9)) : = 72 := by sorry sorry 21 Correction of imo_1960_p2 with autoformalization outputs miniF2F-v1 miniF2F-v2s For what values of the variable does the following inequality hold: 4x2 2x + 1)2 (1 < 2x + 9 ? Let be real number. Assume that: - 1 + 2x 0 (so that the square root is de1 + 2x)2 = 0 (so the defined), - (1 4x2 1+2x)2 < nominator is nonzero), and - 2x + 9. Prove that: (1 1 2 and < 45 8 . /-Formal Statement-/ theorem imo_1960_p2 (x : R) (h0 : 0 1 + 2 * x) (h1 : (1 - Real.sqrt (1 + 2 * x)) ^ 2 = 0) (h2 : 4 * ^ 2 / (1 - Real.sqrt (1 + 2 * x)) ^ 2 < 2 * + 9) : -(1 / 2) < 45 / 8 := by sorry /-Kimina Formalized - miniF2F-v1-/ theorem imo_1960_p2_kimina (x : R) (hx : 0 2 * + 1 1 - sqrt (2 * + 1) = 0) : (4 * ^ 2 / (1 - sqrt (2 * + 1)) ^ 2 < 2 * + 9 < 1 / 2 > 7 / 2) := by sorry /-Kimina Formalized - miniF2F-v2s-/ theorem imo_1960_p2_kimina (x : R) (h0 : 1 + 2 * 0) (h1 : (1 - Real.sqrt (1 + 2 * x))^2 = 0) (h2 : 4 * x^2 / (1 - Real.sqrt (1 + 2 * x))^2 < 2 * + 9) : -1 / 2 < 45 / 8 := by sorry /-Herald Formalized - miniF2F-v1-/ theorem imo_1960_p2_herald (x : R) : (4 * ^ 2 / (1 - Real.sqrt (2 * + 1)) ^ 2 < 2 * + 9) < 11 / 2 sorry by := /-Herald Formalized - miniF2F-v2s-/ theorem imo_1960_p2_herald (x : R) (h1 : 1 + 2 * 0) (h2 : (1 - Real.sqrt (1 + 2 * x)) ^ 2 = 0) (h3 : 4 * ^ 2 / (1 - Real.sqrt (1 + 2 * x)) ^ 2 < 2 * + 9) : -1 / 2 < 45 / 8 := by sorry /-o4-mini Formalized - miniF2F-v1-/ theorem imo_1960_p2_o4mini (x : R) (h_nonneg : 2 * + 1 0) (h_ne_zero : 1 - Real.sqrt (2 * + 1) = 0) : /-o4-mini Formalized - miniF2F-v2s-/ theorem imo_1960_p2 (x : R) (h1 : 1 + 2 * 0) (h2 : (1 - Real.sqrt (1 + 2 * x)) ^ 2 = 0) 4 * ^ 2 / (1 - Real.sqrt (2 * + (h3 : 4 * ^ 2 / (1 - Real.sqrt 1)) ^ 2 < 2 * + 9 -1 / 2 < 45 / 8 = 0 := by sorry (1 + 2 * x)) ^ 2 < 2 * + 9) : -1 / 2 < 45 / 8 := by sorry [Informal and Formal Mismatch] Comparison of amc12b_2003_p6 across miniF2F-v1 and miniF2Fv2 miniF2F-v1 miniF2F-v2s miniF2F-v2c The second and fourth terms of geometric sequence are 2 and 6. Which of the following is possible first term? The second and fourth terms of geometric sequence are 2 and 6. Show that the first term is either - 3 or 2 3 3 . 3 (A) (C) 3 3 3 3 3 3 (E) 3 (B) (D) Show that it is (B) - 3 3 . The second and fourth terms of geometric sequence are 2 and 6. Which of the following is possible first term? Prove that it is one of the following options. (A) (C) 3 3 3 2 3 3 3 (E) (B) (D) /Formal Statement/ theorem amc12b_2003_p6_v1 (a : R) (u : R) /Formal Statement/ theorem amc12b_2003_p6_v2s (a : R) (u : R) (h0 : k, = * ^ k) (h1 : 1 = 2) (h2 : 3 = 6) : 0 = 2 / Real.sqrt 3 0 = (h0 : k, = * ^ k) (h1 : 1 = 2) (h2 : 3 = 6) : 0 = 2 / Real.sqrt 3 0 = (2 / Real.sqrt 3) := by (2 / Real.sqrt 3) := by sorry sorry /Formal Statement/ theorem amc12b_2003_p6_v2c : ( (u : R) (a : R) (r : R), k, = * ^ 1 = 2 3 = 6 0 = Real.sqrt 3) ( . . . = 2 * Real.sqrt 3 / 3) ( . . . = Real.sqrt 3 / 3) ( . . . = Real.sqrt 3) := by sorry /Kimina Formalized miniF2Fv1/ theorem amc12b_2003_p6_kimina (a : R) (h : r, n, = 0 * ^ n) (ha : 1 = 2) (hb : 3 = 6) : /Kimina Formalized miniF2Fv2s/ theorem amc12b_2003_p6_kimina (a : R) (h0 : = 0) (h1 : * = 2) (h2 : * r^3 = 6) : 0 = 2 * sqrt 3 / 3 := by sorry = 2 * Real.sqrt 3 / 3 = 2 * Real.sqrt 3 / 3 := by sorry /Kimina Formalized miniF2Fv2c/ theorem amc12b_2003_p6_kimina (a q: R) (hq : = 0) (ha : = 0) (h1 : a*q = 2) (h2 : a*q^3 = 6): = sqrt 3 = 2*sqrt 3 / 3 = sqrt 3 / 3 = sqrt 3 = 3 := by sorry /Herald Formalized miniF2Fv1/ theorem amc12b_2003_p6_herald (a : R) (h0 : * = 2) (h1 : * r^3 = 6) : = 3 = 2 * Real.sqrt 3 / 3 := by sorry /Herald Formalized miniF2Fv2s/ theorem amc12b_2003_p6_herald (a : R) (h : 2 = 2 4 = 6) : 1 = 2 * Real.sqrt 3 / 3 1 = 2 * Real.sqrt 3 / 3 := by sorry /Herald Formalized miniF2Fv2c/ theorem amc12b_2003_p6 (a : R) (h0 : * = 2) (h1 : * r^3 = 6) : = Real.sqrt 3 = 2 * Real.sqrt 3 / 3 = Real.sqrt 3 / 3 = Real.sqrt 3 = 3 := by sorry /o4mini Formalized miniF2Fv1/ theorem amc12b_2003_p6_o4mini : (a : R), = 0 * = 2 * ^ 3 = 6 = 2 * sqrt 3 / 3 := by sorry /o4mini Formalized miniF2Fv2s/ theorem amc12b_2003_p6_o4mini (a : R) (h1 : * = 2) (h2 : * r^3 = 6) : = 2 * Real.sqrt 3 / 3 = 2 * Real.sqrt 3 / 3 := by sorry /o4mini Formalized miniF2Fv2c/ theorem amc12b_2003_p6_o4mini : (a : R), * = 2 * r^3 = 6 (a = Real.sqrt 3 = 2 * Real.sqrt 3 / 3 = Real.sqrt 3 / 3 = Real.sqrt 3 = 3) := by sorry"
        },
        {
            "title": "E Examples of modified statements",
            "content": "E.1 induction_pord1p1on2powklt5on2 The original problem was unprovable due to missing pair of parentheses, which led to an incorrect formalization. We corrected this error in miniF2F-v2 by inserting the appropriate parentheses. E.2 aime_1990_p4 In the original formal statement, three additional hypotheses (h1, h2, h3) explicitly assert that certain expressions are nonzero, which simplifies proof generation for theorem provers. These are extra assumptions that are not present in the informal statement that was given to the participants of AIME 1990, and they are not necessary to prove the theorem. To remove this discrepancy between the formal and informal statements, we remove the added hypothesis from the formal statement. This makes the theorem more challenging for theorem provers as they have to prove each of those hypothesis as intermediate steps to prove the theorem. [Unprovable] Comparison of induction_pord1p1on2powklt5on2 across miniF2F-v1 and miniF2Fv2 Show that for positive integer n, ((cid:81)n k=1(1 + 1/2k)) < 5/2. miniF2F-v1 miniF2F-v2(s/c) /-Formal Statement - miniF2F-v1-/ theorem /-Formal Statement - miniF2F-v2-/ theorem induction_pord1p1on2powklt5on (n : N) (h0 : 0 < n) : ((cid:81) in Finset.Icc 1 n, 1 + (1 : ) / 2 ^ k) < 5 / 2 := by sorry induction_pord1p1on2powklt5on2 (n : N) (h0 : 0 < n) : ((cid:81) Finset.Icc (1:N) n, ((1 : R) + (1 : R) / 2 ^ k)) < (5 / 2 : R) := by sorry [Simplified] Comparison of aime_1990_p4 across miniF2F-v1 and miniF2Fv2 Find the positive solution to 1 x210x29 + 1 x210x45 2 x210x69 = 0. Show that it is 13. miniF2F-v1 miniF2F-v2(s/c) /-Formal Statement - miniF2F-v1-/ theorem aime_1990_p4 (x : R) (h0 : 0 < x) (h1 : ^ 2 - 10 * - 29 = 0) (h2 : ^ 2 - 10 * - 45 = 0) (h3 : ^ 2 - 10 * - 69 = 0) (h4 : 1 / (x ^ 2 - 10 * - 29) + 1 / (x ^ 2 - 10 * - 45) - 2 / (x ^ 2 - 10 * - 69) = 0) : = 13 := by sorry /-Formal Statement - miniF2F-v2-/ theorem aime_1990_p (x : R) (h0 : 0 < x) (h4 : 1 / (x ^ 2 - 10 * - 29) + 1 / (x ^ 2 - 10 * - 45) - 2 / (x ^ 2 - 10 * - 69) = 0) : = 13 := by sorry E.3 amc12b_2021_p9 In this example, we retained each logarithm in its base form, writing logc directly rather than converting it to log log , so that the formal statement exactly corresponds to the informal one as it 24 appeared in the AMC. These changes yield slightly more challenging version of the problem. And we observe that all three theorem proving models, Deepseek-Prover-V1.5-RL, Goedel-Prover-SFT and Kimina-Prover-Preview-Distill-7B, fail on the modified version of this theorem. E.4 mathd_algebra_487 In the original miniF2F version, the problem was oversimplified: it introduced four variables (instead of two) and omitted the Euclidean-space context, therefore providing extra hints that eases proof generation task for LLMs. In miniF2F-v2, we restore the two-variable formulation over R2, remove these implicit assumptions. This leads to spike in the problems difficulty. These more faithful and challenging instances yield more rigorous benchmark for evaluating theorem provers. 25 [Simplified] Comparison of amc12b_2021_p9 across miniF2F-v1 and miniF2Fv2 miniF2F-v1 miniF2F-v2s miniF2F-v2c What is the value of log2 80 log2 160 log20 2 ? log40 2 What is the value of log2 80 log2 160 log20 2 ? Show that it is 2. log40 2 (A) (D)2 5 4 (B)1 (C) (E) log2 5 Show that it is (D). /-Formal Statement - miniF2F-v1-/ /-Formal Statement - miniF2F-v2s-/ theorem amc12b_2021_p9 : theorem amc12b_2021_p9 : Real.log 80 / Real.log 2 / (Real.log 2 / Real.log 40) - Real.log 160 / Real.log 2 / (Real.log 2 / Real.log 20) = 2 := by sorry Real.logb 2 80 / (Real.logb 40 2) - Real.logb 2 160 / Real.logb 20 2) = 2 := by sorry log40 2 What is the value of log2 80 log2 160 log20 2 ? Prove that it is one of the following options. (A)0 (D)2 5 (B)1 (C) (E) log2 5 /-Formal Statement - miniF2F-v2c-/ theorem amc12b_2021_p9 (X : R) (hX : = Real.logb 2 80 / (Real.logb 40 2) - Real.logb 2 160 / Real.logb 20 2) : = 2 = 4 = 6 = 30 = 32 := by sorry [Excessively Simplified] Comparison of mathd_algebra_487 across miniF2F-v1 and miniF2Fv2 What is the distance between the two intersections of = x2 and + = 1? Show that it is 10. miniF2F-v1 miniF2F-v2(s/c) /-Formal Statement - miniF2F-v1-/ theorem mathd_algebra_487 (a : R) (h0 : = ^ 2) (h1 : + = 1) (h2 : = ^ 2) (h3 : + = 1) (h4 : = c) : Real.sqrt ((a - c) ^ 2 + (b - d) ^ 2) = Real.sqrt 10 := by sorry /-Formal Statement - miniF2F-v2-/ theorem mathd_algebra_487 (F : Set (EuclideanSpace (Fin 2))) (hF : = { 1 = (x 0) ^ 2}) (hG : = { 0 + 1 = 1}) (hI : = (F G)) (A : EuclideanSpace (Fin 2)) (h0 : x, = = B): dist = Real.sqrt 10 := by sorry 26 Examples of challenging miniF2F-v2c problems F.1 imo_1983_p6 In this problem, we did not modify the informal statement; instead, we corrected the paired formal statement. The original task is to prove an inequality and determine when equality occurs. In v1, the formal statement reflects only the first part, omitting the statement and the proof of when the equality holds. We modified the given hypotheses to match the problem formulation, but one could argue that the original formulation is also correct. More importantly, we ask the model to perform two tasks: prove the inequality and determine the values of a, b, and to achieve equality. Now, when asked to perform both tasks, the current medium-sized state-of-the-art prover, Deepseek-Prover-V2-7B, fails and no longer produces correct proof. We believe that the introduced changes are more faithful to the intended difficulty and reflect the limitations of current ATP models. F.2 imo_1997_p5 Another type of change made exclusively in miniF2F-v2c is the correction of both informal and formal statements to match the intended difficulty. In v1, the imo_1997_p5 problem statement is simplified and reworded to match the formal statement. Moreover, instead of requiring the prover to find the solution and prove it, the formal statement provides clear goal. We changed both the informal and formal statements to reflect the original imo_1997_p5 formulation and tasked the models with coming up with the correct goal and writing valid proof. Our results suggest that when the goal is unknown, the models struggle to find valid proofs, since they essentially must solve two separate tasks to achieve the result. [Removed solution from formal statement] Comparison of imo_1983_p6 across miniF2F-v1 and miniF2F-v2c Let a, and be the lengths of the sides of triangle. Prove that: a2b(a b) + b2c(b c) + c2a(c a) 0. Determine when equality occurs. miniF2F-v1 miniF2F-v2c /-Formal Statement - miniF2F-v1-/ theorem imo_1983_p6 (a : R) (h0 : 0 < 0 < 0 /-Formal Statement - miniF2F-v2-/ abbrev imo_1983_p6_solution : Prop := sorry < c) (h1 : < + b) (h2 : < + c) (h3 : < + c) : 0 ^ 2 * * (a - b) + ^ 2 * * (b - c) + ^ 2 * * (c - a) := by theorem imo_1983_p6 (T : Affine.Triangle (EuclideanSpace (Fin 2))) : let := dist (T.points 1) (T.points sorry 2) let := dist (T.points 0) (T.points 2) let := dist (T.points 0) (T.points 1) 0 a^2 * * (a - b) + b^2 * * (b - c) + c^2 * * (c - a) (0 = a^2 * * (a - b) + b^2 * * (b - c) + c^2 * * (c - a) imo_1983_p6_solution c) := by sorry [Simplified informal and formal statements] Comparison of imo_1997_p5 across miniF2F-v1 and miniF2F-v2c miniF2F-v1 miniF2F-v2c Show that if and are positive integers such that xy2 = yx, then (x, y) is equal to (1, 1), (16, 2), or (27, 3). Find all pairs (a, b) of integers a, 1 that satisfy the equation xy2 = yx. /-Formal Statement - miniF2F-v1-/ theorem imo_1997_p5 (x : N) (h0 : 0 < 0 < y) (h1 : /-Formal Statement - miniF2F-v2-/ abbrev imo_1997_p5_solution : Set (NN) := sorry ^ ^ 2 = ^ x) : (x, y) = (1, 1) (x, y) = (16, 2) (x, y) = (27, 3) := by sorry theorem imo_1997_p5 (x : N) (h0 : 1 1 y) : ^ ^ 2 = ^ (x, y) imo_1997_p5_solution := by sorry F.3 amc12_2000_p12 In our efforts to make the problems closer to Math Olympiad settings, we removed the correct answers from MCQ-style questions and reformulated the goals to require first selecting the correct solution and then proving it. [Omitted correct answers from multiple choice problems] Comparison of amc12_2000_p12 across miniF2F-v1 and miniF2F-v2c miniF2F-v1 miniF2F-v2c Let A, M, and be nonnegative integers such that A+M +C = 12. What is the maximum value of AM C+AM +M C+AC? Let A, M, and be nonnegative integers such that A+M +C = 12. What is the maximum value of AM C+AM +M C+AC? Prove that it is one of the following options. (A) 62 (B) 72 (C) 92 (D) 102 (E) 112 Show that it is E. (A) 62 (B) 72 (C) 92 (D) 102 (E) 112 /-Formal Statement - miniF2F-v1-/ theorem amc12_2000_p12 (a : N) (h0 : + + = 12) : * * + * + * + * 112 := by sorry /-Formal Statement - miniF2F-v2-/ theorem amc12_2000_p12 (S: Set N) (hS: = {x : N, (x = * * + * + * + * c) + + = 12}) : IsGreatest 62 IsGreatest 72 IsGreatest 92 IsGreatest 102 IsGreatest 112 := by sorry"
        },
        {
            "title": "G Effect of introduced changes to ATP performance on Olympiad style",
            "content": "questions To investigate the scale of difficulty, we showcase how the theorem provers perform specifically on IMO, AMC and AIME problems. Figure 3 compared four theorem provers across three miniF2F versions. We note that the strongest provers, Deepseek-Prover-V2-7B and Goedel-V2-7B, show substantial decline in performance solving twice as less IMO problems and 15-50% accuracy decline on AMC. We note that many corrected problems in miniF2F-v2c come from IMO and AMC but not AIME, therefore the performance drop in AIME is small across all theorem provers. Figure 3: Distribution of solved Olympiad-level (IMO, AMC, AIME) competition problems present in miniF2F-v1/2s/2c across four theorem provers. Theorem prover names were shortened from their original names. Each bar plot also shows the total number of problems present in the dataset."
        },
        {
            "title": "H Statistics about our modifications",
            "content": "We present the distribution of uncovered errors and inconsistencies in Figure 4. We observe that the majority of the problems in both test and validation sets are simplified and do not reflect the intended difficulty of the problems. Moreover, approximately 40% of formal statements across both sets contained an error, making the evaluation of LLMs on this benchmark less reliable. Figure 4: Pie charts of identified formal and informal statement errors within miniF2F benchmark across test and validation sets."
        },
        {
            "title": "I Failure topics of tested autoformalization models",
            "content": "To gain deeper insight into the formalization errors of the tested autoformalizer models, we present our classifications in Tables 9, 10, and 11. The categorization of failure cases was performed manually by Lean experts, except for the Not validated by Lean4 REPL category, which corresponds to translations that failed compiler verification. Table 9: Frequency of HERALD autoformalization errors the miniF2F-test dataset. Failure case classification Frequency Wrong/missing/incomplete statements or translations Type wrong/mismatch Max/Min of sets/functions wrongly formalized Incomplete set of assumptions Not validated by Lean4 REPL Digits Finite sets Additional assumptions/hypothesis Common divisors Sequences Others 17.5% 16.25% 16.25% 12.5% 7.5% 7.5% 3.75% 3.75% 2.5% 2.5% 10.0% Table 10: Frequency of Kimina-autoformalizer autoformalization errors the miniF2F-test dataset. Failure case classification Frequency Wrong/missing/incomplete statements or translations Not validated by Lean4 REPL Max/Min of sets/functions wrongly formalized Additional assumptions/hypothesis 57.14% 28.57% 7.14% 7.14% Table 11: Frequency of o4-mini autoformalization errors the miniF2F-test dataset. Failure case classification Frequency Not validated by Lean4 REPL Wrong/missing/incomplete statements or translations Max/Min of sets/functions wrongly formalized Incomplete set of assumptions Euclidean spaces Modulus Digits 80.43% 6.52% 6.52% 2.17% 2.17% 1.09% 1.09%"
        },
        {
            "title": "J Toward improving autoformalization models",
            "content": "Improving the performance of autoformalization models requires progress beyond benchmark evaluation. crucial first step is to adopt rigorous and transparent evaluation practices using high-quality, discrepancy-free benchmarks. This paper takes that step by providing more reliable basis for assessing model accuracy and consistency. The next important direction is to develop high-quality training data that accurately aligns formal and informal mathematical statements. Existing datasets often contain discrepancies or are partially closed-source, which can introduce noise during training. Because the miniF2F validation set is frequently reused for training, more consistent benchmark can have direct positive effect on model development. Any training example that misaligns formal and informal statements may negatively influence model accuracy and generalization. Beyond data quality, several factors are likely to affect model performance, including the distribution of the training corpus (e.g., mathematical topics and sample diversity), model architecture, reasoning mechanisms, context length, and the use of automated feedback during training. These aspects have been shown to play critical roles in the performance of large language models and general machine learning systems. Incorporating these insights into future autoformalization research can help identify effective design choices. Finally, the field would benefit from systematic ablation studies that isolate the contribution of individual components such as data quality, architecture, and reasoning modules. Reliable benchmarks are essential for such analyses, as dataset discrepancies can obscure interpretation. We hope that the availability of correct and comprehensive benchmarks will enable more informative and reproducible studies in this emerging research area."
        },
        {
            "title": "K Responsibility statement and License information",
            "content": "We plan to release our dataset under the MIT license on GitHub and Hugging Face. The authors of this submission bear the responsibility in case of rights violation."
        }
    ],
    "affiliations": [
        "Chinese University of Hong Kong",
        "Independent"
    ]
}