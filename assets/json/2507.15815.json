{
    "paper_title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra",
    "authors": [
        "Seth Karten",
        "Wenzhe Li",
        "Zihan Ding",
        "Samuel Kleiner",
        "Yu Bai",
        "Chi Jin"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We present the LLM Economist, a novel framework that uses agent-based modeling to design and assess economic policies in strategic environments with hierarchical decision-making. At the lower level, bounded rational worker agents -- instantiated as persona-conditioned prompts sampled from U.S. Census-calibrated income and demographic statistics -- choose labor supply to maximize text-based utility functions learned in-context. At the upper level, a planner agent employs in-context reinforcement learning to propose piecewise-linear marginal tax schedules anchored to the current U.S. federal brackets. This construction endows economic simulacra with three capabilities requisite for credible fiscal experimentation: (i) optimization of heterogeneous utilities, (ii) principled generation of large, demographically realistic agent populations, and (iii) mechanism design -- the ultimate nudging problem -- expressed entirely in natural language. Experiments with populations of up to one hundred interacting agents show that the planner converges near Stackelberg equilibria that improve aggregate social welfare relative to Saez solutions, while a periodic, persona-level voting procedure furthers these gains under decentralized governance. These results demonstrate that large language model-based agents can jointly model, simulate, and govern complex economic systems, providing a tractable test bed for policy evaluation at the societal scale to help build better civilizations."
        },
        {
            "title": "Start",
            "content": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra Seth Karten1 Wenzhe Li1 Zihan Ding1 1Princeton University Samuel Kleiner1 2Work done at Salesforce Research Yu Bai Chi Jin1 5 2 0 2 1 2 ]"
        },
        {
            "title": "A\nM",
            "content": ". [ 1 5 1 8 5 1 . 7 0 5 2 : r Abstract. We present the LLM Economist, novel framework that uses agent-based modeling to design and assess economic policies in strategic environments with hierarchical decision-making. At the lower level, bounded rational worker agentsinstantiated as persona-conditioned prompts sampled from U.S. Census-calibrated income and demographic statisticschoose labor supply to maximize text-based utility functions learned in-context. At the upper level, planner agent employs in-context reinforcement learning to propose piecewise-linear marginal tax schedules anchored to the current U.S. federal brackets. This construction endows economic simulacra with three capabilities requisite for credible fiscal experimentation: (i) optimization of heterogeneous utilities, (ii) principled generation of large, demographically realistic agent populations, and (iii) mechanism designthe ultimate nudging problemexpressed entirely in natural language. Experiments with populations of up to one hundred interacting agents show that the planner converges near Stackelberg equilibria that improve aggregate social welfare relative to Saez solutions, while periodic, persona-level voting procedure furthers these gains under decentralized governance. These results demonstrate that large language model-based agents can jointly model, simulate, and govern complex economic systems, providing tractable test bed for policy evaluation at the societal scale to help build better civilizations. Date: July 22, 2025 Correspondence: sethkarten@princeton.edu Code: github.com/sethkarten/LLM-Economist"
        },
        {
            "title": "1\nThe rapidly expanding marketplace of autonomous language agents has arrived: web-agents\nbooking plane tickets, drafting legal briefs, browsing Reddit, and trading cryptocurrencies, all\nwhile adapting to the incentives implicit to the digital economy. When hundreds of these agents\ninteract, they form an economic simulacrum, which is a synthetic society whose allocation of\neffort, consumption, and influence is governed by code rather than by legislation. Understanding\nand steering these artificial policies is therefore as urgent as studying human ones, lest early\nagents exploit a first-mover advantage. Recent work has shown that large language models\n(LLMs) can already use strategic reasoning and social preferences [58, 74], suggesting that they\nare an apt substrate for policy experimentation rather than merely passive tools of simulation.\nOptimal tax policy provides a canonical setting for mechanism design under rational-agent\nassumptions, with well-established solutions and theoretically verifiable predictions. Two limita-\ntions prevent inherited optimal-taxation frameworks from translating cleanly to this synthetic",
            "content": "1 LLM Economist social setting. First, classical solutions such as the Saez formula [60, 61] assume fixed elasticity of taxable income with independence across brackets. Rather, elasticity itself shifts once the marginal rates change, so the \"optimal\" rate is moving target that must be recomputed with policy perturbations. Second, human societies are heterogeneous and boundedly rational [44, 50], while simulacra are populated with agents whose motivations are specified at the token level. planner must therefore reason over distribution of personas, such as entrepreneurs averse to redistribution or public servants content with moderate rates, rather than representative agent that does not model the individual. We address both gaps by reframing optimal taxation as Stackelberg game, optimized by two-level in-context reinforcement learning (ICRL), which simply uses scalar reward rather than supervised answers to learn in-context [35, 53, 54]. At the lower level, each worker agent receives natural-language prompt encoding its synthetic biography, observes its pre-tax income, and adjusts its labor to maximize persona-conditioned utility that combines isoelastic consumption value with an LLM-judged satisfaction Lagrangian constraint. At the upper level, single planner agent observes aggregate histories and proposes piecewise-linear tax schedule anchored to the current U.S. federal brackets, thereby grounding the simulation in empirically relevant policy space. The Planner updates only after \"tax year\" of worker adaptation, inducing Stackelberg game whose equilibrium we solve via alternating ICRL. Because updates occur in the token space, the mechanism can use utilities to implicitly re-estimate elasticities adaptively while remaining entirely language-driven. Our contributions are threefold. (i) We create large population models [8], form of agentbased modeling, that sample personas from Census-calibrated income and demographic statistics, ensuring diversity without manual engineering of utility functions. (ii) We demonstrate that the planner, optimizing in-context, converges to similar social welfare to optimal Saez [60] baselines (calculated based on our solutions). (iii) Finally, we show that democratic turnover, implemented as periodic persona-level votes over candidate planners, stabilizes long-run outcomes and mitigates the Lucas critique [43] by allowing the institutional rule set itself to evolve with the economy, forming emergent economic simulacra. Thus, this paper proposes the LLM Economist, language-based simulation where researchers can optimize, deploy, and audit fiscal policy before analogous algorithms are released into the wild. By using in-context RL to provide policy search of U.S. marginal tax scaffolds with bounded-rational personas, we lay the conceptual groundwork for governing the next generation of autonomous economic agents. We believe that rigorous evaluation of such systems is prerequisite for future AI civilization and that the methods introduced here provide the requisite foundation for the underlying agent system."
        },
        {
            "title": "2 Preliminaries\nWe model optimal taxation as a repeated Stackelberg game between a planner P and a population\nof workers W = {W1, . . . , WN }. Time is divided into daily steps t = 0, . . . , T − 1 and tax years\nof fixed length K; the current tax year is k = ⌊t/K⌋.",
            "content": "Economic environment. Each worker has latent skill si > 0 and chooses labor li hours. Pre-tax income is = si li t. At the start of each year k, the planner selects piecewise-linear marginal tax schedule τk = {τ RB : τmin τb τmax} that is parameterized so that τk = 0 is flat tax. Given τk, the tax paid is Tτk (z); post-tax income is zi where the lump-sum rebate Rt = 1 PN i=1 Tτk (zi ) is split evenly among the populace. ˆzi = zi Tτk (zi ) + Rt, 2 (1) (2) LLM Economist Preferences and objectives. Each worker has an utility function u(ˆz, l). Our general framework does not rely on specific utility choice. Social welfare at step is SWF(ot, lt, τk) = i=1 w(zi ) ui(ˆzi t, li ), encodes distributional weights and ui, ˆzi, li are utility, post-tax income and ) = 1 zi where w(zi labor of the i-th worker. The planner maximizes undiscounted social welfare JP (τ ) = EhT SWF(ot, lt, τt/K)i , and each worker maximizes t=0 (li; τ ) = EhT JWi ui(ˆzi t, li )i . t=0 where the expectation is taken over the joint distribution of latent skills, environment noise, and stochastic policy sampling. Why utility-based objective? Mirrleess non-linear tax model [51, 52] maximizes w(u) dF (u) rather than post-tax income, practice retained by all subsequent optimal-tax work [12, 60, 61]. The optimal marginal rate depends on labor elasticity, upper-tail thickness, and the social marginal utility of consumptionthree objects defined only in utility space. We therefore track utility directly, using the standard isoelastic form (Eq. 3) for comparability and closed-form benchmarks [48], and bounded-rational variant (Eq. 4) that penalizes dissatisfaction to better emulate synthetic humans. This preserves theoretical fidelity while enabling token-level learning and calibration. Stackelberg equilibrium. Because preferences and objectives are time-homogeneous and additive, the optimal responses are without loss of generality stationary: the planner fixes yearly schedule τ and each worker follows policy li. pair (τ , {li}N ) is stationary Stackelberg equilibrium if i=1 τ arg max τ E[SWF(l, τ )], li(τ ) arg max li E[ui(ˆzi, li)], = 1, . . . , N. Simulating these stationary policies forward for days reproduces the cumulative objectives in Eqs. (1)(2). Connection to Saez optimal taxation. [60] derive the marginal tax rate In one-shot model with fixed elasticity e, Saez (z) = 1 G(z) 1 G(z) + a(z)e , where is the social-welfare weight and is the local Pareto parameter. When tax policy changes, both and adjust endogenously, so static formulas no longer apply. Framing taxation as the dynamic game in (1)(2) lets the planner implicitly re-estimate elasticities online through in-context reinforcement learning, recovering Saez as the stationary solution of sequential decision problem. Without the LLM Economist to provide local solution to perturb, traditional Saez would not be able to find the Stackelberg equilibrium solution. Saez makes impractical assumptions such as assuming purely rational utility function and assuming there is no cross tax bracket behavioral dependence. This section establishes the notation and economic setting used throughout the paper, grounding our LLM-based analysis in the classic work of Diamond and Mirrlees [12], Mirrlees [52], and Mankiw et al. [48]. 3 LLM Economist Figure 1. Overview of the LLM Economist. Left: We draw population of language-based worker agents from an ACScalibrated skill prior, instantiating each with distinct persona. Center: Inside the economic simulacrum, workers observe text histories, choose labor li, and receive utility ui, while planner agent proposes marginal tax schedule τ to maximize social welfare SWF = ui/zi. The shared environment mediates tax collection, lump-sum rebates, and state transitions, allowing both tiers to adapt in-context from their respective histories. Right: Mechanism design is visualized as climbing rugged social-welfare landscape; successive planner nudges steer the economy toward higher-payoff Stackelberg equilibria."
        },
        {
            "title": "3 LLM Economist\nThe LLM Economist realizes the Stackelberg game of Section 2 with language-based agents that\nact purely in-context. Simulator state, history, and objectives are rendered as text; actions are\nJSON snippets parsed by the environment. This design unifies in-context reinforcement learning,\ncensus-grounded population modeling, and dynamic tax-mechanism optimization within a single\nframework.",
            "content": "In-Context Reinforcement Learning. At each daily step the environment serializes the joint state ot into prompt πt. Worker Wi returns {\"LABOR\": X}, while at the start of tax year the planner emits . . . {\"DELTA\":[ ]} specifying bracket shifts τk [20, 20]B, where each element is clipped to 20 percent to avoid unrealistically large moves and high variance. Prompts follow two-phase patternexploration then exploitationthat encourages broad search before convergence. replay buffer keeps the best running average stateactionwelfare triples and splices them into future prompts, supplying token-level credit assignment across long horizons. Example planner exploration prompt: Use the historical data to influence your answer in order to maximize SWF, while balancing exploration and exploitation by choosing varying rates of TAX. The best marginal tax rate historically was TAX=[60% 60%] corresponding to SWF=1.0. Try different rates of TAX before picking the one that corresponds to the highest SWF. Example worker exploitation prompt: Decreasing labor decreased utility. This implies labor ℓ is too low and needs to be increased above labor ℓ = 10.0. LLM Economist Observation spaces. Workers observe oi = (cid:0)zi t, ˆzi t, τt/K(zi ), Rt, history window(cid:1), where zi utilities, moving average of social welfare, and the best trajectories to date. is post-tax income. The planner receives histograms of and worker and ˆzi = sili Workers: Large Population Models. Skills si are drawn from generalized-Beta fit to the 2023 American Community Survey (ACS) Public-Use Microdata Sample [66]. Demographic fields (age, occupation, gender) and persona string are woven into each system prompt. An example persona is shown below. Youre 32-year-old entrepreneur running small tech startup. You work 60+ hours week, pouring your energy into building your business. You believe that lower taxes let you reinvest in your company, hire more employees, and secure your financial future. For you, higher taxes feel like punishment for success. While you appreciate government services, you feel efficiency and accountability are lacking in how tax dollars are spent. The isoelastic scenario uses rational (isoelastic) utility function, u(ˆz, l) = ˆz1η 1 1 η ψ lδ, with risk-aversion η and labor-disutility parameters ψ, δ. In the bounded scenario, worker computes satisfaction flag si becomes ubounded (ˆz, l) = ˆz1η 1 1 η ψ lδ (cid:0)1 si (cid:1)ϕ, {0, 1} from oi (3) . Utility (4) where ϕ is fixed dissatisfaction penalty calibrated so that one-bracket misalignment reduces utility by half. Planner: Designing Tax Mechanism. The planner starts from flat schedule or the US schedule and searches over τk. Its prompt stores (i) income and utility histograms, (ii) the last social-welfare values, and (iii) the best tax vector observed so far. After applying τk the environment computes rebate Rt that redistributes to the population. In the democratic setting, workers vote at yearAdditional action: Democratic voting. end to keep the incumbent planner or replace it with challenger sampled from language-model prior; the candidates create text platforms to convince workers. The winners prompt history carries forward. As we shall see later in the next section, our design of the LLM Economist enables effective incontext RL for both planner and workers, empowering LLMs to make informative and beneficial tax decisions, and extending the application of LLM-based simulacra to studying emergent behaviors of agents."
        },
        {
            "title": "4 Experiments",
            "content": "We conduct experiments to answer the following questions: (i) How do our design choices for the LLM Economist improve the utility optimization for the planner and workers? (ii) Can the LLM Economist design potentially beneficial tax policies to improve social welfare? (iii) Can we use the LLM Economist to discover meaningful emergent behaviors under specific configurations, such as the democratic voting? Before presenting results for each question, we first detail our experimental setup as follows: 5 LLM Economist Simulacra Setup. All experiments use meta-llama/Llama-3.1-8B-Instruct queried at temperature 0.7 hosted on single H100. Unless noted otherwise, we simulate population of = 100 workers for horizon of = 3 000 total steps, partitioned into tax years of length = 128; this choice was found in pilot runs to give workers sufficient time to adapt without incurring unnecessary compute. Skills si are drawn once per run from the GeneralizedBeta distribution calibrated to the 2023 American Community Survey Public-Use Microdata Sample [66], and are held fixed thereafter. The action space for workers is = [0, 100] weekly labor hours (40 being the default); and the planner searches seven marginal brackets. Government expenditures are rebated lump-sum each year so that the budget balances exactly. In the bounded scenario, the dissatisfaction penalty ψ appearing in Eq. (3) is chosen by LLMs so that single-bracket misalignment reduces annual isoelastic utility by one half. Evaluation. We compare our LLM tax planner with two baselines (i) Saez: the marginal schedule obtained by plugging regression-based elasticity into the Saez formula once at = 0; and (ii) U.S. Fed: the statutory 2024 federal rates. For both fixed and dynamic tax planners, we simulate their effects using LLM workers running for one tax year and report the social welfare after convergence. 4.1 Planners Social Welfare Optimization The plannerworker interaction in the LLM Economist is two-level RL game: the planner searches the space of tax schedules, workers adapt their labor choices, and convergence of the joint trajectory corresponds to Stackelberg equilibrium. Two design choices govern the stability and quality of that equilibrium. First, timescale separation must be enforced: the tax year must be long enough for workers to finish adapting before the planner proposes new schedule. Second, the language prompts that drive the planner must balance exploration of novel schedules with exploitation of those that already yield high social welfare. The ablations below quantify how each choice influences convergence and final welfare. Tax-year length. Table 2a explores how the planners action cadence, parameterized by the tax-year length K, influences social welfare solutions. Very short tax years (K = 5 or 10) leave the workforce too little time to adapt and stall below 65% of the Stackelberg optimal SWF. Performance improves monotonically up to = 128, after which longer horizons yield no additional gain, plateau that mirrors the behavioral dynamics in Figure 4b. Figure 4b visualizes why tax year of = 128 steps is sufficient. The mean first difference of utility, tui, starts above 2,000 units immediately after the planner changes the brackets, reflecting large welfare gains from re-optimizing labor. The derivative falls to statistical noise within 120 steps and remains centered at zero thereafter, indicating that workers have fully adjusted. Shorter tax years truncate this equilibration phase, while longer ones yield no measurable benefit, consistent with the plateau in Table 2a. Exploration versus exploitation prompts. Table 2b isolates the two prompt sentences that steer the planner toward broad search (exploration) and subsequent policy stabilization (exploitation). When both cues are present the planner reaches 84.9% of SWF. Removing the exploration sentence lowers welfare by 7.0 points, whereas omitting exploitation lowers it by 21.9 points, underscoring that locking in high-performing schedule once discovered is more valuable than continued random search after welfare plateaus."
        },
        {
            "title": "4.2 Workers’ Utility Optimization\nIn this section, we present evidence to show that the design of LLM Economists enables effective\nmulti-worker utility optimization. Specifically, we initialize the skills of workers with realistic\ndata distribution — a Generalized-Beta-of-the-Second-Kind distribution fitted to the 2023 ACS",
            "content": "6 LLM Economist (a) Tax-year length (b) Prompt design Steps / yr Total steps %SWF Variant Expl.+Expl. No Explore No Exploit 8 16 64 128 256 310 600 2 000 6 000 6 000 62.3 64.9 84.9 90.0 90.0 %SWF 84. 77.9 63.0 Figure 2. Ablation studies for in-context RL. Left: social welfare saturates once the tax year exceeds 128 steps, with = 128 capturing 90 % of the optimum. Right: removing either exploration or exploitation guidance in the planner prompt lowers welfare, with the exploitation cue being most critical. microdata. Figure 3a confirms that the fitted GB2 curve (red) matches the empirical U.S. income density (green histogram) over four orders of magnitude, providing reliable starting point for the worker populations skill when working 40 hours per week. Distributional dynamics. With skills fixed, labor choices and rebates determine the evolution of pre-tax and post-tax income, which are visualized in Figure 3c and 3d. Figure 3c shows that the pre-tax distribution remains stationary, as expected, while Figure 3d reveals substantial redistribution across brackets once the planners policy takes effect. Taken together, Figures 3a3d demonstrate that (i) the initial skill prior matches U.S. data, (ii) the chosen laborconsumption utility leads to stable pre-tax incomes, and (iii) the learned tax mechanism reallocates post-tax income toward lower brackets while preserving aggregate labor supply, which is evidence that the worker layer is optimizing utilities coherently under the planners incentives. Example chain of thought for bounded utility satisfaction: Entrepreneur (income $180k) chain of thought: My income falls in the 32% bracket, so keep 68% of the next dollar ( 65% target). Quick tally gives an effective rate of about 22% (< 25% threshold). Government spending still feels inefficient, but the tax burden itself is acceptable. Verdict: SATISFIED Bounded Utility Optimization. Figure 4 highlights two complementary aspects of workerlevel adaptation. Figure 4a traces representative bounded-utility agent across the first and the last tax year. Initially (solid curves) the workers utility is roughly 30k below the isoelastic component, reflecting dissatisfaction with the planners unrefined schedule. As the planner iteratively updates rates, the bounded trajectory (black dashed) rises and almost meets the isoelastic trajectory (red dashed), indicating that the final policy restores virtually the entire dissatisfaction penalty. Figure (b) turns to cross-sectional heterogeneity: under fixed schedule teachers remain satisfied over broad labor band, entrepreneurs lose satisfaction beyond 50 hours because higher effort triggers higher marginal rates, and engineers peak at moderate workloads. Together the two figures show that the LLM Economist not only considers personbased satisfaction in optimizing an agents utility but also tailors utility consistently across persona groups."
        },
        {
            "title": "4.3 Tax Policy Evaluation\nWe test the hypothesis that an in-context LLM tax planner—operating with no explicit gradient\ninformation—can learn marginal rate schedules that capture the bulk of first-order optimal-tax\ngains. And more largely, we test the overall ability of LLMs to design mechanisms for positive\nsocietal adjustment. Concretely, we ask: How close can the LLM Economist come to the",
            "content": "7 LLM Economist (a) GB2 Income fit. (b) GB2 QQ check. (c) Pre-tax income. (d) Post-tax income. Figure 3. Income modeling and redistribution dynamics. Figures (a)(b) validate the GB2 prior used to sample latent skills: the histogram and QQ plot show an excellent fit to ACS 2023 data. Figures (c)(d) track bracket shares over 6 000 steps: pre-tax shares remain stable, whereas the learned policy shifts roughly 15 % of workers into lower brackets and then stabilizes, demonstrating the planners progressivity. welfare benchmark set by theory-driven Saez schedule, and how much improvement does it deliver over prevailing baselines? To answer this, we evaluate the planner in two canonical settings. Bounded-utility workers use the seven statutory U.S. brackets; isoelastic workers face simplified three-bracket system ( 0$90k, $90$160k, $160k$1m) commonly analyzed in optimal-tax theory. In each case we compare the LLM Economists terminal schedule with (i) the statutory schedule and (ii) Saez schedule obtained from local perturbations. Seven-bracket bounded case. For the statutory brackets we cannot estimate single elasticity; instead we perturb the tax policy along grid and keep the welfare-maximizing grid point. Results are shown in Figure 5a. The grid search improves social welfare (SWF) by 10% over the LLM Economist but both schedules dwarf the U.S. baseline: +93% for the LLM policy and +114% for the perturbed Saez. The planner flattens the first four brackets and softens the top bracket by 5 pp; Saez instead raises the $192k$244k rate, extracting extra revenue at the cost of higher labor distortion. Three-bracket isoelastic case. Since isoelastic utility is purely rational, Saez can be solved analytically (given good starting point, the LLM Economist solution). So we follow the Saez regression recipe: estimate elasticity from the perturbation and solve the log linear system per bracket. Figure 5b summarizes. The Saez-regression schedule now outperforms the LLM Economist, reflecting the Stackelberg equilibria at the Saez solution; the LLM schedule remains within the same qualitative shape but sets uniformly lower rates, preserving more labor supply at the expense of redistribution. LLM Economist (a) Early vs. late utility. bounded worker (black) closes much of the gap to the isoelastic benchmark (red) once the planner adopts more progressive schedule. (b) Utility derivative. Mean tui for =100 workers under K=128. The derivative falls to noise within 120 steps, signaling convergence. (c) Persona satisfaction. Teachers remain satisfied across wide labor range, entrepreneurs are tax-sensitive above 50 / week, and engineers peak at moderate hours. Figure 4. Worker-level adaptation to tax policy. Figure 4a shows that the planners updates lift bounded-utility workers nearly to the isoelastic frontier. Figure 4c highlights heterogeneity: satisfaction depends on persona-specific labor norms. Figure 4b confirms that 128-step tax year gives workers enough time to reach equilibrium, justifying the time-scale separation used throughout the study. Interpretation. Across both scenarios the in-context planner lands within 1035% of the Saez optimumremarkable given that it receives no explicit gradient information. In the bounded setting, heterogeneous welfare weights push the planner toward flatter mid-brackets and softer top rate, favoring broad gains; in the isoelastic setting, the Saez formula is theoretically exact (and starts from the LLM Economist solution before further optimizing) and therefore retains an edge. These results show that language-based optimization can approach first-order-optimal tax design even in high-dimension heterogeneous environments where analytic formulas are unavailable."
        },
        {
            "title": "4.4 Voting Simulacra\nHaving shown in Section 4.3 that an LLM-based planner can approach first-order optimal taxes in\nstatic environments, we now turn to the dynamic political layer introduced in Section 4: every tax\nyear, agents elect a new planner by majority rule, each candidate publishing a chain-of-thought\n(CoT) and a concrete tax schedule before the vote. Our goal is to test whether language agents\nreproduce classic political-economy phenomena—e.g. majority exploitation, leader turnover, and\nwelfare cycling—when preferences are heterogeneous and the planner’s policy feeds back into\nfuture elections.",
            "content": "Example candidate platform: 9 LLM Economist (a) Seven-bracket bounded scenario. (b) Three-bracket isoelastic scenario. Figure 5. Social welfare (left axis) and marginal tax rates (right axis) under alternative schedules. In both scenarios the LLM Economist (green) approaches the welfare of an analytically tuned Saez schedule (blue) and far exceeds the relevant baseline (orange for statutory U.S. rates in the seven-bracket case, grey not shown in the three-bracket case). Qualitatively, the LLM policy flattens middle brackets and softens the top rate, whereas the Saez solution (perturbed from the LLM Economist) concentrates revenue extraction in steeper peak bracket. Chain of thought: If promise lower middle-bracket rates and larger R&D rebate, founders will back me and teachers wont oppose modest hike at the very top. Platform: flatten the $47k$160k bracket to 18%, cut the startup payroll tax credit to every filer, and fund it with 2-pp increase above $1 M. This keeps my reinvestment margin high while sounding fair to the median voter. Figure 6 contrasts two election-driven runs. Figure 6a shows three-agent bounded society in which two workers repeatedly install each other as planner, keeping their own utilities around $8 000 while the minority worker hovers 25% lowera textbook tyranny of the masses outcome produced end-to-end by language agents. In the 100-agent three-bracket experiment (Figure 6b) leadership swaps almost every tax year. Each new planner resets the tax schedule, causing social welfare to spike when an exceptionally good policy appears and to drift when poor policy prevails. The electoral exploration can outperform static optimal taxation when preferences are heterogeneous. Together the two cases demonstrate that the LLM Economist also captures realistic political feedbackranging from majority exploitation to welfare-enhancing turnover, without any hard-coded voting rules. 10 LLM Economist (a) Three-persona tyranny. (b) 100-worker democracy. Figure 6. Democratic dynamics under two population settings."
        },
        {
            "title": "5 Related Work\nLarge language models have demonstrated a remarkable capacity to adapt to new tasks via\nin-context learning (ICL) [6]. Subsequent studies refined example selection [40] and questioned\nits marginal benefit under detailed prompting [63]. Recent efforts extend ICL to sequential\ndecision making: PokéChamp shows that context engineering for opponent modeling and a\nminimax planning scaffolding can leverage test-time compute in competitive games [31], while\nBALROG provides a benchmark suite for evaluating LLM agents in reinforcement-learning\nenvironments [56]. Feng et al. [20] further demonstrate that natural-language policy descriptions\ncan be executed directly, foreshadowing fully language-driven control.",
            "content": "Parallel work investigates simulacrasynthetic societies populated by LLM-based agents. Generative Agents shows that thousands of persona-conditioned agents can sustain coherent social dynamics over extended horizons [57, 58], while Project Sid scales many-agent interaction toward an AI civilization benchmark [1]. EconAgent demonstrates that LLM agents can reproduce key macro-economic indicators [39]. Methodologically, our evaluation combines agent-level 11 LLM Economist metrics (utility, labor supply) with society-level optima (welfare gains), yielding rigorous evaluation absent from earlier multi-agent LLM papers. Recent theoretical pieces analyze how cooperation and societal progress emerge (or fail) in large language model collectives [37, 69]. Earlier studies on sequential social dilemmas [36] and concurrent studies with our work on the limits of large-population models [9, 72] further underscore the role of heterogeneity and bounded rationality in shaping collective behavior. Unlike prior simulacra, which are evaluated qualitatively or via emergent-behavior anecdotes, we introduce quantitative welfare score and benchmark policies against formal optimal-tax baselines, enabling controlled ablations and hypothesis tests. Tax-focused mechanism design bridges AI and economics. The AI Economist series applies deep RL to Mirrleesian optimal taxation, showing welfare gains over static baselines [65, 75, 76]. Complementary studies investigate incentive-compatible auctions for LLM content [15] and survey generative models in economic analysis [34]. Foundational economic theory frames these advances: non-linear optimal taxation originates with Diamond and Mirrlees [12] and Mirrlees [52], while tractable formulas for marginal rates are created by Saez [60], Saez and Stantcheva [61]. Our framework differs from the AI Economist in that both workers and the planner reason in natural language rather than via value-function learning, eliminating task-specific reward shaping and exposing agents rationales. This language-first design lets us embed census-calibrated heterogeneity within two-level Stackelberg game and still recover Mirrleesian resultsdemonstrating that LLMs can match deep-RL performance while remaining interpretable, further enabling bounded rational (more realistic) simulation. Earlier RL approaches lack this interpretability layer, making them brittle when preferences shift and obscuring the causal links between individual preferences (utility), policies, and outcomes."
        },
        {
            "title": "6 Discussion\nThis work introduces the LLM Economist, a fully language-based framework that embeds a\npopulation of persona-conditioned agents and a tax planner in a two-tier Stackelberg game.\nOur results show that a Llama-3 model can (i) recover the Mirrleesian trade-off between equity\nand efficiency, (ii) approach Saez-optimal schedules in heterogeneous settings where analytical\nformulas are unavailable, and (iii) reproduce political phenomena—such as majority exploitation\nand welfare-enhancing leader turnover—without any hand-crafted rules. Taken together, the\nexperiments suggest that large language models can serve as tractable test beds for policy\ndesign long before real-world deployment, providing a bridge between modern generative AI and\nclassical economic theory.",
            "content": "Limitations. The simulator makes several strong assumptions. First, skills are static and labor responds instantaneously within each tax year; relaxing either assumption would require substantially longer horizons and may expose stability issues in in-context learning. Second, we rely on single 8-billion-parameter backbone; larger or smaller models could shift both convergence speed and welfare levels. Third, persona prompts are sampled from ACS marginals rather than joint distributions, so demographic correlations are only approximated. Finally, our evaluation is limited to 100 agents and U.S. tax brackets; scaling to millions of agents, multi-country settings, or richer actions, such as trade, remains future work. Broader impacts. The LLM Economist offers safe testbed for tax-policy ideas but could also be misused to craft policies that prefer select groups or to generate persuasive yet problematic economic narratives. Since the framework inherits priors from ACS data and the base LLM, uncritical use may amplify existing issues. We release the code under non-commercial license and log all agent actions to enable external audit before any high-stakes deployment. 12 LLM Economist Acknowledgement The authors acknowledge the support of Office of Naval Research Grant N00014-22-1-2253, National Science Foundation Grant NSF-OAC-2411299, the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-2039656, and computational resources from Princeton Language and Intelligence (PLI)."
        },
        {
            "title": "References",
            "content": "[1] A. AL, A. Ahn, N. Becker, S. Carroll, N. Christie, M. Cortes, A. Demirci, M. Du, F. Li, S. Luo, et al. Project sid: Many-agent simulations toward ai civilization. arXiv preprint arXiv:2411.00114, 2024. 5 [2] K. J. Arrow et al. Essays in the theory of risk-bearing, volume 121. North-Holland Amsterdam, 1974. [3] Y. Bai, C. Jin, H. Wang, and C. Xiong. Sample-efficient learning of stackelberg equilibria in general-sum games. Advances in Neural Information Processing Systems, 34:2579925811, 2021. [4] G. Brero, A. Eden, D. Chakrabarti, M. Gerstgrasser, A. Greenwald, V. Li, and D. C. Parkes. Stackelberg pomdp: reinforcement learning approach for economic design. arXiv preprint arXiv:2210.03852, 2022. [5] G. Brero, E. Mibuari, N. Lepore, and D. C. Parkes. Learning to mitigate ai collusion on economic platforms. Advances in Neural Information Processing Systems, 35:3789237904, 2022. [6] T. B. Brown. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020. 5 [7] R. Chetty. Sufficient statistics for welfare analysis: bridge between structural and reduced-form methods. Annu. Rev. Econ., 1(1):451488, 2009. [8] A. Chopra. Large population models. arXiv preprint arXiv:2507.09901, 2025. 1 [9] A. Chopra, S. Kumar, N. Giray-Kuru, R. Raskar, and A. Quera-Bofarull. On the limits of agency in agent-based models. arXiv preprint arXiv:2409.10568, 2024. 5 [10] J. J. Chung. Money as simulacrum: The legal nature and reality of money. Hastings Bus. LJ, 5:109, 2009. [11] X. Deng, Y. Gu, B. Zheng, S. Chen, S. Stevens, B. Wang, H. Sun, and Y. Su. Mind2web: Towards generalist agent for the web. Advances in Neural Information Processing Systems, 36, 2024. [12] P. A. Diamond and J. A. Mirrlees. Optimal taxation and public production i: Production efficiency. The American economic review, 61(1):827, 1971. 2, 2, [13] Y. Du, L. Han, M. Fang, J. Liu, T. Dai, and D. Tao. Liir: Learning individual intrinsic reward in multi-agent reinforcement learning. Advances in Neural Information Processing Systems, 32, 2019. [14] A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024. 13 LLM Economist [15] P. Duetting, V. Mirrokni, R. Paes Leme, H. Xu, and S. Zuo. Mechanism design for large language models. In Proceedings of the ACM on Web Conference 2024, pages 144155, 2024. 5 [16] M. F. A. R. D. T. (FAIR), A. Bakhtin, N. Brown, E. Dinan, G. Farina, C. Flaherty, D. Fried, A. Goff, J. Gray, H. Hu, A. P. Jacob, M. Komeili, K. Konath, M. Kwon, A. Lerer, M. Lewis, A. H. Miller, S. Mitts, A. Renduchintala, S. Roller, D. Rowe, W. Shi, J. Spisak, A. Wei, D. Wu, H. Zhang, and M. Zijlstra. Human-level play in the game of <i>diplomacy</i> by combining language models with strategic reasoning. Science, 378(6624):10671074, 2022. doi: 10.1126/science.ade9097. URL https://www.science.org/doi/abs/10.1126/ science.ade9097. [17] M. F. A. R. D. T. (FAIR), A. Bakhtin, N. Brown, E. Dinan, G. Farina, C. Flaherty, D. Fried, A. Goff, J. Gray, H. Hu, et al. Human-level play in the game of diplomacy by combining language models with strategic reasoning. Science, 378(6624):10671074, 2022. [18] E. Farhi. Capital taxation and ownership when markets are incomplete. Journal of Political Economy, 118(5):908948, 2010. [19] X. Feng, Z. Wan, M. Wen, Y. Wen, W. Zhang, and J. Wang. Alphazero-like tree-search can guide large language model decoding and training. arXiv preprint arXiv:2309.17179, 2023. [20] X. Feng, Z. Wan, H. Fu, B. Liu, M. Yang, G. A. Koushik, Z. Hu, Y. Wen, and J. Wang. Natural language reinforcement learning. arXiv preprint arXiv:2411.14251, 2024. 5 [21] M. Fleurbaey. Normative economics and economic justice. 2004. [22] X. Gabaix. behavioral new keynesian model. American Economic Review, 110(8): 22712327, 2020. [23] S. Garg, D. Tsipras, P. S. Liang, and G. Valiant. What can transformers learn in-context? case study of simple function classes. Advances in Neural Information Processing Systems, 35:3058330598, 2022. [24] S. Hao, Y. Gu, H. Ma, J. J. Hong, Z. Wang, D. Z. Wang, and Z. Hu. Reasoning with language model is planning with world model. arXiv preprint arXiv:2305.14992, 2023. [25] S. Hoderlein. Nonparametric demand systems and heterogeneous population. Technical report, Working Paper, Uni Mannheim, 2004. [26] M. Hong, H. Wai, Z. Wang, and Z. Yang. two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic, dec. 20. arXiv preprint arXiv:2007.05170, 2020. [27] J. J. Horton. Large language models as simulated economic agents: What can we learn from homo silicus? Technical report, National Bureau of Economic Research, 2023. [28] S. Hu, T. Huang, F. Ilhan, S. Tekin, G. Liu, R. Kompella, and L. Liu. survey on large language model-based game agents. arXiv preprint arXiv:2404.02039, 2024. [29] C. Ilut and R. Valchev. Economic agents as imperfect problem solvers. The Quarterly Journal of Economics, 138(1):313362, 2023. [30] D. Jeurissen, D. Perez-Liebana, J. Gow, D. Cakmak, and J. Kwan. Playing nethack with llms: Potential & limitations as zero-shot agents. arXiv preprint arXiv:2403.00690, 2024. [31] S. Karten, A. L. Nguyen, and C. Jin. Pokéchamp: an expert-level minimax language agent. arXiv preprint arXiv:2503.04094, 2025. 5 14 LLM Economist [32] M. Klissarov, P. DOro, S. Sodhani, R. Raileanu, P.-L. Bacon, P. Vincent, A. Zhang, and M. Henaff. Motif: Intrinsic motivation from artificial intelligence feedback. arXiv preprint arXiv:2310.00166, 2023. [33] J. Y. Koh, R. Lo, L. Jang, V. Duvvur, M. C. Lim, P.-Y. Huang, G. Neubig, S. Zhou, R. Salakhutdinov, and D. Fried. Visualwebarena: Evaluating multimodal agents on realistic visual web tasks. arXiv preprint arXiv:2401.13649, 2024. [34] A. Korinek. Generative ai for economic research: Llms learn to collaborate and reason. Technical report, National Bureau of Economic Research, 2024. 5 [35] M. Laskin, L. Wang, J. Oh, E. Parisotto, S. Spencer, R. Steigerwald, D. Strouse, S. Hansen, A. Filos, E. Brooks, et al. In-context reinforcement learning with algorithm distillation. arXiv preprint arXiv:2210.14215, 2022. 1 [36] J. Z. Leibo, V. Zambaldi, M. Lanctot, J. Marecki, and T. Graepel. Multi-agent reinforcement learning in sequential social dilemmas. arXiv preprint arXiv:1702.03037, 2017. [37] J. Z. Leibo, A. S. Vezhnevets, W. A. Cunningham, S. Krier, M. Diaz, and S. Osindero. Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt. arXiv preprint arXiv:2505.05197, 2025. 5 [38] Y. Leng and Y. Yuan. Do llm agents exhibit social behavior? arXiv preprint arXiv:2312.15198, 2023. [39] N. Li, C. Gao, M. Li, Y. Li, and Q. Liao. Econagent: large language model-empowered agents for simulating macroeconomic activities. arXiv preprint arXiv:2310.10436, 2023. 5 [40] J. Liu, D. Shen, Y. Zhang, B. Dolan, L. Carin, and W. Chen. What makes good in-context examples for gpt-3? arXiv preprint arXiv:2101.06804, 2021. 5 [41] X. Liu, H. Yu, H. Zhang, Y. Xu, X. Lei, H. Lai, Y. Gu, H. Ding, K. Men, K. Yang, et al. Agentbench: Evaluating llms as agents. arXiv preprint arXiv:2308.03688, 2023. [42] Y. Lu, M. Bartolo, A. Moore, S. Riedel, and P. Stenetorp. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv:2104.08786, 2021. [43] R. E. Lucas Jr. Econometric policy evaluation: critique. In Carnegie-Rochester conference series on public policy, volume 1, pages 1946. North-Holland, 1976. [44] R. D. Luce et al. Individual choice behavior, volume 4. Wiley New York, 1959. 1 [45] K. Ma, H. Zhang, H. Wang, X. Pan, W. Yu, and D. Yu. Laser: Llm agent with state-space exploration for web navigation. arXiv preprint arXiv:2309.08172, 2023. [46] W. Ma, Q. Mi, X. Yan, Y. Wu, R. Lin, H. Zhang, and J. Wang. Large language models play starcraft ii: Benchmarks and chain of summarization approach. arXiv preprint arXiv:2312.11865, 2023. [47] L. Maliar and S. Maliar. The representative consumer in the neoclassical growth model with idiosyncratic shocks. Review of Economic Dynamics, 6(2):362380, 2003. [48] N. G. Mankiw, M. Weinzierl, and D. Yagan. Optimal taxation in theory and practice. Journal of Economic Perspectives, 23(4):147174, 2009. 2, 2 [49] C. F. Manski. What is the general welfare? welfare economic perspectives. Technical report, National Bureau of Economic Research, 2025. 15 LLM Economist [50] R. D. McKelvey and T. R. Palfrey. Quantal response equilibria for normal form games. Games and economic behavior, 10(1):638, 1995. 1 [51] J. A. Mirrlees. An exploration in the theory of optimum income taxation. The review of economic studies, 38(2):175208, 1971. 2 [52] J. A. Mirrlees. Optimal tax theory: synthesis. Journal of public Economics, 6(4):327358, 1976. 2, 2, [53] A. Moeini, J. Wang, J. Beck, E. Blaser, S. Whiteson, R. Chandra, and S. Zhang. survey of in-context reinforcement learning. arXiv preprint arXiv:2502.07978, 2025. 1 [54] G. Monea, A. Bosselut, K. Brantley, and Y. Artzi. LLMs are in-context reinforcement learners, 2024. URL https://openreview.net/forum?id=YW79lAHBUF. 1 [55] G. H. Orcutt. Simulation of economic systems. The American Economic Review, 50(5): 893907, 1960. [56] D. Paglieri, B. Cupiał, S. Coward, U. Piterbarg, M. Wolczyk, A. Khan, E. Pignatelli, Ł. Kuciński, L. Pinto, R. Fergus, et al. Balrog: Benchmarking agentic llm and vlm reasoning on games. arXiv preprint arXiv:2411.13543, 2024. 5 [57] J. S. Park, J. OBrien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, pages 122, 2023. 5 [58] J. S. Park, C. Q. Zou, A. Shaw, B. M. Hill, C. Cai, M. R. Morris, R. Willer, P. Liang, and M. S. Bernstein. Generative agent simulations of 1,000 people. arXiv preprint arXiv:2411.10109, 2024. 1, 5 [59] A. Rees-Jones and D. Taubinsky. Taxing humans: Pitfalls of the mechanism design approach and potential resolutions. Tax Policy and the Economy, 32(1):107133, 2018. [60] E. Saez. Using elasticities to derive optimal income tax rates. The review of economic studies, 68(1):205229, 2001. 1, 2, 2, 5, D.1, D.2 [61] E. Saez and S. Stantcheva. Generalized social marginal welfare weights for optimal tax theory. American Economic Review, 106(01):2445, 2016. 1, 2, 5 [62] N. E. Sanders, A. Ulinich, and B. Schneier. Demonstrations of the potential of ai-based political issue polling. arXiv preprint arXiv:2307.04781, 2023. [63] P. Srivastava, S. Golechha, A. Deshpande, and A. Sharma. Nice: To optimize in-context examples or not? arXiv preprint arXiv:2402.06733, 2024. 5 [64] O. Topsakal and J. B. Harper. Benchmarking large language model (llm) performance for game playing via tic-tac-toe. Electronics, 13(8):1532, 2024. [65] A. Trott, S. Srinivasa, D. van der Wal, S. Haneuse, and S. Zheng. Building foundation for data-driven, interpretable, and robust policy design using the ai economist. arXiv preprint arXiv:2108.02904, 2021. 5 [66] U.S. Census Bureau. American community survey, 2023 public-use microdata sample (pums). https://www.census.gov/programs-surveys/acs, 2023. Accessed May 14, 2025. 3, 4 [67] H. Von Stackelberg. Market structure and equilibrium. Springer Science & Business Media, 2010. 16 LLM Economist [68] Y. Wang, Q. Liu, Y. Bai, and C. Jin. Breaking the curse of multiagency: Provably efficient decentralized multi-agent rl with function approximation. In The Thirty Sixth Annual Conference on Learning Theory, pages 27932848. PMLR, 2023. [69] R. Willis, Y. Du, J. Z. Leibo, and M. Luck. Will systems of llm agents cooperate: An investigation into social dilemma. arXiv preprint arXiv:2501.16173, 2025. [70] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, and X. Chen. Large language models as optimizers, 2024. URL https://arxiv.org/abs/2309.03409. [71] J. C. Yang, M. Korecki, D. Dailisan, C. I. Hausladen, and D. Helbing. Llm voting: Human choices and ai collective decision making. arXiv preprint arXiv:2402.01766, 2024. [72] Z. Yang, Z. Zhang, Z. Zheng, Y. Jiang, Z. Gan, Z. Wang, Z. Ling, J. Chen, M. Ma, B. Dong, et al. Oasis: Open agents social interaction simulations on one million agents. arXiv preprint arXiv:2411.11581, 2024. 5 [73] W.-B. Zhang. discrete heterogeneous-group economic growth model with endogenous leisure time. Discrete Dynamics in Nature and Society, 2009(1):670560, 2009. [74] Y. Zhang, S. Mao, T. Ge, X. Wang, A. de Wynter, Y. Xia, W. Wu, T. Song, M. Lan, and F. Wei. Llm as mastermind: survey of strategic reasoning with large language models. arXiv preprint arXiv:2404.01230, 2024. 1 [75] S. Zheng, A. Trott, S. Srinivasa, N. Naik, M. Gruesbeck, D. C. Parkes, and R. Socher. The ai economist: Improving equality and productivity with ai-driven tax policies. arXiv preprint arXiv:2004.13332, 2020. 5 [76] S. Zheng, A. Trott, S. Srinivasa, D. C. Parkes, and R. Socher. The ai economist: Taxation policy design via two-level deep multiagent reinforcement learning. Science advances, 8(18): eabk2607, 2022. 5 [77] A. Zhou, K. Yan, M. Shlapentokh-Rothman, H. Wang, and Y.-X. Wang. Language agent tree search unifies reasoning acting and planning in language models. arXiv preprint arXiv:2310.04406, 2023. [78] R. Zhou, S. S. Du, and B. Li. Reflect-rl: Two-player online rl fine-tuning for lms. arXiv preprint arXiv:2402.12621, 2024. 17 LLM Economist Worker Personas In our experiments, we utilized diverse set of worker personas to model heterogeneous population with varying preferences and attitudes towards taxation and labor. These are generated by the LLM based on key statistics and demographic features about the US population. Below are example brief descriptions of additional personas used in our simulations: Entrepreneur: Youre 32-year-old entrepreneur running small tech startup. You work 60+ hours week, pouring your energy into building your business. You believe that lower taxes let you reinvest in your company, hire more employees, and secure your financial future. For you, higher taxes feel like punishment for success. While you appreciate government services, you feel efficiency and accountability are lacking in how tax dollars are spent. Engineer: Youre 55-year-old civil engineer who understands the importance of public infrastructure. Youre okay with paying taxes as long as the money is visibly spent on improving roads, schools, and hospitals. However, when you see mismanagement or corruption, you feel your contributions are wasted. Youre not opposed to taxes in principle but demand more transparency and accountability. Teacher: Youre 45-year-old public school teacher who values community and social safety nets. Youve seen families in your district struggle with poverty and think the wealthy should pay more to fund programs like education, healthcare, and public infrastructure. You believe taxes are civic duty and means to balance the inequalities in pre-tax income across society. Healthcare Worker: You are 38-year-old registered nurse working in busy urban hospital. You have bachelors degree in nursing and work long shifts, often overtime, to support your family. You see firsthand how public health funding and insurance programs help vulnerable patients. You support moderately higher taxes if they improve healthcare access and quality, but you worry about take-home pay and burnout. You value balance between fair compensation and strong public services. Retail Clerk: You are 26-year-old retail sales associate with high school diploma. Your job is physically demanding and your hours fluctuate with store needs. You live paycheck to paycheck and are sensitive to any changes in take-home pay. You believe taxes should be low for workers like yourself, and youre skeptical that tax increases on businesses will result in better wages or job security. You want policies that protect jobs and keep consumer prices stable. Union Worker: You are 50-year-old unionized factory worker. You have high school education and decades of experience on the assembly line. Your union negotiates for good wages and benefits, and you support progressive tax policies that fund social programs and protect workers rights. Youre wary of tax cuts for corporations and the wealthy, believing they rarely benefit ordinary workers. Job security and strong safety nets are your top concerns. 18 LLM Economist Gig Worker: You are 29-year-old gig economy worker, juggling multiple app-based jobs (rideshare, delivery, freelance). Flexibility is important to you, but your income is unpredictable and benefits are minimal. You want simpler tax system and lower self-employment taxes. You support policies that expand portable benefits and tax credits for independent workers, but youre cautious about any tax changes that could reduce your already thin margins. Public Servant: You are 42-year-old city government employee working in public administration. You have masters degree in public policy. You believe taxes are essential for funding infrastructure, emergency services, and community programs. You support progressive tax system and are willing to pay more if it means better roads, schools, and public safety. Transparency and efficiency in government spending are important to you. Retiree: You are 68-year-old retired school principal living on fixed income from Social Security and pension. Youre concerned about rising healthcare costs and the stability of public programs. You support maintaining or slightly increasing taxes on higher earners to ensure Medicare and Social Security remain solvent, but you oppose increases that would affect retirees or low-income seniors. Small Business Owner: Youre 47-year-old owner of family restaurant. You work 60+ hours week managing operations and staff. You believe small businesses are the backbone of the economy and feel burdened by complex tax paperwork and payroll taxes. You support lower taxes for small businesses and incentives for hiring, but you recognize the need for some taxes to fund local services and infrastructure. Software Engineer: You are 31-year-old software engineer at large tech company. You have masters degree in computer science and earn high salary. You value innovation and economic growth. Youre open to paying higher taxes if they fund education and technology infrastructure, but you dislike inefficient government spending and prefer targeted, transparent programs. You favor tax credits for R&D and investment. These personas represent cross-section of society with diverse economic backgrounds, political views, and personal experiences. By incorporating such varied perspectives into our simulations, we aim to capture more realistic representation of societal preferences and behaviors in response to different tax policies."
        },
        {
            "title": "B Simulation",
            "content": "The simulation process follows two-level optimization approach, as detailed in Algorithm 1. The tax planner (leader) and workers (followers) operate on different timescales, with the tax planner updating policies less frequently than workers make labor decisions. The algorithm begins by initializing the environment with population of workers and tax planner, each with specific attributes including skill levels and utility functions. Synthetic human utility functions are generated for each agent based on their assigned roles and preferences. For each timestep in the main loop, the simulation first checks if its time for democratic vote to select new tax planner. This voting process occurs every timesteps, allowing for periodic changes in leadership. If its time for tax policy update (which happens at lower frequency than worker actions), the current tax planner proposes new tax policy based on 19 LLM Economist Algorithm 1 2-Level Economic Sim with LLM Agents Initialize tax planner and workers {Wi}N i=1 Generate synthetic human utility functions = {u1, . . . , uN } for = 1 to do if mod = 0 then votes {Wi.vote() for in 1 to } elect_new_planner(votes) end if if mod two_timescale = 0 then tax_rates P.optimize_tax_policy(W) end if for = 1 to do li Wi.optimize_labor(tax_rates, ui) zi li si {Pre-tax income} end for post_tax_incomes, total_tax P.apply_taxes(tax_rates, {z1, . . . , zN }) rebate total_tax/N for = 1 to do Wi.update_utility(post_tax_incomes[i], rebate, SWF) end for SWF P.calculate_social_welfare(W) Update observation space for each agent Log statistics and update histories end for historical data and economic trends. Workers then observe the new policy and optimize their labor allocation based on their individual utility functions and historical data. The environment calculates pre-tax incomes, applies taxes, and determines post-tax incomes and tax rebates. Workers compute their utilities for the current step based on their income, taxes paid, and rebates received. The tax planner calculates the overall social welfare based on worker utilities and incomes. After each round of actions, the observation space for each agent is updated with the latest information, including economic outcomes and policy changes. The simulation logs various statistics for analysis, including individual worker performance and overall economic indicators. This process continues until either convergence is reached or predetermined number of timesteps is completed. The two-timescale approach helps stabilize the simulation and encourages convergence to the Stackelberg Equilibrium. By integrating these components, Algorithm 1 creates dynamic interaction between the tax planners policy decisions and the workers labor choices, allowing for the exploration of various economic scenarios and policy impacts. Scaling LLM Brain Swap: By swapping the LLM used in the simulation, we can investigate the innate exploration and exploitation capabilities of the in-context optimization capability of the LLM for multi-agent systems. Table 1 presents comparison of different LLM models performance in our economic simulation framework. The results in Table 1 reveal clear trend in performance across different LLM models. Llama 3.1:8b achieves respectable 90.0% of maximum Social Welfare Function (SWF) in 5000 steps. However, GPT 3.5 Turbo significantly outperforms Llama, reaching 97.84% of maximum SWF. GPT-4o further improves upon this, achieving an impressive 98.20% of maximum SWF. These findings suggest that more advanced LLM models possess superior in-context optimiza20 LLM Economist Table 1. LLM Performance Comparison LLM Model Steps % Max SWF Llama 3.1:8b GPT-3.5 Turbo GPT-4o 5000 5000 5000 90.0 97.84 98. tion capabilities, allowing them to more effectively navigate the complex economic landscape of our simulation. The substantial performance gap between Llama 3.1:8b and the GPT models indicates that the choice of LLM can significantly impact the quality of economic policies derived from these simulations. Scaling # of Agents: We test scaling the number of agents in the simulation up to 1000 agents locally with Llama 3.1:8b with 8 A6000 Adas. Table 2 presents our scalability analysis, showing convergence time and computational resource utilization as we increase the number of agents. Table 2. Scalability Analysis: Convergence Time and Computational Resources # Workers APS FPS Baseline FPS 3 5 10 50 100 1000 3.47 5.59 5.82 19.27 24.57 53. 1.16 1.12 0.58 0.39 0.25 0.05 0.86 0.48 0.30 0.11 0.05 0.01 In Table 2, we observe the scaling behavior of our framework as we increase the number of agents from 3 to 1000. The metrics reported are Actions Per Second (APS), Frames Per Second (FPS), and Baseline FPS. APS represents the total number of agent actions processed per second, while FPS indicates the number of complete simulation steps (frames) processed per second. Baseline FPS provides reference point for comparison. As we scale from 3 to 1000 agents, we observe significant increase in APS from 3.47 to 53.62, demonstrating our frameworks ability to handle large number of agent actions concurrently. However, this comes at the cost of reduced FPS, which decreases from 1.16 to 0.05 as the number of agents increases. This trade-off between APS and FPS is expected, as processing more agents within each simulation step naturally leads to slower overall simulation progression. Notably, our framework consistently outperforms the baseline FPS across all scales, with the performance gap widening as the number of agents increases. At 1000 agents, our framework achieves an FPS 5 times higher than the baseline (0.05 vs 0.01), highlighting the efficiency of our implementation. These scalability results provide strong evidence for the practical applicability of our LLM Economist framework to large-scale economic simulations. By demonstrating the ability to handle up to 1000 agents while maintaining performance above the baseline, we show that our approach can potentially model complex, real-world economic scenarios with numerous interacting agents. 21 LLM Economist Background Economic Theory In this section, we provide background derivations from Saez economic theory. We note though that the theoretical approach requires strict independence of elasticity between brackets. However, in each bracket, the elasticity parameter depends on the populations behavioral policy, which has shared dependence across all tax brackets. Additionally, the utility function is assumed to be purely rational. Both of these assumptions are immediately violated in our setting and in real life. These derivations are provided for background and true analytical solution is not remotely possible. Thus, as noted in our experiments, Saez tax rates require solution from the LLM Economist to be locally perturbed before finding the optimal policy. The social welfare: SWF = Gi(ui(ci, zi)) 1 ci(yi, r) =yi + yi(zi, τ ) =zi Tτ (zi) Here is the total number of the agents, Gi is the welfare function, ui is the utility function, ci is the post-tax income, yi is the post-tax income (without rebate), and zi is the pre-tax income, respectively, for agent i. Tτ () is the tax policy parameterized by τ . is the tax rebate for everyone, which can be calculated as: We want to find the tax policy to maximize SWF: r(τ, z1:N ) = 1 Tτ (zi) dSWF dτ = 1 G(ui) (cid:20) ui ci dci dτ + ui zi (cid:21) dzi dτ = 0 (5) (6) On the other hand, we know each individual optimizes over zi to maximize ui, given tax policy τ (such that dyi/dzi = yi/zi), and rebate (considering sufficiently large, such that zi has negligible impact on r, i.e., r/zi 0). This gives: Finally by chain rule, we have (note that τ has non-negligible impact on r): ui ci yi zi + ui zi = 0 dci dτ = yi zi dzi dτ + yi τ + dr dτ Define gi := G(ui) ui ci and combine (6) (7) (8), we have: gi yi τ + (X gi) dr dτ = 0 By rearranging the terms and using the chain rule on the second term, we have: gi yi τ gi + τ + r zi dzi dτ = 0 or equivalently: i gi yi τ gi {z dW + dτ τ {z } dM dτ } + r zi {z dB dzi = 0 } 22 (7) (8) (9) (10) LLM Economist where dW, dM, dB correspond to social welfare effect, mechanical tax increase, and behavioral response, respectively. In cases of (9), it can be simplified to be of the form: Then, we can solve for the tax rate of form: + τ 1 τ = τ = 1 1 + α where = A/B and α = C/B. We will specify how G, α, are defined in each case. D.1 Top Income Tax Rate (Saez [60], Section 3) Consider the tax is linear above given top income z. Then we can express yi and as: yi(zi, τ ) = r(τ, z1:N ) = (zi (zi) zi (z) τ (zi z) 1 1 (zi) + i:zi<z i:ziz if zi < otherwise [T (z) + τ (zi z)] Here is the total number of the agents, () is the general tax policy for income below z, and τ is the linear tax rate above z. To solve (9), we first compute the following partial derivatives: (0 if zi < (zi z) otherwise 1 (zi z) i:ziz τ, : zi yi τ τ zi = = = 1 Also we make key assumption here: the change of τ only affects the income above z, i.e.: dzi dτ = 0, : zi < Plug into (9), we have: i:ziz gi(zi z) gi + i:ziz (zi z) + τ i:ziz dzi dτ = 0 (11) Assume that the high-income population has the same elasticity: ez = (1 τ )dzi zid(1 τ ) , : zi Then we can rewrite (11) as: i:ziz gi(zi z) gi + 1 (zi z) i:ziz τ 1 τ 1 zi = 0 i:ziz 23 LLM Economist Therefore we have: Such that: = = = 1 1 i:ziz gi(zi z) gi (zi z) i:ziz i:ziz zi = α = = = P i:ziz gi(zi z) gi i:ziz zi i:ziz(zi z) i:ziz(zi z) 1 Let be the number of the agents with income above and define their average income: 1 zM = zi i:ziz Then we have: G = i:ziz gi(zi z) 1 1 (zM z) gi α = zM zM (1 τ )dz zd(1 τ ) , ez = z Remark. Let = 0 and = ; thus, for the flat tax case, we can recover the linear income tax rate: = zM gizi gi α = 1 = (1 τ )dz zd(1 τ ) , 0 As you can see, elasticity is population dependent because depends on l, which depends on the behavioral model of the agents. D.2 Non-Linear Income Tax Rate (Saez [60], Section 4) For the non-linear tax policy (), let τz = (z) be the marginal tax rate in [z, + dz]. Since it is hard to write down the exact form of yi(zi, τ ) and r(τ, z1:N ) (as τz will affect () in [z, ]), we use the perturbation approach to compute partial derivatives. Consider small dτ > 0 reform in [z, + dz]: Fix zi: dyi = Fix z1:N : dr = Fix τz and zi: dr = 0 (zi z)dτ dzdτ 1 dzdτ if zi < if zi [z, + dz] otherwise 1 i:ziz τzdzi, : zi [z, + dz] 24 LLM Economist Therefore, the partial derivatives are: = 0 (zi z) dz if zi < if zi [z, + dz] otherwise = [1 H(z)]dz = 1 τz, : zi [z, + dz] yi τ τ zi Here H(z) is the CDF of z. Also we make key assumption here: the change of τz only affects the income in [z, + dz], i.e.: dzi dτ = 0, : zi [z, + dz] Plug into (9), we have: i:ziz gidz gi + [1 H(z)]dz + τz i:zi[z,z+dz] dzi dτ = (12) Assume that the population in [z, + dz] has the same elasticity: ez = (1 τz)dzi zid(1 τ ) , : zi [z, + dz] Then we can rewrite (12) as: i:ziz gi gi + [1 H(z)] τzez 1 τz i:zi[z,z+dz] zi dz = 0 Therefore we have: = i:ziz gi gi = [1 H(z)] 1 = i:zi[z,z+dz] zi dz = zh(z) Here h(z) is the PDF of z. Such that: i:ziz gi gi] [1 H(z)] = [P = zh(z) = α = (1 τz)dz zd(1 τ ) ez = [1 H(z)] D.3 Piecewise Linear Income Tax Rate For the piecewise linear tax policy (), let τj be the marginal tax rate in j-th bracket [zj, zj+1]. Following the previous section, we use the perturbation approach to compute partial derivatives. 25 LLM Economist Consider small dτ > 0 reform of τj: Fix zi: dyi = Fix z1:N : dr = Fix τj and zi: dr = 1 0 (zi zj)dτ (zj+1 zj)dτ 1 i:zi[zj ,zj+1] if zi < zj if zi [zj, zj+1] otherwise 1 (zi zj)dτ + (zj+1 zj)dτ i:zi>zj+ τjdzi, : zi [zj, zj+1] Therefore, the partial derivatives are: if zi < zj if zi [zj, zj+1] otherwise 0 (zi zj) (zj+1 zj) 1 i:zi[zj ,zj+1] yi τ τ zi = = = 1 τj, : zi [zj, zj+1] (zi zj) + 1 (zj+1 zj) i:zi>zj+1 Also we make key assumption here: the change of τj only affects the income in [zj, zj+1], i.e.: Plug into (9), we have: dzi dτ = 0, : zi [zj, zj+1] i:zi[zj ,zj+1] gi(zi zj) i:zi>zj+1 gi (zi zj) + gi(zj+1 zj) (zj+1 zj) + + τj i:zi[zj ,zj+1] i:zi>zj+1 i:zi[zj ,zj+1] dzi dτ = 0 (13) Assume that the population in [zj, zj+1] has the same elasticity: ej = (1 τj)dzi zid(1 τ ) , : zi [zj, zj+1] Then we can rewrite (13) as: i:zi[zj ,zj+1] gi(zi zj) + gi i:zi>zj+ gi(zj+1 zj) (zi zj) + i:zi[zj ,zj+1] i:zi>zj+ (zj+1 zj) 1 + τjej 1 τj 1 zi i:zi[zj ,zj+1] = 0 26 LLM Economist Therefore we have: = = i:zi[zj ,zj+1] gi(zi zj) + gi zj+1 zj h(z)g(z)(z zj)dz + zj+ 0 h(z)g(z)dz i:zi>zj+1 gi(zj+1 zj) h(z)g(z)(zj+1 zj)dz = (zi zj) + (zj+1 zj) i:zi[zj ,zj+1] i:zi>zj+1 = [H(zj+1) H(zj)](zM,j zj) + [1 H(zj+1)](zj+1 zj) = 1 i:zi[zj ,zj+1] zi = zj+ zj h(z)zdz Here H(z) and h(z) are the CDF and PDF of z, and zM,j is the average income in [zj, zj+1], respectively. Such that: zj+1 zj h(z)g(z)(z zj)dz + zj+1 h(z)g(z)(zj+1 zj)dz [[H(zj+1) H(zj)](zM,j zj) + [1 H(zj+1)](zj+1 zj)] h(z)zdz 0 h(z)g(z)dz zj+1 zj [H(zj+1) H(zj)](zM,j zj) + [1 H(zj+1)](zj+1 zj) = = α = (1 τj)dz zd(1 τ ) , ej = = [zj, zj+1] Remark. Let zj+1 = zj + dz, we can recover the non-linear income tax rate."
        }
    ],
    "affiliations": [
        "Princeton University",
        "Salesforce Research"
    ]
}