{
    "paper_title": "Interact, Instruct to Improve: A LLM-Driven Parallel Actor-Reasoner Framework for Enhancing Autonomous Vehicle Interactions",
    "authors": [
        "Shiyu Fang",
        "Jiaqi Liu",
        "Chengkai Xu",
        "Chen Lv",
        "Peng Hang",
        "Jian Sun"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Autonomous Vehicles (AVs) have entered the commercialization stage, but their limited ability to interact and express intentions still poses challenges in interactions with Human-driven Vehicles (HVs). Recent advances in large language models (LLMs) enable bidirectional human-machine communication, but the conflict between slow inference speed and the need for real-time decision-making challenges practical deployment. To address these issues, this paper introduces a parallel Actor-Reasoner framework designed to enable explicit bidirectional AV-HV interactions across multiple scenarios. First, by facilitating interactions between the LLM-driven Reasoner and heterogeneous simulated HVs during training, an interaction memory database, referred to as the Actor, is established. Then, by introducing the memory partition module and the two-layer memory retrieval module, the Actor's ability to handle heterogeneous HVs is significantly enhanced. Ablation studies and comparisons with other decision-making methods demonstrate that the proposed Actor-Reasoner framework significantly improves safety and efficiency. Finally, with the combination of the external Human-Machine Interface (eHMI) information derived from Reasoner's reasoning and the feasible action solutions retrieved from the Actor, the effectiveness of the proposed Actor-Reasoner is confirmed in multi-scenario field interactions. Our code is available at https://github.com/FanGShiYuu/Actor-Reasoner."
        },
        {
            "title": "Start",
            "content": "Interact, Instruct to Improve: LLM-Driven Parallel Actor-Reasoner Framework for Enhancing Autonomous Vehicle Interactions Shiyu Fang, Jiaqi Liu, Chengkai Xu, Chen Lv, Senior Member, IEEE, Peng Hang, Senior Member, IEEE, and Jian Sun 1 5 2 0 2 ] . [ 1 2 0 5 0 0 . 3 0 5 2 : r AbstractAutonomous Vehicles (AVs) have entered the commercialization stage, but their limited ability to interact and express intentions still poses challenges in interactions with Humandriven Vehicles (HVs). Recent advances in large language models (LLMs) enable bidirectional human-machine communication, but the conflict between slow inference speed and the need for real-time decision-making challenges practical deployment. To address these issues, this paper introduces parallel ActorReasoner framework designed to enable explicit bidirectional AVHV interactions across multiple scenarios. First, by facilitating interactions between the LLM-driven Reasoner and heterogeneous simulated HVs during training, an interaction memory database, referred to as the Actor, is established. Then, by introducing the memory partition module and the two-layer memory retrieval module, the Actors ability to handle heterogeneous HVs is significantly enhanced. Ablation studies and comparisons with other decision-making methods demonstrate that the proposed Actor-Reasoner framework significantly improves safety and efficiency. Finally, with the combination of the external HumanMachine Interface (eHMI) information derived from Reasoners reasoning and the feasible action solutions retrieved from the Actor, the effectiveness of the proposed Actor-Reasoner is confirmed in multi-scenario field interactions. Our code is available at https://github.com/FanGShiYuu/Actor-Reasoner. Index TermsAutonomous vehicles, Large language model, Driving interaction, external Human-Machine Interface, Memory retrieval I. INTRODUCTION autonomous driving technology continues to advance, Autonomous Vehicles (AVs) have transitioned from an initial phase focused on technological competition to new phase centered on commercial deployment. However, when interacting with heterogeneous and uncontrolled Human-driven Vehicles (HVs), AVs often display behavior that appears overly arbitrary or difficult to interpret. This highlights significant deficiencies in their ability to interact effectively and express intentions clearly in complex scenarios. This work was supported in part by the State Key Lab of Intelligent Transportation System under Project No. 2024-A002, the National Natural Science Foundation of China (52302502, 52472451), the Shanghai Scientific Innovation Foundation (No.23DZ1203400), and the Fundamental Research Funds for the Central Universities. S. Fang, J. Liu, C. Xu, P. Hang and J. Sun are with the College of Transportation, Tongji University, Shanghai 201804, China, and the State Key Lab of Intelligent Transportation System, Beijing 100088, China. (e-mail: {2111219, liujiaqi13, 2151162, hangpeng, sunjian}@tongji.edu.cn). C. Lv is with the Nanyang Technological University, 639798, Singapore. (email: lyuchen@ntu.edu.sg). Various techniques have been proposed to enhance the interaction capabilities of AV, drawing from fields such as artificial potential field theory [1, 2], game theory [3, 4], and cognitive theory [5, 6]. However, intentions in these approaches often express rely on implicit signals, such as changes in acceleration or lateral movement. While such implicit communication is common and effective among human drivers, it tends to be less effective in AV-HV interaction due to the limited interaction experience and trust that people have with AVs. To address this, some studies have introduced external Human-Machine Interface (eHMI) that use text [7], images [8], or lights [9, 10] to explicitly convey the AV intentions. Whereas, existing methods typically depend on fixed-display modes based on predefined rules, which fail to account for the heterogeneity of interaction opponents or bidirectionality of intent communication [11, 12]. Given the remarkable advancements of Large Language Models (LLMs) in natural language understanding and other domains [13, 14], they present promising avenue for enabling bidirectional intention exchange between AVs and HVs through natural language. Research has shown that LLMs can effectively support various functions in autonomous driving, such as perception[15, 16], decision-making [17, 18], and control [19]. However, current studies often focus on specific scenarios, which limits their generalizability [20]. Moreover, high-level reasoning often requires substantial computation time, and the computational resources of AVs are typically limited, making it difficult to ensure timely responses in dynamic interactions. Therefore, how to achieve real-time response with LLMs also remains to be addressed. Upon deeper analysis, we uncover three main challenges in improving the interaction and intent expression capabilities of AVs: Real-time adaptability and interpretability of decision: AVs must rapidly adapt their behavior to dynamic environments while ensuring their actions are interpretable to other road users for safe and efficient interactions. Heterogeneity and unpredictability of human drivers: AV decisions must be robust enough to handle the diverse driving styles and behaviors of HVs, ensuring effective interactions across heterogeneous HVs. Complexity and diversity of driving scenarios: versatile decision framework is needed to navigate diverse traffic environments, accommodating different conflict types and driving rules. 2 several experiments. Finally, conclusions are made in Section VI. II. LITERATURE REVIEW How to enhance the performance of AVs in complex interactive scenarios has garnered significant attention over the past few years. In this section, we summarize the advancements in improving decision-making interactivity, enhancing AVs intention visibility, and exploring the applications of LLMs in autonomous driving to uncover the key challenges that persist in driving interactions and to clarify the motivation behind this study. A. Interactive Decision-Making indicates that at AVs have now entered the commercial deployment stage both domestically and internationally. While they are capable of handling most driving scenarios, the Beijing Autonomous Vehicle Road Test Report least 36% of takeovers occur during interactions with other road users, indicating that there is still room for improvement in AV decision-making during such interactions [21]. To enhance the interaction capabilities of AVs, several approaches have been explored, including optimization-based [22], rule-based [23, 24], and learning-based [25]. Schwarting et al. [3] proposed method utilizes Social Value Orientation (SVO), which quantifies an agents level of selfishness or altruism, to improve AVs adaptability in decision-making with heterogeneous objects. Chu et al. [26] applied cognitive rules, such as the Stimulus-Organism-Response (SOR) model, to improve the human-likeness of AV decision-making. Huang et al. [27] employed hierarchical game to describe interactions in driving scenarios and further incorporated layered transformer to capture these interactions, therefore enhancing the AVs interactive capabilities. Although the above studies effectively improve AVs interaction capabilities by adjusting internal decision-making algorithms, they overlook how to accurately and effectively communicate the AVs intention to other road users after decision is made. As result, the behavior exhibited by the AV may lack sufficient interpretability, potentially leading to misunderstandings among other road users. B. Driving Intent Expression According to Californias Department of Motor Vehicles (DMV), 31% of disengagements are attributed to misinterpretation of intent among interaction participants [28]. To better convey AVs intention, existing studies focus on both implicit and explicit methods. Implicit intention expression in AVs can be divided into longitudinal and lateral components based on vehicle dynamics [29, 30]. Liu et al. [31] analyzed human drivers implicit intention expression patterns through trajectory and developed an intention-aware acceleration generation method for AVs. Ye et al. [32] proposed progressive lane-change model, where intentions are represented by lateral displacement. Results demonstrated that with multi-step implicit intention expression, lane-change success rate of AV is significantly improved. Fig. 1. Main challenges in improving the interaction and intent expression capabilities of AVs. To address the aforementioned challenges, this paper establishes an Actor-Reasoner framework driven by LLM, aimed at improving the interactive decision-making and intent expression capabilities of AVs. By leveraging interaction memories accumulated through Interactions with heterogeneous simulated vehicles during training and incorporating Instructions from HVs in real-time field testing, the performance of AVs in complex scenarios is significantly Improved. Our contributions can be summarized as follows: Inspired by the dual-system model of behavioral science theory, which includes intuitive fast reactions and deliberate slow reasoning, this study proposes an ActorReasoner framework. By integrating natural language as an intermediary and enabling the parallel operation of the Actor and Reasoner, the framework facilitates explicit bidirectional interaction between HVs and AVs. The Reasoner combines standardized definition of interaction scenario states and HV instructions as prompts. By leveraging localized LLM with Chain-of-Thought (CoT) reasoning to derive HV driving style estimations and eHMI displays, the decision interpretability and generalizations across different scenarios are improved. The Actor, segmented interaction memory database formed through interactions between the Reasoner and identifies the correheterogeneous simulated HVs. It sponding memory blocks to be retrieved based on the Reasoners inference about HV driving styles and retrieves feasible actions from the most similar past memories by combining quantitative scenario descriptions with qualitative experience. Results from ablation studies and comparisons with other methods show that the Actor-Reasoner effectively enhances safety and efficiency. By applying to multivehicle interactions and real-world field tests, demonstrates strong generalizability and practicality. To the best of our knowledge, this is the first study to use LLMs for real-time AV-HV interactions across multiple scenarios. The rest of the paper is organized as follows. Section III presents literature review of existing studies on improving the interaction and intent expression capabilities of AVs. Section III formulates the problem of our research. Section IV introduces the architecture of the proposed Actor-Reasoner framework. In Section V, we validate our framework through Additionally, explicit intention expression can be conveyed through lights, gestures, and honking [33]. Since lighting changes and honking can provoke other drivers, researchers have explored eHMIs to display intentions currently [34, 35]. Field experiments by Rettenmaier et al. [36] and Papakostopoulos et al. [37]. showed that eHMI improves AV intention recognition in ambiguous traffic situations, accelerating interaction convergence. Further studies by Dey et al. [38]. confirmed that combining implicit dynamics with explicit eHMI enables more accurate AV intention recognition by other road users. However, current research on intention expression primarily focuses on interface designs, with content typically triggered by fixed set of predefined options [7]. Such approaches to interactions in various scenarios and struggle to adapt with diverse opponents, resulting in one-way communication. Thus, bidirectional interaction framework capable of both understanding the intentions of other opponent and effectively expressing its own is still needed. C. Recent LLM Advancements in AVs Recent advancements in LLMs have endowed them with powerful ability to accurately understand human intentions and express their own ideas effectively, facilitating explicit bidirectional driving interactions. Several studies have already integrated LLMs into various subsystems of autonomous driving [39, 40, 41]. For example, Wen et al. [20] designed reflection module to help LLMs learn from historical interaction experiences, preventing repeated mistakes. Sha et al. [19] combined LLMs with Model Predictive Control (MPC) to enable AVs to interpret and reason with high-level information, thereby achieving interpretable and style-variable decisions. Fang et al. [42] developed centralized-distributed negotiation architecture based on LLMs, enabling cooperative decisionmaking among multiple AVs in mixed traffic. However, the slow inference speed of LLMs and the limited computational resources available in AV result in the aforementioned research mostly focused on simulation environments [43]. Though Cui et al. [18, 44] introduced Talk2Drive, groundbreaking implementation that deploys LLMs on realworld autonomous vehicles. Their interaction mainly involves communication between the AV and its passengers, focusing on adjusting the vehicles driving style based on human instructions after the driving process, rather than facilitating real-time interaction between human drivers and AVs. In summary, due to the limitations of LLM inference speed, there remains gap in how to leverage LLMs to enhance the interaction and intention expression capabilities of AVs in realtime field interactions. 3 Positions and speeds are assumed to be perfectly available through communication, without considering errors introduced by perception modules. Human drivers are assumed to act consistently with their stated instructions, with no deceptive behaviors. Driving intentions are simplified into two distinct categories: yielding or rushing, with the flexibility to switch between these two states. B. Formulation of Driving Interaction Driving interaction is characterized by partial observability, stochastic dynamics, and sequential decision dependency, which align closely with the core features of Partially Observable Markov Decision Process (POMDP). Therefore, we define the POMDP using the tuple MG = (S, [Oi], [Ai], P), R) to determine the optimal decision for AV during the driving interaction, where: denotes the state space, encompassing the states of all agents and the environment, Oi represents the observation space for each agent V, Ai denotes the action space for agent i, represents the transition function, capturing the probability of moving from one state to another. denotes the the immediate reward obtained by performing action in state S. At any given time step, each agent receives an individual : Oi and selects an action ai Ai observation oi : Oi Ai [0, 1]. The agent then based on policy πi transitions to new state with probability given by the state transition function P(ss, a) : A1 AN S, where is the total number of agents. Finally, to generate the optimal decision during interaction, the problem can be framed as follows: = arg max J(a) = arg max (cid:34) (cid:88) (cid:35) γtR(a, Sπ) (1) t=0 where is the optimal decision under state with policy π, and J(a) is the abbreviation for the objective function to be optimized. IV. METHODOLOGY Complex and dynamic driving interactions place high demands on the real-time performance and interpretability of AV decision-making. Additionally, the heterogeneity of agents and the diversity of scenarios further amplify these challenges. To address these issues, this paper proposes an LLM-driven Actor-Reasoner framework, which combines fast system retrieval with slow system reasoning to enable effective driving interactions tailored to heterogeneous HVs and diverse scenarios. III. PROBLEM FORMULATION A. Assumptions To simplify the problem and concentrate on the core aspects of driving interactions between AV and HV, the following assumptions are made: A. Overall Architecture Fig. 2 depicts the overall framework of the proposed ActorReasoner architecture. This architecture draws on two cognitive modes from behavioral science theory when thinking: intuitive fast reactions and deliberate slow reasoning [45, 46]. 4 Fig. 2. Overview of the proposed Actor-Reasoner architecture for driving interaction. That is, in real-world decision-making, the human brain alternates between instinctively generating quick actions based on experience and formulating well-thought-out strategies after careful consideration. Building on this concept, parallel framework comprising an LLM-based fast system and Twolayer Memory Retrieval-based (TMemR-based) slow system is designed. This architecture enables the identification of heterogeneous driver styles, the design of eHMI display information, and the rapid generation of AV decisions during driving interactions. In addition to the Actor-Reasoner architecture, the proposed framework incorporates heterogeneous driver reproduction module and an environment module. During the training phase, non-cooperative Bayesian game is utilized to model the decision-making processes of heterogeneous HVs, which are subsequently simulated for interaction within virtual simulative environment. In the testing phase, experiments are carried out in real-world test field, where HVs are manually operated by experienced drivers. Further details are provided in Section V. B. Reasoner Language, as critical medium for bidirectional communication, can serve as valuable tool for enhancing driving interaction. This subsection introduces the Reasoner, which employs CoT reasoning with LLM to derive the driving style of HVs and eHMI information of AVs. Fig. 3 illustrates an example of how the Reasoner employs CoT to complete the reasoning process. First, based on the scenario description and HV instructions, the intent of the interacting HV is estimated. Next, the drivers style is inferred and categorized as general, aggressive, or conservative. After summarizing the intent and driving style of the HV, the AVs final action is determined. Finally, eHMI information is generated based on this action to share the AVs intention with the interacting HV. This process can be formularized as Fig. 3. Illustration of the Reasoners CoT-based reasoning process. recursive problem that follows: = arg max J(a, arg max θ = arg max J(h, a) = arg max J(τ ))) J(θ, arg max τ (cid:34) (cid:88) γtR(h, S, I, aπl) (cid:35) t=0 (2) where τ is the estimated HV intention, θ is the inferred HV driving style, is the displayed eHMI information, is the instruction from HV, and πl is the pre-trained policy of LLM. By leveraging CoT reasoning to decompose the decisionmaking task into series of sub-questions, the reliability and interpretability of the responses of Reasoner in complex driving interactions are improved. Additionally, the Reasoner plays different roles depending on whether the current interaction is in the training or testing phase. Algorithm. 1 summarizes the main process in the training process. During training, the designed Reasoner interacts with the simulated heterogeneous vehicles frame by frame, storing the current scenario state and the CoT reasoning results in an external memory database. Ultimately, after filtering out behaviors that lead to inefficient or unsafe driving interactions, refined memory database is constructed. Algorithm 1: Train phase of Reasoner. Input: Vehicle states Output: Overall memory database // Infer response 1 Initialize termination condition False; 2 while not do 3 Generate prompt based on vehicle states S; Feed prompt to Reasoner to generate response; Extract HV intention τ , HV driving style θ, AV final action a, and eHMI information from response as memory m; // Store memory foreach Dθ do Filter out inefficient and unsafe experience; Add memory to the corresponding memory block Dθ m; 4 6 7 8 9 end check terminal condition ; 10 11 end However, during testing, the reasoning speed of the Reasoner often falls short of meeting the high-frequency and realtime requirements of decision-making in interactions. Therefore, in field tests, the AVs decisions are rapidly retrieved by the Actor from the memory database. In this phase, the Reasoner is solely responsible for inferring the HVs driving style and the eHMI displays information to better guide the Actor in generating experienced decisions. C. Actor Given the high real-time requirements of driving interactions for AV decision-making, this paper proposes memory retrieval-based decision-making model, termed the Actor. Drawing from the experience accumulated during the training phase, the Actor serves as lightweight reflection of the Reasoner. Based on the current scenario description and experience description, Actor retrieves the most similar past scenarios and the corresponding decision from the database, thereby rapidly providing feasible solution. Overall, the Actor consists of two main processes: Memory Partition and Two-layer Memory Retrieval. 1) Memory Partition: In real-world scenarios, human drivers exhibit heterogeneous driving behaviors. To address this variability, during the memory partition phase, the database is partitioned into several blocks based on the driving style of the interacting HV, as inferred by the Reasoner. Each block stores interaction memory specific to particular driving style. Under default conditions, the Actor retrieves similar memories from the general memory block. Once the Reasoner the Actor infers the driving style of the interacting HV, switches to the corresponding memory block to retrieve more suitable solution. This adaptive mechanism significantly enhances the AVs ability to interact with HVs of different driving styles, enabling the AV to generate responses that better align with human driver expectations across various 5 scenarios. This memory partition process can be formularized as follows: = Θ (cid:91) θ=1 Dθ, Dθ = {(S, a)f (S) = θ} (3) where is the overall memory database, which stores historical memory when Reasoner interacts with heterogeneous HVs, Dθ represents the θ memory block, containing interaction data specific to the θ driving style, and (S) is the driving style identification function of Reasoner that maps scenario to driving style category θ. Memory partitioning effectively narrows the retrieval scope, enabling the system to search only within the memory block associated with the specific driving style. This approach significantly reduces unnecessary data access and improves retrieval efficiency. 2) Two-Layer Memory Retrieval: Once the appropriate memory block is identified, the Actor will further perform quick search within that memory block to find the most similar memory to the current interaction state and adopt the corresponding AV action from that memory. Each memory consists of three types of information: scenario description Sj, experience description Ej, and corresponding action, as shown in Eq. 4. mj = (Sj, Ej, aj) , vy Sj = [xj, yj, vx Ej = [τj, θj, Ij, hj] , cj] (4) where mj represents the smallest basic memory unit in the memory block, the scenario description Sj includes the positions [xj, yj] and velocities [vx ] of the vehicles in the longitudinal and lateral directions during the driving interaction, cj is the conflict information of vehicle j, such as Time to Collision (TTC). , vy The standardized scenario description consists of vehicle state variables such as speed, position, and so on. These numerical values are stored to describe the current interaction situation. The experience description, on the other hand, records the Reasoners inference responses, which are textual information for the Actor to invoke. Given that memories consist of two types of data, twolayer memory retrieval method is proposed to search for similar memories more effectively and accurately. First, based on the scenario description, the similarity between the current scenario and the scenarios in the memory block is calculated, and set of filtered similar scenarios is established. The similarity between the scenarios is measured using the weighted Manhattan distance, which is given by: = {mj d(Sc, Sj) < ϵ} d(Sc, Sj) = (cid:88) i=1 ω Sc Sj (5) where is the filtered scenarios that are similar to the current state Sc, ϵ is the predefined threshold to determine whether states are similar, and is the distance function that describes similarity with weight ω. Furthermore, the experience descriptions composed of textual information in similar scenarios filtered by the upper layer are converted into vectors. These vectors are then compared using cosine similarity to ultimately identify the most suitable experienced action. The experience retrieval process can be formularized as: aexp = aj , mj = arg max jF ϕ(Ec) ϕ(Ej) ϕ(Ec)ϕ(Ej) (6) where is the index of the most similar experience in filtered memory, and aexp is the experienced action generated by the Actor. Algorithm. 2 summarizes the main process of the proposed Actor-Reasoner architecture for field test driving interaction. During the interaction, three threads are running in parallel: the Reasoner, the Actor, and the Environment. The Reasoner thread is responsible for inferring the HV driving style for the Actor and generating the corresponding eHMI feedback based on current vehicle states and human instructions. The Actor thread, on the other hand, filters similar scenarios based on the inferred driving style and selects the most similar memory to retrieve the AV action. Finally, the Environment thread updates the scenario and monitors the latest human instructions. This parallel execution structure ensures that the system efficiently handles complex interactions, enabling realtime, context-aware AV decision-making. V. EXPERIMENTS AND ANALYSIS To validate the effectiveness of the proposed Actor-Reasoner architecture, this section is structured into four key parts. First, several state-of-the-art (SOTA) LLMs were compared to identify the foundational model for the Reasoner. Second, ablation experiments were conducted to demonstrate the significant impact of the proposed TMemR mechanism and the incorporation of HV instructions on interaction success rates. Furthermore, the adaptability of the method in multi-vehicle environments is verified, with comparison of its safety and efficiency against other decision-making approaches. Finally, through field tests with real-time interaction with HVs, the methods applicability to actual AV systems is confirmed. A. Experiment Settings 1) Reproduction of HV: To reproduce the heterogeneous HVs for evaluating the proposed Actor-Reasoner decisionmaking framework, drivers were categorized as aggressive, conservative, or normal based on our previous research [47]. Maximum entropy inverse reinforcement learning was then employed to calibrate their driving preferences. Finally, noncooperative Bayesian model was used to simulate the decisions of heterogeneous HVs. 2) Interaction Environment: To validate the generalization capability of the proposed method across various scenarios, both simulation training and field tests were conducted in three types of environments: intersections, roundabouts, and merging areas, as shown in Fig. 2. In each case, vehicles were randomly generated at multiple entries. Additionally, during the training phase, only one AV and one HV with randomly generated driving style were included. 6 Algorithm 2: Test Phase of Actor-Reasoner Input: Vehicle states S, Overall memory database Output: Final AV action a, eHMI information // Initialization 1 3 4 5 Set HV driving style θ General; Set initial AV action IDLE; Set termination flag False; Set other variables τ, I, None; Initialize shared thread lock [S, a, τ, θ, I, h]; // Start Thread Pool // Parallel Thread 1 (Reasoner): 6 while not do Retrieve current vehicle state and human instructions from lock Sc, Ic l; Construct prompt for reasoning; Infer current HV style θc and generate eHMI information with Reasoner; Update shared thread lock θc, h; // Parallel Thread 2 (Actor): 10 11 end 12 while not do 13 Retrieve scenario description from lock Sc l; Generate experience description from lock Ec = [τc, θc, Ic, hc] l; foreach mj Dθc do Filter out similar scenarios with Eq. 5 ; Find the most similar memory with Eq. 6 ; Retrieve the corresponding action from m; Update shared thread lock a; end 20 21 end // Parallel Thread 3 (Environment): 22 while not do 23 Retrieve current vehicle state and AV action from lock Sc, l; Generate next vehicle state based on Sc, and HV action; Listen for the latest human instruction I; Update shared thread lock S, I; Check terminal condition ; 9 14 15 16 17 19 24 25 26 27 28 end B. Comparison of the Reasoners Foundational Model The rapid development of LLMs has led to the release of various models by different companies. However, due to differences in the data used for training and model architecture, their performance in handling different tasks varies. To identify the best-performing model for driving interaction tasks, we compared the success rates and single-step inference times of several models, including Llama3-7B, Qwen2-7B, Mistral-7B, Gemma-7B, and Deepseek-r1-7B, during training. successful case is defined as one where there are no collisions or deadlocks. Based on the results in Tab. II, Llama3 exhibits the highest success rate in driving interaction and has moderate inference speed. Therefore, we chose it as the foundational model for TABLE PERFORMANCE OF REASONER WITH DIFFERENT LLMS Metrics Success Rate Inference time (s) Models Llama3 98%* 2.6 Qwen2 82% 3.6 Gemma 96% 1.8 Deepseek-r1 94% 10.2 the Reasoner to build an interaction memory dataset through interacting with simulated vehicles. C. Ablation Study of the Actor-Reasoner After selecting the Llama3-7B as the foundational model for the Reasoner, ablation experiments were conducted to further compare the effectiveness of the proposed approach. These instruction, experiments included four conditions: without without memory partition, without two-layer memory retrieval, and the complete Actor-Reasoner. In the absence of HV instructions, HVs do not explicitly communicate their intentions to AVs, limiting interaction to one-way intent transmission via eHMI. When the memory partitioning module is not introduced, AVs assume HVs are homogeneous, performing retrieval only within the general memory block. Lastly, without two-layer memory retrieval, scenario descriptions and experience descriptions were concatenated, and the most similar memories were retrieved using cosine similarity. Fig. 4. Ablation Study Results on Success Rates Across Various Scenarios. Fig. 4 illustrates the models performance across different scenarios. Overall, in terms of the performance of different model designs, the absence of the memory partition module had the greatest impact on the model, with the success rate dropping by an average of 15%, and maximum decrease of 22% in the roundabout scenario. Additionally, the removal of the two-layer memory retrieval and HV instruction resulted in 10% and 5% decrease in average success rates, respectively. On the other hand, from scenario perspective, the success rate generally decreased from merging areas to roundabouts and intersections. The proposed Actor-Reasoner achieves 100% success rate in simpler scenarios like merging areas, where conflicts are relatively straightforward and priority is clear. However, in more complex scenarios, such as intersections, the success rate is lower at 94%. 7 Furthermore, in addition to the improvement in model performance, to validate the significant impact of the memory partition module in enhancing retrieval efficiency, Fig. 5 presents the retrieval time required for the database under different numbers of stored memories. As shown in the figure, the retrieval speed significantly improves after introducing the memory partition module, with an average increase of 12% and peak of 19%. This indicates that the designed memory partition module not only enhances the models success rate but also significantly boosts decision-making speed, facilitating the application of AVs in field interactions. Fig. 5. Retrieval time performance of the Actor with varying numbers of stored memories. In addition, Fig. 6 compares vehicle trajectories and decision-making processes with and without the memory partition module to visualize the performance differences among models. During the first 4 seconds of interaction, the vehicles trajectory and decision-making exhibited similar characteristics. However, from the 6s onward, the AV without the memory partition module began to decelerate. This is mainly because the interacting HDVs are already very close to the conflict point, causing the retrieved action suggestions from the entire memory database to be compromised, ultimately leading to deadlock where both vehicles stop, expecting the other to go first. In contrast, with the designed memory partition module activated, the Reasoner identified the HV as conservative type by the 4s and anticipated further yielding. At this point, Actor retrieved experienced action within the conservative memory block. Consequently, the retrieved experience action suggested maintaining the current speed, effectively preventing deadlock. D. Multi-Vehicle Environment Application and Evaluation The proposed Actor-Reasoner framework is also applicable in multi-vehicle driving interaction environments. To validate its performance, we selected the intersection scenario and compared the Actor-Reasoner with several other AV decisionmaking methods, including optimization-based methods (NonCooperative Game [48]), rule-based methods (P-IDM [49]), learning-based methods (PPO [50]), and LLM-based methods (Dilu [20]) in terms of safety and efficiency. The intersection scenario involves one AV and three HVs with randomly assigned driving styles. Fig. 7 shows the PET distribution of different methods, where the numbers on the left represent the proportion of 8 Fig. 6. Comparison of vehicle trajectories and decision-making processes with and without the memory partition module. Tab. II further compares the differences in travel velocity across methods. Based on our observations of trajectories, we found that Dilus average travel speed, which is nearly identical to the speed limit, results from its overly aggressive behavior. In almost all cases, Dilu-driven AVs continuously accelerate until reaching the desired speed, forcing surrounding HVs to brake and avoid collisions. This is the primary reason for its significantly higher rate of dangerous interactions compared to other methods. Therefore, we believe that its travel velocity does not effectively reflect its efficiency, and we excluded Dilus performance from the analysis. According to Tab. II, after excluding Dilu, the proposed Actor-Reasoner achieves the best average velocity at 4 m/s. Additionally, while PPOs performance in safety is slightly worse than that of the proposed Actor-Reasoner, it can still maintain minimum travel velocity of 2.7 m/s, indicating its ability to safeguard efficiency. This is an area where our algorithm can be further improved. Finally, PIDM and NonCooperative Game performed the worst in terms of efficiency, with average travel velocities of 2.9 m/s and 2.5 m/s, respectively. This low efficiency may stem from their excessive emphasis on safety. Overall, through the analysis of PET and travel velocity, the proposed Actor-Reasoner demonstrates the ability to maintain high efficiency while ensuring safety, proving its superiority in multi-vehicle interactions. Fig. 8 illustrates the vehicle trajectories and decisionmaking process during multi-vehicle interactions. Compared to interacting with single HV, in the presence of multiple potential interacting agents, the AV will first identify the HV with the highest risk based on the TTC from the scenario description and regard it as the interacting opponent. In the first 5s of the interaction, HV1 with higher speed becomes the primary focus of the AV. The Reasoner recognizes it as an aggressive style, and the Actor retrieves deceleration action from the corresponding memory block to prevent collision. Once HV1 passes the conflict point, the AV shifts its focus to Fig. 7. PET distribution under different decision-making methods. TABLE II EFFICIENCY PERFORMANCE UNDER DIFFERENT DECISION-MAKING METHODS Methods PIDM Non-Cooperative Game PPO Dilu Actor-Reasoner (Ours) Travel Velocity (m/s) Average Max Min 0.12 0.18 2.7 4.2 0.27 2.9 2.5 3.9 4.9 4.0* 5 5 4.7 5 5 dangerous interaction events among all interactions. An interaction is considered dangerous if the distance between two vehicles leaving the conflict zone is less than the length of the vehicle. Based on the results from Fig.7, the proposed ActorReasoner framework performs the best, with dangerous interaction rate of only 1%. Additionally, the rule-based PIDM and optimization-based Non-Cooperative Game performed second, with rates of 3% and 2%, respectively. The primary reason is that the two methods respectively rely on spatial planning and constraints to ensure that vehicles do not enter the conflict zone at the same time. Finally, Dilu performed the worst in interactions with an 11% dangerous rate, which could be attributed to the method originally designed for highway scenarios, where the intensity and patterns of conflicts differ from those in intersections and roundabouts. 9 Fig. 8. Vehicle trajectories and decision-making process during multi-vehicle interactions. HV3. Given that HV3 is stationary and shows yielding intent, the Reasoner identifies it as conservative style and retrieves an acceleration action to avoid deadlock. Actor-Reasoner framework, the AV determined the required acceleration and generated corresponding throttle and brake control commands. Overall, in multi-vehicle interaction scenarios, the proposed Actor-Reasoner framework effectively recognizes the driving styles of different HVs and retrieves appropriate decisions to prevent deadlock and collisions. E. Field Testing and Real AV Application Finally, field test of the proposed Actor-Reasoner was conducted at Tongji Small Town (TJST) in Shanghai, China, including three scenarios: roundabouts, and merging areas, as shown in Fig. 9. intersections, To intuitively demonstrate the performance of the ActorReasoner framework in real-world interactions, field test case is shown in Fig. 10. In this scenario, the HV entered the intersection earlier and had higher initial speed. Consequently, the Reasoner classified the HV as an aggressive driver, prompting the eHMI to display will be Slower to convey the AVs intention. Based on this assessment, the Actor retrieved deceleration action to allow the HV to pass through the intersection first. However, the HV driver did not follow the AVs guidance and instead chose to stop at 15s, verbally stating, will be slower. After converting this speech input to text and feeding it into both the Reasoner and the Actor, the Reasoner first interpreted the HVs intent and, after reasoning, decided to display will be Faster on the eHMI to ensure efficient interaction. The Actor then generated an acceleration decision in real-time, ultimately allowing the AV to pass through the intersection first. Therefore, the proposed ActorReasoner framework has been validated in real-world driving interactions for enhancing both AV interaction and intent expression capabilities. Additionally, we visualized the models performance in other scenarios, data and videos are available here 1. through the field test, Fig. 9. Field test scenarios of the proposed Actor-Reasoner at Tongji Small Town. During each interaction, human drivers were asked to express their intentions via voice, which were continuously monitored by the AVs OBU. The HV instructions were then converted into textual information, serving as the current experience description. Additionally, real-time HV data, such as position information, was transmitted to the AV through vehicle-to-vehicle communication, enabling the formation of the scenario description. Based on the proposed VI. CONCLUSION The lack of interaction and intent expression capabilities is key challenge currently faced by AVs on open roads. Recent advancements in LLMs offer new approach to AV decision-making. To address the conflict between the slow inference speed of LLMs and the high real-time interaction 1https://fangshiyuu.github.io/Actor-Reasoner/ 10 Fig. 10. Vehicle trajectories and decision-making process during field interactions. requirements of driving, this paper draws on behavioral sciences fast and slow decision-making systems and proposes an Actor-Reasoner framework. By enabling the LLM-based Reasoner to interact with heterogeneous background vehicles during simulation training, an interaction memory, known as the Actor, is constructed. In field tests, with human driver instructions, the Actor and Reasoner operate in parallel to generate AV decisions and eHMI display information, respectively. Through ablation studies and comparisons with other decision-making methods, the Actor-Reasoner framework has demonstrated superior safety and efficiency. Additionally, the method has been applied to multi-vehicle interactions and real-world field tests, proving its strong generalizability and practicality. However, there is still room for further research in this area. Currently, our study primarily focuses on AV decision-making and intent expression. Given the gradual nature of human cognition, future work will explore how to further optimize the content displayed through eHMI, making it easier for human drivers to accept guidance from AVs. Additionally, we aim to investigate the potential for transferring the proposed framework to the collaborative driving area, extending the focus from optimizing individual behavior to enhancing overall system performance. REFERENCES [1] L. Li, J. Gan, Z. Yi, X. Qu, and B. Ran, Risk perception and the warning strategy based on safety potential field theory, Accident Analysis and Prevention, vol. 148, p. 105805, 2020. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0001457520316250 [2] J. Wang, J. Wu, X. Zheng, D. Ni, and K. Li, Driving safety field theory modeling and its application in pre-collision warning system, Transportation Research Part C: Emerging Technologies, vol. 72, pp. 306324, 2016. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S0968090X16301887 [3] W. Schwarting, A. Pierson, J. Alonso-Mora, S. Karaman, and D. Rus, Social behavior for autonomous vehicles, Proceedings of the National Academy of Sciences, vol. 116, no. 50, pp. 24 97224 978, 2019. [4] C. F. Camerer and E. Fehr, When does economic man dominate social behavior? science, vol. 311, no. 5757, pp. 4752, 2006. [5] S. Xie, Y. Yang, M. Fu, and J. Zheng, cognition-inspired human-like decision-making method for automated vehicles, IEEE Transactions on Intelligent Transportation Systems, 2024. [6] A. Zgonnikov, D. Abbink, and G. Markkula, Should stay or should go? cognitive modeling of left-turn gap acceptance decisions in human drivers, Human factors, vol. 66, no. 5, pp. 13991413, 2024. [7] P. Bazilinskyy, D. Dodou, and J. De Winter, Survey on ehmi concepts: The effect of text, color, and perspective, Transportation research part F: traffic psychology and behaviour, vol. 67, pp. 175194, 2019. [8] X. Zhao, X. Li, A. Rakotonirainy, S. Bourgeois-Bougrine, D. Gruyer, and P. Delhomme, The invisible gorilladuring pedestrian-av interaction: Effects of secondary tasks on pedestrians reaction to ehmis, Accident Analysis & Prevention, vol. 192, p. 107246, 2023. [9] J. Bindschadel, I. Krems, and A. Kiesel, Active vehicle pitch motion for communication in automated driving, Transportation research part F: traffic psychology and behaviour, vol. 87, pp. 279294, 2022. [10] J. Bindschadel, P. Weimann, and A. Kiesel, Using ehmi, acoustic signal, and pitch motion to communicate the intention of automated vehicles to pedestrians: wizard of oz study, Transportation research part F: traffic psychology and behaviour, vol. 97, pp. 5972, 2023. [11] Y. Li, H. Liu, and B. Deml, Hmi-based communication methods for negotiation between manually driven vehicle driver and an autonomous vehicle in an ambiguous traffic scenario, in 2022 IEEE/SICE International Symposium on System Integration (SII), 2022, pp. 244249. [12] Z. Tan, N. Dai, Y. Su, R. Zhang, Y. Li, D. Wu, and S. Li, Humanmachine interaction in intelligent and connected vehicles: review of status quo, issues, and opportunities, IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 9, pp. 13 95413 975, 2022. [13] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, Language models are unsupervised multitask learners, 2019. [Online]. Available: https://api.semanticscholar.org/CorpusID: [14] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi, Q. Le, and D. Zhou, Chain-of-thought prompting elicits reasoning in large language models, 2023. [Online]. Available: https://arxiv.org/abs/2201.11903 [15] Z. Guo, A. Lykov, Z. Yagudin, M. Konenkov, and D. Tsetserukou, Co-driver: Vlm-based autonomous driving assistant with human-like behavior and understanding for complex road scenes, arXiv preprint arXiv:2405.05885, 2024. [16] A. Gopalkrishnan, R. Greer, and M. Trivedi, Multi-frame, lightweight & efficient vision-language models for question answering in autonomous driving, arXiv preprint arXiv:2403.19838, 2024. [17] D. Fu, X. Li, L. Wen, M. Dou, P. Cai, B. Shi, and Y. Qiao, Drive like human: Rethinking autonomous driving with large language models, 2023. [Online]. Available: https://arxiv.org/abs/2307.07162 [18] C. Cui, Z. Yang, Y. Zhou, Y. Ma, J. Lu, L. Li, Y. Chen, J. Panchal, and Z. Wang, Personalized autonomous driving with large language models: Field experiments, 2024. [Online]. Available: https://arxiv.org/abs/2312. [19] H. Sha, Y. Mu, Y. Jiang, L. Chen, C. Xu, P. Luo, S. E. Li, M. Tomizuka, W. Zhan, and M. Ding, Languagempc: Large language models as decision makers for autonomous driving, 2023. [Online]. Available: https://arxiv.org/abs/2310.03026 [20] L. Wen, D. Fu, X. Li, X. Cai, T. Ma, P. Cai, M. Dou, B. Shi, L. He, and Y. Qiao, Dilu: knowledge-driven approach to autonomous [Online]. Available: driving with large language models, 2024. https://arxiv.org/abs/2309.16292 [21] MZONE, Beijing autonomous vehicle road test report 2022, 2022, http://www.mzone.site/index.php/index/index/cid/2/sid/21.html. [22] S. Fang, P. Hang, and J. Sun, real-time cooperative driving framework for un-signalized intersection, in 2023 7th CAA International Conference on Vehicular Control and Intelligence (CVCI). IEEE, 2023, pp. 16. [23] Y. Xing, C. Lv, D. Cao, and P. Hang, Toward human-vehicle collaboration: Review and perspectives on human-centered collaborative automated driving, Transportation research part C: emerging technologies, vol. 128, p. 103199, 2021. [24] R. Kaufman, J. Costa, and E. Kimani, Effects of multimodal explanations for autonomous driving on driving performance, cognitive load, expertise, confidence, and trust, Scientific reports, vol. 14, no. 1, p. 13061, 2024. [25] D. Zhou, P. Hang, and J. Sun, Reasoning graph-based reinforcement learning to cooperate mixed connected and autonomous traffic at unsignalized intersections, Transportation Research Part C: Emerging Technologies, vol. 167, p. 104807, 2024. [26] P. Chu, Y. Yu, J. Yang, and C. Huang, Understanding the mechanism behind young drivers distracted driving behaviour based on sor theory, Journal of Transportation Safety & Security, vol. 14, no. 10, pp. 1655 1673, 2022. [27] Z. Huang, H. Liu, and C. Lv, Gameformer: Game-theoretic modeling and learning of transformer-based interactive prediction and planning for autonomous driving, in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 39033913. [28] C. D. of Motor Vehicles, Autonomous vehicle disengagement reports 2019, 2019. and K. Bengler, automated vehicle movements Communication [29] M. Rettenmaier, S. Dinkel, via motion suitability of to negotiate the right of way in road bottleneck scenarios, Applied Ergonomics, vol. 95, p. 103438, 2021. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/S0003687021000855 [30] R. Yuan, M. Abdel-Aty, X. Gu, O. Zheng, and Q. Xiang, unified modeling framework for lane change intention recognition and vehicle status prediction, Physica A: Statistical Mechanics and its Applications, vol. 632, p. 129332, 2023. [31] J. Liu, X. Qi, Y. Ni, J. Sun, and P. Hang, Human-like implicit intention expression for autonomous driving motion planning based on learning human intenion priors, IEEE Transactions on Intelligent Vehicles, vol. PP, pp. 116, 01 2024. [32] Y. Ye, Y. Ni, and J. Sun, Defining and modeling active-responsive merging behavior at high-density expressway on-ramp bottlenecks, China J. Highw. Transp, vol. 35, pp. 278290, 2022. [33] Y. M. Lee, R. Madigan, O. Giles, L. Garach-Morcillo, G. Markkula, C. Fox, F. Camara, M. Rothmueller, S. A. Vendelbo-Larsen, P. H. Rasmussen et al., Road users rarely use explicit communication when interacting in todays traffic: implications for automated vehicles, Cognition, Technology & Work, vol. 23, pp. 367380, 2021. [34] C. S. Dula and E. S. Geller, Risky, aggressive, or emotional driving: Addressing the need for consistent communication in research, Journal of safety research, vol. 34, no. 5, pp. 559566, 2003. [35] A. R. McGarva and M. Steiner, Provoked driver aggression and status: field study, Transportation research part F: traffic psychology and behaviour, vol. 3, no. 3, pp. 167179, 2000. [36] M. Rettenmaier, D. Albers, and K. Bengler, After you?! use of external human-machine interfaces in road bottleneck scenarios, Transportation Research Part F: Traffic Psychology and Behaviour, vol. 70, pp. 175190, 2020. [Online]. Available: https://www. sciencedirect.com/science/article/pii/S1369847819308757 [37] V. Papakostopoulos, D. Nathanael, E. Portouli, and A. Amditis, Effect of external hmi for automated vehicles (avs) on drivers ability to infer 11 the av motion intention: field experiment, Transportation Research Part F: Traffic Psychology and Behaviour, vol. 82, pp. 3242, 2021. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S1369847821001686 [38] D. Dey, A. Matviienko, M. Berger, B. Pfleging, M. Martens, and J. Terken, Communicating the intention of an automated vehicle to pedestrians: The contributions of ehmi and vehicle behavior, it - Information Technology, vol. 63, no. 2, pp. 123141, 2021. [Online]. Available: https://doi.org/10.1515/itit-2020- [39] C. Chang, S. Wang, J. Zhang, J. Ge, and L. Li, Llmscenario: Large language model driven scenario generation, IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 54, no. 11, pp. 6581 6594, 2024. [40] S. Zhang, W. Huang, Z. Gao, H. Chen, and C. Lv, Wisead: Knowledge augmented end-to-end autonomous driving with vision-language model, 2024. [Online]. Available: https://arxiv.org/abs/2412.09951 [41] J. Ge, C. Chang, J. Zhang, L. Li, X. Na, Y. Lin, L. Li, and F.-Y. Wang, Llm-based operating systems for automated vehicles: new perspective, IEEE Transactions on Intelligent Vehicles, 2024. [42] S. Fang, J. Liu, M. Ding, Y. Cui, C. Lv, P. Hang, and J. Sun, Towards interactive and learnable cooperative driving automation: large language model-driven decision-making framework, 2024. [Online]. Available: https://arxiv.org/abs/2409.12812 [43] C. Xu, J. Liu, S. Fang, Y. Cui, D. Chen, P. Hang, and J. Sun, Tell-drive: Enhancing autonomous driving with teacher learning, 2025. [Online]. Available: llm-guided deep reinforcement https://arxiv.org/abs/2502.01387 [44] C. Cui, Y. Ma, X. Cao, W. Ye, and Z. Wang, Receive, reason, and react: Drive as you say, with large language models in autonomous vehicles, IEEE Intelligent Transportation Systems Magazine, vol. 16, no. 4, pp. 8194, 2024. [45] K. Christakopoulou, S. Mourad, and M. Mataric, Agents thinking fast and slow: talker-reasoner architecture, 2024. [Online]. Available: https://arxiv.org/abs/2410.08328 [46] D. Kahneman, Thinking, fast and slow, Farrar, Straus and Giroux, 2011. [47] S. Fang, P. Hang, C. Wei, Y. Xing, and J. Sun, Cooperative driving of connected autonomous vehicles in heterogeneous mixed traffic: game theoretic approach, IEEE Transactions on Intelligent Vehicles, 2024. [48] X. Zhao, M. Wang, S. Fang, and J. Sun, Towards active motion planning in interactive driving scenarios: generic utility term of interaction activeness, in 2023 IEEE Intelligent Vehicles Symposium (IV), 2023, pp. 16. [49] Z. Deng, W. Hu, T. Huang, C. Sun, J. Zhong, and A. Khajepour, Social predictive intelligent driver model for autonomous driving simulation, Automotive Innovation, pp. 112, 2025. [50] Y. Gu, Y. Cheng, C. L. P. Chen, and X. Wang, Proximal policy optimization with policy feedback, IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 52, no. 7, pp. 46004610, 2022. Shiyu Fang received the B.S. degree in transportation engineering from Jilin University, Changchun, China. He is currently pursuing the Ph.D. degree with the Department of Traffic Engineering, Tongji University, Shanghai, China. His main research interests include decision making and motion planning for autonomous vehicles. 12 Jian Sun received the Ph.D. degree from Tongji University in 2006. Subsequently, he was at Tongji University as Lecturer, and then promoted to the position as Professor in 2011, where he is currently Professor with the College of Transportation Engineering and the Dean of the Department of Traffic Engineering. His main research interests include traffic flow theory, traffic simulation, connected vehicle-infrastructure system, and intelligent transportation systems. Jiaqi Liu received the B.S. degree in transportation engineering from Tongji University, where he is currently pursing the M.S. degree. His research interests include decision-making of autonomous vehicles and data-driven traffic simulation. He won the Best Paper Award of CUMCM in 2020. He is Visiting Researcher with the Department of Mechanical Engineering, University of California, Berkeley. Chengkai Xu is an undergraduate student at Tongji University, and will continue his studies at Tongji University as masters student. His research interests include decision-making processes, reinforcement learning techniques, and the application of foundation models to enhance autonomous driving systems. Chen Lv received his Ph.D. degree from the De partment of Automotive Engineering, Tsinghua University, China, in 2016. From 2014 to 2015, he was joint Ph.D. researcher in the EECS Dept., University of California, Berkeley. He is currently an Associate Professor at Nanyang Technology University, Singapore. His research focuses on advanced vehicles and human-machine systems, where he has con tributed over 100 papers and obtained 12 granted patents in China. Dr. Lv serves as an Associate Editor for IEEE TITS, IEEE T-VT, IEEE T-IV, and Guest Editor for IEEE ITS Magazine, IEEE-ASME TMECH, Applied Energy, etc. He received many awards and honors, selectively including the Highly Commended Paper Award of IMechE UK in 2012, Japan NSK Outstanding Mechanical Engineering Paper Award in 2014, Tsinghua University Outstanding Doctoral Thesis Award in 2016, IEEE IV Best Workshop/Special Session Paper Award in 2018, Automotive Innovation Best Paper Award in 2020, the winner of Waymo Open Dataset Challenges at CVPR 2021, and Machines Young Investigator Award in 2022 Peng Hang is Research Professor at the Department of Traffic Engineering, Tongji University, Shanghai, China. He received the Ph.D. degree with the School of Automotive Studies, Tongji University, Shanghai, China, in 2019. He was Visiting Researcher with the Department of Electrical and Computer Engineering, National University of Singapore, Singapore, in 2018. From 2020 to 2022, he served as Research Fellow with the School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore. His research interests include vehicle dynamics and control, decision making, motion planning and motion control for autonomous vehicles. He serves as an Associate Editor of IEEE Transactions on Vehicular Technology, Journal of Field Robotics, IET Smart Cities, and SAE International Journal of Vehicle Dynamics, Stability, and NVH."
        }
    ],
    "affiliations": [
        "College of Transportation, Tongji University, Shanghai 201804, China",
        "Nanyang Technological University, 639798, Singapore",
        "State Key Lab of Intelligent Transportation System, Beijing 100088, China"
    ]
}