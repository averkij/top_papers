{
    "paper_title": "Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics",
    "authors": [
        "Yuchen Yang",
        "Linfeng Dong",
        "Wei Wang",
        "Zhihang Zhong",
        "Xiao Sun"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "In 3D human pose and shape estimation, SMPLify remains a robust baseline that solves inverse kinematics (IK) through iterative optimization. However, its high computational cost limits its practicality. Recent advances across domains have shown that replacing iterative optimization with data-driven neural networks can achieve significant runtime improvements without sacrificing accuracy. Motivated by this trend, we propose Learnable SMPLify, a neural framework that replaces the iterative fitting process in SMPLify with a single-pass regression model. The design of our framework targets two core challenges in neural IK: data construction and generalization. To enable effective training, we propose a temporal sampling strategy that constructs initialization-target pairs from sequential frames. To improve generalization across diverse motions and unseen poses, we propose a human-centric normalization scheme and residual learning to narrow the solution space. Learnable SMPLify supports both sequential inference and plug-in post-processing to refine existing image-based estimators. Extensive experiments demonstrate that our method establishes itself as a practical and simple baseline: it achieves nearly 200x faster runtime compared to SMPLify, generalizes well to unseen 3DPW and RICH, and operates in a model-agnostic manner when used as a plug-in tool on LucidAction. The code is available at https://github.com/Charrrrrlie/Learnable-SMPLify."
        },
        {
            "title": "Start",
            "content": "Learnable SMPLify: Neural Solution for Optimization-Free Human Pose Inverse Kinematics Yuchen Yang* 1,2 1Fudan University Linfeng Dong3,2 Wei Wang2 2Shanghai Artificial Intelligence Laboratory Zhihang Zhong2 Xiao Sun(cid:12) 2 3Zhejiang University 5 2 0 A 9 1 ] . [ 1 2 6 5 3 1 . 8 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "In 3D human pose and shape estimation, SMPLify remains robust baseline that solves inverse kinematics (IK) through iterative optimization. However, its high computational cost limits its practicality. Recent advances across domains have shown that replacing iterative optimization with data-driven neural networks can achieve significant runtime improvements without sacrificing accuracy. Motivated by this trend, we propose Learnable SMPLify, neural framework that replaces the iterative fitting process in SMPLify with single-pass regression model. The design of our framework targets two core challenges in neural IK: data construction and generalization. To enable effective training, we propose temporal sampling strategy that constructs initializationtarget pairs from sequential frames. To improve generalization across diverse motions and unseen poses, we propose human-centric normalization scheme and residual learning to narrow the solution space. Learnable SMPLify supports both sequential inference and plug-in post-processing to refine existing image-based estimators. Extensive experiments demonstrate that our method establishes itself as practical and simple baseline: it achieves nearly 200 faster runtime compared to SMPLify, generalizes well to unseen 3DPW and RICH, and operates in model-agnostic manner when used as plug-in tool on LucidAction. The code is available at https://github.com/Charrrrrlie/ Learnable-SMPLify. 1. Introduction The replacement of traditional iterative optimization with data-driven and learned inference via neural networks has become unifying trend across many domains. For example, VGGT [53] in multi-view stereo, GAIL [14] in control, and even NeuroSAT [45] for satisfiability solving. In 3D human pose and shape estimation, classical optimization- *Work performed during his internship at Shanghai Artificial Intelligence Laboratory. Figure 1. Illustration of SMPLify and motivation of our work. IK and FK denote inverse kinematics and forward kinematics, respectively. Opt. refers to optimized items. The high computational cost of the iterative process and the reliance on human priors motivate the development of data-driven and non-iterative approach. based approaches such as SMPLify(-X) [6, 41] continue to serve as robust baselines and are still widely employed in downstream tasks such as 3D reconstruction and animation [38, 42, 61]. This enduring reliance on SMPLify(- X) motivates the need for research to enhance its performance, running in parallel with image-based regression methods [5, 8, 12, 22, 55]. As illustrated in Fig. 1, SMPLify addresses the ill-posed inverse kinematics (IK) problem of fitting the SMPL model to provided joints, aiming to minimize joint reconstruction error while enforcing human body priors. Being fundamentally optimization-based, SMPLify suffers from two functional limitations. Firstly, the performance heavily depends on initialization quality. To improve this, existing methods leverage rich image cues by training neural networks to produce better initialization [13, 21, 27], and by incorporating various auxiliary constraints such as silhouettes and part segmentations [16, 29, 43, 57], thereby stabilizing optimization. Additionally, SMPLify relies on timeconsuming iterative procedures. In response, hybrid IK methods attempt to obtain closed-form solution from images by estimating elements like twist angles [30, 31] or vertex maps [47]. However, solving the core SMPLify inverse kinematics problem directly from joints, without auxiliary image cues, remains underexplored. Song et al. [48] employ gradient information to guide IK but still require iterative procedures. KAMA [17] derives an analytical solution by ignoring twist 1 rotation ambiguity, which compromises accuracy. No existing method provides solution that is both accurate and entirely free of optimization. In this work, we propose Learnable SMPLify, neural inverse kinematics framework that estimates SMPL parameters from joints through single-time regression. Our framework aligns the overall setting of SMPLify but without iterative optimization, while maintaining high accuracy and anatomical validity by data-driven way. The detailed design of Learnable SMPLify specifically targets two core challenges in neural inverse kinematics. 1) Proper initialization-target pair data for training. Initialization requires being sufficiently close to the target to ensure convergence in the ill-posed IK space, yet not too close to avoid trivial learning. To balance this, we exploit the spatial continuity of human motion and construct initializationtarget pairs from adjacent video frames. By varying the temporal interval between them, the model learns to transfer initial SMPL parameters toward the target across spectrum of realistic and plausible data. 2) Generalization ability. Unlike optimization-based IK solvers that adapt to each instance through iterative fitting, neural IK models must generalize across diverse motions and unseen poses. To stabilize inference, we design human-centric coordinate system to normalize initial and target joints. This normalization eliminates variations in global orientation and translation. Furthermore, instead of directly regressing absolute SMPL parameters, the network predicts the residuals between initialization and target, which constrains the solution space and further enhances generalization. To sum up, Learnable SMPLify collects initial and target joints from the adjacent video sequences and normalizes them in the human-centric coordinate system. The normalized joints are passed to GCN-based joint feature extractor [59], which encodes motion-aware features. These features are then used to regress the residual SMPL parameters between the initialization and the target, producing the final results in single forward pass. Trained on AMASS [36] and evaluated on large-scale AMASS, 3DPW [52], and RICH [15] datasets, the proposed Learnable SMPLify framework consistently outperforms existing methods. Compared to the classical SMPLify, Learnable SMPLify is nearly 200 times faster and achieves over 5mm PVE improvement across all datasets. The results validate the effectiveness of our approach and are coherent with the accurate and optimization-free motivation. Furthermore, we demonstrate the utility of Learnable SMPLify as plug-in post-processing module by refining predictions from existing image-based human pose and shape estimation methods [46, 60] on the challenging LucidAction [11] dataset. Our contributions are summarized into threefold: We propose Learnable SMPLify, neural inverse kinematics framework that regresses SMPL parameters from joints in single forward pass, removing the need for iterative optimization while maintaining high accuracy. We introduce human-centric normalization scheme and training strategy based on temporally adjacent frames, enabling effective residual learning in the ill-posed inverse kinematics setting. We demonstrate that Learnable SMPLify serves as simple yet strong baseline across multiple datasets, highlighting its practicality and generalization capability for future research in neural inverse kinematics. 2. Related Work 2.1. General Inverse Kinematics The inverse kinematics (IK) problem has been extensively studied in robotics, computer graphics, and related fields. Classical numerical solvers [4, 7, 24, 56] address the IK problem via iterative optimization, which is conceptually straightforward but often computationally expensive. To improve efficiency, heuristic methods [3, 35, 44] offer faster solutions by involving local adjustment and approximation, rather than global optimization. More recently, data-driven approaches have gained popularity, where neural networks are trained to directly predict inverse solutions [2, 10, 64]. Several neural network-based methods are tailored to introduce domain knowledge for particular tasks, such as human motion [50], and pose editing [18, 39, 51]. The task-specific nature highlights the effectiveness of vertical domain methods, motivating the exploration of learnable inverse kinematics formulations for human pose and shape estimation. 2.2. Human Pose and Shape Inverse Kinematics We review human pose and shape (HPS) estimation methods from the perspective of IK, with focus on approaches that utilize parametric models of SMPL(-X). Traditionally, IK refers to computing joint angles given the desired position or orientation of specific body parts. In HPS, inverse kinematics extends to regression-based methods that predict SMPL parameters from images, where inferring pose and shape from observations inverts the SMPL forward process. large number of methods [13, 22, 25, 26, 28] fall into this category. To handle the diversity of in-the-wild images, recent approaches adopt larger neural networks trained on increasingly diverse datasets [5, 8, 12, 32, 55]. Meanwhile, PyMAF [63] and ReFit [54] introduce iterative feedback mechanisms to refine predictions, incorporating the strengths of optimization-based HPS methods. Optimization-based methods follow the conventional IK paradigm. With the proposal of SMPL(-X) model, SMPLify(-X) [6, 41] formulates HPS as an optimization problem that iteratively fits SMPL(-X) model to the given keypoints. The objective function typically combines joint 2 fitting error with regularization terms based on pose and shape priors from kinematic rules and simple generative models [23, 37]. Although SMPLify(-X) serves as robust baseline in practical applications, it is sensitive to initialization and suffers from slow convergence due to iterative optimization. To stabilize optimization, existing methods leverage regression networks to produce better initialization [13, 21, 27], incorporate auxiliary constraints [16, 29, 43, 49, 57], and extend to complex application scenarios [40, 62]. To accelerate the iteration process, Li et al. [30, 31] estimate twist angles from images to enable closed-form solution, while PLIKS [47] introduces pseudo-linear solver by predicting UV maps. The setting of KAMA [17] and Song et al. [48] is most closely related to our work. Both aim to accelerate the SMPLify IK process by operating directly on joint positions, without relying on additional visual input. Song et al. employ neural networks to incorporate the SMPL parameter gradient using fixed number of parameter updates during the forward process. KAMA derives an analytical solution by applying approximation rules based on the kinematic tree. However, Song et al. still depend on the iterative process, while KAMA achieves efficiency at the cost of reduced accuracy. In this paper, we accelerate the SMPLify optimization by replacing its iterative process with single forward pass through neural network. Our method eliminates the need for costly optimization while maintaining high accuracy, enabled by carefully designed initialization and normalization strategies. 3. Method 3.1. Preliminaries The SMPL body model [33], denoted as M, parameterizes the 3D human mesh consisting of = 6890 vertices using pose parameters θ R243 and shape parameters β R10. The forward kinematics (FK) of SMPL is to deform the mesh template based on given pose and shape parameters: = M(θ, β, ξ), (1) where ξ indicates the pose and shape blend parameters of SMPL model M. SMPL is defined in canonical space and can be transformed into world coordinates using translation . The joint locations can be computed from the mesh vertices using fixed linear regressor Jtr: = JtrV. (2) The conventional inverse kinematics (IK) of SMPL refers to estimating pose and shape parameters from joint positions with initialization: θ, β = IK(J, θinit, βinit). (3) In the original SMPLify [6], the initialization is set to Tpose, where both θinit and βinit are zero vectors. However, due to information loss in the forward kinematics, the inverse kinematics problem is severely ill-posed when learning from suboptimal initialization. Prior studies [13, 21, 27] demonstrate that improved initialization significantly enhances the performance of SMPLify. 3.2. Learnable SMPLify 3.2.1 Problem Formulation Similar to prior optimization-based methods [17, 30, 31], we introduce Learnable SMPLify, an optimization-free neural solver that improves SMPLify with 3D joint locations Jtarget as input. As defined in Eq. (3), our problem setup follows the conventional SMPL IK problem: the target joints Jtarget and initial parameters (θinit, βinit) are given to predict SMPL parameters (θpred, βpred). Since human shape parameters can be inferred from skeletal structure [17], we focus our efforts on regressing the pose parameters [30, 31]. For simplicity, we assume that the initial and target shape parameters are considered identical: β βinit βtarget. (4) Its practical implementation is provided in Sec. 3.2.3. Formally, as illustrated in Fig. 2, Learnable SMPLify mimics the IK process through learnable function F: θpred = F(Jtarget, θinit, β). (5) 3.2.2 Framework Preprocessing. Given the initial parameters, we obtain the initial joints Jinit via SMPL forward kinematic process, defined in Eq. (1) and Eq. (2): Jinit = JtrM(θinit, β, ξ). (6) Mindset. With both the initial and target joint positions available, we reinterpret the IK problem as motion transition task. Specifically, regression from initial SMPL parameters to target ones can be guided by modeling the motion transition from initial joints to target joints. Therefore, Learnable SMPLify framework becomes straightforward: feature extraction module that encodes information from joint positions and regressor that predicts the residual between initial and target SMPL parameters. Human-centric Coordinate. Unlike optimization-based IK solvers that perform fitting per instance, Learnable SMPLify must generalize across diverse joint inputs, varying in action, scale, and orientation. To ease the data diversity issue, we propose human-centric normalization strategy before joint feature extraction. 3 Figure 2. Overview of Learnable SMPLify. The framework first constructs human-centric coordinate system from the initial joints and uses it to normalize both the initial and target joints into the same reference frame. Then, neural solver, comprised of joint feature extractor and regressor, takes the normalized joints along with the initial SMPL parameters to predict residual pose parameters. The normalization strategy constructs an orthonormal frame from joint locations, reducing the models solution space by eliminating variations in global orientation and translation. Specifically, for given skeleton of joints J, we define its human-centric coordinate system as follows: First, we centralize the skeleton by translating all joints so that the pelvis lies at the origin. Let Jp denote the pelvis joint, and define the translation: = Jp, and = T. (7) Let Jlh, Jrh, Jt denote left hip, right hip, and thorax of the centralized joints c, respectively. We then define two direction vectors t1 and t2: t1 = Jlh Jrh, (8) t2 = Jp Jt. From these, we construct an orthonormal basis as follows. The y-axis is defined as the unit vector along t1: (9) = t1 t1 , (10) The z-axis is the component of t2 orthogonal to with normalization: = t2 (t2 y) t2 (t2 y) . (11) The x-axis is given by the normalized cross product to ensure right-handed coordinate system: = y y . (12) Finally, we assemble the rotation matrix R33 that transforms vectors from the world coordinate system into this human-centric frame: = (cid:2)x z(cid:3)T . (13) 4 With the human-centric coordinate frame defined above, we now apply it to transform joint positions for SMPL IK. Using the rotation matrix Rinit and translation vector Tinit of the initialization joints Jinit, we perform rigid transformation, yielding the joint locations in human-centric coordinates of initialization, denoted as Jinit,init. For the target joints, we adopt the same coordinate system defined by Jinit and transform the target joints Jtarget accordingly to obtain Jtarget,init. Instead of converting Jtarget to its own human-centeric coordinates, i.e. Jtarget,target, the current process maintains relative motion information from Jinit to Jtarget, facilitating meaningful feature extraction for target SMPL parameter regression. Neural Solver. To regress target SMPL parameters, we employ joint feature extractor and regressor. Note that we focus on the general formulation of neural IK frameworks. Therefore, we leverage existing well-structured networks to achieve our goals, rather than design new architectures. Architecture details are provided in the Appendix A. Specifically, the joint feature extractor ϕ is built on an action recognition network [59], which effectively extracts human motion information from sequential joint inputs. The input to ϕ is the concatenation of the initial and target joints in the shared human-centric coordinate system: = ϕ(Jinit,init Jtarget,init), (14) where RD denotes the resulting joint feature vector in dimension and indicates concatenation. Then we further concatenate the initial SMPL parameters to supply joint features and input the combined representation into lightweight MLP-based regressor ψ [54]. Since inverse kinematics is inherently ill-posed, directly regressing the absolute target SMPL parameters often leads to suboptimal solutions. To mitigate this, we let the regressor ψ to predict the residual pose parameters with respect to the initialization: θ = ψ(F θinit β). (15) Practically, we represent the pose parameters using rotation matrices [8, 12, 54] for numerical continuity. The final prediction is obtained via rotation composition in SO(3): θpred = θ θinit. (16) 3.2.3 Data Preparation and Inference Protocols Up to this point, we have introduced how the Learnable SMPLify framework estimates the target pose parameter through single-time regression. Next, we present the construction of training data and the implementation of inference in our proposed framework. Training. As learning-based method, key challenge is constructing meaningful paired data for training. In Learnable SMPLify, this corresponds to selecting appropriate initialization-target pairs. The initialization must be close enough to the target to allow convergence in the ill-posed inverse kinematics problem, yet sufficiently distant to prevent the model from exploiting trivial solutions. Therefore, by exploiting the continuity of human motion, we construct paired training data by sampling adjacent frames from motion sequences. Given motion sequence represented by SMPL parameters as {(θ0, β), (θ1, β), ..., (θT 1, β)}, we uniformly sample training pairs at time index with temporal offset as follows: θinit = θts, and θtarget = θt. (17) To improve generalization and robustness, we vary the sampling interval during training within range [1, S], and apply data augmentation by swapping the initialization and target samples. Based on these sample pairs, we supervise the model using constraints at three levels: pose parameters θ, regressed keypoints J, and human mesh vertices . The corresponding losses are defined as: Lpose = arccos( r(θT targetθpred 1) 2 ), (18) Lkp = Jtarget Jpred2, Lmesh = Vtarget Vpred2. Here, Lpose is geodesic loss on SO(3), while the others use L2 loss. (19) (20) The total loss is defined as: = λposeLpose + λkpLkp + λmeshLmesh. (21) The weights λpose, λkp, λmesh are hyperparameters that balance the influence of each term. 5 Inference. Learnable SMPLify supports two inference protocols: Plug-in Post-processing. Following the strategy used in SPIN [27], any SMPL prediction can be treated as an initialization. The model then refines it by regressing residual SMPL parameters in one-step forward. Sequential Inference. For sequential data, given the first frame SMPL parameters, the model predicts the parameters for each subsequent frame by using the previous frames output as initialization. The sequential inference protocol reflects the core motivation behind our training data construction: modeling motion transitions from plausible initializations. This enables robust application to sequential inputs by leveraging initializations that are naturally provided by temporal consistency. Additionally, since the subject shape remains constant across frames, we simplify the pipeline by focusing on pose inverse kinematics, as formulated in Eq. (4). 4. Experiments 4.1. Datasets and Metrics We split the AMASS [36] dataset into training and testing sets with 7 : 3 ratio, and use the training split to train Learnable SMPLify. For evaluation, we perform both indomain testing on AMASS and cross-domain evaluation on 3DPW [52] and RICH [15]. Additionally, we further evaluate the plug-in post-processing ability on LucidAction [11], dataset of gymnastic scenes with challenging actions. Dataset information is detailed in Appendix B.1. For evaluation metrics, we adopt Per-Vertex Error (PVE), which computes the mean L2 distance between predicted and ground-truth SMPL vertices, to assess the human pose and shape estimation accuracy. We additionally report PA-PVE, which applies Procrustes Alignment before error computation to account for global misalignment. 4.2. Implementation Details The temporal sampling range is set to 9. The loss balance weights λpose, λkp and λmesh are set to 1.0, 5.0, and 1.0, respectively. We use the OpenPose [9] SMPL regressor to generate 25 keypoints for the framework input. The model is optimized using AdamW [34] with batch size of 128 for 100 epochs. The learning rate is initialized at 104 and decayed via cosine annealing. 4.3. Evaluation on Sampled Frames To evaluate inverse kinematics performance, we follow the data construction procedure outlined in Sec. 3.2.3, which samples both initialization and target poses in sequence with temporally offset defined by s. Specifically, the initialization pose is given by θts, and the target pose by θt. As baselines, we include: Table 1. Evaluations on s-step prior frame initialization. PVEs are in mm. Runtime is in seconds. Lower is better for all metrics. Method = 1 = 5 = 1 = 5 = 1 = AMASS 3DPW RICH PVE PA-PVE Runtime PVE PA-PVE Runtime PVE PA-PVE PVE PA-PVE PVE PA-PVE PVE PA-PVE Direct Copy SMPLify [6] Ours 21.36 18. 3.23 9.72 18.50 2.23 - 11.73 0.06 98.72 19. 9.74 44.02 18.56 7.00 - 12.52 0.06 24.51 17. 4.35 9.38 17.08 2.66 106.85 18.31 13.09 40.84 18. 8.69 31.08 20.75 12.57 13.04 21.19 5.87 95.82 21. 42.14 21.45 20.92 11.96 Table 2. Evaluations on sequential inference. PVEs are in mm. Lower is better for all metrics. Method AMASS 3DPW RICH PVE PA-PVE PVE PA-PVE PVE PA-PVE Song et al. [48] KAMA [17] SMPLify [6] 21.61 - 28.00 13.29 - 26.40 104.56 47.40 26. 51.29 - 24.71 115.13 - 38.95 58.11 - 31.64 Ours 17.22 15. 21.23 19.34 27.51 24.02 Direct Copy, which simply uses the initialization as the prediction to highlight discrepancies between the initial and target poses. SMPLify [6], an optimization-based method that refines SMPL parameters from initialization. In Tab. 1, we report performance on the in-domain AMASS dataset. Despite the close proximity between initialization and target poses, our method significantly outperforms the Direct Copy baseline, indicating that performance gains do not merely result from initialization similarity. Compared to SMPLify, our approach effectively utilizes initialization and captures fine-grained differences (s = 1), leading to superior performance. Moreover, our method achieves fast runtime by eliminating the costly iterative procedures. Specifically, it offers close to 200 speed-up compared to SMPLify with only 6.1M trainable parameters, making it suitable for real-time applications. Unlike SMPLify, whose runtime increases from 11.73s at = 1 to 12.52s at = 5, our methods inference time is invariant to initialization quality, maintaining both speed and accuracy consistently. We further assess generalization ability, using the crossdomain 3DPW and RICH datasets. Even without being trained on these datasets, our method consistently outperforms SMPLify across varying initialization conditions. 4.4. Evaluation on Sequential Inference Building on the frame-based evaluation, we further assess performance in the practical setting of sequential inference. As introduced in Sec. 3.2.3, we initialize the sequence using the first frame and iteratively predict each subsequent frame based on the preceding prediction. We include extra baselines for comparison: Song et al. [48], learning-based approach that iteratively Figure 3. Qualitative evaluation on sequential inference. Predicted (white) and ground-truth meshes (red) are overlaid for visual comparison. Each row displays samples from single sequence. regresses poses from canonical T-pose. We implement this under the same training scheme as our method. However, due to its network design, it cannot incorporate initialization directly into its predictions. KAMA [17], derives an analytical solution based on the human kinematic tree. Since KAMA is not open-sourced, we only include its reported performance as reference. As discussed in Sec. 2.2, our work focuses on solving the IK problem based on joint positions. Therefore, we do not include image-based regression methods as baselines for comparison, as they operate under distinct settings. As shown in Tab. 2, the proposed Learnable SMPLify consistently outperforms all baselines across evaluated datasets, achieving 17.22mm, 21.23mm, and 27.51mm PVE on AMASS, 3DPW, and RICH datasets. These results demonstrate robust consistency and generalization of our approach in real application. Notably, unlike Song et al., our method can effectively leverage initialization, yielding significant performance gains on previously unseen data in 3DPW and RICH datasets. Similar to SMPLify, our method must address error accumulation arising from initialization based on preceding predictions during sequential inference. The superior performance demonstrates our models ability to produce plausible results while remaining robust to noise, 6 Figure 4. Qualitative results of plug-in post-processing. The left and right columns present the results based on GVHMR and SMPLest-X, respectively. Significant errors are marked with red circles. Faces are mosaicked for ethical considerations. Best viewed when zoomed in. even without relying on the iterative optimization used in SMPLify to correct predictions. vides realistic evaluation setting involving complex, crossdomain motion sequences with challenging poses. Qualitative results in Fig. 3 further confirm the robustness of our method to obtain plausible predictions during sequential inference. As shown, the per-vertex error of approximately 20mm reported in Tab. 2 translates to only minor deviations at the scale of the human body with limited perceptual impact. Combined with fast inference speed, the high visual accuracy of our method underscores its practicality for real-world motion capture applications. 4.5. Evaluation on Plug-in Post-Processing As described in Sec. 3.2.3, aside from sequential inference, the proposed Learnable SMPLify also supports plugin post-processing. To evaluate its effectiveness in this setting, we adopt two state-of-the-art image-based human pose and shape estimation methods as baselines: GVHMR [46], which provides estimation by leveraging multiple 2D cues, including YOLO bonding boxes [20], 2D poses from ViTPose [58], and image features from HMR2.0 [12]. SMPLest-X [60], which associates 10 million training instances from diverse data sources for scaling. We conduct experiments on the LucidAction [11] dataset, which is not included in the training sets of most existing human pose and shape estimation methods. This proAs shown in Fig. 4, the baseline methods exhibit noticeable errors, especially in end-effectors such as hands and feet, largely due to error accumulation propagated through the kinematic tree. Our method takes the baseline predictions as initialization and effectively refines the results. Notably, its performance across both baselines unveils its model-agnostic nature, enabled by generalization from temporal sequence training. For the LucidAction dataset, joint labels are obtained using 2D estimator [19] combined with multi-view triangulation, which introduces certain level of noise. Our approachs robustness to such noise makes our approach practical and lightweight plug-in post-processing solution that seamlessly leverages the rapid progress in image-based human pose and shape estimation. 4.6. Ablation Study To evaluate the effectiveness of the proposed strategies in Learnable SMPLify, we conduct ablation studies in this section. For efficient evaluation, all models are trained using 50% of the AMASS training split. We evaluate them on the AMASS and 3DPW test splits to represent in-domain and cross-domain scenarios, respectively. We adopt the experiment setting on sampled frames described in Sec. 4.3 to assess the fundamental inverse kinematics capability under 7 Table 3. Ablation study on framework components with s-step prior frame initialization. PVEs are in mm. Lower is better for all metrics. Exp. Setting AMASS 3DPW = 1 = = 1 = 5 PVE PA-PVE PVE PA-PVE PVE PA-PVE PVE PA-PVE 1 2 - w/o Human-centric Normalization Direct Prediction Learnable SMPLify 10.28 35.95 3.28 5.41 22.26 2.28 22.47 35.95 9.80 13.08 22.26 7.06 59.63 276.28 4.40 13.93 102.48 2. 115.75 276.28 13.23 41.17 102.48 8.80 Table 4. Ablation study on temporal sampling range with s-step prior frame initialization. PVEs are in mm. Lower is better for all metrics. Setting = 1 = = 1 = 5 AMASS 3DPW PVE PA-PVE PVE PA-PVE PVE PA-PVE PVE PA-PVE = 3 = 5 = 7 = 9 = 11 3.30 3.49 3.81 3.28 3.91 2.17 2.35 2.41 2.28 2.57 15.04 12.70 12.76 9.80 12.15 8.96 8.52 8.20 7.06 8.12 4.56 4.59 4.99 4.40 5. 2.72 2.80 2.88 2.69 3.04 19.41 16.94 16.54 13.23 16.41 11.13 10.43 10.00 8.80 9.96 varying initialization conditions. 4.6.1 Effectiveness of the Framework As shown in Tab. 3, we focus our analysis on two key components of the proposed framework: Human-centric Normalization, which aims to improve generalization across domains, and residual learning in the Neural Solver, which is designed to effectively leverage initialization for further generalization improvement in inverse kinematics. In Exp.1, we replace the proposed Human-centric Normalization with simple baseline that applies location and scale normalization to both the initialization and target joints. While this baseline achieves reasonable performance on the AMASS dataset, its effectiveness drops significantly on the 3DPW dataset, with the PVE increasing to 115.75mm under the = 5 setting. This degradation highlights the domain shift that remains unresolved by naive normalization. In contrast, Learnable SMPLify generalizes well to 3DPW, demonstrating that the proposed Human-centric Normalization effectively mitigates crossdomain discrepancies. In Exp.2, we evaluate the Direct Prediction baseline by using fixed T-pose as initialization, replacing the s-step prior frame. As result, its performance remains unchanged across different values of s. However, this direct prediction strategy results in inferior performance, particularly on the unseen 3DPW dataset, where the PVE increases to 276mm. This degradation is primarily due to the ambiguity introduced when estimating target poses from fixed T-pose, which reflects the ill-posed nature of human pose inverse kinematics. In comparison, Learnable SMPLify eases this issue by utilizing temporally consistent initialization, highlighting the effectiveness of the residual learning design in the proposed Neural Solver. 4.6."
        },
        {
            "title": "Impact of Temporal Sampling Range",
            "content": "As shown in Tab. 4, we analyze the impact of temporal sample range [1, S], which is implemented in Eq. (17) to introduce diversity and robustness into the training process. By varying the temporal sampling range {3, 5, 7, 9, 11}, we observe that Learnable SMPLify achieves the best overall performance on both the AMASS and 3DPW datasets when = 9. For smaller sampling range, the model learns to handle small discrepancies between the initialization and target poses effectively. For example, the = 3 setting performs well under the = 1 condition but struggles when faced with larger temporal gaps such as = 5. In contrast, larger sampling range leads to the opposite effect. The = 9 configuration offers balanced trade-off, providing an optimal point to allow the model to generalize across both shortand long-term transitions. 5. Conclusion In this paper, we propose Learnable SMPLify, neural solution for optimization-free human pose inverse kinematics. By replacing the iterative optimization in traditional SMPLify with neural solver, our approach significantly accelerates inference speed while maintaining high accuracy. To enhance generalization ability, we introduce human-centric normalization strategy on both initial and target joints. Training pairs are constructed by sampling from temporal sequences, enabling the model to tackle the ill-posed inverse kinematics via residual learning. Benefited from these designs, Learnable SMPLify produces consistent and plausible predictions in sequential inference and exhibits model-agnostic nature in plug-in post-processing for refining methods. Extensive experiments across multiple benchmarks validate the effectiveness of Learnable SMPLify as practical and simple baseline for human pose inverse kinematics."
        },
        {
            "title": "References",
            "content": "[1] Easymocap - make human motion capture easier. Github, 2021. 1 [2] Lynton Ardizzone, Jakob Kruse, Sebastian Wirkert, Daniel Rahner, Eric Pellegrini, Ralf Klessen, Lena MaierHein, Carsten Rother, and Ullrich Kothe. Analyzing inverse problems with invertible neural networks. arXiv preprint arXiv:1808.04730, 2018. 2 [3] Andreas Aristidou and Joan Lasenby. Fabrik: fast, iterative solver for the inverse kinematics problem. Graphical Models, 73(5):243260, 2011. 2 [4] Aldo Balestrino, Giuseppe De Maria, and Lorenzo Sciavicco. Robust control of robotic manipulators. IFAC Proceedings Volumes, 17(2):24352440, 1984. 2 [5] Fabien Baradel, Matthieu Armando, Salma Galaaoui, Romain Bregier, Philippe Weinzaepfel, Gregory Rogez, and Thomas Lucas. Multi-hmr: Multi-person whole-body human mesh recovery in single shot. In European Conference on Computer Vision, pages 202218. Springer, 2024. 1, 2 [6] Federica Bogo, Angjoo Kanazawa, Christoph Lassner, Peter Gehler, Javier Romero, and Michael Black. Keep it smpl: Automatic estimation of 3d human pose and shape from single image. In European conference on computer vision, pages 561578. Springer, 2016. 1, 2, 3, [7] Samuel Buss and Jin-Su Kim. Selectively damped least squares for inverse kinematics. Journal of Graphics tools, 10(3):3749, 2005. 2 [8] Zhongang Cai, Wanqi Yin, Ailing Zeng, Chen Wei, Qingping Sun, Wang Yanjun, Hui En Pang, Haiyi Mei, Mingyuan Zhang, Lei Zhang, et al. Smpler-x: Scaling up expressive human pose and shape estimation. Advances in Neural Information Processing Systems, 36:1145411468, 2023. 1, 2, 5 [9] Z. Cao, G. Hidalgo Martinez, T. Simon, S. Wei, and Y. A. Sheikh. Openpose: Realtime multi-person 2d pose estimation using part affinity fields. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2019. 5 [10] Akos Csiszar, Jan Eilers, and Alexander Verl. On solving the inverse kinematics problem using neural networks. In 2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP), pages 16, 2017. 2 [11] Linfeng Dong, Wei Wang, Yu Qiao, and Xiao Sun. Lucidaction: hierarchical and multi-model dataset for comprehensive action quality assessment. Advances in Neural Information Processing Systems, 37:9646896482, 2024. 2, 5, 7 [12] Shubham Goel, Georgios Pavlakos, Jathushan Rajasegaran, Angjoo Kanazawa, and Jitendra Malik. Humans in 4d: ReIn constructing and tracking humans with transformers. Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1478314794, 2023. 1, 2, 5, 7 [13] Riza Alp Guler and Iasonas Kokkinos. Holopose: Holistic 3d human reconstruction in-the-wild. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1088410894, 2019. 1, 2, 3 [14] Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning. In Advances in neural information processing systems, 2016. 1 [15] Chun-Hao Huang, Hongwei Yi, Markus Hoschle, Matvey Safroshkin, Tsvetelina Alexiadis, Senya Polikovsky, Daniel Scharstein, and Michael Black. Capturing and inferring In Proceedings of dense full-body human-scene contact. the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1327413285, 2022. 2, 5 [16] Yinghao Huang, Federica Bogo, Christoph Lassner, Angjoo Kanazawa, Peter Gehler, Javier Romero, Ijaz Akhter, and Michael Black. Towards accurate marker-less human shape and pose estimation over time. In 2017 international conference on 3D vision (3DV), pages 421430. IEEE, 2017. 1, 3 [17] Umar Iqbal, Kevin Xie, Yunrong Guo, Jan Kautz, and Pavlo Molchanov. Kama: 3d keypoint aware body mesh articulation. In 2021 International Conference on 3D Vision (3DV), pages 689699. IEEE, 2021. 1, 3, 6 [18] Jiaxi Jiang, Paul Streli, Xuejing Luo, Christoph Gebhardt, and Christian Holz. Manikin: biomechanically accurate neural inverse kinematics for human motion estimation. In European Conference on Computer Vision, pages 128146. Springer, 2024. 2 [19] Tao Jiang, Peng Lu, Li Zhang, Ningsheng Ma, Rui Han, Chengqi Lyu, Yining Li, and Kai Chen. Rtmpose: Realtime multi-person pose estimation based on mmpose. arXiv preprint arXiv:2303.07399, 2023. [20] Glenn Jocher, Ayush Chaurasia, and Jing Qiu. Ultralytics YOLOv8. https://github.com/ultralytics/ ultralytics, 2023. 7 [21] Hanbyul Joo, Natalia Neverova, and Andrea Vedaldi. Exemplar fine-tuning for 3d human model fitting towards inthe-wild 3d human pose estimation. In 2021 International Conference on 3D Vision (3DV), pages 4252. IEEE, 2021. 1, 3 [22] Angjoo Kanazawa, Michael Black, David Jacobs, and Jitendra Malik. End-to-end recovery of human shape and pose. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 71227131, 2018. 1, 2 [23] Diederik Kingma, Max Welling, et al. Auto-encoding variational bayes, 2013. 3 [24] Charles Klein and Ching-Hsiang Huang. Review of pseudoinverse control for use with kinematically redundant manipulators. IEEE Transactions on Systems, Man, and Cybernetics, (2):245250, 2012. 2 [25] Muhammed Kocabas, Nikos Athanasiou, and Michael Black. Vibe: Video inference for human body pose and In Proceedings of the IEEE/CVF conshape estimation. ference on computer vision and pattern recognition, pages 52535263, 2020. [26] Muhammed Kocabas, Chun-Hao Huang, Otmar Hilliges, and Michael Black. Pare: Part attention regressor for 3d In Proceedings of the IEEE/CVF human body estimation. international conference on computer vision, pages 11127 11137, 2021. 2 [27] Nikos Kolotouros, Georgios Pavlakos, Michael Black, and Kostas Daniilidis. Learning to reconstruct 3d human pose 9 and shape via model-fitting in the loop. In Proceedings of the IEEE/CVF international conference on computer vision, pages 22522261, 2019. 1, 3, 5 [28] Nikos Kolotouros, Georgios Pavlakos, and Kostas Daniilidis. Convolutional mesh regression for single-image human shape reconstruction. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 45014510, 2019. 2 [29] Christoph Lassner, Javier Romero, Martin Kiefel, Federica Bogo, Michael Black, and Peter Gehler. Unite the people: Closing the loop between 3d and 2d human representations. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 60506059, 2017. 1, 3 [30] Jiefeng Li, Chao Xu, Zhicun Chen, Siyuan Bian, Lixin Yang, and Cewu Lu. Hybrik: hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 33833393, 2021. 1, [31] Jiefeng Li, Siyuan Bian, Qi Liu, Jiasheng Tang, Fan Wang, and Cewu Lu. Niki: Neural inverse kinematics with invertible neural networks for 3d human pose and shape estimation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1293312942, 2023. 1, 3 [32] Jing Lin, Ailing Zeng, Haoqian Wang, Lei Zhang, and Yu Li. One-stage 3d whole-body mesh recovery with component In Proceedings of the IEEE/CVF Conaware transformer. ference on Computer Vision and Pattern Recognition, pages 2115921168, 2023. 2 [33] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael Black. Smpl: skinned multiperson linear model. ACM Transactions on Graphics (TOG), 34(6):116, 2015. 3 [34] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017. 5 [35] David Luenberger, Yinyu Ye, et al. Linear and nonlinear programming. Springer, 1984. 2 [36] Naureen Mahmood, Nima Ghorbani, Nikolaus Troje, Gerard Pons-Moll, and Michael Black. Amass: Archive In Proceedings of of motion capture as surface shapes. the IEEE/CVF international conference on computer vision, pages 54425451, 2019. 2, 5 [37] Geoffrey McLachlan and David Peel. Finite mixture models. John Wiley & Sons, 2000. 3 [38] Muyao Niu, Mingdeng Cao, Yifan Zhan, Qingtian Zhu, Mingze Ma, Jiancheng Zhao, Yanhong Zeng, Zhihang Zhong, Xiao Sun, and Yinqiang Zheng. Anicrafter: Customizing realistic human-centric animation via avatarbackground conditioning in video diffusion models. arXiv preprint arXiv:2505.20255, 2025. 1 [39] Boris Oreshkin, Florent Bocquelet, Felix Harvey, Bay Raitt, and Dominic Laflamme. Protores: Proto-residual network for pose authoring via learned inverse kinematics. arXiv preprint arXiv:2106.01981, 2021. [41] Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed AA Osman, Dimitrios Tzionas, and Expressive body capture: 3d hands, Michael Black. In Proceedings of face, and body from single image. the IEEE/CVF conference on computer vision and pattern recognition, pages 1097510985, 2019. 1, 2 [42] Lingteng Qiu, Xiaodong Gu, Peihao Li, Qi Zuo, Weichao Shen, Junfei Zhang, Kejie Qiu, Weihao Yuan, Guanying Chen, Zilong Dong, et al. Lhm: Large animatable human In reconstruction model from single image in seconds. Proceedings of the IEEE/CVF International Conference on Computer Vision, 2025. 1 [43] Davis Rempe, Tolga Birdal, Aaron Hertzmann, Jimei Yang, Srinath Sridhar, and Leonidas Guibas. Humor: 3d human motion model for robust pose estimation. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1148811499, 2021. 1, 3 [44] Nizar Rokbani, Alicia Casals, and Adel Alimi. Ik-fa, new heuristic inverse kinematics solver using firefly algoIn Computational intelligence applications in modrithm. eling and control, pages 369395. Springer, 2014. 2 [45] Daniel Selsam, Matthew Lamm, Benedikt Bunz, Percy Liang, Leonardo de Moura, and David Dill. Learning sat solver from single-bit supervision. In International Conference on Learning Representations, 2019. 1 [46] Zehong Shen, Huaijin Pi, Yan Xia, Zhi Cen, Sida Peng, Zechen Hu, Hujun Bao, Ruizhen Hu, and Xiaowei Zhou. World-grounded human motion recovery via gravity-view coordinates. In SIGGRAPH Asia 2024 Conference Papers, pages 111, 2024. 2, 7 [47] Karthik Shetty, Annette Birkhold, Srikrishna Jaganathan, Norbert Strobel, Markus Kowarschik, Andreas Maier, and Bernhard Egger. Pliks: pseudo-linear inverse kinematic In Proceedings of solver for 3d human body estimation. the IEEE/CVF conference on computer vision and pattern recognition, pages 574584, 2023. 1, [48] Jie Song, Xu Chen, and Otmar Hilliges. Human body model fitting by learned gradient descent. In European Conference on Computer Vision, pages 744760. Springer, 2020. 1, 3, 6 [49] Garvita Tiwari, Dimitrije Antic, Jan Eric Lenssen, Nikolaos Sarafianos, Tony Tung, and Gerard Pons-Moll. Pose-ndf: Modeling human pose manifolds with neural distance fields. In European Conference on Computer Vision, pages 572 589. Springer, 2022. 3 [50] Ruben Villegas, Jimei Yang, Duygu Ceylan, and Honglak Lee. Neural kinematic networks for unsupervised motion In Proceedings of the IEEE conference on retargetting. computer vision and pattern recognition, pages 86398648, 2018. 2 [51] Vikram Voleti, Boris Oreshkin, Florent Bocquelet, Felix Harvey, Louis-Simon Menard, and Christopher Pal. Smpl-ik: Learned morphology-aware inverse kinematics for ai driven artistic workflows. In SIGGRAPH Asia 2022 Technical Communications, pages 17, 2022. 2 [40] Priyanka Patel and Michael Black. Camerahmr: Aligning people with perspective. arXiv preprint arXiv:2411.08128, 2024. 3 [52] Timo Von Marcard, Roberto Henschel, Michael Black, Bodo Rosenhahn, and Gerard Pons-Moll. Recovering accurate 3d human pose in the wild using imus and moving In Proceedings of the IEEE/CVF conference on networks. computer vision and pattern recognition, pages 57455753, 2019. 2 camera. In Proceedings of the European conference on computer vision (ECCV), pages 601617, 2018. 2, 5 [53] Jianyuan Wang, Minghao Chen, Nikita Karaev, Andrea Vedaldi, Christian Rupprecht, and David Novotny. Vggt: Visual geometry grounded transformer. In Proceedings of the Computer Vision and Pattern Recognition Conference, pages 52945306, 2025. 1 [54] Yufu Wang and Kostas Daniilidis. Refit: Recurrent fitting network for 3d human recovery. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1464414654, 2023. 2, 4, 5, 1 [55] Yufu Wang, Yu Sun, Priyanka Patel, Kostas Daniilidis, Michael Black, and Muhammed Kocabas. Prompthmr: In Proceedings of the Promptable human mesh recovery. Computer Vision and Pattern Recognition Conference, pages 11481159, 2025. 1, 2 [56] William Wolovich and Howard Elliott. computational In The 23rd IEEE Contechnique for inverse kinematics. ference on Decision and Control, pages 13591363. IEEE, 1984. [57] Donglai Xiang, Hanbyul Joo, and Yaser Sheikh. Monocular total capture: Posing face, body, and hands in the wild. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1096510974, 2019. 1, 3 [58] Yufei Xu, Jing Zhang, Qiming Zhang, and Dacheng Tao. Vitpose: Simple vision transformer baselines for human pose estimation. Advances in neural information processing systems, 35:3857138584, 2022. 7 [59] Sijie Yan, Yuanjun Xiong, and Dahua Lin. Spatial temporal graph convolutional networks for skeleton-based action recognition. In Proceedings of the AAAI conference on artificial intelligence, 2018. 2, 4, 1 [60] Wanqi Yin, Zhongang Cai, Ruisi Wang, Ailing Zeng, Chen Wei, Qingping Sun, Haiyi Mei, Yanjun Wang, Hui En Pang, Mingyuan Zhang, Lei Zhang, Chen Change Loy, Atsushi Yamashita, Lei Yang, and Ziwei Liu. Smplest-x: Ultimate scaling for expressive human pose and shape estimation. arXiv preprint arXiv:2501.09782, 2025. 2, 7 [61] Zhengming Yu, Wei Cheng, Xian Liu, Wayne Wu, and Kwan-Yee Lin. Monohuman: Animatable human neuIn Proceedings of the ral field from monocular video. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1694316953, 2023. 1 [62] Andrei Zanfir, Elisabeta Marinoiu, and Cristian Sminchisescu. Monocular 3d pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 21482157, 2018. [63] Hongwen Zhang, Yating Tian, Xinchi Zhou, Wanli Ouyang, Yebin Liu, Limin Wang, and Zhenan Sun. Pymaf: 3d human pose and shape regression with pyramidal mesh alignment In Proceedings of the IEEE/CVF internafeedback loop. tional conference on computer vision, pages 1144611456, 2021. 2 [64] Yi Zhou, Connelly Barnes, Jingwan Lu, Jimei Yang, and Hao Li. On the continuity of rotation representations in neural 11 Learnable SMPLify: Neural Solution for Optimization-Free Human Pose Inverse Kinematics"
        },
        {
            "title": "Supplementary Material",
            "content": "A. Neural Solver Architecture The neural solver in Learnable SMPLify comprises feature extractor and regressor. The feature extractor ϕ builds on the classic skeletonbased action recognition method ST-GCN [59]. It processes input joint sequences Jseq RT D, where the concatenated initial and target joints in Eq. (14) form = 2, = 25, = 3 sequence, facilitating straightforward implementation. The extractor consists of 10 blocks of graph convolution and temporal convolution layers, each with residual connections. It raises features from 3 to 256, then applies pooling over the temporal and joint dimensions to yield compact joint-level representation R256. Next, we concatenate the initial pose and beta parameters, resulting in an enriched feature vector of dimension R335. For regressor ψ, we follow the design of ReFit [54]. two-layer MLP mapping the refined feature into RM 256, where denotes the number of SMPL pose parameters. Finally, separate linear layers independently predict each pose parameter in 6D rotation representation, corresponding to the first two columns of rotation matrix. B. Experiment B.1. Dataset Details AMASS. AMASS associates various optical marker-based motion capture datasets to construct more than 40 hours motion data, forming rich foundation for our neural inverse kinematics solver. We split the dataset into train and test sets at the granularity of sequence with 7 : 3 ratio. To avoid repetitive initial poses, the first and last 10% of data in each sequence are removed. All sequences are sampled at 30 fps to ensure that our training strategy captures similar discrepancies between initialization and target. During training and testing, we sample initialization and target pairs at intervals of 10 across all sequences. Finally, the data process yields 298, 496 initialization-target pairs for training and 127, 926 pairs for testing. 3DPW. 3DPW collects human motion data in the wild using IMUs and moving camera. It provides SMPL annotations in high quality that are widely used for evaluation in human pose and shape estimation. We only use the official test split to evaluate our model. It yields 35, 145 initialization-target pairs across 37 sequences for testing. RICH. RICH contains motion data of real human-scene interactions, both indoors and outdoors, captured using multi-view motion capture system with 3D scans. The dataset contains high-quality SMPL-X annotations, which we convert to SMPL format for evaluation. We use 298, 638 initialization-target pairs in 52 sequences of the official test split to evaluate our model. LucidAction. LucidAction provides 259 types of actions from 8 diverse gymnastics events across 4 distinct curriculum level, from beginner to expert difficulty. It provides 3D human pose annotations captured in multi-view optical motion capture systems. We adopt 21 types of actions from the second difficult level in mens/womens floor exercise events for demonstration. B.2. Experiment Details Sequential Inference. As we focus on pose inverse kinematics and with the assumption that the subjects shape is invariant, we use the ground truth shape parameter for all baselines during evaluation to ensure fair comparison. All initial and target joints are taken from the ground truth. This ensures an accurate evaluation of the algorithms ability to fit the SMPL pose to target data, while avoiding the influence of estimation noise. Later, the Plug-in PostProcessing step demonstrates practical scenario where estimated joints are applied. For SMPLify, we employ the implementation from ZJU-Mocap [1], which supports optimizing SMPL parameters on 3D joints. We initialize both SMPLify and our Learnable SMPLify with the ground-truth pose of the first frame, and apply frame-by-frame inference for the full sequence. For Song et al.s we apply the 3D joints as input and train their model using the same AMASS dataset split as ours to ensure fairness in evaluation. For KAMA, we select the reported performance under the setting that uses ground truth joints to ensure alignment with our evaluation protocol. Plug-in Post-Processing. Although GVHMR is worldaligned method, we observe scale estimation errors when comparing its outputs with the 3D joints provided in LucidAction. To address this, we use the results in the estimated camera coordinate system and transform them into the world coordinate system using the calibrated camera parameters. Alternatively, the same alignment can be achieved by transforming the ground-truth joints into the estimated camera coordinate system. For SMPLest-X, we use the publicly released large-scale model for experiments. Similarly, we convert its predictions into SMPL format in the world coordinate system for convenience. 1 Table 5. Evaluations on iterative sequential inference. PVEs are in mm. Lower is better for all metrics. Config. AMASS 3DPW RICH PVE PA-PVE PVE PA-PVE PVE PA-PVE = 1 = 3 = 5 17.22 16.25 15. 15.72 14.97 14.56 21.23 19.92 20.03 19.34 18.24 18.28 27.51 25.72 25.52 24.02 22.99 22.93 B.3. Iterative Sequential Inference Possessing single forward characteristic, the proposed Learnable SMPLify can also be applied iteratively. In Tab. 5, we evaluate the performance on sequential inference. For each frame, we perform iterations, where the result from the 1th iteration is used to initialize the k-th iteration. The initialization for the 0-th iteration of the current frame is taken from the final prediction of the previous frame. We present the best results between iterative inference and non-iterative inference for each configuration. The comparison of = 1 and = 3 settings demonstrates that applying our method iteratively further improves the performance. The comparison between = 3 and = 5 indicates convergence, as increasing the number of iterations yields no significant and consistent gains."
        }
    ],
    "affiliations": [
        "Fudan University",
        "Shanghai Artificial Intelligence Laboratory",
        "Zhejiang University"
    ]
}