{
    "paper_title": "MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character Recognition with over 97K Categories",
    "authors": [
        "Yuyi Zhang",
        "Yongxin Shi",
        "Peirong Zhang",
        "Yixin Zhao",
        "Zhenhua Yang",
        "Lianwen Jin"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Foundational to the Chinese language and culture, Chinese characters encompass extraordinarily extensive and ever-expanding categories, with the latest Chinese GB18030-2022 standard containing 87,887 categories. The accurate recognition of this vast number of characters, termed mega-category recognition, presents a formidable yet crucial challenge for cultural heritage preservation and digital applications. Despite significant advances in Optical Character Recognition (OCR), mega-category recognition remains unexplored due to the absence of comprehensive datasets, with the largest existing dataset containing merely 16,151 categories. To bridge this critical gap, we introduce MegaHan97K, a mega-category, large-scale dataset covering an unprecedented 97,455 categories of Chinese characters. Our work offers three major contributions: (1) MegaHan97K is the first dataset to fully support the latest GB18030-2022 standard, providing at least six times more categories than existing datasets; (2) It effectively addresses the long-tail distribution problem by providing balanced samples across all categories through its three distinct subsets: handwritten, historical and synthetic subsets; (3) Comprehensive benchmarking experiments reveal new challenges in mega-category scenarios, including increased storage demands, morphologically similar character recognition, and zero-shot learning difficulties, while also unlocking substantial opportunities for future research. To the best of our knowledge, the MetaHan97K is likely the dataset with the largest classes not only in the field of OCR but may also in the broader domain of pattern recognition. The dataset is available at https://github.com/SCUT-DLVCLab/MegaHan97K."
        },
        {
            "title": "Start",
            "content": "MegaHan97K: Large-Scale Dataset for Mega-Category Chinese Character Recognition with over 97K Categories Yuyi Zhanga,b, Yongxin Shia, Peirong Zhanga, Yixin Zhaoa, Zhenhua Yanga, Lianwen Jina,b aSchool of Electronic and Information Engineering, South China University of Technology, Guangzhou, China. bSCUT-Zhuhai Institute of Modern Industrial Innovation, Zhuhai, China 5 2 0 2 ] . [ 1 7 0 8 4 0 . 6 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Foundational to the Chinese language and culture, Chinese characters encompass extraordinarily extensive and ever-expanding categories, with the latest Chinese GB18030-2022 standard containing 87,887 categories. The accurate recognition of this vast number of characters, termed mega-category recognition, presents formidable yet crucial challenge for cultural heritage preservation and digital applications. Despite significant advances in Optical Character Recognition (OCR), mega-category recognition remains unexplored due to the absence of comprehensive datasets, with the largest existing dataset containing merely 16,151 categories. To bridge this critical gap, we introduce MegaHan97K, mega-category, large-scale dataset covering an unprecedented 97,455 categories of Chinese characters. Our work offers three major contributions: (1) MegaHan97K is the first dataset to fully support the latest GB18030-2022 standard, providing at least six times more categories than existing datasets; (2) It effectively addresses the long-tail distribution problem by providing balanced samples across all categories through its three distinct subsets: handwritten, historical and synthetic subsets; (3) Comprehensive benchmarking experiments reveal new challenges in mega-category scenarios, including increased storage demands, morphologically similar character recognition, and zero-shot learning difficulties, while also unlocking substantial opportunities for future research. To the best of our knowledge, the MetaHan97K is likely the dataset with the largest classes not only in the field of OCR but may also in the broader domain of pattern recognition. The dataset is available at https://github.com/SCUT-DLVCLab/MegaHan97K. Keywords: Optical character recognition, Zero-shot learning, Chinese character recognition, Mega-category 1. Introduction Optical Character Recognition (OCR) is fundamental task in computer vision that has garnered intensive research attention for decades [1, 2, 3, 4, 5]. Within this field, Chinese character recognition (CCR) [6, 7, 8, 9] has long been pivotal issue due to its unique challenges. Unlike Latin, the Chinese character lexicon is continuously expanding to encompass broader spectrum of infrequently-used and archaic characters. For instance, the latest Chinese GB18030-2022 [10] standard includes 87,887 categories, marking substantial expansion from the 27,533 categories in the preceding GB18030-2000 [11]. This expansion reflects increasing demands in areas such as historical document research, digitization of ancient texts, and various social applications1. Accurately recognizing mega-category characters poses significant challenge within the field of CCR and holds paramount significance for the aforementioned areas, impacting not only academic research but also the broader ability Email addresses: yuyi.zhang11@foxmail.com (Yuyi Zhang), yongxin_shi@foxmail.com (Yongxin Shi), eeprzhang@mail.scut.edu.cn (Peirong Zhang), yixin_zhao01@126.com (Yixin Zhao), eezhyang@gmail.com (Zhenhua Yang), lianwen.jin@gmail.com (Lianwen Jin) Co-first author. *Corresponding authors. 1https://en.wikipedia.org/wiki/GB 18030 Preprint submitted to Pattern Recognition to preserve and interact with cultural heritage digitally. However, to the best of our knowledge, the mega-category challenge remains unexplored, primarily due to data deficiency across several aspects. First, although numerous datasets have been released [12, 13, 14] to propel the advancement of CCR, the majority of them lean to encompass common characters, with only minor proportion for rare characters. Second, the largest dataset to date, M5HisDoc [15], containing only 16,151 categories, is significantly fewer than the total categories in the contemporary Chinese lexicon. Third, these datasets suffer from pronounced long-tail distribution issues, with many categories having only one or two samples. The paucity of data hampers both the training and evaluation of existing CCR systems, critically stalling the explorations of mega-category CCR. To fill this gap and advance the development of CCR toward cultural heritage preservation, digital applications, and societal needs, we introduce MegaHan97K, mega-category, large-scale dataset that contains an unprecedented 97,455 character categories. Figure 1 presents comparison of the MegaHan97K dataset with previous datasets across three dimensions: category, instance count, and data type. MegaHan97K offers several key features as follows: MegaHan97K includes Chinese characters of 97,455 categories, which significantly surpasses existing datasets by at least six times in categories. June 6, Figure 1: Comparing MegaHan97K with existing Chinese character datasets. The green and blue bubbles represent handwritten and historical datasets, respectively. The area of the bubble and the number in brackets denote categories in each dataset. MegaHan97K is the first to support the latest Chinese GB18030-2022 standard, ensuring the most comprehensive coverage and compatibility with modern Chinese processing systems. MegaHan97K contains three distinct subsets: handwritten, historical, and synthetic. Each subset contains greater number of character categories compared to existing datasets, resulting in remarkable scale and diversity advantages. MegaHan97K effectively mitigates long-tail distribution issues by providing balanced and sufficient number of samples for each category, ensuring robust training and validation of CCR models. To evaluate the effectiveness of MegaHan97K, we thoroughly benchmark our dataset using various CCR methods, including the state-of-the-art CCR-CLIP [16], HierCode [17], PCSS [18], SideNet [19], etc. The experimental results of the mega-category on MegaHan97K reveal significant challenges for CCR models in this context, such as numerous morphologically similar characters, severe radical zero-shot issues, and increased storage demands. Furthermore, we conduct cross-validation with previous datasets to show the necessity of mega-category Chinese characters dataset to drive further progress in this field. 2. Related Work 2.1. Chinese Character Datasets Existing Chinese character datasets can be mainly divided into two types: handwritten and historical datasets. Handwritten datasets tend to focus solely on common Chinese character categories. For instance, HCL2000 [20] comprises 3,755 frequentlyused Chinese characters written by 1,000 writers. HIT-MW [21] includes 853 forms and 3,041 categories authored by over 780 writers. SCUT-COUCH2009 [22] consists of 11 subsets with larger vocabularies and more writers. CASIA-HWDB [12] contains approximately 3.9 million isolated character samples across 7,356 categories, written by 1,020 writers. Compared to handwritten datasets, historical counterparts typically encompass broader range of categories. TKH-MTH [23] includes 1,500 images of Chinese historical documents across two types and 4,058 character categories. MTHv2 [24], an extension of TKH-MTH, comprises 3,199 images across the same two types and 6,733 character categories. ICDAR 2019 HDRC-CHINESE [25] is large structured dataset containing 8,353 character categories. CASIA-AHCDB [13] contains over 2.2 million character samples of 10,350 categories, which are tailored for character recognition in historical documents. M5HisDoc [15] is currently the largest dataset of historical documents, comprising two subsets, five stylistic properties, and 16,151 character categories. Additionally, CTW [26] is challenging dataset collected from street views, containing 812,872 Chinese character images spanning 3,650 classes, with complex backgrounds and diverse fonts. However, these datasets confront several shortcomings. First, no existing dataset supports mega-category scenarios, thereby hindering the progress in related research areas. Second, these datasets still exhibit long-tail distribution problems, with many categories having only one or two samples, which renders them insufficient for effectively training and evaluating CCR models. Consequently, there is pressing need to introduce new dataset to address these limitations. 2.2. Chinese Character Recognition Method Early Chinese Character Recognition (CCR) methods [27, 28] employ Convolutional Neural Networks (CNNs) to extract features from character images and achieve exceptional performance. However, the challenge of data shortage is exacerbated by the extensive and ever-growing lexicon of Chinese characters, coupled with the labor-intensive data collection and annotation. Hence, numerous zero-shot CCR methods [29, 30, 31, 32, 33, 34] have been proposed to address this issue. For instance, DenseRAN [35], FewShotRAN [36], and CUE [37] consider the recognition task as radical sequence prediction problem. HDE [38] and HierCode [17] encode the Ideographic Description Sequences (IDS) of Chinese characters to construct unique representations for each character. Chen et al. [39] decomposed Chinese characters into strokes and recognized Chinese characters by predicting stroke sequences. SideNet [19] and ACPM [40] simultaneously leverage the various intrinsic information of Chinese characters, e.g., radicals, strokes, and glyphs, to recognize Chinese characters, achieving favorable results. Yu et al. [16] simulated humans recognizing, through aligning the character image and IDS, demonstrating robust zero-shot capabilities. Ao et al. [18] employed GAN-based model to generate unseen data, thereby significantly enhancing the training and testing processes. Although existing research methods have demonstrated their zero-shot capabilities on the CASIA-HWDB [12] and CTW [26] datasets, these validations are typically limited to the scope of 3,755 Level-1 commonlyused characters. To date, due to the lack of data, few studies have attempted to evaluate the zero-shot performance of these methods across broader range of categories. 3. MegaHan97K Dataset 3.1. Lexicon Determination To meet the escalating demands, the Chinese character lexicon is continuously expanding to encompass broader spectrum of infrequently-used and archaic characters. For instance, the Chinese GB18030 standards have shown substantial growth over the years: GB18030-2000 [11], GB18030-2005 [41], and GB18030-2022 [10] standards comprise 27,533, 70,244, and 87,887 categories, respectively. The Unicode standard2 encompasses about 100,000 categories of Chinese characters, exhibiting broader repertoire that fully covers the GB18030-2022 standard [10]. To ensure the broadest possible coverage of the Chinese character, we first incorporate all Chinese characters from GB18030-2022 into our lexicon, then supplement it with Unicode 15.0.0, amassing total of 98,208 categories of Chinese characters. However, we identify certain ambiguous pairs of Chinese characters, which share identical structures and radical formations despite bearing distinct Unicode encodings, as illustrated in Figure 2. To avoid confusion about the recognition of such characters, we propose checking and removing strategy based on IDS comparison. Specifically, by comparing the IDS of all characters, we find pairs of characters with the same IDS and represent them uniformly with the smaller Unicode encodings. With this strategy, we end up retaining 97,455 Chinese character categories. 3.2. Data Acquisition MegaHan97K consists of three subsets: historical, handwritten, and synthetic. In the following, we will delve into the details of the data acquisition. Historical subset. Given the extensive number of rare and variant forms in Chinese characters, samples of these categories Figure 2: The example of ambiguous Chinese characters. are extremely scarce. Considering that most available samples may have already been incorporated into existing datasets, we collect data from M5HisDoc [15], which currently contains the largest variety of character categories, and complement it with additional samples from the HanDian website3. For M5HisDoc, we gather characters based on their sample numbers. Specifically, we randomly select 30 samples from the category with more than 30 samples; otherwise, all available samples are included. However, M5HisDoc contains only 16,151 Chinese character categories and demonstrates severe long-tail distribution problem (20% of the categories have less than 3 samples), making it inadequate for our requirements. To address these limitations, we turn to the Internet for additional data. The HanDian website contains carefully organized Chinese character images from historical documents. Therefore, we develop web crawler program to download the images and corresponding characters of the Kangxi Dictionary as images and labels to construct the Kangxi Dictionary part in the historical subset. The Kangxi Dictionary part encompasses 47,064 Chinese character categories with at least one image per category. In total, we have collected approximately 400K samples in the historical subset. The visualization of the historical subset is presented in Figure 3(a). Although we have made extensive efforts to collect historical samples across diverse character categories, the current data exhibits three significant constraints: the category count remains substantially below the 97,455 classes defined in the latest Chinese GB18030-2022 standard, limited samples per category, and pronounced long-tail distribution. To overcome these deficiencies, we propose expanding the dataset through the collection of handwritten Chinese characters. Handwritten subset. The handwritten subset constitutes the most critical parts in MegeHan97K, which covers all 97,455 categories of our lexicon. For data acquisition, we develop 2https://home.unicode.org 3https://www.zdic.net 3 Table 1: summary of the proposed MegaHan97K dataset. Original and Augmented represent the original and augmented versions of the handwritten subset, respectively. Kangxi denotes the Kangxi Dictionary. Subset #Category #Instance Handwritten Original Augmented 96,362 416, 97,455 481,455 Historical M5HisDoc Kangxi 47,064 49,438 16,151 353,296 Synthetic Total 97,455 3,314, 97,455 4,614,675 Table 2: Comparing MegaHan97K with existing Chinese character datasets. indicates that we count only those subsets related to the Chinese GB2312-80 standard in SCUT-COUCH2009. * denotes that our analysis is limited to the training set because only the training set of ICDAR 2019 HDRC-CHINESE is available. Hw., His., and Syn. represent handwritten, historical, and synthetic types of data, respectively. Dataset HIT-MW [21] HCL2000 [20] SCUT-COUCH [22] CASIA-HWDB [12] TKH-MTH [23] IC19 HDRC [25] CASIA-AHCDB [13] MTHv2 [24] M5HisDoc [15] MegaHan97K (Ours) Year 2007 2009 2011 2011 2018 2019 2019 2020 2023 Type Hw. His. #Instance #Category Syn. 186,444 3,755,000 1,472,420 3,721,874 521,377 2,482,994 2,276,740 1,081,663 4,367,360 4,614,675 3,041 3,755 8,147 7,815 4,058 8,353 10,350 6,733 16,151 97,455 vide plentiful total number of samples, the average sample count per category remains constrained, merely sufficient for model validation. Drawing inspiration from prior works [39, 16], we seek to enrich our training data by rendering character images. Nevertheless, these works utilizing TrueType Font (TTF) files to render character images are limited to handling few thousand categories, and merely handful of TTF files (fewer than five) support the extensive range of 100,000 categories. Consequently, we employ the advanced font generation model FontDiffuser [42] to synthesize character data. Specifically, we meticulously select 319 TTF files4 with styles similar to ancient manuscripts and handwritten characters to serve as style image inputs for FontDiffuser, with the PuHuiTi TTF file5 employed as the reference content inputs. All employed TTF files are under an open license. FontDiffuser is trained to mimic the style of these style images while preserving the content of the reference images. After training, the model is then employed to generate 35 samples in different styles for each category of Chinese characters. We extracted 10% of the synthesized data for sampling inspection to verify that it meets predefined quality standards. The explanation for generating 35 samples per category is detailed in Section 4.5. To simulate real-world scenarios, we apply the augmentation process to all synthetic data, as we implement it on the handwritten subset. The visualization of the synthetic subset is shown in Figure 3 (c). 3.3. Dataset Analysis The summarization of the MegaHan97K dataset and the comparison with other datasets are demonstrated in Table 1 and 2, respectively. The comparison between MegaHan97K and existing 4https://www.maoken.com/all-fonts-imgs 5https://www.alibabafonts.com/#/font 4 Figure 3: The visualization of the MegaHan97K dataset. HandWT-O (Original) and HandWT-A (Augmented) represent the pre-processed and post-processed versions of the handwritten subset, respectively. Zoom in for better view. dedicated website featuring user interface that includes main writing board, toolbar, printed character display area, and information display block, as depicted in Figure 4. To enrich data diversity regarding writing mode and writing style, we invite 94 volunteers to write Chinese characters on our website. Each volunteer is tasked with writing on Android-based tablets using their specific stylus. For the 27,533 categories defined by the GB18030-2000 standard, we collect 20 samples per category. Additionally, for the 69,922 categories not included in the GB18030-2000 standard, we collect 5 samples per category. In total, we have collected approximately 900K samples. To ensure the data quality, each sample is verified by at least one of the papers authors. The complete data writing and checking process takes approximately 2,300 person-hours. After that, partial clean images undergo processing to simulate characteristics of real-world historical documents as depicted in Figure 5. First, we randomly increase the stroke thickness to emulate the style of characters in ancient manuscripts. Second, we choose 30 typical types of ancient manuscript backgrounds from M5HisDoc [15] and utilize them to replace the white background of the image randomly. Finally, we apply random blurring and color jitter to 80% of the images while keeping the remaining portion unchanged. We denote the preprocessed and post-processed data as HandWT-O (Original) and HandWT-A (Augmented), respectively. Notably, the original and augmented parts are sourced from different real data, respectively. Visualizations of the handwritten subset are presented in Figure 3(b). Synthetic subset. While the aforementioned subsets proFigure 4: The user interface of the data acquisition website. Figure 5: Illustration of data processing to simulate realistic scenarios. Table 3: Category distribution and sample counts of MegaHan97K in general and zero-shot settings. * denotes that all data presented are real. General Setting Zero-Shot Setting*"
        },
        {
            "title": "Dataset",
            "content": "Training Set Test Set* Total #Category 94,755 97,455 97,455 #Instance 3,927,457 687,218 4,614,675 #Category 27,533 69,922 97,455 #Instance 771,389 404,097 1,175,486 Table 5: Category distribution and sample counts in the MegaHan97K test set under the general setting. Original and Augmented represent the original and augmented versions of the handwritten subset, respectively. Kangxi denotes the Kangxi Dictionary. Subset Synthetic #Category #Instance - - Handwritten Original Augmented 96,362 288,780 97,455 223, Historical M5HisDoc Kangxi 47,064 49,438 16,151 125,189 Total 97,455 687,218 Table 4: Category distribution and sample counts in the MegaHan97K training set under the general setting. Original and Augmented represent the original and augmented versions of the handwritten subset, respectively. Kangxi denotes the Kangxi Dictionary. Table 6: Category distribution and sample counts in the MegaHan97K training set under the zero-shot setting. Original and Augmented represent the original and augmented versions of the handwritten subset, respectively. Kangxi denotes the Kangxi Dictionary. Subset Synthetic #Category #Instance 97,455 3,314,000 Handwritten Original Augmented 27,533 192,675 27,533 192, Historical M5HisDoc Kangxi 9,369 228,107 - - Total 97,455 3,927,457 Subset #Category #Instance Handwritten Original Augmented 27,533 275,250 27,533 275,250 Historical M5HisDoc Kangxi 22,588 23,327 8,005 197,562 Total 27,533 771,389 datasets reveals the following advantages. First, MegaHan97K encompasses an unprecedented 97,455 categories of Chinese characters, which surpasses existing datasets by at least six times in categories. This propels the potential and advancements in the mega-category CCR. Second, MegaHan97K is the first dataset to completely cover the latest Chinese GB18030-2022 standard, ensuring comprehensive coverage and compatibility with modern Chinese character processing systems. Third, MegaHan97K contains three subsets: handwritten, historical, and synthetic. Each contains more character categories than existing datasets, manifesting remarkable scale and diversity advantages. Finally, while several datasets feature over ten thousand categories, they often suffer from long-tail distribution issues. For instance, approximately 20% of the categories in M5HisDoc [15] have fewer than three samples. In contrast, MegaHan97K effectively mitigates long-tail distribution issues by providing balanced and sufficient number of samples for each category, ensuring robust training and validation of CCR models. The mitigation of the long-tail distribution problem will be further examined in Section 4.4. 4. Experiments 4.1. Experimental Setup Methods. Recently, Chinese character recognition methods have achieved remarkable progress, showcasing impressive 5 Table 7: Category distribution and sample counts in the MegaHan97K test set under the zero-shot setting. Original and Augmented represent the original and augmented versions of the handwritten subset, respectively. Kangxi denotes the Kangxi Dictionary. Subset #Category #Instance Handwritten Original Augmented 68,829 206,205 69,922 141, Historical M5HisDoc Kangxi 24,476 26,111 1,364 30,545 Total 69,922 404,097 performance in general and zero-shot CCR. However, most evaluations are conducted using the CASIA-HWDB [12] and CTW [26] datasets, which are severely constrained in the range of character categories and fall short in cultural heritage preservation and societal needs. To comprehensively evaluate character recognition methods on the mega-category scenario, we benchmark five types of methods on MegaHan97K, including general (ResNet [43]), radical sequence predicting-based (FewShotRAN [36]), radical embedding-based (HDE [38], RIE [37], SideNet [19], HierCode [17]), image-IDS matching-based (CCRCLIP [16]), and glyph-based (OpenCCD [32], PCSS [18]) methods. Stroke-based methods (SLD [39], ACPM [40]) are not included due to the lack of stroke-level information. These methods typically utilize interchangeable visual encoders, such as ResNet or ViT, to encode input images, while incorporating prior knowledge (e.g., strokes, radicals, and glyphs) of each Chinese character to capture its structural information. The primary distinction among these approaches lies in how they leverage the prior knowledge of characters. (1) Radical sequence predicting-based methods: FewShotRAN [36] utilizes visual encoder to extract character features, followed by recurrent neural network to predict the IDS of Chinese characters. (2) Radical embedding-based methods: HDE [38], SideNet [19], and HierCode [17] convert the IDS of Chinese characters into binary trees. HDE encodes node paths to generate unique character representations. SideNet enhances HDE with learnable parameters for adaptive feature adjustment during training. HierCode uses prototype encoding to traverse the binary tree for robust feature representation. RIE leverages radical entropy to construct unique character encodings. After extracting visual features, these methods calculate the similarity between the visual features and the corresponding encoding table to produce the final predictions. (3) Image-IDS matching-based methods: CCR-CLIP [16] employs CLIPs visual encoder and text encoder to encode character images and IDS respectively, aligning them within the feature space to further capture the relationships between visual and structural features of Chinese characters. (4) Glyph-based methods: OpenCCD [32] achieves Chinese character recognition by comparing the features of the input image with the features of printed images. PCSS [18] continuously updates the features of printed images through prototype learning, thereby obtaining more robust feature representations of Chinese characters. Implementation details. For fair comparison of HDE [38], RIE [37], and HierCode [17], we employ ResNet50 [43] as the backbone and optimize these models using the Adam optimizer with initial lr=0.001, β1=0.9, and β2=0.99. The size of the input image is normalized to 9696, and the batch size is set to 400. 6 For SideNet [19], we only implement the DDCM version due to the extremely large memory demands of its complete version in the mega-category scenario. To handle the increased number of radicals from the extensive categories of Chinese characters, we expand the dimension of the radical prototype layer in FewShotRAN [36] and OpenCCD [32] from 512 to 1024. Apart from these modifications, all remaining details are strictly implemented with their corresponding papers. Additionally, we reproduce RIE [37], while the other methods are implemented using either open-source code or code provided by the authors. We use character accuracy as the evaluation criteria. All experiments are conducted on server equipped with an Intel Xeon Platinum 8360Y CPU @ 2.40GHz and an NVIDIA A6000 GPU with 48GB memory. The software environment consisted of Ubuntu 20.04 LTS, PyTorch 1.13.1, CUDA 11.7, and cuDNN 8.5.0. Dataset splitting. Following prior research [39, 37, 16], we conduct experiments in two settings: general and zero-shot CCR. An overview of the splitting of these two settings is included in Table 3. The general CCR setting indicates that the categories in the test set are included in the training set, as outlined in Table 4 and Table 5. Conversely, in the zero-shot CCR setting, the categories in the test set are entirely absent from the training set. As detailed in Table 6 and Table 7, we split the real data in MegaHan97K into two parts. The 27,533 categories in the GB18030-2000 standard are used as training data, and the remaining 69,922 categories are used as testing data, ensuring that the training and test categories do not overlap. 4.2. General Chinese Character Recognition Table 8 and Table 9 demonstrate the results of general Chinese character recognition. We derive the following observations. (1) The synthetic subset significantly enhances CCR performance. As shown in the last three columns in Table 8, it is evident that all models achieve remarkably superior performance when trained with the synthetic subset, exhibiting an impressive average improvement of 22.43% compared to without the synthetic subset. This underscores the effectiveness of our synthetic subset and further highlights its utility as an efficacious solution to the challenge of collecting adequate training data in mega-category scenarios. (2) Mega-category scenarios present the challenge of exponentially increased storage requirements. As shown in Table 9, the storage demands of all methods increase substantially under the mega-category setting, which is primarily attributed to the increment in the category number. The surge in categories not only increases storage demands in the classification layer but also significantly impacts the storage space needed for this prior information (e.g., structural, radical, and stroke information). In comparison to 16,151 (the maximum number of categories in existing datasets), most models showcase larger than 60% size increases in storage requirements under our 97,455 categories. It underscores that the mega-category nature of our dataset introduces novel challenges to CCR, particularly for computational resource requirements and the deployment of mega-category models on edge devices, such as phones and tablets. This previously unforeseen observation offers novel insights that could spark new ideas for Table 8: Comparison of various methods in terms of average inference time (AIT), and accuracy. w./o. syn. and w. syn. indicate without and with the synthetic subset, respectively. denotes the accuracy improvement with the synthetic subset. The bold and underline indicate the best and second best, respectively. Method Venue AIT ResNet50 [43] FewShotRAN [36] HDE [38] OpenCCD [32] RIE [37] CCR-CLIP [16] SideNet [19] HierCode [17] PCSS [18] CVPR16 PRL19 PR20 CVPR22 PR23 ICCV23 PR24 PR24 ICASSP 16ms 12ms 15ms 16ms 15ms 13ms 1809ms 15ms 14ms ACC (%) w./o. Syn. w. Syn. 88.76 88.41 88.86 88.55 88.36 89.56 88.63 92.32 89.53 34.89 69.25 65.85 79.49 62.92 82.04 61.82 66.58 78.27 (%) +53.87 +19.16 +23.01 +9.06 +25.44 +7.52 +26.81 +25.74 +11.26 Table 9: Comparative analysis of model sizes, prior information sizes, footprints, and Additional Footprint Proportion (AFP) across various Chinese character recognition methods in the mega-category scenario. Prior size refers to the size of additional prior information, such as structure and radical information. The footprint represents the sum of the model size and the size of the prior information. AFP indicates the percentage increase in footprint when character categories expand from 16,151 to 97,455 relative to the total footprint. Method ResNet50 [43] FewShotRAN [36] HDE [38] OpenCCD [32] RIE [37] CCR-CLIP [16] SideNet [19] HierCode [17] PCSS [18] Model Size 893.1MB 1735.6MB 109.1MB 634.9MB 109.1MB 261.8MB 83.3MB 109.0MB 30.6MB Prior Size - - 352.4MB 199.6MB 352.0MB 199.6MB Footprint 893.1MB 1735.6MB 461.5MB 834.5MB 461.1MB 461.4MB 10936.4MB 11019.7MB 283.3MB 1628.9MB 174.3MB 1598.3MB AFP (%) 71.12 79.19 63.62 19.95 63.70 36.09 82.79 51.32 81. future research in the field of pattern recognition with the megacategory scenario. (3) Morphologically similar and complex characters in MegaHan97K present significant challenges for CCR. Ideographic Description Sequences (IDS) encapsulate the inherent structure of Chinese characters, comprised of radicals and structural symbols. We assume that Chinese characters with an IDS edit distance of no more than three are morphologically similar. Analysis of the edit distances between the IDS of erroneous samples and their corresponding ground truths reveals that 38.34% of these distances are three or fewer. This suggests that substantial number of morphologically similar characters are misidentified, primarily due to the presence of the mega-category in the Chinese character lexicon. Additionally, characters with complex shapes are also prone to confusion, with 74.18% of the error samples featuring ten or more strokes. 4.3. Zero-Shot Chinese Character Recognition We conduct zero-shot CCR experiments to further evaluate the zero-shot capability of existing methods. The results listed in Table 10 reveal that: (1) The mega-category of MegaHan97K poses significant challenge for zero-shot CCR. All methods deliver unsatisfactory performance under the mega-category setting, primarily due to the overly large category, which results in significant number of radical zero-shot instances in the test set. This introduces scenario that is notably more complex than previous challenges. (2) The CLIP-based method outperforms 7 Table 10: Comparison of various methods in zero-shot Chinese character recognition experiment. Print. denotes that the method uses additional printed images. Method FewShotRAN [36] HDE [38] OpenCCD [32] CCR-CLIP [16] RIE [37] SideNet-DDCM [19] HierCode [17] PCSS [18] Venue PRL19 PR20 CVPR22 ICCV23 PR23 PR24 PR24 ICASSP24 Print. ACC (%) 46.76 47.39 76.06 79.04 45.41 47.68 46.82 77.34 other approaches in the zero-shot scenario. CCR-CLIP, an image-IDS matching-based method built upon CLIP, delivers the optimal zero-shot performance, surpassing its closest competitor, SideNet-DDCM, by 31.36% in recognition accuracy. This superior performance may be attributed to its use of contrastive learning, which aligns image and text features in the same latent space, potentially enabling the model to better capture the structural information of Chinese characters. (3) Glyph-based method is effective in zero-shot recognition. For methods that utilize additional printed character images for training or testing, OpenCCD outperforms FewShotRAN by achieving 29.3% higher performance and demonstrates comparable performance to the optimal model CCR-CLIP. This effectiveness stems from the use of printed character templates, which can effectively introduce prior knowledge. However, these methods require large number of printed images during training, leading to higher training costs. (4) Radical embedding-based methods have smaller footprint but show limited effectiveness in the zero-shot scenario. As shown in Tables 9 and 10, the radical embedding-based methods, such as HierCode, HDE, and RIE, have smaller footprints compared to other types of methods. However, this smaller footprint leads to greater compression of prior information, which may result in information loss and subsequently degrade the models performance. 4.4. Long-tail distribution Problem Analysis We conduct experiments to analyze the long-tail distribution problem on the M5HisDoc [15] and MegaHan97K datasets. Our assessment employs dual metrics: top-1 accuracy and macro accuracy [44], where macro accuracy is computed by aggregating individual category accuracies and calculating their arithmetic mean. The latter, particularly efficacious in quantifying model performance across the character distribution spectrum, shows high sensitivity to data-scarce categories [44]. As shown in Table 11, both HierCode [17] and CCR-CLIP [16] achieve high macro accuracy on the MegaHan97K dataset, indicating that the training set features relatively balanced distribution of categories, enabling effective learning across all classes. Furthermore, the minimal discrepancy between top-1 and macro accuracy for both methods suggests that the test set of MegaHan97K is also well-balanced. Therefore, there is essentially no long-tail distribution problem in the MegaHan97K dataset. Conversely, both models demonstrate considerably lower macro Table 11: Comparative analysis of long-tail problem. Macro ACC is defined as calculating the accuracy for each category individually and then averaging the results. Method MegaHan97K (Ours) Top1 ACC Macro ACC M5HisDoc [15] Top1 ACC Macro ACC CCR-CLIP [16] HierCode [17] 89.56% 92.32% 91.52% 93.62% 93.26% 94.08% 71.96% 63.48% accuracy relative to top-1 accuracy on the M5HisDoc dataset, indicating severe long-tail distribution issues prevalent in both the training and test sets. 4.5. Investigating Synthetic Data Effects and Limitations In this subsection, we analyze the effects and limitations of synthetic data on model performance, summarized as follows: (1) Impact of Synthetic Data Volume: We conduct an experimental study to investigate the effect of synthetic data volume, as depicted in Figure 7. With the addition of synthetic data, the accuracy first improves and tends to stabilize. When the number of synthetic data samples per category is fewer than 35, accuracy exhibits an upward trajectory as additional data is incrementally introduced. However, once the number reaches approximately 35, accuracy plateaus at around 92.4%, suggesting point of diminishing returns. It is noteworthy that increasing the volume of synthetic data significantly prolongs the duration of training. Consequently, we select 35 samples per category for our training set to balance optimal accuracy with reasonable training time. (2) Limitations for Complex and Similar Characters: To verify whether increasing synthesized data for challenging samples can further improve model performance, we select Chinese characters with more than 10 strokes to represent complex characters and those with an IDS edit distance of less than 3 to represent similar characters. For these characters, we increase the number of synthesized samples to 70, while keeping the sample size at 35 for the remaining characters. Despite this adjustment, experiments show only marginal improvement in Top-1 accuracy, increasing from 92.32% to 92.35%. Additionally, we use the latest state-of-the-art method IF-Font [45] to synthesize data and train the recognition model with 15 samples per category, achieving an accuracy of 90.96%, comparable to FontDiffuser. To analyze the reason for such marginal improvement, we perform visualization of the synthesized samples for these complex and similar characters, as shown in Figure 6. The results reveal that font synthesis models struggle with these challenging samples, exhibiting issues such as stroke misplacement and missing details. The incorrectly synthesized characters may confuse the recognition model, hampering the recognition accuracy. This indicates that merely increasing synthesized data for challenging samples or adopting more advanced models may still fail to address the challenges in mega-category Chinese character recognition. 4.6. Cross-Validation with Other Datasets We also conduct cross-validation experiments on CASIAAHCDB [13], M5HisDoc [15], CASIA-HWDB [12], and MegaTable 12: Cross-validation of the CCR-CLIP [16] model trained on other datasets and MegaHan97K. The entries in gray represent intra-dataset validations. Task CASIA-AHCDB MegaHan97K MegaHan97K CASIA-AHCDB CASIA-AHCDB CASIA-AHCDB CASIA-HWDB MegaHan97K MegaHan97K CASIA-HWDB CASIA-HWDB CASIA-HWDB M5HisDoc MegaHan97K MegaHan97K M5HisDoc M5HisDoc M5HisDoc ACC (%) 12.05 80.79 94.23 20.65 72.64 96.38 29.12 75.34 93.26 Table 13: Performance comparison of CCR-CLIP model trained by combining MegaHan97K with different datasets. Historical, synthetic, and handwritten refer to the historical subset, synthetic subset, and handwritten subset, respectively. #Line Training Set Test Set HWDB HWDB HWDB HWDB+Historical HWDB HWDB+Synthetic HWDB HWDB+Handwritten HWDB HWDB+MegaHan97K AHCDB AHCDB AHCDB AHCDB+Historical AHCDB AHCDB+Synthetic AHCDB AHCDB+Handwritten AHCDB AHCDB+MegaHan97K M5HisDoc M5HisDoc M5HisDoc+MegaHan97K M5HisDoc Acc (%) Macro Acc (%) 96.38 92.60 96.67 96.74 96.76 94.23 96.07 97.91 98.41 98.49 93.26 95. 95.06 92.59 96.67 96.73 96.76 85.64 92.08 92.31 94.21 95.27 71.96 81.53 1 2 3 4 5 6 7 8 9 10 11 12 Han97K using the CCR-CLIP [16] model. Notably, the data from M5HisDocs test set are not included in MegaHan97Ks training set. Based on the results in Table 12, we draw the following conclusions. (1) MegaHan97K manifests robust generalization capabilities. The models trained on the MegaHan97K dataset exhibit robust generalization performance on other datasets. (2) The MegaHan97K dataset presents novel challenges to the field due to its inclusion of mega-categories. The models trained on existing datasets exhibit underperformance on the MegaHan97K dataset. This is primarily attributed to the limited number of categories in existing datasets, which hinders the models ability to generalize effectively to the more complex challenge posed by the mega-category scenario in the MegaHan97K dataset. 4.7. Analysis of the Impact of Combining MegaHan97K with"
        },
        {
            "title": "Different Datasets",
            "content": "In this subsection, we combine MegaHan97K with existing datasets for joint training to investigate its impact on the performance of these datasets. From the experimental results in Table 13 (Lines 1, 5, 6, 10, 11, and 12), it can be observed that integrating MegaHan97K with existing datasets significantly improves the models Top-1 accuracy and Macro accuracy. The improvement in Macro accuracy indicates that the models ability to recognize rare and variant characters has been enhanced, demonstrating greater robustness. Furthermore, we select two representative datasets, HWDB (handwritten) and AHCDB (historical), to explore the impact of combining different MegaHan97K subsets (historical, synthetic, 8 Figure 6: Comparison of challenging samples synthesized by FontDiffuser and IF-Font with ground truth (GT). Red boxes indicate errors, while green boxes highlight correct components. text-level and page-level data offer richer contextual semantic information that better reflects daily usage scenarios, characterlevel datasets maintain unique research value. Our focus on character-level recognition is motivated by the following factors: (1) Many of the characters within the 97K categories we collect are rare or variant forms, significantly complicating the collection of text line data that naturally includes these characters. Given the scarcity and specialized nature of these characters, character-level analysis provides foundation for understanding these rare glyphs while enabling research into the evolution and variations of Chinese characters. (2) Our character-level dataset is particularly useful in scenarios such as the digitization and restoration of ancient documents [46, 47]. For example, as shown in Figure 9, certain historical documents have suffered damage due to improper preservation, leading to the loss of contextual information and leaving only few recognizable characters. In such cases, textlevel recognition models may fail. Instead, robust characterlevel recognition model capable of effectively identifying the remaining clear characters could assist historians in further digitization or restoration efforts. As demonstrated in Section 4.7 and Table 13 (Lines 6-12), the integration of our dataset with existing ancient datasets significantly improves the models ability to recognize rare and variant characters, demonstrating greater robustness. Consequently, our dataset holds significant implications for specialized fields working with rare or ancient characters, particularly in the digitization and restoration of ancient documents. 6. Visualization In this section, we present visualizations of the misclassified samples from the best-performing CCR-CLIP model to further illustrate the challenges in mega-category Chinese character recognition. As shown in Figure 10 (a), this scenario contains large number of complex Chinese characters, which are often highly similar to one another, differing only in subtle details such as strokes or individual radicals. Accurately identifying these characters requires models to have fine-grained perception of strokes and radicals, which presents significant challenge for existing methods. This observation further underscores the significance of our dataset, as it presents novel challenges for future research in large-vocabulary Chinese character recognition. Additionally, we conduct experiments on the M5HisDoc dataset to analyze potential challenging cases that might occur in real-world scenarios. As shown in Figure 10 (b), several Figure 7: Effects of increasing synthetic sample sizes on accuracy. handwritten) during training on model performance. The results in Table 13 show that for HWDB, the synthetic and handwritten subsets (lines 3 and 4) improve the models performance. However, the historical subset (line 2) leads to decrease in performance due to the significant stylistic differences between the historical subset and handwritten data. In contrast, for AHCDB, all three subsets of MegaHan97K (lines 79 in Table 13) positively contribute to model performance. This can be attributed to the data augmentation strategies applied to the synthetic and handwritten subsets in MegaHan97K (as illustrated in Figure 5), which effectively simulate the style of historical data. To further analyze the advantages of combining MegaHan97K into model training, we use the HWDB dataset as an example and conduct comparative visualization of the model outputs with and without MegaHan97K. As shown in Figure 8, the characters that are incorrectly recognized without MegaHan97K but correctly identified when using it are mostly similar characters or rare characters. Whether it is relatively simple characters (e.g., Figure 8 (a)-(g)) or complex characters (e.g., Figure 8 (h)-(o)), the model performs poorly without the inclusion of MegaHan97K. The main reason for this phenomenon is the lack of such characters in the training data. Therefore, this analysis further highlights the significance of the proposed dataset in the field of Chinese character recognition, as it provides mega-category of Chinese character data, including rare, visually similar, and complex characters. 5. Discussion Several existing datasets [15, 12] contain annotations spanning three levels: character, text, and page levels. Although 9 Figure 8: Comparison of prediction results with and without the use of MegaHan97K. HWDB represents predictions from the model trained only on the HWDB dataset, while HWDB+Mega represents predictions from the model trained on both the HWDB and MegaHan97K datasets. Figure 9: Analysis of damaged ancient document. The left side shows sample of damaged ancient document, while the right side provides detailed qualitative analysis of specific regions. Highlighted cases include variant/rare characters (red boxes), completely damaged characters (blue boxes), and blurred or stroke-loss characters (green boxes). Variant characters refer to characters that share the same meaning and pronunciation as their counterparts but differ in glyph, such as variations in radicals or strokes. issues in historical Chinese characters are identified, including missing strokes (Figure 10 (b) (1)-(3)), stroke adhesion (Figure 10 (b) (4)-(9)), illegible handwriting (Figure 10 (b) (10)-(11)), blurriness (Figure 10 (b) (12)-(13)), and extra strokes (Figure 10 (b) (14)). These issues result in misclassification and are worth further investigation in future research. 7. Limitation In this section, we analyze the limitations of the MegaHan97K and our strategies to address them as follows: (1) Coverage of Chinese Character Categories: Despite our significant efforts to collect the widest possible range of Chinese character categories, there are some variant and rare categories that are not included in the current work due to their lack of standardized computer coding (the Chinese national standard [10] or Unicode6). If additional character categories are officially encoded in the future, we will consider expanding our dataset accordingly. 6https://home.unicode.org (2) Domain Gap Between Writing on Tablets and Paper: Although we thoroughly optimize the handwriting collection system to simulate writing on paper, we acknowledge certain domain gap between writing on tablets and on paper. However, this gap has limited impact on the model and can be mitigated with appropriate training strategies. For instance, as shown in lines 1 and 5 of Table 13, combined training on the HWDB and MegaHan97K datasets slightly improves Top-1 accuracy and noticeable increases macro accuracy from 95.06% to 96.76%, demonstrating that combined training effectively reduces domain discrepancies and enhances model performance. (3) Limited Sample Size: Due to huge number of character categories, the collection and verification of the dataset are extremely labor-intensive and time-consuming. As result, in the test set, we collect only five handwritten samples for each type of Chinese character. In the future, we plan to collect more samples to further expand the dataset. 8. Conclusion In the paper, we introduce MegaHan97K, mega-category, large-scale dataset that contains the largest 97,455 Chinese char10 Figure 10: Visualization analysis of the misclassified samples from the CCR-CLIP model. The misclassified components, such as radicals or strokes, are highlighted with red boxes, while the correctly recognized ones are marked with green boxes. acter categories. It is the first dataset that supports the latest Chinese GB18030-2022 standard and boasts the largest category to date, at least six times more expansive than existing datasets. We conduct an extensive benchmark evaluation of MegaHan97K and perform detailed analysis of the results. Our findings suggest that MegaHan97K more accurately mirrors the challenges faced in cultural heritage preservation and societal needs, while also showing enhanced compatibility with contemporary Chinese character processing systems. We believe this dataset will serve as an invaluable resource for researchers dedicated to advancing the field of mega-category Chinese character recognition."
        },
        {
            "title": "Acknowledgement",
            "content": "This research is supported in part by the National Natural Science Foundation of China (Grant No.:62476093, 62441604), and the National Key Research and Development Program of China (2022YFC3301703)."
        },
        {
            "title": "References",
            "content": "[1] X.-D. Zhou, Y.-M. Zhang, F. Tian, H.-A. Wang, C.-L. Liu, Minimum-risk training for semi-markov conditional random fields with application to handwritten Chinese/japanese text recognition, Pattern Recognition 47 (5) (2014) 19041916. [2] C. Luo, L. Jin, Z. Sun, MORAN: multi-object rectified attention network for scene text recognition, Pattern Recognition 90 (2019) 109118. [3] S. Fang, H. Xie, Y. Wang, Z. Mao, Y. Zhang, Read like humans: Autonomous, bidirectional and iterative language modeling for scene text recognition, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 70987107. [4] C. Wang, C. Liu, Z. Fang, Z. Han, C. Liu, X. Yin, Open set text recognition technology, Journal of Image and Graphics 28 (06) (2023) 17671791. [5] C. Liu, L. Jin, X. Bai, X. Li, F. Yin, Frontiers of intelligent document analysis and recognition: review and prospects, Journal of Image and Graphics 28 (08) (2023) 22232252. 11 [6] Y.-M. Su, J.-F. Wang, novel stroke extraction method for Chinese characters using Gabor filters, Pattern Recognition 36 (3) (2003) 635647. [7] X.-Y. Zhang, Y. Bengio, C.-L. Liu, Online and offline handwritten Chinese character recognition: comprehensive study and new benchmark, Pattern Recognition 61 (2017) 348360. [8] Z.-R. Wang, J. Du, J.-M. Wang, Writer-aware CNN for parsimonious HMM-based offline handwritten Chinese text recognition, Pattern Recognition 100 (2020) 107102. [9] G. Huang, X. Luo, S. Wang, T. Gu, K. Su, Hippocampus-heuristic character recognition network for zero-shot learning in Chinese character recognition, Pattern Recognition 130 (2022) 108818. [10] M. of Industry, I. Technology, //openstd.samr.gov.cn/bzgk/gb/newGbInfo?hcno= A1931A578FE14957104988029B0833D3 (2022). GB18030-2000, GB18030-2022, Administration, S. https:// https: [11] N. openstd.samr.gov.cn/bzgk/gb/newGbInfo?hcno= 4F885660EB8B3AC463C2ED336DB3B67B (2000). [12] C.-L. Liu, F. Yin, D.-H. Wang, Q.-F. Wang, CASIA Online and Offline Chinese Handwriting Databases, in: International Conference on Document Analysis and Recognition (ICDAR), 2011, pp. 3741. [13] Y. Xu, F. Yin, D.-H. Wang, X.-Y. Zhang, Z. Zhang, C.-L. Liu, CASIA-AHCDB: Large-Scale Chinese Ancient Handwritten Characters Database, in: International Conference on Document Analysis and Recognition (ICDAR), 2019, pp. 793798. [14] H. Zhang, L. Liang, L. Jin, Scut-hccdoc: new benchmark dataset of handwritten chinese text in unconstrained camera-captured documents, Pattern Recognition (2020) 107559. [15] Y. Shi, C. Liu, D. Peng, C. Jian, J. Huang, L. Jin, M5HisDoc: Largescale Multi-style Chinese Historical Document Analysis Benchmark, in: Advances in Neural Information Processing Systems (NeurIPS), Vol. 36, 2023, pp. 7848378495. [16] H. Yu, X. Wang, B. Li, X. Xue, Chinese Text Recognition with PreTrained CLIP-Like Model Through Image-IDS Aligning, in: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023, pp. 1194311952. [17] Y. Zhang, Y. Zhu, D. Peng, P. Zhang, Z. Yang, Z. Yang, C. Yao, L. Jin, Hiercode: lightweight hierarchical codebook for zero-shot chinese text recognition, Pattern Recognition 158 (2025) 110963. [18] X. Ao, X.-H. Li, X.-Y. Zhang, C.-L. Liu, Prototype calibration with synthesized samples for zero-shot chinese character recognition, in: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2024, pp. 62956299. [19] Z. Li, Y. Huang, D. Peng, M. He, L. Jin, SideNet: Learning Representations from Interactive Side Information for Zero-Shot Chinese Character Recognition, Pattern Recognition 148 (2024) 110208. [20] H. Zhang, J. Guo, G. Chen, C. Li, HCL2000 - Large-scale Handwritten Chinese Character Database for Handwritten Character Recognition, in: International Conference on Document Analysis and Recognition (ICDAR), 2009, pp. 286290. [21] T. Su, T. Zhang, D. Guan, Corpus-based HIT-MW Database for Offline Recognition of General-purpose Chinese Handwritten Text, International Journal on Document Analysis and Recognition 10 (1) (2007) 2738. [22] L. Jin, Y. Gao, G. Liu, Y. Li, K. Ding, SCUT-COUCH2009a comprehensive online unconstrained Chinese handwriting database and benchmark evaluation, International Journal on Document Analysis and Recognition 14 (2011) 5364. [23] H. Yang, L. Jin, W. Huang, Z. Yang, S. Lai, J. Sun, Dense and Tight Detection of Chinese Characters in Historical Documents: Datasets and Recognition Guided Detector, IEEE Access 6 (2018) 3017430183. [24] W. Ma, H. Zhang, L. Jin, S. Wu, J. Wang, Y. Wang, Joint Layout Analysis, Character Detection and Recognition for Historical Document Digitization, in: International Conference on Frontiers in Handwriting Recognition (ICFHR), 2020, pp. 3136. [25] R. Saini, D. Dobson, J. Morrey, M. Liwicki, F. Simistira Liwicki, ICDAR 2019 Historical Document Reading Challenge on Large Structured Chinese Family Records, in: International Conference on Document Analysis and Recognition (ICDAR), 2019, pp. 14991504. [26] T.-L. Yuan, Z. Zhu, K. Xu, C.-J. Li, T.-J. Mu, S.-M. Hu, large Chinese text dataset in the wild, Journal of Computer Science and Technology 34 (2019) 509521. [27] D. Ciresan, U. Meier, Multi-Column Deep Neural Networks for offline handwritten Chinese character classification, in: International Joint Conference on Neural Networks (IJCNN), 2015, pp. 16. [28] X. Xiao, L. Jin, Y. Yang, W. Yang, J. Sun, T. Chang, Building fast and compact convolutional neural networks for offline handwritten Chinese character recognition, Pattern Recognition 72 (2017) 7281. [29] Z. Li, Q. Wu, Y. Xiao, M. Jin, H. Lu, Deep Matching Network for Handwritten Chinese Character Recognition, Pattern Recognition 107 (2020) 107471. [30] T.-Q. Wang, F. Yin, C.-L. Liu, Radical-Based Chinese Character Recognition via Multi-Labeled Learning of Deep Residual Networks, in: International Conference on Document Analysis and Recognition (ICDAR), Vol. 01, 2017, pp. 579584. [31] X. Ao, X.-Y. Zhang, C.-L. Liu, Cross-modal prototype learning for zeroshot handwritten character recognition, Pattern Recognition 131 (2022) 108859. [32] C. Liu, C. Yang, X.-C. Yin, Open-Set Text Recognition via CharacterContext Decoupling, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022, pp. 45234532. [33] C. Liu, C. Yang, H.-B. Qin, X. Zhu, C.-L. Liu, X.-C. Yin, Towards openset text recognition via label-to-prototype learning, Pattern Recognition 134 (2023) 109109. [34] X. Ao, X.-H. Li, X.-Y. Zhang, C.-L. Liu, Prototype Calibration with Synthesized Samples for Zero-Shot Chinese Character Recognition, in: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2024, pp. 62956299. [35] W. Wang, J. Zhang, J. Du, Z.-R. Wang, Y. Zhu, DenseRAN for Offline Handwritten Chinese Character Recognition, in: International Conference on Frontiers in Handwriting Recognition (ICFHR), 2018, pp. 104109. [36] T. Wang, Z. Xie, Z. Li, L. Jin, X. Chen, Radical Aggregation Network for Few-Shot Offline Handwritten Chinese Character Recognition, Pattern Recognition Letters 125 (2019) 821827. [37] G.-F. Luo, D.-H. Wang, X. Du, H.-Y. Yin, X.-Y. Zhang, S. Zhu, Selfinformation of Radicals: new clue for zero-shot Chinese character recognition, Pattern Recognition 140 (2023) 109598. [38] Z. Cao, J. Lu, S. Cui, C. Zhang, Zero-Shot Handwritten Chinese Character Recognition with Hierarchical Decomposition Embedding, Pattern Recognition 107 (2020) 107488. [39] J. Chen, B. Li, X. Xue, Zero-Shot Chinese Character Recognition with Stroke-Level Decomposition, in: Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), 2021, pp. 615621. [40] X. Zu, H. Yu, B. Li, X. Xue, Chinese Character Recognition with Augmented Character Profile Matching, in: Proceedings of ACM International Conference on Multimedia (ACM MM), 2022, p. 60946102. [41] N. S. Administration, GB18030-2005, https:// openstd.samr.gov.cn/bzgk/gb/newGbInfo?hcno= C344D8D120B341A8DD328954A9B27A99 (2005). [42] Z. Yang, D. Peng, Y. Kong, Y. Zhang, C. Yao, L. Jin, FontDiffuser: OneShot Font Generation via Denoising Diffusion with Multi-Scale Content Aggregation and Style Contrastive Learning, in: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), Vol. 38, 2024, pp. 6603 6611. [43] K. He, X. Zhang, S. Ren, J. Sun, Deep Residual Learning for Image Recognition, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. [44] Y. Zhang, B. Kang, B. Hooi, S. Yan, J. Feng, Deep long-tailed learning: survey, IEEE Transactions on Pattern Analysis and Machine Intelligence 45 (9) (2023) 1079510816. [45] X. Chen, X. Ke, W. Guo, If-font: Ideographic description sequencefollowing font generation, Advances in Neural Information Processing Systems (NeurIPS) 37 (2025) 1417714199. [46] Y. T. Zheng, X. L. Li, Z. X. Yin, G. Gao, Y. Weng, Multi-feature fusion based automatic reconstruction in related to Chinese ancient manuscript fragments of dunhuang, Journal of Image and Graphics 28 (08) (2023) 23302342. [47] Z. Yang, D. Peng, Y. Shi, Y. Zhang, C. Liu, L. Jin, Predicting the Original Appearance of Damaged Historical Documents, Proceedings of the AAAI Conference on Artificial Intelligence (2025). [48] J. Chang, Y. Gu, Y. Zhang, Y.-F. Wang, C. Innovation, Chinese Handwriting Imitation with Hierarchical Generative Adversarial Network, in: British Machine Vision Conference (BMVC), 2018, p. 290. [49] P. Lyu, X. Bai, C. Yao, Z. Zhu, T. Huang, W. Liu, Auto-Encoder Guided GAN for Chinese Calligraphy Synthesis, in: International Conference on Document Analysis and Recognition (ICDAR), Vol. 01, 2017, pp. 10951100. [50] Y. Tian, zi2zi: Master Chinese calligraphy with conditional adversarial networks, Internet] https://github. com/kaonashi-tyc/zi2zi 3 (2017) 2. [51] D. Sun, T. Ren, C. Li, H. Su, J. Zhu, Learning to Write Stylized Chinese Characters by Reading Handful of Examples (2018). arXiv:1712. 06424. [52] Y. Zhang, Y. Zhang, W. Cai, Separating Style and Content for Generalized Style Transfer, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2018. [53] Y. Kong, C. Luo, W. Ma, Q. Zhu, S. Zhu, N. Yuan, L. Jin, Look Closer To Supervise Better: One-Shot Font Generation via Component-Based Discriminator, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022, pp. 1348213491. [54] S. Park, S. Chun, J. Cha, B. Lee, H. Shim, Few-shot Font Generation with Localized Style Representations and Factorization, in: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), Vol. 35, 2021, pp. 23932402. [55] S. Park, S. Chun, J. Cha, B. Lee, H. Shim, Multiple Heads Are Better Than One: Few-Shot Font Generation With Multiple Localized Experts, in: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 1390013909. [56] C. Wang, M. Zhou, T. Ge, Y. Jiang, H. Bao, W. Xu, CF-Font: Content Fusion for Few-Shot Font Generation, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp. 18581867. [57] Y. Xie, X. Chen, L. Sun, Y. Lu, DG-Font: Deformable Generative Networks for Unsupervised Font Generation, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 51305140. [58] Y. Tang, L. Peng, Q. Xu, Y. Wang, A. Furuhata, CNN Based Transfer Learning for Historical Chinese Character Recognition, in: IAPR Workshop on Document Analysis Systems (DAS), 2016, pp. 2529. [59] Y. Li, L. Jin, X. Zhu, T. Long, SCUT-COUCH2008: comprehensive online unconstrained Chinese handwriting dataset, in: International Conference on Frontiers in Handwriting Recognition (ICFHR), Vol. 2008, 2008, pp. 165170. [60] L.-W. Jin, J.-X. Yin, X. Gao, J.-C. Huang, Study of Several directional feature extraction methods with local elastic meshing technology for HCCR, in: Proceedings of the Sixth Int. Conference for Young Computer Scientist (ICYCS), 2001, pp. 232236. [61] F. Chang, Techniques for solving the large-scale classification problem in Chinese handwriting recognition, in: Summit on Arabic and Chinese 12 Handwriting Recognition (SACH), Springer, 2006, pp. 161169. [62] M. Pechwitz, S. S. Maddouri, V. Margner, N. Ellouze, H. Amiri, et al., IFN/ENIT-database of handwritten Arabic words, in: Proceedings of the Colloque International Francophone sur lEcrit et le Document (CIFED), Vol. 2, Citeseer, 2002, pp. 127136. [63] N. E. B. Amara, O. Mazhoud, N. Bouzrara, N. Ellouze, ARABASE: Relational Database for Arabic OCR Systems., in: Proceedings of the International Arab Journal of Information Technology (IAJIT), Vol. 2, 2005, pp. 259266. [64] J. Hull, database for handwritten text recognition research, IEEE Transactions on Pattern Analysis and Machine Intelligence 16 (5) (1994) 550 554. [65] U.-V. Marti, H. Bunke, The IAM-database: an English sentence database for offline handwriting recognition, International Journal on Document Analysis and Recognition 5 (2002) 3946. [66] Z. Xie, Z. Sun, L. Jin, H. Ni, T. Lyons, Learning Spatial-Semantic Context with Fully Convolutional Recurrent Network for Online Handwritten Chinese Text Recognition, IEEE Transactions on Pattern Analysis and Machine Intelligence 40 (8) (2017) 19031917. [67] C.-L. Liu, S. Jaeger, M. Nakagawa, Online Recognition of Chinese Characters: The State-of-the-Art, IEEE Transactions on Pattern Analysis and Machine Intelligence 26 (2) (2004) 198213. [68] Q. Lin, C. Luo, L. Jin, S. Lai, Stan: sequential transformation attentionbased network for scene text recognition, Pattern Recognition 111 (2021) 107692. [69] C.-L. Liu, I.-J. Kim, J. H. Kim, Model-based stroke extraction and matching for handwritten Chinese character recognition, Pattern Recognition 34 (12) (2001) 23392352. [70] M. Yang, B. Yang, M. Liao, Y. Zhu, X. Bai, Class-aware mask-guided feature refinement for scene text recognition, Pattern Recognition 149 (2024) 110244. [71] Z. Cai, M. Cao, H. Chen, K. Chen, K. Chen, X. Chen, X. Chen, Z. Chen, Z. Chen, P. Chu, X. Dong, H. Duan, Q. Fan, Z. Fei, Y. Gao, J. Ge, C. Gu, Y. Gu, T. Gui, A. Guo, Q. Guo, C. He, Y. Hu, T. Huang, T. Jiang, P. Jiao, Z. Jin, Z. Lei, J. Li, J. Li, L. Li, S. Li, W. Li, Y. Li, H. Liu, J. Liu, J. Hong, K. Liu, K. Liu, X. Liu, C. Lv, H. Lv, K. Lv, L. Ma, R. Ma, Z. Ma, W. Ning, L. Ouyang, J. Qiu, Y. Qu, F. Shang, Y. Shao, D. Song, Z. Song, Z. Sui, P. Sun, Y. Sun, H. Tang, B. Wang, G. Wang, J. Wang, J. Wang, R. Wang, Y. Wang, Z. Wang, X. Wei, Q. Weng, F. Wu, Y. Xiong, C. Xu, R. Xu, H. Yan, Y. Yan, X. Yang, H. Ye, H. Ying, J. Yu, J. Yu, Y. Zang, C. Zhang, L. Zhang, P. Zhang, P. Zhang, R. Zhang, S. Zhang, S. Zhang, W. Zhang, W. Zhang, X. Zhang, X. Zhang, H. Zhao, Q. Zhao, X. Zhao, F. Zhou, Z. Zhou, J. Zhuo, Y. Zou, X. Qiu, Y. Qiao, D. Lin, Internlm2 technical report (2024). arXiv:2403.17297. [72] A. Yang, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu, C. Li, D. Liu, F. Huang, H. Wei, H. Lin, J. Yang, J. Tu, J. Zhang, J. Yang, J. Yang, J. Zhou, J. Lin, K. Dang, K. Lu, K. Bao, K. Yang, L. Yu, M. Li, M. Xue, P. Zhang, Q. Zhu, R. Men, R. Lin, T. Li, T. Tang, T. Xia, X. Ren, X. Ren, Y. Fan, Y. Su, Y. Zhang, Y. Wan, Y. Liu, Z. Cui, Z. Zhang, Z. Qiu, Qwen2.5 technical report (2025). arXiv:2412.15115."
        }
    ],
    "affiliations": [
        "SCUT-Zhuhai Institute of Modern Industrial Innovation, Zhuhai, China",
        "School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China"
    ]
}