{
    "paper_title": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces",
    "authors": [
        "Minju Gwak",
        "Guijin Son",
        "Jaehyung Kim"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The Uniform Information Density (UID) hypothesis suggests that effective communication maintains a stable flow of information. In this work, we revisit this principle in the context of large language model (LLM) reasoning traces, asking whether step-level uniformity reflects reasoning quality. To this end, we propose an entropy-based stepwise information density metric and introduce two complementary measures of uniformity, local and global uniformity scores. Across the experiments on six different reasoning benchmarks, we find that step-level uniformity not only provides a strong theoretical lens but also yields practical performance benefits; for example, selecting reasoning traces with more uniform information density at the step-level improves accuracy by 10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals that correct reasoning traces tend to avoid sharp information density spikes, while incorrect traces exhibit irregular information bursts. These results demonstrate that UID-inspired information density measures outperform alternative internal signals as predictors of reasoning quality. Results highlight the uniformity of the information density as a robust diagnostic and selection criterion for building more reliable and accurate reasoning systems."
        },
        {
            "title": "Start",
            "content": "Minju Gwak Yonsei University mjgwak@yonsei.ac.kr Guijin Son OneLine AI guijin.son@oneline.com Jaehyung Kim Yonsei University jaehyungk@yonsei.ac.kr 5 2 0 2 8 ] A . [ 1 3 5 9 6 0 . 0 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "The Uniform Information Density (UID) hypothesis suggests that effective communication maintains stable flow of information. In this work, we revisit this principle in the context of large language model (LLM) reasoning traces, asking whether step-level uniformity reflects reasoning quality. To this end, we propose an entropy-based stepwise information density metric and introduce two complementary measures of uniformity, local and global uniformity scores. Across the experiments on six different reasoning benchmarks, we find that step-level uniformity not only provides strong theoretical lens but also yields practical performance benefits; for example, selecting reasoning traces with more uniform information density at the step-level improves accuracy by 10-32% relative gains over baselines at AIME2025. Our analysis further reveals that correct reasoning traces tend to avoid sharp information density spikes, while incorrect traces exhibit irregular information bursts. These results demonstrate that UID-inspired information density measures outperform alternative internal signals as predictors of reasoning quality. Results highlight the uniformity of the information density as robust diagnostic and selection criterion for building more reliable and accurate reasoning systems."
        },
        {
            "title": "Introduction",
            "content": "Chain-of-Thought (CoT) reasoning has become central technique for enhancing large language models (LLMs) on complex reasoning tasks (Wei et al., 2023; Kojima et al., 2023; Chae et al., 2023). By generating step-by-step rationales, CoT enables models to decompose problems into simpler subproblems and thereby improve accuracy (Golovneva et al., 2023; Prasad et al., 2023; Yao et al., 2023). Despite these successes, recent studies have highlighted the fragility of this approach (Zhao et al., 2025a). For example, the intermediate rationales are often logically inconsistent or incoherent, and hence models may still fail to generalize out-of domain tasks even when generating lengthy reasoning traces (Shojaee et al., 2025). This raises critical question: how can we determine whether LLMs are reasoning effectively, rather than merely generating superficially coherent text? Clues may lie in human communication itself, which information theory characterizes as the transmission of signal through noisy channel with limited capacity (Shannon, 1948). The psycholinguistic hypothesis of Uniform Information Density (UID) builds on this foundation, proposing that speakers distribute information as evenly as possible to balance clarity and efficiency (Fenk and Fenk-Oczlon, 1980; Genzel and Charniak, 2002; Clark et al., 2023; Jaeger and Levy, 2006). If the rate of information exceeds the channels capacity, comprehension breaks down; if it falls too far below, communication becomes inefficient, as the same content could be conveyed more compactly. Psycholinguistic evidence supports this claim: effective communication relies on relatively uniform flow of information (Meister et al., 2021; Aylett and Turk, 2004), aligned with the limits of human cognitive processing. When this balance is disrupted by too much or too little information, communication deteriorates. Motivated by this analogy, we ask whether similar principle governs reasoning in LLMs. Just as human speakers maintain balanced information flow to support comprehension, effective reasoning traces may require comparable uniformity across steps. Recent findings from cognitive science also support to this view: Bhambri et al. (2025) shows that reasoning paths interpretable to humans are also easier for models to generate and learn, suggesting shared structure between human cognition and machine reasoning. For example, wellreasoned math solution generally exhibits consistent step-by-step progress, where each step builds smoothly on the last, whereas incoherent solutions often oscillate between overly trivial and overly complex steps. To investigate this, we focus on analyzing the information flow of LLM-generated reasoning traces on challenging mathematical benchmarks. Specifically, we begin by defining per-step measurements of information density, and examine by answer correctness. Then, we introduce two complementary metrics that quantify the uniformity throughout the reasoning trace at globaland local-level, using entropy-based per-step measurement. Our experiments reveal clear pattern: unlike human communication, reasoning traces with low global uniformity tend to produce correct answers; at the same time, high local uniformity shows higher correlation with answer correctness. This suggests that effective reasoning balances local uniformity and global uniformity. Empirical results show that trends in local and global uniformity can serve as reliable proxy for determining high and low quality reasoning traces that directly affect answer correctness. Overall, our contributions are threefold: To our knowledge, we are the first to introduce information-theoretic metrics for quantifying the reasoning structure of LLMs both at the step and trace level. Contrary to our hypothesis, we find that reasoning patterns characterized by global nonuniformity and local uniformity in surprisal, correlate with reasoning success on challenging mathematical reasoning tasks. Extensive analyses show that deviations from such patterns can serve as an internal signal for predicting failure cases, enabling potential improvements in LLM reasoning and evaluation."
        },
        {
            "title": "2.1 Background: Uniform information",
            "content": "density (UID) hypothesis The Uniform Information Density (UID) hypothesis models language as signal transmitted through noisy channel with limited capacity (Meister et al., 2021; Tsipidi et al., 2024). It posits that speakers aim to convey information efficiently without overwhelming the listeners processing resources. Let an utterance = [u1,u2, . . . , uN ] be sequence of linguistic units, such as words, subwords, or characters, depending on the granularity of representation. For each unit un, we can define surprisal as the unexpectedness of unit, given its previous context. Formally, surprisal is defined as: s(un) = log (un u<n), where (unu<n) is the probability of seeing unit utterance un after the earlier sequence u<n = [u1, . . . , un1]. The high surprise of the unit indicates that it is very unexpected and hard to process for the person receiving the information, while units with lower surprisal are easier to process. In this sense, surprisal can be perceived as information content. To capture the overall cognitive load of message, we aggregate this surprisal across all units in the sequence. Given an utterance u, the total processing effort can be expressed as: Eprocess(u) (cid:88) n=1 s(un)k + N. for some constant > 0 and > 1. Here, the exponent encodes the super-linear nature of processing effort: Surprisal does not contribute linearly but instead grows disproportionately when is large. In other words, rare or unexpected units impose much greater effort than predictable ones. Therefore, when following such formulation, more uniform distribution of surprisal across language signal minimizes total processing effort, whereas spiky linguistic signal with highly uneven surprisal values increase the burden of communication (Meister et al., 2021). If information is concentrated in few highly surprising units, the receiver experiences sharp spikes in processing difficulty (Hale, 2001; Levy, 2008; Brouwer et al., 2010); if it is too sparse, communication is inefficient. The high-level intuition of the UID hypothesis is that the most efficient communication strategy is to distribute surprisal as evenly as possible across the sequence, maintaining stable level of processing effort. This tendency has been empirically observed across syllables, words, syntax, and discourse (Meister et al., 2021). While UID has been extensively validated in human language, its implications for machine reasoning remain underexplored. LLMs, or more specifically, recent reasoning models such as DeepseekR1 (DeepSeek-AI et al., 2025) and Qwen3 (Yang et al., 2025) generate step-by-step CoT traces, much like how human speech unfold over time. If we treat each reasoning step zi like unit with surprisal s(zi), single reasoning trace = [z1, z2, . . . , zN ] can be analyzed in the same way to have the total reasoning effort: Ereason(z) (cid:88) n=1 s(zn)k + N. Then, natural question arises: does the UID hypothesis hold for good reasoning patterns in LLMs? smooth, uniform surprisal profile may reflect clear and logical reasoning, while sharp spikes may signal confusion or errors. We extend UID hypothesis beyond psycholinguistics to probe the structure of CoT reasoning of LLMs, offering new lens on why reasoning models succeed or fail."
        },
        {
            "title": "2.2 Preliminary analysis with step-wise",
            "content": "information density in reasoning traces We start by defining the step-level information density IDi for reasoning trace = [z1, . . . , zN ] with steps, where each reasoning step zi is composed of Mi tokens, i.e., zi = [x1, . . . , xMi]. We divide the given reasoning trace into multiple reasoning steps by nn, following Lightman et al. (2023). Let pt(v) be the predictive distribution over the vocabulary at the token position t, and lt = log pt(xt) the log-probability of the generated token xt. Then, to characterize IDi, we consider entropy over tokens in each step, as defined below: Ht = (cid:88) vV pt(v) log pt(v), and step-level entropy aggregated across tokens is: IDi ="
        },
        {
            "title": "1\nMi",
            "content": "Mi(cid:88) t=1 Ht. Justifications for using entropy as proxy. We use entropy as proxy for information density because it reflects both model confidence and variability in reasoning; low entropy indicates confident, almost deterministic predictions, while higher entropy suggests uncertainty and the exploration of multiple plausible continuations (Shannon, 1948; Kuhn and Johnson, 2013). From an informationtheoretic perspective, entropy quantifies the expected number of bits required to encode the predictive distribution, with higher values corresponding to richer informational content (Cover and Thomas, 2006). Aggregating entropy across tokens offers compact, interpretable signal of reasoning difficulty, marking where the model hesitates versus flows smoothly. Furthermore, our empirical results (a) Correct Traces (b) Incorrect Traces Figure 1: Averaged IDi scores of LLM reasoning trace on AIME2025. Correct traces show downward trend with smooth decay, while incorrect traces show noisy entropy with unresolved spikes. (see Appendix A.1) find that using entropy as proxy internal signal is more effective in discriminating the good and bad structures of reasoning traces of LLMs compared to other log-probability and confidence-based methods. Figure 1 compares the evolution of entropy at the step level, therefore IDi, between the averaged reasoning traces for correct and incorrect solutions in AIME2025. Here, correct traces exhibit clear global trend: entropy begins with exploratory fluctuations, stabilizes in mid-trace, and then steadily decays toward near zero, reflecting structured process of uncertainty resolution and convergence on the final answer. In contrast, incorrect traces lack such global trajectory, instead displaying flat, noisy entropy with occasional sharp spikes that fail to resolve into stability. As we examine entropy peaks at the level of individual reasoning traces, we find that interpreting them solely through the semantic content of the text is difficult (see Appendix A.2). To be specific, (1) entropy levels in both traces can be quite varying, (2) number of transition words (i.e. But, each IDi [0, 1], normalized values are given by ID = IDim , = min 1iN IDi, = max 1iN IDi. The variance of the normalized information density values = [ID ] is then given by 1, . . . , ID Var(u) = 1 (cid:80)N i=1 (ID µ)2 , µ = 1 (cid:80)N i=1 ID i. Figure 2: Information distribution across words of two hypothetical sentences, showing two types of uniformness. Sentence shows global uniformity similar to incorrect reasoning traces, while Sentence shows local uniformity similar to correct reasoning traces. Recreation of Fig. 4 in (Collins, 2014) and Fig. 2 in (Meister et al., 2021) Alternatively, Wait) may appear more at correct traces contrary to our intuition, and (3) the number of steps may be shorter and concise at wrong reasoning traces. More importantly, such an approach does not provide consistent basis for interpretation across different domains. This limitation highlights the need for unified structural perspective. Building on such motivation, we introduce framework for measuring the uniformity of information density in reasoning traces."
        },
        {
            "title": "2.3 Measuring the uniformity of information",
            "content": "density in reasoning trace To measure the uniformity of information density in reasoning trace, we first clarify what \"uniform\" means. Prior psycholinguistic theory offers two perspectives (Meister et al., 2021; Collins, 2014), as shown in Figure 2. Global uniformity maintains stable surprisal rate across the trace (blue, Sentence A), while local uniformity reflects smooth, gradual step-level changes (green, Sentence B). Under these two definitions, Sentence (blue) adheres more closely to global uniformity, while Sentence is closer to local uniformity (Meister et al., 2021). Based on these conflicting perspectives, we explore two different UID metrics reasoning traces: (1) variance and (2) step-to-step spikes and falls. On the one hand, variance measures how much the surprisal values diverge from the mean, capturing whether the process is globally unstable in the overall information load. Formally, let reasoning trace have steps and define the (nonnegative) information density vector as = [ID1, . . . , IDN ]. After min-max normalization to bound On the other hand, step-to-step spikes and falls in information density values capture the smoothness of local changes, reflecting whether reasoning unfolds in stable progression or in fragmented bursts. Formally, we define the local change at step as = ID i1 for = 2, . . . , . The mean and variance of these local changes are: ID µ = 1 (cid:80)N i=2 i, = 1 σ2 1 (cid:80)N i=2(i µ)2. Then, thresholds at µ kσ are applied to identify significant deviations in surprisal: > µ + kσ (k {2, 3}) marks an upward spike, while < µ kσ marks downward fall. We will consider both the variance and the number of spikes and falls measured with step-level information density, to evaluate how uniform or not reasoning trace is. These two metrics directly link back to our earlier observations (Figure 1): correct traces tend to show lower variance and smoother transitions (i.e., smaller number of spikes and falls), while incorrect traces exhibit instability and erratic spikes. Together, they provide unified structure for distinguishing reasoning where uncertainty is globally unstable and unevenly concentrated."
        },
        {
            "title": "3 Does the UID Hypothesis Hold in LLM",
            "content": "Reasoning Traces?"
        },
        {
            "title": "3.1 Main Results",
            "content": "Unlike human communication, postulated by the original UID hypothesis, global non-uniform dustribution along with local uniform distribution predicts reasoning success in LLMs. To fully leverage and track the reasoning capabilities of LLMs, we use two widely known reasoning models Qwen3-8B (Yang et al., 2025) and Deepseek-R1-Distill-Qwen-7B (DeepSeekAI et al., 2025) on four challenging mathematical benchmarks: AIME2025, BRUMO2025, HMMT2025, and MinervaMath. We first sample reasoning traces of each question 5 times. Then, we calculate their corresponding UID score, and select the traces with the highest and lowest scores. Table 1: Main result. Performance of DeepSeek-R1-Distill-Qwen-7B and Qwen3-8B on four math benchmarks (AIME2025, BRUMO2025, HMMT2025, and MinervaMath). Results are averaged over seeds 42, 1234, and 2025 with standard deviations. UID-guided methods (local uniformity and global non-uniformity) consistently outperform non-UID baselines. The best and second-best scores are highlighted in bold and underline, respectively. Full results are in Appendix A.4. Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (Local, 3σ) Low UID (Local, 3σ) High UID (Global, var) Low UID (Global, var) DeepSeek-R1-Distill-Qwen-7B AIME2025 BRUMO2025 HMMT2025 MinervaMath 0.40 0.02 0.48 0.04 0.48 0.04 0.48 0.04 0.27 0.00 0.53 0.06 0.52 0.08 0.33 0.00 0.54 0.01 0.52 0.04 0.52 0.05 0.56 0.05 0.39 0.07 0.56 0.02 0.64 0.05 0.44 0.02 0.24 0.00 0.28 0.02 0.27 0.00 0.24 0. 0.18 0.04 0.30 0.00 0.26 0.04 0.16 0.04 0.30 0.00 0.30 0.00 0.30 0.00 0.30 0.00 0.26 0.01 0.31 0.01 0.30 0.01 0.28 0.00 Qwen3-8B Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (Local, 3σ) Low UID (Local, 3σ) High UID (Global, var) Low UID (Global, var) AIME2025 BRUMO2025 HMMT2025 MinervaMath 0.67 0.01 0.63 0.00 0.60 0.00 0.60 0.00 0.63 0.00 0.69 0.03 0.70 0.00 0.66 0.02 0.68 0.02 0.71 0.02 0.63 0.03 0.64 0.04 0.63 0.07 0.70 0.03 0.61 0.06 0.68 0. 0.43 0.01 0.50 0.03 0.42 0.06 0.43 0.05 0.40 0.03 0.48 0.04 0.47 0.03 0.41 0.02 0.34 0.01 0.34 0.01 0.33 0.01 0.33 0.01 0.34 0.01 0.34 0.01 0.33 0.01 0.34 0.02 To evaluate the effectiveness of uniformity-based selection, we consider the following three baselines to find good logical trail: (1) Self-Certainty (Kang et al., 2025), (2) high confidence, and (3) low entropy. Details of the experiment setup are in AppendixA.3. Our experiments in the four benchmarks reveal that UID-based measures consistently improve reasoning accuracy over non-UID baselines, with particularly pronounced gains for Deepseek-R1-Distill-Qwen-7B (see Table 1). For instance, under local uniformity, when thresholds are applied: Low UID (3σ) achieves 0.53 on AIME2025, 0.56 on BRUMO2025, 0.30 on HMMT2025, and 0.31 on MinervaMath, maintaining comparable gains across all four benchmarks. Notably, global non-uniformity paired with High UID (var) further boosts performance on BRUM2025 (0.64) and AIME2025 (0.52), outperforming Self-Certainty (0.52 and 0.48, respectively) by margins of 23% and 8%. These results suggest that enforcing local smoothness while allowing global heterogeneity in surprisal distribution provides the most stable signal for reasoning. As shown in Table 1, Qwen3-8B model follows the same trend but with reduced margins, as its stronger baseline leaves less room for improvement. For example, under local uniformity, Low UID (3σ) achieves 0.69 on AIME2025, 0.70 on BRUMO2025, 0.48 on HMMT2025, and 0.34 on MinervaMath, consistently outperforming the non-UID baselines. Similarly, under global non-uniformity, High UID (var) reaches 0.70 on AIME2025 and 0.47 on HMMT2025, exceeding Self-Certainty (0.63 and 0.50, respectively) by notable margins. These results confirm that UIDbased measures still provide stable gains, particularly when enforcing local smoothness, even though the improvements are less pronounced compared to weaker baseline models. Table 2: Model size analysis. Performance of Qwen3 models (1.7B, 4B, 8B) on AIME2025. Results are averaged over seeds 42, 1234, and 2025 with standard deviations. The best and second-best scores are highlighted in bold and underline, respectively. Full results are in Appendix A.5 Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (Local, 3σ) Low UID (Local, 3σ) High UID (Global, var) Low UID (Global, var) Qwen3-1.7B Qwen3-4B Qwen3-8B 0.35 0.02 0.45 0.04 0.37 0.06 0.37 0.06 0.24 0.05 0.41 0.04 0.37 0.07 0.33 0.03 0.65 0.01 0.73 0.03 0.62 0.05 0.63 0.09 0.54 0.02 0.69 0.02 0.66 0.04 0.67 0. 0.67 0.01 0.63 0.00 0.60 0.00 0.60 0.00 0.63 0.00 0.69 0.04 0.70 0.00 0.66 0.02 Together, these results underscore the utility of UID-guided evaluation: enforcing local uniformity (little jumps between steps) while allowing global non-uniformity (uneven but structured concentration) leads to measurable improvements in reasoning accuracy. The gains, up to 32% relative for Deepseek-R1-Distill-Qwen-7B, demonstrate that UID metrics provide complementary structure beyond conventional confidence or entropy heuristics. To further contextualize these results, we next examine how the observed UIDdriven improvements vary across different model capacities and problem difficulty levels."
        },
        {
            "title": "4.1 Trends across different model sizes",
            "content": "Table 2 reveals clear trends across Qwen3 models of different sizes (1.7B, 4B, 8B). As expected, larger models achieve stronger baselines, with overall accuracy rising from 0.35 (1.7B) to 0.65 (4B) and 0.67 (8B), while Self-Certainty peaks at 0.73 for the 4B model before slightly dropping to 0.63 at 8B. Despite stronger baselines leaving less headroom, UID-based methods continue to provide meaningful gains. Local uniformity (Low UID 3σ) delivers consistent improvements across all scales, raising performance to 0.41 for 1.7B, 0.69 for 4B, and 0.69 for 8B, showing that enforcing local smoothness stabilizes reasoning regardless of size. By contrast, global non-uniformity (Hgh UID var) scales particularly well: while the 1.7B model only reaches 0.37, the 4B and 8B models rise to 0.66 and 0.70, with the latter achieving the best overall score in the table. These results suggest size-dependent effect: smaller models benefit most from local smoothing, whereas larger models derive greater advantage from global non-uniformity in surprisal distribution."
        },
        {
            "title": "4.2 Trends across various difficulty levels",
            "content": "Table 3 further reveals the interaction between local and global UID signals shifts as problem difficulty increases. On easier problems (Levels 1-2), the strongest performance arises when traces are locally non-uniform but globally uniform. For example, High UID (3σ) under local non-uniformity achieves 0.98 at Level 1 and 0.89 at Level 2, while the globally uniform Low UID (var) also reaches 0.98 and 0.90, respectively. Both outperform the baselines, indicating that local variability enriches reasoning while global uniformity stabilizes it on simpler tasks. In contrast, on harder problems (Levels 3-5), accuracy peaks when traces are locally uniform but globally non-uniform. At Level 3, Low UID (var), which denotes global uniformity achieves 0.94, but by Level 4 and 5, the best scores come from High UID (var), which represents global nonuniformity. Local methods under uniformity (i.e. Low UID (2σ, 3σ) also perform competitively (0.91 0.89), suggesting that as reasoning grows more compex, local uniformity provides stability while global non-uniformity injects necessary flexibility. Taken together, these results suggest complementary trend: (1) easier problems benefit from local non-uniformity coupled with global uniformity, and (2) harder problems benefit from local uniformity coupled with global non-uniformity."
        },
        {
            "title": "4.3 UID-based selection is sample-efficient",
            "content": "Table 4 highlights that our method demonstrates strong sample efficiency, with smaller sample sizes consistently outperforming or matching larger ones. In our UID-based methods, Low UID (3σ) achieves 0.720 0.02 with 10 samples, remaining higher than 0.66 0.02 with 15. Even variance-based selection reaches 0.70 0.03 with 5 or 10 samples, dropping to 0.65 0.03 with 15. Our findings suggest that our approach can achieve state-of-the-art performance without requiring extensive sampling, underscoring its practicality for resource-efficient deployment in real-world reasoning tasks."
        },
        {
            "title": "4.4 Application outside math domain",
            "content": "To evaluate the generality of UID-based guidance beyond mathematical reasoning, we applied our framework to the GPQA-Diamond benchmark using Qwen3-8B. The results in Table 5 show that while strong baselines dominate, UID measures Table 3: Benchmark difficulty analysis. Performance of Qwen3-8B on Math500 across Levels 15. The best and second-best scores are highlighted in bold and underline, respectively, per column. Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (Local, 3σ) Low UID (Local, 3σ) High UID (Global, var) Low UID (Global, var) Level 1 Level 2 Level 3 Level 4 Level 5 Average Std 0.96 0.94 0.95 0.95 0.98 0.93 0.93 0.98 0.87 0.87 0.88 0.88 0.89 0.87 0.87 0.90 0.93 0.92 0.92 0.92 0.92 0.92 0.92 0. 0.91 0.91 0.90 0.90 0.89 0.91 0.91 0.89 0.90 0.89 0.88 0.88 0.87 0.89 0.90 0.88 0.91 0.03 0.91 0.03 0.91 0.03 0.90 0.03 0.91 0.04 0.90 0.02 0.91 0.02 0.92 0. Table 4: Performance across different sampling strategies. (Sample by 5, 10, 15), on AIME 2025 using Qwen3-8B. Bold indicates the best performance in each row. Full results are in Appendix A.6 Table 5: Performance on GPQA-Diamond. using Qwen3-8B. The best and second-best scores are highlighted in bold and underline, respectively. Methods () Sample by 5 Sample by 10 Sample by 15 Overall Acc Self-Certainty High Conf Low Ent High UID (3σ) Low UID (3σ) High UID (var) Low UID (var) 0.67 0.01 0.63 0.00 0.60 0.00 0.60 0.00 0.63 0.00 0.69 0.03 0.70 0.00 0.66 0.02 0.68 0.01 0.62 0.04 0.57 0.03 0.56 0.04 0.53 0.05 0.72 0.02 0.70 0.03 0.63 0.00 0.68 0.00 0.67 0.05 0.52 0.02 0.57 0.05 0.62 0.06 0.66 0.02 0.65 0.03 0.62 0. still provide competitive signals. The best performance is achieved by Self-Certainty (0.682), followed by Low UID (3σ) (0.677), both outperforming Overall Accuracy (0.640). Other UIDbased variants, including High UID (var) (0.631) and Low UID (var) (0.611), remain close to baseline levels, suggesting that surprisal-based adjustments are less pronounced in non-math domains. Nevertheless, the fact that Low UID (3σ) nearly matches the best-performing non-UID method indicates that local smoothness retains utility outside of structured problem solving. Overall, these findings demonstrate that UID-guided methods, though most impactful in math-intensive reasoning, also extend stably to knowledge-centric tasks, highlighting their broader applicability."
        },
        {
            "title": "Trace Interpretation",
            "content": "We view the UID scores not simply as performance heuristics but also as lens for reasoning trace interpretation. Traces with high UID variance tend to show compact reasoning, where information is Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (3σ) Low UID (3σ) High UID (var) Low UID (var) Acc. 0.640 0.682 0.616 0. 0.591 0.677 0.631 0.611 introduced with natural ebb and flow, resulting in concise and coherent explanations. In contrast, traces with low variance often expand into unnecessarily long reasoning paths, frequently leading to false answers and noticeable repetition of tokens or even entire sentences. From our qualitative analysis (Appendix A.7), we find that this variance-based distinction consistently highlights structural differences in reasoning quality. We look at the highest and lowest variance traces of the entire generated traces. High-variance traces reveal how effective reasoning balances information density across steps, while low-variance traces expose the pitfalls of uniform but uninformative expansion. This suggests that UID not only correlates with accuracy but also provides an interpretable lens into the structure of LLM reasoning."
        },
        {
            "title": "6.1 Fragility of CoT and the role of individual",
            "content": "reasoning steps CoT prompting improves reasoning but remains fragile (Wei et al., 2023; Zhao et al., 2025a; Kojima et al., 2023; Chae et al., 2023; Chen et al., 2023). Small, seemingly irrelevant perturbations in the reasoning chain can sharply reduce accuracy (Mirzadeh et al., 2025; Tang et al., 2023), suggesting that models often produce the appearance of reasoning rather than logically sound traces (Shojaee et al., 2025). Moreover, longer reasoning steps do not necessarily reflect the true difficulty of the problem, and many intermediate steps can be altered or even removed without changing the final answer (Lanham et al., 2023). This raises doubts about the necessity and faithfulness of these step-by-step explanations. Another line of research takes different perspective: rather than viewing all steps as equally important, it suggests that small subset of pivotal steps within CoT traces disproportionately drives predictions (Bogdan et al., 2025). Attribution methods and their frameworks identify and highlight these critical steps, emphasizing the need to understand how individual steps shape outcomes(Golovneva et al., 2023; Wu et al., 2023; Bigelow et al., 2024). Despite these advances, prior works have no clear interpretations of what constitutes as truly good reasoning pattern. 6."
        },
        {
            "title": "Intrinsic signals in LLM reasoning",
            "content": "Research on LLM reasoning has increasingly turned to internal model signals to gain insight into how reasoning unfolds(Zhao et al., 2025b; Zhang et al., 2025). Many approaches use these signals to improve performance, such as self-consistency (Zuo et al., 2025), self-certainty (Kang et al., 2025; Zhao et al., 2025b), or confidence (Jang et al., 2025) to refine outputs, or using entropy-based measures to encourage diverse reasoning paths (Zhang et al., 2025; Agarwal et al., 2025; Gao et al., 2025; Lee et al., 2025; Li et al., 2025; Zhou et al., 2023). However, these methods largely treat internal signals as heuristics for guiding or controlling reasoning, without providing principled account of why certain reasoning traces are more coherent than others. In contrast, we ground our analysis in the longstanding psycholinguistic theory of Uniform Information Density (UID) hypothesis, which offers theoretical lens for understanding how information is introduced, transformed, and propagated through reasoning. Our perspective on information flow in reasoning traces goes beyond performance heuristics, highlighting structural features that define coherence and provide interpretability."
        },
        {
            "title": "7 Limitations and Discussions",
            "content": "While our study highlights the importance of entropy-uniformity in identifying coherent reasoning traces, several limitations remain. First, our analysis is restricted to mathematical reasoning datasets such as AIME2025, which may not fully capture reasoning behaviors in broader domains like commonsense or medical problem-solving. Future work should examine whether the observed patterns generalize across diverse datasets and modalities. Second, our methodology focuses primarily on tokenand step-level entropy dynamics. Although this provides valuable insights into information flow, it may overlook higher-order structural aspects of reasoning, such as discourse-level organization or long-range dependencies. Incorporating additional linguistic or cognitive features could enrich our framework."
        },
        {
            "title": "8 Conclusion",
            "content": "This paper revisits the long-standing Uniform Information Density (UID) hypothesis in the context of large language model reasoning. By shifting the focus from output-level correctness to step-level information flow, we demonstrate that entropyuniformity serves as meaningful indicator of reasoning quality. Our analysis reveals that coherent reasoning traces tend to distribute information more evenly across steps, while disfluent traces exhibit sharp entropy fluctuations. On the other hand, non-uniform traces at the global level with higher variance leads to more coherent reasoning trace. These findings bridge psycholinguistic theory with computational analysis, providing new lens for interpreting model reasoning beyond performance metrics. Ultimately, our work suggests that UIDinspired measures can guide the design of more interpretable and trustworthy reasoning systems."
        },
        {
            "title": "References",
            "content": "Shivam Agarwal, Zimin Zhang, Lifan Yuan, Jiawei Han, and Hao Peng. 2025. The unreasonable effectiveness of entropy minimization in llm reasoning. Preprint, arXiv:2505.15134. Matthew Aylett and Alice Turk. 2004. The smooth signal redundancy hypothesis: functional explanation for relationships between redundancy, prosodic prominence, and duration Preprint, SAGE Jourin spontaneous speech. nals:10.1177/00238309040470010201. Mislav Balunovic, Jasper Dekoninck, Ivo Petrov, Nikola Jovanovic, and Martin Vechev. 2025. Matharena: Evaluating llms on uncontaminated math competitions. Preprint, arXiv:2505.23281. Siddhant Bhambri, Upasana Biswas, and Subbarao Kambhampati. 2025. Do cognitively interpretable reasoning traces improve llm performance? Preprint, arXiv:2508.16695. Eric Bigelow, Ari Holtzman, Hidenori Tanaka, and Tomer Ullman. 2024. Forking paths in neural text generation. Preprint, arXiv:2412.07961. Paul C. Bogdan, Uzay Macar, Neel Nanda, and Arthur Conmy. 2025. Thought anchors: Which llm reasoning steps matter? Preprint, arXiv:2506.19143. Harm Brouwer, Hartmut Fitz, and John C. J. Hoeks. 2010. Modeling the noun phrase versus sentence coordination ambiguity in dutch: Evidence from surprisal theory. Preprint, ACL:W10-2009. Hyungjoo Chae, Yongho Song, Kai Tzu iunn Ong, Taeyoon Kwon, Minjin Kim, Youngjae Yu, Dongha Lee, Dongyeop Kang, and Jinyoung Yeo. 2023. Dialogue chain-of-thought distillation for commonsense-aware conversational agents. Preprint, arXiv:2310.09343. Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. 2023. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Preprint, arXiv:2211.12588. Thomas Hikaru Clark, Clara Meister, Tiago Pimentel, Michael Hahn, Ryan Cotterell, Richard Futrell, and Roger Levy. 2023. cross-linguistic pressure for uniform information density in word order. Preprint, arXiv:2306.03734. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve math word problems. Preprint, arXiv:2110.14168. MX Collins. 2014. Information density and dependency length as complementary cognitive models. Journal of Psycholinguistic Research, 43(5):651681. Thomas M. Cover and Joy A. Thomas. 2006. Elements of information theory. The standard textbook explaining entropy as the expected number of bits required to encode distribution. DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, R. J. Chen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W. L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X. Zhu, Yanhong Xu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen Zhang. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. Preprint, arXiv:2501.12948. August Fenk and Gertraud Fenk-Oczlon. 1980. Konstanz im kurzzeitgedächtnis - konstanz im Preprint, Joursprachlichen informationsfluß? nal:Zeitschrift für experimentelle und angewandte Psychologie, Vol. 27, pp. 400-414. Zitian Gao, Lynx Chen, Haoming Luo, Joey Zhou, and Bryan Dai. 2025. One-shot entropy minimization. Preprint, arXiv:2505.20282."
        },
        {
            "title": "Dmitriy Genzel",
            "content": "and Eugene Charniak. Entropy rate constancy in text. ACM/ACL:10.3115/1073083.1073117. 2002. Preprint, Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, and Asli Celikyilmaz. 2023. Roscoe: suite of metrics for scoring step-by-step reasoning. Preprint, arXiv:2212.07919. John Hale. 2001. probabilistic earley parser as psycholinguistic model. In North American Chapter of the Association for Computational Linguistics. T. Florian Jaeger and Roger P. Levy. 2006. Speakers optimize information density through syntactic reduction. Hyosoon Jang, Yunhui Jang, Sungjae Lee, Jungseul Ok, and Sungsoo Ahn. 2025. Self-training large language models with confident reasoning. Preprint, arXiv:2505.17454. Zhewei Kang, Xuandong Zhao, and Dawn Song. 2025. Scalable best-of-n selection for large language models via self-certainty. Preprint, arXiv:2502.18581. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2023. Large language models are zero-shot reasoners. Preprint, arXiv:2205.11916. Max Kuhn and Kjell Johnson. 2013. Applied predictive modeling. Discusses entropy in predictive distributions as signal of model uncertainty. Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamile Lukošiute, Karina Nguyen, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Robin Larson, Sam McCandlish, Sandipan Kundu, Saurav Kadavath, Shannon Yang, Thomas Henighan, Timothy Maxwell, Timothy Telleen-Lawton, Tristan Hume, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. Bowman, and Ethan Perez. 2023. Measuring faithfulness in chainof-thought reasoning. Preprint, arXiv:2307.13702. Dongseok Lee, Jimyung Hong, Dongyoung Kim, and Jaehyung Kim. 2025. Training-free llm verification via recycling few-shot examples. Preprint, arXiv:2506.17251. R. Levy. 2008. Expectation-based syntactic comprehension. Cognition, 106:11261177. Zeju Li, Jianyuan Zhong, Ziyang Zheng, Xiangyu Wen, Zhijian Xu, Yingying Cheng, Fan Zhang, and Qiang Xu. 2025. Compressing chain-of-thought in llms via step entropy. Preprint, arXiv:2508.03346. Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Preprint, 2023. arXiv:2305.20050. Lets verify step by step. Clara Meister, Tiago Pimentel, Patrick Haller, Lena Jäger, Ryan Cotterell, and Roger Levy. 2021. Revisiting the uniform information density hypothesis. Preprint, arXiv:2109.11635. Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar. 2025. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models. Preprint, arXiv:2410.05229. Archiki Prasad, Swarnadeep Saha, Xiang Zhou, and Mohit Bansal. 2023. Receval: Evaluating reasoning chains via correctness and informativeness. Preprint, arXiv:2304.10703. David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R. Bowman. 2023. Gpqa: graduate-level google-proof qa benchmark. Preprint, arXiv:2311.12022. Claude E. Shannon. 1948. mathematical theory of communication. Preprint, DOI:10.1002/j.15387305.1948.tb01338.x. Parshin Shojaee, Iman Mirzadeh, Keivan Alizadeh, Maxwell Horton, Samy Bengio, and Mehrdad Farajtabar. 2025. The illusion of thinking: Understanding the strengths and limitations of reasoning models via the lens of problem complexity. Preprint, arXiv:2506.06941. Xiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. 2023. Large language models are in-context semantic reasoners rather than symbolic reasoners. Preprint, arXiv:2305.14825. Eleftheria Tsipidi, Franz Nowak, Ryan Cotterell, Ethan Wilcox, Mario Giulianelli, and Alex Warstadt. 2024. Surprise! uniform information density isnt the whole story: Predicting surprisal contours in long-form discourse. Preprint, arXiv:2410.16062. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023. Self-consistency improves chain of thought reasoning in language models. Preprint, arXiv:2203.11171. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-thought prompting elicits reasoning in large language models. Preprint, arXiv:2201.11903. Skyler Wu, Eric Meng Shen, Charumathi Badrinath, Jiaqi Ma, and Himabindu Lakkaraju. 2023. Analyzing chain-of-thought prompting in large language models via gradient-based feature attributions. Preprint, arXiv:2307.13339. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu. 2025. Qwen3 technical report. Preprint, arXiv:2505.09388. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving with large language models. Preprint, arXiv:2305.10601. Qingyang Zhang, Haitao Wu, Changqing Zhang, Peilin Zhao, and Yatao Bian. 2025. Right question is already half the answer: Fully unsupervised llm reasoning incentivization. Preprint, arXiv:2504.05812. Chengshuai Zhao, Zhen Tan, Pingchuan Ma, Dawei Li, Bohan Jiang, Yancheng Wang, Yingzhen Yang, and Huan Liu. 2025a. Is chain-of-thought reasoning of llms mirage? data distribution lens. Preprint, arXiv:2508.01191. Xuandong Zhao, Zhewei Kang, Aosong Feng, Sergey Learning Preprint, Levine, and Dawn Song. 2025b. to reason without external rewards. arXiv:2505.19590. Chuyue Zhou, Wangjie You, Juntao Li, Jing Ye, Kehai Chen, and Min Zhang. 2023. INFORM: Information eNtropy based multi-step reasoning FOR large language models. In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*. Yuxin Zuo, Kaiyan Zhang, Li Sheng, Shang Qu, Ganqu Cui, Xuekai Zhu, Haozhan Li, Yuchen Zhang, Xinwei Long, Ermo Hua, Biqing Qi, Youbang Sun, Zhiyuan Ma, Lifan Yuan, Ning Ding, and Bowen Zhou. 2025. Ttrl: Test-time reinforcement learning. Preprint, arXiv:2504.16084."
        },
        {
            "title": "A Appendix",
            "content": "A.1 Empirical analyses on various internal signals as proxy for information density We consider three metrics as proxy for information density IDi: (1) log-probability LPi as confidence signal, composed from the average token log-probability over step i, (2) entropy Hi as an uncertainty signal, and (3) confidence gap Di as divergence signal defined as the difference between the log-probability of the current and the previous steps. Formally, log-probability LPi of step is the average token log-probability over step i: LPi = 1 bi ai + 1 bi(cid:88) t=ai ℓt. While token-level entropy Ht as Ht = (cid:88) vV pt(v) log pt(v), step-level entropy Hi is defined as Hi = 1 bi ai + bi(cid:88) t=ai Ht Log-probability gap Di is defined as Di = LPi LPi1 We calculate variance over reasoning traces where each LPi, Hi, and Di is used as proxy of IDi, and calculate the accuracy of the traces with the highest and lowest variance (i.e. the degree of global uniformity). Results in Figure 3 reveal that entropy measures the difference between highest and lowest trends more profoundly than others across various models. A.2 Trace-level analysis of reasoning steps of correct and wrong responses Figure 4 to Figure 15 are some examples of the case studies performed. We conduct trace-level analysis of reasoning steps of single instances of LLM response to see if we can significantly find patterns only at the token level by looking at entropy peaks where we define peaks as stpes above u+2σ where and σ are, respectively, average and standard deviations of the entropy value of individual steps. We use Qwen3-8B on AIME2025 dataset. For both correct and wrong reasoning traces, we (1) identify outlier steps on reasoning traces, and (2) identify their corresponding token-level steps to see if there are meaningful differences between correct and incorrect traces. We also look at the number of total number of steps of both correct and wrong reasoning traces. We identify that only qualitively identifying the reasoning traces is not enough to effectively discriminate high-and-low quality reasoning. To be specific, (1) entropy levels in both traces can be quite varying, (2) number of transition words (i.e. But, Alternatively, Wait) may appear more at correct traces contrary to our intuition, and (3) the number of steps may be shorter and concise at wrong reasoning traces. (a) Accuracy of traces with max vs. min variance in confidence gap A."
        },
        {
            "title": "Implementation details",
            "content": "A.3.1 Hyperparameters and GPUs. We use 2 H100 GPUs for our main results on Qwen3-8B (thinking mode) and Deepseek-DistillQwen-7B, and 4 RTX A6000 GPUs for others. Temperature is 0.6, top-p 0.95, and top-k 20, as stated in (Yang et al., 2025) and (DeepSeek-AI et al., 2025). A.3.2 Benchmarks. AIME 2025. The American Invitational Mathematics Examination (AIME) is prestigious US high school math contest consisting of challenging integer-answer quetions. The AIME 2025 benchmark uses problems from the 2025 contests to evaluate LLMs mathematical reasoning by requiring single correct integer answer. The test set used in our analysis contains of 30 questions. BRUMO 2025.1 The Brown University Math Olympiad (BRUMO) is mathematics competition for students. The BRUMO 2025 benchmark is built from the problems of the 2025 BRUMO competition, and as part of the MathArena (Balunovic et al., 2025) benchmark suite, it consists of 30 finalanswer problems. Each requires unique numeric or closed-form solution. Unlike proof-based contests, BRUMO problems are evaluated on answer correctness. HMMT 2025. 2 The Harvard-MIT Mathematics Tournament (HMMT) is renowned competition featuring diverse problems in algebra, geometry, combinatorics, and number theory. The HMMT 1https://huggingface.co/datasets/MathArena/ brumo_ 2https://huggingface.co/datasets/MathArena/ hmmt_feb_2025 (b) Accuracy of traces with max vs. min variance in entropy (c) Accuracy of traces with max vs. min variance in logprobability Figure 3: Empirical results on AIME2025 show that entropy-uniformity is the most effective criterion for identifying sound reasoning traces. 2025 benchmark uses newly releassed problems from the February 2025 tournament, providing broader variety of tasks than AIME. The set used in our analysis contains of 30 questions. MinervaMath. 3The Minerva Math benchamrk consists of advanced quantitative problems sourced from university-level STEM courses, including physics, chemistry, and higher mathematics. The set used in our analysis contains of 272 questions. 4 Math500 is small but challengMath500. ing benchmark consisting of 500 competition-style mathematics problems drawn from sources like AMC and AIME, designed to evaluate large language models mathematical reasoning abilities. Unlike broader datasets such as GSM8K (Cobbe et al., 2021), which covers elementary arithmetic word problems, or MATH, which spans thousands of high-school-level competition problems, Math500 focuses on especially difficult cases that demand multi-step reasoning, symbolic manipulation, and structured problem-solving. Because of its difficulty and compact size, it is primarily used as stress test for advanced reasoning models rather than for training, making it key benchmark for measuring the upper limits of LLM mathematical reasoning performance. The set used in our analysis contains 500 questions. GPQA-Diamond. GPQA-Diamond (Rein et al., 2023) is the hardest subset of the Graduate-Level Google-Proof Q&A benchmark, consisting of 198 multiple-choice questions in biology, chemistry, and physics. These questions are crafted by domain experts and validated by multiple PhD-level validators to ensure clarity and high difficulty. The Google-proof design means that even with web search, solving them requires deep reasoning rather than lookup. A.3.3 Baseline Details. We re-implemented all logic using vLLM, unlike some of the codes initially released. Our baselines are path-selection methods comparable to ours. Self-Certainty. This is the implementation of Kang et al. (2025), where it evaluates LLMs reasoning by introducing self-certainty, confidence score assigned at each reasoning step. Selfcertainty captures whether the model is confident in its logical steps, and uses Borda Voting to improve 3https://huggingface.co/datasets/math-ai/ minervamath 4https://huggingface.co/datasets/ HuggingFaceH4/MATHanswer selection. Borda Voting ranks outputs by aggregared confidence rather than relying on simple majority voting used in Self-Consistency (Wang et al., 2023). Highest Confidence. This is naive implementation that selects the path with the highest oeverall token confidence in the reasoning trace. Similar methods have been introduced in (Jang et al., 2025), where paths for training are selected based on the traces with the highest confidence. Lowest Entropy. This is naive implementation that selects the path with the lowest overall token entropy in the reasoning trace, driven from the idea that entropy itself is measurement of uncertainty. A.4 Details of the main experiment Details of all the experiments carried out on the three seeds (42, 1234, 2025) are in Table 6 and Table 7. A.5 Details of the performance across different model sizes. Details of all the experiments carried out on the three seeds (42, 1234, 2025) are in Table 8. A.6 Details of the performance across different sampling numbers. Details of all the experiments carried out on the three seeds (42, 1234, 2025) are in Table 9. A.7 Qualitative analysis on reasoning traces with low and high UID scores We qualitatively examine the reasoning traces that have the lowest and highest calculated UID scores in the entire reasoning trace, and see their differences in Figure 16 and Figure 17. Specifically, traces that are globally non-uniform exhibits the natural ebb and flow of high-quality reasoning. Meanwhile, low-variance traces expose the pitfalls of uniform but uninformative expansion. A.8 Usage of AI assistants In preparing this work, we used AI-based writing assistants to improve sentence structure, correct grammatical errors, and enhance overall readability. These tools were employed solely for language refinement and did not contribute to the development of technical content, research methodology, or experimental analysis. All scientific ideas, results, and conclusions presented in the paper were conceived and authored entirely by the researchers. Use of AI assistance was restricted to editorial purposes and did not affect the originality or intellectual contributions of the work. Figure 4: Q6 Correct Trace Visualization Figure 5: Q6 Correct Trace Text Figure 6: Q6 Incorrect Trace Visualization Figure 7: Q6 Incorrect Trace Text Figure 8: Q11 Correct Trace Visualization Figure 9: Q11 Correct Trace Text Figure 10: Q11 Incorrect Trace Visualization Figure 11: Q11 Incorrect Trace Text Figure 12: Q17 Correct Trace Visualization Figure 13: Q17 Correct Trace Text Figure 14: Q17 Incorrect Trace Visualization Figure 15: Q17 Incorrect Trace Text Table 6: Main result. Results of deepseek-r1-distill-qwen-7b on four math benchmarks (AIME2025, BRUMO2025, HMMT2025, and MinervaMath). Performance is reported across seeds 42, 1234, and 2025, with averages and standard deviations (Avg Std). Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (avg) Low UID (avg) High UID (2σ) Low UID (2σ) High UID (3σ) Low UID (3σ) High UID (var) Low UID (var) AIME2025 BRUNO2025 HMMT2025 MinervaMath Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std 0.413 0.500 0.500 0.500 0.267 0.567 0.267 0.533 0.267 0.567 0.567 0.333 0.387 0.433 0.433 0.433 0.267 0.467 0.267 0.467 0.267 0.467 0.433 0.333 0.413 0.500 0.500 0.500 0.267 0.567 0.267 0.533 0.267 0.567 0.567 0. 0.404 0.015 0.478 0.039 0.478 0.039 0.478 0.039 0.267 0.000 0.534 0.058 0.267 0.000 0.511 0.038 0.267 0.000 0.534 0.058 0.522 0.077 0.333 0.000 0.547 0.500 0.567 0.600 0.467 0.633 0.467 0.567 0.467 0.567 0.600 0.467 0.527 0.567 0.533 0.567 0.333 0.567 0.333 0.567 0.333 0.567 0.633 0. 0.533 0.500 0.467 0.500 0.367 0.533 0.367 0.567 0.367 0.533 0.700 0.433 0.536 0.010 0.522 0.039 0.522 0.051 0.556 0.051 0.389 0.070 0.578 0.050 0.389 0.070 0.567 0.000 0.389 0.070 0.556 0.019 0.644 0.052 0.444 0.019 0.240 0.300 0.267 0.267 0.133 0.267 0.133 0.300 0.133 0.300 0.300 0. 0.233 0.267 0.267 0.233 0.200 0.267 0.200 0.300 0.200 0.300 0.233 0.133 0.233 0.267 0.267 0.233 0.200 0.267 0.200 0.300 0.200 0.300 0.233 0.133 0.235 0.004 0.278 0.019 0.267 0.000 0.244 0.020 0.178 0.039 0.267 0.000 0.178 0.039 0.300 0.000 0.178 0.039 0.300 0.000 0.256 0.039 0.156 0. 0.297 0.305 0.305 0.298 0.261 0.308 0.266 0.302 0.257 0.305 0.298 0.279 0.294 0.301 0.305 0.305 0.279 0.313 0.268 0.324 0.268 0.324 0.313 0.283 0.297 0.305 0.305 0.298 0.261 0.309 0.266 0.302 0.257 0.305 0.298 0. 0.296 0.002 0.304 0.002 0.305 0.000 0.300 0.004 0.267 0.010 0.310 0.003 0.267 0.001 0.309 0.013 0.261 0.006 0.311 0.011 0.303 0.009 0.280 0.002 Table 7: Scaling. Results of Qwen3-8B on four math benchmarks (AIME2025, BRUMO2025, HMMT2025, and MinervaMath). Performance is reported across seeds 42, 1234, and 2025, with averages and standard deviations (Avg Std). Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (avg) Low UID (avg) High UID (2σ) Low UID (2σ) High UID (3σ) Low UID (3σ) High UID (var) Low UID (var) AIME2025 BRUMO2025 HMMT2025 MinervaMath Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std 0.660 0.633 0.600 0.600 0.667 0.667 0.633 0.667 0.633 0.667 0.700 0.667 0.660 0.633 0.600 0.600 0.667 0.667 0.633 0.667 0.633 0.667 0.700 0.667 0.680 0.633 0.600 0.600 0.633 0.767 0.633 0.733 0.633 0.733 0.700 0. 0.667 0.009 0.633 0.000 0.600 0.000 0.600 0.000 0.656 0.016 0.700 0.047 0.633 0.000 0.689 0.031 0.633 0.000 0.689 0.031 0.700 0.000 0.656 0.016 0.667 0.700 0.633 0.633 0.600 0.633 0.533 0.667 0.533 0.667 0.533 0.600 0.707 0.733 0.667 0.700 0.700 0.700 0.700 0.733 0.700 0.733 0.633 0. 0.673 0.700 0.600 0.600 0.667 0.700 0.667 0.700 0.667 0.700 0.667 0.667 0.682 0.018 0.711 0.016 0.633 0.027 0.644 0.042 0.656 0.042 0.678 0.032 0.633 0.072 0.700 0.027 0.633 0.072 0.700 0.027 0.611 0.057 0.678 0.069 0.440 0.500 0.500 0.500 0.367 0.533 0.433 0.533 0.433 0.533 0.500 0. 0.407 0.467 0.400 0.400 0.367 0.400 0.367 0.400 0.367 0.433 0.467 0.400 0.427 0.533 0.367 0.400 0.367 0.500 0.400 0.467 0.400 0.467 0.433 0.400 0.425 0.014 0.500 0.027 0.422 0.057 0.433 0.047 0.367 0.000 0.478 0.057 0.400 0.027 0.467 0.054 0.400 0.027 0.478 0.042 0.467 0.027 0.411 0. 0.337 0.342 0.331 0.338 0.349 0.330 0.353 0.342 0.349 0.338 0.346 0.346 0.342 0.353 0.342 0.338 0.338 0.335 0.335 0.338 0.335 0.342 0.331 0.349 0.329 0.335 0.327 0.324 0.316 0.338 0.320 0.327 0.320 0.327 0.319 0. 0.336 0.005 0.343 0.007 0.333 0.006 0.333 0.007 0.334 0.014 0.334 0.003 0.336 0.013 0.336 0.006 0.335 0.012 0.336 0.006 0.332 0.011 0.335 0.019 Table 8: Model Size Analysis. Results of Qwen3 models (1.7B, 4B, 8B) on AIME2025. Performance is reported across seeds 42, 1234, and 2025, with averages and standard deviations (Avg Std). Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (avg) Low UID (avg) High UID (2σ) Low UID (2σ) High UID (3σ) Low UID (3σ) High UID (var) Low UID (var) 1.7B 4B 8B Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std 0.327 0.400 0.333 0.333 0.233 0.433 0.200 0.433 0.200 0.433 0.367 0.300 0.340 0.467 0.333 0. 0.333 0.400 0.300 0.433 0.300 0.433 0.300 0.367 0.367 0.467 0.433 0.433 0.233 0.433 0.233 0.367 0.233 0.367 0.433 0.333 0.3450.020 0.4450.039 0.3660.058 0.3660.058 0.2660.058 0.4220.019 0.2440.051 0.4110.038 0.2440.051 0.4110.038 0.3670.067 0.3330.034 0.660 0.767 0.667 0. 0.533 0.733 0.533 0.700 0.533 0.700 0.700 0.600 0.653 0.700 0.567 0.567 0.533 0.700 0.567 0.733 0.567 0.700 0.633 0.733 0.640 0.733 0.633 0.600 0.500 0.667 0.533 0.700 0.533 0.667 0.633 0.667 0.6510.010 0.7330.034 0.6220.051 0.6330. 0.5220.019 0.7000.033 0.5440.020 0.7110.019 0.5440.020 0.6890.019 0.6550.039 0.6670.067 0.660 0.633 0.600 0.600 0.667 0.667 0.633 0.667 0.633 0.667 0.700 0.667 0.660 0.633 0.600 0.600 0.660 0.667 0.633 0.667 0.633 0.667 0.700 0.667 0.680 0.633 0.600 0. 0.633 0.767 0.633 0.733 0.633 0.733 0.700 0.633 0.6670.012 0.6330.000 0.6000.000 0.6000.000 0.6530.018 0.7000.058 0.6330.000 0.6890.038 0.6330.000 0.6890.038 0.7000.000 0.6560.020 Table 9: Sampling strategies. Results across different sampling strategies (Sample by 5, 10, and 15) on AIME2025. Performance is reported across seeds 42, 1234, and 2025, with averages and standard deviations (Avg Std). Methods () Overall Acc Self-Certainty High Conf Low Ent High UID (avg) Low UID (avg) High UID (2σ) Low UID (2σ) High UID (3σ) Low UID (3σ) High UID (var) Low UID (var) Sample by 5 Sample by 10 Sample by 15 Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std Seed 42 Seed 1234 Seed 2025 Avg Std 0.660 0.633 0.600 0.600 0.667 0.667 0.633 0.667 0.633 0.667 0.700 0. 0.660 0.633 0.600 0.600 0.667 0.667 0.633 0.667 0.633 0.667 0.700 0.667 0.680 0.633 0.600 0.600 0.633 0.767 0.633 0.733 0.633 0.733 0.700 0.633 0.6670.009 0.6330.000 0.6000.000 0.6000.000 0.6560.016 0.7000.047 0.6330.000 0.6890.031 0.6330.000 0.6890.031 0.7000.000 0.6560. 0.680 0.567 0.567 0.500 0.567 0.667 0.500 0.700 0.500 0.700 0.700 0.633 0.673 0.633 0.533 0.567 0.533 0.733 0.500 0.733 0.500 0.733 0.667 0.633 0.693 0.667 0.600 0.600 0.667 0.700 0.600 0.733 0.600 0.733 0.733 0. 0.6820.008 0.6220.042 0.5670.027 0.5560.042 0.5890.057 0.7000.027 0.5330.047 0.7220.016 0.5330.047 0.7220.016 0.7000.027 0.6330.000 0.687 0.633 0.533 0.633 0.700 0.633 0.700 0.633 0.700 0.633 0.667 0.600 0.678 0.733 0.533 0.567 0.567 0.667 0.600 0.667 0.600 0.667 0.600 0. 0.683 0.633 0.500 0.500 0.600 0.667 0.567 0.667 0.567 0.667 0.667 0.633 0.6830.004 0.6660.047 0.5220.016 0.5670.054 0.6220.057 0.6560.016 0.6220.057 0.6560.016 0.6220.057 0.6560.016 0.6450.032 0.6220.016 Figure 16: Reasoning trace with the highest variance score, with rich reasoning. math_equal is True Figure 17: Reasoning trace with the lowest variance score, showing that the model is stuck. math_equal is False"
        }
    ],
    "affiliations": [
        "OneLine AI",
        "Yonsei University"
    ]
}