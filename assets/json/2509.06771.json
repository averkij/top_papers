{
    "paper_title": "D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning",
    "authors": [
        "Sai Kartheek Reddy Kasu",
        "Mohammad Zia Ur Rehman",
        "Shahid Shafi Dar",
        "Rishi Bharat Junghare",
        "Dhanvin Sanjay Namboodiri",
        "Nagendra Kumar"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Dark humor in online memes poses unique challenges due to its reliance on implicit, sensitive, and culturally contextual cues. To address the lack of resources and methods for detecting dark humor in multimodal content, we introduce a novel dataset of 4,379 Reddit memes annotated for dark humor, target category (gender, mental health, violence, race, disability, and other), and a three-level intensity rating (mild, moderate, severe). Building on this resource, we propose a reasoning-augmented framework that first generates structured explanations for each meme using a Large Vision-Language Model (VLM). Through a Role-Reversal Self-Loop, VLM adopts the author's perspective to iteratively refine its explanations, ensuring completeness and alignment. We then extract textual features from both the OCR transcript and the self-refined reasoning via a text encoder, while visual features are obtained using a vision transformer. A Tri-stream Cross-Reasoning Network (TCRNet) fuses these three streams, text, image, and reasoning, via pairwise attention mechanisms, producing a unified representation for classification. Experimental results demonstrate that our approach outperforms strong baselines across three tasks: dark humor detection, target identification, and intensity prediction. The dataset, annotations, and code are released to facilitate further research in multimodal humor understanding and content moderation. Code and Dataset are available at: https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning"
        },
        {
            "title": "Start",
            "content": "D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning Sai Kartheek Reddy Kasu (Indian Institute of Information Technology Dharwad, India) Mohammad Zia Ur Rehman (Indian Institute of Technology Indore, India) Shahid Shafi Dar (Indian Institute of Technology Indore, India) Rishi Bharat Junghare (Indian Institute of Technology Indore, India) Dhanvin Sanjay Namboodiri (Malaviya National Institute of Technology Jaipur, India) Nagendra Kumar (Indian Institute of Technology Indore, India) Email(s): 21bds027@iiitdwd.ac.in, phd2101201005@iiti.ac.in, phd2201201004@iiti.ac.in, cse220001063@iiti.ac.in, 2022uec1253@mnit.ac.in, nagendra@iiti.ac.in These are co-first authors with equal contribution. Corresponsding author This is the preprint version of the accepted paper. Accepted in IEEE International Conference on Data Mining (ICDM), 2025 5 2 0 S 8 ] . [ 1 1 7 7 6 0 . 9 0 5 2 : r D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning Sai Kartheek Reddy Kasu Indian Institute of Information Technology Dharwad, India 21bds027@iiitdwd.ac.in Mohammad Zia Ur Rehman Indian Institute of Technology Indore, India phd2101201005@iiti.ac.in Shahid Shafi Dar Indian Institute of Technology Indore, India phd2201201004@iiti.ac.in Rishi Bharat Junghare Indian Institute of Technology Indore, India cse220001063@iiti.ac.in Dhanvin Sanjay Namboodiri Malaviya National Institute of Technology Jaipur, India 2022uec1253@mnit.ac.in Nagendra Kumar Indian Institute of Technology Indore, India nagendra@iiti.ac.in AbstractDark humor in online memes poses unique challenges due to its reliance on implicit, sensitive, and culturally contextual cues. To address the lack of resources and methods for detecting dark humor in multimodal content, we introduce novel dataset of 4,379 Reddit memes annotated for dark humor, target category (gender, mental health, violence, race, disability, and other), and three-level intensity rating (mild, moderate, severe). Building on this resource, we propose reasoning-augmented framework that first generates structured explanations for each meme using Large VisionLanguage Model (VLM). Through Role-Reversal Self-Loop, VLM adopts the authors perspective to iteratively refine its explanations, ensuring completeness and alignment. We then extract textual features from both the OCR transcript and the self-refined reasoning via text encoder, while visual features are obtained using vision transformer. Tri-stream Cross-Reasoning Network (TCRNet) fuses these three streams, text, image, and reasoning, via pairwise attention mechanisms, producing unified representation for classification. Experimental results demonstrate that our approach outperforms strong baselines across three tasks: dark humor detection, target identification, and intensity prediction. The dataset, annotations, and code are released to facilitate further research in multimodal humor understanding and content moderation. Code and Dataset Access: https://github.com/Sai-KartheekReddy/D-Humor-Dark-Humor-Understanding-via-MultimodalOpen-ended-Reasoning Index TermsMultimodal Data Mining, Dark Humor Detection, VLMs, Social Media Analysis, Content Moderation. Caution: This paper contains offensive content due to the nature of the topic, which may be disturbing or offensive to some readers. Reader discretion is advised. I. INTRODUCTION Dark humor represents challenging domain for data mining, as it uses subtle elements to convey complex, often controversial humor. The difference between conventional clean humor and dark humor can be quite subtle. While there can These are co-first authors with equal contribution. Corresponding author never be an objective way to distinguish them, there are some key identifiers for dark humor. Clean humor generally uses topics that everyone can relate to and collectively laugh at. On the other hand, dark humor exploits topics that are typically considered insensitive, as shown in Figure 1. According to Ruch et al. [1], dark humor typically incorporates one of four distinct elements, sarcasm, cynicism, satire, or irony, each characterized by unique linguistic and cognitive features that shape its expression. (a) Clean humor (b) Clean humor (c) Dark humor (d) Dark humor Fig. 1: comparison of clean and dark humor (Source: Reddit). However, in todays digital landscape, social media platforms frequently convey dark humor not just through linguistic expressions but also by image-text combinations [2], [3] such as memes, which add multimodal layer to their interpretation. While memes have become dominant form of online communication, detecting dark humor within them remains an underexplored problem due to the interplay between imagery, text, and cultural context. Effectively mining and detecting dark humor memes requires multimodal approaches capable of integrating textual and visual cues to accurately capture these subtle humor styles [4], [5]. Advancing automated detection in this space can significantly enhance content moderation, sentiment analysis, and the broader understanding of how humor operates in complex, multimodal social media data [6]. However, there exists no multimodal dark humor dataset, which limits progress in this underexplored yet critical area. to the best of our knowledge, To address the scarcity of resources for studying dark humor in memes, we introduce novel dataset comprising large collection of memes sourced from popular social media platforms, each containing both visual and textual components for comprehensive multimodal analysis. Annotators annotated the dataset not only to distinguish between dark humor and nondark humor memes in binary classification framework but also to identify target groups commonly referenced or affected by dark humor, including gender, mental health, violence, race, disability, and other sensitive categories. This granular labeling supports deeper exploration of the social and ethical dimensions embedded within dark humor, enabling both the technical challenge of humor detection and the analysis of its underlying themes and potential impacts in online meme culture. Since humor plays an important role in mental health [7], [8], our dataset could be an important resource. In addition to the dataset, we propose novel multimodal approach for dark humor detection in memes that harnesses the complementary strengths of large language models (LLMs) [9] and visual-textual feature extraction. Specifically, we first employ the Qwen-2.5-7B VisionLanguage Model to generate an initial structured reasoning for each meme, capturing highlevel contextual and inferential cues. Next, we apply an Iterative Reasoning Refinement via Role-Reversal Self-Loop. Qwen is prompted to become the original author of the meme and critically review its own explanation, verifying that each field (summary, implied joke, narrative structure, emotional effect, dark attributes, and target) is both faithful and complete. This role-reversal step mimics reflective human reasoning, encouraging the model to correct omissions or misalignments before yielding final, refined explanation. Textual features are then extracted from both the memes transcript using BERT and the self-refined reasoning using S-BERT, while visual features are obtained via ViT for multimodal representation learning. To effectively model the interplay among text, image, and reasoning, we employ Tri-stream CrossReasoning Network (TCRNet) that applies pairwise scaled dot-product attention across all three modalities. The resulting attended representations are concatenated into unified feature vector, which is passed to final classification head. This pipeline, combining self-refined reasoning with multimodal fusion, demonstrates the power of hybrid, alignment-aware architectures in capturing the nuanced affective and figurative characteristics of dark humor in social media memes. Key Contributions of this work are as follows: Dark Humor Meme Dataset: We introduce first multimodal dark humor dataset consisting of memes collected from Reddit. Each entry includes both image and OCRextracted text, annotated not only for binary dark humor versus non-dark humor, but also for target category ( gender, mental health, violence, race, disability, and other) and three-level intensity rating (mild, moderate, severe). This granular annotation enables detailed analysis of social and ethical dimensions in dark humor in memes. Iterative Self-Refined Reasoning: We use Qwen-2.57B VLM to generate an initial structured explanation (summary, implied joke, narrative, emotional effect, dark attributes, target). Then, via Role-Reversal Self-Loop, Qwen assumes the meme authors perspective to critique and refine its own reasoning, ensuring higher alignment and completeness before feature extraction. Reasoning-Enhanced Multimodal Framework: We propose multimodal architecture that fuses image embeddings, text embeddings, and embeddings of the selfrefined Qwen reasoning through Tri-stream CrossReasoning Network (TCRNet). Pairwise attention across the three streams captures implicit and semantic cues, yielding state-of-the-art performance on dark humor detection, target identification, and intensity prediction. II. LITERATURE REVIEW Dark humor, while increasingly present in online discourse, remains underexplored in computational linguistics. Unlike general humor detection, dark humor poses unique challenges due to its reliance on morally deviant, taboo, or emotionally provocative content. Ruch et al. [1] identify four rhetorical styles central to dark humor, sarcasm, cynicism, satire, and irony, each involving complex linguistic and psychological cues. While studies directly targeting dark humor are rare, significant advances have been made in detecting its constituent forms. Sarcasm detection has seen considerable progress, particularly through multimodal approaches. Bao et al. [10] proposed HIAN, which uses BiLSTM, attention, and transformers to fuse text, image, and class-based features, capturing crossmodal inconsistencies indicative of sarcasm. Gupta et al. [11] extended this with MLFTI, weighted multimodal fusion model combining text and visual cues in shared latent space, achieving 93% accuracy on Twitter data. Jia et al. [12] addressed generalization challenges with DMSD-CL, which uses counterfactual data augmentation and contrastive learning to reduce bias from spurious correlations. Liang et al. [13] introduced MMGCL, graph-based contrastive learning model that integrates text, OCR, and visual objects, effectively modeling sentiment incongruity, an important signal in sarcastic and darkly humorous content. Irony detection has also been actively explored. Saroj and Pal [14] demonstrated the importance of domain adaptation with an ensemble of contextual models fine-tuned for political discourse. Maladry et al. [15] achieved strong results in Dutch by combining transformer models with engineered sentimentclash features. In low-resource setting, Bolucu and Can [16] employed UCCA-based graph neural networks for Turkish irony detection, achieving an F1-score of 94.85%, and demonstrating the value of structured semantic modeling. Satire, though less studied, has seen recent computational advances. Goyal et al. [17] contrasted satire with sarcasm in multimodal framework, combining BERT, ResNet, and I3D to capture linguistic and visual nuances. Ortega-Bueno et al. [18] proposed MvAttLSTM, multilingual model that integrates linguistic, sentence-level, and contextual embeddings to detect satire and irony in Spanish. Kamal et al. [19] introduced BiSAT, BiLSTM with self-attention and handcrafted linguistic features, achieving strong results on short satirical texts across multiple datasets. While these studies provide robust foundation, several limitations remain. Most notably, research tends to treat sarcasm, irony, satire, and related styles as isolated tasks, overlooking the fact that they frequently co-occur or interact within single instance of humor, particularly in dark humor. Though there are few works [20], [21], cynicism remains virtually unexamined as computational task. Furthermore, many models are tailored to narrow domains or specific modalities, limiting their generalizability across contexts, cultures, and moral boundaries. These gaps highlight the necessity of framing sarcasm, irony, satire, and cynicism not as independent phenomena but as interrelated components of broader category, dark humor. unified modeling approach is essential to capture the layered, morally provocative, and affectively ambiguous nature of dark humor in real-world discourse. III. DATASET DESCRIPTION AND ANNOTATION PROCESS In this section, we describe the process of dataset collection and the annotation methodology employed. We detail the sources from which the data is gathered, the criteria used for selecting samples, and the steps taken to ensure annotation quality and consistency. This comprehensive overview provides the foundation for understanding the datasets structure and reliability for subsequent analysis. A. Dataset Collection and harmful content analysis. The actual annotations were carried out by three undergraduate computer science students who voluntarily participated with informed consent. As token of appreciation, they were granted access to A100 GPU resources for their own research. gold-standard seed set of 100 memes, balanced across dark and non-dark humor, was first annotated by the expert team. This dataset, along with detailed codebook, was used to train the student annotators. The codebook defined annotation criteria with examples for three subtasks: (i) dark humor identification, (ii) target of the humor, and (iii) intensity level. After the initial labeling round, annotation discrepancies were discussed collectively to refine interpretation and improve consistency. 1) Annotation Dimensions: Each meme was annotated across three distinct dimensions: Dark Humor (DH): Binary label indicating whether the meme contains dark humor. Target: The specific group, topic, or subject that is the focus of the memes humor (e.g., gender, mental health, disability). Intensity: The perceived intensity of the dark humor, annotated on three-level ordinal scale: Mild (1): Humor that is subtly dark or lightly suggestive. Moderate (2): Humor that is more direct and clearly involves sensitive theme. Severe (3): Highly explicit or extreme dark humor involving graphic or taboo content. C. Annotation in Batch Mode Following the training phase, the remaining memes were annotated in weekly batches of 200 memes. To mitigate potential cognitive fatigue from exposure to sensitive content, annotators were encouraged to take breaks of 1015 minutes after each set of 10 memes, aligning with recommendations in prior work on annotator well-being [22]. We also enforced soft cap of 50 memes per day to prevent overload. Regular check-in meetings were held to discuss any difficult cases, resolve annotation conflicts, and monitor the psychological impact of labeling dark content [23]. All annotations were finally reviewed by the supervising researchers to create high-quality, adjudicated gold-standard dataset. D. Inter-Annotator Agreement All memes in our dataset were sourced from Reddit. We used the Reddit API to retrieve posts containing both an image and accompanying text, and applied OCR to extract embedded text. subsequent manual screening eliminated the duplicates, resulting in high-quality corpus of 4,397 multimodal memes for annotation and analysis. B. Annotator Training"
        },
        {
            "title": "The annotation process was overseen by a faculty member\nand a PhD researcher with expertise in computational humor",
            "content": "To assess the consistency of annotations across annotators, we computed inter-annotator agreement scores using both pairwise Cohens Kappa and Fleiss Kappa. Table summarizes the results for the three annotation tasks: Dark Humor (DH), Target, and Intensity. For the dark humor task, unweighted Cohens Kappa scores ranged from 58.92 to 85.88 across annotator pairs, with Fleiss Kappa of 70.29, indicating substantial agreement. The target task yielded similarly strong results, with pairwise Cohens Kappa scores as high as 83.55 and Fleiss Kappa (a) Dark Humor: No Target: N/A Intensity: N/A (b) Dark Humor: Yes Target: Disability Intensity: 2 (c) Dark Humor: Yes Target: Gender/Sex Intensity: 3 (d) Dark Humor: Yes Target: Race/Ethnicity Intensity: (e) Dark Humor: Yes Target: Gender/Sex Intensity: 2 (f) Dark Humor: Yes Target: Mental Health Intensity: 2 (g) Dark Humor: Yes Target: Disability Intensity: 2 (h) Dark Humor: Yes Target: Violence/Death Intensity: 3 Fig. 2: subset of memes from D-Humor dataset, classified by their dark humor presence, target, and intensity. (Source: Reddit) of 72.13, reflecting high agreement on identifying the memes intended subject. TABLE I: Inter-annotator agreement scores. A: Annotator; DH: Dark Humor; Unwt: Unweighted; Wt: Weighted; Kappa: Cohens Kappa; Wt Kappa: Weighted Cohens Kappa; Kappa: Fleiss Kappa. Task DH Target Intensity Ann Pair A1&A2 A2&A3 A3&A1 A1&A2 A2&A3 A3&A1 A1&A2 A2&A3 A3&A UnWt Kappa Wt Kappa Kappa 66.05 85.88 58.92 70.31 83.55 62.47 53.24 76.59 45.89 - - - - - - 74.39 87.26 69.45 70.29 72. 58.57 The intensity task, which involves ordinal labels (mild, moderate, severe), naturally presents more subjectivity. We computed both unweighted and weighted Cohens Kappa for this task only, since weighted Kappa accounts for the degree in ordinal annotations. While unweighted of disagreement scores ranged from 45.89 to 76.59, the weighted Kappa values were significantly higher, reaching up to 87.26. The Fleiss Kappa for intensity was 58.57, suggesting moderate agreement overall. The use of annotator training, expert supervision, and structured annotation guidelines helped ensure consistent and replicable labeling across complex and sensitive humor categories. E. Dataset Statistics Table II presents detailed breakdown of our dataset across both training and test splits. The dataset consists of meme samples labeled for the presence or absence of dark humor, along with fine-grained annotations on their target category and humor intensity. sample of memes from the D-HUMOR dataset is shown in Figure 2. 1) Dark Humor Distribution: The training set contains total of 3,503 memes, with 1,577 labeled as containing dark humor and 1,926 as non-dark humor. The test set comprises 876 memes, including 397 positive and 479 negative samples. This relatively balanced distribution supports effective supervised training and facilitates fair evaluation. 2) Target Categories: Each meme labeled as dark humor was further annotated with the specific target of its humor. In the training set, the most frequently targeted categories are Gender/Sex-Related Topics (683 instances), followed by Other (351), and Mental Health (222). These three categories also dominate the test set distribution, indicating consistent prevalence across both data splits. 3) Intensity Levels: In the training data, the distribution is skewed toward lower intensity: 903 memes are rated as Mild, 466 as Moderate, and only 208 as Severe. similar trend appears in the test set, with 229, 132, and 46 memes across the three levels, respectively. This distribution reflects the realworld observation that while most dark humor is implicit or moderately suggestive, highly explicit content is comparatively rare. TABLE II: Summary of dataset Train Data Test Data Dark Humor No Yes Count 1,926 1,577 Dark Humor No Yes Count 479 397 Train Data: Target vs Intensity Test Data: Target vs Intensity Target Gender/Sex-Related Topics Mental Health Disability Race/Ethnicity Violence/Death Other Total 1 303 169 30 32 94 275 903 2 248 49 26 35 48 60 466 3 132 4 19 19 18 16 208 Total 683 222 75 86 160 351 1,577 Target Gender/Sex-Related Topics Mental Health Disability Race/Ethnicity Violence/Death Other Total 1 59 46 9 5 31 79 229 2 74 9 7 7 13 12 132 3 28 3 3 6 3 3 46 Total 161 58 19 18 47 94 397 Overall, this rich annotation framework provides valuable granularity for developing and benchmarking models that aim to understand not only the presence of dark humor but also its target and intensity. IV. METHODOLOGY Understanding dark humor in memes requires reasoning beyond literal content, as it often relies on abstract incongruity between text and visuals. To address this, we propose reasoning-augmented multimodal framework that leverages linguistic cues, image semantics, and inferred commonsense reasoning. The architecture, as shown in Figure 3, comprises five components: reasoning refinement, feature extraction, cross-attention fusion, feature aggregation, and final classification. A. Structured Reasoning Generation Understanding dark humor memes requires more than just identifying surface-level content. The humor often hinges on subtle context, cultural subtext, visual incongruities, and emotionally conflicting cues, many of which may be implicit, taboo, or deliberately ambiguous. These characteristics make dark humor memes uniquely challenging to interpret, both for humans and machines. To address this, we enrich the meme classification process with structured explanatory signals. By explicitly breaking down the reasoning behind memes humor, emotional tone, and target, we provide the model with additional context that aids in disambiguation. This additional supervision helps the model move beyond superficial patterns and capture the deeper intent and affective contrast that are typical in dark humor. Moreover, structured reasoning allows for improved transparency and interpretability, supporting downstream applications like content moderation, harm detection, and bias analysis. 1) Structured Explanation Schema: We design each explanation using six-part schema that captures distinct dimensions of the memes communicative intent and stylistic choices: 1) Meme Summary: concise description of the memes image and text. 2) Implied Joke: The core humorous element inferred from the meme. 3) Narrative Structure: The rhetorical style (e.g., sarcasm, irony, absurdism). 4) Emotional Effect: The emotional response the meme is designed to elicit. 5) Dark Attributes: Any presence of taboo, offensive, or socially sensitive themes. 6) Target: The entity, group, or concept being referenced or mocked. This decomposition facilitates fine-grained understanding, and the modular format can be encoded and fused with visionlanguage features during classification. 2) Iterative Reasoning Refinement via Role-Reversal SelfLoop: Interpreting dark humor requires not only visual-textual understanding but also alignment with nuanced social, cultural, and emotional cues, an area where even large models often fail. To bridge this gap, we propose novel technique called RoleReversal Self-Loop, simple yet powerful mechanism for enhancing AI alignment in tasks involving implicit reasoning and culturally sensitive content. After generating an initial structured reasoning using the Qwen-2.5-7B Vision-Language Model (VLM), we prompt the model to assume reversed role: it becomes the original author of the meme. Under this setup, the model is asked to review the reasoning it received for its own meme and critically assess whether the fields are faithful and complete as shown in Figure 4. This role-flip is psychologically aligned with reflective human behavior, encouraging the model to evaluate explanations with self-interested perspective, thereby improving alignment. This approach has two key benefits: It ensures that each explanation component is reviewed in context, preventing the model from over-focusing on only one field (e.g., the joke or the target). Fig. 3: Overview of the proposed reasoning-augmented multimodal architecture. Each meme (image + OCR text) is first processed by VLM to generate and refine structured explanation via the Role-Reversal Self-Loop mechanism. Text encoders encode the OCR transcript and the self-refined explanation into textual embeddings, while the image encoder extracts visual embeddings from the meme image. Tri-stream Cross-Reasoning Network (TCRNet) then applies pairwise scaled dot-product attention across the three modalities, text, image, and reasoning, to produce attended representations. These representations are concatenated into unified feature vector, which is passed through classification head to predict dark humor presence, target category, and intensity. Importantly, our manual review of subset of explanations revealed that most improvements were concentrated in the fields of Narrative Structure, Dark Attributes, and Implied Joke, components that demand deeper contextual reasoning. Fields like Meme Summary, Target, and Emotional Effect were more stable across iterations, suggesting they are more straightforward to interpret initially. Role-Reversal Self-Loop Prompt Template You are the author and creator of the given dark humor meme. Someone else has provided detailed explanation of your memes meaning, humor, and components, including the Meme Summary, Implied Joke, Narrative Structure, Emotional Effect, Dark Attributes, and Target. Your task is to review their explanation from your perspective as the original author. Analyze how well their reasoning aligns with your intended humor, message, tone, and overall context. For each component, identify any inaccuracies, missing details, or misunderstandings. Then, provide thorough, corrected explanation that fully reflects your original intent, ensuring clarity, accuracy, and completeness. Please present your revised explanation below. [Explanation Components Inserted Here] Fig. 4: Self-loop mechanism using Role Reversal (RR) Prompting. The input meme is passed to language model which generates an initial explanation. This explanation is then refined iteratively through Role Reversal prompting, where the model assumes the role of reviewer to critique and improve its own output. After such refinement cycles, final explanation is obtained. This mechanism enables the model to simulate self-awareness and improve explanatory coherence without external supervision. It encourages introspective correction without requiring external feedback or manual interventions, thereby improving scalability and automation. We apply this refinement loop iteratively for maximum of 5 epochs. On average, explanations converge and stabilize by approximately 3 epochs, indicating that the model typically needs only few rounds to self-correct and align its output. B. Feature Extraction"
        },
        {
            "title": "We concatenate the resulting vectors to obtain a unified",
            "content": "We extract embeddings from three modalities: the memes original transcript , the generated reasoning R, and the image I. Textual Features: We use the BERT model to encode both and into contextual token embeddings: FT = BERT(T ) R197768 FR = S-BERT(R) R197768 (1) (2) Each row corresponds to subword token in 768dimensional embedding space. Visual Features: We use the ViT model, which combines vision and language pretraining objectives, to extract features from the meme image: FI = ViT(I) R197768 (3) representation: = [vT ; vT R; vIR] R2,304 (11) This vector serves as the multimodal reasoning-aware representation fed into the final classification layer. E. Hyperparameters and System Description Table III lists the primary hyperparameters used for the proposed framework. Encoder-only text and image models share identical training configurations, while LLMs fine-tuned with QLoRA use 3 epochs and low-rank adaptation settings (r = 8, α = 32, dropout 0.1). The TCRNet additionally employs dropout (0.3) and eight attention heads in its training setup. TABLE III: Key hyperparameter configurations used across different model types. This representation captures visual cues such as objects, expressions, and contextual artifacts relevant to the meme. Model Type Encoder-Only Text Models C. Tri-stream Cross-Reasoning Network (TCRNet) To effectively model inter-modal interactions and capture reasoning-driven dependencies, we introduce Tri-stream Cross-Reasoning Network [24], [25]. This module enables each modality, text (T ), image (I), and LLM-generated reasoning (R), to mutually inform and align with one another by attending across pairs. Specifically, we use scaled dot-product attention to implement pairwise reasoning flows. Let QX = FXWQ, KY = FY WK, and VY = FY WV be the linear projections of modalities and , where X, {T, I, R}. The attention from to is computed as: Attn(X ) = softmax (cid:19) (cid:18) QX Y dk VY (4) This formulation allows modality to selectively extract context-aware signals from modality , thereby modeling semantic incongruity, visual-verbal contradictions, and inferential alignment, all of which are critical in dark humor. We compute such cross-reasoning across all three modality pairs: (cid:101)FT = Attn(T I) (cid:101)FT = Attn(T R) (cid:101)FIR = Attn(I R) (5) (6) (7) D. Feature Aggregation Each cross-reasoned output is aggregated using average pooling to yield fixed-length vectors: vT = AvgPool((cid:101)FT ) vT = AvgPool((cid:101)FT R) vIR = AvgPool((cid:101)FIR) (8) (9) (10) Hyperparameter Epochs Batch Size Learning Rate Epoch LoRA Rank (r) LoRA Alpha LoRA Dropout Target Modules Epochs Batch Size Learning Rate Epochs Batch Size Learning Rate Dropout Attention Heads Value 5 16 0.00002 3 8 32 0.1 proj, proj 5 16 0.00002 5 16 0.00002 0.3 8 LLMs with QLoRA Image Models TCRNet All experiments were conducted on server equipped with Intel(R) Xeon(R) Silver 4316 CPU @ 2.30GHz, 4 NVIDIA A16 GPUs (each with 16 GB VRAM), running CUDA 12.8 and driver version 570.133.07. The training utilized PyTorch with GPU acceleration, and computations were distributed using single GPU unless specified otherwise. V. RESULTS AND DISCUSSION A. Experimental Findings Table IV presents comprehensive evaluation of various models on three tasks: dark humor detection (binary classification), target identification (multi-class classification), and intensity prediction. We report Accuracy, Macro-F1, and Weighted-F1 for all tasks, and additionally include Pearson correlation for intensity prediction, as it is ordinal. When relying solely on OCR-extracted text, pretrained models like BERT, DistilBERT, and LLaMA achieve reasonable performance for dark humor detection. LLaMA leads with 71.72% accuracy and Macro-F1 of 71.14%. However, these textonly systems struggle to identify the specific target of the humor and to gauge its intensity. For instance, DistilBERTs target identification Macro-F1 is only 55.98%, and BERTs intensity Pearson correlation is modest 27.18%. These results indicate that while textual cues carry considerable information TABLE IV: Evaluation of various models across different input modalities for dark humor meme analysis. The highest performance in each metric is highlighted in bold, while the second-best performance is marked with symbol. P-corr denotes the Pearson correlation coefficient used to evaluate the ordinal classification task for Intensity. Model Dark Humor (Yes/No) Accuracy Macro-F1 Wt-F Target Accuracy Macro-F1 Wt-F1 Accuracy Macro-F1 Wt-F1 P-Corr. Intensity 57.76 64.04 64.95 57.69 62.82 64. 69.75 69.55 71.45 70.05 69.81 71.72 69.41 69.23 71.14 OCR Text Only BERT [26] Distil-BERT [27] Llama-3.2-3b-it [28] Image Only CLIP [29] ViT [30] BLIP [31] VLMs (Prompt based Zero-Shot) Qwen-2.5-7b-it [32] LLaVA-1.6-mistral-7b [33] OCR Text + Structured Explanation (with Role-Reversal Prompting) 71.24 BERT 70.53 Distil-BERT 73.39 Llama-3.2-3b-it VLMs (Prompt based Zero-Shot with Role-Reversal Prompting) 64.04 Qwen-2.5-7b-it 46.80 LLaVA-1.6-mistral-7b 75.00 TCRNet (ours) 71.13 70.32 73.19 70.88 70.02 72.91 64.02 35.40 73.55 63.95 32.86 74.13 57.85 63.45 64.72 64.27 45.32 63.83 28.27 63.26 31. 59.69 61.50 54.52 37.53 45.59 44.84 57.68 48.87 55.67 49.62 64.48 65.37 66.41 59.17 53.27 55.98 38. 35.43 32.76 40.53 53.70 48.30 61.67 62.53 50.37 50.97 51.44 60.54 59.53 60.91 51.96 38.47 39.86 43. 56.28 49.14 65.42 66.07 57.62 55.01 50.03 64.17 58.91 55.81 57.62 46.59 45.75 37.41 57.63 55.22 52. 40.30 54.66 58.19 17.63 30.23 56.33 55.56 58.14 29.22 37.03 62.72 31.18 36.22 41.69 15.27 24. 43.16 43.98 37.94 28.97 34.41 49.71 40.72 51.14 54.40 14.14 29.92 55.10 54.95 53.76 29.33 39.35 60. 27.18 26.25 17.05 2.40 7.14 19.96 17.50 11.48 32.12 32.56 24.4 11.84 15.22 38.63 for detecting the presence of dark humor, they lack the broader context and implicit signals needed to pinpoint whom or what the joke is aimed at, and how severe it is. Purely image-based models, such as CLIP, ViT, and BLIP, underperform compared to text-only baselines. BLIP achieves the highest image-only dark humor accuracy at 64.95%, but target identification accuracy remains below 45% and intensity accuracy under 60%. The Pearson correlation for intensity is especially low, for instance, 19.96% for BLIP. This suggests that, although visual features capture facial expressions, color palettes, and scene context, they fail to convey the nuanced semantics that define dark humor. In other words, imagery alone lacks the explicit linguistic content that often carries the punchline or the taboo reference. Zero-shot vision-language models, such as Qwen-VL and Next-LLaVA-VL, demonstrate limited effectiveness without task-specific fine-tuning. Qwen-VL achieves 64.27% dark humor accuracy and 17.50% intensity correlation, while NextLLaVA-VL lags further behind (45.32% accuracy for humor detection, 11.48% intensity correlation). Even when provided with structured explanations as prompts, these VLMs show only marginal improvements. For example, Next-LLaVA-VLs intensity correlation rises from 11.48% to 15.22% with explanations, but remains far below the performance of models trained on text-plus-explanation inputs. These observations highlight that, although large VLMs contain rich pretraining knowledge, they still require supervised adaptation to handle the implicit, sensitive nature of dark humor. Augmenting OCR text with structured explanations yields consistent and substantive gains across all tasks. Under the OCR Text + Structured Explanation setting, BERTs dark humor accuracy increases from 70.05% to 71.24%, and DistilBERTs target Macro-F1 jumps from 55.98% to 62.53%. Most notably, intensity Pearson correlation for DistilBERT improves from 26.25% to 32.56%. These results underline that structured explanations, capturing implied jokes, narrative structure, and emotional effect, supplement raw text with crucial contextual cues. Even LLaMA, which already performs well with text alone, sees its dark humor accuracy rise to 73.39% when explanations are included, confirming that reasoning signals complement large language model outputs. Our proposed TCRNet model, which implements Tristream Cross-Reasoning Network to fuse OCR text, image features, and structured explanations, achieves the best overall results. TCRNet attains 75.00% accuracy on dark humor detection and 62.72% accuracy on intensity prediction, both the highest scores among all evaluated methods. By explicitly aligning visual and textual streams with reasoning-derived explanations, TCRNet captures implicit associations and semantic incongruities that single-modality or non-reasoning models miss. These improvements demonstrate that reasoning-aware, multimodal fusion is essential for accurately understanding and categorizing dark humor memes. VI. ABLATION STUDY From the ablation study presented in Figure 5, it is evident that the reasoning component based on structured explanations plays critical role in enhancing the performance of TCRNet across all three tasks. When the explanation modality is removed, there is substantial drop in performance, particularly in Target Identification (Macro-F1 drops from 60.54 to 35.11) and Dark Humor Classification (Weighted-F1 drops from 74.13 to 67.31). This clearly indicates that dark humor memes often rely on implicit, nuanced reasoning that goes beyond surface-level textual or visual cues. Unlike typical classification problems, where raw OCR text or image features might suffice, dark humor detection (a) Dark humor (b) Target identification (c) Intensity prediction Fig. 5: The charts represent an ablation study of TCRNet on Dark Humor Meme Analysis. Each ablation removes one component (OCR Text, Image, or Explanation) to study its impact. The full TCRNet results are included in Table IV. demands an externalized and structured interpretive view. The explanation-based features help the model contextualize morally ambiguous content, sarcasm, or deception, which are often difficult to infer directly from the raw input. These findings emphasize the importance of integrating explicit reasoning mechanisms into multimodal understanding systems, especially for complex, subjective tasks like dark humor analysis. VII. CONCLUSION In this work, we introduced the D-Humor dataset, multimodal collection of 4,397 Reddit memes annotated for dark humor (yes/no), target category (gender, mental health, violence, race, disability, other), and three-level intensity rating (mild, moderate, severe). We further proposed reasoningaugmented framework that first generates and self-refines structured explanations using Qwen-2.5-7B VLM, then fuses OCR text, ViT-based image features, and refined reasoning via Tri-stream Cross-Reasoning Network (TCRNet). Experimental results across three tasks, dark humor detection, target identification, and intensity prediction, demonstrate that (1) text-only or image-only models are insufficient for capturing the nuances of dark humor, (2) zero-shot vision-language models underperform without fine-tuning, and (3) augmenting OCR text with structured explanations yields consistent gains. Our proposed TCRNet achieves state-of-the-art performance, attaining 75.00% accuracy on dark humor detection and 62.72% accuracy on intensity prediction, outperforming all baselines by significant margin. An ablation study confirms that the structured explanation component is critical: removing explanations leads to dramatic drop in Target Identification Macro-F1 (from 60.54% to 35.11%) and Dark Humor Weighted-F1 (from 74.13% to 67.31%). These findings highlight that dark humor in memes relies on implicit, context-dependent cues, such as implied jokes and emotional effect, that cannot be inferred from raw text or images alone, necessitating explicit reasoning signals. While we acknowledge that D-Humor is skewed toward the Gender/Sex-Related Topics label, likely reflecting the greater availability of such content online, models trained on this data generalize well across all categories and do not exhibit overfitting. For future work, we plan to expand the dataset with additional target classes to enable finer-grained analyses, as well as investigate semi-supervised and selfsupervised techniques to further improve generalization to emerging dark humor trends. We also aim to explore more advanced alignment mechanisms within the Tri-stream CrossReasoning framework to better capture evolving cultural and social nuances in online humor."
        },
        {
            "title": "ETHICAL CONSIDERATION",
            "content": "We propose the D-Humor Dataset as novel resource to study dark humor in memes. Due to the sensitive and potentially offensive nature of the content, users should exercise caution and follow ethical guidelines when handling the data. The dataset is intended exclusively for academic and research purposes aimed at advancing understanding in this domain. To protect the privacy of individuals and maintain data integrity, public redistribution, sharing, or any unauthorized dissemination of the dataset is strictly prohibited. Access will be granted only upon signing data usage agreement."
        },
        {
            "title": "REDDIT ETHICAL POLICY FOR SCRAPING THE MEMES",
            "content": "In conducting our D-Humor Project, we collected publicly available memes from Reddit, ensuring strict adherence to Reddits Privacy Policy and Public Content Policy.1 Reddit emphasizes user anonymity by not requiring real names or photos, stripping metadata from shared media, and prohibiting doxxing. Our data collection excluded any personally identifiable information, such as usernames, email addresses, or IP data, focusing solely on content that users have made publicly accessible. Reddits Public Content Policy permits the use of public posts and comments for research, provided that user privacy is respected and content is not used for surveillance or identification.2 We also ensured that no deleted or private content was included, aligning with Reddits guidelines that prohibit unauthorized scraping and highlight the importance of user consent and data protection. We took care to follow the platforms stated policies and norms regarding data usage.3 1https://www.redditinc.com/policies/privacy-policy 2https://support.reddithelp.com/hc/en-us/articles/26410290525844 3https://www.redditinc.com/policies/user-agreement-april-18-2023 ACKNOWLEDGMENT The authors thank IIT Indore for providing financial support for the registration of the article. The authors thank the UGC Junior Research Fellowship (UGC-JRF) scheme, an initiative of the Government of India, for providing the Ph.D. fellowship to Mohammad Zia Ur Rehman (NTA Ref. No.: 190510846524). The authors are also thankful for the Young Faculty Research Catalysing Grant (YFRCG) by the Indian Institute of Technology Indore for providing the resources to the project (Project ID: IITI/YFRCG/2023-24/03)."
        },
        {
            "title": "REFERENCES",
            "content": "[1] W. Ruch, S. Heintz, T. Platt, L. Wagner, and R. T. Proyer, Broadening humor: Comic styles differentially tap into temperament, character, and ability, Frontiers in psychology, vol. 9, p. 6, 2018. [2] Y. Li, Y. Li, S. Zhang, G. Liu, Y. Chen, R. Shang, and L. Jiao, An attention-based, context-aware multimodal fusion method for sarcasm detection using inter-modality inconsistency, Knowledge-Based Systems, vol. 287, p. 111457, 2024. [3] Z. Xi, B. Yu, and H. Wang, Multimodal sarcasm detection based on sentiment-clue inconsistency global detection fusion network, Expert Systems with Applications, vol. 275, p. 127020, 2025. [4] M. Rahman, M. A.-M. Provath, K. Deb, P. K. Dhar, and T. Shimamura, Camfusion: Context-aware multi-modal fusion framework for detecting sarcasm and humor integrating video and textual cues, IEEE Access, 2025. [5] A. K. Singh, G. Kim, J. Kim, H.-m. Park, B. J. Choi, and W. De Neve, Ramm: residual attention multimodal model for humor detection, in International Conference on Intelligent Human Computer Interaction. Springer, 2025, pp. 229240. [6] M. Z. U. Rehman, D. Raghuvanshi, U. Jain, S. Bansal, and N. Kumar, multimodal-multitask framework with cross-modal relation and hierarchical interactive attention for semantic comprehension, Information Fusion, p. 103628, 2025. [7] A. Szabo, The acute effects of humor and exercise on mood and anxiety, Journal of leisure research, vol. 35, no. 2, pp. 152162, 2003. [8] J. Basler, D. Poto, M. Ferincz, S. Karpati, and A. N. Zsido, Why arent you laughing?the effect of dark and light humor on anxiety and affective state, Personality and Individual Differences, vol. 240, p. 113133, 2025. [9] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., Language models are few-shot learners, Advances in neural information processing systems, vol. 33, pp. 18771901, 2020. [10] Y. Bao, X. Zhao, P. Zhang, Y. Qi, and H. Li, Hian: hybrid interactive attention network for multimodal sarcasm detection, Pattern Recognition, vol. 164, p. 111535, 2025. [11] A. Gupta, A. Mittal, and R. Jain, novel sarcasm detection approach for text-image data: Leveraging multimodal fusion and weighted latent factors, Information Fusion, p. 103266, 2025. [12] M. Jia, C. Xie, and L. Jing, Debiasing multimodal sarcasm detection with contrastive learning, in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 16, 2024, pp. 18 35418 362. [13] B. Liang, L. Gui, Y. He, E. Cambria, and R. Xu, Fusion and discrimination: multimodal graph contrastive learning framework for multimodal sarcasm detection, IEEE Transactions on Affective Computing, 2024. [14] A. Saroj and S. Pal, Ensemble-based domain adaptation on social media posts for irony detection, Multimedia Tools and Applications, vol. 83, no. 8, pp. 23 24923 268, 2024. [15] A. Maladry, E. Lefever, C. Van Hee, and V. Hoste, The limitations of irony detection in dutch social media, Language Resources and Evaluation, vol. 58, no. 4, pp. 13551386, 2024. [16] N. Bolucu and B. Can, Semantically-informed graph neural networks for irony detection in turkish, ACM Transactions on Asian and LowResource Language Information Processing, vol. 24, no. 1, pp. 120, 2025. [17] D. Goyal, S. K. Mishra, and V. K. Rai, multimodal framework for satire vs. sarcasm detection, in 2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT). IEEE, 2024, pp. 17. [18] R. Ortega-Bueno, P. Rosso, and J. E. M. Pagola, Multi-view informed attention-based model for irony and satire detection in spanish variants, Knowledge-Based Systems, vol. 235, p. 107597, 2022. [19] A. Kamal, M. Abulaish et al., Contextualized satire detection in short texts using deep learning techniques, Journal of Web Engineering, vol. 23, no. 1, pp. 2752, 2024. [20] O. Ogbanufe, M. C. Jones, and J. I. Hancock, Job demands, identity, and outcomes: The mediating role of cynicism among cybersecurityfocused employees, Computers & Security, vol. 150, p. 104277, 2025. [21] Q. Liu, L. Wang, and M. Luo, When seeing is not believing: selfefficacy and cynicism in the era of intelligent media, Humanities and Social Sciences Communications, vol. 12, no. 1, pp. 113, 2025. [22] M. L. Ybarra, K. J. Mitchell, J. Wolak, and D. Finkelhor, Examining characteristics and associated distress related to internet harassment: findings from the second youth internet safety survey, Pediatrics, vol. 118, no. 4, pp. e1169e1177, 2006. [23] M. Z. U. Rehman, A. Bhatnagar, O. Kabde, S. Bansal, and N. Kumar, Implihatevid: benchmark dataset and two-stage contrastive learning framework for implicit hate speech detection in videos, in Proceedings of the Association for Computational Linguistics (Volume 1: Long Papers), 2025, pp. 17 20917 221. [24] Y. Zhou, Z. Chen, and H. Yang, Multimodal learning for hateful memes detection, in 2021 IEEE International conference on multimedia & expo workshops (ICMEW). IEEE, 2021, pp. 16. the 63rd Annual Meeting of [25] Y. Tang, L. Zhang, Q. Teng, F. Min, and A. Song, Triple cross-domain attention on human activity recognition using wearable sensors, IEEE Transactions on Emerging Topics in Computational Intelligence, vol. 6, no. 5, pp. 11671176, 2022. [26] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, in Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers), 2019, pp. 41714186. [27] V. Sanh, L. Debut, J. Chaumond, and T. Wolf, Distilbert, distilled version of bert: smaller, faster, cheaper and lighter, arXiv preprint arXiv:1910.01108, 2019. [28] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, F. Azhar et al., Llama: Open and efficient foundation language models, arXiv preprint arXiv:2302.13971, 2023. [29] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark et al., Learning transferable language supervision, in International visual models from natural conference on machine learning. PmLR, 2021, pp. 87488763. [30] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al., An image is worth 16x16 words: Transformers for image recognition at scale, in International Conference on Learning Representations, 2021. [31] J. Li, D. Li, C. Xiong, and S. Hoi, Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation, in International conference on machine learning. PMLR, 2022, pp. 12 88812 900. [32] Qwen Team, Qwen2.5-7B-Instruct, https://huggingface.co/Qwen/ Qwen2.5-7B-Instruct, 2025, [Online; accessed 2-June-2025]. [33] H. Liu, C. Li, Q. Wu, and Y. J. Lee, Visual instruction tuning, Advances in neural information processing systems, vol. 36, pp. 34 892 34 916, 2023."
        }
    ],
    "affiliations": [
        "Indian Institute of Information Technology Dharwad, India",
        "Indian Institute of Technology Indore, India",
        "Malaviya National Institute of Technology Jaipur, India"
    ]
}