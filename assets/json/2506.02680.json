{
    "paper_title": "Solving Inverse Problems with FLAIR",
    "authors": [
        "Julius Erbach",
        "Dominik Narnhofer",
        "Andreas Dombos",
        "Bernt Schiele",
        "Jan Eric Lenssen",
        "Konrad Schindler"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Flow-based latent generative models such as Stable Diffusion 3 are able to generate images with remarkable quality, even enabling photorealistic text-to-image generation. Their impressive performance suggests that these models should also constitute powerful priors for inverse imaging problems, but that approach has not yet led to comparable fidelity. There are several key obstacles: (i) the encoding into a lower-dimensional latent space makes the underlying (forward) mapping non-linear; (ii) the data likelihood term is usually intractable; and (iii) learned generative models struggle to recover rare, atypical data modes during inference. We present FLAIR, a novel training free variational framework that leverages flow-based generative models as a prior for inverse problems. To that end, we introduce a variational objective for flow matching that is agnostic to the type of degradation, and combine it with deterministic trajectory adjustments to recover atypical modes. To enforce exact consistency with the observed data, we decouple the optimization of the data fidelity and regularization terms. Moreover, we introduce a time-dependent calibration scheme in which the strength of the regularization is modulated according to off-line accuracy estimates. Results on standard imaging benchmarks demonstrate that FLAIR consistently outperforms existing diffusion- and flow-based methods in terms of reconstruction quality and sample diversity."
        },
        {
            "title": "Start",
            "content": "Julius Erbach1,2 Dominik Narnhofer1 Andreas Dombos1 1ETH Zürich Bernt Schiele2 Jan Eric Lenssen2 Konrad Schindler1 2Max Planck Institute for Informatics, Saarland Informatics Campus 5 2 0 2 J 3 ] . [ 1 0 8 6 2 0 . 6 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Flow-based latent generative models such as Stable Diffusion 3 are able to generate images with remarkable quality, even enabling photorealistic text-to-image generation. Their impressive performance suggests that these models should also constitute powerful priors for inverse imaging problems, but that approach has not yet led to comparable fidelity. There are several key obstacles: (i) the encoding into lower-dimensional latent space makes the underlying (forward) mapping non-linear; (ii) the data likelihood term is usually intractable; and (iii) learned generative models struggle to recover rare, atypical data modes during inference. We present FLAIR, novel training free variational framework that leverages flowbased generative models as prior for inverse problems. To that end, we introduce variational objective for flow matching that is agnostic to the type of degradation, and combine it with deterministic trajectory adjustments to recover atypical modes. To enforce exact consistency with the observed data, we decouple the optimization of the data fidelity and regularization terms. Moreover, we introduce time-dependent calibration scheme in which the strength of the regularization is modulated according to off-line accuracy estimates. Results on standard imaging benchmarks demonstrate that FLAIR consistently outperforms existing diffusionand flow-based methods in terms of reconstruction quality and sample diversity."
        },
        {
            "title": "Introduction",
            "content": "Flow-based generative models are at the core of modern image generators like Stable Diffusion or FLUX [14]. Beyond image generation based on text prompts, these models have emerged as powerful data-driven priors for whole range of visual computing tasks. Their comprehensive representation of the visual world, learned from internet-scale training datasets, makes them an attractive alternative to traditional handcrafted image priors. Often, they can be used without any task-specific retraining. While it is evident that model capable of generating photorealistic images should be suitable as prior (a.k.a. regularizer) for inverse imaging problems, practical implementation faces several challenges. On the one hand, flow-based models normally operate in the lower-dimensional latent space of variational autoencoder (VAE), which means that the forward operator (the relationship between the observed, degraded image and the desired, clean target image) is no longer linear. On the other hand, the iterative nature of the generative process means that intermediate stages are corrupted with (time-dependent) random noise. Hence, one cannot explicitly evaluate their data likelihood, which renders the data term intractable. Moreover, learned generative models tend to overly favor regions of the training distribution that have high sample density. For test samples that fall in low-density regions, the prior will have too strong tendency to pull towards outputs with higher a-priori likelihood, compromising fidelity to the input observations. Here, we propose flow-based latent adaptive inference with deterministic re-noising (FLAIR), novel training free variational framework explicitly tailored to integrate flow-based latent diffusion models into inverse problem-solving. To the best of our knowledge, FLAIR is the first scheme that combines Preprint. Figure 1: Starting from the adjoint based initialization, we alternate between (i) regularizer updates via flow-matching loss that aligns the posterior velocity ut with the learned velocity field vθ, and (ii) hard data consistency steps that project the current estimate onto the measurement manifold. latent generative modeling, flow matching and variational inference into unified formulation for inverse problems. Our main contributions are novel variational objective for inverse problems with flow-matching priors. Deterministic trajectory adjustments to robustly handle rare or atypical data scenarios. Decoupled optimization of data and regularization terms, enabling hard data consistency. novel, time-dependent weighting scheme, calibrated via offline accuracy estimates, that adapts the regularization along the flow trajectory to match the changing reliability of the models predictions, ensuring robust inference."
        },
        {
            "title": "2 Related Work",
            "content": "Deep learning based priors. Deep learningbased methods typically follow one of two main approaches: they either directly learn an inverse mapping [25, 18, 27, 4], or aim to learn suitable prior, either through non-generative approaches like unrolled optimization networks [15, 26, 1, 32] or through generative models such as generative adversarial networks [33, 7, 41], or diffusion [17, 44, 47] respectively flow based models [28, 30]. The latter have demonstrated impressive performance in image generation tasks, sparking growing interest in leveraging them as priors for solving inverse problems, particularly through posterior sampling techniques. Posterior sampling. Although incorporating the prior learned from diffusion or flowbased model seems straightforward, problems arise due to the inherent time-dependent structure of diffusion models, which makes the likelihood term intractable [11]. variety of approaches have been proposed for diffusion-based posterior sampling, including, enforcing the trajectory to stay on the respective noise manifold [11, 12], applying an SVD to run diffusion in spectral domain [22], utilizing range-null space decomposition during the reverse diffusion process [22], guidance by the pseudo-inverse of the forward operator [45]. Many prior methods perform well in pixel space but are difficult to apply in latent diffusion models due to VAE non-linearity or memory constraints. In order to circumvent this issue, the authors of ReSample [43] rely on enforcing hard data consistency through optimization and resampling during the reverse diffusion process. PSLD [38], introduces additional objectives terms in order to ensure that all gradient updates point to the same optima in the latent space. FlowChef [35] incorporates guidance into the flow trajectory during inference, whereas FlowDPS [23] separates the update step into two components: one for estimating the clean image and another for estimating the noise. In contrast FLAIR follows another class of posterior sampling-based methods, which integrate diffusion priors with inverse problems by directly optimizing variational objective that approximates 2 the data posterior [31]. This framework was recently extended by RSD [54], which incorporates repulsion mechanism to promote sample diversity and applied to latent diffusion models. known issue with this type of optimization is mode collapse [36], which leads to blurry results for these methods. Our method targets this problem by introducing deterministic trajectory adjustment."
        },
        {
            "title": "3 Background",
            "content": "3.1 Inverse problems In many imaging tasks, such as inpainting [5], super-resolution [34] or tomographic reconstruction [42], one aims to recover target signal Rn from distorted observation Rm. The observation is regarded as the result of applying forward operator : Rn (cid:55) Rm to the target signal, corrupted by additive Gaussian noise ν Rm with standard deviation σν. = Ax + ν. (1) In most practical applications, the forward operator is either non-invertible or severely illconditioned, making (1) generally ill-posed. Variational methods solve ill-posed inverse problems by minimizing an energy functional E(x, z) = D(x, y) + R(x). (2) to recover the solution. Interpreted probabilistically via Bayes theorem, the posterior distribution p(xz) is proportional to the product p(zx)p(x). In the negative log-domain, this yields the data term D(x, z) = log p(zx) and the regularizer R(x) = log p(x). Handcrafted priors based on regularity assumptions like sparsity [39, 40, 10, 13, 9] have long been the standard, but have largely been replaced by deep learning-based methods in modern data-driven schemes. 3.2 Flow based priors Models based on flow matching [28] learn time-dependent vector field vθ(xt, t) that continuously transforms samples from simple initial distribution p1(x) to complex target data distribution p0(x). Formally, this transformation is described by solving the ordinary differential equation (ODE): dt ψt(x) = vθ,t(ψt(x)), [0, 1], (3) where ψt(x) represents the trajectory of sample evolving smoothly from an initial sample drawn at = 1 toward target sample at = 0. Since the integrated ODE path maps the simple distribution p1(x) to the complex target p0(x), the learned flow-based model captures the structure of the data and can therefore serve as powerful prior for solving inverse problems. To make this approach tractable for high-resolution data, we adopt the latent diffusion model (LDM) framework [37], which shifts the generative process to lower-dimensional latent space using pretrained autoencoder with encoder : Rn (cid:55) Rd and decoder : Rd (cid:55) Rn with n. However, applying such priors to inverse problems introduces challenges, as the non-linearity of the VAE disrupts the linear relationship between measurements and the target signal, resulting in nonlinear forward operator. 3.3 Variational flow sampling To solve inverse problems from Bayesian perspective, we aim to sample from the posterior p(x0y) p(yx0)p(x0), (4) where the likelihood is given by p(yx0) = (Ax0, σ2Id), and p(x0) represents the prior modeled by the flow-based generative model. Inspired by previous work [31, 54] we introduce variational distribution q(x0y) = (µx, σ2 x) to approximate the true posterior p(x0y), by minimizing their KullbackLeibler divergence: q(x0y) arg min q(x0y) KL(q(x0y)p(x0y)). Rewriting the KL divergence by means of the variational lower bound leads to: KL(q(x0y)p(x0y)) = Eq(x0y)[log p(yx0)] (cid:125) (cid:124) (cid:123)(cid:122) D(x, y) + KL(q(x0y)p(x0)) (cid:123)(cid:122) (cid:125) R(x) (cid:124) + log p(y) (cid:124) (cid:123)(cid:122) (cid:125) const . (5) (6) 3 Since single Gaussian cannot capture multi-modal posterior, we simplify to deterministic approximation, setting σ2 = 0. Equivalently, this corresponds to single-particle approximation in the sense of Stein variational methods [29]. As shown in [46], rewriting Equation 6 under this approximation and extending it to the time-dependent noisy posterior yields: arg min q(x0y) Eq(x0y) (cid:124) (cid:20) (µx)2 2σ2 ν (cid:123)(cid:122) D(x, y) (cid:21) (cid:125) + (cid:90) (cid:124) ω(t) Eq(xty) (cid:104) log q(xty) log p(xt)2(cid:105) dt (cid:123)(cid:122) R(x) (cid:125) (7) The first term in Equation 7 describes the data term D(x, y) and the second the regularizer R(x), where the integral ensures optimization over the entire diffusion trajectory. Notably, the latter constitutes weighted score-matching objective, where log p(xt) represents the score function [47], which may be extracted from pretrained diffusion or flow model. The score of the noisy variational distribution depends on the forward diffusion process and can be computed analytically. Note that for ω(t) = β(t)/2 the weighted score-matching loss recovers the gradient of the diffusion models evidence lower bound, so that optimizing it yields the maximum likelihood estimate of the data distribution [46]. However, optimizing Equation 7 is costly, as it requires computing the gradient through the flow model. As shown in [49] this can be circumvented by reformulating the regularizer in terms of the Wasserstein gradient flow: µxR(x) = Eq(xty) ω(t)( log q(xty) (cid:124) (cid:125) (cid:123)(cid:122) score of noisy variational distribution log p(xt) (cid:125) (cid:123)(cid:122) (cid:124) score of noisy prior distribution ) (8) Note that optimizing only the regularization term, without the data term, at test time is equivalent to the objective of Score Distillation Sampling (SDS) [36]."
        },
        {
            "title": "4 Method",
            "content": "Flow Formulation. The variational formulation in Equation 7 is formulated for the score, but can be reformulated into denoising or ϵθ parametrization [47, 31]. However, we are interested in variational objective that depends on the velocity field vθ(xt, t), which characterizes the probabilistic trajectory that connects the noise and data distributions. Proposition 1. We propose to replace the score-based regularizer in the standard variational objective with flow matching formulation, resulting in the following objective function: arg min q(x0y) Eq(x0y) (cid:124) (cid:20) (µx)2 2σ2 ν (cid:123)(cid:122) D(x, y) (cid:21) (cid:125) + (cid:90) 0 (cid:124) λR(t) Eq(xty) (cid:104) vθ(xt, t) ut(xtϵ)2(cid:105) (cid:123)(cid:122) R(x) dt (cid:125) (9) The flow-matching term that defines the regularizer arises by re-parameterizing the variational distribution to q(xty) = ((1 t)µx, t2 I). This corresponds to sampling via the deterministic map ψt(x0 ϵ) = (1 t) x0 + ϵ, with ϵ (0, I). By re-formulating the score in terms of the target velocity field ut, we get: log q(xty) = (1 t)ut(xtϵ) + xt (10) For the learned velocity vθ(xt, t) similar approximation holds for full derivation please see the supplementary material subsection A.2. vθ(xt, t) tx log p(xt) xt 1 We can therefore approximate the score of the noisy prior with our learned velocity field vθ log p(xt) (1 t)vθ(xt, t) + xt . 4 (11) (12) Hard Data Consistency. Existing variational posterior sampling approaches [31, 54] impose soft constraints on the data fidelity term D(x, y). In contrast, recent work [43] has demonstrated that, when sampling from latent diffusion models, enforcing hard data consistency generally leads to better reconstructions with improved visual fidelity. Our method shares this motivation, but differs in that we optimize over variational distribution, i.e., we compute min Eq(x0y)[ log p(yx0)]. An additional advantage of this variational setup is that it allows us to initialize the optimization variable with an adjoint based initialization µx = E(Ay), with being the encoder of the VAE. Accuracy Calibration. As our framework evaluates the trajectory at each timestep, we aim to weight the regularizers contribution according to its reliability. It has been shown that the difficulty of the prediction task depends on the network parameterization, as well as on the specific timestep [19]. Since the regularization term R(x) in our approach is equivalent to the training objective of the pre-trained flow model, we can easily weight it by the expected model error, which we calibrate on small set of images. Specifically, we sample calibration images and compute the conditional flow matching objective for 100 linearly spaced time steps between 0 and 1, then average the error over all images to obtain the expected model error at each time step. Different functions of the model error can be chosen as weight for the regularizer. We choose: λR(t) = 1 (cid:32) (cid:88) i= (cid:13) (cid:13)vθ(x(i) (cid:13) , t) ut(x(i) 2(cid:33)1 (cid:13) (cid:13) (cid:13) ϵ) (13) and set λR(t) = 0 for all < 0.2, since the accuracy of SD3 is heavily degraded for low noise levels. Deterministic Trajectory Adjustment. Score distillation sampling relies on the assumption that xt = (1 t)µx + tϵ lies in region of the learned prior that has reasonably high support/density. In practice, this is not always the case. When not tightly conditioned (usually with extensive text prompts), even the best available diffusion models assign low density to many plausible regions of the latent space, leading to bad gradient steps. Therefore, we increase the probability of p(xt) by additionally conditioning xt on the estimated \"end-point\" µ. Proposition 2. We introduce reparameterized variational distribution with mean that linearly interpolates between the posterior mean µx and model-guided ˆx1: q(xt y) = (cid:0)(1 t)µx + tαˆx1, t2(1 α2)I(cid:1) , (14) where ˆx1 = xt+δt + (1 δt)vθ(xt+δt, + δt) is single-step velocity-based predictor, and α [0, 1] controls the trade-off between deterministic guidance and random noise. This reparameterization induces the following reference velocity field: ut(xt ϵ) = αˆx1 + 1 α2ϵ xt 1 . (15) Intuitively, changing the formulation in this manner ensures that the model relocates the sample to its expected position on the learned manifold, rather than injecting arbitrary noise, which could drive it in direction that has high prior likelihood but is not consistent with the observation. To further encourage exploration and avoid collapsing onto the trajectory of the adjoint measurement, we inject an additional, stochastic component ϵ during this process. full derivation can be found in the supplementary material, subsection A.2. 4.1 Algorithm the components disThe following pseudo-code summarizes our method, cussed above. We adapt the standard scheme [31, 54] of linearly traversing time in descending manner and stop at = 0.2 as explained in section 4. We choose α = 1 t. Gradient updates to enforce hard data consistency are performed using stocasintegrating all 5 tic gradient descent. For further implementation details and ablations, see subsection A. Algorithm 1: The FLAIR solver for inverse imaging problems Input: µx = A(y), λR, α, y, A, vθ Output: µx ˆϵ (0, I); for 1 to 0 by do xt (1 t) µx + ˆϵ; initial noise sample sample noisy latent ; ut(xt ˆϵ) ˆϵ xt 1 µx vθ(xt, t) ut(xt ˆϵ); µx µx λR µx R; µx arg minµx A(µx)2; ϵ (0, I); ˆx1 xt + (1 t) vθ(xt, t); ˆϵ α ˆx1 + 1 α2 ϵ; update w.r.t. regularizer hard data consistency predict deterministic noise update noise estimate"
        },
        {
            "title": "5 Experiments",
            "content": "We evaluate the performance of FLAIR on variety of inverse imaging tasks and compare against several baselines, using the SD3 backbone without any fine-tuning. We used several metrics including SSIM [50], LPIPS [53] and patchwise FID [16] (pFID) to comprehensively assess the perceptual and quantitative quality of the reconstructions. FID is computed using InceptionV3 features on patches of 256x256 resolution. All experiments were performed on single NVidia RTX 4090 GPU with 24GB of VRAM. For completeness we also show PSNR values, but point out that the metric is not well suited for our purposes: PSNR favors the posterior mean, while the goal of the variational approach is to sample from the posterior distribution. Accordingly, PSNR is known to prefer over-smoothed, blurry outputs over sharp ones with even the slightest misalignment of high frequency content [6]. 5.1 Setup Datasets. We utilize two high-resolution image datasets: FFHQ [20] and DIV2K [2]. FFHQ consists of 70k diverse face images at 10241024 resolution of which we take the first 1000 samples. It is covering variations in age, pose, lighting, and ethnicity. DIV2K contains 800 high-quality images in 2K resolution that span range of natural scenes with varied textures and structures. Baselines. Our method is benchmarked against several recent inverse imaging solvers based on posterior sampling. Specifically, we compare to ReSample [43], FlowDPS [23], FlowChef [35], and RSD [54]. The latter is used without repulsive term as it delivers better results. To ensure fair and meaningful comparison, all methods are evaluated with the same number of function evaluations. Problem Setting. We run and evaluate all methods at fixed output resolution of 768768 pixels. For single image super-resolution, we consider scaling factors of 8 and 12. The corresponding low-resolution inputs are generated by bicubic downsampling. Motion blur is simulated with blur kernel of size 61. For box inpainting, we mask large, continuous rectangles that cover approximately one third of the observation. All synthesized observations are corrupted with additive Gaussian noise, with standard deviation σν of 0.5%. For inference on the FFHQ dataset, we use predefined text prompt of the form \"A high quality photo of face\", and for DIV2k \"A high quality photo of\" concatenated with an image-specific description retrieved by applying DAPE [51] to the observation. 5.2 Experimental Results Inverse Problems. Our experiments clearly demonstrate that FLAIR outperforms existing flow-based approaches in terms of all perceptual metrics, see Table 1. In the case of image inpainting, our method produces high-quality reconstructions that fully leverage the power of the generative model and blend naturally into the surrounding context, avoiding degradations and artifacts that we observe in the baselines. In particular, FlowDPS tends to produce implausible textures in the inpainted regions, while FlowChef regularly fails to generate semantically consistent content at all. For single-image super-resolution, FLAIR consistently delivers 6 Figure 2: Qualitative comparison. FLAIR produces posterior samples of high perceptual quality while maintaining high data likelihood. Best viewed zoomed in. the most perceptually convincing and realistic outputs. Notably, the FID scores remain low for both 8 and 12 magnification, indicating an effective usage of the generative prior to overcome the increasing ill-posedness. Again, FlowDPS suffers from blur and low texture quality, whereas FlowChef tends to lose semantic coherence. In motion deblurring, FLAIR also restores sharper and semantically more credible content than competing approaches, which often suffer from residual blur or inconsistent details. The boost in reconstruction quality is quantitatively reflected by all metrics, confirming that FLAIR reconstructs images with high fidelity. For further qualitative examples, please see subsection A.9. Posterior Variance. To demonstrate that FLAIR does not suffer from mode collapse, we assess the posterior variance Var[xz] for the task of 12 Super Resolution, by drawing 32 samples for fixed observation and computing their pixel-wise variance. We conduct that experiment for our FLAIR approach, for RSD with repulsive term, and for FlowDPS [23]. The example in Figure 3 illustrates that FLAIR has the highest sample diversity, which is also reflected in the corresponding variance maps. Notably, the sample variance is concentrated in regions with high-frequency textures. This indicates that our method reliably reconstructs the posterior, whose low-frequency part is, in the super-resolution setting, tightly constrained by the likelihood term. Editing. Beyond image restoration, we observe that our method also performs remarkably well for text-based image editing, by simply presenting suitable target prompts during inpainting. Figure 4 illustrates variety of edited images generated from the same photograph with the help of the depicted masks and prompts. 7 Table 1: Quantitative results with 50 NFE and σν = 0.01. SR 8 SR 12 Motion Deblurring Inpainting Method LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR FFHQ 768768 ReSample 0.400 55.6 0.815 0.374 40.3 0.756 FlowDPS 0.391 51.7 0.776 RSD 0.341 30.5 0.760 FlowChef 0.213 13.3 0.777 Ours ReSample 0.533 55.0 0.625 0.476 54.2 0.567 FlowDPS 0.539 60.9 0.591 RSD 0.490 48.6 0.539 FlowChef 0.353 26.5 0.607 Ours 26.37 29.24 29.69 28.42 29.54 22.34 23.01 23.45 21.84 23.30 0.474 80.3 0.786 0.413 47.2 0.741 0.462 71.7 0.743 0.373 41.0 0.730 0.271 16.2 0.740 0.643 88.1 0.562 0.547 67.4 0.528 0.684 95.7 0.523 0.525 55.3 0.492 0.421 32.1 0.525 25.47 28.05 28.11 27.00 27.71 DIV2K 768768 20.85 21.79 21.96 20.52 21.39 0.457 82.9 0.788 0.431 49.5 0.732 0.458 77.3 0.743 0.406 35.0 0.716 0.236 10.7 0. 0.556 79.7 0.617 0.558 60.4 0.536 0.638 97.6 0.551 0.561 51.3 0.486 0.315 21.1 0.653 25.45 27.64 27.67 25.81 29.61 21.79 21.88 22.10 19.90 24.44 0.366 70.8 0.827 0.344 38.3 0.771 0.478 73.3 0.736 0.394 71.0 0.780 8.7 0.828 0.184 0.285 51.9 0.796 0.328 34.2 0.692 0.464 63.9 0.678 0.489 86.3 0.659 0.163 11.0 0.815 21.83 19.19 21.97 18.18 23. 22.68 21.71 23.23 20.87 23.75 Figure 3: Zoomed-in reconstructions for x12 Super Resolution. We show posterior samples (col. 14) of FLAIR, FlowDPS, and RSD, posterior mean and standard deviation (over 32 samples, col. 5,6). 0 0.16 5.3 Ablation Studies We systematically analyze the impact of key design choices in our method. Specifically, we ablate the deterministic trajectory adjustment, the use of hard data consistency, and the calibration of the regularizer weight for 12 super-resolution, using subset of 100 samples from the FFHQ and DIV2K datasets. Quantitative and qualitative results are shown in Table 2 and Figure 5, respectively. Figure 4: Edited images shown alongside original, with prompts: \"A high resolution portrait of a...\" 8 Figure 5: Qualitative samples from the ablation study on 12 Super Resolution. Hard Data Consistency (HDC). Dropping the hard data consistency degrades both metrics, with PSNR being particularly affected due to poorer alignment with the input observation, which is also evident in the visual example: the reconstruction is plausible, but deviates from the observation. Deterministic Trajectory Adjustment (DTA). The biggest performance drop compared to the full setup occurs when removing the deterministic trajectory adjustment, as standard noise injection harms the gradient updates in low-density regions of the prior. The reconstruction appears overly smooth and lacks texture details. Calibrated Regularizer Weight (CRW). Replacing our calibrated regularizer weight with λR(t) = also has strong impact on perceptual quality: the result is visibly blurred if one ignores the changing accuracy of the regularizer along the flow trajectory. Table 2: Ablation study for 12 super-resolution on DIV2K and FFHQ. Model components are individually switched on or off. HDC DTA CRW FFHQ LPIPS PSNR DIV2K LPIPS PSNR 0.259 0.297 0.432 0.363 0.392 27.45 27.17 27.20 28.58 28. 0.427 0.467 0.622 0.583 0.605 21.05 20.82 21.69 21.98 21.99 Legend. HDC: Hard Data Consistency; DTA: Deterministic Trajectory Adjustment; CRW: Calibrated Regularizer Weight. = included, = ablated."
        },
        {
            "title": "6 Conclusion and Limitations",
            "content": "We have presented FLAIR, training-free variational framework for inverse problems that uses flow-based generative model as its image prior. By combining the power of (latent) flow-based models with principled reconstruction of the posterior distribution, FLAIR addresses key limitations of existing methods. First, it is able to recover atypical modes, by combining the degradation-agnostic flow matching loss with deterministic trajectory adjustments. Second, it enables hard data consistency without sacrificing sample diversity, by decoupling the data consistency constraint from the regularization, while adaptively reweighting the latter according to its expected accuracy, calibrated offline. Experiments with different image datasets and tasks confirm that FLAIR consistently achieves higher reconstruction quality than existing baselines based on either flow matching or denoising diffusion. Notably, our proposed method achieves, at the same time, excellent perceptual quality, close adherence to the input observations, and high sample diversity. Evidently, FLAIR inherits the limitations of the underlying generative model, in our implementation Stable Diffusion 3. These include biases caused by the selection of training data, constraints w.r.t. the output resolution, and limited ability to recover out-of-distribution modes. Furthermore, our approach introduces additional hyper-parameters needed to control the deterministic trajectory adjustment. We note that high fidelity image restoration methods can potentially be misused for unethical image manipulations."
        },
        {
            "title": "References",
            "content": "[1] Hemant Aggarwal, Merry Mani, and Mathews Jacob. MoDL: Model-based deep learning architecture for inverse problems. IEEE Transactions on Medical Imaging, 38(2):394405, 2018. [2] Eirikur Agustsson and Radu Timofte. NTIRE 2017 challenge on single image super-resolution: Dataset and study. In CVPR Workshops, 2017. [3] Eirikur Agustsson and Radu Timofte. NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, July 2017. [4] Alexander Becker, Rodrigo Caye Daudt, Nando Metzger, Jan Dirk Wegner, and Konrad Schindler. Neural fields with thermal activations for arbitrary-scale super-resolution. arXiv:2311.17643, 2023. [5] Marcelo Bertalmio, Guillermo Sapiro, Vincent Caselles, and Coloma Ballester. Image inpainting. In Proceedings of the 27th annual conference on Computer graphics and interactive techniques, pages 417424, 2000. [6] Yochai Blau and Tomer Michaeli. The perception-distortion tradeoff. In CVPR, 2018. [7] Ashish Bora, Ajil Jalal, Eric Price, and Alexandros Dimakis. Compressed sensing using generative models. In ICML, 2017. [8] Levi Borodenko. motionblur: Generate authentic motion blur kernels and apply them to images. https://github.com/LeviBorodenko/motionblur, 2025. Accessed: 2025-05-19. [9] Kristian Bredies and Martin Holler. Higher-order total variation approaches and generalisations. Inverse Problems. Topical Review, 36(12):123001, 2020. [10] Antonin Chambolle and Thomas Pock. first-order primal-dual algorithm for convex problems with applications to imaging. Journal of Mathematical Imaging and Vision, 40(1):120145, 2011. [11] Hyungjin Chung, Jeongsol Kim, Michael McCann, Marc Klasky, and Jong Chul Ye. Diffusion posterior sampling for general noisy inverse problems. In ICLR, 2023. [12] Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving diffusion models for inverse problems using manifold constraints. NeurIPS, 35, 2022. [13] Ingrid Daubechies, Michel Defrise, and Christine De Mol. An iterative thresholding algorithm for linear inverse problems with sparsity constraint. Communications on Pure and Applied, 57(11):14131457, 2004. [14] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, and Robin Rombach. Scaling rectified flow transformers for high-resolution image synthesis. In ICML, 2024. [15] Kerstin Hammernik, Teresa Klatzer, Erich Kobler, Michael Recht, Daniel Sodickson, Thomas Pock, and Florian Knoll. Learning variational network for reconstruction of accelerated MRI data. Magnetic Resonance in Medicine, 79(6):30553071, 2018. [16] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by two time-scale update rule converge to local Nash equilibrium. In NeurIPS, 2017. [17] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. NeurIPS, 2020. [18] Viren Jain and Sebastian Seung. Natural image denoising with convolutional networks. NeurIPS, 2008. 10 [19] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. In NeurIPS, 2022. [20] Tero Karras, Samuli Laine, and Timo Aila. style-based generator architecture for generative adversarial networks. In CVPR, 2019. [21] Tero Karras, Samuli Laine, and Timo Aila. style-based generator architecture for generative adversarial networks. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 44014410, 2019. Introduces the Flickr-Faces-HQ (FFHQ) dataset. [22] Bahjat Kawar, Gregory Vaksman, and Michael Elad. SNIPS: Solving noisy inverse problems stochastically. NeurIPS, 34, 2021. [23] Jeongsol Kim, Bryan Sangwoo Kim, and Jong Chul Ye. FlowDPS: Flow-driven posterior sampling for inverse problems. arXiv:2503.08136, 2025. [24] Jeongsol Kim, Bryan Sangwoo Kim, and Jong Chul Ye. FlowDPS: Flow-driven posterior sampling for inverse problems. https://https://github.com/FlowDPS-Inverse/FlowDPS, 2025. Accessed: 2025-05-19. [25] Florian Knoll, Jure Zbontar, Anuroop Sriram, Matthew J. Muckley, Mary Bruno, Aaron Defazio, Marc Parente, Krzysztof J. Geras, Joe Katsnelson, Hersh Chandarana, Zizhao Zhang, Michal Drozdzalv, Adriana Romero, Michael Rabbat, Pascal Vincent, James Pinkerton, Duo Wang, Nafissa Yakubova, Erich Owens, C.Lawrence Zitnick, Michael P. Recht, Daniel K. Sodickson, and Yvonne W. Lui. fastMRI: publicly available raw k-space and DICOM dataset of knee images for accelerated MR image reconstruction using machine learning. Radiology: Artificial Intelligence, 2(1):e190007, 2020. [26] Erich Kobler, Alexander Effland, Karl Kunisch, and Thomas Pock. Total deep variation: stable regularization method for inverse problems. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021. [27] Christian Ledig, Lucas Theis, Ferenc Huszár, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-realistic single image super-resolution using generative adversarial network. In CVPR, 2017. [28] Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative modeling. In ICLR, 2023. [29] Qiang Liu and Dilin Wang. Stein variational gradient descent: general purpose bayesian inference algorithm. In NeurIPS, volume 29, pages 23782386, 2016. [30] Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. arXiv:2209.03003, 2022. [31] Morteza Mardani, Jiaming Song, Jan Kautz, and Arash Vahdat. variational perspective on solving inverse problems with diffusion models. In ICLR, 2024. [32] Dominik Narnhofer, Alexander Effland, Erich Kobler, Kerstin Hammernik, Florian Knoll, and Thomas Pock. Bayesian uncertainty estimation of learned variational MRI reconstruction. IEEE Transactions on Medical Imaging, 41(2):279291, 2021. [33] Dominik Narnhofer, Kerstin Hammernik, Florian Knoll, and Thomas Pock. Inverse GANs for accelerated MRI reconstruction. In Wavelets and Sparsity XVIII, volume 11138. SPIE, 2019. [34] Sung Cheol Park, Min Kyu Park, and Moon Gi Kang. Super-resolution image reconstruction: technical overview. IEEE signal processing magazine, 20(3):2136, 2003. [35] Maitreya Patel, Song Wen, Dimitris N. Metaxas, and Yezhou Yang. Steering rectified flow models in the vector field for controlled image generation. arXiv:2412.00100, 2024. [36] Ben Poole, Ajay Jain, Jonathan Barron, and Ben Mildenhall. Dreamfusion: Text-to-3d using 2d diffusion. In ICLR, 2023. 11 [37] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022. [38] Litu Rout, Negin Raoof, Giannis Daras, Constantine Caramanis, Alex Dimakis, and Sanjay Shakkottai. Solving linear inverse problems provably via posterior sampling with latent diffusion models. In NeurIPS, 2023. [39] Leonid Rudin, Stanley Osher, and Emad Fatemi. Nonlinear total variation based noise removal algorithms. Physica D: Nonlinear Phenomena, 60(1-4):259268, 1992. [40] Sylvain Sardy, Paul Tseng, and Andrew Bruce. Robust wavelet denoising. IEEE Transactions on Signal Processing, 49(6):11461152, 2001. [41] Viraj Shah and Chinmay Hegde. Solving linear inverse problems using gan priors: An algorithm with provable guarantees. In ICASSP, 2018. [42] Emil Sidky and Xiaochuan Pan. Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization. Physics in Medicine & Biology, 53(17):4777, 2008. [43] Bowen Song, Soo Min Kwon, Zecheng Zhang, Xinyu Hu, Qing Qu, and Liyue Shen. Solving inverse problems with latent diffusion models via hard data consistency. In ICLR, 2024. [44] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In ICLR, 2021. [45] Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan Kautz. Pseudoinverse-guided diffusion models for inverse problems. In ICLR, 2023. [46] Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum likelihood training of score-based diffusion models. NeurIPS, 34, 2021. [47] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In ICLR, 2021. [48] Yinhuai Wang, Jiwen Yu, and Jian Zhang. Zero-shot image restoration using denoising diffusion null-space model. ICLR, 2023. [49] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation. In NeurIPS, 2023. [50] Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image Processing, 13(4):600 612, 2004. [51] Rongyuan Wu, Tao Yang, Lingchen Sun, Zhengqiang Zhang, Shuai Li, and Lei Zhang. Seesr: Towards semantics-aware real-world image super-resolution. In CVPR, pages 2545625467, June 2024. [52] Rongyuan Wu, Tao Yang, Lingchen Sun, Zhengqiang Zhang, Shuai Li, and Lei Zhang. Seesr: Towards semantics-aware real-world image super-resolution. In CVPR, pages 2545625467, 2024. [53] Richard Zhang, Phillip Isola, Alexei Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as perceptual metric. In CVPR, 2018. [54] Nicolas Zilberstein, Morteza Mardani, and Santiago Segarra. Repulsive latent score distillation for solving inverse problems. In ICLR, 2025."
        },
        {
            "title": "Supplementary Material",
            "content": "In the following, we provide detailed line-by-line derivations of the mathematical formulations used in the paper, as well as additional implementation details and experimental results."
        },
        {
            "title": "A Derivations",
            "content": "A.1 Derivation of flow-based variational formulation The linear conditional flow and its corresponding velocity are defined as: ψt(x0 ϵ) = (1 t) x0 + ϵ, ϵ (0, I) , ut(xtϵ) = dψt dt (ψ1 (xtϵ)ϵ) . The score of the noisy variational distribution can be analytically computed with: q(xty) = ((1 t)µx, t2 I) , xt log q(xty) = ϵ . We compute dψt dt (x0ϵ) = x0 + ϵ and ψ1 (xtϵ) and insert it into Equation 17: ut(xtϵ) = ϵ xt 1 . Solving Equation 20 for ϵ and inserting in Equation 19 gives: xt log q(xty) = (1 t)ut(xtϵ) + xt . For the learned velocity vθ(xt, t) similar approximation holds: vθ(xt, t) tx log p(xt) xt 1 . Hence, we can approximate the score of the noisy prior with our learned velocity field vθ xt log p(xt) (1 t)vθ(xt, t) + xt , (16) (17) (18) (19) (20) (21) (22) (23) and we see that for ω(t) = therefore set ω(t) = 1t and end up at our final objective: 1t we obtain the conditional flow matching objective for R(x). We arg min q(x0y) Eq(x0y) (cid:124) (cid:20) (µx)2 2ν2 (cid:123)(cid:122) D(x, y) (cid:21) (cid:125) + (cid:90) 0 (cid:124) Eq(xty) vθ(xt, t) ut(xtϵ)2(cid:105) (cid:104) dt . (24) (cid:123)(cid:122) R(x) (cid:125) Again, the gradient step for the regularizer becomes: µx R(x) = Eq(xty) [vθ(xt, t) ut(xtϵ)] . A.2 Derivation of trajectory adjusted flow-based variational formulation To achieve the proposed trajectory adjustment, we modify the forward process to: ˆx1 = xt+dt + (1 dt)vθ(xt+dt, + dt) , xt = (1 t)µx + (αˆx1 + (cid:124) (cid:112) (cid:123)(cid:122) ˆϵ 1 α2ϵ) (cid:125) , (25) (26) (27) where ˆx1 is the noise vector prediction from the last optimization iteration. This induces variational distribution: q(xt y) = (cid:0)(1 t)µx + tαˆx1, t2(1 α2)I(cid:1) , (28) 13 leading to score of xt log q(xt y) = 1 t2(1 α2) (cid:112) 1 α2ϵ = ϵ 1 α2 . The velocity field is again computed by Equation 17. We start by defining the flow: ψt(x0 ϵ) = (1 t)x0 + (cid:16) αˆx1 +"
        },
        {
            "title": "The resulting derivative reads",
            "content": "(cid:112) (cid:17) 1 α2ϵ . and the inverse becomes ψt(x0 ϵ) = αˆx1 x0 + (cid:112) 1 α2ϵ , dt x0 = ψ1 (xt ϵ) = xt tαˆx1 1 1 α2ϵ . Plugging these results into Equation 17: ut(xt ϵ) = αˆx1 + 1 α2ϵ xt 1 . A.3 Derivation of Score from Flow The score matching objective reads as: xt ln pt(xt) = arg min θ EtU [0,1],x0p0,ϵN (0,I) w(t) (cid:34) (cid:13) (cid:13) (cid:13) (cid:13) sθ(xt, t) + 1 (cid:13) (cid:13) σ(t)2 (xt µ(x0, t)) (cid:13) (cid:13) where, σ(t)2 (xt µ(x0, t)) = xt log pt(xt x0), with pt(xt x0) = (µt(x0), σ2 Equation 34 is solved by: I). Note that as usual we assume µt(x0) being linear in x0. and can be written as: xt log pt(xt) = Ept(x0xt) [xt log pt(xtx0)] , xt log pt(xt) = (xt µ(E[x0 xt], t)) σ(t)2 . In the case of OT flow-matching, we obtain xt = (1 t)x0 + tx1, x1 (0, Id) and p(xtx0) = ((1 t)x0, t2). The optimal velocity under the flow matching loss is given by: v(xt, t) = E[x1 x0 xt]. Expressing x1 = xt(1t)x0 , we can insert into Equation 39 and obtain: E[x0 xt] = xt tE[x1 x0 xt]. Inserting in Equation 37 leads to: xt log pt(xt) = xt (1 t)(xt tE[x1 x0 xt]) , which for v(xt, t) = E[x1 x0 xt] reads as: xt log p(xt) (1 t)vθ(xt, t) + xt . (29) (30) (31) (32) (33) 2(cid:35) , (34) (35) (36) (37) (38) (39) (40) (41) (42) A.4 Implementation details Flow Model and Regularizer Settings. As flow matching model, we us Stable Diffusion 3.5Medium, which has been released under the Stability Community License. The classifier-free guidance scale is set to 2 for all experiments. To minimize the regularization term, we use stochastic gradient descent with learning rate of 1. Data Likelihood Term. We use stochastic gradient descent for the minimization of the data term towards hard data consistency. For numerical stability, the squared error is summed over all measurements instead of computing the mean. The learning rate has to be adjusted accordingly, to compensate for the varying number of measurements y. Moreover, the minimization is terminated with early stopping once the likelihood term reaches 1 104 len(y), to not overfit the noise in the image observation. Super-resolution. We employ bicubic downsampling as the forward operator, as implemented in [48]. The learning rate is set to 12 for 12 super-resolution and to 6 for 8 super-resolution. Motion Deblurring. different motion blur kernel is created for each sample using the MotionBlur package [8], available via github, with kernel size 61 and intensity 0.5. The learning rate for our data term optimizer is set to 101. Inpainting. For inpainting on FFHQ we always use the same rectangular mask at fixed position, chosen such that it roughly masks out the right side of the face (Figure 7). For DIV2k we also use fixed mask for all samples, consisting of six randomly generated rectangles (Figure 10). Data. We use the publicly available Flickr Faces High Quality dataset [21], which is realeased under the Creative Commons BY 2.0 License and the DIV2K dataset [3], which is released under research only license. For FFHQ we use the first 1000 samples of the evaluation dataset and for DIV2K we use the 800 training samples. We downscale both datasets to 768 768 px by applying bicubic sampling so that the shorter edge of the frame has 768 px and apply central cropping afterwards. A.5 Baselines For comparability, all baselines use Stable Diffusion 3.5-Medium and the same task definitions as in A.4. FlowDPS [23] The standard FlowDPS implementation [24] is applied with 50 NFE, classifier-free guidance scale of 2, and step sizes of 15 for inpainting and 10 for all other tasks. FlowChef [35] Additionally, [24] is employed for FlowChef as well, using 50 NFE, classifier-free guidance scale of 2, and step size of 1 for all tasks. Repulsive Score Distillation (RSD) [54]. We implement RSD for flow-matching models by applying Proposition 1 with ω(t) = t, resulting in weighting term consistent with the original RSD approach. However, we omit the pixel-space augmentation as it negatively affected performance when combined with the SD3 VAE. Consistent with the original findings from RSD, we observed that incorporating the repulsive term improves sample diversity but reduces fidelity. Therefore, we set the repulsive term to 0 for all results presented in the table, employing it exclusively for comparing posterior variances. ReSample [43] We re implement ReSample for flow-matching by setting αt = (1t)2 t2+(1t)2 . Furthermore, we compute the hard-data consistency at every iteration as larger skip steps seem to harm performance. We set the learning rate of the data term optimizer to 15 for all inverse problems. PSLD [38] Our attempt to adapt PSLD following [24]using 500 NFE, classifier-free guidance scale of 2, and step sizes of 1 (12 super-resolution), 0.5 (8 super-resolution and motion deblurring) and 0.1 (inpainting)did not yield meaningful results. A.6 Regularizer weighting Figure 6 displays the mean and standard deviation of the conditional flow matching loss LCF as function of t, estimated over 100 samples. The loss function starts with high values at = 1, decreases over time, but then starts to rise again, and when reaching 0.2 even exceeds its initial value . The rising loss when approaching = 0 is due, in part, to the increasing difficulty of distinguishing high-frequency image content from residual noise. Another factor is that near = 0 the model 15 operates in highly sensitive regime where small prediction errors can cause disproportionately large deviations from the target, making accurate flow estimation particularly challenging in the final stages of the trajectory. We therefore modulate the regularization term according to the model error. Different weighting functions for (LCF ) could be chosen that fulfill the condition λR(t=0) = 0. We simply take the reciprocal of the model error λR(t) = L1 CF M,t as the regularization weight while 0.2, then set it to 0 for < 0.2. An alternative would be to shift the reciprocal of L1 CF M,t by L1 CF M,t=0, such that λR(t) = L1 CF M,t=0. In Table 3 we compare our default weighting with this variant, denoted as λshif t. CF M,t L1 Figure 6: The Flow-Matching loss over time t. Table 3: Quantitative results with 50 NFE and σν = 0.01. We compare different weighting functions λR(t) based on the model error SR 8 SR 12 Motion Deblurring Inpainting Method LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR FFHQ 768 λshif Ours 0.246 27.4 0.793 0.213 13.3 0.777 29.91 29.54 λshif Ours 0.379 30.4 0.625 0.353 26.5 0.607 23.58 23. A.7 Effect of captioning 0.286 24.4 0.766 0.271 16.2 0.740 0.237 14.5 0.790 0.236 10.7 0.772 28.19 27.71 DIV2K 768768 21.40 21.39 0.434 37.5 0.522 0.421 32.1 0.525 0.337 25.8 0.664 0.315 21.1 0. 29.84 29.61 0.180 0.184 8.2 0.828 8.7 0.828 23.58 23.69 24.54 24.44 9.0 0.819 0.151 0.163 11.0 0. 23.79 23.75 Given the diversity of DIV2k, we use DAPE [52] to generate captions for it and include them in the prompt high quality photo of [DAPE caption]. For FFHQ we always prompt with high quality photo of face.. The effect of the text prompt is to increase the likelihood of our sample under the prior of the (pre-trained, frozen) image generator. For comparison, we also ran experiments without data specific captions, where we always used the generic prompt high quality photo. Results are shown in Table 4 Table 4: Quantitative results with 50 NFE and σν = 0.01. We compare our version with data-specific captions and version without captions."
        },
        {
            "title": "Method",
            "content": "LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR"
        },
        {
            "title": "FFHQ",
            "content": "DIV2K wo captions Ours 0.278 0.271 17.0 16.2 0.734 0.740 27.66 27. 0.488 0.421 51.5 32.1 0.546 0.525 21.82 21.39 A.8 Additional Experimental Results We present the experimental results from the main paper in Table 5, now augmented with sample-wise standard deviations for all metrics except FID. 16 Table 5: Quantitative results with 50 NFE and σν = 0.01 Super-resolution (8 and 12). SR 8 SR 12 Method LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR FFHQ 768768 ReSample FlowDPS RSD FlowChef Ours 0.400 0.069 0.374 0.107 0.391 0.079 0.341 0.083 0.213 0.056 ReSample FlowDPS RSD FlowChef Ours 0.533 0.130 0.476 0.129 0.539 0.121 0.490 0.116 0.353 0. 55.6 40.3 51.7 30.5 13.3 55.0 54.2 60.9 48.6 26.5 0.815 0.051 0.756 0.075 0.776 0.052 0.760 0.064 0.777 0.051 26.37 1.00 29.24 2.04 29.69 2.04 28.42 2.22 29.54 2.02 0.474 0.078 0.413 0.107 0.462 0.093 0.373 0.084 0.271 0.071 DIV2K 768 0.625 0.132 0.567 0.139 0.591 0.124 0.539 0.137 0.607 0.127 22.34 2.27 23.01 3.01 23.45 2.96 21.84 2.96 23.30 2.90 0.643 0.152 0.547 0.139 0.684 0.137 0.525 0.118 0.421 0.131 80.3 47.2 71.7 41.0 16.2 88.1 67.4 95.7 55.3 32.1 0.786 0.056 0.741 0.074 0.743 0.059 0.730 0.068 0.740 0. 25.47 1.16 28.05 2.06 28.11 2.00 27.00 2.07 27.71 2.00 0.562 0.151 0.528 0.146 0.523 0.132 0.492 0.145 0.525 0.136 20.85 3.02 21.79 2.94 21.96 2.86 20.52 2.85 21.39 2.67 Table 6: Quantitative results with 50 NFE and σν = 0.01 Motion deblurring and in-painting. Motion Deblurring In-painting Method LPIPS FID SSIM PSNR LPIPS FID SSIM PSNR FFHQ 768768 ReSample FlowDPS RSD FlowChef Ours 0.457 0.087 0.431 0.117 0.458 0.098 0.406 0.093 0.236 0. ReSample FlowDPS RSD FlowChef Ours 0.556 0.146 0.558 0.153 0.638 0.156 0.561 0.123 0.315 0.107 82.9 49.5 77.3 35.0 10.7 79.7 60.4 97.6 51.3 21.1 0.788 0.058 0.732 0.078 0.743 0.059 0.716 0.072 0.772 0.055 25.45 1.46 27.64 2.20 27.67 2.47 25.81 2.61 29.61 2. 0.366 0.053 0.344 0.060 0.478 0.082 0.394 0.069 0.184 0.038 DIV2K 768768 0.617 0.134 0.536 0.148 0.551 0.136 0.486 0.148 0.653 0.121 21.79 2.52 21.88 3.02 22.10 3.07 19.90 3.06 24.44 3.05 0.285 0.073 0.328 0.103 0.464 0.112 0.489 0.148 0.163 0.053 70.8 38.3 73.3 71.0 8. 51.9 34.2 63.9 86.3 11.0 0.827 0.033 0.771 0.048 0.736 0.048 0.780 0.051 0.828 0.029 21.83 1.68 19.19 3.19 21.97 2.58 18.18 2.84 23.69 2.77 0.796 0.067 0.692 0.112 0.678 0.077 0.659 0.131 0.815 0.054 22.68 1.84 21.71 2.67 23.23 2.21 20.87 2.65 23.75 2.74 A.9 Additional Qualitative Examples To illustrate the visual differences behind the error metrics, we present additional qualitative results for both FFHQ and DIV2k, comparing FLAIR with existing approaches. These examples complement the images in the main paper and highlight the visual fidelity, consistency, and robustness of our method across diverse scenes and different degradations. Figure 13 features full sized version of the variance figure in section subsection 5.2. A.10 Failure cases We observe two main failure modes for FLAIR, see Figure 14. First, we find that super-resolution on DIV2k occasionally results in grainy textures, usually in regions with abundant high-frequency detail and complicated light transport. Potentially, this happens for images which do not have high probability under the prior. We do not observe those artifacts for the FFHQ dataset. Second, we observe few instances where the strong generative prior hallucinates semantically inconsistent or misaligned structures especially facial features. 17 Figure 7: Inpainting results on FFHQ. Shown are observation, reference methods, FLAIR and ground truth. FLAIR produces realistic, high-frequency details while previous works either fail to inpaint the region correctly or collapse to overly smooth solutions. Figure 8: 12 super-resolution results on FFHQ. Shown are observation, reference methods, FLAIR and ground truth. FLAIR produces sharp and results which still fulfill the data term, whereas the baselines tend to predict blurry images. 19 Figure 9: Motion de-blur results on FFHQ. Shown are observation, reference methods, FLAIR and ground truth. FLAIR produces sharp and results which still fulfill the data term, whereas the baselines tend to predict blurry images. 20 Figure 10: Inpainting results on DIV2k. Shown are observation, reference methods, FLAIR and ground truth. FLAIR produces realistic, high-frequency details while previous works either fail to inpaint the region correctly or collapse to overly smooth solutions. Moreover they do not fit the data term (not inpainted region) very well. Figure 11: 12 super-resolution results on DIV2k. Shown are observation, reference methods, FLAIR and ground truth. FLAIR produces sharp and results which still fulfill the data term, whereas the baselines tend to predict blurry images. 22 Figure 12: Motion de-blur results results on DIV2k. Shown are observation, reference methods, FLAIR and ground truth. FLAIR produces sharp and results which still fulfill the data term, whereas the baselines tend to predict blurry images. 23 Figure 13: Individual samples for x12 Super Resolution with zoom and std. FLAIR produces varied samples from the posterior. For superresoltion The variance is expected to be mostly in the high frequencies, because the data term limits low frequency variations. The baselines tend to predict very similar looking images with less detail. Figure 14: Qualitative failure cases of FLAIR on DIV2k and FFHQ. Top row: grainy results from systematic error. Those errors potentially stem from weak prior for those images. For example we do not observe them for the FFHQ dataset Bottom row: Semantically inconsistent failures. Sometimes the model lacks the ability to incorporate globally consistent semantics into its restorations."
        }
    ],
    "affiliations": [
        "ETH Zürich",
        "Max Planck Institute for Informatics, Saarland Informatics Campus"
    ]
}