{
    "paper_title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
    "authors": [
        "Max Ruiz Luyten",
        "Mihaela van der Schaar"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative."
        },
        {
            "title": "Start",
            "content": "The ReasoningCreativity Trade-off: Toward Creativity-Driven Problem Solving"
        },
        {
            "title": "University of Cambridge",
            "content": "6 2 0 2 2 ] . [ 1 7 4 7 0 0 . 1 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "large reasoning paths, State-of-the-art language model (LLM) pipelines rely on bootstrapped reasoning loopssampling diverse chains of thought and reinforcing the highest-scoring onesmainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the models distribution over slashing semantic entropy and undermining creative problemsolving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative."
        },
        {
            "title": "1 Introduction",
            "content": "Diversity collapse in modern training loops. canonical post-training pipeline for training reasoning LLMs includes two main stages: after supervised fine-tuning, the focus shifts to reinforcement learning (RL), which rewards the highest-scoring traces, typically based on correctness. recurring and detrimental side-effect of this process is creative collapse: the models output entropy plummets, resulting in distribution dominated by handful of semantic templates (Mohammadi, 2024). Creative collapse has been extensively reported across RL from human feedback (RLHF) stages (Kirk et al., 2024), when applying GRPO for mathematical reasoning (Shao et al., 2024), and during self-consistency tuning (Wang et al., 2023). In this paper, we examine why this collapse occurs and whether we can apply design choices that prevent it without sacrificing accuracy. Why diversity matters: Creativity as diverse portfolio for generalization. Especially for tasks outside the training distribution (OOD), creativity in problem-solving is not just nice-to-have but rather core requirement for high performance. single reasoning template will inevitably fail when under novel conditions. We therefore frame creativity as the ability to maintain diverse portfolio of high-utility reasoning strategies. This portfolio promotes OOD generalization, robust planning, and genuine discovery (Stanley and Lehman, 2020). The central question. Our work addresses the following question: Can we design framework that: 1. explains why diversity collapse occurs, 2. predicts the specific mode of collapse for different algorithms, and 3. provides provably effective designs that guarantee diverse portfolio of reasoning paths? Existing literature provides incomplete answers. KL penalties preserve diversity by constraining the policys proximity to base model, limiting drift at the cost of indiscriminately penalizing diverse, high-utility distant parameterizations. Sampling-based methods like Boltzmann sampling or top-k decoding also increase diversity at the cost of quality, and, more critically, they cannot recover strategies whose probabilities have vanished during training. The ReasoningCreativity Trade-off Our answer: Distributional Creative Reasoning. Our primary contribution is theoretical: we provide unified framework to analyze diversity decay and provably sufficient remedy. Since our object of study is not an individual trace, we analyze the dynamics of the entire conditional distribution pθ(π x) over the space of solution traces. By modeling training as gradient flow on this probability simplex, we develop framework, Distributional Creative Reasoning (DCR), to analyze diversity decay and uncover its various sources. The DCR objective is core component of this framework and encompasses multiple terms for utility, regularization, and crucial, strictly concave diversity energy: J(p) = U[p] + λD[p] βKL KL(cid:0)ppbase (cid:1). In particular, the diversity energy D[p] is composite functional with two distinct roles: D[p] = αH[p] βQ[p]. In this equation, αH[p], the Shannon entropy, promotes undiscriminated breadth, while βQ[p] is kernel coverage term that penalizes concentration on semantically similar traces, thereby promoting conceptual distinctiveness. This objective can recover various existing algorithms as specific instantiations, including STaR (Zelikman et al., 2022), GRPO (Shao et al., 2024), and DPO (Rafailov et al., 2023). DCR leads to three core theoretical insights: First, it leads to the Diversity Decay Theorem, which predicts distinct modes of collapse under scalar-only objectives for the most well-known reasoning algorithms: (i) winner-takes-all fixation for STaR, (ii) neutral drift for GRPO, and (iii) homogenization of correct strategies for DPO. Second, we prove that incorporating the DCR diversity energy fundamentally can alter the learning dynamics, guaranteeing convergence to unique, stable, and diverse interior equilibrium that neutralizes these collapse modes. Third, DCR provides set of design levers, the specific creativity kernel k(π, π) and the coefficients α and β. We analyze the effects of their choices, resulting in recipe for training models that are both correct and creative. Contributions. 1. Unified Dynamical Lens. We introduce variational framework based on Shahshahani gradient flow that encompasses STaR, GRPO, and DPO. Within this framework, we derive their diversity decay dynamics under scalar objectives and finitebatch noise. We also provide recipe for adapting the framework to new reward designs. 2. Remedy for Collapse. We prove that the DCR objective, with the diversity energy functional D[p] = αH[p] βQ[p] guarantees convergence to high utility and (under an appropriate design) diverse policy, preventing creative collapse. 3. Principled Design Space and Practical Recipes. We detail how to design the creativity kernel and provide guidance on tuning DCRs hyperparameters. We hope this will transform diversity preservation from ad-hoc heuristics to principled design process. Road-map. Section 2 discusses the literature on diversity collapse and related theoretical frameworks. Section 3 formally defines the DCR objective and its associated gradient flow dynamics. Section 4 presents the Diversity Decay Theorem, analyzing the distribution modes of STaR, GRPO, and DPO under scalar objectives. Section 5 proves how the DCR diversity energy reshapes the equilibrium landscape to guarantee diverse outcomes, and Section 6 discusses the design of the creativity kernel. Finally, Section 7 concludes with key insights and future directions. We empirically validate these theoretical collapse modes in Section J."
        },
        {
            "title": "2 Related Work",
            "content": "From reward optimisation to reasoning monoculture. consistent empirical observation is now widely documented in the literature: when language model is trained to maximise single scalar reward, its solution space contracts. Early studies of RLHF showed that the resulting policy rarely develops novel strategies; instead, it reweights the trajectories present in the SFT checkpoint, leading to higher Pass@1 accuracy while leaving the underlying portfolio unchanged (Yue et al., 2025). Controlled ablations subsequently isolated the cause to the RLHF stage. Diversity, measured by entropy, typetoken ratio, and embedding spread, dropped notably after RLHF, while the preceding SFT maintained it (Kirk et al., 2024). The effect is algorithm-agnostic: PPO, Expert Iteration, and GRPO all converge to the same narrow attractors, failing to explore significantly beyond solutions already produced by SFT models (Havrilla et al., 2024). Beyond reasoning-based benchmarks, creative decline has also been documented in other domains. On openended story-telling and idea-generation tasks, aligned Llama-2 variants lose 36 token-level entropy and cluster in few semantic basins (Mohammadi, 2024). Max Ruiz Luyten, Mihaela van der Schaar Treating set of traces as population, Murthy et al. (2025) quantified conceptual variance, further underscoring that RLHF results in less diversity than either instruction-tuned or human populations. The overall conclusion from these works is that performance gains come, at least partly, at the cost of reducing the space of possible explanations and expressions. First attempts at diversity-aware objectives. Several works have sought to counter this collapse by injecting ad hoc diversity terms. Entropy-regularised PPO is the most widespread heuristic, but its effect is largely to keep stochasticity indiscriminately, leaving performance gains on the table, and it does not aim to foster qualitatively distinct ideas. Novelty search and quality-diversity algorithms from evolutionary methods have also been applied to language modelling, yet the generated solutions are typically managed separately from the model, and redistillation frequently regresses gains (Havrilla et al., 2024). At the reward level, Xiao et al. (2024) identified preference-collapse in RLHF and proposed Preference-Matching regulariser that adds an entropy bonus, improving minority-preference recall but with the same drawback as discussed above, and without principled analysis of how much diversity is sufficient. In conclusion, these works demonstrate viability but leave open unifying view that predicts when collapse will occur and the size of the required counterforce. Theoretical lenses on collapse. Two theoretical lines are especially relevant. First, replicator dynamics from evolutionary game theory (Hofbauer and Sigmund, 1998) have been used to model reward optimisation in large populations and already hint that pure utility maximisation drives mass toward the highestfitness type. Second, information-theoretic RL reinterprets entropy bonuses as Lagrange multipliers of KL constraint, but offers no guarantee that entropy will capture structural novelty. While these frameworks provide valuable insights, they do not offer comprehensive analysis of creativity in LLMs. Distributional Creative Reasoning (DCR). Our work builds on the empirical diagnostics of collapse (Yue et al., 2025; Kirk et al., 2024; Havrilla et al., 2024; Mohammadi, 2024; Murthy et al., 2025) and the first corrective steps of PM-RLHF (Xiao et al., 2024), but provides more fundamental and unified solution, differing in three key respects: 1. Variational Framework for Diversity. We include in DCR single concave diversity regularizers, D[p], composed of distinct terms, like entropy (Shannon entropy H[p] weighted by α) and structured novelty promotion (through kernel k(π, π) in quadratic form Q[p] weighted by β). Properly choosing the functional form of the kernel and the relative weights α and β for these components within D[p] ensures convergence to stable, mixed-strategy ensembles, effectively counteracting collapse. 2. Characterization of Diversity Dynamics. Whereas prior work largely reports collapse through empirical analyses, our framework provides dynamical systems examination (Section 4) that demonstrates how the scalar-reward objectives for STaR, GRPO, and DPO inherently lead to distinct dynamical modes that drive the evolution and erosion of diversity. This results in deeper, mechanistic understanding of why reasoning monocultures form. 3. Actionable and Principled Design. DCR characterizes how diverse training objectives and diversity-regularizing terms affect the diversity dynamics. This transforms the search for diversity from heuristics to principled design. This involves selecting the kernel function and hyperparameters for the diversity functional D[p] (i.e., α and β), which become levers to shape the policys distribution."
        },
        {
            "title": "3 Distributional Creative Reasoning",
            "content": "DCR recasts LLM training as dynamical system within the space of probability distributions over solution traces. This perspective enables the formal definition and promotion of diversity alongside correctness. This section establishes DCRs mathematical foundations: its variational objective, the role of the diversity component, and the resultant dynamics. 3.1 The Landscape of Reasoning For given prompt , an LLM generates trace π = (t1, . . . , tπ), sequence of tokens from finite vocabulary up to maximum length . Traces can represent chains of thought, code, or action sequences. The set of all such traces, ST , is vast but finite for any fixed and vocabulary, justifying finite-dimensional analysis, and the choice of the counting measure on ST . An LLMs policy p(x) is probability mass function over ST , represented as vector in the probability simplex S1, where := ST : S1 = (cid:110) [0, 1]S pi = 1 (cid:111) . (cid:88) i=1 This compact, convex polytope is our domain for policy optimization. Treating the policy as full distriThe ReasoningCreativity Trade-off bution, rather than focusing on single best traces, is crucial for modeling its diversity."
        },
        {
            "title": "3.2 The DCR Objective",
            "content": "During training, we optimize an objective J(p) over S1. In DCR, we model the objective as term representing task performance, and others for KL and diversity regularization: J(p) = U[p] + λD[p] βKL KL(cid:0)ppbase (cid:1). The components are: 1. Utility (U[p]): U[p] = (cid:80) (π)p(π) is the expected utility (e.g., correctness) of traces, encouraging high-quality outputs. πST 2. Diversity Energy (D[p]): Weighted by λ 0, this functional (detailed in Section 3.3) rewards policies with diversity, countering collapse. 3. KL-Divergence: It penalizes divergence from reference policy pbase (e.g., the SFT checkpoint), promoting stability. The coefficients λ, β!KL 0 tune this balance. Proposition 3.1 (Concavity of D, cf. Section A.3). If the kernel matrix is PSD, D[p] is concave. It is strictly concave on the affine simplex if α > 0, or if β > 0 and is strictly positive definite on the tangent subspace. Strict concavity ensures well-defined optimization target. In practice, incorporating into J(p) small entropy barrier +εH[p] (ε (0, 104] small) ensures strict concavity and that p(π) > 0 throughout optimization, guaranteeing unique interior maximizer (cf. Section A.4, Proposition A.1)."
        },
        {
            "title": "3.4 Learning Dynamics: Gradient Flow",
            "content": "We model policy evolution under J(p) as gradient flow on S1, endowed with the Shahshahani metric. For tangent vectors u, at policy p, this metric is gp(u, v) = (cid:80) π u(π)v(π)/p(π), and ensures the flow remains on the simplex. The DCR gradient flow is replicator-like ODE (cf. Section A.5, Eq. (6)): pt(π) = pt(π) (Ft(π) Ept[Ft]) , where the effective trace fitness Ft(π) = δJ δp(π) Section A.6): (cid:12) (cid:12)pt is (cf. 3.3 The Diversity Energy Functional D[p] Ft(π) = (π) + λ (α(1 log pt(π)) 2β(Kpt)π) Clearly, the core of DCRs creativity preservation mechanism is the diversity energy functional D[p], designed to reward both probabilistic spread and semantic variation: D[p] = αH[p] βQ[p], with α, β 0. Indeed, its two components serve distinct roles: 1. Shannon Entropy (H[p]): Promotes breadth by rewarding probability distributed across many traces, ensuring baseline level of diversity and exploration. (cid:80) 2. Kernel Coverage (Q[p]): Q[p] = pKp = π,π k(π, π)p(π)p(π). Here, is the matrix of symmetric, positive semi-definite (PSD) creativity kernel (see Section 6) measuring trace similarity. βQ[p] thus penalizes probability concentration on similar traces, fostering semantic distinctiveness. While entropy provides valuable form of regularization, entropy alone is insufficient for structured creativity, as it is blind to the content of the traces. The kernel term is essential for promoting qualitatively different reasoning strategies, and the full functional D[p] is concave, which will prove to be useful: (cid:18) βKL 1 + log pt(π) pbase(π) (cid:19) . Under the discussed regularity assumptions (finite ST , p(π) > 0 via an entropy barrier, PSD k, and bounded (π); cf. Section A.1, (A1)(A7)), the flow converges: Theorem 3.1 (Global Convergence of DCR Training, cf. Section A.6, Theorem A.1). Let (cid:101)J(p) = J(p) + εH[p] be strictly concave on the affine simplex (e.g. if λα + ε > 0 and is PSD) and Assumptions (A1)(A7) hold. For any p0 int S1, the Shahshahani gradient flow pt = Sh (cid:101)J(pt) has unique global solution pt, which lies on the interior of the simplex. The objective (cid:101)J(pt) is strictly increasing (unless pt = p), and pt as , where is the unique maximizer of (cid:101)J(p). Thus, DCR training with its explicit diversity energy functional provably converges to unique policy that balances utility, diversity, and regularization. 3.5 Parametric Realization and Scalability Parametric Realization. In practice, LLMs are function approximators. For tractability, we represent LLMs as parameterization over policies pθ(π) via softmax over logits θπ, so that for any target policy int S1, there exists unique set of Max Ruiz Luyten, Mihaela van der Schaar (gauge-fixed) logits θ such that pθ = p, making the parametric form sufficiently expressive (cf. Section B.2, Proposition B.1). To ensure numerical stability and align with the theoretical requirement of pθ(π) > δ > 0, we assume the use of projection or clipping, which constrain policies to trimmed simplex (cf. Section B). The properties of these parameterized policies and their gradients under stochastic optimization are detailed in Section and underpin the analysis of noise effects in Section 4.3. Scalability. Training is performed with stochastic gradient descent on θ. The kernel coverage term Q[pθ], even though it may be intensive to fully realize, can be efficiently managed in this setting. For mini-batch of sampled traces, an unbiased estimate of the gradient of Q[pθ] can be computed via U-statistic, with computational cost of O(B2) per step. This quadratic complexity is standard in contrastive and metric learning methods. Practical kernel design strategies, including embedding-based kernels and gating mechanisms to focus diversity on correct traces, are discussed in Section 6."
        },
        {
            "title": "4 Collapse Under Scalar Objectives",
            "content": "While the DCR framework (Section 3) encompasses regularization terms, typical LLM training pipeline often defaults to simpler, scalar-driven objectives. These scenarios correspond to DCR with negligible diversity energy coefficient (λ 0) and purely entropic diversity term with small weight (β = 0, small λα). This section provides dynamical systems analysis of these scalar objective cases, demonstrating how they lead to distinct and predictable modes of diversity collapse. This analysis culminates in the Diversity Decay Theorem, which formally characterizes these failure modes and motivates the necessity of the full DCR objective. 4.1 Scalar-Driven Dynamics: The SRCT Framework When diversity energy is minimal, the policy p(t) evolves according to the replicator-entropy flow (formally derived in Sections to F): pπ(t) =pπ(t)(cid:0)ϕπ(p(t)) ϕ(p(t))(cid:1) (1) ε pπ(t)(cid:0)log pπ(t) log p(t)p(t) (cid:1), where ϕπ(p) is the trace score derived from the utility and any KL term, ϕ(p) is its mean, and ε 0 is the effective entropic weight (e.g., ε = εbase + λα). The key diagnostic for diversity dynamics is the evolution of zij(t) = log(pi(t)/pj(t)), the log-ratio between two traces, which follows the ODE (cf. Sections to F): dt zij(t) = (ϕi(p(t)) ϕj(p(t))) εzij(t). (2) This equation reveals that diversity dynamics is driven by two competing forces: selective pressure from score differences, which can negatively impact diversity, and entropic damping, which always pushes log-ratios towards zero (equalization)."
        },
        {
            "title": "4.2 Deterministic Diversity Decay (Small ε)",
            "content": "In the pure-selection limit where ε 0, the raw effect of scalar rewards becomes apparent. While incorrect traces are universally suppressed due to their lower utility (cf. Sections to F), the diversity among correct traces (π C) evolves in three distinct, algorithmspecific modes: STaR: Winner-Takes-All Collapse. For two correct traces a, C, the score difference is ϕa(p) ϕb(p) = (pa pb)/ρ(t), where ρ(t) is the total mass on correct traces. The log-ratio dynamics become dt log pa = (pa pb)/ρ(t) (see Section D). pb Any initial random advantage for trace (pa(0) > pb(0)) creates positive feedback loop, causing pa/pb and leading to rapid, deterministic collapse onto single dominant correct solution. GRPO: Proportional Curation & Drift Vulnerability. For correct traces a, C, GRPOs score design results in ϕa(p) ϕb(p) = 0. The logdt log pa ratio dynamics become 0 (see Section E). pb This preserves the initial relative probabilities of correct traces, creating neutrally stable manifold. However, this provides no active protection for diversity, making the policy vulnerable to stochastic drift from mini-batch sampling. DPO: Equalization & Homogenization. For two correct traces a, C, the score difference is ϕa(p)ϕb(p) = gβ(log pa)gβ(log pb), where gβ() is strictly decreasing function (see Section F). Since dt log pa has the opposite sign of log pa , this dypb pb namic actively drives pa/pb 1. DPO thus homogenizes the probability distribution across the set of preferred traces, but it does not promote targeted semantic diversity between conceptually different solutions (thereby pushing probability mass towards longer traces). The ReasoningCreativity Trade-off"
        },
        {
            "title": "Noise",
            "content": "training is stochastic. In practice, The discrete mini-batch updates converge to Wright-Fisher-type stochastic differential equation (SDE) in the diffusion limit (formally derived in Section H, Theorem H.1): dpi = Fi(p) dt + (cid:32) 1 pi dWi pi (cid:33) pk dWk , (cid:88) where Fi(p) is the deterministic drift and is the batch size. Such random effect from batching can result in noise-induced collapse: STaR: The strong winner-takes-all dynamic is robust, and noise results only on minor perturbations around the deterministic collapse trajectory. GRPO: The neutral stability is fragile. Stochastic fluctuations introduce random selective pressure, causing the policy to drift along the manifold of correct solutions until it fixates on corner or small subset, leading to diversity collapse in this algorithm. DPO: While equalization is the deterministic tendency, noise can break symmetries and result in convergence to state where subset of solutions dominates, even if they are semantically redundant. Although small ε ensures the policy remains in the interior (min pi(t) > δ > 0), the SDE admits unique invariant measure π (Section H, Theorem H.3). For small ε, this measure concentrates in high-utility, lowdiversity regions, as the stationary distribution is heavily influenced by the utility landscape (Section H, Section H.7). Batch noise does not increase diversity; it often accelerates fixation. 4.4 Synthesis: The Diversity Decay Theorem The analyses of both the deterministic and the stochastic dynamics converge on the conclusion that scalar-driven objectives with minimal entropic regularization are fundamentally insufficient to maintain creative repertoire of reasoning strategies. This leads to our main diagnostic result. Theorem 4.1 (Diversity Decay Theorem). Under scalar-objective training (DCR with λ 0 or β = 0), policies exhibit algorithm-specific modes of diversity decay among correct traces: (i) STaR follows winner-takes-all dynamics, deterministically collapsing onto single dominant correct trace. (ii) GRPO evolves on neutrally stable manifold of correct traces, leading to stochastic drift and eventual fixation on low-diversity subset. (iii) DPO actively homogenizes probabilities across high-utility traces, leading to equalization instead of structured semantic diversity. Minimal entropy (ε 1) does not prevent these outcomes and finite-batch noise can accelerate collapse. Scope Note: This theorem characterizes the decay modes for STaR, GRPO, and DPO; it is not general statement about every scalar-only objective. The defined diversity-trajectories highlight the need for more structured lever to influence the dynamics. The failure does not lie in the optimization process itself, but rather in the objective, which lacks an explicit, strong enough force that rewards structured diversity. This motivates the introduction of the DCR objective, specifically its diversity energy functional D[p], as mechanism to counteract these modes and actively carve rich and creative policy landscape."
        },
        {
            "title": "Equilibrium Structure",
            "content": "Scalar objectives, as demonstrated in Section 4, lead to degeneration in reasoning diversity. The DCR framework provides solution by incorporating diversity energy functional, D[p]. It reshapes the optimization landscape, altering the learning dynamics toward different equilibria: those that contain various simultaneously correct and diverse traces. This section details how DCRs diversity regularizer achieves this shift. 5.1 From Collapse to Structured Diversity With its full objective J(p) = U[p] + λD[p] βKL KL(ppbase) and diversity weight λ > 0, DCR leverages the diversity energy D[p] = αH[p] βQ[p]. 5.2 The Dual Levers of Diversity Energy: Shaping The specific structure of the equilibrium with diversity weight is shaped by the two components of the diversity energy, λD[p] = λαH[p] λβQef [p]. For practical applications, the quadratic term can incorporate an effective kernel kef (π, π) := R(π)R(π)ksem(π, π), which gates semantic kernel ksem with verifier R(π) = 1π to focus the diversity pressure only on correct traces (see Section I, Section 6.3). Max Ruiz Luyten, Mihaela van der Schaar 1. Entropic Pressure (λαH[p]): The entropic pressure promotes probabilistic breadth. It is the simplest mechanism for encouraging the equalization of probabilities among correct traces, at the cost of also promoting incorrect ones (Section I)."
        },
        {
            "title": "Structural",
            "content": "term penalizes Diversity 2. Kernel-Driven (λβQef [p]): for concentrating mass on sets of correct traces that are semantically similar (as defined by ksem). It therefore actively promotes structural or semantic diversity among distinct, valid reasoning paths (Section I). Entropy alone cannot achieve this structured outcome."
        },
        {
            "title": "Diversity at Equilibrium",
            "content": "The DCR equilibrium is characterized by the firstorder condition Uπ 2λβ(Kef p)π εtotal log π Constant (ignoring KL terms and gauge constants; see Section I.2). crucial consequence for incorrect traces (where (Kef p)i = 0 and Ui = 0) and correct traces (where Uc = 1) is the exact equilibrium ratio (cf. Section I.2): (cid:18) p 1 2λβ(Kef p)c εtotal exp (cid:19) . This identity reveals central trade-off. To effectively suppress incorrect traces, the exponents numerator, 12λβ(Kef p)c, must be substantially positive. This provides clear heuristic for tuning the kernel weight: the kernel penalty among correct traces should not overwhelm the unit utility gain, i.e., 2λβ(Kef p)c < 1. At the same time, while larger εtotal (from larger λα) aids equalization among correct traces, it also increases the denominator of the exponent, thereby weakening the suppression of incorrect traces. careful choice of λα and λβ is therefore essential to steer this trade-off and achieve phase where incorrect traces are suppressed while rich, diverse set of correct solutions thrives."
        },
        {
            "title": "6 The Creativity Kernel",
            "content": "The preceding sections established that DCRs diversity energy, D[p] = αH[p] βQ[p], is pivotal in guiding learning towards equilibria that are diverse and stable (Section 5). While the entropy component, αH[p], provides naive probabilistic breadth, it is intrinsically blind to the content and structure of reasoning traces. This section explains how to build the kernel-based component βQ[p] to provide plausible, grounded mechanism for developing LLMs with structured, semantic diversity."
        },
        {
            "title": "6.1 Limitations of Entropic Diversity",
            "content": "H[p]s utility for promoting genuine creativity is limited because it operates solely on trace probabilities, irrespective of their content or conceptual underpinnings. It cannot, for instance, distinguish set of solutions that are mere syntactic rephrasings of single idea from set representing truly distinct problemsolving strategies. Entropy alone is insufficient for structured creativity; without mechanism to differentiate valuable novelty from trivial variation, it also preserves probability mass on incorrect traces, hindering optimization of correctness. To generate correct, structurally varied solutions, an LLM requires mechanism that appreciates and actively promotes semantic dissimilarity rather than merely probabilistic dispersion. 6.2 Sculpting Semantic Diversity Q[p] term π,πST kernel quadratic The = (cid:80) k(π, π)p(π)p(π) within DCR is designed to fill this critical gap. The creativity kernel k(π, π) is symmetric, positive semi-definite (PSD) function the similarity or redundancy that quantifies between traces π and π. By including βQ[p] (for β > 0) in the diversity energy, DCR explicitly penalizes policies that concentrate probability on sets of traces deemed highly similar by k. As explored in Section (Section I.1), an ideally engineered kernel could, in principle, sculpt highly specific target equilibrium p. Achieving this, however, would require the kernel to satisfy stringent, globally defined, and equilibrium-dependent conditions (cf. Section I, Proposition I.1). While this idealized scenario underscores the deep, direct influence of k(π, π) on the policy structure p, its practical realization is typically infeasible. This motivates the shift towards more practical, learnable semantic kernels. 6.3 Practical Design of the Semantic Kernel more pragmatic and powerful DCR strategy, detailed in Section (Section I.2), must utilize learnable semantic kernel ksem(π, π) as its foundation. This ksem should be able to capture meaningful similarities between traces. To ensure this semantic guidance is applied judiciously, DCR adopts an effective kernel, kef (π, π): kef (π, π) := R(π)R(π)ksem(π, π), where R(π) = 1{π C} is binary verifier for correct traces C. The kernel coverage term thus becomes Qef [p] = (cid:80) c,cC pcpcksem(c, c). This construction focuses the diversity-promoting penalty λβQef [p] The ReasoningCreativity Trade-off exclusively on interactions among correct traces, promoting targeted diversity: it encourages the model to find diverse valid solutions, rather than rewarding diverse ways to be wrong, as incorrect traces do not participate in the kernel interactions that shape diversity (recall (Kef p)i = 0 for from Section 5.3). Practical examples of ksem can include embeddingbased kernels, where we compute an embedding for each trace (e.g., sentence-level embeddings over the full chain of thought) and apply standard PSD kernel on those, or domain-tailored kernels, in structured tasks like mathematics, where ksem can be learned using structural proximity (e.g., from proof-step or lemma dependency graphs), so that similarity reflects shared strategy rather than just surface-level wording. 6. Implementation and Desiderata The kernel term can be readily integrated into standard training loops. For SGD, the gradient of Qef [p] can be estimated with the mini-batch of sampled traces. The quadratic nature of Qef [p] admits Ustatistic estimator with O(B2) per-step cost, manageable complexity in the context of LLM training. The efficacy of kernel-driven diversity inherently depends on the quality of the learned ksem(π, π). Key desiderata for its design include (cf. Section 6.3): (1) Intra-Lump Coherence or high similarity for traces belonging to the same essential category or lump of solutions (ignoring syntactic differences); and (2) Inter-Lump Discrimination: It must assign low similarity to traces from qualitatively different correct problem-solving approaches."
        },
        {
            "title": "7 Concluding Insights",
            "content": "Scalar reward maximization leads to collapse of strategic diversity. This paper has established principled remedy: Distributional Creative Reasoning (DCR), which recasts training as gradient flow on the policy simplex. predicting algorithm-specific Our Diversity Decay Theorem offers precise diagnosis, collapse modeswinner-takes-all (STaR), neutral drift (GRPO), and homogenization (DPO). The DCR framework counteracts this decay by incorporating diversity energy functional, D[p] = αH[p] βQ[p]. We proved this ensures convergence to unique, stable, and interior policy p. DCR provides concrete design levers. The creativity kernel, particularly when gated to correct traces via an effective kernel keff , actively promotes novel, valid strategies. Tuning the balance between entropic breadth (α) and kernel-driven diversity (β) allows practitioners to navigate the trade-off between equalization and the suppression of incorrect traces, as quantified by our equilibrium analysis."
        },
        {
            "title": "7.1 Testable Predictions",
            "content": "Our theoretical framework yields set of concrete, falsifiable predictions that align with existing empirical observations: 1. Algorithm-Specific Decay Modes."
        },
        {
            "title": "Under",
            "content": "scalar-only objectives: STaR exhibits winner-takes-all fixation on single successful strategy. GRPO shows neutral drift among correct traces, leading to stochastic erosion of diversity. DPO will act as an entropy equalizer, homogenizing probabilities across preferred traces. 2. Kernel Sufficiency for Structured Diversity. An entropy-only approach (β = 0, α > 0) preserves indiscriminate policy breadth at the cost of correctness. kernel-inclusive approach (β > 0) can not only prevent collapse but will also measurably increase the semantic diversity among correct solutions. Acknowledgements. The authors would like to acknowledge and thank their funders, where Max Ruiz Luyten is funded by AstraZeneca. Moreover, we would like to warmly thank all the anonymous reviewers, alongside research group members of the van der Schaar lab (www.vanderschaar-lab.com), for their valuable input, comments, and suggestions as the paper was developed. We used ChatGPT and Gemini to edit and polish the text and for coding assistance. References Alexander Havrilla, Yuqing Du, Sharath Chandra Raparthy, Christoforos Nalmpantis, Jane Dwivedi-Yu, Eric Hambro, Sainbayar Sukhbaatar, and Roberta Raileanu. Teaching large language models to reason with reinforcement learning. In AI for Math Workshop @ ICML 2024, 2024. URL https:// openreview.net/forum?id=mjqoceuMnI. J. Hofbauer and K. Sigmund. Evolutionary Games and Population Dynamics. Cambridge University Press, Cambridge, 1998. ISBN 9780521625708. URL https://pure.iiasa.ac.at/id/eprint/5442/. Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, Edward Grefenstette, and Roberta Raileanu. Understanding the Max Ruiz Luyten, Mihaela van der Schaar Ethan Zelikman, Yuhuai Wu, and Noah D. Goodman. Star: Bootstrapping reasoning with reasoning. arXiv preprint arXiv:2203.14465, 2022. effects of RLHF on LLM generalisation and diversity. In The Twelfth International Conference on Learning Representations, 2024. URL https: //openreview.net/forum?id=PXD3FAVHJT. Behnam Mohammadi. Creativity has left the chat: The price of debiasing language models, 2024. URL https://arxiv.org/abs/2406.05587. Sonia Krishna Murthy, Tomer Ullman, and Jennifer Hu. One fish, two fish, but not the whole sea: Alignment reduces language models conceptual diversity. In Luis Chiruzzo, Alan Ritter, and Lu Wang, editors, Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 11241 11258, Albuquerque, New Mexico, April 2025. Association for Computational Linguistics. ISBN 9798-89176-189-6. URL https://aclanthology.org/ 2025.naacl-long.561/. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher Manning, Stefano Ermon, and Chelsea Finn. Direct preference optimization: Your language model is secretly reward model. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https:// openreview.net/forum?id=HPuSIXJaa9. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024. URL https: //arxiv.org/abs/2402.03300. Kenneth O. Stanley and Joel Lehman. Why greatness cannot be planned: The myth of the objective, 2020. Springer, 2015 original, updated. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview. net/forum?id=1PL1NIMMrw. Jiancong Xiao, Ziniu Li, Xingyu Xie, Emily Getzen, Cong Fang, Qi Long, and Weijie J. Su. On the algorithmic bias of aligning large language models with rlhf: Preference collapse and matching regularization, 2024. URL https://arxiv.org/abs/2405. 16455. Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, and Gao Huang. Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model?, 2025. URL https://arxiv.org/abs/2504.13837. The ReasoningCreativity Trade-off"
        },
        {
            "title": "A Mathematical Foundations and Problem Formalism",
            "content": "This appendix fixes notation and geometric conventions on the simplex, records canonical inequalities and curvature facts for the objective slices (entropy/KL/kernel), develops the Shahshahani gradient representation, and derives global properties of the induced gradient flows (Lyapunov identity, logratio contraction, timeuniform floors/caps, and exponential convergence). It also states generic BarrierDominance (BD) calculus for forward invariance of trimmed domains. A.1 Preliminaries and Standing Assumptions Scope & conventions. All logarithms are natural; 0 log 0 := 0. The indicator is 1{}, and u, is the Euclidean inner product. We write to mean for an absolute constant C; any parameter dependence is displayed as C(). Sums over traces are with respect to the counting measure on the finite set ST ."
        },
        {
            "title": "Meaning",
            "content": "Fixed prompt / task instance Trace (finite token sequence, length ) Trace set up to length ; := ST Policy mass on π (probability on ST ) Probability simplex on ST Shannon entropy, (cid:80) KullbackLeibler divergence, (cid:80) π p(π) log p(π) q(π) Symmetric positive semidefinite kernel on ST π ST ST p(π) S1 H[p] DKL(pq) k(π, π) = [k(π, π)] Kernel matrix in RSS D[p] Diversity: α H[p] β pKp π p(π) log p(π) Standing assumptions. (A1) Finite trace space. ST is finite for fixed horizon < ; policies are S1 RS. (A2) Interior vs. trimmed domain. Variational derivatives and Shahshahani gradients are taken on int S1 = := {p S1 : pi {p : minπ p(π) > 0}. When floor is operative, we work on the trimmed simplex S1 δ i}, nonempty iff δ 1/S. δ (A3) Entropy/KL domains. H[p] and (when present) DKL(ppbase) are defined on the closed simplex; all variational derivatives are computed on int S1. Adding +εH (ε 0) is permitted. (A4) Kernel regularity and strictness on . = 0. Write := {1} and ΠT := 11. The quadratic slice pKp is strictly concave along feasible directions iff ker = {0} (equivalently, ΠT KΠT 0 on ). (A5) Bounded utility. (π) Umax < on ST whenever U[p] = (cid:80) π (π)p(π) is used. (A6) Nonnegative coefficients. α, β, βKL, λ, ε 0 unless noted. (A7) Base-policy support (for KL). If DKL(ppbase) is present, assume pbase(π) pbase,min > 0 for all π. Norm conventions. For vectors: 1, 2, . For RSS: A22 (spectral norm) and := maxi (cid:80) Aij. A.2 Spaces and Simplex Geometry A.2.1 Trace space, simplex, tangent. Fix vocabulary and horizon N. ST = {(t1, . . . , tℓ) : 1 ℓ T, ti V}, := ST < . Max Ruiz Luyten, Mihaela van der Schaar Policies are S1 := {p [0, 1]S : 1, = 1}. On int S1, feasible directions lie in the affine tangent = TpS1 = {v RS : 1, = 0} = {1}, which does not depend on p. A.2.2 Floors: policy vs. effective. chosen floor δ (0, 1/S] defines the trimmed simplex S1 cliprenormalize with threshold δ (0, 1] induces an effective floor δ = {p S1 : pi δ i}. Algorithmic δeff (p) = δ j=1 max{pj, δ} (cid:80)S (cid:104) δ 1 + (S 1)δ (cid:105) , , δ since the denominator ranges from 1 to 1 + (S 1)δ (max at simplex vertex). The exact cliprenormalize map and logit lift are given in Section B. A.2.3 Canonical inequalities. Lemma A.1 (Meanlog bounds and entropic Lipschitzness). Let S1 and log := (cid:80) pi log pi. 1. (Meanlog bounds) For all S1, log log 0. 2. (Entropic Lipschitz on δ ) Fix δ (0, 1/S] and Λ(δ) := 1 + log(1/δ). For all p, S1 δ , (cid:13)p (log log p) (log log q)(cid:13) (cid:13) H(p) H(q)2 1 δ (cid:13)2 Λ(δ) (2 + q2, H(r) = (1 + log r), S) q2. (3) (4) Proof. (1) Upper bound: each log pi 0. Lower bound: H(p) is maximized at the uniform = (1/S)1 with H(u) = log S. (2) For (3), 2H(r) = diag(1/ri) on int S1 so 2H(r)22 1/δ on S1 applies. , and the meanvalue theorem δ For (4), set E(r) := (log log r) and G(r) := log r. Then DG(r)[h] = (1 + log r), hence DG(r)22 Λ(δ). For B(r) := log r, DB(r)[h] = (cid:68) (1 + log r) (cid:69) + log h, so DB(r)22 Λ(δ) S1 δ . Therefore DE(r)22 Λ(δ)(2 + + (Λ(δ) 1) because 1 + log r2 Λ(δ) S, r2 1, and log Λ(δ) 1 on S) and the meanvalue theorem yields (4). A.3 Functionals: Entropy, KL, Kernel, and Diversity A.3.1 Entropy and KL calculus. On int S1, H[p] = (cid:88) pi log pi, δH δpi = (1 + log pi), 2H = diag(1/pi), DKL(pq) = (cid:88) pi log pi qi , δ δpi DKL(pq) = 1 + log pi qi , 2DKL(pq) = diag(1/pi), with qi > 0 for KL. Both extend continuously to the closed simplex (using 0 log 0 := 0). The ReasoningCreativity Trade-off A.3.2 Kernel quadratic form. For = 0, set Q[p] = pKp. Then (Q)(p) = 2Kp, 2(Q) = 2K 0, so is concave on RS and 2K22-Lipschitz in gradient. Along any feasible direction , d2 dt2 [Q(p0 + tv)]t=0 = 2 vKv, hence strict concavity on feasible directions iff ker = {0} (equivalently ΠT KΠT 0 on ). A.3.3 Diversity functional. Let D[p] = αH[p] βQ[p] with α, β 0. Writing κT := λmin (cid:0)(ΠT KΠT ) (cid:1) 0, for all int S1 and , 2D[p] v, = α2H[p]v, 2β vKv (cid:0)α + 2βκT (cid:1) v2 2. Thus is concave, αstrongly concave on the affine simplex if α > 0, and strictly concave along feasible directions when α = 0, β > 0, and κT > 0. A.4 Barriers and Interiority A.4.1 Entropy/KL barriers exclude boundary maximizers. Proposition A.1 (Interior maximizers). Let be concave on S1. 1. For any ε > 0, (cid:101)J(p) := J(p) + εH[p] is strictly concave on int S1 and attains its unique maximum at an interior point. 2. If pbase has full support (A7), then for any βKL > 0, J(p) βKLDKL(ppbase) cannot be maximized on the boundary S1. Proof. (1) On int S1, 2H = diag(1/p) 0, so (cid:101)J is strictly concave. At boundary point with some pi = 0, the directional derivative of pi log pi = log along ei diverges to + as 0, excluding boundary maxima. (cid:3) (2) With pi = 0, for p(t) = (1 t)p + tei, t0 = log + 1 log pbase,i , so the derivative of dt βKLDKL(pbase) is + inward. Boundary maxima are impossible. pbase,i (cid:2)t log A.4.2 No finitetime boundary hitting under bounded fitness. Lemma A.2 (Bounded fitness implies interiority). Consider the replicator ODE pi = pi continuous field satisfying supp,i Gi(p) < . If p(0) int S1, then for all 0 and all i, (cid:0)Gi(p) Ep[G](cid:1) with e2M tpi(0) pi(t) e2M tpi(0), in particular pi(t) > 0 for all t. Proof. dt log pi = Gi(p) Ep[G] is bounded in [2M, 2M ]; integrate. Remark A.1 (Applicability). For Gi(p) = (i) 2λβ (Kp)i, (A5) and finiteness of imply (Kp)i and hence uniform < . A.5 Shahshahani Geometry and Gradient Representation A.5.1 Metric and replicator form. On int S1, the Shahshahani metric on = {1} is gp(u, v) := (cid:88) i=1 uivi pi (u, ). (5) Max Ruiz Luyten, Mihaela van der Schaar For 1, the Shahshahani gradient is the unique with gp(w, v) = DJ[p] for all , yielding the classical replicator form pi = (ShJ)i = pi (cid:16) δJ δpi (cid:17) Ep[ δJ δp ] , Ep[ξ] := (cid:88) piξi. (6) Mass is conserved ((cid:80) δJ/δp (gauge invariance), since centering by Ep[] removes it. pi = 0). The dynamics are invariant under adding any scalar field a(p) to the scores A.5.2 Integrability of replicator fields. Proposition A.2 (Integrability on the simplex). Let 1(int S1; RS) and consider pi = pi The following are equivalent; they hold iff there exists 1 with = ShJ: (cid:0)Gi(p)Ep[G](cid:1). (AC) Anchored crosspartials: for some (hence any) anchor k, pj (Gi Gk) = pi(Gj Gk) for all i, = k. (PJ) ProjectedJacobian symmetry: there exists scalar field a(p) such that ΠT D(cid:0)G a1(cid:1)ΠT is symmetric on for all p. In that case, is unique up to an additive constant and gauge a(p)1. Proof sketch. Work on the chart = (p1, . . . , pS1), pS = 1 (cid:80)S1 i=1 qi. The -restricted 1form is ωT = (cid:80)S1 i=1 (Gi GS) dqi. Condition (AC) is the closedness of ωT ; on the simply connected domain, Poincares lemma yields exactness, giving with qiJ = Gi GS. Setting a(p) := GS(p) recovers the replicator field. (PJ) is the coordinatefree restatement on . Instantiation. For = + λD βKLDKL(()pbase) + εH, the pointwise variational derivative is Fi(p) := δJ δpi = Ui 2λβ (Kp)i (λα + ε) (1 + log pi) βKL (cid:16) 1 + log (cid:17) , pi pbase,i and the flow is pi = pi (cid:0)Fi(p) Ep[F ](cid:1). A.6 GradientFlow Dynamics and Convergence A.6.1 ODEs and barrier strength. Let J(p) = U[p] + λD[p] βKLDKL(ppbase), (cid:101)J(p) = J(p) + εH[p], and define the aggregate barrier strength := ε + λα + βKL. Then the (cid:101)Jflow is pi = pi (cid:16) (cid:17) (cid:101)Fi(p) Ep[ (cid:101)F ] , (cid:101)Fi(p) = Fi(p) ε(1 + log pi), with mass conservation (cid:80) pi = 0. A.6.2 Lyapunov identity (with boundary continuity). Lemma A.3 (Strict Lyapunov identity). Along any solution (cid:55) pt int S1 of (7), dt (cid:101)J(pt) = gpt (cid:0)Sh (cid:101)J(pt), Sh (cid:101)J(pt)(cid:1) = (cid:88) pt(i) (cid:16) δ (cid:101)J δpi (pt) Ept[ δ (cid:101)J δp ] (cid:17)2 0, (7) (8) with equality iff Sh (cid:101)J(pt) = 0. Moreover, the righthand side extends continuously to the closed simplex: p(log p)2 0 as 0 and (A7) yields the same for p(cid:0) log pbase (cid:1)2 . The ReasoningCreativity Trade-off A.6.3 Logratio contraction; timeuniform floor and cap. Lemma A.4 (Logratio contraction and uniform bounds). Assume (A1), (A4), (A5), (A7) and > 0. For zij(t) := log pi(t) pj (t) , where zij(t) = zij(t) + cij(pt), cij(p) B, := 2Umax + 4λβ + βKL log pbase,max pbase,min . Hence zij(t) zij(0)eAt + (1 eAt) , and for all 0 and all i, 1 eM pi(t) eM . (9) (10) dt log pi = (cid:101)FiEp[ (cid:101)F ] to get zij = (cid:101)Fi (cid:101)Fj. The (log p)terms contribute zij, Proof. Subtract the logdynamics while the remaining terms are bounded by B. Solve the linear ODE and use the standard maxcoordinate argument to obtain (10). A.6.4 Global convergence with explicit rate. Theorem A.1 (Wellposedness, unique equilibrium, exponential rate). Assume (A1), (A4), (A5), (A7) and > 0. For any p0 int S1, the flow (7) admits unique global solution staying in the compact trimmed simplex S1 with δ = 1/(SeM ) from Lemma A.4. On the affine simplex, δ 2 (cid:101)J(p) = 2H(p) 2λβK = diag(1/p) 2λβK I, so (cid:101)J is Astrongly concave and has unique maximizer int S1. Moreover, and dt (cid:0) (cid:101)J(p) (cid:101)J(pt)(cid:1) 2A δ (cid:0) (cid:101)J(p) (cid:101)J(pt)(cid:1), pt p2 (cid:113) (cid:124) (cid:0) 2 (cid:101)J(p) (cid:101)J(p0)(cid:1) (cid:125) (cid:123)(cid:122) =:C exp(Aδ t) . Proof sketch. Lyapunov identity and Lemma A.4 give global existence and uniform floor δ. Strong concavity on (cid:101)J(p) (cid:101)J(p)(cid:1). Since gp(w, w) the affine simplex yields the Polyak(cid:32)Lojasiewicz inequality ΠT (cid:101)J(p)2 δΠT w2 , (8) implies exponential decay of the suboptimality gap and then of pt p2 by strong concavity. 2 on S1 2 2A(cid:0) δ Remarks. (i) If = 0 (no entropy/KL barrier), the contraction term in (9) vanishes; neither the timeuniform floor/cap (10) nor exponential convergence follow by this route (uniqueness may still hold if ΠT KΠT 0). (ii) For = 1, statements are trivial. (iii) The bound for (Kp)i (Kp)j can be sharpened (e.g., by 2K22) without changing the argument. A.7 Special Case: Replicator Flow with SingleSite Scores Consider pi = pi Proposition A.3 (Lyapunov structure). Define L(p) = (cid:80)S (cid:0)Gi(pi) Ep[G](cid:1) where Gi depends only on pi. i=1 Ψi(pi) with Ψ i(s) = Gi(s). Then dt L(p(t)) = Varp(t) (cid:2)G(p(t))(cid:3) = (cid:88) (cid:0)Gi(pi) Ep[G](cid:1)2 pi 0, with equality iff Gi(pi) is constant across the support. If, in addition, all Gi are identical and strictly monotone, the unique interior equilibrium is uniform on its support. In general, with distinct strictly monotone Gi, the interior equilibrium need not be uniform. Max Ruiz Luyten, Mihaela van der Schaar A.8 BarrierDominance (BD) Scope. Consider the deterministic replicator field endowed with an entropy slice pi = pi (cid:0)ϕi(p) ϕ(p)(cid:1) + εBD pi (cid:0)log log pi (cid:1), ϕ(p) := (cid:88) pj ϕj(p), (11) with εBD 0 and selection score field ϕ : S1 RS. Norms are as in A.1. A.8.1 Entropy face gap LS(δ). Definition A.1 (Entropy face gap). For 2 and δ (0, 1/S], LS(δ) := inf (cid:110) log log δ : S1, s.t. pi = δ (cid:111) . Lemma A.5 (Closed form and properties). For all 2 and δ (0, 1/S], LS(δ) = (1 δ) log 1 δ (S 1)δ , with LS(δ) 0 (equality iff δ = 1/S); LS is strictly decreasing in δ and, for fixed δ, strictly decreasing in S. Proof. Fix the face {pi = δ}. Jensen for the convex (cid:55) log implies the minimum when the remaining mass 1 δ is split equally: pj = (1 δ)/(S 1) for = i. Lemma A.6 (Twosided bounds). For all 2 and δ (0, 1/S], log 1 (S 1)δ (cid:124) (cid:0)1 + log 1 (S1)δ (cid:1)δ LS(δ) log 1 (S 1)δ (cid:123)(cid:122) lower (cid:125) (cid:124) (cid:123)(cid:122) upper . (cid:125) A.8.2 Deterministic BD conditions. Assume ϕ is bounded on the operative domain: Mϕ, := supp ϕ(p) < , Mϕ,2 := supp ϕ(p)2 < . Proposition A.4 (Forward invariance of S1 ). For the flow (11), fix δ (0, 1/S]. If either δ (ℓ) (ℓ2) εBD LS(δ) 2 Mϕ,, εBD LS(δ) 2 Mϕ,2, then δ is forward invariant: any solution with p(0) S1 δ satisfies p(t) S1 δ for all 0. Proof. On the face {pi = δ}, pi pi = ϕi ϕ (cid:124) (cid:123)(cid:122) (cid:125) 2Mϕ, or 2Mϕ,2 + εBD (log log δ) (cid:125) (cid:124) (cid:123)(cid:122) LS (δ) . Hence the outward normal component is nonnegative on every face under either condition. By Nagumos tangency criterion (viability theory), S1 is forward invariant. δ Remark A.2 (Tightness and scaling). The factor 2 in the ℓ condition is tight without further structure (place all remaining mass on single coordinate and choose ϕ with opposite signs on the two active coordinates). For small δ, LS(δ) log(cid:0)1/((S 1)δ)(cid:1) and degrades monotonically with S; at δ = 1/S, LS(δ) = 0 and the trimmed set collapses to the uniform point. The ReasoningCreativity Trade-off Parametric (Logit-Space) Geometry and Propagation Bounds B."
        },
        {
            "title": "Introduction and Notation",
            "content": "This appendix records the deterministic, parametric (logit-space) geometry used throughout: the soft-max map, its Jacobian, conditioning, Lipschitz constants, the cliprenormalize/logit-lift construction, composite smoothness constants, and second-order remainders. Stochastic topics (e.g., clipping bias, mini-batch covariance) are deferred to Section H. Notation. Let 1 := (1, . . . , 1). The simplex and its relative interior are S1 := {p [0, 1]S : 1, = 1}, ri(S1) = {p S1 : pi > 0 i}. The centered logit space (gauge slice) and the tangent space are Θ := {θ RS : 1, θ = 0}, := 1, ΠT := 1 11, := ΠT . Define the soft-max pθ := softmax(θ) := eθ/1, eθ S1, and its Jacobian Jθ := θpθ = diag(pθ) pθp θ . Appendix writes the same covariance-form matrix as S(p) := diag(p) pp; we use the identification Jθ = S(pθ) (12) to keep notation uniform across appendices. B.2 Soft-max Map: Gauge, Inverse, and Log-ratio Lemma B.1 (Translation invariance). For any θ RS and R, softmax(θ + c1) = softmax(θ). Proposition B.1 (Real-analytic diffeomorphism). The restriction softmax : Θ ri(S1) is real-analytic diffeomorphism with inverse : ri(S1) Θ, G(p) := log = log 1 1, log 1. Proof. For ri(S1), writing log := 1 1, log p, softmax(G(p))i = exp(cid:0)log pi log p(cid:1) exp(cid:0)log pj log p(cid:1) = pi. (cid:80) Conversely, for θ Θ, G(softmax(θ))i = log (cid:17) (cid:16) eθi (cid:80) eθj (cid:88) log 1 (cid:17) (cid:16) eθk (cid:80) eθj = θi. Analyticity follows from analyticity of exp and log and linearity of C. Corollary B.1 (Log-ratios & gauge uniqueness). If = softmax(θ) with θ Θ, then θi θj = log(pi/pj) for all = j. If softmax(θ) = softmax(θ), then θ θ = c1; on Θ this forces θ = θ. Remark B.1 (Edge case = 1). If = 1, then Θ = {0}, 0 = {1}, and softmax(0) = 1. B.3 Geometry and Conditioning of the Soft-max Jacobian Basic differential. For any θ, Jθ = diag(pθ) pθp θ = S(pθ). (13) Max Ruiz Luyten, Mihaela van der Schaar Lemma B.2 (Kernel, rank, variance form). Let = pθ. Then ker Jθ = span{1} and rank(Jθ) = 1. Moreover, for , vJθv = (cid:88) piv2 (cid:16) (cid:88) (cid:17)2 pivi = 1 2 (cid:88) i,j pipj (vi vj)2 = Varip(vi) 0, with equality iff = 0. Corollary B.2 (Loewner sandwich on ; global operator norm). If pmin := mini pθ(i) > 0, then pmin Jθ 1 2 , Jθop 1 2 . 2. Lower qiv2 qivi)2 0 (CauchySchwarz with weights q). Since JθT and Jθ1 = 0, the global Jθop equals the Proof. Upper bound: for , Popovicius inequality yields Varp(vi) 1 bound: write = pmin1 + with 0, (cid:80) ((cid:80) supremum on . 4 (max min v)2 1 qi = 1 Spmin. Then for , vJθv pminv2 2 v2 2 = (cid:80) Remark B.2 (Tightness). The upper bound 1 attained at = 1 1, where Jθ = (1/S)I. 2 is attained for = 2 at = (1/2, 1/2); the lower bound pmin is Lemma B.3 (Per-coordinate bound). For every θ and {1, . . . , S}, θk Jθop 1 3 3 and the constant 1 3 3 is optimal (already for = 2). Proof sketch. WLOG = 1. With := p1 (0, 1) and RS1 0 , (cid:80) = 1 a, θ1 Jθ = (a, b), (a, b) = (cid:20)(1 a)(1 2a) (1 2a)b 2bb diag(b) (1 2a)b (cid:21) . The Rayleigh quotient in is convex on the simplex (Hessian 4yy 0), thus maximized at vertex = (1a)ej. In the {e1, ej} subspace the spectral norm equals 2a(1 a)1 2a, whose maximum over [0, 1] is 1/(3 3) at = 1 . 2 1 2 3 Theorem B.1 (Global Lipschitz continuity of θ (cid:55) Jθ). For all θ1, θ2 Θ, Jθ2 Jθ1op 1 3 3 θ2 θ11 3 3 θ2 θ12 3 θ2 θ1. Proof. Parameterize θ(τ ) = θ1 + τ (θ2 θ1). By the fundamental theorem of calculus and Lemma B.3, Jθ2 Jθ1op (cid:90) 1 (cid:88) 0 k=1 θk θk Jθ(τ )op dτ 1 3 3 θ1. The ℓ2, ℓ versions follow from norm monotonicity. Remark B.3 (Dimension-free lower bounds). Along θ(t) = (t, t, 0, . . . , 0) one has dJθ(t)/dtop = 2/(3 3) at the extremal while θ(t)1 = 2, giving optimality in the ℓ1 domain norm. Restricting to the same two-coordinate subspace gives L(2) 3) and L() 2/(3 3). 2/(3 Boundary behavior. As pmin 0 (e.g., pθ ei), Jθ = S(pθ) 0. Then λmin(Jθ ) 0 while λmax(Jθ ) 1 2 , so κ(Jθ ) (1/2)/pmin . The ReasoningCreativity Trade-off B.4 ClipRenormalize and the Logit Lift Definition and effective floor. Fix δ (0, 1). Define the cliprenormalize operator Cδ (p) := max(p, δ) max(p, δ)1 , (max(p, δ))i := max{pi, δ}. If = Cδ (p), then qi δmin := δ/(1 + (S 1)δ), and this lower bound is sharp whenever clipping occurs. Given δ (0, 1/S), δ = δ 1 (S 1)δ = min (cid:0)Cδ (p)(cid:1) δ p. Logit lift and normalization cancellation. Define the logit lift : Θ Θ, (θ) := log (cid:0) max(pθ, δ)(cid:1). If = max(pθ, δ) and := p/p1, then (θ) = log and softmax(P (θ)) = = Cδ (pθ). (14) Proposition B.2 (Global Lipschitz of and softmax ). For all θ, ϑ Θ, (θ) (ϑ)2 1 2δ θ ϑ2, softmax(P (θ)) softmax(P (ϑ))2 1 4δ θ ϑ2. Proof. pθ pϑ2 1 [δ, 1]; is nonexpansive; softmax has Jacobian norm 1 2 . 2 θ ϑ2 (MVT + Corollary B.2); clipping is 1-Lipschitz in ℓ2; log is 1/δ-Lipschitz on Differentials (a.e.). Since is piecewise 1, DP (θ)op 1 2δ for a.e. θ, D(softmaxP )(θ)op 1 4δ . (15) Local no-clip criterion. is clipped: (θ) = log pθ = θ. If mini pθ0 (i) δ +ε and θ θ02 ε, then pθ pθ0 1 2 ε, hence no coordinate Post-clipping deviation with known floor. If mini pθ(i) δ > 0 and := {i : pθ(i) < δ}, then (θ) θ2 δ δ S. δ δ (16) Smooth vs. hard clip; Lipschitz of DP . Let LDP denote Lipschitz constant of θ (cid:55) DP (θ) in operator norm. Two regimes are useful: Hard-clip, kink-free segment (active set fixed): LDP 1 4δ2 + 3 3 1 δ . Smooth clip surrogate χτ : if 0 χ τ 1 and Lip(χ τ ) cτ , then LDP 1 + cτ 4δ2 + cτ 2δ + 3 3 1 δ . (17) (18) Max Ruiz Luyten, Mihaela van der Schaar B.5 Composite Smoothness for Φ(θ) := J(softmax(P (θ))) Domain and Assumption (A). By (14), p(θ) := softmax(P (θ)) = Cδ (pθ) lies in the rectangle [δmin, 1]S, δmin = δ/(1 + (S 1)δ). Assumption (A) (Euclidean norms throughout): for all p, [δmin, 1]S, pJ(p) pJ(q)2 Lpp q2, sup p[δmin,1]S pJ(p)2 Gp < . Chain pieces and uniform bounds. Let ϕ(θ) := (θ), p(θ) := softmax(ϕ(θ)), and Using (15) and Corollary B.2, uniformly in θ, B(θ) := Dθp(θ) = Jϕ(θ) DP (θ). DP (θ)op 1 2δ , Jϕ(θ)op 1 2 , B(θ)op 1 4δ . Also, Proposition B.2 gives p(θ2) p(θ1)2 1 4δ θ2 θ12. Lemma B.4 (Lipschitz of B(θ)). For all θ1, θ2 Θ, (19) (20) B(θ2) B(θ1)op (cid:16) with LDP as in (17)(18). 3 1 δ2 (cid:17) + 1 2 LDP θ2 θ12, Proof. Split B(θ2) B(θ1) = (Jϕ2 Jϕ1)DP (θ2) + Jϕ1(DP (θ2) DP (θ1)). First term: by Theorem B.1 and Proposition B.2, Jϕ2 Jϕ1op 1 3 3 ϕ2 ϕ11 3 ϕ2 ϕ12 θ2, 3 δ 6 then multiply by DP (θ2)op 1 2δ . Second term: Jϕ1op 1 2 and DP (θ2) DP (θ1)op LDP θ2. Theorem B.2 (Composite Lipschitz constant for θΦ). Under Assumption (A), θΦ(θ2) θΦ(θ1)2 Lθ θ2 θ12, Lθ Lp 16 δ2 (cid:16) + Gp 12 3 δ2 + 1 2 LDP (cid:17) . Proof. θΦ(θ) = B(θ)pJ(p(θ)). Subtract and add: θΦ2 B2 B1op pJ(p1)2 + B2op pJ(p2) pJ(p1)2. Use Lemma B.4 and pJ(p1)2 Gp for the first term. For the second, apply (19) and (20). Step-size guidance. conservative choice for gradient methods on Φ is η 1/Lθ. common heuristic (ignoring Gp-driven variation of B) is η 16δ2 /Lp. B.6 Quadratic Approximation and Hessian Suprema Second derivatives. For i, k, ℓ {1, . . . , S}, (cid:104) θℓθk pθ(i) = pθ(i) (δiℓ pθ(ℓ))(δik pθ(k)) pθ(k)(cid:0)δkℓ pθ(ℓ)(cid:1)(cid:105) . (21) Let Hkℓ(θ) RS collect the components θℓθk pθ(i), and H(θ)[u, v] := (cid:80) k,ℓ ukvℓ Hkℓ(θ). The ReasoningCreativity Trade-off Theorem B.3 (ℓ2 and ℓ1 suprema). For every 2, sup θ,k,ℓ Hkℓ(θ)2 = 1 54 , sup θ,k,ℓ Hkℓ(θ)1 = 1 3 . Both are attained for = 2, and are strict suprema for > 2 (approached by concentrating residual mass). Proof sketch. Using (21), for fixed (k, ℓ) the Rayleigh quotient in the residual mass is convex over the simplex, hence maximized at vertices (mass on one coordinate). Reducing to 22 or 33 blocks yields the stated optima, attained at = ( 1 , 0, . . .). 2 1 2 , 1 2 1 2 3 Second-order expansion and remainders. For any θ, RS and η 0, pθ+ηg = pθ + ηJθg + η2 (cid:90) 1 0 (1 τ ) H(θ + τ ηg)[g, g] dτ. Consequently, 3 6 Rθ,η1 η2 Rθ,η2 η2 Rθ,η2 η2 2 6 3 g2 1, 54 g2 1, g2 2 Rθ,η η2 6 3 g2 1, (s := g0). (22) (23) The last bound uses Theorem B.1 to control Jθ+sg[g]op and g1 g2. δ-interior refinements. Assume the path τ (cid:55) pθ+τ ηg stays in the trimmed simplex For and mδ, define the extremal mass-under-a-floor functional S1 δ := {p S1 : pi δ i}, δ (0, 1/S). Ξm(M ; δ) := max (cid:110) (cid:88) j=1 x2 : (cid:88) j=1 xj = M, xj δ (cid:111) = (M (m 1)δ)2 + (m 1)δ2. (24) Then, for = ℓ with = pθ(k) [δ, 1 (S 1)δ], Hkk2 2 (a(1 a)(1 2a))2 + a2(2a 1)2 ΞS1(1 a; δ) =: (cid:0)cdiag 2 (δ, S)(cid:1)2 , and for = ℓ with a, [δ, 1 (S 1)δ], := 1 [(S 2)δ, 1 2δ], Hkℓ2 2 (ab)2(cid:2)(2a 1)2 + (2b 1)2(cid:3) + 4a2b2 ΞS2(r; δ) =: (cid:0)coff 2 (δ, S)(cid:1)2 . Define c2(δ, S) := max{cdiag , coff of squares) yields c1(δ, S) < 1/(3 2 2 } < 1/ 3) with 54. An entirely analogous construction (sums of absolute values instead max k,ℓ Hkℓ(θ)2 c2(δ, S), max k,ℓ Hkℓ(θ)1 c1(δ, S) whenever pθ δ . The global maximizers lie at = 1 2 1 0.7887, 0.2113. Thus if 3 δ > δcrit := 1 2 1 0.2113, 3 (25) then c2(δ, S) < 1/ 54 and c1(δ, S) < 1/(3 global constants with c2(δ, S) and c1(δ, S). 3) strictly. The remainder bounds (23) improve by replacing the Max Ruiz Luyten, Mihaela van der Schaar B.7 Reference table: Parametric Constants Spectral norms are op; vector norms are Euclidean unless labeled. Tangent space = 1, projector ΠT , centering as above. The bridge (12) Jθ = S(pθ) is used in Section C."
        },
        {
            "title": "Symbol",
            "content": "Value / Bound (where introduced) 1 Jθop 1 Jθ2 Jθ1op 3 (θ) (ϑ)2 1 2δ 1 B(θ)op 4δ Hard-clip kink-free: (17); smooth clip: (18) LDP 2 (global); λ(Jθ ) [pmin, 1 2 ] (Corollary B.2) θ2 θ1 3 3 3 3 θ ϑ2 (Proposition B.2) (Section B.5, (19)) 3 θ (Theorem B.1) Lθ supk,ℓ Hkℓ2 supk,ℓ Hkℓ1 c1(δ, S), c2(δ, S) (cid:16) + 1 + Gp Lp 16 δ2 12 54 (Theorem B.3) 3 δ2 = 1/ = 1/(3 3) (Theorem B.3) ℓ1/ℓ2 Hessian suprema on S1 2 LDP (cid:17) (Theorem B.2) , both < global constants (B.6) δ Domain reminder for composite bounds. All composite bounds in B.5 are evaluated on the rectangle [δmin, 1]S, where δmin = δ/(1 + (S 1)δ) (from cliprenormalize). Assumption (A) holds on this set. The Self-Reinforcing Correctness Training (SRCT) Framework This appendix records the SRCT calculus used throughout the paper, with canonical constants, operator identities, and dynamical statements in form suitable for direct citation. The development is self-contained and uses the standard Shahshahanireplicator correspondence. C.1 Domain, notation, and canonical constants Fix 2 and floor 0 < δ < 1/K. The trimmed simplex is K1 δ := (cid:110) [0, 1]K : (cid:88) pi = 1, pi δ (cid:111) , := 1 = {v RK : v, 1 = 0}. i=1 Euclidean inner products and norms are used throughout. Write log := (cid:80) pi log pi and H(p) := log p. Λ := 1 + log 1 δ , CA := (2 + K) Λ, := ε + λα + βKL 0. C.2 SRCT objective, correct variational derivative, and canonical drift Let RK be bounded utility vector, RKK symmetric PSD, and pbase K1 with full support pbase,i > 0. Consider (cid:101)J[p] = (cid:88) (cid:16) Uipi + λ αH[p] β pKp (cid:17) βKLKL(ppbase) + εH[p]. direct calculation gives the pointwise variational derivative δ (cid:101)J δpi = Ui 2λβ (Kp)i + βKL log pbase,i (cid:0)1 + log pi (cid:1), = ε + λα + βKL. Introduce the selection covariance and entropic vector S(p) := diag(p) pp, E(p) := (log log p), The ReasoningCreativity Trade-off and the selective score Then the Shahshahani gradient flow = Sh (cid:101)J(p) is the SRCT ODE ϕA(p) := 2λβ Kp + βKL log pbase. = (p) := S(p) ϕA(p) E(p), (cid:88) pi = 0 (tangency to ). C.3 Operator facts for and the entropic map Selection covariance S(p). For all p, S(p)1 = 0, and vS(p)v = Varp(V ) where takes value vi with probability pi. By Popoviciu and (max min)2 2v2 2, S(p)22 1 2 , S(p) S(q)22 3 q2. Entropic vector E(p). For any K1 δ and RK, the Jacobian is JE(p) = diag(cid:0)1 + log log p(cid:1) 1 + log p, v. Consequently, on δ , E(p) E(q)2 (2 + K) Λ q2. C.4 Global Lipschitz of the SRCT drift and Caratheodory regularity Let Lϕ := 2λβ K22 and Mϕ,2 := suppK1 δ ϕA(p)2 < (compactness). Using C.3 and = SϕA AE, (p) (q)2 (cid:16) 1 2 Lϕ + 3 Mϕ,2 + CA (cid:17) q2. Hence is globally Lipschitz on K1 . For non-autonomous scores ϕA(t, p) that are measurable in t, locally Lipschitz in p, and locally bounded, (t, p) satisfies Caratheodory conditions on ri K1 ; the ODE admits unique local absolutely continuous solution from any interior initial condition. Tangency to and C.7 (BD) give global-in-time confinement. δ δ C.5 Mass balance and log-ratio calculus For any absolutely continuous solution p() with (t) := (cid:80) (t) = (cid:16) ϕA(t, p(t)) log p(t) pi(t), (cid:17) (cid:0)1 (t)(cid:1), ϕA = (cid:88) piϕA,i. Thus (0) = 1 (t) 1. Fix = and let be an interval on which pi, pj > 0. Set z(t) := log pi(t) pj (t) and dij(t) := (cid:0)Ui Uj (cid:1) 2λβ(cid:0)(Kp)i (Kp)j (cid:1) + βKL log pbase,i pbase,j . Subtracting the and equations yields the log-ratio identity z(t) = dij(t) z(t) for a.e. J, z(t) = z(t0)eA(tt0) + (cid:90) t0 eA(ts) dij(s) ds. (eq:C-VoC) The usual time-varying and constant-box envelopes follow by comparison; if > 0 and dij on [t0, ) J, then z(t) z(t0)eA(tt0) + (1 eA(tt0)) (uniform boundedness). Max Ruiz Luyten, Mihaela van der Schaar C.6 Positivity and face invariance on the closed simplex Let H(p) = log [0, log K] and Mtraj(t) := maxk ϕA,k ϕA(t, p(t)) L1 loc. Lemma C.1 (No finite-time boundary hitting). If pi(0) > 0, then for all finite t, log pi(t) log pi(0) (cid:90) 0 (cid:16) Mtraj(s) + H(cid:0)p(s)(cid:1)(cid:17) ds, pi(t) > 0. Lemma C.2 (Face invariance at zero). If pi(0) = 0, then pi(t) 0. Sketch. With = pi, one has = a(t) log with L1 0+dr/ω(r) = , giving uniqueness of 0 through y(0) = 0. loc. The Osgood modulus ω(y) = y(1 + log y) satisfies (cid:82) C.7 BarrierDominance and confinement on K1 δ On the lower face {pi = δ}, using pj δ and (cid:80) face gap j=i pj = 1 δ, the convexity of (cid:55) log yields the entropy LK(δ) := (1 δ) log 1 δ (K 1)δ > 0 (δ < 1/K). direct computation gives the face inequality at pi = δ : Fi(p) δ (cid:16) LK(δ) (cid:0)ϕA,i(p) ϕA(p)(cid:1)(cid:17) . (eq:C-face-gap) Define the worst outward selective pressure on the boundary face eff := sup (cid:0)ϕA,i(p) ϕA(p)(cid:1) < . pK1 δ i: pi=δ Theorem C.1 (BarrierDominance). If LK(δ) face eff (eq:C-BD) then (p) lies in the tangent cone of K1 inequality is strict, trajectories starting in ri K1 δ δ at every boundary point; hence K1 is forward invariant. If the δ never hit the boundary (strict interior invariance). Coarse sufficient BD. Since ϕA,i ϕA 2ϕA, it suffices that LK(δ) 2 sup ϕA(p). pK1 δ Degenerate floor: If δ = 1/K, then LK(δ) = 0 and the simplex is singleton. C.8 Existence/uniqueness on the mass hyperplane By C.4, is globally Lipschitz on K1 pi = 1}. KirszbraunValentine yields Lipschitz extension (cid:101)F : with the same constant; PicardLindelof gives unique global absolutely continuous solution from any p(0) H. Under (C.1), the trajectory remains in K1 and tangent to := {p : (cid:80) δ . δ C.9 Single-site score fields: Lyapunov structure and convergence Assume separable score ϕi(p) = fi(pi) with fi C([δ, 1]) 1((δ, 1]), supi,s On K1 take δ = δ; on the closed simplex (for = 0) take δ = 0. Define δ (s) < , and 0 on (δ, 1]. gi(s) := fi(s) log s, Ψi(s) := (cid:90) s0 gi(u) du, Lψ(p) := (cid:88) i=1 Ψi(pi), g(p) := (cid:88) pigi(pi). Along classical solutions, The ReasoningCreativity Trade-off dt (cid:0)p(t)(cid:1) = Lψ (cid:88) i=1 pi(t) (cid:0)gi(pi(t)) g(p(t))(cid:1) 0. Regime > 0: strong concavity, KKT, convergence. On [δ, 1], affine simplex i(s) = (s) A/s A, hence on the D2Lψ(p) = diag(g 1(p1), . . . , K(pK)) AI, so Lψ is A-strongly concave. Maximization over K1 scalar and multipliers ν 0 such that δ has unique solution p; the KKT conditions give gi(p ) = ν , (δ ν ) = 0, = 1. (cid:88) Under strict BD, is interior and gi(p bounded above, LaSalles invariance principle implies global convergence to p. ) c. Since trajectories are confined and Lψ is nondecreasing and Regime = 0: water-filling and support selection. Assume (CR+SM): each fi is continuous and strictly decreasing on [0, 1], with inverse 1 : [fi(1), fi(0)] [1, 0]. There exists unique pair (S, c) with (cid:88) iS 1 (c) = 1, = (c), (cid:40) 1 0, S, / S, = { : fi(1) < fi(0) }. Moreover, Lψ is strictly concave on every face; by face invariance and monotonicity, p(t) p. C.10 Safe denominators (linear-functional floor) If ϕ contains denominators of the form ap with RK + {0}, then on K1 , δ Hence such denominators are uniformly bounded away from zero. ap δ a1."
        },
        {
            "title": "D STaR through the SRCT Lens",
            "content": "This appendix instantiates the SRCT framework for the Self-Taught Reasoner. We specify the score field, establish norm and Lipschitz bounds (including Jacobian structure and rank), prove well-posedness and confinement (trimmed-domain barrierdominance), and analyze log-ratio dynamics and asymptotics. D.1 Setting, notation, and basic aggregates Fix 2 and the probability simplex K1 := (cid:110) [0, 1]K : pk = 1 (cid:111) , (cid:88) k=1 int K1 := {p K1 : pk > 0 k}. Split indices into correct (size 1) and incorrect := {1, . . . , K} (size = ). For K1 define ρ(p) := (cid:88) pc, S(2)(p) := (cid:88) p2 c, log := pk log pk [ log K, 0]. (cid:88) cC For floor δ (0, 1/K), the trimmed simplex is cC k= K1 δ := {p K1 : min pk δ} ρ(p) δ. Vector norms are Euclidean; for matrices we use 1 (max. column sum), (max. row sum), and the spectral norm 2, with J2 (cid:112)J1J. Max Ruiz Luyten, Mihaela van der Schaar D.2 The STaR score field: bounds, Jacobian, and Lipschitzness Definition D.1 (STaR score). On := {p int K1 : ρ(p) > 0} define ϕSTaR : RK by ϕSTaR (p) = pk S(2)(p) ρ(p) S(2)(p) ρ(p) , , C, I. For 1 and int K1, ρ(p) > 0, hence = int K1 and ϕSTaR is on D. Componentwise and norm bounds (sharp). For ρ = ρ(p) and S(2) = S(2)(p): (cid:88) k=1 pk ϕSTaR (p) = 0 (centering). For C, 0 pc ρ and S(2) ρ2/M (CauchySchwarz), whence ϕc (cid:2)ρ, 1 ρ (cid:3), ϕi = S(2) ρ [ρ, 0] (i I), ϕSTaR(p) 1. Moreover, ϕSTaR(p)2 2 1 2 ρ(p) + ρ(p)2 1, ϕSTaR(p)2 1. The quadratic upper bound is tight in the limit ρ 1 with all correct mass on one index. Lemma D.1 (Jacobian, zero columns on I, and rank). Let J(p) := [ϕSTaR I. For C, /pj](p). Then Jk,j(p) = 0 for all (cid:19) pj (cid:18) pk ρ = δkjρ pk ρ2 , (cid:19) pj (cid:18) S(2) ρ = 2pjρ S(2) ρ2 , hence Jk,j(p) = δkj ρ 2pj ρ 0, 2pj ρ pk ρ2 S(2) ρ2 , + + S(2) ρ2 , C, C, I, C, I. In particular, rank J(p) . Proposition D.1 (Lipschitz bounds on K1 for K1 δ , δ and interior compacts). On δ one has ρ δ. Uniformly J(p) 2 δ + + 2, J(p)1 2 δ + 3K, J(p)2 (cid:114)(cid:16) 2 δ + 3K (cid:17)(cid:16) 2 δ (cid:17) + + 2 . If D0 int K1 is compact with ρ(p) ρmin > 0, then uniformly for D0, J(p) + 1 ρmin + + 2, J(p)1 2 ρmin + 3K, J(p)2 (cid:114)(cid:16) 2 ρmin + 3K (cid:17)(cid:16) +1 ρmin (cid:17) + + . Proof sketch. Sum the absolute values of the entries in Lemma D.1 by rows/columns using ρ δ, pj ρ, S(2) ρ2; then apply J2 (cid:112)J1J. The ReasoningCreativity Trade-off Continuity caveat (stiffness near faces). Although ϕSTaR is bounded and smooth on D, the 1/ρ2 factors in blow up as ρ 0. Thus ϕSTaR is not globally Lipschitz on int K1; quantitative Lipschitz control requires either K1 or uniform ρmin > 0. δ Proposition D.2 (Ambient spectral lower bound; dependence on ). For all D, J(p)2 pC2 ρ(p) (cid:114)"
        },
        {
            "title": "K\nM",
            "content": ". Proof. Let = (pC/pC2, 0I). Lemma D.1 implies Jv = (pC2/ρ) 1. Taking inner product with 1/ the first inequality; CauchySchwarz gives pC2 ρ/ Corollary D.1 (Exact formulas when = 1). If = 1 with = {c}, then J(p) = 1 . K. The restriction to the tangent space = 1 has operator norm JT 2 = , hence J(p)2 = 1; moreover ΠT JΠT 0."
        },
        {
            "title": "K yields",
            "content": "D.3 STaR as an SRCT flow: well-posedness, Lipschitz drift, and confinement Dynamics. For ε 0 (entropic weight), the SRCT ODE reads pk = pk ϕSTaR (p) ε pk (cid:0)log pk log p(cid:1), = 1, . . . , K. By centering, (cid:80) pk = 0, so (cid:80) pk(t) 1. No finite-time boundary hitting and uniform floor. Let Yi := log pi. Using ϕSTaR log K, 1 and log Yi 1 + ε log εYi. Therefore Yi(t) remains finite on any finite interval (no coordinate reaches 0 in finite time, even for ε = 0). If ε > 0, solving the linear inequality gives the uniform floor pi(t) min (cid:110) pi(0), 1 e1/ε(cid:111) (t 0). Global ℓ2 Lipschitz bound for the SRCT drift on K1 (log log p). Then δ . Write S(p) := diag(p) pp and E(p) := (p) := ϕSTaR(p) ε E(p) = S(p) ϕSTaR(p) ε E(p). On K1 δ , S(p)22 1 2 , S(p) S(q)22 3p q2, and, with Λ := 1 + log(1/δ), Combining with sup ϕSTaR2 E(p) E(q)2 (2 + K) Λ q2. and Lϕ,2 := suprK1 δ J(r)2 from Proposition D.1, (p) (q)2 (cid:16) 2 Lϕ,2 + 3 + ε(2 + (cid:17) K)Λ q2 (p, K1 δ ). Forward invariance of trimmed simplex (BarrierDominance). On the facet pi = δ, pi = δ (cid:16) ϕSTaR (p) + ε [ log log δ ] (cid:17) . The entropy face gap LK(δ) := inf p: pi=δ (cid:0)log log δ(cid:1) = (1 δ) log 1 δ (K 1)δ Max Ruiz Luyten, Mihaela van der Schaar is attained by equalizing the other 1 coordinates. Since ϕSTaR 1, so the sharp sufficient condition inf p: pi=δ pi δ (cid:0)1 + ε LK(δ)(cid:1), ε LK(δ) guarantees inward pointing drift on every facet and hence forward invariance (Nagumo). conservative alternative, robust to mild non-centering, uses ϕi ϕ 2ϕ"
        },
        {
            "title": "K to give",
            "content": "ε LK(δ) 2 . Uniform linear growth. Along any trajectory in int K1, pi piϕi + ε(cid:0)pi log pi + pilog p(cid:1) 1 + ε (cid:16) 1 + log (cid:17) . Well-posedness summary. For any p(0) int K1 and ε 0 there is unique global solution in int K1 (no finite-time boundary hitting). On K1 the drift is globally Lipschitz with the bound above; under either BD condition the trimmed simplex is forward invariant. For ε > 0 every coordinate satisfies the uniform floor. δ D.4 Log-ratio dynamics and asymptotics For = j, set zkj := log pk pj . Differentiating, zkj(t) = (cid:0)ϕSTaR (p(t)) ϕSTaR (p(t))(cid:1) ε zkj(t). Instantiating the score differences: ϕi ϕj 0 (i, I), ϕa ϕb = pa pb ρ (a, C), ϕc ϕi = pc ρ (c C, I). Incorrect vs. incorrect (i, I). when ε > 0. zij = εzij zij(t) = zij(0)eεt: incorrect traces equalize exponentially Within (a, C). zab = papb ρ εzab, (cid:12) (cid:12) papb ρ (cid:12) (cid:12) < 1. Variation of constants yields zab(t) zab(0)eεt + 1 eεt ε . On K1 δ , ρ δ strengthens this to zab(t) zab(0)eεt + 1 δ ε (1 eεt). Correct vs. incorrect (c C, I). Let c(t) arg maxcC pc(t) and set zic := log pi pc . Then zic = pc ρ εzic , pc ρ (cid:104) 1 (cid:105) , , 1 so zic (t) (cid:104) zic (0)eεt 1eεt ε , zic (0)eεt 1eεt ε (cid:105) , lim sup pi(t) pc (t) e1/(M ε). The ReasoningCreativity Trade-off Asymptotics. g/ε and If ε > 0 and there exists with pc(t) > 0 and pc(t) ρ(t) [1/M, 1], then zic(t) pi(t) eg/ε (cid:2)p e1/ε, e1/(M ε)(cid:3). If ε = 0 and there exist C, gmin > 0 with pc(t) zci(t) + and pi(t) 0 (incorrect mass vanishes). Non-vanishing ρ alone does not imply extinction. ρ(t) gmin on an unbounded time set, then zci gmin, hence D.5 Edge cases and remarks If = 0 the score in Definition D.1 is undefined (ρ 0). If = K, then ρ 1 and ϕSTaR j=1 p2 . The ambient lower bound in Proposition D.2 is realized in the normal direction span{1} and does not directly lower-bound the tangent-restricted operator ΠT JΠT with = 1. (p) = pk (cid:80)K"
        },
        {
            "title": "E GRPO through the SRCT Lens",
            "content": "We analyze GRPO within the SRCT framework. We prove barrierdominance (face invariance), derive rank-one Lipschitz constants for the GRPO score, obtain two-sided cross-class envelopes, and establish exponential convergence to unique two-level equilibrium under slope condition. E.1 Setup and GRPO characteristic Domain and classes. Fix integers 2, 2, and floor δ (0, 1/K]. Work on the trimmed simplex (cid:110) K1 δ := [0, 1]K : pk = 1, pk δ (cid:111) . (cid:88) k=1 Partition indices into correct and incorrect sets C, with sizes KC := 0, KI := 0, KC + KI = K. Write the correct mass ρ := ρC(p) := (cid:88) pc. If KI 1 and K1 δ then ρ (cid:2) KCδ, 1 KI δ (cid:3). cC GRPO characteristic. For (0, G] set fG(t) := (cid:112)(G t)/t. With Binom(G 1, ρ) define c1(ρ) := E(cid:2)fG(1 + S)(cid:3), hG(ρ) := c1(ρ) 1 ρ (ρ (0, 1)). Lemma E.1 (basic properties of hG). The map hG extends to 1([0, 1]) with hG(0) = hG(1) = 1, DG := sup ρ[0,1] G(ρ) < . Moreover for all ρ [0, 1], and hG is constant when {2, 3}. 1 1 hG(ρ) 1, 1(1) = Proof sketch. c1 is finite binomial sum of smooth terms, hence C([0, 1]). Expansion at ρ = 1 gives c1(1) = 0 and 1 and is 1 on [0, 1]; boundedness of follows by continuity on compact interval. The lower bound follows from fG(t) (G t)/G on [1, G]. The upper bound follows from binomial reweighting showing hG is an average of terms bounded by 1, so hG extends continuously with hG(1) = 1. Lemma E.2 (binomial-shift identities). For all ρ [0, 1] with Binom(G 1, ρ), (1 ρ) hG(ρ) = (cid:104)(cid:113) G1S 1+S (cid:105) , ρ hG(ρ) = (cid:104)(cid:113) GS (cid:105) . Max Ruiz Luyten, Mihaela van der Schaar E.2 GRPO scores: envelopes and rank-one Lipschitz constants Scores and centering. The raw GRPO score is class-constant: γraw (p) = (cid:40) hG(ρ), C, I. 0, Its centered version (cid:98)γk := γraw (cid:80) pjγraw equals (cid:40) (cid:98)γk(p) = (1 ρ) hG(ρ), C, ρ hG(ρ), I, (cid:88) k=1 pk (cid:98)γk(p) = 0. If KI = 0 or KC = 0 then (cid:98)γ 0. Pointwise envelopes. By Lemma E.2, (cid:98)γ(p) 1, (cid:98)γ(p)2 = hG(ρ) (cid:112)KC(1 ρ)2 + KI ρ2 1 (cid:112)max{KC, KI } . If additionally KI 1 and K1 , then 1 ρ KI δ and δ 1 KI δ hG(ρ) =: HG, (cid:98)γ(p)2 HG (cid:112)max{KC, KI }. Rank-one Jacobian and exact norms. Set α(ρ) := dρ (cid:0)(1 ρ)hG(ρ)(cid:1) = 1(ρ), β(ρ) := dρ (cid:0) ρ hG(ρ)(cid:1) = hG(ρ) ρ G(ρ). Since ρC = 1C, D(cid:98)γ(p) = (cid:0)α 1C, β 1I (cid:1) (1C) =: (rank one). Thus the operator norms are exact: D(cid:98)γ(p)22 = u2 v2 = (cid:112) KC (cid:0)KCα2 + KI β2(cid:1)1/2 , D(cid:98)γ(p)T 2 = (cid:113) KC KI (cid:0)KCα2 + KI β2(cid:1)1/2 = (cid:113) KI D(cid:98)γ(p)22 . Consequently, the sharp global Lipschitz constant on the simplex is Ltan γ := sup pK1 D(cid:98)γ(p)T 2 = (cid:113) KC KI sup ρ[0,1] (cid:0)KCα(ρ)2 + KI β(ρ)2(cid:1)1/2 . From α + DG, β + DG with := sup hG = 1, Ltan γ (cid:112) KCKI (cid:0)H + DG (cid:1). E.3 SRCT drift: global Lipschitzness and mass conservation Drift. With entropy weight ε > 0 define Fk(p) := pk (cid:16) (cid:98)γk(p) ε(cid:0) log pk log p(cid:1)(cid:17) , log := (cid:88) i=1 pi log pi. Centeredness yields (cid:80) Fk(p) = 0 (mass conservation). The ReasoningCreativity Trade-off Entropic Lipschitz bound on K1 decomposition gives δ . On [δ, 1], h(x) := log has Λ := 1 + log(1/δ). direct ent(p) ent(q)2 ε Λ (2 + K) q2, p, K1 δ . Selection Lipschitz bound and full modulus. For sel(p) := (cid:98)γ(p) and p, K1 , sel(p) sel(q)2 (cid:0)diag(p)22 Ltan γ + sup rK1 δ (cid:98)γ(r)2 δ (cid:1) q2, with diag(p)22 1 (K 1)δ. Using either sup (cid:98)γ2 (cid:112)max{KC, KI }, trim-aware bound HG 1(cid:112)max{KC, KI } or (when KI 1) the (p) (q)2 (cid:16) (1 (K 1)δ)Ltan γ + Mγ + ε Λ (2 + (cid:17) K) q2 , where Mγ denotes the chosen envelope. E.4 BarrierDominance (BD) and forward invariance Entropy face gap. For facet pk = δ define the gap The global lower benchmark (uniform-others gap) is Gapk(p) := log log δ. LK(δ) := (1 δ) log (cid:16) 1 δ (K 1)δ (cid:17) . At fixed ρ = ρC(p), the minimal face gap is attained by equalizing within blocks: E(I) min(ρ) = (δ 1) log δ + 1{KC 1} ρ log (cid:17) (cid:16) ρ KC + 1{KI 2} (1 δ ρ) log (cid:16) 1 δ ρ KI 1 (cid:17) , E(C) min(ρ) = (δ 1) log δ + 1{KC 2} (ρ δ) log (cid:17) (cid:16) ρ δ KC 1 + 1{KI 1} (1 ρ) log (cid:16) 1 ρ KI (cid:17) , and minρ E() min(ρ) = LK(δ). Exact BD on facets. On pk = δ, Fk(p) = δ (cid:0) (cid:98)γk(p) + ε Gapk(p)(cid:1). Correct faces: if and KI 1, then (1 ρ) KI δ > 0 implies (cid:98)γk = (1 ρ)hG(ρ) > 0, hence Fk(p) εδE(C) if I, then (cid:98)γk = ρhG(ρ) 0. The facet is inward/tangent iff min(ρ) 0 (automatically inward). Incorrect faces: (BDexact) ε E(I) min(ρ) ρ hG(ρ) ρ (cid:2)KCδ, 1 KI δ (cid:3). Convenient sufficient relaxations. Using E(I) min(ρ) LK(δ) and ρ hG(ρ) 1 = (BDexact). ε LK(δ) 1, On trimmed domains with KI 1, 1 ρ KI δ implies hG(ρ) HG = 1/(KI δ), hence ε LK(δ) 1 KI δ = (BDexact). Max Ruiz Luyten, Mihaela van der Schaar Well-posedness and invariance. log pi, Interior solutions cannot hit the boundary in finite time: writing yi := yi = (cid:98)γi(p) εyi εlog G 1 εyi + ε log K, so yi cannot blow up in finite time. ward/tangent; K1 set, yielding global existence and uniqueness. δ If (BDexact) (or either sufficient relaxation) holds, every facet is inis forward invariant and the drift is globally Lipschitz on compact forward-invariant E.5 Log-ratio dynamics, envelopes, and scalar reduction For = j, dt log pi pj = (cid:98)γi(p) (cid:98)γj(p) ε log pi pj . Intra-class equalization. If i, are in the same class then (cid:98)γi = (cid:98)γj and log pi(t) pj(t) = eεt log pi(0) pj(0) . Thus within-class proportions equalize exponentially at rate ε. Cross-class envelopes. For C, let zci := log(pc/pi). Then zci(t) = hG(ρC(t)) εzci(t). Variation of constants and Lemma E.1 give, for all 0, (cid:104) zci(t) zci(0)eεt + 1 1 ε (1 eεt), zci(0)eεt + G1 ε (cid:105) (1 eεt) . If (BD) holds with KI 1, then hG(ρC(s)) HG along the trajectory and the upper envelope sharpens to zci(t) zci(0)eεt + HG ε (1 eεt). Feasibility band (under BD). Write pc = αcρ with (cid:80) Ψ(ρ) := log (cid:16) KI KC ρ 1 ρ (cid:17) , αc = 1 and pi = βi(1 ρ) with (cid:80) KCez KI + KCez . ρ(z) = βi = 1, and define Let Then C(t) := max a,bC (cid:12) (cid:12) (cid:12) log pa(t) pb(t) (cid:12) (cid:12) (cid:12), (t) := max j,kI (cid:12) (cid:12) (cid:12) log pj(t) pk(t) (cid:12) (cid:12) (cid:12), δintra(t) := C(t) + (t) = δintra(0)eεt. zci(t) Ψ(ρC(t)) δintra(t) and ρC(t) (cid:2)KCδ, 1 KI δ (cid:3) . Scalar reduction, closure error, and fixation (under BD). Define F(z) := hG(ρ(z)) εz. Since ρ(z) 1 4 , (cid:12) (cid:12)hG(ρC) hG(ρ(zci))(cid:12) (cid:12) DG ρC ρ(zci) DG 4 zci Ψ(ρC) DG 4 δintra(t). Hence zci = F(zci) + r(t) with r(t) DG Theorem E.1 (fixation under slope condition). If ε > DG zero z. Moreover, for all C, I, 4 δintra(t). 4 , then is strictly decreasing and has unique zci(t) e(ε DG 4 )t (cid:16) zci(0) + C(0) + (0) (cid:17) . If (cid:2)Ψ(KCδ), Ψ(1 KI δ)(cid:3) then the limit distribution is interior and class-uniform: ez KCez + KI Otherwise the limit lies on the corresponding face (feasibility truncation). 1 KCez + KI (c C), = = (i I). The ReasoningCreativity Trade-off E.6 Edge cases and checks Maximal trim: if δ = 1/K, then K1 Degenerate classes: if KI = 0 or KC = 0, then (cid:98)γ 0 and pi = εpi(log pi log p); the unique equilibrium = {(1/K, . . . , 1/K)}; dynamics are trivial. δ on active coordinates is uniform. Single incorrect: KI = 1 yields ρ = 1 δ on the only incorrect face and E(I) min(1 δ) = (δ 1) log δ + (1 δ) log (cid:16) 1δ KC (cid:17) . The uniform sufficient BD εLK(δ) 1 is sharp as δ 0. Two classes (K = 2): KC = KI = 1 and = log(pc/pi) obey = hG(pc) εz; the envelopes become equalities with ρ = pc. Constant cases: for {2, 3}, hG 1, so Ltan γ = 1 KCKI and F(z) = 1 εz."
        },
        {
            "title": "F DPO through the SRCT Lens",
            "content": "This appendix develops self-contained SRCT analysis of Direct Preference Optimisation (DPO). We define the score field, prove uniform size and Lipschitz bounds (with explicit constants), record entropy and fulldrift Lipschitz constants, establish well-posedness and BarrierDominance (BD) confinement (exact face test and tight templates), derive intra-class contraction with sharp thresholds, give cross-class envelopes (including trimmed sharpening and static cap), prove eventual trimming under slope condition, and conclude existence, uniqueness, and global convergence to two-level equilibrium. All logarithms are natural. Notation. Fix an integer 2. The simplex and trimmed simplex are K1 := (cid:110) [0, 1]K : pi = (cid:111) , (cid:88) i=1 K1 δ := (cid:110) K1 : min pi δ (cid:111) , with floor 0 < δ < 1/K. For vectors, , 2 denote max/Euclidean norms; for matrices, 22. We write log := (cid:80) pj log pj. F.1 Setting and single-site map Each index {1, . . . , K} is labeled si {+1, 1}, with := {i : si = +1}, := {i : si = 1} and sizes := C, := I. Fix β > 0 and reference ℓ0 R. Define gβ(ℓ) := 1 σ(cid:0)β(ℓ ℓ0)(cid:1), σ(z) := 1 1 + ez , so gβ C(R), 0 < gβ(ℓ) < 1, strictly decreasing, and β(ℓ) = β 4 sech2(cid:16) β(ℓ ℓ0) 2 (cid:17) [β/4, 0). For (0, 1], define the raw scores and centered field γi(u) := si gβ(log u), γ(p) := (cid:88) j=1 pjγj(pj), ϕi(p) := γi(pi) γ(p). By construction, (cid:80) piϕi(p) = 0. Max Ruiz Luyten, Mihaela van der Schaar F.2 Uniform size and Lipschitz bounds for the DPO score"
        },
        {
            "title": "Let",
            "content": "Mγ, := sup gβ(log u) = gβ(log δ) (0, 1), Λ := 1 + log u[δ,1] 1 δ . Lemma F.1 (Size bounds). For every K1 δ , ϕ(p) 2Mγ,, ϕ(p)2 2Mγ, K. Proof. ϕi γi + γ Mγ, + (cid:80) Lemma F.2 (Lipschitz of single-site map). For fi(s) := γi(s) = sigβ(log s) on [δ, 1], pjγj 2Mγ,, then 2 . i (s) = β(log s) cmax δ β 4δ =: Lf , where cmax := supℓ[log δ,0](g Lemma F.3 (Operator-norm Lipschitz for ϕ). For all p, K1 β(ℓ)) β/4; the inequality is strict if ℓ0 / [log δ, 0]. , δ ϕ(p) ϕ(q)2 Lϕ q2, Lϕ := Mγ, + ( Proof. Write ϕ(p) = (p) 1 (pf (p)) with (p) = (fi(pi))i. Then + 1)Lf . Jϕ(p) = diag(f (p)) 1 (f (p) + (p)). δ : (p)2 On K1 12(f (p)2 + (p)2) = Mγ, + ( the claim. Lemma F.4 (Mixed ℓℓ1 bound). For all p, K1 , δ KMγ,, (p)2 Lf , diag(f (p))22 Lf . Hence Jϕ(p)22 Lf + + 1)Lf , and the mean-value formula on the convex domain yields ϕ(p) ϕ(q) Lf q + (Mγ, + Lf ) q1. F.3 Entropy map and drift Lipschitzness Define E(p) := (log log 1), Lemma F.5 (Entropy map). For all p, , δ (p) := ϕ(p) ε E(p) (ε 0). E(p) E(q)2 Clog q2, Clog := (2Λ 1) + Λ (2 + K)Λ. Proof. The Jacobian is JE(p) = diag(1 + log log p) 1 + log p, v. On K1 Λ. Mean-value completes the proof. and 1 + log p, 22 p21 + log p2 Proposition F.1 (Full drift Lipschitz). For all p, K1 δ , δ , diag() 22 2Λ 1 (p) (q)2 (cid:16) Lϕ + 2Mγ, + εClog (cid:17) q2. Proof. Product decomposition: pϕ(p)q ϕ(q)2 ϕ(p)pq2 +ϕ(p)ϕ(q)2 (2Mγ, +Lϕ)pq2, then add the entropy term via Lemma F.5. F.4 DPOSRCT ODE, mass conservation, and positivity The SRCT drift is pi = pi (cid:104) ϕi(p) ε(cid:0) log pi log p(cid:1)(cid:105) , = 1, . . . , K. piϕi(p) = 0 and (cid:80) Mass conservation holds since (cid:80) Proposition F.2 (No finite-time boundary hitting). Let p(0) int K1 and ε 0. Then the solution exists for all 0 and remains in the interior for every finite t. Proof. Set yi := log pi. Using ϕi 2 and (1 eεt) for ε > 0, and log log K, yi(t) yi(0) + 2t for ε = 0. Thus yi(t) < for finite t. yi εyi + (2 + ε log K), whence yi(t) yi(0)eεt + 2+ε log pi(log pi log p) = 0. ε The ReasoningCreativity Trade-off F.5 BarrierDominance (BD) On the lower face pi = δ, (cid:16) pi = δ ϕi(p) + ε(cid:0)log log δ (cid:1)(cid:17) . By convexity of (cid:55) log s, the entropy face gap LK(δ) := (1 δ) log 1 δ (K 1)δ > 0 satisfies log log δ LK(δ) on that face. Exact face test (necessary & sufficient). ϕi(p) + ε(cid:0)log log δ for all with pi = δ. pi 0 on pi = δ iff (cid:1) 0 Uniform sufficient templates. Using Lemma F.1: εLK(δ) Mϕ, or εLK(δ) Mϕ,2 ( K), where Mϕ, := supp ϕ(p) 2Mγ, 2 and Mϕ,2 := supp ϕ(p)2 2Mγ, sharp ℓ test; the second yields the tight threshold εLK(δ) 2 Strict inequality implies strict interior invariance. and the convenient conservative form 4 K. The first is K. 2 Numerical note. As δ 0, Lf = Θ(1/δ) and Clog = Θ(log(1/δ)) deteriorate; discretizations should scale stepsizes accordingly. F. Intra-class contraction For i, with si = sk =: s, set zik := log pi pk . Subtracting the logp equations gives zik = ϕi(p) ϕk(p) εzik = s(cid:0)gβ(log pi) gβ(log pk)(cid:1) εzik = (cid:0)s β(ξ) ε(cid:1) zik, for some ξ between log pi and log pk. Definition F.1 (Sharp thresholds). copen := sup ℓ0 (g β(ℓ)) = β 4 max ℓ0 sech2(cid:16) β(ℓ ℓ0) 2 (cid:17) = (cid:40)β/4, β 4 sech2(cid:0) βℓ 2 ℓ0 0, ℓ0 > 0, (cid:1), and, under confinement to K1 δ , cmax := sup ℓ[log δ,log(1(K1)δ)] (g β(ℓ)) copen. Theorem F.1 (Intra-class contraction). (i) For i, C, zik(t) zik(0) eεt. simplex, (ii) For i, I, on the open zik(t) zik(0) e(εcopen)t iff ε > copen. Under confinement to K1 ε. For = 1, choosing data with δ β(ξ0) c. β(ξ) 0 gives rate dt zik (c ε)zik with {copen, cmax}; Gronwall gives sufficiency, and necessity follows by the same holds with cmax replacing copen. Proof. For = +1, Slope Condition (SC). We will often invoke the sufficient condition which implies ε > copen and hence contraction in both classes. (SC) ε > β/ Max Ruiz Luyten, Mihaela van der Schaar F.7 Cross-class envelopes, trimming sharpenings, and static cap For C, I, set zij := log pi pj . Then zij = gβ(log pi) + gβ(log pj) εzij =: h(t) εzij. Since gβ is decreasing and log px 0, we have gβ(log px) gβ(0) and gβ(log px) < 1. Variation of constants yields, for all 0, zij(t) (cid:104) z0eεt + 2gβ (0) ε (1 eεt), z0eεt + 2 (cid:105) ε (1 eεt) , z0 := zij(0). (26) If, in addition, p(t) K1 δ , then log px [log δ, 0] and zij(t) z0eεt + 2 gβ(log δ) ε (1 eεt). Independently, mass constraints on K1 δ give the static cap zij(t) log 1 (K 1)δ δ (t 0). Lemma F.6 (Cap dominates half-gap). For every 2 and δ (0, 1/K), 1 2 log 1 δ (K 1)δ < log 1 (K 1)δ δ . Proof. Equivalently, the function decreases from 1 at 0 to 0 at 1/K. 1δ (K1)δ < (cid:0) 1(K1)δ (cid:1)2 δ , which reduces to (K 1)(cid:0)1(K 1)δ(cid:1)2 (27) (28) δ(1δ) > 0 on (0, 1/K); Compatibility under BD. Under the sharp ℓ BD test εLK(δ) Mϕ, 2, 2gβ(0) ε 2 ε LK(δ) log 1 δ (K 1)δ < 2 log 1 (K 1)δ δ by Lemma F.6, so the asymptotic lower envelope in (26) lies strictly below the static cap (28). stronger trimmed constant is available by replacing gβ(0) with := gβ(log(1 (K 1)δ)) in (26); sufficient compatibility condition is ε 2 log 1(K1)δ . δ F.8 Lyapunov structure and eventual trimming (under SC) Define Gi(s) := si gβ(log s) ε log s, Ψi(s) := (cid:90) δ Gi(u) du, L(p) := (cid:88) i= Ψi(pi). The ODE rewrites as pure replicator: pi = pi (cid:0)Gi(pi) G(p)(cid:1), G(p) := (cid:88) pjGj(pj), and satisfies the Lyapunov identity L(cid:0)p(t)(cid:1) = dt (cid:88) i=1 (cid:0)Gi(pi) G(p)(cid:1)2 pi 0. (29) Under (SC), affine simplex. i(s) = (sig β(log s) ε)/s < 0 for both classes, so each Ψi and hence is strictly concave on the The ReasoningCreativity Trade-off Proposition F.3 (Eventual trimming under (SC)). Assume (SC) and p(0) int K1. There exist δ > 0 and < (depending on K, M, N, β, ε, p(0)) such that p(t) K1 for all . An explicit choice is: δ ZU := max (cid:26) 2 ε (cid:27) , max iC,jI zij(0) , := eZU , := eZL , ZL := gβ(0) ε > 0, and then, for some large enough, pi(t)/pj(t) for all C, I, , which implies min pk(t) δ := (N + r) > 0 (t ). Sketch. Use the envelopes (26) to choose any ZL < lim inf zij and ZU > supt zij(t). From pi upj and pi rpj, derive lower bounds on class masses and on the minimal coordinate (algebra as in the display). F.9 Two-level equilibrium: existence, uniqueness, and global convergence two-level equilibrium has the gap := log(LC/LI) 0: = LC for and = LI for I, with LC + LI = 1. Parameterize by LI(z) = 1 + ez , LC(z) = ez + ez . At equilibrium, Gi(p ) const, equivalently (cid:0) log LC(z)(cid:1) + gβ (cid:0) log LI(z)(cid:1) = εz. gβ Define h(z) := gβ(log LC(z)) + gβ(log LI(z)) (0, 2) and (z) := h(z) εz. Then (0) = 2gβ(log(1/K)) > 0, and (z) as (since is bounded). Differentiating, h(z) = β(log LC) LI + β(log LI) (M LC), h(z) β/4, so under (SC) we have (z) β/4 ε < 0 and thus: Lemma F.7 (Unique gap and quantitative bounds). Under (SC) there exists unique > 0 solving (z) = 0. Moreover 2gβ(0) ε 2 ε , h(0) ε + β/4 h(0) ε β/4 , h(0) = 2gβ (cid:0) log 1 (cid:1). Theorem F.2 (Global convergence). Assume (SC). For any p(0) int K1, the trajectory converges to the unique two-level equilibrium with gap from Lemma F.7. Proof. By Proposition F.3, p(t) enters and stays in compact trimmed simplex for . On this compact set the drift is globally Lipschitz (Proposition F.1). The Lyapunov identity (29) and strict concavity of under (SC) imply that the largest invariant set in { = 0} consists of equilibria, which are two-level; uniqueness of then yields global convergence. If = 0 (all si = +1), β(log s) ε)/s ε/s < 0 for any Edge cases (no mixed preferences). ε 0; the unique equilibrium is uniform and globally attractive. If = 0 (all si = 1), uniqueness and global attraction of the uniform equilibrium hold provided ε > β/4. i(s) = (g Choosing compatible floor. Given z, set δ LI(z) to ensure K1 since LK(δ) as δ 0. δ . This does not obstruct BD Dynamics on Coarse-Grained Lumps Simplex, solution concept, and entropy map. Let the finite index set be = {π1, . . . , πS} (S 2). The closed simplex is S1 := (cid:110) [0, 1]S : pπ = (cid:111) , (cid:88) π int S1 := {p S1 : min π pπ > 0}. Max Ruiz Luyten, Mihaela van der Schaar We work with Caratheodory solutions : [0, ] S1 of p(t) = p(t) ϕ(cid:0)p(t)(cid:1) ε E(cid:0)p(t)(cid:1), ε 0, (SRCT) where ϕ : S1 RS is centered, (cid:80) π pπϕπ(p) = 0, and π(p) := h(pπ) pπlog p, h(x) := log x, log := (cid:88) π pπ log pπ. is continuous on S1; if pπ = 0, then (p ϕ)π = forward invariant. π(p) = 0, so faces are viable and the closed simplex is Trim and feasibility. Fix δ (0, 1/S] and the trimmed simplex S1 (nonempty by choice of δ). δ := {p S1 : pπ δ π} G.1 Lumps Let (Ck)KL k=1 be partition of into nonempty, disjoint lumps. For = 1, . . . , KL define KL(cid:88) (cid:88) (cid:88) (cid:88) qk := pπ, mk := pπ log pπ, pπ log pπ = mj. := If qk > 0, write EpCk [log p] := (1/qk) (cid:80) Lemma G.1 (Lump ODE). Every Caratheodory solution of (SRCT) satisfies, for each k, πCk pπ log pπ so that mk = qk EpCk [log p]. πCk πCk j=1 π qk = (cid:88) πCk pπ ϕπ(p) ε(cid:0)mk qk h(cid:1). (30) If qk > 0, equivalently qk = (cid:80) continuity. πCk pπ ϕπ(p) ε qk (cid:0)EpCk [log p] h(cid:1). For qk = 0 the right-hand side vanishes by Aggregation operator. Let {0, 1}KLS be the indicator matrix, Akπ = 1{πCk}, so that = Ap. Exact norms: A11 = 1, A22 = m, = m, := max Ck. (31) In particular, aggregation is 1-Lipschitz in ℓ1: Au Av1 v1. G.2 Technical facts used repeatedly On δ : Mean-log bounds. log log (cid:0)1 (S 1)δ (cid:1) log(cid:0)1 (S 1)δ (cid:1) + (S 1)δ log δ 0. Entropy size. With E(p) := (log log 1), E(p)1 2 log 1 δ . Replicator matrix bounds. Writing S(p) := diag(p) pp, S(p)22 1 2 , S(p) S(q)22 3 q2 . Centeredness gives ϕ = S(p)ϕ. Selection envelopes. For any domain S1 and lump Ck, (cid:12) (cid:12) (cid:12) (cid:88) πCk (cid:12) (cid:12) (cid:12) qk Mϕ,(D) and qk Mϕ,2(D), pπ ϕπ(p) with Mϕ,(D) := suppD ϕ(p), Mϕ,2(D) := suppD ϕ(p)2. (32) (33) (34) (35) The ReasoningCreativity Trade-off G.3 Small-ε perturbation: trace and lump bounds Assume on S1 δ that ϕ(p)2 Mϕ,2, ϕ(p) ϕ(q)2 Lϕ q2. By (34), for F0(p) := ϕ(p) = S(p)ϕ(p), F0(p) F0(q)1 L(1) q1, L(1) := (cid:16) 1 2 Lϕ + 3 Mϕ,2 (cid:17) . (36) (37) Theorem G.1 (Trace-level perturbation with exit-time qualification). Let pε, p0 solve pε = F0(pε) εE(pε) and p0 = F0(p0) with pε(0) = p0(0) S1 . Set τ := inf{t > 0 : minπ pε π(t) = δ}. Then for [0, τ ), π(t) = δ or minπ p0 δ pε(t) p0(t)1 2 ε log(1/δ) L(1) (cid:16) eL(1) 1 (cid:17) . Consequently, for any partition, qε(t) q0(t)1 pε(t) p0(t)1. Forward-invariance templates. Let LS(δ) := (1 δ) log 1δ (S1)δ > 0. If on S1 δ either then S1 δ is forward invariant for (SRCT), and the bound in Theorem G.1 holds for all 0. ε LS(δ) 2 Mϕ, or ε LS(δ) 2 Mϕ,2, (38) G.4 Pure-score (ε = 0) lump dynamics When ε = 0, Lemma G.1 reduces to qk = (cid:80) πCk pπ ϕπ(p). G.4.1 STaR Let denote correct indices (M := 1) and := C. Set ρ(p) := (cid:80) The centered STaR field is cC pc and S(2)(p) := (cid:80) cC p2 c. ϕSTaR π (p) = pπ S(2)(p) ρ(p) S(2)(p) ρ(p) , , π C, π I, defined when ρ(p) > 0. Proposition G.1 (STaR lump ODE). For S(2) k,C(p) := (cid:80) πCkC p2 π, qk = S(2) k,C(p) qk S(2)(p) ρ(p) . If Ci, Cj C, then dt log qi qj = 1 ρ (cid:16) S(2) i,C qi S(2) j,C qj (cid:17) . G.4.2 GRPO Let 2 be the group size and hG : [0, 1] (0, ) the GRPO characteristic (continuous), e.g. bounded by 1. The centered two-level field is ϕGRPO π (p) = (cid:40) (1 ρ(p)) hG(ρ(p)), π C, π I. ρ(p) hG(ρ(p)), For qk,C := (cid:80) Proposition G.2 (GRPO lump ODE). πCkC pπ define corr(Ck; p) := qk,C/qk (if qk > 0). qk = hG (cid:0)ρ(p)(cid:1) qk (cid:0)corr(Ck; p) ρ(p)(cid:1) . Hence dt log qi qj = hG(ρ)(cid:0)corr(Ci; p) corr(Cj; p)(cid:1). Max Ruiz Luyten, Mihaela van der Schaar G.4.3 DPO (sign-pure lumps) Fix labels sπ {1} and link gβ : (0, 1) with β(ℓ) [β/4, 0) on [log δ, 0]. Define γπ(p) := sπ gβ(log pπ), γ(p) := (cid:88) π pπ γπ(p), ϕπ(p) := γπ(p) γ(p). Assume each lump Ck is sign-pure: sπ sk on Ck. Let Gk(p) := 1 qk (cid:88) πCk pπ gβ(log pπ), g(p) := KL(cid:88) j=1 qj sj Gj(p) = γ(p). Interpret qkGk := (cid:80) Proposition G.3 (DPO lump ODE (sign-pure)). πCk pπ gβ(log pπ) so the right-hand side is well-defined even if qk = 0. qk = qk (cid:0)sk Gk(p) g(p)(cid:1) . If Ci = {πi} and Ck = {πk} with sπi = sπk =: s, then for zik := log(pπi/pπk ), zik = s(cid:0)gβ(log pπi) gβ(log pπk )(cid:1), zik (β/4) zik. G.5 Entropy deviation envelopes for the lump term For qk > 0 write wπ := pπ/qk on Ck and H(wk) := (cid:80) wπ log wπ. Then πCk mk = qk log qk + qk (cid:88) πCk wπ log wπ (cid:2)qk log qk Ck , qk log qk (cid:3) , hence mk qk qk max On S1 δ , the dimension-only bound (cid:110) log qk , (cid:12) (cid:12) log qk Ck h(cid:12) (cid:12) (cid:111) . mk qk qk log 1 (S 1)δ δ is immediate from the log-domain [log δ, log(1 (S 1)δ)]. G.6 Open problems (39) (40) (41) Fix partition of indices into correct and incorrect with sizes KC := 0, KI := 0 (K = KC + KI = S). For δ (0, 1/K) define the trimmed simplex K1 (K1)δ > 0. The feasible band for ρ := (cid:80) cC pc is [KCδ, 1 KI δ]. and the uniform face gap LK(δ) := (1 δ) log 1δ δ Face-wise entropy minima (at fixed ρ and pk = δ). For fixed ρ and an incorrect face I, E(I) min(ρ) = (δ 1) log δ + 1{KC 1} ρ log ρ KC + 1{KI 2} (1 δ ρ) log 1 δ ρ KI 1 . For correct face C, E(C) min(ρ) = (δ 1) log δ + 1{KC 2} (ρ δ) log ρ δ KC 1 + 1{KI 1} (1 ρ) log 1 ρ KI . In both cases E() min(ρ) LK(δ) and the minima are attained by uniform allocation among active coordinates. The ReasoningCreativity Trade-off OP1 (sharp BD thresholds at trim δ). STaR. On incorrect faces, ϕk = S(2)/ρ ρ; inwardness at fixed ρ follows if ρ + ε E(I) min(ρ) 0, hence ε(I) suf (δ; KC, KI ) := max ρ[KC δ, 1KI δ] ρ E(I) min(ρ) suffices. On correct faces, ϕk = (δ S(2))/ρ (δ S(2) max(ρ, δ))/ρ with S(2) max(ρ, δ) = δ2 + (ρ δ)2, so ε(C) suf (δ; KC, KI ) := max ρ max{0, S(2) ρ E(C) max(ρ, δ) δ} min(ρ) suffices. The uniform sufficient threshold is εSTaR for incorrect faces and KC = 2 for correct faces. suf := max{ε(I) suf , ε(C) suf }. The above are exact in the special cases KC = 1 GRPO. On correct faces the drift is inward for any ε 0. On incorrect faces, inwardness at fixed ρ is equivalent to ρ hG(ρ) + ε E(I) min(ρ) 0, hence the exact threshold εGRPO crit (δ; KC, KI , G) = max ρ[KC δ, 1KI δ] ρ hG(ρ) E(I) min(ρ) . Useful bounds: εGRPO crit 1/LK(δ) and εGRPO crit (1KI δ) KI δ LK (δ) . OP2 (DPO sensitivity to ε; gap and linear response). Assume ε > β/4. Then the SRCT flow admits interior equilibrium p(ε) (all correct, resp. incorrect, coordinates equal). Let z(ε) := unique two-level log(p /p ) 0 satisfy h(z) = ε z, h(z) := gβ(log LC(z)) + gβ(log LI(z)), with LI(z) := (KI + KCez)1 and LC(z) := ezLI(z). Then: dε z(ε) = z(ε) ε h(z(ε)) < 0, z(ε) = h(0) ε + h(0)h(0) ε2 + O(ε3). Moreover, writing ℓπ := log π(ε) and dπ := ε sπg β(ℓπ) > 0, dε π = p π ℓπ dπ , := p, D1ℓ p, D11 , := diag(dπ), and for any lump Ck, dε = (cid:88) πCk π ℓπ dπ . OP3 (DPO coarse-graining: closure errors). For sign-pure lump Ck with weights wπ := pπ/qk, let ℓk := (cid:80) wπ(log pπ ℓk)2, and H(wk) := (cid:80) set cmax := supℓ[log δ, 0](g πCk β(ℓ)) β/4. Then wπ log wπ. On S1 wπ log pπ, σ2 := (cid:80) πCk πCk δ (cid:12) (cid:12) (cid:12)Gk gβ(log qk) (cid:12) (cid:12) (cid:12) cmax σk + cmax H(wk) (static closure error), and the exact log-ratio identity augments to dt log qi qj = siGi sjGj ε log + ε(cid:0)H(wi) H(wj)(cid:1), qi qj so that replacing Gk by gβ(log qk) incurs an error bounded by cmax(σi +σj +H(wi)+H(wj))+ε(H(wi)+H(wj)). Max Ruiz Luyten, Mihaela van der Schaar (i) STaR requires KC 1 (else ρ 0). (ii) The BD templates (38) are sufficient (not necessary). Remarks. (iii) The lump-level entropy term is not the gradient of lump entropy; bounds (40)(41) are the correct bridge. All statements above are consistent with the SRCT model (SRCT), are valid on the closed simplex via E, and become uniform on S1 under (36). δ"
        },
        {
            "title": "H Analysis of Stochasticity in SRCT",
            "content": "This appendix develops concise, selfcontained analysis of the stochastic dynamics induced by minibatch sampling in SRCT. We (i) fix the domain and standing hypotheses, (ii) quantify global Lipschitz moduli and minibatch noise statistics, (iii) derive ODE and diffusion limits under the correct scaling, (iv) analyze boundary behavior (unreflected vs. reflected models), (v) record uniform ellipticity on the tangent bundle, (vi) treat small centred bias via an exponential Lyapunov device, and (vii) provide algorithmspecific logratio SDEs. H.1 Domain, notation, and standing hypotheses Fix an integer 2 and design floor δ (0, 1/K). The trimmed simplex is K1 δ := (cid:8) [0, 1]K : (cid:88) i=1 pi = 1, min pi δ (cid:9). All logarithms are natural; 0 log 0 := 0. For RK and probability vector p, set xp := (cid:80) log := (cid:80) subspace is := 1. pixi and pi log pi. Vector norms 2, are Euclidean and supremum norms, respectively. The tangent Score field and SRCT drift. centred score field ϕ : K1 δ RK satisfies (cid:88) i= pi ϕi(p) = 0 ( K1 δ ), (S1) and the uniform regularity Mϕ := sup ϕ(p) < , ϕ(p) ϕ(q)2 Lϕ q2 ( p, K1 δ ). (S2S3) For ε 0, the SRCT drift is Fi(p) := pi (cid:104) ϕi(p) ε(cid:0) log pi log p(cid:1)(cid:105) , (p) by (S1). Write E(p) := (cid:0) log log 1(cid:1) and S(p) := diag(p) pp; then (p) = S(p)ϕ(p) εE(p). H.2 Global Lipschitz moduli and envelopes Define Λ(δ) := 1 + log 1 δ Lemma H.1 (Entropy map modulus). For all p, K1 and Clog(K, δ) := (2 + K) Λ(δ). , δ E(p) E(q)2 Clog(K, δ) q2. Lemma H.2 (Global Lipschitz drift). For all p, K1 , δ (p) (q)2 (cid:0)Lϕ + Mϕ + ε Clog(K, δ)(cid:1) q2. Proofs (sketch). For Lemma H.1, write E(r) = G(r) log with G(r) := log and use that (x log x) Kp q2. Lemma H.2 follows from Λ(δ) on [δ, 1] together with log log Λ(δ)p q1 Λ(δ) (ϕ(p) ϕ(q))2 Lϕp q2, (p q) ϕ(q)2 Mϕp q2, and Lemma H.1. The ReasoningCreativity Trade-off Size envelope. On K1 δ one has log 1/e and log log 1 δ , hence Fi(p) Mϕ + ε (cid:16) 1 + log 1 δ (cid:17) ( i). (42) H.3 Discrete minibatch updates and noise statistics Given step size η > 0 and batch size N, define Nt Multinomial(B, pt), ξt+1 :="
        },
        {
            "title": "Nt\nB",
            "content": "pt T, pt+1 = pt + η(cid:0)F (pt) + ξt+1 (cid:1), optionally followed by Euclidean projection onto K1 δ (which preserves mass). Lemma H.3 (Minibatch noise). Conditionally on pt, E[ξt+1 pt] = 0, E[ξt+12 2 pt] = 1 pt2 2 1 BK <"
        },
        {
            "title": "1\nB",
            "content": ". H.4 Continuoustime limits (correct scaling) Let (cid:101)p(η) be the piecewiselinear interpolation. Set γη := η/B. Theorem H.1 (ODE and diffusion limits). Fix > 0. As η 0 on [0, ]: (i) If γη 0, then (cid:101)p(η) in C([0, ], RK), where solves = (p). (ii) If γη γ (0, ), then (cid:101)p(η) solving the WrightFishertype SDE dpi = Fi(p) dt + (cid:16) γ pi dWi pi (cid:88) pk dWk (cid:17) , = 1, . . . , K, (43) k=1 with independent standard Brownian motions (Wk) and (cid:80) pi(t) 1. Sketch. Using Lemma H.3, the predictable quadratic variation of (cid:80) s<t/η η ξs+1 is (cid:80) η2E[ξ2] (η/B) = γηt. Combine Lemma H.2 with functional martingale CLT (EthierKurtz) and Gronwalltype estimates on the compact domain K1 . δ H.5 Boundary behavior: entropy gap and BD conditions For (0, 1) define the face gap Γ(y) := inf pK1 pi=y (cid:16) (cid:88) j=1 pj log pj log pi (cid:17) = (1 y) log 1 (K 1)y . (44) In particular LK(δ) := (1 δ) log 1δ (K1)δ > 0 for δ (0, 1/K), and if pi = δ then log log pi LK(δ). BarrierDominance (facewise). We say BD holds if, for each i, (cid:104) ϕi(p) + ε(cid:0)log log pi (cid:1) (cid:105) > 0. inf pK1 δ pi=δ convenient sufficient condition is Proposition H.1 (Deterministic forward invariance). If BD holds, then K1 (Nagumo criterion). conservative test is ε LK(δ) 2Mϕ. δ is forward invariant for = (p) ε LK(δ) > Mϕ. (45) Max Ruiz Luyten, Mihaela van der Schaar Unreflected vs. reflected diffusions. Unreflected model. In (43), the onedimensional marginal variance at trimmed face pi = δ equals γ δ(1 δ) > 0; hence a.s. nonattainability of the face cannot be deduced from inward drift alone. What holds are sharp highprobability nonexit bounds on finite horizons. Reflected model. With orthogonal, masspreserving reflection on each face of K1 , solutions remain in the trim for all by construction. On the compact domain with globally Lipschitz drift and uniformly elliptic tangent covariance, the reflected diffusion is strong Feller and irreducible, admits unique invariant law, and exhibits exponential mixing. Theorem H.2 (Bandwise highprobability confinement (unreflected)). Fix coordinate and band width η0 (0, 1 Kδ], and set ymax := δ + η0 and δ Γband := inf y[δ,ymax] Γ(y), µband := δ (cid:0)ε Γband Mϕ (cid:1), σ2 max := γ ymax(1 δ). If ε Γband > Mϕ, then for any start Y0 = pi(0) [δ, ymax], P(hit δ before ymax) exp (cid:16) 2 µband σ2 max (cid:17) (Y0 δ) . By the strong Markov property this yields an exponentially small (in η0 and γ1) probability of ever touching the floor from any interior start. Theorem H.3 (Reflected diffusion: wellposedness and ergodicity). On K1 = {(cid:80) unique invariant probability measure π with with orthogonal reflection in pi = 1}, the SDE (43) admits unique global strong solution, is strong Feller and irreducible, and has δ Pt(p, ) πTV eκt ( δ , 0). H.6 Uniform ellipticity on the tangent bundle Let Q(p) := γ(diag(p) pp) = γ S(p). For any K1 δ and , γ 2 The upper bound is Popovicius inequality; the lower bound uses (cid:80) 2 vQ(p)v γ δ v2 v2 2. piv2 δv2 2. (46) H.7 Gradientfield drifts and stationary laws If ϕ = Ψ and (S1) holds, π (when it exists; e.g., Theorem H.3) is characterized as the unique Neumann solution of the stationary FokkerPlanck equation associated with (43). The naive Gibbs ansatz exp{2γ1(Ψ εH)} 2 QT gives fails in general: = 2F unless 0. inserting = 2γ1(Ψ εH) into the reversibility identity = 1 2 (divT Q) 1 H.8 Small centred bias: concentration toward the fittest face Let δ RK satisfy (cid:80) γδ := δmax maxiI δi > 0 (if = ). The biased drift is δi = 0 and set δmax := maxi δi, := {i : δi = δmax}, := Sc, and the selection gap δ (p) := pi (cid:104) ϕi(p) + δi (cid:88) pjδj ε(cid:0) log pi log p(cid:1)(cid:105) . Exponential Lyapunov device (reflected model). Let m(p) := (cid:80) (variance of δ under p). For λ > 0 define (p) := eλm(p). Lemma H.4 (Lyapunov inequality). For the reflected diffusion with generator Lδ and any K1 δjpj and (p) := (cid:80) , pj(δj m(p))2 δ LδU (p) (p) (cid:16) λ (p) λ δ (cid:0)Mϕ + εClog (cid:1)(cid:17) . In particular, with λ := (cid:0)2δ(Mϕ + εClog)(cid:1)1 , LδU (cid:0)λV 1 (cid:1). The ReasoningCreativity Trade-off Proof. = λU δ, 2U = λ2U δδ; the diffusion contribution is nonnegative. For the drift, use (cid:80) m) = and the envelopes (cid:80) pj log pj log Clog. pjϕj Mϕ, (cid:80) pjδj(δj Theorem H.4 (Stationary concentration near the fittest face). Let π be the invariant law of the reflected biased diffusion. Then Eπ [V ] 2λδ 2λ with λ = 1 2δ(Mϕ + εClog) . Since (p) γ2 δ L(p)(cid:0)1L(p)(cid:1) with L(p) := (cid:80) iI pi, this implies the symmetric band estimate, for any θ (0, 1 2 ], (cid:8) θ L(p) 1 θ (cid:9) π 1/(Mϕ+εClog) δ(Mϕ + εClog) γ2 δ θ(1 θ) . Remark (no fixation under positive floor). iI pi(t) δ for all t; thus one has concentration toward (not fixation on) the fittest face. bona fide fixation statement appears only in the vanishingfloor limit δ 0. If δ > 0 then (cid:80) H.9 Logratio SDEs (algorithmspecific) For zij := log(pi/pj), Itˆos formula applied to (43) yields the exact identity dzij = (cid:0)ϕi(p) ϕj(p)(cid:1) dt ε zij dt γ 2 (cid:16) 1 pi pi (cid:17) 1 pj pj dt + γ (cid:16) dWi pi (cid:17) . dWj pj (47) GRPO (withinclass). reduces to If all correct traces share the same centred score, ϕi = ϕj within the class, then (47) dzij = ε zij dt γ 2 (cid:16) 1 pi pi (cid:17) 1 pj pj dt + γ (cid:16) dWi pi (cid:17) . dWj pj STaR (withinclass). If ϕi ϕj = (pi pj)/ρ with ρ := (cid:80) cC pc, then dzij = (cid:16) pi pj ρ ε zij (cid:17) dt γ 2 (cid:16) 1 pi pi (cid:17) 1 pj pj dt + γ (cid:16) dWi pi (cid:17) . dWj pj On δ one has pi pj/ρ 1(K1)δ δ zij. DPO (samesign pair). With si {1} and ϕi(p) = si gβ(log pi) (cid:80) for i, with si = sk and pi pk, pkskgβ(log pk), β(x) [β/4, 0); dzik (cid:0)s β(ξ) ε(cid:1) zik dt + (Itˆo & noise as in (47)). Intraclass logratios contract if ε > sup(g β) (e.g. ε > β/4). H.10 Regime dictionary (concise) Let := σ2/λeff with σ2 := γ the diffusion variance scale and λeff local contraction modulus of on (for logratios, λeff ε). Under BD: 1 (low noise): tight interior concentration; Var(zij) = O(σ2/ε). 1 (balanced): moderate interior spread; unique invariant law. 1 (noisedominated but interior): broad interior law; faces are still repelling. Max Ruiz Luyten, Mihaela van der Schaar If BD fails, boundary approach and absorption may occur; interior concentration statements do not apply. Summary. On the trimmed simplex, the SRCT drift is globally Lipschitz with an explicit modulus; minibatch noise is centred with variance O(1/B). The correct continuoustime limits are the ODE (η/B 0) and WrightFishertype diffusion (η/B γ). The entropy face gap LK(δ) quantifies inward normal speed; BD yields ODE invariance and, for the unreflected SDE, highprobability confinement on finite horizons; the reflected diffusion is strictly invariant and exponentially ergodic. small centred bias admits an exponential Lyapunov control that quantifies stationary concentration toward the fittest face. Exact logratio SDEs provide algorithmspecific envelopes (GRPO, STaR, DPO)."
        },
        {
            "title": "I Kernel Design Strategies for SRCT",
            "content": "This appendix gives selfcontained, concise treatment of kernel design and analysis for SRCT. Part I.1 establishes an exact twolevel stationarity condition, curvature (uniqueness/interiority), tight logratio envelope with dynamic floor, exponential convergence rates, uniform suppression guarantee, and blockconstant PSD construction that realizes prescribed class gap with controlled norms. Part I.2 turns to practically learned kernels, including gated effective kernel, exact suppression ratios, supportfunction identity that quantifies diversity pressure, and an explicit global Lipschitz modulus for the SRCT drift. Setting, notation, and standing assumptions. Let = {π1, . . . , πS}, 2, and S1 := {p [0, 1]S : (cid:80)S i=1 pi = 1}. All logs are natural; 0 log 0 := 0. Fix partition = with = , sizes := 1, := = , and utilities Ui := 1{iC} {0, 1}. Kernels are symmetric PSD: = 0. Vector norms 2, ; operator norms A22 (spectral), := maxi Aij, Amax := maxi,j Aij. Let := 1 (tangent subspace) and ΠT := 1 (cid:80) 11. SRCT objective, Shahshahani flow, and gauge. For λ, β 0 and entropy strength > 0 define (cid:101)J(p) := λβ pKp + H[p], H[p] := (cid:88) i=1 pi log pi. Variational derivative (on int S1): Fi(p) = δ (cid:101)J δpi = Ui 2λβ (Kp)i (1 + log pi), (p) := (cid:88) pjFj(p). The Shahshahani (replicator) flow is pi = pi (cid:0)Fi(p) (p)(cid:1), (cid:88) pi = 0. Adding constant to leaves the vector field invariant (gauge invariance); thus the +1 in A(1 + log pi) can be absorbed into the KKT multiplier at stationarity. I.1 Idealized Kernel for TwoLevel Equilibrium Twolevel target. Fix δ (0, 1) with δ < 1 and set := δ (i I), =: pC := 1 δ > 0 (c C), and write VC := (Kp)c (all C), VI := (Kp)i (all I). Proposition I.1 (KKT classwise constancy + gap). Under the twolevel ansatz above, is stationary point of the Shahshahani flow if and only if (i) Classwise constancy: (Kp)c VC for all and (Kp)i VI for all I. (ii) Gap identity: The ReasoningCreativity Trade-off 1 2λβ (VC VI ) log pC δ = 0. Proof. Subtract the KKT equations for two indices in the same class to force classwise constancy; subtract correctincorrect pair and use Uc Ui = 1 and log = log(pC/δ) to obtain the gap. The converse is immediate by inspection. log Curvature, strict concavity, uniqueness, interiority. Let κT := λmin (cid:0)(ΠT KΠT )T (cid:1) 0. For any , 2 (cid:101)J(p)v, = v2 pi (cid:88) 2λβ vKv (A + 2λβ κT ) v2 2. Hence (cid:101)J is Astrongly concave on the affine simplex; in particular, the maximizer is unique and (by the steepness of H[p]) interior. Logratio dynamics, operatornorm envelope, dynamic floor. Let zij := log pi pj . Along trajectories, zij = (Ui Uj) 2λβ(cid:0)(Kp)i (Kp)j (cid:1) zij. For all S1 and = j, (cid:12)(Ki Kj)p(cid:12) where one may take any of the following (use the tightest available): (cid:12) (cid:12)(Kp)i (Kp)j (cid:12) = (cid:12) (cid:12) (cid:12) K, (cid:26) 2 K22, 2 K, 2 Kmax, max i=j Ki Kj . (cid:27) With := Ui Uj + 2λβ 1 + 2λβ K, variation of constants yields zij(t) zij(0)eAt + (1 eAt). Let := max (cid:110) zkℓ(0), (cid:111) , δ := S1eM. Then, for all 0 and all i, δ pi(t) mini pi δ} is forwardinvariant. , so the ODE is globally wellposed and δ := {p S1 : Exponential convergence. Let a(p) := (p) p, (p)1. Along trajectories, 2 on δ. Since (cid:101)J is Astrongly concave on the affine simplex, (cid:101)J(p) (cid:101)J(p) 1 δa(pt)2 all 0, dt (cid:101)J(pt) = (cid:80) 2A a(p)2 pi ai(pt)2 2. Therefore, for (cid:101)J(p) (cid:101)J(pt) (cid:0) (cid:101)J(p) (cid:101)J(p0)(cid:1)e2Aδ t, pt p2 (cid:113) (cid:0) (cid:101)J(p) (cid:101)J(p0)(cid:1) eAδ t. 2 Moreover, since 2 (cid:101)J(p) diag(1/p), (cid:101)J is Astrongly concave in the Shahshahani metric gp(u, u) = (cid:80) and the Riemannian PL inequality with the Lyapunov identity gives the δfree rate u2 /pi, (cid:101)J(p) (cid:101)J(pt) (cid:0) (cid:101)J(p) (cid:101)J(p0)(cid:1)e2At. Stationary structure and uniform suppression. At any equilibrium p, subtracting KKT equations with the same utility yields, for Ua = Ub, For C, I, log p = (cid:16) 2λβ (Kp)a (Kp)b (cid:17) . log p = (cid:16) 1 1 2λβ(cid:0)(Kp)c (Kp)i (cid:1)(cid:17) . pindependent sufficient condition ensuring i < for all such pairs is 2λβ < 1 (use any bound above; the ℓ rowdifference is tight). max k=ℓ eM Max Ruiz Luyten, Mihaela van der Schaar Blockconstant kernels: PSD, norms, gap realization, lownorm choice. Consider Kij = κCC, κII , κCI , i, C, i, I, otherwise. Let := ( κCC κCI 0 0, i.e., κCC 0, κII 0, κCCκII κ2 = max{M κCC + κCI , κCI + κII }. With the twolevel p, κCI κII ) and : R2 RS, (a, b) = 1C + 1I, so = BT and rank(K) 2. Then CI . Norm controls: K22 max{M, } B22 and (Kp)c (Kp)i = (κCC κCI ) (1 δ) + (κCI κII ) δ, so the gap identity of Proposition I.1 becomes (1 δ)(κCC κCI ) + δ(κCI κII ) = 1 log(pC/δ) 2λβ =: X. lownorm constructive choice sets κCI = 0 and then κmin II = max (cid:110) 0, (cid:111) δ (N 1), κCC = + δ κmin II 1 δ , minimizing = max{M κCC, κII } under PSD. Edge case = 0: λβ pKp + H[p] yields unique interior solution for > 0. the gap is void; maximizing I.2 Practical Design with Learnable Semantic Kernel Gated effective kernel and objective. Let ksem = binary verifier with = {i : Ri = 1}, = {i : Ri = 0}. Define the effective kernel sem 0 be learnable semantic kernel and {0, 1}S Keff := Diag(R) ksem Diag(R) 0. Consider the objective (p) = + λ(cid:0)α H[p] β pKeff p(cid:1), λ, α, β 0, and let the effective entropy coefficient be The SRCT flow uses the score ϕi(p) = Ui 2λβ (Keff p)i and reads εtot := εbase + λα, εbase > 0. pi = pi (cid:0)ϕi(p) ϕ(p)(cid:1) εtot pi (cid:0) log pi log p(cid:1), ϕ(p) := (cid:88) pjϕj(p), log := (cid:88) pj log pj. Stationary points int S1 satisfy the KKT system Ui 2λβ (Keff p)i εtot (cid:0)1 + log (cid:1) = λ0, with the +1 and λ0 eliminated by taking differences. Incorrect suppression and equalization among correct traces. Since Keff (i, ) 0 for I, (Keff p)i = 0 and, for any C, p (cid:18) = exp 1 2λβ (Keff p)c εtot (cid:19) . Thus strong suppression (p ) is promoted by small εtot and moderate λβ (Keff p)c. For a, C, εtot log (cid:16) = 2λβ p (Keff p)b (Keff p)a (cid:17) , so larger εtot enhances equalization when the correctside kernel averages are close. The ReasoningCreativity Trade-off Supportfunction identity (diversity pressure). For any RSS and distinct i, j, sup pS1 (cid:12) (cid:12)(Ap)i (Ap)j (cid:12) (cid:12) = sup pS (cid:12)(Ai Aj)p(cid:12) (cid:12) (cid:12) = Ai Aj. (Proof: S1 is the convex hull of basis vectors; the support function in direction equals maxk ak; take absolute values.) Applying this to = Keff shows that the maximal instantaneous disparity of kernel averages across two correct indices is exactly the ℓ rowdifference; when ksem is semantically coherent, this term is larger across distinct semantic lumps, enforcing diversity via the β pKeff penalty. Global Lipschitz modulus of the SRCT drift on trimmed simplex. Let S1 := {p S1 : pi δ i} and Λ(δ) := 1 + log(1/δ). Write S(p) := diag(p) pp and E(p) := (cid:0) log log 1(cid:1), so the drift is (p) = S(p)ϕ(p) εtotE(p) with ϕ(p) = 2λβ Keff p. On S1 δ , δ S(p)22 1 2 , S(p) S(q)22 3 q2, L(2) ϕ := 2λβ Keff 22, ϕ(p)2 + 2λβ Keff 22 =: Mϕ,2, E(p) E(q)2 Λ(δ) (2 + S) q2. Combining, (p) (q)2 (cid:16) 1 2 L(2) ϕ + 3 Mϕ,2 + εtot Λ(δ) (2 + (cid:17) S) q2. Hence the ODE is globally Lipschitz on S1 δ with an explicit modulus. Tuning guidance (concise). Smaller εtot (i.e., smaller λα given εbase) yields exponentially stronger incorrect suppression but weaker equalization; larger εtot does the opposite. The coefficient λβ regulates semantic diversity pressure via Keff and should be chosen to spread mass across genuinely distinct correct lumps without excessively penalizing semantically coherent highutility traces. Designtoguarantee checklist (explicit constants). 1. Target & gap. = 1 δ 2. Kernel. Choose symmetric PSD realizing the gap; for blockconstant K, the lownorm choice is κCI = 0 1 log(pC/δ) 2λβ with pC = . and κII = κmin II , κCC = + δ κmin II 1 δ . 3. Curvature (uniqueness/interiority). Ensure > 0 (then the maximizer is unique and interior). 4. Logratio floor. With any option above, set = 1 + 2λβ K, = max{maxi=j zij(0), B/A}, δ = S1eM; then pi(t) [δ, eM/S] for all t. 5. Rates. EuclideanPL on δ: pt p2 (cid:113) 2 (cid:0) (cid:101)J(p) (cid:101)J(p0)(cid:1) eAδt; metricPL (δfree): (cid:101)J(p) (cid:101)J(pt) ( (cid:101)J(p) (cid:101)J(p0))e2At. 6. Suppression. uniform sufficient condition for < is 2λβ < 1. Notation hygiene and edge cases. Symbol δ denotes the prescribed target floor in the twolevel ansatz, while δ = S1eM is the dynamic floor from the logratio envelope. When = 0, the crossclass gap is void; all curvature, floor, and convergence statements remain valid with > 0."
        },
        {
            "title": "J Insight Experiments",
            "content": "This appendix complements the main paper with simple experiments to validate parts of the theory. Unless stated otherwise: lines are means across five seeds and ribbons show 1 s.d; the vertical line at step 200 indicates the eventdetection smoothing floor. Metrics used throughout are the entropy = (cid:80) pi log pi, fixation index Max Ruiz Luyten, Mihaela van der Schaar Fix = (cid:80) probability on incorrect traces), and the objective proxy p2 , cluster Gini (inequality over masses of the three correctstrategy clusters), incorrect mass (total Jp := utility mass + λα λβ pKeff p. J.1 Experimental Implementation and Reproducibility Synthetic trace universe. All experiments share the same finite trace universe with = 12 traces. Eight traces are correct and partitioned into three semantic clusters (strategies) A, B, of sizes 3, 3, 2; the remaining four are incorrect. Let {1, . . . , 12} be the set of correct traces and = {1, . . . , 12} the incorrect traces. policy is probability vector S1, with numerical clipping pi max(pi, 1012) before any log is evaluated. Cluster membership is used only for analysis and, in Study B, for the creativity kernel. Verifier and rewards. Correctness is deterministic: (i) = 1 for C, (i) = 0 for I. In Study B, we additionally use base rewards r(i) = 1.0 for and r(i) = 0.2 for I. Mini-batch sampling and noise. Each update step draws multinomial mini-batch of size from the current policy p, yielding counts Multinomial(B, p) and empirical frequencies ˆp = n/B. All fitness/payoff computations that require batch statistics use ˆp (not the full p) so that finite-batch noise is the only source of stochasticity. pi log pi. p2 Common metrics and event detection. At fixed intervals we log: Entropy: H[p] = (cid:80) Fixation index: Fix = (cid:80) Cluster masses: mA, mB, mC (probability within each correct cluster). Cluster inequality: Gini(mA, mB, mC). Incorrect mass: Minc = (cid:80) Objective proxy (Study B): Jp = (cid:80) (monoculture 1). iI pi. described below. iC pi + λα H[p] λβ pKeffp, where Keff is the gated creativity kernel Events are detected on 50-step moving averages with 200-step floor: (i) fixation (STaR/GRPO) when maxi pi 0.75 and max{mA, mB, mC} 0.9; (ii) homogenization (DPO) when the smoothed cluster Gini 0.10 and all nonzero cluster masses 0.15. Unless noted, runs use = 5000 steps and five seeds {101, 202, 303, 404, 505}; lines show seed means and ribbons 1 s.d. Theoretical (replicator) update used in Studies and A+. All theory tracks use the same exponentiated-gradient (replicator) step with learning rate η = 0.15 and barrier ε {0, 3 104}. The method-specific fitness ϕi is: pi pi exp(cid:0)η [ϕi ε log pi](cid:1), p/p1, STaR: ϕi = ˆpi/ˆρ if C, else 0, ˆρ = (cid:88) cC ˆpc; GRPO: ϕi = 1{i C}; DPO: ϕi = log (cid:0) max(ˆpi, 1012)(cid:1) if C, else 0. Algorithm-faithful (procedural) updates used in Study A+. In parallel to the theory track, we run algorithm-faithful procedures on logits θ with = softmax(θ): STaR (sequential reinforcement). Sample up to traces i.i.d.; on the first correct apply θ θ + ηstar(ec p). If none is correct, no-op that step. {16, 64} co-varies with B. The ReasoningCreativity Trade-off GRPO (group REINFORCE with baseline). Sample group of size m; with centered advantages aj = rj r, θ θ + ηgrpo (cid:80) aj(eij p); {8, 16, 32} depending on B. DPO (pairwise preferences, Davidson ties). For pairs (i, j) drawn from the batch, compute the Davidson log-likelihood with tie parameter ν and take gradient step θ θ + ηdpoθℓ. We use batched pairs and adaptive scaling to match one-step norms to the theory track. For each method and B, ηproc (and, for DPO, pairs-per-step and ν) is calibrated on small set of anchor states to maximize the mean cosine between one-step from the procedural and theory tracks while keeping the norm ratio close to 1. DCR objective and kernel (Study B). Study augments GRPO-like base with diversity energy λ(αH[p] β Q[p]), and folds the entropic term into the effective barrier: ε εbarrier + λα with εbarrier = 104. The gated kernel is Keff = Ksem R, Rii = 1{i C}, and Ksem(i, j) = 1 if i, are correct and in the same cluster, else 0. The fitness used in the replicator step is so that the quadratic penalty λβ pKeffp discourages concentration on similar correct traces only. We sweep α {0.02, 0.05, 0.10}, β {0.10, 0.25, 0.50, 0.75}, with λ = 1, = 128, η = 0.15. Two ablations are reported: Entropy-only (β = 0) and Ungated (apply to all traces). ϕi = r(i) 2λβ (Keff ˆp)i, seeds Unless Time horizons, {101, 202, 303, 404, 505}; 50-step moving averages and 200-step event floor are used for all event times and overlaid ribbons. seeds, and smoothing. = 5000 steps; stated otherwise: We run all experiments on single NVIDIA RTX 6000 with 49GB of VRAM. J.2 Strategysimplex overview  (Fig. 1)  Figure 1 provides qualitative, distributional view of training on the threestrategy simplex (clusters A/B/C): STaR flows to corner (monoculture), GRPO meanders along neutral manifold before noisedriven fixation, DPO equalizes mass within the correct set, and DCR converges to unique interior equilibrium with multistrategy support. These panels summarize the highlevel modes that are quantitatively confirmed in the subsequent figures. J.3 Study A: scalarobjective dynamics  (Fig. 2)  Figure 2 aggregates the time evolution of H, Fix, cluster Gini, and incorrect mass for STaR, GRPO, and DPO. STaR collapses essentially immediately (H 0, Fix 1); GRPO exhibits slow, batchsizedependent drift (median fixation 4.7k steps at B=16; no fixation by 5k at B=64); DPO homogenizes correct strategies early while maintaining zero incorrect mass. J.4 Study B: overlays and alignment diagnostics (Figs. 3, 4, 5) The overlays in Fig. 3 compare the replicator theory track and the algorithmfaithful procedural track for common seed: STaR nearly coincides; GRPO shows smallmagnitude neutral steps; DPO matches event timing but sustains higher entropy due to pairedcomparison (Davidson ties) and the θ (cid:55) geometry. Perstep alignment in Fig. 4 shows (i) high sign agreement for DPO with modest cosine (geometry mismatch), (ii) nearneutral GRPO behavior, and (iii) high STaR cosine with zero eventgap. Batchsize summaries in Fig. 5 confirm that, despite low cosines at larger B, the onestep JS divergence shrinks and event timing synchronizes. J.5 Study C: DCR phase diagrams  (Fig. 6)  and ablations  (Fig. 7)  Figure 6 sweeps (α, β) and reports: incorrect mass, minimum cluster mass, betweenseed JSD, and correct mass. broad band achieves nearzero incorrect mass, full coverage, and negligible betweenseed JSDan empirical signature of unique, interior, diverse equilibrium. Max Ruiz Luyten, Mihaela van der Schaar Figure 1: Strategysimplex dynamics. Representative trajectories of cluster masses (mA, mB, mC) under STaR, GRPO, DPO, and DCR. STaR collapses to vertex; GRPO drifts along the face; DPO equalizes on the face; DCR reaches stable interior point retaining all clusters. Early (step 200) and late (step 5000) states are marked. Figure 7 compares DCR, Entropyonly, and Ungated. While coverage saturates at 3 for all, DCR reduces kernel energy (structured diversity) and maintains large positive safety margins; Entropyonly lacks targeted distinctiveness; Ungated penalizes incorrectincorrect similarity, degrading safety despite larger proxy gains. J.6 Objective and safety trajectories (Fig 8) Figure 8 shows trajectories: DCR reaches stable interior solution with safety 0.93; Entropyonly has safety fixed at 1 (no kernel); Ungated converges at much lower safety ( 0.48). J.7 Safetymargin distribution  (Fig. 9)  The histogram in Fig. 9 reports the minimum safety margin attained along training within the DCR band; all runs remain strictly positive (worst case 0.267), empirically validating the tuning rule that kernel pressure must not overwhelm the unit utility signal. The ReasoningCreativity Trade-off Figure 2: Study A: collapse modes. Rows: STaR (top), GRPO (middle), DPO (bottom). Columns: entropy H, fixation index Fix, cluster Gini, incorrect mass (log scale). STaR deterministically fixates; GRPO drifts with speed increasing at smaller batch; DPO equalizes among correct traces while keeping incorrect mass at 0. Max Ruiz Luyten, Mihaela van der Schaar Figure 3: Theory vs. procedural overlays (single seed). Entropy and clusterGini trajectories for STaR, GRPO, and DPO. Procedural updates (sequential STaR, group REINFORCE, Davidsonties DPO) track theory closely in events; instantaneous directions differ most for DPO. The ReasoningCreativity Trade-off Figure 4: Alignment vs. theory over time. For each method: cosine of (solid: Euclidean; dotted: Shahshahani), sign agreement of logratio slopes, and eventtime gap (procedural theory). DPO: low cosine, nearperfect signs; GRPO: nearneutral; STaR: high cosine, zero gap. Figure 5: Alignment summary vs. batch size. Euclidean/Shahshahani cosine and onestep JS divergence as functions of (markers: mean; bars: s.d.). Cosine decreases with for DPO while JS concurrently decreases, indicating increasingly synchronous trajectories despite metric/parameterization mismatch. Max Ruiz Luyten, Mihaela van der Schaar Figure 6: DCR phase diagrams over (α, β). From left to right: incorrect mass (log scale), minimum cluster mass, betweenseed JSD, and correct mass. contiguous band shows nearzero error, high structured diversity, and unique terminal distribution. Figure 7: DCR vs. ablations. Bars (meansd) for incorrect mass (log axis), coverage, kernel energy, objective Jp, and safety margin. DCR achieves the best tradeoff (low error, full coverage, lower kernel energy, strong safety). Entropyonly preserves breadth without distinctiveness; Ungated reduces safety by penalizing similarity outside the correct set. Figure 8: Objective & safety (overlay). Overlay of Jp (left) and safety (right) for DCR (green), Entropyonly (gray), and Ungated (gold). The ReasoningCreativity Trade-off Figure 9: Safetymargin distribution within the DCR band. Minimum safety margin per run (bars) with scatter inset over (α, β) (green markers). All seeds stay comfortably above 0 (min 0.267)."
        }
    ],
    "affiliations": []
}