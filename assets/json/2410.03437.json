{
    "paper_title": "Zebra: In-Context and Generative Pretraining for Solving Parametric PDEs",
    "authors": [
        "Louis Serrano",
        "Armand Kassaï Koupaï",
        "Thomas X Wang",
        "Pierre Erbacher",
        "Patrick Gallinari"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Solving time-dependent parametric partial differential equations (PDEs) is challenging, as models must adapt to variations in parameters such as coefficients, forcing terms, and boundary conditions. Data-driven neural solvers either train on data sampled from the PDE parameters distribution in the hope that the model generalizes to new instances or rely on gradient-based adaptation and meta-learning to implicitly encode the dynamics from observations. This often comes with increased inference complexity. Inspired by the in-context learning capabilities of large language models (LLMs), we introduce Zebra, a novel generative auto-regressive transformer designed to solve parametric PDEs without requiring gradient adaptation at inference. By leveraging in-context information during both pre-training and inference, Zebra dynamically adapts to new tasks by conditioning on input sequences that incorporate context trajectories or preceding states. This approach enables Zebra to flexibly handle arbitrarily sized context inputs and supports uncertainty quantification through the sampling of multiple solution trajectories. We evaluate Zebra across a variety of challenging PDE scenarios, demonstrating its adaptability, robustness, and superior performance compared to existing approaches."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 8 ] . [ 2 7 3 4 3 0 . 0 1 4 2 : r ZEBRA: IN-CONTEXT AND GENERATIVE PRE-"
        },
        {
            "title": "TRAINING FOR SOLVING PARAMETRIC PDES",
            "content": "Louis Serrano1 Armand Kassaı Koupaı1 Thomas Wang1 Pierre Erbacher 2 Patrick Gallinari1,3 1Sorbonne Universite, CNRS, ISIR, 75005 Paris, France 2Naver Labs Europe, France 3Criteo AI Lab, Paris, France"
        },
        {
            "title": "ABSTRACT",
            "content": "Solving time-dependent parametric partial differential equations (PDEs) is challenging, as models must adapt to variations in parameters such as coefficients, forcing terms, and boundary conditions. Data-driven neural solvers either train on data sampled from the PDE parameters distribution in the hope that the model generalizes to new instances or rely on gradient-based adaptation and meta-learning to implicitly encode the dynamics from observations. This often comes with increased inference complexity. Inspired by the in-context learning capabilities of large language models (LLMs), we introduce Zebra, novel generative autoregressive transformer designed to solve parametric PDEs without requiring gradient adaptation at inference. By leveraging in-context information during both pre-training and inference, Zebra dynamically adapts to new tasks by conditioning on input sequences that incorporate context trajectories or preceding states. This approach enables Zebra to flexibly handle arbitrarily sized context inputs and supports uncertainty quantification through the sampling of multiple solution trajectories. We evaluate Zebra across variety of challenging PDE scenarios, demonstrating its adaptability, robustness, and superior performance compared to existing approaches. GitHub page: https://github.com/LouisSerrano/zebra."
        },
        {
            "title": "INTRODUCTION",
            "content": "Training partial differential equation (PDE) solvers is challenging task due to the variety of behaviors that can arise in physical phenomena, and neural solvers have limited generalization capability(Chen et al., 2018; Raissi et al., 2019; Li et al., 2021). We tackle the parametric PDE problem (Cohen & Devore, 2015), where model is trained on trajectories defined by varying PDE parameters with the goal of generalizing across wide range of parameters. The parameters may include initial and boundary conditions, physical coefficients, and forcing terms. We focus on pure datadriven approaches that do not leverage any prior knowledge on the underlying equations. natural approach to this problem is to sample from the parameter distribution, i.e., to train using different PDE instances or parameter values, along with multiple trajectories for each PDE instance. This requires training set representative of the distribution of the underlying dynamical system, which is difficult to meet in practice given the complexity of physical phenomena. Other approaches explicitly condition on specific PDE parameters, (Brandstetter et al., 2022b; Takamoto et al., 2023) relying on the availability of such prior knowledge. This requires physical model of the observed system, making the incorporation of PDE parameters into neural solvers challenging beyond basic PDE coefficients. An alternative approach involves online adaptation to new PDE instances by leveraging observations from novel environments. Here we consider that an environment is charaterized by set of parameters. This adaptation is often implemented through meta-learning, where the model is trained on variety of simulations corresponding to different environmentsi.e., varying PDE parameter valuesso that it can quickly adapt to new, unseen PDE simulation instances using few trajectory examples(Kirchmeyer et al., 2022; Yin et al., 2022). This method offers high flexibility but requires gradient updates for adaptation, adding computational overhead. Another Corresponding author: louis.serrano@isir.upmc.fr 1 common setting involves leveraging historical data to condition the neural network, allowing it to generalize to new PDE instances without retraining (Li et al., 2021; McCabe et al., 2023). Again the generalization ability is limited to dynamics close to the ones used for training. Exploring another direction and motivated by the successes encountered in natural language processing and vision, some authors have begun investigating the development of foundation models for spatio-temporal dynamic physical processes (Subramanian et al., 2023; Herde et al., 2024; McCabe et al., 2023). This approach involves training large model on variety of physics-based numerical simulations with the expectation that it will generalize to new situations or equations. While they consider multiple physics we focus on solving parametric PDEs, i.e. multiple variations of the same physical phenomenon. We explore here new direction inspired by the successes of in-context learning (ICL) and its ability to generalize to downstream tasks without retraining (Brown et al., 2020; Touvron et al., 2023). We propose framework, denoted Zebra, relying on in-context pretraining (ICP), for solving parametric PDEs and learning to condition neural solvers to adapt fast to new situations or said otherwise for solving for new parameter values. As for ICL in language the model is trained to generate appropriate responses given context examples and query. The context examples could be trajectories from the same dynamics starting from different initial conditions, or simply brief history of past system states for the target trajectory. The query will consist for example of an initial state condition, that will serve as inference starting point for the forecast. This approach offers key advantages compared to existing methods. It can leverage contexts of different types and sizes, it requires only few context examples to adapt to new dynamics and can can handle as well 0-shot learning. It allows us to cover large variety of situations. On the technical side, Zebra introduces novel generative autoregressive solver for parametric PDEs. It employs an encode-generate-decode framework: first, vector-quantized variational autoencoder (VQ-VAE) (Oord et al., 2017) is learnt to compress physical states into discrete tokens and to decode it back to the original physical space. Next, generative autoregressive transformer is pre-trained using next token objective. To leverage the in-context properties of the model, Zebra is directly pretrained on arbitrary-sized contexts such as extra trajectories or historical states of the target dynamics. At inference, Zebra can handle varying context sizes for conditioning and support uncertainty quantification, enabling generalization to unseen PDE parameters without gradient updates. Our main contributions include: We introduce generative autoregressive transformer for modeling physical dynamics. It operates on compact discretized representations of physical state observations. This discretization is performed through VQ-VAE. The encoder tokenizes observations into sequences of tokens, while the decoder reconstructs the original states. This framework represents the first successful application of generative modeling using quantized representations of physical systems. To harness the in-context learning strengths of autoregressive transformers, we develop new pretraining strategy that conditions the model on historical states or example trajectories with similar dynamics, allowing it to handle arbitrary-sized context token inputs. We evaluate Zebra on range of parametric PDEs on two distinct settings. In the first, the model infers dynamics from context trajectory that shares similar behavior with the target but differs in initial conditions, representing one-shot setting. Zebras performance is benchmarked against domain-adaptation baselines specifically trained for such tasks. In the second scenario, only limited number of historical frames of the target trajectory are available, requiring the model to deduce the underlying dynamics solely from these inputs. Zebra consistently demonstrates competitive performance across both evaluation contexts. Figure 1: Zebra Framework for solving parametric PDEs. 1) finite vocabulary of physical phenomena is learned by training VQ-VAE on spatial representations. 2) During the pretraining, multiple trajectories sharing the same dynamics are tokenized and concatenated into common sequence S. transformer is used to predict the next tokens in these sequences, conditioned on the context. This enables the model to perform both zero-shot and few-shot generation, without gradient-based updates."
        },
        {
            "title": "2 PROBLEM SETTING",
            "content": "2.1 SOLVING PARAMETRIC PDE We aim to solve parametric time-dependent PDEs beyond the typical variation in initial conditions. Our goal is to train models capable of generalizing across wide range of PDE parameters. To this end, we consider time-dependent PDEs with different initial conditions, and with additional degrees of freedom, namely: (1) coefficient parameters such as fluid viscosity or advection speed denoted by vector µ ; (2) boundary conditions B, e.g. Neumann or Dirichlet; (3) forcing terms δ, including damping parameter or sinusoidal forcing with different frequencies. To simplify notation we denote ξ := {µ, B, δ} and we define Fξ as the set of PDE solutions corresponding to the PDE parameters µ, boundary conditions and forcing term δ, and refer to Fξ as PDE partition. Formally, solution u(x, t) within Fξ satisfies: (cid:18) t B(u)(x, t) = 0, = δ, µ, t, x, u, x , (cid:19) 2u x2 , . . . , Ω, (0, ] u(0, x) = u0, Ω Ω, (0, ] (1) (2) (3) where is function of the solution and its spatial derivatives on the domain Ω, and also includes the forcing term δ ; is the boundary condition constraint (e.g., spatial periodicity, Dirichlet, or Neumann) that must be satisfied at the boundary of the domain Ω; and u0 is the initial condition sampled with probability measure u0 p0(.)."
        },
        {
            "title": "2.2 GENERALIZATION FOR PARAMETRIC PDE",
            "content": "Solving time-dependent parametric PDEs requires developing neural solvers capable of generalizing to whole distribution of PDE parameters. In practice, changes in the PDE parameters often lead to distribution shifts in the trajectories which makes the problem challenging. Different directions are currently being explored briefly reviewed below. We focus on pure data-driven approaches that do not make use of any prior knowledge on the equations. We make the assumption that the models are learned from numerical simulations so that it is possible to generate from multiple parameters. This emulates real situations where for example, physical phenomenon is observed in different contexts. 0-shot learning with temporal conditioning first direction consists in adapting the classical ERM framework to parametric PDE solving by sampling multiple instances of PDE, in the hope that this will generalize to unseen conditions in 0-shot setting. It is usually assumed that for both learning and inference, sequence of past states is provided as initial input to the model, leveraging its potential to infer the dynamics characteristics in order to forecast future values. The neural solver Gθ is then conditioned by sequence of past states for trajectory utmt:t := (utmt, . . . , ut) where 1. Depending on the architecture, this can be implemented by stacking the information in the channel dimension (Li et al., 2021), or by creating an additional temporal dimension as done in video prediction contexts (McCabe et al., 2023; Ho et al., 2022). This approach makes an implicit i.i.d. assumption on the training - test distributions which is often not met with dynamical phenomena. It offers limited flexibility in cases where only limited historical context is accessible. Few-shot learning by fine tuning Another category of methods leverages fine tuning. As for the 0-shot setting above, model is pretrained on distribution of the PDE parameters. At inference, for new environment, fine tuning is performed on sample of the environment trajectories. This approach often relies on large fine tuning samples and involves updating all or subset of parameters (Subramanian et al., 2023; Herde et al., 2024). Adaptive conditioning more flexible approach relies on adaptation at inference time through meta-learning. It posits that set of environments are available from which trajectories are sampled, each environment being defined by specific PDE parameter values (Zintgraf et al., 2019a; Kirchmeyer et al., 2022). The model is trained from sampling from the environments distribution to adapt fast to new environment. The usual formulation is to learn shared and specific environment parameters Gθ+θξ , where θ and θξ are respectively the shared and specific parameters. At inference, for new environment, only small number of parameters θξ is adapted from small sample of observations. Table 1: Key distinctions with Baselines. Zebra is the only method that supports both adaptive conditioning, temporal conditioning, and does not require gradient computations at inference. Method Adaptive conditioning Temporal conditioning CAPE CODA MPP Zebra In-context"
        },
        {
            "title": "3 ZEBRA FRAMEWORK",
            "content": "We introduce Zebra, novel framework designed to solve parametric PDEs through in-context learning and flexible conditioning. Zebra utilizes an autoregressive transformer to model partial differential equations (PDEs) within compact, discrete latent space. spatial CNN encoder is employed to map physical spatial observations into these latent representations, while CNN decoder accurately reconstructs them. As illustrated in Figure 1, our pretraining pipeline consists of two key stages: 1) Learning finite vocabulary of physical phenomena, and 2) Training the transformer using an in-context pretraining strategy, enabling the model to effectively condition on contextual in4 formation. At inference, Zebra allows both adaptive and temporal conditioning through in-context learning  (Table 1)  ."
        },
        {
            "title": "3.1 LEARNING A FINITE VOCABULARY OF PHYSICAL PHENOMENA",
            "content": "In order to leverage the auto-regressive transformer architecture and adopt next-token generative pretraining, we need to convert physical observations into discrete representations. To keep the modeling with the transformer computationnaly tractable, we do not quantize the observations directly but rather quantize compressed latent representations by employing VQVAE (Oord et al., 2017). Our encoder spatially compresses the input function ut by reducing its spatial resolution to lower resolution while increasing the channel dimension to d. This is achieved through convolutional model Ew, which maps the input to continuous latent variable zt = Ew(ut), where zt Rhwd. The latent variables are then quantized to discrete codes zt using codebook of size = and through the quantization step q. For each spatial code zt [ij], the nearest codebook entry zk is selected: q,[ij] = q(zt zt [ij]) := arg min zkZ zt [ij] zk. The decoder Dψ reconstructs the signal ˆut from the quantized latent codes ˆzt q. Both models are jointly trained to minimize the reconstruction error between the function ut and its reconstruction ˆut = Dψ Ew(ut). The codebook is updated using an exponential moving average (EMA) strategy, which stabilizes training and ensures high codebook occupancy. The training objective is: LVQ = ut ˆut2 ut2 + αsg[zt q] Ew(ut)2 2, where the first term is the Relative L2 loss commonly used in PDE modeling, and the second term is the commitment loss, ensuring encoder outputs are close to the codebook entries. The parameter α, set to 0.25, balances the two components. We provide additional details on the architecutre in Appendix C. Once this training step is done, we can tokenize trajectory ut:t+mt by applying our encoder in parallel on each timestamp to obtain discrete codes zt:t+mt and retrieve the corresponding index entries st:t+mt from the codebook Z. Similarly, we detokenize discrete indices with the decoder. 3.2 IN-CONTEXT MODELING We design sequences that enable Zebra to perform in-context learning on trajectories that share underlying dynamics. To incorporate varying amounts of contextual information, we draw number between 1 and nmax, then sample trajectories sharing the same dynamics, each with snapshots starting from time t, denoted as (ut:t+mt ). These trajectories are tokenized into index representations (st:t+mt , . . . , st:t+mt ), which are flattened into sequences s1, . . . , sn, maintaining the temporal order from left to right. In practice, we fix nmax = 6 and = 9. , . . . , ut:t+mt 1 Since our model operates on tokens from codebook, we found it advantageous to introduce special tokens to structure the sequences. The tokens <bot> (beginning of trajectory) and <eot> (end of trajectory) clearly define the boundaries of each trajectory within the sequence. Furthermore, as we sample sequences with varying context sizes, we maximize the utilization of the transformers context window by stacking sequences that could also represent different dynamics. To signal that these sequences should not influence each other, we use the special tokens <bos> (beginning of sequence) and <eos> (end of sequence). The final sequence design is: = <bot>[s1]<eot><bot>[s2]<eot> . . . <bot>[sn]<eot> And our pretraining dataset is structured as follows: <bos>[S1]<eos><bos>[S2]<eos> . . . <bos>[Sl]<eos>"
        },
        {
            "title": "3.3 NEXT-TOKEN PRETRAINING",
            "content": "The transformer is trained using self-supervised learning on next-token prediction task with teacher forcing (Radford et al., 2018). Given sequence of discrete tokens of length , the model is optimized to minimize the negative log-likelihood (cross-entropy loss): LTransformer = ES (cid:88) log p(S[i]S[i<i]), i=1 where the model learns to predict each token S[i] conditioned on all previous tokens S[i<i]. Due to the transformers causal structure, earlier tokens in the sequence are not influenced by later ones, while later tokens benefit from more context, allowing for more accurate predictions. This structure naturally supports both generation in zero-shot and few-shot setting within unified framework. Our transformer implementation is based on the Llama architecture (Touvron et al. (2023)). Additional details can be found in Appendix C. Up to our knowledge, this is the first adaptation of generative auto-regressive transformers to the modeling of physical dynamics. 3. INFERENCE: FLEXIBLE CONDITIONING In this section, we outline the inference pipeline for Zebra across various scenarios. For simplicity, we assume that all observations have already been tokenized and omit the detokenization process. Let represent the target token sequence for which we aim to predict the following timestamps. Temporal conditioning with ℓ frames: structured as = The prompt ], and the transformer generates the subsequent tokens based on this is <bos><bot>[s0:ℓt input. Adaptive conditioning with examples and an initial condition: The prompt is structured ]<eot> . . . <bot>[s0:mt ], allowing the as = <bos><bot>[s0:mt model to adapt based on the provided examples and initial condition. ]<eot><bot>[s0 Adaptive conditioning with examples and ℓ frames: This setup combines constructured as = from multiple trajectories with the initial text <bos><bot>[s0:mt 1 ]<eot> . . . <bot>[s0:mt timestamps, ]<eot><bot>[s0:ℓt ]. At inference, we adjust the temperature parameter τ to calibrate the level of diversity of the nexttoken distributions. The temperature τ scales the logits yi before the softmax function : p(S[i] = kS[i<i]) = softmax (cid:17) (cid:16) yk τ = (cid:1) exp (cid:0) yk exp (cid:0) yj τ τ (cid:80) (cid:1) When τ > 1, the distribution becomes more uniform, encouraging exploration, whereas τ < 1 sharpens the distribution, favoring more deterministic predictions."
        },
        {
            "title": "4 EXPERIMENTS",
            "content": "In this section, we experimentally validate that our framework enables various types of conditioning during inference. As the first model capable of performing in-context learning with an autoregressive transformer for PDEs, Zebra can tackle wide range of tasks that existing frameworks are unable to address without gradient-based adaptation or finetuning. We conduct pretraining as outlined in Section 3 for each dataset described in Section 4.1 and evaluate Zebra on distinct tasks without additional finetuning. We begin by assessing Zebras performance in the challenging oneshot setting, focusing on adaptation methods as the main baselines (Section 4.2). Next, we compare its performance in the more traditional temporal conditioning tasks in Section 4.3. Lastly, we examine the uncertainty quantification enabled by Zebras generative nature and analyze the models generated trajectories in Section 4.4 and Appendix D.1, respectively. 4.1 DATASETS DETAILS As in Kirchmeyer et al. (2022), we generate data in batches where each batch of trajectories shares the same PDE parameters. For each batch or environment, the resulting trajectories sharing the 6 Table 2: Dataset Summary Dataset Name Number of env. Trajectories per env. Main parameters Advection Heat Burgers Wave boundary Combined equation Wave 2D Vorticity 2D 1200 1200 1200 4 1200 1200 10 10 10 3000 10 10 10 Advection speed Diffusion and forcing Diffusion and forcing Boundary conditions α, β, γ Wave celerity and damping Diffusion Table 3: One-shot adaptation. Conditioning from similar trajectory. Test results in relative L2 on the trajectory. indicates inference has diverged. Advection Heat Burgers Wave Combined Wave 2D Vorticity 2D CAPE CODA [CLS] ViT Zebra 0.00941 0.00687 0. 0.00794 0.223 0.546 0.136 0.154 0.213 0.767 0.116 0.115 0.978 1.020 0. 0.245 0.00857 0.0120 0.0446 0.00965 0.777 0.271 0.207 0.678 0. 0.119 same dynamics have different initial conditions. We consider different whole factors of variations across multiple datasets and drastically increase the different number of environments compared to previous studies (Yin et al. (2022), Kirchmeyer et al. (2022)). We conduct experiments across seven datasets: five in 1DAdvection, Heat, Burgers, Wave-b, Combinedand two in 2DWave 2D, Vorticity. These datasets were selected to encompass different physical phenomena and test generalization under changes to various PDE terms, as described below. Varying PDE coefficients The changing factor is the set of coefficients µ in Equation 1. For the Burgers, Heat, and Vorticity 2D equations, the viscosity coefficient ν varies across environments. For Advection, the advection speed β changes. In Wave-c and Wave-2D, the waves celerity is unique to each environment, and the damping coefficient varies across environments in Wave-2D. In the Combined equation, three coefficients (α, β, γ) vary, each influencing different derivative terms respectively: u2 x3 on the right-hand side of Equation 1. x2 , 3u , + 2u In this case, the varying parameter is the boundary condition Varying boundary conditions from Equation 2. For Wave-b, we explore two types of boundary conditionsDirichlet and Neumannapplied independently to each boundary, resulting in four distinct environments. In Burgers Varying forcing term The varying parameter is the forcing term δ in Equation 1. and Heat, the forcing terms vary by the amplitude, frequency, and shift coefficients of δ(t, x) = (cid:80)5 (cid:16) j=1 Aj sin ωjt + 2π lj + ϕj (cid:17) . detailed description of the datasets is provided in Appendix B, and summary of the number of environments used during training, the number of trajectories sharing the same dynamics, and the varying PDE parameters across environments is presented in Table 2. For testing, we evaluate all methods on trajectories with new initial conditions on unseen environments. Specifically, we used 120 new environments for the 2D datasets and 12 for the 1D datasets, with each environment containing 10 trajectories. 4.2 CONTEXT ADAPTATION FROM SIMILAR TRAJECTORIES Setting We evaluate Zebras ability to perform in-context learning by leveraging example trajectories that follow the same underlying dynamics as the target. Formally, in the n-shot adaptation setting, we assume access to set of context trajectories {u0:mt } at inference time, all of which belong to the same dynamical system Fξ. The goal of the adaptation task is to accurately predict future trajectory ut:mt , knowing that the target from new initial condition u0 , . . . , u0:mt 1 7 dynamics is shared with the provided context example trajectories. In this comparison, Zebra is the only model that performs in-context learning from these example trajectories. Sampling For Zebra, we employ random sampling procedure for generating the next tokens for all datasets, setting low temperature (τ = 0.1) to prioritize accuracy over diversity. Predictions are generated using single sample under this configuration. Baselines We evaluate Zebra against CODA (Kirchmeyer et al., 2022) and CAPE (Takamoto et al., 2023). CODA is meta-learning framework designed for learning parametric PDEs. It leverages common knowledge from multiple environments where trajectories from same environment share the same PDE parameter values. CODA training performs adaptation in the parameter space by learning shared parameters across all environments and context vector ce specific to each environment. At the inference stage, CODA adapts to new environment in one-shot manner by only tuning ce with several gradient steps. CAPE is not designed to perform adaptation via extratrajectories, but instead needs the correct parameter values as input to condition neural solver. We adapt it to our setting, by learning context ce instead of using the real parameter values. During adaptation, we only tune this context ce via gradient updates. Additionally, we introduce baseline based on vision transformer (Peebles & Xie, 2023), integrating [CLS] token that serves as learned parameter for each environment. This token lets the model handle different dynamics, and during inference, we adapt the [CLS] vector via gradient updates, following the same approach used in CODA and CAPE. We refer to this baseline as [CLS]ViT. Metrics We evaluate the performance using the Relative L2 norm between the predicted rollout trajectory ˆutrajectory : L2 and the ground truth utrajectory ˆutrajectory (cid:80) 2 . test = 1 Ntest jtest utrajectory utrajectory 2 Results As evidenced in Table 3, Zebra demonstrates strong overall performance in the one-shot adaptation setting, often surpassing baseline methods that have been trained specifically for this task. In more challenging datasets, such as Burgers, Wave-b, and the 2D cases, Zebra consistently achieves lower relative L2 errors, highlighting its capacity to model complex dynamics effectively. Notably, Zebra excels in 2D environments, outperforming both CODA and [CLS]ViT and avoiding the divergence issues encountered by CAPE. While Zebra performs comparably to CODA on simpler datasets like Advection and Combined, its overall stability and versatility across range of scenarios, particularly in 2D settings, highlight its competitiveness. Although there is room for improvement in specific cases, such as the Heat dataset, Zebra stands out as reliable and scalable solution for in-context adaptation for parametric PDEs, offering robust alternative to existing gradient-based methods. We further analyze the influence of the number of context examples on the rollout performance with Zebra, as illustrated in Figure 2. While there is general decreasing trendindicating that more context examples tend to reduce rollout lossthere is still noticeable variance in the results. This suggests that the relationship between the number of context examples and performance is not perfectly linear. We hypothesize that this analysis would benefit from being conducted with more than single sample per trajectory to ensure more robust estimations. Figure 2: Influence of the number of examples. Zebras rollout loss for different number of trajectory examples. The x-axis is the # of context examples and the y-axis is the Relative L2."
        },
        {
            "title": "4.3 TEMPORAL CONDITIONING",
            "content": "Setting We then evaluate the temporal conditioning capabilities of Zebra, i.e. its generalization capabilities when conditioned by the initial states of the target trajectories. Formally, given new trajectory u, we suppose that set of ℓ states u0:(ℓ1)t is already available from the trajectory and we wish to predict the states at the following timestamps uℓt:mt . Baselines We test Zebra against CODA (Kirchmeyer et al., 2022), CAPE (Takamoto et al., 2023) and MPP (McCabe et al., 2023). CODA is designed for adapting neural networks to new environment given an extra-trajectory sampled from this environment. In this setup, we do not have access to extra-trajectories but to the first timestamps of the target trajectory. We thus modify CODA for this setting; the model is adapted with the ℓ first states by learning only ce, and then starts from u(ℓ1)t to predict the rest of the trajectory. We adapt CAPE to that setting too, as done with CODA. MPP is vision transformer conditioned by sequence of frames, using temporal and spatial self-attention blocks to capture spatio-temporal dependencies. MPP does not require additional adaptation at inference and can be used in zero-shot on new trajectories. It is pretrained with fixed number of input frames. For Zebra, we employ the sampling procedure described in Section 4.2. Table 4: Zero-shot prediction from 2 frames. Conditioning from trajectory history with 2 frames as input. Test results in relative L2 on the trajectory. indicates inference has diverged. Advection Heat Burgers Wave Combined Wave 2D Vorticity 2D CAPE CODA MPP[2] MPP[3] Zebra 0.00682 0.00560 0.0075 0.919 0.234 0.378 0.0814 1.0393 0.00631 0. 0.225 0.472 0.100 0.581 0.221 1.10 0.994 1.0393 0.900 0. 0.0125 0.0197 0.0250 0.201 0.0084 0.974 0.285 0.596 0. 0.623 0.101 0.219 0.0874 Results Section 4.3 highlights Zebras strong zero-shot prediction performance using only 2 frames (ℓ = 2) as context, outperforming competing methods across wide range of PDEs. Notably, Zebra excels on both 1D and 2D datasets, delivering consistent and robust results even in complex dynamics like Wave 2D and Vorticity 2D. CAPE and CODA, while competitive in some datasets, either diverge or struggle with accuracy in more challenging scenarios, particularly in 2D problems. MPP trained with two frames (MPP[2]) is overall very strong baseline in this setting; it performs best on Heat and Burgers and obtains good results in the 2D cases. However, if we take model that has been pretrained specifically on three frames (MPP[3]), and test it under this setting, the performance degrades drastically. In contrast, Zebra exhibits high flexibility. It can be used with any number of frames, as long it does not exceed the maximum sequence size seen during training. Furthermore, keeping this setting with two initial frames as inputs, we expose in Figure 3 the gains we could expect on the rollout loss if we had access in addition to the input frames to an example trajectory as described in Section 4.2. We can observe that Zebra consistently improves its accuracy when prompted with an additional example. Most notably, Zebras behaviour goes from random predicition on Wave in zero-shot to more confident predictions thanks to the additional example. Figure 3: Zero-shot vs one-shot performance of Zebra with 2 frames. 4.4 UNCERTAINTY QUANTIFICATION Since Zebra is generative model, it allows us to sample multiple plausible trajectories for the same conditioning input, enabling the computation of key statistics across different generations. By calculating the pointwise mean and standard deviation, we can effectively visualize the models 9 uncertainty in its predictions. In Figure 4, the red curve represents the ground truth, the blue curve is the predicted mean and the blue shading indicates the empirical confidence interval (3 standard deviation). Motivated by this observation, we investigate how varying the models temperature parameter τ affects its predictions; specifically in the one-shot adaptation setting described in Section 4.2. By adjusting τ , we aim to assess its impact on both the accuracy and variability of the predictions. We employ three metrics to evaluate the models uncertainty: 1. Relative L2 loss: This assesses the accuracy of the generated trajectories by measuring the bias of the predictions relative to the ground truth. 2. Relative standard deviation: We estimate the variability of the predictions using the forwhere ˆm and ˆσ represent the empirical mean and standard mula: Relative Std = ˆσ2 ˆm2 deviation of the predictions, computed pointwise across 10 generations. 3. Confidence level: We create pointwise empirical confidence intervals CI(x) = [ ˆm(x) 3ˆσ(x), ˆm(x) + 3ˆσ(x)] as: the Confidence level = 1 1u(x)CI(x). This score indicates how often the ground nx truth falls within the empirical confidence interval generated from sampling multiple trajectories. confidence compute level and (cid:80) When modeling uncertainty, the model achieves traedoff between the quality of the mean prediction approximation and the guarantee for this prediction to be in the corresponding confidence interval. Figure 5 illustrates the trade-off between mean prediction accuracy and uncertainty calibration. At lower temperatures, we achieve the most accurate predictions, but with lower variance, i.e. with no guarantee that the target value is within the confidence interval around the predicted mean. Across most datasets, the confidence level then remains low (less than 80% for τ < 0.25), indicating that the true solutions are not reliably captured within the empirical confidence intervals. Conversely, increasing the temperature results in less accurate mean predictions and higher relative standard deviations, but the confidence intervals become more reliable, with levels exceeding 95% for τ > 0.5. Therefore, the temperature can be calibrated depending on whether the focus is on accurate point estimates or reliable uncertainty bounds. Figure 4: Uncertainty quantification with Zebra in one-shot setting on Heat. Figure 5: Uncertainty quantification with Zebra"
        },
        {
            "title": "5 LIMITATIONS",
            "content": "The quality of the generated trajectories is limited by the decoders ability to reconstruct details from the quantized latent space. While the reconstructions are excellent for many applications, we 10 believe there is room for improvement. Future work could explore scaling the codebook size, as suggested by Yu et al. (2023a) and Mentzer et al. (2023), to enhance the models reconstruction capabilities. Additionally, investigating approaches that avoid vector quantization (Li et al., 2024) could offer even further improvements, provided that in-context learning capabilities are preserved. Lastly, our encoder and decoder are built using convolutional blocks, which restricts their use to regular domains. More flexible architectures, such as those proposed by Serrano et al. (2024), could help extend the model to more complex and irregularly sampled systems."
        },
        {
            "title": "6 CONCLUSION",
            "content": "This study introduces Zebra, novel generative model that adapts language model pretraining techniques for solving parametric PDEs. We propose pretraining strategy that enables Zebra to develop in-context learning capabilities. Our experiments demonstrate that the pretrained model performs competitively against specialized baselines across various scenarios. Additionally, as generative model, Zebra facilitates uncertainty quantification and can generate new trajectories, providing valuable flexibility in applications."
        },
        {
            "title": "7 REPRODUCIBILITY STATEMENT",
            "content": "We describe the pretraining strategy in Section 3, and provide details on the architecture and its hyperparameters in Appendix C. The datasets used are described in Appendix B. We plan to release the code, the weights of the models, and the datasets used in this study."
        },
        {
            "title": "REFERENCES",
            "content": "Akio Arakawa. Computational design for long-term numerical integration of the equaJournal of Comtions of fluid motion: Two-dimensional putational Physics, 1(1):119143, 1966. https://doi.org/10. 1016/0021-9991(66)90015-5. URL https://www.sciencedirect.com/science/ article/pii/0021999166900155. incompressible flow. part ISSN 0021-9991. i. doi: Johannes Brandstetter, Max Welling, and Daniel Worrall. Lie point symmetry data augmentation for neural pde solvers. In International Conference on Machine Learning, pp. 22412256. PMLR, 2022a. Johannes Brandstetter, Daniel Worrall, and Max Welling. Message passing neural pde solvers. International Conference on Learning Representations, 2022b. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners, 2020. Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William Freeman. Maskgit: Masked generative image transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1131511325, 2022. Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary differential equations. Advances in neural information processing systems, 31, 2018. Albert Cohen and Ronald Devore. Approximation of high-dimensional parametric pdes. Acta Numerica, 2015. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recogniInternational Conference on Learning Representations., 10 2021. URL http: tion at scale. //arxiv.org/abs/2010.11929. 11 Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 1287312883, 2021. Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In International conference on machine learning, pp. 11261135. PMLR, 2017. Zhongkai Hao, Chang Su, Songming Liu, Julius Berner, Chengyang Ying, Hang Su, Anima Anandkumar, Jian Song, and Jun Zhu. Dpot: Auto-regressive denoising operator transformer for largescale pde pre-training. 41th International Conference on Machine Learning (ICML 2024), 2024. Maximilian Herde, Bogdan Raonic, Tobias Rohner, Roger Kappeli, Roberto Molinaro, Emmanuel de Bezenac, and Siddhartha Mishra. Poseidon: Efficient foundation models for pdes. 2024. Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David Fleet. Video diffusion models. Advances in Neural Information Processing Systems, 35:8633 8646, 2022. Matthieu Kirchmeyer, Yuan Yin, Jeremie Don`a, Nicolas Baskiotis, Alain Rakotomamonjy, and Patrick Gallinari. Generalizing to new physical systems via context-informed dynamics model. In International Conference on Machine Learning, pp. 1128311301. PMLR, 2022. Tianhong Li, Yonglong Tian, He Li, Mingyang Deng, and Kaiming He. Autoregressive image generation without vector quantization. arXiv preprint arXiv:2406.11838, 2024. Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations. arXiv preprint arXiv:2010.08895, 2020. Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differInternational Conference on Learning Representations., 10 2021. URL ential equations. http://arxiv.org/abs/2010.08895. Michael McCabe, Bruno Regaldo-Saint Blancard, Liam Holden Parker, Ruben Ohana, Miles Cranmer, Alberto Bietti, Michael Eickenberg, Siavash Golkar, Geraud Krawezik, Francois Lanusse, et al. Multiple physics pretraining for physical surrogate models. arXiv preprint arXiv:2310.02994, 2023. Fabian Mentzer, David Minnen, Eirikur Agustsson, and Michael Tschannen. Finite scalar quantization: Vq-vae made simple. International Conference on Learning Representations, 2023. Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. Neural discrete representation learning. arXiv preprint arXiv:1711.00937, 2017. Junyoung Park, Federico Berto, Arec Jamgochian, Mykel Kochenderfer, and Jinkyoo Park. Firstorder context-based adaptation for generalizing to new dynamical systems. 2023. URL https: //openreview.net/forum?id=AW0i0lOhzqJ. William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 41954205, 2023. Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018. Maziar Raissi, Paris Perdikaris, and George Karniadakis. Physics-informed neural networks: deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics, 378:686707, 2019. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. volume 9351, 2015. doi: 10.1007/978-3-319-24574-4 28. Louis Serrano, Thomas Wang, Etienne Le Naour, Jean-Noel Vittaut, and Patrick Gallinari. Aroma: Preserving spatial structure for latent pde modeling with local neural fields. arXiv preprint arXiv:2406.02176, 2024. Shashank Subramanian, Peter Harrington, Kurt Keutzer, Wahid Bhimji, Dmitriy Morozov, Michael Mahoney, and Amir Gholami. Towards foundation models for scientific machine learning: Characterizing scaling and transfer behavior. Advances in Neural Information Processing Systems 37 (NeurIPS 2023), 2023. Makoto Takamoto, Francesco Alesiani, and Mathias Niepert. Learning neural pde solvers with International Conference on Machine Learning (ICML), parameter-guided channel attention. 2023. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. CoRR, 2023. Wolf. Huggingfaces transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771, 2019. Yuan Yin, Ibrahim Ayed, Emmanuel de Bezenac, Nicolas Baskiotis, and Patrick Gallinari. Leads: Learning dynamical systems that generalize across environments. Neural Information Processing Systems, 2022. Lijun Yu, Yong Cheng, Kihyuk Sohn, Jose Lezama, Han Zhang, Huiwen Chang, Alexander Hauptmann, Ming-Hsuan Yang, Yuan Hao, Irfan Essa, et al. Magvit: Masked generative video transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1045910469, 2023a. Lijun Yu, Jose Lezama, Nitesh Gundavarapu, Luca Versari, Kihyuk Sohn, David Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander Hauptmann, et al. Language model beats diffusion tokenizer is key to visual generation. arXiv preprint arXiv:2310.05737, 2023b. Luisa Zintgraf, Kyriacos Shiarli, Vitaly Kurin, Katja Hofmann, and Shimon Whiteson. Fast context adaptation via meta-learning. In International Conference on Machine Learning, pp. 76937702. PMLR, 2019a. Luisa Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, and Shimon Whiteson. Fast context adaptation via meta-learning. 36th International Conference on Machine Learning, ICML 2019, 2019-June, 2019b."
        },
        {
            "title": "A RELATED WORK",
            "content": "A.1 LEARNING PARAMETRIC PDES The classical ML paradigm The classical ML paradigm for solving parametric PDEs consists in sampling from the PDE parameter distribution trajectories to generalize to new PDE parameter values. It is the classical ERM approach. The natural way for generalizing to new PDE parameters is to explicitly embedded them in the neural network (Brandstetter et al., 2022b). Takamoto et al. (2023) proposed channel-attention mechanism to guide neural solvers with the physical coefficients given as input; it requires complete knowledge of the physical system and are not designed for other PDE parameter values, e.g., boundary conditions. It is commonly assumed that prior knowledge are not available, but instead rely on past states of trajectories for inferring the dynamics. Neural solvers and operators learn parametric PDEs by stacking the past states as channel information as done in Li et al. (2021), or by creating additional temporal dimension as done in video prediction contexts (Ho et al., 2022; McCabe et al., 2023). Their performance drops when shifts occur in the data distribution, which is often met with parametric PDEs, as small changes in the PDE parameters can lead to various dynamics. To better generalize to new PDE parameter values, Subramanian et al. (2023) instead leverages fine-tuning from pretrained models to generalize to new PDE parameters. It however often necessitates relatively large number of fine tuning samples to effectively adapt to new PDE parameter values, by updating all or subset of parameters (Herde et al., 2024; Hao et al., 2024). Adaptive conditioning To better adapt to new PDE parameters values at inference, several works have explored meta-learning (also referred to multi-environments learning). During training, limited number of environments are available, each corresponding to specific PDE instance. Yin et al. (2022) proposes LEADS, multi-task framework for learning parametric PDEs, where shared model from all environments and model specific to each environment are learned jointly. At inference, for new PDE instance, the shared model remain frozen and only model specific to that environment is learned. Kirchmeyer et al. (2022) proposes to perform adaptive conditioning in the parameter space; the framework adapts the weights of model to each environment via hypernetwork conditioned by context vector ce specific to each environment. At inference, the model adapts to new environment by only tuning ce. Park et al. (2023) bridges the gap from the classical gradient-based meta-learning approaches by addressing the limitations of second-order optimization of MAML and its variants (Finn et al., 2017; Zintgraf et al., 2019b). A.2 GENERATIVE MODELS Auto-regressive Transformers for Images and Videos Recent works have explored combining language modeling techniques with image and video generation, typically using VQ-VAE (Oord et al., 2017) paired with causal transformer (Esser et al., 2021) or bidirectional transformer (Chang et al., 2022). VQGAN (Esser et al., 2021) has become the leading framework by incorporating perceptual and adversarial losses to improve the visual realism of decoder outputs from quantized latent representations. However, while these methods succeed in generating visually plausible images, they introduce biasdriven by perceptual and adversarial lossesthat leads the network to prioritize perceptual similarity and realism, often causing reconstructions to deviate from the true In contrast, Zebra focuses on maximizing reconstruction accuracy, and did not observe input. benefits from using adversarial or perceptual losses during training. In video generation, models like Magvit (Yu et al., 2023a) and Magvit2 (Yu et al., 2023b) adopt similar strategies, using 3D CNN encoders to compress sequences of video frames into spatiotemporal latent representations by exploiting the structural similarities between successive frames in video. However, such temporal compression is unsuitable for modeling partial differential equations (PDEs), where temporal dynamics can vary significantly between frames depending on the temporal resolution. With Zebra, we spatially compress observations using the encoder and learn the temporal dynamics with an auto-regressive transformer, avoiding temporal compression."
        },
        {
            "title": "B DATASET DETAILS",
            "content": "B.1 ADVECTION We consider 1D advection equation with advection speed parameter β: tu + βxu = 0 For each environment, we sample β with uniform distribution in [0, 4]. We sample 1200 parameters, and 10 trajectories per parameter, constituting training set of 12000 trajectories. At test time, we draw 12 new parameters and evaluate the performance on 10 trajectories each. We fix the size of the domain = 128 and draw initial conditions as described in Equation (5) in appendix B.5 and generate solutions with the method of lines and the pseudo-spectral solver described in Brandstetter et al. (2022b). We take 140 snapshots along 100s long simulations, which we downsample to 14 timestamps for training. We used spatial resolution of 256. B.2 BURGERS We consider the Burgers equation as special case of the combined equation described in Appendix B.5 and initially in Brandstetter et al. (2022b), with fixed γ = 0 and α = 0.5. However, in this setting, we include forcing term δ(t, x) = (cid:80)J j=1 Aj sin(ωjt + 2πℓjx/L + ϕj) that can vary across different environments. We fix = 5, = 16. We draw initial conditions as described in Equation (5). For each environment, we sample β with log-uniform distribution in [1e 3, 5], and sample the forcing term coefficients uniformly: Aj [0.5, 0.5], ωj [0.4, 0.4], ℓj {1, 2, 3}, ϕj [0, 2π]. We create dataset of 1200 environments with 10 trajectories for training, and 12 environments with 10 trajectories for testing. We use the solver from Brandstetter et al. (2022b), and take 250 snapshots along the 4s of the generations. We employ spatial resolution of 256 and downsample the temporal resolution to 25 frames. B.3 HEAT We consider the heat equation as special case of the combined equation described in Appendix B.5 and initially in Brandstetter et al. (2022b), with fixed γ = 0 and α = 0. However, in this setting, we include forcing term δ(t, x) = (cid:80)J j=1 Aj sin(ωjt + 2πℓjx/L + ϕj) that can vary across different environments. We fix = 5, = 16. We draw initial conditions as described in Equation (5). For each environment, we sample β with log-uniform distribution in [1e 3, 5], and sample the forcing term coefficients uniformly: Aj [0.5, 0.5], ωj [0.4, 0.4], ℓj {1, 2, 3}, ϕj [0, 2π]. We create dataset of 1200 environments with 10 trajectories for training, and 12 environments with 10 trajectories for testing. We use the solver from Brandstetter et al. (2022b), and take 250 snapshots along the 4s of the generations. We employ spatial resolution of 256 and downsample the temporal resolution to 25 frames. B.4 WAVE BOUNDARY We consider 1D wave equation as in Brandstetter et al. (2022b). ttu c2xxu = 0, [8, 8] where is the wave velocity (c = 2 in our experiments). We consider Dirichlet B[u] = = 0 and Neumann B[u] = xu = 0 boundary conditions. We consider 4 different environments as each boundary can either respect Neumann or Dirichlet conditions, and sample 3000 trajectories for each environment. This results in 12000 trajectories for 15 training. For the test set, we sample 30 new trajectories from these 4 environments resulting in 120 test trajectories. The initial condition is Gaussian pulse with peak at random location. Numerical ground truth is generated with the solver proposed in Brandstetter et al. (2022b). We obtain ground truth trajectories with resolution (nx, nt) = (256, 250), and downsample the temporal resolution to obtain trajectories of shape (256, 60). B.5 COMBINED EQUATION We used the setting introduced in Brandstetter et al. (2022b), but with the exception that we do not include forcing term. The combined equation is thus described by the following PDE: [tu + x(αu2 βxu + γxxu)](t, x) = δ(t, x), δ(t, x) = 0, u0(x) = (cid:88) j=1 Aj sin(2πℓjx/L + ϕj). (4) (5) For training, we sampled 1200 triplets of parameters uniformly within the ranges α [0, 1], β [0, 0.4], and γ [0, 1]. For each parameter instance, we sample 10 trajectories, resulting in 12000 trajectories for training and 120 trajectories for testing. We used the solver proposed in Brandstetter et al. (2022a) to generate the solutions. The trajectories were generated with spatial resolution of 256 for 10 seconds, along which 140 snapshots are taken. We downsample the temporal resolution to obtain trajectories with shape (256, 14). B.6 VORTICITY We propose 2D turbulence equation. We focus on analyzing the dynamics of the vorticity variable. The vorticity, denoted by ω, is vector field that characterizes the local rotation of fluid elements, defined as ω = u. The vorticity equation is expressed as: ω + (u )ω ν2ω = 0 (6) Here, represents the fluid velocity field, ν is the kinematic viscosity with ν = 1/Re. For the vorticity equation, the parametric problem consists in learning dynamical systems with changes in the viscosity term. For training, we sampled 1200 PDE parameter values in the range ν = [1e 3, 1e 2]. For test, we evaluate our model on 120 new parameters not seen during training in the same paramter range. For each parameter instance, we sample 10 trajectory, resulting in 12000 trajectories for training and 1200 for test. Data generation For the data generation, we use 5 point stencil for the classical central difference scheme of the Laplacian operator. For the Jacobian, we use second order accurate scheme proposed by Arakawa that preserves the energy, enstrophy and skew symmetry (Arakawa, 1966). Finally for solving the Poisson equation, we use Fast Fourier Transform based solver. We discretize periodic domain into 512 512 points for the DNS and uses RK4 solver with = 1e 3 on temporal horizon [0, 2]. We then perform temporal and spatial down-sample operation, thus obtaining trajectories composed of 10 states on 64 64 grid. We consider the following initial conditions: E(k) = π 4 3 (cid:18) k0 (cid:19)4 1 (cid:32) exp (cid:18) k0 (cid:19)2(cid:33) Vorticity is linked to energy by the following equation : ω(k) = (cid:114) E(k) πk 16 (7) (8) B.7 WAVE 2D We propose 2D damped wave equation, defined by 2ω t2 c2ω + ω = 0 (9) where is the wave speed and is the damping coefficient. We are only interested in learning ω. To tackle the parametric problem, we sample 1200 parameters in the range = [0, 50] and = [100, 500]. For validation, we evaluate our model on 120 new parameters not seen during training in the same paramter range. For each parameter instance, we sample 10 trajectory, resulting in 12000 trajectories for training and 1200 for validation. Data generation For the data generation, we consider compact spatial domain Ω represented as 64 64 grid and discretize the Laplacian operator similarly. is implemented using 5 5 discrete Laplace operator in simulation. For boundary conditions, null neumann boundary conditions are imposed. We set = 6.25e 6 and generate trajectories on the temporal horizon [0, 5e 3]. The simulation was integrated using fourth order runge-kutta schema from an initial condition corresponding to sum of gaussians: ω0(x, y) = (cid:88) i=1 (cid:18) exp (x xi)2 + (y yi)2 2σ2 (cid:19) (10) where we choose = 5 gaussians with σi U[0.025,0.1], xi U[0,1], yi U[0.,1]. We fixed to 1 here. Thus, all initial conditions correspond to sum of gaussians of varying amplitudes."
        },
        {
            "title": "C ARCHITECTURE DETAILS",
            "content": "C.1 BASELINE IMPLEMENTATIONS For all baselines, we followed the recommendations given by the authors. We report here the architectures used for each baseline: CODA: For CODA, we implemented U-Net Ronneberger et al. (2015) and FNO (Li et al., 2020) as the neural network decoder. For all the different experiments, we reported in the results the best score among the two backbones used. We trained the different models in the same manner as Zebra, i.e. via teacher forcing (Radford et al., 2018). The model is adapted to each environment using context vector specific to each environment. For the size of the context vector, we followed the authors recommendation and chose context size equals to the number of degrees of freedom used to define each environment for each dataset. At inference, we adapt to new environment using 250 gradient steps. CAPE: For CAPE (Takamoto et al., 2023), we adapted the method to an adaptation setting. Instead of giving true physical coefficients as input, we learn to auto-decode context vector ce as in CODA, which implicitly embeds the specific characteristics of each environment. During inference, we only adapt ce with 250 gradient steps. For the architectures, we use UNET and FNO as the backbones, and reported the best results among the two architectures for all settings. [CLS] ViT: For the ViT, we use simple vision transformer architecture Dosovitskiy et al. (2021), but adapt it to meta-learning setting where the CLS token encodes the specific variations of each environment. At inference, the CLS token is adapted to new environment with 100 gradient steps. MPP: For MPP, we used the same model as the one used in the paper (McCabe et al., 2023). As MPP was initially designed for 2D data, we also implemented 1D version of MPP, to evaluate it both on our 1D and 2D datasets. At inference, MPP can be directly evaluated on new trajectories. C.2 ZEBRA ADDITIONAL GENERATION DETAILS We provide illustrations of our inference pipeline in Figure 6 and in Figure 7 both in the case of adaptive conditioning and temporal conditioning. We also include schematic view of the different 17 generation possibilities with Zebra in Figure 8, using the sequence design adopted during pretraining Figure 6: Zebras inference pipeline from context trajectory. The context trajectory and initial conditions are tokenized into index sequences that are concatenated according to the sequence design adopted during pretraining. The transformer then generates the next tokens to complete the sequence. We detokenize these indices to get back to the physical space. Figure 7: Zebras inference pipeline from observations of several initial frames. The initial timestamps are tokenized into index sequences that are concatenated according to the sequence design adopted during pretraining. The transformer then generates the next tokens to complete the sequence. We detokenize these indices to get back to the physical space. 18 Figure 8: Generation possibilities with Zebra. C.3 AUTO-REGRESSIVE TRANSFORMER Zebras transformer is based on Llamas architecture, which we describe informally in Figure 9. We use the implementation provided by HuggingFace (Wolf, 2019) and the hyperparameters from Table 5 in our experiments. For training the transformer, we used single NVIDIA TITAN RTX for the 1D experiments and used single A100 for training the model on the 2D datasets. Training the transformer on 2D datasets took 20h on single A100 and it took 15h on single RTX for the 1d dataset. 19 Figure 9: Zebras transformer architecture is based on Llama (Touvron et al., 2023). Table 5: Hyperparameters for Zebras Transformer Hyperparameters Advection Heat Burgers Wave Combined Vorticity 2D Wave 2D max context size batch size num gradient accumulations hidden size mlp ratio depth num heads vocabulary size start learning rate weight decay scheduler num epochs 2048 4 1 256 4.0 8 8 264 1e-4 1e-4 Cosine 100 2048 4 1 256 4.0 8 8 264 1e-4 1e-4 Cosine 100 2048 4 1 256 4.0 8 8 264 1e-4 1e-4 Cosine 100 2048 4 1 256 4.0 8 8 264 1e-4 1e-4 Cosine 100 2048 4 1 256 4.0 8 8 264 1e-4 1e-4 Cosine 100 8192 2 4 384 4.0 8 8 2056 1e-4 1e-4 Cosine 8192 2 4 512 4.0 8 8 2056 1e-4 1e-4 Cosine 30 C.4 VQVAE We provide schematic view of the VQVAE framework in Figure 10 and detail the architectures used for the encoder and decoder on the 1D and 2D datasets respectively in Figure 11 and Figure 12. As detailed, we use residual blocks to process latent representations, and downsampling and upsampling block for decreasing / increasing the spatial resolutions. We provide the full details of the hyperparameters used during the experiments in Table 6. For training the VQVAE, we used single NVIDIA TITAN RTX for the 1D experiments and used single V100 for training the model on the 20 2D datasets. Training the encoder-decoder on 2D datasets took 20h on single V100 and it took 4h on single RTX for 1D dataset. Figure 10: Zebras VQVAE is used to obtain compressed and discretized latent representation. By retrieving the codebok index for each discrete representation, we can obtain discrete tokens encoding physical observations that can be mapped back to the physical space with high fidelity. Table 6: Hyperparameters for Zebras VQVAE Hyperparameters Advection Heat Burgers Wave Combined Vorticity 2D Wave 2D start hidden size max hidden size num down blocks codebook size code dim num codebooks shared codebook tokens per frame start learning rate weight decay scheduler num epochs 64 256 4 256 64 2 True 32 3e-4 1e-4 Cosine 1000 64 256 4 256 64 2 True 32 3e-4 1e-4 Cosine 1000 64 256 4 256 64 2 True 32 3e-4 1e-4 Cosine 1000 64 256 4 256 64 2 True 32 3e-4 1e-4 Cosine 1000 64 256 4 256 64 2 True 32 3e-4 1e-4 Cosine 1000 128 1024 2 2048 16 1 True 256 3e-4 1e-4 Cosine 128 1024 3 2048 16 2 True 128 3e-4 1e-4 Cosine 300 21 Figure 11: Architecture of Zebras VQVAE for 1D datasets. Each convolution acts only on the spatial dimension and uses kernel of size 3. The Residual Blocks are used to process information and increase or decrease the channel dimensions, while the Up and Down blocks respectively upsample and down-sample the resolution of the inputs. In 1D, we used spatial compression factor of 16 on all datasets. Every downsampling results in doubling of the number of channels, and likewise, every upsampling is followed by reduction of the number of channels by 2. We choose maximum number of channels of 256. 22 Figure 12: Architecture of Zebras VQVAE for 2D datasets. Each convolution acts only on the spatial dimensions and uses kernel of size 3. The Residual Blocks are used to process information and increase or decrease the channel dimensions, while the Up and Down blocks respectively upsample and down-sample the resolution of the inputs. In 2D, we used spatial compression factor of 4 for Vorticity, and 8 for Wave2D. Every downsampling results in doubling of the number of channels, and likewise, every upsampling is followed by reduction of the number of channels by 2. We choose maximum number of channels of 1024."
        },
        {
            "title": "D ADDITIONAL QUANTITATIVE RESULTS",
            "content": "D.1 ANALYSIS OF THE GENERATION Setting In this section, we aim to evaluate whether our pretrained model can generate new samples given the observation of trajectory in new environment. The key difference with previous settings is that we do not condition the transformer with tokens derived from real initial condition. We expect the model to generate trajectories, including the initial conditions, that altogether follow the same dynamics as in the observations. Our objective is to assess three main aspects: 1) Are the generated trajectories faithful to the context example, i.e., do they follow the same dynamics as those observed in the context ? 2) How diverse are the generated trajectoriesare they significantly different from each other? 3) What type of initial conditions does Zebra generate? Metrics To quantify the first aspect, we propose straightforward methodology. We generate ground truth trajectories using the physical solver that was originally employed to create the dataset, starting with the initial conditions produced by Zebra and using the ground truth parameters of the environment (that Zebra cannot access). We then compute the L2 distance between the Zebragenerated trajectories and those generated by the physical solver. For the second aspect, we calculate the average distance between the Zebra-generated trajectories to measure diversity. These two metrics are presented in Table 7 for both the Advection and Combined Equations. Finally, as qualitative analysis, we perform PCA on the initial conditions generated by Zebra, and we visualize the first two components in Figure 13 for the Combined Equation case. Sampling We keep the default temperature (τ = 1.0) to put the focus on diversity, and for each context trajectory, we generate 10 new trajectories in parallel. Results According to table 7, we can conclude that in this context, Zebra can faithfully generate new initial conditions and initial trajectories that respect the same physics as described in the context example. This means that our model has learned the statistical properties that relate the initial conditions with the later timestamps. The high average L2 between generated samples indicate that the generated samples are diverse. We can visually verify this property by looking at fig. 13, noting that the generated samples cover well the distribution of the real samples. Table 7: Fidelity and diversity - The L2 is proxy score for measuring the fidelity to the dynamics in the context. The average L2 between samples quantifies the distance between each generation. Model L2 Average L2 between samples Advection Combined Equation 0.0185 0.0136 1.57 1."
        },
        {
            "title": "E QUALITATIVE RESULTS",
            "content": "We provide visualizations of the trajectories generated with Zebra under different settings in the following figures: Zero-shot prediction: Figure 15, Figure 19, Figure 24, Figure 27, Figure 30, Figure 36, Figure 42. One-shot prediction: Figure 14, Figure 18, Figure 22, Figure 26, Figure 29, Figure 33, Figure 39. Five-shot prediction: Figure 16, Figure 20, Figure 23, Figure 31. Uncertainty quantification: Figure 17, Figure 21, Figure 25, Figure 28, Figure 25. 24 (a) Analysis of the distribution of the generated initial conditions (t=0). (b) Analysis of the distribution of the generated trajectories (t=9). Figure 13: Qualitative analysis. We generate new initial conditions and obtain rollout trajectories with Zebra on new test environments. We then perform PCA in the physical space to project on low-dimensional space, at two given timestamps to check whether the distributions match. E.1 ADVECTION Figure 14: One-shot adaptation on Advection Figure 15: Zero-shot prediction on Advection 26 Figure 16: Five-shot adaptation on Advection Figure 17: Uncertainty quantification on Advection 28 E.2 BURGERS Figure 18: One-shot adaptation on Burgers Figure 19: Zero-shot prediction on Burgers Figure 20: Five-shot adaptation on burgers 30 Figure 21: Uncertainty quantification on Burgers 31 Figure 22: One-shot adaptation on Heat Figure 23: Five-shot prediction on Heat Figure 24: Zero-shot adaptation on Heat 33 Figure 25: Uncertainty quantification on Heat 34 E.3 HEAT E.4 WAVE BOUNDARY Figure 26: One-shot adaptation on Wave 35 Figure 27: Zero-shot prediction on Wave Figure 28: Uncertainty quantification on Wave E.5 COMBINED EQUATION Figure 29: One-shot adaptation on Combined Figure 30: Zero-shot prediction on Combined 37 Figure 31: Five-shot adaptation on Combined Figure 32: Uncertainty quantification on Combined equation E.6 VORTICITY Figure 33: One-shot adaptation on Vorticity. Example 1. 39 Figure 34: One-shot adaptation on Vorticity. Example 2. Figure 35: One-shot adaptation on Vorticity. Example 3. Figure 36: Zero-shot prediction on Vorticity. Example 1. Figure 37: Zero-shot prediction on Vorticity. Example 2. 40 Figure 38: Zero-shot prediction on Vorticity. Example 3. E.7 WAVE 2D Figure 39: One-shot adaptation on Vorticity. Example 1. Figure 40: One-shot adaptation on Wave2d. Example 2. Figure 41: One-shot adaptation on Wave2d. Example 3. 41 Figure 42: Zero-shot prediction on Wave2d. Example 1. Figure 43: Zero-shot prediction on Wave2d. Example 2. Figure 44: Zero-shot prediction on Wave2d. Example 3."
        }
    ],
    "affiliations": [
        "Criteo AI Lab, Paris, France",
        "Naver Labs Europe, France",
        "Sorbonne Universite, CNRS, ISIR, 75005 Paris, France"
    ]
}