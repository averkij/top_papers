{
    "paper_title": "A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality",
    "authors": [
        "Ishika Agarwal",
        "Zhenlin He",
        "Dhruva Patil",
        "Dilek Hakkani-TÃ¼r"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by ~14 points, general, non-idiomatic translation implicitly improves by ~8 points, and cross-lingual translation abilities (trained on one language, evaluated on another) improves by ~6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding."
        },
        {
            "title": "Start",
            "content": "A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality Ishika Agarwal*1, Zhenlin He*1, Dhruva Patil2, Dilek Hakkani-Tur1 1UIUC, 2Independent ishikaa2, zhenlin5, dilek@illinois.edu, dhruvakpatil@gmail.com 6 2 0 2 9 ] . [ 1 7 0 3 6 0 . 1 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by 14 points1, general, non-idiomatic translation implicitly improves by 8 points, and crosslingual translation abilities (trained on one language, evaluated on another) improves by 6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding. Figure 1: There are three challenges when modeling and translating non-compositional phrases."
        },
        {
            "title": "Introduction",
            "content": "The focus on multilingual language modeling has grown significantly (Adelnia and Dastjerdi, 2011; Cheng and Bhat, 2024; Anonymous, 2025; Wu et al., 2018) because of how accessible LLMs become when they can converse in different languages. However, multilingual language modeling is difficult, due to alignment based problems. Broadly, these problems can be categorized into language specific knowledge where models contain different facts about the same topic in different languages (Agarwal et al., 2025; Jin et al., 2025), non-isomorphic phrases or words that do not have direct translations in other languages (like the word jugaad in Hindi) (Wu et al., 2024a; Meng et al., 2025), and non-compositional phrases whose meaning cannot be derived from individual words) (Zhou and Bhat, 2024). The focus of this work is on improving the translation abilities of noncompositional sentences. *These authors contributed equally to this work. Correspondence to ishikaa2@illinois.edu. 1This is an average improvement across all metrics measuring n-gram similarity and semantic similarity. More details are available in Section 4. Specifically, translating non-compositional phrases poses three challenges, as illustrated in Figure 1. Firstly, their meanings cannot be derived from the individual, constituent 1 words (Zhou et al., 2023). Moreover, they compress historical stories and cultural assumptions, which make their literal translations and intended meanings differ greatly. Second, many idioms do not have semantically equivalent translations: language models tend to paraphrase text during translation, and thus show strong literal translation bias towards non-compositional phrases (Adelnia and Dastjerdi, 2011). These literal decodings erase the idioms figurative intent and leads to incorrect, misleading translations. Third, and finally, non-compositional phrases are highly context dependent and can have different meanings (Fornaciari et al., 2024). These issues result in subpar translation quality, and highlight broader cultural translation gap that current LLMs are not equipped to bridge without specialized training. In this work, we propose to improve the translation quality of language models in the form of training-free solution, and trainingbased solution. The training-free solution is simple, three-step prompting pipeline that encourages the model to think about the cultural context and semantic meaning of an idiom before translating it. The training-based solution uses GRPOstyle fine-tuning to encourage models to translate idioms semantically. In particular, we show the efficacy of using MTQE (Machine Translation Quality Estimation) models, such as COMET (Rei et al., 2020, 2022, 2023), as reward model for fine-tuning LLMS with GRPO (Group Relative Policy Optimization) (Shao et al., 2024). MTQE models are trained on human preference data, which contains implicit signals of non-compositional phrases. We use MTQE rewards as form of distillation to train LLMs for better translation quality. All methods are outlined in Section 3. We use Chinese and Hindi idioms from existing datasets (outlined in Section 3.1) to evaluate our methods. We evaluate on small language models (Qwens 3B model and Llamas 8B model) to show that we can improve small language models for cheap and accessible translation. We measure translation quality across various dimensions of semantic and n-gram based similarity, and find that by using MTQE rewards during GRPO fine-tuning on idiomatic data: 1. Idiomatic translation quality improves by 14 points (Figures 3 and 4), 2. Non-idiomatic, general, translation quality improves by 8 points (Figures 5 and 6), and 3. Cross-lingual semantic representation (idiom training in one language transfers to another) improves by 6 points (Figures 7 and 8)."
        },
        {
            "title": "2 Background",
            "content": "2.1 MTQE Models MTQE models estimate the quality of machine translated text (Rei et al., 2020). There are two kinds: reference-free and reference-based (Rei et al., 2022, 2023). Reference-free models are given source text and translated text as input. Their output is scalar score between 0 to 1 that indicates the semantic equivalence between the source and translation (the closer it is to 1, the stronger the semantic equivalence) (Zhao et al., 2024). Thus, during training, sentences that are semantically closer will output higher scores and those that are semantically less equivalent will receive lower scores. Reference-based models, on the other hand, are given source text, translated text, and reference text. Their output is also scalar between 0 to 1, and also indicate the semantic equivalence between source, translation, and reference. They rely on gold standard, humanannotated references off of which to base the numerical MTQE scores. During training, the model learns to output direct assessment scores to the given source, translated, and reference text (Rei et al., 2022). We posit that due to MTQE models being trained on parallelly translated and/or human annotated data, they autonomously learn how to model non-compositional language. We can use such models as form of weak distillation to teach models to translate non-compositional language effectively. 2.2 Idiom Translation Idiom and proverb detection and generation have been studied extensively in literature (Cheng and Bhat, 2024; Lai and Nissim, 2024). 2 Some works focus on detection and generation (Wu et al., 2024b; Zhou et al., 2023; He et al., 2024; De Luca Fornaciari et al., 2024), while others work on creating high-quality curated datasets (Zeng et al., 2023; Rezaeimanesh et al., 2024; Tedeschi et al., 2022; Haagsma et al., 2020). While detection and generation abilities are still improving, translation remains problem (Cheng and Bhat, 2024). Sources show that while proprietary, closed-source language models are able to translate idioms well, opensource language models have not yet reached SOTA results (Obeidat et al., 2024). Kim et al. (2025) suggests language models do indeed know the semantic meaning behind idioms, they just need to be extracted properly. Previous work has mostly used prompting methods (Gao et al., 2025; Rafatbakhsh et al., 2021). Rather than default to translating literal meanings (Rezaeimanesh et al., 2024), language models must be fine-tuned for translating semantic meanings behind idioms. Recent literature suggests that reinforcement learning can sharpen output distributions towards specific task (Yue et al., 2025). We borrow this finding and use GRPO to improve language models ability to translate non-compositional language. 3 Improving Non-Compositional Translation 3.1 Dataset Creation Our evaluation spans two languages: Chinese and Hindi. We release our datasets, along with all of our code here. The same training and testing splits are used for all baselines, which allows for direct comparison between all methods. Chinese. We use the PETCI dataset (Tang, 2022) for ChineseEnglish idiom translation. We first run preprocessing script on the original release that trims stray whitespace and removes rows where either the Chinese idiom or the English translation is empty, contains only whitespace, or is marked as missing. After cleaning 4,310 sentences in the original dataset, we obtain 1,623 valid idiomtranslation pairs. We use 1,000 for training and 623 for testing. idioms from the OPUS OpenSubtitles corpus (Zhang et al., 2020) with additional highquality synthetic pairs generated using GPT5. We filter this collection by removing duplicates, discarding entries with incomplete or overly literal translations, and manually validating idioms that appear ambiguous or context-dependent. After cleaning, we select 1,000 valid HindiEnglish idiom pairs, which we split deterministically into 800 training examples and 200 test examples. 3.2 Training-Based We explore using GRPO (Shao et al., 2024) for fine-tuning models to improve an LLMs translation abilities. In particular, the reward model is an MTQE model, and the LLM is rewarded based on how effective translations are based on the ground truth. As mentioned before, there are two kinds of MTQE models: reference-free and reference-based. Within these variations, we contrive different settings for rewards (see Figure 2): 1. QE-Positive. QE models take in as input the source text (src) and the maIn this setchine translated text (mt). ting, src is the input idiom in different language, and mt is the LLM generated translation during training. This reward encourages LLMs to generate translations that are semantically equivalent to the original input idiom. We denote this as QEpos(idiom, mt). 2. QE-Negative. Here, src is the literal meaning of the idiom (in English) and mt is, again, the generated translation during training. Note: both src and mt are in English in this setting. This is creative misuse of MTQE. Although it is expected to have crosslingual outputs, it is ultimately semantic similarity metric. In this case, we apply negative reward for the MTQE between src and mt, encouraging the LLM to generate translations that are not semantically equivalent to the literal translations. We denote this as QEneg(literal, mt). Hindi. We compile dataset from multiple sources, combining mined HindiEnglish 3. QE-Constrained. The issue in the QEPositive setting is that bad translations do 3 (a) (b) (c) (d) Figure 2: Illustration of the distinction between all three GRPO-QE-* methods. (a) QE-Positive pulls semantically equivalent texts closer. (b) QE-Negative pulls semantically inequivalent texts apart. (c) QE-Constrained balances both. (d) QE-DA uses ground-truth reference translation to inform MTQE. not get discouraged. The issue in the QENegative setting is that some idioms can be correctly literally translated in another language (for example: plenty of fish in the sea in English and Hay mas peces en el mar in Spanish are correct, literal translations of each other). To bridge these gaps, we test third setting. We simply assign the joint reward: QEpos(idiom, mt) QEneg(literal, mt). This helps encourage the LLM to semantically translate the idiom, and discourage the LLM to literally translate. 3. Natural Idiomatic Translation. Given both and L, the model produces single fluent English expression that captures the idiomatic sense (prompt in Figure 11, Appendix A). Unlike decoding-based reranking or reinforcement learning, this method introduces no additional optimization, instead relies entirely on prompt engineering and explicit reasoning decomposition. This structured prompting approach aims to mitigate the literalism observed in the raw model. 4. QE-DA. This setting follows the QEPositive setup, where src is the source idiom, and mt is the machine translated idiom, but it also receives ref, which is the ground truth translated idiom. This reward will encourage models to translate idioms towards specific target translation. 3.3 Training-Free Structured Prompting We also develop training-free idiom translation method designed to reduce literaltranslation bias with just prompt engineering. The core idea is to dissect idiom translation into three explicit reasoning stages: 1. Idiomatic Explanation. The model explains the idioms figurative meaning in English, emphasizing cultural meaning over surface semantics, denoted by (prompt in Figure 9, Appendix A). 2. Literal Semantics. The model provides word-by-word literal translation of the idiom, yielding L, which helps to disentangle literal and figurative interpretations (prompt in Figure 10, Appendix A)."
        },
        {
            "title": "4 Experiments",
            "content": "4.1 Setup (1) use Qwen/Qwen2.5-3B efficacy of our Models. To show the language small method, we two (shortmodels: hand: Qwen) (Yang et al., 2025), and (2) meta-llama/Llama-3.1-8B (shorthand: Llama) (Grattafiori et al., 2024). We employ small LMs to showcase the efficacy of our method compared to larger LMs. For all model inference, we use temperature of 0.3. For SFT, we train models for 3 epochs. For GRPO, we use the verl library (Sheng et al., 2024), with 4 completions per group, and 5 epochs. All other settings can be found in our Github repository. Metrics. Our evaluation contains variety of metrics to test different aspects of the translation quality. First off, we report the scores of the same MTQE models that we use as reward models for GRPO, to show the final reward of the tuned models. DA are the Direct Assessment scores (specifically, the Unbabel/wmt22-comet-da model), and QE are the Quality Estimation scores (specifically, the Unbabel/wmt22-cometkiwi-da model). 4 Figure 3: Evaluation of translation abilities of Chinese idioms. Here, we see that the LIA and TrainingFree (TF) baselines do well on Qwen-2.5-3B, but not on Llama-3.1-8B (hence is unreliable). The GRPO based methods are not only performant, but also reliable. We evaluate the n-gram similarity between the predicted translation and the ground truth translation with ROUGE. However, ROUGE is too rigid metric that measures the n-gram overlap ration and does not measure for semantic similarity hence, we also use embedding models to embed the semantic similarity of the predicted translation and ground truth translation; we, then, report the cosine distance between these embeddings (i.e., Embedding Distance). Finally, to make our evaluation comprehensive, we employ an LLM-as-a-Judge (abbreviated to LAJ) to score the semantic similarity between the predicted and ground truth translation. The particular LLM-as-aJudge we use is the Prometheus-7v-V2.0 model (Kim et al., 2024). Baselines We employ variety of baseline methods. First, we use core translation models: sequence-to-sequence (NLLB (Team et al., 2022)) and autoregressive (Command-R (Cohere et al., 2025)). To compare our trainingfree method, we use the LIA (Language Model Based Idiom Alignment) (Donthi et al., 2025)2. To compare our training-based method, we fine-tune models using supervised fine-tuning (SFT) using cross-entropy loss. 2The same paper also proposes SIA (Semantic Idiom Alignment), but their setting requires an external database of idioms to retrieve from, which is then fed into SIA to select highly matching translations. We do not choose to compare against this particular baseline as we do not assume access to an external database. Non-Idiomatic Performance In order to ensure our idiom-specific methods (especially, the training-based) do not deteriorate in translating non-idiomatic text, we measure the performance of our methods on non-idiomatic text translation. We use the same metrics as mentioned above, and we employ the Opus-100 (Zhang et al., 2020) dataset. This dataset contains pairs of source and machine translated text pairs. We use the en-zh and en-hi pairs from the dataset, and use 400 randomly selected data points from the test splits of the Opus dataset for our evaluation. 4.2 Results and Analysis Idiom Translation. Figures 3 and 4 contain the evaluation results on Chinese and Hindi idioms, respectively. The NLLB and CommandR models tend to be better at the Qwen and Llama base models (they score an average of 2.91 (Qwen) and 5.03 (Llama) points3 higher for Chinese translation, and 4.80 (Qwen) and 6.48 (Llama) points higher for Hindi translation. Still, the results show that training3To aggregate these metrics into one reportable score, we take the average of all 5 metrics: DA, QE, ROUGE, Embedding Distance and LAJ. The first four are on the same scale, while LAJ is on scale of 1-5. To calibrate them all on the same scale, we multiply the LAJ score by 20. Thus, to calculate the performance of particular method, we use the following formula: = (DA+QE+ROUGE+EmbeddingDistance+20LAJ)/5. To find the difference in performance between baseline and method B, we calculate pA pB. 5 Figure 4: Evaluation of translation abilities of Hindi idioms. Here, we see that the core translation models (NLLB and Command-R) translate Hindi idioms well, but nChinese idioms  (Fig. 3)  . The GRPO based methods are not only performant, but also reliable. free/-based methods can improve flexible language models so they can perform on-par with translation models that have dedicated machine translation or parallelly translated datasets4. Comparing the training-free methods (LIA and TrainingFree (denoted by TF in the figures)), we see that Qwen performs better with LIA (LIA is 1.65 points better than TrainingFree), while Llama performs better with TrainingFree (it is 2.18 points better than LIA). These inconsistent results show that prompting is not reliable method, motivating the need for fine-tuning. Supervised fine-tuning the models consistently cause models to perform worse than even the base models this is because the models are being trained for outputting particular sentences, rather than understanding semantic meaning of sentences. Thus, using RL is our final approach, which significantly outperforms the base and SFT models: The QE-Positive models outperform the base and SFT models by 13.23 and 18.80 points, respectively; the QENegative models outperform them by 13.20 and 18.77 points, respectively; the QE-Constrained models outperform them by 13.64 and 19.22 points, respectively; finally, the QE-DA models 4According to the model cards (Yang et al., 2025; Grattafiori et al., 2024), the training sets have multilingual data, but the data is not necessarily parallelly translated in other language. These multilingual data are generally for multilingual question-answering, reasoning, and knowledge tasks. outperform them by 14.60 and 20.18 points, respectively. Overall, the RL models bring an absolute point improvement of 13.67 points in idiom-translation ability. Performance on non-idiomatic sentence translation. Figures 5 and 6 show the results of translation abilities of non-idiomatic text translation in Chinese and Hindi respectively. These tables show that the performance on general, mostly non-idiomatic text translation not only maintains, but also improves with the GRPO models, compared to base (average of 8.39 points) and SFT (average of 25.07 points). Of course, the translation models are better performing (the best translation model is 7.90 points better than the best GRPO model). We hypothesize that the GRPO-tuned language models have improved semantic representation across languages, so they could ultimately outperform the translation models on reasoning, knowledge, and question-answering tasks. Effects of language-specific training. Figures 7 and 8 contain the evaluation results for the transfer settings. Comparing the results from Figures 4 and 8 versus Figures 3 and 7, there do exist significant transferability capabilities between the trained models. In particular, models trained on Chinese idioms but evaluated on Hindi idioms perform 8.04(Qwen)/15.73(Llama) points better Figure 5: Evaluation of translation abilities of regular Chinese sentences. Here, it is shown that performance does not deteriorate when models are trained on idiomatic data. Figure 6: Evaluation of translation abilities of regular Hindi sentences. Here, it shows that performance does not deteriorate when models are trained on idiomatic data. than base models and 0.38(Qwen)/1.81(Llama) points better than models trained on Hindi idioms. On the contrary, models trained on Hindi idioms but evaluated on Chinese idioms perform 7.73(Qwen)/12.70(Llama) points better than base models, Qwen performs -1.31 worse than models trained on Chinese, and Llama performs 0.76 points better. The overall boost of 8.62 absolute points in translation improvement shows that training on one language does not hinder the performance on other languages. Effect of reward model. Even though we had broken down the rewards into four, there are no noticeable effects of each reward. This is encouraging because they all have different kinds of supervision. QE-Positive requires just an input idiom, which can be extracted from large corpora with idiom detectors. QE-Negative and QE-Constrained requires source and literal translation, which might be bit expensive to get. Although, costs can be avoided by using small enough language model that reliably generates literal translations. QE-DA, however, is the most expensive as it requires ground truth translation of idioms obtaining this is expensive, as it necessitates annotation from either humans or closed-source large language models. Since the least expensive reward QE-Positive Figure 7: Evaluation of Hindi-trained models translating Chinese idioms. Per Fig. 3, Qwen-2.5-3B achieved DA: 42.89, QE: 37.09, ROUGE: 8.04, ED: 50.76, LAJ: 1.79; Llama-3.1-8B achieved DA: 40.67, QE: 37.05, ROUGE: 7.16, ED: 45.94, LAJ: 1.66. GRPO models outperform base models. Figure 8: Evaluation of Chinese-trained models translating Hindi idioms. Per Fig. 4, Qwen-2.5-3B achieved DA: 46.08, QE: 48.92, ROUGE: 5.28, ED: 44.16, LAJ: 1.95; Llama-3.1-8B achieved DA: 43.87, QE: 47.31, ROUGE: 4.80, ED: 48.65, LAJ: 1.52. GRPO methods outperform base models. does not lag far behind the most accurate reward QE-DA, we are able to showcase the robustness of using MTQE rewards."
        },
        {
            "title": "5 Conclusion",
            "content": "In this work, we explore structured approaches to improving non-compositional language translation. As our main contribution, we present GRPO-based fine-tuning using MTQE models as reward models. Our experimentation uncovers three results: (1) idiom translation abilities increase by an average of 13.67 absolute points over base models across languages and architectures, (2) non-idiomatic translation abilities are implicitly improved by 8.39 absolute points, and (3) cross-lingual translation abilities are also improved by 5.73 absolute points. These results show that MTQE rewards effectively distill their multilingual language embedding capabilities to language models: they improve semantic relationships in multilingual language models, are reliable to not compromise current language model abilities, and enables models to generalize to other languages meaningfully. These results encourage future work to understanding the complementary nature of mapping semantics in various languages for improving multilingual language modeling."
        },
        {
            "title": "6 Limitations",
            "content": "While MTQE models can handle broad variety of languages and have shown to be aligned with human preferences, our method is upperbounded by the performance of MTQE models the GRPO-trained translation models can only be as good as the MTQE models are. Plus, MTQE models also require many parallel data to be trained. Furthermore, RL is an expensive algorithm in general even after choosing small model sizes and small datasets, 8 training took around 6-12 hours to train on 4 NVIDIA H100s, which is not accessible. Future work involves understanding how to reduce the computational cost to train better multilingual models."
        },
        {
            "title": "References",
            "content": "Amineh Adelnia and Hossein Vahid Dastjerdi. 2011. Translation of idioms: hard task for the translator. Theory and practice in language studies, 1(7):879883. Ishika Agarwal, Nimet Beyza Bozdag, and Dilek Hakkani-Tur. 2025. Language specific knowledge: Do models know better in than in english? Preprint, arXiv:2505.14990. Anonymous. 2025. Fine-grained reward optimization for machine translation. arXiv preprint. Kellen Cheng and Suma Bhat. 2024. No context needed: Contextual quandary in idiomatic reasoning with pre-trained language models. Association for Computational Linguistics. Team Cohere, Aakanksha, Arash Ahmadian, Marwan Ahmed, Jay Alammar, Yazeed Alnumay, Sophia Althammer, Arkady Arkhangorodsky, Viraat Aryabumi, Dennis Aumiller, Raphael Avalos, Zahara Aviv, Sammie Bae, Saurabh Baji, Alexandre Barbet, Max Bartolo, Bjorn Bebensee, Neeral Beladia, Walter Beller-Morales, and 207 others. 2025. Command a: An enterprise-ready large language model. Preprint, arXiv:2504.00698. Francesca De Luca Fornaciari, Begona Altuna, Itziar Gonzalez-Dios, and Maite Melero. 2024. hard nut to crack: Idiom detection with conversational large language models. In Proceedings of the 4th Workshop on Figurative Language Processing (FigLang 2024), pages 3544, Mexico City, Mexico (Hybrid). Association for Computational Linguistics. Sundesh Donthi, Maximilian Spencer, Om Patel, Joon Doh, Eid Rodan, Kevin Zhu, and Sean OBrien. 2025. Improving llm abilities in idiomatic translation. Preprint, arXiv:2407.03518. Francesca De Luca Fornaciari, Begona Altuna, Itziar Gonzalez-Dios, and Maite Melero. 2024. hard nut to crack: Idiom detection with conversational large language models. Preprint, arXiv:2405.10579. Hui Gao, Jing Zhang, Peng Zhang, and Chang Yang. 2025. Consistency rating of semantic transparency: an evaluation method for metaphor competence in idiom understanding tasks. In Proceedings of the 31st International Conference on Computational Linguistics, pages 10460 10471, Abu Dhabi, UAE. Association for Computational Linguistics. Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, and 542 others. 2024. The llama 3 herd of models. Preprint, arXiv:2407.21783. Hessel Haagsma, Johan Bos, and Malvina Nissim. 2020. MAGPIE: large corpus of potentially idiomatic expressions. In Proceedings of the 12th Language Resources and Evaluation Conference, pages 279287, Marseille, France. European Language Resources Association. Wei He, Marco Idiart, Carolina Scarton, and Aline Villavicencio. 2024. Enhancing idiomatic representation in multiple languages via an adaptive contrastive triplet loss. Preprint, arXiv:2406.15175. Zhijing Jin, Max Kleiman-Weiner, Giorgio Piatti, Sydney Levine, Jiarui Liu, Fernando Gonzalez, Francesco Ortu, Andras Strausz, Mrinmaya Sachan, Rada Mihalcea, Yejin Choi, and Bernhard Scholkopf. 2025. Language model alignment in multilingual trolley problems. Preprint, arXiv:2407.02273. Jisu Kim, Youngwoo Shin, Uiji Hwang, Jihun Choi, Richeng Xuan, and Taeuk Kim. 2025. Memorization or reasoning? exploring the idiom understanding of LLMs. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pages 2168921710, Suzhou, China. Association for Computational Linguistics. Seungone Kim, Juyoung Suk, Shayne Longpre, Bill Yuchen Lin, Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, and Minjoon Seo. 2024. Prometheus 2: An open source language model specialized in evaluating other language models. Preprint, arXiv:2405.01535. Huiyuan Lai and Malvina Nissim. 2024. survey on automatic generation of figurative language: From rule-based systems to large language models. ACM Computing Surveys, 56(10):134. Lei Meng, Yinlin Li, Wei Wei, and Caipei Yang. 2025. Resolving linguistic asymmetry: Forging symmetric multilingual embeddings through asymmetric contrastive and curriculum learning. Symmetry, 17(9):1386. Mohammed Obeidat, Ahmad Haider, Sausan Abu Tair, and Yousef Sahari. 2024. Analyzing the performance of gemini, chatgpt, and google translate in rendering english idioms into arabic. FWU Journal of Social Sciences, 18(4). 9 Elaheh Rafatbakhsh, Alireza Ahmadi, Amirsaeid Moloodi, and Saeed Mehrpour. 2021. Development and validation of an automatic item generation system for english idioms. Educational Measurement: Issues and Practice, 40(2):4959. Ricardo Rei, Jose G. C. de Souza, Duarte Alves, Chrysoula Zerva, Ana Farinha, Taisiya Glushkova, Alon Lavie, Luisa Coheur, and Andre F. T. Martins. 2022. COMET-22: Unbabel-IST 2022 submission for the metrics shared task. In Proceedings of the Seventh Conference on Machine Translation (WMT), pages 578585, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. Ricardo Rei, Ana Farinha, and Alon Lavie. 2020. Comet: neural framework for mt evaluation. arXiv preprint arXiv:2009.09025. Ricardo Rei, Nuno M. Guerreiro, Jose Pombal, Daan van Stigt, Marcos Treviso, Luisa Coheur, Jose G. C. de Souza, and Andre F. T. Martins. 2023. Scaling up cometkiwi: Unbabel-ist 2023 submission for the quality estimation shared task. Preprint, arXiv:2309.11925. Mohammad Rezaeimanesh and 1 others. 2024. Large language models for persianenglish idiom translation. arXiv preprint arXiv:2401.04840. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. 2024. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. Preprint, arXiv:2402.03300. Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu. 2024. Hybridflow: flexible and efficient rlhf framework. arXiv preprint arXiv: 2409.19256. Kenan Tang. 2022. Petci: parallel english translation dataset of chinese idioms. arXiv preprint arXiv:2202.09509. NLLB Team, Marta R. Costa-juss`a, James Cross, Onur elebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, and 20 others. 2022. No language left behind: Scaling human-centered machine translation. Preprint, arXiv:2207.04672. Simone Tedeschi, Federico Martelli, and Roberto Navigli. 2022. Id10m: Idiom identification in 10 languages. In Findings of the Association for Computational linguistics: NAACL 2022, pages 27152726. Di Wu, Yibin Lei, Andrew Yates, and Christof Monz. 2024a. Representational isomorphism and alignment of multilingual large language models. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 1407414085. Lijun Wu, Yingce Xia, Fei Tian, Tao Qin, Jue Lai, and Tie-Yan Liu. 2018. study of reinforcement learning for neural machine translation. arXiv preprint arXiv:1808.08866. Mingmin Wu, Guixin Su, Yongcheng Zhang, Zhongqiang Huang, and Ying Sha. 2024b. Refining idioms semantics comprehension via contrastive learning and cross-attention. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 1378513795. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, and 41 others. 2025. Qwen3 technical report. Preprint, arXiv:2505.09388. Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, and Gao Huang. 2025. Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model? Preprint, arXiv:2504.13837. Ziheng Zeng, Kellen Tan Cheng, Srihari Venkat Nanniyur, Jianing Zhou, and Suma Bhat. 2023. Iekg: commonsense knowledge graph for idiomatic expressions. Preprint, arXiv:2312.06053. Biao Zhang, Philip Williams, Ivan Titov, and Rico Sennrich. 2020. Improving massively multilingual neural machine translation and zero-shot translation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 16281639, Online. Association for Computational Linguistics. Haofei Zhao, Yilun Liu, Shimin Tao, Weibin Meng, Yimeng Chen, Xiang Geng, Chang Su, Min Zhang, and Hao Yang. 2024. From handcrafted features to llms: brief survey for machine translation quality estimation. Preprint, arXiv:2403.14118. Jianing Zhou and Suma Bhat. 2024. Noncompositional expression generation and its continual learning. In Findings of the Association for Computational Linguistics ACL 2024, pages 28282839. Jianing Zhou, Ziheng Zeng, Hongyu Gong, and Suma Bhat. 2023. Non-compositional expression generation based on curriculum learning and continual learning. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 43204335."
        },
        {
            "title": "A Prompts",
            "content": "Tables 9, 10, and 11 contain the prompts for the TrainingFree method described in Section 3.2."
        },
        {
            "title": "B Licenses",
            "content": "All datasets are publicly available and do not contain any personally identifiable information. The PETCI dataset is under the Creative Commons 4.0 license, the Open Subtitles dataset is under the GNU General Public License, the NLLB and Command-R models are under the Creative Commons Attribution Non Commercial 4.0 license, the Qwen model is under the Apache 2.0 license, and the Llama model is under the Llama license."
        },
        {
            "title": "C Human Annotators",
            "content": "In creating the dataset, we used human annotators to verify the validity of the dataset. The authors of this paper were appropriate enough to create this dataset as they knew either Chinese or Hindi, and they were unbiased in their dataset verification process. We wrote up guidelines to make sure the idiomatic data was not too literal or overly ambiguous of whether it had figurative or literal meaning."
        },
        {
            "title": "D Usage of AI Assistants",
            "content": "There were only two things AI Assistants were used for: (1) writing code for plotting figures (after processing the data ourselves, we described to ChatGPT the format of the figures that we wanted and asked it how to add color scheme), and (2) revising small chunks of text like the title, the abstract, and caption figures (we had already written the title and abstract, but we instructed Claude to refine the writing by making it clearer and shorter). No AI Assistants were used for any of the other tasks: paper writing, code writing, results analysis, or ideation (or even, this section). 11 Idiomatic Explanation Prompt Explain the meaning of the following {lang} idiom in English. - Audience: educated readers; be concise (= 2 sentences). - Do not translate word-by-word; provide the **idiomatic sense**. Idiom: {idiom} Figure 9: Prompt to elicit Idiomatic Explanation, which is Step 1 in our training-free, structured prompting approach outlined in section 3.3. Literal Semantics Prompt Provide **literal, word-by-word** English translation for the following {lang} idiom. - Keep it terse and faithful to each component. - No commentary, just the literal gloss. Idiom: {idiom} Figure 10: Prompt to elicit Literal Semantics, which is Step 2 in our training-free, structured prompting approach outlined in section 3.3. Natural Idiomatic Translation Prompt Produce **natural English idiomatic translation** given: (1) An idiom explanation (idiomatic meaning) and (2) literal word-by-word gloss. Rules: - Output single short English phrase/sentence that native speaker would actually say. - Prefer clarity and naturalness over literalness. - No extra commentary. Idiom: {idiom} Explanation: {explanation} Literal: {literal} Result: Figure 11: Prompt to elicit Natural Idiomatic Translation, which is Step 2 in our training-free, structured prompting approach outlined in section 3.3."
        }
    ],
    "affiliations": [
        "UIUC"
    ]
}