{
    "paper_title": "ChemDFM-R: An Chemical Reasoner LLM Enhanced with Atomized Chemical Knowledge",
    "authors": [
        "Zihan Zhao",
        "Bo Chen",
        "Ziping Wan",
        "Lu Chen",
        "Xuanze Lin",
        "Shiyang Yu",
        "Situo Zhang",
        "Da Ma",
        "Zichen Zhu",
        "Danyang Zhang",
        "Huayang Wang",
        "Zhongyang Dai",
        "Liyang Wen",
        "Xin Chen",
        "Kai Yu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "While large language models (LLMs) have achieved impressive progress, their application in scientific domains such as chemistry remains hindered by shallow domain understanding and limited reasoning capabilities. In this work, we focus on the specific field of chemistry and develop a Chemical Reasoner LLM, ChemDFM-R. We first construct a comprehensive dataset of atomized knowledge points to enhance the model's understanding of the fundamental principles and logical structure of chemistry. Then, we propose a mix-sourced distillation strategy that integrates expert-curated knowledge with general-domain reasoning skills, followed by domain-specific reinforcement learning to enhance chemical reasoning. Experiments on diverse chemical benchmarks demonstrate that ChemDFM-R achieves state-of-the-art performance while providing interpretable, rationale-driven outputs. Further case studies illustrate how explicit reasoning chains significantly improve the reliability, transparency, and practical utility of the model in real-world human-AI collaboration scenarios."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 2 ] . [ 1 0 9 9 1 2 . 7 0 5 2 : r ChemDFM-R: An Chemical Reasoner LLM Enhanced with Atomized Chemical Knowledge Zihan Zhao1,3 Bo Chen2 Ziping Wan2 Lu Chen1,2,3 Xuanze Lin4 Shiyang Yu1,3 Situo Zhang1,3 Da Ma1,3 Zichen Zhu1,3 Danyang Zhang1,3 Huayang Wang1,3 Zhongyang Dai2 Liyang Wen2 Xin Chen2 Kai Yu1,2,3 1X-LANCE Lab, School of Computer Science MoE Key Lab of Artificial Intelligence, SJTU AI Institute Shanghai Jiao Tong University, Shanghai 200240, China 2Suzhou Laboratory, Suzhou, China 3Jiangsu Key Lab of Language Computing, Suzhou 215123, China 4School of Chemistry and Chemical Engineering Shanghai Jiao Tong University, Shanghai 200240, China {zhao_mengxin, chenlusz, kai.yu}@sjtu.edu.cn"
        },
        {
            "title": "Abstract",
            "content": "While large language models (LLMs) have achieved impressive progress, their application in scientific domains such as chemistry remains hindered by shallow domain understanding and limited reasoning capabilities. In this work, we focus on the specific field of chemistry and develop Chemical Reasoner LLM, ChemDFM-R1. We first construct comprehensive dataset of atomized knowledge points to enhance the models understanding of the fundamental principles and logical structure of chemistry. Then, we propose mix-sourced distillation strategy that integrates expert-curated knowledge with general-domain reasoning skills, followed by domain-specific reinforcement learning to enhance chemical reasoning. Experiments on diverse chemical benchmarks demonstrate that ChemDFM-R achieves state-of-the-art performance while providing interpretable, rationale-driven outputs. Further case studies illustrate how explicit reasoning chains significantly improve the reliability, transparency, and practical utility of the model in real-world human-AI collaboration scenarios."
        },
        {
            "title": "Introduction",
            "content": "With the remarkable capabilities and performance demonstrated by large language models (LLMs) [Brown et al., 2020, Achiam et al., 2023, Team et al., 2023], the development of domainspecialized LLMs has emerged as popular approach to addressing complex problems [Hendrycks et al., 2020, Chen et al., 2021, Wang et al., 2024]. Specifically, in the scientific domain, many efforts focus on specializing LLMs for specific tasks [Yu et al., 2024, Antunes et al., 2024, Sriram et al., 2024] or building general-purpose scientific assistants [Zhao et al., 2025b, Zhang et al., 2024a, Zhao et al., 2024, Zhang et al., 2025b, Tan et al., 2025]. However, given the inherent complexity and high demand for reliability in the scientific domain, current models often struggle with inadequate performance and limited interpretability, which significantly hinders their practical applicability. Recently, great success has been achieved in constructing reasoner LLMs in the general domain [Jaech et al., 2024, Guo et al., 2025, Team et al., 2025, Comanici et al., 2025]. Beyond enhancing overall Zihan Zhao, Bo Chen, and Ziping Wan contribute equally to this work. Xin Chen, Kai Yu, and Lu Chen are the corresponding authors. 1The inference code and the model parameters will be open-sourced. Preprint. model performance, the reasoning-before-answering pattern directly exhibits how and why the LLM comes up to this answer and therefore markedly improves the reliability and interpretability of the LLMs answer. Through the generated rationale, people can confirm the correctness of the answer or identify why the model makes mistakes. Therefore, reasoning-augmented LLMs offer promising new approach to addressing the aforementioned challenges in scientific-domain LLMs, potentially enhancing their practical utility. However, current research on reasoner LLMs has predominantly focused on general domains, as well as mathematics [Yang et al., 2024b, Shao et al., 2024] and programming [Zhu et al., 2024, Hui et al., 2024]. In scientific domains where professional knowledge and specific logic are vital and can hardly be harvested from natural language content, the reasoning capability of existing LLMs remains highly limited. There are two reasons that hinder current LLMs from excelling in science-domain-specific reasoning: 1) The understanding of domain knowledge remains superficial as advanced domain knowledge is typically insufficient in general-purpose corpora. Moreover, it is noticed that even current domain-specific LLMs also suffer from shallow understanding of domain knowledge. The literature and high-level phenomena used in current domain LLM training [Taylor et al., 2022, Xie et al., 2023, Zhao et al., 2025b, Zhang et al., 2024a, Yu et al., 2024] often fail to conduct proper breakdown into internal mechanisms and atomized knowledge points. For example, in the field of chemistry, the types and positions of functional groups within molecules fundamentally determine molecules properties and reactivities. However, instead of training on the functional-grouplevel knowledge, current chemical LLMs usually directly learn the molecule-level knowledge about properties and reactivities. The lack of atomized knowledge significantly constrains the capacity of these models for providing high-quality rationales. 2) The intrinsic reasoning logic in these domains differs significantly from that in general domains such as mathematics and programming, making it difficult for models to generalize relevant reasoning skills through training in general domains. Therefore, specific reasoning training in the vertical domains is needed. In this work, we focus on addressing the two aforementioned challenges in the chemistry domain and develop chemical reasoner LLM, ChemDFM-R. Specifically, we consider the presence of functional groups in molecules and the changes of functional groups during reactions to be atomized knowledge points. We develop toolkit to identify these features from molecules and reactions and incorporate them into the domain pretraining corpus. The resulting corpus contains over 101 billion tokens from 12 million literature, 30 million molecules, and 7 million reactions. To tackle the second issue, we develop mix-sourced distillation process that can take advantage of both the expertise in the carefully curated knowledge points and the advanced reasoning capabilities of general LLMs. Domain-specific reinforcement learning is utilized following the distillation process to further enhance the reasoning capability. The resulting model, ChemDFM-R, shows promising reasoning capabilities as well as advanced performance in multiple chemical benchmarks and can provide high-quality rationale, helping researchers deeply understand and verify its answer. In short, the contributions of this work are threefold: We developed toolkit to identify the functional groups of molecules and the changes of functional groups during reactions. With the help of this toolkit, we constructed 101 billion-token domain pretraining corpus, named ChemFG, featuring atomized functionalgroup-level knowledge in chemistry. With the base model domain-pretrained with ChemFG from Qwen2.5-14B, we further conducted instruction tuning, mix-sourced distillation, and domain-specific reinforcement learning in order. The proposed distillation and reinforcement learning significantly boost the models capability of chemical reasoning and produce the first chemical reasoner LLM, ChemDFM-R. Extensive experiments are conducted, and the results demonstrate the promising chemical reasoning capability of ChemDFM-R. The created model achieves outstanding performance and manages to generate clear and rational rationales, which significantly boost the reliability and interpretability of the final answer."
        },
        {
            "title": "2 ChemFG",
            "content": "In the field of chemistry, functional groups serve as the bridge between molecular structures, properties, and reactivities, making them one of the most critical intermediate reasoning steps in chemical 2 reasoning. However, existing training corpora of LLMs often lack detailed information on molecular functional groups, preventing models from directly and precisely learning this atomized chemical knowledge. Therefore, we crawl and construct functional-group-centered domain pertaining corpus, ChemFG, which contains over 101 billion tokens constructed from 12 million literature, 30 million molecules, and 7 million reactions."
        },
        {
            "title": "2.1 Raw Data Collection",
            "content": "ChemFG mainly consists of data from three sources: literature, molecules, and reactions. Literature. Literature, including papers and textbooks, contains not only the widely accepted chemical knowledge and laws, but also the cutting-edge research in the field of chemistry. Therefore, to take full advantage of chemical literature, we collected over 12 million literature from the open Internet dated prior to January 2022. After further cleaning and deduplication, 79B tokens are obtained from it. Molecules. Molecules are the fundamental participants in various chemical processes. Therefore, it is crucial for Chemical LLMs to understand molecular structures and properties. We manage to acquire large-scale molecule datasets from PubChem2, one of the biggest open accessible chemical databases with more than 100M compounds. We include 30 million molecules along with their notations, descriptions (if applicable), and properties. Besides PubChem, we also leverage the PubChemQC [Nakata and Shimazaki, 2017] dataset, which contains the quantum chemical calculation results of 86M molecules from PubChem, to supplement the quantum chemical properties of these molecules, such as dipole moment and orbital energy. To diversify the final data entry, we randomize the order of the properties and use three different formats: markdown list, markdown tables, and JSON dictionary to formulate the molecule data. Reactions. Reactions are the major process in the chemical world. The reactions and non-reactions between molecules are the primary ways in which chemistry impacts our daily lives. In ChemFG, we use the reactions from USPTO-FULL [Dai et al., 2019], one of the most comprehensive opensourced chemical reaction databases. To avoid data leakage, we exclude the test set of USPTO-FULL, USPTO-MIT [Jin et al., 2017], and USPTO-50K [Schneider et al., 2016] according to the products of reactions. Moreover, to further enhance the data diversity, we leverage the SMILES augmentation method introduced in R-SMILES [Zhong et al., 2022] and achieve total of 10 times augmentation of data. Finally, corpus of 7 million reactions is obtained."
        },
        {
            "title": "2.2 Functional Group Identification",
            "content": "Although we have collected web-scale molecules and reactions from the open Internet, there are no existing benchmarks that describe the correspondence between functional groups with molecules or reactions. To tackle this issue, we develop functional group identification toolkit based on thermo library3, SMARTS (SMiles ARbitrary Target Specification) notations4, and atom mapping annotations of reactions. Specifically, we extend and refine the SMARTS list of functional groups provided by thermo to identify the functional groups present in molecule. After our improvement, the tool can successfully identify 241 types of different common functional groups (see Appendix A), while the original thermo can only identify 83 types with errors. With this functional group identifier, we annotate the functional groups of all the molecules in our domain-pertaining corpus and incorporate them as one of the molecular properties during the formulation of the final data entry. As for reactions, we annotate the changes of functional groups during reactions with the following process. First, with the help of atom mapping annotations provided by the USPTO-FULL dataset, we identify the reaction centers as the atoms that are involved in bond changes during reactions. Based on these reaction centers, we identify the reacting functional groups as the reactants functional groups that contain any of the reaction centers but do not appear in the product. Similarly, the resulting 2https://pubchem.ncbi.nlm.nih.gov/ 3https://thermo.readthedocs.io/ 4https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html 3 Figure 1: The overview of the training pipeline of ChemDFM-R. functional groups are defined as the products functional groups that contain any of the reaction centers but do not appear in any of the reactants. Finally, the reaction can be described as reaction between the reacting functional groups that results in the formation of new functional groups. Besides functional groups, there are other structural changes during reactions that are equally important, including ring breaking, ring forming, and bond changes outside functional groups. Therefore, we further construct tools to identify these changes."
        },
        {
            "title": "2.3 Quality Control",
            "content": "To ensure the annotation quality of functional groups, we hire three chemical experts to conduct manual inspections. Firstly, all the experts agree that our SMARTS list has already covered the most common functional groups. For molecules, our tools annotation accuracy of 100 random samples reaches over 90%, with errors primarily due to corner cases such as rare functional groups or complex interactions between functional groups and aromatic rings. For the annotation of reactions, our tool achieves over 80% accuracy when tested with 100 random samples. The errors mainly arise from invalid reactions or wrong atom mapping annotations."
        },
        {
            "title": "3 ChemDFM-R",
            "content": "As outlined in Figure 1, the training pipeline can be divided into two parts: 1) Domain Pretraining and Instruction Tuning ( 3.1), where the basic general LLM is trained with atomized chemical knowledge; 2) Distillation and Reinforcement Learning ( 3.2), where the models chemical reasoning capability is enhanced."
        },
        {
            "title": "3.1 Atomized Chemical Knowledge Enhancement",
            "content": "In this stage, our model mainly learns the atomized chemical knowledge to prepare itself with ingredients to cook the chemical rationales. Specifically, we achieve that through domain pretraining and instruction tuning. Domain Pretraining. In domain pretraining, we leverage the 101 billion-token ChemFG corpus introduced in Section 2 to familiarize our model with the knowledge related to functional groups. Considering that general knowledge is also vital for Chemical LLMs, we train our model from one of the most advanced general LLMs, QWen2.5-14B [Yang et al., 2024a]. We also incorporate 4 Figure 2: Comparison of rationales generated by o3-mini with and without additional input information. We mark the correct analyses in the rationale as green, while the wrong ones as red. For more examples and detailed analyses, please refer to Appendix C. substantial amount of general-domain pretraining data into our domain pretraining corpus to ensure that the model retains its general capabilities as much as possible. Instruction Tuning. We believe that the primary goal of instruction tuning is to teach the model how to analyze the purpose and requirements of given task and establish connections with the knowledge it learned during the pretraining phase. However, previous instruction tuning datasets in the field of chemistry usually suffer from severe lack of diversity. Existing datasets typically derive their data from predefined chemistry tasks. On the one hand, the variety of these tasks is inherently limited. On the other hand, within the same task, the instructions used to describe the task are highly repetitive. Therefore, we construct new instruction tuning dataset for ChemDFM-R. Building upon the instruction tuning dataset of ChemDFM, we significantly enhance the diversity of instructions for each task and introduce numerous new chemistry-related tasks, such as scientific paper QA, chemical property ordering, and reaction step prediction. This expansion improves the overall diversity of the dataset. For detailed information on the construction and composition of the instruction tuning dataset, please refer to Appendix B. To maintain the general capabilities of our model, we mixed our chemical instruction tuning data with general instruction tuning data in 1:2 ratio. The Qwen2.5-14B model is finetuned for 2 epochs on this mixed dataset after domain pretraining, resulting in the ChemDFM-I model."
        },
        {
            "title": "3.2 Chemical Rationale Learning",
            "content": "The primary goal of this stage is to teach the model how to reason with the atomized knowledge it has acquired. Chemical reasoning requires deep understanding of chemical principles and logic, as well as the capability to apply them for analysis. These capabilities can not be learned or induced from general-domain reasoning training. Therefore, we propose chemical rationale learning 5 pipeline to specifically enhance the chemical reasoning capabilities of LLMs based on distillation and reinforcement learning. Mix-sourced Distillation. We leverage distillation to prevent the early unstable cold start phase of reinforcement learning. It could illustrate the reasoning patterns to the model and build up its basic reasoning capabilities. The common distillation method for LLMs involves gathering rationales from an advanced reasoning LLM, such as DeepSeek-R1 [Guo et al., 2025] and o3-mini [OpenAI, 2025b], and training the student model using the same loss as instruction tuning. However, this process assumes that the teacher LLM is capable of generating sufficiently reasonable rationales, which is often false in the chemical field. Owing to the limited understanding of atomized knowledge and chemical logic, even powerful general-domain reasoner model will highly probably fail to generate accurate and in-depth enough reasoning for chemical problems. To tackle this problem, we develop mix-sourced distillation process to take advantage of both the expertise in the carefully curated knowledge points and the advanced reasoning capabilities of general LLMs. Specifically, the entries in the distillation dataset come from three sources: 1) the instruction tuning dataset of ChemDFM-R (70%); 2) constructed pseudo-reasoning describing the functional groups of the involved molecules or reactions (22%); 3) teachers rationales where additional measure is taken to ensure high quality (8%). Moreover, instead of asking teacher models to generate rationales from scratch, we provide them with rich additional information, including the ground truth answer of the problem and the information of the functional groups of the molecules and reactions that appear in the problem. Comparisons of the rationales generated by DeepSeek-R1 with and without the additional information are illustrated in Figure 2, where the rationales generated with full additional information are significantly more valid and in-depth than the other two. More examples and detailed analysis of the generated rationales using different methods are illustrated in Appendix C, which demonstrates the advantages of our method in terms of generating accurate, complete, and logical rationales. Specifically, we use DeepSeek-R1 and o3-mini as the teacher models. To further validate the quality of the teachers rationales, we hired three chemical experts to manually inspect the rationales. Results show that among the sampled 264 rationales, 177 of them (67%) exhibit sufficiently high quality, 60 of them (23%) have minor, acceptable flaws such as reasoning step skipping or missing possibilities, and 27 of them (10%) contain substantive issues such as logic errors or nonsense reasoning. Considering that reinforcement learning will be used after distillation to correct errors and improve performance, and that it is difficult to systematically distinguish these problems in the rationales, we used all the data during the distillation process. Similar to instruction tuning, we mix our mix-sourced distillation dataset with general data in 1:2 ratio. Moreover, the general data is also sampled from multiple sources, where 92% of the entries are sampled from the general data for instruction tuning of ChemDFM-R and 8% of the entries are sampled from AM-Deepseek-R1-Distill-1.4M [Zhao et al., 2025a]. The ChemDFM-I model is finetuned for one epoch on this mixed dataset. Reinforcement Learning. After distillation, reinforcement learning (RL) is leveraged to further enhance the reasoning capabilities of our model. The composition of the RL dataset is illustrated in Figure 1, while more details of our reinforcement learning process are illustrated in Appendix D."
        },
        {
            "title": "4 Experimental Results",
            "content": "We first evaluate ChemDFM-R with multiple baselines on several benchmarks specifically designed for assessing the chemical capabilities of LLMs ( 4.1). Then, to highlight the importance and effectiveness of chemical reasoning, we analyze the rationale of our model in detail ( 4.2) and demonstrate its capability in facilitating reliable human-AI collaboration ( 4.3)."
        },
        {
            "title": "4.1 Benchmark Evaluation",
            "content": "We evaluate ChemDFM-R and the baseline models on two of the most popular and comprehensive benchmarks specifically designed for assessing the chemical capabilities of LLMs: SciKnowE6 Table 1: Benchmark results on SciKnowEval and ChemEval. mol. stands for molecule and react. stands for reaction. The best performance for each task is indicated using boldface. * We use PRS [Peng et al., 2025] to balance the different scales of the scores on different tasks in the ChemEval benchmark."
        },
        {
            "title": "SciKnowEval",
            "content": "ChemEval* text mol. react. all text mol. react. all Qwen2.5-14B-Instruct ChemDFM-I ChemDFM-R 0.77 0.77 0.77 0.36 0.50 0.52 0.72 0.95 0.95 0.61 0.69 0. 0.78 0.80 0.80 0.24 0.69 0.88 0.47 0.60 0.66 0.57 0.72 0.78 val [Feng et al., 2024] and ChemEval [Huang et al., 2024]. Given the large number of tasks included in SciKnowEval (19 tasks) and ChemEval (36 tasks), to facilitate fair and clear comparison, we categorized the tasks into three groups: text-centric, molecule-centric, and reaction-centric tasks."
        },
        {
            "title": "4.1.1 Performance Comparison with Baselines",
            "content": "First, we demonstrate the effectiveness of our training pipeline by comparing the performances of ChemDFM-R with those of 1) Qwen2.5-14B-Instruct [Yang et al., 2024a], which is the generaldomain instruction tuning model of Qwen2.5-14B, and 2) ChemDFM-I, which incorporates atomized chemical knowledge enhancement but precedes the stage of chemical rationale learning. The results are illustrated in Table 1. As showcased in Table 1, ChemDFM-R consistently outperforms Qwen2.5-14B-Instruct on both SciKnowEval and ChemEval. This demonstrates that our specialization pipeline has successfully improved the models chemical capabilities. Specifically, the performances on text-centric tasks remain almost intact while those on molecule-centric and reaction-centric tasks increase significantly, leading to large boost in the overall performance. This demonstrates that our method manages to improve the chemical capabilities of LLM while largely maintaining its abilities in understanding natural language. When taking the ChemDFM-I model into consideration, we observe clear performance improvement trend from Qwen2.5-14B-Instruct to ChemDFM-I and further to ChemDFM-R. This demonstrates that both the atomized chemical knowledge enhancement stage and the chemical rationale learning stage are crucial in achieving the final performance improvement. The atomized chemical knowledge enhancement stage enhances the models chemical knowledge, while the chemical rationale learning stage teaches the model how to conduct plausible reasoning with this knowledge. Beyond improved performance, the chemical reasoning capability of ChemDFM-R also enhances reliability and facilitates more effective humanAI collaboration, which will be discussed in subsequent sections. Furthermore, Figure 3 illustrates the performance changes across individual tasks. The results clearly show that most tasks benefit from our training pipeline, especially the molecule-centric tasks and reaction-centric tasks. Moreover, the two training stages provide complementary gains across different tasks, enabling the final model to achieve superior results on broader range of tasks. Notably, among the tasks where ChemDFM-R does not surpass Qwen2.5-14B-Instruct, substantial proportion involves numerical prediction, such as Yield Extraction, Molecular Property Calculation, and Product Yield Prediction. In fact, all the molecule-centric and reaction-centric tasks where ChemDFM-R falls short of Qwen2.5-14B-Instruct are those involving numerical reasoning and prediction. This pattern suggests that the numerical calculation and prediction abilities of ChemDFM-R are relatively weak, highlighting potential direction for further improvements."
        },
        {
            "title": "4.1.2 Performance Comparison with Advanced LLMs",
            "content": "To further demonstrate the prowess of ChemDFM-R, we compare it with three sets of models: 1) existing chemical LLMs, including MolInst [Fang et al., 2024], ChemLLM [Zhang et al., 2024a], and ChemDFM [Zhao et al., 2025b]; 2) advanced non reasoning LLMs in the general domain, including GPT-4o [Hurst et al., 2024] and Qwen3-14B (no think) [Yang et al., 2025]; 3) advanced reasoning LLMs in the general domain, including DeepSeek-R1 [Guo et al., 2025], Qwen3-14B (think) [Yang 7 Figure 3: The performance change for all the individual tasks in SciKnowEval and ChemEval between Qwen2.5-14B-Instruct, ChemDFM-I, and ChemDFM-R. et al., 2025], and o4-mini [OpenAI, 2025a]. The experimental results are illustrated in Table 2. For detailed task categorization and the performance of individual tasks, please refer to Appendix E. As shown in Table 2, ChemDFM-R significantly outperforms both the general-domain LLMs and domain-specific LLMs of similar size, especially in the molecule-centric and reaction-centric tasks. Specifically, it even surpasses Qwen3-14B, the next-generation model in the same series as our base model Qwen2.5-14B. When compared to cutting-edge LLMs, ChemDFM-R achieves better performance than GPT-4o and DeepSeek-R1, while demonstrating competitive results relative to o4-mini. Considering the tiny size of our model, this result strongly demonstrates the prowess of ChemDFM-R and the effectiveness of our specialization process."
        },
        {
            "title": "4.2 Rationale Analysis",
            "content": "To further validate the correctness and precision of ChemDFM-Rs reasoning capability, we conducted thorough analysis of the rationales generated by ChemDFM-R. An example is illustrated in Figure 4, with additional examples provided in the Appendix F. In Figure 4, ChemDFM-R is asked to pick correct product for the given reaction. Instead of wasting time (tokens) on analyzing the SMILES in great detail, which DeepSeek-R1 always does, ChemDFM-R1 goes directly into the key point of this question: the functional groups present in the reactants and the potential reactions between them. Specifically, ChemDFM-R successfully identifies 8 Table 2: Benchmark results on SciKnowEval and ChemEval. mol. stands for molecule and react. stands for reaction. The best performance for each task is indicated using boldface, while the second-best is indicated using underline. * We use PRS [Peng et al., 2025] to balance the different scales of the scores on different tasks in the ChemEval benchmark."
        },
        {
            "title": "SciKnowEval",
            "content": "ChemEval* text mol. react. all text mol. react. all MolInst ChemLLM-20B-DPO ChemDFM-13B-v1.0 ChemDFM-8B-v1.5 GPT-4o Qwen3-14B (no think) DeepSeek-R1 Qwen3-14B (think) o4-mini ChemDFM-R 0.69 0.74 0.70 0. 0.76 0.77 0.80 0.87 0.81 0.77 0.38 0.38 0.43 0.46 0.45 0.35 0.31 0.41 0. 0.52 0.42 0.88 0.85 0.87 0.45 0.80 0.83 0.88 0.97 0.95 0.55 0.62 0.62 0. 0.61 0.61 0.62 0.70 0.74 0.70 0.47 0.65 0.62 0.27 0.83 0.82 0.81 0.79 0. 0.80 0.16 0.25 0.43 0.13 0.36 0.25 0.20 0.25 0.63 0.88 0.10 0.19 0.36 0. 0.56 0.28 0.50 0.43 0.59 0.66 0.29 0.43 0.50 0.21 0.65 0.53 0.58 0.56 0. 0.78 Figure 4: An example of the responses generated by ChemDFM-R on the reaction prediction task. 9 Figure 5: An example of reliable human-AI collaboration using ChemDFM-R. We draw inspiration from this conversation from Li et al. [2025]. This example illustrates process of research inspiration seeking with the help of ChemDFM-R. the key functional group, the carbamate ester group. By recalling that the carbamate ester group is typically used to protect amino groups, ChemDFM-R infers that the reaction taking place is likely deprotection reaction. Then, ChemDFM-R confirms its assumption by examining the provided reagents. Finally, ChemDFM-R predicts the feature of the possible product and picks the option that matches it. This example demonstrates the precision of ChemDFM-R in finding the key point of chemical questions, and the effectiveness and efficiency of ChemDFM-Rs rationales. Moreover, it is also worth noticing that, instead of using the elimination-shortcut which is commonly adopted by other cutting-edge reasoning LLMs, ChemDFM-R directly reasoned out the reaction mechanism and the features of the correct answer, thereby selecting the correct option."
        },
        {
            "title": "4.3 Reliable Human-AI Collaboration",
            "content": "Another important advantage of ChemDFM-Rs reasoning capability is that it allows humans to verify the correctness of answers, identify and correct errors in the reasoning process, and discover new insights or perspectives. This enables more practical, reliable, and flexible human-AI collaboration. In this section, we demonstrate the prowess of ChemDFM-R to facilitate reliable human-AI collaboration through examples. Specifically, an example is showcased in Figure 5, while more examples are illustrated in Appendix G. 10 Specifically, to make our example more realistic, we design our conversation topic according to newly published chemical research paper, Li et al. [2025]. It is worth noticing that this paper was published in 2025, so it is impossible for ChemDFM-R to have encountered this paper during either the pretraining of the base model, Qwen2.5-14B, or our domain-pretraining process. To demonstrate the potential of ChemDFM-R, we assume the role of researcher seeking new research inspiration and engage dialogue with the model about the subfield to which this paper belongs. First, as researcher seeking inspiration, we first ask ChemDFM-R to introduce the oxygen evolution reaction (OER) briefly, including the definition and mechanism of it. Although the answer itself is relatively rigid response to the question, the models rationale reveals interesting insights. In its rationale, ChemDFM-R mentions that OER requires transition metal oxide catalyst, which often presents valuable opportunities for further research. Therefore, we further ask it to give more detailed recommendations for the catalysts. As response, ChemDFM-R proposes multiple different oxides, which is wide range for us to dig into. However, in its rationale, ChemDFM-R itself says that iridium oxide (IrO2) is particularly notable for its ..., which is very inspiring. Since it is well known that iridium-based compounds are often very expensive, natural follow-up question arises: how can we optimize this catalyst to reduce its cost while maintaining its catalytic performance? Surprisingly, ChemDFM-R manages to propose the initial ideas that align closely with the ideas presented in Li et al. [2025], forming mixed metal oxides or heterostructures and optimizing the morphology and surface area of the catalysts. At this point, broad research direction has taken shape. It is worth noticing that nearly all the inspirations are drawn from the rationale of ChemDFM-R, which demonstrates the significance and value of ChemDFM-Rs ability to generate reasoning. This example shows that, with the enhanced chemical knowledge and strong chemical reasoning capabilities, ChemDFM-R has the potential to facilitate reliable human-AI collaboration, and so that advancing AI-driven research and applications."
        },
        {
            "title": "5.1 General Domain Reasoner LLMs",
            "content": "Shortly after the emergence of LLMs, their remarkable emergent reasoning capabilities were discovered by Kojima et al. [2022] and explored by works such as ToT [Yao et al., 2023] and PAL [Gao et al., 2023]. Recently, OpenAI-o1 [Jaech et al., 2024] followed by DeepSeek-R1 [Guo et al., 2025] and Kimi K1.5 [Team et al., 2025] demonstrated the prowess of reasoning models and the method to enhance LLMs reasoning capabilities using reinforcement learning-based pipelines. Subsequently, many studies have focused on improving the reasoning capabilities of models in various general domains, primarily in mathematics and coding. For example, Shao et al. [2024] and Zhang et al. [2024b] have further proven and discussed the effectiveness of reinforcement learning in terms of enhancing models reasoning capabilities, while Dou et al. [2024] and Zhang et al. [2025c] have explored better reward functions in mathematics and coding. Despite the active research on reasoner models in general domains, there is little research focused on developing chemical reasoner LLMs. Considering that chemical reasoning requires domainspecific atomized knowledge and intrinsic logic, enhancing chemical reasoning capabilities demands specialized and targeted training. In this work, we designed relatively comprehensive reward system for various chemical tasks to enable reinforcement learning tailored to chemical problems. Additionally, we developed an effective distillation data acquisition method to mitigate the knowledge gap of general LLMs, allowing us to leverage the power of general-domain reasoner LLMs to prevent the early unstable cold start phase of reinforcement learning."
        },
        {
            "title": "5.2 Chemical LLMs",
            "content": "The specialization of LLMs has become one of the most popular research areas after the emergence of LLMs in the general domain, including the development of chemical LLMs. LlaSMol [Yu et al., 2024] and Mol-Instruct [Fang et al., 2024] construct chemical instruction tuning dataset and develop models that could excel on multiple chemical tasks, while extensive training with only chemical tasks has led to substantive loss of natural language capabilities and task generalization ability in these models. Shortly after, Zhang et al. [2024a] leveraged high-quality instruction tuning and developed ChemLLM, which has acquired advanced chemical capabilities while retaining considerable level of 11 general language abilities. Furthermore, ChemDFM [Zhao et al., 2025b] achieved stronger chemical and generalization capabilities through domain pretraining and instruction tuning with both chemical data and general-domain data. It is worth noticing that all data used in previous work is from opensourced databases or benchmarks. They usually directly model the correlation between molecules or reactions and the terminal phenomena, such as molecular properties or reaction yields, while the factors that truly have direct impact are the functional groups within the molecules. Without this atomized chemical knowledge, it would be arduous for current chemical LLMs to generate rationales that align with chemical intuition and principles. Therefore, in this work, we tackle this issue by constructing function-group-centric domain pretraining corpus to introduce this atomized chemical knowledge to LLMs. Recently, there has been some work starting to build reasoning models for specific chemical tasks, such as retrosynthesis [Zhang et al., 2025a], but general chemical reasoner model is still absent."
        },
        {
            "title": "6 Conclusion",
            "content": "In this work, we have developed chemical reasoner LLM, ChemDFM-R, by tackling both the limitations in understanding atomized chemical knowledge and the domain-specific reasoning logic. By incorporating atomized knowledge about molecular functional groups and their changes during reactions into the pretraining corpus, and applying mix-sourced distillation approach before reinforcement learning, we have enhanced the models ability to reason efficiently and effectively in chemistry. Our extensive experiments demonstrate that ChemDFM-R significantly improves chemical problem-solving and reasoning capabilities, making it valuable tool for facilitating reliable human-AI collaboration in chemistry and advancing AI-driven research and applications."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. Luis Antunes, Keith Butler, and Ricardo Grau-Crespo. Crystal structure generation with autoregressive large language modeling. Nature Communications, 15(1):10570, 2024. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901, 2020. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. Hanjun Dai, Chengtao Li, Connor Coley, Bo Dai, and Le Song. Retrosynthesis prediction with conditional graph logic network. Advances in Neural Information Processing Systems, 32, 2019. Shihan Dou, Yan Liu, Haoxiang Jia, Limao Xiong, Enyu Zhou, Wei Shen, Junjie Shan, Caishuang Huang, Xiao Wang, Xiaoran Fan, et al. Stepcoder: Improve code generation with reinforcement learning from compiler feedback. arXiv preprint arXiv:2402.01391, 2024. Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, and Huajun Chen. Mol-instructions: large-scale biomolecular instruction dataset for large language models. In ICLR. OpenReview.net, 2024. URL https://openreview.net/pdf?id= Tlsdsb6l9n. Kehua Feng, Keyan Ding, Weijie Wang, Xiang Zhuang, Zeyuan Wang, Ming Qin, Yu Zhao, Jianhua Yao, Qiang Zhang, and Huajun Chen. Sciknoweval: Evaluating multi-level scientific knowledge of large language models. arXiv preprint arXiv:2406.09098, 2024. 12 Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. Pal: Program-aided language models. In International Conference on Machine Learning, pages 1076410799. PMLR, 2023. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and arXiv preprint Jacob Steinhardt. Measuring massive multitask language understanding. arXiv:2009.03300, 2020. Yuqing Huang, Rongyang Zhang, Xuesong He, Xuyang Zhi, Hao Wang, Xin Li, Feiyang Xu, Deguang Liu, Huadong Liang, Yi Li, et al. Chemeval: comprehensive multi-level chemical evaluation for large language models. arXiv preprint arXiv:2409.13989, 2024. Binyuan Hui, Jian Yang, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Lei Zhang, Tianyu Liu, Jiajun Zhang, Bowen Yu, Keming Lu, et al. Qwen2. 5-coder technical report. arXiv preprint arXiv:2409.12186, 2024. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024. Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. arXiv preprint arXiv:2412.16720, 2024. Wengong Jin, Connor Coley, Regina Barzilay, and Tommi Jaakkola. Predicting organic reaction outcomes with weisfeiler-lehman network. Advances in neural information processing systems, 30, 2017. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35: 2219922213, 2022. Gengnan Li, Adyasa Priyadarsini, Zhenhua Xie, Sinwoo Kang, Yuzi Liu, Xiaobo Chen, Shyam Kattel, and Jingguang Chen. Achieving higher activity of acidic oxygen evolution reaction using an atomically thin layer of iro over co3o4. Journal of the American Chemical Society, 147(8): 70087016, 2025. Maho Nakata and Tomomi Shimazaki. Pubchemqc project: large-scale first-principles electronic structure database for data-driven chemistry. Journal of chemical information and modeling, 57(6): 13001308, 2017. OpenAI. Introducing openai o3 and o4-mini, 2025a. URL https://openai.com/index/ introducing-o3-and-o4-mini. OpenAI. Openai introducing-o3-and-o4-mini. o3-mini, jan 2025b. URL https://openai.com/index/ Jing Peng, Yucheng Wang, Bohan Li, Yiwei Guo, Hankun Wang, Yangui Fang, Yu Xi, Haoyu Li, Xu Li, Ke Zhang, Shuai Wang, and Kai Yu. survey on speech large language models for understanding, 2025. URL https://arxiv.org/abs/2410.18908. Nadine Schneider, Nikolaus Stiefl, and Gregory Landrum. Whats what: The (nearly) definitive guide to reaction role assignment. Journal of chemical information and modeling, 56(12):2336 2346, 2016. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Yang Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024. Anuroop Sriram, Benjamin Miller, Ricky TQ Chen, and Brandon Wood. Flowllm: Flow matching for material generation with large language models as base distributions. Advances in Neural Information Processing Systems, 37:4602546046, 2024. Qian Tan, Dongzhan Zhou, Peng Xia, Wanhao Liu, Wanli Ouyang, Lei Bai, Yuqiang Li, and Tianfan Fu. Chemmllm: Chemical multimodal large language model. arXiv preprint arXiv:2505.16326, 2025. Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: large language model for science. arXiv preprint arXiv:2211.09085, 2022. Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew Dai, Anja Hauth, Katie Millican, et al. Gemini: family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023. Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et al. Kimi k1. 5: Scaling reinforcement learning with llms. arXiv preprint arXiv:2501.12599, 2025. Yuwei Wan, Yixuan Liu, Aswathy Ajith, Clara Grazian, Bram Hoex, Wenjie Zhang, Chunyu Kit, Tong Xie, and Ian Foster. Sciqag: framework for auto-generated science question answering dataset with fine-grained evaluation, 2024. URL https://arxiv.org/abs/2405.09939. Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, et al. Mmlu-pro: more robust and challenging multitask language understanding benchmark. Advances in Neural Information Processing Systems, 37: 9526695290, 2024. Zhenqin Wu, Bharath Ramsundar, Evan Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh Pappu, Karl Leswing, and Vijay Pande. Moleculenet: benchmark for molecular machine learning. Chemical science, 9(2):513530, 2018. Tong Xie, Yuwei Wan, Wei Huang, Zhenyu Yin, Yixuan Liu, Shaozhou Wang, Qingyuan Linghu, Chunyu Kit, Clara Grazian, Wenjie Zhang, et al. Darwin series: Domain specific large language models for natural science. arXiv preprint arXiv:2308.13565, 2023. An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115, 2024a. An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, et al. Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement. arXiv preprint arXiv:2409.12122, 2024b. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. Advances in neural information processing systems, 36:1180911822, 2023. Weidong Yao, Ziqi Liu, Hao Ling, Hongyu Wang, Hufeng Zheng, Shao-Hua Wang, Dao-Yong Zhu, Sheng-Yong Zhang, and Xiaoming Chen. Convergent total synthesis of (-)-calidoustene. Journal of the American Chemical Society, 147(19):1596315969, 2025. Botao Yu, Frazier Baker, Ziqi Chen, Xia Ning, and Huan Sun. Llasmol: Advancing large language models for chemistry with large-scale, comprehensive, high-quality instruction tuning dataset. arXiv preprint arXiv:2402.09391, 2024. Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan, Gaohong Liu, Lingjun Liu, et al. Dapo: An open-source llm reinforcement learning system at scale. arXiv preprint arXiv:2503.14476, 2025. 14 Di Zhang, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, Weiran Huang, Xiangyu Yue, Wanli Ouyang, et al. Chemllm: chemical large language model. arXiv preprint arXiv:2402.06852, 2024a. Situo Zhang, Hanqi Li, Lu Chen, Zihan Zhao, Xuanze Lin, Zichen Zhu, Bo Chen, Xin Chen, and Kai Yu. Reasoning-driven retrosynthesis prediction with large language models via reinforcement learning, 2025a. URL https://arxiv.org/abs/2507.17448. Yu Zhang, Yang Han, Shuai Chen, Ruijie Yu, Xin Zhao, Xianbin Liu, Kaipeng Zeng, Mengdi Yu, Jidong Tian, Feng Zhu, et al. Large language models to accelerate organic chemistry synthesis. Nature Machine Intelligence, pages 113, 2025b. Yuxiang Zhang, Shangxi Wu, Yuqi Yang, Jiangming Shu, Jinlin Xiao, Chao Kong, and Jitao Sang. o1-coder: an o1 replication for coding. arXiv preprint arXiv:2412.00154, 2024b. Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, and Junyang Lin. The lessons of developing process reward models in mathematical reasoning. arXiv preprint arXiv:2501.07301, 2025c. Han Zhao, Haotian Wang, Yiping Peng, Sitong Zhao, Xiaoyu Tian, Shuaiting Chen, Yunjie Ji, and Xiangang Li. 1.4 million open-source distilled reasoning dataset to empower large language model training. arXiv preprint arXiv:2503.19633, 2025a. Zihan Zhao, Bo Chen, Jingpiao Li, Lu Chen, Liyang Wen, Pengyu Wang, Zichen Zhu, Danyang Zhang, Yansi Li, Zhongyang Dai, et al. Chemdfm-x: towards large multimodal model for chemistry. Science China Information Sciences, 67(12):220109, 2024. Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, Hongshen Xu, Zichen Zhu, Su Zhu, et al. Developing chemdfm as large language foundation model for chemistry. Cell Reports Physical Science, 6(4), 2025b. Zipeng Zhong, Jie Song, Zunlei Feng, Tiantao Liu, Lingxiang Jia, Shaolun Yao, Min Wu, Tingjun Hou, and Mingli Song. Root-aligned smiles: tight representation for chemical reaction prediction. Chemical Science, 13(31):90239034, 2022. Qihao Zhu, Daya Guo, Zhihong Shao, Dejian Yang, Peiyi Wang, Runxin Xu, Wu, Yukun Li, Huazuo Gao, Shirong Ma, et al. Deepseek-coder-v2: Breaking the barrier of closed-source models in code intelligence. arXiv preprint arXiv:2406.11931, 2024."
        },
        {
            "title": "A Functional Groups covered by ChemFG",
            "content": "The functional groups that can be recognized by our toolkit are categorized based on the heteroatoms and listed as follows: Hydrocarbon Groups (7): alkene, alkyne, allene, cumulene, carbocation, carbanion, carbene. Boron Groups (6): borane, boronic acid, boronic ester, borinic acid, borinic ester, borate ester. Oxygen Groups (36): alcohol, alkoxide, ether, phenol, phenolate, enol, enolate, enol ether, alkynol, alkynolate, alkynol ether, ketone, ketene, aldehyde, hemiketal, hemiacetal, ketal, acetal, carboxylic acid, carboxylate, ester, organic acid anhydride, carboxylic anhydride, organic carbonate, organic hydroperoxide, organic peroxide, peroxyacid, ortho ester, orthocarbonate ester, methylenedioxy, ethylenedioxy, oxonium ion, oxocarbenium ion, carbonyl ylide, oxonium ylide, epoxy. Nitrogen Groups (62): primary amine, secondary amine, tertiary amine, ammonium cation, quat, amine oxide, enamine, hydroxylamine, hemiaminal, hemiaminal ether, thioaminal, thioaminal ether, aminal, primary ketimine, secondary ketimine, primary aldimine, secondary aldimine, amidine, guanidine, ketoxime, aldoxime, hydrazone, organic amide, amidate anion, imide, carbamic acid, carbamate ester, carbamate anion, azide, azo, hydrazine, acylhydrazine, amidrazone, cyanate, isocyanate, nitrile, isonitrile, cyanamide, carbodiimide, 15 Figure 6: The distribution of the functional groups in the domain-pretraining corpus. nitrate ester, nitrite ester, nitro, nitroso, nitrosamine, iminium cation, nitrone, nitronic acid, imidic acid, imidate anion, imidate, imidocarbonate, imidocarbamate, urea, azoxy, N-oxoammonium, hydroxamic acid, hydroxamate, azanide, azomethine ylide, nitrile ylide, isodiazene, nitronate. Sulfur Groups (85): mercaptan, thiolate anion, organic sulfide, thioenol, enedithiol, thioenolate, thioenol ether, persulfide anion, organic disulfide, sulfenic acid, sulfenic ester, sulfenamide, sulfoxide, sulfone, sulfine, sulfene, sulfinylamine, sulfur diimide, sulfinic acid, sulfonic acid, sulfinate ester, sulfonate ester, sulfinate anion, sulfonate anion, thiosulfinate, thiosulfonate, thiosulfurous ester, dithiosulfurous ester, thiosulfuric ester, organosulfite, organosulfate, dialkylsulfates, sulfinamide, sulfonamide, sulfamic acid, sulfamate, sulfamide, thiocyanate, isothiocyanate, thioketone, thioketene, thial, thioamide, thiourea, hemithioketal, hemithioacetal, dithiohemiketal, dithiohemiacetal, monothioketal, monothioacetal, dithioketal, dithioacetal, carbothioic S-acid, carbothioic O-acid, thiol form thiocarboxylate, thione form thiocarboxylate, thiolester, thionoester, carbodithioic acid, carbodithioic anion, carbodithioic ester, monothiocarbonate, xanthic acid, xanthate, xanthate anion, dithiocarbonate, trithiocarbonate, O-thiocarbamic acid, S-thiocarbamic acid, O-thiocarbamate, Sthiocarbamate, O-thiocarbamate anion, S-thiocarbamate anion, thioimidic acid, thioimidate anion, thioimidate, dithiocarbamic acid, dithiocarbamate, dithiocarbamate anion, imidothiocarbonate, imidodithiocarbonate, imidothiocarbamate, sulfonium ion, sulfonium ylide, sulfoxonium ylide. Silicon Groups (5): silane, siloxane, silyl ether, silyl enol ether, silyl alkynol ether. Phosphorus Groups (17): phosphine, phosphonium, aminophosphine, phosphine oxide, phosphinic acid, phosphinate, phosphonic acid, phosphonate, phosphite ester, phosphinite, phosphonite, phosphodiester, phosphate mono-ester, phosphate tri-ester, phosphoramide, thiophosphate, phosphonium ylide. Halogen Groups (14): fluoro, chloro, bromo, iodo, halamine, sulfenyl halide, sulfinyl halide, sulfonyl halide, halosulfate, phosphoryl halide, phosphorus halide, acyl halide, imidoyl halide, thioacyl halide. Organometalic Groups (5): organolithium, organomagnesium, organoaluminium, organozinc, organomercury. Aromatic (4): pyrrolic N, pyridinic N, aromatic O, aromatic S. The occurrence of these functional groups in the domain-pretraining corpus is shown in Figure 6."
        },
        {
            "title": "B Instruction Tuning Dataset",
            "content": "B.1 Raw Data Collection Our instruction tuning dataset is constructed of three parts corresponding to the three main information carriers in chemistry: molecule-centric tasks, reaction-centric tasks, and knowledge-centric tasks. The distribution of instruction tuning data is shown in Figure 7. B.1.1 Molecule-Centric Tasks Name Translation: The name translation between SMILES, IUPAC name, and molecular formula. The data is constructed from PubChem5. Description Generation: The molecule description task is to describe the molecule given its SMILES. The data is constructed from PubChem. We only use the high-quality descriptions that contain more than two sentences. Molecule Design: The molecule design task is the reverse task of molecule description. It requires the model to predict the SMILES given the molecule description. We use the same high-quality description data from PubChem to construct this task. Property Classification: These tasks require models to predict the value of molecular properties from list of candidates (usually yes and no). The data is constructed from 5 of the most popular property classification datasets in MoleculeNet [Wu et al., 2018], namely BACE, BBBP, ClinTox, HIV, and Tox21. Property Regression: These tasks require the models to predict the value of molecular properties, which is real number. Data are also from MoleculeNet, namely FreeSolv, Lipo, and QM9. Property Ordering: Provided list of molecules, models are asked to rank them in ascending or descending order of some specific property. Raw data comes from the same source as property regression. Property Selection: Provided list of molecules, models are asked to select the one with the highest or lowest value of some specific property. Raw data comes from the same source as property regression. B.1.2 Reaction-Centric Tasks Reaction Completion: Given an incomplete reaction, models need to complete the missing reactants, reagents, or products. Raw data comes from USPTO-Full [Dai et al., 2019], USPTO-MIT [Jin et al., 2017], and USPTO-50K [Schneider et al., 2016]. 5https://pubchem.ncbi.nlm.nih.gov/ 17 Step Prediction: Given reaction, models are required to predict the experimental procedure to conduct it in the laboratory. Raw data comes from USPTO [Dai et al., 2019]. Yield Prediction: In this task, models are required to predict the yield of the given reactions. The data is constructed from the USPTO dataset. Temperature Prediction: In this task, models are required to predict the temperature that is suitable for the given reactions to conduct. The data is constructed from the USPTO dataset. Reaction Component Selection: In this task, series of reactants and reagents is given with list of candidate molecules. Models need to pick from the candidates the molecules that could participate in the reaction and lead to the highest yield. The data is constructed from the USPTO dataset. B.1.3 Knowledge-Centric Tasks Exam Questions: This task is composed of questions from the exams in middle school and high school. Raw data comes from the Open Internet. Literature QA: In this task, models are required to answer questions based on the given paragraph. The data is extracted from the long paragraph following the method in SciQAG [Wan et al., 2024]. The raw data comes from the articles in the domain-pertaining. The articles are split into sections and then truncated into paragraphs within 2k to 3k tokens. We ask GPT-4o-mini to extract 15 keywords from each paragraph, then generate 10 question-answer pairs according to them. We adopt another LLM, Qwen2.5-14B-Instruct, to evaluate the quality of the QA pair in 4 dimensions: completeness, accuracy, reasonableness, and agnosticism. The LLM will score the QA pair from 1 to 5 using the designed prompts. QA pairs with any scores below 5 are discarded. If there are more than 1 QA pair left, the questions are asked in conversation turns. Literature Summarization: In this task, models are required to give summarization of the paragraph. The summarization is generated from GPT-4o-mini from the paragraph sample. Literature Translation: In this task, models are required to translate the English paragraph into Chinese. The translation is generated from GPT-4o-mini from the paragraph sample. Since the source data consists of OCR text extracted from English articles, which is inherently noisy, we decided to discard the reverse task of translating Chinese paragraphs into English. B.2 Instruction Generation To acquire higher generalization capability, we adopt two-stage process to obtain as diverse set of instructions as possible for each task. Specifically, based on the number of data entries for each task, we first manually write 5-20 seed task descriptions accordingly. Then, we ask three different models, Qwen2.5-72B-Instruct, Llama-3.1-70B-Instruct, and GPT-4o-mini, to diversify these task descriptions. Specifically, during each request, we sample 5 descriptions from all the generated descriptions and ask the model to generate 10 new descriptions using 5 different prompts one by one. Following this, we append to each of the descriptions the instructions that introduce the input of each data entry by formatted string of Python and ask GPT-4o-mini to further diversify them. As result of the above diversification process, we constructed number of instructions equivalent to approximately 2% of its total data volume for each task. In other words, each instruction appears around 50 times in the instruction-tuning dataset."
        },
        {
            "title": "C Comparison of Rationales Generated by Teacher Models",
            "content": "As shown in Figure 2, 8, and 9, the rationales generated using our method exhibit distinct advantages in terms of accuracy, completeness, and logicality. The advantage in accuracy is mainly reflected in Figure 2. In Figure 2, o3-mini completely misunderstands the chemical reaction that occurs between the given molecules. This might result from its incorrect identification of the reagents and the structure of the complex reactants (these errors are also reflected in the rationales). When given the correct answer, o3-mini still mistakenly identified 18 Figure 7: The distribution of instruction tuning data. chloro-ketone as acyl chloride and consistently adhered to this error throughout the reasoning process, resulting in series of related structural inaccuracies. On the contrary, when the functional group information is provided, o3-mini manages to generate near-perfect rationale with zero error. The advantage in completeness is mainly reflected in Figure 8. In Figure 8, given only the question, DeepSeek-R1 only generates brief analysis on the second option while dismissing the other three options with single sentence in total. This overly simple analysis leads to wrong prediction. With the help of the ground truth answer, the generated rationale analyzes all options individually. However, due to its lack of chemical knowledge, the analysis still exhibits errors in functional group recognition or overlooks key influencing factors. After enhancing chemical knowledge with the functional group information, DeepSeek-R1 finally manages to generate more comprehensive analysis with few errors. The advantage in logicality is mainly reflected in Figure 9. In Figure 9, with only the question, o3-mini can hardly generate any useful rational. The rational merely repeats the IUPAC components mentioned in the question before rushing to highly inaccurate conclusion without substantive analysis. When given the ground truth answer, o3-mini can construct reasonably good rationale with minimal factual error. However, the rationale still contains non-negligible issues in terms of logical coherence. sound reasoning process should follow the approach exemplified by the reasoning chain generated by o3-mini using our method: analyzing in the order of molecular skeleton, functional groups, heteroatoms, and chiral centers. This sequence reflects step-by-step refinement from the fundamental molecular structure to more intricate structural details. However, with only the question and answer, the generated rationale mixes these analytical steps and lacks critical details, such as the precise position of the nitrogen atom, resulting in disorganized and incomplete reasoning process."
        },
        {
            "title": "D Details of Reinforcement Learning",
            "content": "We use the DAPO [Yu et al., 2025] algorithm for reinforcement learning. For each training sample, we sample 8 different rollouts during training. The learning rate is set to 5e-7, and the batch sizes for rollouts and training are set to 512 and 128, respectively. As for the reward system, we follow the method recommended by DeepSeek-R1 [Guo et al., 2025], where the reward system consists of format rewards and accuracy rewards. The format rewards evaluate whether response strictly follows 19 Figure 8: Comparison of rationales generated by o3-mini with and without additional input information. We mark the correct analyses in the rationale as green, while the wrong ones as red. the reasoning format, and the accuracy rewards evaluate whether response is correct. Specifically, considering the redundancy of the casual SMILES notations (one molecule could correspond to multiple SMILES), we first canonicalize all the SMILES in the response before calculating the accuracy rewards."
        },
        {
            "title": "E Detail Results of Benchmark Evaluation",
            "content": "E.1 ChemEval We consider the L1 and L2 level tasks in ChemEval as text-centric tasks, the L3 level tasks as molecule-centric tasks, and the L4 level tasks as reaction-centric tasks. Moreover, there are tasks that we can not achieve feasible grading in ChemEval. We temporarily skip these tasks. The raw results are demonstrated in Table 3. As illustrated in Table 3, ChemDFM-R manages to achieve competitive performance in the textcentric tasks compared with the cutting-edge LLMs, while achieve SOTA performance across all the molecule-centric tasks and large portion of the reaction-centric tasks. detailed analysis of the task characteristics reveals that ChemDFM-R tends to perform less effectively on tasks involving numerical prediction, which will be key focus of our future optimization efforts. 20 -"
        },
        {
            "title": "R\nM\nF\nD\nm\ne\nh\nC",
            "content": "i - 4 4 1 - 3 Q S D 4 1 - 3 Q ) h ( 1 - ) h ( 4 - G"
        },
        {
            "title": "M\nF\nD\nm\ne\nh\nC",
            "content": ". 5 1 - 8 -"
        },
        {
            "title": "M\nF\nD\nm\ne\nh\nC",
            "content": ". 0 1 - 3 1 -"
        },
        {
            "title": "M\nL\nL\nm\ne\nh\nC",
            "content": "O 0 2 - - I c e s 5 6 . 0 0 0 . 0 5 8 . 0 3 1 . 0 2 6 . 0 6 2 . 2 7 . 0 3 7 . 0 5 9 . 0 5 9 . 0 9 4 . 0 5 7 . 0 6 . 0 9 6 . 0 5 1 . 0 0 5 . 0 0 3 . 0 4 8 . 5 7 . 0 5 8 . 0 5 5 . 0 5 3 . 0 0 0 . 0 3 7 . 7 5 . 0 5 2 . 0 5 4 . 0 5 3 . 0 0 4 . 0 0 0 . 0 3 . 0 5 1 . 0 0 6 . 0 0 2 . 0 9 0 . 0 0 0 . 5 6 . 0 0 0 . 0 5 8 . 0 0 1 . 0 7 5 . 0 6 2 . 8 6 . 0 2 7 . 0 5 9 . 0 5 9 . 0 6 7 . 0 0 9 . 5 7 . 0 7 6 . 0 3 1 . 0 0 5 . 0 0 2 . 0 9 6 . 0 6 . 0 5 5 . 0 5 1 . 0 0 0 . 0 0 0 . 0 6 6 . 4 3 . 0 8 1 . 0 0 0 . 0 0 3 . 0 0 3 . 0 0 0 . 2 2 . 0 0 1 . 0 5 3 . 0 5 4 . 0 7 0 . 0 5 0 . 0 8 . 0 0 0 . 0 0 8 . 0 7 0 . 0 7 6 . 0 0 2 . 5 6 . 0 4 5 . 0 0 9 . 0 5 9 . 0 1 6 . 0 5 8 . 5 9 . 0 5 6 . 0 8 1 . 0 0 5 . 0 0 3 . 0 2 4 . 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 9 5 . 8 3 . 0 0 0 . 0 5 3 . 0 5 2 . 0 5 3 . 0 0 0 . 5 3 . 0 1 1 . 0 6 0 . 0 5 2 . 0 0 1 . 0 0 0 . 0 9 . 0 0 0 . 0 5 9 . 0 4 0 . 0 0 7 . 0 8 2 . 1 7 . 0 9 7 . 0 5 9 . 0 5 9 . 0 1 7 . 0 0 0 . 5 7 . 0 2 6 . 0 0 1 . 0 5 5 . 0 5 2 . 0 0 1 . 5 0 . 0 0 0 . 0 5 0 . 0 0 0 . 0 0 0 . 0 7 5 . 0 3 . 0 5 0 . 0 0 1 . 0 5 0 . 0 5 2 . 0 0 0 . 8 1 . 0 0 1 . 0 8 1 . 0 5 2 . 0 1 3 . 0 5 0 . 5 7 0 . 0 0 0 . 5 8 0 . 9 0 0 . 1 6 0 . 4 2 0 . 5 6 0 . 3 7 0 . 5 9 0 . 5 9 0 . 4 7 0 . 5 8 0 . 5 7 0 . 0 7 0 . 4 2 0 . 0 4 0 . 0 3 0 . 3 4 0 . 0 0 0 . 5 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 4 5 0 . 1 4 0 . 0 0 0 . 5 0 0 . 5 1 0 . 2 0 0 . 0 0 0 . 3 2 0 . 8 0 0 . 0 0 0 . 5 1 0 . 5 1 0 . 0 0 0 . 5 7 0 . 0 0 0 . 0 8 0 . 5 1 0 . 7 6 0 . 0 2 0 . 0 7 0 . 5 7 0 . 5 7 0 . 5 9 0 . 9 7 0 . 5 9 0 . 0 8 0 . 7 6 0 . 4 1 0 . 0 5 0 . 5 3 0 . 0 0 0 . 0 0 0 . 5 0 0 . 1 1 0 . 3 2 0 . 0 0 0 . 5 0 0 . 5 2 0 . 5 2 0 . 5 9 0 . 9 4 0 . 0 3 0 . 0 3 0 . 4 0 0 . 2 0 0 . 0 2 0 . 5 0 0 . a r C - T 0 6 0 . 0 4 0 . 0 1 0 . 0 0 0 . 0 0 0 . 0 0 0 . 4 6 0 . 7 3 0 . 5 3 0 . 0 0 0 . 0 0 0 . 0 0 0 . 5 0 0 . 0 0 0 . 9 0 0 . 9 1 0 . s i e - c M a r C - t R 8 0 0 . 0 1 0 . 0 1 0 . 5 3 0 . 0 0 0 . 2 2 0 . 7 0 0 . 0 1 0 . 5 5 0 . 8 1 0 . 5 0 0 . 2 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 2 2 0 . 9 0 0 . 5 0 0 . 0 0 0 . 9 0 0 . 0 0 0 . 0 5 . 0 5 0 0 . 0 7 . 2 1 0 . 9 5 . 0 2 . 0 7 4 . 0 3 8 . 0 2 . 0 0 4 0 . 6 2 . 0 5 5 . 0 2 . 0 4 5 . 2 2 . 0 0 4 . 5 1 . 0 6 7 . 5 2 . 0 5 4 . 0 1 . 0 0 0 . 0 0 . 0 1 6 . 9 3 . 0 8 0 . 0 2 . 0 9 1 . 5 0 . 0 0 0 . 1 7 . 0 8 1 . 3 0 . 0 0 2 . 5 0 . 0 0 1 0 . 5 . 0 0 0 . 0 5 . 0 7 1 0 . 4 4 . 0 0 0 . 0 9 5 . 0 0 7 . 0 5 7 . 0 5 9 . 0 7 4 . 0 0 9 . 0 5 5 . 0 6 4 . 0 2 1 . 0 0 5 . 0 3 1 . 0 7 5 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 3 5 . 0 6 3 . 0 3 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 7 2 . 0 9 1 . 0 0 0 . 0 0 2 . 0 4 1 . 0 0 0 . 0 0 4 . 0 0 0 . 5 5 . 0 1 0 . 0 0 0 . 0 5 0 . 0 4 3 . 0 8 5 . 0 7 . 0 5 9 . 0 1 2 . 0 0 8 . 0 0 0 . 0 6 5 . 9 1 . 0 0 4 . 0 0 2 . 0 4 0 . 0 0 0 . 0 0 0 . 0 0 . 0 0 0 . 0 0 0 . 0 0 5 . 0 0 3 . 0 0 0 . 0 0 . 0 0 0 . 0 0 0 . 0 0 0 . 0 7 7 . 0 0 2 . 0 0 . 0 0 2 . 0 3 0 . 0 0 0 . 0 c c A"
        },
        {
            "title": "U\nE\nL\nB",
            "content": "1 1 1 1 1 1 1 1 1 F"
        },
        {
            "title": "U\nE\nL\nB",
            "content": "c 1 F"
        },
        {
            "title": "M\nE",
            "content": "c A"
        },
        {
            "title": "U\nE\nL\nB",
            "content": "c c A c S S c A r c s M a k F a S"
        },
        {
            "title": "E\ne\nm\nT",
            "content": "i"
        },
        {
            "title": "E\nM",
            "content": "r C"
        },
        {
            "title": "E\nd\nl\ne\ni\nY",
            "content": "n b G O"
        },
        {
            "title": "G\nN\nl\no\nM",
            "content": "F 2 U 2 I E S 2 U P 2 I S 2 S"
        },
        {
            "title": "C\nP\nl\no\nM",
            "content": "C 2 c u R R R S t c m e T P r e t r I Table 3: The detailed benchmark results of different models on ChemEval. 21 Figure 9: Comparison of rationales generated by DeepSeek-R1 with and without additional input information. We mark the correct analyses in the rationale as green, while the wrong ones as red. E.2 SciKnowEval We group the tasks in SciKnowEval based on their input and output. Specifically, the task is classified as text-centric task if there is no SMILES appear in its input or output, as reaction-centric task if there are reaction SMILES appear in its input or output, and as molecule-centric task otherwise. Due to budget limit, we currently skip the tasks that require GPT-4o for grading. The raw results are demonstrated in Table 4. As illustrated in Table 4, ChemDFM-R achieves competitive performance on SciKnowEval compared to cutting-edge LLMs. It is worth noting that ChemDFM-Rs performance advantage is less pronounced on SciKnowEval than on ChemEval. This is primarily because most tasks in SciKnowEval are formulated as multiple-choice questions, which substantially reduce the burden on the models comprehension and generation processes, allowing it to arrive at correct answers through shortcuts such as option comparison and elimination."
        },
        {
            "title": "F More Rationale Analysis",
            "content": "As illustrated in Figure 10, when asked to describe molecule given by SMILES, ChemDFM-R first analyzes the functional groups present in the molecule, such as the alkene group, the phosphate monoester group, and the pyrrolic group. Then, ChemDFM-R successfully correlates the composition and connectivity of these functional groups with metabolic pathways and further manages to identify the molecule as coenzyme derivative. After that, it recognizes the deprotonated thiolester linkage in the molecule and further narrows down the molecule to an acyl-CoA derivative. Finally, ChemDFMR gives relatively comprehensive description of the molecule. ChemDFM-R even provides the potential role of this molecule in metabolic processes in its rationale, further demonstrating its strong reasoning ability as well as the value of the rationale as complement to the final answer. 22 -"
        },
        {
            "title": "R\nM\nF\nD\nm\ne\nh\nC",
            "content": "i - 4 4 1 - 3 Q S D 4 1 - 3 Q ) h ("
        },
        {
            "title": "1\nR",
            "content": "- ) h ( 4 - G"
        },
        {
            "title": "M\nF\nD\nm\ne\nh\nC",
            "content": "5 . 1 - 8 -"
        },
        {
            "title": "M\nF\nD\nm\ne\nh\nC",
            "content": "0 . 1 - 3 1 -"
        },
        {
            "title": "M\nL\nL\nm\ne\nh\nC",
            "content": "O 0 2 - - I s T 0 8 0 . 8 9 0 . 8 9 0 . 8 9 0 . 2 9 0 . 7 9 0 . 7 2 0 . 4 5 0 . 4 4 0 . 1 8 0 . 0 9 0 . 5 4 0 . 1 5 0 . 7 3 0 . 0 2 0 . 4 3 0 . 3 8 0 . 9 9 0 . 0 9 0 . 9 8 0 . 8 9 . 0 9 9 . 9 9 . 0 3 9 . 0 6 9 . 0 0 1 0 . 2 9 0 . 5 5 0 . 0 8 . 0 6 9 0 . 8 4 0 . 4 . 0 3 6 0 . 5 4 0 . 7 5 0 . 5 7 . 0 9 9 . 5 9 0 . 4 8 . 8 9 . 0 9 9 0 . 9 . 0 2 9 . 0 6 . 0 3 7 0 . 1 9 . 0 1 5 0 . 3 8 . 4 8 . 0 2 4 . 0 1 . 0 1 3 . 8 3 . 0 7 3 . 4 4 . 0 4 9 . 3 8 . 0 6 8 0 . 7 9 . 6 9 0 . 9 9 0 . 3 9 . 5 9 0 . 1 1 0 . 9 7 . 2 6 0 . 2 8 0 . 2 4 . 1 4 0 . 3 1 0 . 4 0 . 9 3 0 . 7 0 0 . 9 6 . 2 8 0 . 3 8 0 . 4 8 . 9 9 . 0 8 9 . 0 9 9 . 0 4 9 . 0 7 9 . 0 8 0 . 4 5 . 0 2 5 . 0 1 8 . 0 1 7 . 0 8 3 . 0 9 0 . 7 1 . 0 7 3 . 0 1 3 . 0 9 3 . 0 1 9 . 0 0 7 . s i e - T 6 8 . 0 0 0 . 1 9 9 . 0 0 0 . 5 9 . 0 7 9 . 0 0 1 . 0 2 5 . 0 7 3 . 0 5 8 . 0 8 . 0 9 9 . 0 7 9 . 0 7 9 . 0 8 8 . 0 6 9 . 2 2 . 0 7 3 . 0 5 4 . 0 5 6 . 0 a r C - c M 7 8 . 4 4 . 0 4 1 . 0 6 2 . 0 5 3 . 0 6 4 . 0 1 6 . 3 8 . 0 8 4 . 0 2 2 . 0 3 2 . 0 0 3 . 0 6 2 . 9 8 . 0 a r C - t R 8 4 . 0 1 4 . 0 6 9 . 0 7 7 . 8 7 . 0 8 9 . 0 5 9 . 0 7 9 . 0 6 8 . 0 5 9 . 2 1 . 0 7 3 . 0 4 4 . 0 0 6 . 0 0 7 . 0 8 3 . 3 2 . 0 7 1 . 0 1 3 . 0 5 3 . 0 4 8 . 0 2 9 . 8 7 . 0 9 7 0 . 9 9 0 . 7 9 . 8 9 0 . 9 8 0 . 6 9 . 6 1 0 . 3 3 0 . 4 5 . 5 7 0 . 1 7 0 . 4 3 . 1 2 0 . 6 2 0 . 3 3 . 1 3 0 . 3 5 0 . 3 9 . 3 8 0 . 5 7 0 . 6 9 . 4 9 0 . 5 9 0 . 3 8 . 3 9 0 . 1 0 0 . 5 3 . 4 5 0 . 9 6 0 . 0 6 . 2 3 0 . 4 1 0 . 6 2 . 9 3 0 . 3 3 0 . 4 6 . 9 3 0 . 4 4 0 ."
        },
        {
            "title": "L\nm\ne\nh\nC",
            "content": ". n e a . P . d o C"
        },
        {
            "title": "V\nH\nm\ne\nh\nC",
            "content": "I"
        },
        {
            "title": "R\nm\ne\nh\nC",
            "content": ". n a . m d . T M T S C . C N d P . P . l . C g l . . P M r . S . l d n c s h s e Table 4: The detailed benchmark results of different models on SciKnowEval. 23 Figure 10: The overview of the training pipeline of ChemDFM-R on the molecule captioning task. Figure 11: The overview of the training pipeline of ChemDFM-R on the SMILES to IUPAC task. 24 Figure 12: An example of reliable human-AI collaboration using ChemDFM-R. We draw inspiration from this conversation from Li et al. [2025]. This example illustrates process of error detection and correction with the help of rationales. Figure 11 showcases an example response of ChemDFM-R when asked to generate the IUPAC name of the given molecule. The IUPAC name is the standard name for molecule, assigned according to the rules established by the International Union of Pure and Applied Chemistry (IUPAC). It can effectively reflect the functional groups present in the molecule and their connectivity. Therefore, ChemDFM-R starts its reasoning with comprehensive analysis of the functional groups of the given molecule. Then, it emphasizes the importance of correctly labeling the atoms, which is precisely an area where large language models are particularly prone to errors. After this, ChemDFM-R follows the rule of IUPAC naming and divides the molecule into its principal structural components. It also specifically points out the N-substitution with the sulfonamide group. Finally, complicated and correct IUPAC name is predicted by ChemDFM-R. More Examples of Reliable Human-AI Collaboration Figure 12 illustrates conversation starting from the same turn as that illustrated in the main text. In this conversation, we focus on fully understanding the mechanism of the oxygen evolution reaction (OER). Suppose, as newbie, we are unable to determine the correctness of the answer. With the help of ChemDFM-Rs rationale, we could easily discover that the key step of the reaction mentioned in the rationale, which is the formation of an oxygen-oxygen bond, is absent in the answer. This could serve as reminder that the answer could be incorrect, and drive us to further request the model to clarify this inconsistency. After this follow-up inquiry, the model provided better answer. Figure 13 is conversation about reaction proposed in Yao et al. [2025]. We first ask ChemDFM-R to explain the reason for the different ratios of the chiral epoxy products. Although the models answer is relatively broad, ChemDFM-R thoroughly analyzes the influence factors in its rationale, including the bonds geometry and the spatial arrangement of substituents around the double bond, 25 Figure 13: An example of reliable human-AI collaboration using ChemDFM-R. We draw inspiration from this conversation from Yao et al. [2025]. This example illustrates process of information completion. which is not included in the answer. With this information, we can further pursue the follow-up question and obtain an improved answer."
        }
    ],
    "affiliations": [
        "Jiangsu Key Lab of Language Computing, Suzhou 215123, China",
        "School of Chemistry and Chemical Engineering Shanghai Jiao Tong University, Shanghai 200240, China",
        "Suzhou Laboratory, Suzhou, China",
        "X-LANCE Lab, School of Computer Science MoE Key Lab of Artificial Intelligence, SJTU AI Institute Shanghai Jiao Tong University, Shanghai 200240, China"
    ]
}