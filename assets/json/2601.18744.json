{
    "paper_title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
    "authors": [
        "Fangxu Yu",
        "Xingang Guo",
        "Lingzhi Yuan",
        "Haoqiang Kang",
        "Hongyu Zhao",
        "Lianhui Qin",
        "Furong Huang",
        "Bin Hu",
        "Tianyi Zhou"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/."
        },
        {
            "title": "Start",
            "content": "TSRBENCH: Comprehensive Multi-task Multi-modal Time Series"
        },
        {
            "title": "Reasoning Benchmark for Generalist Models",
            "content": "Fangxu Yu 1 Xingang Guo 2 Lingzhi Yuan 1 Haoqiang Kang 3 Hongyu Zhao 1 Lianhui Qin 3 Furong Huang 1 Bin Hu 2 Tianyi Zhou"
        },
        {
            "title": "Abstract",
            "content": "1. Introduction 6 2 0 2 6 2 ] . [ 1 4 4 7 8 1 . 1 0 6 2 : r Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBENCH, comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBENCH features: (i) diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. (ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBENCH. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate contextaware forecasting, indicating decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBENCH provides standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/. 1University of Maryland, College Park 2University of Illinois at UrbanaChampaign 3University of California, San Diego 4Mohamed bin Zayed University of Artificial Intelligence. Correspondence to: Tianyi Zhou <tianyi.david.zhou@gmail.com>. 1 Time series data pervades real-world environments and underpins decision-making across high-stakes domains, including finance (Dong et al., 2024), healthcare (Morid et al., 2023), and industrial systems (Yan et al., 2024). Since substantial portion of real-world information is inherently temporal, reasoning on time series becomes core capability for building generalist models that can reliably solve practical problems. Equipping models with such reasoning abilities enables automated systems to interpret temporal signals in context, supporting downstream applications such as education (Mao et al., 2024), clinical management (Matowe et al., 2003), disaster forecasting (Hakim et al., 2024), and scientific discovery (Yu et al., 2025c). Given the critical importance of time series reasoning, there is pressing need for standardized and automated evaluation frameworks that enable comprehensive assessment and comparison. However, existing work remains largely anchored in traditional time series analysis, which adopts reductive view by treating time series as isolated numerical sequencesthereby stripping away the causal structure and semantic context essential for real-world problemsolving. Recent benchmarks have begun to integrate context (Williams et al., 2024; Liu et al., 2024; Cai et al., 2024a; Kong et al., 2025; Wu et al., 2025), yet they predominantly target surface-level pattern understanding, which is insufficient for complex problem-solving. Other initiatives that attempt to probe reasoning capabilities (Chen et al., 2025b; Wang et al., 2025c; Guan et al., 2025) often remain confined to narrow domains or restricted task scopes. This systemic limitation underscores the urgent demand for comprehensive, multi-dimensional benchmark specifically designed to stress-test the full spectrum of time series reasoning. In this paper, we introduce TSRBENCH, large-scale and comprehensive benchmark curated to assess the time series problem-solving capability of generalist models across multiple domains and tasks. TSRBENCH extensively collect, select, and synthesize problems from 14 domains. This extensive collection has culminated in benchmark comprising 4125 problems. We categorize the problems into four TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Table 1: Comparison with Representative Time Series Benchmarks. Modality denotes the input format, where and represent textual and visual representations of time series, respectively. Benchmark Forecasting-Centric TimeMMD (Liu et al., 2024) CiK (Williams et al., 2024) Analysis-Centric TimeSeriesExam (Cai et al., 2024a) MTBench (Chen et al., 2025b) EngineMT-QA (Wang et al., 2025c) SciTS (Wu et al., 2025) TimeMQA (Kong et al., 2025) TSR-SUITE (Guan et al., 2025) TSRBench (Ours) Scale & Diversity Reasoning Capabilities Modality # Domains # Tasks # Questions Multivariate Perc. Reas. Pred. Dec. 9 8 1 2 1 12 12 9 14 1 1 5 4 4 7 5 15 16K 0.3K 0.7K 2.4K 11K 51K 200K 4K 4.1K ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ T, T T, V, T+V major dimensions of time series abilitiesPerception, Reasoning, Prediction, and Decision-Making, which comprises 15 tasks for different abilities (See Figure 1 for examples). Additionally, it supports four modalities of time series for generalist models: text, image, text-image interleaved, and time series embeddings, providing comprehensive evaluation and comparison that modern AI systems could handle. To facilitate the evaluation of LLMs and MLLMs, we design unified evaluation setup. Time series are transformed into textual sequences of numbers for LLMs and into plots for VLMs. For proprietary models, we evaluate text-form (T), vision-form (V), and combined (T+V) representation to test modality fusion. Based on TSRBENCH, we evaluate 6 leading proprietary models (e.g., GPT-5 (OpenAI, 2025)), 12 open-source LLMs (e.g., Qwen3 (Yang et al., 2025a)), 13 open-source VLMs (e.g., InternVL3.5 (Wang et al., 2025b)). Our evaluation yields three key findings: i) While current generalist models demonstrate strong performance on time series perception, they struggle significantly with complex reasoning, forecasting, and decision-making tasks. ii) The scaling law holds for most time series reasoning tasks on both LLMs and VLMs, with the notable exception of time series prediction. iii) Time Series Prediction tasks have weak relationships with other tasks. iv) Textual and visual representations of time series are strongly complementary, often solving different sets of problems, yet current models struggle to leverage both modalities simultaneously for improved performance. Additionally, our ablation studies provide practical insights into model design, particularly regarding the impact of visualization resolution, tool augmentation, and inference-time reasoning effort. 2. Related Work Time Series Benchmarks. Time series has long been studied. In the long run, existing benchmarks primarily focus on time series analysis tasks, including forecasting (Godahewa et al., 2021; Bauer et al., 2021; Qiu et al., 2024; Wang et al., 2024b; Li et al., 2025; Hu et al., 2025), classification (Ismail Fawaz et al., 2019; Ruiz et al., 2020), imputation (Du et al., 2024b; Kazijevs & Samad, 2023), and anomaly detection (Lai et al., 2021; Wenig et al., 2022; Zhou & Yu, 2024). Recent works begin to explore whether LLMs/MLLMs can understand the time series (Tan et al., 2024; Merrill et al., 2024). TimeSeriesExam (Cai et al., 2024a) evaluates the time series understanding of LLMs and VLMs through synthetic data, but only focuses on holistic perception. MTBench (Chen et al., 2025b) combines news reports with time series to assess models reasoning capabilities, but is restricted to narrow domains such as finance and weather. TimeMMD (Liu et al., 2024) and CiK (Williams et al., 2024) focus on the time series forecasting task with the aid of contextual events or background. TSR-SUITE (Guan et al., 2025) and EngineMT-QA (Wang et al., 2025c) only cover narrow reasoning tasks, and TimeMQA (Kong et al., 2025) evaluates LLMs mainly on traditional time series analysis. General Reasoning Benchmarks. Numerous benchmarks have been developed to evaluate the general reasoning and problem-solving capabilities of generalist models. Notable examples include MMLU (Yue et al., 2024) and MMLUPro (Yue et al., 2024), GPQA (Rein et al., 2024), which assesses knowledge across wide range of subjects. Benchmarks in science domains (Zhao et al., 2025; Wang et al., 2025a; He et al., 2024; Xu et al., 2025b; Zou et al., 2024), and engineering domains (Syed et al., 2024; Kevian et al., 2024; Guo et al., 2025b) evaluate problem-solving ability. In addition, benchmarking in social scenarios (Le et al., 2019; Kim et al., 2023; Yu et al., 2025a) evaluates the ability to understand human minds. In multimodal domains, benchmarks range from scientific domains (Lu et al., 2023; Wang et al., 2024a) to embodied reasoning (Yang et al., 2025b; Du et al., 2024a) and video reasoning (Li et al., 2024; Cheng et al., 2025). While general reasoning benchmarks may sporadically incorporate time series-related tasks, they lack 2 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Figure 1: Overview of TSRBENCH. TSRBENCH evaluates generalist models across four core capabilities: Perception, Reasoning, Prediction, and Decision-Making, each including multiple different tasks from real applications. comprehensive and systematic evaluation framework dedicated to temporal dynamics. We introduce TSRBENCH to fill this critical gap. 3. TSRBENCH 3.1. Overview of TSRBENCH We introduce TSRBENCH, comprehensive benchmark comprising 4125 instances across 14 domains to assess generalist models on 4 key dimensions in time series reasoning: Perception, Reasoning, Forecasting, and DecisionMaking. TSRBENCH consists of 15250 time series from 14 domains, spanning 15 diverse tasks. Figure 2 provides visual overview of our taxonomy and task distribution. See domain distribution in Figure 11 and G.1 for more cases. 3.2. Time Series Perception This dimension evaluates the models ability to derive conclusions from temporal patterns and prior knowledge, covering four tasks: i) Pattern Analysis ii) Noise Understanding iii) Anomaly Detection, and iv) Similarity Analysis. Pattern Analysis (PA) evaluates the models ability to discern fundamental time series properties, encompassing structural characteristics such as trend, cyclicity, stationarity, and core statistical attributes like the series mean. Noise Understanding (NU) challenges the model to quantify and characterize the scale and magnitude of stochastic noise Figure 2: Statistics of tasks in TSRBENCH. inherent in the data. Anomaly Detection (AD) probes the models capacity to identify and classify out-of-distribution observations; this extends beyond mere localization (e.g., start, middle, end) to include the characterization of anomaly types (e.g., pattern cutoffs, signal flips) and the conceptual grasp of the underlying pattern without the perturbation. Finally, Similarity Analysis (SA) assesses the models proficiency in comparative reasoning between two or more series, determining shared patterns, congruent statistical properties 3 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models (e.g., variance or noise profiles), commonality in underlying data distributions, or coherence in trend direction. 3.3. Time Series Reasoning This dimension evaluates the ability to derive conclusions from temporal patterns and prior knowledge, covering seven tasks: i) Etiological Reasoning, ii) Causal Discovery, iii) Abductive Reasoning, iv) Temporal Relation Reasoning, v) Numerical Reasoning, vi) Deductive Reasoning, vii) Inductive Reasoning. Etiological Reasoning (ER) involves inferring the generative sources or underlying causal factors responsible for an observed time series. Questions in this task require both time series perception and commonsense reasoning ability. Causal Discovery (CD) focuses on determining the existence and direction of causal relationships between multiple time series. The causal relationship is determined by both the patterns of time series and contextual backgrounds. Abductive Reasoning (AR) evaluates models ability to infer the most plausible latent event that explains change in the time series, given both historical and future observations. This task requires the model not only to localize the timestamp at which the event occurs, but also to detect the resulting change in the series and generate reasonable explanatory hypothesis for it. Temporal Relation Reasoning (TR) challenges the model to determine the order of events based on the observations on time series. This task evaluates localization of events on time series and establishes the correct chronological sequence of events embedded within time series. Numerical Reasoning (NR) challenges the models ability to perform quantitative calculations that require contextual understanding of the time series domains. Deductive Reasoning (DR) requires the model to derive logically consistent conclusions from predefined rules, which requires the model to accurately apply the rules to the time series to draw the final conclusion. Inductive Reasoning (IR) evaluates the models ability to infer principles or rules (e.g., periodicity) and patterns based on historical observations and domain knowledge. After that, the model needs to apply the inferred rules to predict future events at specific time. Unlike standard forecasting, which prioritizes minimizing numerical error through curve-fitting, IR requires models to abstract the underlying rules to predict specific future events. These seven tasks comprehensively assess the models capacity to interpret complex temporal dynamics, infer underlying causal structures, and apply logical principles to time series data beyond pattern recognition. 3.4. Time Series Prediction We evaluate predictive capabilities through two tasks: i) Time Series Forecasting and ii) Event Prediction. Time Series Forecasting (TSF) evaluates the prediction of future numerical values conditioned on both historical observations and contextual events. This challenges the model to reason about the interaction dynamics between the continuous series and the discrete events. To reduce the difficulty of directly predicting numerical series for generalist models (indicated by (Tan et al., 2024)), we transform the forecasting tasks into multiple-choice. This challenges the model to reason about the interaction dynamics between the continuous series and the discrete events. Event Prediction (EP) involves anticipating future discrete events given the historical time series. This requires synthesizing pattern analysis with commonsense or domain-specific reasoning to predict what events will happen in the future. 3.5. Time Series Decision-Making This dimension assesses the ability of models to make decisions based on the understanding of both time series and context. We assess this through two aspects: i) Qualitative Decision-Making and ii) Quantitative Decision-Making. Qualitative Decision-Making (QualDM) requires the model to leverage pattern analysis within time series and contextual knowledge to inform decisions. This task assesses the models ability to make correct decisions under complex time series and knowledge. Quantitative Decision-Making (QuantDM) challenges the model to determine an optimal course of action by evaluating the outcomes of multiple possible operational procedures. This task assesses the models ability to accurately simulate the application of distinct sets of rules and environmental constraints to given time series. It requires the model to quantitatively compare the resulting performance metrics from each procedure and identify the single procedure that yields the optimal result. 3.6. Data Collection Principles for TSRBENCH To accomplish high-quality dataset, we have the following considerations when collecting data: (1) High TextTimeseries Alignment. The context should be highly aligned with the time series and complement the information, and be indispensable for reasoning. (2) Domain Diversity and Generalizability. The data should be sourced from wide array of domains to ensure the benchmark tests for general reasoning capabilities and prevent models from succeeding via domain-specific overfitting. (3) Verifiable and Unambiguous Ground Truth. To ensure correctness, we employ two strategies for answer generation: (i) using high-fidelity simulations (e.g., Python code) where the ground-truth is unambiguously determined, and (ii) retrieving and extracting from the time series or its contexts. (4) Synthetic Data for Quantitative Reasoning. While realworld data provides essential complexity, it often lacks the high-precision ground truth required for rigorous quantitative evaluation. To bridge this gap, we incorporate synthetic TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models data via simulations (e.g., chaotic physical systems and algorithmic trading backtesting). This approach ensures that the underlying data-generating processes are unambiguously determined, providing verifiable and noise-free platform to stress-test models capacity for precise numerical reasoning and deductive logic. More details of data construction are provided in Appendix D. 4. Experiments 4.1. Experimental Setups. We evaluate both open-source and proprietary LLMs, VLMs, and Time Series LLMs, including 6 proprietary models, and 26 SOTA open-source models. For proprietary models, we evaluate DeepSeek-V3.2 (Guo et al., 2025a), Gemini2.5-Flash (Comanici et al., 2025), o4-mini, and GPT-5. Open-source LLMs will include Qwen2.5(3B / 7B / 72B), Qwen3 (8B / 32B / 235B-A22B) (Yang et al., 2025a), Gemma3 (12B / 27B) (Team et al., 2025b), InternLM3 (8B) (Cai et al., 2024b), and GPT-OSS (20B / 120B) (Agarwal et al., 2025). Open-source VLMs include Llama-4Scout-17B-16E-Instruct (Platforms, 2025), Qwen2.5-VL (3B / 7B / 72B) (Bai et al., 2025), Qwen3-VL(8B / 32B / 235B-A22B) (Yang et al., 2025a), InternVL3.5 (1B / 8B/ 38B) (Wang et al., 2025b), MiniCPM-V-4.5 (8B) (Yao et al., 2024), and MiMo-VL-RL (7B) (Team et al., 2025a). For TSLLMs, we evaluate TS-Reasoner (7B) (Yu et al., 2025b) and ChatTS (14B) (Xie et al., 2024). We enable reasoning for all the models. Time series are transformed into textual sequences of numbers for LLMs, transformed into plots via code for VLMs, and transformed into embeddings via model projectors for TSLLMs. Specifically, we adopt standardized visual encoding protocol to ensure consistency. Based on our ablation study ( 4.4), we fix the resolution at 100 PPI to balance token efficiency with feature visibility. For proprietary models, we feed textual, visualized, and both forms to evaluate. We use accuracy as the primary metric in our experiments. 4.2. Main Results Table 2 summarizes the results for all tasks. Overall, current generalist models demonstrate strong performance on time series perception but struggle with reasoning, prediction, and decision-making tasks. Among proprietary models, we observe that GPT-5 (T+V), which uses both textual and visual time series, achieves the highest overall accuracy (55.6%). For open-source LLMs, Qwen2.5-72B delivers the strongest overall performance (42.4%). For open-source VLMs, Qwen3-VL-32B achieves the highest overall accuracy (44.9%). Time series LLMs perform competitively with similar-sized LLMs and VLMs, yet still have large gap from advanced models. Additionally, reasoning efforts significantly improve performance, as evidenced by Figure 3: Overall accuracy and model sizes. Each plot illustrates the relationship between the log-scaled model size and the performance across all models. The left and right plots correspond to LLMs and VLMs, respectively. Figure 4: Spearmans rank correlation (ρ) between tasks. \"(*)\" marks correlations with p-values ď 0.05. the overall accuracy increases for o4-mini-high (+4.3%) and GPT-5-mini-high (+7.2%) compared to their respective baseline (T+V) models. Nevertheless, substantial performance gap remains between the top proprietary model (GPT-5 (T+V) at 55.6%) and the best-performing open-source models (Qwen3-VL-32B at 44.9%). 4.3. Further Findings Finding 1. The scaling law still holds for most of the time series reasoning tasks on both LLMs and VLMs, except for time series prediction. We quantitatively analyze the relationship between model scale and performance on time series reasoning tasks by calculating Spearmans rank correlation for both (i) LLMs and (ii) VLMs. Figure 3 illustrates the performance trends across model families, revealing clear positive correlation between overall accuracy and model size. To provide deeper insight, we further investigate this correlation across individual capability dimensions. As detailed in Table 3, while Perception, Reasoning, and Decision-Making exhibit strong positive correlations with model size, Prediction tasks notably diverge from this trend for both LLMs and VLMs. This discrepancy indicates that current generalist models, even when scaled and provided with context, continue to struggle with effective forecasting (Tan et al., 2024). 5 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Table 2: Model performance on TSRBENCH, where the results of proprietary models are shown with blue background, and results of open-source models are shown with green background. For proprietary models, \"T\" denotes inputting textual time series, \"V\" to visualized time series, and \"T+V\" to using both. o4-mini and GPT-5(-mini) employ low-reasoning efforts by default. The suffix \"-high\" indicates employing high-reasoning efforts. Best results are shown in bold. Model Perception Reasoning Prediction Decision Overall PR NU AD SA ER CD AR TR NR DR IR TSF EP QualDM QuantDM DeepSeek-V-3.2 (T) o4-mini (T) GPT-5-mini (T) GPT-5 (T) Qwen2.5-3B Qwen2.5-7B Qwen2.5-72B Qwen3-1.7B Qwen3-8B Qwen3-32B Qwen3-235B-A22B Gemma3-12B-it Gemma3-27B-it InternLM3-8B GPT-OSS-20b GPT-OSS-120b o4-mini (V) GPT-5-mini (V) GPT-5 (V) Qwen2.5-VL-3B Qwen2.5-VL-7B Qwen2.5-VL-72B Qwen3-VL-8B Qwen3-VL-32B Qwen3-VL-235B-A22B Phi4-Multimodal-8B Llama-4-Scout-17B-16E InternVL3.5-1B InternVL3.5-8B InternVL3.5-38B MiniCPM-V-4.5-8B MiMo-VL-7B-RL Claude-4.5-Haiku (T+V) Gemini-2.5-Flash (T+V) o4-mini (T+V) o4-mini-high (T+V) GPT-5-mini (T+V) GPT-5-mini-high (T+V) GPT-5 (T+V) 67.7 73.1 72.2 75.7 46.4 50.7 55.3 45.8 51.8 54.7 66.0 51.5 56.1 51.2 64.2 66.8 77.4 78.7 83.6 44.2 48.2 60.9 60.4 73.9 65.8 52.3 41.5 47.2 60.9 58.8 63.6 58.2 57.1 75.2 79.0 82.5 78.4 80.3 84. 56.3 65.5 59.8 62.1 51.7 50.6 55.2 59.8 56.3 52.9 56.3 59.8 59.8 42.5 58.6 56.3 72.4 69.0 72.4 50.6 55.2 55.2 58.6 59.8 65.5 46.0 44.8 49.4 55.2 60.9 56.3 64.4 41.4 73.6 70.1 71.3 65.5 75.9 72.4 57.4 61.2 63.6 61.2 33.3 41.1 47.3 38.0 48.8 50.4 59.7 48.9 48.1 35.7 50.4 59.8 66.7 69.0 69.8 41.9 42.6 55.8 51.9 59.7 61.2 41.9 38.8 38.8 52.7 55.8 56.6 52.7 48.8 69.0 65.1 64.3 63.6 63.6 61. 64.6 71.7 69.9 69.0 51.3 54.9 66.4 51.3 56.6 62.8 67.3 65.5 68.1 54.0 69.0 69.0 73.5 69.0 73.5 53.1 60.2 77.0 61.1 76.1 71.7 48.7 46.9 46.9 64.6 69.9 62.8 65.5 55.8 79.6 76.1 76.1 72.6 75.2 70.8 Textual Times Series as Input 35.7 39.0 27.7 55.3 25.0 32.3 58.0 30.1 29.3 35.9 34.7 34.7 37.0 24.7 32.0 26.3 70.7 58.0 62.7 85.3 38.0 46.0 62.0 48.7 57.3 66.0 86.7 42.0 66.7 48.0 48.7 58. 19.4 34.4 39.4 68.8 21.2 28.1 33.8 30.0 23.1 27.5 28.1 23.7 21.9 23.8 17.5 31.3 27.3 64.7 65.2 72.2 34.8 33.2 38.2 27.0 36.5 37.5 44.8 33.2 36.0 30.0 43.3 48.5 Visual Times Series as Input 30.7 41.0 37.0 24.0 25.3 52.0 38.8 44.7 47.7 22.3 53.0 24.3 38.3 43.0 24.3 34.7 55.3 58.7 81.3 42.0 57.3 58.0 50.0 69.3 84.7 28.7 75.3 46.7 60.0 52.7 54.7 65.3 39.4 41.9 68.1 25.6 26.9 30.6 24.4 39.4 25.0 23.1 28.1 24.4 27.5 31.2 20.6 30. 56.2 54.5 64.0 30.2 30.8 34.0 39.9 56.6 43.0 30.5 41.5 29.2 40.5 43.8 26.5 33.0 47.6 42.0 41.3 50.0 29.2 24.0 36.8 28.4 23.6 34.4 49.2 28.0 29.3 28.7 20.7 28.0 32.8 39.6 48.0 27.6 26.0 35.6 27.6 41.7 42.8 25.2 30.0 24.0 31.6 30.4 22.8 25.6 32.0 42.6 45.1 42.3 20.0 15.1 20.9 18.3 14.0 22.6 22.6 21.1 22.3 23.4 31.4 39.1 29.7 36.0 34.6 23.4 21.7 30.6 27.7 31.7 39.7 24.6 25.1 25.7 25.7 30.9 22.3 23.7 Both Visual & Textual Time Series as Input 24.0 36.0 37.4 44.0 38.9 47.4 38.9 19.7 31.0 38.0 66.3 36.3 69.0 50.3 78.0 86.7 64.0 76.7 76.0 82.0 93.3 32.5 35.6 35.0 55.0 33.1 56.2 68.8 50.0 39.8 66.8 70.8 66.2 71.8 72.0 45.2 36.8 24.8 30.8 30.0 42.0 44. Embedded Time Series as Input 24.0 43.0 50.0 62.0 19.0 28.0 40.0 20.0 33.0 36.0 39.0 41.0 35.0 31.0 43.0 40.0 51.0 51.0 57.0 25.0 32.0 32.0 38.0 45.0 31.0 26.0 23.0 27.0 29.0 34.0 24.0 36.0 52.0 43.0 51.0 53.0 54.0 57.0 58.0 26.5 33.1 23.5 37.8 31.4 33.5 30.7 39.2 46.7 31.1 29.0 39.4 36.1 36.6 27.4 31.1 29.4 27.5 38.8 24.2 30.7 22.6 50.7 37.4 25.3 32.1 39.7 34.7 38.2 32.2 44.6 35. 22.2 26.7 29.3 33.6 24.4 32.5 37.8 47.2 73.3 67.8 79.7 58.3 37.5 70.3 67.8 48.9 46.1 48.9 34.2 42.8 66.4 37.2 59.7 73.6 66.1 71.9 44.2 46.7 46.1 23.9 24.4 26.4 25.8 78.0 46.4 41.9 32.5 27.8 29.7 48.3 66.7 74.4 71.9 65.6 68.9 78.1 ChatTS-14B TS-Reasoner-7B 50.7 53. 50.6 56.3 46.5 48.1 55.8 50.4 21.7 28.9 34.3 24.3 51.3 57. 24.4 26.9 30.5 37.2 23.6 23.6 25.0 24.0 19.2 31.7 52.2 55. 33.1 30.4 35.5 31.9 22.7 31.0 34.0 31.3 34.9 34.9 34.8 34.3 33.1 33.7 34.9 33.7 29.9 26.0 26.9 31.0 33.7 29.3 33.4 33.7 32.5 34.9 33.7 34.3 33.4 35.2 26.3 29.0 18.1 34.3 29.9 25.4 34.3 32.8 31.9 29.3 32.8 28.3 36.0 30.3 32.0 24.0 25.7 30.3 24.7 28.7 31.7 30.0 31.3 30.3 26.7 32.7 31.0 42.3 28.3 30.0 20.0 26.3 31.7 29.7 35.7 28.7 29.0 33.3 21.3 22.3 29.0 29.7 33. 28.0 49.7 36.0 24.3 29.7 24.3 34.3 27.7 21.7 39.1 47.7 46.6 55.5 33.2 33.7 42.4 36.8 38.3 38.6 42.2 37.2 38.6 37.0 38.1 42.0 46.6 46.0 52.4 31.3 34.7 39.1 40.2 44.9 41.0 31.9 42.3 33.8 39.5 39.4 35.9 37.2 37.1 46.5 48.2 52.5 46.9 54.1 55.6 33.5 36. Table 3: Spearmans rank correlation (ρ) between LLM and VLM performances and model size on main dimensions. \"(*)\" marks correlations with p-values ď 0.05. ρ Overall Perception Reasoning Prediction Decision-Making LLM 0.9248 (*) VLM 0.6436 (*) 0.8929 (*) 0.8301 (*) 0.9795 (*) 0.6389 (*) -0.2415 -0.2612 0.7380 (*) 0.5596 results are shown in Figure 4. We found that both LLMs and VLMs show strong correlation within perception, reasoning, and decision-making tasks, but weak correlation with prediction tasks. This indicates that even though the model can well understand and reason on the time series, it still falls short in forecasting the numerical time series and events. See Appendix F.1 for correlations within tasks. Finding 2. Perception, Reasoning, and Decision are highly correlated, and have weak correlation with the Prediction task. Finding 3. Although the textual and visual representations of time series achieve similar performance, they are strongly complementary. To investigate the correlation between tasks, we compute the Spearman correlation between four main tasks, and the We investigate the impact of different time series modalities, textual versus visual, using o4-mini, GPT-5-mini, and GPT6 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Table 4: Performance changes of models with tool augmentation. indicates the performance difference after enabling tool-augmented reasoning. Model Perception Reasoning Prediction Decision Overall PR NU AD SA ER CD AR TR NR DR IR TSF EP QualDM QuantDM o4-mini (T+V) -1.6 0.0 +1.6 GPT-5-mini (T+V) -0. +1.2 +2.3 GPT-5 (T+V) -2.2 -3.4 +3. -2.6 -0.9 -0.9 Proprietary models -1.7 +1. +5.3 +4.4 -1.8 +0.2 +1.1 -2. -3.3 -4.0 -2.6 +1.3 +1.3 +0. -1.6 -3.0 -3.0 +4.6 +2.1 -3. -1.2 -0.9 +4.7 +1.5 -3.2 +5. +5.0 -1.3 +1.2 +0.5 +0.6 +1. +2.5 +14.0 +4.0 +1.4 Figure 5: Analysis of modality complementarity. Left: Comparison between textual and visual time series representations. Right: Ratio of model (T+V) answers identical to model (T) or model (V). 5. Our results reveal two key findings regarding modality performance and complementarity. First, although textual and visual modalities achieve comparable overall accuracy, their strengths diverge across tasks. As shown in Table 2, visual representations outperform textual ones in Perception tasks, but this advantage diminishes in Reasoning, Prediction, and Decision-Making tasks that require fine-grained information extraction. This motivates an analysis of whether the two modalities capture complementary features. Specifically, we investigate the proportion of instances correctly solved by both representations (intersection) versus those solved by at least one (union). As shown in Figure 5 (left), the intersection yields low accuracy while the union yields high accuracy. This indicates that textual and visual representations are successful on different subsets of samples, with neither approach being dominant. However, enabling models to jointly process textual and visual time series (T+V) does not yield significant gains over single-modality inputs  (Table 2)  . As shown in Figure 5 (right), T+V solutions largely overlap with those already solved by either modality alone, suggesting that current models fail to effectively fuse cross-modal information. Finding 4. Tasks with high variance, highlighted in red in Figure 6, indicate that poorer-performing models can be improved through distillation from stronger ones, while low-accuracy, low-variance tasks shown in blue reveal shared weaknesses requiring better training data. closer examination of the performance distribution in 7 Figure 6: Performance distribution of evaluated models across TSRBENCH tasks. High and low inter-model variance tasks are highlighted in Red and Blue, respectively. Figure 6 reveals two distinct regimes of task difficulty. To characterize these regimes, we compute the mean accuracy and variance for each task by aggregating results across all models and input time-series representations (e.g., text and vision) reported in Table 2. On the one hand, tasks with high variance (red in Figure 6), such as Abductive Reasoning and Event Prediction, show that specific models handle them well while others struggle. This gap suggests that weaker models could likely improve their reasoning skills through knowledge distillation from the stronger ones. On the other hand, low-accuracy, low-variance tasks (blue in Figure 6), including Quantitative Decision-Making and Time Series Forecasting, show uniformly poor performance across all models. This reveals shared weaknesses in current generalist models, where progress will likely require data-centric pre-training with richer quantitative and temporal supervision. 4.4. Further Investigation Does Time Series Analysis Tool-use Help? To investigate whether generalist models fail due to their weaknesses in understanding the time series, we enrich the understanding of temporal patterns by extracting comprehensive set of statistical, structural, and frequency-domain features from each time series. These include summary statistics (e.g., mean, variance), trend and seasonality measures, temporal dependencies, local extrema and change points, similarity metrics and outlier indicators. We conduct experiments on o4-mini, Qwen3-VL-32B, GPT-5-mini, and GPT-5. The results in Table 4 show slight overall improvement, but TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Figure 7: Performance of GPT-5 (left), Qwen3-32B (middle), Qwen3-VL-32B (right), with (non-) reasoning modes. Figure 8: Impact of visual resolution on performance for Visual-only (left) and Text+Visual (right) as inputs. vary task to task. This indicates that more time series details complement some lack for models. See more details and specific analysis functions in Appendix E. Impact of Resolutions for visual time series. We investigate the effect of five visualization resolutions on performance. Our results, shown in Figure 8, indicate that mid-range resolutions (100 PPI) achieve better results compared to both lower (10 PPI, 50 PPI) and higher (200 PPI, 400 PPI) resolutions. While low-resolution images may lack the fine-grained details necessary for understanding and reasoning, excessively high resolutions can introduce unnecessary complexity, making it harder for models to focus on relevant information or capture global patterns for reasoning. Notably, the performance degradation at low resolutions is mitigated when textual time series is provided alongside visualizations. This suggests that textual time series can partially compensate for visual information loss, providing degree of cross-modal redundancy. These results highlight the importance of selecting an appropriate resolution for visualized time series reasoning. Impact of Inference-Time Scaling. We investigate the impact of inference-time computation on performance by evaluating GPT-5, Qwen3-32B, and Qwen3-VL-32B in both reasoning and non-reasoning modes. As illustrated in Figure 7, clear performance divergence emerges: while Perception tasks remain robust to reduced compute, Reasoning, Prediction, and Decision-Making tasks suffer sharp degradation. These results suggest that while generalist models can intuitively \"perceive\" temporal patterns through fast, heuristic processing, yet deriving logical conclusions from 8 Figure 9: Error type distribution of three models. those patterns is computationally intensive process that necessitates deliberative reasoning. 4.5. Error Analysis To systematically diagnose failure mechanisms, we conducted fine-grained error analysis on GPT-5 (T+V), Gemini-2.5-Flash (T+V), and Claude-4.5-Haiku (T+V). We randomly sampled 150 failure instances (10 per task subset) and categorized them into four-tier taxonomy: Reasoning, Perception, Question Understanding, and Domain Knowledge. Our quantitative analysis reveals that Reasoning and Perception errors are the predominant failure modes across all models, whereas errors stemming from Question Understanding or Domain Knowledge misapplication are marginal. This distribution pinpoints the critical bottleneck: current models are limited not by lack of knowledge or linguistic comprehension, but by deficiencies in perceiving temporal patterns and performing rigorous reasoning based on those perceptions. See Appendix G.2 for error cases. 5. Conclusion We introduce TSRBENCH, comprehensive benchmark for systematically evaluating the time-series understanding and reasoning capabilities of generalist models across diverse tasks and domains. Our extensive empirical study reveals several fundamental challenges, which highlight critical limitations of current generalist models. We hope TSRBENCH will inspire and guide future research toward building more capable time series reasoning approaches and models. TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models"
        },
        {
            "title": "References",
            "content": "Agarwal, S., Ahmad, L., Ai, J., Altman, S., Applebaum, A., Arbus, E., Arora, R. K., Bai, Y., Baker, B., Bao, H., et al. gpt-oss-120b & gpt-oss-20b model card. arXiv preprint arXiv:2508.10925, 2025. Aggarwal, P., Madaan, A., Yang, Y., et al. Lets sample step by step: Adaptive-consistency for efficient reasoning and coding with llms. arXiv preprint arXiv:2305.11860, 2023. Bachlin, M., Roggen, D., Troster, G., Plotnik, M., Inbar, N., Meidan, I., Herman, T., Brozgol, M., Shaviv, E., Giladi, N., et al. Potentials of enhanced context awareness in wearable assistants for parkinsons disease patients with In 2009 international the freezing of gait syndrome. symposium on wearable computers, pp. 123130. IEEE, 2009. Bai, S., Chen, K., Liu, X., Wang, J., Ge, W., Song, S., Dang, K., Wang, P., Wang, S., Tang, J., et al. Qwen2. 5-vl technical report. arXiv preprint arXiv:2502.13923, 2025. Bauer, A., Züfle, M., Eismann, S., Grohmann, J., Herbst, N., and Kounev, S. Libra: benchmark for time series forecasting methods. In Proceedings of the ACM/SPEC International Conference on Performance Engineering, pp. 189200, 2021. Besta, M., Blach, N., Kubicek, A., Gerstenberger, R., Podstawski, M., Gianinazzi, L., Gajda, J., Lehmann, T., Niewiadomski, H., Nyczyk, P., et al. Graph of thoughts: Solving elaborate problems with large language models. In Proceedings of the AAAI conference on artificial intelligence, volume 38, pp. 1768217690, 2024. Brown, B., Juravsky, J., Ehrlich, R., Clark, R., Le, Q. V., Ré, C., and Mirhoseini, A. Large language monkeys: Scaling inference compute with repeated sampling. arXiv preprint arXiv:2407.21787, 2024. Cai, Y., Choudhry, A., Goswami, M., and Dubrawski, A. Timeseriesexam: time series understanding exam. arXiv preprint arXiv:2410.14752, 2024a. Cai, Z., Cao, M., Chen, H., Chen, K., Chen, K., Chen, X., Chen, X., Chen, Z., Chen, Z., Chu, P., et al. Internlm2 arXiv preprint arXiv:2403.17297, technical report. 2024b. Chang, C., Hwang, J., Shi, Y., Wang, H., Peng, W.-C., Chen, T.-F., and Wang, W. Time-imm: dataset and benchmark for irregular multimodal multivariate time series. arXiv preprint arXiv:2506.10412, 2025. Chen, H., Peng, J., Min, D., Sun, C., Chen, K., Yan, Y., Yang, X., and Cheng, L. Mvi-bench: comprehensive benchmark for evaluating robustness to misleading visual inputs in lvlms. arXiv preprint arXiv:2511.14159, 2025a. Chen, J., Feng, A., Zhao, Z., Garza, J., Nurbek, G., Qin, C., Maatouk, A., Tassiulas, L., Gao, Y., and Ying, R. Mtbench: multimodal time series benchmark for temporal reasoning and question answering. arXiv preprint arXiv:2503.16858, 2025b. Chen, M. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. Chen, Y., He, J., Fu, L., Zhang, S., Jin, R., Dai, X., Li, J., Min, D., Hu, N., Zhang, Y., et al. Pandora: Leveraging code-driven knowledge transfer for unified structured knowledge reasoning. arXiv preprint arXiv:2508.17905, 2025c. Cheng, J., Ge, Y., Wang, T., Ge, Y., Liao, J., and Shan, Y. Video-holmes: Can mllm think like holmes for complex video reasoning? arXiv preprint arXiv:2505.21374, 2025. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021. Comanici, G., Bieber, E., Schaekermann, M., Pasupat, I., Sachdeva, N., Dhillon, I., Blistein, M., Ram, O., Zhang, D., Rosen, E., et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. Ding, R., Zhang, C., Wang, L., Xu, Y., Ma, M., Zhang, W., Qin, S., Rajmohan, S., Lin, Q., and Zhang, D. Everything of thoughts: Defying the law of penrose triangle for thought generation. In Findings of the Association for Computational Linguistics: ACL 2024, pp. 16381662, 2024. Dong, Z., Fan, X., and Peng, Z. Fnspid: comprehensive In Proceedings financial news dataset in time series. of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 49184927, 2024. Du, M., Wu, B., Li, Z., Huang, X., and Wei, Z. Embspatialbench: Benchmarking spatial understanding for embodarXiv ied tasks with large vision-language models. preprint arXiv:2406.05756, 2024a. Du, W., Wang, J., Qian, L., Yang, Y., Ibrahim, Z., Liu, F., Wang, Z., Liu, H., Zhao, Z., Zhou, Y., et al. Tsi-bench: Benchmarking time series imputation. arXiv preprint arXiv:2406.12747, 2024b. TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Fei, Y., Yu, C., Li, K., Chen, X., Zhang, Y., Cui, C., Xiao, J., Xu, Y., and Tao, Y. Leaves: an expandable lightcurve data set for automatic classification of variable stars. The Astrophysical Journal Supplement Series, 275 (1):10, 2024. He, C., Luo, R., Bai, Y., Hu, S., Thai, Z. L., Shen, J., Hu, J., Han, X., Huang, Y., Zhang, Y., et al. Olympiadbench: challenging benchmark for promoting agi with olympiadlevel bilingual multimodal scientific problems. arXiv preprint arXiv:2402.14008, 2024. Gao, T., Chen, P., Zhang, M., Fu, C., Shen, Y., Zhang, Y., Zhang, S., Zheng, X., Sun, X., Cao, L., et al. Cantor: Inspiring multimodal chain-of-thought of mllm. In Proceedings of the 32nd ACM International Conference on Multimedia, pp. 90969105, 2024. Godahewa, R., Bergmeir, C., Webb, G. I., Hyndman, R. J., and Montero-Manso, P. Monash time series forecasting archive. arXiv preprint arXiv:2105.06643, 2021. Gou, Z., Shao, Z., Gong, Y., Shen, Y., Yang, Y., Duan, N., and Chen, W. Critic: Large language models can selfcorrect with tool-interactive critiquing. arXiv preprint arXiv:2305.11738, 2023. Guan, T., Meng, Z., Li, D., Wang, S., Yang, C.-H. H., Wen, Q., Liu, Z., Siniscalchi, S. M., Jin, M., and Pan, S. Timeomni-1: Incentivizing complex reasoning with time series in large language models. arXiv preprint arXiv:2509.24803, 2025. Guha, N., Nyarko, J., Ho, D., Ré, C., Chilton, A., ChohlasWood, A., Peters, A., Waldon, B., Rockmore, D., Zambrano, D., et al. Legalbench: collaboratively built benchmark for measuring legal reasoning in large language models. Advances in neural information processing systems, 36:4412344279, 2023. Guo, D., Yang, D., Zhang, H., Song, J., Wang, P., Zhu, Q., Xu, R., Zhang, R., Ma, S., Bi, X., et al. Deepseekr1 incentivizes reasoning in llms through reinforcement learning. Nature, 645(8081):633638, 2025a. Guo, X., Li, Y., Kong, X., Jiang, Y., Zhao, X., Gong, Z., Zhang, Y., Li, D., Sang, T., Zhu, B., et al. Toward engineering agi: Benchmarking the engineering design capabilities of llms. arXiv preprint arXiv:2509.16204, 2025b. Guo, X., Tyagi, U., Gosai, A., Vergara, P., Park, J., Montoya, E. G. H., Zhang, C. B. C., Hu, B., He, Y., Liu, B., et al. Beyond seeing: Evaluating multimodal llms on toolenabled image perception, transformation, and reasoning. arXiv preprint arXiv:2510.12712, 2025c. Hakim, D. K., Gernowo, R., and Nirwansyah, A. W. Flood prediction with time series data mining: Systematic review. Natural Hazards Research, 4(2):194220, 2024. Ho, M., Si, C., Feng, Z., Yu, F., Yang, Y., Liu, Z., Hu, Z., and Qin, L. Arcmemo: Abstract reasoning composition with lifelong llm memory. arXiv preprint arXiv:2509.04439, 2025. Hu, Y., Li, Y., Liu, P., Zhu, Y., Li, N., Dai, T., Xia, S.-t., Cheng, D., and Jiang, C. Fintsb: comprehensive and practical benchmark for financial time series forecasting. arXiv preprint arXiv:2502.18834, 2025. Huang, W., Jia, B., Zhai, Z., Cao, S., Ye, Z., Zhao, F., Xu, Z., Hu, Y., and Lin, S. Vision-r1: Incentivizing reasoning capability in multimodal large language models. arXiv preprint arXiv:2503.06749, 2025. Ismail Fawaz, H., Forestier, G., Weber, J., Idoumghar, L., and Muller, P.-A. Deep learning for time series classification: review. Data mining and knowledge discovery, 33 (4):917963, 2019. Jimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press, O., and Narasimhan, K. Swe-bench: Can language modarXiv preprint els resolve real-world github issues? arXiv:2310.06770, 2023. Karan, A. and Du, Y. Reasoning with sampling: Your base model is smarter than you think. arXiv preprint arXiv:2510.14901, 2025. Kazijevs, M. and Samad, M. D. Deep imputation of missing values in time series health data: review with benchmarking. Journal of biomedical informatics, 144:104440, 2023. Kevian, D., Syed, U., Guo, X., Havens, A., Dullerud, G., Seiler, P., Qin, L., and Hu, B. Capabilities of large language models in control engineering: benchmark study on gpt-4, claude 3 opus, and gemini 1.0 ultra. arXiv preprint arXiv:2404.03647, 2024. Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P., and Sabharwal, A. Decomposed prompting: modular approach for solving complex tasks. arXiv preprint arXiv:2210.02406, 2022. Hao, S., Gu, Y., Ma, H., Hong, J. J., Wang, Z., Wang, D. Z., and Hu, Z. Reasoning with language model is planning with world model. arXiv preprint arXiv:2305.14992, 2023. Kim, H., Sclar, M., Zhou, X., Bras, R. L., Kim, G., Choi, Y., and Sap, M. Fantom: benchmark for stress-testing machine theory of mind in interactions. arXiv preprint arXiv:2310.15421, 2023. TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Kong, Y., Yang, Y., Hwang, Y., Du, W., Zohren, S., Wang, Z., Jin, M., and Wen, Q. Time-mqa: Time series multitask question answering with context enhancement. arXiv preprint arXiv:2503.01875, 2025. Kwapisz, J. R., Weiss, G. M., and Moore, S. A. Activity recognition using cell phone accelerometers. ACM SigKDD Explorations Newsletter, 12(2):7482, 2011. Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C. H., Gonzalez, J., Zhang, H., and Stoica, I. Efficient memory management for large language model serving In Proceedings of the 29th symwith pagedattention. posium on operating systems principles, pp. 611626, 2023. Lai, K.-H., Zha, D., Xu, J., Zhao, Y., Wang, G., and Hu, X. Revisiting time series outlier detection: Definitions In Thirty-fifth conference on neural and benchmarks. information processing systems datasets and benchmarks track (round 1), 2021. Le, M., Boureau, Y.-L., and Nickel, M. Revisiting the evaluation of theory of mind through question answering. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 58725877, 2019. Lee, G., Yu, W., Shin, K., Cheng, W., and Chen, H. Timecap: Learning to contextualize, augment, and predict time series events with large language model agents. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pp. 1808218090, 2025. Li, B., Wang, R., Wang, G., Ge, Y., Ge, Y., and Shan, Y. Seed-bench: Benchmarking multimodal llms with generative comprehension. arXiv preprint arXiv:2307.16125, 2023. Li, Y., Chen, X., Hu, B., Wang, L., Shi, H., and Zhang, M. Videovista: versatile benchmark for video understanding and reasoning. arXiv preprint arXiv:2406.11303, 2024. Li, Z., Qiu, X., Chen, P., Wang, Y., Cheng, H., Shu, Y., Hu, J., Guo, C., Zhou, A., Jensen, C. S., et al. Tsfm-bench: comprehensive and unified benchmark of foundation models for time series forecasting. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2, pp. 55955606, 2025. Liang, Y., Chow, W., Li, F., Ma, Z., Wang, X., Mao, J., Chen, J., Gu, J., Wang, Y., and Huang, F. Rover: Benchmarking reciprocal cross-modal reasoning for omnimodal generation. arXiv preprint arXiv:2511.01163, 2025. Liu, H., Xu, S., Zhao, Z., Kong, L., Prabhakar Kamarthi, H., Sasanur, A., Sharma, M., Cui, J., Wen, Q., Zhang, C., et al. Time-mmd: Multi-domain multimodal dataset for time series analysis. Advances in Neural Information Processing Systems, 37:7788877933, 2024. Lu, P., Bansal, H., Xia, T., Liu, J., Li, C., Hajishirzi, H., Cheng, H., Chang, K.-W., Galley, M., and Gao, J. Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts. arXiv preprint arXiv:2310.02255, 2023. Mao, S., Zhang, C., Song, Y., Wang, J., Zeng, X.-J., Xu, Z., and Wen, Q. Time series analysis for education: Methods, applications, and future directions. arXiv preprint arXiv:2408.13960, 2024. Matowe, L. K., Leister, C. A., Crivera, C., and KorthBradley, J. M. Interrupted time series analysis in clinical research. Annals of Pharmacotherapy, 37(7-8):1110 1116, 2003. Merrill, M. A., Tan, M., Gupta, V., Hartvigsen, T., and Althoff, T. Language models still struggle to zero-shot reason about time series. arXiv preprint arXiv:2404.11757, 2024. Morid, M. A., Sheng, O. R. L., and Dunbar, J. Time series prediction using deep learning methods in healthcare. ACM Transactions on Management Information Systems, 14(1):129, 2023. Oh, J., Lee, G., Bae, S., Kwon, J.-m., and Choi, E. Ecg-qa: comprehensive question answering dataset combined with electrocardiogram. Advances in Neural Information Processing Systems, 36:6627766288, 2023. OpenAI. Introducing gpt-5. https://openai.com/ zh-Hans-CN/gpt-5/, Aug 2025. Platforms, M. The llama 4 herd: The beginning of new era of natively multimodal ai inhttps://ai.meta.com/blog/ novation. llama-4-multimodal-intelligence/, Apr 2025. Accessed: 2025-11-03. Qiu, X., Hu, J., Zhou, L., Wu, X., Du, J., Zhang, B., Guo, C., Zhou, A., Jensen, C. S., Sheng, Z., et al. Tfb: Towards comprehensive and fair benchmarking of time series forecasting methods. arXiv preprint arXiv:2403.20150, 2024. Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y., Dirani, J., Michael, J., and Bowman, S. R. Gpqa: graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024. Ruiz, A. P., Flynn, M., and Bagnall, A. Benchmarking multivariate time series classification algorithms. arXiv preprint arXiv:2007.13156, 2020. 11 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Snell, C., Lee, J., Xu, K., and Kumar, A. Scaling llm testtime compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314, 2024. Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., Garriga-Alonso, A., et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on machine learning research, 2023. Stein, G., Shadaydeh, M., Blunk, J., Penzel, N., and Denzler, J. Causalriversscaling up benchmarking of causal discovery for real-world time-series. arXiv preprint arXiv:2503.17452, 2025. Syed, U., Light, E., Guo, X., Zhang, H., Qin, L., Ouyang, Y., and Hu, B. Benchmarking the capabilities of large language models in transportation system engineering: Accuracy, consistency, and reasoning behaviors. arXiv preprint arXiv:2408.08302, 2024. Tan, M., Merrill, M., Gupta, V., Althoff, T., and Hartvigsen, T. Are language models actually useful for time series forecasting? Advances in Neural Information Processing Systems, 37:6016260191, 2024. Tan, M., Merrill, M. A., Gottesman, Z., Althoff, T., Evans, D., and Hartvigsen, T. Inferring events from time series using language models. arXiv preprint arXiv:2503.14190, 2025. Team, C., Yue, Z., Lin, Z., Song, Y., Wang, W., Ren, S., Gu, S., Li, S., Li, P., Zhao, L., Li, L., Bao, K., Tian, H., Zhang, H., Wang, G., Zhu, D., Cici, He, C., Ye, B., Shen, B., Zhang, Z., Jiang, Z., Zheng, Z., Song, Z., Luo, Z., Yu, Y., Wang, Y., Tian, Y., Tu, Y., Yan, Y., Huang, Y., Wang, X., Xu, X., Song, X., Zhang, X., Yong, X., Zhang, X., Deng, X., Yang, W., Ma, W., Lv, W., Zhuang, W., Liu, W., Deng, S., Liu, S., Chen, S., Yu, S., Liu, S., Wang, S., Ma, R., Wang, Q., Wang, P., Chen, N., Zhu, M., Zhou, K., Zhou, K., Fang, K., Shi, J., Dong, J., Xiao, J., Xu, J., Liu, H., Xu, H., Qu, H., Zhao, H., Lv, H., Wang, G., Zhang, D., Zhang, D., Zhang, D., Ma, C., Liu, C., Cai, C., and Xia, B. Mimo-vl technical report, 2025a. URL https://arxiv.org/abs/2506.03569. Team, G., Kamath, A., Ferret, J., Pathak, S., Vieillard, N., Merhej, R., Perrin, S., Matejovicova, T., Ramé, A., Rivière, M., et al. Gemma 3 technical report. arXiv preprint arXiv:2503.19786, 2025b. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. Glue: multi-task benchmark and analysis In Proplatform for natural language understanding. ceedings of the 2018 EMNLP workshop BlackboxNLP: Analyzing and interpreting neural networks for NLP, pp. 353355, 2018. Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. Superglue: stickier benchmark for general-purpose language understanding systems. Advances in neural information processing systems, 32, 2019. Wang, K., Pan, J., Shi, W., Lu, Z., Ren, H., Zhou, A., Zhan, M., and Li, H. Measuring multimodal mathematical reasoning with math-vision dataset. Advances in Neural Information Processing Systems, 37:9509595169, 2024a. Wang, L., Su, E., Liu, J., Li, P., Xia, P., Xiao, J., Zhang, W., Dai, X., Chen, X., Meng, Y., et al. Physunibench: An undergraduate-level physics reasoning benchmark for multimodal models. arXiv preprint arXiv:2506.17667, 2025a. Wang, W., Gao, Z., Gu, L., Pu, H., Cui, L., Wei, X., Liu, Z., Jing, L., Ye, S., Shao, J., et al. Internvl3. 5: Advancing open-source multimodal models in versatility, reasoning, and efficiency. arXiv preprint arXiv:2508.18265, 2025b. Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., and Zhou, D. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022. Wang, Y., Wu, H., Dong, J., Liu, Y., Wang, C., Long, M., and Wang, J. Deep time series models: comprehensive survey and benchmark. arXiv preprint arXiv:2407.13278, 2024b. Wang, Y., Lei, P., Song, J., Hao, Y., Chen, T., Zhang, Y., Jia, L., Li, Y., and Wei, Z. Itformer: Bridging time series and natural language for multi-modal qa with largescale multitask dataset. arXiv preprint arXiv:2506.20093, 2025c. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022. Wagner, P., Strodthoff, N., Bousseljot, R.-D., Kreiseler, D., Lunze, F. I., Samek, W., and Schaeffter, T. Ptb-xl, large publicly available electrocardiography dataset. Scientific data, 7(1):115, 2020. Wenig, P., Schmidl, S., and Papenbrock, T. Timeeval: benchmarking toolkit for time series anomaly detection algorithms. Proceedings of the VLDB Endowment, 15 (12):36783681, 2022. TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Williams, A. R., Ashok, A., Marcotte, É., Zantedeschi, V., Subramanian, J., Riachi, R., Requeima, J., Lacoste, A., Rish, I., Chapados, N., et al. Context is key: benchmark for forecasting with essential textual information. arXiv preprint arXiv:2410.18959, 2024. Wu, H., Zhang, Z., Zhang, E., Chen, C., Liao, L., Wang, A., Li, C., Sun, W., Yan, Q., Zhai, G., et al. Q-bench: benchmark for general-purpose foundation models on low-level vision. arXiv preprint arXiv:2309.14181, 2023. Wu, W., Zhang, Z., Liu, L., Xu, X., Liu, J., Fan, K., Lv, Q., Zhuang, J., Zhang, C., Yuan, Z., et al. Scits: Scientific time series understanding and generation with llms. arXiv preprint arXiv:2510.03255, 2025. Xie, T., Gao, Z., Ren, Q., Luo, H., Hong, Y., Dai, B., Zhou, J., Qiu, K., Wu, Z., and Luo, C. Logic-rl: Unleashing llm reasoning with rule-based reinforcement learning. arXiv preprint arXiv:2502.14768, 2025. Xie, Z., Li, Z., He, X., Xu, L., Wen, X., Zhang, T., Chen, J., Shi, R., and Pei, D. Chatts: Aligning time series with llms via synthetic data for enhanced understanding and reasoning. arXiv preprint arXiv:2412.03104, 2024. Xu, R., Wang, Z., Fan, R.-Z., and Liu, P. Benchmarking benchmark leakage in large language models. arXiv preprint arXiv:2404.18824, 2024. Xu, X., Xu, Q., Xiao, T., Chen, T., Yan, Y., Zhang, J., Diao, S., Yang, C., and Wang, Y. Ugphysics: comprehensive benchmark for undergraduate physics reasoning with large language models. arXiv preprint arXiv:2502.00334, 2025a. Xu, X., Zhang, J., Chen, T., Chao, Z., Hu, J., and Yang, C. Ugmathbench: diverse and dynamic benchmark for undergraduate-level mathematical reasoning with large arXiv preprint arXiv:2501.13766, language models. 2025b. Yan, P., Abdulkadir, A., Luley, P.-P., Rosenthal, M., Schatte, G. A., Grewe, B. F., and Stadelmann, T. comprehensive survey of deep transfer learning for anomaly detection in industrial time series: Methods, applications, and directions. IEEE Access, 12:37683789, 2024. Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025a. Yang, R., Chen, H., Zhang, J., Zhao, M., Qian, C., Wang, K., Wang, Q., Koripella, T. V., Movahedi, M., Li, M., et al. Embodiedbench: Comprehensive benchmarking multimodal large language models for vision-driven embodied agents. arXiv preprint arXiv:2502.09560, 2025b. Yang, Z., Li, L., Wang, J., Lin, K., Azarnasab, E., Ahmed, F., Liu, Z., Liu, C., Zeng, M., and Wang, L. Mm-react: Prompting chatgpt for multimodal reasoning and action. arXiv preprint arXiv:2303.11381, 2023. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022. Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y., and Narasimhan, K. Tree of thoughts: Deliberate problem solving with large language models. Advances in neural information processing systems, 36:1180911822, 2023. Yao, Y., Yu, T., Zhang, A., Wang, C., Cui, J., Zhu, H., Cai, T., Li, H., Zhao, W., He, Z., et al. Minicpm-v: gpt-4v level mllm on your phone. arXiv preprint arXiv:2408.01800, 2024. Yu, F., Jiang, L., Kang, H., Hao, S., and Qin, L. Flow of reasoning: Training llms for divergent problem solving with minimal examples. arXiv preprint arXiv:2406.05673, 2024. Yu, F., Jiang, L., Huang, S., Wu, Z., and Dai, X. Persuasivetom: benchmark for evaluating machine theory of mind in persuasive dialogues. arXiv preprint arXiv:2502.21017, 2025a. Yu, F., Zhao, H., and Zhou, T. Ts-reasoner: Aligning time series foundation models with llm reasoning. arXiv preprint arXiv:2510.03519, 2025b. Yu, F., Lu, Z., Niu, L., Meng, F., and Zhou, J. Arrowgev: Grounding events in video via learning the arrow of time. arXiv preprint arXiv:2601.06559, 2026. Yu, R., Qiu, C., Ladwig, R., Hanson, P., Xie, Y., and Jia, X. Physics-guided foundation model for scientific discovery: An application to aquatic science. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pp. 2854828556, 2025c. Yu, T., Zhang, R., Yang, K., Yasunaga, M., Wang, D., Li, Z., Ma, J., Li, I., Yao, Q., Roman, S., et al. Spider: large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. arXiv preprint arXiv:1809.08887, 2018. Yue, X., Ni, Y., Zhang, K., Zheng, T., Liu, R., Zhang, G., Stevens, S., Jiang, D., Ren, W., Sun, Y., et al. Mmmu: massive multi-discipline multimodal understanding and reasoning benchmark for expert agi. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 95569567, 2024. TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Zhou, H., Li, X., Wang, R., Cheng, M., Zhou, T., and Hsieh, C.-J. R1-zeros\" aha moment\" in visual reasoning on 2b non-sft model. arXiv preprint arXiv:2503.05132, 2025. Zhou, Z. and Yu, R. Can llms understand time series anomalies? arXiv preprint arXiv:2410.05440, 2024. Zou, C., Guo, X., Yang, R., Zhang, J., Hu, B., and Zhang, H. Dynamath: dynamic visual benchmark for evaluating mathematical reasoning robustness of vision language models. arXiv preprint arXiv:2411.00836, 2024. Zhang, C., Li, R., Tan, M., Yang, M., Zhu, J., Yang, D., Zhao, J., Ye, G., Li, C., and Hu, X. Cpsycoun: reportbased multi-turn dialogue reconstruction and evaluation framework for chinese psychological counseling. arXiv preprint arXiv:2405.16433, 2024a. Zhang, R., Jiang, D., Zhang, Y., Lin, H., Guo, Z., Qiu, P., Zhou, A., Lu, P., Chang, K.-W., Qiao, Y., et al. Mathverse: Does your multi-modal llm truly see the diagrams in visual math problems? In European Conference on Computer Vision, pp. 169186. Springer, 2024b. Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., and Artzi, Y. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675, 2019. Zhang, Y., Yang, J., Yuan, Y., and Yao, A. C.-C. Cumulative reasoning with large language models. arXiv preprint arXiv:2308.04371, 2023a. Zhang, Y., Khalifa, M., Logeswaran, L., Kim, J., Lee, M., Lee, H., and Wang, L. Small language models need strong verifiers to self-correct reasoning. arXiv preprint arXiv:2404.17140, 2024c. Zhang, Y., Yang, W., Wang, J., Ma, Q., and Xiong, J. Camef: Causal-augmented multi-modality event-driven financial forecasting by integrating time series patterns and salient macroeconomic announcements. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2, pp. 38673878, 2025. Zhang, Z., Zhang, A., Li, M., Zhao, H., Karypis, G., and Smola, A. Multimodal chain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b. Zhao, W., Ma, Q., Shi, J., Wu, S., Han, J., Xiao, Y., Chen, S.-Y., Luo, X., Schmidt, L., and Zou, J. Prism-physics: Causal dag-based process evaluation for physics reasoning. arXiv preprint arXiv:2510.03185, 2025. Zheng, G., Yang, B., Tang, J., Zhou, H.-Y., and Yang, S. Ddcot: Duty-distinct chain-of-thought prompting for multimodal reasoning in language models. Advances in Neural Information Processing Systems, 36:51685191, 2023. Zhong, X., Jin, B., Ouyang, S., Shen, Y., Jin, Q., Fang, Y., Lu, Z., and Han, J. Benchmarking retrievalaugmented generation for chemistry. arXiv preprint arXiv:2505.07671, 2025. Zhou, D., Schärli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Cui, C., Bousquet, O., Le, Q., et al. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022. 14 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models A. Additional Related Work A.1. MLLM/LLM Reasoning. Recent advances in Large Language Models (LLMs) and Multimodal LLMs (MLLMs) have catalyzed shift from pattern matching to deliberate problem-solving. Initial efforts focused on prompt engineering to induce intermediate reasoning steps (Wei et al., 2022; Khot et al., 2022; Zhou et al., 2022; Zheng et al., 2023; Zhang et al., 2023b; Gao et al., 2024; Ho et al., 2025; Chen et al., 2025c; Liang et al., 2025), though these approaches remain heavily dependent on heuristic human design. To mitigate this dependency, subsequent research has explored scaling test-time compute to enhance reasoning depth. This includes parallel sampling strategies (Brown et al., 2024; Snell et al., 2024; Karan & Du, 2025; Wang et al., 2022; Aggarwal et al., 2023), sequential refinement frameworks (Yao et al., 2022; Yang et al., 2023; Gou et al., 2023; Zhang et al., 2024c; 2023a), and hybrid search architectures (Yao et al., 2023; Besta et al., 2024; Hao et al., 2023; Ding et al., 2024). Most recently, paradigm shift towards internalized reasoning has emerged, where models explicitly learn reasoning behaviors via Reinforcement Learning (Guo et al., 2025a; Yu et al., 2024; Xie et al., 2025; Zhou et al., 2025; Huang et al., 2025; Yu et al., 2026). This trajectory has culminated in advanced reasoning models such as the Qwen3-series (Yang et al., 2025a), which demonstrate remarkable proficiency in textual and multimodal tasks. However, the adaptation of these reasoning paradigms to the time series domain remains significantly underexplored, presenting critical avenue for future investigation. A.2. Benchmarks for Generalist Models. variety of benchmarks assess generalist model reasoning and their problem-solving capabilities. In the early stages of generalist models, benchmarks such as GLUE (Wang et al., 2018), BERTScore (Zhang et al., 2019), and SuperGLUE (Wang et al., 2019) primarily focused on natural language understanding through small-scale, single-task evaluations. As generalist models rapidly scale up in size and begin to exhibit emergent generalization abilities, new wave of benchmarks has emerged, such as MMLU (Yue et al., 2024), BIG-bench (Srivastava et al., 2023), Q-Bench (Wu et al., 2023), and Seed-Bench (Li et al., 2023). These benchmarks aim to assess wider range of capabilities, including reasoning, factual knowledge, and visual recognition. To more comprehensively evaluate specific abilities, research works subdivide the aspects of evaluation, such as science reasoning (Cobbe et al., 2021; Xu et al., 2025a; Lu et al., 2023; Zhang et al., 2024b; Zhong et al., 2025), social reasoning (Guha et al., 2023; Zhang et al., 2024a; Kim et al., 2023), and engineering reasoning (Chen, 2021; Jimenez et al., 2023; Yu et al., 2018; Guo et al., 2025b; Chen et al., 2025a; Guo et al., 2025c). These diverse benchmarks highlight the broad coverage yet increasing specialization of reasoning evaluations, reflecting shift from coarse-grained language understanding toward fine-grained, domain-specific, and comprehensive assessments of complex reasoning abilities in modern generalist models. B. Future Research Directions While TSRBENCH represents significant step forward in evaluating generalist models on time series understanding and reasoning, several challenges remain, offering rich opportunities for future research. Below, we outline potential research directions: Multi-view Time Series Understanding: Current models struggle to fuse textual and visual representations despite their strong complementarity. Future research should focus on developing alignment techniques that effectively fuse high-resolution visual patterns with semantic textual context to enhance holistic understanding. Large-scale Pretrained Time Series Models: Given the collective blind spots in quantitative forecasting observed across generalist models, there is critical need to develop foundation models pre-trained specifically on massive-scale, diverse time series corpora. This data-centric approach is essential to bridge the gap between semantic reasoning and precise numerical extrapolation. Multi-agent Time Series Systems: Complex time series problems often require distinct capabilities ranging from pattern recognition to logical deduction and domain knowledge retrieval. multi-agent framework could decompose these tasks, employing specialized agents to collaborate on and verify predictions, thereby overcoming the limitations of single-model reasoning. Test-time Scaling Approaches: Our ablation studies reveal that reasoning-intensive tasks suffer significantly without sufficient inference-time computation. In addition, we show on o4-mini and GPT-5-mini that increased reasoning efforts TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Model Name URL Table 5: Model list and URL. Proprietary Models DeepSeek-V3.2-Exp o4-mini GPT-5-mini GPT-5 Claude-4.5-Haiku Gemini-2.5-Flash https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp https://platform.openai.com/docs/models/o4-mini https://platform.openai.com/docs/models/gpt-5-mini https://platform.openai.com/docs/models/gpt-5 https://www.anthropic.com/claude/haiku https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash Qwen3-1.7B Qwen3-8B Qwen3-32B Qwen3-235B-A22B Qwen2.5-3B Qwen2.5-7B Qwen2.5-72B Gemma-3-12B-it Gemma-3-27B-it InternLM3-8B GPT-OSS-20B GPT-OSS-120B Open Source Large Language Models https://huggingface.co/Qwen/Qwen3-1.7B https://huggingface.co/Qwen/Qwen3-8B https://huggingface.co/Qwen/Qwen3-32B https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507 https://huggingface.co/Qwen/Qwen2.5-3B-Instruct https://huggingface.co/Qwen/Qwen2.5-7B-Instruct https://huggingface.co/Qwen/Qwen2.5-72B-Instruct https://huggingface.co/google/gemma-3-12b-it https://huggingface.co/google/gemma-3-27b-it https://huggingface.co/internlm/internlm3-8b-instruct https://huggingface.co/openai/gpt-oss-20b https://huggingface.co/openai/gpt-oss-120b Vision Language Models Qwen/Qwen2.5-VL-3B-Instruct Qwen/Qwen2.5-VL-7B-Instruct Qwen/Qwen2.5-VL-72B-Instruct https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct https://huggingface.co/Qwen/Qwen3-VL-32B-Instruct Qwen2.5-VL-3B Qwen2.5-VL-7B Qwen2.5-VL-72B Qwen3-VL-8B Qwen3-VL-32B Qwen3-VL-235B-A22B https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Instruct Phi4-Multimodal-8B Llama-4-scout-17B-16E https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct https://huggingface.co/OpenGVLab/InternVL3_5-1B InternVL3.5-1B https://huggingface.co/OpenGVLab/InternVL3_5-8B InternVL3.5-8B https://huggingface.co/OpenGVLab/InternVL3_5-38B InternVL3.5-38B https://huggingface.co/openbmb/MiniCPM-V-4_5 MiniCPM-V-4.5-8B https://huggingface.co/XiaomiMiMo/MiMo-VL-7B-RL MiMo-VL-7B-RL https://huggingface.co/microsoft/Phi-4-multimodal-instruct ChatTS-14B TS-Reasoner-7B https://huggingface.co/bytedance-research/ChatTS-14B https://huggingface.co/ParadiseYu/TS-Reasoner-7B Vision Language Models substantially benefit reasoning performance. Future work should explore adaptive reasoning strategies, such as structured reasoning and self-verification. C. Model Versions Table 5 lists the versions of the models and their official links used in our experiments. We accessed proprietary models through the API calls and open-source models via local deployment using VLLM (Kwon et al., 2023). D. Data Collection We first introduce the key challenges in constructing TSRBENCH, followed by the construction pipeline. We then detail each component of the pipeline with corresponding data quality verification. Finally, we discuss considerations for fairness and data release. Challenges. Creating high-quality, multi-domain numerical-text series dataset presents significant challenges, encompassing the effective gathering, filtering, and alignment of useful textual data. First, textual sources are sparse. Unlike numerical data, typically provided by \"packaged\" source, textual data are collected from variety of dispersed sources, such as reports and news articles, necessitating extensive individual collection efforts. Second, textual information is noisy. TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Figure 10: Pipeline of data collection in TSRBENCH. Raw textual data often contains large portions of irrelevant information and potential data contamination, such as expert predictions in reports, requiring rigorous filtering processes to ensure data quality. Third, textual data requires precise alignment. It is essential to achieve temporal alignment between textual and numerical data by synchronizing reported times with numerical time steps (e.g., the time step where text is posted) and ensuring that the effective duration of textual information matches the relevant time frames at various granularities (e.g., seasonal report should correspond to 12 time steps in weekly time series). Additionally, the dataset faces challenges regarding ease of use, maintenance, and regular updates to remain relevant and useful for ongoing research and applications. Pipeline Overview. We propose comprehensive pipeline for constructing TSRBENCH. As illustrated in Figure 10, the construction process is divided into three key steps: (1) Raw data collection. We gather time series from reputable sources or code synthesis to ensure reliability and accuracy. (2) Question Generation. Questions are created by humans for each reasoning task to ensure that there is no ambiguity in the question. After that, we use either code or rule-based extractor to generate ground-truth from the data. (3) Verification. For each data source, we examine whether the context is highly correlated to the time series, and further use code and rules to verify the quality of the answer to ensure the correctness. D.1. Data Acquisition To address the challenges of data scarcity and noise, we employ dual-stream strategy for raw data acquisition, ensuring both diversity and precision. Synthetic Data Collection. For domains or tasks (e.g., numerical reasoning) where real-world data is sparse or difficult to isolate (e.g., complex physical simulations or specific medical scenarios), we utilize synthesis approach. We select diverse Seed Domains such as chemistry and seismology. Leveraging domain knowledge, we design Python generation functions (synthesize_ts) to simulate realistic time series data. This approach allows us to precisely control the underlying variables, ensuring the data is clean and the parameters are known. Web Data Collection. To capture real-world complexity, we aggregate massive datasets from reputable public repositories. We employ human annotators to rigorously verify the alignment between texts and time series. Crucially, we enforce strict temporal alignment to ensure that textual reports (e.g., news events) accurately correspond to numerical changes in the time series. To minimize the risk of data leakage, we process the raw data by anonymizing specific entities (e.g., replacing \"Lakers\" with \"Team A\", \"James Harden\" with \"Player 1\"). Please refer to Table 6 for an overview of the data sources. D.2. Question & Answer Generation Once the raw data is collected, we generate reasoning tasks designed to test specific analytical capabilities. To avoid the ambiguity often associated with automated generation, we manually design the question templates. We then generate answers via two methods: (1) Code-Based Calculation: For synthetic data, answers are derived programmatically using the underlying physical formulas or logic rules defined during generation. (2) Rule-Based Extraction: For web data, we use rule-based extractors to derive the correct answers directly from the data source, or retrieve them from associated metadata, time series values, or textual contexts. 17 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Figure 11: Domain distribution of TSRBENCH. Unlabeled indicates time series that are not associated with any specific domain. D.3. Answer Verification To ensure TSRBENCH serves as rigorous benchmark, we implement strict two-stage verification mechanism before any data is accepted. For synthetic tasks, we employ Code Verifier that re-executes the generation logic to ensure the answer aligns precisely with the simulation parameters. For web-based tasks, we utilize Fact Verifier to cross-reference generated answers against ground-truth records. Furthermore, we rigorously construct distractors for multiple-choice questions to ensure validity. We generate these either through algorithmic manipulation (e.g., reversing the ground-truth time series) to guarantee the choice is incorrect or by retrieving semantically distinct options validated by LLMs. Table 6: Data sources for each task. Category Data Source Pattern Recognition Noise Understanding Anomaly Detection Similarity Analysis Etiological Reasoning Causal Discovery Abductive Reasoning Temporal Relation Reasoning Numerical Reasoning Deductive Reasoning Inductive Reasoning Sequence Forecasting Event Prediction Qualitative Decision-Making Quantitative Decision-Making Timeseriesexam (Cai et al., 2024a) Timeseriesexam (Cai et al., 2024a) Timeseriesexam (Cai et al., 2024a) Timeseriesexam (Cai et al., 2024a) LEAVES (Fei et al., 2024), Human Activity Recognition (Kwapisz et al., 2011; Bachlin et al., 2009) CausalRiver (Stein et al., 2025) GAMETIME (Tan et al., 2025) Time-IMM (Chang et al., 2025) Synthetic Data Synthetic Data Kaggle: Philippines Typhoon Trend (20142024), Sunspots Dataset CAMFE (Zhang et al., 2025) TimeCAP (Lee et al., 2025) ECG-QA (Oh et al., 2023), PTB-XL (Wagner et al., 2020) Synthetic Data D.4. Data Contamination & Quality Control We perform data leakage detection to alleviate the potential data contamination in TSRBENCH. Following (Xu et al., 2024), we utilize n-gram accuracy to detect any data leakage within different LLMs. Concretely, we combined each problem, textual time series, and its solution in the dataset and randomly chose 20 positions for extracting 5-grams. sample is considered contaminated if the 5-grams predicted by the model match the actual 5-grams Table 7: The proportion (in %) of data leakage detection for TSRBENCH. Model N-gram Accuracy (%) o4-mini GPT-5-mini GPT-5 0.3% 0.1% 0.4% 18 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models from the dataset. We perform on the best-performing models, o4-mini, GPT-5-mini, GPT-5. The results are presented in Table 7. It is shown that most of models exhibit low N-gram accuracy, indicating low data leakage. E. Time Series Analysis Tools To enhance the reasoning capabilities of the models regarding numerical data, we integrated deterministic analysis module. This module processes raw time series input tx1, x2, . . . , xnu and injects structured statistical summaries into the models context window alongside the raw time series. The analysis pipeline consists of five core components: statistical profiling, trend detection, extremum identification, change point detection, and series comparison. E.1. Data Preprocessing Prior to analysis, all input series are sanitized. Non-numeric artifacts (e.g., formatting commas) are removed, and the series is converted to floating-point array. E.2. Descriptive Statistics We compute the fundamental statistical moments and distribution properties to provide the model with global view of the data scale and shape. The computed metrics include the mean (µ), standard deviation (σ), range (xmax xmin), median, and variance (σ2). Additionally, we calculate the skewness and kurtosis to describe the asymmetry and tailedness of the distribution, respectively, utilizing the scipy.stats library. E.3. Trend Analysis To formally quantify the trajectory of the time series, we utilize Ordinary Least Squares (OLS) linear regression. We model the series as xt β1t ` β0 ` ϵ, where is the time index. The tool outputs: Slope (β1): Indicates the direction and magnitude of the trend (increasing if β1 ą 0, decreasing if β1 ă 0). Coefficient of Determination (R2): Measures the proportion of variance in the dependent variable predictable from the independent variable. Trend Strength: We categorize strength based on the Pearson correlation coefficient r. trend is classified as strong if ą 0.7, moderate if 0.4 ă ď 0.7, and weak otherwise. E.4. Peak and Valley Detection Local extrema are identified to highlight turning points in the data. We employ signal processing approach (via scipy.signal.find_peaks) to find indices such that xt is local maximum (peak) or minimum (valley). To filter out noise, we apply prominence threshold . By default, is dynamic: 0.5 σX (1) where σX is the standard deviation of the series. This ensures that only significant structural peaks are reported to the LLM, reducing context noise. E.5. Change Point Detection To detect sudden shifts or volatility clustering, we analyze the first-order difference of the series, defined as xt xt xt1. time step is flagged as change point if the magnitude of the change exceeds statistical threshold θ: xt ą θ, where θ 2 stdpXq (2) This method effectively captures sudden shocks or regime changes in the time series that may be difficult for the LLM to infer from raw tokens alone. TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Table 8: Spearmans rank correlation (ρ) between LLM, VLM performance and model size. We mark correlations with p-values ď 0.05 using (*). Metric Perception Reasoning Prediction Decision PR NU AD SA ER CD AR TR NR DR IR TSF EP QualDM QuantDM ρ (LLM) ρ (VLM) 0.9021 (*) 0.7502 (*) 0.1221 0. 0.7352 (*) 0.7537 (*) 0.8558 (*) 0.7835 (*) 0.6469 (*) 0.6707 (*) 0.4601 0.7268 (*) 0.6986 (*) 0.3498 0.2733 0. 0.8037 (*) 0.6482 (*) 0.2831 0.6193 (*) 0.7671 (*) 0.3763 -0.5525 0.0280 -0.0046 -0.3684 0.5092 0. 0.7626 (*) 0.5880 E.6. Multivariate Comparison When the input contains multiple time series (X and ), the agent performs pairwise comparisons to determine their relationship. 1. Pearson Correlation: We calculate the coefficient ρX,Y and the associated p-value to test for linear correlation. 2. Cross-Correlation and Lag: We compute the normalized cross-correlation function to identify the optimal lag τ that maximizes similarity: τbest argmax pX qpτ τ (3) 3. Statistical Difference: Welchs t-test is performed to determine if the means of the two series are significantly different (p-value ă 0.05). F. Additional Results F.1. Fine-grained Correlation Results Table 8 provides detailed correlation analysis between model size and performance on individual tasks. The results indicate that for both LLMs and VLMs, model size positively correlates with performance on most perception, reasoning, and decision-making tasks, but not on prediction tasks. G. Cases G.1. Question Cases Pattern Analysis Question: You are time series analysis expert. What is the most dominant pattern in this complex time series? Answer Choices: (A) Noise (B) Trend (C) Seasonality Correct Answer: (C) Anomaly Detection Question: You are time series analysis expert. The following time series has an anomaly where the pattern is cutoff at certain point in time. What is the likely pattern of the time series without the anomaly? Answer Choices: (A) Sine wave with linear trend (B) Sawtooth wave with exponential trend TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models (C) Square wave with log trend Correct Answer: (B) Noise Understanding Question: You are time series analysis expert. The given time series is random walk process. What is the most likely noise level? Answer Choices: (A) 0.35 (B) 8.59 (C) 3.72 Correct Answer: (C)"
        },
        {
            "title": "Similarity Analysis",
            "content": "Question: You are time series analysis expert. You are given two time series that both have trend component. Do they share the same direction of trend? Answer Choices: (A) Yes (B) No Correct Answer: (A) Etiological Reasoning Question: You are given short tri-axial accelerometer time series collected at sampling rate of 20 Hz from subject performing physical activity. The sequence consists of 10 consecutive timestamps (approximately 0.5 seconds), where each timestamp contains acceleration measurements along the X, Y, and axes, yielding total of 30 values formatted as: rx1, y1, z1, x2, y2, z2, . . . , x10, y10, z10s. Acceleration values lie in the range r20, 20s, where 10 corresponds to 1g (approximately 9.8 m/s2), and the measurements include gravitational acceleration. Consequently, when the device is stationary on flat surface, the vertical axis typically registers approximately 10. The subject is performing one of the following six activities: walking, jogging, sitting, standing, upstairs, or downstairs. Given the provided accelerometer time series, identify the activity label that most likely generated the data. Answer Choices: (A) Walking (B) Jogging (C) Upstairs (D) Downstairs (E) Sitting (F) Standing Correct Answer: (D) 21 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Numerical Reasoning Question: The following time series shows the concentration (in mol/L) of reactant over time during chemical reaction. Based on the concentration decay pattern, determine the reaction order (zero, first, or second) and calculate the rate constant k. For zero-order: C0 kt; for first-order: C0ekt; for second-order: 1 Assume this is first-order reaction and calculate k. 1 ` kt. Answer Choices: (A) 2.064 (B) 0.0344 (C) 0.0241 (D) 0.0758 Correct Answer: (B) Temporal Relation Reasoning Question: Based on the provided GoldSteinScale time series and event timestamps, determine the correct chronological order of the following events: (1) The Australian Manufacturing Workers Union, Australian Workers Union, and Electrical Trades Union are involved in industrial action against Qantas, targeting the airlines engineers to demand better wages and working conditions . . . (2) The article does not directly mention labor unions or their activities. It highlights how Australian workers are increasingly using AI and robotics to reduce monotonous and physically demanding tasks, potentially leading to shifts in job roles and productivity. . . . (3) The Australian Workers Union (AWU) raised safety concerns prior to the incident at the Golden Plains Wind Farm, highlighting issues such as poor safety standards, non-unionized contractors, and near misses. AWU representatives expressed dissatisfaction with the companys response during meeting, feeling their concerns were dismissed and that safety standards in the renewable sector lag behind civil construction . . . (4) The Australian Manufacturing Workers Union (AMWU) commissioned report highlighting that reducing Australias industrial gas use would protect jobs and support manufacturing sectors, emphasizing the importance of supporting workers through transition to electrification and green hydrogen. AMWUs national secretary, Steve Murphy, stressed the need to prioritize gas resources for industries that employ hundreds of thousands of workers, as part of fair industrial transition amid decarbonization efforts . . . (5) Greater Victoria Canada Post workers, represented by the Canadian Union of Postal Workers (CUPW), are preparing for potential strike after over year of negotiations with Canada Post. The union, which includes 600 workers in the region, has voted overwhelmingly in favor of strike action, demanding 22% wage increase over four years and other improvements such as pensionable hours and guaranteed 40-hour work week . . . (6) The article highlights concerns from the Australian Workers Union NSW branch secretary Tony Callinan, who emphasizes that forestry workers are \"extremely worried\" about their future jobs due to the potential establishment of the Great Koala National Park. Workers fear job losses in the forestry and timber processing industries if the parks creation leads to restricted wood supply and mill closures . . . (7) The Australian Workers Union (AWU) has proposed reform for long service leave, advocating for \"portable\" long service leave system that would allow workers to accumulate two months of leave over ten years working across multiple employers. The union, representing 75,000 members, urged the federal government to implement this change, 22 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models emphasizing its benefits for workers in insecure employment, such as casuals . . . (8) The article highlights industry advocacy by the Victorian Automotive Chamber of Commerce (VACC) and the Motor Trades Association of Australia (MTAA), which are representative organizations akin to labor unions. These groups supported the inclusion of automotive trades on the revised Core Skills Occupation List (CSOL) to address labor shortages, emphasizing the importance of skilled migration for workforce solutions. They submitted evidence-backed data to the government, demonstrating the critical need for skilled automotive workers. . . . Event Timestamps (random order): 2024-12-13 10:30:00 2024-12-19 17:00:00 2024-11-11 19:15:00 2024-11-15 04:15:00 2024-12-05 23:00: 2024-11-08 05:45:00 2024-11-20 00:00:00 2024-10-20 00:00:00 Answer Choices: (A) (2)(6)(4)(7)(8)(3)(5)(1) (B) (2)(5)(3)(7)(4)(8)(6)(1) (C) (4)(8)(2)(6)(1)(7)(5)(3) (D) (4)(3)(6)(5)(1)(2)(8)(7) Correct Answer: (B) Abductive Reasoning Question: You are an expert in basketball game analysis. Given sequence of past events, future events, and corresponding time series data from game, determine the most plausible event that occurred in between to link them. Past Events: 12:00-1st: Player 6 (Team A) vs. Player 3 (Team B) (Player 2 (Team B) gains possession) 11:38-1st: Player 6 (Team B) misses 27-foot three-point jumper . . . 6:56-4th: Player 6 (Team B) makes 25-foot three-point jumper (Player 7 (Team B) assists) Team Full timeout Player 2 (Team A) enters the game for Player 9 (Team A) Player 6 (Team A) enters the game for Player 7 (Team A) 6:45-4th: [A CRITICAL EVENT HAPPENED HERE] Future Events: 6:39-4th: Player 6 (Team A) offensive rebound 6:33-4th: Player 2 (Team A) misses 27-foot step back jumpshot 23 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models . . . 0:0-4th: End of the 4th Quarter End of Game TASK Based on the games context and the data provided up to this point, what was the most likely event to occur? Answer Choices: (A) Player 3 (Team A) misses 20-foot two point shot (B) Player 3 (Team A) misses driving floating jump shot (C) Player 13 (Team A) blocks Player 19 (Team B) 5-foot two point shot (D) Player 3 (Team A) makes 13-foot jumper (Player 6 (Team A) assists) Correct Answer: (B) Deductive Reasoning Question:A time series xptq is generated by three-dimensional chaotic physical system (the Lorenz Attractor). The systems state rxptq, yptq, zptqs evolves according to the following deterministic set of coupled differential equations, approximated by the discrete-time Euler method. Extreme precision is required as even minor deviations can lead to incorrect results. System Rules: xptq xpt tq ` σ pypt tq xpt tqq yptq ypt tq ` pxpt tq pρ zpt tqq ypt tqq zptq zpt tq ` pxpt tq ypt tq β zpt tqq For this specific instance, the parameters are: σ 9.89, ρ 27.84, β 2.656, 0.01 The initial conditions at 0 are: px0, y0, z0q p0.31, 0.13, 0.8q Which of the following time series for xptq perfectly and completely represents the evolution of this system for all 120 steps? Answer Choices: (A) 0.31, 0.2922, . . . , -5.13478, -5.39509 (B) 0.31, 0.2922, . . . , -5.12121, -5.38171 (C) 0.31, 0.2922, . . . , -5.14932, -5.41033 (D) 0.31, 0.2922, . . . , -5.27837, -5.54593 Correct Answer: (C) Inductive Reasoning Question: This historical time series shows the monthly mean number of sunspotsthose cooler, dark patches on the Suns surface caused by intense magnetic activityfrom 09/1936 to 08/1969, where each timestamp represents month. Based on this data, the predicted monthly mean sunspot number for 02/1979 (rounded to the nearest integer) is? 24 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Answer Choices: (A) 18 (B) 35 (C) 48 (D) 195 Correct Answer: (D) Causal Discovery Question: Based on the daily runoff water level time series data from 5 river sensors in East Germany, which adjacency matrix most accurately describes the causal relationship between them? In the matrix, columns represent cause nodes, rows represent result nodes, and 1 indicates the presence of causal effects. 1 1 1 1 Answer Choices: (A) 5 2 5 (B) 2 (C) 2 5 (D) 2 3 4 3 4 3 3 Correct Answer: (B) Time Series Forecasting Question: An event occurred affecting the Dow Jones Industrial Average (DJIA) stock index. The event summary is: The overall PPI for final demand rose 0.4% in June, following 0.2% decline in May. The index for final demand goods increased 0.5%, while the index for final demand services rose 0.3%. The stage 4 intermediate demand index rose 0.5%, while the stage 3 intermediate demand index inched up 0.1%. The stage 2 intermediate demand index moved up 0.4%, and the stage 1 intermediate demand index increased 0.5%. The PPI for intermediate demand goods increased 0.4% in June, driven by 1.5% increase in processed goods and 0.9% decrease in unprocessed goods. The PPI for services for intermediate demand climbed 0.6%, driven by 1.3% increase in trade services and 0.5% rise in transportation and warehousing services. 25 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models The report also highlights the following key points: The PPI for final demand goods increased 2.1% over the past 12 months, while the index for final demand services rose 2.1%. The PPI for energy goods increased 2.9% over the past 12 months, while the PPI for food products increased 3.5%. The PPI for industrial materials, excluding food and energy, increased 1.5% over the past 12 months. The PPI for construction materials, such as lumber, plywood, and paper products, increased 1.4% over the past months. The PPI for machinery and equipment, such as motor vehicle parts, aircraft engines and parts, and medical devices, increased 1.3% over the past 12 months. The report also provides an overview of the prices of goods and services produced by domestic industries in the United States, covering sectors such as insurance, real estate, rental and leasing, professional services, employment, travel, security, cleaning, waste management, healthcare, education, accommodation, food, repair, entertainment, wholesale, retail, metal treatment, mining, and construction. The report shows that the overall PPI increased by 1.4% in June 2009 compared to the previous month, and by 4.3% compared to the same period in the previous year. The index for insurance and annuities increased by 1.7% in June 2009, while the index for real estate services increased by 4.0%. The index for rental and leasing of goods decreased by 0.2%, while the index for professional services increased by 2.1%. Overall, the PPI report suggests moderate pace of inflation, with prices rising across various categories, including goods and services. The report provides valuable insights for businesses, policymakers, and investors to understand inflationary pressures and make informed decisions. You are provided with the historical multivariate time series data for the 35 days leading up to and including the event day. Based on the historical data and the event context, which of the following options represents the most plausible trend for the Closing price over the next 35 days? Please choose the list of values that best corresponds to the predicted future trajectory. Answer Choices: (A) 17092.76, 17093.24, 17093.24, 17090.95, 17090.95, 17102.82, 17102.82, 17102.52, 17102.52, 17111.03, 17111.03, 17110.52, 17110.52, 17105.86, 17105.86, 17113.12, 17113.12, 17116.17, 17116.17, 17117.36, 17117.36, 17110.52, 17110.52, 17108.39, 17108.39, 17104.29, 17104.29, 17110.29, 17110.29, 17105.86, 17105.86, 17123.75, 17123.75, 17133.03, 17133.03 (B) 17084.81, 17084.81, 17094.09, 17094.09, 17111.98, 17111.98, 17107.55, 17107.55, 17113.55, 17113.55, 17109.45, 17109.45, 17107.32, 17107.32, 17100.48, 17100.48, 17101.67, 17101.67, 17104.72, 17104.72, 17111.98, 17111.98, 17107.32, 17107.32, 17106.81, 17106.81, 17115.32, 17115.32, 17115.02, 17115.02, 17126.89, 17126.89, 17124.60, 17124.60, 17125.08 (C) 17133.03, 17133.03, 17123.75, 17123.75, 17105.86, 17105.86, 17110.29, 17110.29, 17104.29, 17104.29, 17108.39, 17108.39, 17110.52, 17110.52, 17117.36, 17117.36, 17116.17, 17116.17, 17113.12, 17113.12, 17105.86, 17105.86, 17110.52, 17110.52, 17111.03, 17111.03, 17102.52, 17102.52, 17102.82, 17102.82, 17090.95, 17090.95, 17093.24, 17093.24, 17092.76 (D) 17133.03, 17133.03, 17142.31, 17142.31, 17160.20, 17160.20, 17155.77, 17155.77, 17161.77, 17161.77, 17157.67, 17157.67, 17155.54, 17155.54, 17148.70, 17148.70, 17149.89, 17149.89, 17152.94, 17152.94, 17160.20, 17160.20, 17155.54, 17155.54, 17155.03, 17155.03, 17163.54, 17163.54, 17163.24, 17163.24, 17175.11, 17175.11, 17172.82, 17172.82, 17173.30 Correct Answer: (C) TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Event Prediction Question: Your task is to predict whether it will rain or not in New York in the next 24 hours. Review the time-series data provided for the last 24 hours. Each time series consists of hourly values separated by token for the following indicators: Answer Choices: (A) Rain (B) No Rain Correct Answer: (B) Qualitative Decision Making Question: You are an expert cardiologist specializing in ECG interpretation and diagnosis of cardiovascular diseases. Your task is to analyze the 12-lead ECG signals and make clinical treatment decisions based on: 1. **Signal Pattern Recognition**: Identify pathological waveforms (ST elevation/depression, T-wave inversions, waves, QRS morphology) across all leads to recognize acute ischemia, infarction, or conduction abnormalities. 2. **Anatomical Correlation**: Recognize which leads correspond to specific cardiac regions (inferior, anterior, lateral, septal walls) to localize the affected myocardial territory and implicated coronary artery. 3. **Clinical Reasoning**: Integrate ECG findings with your knowledge of cardiac pathophysiology to determine disease acuity (emergent vs urgent vs elective) and appropriate treatment pathway (urgent reperfusion, ACS protocol, monitoring, medication adjustment). 4. **Differential Diagnosis**: Consider multiple conditions that could produce similar ECG patterns and select the most appropriate treatment based on the overall clinical picture and established guidelines (AHA/ACC/ESC). The time-series data represent normalized ECG signals sampled at 100 Hz. Each of the 12 leads provides different electrical view of the hearts activity. Analyze the morphology, amplitude, duration, and spatial distribution of waveforms systematically to guide evidence-based clinical decisions. Based on the 12-lead ECG analysis above and the provided signal data, what is the most appropriate clinical management? Answer Choices: (A) Clinical correlation; repeat ECG and consider stress test (B) Assess for hypertension; initiate antihypertensive therapy; echo (C) Monitor; often benign variant, but assess if symptomatic (D) Monitor digoxin levels; assess for toxicity (arrhythmias, GI, visual) Correct Answer: (A) Quantitative Decision-Making Question: You are quantitative analyst backtesting several trading strategies. Here are the five strategies youre evaluating: 27 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models (A) SMA Crossover (20/50): Buys when the 20-day moving average crosses above the 50-day moving average, sells when it crosses below. (B) MACD (12/26/9): Buys when the MACD line crosses above the signal line, sells when it crosses below. (C) RSI (14, 30/70): Buys when RSI falls below 30 (oversold condition), sells when RSI rises above 70 (overbought condition). (D) Bollinger Bands (20, 2σ): Buys when price falls below the lower band (P ă µ 2σ), sells when price rises above the upper band (P ą µ ` 2σ). (E) Buy and Hold: Enters the position at the beginning and holds it for the entire period. You have backtested these strategies on the provided price series with an initial capital of $10,000 and transaction cost of 0.1% per trade. Based on the price data provided and standard technical analysis principles, which strategy would you expect to achieve the best Maximum Drawdown (MDD)? Answer Choices: (A) SMA Crossover (B) MACD (C) RSI (D) Bollinger Bands (E) Buy and Hold Correct Answer: (D) G.2. Error Cases Perception Error Question: You are quantitative analyst backtesting several trading strategies. Here are the five strategies youre evaluating: (A) SMA Crossover (20/50): Buys when the 20-day moving average crosses above the 50-day moving average, sells when it crosses below. (B) MACD (12/26/9): Buys when the MACD line crosses above the signal line, sells when it crosses below. (C) RSI (14, 30/70): Buys when RSI falls below 30 (oversold condition), sells when RSI rises above 70 (overbought condition). (D) Bollinger Bands (20, 2σ): Buys when price falls below the lower band (P ă µ 2σ), sells when price rises above the upper band (P ą µ ` 2σ). (E) Buy and Hold: Enters the position at the beginning and holds it for the entire period. You have backtested these strategies on the provided price series with an initial capital of $10,000 and transaction cost of 0.1% per trade. Based on the price data provided and standard technical analysis principles, which strategy would you expect to achieve the best Maximum Drawdown (MDD)? Answer Choices: (A) SMA Crossover, (B) MACD, (C) RSI, (D) Bollinger Bands, (E) Buy and Hold Correct Answer: (D) Model Answer: (B) Prediction Rationale: In order to assess which strategy would result in the best Maximum Drawdown (MDD), we must understand that MDD is measure of the largest cumulative loss from peak to trough during the investment period. lower MDD means more favorable outcome in terms of risk. For the provided strategies, heres quick overview of their characteristics relevant to MDD: SMA Crossover is relatively simple and reacts to broader trends, MACD focuses on momentum and potential trend changes. RSI deals with overbought and oversold levels, suggesting possible reversals. Bollinger Bands consider volatility and mean reversion tendencies. Buy and Hold maintains TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models constant position, exposing it fully to market volatility. Since the price series provided doesnt show extreme volatility and has relatively steady pattern, momentum strategy like MACD or trend-following one like the SMA Crossover might perform better. RSI may suffer from whipsaws in less volatile conditions, and Bollinger Bands could result in numerous false signals. The Buy and Hold strategy is likely to have the highest MDD since it does not attempt to mitigate losses during downturns. Given the nature of the data and the strategies, the MACD, which identifies potential trend changes with its dual averaging process, might exhibit better control over drawdowns by exiting positions as momentum wanes. Hence, MACD might have the best MDD among the alternatives. Error Analysis: The primary error is misread of the time series regime. The model asserted the series was relatively steady and not highly volatile, then generalized that momentum (MACD) would best control drawdowns. This ignores the actual pattern implied by the ground truthBollinger Bands achieving the best MDD is consistent with an oscillatory/mean-reverting series where prices frequently touch/extreme-deviate from the 20-day mean. In such regimes, Bollinger entries occur near local troughs (below the lower band) and exits near local peaks (above the upper band), limiting time-in-market and capping peak-to-trough equity declineshence lower MDD. The models reasoning about false signals penalizes return stability but does not address maximum drawdown mechanics; meanwhile, MACD can remain exposed during adverse swings until crossover, allowing larger equity drawdowns. The failure to ground conclusions in the series features led to choosing MACD over the mean-reversion strategy that better minimizes MDD. Reasoning Error Question:A time series xptq is generated by three-dimensional chaotic physical system (the Lorenz Attractor). The systems state rxptq, yptq, zptqs evolves according to the following deterministic set of coupled differential equations, approximated by the discrete-time Euler method. Extreme precision is required as even minor deviations can lead to incorrect results. System Rules: xptq xpt tq ` σ pypt tq xpt tqq yptq ypt tq ` pxpt tq pρ zpt tqq ypt tqq zptq zpt tq ` pxpt tq ypt tq β zpt tqq For this specific instance, the parameters are: σ 9.85, ρ 28.14, β 2.693, 0.01 The initial conditions at 0 are: px0, y0, z0q p0.51, 0.99, 0.9q Which of the following time series for xptq perfectly and completely represents the evolution of this system for all 120 steps? Answer Choices: (A) 0.51, 0.55728, . . . , -9.42117, -9.90424 (B) 0.51, 0.55728, . . . , -9.53038, -10.01795 (C) 0.51, 0.55728, . . . , -9.40467, -9.8885 (D) 0.51, 0.55728, . . . , -9.37258, -9.8573 Correct Answer: (C) Model Answer: (A) Prediction Rationale:The problem requires precise simulation of the Lorenz system using the Euler method with given parameters. The initial conditions and equations are deterministic, so we need to simulate the system step-by-step 29 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models to identify the correct time series for xptq. The system evolves according to the discrete-time Euler method equations: xptq xpt tq ` σ pypt tq xpt tqq yptq ypt tq ` pxpt tq pρ zpt tqq ypt tqq zptq zpt tq ` pxpt tq ypt tq β zpt tqq For this specific instance, we are given the parameters σ 9.85, ρ 28.14, β 2.693, 0.01, and initial conditions at 0 of px0, y0, z0q p0.51, 0.99, 0.9q. Since the first few values in the options are identical, we simulate the immediate steps to verify the trajectory. For Step 1, we compute: x1 0.51 ` 0.01 9.85 p0.99 0.51q 0.55728 y1 0.99 ` 0.01 p0.51 p28.14 0.9q 0.99q 1.119024 z1 0.9 ` 0.01 p0.51 0.99 2.693 0.9q 0.880812 For Step 2, using the values from Step 1: x2 0.55728 ` 0.01 9.85 p1.119024 0.55728q 0.612588264 y2 1.119024 ` 0.01 p0.55728 p28.14 0.880812q 1.119024q 1.25984954 z2 0.880812 ` 0.01 p0.55728 1.119024 2.693 0.880812q 0.863336026 Comparing these computed values with the provided options, we look for the sequence that matches precisely. After simulating the entire sequence, we find that option matches the computed values. Thus, the answer is A. Error Analysis: The models reasoning is incomplete and unjustified for chaotic, precision-sensitive task. It computes only the first two Euler steps and then asserts that after simulating the entire sequence, option matches, without showing any mid/late-step calculations or an element-wise comparison to the four candidate series. In Lorenz system, early steps often look similar across candidates, while discriminating differences emerge later; the prompt explicitly emphasizes that extreme precision is required. The model neither carried the simulation through 120 steps nor addressed rounding/precision alignment with the provided series, making its conclusion unsupported. The ground truth (C) indicates that when the full, high-precision integration is performed and compared, does not match. Thus, the primary failure is flawed reasoning process: prematurely concluding based on partial computation and neglecting the necessary rigorous comparison. Domain Knowledge Error Question: The following time series shows daily meteorological data: temperature (C), relative humidity (%), net radiation (MJ/m2/day), and wind speed at 2m height (m/s). Using the FAO-56 Penman-Monteith equation, what is the total cumulative reference evapotranspiration (ET0) over this period (in mm)? Answer Choices: (A) 67.9, (B) 116.5, (C) 166.4, (D) 216.3 Correct Answer: (C) Model Answer: (D) Prediction Rationale: To calculate the total cumulative reference evapotranspiration (ET0) using the FAO56 Penman-Monteith equation, we apply the formula 30 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models for each day and sum the results. The equation used is: ET0 0.408pRn Gq ` γ ˆ p900{pT ` 273qq ˆ u2 ˆ VPD ` γ where ET0 is in mm/day, is slope of vapor pressure curve, Rn is net radiation, 0, γ 0.067, is temp, u2 is wind speed, and VPD is vapor pressure deficit. Estimation from graph: We estimated daily values for 25 days. For example: Day 0: 28C, RH 50%, Rn 13.5, u2 3.0. Calculated ET0 8.22 mm/day. Average conditions: 25C, RH 50%, Rn 13.5, u2 3.0. Calculation: Using average values (T 25C), we computed ET0 7.66 mm/day. Total over 25 days 191.5 mm. Sensitivity check with higher temperatures: At 29C: ET0 8.31 mm/day Ñ Total 207.75 mm. At 30C: ET0 8.40 mm/day Ñ Total 210.0 mm. Given temperatures often exceed 28C and high radiation, the total is likely around 215220 mm. Option (216.3) matches this estimate best. Error Analysis: The model systematically overestimated the result due to **domain knowledge error** in the formula application. It used an incorrect denominator ( ` γ) instead of the standard FAO-56 form ( ` γp1 ` 0.34u2q). By omitting the wind speed correction term (1 ` 0.34u2), the model significantly underestimated the aerodynamic resistance, inflating daily ET0 values by approx. 27%, pushing the cumulative total from 166.4 mm (Ground Truth) to 216.3 mm (Models choice). Question Understanding Error Question: Based on the daily runoff water level time series data from 5 river sensors in East Germany, which adjacency matrix most accurately describes the causal relationship between them? In the matrix, columns represent cause nodes, rows represent result nodes, and 1 indicates the presence of causal effects. 1 1 1 1 Answer Choices: (A) 5 2 5 (B) 2 (C) 2 5 (D) 2 3 4 3 4 3 3 Correct Answer: (A) Model Answer: (D) Prediction Rationale: To determine the most accurate adjacency matrix, first need to understand the relationships between the time series data of the rivers. The rivers with higher magnitudes in their time series (e.g., River 175, 176, 177) show large spikes, suggesting possible influence from upstream rivers. River 119 and 257 have lower and more consistent values, likely being affected by the larger rivers. 31 TSRBENCH: Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models Analyzing the options, the matrix that best reflects causal relationships from the larger rivers to the others is option D. It indicates that River 176 (second row) influences River 175, and River 175 influences others (first row), which aligns with the observed data patterns. Error Analysis: The model misinterpreted the adjacency matrix orientation specified in the question. The prompt clearly states that columns represent cause nodes and rows represent result nodes. However, in its justification, the model said the matrix indicates that River 176 (second row) influences River 175, which treats rows as causes rather than results. This inversion leads to fundamentally wrong reading of edges in option (e.g., D[2,3]=1 actually means node 3 causes node 2, not that row 2 causes row 3). While the model also relied on weak heuristic (magnitude/spikes imply causality), the decisive error is the matrix semantics misunderstanding, which directly corrupted the mapping from observed relationships to matrix entries and explains the selection of over the ground truth A."
        }
    ],
    "affiliations": [
        "Mohamed bin Zayed University of Artificial Intelligence",
        "University of California, San Diego",
        "University of Illinois at UrbanaChampaign",
        "University of Maryland, College Park"
    ]
}