{
    "paper_title": "QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL",
    "authors": [
        "Cong Yu",
        "Valter Uotila",
        "Shilong Deng",
        "Qingyuan Wu",
        "Tuo Shi",
        "Songlin Jiang",
        "Lei You",
        "Bo Zhao"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Designing and optimizing task-specific quantum circuits are crucial to leverage the advantage of quantum computing. Recent large language model (LLM)-based quantum circuit generation has emerged as a promising automatic solution. However, the fundamental challenges remain unaddressed: (i) parameterized quantum gates require precise numerical values for optimal performance, which also depend on multiple aspects, including the number of quantum gates, their parameters, and the layout/depth of the circuits. (ii) LLMs often generate low-quality or incorrect quantum circuits due to the lack of quantum domain-specific knowledge. We propose QUASAR, an agentic reinforcement learning (RL) framework for quantum circuits generation and optimization based on tool-augmented LLMs. To align the LLM with quantum-specific knowledge and improve the generated quantum circuits, QUASAR designs (i) a quantum circuit verification approach with external quantum simulators and (ii) a sophisticated hierarchical reward mechanism in RL training. Extensive evaluation shows improvements in both syntax and semantic performance of the generated quantum circuits. When augmenting a 4B LLM, QUASAR has achieved the validity of 99.31% in Pass@1 and 100% in Pass@10, outperforming industrial LLMs of GPT-4o, GPT-5 and DeepSeek-V3 and several supervised-fine-tuning (SFT)-only and RL-only baselines."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 ] . [ 1 7 6 9 0 0 . 0 1 5 2 : r QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL QUASAR: QUANTUM ASSEMBLY CODE GENERATION USING TOOL-AUGMENTED LLMS VIA AGENTIC RL Cong Yu1, Valter Uotila1, 2, Shilong Deng3, Qingyuan Wu4 Tuo Shi1, Songlin Jiang1, Lei You5, Bo Zhao1, * 1 Aalto University, 2 University of Helsinki, 3 University of Liverpool, 4 University of Southampton, 5 Technical University of Denmark"
        },
        {
            "title": "ABSTRACT",
            "content": "Designing and optimizing task-specific quantum circuits are crucial to leverage the advantage of quantum computing. Recent large language model (LLM)-based quantum circuit generation has emerged as promising automatic solution. However, the fundamental challenges remain unaddressed: (i) parameterized quantum gates require precise numerical values for optimal performance, which also depend on multiple aspects, including the number of quantum gates, their parameters, and the layout/depth of the circuits. (ii) LLMs often generate low-quality or incorrect quantum circuits due to the lack of quantum domain-specific knowledge. We propose QUASAR, an agentic reinforcement learning (RL) framework for quantum circuits generation and optimization based on tool-augmented LLMs. To align the LLM with quantum-specific knowledge and improve the generated quantum circuits, QUASAR designs (i) quantum circuit verification approach with external quantum simulators and (ii) sophisticated hierarchical reward mechanism in RL training. Extensive evaluation shows improvements in both syntax and semantic performance of the generated quantum circuits. When augmenting 4B LLM, QUASAR has achieved the validity of 99.31% in Pass@1 and 100% in Pass@10, outperforming industrial LLMs of GPT-4o, GPT-5 and DeepSeek-V3 and several supervised-fine-tuning (SFT)-only and RL-only baselines. We release our model at HuggingFace and provide the training code at GitHub."
        },
        {
            "title": "INTRODUCTION",
            "content": "Quantum hardware has improved remarkably in recent years (AI & Collaborators, 2025; Bravyi et al., 2024; Bluvstein et al., 2024) and this rapid hardware development creates demand for improved quantum software and algorithms. Quantum software and algorithms can be categorized into classical platforms that support quantum computers themselves, including quantum error mitigation software and quantum compilers. The second category comprises domain-specific quantum algorithms, including examples like Shors algorithm and Grovers algorithm. At the core of quantum software and algorithms is the quantum circuit model (Nielsen & Chuang, 2010), which is an assembly-level abstraction for operating gate-based quantum computers. Most of the quantum algorithms can be expressed as quantum circuits (Jordan, 2025). The design of quantum circuits is the foundation in quantum compilers and quantum algorithm development. In this paper, we consider quantum assembly code, i.e., Open Quantum Assembly Language (OpenQASM) (Cross et al., 2022), to represent and model quantum circuits due to its generality and machine-independence the generated circuits can be deployed on any quantum machines without binding to specific vendors. Unlike Python-based quantum programming languages (e.g., Qiskit (Javadi-Abhari et al., 2024a) and Cirq (Developers, 2025)), OpenQASM is low-level language and closer to the QPU hardware (similar to classical assembly languages in CPUs). The value of OpenQASM lies in platform-agnostic quantum software stacks, including quantum software-hardware co-design, performance characterization, and cross-platform bench- *Corresponding author: bo.zhao@aalto.fi 1 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL marking. Leading quantum hardware vendors offer OpenQASM as an interface to their QPUs, alongside their own development kits (e.g., Braket SDK (Amazon Web Services), Cirq and Qiskit). Despite their central role in quantum computing, quantum circuits present two major difficulties in practice. First, they form complex abstraction to define quantum algorithms compared to classical methods, making them difficult even for expert practitioners (Haferkamp et al., 2022). Second, such difficulties are further amplified in OpenQASM code, which is particularly error-prone to write for complex quantum algorithms Cross et al. (2022) due to its unique low-level grammar and syntax. We identify three key challenges in quantum circuit generation: (1) QASM code includes numerous numerical parameters in parametrized gates, which are difficult for LLMs to handle accurately; (2) unlike classical code generation, QASM evaluation is nontrivial, as its correctness depends not only on syntactic validity but also on the underlying quantum semantics, which are inherently probabilistic and nondeterministic; and (3) LLM-generated QASM can fail in various ways (see Figure 1), including compilation error, producing incorrect qubit counts and low-quality parameters. Fig. 1: Illustration of four possible outcomes for generated OpenQASM code: (a) fails to compile; (b) compiles but uses an incorrect number of qubits; (c) compiles with the correct number of qubits but suboptimal parameters; (d) the desired case compiles successfully, uses the correct number of qubits, and achieves near-optimal parameters. We present QUASAR, an agentic RL post-training framework for LLMs to generate quantum circuits in OpenQASM 3.0. QUASAR achieves this through two key innovations. First, to equip the model with quantitative understanding of parameterized gates, we develop an agentic RL pipeline with carefully designed external quantum verification tool, in which an LLM interacts directly with quantum simulators. Second, we design hierarchical four-level reward mechanism that enforces correctness as prerequisite and, conditioned on correctness, promotes stronger task alignment in the generated circuits. While LLMs are not considered native optimizers for quantum circuit parameters, QUASAR shows that they can learn beneficial ansatz patterns and initial parameter configurations for quantum optimization problems, as illustrated in Figure 2. q0 : q1 : q2 : q3 : q4 : q5 : H RY (1.445) RY (0.1259) RY (0.0005) RY (1.442) RY (1.571) RY (1.442) RY (0.121) RY (0.1183) RY (0.7003) RY (0.4962) RY (0.2489) RY (0.0227) RY (1.034) RY (0.4549) RY (0.3788) RY (0.1488) Fig. 2: Example of an LLM-generated ansatz with initial parameters. 2 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL More precisely, the hierarchical reward mechanism consists of four stages. (1) The syntax reward considers whether the LLM-generated OpenQASM code can be parsed. If this fails, the other rewards cannot be computed, and thus, this reward is set relatively high. (2) The system computes JensenShannon entropy (Menendez et al., 1997) between the LLM-generated and ground truth distributions in computational basis states, which creates so-called distributional alignment term for the model. (3) The third reward considers the expectation value discrepancies between LLMgenerated and ground-truth circuits for task-specific alignmentcomputing expectation values re- (4) The fourth part reward quires the problem-specific cost Hamiltonian (Abbas et al., 2024a). function examines the usability of the LLM-generated circuit in realistic setup where the circuit optimization continues. This reward counts the number of optimization steps and computes the final optimized expectation value. The final reward for the fourth part is weighted sum of these two elements. In this paper, we make the following contributions. We design an end-to-end processing pipeline to combine supervised fine-tuning and RLbased post-training, which efficiently interacts with an external quantum verification tool. We design 4-level hierarchical reward mechanism for RL that jointly optimizes syntactic validity, distributional similarity, expectation value differences, and the number of required optimization steps to generate quantum circuits tailored for specific optimization problems. We evaluate QUASAR to augment an example LLM, 4B-Qwen3 model, which outperforms several leading industrial LLMs. The results demonstrate that LLMs can generate practical ansatz patterns and parameter initializations for Quantum Approximate Optimization Algorithm (QAOA) and Variational Quantum Eigensolver (VQE) quantum circuits, highlighting QUASARs potential in scalable quantum circuits and algorithm design."
        },
        {
            "title": "2 RELATED WORKS",
            "content": "In recent years, there has been increasing interest in applying GPTand LLM-based tools to address challenges in designing and constructing circuits for various quantum computational challenges. In one of the first works, IBM Quantum (2025) fine-tuned large language models to serve as Qiskit Code Assistant, which was evaluated with (Vishwakarma et al., 2024). This work was further improved with post-training reinforcement learning (Dupuis et al., 2025a). Campbell et al. (2025) leveraged Chain-of-Thought (CoT) reasoning and Retrieval-Augmented Generation (RAG) in multi-agent setting to facilitate the synthesis of quantum circuits. These efforts are closely tied to the Qiskit framework, whereas our approach targets OpenQASM 3.0 Cross et al. (2022), platform-independent standard now supported by Qiskit, PennyLane, and Cirq. LLMs have also been used for optimizing ansatz design (Liang et al., 2023; Ueda & Matsuo, 2025), and Arlt et al. (2024) used language models to design quantum experiments. Gujju et al. (2025) utilized LLMs for guided ansatz design in financial modeling. Compared to LLM-based methods, standard transformers and GPT-based systems have received more attention. Fitzek et al. (2024) trained the standard GPT model to predict measurement outcomes from neutral atom quantum computer. The findings revealed limitations in the standard GPT models ability to predict measurement outcomes, which could prove valuable in expanding our knowledge of the boundaries of present-day LLMs. Using the standard transformer-based approach, Nvidia has designed an optimization pipeline that produces quantum circuits, which are aimed at identifying ground states in electronic structure Hamiltonians (Nakaji et al., 2024). Since the trainable parameters are in the transformer model, the method tries to circumvent some of the problems in current variational methods, like barren plateaus. Apak et al. (2024) developed KetGPT, which uses GPT-based model to generate realistic quantum circuits. The model is trained in QASMBench circuits (Li et al., 2023). The circuits are restricted to the OpenQASM 2.0 format, without supporting parameters. Finally, Tyagin et al. (2025) developed QAOA-GPT, which is capable of generating QAOA-type circuits that solve the MaxCut problem. Dupuis et al. (2025b) is the first to use quantum-verifiable reward to post-training LLMs to generate Qiskit code. 3 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL"
        },
        {
            "title": "3.1 QUANTUM COMPUTING AND QUANTUM OPTIMIZATION",
            "content": "Quantum computing exploits the principles of quantum mechanics to perform computations using quantum bits (qubits) instead of classical bits. qubit is unit vector in two-dimensional Hilbert space and can exist in superposition α0 + β1 with α, β and α2 + β2 = 1 (Nielsen & Chuang, 2010). Multi-qubit states arise via tensor products, and computation proceeds by applying unitary gates. Rotation gates Rx(θ), Ry(θ), Rz(θ) are unitary for all θ, and together with entangling operations (e.g., CNOT) and standard gates (e.g., Hadamard, CZ), they form universal gate set (Yang et al., 2023). By combining these gates into parameterized circuits (θ), one obtains flexible framework for variational quantum algorithms. One of the most promising applications is quantum optimization (Abbas et al., 2024b). Classical problems such as QUBO and HUBO (Lucas, 2014; Boros & Hammer, 2002) can be rewritten in terms of spin variables and mapped to Pauli-Z operators, turning them into Hamiltonian minimization tasks. The goal is to prepare parameterized state (θ)0 whose expectation value 0U (θ)HU (θ)0 approximates the ground state of H. Hybrid quantum-classical methods iteratively optimize θ: QAOA uses cost Hamiltonian and mixer ansatz (Farhi et al., 2014), VQE employs expressive or hardware-efficient ansatzes (Peruzzo et al., 2014), and adaptive VQE constructs circuits gate by gate from predefined pool (Grimsley et al., 2019). 3.2 OPENQASM LANGUAGE OpenQASM (Open Quantum Assembly Language) (Cross et al., 2022) is low-level programming language designed for expressing quantum circuits and operations, which is similar to traditional Hardware Description Language (HDL) like Verilog and VHDL. It serves as an intermediate representation (IR) for quantum algorithms, allowing them to be executed on various quantum hardware platforms. OpenQASM provides standardized way to describe quantum gates, measurements, and other operations, making it easier for developers to write and share quantum programs. OpenQASM is widely used in the quantum computing community, since many popular quantum computing software frameworks, such as IBMs Qiskit (Javadi-Abhari et al., 2024b), Googles Cirq (Developers, 2025), Microsofts QDK (Microsoft), and Rigettis Forest(Smith et al., 2017), support OpenQASM as means of serializing quantum circuits in standard way. This allows developers to write quantum algorithms in high-level language and then compile them down to OpenQASM for distribution between different quantum hardware backends. OpenQASM has become the conjunction between quantum software and hardware, being critical for both platform-agnostic and platform-specific optimization, mapping, scheduling, evaluation, profiling, and simulation. 3.3 AGENTIC REINFORCEMENT LEARNING WITH TOOL USE Agentic Reinforcement Learning with Tool use (ARLT) can efficiently enhance domain-specific performance in the LLM post-training stage, allowing LLMs to use tools to interact with the environment and learn from verified feedback. Specifically, the policy LLM πθ aims to predict the next token τt based on the context τ<t. The entire response τ will be evaluated by the verified reward function R. GRPO (Shao et al., 2024) is the commonly used RL algorithm in recent ARLT works (Jiang et al., 2025; Qian et al., 2025), and has been proven successful since DeepSeek-AI et al. (2025). Specifically, given group of rollout trajectories {R(τi)}G i=1, the objective of GRPO is defined as follows: (θ) = 1 (cid:88) i=1 1 τ τ (cid:88) t=1 (cid:104) min t(θ) ˆAi ri t, clip (cid:0)ri t(θ), 1 ϵ, 1 + ϵ(cid:1) ˆAi (cid:105) , (1) t(θ) = πθ(τ where ri πold(τ the normalized advantage. τ τ <t) <t) is the token-level importance ratio and ˆAi = R(τ i)mean({R(τ )}G std({R(τ )}G j=1) j=1)) is 4 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL"
        },
        {
            "title": "4.1 RL POST-TRAINING PIPELINE",
            "content": "(a) Agentic RL-Quantum Framework (b) Hierarchical Reward Workflow Fig. 3: QUASAR design: (a) agentic RL-quantum framework, and (b) hierarchical reward. Online Interaction with Quantum Agent. Building on Jiang et al. (2025), our quantum agent consolidates the environment and reward computation into single tool module (see Figure 3). At each RL step: (A) the language model proposes an OpenQASM circuit and calls the external tool Quantum Tool Server, via HTTP; (B) the agentic tool executes certain quantum simulation and computes verifiable reward; (C) it returns structured feedback, which includes the scalar reward, execution errors, validity flags, and trajectory trace; and (D) the training loop ingests this feedback and updates the policy via GRPO. To bootstrap syntactic competence, we first perform supervised fine-tuning without intermediate reasoning traces (non-CoT SFT) using the dataset of Jern et al. (2025). We then apply ARLT to further improve both syntactic and semantic correctness, using simulation-derived signals to shape the policy through policy-gradient updates. Quantum Verification. LLMs can generate code in languages such as Python, C++, and x86-64 based on (Wei et al., 2025), but generating low-level quantum circuits is particularly challenging (Fu et al., 2025). OpenQASM is domain-specific language with limited exposure during pretraining, making it difficult for models to produce syntactically correct and semantically meaningful circuits. In addition, designing quantum circuits requires deep understanding of the target optimization problem and underlying quantum computing principles. To address these challenges, we integrate an agentic quantum verification module into our RL framework. This module simulates the generated OpenQASM code and evaluates its performance on carefully designed quantum tasks. The resulting metrics are transformed into reward signals that guide the training. 4.2 REWARD DESIGN Hierarchical reward mechanism. We introduce hierarchical reward that covers four key aspects of the generated OpenQASM code: (i) syntactic correctness, (ii) distributional alignment (an entropy-based term), (iii) an expectation-value term, and (iv) an optimization-progress term. The computation is hierarchical: we first verify the syntactic correctness of the generated OpenQASM; if it is valid, we then measure the distributional discrepancy between the generated and ground-truth circuits (e.g., via the JensenShannon distance DJS(pgen, pgt)) to quantify overall mismatch. Notably, generated circuits often realize unitaries ˆU that deviate substantially from the ground truth , leading to markedly different measurement distributions in the computational basis. Yet for given quantum optimization task, performance can still be comparable because evaluation is with respect to the problem Hamiltonian H, via E(ψ) = ψHψ. To capture this task-specific behavior, we augment the objective with two problem-aware terms: (a) an expectation-value reward that calculates the distance between the eigenvalues of the generated circuit and the ground truth circuit, and (b) an optimization-progress reward that credits the improvement achieved by local optimizer. The reward is based on the optimization steps from the generated circuit to the optimal, and the gap between the final converged circuit and the ground truth one. 5 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL In addition to the above rewards, we introduce qubit-mismatch penalty in stage (ii) to discourage the generation or disappearance of qubits. This penalty addresses common issue in our training loop, where LLMs often generate circuits with qubit count inconsistent with the ground-truth circuit, leading to reward calculation errors. For example, prompt requesting 9-qubit circuit may result in the LLM producing qubit[7] q;. We adopt hierarchical procedure to compute rewards, as illustrated in Figure 3b. Specifically, if the distributional divergence between the generated and ground-truth circuits exceeds predefined threshold, we additionally evaluate Hamiltonian-based expectation-value reward. If either the (normalized) expectation-value reward surpasses its threshold or the distributional divergence falls below its threshold, we proceed to run local optimizer and assign an optimization-progress reward. This hierarchical design ensures the objective is robust to circuits that differ in distribution but are equally fit for the given task. The intuition is that high entropy-based reward already indicates strong distributional alignment, making expensive eigenvalue comparisons unnecessary. Conversely, if the entropy-based reward is low, we assess problem-specific similarity via eigenvalues. Only when either the distributional or expectation-value scores are sufficiently high do we perform local optimization; otherwise, the circuits are deemed too low-quality to justify further evaluation. In the following, we introduce each of the four reward components in detail. 4.2.1 SYNTACTIC REWARD Syntactic reward refers to the syntactic correctness of the circuits. circuit is considered syntactically correct if the Qiskit QASM 3.0 parser can parse it. This implies that it follows the grammatical rules of the OpenQASM standard (Cross et al., 2022). If the generated QASM fails to compile, the reward calculation process ends and returns 1. 4.2.2 ENTROPY REWARD Previous work Jern et al. (2025) evaluated the quality of circuits with respect to relative entropy, i.e., Kullback-Leibler divergence. In this work, we design the reward as the JensenShannon distance, which can be understood as normalized relative entropy to the interval [0, 1] for the stability of RL training. The Jensen-Shannon distance is implemented as dJS = (p, q) = (cid:115) JS(p q) log , (2) where 2 DKL(p m) + 1 for probability distributions and and DKL is the standard KL-divergence. The distribution = 1 2 (p+q). The reward is 1dJS(p, q) [0, 1], so that reward of 1.0 is returned for those distributions that are identically the same, and 0 for those that are very different. 2 DKL(q m), JS(p q) = As mentioned earlier, the generated QASM may have different number of qubits than the groundtruth QASM, which makes the entropy-based reward inapplicable due to the resulting dimension mismatch. Let ngen and ngt be the qubit counts of generated and ground-truth QASM and = min(ngen, ngt). We define qubit-mismatch penalty Rqm = clip[0.2,0] (cid:0)α + β + γ aextra + η ecross (cid:1), = ngen ngt, where aextra counts active extra qubits beyond the first (idle or reset-only ancillas incur little or no penalty) and ecross counts multi-qubit gates that entangle extras with core wires. To ensure fairness, the distribution term DJS is computed on the first qubits (marginalization), and its weight is downscaled by the mismatch severity. Note that for the expectation-value term and the optimization-progress term below, we pad the problem Hamiltonian with identities to ensure that its width matches the circuit, thereby preserving comparability while preventing reward hacking via ancillary qubits. 4.2.3 EXPECTATION-VALUE REWARD The training dataset consists of optimization problems expressed as eigenvalue minimization problems. Measuring from an ideal circuit would return the optimal eigenvalue with probability 1. This 6 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL means that the expectation value from this circuit would coincide with the eigenvalue. In the realistic cases, the measured expectation values over the weighted eigenvalues from the circuits are always larger than the optimal result. The expectation value from the LLM-generated circuit and the ground truth optimal eigenvalue enable us to construct the third reward function as follows. For syntactically correct LLM-generated quantum circuit, we simulate the circuit and compute the expectation value of the problem-specific cost Hamiltonian. Let his value be Egen. To establish reference for comparison, we also compute the minimum (optimal solution) and maximum eigenvalues for the problem-specific cost Hamiltonian. Let these values be Emin and Emax. Because 0 Emin < Egen < Emax, we calculate the min-max normalized value as min max(Egen) := Egen Emin Emax Emin , (3) which is again value in the interval [0, 1]."
        },
        {
            "title": "4.2.4 OPTIMIZATION REWARD",
            "content": "It is unlikely that LLMs generate parameterized quantum circuits that are immediately solutions to the given optimization problems. Thus, the realistic pipeline includes phase where the user continues optimizing the parameters in the LLM-generated circuit. Given the complexity of the parameter optimization problem, the most realistic measure of the usefulness of the LLM-generated circuit is the number of optimization steps required to achieve an optimized circuit, where sufficiently low expectation value can be measured. Hence, the system implements module that allows for ongoing optimization. In this case, the reward is defined as 1/(1 + n), where is the number of optimization steps required for the LLM-generated circuit to reach an optimized quantum circuit for the given optimization problem. Additionally, the system should favor those generated quantum circuits with which the lower expectation value can be obtained. Let Eopt be the expectation value after the optimization loop has been applied to the LLM-generated quantum circuit. Let Emin again be the ideal ground truth, i.e., the optimal eigenvalue. Then, we include 1 1 + + min max(Eopt), (4) where min max was defined in Equation 3."
        },
        {
            "title": "5 EXPERIMENTS",
            "content": "5.1 EXPERIMENTAL SETUP Training Setup. We utilize the training data from (Jern et al., 2025), which is one of the most extensive available datasets of quantum circuits in QASM format covering 12 central optimization problem primitives on graphs (Karp, 1972), and many of their abstract descriptions appeared in (Lucas, 2014). Since Jern et al. (2025) does not describe these problems in detail, we include more detailed description for each problem in the Appendix C.2. The key characteristics in this dataset are the parametrized circuits with optimal parameters, the problem Hamiltonians, and the smallest and largest eigenvalues for the Hamiltonians. The full dataset is constructed so that for each optimization problem, the system generates random graph, where the problem is solved using QAOA, VQE, and adaptive VQE. If the quantum optimization problem is simulable and optimization converges, the problem, graph, circuits in QASM format, and Hamiltonian, along with other data, are included in the training dataset. The complete details of the problem are provided in the Appendix C.2. We fine-tune 4B SFT model with GRPO on 16H100-64GB GPUs using FSDP (Zhao et al., 2023). Each prompt samples n=16 rollouts via vLLM (Kwon et al., 2023) (temperature 0.7, topp = 0.8). The average training time is 48 hours. More details can be found in Appendix A. Evaluation Metrics. We evaluate the fine-tuned model across four complementary metrics designed to assess both syntactic fidelity and optimization quality. First, we measure syntactical correctness ratio (SCR), defined as the percentage of generated outputs that can be parsed as valid OpenQASM 3.0 circuits using Qiskits QASM parser. This metric captures whether the model has 7 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL internalized the grammar of the domain-specific language. Second, we perform successful rate of expectation value (SREV), where each syntactically correct circuit is simulated and the expectation value for the problem-specific cost Hamiltonian is computed. We compute the expectation value of generated circuit as E(C) = ψCHψC. Let denote the ground-truth QASMs expectation. The circuit is counted as successful if E(C) 0.2, and SREV is the percentage of successful QASMs. Third, we evaluate the relative entropy (RE) of probability distributions by computing the KL divergence DKL(Psol Pgen) between the outcome distribution of the generated circuit and that of the optimized reference. Finally, we compute the High-Quality Circuit Ratio (HQCR), defined as the proportion of generated circuits whose relative entropy against the ground-truth distributions is within threshold 0.1. This metric provides more interpretable measure of how often the model produces reasonable solutions. Each metric is measured in Pass@1 and Pass@10, where Pass@1 evaluates whether single sampled QASM per prompt meets the criterion, and Pass@10 evaluates whether at least one out of ten sampled QASMs meets the criterion. Results are shown in Table 1, where up/down arrows by column names indicate whether higher or lower values are better. Baselines. The baselines can be categorized into three groups. (i) Prompting-Based State-of-theart LLMs: We evaluate DeepSeek-V3 (Liu et al., 2024) and OpenAIs GPT-4o (Hurst et al., 2024) and GPT-5 (OpenAI, 2025) via their official API, with GPT-5 being OpenAIs latest flagship. All models are evaluated using few-shot prompting with four demonstration examples. (ii) SFT-only: We train Qwen-3-4B using SFT only. (iii) RL-only: We evaluate cold-start model trained using the GRPO algorithm (Shao et al., 2024). 5.2 RESULTS Tab. 1: QUASARs Pass@K and comparison with existing techniques. Methods SCR SREV RE HQCR SCR SREV RE HQCR Pass@1 Pass@10 Few-Shot Prompting DeepSeek-V3 GPT-5 GPT-4o 94.83% 87.07% 87.93% 12.24% 10.00% 9.83% 19.20 19.94 19.42 10.00% 6.90% 6.38% 98.97% 90.52% 88.79% 26.38% 27.07% 18.62% Post-Training (Qwen3-4B) SFT Cold Start GRPO QUASAR (ours) 97.41% 84.48% 99.31% 18.97% 19.84% 22.41% 12.74 14.32 11.61 15.17% 12.41% 17.24% 99.65% 95.17% 100% 31.55% 27.59% 33.10% 16.39 11.57 14.08 10.81 11.38 8.48 16.38% 16.55% 12.07% 23.62% 18.96% 27.24% Performance Analysis. We report the performance of QUASAR in Table 1. QUASAR achieves strong results against all baselines, with pass@1 of 99.31% SCR. Compared to the best competing methods, it yields +12.95% improvement in SREV (22.41 vs. 19.41 for Cold Start (GRPO)), an +8.87% reduction in RE (11.61 vs. 12.74 for SFT), and +13.64% gain in HQCR over SFT. For pass@10, we even achieve 100% syntactical correctness and even better semantic improvement. Meanwhile, as noted earlier, HQCR was measured with fixed threshold of 0.1. In Figure 4, we vary this threshold from 0.1 to 0.9 and report The fraction of valid QASMs that qualify as highquality. At best, QUASAR achieves +13.65% improvement over SFT, +72.4% over DeepSeek-V3, and up to 1.65 and 1.50 improvements over GPT-4o and GPT-5, respectively. Furthermore, to quantify the semantic closeness of the generated QASMs to the ground truth, we also measure = E(C) defined before; note that smaller values indicate higher-quality QASMs. Figure 5 illustrates the distribution of for each model, QUASAR achieves substantial improvements over all baselines, including 4.9% reduction in the median and 9.7% reduction in the upper quartile compared to the second-best SFT. In addition, we compare QUASAR-generated QASMs with random parameter initialization baseline, common practice in hybrid quantum-classical algorithms. For each QUASAR circuit, we evaluated JS-divergence and expectation value relative to the Hamiltonian and ground truth, alongside 100 randomized variants with parameters sampled from (π, π]. The results show that QUASAR consistently outperforms random initialization, achieving lower JS-divergence (0.79 vs. 0.95) and 8 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL expectation values closer to the optimum (0.16 vs. 0.36). Further details are provided in Appendix D."
        },
        {
            "title": "5.3 ABLATION STUDY OF THE HIERARCHICAL REWARD",
            "content": "We quantify the contribution of each reward term by independently removing each component of the hierarchy reward in section 4. For each variant, we disable exactly one component while keeping the remainder unchanged; we also report Validity-only sanity baseline, which only returns reward based on whether the generated QASM is valid(1) or not(1). All runs are initialized from the same SFT checkpoint and trained with matched compute (identical optimizer, schedule, batch size, steps, and decoding settings). The evaluation metrics are the same as presented in section 4, and the results are summarized in Table 2. Distributional alignment (RE) is the primary driver of all metrics. Removing RE causes the largest drop across semantic metrics and, unexpectedly, even harms syntactic correctness. This highlights that coarse-grained alignment of measurement distributions is essential for effective reward shaping. Expectation value (EV) safeguards hard cases. Disabling EV reduces SREV as expected and slightly degrades other semantic metrics. When distributional divergence is high, EV provides task-specific signal that rescues otherwise borderline QASMs. Optimization progress (Opt) provides incremental gains. Removing Opt leads to notable drop in HQCR, with larger gap at Pass@10 than at Pass@1. This suggests that rewarding fewer optimization steps can also benefit the training. Qubit mismatch penalty (QMP) ensures stability. Without QMP, qubit-count inconsistencies increase and reward noise emerges (e.g., evaluation failures or padded comparisons), lowering all metrics. Validity-only rewards are insufficient. reward that enforces only basic validity achieves reasonable SCR but lags considerably on SREV, RE, and HQCR, even performing slightly worse than SFT. This underscores the necessity of semantically informed reward signals. Fig. 4: HQCR with varying threshold. Fig. 5: for valid QASMs. Tab. 2: Reward ablation for QUASAR: contribution of each component. Variant Components SCR SREV RE HQCR SCR SREV RE HQCR Pass@1 Pass@10 Full (QUASAR) Val + RE + EV + Opt + QMP 99.31% 22.41% w/o EV term w/o RE term w/o Opt term w/o QMP Val + RE + Opt + QMP Val + EV + Opt + QMP Val + RE + EV + QMP Val + RE + EV + Opt Validity only Val 98.62% 66.38% 98.79% 98.79% 20.69% 5.17% 21.90% 21.72% 99.13% 18.79% 11.61 11.82 24.67 11.98 12. 12.89 17.24% 100% 33.10% 16.38% 5.69% 16.90% 16.21% 100% 79.82% 100% 100% 31.03% 15.52% 32.76% 31.55% 14.66% 100% 30.86% 8.48 9.12 18.26 9.01 9. 11.27 27.24% 26.72% 16.90% 26.55% 27.06% 23.27%"
        },
        {
            "title": "6 CONCLUSION",
            "content": "We presented QUASAR, an agentic reinforcement learning framework for post-training large language models to generate OpenQASM 3.0 circuits with high syntactic validity and semantic fidelity. By integrating an external verification tool with quantum-aware RL and hierarchical reward that enforces syntax, aligns distributions, reduces expectation-value errors, and promotes optimization efficiency, QUASAR consistently outperforms leading industrial LLMs and SFT-only and RL-only 9 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL baselines across quantum optimization benchmarks. Our results highlight that distributional alignment is the key driver of quality, while expectation-value and optimization-progress terms provide complementary gains, demonstrating that tool-augmented RL can effectively bridge general-purpose LLMs and domain-specific quantum code generation, paving the way for broader applications in automated quantum algorithm design. Appendix discusses the limitations and future directions."
        },
        {
            "title": "7 ACKNOWLEDGEMENT",
            "content": "This work is funded by Research Council of Finland (grant number 362729) Business Finland (grant number 169/31/2024), and the Finnish Quantum Doctoral Programme (QDOC), to PI Bo Zhao. We acknowledge the computational resources provided by the Aalto Science-IT project. We acknowledge EuroHPC Joint Undertaking for awarding us access to MareNostrum5 hosted by BSC, Spain. 10 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL"
        },
        {
            "title": "REFERENCES",
            "content": "Amira Abbas, Andris Ambainis, Brandon Augustino, Andreas Bartschi, Harry Buhrman, Carleton Coffrin, Giorgio Cortiana, Vedran Dunjko, Daniel J. Egger, Bruce G. Elmegreen, Nicola Franco, Filippo Fratini, Bryce Fuller, Julien Gacon, Constantin Gonciulea, Sander Gribling, Swati Gupta, Stuart Hadfield, Raoul Heese, Gerhard Kircher, Thomas Kleinert, Thorsten Koch, Georgios Korpas, Steve Lenk, Jakub Marecek, Vanio Markov, Guglielmo Mazzola, Stefano Mensa, Naeimeh Mohseni, Giacomo Nannicini, Corey OMeara, Elena Pena Tapia, Sebastian Pokutta, Manuel Proissl, Patrick Rebentrost, Emre Sahin, Benjamin C. B. Symons, Sabine Tornow, Vıctor Valls, Stefan Woerner, Mira L. Wolf-Bauwens, Jon Yard, Sheir Yarkoni, Dirk Zechiel, Sergiy Zhuk, and Christa Zoufal. Challenges and opportunities in quantum optimization. Nature Reviews Physics, 6(12):718735, October 2024a. ISSN 2522-5820. doi: 10.1038/s42254-024-00770-9. URL http://dx.doi.org/10.1038/s42254-024-00770-9. Amira Abbas, Andris Ambainis, Brandon Augustino, Andreas Bartschi, Harry Buhrman, CarChallenges and opportunities in quantum opleton Coffrin, Giorgio Cortiana, et al. Nature Reviews Physics, 6(12):718735, December 2024b. timization. ISSN 25225820. doi: 10.1038/s42254-024-00770-9. URL https://www.nature.com/articles/ s42254-024-00770-9. Publisher: Nature Publishing Group. Google Quantum AI and Collaborators. Quantum error correction below the surface code doi: 10.1038/ ISSN 1476-4687. threshold. Nature, 638(8052):920926, February 2025. s41586-024-08449-y. Amazon Web Services. Amazon Braket. URL https://aws.amazon.com/braket/. Prashanti Priya Angara, Emily Martins, Ulrike Stege, and Hausi Muller. SCOOP: QuantumComputing Framework for Constrained Combinatorial Optimization. In 2025 IEEE International Conference on Quantum Computing and Engineering, 2025. Boran Apak, Medina Bandic, Aritra Sarkar, and Sebastian Feld. KetGPT Dataset Augmentation of Quantum Circuits Using Transformers. In Leonardo Franco, Clelia de Mulatier, Maciej Paszynski, Valeria V. Krzhizhanovskaya, Jack J. Dongarra, and Peter M. A. Sloot (eds.), Computational Science ICCS 2024, pp. 235251, Cham, 2024. Springer Nature Switzerland. ISBN 978-3-03163778-0. Soren Arlt, Haonan Duan, Felix Li, Sang Michael Xie, Yuhuai Wu, and Mario Krenn. MetaDesigning Quantum Experiments with Language Models. arXiv preprint arXiv:2406.02470, 2024. Dolev Bluvstein, Simon J. Evered, Alexandra A. Geim, Sophie H. Li, Hengyun Zhou, et al. Logical quantum processor based on reconfigurable atom arrays. Nature, 626(7997):5865, February 2024. ISSN 1476-4687. doi: 10.1038/s41586-023-06927-3. Endre Boros and Peter L. Hammer. Discrete Applied Mathematics, 123(1):155225, 2002. https://doi.org/10. 1016/S0166-218X(01)00341-9. URL https://www.sciencedirect.com/science/ article/pii/S0166218X01003419. Pseudo-Boolean optimization. doi: ISSN 0166-218X. Sergey Bravyi, Andrew W. Cross, Jay M. Gambetta, Dmitri Maslov, Patrick Rall, and Theodore J. Yoder. High-threshold and low-overhead fault-tolerant quantum memory. Nature, 627(8005): 778782, March 2024. ISSN 1476-4687. doi: 10.1038/s41586-024-07107-7. Kamil Bradler, Shmuel Friedland, Josh Izaac, Nathan Killoran, and Daiqin Su. Graph isomorphism and Gaussian boson sampling. Special Matrices, 9(1):166196, 2021. doi: 10.1515/ spma-2020-0132. URL https://doi.org/10.1515/spma-2020-0132. Charlie Campbell, Hao Mark Chen, Wayne Luk, and Hongxiang Fan. Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction. arXiv preprint arXiv:2504.14557, 2025. Aaron Clauset, M. E. J. Newman, and Cristopher Moore. Finding community structure in very large networks. Physical Review E, 70(6):066111, December 2004. doi: 10.1103/PhysRevE.70. 066111. 11 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL Qiskit Community. WarmStartQAOAOptimizer Qiskit Optimization 0.7.0. https: //qiskit-community.github.io/qiskit-optimization/stubs/qiskit_ optimization.algorithms.WarmStartQAOAOptimizer.html, 2025. Accessed: 2025-09-16. Jeremy Cook, Stephan Eidenbenz, and Andreas Bartschi. The Quantum Alternating Operator Ansatz on Maximum k-Vertex Cover. In 2020 IEEE International Conference on Quantum Computing and Engineering, 10 2019. doi: 10.1109/QCE49297.2020.00021. William Cook and Andre Rohe. Computing Minimum-Weight Perfect Matchings. INFORMS Journal on Computing, 11(2):138148, May 1999. ISSN 1091-9856, 1526-5528. doi: 10.1287/ijoc. 11.2.138. Andrew W. Cross, Ali Javadi-Abhari, Thomas Alexander, Niel de Beaudrap, Lev S. Bishop, et al. OpenQASM 3: broader and deeper quantum assembly language. ACM Transactions on Quantum Computing, 3(3):150, September 2022. ISSN 2643-6809, 2643-6817. doi: 10.1145/3505636. arXiv:2104.14722 [quant-ph]. DeepSeek-AI, Daya Guo, and et al. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. arXiv preprint arXiv:2501.12948, 2025. doi: 10.48550/arXiv.2501. 12948. Cirq Developers. Cirq. Zenodo, August 2025. doi: 10.5281/ZENODO.4062499. URL https: //zenodo.org/doi/10.5281/zenodo.4062499. Nicolas Dupuis, Adarsh Tiwari, Youssef Mroueh, David Kremer, Ismael Faro, and Juan Cruz-Benito. (arXiv:2508.20907), August 2025a. doi: 10.48550/arXiv.2508.20907. arXiv:2508.20907 [quantph]. Quantum Verifiable Rewards for Post-Training Qiskit Code Assistant. Nicolas Dupuis, Adarsh Tiwari, Youssef Mroueh, David Kremer, Ismael Faro, and Juan CruzBenito. Quantum Verifiable Rewards for Post-Training Qiskit Code Assistant. arXiv preprint arXiv:2508.20907, 2025b. Jack Edmonds. Paths, Trees, and Flowers. Canadian Journal of Mathematics, 17:449467, January 1965a. ISSN 0008-414X, 1496-4279. doi: 10.4153/CJM-1965-045-4. Jack Edmonds. Maximum matching and polyhedron with 0,1-vertices. Journal of Research of the National Bureau of Standards Section Mathematics and Mathematical Physics, 69B(1 and 2): 125, January 1965b. ISSN 0022-4340. doi: 10.6028/jres.069B.013. Daniel J. Egger, Jakub Mareˇcek, and Stefan Woerner. Warm-starting quantum optimization. QuanISSN 2521-327X. doi: 10.22331/q-2021-06-17-479. URL http: tum, 5:479, June 2021. //dx.doi.org/10.22331/q-2021-06-17-479. Edward Farhi, Jeffrey Goldstone, Sam Gutmann, and Michael Sipser. Quantum Computation by Adiabatic Evolution, January 2000. arXiv:quant-ph/0001106. Edward Farhi, Jeffrey Goldstone, and Sam Gutmann. Quantum Approximate Optimization Algorithm. arXiv preprint arXiv:1411.4028, 2014. doi: 10.48550/arXiv.1411.4028. David Fitzek, Yi Hong Teoh, Hin Pok Fung, Gebremedhin A. Dagnew, Ejaaz Merali, M. Schuyler Moss, Benjamin MacLellan, and Roger G. Melko. RydbergGPT. arXiv preprint arXiv:2405.21052, may 2024. doi: 10.48550/arXiv.2405.21052. Santo Fortunato and Darko Hric. Community detection in networks: user guide. Physics ISSN 03701573. doi: 10.1016/j.physrep.2016.09.002. Reports, 659:144, November 2016. arXiv:1608.00163 [physics]. Zhenxiao Fu, Fan Chen, and Lei Jiang. QAgent: An LLM-based Multi-Agent System for Autonomous OpenQASM programming. arXiv preprint arXiv:2508.20134, 2025. 12 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL Frank Gaitan and Lane Clark. Graph isomorphism and adiabatic quantum computing. Phys. Rev. A, 89:022342, Feb 2014. doi: 10.1103/PhysRevA.89.022342. URL https://link.aps.org/ doi/10.1103/PhysRevA.89.022342. Harper R. Grimsley, Sophia E. Economou, Edwin Barnes, and Nicholas J. Mayhall. An adaptive variational algorithm for exact molecular simulations on quantum computer. Nature Communications, 10(1):3007, July 2019. ISSN 2041-1723. doi: 10.1038/s41467-019-10988-2. Yaswitha Gujju, Romain Harang, and Tetsuo Shibuya. LLM-Guided Ansatze Design for Quantum Circuit Born Machines in Financial Generative Modeling, 2025. Jonas Haferkamp, Philippe Faist, Naga B. T. Kothakonda, Jens Eisert, and Nicole Yunger Halpern. Linear growth of quantum circuit complexity. Nature Physics, 18(5):528532, March 2022. ISSN 1745-2481. doi: 10.1038/s41567-022-01539-6. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. GPT-4o System Card. arXiv preprint arXiv:2410.21276, 2024. IBM Quantum. Qiskit Code Assistant, 2025. URL https://quantum.cloud.ibm.com/ docs/en/guides/qiskit-code-assistant. Accessed: 2025-07-11. Ali Javadi-Abhari, Matthew Treinish, Kevin Krsulich, Christopher J. Wood, Jake Lishman, Julien Gacon, Simon Martiel, Paul D. Nation, Lev S. Bishop, Andrew W. Cross, Blake R. Johnson, and Jay M. Gambetta. Quantum Computing with Qiskit. arXiv preprint arXiv:2405.08810, 2024a. doi: 10.48550/arXiv.2405.08810. Ali Javadi-Abhari, Matthew Treinish, Kevin Krsulich, Christopher J. Wood, Jake Lishman, Julien Gacon, Simon Martiel, Paul D. Nation, Lev S. Bishop, Andrew W. Cross, Blake R. Johnson, and Jay M. Gambetta. Quantum computing with Qiskit, 2024b. Linus Jern, Valter Uotila, Cong Yu, and Bo Zhao. Agent-Q: Fine-Tuning Large Language Models for Quantum Circuit Generation and Optimization. In 2025 IEEE International Conference on Quantum Computing and Engineering (QCE). IEEE, 2025. Dongfu Jiang, Yi Lu, Zhuofeng Li, Zhiheng Lyu, Ping Nie, Haozhe Wang, Alex Su, Hui Chen, Kai Zou, Chao Du, et al. VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use. arXiv preprint arXiv:2509.01055, 2025. Stephen P. Jordan. Quantum Algorithm Zoo. https://quantumalgorithmzoo.org, 2025. Richard M. Karp. Reducibility among Combinatorial Problems, pp. 85103. Springer US, Boston, ISBN 978-1-4684-2001-2. doi: 10.1007/978-1-4684-2001-2 9. URL https: MA, 1972. //doi.org/10.1007/978-1-4684-2001-2_9. Thomas Krauss, Joey McCollum, Chapman Pendery, Sierra Litwin, and Alan J. Michaels. Solving IEEE Transactions on Quantum the Max-Flow Problem on Quantum Annealing Computer. Engineering, 1:110, 2020. doi: 10.1109/TQE.2020.3031085. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. Efficient Memory Management for Large Language Model Serving with PagedAttention. In Proceedings of the 29th Symposium on Operating Systems Principles, SOSP 23, pp. 611626, New York, NY, USA, 2023. Association for ComISBN 9798400702297. doi: 10.1145/3600006.3613165. URL https: puting Machinery. //doi.org/10.1145/3600006.3613165. Ang Li, Samuel Stein, Sriram Krishnamoorthy, and James Ang. QASMBench: Low-Level Quantum Benchmark Suite for NISQ Evaluation and Simulation. ACM Transactions on Quantum Computing, 4(2), February 2023. doi: 10.1145/3550488. URL https://doi.org/10.1145/ 3550488. 13 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL Zhiding Liang, Jinglei Cheng, Rui Yang, Hang Ren, Zhixin Song, Di Wu, Xuehai Qian, Tongyang Li, and Yiyu Shi. Unleashing the Potential of LLMs for Quantum Computing: Study in Quantum Architecture Design. (arXiv:2307.08191), July 2023. doi: 10.48550/arXiv.2307.08191. arXiv:2307.08191 [quant-ph]. Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. DeepSeek-V3 Technical Report. arXiv preprint arXiv:2412.19437, 2024. Ilya Loshchilov and Frank Hutter. Decoupled Weight Decay Regularization. arXiv preprint arXiv:1711.05101, 2017. Andrew Lucas. Ising formulations of many NP problems. Frontiers in Physics, 2, February 2014. ISSN 2296-424X. doi: 10.3389/fphy.2014.00005. URL https://www.frontiersin. org/journals/physics/articles/10.3389/fphy.2014.00005/full. M.L. Menendez, J.A. Pardo, L. Pardo, and M.C. Pardo. The jensen-shannon divergence. Journal of the Franklin Institute, 334(2):307318, 1997. ISSN 0016-0032. doi: https://doi.org/10. 1016/S0016-0032(96)00063-4. URL https://www.sciencedirect.com/science/ article/pii/S0016003296000634. Microsoft. Azure Quantum Development Kit. URL https://github.com/microsoft/ qsharp. Kouhei Nakaji, Lasse Bjørn Kristensen, Jorge A. Campos-Gonzalez-Angulo, Mohammad Ghazi Vakili, Haozhe Huang, Mohsen Bagherimehrab, Christoph Gorgulla, FuTe Wong, Alex McCaskey, Jin-Sung Kim, Thien Nguyen, Pooja Rao, and Alan Aspuru-Guzik. The generative quantum eigensolver (GQE) and its application for ground state search. arXiv preprint arXiv:2401.09253, jan 2024. doi: 10.48550/arXiv.2401.09253. Christian F. A. Negre, Hayato Ushijima-Mwesigwa, and Susan M. Mniszewski. Detecting multiple communities using quantum annealing on the D-Wave system. PLOS ONE, 15(2):114, 02 2020. doi: 10.1371/journal.pone.0227538. URL https://doi.org/10.1371/journal. pone.0227538. Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, Cambridge ; New York, 10th anniversary ed edition, 2010. ISBN 978-1107-00217-3. OpenAI. Introducing GPT-5, August 2025. introducing-gpt-5/. Accessed: 2025-09-21. URL https://openai.com/index/ Alberto Peruzzo, Jarrod McClean, Peter Shadbolt, Man-Hong Yung, Xiao-Qi Zhou, Peter J. Love, Alan Aspuru-Guzik, and Jeremy L. OBrien. variational eigenvalue solver on photonic quantum processor. Nature Communications, 5:4213, July 2014. doi: 10.1038/ncomms5213. ISSN 2041-1723. Cheng Qian, Emre Can Acikgoz, Qi He, Hongru Wang, Xiusi Chen, Dilek Hakkani-Tur, Gokhan Tur, and Heng Ji. ToolRL: Reward is All Tool Learning Needs, 2025. Atanu Rajak, Sei Suzuki, Amit Dutta, and Bikas K. Chakrabarti. Quantum annealing: an overview. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 381(2241):20210417, December 2022. doi: 10.1098/rsta.2021.0417. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Yang Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024. Robert S. Smith, Michael J. Curtis, and William J. Zeng. Practical Quantum Instruction Set Architecture, 2017. QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL Ilya Tyagin, Marwa H. Farag, Kyle Sherbert, Karunya Shirali, Yuri Alexeev, and Ilya Safro. QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate Optimization Algorithm Circuits. (arXiv:2504.16350), April 2025. doi: 10.48550/arXiv.2504.16350. arXiv:2504.16350 [quant-ph]. Kento Ueda and Atsushi Matsuo. Optimizing Ansatz Design in Quantum Generative Adversarial (arXiv:2503.12884), March 2025. doi: 10.48550/ Networks Using Large Language Models. arXiv.2503.12884. arXiv:2503.12884 [quant-ph]. Sanjay Vishwakarma, Francis Harkins, Siddharth Golecha, Vishal Sharathchandra Bajpe, Nicolas Dupuis, Luca Buratti, David Kremer, Ismael Faro, Ruchir Puri, and Juan Cruz-Benito. Qiskit HumanEval: An Evaluation Benchmark For Quantum Code Generative Models. In 2024 IEEE International Conference on Quantum Computing and Engineering (QCE), volume 1, pp. 1169 1176. IEEE, 2024. Anjiang Wei, Jiannan Cao, Ran Li, Hongyu Chen, Yuhui Zhang, Ziheng Wang, Yuan Liu, Thiago SFX Teixeira, Diyi Yang, Ke Wang, et al. EquiBench: Benchmarking Large Language Models Understanding of Program Semantics via Equivalence Checking. arXiv preprint arXiv:2502.12466, 2025. Zebo Yang, Maede Zolanvari, and Raj Jain. Survey of Important Issues in Quantum Computing and Communications. IEEE Communications Surveys & Tutorials, 25(2):10591094, 2023. doi: 10.1109/COMST.2023.3254481. Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, et al. PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel, 2023. 15 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL"
        },
        {
            "title": "A IMPLEMENTATION DETAILS",
            "content": "Our QUASAR is built on Verl-Tool (Jiang et al., 2025), and we mainly adopted the hyperparameter settings from Verl-Tool. The base model for SFT is Qwen3-4B-Instruct-2507, and we perform SFT adopting the same setting from Jern et al. (2025). Training runs on 16 NVIDIA H100-64GB GPUs (4 nodes 4 GPUs). The training hour is 48. The specific hyparameters setting is detailed in Table 3 Tab. 3: Training settings for agentic RL with 4B SFT model. Component Configuration"
        },
        {
            "title": "Base model\nSFT setup\nSFT learning rate\nRollout Num\nTemperature\ntop p\ntop k\nToken limits\nOptimizer\nLearning rate\nEpochs\nBatch size",
            "content": "Qwen3-4B-Instruct-2507 Quantum Datasets (Jern et al., 2025) 2 105 16 0.7 0.8 -1 1024 (Prompt), 9216 (Response), 2048 (Observation), 8192 (Action) AdamW (Loshchilov & Hutter, 2017) 1 106"
        },
        {
            "title": "B QUANTUM COMPUTING AND QUANTUM OPTIMIZATION",
            "content": "Quantum computing is an emerging computing paradigm that relies on the principles of quantum mechanics (Nielsen & Chuang, 2010). Some types of quantum computing hardware include superconducting circuits, photonic systems, trapped ions, spin qubits, and neutral atoms (Yang et al., 2023). While hardware often differs at fundamental level, the most common abstraction to design quantum computing algorithms is the quantum circuit model, whose fundamental unit is quantum bit. Whereas classical computing is based on discrete bits 0 and 1, quantum computing is based on quantum bits (qubits), which can be in superposition. single qubit is defined as φ = α0 + β1, where 0 = [1 0] and 1 = [0 1] are column vectors and α, β so that α2 + β2 = 1. qubit is an element of Hilbert space. Multi-qubit systems can be constructed using the tensor product of Hilbert spaces. Quantum computing is performed by applying quantum logic gates to the system of qubits. These gates are defined by unitary matrices . Matrix is unitary if = = 1, where is the conjugate transpose of . Considering the unitaries in this work, special set of unitaries is the parametrized rotation gates, can be defined as Rz(θ) = (cid:20)eiθ/2 (cid:21) 0 eiθ/2 , Rx(θ) = (cid:20) cos θ 2 sin θ 2 (cid:21) sin θ 2 cos θ , Ry(θ) = (cid:20)cos θ sin θ 2 2 sin θ cos θ 2 2 (cid:21) . These gates are unitary for every θ [0, 2π]. Using these gates and other standard gates such as Hadamard, CNOT, and CZ gates, we can construct vast class of parametrized quantum circuits whose elements we denote as (θ), where θ = (θ1, . . . , θm) is parameter vector. These types of parametrized gates serve as the basis for quantum optimization routines, which form the core set of circuits used as training data in this work. Next, we discuss quantum optimization. Quantum optimization (Abbas et al., 2024b) is one of the most promising applications in quantum computing. While quantum optimization can be performed with specialized devices, such as quantum annealers (Rajak et al., 2022), which are particular instances of adiabatic quantum computers (Farhi et al., 2000), multiple promising algorithms enable us to optimize specific class of functions on universal quantum computers using the quantum circuit model. The key idea is to express given optimization problem in binary optimization format, which can be quadratic 16 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL unconstrained binary optimization (QUBO) problem (Lucas, 2014) or higher-order unconstrained binary optimization (HUBO) problem (Boros & Hammer, 2002). Let be positive integer and [n] := {1, . . . , n} be an indexing set. Formally, QUBO problems are then defined as the following minimization problem arg min x{0,1}n (cid:88) i[n] αixi + (cid:88) i<j αi,jxixj, and HUBO problems are defined as arg min x{0,1}n (cid:88) (cid:89) xi, αS S[n] iS (5) (6) where coefficients αi for [n]. The QUBO problem is special case of the HUBO problem where the variable interactions are limited to two. By performing variable rewriting process xi (cid:55) 1 2 (1 + zi), where zi {1, 1} is spin variable, we obtain the equivalent optimization formulations in terms of spin variables. By noting that the eigenvalues for the Pauli-Z operator σz = (cid:21) (cid:20)1 0 0 are 1 and 1, we can further map the spin variable formulation to the Hamiltonian (cid:88) αS (cid:89) σz , S[n] iS where σz is the Pauli-Z operator acting on qubit i. This rewriting process essentially translates the original binary optimization problem into an eigenvalue minimization problem for the Hamiltonian matrices that are the result of the unconstrained problems. The standard form of quantum optimization is based on the idea that we can prepare state that enables us to measure sufficiently low expectation value for Hamiltonian, which depends on the QUBO or HUBO problem. The preparation of this state is done with parametrized unitary (θ). The goal is to estimate the gradient for the following function (θ) := 0U (θ)HU (θ)0, (7) which maps parameter vectors θ to expectation values of Hamiltonian H. For fixed parameter vector θ, (θ) can be estimated with quantum computer. By minimizing (θ) with suitable classical optimization algorithm, we are likely to prepare state such that when we measure 0U (θ) in the computational basis, the bitstring with the highest probability is solution to the optimization problem. The standard methods for solving quantum optimization problems on universal quantum computers include the Quantum Approximate Optimization Algorithm (QAOA) (Farhi et al., 2014), Variational Quantum Eigensolver (VQE) (Peruzzo et al., 2014), and adaptive VQE (Grimsley et al., 2019). Considering QAOA, the method requires preparing special parameterized ansatz that consists of circuit built based on the cost Hamiltonian that describes the optimization problem. The second part of the parametrized circuit is mixer Hamiltonian, which is often simple layer of parametrized Rx rotation gates that act on every qubit in the system. Then, the expectation value for the cost Hamiltonian is measured as in Equation 7. By tuning the parameters with classical optimization methods, the goal is to minimize the expectation value. The VQE algorithm is similar except that the ansatz structure does not depend on the cost Hamiltonian, which enables the usage of either more expressive ansatzes or ansatzes that are hardware efficient. Otherwise, VQE is similarly hybrid quantum-classical algorithm. Finally, adaptive VQE employs method where the user defines parametrized gate pool, where the algorithm picks gates and positions them in the circuit. Then, it evaluates the gradient and chooses the gate that performs the best. This leads to circuit structures that are problem-specific but highly adapted. 17 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL"
        },
        {
            "title": "C TRAINING DATASET",
            "content": "C.1 OFFLINE DATA COLLECTION Effective verification requires access to accurate ground-truth metadata for each quantum optimization problem. Before training, we collect this metadata offline using the algorithms described in (Jern et al., 2025). For each optimization problem, we obtain (i) the cost Hamiltonian of each specific optimization problem, (ii) the parameterized solution (ground-truth) circuits, and (iii) the largest/smallest eigenvalues Emax and Emin for the ground-truth circuits with respect to the cost Hamiltonian. We feed this metadata into the quantum agent, which uses it to evaluate the OpenQASM code proposed by the language model. C.2 QUANTUM OPTIMIZATION PROBLEMS C.2.1 CONNECTED COMPONENT FOR NODE The problem of finding connected component for fixed node means finding subgraph Gs of graph such that vfix Gs and Gs is connected graph. graph is connected if path connects every two nodes in the graph. This formulation is based on two constraints. Let be the set of nodes in graph and let xv be the binary variable for each indicating if the node belongs to the connected component or not. The first constraint is so-called adjacency constraint term: (v) xv 2 xu , (cid:88) uN (v) (cid:88) vV where (v) is the set of adjacent nodes to node and (v) is the size of this set. This constraint encodes the fact that if xv is activated, then we have to activate every variable linked to its neighbors, making the graph connected. Additionally, we include regulation term (cid:88) vV xv, which encodes the fact that we should not activate unnecessary variables, especially we should not activate every variable in the graph if they are not in the same connected component. Before solving the problem, we set xvfix = 1. This problem is not NP-hard, but it can be easily encoded as QUBO and is common graph optimization primitive. Thus, it provides good example to be included in the training data. C.2.2 COMMUNITY DETECTION The community detection problem seeks partition of graph so that the density of the edges within the partitions in is higher than the density of edges between them. The quality of the partitioning, i.e., communities, is often measured with modularity Clauset et al. (2004). The modularitybased community detection has straightforward formulation in terms of QUBO optimization problems (Negre et al., 2020) if we consider dividing the graph into two communities. Assume weighted graph = (V, E) given as an adjacency matrix A, where Aij is either 0 if there is no edge between nodes and , or wij, which is the weight for edge ij E. Define node degree di = (cid:80) Aij and collect the degree sequence to vector = (d1, . . . , dn), where = . Following (Negre et al., 2020), the modularity measure is defined as = dd 2m , where = (cid:80) ij Aij. Then, we fix as the number of communities and define set of binary variables xv,k for each node and 1 indicating to which partition the node belongs. The QUBO objective that aims to maximize modularity is the following constraint 1 2m (cid:88) (cid:88) (cid:18) i,jV k=1 Aij (cid:19) didj 2m xi,kxj,k. 18 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL Note that the product xi,kxj,k works as an indicator function: and are in the same community if and only if xi,kxj,k = 1. Moreover, we ensure that every node belongs to only single community, which can be achieved with the following one-hot encoding (cid:33)2 (cid:32) (cid:88) (cid:88) 1 xi,k , where the penalty factor should be sufficiently large. The problem is proved to be NP-hard Fortunato & Hric (2016). iV k=1 C.2.3 K-SIZED CLIQUE Lucas (2014) presented the QUBO formulation for finding k-sized clique. The problem is to return complete subgraph of size from given graph G. The decision problem is NP-complete (Karp, 1972). The QUBO formulation for this problem is as follows. The first constraint encodes that we choose vertices (cid:32) (cid:33)2 (cid:88) vV xv and the second constraint encodes that we have to have k(k 1)/2 edges between the vertices k(k 1) 2 (cid:88) ijE 2 xixj . The number of k(k 1)/2 edges characterizes complete graph. Then, A, > 0 are chosen so that > kB. C.2.4 GRAPH ISOMORPHISM Graph isomorphism between graphs G1 and G2 seeks bijective mapping : V1 V2 between the vertex sets of graphs G1 and G2 such that whenever (v1, v2) E1 is an edge in graph G1, then (f (v1), (v2)) E2 is an edge in graph E2. Lucas (2014) describes the standard QUBO formulation for finding graph isomorphism with QUBO formulation, but formulations also exist for adiabatic quantum computers (Gaitan & Clark, 2014) and boson samplers (Bradler et al., 2021). Assuming that u, V1 and i, V2 are nodes, the first constraint is expressed as (cid:88) vV1 (cid:32) 1 (cid:88) iV2 (cid:33) xv,i + (cid:32) 1 (cid:88) iV (cid:88) vV1 (cid:33)2 xv,i , which encodes the fact that there has to be bijective mapping between the vertices. The second constraint encodes the fact that the bijective mapping has to respect edges (cid:88) (cid:88) (cid:88) (cid:88) xv,ixu,j + xv,ixu,j. ij /E1 vuE2 ijE1 vu /E2 It suffices to assume that A, > 0. C.2.5 GRAPH COLORING Assuming that colors and graph are given, the graph coloring problem seeks solution to the problem if the colors can be assigned to the vertices of so that no edge connects two vertices of the same color. The problem is known to be NP-complete Karp (1972). Lucas (2014) again presents the following formulation. Let xv,i be the binary variable indicating if the node should be colored with color i. The first constraint is the standard one-hot encoding, which states that every node should have one color (cid:32) (cid:88) (cid:88) (cid:33)2 1 xv,i . i=1 The second constraint penalizes those cases when an edge connects two vertices with the same color vV (cid:88) (cid:88) uvE i=1 xu,ixv,i. 19 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL C.2.6 TRAVELING SALESMAN The traveling salesman problem is one of the most studied optimization problems on graph, where starting from given node, the goal is to find path in the weighted graph that visits every node in the graph exactly once. Lucas (2014) presents the following formulation with first constraint as HA = (cid:88) v=1 (1 (cid:88) j=1 xv,j) + (cid:88) j=1 (1 and the second constraint as HB = (cid:88) wuv (uv)E xv,j)2 + (cid:88) (cid:88) (uv) /E j=1 xu,jxv,j+1 xu,jxv,j+1 (cid:88) v=1 (cid:88) j=1 The decision problem is NP-complete (Karp, 1972). The penalizing terms can be chosen as 0 < max wuv < (Lucas, 2014). C.2.7 WEIGHTED MINIMUM MAXIMAL MATCHING matching in graph is subset of its edges such that no two edges share the same vertex. Finding matching is not generally NP-hard (Edmonds, 1965a;b) without additional constraints requiring minimality over the selected edges (Lucas, 2014). One of such formulations is to find maximal matching on weighted graph with the minimum cost Cook & Rohe (1999). maximal matching is solution where, if any edge not yet in the matching is included, the resulting subset of edges would no longer form matching. Jern et al. (2025) considered this problem as special instance of the exact set cover, where the edges are identified with two-element sets. This way, the exact set cover formula in (Lucas, 2014) can be used, simplifying the formulation. The first constraint enforces that for every node, exactly one edge is activated: 1 2 xe (cid:88) eN (v) (cid:88) vV where = + 1. The second constraint encodes the fact that we want to minimize the weight of this matching (cid:88) we. C.2.8 VERTEX AND EDGE COVERS eE The vertex/edge cover problem seeks the smallest set of vertices/edges in graph such that every edge/vertex has at least one vertex/edge in this set. The QUBO formulation (Lucas, 2014) for the vertex cover problem consists of two constraints and (cid:88) uvE (1 xu)(1 xv) (cid:88) xv, vV where we choose < A. The first constraint encodes the fact that every edge is connected to at least one vertex that is part of the cover. The second constraint aims to minimize the number of vertices in the cover. The decision problem is NP-complete (Karp, 1972). QAOA was previously benchmarked on special version of this problem (Cook et al., 2019). The edge cover admits simple higher-order unconstrained binary optimization formulation as follows (Jern et al., 2025; Angara et al., 2025). The first constraint encodes that every vertex should be connected to at least one edge that is part of the cover: (cid:88) (cid:89) (1 xe). vV eN (v) 20 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL The previous constraint is higher-order polynomial, which can be alternatively written as quadratic polynomial using slack variables. The second constraint aims to minimize the size of the cover: (cid:88) xe. Again, we choose < A. C.2.9 MAXFLOW AND MINCUT eE flow network is directed graph with designated source and sink nodes, where each edge is assigned non-negative capacity. The network contains no self-loops. flow is given by function : that assigns real value (u, v) for each edge (u, v) representing the amount of flow. maximum flow problem is to find viable flow from the source to the sink through the flow network, obtaining the maximum flow rate. Krauss et al. (2020) developed the QUBO formulation for the MaxFlow problem. In the same work, the authors also developed QUBO formulation for the MinCut problem. MaxFlow can first be presented as quadratic unconstrained integer optimization problem. The first constraint encodes that for each edge, the input and output flow are equal: 2 (cid:88) (cid:88) ze (cid:88) ze , vV eN (v) eN +(v) where (v) is the set of edges leaving node v, +(v) is the set of edges coming to node v, and ze is the capacity of the edge, represented as an integer variable. Simultaneously, we want to maximize the flow, meaning we want to minimize (cid:88) ze, eN +(v) where > 0 is positive constant. Next, the encoding can employ the standard mechanism from (Lucas, 2014) to encode the integer variables as binary variables. Due to the MaxFlow MinCut theorem, we automatically obtain formulation for the MinCut problem as well. MinCut can be presented as A(xs + xsxt) + (cid:88) αi,j(xi xixj), ijE where xs is the variable for the source node, xt is the variable for the target node, and αi,j is the capacity or the weight. The part xi xixj evaluates 1 if xi = 1 and xj = 0, indicating that the edge is in the cut. We choose that > (cid:80) ijE αij. COMPARISON WITH RANDOM BASELINE. One of the most common parameter initialization methods for hybrid quantum-classical algorithms is still to use random parameters. Thus, it is crucial to understand if initial parameters in the QUASAR-generated QASMs outperform the randomized baseline. We evaluate this regarding two metrics: JS-divergence and expectation values. For every QUASAR-generated QASM, we computed the expectation value and JS-divergence with respect to the Hamiltonian and the ground truth. We parametrized the QUASAR-generated QASM and initialized 100 QASMs with uniformly randomly sampled parameters from the interval (π, π]. For these QASMs, we computed the JS-diverge and expectation values. By comparing these metrics, we can see that both the distributions and expectation values from the QUASAR-generated QASMs are closer to the optimal than random parameter initializations on average. The results are collected in Table 4."
        },
        {
            "title": "E LIMITATIONS",
            "content": "We performed an experimental comparison between WarmStartQAOAOptimizer (Community, 2025) introduced in (Egger et al., 2021) to understand if QUASAR would work as warm-start 21 QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL Tab. 4: Comparison of QUASAR and random baseline metrics. Both JS-divergence and minmax-scaled expectation values are in [0, 1], so that lower is better. Metric QUASAR JS-divergence Random JS-divergence QUASAR Expectation Value Random Expectation Value Value 0.79 0.95 0.16 0.36 method for quantum optimization. The WarmStartQAOAOptimizer utilizes presolver, which solves relaxed continuous variable version of the QUBO problem and then initializes the QAOA initial state and mixer accordingly. In our implementation, we utilized Gurobi, high-performance industry-level solver. For the 564 syntactically correct QASMs in the test dataset (580 test cases in total), the average min max value for the WarmStartQAOAOptimizer is 0.007, which necessarily indicates that the presolver was capable of solving the problems optimally on average and preparing state and mixer that encoded the correct solution. The corresponding value for QUASAR was 0.1600, which was also presented in Table 4. This result indicates that QUASAR is still limited as warm-start method compared to the state-of-the-art rule-based WarmStartQAOAOptimizer. On the other hand, WarmStartQAOAOptimizer works best with QUBO problems. Thus, QUASAR might be viable method to warm-start more complex problems, such as HUBO problems, where WarmStartQAOAOptimizers performance seemed to decrease. The method can be efficiently adapted to HUBO problems by simply optimizing the problem, which excludes the higher-order terms. By computing the values for those 60 HUBO problems in the test data set, which compiled correctly (62 HUBO test cases in total), the corresponding values are 0.0656 for WarmStartQAOAOptimizer and 0.2356 for QUASAR. While WarmStartQAOAOptimizer performance was an order of magnitude worse on these problems, it still outperformed QUASAR. To address these limitations, the training dataset could be extended with QASMs that the WarmStartQAOAOptimizer prepares for the QASMs in the training dataset."
        }
    ],
    "affiliations": [
        "Aalto University",
        "Technical University of Denmark",
        "University of Helsinki",
        "University of Liverpool",
        "University of Southampton"
    ]
}