{
    "paper_title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
    "authors": [
        "Murat Bilgehan Ertan",
        "Emirhan Böge",
        "Min Chen",
        "Kaleel Mahmood",
        "Marten van Dijk"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 9 1 ] . [ 1 7 3 9 2 1 . 1 0 6 2 : r a"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Murat Bilgehan Ertan 1 2 Emirhan Boge 3 Min Chen 2 Kaleel Mahmood 4 * Marten van Dijk 1 2 *"
        },
        {
            "title": "Abstract",
            "content": "As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that stateof-the-art MIAs degrade when models are finetuned on SAGE-generated paraphrases, indicating that their signals are not robust to semanticspreserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as standalone mechanism for copyright auditing of LLMs. 1. Introduction Large language models (LLMs) are increasingly trained and fine-tuned on massive text corpora whose precise composition is rarely disclosed (Longpre et al., 2023; Touvron et al., 2023), raising concern that training datasets may contain copyrighted material used without permission. These conThese authors contributed equally to this work.*Equally contributed insights, supervision, and responsibility for the successful completion of this work. 1Centrum Wiskunde & Informatica (CWI), Amsterdam, The Netherlands 2Vrije Universiteit Amsterdam, Amsterdam, The Netherlands 3Independent Researcher 4University of Rhode Island, Kingston, RI, United States. Correspondence to: Murat Bilgehan Ertan <bilgehan.ertan@cwi.nl>. Preprint. January 21, 2026. cerns are amplified by evidence that LLMs can memorize and reproduce training data (Carlini et al., 2021; Mireshghallah et al., 2022; Nasr et al., 2025; Ahmed et al., 2026), and by demonstrated vulnerabilities to extraction and inference attacks (Carlini et al., 2021; Chu et al., 2024; Guo et al., 2024). In practice, fine-tuning is widely used in sensitive domains such as medical (Singhal et al., 2023), legal (Guha et al., 2023), financial (Wu et al., 2023), and code-generation (Li et al., 2023) applications, where it often relies on private, regulated, or copyrighted data. As courts begin to confront these issues, central question emerges: what technical evidence, if any, can reliably demonstrate that particular copyrighted work was used to train model? recent U.S. federal ruling highlights the stakes of this question. In Bartz v. Anthropic PBC (2025), the court held that Anthropics use of books for model training did not violate copyright law2. Notably, the decision relied entirely on documentary evidence and company admissions, without considering any technical analysis of model behavior. While such evidence may suffice in cases involving voluntary disclosures, future disputes are likely to arise in settings where factual admissions are absent, adversarial incentives are strong (Henderson et al., 2023), and credible technical evidence would be required to substantiate claims of unauthorized data use. Membership inference attacks (MIAs) (Shokri et al., 2017; Carlini et al., 2021) are natural candidate for providing such technical evidence. Originally developed to detect whether record belonged to the training set of classifier, MIAs for LLMs typically rely on loss reduction, likelihood ratios, or calibration signals (Meeus et al., 2024a; Maini et al., 2024). Prior work has shown that LLMs can be vulnerable to MIAs under certain fine-tuning regimes (Chen et al., 2024; Zhang et al., 2025). Recent studies reveal substantial limitations: high reported AUCs often arise from temporal or distributional artifacts rather than genuine memorization (Duan et al., 2024; Meeus et al., 2024b; 2025; Maini et al., 2024), and MIAs against pre-training data are largely ineffective because each pre-training sample is typically seen only once (Komatsuzaki, 2019; Kandpal et al., 2022; Muennighoff et al., 2023; Das et al., 2025). Any method introduced in court must remain robust to ma2See Bartz v. Anthropic PBC, No. 24-05417 (N.D. Cal. 2025)."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Prosecutor Judge Accused / Defendant Prosecutor claim & evidence Judge sets threshold τ & decides"
        },
        {
            "title": "Accused\nmodel owner",
            "content": "submits claim & evidence provides model access sets τ / decides Suspect text allegedly from inputs Membership Inference compute score s(x); compare to τ audit Trained LLM released / audited Threshold selection: choose τ train / fine-tune Paraphrased dataset semantic-preserving variants (SAGE) Figure 1. JudgeProsecutorAccused protocol and artifact flow. Party-owned artifacts (prosecutor evidence; accused model/data) are color-coded by role, while auditing and obfuscation techniques (membership inference; paraphrasing/SAGE) are shown in neutral gray. nipulation by an accused party, interpretable to non-experts, and stable under distribution shifts. Existing MIAs fail to guarantee these properties (Zhang et al., 2025; Meeus et al., 2025; Du et al., 2025). In particular, an accused can paraphrase or otherwise obfuscate text prior to training (Krishna et al., 2023; Sadasivan et al., 2025; Zhang et al., 2025). Because judges cannot observe the original training corpus, any useful technical evidence must withstand such adversarial transformations. In this work, we examine whether MIAs can reliably serve as evidence that specific copyrighted text was used during LLM training, both conceptually and empirically. We formalize this question through communication protocol between three partiesjudge, prosecutor, and accusedthat captures the evidentiary structure of copyright disputes and highlights key requirement: any MIA-based claim must remain valid even when the accused can paraphrase or otherwise obfuscate the suspected text. Guided by this protocol, we systematically evaluate state-of-the-art MIAs on finetuned LLMs under paraphrasing-based transformations that preserve semantic meaning while substantially altering surface form, using new paraphrasing pipeline we introduce, SAGE (Structure-Aware SAE-Guided Extraction). By leveraging Sparse Autoencoders (SAEs) (Bricken et al., 2023; Huben et al., 2024), SAGE operates independently of the target models internals. SAGE1 enforces semantic preservation while suppressing surface-level token overlap by guiding paraphrasing with semantic similarity signal derived from SAEs. This signal is summarized by the Semantic Persistence Score (SPS), which measures whether paraphrased text retains underlying semantic content despite substantial changes in phrasing. Using this framework, our analysis reveals structural limitation of existing membership inference attacks: their signals are dominated by lexical and distributional artifacts rather than robust evidence that model has internalized 1https://github.com/kiraz-ai/sage-sps-mia 2 specific copyrighted work. Because this vulnerability persists under semantics-preserving obfuscation, current MIAs struggle to meet the robustness requirements implied by our communication protocol, limiting their suitability as technical evidence in adversarial copyright auditing. (i), we formalize judgeprosecutor Contributions. accused communication protocol that makes explicit the evidentiary assumptions, adversarial incentives, and admissibility requirements in copyright auditing of LLM training data. (ii), we introduce SAGE (Structure-Aware SAEGuided Extraction), semantic paraphrasing framework guided by Sparse Autoencoders and Semantic Persistence Score (SPS), which preserves meaning and document structure while enabling ablations that isolate structural and factual sources of membership signal. (iii), through systematic experiments, we show that state-of-the-art membership inference attacks degrade substantially under realistic, semantics-preserving obfuscation even when the model retains the underlying knowledge, and, grounded in our protocol and prior work, argue that under adversarial settings, in terms of robustness, MIAs are insufficient, on their own, as evidentiary tools for copyright enforcement. Paper outline. Section 2 establishes the judgeprosecutor accused communication protocol, formalizing the robustness and admissibility requirements for technical evidence in copyright disputes. Section 3 introduces our framework, SAGE, and the SPS used to quantify semantic preservation. Section 4 presents our experimental evaluation, demonstrating the sensitivity of MIAs to paraphrasing and validating the downstream utility of audited models. Section 5 discusses the implications for copyright enforcement and the limitations of our study. Section 6 reviews prior work on membership inference and auditing. Finally, Section 7 concludes with summary."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "2. Copyright Auditing Under Blackmun & Supreme Court of the United States (1993), admissibility of technical evidence hinges on reliability. In adversarial auditing settings, we focus on one necessary aspect of this requirement: robustness to semanticspreserving transformations available to an accused party. If membership inference claim can be invalidated by such transformations, it cannot constitute reliable evidence regardless of its stability or explanatory framing. We study the problem of copyright auditing for LLMs: given suspect text and black-box access to deployed model fθ, can one determine whether x, or semantically equivalent variant, was used during training? Because copyright concerns protected expression rather than exact duplication, any auditing procedure must reason about semantic content under meaning-preserving transformations. Here, black-box access refers to query-only access to the model, allowing the auditor to observe outputs such as generated text, token probabilities, or likelihoods, but not internal states. We formalize copyright auditing as communication protocol between three parties: prosecutor, an accused, and judge (see Figure 1). The prosecutor provides suspect text and black-box access to the model fθ, and claims that appeared in the training data of fθ. The prosecutors objective is to supply technical evidence, typically via membership inference attack, that the models behavior on is inconsistent with non-membership. The accused is the model owner or developer. Their objective is to minimize legal, financial, or regulatory exposure while protecting proprietary datasets and complying with privacy or contractual obligations. In pursuit of this objective, the accused may apply transformations to training data, including paraphrasing, summarization, or other semantic-preserving defenses. The judge must evaluate the prosecutors claim without access to the training data. This reflects practical and legal realities: training corpora are often protected by intellectual property law, privacy regulation, or contractual constraints, and may be unavailable even under litigation. Operational constraints. This protocol operates under three realistic constraints. First, training datasets are opaque: neither party can be assumed to disclose the full corpus, even in cooperative settings (See Appendix for discussion on dataset-level comparisons). Second, semanticpreserving transformations are allowed: the accused may legally or strategically obfuscate any training text by applying transformations that preserve meaning, such as paraphrasing, summarization, or stylistic rewriting. Third, the judge must fix decision rule to determine whether specific input was used during training, typically by thresholding membership inference attack score s(x) at some value τmia, such that s(x) > τmia implies membership. In practice, the appropriate choice of τmia depends on the model, dataset, and input distribution, as membership scores are sensitive to the intrinsic difficulty of the input text (Watson et al., 2022; Carlini et al., 2022) and to the models generalization behavior. Consequently, thresholds calibrated on one distribution may fail to control false positive rates under distribution shift (Duan et al., 2024; Meeus et al., 2024b; 2025; Mattern et al., 2023). Definition 2.1 (Semantic Equivalence). Two texts x, are semantically equivalent, denoted x, if (i) their high-level semantic representations are close under semantic similarity metric, instantiated later in Section 3 as the Semantic Persistence Score (SPS) with SPS(x, x) τsps, and (ii) replacing with in the training data does not materially degrade downstream utility of the resulting finetuned model, i.e., (f (x) ) εutil, where (x) denotes the model fθ fine-tuned on data containing x. ) (f (x) θ θ θ Formal evidentiary criteria. Let A(x; fθ) denote an auditing statistic (for example, an MIA score), where larger values indicate stronger evidence of membership. Let τmia be fixed decision threshold, and let I[] denote the indicator function that outputs 1 if its argument is true and 0 otherwise. Let denote family of semanticpreserving transformations on . Paraphrasing is concrete and practically important subclass of , but our definitions apply more broadly. Definition 2.2 (Robustness). An auditing method with score A(x; fθ) and threshold τmia is robust to family of semantic-preserving transformations if there exists εrob > 0 such that for any with (x), A(x; fθ) A(T (x); fθ) εrob. In particular, if A(x; fθ) is non-ambiguous2 in the sense that A(x; fθ) τmia εrob, then induced membership decisions agree: I[A(x; fθ) τmia] = I[A(T (x); fθ) τmia]. Accordingly, the remainder of this work focuses exclusively on evaluating whether existing MIAs satisfy this robustness requirement. We emphasize that this section does not propose legal standard; rather, it formalizes technical threat model that captures information asymmetries and adversarial incentives that may arise in litigation. 3. Structure Aware SAE-Guided Extraction We propose Structure-Aware Sparse AutoEncoder-Guided Extraction (SAGE), structure-aware, metric-guided paraphrasing pipeline that generates obfuscated training data 2If A(x; fθ) τmia and A(x; fθ) τmia εrob, then A(x; fθ) τmia + εrob, which implies A(T (x); fθ) τmia. The case A(x; fθ) τmia follows analogously."
        },
        {
            "title": "SAGE",
            "content": "SAGE-R Description have created PDF/A-2b document with pdfbox and have found that the font ... Specification: ISO 19005-2:2011, Clause: 6.2.11.4, Test number: 4 ... That is: some CIDs which are in the CIDToGidMap dont appear in the CIDSet. <section type=\"structure\"> Description </section> <section type=\"narrative\"> Using pdfbox, produced PDF/A-2b document and ... </section> <section type=\"structure\"> Specification: ISO 190052:2011, Clause: 6.2.11.4, Test number: 4 </section> <section type=\"narrative\"> Specifically, certain CIDs included in the CIDToGidMap are absent from the CIDSet. </section> Description Using pdfbox, produced PDF/A2b document and ... Specification: ISO 19005-2:2011, Clause: 6.2.11.4, Test number: 4 Specifically, certain CIDs included in the CIDToGidMap are absent from the CIDSet."
        },
        {
            "title": "REMOVED",
            "content": "Using <<FACT_1>>, produced <<FACT_2>> document and"
        },
        {
            "title": "REMOVED",
            "content": "Specifically, certain CIDs included in the <<FACT_3>> are absent from the <<FACT_4>> Figure 2. SAGE qualitative example. Structure-aware dataset generation in SAGE and SAGE-R. The original document (left) is decomposed into structural and narrative sections. Paraphrasing preserves structural sections verbatim while rewriting narrative content. SAGE retains factual anchors and document structure, whereas SAGE-R removes structural sections and replaces factual entities with placeholders (<<FACT i>>). Green and red markers indicate preserved and removed components, respectively. while preserving semantic content. Given an input document x, SAGE decomposes the text into an ordered sequence of sections {sk}K k=1 using fixed LLM prompt. Each section is classified as either structural (e.g., headers, citations, code blocks, identifiers) or narrative (prose and explanations). Structural sections are preserved verbatim, while = 3 paraphrasing candidates are generated for narrative sections and evaluated under explicit semantic and surface-form constraints. The final paraphrase is selected by maximizing trade-off between semantic preservation and lexical divergence. = arg max xC(x) (cid:104) SPS(x, x) (cid:124) (cid:125) (cid:123)(cid:122) semantic persistence WordSim(x, x) (cid:123)(cid:122) (cid:125) surface overlap (cid:124) (cid:105) (1) where C(x) is the finite set of candidates. This objective ensures retains the original meaning while minimizing surface-form overlap. The generation prompts and full algorithm are provided in Appendix D.1 and D.2, respectively. 3.1. Semantic Persistence We define semantic persistence as invariance of fixed semantic observers feature activations under paraphrasing. Let (x) RM be the sparse feature vector extracted from semantic observer given input x. We define active feature indices as Ix = {i (x)i > 0}. 3.1.1. THE SEMANTIC ORACLE In all experiments, we instantiate the semantic observer using Sparse Autoencoder (SAE) attached to an intermediate layer of separate, fixed language model (the semantic oracle). The SAE induces function : RM that maps text sequence to sparse vector of monosemantic feature activations (Bricken et al., 2023; Templeton et al., 2024). To prevent formatting artifacts from influencing the oracle, we compute SAE features only on narrative text spans, excluding structural sections such as headers, citations, and formatting markers. Definition 3.1 (Semantic Persistence Score (SPS)). Given SAE feature representations, we define the Semantic Persistence Score (SPS) as measure of semantic alignment between an original text and its paraphrase x. Let {sk}K k=1 and {sk}K k=1 denote the corresponding narrative spans extracted from and x. The SPS is defined as the average cosine similarity between SAE feature vectors computed on each span: SPS(x, x) ="
        },
        {
            "title": "1\nK",
            "content": "K (cid:88) k=1 (sk) (sk) (sk) (sk) . SPS evaluates similarity in sparse feature space where individual activations correspond to specific semantic factors (Bricken et al., 2023), allowing it to distinguish true semantic preservation from superficial similarity."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "3.2. Word Similarity In addition to semantic preservation, SAGE enforces surface-form divergence at the word level. Lower values of WordSim(x, x) indicate less surface-form reuse (overlap) between the original and paraphrased text. Definition 3.2 (Word Similarity (WordSim)). Let = {Jaccword, Ovw-tri, Ovc5}, where Jaccword(x, x) denotes the Jaccard similarity between sets of lowercase alphanumeric word tokens, Ovw-tri(x, x) denotes the overlap ratio of word trigrams in that also appear in (normalized by the number of trigrams in x), and Ovc5(x, x) denotes the overlap ratio of character 5-grams in that also appear in (normalized by the number of 5-grams in x). The combined surface similarity score is defined as: WordSim(x, x) = 1 (cid:88) mM m(x, x). 4. Results We evaluate whether MIAs satisfy the robustness requirement introduced in Def. 2.2. Our experiments center on the following question: Do MIAs remain robust when the training data is paraphrased without changing its meaning? Across all evaluated settings, we observe consistent pattern: MIAs exhibit detectable signals on unmodified text, but their performance degrades sharply under paraphrasing, even though the models underlying semantic representations remain stable. 4.1. Membership Inference Attack Evaluation Our experiments follow the MIMIR benchmark introduced by Duan et al. (2024), using the same 13-gram (13 0.8) split as in prior work (Zhang et al., 2025). In contrast to the full benchmark, we evaluate on five representative datasets spanning academic, web, and curated corpora: arXiv, HackerNews (HN), PubMed, Pile-CC, and Wikipedia (Wiki). Unless otherwise stated, all experiments use LLaMA-3.23B (Grattafiori et al., 2024) as the fine-tuned target model (i.e., the defendant model in Fig. 1). Additional results on Pythia-7B (Biderman et al., 2023) are reported in Appendix I. For the SAGE paraphrasing pipeline, we employ three independent paraphrasing models: DeepSeekV3.2 (DeepSeek-AI, 2024), Gemini-2.5-Flash (Google, 2025), and Grok-4.1-Fast (xAI, 2025). For each paraphraser, we generate separate paraphrased training dataset, finetune an independent target model, and compute all evaluation metrics. Reported SAGE results are obtained by averaging metrics across these independently fine-tuned models, mitigating paraphraser-specific artifacts. Semantic persistence during SAGE optimization is evaluated using fixed, pretrained SAE (Bloom et al., 2024), trained on gemma-2b and attached to layer 12 (residual stream, postactivation). This SAE serves as an external semantic oracle that is independent of the audited model and is not trained or adapted as part of our experiments. We consider two fine-tuning regimes for the target model: end-to-end full fine-tuning and parameter-efficient finetuning for three epochs on the same MIMIR training split. Low-Rank Adaptation (LoRA) (Hu et al., 2022) fine-tunes large models by injecting small number of trainable lowrank matrices into existing weights while keeping the base parameters frozen, substantially reducing memory and compute overhead. We include LoRA because it is widely adopted fine-tuning paradigm in practice and prior work has shown that parameter-efficient fine-tuning can exhibit different memorization and privacy behaviors than full finetuning (Biderman et al., 2024; Shuttleworth et al., 2024; Zhang et al., 2025). Implementation details and hyperparameters are in Appendix D, with per-model results in Appendix H. We evaluate nine MIAs proposed for large language models (Carlini et al., 2021; Zhang et al., 2025): Loss (Yeom et al., 2018), Zlib (Carlini et al., 2021), Lowercase (Carlini et al., 2021), Min-K% Prob (Shi et al., 2024), MinK%++ (Zhang et al., 2024), ReCall (Xie et al., 2024), CON-ReCall (Wang et al., 2025), Bag-of-Words (Meeus et al., 2025; Das et al., 2025)3, and the reference-based Ratio (Carlini et al., 2021) attack. For reference-based attacks, we follow SOFT (Zhang et al., 2025) and use OpenLLaMA-7B (Geng & Liu, 2023) as the shadow model. In all settings, we evaluate attacks using queries sampled from the original distribution. Training regimes. For each fine-tuning track, we compare the following regimes: We consider the following training regimes: Pretrained (PT), the base model without additional fine-tuning; Fine-tuned (FT), standard fine-tuning on the original MIMIR training split (reported separately for full and LoRA fine-tuning); SOFT, reproduced from the selective obfuscation pipeline of (Zhang et al., 2025), which modifies the training corpus during fine-tuning by replacing influential examples with paraphrased variants generated by an auxiliary language model, using targeted paraphrasing conditioned on access to model internals. SAGE (structureaware), fine-tuning on SAGE-generated paraphrases obtained via structure-aware extraction and recombination, where narrative sections are paraphrased independently and reinserted into the original document skeleton while preserving section boundaries, metadata, and formatting; and SAGE-R (structureand factual-removed), reduced variant 3Bag-of-Words infers membership from lexical features of the dataset only, without accessing the target model, and thus serves as control for dataset-specific artifacts rather than memorization."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "in which extracted narrative sections are flattened into single continuous text stream and factual anchors (e.g., names, numbers, and dates) are removed, eliminating both structural and factual sources of membership signal (see Fig. 2)4. Factual anchors are identified using fixed LLM-prompting procedure that tags entity mentions, numeric values, and date expressions (see App. D.3). Qualitative examples are provided in Appendix F. We emphasize that both SAGE and SAGE-R variants rely only on semantic oracle to guide paraphrasing and do not require access to the internals of the model in question, whereas SOFT explicitly depends on such access. We also observe discrepancy between our reproduced SOFT results and those reported in the original paper. All SOFT results presented in this work are obtained using corrected implementation of the SOFT methodology that resolves inconsistencies in the official codebase and follows the intended pipeline; detailed discussion is provided in Appendix C. 4.2. Impact of Paraphrasing Defenses on MIAs Tables 1 and 2 report MIA performance, showing average5 and per-attack AUC across attacks and TPR@1% FPR, which we use as complementary measures of attack effectiveness. As sanity check, we also evaluate attacks on the pretrained (PT) model, which has not been exposed to downstream data, and observe random-guessing performance across datasets (AUC 0.5, Fig. 3). Corresponding TPR@FPR results for the pretrained model, which align with random-guessing behavior, are reported in App. H. Figure 3. Average performance of MIAs across datasets and methods, averaged over three independently fine-tuned models, one per paraphraser-generated dataset. (a) LoRA fine-tuning. (b) Full fine-tuning. Lower is better. In both regimes, the same qualitative ordering holds: FT > SOFT > SAGE > SAGE-R > PT. Under LoRA fine-tuning, paraphrasing substantially suppresses MIAs. Under LoRA fine-tuning, MIAs achieve 4Tokens corresponding to removed facts (e.g., FACT1) are masked during training. 5Bag-of-Words is omitted from the average calculation, as it does not query the target model and serves only as control baseline. 6 strong performance on the original data (FT), confirming the presence of exploitable membership signals in the absence of defenses (Tables 1 and 2). Introducing paraphrasing consistently degrades attack effectiveness across attacks and datasets: SAGE leads to substantial reduction in both AUC and low-FPR metrics, while SAGE-R further suppresses performance to levels close to the pretrained baseline. This degradation is systematic and observed across all evaluated datasets, indicating that paraphrasing weakens membership signals under parameter-efficient fine-tuning. Full fine-tuning amplifies leakage but preserves the ordering of defenses. Figure 3 presents the corresponding results under full fine-tuning. While the qualitative ordering of regimes remains consistent, meaning that SAGE variants outperform SOFT and substantially reduce leakage relative to FT, the absolute level of attack success is uniformly higher than in the LoRA setting. Stronger memorization effects induced by full fine-tuning are therefore more difficult to eliminate entirely via paraphrasing alone. Nevertheless, even in this more challenging regime, SAGE and SAGE-R continue to provide clear reduction in attack performance compared to standard fine-tuning; detailed per-attack results for full fine-tuning are reported in Appendix H. Stability across regimes. Across both LoRA and full finetuning, the relative ordering remains stable (FT > SOFT > SAGE > SAGE-R), suggesting that existing MIAs rely primarily on surface-level regularities rather than invariant semantic representations (see Fig. 3). Accordingly, SOFT (Zhang et al., 2025) reduces leakage relative to FT but remains consistently weaker than SAGE and SAGE-R, despite requiring access to model internals, while SAGE achieves stronger suppression without such access. Although SAGE-R removes approximately 9.8% of tokens on average, these correspond specifically to extracted factual anchors; an ablation removing facts without paraphrasing yields only limited MIA suppression (Appendix G). 4.3. Utility Evaluation We evaluate utility using two complementary criteria. For paraphrase quality we use SPS which measures semantic consistency beyond surface overlap. For downstream utility, we follow prior work and adopt an LLM-as-a-Judge framework (Zhang et al., 2025). Although perplexity is commonly used metric, it is sensitive to surface-level variation and is difficult to interpret under paraphrasing, particularly in datasets such as MIMIR. Human evaluation, while informative, is expensive and does not scale. We therefore rely on SPS and LLM-based judgments as practical alternatives. 4.3.1. PARAPHRASE QUALITY Using the SPS and WordSim metrics introduced in Definitions 3.1 and 3.2, we evaluate the quality of our para-"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 1. AUC: Average performance of MIAs across datasets and methods, averaged over three independently fine-tuned models, one per paraphraser-generated dataset (LoRA). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.685 0.682 0.667 0.579 0.634 0.698 0.650 0.842 0. 0.602 0.602 0.593 0.546 0.565 0.607 0.579 0.693 0."
        },
        {
            "title": "Average",
            "content": "0.68 0.60 0.559 0.562 0.516 0.524 0.533 0.559 0.541 0.632 0.498 0.55 0.658 0.663 0.699 0.561 0.657 0.666 0.636 0.903 0.510 0.582 0.586 0.607 0.533 0.578 0.588 0.572 0.752 0. 0.68 0.60 0.528 0.529 0.521 0.510 0.526 0.532 0.531 0.572 0.510 0.53 0.645 0.667 0.687 0.568 0.624 0.661 0.593 0.916 0.498 0.547 0.562 0.572 0.531 0.537 0.559 0.530 0.681 0. 0.67 0.56 0.515 0.527 0.499 0.516 0.510 0.524 0.513 0.569 0.498 0.52 0.710 0.724 0.657 0.548 0.628 0.719 0.603 0.894 0.524 0.588 0.589 0.573 0.512 0.549 0.590 0.546 0.727 0. 0.69 0.58 0.535 0.532 0.519 0.492 0.523 0.531 0.526 0.583 0.524 0.53 0.645 0.645 0.669 0.566 0.626 0.666 0.628 0.857 0.528 0.549 0.550 0.582 0.523 0.532 0.561 0.549 0.674 0. 0.66 0.57 0.530 0.530 0.542 0.516 0.519 0.537 0.534 0.624 0.528 0.54 Table 2. TPR@1%FPR: Average performance of MIAs across datasets and methods, averaged over three independently fine-tuned models, one per paraphraser-generated dataset (LoRA). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.028 0.031 0.058 0.048 0.018 0.030 0.030 0.200 0.007 0.013 0.018 0.033 0.024 0.009 0.016 0.018 0.077 0."
        },
        {
            "title": "Average",
            "content": "0.06 0.03 0.006 0.010 0.008 0.015 0.004 0.007 0.007 0.013 0.007 0.01 0.041 0.051 0.048 0.047 0.057 0.047 0.044 0.164 0.004 0.026 0.034 0.031 0.027 0.029 0.028 0.026 0.073 0. 0.06 0.03 0.014 0.016 0.015 0.017 0.015 0.016 0.015 0.020 0.004 0.02 0.022 0.039 0.036 0.030 0.024 0.021 0.028 0.185 0.010 0.015 0.020 0.022 0.014 0.015 0.011 0.013 0.034 0. 0.05 0.02 0.012 0.019 0.013 0.011 0.012 0.009 0.011 0.015 0.010 0.01 0.036 0.036 0.028 0.042 0.032 0.037 0.022 0.122 0.011 0.016 0.015 0.016 0.012 0.020 0.014 0.012 0.032 0. 0.04 0.02 0.008 0.005 0.008 0.015 0.012 0.007 0.008 0.016 0.011 0.01 0.036 0.037 0.045 0.078 0.039 0.041 0.027 0.190 0.011 0.014 0.015 0.022 0.020 0.018 0.012 0.012 0.072 0. 0.06 0.02 0.011 0.009 0.008 0.017 0.011 0.011 0.009 0.058 0.011 0.02 phrasing. Figure 4 shows that, SAGE retains the conceptual meaning within the original datasets, as reported with SPS results. Furthermore, low WordSim scores confirm that the paraphrasing process substantially reduces surface overlap with the original text while preserving semantic content. Full results and detailed analysis of SPS are in Appendix E. This combination supports the suppression of MIA signals without degrading downstream fine-tuning utility. We ablate over SAE layers and models and find that SPS is stable across layers and consistently separates SAGE and SAGE-R, though absolute values vary by model (Appendix E.2). 4.3.2. LLM-AS-A-JUDGE Table 3. Utility evaluation using an LLM-as-a-Judge under LoRA fine-tuning. Higher scores indicate better knowledge retention. Results are averaged over three independently fine-tuned models, each fine-tuned on dataset generated by different paraphraser. not imply that fine-tuned models forget the underlying training content. We therefore evaluate downstream utility using an LLM-as-a-Judge framework (Zheng et al., 2023), following prior work (Zhang et al., 2025). To mitigate the inherent noise and variance of LLM evaluators (Chiang & Lee, 2023; Wang et al., 2024), we employ jury approach: we query three independent LLM judges three times per example (325 questions) and report the averaged scores (Verga et al., 2024). As shown in Table 3, models fine-tuned on SAGE-paraphrased data achieve utility comparable to standard fine-tuning and consistently outperform the pre-trained baseline, with no utility degradation under SAGE or SAGER. These results show that both SAGE and SAGE-R satisfy the semantic equivalence criterion defined in Definition 3.1: high SPS establishes semantic persistence, while the LLMas-a-Judge evaluation confirms utility preservation. Full evaluation details and discussion are in Appendix D.4."
        },
        {
            "title": "Dataset",
            "content": "ArXiv Wikipedia Pile-CC PubMed HackerNews"
        },
        {
            "title": "Average",
            "content": "PT 45.7 46.6 45.1 53.9 42.1 47.8 FT SAGE SAGE-R 47.0 48.3 51.6 55.9 45. 49.5 53.1 54.6 49.4 60.9 45.9 52.8 52.8 49.0 45.2 60.0 39.3 49."
        },
        {
            "title": "The collapse of MIA performance under paraphrasing does",
            "content": "7 5. Discussion Framed by our communication protocol (Section 2), our results highlight tension between the behavior of existing MIAs and the robustness requirements implied by copyright auditing (see Def. 2.2). While prior work attributes strong MIA performance to overfitting or distributional artifacts (Yeom et al., 2018; Maini et al., 2024; Duan et al., 2024; Meeus et al., 2024b; 2025), our results address dis-"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "whether such ensemble-based procedures yield stable evidence under adversarial, semantics-preserving obfuscation. 6. Related Works prominent line of work proposes model-centric defenses based on differential privacy. Techniques such as DPSGD (Abadi et al., 2016) and parameter-efficient variants including DP-LoRA (Liu et al., 2025; Yu et al., 2022; Li et al., 2022) bound the influence of individual training samples by injecting noise during optimization. While these methods provide formal privacy guarantees, they typically incur nontrivial utility degradation, require careful hyperparameter tuning, and often struggle to scale to large models or low-noise regimes relevant in practice. Recent work has proposed alternative membership inference attacks for finetuned LLMs, including SPV-MIA (Fu et al., 2024), which leverages self-prompted reference models and probabilistic variation signals. Our evaluation focuses on attacks whose decision rules operate directly on the queried text and model outputs under fixed auditing protocol. We exclude adaptive methods like SPV-MIA, as their reliance on dynamic calibration mechanisms introduces distinct questions about robustness and admissibility, which we leave to future work. parallel line of research focuses on dataset copyright auditing. Existing approaches include intrusive watermarking, dataset inference, and document-level MIAs (Meeus et al., 2024b; Du et al., 2025). For instance, DE-COP (Duarte et al., 2024) proposes detecting copyrighted content by probing whether model can distinguish verbatim text from paraphrased variations. Dataset inference methods (Maini et al., 2024) address aggregate dataset-level inclusion rather than record-level membership, and are thus orthogonal to the individual-instance auditing setting considered in this work. Watermarking-based audits operate under different assumptions, typically relying on proactive watermark insertion, though recent work has shown they are vulnerable to evasion via recursive paraphrasing (Sadasivan et al., 2025). In contrast, we consider post hoc auditing without assuming such instrumentation. 7. Conclusion We evaluated membership inference attacks (MIAs) through formal judgeprosecutoraccused communication protocol and showed that they face significant challenges in providing robust evidence of copyright infringement under realistic adversarial conditions. Even when MIAs exhibit non-trivial performance under favorable settings, semanticpreserving paraphrasing destabilizes their signals while preserving meaning and downstream utility. This indicates that MIAs largely depend on surface-level artifacts rather than semantic use, whereas copyright claims fundamentally Figure 4. AUCWordSim tradeoff: Average MIA AUC ( means stronger privacy) vs. WordSim ( indicates greater divergence from original). Each point represents dataset-level average over paraphraser models; gray segments connect SAGE to SAGE-R within each dataset. Labels indicate SPS. tinct robustness limitation. We do not claim that MIAs are universally ineffective; rather, we observe that even under such favorable conditions, membership scores can change substantially under semantics-preserving transformations. This sensitivity suggests that current MIAs depend strongly on surface-level lexical regularities, rather than features that are invariant to meaning-preserving rewrites, undermining their evidentiary value in adversarial auditing settings. Limitations. We acknowledge that paraphrasing does not fully eliminate memorization: MIAs retain performance substantially above chance (AUC 0.70.8) under full finetuning. However, the presence of statistical signal does not directly translate into evidentiary reliability for copyright auditing. As noted in Definition 2.2, admissible evidence requires decision threshold τmia. Our results show that semantics-preserving transformations can shift score distributions sufficiently to make such thresholds unstable, even when aggregate performance remains high. As result, the remaining signal appears sensitive to surface-level artifacts and difficult to interpret consistently in adversarial settings. Finally, we note that our findings are specific to the text modality considered here; other domains, such as image or code generation, may exhibit different trade-offs. Future work. Promising directions include auditing mechanisms that target semantic or functional behavior rather than surface-level memorization, as well as protocol-aware and game-theoretic formulations that explicitly model strategic behavior, incentives, and evidentiary thresholds between the parties involved. An important extension is to study adaptive auditing strategies in which the prosecutor generates and aggregates membership signals across multiple semantically equivalent paraphrases of suspect text, and to characterize"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "concern the use of protected expression. This suggests that reliable copyright auditing cannot rely on membership inference alone and instead requires protocol-aware approaches aligned with legal standards of evidence."
        },
        {
            "title": "Impact Statement",
            "content": "This paper membership inference attacks as technical evidence for copyright auditing of large language models under adversarial conditions. Our results show that the effectiveness of existing MIAs degrades under semantics-preserving transformations, raising concerns about their robustness in adversarial settings. This work helps clarify the limitations of current auditing signals in legal, regulatory, and policy settings, and encourages the development of threat-model-aware alternatives. While the paraphrasing techniques studied here could be misused to obfuscate training data, they reflect realistic capabilities already available to model developers rather than introducing new risks. Overall, this work aims to promote more responsible use and interpretation of machine learning security tools in highstakes auditing contexts."
        },
        {
            "title": "Acknowledgments",
            "content": "The contribution of Marten van Dijk, Murat Bilgehan Ertan and Min Chen to this publication is part of the project CiCS of the research program Gravitation which is (partly) financed by the Dutch Research Council (NWO) under the grant 024.006.037. We acknowledge the use of the DAS-6 High-Performance Computing cluster at Vrije Universiteit Amsterdam for GPU-based experiments (Bal et al., 2016)."
        },
        {
            "title": "References",
            "content": "Abadi, M., Chu, A., Goodfellow, I. J., McMahan, H. B., Mironov, I., Talwar, K., and Zhang, L. Deep learning with differential privacy. In Weippl, E. R., Katzenbeisser, S., Kruegel, C., Myers, A. C., and Halevi, S. (eds.), Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, Vienna, Austria, October 24-28, 2016, pp. 308318. ACM, 2016. doi: 10.1145/2976749.2978318. URL https: //doi.org/10.1145/2976749.2978318. Ahmed, A., Cooper, A. F., Koyejo, S., and Liang, P. Extracting books from production language models, 2026. URL https://arxiv.org/abs/2601.02671. Bal, H. E., Epema, D. H. J., de Laat, C., van Nieuwpoort, R., Romein, J. W., Seinstra, F. J., Snoek, C., and Wijshoff, H. A. G. medium-scale distributed system for computer science research: Infrastructure for the long term. Computer, 49(5):5463, 2016. doi: 10.1109/MC.2016.127. URL https://doi.org/10.1109/MC.2016. 127. Biderman, D., Portes, J. P., Ortiz, J. J. G., Paul, M., Greengard, P., Jennings, C., King, D., Havens, S., Chiley, V., Frankle, J., Blakeney, C., and Cunningham, J. P. LoRA learns less and forgets less. Trans. Mach. Learn. Res., 2024, 2024. URL https://openreview.net/f orum?id=aloEru2qCG. Biderman, S., Schoelkopf, H., Anthony, Q. G., Bradley, H., OBrien, K., Hallahan, E., Khan, M. A., Purohit, S., Prashanth, U. S., Raff, E., Skowron, A., Sutawika, L., and van der Wal, O. Pythia: suite for analyzing large language models across training and scaling. In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J. (eds.), International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pp. 23972430. PMLR, 2023. URL https://proceedings.mlr.press/v202/b iderman23a.html. Blackmun, H. and Supreme Court of the United States. Daubert v. Merrell Dow Pharmaceuticals, Inc. 509 U.S. 579, pp. 579593, 1993. URL https://supreme. justia.com/cases/federal/us/509/579/. Bloom, J., Tigges, C., Duong, A., and Chanin, D. Saelens. https://github.com/decoderesearch/SA ELens, 2024. Bricken, T., Templeton, A., Batson, J., Chen, B., Jermyn, A., Conerly, T., Turner, N., Anil, C., Denison, C., Askell, A., Lasenby, R., Wu, Y., Kravec, S., Schiefer, N., Maxwell, T., Joseph, N., Hatfield-Dodds, Z., Tamkin,"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "A., Nguyen, K., McLean, B., Burke, J. E., Hume, T., Carter, S., Henighan, T., and Olah, C. Towards monosemanticity: Decomposing language models with dictionary learning. Transformer Circuits Thread, 2023. URL https://transformer-circuits.pub/2023 /monosemantic-features/index.html. Carlini, N., Tram`er, F., Wallace, E., Jagielski, M., HerbertVoss, A., Lee, K., Roberts, A., Brown, T. B., Song, D., Erlingsson, U., Oprea, A., and Raffel, C. Extracting training data from large language models. In Bailey, M. D. and Greenstadt, R. (eds.), 30th USENIX Security Symposium, USENIX Security 2021, August 11-13, 2021, pp. 26332650. USENIX Association, 2021. URL http s://www.usenix.org/conference/usenix security21/presentation/carlini-extra cting. Carlini, N., Chien, S., Nasr, M., Song, S., Terzis, A., and Tram`er, F. Membership inference attacks from In 43rd IEEE Symposium on Secufirst principles. rity and Privacy, SP 2022, San Francisco, CA, USA, May 22-26, 2022, pp. 18971914. IEEE, 2022. doi: 10.1109/SP46214.2022.9833649. URL https:// doi.org/10.1109/SP46214.2022.9833649. Chen, X., Tang, S., Zhu, R., Yan, S., Jin, L., Wang, Z., Su, L., Zhang, Z., Wang, X., and Tang, H. The janus interface: How fine-tuning in large language models amplifies the privacy risks. In Luo, B., Liao, X., Xu, J., Kirda, E., and Lie, D. (eds.), Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security, CCS 2024, Salt Lake City, UT, USA, October 14-18, 2024, pp. 12851299. ACM, 2024. doi: 10.1145/3658644.36 90325. URL https://doi.org/10.1145/3658 644.3690325. Chiang, D. C. and Lee, H. Can large language models be an alternative to human evaluations? In Rogers, A., Boyd-Graber, J. L., and Okazaki, N. (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pp. 15607 15631. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.ACLLONG.870. URL https://doi.org/10.18653/v1/2023.acl -long.870. Chu, J., Sha, Z., Backes, M., and Zhang, Y. Reconstruct your previous conversations! comprehensively investigating privacy leakage risks in conversations with GPT models. In Al-Onaizan, Y., Bansal, M., and Chen, Y. (eds.), Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024, pp. 6584 6600. Association for Computational Linguistics, 2024. doi: 10.18653/V1/2024.EMNLP-MAIN.377. URL https://doi.org/10.18653/v1/2024.emn lp-main.377. Das, D., Zhang, J., and Trant`er, F. Blind baselines beat membership inference attacks for foundation models. In Blanton, M., Enck, W., and Nita-Rotaru, C. (eds.), 2025 IEEE Security and Privacy, SP 2025 - Workshops, San Francisco, CA, USA, May 15, 2025, pp. 118125. IEEE, 2025. doi: 10.1109/SPW67851.2025.00016. URL https://doi.org/10.1109/SPW67851.2025. 00016. DeepSeek-AI. DeepSeek-V3 technical report. CoRR, abs/2412.19437, 2024. doi: 10.48550/ARXIV.2412. 19437. URL https://doi.org/10.48550/arX iv.2412.19437. Du, L., Zhou, X., Chen, M., Zhang, C., Su, Z., Cheng, P., Chen, J., and Zhang, Z. SoK: Dataset copyright auditing in machine learning systems. In Blanton, M., Enck, W., and Nita-Rotaru, C. (eds.), IEEE Symposium on Security and Privacy, SP 2025, San Francisco, CA, USA, May 12-15, 2025, pp. 119. IEEE, 2025. doi: 10.1109/SP61 157.2025.00025. URL https://doi.org/10.110 9/SP61157.2025.00025. Duan, M., Suri, A., Mireshghallah, N., Min, S., Shi, W., Zettlemoyer, L., Tsvetkov, Y., Choi, Y., Evans, D., and Hajishirzi, H. Do membership inference attacks work on large language models? CoRR, abs/2402.07841, 2024. doi: 10.48550/ARXIV.2402.07841. URL https: //doi.org/10.48550/arXiv.2402.07841. Duarte, A. V., Zhao, X., Oliveira, A. L., and Li, L. DECOP: detecting copyrighted content in language models training data. In Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 2127, 2024. OpenReview.net, 2024. URL https://op enreview.net/forum?id=LO4xhXmFal. Fu, W., Wang, H., Gao, C., Liu, G., Li, Y., and Jiang, T. Membership inference attacks against fine-tuned large language models via self-prompt calibration. In Globersons, A., Mackey, L., Belgrave, D., Fan, A., Paquet, U., Tomczak, J. M., and Zhang, C. (eds.), Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024, 2024. URL http://papers.nips.cc/p aper_files/paper/2024/hash/f36ad6941 88bb4c4bbbd61e2038e069e-Abstract-Con ference.html. Gemma Team. Gemma: Open models based on gemini research and technology. CoRR, abs/2403.08295, 2024."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "doi: 10.48550/ARXIV.2403.08295. URL https: //doi.org/10.48550/arXiv.2403.08295. Mach. Learn. Res., 24:400:1400:79, 2023. URL http: //jmlr.org/papers/v24/23-0569.html. Geng, X. and Liu, H. OpenLLaMA: An open reproduction of LLaMA, May 2023. URL https://github.com /openlm-research/open_llama. Google. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. CoRR, abs/2507.06261, 2025. doi: 10.48550/ARXIV.2507.06261. URL https: //doi.org/10.48550/arXiv.2507.06261. Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Vaughan, A., et al. The Llama 3 herd of models. CoRR, abs/2407.21783, 2024. doi: 10.48550/ARXIV.2407.21 783. URL https://doi.org/10.48550/arXiv .2407.21783. Guha, N., Nyarko, J., Ho, D. E., Re, C., Chilton, A., Aditya, K., Chohlas-Wood, A., Peters, A., Waldon, B., Rockmore, D. N., Zambrano, D., Talisman, D., Hoque, E., Surani, F., Fagan, F., Sarfaty, G., Dickinson, G. M., Porat, H., Hegland, J., Wu, J., Nudell, J., Niklaus, J., Nay, J. J., Choi, J. H., Tobia, K., Hagan, M., Ma, M., Livermore, M. A., Rasumov-Rahe, N., Holzenberger, N., Kolt, N., Henderson, P., Rehaag, S., Goel, S., Gao, S., Williams, S., Gandhi, S., Zur, T., Iyer, V., and Li, Z. Legalbench: collaboratively built benchmark for measuring legal reasoning in large language models. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S. (eds.), Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http: //papers.nips.cc/paper_files/paper/2 023/hash/89e44582fd28ddfea1ea4dcb0eb bf4b0-Abstract-Datasets_and_Benchmar ks.html. Guo, H., Cheng, S., Jin, X., Zhang, Z., Zhang, K., Tao, G., Shen, G., and Zhang, X. BiScope: AI-generated text detection by checking memorization of preceding tokens. In Globersons, A., Mackey, L., Belgrave, D., Fan, A., Paquet, U., Tomczak, J. M., and Zhang, C. (eds.), Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024, 2024. URL http://papers .nips.cc/paper_files/paper/2024/hash /bc808cf2d2444b0abcceca366b771389-Abs tract-Conference.html. Henderson, P., Li, X., Jurafsky, D., Hashimoto, T., Lemley, M. A., and Liang, P. Foundation models and fair use. J. Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. LoRA: Low-rank adaptation of large language models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview.net/forum?id= nZeVKeeFYf9. Huben, R., Cunningham, H., Smith, L. R., Ewart, A., and Sharkey, L. Sparse autoencoders find highly interpretable features in language models. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/forum?id= F76bwRSLeK. Kandpal, N., Wallace, E., and Raffel, C. Deduplicating training data mitigates privacy risks in language models. In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and Sabato, S. (eds.), International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pp. 1069710707. PMLR, 2022. URL https://proceedings.mlr.pres s/v162/kandpal22a.html. Komatsuzaki, A. One epoch is all you need. CoRR, abs/1906.06669, 2019. URL http://arxiv.org/ abs/1906.06669. Krishna, K., Song, Y., Karpinska, M., Wieting, J., and Iyyer, M. Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S. (eds.), Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http: //papers.nips.cc/paper_files/paper/2 023/hash/575c450013d0e99e4b0ecf82bd1 afaa4-Abstract-Conference.html. Li, R., Allal, L. B., Zi, Y., Muennighoff, N., Kocetkov, D., Mou, C., Marone, M., Akiki, C., Li, J., Chim, J., Liu, Q., Zheltonozhskii, E., Zhuo, T. Y., Wang, T., Dehaene, O., Davaadorj, M., Lamy-Poirier, J., Monteiro, J., Shliazhko, O., Gontier, N., Meade, N., Zebaze, A., Yee, M., Umapathi, L. K., Zhu, J., Lipkin, B., Oblokulov, M., Wang, Z., V, R. M., Stillerman, J. T., Patel, S. S., Abulkhanov, D., Zocca, M., Dey, M., Zhang, Z., Fahmy, N., Bhattacharyya, U., Yu, W., Singh, S., Luccioni, S., Villegas, P., Kunakov, M., Zhdanov, F., Romero, M., Lee, T., Timor, N., Ding, J., Schlesinger, C., Schoelkopf, H.,"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Ebert, J., Dao, T., Mishra, M., Gu, A., Robinson, J., Anderson, C. J., Dolan-Gavitt, B., Contractor, D., Reddy, S., Fried, D., Bahdanau, D., Jernite, Y., Ferrandis, C. M., Hughes, S., Wolf, T., Guha, A., von Werra, L., and de Vries, H. StarCoder: may the source be with you! Trans. Mach. Learn. Res., 2023, 2023. URL https: //openreview.net/forum?id=KoFOg41haE. Li, X., Tram`er, F., Liang, P., and Hashimoto, T. Large language models can be strong differentially private learners. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https: //openreview.net/forum?id=bVuP3ltATMz. Liu, X., Zhu, R., Zha, D., Gao, J., Zhong, S., White, M., and Qiu, M. Differentially private low-rank adaptation of large language model using federated learning. ACM Trans. Manag. Inf. Syst., 16(2):124, 2025. doi: 10.1145/ 3682068. URL https://doi.org/10.1145/36 82068. Longpre, S., Mahari, R., Chen, A., Obeng-Marnu, N., Sileo, D., Brannon, W., Muennighoff, N., Khazam, N., Kabbara, J., Perisetla, K., Wu, X., Shippole, E., Bollacker, K. D., Wu, T., Villa, L., Pentland, S., Roy, D., and Hooker, S. The data provenance initiative: large scale audit of dataset licensing & attribution in AI. CoRR, abs/2310.16787, 2023. doi: 10.48550/ARXIV.2310.16 787. URL https://doi.org/10.48550/arXiv .2310.16787. Maini, P., Jia, H., Papernot, N., and Dziedzic, A. LLM dataset inference: Did you train on my dataset? In Globersons, A., Mackey, L., Belgrave, D., Fan, A., Paquet, U., Tomczak, J. M., and Zhang, C. (eds.), Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024, 2024. URL http://papers.nip s.cc/paper_files/paper/2024/hash/e01 519b47118e2f51aa643151350c905-Abstrac t-Conference.html. Mattern, J., Mireshghallah, F., Jin, Z., Scholkopf, B., Sachan, M., and Berg-Kirkpatrick, T. Membership inference attacks against language models via neighbourhood comparison. In Rogers, A., Boyd-Graber, J. L., and Okazaki, N. (eds.), Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023, pp. 1133011343. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.FINDI NGS-ACL.719. URL https://doi.org/10.186 53/v1/2023.findings-acl.719. Meeus, M., Jain, S., Rei, M., and de Montjoye, Y. Did the neurons read your book? document-level membership inference for large language models. In Balzarotti, D. and Xu, W. (eds.), 33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024. USENIX Association, 2024a. URL https: //www.usenix.org/conference/usenixse curity24/presentation/meeus. Meeus, M., Shilov, I., Faysse, M., and de Montjoye, Y. Copyright traps for large language models. In Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024b. URL https://openreview.net/forum ?id=LDq1JPdc55. Meeus, M., Shilov, I., Jain, S., Faysse, M., Rei, M., and de Montjoye, Y. SoK: Membership inference attacks on LLMs are rushing nowhere (and how to fix it). In IEEE Conference on Secure and Trustworthy Machine Learning, SaTML 2025, Copenhagen, Denmark, April 9-11, 2025, pp. 385401. IEEE, 2025. doi: 10.1109/SA TML64287.2025.00028. URL https://doi.org/ 10.1109/SaTML64287.2025.00028. Mireshghallah, F., Goyal, K., Uniyal, A., Berg-Kirkpatrick, T., and Shokri, R. Quantifying privacy risks of masked language models using membership inference attacks. In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pp. 8332 8347. Association for Computational Linguistics, 2022. doi: 10.18653/V1/2022.EMNLP-MAIN.570. URL https://doi.org/10.18653/v1/2022.emn lp-main.570. Muennighoff, N., Rush, A. M., Barak, B., Scao, T. L., Tazi, N., Piktus, A., Pyysalo, S., Wolf, T., and Raffel, C. A. Scaling data-constrained language models. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S. (eds.), Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/pap er/2023/hash/9d89448b63ce1e2e8dc7af7 2c984c196-Abstract-Conference.html. Nasr, M., Rando, J., Carlini, N., Hayase, J., Jagielski, M., Cooper, A. F., Ippolito, D., Choquette-Choo, C. A., Tram`er, F., and Lee, K. Scalable extraction of training data from aligned, production language models. In The Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. OpenReview.net, 2025. URL https://openreview .net/forum?id=vjel3nWP2a."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "OpenAI. GPT-4 technical report, 2024. URL https: //arxiv.org/abs/2303.08774. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. Language models are unsupervised multitask learners. OpenAI, 2019. URL https://cdn.open ai.com/better-language-models/langua ge_models_are_unsupervised_multitask _learners.pdf. Sadasivan, V. S., Kumar, A., Balasubramanian, S., Wang, W., and Feizi, S. Can AI-generated text be reliably detected? stress testing AI text detectors under various attacks. Trans. Mach. Learn. Res., 2025, 2025. URL https://openreview.net/forum?id=OOgs AZdFOt. Shi, W., Ajith, A., Xia, M., Huang, Y., Liu, D., Blevins, T., Chen, D., and Zettlemoyer, L. Detecting pretraining data from large language models. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/forum?id= zWqr3MQuNs. Shokri, R., Stronati, M., Song, C., and Shmatikov, V. Membership inference attacks against machine learning models. In 2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose, CA, USA, May 22-26, 2017, pp. 318. IEEE Computer Society, 2017. doi: 10.1109/SP.2017.41. URL https://doi.org/10.1109/SP.2017. 41. Shuttleworth, R., Andreas, J., Torralba, A., and Sharma, P. LoRA vs full fine-tuning: An illusion of equivalence. CoRR, abs/2410.21228, 2024. doi: 10.48550/ARXIV.2 410.21228. URL https://doi.org/10.48550/a rXiv.2410.21228. Singhal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W., Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S., Payne, P., Seneviratne, M., Gamble, P., Kelly, C., Babiker, A., Scharli, N., Chowdhery, A., Mansfield, P., Demner-Fushman, D., Aguera Arcas, B., Webster, D., Corrado, G. S., Matias, Y., Chou, K., Gottweis, J., Tomasev, N., Liu, Y., Rajkomar, A., Barral, J., Semturs, C., Karthikesalingam, A., and Natarajan, V. Large language models encode clinical knowledge. Nature, 620(7972):172180, Aug 2023. ISSN 1476-4687. doi: 10.1038/s41586-023-06291-2. URL https: //doi.org/10.1038/s41586-023-06291-2. Templeton, A., Conerly, T., Marcus, J., Lindsey, J., Bricken, T., Chen, B., Pearce, A., Citro, C., Ameisen, E., Jones, A., Cunningham, H., Turner, N. L., McDougall, C., MacDiarmid, M., Freeman, C. D., Sumers, T. R., Rees, E., Batson, J., Jermyn, A., Carter, S., Olah, C., and Henighan, T. Scaling monosemanticity: Extracting interpretable features from claude 3 sonnet. Transformer Circuits Thread, 2024. URL https://transformer-circuits. pub/2024/scaling-monosemanticity/ind ex.html. Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Canton-Ferrer, C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. Llama 2: Open foundation and fine-tuned chat models. CoRR, abs/2307.09288, 2023. doi: 10.48550/ARXIV.2307.09 288. URL https://doi.org/10.48550/arXiv .2307.09288. Verga, P., Hofstatter, S., Althammer, S., Su, Y., Piktus, A., Arkhangorodsky, A., Xu, M., White, N., and Lewis, P. Replacing judges with juries: Evaluating LLM generations with panel of diverse models. CoRR, abs/2404.18796, 2024. doi: 10.48550/ARXIV.2404.18796. URL https: //doi.org/10.48550/arXiv.2404.18796. Wang, C., Wang, Y., Hooi, B., Cai, Y., Peng, N., and Chang, K. Con-ReCall: Detecting pre-training data in LLMs via contrastive decoding. In Rambow, O., Wanner, L., Apidianaki, M., Al-Khalifa, H., Eugenio, B. D., and Schockaert, S. (eds.), Proceedings of the 31st International Conference on Computational Linguistics, COLING 2025, Abu Dhabi, UAE, January 19-24, 2025, pp. 10131026. Association for Computational Linguistics, 2025. URL https://aclanthology.org/2025.coling -main.68/. Wang, P., Li, L., Chen, L., Cai, Z., Zhu, D., Lin, B., Cao, Y., Kong, L., Liu, Q., Liu, T., and Sui, Z. Large language models are not fair evaluators. In Ku, L., Martins, A., and Srikumar, V. (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024, pp. 9440 9450. Association for Computational Linguistics, 2024. doi: 10.18653/V1/2024.ACLLONG.511. URL https://doi.org/10.18653/v1/2024.acl -long.511."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "against membership inference attacks. In Bauer, L. and Pellegrino, G. (eds.), 34th USENIX Security Symposium, USENIX Security 2025, Seattle, WA, USA, August 13-15, 2025, pp. 81358154. USENIX Association, 2025. URL https://www.usenix.org/conference/us enixsecurity25/presentation/zhang-kai yuan. Zheng, L., Chiang, W., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E. P., Zhang, H., Gonzalez, J. E., and Stoica, I. Judging LLM-as-a-Judge with MT-Bench and chatbot arena. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S. (eds.), Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http: //papers.nips.cc/paper_files/paper/2 023/hash/91f18a1287b398d378ef22505bf 41832-Abstract-Datasets_and_Benchmar ks.html. Watson, L., Guo, C., Cormode, G., and Sablayrolles, A. On the importance of difficulty calibration in membership inference attacks. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https: //openreview.net/forum?id=3eIrli0TwQ. Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D. S., and Mann, G. BloombergGPT: large language model for finance. CoRR, abs/2303.17564, 2023. doi: 10.48550/A RXIV.2303.17564. URL https://doi.org/10.4 8550/arXiv.2303.17564. xAI. Grok 4 model card. Model card, xAI, August 2025. URL https://data.x.ai/2025-08-20-gro k-4-model-card.pdf. Xie, R., Wang, J., Huang, R., Zhang, M., Ge, R., Pei, J., Gong, N., and Dhingra, B. ReCaLL: Membership inference via relative conditional log-likelihoods. In Al-Onaizan, Y., Bansal, M., and Chen, Y. (eds.), Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024, pp. 8671 8689. Association for Computational Linguistics, 2024. doi: 10.18653/V1/2024.EMNLP-MAIN.493. URL https://doi.org/10.18653/v1/2024.emn lp-main.493. Yeom, S., Giacomelli, I., Fredrikson, M., and Jha, S. Privacy risk in machine learning: Analyzing the connection to overfitting. In 31st IEEE Computer Security Foundations Symposium, CSF 2018, Oxford, United Kingdom, July 9-12, 2018, pp. 268282. IEEE Computer Society, 2018. doi: 10.1109/CSF.2018.00027. URL https://doi. org/10.1109/CSF.2018.00027. Yu, D., Naik, S., Backurs, A., Gopi, S., Inan, H. A., Kamath, G., Kulkarni, J., Lee, Y. T., Manoel, A., Wutschitz, L., Yekhanin, S., and Zhang, H. Differentially private finetuning of language models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview.net/forum?id= Q42f0dfjECO. Zhang, J., Sun, J., Yeats, E. C., Ouyang, Y., Kuo, M., Zhang, J., Yang, H., and Li, H. H. Min-k%++: Improved baseline for detecting pre-training data from large language models. CoRR, abs/2404.02936, 2024. doi: 10.48550/ARXIV.2404.02936. URL https: //doi.org/10.48550/arXiv.2404.02936. Zhang, K., Cheng, S., Guo, H., Chen, Y., Su, Z., An, S., Du, Y., Fleming, C., Kundu, A., Zhang, X., and Li, N. SOFT: selective data obfuscation for protecting LLM fine-tuning"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "A. Appendix Organization The appendix is organized as follows: Appendix discusses the theoretical and practical limitations of relying on dataset-level comparisons for copyright auditing. Appendix details the reproduction issues identified in the SOFT framework, documenting specific implementation bugs regarding training regimes, model checkpointing, and model loading. Appendix provides comprehensive implementation details for SAGE, including algorithmic pseudocode, generation procedures, prompt strategies, and the methodology for the LLM-as-a-Judge utility evaluation. Appendix presents ablation studies and sensitivity analyses for the Semantic Persistence Score (SPS) and Word Similarity (WordSim) metrics, examining their stability across different probe models and layers. Appendix showcases qualitative examples of original documents alongside their SAGE and SAGE-R paraphrased variants across representative datasets. Appendix briefly addresses ablations regarding the removal of factual anchors in the original dataset. Finally, Appendix and Appendix report the extensive results for Membership Inference Attack (MIA) performance on Llama-3.2-3B and EleutherAI/pythia-6.9b respectively, covering all evaluated fine-tuning regimes, defense mechanisms, and evaluator models. B. On Dataset-level Comparisons Why dataset-level comparisons fail. One might attempt to bypass MIAs by asking the accused to disclose dataset and then comparing the suspect text against disclosed documents using token embeddings or nearest-neighbor matching. However, in realistic disputes this approach is not evidentially reliable. First, the accused can omit relevant items, disclose only partial corpora, or disclose transformed corpus whose provenance cannot be independently verified. Second, adding large volumes of unrelated or near-duplicate documents can change nearest-neighbor structure and undermine any fixed decision threshold. Third, without access to the true training corpus, and its preprocessing, the judge cannot calibrate what similarity level constitutes meaningful evidence of use. Consistent with this, prior work notes that most copyright auditing methods already operate under black-box access assumptions (Du et al., 2025). As result, dataset-level similarity may be suggestive in cooporative settings, but it does not provide robust test of infringement under the communication protocol in Section 2. C. Reproduction Issues in SOFT Framework During our attempt to reproduce the results reported in (Zhang et al., 2025), we identified several critical implementation issues in the official SOFT codebase6,7 that prevent faithful reproduction of the reported results. We document these issues below for transparency and to justify our corrected reimplementation. C.1. Bug 1: Inconsistent Training Regime In finetune.py (lines 254265), the implementation applies LoRA (Low-Rank Adaptation) wrapper to the model, then immediately enables gradient computation for all parameters: from peft import get_peft_model, LoraConfig lora_config = LoraConfig( r=128, lora_alpha=256, lora_dropout=0.1, bias=\"none\", task_type=\"CAUSAL_LM\", ) model = get_peft_model(model, lora_config) 6Accessed January 19, 2026, latest commit was: 7ca2b7b3b44e352e8ade6bea62889156fe1bff94. https://github.com/KaiyuanZh/SOFT/ 7https://web.archive.org/web/20251211132711/https://github.com/KaiyuanZh/SOFT"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "for param in model.parameters(): param.requires_grad = True This creates an undefined training regime that is neither standard LoRA fine-tuning (where only adapter parameters are trained) nor full fine-tuning (where all parameters of the original architecture are trained). Instead, it trains all parameters of modified architecture that includes additional LoRA layers. Notably, the original paper reports results using full fine-tuning without LoRA (Tables 1 and 2), making the presence of this snippet unexplained. This ambiguity makes the reported MIA results difficult to interpret and weakens claims that the results correspond to full fine-tuning baselines. C.2. Bug 2: Incorrect Model Checkpointing The training regime inconsistency in Bug 1 causes cascading failure in model saving. When trainer.save model() is called (lines 103 and 351) in finetune.py, the HuggingFace SFTTrainer detects that the model is PeftModel instance and consequently saves only the LoRA adapter weights, not the full model. Since all base model parameters were also trained (due to the requires grad=True loop), these trained weights are discarded and never persisted to disk. The correct approach for full fine-tuning would be to not wrap the model with LoRA at all. While calling model.merge and unload() before saving would merge the adapter weights into the base model, this would not resolve the fundamental issue: the model was trained in an undefined state where both LoRA adapters and the base model parameters were simultaneously trained. This optimization of redundant parameter sets (the base weights and their low-rank corrections) does not correspond to any standard fine-tuning methodology and produces model in an ill-defined state. Thus, even after merging, the resulting weights reflect this anomalous training dynamic rather than either pure full fine-tuning or pure LoRA adaptation. Neither proper fix nor any workaround is implemented in the original codebase. C.3. Bug 3: Model Loading Mismatch In main.py (lines 2932), where MIA attacks are executed, the model is loaded using standard HuggingFace utilities: model = AutoModelForCausalLM.from_pretrained( model_name, torch_dtype=torch.float16 ) This loading mechanism expects complete model checkpoint. However, due to Bug 2, the saved checkpoint contains only LoRA adapter weights. When AutoModelForCausalLM encounters this, it fails to locate full model weights and instead loads the base pretrained model without applying any fine-tuning adaptations8. No PEFT-specific loading mechanism (e.g., PeftModel.from pretrained()) is implemented. We note that even if such PEFT-aware loading were implemented, it would not resolve the underlying issues: the loaded adapter would still reflect the ill-defined training state from Bug 1, and the jointly-trained base model weights would remain lost due to Bug 2. C.4. Impact on Reproducibility The combined effect of these bugs is that all MIA attacks in the evaluation pipeline are executed against the original pretrained model rather than the fine-tuned model. This explains why our initial reproduction attempts yielded nearrandom-guessing performance for SOFT (AUC 0.50), as the model has no membership-specific information to leak. Using the provided codebase with these bugs intact, we were able to reproduce the SOFT defense results reported in their Table 1 and 2 (obtaining near-random-guessing AUC scores). However, we were unable to reproduce the baseline fine-tuning results (approximately 80% AUC) using the same flawed pipeline, as the evaluation necessarily runs against the pretrained model regardless of whether SOFTs obfuscation is applied. It remains unclear how the original authors obtained their reported baseline results with this implementation. To ensure fair and accurate comparison, we developed our own training and evaluation pipeline with the following corrections: 1. Removed the LoRA wrapper for full fine-tuning experiments 8https://huggingface.co/docs/transformers/v5.0.0rc2/en/main_classes/model#transformers. PreTrainedModel.from_pretrained"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Note: one LLM call returns an XML document with STRUCTURE (identical) and NARRATIVE (paraphrased) sections. x(n) PARAPHRASE(x, prompt) SPS 0; WordSim 0; 0 for each narrative section (ri, ri) in x(n) do SPS SPS + SPS(ri, ri) WordSim WordSim + WordSim(ri, ri) + 1 Algorithm 1 SAGE (Structure-Aware SAE-Guided Extraction) 1: Input: document x; max attempts ; thresholds τsps, τov 2: Output: paraphrase 3: ; 4: prompt base prompt 5: for = 1, 2, . . . , do 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: end for 27: return end if SPS SPS/c; WordSim WordSim/c SPS WordSim if > then end if prompt UPDATE(prompt, SPS, WordSim, τsps, τov) end if if SPS τsps and WordSim τov then end for if = 0 then continue u; x(n) return x(n) (SPS; Def. 3.1) (WordSim; Def. 3.2) (early stop) (fallback: best utility over attempts) 2. Ensured complete model weights are saved after training 3. Verified model loading correctly restores fine-tuned weights We retained the original SOFT data preparation and obfuscation methodology to ensure the defense mechanism itself is faithfully reproduced. Specifically, we preserved: (i) their dataset obfuscation pipeline, (ii) the loss-based sample selection strategy that identifies high-risk training samples, and (iii) the dynamic swapping mechanism that replaces original samples with paraphrased counterparts during training. Using this corrected pipeline, we re-trained the models and report our own results in the main tables to ensure correctness and reproducibility. For dataset obfuscation, we adhere to the original SOFT setup and generate paraphrased datasets for SOFT using the gpt-4o-mini-2024-07-18 model specified in their repository. D. Implementation Details D.1. Prompts and Hyperparameters Used Prompts and hyperparameters used can be found in our code repository in supplementary material or here9. D.2. Additional Details on SAGE Generation We provide here full pseudocode for SAGE, the paraphrasing pipeline used throughout our experiments to generate semanticpreserving variants of training documents. The algorithm formalizes the structure-aware rewriting procedure described in Section 3. 9https://github.com/kiraz-ai/sage-sps-mia"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Generation proceeds iteratively, as illustrated in Algorithm 1. For each input document x, SAGE generates sequence of paraphrasing attempts {x(n)}N n=1, where each attempt consists of single paraphrase produced by large language model operating under explicit semantic and surface-form constraints. Each paraphrase preserves structural sections verbatim while rewriting narrative sections only. The structuralnarrative decomposition is performed by the same language model used for paraphrasing, following fixed instruction format. This decomposition relies on deterministic instructions rather than learned classifiers or external heuristics, and the resulting section labels are returned directly by the model as part of the generation output. Structural sections are preserved verbatim, while only narrative sections are eligible for rewriting. After each paraphrasing attempt, SAGE evaluates the candidate using the semantic persistence score SPS(x, x(n)) and the word similarity score WordSim(x, x(n)), aggregated over narrative sections. If candidate satisfies the target thresholds SPS(x, x) 0.60 and WordSim(x, x) 0.35, the procedure terminates early and returns the candidate. Here, WordSim is computed over word sets extracted using simple regex-based tokenizer that retains alphanumeric spans and apostrophes. We emphasize that these thresholds are heuristic choices used solely for early stopping and computational convenience. They should not be interpreted as universal thresholds for semantic equivalence or robustness, nor do they carry any formal guarantees beyond guiding the paraphrase generation process. If the thresholds are not met, SAGE injects metric-based feedback into the next generation prompt. This feedback explicitly instructs the language model to either increase semantic fidelity or further reduce surface-form overlap, depending on which criterion failed. The process continues for fixed number of iterations, after which SAGE selects the candidate maximizing the utility SPS(x, x) WordSim(x, x). Between iterations, prompt updates encode only coarse feedback signals derived from the evaluation metrics, rather than exposing the metrics themselves. This design ensures that the paraphrasing process remains model-agnostic and does not rely on access to the audited models internals. The resulting paraphrases therefore reflect realistic, low-cost semantic obfuscations that an accused party could plausibly apply prior to training. D.3. SAGE-R: Factual Anchor Identification and Removal Both the SAGE-R defense and the FT-F ablation (see Appendix G) rely on identifying and removing factual anchors, defined as concrete entity mentions and literals that can act as stable lexical hooks for membership inference. These include named entities (e.g., people, organizations, locations), numeric quantities, and date expressions. LLM-based tagging. Factual anchors are first identified using fixed LLM-prompting procedure. Given the original document and its narrative representation, the model is prompted to extract structured list of factual items in strict JSON format. Each item consists of textual value, coarse type (e.g., entity, number, date), and optional notes. We use fixed system prompt and small set of few-shot examples, with decoding performed at fixed temperature. To ensure robustness to formatting errors, outputs are validated against predefined schema and re-prompted if necessary. The code and prompts can be found in Appendix D.1. Deterministic placeholder substitution. After factual anchors are identified, replacements are applied using deterministic, rule-based procedure. Factual values are ordered by first occurrence in the original prose-only text and assigned canonical placeholders of the form <<FACT 1>>, <<FACT 2>>, etc. All exact occurrences of each factual value are then replaced using regex-based substitution, ensuring that the same anchor is consistently mapped to the same placeholder within document. This step is entirely deterministic and does not involve additional model calls. We emphasize that this replacement is used solely for analysis and statistical control; during fine-tuning, the corresponding placeholder tokens are masked to prevent the model from learning or exploiting these anchors. Qualitative examples illustrating factual anchor identification and replacement are provided in Appendix F. D.4. LLM-as-a-Judge Utility Evaluation The degradation of membership inference attacks under paraphrasing does not imply that fine-tuned models lose or forget the underlying training knowledge. To verify that models retain usable semantic and conceptual information, we evaluate downstream utility using an LLM-as-a-Judge framework (Zheng et al., 2023), consistent with prior work on model evaluation beyond perplexity (Zhang et al., 2025). This approach replaces surface-level likelihood metrics with semantic assessment"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "of model outputs. Question Generation. For each dataset, we randomly sample documents from the fine-tuning split of MIMIR (we use the ngram 13 0.8 subset and the member field). We prompt GPT-4o-mini (OpenAI, 2024) to generate fixed set of evaluation questions in structured JSON, using only the first 4,000 characters of each sampled document to control context length. Questions are designed to be conceptual and self-contained (e.g., asking for explanations, implications, or high-level relationships), and the prompt discourages reliance on verbatim identifiers (names, exact phrasing, or brittle constants) so that the evaluation targets semantic competence rather than string memorization. We include robust parsing and retry logic to handle occasional malformed JSON generations. Question Generation and Coverage. To probe different notions of training-data familiarity, we generate comprehensive set of evaluation questions using GPT-4o-mini, conditioned on randomly sampled documents from each dataset. Question generation is prompt-driven and dataset-aware, with explicit constraints that discourage generic domain knowledge and instead target signals plausibly induced by exposure during training. Depending on the dataset, questions may include short excerpts (23 sentences) from the source text to ensure answerability without revealing verbatim identifiers. All questions are generated once and reused across models to ensure comparability. D.5. Question Set Composition For each dataset, we generate fixed set of 325 evaluation questions to probe different forms of training-data familiarity beyond brittle surface memorization. All questions are generated once and reused across models to ensure controlled comparisons. The question set combines multiple complementary types, summarized as follows: Standard specific-content questions (50): Target concrete methods, findings, or claims unique to document and are designed to fail under purely general domain knowledge. Closed-book topic questions (25): Probe semantic topic recognition and method awareness without relying on exact values or formulas, ensuring compatibility with SAGE-R. Tiered questions (60 total): Comprising 20 easy (topic recognition), 20 medium (core semantic content), and 20 hard (contextual understanding) questions to separate pretrained and fine-tuned behavior across difficulty regimes. Contrastive pairs (25 pairs / 50 questions): Matched in-domain and out-of-domain questions with identical structure, testing whether model discriminates between training-related and unrelated content. Cloze tasks (40): Fill-in-the-blank questions over key semantic concepts, enabling objective evaluation independent of LLM judges. Dataset-specific topic questions (100): Tailored to corpus characteristics (e.g., ArXiv field classification, Wikipedia article type, HackerNews discussion patterns), focusing on domain and style recognition rather than factual recall. Passage completion tasks (30): Evaluate stylistic and register learning by asking models to continue passage in manner consistent with the source corpus. Response Evaluation. Given question, the subject model generates an answer with stochastic decoding (temperature 0.7, up to 512 new tokens) to reflect typical usage rather than deterministic test-time decoding. Each answer is then graded by an LLM judge against reference answer derived from the source document. Concretely, we use panel of judges (GPT-4o-mini (OpenAI, 2024), DeepSeek-V3.2 (DeepSeek-AI, 2024), and Grok-4.1-fast (xAI, 2025)) and average their scores to reduce single-judge idiosyncrasies; judges output scalar score (on 0100 scale, normalized to [0, 1]) with deterministic decoding (temperature 0.0). To further mitigate run-to-run variance, we repeat the judging process three times per question and average the resulting scores. The final utility score for each model is the mean across all questions after these averages. Prompts and generated question sets are provided in Appendix D.1. Implications for Semantic Equivalence. The LLM-as-a-Judge results complement SPS by validating semantic preservation at the level of functional utility. High SPS values demonstrate representational similarity between original and paraphrased texts, while the judge-based evaluation confirms that this similarity translates into preserved downstream"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "performance. Together, these metrics operationalize semantic equivalence in manner aligned with the requirements of the judgeprosecutoraccused protocol: transformations that preserve meaning and utility cannot be distinguished from the original copyrighted material, even when membership signals are eliminated. Why can SAGE and SAGE-R outperform standard fine-tuning? Interestingly, SAGE, and in some cases SAGE-R achieves higher LLM-as-a-Judge scores than standard fine-tuning  (Table 3)  . We attribute this effect not to increased memorization, but to regularization-like benefit induced by semantic-preserving paraphrasing. By rewriting training data while preserving meaning, SAGE reduces lexical correlations and discourages the model from overfitting to surface-level phrasing. This encourages representations that are more semantically grounded and better aligned with downstream prompting, which can improve judged utility. This effect is most pronounced in structured or technical domains such as ArXiv and PubMed, where paraphrasing promotes abstraction over formulaic repetition. In contrast, gains are smaller or absent in noisier corpora such as HackerNews, where limited semantic structure constrains the benefits of paraphrasing. Overall, these results suggest that SAGE can act as form of data-level regularization that improves semantic generalization without degrading utility. Importantly, these effects do not impact our conclusions: utility comparisons are only interpreted within each dataset, and our core claim is the absence of systematic utility degradation under semantic-preserving paraphrasing, rather than absolute performance improvements. E. Ablation and Analysis on SPS & WordSim E.1. Paraphrase Quality Table 4 report paraphrase quality across datasets and paraphrasing models for SAGE and SAGE-R. Across all settings, SAGE consistently achieves higher SPS than SAGE-R, indicating stronger semantic persistence when structural and factual anchors are preserved. This gap is visible across domains and paraphrasers, including technical corpora (e.g., arxiv, pubmed) as well as more informal data (e.g., hackernews). At the same time, absolute SPS values vary substantially across datasets and paraphrasing models. For instance, technical datasets exhibit higher SPS overall, reflecting the presence of stable factual anchors, while informal domains show lower and more variable scores. No single paraphraser uniformly dominates across datasets, and differences between models (e.g., DeepSeek v3.2 (DeepSeek-AI, 2024) vs. Gemini 2.5 Flash (Google, 2025)) are often comparable in magnitude to differences induced by the dataset itself. Importantly, all configurations maintain low WordSim values, confirming that semantic preservation is achieved alongside substantial surface-level rewriting. Taken together, these results indicate that while SPS reliably distinguishes between semantically richer (SAGE) and more aggressively obfuscated (SAGE-R) paraphrases, its absolute scale is datasetand model-dependent, motivating more detailed analysis of how SPS behaves across semantic observers. E.2. SAE Implementation Details & Ablation We next analyze how the SPS depends on the choice of semantic observer by varying both the probe model and the SAE layer used for feature extraction. Tables 5, 6, and 7 report SPS under SAGE and SAGE-R for three representative probe models (Gemma-2B (Gemma Team, 2024), Pythia-70M-deduped (Biderman et al., 2023), and GPT-2 Small (Radford et al., 2019)), evaluated at multiple transformer layers. All results are averaged across paraphrasing models to isolate the effect of the semantic representation itself. No universal SPS threshold. Across all probe models and layers, we observe substantial variation in absolute SPS values. Earlier layers tend to yield lower scores, while deeper layers often produce higher SPS, reflecting increasing semantic abstraction in the underlying representations. Moreover, the scale of SPS differs markedly between probe models (e.g., Gemma-2B vs. Pythia-70M), indicating that SPS is inherently tied to the robustness and expressivity of the semantic observer. As result, there is no single, model-independent threshold that cleanly separates semantic preservation from semantic drift. This observation suggests that SPS should be interpreted relatively rather than absolutely: either calibrated to the specific probe model and layer, or aggregated (e.g., averaged) across multiple observers to mitigate idiosyncrasies of any single"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 4. SAGE vs. SAGE-R: Complete paraphrase quality metrics of datasets generated by each model. Higher SPS indicates better semantic preservation; lower WordSim indicates greater surface divergence."
        },
        {
            "title": "Model",
            "content": "SPS WordSim SPS WordSim"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R arxiv wikipedia pile cc pubmed hackernews DeepSeek v3.2 Gemini 2.5 Flash Grok 4.1 Fast DeepSeek v3.2 Gemini 2.5 Flash Grok 4.1 Fast DeepSeek v3.2 Gemini 2.5 Flash Grok 4.1 Fast DeepSeek v3.2 Gemini 2.5 Flash Grok 4.1 Fast DeepSeek v3.2 Gemini 2.5 Flash Grok 4.1 Fast 0.761 0.699 0. 0.697 0.672 0.692 0.652 0.576 0.675 0.767 0.666 0.753 0.555 0.528 0.638 0.329 0.360 0.332 0.340 0.375 0. 0.230 0.241 0.253 0.296 0.329 0.306 0.195 0.187 0.226 0.677 0.651 0.644 0.504 0.492 0.488 0.556 0.499 0. 0.602 0.597 0.631 0.501 0.488 0.565 0.271 0.318 0.278 0.211 0.250 0.201 0.181 0.195 0.190 0.242 0.291 0. 0.165 0.162 0.190 representation. Consistent separation between SAGE and SAGE-R. Despite this variability, there is consistent pattern across all ablations: SAGE achieves higher SPS than SAGE-R for every dataset, probe model, and layer considered. This gap persists even when absolute SPS values fluctuate substantially, and remains visible in both shallow and deep representations. In particular, SAGE-R exhibits systematic reduction in SPS relative to SAGE, reflecting the deliberate removal of structural and factual anchors that contribute to stable semantic representations. Implications for SPS as semantic signal. Taken together, these results validate SPS as meaningful measure of semantic persistence rather than similarity heuristic. While SPS does not admit universal threshold applicable across models, it robustly captures relative semantic degradation induced by stronger obfuscation. The fact that the SAGE vs. SAGE-R ordering is invariant to the choice of probe model and layer indicates that SPS reflects genuine semantic property shared across representations, rather than an artifact of particular SAE or architecture. Table 5. Ablation (SAGE vs SAGE-R): SPS by SAE layer for the Gemma-2B probe model at hook blocks.Lk.hook resid post. Here Lk denotes the transformer block index used for feature extraction; higher SPS indicates better semantic preservation. Results are averaged over paraphraser models (DeepSeek v3.2, Gemini 2.5 Flash, Grok 4.1 Fast)."
        },
        {
            "title": "Dataset",
            "content": "SPS L6 SPS L12 SPS L17 SAGE SAGE-R SAGE SAGE-R SAGE SAGE-R arXiv Wikipedia Pile-CC PubMed HackerNews"
        },
        {
            "title": "Average",
            "content": "0.754 0.749 0.687 0.772 0.644 0.721 0.679 0.514 0.590 0.626 0.589 0.600 0.721 0.687 0.634 0.729 0.574 0. 0.657 0.495 0.541 0.610 0.518 0.564 0.812 0.764 0.683 0.797 0.598 0.731 0.775 0.599 0.580 0.733 0.519 0. F. Qualitative Examples of SAGE variants Tables 811 present qualitative examples of different SAGE variants, illustrating their behavior across representative samples."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 6. Ablation (SAGE vs SAGE-R): SPS by SAE layer for the Pythia-70M-deduped probe model at hook blocks.Lk.hook resid post. Here Lk denotes the transformer block index used for feature extraction; higher SPS indicates better semantic preservation. Results are averaged over paraphraser models (DeepSeek v3.2, Gemini 2.5 Flash, Grok 4.1 Fast)."
        },
        {
            "title": "Dataset",
            "content": "SPS L3 SPS L4 SAGE SAGE-R SAGE SAGE-R arXiv Wikipedia Pile-CC PubMed HackerNews"
        },
        {
            "title": "Average",
            "content": "0.658 0.622 0.584 0.693 0.571 0.626 0.564 0.363 0.477 0.448 0.514 0.473 0.655 0.631 0.587 0.694 0.570 0. 0.568 0.386 0.473 0.468 0.503 0.480 Table 7. Ablation (SAGE vs SAGE-R): SPS by SAE layer for the GPT-2 Small probe model at hook blocks.Lk.hook resid pre. Here Lk denotes the transformer block index used for feature extraction; higher SPS indicates better semantic preservation. Results are averaged over paraphraser models (DeepSeek v3.2, Gemini 2.5 Flash, Grok 4.1 Fast)."
        },
        {
            "title": "Dataset",
            "content": "SPS L6 SPS L8 SPS L10 SAGE SAGE-R SAGE SAGE-R SAGE SAGE-R arXiv Wikipedia Pile-CC PubMed HackerNews"
        },
        {
            "title": "Average",
            "content": "0.672 0.637 0.559 0.732 0.529 0.626 0.562 0.348 0.456 0.521 0.472 0.472 0.675 0.651 0.555 0.727 0.507 0. 0.582 0.378 0.450 0.553 0.449 0.483 0.685 0.664 0.559 0.735 0.504 0.629 0.622 0.419 0.449 0.630 0.440 0. G. Ablation on Factual Anchors natural question is whether the observed suppression of membership inference attacks is primarily driven by the removal of explicit factual anchors (e.g., names, numbers, dates), rather than by semantic-preserving paraphrasing. To isolate this effect, we consider an ablation (FT-F) in which factual anchors are removed directly from the original training data, while leaving the surrounding linguistic structure unchanged. This setting preserves much of the original surface form and syntax, but eliminates potentially identifiable facts. Tables 12 and 13 show that factual removal alone yields only partial reduction in attack effectiveness. Across datasets and attacks, FT-F consistently reduces AUC and TPR@FPR relative to standard fine-tuning (FT), indicating that factual anchors do contribute to membership signals. However, the residual leakage remains substantial, and FT-F is uniformly weaker than both SAGE and SAGE-R. In contrast, SAGE further suppresses MIAs by jointly reducing surface-form overlap while preserving semantic content, and SAGE-R achieves the strongest suppression by additionally removing structural and factual cues. The gap between FT-F and SAGE demonstrates that eliminating facts alone is insufficient: membership inference attacks continue to exploit broader lexical and structural regularities that survive factual deletion. These results confirm that robust suppression of MIAs requires semantic-preserving rewriting that actively disrupts surface-level correlations, rather than isolated removal of factual tokens. H. Detailed Results on meta-llama/Llama-3.2-3B Table 14 reports membership inference performance on the pretrained (PT) model across datasets and attacks that is fine-tuned on Llama-3.2-3B (Grattafiori et al., 2024). Since the model has not been exposed to any downstream fine-tuning data, all attacks perform at or near random guessing, with AUC values tightly concentrated around 0.5 and low TPR@0.01%FPR. This establishes lower-bound baseline and validates the experimental setup. From the rest of the tables, we can see that once the model is trained on downstream data, membership inference becomes highly effective, and"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R arxiv / deepseek v3.2 / sample idx=70 abstract: The families of braid groups, surface braid groups, mapping class groups and loop braid groups have representation theory of wild type, so it is very useful to be able to construct such representations *topologically*, so that they may be understood by topological or geometric methods. For the braid groups ${}mathbf{B} n$, Lawrence and Bigelow have constructed families of representations starting from actions of ${}mathbf{B} n$ on the twisted homology of configuration spaces. These were then used by Bigelow and Krammer to prove that the braid groups are linear. We develop general underlying procedure to build homological representations of families of groups, encompass... hackernews / grok 4.1 fast / sample idx=91 Americas Highest Minimum Wage Sparks Fight in Small California City - JumpCrisscross https://www.wsj.com/articles/americashighest-minimum-wage-sparks-fight-insmall-california-city11563960603?mod=rsswn ====== vgoh1 Typical WSJ rubbish. Focus on anecdotes, like the guy who sacks over half of his staff because of < 15% increase in minimum wage. Having grown up solidly in the class of the working poor, can tell you side of the story that is not often told - there is not enough difference in quality of life between working poor and just being on public assistance and unemployed. When you are unemployed, you get government benefits, and most people either have side hustle (odd j... pubmed central / gemini 2.5 flash / sample idx=405 Introduction {#Sec1} ============ While meditation is often viewed and employed as technique to reduce stress (Chiesa and Seretti [@CR8]), its potential to increase cognitive abilities has been emphasized from its beginnings (e.g., Luk [@CR33]). For instance, some Buddhist meditation techniques explicitly and intentionally target the training and improvement of concentration (manasikara) and insight (vipassana; see Santucci [@CR45]), which tap into attentional control and higher-order cognition that according to Lutz et al. ([@CR34]) are systematically affected and improved by meditation. These possible links to cognitive improvement have attracted the attention of researchers, who inde... abstract: The representation theory for groups such as braid groups, surface braid groups, mapping class groups, and loop braid groups is of wild type, making topological constructions particularly valuable. Such topological representations facilitate comprehension through topological and geometric frameworks. In the case of the braid groups ${}mathbf{B} n$, Lawrence and Bigelow developed series of representations. Their method originated from actions of ${}mathbf{B} n$ on the twisted homology groups of configuration spaces. Subsequently, Bigelow and Krammer utilized these constructions to establish the linearity of the braid groups. We introduce universal, foundational proced... The representation theory for groups such as braid groups, surface braid groups, mapping class groups, and loop braid groups is of <<FACT 1>>, making topological constructions particularly valuable. Such topological representations facilitate comprehension through topological and geometric frameworks. In the case of the braid groups <<FACT 2>>, <<FACT 3>> and <<FACT 4>> developed series of representations. Their method originated from actions of <<FACT 2>> on the twisted homology groups of configuration spaces. Subsequently, <<FACT 4>> and <<FACT 5>> utilized these constructions to establish the linearity of the braid groups. We introduce universal, foundational procedure for constru... Americas Highest Minimum Wage Sparks Fight in Small California City - JumpCrisscross https://www.wsj.com/articles/americashighest-minimum-wage-sparks-fight-insmall-california-city11563960603?mod=rsswn ====== vgoh1 Standard WSJ nonsense. It highlights anecdotes, such as the man who lays off more than half his employees due to minimum wage hike under 15%. Raised firmly within the working poor class, can share seldom-discussed aspect: the quality-of-life disparity between the working poor and those unemployed on public assistance is quite small. The unemployed receive government benefits, with most engaging in side hustlessuch as under-the-table odd jobs or occasionally outrig... Standard <<FACT 1>> nonsense. It highlights anecdotes, such as the man who lays off more than half his employees due to minimum wage hike under <<FACT 2>>. Raised firmly within the working poor class, can share seldom-discussed aspect: the quality-of-life disparity between the working poor and those unemployed on public assistance is quite small. The unemployed receive government benefits, with most engaging in side hustlessuch as under-the-table odd jobs or occasionally outright illegal workor perpetrating fraud, like claiming solo residency while actually sharing rent among several people. No judgment here; thats simply how it is. Thus, minimum-wage workers... Introduction {#Sec1} ============ Meditation is frequently perceived and utilized as method for stress reduction (Chiesa and Seretti [@CR8]). Nevertheless, its capacity to enhance cognitive functions has been highlighted since its earliest discussions (e.g., Luk [@CR33]). For example, certain Buddhist meditation practices, as noted by Santucci [@CR45], are specifically designed to cultivate and refine concentration (manasikara) and insight (vipassana). These practices engage attentional control and higher-order cognition, which, according to Lutz et al. ([@CR34]), are systematically influenced and improved through meditation. The potential connections to cognitive enhancement have garne... Meditation is frequently perceived and utilized as method for stress reduction (<<FACT 1>>). Nevertheless, its capacity to enhance cognitive functions has been highlighted since its earliest discussions (e.g., <<FACT 2>>). For example, certain Buddhist meditation practices, as noted by <<FACT 3>>, are specifically designed to cultivate and refine concentration (manasikara) and insight (vipassana). These practices engage attentional control and higher-order cognition, which, according to <<FACT 4>>, are systematically influenced and improved through meditation. The potential connections to cognitive enhancement have garnered considerable interest from the research community. Studies have in... Table 8. Qualitative examples (truncated to 700 chars)."
        },
        {
            "title": "SAGE",
            "content": "SAGE-R hackernews / grok 4.1 fast / sample idx=97 Homestead High School Newspaper, May 22, 1977 - timdierks http://imgur.com/st7eyiR ====== nealabq The paper was, and still is, called The Epitaph. Chris at the time was also one of the publishers/writers of an underground school paper called The Road Apple. DrScump That McDonalds still exists in the same location, but bet they wont accept the coupon anyway. pikachu is cool Especially since it expires on May 29, 1XXX DrScump Theoretically, it could be A.D. 10,000+ ashwinl Part of the ethos back then too: Apple Computer Inc. will explain how to use any of the equipment you have or give demonstrations before you buy one coldcode If you invested the pric... Homestead High School Newspaper, May 22, 1977 - timdierks http://imgur.com/st7eyiR ====== nealabq The newspaper was known as, and continues to be named, The Epitaph. DrScump That McDonalds location remains operational to this day, though they probably wont honor the coupon regardless. pikachu is cool Particularly given that it expires on May 29, 1XXX. DrScump In theory, it could refer to A.D. 10,000+. ashwinl That eras philosophy included: Apple Computer Inc. will explain how to use any of the equipment you have or give demonstrations before you buy one. coldcode Had you invested the burgers cost (shortly after their IPO) and retained it until now, you... The newspaper was known as, and continues to be named, <<FACT 1>>. That <<FACT 2>> location remains operational to this day, though they probably wont honor the coupon regardless. Particularly given that it expires on <<FACT 3>>. In theory, it could refer to <<FACT 4>>. That eras philosophy included: <<FACT 5>> will explain how to use any of the equipment you have or give demonstrations before you buy one. Had you invested the burgers cost (shortly after their IPO) and retained it until now, you might afford an entire franchise. wonder what became of those two <<FACT 6>> units shipped to <<FACT 7>>? Uncertain about those specific units, but an <<FACT 6>> was still operatio... arxiv / grok 4.1 fast / sample idx=170 abstract: We review recent findings that the universe on its largest scales shows hints of the violation of statistical isotropy, in particular alignment with the geometry and direction of motion of the solar system, and missing power at scales greater than 60 degrees. We present the evidence, attempts to explain it using astrophysical, cosmological or instrumental mechanisms, and prospects for future understanding. address: $ˆ1$Kavli Institute for Cosmological Physics and Department of Astronomy and Astrophysics, University of Chicago, Chicago, IL 60637{} E-mail: dhuterer@kicp.uchicago.edu author: - Dragan Huterer$ˆ1$ title: Mysteries on Universes Largest Observable Scales ... abstract: Recent findings indicate that the universe, on its largest scales, exhibits signs of statistical isotropy violationspecifically, alignments with the solar systems geometry and motion direction, along with reduced power at scales exceeding 60 degrees. This review outlines the supporting evidence, explanatory efforts via astrophysical, cosmological, or instrumental causes, and future investigative prospects. address: $ˆ1$Kavli Institute for Cosmological Physics and Department of Astronomy and Astrophysics, University of Chicago, Chicago, IL 60637{} E-mail: dhuterer@kicp.uchicago.edu author: - Dragan Huterer$ˆ1$ title: Mysteries on Universes Largest Observable Scales... Recent findings indicate that the universe, on its largest scales, exhibits signs of statistical isotropy violationspecifically, alignments with the solar systems geometry and motion direction, along with reduced power at scales exceeding <<FACT 1>>. This review outlines the supporting evidence, explanatory efforts via astrophysical, cosmological, or instrumental causes, and future investigative prospects. The cosmological principle asserts that the universe appears homogeneous and isotropic at its largest scales. Typically presented at the start of cosmology courses, this principle forms an essential foundation for deriving key outcomes in quantitative cosmology. For instance, by invoking... Table 9. Qualitative examples (truncated to 700 chars)."
        },
        {
            "title": "SAGE",
            "content": "SAGE-R pubmed central / grok 4.1 fast / sample idx=29 INTRODUCTION ============ Exclusive breastfeeding (EBF) practice is influenced by many factors. Up to the age of 6 months it is positively associated with rural residence, Malay speaking, non-working, smoking and multiparous mothers, term infants, having supportive husband and the mother practicing bed-sharing {}[[@B1]{}]. The working status of mothers influences EBF practice and favorable working environment and support in the workplace promotes EBF practice {}[[@B2]{}]. EBF is usually high during maternity leave in Indonesia and national health survey found that the prevalence was 40% in 2003 {}[[@B3]{}], before falling to 32% in 2012 {}[[@B4]{}]. The increasing number of working mothers... INTRODUCTION ============ Numerous factors affect the practice of exclusive breastfeeding (EBF). For infants up to 6 months old, EBF shows positive links to rural living, Malay-speaking backgrounds, non-working status, smoking habits and multiparity among mothers, term births, supportive husbands, and bed-sharing by the mother {}[[@B1]{}]. Mothers employment status impacts EBF adherence, with supportive workplace conditions and assistance enhancing EBF continuation {}[[@B2]{}]. In Indonesia, EBF rates tend to peak during maternity leave periods; national survey reported 40% prevalence in 2003 {}[[@B3]{}], dropping to 32% by 2012 {}[[@B4]{}]. This decline is attributed to rising numbers of work... Numerous factors affect the practice of exclusive breastfeeding (EBF). For infants up to <<FACT 1>> old, EBF shows positive links to rural living, Malay-speaking backgrounds, non-working status, smoking habits and multiparity among mothers, term births, supportive husbands, and bed-sharing by the mother <<FACT 2>>. Mothers employment status impacts EBF adherence, with supportive workplace conditions and assistance enhancing EBF continuation <<FACT 3>>. In Indonesia, EBF rates tend to peak during maternity leave periods; national survey reported <<FACT 4>> prevalence in <<FACT 5>> <<FACT 6>>, dropping to <<FACT 7>> by <<FACT 8>> <<FACT 9>>. This decline is attributed to rising numbers of w... hackernews / deepseek v3.2 / sample idx=972 Lawmakers Prod FCC to Act on SIM Swapping - mikece https://krebsonsecurity.com/2020/01/senatorsprod-fcc-to-act-on-sim-swapping/ ====== mrandish This seems like its already serious and growing problem. It might be best to take two-pronged approach of quickly implementing process requirements that make such swaps harder for crooks while working to come up with longerterm technological solution. Its crazy that minimum-wage retail mobile store employee is the weak link in system that protects almost everyones financial assets from banking and investment accounts to credit cards and crypto-currencies. throwawayatt purchased an unlocked iPhone recently from Apple and decid... Lawmakers Prod FCC to Act on SIM Swapping - mikece https://krebsonsecurity.com/2020/01/senatorsprod-fcc-to-act-on-sim-swapping/ ====== mrandish The issue of SIM swapping appears to be significant and expanding threat. An effective strategy could involve dual effort: first, to rapidly establish procedural mandates that increase the difficulty for malicious actors to perform these swaps, and second, to concurrently develop more robust, permanent technological fix. It is concerning that low-paid retail mobile store clerk serves as the critical vulnerability in security framework safeguarding the vast majority of financial holdings, spanning from traditional bank and investment acc... The issue of <<FACT 1>> swapping appears to be significant and expanding threat. An effective strategy could involve dual effort: first, to rapidly establish procedural mandates that increase the difficulty for malicious actors to perform these swaps, and second, to concurrently develop more robust, permanent technological fix. It is concerning that low-paid retail mobile store clerk serves as the critical vulnerability in security framework safeguarding the vast majority of financial holdings, spanning from traditional bank and investment accounts to credit lines and digital currencies. After buying an unlocked <<FACT 2>> directly from <<FACT 3>>, opted to transfer my <<FACT 4>>... Table 10. Qualitative examples (truncated to 700 chars)."
        },
        {
            "title": "SAGE",
            "content": "SAGE-R pile cc / grok 4.1 fast / sample idx=448 How We Work How We Work - Its As Easy As 1-2-3 ! - really pleased how quickly they found experienced candidates for us. Very happy ! REM Heres how we can help you... *Dont have Job or Person Specification? No problem, well send you our quick-to-complete, one-page template. Once youve answered the questions, you (and we) will have very clear understanding of what youre looking for. *Not sure how much you should pay your new employee? Well research the market and advise you. * Skill shortages? In theses times of full employment and declining immigration from Europe, skill shortages are becoming an ever more serious problem. As an employer you need to be able to demonstrate cle... pile cc / grok 4.1 fast / sample idx=136 Wines and Meads, from both sides of the pond plus few bits of other fermented food/drink Saturday, November 06, 2010 Disheartening Results.......... Been busy bee today, as there was about 10 or 11 gallons of various brews that needed racking etc.... So why the strange thread title ? Well, its one of those days where Ive got the WTF thoughts going through my head. Why ? Well as was racking various brews, not many of them taste like think they should. And dont really know why that is. For instance, good few years ago, reasonably local brewery, not only made some excellent beers (real ale type), but they also made range of country wines. Id tasted about 5 or 6 of t... How We Work How We Work - Its As Easy As 1-2-3 ! - Really pleased with how quickly they identified experienced candidates for us. Very happy! REM Heres how we can assist you... *No Job or Person Specification available? Thats finewell provide our simple one-page template thats quick to fill out. After responding to the questions, both you and we will gain clear picture of your requirements. *Uncertain about salary for your new hire? We will investigate market rates and provide guidance. *Facing skill shortages? During these periods of full employment and reduced immigration from Europe, such shortages are intensifying as major challenge. Employers must clearly show candidates... Really pleased with how quickly they identified experienced candidates for us. Very happy! <<FACT 1>> Heres how we can assist you... *No Job or Person Specification available? Thats finewell provide our simple one-page template thats quick to fill out. After responding to the questions, both you and we will gain clear picture of your requirements. *Uncertain about salary for your new hire? We will investigate market rates and provide guidance. *Facing skill shortages? During these periods of full employment and reduced immigration from <<FACT 2>>, such shortages are intensifying as major challenge. Employers must clearly show candidates why they should choose YOU over competitors... Wines and Meads, from both sides of the pond plus few bits of other fermented food/drink Saturday, November 06, 2010 Disheartening Results.......... Today was busy bee, since approximately 10 or 11 gallons of different brews had to be racked, among other things. This explains the unusual thread title. Its simply one of those days with WTF thoughts running through my mind. The cause? While racking the various brews, not many tasted the way expected them to. truly have no idea why. As an example, few years ago nearby brewery crafted not just excellent real ale-style beers but also variety of country wines. sampled about 5 or 6 of those wines, and the best descriptio... Today was busy bee, since approximately <<FACT 1>> of different brews had to be racked, among other things. This explains the unusual thread title. Its simply one of those days with WTF thoughts running through my mind. The cause? While racking the various brews, not many tasted the way expected them to. truly have no idea why. As an example, few years ago nearby brewery crafted not just excellent real ale-style beers but also variety of country wines. sampled about <<FACT 2>> of those wines, and the best description of my memory of them remains alcoholic fruit cordials. Much of my knowledge about how wines should be produced derives from experts at resources like <<... Table 11. Qualitative examples (truncated to 700 chars). Table 12. AUC (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. FT-F denotes an ablation in which factual anchors (e.g., names, numbers, dates) are removed directly from the original training data without paraphrasing. (Full Finetuning) arxiv wikipedia pile cc hackernews pubmed FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0. 0.688 1.000 1.000 1.000 1.000 0.498 0.995 0.996 0. 0.670 0.963 0.995 0.995 0.995 0.498 0.921 0.912 0. 0.644 0.747 0.933 0.893 0.986 0.498 0.794 0.786 0. 0.587 0.614 0.809 0.699 0.934 0.498 1.000 1.000 0. 0.705 1.000 1.000 1.000 1.000 0.510 0.978 0.987 0. 0.654 0.834 0.981 0.968 0.993 0.510 0.883 0.890 0. 0.634 0.775 0.889 0.845 0.984 0.510 0.671 0.676 0. 0.546 0.583 0.678 0.619 0.733 0.510 0.999 0.999 0. 0.747 0.999 0.999 0.999 1.000 0.498 0.994 0.997 0. 0.713 0.936 0.995 0.994 1.000 0.498 0.848 0.870 0. 0.627 0.696 0.856 0.765 0.967 0.498 0.696 0.726 0. 0.561 0.577 0.706 0.609 0.815 0.498 1.000 1.000 0. 0.689 0.999 1.000 1.000 1.000 0.524 1.000 1.000 0. 0.668 0.913 1.000 0.999 1.000 0.524 0.947 0.955 0. 0.618 0.711 0.954 0.816 0.997 0.524 0.759 0.785 0. 0.535 0.585 0.766 0.616 0.877 0.524 1.000 1.000 1. 0.698 1.000 1.000 1.000 1.000 0.528 1.000 1.000 0. 0.672 0.983 1.000 1.000 1.000 0.528 0.842 0.837 0. 0.603 0.657 0.867 0.789 0.976 0.528 0.765 0.761 0. 0.573 0.608 0.786 0.697 0.915 0.528 Average 0. 0.95 0.86 0.73 0.96 0.91 0. 0.63 0.97 0.94 0.80 0.65 0. 0.94 0.86 0.69 0.96 0.95 0. 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 13. TPR@FPR=0.01 (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. FT-F denotes an ablation in which factual anchors (e.g., names, numbers, dates) are removed directly from the original training data without paraphrasing. (Full Finetuning) arxiv wikipedia pile cc hackernews pubmed FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R FT FT-F SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.986 0.597 0.997 1. 1.000 1.000 0.007 0.985 0.989 0.786 0.541 0.571 0. 0.975 0.992 0.007 0.393 0.429 0.430 0.356 0.115 0. 0.373 0.893 0.007 0.051 0.057 0.024 0.084 0.018 0. 0.066 0.497 0.007 0.994 0.997 0.980 0.622 0.993 0. 0.993 1.000 0.004 0.559 0.646 0.252 0.324 0.118 0. 0.528 0.966 0.004 0.208 0.257 0.257 0.187 0.127 0. 0.202 0.887 0.004 0.024 0.017 0.017 0.034 0.014 0. 0.018 0.184 0.004 0.988 0.996 0.982 0.673 0.986 0. 0.988 1.000 0.010 0.853 0.970 0.452 0.523 0.508 0. 0.871 0.998 0.010 0.074 0.192 0.124 0.091 0.052 0. 0.099 0.750 0.010 0.011 0.034 0.018 0.017 0.014 0. 0.021 0.255 0.010 1.000 1.000 0.995 0.612 0.994 1. 1.000 1.000 0.011 0.997 0.999 0.739 0.539 0.395 0. 0.988 1.000 0.011 0.450 0.550 0.314 0.265 0.094 0. 0.286 0.968 0.011 0.084 0.113 0.031 0.055 0.022 0. 0.062 0.366 0.011 1.000 1.000 0.990 0.620 0.996 1. 1.000 1.000 0.011 0.995 0.999 0.734 0.558 0.769 0. 0.993 1.000 0.011 0.210 0.277 0.130 0.195 0.057 0. 0.161 0.794 0.011 0.094 0.121 0.034 0.101 0.024 0. 0.082 0.600 0.011 Average 0.95 0.85 0. 0.11 0.95 0.50 0.29 0.04 0. 0.75 0.18 0.05 0.95 0.83 0. 0.10 0.95 0.88 0.26 0.15 that the effect is consistent across datasets, attacks, and evaluator backends. In particular, under full fine-tuning without defenses (FT), most MIAs achieve near-perfect AUCs across all five datasets (Table 15, Table 18, Table 22, Table 26) and this is mirrored by TPR@1%FPR values near 1.0 (Table 16, Table 20, Table 28). When defenses are applied, SAGE reduces leakage substantially and SAGE-R reduces it further, producing large drops in both AUC and TPR across all datasets (e.g., compare FT vs. SAGE vs. SAGE-R columns within Table 15 and Table 16). Finally, the LoRA regime is systematically less vulnerable than full fine-tuning, with noticeably lower AUC/TPR in the undefended setting and further reductions under SAGE/SAGE-R (Table 17, Table 19, Table 21, Table 23, Table 25, Table 27). Overall, these detailed results reinforce the main takeaway: fine-tuning introduces strong membership signal, SAGE mitigates it, and SAGE-R provides the strongest and most consistent suppression, while patterns are stable across datasets and evaluator models. Table 14. Pretrained (PT) membership inference attack performance across datasets and attacks. Each cell reports AUC, with the corresponding TPR@1%FPR shown in parentheses. Evaluated on meta-llama/Llama-3.2-3B. Pretrained (PT) arxiv wikipedia pile cc hackernews pubmed Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words Ensemble 0.513 (0.005) 0.518 (0.008) 0.485 (0.009) 0.510 (0.012) 0.504 (0.006) 0.508 (0.005) 0.514 (0.001) 0.516 (0.008) 0.498 (0.007) 0.562 (0.023) 0.502 (0.015) 0.501 (0.014) 0.507 (0.016) 0.503 (0.016) 0.507 (0.014) 0.506 (0.014) 0.515 (0.016) 0.510 (0.010) 0.510 (0.004) 0.533 (0.030) 0.489 (0.012) 0.498 (0.016) 0.486 (0.012) 0.505 (0.008) 0.491 (0.010) 0.497 (0.010) 0.498 (0.010) 0.482 (0.012) 0.498 (0.010) 0.574 (0.026) 0.501 (0.007) 0.490 (0.005) 0.506 (0.005) 0.482 (0.017) 0.506 (0.012) 0.494 (0.006) 0.515 (0.008) 0.509 (0.007) 0.524 (0.011) 0.522 (0.024) 0.481 (0.005) 0.482 (0.006) 0.513 (0.003) 0.498 (0.007) 0.491 (0.007) 0.484 (0.006) 0.501 (0.007) 0.505 (0.014) 0.528 (0.011) 0.547 (0.042)"
        },
        {
            "title": "Average",
            "content": "0.51 (0.01) 0.51 (0.01) 0.50 (0.01) 0.50 (0.01) 0.50 (0.01) I. Detailed Results on EleutherAI/pythia-6.9b Ablation on EleutherAI/pythia-6.9b (Biderman et al., 2023) (Tables 29 45) shows the same ordering as our main results: attacks are near-chance on the pretrained (PT) model  (Table 29)  , LoRA adaptation yields moderate leakage that is further reduced by SAGE and most strongly by SAGE-R, and full fine-tuning produces the strongest leakage while SAGE/SAGE-R substantially suppress it. Tables 30 and 31 summarizes the results by reporting the average over 3 paraphrasers. Overall, the ablation confirms that our conclusions are not specific to single backbone and that the relative effectiveness of SAGE and SAGE-R is consistent across datasets and attacks."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 15. AUC (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (Full Finetuning). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0. 1.000 1.000 1.000 1.000 0.498 0.921 0.912 0.876 0. 0.747 0.933 0.893 0.986 0.498 0.794 0.786 0.617 0. 0.614 0.809 0.699 0.934 0.498 1.000 1.000 0.999 0. 1.000 1.000 1.000 1.000 0.510 0.883 0.890 0.847 0. 0.775 0.889 0.845 0.984 0.510 0.671 0.676 0.568 0. 0.583 0.678 0.619 0.733 0.510 0.999 0.999 0.999 0. 0.999 0.999 0.999 1.000 0.498 0.848 0.870 0.794 0. 0.696 0.856 0.765 0.967 0.498 0.696 0.726 0.541 0. 0.577 0.706 0.609 0.815 0.498 1.000 1.000 0.999 0. 0.999 1.000 1.000 1.000 0.524 0.947 0.955 0.860 0. 0.711 0.954 0.816 0.997 0.524 0.759 0.785 0.576 0. 0.585 0.766 0.616 0.877 0.524 1.000 1.000 1.000 0. 1.000 1.000 1.000 1.000 0.528 0.842 0.837 0.759 0. 0.657 0.867 0.789 0.976 0.528 0.765 0.761 0.632 0. 0.608 0.786 0.697 0.915 0.528 Average 0.96 0. 0.73 0.96 0.84 0.63 0.97 0. 0.65 0.96 0.86 0.69 0.96 0. 0.72 Table 16. TPR@1% FPR (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (Full Finetuning). arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.986 0.597 0.997 1. 1.000 1.000 0.007 0.393 0.429 0.430 0.356 0.115 0. 0.373 0.893 0.007 0.051 0.057 0.024 0.084 0.018 0. 0.066 0.497 0.007 0.994 0.997 0.980 0.622 0.993 0. 0.993 1.000 0.004 0.208 0.257 0.257 0.187 0.127 0. 0.202 0.887 0.004 0.024 0.017 0.017 0.034 0.014 0. 0.018 0.184 0.004 0.988 0.996 0.982 0.673 0.986 0. 0.988 1.000 0.010 0.074 0.192 0.124 0.091 0.052 0. 0.099 0.750 0.010 0.011 0.034 0.018 0.017 0.014 0. 0.021 0.255 0.010 1.000 1.000 0.995 0.612 0.994 1. 1.000 1.000 0.011 0.450 0.550 0.314 0.265 0.094 0. 0.286 0.968 0.011 0.084 0.113 0.031 0.055 0.022 0. 0.062 0.366 0.011 1.000 1.000 0.990 0.620 0.996 1. 1.000 1.000 0.011 0.210 0.277 0.130 0.195 0.057 0. 0.161 0.794 0.011 0.094 0.121 0.034 0.101 0.024 0. 0.082 0.600 0."
        },
        {
            "title": "Average",
            "content": "0.95 0.43 0.11 0.95 0.29 0. 0.95 0.18 0.05 0.95 0.43 0. 0.95 0.26 0.15 Table 17. AUC performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (LoRA, deepseek/deepseek-v3.2). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.685 0.682 0.667 0.579 0.634 0.698 0.650 0.842 0. 0.600 0.601 0.591 0.546 0.564 0.605 0.578 0.689 0. 0.553 0.556 0.510 0.521 0.531 0.552 0.537 0.618 0. 0.658 0.663 0.699 0.561 0.657 0.666 0.636 0.903 0. 0.580 0.583 0.609 0.532 0.576 0.587 0.571 0.751 0. 0.525 0.526 0.519 0.508 0.525 0.529 0.529 0.564 0. 0.645 0.667 0.687 0.568 0.624 0.661 0.593 0.916 0. 0.547 0.563 0.576 0.531 0.537 0.558 0.530 0.681 0. 0.512 0.525 0.498 0.515 0.509 0.521 0.511 0.561 0. 0.710 0.724 0.657 0.548 0.628 0.719 0.603 0.894 0. 0.588 0.589 0.577 0.512 0.549 0.590 0.547 0.725 0. 0.533 0.528 0.520 0.490 0.523 0.528 0.524 0.581 0. 0.645 0.645 0.669 0.566 0.626 0.666 0.628 0.857 0. 0.545 0.545 0.577 0.519 0.527 0.556 0.545 0.664 0. 0.522 0.523 0.534 0.511 0.514 0.529 0.529 0.607 0."
        },
        {
            "title": "Average",
            "content": "0.68 0.60 0.55 0.68 0.60 0. 0.67 0.57 0.52 0.69 0.58 0. 0.66 0.56 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 18. AUC performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (Full Finetuning, deepseek/deepseek-v3.2). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0. 1.000 1.000 1.000 1.000 0.498 0.908 0.900 0.867 0. 0.732 0.921 0.876 0.981 0.498 0.757 0.750 0.592 0. 0.597 0.772 0.664 0.906 0.498 1.000 1.000 0.999 0. 1.000 1.000 1.000 1.000 0.510 0.870 0.876 0.842 0. 0.761 0.877 0.833 0.982 0.510 0.641 0.644 0.560 0. 0.569 0.648 0.596 0.698 0.510 0.999 0.999 0.999 0. 0.999 0.999 0.999 1.000 0.498 0.841 0.862 0.798 0. 0.690 0.847 0.758 0.958 0.498 0.664 0.691 0.528 0. 0.561 0.674 0.587 0.771 0.498 1.000 1.000 0.999 0. 0.999 1.000 1.000 1.000 0.524 0.943 0.952 0.860 0. 0.714 0.949 0.818 0.998 0.524 0.736 0.756 0.579 0. 0.585 0.740 0.606 0.855 0.524 1.000 1.000 1.000 0. 1.000 1.000 1.000 1.000 0.528 0.813 0.805 0.732 0. 0.630 0.837 0.753 0.965 0.528 0.721 0.717 0.604 0. 0.583 0.740 0.654 0.879 0.528 Average 0.96 0. 0.70 0.96 0.83 0.61 0.97 0. 0.63 0.96 0.86 0.67 0.96 0. 0.68 Table 19. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. Evaluated on meta-llama/Llama-3.2-3B. (LoRA, deepseek/deepseek-v3.2). arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 0.028 0.031 0.058 0.048 0.018 0. 0.030 0.200 0.007 0.013 0.019 0.035 0.022 0.008 0. 0.017 0.082 0.007 0.006 0.011 0.008 0.011 0.003 0. 0.007 0.013 0.007 0.041 0.051 0.048 0.047 0.057 0. 0.044 0.164 0.004 0.024 0.035 0.031 0.028 0.029 0. 0.024 0.072 0.004 0.016 0.015 0.016 0.018 0.015 0. 0.014 0.019 0.004 0.022 0.039 0.036 0.030 0.024 0. 0.028 0.185 0.010 0.015 0.021 0.023 0.014 0.014 0. 0.013 0.039 0.010 0.012 0.018 0.013 0.010 0.010 0. 0.011 0.014 0.010 0.036 0.036 0.028 0.042 0.032 0. 0.022 0.122 0.011 0.016 0.016 0.016 0.011 0.020 0. 0.012 0.031 0.011 0.008 0.005 0.010 0.010 0.013 0. 0.008 0.014 0.011 0.036 0.037 0.045 0.078 0.039 0. 0.027 0.190 0.011 0.013 0.011 0.022 0.020 0.017 0. 0.013 0.063 0.011 0.010 0.007 0.006 0.018 0.011 0. 0.008 0.053 0."
        },
        {
            "title": "Average",
            "content": "0.06 0.03 0.01 0.06 0.03 0. 0.05 0.02 0.01 0.04 0.02 0. 0.06 0.02 0.02 Table 20. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (Full Finetuning, deepseek/deepseek-v3.2). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.986 0.597 0.997 1.000 1.000 1.000 0. 0.369 0.394 0.413 0.321 0.116 0.421 0.357 0.856 0. 0.034 0.043 0.021 0.080 0.019 0.047 0.044 0.377 0. 0.994 0.997 0.980 0.622 0.993 0.995 0.993 1.000 0. 0.189 0.247 0.237 0.169 0.121 0.214 0.188 0.866 0. 0.022 0.014 0.017 0.026 0.010 0.022 0.015 0.126 0. 0.988 0.996 0.982 0.673 0.986 0.987 0.988 1.000 0. 0.089 0.190 0.150 0.087 0.057 0.081 0.110 0.692 0. 0.009 0.023 0.015 0.010 0.012 0.008 0.018 0.169 0. 1.000 1.000 0.995 0.612 0.994 1.000 1.000 1.000 0. 0.447 0.515 0.321 0.245 0.109 0.471 0.307 0.956 0. 0.091 0.116 0.032 0.057 0.022 0.088 0.067 0.334 0. 1.000 1.000 0.990 0.620 0.996 1.000 1.000 1.000 0. 0.171 0.231 0.120 0.154 0.045 0.225 0.103 0.723 0. 0.056 0.070 0.026 0.086 0.019 0.078 0.042 0.465 0."
        },
        {
            "title": "Average",
            "content": "0.95 0.41 0.08 0.95 0.28 0. 0.95 0.18 0.03 0.95 0.42 0. 0.95 0.22 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 21. AUC performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (LoRA, x-ai/grok-4.1-fast). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.685 0.682 0.667 0. 0.634 0.698 0.650 0.842 0.498 0.601 0.601 0.592 0. 0.566 0.607 0.578 0.693 0.498 0.559 0.561 0.516 0. 0.533 0.558 0.540 0.629 0.498 0.658 0.663 0.699 0. 0.657 0.666 0.636 0.903 0.510 0.581 0.585 0.605 0. 0.576 0.587 0.571 0.741 0.510 0.524 0.525 0.518 0. 0.522 0.529 0.528 0.562 0.510 0.645 0.667 0.687 0. 0.624 0.661 0.593 0.916 0.498 0.548 0.563 0.573 0. 0.540 0.561 0.530 0.688 0.498 0.515 0.527 0.496 0. 0.512 0.524 0.513 0.569 0.498 0.710 0.724 0.657 0. 0.628 0.719 0.603 0.894 0.524 0.593 0.595 0.577 0. 0.553 0.596 0.548 0.745 0.524 0.540 0.538 0.520 0. 0.527 0.536 0.528 0.589 0.524 0.645 0.645 0.669 0. 0.626 0.666 0.628 0.857 0.528 0.549 0.550 0.584 0. 0.534 0.560 0.549 0.673 0.528 0.529 0.528 0.542 0. 0.521 0.536 0.533 0.619 0.528 Average 0.68 0. 0.55 0.68 0.60 0.53 0.67 0. 0.52 0.69 0.59 0.53 0.66 0. 0.54 Table 22. AUC performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (Full Finetuning, x-ai/grok-4.1-fast). arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0.688 1.000 1. 1.000 1.000 0.498 0.922 0.913 0.878 0.647 0.757 0. 0.892 0.986 0.498 0.789 0.783 0.615 0.587 0.617 0. 0.693 0.927 0.498 1.000 1.000 0.999 0.705 1.000 1. 1.000 1.000 0.510 0.887 0.894 0.847 0.637 0.788 0. 0.847 0.981 0.510 0.657 0.664 0.555 0.543 0.581 0. 0.610 0.712 0.510 0.999 0.999 0.999 0.747 0.999 0. 0.999 1.000 0.498 0.858 0.880 0.809 0.635 0.715 0. 0.779 0.975 0.498 0.705 0.735 0.542 0.565 0.586 0. 0.617 0.825 0.498 1.000 1.000 0.999 0.689 0.999 1. 1.000 1.000 0.524 0.957 0.964 0.877 0.623 0.721 0. 0.831 0.999 0.524 0.788 0.819 0.572 0.542 0.593 0. 0.640 0.893 0.524 1.000 1.000 1.000 0.698 1.000 1. 1.000 1.000 0.528 0.843 0.839 0.767 0.606 0.672 0. 0.795 0.975 0.528 0.762 0.759 0.624 0.576 0.615 0. 0.697 0.916 0."
        },
        {
            "title": "Average",
            "content": "0.96 0.87 0.73 0.96 0.85 0. 0.97 0.81 0.66 0.96 0.87 0. 0.96 0.80 0.72 Table 23. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (LoRA, x-ai/grok-4.1-fast). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.028 0.031 0.058 0.048 0.018 0.030 0.030 0.200 0. 0.012 0.016 0.032 0.024 0.009 0.014 0.016 0.066 0. 0.006 0.010 0.007 0.016 0.005 0.006 0.004 0.009 0. 0.041 0.051 0.048 0.047 0.057 0.047 0.044 0.164 0. 0.026 0.031 0.030 0.027 0.027 0.029 0.026 0.069 0. 0.012 0.015 0.015 0.017 0.014 0.014 0.015 0.018 0. 0.022 0.039 0.036 0.030 0.024 0.021 0.028 0.185 0. 0.015 0.020 0.021 0.015 0.015 0.010 0.013 0.031 0. 0.012 0.019 0.014 0.012 0.013 0.009 0.011 0.016 0. 0.036 0.036 0.028 0.042 0.032 0.037 0.022 0.122 0. 0.015 0.015 0.017 0.016 0.019 0.014 0.013 0.037 0. 0.008 0.007 0.007 0.020 0.011 0.007 0.008 0.022 0. 0.036 0.037 0.045 0.078 0.039 0.041 0.027 0.190 0. 0.015 0.016 0.023 0.020 0.020 0.016 0.012 0.072 0. 0.011 0.009 0.008 0.016 0.013 0.012 0.008 0.059 0."
        },
        {
            "title": "Average",
            "content": "0.06 0.02 0.01 0.06 0.03 0. 0.05 0.02 0.01 0.04 0.02 0. 0.06 0.02 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 24. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. Evaluated on meta-llama/Llama-3.2-3B. (Full Finetuning, x-ai/grok-4.1-fast). arxiv wikipedia pile cc hackernews pubmed FT SOFT SAGE SAGE-R FT SOFT SAGE SAGE-R FT SOFT SAGE SAGE-R FT SOFT SAGE SAGE-R FT SOFT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.986 0.597 0.997 1.000 1.000 1.000 0. 0.899 0.903 0.892 0.533 0.890 0.904 0.895 0.901 0.007 0.409 0. 0.430 0.385 0.116 0.470 0.352 0.891 0.007 0.050 0.054 0.021 0. 0.018 0.060 0.060 0.472 0.007 0.994 0.997 0.980 0.622 0. 0.995 0.993 1.000 0.004 0.886 0.894 0.886 0.572 0.890 0.895 0. 0.901 0.004 0.227 0.271 0.272 0.203 0.131 0.244 0.209 0.867 0. 0.024 0.018 0.016 0.037 0.020 0.024 0.019 0.159 0.004 0.988 0. 0.982 0.673 0.986 0.987 0.988 1.000 0.010 0.877 0.897 0.883 0. 0.878 0.880 0.878 0.902 0.010 0.068 0.211 0.120 0.104 0. 0.066 0.097 0.824 0.010 0.013 0.040 0.020 0.024 0.014 0.013 0. 0.323 0.010 1.000 1.000 0.995 0.612 0.994 1.000 1.000 1.000 0. 0.899 0.902 0.896 0.560 0.888 0.903 0.898 0.902 0.011 0.493 0. 0.344 0.301 0.079 0.533 0.299 0.983 0.011 0.111 0.149 0.044 0. 0.024 0.121 0.071 0.454 0.011 1.000 1.000 0.990 0.620 0. 1.000 1.000 1.000 0.011 0.899 0.902 0.895 0.559 0.897 0.903 0. 0.902 0.011 0.212 0.265 0.127 0.208 0.072 0.286 0.174 0.796 0. 0.085 0.109 0.028 0.092 0.024 0.119 0.082 0.606 0.011 Average 0.95 0.85 0.44 0.10 0.95 0. 0.30 0.04 0.95 0.85 0.19 0. 0.95 0.86 0.45 0.13 0.95 0. 0.27 0.14 Table 25. AUC performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (LoRA, google/gemini-2.5-flash). arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Loss\nZlib",
            "content": "Lowercase Min-K% Min-K%++ ReCall CON-ReCall"
        },
        {
            "title": "Ratio",
            "content": "Bag-of-Words 0.685 0.682 0.667 0.579 0.634 0.698 0.650 0. 0.498 0.604 0.605 0.597 0.546 0.565 0.609 0.580 0. 0.498 0.566 0.568 0.522 0.526 0.536 0.566 0.545 0. 0.498 0.658 0.663 0.699 0.561 0.657 0.666 0.636 0. 0.510 0.584 0.589 0.606 0.534 0.581 0.591 0.574 0. 0.510 0.535 0.536 0.526 0.513 0.532 0.539 0.537 0. 0.510 0.645 0.667 0.687 0.568 0.624 0.661 0.593 0. 0.498 0.546 0.561 0.567 0.529 0.533 0.558 0.530 0. 0.498 0.517 0.530 0.504 0.517 0.510 0.526 0.514 0. 0.498 0.710 0.724 0.657 0.548 0.628 0.719 0.603 0. 0.524 0.583 0.583 0.566 0.510 0.545 0.584 0.544 0. 0.524 0.533 0.529 0.517 0.492 0.520 0.530 0.525 0. 0.524 0.645 0.645 0.669 0.566 0.626 0.666 0.628 0. 0.528 0.554 0.554 0.586 0.526 0.534 0.566 0.553 0. 0.528 0.538 0.538 0.550 0.519 0.523 0.545 0.539 0. 0."
        },
        {
            "title": "Average",
            "content": "0.68 0.60 0.56 0.68 0.60 0. 0.67 0.56 0.52 0.69 0.58 0. 0.66 0.57 0.55 Table 26. AUC performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. (Full Finetuning, google/gemini-2.5-flash). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0.688 1.000 1.000 1.000 1.000 0. 0.933 0.924 0.882 0.647 0.752 0.943 0.910 0.991 0. 0.835 0.825 0.645 0.595 0.628 0.850 0.739 0.969 0. 1.000 1.000 0.999 0.705 1.000 1.000 1.000 1.000 0. 0.893 0.899 0.853 0.636 0.777 0.899 0.856 0.988 0. 0.715 0.719 0.589 0.557 0.598 0.721 0.651 0.789 0. 0.999 0.999 0.999 0.747 0.999 0.999 0.999 1.000 0. 0.844 0.869 0.775 0.624 0.683 0.855 0.759 0.968 0. 0.719 0.751 0.552 0.567 0.585 0.729 0.624 0.848 0. 1.000 1.000 0.999 0.689 0.999 1.000 1.000 1.000 0. 0.942 0.950 0.842 0.617 0.699 0.950 0.800 0.994 0. 0.753 0.781 0.578 0.532 0.577 0.761 0.602 0.883 0. 1.000 1.000 1.000 0.698 1.000 1.000 1.000 1.000 0. 0.871 0.866 0.778 0.614 0.670 0.895 0.819 0.989 0. 0.812 0.808 0.668 0.589 0.627 0.833 0.741 0.951 0."
        },
        {
            "title": "Average",
            "content": "0.96 0.87 0.76 0.96 0.85 0. 0.97 0.80 0.67 0.96 0.85 0. 0.96 0.81 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 27. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B. Evaluated on meta-llama/Llama-3.2-3B. (LoRA, google/gemini-2.5-flash). arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.028 0.031 0.058 0. 0.018 0.030 0.030 0.200 0.007 0.013 0.019 0.032 0. 0.011 0.018 0.020 0.084 0.007 0.007 0.010 0.008 0. 0.005 0.008 0.009 0.017 0.007 0.041 0.051 0.048 0. 0.057 0.047 0.044 0.164 0.004 0.027 0.035 0.033 0. 0.032 0.029 0.029 0.079 0.004 0.014 0.019 0.014 0. 0.016 0.018 0.015 0.023 0.004 0.022 0.039 0.036 0. 0.024 0.021 0.028 0.185 0.010 0.014 0.020 0.021 0. 0.015 0.011 0.012 0.032 0.010 0.012 0.019 0.013 0. 0.012 0.010 0.011 0.016 0.010 0.036 0.036 0.028 0. 0.032 0.037 0.022 0.122 0.011 0.017 0.013 0.014 0. 0.021 0.013 0.011 0.029 0.011 0.007 0.004 0.008 0. 0.011 0.007 0.008 0.013 0.011 0.036 0.037 0.045 0. 0.039 0.041 0.027 0.190 0.011 0.014 0.017 0.021 0. 0.017 0.011 0.012 0.082 0.011 0.011 0.011 0.010 0. 0.010 0.011 0.010 0.063 0.011 Average 0.06 0. 0.01 0.06 0.04 0.02 0.05 0. 0.01 0.04 0.02 0.01 0.06 0. 0.02 Table 28. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on meta-llama/Llama-3.2-3B(Grattafiori et al., 2024). (Full Finetuning, google/gemini-2.5-flash (Google, 2025)). arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.986 0.597 0.997 1. 1.000 1.000 0.007 0.400 0.435 0.447 0.361 0.112 0. 0.411 0.933 0.007 0.068 0.075 0.031 0.083 0.018 0. 0.093 0.642 0.007 0.994 0.997 0.980 0.622 0.993 0. 0.993 1.000 0.004 0.209 0.254 0.261 0.190 0.130 0. 0.208 0.929 0.004 0.025 0.019 0.017 0.038 0.013 0. 0.021 0.266 0.004 0.988 0.996 0.982 0.673 0.986 0. 0.988 1.000 0.010 0.064 0.174 0.103 0.083 0.047 0. 0.089 0.733 0.010 0.011 0.038 0.019 0.018 0.017 0. 0.023 0.273 0.010 1.000 1.000 0.995 0.612 0.994 1. 1.000 1.000 0.011 0.409 0.528 0.276 0.250 0.094 0. 0.251 0.966 0.011 0.049 0.074 0.018 0.035 0.020 0. 0.048 0.310 0.011 1.000 1.000 0.990 0.620 0.996 1. 1.000 1.000 0.011 0.246 0.334 0.143 0.223 0.055 0. 0.205 0.864 0.011 0.141 0.185 0.048 0.125 0.028 0. 0.121 0.728 0."
        },
        {
            "title": "Average",
            "content": "0.95 0.44 0.14 0.95 0.30 0. 0.95 0.17 0.05 0.95 0.40 0. 0.95 0.30 0.20 Table 29. Pretrained (PT) membership inference attack performance across datasets and attacks. Each cell reports AUC, with the corresponding TPR@1%FPR shown in parentheses. Evaluated on EleutherAI/pythia-6.9b. Pretrained (PT) arxiv wikipedia pile cc hackernews pubmed Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.531 (0.007) 0.536 (0.007) 0.515 (0.017) 0.518 (0.010) 0.519 (0.003) 0.532 (0.007) 0.530 (0.008) 0.539 (0.006) 0.498 (0.007) 0.526 (0.005) 0.527 (0.010) 0.538 (0.007) 0.517 (0.013) 0.535 (0.009) 0.533 (0.006) 0.531 (0.008) 0.551 (0.006) 0.510 (0.004) 0.498 (0.008) 0.504 (0.011) 0.504 (0.011) 0.503 (0.006) 0.505 (0.012) 0.506 (0.007) 0.502 (0.008) 0.516 (0.010) 0.498 (0.010) 0.525 (0.008) 0.519 (0.008) 0.511 (0.018) 0.491 (0.013) 0.517 (0.011) 0.523 (0.010) 0.520 (0.011) 0.547 (0.015) 0.524 (0.011) 0.501 (0.008) 0.504 (0.004) 0.519 (0.006) 0.503 (0.014) 0.506 (0.010) 0.509 (0.007) 0.516 (0.007) 0.549 (0.011) 0.528 (0.011)"
        },
        {
            "title": "Average",
            "content": "0.53 (0.01) 0.53 (0.01) 0.50 (0.01) 0.52 (0.01) 0.51 (0.01)"
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 30. AUC (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (LoRA) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.673 0.670 0.655 0. 0.626 0.689 0.650 0.787 0.498 0.616 0.616 0.615 0. 0.571 0.626 0.600 0.691 0.498 0.571 0.573 0.536 0. 0.544 0.576 0.560 0.615 0.498 0.671 0.675 0.687 0. 0.684 0.682 0.647 0.832 0.510 0.609 0.611 0.621 0. 0.611 0.618 0.592 0.733 0.510 0.551 0.551 0.549 0. 0.552 0.556 0.545 0.607 0.510 0.645 0.664 0.668 0. 0.631 0.661 0.599 0.856 0.498 0.563 0.575 0.582 0. 0.554 0.575 0.543 0.685 0.498 0.528 0.539 0.515 0. 0.522 0.537 0.519 0.574 0.498 0.731 0.740 0.691 0. 0.636 0.749 0.621 0.921 0.524 0.616 0.617 0.598 0. 0.563 0.624 0.563 0.758 0.524 0.556 0.556 0.527 0. 0.534 0.556 0.534 0.623 0.524 0.657 0.657 0.654 0. 0.637 0.678 0.637 0.861 0.528 0.570 0.571 0.578 0. 0.549 0.583 0.566 0.691 0.528 0.546 0.548 0.538 0. 0.535 0.557 0.548 0.644 0.528 Average 0.67 0. 0.56 0.68 0.62 0.55 0.66 0. 0.53 0.71 0.61 0.55 0.67 0. 0.55 Table 31. TPR@1% FPR (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (LoRA) arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 0.032 0.029 0.052 0.066 0.014 0. 0.040 0.065 0.007 0.021 0.019 0.037 0.028 0.008 0. 0.024 0.034 0.007 0.007 0.008 0.016 0.013 0.003 0. 0.012 0.011 0.007 0.030 0.034 0.026 0.042 0.037 0. 0.030 0.040 0.004 0.021 0.026 0.014 0.030 0.027 0. 0.021 0.023 0.004 0.012 0.013 0.007 0.016 0.011 0. 0.013 0.013 0.004 0.020 0.028 0.026 0.020 0.022 0. 0.019 0.025 0.010 0.011 0.017 0.018 0.010 0.016 0. 0.011 0.013 0.010 0.005 0.010 0.012 0.005 0.009 0. 0.006 0.009 0.010 0.039 0.063 0.070 0.059 0.034 0. 0.029 0.280 0.011 0.021 0.027 0.040 0.041 0.022 0. 0.023 0.073 0.011 0.008 0.009 0.015 0.024 0.014 0. 0.014 0.028 0.011 0.033 0.028 0.019 0.066 0.032 0. 0.020 0.067 0.011 0.017 0.011 0.016 0.032 0.016 0. 0.017 0.029 0.011 0.012 0.009 0.013 0.027 0.014 0. 0.014 0.022 0."
        },
        {
            "title": "Average",
            "content": "0.04 0.02 0.01 0.03 0.02 0. 0.02 0.01 0.01 0.08 0.03 0. 0.04 0.02 0.01 Table 32. AUC (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0.697 1.000 1.000 1.000 1.000 0. 0.908 0.898 0.859 0.645 0.735 0.921 0.890 0.976 0. 0.758 0.750 0.638 0.584 0.627 0.770 0.706 0.869 0. 1.000 1.000 0.998 0.709 1.000 1.000 1.000 1.000 0. 0.852 0.857 0.827 0.631 0.781 0.861 0.823 0.966 0. 0.651 0.652 0.606 0.549 0.599 0.656 0.610 0.730 0. 1.000 1.000 1.000 0.731 1.000 1.000 1.000 1.000 0. 0.826 0.844 0.796 0.617 0.691 0.833 0.761 0.953 0. 0.666 0.688 0.569 0.551 0.575 0.676 0.603 0.775 0. 1.000 1.000 1.000 0.675 1.000 1.000 1.000 1.000 0. 0.914 0.920 0.861 0.609 0.688 0.928 0.815 0.994 0. 0.725 0.740 0.611 0.544 0.589 0.737 0.617 0.863 0. 1.000 1.000 0.999 0.703 1.000 1.000 1.000 1.000 0. 0.827 0.822 0.726 0.606 0.670 0.848 0.778 0.962 0. 0.742 0.741 0.632 0.576 0.619 0.759 0.688 0.892 0."
        },
        {
            "title": "Average",
            "content": "0.96 0.85 0.71 0.96 0.82 0. 0.97 0.79 0.64 0.96 0.84 0. 0.96 0.78 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 33. TPR@1% FPR (Avg: deepseek/deepseek-v3.2, x-ai/grok-4.1-fast, google/gemini-2.5-flash) performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.991 0. 0.998 1.000 1.000 1.000 0.007 0.365 0.371 0.379 0. 0.078 0.429 0.377 0.757 0.007 0.040 0.035 0.029 0. 0.009 0.047 0.057 0.165 0.007 0.995 0.996 0.956 0. 0.996 0.996 0.993 1.000 0.004 0.148 0.176 0.128 0. 0.112 0.160 0.143 0.494 0.004 0.017 0.015 0.004 0. 0.020 0.015 0.015 0.062 0.004 0.995 0.998 0.993 0. 0.995 0.994 0.994 1.000 0.010 0.082 0.157 0.158 0. 0.043 0.069 0.083 0.356 0.010 0.009 0.025 0.019 0. 0.008 0.007 0.014 0.096 0.010 1.000 1.000 1.000 0. 0.999 1.000 1.000 1.000 0.011 0.354 0.473 0.365 0. 0.087 0.425 0.286 0.917 0.011 0.071 0.105 0.060 0. 0.027 0.089 0.057 0.349 0.011 1.000 1.000 0.993 0. 1.000 1.000 1.000 1.000 0.011 0.189 0.182 0.126 0. 0.052 0.222 0.133 0.584 0.011 0.075 0.067 0.051 0. 0.029 0.082 0.059 0.361 0.011 Average 0.95 0. 0.06 0.95 0.19 0.02 0.95 0. 0.02 0.95 0.39 0.10 0.95 0. 0.10 Table 34. AUC performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. deepseek/deepseek-v3.2) (LoRA, arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 0.673 0.670 0.655 0.579 0.626 0. 0.650 0.787 0.498 0.616 0.616 0.615 0.553 0.570 0. 0.600 0.689 0.498 0.566 0.569 0.532 0.527 0.539 0. 0.555 0.605 0.498 0.671 0.675 0.687 0.573 0.684 0. 0.647 0.832 0.510 0.606 0.608 0.621 0.551 0.607 0. 0.591 0.728 0.510 0.547 0.547 0.547 0.525 0.550 0. 0.542 0.601 0.510 0.645 0.664 0.668 0.565 0.631 0. 0.599 0.856 0.498 0.564 0.576 0.586 0.534 0.555 0. 0.544 0.687 0.498 0.526 0.536 0.516 0.515 0.520 0. 0.518 0.567 0.498 0.731 0.740 0.691 0.553 0.636 0. 0.621 0.921 0.524 0.619 0.619 0.601 0.519 0.565 0. 0.564 0.759 0.524 0.554 0.553 0.529 0.497 0.533 0. 0.533 0.621 0.524 0.657 0.657 0.654 0.566 0.637 0. 0.637 0.861 0.528 0.565 0.567 0.571 0.527 0.546 0. 0.562 0.683 0.528 0.539 0.541 0.529 0.515 0.530 0. 0.542 0.632 0."
        },
        {
            "title": "Average",
            "content": "0.67 0.61 0.56 0.68 0.62 0. 0.66 0.58 0.53 0.71 0.61 0. 0.67 0.57 0.55 Table 35. AUC performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning, deepseek/deepseek-v3.2) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0.697 1.000 1.000 1.000 1.000 0. 0.897 0.888 0.850 0.640 0.727 0.910 0.878 0.971 0. 0.724 0.717 0.617 0.573 0.608 0.737 0.677 0.832 0. 1.000 1.000 0.998 0.709 1.000 1.000 1.000 1.000 0. 0.843 0.848 0.824 0.629 0.770 0.852 0.819 0.960 0. 0.629 0.629 0.594 0.546 0.589 0.634 0.594 0.706 0. 1.000 1.000 1.000 0.731 1.000 1.000 1.000 1.000 0. 0.822 0.838 0.799 0.615 0.689 0.827 0.758 0.946 0. 0.640 0.659 0.560 0.542 0.563 0.649 0.583 0.742 0. 1.000 1.000 1.000 0.675 1.000 1.000 1.000 1.000 0. 0.915 0.921 0.869 0.608 0.691 0.927 0.822 0.994 0. 0.704 0.713 0.607 0.536 0.581 0.712 0.606 0.832 0. 1.000 1.000 0.999 0.703 1.000 1.000 1.000 1.000 0. 0.800 0.793 0.707 0.596 0.648 0.821 0.749 0.949 0. 0.700 0.698 0.598 0.561 0.591 0.716 0.651 0.859 0."
        },
        {
            "title": "Average",
            "content": "0.96 0.85 0.69 0.96 0.82 0. 0.97 0.79 0.62 0.96 0.84 0. 0.96 0.76 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 36. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (LoRA, deepseek/deepseek-v3.2) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.032 0.029 0.052 0. 0.014 0.033 0.040 0.065 0.007 0.021 0.020 0.035 0. 0.008 0.022 0.025 0.036 0.007 0.007 0.008 0.015 0. 0.003 0.006 0.012 0.009 0.007 0.030 0.034 0.026 0. 0.037 0.031 0.030 0.040 0.004 0.021 0.027 0.014 0. 0.029 0.020 0.019 0.020 0.004 0.012 0.012 0.007 0. 0.012 0.011 0.012 0.013 0.004 0.020 0.028 0.026 0. 0.022 0.016 0.019 0.025 0.010 0.012 0.018 0.017 0. 0.015 0.008 0.012 0.015 0.010 0.005 0.010 0.014 0. 0.011 0.004 0.005 0.009 0.010 0.039 0.063 0.070 0. 0.034 0.058 0.029 0.280 0.011 0.023 0.025 0.038 0. 0.022 0.026 0.024 0.067 0.011 0.009 0.010 0.016 0. 0.014 0.011 0.015 0.024 0.011 0.033 0.028 0.019 0. 0.032 0.032 0.020 0.067 0.011 0.015 0.010 0.015 0. 0.013 0.009 0.016 0.031 0.011 0.010 0.008 0.012 0. 0.014 0.007 0.012 0.020 0.011 Average 0.04 0. 0.01 0.03 0.02 0.01 0.02 0. 0.01 0.08 0.03 0.02 0.04 0. 0.01 Table 37. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning, deepseek/deepseek-v3.2) arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.991 0.616 0.998 1. 1.000 1.000 0.007 0.348 0.368 0.372 0.292 0.081 0. 0.366 0.740 0.007 0.023 0.024 0.024 0.060 0.006 0. 0.045 0.121 0.007 0.995 0.996 0.956 0.628 0.996 0. 0.993 1.000 0.004 0.144 0.177 0.115 0.133 0.115 0. 0.145 0.440 0.004 0.016 0.013 0.004 0.028 0.020 0. 0.016 0.037 0.004 0.995 0.998 0.993 0.663 0.995 0. 0.994 1.000 0.010 0.099 0.166 0.169 0.078 0.051 0. 0.096 0.304 0.010 0.008 0.016 0.017 0.007 0.007 0. 0.012 0.054 0.010 1.000 1.000 1.000 0.588 0.999 1. 1.000 1.000 0.011 0.373 0.475 0.338 0.259 0.106 0. 0.282 0.921 0.011 0.084 0.102 0.060 0.054 0.027 0. 0.064 0.286 0.011 1.000 1.000 0.993 0.632 1.000 1. 1.000 1.000 0.011 0.157 0.142 0.110 0.160 0.047 0. 0.090 0.476 0.011 0.047 0.033 0.032 0.081 0.022 0. 0.035 0.256 0."
        },
        {
            "title": "Average",
            "content": "0.95 0.37 0.04 0.95 0.18 0. 0.95 0.13 0.02 0.95 0.40 0. 0.95 0.17 0.07 Table 38. AUC performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. x-ai/grok-4.1-fast) (LoRA, arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.673 0.670 0.655 0.579 0.626 0.689 0.650 0. 0.498 0.613 0.613 0.611 0.553 0.572 0.623 0.597 0. 0.498 0.569 0.571 0.533 0.529 0.545 0.574 0.559 0. 0.498 0.671 0.675 0.687 0.573 0.684 0.682 0.647 0. 0.510 0.608 0.610 0.618 0.549 0.613 0.617 0.590 0. 0.510 0.548 0.548 0.547 0.523 0.548 0.553 0.543 0. 0.510 0.645 0.664 0.668 0.565 0.631 0.661 0.599 0. 0.498 0.563 0.575 0.584 0.535 0.556 0.575 0.543 0. 0.498 0.526 0.537 0.512 0.517 0.524 0.535 0.518 0. 0.498 0.731 0.740 0.691 0.553 0.636 0.749 0.621 0. 0.524 0.620 0.622 0.601 0.520 0.565 0.629 0.565 0. 0.524 0.561 0.563 0.527 0.502 0.537 0.563 0.537 0. 0.524 0.657 0.657 0.654 0.566 0.637 0.678 0.637 0. 0.528 0.568 0.569 0.575 0.530 0.549 0.581 0.565 0. 0.528 0.545 0.547 0.535 0.519 0.535 0.556 0.547 0. 0."
        },
        {
            "title": "Average",
            "content": "0.67 0.61 0.56 0.68 0.62 0. 0.66 0.58 0.53 0.71 0.61 0. 0.67 0.58 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 39. AUC performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning, x-ai/grok-4.1-fast) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0. 1.000 1.000 1.000 1.000 0.498 0.908 0.898 0.857 0. 0.746 0.922 0.890 0.975 0.498 0.752 0.745 0.630 0. 0.632 0.764 0.698 0.860 0.498 1.000 1.000 0.998 0. 1.000 1.000 1.000 1.000 0.510 0.854 0.859 0.823 0. 0.791 0.862 0.821 0.965 0.510 0.639 0.642 0.598 0. 0.593 0.646 0.600 0.710 0.510 1.000 1.000 1.000 0. 1.000 1.000 1.000 1.000 0.498 0.839 0.857 0.811 0. 0.709 0.847 0.773 0.962 0.498 0.676 0.701 0.566 0. 0.581 0.686 0.610 0.769 0.498 1.000 1.000 1.000 0. 1.000 1.000 1.000 1.000 0.524 0.927 0.933 0.876 0. 0.701 0.940 0.833 0.997 0.524 0.757 0.776 0.620 0. 0.602 0.770 0.641 0.891 0.524 1.000 1.000 0.999 0. 1.000 1.000 1.000 1.000 0.528 0.826 0.822 0.724 0. 0.679 0.847 0.779 0.958 0.528 0.736 0.735 0.625 0. 0.624 0.753 0.686 0.881 0.528 Average 0.96 0. 0.71 0.96 0.83 0.62 0.97 0. 0.64 0.96 0.85 0.70 0.96 0. 0.70 Table 40. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (LoRA, x-ai/grok-4.1-fast) arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 0.032 0.029 0.052 0.066 0.014 0. 0.040 0.065 0.007 0.021 0.018 0.037 0.026 0.007 0. 0.022 0.033 0.007 0.007 0.008 0.017 0.012 0.003 0. 0.012 0.011 0.007 0.030 0.034 0.026 0.042 0.037 0. 0.030 0.040 0.004 0.021 0.025 0.014 0.029 0.025 0. 0.021 0.023 0.004 0.012 0.013 0.007 0.016 0.011 0. 0.014 0.011 0.004 0.020 0.028 0.026 0.020 0.022 0. 0.019 0.025 0.010 0.011 0.017 0.019 0.009 0.017 0. 0.011 0.013 0.010 0.005 0.010 0.012 0.004 0.009 0. 0.006 0.009 0.010 0.039 0.063 0.070 0.059 0.034 0. 0.029 0.280 0.011 0.020 0.026 0.043 0.051 0.023 0. 0.024 0.085 0.011 0.008 0.007 0.012 0.020 0.011 0. 0.013 0.036 0.011 0.033 0.028 0.019 0.066 0.032 0. 0.020 0.067 0.011 0.019 0.012 0.017 0.025 0.019 0. 0.017 0.027 0.011 0.013 0.009 0.012 0.026 0.014 0. 0.013 0.021 0."
        },
        {
            "title": "Average",
            "content": "0.04 0.02 0.01 0.03 0.02 0. 0.02 0.01 0.01 0.08 0.04 0. 0.04 0.02 0.01 Table 41. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning, x-ai/grok-4.1-fast) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.991 0.616 0.998 1.000 1.000 1.000 0. 0.379 0.379 0.368 0.340 0.076 0.428 0.357 0.745 0. 0.041 0.038 0.027 0.085 0.010 0.046 0.050 0.154 0. 0.995 0.996 0.956 0.628 0.996 0.996 0.993 1.000 0. 0.151 0.173 0.129 0.132 0.115 0.166 0.142 0.533 0. 0.015 0.013 0.005 0.020 0.021 0.013 0.015 0.060 0. 0.995 0.998 0.993 0.663 0.995 0.994 0.994 1.000 0. 0.076 0.177 0.173 0.072 0.041 0.064 0.080 0.455 0. 0.010 0.031 0.017 0.008 0.008 0.008 0.011 0.111 0. 1.000 1.000 1.000 0.588 0.999 1.000 1.000 1.000 0. 0.376 0.506 0.405 0.272 0.079 0.476 0.317 0.954 0. 0.092 0.137 0.061 0.069 0.030 0.122 0.068 0.432 0. 1.000 1.000 0.993 0.632 1.000 1.000 1.000 1.000 0. 0.192 0.190 0.108 0.164 0.051 0.206 0.126 0.611 0. 0.062 0.058 0.049 0.108 0.023 0.070 0.051 0.353 0."
        },
        {
            "title": "Average",
            "content": "0.95 0.38 0.06 0.95 0.19 0. 0.95 0.14 0.03 0.95 0.42 0. 0.95 0.21 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 42. AUC performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. google/gemini-2.5-flash) (LoRA, arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.673 0. 0.655 0.579 0.626 0.689 0.650 0.787 0.498 0.620 0. 0.618 0.555 0.571 0.629 0.603 0.696 0.498 0.578 0. 0.542 0.531 0.547 0.583 0.565 0.629 0.498 0.671 0. 0.687 0.573 0.684 0.682 0.647 0.832 0.510 0.612 0. 0.625 0.553 0.612 0.621 0.595 0.741 0.510 0.558 0. 0.554 0.528 0.558 0.562 0.551 0.622 0.510 0.645 0. 0.668 0.565 0.631 0.661 0.599 0.856 0.498 0.561 0. 0.577 0.533 0.551 0.574 0.542 0.680 0.498 0.531 0. 0.517 0.518 0.523 0.540 0.522 0.587 0.498 0.731 0. 0.691 0.553 0.636 0.749 0.621 0.921 0.524 0.609 0. 0.592 0.516 0.558 0.617 0.559 0.742 0.524 0.552 0. 0.526 0.501 0.533 0.551 0.533 0.616 0.524 0.657 0. 0.654 0.566 0.637 0.678 0.637 0.861 0.528 0.576 0. 0.587 0.530 0.551 0.590 0.571 0.703 0.528 0.554 0. 0.550 0.522 0.539 0.566 0.554 0.664 0.528 Average 0. 0.61 0.57 0.68 0.62 0.56 0. 0.57 0.54 0.71 0.60 0.55 0. 0.59 0.56 Table 43. AUC performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning, google/gemini-2.5-flash) arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.999 0.697 1.000 1. 1.000 1.000 0.498 0.919 0.909 0.869 0.646 0.733 0. 0.902 0.983 0.498 0.797 0.787 0.666 0.596 0.642 0. 0.742 0.916 0.498 1.000 1.000 0.998 0.709 1.000 1. 1.000 1.000 0.510 0.860 0.865 0.833 0.632 0.782 0. 0.830 0.972 0.510 0.684 0.685 0.627 0.556 0.616 0. 0.636 0.775 0.510 1.000 1.000 1.000 0.731 1.000 1. 1.000 1.000 0.498 0.818 0.837 0.779 0.613 0.674 0. 0.751 0.951 0.498 0.683 0.705 0.580 0.558 0.581 0. 0.615 0.815 0.498 1.000 1.000 1.000 0.675 1.000 1. 1.000 1.000 0.524 0.901 0.905 0.837 0.605 0.671 0. 0.791 0.990 0.524 0.715 0.732 0.606 0.545 0.583 0. 0.605 0.865 0.524 1.000 1.000 0.999 0.703 1.000 1. 1.000 1.000 0.528 0.856 0.852 0.748 0.612 0.682 0. 0.806 0.978 0.528 0.791 0.790 0.674 0.589 0.642 0. 0.728 0.936 0."
        },
        {
            "title": "Average",
            "content": "0.96 0.86 0.74 0.96 0.83 0. 0.97 0.78 0.65 0.96 0.83 0. 0.96 0.80 0.74 Table 44. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (LoRA, google/gemini-2.5-flash) arxiv wikipedia pile cc hackernews pubmed FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R FT SAGE SAGE-R Loss Zlib Lowercase Min-K% Min-K%++ ReCall CON-ReCall Ratio Bag-of-Words 0.032 0.029 0.052 0.066 0.014 0.033 0.040 0.065 0. 0.022 0.019 0.038 0.028 0.009 0.021 0.024 0.033 0. 0.008 0.008 0.017 0.014 0.004 0.006 0.013 0.013 0. 0.030 0.034 0.026 0.042 0.037 0.031 0.030 0.040 0. 0.020 0.027 0.013 0.031 0.028 0.020 0.022 0.025 0. 0.013 0.013 0.006 0.017 0.011 0.011 0.012 0.016 0. 0.020 0.028 0.026 0.020 0.022 0.016 0.019 0.025 0. 0.010 0.017 0.019 0.011 0.015 0.007 0.011 0.012 0. 0.006 0.011 0.011 0.006 0.008 0.003 0.006 0.009 0. 0.039 0.063 0.070 0.059 0.034 0.058 0.029 0.280 0. 0.020 0.030 0.038 0.037 0.022 0.023 0.021 0.066 0. 0.008 0.010 0.017 0.029 0.016 0.014 0.015 0.024 0. 0.033 0.028 0.019 0.066 0.032 0.032 0.020 0.067 0. 0.017 0.010 0.017 0.035 0.016 0.009 0.018 0.029 0. 0.012 0.010 0.015 0.031 0.014 0.009 0.016 0.026 0."
        },
        {
            "title": "Average",
            "content": "0.04 0.02 0.01 0.03 0.02 0. 0.02 0.01 0.01 0.08 0.03 0. 0.04 0.02 0."
        },
        {
            "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
            "content": "Table 45. TPR@1% FPR performance of MIAs across datasets and defenses. Evaluated on EleutherAI/pythia-6.9b. (Full Finetuning, google/gemini-2.5-flash) arxiv wikipedia pile cc hackernews pubmed FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R FT"
        },
        {
            "title": "SAGE",
            "content": "SAGE-R"
        },
        {
            "title": "Zlib\nLowercase",
            "content": "Min-K% Min-K%++"
        },
        {
            "title": "ReCall",
            "content": "CON-ReCall Ratio Bag-of-Words 1.000 1.000 0.991 0.616 0.998 1. 1.000 1.000 0.007 0.369 0.367 0.397 0.309 0.077 0. 0.409 0.786 0.007 0.055 0.044 0.037 0.086 0.011 0. 0.076 0.220 0.007 0.995 0.996 0.956 0.628 0.996 0. 0.993 1.000 0.004 0.148 0.179 0.140 0.129 0.107 0. 0.143 0.510 0.004 0.019 0.018 0.004 0.015 0.020 0. 0.015 0.088 0.004 0.995 0.998 0.993 0.663 0.995 0. 0.994 1.000 0.010 0.071 0.128 0.132 0.070 0.038 0. 0.074 0.308 0.010 0.010 0.029 0.022 0.012 0.010 0. 0.019 0.122 0.010 1.000 1.000 1.000 0.588 0.999 1. 1.000 1.000 0.011 0.313 0.439 0.353 0.202 0.076 0. 0.258 0.876 0.011 0.038 0.077 0.060 0.043 0.025 0. 0.039 0.330 0.011 1.000 1.000 0.993 0.632 1.000 1. 1.000 1.000 0.011 0.218 0.214 0.160 0.205 0.058 0. 0.183 0.665 0.011 0.117 0.111 0.072 0.145 0.042 0. 0.090 0.475 0."
        },
        {
            "title": "Average",
            "content": "0.95 0.39 0.07 0.95 0.19 0. 0.95 0.11 0.03 0.95 0.36 0. 0.95 0.25 0."
        }
    ],
    "affiliations": [
        "Centrum Wiskunde & Informatica (CWI), Amsterdam, The Netherlands",
        "Independent Researcher",
        "University of Rhode Island, Kingston, RI, United States",
        "Vrije Universiteit Amsterdam, Amsterdam, The Netherlands"
    ]
}