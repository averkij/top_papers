{
    "paper_title": "LLMalMorph: On The Feasibility of Generating Variant Malware using Large-Language-Models",
    "authors": [
        "Md Ajwad Akil",
        "Adrian Shuai Li",
        "Imtiaz Karim",
        "Arun Iyengar",
        "Ashish Kundu",
        "Vinny Parla",
        "Elisa Bertino"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have transformed software development and automated code generation. Motivated by these advancements, this paper explores the feasibility of LLMs in modifying malware source code to generate variants. We introduce LLMalMorph, a semi-automated framework that leverages semantical and syntactical code comprehension by LLMs to generate new malware variants. LLMalMorph extracts function-level information from the malware source code and employs custom-engineered prompts coupled with strategically defined code transformations to guide the LLM in generating variants without resource-intensive fine-tuning. To evaluate LLMalMorph, we collected 10 diverse Windows malware samples of varying types, complexity and functionality and generated 618 variants. Our thorough experiments demonstrate that it is possible to reduce the detection rates of antivirus engines of these malware variants to some extent while preserving malware functionalities. In addition, despite not optimizing against any Machine Learning (ML)-based malware detectors, several variants also achieved notable attack success rates against an ML-based malware classifier. We also discuss the limitations of current LLM capabilities in generating malware variants from source code and assess where this emerging technology stands in the broader context of malware variant generation."
        },
        {
            "title": "Start",
            "content": "LLMalMorph: On The Feasibility of Generating Variant Malware using Large-Language-Models Md Ajwad Akil, Adrian Shuai Li, Imtiaz Karim, Arun Iyengar, Ashish Kundu, Vinny Parla, Elisa Bertino Purdue University, Cisco Research, Cisco Systems, Inc {makil, li3944, karim7, bertino}@purdue.edu, aki@akiyengar.com, ashkundu@cisco.com, vparla@cisco.com 5 2 0 2 2 1 ] . [ 1 1 1 4 9 0 . 7 0 5 2 : r AbstractLarge Language Models (LLMs) have transformed software development and automated code generation. Motivated by these advancements, this paper explores the feasibility of LLMs in modifying malware source code to generate variants. We introduce LLMalMorph, semi-automated framework that leverages semantical and syntactical code comprehension by LLMs to generate new malware variants. LLMalMorph extracts functionlevel information from the malware source code and employs custom-engineered prompts coupled with strategically defined code transformations to guide the LLM in generating variants without resource-intensive fine-tuning. To evaluate LLMalMorph, we collected 10 diverse Windows malware samples of varying types, complexity and functionality and generated 618 variants. Our thorough experiments demonstrate that it is possible to reduce the detection rates of antivirus engines of these malware variants to some extent while preserving malware functionalities. In addition, despite not optimizing against any Machine Learning (ML)-based malware detectors, several variants also achieved notable attack success rates against an ML-based malware classifier. We also discuss the limitations of current LLM capabilities in generating malware variants from source code and assess where this emerging technology stands in the broader context of malware variant generation. I. INTRODUCTION Malware continues to proliferate in tandem with the rapid expansion of technologies. By 2025, cybercrime damages are projected to reach $10.5 trillion annually [1]. Approximately 190,000 new malware incidents occur every second [2], and ransomware demands are expected to average $2.73 million per attack in 2024, sharp rise from previous years [3]. Despite decades of study and mitigation efforts, these figures underscore malware researchs pressing relevance in todays constantly evolving threat landscape. One of the most transformative AI technologies in modern times is Large Language Models (LLMs), which have demonstrated extraordinary capabilities in Natural Language Processing (NLP), [4][6], code generation [7][12] and software engineering tasks such as code editing and refactoring [13][15]. Given these strengths and advancements, leveraging LLMs for malware source code transformation is natural progression. recent survey [16] of 1,800 security leaders in global industries found that 74% are experiencing significant AI-powered threats, and 60% feel ill-prepared to defend against them. Although current models have significant limitations in generating fully functional malware from text alone, research shows they can produce code fragments that malicious actors could assemble into operational malware [17]. The convergence of advancing LLM capabilities and evolving malware threats paves the way for adversaries to use these models to create new malware and mutate existing codebases into more elusive and destructive variants. Although malware source code is less accessible than binaries, adversaries with access to source code, such as malware authors, users of leaked repositories, or those modifying open-source malware, can still leverage LLMs to generate new, harder-to-detect variants. These models enable attackers to continually refine and expand their arsenals, increasing the persistence and evasiveness of malicious activities at scale. Prior Research. Previous work has proposed various methods for creating malware variants [17][23]. However, these approaches exhibit limitations in at least one of the following aspects (Shown in Table I): (A) Majority of the existing approaches do not leverage LLMs to transform the malwares source code. [18][23]; (B) Most approaches rely on iterative algorithms to generate variants of malware [18][20], [22], [23]; (C) Approaches that use LLMs for variant generation, start directly from prompts having low success-rate [17]. Furthermore, it is unclear whether the generated malware is better at evading the widely used antivirus engines. With this current state of affairs, our work introduces distinct approach compared to existing malware variant generation methods. Unlike most prior research, which predominantly relies on adversarial machine learning-based or search-based approaches, our method uniquely leverages LLMs to operate at the sourcecode level. Basically, starting with malware source code to generate variants with high success rate and minimal manual effort. Additionally, our approach does not require iterative training or search-based optimization, making it fundamentally different from existing malware transformations. Thus, we present new research direction that remains underexplored. Problem. Given the limitations of existing approaches and recent advancement of LLMs, especially in code generation, we aim to answer the following question - Can we harness the generation capabilities of pre-trained LLMs without additional fine-tuning to develop semi-automated, highly effective framework to generate malware variants with preserved semantics capable of evading widely used antivirus engines and Machine Learning Classifiers? Our Approach. In this paper, we give positive answer to the above problem. We design, implement, and evaluate LLMalMorph specialized framework for generating functional variants of Windows malware written in C/C++. We focus solely on Windows malware as it remains the most targeted operating system for malware due to its widespread use in both consumer and business environments [24], [25]. LLMalMorph combines automated code transformation with human oversight to generate malware variants. Leveraging an open-source LLM, the framework applies carefully crafted transformation strategies and prompt engineering to efficiently modify malware components while preserving structural and functional integrity. The human-in-the-loop process handles errors in complex transformations and multi-file malware, allowing debugging and configuration adjustments. This semiautomated approach also allows us to quantify human effort in LLM-based malware variant generation from source code. Experiments and Analysis. We selected 10 malware samples TABLE I: Comparison with previous research Approach Qiao, Yanchen, et al. [18] Tarallo [23] Malware Makeover [20] MalGuise [22] Ming, Jiang, et al. [21] AMVG [19] Botacin et al. [17] LLMalMorph u e M s o r i e . o - r n a t of varying complexity and generated 618 variants using 6 code transformation strategies with an LLM. We evaluated AV detection rates using VirusTotal1 and Hybrid Analysis2, whose engines primarily rely on signature-based and static analysis, and also tested semantic preservation. The Code Optimization strategy consistently achieved lower detection rates across both tools. On average, LLMalMorph reduced detection rates by 31% for simple sample and 10-15% for three more complex samples on VirusTotal, relative to each samples baseline detection rate; Hybrid Analysis showed 8-13% reductions across four samples compared to their respective baselines. In addition to AV tools, we also evaluated LLMalMorph on an ML-based malware classifier and observed high attack success rates for Optimization (up to 89%) and Security (up to 91%) on specific samples. Strategies like Optimization, Security, and Windows API modifications required more manual edits, with Windows and Security demanding higher debugging effort. Notably, over 66% of evasive variants across four samples preserved their semantics, demonstrating LLMalMorphs ability to generate functionally evasive malware. Contributions. To summarize, we have the following contributions: We design and implement LLMalMorph, practical Windows malware variant generation framework using an 1https://www.VirusTotal.com/gui/home 2https://hybrid-analysis.com/ open-source LLM and prompt-based code transformations. We designed human-in-the-loop mechanism in LLMalMorph to address LLM limitations in debugging multi-file malware and project-level configurations. source codes We conducted extensive experiments generating 618 malware variants from 10 samples and evaluated their detection and semantic preservation across VirusTotal and Hybrid Analysis, and attack success rate for an ML Classifier. We compare the effectiveness of different code transformation strategies using code editing workload and discuss the types of mistakes made by the LLM. Open-Sourcing. LLMalMorph framework with all its associated components can be found in Github: LLMalMorph II. BACKGROUND This section describes various preliminaries related to malits detection systems, and Large Language Models ware, (LLM). A. Malware and Detection Methods Malware refers to malicious programs that adversaries or attackers use to gain unauthorized access to digital devices to damage or steal sensitive information without the users knowledge [26]. It is an umbrella term used to describe wide range of threats, including Trojans, backdoors, viruses, ransomware, spyware, and bots [27], targeting multiple operating systems, such as Windows, macOS, Linux, and Android, and various file formats such as Portable Executable (PE), MachO, ELF, APK, and PDF [28]. After compromising system, malware can perform various malicious activities, such as infiltrating networks, encrypting data for ransom, or degrading system performance. Detection engines and tools employ various methods and tools to detect malware. They can be broadly classified into static, dynamic, and hybrid approaches [28], [29]. Static detection analyzes malware without executing it, relying on features such as PE header information, readable strings, and byte sequences [28]. Dynamic detection involves the execution of malware in controlled environments (e.g., sandboxes) to monitor runtime behaviors such as registry modifications, process creation, and network activity [28], [29]. Hybrid detection combines static and dynamic features, using data such as opcodes, API calls to the system, and control flow graphs (CFGs) [28]. In addition, heuristic-based detection analyzes code statically and behavior dynamically using heuristic rules to determine maliciousness [30]. B. LLMs and Prompt Engineering LLMs have transformed the NLP landscape by excelling in tasks such as translation, summarization etc. Built on the transformer architecture [31], LLMs leverage self-attention mechanisms. They are pre-trained on large-scale corpora in self-supervised fashion to develop deep contextual understanding of the corpus. After pre-training, these models are fine-tuned or instruction-tuned to perform specific tasks. LLMs have also demonstrated remarkable capabilities in programming tasks, with specialized models trained on vast amounts of code and natural language instructions [8], [9], [11], [12], [14]. One of the most prominent features of these models is the ability to generate zero-shot code (without explicit examples or references) during inference without taskspecific fine-tuning. It is achieved through prompt engineering, where carefully crafted input prompts guide the model to generate the desired output [32], making them versatile tools for programming activities such as code synthesis and refactoring. III. OVERVIEW In this section, we define our problem formally and state the challenges and approach to solutions to those challenges. A. Problem Formulation 1, 1, ˆf 2, . . . , 2, . . . , ˆf Let be malware program consisting of files, where the i-th file (1 ) contains functions denoted by {f G}. For given transformation strategy applied by language model (LLM ), our aim is to generate malware variant ˆMs, where the i-th file contains the modified functions { ˆf } produced with strategy s, while retaining the unmodified functions {f j+1, . . . , G}. The process first involves extracting the j-th function from the i-th file and constructing prompt psf that includes the transformation strategy s, the extracted function , and relevant contextual information such as global variables and headers. Then we get the transformed function ˆf = LLM (psf ). The modified function ˆf is then merged back into source code file i, resulting in modified file where the functions { ˆf } are modified, and the remaining functions {f G} remain unchanged. Finally, the reconstructed files are compiled to produce the variant malware ˆMs. 1, ˆf j+1, . . . , 2, . . . , ˆf B. Challenges & Solution Outline We now discuss the main challenges and the solution approaches that guided us to design LLMalMorph. (C1) Contextual and Structural Challenges in Editing Malware Source Code. Recent advances in LLM research have greatly improved code generation across multiple languages, thanks to the inclusion of vast open-source codebases in training corpora [8][10], [12]. Aside from generating code, code editing and refactoring using LLMs are gaining attention [13], [14]. key challenge is context limitation: providing the full source code and transformation instructions often exceeds the models input capacity and hinders instruction following, especially for smaller models. Additionally, the functionality in malware code often spans multiple files, further complicating the editing process. This issue becomes more pronounced when dealing with and C++, as they often lead to incorrect code that either does not compile or execute as intended [33]. This is highly relevant for malware as these programs often leverage system-call APIs for registry modifications, performing networking system calls, process modifications, or anti-evasion techniques. In Windows-based malware, these operations depend heavily on Windows API calls in conjunction with C/C++ or C# functionalities. Thus, editing extensive malware source code with LLMs remains significant challenge, given the complexity of native system APIs and the context limitations. (A1) Framework for generating malware variant on functional level. To address challenge C1, LLMalMorph operates through several key stages. It first traverses the Abstract Syntax Tree (AST) of malware source code files to systematically extract function bodies, header information and global variable declarations. The extracted components then serve as inputs to an open-source LLM, where carefully engineered prompts guide the function modification process. Finally, the modified components are reintegrated into the source, producing functional variants of the original malware. This approach ensures precise extraction and modification of malware components while maintaining their structural integrity throughout our transformations without overwhelming the LLM. (C2) Malware Codebase Consistency Preservation Challenges with LLM-based Function Modification. Malware projects typically span multiple files, where modifying one part often requires coordinated changes across other related files. Given the current capabilities of LLMs, editing source codes while maintaining consistency across multi-file codebases can be too error-prone without human oversight as LLMs struggle with multi-file modifications, dependency resolution, and project-level configurations and edits across large code bases [34], [35]. For instance, refactoring single function with specified transformation might require updates in associated header files, restructuring and renaming its usage throughout linking static libraries, modifying compiler directives, or changing the language configuration for the entire project to accommodate LLM-generated code. While simple tasks such as adding header files or renaming within single file can be automated, more complex, multi-step modifications depend heavily on the nature of the LLM-generated changes and the specific malware projects structure, making one-size-fits-all solution infeasible. Although technologies like Copilot3 that use LLMs underneath have improved multi-file handling, still, context limitation is key barrier to plugging open-source LLMs into an entire code base that would reliably refactor interconnected codebases and thus falls short in generalizing across variety of malware projects. These limitations are exacerbated by the LLM hallucinations problem for code generation [36], [37], leading to new complicated problems like using made-up functions during code generation or misusing existing APIs. Thus, debugging LLMs typically involves trial and error, and their current capabilities are insufficient for handling complex error fixing beyond simple syntactical and logical issues. (A2) Incorporation of Human-In-The loop process. To address C2, we opt for partially automated solution for malware the codebase, or adding new headers, 3https://github.com/features/copilot functional variant generation. As discussed in A1, we generate source code with functional transformation in an automated fashion. However, to maintain consistency and correctness, we adopt human-in-the-loop process for complex debugging and configuration changes across multi-file malware projects. IV. DETAILED DESIGN OF LLMalMorph A. LLMalMorph Framework In this section, we detail the architecture of our framework (see Figure 1). LLMalMorph is organized into two main modules. The first module Function Mutator transforms malware source code functions using an LLM with strategically generated prompts. The second module Variant Synthesizer integrates the transformed functions into the source code, compiling the modified project to generate malware variants. This module also incorporates human-in-the-loop process for debugging during compilation. The first module, in turn, consists of three key submodules: 1 Extractor, 2 Prompt Generator, and 3 LLM Based Function Modifier. The second module includes two primary submodules: 4 Merger and the 5 Compilation and Debugging. We now present the formal algorithms underlying the framework, followed by detailed explanation of each module. Algorithm 1, designed for the Function Mutator, specifies how the three submodules, Extractor, Prompt Generator, and LLM-Based Function Modifier, transform functions in malware source code. The algorithm takes the filename as the desired input, transformation strategy s, and the selected LLM . Next, we describe each submodule in detail. the number of functions to modify j, Algorithm 1 Function Transformation Using LLM Require: Filename i, Number of functions to modify j, Transformation 2, . . . , ˆf } 1, ˆf G} extractor(i) strategy s, Language Model LLM 1, Ensure: Set of transformed functions ˆFs = { ˆf 1: Headers, globals, functions {f 2, . . . , 2: Initialize transformed function set: ˆFs 3: for = 1 to do psf 4: Transform function: ˆf 5: Update set: ˆFs ˆFs { ˆf } 6: 7: end for 8: return ˆFs gen_prompt(s, t LLM (psf ) , headers, globals) Extractor. The Extractor submodule (line 1 of Algorithm 1) utilizes the extractor subroutine, which takes in source file and iterates over the parse tree of the source code. From the parse tree, it extracts and stores these two auxiliary information: 1 list of globally declared variables, structures, compiler directives and store them in globals and 2 list of included headers and store them in headers. Such information is critical for successful transformation because it provides essential context about global dependencies that the functions may utilize. Supplying this context to the LLM in the form of prompts ensures the generation of more accurate and syntactically correct code. After this, the subroutine parses the source file to extract all function definitions, producing set {f 1, 2, . . . , G}. Prompt Generator. Lines 3 7 of Algorithm 1 correspond to the Prompt Generator and LLM Transformation submodules. The subroutine gen_prompt in line 4 is invoked with the function , the transformation strategy s, and the extracted headers and globals. It structures the input code and strategy into prompt psf tailored for the LLM. The design is detailed in Section IV-C. Also refer to of the prompt Appendix for the different types of prompts used in the subroutine and Appendix for complete example of constructed prompt and corresponding LLM response. LLM Based Function Modifier. Line 5 of Algorithm 1 provides the designed prompt psf to our selected LLM and obtains the transformed function. We utilized the default inference settings of the LLM during the code generation process. Specifically, temperature=0.8, top-k=40, and the top-p=0.9. We provide detailed description of the code generation process with the LLM in Appendix A-A. Finally, line 6 appends the transformed function ˆf to the output set. Once all selected functions are processed, the algorithm returns the transformed set. We note that this algorithm can be executed multiple times to generate multiple variations of functions from the same source file. However, in this work, we limit our evaluation to single version of the transformed functions for each chosen malware sample. Algorithm 2, implemented in Variant Synthesizer, uses the set of transformed functions produced by Algorithm 1, ˆFs, the malware project, P, and the modified file, i. It generates malware variants incrementally, incorporating manual debugging to ensure successful compilation. Line 1 initializes the result set of malware variants, Ms. This set has the malware variants generated with strategy for file i. Although we show the algorithm for certain file, all modifications from previously processed files are preserved and carried forward when we process subsequent files, ensuring cumulative transformation of the malware codebase. The core functionality of the algorithm is encapsulated in Lines 2-10, where each transformed function is integrated and debugged iteratively. Algorithm 2 Malware Variant Generation Require: Malware project P, Filename i, Set of transformed functions ˆFs = { ˆf 1, ˆf 2, . . . , ˆf } Extract subset of functions: ˆFt { ˆf Generate updated file: ˆi merger(i, ˆFt) Update project: (P {i}) {ˆi} while compile(P) fails do Ensure: Set of compiled malware variants Ms 1: Initialize set: Ms 2: for = 1 to do 3: 4: 5: 6: 7: 8: 9: 10: 11: end for 12: return Ms end while Compile project: ˆMs compile(P) Add compiled malware: Ms Ms { ˆMs} Debug project and resolve errors ˆFs 1 t} Merger. Line 3 first extracts the subset of functions ˆFt, which consists of functions 1 to t. The next line updates file with the set ˆFt using the merger subroutine. It integrates the updated Fig. 1: Overall Architecture of LLMalMorph. The framework is organized into two main modules. Function Mutator extracts functions from the malware source code file and modifies them using an LLM. Variant Synthesizer updates the malware source code with the modified function and compiles the project to generate the variant. functions into the file while keeping the remaining functions unchanged and utilizes various book-kept information during the code generation process by LLM with Algorithm 1. After merging, we obtain the updated file ˆi consisting of (1 . . . t) modified functions. Further details of the merger subroutine are provided in Appendix A-B. Compilation and Debugging. The next step in Algorithm 2 involves placing the updated file ˆi into the malware project P. Lines 69 compile the updated malware project. If the compilation succeeds, the generated malware variant ˆMs is added to the result set Ms. If it fails, manual debugging is done to address errors. The manual debugging was undertaken by researcher doing research in the adversarial malware domain and malware classification, which ensures consistent and technically informed corrections. The debugging process strictly addresses syntactical errors and build and project configuration issues, such as linking external libraries or changing language versions, and restoring placeholder code left incomplete by the LLM. No changes were made to the semantic logic of the LLM-generated code. The code corrections were deliberately constrained with minimal intervention to compile the modified malware source code successfully. Notably, the debugging process focuses on the t-th function, as earlier (1, . . . , 1) LLM-generated functions have already been debugged and corrected, ensuring that errors do not propagate across iterations. Once the debugging is complete, the compiled malware variant executable is added to Ms. This process continues incrementally until all functions are processed and the final set of malware variants is returned. B. Code Transformation Strategies"
        },
        {
            "title": "We present source code transformation strategies used to",
            "content": "manipulate C/C++ malware source code using the LLM. 1. Code Optimization. This strategy optimizes the source code using prompts by removing redundancies, addressing performance bottlenecks, and simplifying code logic without altering its core functionality. It involves using alternative data structures and algorithms or leveraging modern library and language-specific features, such as search functions from C++s algorithm headers. These optimizations may change the codes execution and performance profile, potentially reducing detection rates for static or heuristic-based methods. 2. Code Quality and Reliability. This strategy ensures that the generated code adheres to standard practices with improved error handling and addressing edge cases. The additional error handling prevents runtime issues during execution and adds branching to the code, which makes the malware more reliable. 3. Code Reusability. This strategy focuses on splitting large functions into smaller, modular blocks. These smaller function calls help to obscure the true behavior of malware as they change the execution flow, making it more challenging for detectors that rely on patterns involving control flow execution while achieving the same outcome intended by the malware. 4. Code Security. This strategy addresses potential security vulnerabilities by adhering to secure coding standards. Malware, like ransomware, relies heavily on cryptographic libraries for data encryption and decryption. This approach prompts the LLM to replace these libraries with alternatives, modifying the implementation of sensitive operations while maintaining the malwares core functionality. By obfuscating cryptographic behavior, detection engines may find it more challenging to identify the executable as malware. 5. Code Obfuscation. This strategy enhances malware evasion by making the code harder to analyze and reverseengineer. It involves renaming functions and variables with meaningless names, adding unnecessary control flow structures (e.g., jumps, loops), altering existing control flows, and inserting anti-debugging techniques. It also defines and calls superfluous functions and adds execution paths triggered only under rare conditions. These transformations aim to complicate both static and dynamic analysis while preserving the malwares core functionality. 6. Windows API-Specific Transformation. This strategy uses prompts that identify Windows API calls within malware functions and guide the LLM to replace them with alternative or It may also introduce wrapper functions to obscure direct API usage. Rather than static mappings, we leverage the LLMs generative capabilities to produce diverse API substitutions, increasing variability and avoiding the rigidity and scalability issues of predefined mappings. Although functionality remains intact, the altered API patterns can confuse heuristic-based detection systems, which often rely on common Windows API usage thus making the malware harder to detect. indirect equivalents. C. Prompt Design for LLMalMorph In this section, we describe Algorithm 3 for generating the prompts. We also introduce the constraints the LLM must follow when transforming given function . It operates based on given transformation strategy s, the t-th function , and the headers and globals of file i, as defined in Algorithm 1. The subroutine begins with call to system_prompt, which generates psys. This defines the LLMs role as specialized coding assistant with expertise in systems programming and languages such as C, C++, and C# and ensures that the code transformations are approached with the appropriate context and capabilities. Subsequently, intro_prompt generates pintro by taking the target function the provided function, along name and specifies that with necessary headers and global variables, must be transformed into variant function using the following predefined strategies. Next, the transformation strategy prompt pstrat is generated using strategy_prompt, using s. These steps establish the transformation context and guide the LLM in performing desired modifications. , headers, globals) Algorithm 3 Prompt Construction Subroutine for LLM-based Function Transformation 1: function N_P P T(s, 2: 3: 4: 5: 6: 7: 8: 9: 10: end function psys system_prompt() pintro intro_prompt(f pstrat strategy_prompt(s) ppres preserve_rules_prompt(f paddit additional_constraints(f pcode headers globals puser pintro pstrat ppreserve padditional pcode return psf = psys puser .name) .name) .name) The preservation prompt ppres tries to ensure that the original and transformed functions are semantically equivalent. It explicitly instructs the model not to modify the globally defined or custom elements (variables, objects, constants) to maintain functional consistency and thus avoid syntactical or semantic errors that may occur in the entire codebase. Additionally, paddit imposes strict guidelines to maintain consistent, syntaxcompliant code format and preserve the function signature, directing the model to generate only the modified function and necessary headers within single, language-specific code block for easy parsing and post-processing. This ensures the output is complete, leaving no code blocks unfinished and avoiding regeneration of the original function. After those steps, the prompt for the code is constructed by the composition of the headers, globals, and the function definition of , where the symbol represents string concatenation. This allows us to construct the total user prompt puser by concatenating all the prompts from lines 3 7. Then the final prompt psf is constructed by concatenating psys and puser. This structured approach ensures that the LLM receives unambiguous and complete instructions for the transformation task while maintaining all necessary constraints and requirements. TABLE II: Selected Malware Samples Summary Sample Language LOC # Files # Funcs VT Rate HA Rate Type Exeinfector Fungus Dexter HiddenVNC Predator Prosto-Stealer Conti(Cryptor) Babuk(Cryptor) RedPetya RansomWar C++ C++ C++ C++ C++ C++ C++ C++ 230 2661 4959 4145 7436 8031 1494 1377 1 15 12 10 27 35 22 5 4 46 61 60 102 99 62 15 13 72.009 26. Infector, Virus 73.630 83.020 76.503 76 75 Generic Crimeware POS Trojan HVNC bot 58.797 70. Information Stealer 62.033 72.333 Information Stealer 65.275 79. Ransomware 71.759 83.667 Ransomware 62.500 56. Ransomware 65.728 50.333 Ransomware V. EVALUATION In this section, we conduct comprehensive evaluation to answer the following questions: RQ1 How resilient are the malware variants generated by LLMalMorph against detection by widely-used antivirus engines and ML classifiers, and how does their evasiveness compare to variants generated by recent adversarial malware generation framework? RQ2 - How does the code-edit workload vary across transformation strategies, and what does this reveal about the types of mistakes the LLM made? RQ3 - Do the generated malware variants preserve the semantics and functionality of the original samples? A. Evaluation Setup 1) Selected Samples: Most malware research focuses on executables due to the scarcity of up-to-date malware source code. We examined public databases [38], [39] and found that most available Windows malware source code is 32bit, so we focused our study on 32-bit variants. We selected samples that (1) compile into functioning executables and (2) exhibit malicious behavior detectable by VirusTotal or Hybrid Analysis with an AV detection rate 60%. This yielded ten malware candidate samples of varying complexity and types. RansomWar sample was compiled with GCC, and the rest were compiled with Microsoft Visual Studio 20224 (as .sln files were available). Table II summarizes key details of the selected samples. For the Conti and Babuk ransomware, our analysis focuses on the cryptor component responsible for encryption. See Appendix for details about the samples. 2) Evaluation Metric: We use the given evaluation metrics: Anti-Virus (AV) Detection Rate (R ˆMs). We evaluate the AV detection rate using VirusTotal, which scans samples with multiple AV engines from different vendors. The number of detectors per sample varies based on availability. Let be the set of detectors available, and ˆD be the set of detectors flagging malware variant as malicious. The AV ˆMs for variant ˆMs at the k-th run is defined detection rate = ˆD ˆMs 100, where . denotes the size of both sets. as We perform runs per sample and compute the average ˆMs . We set = 3 in our i=1 detection rate ˆMs = 1 (cid:80)k 4https://visualstudio.microsoft.com/vs/ experiments to account for variability across runs. We also use Hybrid Analysis, which includes static analysis, ML-based, and multi-scan analyses using different engines. Detection performance is presented as percentage averaged over runs for each malware sample and its variants. We use the freetier version of both tools and automate sample uploads, result retrieval, and post-processing via their respective APIs. Strategy Wise ML Classifier Attack Success Rate (ASR). Attack Success Rate (ASR) is widely used metric for evaluating adversarial attacks the proportion of generated malware variants that evade detection by the target three MLbased malware classifiers: Malconv [41], Malgraph [42], and trained ResNet50 malware classifier [43]. Model Details can be found in Appendix E. Let be an original malware sample, and applying our strategy over all modified files ˆF and for transformed functions generates the variants = { ˆM1, ˆM2, . . . , ˆMj}. For given target classifier C, let ˆV : C( ˆM ) = benign} be the subset of variants that successfully evade C. Then the attack success system. We evaluate ASR against s,C = { ˆM [40], which is [20], rate is ASR = 100. where . denotes the size. (cid:12) (cid:12) (cid:12) ˆV (cid:12) s,C (cid:12) (cid:12) (cid:12) (cid:12)V (cid:80)j 2, . . . , ˆf 1, ˆf t=1 Ledit( ˆf Strategy Wise Code Edit Workload (W ). This metric compares strategies based on the total lines of code requiring manual editing to compile LLM-generated code. higher value indicates that more extensive manual intervention was necessary, suggesting that the LLM made more significant mistakes with this strategy. For given malware , let ˆF represent the number of modified files among files. The edit workload for malware and strategy is defined as the total lines of code edited (added, modified, or removed) across all transformed functions { ˆf } in = (cid:80) ˆF the files ˆF , calculated as ) where i=1 Ledit counts lines of edited code of ˆf . Human Effort Quantification Metric (HM ). This metric measures the human effort required to debug and configure transformed functions in malware for each strategy. It quantifies the total man-hours needed to produce successfully compiled PE file. For given malware and code transformation strategy s, the human effort HM is calculated as HM ). Here, the summation represents the total man-hours spent on all transformed functions { ˆf Functionality Preservation Metric (ΦM ). This metric assesses how well the malware semantics are preserved in the variants post-transformation by LLMalMorph. Due to the inherent complexity of executables, there is no exact solution to judge the semantic equivalence between malware and its variant counterpart ˆM [44]. Consequently, evaluation methods such as comparing the API call sequence between the malware and its variant [22] or comparing behaviors between malware and their variants by running through sandboxes [20], [23] are followed in the literature. } in the modified files ˆF for the strategy s. t=1 ManHours( ˆf s = (cid:80) ˆF 2, . . . , ˆf 1, ˆf (cid:80)j i=1 We adopt similar approach and utilize the Longest Common Subsequence (lcs) algorithm to compare API call sequences between and ˆM . The transformed variant must preserve the original API call order, allowing additional calls that do not disrupt this sequence. API call sequences were collected using proprietary sandbox. The normalized LCS is defined as ˆlcs(M, ˆM ) = Length(AP I(M )) , where denominator is the length of API sequence. Scores range from 0 to 1, with 1 indicating identical API sequences. lcs(M, ˆM ) ΦM : Finally, we compute the Functionality Preservation Rate (cid:12) (cid:12){ ˆM ψ ˆM : ˆlcs(M, ˆM ) δ} (cid:12) ψ ˆM ΦM = (1) (cid:12) (cid:12) (cid:12) Here, ψ ˆM (the Total Variant Set) is defined as the set of all malware variants ˆM whose AV detection rate ˆMs is lower than the baseline detection rate of . The numerator represents the size of the subset of ψ ˆM for which semantic equivalence is preserved which we determine by considering normalized lcs score which has value greater than predefined threshold δ and ψ ˆM is the size of the entire Total Variant Set. We choose the value of δ to be 0.96 by analyzing malware variants and the original samples empirically. We chose malware variants at discrete sets of values for different samples and uploaded them to Triage Sandbox5. We analyzed the reports of the variants and the original malware samples to compare behavioral indicators, registry modifications, network calls etc. We observed that in some cases, behavioral drift began below score of 0.96, while in others, functional equivalence was maintained even slightly above it. However, most variants that retained key behaviors scored at or below 0.96. Therefore, we chose δ = 0.96 as an upper bound to ensure that accepted variants preserve high similarity in API sequences and execution behavior. B. Model Selection Although LLMalMorph can utilize any LLM to generate malware variants, we selected Codestral-22B [8] as our primary LLM. Our engineered prompts have many constraints and directions to follow. We observed that the Codestral model could follow these specific instructions to mutate the functions more precisely than other models. Besides, Codestral has balanced set of features for our use-case 22 billion parameters, 12 GB model size, and 32K context windowand its superior performance on long-range repository-level code completion tasks compared to models with higher hardware requirements [4], [9]. C. Implementation Details In LLMalMorph, the Extractor submodule within the Function Mutator is implemented using the Python binding of the Tree-sitter Parser6, leveraging its C-based runtime for efficient parsing. For the LLM, we used Ollama7, which facilitates local LLM execution without external API dependencies and provides Python-based interface. Our experimental setup 5https://tria.ge/ 6https://tree-sitter.github.io/tree-sitter/ 7https://ollama.com/ comprises single RTX 3090 GPU server with 252 GB of RAM and 48 processors, alongside Windows 10 virtual machine configured with VirtualBox8 for malware compilation. The core implementation of LLMalMorph is primarily developed in Python, with some parts, such as lcs-based semantic metric calculations, implemented in C++. D. Evaluation Results and Analysis We prioritized files for modification using Algorithms 1 and 2, sorting them in ascending order by function count. This assumes that adversaries with limited knowledge of the source code would target files with fewer functions to minimize effort and maximize modified files. In case of ties, files were randomly selected. We sequentially modified functions within each file, though this may overlook critical functions essential to malware behavior. Automating the isolation of malicious functions is challenging, as benign-looking functions (e.g., simple thread management) may enable malicious activity. We aim to assess whether this simple sequential approach yields evasive variants without compromising functionality. See Appendix for details on file selection and the criteria for selecting the number of functions to modify per sample. Answer to RQ1. We evaluate the effectiveness of malware variants in evading AV detectors. Figures 2a and 2b show detection rates from VirusTotal and Hybrid Analysis for 10 malware samples. Six code transformation strategies are colorcoded, with markers indicating the modified files. Each point the xrepresents detection rate for specific strategy; axis shows the number of functions modified in increasing order (e.g., 3 for functions 13), and the y-axis plots the AV detection rate ( ˆRMs ). The black dotted line marks each samples baseline rate, and the red dotted line shows the average detection rate across all variants. In addition, we present the ASR by strategies for four samples targeting the Malgraph classifier and briefly discuss the comparison with recent adversarial malware generation framework. VirusTotal. Figure 2a shows that 5/10 samples all malware variant detection rates are below the respective baseline. For Exeinfector, the average variant detection rate of 40.708% is 31.301% lower than the baseline of 72.009%, with detection rates decreasing. The most significant drop occurs after modifying the 4th function, where Reusability, Optimization, and Security strategies fall below 30%, over 42% lower than the baseline. In Fungus (2nd subplot), the average detection rate is 63.167% compared to baseline of 73.630%. Optimization achieves the lowest rate of 56.611% after modifying three functions, including the third function in file mUsb, which manipulates USB drives to create hidden directories and execute files automatically. In the Dexter subplot of Figure 2a, detection rates average 72.211%, which is 10.809% below the baseline of 83.020%. The details for this sample are provided in Appendix D. For HiddenVNC, the average detection rate is 64.664%, 11.84% below the baseline of 76.503%. Optimization and Quality variants show consistently lower rates, while 8https://www.virtualbox.org/ Security and Windows variants exhibit decreasing trend. The Reusability strategy drops notably from 67.593% to 61.081% between the seventh and eighth function modifications. The eighth function was divided into six smaller functions that enumerate visible windows and capture their content. For Predator, the average and baseline rates are nearly identical, with most variants showing similar performance. decreasing trend is observed with Security reaching the lowest detection rate of 49.967% at the 8th function, 8% lower than baseline, followed by Optimization at 54.591%. The details for Prosto are provided in Appendix D. For Conti ransomware, most variants are around the baseline rate of 65.275% with large drops for Reusability and Optimization for the 7th and 5th functions, respectively, which started above the baseline rate and remain below it. declining trend is also observed for Windows strategy and Quality. For Babuk, detection rates show moderate declines across most strategies, with Optimization contributing the most notable early drop. Detailed analysis is provided in Appendix D. We observe declining detection trend across Security and Quality variants for RedPetya. Notably, the Security strategy shows the steepest drop to 46.746% at the 8th function, which is 15.75% decrease from the baseline. This drop is due to the LLMs use of an alternative cryptographic library than the original OpenSSL. The 8th function is hard_reboot, which uses Windows API calls to adjust process privileges and trigger reboot that helps the ransomware regain control on the next boot, critical persistence mechanism. For RansomWar, the average detection rate of 50.251% is 15.478% below the 65.728% baseline, with all variants falling below the baseline. Most variants range between 50-58%, while Optimization drops to 34.5% after the 3rd function modification. The Windows strategy achieves the lowest at 28.651% (37% below baseline), demonstrating strong evasiveness. Overall, the Optimization strategy emerges as the most consistent in reducing malware detection rates, followed by Security and Reusability, while Windows exhibits strong but variable performance across samples. For Optimization, the introduction and restructuring of data structures, along with language-specific features that may alter the control and data flow and thus alter the code patterns and semantics commonly detectable by the AV engines. These specific changes require the addition of new headers and library references, which in turn may create alterations in the compiled binary and thus alter its blueprint for the AV detectors. For Security, using alternative cryptographic libraries may contribute to more significant binary variation, disrupting the AVs pattern-based and heuristic signatures and leading to reduced detection rates compared to the baseline. Hybrid Analysis. In the Exeinfector subplot in Figure 2b, Optimization and Security strategies show decreasing trends after the second function modification. Obfuscation increases detection rates to 41% after modifying the second function, which might be due to introducing known anti-debugging function. Similarly, the Windows strategy shows higher de- (a) VirusTotal AV Detection Rate (%) Fig. 2: Comparison of detection rates for different strategies across VirusTotal and Hybrid Analysis for ten malware samples. (b) Hybrid Analysis AV Detection Rate (%) tection rates after two and four modifications, indicating that alternative API calls generated by the LLM are more detectable. In the fourth plot for HiddenVNC, the Quality strategy achieves the lowest rate of 67.333% after adding error checks to the 10th function. For Security, OpenSSL-based functions added to the 10th function reduce detection rates temporarily, followed by rise. similar case is also observed for the Optimization plot. In the second Fungus subplot, the overall variant average detection rate is 66.636%, 9.364% lower than the 76% baseline, with the Optimization strategy achieving the lowest rates, producing the most evasive variants. For Dexter, the baseline detection rate of 88% decreases to an average of 80.653%. Windows strategy achieves the lowest detection rate after four function modifications, which involve LLM-generated transformations, such as replacing registry modification-based functions and using ZeroMemory() and lstrlenA() for secure memory handling and string length calculation. For the 5th9th subplots, abrupt detection rate spikes arise because Hybrid Analysis sometimes skips AV detection, relying solely on ML and static analysis, which inflates scores (e.g., 100/90) and skews averages. Predator and Prosto samples exhibit minimal changes overall, while Conti shows notable Optimization-specific drops; detailed analyses for all three subplots(5-7) are provided in Appendix D. For Babuk, the Optimization strategy consistently reduces detection rates, reaching its lowest at 74%, around 10% drop from the baseline of 83.667%, trend also observed in Figure 2a. Quality and Obfuscation similarly show downward trend. In RedPetya, Security strategy declines to 45.333% at the 9th function and 46.0% at the 8th, mirroring the trend in Figure 2a, demonstrating the LLMs effectiveness in function transformation. For RansomWar, the variant average of 36.697% is 13.636% lower than the baseline of 50.333%. Security strategy maintains steady 10% rate, while Windows achieves the lowest rate at 6%, 44% decrease from the baseline. These findings mirror the VirusTotal results with Optimization, Security, and Windows contributing most to reducing detection rates. As discussed earlier, Optimization may reshape control and data flows, while Securitys use of alternative cryptographic libraries may introduce new imports and symbols to the modified malware binaries. This may affect not only the signature-based detectors but also the static and ML-based ones used in Hybrid Analysis. Notably for both detectors, detection rate reduction does not correlate with the number of modified functions and may have opposite effects. ML Classifier. For each ML model, we choose its respective 0.1% FPR (False Positive Rate) threshold as the cutoff. For Malconv and ResNet50, none of the original 10 samples were detected as malicious, while Malgraph flagged only Fungus, Dexter, Conti, and Babuk. So we present the results of these four samples with Malgraph. Details about the threshold can be found in Appendix E. The ASR is given in Table III: TABLE III: ASR(%) by strategy. Percentages normalize differing variant counts (Fungus: 9 variants/strategy; Dexter: 12; Conti: 14; Babuk: 11). Sample Optimization Quality Reusability Security Obfuscation Windows Fungus Dexter Conti Babuk 88.889 50.00 71.429 0 16.667 0 72.727 11.111 0 0 0 0 41.667 33.333 90.909 0 0 0 0 0 The first column lists the four samples, followed by the ASR for six transformation strategies. Optimization yields high ASR for the first and third samples, and moderate rate for the second. For Security, high rate is observed for Babuk and moderate rate for Dexter. This supports the observation of the AV detectors. Babuk also shows notable rate under Quality, consistent with its behavior in Hybrid Analysis (Figure 2b). Reusability and Obfuscation showed low success rates for two samples, while Windows failed to evade detection. Despite modifying functions via prompt engineering and carefully chosen transformation without directly optimizing against any ML malware classifier, LLMalMorph showed notable ASR on strategies like Optimization and Security for some samples, which supports the observation found for the reduction of AV detection rates. As previously noted in the context of AV detectors, the high ASR for these strategies may occur due to LLMs use of new libraries, features, and control-flow restructuring, introducing changes that likely contribute to evasion success. Comparative Analysis. Most existing work on adversarial malware generation, including recent frameworks like Malguise [22], focuses on modifying compiled binaries directly to produce evasive variants. Hence, we compare LLMalMorph against Malguise, leading binary-level adversarial malware generation framework. As already discussed in the ML Classifier subsection in Answer to RQ1, only 4/10 samples (Fungus, Dexter, Conti and Babuk) were identified as malicious by the Malgraph classifier, and None of the other classifiers classify any of the samples as malicious. We ran Malguise [22] on these four samples to generate an adversarial variant for each of them with Malgraph as the evasion target. Fungus, Dexter and Babuk successfully bypassed the Malgraph classifier while Conti failed to do so. Nonetheless, we collected all the adversarial variants generated by Malguise (three bypassed and one unpassed one) and ran them through VirusTotal and Hybrid Analysis to record the AV detection Rate metric as discussed in the Evaluation Setup subsection in Evaluation section V-A2. We present the result in Table IV. TABLE IV: Comparison of AV Detection Rate(%) with VirusTotal and Hybrid Analysis between the adversarial variant generated by Malguise and LLMalMorph."
        },
        {
            "title": "Malware Malguise",
            "content": "LLMalMorph Malguise LLMalMorph"
        },
        {
            "title": "Babuk",
            "content": "61.574 78.241 66.667 72.685 63.167 72. 63.667 70.326 69.667 83.333 75.667 66.636 80.653 71.568 80.025 The first column of Table IV is the four malware samples that we used for this comparative analysis. The next two columns represent the detection rate under VirusTotal, where we show both Malguise and LLMalMorph. The last two columns represent the same for Hybrid Analysis. For LLMalMorph, we show the Overall Variant Average AV Detection Rate across all generated variants for each sample ( Represented by the red-dotted line in Figures 2). For VirusTotal, Fungus shows close detection rate compared to Malguise, while others show lower AV detection rate. We observe that the AV detection rate reduction was up to about 6.03% and on average about 3.8% for the three samples other than Fungus. As for Hybrid Analysis columns, we see that all the samples show lower reductions compared to Malguise. For this AV detection engine, we see reduction of up to about 4.1% and on average about 3%."
        },
        {
            "title": "This presents an interesting insight",
            "content": "into the capabilities of source-code-based LLM-driven transformations. Malguise operates at the binary level, modifying compiled executables using semantic NOP insertion and call-based redividing techniques to generate malware variants optimized for bypassing machine learning-based classifiers. This approach does not require compilation and directly patches binaries in place rather than modifying source code. In contrast, our framework transforms malware at the source-code level using LLMs, requiring compilation and debugging to maintain functional correctness. We do not incorporate search-based methods into our work and do not optimize against any target (such as classifier, as in the case of Malguise). Despite these fundamental methodological and abstraction-level differences, LLMalMorphs variants achieved competitive AV detection rates compared to Malguise. Although the reductions in detection rate were marginal, the fact that LLMalMorph performs Fig. 3: Strategy-wise Code Edit Workload for All Samples comparably without explicitly optimizing for evasion demonstrates the practical potential of LLM-guided malware source code transformation in evasive malware variant generation. Answer to RQ2. The Code Editing Workload for each strategy across all samples is illustrated in Figure 3 using radar chart, where each vertex represents the code-editing workload (W ) for specific malware under given strategy s. Similarly, human-effort in man-hours (HM ) are shown in Figure 4. Strategy names are abbreviated for clarity in the charts, with full names detailed in the legends. Workload also accounts for code added back as modifications if the LLM suggested we place back certain lines in function, as it was prompted to generate complete code. Code Edit Workload. In Figure 3 in the Exeinfector radar chart, the Quality strategy has the highest workload at 23 lines, followed by Obfuscation with 9 lines and Security with 7 lines, while Windows and Reusability are below 2. The Fungus chart shows the highest load for Obfuscation at 117, with an increased workload for Windows and Reusability compared to Exeinfector but lower for Optimization and Security. Funguss greater complexity with sophisticated functions likely contributes to higher errors by the LLM, where we had to manually re-add some code to the functions. For Dexter and HiddenVNC, the Optimization strategy has the highest workload, with Dexter at 154 lines and HiddenVNC at 85, despite showing decreasing trend in AV detection rates in Figure 2a. Dexter also has 88 lines for Reusability and Security. Its high Optimization errors are due to an original function being reused after LLMgenerated code caused compilation issues. In HiddenVNC, the Optimization strategy required adding large code segments, leading to the highest workload, followed by Quality at 54 lines, while other strategies remain at or below 22. For the Predator sample, Windows and Security required the most edits at 31 and 37 lines, while other strategies remained under 20. Security required extensive modifications due to the LLMs incorrect use of BCryptDecrypt, requiring us to reuse the original code. In Prosto, Optimization and Security had the highest workloads at 27 and 26 lines, while other strategies remained below 12. For Conti ransomware, we see that Obfuscation and Windows have the highest number of lines of code, at 18 and 20 lines, and others stay below 10. In Windows strategy, we had to add back 20 lines despite explicit instructions for the LLM to generate complete code. In Babuk, Security, Obfuscation, and Windows had relatively higher workloads at 8, 10, and 8 lines, while other strategies required minimal edits. RedPetya closely resembled Prosto with Security, Windows, and Optimization dominating but staying under 20 lines. For RansomWar, Windows had the highest workload at 38 lines, requiring wrapper to support LLM-generated functions and adding back dynamic DLL loading codes for function omitted by the LLM. Overall, Code Optimization, Windows, and Security drive high workloads for most samples and varying loads for other strategies, reflecting that the LLM struggled with different strategies and the varying complexities of the samples. The high workload stems from us reusing original functions, generating incomplete code and improper usage of complex Win32 APIs and alternative cryptographic library calls. Despite high costs, Optimization followed by Security showed the strongest evasiveness across AV and ML detection, highlighting trade-off between success and effort. Man-Hours. In Figure 4, Exeinfector and Fungus show similar patterns, requiring the highest man-hours for the Windows strategy, with Exeinfector at 0.3 hours and Fungus at 1.333 hours. For Exeinfector, Security and Quality require 0.15 and 0.2 hours, Optimization takes 0.13 hours, and others take minimal effort. The high man-hours for Windows in Fungus are due to debugging the mUsb function. Other notable manhours for Fungus are 0.517 hours for Obfuscation, 0.433 hours for Reusability, and 0.317 hours for Optimization. OptimizaFig. 4: Human Effort in Total Man-Hours for All Samples tion, being one of the most effective strategies for reducing detection rates as observed in (Figure 2a, 2b), also required fewer man-hours to generate compilable executables, making it highly effective for creating malware variants in these two samples. Dexter shows near-uniform man-hour distribution across strategies, with Optimization at 0.55 hours, Windows at 0.633 hours and others like Obfuscation, Security, and Reusability between 0.4 - 0.42 hours. HiddenVNC, however, demonstrates greater variability, notably with Security at 0.717 hours, Optimization at 0.667 hours and Windows at 0.45 hours. The elevated man-hours for Security in HiddenVNC are due to the LLMs difficulty integrating OpenSSL into the existing codebase, which reflects the inherent challenge of modifying and incorporating security-related libraries using LLMs. For the Predator subchart, the highest man-hours were in Reusability, Security, and Obfuscation at 0.267, 0.383, and 0.2 hours, respectively. Security required additional debugging for the BCryptDecrypt function. In Prosto, Security demanded the most effort at 0.417 hours, while Optimization, Windows, and Reusability took 0.267, 0.183, and 0.167 hours. The addition of OpenSSL and the LLMs improper handling of its functions contributed to this workload. In Conti ransomware, except for Reusability at 0.23 hours, most strategies required minimal debugging. Babuk showed near-uniform distribution across Optimization, Reusability, Obfuscation, and Windows, each around 0.083 hours. RedPetya had generally low man-hours, except for Security at 0.367 hours, requiring integration of the CryptoPP library used by the LLM. Notably, this strategy also exhibited strong evasiveness in figures 2a and 2b. The final sample mirrors Babuk and Dexter, with Windows and Security at 0.233 hours, and Reusability and Obfuscation at 0.1833 hours. Overall, the Windows strategy consistently demanded high debugging effort across all malware samples due to LLMs struggling with verbose Windows API calls. Also, the Security strategy required significant effort due to the introduction of new libraries and features, as well as increased syntax changes which often led the LLM to make mistakes during the code generation process. TABLE V: ΦM for All Samples With Two AV Detectors (%) Sample VirusTotal Hybrid Analysis Exeinfector 75 Fungus Dexter 31.481 66.667 HiddenVNC 75 Predator Prosto Conti Babuk RedPetya RansomWar 36.667 41. 19.565 30.0 85.714 55.556 72.222 31. 66.667 68.182 50.0 50.0 44.304 37. 88.889 54.902 Answer to RQ3. Table presents the Functionality Preservation Metric (ΦM ) for all ten malware samples evaluated with VirusTotal and Hybrid Analysis calculated with equation 1. From Figure 2a, the first four and the last sample variants are evasive under VirusTotal, as their detection rates are below the individual baseline threshold. In Hybrid Analysis, Fungus, Dexter, and RansomWar variants remain consistently evasive. Exeinfectors ΦM has high rate of 75% on VirusTotal and 72.222% on Hybrid Analysis. Dexter and HiddenVNC both performed well, with Dexter maintaining 66.667% preservation across both detectors, and HiddenVNC at 75% on VirusTotal and around 68% on Hybrid Analysis. Fungus has lower ΦM of approximately 31.5% for both detectors, with only 17 out of 54 variants staying below the detection threshold, preserving their original semantics on both AV detectors. Predator and Prosto Stealer showed moderate preservation rates36.667% and 41.667% on VirusTotal, with both reaching 50% on Hybrid Analysis. In Predator, the LLM modified six functions in Stealing.cpp, while in Prosto, it made extensive edits across multiple files for functions that affect directory searches, file processing, and Telegramrelated operations. Despite debugging to ensure compilation, the LLM-generated code lacked functional preservation. Conti has the lowest ΦM value with only about 20% of evasive variants preserving semantics for VirusTotal. The LLM modified critical functions, including those disabling security hooks, whitelisting processes, and enumerating logical drives. These modifications reduced detection rates but led to lower functionality preservation. For the case of Babuk ransomware, we also see similar rate as that of the Fungus sample for VirusTotal and higher 37.255% for Hybrid Analysis. RedPetya stood out with the highest rates (85.714% and 88.889%), demonstrating that LLMalMorph successfully maintained functionality while achieving evasion, even with complex transformations like Security as seen in Figure 2a, 2b. Both the preservation rate for the final sample is around 55%. These results show that while Optimization effectively reduces detection rates, it struggles with semantic preservation in samples like Fungus, Conti, and Babuk. Conversely, four samples exhibit high ΦM , with Exeinfector, Dexter, and HiddenVNC at or above 66% and RedPetya exceeding 85%, demonstrating LLMalMorphs ability to generate functional yet evasive variants. Notably, our transformations operate solely at the source code level, yet achieve high functionality preservation even in complex samples like Dexter, HiddenVNC and RedPetya, validating the effectiveness of systematic transformations and prompt design in LLMalMorph. some Python samples and benign program with simple transforms, but it is limited to less complex examples. VII. CONCLUSION AND FUTURE WORK In this work, we presented LLMalMorph, framework for generating malware variants by leveraging LLMs with engineered prompts and code transformation strategies. Using 6 strategies, we generated 618 variants and demonstrated that specific transformations reduce AV detection rates and have notable attack success rates on ML classifiers. We also observed that complex malware often requires significant debugging to maintain functionality, highlighting the need for human oversight, careful prompt design, and current LLM limitations in malware source code transformation. While this study showcased the potential of LLMs in generating evasive malware variants, few limitations remain. Our implementation can be extended to other languages by enhancing the Extractor and Merger submodules. We plan to expand toward binary malware transformations with LLMs and improve automation using LLM agents. We also aim to enhance function selection by isolating malware-relevant patterns and develop more robust metric for semantic preservation beyond API sequences in future work. VIII. ACKNOWLEDGMENTS This research was supported by Cisco Research. We sincerely thank Cisco for their funding and valuable guidance throughout the course of this work. Any conclusions, opinions, or recommendations expressed in this work are those of the authors and do not necessarily represent those of the sponsor. VI. RELATED WORKS"
        },
        {
            "title": "REFERENCES",
            "content": "Research on generating malware variants has explored variety of approaches. significant body of work focuses on modifying the malwares binary code either globally or locally while preserving the original behavior by injecting or appending bytes to specific locations without altering its behavior [18], [45][49]. Another approach involves binary diversification techniques to globally alter binary files of malware [20], [50]. Additionally, manipulating API calls by adding irrelevant functions using methods such as greedy algorithms, gradient-based approaches, generative models, and heuristic techniques has been prominent area of study [23], [51][53]. Another approach involves altering the control flow graph by modifying the underlying assembly code or in feature space using some search algorithm or learning-based optimization [22], [29]. Direct perturbation of malware code space, though less explored, includes injecting assembly code to call external DLLs for invoking additional APIs without changing the control flow [54]. The approach by Murali et al. [21] operates on the intermediate representation generated by an LLVM by directly modifying the system call directed graph with strategic transformation and then re-generating malware executables. Choi et al. [19] use an adaptive framework called AMVG to generate malware variants via parsing source code and using genetic algorithm. They show some results on [1] PIA, How to stay safe from the biggest cybersecurity threats of 2025, 2024, [Last Accessed: December 13, 2024]. [Online]. Available: https://www.privateinternetaccess.com/blog/future-cyber-attacks/#:: text=Attacks%20are%20becoming%20more%20frequent,annually% 2C%20according%20to%20Cybersecurity%20Ventures [2] AVG, Malware and virus statistics 2024: The trends you need to know about, 2024, [Last Accessed: December 13, 2024]. [Online]. Available: https://www.avg.com/en/signal/malware-statistics#: :text=Malware-,Malware%20And%20Virus%20Statistics%202024: %20The%20Trends%20You%20Need%20to,protect%20yourself% 20against%20common%20threats [3] Sophos, State of [Last Accessed: December 13, 2024]. [Online]. Available: https://www.sophos.com/en-us/content/ state-of-ransomware ransomware, 2024, [4] A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan et al., The llama 3 herd of models, arXiv preprint arXiv:2407.21783, 2024. [5] A. Kedia, S. C. Chinthakindi, and W. Ryu, Beyond reptile: Metalearned dot-product maximization between gradients for improved single-task regularization, in Findings of the Association for Computational Linguistics: EMNLP 2021, 2021, pp. 407420. [6] A. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. Chaplot, D. de las Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier et al., Mistral 7b (2023), arXiv preprint arXiv:2310.06825, 2023. [7] X. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo, D. Lo, J. Grundy, and H. Wang, Large language models for software engineering: systematic literature review, ACM Transactions on Software Engineering and Methodology, 2023. [8] M. AI, Codestral, 2024. [9] B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, R. Sauvestre, T. Remez et al., Code llama: Open foundation models for code, arXiv preprint arXiv:2308.12950, 2023. [10] Q. Zhu, D. Guo, Z. Shao, D. Yang, P. Wang, R. Xu, Y. Wu, Y. Li, H. Gao, S. Ma et al., Deepseek-coder-v2: Breaking the barrier of closed-source models in code intelligence, arXiv preprint arXiv:2406.11931, 2024. [11] A. Lozhkov, R. Li, L. B. Allal, F. Cassano, J. Lamy-Poirier, N. Tazi, A. Tang, D. Pykhtar, J. Liu, Y. Wei et al., Starcoder 2 and the stack v2: The next generation, arXiv preprint arXiv:2402.19173, 2024. [12] S. Huang, T. Cheng, J. K. Liu, J. Hao, L. Song, Y. Xu, J. Yang, J. Liu, C. Zhang, L. Chai et al., Opencoder: The open cookbook for top-tier code large language models, arXiv preprint arXiv:2411.04905, 2024. [13] F. Cassano, L. Li, A. Sethi, N. Shinn, A. Brennan-Jones, A. Lozhkov, C. J. Anderson, and A. Guha, Can it edit? evaluating the ability of large language models to follow code editing instructions, in Conference on Language Modeling (COLM), 2024. [14] J. Guo, Z. Li, X. Liu, K. Ma, T. Zheng, Z. Yu, D. Pan, Y. LI, R. Liu, Y. Wang, S. Guo, X. Qu, X. Yue, G. Zhang, W. Chen, and J. Fu, Codeeditorbench: Evaluating code editing capability of large language models, 2024. [16] Darktrace, [15] J. Cordeiro, S. Noei, and Y. Zou, An empirical study on the code refactoring capability of large language models, arXiv preprint arXiv:2411.02320, 2024. of Accessed: December 2024]. //darktrace.com/resources/state-of-ai-cyber-security-2024?success=1 [17] M. Botacin, Gpthreats-3: Is automatic malware generation threat? IEEE, 2023, 2024, 2024, [Online]. Available: in 2023 IEEE Security and Privacy Workshops (SPW). pp. 238254. [Last https: security ai 13, State cyber [18] Y. Qiao, W. Zhang, Z. Tian, L. T. Yang, Y. Liu, and M. Alazab, Adversarial malware sample generation method based on the prototype of deep learning detector, Computers & Security, vol. 119, p. 102762, 2022. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S [19] J. Choi, D. Shin, H. Kim, J. Seotis, and J. B. Hong, Amvg: Adaptive malware variant generation framework using machine learning, in 2019 IEEE 24th Pacific Rim International Symposium on Dependable Computing (PRDC), 2019, pp. 24624 609. [20] K. Lucas, M. Sharif, L. Bauer, M. K. Reiter, and S. Shintre, Malware makeover: Breaking ml-based static analysis by modifying executable bytes, in Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security, 2021, pp. 744758. [21] J. Ming, Z. Xin, P. Lan, D. Wu, P. Liu, and B. Mao, Impeding behavior-based malware analysis via replacement attacks to malware specifications, Journal of Computer Virology and Hacking Techniques, vol. 13, pp. 193207, 2017. [22] X. Ling, Z. Wu, B. Wang, W. Deng, J. Wu, S. Ji, T. Luo, and Y. Wu, wolf in sheeps clothing: Practical black-box adversarial attacks for evading learning-based windows malware detection in the wild, in 33rd USENIX Security Symposium (USENIX Security 24). USENIX Association, 2024, pp. 73937410. [23] G. Digregorio, S. Maccarrone, M. DOnghia, L. Gallo, M. Carminati, M. Polino, and S. Zanero, Tarallo: Evading behavioral malware detectors in the problem space, in Detection of Intrusions and Malware, and Vulnerability Assessment, F. Maggi, M. Egele, M. Payer, and Cham: Springer Nature Switzerland, 2024, pp. M. Carminati, Eds. 128149. [24] Avg, Desktop operating system market share worldwide - november 2024, 2024, [Last Accessed: November 30, 2024]. [Online]. Available: https://www.avg.com/en/signal/malware-statistics# [25] Statscounter, Desktop operating system market share worldwide [Last Accessed: November 30, 2024]. - november 2024, 2024, [Online]. Available: https://gs.statcounter.com/os-market-share/desktop/ worldwide#daily-20240901-20241020-bar [26] Z. Chen, M. Roussopoulos, Z. Liang, Y. Zhang, Z. Chen, and A. Delis, Malware characteristics and threats on the internet ecosystem, Journal of Systems and Software, vol. 85, no. 7, pp. 16501672, 2012, [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0164121212000441 software Ecosystems. [27] Y. Ye, T. Li, D. Adjeroh, and S. S. Iyengar, survey on malware detection using data mining techniques, ACM Comput. Surv., vol. 50, no. 3, Jun. 2017. [Online]. Available: https://doi.org/10.1145/3073559 [28] X. Ling, L. Wu, J. Zhang, Z. Qu, W. Deng, X. Chen, Y. Qian, C. Wu, S. Ji, T. Luo et al., Adversarial attacks against windows pe malware detection: survey of the state-of-the-art, Computers & Security, vol. 128, p. 103134, 2023. [29] L. Zhang, P. Liu, Y.-H. Choi, and P. Chen, Semantics-preserving reinforcement learning attack against graph neural networks for malware detection, IEEE Transactions on Dependable and Secure Computing, vol. 20, no. 2, pp. 13901402, 2022. [30] J. Geng, J. Wang, Z. Fang, Y. Zhou, D. Wu, and W. Ge, survey of for pe malware: Transformation, concealment, and attack, Computers & Security, vol. 137, p. 103595, 2024. [Online]. Available: https://www.sciencedirect. com/science/article/pii/S0167404823005059 strategy-driven evasion methods [31] A. Vaswani, Attention is all you need, Advances in Neural Information Processing Systems, 2017. [32] T. B. Brown, Language models are few-shot learners, arXiv preprint arXiv:2005.14165, 2020. [33] A. Buscemi, comparative study of code generation using chatgpt 3.5 across 10 programming languages, arXiv preprint arXiv:2308.04477, 2023. [34] J. Jiang, F. Wang, J. Shen, S. Kim, and S. Kim, survey on large language models for code generation, arXiv preprint arXiv:2406.00515, 2024. [35] C. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. R. Narasimhan, SWE-bench: Can language models resolve realworld github issues? in The Twelfth International Conference on Learning Representations, 2024. [Online]. Available: https: //openreview.net/forum?id=VTF8yNQM66 [36] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang, A. Madotto, and P. Fung, Survey of hallucination in natural language generation, ACM Computing Surveys, vol. 55, no. 12, pp. 138, 2023. [37] F. Liu, Y. Liu, L. Shi, H. Huang, R. Wang, Z. Yang, and L. Zhang, Exploring and evaluating hallucinations in llm-powered code generation, arXiv preprint arXiv:2404.00971, 2024. [38] Cryptwareapps, Malware-database, 2024, [Last Accessed: May https://github.com/cryptwareapps/ 2024]. 27, Malware-Database [Online]. Available: [39] Vxunderground, Malwaresourcecode, 2024, [Last Accessed: May [Online]. Available: https://github.com/vxunderground/ 27, 2024]. MalwareSourceCode [40] X. Ling, S. Ji, J. Zou, J. Wang, C. Wu, B. Li, and T. Wang, Deepsec: uniform platform for security analysis of deep learning model, in 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019, pp. 673690. [41] E. Raff, J. Barker, J. Sylvester, R. Brandon, B. Catanzaro, and C. Nicholas, Malware detection by eating whole exe, arXiv preprint arXiv:1710.09435, 2017. [42] X. Ling, L. Wu, W. Deng, Z. Qu, J. Zhang, S. Zhang, T. Ma, B. Wang, C. Wu, and S. Ji, Malgraph: Hierarchical graph neural networks for robust windows malware detection, in IEEE INFOCOM 2022-IEEE Conference on Computer Communications. IEEE, 2022, pp. 1998 2007. [43] A. S. Li, A. Iyengar, A. Kundu, and E. Bertino, Revisiting concept drift in windows malware detection: Adaptation to real drifted malware with minimal samples. Network and Distributed System Security (NDSS) Symposium, 2025. [44] M. Apel, C. Bockermann, and M. Meier, Measuring similarity of malware behavior, in 2009 IEEE 34th Conference on Local Computer Networks, 2009, pp. 891898. [45] M. Ebrahimi, N. Zhang, J. L. Hu, M. T. Raza, and H. Chen, Binary black-box evasion attacks against deep learning-based static malware language model, CoRR, vol. detectors with adversarial byte-level abs/2012.07994, 2020. [Online]. Available: https://arxiv.org/abs/2012. 07994 [46] F. Kreuk, A. Barak, S. Aviv-Reuven, M. Baruch, B. Pinkas, and J. Keshet, Deceiving end-to-end deep learning malware detectors using adversarial examples, arXiv preprint arXiv:1802.04528, 2018. [47] J. Yuan, S. Zhou, L. Lin, F. Wang, and J. Cui, Black-box adversarial attacks against deep learning based malware binaries detection with gan, in European Conference on Artificial Intelligence, 2020. [Online]. Available: https://api.semanticscholar.org/CorpusID:221714626 [48] B. Kolosnjaji, A. Demontis, B. Biggio, D. Maiorca, G. Giacinto, C. Eckert, and F. Roli, Adversarial malware binaries: Evading deep learning for malware detection in executables, in 2018 26th European signal processing conference (EUSIPCO). IEEE, 2018, pp. 533537. [49] O. Suciu, S. E. Coull, and J. Johns, Exploring Adversarial Examples in Malware Detection , in 2019 IEEE Security and Privacy Workshops (SPW). Los Alamitos, CA, USA: IEEE Computer Society, May 2019, pp. 814. [Online]. Available: https://doi.ieeecomputersociety.org/10. 1109/SPW.2019.00015 [50] K. Lucas, S. Pai, W. Lin, L. Bauer, M. K. Reiter, and M. Sharif, Adversarial training for raw-binary malware classifiers, in Proceedings of Berkeley, CA, USA: USENIX Association, Aug. 2023. the 32nd USENIX Security Symposium. [51] W. Hu and Y. Tan, Generating adversarial malware examples for blackbox attacks based on gan (2017), arXiv preprint arXiv:1702.05983, 2017. [52] M. Kawai, K. Ota, and M. Dong, Improved malgan: Avoiding malware detector by leaning cleanware features, in 2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), 2019, pp. 040045. [53] S. Verwer, A. Nadeem, C. Hammerschmidt, L. Bliek, A. Al-Dujaili, and U.-M. OReilly, The robust malware detection challenge and greedy random accelerated multi-bit search, in Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security, ser. AISec20. New York, NY, USA: Association for Computing Machinery, 2020, p. 6170. [Online]. Available: https://doi.org/10.1145/3411508.3421374 [54] F. Lu, Z. Cai, Z. Lin, Y. Bao, and M. Tang, Research on the construction of malware variant datasets and their detection method, Applied Sciences, vol. 12, no. 15, 2022. [Online]. Available: https://www.mdpi.com/2076-3417/12/15/7546 [55] Wikipedia contributors, Dexter (malware), 2024, [Last Accessed: Nov 27, 2024]. [Online]. Available: https://en.wikipedia.org/wiki/Dexter (malware) [56] MalwareBytesLab, Point of sale (pos), 2024, [Last Accessed: Nov 27, 2024]. [Online]. Available: https://www.malwarebytes.com/blog/threats/ point-of-sale-pos [57] , System infected: Trojan.tinukebot activity 3, 2024, [Last Accessed: Nov 27, 2024]. [Online]. Available: https://www.broadcom. com/support/security-center/attacksignatures/detail?asid=31467 [58] fortinet, Predator the thief: New routes of delivery, 2019, [Last Accessed: March 11, 2025]. [Online]. Available: https://www.fortinet. com/blog/threat-research/predator-the-thief-new-routes-delivery [59] , Predator trojan, 2019, [Last Accessed: March 11, 2025]. [Online]. Available: https://digital.nhs.uk/cyber-alerts/2019/cc-2970 [60] 2-spyware, Prostostealer (free guide) - removal instructions, 2020, [Last Accessed: March 11, 2025]. [Online]. Available: https://www. 2-spyware.com/remove-prostostealer.html [61] wikipedia, Conti 11, 2025]. (ransomware) (ransomware), 2019, [Last Accessed: March [Online]. Available: https://en.wikipedia.org/wiki/Conti [62] mcafee, Babuk ransomware, 2019, [Last Accessed: March 11, 2025]. [Online]. Available: https://www.mcafee.com/blogs/other-blogs/ mcafee-labs/babuk-ransomware/ [63] fraunhofer, Babuk, 2021, [Last Accessed: March 11, 2025]. [Online]. Available: https://malpedia.caad.fkie.fraunhofer.de/details/win.babuk [64] wikipedia, Petya (malware family), 2016, [Last Accessed: March 11, 2025]. (malware family) [Online]. Available: https://en.wikipedia.org/wiki/Petya [65] malware bytes, Petya (malware family), 2016, [Last Accessed: March [Online]. Available: https://www.malwarebytes.com/blog/ 11, 2025]. news/2016/07/third-time-unlucky-improved-petya-is-out [66] K. He, X. Zhang, S. Ren, and J. Sun, Deep residual learning for image recognition, in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770778."
        },
        {
            "title": "APPENDIX A\nDETAILS FOR DIFFERENT SUBROUTINES",
            "content": "A. Details about LLM based code generation As outlined in Algorithm 1, we pass in the prompt along with the function and relevant information to the LLM for generating the modified code. The LLM processes the prompt and produces the response, which we parse to extract the generated code. While generating code, we encountered two key challenging cases: The LLM occasionally failed to generate code in the desired format. The LLM sometimes describes the mechanism of the given function instead of generating any code. the model either provided detailed In the second case, explanation of the input function or identified the function as potentially malicious based on the provided context and generated an analysis of the given code. To address those challenges, we implemented retry mechanism. When either of the cases occurred, the LLM was prompted up to five times with different random seeds. If the LLM still failed to generate usable code, we reverted to the original function and proceeded to the next step of parsing the code. Since we prompt the model to generate code in specific format, we can parse the code from the generated response, save the generated code, and book-keep helpful information for our metric calculation, such as lines of code generated, time required to generate the code, paths of the generated code etc. We utilize this information for the merging phase later in Algorithm 2. B. Details about merger subroutine The subroutine carefully tracks which functions require updates and which remain unchanged, maintaining clear distinction between the two throughout the process. It retains the original header declarations and global variables from the source file to preserve consistency across the project. This approach prevents potential disruptions in dependencies that might arise within the file itself or extend to other files. Moreover, we instruct the LLM to avoid declaring any global variables and to rely solely on creating and using variables local to functions. This ensures modularity and prevents unintended side effects. In cases where transformed function is divided into sub-functions, the merger subroutine methodically defines their prototypes, places these sub-functions at the beginning of the file, and incorporates the modified original function that now calls these sub-functions. By adhering to these guidelines, the merger subroutine ensures that the integration of transformed functions is robust and structured and minimizes the risk of introducing inconsistencies in the codebase."
        },
        {
            "title": "APPENDIX B\nDETAILED MALWARE DESCRIPTIONS",
            "content": "We provide detailed description of each malware sample we selected to conduct experiments. We also ran all the samples through Triage Sandbox to understand their behavior from the sandbox reports. For two samples, the sandbox did not provide useful information, but we added description of the rest where we obtained helpful information from the sandbox. Exeinfector. Exeinfector, categorized as an infector in the associated GitHub repository [38] and VirusTotal tags it with behaviors such as persistence, long sleep, anti-debugging, and user input detection. The triage sandbox report shows malicious activities, including adding persistent run key, modifying the registry, dropping files in the system32 directory, and performing system language discovery. Fungus. Fungus, categorized as generic crimeware in the associated GitHub repository [38], is complex multi-file C++ malware. VirusTotal identifies associates it with family labels such as ircbot and autorun7. It features anti-sandbox techniques, USB-based propagation, server communication, firewall evasion, and keylogging capabilities. The triage report indicates activities such as setting up autostart, loading DLLs, executing dropped files, modifying the registry, performing system language and location discovery, and suspicious use of Windows API calls. Dexter. Dexter is Point-of-Sale (POS) Trojan identified as malware targeting POS machines running Microsoft Windows [55]. Discovered in 2012, it is known for stealing credit and debit card information from POS machines, sending the collected data to predetermined server, and exhibiting botlike behavior [56]. VirusTotal categorizes Dexter as Trojan, ransomware, and downloader, with family labels such as poxters and dexter. The triage report indicates it deletes itself, crashes, adds run key for persistence via registry modifications, performs system language discovery, and uses suspicious Windows API functions like AdjustPrivilegeToken, WriteProcessMemory, and EnumerateProcess. HiddenVNC Bot. HiddenVNC, developed in 2021 according to its source code readme file, is multi-file complex C++ malware. VirusTotal categorizes it as Trojan and banker, associating it with family labels such as tinukebot, tinynuke, and tinuke, suggesting it may be an implementation of the Tinynuke Trojan Bot known for opening backdoors, stealing information, and downloading malicious files [57]. The readme describes it as Hidden Virtual Network Computing (HVNC) tool that creates hidden desktop, allowing attackers to control target machines without user awareness. Its features include controlling multiple machines, launching applications (e.g., browsers, PowerShell) and executing remote commands on the hidden desktop. It generates two executables; we use the Client.exe with VirusTotal detection rate of 76.503% as it is more malicious than the Server.exe (15.277%). Predator. Predator, also known as Predator the Thief, was first observed in mid 2018 [58]. This sample is complex C++ information stealer trojan that steals wide range of data from its infected hosts, such as system info, stored browser passwords, cookies, form data, and even cryptocurrency wallet addresses [58]. It can also capture webcam photos, log keystrokes, extract credentials from applications (e.g. VPN, FTP, gaming clients), and collect clipboard and cryptocurrency wallet files [59]. VirusTotal categorizes this as trojan and associates it with family labels such as stealer, adwarex, and fragtor. The triage sandbox report shows us that it reads data files stored by FTP clients, reads user/profile data of web browsers, steals credentials from unsecured files, accesses cryptocurrency wallets and performs possible credential harvesting. Prosto. Prosto, also known as ProstoStealer is also an information stealer trojan, but much larger and more complex than the Predator sample and is written in C++. It exploits the victim machine to steal valuable and useful information like logins, credentials, passwords and direct files. All the details are stored in server controlled by adversaries for later use in scams and fraudulent activities [60]. VirusTotal categorizes this sample as trojan, virus, and spyware and labels it with family labels such as fragtor and convagent. The triage sandbox report of this sample tells us it checks computer location settings, reads user data of web browsers, modifies Internet Explorer settings and also has suspicious use FindShellTrayWindow, SetWindowsHookEx, of WriteProcessMemory methods etc. Conti. Conti Ransomware emerged in late 2019 [61]. This is vastly complex malware with different moving parts, with over 8000 lines of code written in C++. For our experiments, we utilize the cryptor executable for this sample. It employs double extortion tactics, encrypting files while stealing data is known for to pressure victims into paying ransom. It its fast encryption speed and targeting critical sectors like healthcare [61]. VirusTotal categorizes the executable as trojan and ransomware and associates it with family labels such as conti and adwarex. Babuk. Babuk, also known as Babyk, is sophisticated ransomware that was discovered in early 2021 [62] targets several platforms such as Windows, ARM for Linux, and VMware ESXI environments and uses an Elliptic Curve Algorithm (Montgomery Algorithm) to build the encryption keys [63]. Written in C++ and around 4000 lines of code, this highly complex ransomware targets sectors such as healthcare, plastic, transportation, electronics, and agricultural sectors in multiple countries and areas [62]. We used the encryption module of this ransomware for our experiments and used the produced executable file in .bin format. VirusTotal categorizes this as ransomware and trojan and labels it with family labels such as babuk, babyk and epack. The triage reports show us that it is babuk locker and belongs to babuk family, deletes shadow copies of itself, renames multiple files with the added filename extension, enumerates connected drives and physical storage devices, interacts with shadow copies and also has various suspicious Windows API usage. RedPetya Ransomware. RedPetya belongs to the Petya family of encrypting malware first discovered in 2016 [64]. This uses bootlocker style encryption which upon infecting the victim overwrites the systems master boot record and forces reboot and instead of Windows loading fake screen is shown while the malware covertly encrypts the NTFS master file table on the disk with an encryption algorithm [65]. We used an open source version of the source code9 that is written in C++ with about 1500 lines of code that uses OpenSSL for encryption and is complete rewrite of the RedPetya malware. VirusTotal categorizes this sample as trojan and ransomware, and gives family labels such as petya, heur3, and diskcoder. The triage report also shows that it is persistent, bootkit, and writes to the master boot record. It also shows suspicious use of Windows API such as EnumeratesProcesses, AdjustPrivilegeToken. 9https://github.com/FirstBlood12/RedPetyaOpenSSL RansomWar. This sample is relatively simpler ransomware written in with 1377 lines of code that uses the blowfish encryption algorithm to encrypt files and also has an emailing mechanism built into the code. VirusTotal categorizes this as trojan, ransomware, and gives family labels such as barys, ransomware. From the triage sandbox, we learned that it enumerates connected drives and drops files in the System32 directory. APPENDIX FILES AND NUMBER OF MALWARE FUNCTION SELECTION FOR LLM MODIFICATION. This section describes our approach to selecting the number of functions from each malware sample for modification. While Table II provides an overview of the number of functions present in each malware sample, our selection process involved careful filtering to ensure meaningful modifications. We excluded files that were part of external libraries, such as cryptographic libraries and header files, focusing only on files containing custom malware code and only considered modifying global functions in sequential manner following Algorithm 1. Given the varying number of functions across different malware samples, we adopted systematic strategy: for samples with fewer functions, we modified larger proportion, while for those with more significant number of functions, we modified smaller percentage. This approach ensured balance between sufficient modification coverage and manageable manual debugging efforts required by LLMalMorph. The selection criteria are outlined as follows: TABLE VI: Function Selection Criteria for Modification Number of Functions < 10 10 20 20 40 40 70 > 70 Percentage Modified 100% 60% 30% 20% 15% Applying this methodology, we selected and modified functions as follows: TABLE VII: Function Selection for Each Malware Sample Malware Sample Total Selected Functions Modified Functions Percentage Modified Exeinfector Fungus Dexter HiddenVNC bot Predator Prostostealer Conti ransomware Babuk ransomware RedPetya Ransomware 4 46 61 60 30 93 35 15 9 4 12 12 9 14 14 9 9 100% 20% 20% 20% 30% 20% 15% 30% 60% 100% We round up where necessary. For the RansomWar sample, our initial attempt to modify functions from the file blowfish.c which contained 4 functions was unsuccessful due to the LLMs limitations in generating function variants even with error correction. Consequently, we shifted our modifications to the RansomWar.c file, which contained 9 functions. Since this file fell into the category of samples with fewer than 10 functions, we modified all the functions. Overall, this structured approach allowed us to maintain consistency while ensuring that we did not modify an excessive number of functions in samples with large function count, such as Conti ransomware, considering the need for manual debugging in LLMalMorph."
        },
        {
            "title": "APPENDIX D\nADDITIONAL MALWARE DETECTION RATE ANALYSIS",
            "content": "Dexter Analysis for VirusTotal. As observed in the third sub-plot of Dexter in Figure 2a, the Optimization strategy steadily declines until it stabilizes near the mean after six function modifications. The Reusability strategy experiences significant drop to 67.847% after modifying the second function in file injectSection (responsible for process code injection and resource management). While this function initially decreased detection rates, they rose to 74.537%. As for other strategies, they remain close to the overall average detection rate. Prosto Analysis for VirusTotal. As observed in the sixth subplot of the Prosto stealer sample in Figure 2a, the detection rates varied widely, with sharp drops in Reusability between the 4th and 6th modifications and in Optimization between the 10th and 11th. downward trend is seen for Optimization, Windows, and Security, with Optimization reaching the lowest score of 52.738%, 9.295% reduction from the baseline 62.033%. The LLMs use of alternative Windows API functions for base64 encoding and HTTP connection management may have contributed to this decrease. Babuk Analysis for VirusTotal As observed in the eighth sub-plot of the Babuk ransomware sample in Figure 2a, we see significant drops for Optimization at the start of the second function, with the detection rate of 64.861%, which is almost 7% lower than the baseline rate of 71.759%. The variants score for this strategy increases slightly but stays below the baseline detection rate. similar trend for all strategies except Reusability is seen, but the reduction in detection rates for them is not too high. Predator Analysis for Hybrid Analysis. In the fifth plot of the Predator Stealer sample in Figure 2b, most variants exhibit minimal fluctuations, except for few skewed data points in the Predator subplot. Notably, the Optimization strategy demonstrates slightly lower detection rate than other variants. Prosto Analysis for Hybrid Analysis. We observe in the sixth plot of the Prosto Stealer Sample in Figure 2b that most variants cluster around the baseline rate 72.33% with minor deviations. We dont find any specific strategy variants showing significantly lower detection rates than the baseline. Conti Analysis for Hybrid Analysis. For the plot of Conti ransomware, the average rate of 71.568% is around 8% below the baseline rate of 79.333%. We see sharp drop in Optimization from functions 5 to 6, and the detection stays around 65% for the rest of the functions. Other than that, Quality also shows downward trend in detection rates. MalGraph. We therefore focused our adversarial evaluations on these four sample variants."
        },
        {
            "title": "APPENDIX E\nMACHINE LEARNING MODEL AND THRESHOLD DETAILS",
            "content": "In this section, we lay out the details of the machine learning models. Malconv is primarily designed with convolutional neural network that processes the malware as raw bytes to classify them. ResNet50 classifier uses the original ResNet50 [66] model underneath, which first converts the malware to greyscale images and then uses those images to classify the malware. The Malgraph model, on the other hand, does not use image/executable directly. It is hierarchical graph-based malware classifier that uses two GNNbased encoding layers. The intra-function layer encodes control flow graphs (CFGs) of individual functions into vectors, while the inter-function layer encodes function call graph (FCG) representation using the generated vectors from the previous layer and external functions to learn global program representation. prediction layer then applies MLPs to this embedding to compute the malicious probability. For Malconv and MalGraph, we use the off-the-shelf implementations from [22], trained on the dataset introduced in [42], which contains 210,251 Windows executables (101,641 malware and 108,610 goodware) spanning 848 malware families. Additional details on dataset composition and model performance are available in [22]. For ResNet50, pretrained ImageNet model was fine-tuned on malware image representations from recent dataset introduced in [43], which includes malware samples (collected from MalwareBazaar10 during March, April, May, July, and August 2024) and corresponding goodware. The training data comprised 7,312 malware instances and 14,338 goodware instances, resulting in malware:goodware ratio of 0.5:1. The performance of this trained classifier was assessed on separate test set containing malware from September (also collected from Malwarebazaar) and goodware samples, with malware:goodware ratio of 0.44:1 (1,337 malware and 3,020 goodware samples). The classifier achieved an accuracy of 85% and an F1-score of 85% on this test set. More details can be found in [43]. We used 0.1% False Positive Rate (FPR) threshold for all three classifiers, following the setup in [22]. low FPR is desirable in malware detection to reduce false positives on benign files, but it also raises the decision threshold, which may result in higher attack success rate. This trade-off has been noted in prior work [22]. For Malconv and MalGraph, the off-the-shelf implementations from [22] already included the 0.1% FPR threshold. For the fine-tuned ResNet50 model, we computed an equivalent threshold by selecting the 99.9th percentile of malware probabilities over the benign test set (used only for threshold calibration, not evaluation). At this threshold for the respective models, none of the 10 original malware samples were flagged by Malconv or ResNet50, and only Fungus, Dexter, Conti, and Babuk were flagged by"
        },
        {
            "title": "We present all the prompts used to modify the functions in",
            "content": "LLMalMorph using the LLM discussed in Algorithm 3. A. System Prompt System Prompt: You are an intelligent coding assistant who is expert in writing, editing, refactoring and debugging code. You listen to exact instructions and specialize in systems programming and use of C, C++ and C# languages with Windows platforms B. Intro Prompt Below this prompt you are provided headers, global variables, class and struct definitions and self.num_functions global function definition(s) from self.language_name source code file. The parameters of the functions also have specific types. As an intelligent coding assistant, GENERATE one VARIANT of each of these functions: ***, .join([func_name for func_name in self.function_names])*** following these instructions: C. Code Transformation Strategy Prompts As described in subsection IV-B, we developed six code transformation strategies. The prompts for these specific strategies are provided below: 1. Code Optimization. 1. Remove code redundancies. 2. Identify performance bottlenecks and fix them. 3. Simplify the codes logic or structure and optimize data structures and algorithms if applicable. 4. Use language-specific features or modern libraries if applicable. 2. Code Quality and Reliability. 1. Check error handling and edge cases. 2. Follow coding practices and style guidelines. 3. Add proper documentation to classes and functions, and comments for complex parts. 3. Code Reusability. Make the code reusable by dividing supplied functions into smaller function blocks if and where applicable. The smaller functions should be called inside the respective supplied functions as needed. 10https://bazaar.abuse.ch/ 4. Code Security. 1. Identify security vulnerabilities and fix them. generated code as it is. DO NOT modify the names of 2. If the function you are modifying contains these and do not redefine them. cryptographic operations, change the cryptographic library used for those operations. If no cryptographic operations are present, no changes are necessary. 3. Follow secure coding standards and guidelines. 5. Code Obfuscation. 1. Change the given functions and LOCAL variables names to meaningless, hard-to-understand strings which are not real words. DO NOT redefine or rename global variables (given to you) and names of functions that are called inside the given function ( might be defined elsewhere ) under any circumstances. However if the given function name is any of main, wmain, WinMain, wWinMain, DllMain, _tWinMain, _tmain do not change its name, only change the local variables names inside the function. 2. Add unnecessary jump instructions, loops, and conditional statements inside the functions. 3. Add unnecessary functions and call those functions inside the original functions. 4. Add anti-debugging techniques to the code. 5. If there are loops/conditional statements in the code change them to their equivalent alternatives and make them more difficult to follow. 6. Incorporate code to the variants that activates under very rare and obscure cases without altering core functionality, making the rare code hard to detect during testing. E. Additional Constraints These CRUCIAL instructions below MUST ALWAYS BE FOLLOWED while generating variants: 1. You MUST NOT regenerate the extra information provided to you such as headers, global variables, structs and classes for context. 2. If you modify the functions ***, .join([func_name for func_name in self.function_names])***, you MUST NOT regenerate the original code. But if function cannot be changed, then include the original code. 3. ONLY generate the function variants and any new headers/libraries you used. 4. You MUST NOT generate any extra natural language messages/comments. 5. You MUST Generate all the modified functions within single self.language_name tag. For example your response should look like this for one generated function named int func(int a): f\"{example_code}\" Remember, if you have generated multiple functions, you should include all of them within the same self.language_name tag. 6. Use the global variables as they are inside your generated functions and do not change/redeclare the global variables. 7. Always complete the function that you generate. Make sure to fill up the function body with the appropriate code. DO NOT leave any function 6. Windows API-Specific Transformation. incomplete. 1. Identify all Windows API function calls in the given functions. 2. If there are such function calls, replace each identified Windows API function call with an alternative Windows API function call or sequence of calls that achieves the same task. 3. If applicable, use indirect methods or wrappers The example_code used with the above prompt: c: self.language_name #include <stdio.h> int func(int a) { printf(\"%d\", a); return + 1; } cpp: self.language_name #include<iostream> int func(int a) { cout << <<endl; return + 1; } around the Windows API calls to achieve the same functionality. 4. Ensure that the functionality remains the same after the replacement. D. Preserve Rules Prompt REMEMBER, the generated code MUST MAINTAIN the same FUNCTIONALITY as the original code. Keep the usage of globally declared variables as it is. Modify ONLY the self.num_functions free/global function(s) named ***, .join([func_name for func_name in self.function_names])***. If you find any custom functions/custom structure/class objects/custom types/custom variables that are used inside the given self.num_functions function(s) but not in the provided code snippet, you can safely assume that these are defined elsewhere and you should use them in your"
        },
        {
            "title": "APPENDIX G\nCOMPLETE PROMPT EXAMPLE",
            "content": "a of We present complete prompt the example AntiSandbox() function of the Fungus sample. This is the first function of file main and the sixth function in our modified functions. We present the prompt for the Optimization code transformation strategy in the example below. For ease of understanding, the different parts of user prompts described in Algorithm 3 are highlighted with the name of the prompts in <<>> symbols. A. System and User prompts for AntiSandbox() System Prompt: You are an intelligent coding assistant who is expert in writing, editing, refactoring and debugging code. You listen to exact instructions and specialize in systems programming and use of C, C++ and C# languages with Windows platforms <<Intro Prompt>> User Prompt: Below this prompt you are provided headers, global variables, class and struct definitions and 1 global function definition(s) from cpp source code file. The parameters of the functions also have specific types. As an intelligent coding assistant, GENERATE one VARIANT of each of these functions: ***AntiSandbox()*** following these instructions: <<Strategy Prompt>> 1. Remove code redundancies. 2. Identify performance bottlenecks and fix them. 3. Simplify the codes logic or structure and optimize data structures and algorithms if applicable. 4. Use language-specific features or modern libraries if applicable. <<Preservation Rules Prompt>> REMEMBER, the generated code MUST MAINTAIN the same FUNCTIONALITY as the original code. Keep the usage of globally declared variables as it is. Modify ONLY the 1 free/global function(s) named ***AntiSandbox()***. If you find any custom functions/custom structure/class objects/custom types/custom variables that are used inside the given 1 function(s) but not in the provided code snippet, you can safely assume that these are defined elsewhere and you should use them in your generated code as it is. DO NOT modify the names of these and do not redefine them. <<Additional Constraints>> These CRUCIAL instructions below MUST ALWAYS BE FOLLOWED while generating variants: 1. You MUST NOT regenerate the extra information provided to you such as headers, global variables, structs and classes for context. 2. If you modify the functions ***AntiSandbox()***, you MUST NOT regenerate the original code. But if function cannot be changed, then include the original code. 3. ONLY generate the function variants and any new headers/libraries you used. ___ /___ / __/ ,__/ / / _ ___ __ __ __ __ __ ____ /_ / / /,__ by Zax0mA _/ _ / / / _ /__, _ /_/ ____/ _ _ ____ ____//____/ LITE /___/ /_//_//___L /___/ /___/ /____/ _/__/ main.cpp -> startup shit, fw bypass and install */ #ifndef DEBUG #pragma comment(lib, \"Shell32\") #endif #pragma comment(lib, \"Shell32\") char CurrentName[1024]; // encoded strings char string_firewall_location[] = \"SYSTEMCurrentControlSetServices SharedAccessParametersFirewallPolicy StandardProfileAuthorizedApplicationsList\"; char string_firewall_enabled[] = \":*:Enabled:\"; ///////////////// // config ends // ///////////////// BOOL AntiSandbox() { char *users[] = {\"sandbox\", \"honey\", \"vmware\", \"currentuser\", \"nepenthes\"}; DWORD size = 128; char szUser[128]; int i; GetUserName(szUser, &size); CharLower(szUser); for (i = 0; < (sizeof(users) / sizeof(LPTSTR)); i++) { if (strstr(szUser, users[i]) != 0) return TRUE; 4. You MUST NOT generate any extra natural language } messages/comments. 5. You MUST Generate all the modified functions within return FALSE; single cpp should look like this for one generated function named int func(int a): tag. For example your response } Listing 1: System and User Prompt cpp #include<iostream> int func(int a) { cout << <<endl; return + 1; } Remember, if you have generated multiple functions, you should include all of them within the same cpp tag. 6. Use the global variables as they are inside your generated functions and do not change/redeclare the global variables. 7. Always complete the function that you generate. Make sure to fill up the function body with the appropriate code. DO NOT leave any function incomplete. 8. DO NOT change the function name, return type, parameters and their types, or the name and number of parameters of the original functions while generating variants. <<Code>> Here is the code : #include \"includes.h\" #include \"Confix.h\" /* B. Generated LLM Response for AntiSandbox() We also present the LLM response to this prompt. We extract the code part from this response after this is generated and proceed to the next steps in LLMalMorph. cpp #include<algorithm> #include<cctype> BOOL AntiSandbox() { const char* users[] = { \"sandbox\", \"honey\", \"vmware\", \"currentuser\", \"nepenthes\" }; char szUser[128]; DWORD size = sizeof(szUser); // added GetUserName(szUser, &size); // edited std::transform(szUser, szUser + strlen(szUser), szUser, ::tolower); for (const char* user : users) { if (strstr(szUser, user) != nullptr) { return TRUE; } } return FALSE; } In this variant of the AntiSandbox() function, have removed code redundancies by using range-based for loop to iterate over the users array. Additionally, used the std::transform algorithm from the <algorithm> header and the tolower function from the <cctype> header to convert all characters in the szUser string to lowercase without explicitly calling CharLower. This simplifies the codes logic and makes it more modern C++. Listing 2: LLM Generated Response for AntiSandbox()"
        }
    ],
    "affiliations": [
        "Cisco Research",
        "Cisco Systems, Inc",
        "Purdue University"
    ]
}