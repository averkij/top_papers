{
    "paper_title": "GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search",
    "authors": [
        "Heng Zhang",
        "Yuling Shi",
        "Xiaodong Gu",
        "Haochen You",
        "Zijian Zhang",
        "Lubin Gan",
        "Yilei Yuan",
        "Jin Huang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Multi-agent systems powered by Large Language Models excel at complex tasks through coordinated collaboration, yet they face high failure rates in multi-turn deep search scenarios. Existing temporal attribution methods struggle to accurately diagnose root causes, particularly when errors propagate across multiple agents. Attempts to automate failure attribution by analyzing action sequences remain ineffective due to their inability to account for information dependencies that span agents. This paper identifies two core challenges: \\textit{(i) distinguishing symptoms from root causes in multi-agent error propagation}, and \\textit{(ii) tracing information dependencies beyond temporal order}. To address these issues, we introduce \\textbf{GraphTracer}, a framework that redefines failure attribution through information flow analysis. GraphTracer constructs Information Dependency Graphs (IDGs) to explicitly capture how agents reference and build on prior outputs. It localizes root causes by tracing through these dependency structures instead of relying on temporal sequences. GraphTracer also uses graph-aware synthetic data generation to target critical nodes, creating realistic failure scenarios. Evaluations on the Who\\&When benchmark and integration into production systems demonstrate that GraphTracer-8B achieves up to 18.18\\% higher attribution accuracy compared to state-of-the-art models and enables 4.8\\% to 14.2\\% performance improvements in deployed multi-agent frameworks, establishing a robust solution for multi-agent system debugging."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 1 ] . [ 1 1 8 5 0 1 . 0 1 5 2 : r GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search Heng Zhang South China Normal University China 2024025450@m.scnu.edu.cn Haochen You Columbia University USA hy2854@columbia.edu Yuling Shi Shanghai Jiao Tong University China yuling.shi@sjtu.edu.cn Zijian Zhang University of Pennsylvania USA zzjharry@alumni.upenn.edu Xiaodong Gu Shanghai Jiao Tong University China xiaodong.gu@sjtu.edu.cn Lubin Gan University of Science and Technology of China China ganlubin@mail.ustc.edu.cn Yilei Yuan University of Michigan USA yiliey@umich.edu Jin Huang South China Normal University China huangjin@m.scnu.edu.cn Abstract Multi-agent systems powered by Large Language Models excel at complex tasks through coordinated collaboration, yet they face high failure rates in multi-turn deep search scenarios. Existing temporal attribution methods struggle to accurately diagnose root causes, particularly when errors propagate across multiple agents. Attempts to automate failure attribution by analyzing action sequences remain ineffective due to their inability to account for information dependencies that span agents. This paper identifies two core challenges: (i) distinguishing symptoms from root causes in multi-agent error propagation, and (ii) tracing information dependencies beyond temporal order. To address these issues, we introduce GraphTracer, framework that redefines failure attribution through information flow analysis. GraphTracer constructs Information Dependency Graphs (IDGs) to explicitly capture how agents reference and build on prior outputs. It localizes root causes by tracing through these dependency structures instead of relying on temporal sequences. GraphTracer also uses graph-aware synthetic data generation to target critical nodes, creating realistic failure scenarios. Evaluations on the Who&When benchmark and integration into production systems demonstrate that GraphTracer-8B achieves up to 18.18% higher attribution accuracy compared to state-of-the-art models and enables 4.8% to 14.2% performance improvements in deployed multi-agent frameworks, establishing robust solution for multiagent system debugging. Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference17, Washington, DC, USA 2026 Copyright held by the owner/author(s). Publication rights licensed to ACM. Keywords Large Language Model, Multi-agent Systems, Graph, Failure Attribution"
        },
        {
            "title": "1 Introduction\nThe advance of Large Language Model (LLM)-powered agents\nhas unlocked remarkable potential across various cognitive do-\nmains [50]. These advanced systems are increasingly utilized to\naddress intricate tasks, particularly those involving multi-step rea-\nsoning and extensive information integration [13, 100]. However,\nas the complexity of deployed scenarios grows, the constraints of\nrelying on a singular, unified model have become increasingly evi-\ndent [34]. To address these challenges, a new wave of multi-agent\nframeworks has emerged, characterized by their capacity to coordi-\nnate multiple specialized LLM agents, enabling more nuanced task\nexecution and enhancing their capacity to perceive and respond to\ncomplex environments [5, 78].",
            "content": "To address the limitations of single-model systems, multi-agent architectures have emerged as promising solution [21, 31]. These systems organize multiple LLM-based agents to manage tasks more effectively [66]. They divide complex problems into smaller, manageable components and enable different agents to collaborate on specialized subtasks [29, 104]. This design has achieved impressive outcomes across domains such as scientific research, software engineering, and advanced data processing [44, 86]. Their ability to handle comprehensive tasks through distributed reasoning consistently surpasses the performance of single-agent systems [10, 74]. Despite these advancements, the use of multiple autonomous agents introduces complex dependencies [49, 91]. Each agent processes inputs from various sources and provides outputs for subsequent stages [92, 101]. When tasks involve prolonged multi-step reasoning, failures become more frequent [14, 46]. Studies show that common frameworks can experience failures over 80% of the time on difficult tasks [80]. These failures range from errors in how information is processed to breakdowns in coordination between between purely temporal perspective and the real flow of information within the system. Temporal models track when actions occur but fail to capture how information is generated, referenced, and propagated, which are critical for understanding failure causation. We introduce GraphTracer to overcome these limitations by redefining failure attribution through graph-based approach. The framework introduces two primary innovations. First, we design the Information Dependency Graph (IDG) to explicitly represent how information flows within multi-agent systems. An IDG is directed acyclic graph where each node represents specific piece of information generated during execution, and each edge captures usage relationship. An edge from node to node signifies that the information at node explicitly depends on the output of node i. This structure exposes long-range dependencies and separates causal links from simple temporal adjacency. Second, we develop algorithms for root cause localization, operating directly on IDG structures. These algorithms trace back the flow of information from failure points to their origin. root cause is identified as node in the IDG where correcting its information would resolve the failure. This graph-based approach naturally addresses complex scenarios, including those with multiple data sources, conflicting information streams, and extended propagation paths. Our methodology is built on three technical components. First, we incrementally construct IDGs during multi-agent execution. Modern LLMs can specify which prior observations influence their outputs, enabling real-time graph construction by extracting these references. Second, we produce training data through graph-aware fault injection. Instead of randomly introducing errors at arbitrary points, we strategically target structurally important nodes, prioritizing high-degree sources and areas prone to dependency conflicts. This approach generates synthetic failures that mirror realistic error propagation patterns. Finally, we train specialized failure tracer using reinforcement learning guided by graph-structural rewards. This model learns to pinpoint root cause nodes and map error propagation paths. multi-level reward system ensures high accuracy in both identifying root causes and tracing the paths of failure propagation. Our work makes three primary contributions: We identify that current temporal attribution methods fail systematically in multi-turn deep search scenarios because they lack the ability to trace information dependencies spanning multiple agents accurately. This limitation leads to incorrect attribution of observable symptoms as root causes when errors propagate through extended dependency paths. We introduce GraphTracer, graph-based framework that redefines failure attribution by modeling agent interactions as Information Dependency Graphs. This approach traces causal information flows, avoiding the pitfalls of purely temporal analysis. Experiments demonstrate that GraphTracer-8B improves attribution accuracy by 18.18% over Gemini-2.5-Pro and 12.21% over DeepSeek-R1 on the Who&When benchmark. When integrated into multi-agent systems like MetaGPT and MaAS, GraphTracer-8B delivers 4.8% to 14.2% performance improvements across complex reasoning tasks. Figure 1: GraphTracer-8Bs performance comparison with different LLMs. agents [40]. Such reliability issues present significant challenges for deploying these systems in practical settings [3, 23]. Addressing the fragility of multi-agent systems requires an accurate understanding of why failures occur. This involves pinpointing specific steps or components responsible for malfunctioning when tasks are not successfully completed. The challenge becomes more pronounced in multi-turn deep search tasks. These scenarios often produce extensive execution traces involving numerous agent-toagent interactions. Each interaction introduces the risk of new errors or amplifies existing ones. Diagnosing such verbose operational logs manually requires significant expertise and time, making it daunting task. Automated solutions offer potential relief, but their current effectiveness remains limited. Even state-of-the-art reasoning systems fail to reliably identify failure sources in complex multi-agent processes, showing poor accuracy when tested on benchmarks. This problem is further exacerbated by the scarcity of high-quality training data. Current datasets include only small collections of manually annotated failure cases, which are insufficient for training robust automated diagnostic tools. These gaps between the pressing need for reliable failure analysis and the inadequacy of existing approaches underscore the urgency of improving failure attribution methods. Our analysis highlights key limitation in existing attribution methods when applied to multi-turn deep search failures. These methods rely on temporal approach, viewing agent execution as linear sequence of time-ordered actions. Attribution processes trace back through this sequence to find the earliest action that, if corrected, would prevent failure. However, this approach overlooks the underlying structure of information flow. In multi-turn deep search, agents frequently reference and build upon outputs from earlier steps. For example, an agent at step 10 may cite results generated at steps 3, 5, and 7. These interactions create complex dependencies across non-consecutive steps. The actual flow of information forms an interconnected network rather than simple timeline. For instance, outdated data retrieved at step 2 might be passed through downstream agents at steps 6, 9, and 13, each processing it correctly based on the inputs provided. The error becomes evident only at step 18, when synthesis agent detects contradictions between the outdated data and updated information. Temporal methods incorrectly flag step 18 as the source of failure, while the actual issue originated at step 2. This example illustrates the misalignment Figure 2: Overview of the GraphTracer framework: (Left) Framework Establish defines complex queries, agent role assignments, and tool sets. (Middle) Trajectory Collection contrasts successful linear chains with complex graph structures in failed trajectories, employing information dependency analysis for root cause attribution. (Right) Training demonstrates graph-aware data generation and reinforcement learning for precise source-level and path-level error localization."
        },
        {
            "title": "2 Related Work\n2.1 LLM-based Multi-Agent Systems\nRecent advances in Large Language Models have catalyzed the\ndevelopment of multi-agent systems for collaborative problem\nsolving[30, 83]. In software engineering, specialized multi-agent\nframeworks have emerged. The hierarchical debugging decom-\nposes code into multi-granularity components for systematic er-\nror resolution[72], competitive debate enables diverse reasoning\nthrough structured interactions[43], and experience-driven meth-\nods accumulate repair knowledge across problem instances[11],\nwhile repository-level question answering combines dependency\ngraphs with agent tool-calling[63]. These advances build upon\nunderstanding of machine-generated code characteristics[73] and\nleverage techniques for compressing long contexts[24, 71, 94], rein-\nforcement learning for enhanced reasoning[53], and cross-language\ncode translation[81]. More broadly, these systems span a spectrum\nof automation levels. Handcrafted systems such as MetaGPT[35],\nAutoGen[88], and ChatDev[65] require manual specification of\nagent roles, prompting strategies, and coordination protocols. Par-\ntially automated approaches selectively automate components such\nas agent role assignment through AutoAgent[9] and LLMSelector,\nprompt optimization via DSPy[41] and TextGrad[93], or topology\nconstruction such as GPTSwarm[105] and G-Designer[96]. Fully\nautomated systems including AFlow[98], OWL-Workforce[36], and\nMaAS autonomously design and evolve all system components. De-\nspite their growing capabilities, these systems face high failure rates\nin complex scenarios[42]. MAST[7] first systematically character-\nized fourteen prevalent failure patterns in multi-agent frameworks.\nWho&When demonstrated that even advanced reasoning models",
            "content": "struggle with automated failure attribution, achieving accuracy below 10%. Our work addresses this challenge by reformulating failure attribution through explicit modeling of information dependencies."
        },
        {
            "title": "2.2 Graph in Multi-Agent Systems\nGraphs have emerged as a natural abstraction for modeling agent\ninteractions and information flow in multi-agent systems[103]. Re-\nsearch in this domain predominantly focuses on three directions.\nCommunication topology design seeks to optimize how agents\nshould be connected for efficient collaboration[85]. G-Designer[96]\nemploys graph neural networks to architect task-adaptive commu-\nnication structures, while ARG-Designer[70] generates customized\ntopologies through autoregressive graph generation. Method like\nEIB-Learner[52] analyzes information propagation effects to learn\nbalanced topologies that mitigate error cascades. These approaches\ntreat graphs as prescriptive coordination structures. Recent appli-\ncations reveal richer graph semantics: repository-level code under-\nstanding navigates cross-file dependencies through graph-based\ntool invocation[63], debate-based issue resolution constructs fault\npropagation traces for collaborative diagnosis[43], hierarchical de-\nbugging leverages code dependency structures[72], and experience-\ndriven frameworks bulid from repair trajectories[11]. Graph gener-\native modeling leverages multi-agent systems to synthesize realistic\nnetwork structures. GraphAgent-Generator[32] demonstrates that\nLLM-based agents can generate social graphs exhibiting macro-\nscopic network properties through simulation[62]. Hybrid archi-\ntectures integrate graph neural networks with LLM agents for\ndomain-specific tasks such as materials discovery[55, 67], using",
            "content": "GNNs for rapid property prediction[8, 17] while LLMs handle planning and reasoning[26, 105]. In contrast to these applications, our work employs graphs as descriptive representations of information provenance[15]. We construct Information Dependency Graphs to capture how agents cite and build upon prior information[84], enabling root cause analysis of system failures through graphstructural reasoning[54]. This perspective shifts graphs from design tools for coordination to analytical tools for debugging[4, 48]."
        },
        {
            "title": "3.1 Multi-Agent System Formulation\nConsider an LLM-based multi-agent system M tasked with collab-\noratively resolving a user-issued query Q. The system comprises\n𝑁 agents indexed by I = {1, 2, . . . , 𝑁 }, operating in discrete time\nunder a turn-based protocol where only one agent is active at each\ntime step. Formally, the system is characterized by",
            "content": "M = I, S, A, Ψ, 𝜇, (1) where denotes the set of system states, is the overall action space with each agent 𝑖 having local action space A𝑖 A, the scheduler function 𝜇 (𝑡) specifies which agent is active at time 𝑡, and Ψ(𝑠𝑡 +1 𝑠𝑡 , 𝑎𝑡, 𝜇 (𝑡)) models the state transition dynamics given the current state 𝑠𝑡 , action 𝑎𝑡 A𝜇 (𝑡 ) , and the acting agent. At each step 𝑡, the active agent 𝜇 (𝑡) selects an action according to its policy 𝜋𝜇 (𝑡 ) , conditioned on the current state 𝑠𝑡 , the query Q, and subset of the prior interaction history H𝑡 , which can be expressed as 𝑎𝑡 = 𝜋𝜇 (𝑡 ) (𝑠𝑡, H𝑡, Q), H𝑡 {𝑎0, 𝑎1, . . . , 𝑎𝑡 1} (2) The complete execution trajectory is denoted by 𝜏 = (𝑠0, 𝑎0, 𝑠1, 𝑎1, . . . , 𝑠𝑇 ), (3) where 𝑇 indicates the terminal step. The final response to is determined by the complete trajectory 𝜏, encapsulating the collaborative behavior of all agents."
        },
        {
            "title": "3.2 Information Dependency Graph\nWhile the trajectory 𝜏 captures the temporal sequence of actions,\nit does not explicitly represent the underlying information flow\nthat governs multi-agent collaboration. In complex tasks requiring\ndeep search or iterative reasoning, agents frequently cite and build\nupon information produced by prior agents, forming a web of de-\npendencies that transcends simple temporal ordering. To formalize\nthis structure, we introduce the Information Dependency Graph\n(IDG). An IDG associated with trajectory 𝜏 is a directed acyclic\ngraph defined as",
            "content": "G𝜏 = (V, E), (4) where each node 𝑣 represents an information piece produced during execution and each directed edge (𝑣𝑖, 𝑣 𝑗 ) indicates that the information at node 𝑣 𝑗 directly depends on the information at node 𝑣𝑖 . Each node 𝑣 is associated with triple 𝑣 = (𝑡𝑣, 𝜇𝑣, 𝑜𝑣), (5) where 𝑡𝑣 denotes the time step at which the information was produced, 𝜇𝑣 identifies the agent that generated it, and 𝑜𝑣 represents the observation or conclusion itself. We distinguish between two types of nodes based on their structural role. Source nodes are defined as Vsource = {𝑣 deg (𝑣) = 0}, (6) where deg (𝑣) = {𝑢 : (𝑢, 𝑣) E} denotes the in-degree. These represent initial observations such as search results or tool outputs that are not derived from other information within the trajectory. Conversely, derived nodes satisfy deg (𝑣) > 0 and represent conclusions or intermediate results that synthesize information from upstream nodes. An edge (𝑣𝑖, 𝑣 𝑗 ) encodes usage relationship, meaning that the agent generating 𝑣 𝑗 explicitly cited or relied upon the information 𝑜𝑣𝑖 when producing 𝑜𝑣𝑗 . Formally, edge existence is determined by (𝑣𝑖, 𝑣 𝑗 ) 𝑜𝑣𝑗 cites 𝑜𝑣𝑖 where 𝑡𝑣𝑖 < 𝑡𝑣𝑗 (7) We also associate each edge with an optional conflict indicator 𝑐𝑖 𝑗 {0, 1} defined as (cid:40) 𝑐𝑖 𝑗 = if 𝑜𝑣𝑖 and 𝑜𝑣𝑗 contradict on entity or attribute claims 1 0 otherwise (8) The IDG satisfies the acyclicity constraint to ensure that information dependencies form well-founded structure without circular reasoning. Given trajectory 𝜏, the construction of G𝜏 proceeds incrementally during execution. At each step 𝑡, when agent 𝜇 (𝑡) produces an observation or conclusion that is subsequently referenced by later agents, we create node 𝑣 with 𝑡𝑣 = 𝑡 and 𝜇𝑣 = 𝜇 (𝑡). When an agent at step 𝑡 𝑗 cites information from step 𝑡𝑖 with 𝑖 < 𝑗, we add an edge from the node corresponding to 𝑡𝑖 to the node corresponding to 𝑡 𝑗 . This incremental construction ensures that G𝜏 remains lightweight representation, as only information pieces that influence downstream reasoning are included."
        },
        {
            "title": "4.1 Problem Reformulation\nTraditional failure attribution approaches seek the earliest action\nin the temporal sequence whose correction leads to success. Let\nΩ(𝜏) ∈ {0, 1} be a binary evaluation function indicating success\nwhen Ω(𝜏) = 1 and failure when Ω(𝜏) = 0. However, this temporal\nview conflates the manifestation of failure with its underlying cause.\nWhen agents integrate information from multiple sources, a failure\nmay manifest at a synthesis step even though the root cause lies in",
            "content": "an earlier corrupted information source. We reformulate the problem in terms of the IDG G𝜏 = (V, E). node 𝑣 is considered root cause if correcting the information 𝑜𝑣 at that node eliminates the failure. More formally, let R𝑣 (𝜏) denote counterfactual trajectory obtained by replacing the information at node 𝑣 with an oracle-corrected version and propagating this correction through all dependent nodes. The set of root cause nodes is then Vroot = {𝑣 Ω(𝜏) = 0 Ω(R𝑣 (𝜏)) = 1} (9) This formulation differs fundamentally from temporal approaches. node may be root cause even if it occurs early in the trajectory and its impact only becomes apparent much later through chain of dependencies. Beyond identifying individual root causes, we also seek to understand how errors propagate through the graph. For root cause node 𝑣 Vroot, we define failure propagation path as sequence 𝜋 = (𝑣 , 𝑣1, 𝑣2, . . . , 𝑣 𝑓 ), (10) where 𝑣 𝑓 represents the final erroneous output and each consecutive pair (𝑣𝑖, 𝑣𝑖+1) is connected by an edge in E. The objective of our failure tracer is thus to identify the root cause node 𝑣 Vroot and to reconstruct the propagation path 𝜋 that explains how the error influenced the final outcome."
        },
        {
            "title": "4.2 Incremental IDG Construction\nThe IDG G𝜏 is built incrementally as the multi-agent system exe-\ncutes trajectory 𝜏. At each time step 𝑡, we track which information\npieces are produced and which prior information is referenced.\nWhen agent 𝜇 (𝑡) generates an output at step 𝑡, we assign a unique\nidentifier uid𝑡 to this output. If the output contains reasoning or\nconclusions that will potentially be cited by subsequent agents, we\ncreate a node according to the rule",
            "content": "𝑣 CreateNode(𝑡, 𝜇 (𝑡), 𝑜𝑡 ) if 𝑡 > 𝑡 : 𝑎𝑡 references 𝑜𝑡 (11) To identify dependencies, we analyze the reasoning trace produced by each agent. Modern LLMs can be prompted to explicitly indicate which prior observations or conclusions they are using. By parsing these references, we extract the set of unique identifiers , . . .} corresponding to upstream information sources. {uid𝑖1 For each such identifier, we add directed edge according to , uid𝑖2 (𝑣𝑖, 𝑣 𝑗 ) iff 𝑜𝑣𝑗 explicitly cites 𝑜𝑣𝑖 where 𝑡𝑣𝑖 < 𝑡𝑣𝑗 (12) This parsing can be performed using lightweight pattern matching if agents follow structured output formats, or through auxiliary LLM calls if more sophisticated reasoning trace analysis is required. In addition to dependency edges, we also detect conflicts. After constructing the initial graph structure, we perform pairwise consistency checks among nodes that share common descendant. The conflict indicator for an edge pair is computed as shown in Equation (7). The incremental construction ensures computational efficiency. Since only information pieces that are subsequently referenced become nodes, the graph remains compact relative to the full trajectory length. Empirically, the structural complexity satisfies 0.5𝑇 and 2.5V (13) as many actions serve coordination or formatting purposes without producing reusable information."
        },
        {
            "title": "4.3 Root Cause Localization on IDG\nGiven a failed trajectory 𝜏 with Ω(𝜏) = 0 and its associated IDG\nG𝜏 = (V, E), we seek to identify root cause nodes in Vroot and\ntheir corresponding propagation paths. The localization process\nleverages the graph structure to distinguish between symptom\nnodes, where failure is observed, and source nodes, where failure\noriginates. We begin by identifying candidate root nodes through\nbackward traversal from failure nodes. A failure node 𝑣 𝑓 is formally\ndefined as",
            "content": "𝑣 𝑓 where 𝑜𝑣𝑓 FinalOutput(𝜏) Starting from 𝑣 𝑓 , we trace backward along incoming edges to find all ancestor nodes. The ancestor set is computed as and Ω(𝜏) = 0 (14) (𝑣 𝑓 ) = (cid:8)𝑣 directed path from 𝑣 to 𝑣 𝑓 in G𝜏 (cid:9) (15) Source nodes, characterized by zero in-degree, are natural candidates since they represent information not derived from other parts of the trajectory. However, derived nodes with nonzero in-degree can also be root causes if they introduced errors during synthesis or reasoning despite receiving correct inputs. To prioritize among candidates, we compute structural features for each node 𝑣 (𝑣 𝑓 ). The impact score combines out-degree and betweenness centrality as Impact(𝑣) = 𝛼 deg+ (𝑣) + (1 𝛼) Betweenness(𝑣), (16) where deg+ (𝑣) = {𝑢 : (𝑣, 𝑢) E} measures downstream dependencies and Betweenness(𝑣) quantifies how many paths from sources to 𝑣 𝑓 pass through 𝑣. Nodes with high impact scores are prioritized as they capture positions where errors propagate widely. Once candidate root nodes are identified, we validate them through counterfactual analysis. For each candidate 𝑣, we simulate the effect of correcting 𝑜𝑣 and propagating this correction to all descendants. The validation criterion is 𝑣 Vroot iff Ω(R𝑣 (𝜏)) = 1 (17) For root cause nodes confirmed in Vroot, we construct propagation paths to the failure nodes. propagation path is formally extracted as 𝜋 = (𝑣 , 𝑣1, . . . , 𝑣 𝑓 ) where (18) by performing forward traversal from 𝑣 along outgoing edges, selecting at each step the descendant that most directly contributes to the failure. (𝑣𝑖, 𝑣𝑖+1) for all 𝑖,"
        },
        {
            "title": "4.4 Graph-Aware Data Generation\nTo train an effective failure tracer, we require a large corpus of\nannotated failure trajectories. However, naturally occurring failures\nare scarce and manually annotating IDGs is labor-intensive. We\naddress this through graph-aware synthetic data generation, which\nleverages the structural properties of IDGs to create realistic failure\nscenarios.",
            "content": "Our generation strategy begins with successful trajectories from multi-agent systems operating on various tasks. For each successful trajectory 𝜏 with Ω(𝜏) = 1, we construct its IDG G𝜏 as described previously. We then apply targeted perturbations to induce failures. Unlike random fault injection, our perturbations respect the dependency structure. The perturbation probability for each node is weighted by its structural importance as 𝑃perturb (𝑣) deg+ (𝑣) I(deg (𝑣) = 0), (19) which prioritizes high-degree source nodes that influence many downstream agents. We employ three perturbation strategies. Source pollution corrupts nodes satisfying 𝑣 Vtarget = {𝑣 : deg (𝑣) = 0 deg+ (𝑣) 𝑘threshold} (20) simulating scenarios where initial search returns outdated data. Conflict injection selects node pairs satisfying (𝑣𝑖, 𝑣 𝑗 ) where 𝑣𝑑 : (𝑣𝑖, 𝑣𝑑 ) (𝑣 𝑗, 𝑣𝑑 ) 𝑐𝑖 𝑗 = 0 (21) and perturbs one to create contradiction. Edge removal breaks critical paths by removing edges with high betweenness, defined as 𝑒 = arg max 𝑒 EdgeBetweenness(𝑒) (22) After applying perturbation Π to node 𝑣 in G𝜏 , we obtain perturbed graph G𝜏 and re-execute the affected portion to generate 𝜏. The synthetic failure is accepted if and Ω( 𝜏) = 0 ( G𝜏 )V (G𝜏 ) 𝛿, (23) where denotes symmetric difference and 𝛿 controls the magnitude of structural change. The perturbation location is known by construction, providing ground-truth labels (𝑣, 𝜋) for the root cause node and propagation path. By aggregating failures from counterfactual analysis of naturally failed trajectories and graph-aware perturbations of successful ones, we construct comprehensive training dataset Dtracer with both diversity and structural realism."
        },
        {
            "title": "4.5 Training with Graph-Structural Rewards\nWe train our failure tracer using reinforcement learning with a\nmulti-level reward structure that captures both node-level and path-\nlevel correctness. The base model is initialized from a pre-trained\nlanguage model and fine-tuned using an online RL algorithm. For\neach training sample consisting of a failed trajectory 𝜏 and its IDG\nG𝜏 , the model generates candidate attributions in the form of pre-\ndicted root cause nodes and propagation paths. These predictions\nare evaluated against ground-truth annotations using a composite\nreward function. The reward function comprises three components.\nThe format reward Iformat is a binary gate that ensures the model’s\noutput adheres to the required structure for parsing. Specifically,\nreasoning must be enclosed in designated tags and the final answer\nmust specify both a node identifier and a path through the IDG.\nThe source node reward evaluates whether the predicted root cause\nnode matches any node in the ground-truth set, defined as",
            "content": "𝑟source ( ˆ𝑣) = I( ˆ𝑣 Vroot), (24) where ˆ𝑣 denotes the predicted root node. The propagation path reward provides fine-grained feedback on the predicted failure propagation path ˆ𝜋. Let 𝜋 = (𝑣 , 𝑣 𝑓 ) denote the ground1 truth path from the true root cause to the failure node. We measure the similarity between ˆ𝜋 and 𝜋 using graph edit distance 𝑑 ( ˆ𝜋, 𝜋 ), which counts the minimum number of node insertions and deletions required to transform ˆ𝜋 into 𝜋 . The path reward is then , . . . , 𝑣 𝑟path ( ˆ𝜋) = exp (cid:18) 𝑑 ( ˆ𝜋, 𝜋 ) 𝜎 (cid:19) , (25) where 𝜎 controls the sensitivity to path deviations. The total reward combines these components as 𝑅 = Iformat (cid:0)𝜆 𝑟source + (1 𝜆) 𝑟path (cid:1) , (26) where 𝜆 balances the importance of node identification versus path reconstruction. Training proceeds by sampling trajectories from Dtracer, generating multiple candidate predictions per sample, computing rewards for each, and updating the policy using gradientbased RL. The multi-level reward structure encourages the model to leverage both local node features and global graph topology when performing attribution, resulting in tracer that captures the full complexity of information flow in multi-agent systems."
        },
        {
            "title": "5.3 Evaluation Protocols\nWe evaluate on two benchmark suites. The Who&When bench-\nmark [99] provides 127 test cases from Magnetic-One [25] and\nAG2 [68], while our TracerTraj test splits contribute 215 cases across\nthree domains. We measure performance through source-level ac-\ncuracy for identifying root cause nodes and path-level accuracy for\ntracing complete failure propagation. We test under two conditions.\nThe first provides ground truth answers during attribution, while\nthe second requires diagnosis from trajectory and feedback alone,\nfollowing the evaluation protocol from prior work [99].",
            "content": "Table 1: Performance comparison on multi-agent failure attribution. Each cell reports two values: left = w/ (with ground truth), right = w/o G. Best results are bolded. Category: External - methods using real-time web search APIs; Internal - methods using only LLMs internal knowledge."
        },
        {
            "title": "Category",
            "content": "Who&When (handcraft) Who&When (automated) Agent-level Step-level Agent-level Step-level"
        },
        {
            "title": "Open Source Methods",
            "content": "DeepRetrieval [38] Search-R1 [39] R1-Searcher [75] R1-Searcher++ [76] ReSearch [12] StepSearch [82] DeepResearcher [102] WebDancer [87] WebThinker [47] WebSailor [45] WebWatcher [1] ASearcher [27] Atom-Searcher [59] MiroMind Open Deep Research [57] ZeroSearch [77] SSRL [22] AgenTracer [95]"
        },
        {
            "title": "Internal\nInternal\nInternal",
            "content": "45.2/28.6 51.3/22.7 50.3/31.1 48.9/19.5 55.2/38.9 56.3/24.7 49.8/31.1 52.8/19.5 58.3/29.6 49.7/27.2 52.7/21.9 54.5/28.1 46.8/25.3 53.4/32.1 51.6/33.9 54.8/31.2 69.1/63."
        },
        {
            "title": "Closed Source Methods",
            "content": "OpenAI Deep Research [61] Perplexitys DeepResearch [64] Google Geminis DeepResearch [28] Kimi-Researcher [58] Grok AI DeepSearch [89] Doubao with Deep Think [6]"
        },
        {
            "title": "External\nExternal\nExternal\nExternal\nExternal\nExternal",
            "content": "OTC-PO [69] Internal/External 56.4/29.8 55.3/28.9 51.7/33.7 53.2/28.6 54.7/21.1 58.7/31.2 58.9/34."
        },
        {
            "title": "Our Method",
            "content": "6.3/2.1 5.8/1.9 9.2/3.4 11.6/2.7 14.8/6.2 8.9/3.5 11.3/4.7 13.2/5.1 8.7/2.9 12.4/5.6 9.7/4.8 7.9/3.2 10.6/6.8 12.9/6.5 9.8/4.5 10.4/5.7 20.7/20.68 11.9/8.3 9.5/5.7 9.7/6.9 14.3/10.7 12.6/8.4 13.8/7.2 15.7/9.4 52.4/31.8 59.2/28.3 68.3/42.1 62.8/36.7 63.5/29.9 57.1/33.3 67.5/38.9 71.2/35.7 58.9/31.8 55.6/29.2 61.3/24.4 64.7/31.8 56.4/39.9 59.7/28.3 58.2/29.9 62.5/27.1 69.62/63.73 60.7/39.2 61.9/31.4 61.1/38.1 63.4/35.8 67.3/34.8 65.3/32.9 63.8/39.1 8.9/3.2 11.5/4.7 14.2/5.8 16.3/7.1 19.3/4.9 21.7/9.8 12.6/8.4 13.9/6.3 17.4/7.2 15.8/10.9 9.6/5.1 13.7/4.3 18.2/8.5 15.8/11.4 14.6/11.3 16.9/8.7 42.9/38.3 28.3/21.5 31.6/19.8 29.5/22.9 33.7/19.9 34.2/23.1 38.4/18.8 35.6/25."
        },
        {
            "title": "Internal",
            "content": "74.91/69.74 28.63/27.97 76.64/67.42 49.97/44."
        },
        {
            "title": "5.4 Implementation Details\nExperiments run on eight NVIDIA H200 GPUs with 141GB memory\nusing the verl platform. GraphTracer-8B initializes from Qwen3-8B\npretrained weights. For dataset construction, DeepSeek-R1 per-\nforms counterfactual interventions and applies three graph-aware\nperturbations targeting high-degree source nodes, dependency con-\nflicts, and high-centrality edges. Training uses batch size thirty-two",
            "content": "with eight rollouts per example, learning rate one times ten to the negative sixth, and equal weighting between source and path rewards with Gaussian kernel bandwidth one. During inference, we parse structured outputs via regex and use auxiliary LLM calls for unstructured traces, computing graph edit distance through dynamic programming with unit costs. Table 2: Performance comparison on GraphTraj-2.5K across three domains. Each cell: left = w/ (with ground truth), right = w/o (trajectory only). Best and second-best results are bolded and underlined."
        },
        {
            "title": "Model",
            "content": "Source (Agent) Path (Step) Source (Agent) Path (Step) Source (Agent) Path (Step)"
        },
        {
            "title": "Agentic",
            "content": "41.28/18.67 23.54/9.82 25.18/11.37 35.92/19.48 38.65/19.43 18.92/8.31 58.73/31.49 65.18/42.37 4.86/1.52 5.17/2.03 3.95/1.28 18.73/11.26 Open-Source Models Qwen3-8B [37] Llama-3.2-3B [20] Qwen3-32B [37] Qwen3-Coder [79] Closed-Source Models GPT-4.1 [60] DeepSeek-R1 [19] Gemini-2.5-Pro [18] Claude-Sonnet-4 [2] Our Method GraphTracer-8B Relative improvement: +10.9% (Code-Source), +35.7% (Math-Path), +9.8% (Agentic-Path) 54.29/28.73 19.47/9.26 68.94/39.28 61.74/34.92 16.84/7.92 14.58/6.31 14.73/5.62 19.26/8. 48.37/22.64 51.93/25.48 63.48/38.92 53.67/31.28 19.73/13.48 76.42/58.31 62.18/43.92 15.73/7.24 8.96/2.73 9.42/3.68 17.86/8.93 42.19/18.73 36.78/14.92 38.56/19.74 44.82/26. 35.82/21.16 14.73/6.29 38.91/18.72 48.25/26.73 51.48/29.85 52.64/31.19 43.82/24.16 58.93/37.46 19.38/8.65 6.84/2.15 22.47/9.31 31.56/18.42 29.73/16.28 33.47/15.82 24.39/11.58 35.28/21.94 60.84/41.26 56.47/39. 38.72/26."
        },
        {
            "title": "5.6 Model Analysis\nComparing GraphTracer-8B against various model scales reveals\nthat while larger models like Qwen3-32B improve source-level accu-\nracy, they lag in path-level metrics as shown in Table 2. DeepSeek-\nR1 demonstrates strong reasoning but struggles with path recon-\nstruction achieving only modest step-level scores. This pattern\nsuggests existing approaches rely on temporal reasoning which\nbecomes unreliable as dependency chains lengthen. GraphTracer\nbridges this gap by explicitly modeling information provenance to\ntrace error propagation through graph structures rather than linear",
            "content": "Figure 3: GraphTracer-8Bs ablation study. sequences. Small performance variance across domains indicates robust generalization regardless of whether failures stem from coding errors, mathematical mistakes, or coordination breakdowns."
        },
        {
            "title": "5.7 Hyper-parameter Analysis\nFigure 4 illustrates sensitivity to two key hyperparameters govern-\ning the reward structure. The reward balance parameter lambda\nshows consistent peaks around 0.5 across domains, indicating equal\nweighting between source-level and path-level rewards yields op-\ntimal performance. The path sensitivity parameter sigma works\nbest around 1.0 to 1.5, with math showing slightly higher values\ndue to longer dependency chains. Excessively low sigma fails to\nprovide sufficient gradient signal while very high values create\nsparse rewards hindering convergence. These findings validate our\ndesign choices and demonstrate stable performance across reason-\nable hyperparameter ranges. The robustness to hyperparameter\nvariations suggests that our framework captures fundamental struc-\ntural properties of information flow rather than relying on precise\nnumerical tuning.",
            "content": "[5] William Brannon, Suyash Fulay, and Hang Jiang. 2024. Multi-LLM Debate: Framework, Principals, and Interventions. Advances in Neural Information Processing Systems (2024). [6] ByteDance. 2025. Doubao with Deep Think. https://www.doubao.com/. Accessed: 2025. [7] Mert Cemri, Panupong Pasupat, Oyvind Tafjord, Peter Clark, Tushar Khot, Sameer Singh, Wen-tau Yih, Hannaneh Hajishirzi, Mohit Bansal, Xinlei Wang, Graham Neubig, and Amanpreet Singh. 2025. Why Do Multi-Agent LLM Systems Fail? arXiv preprint arXiv:2503.13657 (2025). [8] Chi Chen, Weike Ye, Yunxing Zuo, Chen Zheng, and Shyue Ping Ong. 2022. Universal Graph Neural Network for Materials Discovery. Nature Communications 13 (2022), 3824. [9] Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje Karlsson, Jie Fu, and Yemin Shi. 2023. AutoAgents: Framework for Automatic Agent Generation. arXiv preprint arXiv:2309.17288 (2023). [10] P. Chen, E. Chlenski, and E. Turok. 2025. Overcoming Multi-step Complexity in Multimodal Theory-of-Mind Reasoning with LLMs. International Conference on Machine Learning (2025). [11] Silin Chen, Shaoxin Lin, Xiaodong Gu, Yuling Shi, Heng Lian, Longfei Yun, Dong Chen, Weiguo Sun, Lin Cao, and Qianxiang Wang. 2025. Swe-exp: Experiencedriven software issue resolution. arXiv preprint arXiv:2507.23361 (2025). [12] Xiao Chen et al. 2025. ReSearch: Reinforcement Learning Based Search Engine Query Optimization. arXiv preprint (2025). Referenced in various RL deep research papers. [13] Zhikai Chen, Haitao Mao, and Hang Li. 2024. Chain of Agents: Large Language Models Collaborating on Long Context Tasks. Advances in Neural Information Processing Systems (2024). [14] Ziheng Chen, Yue Song, and Xiaojun Wu. 2025. Agentic Reasoning in LLMs: Multi-Step Failure Analysis. arXiv preprint arXiv:2506.04567 (2025). [15] James Cheney, Laura Chiticariu, and Wang-Chiew Tan. 2009. Provenance in Databases: Why, How, and Where. Foundations and Trends in Databases 1, 4 (2009), 379474. [16] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training Verifiers to Solve Math Word Problems. arXiv preprint arXiv:2110.14168 (2021). [17] Yasen Cui, Jian Zhu, Wei Zhou, Huaijuan Zang, Yongsheng Ren, Jiajia Xu, Shu Zhan, and Wenhui Ma. 2024. SA-GNN: Prediction of Material Properties Using Graph Neural Network based on Multi-head Self-attention Optimization. AIP Advances 14, 5 (2024), 055033. [18] Google DeepMind. 2025. Gemini 2.5: Our most intelligent AI model. https://blog.google/technology/google-deepmind/gemini-model-thinkingupdates-march-2025/. [19] DeepSeek-AI et al. 2025. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. arXiv preprint arXiv:2501.12948 (2025). https://doi.org/10.48550/arXiv.2501. [20] Abhimanyu Dubey et al. 2024. The Llama 3 Herd of Models. arXiv preprint arXiv:2407.21783 (2024). https://doi.org/10.48550/arXiv.2407.21783 [21] Nicholas E. Eddy et al. 2024. On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents. International Conference on Machine Learning (2024). [22] Xiaojun Fan, Hao Sun, Zhen Qiao, Jinhao Guo, Yuxin Hou, Yong Jiang, Pengjun Xie, Fei Huang, and Yongbin Zhang. 2025. SSRL: Self-Search Reinforcement Learning. arXiv preprint arXiv:2508.10874 (2025). [23] Y. Fang, Y. Liu, and M. Li. 2025. Self-Supervised Detection of Coordination Breakdowns in Multi-Agent LLMs. arXiv preprint arXiv:2504.13456 (2025). [24] Yixiong Fang, Tianran Sun, Yuling Shi, and Xiaodong Gu. 2025. Attentionrag: Attention-guided context pruning in retrieval-augmented generation. arXiv preprint arXiv:2503.10720 (2025). [25] Adam Fourney et al. 2024. Magentic-One: Generalist Multi-Agent System for Solving Complex Tasks. arXiv preprint arXiv:2411.04468 (2024). https: //doi.org/10.48550/arXiv.2411. [26] Dawei Gao, Zitao Li, Weirui Kuang, Xuchen Pan, Daoyuan Chen, Zhijian Ma, Bingchen Qian, Liuyi Yao, Lin Zhu, Chen Cheng, Hongzhu Li, Yaliang Zhang, Bolin Wei, and Jingren Wang. 2024. AgentScope: Flexible yet Robust Multiagent Platform. arXiv preprint arXiv:2402.14034 (2024). [27] Jiaxuan Gao, Wei Fu, Minyang Xie, Shusheng Xu, Chuyi He, Zhiyu Mei, Banghua Zhu, and Yi Wu. 2025. Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL. arXiv preprint arXiv:2508.07976 (2025). Figure 4: GraphTracer-8Bs hyperparameter analysis across three domains."
        },
        {
            "title": "References",
            "content": "[1] Alibaba NLP Team. 2025. WebWatcher: Breaking New Frontier of VisionLanguage Deep Research Agent. Announced in Alibaba NLP Deep Research repository. [2] Anthropic. 2025. Introducing Claude Sonnet 4.5. https://www.anthropic.com/ [28] Google DeepMind. 2025. Google Geminis DeepResearch. https://deepmind. news/claude-sonnet-4-5. Model API: claude-sonnet-4-5. google/technologies/gemini/. Accessed: 2025. [3] A. Azizpour, A. Balaji, and T. J. Treangen. 2025. Model-Driven Analysis of Information Processing Errors in LLM Agents. arXiv preprint arXiv:2506.06212 (2025). [4] Michael Bergmeister, Clement Vignac, and Andreas Loukas. 2024. Diffusion Models for Graph Generation and Analysis. Advances in Neural Information Processing Systems 37 (2024). [29] Jiaxin Guo, Ziyu Wang, and Zhihui Zhao. 2025. Survey on LLM-Based MultiAgent Systems: Workflow, Infrastructure, and Evaluation. Autonomous Agents and Multi-Agent Systems (2025). [30] Taicheng Guo, Xiuying Chen, Yaqi Wang, Bowen Chen, Ruidi Wang, Kai Lv, Dawei Li, Shuo Wang, Hai Zhang, and Hua Li. 2024. Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application. arXiv preprint arXiv:2412.17481 (2024). [31] Yihan Guo, Liang Wang, and Chenming Zhang. 2025. Why Do Multi-Agent LLM Systems Fail? arXiv preprint arXiv:2503.13657 (2025). [32] Jiarui He, Tianle Zhou, Wenhao Zhang, Xiran Liu, Zhewei Li, Yuxiao Chen, Yankai Lin, Tianyu Liu, Xin Xie, Hanwen Tong, and Hao Ji. 2024. Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation. arXiv preprint arXiv:2410.09824 (2024). [33] Dan Hendrycks, Collin Burns, Saurabh Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring Mathematical Problem Solving With the MATH Dataset. arXiv preprint arXiv:2103.03874 (2021). https://doi.org/10.48550/arXiv.2103.03874 NeurIPS 2021. [34] Jiaxin Hong, Ziyu Wang, and Zhihui Zhao. 2024. Optimizing LLM Agents for Tool Usage via Contrastive Reasoning. Advances in Neural Information Processing Systems (2024). [35] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber. 2024. MetaGPT: Meta Programming for Multi-Agent Collaborative Framework. The Twelfth International Conference on Learning Representations (2024). https: //openreview.net/forum?id=VtmBAGCN7o [36] Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru Li, Qiguang Chen, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Bernard Ghanem, Ping Luo, and Guohao Li. 2025. OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation. arXiv preprint arXiv:2505.23885 (2025). [37] Binyuan Hui et al. 2025. Qwen3 Technical Report. arXiv preprint arXiv:2505. (2025). https://doi.org/10.48550/arXiv.2505.09388 [38] Zhiyuan Jiang et al. 2025. DeepRetrieval: Learning to Retrieve Passages Dynamically for Biomedical QA. arXiv preprint (2025). Referenced in Deep Research Agents survey. [39] Bowen Jin, Hansi Zeng, Zhenrui Yue, Jinsung Yoon, Sercan Arik, Dong Wang, Hamed Zamani, and Jiawei Han. 2025. Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning. arXiv preprint arXiv:2503.09516 (2025). [40] Wei Ju, Yukun Cai, and Hui Ning. 2025. Towards Reliable Multi-Agent LLM Systems: Failure Rates Over 80%. arXiv preprint arXiv:2503.06789 (2025). [41] Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas Joshi, Hanna Moazam, Heather Miller, Matei Zaharia, and Christopher Potts. 2024. DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines. The Twelfth International Conference on Learning Representations (2024). [42] Guohao Li, Hassan Abou Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2024. Survey of Large Language Models for Multi-Agent Systems. arXiv preprint arXiv:2402.01680 (2024). [43] Han Li, Yuling Shi, Shaoxin Lin, Xiaodong Gu, Heng Lian, Xin Wang, Yantao Jia, Tao Huang, and Qianxiang Wang. 2025. Swe-debate: Competitive multi-agent debate for software issue resolution. arXiv preprint arXiv:2507.23348 (2025). [44] J. Li, S. Mao, and Y. Qin. 2025. LLM-based Agentic Reasoning Frameworks: Survey from Methods and Applications. arXiv preprint arXiv:2508.17692 (2025). [45] Kuan Li, Zhongwang Zhang, Huifeng Yin, Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin, Baixuan Li, Zhengwei Tao, Xinyu Wang, Weizhou Shen, Junkai Zhang, Dingchu Zhang, Xixi Wu, Yong Jiang, Ming Yan, Pengjun Xie, Fei Huang, and Jingren Zhou. 2025. WebSailor: Navigating Super-human Reasoning for Web Agent. arXiv preprint arXiv:2507.02592 (2025). [46] M. Li, L. Meng, and Z. Ye. 2025. Multi-Step Failures in LLM Multi-Agent Frameworks. arXiv preprint arXiv:2507.08901 (2025). [47] Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, JiRong Wen, and Zhicheng Dou. 2025. WebThinker: Empowering Large Reasoning Models with Deep Research Capability. arXiv preprint arXiv:2504.21776 (2025). [48] Zhixun Li et al. 2024. Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems. arXiv preprint arXiv:2410.02506 (2024). https://doi.org/10.48550/arXiv.2410.02506 [49] Ya-Wei Eileen Lin and Ronald R. Coifman. 2025. Challenges in LM Evaluation: Multi-Step Reasoning Reliability. International Conference on Machine Learning (2025). [50] Hao Liu, Jiarui Feng, Lecheng Kong, Ningyue Liang, and Dacheng Tao. 2024. LLM-Based Multi-Agent Framework for GitHub Issue Resolution. Advances in Neural Information Processing Systems (2024). [51] Jiawei Liu et al. 2023. Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation. arXiv preprint arXiv:2305.01210 (2023). https://doi.org/10.48550/arXiv.2305.01210 Introduces MBPP+ as an extension. [52] Qian Liu, Yutong Chen, Zheng Wang, and Lin Zhang. 2024. EIB-Learner: Learning Balanced Topologies for Multi-Agent Collaboration. arXiv preprint arXiv:2410.08932 (2024). [53] Runze Liu, Jiakang Wang, Yuling Shi, Zhihui Xie, Chenxin An, Kaiyan Zhang, Jian Zhao, Xiaodong Gu, Lei Lin, Wenping Hu, et al. 2025. Attention as Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models. arXiv preprint arXiv:2509.26628 (2025). [54] Zijun Liu, Yanzhe Yao, Zhen Li, Guohao Yu, Xiang Qian, Xiaohan Yang, Shuzhou Zhang, Hao Zheng, Yu Zhang, Xiangyu He, Zhiyuan Li, and Diyi Yang. 2024. DyLAN: Dynamic LLM-Agent Network for Collaborative Problem Solving. arXiv preprint arXiv:2310.04406 (2024). [55] Amil Merchant, Simon Batzner, Samuel Schoenholz, Muratahan Aykol, Gowoon Cheon, and Ekin Dogus Cubuk. 2023. Scaling Deep Learning for Materials Discovery. Nature 624 (2023), 8085. [56] Grgoire Mialon et al. 2023. GAIA: benchmark for General AI Assistants. arXiv preprint arXiv:2311.12983 (2023). [57] MiroMind AI Team. 2025. MiroMind Open Deep Research. Open-source deep research system. [58] Moonshot AI. 2025. Kimi-Researcher: Deep Research Capabilities. https://www. moonshot.cn/. Kimi k1.5 with research capabilities. [59] Open Source Community. 2025. Atom-Searcher: Multi-Agent Search Framework. Method referenced in deep research benchmarks. [60] OpenAI. 2025. Introducing GPT-4.1 in the API. https://openai.com/index/gpt-41/. [61] OpenAI. 2025. OpenAI Deep Research. https://openai.com/index/introducingdeep-research/. Accessed: 2025. [62] Joon Sung Park, Joseph OBrien, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael Bernstein. 2023. Generative Agents: Interactive Simulacra of Human Behavior. Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology (2023), 122. [63] Weihan Peng, Yuling Shi, Yuhang Wang, Xinyun Zhang, Beijun Shen, and Xiaodong Gu. 2025. SWE-QA: Can Language Models Answer Repository-level Code Questions? arXiv preprint arXiv:2509.14635 (2025). [64] Perplexity AI. 2025. Perplexitys DeepResearch. https://www.perplexity.ai/. Accessed: 2025. [65] Chen Qian, Xin Liu, Cheng Fu, Shihao Zhang, Yujia Chen, Zhiyuan Wei, Yufan Wang, Zihao Zhang, Ge Zhang, Chenyang Zheng, Yu Wang, Yaxi Yang, and Yang Liu. 2023. ChatDev: Communicative Agents for Software Development. arXiv preprint arXiv:2307.07924 (2023). [66] Vinay Ramasesh et al. 2024. Boosting Virtual Agent Learning and Reasoning: Step-Wise, Multi-Dimensional Assessment. International Conference on Machine Learning (2024). [67] Patrick Reiser, Robin Ruff, Jan Stühmer, and Pascal Friederich. 2024. Connectivity Optimized Nested Line Graph Networks for Crystal Structures. Digital Discovery 3 (2024), 515. [68] Microsoft Research et al. 2025. AG2: The Open-Source AgentOS for Multi-Agent Systems. https://github.com/ag2ai/ag2. Benchmark and framework for agent generation. [69] Research Team. 2025. OTC-PO: Optimal Tool Calls via Reinforcement Learning. Referenced in various RL agent papers. [70] Li Shen, Hao Wang, Yue Zhang, and Chao Zhou. 2025. Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation. arXiv preprint arXiv:2507.18224 (2025). [71] Yuling Shi, Yichun Qian, Hongyu Zhang, Beijun Shen, and Xiaodong Gu. 2025. LongCodeZip: Compress Long Context for Code Language Models. arXiv preprint arXiv:2510.00446 (2025). [72] Yuling Shi, Songsong Wang, Chengcheng Wan, Min Wang, and Xiaodong Gu. 2024. From code to correctness: Closing the last mile of code generation with hierarchical debugging. arXiv preprint arXiv:2410.01215 (2024). [73] Yuling Shi, Hongyu Zhang, Chengcheng Wan, and Xiaodong Gu. 2024. Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. In 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE). IEEE Computer Society, 5162. [74] Aditya Shin, Siqi Zeng, and Makoto Yamada. 2025. Reinforce LLM Reasoning through Multi-Agent Reflection. International Conference on Learning Representations (2025). [75] Huatong Song, Jinhao Jiang, Yingqian Min, Jie Chen, Zhipeng Chen, Wayne Xin Zhao, Ji-Rong Wen, Yang Lu, and Xu Miu. 2025. R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning. arXiv preprint arXiv:2503.05592 (2025). [76] Huatong Song, Jinhao Jiang, Wenqing Tian, Zhipeng Chen, Yuhuan Wu, Jiahao Zhao, Yingqian Min, Wayne Xin Zhao, Lei Fang, and Ji-Rong Wen. 2025. R1Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning. arXiv preprint arXiv:2505.17005 (2025). [77] Hao Sun, Zhen Qiao, Jinhao Guo, Xiaojun Fan, Yuxin Hou, Yong Jiang, Pengjun Xie, Fei Huang, and Yongbin Zhang. 2025. ZeroSearch: Incentivize the Search Capability of LLMs without Searching. arXiv preprint arXiv:2505.04588 (2025). [78] Li Sun, G. Zhang, and X. Zhao. 2024. Coordination and Collaborative Reasoning in Multi-Agent LLMs. arXiv preprint arXiv:2507.08616 (2024). [79] Qwen Team. 2025. Qwen3-Coder: Agentic Coding in the World. https://qwenlm. github.io/blog/qwen3-coder/. [80] B. Wang, Y. Li, and T. Chen. 2025. Reasoning Failures in Extended Multi-Agent LLM Tasks. arXiv preprint arXiv:2508.12345 (2025). [81] Chaofan Wang, Tingrui Yu, Jie Wang, Dong Chen, Wenrui Zhang, Yuling Shi, Xiaodong Gu, and Beijun Shen. 2025. EVOC2RUST: Skeleton-guided Framework for Project-Level C-to-Rust Translation. arXiv preprint arXiv:2508.04295 (2025). [82] Meng Wang et al. 2025. StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization. arXiv preprint (2025). Referenced in Search-R1 and related works. [83] Xinyi Wang, Zhiyuan Chen, Wayne Xin Zhao, and Ji-Rong Wen. 2024. Survey on LLM-based Multi-agent Systems: Workflow, Infrastructure, and Challenges. Science China Information Sciences 67 (2024), 138. [84] Xin Wang, Yang Liu, Haoming Chen, and Wei Zhang. 2024. Attribution and Tracing in LLM-based Multi-Agent Systems. arXiv preprint arXiv:2411.12345 (2024). [85] Yichen Wang, Zhiming Zhang, Zhengzhe Li, Xuan Chen, and Guanghui Liu. 2025. AgentDropout: Designing Multi-Agent Communication Topology via Agent Dropout. arXiv preprint arXiv:2502.12345 (2025). [86] Zhangyu Wang, Yuan Li, and T. Chen. 2025. HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Decomposition. International Conference on Machine Learning (2025). [87] Jialong Wu, Baixuan Li, Runnan Fang, Wenbiao Yin, Liwen Zhang, Zhengwei Tao, et al. 2025. WebDancer: Towards Autonomous Information Seeking Agency. [88] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation. arXiv preprint arXiv:2308.08155 (2023). [89] xAI. 2025. Grok AI DeepSearch. https://x.ai/. Accessed: 2025. [90] Zhangchen Xu et al. 2025. KodCode: Diverse, Challenging, and Verifiable Synthetic Dataset for Coding. arXiv preprint arXiv:2503.02951 (2025). https: //doi.org/10.48550/arXiv.2503.02951 Accepted by ACL 2025. [91] Menglin Yang, Min Zhou, and Marcus Kalander. 2025. Survey on Multi-Agent LLM Architectures and Dependencies. arXiv preprint arXiv:2501.04567 (2025). [92] Y. Ye, X. Chen, and S. Wang. 2025. LLM Agents in Prolonged Reasoning: InputOutput Dependencies. arXiv preprint arXiv:2502.11234 (2025). [93] Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, and James Zou. 2024. TextGrad: Automatic \"Differentiation\" via Text. arXiv preprint arXiv:2406.07496 (2024). [94] Wenhao Zeng, Yaoning Wang, Chao Hu, Yuling Shi, Chengcheng Wan, Hongyu Zhang, and Xiaodong Gu. 2025. Pruning the unsurprising: Efficient code reasoning via first-token surprisal. arXiv preprint arXiv:2508.05988 (2025). [95] Guibin Zhang, Yanwei Chen, Jiawei Liu, Shengchao Li, Haotian Wang, and Tianrui Chen. 2025. AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems? arXiv preprint arXiv:2509.03312 (2025). [96] Guibin Zhang, Yanwei Yue, Enlai Chen, Daoguang Lin, Yanjie Chen, Zenglin Wang, and Yu Zhang. 2024. G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks. arXiv preprint arXiv:2410.11782 (2024). [97] Jiayi Zhang et al. 2024. AFlow: Automating Agentic Workflow Generation. arXiv preprint arXiv:2410.10762 (2024). https://doi.org/10.48550/arXiv.2410.10762 [98] Jiayi Zhang, Jinyu Hong, Haowen Sun, Mingchen Zhuge, Haokun Lin, Ziru Xu, Zhili Tang, Shaohui Ma, Nan Zhang, Fuwen Zhang, Wenxuan Zheng, Yuqi Wang, Zijuan Lin, Jialong Zhang, and Liangdong Pan. 2025. AFlow: Automating Agentic Workflow Generation. The Thirteenth International Conference on Learning Representations (2025). [99] Shaokun Zhang et al. 2025. Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems. https://doi.org/ 10.48550/arXiv.2505.00212 arXiv:2505.00212 [cs.MA] [100] Zihao Zhang, Xunkai Li, and Liang Wang. 2024. Diagnose, Localize, Align: Full-Stack Framework for Reliable LLM Multi-Agent Systems. arXiv preprint arXiv:2409.23188 (2024). [101] Ziwen Zhao, Yifei Su, and Yu Li. 2025. Coordination Failures in Multi-Agent LLM Systems. arXiv preprint arXiv:2504.07890 (2025). [102] Yuxiang Zheng, Dayuan Fu, Xiangkun Hu, Xiaojie Cai, Lyumanshan Ye, Pengrui Lu, and Pengfei Liu. 2025. DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments. arXiv preprint arXiv:2504.03160 (2025). [103] Tianle Zhou, Yue Wang, Xiaolong Chen, and Zheng Li. 2024. Survey on Graph Neural Networks for Multi-Agent Systems. Comput. Surveys 56, 8 (2024), 139. [104] Xi Zhu, Haochen Xue, and Ziwei Zhao. 2025. Multi-Step Planning and Reasoning Improves Acting in LLM Agents. arXiv preprint arXiv:2505.09970 (2025). [105] Mingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and Jürgen Schmidhuber. 2024. GPTSwarm: Language Agents as Optimizable Graphs. Proceedings of the 41st International Conference on Machine Learning (2024), 6274362767."
        }
    ],
    "affiliations": [
        "Columbia University",
        "Shanghai Jiao Tong University",
        "South China Normal University",
        "University of Michigan",
        "University of Pennsylvania",
        "University of Science and Technology of China"
    ]
}