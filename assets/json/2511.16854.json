{
    "paper_title": "MRI Super-Resolution with Deep Learning: A Comprehensive Survey",
    "authors": [
        "Mohammad Khateri",
        "Serge Vasylechko",
        "Morteza Ghahremani",
        "Liam Timms",
        "Deniz Kocanaogullari",
        "Simon K. Warfield",
        "Camilo Jaimes",
        "Davood Karimi",
        "Alejandra Sierra",
        "Jussi Tohka",
        "Sila Kurugol",
        "Onur Afacan"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution. IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey."
        },
        {
            "title": "Start",
            "content": "IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 1 MRI Super-Resolution with Deep Learning: Comprehensive Survey Mohammad Khateri, Serge Vasylechko, Morteza Ghahremani, Liam Timms, Deniz Kocanaogullari, Simon K. Warfield, Camilo Jaimes, Davood Karimi, Alejandra Sierra, Jussi Tohka, Sila Kurugol, Onur Afacan 5 2 0 2 ] . e [ 3 4 5 8 6 1 . 1 1 5 2 : r Abstract High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with focus on deep learning (DL) approaches. It examines DLbased MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution. Index Terms MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey. I. INTRODUCTION IGH-resolution (HR) magnetic resonance imaging (MRI) is essential for capturing fine anatomical details and accurately assessing physiological and functional processes. However, acquiring HR images comes with inherent trade-offs among spatial resolution, signal-to-noise ratio (SNR), and scan This work was supported in part by the Research Council of Finland under Grants 323385 and 358944; by the Flagship of Advanced Mathematics for Sensing Imaging and Modelling; by the saastamoinen foundation; by the KAUTE Foundation; and by Finnish Cultural Foundation. Mohammad Khateri, Alejandra Sierra, and Jussi Tohka are with the A. I. Virtanen Institute for Molecular Sciences, Faculty of Health Sciences, University of Eastern Finland, 70210 Kuopio, Finland (e-mail: {mohammad.khateri, alejandra.sierralopez, jussi.tohka}@uef.fi). Serge Vasylechko, Liam Timms, Deniz Kocanaogullari, Simon Warfield, Davood Karimi, Sila Kurugol, and Onur Afacan are with Harvard Medical School and Boston Childrens Hospital, liam.timms, Boston, MA 02115, USA (e-mail: sila.kurugol, simon.warfield, deniz.kocanaogullari, onur.afacan}@childrens.harvard.edu). {serge.vasylechko, davood.karimi, Morteza Ghahremani is with the Artificial Intelligence in Medical Imaging group at the Department of Radiology, Technical University of Munich, 80333 München, Germany (e-mail:morteza.ghahremani@tum.de). Camilo Jaimes is with the Department of Radiology, Massachusetts General Hospital, Boston, MA 02114 USA (e-mail: cjaimescobos@mgb.org). timethree tightly coupled factors where improving one often degrades the others. For example, achieving higher spatial increasing both resolution typically requires longer scans, imaging costs and the risk of motion artifacts. Low-resolution (LR) imaging is faster and may boost SNR, but often lacks the detail needed for high-quality diagnostics. Balancing this trade-off remains central challenge in MRI [1][3]. Although advanced acquisition techniques, e.g., parallel imaging [4] and compressed sensing [5], offer partial solutions, superresolution (SR) techniques have shown more favorable tradeoff among these parameters than direct HR acquisition [6]. SR techniques reconstruct HR images from more accessible LR scans using computational, hardware-independent methods. By enhancing resolution post-acquisition, SR can help to bridge the gap between fast imaging and diagnostic precision, making it an increasingly valuable tool in MRI [7][16]. Given the pressing need for HR MRI, there is clear demand for comprehensive survey focused on SR techniques tailored to this modality. While most SR surveys address general computer vision tasks [17][28], relatively few focus on medical applications [29][33], and even fewer specifically target MRI SR [34][36]. Existing surveys often overlook MRI-specific challenges and recent advances, such as clinical relevance, diverse MRI applications, and modern developments from computer vision, computational imaging, and inverse problemsincluding denoising diffusion models, implicit neural representations, foundation models, and advanced learning methods. dedicated survey on MRI SR is essential to advance technology, benchmark methods, improve clinical diagnostics, and guide future research by highlighting emerging trends and gaps. To meet this need, our study presents comprehensive survey of MRI SR techniques with the following contributions: 1) thorough review of existing and potentially applicable DL-based approaches to MRI SR, ranging from theoretical foundations to research and clinical applications. 2) comprehensive review of key aspects of DL-based MRI SR, including architectural design, performance evaluation, benchmark datasets, practical applications, and learning strategies, with an emphasis on developing systematic taxonomy to categorize these techniques. 3) review of recent advances in computer vision for MRI SR, including vision Transformers (ViTs), diffusion models, foundation models, implicit neural representations, and Gaussian splatting. 4) discussion of current challenges and future directions 2 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 Fig. 1: Taxonomy of MRI super-resolution methods. in DL-based MRI SR, along with GitHub repository with open-access codes, datasets, tools, and tutorials. II. PROBLEM FORMULATION AND TERMINOLOGY A. Super-Resolution Formulation SR is low-level vision task that aims to recover the unknown HR image RHW from degraded observation Rhwd: = Hδ(x), (1) where, Hδ() : RHW Rhwd is the degradation operator arising from imaging system. We assume throughout that the MRI data have already been reconstructed from kspace into images, and that SR is applied in the image domain. SR is formulated as an ill-posed inverse problem because multiple HR images can correspond to the same LR observation. The degradation operator Hδ() is parameterized by δ primarily includes geometric transformation Γ(), blurring operator, which is convolution with the blur kernel κ, an s-fold under-sampling operator s, and noise n, i.e., δ = {Γ, κ, s, n} [6], [34], [37], [38]. In practice, δ is not directly available; only the LR observation exists, and assumptions on δ are based on estimates or subset of realistic degradation parameters. The ratios τx = H/h, τy = W/w, and τz = D/d represent the undersampling factors in the x, y, and directions, respectively. Theoretically, the SR process is to recover unknown through H1 δ (y), which requires determining the inverse mapδ () : Rhwd RHW D. If this mapping can be ping H1 determined, it would enable the practical recovery of the HR image from the LR observation. SR techniques can generally be categorized into two groups based on their approach to this mapping: model-based and learning-based methods. B. Super-Resolution Approaches 1) Model-Based: Model-based SR methods aim to explicitly model the degradation function in Eq. 1 as combination of several operations, commonly referred to as the forward model. Assuming that the geometric transformation, blurring kernel, and under-sampling operator are known, and considering noise as additivean assumption valid when the SNR exceeds three dB [39]the degradation operator is expressed as: Hδ(x) = (Γ(x) κ) +n, {Γ, κ, s, n} δ (2) The solution ˆx can then be obtained by optimizing maximum posteriori (MAP) formulation as below: {y (Γ(x) κ) q ˆx = arg min + λR(x)}. (3) The first term represents the likelihood, calculated as the pnorm distance between the observation and the degraded latent image x, where 0 < p, 2 are dictated by the KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 3 noise distribution [40][42]. When the SNR exceeds three dB, the noise can be assumed to be identical Gaussian [39], leading to = = 2. R() is the regularization (or prior) term, penalizing the latent image based on prior knowledge of the data. The parameter λ controls the balance between the likelihood and prior term. To mitigate the ill-posedness of SR problems, various regularization techniques have been developed, including Tikhonov [43], [44], total variation (TV) [45][47], self-similarity [48][50], low-rankness [47], [51] [53], sparse representation [54][56], non-local mean [57] [59], and gradient guidance [60][62]. Handcrafted priors can improve SR but have limited performance compared to datadriven approaches. Building effective SR models typically requires the optimization of multiple priors, which is timeand memory-intensive and involves tuning trade-off parameters. Furthermore, SR models are often tailored to specific degradation scenarios, necessitating different models for varying conditions. If the degradation in the LR images does not match the assumed model, significant artifacts may occur due to domain gaps [19], [63], [64]. 2) Learning-Based: Learning-based SR methods establish mapping between LR and HR image spaces, enabling the restoration of HR images from LR inputs. This mapping can be viewed as regression problem, where the goal is to predict HR images based on LR inputs. Early research by [65], introduced co-occurrence priors between LR and HR image patches. Since then, numerous patch-based approaches have emerged, techniques like manifold learning [66], and sparse representation [67][69]. Recently, deep learning (DL)-based SR methods have demonstrated exceptional performance [70] [78]. DL-based methods with end-to-end training automatically learn priors and degradation models directly from the data, eliminating the need for manual design. These methods optimize the objective function below over set of LR-HR pairs {(yi, xi)}N i=1: ˆθ = arg min θ (cid:88) i=1 L(fθ(yi), xi) + λΦ(θ), (4) where L(fθ(yi), xi) represents the loss function between the networks prediction and the ground truth, Φ() represents the regularization term that supports model generalization, and λ is the trade-off parameter that balances the optimization problem. The trained model is then applied to an unseen LR image, fθ(y), to generate the super-resolved output ˆx. Hereinafter, our discussion will center around DL-based methods. C. Perspectives on DL-based Super-Resolution DL-based SR techniques can be approached from different perspectives, each providing unique insights and methodologies for addressing the inverse problem of recovering HR images from LR acquisitions. These perspectives differ in how they incorporate prior knowledge, the degradation model, and apply learning strategies. This section explores these perspectives, including end-to-end data-driven, physics-informed techniques, image-to-image translation (see Fig. 2). Fig. 2: Perspectives on MRI super-resolution methods: (a) Data-driven approach that learns LR-to-HR mapping purely from data; (b) Physics-informed approach that incorporates the underlying imaging physics while mapping the LR-to-HR; and (c) Image-to-image translation approach that translates across LR and HR domains, such as modalities or contrasts. 1) End-to-End Data-Driven Perspective: In the plain end-toend learning paradigm, the SR task is treated as data-driven problem, where neural network directly maps LR images to HR counterparts. The success of this approach hinges on the availability and quality of large-scale datasets, comprising either real-world LR-HR pairs or synthetic pairs generated by downsampling HR images. Dataset diversity and realism are critical to ensuring robust model performance. Various learning paradigmsincluding supervised, unsupervised, and self-supervisedcan be applied depending on the data context and availability [73][75]. 2) Physics-Driven Perspective: The physics-driven or physics-informed approachalso referred to as the interpretable data-driven approachcombines traditional modelbased methods with data-driven techniques to ensure that the SR solution adheres to the physical constraints of the MRI acquisition process. By integrating domain knowledge about imaging physics, these methods achieve more reliable and interpretable results than plain end-to-end data-driven methods [79][84]. This approach is linked to various imaging inverse problems, grounded in strong mathematical principles [85][90]. Physics-informed SR approaches are classified into I) deep plug-and-play, II) deep unfolding, and III) deep equilibrium methods, which will be elaborated in section IV. 3) Image-to-Image Translation Perspective: The image-toimage translation perspective frames SR as task where the model learns to map images from the LR domain to the HR domain. This approach is widely used in medical image analysis, where variations in resolution, contrast, or modality are treated as distinct domains. The objective is to translate LR images into HR counterparts with enhanced anatomical detail and visibility. These tasks often involve challenges such as multiple modalities, varying contrast, or differences in imaging techniques [91][93]. Generative models, such as generative adversarial networks (GANs) and denoising diffusion probabilistic models (DDPMs), are frequently employed within this framework to produce high-quality content [94], which will be further explored in Section VIII. III. MRI SUPER-RESOLUTION A. Key Scenarios in MRI Super-Resolution MRI SR addresses the fundamental trade-offs of the MRI trianglespatial resolution, SNR, and scan timeas well as 4 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 hardware limitations, e.g., magnet strength, gradient performance, and coil design. To overcome these challenges, various imaging strategies have been developed, including fast acquisition protocols, motion-robust techniques, and cost-effective low-field MRI. SR techniques offer computational support across these approaches, enabling high-quality imaging and broader accessibility without requiring modifications to scanner hardware or acquisition protocols. These capabilities make SR valuable in several key scenarios. 1) In-Plane Super-Resolution: In-plane SR enhances spatial resolution within the imaging plane (x, y), enabling finer anatomical detail in individual slices. Physically, this often involves increasing the matrix size (e.g., from 128 128 to 256 256), which reduces voxel size and consequently lowers SNR. To preserve image qualitytypically defined by adequate SNR and tissue contrast (sequence-dependent intensity differences; e.g., T1/T2/proton-density weighting) longer scan times are usually required. In-plane SR (e.g., [95]) mitigates these limitations by computationally boosting resolution without markedly compromising SNR or increasing acquisition time. 2) Through-Plane Super-Resolution: Through-plane SR targets the resolution anisotropy in MRI data, where the inplane resolution (x, y) is higher than the through-plane resolution (z). This anisotropy can hinder 3D analysis. Achieving isotropic resolution, where the through-plane resolution matches the in-plane resolution, requires reducing slice thickness. However, thinner slices reduce voxel size, decreasing SNR as well as increasing scan time as more slices are needed to cover the same volume. SR techniques mitigate these tradeoffs by computationally enhancing through-plane resolution, allowing for isotropic reconstruction without sacrificing SNR or extending scan time. variety of methods have been proposed to achieve isotropic MRI from single anisotropic scan [63], [96][98] or from multiple anisotropic stacks acquired in orthogonal planes [3], [99][102]. Many of these methods build on the foundational idea introduced by Elad and Feuer [103], who first formulated single-image SR reconstruction from multiple measurements. 3) Slice-to-Volume Reconstruction: Slice-to-volume reconstruction (SVR) is form of through-plane SR in which multiple anisotropic data2D slice stacks acquired under motion and from varying orientationsare combined to reconstruct an HR, isotropic volume. SVR jointly performs motion correction and SR by leveraging complementary information across stacks. This is especially valuable in fetal and neonatal imaging, where subject motion and limited acquisition time compromise 3D image quality. Each stack contributes partial, anisotropic observations of the anatomy, and reconstruction is further complicated by both intraand inter-stack motion. SVR addresses these challenges by exploiting cross-stack redundancy and complementary spatial coverage across orientationseach stack provides high in-plane detail along its native slice axis and supplies through-plane information missing in the others [104][106]. While SVR relies on multiple 2D stacks, recent study [107] demonstrates the feasibility of single-stack SVR, utilizing DL to directly infer HR isotropic volumes from single anisotropic input. 4) Isotropic Volumetric Super-Resolution: In certain scenarios, such as fetal diffusion MRI, volumes are acquired with uniformly low resolution across all spatial dimensions (x, y, z) due to the scan time constraints. The goal in this setting is to enhance resolution isotropically in all directions. Unlike through-plane SR, where high in-plane detail serves as structural prior, isotropic SR is more ill-posed, poorly conditioned inverse problem because high-frequency content is missing simultaneously in x, y, and z, leaving no directional cues. Consequently, most approaches depend on fully supervised learning with external HR isotropic datasets. Recent work has shown promising results in isotropically enhancing LR volumes using such strategies [108]. 5) Super-Resolution Across Field Strengths: MRI field strength is key determinant of image quality, influencing SNR, spatial resolution, and diagnostic utility. At lower fields, image quality is degraded. SR methods address this limitation by computationally enhancing resolution, narrowing the gap to high-field performance and enabling diagnostic-quality imaging at lower fields. This is particularly relevant for lowfield and portable systems [109], where SR helps democratize MRI and approximate high-field imaging. SR also offers cost-effective alternative in resource-limited or point-of-care settings. Its clinical viability is increasingly supported, with studies showing improved diagnostic quality across standard to high-field MRI [110][116], as well as in ultra-low-field [117], [118] and portable low-field systems [109], [119]. Several low-field MRI systems have received FDA clearance for clinical use, including the ultra-low-field, portable Hyperfine Swoop (0.064 T) for bedside neuroimaging [120]. Recent reviews also discuss the regulatory landscape and clinical potential of other low-field systems, such as Siemens MAGNETOM Free.Max (0.55 T) and Promaxo (0.066 T) [121], [122]. 6) Temporal Super-Resolution: Temporal SR aims to enhance the temporal resolution of dynamic MRIthat is, the frequency at which images are acquired over time. Higher temporal resolution allows for more precise capture of rapid physiological changes, which is critical in applications such as cardiac imaging, functional MRI, and blood flow assessment. Conventionally, increasing temporal resolution requires faster acquisitions, often at the cost of reduced spatial resolution and lower SNR due to limited sampling. SR techniques address this trade-off by reconstructing temporally enhanced images from low-temporal-resolution data, thereby improving the fidelity of dynamic processes without requiring faster acquisition protocols. Applications of temporal SR include cardiac and functional imaging [123], [124], time-resolved flow imaging such as 4D flow MRI [84], [125], [126], and respirationresolved 4D MRI [127]. 7) Multi-Contrast MRI Super-Resolution: In clinical practice, multiple MRI contrasts (e.g., T1, T2, FLAIR) are routinely employed to capture complementary anatomical and pathological information. Multi-contrast SR leverages the synergy among these modalities by integrating diverse contrast information to enhance image resolution beyond what is achievable with single modality. By incorporating multiple contrasts, it offers more comprehensive depiction of tissue properKHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 5 tieseffectively performing image fusionand supports more accurate diagnosis and informed treatment planning. Recent studies highlight the increasing importance of multi-contrast SR, showcasing progress in both algorithmic innovation and clinical applicability [128][141]. 8) Cross-contrast MRI Super-Resolution: Cross-contrast SR focuses on translating or synthesizing one MRI modality (e.g., T2, FLAIR) from another (e.g., T1), often within an imageto-image translation framework. This approach is particularly valuable in scenarios where certain contrasts are missing, corrupted, or impractical to acquire due to time limitations or patient-specific constraints. By learning mappings between modalities, SR models can generate HR representations of unavailable contrasts, supporting diagnosis and multi-modal analysis. Unlike multi-contrast SR, which fuses multiple available contrasts to enhance target modality, cross-contrast SR predicts distinct contrast, potentially at higher resolution, from single input. Recent deep learning approaches have shown promise in this area, particularly those based on GANs [142][144], and diffusion models [145]. This task intersects with broader research on modality synthesis and domain translation. 9) Cross-Modality Super-Resolution: Cross-modality SR leverages complementary information across different imaging modalitiessuch as MRI, CT, and PETto enhance resolution beyond the limits of single modality. By mapping between modalities, it reconstructs HR images in one domain (e.g., MRI) using data from another with higher resolution or distinct characteristics (e.g., PET for functional insights). This approach is valuable when direct HR imaging is impractical due to risks (e.g., radiation in CT) or limited accessibility. DL methods based on domain translation [142], cross-modal synthesis, and fusion networks have driven progress in this area. Applications include enhancing PET resolution with MRI priors, boosting MRI resolution using CT guidance, and synthesizing detailed anatomical images from LR functional scans [146], [147]. IV. PHYSICS-DRIVEN SUPER-RESOLUTION Physics-driven SR integrates knowledge of imaging physics with learning approaches to solve inverse imaging problems. Notable strategies include deep image priors [148][150] and generative priors [151][153], which serve as implicit regularizer. This section examines three major frameworks: (i) deep plug-and-play (PnP), (ii) deep unfolding, and (iii) deep equilibrium models. We highlight how these frameworks integrate physical modeling with deep learning. A. Deep Plug-and-Play The PnP framework integrates DL-based priors into traditional model-based algorithms, with applications across broad spectrum of inverse imaging problems [81], [154] [160]. The central idea is to replace the handcrafted regularization term in the iterative solution of the MAP formulation (Eq. 3) with pre-trained deep denoiser [157], which is \"plugged\" into the iterative optimization process using Algorithm 1 Plug-and-Play for Image Super-Resolution Require: Observed image y, degradation operator Hδ() = (Γ() κ) s, pre-trained denoiser Dσ(), regularization parameter λ, number of iterations 1: Initialize x0 by upsampling 2: for = 1 to do 3: Data Consistency Step: zk arg min Hδ(z)2 2 + λ xk1 2 4: Denoising Step: xk Dσ (zk) 5: end for 6: return xK methods such as alternating direction method of multipliers (ADMM) [161], half-quadratic splitting (HQS) [162], or majorization-minimization (MM) [163]. The general procedure is summarized in Algorithm 1. PnP combines flexibility and interpretability, adapting to various tasks without needing ground-truth data. Its main drawback is the computational and memory overhead incurred by the repeated execution of the forward model and denoising network, which can hinder scalability. In addition, similar to other model-based methods, it requires manual tuning of the regularization parameter λ and the number of iterations K. B. Deep Unfolding Deep unfolding, or unrolling, provides systematic bridge between iterative model-based algorithms and deep learning. In this approach, each iteration of an optimization algorithm is unrolled into the neural network layers, allowing for the end-to-end training of the network. This offers the advantage of efficient parameter learning and faster inference compared to traditional iterative methods [133], [164]. key benefit of deep unfolding is its interpretability: it retains the underlying mathematical structure of the optimization problem, ensuring that each layer has clear role corresponding to the steps of an iterative method. This combination of interpretability and efficiency makes deep unfolding particularly powerful for applications like image super-resolution [38], [82], [165], [166]. Following this approach, the MRI SR method is structured as an iterative two-step process comprising data consistency enforcement and prior-based refinement, as detailed in Algorithm 2. This recursive formulation mirrors the architecture of deep networks, where each layer progressively refines the reconstruction by alternating between fidelity to the observed data and the incorporation of prior knowledge. conceptual overview of deep unfolding appears in Fig. 3. C. Deep Equilibrium Deep equilibrium (DEQ) networks extend iterative reconstruction methods by directly solving for the fixed point of parameterized update rule. Instead of explicitly unrolling 6 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX Algorithm 2 Deep Unfolding for Image Super-Resolution Require: Observed image y, degradation operator Hδ() = (Γ()κ) s, regularization R(), parameters µ, λ, number of iterations 1: Initialize x0 by upsampling 2: for = 1 to do Step 1: 3: zk arg min 4: Step 2: Hδ(z)2 2 + µ xk12 2 xk arg min µ 2 zk x2 2 + λR(x) 5: end for 6: return xK Fig. 3: Deep unfolding models provide physics-informed approach to imaging inverse problems by integrating the forward model with neural network within an iterative reconstruction framework, as illustrated in Algorithm 2. Each unrolled layer corresponds to single iteration of an optimization algorithm [164], [167]. fixed number of iterations, DEQ models define an implicit mapping and compute its equilibrium state satisfying, = fθ(y, x), (5) (cid:16) + γH , where Hδ and (cid:17) δ(y Hδ(x)) where fθ denotes learned refinement operator. common formulation for imaging inverse problems is fθ(y, x) = Rθ δ represent the forward degradation operator and its adjoint, Rθ is learned prior, and γ are tunable parameters [87]. Unlike deep unfolding, which unrolls iterations into network layers, DEQ models compute the equilibrium point implicitly using fixedpoint solvers such as Anderson acceleration [168] or Broydens method [169]. This enables constant memory usage, since only the equilibrium state is required for both forward and backward passes. As result, DEQ models can scale to much deeper implicit architectures compared to unrolled networks. However, convergence to stable fixed point is not guaranteed and may depend on architectural choices, initialization, and the learned operator [170][172]. Additionally, implicit differentiation introduces extra computational overhead. conceptual illustration of the DEQ formulation is shown in Fig. 4. V. LEARNING APPROACHES IN MRI SR DL-based MRI SR approaches can be broadly categorized into three main groups: (1) learning paradigms, (2) learning strategies, and (3) data-efficient and adaptive methods. Fig. 4: Deep Equilibrium models provide physics-driven approach to imaging inverse problems by incorporating the forward model and neural network within fixed-point formulation [87]. These groups represent complementary dimensions rather than mutually exclusive categories; an MRI SR method may simultaneously fall under multiple dimensions (e.g., selfsupervised multi-task learning method). A. Learning Paradigms MRI SR methods can be classified into three learning paradigms based on the level of supervision: (1) Supervised learning, which uses physically acquired and spatially aligned LR-HR image pairs; (2) Unsupervised learning, which removes the need for paired data by leveraging degradation learning, or unpaired distributions, domain adaptation; (3) Selfsupervised learning, which generates supervision directly from the input image without external training data (see Fig. 5). 1) Supervised Learning: Supervised learning trains models on physically acquired and registered LR-HR image pairs, which has been studied in natural image SR [19]. However, applying this paradigm to MRI presents key challenges: (i) Acquiring matched LR-HR pairs is difficult due to motion artifacts, scanner variability, and the high cost and time required for scansissues exacerbated in dynamic or susceptible regions (e.g., the abdomen) and populations such as fetuses and neonates. (ii) Even when LR and HR scans are available, they often exhibit non-rigid misalignments caused by patient motion or anatomical deformation. Although image registration can reduce misalignment, it often fails to correct complex non-linear changes, particularly in soft tissue [173]. Because of these limitations, few studies have utilized truly acquired LRHR MRI pairs for supervised training. Notable examples include paired multi-modal MRI dataset at 3T and 7T [174], and the work by Chun et al. [175], which used small set of real LRHR pairs to supervise downsampling network for learning realistic degradation. Due to the practical difficulties in collecting well-aligned paired data, there has been growing shift toward unsupervised and self-supervised SR methods that better accommodate the constraints of clinical MRI acquisition. 2) Unsupervised: Unsupervised learning addresses the challenge of unavailable or misaligned LR-HR image pairs by training models on unpaired data or synthetically degraded images. This approach is especially suited to MRI, where motion, scanner variability, and acquisition costs often hinder the collection of paired datasets. Common strategies include: Degradation-based learning: Unsupervised SR methods often simulate LR images from HR scans using predefined degradation models, such as down-sampling [176], [177]. In KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 7 Fig. 5: Learning paradigms for MRI super-resolution: (a) Supervised learning, where the network is trained on physically acquired and well-aligned pairs of LR-HR scans; (b) Unsupervised learning, where no LR-HR pairs are available: 1) generating synthetic LR images from HR scans to create LR-HR training pairs, and 2) scenarios where only LR scans and unpaired examples from the HR target domain are accessible; and (c) Self-supervised learning, where training pairs are generated directly from the available LR scans. tures [70] have been proposed to enhance domain consistency, forming the basis for several subsequent approaches. For example, Zhou et al. [182] introduced an unsupervised SR framework that combines domain correction network in the LR space with an upscaling network for HR reconstruction, enabling training without explicit knowledge of the degradation process. Building on this idea, Liu et al. [63] proposed domain adaptation in both image and latent feature spaces to improve alignment for unpaired and misaligned MRI data. Domain transfer has also been applied to multimodal MRI SR [143], [183] and for synthesizing 7T-like images from 3T scans [112]. comprehensive overview of unpaired image-toimage translation in medical imaging is available in [184]. 3) Self-Supervised Learning: Self-supervised SR eliminates the need for external datasets by training directly on the input LR image, exploiting its internal structure. Unlike supervised methods, self-supervised approaches can adapt to variations in scanner type, acquisition protocol, or anatomical region, making them highly practical for clinical use. In this setting, regions of the input with relatively higher structural fidelity are treated as proxy HR, while corresponding synthetic LR samples are generated from them to form training pairs. representative method is zero-shot self-supervised SR (ZSSR) [185], which exploits patch recurrence across scales to synthetically generate LRHR pairs from single image. This principle has been extended to MRI in methods such as SMORE [97], which reconstructs isotropic 3D volumes from anisotropic inputs without external supervision. Subsequent self-supervised strategies have been applied to range of MRI tasks, including dynamic fetal imaging [101], arbitraryscale through-plane SR [186], and multi-contrast DWI SR with inter-scan motion correction [187]. Sui et al. [188] further advanced this direction with scan-specific generative degradation learning approach, inspired by blind SR [20], which models degradation directly from the input dataenhancing robustness to scanner-specific artifacts and acquisition variability. More recently, [189] extended scan-specific SR with an unsupervised transformer that captures long-range spatial structure, yielding improved patient-specific reconstructions. Fig. 6: Supervised vs. unsupervised super-resolution: Domain gaps between synthetic LR training data and real acquired LR images lead to discrepancies in the super-resolved outputs when models trained on synthetic data are applied to realworld inputs. MRI, k-space truncation is the most commonly used strategy, where HR images are transformed into the frequency domain, partially truncated, and then reconstructed into synthetic LR volumes [73], [99], [178], [179]. Additionally, Iglesias et al. [180] proposed SynthSR, framework that synthetically generates HR images from segmentation maps and produces paired LR images via down-sampling. While such downsampling techniques are widely used, they tend to oversimplify the complexity of real-world clinical acquisitions. In practice, LR and HR images are often acquired using distinct undersampling protocolssuch as partial Fourier, elliptical k-space, or parallel imaging, which are difficult to replicate accurately due to scanner-specific parameters and unknown acquisition settings. Moreover, differences in SNR, coil sensitivity, and system calibration further contribute to discrepancies between synthetic and real degradations [63]. These mismatches lead to domain gap that can hinder model generalization at inference time (see Fig. 6). Domain Transfer (Unpaired Image-to-Image Translation): Degradation-based unsupervised methods reduce reliance on paired data but still depend on simplified assumptions that fail to capture the full complexity of real MRI acquisitions. This mismatch creates domain gap between synthetic and clinical data, motivating domain transfer approaches that directly learn mappings between unpaired LR and HR domains. In MRI SR, domain transfer strategies are often inspired by CycleGAN-based frameworks [181], which treat LR and HR images as distinct domains and learn bidirectional mappings between them. Cycle-in-cycle architecIEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 B. Learning Strategies 1) Multi-Task Learning: Multi-task learning is strategy in which model is trained to perform multiple related tasks simultaneously, leveraging shared representations to enhance overall performance. In the context of SR, this approach improves outcomes by incorporating complementary information from tasks such as image reconstruction, artifact correction, and related processes. Multi-task learning has been extensively studied in MRI. For instance, joint learning of SR and denoising has been explored in [74], [190][192], the combinations of SR and image reconstruction are investigated in [193][196], the integration of SR with motion correction is discussed in [197], [198], and SR combined with Gibbs artifact removal is presented in [199]. Additionally, the synergy between SR and segmentation is explored in [200], and the combination of SR with registration and reconstruction is addressed in [201]. 2) Multi-Modal MRI Learning: Clinical protocols often acquire multiple MRI sequences with complementary contrasts (e.g., T1, T2, FLAIR, diffusion). Conventional SR methods usually process each modality independently, overlooking cross-modal correlations that could enhance reconstruction. Multi-modal MRI SR addresses this by fusing information across contrasts to guide reconstruction. Xu et al. [202], for example, proposed multiscale fusion network that reconstructs HR T2-weighted images using high-frequency structural details from T1-weighted scans. Stimpel et al. [203] developed deep guided filtering framework in which an HR modality (e.g., T1-weighted MRI or CT) guides the SR of LR modality (e.g., T2-weighted MRI), combining locally linear guided filter with learned guidance map to improve transparency and robustness. More recently, Li et al. [204] introduced McMRSR, Transformer-based framework that models long-range dependencies and employs multi-scale contextual matching and aggregation across contrasts. 3) Curriculum Learning: Curriculum learning is training strategy where tasks are introduced in order of increasing difficulty, enabling models to first master simpler concepts before tackling more complex ones [205], [206]. In SR, this approach improves model robustness to high scaling factors, noise, and blurring by gradually exposing the network to such challenges during training, resulting in better reconstruction quality and generalization [207], [208]. 4) Prompt Learning: Prompt learning introduces additional contextual cuesknown as promptsto guide the models reconstruction strategy. In image SR, prompts typically encode degradation characteristics such as blur, noise, or distortion, helping the model adapt its response accordingly. One effective approach employs degradation-conditioned prompt layers to focus on relevant contextual features, improving superresolved output [209], [210]. More recently, [211] introduced multimodal prompt framework leveraging stable diffusion priors to enhance adaptiveness, generalization, and fidelity in image restoration tasks. Although this approach has not yet been applied to MRI, it has the potential to incorporate scan parameters and acquisition protocols as prompts to improve reconstruction performance. 5) Ensemble Learning (Multi-Supervision): Ensemble learning combines predictions from multiple models to achieve improved performance compared to any individual model [212]. Classical strategies include bagging (e.g., Random Forests), boosting (e.g., AdaBoost), and stacking. In MRI SR, ensembles are typically constructed by integrating outputs from several SR networks trained on different priors, architectures, or datasets. This aggregation helps mitigate artifacts and preserve fine details, as the complementary strengths of the models lead to more robust and visually consistent reconstructions [37]. 6) Federated Learning: Federated learning offers privacypreserving paradigm for MRI SR by enabling collaborative model training across multiple institutions without sharing raw patient data. This is particularly valuable in neuroimaging, where datasets are often small and fragmented across sites. Recently, Basira et al. [213] proposed RepFL, replica-based FL framework that creates perturbed replicas of each clients data to improve data diversity and aggregates heterogeneous models for graph super-resolution. Applied to brain connectome reconstruction from MRI, RepFL demonstrated superior performance over conventional FL methods, highlighting the potential of federated approaches for multi-resolution MRI analysis under data scarcity and privacy constraints. 7) Reinforcement Learning Models (RLs): RLs have been explored for SR by framing it as decision-making process where agents iteratively enhance image resolution. These models adaptively learn strategies for dynamic or stagebased upscaling, showing potential in MRI SR for handling complex data variations and improving image quality [214], [215]. However, RL-based SR methods are less common than CNNor GAN-based approaches, since defining suitable states, actions, and reward functions for sequential resolution enhancement is challenging and often less efficient than direct end-to-end learning. 8) Mixture of Experts (MoE): MoE framework combines lightweight gating mechanism with pool of specialized subnetworksexpertsactivating only the most relevant subset for each input, enabling high representational capacity with efficient computation [216]. In MRI SR, experts can specialize in handling specific degradations, anatomical regions, or scanner contrasts, while the gate dynamically selects the best combination for each volume. MoE-DiffSR [217] demonstrates this approach using diffusion backbone with gated experts, achieving strong results on multi-scanner brain and knee datasets. Recent advances in routing and regularization further improve load balancing and scalability, making MoE promising direction for MRI SR. C. Data-Efficient and Adaptive Methods 1) Transfer Learning and Zero-Shot: Transfer learning enables models trained on one task to be adapted for related tasks with limited data. In MRI SR, it enhances efficiency by leveraging pre-trained models from other imaging modalities or existing datasets, reducing reliance on large domainspecific data [218]. This approach accelerates development and improves performance, especially in clinical scenarios with limited HR MRI availability. It has been applied in brain KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 9 TABLE I: Commonly Used Loss Functions in Image Super-Resolution. Loss Category Loss Function (Batch-wise) Pixel-wise Feature-wise GAN-based Prior-based Mean Squared Error: Lℓ2 = 1 Mean Absolute Error: Lℓ1 = 1 Charbonnier Loss: LCharbonnier = 1 (cid:80)N i= (cid:80)N i=1 1 hwd 1 hwd (cid:80)N i=1 (cid:80) (cid:80) (cid:114)(cid:16) j,k,l(x(i) j,k,l x(i) (cid:17)2 L(i) ℓ1 j,k,l ˆx(i) j,k,l ˆx(i) + ϵ2 j,k,l)2 j,k,l (cid:80)N Perceptual Loss: LPerceptual = 1 (cid:13)G(l)(ˆx(i)) G(l)(x(i))(cid:13) (cid:13) Style Loss: Lstyle = 1 (cid:13) i=1 (cid:80)N Adversarial Loss: LG = 1 i=1 log(D(G(y(i)))) Cycle Consistency Loss: Lcyc = 1 (cid:80)N (cid:80)N i=1 i=1 2 (cid:13)ϕ(l)(x(i)) ϕ(l)(ˆx(i))(cid:13) (cid:13) (cid:13) (cid:0)G(H(x(i))) x(i)1 + H(G(y(i))) y(i)1 (cid:1) (cid:80)N Total Variation Loss: LTV = 1 Physics-based Loss: LPhysics = 1 Histogram Loss: LHistogram = 1 Edge Loss: LEdge = 1 (cid:80)N i=1 j,k,l (cid:80)N i=1y(i) D(ˆx(i))2 2 (cid:80)N i=1 δ(Hist(x(i)), Hist(ˆx(i))) p, {1, 2} i=1E(x(i)) E(ˆx(i))p 1 hwd (cid:80) (cid:113) (j ˆx(i) j,k,l)2 + (k ˆx(i) j,k,l)2 + (l ˆx(i) j,k,l)2 Metric-based Metric-Based Loss: LMetric = 1 (cid:80)N i=1M(x(i), x(i)) M(x(i), ˆx(i))2 [219] and cardiac MRI [220]. notable subcategory, zeroshot learning, adapts models directly to test data without taskspecific fine-tuning and has shown promise in medical imaging [221]. 2) Contrastive Learning: Contrastive learning trains models by pulling together similar samples (positives) and pushing apart dissimilar ones (negatives), enabling robust feature representations. Originally developed in computer vision [222], [223], it has recently been applied to MRI SR to cope with scarce paired data. Approaches contrast LR inputs with HR counterparts, synthetic with real LR images, or different contrasts from the same subject [224], encouraging fine-grained structural consistency and reducing domain gaps. Huang et al. [225], for example, introduced perceptual contrastive loss to improve texture realism in multi-contrast MRI SR. 3) Meta learning: Meta-learning, or \"learning to learn,\" enables models to rapidly adapt to new imaging tasks using minimal data. In natural image SR, meta-transfer learning methods (e.g., MTL-SR [226]) have demonstrated impressive adaptability to unseen degradations. Although such approaches have been validated in natural images, their application to MRI SR is only beginning to emerge. Recent work includes Delta-WKV [227], meta-in-context learner that dynamically adjusts model weights during inference to capture both local and global anatomical patterns. Evaluated on benchmark MRI datasets, it achieved state-of-the-art MRI SR quality while reducing computational cost. VI. NETWORK DESIGN Designing effective MRI SR systems requires coordinated choices across loss functions, architectural building blocks, and network paradigms. The following subsections review key loss formulations, core architectural components, and representative network families, highlighting their roles, tradeoffs, and use in MRI SR. A. Loss Functions voxel-wise ℓp-norm losses, which measure pixelor voxellevel intensity differences between reconstructed and reference images. While simple and effective, these losses often fail to capture perceptual quality or structural fidelity. Depending on the learning paradigm (e.g., supervised or unsupervised), complementary objectives have therefore been introduced, including feature-based, GAN-based, prior-informed, and metric-driven losses. These aim to enhance visual realism and anatomical accuracy. We review key loss functions here, where and ˆx denote the ground-truth and predicted HR images, respectively. For clarity, all losses are formulated for single image pair but computed over batches in practice (see Table I). 1) Pixel-/Voxel-wise Loss: Pixel-/voxel-wise losses measure the discrepancy between the super-resolved image ˆx and the ground-truth at losses in this category are ℓ1-norm, measuring the mean absolute error (MAE), the ℓ2-norm, measuring the mean square error (MSE), and Charbonnier loss [228], differentiable variation of the ℓ1 loss: the intensity level. Prominent Lℓ1(x, ˆx) = 1 hwd (cid:88) i,j,k xi,j,k ˆxi,j,k Lℓ2 (x, ˆx) = 1 hwd (cid:88) i,j,k (xi,j,k ˆxi,j,k) LCharbonnier(x, ˆx) = (cid:113) (Lℓ1 (cid:0)x, ˆx)(cid:1)2 + ϵ2, (6) (7) (8) where h, w, and represent the height, width, and depth of x, respectively, while ϵ is small constant, e.g. 103, used to stabilize the optimization process. When comparing ℓ1 to ℓ2, the ℓ2 loss penalizes larger errors more severely but is more lenient with smaller errors, yielding smoother results. In practice, the ℓ1 loss has consistently exhibited superior performance over the ℓ2 loss for different restoration tasks [229], [230]. In SR, loss functions quantify reconstruction errors and guide model optimization. The most common are pixelor Moreover, pixel-/voxel-wise loss functions exhibit the classical regression-to-the-mean effect [231], [232]. Because ℓp IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 norms minimize average per-pixel discrepancies, the optimal estimator under ill-posed conditions is the conditional expectation xpred = E[xHR xLR], causing models trained with ℓp losses to average over plausible solutions and smooth out high-frequency details. 2) Feature-wise Loss: Unlike voxel-/ pixel-wise losses, which aim for intensity-perfect matches between ˆx and x, feature-based losses encourage them to share similar feature representations computed by pre-trained classification network ϕ(), e.g., VGG [233]. The high-level representations extracted by such network on the l-th layer are denoted as ϕ(l)(). Two prominent categories of feature-based losses are perceptual [234], [235] and style [236], [237] loss functions. Perceptual Loss. The perceptual loss, also known as content loss, is defined as the ℓp-norm distance between the highlevel representations of two images: LPerceptual(x, ˆx; ϕ, l) = Lℓp (cid:0)ϕ(l)(x), ϕ(l)(ˆx)(cid:1), (9) Perceptual loss encourages the output image ˆx to resemble to target image in terms of human perception, yielding visually more pleased results. Style Loss: The style loss penalizes ˆx when it deviates from the target image in terms of style-related attributes, i.e., colors, textures, and patterns [236]. This loss utilizes the Gram matrix G(l) (x)) vec(ϕ(l) (x)), where vec() denotes the vectorization operation, and ϕ(l) (x) represents the i-th channel of feature maps at layer of image x. The style loss is defined as: ij (x) = vec(ϕ(l) Lstyle(ˆx, x; ϕ, l) = (cid:13) (cid:13)G(l) (cid:13) where denotes the Frobenius norm. This loss encourages the network to maintain style integrity, particularly in preserving textures, which can yield visually appealing results. ij (ˆx) G(l) (cid:13) 2 (cid:13) ij (x) (cid:13) (10) , 3) GAN-based Loss: Generative adversarial networks (GANs) are notable for their capacity to produce realistic high-quality data. GANs comprise generator, responsible for data generation, and discriminator, which evaluates the authenticity of the generated data by comparing it to target distribution samples. Adversarial Loss. In the context of super-resolution, the generator G() produced super-resolved image, and discriminator D() assesses whether the super-resolved image is real or not. This approach has been implemented in various frameworks as illustrated in [238][241]. vanilla GAN involves the training of two networks, which entails alternating between optimizing two loss functions: 1) the generator loss LG, and 2) the discriminator loss LD: LD = Ex[log(D(x))] Ey[log(1 D(G(y)))], LG = Ey[log(D(G(y)))]. (11) While state-of-the-art GANs are capable of generating highly realistic details, they are susceptible to issues such as mode collapse and convergence problems, and sometimes require additional methods for stabilization [23]. Cycle Consistency Loss: Introduced in the context of unpaired image-to-image translation within GAN frameworks [70], [181], cycle consistency loss ensures that mappings between two distinct domains are inverses of each other. Specifically, it enforces that the mapping : Rwhd RW HD and its reverse : RW HD Rwhd are both bijections. This consistency is promoted through forward consistency: G(H(x)) and backward consistency: H(G(y)). The encouragement of this behavior is enforced using cycle consistency loss: Lcyc = Ex [G(H(x)) x1]+Ey [H(G(y)) y1] (12) By enforcing both forward and backward consistency, cycle consistency loss limits the range of possible mapping functions. This loss can maintain content fidelity between input and translated images, particularly for unpaired restoration tasks where ground truth is unavailable. 4) Prior-based Loss: These losses integrate our prior knowledge about data into optimization, guiding models to meet predetermined expectations based on prior information. Depending on the formulation, they may operate independently of ground truth (e.g., TV) or in conjunction with ground truth data. Total Variation (TV): TV loss encourages spatial smoothness by penalizing large differences between neighboring pixels. It helps suppress spurious variations and artifacts in reconstructed images by promoting piecewise-smooth regions [45]. The loss is defined as: 1 hwd (i ˆxi,j,k)2 + (j ˆxi,j,k)2 + (k ˆxi,j,k) LTV(ˆx) = (cid:88) (cid:113) i,j,k (13) where i, j, and denote the spatial gradients along the height, width, and depth axes, respectively. While stable in 2D, extending TV to volumetric MRI poses numerical stability challenges. Practical implementations of 3D TV for MRI SR have been developed, for example, in fetal brain imaging [46], multi-contrast brain MRI [242], and more recently in deep self-supervised fMRI SR frameworks [243]. Physics-Based: These loss functions embed fundamental physical principles underlying the imaging process into the training objective. By enforcing physics-consistent constraints, they guide model outputs to remain faithful to the physical laws governing MRI acquisition, thereby narrowing the solution space and improving the realism of reconstructed images [83], [244]. common approach is to formulate the loss based on the forward or degradation model: LPhysics = H(ˆx)2 2 (14) where is the observed measurement, ˆx is the reconstructed image, and H() denotes the degradation operator [245]. Histogram: Histogram loss is useful in tasks such as SR, denoising, and contrast enhancement, where maintaining the statistical distribution of pixel intensities is essential for perceptual quality. By minimizing the difference between the histograms of the predicted and target images, this loss encourages the restoration of intensity patterns that closely match the ground truth, thereby enhancing visual realism and fidelity [232], [246], [247]. generic formulation compares histogram distributions using divergence or distance metric: LHistogram = δ(Hist(x), Hist(ˆx)) (15) KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 11 Fig. 7: Overview of super-resolution architectures: (a) Pre-upsampling, (b) Final upsampling, (c) Progressive upsampling, (d) Residual learning with long skip connections, (e) Dense connections with efficient feature reuse, (f) Recursive learning with shared layers. where δ(, ) denotes distance or divergence measure (e.g., L2, KL divergence), and Hist() computes the normalized histogram of the image. Edge-Preserving: Edge-preserving losses aim to maintain sharp structural boundaries during image reconstruction. Methods based on multi-scale gradient field priors [61] penalize discrepancies in edge information between the predicted and target images. These losses are particularly valuable in medical imaging, where preserving anatomical features such as tissue interfaces or lesion boundaries is critical. typical formulation compares edge maps extracted by an edge operator E(): LEdge = E(x) E(ˆx)1 1, (16) where E() computes edge features, e.g., gradients [248]. 5) Metric-based: Metric-based loss functions guide training based on perceptual or evaluation-driven criteria rather than simple pixel-wise differences. By optimizing image quality metrics such as SSIM [249], these losses align better with human visual perception when produce HR outputs: LMetric = M(x, x) M(x, ˆx)2 2, (17) where M(, ) denotes metric, and M(x, x) represents its ideal (reference) value; for example, M(x, x) = 1 in the case of SSIM. B. Fundamental Network Architectures 1) Up-sampling Methods: Upsampling, or upscaling, is fundamental operation in SR tasks, aimed at increasing the spatial dimensions and enhancing the resolution of an image or feature map. Depending on the network design, upsampling can be introduced at various stages: as first-stage preprocessing step, at the final stage to reconstruct HR outputs, or progressively within intermediate layers. An overview of these strategies is illustrated in Fig. 7. Existing methods can be broadly categorized into interpolation-based techniques and learning-based approaches. Interpolation-Based Methods: Traditional upsampling techniques such as nearest-neighbor, bilinear, bicubic, and Lanczos interpolation are widely used due to their simplicity, interpretability, and computational efficiency. Their 3D counterparts (e.g., trilinear interpolation) extend these principles to volumetric data. While easy to implement and fast, interpolation-based methods cannot recover high-frequency information and therefore tend to produce overly smooth or blurred results, particularly at large scaling factors. Learning-based Unlike interpolation-based approaches, learning-based upsampling methods leverage DL techniques to enhance feature maps. These methods are capable of recovering fine details and textures that traditional techniques struggle to capture. Standard learning-based strategies include transposed convolution, sub-pixel layers, and meta-upscaling. Transposed Convolution: Transposed convolutions, also referred to as deconvolutions, are commonly used in SR models to increase the spatial size of feature maps [250], [251]. This operation reverses the spatial effects of standard convolutions by inserting zeros between values and applying convolution, effectively expanding feature maps to higher resolutions. Integrated into end-to-end SR models with learnable parameters, transposed convolutions enable adaptive upscaling of feature maps. However, despite their widespread use in SR tasks [252], they can introduce artifacts like uneven overlaps, leading to checkerboard patterns [253]. Sub-Pixel Layer: The sub-pixel layer upscales feature maps by generating additional channels through convolution and rearranging them to form an HR output, process known as pixel shuffle [254]. This method performs upsampling in the channel dimension, providing greater efficiency, especially with smaller kernel sizes, compared to transposed convolutions. Given scaling factor τ and input channels c, the layer produces feature map of size sub-pixel τ 2c, which is then reshaped to τ τ to form the upsampled output. Compared to transposed convolutions, the sub-pixel layer offers larger receptive field, enabling the capture of more contextual information for realistic detail generation, commonly used in many SR tasks [73], [138], [255], [256]. However, the uneven distribution of receptive fields can introduce artifacts, such as blocky regions and 12 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 unsmooth transitions. Meta Upscale: The meta upscale module offers flexibility by enabling arbitrary scaling factors without requiring separate models for different scales [257], [258]. Unlike traditional SR methods, which necessitate predefined scaling factors, this approach leverages meta-learning to dynamically predict convolution weights for each HR position based on small patches of the LR feature map. This allows continuous zooming and adaptive upsampling with single model, minimizing computational overhead while maintaining high performance across various scaling factors, frequently used in MRI SR [108], [259][261]. Learning-based methods represent significant improvement over traditional interpolation, providing superior performance and the ability to recover high-frequency information crucial for SR tasks. 2) Residual Learning: Residual learning is key technique in SR models that focuses on learning the differences, or residuals, between the input LR and the reference HR, simplifying the task by concentrating on reconstructing high-frequency details. It can be broadly categorized into global and local residual learning. Global residual learning targets the residuals between the LR input and HR output, reducing the need to map the entire image. By focusing on residualsmost of which are near zerothis approach reduces model complexity and training difficulty [262], and frequently has been applied in MRI SR [15]. Local residual learning, inspired by ResNet [263], introduces shortcut connections within model layers to prevent gradient vanishing and degradation, allowing deeper models to effectively learn complex features. Both global and local residual learning typically use shortcut connections, often combined through element-wise addition, though concatenation is also possible. Global residual learning enhances highfrequency detail reconstruction, while local residual learning enables deeper models to manage more complex transformations. The integration of both has become widely adopted approach for improving performance in DL-based SR tasks, including MRI SR [95], [264], [265]. 3) Dense Connections: Dense connections link each layer within dense block to all the previous layers, while simultaneously passing its output forward to subsequent layers. This creates highly interconnected architecture that enhances feature reuse and improves gradient flow. By leveraging growth rate optimization and techniques like 1x1 convolutions for channel compression, dense connections not only reduce the model size but also help prevent overfitting. Despite some computational overhead, they significantly improve image quality by fusing lowand high-level features, leading to superior reconstruction of fine details [266]. Dense connections are highly effective strategy for optimizing SR tasks, particularly in high-precision applications like MRI SR [267], [268]. 4) Recursive Learning: Recursive learning enables SR models to capture higher-level features while keeping the number of parameters low by reapplying the same module multiple times [269], [270]. Although recursive learning is effective in enhancing feature extraction, it can be computationally intensive and susceptible to challenges such as vanishing or exploding gradients. Techniques like residual learning are commonly employed to mitigate these issues [176]. 5) Attention Mechanisms: Attention modules enhance SR by steering the network toward the most informative cues across channel, spatial, temporal, and relational domains. Channel Attention: Channel attention re-weights feature maps along the channel dimension so that informative filters contribute more to the reconstruction. Residual channel attention network (RCAN) [271] popularized this idea in SR. The squeeze-and-excitation (SE) block of Hu et al. [272], later adapted to MRI SR [177], captures global channel statistics via pooling, while second-order channel attention (SOCA) leverages covariance information for finer discrimination [273]. Spatial Attention: Spatial attention focuses on highlighting important regions or pixels in an image, directing the models attention to spatially relevant areas to enhance performance [274], [275]. Spatial and Channel Attention: Joint spatialchannel modules let network attend to where (spatial mask) and what (channel mask) simultaneously. Holistic Attention Network (HAN) [276] pioneers this design in SR. Transformer-style self-attention, adopted in SwinIR [277], further models longrange context while preserving local detail. Recent work augments these blocks with multi-scale kernels and gating, enabling coarse-to-fine feature re-calibration and suppressing block artefacts [278], [279]. Spatial-Temporal Attention: Spatio-temporal blocks jointly attend to where (spatial saliency) and when (frame-toframe coherence), making them pivotal for video SR [252] and dynamic MRI. STADNet [280] illustrates the concept: location-aware spatial branch reuses neighbouring frames for detail, while motion-aware temporal branch, guided by optical flow, aligns dynamics. The fused attention improves anatomical fidelity and temporal consistency, reducing blur in cardiac cine MRI. Self-Attention: Self-attention models long-range dependencies by allowing each position in feature map to interact with all others, thereby aggregating richer contextual information than local convolutions. It was first introduced to SR in natural images through Transformer-based architectures such as IPT [281] and SwinIR [277], which demonstrated strong capability in recovering fine textures and global structures. To address the computational burden of full attention, hierarchical and window-based variants have been proposed. In MRI SR, Transformer-based attention mechanisms have been increasingly adopted, for example, in arbitrary-scale reconstruction [259] and multi-contrast SR [282], where they enhance structural fidelity by capturing non-local anatomical relationships. Cross-Attention: Cross-attention enables one feature stream to query another, fusing complementary cues from inputs with differing resolutions or modalities [118]. In multicontrast MRI SR, DCAMSR [283] uses dual cross-attention to align T1and T2-weighted features, while MS2CAM [284] introduces multi-scale self-cross-attention block that exchanges information across spatial scales, producing sharper and more consistent reconstructions. Graph Attention: Graph attention represents voxels (or patches) as nodes and learns edge weights to aggregate nonKHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 13 local context, making it well-suited to multi-contrast MRI SR. GraphSR [285] builds spatially aware graphs to fuse complementary cues across contrasts, sharpening inter-regional detail. lightweight successor, TDAFD [286], couples dual-attention feature distillation with recursive volumetric Transformer, achieving state-of-the-art performance with only 1 parameters. C. Networks Network architectures play an important role in MRI SR by directly mapping LR inputs to HR outputs. Since the introduction of CNNs to image restoration tasks, architectural advancements such as U-Net [287], ResNet [263], and DenseNet [288] have significantly improved SR performance. These models enhance the preservation of fine anatomical details, reduce artifacts, and maintain structural consistency, which is critical in clinical imaging. CNN-based architectures offer strong balance between flexibility and computational efficiency, making them foundational in early and current MRI SR pipelines. As deep learning evolves, innovations have extended beyond traditional CNNs. Attention-based mechanisms and Transformer architectures, such as vision Transformers (ViTs) and SwinIR [277], improve the modeling of longrange dependencies and spatial precision. In parallel, generative AI approachesparticularly those based on GANs [200] and diffusion models [289]have further advanced perceptual quality and anatomical plausibility. These models synthesize realistic HR outputs from degraded inputs, often guided by structural or modality-specific priors. The following sections provide an overview of key network paradigms that have driven progress in MRI SR, highlighting their unique contributions and trade-offs. 1) Convolutional Neural Networks (CNNs): The use of CNNs in SR was first introduced with SRCNN [290], which established an end-to-end learning framework that outperformed traditional interpolation and sparse-coding approaches in both reconstruction accuracy and scalability. This marked turning point for data-driven SR methods, including in medical imaging. Early applications to MRI SR followed soon after. Pham et al. [291] proposed one of the first deep residual CNNs for enhancing brain MRI, while Bahrami et al. [292] employed patch-based 3D CNN to reconstruct 7T-like brain MRI from 3T scans. Building on these foundations, more advanced CNN architectures were adapted for MRI SR. U-Net [287], originally proposed for biomedical segmentation, has been widely adopted for SR tasks, where its encoderdecoder design and skip connections enable effective multi-scale feature extraction and detail preservation [293]. ResNet [263] addressed the vanishing gradient problem and allowed deeper, more stable networks, which were leveraged in models such as DeepResolve [10] for musculoskeletal MRI. DenseNet [288] improved parameter efficiency through dense connectivity and has inspired residual-dense architectures for brain MRI SR [294]. These architectural innovations advanced MRI SR by improving tissue sharpness and reducing noise and aliasing artifacts [97]. For instance, BrainSR [295] leverages dilated convolutions to expand the receptive field without increasing the number of parameters, thereby enabling richer contextual modeling for fine anatomical detail recovery. SpatioResNet [296] further extends CNN-based designs by integrating spatio-temporal residual learning, facilitating effective multicontrast, 3D, and dynamic MRI SR. Collectively, these developments reinforce the central role of CNNs in state-of-the-art MRI SR pipelines. 2) Long-Range Dependency Models: Methods that capture long-range dependencies play key role in SR by going beyond local convolutional receptive fields. These can be grouped into three main families: Vision Transformers (ViTs): ViTs rely on self-attention to explicitly model pairwise interactions across the entire feature map. SwinIR [277], for example, introduced hierarchical, window-based attention to reduce computational complexity while preserving global context. In MRI SR, ViT-style modules have been integrated for multi-contrast fusion [282], cross-scale SR [283], and brain MRI [131], demonstrating improved recovery of fine structures. State-Space Models (SSMs): Recent alternatives to Transformers, such as Mamba [297], [298], replace explicit attention with structured state-space dynamics. These achieve linear scaling with sequence length, offering efficient global context modeling in MRI SR while maintaining competitive accuracy. Hybrid RNNAttention Models: RWKV [299] combines recurrent dynamics with attention-like updates, enabling efficient modeling of long sequences while retaining Transformerlevel expressivity. In MRI SR, such hybrids improve robustness to noise and motion while lowering computational costs compared to full attention. Integration with CNNs: In practice, long-range dependency modules are almost always combined with convolutional backbones. CNNs contribute strong local feature extraction and spatial inductive biasesbuilt-in assumptions about locality, translation invariance, and spatial structurethat ViTs, SSMs, and hybrids do not inherently provide. When used as modular components, long-range mechanisms complement CNNs by capturing global context while CNNs preserve fine local detail. This combination improves SR fidelity without substantially increasing architectural complexity, making it dominant design choice in MRI SR, where anatomical accuracy must be balanced with computational efficiency. 3) Generative Adversarial Networks (GANs): GANs consist of two components, generator G() and discriminator D(), trained in minimax game. The generator synthesizes HR images, while the discriminator learns to distinguish them from ground truth. This adversarial setup encourages perceptually realistic reconstructions, addressing the limitations of pixel-wise regression losses. The first application to SR was SRGAN [238], which combined adversarial and perceptual content losses to recover fine textures beyond conventional methods. ESRGAN [268] further improved visual fidelity through residual-in-residual dense blocks and relativistic discriminator, setting new benchmarks in natural image SR. Building on these advances, GANs have been widely adapted for MRI SR, where anatomical fidelity is critical. SOUPGAN [300] targeted through-plane slice-thickness SR using perceptually tuned adversarial loss, enabling higher-quality 14 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 reconstructions. DISGAN [76] extended this to 3D volumetric data by introducing wavelet-domain discriminator and residual-in-residual dense generators, jointly addressing denoising and SR with improved generalization across contrasts. To incorporate frequency priors, Xiao et al. [301] proposed hybrid frequency-aware GAN that fused Fourier-domain processing with complex-valued residual U-Net, achieving strong performance in both MRI and CT. More recent efforts integrate temporal and Transformer modules: for example, LSTM-Attention-GAN [302] combines recurrent units with attention mechanisms to improve temporal consistency in sequential brain and lung MR scans. Overall, GAN-based approaches have substantially advanced MRI SR by enhancing perceptual realism and structural detail. However, they remain challenged by training instability, mode collapse, and computational overhead. Stabilization strategiessuch as perceptual loss regularization, spectral normalization, and multi-task discriminatorsare commonly employed to mitigate these issues. 4) Diffusion Models (DMs): Diffusion models (DMs) were first applied to image SR in SR3 [289], which demonstrated that iterative denoising can yield high-quality, perceptually realistic HR reconstructions. Unlike GANs, which generate images in single forward pass, DMs synthesize outputs by reversing stochastic diffusion processgradually removing noise over multiple steps. This iterative design improves stability, controllability, and robustness, properties particularly valuable when structural fidelity is critical. Recent work has adapted DMs for MRI SR with promising results. InverseSR [303] leverages latent diffusion prior trained on UK Biobank brain MRI and introduces two inversion strategies: decoderbased and denoising diffusion implicit model (DDIM)-based, enabling flexible HR reconstruction across varying sparsity levels. To accelerate inference, partial diffusion models (PDMs) [86] proposed latent alignment mechanism that reduces the number of sampling steps while maintaining accuracy. Building on the ResShift paradigm [304], ResSRDiff [305] incorporated residual shifting to align voxel distributions between LR and HR MR volumes, achieving high-quality reconstructions in as few as four steps on ultrahigh-field brain and prostate MRI datasets. While diffusion models are computationally demanding, innovations such as latent-space truncation, residual alignment, and accelerated sampling are making them increasingly viable. Compared to adversarial methods, DMs offer more stable training and stronger generalization in the presence of noise, motion, or low SNR, positioning them as compelling alternativeor complementto GANs in next-generation MRI SR. 5) Implicit Neural Representations (INRs): INRs model data as continuous functions that map spatial coordinatesand optionally auxiliary featuresdirectly to signal intensity values. Unlike conventional discrete grid representations, INRs encode entire images or volumes using neural networks (typically multi-layer perceptrons, MLPs) that learn the underlying signal as continuous function: xi = Mθ(ci, fi), (18) where ci Rd denotes the spatial coordinate (normalized to [0, 1] or [1, 1]), fi Rf is an optional feature vector (e.g., Fig. 8: Illustration of INR-based MRI super-resolution. An encoder maps the input image to coordinate feature grid, from which spatial coordinates and corresponding features are sampled. During training, the network learns continuous mapping from coordinates and features to signal intensities. At inference, the trained model can be queried at arbitrary coordinates to generate HR outputs. Inspired from [306] contrast type, modality, or subject embedding), and Mθ is the learnable mapping parameterized by θ. This formulation enables HR image reconstruction by querying the network at arbitrary coordinate locations, and allows the model to jointly leverage spatial and contextual information during optimization. INRs offer several advantages for SR tasks: They eliminate the need for fixed-scale upsampling modules, reduce memory consumption, and naturally enable continuous spatial interpolation [307]. In the context of MRI SR, INR-based methods have been effectively employed to model both individual slices and full volumetric data with high spatial fidelity. Recent studies have significantly expanded the use of INRs across various MRI SR tasks. One of the earliest applications demonstrated volumetric SR via continuous coordinate-based representations [108]. INRs have since been employed in SVR, as in NeSVoR [105], and further enhanced through meta-learning strategies to improve cross-subject generalization in SVR settings [106]. In cardiac MRI and 4D flow MRI, INR-based methods have enabled joint super-resolution and denoising, improving spatiotemporal coherence and data fidelity [308], [309]. For multi-contrast MRI, INRs have been used to learn continuous cross-contrast representations, enabling enhanced synthesis and preservation of contrast-specific features [134], [310][312]. Personalized, patient-specific INR frameworks have also been introduced to capture individual anatomical variability [313]. Cycle-INR [314] recently proposed novel volumetric SR architecture incorporating local attention-based grid sampling and cycle-consistency loss to address over-smoothing and inter-slice inconsistencies common in anisotropic 3D medical images. Furthermore, [245] combined INRs with spherical harmonics to model continuous spatial-angular domains for SR of diffusion MRI, advancing representation fidelity in both spatial and directional dimensions. 6) Gaussian Splatting (GS): GS models images as continuous fields by representing each pixel as spatially adaptive Gaussian rather than discrete sample. While grid-based methods such as INRs rely on coordinate-to-intensity mapKHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 15 enabling temporally consistent enhancement of fetal and abdominal MRI. Similarly, Xu et al. [101] proposed STRESS, self-supervised spatio-temporal SR framework that learns spatial and temporal dependencies without paired HR data, improving consistency in dynamic fetal MRI. These RNNbased approaches are particularly valuable in motion-sensitive or time-resolved MRI, where they enhance temporal continuity, reduce frame-to-frame artifacts, and improve overall reconstruction quality. 8) Graph Convolutional Networks (GCNs): GCNs extend convolution to graph-structured data, enabling the modeling of non-local anatomical relationships that conventional CNNs often miss. In MRI SR, nodes can represent voxels, patches, or regions, with edges encoding spatial or structural similarity, thereby integrating long-range context to improve structural fidelity and reduce artifacts. Isallari and Rekik [322] proposed GSR-Net, graph U-Net for brain connectivity graph super-resolution, demonstrating the feasibility of graph-based learning in neuroimaging. Ma and Cui [323] introduced hybrid CNNGCN framework for diffusion MRI, where CNNs captured local spatial features while GCNs modeled non-local relationships in the diffusion-encoding domain. More recently, Ma et al. [324] developed GCESS, hybrid network combining convolution and patch-based graph convolution to exploit self-similarity, effectively suppressing artifacts and enhancing detail in MRI reconstructions. While still less common than CNNor GAN-based approaches, GCNs offer principled means of embedding anatomical priors into SR pipelines. VII. FOUNDATION MODELS Foundation models (FMs) are large-scale models trained on diverse, heterogeneous datasets with the capacity to generalize across wide spectrum of tasks. They can be efficiently adapted to downstream applications through fine-tuning, transfer learning, or prompting [325]. In contrast to conventional MRI SR approachesoften designed for single modality, anatomy, or acquisition protocolFM-based methods exploit broad prior knowledge and rich feature representations learned from large-scale data. This confers improved adaptability, robustness, and scalability. Within medical imaging, FMs hold particular promise for MRI SR by enabling the incorporation of anatomical priors, semantic conditioning, and multimodal information (e.g., across imaging contrasts or between imaging and text), thereby unifying reconstruction, interpretation, and task-specific reasoning within single framework. A. Recent Foundation Models for MRI Super-Resolution We highlight two representative FM paradigms for MRI SR, which are (i) anatomically guided multi-task enhancement and (ii) Graph-Based Multimodal Semantic Modeling. 1) Anatomically Guided Multi-Task Enhancement (BME-X): the anatomically guided FM BME-X [326] exemplifies paradigm. two-stage pipeline first infers soft tissue labels from low-quality inputs and then reconstructs high-resolution images conditioned on these priors, promoting anatomically plausible detail across motion correction, denoising, harmonization, and SR. Supervision is enabled via synthetic pairing: Fig. 9: Comparison of feature representations between INR and GS. (a) INRs model pixels as discrete point samples; (b) GS represents each pixel as self-adaptive continuous Gaussian field, allowing smooth and explicit evaluation of field values at arbitrary query locations [315]. pings over fixed grids, GS captures local spatial continuity and uncertainty through overlapping Gaussian functions [315], [316], producing smoother and potentially more detailed reconstructions  (Fig. 9)  . The signal intensity at coordinate is defined as: xi = Mθ(ci, fi Σi, ξi), (19) where ci denotes the spatial coordinate, fi the associated feature, Σi the covariance defining spatial extent, and ξi the opacity controlling contribution strength. The Gaussian weighting function is expressed as: Gi(p ci, Σi) = (p ci)(cid:3) , (20) and the aggregated continuous representation is obtained as: 2 (p ci)T Σ exp(cid:2) 1 1 2πΣi1/2 (p) = (cid:88) σ(ξi) Gi(p ci, Σi) fi, (21) where σ() constrains opacity to [0, 1]. This formulation enables differentiable rendering, adaptive interpolation, and interpretable feature modeling. In superresolution, GS provides principled bridge between discrete sampling and continuous signal representation, achieving highfidelity reconstruction across arbitrary spatial scales [315]. While GS has been applied to MRI reconstruction tasks [317], it has not yet been introduced for MRI SR. 7) Recurrent Neural Networks (RNNs): RNNs, particularly long short-term memory (LSTM) and convolutional LSTM (ConvLSTM) architectures, have been employed in SR tasks where temporal or sequential dependencies are critical. Initially popularized in video SR [318], these models capture correlations across frames to improve temporal consistency. Similar strategies have been extended to dynamic MRI, where temporal coherence is equally important. For example, Basty et al. [319] applied SR to cardiac cine MRI, highlighting the benefits of modeling sequential dynamics. Qin et al. [320] used ConvLSTM blocks in interventional MRI, leveraging frameto-frame coherence for real-time, high-fidelity reconstruction. More recently, Chatterjee et al. [321] introduced DDoS-UNet, dual-channel recurrent UNet that conditions each frame on high-resolution planning scan and the previous SR output, IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 TABLE II: Comparison of MRI Foundation Models for Super-Resolution Aspect BME-X [326] GraphMSR [327] Architecture Knowledge Priors Multimodal Input Enhancement Tasks Generalization Scope Downstream Tasks Tissue-aware dual CNN Tissue segmentation maps No SR, denoising, motion correction, harmonization Lifespan, scanners, pathologies Segmentation, registration, diagnosis Graph neural network with attention Semantic prompts (e.g., text embeddings) Yes (text + image) SR (spatial detail and perceptual enhancement) Diverse anatomical regions and LR or artifact-affected MRIs Perceptual SR, diagnostic fidelity segmentation maps synthesize clean HR images, to which realistic degradations (e.g., downsampling, noise, motion blur, intensity bias) are applied to form LR counterparts with tight alignment. Trained on more than 13,000 brain MRI volumes from 19 public datasets spanning fetal to adult cohorts, BMEX demonstrates robustness to motion-corrupted infant scans and cross-domain scenarios (e.g., 3T7T SR). By coupling tissue-aware conditioning with controlled data generation it improves SR fidelity and yields more consistent downstream segmentation and registration."
        },
        {
            "title": "Multimodal",
            "content": "2) Graph-Based image patches, where nodes represent Modeling (GraphMSR): In contrast to the anatomically guided paradigm of BME-X, GraphMSR [327] approaches MRI SR through It constructs adaptive graph-based multimodal reasoning. graphs over local anatomical regions and edges capture contextual or structural relationships. hierarchical graph attention mechanism then models both local detail and global topology. Distinctively, GraphMSR integrates semantic priors derived from large medical language model: clinically relevant descriptors (e.g., anatomical regions, quality attributes, pathological terms) are encoded as text embeddings and fused with image features via cross-attention. This allows the model to emphasize diagnostically important regions while suppressing artefactual content during reconstruction. B. Comparison and Direction BME-X and GraphMSR represent two distinct FM strategies for MRI SR: one relies on explicit tissue priors for broad enhancement, while the other uses semanticgraph reasoning to emphasize perceptual and diagnostic fidelity. Both highlight the unifying potential of foundation models. Table II summarizes their design and capabilities. It should also be noted, however, that reliance on foundation models carries broader concern: errors or biases present in base model may be inherited by all downstream models that build upon it, leading to widespread propagation of the same flaws. VIII. GENERATIVE AI Generative artificial intelligence (GenAI) has emerged as transformative paradigm for MRI SR, enabling the synthesis of HR images by modeling the underlying distribution of anatomical structures. Beyond enhancing perceptual quality, GenAI approaches can integrate prior knowledge and operate in paired or unpaired learning settings. Prominent GenAI frameworks include GANs, variational autoencoders (VAEs), diffusion models (DMs), and normalizing flows (NFs). Each has distinct strengths and limitations: GANs produce sharp, perceptually realistic outputs but may introduce hallucinations and suffer from training instability; VAEs capture uncertainty and enable controllable generation but often yield overly smooth textures; NFs focus on density estimation with diverse sampling but require deep, memoryintensive architectures, making them less practical for largescale applications; and, DMs achieve state-of-the-art fidelity and robustness, albeit with high computational cost; Among these, diffusion models have rapidly gained prominence for MRI SR due to their ability to model complex anatomical distributions, support flexible conditioning, and integrate seamlessly into inverse problem frameworks without retraining. A. Diffusion Models (DMs) for Super-Resolution DMs are generative frameworks that generate high-quality data by reversing gradual noising process [328], [329]. Originally developed for image generation, they now achieve state-of-the-art performance in image synthesis [147], and inverse imaging problems like SR [289]. DMs model complex data distributions and produce high-quality outputs through iterative refinement. All variants share two-stage structure: (I) Forward process: Gradually corrupts clean sample x0 into noisy samples xt over sequence of timesteps = 0, . . . , , eventually producing the final noisy sample xT . (II) Reverse process: neural network learns to denoise xT , step by step, to recover the original data distribution. In SR, this process is conditioned on the observed LR image to ensure fidelity to the input."
        },
        {
            "title": "There are several",
            "content": "formulations of DMs used in MRI including denoising diffusion probabilistic models SR, (DDPMs) [328], score-based generative models (SGMs) [330], stochastic differential equation (SDE)based diffusion models [331], denoising diffusion implicit models (DDIMs) [332], and latent diffusion models (LDMs) [333]each with distinct mathematical formulations and inference procedures. Their respective forward and reverse processes are summarized in Fig. 10 to highlight the connections with the models discussed below. 1) Denoising Diffusion Probabilistic Models (DDPMs): DDPMs model generation as the reversal of fixed noising process. The forward step adds Gaussian noise to clean image x0: q(xt xt1) = (xt; 1 αtxt1, αtI), (22) KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 17 cross-attention-based DDPM that enhances fidelity to LR inputs while preserving fine anatomical details, and Qiu et al. [337] proposed DBSR, quadratic conditional diffusion model for blind cardiac MRI SR that predicts blur kernels from LR inputs and incorporates them into reconstruction via cascaded residual attention network to improve robustness against motion blur. For multi-contrast SR, Chang et al. [338] leveraged conditional diffusion priors for detail restoration in MRI synthesis. Li et al. [138] proposed DiffMSR, performing diffusion in compact latent space to produce high-frequency priors decoded by prior-guided large window Transformer (PLWformer) for efficient reconstruction. Chen et al. [339] introduced EgDiff, an edge-guided conditional diffusion model that injects contrast-adaptive edge features and applies adaptive multimodality fusion to preserve anatomical boundaries. Mao et al. [340] presented DisC-Diff, disentangled conditional diffusion framework that separates shared and modality-specific features, enhancing robustness and fidelity across contrasts. 2) Score-Based Generative Models (SGMs): SGMs synthesize data by following the score function, i.e., the gradient of the log-density xt log pt(xt) [330]. The forward process perturbs clean data with Gaussian noise: xt = x0 + σtϵ, ϵ (0, I), while sampling is performed via the reverse-time SDE: dxt = [f (xt, t) g2(t)xt log pt(xt)] dt + g(t) wt, (26) (27) where the score xt log pt(xt) is approximated by neural network sθ(xt, y), conditioned on the observed LR image. Training is done via denoising score matching, where the model learns to approximate the true score from noisy inputs: LDSM = Ex0,ϵ,t (cid:34)(cid:13) (cid:13) (cid:13) (cid:13) sθ(xt, y) + 2(cid:35) (cid:13) (cid:13) (cid:13) (cid:13) 1 σt ϵ . (28) SGMs allow flexible sampling using Langevin dynamics or probability-flow ODEs. Conditioning on ensures that the reconstructed HR outputs are consistent with the measured LR data. Liu et al. [341] addressed the challenge of limited cardiac MR data with tailored score learning. Cao et al. [342] focused on high-frequency recovery to accelerate sampling. Wu et al. [343] employed wavelet-domain decomposition for artifact suppression, while Hou et al. [344] proposed FRSGM, integrating ensemble denoisers and spatial self-consistency for fast, robust MRI reconstruction. 3) Stochastic Differential Equation (SDE)-Based Diffusion Models: SDE-based models generalize SGMs by formulating the forward process as continuous-time stochastic differential equation [331]: dx = (x, t) dt + g(t) dwt, (29) where is the drift term, controls the noise scale, and denotes standard Brownian motion. The reverse-time SDE is given by: dx = [f (x, t) g2(t)x log pt(x y)] dt + g(t) wt, (30) where the score function log pt(x y) is approximated by neural network conditioned on the LR image y. Fig. 10: Summary of forward and reverse processes in three major diffusion model formulations: DDPMs, SGMs, and SDE-based models. The bottom row illustrates the forward processes (in red), where clean data x0 is progressively corrupted using Gaussian noise or stochastic dynamics. The top row shows the corresponding reverse processes (in blue): DDPMs perform noise prediction and Gaussian denoising; SGMs apply Langevin dynamics based on learned score functions; and SDE-based models use reverse-time trajectories guided by continuous-time score estimates. Adapted from [23]. with the closed-form: xt = γtx0 + (cid:112)1 γtϵ, ϵ (0, I). (23) The reverse process is modeled as: pθ(xt1 xt, y) = (xt1; µθ(xt, y, t), Σθ(xt, y, t)), (24) where neural network predicts noise-conditioned parameters using the LR input y. Instead of recovering x0 directly, the network estimates the noise: ϵ ϵθ(xt, y)2(cid:105) (cid:104) LCDM = Ex0,ϵ,t (25) . This loss simplifies training and improves sampling. Conditioning on enforces consistency with the measured data. In MRI SR, conditional DDPMs have been adapted for various reconstruction tasks. Wu et al. [334] proposed brain MRI SR framework improving structural fidelity, later extending it with multi-scale self-attention, channel reduction for faster training, and achieving state-of-the-art perceptual quality on T1and diffusion-weighted MRI. Zhao et al. [335] introduced the partial diffusion model (PDM), which initializes from an LR-derived intermediate to cut denoising steps and inference time without quality loss. Ma et al. [336] developed 18 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 Like SGMs, training is done via score matching, where the network learns to approximate the conditional score. Sampling can be performed using numerical solvers (e.g., EulerMaruyama) or deterministic probability-flow ODEs, offering flexibility and stability during inference. While less common in current practice, SDE-based models provide principled framework for incorporating uncertainty, adaptive priors, and continuous-time regularizationvaluable for robust and interpretable MRI reconstruction. [332] non-Markovian (DDIMs): and 4) Denoising Diffusion introduce Implicit Models often DDIMs deterministic sampling strategy that preserves the marginal distributions of DDPMs under fixed noise schedule. Unlike DDPMs, DDIMs allow step skipping, mapping xt+n xt directly over sparse subset of timesteps (skip factor n), controlled by stochasticity parameter η, where η = 0 yields fully deterministic process (see Fig. 11). typical update rule is: xt = γt ˆx0 + (cid:112)1 γt ϵθ(xt+n, + n), (31) where ˆx0 is the predicted clean image, and γt is the cumulative noise factor. In MRI SR, DDIMs are widely adopted as inferencetime accelerators. They are particularly effective in handling distribution shifts via diffusion prior adaptation [90]. Examples include InverseSR [303], which performs DDIM sampling in latent space for faster 3D brain SR, and PDM [335], which skips early steps using LR-derived latents. Res-SRDiff [305] further improves efficiency via residual-based initialization, achieving high-fidelity results in just few steps. Fig. 11: Illustration of DDIM sampling: instead of traversing the model maps xt+n xt using learned all steps, deterministic (or semi-stochastic) function conditioned on y. This enables accelerated inference by skipping intermediate states while preserving fidelity. 5) Latent Diffusion Models (LDMs): LDMs [333] perform diffusion in the latent space of pretrained autoencoder, substantially reducing computational cost compared to pixelspace generation. frozen autoencoder consists of an encoder E, which maps an input image to compact latent representation = E(x), and decoder D, which reconstructs the image as = D(z). Diffusion is applied only in the latent space. In MRI SR, the latent formulation enables efficient 3D reconstruction. Wang et al. [303] introduced InverseSR, training an LDM prior on UK Biobank brain data for highquality 3D SR inference. Yoon et al. [345] showed that latent diffusion substantially improves Alzheimers and mild cognitive impairment classification by preserving diagnostic features. Mármol-Rivera et al. [346] extended LDM-based SR to arbitrary zoom factors, enabling flexible and consistent upscaling across resolution levels. Compared to pixel-space accelerations such as DDIM, which reduce inference time by skipping denoising steps, LDMs achieve efficiency at the representation level and can be combined with DDIM-style step reduction for further speed gains. 6) Frequency-Domain Diffusion Models: Instead of operating in the pixel or latent space, frequency-domain diffusion models apply noise corruption and denoising in the frequency space (e.g., wavelet or Fourier domain). This approach is particularly well suited for MRI SR, where high-frequency components contain critical diagnostic information. Wu et al. [343] proposed wavelet-domain DDPM that suppresses noise and artifacts while preserving fine structures. Similarly, Cao et al. [342] introduced frequency-aware SGM that processes high-frequency bands separately, improving perceptual quality and sampling efficiency. These methods exploit the structured sparsity of MRI frequency content and provide robustness against noise and aliasing. Frequency-based models can also be combined with latent or DDIM accelerations, making them flexible for clinical deployment. 7) Mixture of Diffusion Models (MDMs): Mixture-of-experts (MoE) diffusion models route inputs to specialized denoisers to better capture anatomical variability and acquisition differences. In MRI SR, Wang et al. [217] introduce region-aware gating mechanism that assigns anatomy-specific diffusion experts, enhancing fine-detail preservation and robustness across contrasts and sites. This specialization mitigates single-model brittleness and homogenization but adds complexity in expert calibration and potential boundary artefacts. MDMs thus offer scalable approach to SR by leveraging diverse priors without retraining monolithic model. 8) Diffusion Models for Imaging Inverse Problems via Posterior Estimation: In many real-world inverse problems, such as super-resolution (Eq. 1), only the degraded observation is available, and paired LR-HR datasets are not available for supervised training. Diffusion models address this challenge by serving as powerful generative priors for posterior sampling, enabling accurate image reconstruction without retraining. they approximate the posterior p(x y) by Specifically, combining denoising prior with fidelity term, following KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 19 reconstruction accuracy and latent regularization: LVAE = Eqϕ(zx,y)[log pθ(x z, y)] KL(qϕ(z x, y) p(z)) . (34) The reconstruction term enforces HR fidelity, while the KL divergence regularizes the latent posterior toward the prior, enabling sampling and smooth interpolation [351]. VAEs provide fast inference and structured latent spaces, but Gaussian decoders often produce over-smoothed textures [352], [353]. In MRI SR, Andrew et al. [354] proposed lightweight autoencoder framework for brain MRI SR that surpasses conventional CNN-based approaches in PSNR, SSIM, and computational efficiency. Kapoor et al. [355] developed multiscale VAE for 3D brain MRI, enhancing anatomical variability and perceptual realism. Despite these advances, VAEs generally lag behind diffusion-based methods in perceptual quality and fine-detail reconstruction. Fig. 13: Illustration of the VAE-based MRI super-resolution framework. The encoder qϕ(z x) approximates the posterior over latent variables given HR ground truth and LR input y, while the decoder pθ(x z, y) reconstructs the HR image. Training maximizes the ELBO to balance fidelity and latent regularization. 2) Normalizing Flow Models (NFMs): Normalizing flows transform simple base distribution (e.g., standard Gaussian) into complex target distribution via sequence of invertible mappings: = fK f1(z), (0, I), (35) where each fk is bijective and differentiable. This property allows the exact computation of the data log-likelihood using the change-of-variables formula: log p(x) = log p(z) + (cid:88) log det (cid:12) (cid:12) (cid:12) (cid:12) (cid:18) fk hk1 (cid:19)(cid:12) (cid:12) (cid:12) (cid:12) , (36) k=1 where hk1 is the intermediate representation before fk. For SR, conditional flows model p(x y) by incorporating LR features into each transformation, enabling both exact likelihood estimation and the generation of diverse HR outputs by sampling different z. In MRI SR, Ko et al. [356] introduced MRIFLow, conditional flow model producing anatomically consistent and diverse reconstructions, while Dong et al. [357] proposed multi-scale invertible network to improve fidelity across contrasts. Despite their flexibility, NFMs often require deep architectures to be expressive, which can increase memory and computational cost. 3) Generative Adversarial Networks (GANs): GANs were first introduced in Section VI-C.3 from network architecture standpoint. In this section, we revisit them through the lens of generative modeling, highlighting their adversarial training dynamics and applications in MRI super-resolution. Fig. 12: Overview of diffusion corruption spaces in MRI SR. Top: Forward (red) and reverse (blue) denoising steps. Bottom: Three types of domains in which the diffusion process occurs(i) pixel-based diffusion, operating directly on image pixels; (ii) latent space diffusion, operating in latent representation obtained via an encoder (E) and mapped back through decoder (D); and (iii) frequency-based diffusion, operating in transformed domain (T ) and its inverse (iT ), such as wavelet or Fourier. Adapted from [23]. the identity: log p(x y) = log p(x) + log p(y x). (32) This decomposition underlies iterative sampling schemes that alternate between denoising stepusing the learned score log p(x)and measurement consistency stepdriven by the likelihood gradient log p(y x). Such strategies, commonly referred to as posterior sampling, enable solving inverse problems without retraining. during Representative approaches include ILVR [347], which components sampling; aligns low-frequency DDRM [348], which closed-form posterior leverages means for linear measurements; and DPS [349], which injects explicit likelihood gradients into the diffusion trajectory. These methods have demonstrated strong results across wide range of imaging tasks. For broader taxonomy and analysis of diffusion-based inverse solvers, refer to the survey by Daras et al. [350]. B. Alternative Generative Models for Super-Resolution While diffusion models currently dominate generative SR, alternative paradigmsvariational autoencoders (VAEs) and normalizing flows (NFs)offer complementary trade-offs in inference speed, interpretability, and likelihood estimation. 1) Variational Autoencoders (VAEs): For SR, VAEs adopt probabilistic latent-variable framework in which an encoder qϕ(z x, y) approximates the posterior distribution over latent variables given the HR target and its LR counterpart y. decoder pθ(x z, y) then reconstructs the HR image from the latent representation: p(z), pθ(x z, y), (33) where p(z) is typically standard Gaussian prior. Training maximizes the evidence lower bound (ELBO), which balances 20 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 contentcommonly termed hallucinationsthat do not correspond to true tissue structures. Such artifacts pose critical concerns in clinical applications, where diagnostic reliability and anatomical accuracy are paramount. GANs provide compact and often interpretable latent space, enabling intuitive sampling and interpolation. However, they are prone to mode collapse and may inadequately cover the full data distribution. This can result in samples that appear realistic but deviate from physiological plausibility. VAEs learn smooth, probabilistic latent representation that promotes broader mode coverage compared to GANs. Yet, their reliance on pixel-wise reconstruction often leads to overly smoothed or blurry outputs, limiting their utility in tasks demanding high-frequency detail. DMs avoid using compact latent embeddings. Instead, they generate images by progressively denoising high-dimensional noise over multiple steps. This iterative process enables excellent coverage of the data distribution and minimizes hallucination risk. However, because DMs do not rely on structured latent space, their internal representations are less interpretable and offer limited direct control over the generation processpotentially posing challenges for clinical integration where transparency and fine-grained control are important. 2D vs. 3D Super-Resolution: Most generative models for SR are designed for 2D data, which simplifies computation but overlooks cross-slice dependencies. Extending these approaches to 3D SR poses challenges due to the increased memory requirements and the need to maintain spatial continuity across volumetric dimensions. IX. PERFORMANCE EVALUATION A. Image Quality Assessments Image quality assessment (IQA) is crucial to ensure the accuracy and reliability of HR images generated by MRI SR algorithms for clinical and research applications. IQA methods are generally classified into subjective and objective approaches. Subjective methods rely on expert evaluation, closely aligning with human perception but are timeconsuming and costly. In contrast, objective methods use computational algorithms to efficiently quantify distortions, reducing cost, bias, and inconsistencies from human evaluation. However, objective methods often fail to fully capture the nuanced aspects of human visual perception that are critical in clinical settings. IQA can be conducted using full-reference methods, which compare generated HR images to reference, or no-reference methods, which assess image quality without requiring reference. This section explores both subjective and objective IQA metrics, highlights the need for learning-based IQA approaches in MRI SR, and discusses the critical tradeoffs between perceptual quality and distortion evaluations. 1) Peak Signal-to-Noise Ratio (PSNR): The PSNR is fullreference IQA metric that measures the quality of reconstructed image compared to the original reference image. It is expressed in decibels (dB) and is calculated using the Fig. 14: Illustration of normalizing flow model. simple base distribution z0 p0(z0), typically standard Gaussian, is transformed through sequence of invertible functions f1, . . . , fK into complex target distribution = zK. The forward (generation) path increases distribution complexity, while the reverse (normalization) path enables exact likelihood computation and inference. Adapted from [358]. GAN-based SR methods consist of generator Gθ() that produces HR images ˆx = Gθ(y) from LR inputs y, and discriminator Dϕ() that assesses whether the generated images are real or generated. The training involves min-max game with the following objective functions: min Gθ max Dϕ Ladv(Gθ, Dϕ) = Exp(x)[log Dϕ(x)]+ Eyp(y)[log(1 Dϕ(Gθ(y)))], (37) where p(x) denotes the distribution of real HR images, and p(y) is the distribution of LR inputs. Additionally, perceptual or content losses are often used to ensure fidelity to the ground truth. GAN-based SR methods have been extensively studied in MRI [267], [300], [359] prior to the emergence of diffusion models, due to their one-pass generation (hence, fast), memory efficiency, and ability to produce perceptually realistic images. Fig. 15: Overview of GAN-based super-resolution. The generator Gθ maps the LR image to an estimated HR image ˆx, while the discriminator Dϕ distinguishes real HR images from generated ones. The training is adversarial, encouraging the generator to produce perceptually realistic outputs aligned with the HR data distribution. Adapted from [38]. C. Challenges with GenAI Hallucinations and Latent Space Limitations: Generative models may produce anatomically implausible or unrealistic KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 21 TABLE III: Image Quality Assessment Metrics in Super Resolution Metric Formula Peak Signal-to-Noise Ratio (PSNR) PSNR = 10 log (cid:17) (cid:16) MAX2 MSE Structural Similarity Index (SSIM) SSIM = (x, ˆx) = [Cl(x, ˆx)]α [Cc(x, ˆx)]β [Cs(x, ˆx)]γ Visual Information Fidelity (VIF) VIF = (cid:80) I(Ref;DistortedHVS) (cid:80) I(Ref;Ideal) Contrast-to-Noise Ratio (CNR) CNR = µROIµbackground σnoise Task-based Evaluation Evaluates performance in downstream tasks Mean Opinion Score (MOS) Aggregates human ratings of image quality Description Full-reference Measures distortions (dB) Range: [0, ), typically [20, 40] dB Full-reference Measures perception Range: [0, 1] Full-reference Measures perceptual information preserved Range: [0, 1] No-reference Measures contrast against noise Range: [1, ), typically > 1 Full or No-reference Measures perception/distortion/fidelity Range: Variable, depending on task and metric Full or No-reference Measures perception Range: [1, 5] (poor to excellent) following formula: PSNR = 10 log10 (cid:19) (cid:18) MAX2 MSE (38) Where MAX is the maximum possible pixel value of the image (e.g., 255 for an 8-bit grayscale image). And MSE is the mean squared error, which represents the average of the squared differences between the original and reconstructed pixel values over all pixels in the image. Although PSNR is commonly used as quality metric in SR, it does not fully align with human visual perception. Techniques that focus on optimizing voxel- /pixel-level correlations, which often lead to higher PSNR values, can produce outputs that are overly smooth and lack intricate details. In contrast, GANs, which are designed to enhance fine details, may result in lower PSNR scores, highlighting the discrepancy between PSNR values and human perception of image quality [289]. 2) Structural Similarity Index (SSIM): The SSIM is fullreference IQA metric designed to assess the structural similarity between images, taking into account the characteristics of the human visual system [360]. It evaluates images based on their luminance (Cl(x, ˆx)), contrast (Cc(x, ˆx)), and structural (Cs(x, ˆx)) contents as follows: Cl(x, ˆx) = Cc(x, ˆx) = 2µxµˆx + c1 + µ2 µ2 ˆx + c1 2σxσˆx + c2 + σ2 σ2 ˆx + c2 , , Cs(x, ˆx) = σxˆx + c3 σxσˆx + , (39a) (39b) (39c) here, µx and σx denote the mean and standard deviation of image x, and σxˆx represents the covariance between images and ˆx. c1, c2, and c3 are small positive constants introduced for stability in the calculations. The SSIM score is defined by, SSIM(x, ˆx) = [Cl(x, ˆx)]α[Cc(x, ˆx)]β[Cs(x, ˆx)]γ, (40) where α > 0, β > 0, and γ > 0 are control parameters that offer flexibility to adjust the relative importance of luminance, contrast, and structural information in the overall SSIM measurement. It is worth noting that SSIM operates on small windows, typically with dimensions like 11 11, and the final reported value is derived from the mean SSIM scores across these windows. Multi-scale SSIM [361] was then introduced to better capture image quality across different resolutions by analyzing the image at multiple scales. This approach provides enhanced sensitivity to variations in viewing conditions, making it more robust in applications where image quality assessment needs to account for multiple levels of detail. 3) Visual Information Fidelity (VIF): The VIF is fullreference IQA metric that quantifies the amount of visual information preserved in distorted image relative to reference, based on statistical models of natural scenes and the human visual system (HVS) [362]. The reference image is modeled using Gaussian scale mixtures in the wavelet domain, and distortions are assumed to result from signal attenuation and additive noise. The HVS is approximated by set of local frequency-selective channels followed by contrast masking mechanism. VIF is calculated as the ratio of two mutual information terms: VIF = (cid:80) ksubbands I(Reference; Distorted HVS) (cid:80) ksubbands I(Reference; Ideal HVS) (41) Here, the numerator estimates the information that human observer (modeled by the HVS) can extract from the distorted image. The denominator represents the maximum extractable information by an idealized human visual system with perfect perception and no distortion. VIF scores typically range from 0 to 1, where higher values indicate better perceptual quality. Compared to PSNR or SSIM, VIF correlates more strongly with subjective human evaluations and is gaining adoption in perceptual assessments of MRI SR [326]. 4) Contrast-to-Noise Ratio (CNR): The CNR is noreference IQA metric that quantifies the contrast between IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 region of interest (ROI) and the background, relative to the level of noise in the image [363], with the following calculation: CNR = µROI µbackground σnoise (42) where µROI is the mean intensity of the region of interest, µbackground is the mean intensity of the background, and σnoise is the standard deviation of the noise. higher CNR value indicates better differentiation between the ROI and the background, which is crucial for detecting fine structures in MRI. 5) Task-based Evaluation: SR models are frequently assessed based on their impact on downstream tasks, particularly in medical imaging. Original and reconstructed HR images are input into pre-trained models, and reconstruction quality is inferred from changes in task performance. This is particularly relevant for applications such as tumor segmentation [293], detection [364], and segmentation [108], where the effectiveness of SR models is determined by improvements in key clinical outcomes. Recent work has also demonstrated that SR can influence downstream morphometric analyses. For example, Nian et al. [365] used 3D-EDSR model to generate multiresolution MRI volumes and systematically evaluated thickness estimation how spatial resolution affects cortical across multiple processing pipelines. 6) Mean Opinion Score (MOS): The MOS is an IQA technique that relies on qualitative evaluation methods. In this approach, human raters are asked to assess the perceptual quality of images, providing scores that typically range from 1 (poor) to 5 (excellent). The mean value of these scores is used to represent the overall performance. [366], [367] Although MOS provides perceptual assessment through human judgment, it is prone to biases, non-linear perception scales, and inconsistencies in rating criteria [18]. 7) Advancing MRI-Specific IQA: Accurate and clinically meaningful evaluation of super-resolved MRI requires domainspecific IQA techniques. This section reviews recent progress, emerging needs, and future directions for MRI-tailored IQA. MRI-specific Metrics: Recent work has focused on MRIspecific no-reference IQA metrics, addressing contexts where ground truth is unavailable. For example, Stepien et al. [368] developed deep learning IQA model that correlates strongly with radiologists perceptual ratings. Meanwhile, Rubert et al. [369] proposed the brain mask inlier fraction, task-specific metric for evaluating super-resolved fetal brain MRI reconstructions. This metric demonstrated high concordance with expert ratings and enabled adaptive scan terminationfacilitating more efficient and reliable clinical workflows. Clinical validation of knee MRI SR is presented in [370], whereas its impact on spinal cord imagingspecifically regarding lesion detection sensitivity, interrater variability, and clinical utilityis assessed in [371]. Multi-center fetal MRI SR is addressed in [372], where quality-aware generative model is proposed to handle acquisition variability and improve both visual and segmentation outcomes. Need for Learning-Based Perceptual IQA: In computer learning-based IQA methods such as NIMA [373] vision, and LPIPS [374] assess perceptual quality using deep feature Fig. 16: The perception-distortion trade-off in image restoration algorithms reveals fundamental challenge: Regardless of algorithmic differences, there is region in the perceptiondistortion plane that remains unattainable. When algorithms approach this region, improve either distortion or perceptual quality, not both simultaneously [353], [378]. the choice emerges: representations. Adapting these approaches to MRI SR may better reflect clinical relevance than traditional metrics like PSNR or SSIM. Recent work [375] benchmarked 35 IQA metrics using 14,700 expert scores across MRI tasks, showing that metric performance varies with network architecture and that some perceptual metrics align closely with radiologist evaluationshighlighting the importance of developing MRIspecific IQA tools. Assessing Synthetic MRI Images: Recent work [376] highlights the limitations of commonly used no-reference IQA metrics in evaluating generative models for medical imaging. Using brain MRI data, the study shows that many metrics poorly reflect clinical relevance, particularly in detecting localized anatomical errors or assessing suitability for downstream tasks. It underscores the need for task-aware, clinically validated evaluation frameworks when assessing synthetic medical images. Emerging Directions: Multi-Modal Language Models In computer vision, multi-modal language models have been explored for image quality assessment by integrating visual and textual information [377], offering promising direction for future MRI IQA development. 8) Perception-Distortion Trade-off: Evaluating SR image quality is inherently challenging due to the trade-off between distortion-based metrics (e.g., PSNR) and perceptual metrics (e.g., expert ratings). While distortion metrics assess pixellevel fidelity, they often fail to capture perceptual realism. Conversely, optimizing for perceptual quality may increase pixel-wise errors. This fundamental trade-off implies that improving one often degrades the other (see Fig. 16). Consequently, balanced evaluation strategycombining both metric typesis essential. In scientific and clinical contexts, unlike generic computer vision tasks, greater emphasis is often placed on distortion fidelity, though perceptual quality remains critical consideration. KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 23 TABLE IV: Benchmark MRI Datasets Used in Super-Resolution Studies Dataset Name fastMRI [380], [381] NAMIC [382] IXI [383] HCP [384], [385] dHCP [386] CRL [387] EPI [388] BraTS [389][391] Body Part Knee Brain Brain Brain Brain Neonatal Brain Fetal Brain Fetal Brain Brain (Tumor) MRI Acceleration # Subjects Field Strength (T) Purpose 1.5, 3 1.5, 3 1.5, 3 1.5, 3 3, 7 3 3 3 1.5, 1,398 6,970 20+ 581 1,200 500+ 80 111 350+ Segmentation, SR Brain Imaging Connectomics Early Development Brain Atlas EPI Time Series Tumor Segmentation Modality sMRI (T2, PD) sMRI (T1, T2, FLAIR) sMRI (T1, T2), dMRI, fMRI, PD, MRA sMRI (T1, T2, PD), dMRI, MRA sMRI (T1, T2, FLAIR), fMRI, dMRI sMRI (T1, T2), fMRI sMRI (T2) fMRI sMRI (T1, T1c, T2, FLAIR) B. Benchmark Datasets This section organizes benchmark datasets based on imaging modalities, anatomical focus (brain, body), and field strength, as summarized in Table IV. The imaging modalities discussed include standard MRI sequences [379]: Structural MRI (sMRI): Includes T1-weighted (T1w), T2-weighted (T2w), PD, and FLAIR sequences used to characterize brain and anatomical structures. Proton Density-weighted (PD): Offers high anatomical detail by minimizing T1 and T2 contrast. Fluid-Attenuated Inversion Recovery (FLAIR): Suppresses cerebrospinal fluid (CSF) signals to highlight lesions. Diffusion-Weighted Imaging (DWI) and Diffusion Tensor Imaging (DTI): Assess microstructural tissue properties and white matter tracts. Magnetic Resonance Angiography (MRA): Visualizes blood vessels using MRI. Functional MRI (fMRI): Measures brain activity using blood-oxygen-level-dependent (BOLD) contrast, including resting-state and task-based protocols. 1) fastMRI: The fastMRI dataset provides fully sampled and retrospectively undersampled multi-coil k-space data for knee and brain MRI [380], [381]. It includes PD and PD with fat suppression (PD-FS) sequences for the knee, as well as T1w, T2w, and FLAIR sequences for the brain. The dataset is designed to support machine learning research in MRI reconstruction, acceleration, and super-resolution. 2) IXI: The IXI dataset contains nearly 600 MRI scans from healthy adult volunteers across three hospitals in London, acquired at 1.5T and 3T field strengths. Each subject includes T1w, T2w, PD, DWI, and MRA sequences [383]. 3) HCP: The Human Connectome Project (HCP) provides high-resolution MRI data from approximately 1,200 healthy adults, covering both structural and functional imaging. It includes T1w, T2w, fMRI (resting-state and task-based), and DWI modalities acquired at 3T; subset of participants also underwent 7T imaging [384], [385]. 4) dHCP: The Developing Human Connectome Project (dHCP) provides high-resolution structural and functional MRI data of neonates. The latest release includes imaging data from 558 subjects, with T1w, T2w, and resting-state fMRI scans acquired at 3T using motion-robust protocols and dedicated neonatal head coil [386]. modal brain MRI data from over 20 healthy subjects. It includes T1w, T2w, PD, DWI, fMRI, and MRA modalities, acquired at 1.5T and 3T. The dataset supports research in segmentation, registration, and super-resolution [382]. 6) CRL: The Computational Radiology Lab (CRL) fetal brain atlas dataset provides in utero T2w MRI scans of fetuses with gestational ages ranging from 21 to 38 weeks. The data were acquired at 3T using motion-robust protocols and were used to construct normative spatiotemporal atlas of fetal brain development [387]. 7) EPI: The EPI dataset contains fetal echo-planar imaging (EPI) time series from 111 in utero MRI sessions, spanning gestational ages from 25 to 35 weeks. It was developed to study spontaneous fetal brain activity and supports motion correction and fetal fMRI research [388]. 8) BraTS: The Brain Tumor Segmentation (BraTS) dataset is curated for the development and benchmarking of glioma segmentation algorithms. It comprises multimodal MRI scans, including T1w, T1-weighted post-contrast (T1c), T2w, and FLAIR sequences, from patients with highand low-grade gliomas. The scans are acquired at 1.5T and 3T and include expert-annotated tumor subregions [389][391]. 9) Other Public Repositories Suitable for MRI SR: While the datasets in Table IV are commonly used when evaluating MRI SR methods, several large public repositories host MRI data that are highly suitable for SR studies but remain underutilized. These sources provide diverse scanners, protocols, and resolutions, enabling rigorous evaluation of generalization, domain shift, and reliability. Some examples include: OpenNeuro (formerly OpenfMRI): large archive of BIDScompliant datasets across sMRI, fMRI, and dMRI, including multi-site 3T and 7T acquisitions [392], [393]. Medical Segmentation Decathlon (MSD): MSD included ten-task collection of 2,633 3D volumes across diverse anatomies/modalities. Designed for segmentation, but its MRI subsets (Brain, Hippocampus, Cardiac, Prostate) with heterogeneous protocols and anisotropic voxels make it practical SR testbed, enabling standardized downstream evaluation (e.g., segmentation). [394], [395] Alzheimers Disease Neuroimaging Initiative (ADNI): multi-site, longitudinal Alzheimers disease cohort with standardized MRI at 1.5/3T (T1w, T2w, FLAIR, dMRI, fMRI, and ASL; PET is also available). ADNI distributes raw MRI and automated derivatives (e.g., FreeSurfer). [396] 5) NAMIC: The NAMIC dataset, developed under the National Alliance for Medical Image Computing, provides multiThe Cancer Imaging Archive (TCIA): large-scale repository of de-identified medical images, including numerous MRI 24 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 TABLE V: MRI Scanner Field Strength and Applications"
        },
        {
            "title": "Field Strength",
            "content": "Typical Use / Regions Ultra-low (<0.1T) Low-field (<1.0T) Mid-field (1.01.5T) High-field (3.0T) Ultra-high (7.0T) Portable and bedside imaging used in emergency rooms, rural clinics, and low-resource settings. Basic imaging in lowand middle-income Countries; cost-effective in infrastructure-limited regions. Standard diagnostic workhorse globally; both developing and developed countries. High-resolution imaging; widely adopted in high-income countries. Used mainly for research and specialized clinical cases in high-income centers. collections spanning brain, breast, prostate, and other cancers. TCIA provides multi-institutional, multi-sequence data (e.g., T1w, T2w, DWI), often with accompanying clinical and genomic information, making it highly valuable for SR studies involving oncology and cross-domain generalization. [397] X. GLOBAL ACCESS AND CLINICAL APPLICATIONS A. Technology Distribution, Economic Significance, and the Importance of Super-Resolution According to OECD statistics, there are an estimated 65,000 MRI scanners worldwide, corresponding to roughly 7 units per million population [398], [399]. Access is highly unequal: high-income countries average over 25 scanners per million people, while lowand middle-income countries have around 1 scanner per million, and approximately two-thirds of the global population has little or no access to MRI [400], the majority of systems [401]. In terms of field strength, in high-income countries are midto high-field (1.5 and 3 T), whereas substantial proportion of scanners in some countries (e.g., 50% in China, 42% in Japan) operate below 1.5 [401]. Ultra-high-field (7 and above) systems remain confined to research centers, while ultra-low-field and portable MRI are emerging as cost-effective options for point-of-care imaging in resource-limited environments, where super-resolution techniques can help mitigate lower SNR and resolution [398], [402]. Democratized MRI: Democratizing MRI through affordable portable systems, especially in low-income countries, can greatly enhance healthcare access by providing advanced imaging without the high costs and infrastructure needs of traditional MRI. Ultra-low-field MRI systems, like 0.055T, paired with SR techniques, can improve image quality by reconstructing HR images like those acquired by higher-field MRI [403][406]. This allows for more accurate diagnoses using cost-effective equipment, making high-quality MRI accessible in under-resourced areas and supporting equitable healthcare [407]. XI. THEORETICAL AND CONCEPTUAL FOUNDATIONS A. Theoretical Limits of Bandwidth Extrapolation in Super-Resolution Classical signal processing theory defines fundamental limits on how much high-frequency information can be recovered in SR. Youla and Webb [433] established the feasibility of image reconstruction as the intersection of multiple physical constraint sets using alternating orthogonal projections, providing general geometric framework for inverse problems. Building on this, Donoho [434] derived rigorous stability bounds for bandwidth extrapolation, showing that reliable recovery of frequencies beyond the diffraction or sampling limit is fundamentally impossible without strong priors: even minimal noise causes unbounded amplification. Under sparsity assumptions, partial super-resolution becomes theoretically attainable, but stability degrades rapidly with increasing resolution factors. These foundational results underscore that classical SR is fundamentally constrained by the physics of sampling and noise. In contrast, modern learning-based methods sidestep these limitations by synthesizing perceptually plausiblethough not strictly accuratehigh-frequency details, reflecting the perceptiondistortion trade-off [353]. B. Denoising, Deblurring, Inpainting, and Super-Resolution: View of Inverse Imaging Denoising, deblurring, inpainting, and SR are classical inverse imaging problems, unified under common goal: recovering high-fidelity image from degraded observation y. As introduced in Section II, the SR problems can be described by, = Hδ(x) = (Γ(x) κ) +n, where the degradation operator Hδ incorporates spatial transformation Γ, blur kernel κ, downsampling s, and additive noise n. The specific inverse problem is determined by which of these degradation components are active: Denoising: B. Applications of MRI Super-Resolution MRI super-resolution (SR) has been applied across broad spectrum of medical imaging domains. By computationally enhancing spatial resolution without increasing acquisition time, SR improves anatomical visualization, diagnostic accuracy, and quantitative analysis in both human and animal studies. Table VI summarizes representative application areas where MRI SR contributes to improved image quality, supporting both clinical practice and research. = + with Γ = I, κ = δ, = 1 Remove additive noise from otherwise clean images. Deblurring: = κ + with Γ = I, = 1, κ = δ Restore image sharpness degraded by blurring. Inpainting: = + with {0, 1}W KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 25 TABLE VI: Representative Applications of MRI Super-Resolution Across Medical Imaging Application Area Description / Benefit Image-guided surgery & Interventions Neurodegenerative disorders Pediatric & Fetal imaging Robotics & Navigation Point-of-Care / Emergency Atlas reconstruction Oncologic imaging Cardiovascular imaging Spinal & Musculoskeletal imaging Specialized modalities Functional & Metabolic imaging Radiomics & AI diagnostics Knee osteoarthritis Enhanced segmentation 4D flow MRI of neurofluids Tissue microstructure mapping Ultra-high-field fMRI Diffusion & Perfusion Imaging Neuroimaging in Animal Models Tractography Validation Anatomical Quantification Quantitative Imaging Bone and Kidney Imaging Enhances anatomical detail for planning and MRI-guided therapy. Enables early detection of Alzheimers disease and cognitive decline. Allows faster, motion-robust scans for pediatric and fetal patients. Improves visual feedback for MRI-guided robotic procedures. Enhances portable MRI usability in resource-limited environments. Builds HR anatomical atlases for research and clinical studies. Improves tumor delineation, treatment planning, and therapy monitoring. Provides better visualization of myocardial structures and blood flow. Supports spinal cord and soft-tissue assessment with improved detail. Enables CEST-MRI and MPI for HR molecular imaging. Enhances spatial resolution in fMRI and MR spectroscopy. Improves feature extraction and ML-based classification accuracy. Supports early detection of cartilage degeneration. Enables self-supervised SR for resource-efficient 3D MRI segmentation. Provides HR velocity fields of cerebrospinal and cerebral blood flow. Estimates HR tissue microstructure maps from low-quality dMRI. Localizes fine-scale motion-selective sites in early visual cortex. Enhances microstructural and vascular characterization in dMRI and perfusion MRI. Provides HR imaging for rodent and primate neuroscience research. Improves microstructure mapping and fiber connectivity estimation. Enables precise morphological and volumetric analysis. Improves dynamic mapping and water quantification in MRI. Facilitates whole-body or organ-specific MRI reconstruction. References [408], [409] [410], [411] [100], [412] [413], [414] [109], [415] [387], [416] [293] [337], [417] [10], [418] [419], [420] [421] [422], [423] [424] [425] [192] [426] [249] [245], [427] [219], [428] [322], [429] [430] [431], [432] [428] Recover missing or occluded image regions using binary mask. Super-Resolution: = (Γ(x) κ) +n Recover spatial resolution from downsampled, blurred, and noisy observations with possible misalignment. Although the degradations differ, these tasks are governed by shared mathematical structure and are often addressed using similar strategiessuch as MAP estimation, regularization, plug-and-play priors, and deep unfolding. Denoising [435][439], in particular, is foundational and frequently used as module within broader frameworks (e.g., PnP [154], equivariant imaging [440]). Deblurring enhances sharpness and structural fidelity [441], while inpainting can recover the missing data [442] or under-sampled acquisitions [443]. Among these, SR is generally the most ill-posed due to its compounded degradation effects. C. Uncertainty Quantification in Super-Resolution"
        },
        {
            "title": "Uncertainty quantification is critical",
            "content": "in super-resolution, particularly for medical imaging applications where reliability is essential. Bayesian approaches have been used to estimate predictive uncertainty [444][446], enhancing interpretability and trust in SR outputs. GAN-based methods have also incorporated uncertainty modeling to improve robustness under ambiguous inputs [447]. Recent work on equivariant bootstrapping [448] and comprehensive reviews [449], [450] highlight both methodological advances and open challenges in integrating uncertainty into deep learning-based SR pipelines. XII. TECHNICAL & METHODOLOGICAL CONSIDERATIONS A. Challenges with Real Data and Solutions Real-world clinical MRI data present numerous challenges for SR models, ranging from missing or imperfect ground truth to variability in image quality and scale. These issues hinder the direct application of supervised learning and call for alternative strategies. Table VII summarizes key challenges and corresponding solutions provided by DL-based strategiesincluding reference-free training, misalignmentaware models, domain adaptation, and continuous-scale SR techniquesthat have been proposed to address the limitations of real-world data in MRI SR pipelines. B. Deviations from General Deep Learning Practices While DL-based SR models often follow conventional DL methodologies, certain practicessuch as batch normalization and dropoutrequire domain-specific reconsideration. 1) Batch Normalization (BN): BN is widely used in DL to accelerate and improve stability of training by reducing internal covariate shift [459]. Early SR models incorporated BN for these benefits. However, subsequent research revealed that BN can impair the preservation of fine textures and introduce artifacts, particularly in pixel-level tasks like SR. As result, many recent SR architectures have omitted BN to retain image fidelity and reduce memory usage, allowing for deeper or wider network designs [26]. 2) Dropout: Dropout is regularization technique that mitigates overfitting by randomly deactivating neurons during training [460]. However, its stochastic nature can disrupt the 26 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 TABLE VII: Key Challenges in MRI Super-Resolution with Real-World Data and Representative Solutions Challenge Description Representative Solutions Absence of References Paired HR images are rarely available in clinical settings, making supervised training impractical. Imperfect References Available HR images may contain noise, or scanner-induced distortions. Misregistration Spatial misalignments between LR and HR pairs, especially in multi-contrast, longitudinal, or SVR contexts. Reference-free strategies: unsupervised learning [63], [180], [101], [182], self-supervised learning [97], [185], and deep plug-and-play methods [164], [436], [440], [451], [452]. Training with imperfect supervision via no-clean reference is possible and discussed in several studies [255], [453], [454]. Robust training with misalignment-aware networks or registration preprocessing [140], [455]. Arbitrary Scaling Factors Real-world LR-HR pairs often involve noninteger resolution ratios. Meta-learning, continuous representation models, and implicit neural networks [108], [186], [259][261], [456][458]. learning of fine spatial details, making it rarely used in SR models. Kong et al. [461] showed that applying dropout selectivelye.g., in the final layerscan improve performance under multi-degradation settings. In contrast, Xu et al. [462] found that standard dropout degrades high-frequency detail reconstruction and proposed an adaptive variant tailored for SR tasks. C. Efficiency Balancing model performance with computational complexity is essential for practical applications of MRI SR. Key factors for evaluating efficiency include model size, computational cost (e.g., multiplication-addition operations), memory usage, and inference time. These aspects directly impact deployment feasibility, particularly on resource-constrained clinical systems [463], [464]. 1) Model Size: Model size reflects the number of trainable parameters and determines storage and memory requirements. Larger models may offer higher performance but are often impractical for deployment on devices with limited computational resources. Designing compact and lightweight architectures is therefore critical for real-time and embedded applications. 2) Multiplication-Additions (Mult-Adds): Multiplicationaddition operations (Mult-Adds) serve as fundamental metric for estimating models computational complexity. FLOPs (floating point operations) are often approximated as twice the number of Mult-Adds. Since inference time scales proportionally with Mult-Adds, minimizing them is essential for achieving fast and efficient performance. 3) Memory Usage: Memory consumption during inference affects both speed and device compatibility. High memory usage can restrict deployment on edge devices or increase latency. Techniques such as mixed-precision trainingleveraging both float32 and float16 arithmetichave shown to reduce memory footprints significantly without compromising model accuracy [465]. 4) Inference Time: Inference time refers to the wall-clock time required for model to process given input. It is influenced by model size, Mult-Adds, and memory efficiency. In latency-sensitive settings such as interactive image-guided surgery or emergency diagnostics, minimizing inference time is critical for usability and safety. D. Preprocessing Preprocessing is often necessary before training or applying SR to collected MRI data to improve anatomical consistency, normalize intensity statistics, mitigate common MRI artifacts, and reduce nuisance variability between images. While public datasets may come with degree of preprocessing already applied, this is not universally true and will not be the case for newly acquired or clinical data. The exact preprocessing steps required depend on MRI acquisition details, the anatomy of interest, and the specific SR objective. Table VIII lists some common operations and non-exhaustive set of some widelyused tools. [474], pipelines fMRIPrep Additionally, as [475], [473], such sMRIPrep FreeSurfers QSIPrep recon-all, FSLs fsl_anat, AFNIs afni_proc, MRtrix3s dwipreproc, MINCs bic-pipelines, TORTOISE [476] and others provide preconfigured workflows validated within their respective regimes. When used in SR studies, each step should be considered in the context of the study goal. For example, aggressive denoising or smoothing may erase details that SR is meant to reconstruct; leaving bias fields, misalignments, or distortions may hinder training or may be addressed in SR model design; segmentation steps in existing pipelines may be undesirable on LR input and improved by inserting SRR steps; some intensity normalization approaches are only applicable to the brain; some software tools may have performance issues on SR. E. Open-Source and Proprietary Software curated list of open-source and proprietary tools relevant to MRI super-resolution, including implementations, datasets, and official repositories, is available in our GitHub1. 1https://github.com/mkhateri/Awesome-MRI-Super-Resolution KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY TABLE VIII: Common Preprocessing Steps and Selected Tools for MRI"
        },
        {
            "title": "Purpose",
            "content": "Representative Tools Image Volume Registration Align scans across timepoints, modalities, or subjects. Slice-wise Motion Correction"
        },
        {
            "title": "Bias Field Correction",
            "content": "Reduce intra-scan motion artifacts, partially important in fetal, neonatal, and elderly populations. Corrects spatially varying non-uniformities due MRI coil physics. oolMCFLIRT [466] (FSL), antsRegistrationSyN [467] (ANTs), (ITK), mni_autoreg collins1994auto,collins1995auto (MINC) Elastix [468] EDDY (FSL), SVRTK [469] N4ITK [470] (FSL), nu_correct [472] (MINC), dwibiascorrect (MRtrix3) ITK), FAST [471] (ANTs or Standardizes image intensities. ITK/simpleITK functions, intensity-normalization (python library), dwiintensitynorm (MRtrix3), inormalize (MINC) Mitigates geometric distortions common in EPI used for fMRI and DWI. TOPUP (FSL), EDDY (FSL), DR-BUDDI (AFNI), 3dQwarp (AFNI), SynB0-DISCO Intensity Normalization and/or Susceptibility Eddy Current Distortion Corrections Denoising"
        },
        {
            "title": "Reduces thermal noise influence",
            "content": "dwidenoise patch2self,nlmeans,localpca DenoiseImage (ANTs), SANLM (CAT12) (MRtrix3), (DIPY), mrdegibbs (MRtrix3), gibbs_removal (DIPY)"
        },
        {
            "title": "Gibbs Unringing",
            "content": "Reduces discrete Fourier transform ringing artifacts. XIII. CRITICAL OUTLOOK AND FUTURE DIRECTIONS In this survey, we reviewed DL-based MRI SR from the perspectives of computer vision, computational imaging, inverse problems, and MR physics. We analyzed key scenarios spanning end-to-end, physics-driven, and image-to-image translation paradigms; proposed taxonomy covering supervision level, architectural backbone, and physics coupling; and consolidated advances in learning strategies, IQA, benchmark datasets, and deployment considerations. We also curated open-source resources to facilitate further research. While categorizing existing approaches provides structured view of the field, translating MRI SR into routine clinical practice will require coordinated advances across the following fronts. A. Learning Approach MRI SR in real-world settings is often constrained by the lack of paired LRHR data, absence of reliable HR ground truth, limited training samples, and distribution shifts across sites, vendors, and protocols. Progress will require greater emphasis on unsupervised and self-supervised paradigms capable of leveraging unpaired data and adapting to unseen domains. Data-efficient strategies, such as transfer learning and few-/zero-shot adaptation, offer promising direction for addressing these challenges without the need for large paired datasets, yet they have received limited attention. B. Network Design Loss functions and architectural innovation remain central to SR performance, yet recent progress has been incremental. Most work has prioritized optimizing PSNR/SSIM, which may not reflect clinical utility. Future designs should balance fidelity, robustness, efficiency, and interpretability, incorporating domain-specific inductive biases and physics-aware components to improve both accuracy and reliability. Networks should be optimized not only for perceptual and quantitative quality but also for downstream clinical tasks, potentially through task-aware objectives and expert-in-the-loop feedback. An important yet underexplored issue is the well-known regression-to-the-mean effect that arises when training with ℓp-norm losses, the most widely used objective functions. In ambiguous regions where multiple plausible high-frequency structures exist, ℓp optimization favors their average, leading to overly smoothed reconstructions and the potential loss of clinically relevant fine details [231]. Addressing this limitation will require new objective functions and architectural strategies that preserve structural variability. Promising directions include distributional modeling approaches that explicitly capture uncertainty [232], or adaptive step-size strategies in diffusion-based frameworks [231]. C. Generative AI Generative AI has shown superb results in 2D MRI SR. Extending these gains to 3D remains difficult due to the higher data dimensionality, large GPU memory demands, and the need to maintain spatial coherence across slices. Another major challenge is hallucinationssynthetic but non-existent anatomical featureswhich threaten diagnostic reliability in clinical use. This tension between perceptual realism and structural fidelity defines central challenge for the field [477], [478]. Future progress will require methods that: (1) ensure volumetric consistency; (2) improve computational efficiency via MRI-specific latent diffusion; (3) integrate generative realism with physics-based constraints through imaging inverse problem frameworks [479][481]; (4) enable domain adaptation, such as steerable or robust diffusion models [482]; (5) 28 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX develop reliable synthetic HR MRI pipelines for augmentation in rare-disease and data-scarce settings; and (6) leverage multimodal generation to synthesize well-aligned complementary data (e.g., multi-contrast, multi-field strength) when direct acquisition or precise matching is not feasible. D. Foundation Models While progress in applying foundation models to MRI SR has been limited, their potential is considerable. Trained on large, diverse datasets, these models can capture rich anatomical and modality-aware representations, enabling robust generalization across sites, vendors, and acquisition protocols. Although their direct application may not always yield optimal results, coupling them with fewor zero-shot adaptation offers powerful means to rapidly adapt to new data with minimal retraining. E. Interpretability The black-box nature of DL can hinder trust in safetycritical settings. Developing interpretable approaches aligned with MRI physics, coupled with calibrated uncertainty estimation and failure detection, can enhance transparency, mitigate risk, and support regulatory approval. F. Data 1) Data Acquisition: Acquiring paired LRHR MRI data under controlled conditionssuch as breath-hold scans, artifactminimized acquisitions, or specialized protocolscan provide high-quality references for model training. Such datasets enable learning of realistic degradation patterns that go beyond simplistic downsampling or k-space truncation, capturing the complex noise, motion, and system-specific effects present in real acquisitions. Incorporating diverse anatomical regions, pathologies, and scanner settings during acquisition further enhances generalization and clinical relevance. 2) Data Curation: Beyond simply collecting data, effective curation shapes its clinical value. Visionlanguage methods linked to radiology reports can spotlight disease-relevant regions, ensuring that SR models focus where it matters most. Each dataset should undergo rigorous annotation, quality control, and standardization, with detailed metadata, scanner settings, acquisition context, and pathology labels, enabling precise training, fair evaluation, and robust adaptation across diverse clinical environments. G. Benchmarking Despite significant progress in MRI SR, fair comparison remains challenging. Even when the same benchmark datasets are used, differences in preprocessing pipelines often lead to discrepancies in reported performance. Progress will require standardized benchmarking frameworks with high-quality, publicly available datasets and consistent evaluation protocols. Such benchmarks should span diverse anatomies, pathologies, scanners, and acquisition settings, with harmonized preprocessing and realistic, well-documented degradation models to ensure comparability and reproducibility. H. MR Physics in Forward Model An important aspect often overlooked in the forward degradation model in Equation 2 used for MRI SR is the incorporation of the MRI slice profile. The slice profile characterizes the sensitivity variation across the slice thickness due to nonideal radiofrequency (RF) excitation pulses and slice-selective gradient fields. In practice, this profile is rarely an ideal rectangular function; imperfections in RF pulse shape, gradient nonlinearities, and system bandwidth constraints lead to tapered or asymmetric sensitivity profiles that extend beyond the nominal slice thickness. These deviations cause through-plane blurring and partial volume effects, reducing effective spatial resolution and introducing anisotropy. To account for this, the blur component κ in the degradation operator Hδ() can be decomposed into an in-plane point spread function and through-plane slice profile kernel, often modeled as 1D convolution along the slice-selection axis. This modification more accurately represents the physics of volumetric MR acquisition. Incorporating the slice profile into the forward model enables SR algorithms to predict and reverse slice-profileinduced blurring, yielding reconstructions that are more physically consistent with the underlying acin through-plane SR quisition. This is particularly critical and slice-to-volume reconstruction scenarios, where ignoring slice profile effects can limit achievable resolution, alter tissue contrast, and introduce artifacts. Accurate modeling of slice sensitivity supports better network generalization across acquisition protocols and contributes to more reliable quantitative and qualitative outcomes in clinical and research settings. I. Application to Diffusion MRI (dMRI) SR has particular significance in dMRI, where increasing spatial resolution, angular (q-space) resolution, and coverage across multiple b-values leads to substantially longer scan times and greater sensitivity to motion and artifacts. While only handful of SR studies have explicitly addressed dMRI (e.g., [245], [296]), recent review [483] highlights growing efforts in image enhancement, interpolation, and superresolution of dMRI. Future directions for dMRI SR should explicitly target the preservation of diffusion-specific information. Promising avenues include: (1) physics-aware models that respect the mathematical constraints of the diffusion signal, account for noise statistics, and model the effects of motion and eddy currents; (2) task-driven objectives that optimize SR reconstructions not only for visual fidelity but also for downstream tasks such as tractography, connectomics, and microstructural biomarker estimation; and (3) cross-domain integration, leveraging structural MRI, anatomical priors, or biophysical models (e.g., tensor or multi-compartment models) to constrain and regularize SR. J. Current and Future Clinical applications 1) In-Plane Resolution Enhancement: All major MRI vendors now offer DL-based SR solutions that enable higher resolution imaging from standard acquisitions without increasing KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 29 scan time. These techniques use neural networks trained on paired low and high resolution datasets to synthesize fine anatomical details, effectively doubling in plane matrix sizes while preserving edge sharpness and tissue contrast. Raw data consistency checks ensure diagnostic reliability by preventing artifactual hallucinations. The technology is clinically implemented for neuroimaging applications including small vessel visualization and musculoskeletal MRI where submillimeter resolution is critical. 2) Fetal MRI Super Resolution: Fetal MRI presents unique challenges because random fetal movement prevents reliable generation of standard axial, coronal and sagittal views during acquisition. SR reconstruction addresses this limitation by computationally combining motion-corrupted 2D slices from multiple orientations to create isotropic 3D volumetric datasets. This AI-driven technique is now clinically established for visualizing critical neurodevelopmental features, including cortical folding patterns, brainstem anatomy, and subtle structural abnormalities. The resulting isotropic resolution enables radiologists to reconstruct diagnostically useful images in any plane while maintaining high spatial resolution, overcoming fundamental constraint of conventional fetal MRI protocols. 3) Portable and Low-Field MRI: Portable MRI systems are transforming healthcare by enabling accessible, cost-effective imaging in diverse settings, from rural clinics to emergency rooms. They facilitate rapid diagnosis and treatment decisions without the infrastructure demands of high-field scanners, expanding access to advanced imaging in underserved areas. Super-resolution techniques can substantially enhance the clinical utility of portable MRI by compensating for the lower SNR and spatial resolution of low-field systems, enabling diagnostically accurate, high-resolution reconstructions [109], [405], [484][486]. Several portable and low-field MRI systems have already received FDA clearance for clinical use, underscoring their growing translational impact. Recent reviews further highlight the evolving regulatory landscape and clinical potential of these devices [120][122]. 4) Future Directions: Future advancements may enable multi-contrast SR from single acquisitions and reduce reliance on motion correction through real-time adaptive reconstruction. The integration of federated learning could expand anatomical diversity in training datasets, while open innovation platforms may accelerate customization for niche applications, including fetal cardiac MRI and oncology. The convergence of higher resolution outputs with faster scan times promises to redefine diagnostic thresholds in MRI. K. Competitions Despite the success of SR competitions in computer visionsuch as NTIRE [487], [488] and PIRM [489]no dedicated platform exists for MRI SR. This absence limits standardized evaluation, reproducibility, and coordinated technical progress in domain with distinct clinical requirements. community-driven MRI SR competition could be organized into specialized tracks, each addressing key bottleneck: Method Development: Advancing algorithms purposebuilt for MRI-specific challenges, covering diverse SR scenarios outlined in Section. III. Image Quality Assessment: Innovating evaluation methods beyond PSNR/SSIM to capture perceptual and clinical relevance, particularly in settings without HR ground truth. Benchmark Datasets: Curating and standardizing diverse, spanning representative anatomy, pathology, vendor, and field-strength variations to enable fair and reproducible comparisons. clinically datasets Preprocessing Standards: Establishing harmonized preprocessing pipelines, tailored to each anatomy and dataset type, covering spatial registration, motion correction, and intensity normalization to ensure comparability across methods. Running these tracks in parallel would enable progress in algorithms, evaluation, and datasets while collectively advancing MRI SR toward clinical translation. Such competitions could also yield lasting resourcesreference implementations, standardized pipelines, and reproducible baselineslowering barriers to entry and accelerating adoption in practice. L. Clinical Validation Most current MRI SR studies rely on PSNR and SSIM, which fail to capture modality-specific nuances or the true clinical utility of reconstructed images. Future validation should incorporate MRI-specific and task-relevant metrics, expert radiologist assessments, multimodal evaluation using vision language models, and performance on downstream clinical tasks. For generative AI outputs, it is necessary to implement safeguards that can detect hallucinations, anatomical inconsistencies, and clinically irrelevant details, ideally by using hybrid pipelines that combine automated screening with expert review. Most current SR algorithms are primarily evaluated on synthetic data created by downsampling high-resolution images, with limited testing on real data. For meaningful assessment of their performance, it is essential to evaluate these algorithms on real-world dataand ideally on clinical data that includes relevant pathologies. Clinical validation of MRI SR methods should adopt rigorous and multi-layered strategy that addresses both technical performance and clinical applicability. Robust protocols can include multi-center reader studies where trained radiologists evaluate SR outputs across representative patient populations, imaging protocols, and scanner types. These studies should be blinded, include inter-rater and intra-rater agreement analyses, and assess image fidelity for clinically important endpoints such as accurate delineation of anatomical structures, lesion conspicuity, and diagnostic confidence. Evaluation should also be carried out in downstream AIenabled diagnostic tasks, including tumor segmentation, brain volumetry, and radiomics-based prediction, to quantify the real-world impact of SR models on clinical decision-making. Coupling image quality metrics with such task-based endpoints ensures that improvements in visual appearance correspond to measurable diagnostic benefits. For models that may hallucinate or generate non-physical structures, validation frameworks should integrate automated 30 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 artifact and hallucination detection methods, for example, structural consistency mapping or physics-informed plausibility checks, followed by targeted expert review of flagged cases. These safety measures are essential for regulatory approval and clinical trust. The development of standardized and publicly accessible clinical validation benchmarks is critical next step. Such resources should provide reference datasets with paired LRHR MRI, expert annotations, and well-defined evaluation protocols to ensure reproducibility, fairness in comparison, and continuous improvement of SR methods."
        },
        {
            "title": "REFERENCES",
            "content": "[1] O. Afacan, B. Erem, D. P. Roby, N. Roth, A. Roth, S. P. Prabhu, and S. K. Warfield, Evaluation of motion and its effect on brain magnetic resonance image quality in children, Pediatric radiology, vol. 46, pp. 17281735, 2016. [2] R. W. Brown, Y.-C. N. Cheng, E. M. Haacke, M. R. Thompson, and R. Venkatesan, Magnetic resonance imaging: physical principles and sequence design. John Wiley & Sons, 2014. [3] Y. Sui, O. Afacan, C. Jaimes, A. Gholipour, and S. K. Warfield, Gradient-guided isotropic mri reconstruction from anisotropic acquisitions, IEEE transactions on computational imaging, vol. 7, pp. 1240 1253, 2021. [4] K. P. Pruessmann, M. Weiger, M. B. Scheidegger, and P. Boesiger, Sense: sensitivity encoding for fast mri, Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine, vol. 42, no. 5, pp. 952962, 1999. [5] C. Lazarus, P. Weiss, L. El Gueddari, F. Mauconduit, A. Massire, M. Ripart, A. Vignaud, and P. Ciuciu, 3d variable-density sparkling trajectories for high-resolution t2*-weighted magnetic resonance imaging, NMR in Biomedicine, vol. 33, no. 9, p. e4349, 2020. [6] E. Plenge, D. H. Poot, M. Bernsen, G. Kotek, G. Houston, P. Wielopolski, L. van der Weerd, W. J. Niessen, and E. Meijering, Superresolution methods in mri: can they improve the trade-off between resolution, signal-to-noise ratio, and acquisition time?, Magnetic resonance in medicine, vol. 68, no. 6, pp. 19831993, 2012. [7] D. Fiat, Method of enhancing an mri signal, Jan. 27 2005. US Patent App. 10/788,878. [8] L. Kang, B. Tang, J. Huang, and J. Li, 3d-mri super-resolution reconstruction using multi-modality based on multi-resolution cnn, Computer Methods and Programs in Biomedicine, vol. 248, p. 108110, 2024. [9] M. Hokamura, H. Uetani, T. Nakaura, K. Matsuo, K. Morita, Y. Nagayama, M. Kidoh, Y. Yamashita, M. Ueda, A. Mukasa, et al., Exploring the impact of super-resolution deep learning on mr angiography image quality, Neuroradiology, vol. 66, no. 2, pp. 217226, 2024. [10] A. S. Chaudhari, Z. Fang, F. Kogan, J. Wood, K. J. Stevens, E. K. Gibbons, J. H. Lee, G. E. Gold, and B. A. Hargreaves, Superresolution musculoskeletal mri using deep learning, Magnetic resonance in medicine, vol. 80, no. 5, pp. 21392154, 2018. [11] C. Zhao, M. Shao, A. Carass, H. Li, B. E. Dewey, L. M. Ellingsen, J. Woo, M. A. Guttman, A. M. Blitz, M. Stone, et al., Applications of deep learning method for anti-aliasing and super-resolution in mri, Magnetic resonance imaging, vol. 64, pp. 132141, 2019. [12] D. Qiu, Y. Cheng, and X. Wang, Medical image super-resolution reconstruction algorithms based on deep learning: survey, Computer Methods and Programs in Biomedicine, vol. 238, p. 107590, 2023. [13] G. Vis, M. Nilsson, C.-F. Westin, and F. Szczepankiewicz, Accuracy and precision in super-resolution mri: Enabling spherical tensor diffusion encoding at ultra-high b-values and high resolution, NeuroImage, vol. 245, p. 118673, 2021. [14] X. Chen, Y. Qiu, W. Liang, G. Zhou, and S. Xie, Spatial information regularized tensor decomposition framework for super-resolution reconstruction of medical mri and radiographs, IEEE Transactions on Computational Imaging, vol. 8, pp. 865878, 2022. [15] C.-M. Feng, K. Wang, S. Lu, Y. Xu, and X. Li, Brain mri superresolution using coupled-projection residual network, Neurocomputing, vol. 456, pp. 190199, 2021. [16] Y. Sui, O. Afacan, A. Gholipour, and S. K. Warfield, Fast and highresolution neonatal brain mri through super-resolution reconstruction from acquisitions with variable slice selection direction, Frontiers in Neuroscience, vol. 15, p. 636268, 2021. [17] L. Zhang, A. Li, Q. Hou, C. Zhu, and Y. C. Eldar, Deep-learningempowered super resolution: comprehensive survey and future prospects, Proceedings of the IEEE, 2025. [18] Z. Wang, J. Chen, and S. C. Hoi, Deep learning for image superresolution: survey, IEEE transactions on pattern analysis and machine intelligence, vol. 43, no. 10, pp. 33653387, 2020. [19] H. Chen, X. He, L. Qing, Y. Wu, C. Ren, R. E. Sheriff, and C. Zhu, Real-world single image super-resolution: brief review, Information Fusion, vol. 79, pp. 124145, 2022. [20] A. Liu, Y. Liu, J. Gu, Y. Qiao, and C. Dong, Blind image superresolution: survey and beyond, IEEE transactions on pattern analysis and machine intelligence, vol. 45, no. 5, pp. 54615480, 2022. [21] K. Chauhan, S. N. Patel, M. Kumhar, J. Bhatia, S. Tanwar, I. E. Davidson, T. F. Mazibuko, and R. Sharma, Deep learning-based single-image super-resolution: comprehensive review, IEEE Access, vol. 11, pp. 2181121830, 2023. [22] J. Li, Z. Pei, and T. Zeng, From beginner to master: survey for deep learning-based single-image super-resolution, arXiv preprint arXiv:2109.14335, vol. 2, 2021. [23] B. B. Moser, A. S. Shanbhag, F. Raue, S. Frolov, S. Palacio, and A. Dengel, Diffusion models, image super-resolution, and everything: survey, IEEE Transactions on Neural Networks and Learning Systems, 2024. [24] G. Gendy, G. He, and N. Sabor, Diffusion models for image superresolution: State-of-the-art and future directions, Neurocomputing, vol. 617, p. 128911, 2025. [25] B. B. Moser, F. Raue, S. Frolov, S. Palacio, J. Hees, and A. Dengel, Hitchhikers guide to super-resolution: Introduction and recent advances, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 8, pp. 98629882, 2023. [26] D. C. Lepcha, B. Goyal, A. Dogra, and V. Goyal, Image supertrends, challenges and resolution: comprehensive review, recent applications, Information Fusion, vol. 91, pp. 230260, 2023. [27] C. Tian, X. Zhang, J. C.-W. Lin, W. Zuo, Y. Zhang, and C.-W. Lin, Generative adversarial networks for image super-resolution: survey, arXiv preprint arXiv:2204.13620, 2022. [28] Y. K. Ooi and H. Ibrahim, Deep learning algorithms for single image super-resolution: systematic review, Electronics, vol. 10, no. 7, p. 867, 2021. [29] S. Umirzakova, S. Ahmad, L. U. Khan, and T. Whangbo, Medical image super-resolution for smart healthcare applications: comprehensive survey, Information Fusion, p. 102075, 2023. [30] Y. Li, B. Sixou, and F. Peyrin, review of the deep learning methods for medical images super resolution problems, Irbm, vol. 42, no. 2, pp. 120133, 2021. [31] H. Yang, Z. Wang, X. Liu, C. Li, J. Xin, and Z. Wang, Deep learning in medical image super resolution: review, Applied Intelligence, vol. 53, no. 18, pp. 2089120916, 2023. [32] S. Kaji and S. Kida, Overview of image-to-image translation by use of deep neural networks: denoising, super-resolution, modality conversion, imaging, Radiological physics and and reconstruction in medical technology, vol. 12, no. 3, pp. 235248, 2019. [33] M. Yu, Z. Xu, and T. Lukasiewicz, general survey on medical image super-resolution via deep learning, Computers in Biology and Medicine, vol. 193, p. 110345, 2025. [34] E. Van Reeth, I. W. Tham, C. H. Tan, and C. L. Poh, Super-resolution in magnetic resonance imaging: review, Concepts in Magnetic Resonance Part A, vol. 40, no. 6, pp. 306325, 2012. [35] Z. Ji, B. Zou, X. Kui, J. Liu, W. Zhao, C. Zhu, P. Dai, and Y. Dai, Deep learning-based magnetic resonance image super-resolution: survey, Neural Computing and Applications, pp. 128, 2024. [36] A. Muhammad, S. Aramvith, K. Duangchaemkarn, and M.-T. Sun, Brain mri image super-resolution reconstruction: systematic review, IEEE Access, 2024. [37] Q. Lyu, H. Shan, and G. Wang, Mri super-resolution with ensemble learning and complementary priors, IEEE Transactions on Computational Imaging, vol. 6, pp. 615624, 2020. [38] Z. Zhao, J. C. Ye, and Y. Bresler, Generative models for inverse imaging problems: From mathematical foundations to physics-driven applications, IEEE Signal Processing Magazine, vol. 40, no. 1, pp. 148163, 2023. [39] H. Gudbjartsson and S. Patz, The rician distribution of noisy mri data, Magnetic resonance in medicine, vol. 34, no. 6, pp. 910914, 1995. [40] D. Meng and F. De La Torre, Robust matrix factorization with unknown noise, in Proceedings of the IEEE international conference on computer vision, pp. 13371344, 2013. KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 31 [41] C. A. Bouman, Foundations of computational imaging: model-based approach. SIAM, 2022. [42] D. Ren, W. Zuo, D. Zhang, L. Zhang, and M.-H. Yang, Simultaneous fidelity and regularization learning for image restoration, IEEE transactions on pattern analysis and machine intelligence, vol. 43, no. 1, pp. 284299, 2019. [43] X. Zhang, E. Y. Lam, E. X. Wu, and K. K. Wong, Application of tikhonov regularization to super-resolution reconstruction of brain mri images, in Medical Imaging and Informatics: 2nd International Conference, MIMI 2007, Beijing, China, August 14-16, 2007 Revised Selected Papers, pp. 5156, Springer, 2008. [44] M. Brudfors, Y. Balbastre, P. Nachev, and J. Ashburner, for super-resolving multimodal clinical mri, arXiv preprint tool arXiv:1909.01140, 2019. [45] L. I. Rudin, S. Osher, and E. Fatemi, Nonlinear total variation based noise removal algorithms, Physica D: nonlinear phenomena, vol. 60, no. 1-4, pp. 259268, 1992. [46] S. Tourbier, X. Bresson, P. Hagmann, J.-P. Thiran, R. Meuli, and M. B. Cuadra, An efficient total variation algorithm for super-resolution in fetal brain mri with adaptive regularization, NeuroImage, vol. 118, pp. 584597, 2015. [47] F. Shi, J. Cheng, L. Wang, P.-T. Yap, and D. Shen, Lrtv: Mr image super-resolution with low-rank and total variation regularizations, IEEE transactions on medical imaging, vol. 34, no. 12, pp. 24592466, 2015. [48] D. Glasner, S. Bagon, and M. Irani, Super-resolution from single image, in 2009 IEEE 12th international conference on computer vision, pp. 349356, IEEE, 2009. [49] J. V. Manjón, P. Coupé, A. Buades, D. L. Collins, and M. Robles, Mri superresolution using self-similarity and image priors, International journal of biomedical imaging, vol. 2010, no. 1, p. 425891, 2010. [50] A. Bustin, D. Voilliot, A. Menini, J. Felblinger, C. de Chillou, D. Burschka, L. Bonnemains, and F. Odille, Isotropic reconstruction of mr images using 3d patch-based self-similarity learning, IEEE transactions on medical imaging, vol. 37, no. 8, pp. 19321942, 2018. [51] V. Cherukuri, T. Guo, S. J. Schiff, and V. Monga, Deep mr brain image super-resolution using spatio-structural priors, IEEE Transactions on Image Processing, vol. 29, pp. 13681383, 2019. [52] P. Li, J. Chen, D. Nan, J. Zou, D. Lin, and Y. Hu, Motion-aligned 4dmri reconstruction using higher degree total variation and locally lowrank regularization, Magnetic Resonance Imaging, vol. 93, pp. 97 107, 2022. [53] X. Zhang, H. Lu, D. Guo, Z. Lai, H. Ye, X. Peng, B. Zhao, and X. Qu, Accelerated mri reconstruction with separable and enhanced low-rank hankel regularization, IEEE transactions on medical imaging, vol. 41, no. 9, pp. 24862498, 2022. [54] Y. Zhang, J. Liu, W. Yang, and Z. Guo, Image super-resolution based on structure-modulated sparse representation, IEEE Transactions on Image Processing, vol. 24, no. 9, pp. 27972810, 2015. [55] Y.-H. Wang, J. Qiao, J.-B. Li, P. Fu, S.-C. Chu, and J. F. Roddick, Sparse representation-based mri super-resolution reconstruction, Measurement, vol. 47, pp. 946953, 2014. [56] Y. Zhang, G. Wu, P.-T. Yap, Q. Feng, J. Lian, W. Chen, and D. Shen, Hierarchical patch-based sparse representationa new approach for resolution enhancement of 4d-ct lung data, IEEE transactions on medical imaging, vol. 31, no. 11, pp. 19932005, 2012. [57] M. Protter, M. Elad, H. Takeda, and P. Milanfar, Generalizing the nonlocal-means to super-resolution reconstruction, IEEE Transactions on image processing, vol. 18, no. 1, pp. 3651, 2008. [58] J. V. Manjón, P. Coupé, A. Buades, V. Fonov, D. L. Collins, and image analysis, M. Robles, Non-local mri upsampling, Medical vol. 14, no. 6, pp. 784792, 2010. [59] K. Jafari-Khouzani, Mri upsampling using feature-based nonlocal means approach, IEEE transactions on medical imaging, vol. 33, no. 10, pp. 19691985, 2014. [60] S. Farsiu, M. D. Robinson, M. Elad, and P. Milanfar, Fast and robust multiframe super resolution, IEEE transactions on image processing, vol. 13, no. 10, pp. 13271344, 2004. [61] Y. Sui, O. Afacan, A. Gholipour, and S. K. Warfield, Isotropic mri super-resolution reconstruction with multi-scale gradient field prior, in International Conference on Medical Image Computing and ComputerAssisted Intervention, pp. 311, Springer, 2019. [62] Y. Sui, O. Afacan, A. Gholipour, and S. K. Warfield, Learning gradient guidance for spatially isotropic mri super-resolution reconstruction, in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 136146, Springer, 2020. [63] J. Liu, H. Li, T. Huang, E. Ahn, K. Han, A. Razi, W. Xiang, J. Kim, and D. D. Feng, Unsupervised representation learning for 3-dimensional magnetic resonance imaging super-resolution with degradation adaptation, IEEE Transactions on Artificial Intelligence, 2024. [64] J. Liang, H. Zeng, and L. Zhang, Efficient and degradation-adaptive network for real-world image super-resolution, in European Conference on Computer Vision, pp. 574591, Springer, 2022. [65] W. T. Freeman, E. C. Pasztor, and O. T. Carmichael, Learning lowlevel vision, International journal of computer vision, vol. 40, pp. 25 47, 2000. [66] X. Lu, Z. Huang, and Y. Yuan, Mr image super-resolution via manifold regularized sparse learning, Neurocomputing, vol. 162, pp. 96104, 2015. [67] N. F. Velasco, A. Rueda, C. Santa Marta, and E. Romero, sparse bayesian representation for super-resolution of cardiac mr images, Magnetic Resonance Imaging, vol. 36, pp. 7785, 2017. [68] D. Zhang, J. He, Y. Zhao, and M. Du, Mr image super-resolution reconstruction using sparse representation, nonlocal similarity and sparse derivative prior, Computers in biology and medicine, vol. 58, pp. 130145, 2015. [69] Y. Jia, A. Gholipour, Z. He, and S. K. Warfield, new sparse representation framework for reconstruction of an isotropic high spatial resolution mr volume from orthogonal anisotropic resolution scans, IEEE transactions on medical imaging, vol. 36, no. 5, pp. 11821193, 2017. [70] Y. Yuan, S. Liu, J. Zhang, Y. Zhang, C. Dong, and L. Lin, Unsupervised image super-resolution using cycle-in-cycle generative adversarial networks, in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pp. 701710, 2018. [71] S. Wang, R. Wu, S. Jia, A. Diakite, C. Li, Q. Liu, H. Zheng, and L. Ying, Knowledge-driven deep learning for fast mr imaging: Undersampled mr image reconstruction from supervised to un-supervised learning, Magnetic Resonance in Medicine, vol. 92, no. 2, pp. 496 518, 2024. [72] J. Guerreiro, P. Tomás, N. Garcia, and H. Aidos, Super-resolution of magnetic resonance images using generative adversarial networks, Computerized Medical Imaging and Graphics, p. 102280, 2023. [73] X. Zhao, Y. Zhang, T. Zhang, and X. Zou, Channel splitting network for single mr image super-resolution, IEEE transactions on image processing, vol. 28, no. 11, pp. 56495662, 2019. [74] M. Yu, M. Guo, S. Zhang, Y. Zhan, M. Zhao, T. Lukasiewicz, and Z. Xu, Rirgan: An end-to-end lightweight multi-task learning method for brain mri super-resolution and denoising, Computers in Biology and Medicine, vol. 167, p. 107632, 2023. [75] S. Zhi, Y. Wang, H. Xiao, T. Bai, B. Li, Y. Tang, C. Liu, W. Li, T. Li, H. Ge, et al., Coarsesuper-resolutionfine network (cosf-net): unified end-to-end neural network for 4d-mri with simultaneous motion estimation and super-resolution, IEEE Transactions on Medical Imaging, 2023. [76] Q. Wang, L. Mahler, J. Steiglechner, F. Birk, K. Scheffler, and G. Lohmann, Disgan: wavelet-informed discriminator guides gan to mri super-resolution with noise cleaning, in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 2452 2461, 2023. [77] P. Lei, F. Fang, G. Zhang, and T. Zeng, Decomposition-based variational network for multi-contrast mri super-resolution and reconstruction, in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 2129621306, 2023. [78] B. Huang, H. Xiao, W. Liu, Y. Zhang, H. Wu, W. Wang, Y. Yang, Y. Yang, G. W. Miller, T. Li, et al., Mri super-resolution via realistic learning, Physics in Medicine & downsampling with adversarial Biology, vol. 66, no. 20, p. 205004, 2021. [79] Z. Chen, M. C. Stapleton, Y. Xie, D. Li, Y. L. Wu, and A. G. Christodoulou, Physics-informed deep learning for t2-deblurred superresolution turbo spin echo mri, Magnetic Resonance in Medicine, vol. 90, no. 6, pp. 23622374, 2023. [80] K. Hammernik, T. Küstner, B. Yaman, Z. Huang, D. Rueckert, F. Knoll, and M. Akçakaya, Physics-driven deep learning for computational magnetic resonance imaging: Combining physics and machine learning for improved medical imaging, IEEE signal processing magazine, vol. 40, no. 1, pp. 98114, 2023. [81] W. C. Karl, J. E. Fowler, C. A. Bouman, M. Çetin, B. Wohlberg, and J. C. Ye, The foundations of computational imaging: signal processing perspective, IEEE Signal Processing Magazine, vol. 40, no. 5, pp. 4053, 2023. [82] G. Yang, L. Zhang, A. Liu, X. Fu, X. Chen, and R. Wang, Mgdun: An interpretable network for multi-contrast mri image super-resolution re32 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 construction, Computers in Biology and Medicine, vol. 167, p. 107605, 2023. via novel slice-profile transformation super-resolution, IEEE Access, 2023. [83] Y. Zhu, J. Cheng, Z.-X. Cui, Q. Zhu, L. Ying, and D. Liang, Physicsdriven deep learning methods for fast quantitative magnetic resonance imaging: Performance improvements through integration with deep neural networks, IEEE Signal Processing Magazine, vol. 40, no. 2, pp. 116128, 2023. [84] A. Kazemi, I. J. Abecassis, and A. A. Amini, Pi-gnn: Physicsinformed graph neural network for super-resolution of 4d flow mri, in 2024 IEEE International Symposium on Biomedical Imaging (ISBI), pp. 15, IEEE, 2024. [85] B. Song, S. M. Kwon, Z. Zhang, X. Hu, Q. Qu, and L. Shen, Solving inverse problems with latent diffusion models via hard data consistency, arXiv preprint arXiv:2307.08123, 2023. [86] Q. Qu and L. Shen, Solving inverse problems with latent diffusion models via hard data consistency, 2024. [87] D. Gilton, G. Ongie, and R. Willett, Deep equilibrium architectures for inverse problems in imaging, IEEE Transactions on Computational Imaging, vol. 7, pp. 11231133, 2021. [88] C. Alkan, J. Oscanoa, D. Abraham, M. Gao, A. Nurdinova, K. Setsompop, J. M. Pauly, M. Mardani, and S. Vasanawala, Variational diffusion models for blind mri inverse problems, in NeurIPS 2023 Workshop on Deep Learning and Inverse Problems, 2023. [89] J. R. Chand and M. Jacob, Multi-scale energy (muse) framework for inverse problems in imaging, IEEE Transactions on Computational Imaging, 2024. [90] H. Chung and J. C. Ye, Deep diffusion image prior for efficient ood adaptation in 3d inverse problems, in European Conference on Computer Vision, pp. 432455, Springer, 2024. [91] J. Wang, A. F. Heimann, M. Tannast, and G. Zheng, Ct-guided, unsupervised super-resolution reconstruction of single 3d magnetic resonance image, in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 497507, Springer, 2023. [92] X. Zeng, B. Li, and X. Wang, Mmnet: medical image-to-image translation network based on manifold-value correction and manifold matching, Neural Computing and Applications, vol. 35, no. 23, pp. 1697516994, 2023. [93] C. J. Wang, N. S. Rost, and P. Golland, Spatial-intensity transforms for medical image-to-image translation, IEEE transactions on medical imaging, vol. 42, no. 11, pp. 33623373, 2023. [94] M. Safayani, B. Mirzapour, N. Salehi, H. Ravaee, et al., Unpaired image-to-image translation with content preserving perspective: review, arXiv preprint arXiv:2502.08667, 2025. [95] X. Xue, Y. Wang, J. Li, Z. Jiao, Z. Ren, and X. Gao, Progressive subband residual-learning network for mr image super resolution, IEEE journal of biomedical and health informatics, vol. 24, no. 2, pp. 377 386, 2019. [96] A. Jog, A. Carass, and J. L. Prince, Self super-resolution for magnetic resonance images, in Medical Image Computing and ComputerAssisted Intervention-MICCAI 2016: 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings, Part III 19, pp. 553560, Springer, 2016. [97] C. Zhao, B. E. Dewey, D. L. Pham, P. A. Calabresi, D. S. Reich, and J. L. Prince, Smore: self-supervised anti-aliasing and superresolution algorithm for mri using deep learning, IEEE transactions on medical imaging, vol. 40, no. 3, pp. 805817, 2020. [98] R. Benisty, Y. Shteynman, M. I. Porat, F. Anat, and Moti, Simple: Simultaneous multi-plane self-supervised learning for isotropic mri restoration from anisotropic data, arXiv:2408.13065v, 2024. [99] Y. Sui, O. Afacan, C. Jaimes, A. Gholipour, and S. K. Warfield, Scanspecific generative neural network for mri super-resolution reconstruction, IEEE transactions on medical imaging, vol. 41, no. 6, pp. 1383 1399, 2022. [100] A. Gholipour, J. A. Estroff, and S. K. Warfield, Robust superresolution volume reconstruction from slice acquisitions: application to fetal brain mri, IEEE transactions on medical imaging, vol. 29, no. 10, pp. 17391758, 2010. [101] J. Xu, E. Abaci Turk, P. E. Grant, P. Golland, and E. Adalsteinsson, Stress: Super-resolution for dynamic fetal mri using selfsupervised learning, in Medical Image Computing and Computer Assisted InterventionMICCAI 2021: 24th International Conference, Strasbourg, France, September 27October 1, 2021, Proceedings, Part VII 24, pp. 197206, Springer, 2021. [102] J. Lin, Q. Miao, C. Surawech, S. S. Raman, K. Zhao, H. H. Wu, and K. Sung, High-resolution 3d mri with deep generative networks [103] M. Elad and A. Feuer, Restoration of single superresolution image from several blurred, noisy, and undersampled measured images, IEEE transactions on image processing, vol. 6, no. 12, pp. 16461658, 1997. [104] A. Uus, T. Zhang, L. H. Jackson, T. A. Roberts, M. A. Rutherford, J. V. Hajnal, and M. Deprez, Deformable slice-to-volume registration for motion correction of fetal body and placenta mri, IEEE transactions on medical imaging, vol. 39, no. 9, pp. 27502759, 2020. [105] J. Xu, D. Moyer, B. Gagoski, J. E. Iglesias, P. E. Grant, P. Golland, and E. Adalsteinsson, Nesvor: implicit neural representation for slice-tovolume reconstruction in mri, IEEE transactions on medical imaging, vol. 42, no. 6, pp. 17071719, 2023. [106] M. Dannecker, T. Sanchez, M. B. Cuadra, Ö. Turgut, A. N. Price, L. Cordero-Grande, V. Kyriakopoulou, J. V. Hajnal, and D. Rueckert, Meta-learning slice-to-volume reconstruction in fetal brain mri using implicit neural representations, arXiv preprint arXiv:2505.09565, 2025. [107] S. I. Young, Y. Balbastre, B. Fischl, P. Golland, and J. E. Iglesias, Fully convolutional slice-to-volume reconstruction for single-stack mri, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1153511545, 2024. [108] Q. Wu, Y. Li, Y. Sun, Y. Zhou, H. Wei, J. Yu, and Y. Zhang, An arbitrary scale super-resolution approach for 3d mr images via implicit neural representation, IEEE Journal of Biomedical and Health Informatics, vol. 27, no. 2, pp. 10041015, 2022. [109] K. T. Islam, S. Zhong, P. Zakavi, Z. Chen, H. Kavnoudias, S. Farquharson, G. Durbridge, M. Barth, K. L. McMahon, P. M. Parizel, et al., Improving portable low-field mri image quality through imageto-image translation using paired low-and high-field images, Scientific Reports, vol. 13, no. 1, p. 21183, 2023. [110] K. Bahrami, F. Shi, I. Rekik, Y. Gao, and D. Shen, 7t-guided superresolution of 3t mri, Medical physics, vol. 44, no. 5, pp. 16611677, 2017. [111] K. Bahrami, F. Shi, X. Zong, H. W. Shin, H. An, and D. Shen, Reconstruction of 7t-like images from 3t mri, IEEE transactions on medical imaging, vol. 35, no. 9, pp. 20852097, 2016. [112] Z. S. Siam, R. T. Hasan, M. H. Chowdhury, M. S. I. Sumon, M. B. I. Reaz, S. H. B. M. Ali, A. Mushtak, I. Al-Hashimi, S. B. Zoghoul, and M. E. Chowdhury, Improving mri resolution: cycle consistent generative adversarial network-based approach for 3t to 7t translation, IEEE Access, 2024. [113] Z. Eidex, J. Wang, M. Safari, E. Elder, J. Wynne, T. Wang, H.-K. Shu, H. Mao, and X. Yang, High-resolution 3t to 7t adc map synthesis with hybrid cnn-transformer model, Medical Physics, vol. 51, no. 6, pp. 43804388, 2024. [114] R. R. Jha, B. R. Kumar, S. K. Pathak, A. Bhavsar, and A. Nigam, Trganet: Transforming 3t to 7t dmri using trapezoidal rule and graph based attention modules, Medical Image Analysis, vol. 87, p. 102806, 2023. [115] Y. Zhang, P.-T. Yap, L. Qu, J.-Z. Cheng, and D. Shen, Dual-domain convolutional neural networks for improving structural information in 3 mri, Magnetic resonance imaging, vol. 64, pp. 90100, 2019. [116] Q. Cui, D. Tosun, P. Mukherjee, and R. Abbasi-Asl, 7t mri synthesization from 3t acquisitions, in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 3544, Springer, 2024. [117] S. Dayarathna, K. T. Islam, and Z. Chen, Ultra low-field to high-field mri translation using adversarial diffusion, in 2024 IEEE International Symposium on Biomedical Imaging (ISBI), pp. 14, IEEE, 2024. [118] J. Jiang, F. Qi, H. Du, J. Xu, Y. Zhou, D. Gao, and B. Qiu, Superresolution reconstruction of 3t-like images from 0.35 mri using hybrid attention residual network, IEEE Access, vol. 10, pp. 32810 32821, 2022. [119] H. Lin, M. Figini, F. DArco, G. Ogbole, R. Tanno, S. B. Blumberg, L. Ronan, B. J. Brown, D. W. Carmichael, I. Lagunju, et al., Low-field magnetic resonance image enhancement via stochastic image quality transfer, Medical Image Analysis, vol. 87, p. 102807, 2023. [120] K. N. Sheth, M. H. Mazurek, M. M. Yuen, B. A. Cahn, J. T. Shah, A. G. Ward, J. W. Kim, N. Mahmood, A. J. Cole, J. Schindler, et al., Assessment of brain injury using portable, low-field magnetic the bedside of critically ill patients, JAMA resonance imaging at Neurology, vol. 78, no. 1, pp. 4147, 2021. [121] C. Z. Cooley, R. L. Barry, W. H. Heiss, N. A. Kazim, K. F. King, R. Lattanzi, G. Madelin, J. P. Marques, S. Michaeli, J. Tian, L. L. Wald, and A. Waldman, Clinical impact of low-field mri: current status and KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 33 future directions, Journal of Magnetic Resonance Imaging, vol. 57, no. 1, pp. 5167, 2023. in International Workshop on Machine Learning in Medical Imaging, pp. 382391, Springer, 2024. [122] T. C. Arnold, R. L. Barry, N. K. Chen, W. H. Heiss, N. A. Kazim, R. Lattanzi, G. Madelin, J. P. Marques, S. Michaeli, J. Tian, L. L. Wald, A. Waldman, and C. Z. Cooley, Low-field mri: clinical promise and challenges, Journal of Magnetic Resonance Imaging, vol. 57, no. 1, pp. 2544, 2023. [123] G. Li, J. Wei, M. Kadbi, J. Moody, A. Sun, S. Zhang, S. Markova, K. Zakian, M. Hunt, and J. O. Deasy, Novel super-resolution approach to time-resolved volumetric 4-dimensional magnetic resonance imaging with high spatiotemporal resolution for multi-breathing cycle motion assessment, International Journal of Radiation Oncology* Biology* Physics, vol. 98, no. 2, pp. 454462, 2017. [124] X. Nie, Z. Saleh, M. Kadbi, K. Zakian, J. Deasy, A. Rimner, and G. Li, super-resolution framework for the reconstruction of t2-weighted (t2w) time-resolved (tr) 4dmri using t1w tr-4dmri as the guidance, Medical physics, vol. 47, no. 7, pp. 30913102, 2020. [125] F. Shone, N. Ravikumar, T. Lassila, M. MacRaild, Y. Wang, Z. A. Taylor, P. Jimack, E. DallArmellina, and A. F. Frangi, Deep physicsinformed super-resolution of cardiac 4d-flow mri, in International Conference on Information Processing in Medical Imaging, pp. 511 522, Springer, 2023. [126] L. Ericsson, A. Hjalmarsson, M. U. Akbar, E. Ferdian, M. Bonini, B. Hardy, J. Schollenberger, M. Aristova, P. Winter, N. Burris, et al., Generalized super-resolution 4d flow mri-using ensemble learning to extend across the cardiovascular system, IEEE journal of biomedical and health informatics, 2024. [127] G. S. V. Chilla, C. H. Tan, and C. L. Poh, Deformable registrationbased super-resolution for isotropic reconstruction of 4-d mri volumes, IEEE Journal of Biomedical and Health Informatics, vol. 21, no. 6, pp. 16171624, 2017. [128] Q. Lyu, H. Shan, C. Steber, C. Helis, C. Whitlow, M. Chan, and G. Wang, Multi-contrast super-resolution mri through progressive network, IEEE transactions on medical imaging, vol. 39, no. 9, pp. 27382749, 2020. [129] C.-M. Feng, H. Fu, S. Yuan, and Y. Xu, Multi-contrast mri superresolution via multi-stage integration network, in Medical Image Computing and Computer Assisted InterventionMICCAI 2021: 24th International Conference, Strasbourg, France, September 27October 1, 2021, Proceedings, Part VI 24, pp. 140149, Springer, 2021. [130] C.-M. Feng, Y. Yan, K. Yu, Y. Xu, H. Fu, J. Yang, and L. Shao, Exploring separable attention for multi-contrast mr image superresolution, IEEE Transactions on Neural Networks and Learning Systems, 2024. [131] L. Liu, T. Liu, W. Zhou, Y. Wang, and M. Liu, Mapanet: multi-scale attention-guided progressive aggregation network for multi-contrast mri super-resolution, IEEE Transactions on Computational Imaging, 2024. [132] X. Huang, P. Zhang, J. Song, Q. Huang, C. Huang, and D. Huang, Ddformer: Dual-domain and dual-aggregation transformer for multicontrast mri super-resolution, in 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pp. 30293036, IEEE, 2023. [133] G. Yang, L. Zhang, M. Zhou, A. Liu, X. Chen, Z. Xiong, and F. Wu, Model-guided multi-contrast deep unfolding network for mri superresolution reconstruction, in Proceedings of the 30th ACM International Conference on Multimedia, pp. 39743982, 2022. [134] J. McGinnis, S. Shit, H. B. Li, V. Sideri-Lampretsa, R. Graf, M. Dannecker, J. Pan, N. Stolt-Ansó, M. Mühlau, J. S. Kirschke, et al., Singlesubject multi-contrast mri super-resolution via implicit neural representations, in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 173183, Springer, 2023. [135] B. Zou, Z. Ji, C. Zhu, Y. Dai, W. Zhang, and X. Kui, Multi-scale deformable transformer for multi-contrast knee mri super-resolution, Biomedical Signal Processing and Control, vol. 79, p. 104154, 2023. [136] W. Kong, B. Li, K. Wei, D. Li, J. Zhu, and G. Yu, Dual contrast attention-guided multi-frequency fusion for multi-contrast mri superresolution, Physics in Medicine & Biology, vol. 69, no. 1, p. 015010, 2023. [137] P. Lei, L. Hu, F. Fang, and G. Zhang, Joint under-sampling pattern and dual-domain reconstruction for accelerating multi-contrast mri, IEEE Transactions on Image Processing, 2024. [138] G. Li, C. Rao, J. Mo, Z. Zhang, W. Xing, and L. Zhao, Rethinking diffusion model for multi-contrast mri super-resolution, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1136511374, 2024. [139] S. Zheng, Y. Wang, S. Du, and C. Qin, Sgsr: Structure-guided multicontrast mri super-resolution via spatio-frequency co-query attention, [140] P. Lei, M. Zhang, F. Fang, and G. Zhang, Robust deep convolutional dictionary model with alignment assistance for multi-contrast mri super-resolution, IEEE Transactions on Medical Imaging, 2025. [141] J. Li, H. Yang, Q. Yi, M. Lu, J. Shi, and T. Zeng, High-frequency modulated transformer for multi-contrast mri super-resolution, IEEE Transactions on Medical Imaging, 2025. [142] K. Armanious, C. Jiang, M. Fischer, T. Küstner, T. Hepp, K. Nikolaou, S. Gatidis, and B. Yang, Medgan: Medical image translation using gans, Computerized medical imaging and graphics, vol. 79, p. 101684, 2020. [143] Y. Feng, S. Deng, J. Lyu, J. Cai, M. Wei, and J. Qin, Bridging mri cross-modality synthesis and multi-contrast super-resolution by finegrained difference learning, IEEE Transactions on Medical Imaging, 2024. [144] Q. Yang, N. Li, Z. Zhao, X. Fan, E. I.-C. Chang, and Y. Xu, Mri cross-modality image-to-image translation, Scientific reports, vol. 10, no. 1, p. 3753, 2020. [145] M. Özbey, O. Dalmaz, S. U. Dar, H. A. Bedel, S. Özturk, A. Güngör, and T. Çukur, Unsupervised medical image translation with adversarial diffusion models, IEEE Transactions on Medical Imaging, vol. 42, no. 12, pp. 35243539, 2023. [146] N. Liang, Medical image fusion with deep neural networks, Scientific Reports, vol. 14, no. 1, p. 7972, 2024. [147] S. Dayarathna, K. T. Islam, S. Uribe, G. Yang, M. Hayat, and Z. Chen, Deep learning based synthesis of mri, ct and pet: Review and analysis, Medical image analysis, vol. 92, p. 103046, 2024. [148] D. Ulyanov, A. Vedaldi, and V. Lempitsky, Deep image prior, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 94469454, 2018. [149] K. Zhang, Y. Li, W. Zuo, L. Zhang, L. Van Gool, and R. Timofte, Plug-and-play image restoration with deep denoiser prior, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 44, no. 10, pp. 63606376, 2021. [150] J. Yoo, K. H. Jin, H. Gupta, J. Yerly, M. Stuber, and M. Unser, Timedependent deep image prior for dynamic mri, IEEE Transactions on Medical Imaging, vol. 40, no. 12, pp. 33373348, 2021. [151] Y. Sun, Z. Wu, Y. Chen, B. T. Feng, and K. L. Bouman, Provable probabilistic imaging using score-based generative priors, IEEE Transactions on Computational Imaging, 2024. [152] S. Huang, X. Liu, T. Tan, M. Hu, X. Wei, T. Chen, and B. Sheng, Transmrsr: transformer-based self-distilled generative prior for brain mri super-resolution, The Visual Computer, vol. 39, no. 8, pp. 3647 3659, 2023. [153] M. Zach, F. Knoll, and T. Pock, Stable deep mri reconstruction using generative priors, IEEE Transactions on Medical Imaging, 2023. [154] S. V. Venkatakrishnan, C. A. Bouman, and B. Wohlberg, Plug-andplay priors for model based reconstruction, in 2013 IEEE global conference on signal and information processing, pp. 945948, IEEE, 2013. [155] K. Zhang, W. Zuo, and L. Zhang, Deep plug-and-play super-resolution for arbitrary blur kernels, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 16711681, 2019. [156] S. Shoushtari, J. Liu, E. P. Chandler, M. S. Asif, and U. S. Kamilov, Prior mismatch and adaptation in pnp-admm with nonconvex convergence analysis, arXiv preprint arXiv:2310.00133, 2023. [157] U. S. Kamilov, C. A. Bouman, G. T. Buzzard, and B. Wohlberg, Plug-and-play methods for integrating physical and learned models in computational imaging: Theory, algorithms, and applications, IEEE Signal Processing Magazine, vol. 40, no. 1, pp. 8597, 2023. [158] R. Ahmad, C. A. Bouman, G. T. Buzzard, S. Chan, S. Liu, E. T. Reehorst, and P. Schniter, Plug-and-play methods for magnetic resonance imaging: Using denoisers for image recovery, IEEE signal processing magazine, vol. 37, no. 1, pp. 105116, 2020. [159] Y. Gao, Z. Xiong, S. Shan, Y. Liu, P. Rong, M. Li, A. H. Wilman, G. B. Pike, F. Liu, and H. Sun, Plug-and-play latent feature editing for orientation-adaptive quantitative susceptibility mapping neural networks, Medical Image Analysis, vol. 94, p. 103160, 2024. [160] M. Terris, U. S. Kamilov, and T. Moreau, Fire: Fixed-points of restoration priors for solving inverse problems, in Proceedings of the Computer Vision and Pattern Recognition Conference, pp. 23185 23194, 2025. [161] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein, et al., Distributed optimization and statistical learning via the alternating direction method of multipliers, Foundations and Trends in Machine learning, vol. 3, no. 1, pp. 1122, 2011. 34 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 [162] M. Nikolova and M. K. Ng, Analysis of half-quadratic minimization methods for signal and image recovery, SIAM Journal on Scientific computing, vol. 27, no. 3, pp. 937966, 2005. [163] Y. Sun, P. Babu, and D. P. Palomar, Majorization-minimization algorithms in signal processing, communications, and machine learning, IEEE Transactions on Signal Processing, vol. 65, no. 3, pp. 794816, 2016. [164] V. Monga, Y. Li, and Y. C. Eldar, Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing, IEEE Signal Processing Magazine, vol. 38, no. 2, pp. 1844, 2021. [165] K. Yamato and S. Ito, Super-resolution for mri using phase-scrambling fourier transform imaging and unrolling model-based network, IEEE Access, 2023. [166] Y. Wang, S. Shoushtari, and U. S. Kamilov, Diff-unfolding: modelbased score learning framework for inverse problems, arXiv preprint arXiv:2505.11393, 2025. [167] K. Zhang, L. V. Gool, and R. Timofte, Deep unfolding network for image super-resolution, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 32173226, 2020. [168] H. F. Walker and P. Ni, Anderson acceleration for fixed-point iterations, SIAM Journal on Numerical Analysis, vol. 49, no. 4, pp. 1715 1735, 2011. [169] S. Bai, J. Z. Kolter, and V. Koltun, Deep equilibrium models, Advances in neural information processing systems, vol. 32, 2019. [170] Z. Zou, J. Liu, B. Wohlberg, and U. S. Kamilov, Deep equilibrium learning of explicit regularization functionals for imaging inverse problems, IEEE Open Journal of Signal Processing, 2023. [171] G. T. Buzzard, S. H. Chan, S. Sreehari, and C. A. Bouman, Plugand-play unplugged: Optimization-free reconstruction using consensus equilibrium, SIAM Journal on Imaging Sciences, vol. 11, no. 3, pp. 20012020, 2018. [172] J. Cao, Y. Shi, K. Zhang, Y. Zhang, R. Timofte, and L. Van Gool, Deep equilibrium diffusion restoration with parallel sampling, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 28242834, 2024. [173] A. Zakeri, A. Hokmabadi, N. Bi, I. Wijesinghe, M. G. Nix, S. E. Petersen, A. F. Frangi, Z. A. Taylor, and A. Gooya, Dragnet: Learningbased deformable registration for realistic cardiac mr sequence generation from single frame, Medical Image Analysis, vol. 83, p. 102678, 2023. [174] L. Chu, B. Ma, X. Dong, Y. He, T. Che, D. Zeng, Z. Zhang, and S. Li, paired dataset of multi-modal mri at 3 tesla and 7 tesla with manual hippocampal subfield segmentations, Scientific Data, vol. 12, no. 1, p. 260, 2025. [175] J. Chun, H. Zhang, H. M. Gach, S. Olberg, T. Mazur, O. Green, T. Kim, H. Kim, J. S. Kim, S. Mutic, et al., Mri super-resolution reconstruction for mri-guided adaptive radiotherapy using cascaded deep learning: In the presence of limited training data and unknown translation model, Medical physics, vol. 46, no. 9, pp. 41484164, 2019. [176] J. Shi, Z. Li, S. Ying, C. Wang, Q. Liu, Q. Zhang, and P. Yan, Mr image super-resolution via wide residual networks with fixed skip connection, IEEE journal of biomedical and health informatics, vol. 23, no. 3, pp. 11291140, 2018. [177] Y. Zhang, K. Li, K. Li, and Y. Fu, Mr image super-resolution with squeeze and excitation reasoning attention network, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1342513434, 2021. [178] Y. Li, Y. Iwamoto, L. Lin, R. Xu, R. Tong, and Y.-W. Chen, Volumenet: lightweight parallel network for super-resolution of mr and ct volumetric data, IEEE Transactions on Image Processing, vol. 30, pp. 48404854, 2021. [179] Y. Chen, Y. Xie, Z. Zhou, F. Shi, A. G. Christodoulou, and D. Li, Brain mri super resolution using 3d deep densely connected neural networks, in 2018 IEEE 15th international symposium on biomedical imaging (ISBI 2018), pp. 739742, IEEE, 2018. [180] J. E. Iglesias, B. Billot, Y. Balbastre, C. Magdamo, S. E. Arnold, S. Das, B. L. Edlow, D. C. Alexander, P. Golland, and B. Fischl, Synthsr: public ai tool to turn heterogeneous clinical brain scans into highresolution t1-weighted images for 3d morphometry, Science advances, vol. 9, no. 5, p. eadd3607, 2023. [181] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, Unpaired image-to-image translation using cycle-consistent adversarial networks, in Proceedings of the IEEE international conference on computer vision, pp. 2223 2232, 2017. [182] H. Zhou, Y. Huang, Y. Li, Y. Zhou, and Y. Zheng, Blind superresolution of 3d mri via unsupervised domain transformation, IEEE Journal of Biomedical and Health Informatics, vol. 27, no. 3, pp. 1409 1418, 2022. [183] Y. Iwamoto, K. Takeda, Y. Li, A. Shiino, and Y.-W. Chen, Unsupervised mri super resolution using deep external learning and guided residual dense network with multimodal image priors, IEEE Transactions on Emerging Topics in Computational Intelligence, vol. 7, no. 2, pp. 426435, 2022. [184] J. Chen, S. Chen, L. Wee, A. Dekker, and I. Bermejo, Deep learning based unpaired image-to-image translation applications for medical physics: systematic review, Physics in Medicine & Biology, vol. 68, no. 5, p. 05TR01, 2023. [185] A. Shocher, N. Cohen, and M. Irani, zero-shot super-resolution using deep internal learning, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 31183126, 2018. [186] H. Zhang, Y. Zhang, Q. Wu, J. Wu, Z. Zhen, F. Shi, J. Yuan, H. Wei, C. Liu, and Y. Zhang, Self-supervised arbitrary scale super-resolution framework for anisotropic mri, in 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI), pp. 15, IEEE, 2023. [187] B. Gundogdu, M. Medved, A. Chatterjee, R. Engelmann, A. Rosado, G. Lee, N. C. Oren, A. Oto, and G. S. Karczmar, Self-supervised multicontrast super-resolution for diffusion-weighted prostate mri, Magnetic resonance in medicine, vol. 92, no. 1, pp. 319331, 2024. [188] Y. Sui, O. Afacan, A. Gholipour, and S. K. Warfield, Mri superresolution through generative degradation learning, in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 430440, Springer, 2021. [189] Y. Sui, O. Afacan, C. Jaimes, A. Gholipour, and S. K. Warfield, Unsupervised transformer learning for rapid and high-quality mri data acquisition, Health Data Science, vol. 5, p. 0340, 2025. [190] H. Chung, E. S. Lee, and J. C. Ye, Mr image denoising and superresolution using regularized reverse diffusion, IEEE Transactions on Medical Imaging, vol. 42, no. 4, pp. 922934, 2022. [191] M. F. Fathi, I. Perez-Raya, A. Baghaie, P. Berg, G. Janiga, A. Arzani, and R. M. DSouza, Super-resolution and denoising of 4d-flow mri using physics-informed deep neural nets, Computer Methods and Programs in Biomedicine, vol. 197, p. 105729, 2020. [192] N. M. Patel, E. R. Bartusiak, S. M. Rothenberger, A. Schwichtenberg, E. J. Delp, V. L. Rayz, and A. D. N. Initiative, Super-resolving and denoising 4d flow mri of neurofluids using physics-guided neural networks, Annals of Biomedical Engineering, vol. 53, no. 2, pp. 331 347, 2025. [193] C.-M. Feng, Y. Yan, H. Fu, L. Chen, and Y. Xu, Task transformer network for joint mri reconstruction and super-resolution, in Medical Image Computing and Computer Assisted InterventionMICCAI 2021: 24th International Conference, Strasbourg, France, September 27 October 1, 2021, Proceedings, Part VI 24, pp. 307317, Springer, 2021. [194] Y. Ding, T. Zhou, L. Xiang, and Y. Wu, Cross-contrast mutual fusion network for joint mri reconstruction and super-resolution, Pattern Recognition, vol. 154, p. 110599, 2024. [195] J. Chen, F. Wu, and W. Wang, Joint mr image reconstruction and super-resolution via mutual co-attention network, Journal of Computational Design and Engineering, vol. 11, no. 1, pp. 288304, 2024. [196] W. Wang, H. Shen, J. Chen, and F. Xing, Mhan: Multi-stage hybrid attention network for mri reconstruction and super-resolution, Computers in Biology and Medicine, vol. 163, p. 107181, 2023. [197] Z. Chen, H. Ren, Q. Li, and X. Li, Motion correction and superresolution for multi-slice cardiac magnetic resonance imaging via multi-stage deep learning approach, in 2024 IEEE International Symposium on Biomedical Imaging (ISBI), pp. 14, IEEE, 2024. [198] W. Zhang, B. Basaran, Q. Meng, M. Baugh, J. Stelter, P. Lung, U. Patel, W. Bai, D. Karampinos, and B. Kainz, Mocosr: Respiratory motion correction and super-resolution for 3d abdominal mri, in International Conference on Medical Image Computing and ComputerAssisted Intervention, pp. 121131, Springer, 2023. [199] Y. Liu, E. Z. Chen, X. Chen, T. Chen, and S. Sun, An unsupervised framework for joint mri super resolution and gibbs artifact removal, in International Conference on Information Processing in Medical Imaging, pp. 403414, Springer, 2023. [200] Q. Delannoy, C.-H. Pham, C. Cazorla, C. Tor-Díez, G. Dollé, H. Meunier, N. Bednarek, R. Fablet, N. Passat, and F. Rousseau, Segsrgan: Super-resolution and segmentation using generative adversarial networksapplication to neonatal brain mri, Computers in Biology and Medicine, vol. 120, p. 103755, 2020. [201] V. Corona, A. Aviles-Rivero, N. Debroux, C. Le Guyader, and C.- B. Schönlieb, Variational multi-task mri reconstruction: Joint reconstruction, registration and super-resolution, Medical Image Analysis, vol. 68, p. 101941, 2021. KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 35 [202] Q.-H. Xu and B. Li, Multi-scale fusion for spatially decoupled multimodal mri super-resolution reconstruction, IEEE Transactions on Instrumentation and Measurement, 2025. [203] B. Stimpel, C. Syben, F. Schirrmacher, P. Hoelter, A. Dörfler, and A. Maier, Multi-modal deep guided filtering for comprehensible medical image processing, IEEE transactions on medical imaging, vol. 39, no. 5, pp. 17031711, 2019. [204] G. Li, J. Lv, Y. Tian, Q. Dou, C. Wang, C. Xu, and J. Qin, Transformer-empowered multi-scale contextual matching and aggregation for multi-contrast mri super-resolution, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2063620645, 2022. [205] Y. Bengio, J. Louradour, R. Collobert, and J. Weston, Curriculum learning, in Proceedings of the 26th annual international conference on machine learning, pp. 4148, 2009. [206] R. Gao and K. Grauman, On-demand learning for deep image restoration, in Proceedings of the IEEE international conference on computer vision, pp. 10861095, 2017. [207] Z. Li, J. Yang, Z. Liu, X. Yang, G. Jeon, and W. Wu, Feedback network for image super-resolution, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 38673876, 2019. [208] Y. Wang, F. Perazzi, B. McWilliams, A. Sorkine-Hornung, O. SorkineHornung, and C. Schroers, fully progressive approach to singleimage super-resolution, in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pp. 864873, 2018. [209] A. H. Khan, C. Micheloni, and N. Martinel, Lightweight prompt learning implicit degradation estimation network for blind super resolution, IEEE Transactions on Image Processing, 2024. [210] C. Wang, J. Pan, W. Wang, J. Dong, M. Wang, Y. Ju, and J. Chen, Promptrestorer: prompting image restoration method with degradation perception, Advances in Neural Information Processing Systems, vol. 36, pp. 88988912, 2023. [211] Y. Ai, H. Huang, X. Zhou, J. Wang, and R. He, Multimodal prompt perceiver: Empower adaptiveness generalizability and fidelity for all-inone image restoration, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2543225444, June 2024. [212] X. Dong, Z. Yu, W. Cao, Y. Shi, and Q. Ma, survey on ensemble learning, Frontiers of Computer Science, vol. 14, pp. 241258, 2020. [213] R. Ghilea and I. Rekik, Replica-based federated learning with heterogeneous architectures for graph super-resolution, in International workshop on machine learning in medical imaging, pp. 273282, Springer, 2023. [214] K. Vassilo, C. Heatwole, T. Taha, and A. Mehmood, Multi-step reinforcement learning for single image super-resolution, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pp. 512513, 2020. [215] W. Chen, J. Liu, T. W. Chow, and Y. Yuan, Star-rl: Spatial-temporal hierarchical reinforcement learning for interpretable pathology image super-resolution, IEEE Transactions on Medical Imaging, 2024. [216] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton, Adaptive mixtures of local experts, Neural computation, vol. 3, no. 1, pp. 7987, 1991. [217] Z. Wang, Y. Ru, A. Chetouani, F. Chen, F. Bauer, L. Zhang, D. Hans, R. Jennane, M. Jarraya, and Y. H. Chen, Moediff-sr: Mixture of experts-guided diffusion model for region-adaptive mri super-resolution, arXiv preprint arXiv:2504.07308, 2025. [218] S. Park, J. Yoo, D. Cho, J. Kim, and T. H. Kim, Fast adaptation to super-resolution networks via meta-learning, in Computer Vision ECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part XXVII 16, pp. 754769, Springer, 2020. [219] Z. Liang and J. Zhang, Mouse brain mr super-resolution using deep learning network trained with optical imaging data, Frontiers in Radiology, vol. 3, p. 1155866, 2023. [220] Y. Xia, N. Ravikumar, J. P. Greenwood, S. Neubauer, S. E. Petersen, and A. F. Frangi, Super-resolution of cardiac mr cine imaging using conditional gans and unsupervised transfer learning, Medical Image Analysis, vol. 71, p. 102037, 2021. [221] Z. Chen, L. Yang, J.-H. Lai, and X. Xie, Cunerf: Cube-based neural radiance field for zero-shot medical image arbitrary-scale super resolution, in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 2118521195, 2023. [222] G. Wu, J. Jiang, and X. Liu, practical contrastive learning framework for single-image super-resolution, IEEE Transactions on Neural Networks and Learning Systems, 2023. [223] X. Chen, J. Pan, K. Jiang, Y. Li, Y. Huang, C. Kong, L. Dai, and Z. Fan, Unpaired deep image deraining using dual contrastive learning, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 20172026, 2022. [224] H. Li, Q. Liu, J. Liu, X. Liu, Y. Dong, T. Huang, and Z. Lv, Unpaired mri super resolution with contrastive learning, in 2024 IEEE International Symposium on Biomedical Imaging (ISBI), pp. 15, IEEE, 2024. [225] S. Huang, G. Chen, Y. Yang, X. Wang, and C. Liang, Mftn: multilevel feature transfer network based on mri-transformer for mr image super-resolution, in Proceedings of the AAAI conference on artificial intelligence, vol. 38, pp. 23662373, 2024. [226] J. W. Soh, S. Cho, and N. I. Cho, Meta-transfer learning for zeroshot super-resolution, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 35163525, 2020. [227] R. Lu, B. Liao, H. Hou, J. Lv, and X. Hai, Delta-wkv: novel meta-in-context learner for mri super-resolution, arXiv preprint arXiv:2502.20852, 2025. [228] P. Charbonnier, L. Blanc-Feraud, G. Aubert, and M. Barlaud, Two deterministic half-quadratic regularization algorithms for computed imaging, in Proceedings of 1st international conference on image processing, vol. 2, pp. 168172, IEEE, 1994. [229] B. Lim, S. Son, H. Kim, S. Nah, and K. Mu Lee, Enhanced deep residual networks for single image super-resolution, in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pp. 136144, 2017. [230] H. Zhao, O. Gallo, I. Frosio, and J. Kautz, Loss functions for image restoration with neural networks, IEEE Transactions on computational imaging, vol. 3, no. 1, pp. 4757, 2016. [231] M. Delbracio and P. Milanfar, Inversion by direct iteration: An alternative to denoising diffusion for image restoration, arXiv preprint arXiv:2303.11435, 2023. [232] M. Delbracio, H. Talebei, and P. Milanfar, Projected distribution loss for image enhancement, in 2021 IEEE International Conference on Computational Photography (ICCP), pp. 112, IEEE, 2021. [233] K. Simonyan and A. Zisserman, Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409.1556, 2014. [234] J. Johnson, A. Alahi, and L. Fei-Fei, Perceptual losses for real-time style transfer and super-resolution, in Computer VisionECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 1114, 2016, Proceedings, Part II 14, pp. 694711, Springer, 2016. [235] M. S. Sajjadi, B. Scholkopf, and M. Hirsch, Enhancenet: Single image super-resolution through automated texture synthesis, in Proceedings of the IEEE international conference on computer vision, pp. 4491 4500, 2017. [236] L. A. Gatys, A. S. Ecker, and M. Bethge, Image style transfer using convolutional neural networks, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 24142423, 2016. [237] X. Wang, K. Yu, C. Dong, and C. C. Loy, Recovering realistic texture in image super-resolution by deep spatial feature transform, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 606615, 2018. [238] C. Ledig, L. Theis, F. Huszár, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, et al., Photo-realistic single image super-resolution using generative adversarial network, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 46814690, 2017. [239] Y. Jo, S. Yang, and S. J. Kim, Investigating loss functions for extreme super-resolution, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops, pp. 424425, 2020. [240] E. Schonfeld, B. Schiele, and A. Khoreva, u-net based discriminator for generative adversarial networks, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 82078216, 2020. [241] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, Generative adversarial nets, Advances in neural information processing systems, vol. 27, 2014. [242] M. Brudfors, Y. Balbastre, P. Nachev, and J. Ashburner, Mri superresolution using multi-channel total variation, in Annual Conference on Medical Image Understanding and Analysis, pp. 217228, Springer, 2018. [243] F. Pérez-Bueno, H. B. Li, S. Nasr, C. Caballero-Gaudes, and J. E. Iglesias, Tv-based deep 3d self super-resolution for fmri, in 2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI), pp. 15, IEEE, 2025. 36 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX [244] P. Li and Y. Hu, Enhancing mrf reconstruction: model-based deep learning approach leveraging learned sparsity and physics priors, IEEE Transactions on Computational Imaging, 2024. [245] R. Wu, J. Cheng, C. Li, J. Zou, W. Fan, H. Guo, Y. Liang, and S. Wang, Spatial-angular representation learning for high-fidelity continuous super-resolution in diffusion mri, arXiv preprint arXiv:2501.16014, 2025. [246] B. Xiao, Y. Xu, H. Tang, X. Bi, and W. Li, Histogram learning in image contrast enhancement, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pp. 00, 2019. [247] B. Kim, S. Lee, N. Kim, D. Jang, and D.-S. Kim, Learning color representations for low-light image enhancement, in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 14551463, 2022. [248] X. Hua, Z. Du, H. Yu, and J. Maa, Convolutional neural network based on sparse graph attention mechanism for mri super-resolution, arXiv preprint arXiv:2305.17898, 2023. [249] H. B. Li, M. S. Rosen, S. Nasr, and J. E. Iglesias, Resolution-and stimulus-agnostic super-resolution of ultra-high-field functional mri: application to visual studies, in 2024 IEEE International Symposium on Biomedical Imaging (ISBI), pp. 15, IEEE, 2024. [250] M. D. Zeiler, D. Krishnan, G. W. Taylor, and R. Fergus, Deconvolutional networks, in 2010 IEEE Computer Society Conference on computer vision and pattern recognition, pp. 25282535, IEEE, 2010. [251] M. D. Zeiler and R. Fergus, Visualizing and understanding convolutional networks, in Computer VisionECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part 13, pp. 818833, Springer, 2014. [252] C. Fu, H. Yuan, L. Shen, R. Hamzaoui, and H. Zhang, 3dattgan: 3d attention-based generative adversarial network for joint spacetime video super-resolution, IEEE Transactions on Emerging Topics in Computational Intelligence, 2024. [253] A. Odena, V. Dumoulin, and C. Olah, Deconvolution and checkerboard artifacts, Distill, vol. 1, no. 10, p. e3, 2016. [254] W. Shi, J. Caballero, F. Huszár, J. Totz, A. P. Aitken, R. Bishop, D. Rueckert, and Z. Wang, Real-time single image and video superresolution using an efficient sub-pixel convolutional neural network, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 18741883, 2016. [255] M. Khateri, M. Ghahremani, S. Alejandra, and J. Tohka, No-cleanreference image super-resolution: Application to electron microscopy, IEEE transactions on computational imaging, vol. 10, pp. 10941110, 2024. [256] D. Qiu, Y. Cheng, and X. Wang, Progressive feedback residual attention network for cardiac magnetic resonance imaging super-resolution, IEEE Journal of Biomedical and Health Informatics, vol. 27, no. 7, pp. 34783488, 2023. [257] X. Hu, H. Mu, X. Zhang, Z. Wang, T. Tan, and J. Sun, Meta-sr: magnification-arbitrary network for super-resolution, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 15751584, 2019. [258] L. Deng, Y. Zhang, X. Yang, S. Huang, and J. Wang, Meta-learning image super-resolution., Computers, multi-scale radiology medical Materials & Continua, vol. 75, no. 2, 2023. [259] Z. Han and W. Huang, Arbitrary scale super-resolution diffusion model for brain mri images, Computers in Biology and Medicine, vol. 170, p. 108003, 2024. [260] C. Tan, J. Zhu, and P. Lio, Arbitrary scale super-resolution for brain mri images, in IFIP International Conference on Artificial Intelligence Applications and Innovations, pp. 165176, Springer, 2020. [261] G. Li, L. Zhao, J. Sun, Z. Lan, Z. Zhang, J. Chen, Z. Lin, H. Lin, and W. Xing, Rethinking multi-contrast mri super-resolution: Rectanglewindow cross-attention transformer and arbitrary-scale upsampling, in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 2123021240, 2023. [262] J. Kim, J. K. Lee, and K. M. Lee, Accurate image super-resolution using very deep convolutional networks, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 16461654, 2016. [263] K. He, X. Zhang, S. Ren, and J. Sun, Deep residual learning for image recognition, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770778, 2016. [264] Z. Han and W. Huang, Prostate mri super-resolution using discrete residual diffusion model, in 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pp. 19471950, IEEE, 2023. [265] J. Du, Z. He, L. Wang, A. Gholipour, Z. Zhou, D. Chen, and Y. Jia, Super-resolution reconstruction of single anisotropic 3d mr images using residual convolutional neural network, Neurocomputing, vol. 392, pp. 209220, 2020. [266] T. Tong, G. Li, X. Liu, and Q. Gao, Image super-resolution using dense skip connections, in Proceedings of the IEEE international conference on computer vision, pp. 47994807, 2017. [267] Y. Chen, F. Shi, A. G. Christodoulou, Y. Xie, Z. Zhou, and D. Li, Efficient and accurate mri super-resolution using generative adversarial network and 3d multi-level densely connected network, in International conference on medical image computing and computerassisted intervention, pp. 9199, Springer, 2018. [268] J. Wang, Y. Chen, Y. Wu, J. Shi, and J. Gee, Enhanced generative adversarial network for 3d brain mri super-resolution, in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 36273636, 2020. [269] J. Kim, J. K. Lee, and K. M. Lee, Deeply-recursive convolutional network for image super-resolution, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 16371645, 2016. [270] Y. Tai, J. Yang, and X. Liu, Image super-resolution via deep recursive residual network, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 31473155, 2017. [271] Y. Zhang, K. Li, K. Li, L. Wang, B. Zhong, and Y. Fu, Image superresolution using very deep residual channel attention networks, in Proceedings of the European conference on computer vision (ECCV), pp. 286301, 2018. [272] J. Hu, L. Shen, and G. Sun, Squeeze-and-excitation networks, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 71327141, 2018. [273] T. Dai, J. Cai, Y. Zhang, S.-T. Xia, and L. Zhang, Second-order attention network for single image super-resolution, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 1106511074, 2019. [274] S. Woo, J. Park, J.-Y. Lee, and I. S. Kweon, Cbam: Convolutional block attention module, in Proceedings of the European conference on computer vision (ECCV), pp. 319, 2018. [275] J. Liu, W. Zhang, Y. Tang, J. Tang, and G. Wu, Residual feature aggregation network for image super-resolution, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 23592368, 2020. [276] B. Niu, W. Wen, W. Ren, X. Zhang, L. Yang, S. Wang, K. Zhang, X. Cao, and H. Shen, Single image super-resolution via holistic attention network, in Computer VisionECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part XII 16, pp. 191207, Springer, 2020. [277] J. Liang, J. Cao, G. Sun, K. Zhang, L. Van Gool, and R. Timofte, Swinir: Image restoration using swin transformer, in Proceedings of the IEEE/CVF international conference on computer vision, pp. 1833 1844, 2021. [278] Z. Chen, Y. Zhang, J. Gu, L. Kong, X. Yang, and F. Yu, Dual aggregation transformer for image super-resolution, in Proceedings of the IEEE/CVF international conference on computer vision, pp. 12312 12321, 2023. [279] Y. Wang, Y. Li, G. Wang, and X. Liu, Multi-scale attention network for single image super-resolution, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5950 5960, 2024. [280] J. Lyu, S. Wang, Y. Tian, J. Zou, S. Dong, C. Wang, A. I. AvilesRivero, and J. Qin, Stadnet: Spatial-temporal attention-guided dualpath network for cardiac cine mri super-resolution, Medical Image Analysis, vol. 94, p. 103142, 2024. [281] H. Chen, Y. Wang, T. Guo, C. Xu, Y. Deng, Z. Liu, S. Ma, C. Xu, C. Xu, and W. Gao, Pre-trained image processing transformer, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 1229912310, 2021. [282] J. Lyu, G. Li, C. Wang, Q. Cai, Q. Dou, D. Zhang, and J. Qin, Multicontrast mri super-resolution via transformer-empowered multiscale contextual matching and aggregation, IEEE Transactions on Neural Networks and Learning Systems, 2023. [283] S. Huang, J. Li, L. Mei, T. Zhang, Z. Chen, Y. Dong, L. Dong, S. Liu, and M. Lyu, Accurate multi-contrast mri super-resolution via dual cross-attention transformer network, in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 313322, Springer, 2023. KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 37 [284] J. Hu, Y. Qin, H. Wang, and J. Han, Ms2cam: Multi-scale self-crossattention mechanism-based mri super-resolution, Displays, vol. 88, p. 103033, 2025. [285] X. Hua, Z. Du, J. Ma, and H. Yu, Multi kernel cross sparse graph attention convolutional neural network for brain magnetic resonance imaging super-resolution, Biomedical Signal Processing and Control, vol. 96, p. 106444, 2024. [286] J. Zhao, T. Hong, H. Qi, Z. Zhou, and H. Wang, lightweight 3d distillation volumetric transformer for 3d mri super-resolution, IEEE Journal of Biomedical and Health Informatics, 2025. [287] O. Ronneberger, P. Fischer, and T. Brox, U-net: Convolutional networks for biomedical image segmentation, in Medical image computing and computer-assisted interventionMICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18, pp. 234241, Springer, 2015. [288] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, Densely connected convolutional networks, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700 4708, 2017. [289] C. Saharia, J. Ho, W. Chan, T. Salimans, D. J. Fleet, and M. Norouzi, Image super-resolution via iterative refinement, IEEE transactions on pattern analysis and machine intelligence, vol. 45, no. 4, pp. 4713 4726, 2022. [290] C. Dong, C. C. Loy, K. He, and X. Tang, Image super-resolution using deep convolutional networks, IEEE transactions on pattern analysis and machine intelligence, vol. 38, no. 2, pp. 295307, 2015. [291] C.-H. Pham, A. Ducournau, R. Fablet, and F. Rousseau, Brain mri super-resolution using deep 3d convolutional networks, in 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), pp. 197200, IEEE, 2017. [292] K. Bahrami, F. Shi, I. Rekik, and D. Shen, Convolutional neural network for reconstruction of 7t-like images from 3t mri using appearance and anatomical features, in International Workshop on Deep Learning in Medical Image Analysis, pp. 3947, Springer, 2016. [293] Z. Zhou, A. Ma, Q. Feng, R. Wang, L. Cheng, X. Chen, X. Yang, K. Liao, Y. Miao, and Y. Qiu, Super-resolution of brain tumor mri images based on deep learning, Journal of Applied Clinical Medical Physics, vol. 23, no. 11, p. e13758, 2022. [294] D. Zhu and D. Qiu, Residual dense network for medical magnetic resonance images super-resolution, Computer Methods and Programs in Biomedicine, vol. 202, p. 105969, 2021. [295] J. Du, L. Wang, Y. Liu, Z. Zhou, Z. He, and Y. Jia, Brain mri superresolution using 3d dilated convolutional encoderdecoder network, IEEE Access, vol. 8, pp. 1893818950, 2020. [296] M. Lyon, P. Armitage, and M. A. Álvarez, Spatio-angular convolutions for super-resolution in diffusion mri, Advances in Neural Information Processing Systems, vol. 36, 2024. [297] Z. Ji, B. Zou, X. Kui, P. Vera, and S. Ruan, Deform-mamba network for mri super-resolution, arXiv preprint arXiv:2407.05969, 2024. [298] Z. Ji, B. Zou, X. Kui, P. Vera, and S. Ruan, Self-prior guided mambaimage super-resolution, arXiv preprint unet networks for medical arXiv:2407.05993, 2024. [299] Z. Yang, J. Li, H. Zhang, D. Zhao, B. Wei, and Y. Xu, Restore-rwkv: Efficient and effective medical image restoration with rwkv, IEEE Journal of Biomedical and Health Informatics, 2025. [300] K. Zhang, H. Hu, K. Philbrick, G. M. Conte, J. D. Sobek, P. Rouzrokh, and B. J. Erickson, Soup-gan: Super-resolution mri using generative adversarial networks, Tomography, vol. 8, no. 2, pp. 905919, 2022. [301] Y. Xiao, C. Chen, L. Wang, J. Yu, X. Fu, Y. Zou, Z. Lin, and K. Wang, novel hybrid generative adversarial network for ct and mri superresolution reconstruction, Physics in Medicine & Biology, vol. 68, no. 13, p. 135007, 2023. [302] Q. Zhang, Y. Hang, F. Wu, S. Wang, and Y. Hong, Super-resolution of 3d medical images by generative adversarial networks with long and short-term memory and attention, Scientific Reports, vol. 15, no. 1, p. 20828, 2025. [303] J. Wang, J. Levman, W. H. L. Pinaya, P.-D. Tudosiu, M. J. Cardoso, and R. Marinescu, Inversesr: 3d brain mri super-resolution using latent diffusion model, in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 438447, Springer, 2023. [304] Z. Yue, J. Wang, and C. C. Loy, Resshift: Efficient diffusion model for image super-resolution by residual shifting, Advances in Neural Information Processing Systems, vol. 36, pp. 1329413307, 2023. [305] M. Safari, S. Wang, Z. Eidex, Q. Li, E. H. Middlebrooks, D. S. Yu, and X. Yang, Mri super-resolution reconstruction using efficient diffusion probabilistic model with residual shifting, arXiv preprint arXiv:2503.01576, 2025. [306] Z. Li, Z. Li, H. Li, Q. Fan, K. L. Miller, W. Wu, A. S. Chaudhari, and Q. Tian, Enhance the image: Super resolution using artificial intelligence in mri, arXiv preprint arXiv:2406.13625, 2024. [307] H. Liu, Z. Li, F. Shang, Y. Liu, L. Wan, W. Feng, and R. Timofte, Arbitrary-scale super-resolution via deep learning: comprehensive survey, Information Fusion, vol. 102, p. 102015, 2024. [308] J. Lyu, G. Wang, Z. Wang, S. Dong, W. Ding, and C. Wang, Diffusionprior based implicit neural representation for arbitrary-scale cardiac cine mri super-resolution, Information Fusion, p. 103510, 2025. [309] S. Saitta, M. Carioni, S. Mukherjee, C.-B. Schönlieb, and A. Redaelli, Implicit neural representations for unsupervised super-resolution and denoising of 4d flow mri, Computer methods and programs in biomedicine, vol. 246, p. 108057, 2024. [310] J. Wei, G. Yang, W. Wei, A. Liu, and X. Chen, Multi-contrast mri arbitrary-scale super-resolution via dynamic implicit network, IEEE Transactions on Circuits and Systems for Video Technology, 2025. [311] J. McGinnis, S. Shit, H. B. Li, V. Sideri-Lampretsa, R. Graf, M. Dannecker, J. Pan, N. S. Ansó, M. Mühlau, J. S. Kirschke, et al., Multicontrast mri super-resolution via implicit neural representations, CoRR, 2023. [312] L. Liu, J. Zou, C. Xu, K. Wang, J. Lyu, X. Xu, Z. Hu, and J. Qin, Im-diff: Implicit multi-contrast diffusion model for arbitrary scale mri super-resolution, IEEE Journal of Biomedical and Health Informatics, 2025. [313] Y. Li, Y.-P. Liao, J. Wang, W. Lu, and Y. Zhang, Patient-specific mri super-resolution via implicit neural representations and knowledge transfer, Physics in Medicine & Biology, vol. 70, no. 7, p. 075021, 2025. [314] W. Fang, Y. Tang, H. Guo, M. Yuan, T. C. Mok, K. Yan, J. Yao, X. Chen, Z. Liu, L. Lu, et al., Cycleinr: Cycle implicit neural representation for arbitrary-scale volumetric super-resolution of medical data, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1163111641, 2024. [315] J. Hu, B. Xia, B. Chen, W. Yang, and L. Zhang, Gaussiansr: High fidelity 2d gaussian splatting for arbitrary-scale image super-resolution, in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 39, pp. 35543562, 2025. [316] D. Chen, L. Chen, Z. Zhang, and L. Zhang, Generalized and efficient 2d gaussian splatting for arbitrary-scale super-resolution, arXiv preprint arXiv:2501.06838, 2025. [317] T. Peng, R. Zha, Z. Li, X. Liu, and Q. Zou, Three-dimensional mri reconstruction with gaussian representations: Tackling the undersampling problem, arXiv preprint arXiv:2502.06510, 2025. [318] Z. Li, J. Yu, Y. Wang, H. Zhou, H. Yang, and Z. Qiao, Deepvolume: Brain structure and spatial connection-aware network for brain mri super-resolution, IEEE transactions on cybernetics, vol. 51, no. 7, pp. 34413454, 2019. [319] N. Basty and V. Grau, Super resolution of cardiac cine mri sequences using deep learning, in Image Analysis for Moving Organ, Breast, and Thoracic Images: Third International Workshop, RAMBO 2018, Fourth International Workshop, BIA 2018, and First International Workshop, TIA 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16 and 20, 2018, Proceedings 3, pp. 2331, Springer, 2018. [320] C. Qin, J. Schlemper, J. Caballero, A. N. Price, J. V. Hajnal, and D. Rueckert, Convolutional recurrent neural networks for dynamic mr image reconstruction, IEEE transactions on medical imaging, vol. 38, no. 1, pp. 280290, 2018. [321] S. Chatterjee, C. Sarasaen, G. Rose, A. Nürnberger, and O. Speck, Ddos-unet: Incorporating temporal information using dynamic dualchannel unet for enhancing super-resolution of dynamic mri, IEEE Access, 2024. [322] M. Isallari and I. Rekik, Brain graph super-resolution using adversarial graph neural network with application to functional brain connectivity, Medical Image Analysis, vol. 71, p. 102084, 2021. [323] J. Ma and H. Cui, Hybrid graph convolutional neural networks for super resolution of dw images, in Computational Diffusion MRI: International MICCAI Workshop, Lima, Peru, October 2020, pp. 201 212, Springer, 2021. [324] Q. Ma, Z. Lai, Z. Wang, Y. Qiu, H. Zhang, and X. Qu, Mri reconstruction with enhanced self-similarity using graph convolutional network, BMC Medical Imaging, vol. 24, no. 1, p. 113, 2024. [325] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al., On the opportunities and risks of foundation models, arXiv preprint arXiv:2108.07258, 2021. IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2025 [326] Y. Sun, L. Wang, G. Li, W. Lin, and L. Wang, foundation model for enhancing magnetic resonance images and downstream segmentation, registration and diagnostic tasks, Nature Biomedical Engineering, vol. 9, no. 4, pp. 521538, 2025. [327] Z. Qin, Z. He, Y. Zhang, Y. Shen, and K. Li, Graphmsr: graph foundation model-based approach for mri image super-resolution with multimodal semantic integration, Pattern Recognition, p. 112178, 2025. [328] J. Ho, A. Jain, and P. Abbeel, Denoising diffusion probabilistic models, Advances in neural information processing systems, vol. 33, pp. 68406851, 2020. [329] C. He, Y. Shen, C. Fang, F. Xiao, L. Tang, Y. Zhang, W. Zuo, Z. Guo, and X. Li, Diffusion models in low-level vision: survey, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2025. [330] Y. Song and S. Ermon, Generative modeling by estimating gradients of the data distribution, Advances in neural information processing systems, vol. 32, 2019. [331] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole, Score-based generative modeling through stochastic differential equations, arXiv preprint arXiv:2011.13456, 2020. [332] J. Song, C. Meng, and S. Ermon, Denoising diffusion implicit models, arXiv preprint arXiv:2010.02502, 2020. [333] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, High-resolution image synthesis with latent diffusion models, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 1068410695, 2022. [334] Z. Wu, X. Chen, S. Xie, J. Shen, and Y. Zeng, Super-resolution of brain mri images based on denoising diffusion probabilistic model, Biomedical Signal Processing and Control, vol. 85, p. 104901, 2023. [335] K. Zhao, K. Pang, A. L. Y. Hung, H. Zheng, R. Yan, and K. Sung, Mri super-resolution with partial diffusion models, IEEE Transactions on Medical Imaging, 2024. [336] J. Ma, G. Jian, and J. Chen, Diffusion model-based mri superresolution synthesis, International Journal of Imaging Systems and Technology, vol. 35, no. 2, p. e70021, 2025. [337] D. Qiu, Y. Cheng, K. K. Wong, W. Zhang, Z. Yi, and X. Wang, Dbsr: Quadratic conditional diffusion model for blind cardiac mri superresolution, IEEE Transactions on Multimedia, 2024. [338] C.-W. Chang, J. Peng, M. Safari, E. Salari, S. Pan, J. Roper, R. L. Qiu, Y. Gao, H.-K. Shu, H. Mao, et al., High-resolution mri synthesis using data-driven framework with denoising diffusion probabilistic modeling, Physics in Medicine & Biology, vol. 69, no. 4, p. 045001, 2024. [339] G. Chen, Z. Zhu, Z. Liu, C. Lin, S. Zheng, H. Xu, Y. Zhao, and K. He, Edge-guided conditional diffusion model for multi-contrast mri superresolution, Information Fusion, p. 103514, 2025. [340] Y. Mao, L. Jiang, X. Chen, and C. Li, Disc-diff: Disentangled conditional diffusion model for multi-contrast mri super-resolution, in International Conference on Medical Image Computing and ComputerAssisted Intervention, pp. 387397, Springer, 2023. [341] Y. Liu, Z.-X. Cui, S. Qin, C. Liu, H. Zheng, H. Wang, Y. Zhou, D. Liang, and Y. Zhu, Score-based diffusion models with selfsupervised learning for accelerated 3d multi-contrast cardiac mr imaging, IEEE Transactions on Medical Imaging, 2025. [342] C. Cao, Z.-X. Cui, Y. Wang, S. Liu, T. Chen, H. Zheng, D. Liang, and Y. Zhu, High-frequency space diffusion model for accelerated mri, IEEE Transactions on Medical Imaging, vol. 43, no. 5, pp. 18531865, 2024. [343] W. Wu, Y. Wang, Q. Liu, G. Wang, and J. Zhang, Wavelet-improved score-based generative model for medical imaging, IEEE transactions on medical imaging, 2023. [344] R. Hou, F. Li, and T. Zeng, Fast and reliable score-based generative model for parallel mri, IEEE Transactions on Neural Networks and Learning Systems, 2023. [345] D. Yoon, Y. Myong, Y. G. Kim, Y. Sim, M. Cho, B.-M. Oh, and S. Kim, Latent diffusion model-based mri superresolution enhances mild cognitive impairment prognostication and alzheimers disease classification, NeuroImage, vol. 296, p. 120663, 2024. [346] J. A. Mármol-Rivera, J. D. Fernández-Rodríguez, B. Asenjo, and E. López-Rubio, Latent diffusion for arbitrary zoom mri superresolution, Expert Systems with Applications, p. 127970, 2025. [347] J. Choi, S. Kim, Y. Jeong, Y. Gwon, and S. Yoon, Ilvr: Conditioning method for denoising diffusion probabilistic models, arXiv preprint arXiv:2108.02938, 2021. [348] B. Kawar, M. Elad, S. Ermon, and J. Song, Denoising diffusion restoration models, Advances in neural information processing systems, vol. 35, pp. 2359323606, 2022. [349] H. Chung, J. Kim, M. T. Mccann, M. L. Klasky, and J. C. Ye, Diffusion posterior sampling for general noisy inverse problems, arXiv preprint arXiv:2209.14687, 2022. [350] G. Daras, H. Chung, C.-H. Lai, Y. Mitsufuji, J. C. Ye, P. Milanfar, A. G. Dimakis, and M. Delbracio, survey on diffusion models for inverse problems, arXiv preprint arXiv:2410.00083, 2024. [351] D. P. Kingma and M. Welling, Auto-encoding variational bayes, arXiv preprint arXiv:1312.6114, 2013. [352] A. B. L. Larsen, S. K. Sønderby, H. Larochelle, and O. Winther, Autoencoding beyond pixels using learned similarity metric, in International conference on machine learning, pp. 15581566, PMLR, 2016. [353] Y. Blau and T. Michaeli, The perception-distortion tradeoff, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 62286237, 2018. [354] J. Andrew, T. Mhatesh, R. D. Sebastin, K. M. Sagayam, J. Eunice, M. Pomplun, and H. Dang, Super-resolution reconstruction of brain magnetic resonance images via lightweight autoencoder, Informatics in Medicine Unlocked, vol. 26, p. 100713, 2021. [355] J. Kapoor, J. H. Macke, and C. F. Baumgartner, Multiscale metamorphic vae for 3d brain mri synthesis, arXiv preprint arXiv:2301.03588, 2023. [356] K. Ko, B. Lee, J. Hong, D. Kim, and H. Ko, Mriflow: Magnetic resonance image super-resolution based on normalizing flow and frequency prior, Journal of Magnetic Resonance, vol. 352, p. 107477, 2023. [357] S. Dong, Z. Cai, G. Hangel, W. Bogner, G. Widhalm, Y. Huang, Q. Liang, C. You, C. Kumaragamage, R. K. Fulbright, et al., flow-based truncated denoising diffusion model for super-resolution magnetic resonance spectroscopic imaging, Medical Image Analysis, vol. 99, p. 103358, 2025. [358] J. Shen and H.-W. Shen, Psrflow: Probabilistic super resolution with flow-based models for scientific data, IEEE Transactions on Visualization and Computer Graphics, vol. 30, no. 1, pp. 986996, 2023. [359] Y. Chen, A. G. Christodoulou, Z. Zhou, F. Shi, Y. Xie, and D. Li, Mri super-resolution with gan and 3d multi-level densenet: smaller, faster, and better, arXiv preprint arXiv:2003.01217, 2020. [360] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, Image quality assessment: from error visibility to structural similarity, IEEE transactions on image processing, vol. 13, no. 4, pp. 600612, 2004. [361] Z. Wang, E. P. Simoncelli, and A. C. Bovik, Multiscale structural similarity for image quality assessment, in The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003, vol. 2, pp. 1398 1402, Ieee, 2003. [362] H. R. Sheikh and A. C. Bovik, Image information and visual quality, IEEE Transactions on image processing, vol. 15, no. 2, pp. 430444, 2006. [363] M. Bernstein, Handbook of MRI pulse sequences. Elsevier, 2004. [364] V. A. Kelkar, X. Zhang, J. Granstedt, H. Li, and M. A. Anastasio, Task-based evaluation of deep image super-resolution in medical imaging, in Medical Imaging 2021: Image Perception, Observer Performance, and Technology Assessment, vol. 11599, pp. 207213, SPIE, 2021. [365] R. Nian, M. Gao, S. Zhang, J. Yu, A. Gholipour, S. Kong, R. Wang, Y. Sui, C. Velasco-Annis, X. Tomas-Fernandez, et al., Toward evaluation of multiresolution cortical thickness estimation with freesurfer, macruise, and brainsuite, Cerebral Cortex, vol. 33, no. 9, pp. 5082 5096, 2023. [366] J. D. Rudie, T. Gleason, M. J. Barkovich, D. M. Wilson, A. Shankaranarayanan, T. Zhang, L. Wang, E. Gong, G. Zaharchuk, and J. E. Villanueva-Meyer, Clinical assessment of deep learningbased superresolution for 3d volumetric brain mri, Radiology: Artificial Intelligence, vol. 4, no. 2, p. e210059, 2022. [367] Y. Terada, T. Miyasaka, A. Nakao, S. Funayama, S. Ichikawa, T. Takamura, D. Tamada, H. Morisaka, and H. Onishi, Clinical evaluation of super-resolution for brain mri images based on generative adversarial networks, Informatics in Medicine Unlocked, vol. 32, p. 101030, 2022. [368] I. Stepien and M. Oszust, No-reference image quality assessment of magnetic resonance images with multi-level and multi-model representations based on fusion of deep architectures, Engineering Applications of Artificial Intelligence, vol. 123, p. 106283, 2023. [369] N. Rubert, D. M. Bardo, J. Vaughn, P. Cornejo, and L. F. Goncalves, Data quality assessment for super-resolution fetal brain mr imaging: retrospective 1.5 study, Journal of Magnetic Resonance Imaging, vol. 54, no. 4, pp. 13491360, 2021. KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 39 [370] J. Vosshenrich, H.-C. Breit, R. Donners, M. M. Obmann, S. S. Walter, A. Serfaty, T. C. Rodrigues, M. Recht, S. E. Stern, and J. Fritz, Clinical implementation of sixfold-accelerated deep learning super-resolution knee mri in under 5 minutes: Arthroscopy-validated diagnostic performance, American Journal of Roentgenology, 2025. [371] G. A. Wintergerst, S. W. Remedios, A. T. Newton, S. A. Smith, B. A. Landman, and K. G. Schilling, Measuring impact of super-resolution on spinal cord mri scans: Lesion detection sensitivity, variability, and impact, in 2025 IEEE 22nd International Symposium on clinical Biomedical Imaging (ISBI), pp. 15, IEEE, 2025. [372] T. Sanchez, V. Zalevskyi, A. Mihailov, G. Martí-Juan, E. Eixarch, A. Jakab, V. Dunet, M. Koob, G. Auzias, and M. B. Cuadra, Automatic quality control in multi-centric fetal brain mri super-resolution reconstruction, arXiv preprint arXiv:2503.10156, 2025. [373] H. Talebi and P. Milanfar, Nima: Neural image assessment, IEEE transactions on image processing, vol. 27, no. 8, pp. 39984011, 2018. [374] R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang, The unreasonable effectiveness of deep features as perceptual metric, in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 586595, 2018. [375] S. Kastryulin, J. Zakirov, N. Pezzotti, and D. V. Dylov, Image quality assessment for magnetic resonance imaging, IEEE Access, vol. 11, pp. 1415414168, 2023. [376] Y. Deo, Y. Jia, T. Lassila, W. A. Smith, T. Lawton, S. Kang, A. F. Frangi, and I. Habli, Metrics that matter: Evaluating imimage generation, arXiv preprint age quality metrics for medical arXiv:2505.07175, 2025. [377] Z. You, Z. Li, J. Gu, Z. Yin, T. Xue, and C. Dong, Depicting beyond scores: Advancing image quality assessment through multimodal language models, in European Conference on Computer Vision, pp. 259276, Springer, 2025. [378] R. Cohen, I. Kligvasser, E. Rivlin, and D. Freedman, Looks too good to be true: An information-theoretic analysis of hallucinations in generative restoration models, arXiv preprint arXiv:2405.16475, 2024. [379] D. W. McRobbie, E. A. Moore, M. J. Graves, and M. R. Prince, MRI from Picture to Proton. Cambridge university press, 2017. [380] https://fastmri.med.nyu.edu/. [381] J. Zbontar, F. Knoll, A. Sriram, T. Murrell, Z. Huang, M. J. Muckley, A. Defazio, R. Stern, P. Johnson, M. Bruno, et al., fastmri: An open dataset and benchmarks for accelerated mri, arXiv preprint arXiv:1811.08839, 2018. [382] https://www.na-mic.org/wiki/Downloads. [383] https://brain-development.org/ixi-dataset/. [384] https://www.humanconnectome.org/study/ hcp-young-adult/data-releases. [385] D. C. Van Essen, S. M. Smith, D. M. Barch, T. E. Behrens, E. Yacoub, K. Ugurbil, W.-M. H. Consortium, et al., The wu-minn human connectome project: an overview, Neuroimage, vol. 80, pp. 6279, 2013. [386] A. Makropoulos, E. C. Robinson, A. Schuh, R. Wright, S. P. Fitzgibbon, J. Bozek, S. J. Counsell, D. Rueckert, and A. D. Edwards, The developing human connectome project: Typical and atypical brain development in early life, NeuroImage, vol. 185, pp. 891905, 2019. [387] A. Gholipour, C. K. Rollins, C. Velasco-Annis, A. Ouaalam, A. Akhondi-Asl, O. Afacan, C. M. Ortinau, S. Clancy, C. Limperopoulos, E. Yang, et al., normative spatiotemporal mri atlas of the fetal brain for automatic segmentation and analysis of early brain growth, Scientific reports, vol. 7, no. 1, p. 476, 2017. [388] J. Luo, E. Abaci Turk, C. Bibbo, B. Gagoski, D. J. Roberts, M. Vangel, C. M. Tempany-Afdhal, C. Barnewolt, J. Estroff, A. Palanisamy, et al., In vivo quantification of placental insufficiency by bold mri: human study, Scientific reports, vol. 7, no. 1, p. 3713, 2017. [389] S. Bakas, M. Reyes, A. Jakab, S. Bauer, M. Rempfler, A. Crimi, R. T. Shinohara, C. Berger, S. M. Ha, M. Rozycki, et al., Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the brats challenge, arXiv preprint arXiv:1811.02629, 2018. [390] C. T. Lloyd, A. Sorichetta, and A. J. Tatem, High resolution global gridded data for use in population studies, Scientific data, vol. 4, no. 1, pp. 117, 2017. [391] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby, Y. Burren, N. Porz, J. Slotboom, R. Wiest, et al., The multimodal brain tumor image segmentation benchmark (brats), IEEE transactions on medical imaging, vol. 34, no. 10, pp. 19932024, 2014. J. Gorgolewski, F. Feingold, R. Blair, Y. O. Halchenko, E. Miller, N. Hardcastle, J. Wexler, O. Esteban, J. Markiewicz, K. [392] C. M. Goncavles, et al., The openneuro resource for sharing of neuroscience data, Elife, vol. 10, p. e71774, 2021. [393] A. Gramfort and M. S. Hämäläinen, ds000248, 2020. Version 1.2.4. [394] M. Antonelli, A. Reinke, S. Bakas, K. Farahani, A. Kopp-Schneider, B. A. Landman, G. Litjens, B. Menze, O. Ronneberger, R. M. Summers, et al., The medical segmentation decathlon, Nature communications, vol. 13, no. 1, p. 4128, 2022. [395] Medical segmentation decathlon. http://medicaldecathlon. com/. Accessed: 2025-08-15. [396] Alzheimers Disease Neuroimaging Initiative, Adni data. https: //adni.loni.usc.edu/data-samples/adni-data/, 20032025. [397] K. Clark, B. Vendt, K. Smith, J. Freymann, J. Kirby, P. Koppel, S. Moore, S. Phillips, D. Maffitt, M. Pringle, et al., The cancer imaging archive (tcia): maintaining and operating public information repository, Journal of digital imaging, vol. 26, no. 6, pp. 10451057, 2013. [398] Y. Liu, A. T. Leong, Y. Zhao, L. Xiao, H. K. Mak, A. C. O. Tsang, G. K. Lau, G. K. Leung, and E. X. Wu, low-cost and shielding-free ultra-low-field brain mri scanner, Nature Communications, vol. 12, no. 1, p. 7238, 2021. [399] E. Author and et al., Global inequities in access to mri technology: quantitative analysis, Nature Communications, vol. 12, no. 1, p. 7238, 2021. [400] S. Murali, H. Ding, F. Adedeji, C. Qin, J. Obungoloch, I. Asllani, U. Anazodo, N. A. Ntusi, R. Mammen, T. Niendorf, et al., Bringing mri to low-and middle-income countries: directions, challenges and potential solutions, NMR in Biomedicine, vol. 37, no. 7, p. e4992, 2024. [401] M. Jalloul, M. Miranda-Schaeubinger, A. M. Noor, J. M. Stein, R. Amiruddin, H. M. Derbew, V. L. Mango, A. Akinola, K. Hart, J. Weygand, et al., Mri scarcity in low-and middle-income countries, NMR in Biomedicine, vol. 36, no. 12, p. e5022, 2023. [402] E. Ljungberg, F. Padormo, M. Poorman, P. Clemensson, N. Bourke, J. C. Evans, J. Gholam, I. Vavasour, S. H. Kollind, S. L. Lafayette, et al., Characterization of portable ultra-low field mri scanners for multi-center structural neuroimaging, Human Brain Mapping, vol. 46, no. 8, p. e70217, 2025. [403] V. Lau, L. Xiao, Y. Zhao, S. Su, Y. Ding, C. Man, X. Wang, A. Tsang, P. Cao, G. K. Lau, et al., Pushing the limits of low-cost ultra-low-field mri by dual-acquisition deep learning 3d superresolution, Magnetic Resonance in Medicine, vol. 90, no. 2, pp. 400416, 2023. [404] M. Figini, H. Lin, F. DArco, G. Ogbole, M. C. Rossi-Espagnet, O. I. Oyinloye, J. Yaria, D. A. Nzeh, M. O. Atalabi, D. W. Carmichael, et al., Evaluation of epilepsy lesion visualisation enhancement in low-field mri using image quality transfer: preliminary investigation of clinical potential for applications in developing countries, Neuroradiology, pp. 110, 2024. [405] L. Baljer, Y. Zhang, N. J. Bourke, K. A. Donald, L. E. Bradford, J. E. Ringshaw, S. R. Williams, S. C. Deoni, S. C. Williams, K. S. S. Team, et al., Ultra-low-field paediatric mri in low-and middle-income countries: Super-resolution using multi-orientation u-net, Human Brain Mapping, vol. 46, no. 1, p. e70112, 2025. [406] L. Baljer, U. Briski, R. Leech, N. J. Bourke, K. A. Donald, L. E. Bradford, S. R. Williams, S. Parkar, S. Kaleem, S. Osmani, et al., Gambas: Generalised-hilbert mamba for super-resolution of paediatric ultra-low-field mri, arXiv preprint arXiv:2504.04523, 2025. [407] L. Baljer, Y. Zhang, N. Bourke, K. Donald, L. Bradford, J. Ringshaw, S. Williams, S. Deoni, S. Williams, F. Váša, et al., Multi-orientation u-net for super-resolution of ultra-low-field paediatric mri, 2024. [408] J. Yuan, O. L. Wong, Y. Zhou, K. Y. Chueng, and S. K. Yu, fast volumetric 4d-mri with sub-second frame rate for abdominal motion monitoring and characterization in mri-guided radiotherapy, Quantitative imaging in medicine and surgery, vol. 9, no. 7, p. 1303, 2019. [409] J. Grover, P. Liu, B. Dong, S. Shan, B. Whelan, P. Keall, and D. E. Waddington, Super-resolution neural networks improve the spatiotemporal resolution of adaptive mri-guided radiation therapy, Communications Medicine, vol. 4, no. 1, p. 64, 2024. [410] G. Huang, X. Chen, Y. Shen, and S. Wang, Mr image super-resolution using wavelet diffusion for predicting alzheimers disease, in International Conference on Brain Informatics, pp. 146157, Springer, 2023. [411] O. Grigas, R. Damaševiˇcius, and R. Maskeliunas, Positive effect of super-resolved structural magnetic resonance imaging for mild cognitive impairment detection, Brain sciences, vol. 14, no. 4, p. 381, 2024. 40 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX [412] C. C. Tsai, X. Chen, S. Ahmad, and P.-T. Yap, Robust unsupervised super-resolution of infant mri via dual-modal deep image prior, in International Workshop on Machine Learning in Medical Imaging, pp. 4251, Springer, 2023. [413] D. E. Martinez, W. Meinhold, J. Oshinski, A.-P. Hu, and J. Ueda, Super resolution for improved positioning of an mri-guided spinal cellular injection robot, Journal of Medical Robotics Research, vol. 6, no. 01n02, p. 2140002, 2021. [414] F. Wang, X. Sun, Z. Ma, and J. Li, Stereo attention-based all-in-one super-resolution for robot-assisted minimally invasive surgery, Journal of Robotic Surgery, vol. 18, no. 1, p. 27, 2024. [415] C. Donnay, S. V. Okar, C. Tsagkas, M. I. Gaitán, M. Poorman, D. S. Reich, and G. Nair, Super resolution using sparse sampling at portable ultra-low field mr, Frontiers in Neurology, vol. 15, p. 1330203, 2024. [416] H. H. Lee, A. M. Saunders, M. E. Kim, S. W. Remedios, L. W. Remedios, Y. Tang, Q. Yang, X. Yu, S. Bao, C. Cho, et al., Superresolution multi-contrast unbiased eye atlases with deep probabilistic refinement, Journal of Medical Imaging, vol. 11, no. 6, pp. 064004 064004, 2024. [417] J.-Y. Lin, Y.-C. Chang, and W. H. Hsu, Efficient and phase-aware video super-resolution for cardiac mri, in Medical Image Computing and Computer Assisted InterventionMICCAI 2020: 23rd International Conference, Lima, Peru, October 48, 2020, Proceedings, Part IV 23, pp. 6676, Springer, 2020. [418] B. Dewey, S. Remedios, M. Sanjayan, N. Rjeily, A. Lee, C. Wyche, S. Duncan, J. Prince, P. Calabresi, K. Fitzgerald, and E. Mowry, Superresolution in clinically available spinal cord mris enables automated atrophy analysis, AJNR Am Neuroradiol, 2024. Epub ahead of print. [419] S. Wu, W. Chen, Z. Li, S. Wang, H. Sun, and X. Song, Comet: Crossspace optimization-based mutual learning network for super-resolution of cest-mri, IEEE Journal of Biomedical and Health Informatics, 2023. [420] A. Güngör, B. Askin, D. A. Soydan, E. U. Saritas, C. B. Top, and T. Çukur, Transms: Transformers for super-resolution calibration in magnetic particle imaging, IEEE Transactions on Medical Imaging, vol. 41, no. 12, pp. 35623574, 2022. [421] J. Ota, K. Umehara, J. Kershaw, R. Kishimoto, Y. Hirano, Y. Tachibana, H. Ohba, and T. Obata, Super-resolution generative adversarial networks with static t2* wi-based subject-specific learning to improve spatial difference sensitivity in fmri activation, Scientific Reports, vol. 12, no. 1, p. 10319, 2022. [422] Z. Iqbal, D. Nguyen, G. Hangel, S. Motyka, W. Bogner, and S. Jiang, Super-resolution 1h magnetic resonance spectroscopic imaging utilizing deep learning, Frontiers in oncology, vol. 9, p. 1010, 2019. [423] M. Hou, L. Zhou, and J. Sun, Deep-learning-based 3d super-resolution mri radiomics model: superior predictive performance in preoperative t-staging of rectal cancer, European radiology, vol. 33, no. 1, pp. 110, 2023. [424] K. Wang, W. V. Liu, R. Yang, L. Li, X. Lu, H. Lei, J. Jiang, and Y. Zha, Super-resolution synthetic mri using deep learning reconstruction for accurate diagnosis of knee osteoarthritis, Insights into Imaging, vol. 16, no. 1, p. 44, 2025. [425] Z. Song, Y. Zhao, X. Li, M. Fei, X. Zhao, M. Liu, C. Chen, C.-H. Yeh, Q. Wang, G. Zheng, et al., Rehrseg: Unleashing the power of selfsupervised super-resolution for resource-efficient 3d mri segmentation, Neurocomputing, p. 129425, 2025. [426] Y. Qin, Y. Li, Z. Zhuo, Z. Liu, Y. Liu, and C. Ye, Multimodal superresolved q-space deep learning, Medical Image Analysis, vol. 71, p. 102085, 2021. [427] C. Sun, N. Goyal, Y. Wang, D. L. Tharp, S. Kumar, and T. A. Altes, Conditional diffusion-generated super-resolution for myocardial perfusion mri, Frontiers in Cardiovascular Medicine, vol. 12, p. 1499593, 2025. [428] O. Dzyubachyk, A. Khmelinskii, E. Plenge, P. Kok, T. J. Snoeks, D. H. Poot, C. W. Löwik, C. P. Botha, W. J. Niessen, L. van der Weerd, et al., Interactive local super-resolution reconstruction of whole-body mri mouse data: pilot study with applications to bone and kidney metastases, Plos one, vol. 9, no. 9, p. e108730, 2014. [429] A. Ordinola, D. Abramian, M. Herberthson, A. Eklund, and E. Özarslan, Super-resolution mapping of anisotropic tissue structure with diffusion mri and deep learning, Scientific Reports, vol. 15, no. 1, p. 6580, 2025. [430] A. Suwannasak, S. Angkurawaranon, P. Sangpin, I. Chatnuntawech, K. Wantanajittikul, and U. Yarach, Deep learning-based superresolution of structural brain mri at 1.5 t: application to quantitative volume measurement, Magnetic Resonance Materials in Physics, Biology and Medicine, pp. 111, 2024. [431] J. Lee, W. Jung, S. Yang, J. H. Park, I. Hwang, J. W. Chung, S. H. Choi, and K. S. Choi, Deep learning-based super-resolution and denoising algorithm improves reliability of dynamic contrast-enhanced mri in diffuse glioma, Scientific Reports, vol. 14, no. 1, p. 25349, 2024. [432] D. C. Thomas, A.-M. Oros-Peusquens, M. Schöneck, A. Willuweit, Z. Abbas, M. Zimmermann, J. Felder, A. Celik, and N. J. Shah, In vivo measurement of rat brain water content at 9. 4 mr using super-resolution reconstruction: Validation with ex vivo experiments, Journal of Magnetic Resonance Imaging, vol. 60, no. 1, pp. 161172, 2024. [433] D. Youla and H. Webb, Generalized image restoration by the method of alternating orthogonal projections, IEEE Transactions on Circuits and Systems, vol. 25, no. 9, pp. 694702, 1978. [434] D. L. Donoho, Superresolution via sparsity constraints, SIAM journal on mathematical analysis, vol. 23, no. 5, pp. 13091331, 1992. [435] B. Iskender, M. L. Klasky, and Y. Bresler, Red-psm: Regularization by denoising of partially separable models for dynamic imaging, in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 1059510604, 2023. [436] Y. Romano, M. Elad, and P. Milanfar, The little engine that could: Regularization by denoising (red), SIAM Journal on Imaging Sciences, vol. 10, no. 4, pp. 18041844, 2017. [437] C. Wu, Q. Kong, Z. Jiang, and S. K. Zhou, Self-supervised diffusion mri denoising via iterative and stable refinement, arXiv preprint arXiv:2501.13514, 2025. [438] T. Xiang, M. Yurt, A. B. Syed, K. Setsompop, and A. Chaudhari, Ddm2: Self-supervised diffusion mri denoising with generative diffusion models, arXiv preprint arXiv:2302.03018, 2023. [439] P. Milanfar and M. Delbracio, Denoising: powerful building block for imaging, inverse problems and machine learning, Philosophical Transactions A, vol. 383, no. 2299, p. 20240326, 2025. [440] D. Chen, M. Davies, M. J. Ehrhardt, C.-B. Schönlieb, F. Sherry, and J. Tachella, Imaging with equivariant deep learning: From unrolled network design to fully unsupervised learning, IEEE Signal Processing Magazine, vol. 40, no. 1, pp. 134147, 2023. [441] Y. Lim, Y. Bliesener, S. Narayanan, and K. S. Nayak, Deblurring for spiral real-time mri using convolutional neural networks, Magnetic resonance in medicine, vol. 84, no. 6, pp. 34383452, 2020. [442] R. Zhu, X. Zhang, H. Pang, C. Xu, and C. Ye, Advancing brain tumor inpainting with generative models, arXiv preprint arXiv:2402.01509, 2024. [443] S. K. Kang, S. A. Shin, S. Seo, M. S. Byun, D. Y. Lee, Y. K. Kim, D. S. Lee, and J. S. Lee, Deep learning-based 3d inpainting of brain mr images, Scientific reports, vol. 11, no. 1, p. 1673, 2021. [444] R. Tanno, D. E. Worrall, E. Kaden, A. Ghosh, F. Grussu, A. Bizzi, S. N. Sotiropoulos, A. Criminisi, and D. C. Alexander, Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion mri, NeuroImage, vol. 225, p. 117366, 2021. [445] T. Liu, J. Cheng, and S. Tan, Spectral bayesian uncertainty for image the IEEE/CVF Conference on super-resolution, in Proceedings of Computer Vision and Pattern Recognition, pp. 1816618175, 2023. [446] A. Kar and P. K. Biswas, Fast bayesian uncertainty estimation and reduction of batch normalized single image super-resolution network, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 49574966, 2021. [447] C. Ma, Uncertainty-aware gan for single image super resolution, in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, pp. 40714079, 2024. [448] J. Tachella and M. Pereyra, Equivariant bootstrapping for uncertainty quantification in imaging inverse problems, arXiv preprint arXiv:2310.11838, 2023. [449] M. Abdar, F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu, M. Ghavamzadeh, P. Fieguth, X. Cao, A. Khosravi, U. R. Acharya, et al., review of uncertainty quantification in deep learning: Techniques, applications and challenges, Information fusion, vol. 76, pp. 243297, 2021. [450] Z. Chen, K. Pawar, M. Ekanayake, C. Pain, S. Zhong, and G. F. Egan, Deep learning for image enhancement and correction in magnetic resonance imagingstate-of-the-art and challenges, Journal of Digital Imaging, vol. 36, no. 1, pp. 204230, 2023. [451] J. I. Tamir, S. X. Yu, and M. Lustig, Unsupervised deep basis pursuit: Learning inverse problems without ground-truth data, arXiv preprint arXiv:1910.13110, 2019. [452] M. Terris, T. Moreau, N. Pustelnik, and J. Tachella, Equivariant plug-and-play image reconstruction, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 25255 25264, 2024. KHATERI et al.: MRI SUPER-RESOLUTION WITH DEEP LEARNING: COMPREHENSIVE SURVEY 41 [475] Y. Cai, F.-C. Zhang, Z. M. Saygin, B. T. Wyman, et al., Qsiprep: an integrative platform for preprocessing and reconstructing diffusion mri data, Nature Methods, vol. 18, no. 7, pp. 775778, 2021. [476] C. Pierpaoli, L. Walker, M. O. Irfanoglu, A. Barnett, P. Basser, L.-C. Chang, C. Koay, S. Pajevic, G. Rohde, J. Sarlls, et al., Tortoise: an integrated software package for processing of diffusion mri data, in ISMRM 18th annual meeting, vol. 1597, ISMRM Germany, 2010. [477] X. He, H. Tang, Z. Tu, J. Zhang, K. Cheng, H. Chen, Y. Guo, M. Zhu, N. Wang, X. Gao, et al., One step diffusion-based super-resolution with time-aware distillation, arXiv preprint arXiv:2408.07476, 2024. [478] Y. Zhu, R. Wang, S. Lu, J. Li, H. Yan, and K. Zhang, Oftsr: Onestep flow for image super-resolution with tunable fidelity-realism tradeoffs, arXiv preprint arXiv:2412.09465, 2024. [479] G. Daras, H. Chung, C.-H. Lai, Y. Mitsufuji, P. Milanfar, A. G. Dimakis, C. Ye, and M. Delbracio, survey on diffusion models for inverse problems. 2024, URL https://giannisdaras. github. io/publications/diffusion_survey. pdf. [480] Y. Zhu, K. Zhang, J. Liang, J. Cao, B. Wen, R. Timofte, and L. Van Gool, Denoising diffusion models for plug-and-play image restoration, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12191229, 2023. [481] S. Martin, A. Gagneux, P. Hagemann, and G. Steidl, Pnp-flow: Plug-and-play image restoration with flow matching, arXiv preprint arXiv:2410.02423, 2024. [482] R. Barbano, A. Denker, H. Chung, T. H. Roh, S. Arridge, P. Maass, B. Jin, and J. C. Ye, Steerable conditional diffusion for out-ofdistribution adaptation in medical image reconstruction, IEEE Transactions on Medical Imaging, 2025. [483] D. Karimi and S. K. Warfield, Diffusion mri with machine learning, Imaging Neuroscience, vol. 2, pp. 155, 2024. [484] J. E. Iglesias, R. Schleicher, S. Laguna, B. Billot, P. Schaefer, B. McKaig, J. N. Goldstein, K. N. Sheth, M. S. Rosen, and W. T. Kimberly, Quantitative brain morphometry of portable low-field-strength mri using super-resolution machine learning, Radiology, vol. 306, no. 3, p. e220522, 2022. [485] C. Man, V. Lau, S. Su, Y. Zhao, L. Xiao, Y. Ding, G. K. Leung, A. T. Leong, and E. X. Wu, Deep learning enabled fast 3d brain mri at 0.055 tesla, Science Advances, vol. 9, no. 38, p. eadi9327, 2023. [486] L. Li, Q. He, S. Wei, H. Wang, Z. Wang, Z. Wei, H. He, C. Xiang, and W. Yang, Fast, high-quality, and unshielded 0.2 low-field mobile mri using minimal hardware resources, Magnetic Resonance Materials in Physics, Biology and Medicine, pp. 114, 2024. [487] E. Agustsson and R. Timofte, Ntire 2017 challenge on single image super-resolution: Dataset and study, in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pp. 126135, 2017. [488] B. Ren, Y. Li, N. Mehta, R. Timofte, H. Yu, C. Wan, Y. Hong, B. Han, Z. Wu, Y. Zou, et al., The ninth ntire 2024 efficient super-resolution challenge report, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 65956631, 2024. [489] A. Ignatov, R. Timofte, T. Van Vu, T. Minh Luu, T. Pham, C. Van Nguyen, Y. Kim, J.-S. Choi, M. Kim, J. Huang, et al., Pirm challenge on perceptual image enhancement on smartphones: Report, in Proceedings of the European Conference on Computer Vision (ECCV) Workshops, pp. 00, 2018. [453] J. Lehtinen, Noise2noise: Learning image restoration without clean data, arXiv preprint arXiv:1803.04189, 2018. [454] J. Tachella, M. Davies, and L. Jacques, Unsure: self-supervised learning with unknown noise level and steins unbiased risk estimate, arXiv preprint arXiv:2409.01985, 2024. [455] J. Wei, G. Yang, Z. Wang, Y. Liu, A. Liu, and X. Chen, Misalignmentresistant deep unfolding network for multi-modal mri super-resolution and reconstruction, Knowledge-Based Systems, vol. 296, p. 111866, 2024. [456] X. Tu, G. Li, and Y. Liu, Synergizing frequency domain and texture-aware implicit module for mri arbitrary-scale super-resolution, Biomedical Signal Processing and Control, vol. 98, p. 106760, 2024. [457] M. Zhao, J. Fang, and B. Chen, An arbitrary-scale super-resolution network for multi-contrast mri with permuted cross-attention, IEEE Journal of Biomedical and Health Informatics, 2025. [458] K. Pang, K. Zhao, A. L. Y. Hung, H. Zheng, R. Yan, and K. Sung, Nexpr: Neural explicit representation for fast arbitrary-scale medical image super-resolution, Computers in biology and medicine, vol. 184, p. 109354, 2025. [459] S. Ioffe and C. Szegedy, Batch normalization: Accelerating deep network training by reducing internal covariate shift, in International conference on machine learning, pp. 448456, pmlr, 2015. [460] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, Dropout: simple way to prevent neural networks from overfitting, The journal of machine learning research, vol. 15, no. 1, pp. 19291958, 2014. [461] X. Kong, X. Liu, J. Gu, Y. Qiao, and C. Dong, Reflash dropout in image super-resolution, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 60026012, 2022. [462] H. Xu, J. Huang, W. Yu, J. Tan, Z. Zou, and F. Zhao, Adaptive dropout: Unleashing dropout across layers for generalizable image super-resolution, in Proceedings of the Computer Vision and Pattern Recognition Conference, pp. 75137523, 2025. [463] J. Li, Z. Pei, and T. Zeng, From beginner to master: survey for deep learning-based single-image super-resolution. arxiv 2021, arXiv preprint arXiv:2109.14335. [464] S. Anwar, S. Khan, and N. Barnes, deep journey into superresolution: survey, ACM Computing Surveys (CSUR), vol. 53, no. 3, pp. 134, 2020. [465] P. Micikevicius, S. Narang, J. Alben, G. Diamos, E. Elsen, D. Garcia, B. Ginsburg, M. Houston, O. Kuchaiev, G. Venkatesh, et al., Mixed precision training, arXiv preprint arXiv:1710.03740, 2017. [466] M. Jenkinson, P. Bannister, M. Brady, and S. Smith, Improved optimization for the robust and accurate linear registration and motion correction of brain images, NeuroImage, vol. 17, no. 2, pp. 825841, 2002. [467] B. B. Avants, N. J. Tustison, and G. Song, reproducible evaluation of ants similarity metric performance in brain image registration, NeuroImage, vol. 54, no. 3, pp. 20332044, 2011. [468] S. Klein, M. Staring, K. Murphy, M. A. Viergever, and J. P. W. Pluim, elastix: toolbox for intensity-based medical image registration, IEEE Transactions on Medical Imaging, vol. 29, no. 1, pp. 196205, 2010. [469] A. Uus, T. Zhang, L. H. Jackson, T. A. Roberts, M. A. Rutherford, J. V. Hajnal, and M. Deprez, Deformable Slice-to-Volume Registration for Motion Correction of Fetal Body and Placenta MRI, IEEE Trans. Med. Imaging, vol. 39, pp. 27502759, Sept. 2020. [470] N. J. Tustison, B. B. Avants, P. A. Cook, Y. Zheng, A. Egan, P. A. Yushkevich, and J. C. Gee, N4itk: improved n3 bias correction, IEEE Transactions on Medical Imaging, vol. 29, no. 6, pp. 13101320, 2010. [471] Y. Zhang, M. Brady, and S. Smith, Segmentation of brain MR images through hidden Markov random field model and the expectationmaximization algorithm, IEEE Trans. Med. Imaging, vol. 20, pp. 45 57, Jan. 2001. [472] R. D. Vincent, P. Neelin, N. Khalili-Mahani, A. L. Janke, V. S. Fonov, S. M. Robbins, L. Baghdadi, J. Lerch, J. G. Sled, R. Adalat, D. MacDonald, A. P. Zijdenbos, D. L. Collins, and A. C. Evans, MINC 2.0: Flexible Format for Multi-Modal Images, Front. Neuroinform., vol. 10, Aug. 2016. [473] O. Esteban, C. J. Markiewicz, R. C. Blair, C. A. Moodie, A. I. Isik, A. Erramuzpe, J. D. Kent, M. Goncalves, E. DuPre, M. Snyder, et al., fmriprep: robust preprocessing pipeline for functional mri, Nature Methods, vol. 16, no. 1, pp. 111116, 2019. [474] O. Esteban, C. J. Markiewicz, M. Goncalves, D. Jarecka, C. Burns, C. Madison, D. Clark, M. Waskom, T. E. Nichols, S. S. Ghosh, and R. A. Poldrack, smriprep: Structural mri preprocessing workflows, 2019. Zenodo software release."
        }
    ],
    "affiliations": [
        "A. I. Virtanen Institute for Molecular Sciences, Faculty of Health Sciences, University of Eastern Finland",
        "Artificial Intelligence in Medical Imaging group at the Department of Radiology, Technical University of Munich",
        "Department of Radiology, Massachusetts General Hospital",
        "Harvard Medical School and Boston Childrens Hospital"
    ]
}