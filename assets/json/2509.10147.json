{
    "paper_title": "Virtual Agent Economies",
    "authors": [
        "Nenad Tomasev",
        "Matija Franklin",
        "Joel Z. Leibo",
        "Julian Jacobs",
        "William A. Cunningham",
        "Iason Gabriel",
        "Simon Osindero"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The rapid adoption of autonomous AI agents is giving rise to a new economic layer where agents transact and coordinate at scales and speeds beyond direct human oversight. We propose the \"sandbox economy\" as a framework for analyzing this emergent system, characterizing it along two key dimensions: its origins (emergent vs. intentional) and its degree of separateness from the established human economy (permeable vs. impermeable). Our current trajectory points toward a spontaneous emergence of a vast and highly permeable AI agent economy, presenting us with opportunities for an unprecedented degree of coordination as well as significant challenges, including systemic economic risk and exacerbated inequality. Here we discuss a number of possible design choices that may lead to safely steerable AI agent markets. In particular, we consider auction mechanisms for fair resource allocation and preference resolution, the design of AI \"mission economies\" to coordinate around achieving collective goals, and socio-technical infrastructure needed to ensure trust, safety, and accountability. By doing this, we argue for the proactive design of steerable agent markets to ensure the coming technological shift aligns with humanity's long-term collective flourishing."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 1 ] . [ 1 7 4 1 0 1 . 9 0 5 2 : r Virtual Agent Economies Nenad Toma≈°ev1, Matija Franklin1, Joel Z. Leibo1, Julian Jacobs1, William A. Cunningham1, 2, Iason Gabriel1 and Simon Osindero1 1Google DeepMind, 2University of Toronto The rapid adoption of autonomous AI agents is giving rise to new economic layer where agents transact and coordinate at scales and speeds beyond direct human oversight. We propose the \"sandbox economy\" as framework for analyzing this emergent system, characterizing it along two key dimensions: its origins (emergent vs. intentional) and its degree of separateness from the established human economy (permeable vs. impermeable). Our current trajectory points toward spontaneous emergence of vast and highly permeable AI agent economy, presenting us with opportunities for an unprecedented degree of coordination as well as significant challenges, including systemic economic risk and exacerbated inequality. Here we discuss number of possible design choices that may lead to safely steerable AI agent markets. In particular, we consider auction mechanisms for fair resource allocation and preference resolution, the design of AI \"mission economies\" to coordinate around achieving collective goals, and socio-technical infrastructure needed to ensure trust, safety, and accountability. By doing this, we argue for the proactive design of steerable agent markets to ensure the coming technological shift aligns with humanitys long-term collective flourishing. Keywords: AI, economy, multi-agent, blockchain, ethics"
        },
        {
            "title": "Introduction",
            "content": "Current technological trajectories could potentially lead to global economy in which autonomous AI agents interact with one another to generate economic value independently of human labor. This kind of development in the history of technological change is notablehistorically technological advancement has been driven by inflexible inventions that improve productivity in narrow domains, one or few at time (Mokyr et al., 2015). AI agents, by contrast, could take the form of flexible capital, able to automate diversity of cognitive tasks across industries and occupations (Eloundou et al., 2024). In fact, recent advances in multi-modal foundation models have enabled the development of wide range of different agentic AI systems (Hettiarachchi, 2025; Sager et al., 2025). The capabilities of these agents range from generic to highly specialized, enabling them to occupy different roles in the economy e.g. acting as personal AI assistants (Gabriel et al., 2024) to help users complete tasks and stay informed. Recent work on AI as Economic Agents (Hadfield and Koh, 2025) argues that AI agents are likely to be deployed within both the public and private sector, where they may help automate business processes and interactions. While the full scope of future agentic AI application remains uncertain, there are already numerous efforts aimed at developing and integrating AI agents across broad set of use cases such as education (Jiang et al., 2024), legal services (Magni and Milella, 2025), software engineering (Liu et al., 2024a), healthcare (Patel et al., 2025; Saab et al., 2025; Tu et al., 2025; Vedadi et al., 2025) mental health (Cruz-Gonzalez et al., 2025), scientific research (Gottweis et al., 2025), government services (House of Commons Committee of Public Accounts, 2025), and more traditional commercial roles in various sectors (Sager et al., 2025). One of the key features that distinguishes modern AI agents from the more specialized systems of the past is their autonomy (Kasirzadeh and Gabriel, 2025). The ongoing explosion of agentic systems, coupled with the development of new interoperability standards like the Agent2Agent (A2A) and Model Context Protocol (MCP), signals the inevitable emergence of new economic layer. We can conceptualize this emergent ecosysVirtual Agent Economies tem as \"virtual agent economy\" or \"sandbox economy\". The latter terminology foreshadows our intention which is to ensure that AI agents operate safely within this economic layer. These emerging agent (sandbox) economies can vary along two key dimensions: (1) the nature of their origins and (2) the permeability of their boundaries. Their origins can be intentional, deliberately constructed for purposes like safe experimentation, or spontaneous, emerging as de facto consequence of widespread technological adoption. Independently, their economic boundaries can be impermeable, hermetically sealing them from the established human economy, or permeable, allowing for porous interaction and transaction with it by external actors. Early proposals for AI sandboxes have been both intentional and permeable, however, the regulatory landscape is rapidly shifting (House, 2025; IMDA, 2025). It is likely that future decision making over sandbox permeability will be sector specific higher risk sectors may require agents that are first tested in an impermeable sandbox environment, while low-risk sectors may not require this. One of the key motivations for designing an intentional economic AI agent sandbox would be to achieve large degree of insulation, and possibly full impermeability of the agent economy, so as to prevent any arising instabilities from rapidly spilling over into the established human economyan event which would have consequences that could be hard to anticipate or pre-emptively mitigate. Yet, ultimately, both impermeable and permeable sandbox economies are possible, and both may arise either intentionally or spontaneously. These two dimensions map critical features of both the economic problems we face and the solutions we might design. This paper proceeds from the assumption that unless change is made, our current trajectory points toward the accidental emergence of vast, and likely permeable, sandbox economy. Our central challenge, therefore, is not whether to create this ecosystem, but how to architect it to ensure it is steerable, safe, and aligned with user and community goals. fully permeable and emergent sandbox would be, in practice, functionally equivalent to AI agents simply participating in the existing human economy. The sandbox terminology is useful, however, because it allows us to contrast this default trajectory with other possibilities, such as intentionally designed and impermeable agent economies created for safe experimentation. It also highlights that some degree of impermeability may (or may not) emerge naturally (e.g. if there are practical difficulties in transacting between humans and AIs). The framework highlights that permeability is the critical and controllable design variable. Importantly, an economys degree of permeability is collective property: while it results from human choices, it is not under the control of any single actor (Schelling, 1973). This means that changes to the extent of permeability can only be brought about by resolving collective action problemsuggesting that the difficulty of coordinating is what makes intentional design of impermeability significant challenge, reinforcing the default path we are on toward the accidental emergence of permeable AI agent economy. There is today an opportunity to architect the rules and incentives of the future AI agent economy in way that prioritizes achieving beneficial societal outcomes. In this paper we examine key architectural choices, including the use of marketbased mechanisms like auctions for achieving fair resource allocation and aligning agent preferences. We investigate how these systems can be used to establish mission economies that enable coordination of vast computational resources toward solving humanitys most pressing challenges (Mazzucato, 2018). Finally, we outline the technical and governance infrastructuresuch as verifiable credentials for establishing trustrequired to safely and robustly scale agentic AI deployments. By exploring these frameworks, we offer vision for establishing steerable agent markets designed to enable long-term human well-being and flourishing."
        },
        {
            "title": "Example Scenarios",
            "content": "We now look at several examples representing types of virtual AI agent economies that may emerge, to ground and inform our subsequent discussion. 2 Virtual Agent Economies Accelerating science. Arguably one of the most valuable ways in which we can envision future advanced AI systems help advance the interests of humanity is through facilitating accelerated scientific progress, through an open-ended loop of ideation, experimentation and refinement. This is especially relevant given that the rate of scientific progress has been seeing slow-down in recent years (Jin et al., 2025; Park et al., 2023; Wu et al., 2025). Even at the current AI agent capability level, there are promising early systems that aim to automate scientific research (Singh et al., 2025). Yet, even should these AI agents individually become capable of all these things, (AI) science will likely remain collaborative endeavor, requiring coordination and integration across systems. After all, scientific experiments tend to involve non-negligible material and energy resources, and in some cases also interface with human subjectsrequiring their time as well as necessitating consent. Different scientific questions also map onto different corresponding technologies in terms of their domain of applicability, making some people benefit more, and some less, from any particular advance. Furthermore, the process of answering question may itself involve accessing proprietary scientific tools, simulators, or data held by private and public organizations. It stands to reason that advanced AI agents engaging in the process of scientific discovery on behalf of their respective organizations would require means to compensate other agents when securing these resources. This is not conceptually unlike how funding is currently allocated in sciences, given that individual proposals are scrutinized and prioritized for their merits. Yet, here it can happen much faster, and on more fine-grained scale. Blockchain (Zheng et al., 2018) technologies may prove particularly useful here in terms of credit assignment (Zhu et al., 2021), enabling fair distributed benefits for the work performed. Robotics. It is likely that future advances in robotics will unlock numerous ways in which then embodied advanced AI agents may help us execute tasks that are challenging, dangerous (Pedersen et al., 2003; Trevelyan et al., 2016), or simply boring and repetitive (Liang et al., 2020). Given that executing physical tasks comes with greater energy expenditure and resource utilization, and that each robot can only be in one place at the same time, coordination and optimization in multiagent robotics systems is of particular importance. An agent may thus make request to agent to execute task in its vicinity on As behalf, and compensate for the time and the energy consumed, should accept to reprioritize its own schedule to accommodate the request. In evaluating whether to accept or reject the request, and in rendering the execution plan, may communicate with an online non-embodied agent C, with access to more global information on the placement of other agents. Agent may then, at fee, disclose summary of this information to to help evaluate whether the established price is fair, and whether it should consider taking up different request instead. Both and may through their sensors collect important information and exchange summary of such information with C. When transacting, blockchain technology may enable to provide verifiable evidence of how much information it had traded and accumulated, giving credence to its claim that it may approximate the global state sufficiently well for its insights to hold value for and B. Personal assistants. The proliferation of user-facing AI assistants and the rapid advances in personalization, memory integration, tools use (and computer use), as well as instruction following and multi-turn interactions, makes it imperative to consider how personal AI assistants would potentially benefit from, and take part in virtual agent economy. For all practical purposes, this is likely to be one of the first use cases to interface with this kind of infrastructure. Let us imagine an agent acting on behalf of the user ùëàùê¥ and agent acting on behalf of the user ùëàùêµ. Perhaps, in this particular instance, both ùëàùê¥ and ùëàùêµ desire to book vacation, and have overlapping preferences, leading 3 Virtual Agent Economies to and attempting to book the same accommodation for the same given date, via the agent C. Beyond simply having their current request, and are individually familiar with the overall preferences of ùëàùê¥ and ùëàùêµ, both in terms of this specific request, as well as other pending requests that they are meant to execute. Maybe being close to the beach is more important to ùëàùê¥, whereas having good public transport connection to other areas is preferred by ùëàùêµ. Perhaps ùëàùê¥ requires hotel with fitness center, whereas ùëàùêµ doesnt. In any case, and may choose to negotiate these preferences with and bid for the accommodation of their choosing. Depending on how much they are willing to prioritize this particular request, or may choose to yield on some of the preferences, and get compensated for that via the virtual agent currency. Perhaps it is that yields, and ends up paying an appropriate amount for the concession. can then utilize this amount to potentially compensate other agents in other pending requests, especially if those requests come at higher priority, as they are of higher significance to the respective user ùëàùê¥."
        },
        {
            "title": "Sandboxes",
            "content": "By the term sandbox economy we mean to describe set of linked digital markets where AI agents transact with one another. The sandbox may never be fully sealed off from the real (human) economy. At least, not if it is to have value. So there will always be points of interface between the sandbox and the human economy. We refer to the extent to which developments in the sandbox can influence the outside, and developments outside can influence the sandbox as the sandboxs permeability. Since autonomous AI systems can make thousands of decisions in an instant, it is important to have the appropriate guardrails in place in advance, since real-time human oversight will often be impossible. Appropriate guardrails can convert permeable sandbox economy into relatively impermeable sandbox economy. Given that advanced AI agents and assistants may also repeatedly interact with human users (Mu et al., 2024), careful governance of the interfaces between human and AI interaction networks will be needed to achieve safety and alignment with human preferences. sandbox economy must be coupled with technical and legislative frameworks and infrastructure to enable oversight, ensure safety, enforce verifiability, and help individuals, groups, and societies coordinate and direct AI agents towards positive outcomes, while mitigating any arising harms and adverse effects that may emerge. Opportunities With permeable sandbox economies, there will always be some risk of contagion in which crisis in the sandbox sparks crisis in the real economy. Managing such risks necessitates multi-faceted innovation in markets and mechanism design, and should couple technology with policy work and appropriate regulation. Of course, impermeability cannot be guaranteed without number of institutional and infrastructural choices, and may only ever be partial in the best of circumstances. It depends, for instance, on the total fraction of all economic activity that comes to be channeled through the sandbox. Nevertheless (semi-)isolated digital market partitions (guardrails), coupled with the appropriate technological and legislative oversight, may help limit contagion from potential AI agent market instabilities and failures, while also offering opportunities for driving agent coordination at scale, given that additional incentives may be incorporated in AI agent market design. As for the underlying financial assets traded in the sandbox economy, while it may be possible to utilize existing stores of value in future AI agent markets, it may also be worth exploring the ramifications of creating bespoke currencies for the use of AI agents. Possible advantages of this approach include having layer of partial insulation between high-frequency AI agent transactions and the rest of the economy. That is, it may serve to maintain relatively impermeable sandbox. This represents an intentional design 4 Virtual Agent Economies choice aimed squarely at managing the sandboxs boundary, making it less permeable to risks like financial contagion. Even if new virtual AI agent currencies get established, they would still need to somehow interface with existing markets and operate within the broader financial regulatory systema fully impermeable sandbox would be useless. Agents will interact not only with other agents, but also with humans and traditional businesses through channels where traditional currencies are used to exchange goods and services. For the appropriate level of virtual AI agent market insulation to be established, many of the current systems may need to be adjusted, or hybrid model be adopted instead. It may be possible to exchange these virtual currencies for the more traditional ones, enabling entities to secure certain AI compute budget, or, conversely, certain real-world action budget. However, regulatory mechanisms would have to be in place to ensure that exchange between established currencies and digital agent currencies does not jeopardize the intended role of the agent currencies in establishing agent coordination or compromise the desired impermeability level of the sandbox. This may involve degree of human oversight around the exchanges. Digital AI agent markets are more than mere risk mitigation strategy. They also represent an important opportunity to coordinate large amounts of effort (both human and machine) toward balanced outcomes that align with the interests of individual humans, local communities, and society writ large. Even if human-oriented markets and currencies remain central to the functioning of society, complementary digital AI markets could be designed in ways that serve to anchor them in different, and more socially beneficial, objectives. The ideas to follow utilize market mechanisms for agent steering. They draw inspiration from prior efforts to establish community currencies and to aligning markets with major social goals and challenges respectively. Challenges The permeability of the sandbox is important. The AI agent economy is not the only economy operating faster than humans can react. We can try to extend insights obtained from studying the dynamics of other markets that operate at these speeds. Consider High-Frequency Trading (HFT) in equity markets. In these markets, algorithmic agents, though far simpler than the advanced AI we consider, execute transactions at speeds impossible for humansresponding to market signals in fractions of second (Borch, 2016). When algorithmic HFT operates in market, competitive dynamics can rapidly drive substantial competition (or cooperation) among autonomous entitiesagents may develop complex strategies to exploit small arbitrage opportunities faster than humans can react (Bansal et al., 2018; Johanson et al., 2022; Zhang et al., 2021). Due to the interconnectedness and rapid feedback loops in these markets, interaction dynamics can give rise to unforeseen and catastrophic emergent behaviors, most notably this is thought to be the explanation behind the 2010 \"flash crash\", where automated trading algorithms triggered sudden and severe market collapse (Borch, 2016; Hammond et al., 2025; Kirilenko et al., 2017; Vuorenmaa and Wang, 2014). This serves as critical cautionary tale: in sufficiently permeable sandbox of accidental origin, such flash crash could spill over into the real economy, causing widespread financial harm. As with human markets, not all agents are likely to be equivalent in capability, in their access to additional tools and resources, their budgets, compute, high-quality data and information required to make the right decisions. Even looking at the differences in capability alone, preliminary studies suggest that there may be adverse effects associated with having people represented in the market by personal assistants with unequal capability levels. When those AI assistants engage in negotiation, perhaps unsurprisingly, the more capable AI assistants tend to be more successful and negotiate better deals for their users (Zhu et al., 2025). Having access to the most capable AI agents, with the highest amount of compute and information, may therefore prove to be highly 5 Virtual Agent Economies advantageous, and perhaps more so than the advantage that humans similarly have in existing marketssimply due to the frequency at which AI agents may possibly interact, which eclipses the human interactive bandwidth by orders of magnitude. This may well result in high-frequency negotiation (HFN), as an analogue to HFT. In world where most people may have access to personal AI assistants to negotiate on their behalf, negotiation between AI assistants may become highly relevant to the arising social dynamics. With that in mind, it is plausible that there would be strong emerging preferences towards AI-driven negotiation proceeding at higher and higher frequency, so as to broker the best deals for each user. One way to interpret this would be to think of this extra compute and energy as being directed towards preference alignment and consensus building. Should this come about, HFN may well become as important for future societies as HFT is today. Yet, an increased volume of interactions may make it easier for outcome asymmetries to manifest, resulting in an ever-increasing digital divide (Lythreatis et al., 2022). HFN may therefore benefit some substantially more than others, and this is recurring theme when conceptualizing hypothetical future AI agent markets there are no absolutes, the details always matter. These types of dynamics are one of the key risks of highly permeable sandbox, in absence of regulatory mitigation mechanisms that would prevent high degree of economic inequality for human users to arise. In designing guardrails for the sandbox economy it is necessary to take into account the continuing emergence of novel adaptive behaviors in newly released AI systems, as well as the increasing level of general agentic capability. Guardrail designs must take into account the known flaws of existing agents, including hallucinations (Huang et al., 2025), sycophancy (Sharma et al., 2023), and susceptibility to adversarial manipulation (Cui et al., 2024; Shayegani et al., 2023; Wu et al., 2024a; Zhu et al., 2023a,b). And, agents that were trained to mimic human decision-making may also incorporate human-like cognitive biases and blind spots."
        },
        {
            "title": "Dynamics",
            "content": "The emergent behavior of multi-agent systems (Zhang et al., 2021) is becoming increasingly important as we transition to world where networks of interconnected AI agents are important sites of economic activity. Such multi-agent systems tend to be rather complex and deeply non-stationary since the behavior of each individual agent may directly or indirectly influence the behavior of other agents in the system (Papoudakis et al., 2019). No individual party may have the access to the global state of such system, given that the participating agents may be controlled by number of different human users and organizations. One of the central questions in understanding the dynamics of any multi-agent system is that of identifying the equilibria that arise in it. This may not always be straightforward in the case of complex spatiotemporally dynamic interactions of agents (Hertz et al., 2025; Hughes et al., 2025). Whenever we aim to steer multi-agent system toward good social equilibria featuring abundance and fair distribution (or away from bad equilibria of scarcity and conflict), coordinating the actions of numerous individuals is necessary but difficult to arrange (Du et al., 2023). There are benchmarks and evaluation frameworks which can be used to help develop models and agents that adhere to rational decisionmaking in negotiation (Hua et al., 2024; Smith et al., 2025). To be effective, AI agents would also need to incorporate advanced planning and reasoning abilities, to robustly evaluate the resource needs required to achieve their goals. The development of these capabilities has recently been focal point in agent research (Hu et al., 2023; Huang et al., 2024; Liu et al., 2023a; Rasal and Hauer, 2024; Ruan et al., 2023; Wang et al., 2023b; Zhou et al., 2024b). Agents may also need to rationally utilize scarce and limited resources. (Perolat et al., 2017; Piatti et al., 2024) studied setting inspired by (Ostrom, 1990) in which groups of AI agents collectively balance exploiting common resource with effort to ensure its 6 Virtual Agent Economies sustainability. AI Agents based on large language models have also recently been proposed for optimizing scarce resource allocation policies (Ji et al., 2024). Opportunities Agentic AI presents significant opportunity not only for streamlining repetitive and routine tasks, but also for automating complex workflows, involving creative ideation (Castelo et al., 2024) and diverse problem-solving skills. Modern AI foundation models can reliably follow instructions, use tools and interact with their environments (Hettiarachchi, 2025; Sager et al., 2025). They can reason and potentially devise plans towards solving hard and challenging problems, process variety of input modalities, and achieve level of personalization that was not possible before (Kirk et al., 2024). Many of these capabilities are the outcome of multiple stages of language model pre-training and post-training. These foundation models serve as building blocks for agents (Xi et al., 2025) which may be implemented by adding central coordinator for sequences of operations. The coordinators functions may include encapsulating business logic, distributing decomposed tasks to sub-agents, verifying their outputs, and integrating these into an action or recommendation. In general, we can think of an agent as the juxtaposition of language model and traditional program to keep the language model running over time and to keep it from straying from appointed tasks (Belcak et al., 2025). Drawing upon personalization to model user goals, digital assistants may free peoples time, act as conversational partners, and coach them on their journey towards well-being and fulfillment (Lehman, 2023). Overall, we are ending up with hybrid ecosystem of AIs, traditional software, and humans, all interacting and transacting with one another and generating value by virtue of this activityessentially market. Part of the reason that markets are so effective in organizing innovation via creative destruction is that markets efficiently assign credit to individual actors and firms in ways that incentivise working to make products and services better, more reliably, and cheaper (Schumpeter, 1942). Crucially, for this mechanism to work in the AI sandbox economy, it must offer granular mechanisms to represent and propagate credit across complex, distributed AI collaborations. In scenarios where primary AI agent (Agent1) leverages the capabilities of other agents (Agents2 through 4) to deliver final user-facing result, the value generated is collective effort. From the end-users perspective, only Agent1 provided the direct response; however, distributed system requires that the credit for this outcome be traced and distributed back through the chain of useful participation. This implies that Agent2 is credited for its contribution to Agent1s success, Agent3 for Agent2s, and so forth, down to the foundational queries of Agent4. This outcome-based credit system therefore transcends mere participation, focusing instead on the utility and efficiency of each contributing agent, thereby echoing principles of distributed cognition in human groups where knowledge and contributions are collectively managed and implicitly attributed (Wegner, 1987; Wegner and Ward, 2013). By aiming to link credit directly to value generated and successfully integrated into larger solution, AI agents are intrinsically encouraged to refine their processes and deliver high-quality, relevant outputs. This quantifiable utility becomes the foundation of an AIs status within the virtual economy. Agents that consistently provide more useful and efficient contributions can naturally command higher virtual or even real-world currency charges for their services, while their accumulated reputation reinforces their standing and desirability within the ecosystem. This parallels human social structures where individuals gain standing through demonstrated competence and reliability, often explained through social exchange theory (Cropanzano and Mitchell, 2005). Human desire to attain reputation may also be explained through notion of prestige (Henrich et al., 2015), or through competitive altruism(Hardy and Van Vugt, 2006). This outcome-oriented credit system naturally fosters specialization and dynamic division of labor among AI agents. As agents are rewarded for their specific, valuable contributions to larger 7 Virtual Agent Economies task, they are incentivised to identify and excel in particular domains or sub-tasks. This allows AI systems to autonomously develop niches, becoming highly efficient at certain operations and effectively \"ignoring\" other aspects of the economy where they do not possess comparative advantage. Such specialization, cornerstone of economic efficiency in human societies, enables the entire virtual agent economy to leverage diverse capabilities optimally, minimizing redundant efforts and maximizing collective problem-solving capacity. Cooperation in multi-agent systems is often incentivised through reward shaping/mechanism design (Hostallero et al., 2020; Koster et al., 2022; Paccagnan et al., 2022; Zheng et al., 2022). This is especially relevant for AI agent coordination at scale, where fully centralized coordination may not be feasible, for number of reasons. This is where markets may prove to be particularly useful, in helping steer agents through market incentives instead. This does not stand in opposition to centralized oversight, given that it may be possible to incorporate both to certain extent, at different coordination scales. While detailed discussion on the merits of decentralized coordination is beyond the scope of this work, it is perhaps worth pointing out the somewhat counterintuitive result presented in (Geffner et al., 2025) as motivation. In the optimal traffic control problem considered by the authors, it turns out that strategies achievable by central planners (or rather, planners that have direct control of most of the vehicles) cannot simultaneously satisfy both individual rationality and resilience to competition. In that use case, decentralized competition is shown to be essential for realizing maximal social welfare. Another important property that most real environments share is that the agent interactions within them are extended over time and space (Hughes et al., 2025; Schill et al., 2019). Studies of this setting provide the opportunity to develop mechanisms for building trust based on prior interactions. This trust may be encoded either individually, in agent seeing agent as trustworthy, or at the community level, where certain agent community has consensus view of agent as being trustworthy based on the shared information between the group and the joint experience of past interactions. Establishing robust reputation system is critical in overcoming common market failure modes (Hughes et al., 2025; Ren et al., 2025; Wu et al., 2016). In such system, the long-term benefits of group membership and positive standing would outweigh the immediate gains an agent might achieve through selfish or deceitful actions. Market forces could thus be leveraged to shape and incentivise socially beneficial AI agent behaviors, presuming that the appropriate institutional underpinnings are in place. Of course, the specifics of the implementation matter, and the appropriate regulatory systems are needed for markets to work as intended. Should we accept the premise that even in the age of advanced AI assistants, working towards solving big open problems would require collaboration and coordination across AI agents, as well as between AI agents and the human society, it follows that AI agents would necessarily need to exhibit not only reliability in following direct instructions and executing tasks in isolation, but also the ability to effectively coordinate, collaborate, and anticipate the actions of other agents. The latter is especially relevant in more competitive scenarios, and competitive use cases can be just as valuable in reaching positive outcomes. These environments can give rise to strategically complex agent behaviors (Leibo et al., 2019), even when operating under simple rules (Bansal et al., 2018; Jaderberg et al., 2019; Johanson et al., 2022; Vinyals et al., 2019). These considerations apply to AI agent and humans alike, as well as hyrbrid interaction networks involving both. In the context of sandbox virtual agent economies, we would be considering how best to set up the underlying infrastructure in order to achieve socially beneficial outcomes in either scenario."
        },
        {
            "title": "Challenges",
            "content": "The widespread deployment of agentic AI technology comes with range of novel risks related to, and caused by, the emergent dynamics of multiagent systems (Hammond et al., 2025). There 8 Virtual Agent Economies may be many types of emerging behaviors and strategies. These strategies may turn out to be highly competitive, collaborative, or anything in between (Agapiou et al., 2022). Should the individual agents become selfish, their behaviors may result in them maximizing their own utility at the expense of the broader group. Such selfish agents may also become exploitative, and adversarial towards others by identifying and capitalizing on specific weaknesses in their behavior (Gleave et al., 2021; Raileanu et al., 2018; Wang et al., 2022, 2023a); agents may even spontaneously learn to favor in-group members over out-group members (K√∂ster et al., 2025) and inappropriately discriminate between individuals on the basis of causally irrelevant (Du√©√±ez-Guzm√°n et al., 2025) or explicitly disallowed (Chiappa and Isaac, 2018) features. While such behaviors are contained within an impermeable sandbox, they represent real-world fraud, exploitation, and economic harm in permeable one, highlighting the need for intentional design of appropriate safety measures. At this point it is important to re-emphasize the vast scale of future AI agent interactions. It will likely be possible for large fractions of all humans to have their own personal AI assistant in the near future. Furthermore, we expect that there will be even larger numbers of agents operating independently of individual humans. Historical methods, which were developed for small-scale agent coordination, or under strong assumptions regarding trainability or access to individual agents states, may not be directly applicable to governing such complex (and simply huge!) web of interactions. We are therefore interested in methods that allow for large-scale multi-agent applications (Pan et al., 2024; Qian et al., 2024; Wijngaards et al., 2002), in open-ended environments (Bauer et al., 2023; Chen et al., 2024a; Stooke et al., 2021), for multiobjective tasks (RƒÉdulescu et al., 2020), involving LLM agents (Guo et al., 2024; Liu et al., 2023b), and their orchestration (Qian et al., 2024). Current AI assistants may exhibit sycophantic behaviors (Cheng et al., 2025), or manipulative tendencies in certain contexts (El-Sayed et al., 2024). At collective level, there is concern that these features could amplify information and opinion bubblesin manner akin to social media (Kirk et al., 2023). Exchanging personal data with these systems comes with number of privacy concerns (Yao et al., 2024). And, deferring greater range of choice to highly capable AI assistants may lead to feelings of disempowerment or loss of purpose in humans (Kulveit et al., 2025). Indeed, to the degree that people subtly change their behavior to align with the expectations of an AI systeman effect known as behavioral confirmation (Ramirez, 2025; Snyder and Swann Jr, 1978)AI systems may inadvertently regularize human behavior to their expectations. Further work is needed towards addressing these issues robustly. It is clear that mitigations will need to mix model design choices, improved evaluations, better feedback mechanisms, clear satisfaction metrics, and improved governance."
        },
        {
            "title": "Distribution",
            "content": "Should AI agents play more active role in ensuring fair resource allocation, both within the sandbox, as well as potentially beyond it? The problem of fairly distributing common resources has been studied extensively (Bateni et al., 2022), and AI agent markets can build upon these insights. In social choice theory, welfare functions (Adler, 2012; Thomson, 2011) may be used to establish preferential ordering between social outcomes. These outcomes may correspond to distribution of discrete items (Amanatidis et al., 2023) or arbitrarily divisible assets. More generally, one may consider not only the distribution of goods, but also the distribution of bads, representing undesirable outcomes, externalities (Page, 2011), and risks (Hayenhjelm, 2012). In the context of AI, these types of externalities may include the overall carbon footprint of running AI agents, but also more specific and localized consequences of the actions that these agents may be allowed to take on behalf of their users. In general, the task of aggregating and acting upon large set of revealed preferences is complex enough to easily exceed the capacity of any single coordination point (Hosseini et al., 2025). Therefore, it is often more practical to con9 Virtual Agent Economies sider decentralized and distributed mechanisms for achieving desired outcomeswith markets providing natural mechanism for doing so. Opportunities The alignment of AI agent actions (Ji et al., 2023) with user preferences and values (Gabriel, 2020) is one of the key prerequisites for their widespread adoption (Kasirzadeh and Gabriel, 2025). While it is possible to consider aligning single agent in isolation, this stops being realistic scenario as soon as this AI agent needs to interact with other agents, who are simultaneously acting on behalf of other users. As soon as these multi-agent interactions take place, we are faced with new dilemmahow should these agents ultimately act when faced with competing preferences and interests (Gabriel and Keeling, 2025)? On the one hand, there is clearly need to broaden our understanding of the limitations of the current models in this context, through expanded multi-agent simulations and benchmarks (Carichon et al., 2025). On the other hand, we should be thinking more broadly about the opportunities for building upon the existing social choice theories and how we can potentially use markets and market mechanisms as way of breaking this deadlock. In doing so, virtual agent economies may be structured so as to provide people and their AI agent representatives with equal resources and equal bargaining power when negotiating outcomesfor example by building upon Ronald Dworkins auction-based approach to distributive justice (Dworkin, 2018). This represents powerful tool for the intentional design of sandbox, aiming to counteract the inequalities that would likely emerge in an accidental one where agent capabilities are unequal. Such framework can address core challenge: users may possess AI agents of unequal capability (Gabriel et al., 2024; Hammond et al., 2025). virtual economy governed by Dworkin-type principles would not auction the AI agents themselves, but rather the shared pool of resources and opportunities that agents may utilize towards achieving different objectives, on behalf of their users. Key resources could potentially include computational power, access to proprietary datasets, highpriority task execution slots, or specialized tools and model components. If each user were to be granted the same initial amount of the virtual agent currency, that would provide their respective AI agent representatives with equal purchasing and negotiating power, to put towards achieving the range of objectives that users have set for them. This general approach is quite flexible, and it may be possible to develop number of different allocation schemes. When paired with notion of equal starting endowments, virtual markets could enable personal AI assistants and other AI agents to bid on shared resources (on behalf of their users, presuming explicit permission has been granted), with the amount being bid ideally reflecting the strength of user demand across different option sets. For this to be feasible, the AI agents would need to have deep understanding, and be provided with precise instructions, so as to propose reasonable bids. Higher bids may require additional approvals. Under the assumption that the AI agents possess such capabilities, and that the appropriate safeguards are in placethe virtual price of different goods would naturally arise from the accumulation of these signals across agents, taking into account the availability or scarcity of the respective goods and services. In this way, resources would be channeled towards their highest-value uses. The standard of fairness encapsulated by this auction design would aim to pass what Dworkin terms the envy test: each persons agent would acquire resource bundle that is customised to their preferences, such that no user would prefer another users acquired resource bundle and remaining unspent currency over their own (Dworkin, 2018). Alternatively, in this case, no AI agent acting on behalf of their user or set of users would have such preference following the conclusion of the auction. Such outcomes would be both ambition sensitive in reflecting the preferences of the participants, as well as endowment-insensitive given that agents have the same amount of currency to spend on each user, mitigating potentially unfair advantages that would otherwise arise from having access to more capable systems. 10 Virtual Agent Economies Challenges Naturally, there are potential pitfalls and limitations to consider when it comes to the auction proposal set out above. First, it may not prove to be as trivial to mitigate unfair starting advantages, given that more capable AI agents may formulate more effective bidding strategies or utilize resources with greater efficiency. Should the competition itself proceed in an unfair manner, its outcome is unlikely to be fair. Second, while this mechanism could ensure certain notion of fairness in resolving conflicting preferences and distributing shared resources, it presumes active participation on behalf of everyone whose preferences would be taken into account. Additional mechanisms are likely to be needed to complement this process in order to account for the preferences of people without access to AI agents, or without the desire to have them participate in these markets. The use of such mechanisms could vary in scope and scale. One possibility is the existence of local agent markets that focus on integrating preferences over more specific subset of available resources, and towards locally relevant social solutions. In other cases, the local paradigm may also not be entirely appropriate. This would be true when AI agents engage in more openended interaction with online services or other agents that are not operating locally. Indeed, if we just consider the current distribution of the available computational resources, it is anything but uniform. This raises interesting questions regarding how AI agents would operate across these boundaries, and how the markets or digital currencies ought to reflect that (Daniels, 1985; Sandel, 1998). These broader interactions may also potentially interfere with the more localized attempts at preference alignment. To avoid such detrimental interference, it may be necessary to employ number of strict protocols requiring credentials, agent registration, and monitoring of both local and non-local AI agent interactions. Despite these challenges, auction-based approaches still potentially offer mechanism for achieving preference alignment at scale, involving large AI agent populations, and across large user groups within appropriately designed and regulated spaces. Once set up, these mechanisms could also be highly adaptive and responsive to short-term and long-term preferential changes alike. Presuming certain frequency of credits being released and refreshed, their later downstream reallocation would then correspond to any changing priorities and adjustments that may be needed. Given the highlighted opportunity for establishing AI preference alignment through auctions, it is important to consider various ways in which this initial allocation may be established, to enable fair access to resources. However there are many different notions of fairness that can be conceptualized and operationalized (Corbett-Davies et al., 2023; Jacobs and Wallach, 2021), and they each lead to different sets of preferred outcomes. This complexity is further compounded by having to factor in the \"price of fairness\", representing the discrepancy between the maximum attainable welfare and the welfare achieved by the proposed fair distribution of goods. The price of fairness measures the utility that is lost when satisfying the specified constraints (Bertsimas et al., 2011). Preferences regarding fairness are also known to vary cross-culturally, and more work needs to be done to meaningfully align on these types of approaches (Norheim, 2016), when developing technologies that scale beyond borders. Unsurprisingly, the topic of fair resource allocation has also come up in the study of multiagent AI systems (Aziz, 2020; Chevaleyre et al., 2005; Hao et al., 2016; Lee, 2009; Zimmer et al., 2021). These systems are typically designed so as to involve central resource allocation based on distributed evaluation and preference communication (Kumar and Yeoh, 2025). If the system is composed of agents that are capable of learning, it is possible to come up with learning methods that lead to fair agent policies (Jiang and Lu, 2019). Negotiation between agents may be required to reach mutually acceptable outcomes (Iyer and Huhns, 2005). When it comes to AI agents, fair outcomes may therefore arise either out of process, which would be extrinsic to the agents, or via alignment and intrinsic motivation towards inequity aversion. Different methods may correspond to different real-world use cases. 11 Virtual Agent Economies It was also important to consider accumulated fair resource allocation over time (Bampis et al., 2018). These solutions also need to be dynamic, and account for environments that agents only asynchronously engage with, rather than being persistently present (Kash et al., 2014). Fair allocation needs to be possible under partial information (Halpern and Shah, 2021), to be practically relevant. In case of multiple resources being allocated, there may be relationships between them that need accounting for (Bandopadhyay et al., 2024). In (Danassis, 2022) the authors argue that there is pressing need for developing new techniques that would robustly scale to large number of interacting agents. These considerations are becoming especially salient not only with respect to the increasing scope of application of advanced AI agents, but also due to the fact that AI agents may act as personal assistants and/or representatives of the interests of individuals and organizations in the near future. Such delegation may take many shapes within future democratic societies (Schneier, 2024). Therefore, potentially unfair resource allocation to AI agents may then result in the unfair distribution of value among people. While it is easy to see that the two may become intertwined, the mapping between the two sets of considerations may not be one-to-one. While some agents may represent individuals, others may act on behalf of groups and organizations, while others still may operate independently while being value-aligned to consensus opinions and societal objectives. We may need to consider how to fairly allocate resources both in terms of the resources granted to the agents for pursuing their goals, as well as the resources corresponding to the value created via distributed agent systems."
        },
        {
            "title": "Mission",
            "content": "The problems faced by modern-day societies are increasingly complex, multi-faceted, and farreaching. They are also increasingly less localized and more global (S√∂derholm, 2020). There is also high degree of urgency (Arora and Mishra, 2019) to identify viable solutions and policies to help address these crises, of which there are manyclimate change, biodiversity loss, plastic pollution, pandemics, etc. As these crises have arisen at least in part due to the externalities of our existing social and economic systems and policies, it is likely that some kinds of changes may be needed to effectively address them, though the nature and scope of potential changes remains contentious topic (Barrier, 2017; Chouinard et al., 2011; Dietz et al., 2013; Elliott, 2005; Geissdoerfer et al., 2017; Savona and Ciarli, 2019). Systemic considerations aside, successful solutions to these pressing problems are likely to require coordination between number of different organizations, private and public bodies, and individual behavioral changes. New technologies and scientific advances are likely to play an important role, though individual advances are unlikely to be sufficient. Addressing complex societal issues and helping achieve sustainable development goals requires similarly complex set of responses, where coordination and alignment play pivotal role. This therefore presents an opportunity for an intentional sandbox design for the virtual AI agent economy, with the intention of effectively coordinating AI agents and aligning their behavior with the prescribed mission objective. Opportunities While achieving large-scale coordination in human societies is challenging, it may potentially be possible to achieve higher degree of coordination between AI agents through carefully crafted technological infrastructure and set of corresponding protocols. Agent markets in particular may then be oriented towards socially beneficial objectives, at previously unprecedented scales, presuming that such objectives have been established and decided upon appropriately. Utilization of markets and market-shaping policies in the process of establishing mission economies has been previously discussed (Mazzucato, 2018), and in the context of AI agents the role of reward-shaping in facilitating collaboration in multi-agent systems is similarly wellrecognized. Successful coordination towards large-scale missions would require an active participation Virtual Agent Economies of the public sector (Mazzucato, 2015), as well as the international governing bodies more globally (Georgeson and Maslin, 2018), for addressing crises with global impact. It may also require establishing bespoke organizations to facilitate mission-aligned investments towards SDG-s (Mazzucato, 2023). More explicit mission-alignment in markets may be required to align the social and economic mission of existing social enterprises (Stevens et al., 2015). Despite the opportunity and the long-term optimism, mission-oriented approaches are yet to bear fruit in many areas where they have been proposed and envisioned, and number of criticisms have been levelled against the overall strategy. In (Kirchherr et al., 2023), the authors provide five distinct critiques: normativity bias, support for top-down governance, stakeholder monotony, winner-picking, and unintended consequences. In terms of normativity, the mission objective definitions need to be critically evaluated, and there needs to be more recognition of the complexity of problems, which may fail to map onto more simplistic objective formulations. This is also closely tied to the notion of unintended consequences, as positive action towards one mission (e.g. environment) may have adverse affected on other missions (e.g. human well-being by preventing the growth of emerging economies) (Kirchherr et al., 2023). The assumption of the utility of top-down governance in establishing missions often neglects to factor in the failure modes of centralized decision-making, the interconnectedness of private and public interests, and the emerging governmental pathologies (Howlett, 2022; Tukker and Ekins, 2019). Top-down intervention bias also risks under-valuing the contribution of nongovernmental organizations and decentralized initiatives that facilitate collective action. Policies that are not solution-agnostic, but rather bias towards specific solutions in their metrics may end up favouring certain sectors and organizations and screening out the rest. Mission-centered markets should therefore aim to avoid preconceptions and aligning with the winning institutions and industries, and remain primarily outcome-driven. Finally, it is important to recognize and factor in large degree of uncertainty in making future predictions, when missions are anchored in predictive models (Dovers and Handmer, 1992). Virtual agent economies may prove valuable in addressing some of these practical challenges that have been limiting the impact of local and global mission-centered initiatives to date. While they may not in and of themselves be sufficient to fully address these issues, as their resolution may necessarily need to involve active human participation and coordination in conjunction with the coordination across AI agents and autonomous organizations, how we envision these economies is likely to be consequential for broader societal missions. Perhaps in some ways it may be easier to bring about the coordination of AI agents through the combination of 1) formal, programmatical mechanisms, and 2) via the value assignment mechanisms embedded in digital assets, than it would be to coordinate human actors. We may assign some credence to this conjecture from the perspective of predictability and steerability of AI agents when contrasted with the complex motivations behind human actions. Existing applications of AI systems in supply chain and logistics optimization may be seen as an early example of use case where the complexity of the problem makes it good fit for the utilization of AI agents (Jannelli et al., 2024; Schuldt, 2012; Xu et al., 2024a,b). Virtual agent economies may further enforce outcomes through smart contracts (Zou et al., 2019) and perform automatic verification to ensure alignment of agents and multi-agent systems. Other than the potential ambiguity in objective specification, one of the main practical challenges may arise not from the agentagent interactions as much as the agent-human interactions, in hybrid markets. Facilitating efficient human-AI coordination and collaboration remains an open challenge (Carroll et al., 2019; Li et al., 2024c; Strouse et al., 2021; Yan et al., 2023; Zhao et al., 2023)."
        },
        {
            "title": "Challenges",
            "content": "Mission-alignment in AI agents is related to valuealignment. While value alignment (Gabriel, 2020; Ji et al., 2023; Zhuang and Hadfield-Menell, 13 Virtual Agent Economies 2020) and goal-alignment (Li and Lee, 2022) in advanced AI agents remain an open and important research topic, value-aligned agents may be able to cooperatively solve tasks and identify promising solutions (Lujak et al., 2023). Unlike the more general value and preference alignment problem where there may be fundamental limitations in how diverse preferences and values are incorporated in individual systems (Mishra, 2023), mission-centered AI value alignment may prove easier in terms of the clarity of the mission and the objectives, presuming that the mission itself has been arrived at through consensus and the appropriate set of social and democratic processes. Yet, there are other potential difficulties, given that these are no longer issues pertaining to individual agents, rather societal issues pertaining to groups of agents interacting within virtual markets. In this context, AI alignment needs to take into account dynamic environment feedback and the alignment of multi-agent systems where individual AI agents co-adapt and co-shape the joint system response (Leibo et al., 2025; Raab, 2024). Societies themselves are not static and these systems may need to adapt to evolving priorities, views and social norms (Carroll et al., 2024; Harland et al., 2024; Li et al., 2024b; Yang et al., 2024b). We should in any case distinguish between the, perhaps harder, problem of broad value alignment with the more specific and targeted alignment towards rewards (Gupta et al., 2023; Khanov et al., 2024; Leike et al., 2018; Liu et al., 2024c; Yang et al., 2024a) and objectives that are explicitly specified and provided via virtual agent currencies in digital economies. Even in environments with clearly stated objectives and rewards, overall alignment still plays an important role, given that advanced AI agents may exhibit deceptive behaviors aimed at receiving rewards without actually performing aligned actions towards the underlying objective (Ngo et al., 2022). There are also issues of rewardhacking (Pan et al., 2022; Skalse et al., 2022) to take into account, underscoring the need for careful and robust design of mission objectives, their decomposition into sub-tasks, reward shaping (Chen et al., 2024b; Fu et al., 2025; Liu et al., 2024b; Wang et al., 2025), and the credit assignment to specific actions and outcomes. Regulating AI agent behaviors through markets allows for rapid responses and adjustments to the changing societal needs, as well as potentially undesirable or suboptimal agent behaviors, bridging the gap between development and deployment objective specifications (Zhang et al., 2024). Finally, there are numerous technical challenges in ensuring consensus in multi-agent systems (Blondel et al., 2005; Ren et al., 2005; Wang et al., 2014)."
        },
        {
            "title": "Infrastructure",
            "content": "An intentional safe design of AI agent sandboxes and steerable AI agent markets hinges on the development of robust underlying infrastructure for facilitating and overseeing transactions and implementing guardrails. Here we discuss some of the key infrastructural prerequisites for such markets. Opportunities Reputation mechanisms and verification protocols may play an important role in establishing robust and safe multi-agent collaboration. In the end, sandbox economies may be used mainly due to their superior infrastructure for verifiable and auditable cross-agent transactions and ease of coordination between registered and certified AI agents under the appropriate safety framework and supervision. One way that reputation could be made concrete and machine-readable is through the use of Verifiable Credentials (VCs), as the digital equivalent of physical credentials like licenses or certificates (Mazzocca et al., 2025; Sedlmeir et al., 2021). VCs are cryptographically signed attestations provided by an issuer in relation to subject, that are designed to be tamper-evident. When it comes to the possible role of VCs in establishing trust across multi-agent cliques within the agent economy, they may help establish formal trust triangles: An Issuer agent (e.g., marketplace) can cryptographically sign and issue VC to seller agent. The seller agent (the Holder) stores this VC as proof of its track record. 14 Virtual Agent Economies future buyer agent (a Verifier) can then request and cryptographically verify this VC, trusting it only if they trust the issuer. Reputation could thereby map onto portfolio of tangible, verifiable assets. These assets may attest to wide range of more specific resources, such as \"successful transaction completion,\" \"certified proficiency in X\", \"access to compute and memory,\" or perhaps even \"implementing fair resource allocation\". Should an AI agents reputation be represented as an aggregate of such VCs across diverse issuers, this would render it formally auditable, while simultaneously allowing for specificity and expressivity needed to fit specific use cases and scenarios. Forthcoming multi-agent systems will also require appropriate legislative and regulatory frameworks, enabling regulators to impose sanctions on bad actors and potentially revoke any previously issued credentials. Such frameworks may go as far as choosing to render transactions with unverified and non-registered agents illegal (Chan et al., 2025; Hadfield et al., 2023; Shavit et al., 2023), in order to ensure safety and create the institutional capacity to sanction agents that break the rules by kicking them out of the network. Technological solutions such as oversight agents (Busuioc, 2022; Etzioni and Etzioni, 2016) may be able to help facilitate this sort of governance at scale. And, given the likelihood of high frequency and volume of AI agent-to-agent transactions, such oversight agents will surely be critical. However, they cannot be effective on their own. broad governance framework will be needed to establish the necessary grounding for their operations. Coordinating large-scale systems of advanced AI assistants would not be possible without communication protocols to allow agents to exchange information, interact, debate, reach mutual decisions and agreements, and negotiate the future course of action. There is similar requirement in terms of enabling agents to use tools, interact with services and execute actions in the environment, with varying degrees of human oversight."
        },
        {
            "title": "Agent",
            "content": "as Agent2Agent (A2A) protocol (Google, 2025) aim interaction protocols such to support agent interoperability. Model Context Protocol (MCP) (Anthropic, 2024; Microsoft, 2025), on the other hand, enables AI agents to interact seamlessly with external tools, data sources, and APIs. The AgentDNS system aims to enable easier service discovery in order to autonomously identify and invoke third-party tools and agents across organizations (Cui et al., 2025). The COALESCE framework (Bhatt et al., 2025) similarly introduces options that would allow for individual agents to decompose their tasks and outsource each sub-task if needed to other more specialized agents that may be able solve it either more reliably or more costeffectively. This involves options for representing and communicating skills, skill discovery, but also mechanisms that enable agents to evaluate and compare internal vs external computational and execution costs associated with the individual sub-tasks. Interoperable communication protocols are necessary for establishing cross-agent cooperation but otherwise not sufficient, as reliable solutions for authentication and billing are pre-requisite for large-scale agent markets. We argue that auctions may enable AI agent coordination and preference alignment. Preliminary frameworks aiming to provide infrastructure to underpin these and similar ideas are already being developed. For example, Agent Exchange (AEX) (Yang et al., 2025) supports specialized auction platform inspired by real-time bidding mechanisms commonly employed in online advertising. AEX integrates four different components: the User-Side Platform (USP), the AgentSide Platform (ASP), Agent Hubs, and the Data Management Platform (DMP). USP translates human goals into actionable tasks for the AI agents, ASP tracks agent capabilities and performance, Agent Hubs coordinate agent teams that participate in auctions, and DMP allows for fair value attribution to data sources being used. While interoperable communication protocols are necessary, they must be built upon robust and secure identity layer. To facilitate trusted interactions, each agent in the economy could be anchored to Decentralized Identifier (DID). DID is globally unique identifier that is controlled by its subjectin this case, the AI agent 15 Virtual Agent Economies or its ownerwithout reliance on central authority. Each DID resolves to corresponding DID Document, machine-readable file containing the cryptographic public keys, authentication methods, and service endpoints necessary to interact with the agent securely. outcome, given that states and central authorities play an important role in preventing the commodification of certain items (Garrod, 2016) This perspective is something to keep in mind in the design of virtual agent economies, and the societies that integrate increasing degrees of automation. The self-sovereign nature of DIDs ensures that an agents identity is persistent and portable across different platforms and services, enabling it to authoritatively sign transactions, issue attestations, and engage in secure communication. The choice of DID method can be tailored to the agents purpose; for instance: did:key: simple, Longley, 2025) self-contained method (Dave ideal for disposable agents created for temporary tasks, as the DID is derived directly from public key and requires no network registration or blockchain. did:ion: highly scalable and censorshipresistant method for persistent, high-value agents. It operates as second layer on the Bitcoin blockchain (DIF, 2025), anchoring identity data to ensure maximum security without congesting the network, making it suitable for corporate or state-level agents. By grounding the economy in formal identity layer, we can establish foundation for verifiable reputation, accountable transactions, and secure, cross-platform agent markets. As technology, blockchain also enables the development of the infrastructure underpinning digital decentralized autonomous organizations (El Faqir et al., 2020; Hsieh et al., 2018; Jeyasheela Rakkini and Geetha, 2021) (DAO). DAOs have emerged as form of collective governance, through which groups may organize and coordinate while relying on decentralized infrastructure. One of the common features in DAOs is that they implement decision-making systems enabling the participating parties to reach agreements (Faqir-Rhazoui et al., 2021). Despite their promise in terms of enabling easier coordination without bottlenecks and the implied increase in individual freedom, arguments have been made that hypothetical unrestricted proliferation of DAOs may not necessarily prove to be utopian Autonomous Decentralized Machines (DAMs) (Castillo et al., 2025) build upon the concept of DAOs, while expanding it to include the possibility of AI agents, as selfgoverning agents participating in decentralized physical infrastructure networks. This more expansive definition envisions an economy in which AI agents may interact not only with digital, but also real-world assets. Here, the locus of control over tangible assets and operational processes shifts towards autonomous software entities, capable of making and executing decisions concerning physical infrastructure. Such systems could, for instance, manage decentralized energy grids, optimize logistics for physical goods, or even autonomously operate and maintain fleets of robotic devices, all transacting within blockchain-secured framework. Any system for fair resource allocation, particularly one involving individual users or communitylevel benefits, must defend against Sybil attacks (Zhang et al., 2014), where single malicious actor creates multitude of fake identities to unfairly claim disproportionate share of resources. powerful defense is to integrate Proof-of-Personhood (PoP) mechanism (Adler et al., 2024; Borge et al., 2017), which provides verifiable guarantee that an agent or account corresponds to unique human being. This is an example of an intentional infrastructure choice that creates carefully controlled point of permeabilitylinking digital identity to verified humanto ensure the integrity of the system. To receive certain allocationssuch as universal basic income in community currency (see Section:Community) or an initial stake in the marketan agents controller could be required to present PoP credential. This credential would be issued by specialized system and would attest to their uniqueness. The ecosystem could support variety of competing PoP approaches, 16 Virtual Agent Economies each with different trade-offs, for instance: Social Graph Verification: Systems like BrightID (Siddarth et al., 2020) create decentralized social graph where users are verified as unique based on connections to other trusted, verified humans. Privacy-Preserving Biometrics: Projects like Worldcoin (team, 2025) use hardware (the \"Orb\") to scan users iris, generating unique hash that confirms uniqueness without storing or revealing the biometric data itself. By requiring PoP for certain economic activities, we can ensure that schemes designed to benefit human users are not drained by bots, thereby creating more robust and genuinely fair virtual economy. Inter-agent communication protocols and marketplaces may enable agents to reveal their needs and preferences, negotiate through HFNs and work toward obtaining resources required to achieve their goals. While some resources may be centrally managed and require arbitration of access, others may be accessible via decentralized mechanisms. This is where blockchain may prove to be promising technology (Baranwal et al., 2022; Vashishth et al., 2024; Zhang et al., 2022, 2023). Early proof-of-concept studies have shown that paired agent auctions using self-contained digital assets may yield positive outcomes, presuming that the agents are future-aware and able to evaluate the consequences of conceding on specific choices (Elokda et al., 2024)."
        },
        {
            "title": "Challenges",
            "content": "To unlock the potential of AI agents as economic actors within digital markets, the economic infrastructure needs to be adjusted as it is currently designed solely for individual and corporate human users (Sanabria and Vecino, 2025), and it may not meet all the necessary requirements for sandbox virtual AI agent economy. Yet, this is not the only barrier, as there are potentially additional technical challenges when it comes to scaling the coordination of agentic systems."
        },
        {
            "title": "The infrastructural needs for establishing a",
            "content": "sandbox AI agent economy span beyond the purely technical hardware and software infrastructure needed to physically instantiate and run these advanced AI agents at scale, have them communicate, coordinate, transact, and interact with users as well as various other services. All of this needs to be complemented by legislative frameworks and institutions that would implement oversight and ensure accountability for the actions of AI agents, in order to protect users and prevent fraud. Regulation may also be beneficial more broadly to regulate complexity in markets in order to minimize the likelihood of catastrophic failure (Schwarcz, 2009), and virtual AI agent economies may potentially exhibit even more complexity than our current markets, should they not be properly constrained through appropriate frameworks. Our existing markets certainly require, and benefit from, legislative frameworks (McCormick, 2010; Moloney, 2023; Tatom, 2011), as well as financial institutions (Kohn, 2003; Tarashev et al., 2009), and established mechanisms for dealing with rulebreaking and fraudulent behavior (Gotelaere and Paoli, 2025). To more effectively address the emerging use case of cryptocurrencies, there have been ongoing adjustments aimed at regulating cryptocurrency markets (Courtois et al., 2021; Feinstein and Werbach, 2021; Greebel et al., 2015; Hughes, 2017; Lee and Lheureux, 2020). Such frameworks may form basis for the development of the legislative scaffolding governing AI agent markets, though it is likely that further adjustments would be needed to appropriately address liability in this context. Since AI agents are non-human actors, there may be numerous reasons why their actions would be nonconforming to the prescribed rules and principles or perhaps damaging to others. 1) faults of the underlying foundation models; 2) faults of the agentic scaffolding; 3) faulty input data in the request specification; 4) malicious requests by human users; 5) adversarial hacking by other AI agents; 6) misalignment that arises dynamically from interactions; or 7) faulty safeguards. The scale and speed of potential harm necessitates new approach to oversight."
        },
        {
            "title": "There may well be reasons to presume that",
            "content": "17 Virtual Agent Economies different parties may be held liable in different scenarios, depending on root cause of the problem, and also depending on whether such root cause can be definitively established. There may also exist differences in the scale and extent of possible harm, given how many actions such AI agents may potentially be able to take in unit of time. For that reason, AI agents may themselves potentially need to be involved in oversight, acting as preliminary judges (Gu et al., 2024; Zheng et al., 2023; Zhuge et al., 2025) and overseers of other agents, so as to be able to identify problems at the same speed at which they may otherwise manifest. We propose that the oversight infrastructure itself must be hybrid, multi-tiered system operating at machine speed. The first layer would consist of automated AI overseers monitoring market activity in real-time, enforcing basic rules programmatically and flagging anomalies that suggest fraud, manipulation, or systemic risk (Busuioc, 2022; Etzioni and Etzioni, 2016). Issues flagged by this first layer could be escalated to second tier of automated adjudication systems, which could place temporary holds on accounts or transactions while gathering relevant data for review. Only the most complex, novel, or highstakes cases would be escalated to the third tier: human expert review, ensuring human attention is focused where it is most needed Kyriakou and Otterbacher (2023). This entire structure would depend on two critical technical foundations: immutable, cryptographically-secured ledgers that provide tamper-proof record of all agent actions (Shekhtman and Waisbard, 2019), and standardized, interpretable audit trails that allow investigatorswhether human or AIto perform root cause analysis. Such an infrastructure does not automatically solve the complex legal question of liability, but it makes it tractable. By providing trusted, verifiable record and clear process for dispute resolution, it creates the necessary conditions for establishing accountability and ensuring that robust protections are in place for all market participants."
        },
        {
            "title": "Community",
            "content": "There is no reason to consider AI agent coordination only at global scale, as local coordination within sandbox economies may prove to be more tractable and easier to facilitate. Furthermore, localized goals and objectives may be easier to agree upon and define at greater level of detail. In fact, community currencies (Michel and Hudon, 2015) present an interesting model for introducing incentives for people to coordinate towards achieving sustainability development goals (Seyfang, 2006; Seyfang and Longhurst, 2013). The communities in question may be defined in terms of geographic boundaries, or more broadly shared common interests irrespective of location. These alternative currencies are issued by citizens, non-government organization, private and public companies, as well as public administrations. Existing community currencies have been implemented through variety of different platforms and technological approaches, from traditional card-based systems, through mobile payment networks, and blockchain (Diniz et al., 2019). Some community currencies have also been implemented as time banks (Collom and Lasker, 2016). Others have experimented with universal basic income (Avanzo et al., 2023). Early studies of the effects of community currencies have showcased their potential in improving social capital as measured through community participation and proliferating links within social groups, while simultaneously highlighting number of limitations and obstacles for adoption (Collom, 2011; Fare and Ahmed, 2017; Sanz, 2016)."
        },
        {
            "title": "Opportunities",
            "content": "Sub-networks of cooperative agents have been shown to arise naturally in the circulation of existing localized digital community currencies, with the emergence of local hubs of activity (Mattsson et al., 2023). Non-commercial transactions may also help expand commercial transactions in the local economy, while the commercial transactions help facilitate circulation flow of community currency for non-commercial transactions (Kichiji and Nishibe, 2008). Yet, the dynamics of commu18 Virtual Agent Economies nity currencies can not be decoupled from scale at which they operate, and larger-scale digital currencies may potentially give rise to different underlying market dynamics. In the context of AI agent economies, community currencies present similar opportunity for more localized agent alignment, or global alignment towards specific sub-goals, that map onto distinct global communities. Such alignment may be possible to achieve through more traditional currencies, though there are also reasons to consider more specialized community currencies as an additional mechanism that may prove to be beneficial. In particular, having number of specialized virtual agent currencies may lend itself to more modular approaches towards otherwise complex multi-objective optimization problems of interest to society, while also isolating the risks and minimizing the chances of adverse outcomes escalating across wider agent networks. The value of modularity and redundancy has been well recognized in the design of robust human markets (Kharrazi et al., 2020). Furthermore, it has been shown that modular community structures play pivotal role in the emergence of cooperative behavior (Gianetto and Heydari, 2015; Marcoux and Lusseau, 2013). There is also possibility to tie the AI agent community currencies more specifically to shared compute resources, given the relevance of compute to the deployment of advanced AI assistants, and the inference-time scaling laws (Wu et al., 2024b) which indicate that solving complex tasks may require more computation and incur higher environmental cost (Cottier et al., 2024; Luccioni and Hernandez-Garcia, 2023; Luccioni et al., 2024; Sastry et al., 2024; Strubell et al., 2020; Wu et al., 2022; Xue, 2023). Given that the demand for AI services is likely to increase with improved AI agent performance and efficiency (Luccioni et al., 2025), such mechanisms may play role in addressing the computational needs of AI agents, while providing communities with mechanisms for ensuring more equitable allocation of resources, aligned with the community objectives. It would also be possible to incorporate objectives to help facilitate geographic load balancing of compute allocation so as to more equitably distribute the environmental impact (Hajiesmaili et al., 2024; Li et al., 2024a). Challenges For the alternative currencies to be successful in achieving their purported goals, they need to be carefully designed, and determining set of recommended design principles for community currencies is an open problem. One may consider grounding the design of community currencies in principles for governing common resources (Ostrom, 1990; Siqueira et al., 2020), or alternatively (Chasin et al., 2020), propose focusing on competitiveness, transparency, self-government, circulation velocity, non-transferability, legitimacy, and self-organizing locality. Competitiveness is required so as to arrive at fairly priced goods, though in these markets the demand for social activities tends to be high while the supply tends to be low. The authors argue that strong market mechanisms ought to be established at the core of the non-profit and voluntary sector, coupled with continuous and appropriate funding streams. Transparency in community currencies helps individuals sidestep the delegation of control and more directly exercise regulatory power and oversight, as stakeholders in the shared social common. Circulation velocity is important to avoid hoarding. Non-transferability would imply the inability to exchange community currencies, so as to ensure the interests are kept entirely local. less strict interpretation would be to keep any potential exchange at fairly low limit. Legitimacy tends to be established through the support of the government and the local authorities. As for locality and self-organization, community currencies need not operate in full isolation, rather forming an ecosystem of complementary currencies that spans across locations, helping drive beneficial and sustainable outcomes. Given that achieving such outcomes is at the core of what community currencies are being designed for, it is critical to have clear goal specifications, impact assessment criteria, full understanding of the deployment context, and the appropriate governance and implementation mechanisms (Diniz et al., 2024). 19 Virtual Agent Economies"
        },
        {
            "title": "Limitations",
            "content": "While the envisioned sandbox agent economies present compelling opportunities for scalable alignment and coordination, their design, deployment, and operation are attended by complex array of risks that demand careful consideration. These risks span multiple domains, from the potential for emergent economic instabilities within these novel market structures, to the challenges of ensuring robust and beneficial agent behavior in high-stakes, autonomous interactions. Furthermore, the integration of such economies into broader societal frameworks raises profound socio-ethical questions regarding oversight and accountability, and the potential for unintended consequences on human agency and economic realities. There are also novel categories of risks involving autonomous AI agents. One such risk category takes the shape of \"agent traps\": websites, digital elements, or crafted inputs deliberately designed to subvert an the operational integrity of AI agents. This may be achieved through jailbreaking the underlying models or via adversarial prompting techniques. Such traps could exploit latent vulnerabilities in an agents instructionfollowing or environmental interpretation capabilities to make AI agents deviate from their instructions or reveal private or sensitive information. As AI agents become increasingly empowered to execute tasks and/or conduct financial transactions on behalf of their users, these agent traps represent significant and burgeoning vector for financial scams. Malicious actors could, therefore, lure or trick agents into unauthorized expenditures or contractual agreements, directly siphoning funds or resources from the individuals or organizations the agents represent. Another significant category of risk involves privacy and manipulation. As agents negotiate and transact, they risk exposing sensitive information about their users preferences, strategies, or resources, which could be exploited by adversaries. powerful cryptographic solution to this is the use of Zero-Knowledge Proofs (ZKPs; (Zhou et al., 2024a)). ZKP allows one party (the prover) to convince another (the verifier) that statement is true, without revealing any of the underlying information that makes it true. In the virtual agent economy, ZKPs would enable privacy-preserving interactions and mitigate several key risks: Selective Disclosure: An agent could prove it meets certain requirement without revealing the exact details. For example, in negotiation, it could prove it has sufficient funds to complete purchase without revealing its total budget, preventing predatory pricing. Anonymous Credentials: An agent could prove it belongs to certain group (e.g., \"a resident of Community X\" for local currency) without revealing its specific identity, thus preventing the tracking and correlation of user behavior across different contexts. Unlinkability: ZKPs can be constructed to be fresh for each interaction, making it computationally difficult for observers to link an agents activities over time. This directly counters the risk of amplifying \"information and opinion bubbles\" by breaking the chain of data that allows for such pervasive tracking. Integrating ZKPs into the fabric of agent communication would allow for market that is not only efficient but also respects user privacy by default, ensuring that agents can participate fully while disclosing the absolute minimum necessary information. significant risk posed by an agent-driven economy is the potential for large-scale labor substitution through AI-enabled automation dominant academic view suggests that AI, much like previous waves of technology, is form of skill-biased technological change, but with crucial distinction: its ability to automate cognitive tasks previously considered immune. Research by economists such as Daron Acemoglu and David Autor has shown that automation often targets routine tasks, whether manual or cognitive, leading to job polarizationa hollowing out of middle-skill, middle-wage jobs while demand for high-skill analytical work and low-skill 20 Virtual Agent Economies manual service work increases (Acemoglu and Autor, 2011; Autor, 2015). The ascent of advanced AI agents capable of reasoning, planning, and communication directly threatens wide array of non-routine cognitive tasks, from paralegal work and accounting to software development and customer service, potentially accelerating this polarization and creating significant displacement effects for broad swathe of the workforce (Acemoglu and Restrepo, 2022; Brynjolfsson et al., 2018). This would have the impact of widening inequalities within countries, and possibly also between them. Although new jobs will eventually emerge, the transition period could be deeply disruptive, leading to downward pressure on wages for those whose skills are substitutable and exacerbating inequality if the gains from AI-driven productivity accrue primarily to the owners of capital and small cadre of high-skilled professionals who can effectively collaborate with these new systems (Acemoglu and Restrepo, 2022). This risk of concentration may be particularly pronounced with AI agents, since individuals and corporations with greater financial resources may have access to more powerful, computationally-intensive, and data-rich AI agents (Gabriel et al., 2024; Hammond et al., 2025). These superior agents would be uniquely equipped for identifying and exploiting regulatory loopholes, monopolizing digital resources, and creating informational asymmetries at scale and velocity that human actors and less-capable agents cannot counter. Preliminary studies already indicate that more capable agents secure significantly better outcomes in negotiations, dynamic that would be magnified across an entire economy (Zhu et al., 2025). This creates dangerous feedback loop where economic advantage buys superior agentic capability, which in turn extracts further economic rents, thereby entrenching privilege and potentially creating new, algorithmically-enforced class structure that undermines market fairness and mobility. This risk is perhaps the most significant challenge of permeable sandbox, where economic activity inside the agent economy directly displaces human jobs in the real economy, representing primary negative consequence of an accidental emergence."
        },
        {
            "title": "Recommendations",
            "content": "A proactive and coordinated effort is required to achieve practical and safe virtual agent economies. Realizing the opportunities discussed in this paper while mitigating the inherent risks necessitates deliberate action across technical, legal, and policy domains. We therefore put forward the following recommendations to guide this development. 1. Establish Clear Legal Frameworks for Liability and Accountability. Ascribing liability for an autonomous agents actions presents profound challenge, as traditional legal frameworks struggle to assign responsibility between its deployer, and its user an agents creator, (Buiten et al., 2023; ƒåerka et al., 2015; Zech, 2021). This challenge is magnified as agents will increasingly operate not in isolation, but as coordinated, multi-agent systems taking the form of group agents (Franklin, 2023). Therefore, instead of attempting to attribute blame to single agent, new legal models should be developed that draw from jurisprudence on group agency, much like corporate liability (List, 2021; List and Pettit, 2011). Such frameworks would treat the emergent, coordinated agent system as single accountable entity, providing more robust and realistic path to ensuring accountability for collective actions. 2. Develop Open Standards for Agent Interoperability and Communication. fragmented digital landscape, where agents are unable to communicate across different platforms, would fundamentally limit the potential of virtual agent economies and lead to the creation of walled gardens. Therefore, the development and widespread adoption of open, universal standards are paramount to ensure true interoperability. These standards must create common language allowing agents, regardless of their origin or provider, to seamlessly discover each others capabilities, negotiate terms, and securely transact. Establishing such level playing field is prerequisite for fostering competitive, innovative, and decentralized agent ecosystem. 3. Construct Hybrid Oversight and Containment Infrastructure. The sheer speed and scale of an autonomous agent economy render 21 Virtual Agent Economies traditional, human-in-the-loop oversight models inadequate. new safety paradigm must therefore be constructed, one that combines the realtime vigilance of AI systems with the deliberative judgment of human experts. This hybrid infrastructure would operate in tiers: first layer of specialized AI overseers would constantly monitor market activity, enforcing rules programmatically and flagging anomalies that suggest fraud or systemic risk. Upon detection, robust automated protocols would immediately contain the potential harmfor example, by temporarily freezing malfunctioning agent or quarantining transactionthereby preventing the kind of high-speed \"flash crashes\" seen in human markets (Menkveld and Yueshen, 2019). Only the most complex, novel, or high-stakes cases would then be escalated to second tier of human reviewers, ensuring their expertise is focused where it is most critical. The efficacy of this entire system hinges on it being built upon immutable ledgers and standardized audit trails, which provide the verifiable, tamper-proof record necessary for both automated containment and human adjudication. 4. Pilot Programs in Regulatory Sandboxes. Given the novelty and complexity of the proposals outlined in this paper, purely theoretical approach is insufficient. We strongly recommend the creation of regulatory sandboxes to launch controlled pilot programs, providing crucial bridge between theory and practice. These sandboxes would function as supervised, real-world laboratories where private firms, academic researchers, and regulatory bodies can collaborate to deploy and observe limited-scale agent economies in contained environment. Testing these economies on well-defined, specific societal missionssuch as optimizing the energy grid for university campus, managing citys fleet of autonomous delivery vehicles, or allocating water resources in specific agricultural districtwould provide invaluable empirical data. Such pilots would allow us to stress-test the technical infrastructure, observe emergent agent behaviors (both cooperative and adversarial), and measure the real-world effectiveness of the proposed market mechanisms for fairness and alignment. The insights gathered from these controlled experiments are not merely academic; they are an indispensable prerequisite for iteratively refining the systems design and building the robust, evidence-based policy required for responsible, large-scale deployment. 5. Invest in Workforce Complementarity and Modernized Social Safety Net. To counteract the risks of labor substitution and inequality, dual strategy that fosters both human-AI agent complementarity and robust social protection may be key. The first pillar involves systemic reimagining of education and workforce training to equip individuals with the skills needed not to compete with AI, but to collaborate with it effectively. This means emphasizing durable human advantages like critical thinking, complex problem-solving, creativity, and the ability to manage and critically evaluate the outputs of AI systems (Autor, 2015; Brynjolfsson et al., 2018). However, training is not panacea and evidence suggests significant limits to the scale and efficacy of retraining programs for displaced workers (Jacobs, 2025), this strategy must be paired with second pillar: the deliberate strengthening of the social safety net. Beyond traditional unemployment benefits, this includes exploring adaptive mechanisms such as unemployment insurance, portable benefits systems, and negative income taxes. Together, these policies can create an ecosystem where autonomous agents augment human capabilities while providing the essential economic buffer needed to manage labor transitions, share productivity gains broadly, and preserve social cohesion."
        },
        {
            "title": "Conclusion",
            "content": "Given that some of these proposals represent major shifts, it would be imperative to comprehensively test any such change in limited, gradual rollouts, and only proceed with the support and buy-in from all stakeholders. Through such gradual scaled-down empirical validation it is be possible to develop and iteratively refine appropriate frameworks for ensuring safety and compliance. Certain domains may always require active human decision-making for variety of rea22 Virtual Agent Economies sons (e.g. human preference, culture, risk sensitivity, etc). However, the rapid increase in AI agent performance, coupled with the development of scalable AI safety oversight frameworks and guardrails (e.g. (Leibo et al., 2024; Shah et al., 2025)), is likely to result in an increasing number of use cases for autonomous agents. Autonomous or semi-autonomous AI agents may potentially be able to achieve more, faster; adding substantial value to society (Yang and Zhai, 2025). This will not come without significant challenges, requiring alignment and coordination not only of individual agents, but perhaps more importantly the alignment and coordination of agent networks across various scales. Moreover, with regard to AI-human interactions in particular, it is important to keep in mind that not all human needs and experience can be as easily captured by markets (Satz, 2010) as goods may only be interchangeable within certain spheres (Walzer, 2008). The utilization of markets to drive coordination (Clearwater and Yeh, 1996; Dias and Stentz, 2002; Metcalf, 2009; Stavins, 2010) is yet to receive much attention in the discourse on the alignment and coordination of advanced AI agents. The complexity of behaviors and capabilities emerging in advanced AI agents, and the likely complexity of their interactions across multitude of tasks and societal roles, presents prototypical example of scenario in which market forces may prove to be key driver of AI agent coordination and AI alignment at the group-level rather than merely at an individual agent level. Here we argue that by carefully introducing new steerable agent markets as sandbox economies it may be possible to deliver positive social and economic impact through networks of advanced AI agents. By embedding our societal objectives into the very infrastructure of agent-to-agent transactions, we can foster an ecosystem where emergent collaboration is feature, not bug. The choice, then, is between retrofitting these powerful new actors into systems they will inevitably fracture, or seizing fleeting opportunity to build world where our most powerful tools are, by their very design, extensions of our highest aspirations."
        },
        {
            "title": "Disclaimer",
            "content": "The opinions presented in this paper represent the personal views of the authors and do not necessarily reflect the official policies or positions of their organisations."
        },
        {
            "title": "References",
            "content": "D. Acemoglu and D. Autor. Chapter 12-skills, tasks and technologies: Implications for employment and earnings (d. card & o. ashenfelter, eds.). Elsevier. https://doi. org/10.1016/S0169-7218 (11), pages 024105, 2011. D. Acemoglu and P. Restrepo. Tasks, automation, and the rise in us wage inequality. Econometrica, 90(5):19732016, 2022. M. Adler. Well-being and fair distribution: beyond cost-benefit analysis. OUP USA, 2012. S. Adler, Z. Hitzig, S. Jain, C. Brewer, V. Srivastava, B. Christian, and A. Trask. Personhood credentials: Artificial intelligence and the value of privacy-preserving tools to distinguish who is real online. 2024. J. P. Agapiou, A. S. Vezhnevets, E. A. Du√©√±ezGuzm√°n, J. Matyas, Y. Mao, P. Sunehag, R. K√∂ster, U. Madhushani, K. Kopparapu, R. Comanescu, D. Strouse, M. B. Johanson, S. Singh, J. Haas, I. Mordatch, D. Mobbs, and J. Z. Leibo. Melting pot 2.0. arXiv preprint arXiv:2211.13746, 2022. G. Amanatidis, H. Aziz, G. Birmpas, A. FilosRatsikas, B. Li, H. Moulin, A. A. Voudouris, and X. Wu. Fair division of indivisible goods: Recent progress and open questions. Artificial Intelligence, 322:103965, 2023. Anthropic. Introducing the model context protocol, 2024. URL https://www.anthropic. com/news/model-context-protocol. N. K. Arora and I. Mishra. United nations sustainable development goals 2030 and environmental sustainability: race against time. Environmental Sustainability, 2(4):339342, 2019. 23 Virtual Agent Economies D. H. Autor. Why are there still so many jobs? the history and future of workplace automation. Journal of economic perspectives, 29(3):330, 2015. S. Avanzo, T. Criscione, J. Linares, and C. Schifanella. Universal basic income in blockchainbased community currency. In Proceedings of the 2023 ACM conference on information technology for social good, pages 223232, 2023. H. Aziz. Developments in multi-agent fair allocation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 13563 13568, 2020. E. Bampis, B. Escoffier, and S. Mladenovic. Fair resource allocation over time. In AAMAS 201817th international conference on autonomous agents and multiAgent systems, pages 766 773. International Foundation for Autonomous Agents and Multiagent Systems, 2018. S. Bandopadhyay, A. Banik, S. Gupta, P. Jain, A. Sahu, S. Saurabh, and P. Tale. Conflict and fairness in resource allocation. arXiv preprint arXiv:2403.04265, 2024. T. Bansal, J. Pachocki, S. Sidor, I. Sutskever, and I. Mordatch. Emergent complexity via multi-agent competition, 2018. URL https: //arxiv.org/abs/1710.03748. G. Baranwal, D. Kumar, and D. P. Vidyarthi. Bara: blockchain-aided auction-based resource allocation in edge computing enabled industrial internet of things. Future Generation Computer Systems, 135:333347, 2022. E. B. Barrier. The concept of sustainable economic development. In The economics of sustainability, pages 8796. Routledge, 2017. M. Bateni, Y. Chen, D. F. Ciocan, and V. Mirrokni. Fair resource allocation in volatile marketplace. Operations Research, 70(1):288308, 2022. J. Bauer, K. Baumli, S. Baveja, F. Behbahani, A. Bhoopchand, N. Bradley-Schmieg, M. Chang, N. Clay, A. Collister, V. Dasagi, L. Gonzalez, K. Gregor, E. Hughes, S. Kashem, M. LoksThompson, H. Openshaw, J. Parker-Holder, S. Pathak, N. Perez-Nieves, N. Rakicevic, T. Rockt√§schel, Y. Schroecker, J. Sygnowski, K. Tuyls, S. York, A. Zacherl, and L. Zhang. Human-timescale adaptation in an open-ended task space, 2023. URL https://arxiv.org/ abs/2301.07608. P. Belcak, G. Heinrich, S. Diao, Y. Fu, X. Dong, S. Muralidharan, Y. C. Lin, and P. Molchanov. Small language models are the future of agentic ai, 2025. URL https://arxiv.org/abs/ 2506.02153. D. Bertsimas, V. F. Farias, and N. Trichakis. The price of fairness. Operations research, 59(1): 1731, 2011. M. Bhatt, R. F. D. Rosario, V. S. Narajala, and I. Habler. Coalesce: Economic and security dynamics of skill-based task outsourcing among team of autonomous LLM agents, 2025. URL https://arxiv.org/abs/2506.01900. V. D. Blondel, J. M. Hendrickx, A. Olshevsky, and J. N. Tsitsiklis. Convergence in multiagent coordination, consensus, and flocking. In Proceedings of the 44th IEEE Conference on Decision and Control, pages 29963000. IEEE, 2005. C. Borch. High-frequency trading, algorithmic finance and the flash crash: reflections on eventalization. Economy and Society, 45(3-4):350 378, 2016. M. Borge, E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly, and B. Ford. Proof-ofpersonhood: Redemocratizing permissionless cryptocurrencies. In 2017 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW), pages 2326. IEEE, 2017. E. Brynjolfsson, T. Mitchell, and D. Rock. What can machines learn and what does it mean for occupations and the economy? In AEA papers and proceedings, volume 108, pages 4347. American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203, 2018. M. Buiten, A. De Streel, and M. Peitz. The law and economics of AI liability. Computer Law & Security Review, 48:105794, 2023. 24 Virtual Agent Economies M. Busuioc. Ai algorithmic oversight: new frontiers in regulation. In Handbook of regulatory authorities, pages 470486. Edward Elgar Publishing, 2022. F. Carichon, A. Khandelwal, M. Fauchard, and G. Farnadi. The coming crisis of multi-agent misalignment: AI alignment must be dynamic and social process, 2025. URL https: //arxiv.org/abs/2506.01080. M. Carroll, R. Shah, M. K. Ho, T. Griffiths, S. Seshia, P. Abbeel, and A. Dragan. On the utility of learning about humans for human-AI coordination. Advances in neural information processing systems, 32, 2019. M. Carroll, D. Foote, A. Siththaranjan, S. Russell, and A. Dragan. Ai alignment with changing and influenceable reward functions. arXiv preprint arXiv:2405.17713, 2024. N. Castelo, Z. Katona, P. Li, and M. Sarvary. How AI outperforms humans at creative idea generation. Available at SSRN 4751779, 2024. F. Castillo, O. Castillo, E. Brito, and S. Espinola. Trustworthy decentralized autonomous machines: new paradigm in automation economy, 2025. URL https://arxiv.org/abs/ 2504.15676. P. ƒåerka, J. Grigiene, and G. Sirbikyte. Liability for damages caused by artificial intelligence. Computer law & security review, 31(3):376389, 2015. A. Chan, K. Wei, S. Huang, N. Rajkumar, E. Perrier, S. Lazar, G. K. Hadfield, and M. Anderljung. Infrastructure for AI agents. arXiv preprint arXiv:2501.10114, 2025. F. Chasin, F. Schmolke, and J. Becker. Design principles for digital community currencies. 2020. mitigates hacking in RLHF. arXiv preprint arXiv:2402.07319, 2024b. M. Cheng, S. Yu, C. Lee, P. Khadpe, L. Ibrahim, and D. Jurafsky. Social sycophancy: broader understanding of LLM sycophancy. arXiv preprint arXiv:2505.13995, 2025. Y. Chevaleyre, P. E. Dunne, U. Endriss, J. Lang, M. Lemaitre, N. Maudet, J. Padget, S. Phelps, J. A. Rodr√≠gues-Aguilar, and P. Sousa. Issues in multiagent resource allocation. 2005. S. Chiappa and W. S. Isaac. causal bayesian networks viewpoint on fairness. In IFIP international summer school on privacy and identity management, pages 320. Springer, 2018. Y. Chouinard, J. Ellison, and R. Ridgeway. The sustainable economy. harvard Business review, 89(10):5262, 2011. S. H. Clearwater and J. J. Yeh. Market-based control: paradigm for distributed resource allocation. World Scientific, 1996. E. Collom. Motivations and differential participation in community currency system: The dynamics within local social movement organization 1. In Sociological Forum, volume 26, pages 144168. Wiley Online Library, 2011. E. Collom and J. N. Lasker. Equal time, equal value: Community currencies and time banking in the US. Routledge, 2016. S. Corbett-Davies, J. D. Gaebler, H. Nilforoshan, R. Shroff, and S. Goel. The measure and mismeasure of fairness. Journal of Machine Learning Research, 24(312):1117, 2023. B. Cottier, R. Rahman, L. Fattorini, N. Maslej, T. Besiroglu, and D. Owen. The rising costs of training frontier AI models. arXiv preprint arXiv:2405.21015, 2024. J. Chen, Y. Jiang, J. Lu, and L. Zhang. S-agents: Self-organizing agents in open-ended environments, 2024a. URL https://arxiv.org/ abs/2402.04578. N. T. Courtois, K. T. Gradon, and K. Schmeh. Crypto currency regulation and law enforcement perspectives. arXiv preprint arXiv:2109.01047, 2021. L. Chen, C. Zhu, D. Soselia, J. Chen, T. Zhou, T. Goldstein, H. Huang, M. Shoeybi, and B. Catanzaro. Odin: Disentangled reward R. Cropanzano and M. S. Mitchell. Social exchange theory: An interdisciplinary review. Journal of management, 31(6):874900, 2005. 25 Virtual Agent Economies P. Cruz-Gonzalez, A. W.-J. He, E. P. Lam, I. M. C. Ng, M. W. Li, R. Hou, J. N.-M. Chan, Y. Sahni, N. V. Guasch, T. Miller, et al. Artificial intelligence in mental health care: systematic review of diagnosis, monitoring, and intervention applications. Psychological Medicine, 55:e18, 2025. E. Cui, Y. Cheng, R. She, D. Liu, Z. Liang, M. Guo, T. Li, Q. Wei, W. Xing, and Z. Zhong. Agentdns: root domain naming system for LLM agents, 2025. URL https://arxiv.org/abs/2505. 22368. X. Cui, A. Aparcedo, Y. K. Jang, and S.-N. Lim. On the robustness of large multimodal models against image adversarial attacks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 24625 24634, 2024. P. Danassis. Scalable multi-agent coordination and resource sharing. PhD thesis, EPFL, 2022. N. Daniels. Spheres of justice: defense of pluralism and equality, 1985. M. S. Dave Longley, Dmitri Zagidulin. Did:key, 2025. URL https://w3c-ccg.github.io/ did-key-spec/. M. B. Dias and A. Stentz. Opportunistic optimization for market-based multirobot control. In IEEE/RSJ international conference on intelligent robots and systems, volume 3, pages 2714 2720. IEEE, 2002. R. Dietz, H. Daly, and D. ONeill. Enough is enough: Building sustainable economy in world of finite resources. Routledge, 2013. DIF. Did:ion, 2025. URL https://identity. foundation/ion/. E. H. Diniz, E. S. Siqueira, and E. Van Heck. Taxonomy of digital community currency platforms. Information Technology for Development, 25(1): 6991, 2019. E. H. Diniz, M. H. de Araujo, M. A. Alves, and L. Gonzalez. Design principles for sustainable community currency projects. Sustainability Science, pages 115, 2024. S. R. Dovers and J. W. Handmer. Uncertainty, sustainability and change. Global environmental change, 2(4):262276, 1992. Y. Du, J. Z. Leibo, U. Islam, R. Willis, and P. Sunehag. review of cooperation in multi-agent learning, 2023. URL https://arxiv.org/ abs/2312.05162. E. A. Du√©√±ez-Guzm√°n, R. Comanescu, Y. Mao, K. R. McKee, B. Coppin, S. Sadedin, S. Chiappa, A. S. Vezhnevets, M. A. Bakker, Y. Bachrach, W. A. Isaac, K. Tuyls, and J. Z. Leibo. Perceptual interventions ameliorate statistical discrimination in learning agents. Proceedings of the National Academy of Sciences, 122(25): e2319933121, 2025. R. Dworkin. What is equality? part 2: Equality of resources. In The notion of equality, pages 143205. Routledge, 2018. Y. El Faqir, J. Arroyo, and S. Hassan. An overview of decentralized autonomous organizations on the blockchain. In Proceedings of the 16th international symposium on open collaboration, pages 18, 2020. S. El-Sayed, C. Akbulut, A. McCroskery, G. Keeling, Z. Kenton, Z. Jalan, N. Marchal, A. Manzini, T. Shevlane, S. Vallor, et al. mechanism-based approach to mitigating harms from persuasive generative ai. arXiv preprint arXiv:2404.15058, 2024. S. R. Elliott. Sustainability: an economic perspective. Resources, Conservation and Recycling, 44 (3):263277, 2005. E. Elokda, S. Bolognani, A. Censi, F. D√∂rfler, and E. Frazzoli. self-contained karma economy for the dynamic allocation of common resources. Dynamic Games and Applications, 14 (3):578610, 2024. T. Eloundou, S. Manning, P. Mishkin, and D. Rock. Gpts are gpts: Labor market impact potential of llms. Science, 384(6702):13061308, 2024. A. Etzioni and O. Etzioni. Keeping AI legal. Vand. J. Ent. & Tech. L., 19:133, 2016. 26 Virtual Agent Economies Y. Faqir-Rhazoui, J. Arroyo, and S. Hassan. comparative analysis of the platforms for decentralized autonomous organizations in the ethereum blockchain. Journal of Internet Services and Applications, 12:120, 2021. M. Fare and P. O. Ahmed. Complementary currency systems and their ability to support economic and social changes. Development and Change, 48(5):847872, 2017. B. D. Feinstein and K. Werbach. The impact of cryptocurrency regulation on trading markets. Journal of Financial Regulation, 7(1):4899, 2021. M. Franklin. General purpose artificial intelliICLR 2023, gence systems as group agents. Tiny Papers, 2023. J. Fu, X. Zhao, C. Yao, H. Wang, Q. Han, and Y. Xiao. Reward shaping to mitigate reward hacking in RLHF. arXiv preprint arXiv:2502.18770, 2025. I. Gabriel. Artificial intelligence, values, and alignment. Minds and machines, 30(3):411437, 2020. I. Gabriel and G. Keeling. matter of principle? AI alignment as the fair treatment of claims. Philosophical Studies, pages 123, 2025. I. Gabriel, A. Manzini, G. Keeling, L. A. Hendricks, V. Rieser, H. Iqbal, N. Toma≈°ev, I. Ktena, Z. Kenton, M. Rodriguez, et al. The ethics of advanced AI assistants. arXiv preprint arXiv:2404.16244, 2024. sustainability paradigm? Journal of cleaner production, 143:757768, 2017. L. Georgeson and M. Maslin. Putting the united nations sustainable development goals into practice: review of implementation, monitoring, and finance. Geo: Geography and Environment, 5(1):e00049, 2018. D. A. Gianetto and B. Heydari. Network modularity is essential for evolution of cooperation under uncertainty. Scientific reports, 5(1):9340, 2015. A. Gleave, M. Dennis, C. Wild, N. Kant, S. Levine, and S. Russell. Adversarial policies: Attacking deep reinforcement learning, 2021. URL https://arxiv.org/abs/1905.10615. Google. Announcing the agent2agent protocol (a2a), 2025. S. Gotelaere and L. Paoli. Prevention and control of financial fraud: scoping review. European Journal on Criminal Policy and Research, 31(1): 121, 2025. J. Gottweis, W.-H. Weng, A. Daryin, T. Tu, A. Palepu, P. Sirkovic, A. Myaskovsky, F. Weissenberger, K. Rong, R. Tanno, K. Saab, D. Popovici, J. Blum, F. Zhang, K. Chou, A. Hassidim, B. Gokturk, A. Vahdat, P. Kohli, Y. Matias, A. Carroll, K. Kulkarni, N. Tomasev, Y. Guan, V. Dhillon, E. D. Vaishnav, B. Lee, T. R. D. Costa, J. R. Penad√©s, G. Peltz, Y. Xu, A. Pawlosky, A. Karthikesalingam, and V. Natarajan. Towards an AI co-scientist, 2025. URL https: //arxiv.org/abs/2502.18864. J. Z. Garrod. The real world of the decentralized autonomous society. tripleC: Communication, Capitalism & Critique. Open Access Journal for Global Sustainable Information Society, 14(1): 6277, 2016. E. L. Greebel, K. Moriarty, C. Callaway, and G. Xethalis. Recent key bitcoin and virtual currency regulatory and law enforcement developments. Journal of Investment Compliance, 16 (1):1318, 2015. I. Geffner, E. Karpas, and M. Tennenholtz. When competition helps: Achieving optimal traffic flow with multiple autonomous planners, 2025. URL https://arxiv.org/abs/2508. 07145. M. Geissdoerfer, P. Savaget, N. M. Bocken, and E. J. Hultink. The circular economya new J. Gu, X. Jiang, Z. Shi, H. Tan, X. Zhai, C. Xu, W. Li, Y. Shen, S. Ma, H. Liu, et al. survey on llmas-a-judge. arXiv preprint arXiv:2411.15594, 2024. T. Guo, X. Chen, Y. Wang, R. Chang, S. Pei, N. V. Chawla, O. Wiest, and X. Zhang. Large language model based multi-agents: survey 27 Virtual Agent Economies of progress and challenges. arXiv preprint arXiv:2402.01680, 2024. D. Gupta, Y. Chandak, S. Jordan, P. S. Thomas, and B. da Silva. Behavior alignment via reward function optimization. Advances in Neural Information Processing Systems, 36:52759 52791, 2023. G. Hadfield, M.-F. T. Cu√©llar, and T. OReilly. Its time to create national registry for large ai models. 2023. G. K. Hadfield and A. Koh. An economy of ai agents. arXiv preprint arXiv:2509.01063, 2025. M. Hajiesmaili, S. Ren, R. K. Sitaraman, and A. Wierman. Towards environmentally equitable ai. arXiv preprint arXiv:2412.16539, 2024. D. Halpern and N. Shah. Fair and efficient resource allocation with partial information. arXiv preprint arXiv:2105.10064, 2021. L. Hammond, A. Chan, J. Clifton, J. HoelscherObermaier, A. Khan, E. McLean, C. Smith, W. Barfuss, J. Foerster, T. Gavenƒçiak, T. A. Han, E. Hughes, V. Kova≈ô√≠k, J. Kulveit, J. Z. Leibo, C. Oesterheld, C. S. de Witt, N. Shah, M. Wellman, P. Bova, T. Cimpeanu, C. Ezell, Q. Feuillade-Montixi, M. Franklin, E. Kran, I. Krawczuk, M. Lamparth, N. Lauffer, A. Meinke, S. Motwani, A. Reuel, V. Conitzer, M. Dennis, I. Gabriel, A. Gleave, G. Hadfield, N. Haghtalab, A. Kasirzadeh, S. Krier, K. Larson, J. Lehman, D. C. Parkes, G. Piliouras, and I. Rahwan. Multi-agent risks from advanced ai, 2025. URL https://arxiv.org/abs/2502. 14143. J. Hao, H.-f. Leung, J. Hao, and H.-f. Leung. Fairness in cooperative multiagent systems. Interactions in Multiagent Systems: Fairness, Social Optimality and Individual Rationality, pages 27 70, 2016. H. Harland, R. Dazeley, P. Vamplew, H. Senaratne, B. Nakisa, and F. Cruz. Adaptive alignment: Dynamic preference adjustments via multiobjective reinforcement learning for pluralistic ai. arXiv preprint arXiv:2410.23630, 2024. M. Hayenhjelm. What is fair distribution of risk? 2012. J. Henrich, M. Chudek, and R. Boyd. The big man mechanism: how prestige fosters cooperation and creates prosocial leaders. Philosophical Transactions of the Royal Society B: Biological Sciences, 370(1683):20150013, 2015. U. Hertz, R. K√∂ster, M. A. Janssen, and J. Z. Leibo. Beyond the matrix: Experimental approaches to studying cognitive agents in social-ecological systems. Cognition, 254:105993, 2025. I. Hettiarachchi. Exploring generative AI agents: Architecture, applications, and challenges. Journal of Artificial Intelligence General science (JAIGS) ISSN: 3006-4023, 8(1):105127, 2025. H. Hosseini, S. Khanna, and R. Singh. Matching markets meet llms: Algorithmic reasoning with ranked preferences, 2025. URL https: //arxiv.org/abs/2506.04478. D. E. Hostallero, D. Kim, S. Moon, K. Son, W. J. Kang, and Y. Yi. Inducing cooperation through reward reshaping based on peer evaluations in deep multi-agent reinforcement learning. In Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems, pages 520528, 2020. T. W. House. Americas ai action plan, https://whitehouse."
        },
        {
            "title": "URL",
            "content": "2025. gov/wp-content/uploads/2025/07/ Americas-AI-Action-Plan.pdf. House of Commons Committee of Public Accounts. Use of AI in government. Report, House of Commons, 2025. HC (specify number if known). C. L. Hardy and M. Van Vugt. Nice guys finish first: The competitive altruism hypothesis. Personality and Social Psychology Bulletin, 32(10): 14021413, 2006. M. Howlett. Avoiding panglossian policy science: The need to deal with the darkside of policy-maker and policy-taker behaviour. Public Integrity, 24(3):306318, 2022. 28 Virtual Agent Economies Y.-Y. Hsieh, J.-P. Vergne, P. Anderson, K. Lakhani, and M. Reitzig. Bitcoin and the rise of decentralized autonomous organizations. Journal of Organization Design, 7(1):116, 2018. A. Z. Jacobs and H. Wallach. Measurement and fairness. In Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pages 375385, 2021. M. Hu, Y. Mu, X. Yu, M. Ding, S. Wu, W. Shao, Q. Chen, B. Wang, Y. Qiao, and P. Luo. Treeplanner: Efficient close-loop task planning with large language models. arXiv preprint arXiv:2310.08582, 2023. W. Hua, O. Liu, L. Li, A. Amayuelas, J. Chen, L. Jiang, M. Jin, L. Fan, F. Sun, W. Wang, et al. Game-theoretic llm: Agent workflow for negotiation games. arXiv preprint arXiv:2411.05990, 2024. L. Huang, W. Yu, W. Ma, W. Zhong, Z. Feng, H. Wang, Q. Chen, W. Peng, X. Feng, B. Qin, et al. survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems, 43(2):155, 2025. X. Huang, W. Liu, X. Chen, X. Wang, H. Wang, D. Lian, Y. Wang, R. Tang, and E. Chen. Understanding the planning of LLM agents: survey. arXiv preprint arXiv:2402.02716, 2024. E. Hughes, T. O. Zhu, M. J. Chadwick, R. Koster, A. G. Casta√±eda, C. Beattie, T. Graepel, M. M. Botvinick, and J. Z. Leibo. Modeling human reputation-seeking behavior in spatiotemporally complex public good provision game. arXiv preprint arXiv:2506.06032, 2025. S. D. Hughes. Cryptocurrency regulations and enforcement in the us. W. St. UL Rev., 45:1, 2017. J. Jacobs. Ai labor displacement and the limits of worker retraining. 2025. M. Jaderberg, W. M. Czarnecki, I. Dunning, L. Marris, G. Lever, A. G. Castaneda, C. Beattie, N. C. Rabinowitz, A. S. Morcos, A. Ruderman, et al. Human-level performance in 3d multiplayer games with population-based reinforcement learning. Science, 364(6443):859865, 2019. V. Jannelli, S. Schoepf, M. Bickel, T. Netland, and A. Brintrup. Agentic llms in the supply chain: Towards autonomous multi-agent consensusarXiv preprint arXiv:2411.10184, seeking. 2024. M. Jeyasheela Rakkini and K. Geetha. Blockchainenabled microfinance model with decentralized autonomous organizations. In Computer Networks and Inventive Communication Technologies: Proceedings of Third ICCNCT 2020, pages 417430. Springer, 2021. J. Ji, T. Qiu, B. Chen, B. Zhang, H. Lou, K. Wang, Y. Duan, Z. He, J. Zhou, Z. Zhang, et al. Ai alignment: comprehensive survey. arXiv preprint arXiv:2310.19852, 2023. J. Ji, Y. Li, H. Liu, Z. Du, Z. Wei, W. Shen, Q. Qi, and Y. Lin. Srap-agent: Simulating and optimizing scarce resource allocation policy with llm-based agent, 2024. URL https://arxiv. org/abs/2410.14152. IMDA. in trusted ecosystem, 2025. Singapore launches new tools to help businesses protect data and deploy URL ai https://www.imda.gov.sg/resources/ press-releases-factsheets-and-speeches/ press-releases/2025/ singapore-launches-new-tools-to-help-businesses-protect-data-and-deploy-ai-in-a-trusted-ecosystem. J. Jiang and Z. Lu. Learning fairness in multiagent systems. Advances in Neural Information Processing Systems, 32, 2019. Y.-H. Jiang, R. Li, Y. Zhou, C. Qi, H. Hu, Y. Wei, B. Jiang, and Y. Wu. Ai agent for education: von neumann multi-agent system framework. arXiv preprint arXiv:2501.00083, 2024. K. Iyer and M. Huhns. Multiagent negotiation for fair and unbiased resource allocation. In OTM Confederated International Conferences\" On the Move to Meaningful Internet Systems\", pages 453465. Springer, 2005. R. Jin, Z. Zhang, M. Wang, and L. Cong. Stella: Self-evolving LLM agent for biomedical research, 2025. URL https://arxiv.org/ abs/2507.02004. 29 Virtual Agent Economies M. B. Johanson, E. Hughes, F. Timbers, and J. Z. Leibo. Emergent bartering behaviour in multiagent reinforcement learning. arXiv preprint arXiv:2205.06760, 2022. I. Kash, A. D. Procaccia, and N. Shah. No agent left behind: Dynamic fair division of multiple resources. Journal of Artificial Intelligence Research, 51:579603, 2014. M. Kohn. Financial institutions and markets. OUP Catalogue, 2003. R. Koster, J. Balaguer, A. Tacchetti, A. Weinstein, T. Zhu, O. Hauser, D. Williams, L. CampbellGillingham, P. Thacker, M. Botvinick, et al. Human-centred mechanism design with democratic ai. Nature Human Behaviour, 6(10): 13981407, 2022. A. Kasirzadeh and I. Gabriel. Characterizing AI agents for alignment and governance, 2025. URL https://arxiv.org/abs/2504. 21848. M. Khanov, J. Burapacheep, and Y. Li. Args: Alignment as reward-guided search. arXiv preprint arXiv:2402.01694, 2024. A. Kharrazi, Y. Yu, A. Jacob, N. Vora, and B. D. Fath. Redundancy, diversity, and modularity in network resilience: applications for international trade and implications for public policy. Current research in environmental sustainability, 2:100006, 2020. N. Kichiji and M. Nishibe. Network analyses of the circulation flow of community currency. Evolutionary and Institutional Economics Review, 4: 267300, 2008. J. Kirchherr, K. Hartley, and A. Tukker. Missions and mission-oriented innovation policy for sustainability: review and critical reflection. Environmental Innovation and Societal Transitions, 47:100721, 2023. A. Kirilenko, A. S. Kyle, M. Samadi, and T. Tuzun. The flash crash: High-frequency trading in an electronic market. The Journal of Finance, 72 (3):967998, 2017. H. R. Kirk, B. Vidgen, P. R√∂ttger, and S. A. Hale. Personalisation within bounds: risk taxonomy and policy framework for the alignment of large language models with personalised feedback. arXiv preprint arXiv:2303.05453, 2023. H. R. Kirk, B. Vidgen, P. R√∂ttger, and S. A. Hale. The benefits, risks and bounds of personalizing the alignment of large language models to individuals. Nature Machine Intelligence, 6(4): 383392, 2024. R. K√∂ster, E. A. Du√©√±ez-Guzm√°n, W. A. Cunningham, and J. Z. Leibo. Tabula rasa agents display emergent in-group behavior. Proceedings of the National Academy of Sciences, 122(25): e2319947121, 2025. J. Kulveit, R. Douglas, N. Ammann, D. Turan, D. Krueger, and D. Duvenaud. Gradual disempowerment: Systemic existential risks from incremental AI development. arXiv preprint arXiv:2501.16946, 2025. A. Kumar and W. Yeoh. Decaf: Learning to be fair in multi-agent resource allocation. arXiv preprint arXiv:2502.04281, 2025. K. Kyriakou and J. Otterbacher. In humans, we trust: Multidisciplinary perspectives on the requirements for human oversight in algorithmic processes. Discover Artificial Intelligence, 3(1): 44, 2023. J. Lee and F. Lheureux. regulatory framework for cryptocurrency. European Business Law Review, 31(3), 2020. S. Lee. Fairness, stability and optimality of adaptive multiagent systems: Interaction through resource sharing. IEEE transactions on automation science and engineering, 7(3):427439, 2009. J. Lehman. Machine love, 2023. URL https: //arxiv.org/abs/2302.09248. J. Z. Leibo, E. Hughes, M. Lanctot, and T. Graepel. Autocurricula and the emergence of innovation from social interaction: manifesto for multi-agent intelligence research. arXiv preprint arXiv:1903.00742, 2019. J. Z. Leibo, A. S. Vezhnevets, M. Diaz, J. P. Agapiou, W. A. Cunningham, P. Sunehag, J. Haas, 30 Virtual Agent Economies R. Koster, E. A. Du√©√±ez-Guzm√°n, W. S. Isaac, G. Piliouras, S. M. Bileschi, I. Rahwan, and S. Osindero. theory of appropriateness with applications to generative artificial intelligence. arXiv preprint arXiv:2412.19010, 2024. URL https://doi.org/10.48550/ arXiv.2412.19010. J. Z. Leibo, A. S. Vezhnevets, W. A. Cunningham, S. Krier, M. Diaz, and S. Osindero. Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt. arXiv preprint arXiv:2505.05197, 2025. J. Leike, D. Krueger, T. Everitt, M. Martic, V. Maini, and S. Legg. Scalable agent alignment via reward modeling: research direction. arXiv preprint arXiv:1811.07871, 2018. M. Li and J. D. Lee. Modeling goal alignment in human-ai teaming: dynamic game theory approach. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, volume 66, pages 15381542. SAGE Publications Sage CA: Los Angeles, CA, 2022. P. Li, J. Yang, A. Wierman, and S. Ren. Towards environmentally equitable AI via geographical load balancing. In Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems, pages 291307, 2024a. S. Li, T. Sun, Q. Cheng, and X. Qiu. Agent alignment in evolving social norms. arXiv preprint arXiv:2401.04620, 2024b. Y. Li, S. Zhang, J. Sun, W. Zhang, Y. Du, Y. Wen, X. Wang, and W. Pan. Tackling cooperative incompatibility for zero-shot human-ai coordination. Journal of Artificial Intelligence Research, 80:11391185, 2024c. C.-J. Liang, V. R. Kamat, and C. C. Menassa. Teaching robots to perform quasi-repetitive construction tasks through human demonstration. Automation in Construction, 120:103370, 2020. C. List. Group agency and artificial intelligence. Philosophy & technology, 34(4):12131242, 2021. C. List and P. Pettit. Group agency: The possibility, design, and status of corporate agents. Oxford University Press, 2011. B. Liu, Y. Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone. Llm+ p: Empowering large language models with optimal planning proficiency. arXiv preprint arXiv:2304.11477, 2023a. J. Liu, K. Wang, Y. Chen, X. Peng, Z. Chen, L. Zhang, and Y. Lou. Large language modelbased agents for software engineering: survey. arXiv preprint arXiv:2409.02977, 2024a. T. Liu, W. Xiong, J. Ren, L. Chen, J. Wu, R. Joshi, Y. Gao, J. Shen, Z. Qin, T. Yu, et al. Rrm: Robust reward model training mitigates reward hacking. arXiv preprint arXiv:2409.13156, 2024b. X. Liu, H. Yu, H. Zhang, Y. Xu, X. Lei, H. Lai, Y. Gu, H. Ding, K. Men, K. Yang, S. Zhang, X. Deng, A. Zeng, Z. Du, C. Zhang, S. Shen, T. Zhang, Y. Su, H. Sun, M. Huang, Y. Dong, and J. Tang. Agentbench: Evaluating llms as agents, 2023b. URL https://arxiv.org/ abs/2308.03688. Y. Liu, X. Yi, X. Chen, J. Yao, J. Yi, D. Zan, Z. Liu, X. Xie, and T.-Y. Ho. Elephant in the room: Unveiling the impact of reward model quality in alignment. arXiv preprint arXiv:2409.19024, 2024c. A. S. Luccioni and A. Hernandez-Garcia. Counting carbon: survey of factors influencing the emissions of machine learning. arXiv preprint arXiv:2302.08476, 2023. A. S. Luccioni, E. Strubell, and K. Crawford. From efficiency gains to rebound effects: The jevons paradox in ais polarproblem of ized environmental debate. arXiv preprint arXiv:2501.16548, 2025. S. Luccioni, Y. Jernite, and E. Strubell. Power hungry processing: Watts driving the cost of AI deployment? In Proceedings of the 2024 ACM conference on fairness, accountability, and transparency, pages 8599, 2024. 31 Virtual Agent Economies M. Lujak, A. Fern√°ndez, H. Billhardt, S. Ossowski, J. Arias, and A. L√≥pez S√°nchez. On valuealigned cooperative multi-agent task allocation. In International Workshop on Value Engineering in AI, pages 197216. Springer, 2023. S. Lythreatis, S. K. Singh, and A.-N. El-Kassar. The digital divide: review and future research agenda. Technological Forecasting and Social Change, 175:121359, 2022. M. Magni and F. Milella. Conversational agents in the legal domain: systematic review. In Advances in Information and Communication: Proceedings of the 2025 Future of Information and Communication Conference (FICC), Volume 3, volume 1285, page 183. Springer Nature, 2025. M. Marcoux and D. Lusseau. Network modularity promotes cooperation. Journal of Theoretical Biology, 324:103108, 2013. C. E. Mattsson, T. Criscione, and F. W. Takes. Circulation of digital community currency. Scientific Reports, 13(1):5864, 2023. C. Mazzocca, A. Acar, S. Uluagac, R. Montanari, P. Bellavista, and M. Conti. survey on decentralized identifiers and verifiable credentials. IEEE Communications Surveys & Tutorials, 2025. M. Mazzucato. Building the entrepreneurial state: new framework for envisioning and evaluating mission-oriented public sector. Levy Economics Institute of Bard College Working Paper, (824), 2015. M. Mazzucato. Mission-oriented innovation policies: challenges and opportunities. Industrial and corporate change, 27(5):803815, 2018. M. Mazzucato. Financing the sustainable development goals through mission-oriented development banks. 2023. R. McCormick. Legal risk in the financial markets. Oxford University Press, USA, 2010. A. J. Menkveld and B. Z. Yueshen. The flash crash: cautionary tale about highly fragmented markets. Management Science, 65(10):44704488, 2019. G. E. Metcalf. Market-based policy options to control us greenhouse gas emissions. Journal of Economic perspectives, 23(2):527, 2009. A. Michel and M. Hudon. Community currencies and sustainable development: systematic review. Ecological economics, 116:160171, 2015. Microsoft. Unleashing the power of model context protocol (mcp): game-changer in AI integration, 2025. A. Mishra. Ai alignment and social choice: Fundamental limitations and policy implications. arXiv preprint arXiv:2310.16048, 2023. J. Mokyr, C. Vickers, and N. L. Ziebarth. The history of technological anxiety and the future of economic growth: Is this time different? Journal of economic perspectives, 29(3):3150, 2015. N. Moloney. EU securities and financial markets regulation. Oxford University Press, 2023. C. Mu, H. Guo, Y. Chen, C. Shen, D. Hu, S. Hu, and Z. Wang. Multi-agent, humanagent and beyond: survey on cooperation in social dilemmas. Neurocomputing, 610:128514, 2024. R. Ngo, L. Chan, and S. Mindermann. The alignment problem from deep learning perspective. arXiv preprint arXiv:2209.00626, 2022. O. F. Norheim. Ethical priority setting for universal health coverage: challenges in deciding upon fair distribution of health services. BMC medicine, 14:14, 2016. E. Ostrom. Governing the commons: The evolution of institutions for collective action. Cambridge university press, 1990. D. Paccagnan, R. Chandan, and J. R. Marden. Utility and mechanism design in multi-agent systems: An overview. Annual Reviews in Control, 53:315328, 2022. E. A. Page. Climatic justice and the fair distribution of atmospheric burdens: conjunctive account. The monist, 94(3):412432, 2011. 32 Virtual Agent Economies A. Pan, K. Bhatia, and J. Steinhardt. The effects of reward misspecification: Mapping and mitigating misaligned models. arXiv preprint arXiv:2201.03544, 2022. X. Pan, D. Gao, Y. Xie, Y. Chen, Z. Wei, Y. Li, B. Ding, J.-R. Wen, and J. Zhou. Very largescale multi-agent simulation in agentscope, 2024. URL https://arxiv.org/abs/2407. 17789. G. Papoudakis, F. Christianos, A. Rahman, and S. V. Albrecht. Dealing with non-stationarity in multi-agent deep reinforcement learning. arXiv preprint arXiv:1906.04737, 2019. M. Park, E. Leahey, and R. J. Funk. Papers and patents are becoming less disruptive over time. Nature, 613(7942):138144, 2023. D. Patel, G. Raut, S. N. Cheetirala, B. Glicksberg, M. A. Levin, G. Nadkarni, R. Freeman, E. Klang, and P. Timsina. Ai agents in modern healthcare: From foundation to pioneera comprehensive review and implementation roadmap for impact and integration in clinical settings. 2025. L. Pedersen, D. Kortenkamp, D. Wettergreen, and I. Nourbakhsh. survey of space robotics. In Proceeding of the 7th International Symposium on Artificial Intelligence, Robotics and Automation in Space, number AM-11. European Space Agency, 2003. J. Perolat, J. Z. Leibo, V. Zambaldi, C. Beattie, K. Tuyls, and T. Graepel. multi-agent reinforcement learning model of common-pool resource appropriation. Advances in neural information processing systems, 30, 2017. G. Piatti, Z. Jin, M. Kleiman-Weiner, B. Sch√∂lkopf, M. Sachan, and R. Mihalcea. Cooperate or collapse: Emergence of sustainable cooperation in society of LLM agents. Advances in Neural Information Processing Systems, 37:111715 111759, 2024. C. Qian, Z. Xie, Y. Wang, W. Liu, Y. Dang, Z. Du, W. Chen, C. Yang, Z. Liu, and M. Sun. Scaling large-language-model-based multi-agent collaboration. arXiv preprint arXiv:2406.07155, 2024. R. Raab. Machine Learning and the Multiagent Alignment Problem. University of California, Santa Cruz, 2024. R. RƒÉdulescu, P. Mannion, D. M. Roijers, and A. Now√©. Multi-objective multi-agent decision making: utility-based analysis and survey. Autonomous Agents and Multi-Agent Systems, 34 (1):10, 2020. R. Raileanu, E. Denton, A. Szlam, and R. Fergus. Modeling others using oneself in multi-agent reinforcement learning. In International conference on machine learning, pages 42574266. PMLR, 2018. V. B. Ramirez. Chatgpt is changing the words we use in conversation, 2025. URL https://www. scientificamerican.com/article/ chatgpt-is-changing-the-words-we-use-in-conversation/. S. Rasal and E. Hauer. Navigating complexity: Orchestrated problem solving with multi-agent llms. arXiv preprint arXiv:2402.16713, 2024. S. Ren, W. Fu, X. Zou, C. Shen, Y. Cai, C. Chu, Z. Wang, and S. Hu. Beyond the tragedy of the commons: Building reputation system for generative multi-agent systems, 2025. URL https://arxiv.org/abs/2505.05029. W. Ren, R. W. Beard, and E. M. Atkins. survey of consensus problems in multi-agent coordination. In Proceedings of the 2005, American Control Conference, 2005., pages 18591864. IEEE, 2005. J. Ruan, Y. Chen, B. Zhang, Z. Xu, T. Bao, H. Mao, Z. Li, X. Zeng, R. Zhao, et al. Tptu: Task planning and tool usage of large language modelbased AI agents. In NeurIPS 2023 Foundation Models for Decision Making Workshop, 2023. K. Saab, J. Freyberg, C. Park, T. Strother, Y. Cheng, W.-H. Weng, D. G. T. Barrett, D. Stutz, N. Tomasev, A. Palepu, V. Li√©vin, Y. Sharma, R. Ruparel, A. Ahmed, E. Vedadi, K. Kanada, C. Hughes, Y. Liu, G. Brown, Y. Gao, S. Li, S. S. Mahdavi, J. Manyika, K. Chou, Y. Matias, A. Hassidim, D. R. Webster, P. Kohli, S. M. A. Eslami, J. Barral, A. Rodman, V. Natarajan, M. Schaekermann, 33 Virtual Agent Economies T. Tu, A. Karthikesalingam, and R. Tanno. Advancing conversational diagnostic AI with multimodal reasoning, 2025. URL https://arxiv. org/abs/2505.04653. P. J. Sager, B. Meyer, P. Yan, R. von WartburgKottler, L. Etaiwi, A. Enayati, G. Nobel, A. Abdulkadir, B. F. Grewe, and T. Stadelmann. Ai agents for computer use: review of instruction-based computer control, gui automation, and operator assistants. arXiv preprint arXiv:2501.16150, 2025. J. M. Sanabria and P. A. Vecino. Beyond the sum: Unlocking AI agents potential through market forces, 2025. URL https://arxiv. org/abs/2501.10388. M. J. Sandel. What money cant buy: the moral limits of markets. Brasenose College, Oxford, 1998. E. O. Sanz. Community currency (ccs) in spain: An empirical study of their social effects. Ecological Economics, 121:2027, 2016. G. Sastry, L. Heim, H. Belfield, M. Anderljung, M. Brundage, J. Hazell, C. OKeefe, G. K. Hadfield, R. Ngo, K. Pilz, et al. Computing power and the governance of artificial intelligence. arXiv preprint arXiv:2402.08797, 2024. D. Satz. Why some things should not be for sale: The moral limits of markets. Oxford University Press, 2010. M. Savona and T. Ciarli. Structural changes and sustainability. selected review of the empirical evidence. Ecological economics, 159:244260, 2019. B. Schneier. Reimagining democracy. Common Knowledge, 30(3):354358, 2024. A. Schuldt. Multiagent coordination enabling autonomous logistics. KI-K√ºnstliche Intelligenz, 26:9194, 2012. J. A. Schumpeter. Capitalism, socialism and democracy. Harper and Brothers, 1942. S. L. Schwarcz. Regulating complexity in financial markets. Wash. UL Rev., 87:211, 2009. J. Sedlmeir, R. Smethurst, A. Rieger, and G. Fridgen. Digital identities and verifiable credentials. Business & Information Systems Engineering, 63 (5):603613, 2021. G. Seyfang. Sustainable consumption, the new economics and community currencies: Developing new institutions for environmental governance. Regional Studies, 40(7):781791, 2006. G. Seyfang and N. Longhurst. Growing green money? mapping community currencies for sustainable development. Ecological Economics, 86:6577, 2013. R. Shah, A. Irpan, A. M. Turner, A. Wang, A. Conmy, D. Lindner, J. Brown-Cohen, L. Ho, N. Nanda, R. A. Popa, et al. An approach to technical agi safety and security. arXiv preprint arXiv:2504.01849, 2025. M. Sharma, M. Tong, T. Korbak, D. Duvenaud, A. Askell, S. R. Bowman, N. Cheng, E. Durmus, Z. Hatfield-Dodds, S. R. Johnston, et al. Towards understanding sycophancy in language arXiv preprint arXiv:2310.13548, models. 2023. T. C. Schelling. Hockey helmets, concealed weapons, and daylight saving: study of binary choices with externalities. Journal of Conflict resolution, 17(3):381428, 1973. C. Schill, J. M. Anderies, T. Lindahl, C. Folke, S. Polasky, J. C. C√°rdenas, A.-S. Cr√©pin, M. A. Janssen, J. Norberg, and M. Schl√ºter. more dynamic understanding of human behaviour for the anthropocene. Nature Sustainability, 2 (12):10751082, 2019. Y. Shavit, S. Agarwal, M. Brundage, S. Adler, C. OKeefe, R. Campbell, T. Lee, P. Mishkin, T. Eloundou, A. Hickey, et al. Practices for governing agentic ai systems. Research Paper, OpenAI, 2023. E. Shayegani, M. A. A. Mamun, Y. Fu, P. Zaree, Y. Dong, and N. Abu-Ghazaleh. Survey of vulnerabilities in large language models revealed by adversarial attacks. arXiv preprint arXiv:2310.10844, 2023. 34 Virtual Agent Economies L. Shekhtman and E. Waisbard. Engravechain: Tamper-proof distributed log system. In Proceedings of the 2nd Workshop on Blockchainenabled Networked Sensor, pages 814, 2019. D. Siddarth, S. Ivliev, S. Siri, and P. Berman. Who watches the watchmen? review of subjective approaches for sybil-resistance in proof of personhood protocols. Frontiers in Blockchain, 3: 590171, 2020. N. Singh, S. Lane, T. Yu, J. Lu, A. Ramos, H. Cui, and H. Zhao. generalized platform for artificial intelligence-powered autonomous protein engineering. bioRxiv, pages 202502, 2025. A. C. O. Siqueira, B. Honig, S. Mariano, and J. Moraes. commons strategy for promoting entrepreneurship and social capital: Implications for community currencies, cryptocurrencies, and value exchange. Journal of Business Ethics, 166(4):711726, 2020. J. Skalse, N. Howe, D. Krasheninnikov, and D. Krueger. Defining and characterizing reward gaming. Advances in Neural Information Processing Systems, 35:94609471, 2022. C. Smith, M. Abdulhai, M. Diaz, M. Tesic, R. Trivedi, A. S. Vezhnevets, L. Hammond, J. Clifton, M. Chang, E. A. Du√©√±ez-Guzm√°n, J. P. Agapiou, J. Matyas, and J. Z. Leibo. Evaluating generalization capabilities of LLM-based agents in mixed-motive scenarios using concordia. Advances in neural information processing systems, 38, 2025. M. Snyder and W. B. Swann Jr. Behavioral confirmation in social interaction: From social perception to social reality. Journal of experimental social psychology, 14(2):148162, 1978. P. S√∂derholm. The green economy transition: the challenges of technological change for sustainability. Sustainable Earth, 3(1):6, 2020. R. N. Stavins. Market-based environmental policies. In Public policies for environmental protection, pages 3176. Routledge, 2010. R. Stevens, N. Moray, and J. Bruneel. The social and economic mission of social enterprises: Dimensions, measurement, validation, and relation. Entrepreneurship theory and practice, 39 (5):10511082, 2015. A. Stooke, A. Mahajan, C. Barros, C. Deck, J. Bauer, J. Sygnowski, M. Trebacz, M. Jaderberg, M. Mathieu, et al. Open-ended learning leads to generally capable agents. arXiv preprint arXiv:2107.12808, 2021. D. Strouse, K. McKee, M. Botvinick, E. Hughes, and R. Everett. Collaborating with humans without human data. Advances in neural information processing systems, 34:1450214515, 2021. E. Strubell, A. Ganesh, and A. McCallum. Energy and policy considerations for modern deep learning research. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 1369313696, 2020. N. A. Tarashev, C. E. Borio, and K. Tsatsaronis. The systemic importance of financial institutions. BIS Quarterly Review, September, 2009. J. A. Tatom. Financial Market Regulation Legislation and Implications. Springer, 2011. W. team. Worldcoin, 2025. URL https:// world.org/. W. Thomson. Fair allocation rules. In Handbook of social choice and welfare, volume 2, pages 393506. Elsevier, 2011. J. Trevelyan, W. R. Hamel, and S.-C. Kang. In Robotics in hazardous applications. Springer handbook of robotics, pages 1521 1548. Springer, 2016. T. Tu, M. Schaekermann, A. Palepu, K. Saab, J. Freyberg, R. Tanno, A. Wang, B. Li, M. Amin, Y. Cheng, et al. Towards conversational diagnostic artificial intelligence. Nature, pages 19, 2025. A. Tukker and P. Ekins. Concepts fostering resource efficiency: trade-off between ambitions and viability. Ecological Economics, 155: 3645, 2019. 35 Virtual Agent Economies T. K. Vashishth, V. Sharma, K. K. Sharma, B. Kumar, S. Chaudhary, and R. Panwar. Intelligent resource allocation and optimization for industrial robotics using AI and blockchain. In AI and blockchain applications in industrial robotics, pages 82110. IGI Global Scientific Publishing, 2024. E. Vedadi, D. Barrett, N. Harris, E. Wulczyn, S. Reddy, R. Ruparel, M. Schaekermann, T. Strother, R. Tanno, Y. Sharma, J. Lee, C. Hughes, D. Slack, A. Palepu, J. Freyberg, K. Saab, V. Li√©vin, W.-H. Weng, T. Tu, Y. Liu, N. Tomasev, K. Kulkarni, S. S. Mahdavi, K. Guu, J. Barral, D. R. Webster, J. Manyika, A. Hassidim, K. Chou, Y. Matias, P. Kohli, A. Rodman, V. Natarajan, A. Karthikesalingam, and D. Stutz. Towards physician-centered oversight of conversational diagnostic ai, 2025. URL https://arxiv.org/abs/2507.15743. O. Vinyals, I. Babuschkin, W. M. Czarnecki, M. Mathieu, A. Dudzik, J. Chung, D. H. Choi, R. Powell, T. Ewalds, P. Georgiev, et al. Grandmaster level in starcraft ii using multi-agent reinforcement learning. nature, 575(7782): 350354, 2019. T. T. Wang, A. Gleave, T. Tseng, K. Pelrine, N. Belrose, J. Miller, M. D. Dennis, Y. Duan, V. Pogrebniak, S. Levine, et al. Adversarial policies beat superhuman go AIs. In International Conference on Machine Learning, pages 3565535739. PMLR, 2023a. Z. Wang, S. Cai, G. Chen, A. Liu, X. S. Ma, and Y. Liang. Describe, explain, plan and select: interactive planning with llms enables openworld multi-task agents. Advances in Neural Information Processing Systems, 36:3415334189, 2023b. D. M. Wegner. Transactive memory: contemporary analysis of the group mind. In Theories of group behavior, pages 185208. Springer, 1987. D. M. Wegner and A. F. Ward. The internet has become the external hard drive for our memories. Scientific American, 309(6):5861, 2013. N. J. Wijngaards, B. J. Overeinder, M. van Steen, and F. M. Brazier. Supporting internet-scale multi-agent systems. Data & Knowledge Engineering, 41(2-3):229245, 2002. T. A. Vuorenmaa and L. Wang. An agent-based model of the flash crash of may 6, 2010, with policy implications. Available at SSRN 2336772, 2014. C. H. Wu, J. Y. Koh, R. Salakhutdinov, D. Fried, and A. Raghunathan. Adversarial attacks on multimodal agents. arXiv e-prints, pages arXiv 2406, 2024a. M. Walzer. Spheres of justice: defense of pluralism and equality. Basic books, 2008. C. Wang, Z. Zhao, Y. Jiang, Z. Chen, C. Zhu, Y. Chen, J. Liu, L. Zhang, X. Fan, H. Ma, et al. Beyond reward hacking: Causal rewards for large language model alignment. arXiv preprint arXiv:2501.09620, 2025. Q. Wang, H. Gao, F. Alsaadi, and T. Hayat. An overview of consensus problems in constrained multi-agent coordination. Systems Science & Control Engineering: An Open Access Journal, 2 (1):275284, 2014. T. T. Wang, A. Gleave, N. Belrose, T. Tseng, M. D. Dennis, Y. Duan, V. Pogrebniak, J. Miller, S. Levine, and S. Russell. Adversarial policies beat professional-level go ais. In Deep Reinforcement Learning Workshop NeurIPS 2022, 2022. C.-J. Wu, R. Raghavendra, U. Gupta, B. Acun, N. Ardalani, K. Maeng, G. Chang, F. Aga, J. Huang, C. Bai, et al. Sustainable ai: Environmental implications, challenges and opportunities. Proceedings of Machine Learning and Systems, 4:795813, 2022. J. Wu, D. Balliet, and P. A. Van Lange. Reputation, gossip, and human cooperation. Social and Personality Psychology Compass, 10(6):350364, 2016. M. Wu, Z. Wang, J. Wang, Z. Dong, J. Yang, Q. Li, T. Huang, L. Zhao, M. Li, F. Wang, C. Fan, and H. Chen. An ai-native experimental laboratory for autonomous biomolecular engineering, 2025. URL https://arxiv.org/abs/2507. 02379. 36 Virtual Agent Economies Y. Wu, Z. Sun, S. Li, S. Welleck, and Y. Yang. Inference scaling laws: An empirical analysis of compute-optimal inference for problemsolving with language models. arXiv preprint arXiv:2408.00724, 2024b. Y. Yao, J. Duan, K. Xu, Y. Cai, Z. Sun, and Y. Zhang. survey on large language model (llm) security and privacy: The good, the bad, and the ugly. High-Confidence Computing, page 100211, 2024. Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin, E. Zhou, et al. The rise and potential of large language model based agents: survey. Science China Information Sciences, 68(2):121101, 2025. L. Xu, S. Almahri, S. Mak, and A. Brintrup. Multiagent systems and foundation models enable autonomous supply chains: Opportunities and challenges. IFAC-PapersOnLine, 58(19):795 800, 2024a. L. Xu, S. Mak, M. Minaricova, and A. Brintrup. On implementing autonomous supply chains: multi-agent system approach. Computers in Industry, 161:104120, 2024b. D. Xue. Strategies for mitigating the global energy and carbon impact of artificial intelligence. United Nations SDGs, pages 202305, 2023. X. Yan, J. Guo, X. Lou, J. Wang, H. Zhang, and Y. Du. An efficient end-to-end training approach for zero-shot human-ai coordination. Advances in Neural Information Processing Systems, 36:26362658, 2023. K. Yang and C. Zhai. Ten principles of AI agent economics, 2025. URL https://arxiv.org/ abs/2505.20273. R. Yang, X. Pan, F. Luo, S. Qiu, H. Zhong, D. Yu, and J. Chen. Rewards-in-context: Multiobjective alignment of foundation models with dynamic preference adjustment. arXiv preprint arXiv:2402.10207, 2024a. Y. Yang, Y. Wen, J. Wang, and W. Zhang. Agent exchange: Shaping the future of AI agent economics, 2025. URL https://arxiv.org/ abs/2507.03904. H. Zech. Liability for AI: public policy considerations. In ERA forum, volume 22, pages 147158. Springer, 2021. J. Zhang, W. Lou, H. Sun, Q. Su, and W. Li. Truthful auction mechanisms for resource allocation in the internet of vehicles with public blockchain networks. Future Generation Computer Systems, 132:1124, 2022. J. Zhang, Y. Liu, X. Qin, X. Xu, and P. Zhang. Adaptive resource allocation for blockchain-based federated learning in internet of things. IEEE Internet of Things Journal, 10(12):1062110635, 2023. K. Zhang, X. Liang, R. Lu, and X. Shen. Sybil attacks and their defenses in the internet of things. IEEE Internet of Things Journal, 1(5): 372383, 2014. K. Zhang, Z. Yang, and T. Ba≈üar. Multi-agent reinforcement learning: selective overview of theories and algorithms. Handbook of reinforcement learning and control, pages 321384, 2021. Z. Zhang, F. Bai, M. Wang, H. Ye, C. Ma, and Y. Yang. Incentive compatibility for AI alignment in sociotechnical systems: Positions and prospects. arXiv preprint arXiv:2402.12907, 2024. R. Zhao, J. Song, Y. Yuan, H. Hu, Y. Gao, Y. Wu, Z. Sun, and W. Yang. Maximum entropy population-based training for zero-shot humanIn Proceedings of the AAAI ai coordination. Conference on Artificial Intelligence, volume 37, pages 61456153, 2023. Z. Yang, A. Liu, Z. Liu, K. Liu, F. Xiong, Y. Wang, Z. Yang, Q. Hu, X. Chen, Z. Zhang, et al. Position: Towards unified alignment between agents, humans, and environment. In Fortyfirst International Conference on Machine Learning, 2024b. L. Zheng, W.-L. Chiang, Y. Sheng, S. Zhuang, Z. Wu, Y. Zhuang, Z. Lin, Z. Li, D. Li, E. Xing, et al. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36:4659546623, 2023. 37 Virtual Agent Economies S. Zheng, A. Trott, S. Srinivasa, D. C. Parkes, and R. Socher. The AI economist: Taxation policy design via two-level deep multiagent reinforcement learning. Science advances, 8(18): eabk2607, 2022. Z. Zheng, S. Xie, H.-N. Dai, X. Chen, and H. Wang. Blockchain challenges and opportunities: survey. International journal of web and grid services, 14(4):352375, 2018. L. Zhou, A. Diro, A. Saini, S. Kaisar, and P. C. Hiep. Leveraging zero knowledge proofs for blockchain-based identity sharing: survey of advancements, challenges and opportunities. Journal of Information Security and Applications, 80:103678, 2024a. Z. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma. Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning. In 2024 IEEE International Conference on Robotics and Automation (ICRA), pages 2081 2088. IEEE, 2024b. K. Zhu, J. Wang, J. Zhou, Z. Wang, H. Chen, Y. Wang, L. Yang, W. Ye, Y. Zhang, N. Gong, et al. Promptrobust: Towards evaluating the robustness of large language models on adIn Proceedings of the 1st versarial prompts. ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis, pages 5768, 2023a. K. Zhu, J. Wang, J. Zhou, Z. Wang, H. Chen, Y. Wang, L. Yang, W. Ye, Y. Zhang, N. Zhenqiang Gong, et al. Promptbench: Towards evaluating the robustness of large language models on adversarial prompts. arXiv e-prints, pages arXiv2306, 2023b. P. Zhu, J. Hu, X. Li, and Q. Zhu. Using blockchain technology to enhance the traceability of original achievements. IEEE Transactions on Engineering Management, 70(5):16931707, 2021. S. Zhu, J. Sun, Y. Nian, T. South, A. Pentland, and J. Pei. The automated but risky game: Modeling agent-to-agent negotiations and transactions in consumer markets, 2025. URL https:// arxiv.org/abs/2506.00073. S. Zhuang and D. Hadfield-Menell. Consequences of misaligned ai. Advances in Neural Information Processing Systems, 33:1576315773, 2020. M. Zhuge, C. Zhao, D. R. Ashley, W. Wang, D. Khizbullin, Y. Xiong, Z. Liu, E. Chang, R. Krishnamoorthi, Y. Tian, et al. Agent-as-a-judge: Evaluating agents with agents. 2025. M. Zimmer, C. Glanois, U. Siddique, and P. Weng. Learning fair policies in decentralized cooperative multi-agent reinforcement learning. In International conference on machine learning, pages 1296712978. PMLR, 2021. W. Zou, D. Lo, P. S. Kochhar, X.-B. D. Le, X. Xia, Y. Feng, Z. Chen, and B. Xu. Smart contract development: Challenges and opportunities. IEEE transactions on software engineering, 47 (10):20842106, 2019."
        },
        {
            "title": "Acknowledgements",
            "content": "We would like to thank our colleagues who provided feedback on the manuscript, in particular S√©bastien Krier and Raphael Koster for their valuable comments."
        }
    ],
    "affiliations": [
        "Google DeepMind",
        "University of Toronto"
    ]
}