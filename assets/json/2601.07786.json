{
    "paper_title": "\"TODO: Fix the Mess Gemini Created\": Towards Understanding GenAI-Induced Self-Admitted Technical Debt",
    "authors": [
        "Abdullah Al Mujahid",
        "Mia Mohammad Imran"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As large language models (LLMs) such as ChatGPT, Copilot, Claude, and Gemini become integrated into software development workflows, developers increasingly leave traces of AI involvement in their code comments. Among these, some comments explicitly acknowledge both the use of generative AI and the presence of technical shortcomings. Analyzing 6,540 LLM-referencing code comments from public Python and JavaScript-based GitHub repositories (November 2022-July 2025), we identified 81 that also self-admit technical debt(SATD). Developers most often describe postponed testing, incomplete adaptation, and limited understanding of AI-generated code, suggesting that AI assistance affects both when and why technical debt emerges. We term GenAI-Induced Self-admitted Technical debt (GIST) as a proposed conceptual lens to describe recurring cases where developers incorporate AI-generated code while explicitly expressing uncertainty about its behavior or correctness."
        },
        {
            "title": "Start",
            "content": "TODO: Fix the Mess Gemini Created: Towards Understanding GenAI-Induced Self-Admitted Technical Debt Abdullah Al Mujahid Mia Mohammad Imran Missouri University of Science and Technology Missouri University of Science and Technology Department of Computer Science Department of Computer Science Rolla, MO, USA Rolla, MO, USA amgzc@mst.edu imranm@mst.edu 6 2 0 2 2 1 ] . [ 1 6 8 7 7 0 . 1 0 6 2 : r Abstract As large language models (LLMs) such as ChatGPT, Copilot, Claude, and Gemini become integrated into software development workflows, developers increasingly leave traces of AI involvement in their code comments. Among these, some comments explicitly acknowledge both the use of generative AI and the presence of technical shortcomings. Analyzing 6,540 LLM-referencing code comments from public Python and JavaScript-based GitHub repositories (November 2022July 2025), we identified 81 that also self-admit technical debt (SATD). Developers most often describe postponed testing, incomplete adaptation, and limited understanding of AI-generated code, suggesting that AI assistance affects both when and why technical debt emerges. We term GenAI-Induced Self-admitted Technical debt (GIST) as proposed conceptual lens to describe recurring cases where developers incorporate AI-generated code while explicitly expressing uncertainty about its behavior or correctness. CCS Concepts Software and its engineering Software maintenance tools; Maintaining software; General and reference Empirical studies; Human-centered computing Open source software. Keywords self-admitted technical debt, generative AI, large language models, AI-assisted software development, human-AI collaboration ACM Reference Format: Abdullah Al Mujahid and Mia Mohammad Imran. 2026. TODO: Fix the Mess Gemini Created: Towards Understanding GenAI-Induced Self-Admitted Technical Debt. In . ACM, New York, NY, USA, 6 pages. https://doi.org/10.1 145/nnnnnnn.nnnnnnn"
        },
        {
            "title": "1 Introduction\nLarge Language Models (LLMs) are rapidly transforming software\ndevelopment workflows. Integrated tools such as GitHub Copilot,\nChatGPT, and Gemini now assist with code generation, refactoring,",
            "content": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference17, Washington, DC, USA 2026 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-x-xxxx-xxxx-x/YYYY/MM https://doi.org/10.1145/nnnnnnn.nnnnnnn Figure 1: Example self-admitted comment illustrating requirement debt documentation, and testing. While these systems increase productivity, they also introduce novel forms of risk and uncertainty. Developers must evaluate, correct, and maintain code partially written by non-human agents. Code comments, particularly those that self-admit technical shortcomings, offer unique window into how developers interpret and manage AI-assisted contributions. In software engineering, self-admitted technical debt (SATD) signals areas requiring future improvement. When such comments reference LLMs, they reveal not only perceived code deficiencies but also evolving conceptions of accountability between human and machine collaborators. Figure 1 shows one such example, where developer notes that function was generated by Gemini and remains unfinished, illustrating how AI involvement and deferred implementation converge to create potential debt. While prior research has established taxonomies and automated methods for identifying SATD [2, 3, 20, 25, 26], little is known about how technical debt manifests in code influenced by generative AI. Early studies on AI-assisted development highlight productivity benefits [4, 8], but also point to challenges of correctness, explainability, and trust. What remains unclear is how developers themselves recognize and document these challenges in practice, and whether AI involvement reshapes the kinds of debt that are self-admitted during development. This study explores SATD in the context of generative AI-assisted software development. By analyzing code comments that explicitly reference both LLM use and technical debt markers, we investigate how developers identify and articulate shortcomings in AI-generated code. Specifically, we ask: RQ1: What types of self-admitted technical debt emerge in developer comments that acknowledge both LLM involvement and technical debt? We observed that developers most frequently report Design Debt (33/81), followed by Requirement Debt (17/81) and Test Debt (17/81). Compared to prior SATD distributions, design-related issues are proportionally lower, while requirement and testing debts are higher, indicating that AI-assisted development tends to shift self-admitted Conference17, July 2017, Washington, DC, USA Abdullah Al Mujahid and Mia Mohammad Imran debt toward later development stages, particularly requirement completion and validation activities. RQ2: How do developers attribute the role of AI in generativeAI induced SATDs? We found that developers often attribute AI-assisted code as trigger for potential issues, expressing uncertainty about its completeness and correctness and noting the need for more verification or revision (34/81 cases). In several instances, developers hold AIassisted code responsible for errors, redundant logic, or unstable behavior that must be resolved later (22/81 cases). At the same time, they also recognize AI assistance as beneficial for improving, refining, or validating existing implementations which contributes to resolving existing technical debts (19/81 cases). Our findings show that AI-assisted development reshapes the distribution of technical debt, with fewer design-related issues but higher prevalence of requirement and testing debts. Beyond these shifts, we identify distinct form of debt is emerging when AIgenerated code is adopted without full developer understanding or confidence. We term this GenAI-Induced Self-admitted Technical debt (GIST). To the best of our knowledge, this is the first empirical study that systematically examines self-admitted technical debt explicitly linked to generative AI usage in source code comments. Looking ahead, our work posits several directions to examine how AI involvement influences the emergence and evolution of technical debt across the software development life cycle (SDLC), and how development tools or team practices might adapt to identify, document, and manage these AI-related debts more effectively. DATA AVAILABILITY The dataset is available at [23]."
        },
        {
            "title": "2 Related Work\nSelf-Admitted Technical Debt. Potdar and Shihab conducted an ex-\nploratory study on SATD by manually analyzing code comments to\ncharacterize how developers acknowledge and describe technical\ndebt [24]. Maldonado et al. introduced a widely used taxonomy\nand later developed NLP-based methods for automatic SATD de-\ntection [20, 21]. Li et al. conducted a systematic mapping study on\ntechnical debt and its management, categorizing major debt types,\nsummarizing management strategies, and identifying gaps in empir-\nical evidence and automation that shaped subsequent research on\ntechnical debt [18]. Large-scale empirical analyses further quanti-\nfied SATD prevalence and types across open-source projects [5, 14].\nSubsequent work compared SATD practices in industry and open\nsource [34], examined keyword-based detection [25, 26], and pro-\nposed refined taxonomies [7]. Other research extended detection\nbeyond comments to multiple artifacts such as commits, issues,\nand pull requests [17]. In parallel, automation efforts have mapped\ntools for technical-debt management across the development life-\ncycle [6].",
            "content": "AI-Assisted Software Development. Recent studies have examined how generative AI is influencing software engineering practice. Sauvola et al. discussed how AI may reshape development processes and responsibilities [28], while Coutinho et al. reported productivity gains alongside reliability and trust challenges [8]. Empirical studies of GitHub Copilot and other LLM tools have analyzed developerAI collaboration and code quality [4, 9, 13, 15]. Related work has also explored AI for identifying or managing technical debt [16, 22]. Despite these advances, little has been explored about how the use of AI itself contributes to the formation of technical debt. Our study addresses this gap by analyzing code comments that explicitly mention both AI involvement and self-admitted technical debt."
        },
        {
            "title": "3 Methodology\n3.1 Data Collection\n3.1.1 Collection of LLM Referenced Comments. We collected source\ncode comments from public GitHub repositories between Novem-\nber 2022 and July 2025, focusing on Python and JavaScript as these\ntwo are the most widely used languages in open-source ecosys-\ntem [10, 11, 31]. To identify comments where developers explicitly\nmention the use of AI/LLM tools, we built 196 structured search\nqueries combining (A) 7 AI related terms (e.g., LLM, AI, GPT, Chat-\nGPT, Copilot, Gemini, Claude), (B) 6 generative verbs (e.g., generated,\nsuggested, written), and (C) 4 connector terms (by, from, with, using).\nQueries of the forms (A + B) and (B + C + A) were executed via\nthe GitHub Code Search API [12], yielding 37,234 files. We then\nused AST parsing to extract matched comments [30]. Since many\ncomments were duplicates (e.g., ‚Äúgenerated by ChatGPT‚Äù, we\nremoved them. After deduplication, we found 6,540 unique com-\nments.",
            "content": "3.1.2 Debt Acknowledgment Detection. Within this LLMreferenced set, we applied second filter using canonical self-admitted technical debt keywords recognized in empirical software engineering research: TODO, FIXME, HACK, XXX [26]. The search was performed using regular expressions with case-insensitive matching to capture variations such as // todo or # FixMe. 3.1.3 Resulting Dataset. The intersection of these two filters yielded 96 unique comments that both (a) acknowledged the use or influence of AI/LLM and (b) contained explicit indicators of technical debt. Of the collected comments, 1.47% met our criteria, which is close to the 1.86% of SATD comments reported by [21]."
        },
        {
            "title": "3.2 SATD Types\n3.2.1 Taxonomy of SATD. To ensure compatibility with prior re-\nsearch on self-admitted technical debt, we adopted the widely used\ntaxonomy by Maldonado et al. [20]. They proposed 5 common\nSATD types:",
            "content": "Design Debt: These comments show design flaws in the code, such as misplaced logic, missing abstractions, overly long methods, or temporary workaround implementations. Defect Debt: Comments where author states that there is defect in the code. Documentation Debt: Authors clearly mention the need for documentation of the code. Requirement Debt: Expresses incompleteness of the code or unit of code such as: class, function or method. Test Debt: Shows the need for implementation or improvement of test. TODO: Fix the Mess Gemini Created: Towards Understanding GenAI-Induced Self-Admitted Technical Debt Conference17, July 2017, Washington, DC, USA 3.2.2 Annotation. Two annotators independently labeled the 96 source code comments following the guidelines provided by Maldonado et al. [20], as detailed in their replication package [19]. Each comment was classified into one of the five SATD categories described in Section 3.2.1. Inter-annotator agreement, measured using Cohens ùúÖ=0.896, indicated high consistency. Disagreements were resolved through in-person discussion. During annotation, we found 10 instances where AI/LLM mention without actual usage of AI, and in 5 instances did not contain technical debt. These 15 instances were labeled as False Positive and removed from the dataset, yielding final set of 81 annotated comments."
        },
        {
            "title": "3.3 Identifying the Role of AI\nTo understand how developers attribute the role of AI in LLM-\nreferenced SATD comments, we manually analyzed all 81 comments\nusing an open coding approach, where categories and concepts were\ninductively derived from the data rather than predefined [29, 32].\nAs no prior taxonomy describes how AI contributes to technical\ndebt, the two authors collaboratively developed through an iterative\ndiscussion. They reviewed the comments, compared interpretations,\nand refined emerging themes until stable and consistent categories\nwere established. This process led to 4 types of roles:\n‚Ä¢ Source: Developers indicate that AI-generated code directly in-\ntroduces problems such as incorrect logic, incomplete implemen-\ntation, redundant code, or temporary fixes. In these cases, AI is ex-\nplicitly described as causing the debt. Example: ‚ÄúTODO:ChatGPT\nsuggested super().close() and it crashed so I added\nthe if. I don‚Äôt about this.‚Äù",
            "content": "Catalyst: Developers express uncertainty about AI-generated contributions that function but may require later verification. AI does not cause an immediate issue but prompts awareness of potential future debt. Example: TODO! validators generated by copilot , should be verified :works but doesnt mean it works all the time. Mitigator: Developers mention using AI to help address existing debt, such as by generating tests or refactoring suggestions. Example: TODO - Try these tests, generated by Copilot Neutral: AI or technical debt terms are mentioned without clear link to the creation or resolution of technical debt. The annotation instructions for open coding are available in our replication package [23]."
        },
        {
            "title": "4 RQ1: What types of self-admitted technical\ndebt emerge in developer comments that\nacknowledge both LLM involvement and\ntechnical debt?",
            "content": "We begin by examining the types of self-admitted technical debt that appear in comments explicitly mentioning LLM use."
        },
        {
            "title": "4.1 Results\nTable 1 summarizes the types of SATD identified in code comments\nthat explicitly mention generative-AI usage. The most common\ncategory is Design Debt (33/81), which reflects issues such as mis-\nplaced code, poor implementation or a temporary workaround. For",
            "content": "example, TODO - this is copilot generated code, needs refactoring to kdata object is indicating that the implementation needs to be refactored, adding design debt to the developers. Similarly, TODO: Modify this component to fit your needs. The ProfilePage component was generated with Github Copilot. suggests that the developers need to modify the AI-suggested component to fit project-specific needs. Requirement Debt appears in 17/81 comments. Figure 1 illustrates typical example where function was initially generated by Gemini but left unfinished. Another comment, TODO: Add parameter to include ingredients from the gpt generated check, demonstrates deferred integration task where AI generated code needs to include the additional parameters. We observed Test Debt in 17/81 cases, where developers defer testing or validation of the integrated AI-assisted code, e.g., TODO: test this Copilot generated code. There are also comments mentioning about tests generated by generative AI, which requires further improvement, e.g., TODO 2023-08-23 10:41: - [ ] Skeleton of tests written by ChatGPT, write tests. We further noticed Defect Debts in 11/81 instances, where developers acknowledging defect/bug that needs to be fixed. For example, comments such as TODO fix this ChatGPT created code. and TODO: Does not work. Its just generated from ChatGPT illustrate those. very small portion were Documentation Debt (3/81), e.g., TODO (USERNAME): This comment is generated by ChatGPT, which may not be accurate."
        },
        {
            "title": "5 RQ2: How do developers attribute the role of",
            "content": "AI in generative-AI induced SATDs? While RQ1 established that AI-assisted development shifts the distribution of technical debt toward implementation and validation stages. However, these categories alone do not capture how developers perceive AIs responsibility in creating or mitigating such Conference17, July 2017, Washington, DC, USA Abdullah Al Mujahid and Mia Mohammad Imran Table 1: Distribution of Technical Debt Types Debt Type Design Debt Requirement Debt Test Debt Defect Debt Documentation Debt Total What the comment addresses Problematic design, misplaced code, poor implementation Incomplete/partial implementation Needs test/verification/validation of AI supported code Bug/defect in code Incomplete/improper documentation Example TODO - this is copilot generated code, needs refactoring to kdata object TODO: Add parameter to include ingredients from the gpt generated check [...] TODO: test this Copilot generated code TODO fix this ChatGPT created code. TODO (USERNAME): This comment is generated by ChatGPT, which may not be accurate. Count 33 (40.74%) 17 (20.98%) 17 (20.98%) 11 (13.58%) 3 (3.70%) 81 debt. To address this, we examine the ways developers attribute roles to AI when discussing self-admitted technical debt."
        },
        {
            "title": "5.1 Results.\nFigure 2 summarizes the roles developers attribute to AI within\nSATD-related comments. The most common role is that of a Catalyst\n- (34/81, 41.98%), where AI-assisted codes prompt awareness of\npotential technical debt. These comments express uncertainty about\ncorrectness or completeness, leading developers to defer testing\nand validation. For instance, ‚ÄúTODO: generated by ChatGPT,\ndon‚Äôt know how reasonable this is‚Äù shows doubt about the\nreliability of a generated artifact, while, ‚ÄúTODO: AI Generated,\nplease check the fields.‚Äù records postponed checking. Here,\nAI functions as a Catalyst, surfacing uncertainty that developers\nacknowledge as potential debt.",
            "content": "In 22/81 (27.2%) cases, developers are identifying AI as Source of technical debt. These comments describe situations where AIgenerated code introduces errors, redundant logic, or unstable behavior that developers must later address. For example, TODO: Does not work. Its just generated from ChatGPT signals nonfunctional output that requires fixing, while TODO: remove all unnecessary methods; this is an AI-generated file points to redundant code. third pattern, we observed in 19/81 cases, developers frame AI as Mitigator. Here, AI contributes to reducing existing debt by generating refactors, test scaffolds, or suggesting design alternatives. For instance, PJB replaced with new in each case. TODO: use an improved const as suggested by Claude here, Claude is suggesting how to mitigate past debt Finally, In 6/81 (7.4%) of the comments are classified as neutral, where AI is mentioned but its role to technical debt cannot be clearly determined. Distribution of AI Roles Across SATD Types. Figure 2 shows how AI roles vary across SATD types. When AI is identified as the Source of debt, it is most often associated with Design Debt (9 instances), followed by Requirement Debt and Test Debt (6 instances each), and Documentation Debt (1 instance). As Catalyst, AI is primarily linked to Test Debt (15 instances) and Design Debt (13 instances). When acting as Mitigator, it is most commonly associated with Requirement Debt (9 instances) and Design Debt (8 instances), reflecting its use in supporting code generation and refactoring. Figure 2: GenAI roles across SATD types"
        },
        {
            "title": "6 GenAI-Induced Self-admitted Technical debt",
            "content": "(GIST) We observed recurring pattern that developers are integrating AIassisted code into their production codebases despite i) uncertainty about its correctness, and ii) limited understanding of its internal logic. We introduce this notion as conceptual interpretation grounded in observed self-admitted comments. This pattern appears across multiple SATD types discussed in Section 3.2.1. For example, TODO: Fix the Mess Gemini Created: Towards Understanding GenAI-Induced Self-Admitted Technical Debt Conference17, July 2017, Washington, DC, USA in the comment, TODO: Copilot suggested this function (I have no clue what the regex is doing), the developer acknowledges incorporating an AI-generated function without understanding its behavior. Similarly, TODO: This is totally GPT generated and Im not sure it works expresses uncertainty about correctness, and TODO: generated by ChatGPT, dont know how reasonable this is reflects doubt about the plausibility of the AI output. Collectively, these comments illustrate recurring form of uncertainty-driven technical debt that we refer to as GenAI-Induced Self-admitted Technical debt (GIST). The observed pattern is consistent with prior work on automation bias, where developers rely on automated suggestions despite uncertainty about their correctness or rationale [1, 27]. Research in human-AI interaction has shown that such reliance can influence judgment, verification behavior, and trust in automated systems [1, 27, 33]. In our study, we observe how automation-related uncertainty is documented as self-admitted technical debt in source code comments. GIST characterizes situations in which uncertainty about AIgenerated code is not immediately resolved but instead deferred, creating latent burden for future development and maintenance. This form of debt manifests through two recurring dimensions: Knowledge Deficit and Deferred Quality Assurance: Developers integrate AI-generated code without full understanding of its underlying logic or correctness, creating gap between the artifact and their mental model of the system. This partial comprehension often leads to postponed validation or testing, as developers defer closer examination to later stage. Such deferral constitutes cognitive form of technical debt: understanding is temporarily outsourced to the AI, leaving uncertainty that may resurface during maintenance or modification. Lack of Trust and Delegated Responsibility: Developers uncertainty about the reliability or rationale of AI-generated code may erode their confidence in the system as whole. To manage this uncertainty, responsibility for verifying or improving the AIs output is implicitly shifted to other team members or future revisions. This delegation reflects an operational dimension of GIST, where provisional integration of AI output allows unverified code to persist, creating ambiguity around ownership and long-term accountability."
        },
        {
            "title": "7 Implications and Reflections\n7.1 Technical Debt in AI-Assisted Development\nOur findings reveal a shift in the composition of SATD. Design Debt\nhas become less dominant, while Requirement and Test Debts are\nincreasingly common. The changing distribution of debt types sug-\ngests that AI assistance is reshaping not the taxonomy of technical\ndebt but its underlying causes. In traditional settings, debt often\nresults from conscious trade-offs or time pressure. In contrast, AI-\nassisted debt tends to emerge from partial reliance on automatically\ngenerated code and deferred human oversight. This shift implies\nthat technical debt frameworks may need to account for delegated\ndecision-making, where responsibility for quality and completion is\nshared between humans and AI systems. More broadly, our observa-\ntions suggest that some AI-related debt may arise unintentionally,",
            "content": "not from deliberate shortcuts but from uncertainty about the behavior or suitability of AI-generated code."
        },
        {
            "title": "7.2 Interpreting GIST\nThe notion of GIST highlights how limited understanding of AI-\ngenerated code can affect long-term maintainability. When code\nfunctions without a clear rationale, comprehension and account-\nability may become fragmented, increasing future effort to mod-\nify, validate, or extend the code. In the analyzed comments, devel-\nopers explicitly acknowledge such uncertainty when integrating\nAI-generated artifacts, indicating awareness of potential future\nmaintenance challenges.",
            "content": "Integrating principles from explainable AI and responsible AI could help mitigate these risks by promoting transparency about how models produce code, documenting decision rationales, and clarifying accountability when AI assistance is used. Such practices may help developers retain insight into AI-generated code and better recognize when limited understanding could introduce additional maintenance effort over time."
        },
        {
            "title": "9 Conclusion and Future Work\nThis study provides an empirical examination of self-admitted tech-\nnical debt that explicitly references the use of generative AI. By\nanalyzing 81 LLM-related code comments, we observe that AI as-\nsistance is associated with a shift in how debt is self-admitted:\ndesign-related issues appear less frequently, while requirement and\ntesting debts are more common, reflecting deferred completion and\nvalidation of AI-generated code. We propose GenAI-Induced Self-\nadmitted Technical debt (GIST) as a conceptual lens to describe",
            "content": "Conference17, July 2017, Washington, DC, USA Abdullah Al Mujahid and Mia Mohammad Imran recurring patterns of self-admitted technical debt in which developers explicitly express uncertainty about the behavior or rationale of AI-generated code, inviting researchers to further examine, refine, and empirically validate this notion across broader contexts. Our study represents an initial step toward understanding AIrelated technical debt and how generative AI is influencing software development life cycle practices. The analysis is limited to Python and JavaScript projects; future work should extend to additional languages and ecosystems to assess whether similar patterns hold. Longitudinal repository studies and automated analysis techniques could further illuminate how AI-related debts evolve over time and whether they are resolved or accumulate as systems mature. Future research may also explore practices that improve the transparency and verifiability of AI-generated code, supporting developers in managing uncertainty and sustaining long-term maintainability in AI-assisted software development. References [1] Uju√© Agudo, Karlos Liberal, Miren Arrese, and Helena Matute. 2024. The impact of AI errors in human-in-the-loop process. Cognitive Research: Principles and Implications 9, 1 (2024), 1. [2] Nicolli SR Alves, Thiago Mendes, Manoel De Mendon√ßa, Rodrigo Sp√≠nola, Forrest Shull, and Carolyn Seaman. 2016. Identification and management of technical debt: systematic mapping study. Information and Software Technology 70 (2016), 100121. [3] Nicolli S.R. Alves, Leilane F. Ribeiro, Vivyane Caires, Thiago S. Mendes, and Rodrigo O. Sp√≠nola. 2014. Towards an Ontology of Terms on Technical Debt. In 2014 Sixth International Workshop on Managing Technical Debt. 17. doi:10.1109/ MTD.2014.9 [4] Stefan Barke, Reid Holmes, and Christian Bird. 2023. Grounded Copilot: How Programmers Interact with Code-Generating Models. In Proceedings of the 45th International Conference on Software Engineering (ICSE 23). IEEE/ACM, 1433 1445. doi:10.1109/ICSE48619.2023.00119 [5] Gabriele Bavota and Barbara Russo. 2016. large-scale empirical study on selfadmitted technical debt. In Proceedings of the 13th international conference on mining software repositories. 315326. [6] Jo√£o Paulo Biazotto, Daniel Feitosa, Paris Avgeriou, and Elisa Yumi Nakagawa. 2024. Technical debt management automation: State of the art and future perspectives. Information and Software Technology 167 (2024), 107375. [7] Nathan Cassee, Fiorella Zampetti, Nicole Novielli, Alexander Serebrenik, and Massimiliano Di Penta. 2022. Self-admitted technical debt and comments polarity: an empirical study. Empirical Software Engineering 27, 6 (2022), 139. [8] Mariana Coutinho, Lorena Marques, Anderson Santos, Marcio Dahia, Cesar Fran√ßa, and Ronnie de Souza Santos. 2024. The role of generative ai in software development productivity: pilot case study. In Proceedings of the 1st ACM International Conference on AI-Powered Software. 131138. [9] Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang, Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng Sha, Xin Peng, and Yiling Lou. 2024. Evaluating large language models in class-level code generation. In Proceedings of the IEEE/ACM 46th International Conference on Software Engineering. 113. [10] GitHub. 2023. The State of Open Source and AI in 2023. https://github.blog/newsinsights/research/the-state-of-open-source-and-ai/ [Available Online]. [11] GitHub. 2024. Octoverse 2024: AI leads Python to top language. https://github.b log/news-insights/octoverse/octoverse-2024/ [Available Online]. [12] GitHub, Inc. [n. d.]. GitHub Code Search API. https://docs.github.com/en/rest/co de-search. [Available Online]. [13] Qi Guo, Junming Cao, Xiaofei Xie, Shangqing Liu, Xiaohong Li, Bihuan Chen, and Xin Peng. 2024. Exploring the potential of chatgpt in automated code refinement: An empirical study. In Proceedings of the 46th IEEE/ACM International Conference on Software Engineering. 113. [14] Qiao Huang, Emad Shihab, Xin Xia, David Lo, and Shanping Li. 2018. Identifying self-admitted technical debt in open source projects using text mining. Empirical Software Engineering 23, 1 (2018), 418451. doi:10.1007/s10664-017-9522-4 [15] Kailun Jin, Chung-Yu Wang, Hung Viet Pham, and Hadi Hemmati. 2024. Can chatgpt support developers? an empirical evaluation of large language models for code generation. In Proceedings of the 21st International Conference on Mining Software Repositories. 167171. [16] Jun Li, Lixian Li, Jin Liu, Xiao Yu, Xiao Liu, and Jacky Wai Keung. 2025. Large language model ChatGPT versus small deep learning models for self-admitted technical debt detection: Why not together? Software: Practice and Experience 55, 1 (2025), 328. [17] Yikun Li, Mohamed Soliman, and Paris Avgeriou. 2023. Automatic identification of self-admitted technical debt from four different sources. Empirical Software Engineering 28, 6 (2023), 131. doi:10.1007/s10664-023-10297-9 [18] Zengyang Li, Paris Avgeriou, and Peng Liang. 2015. systematic mapping study on technical debt and its management. Journal of systems and software 101 (2015), 193220. [19] E. Maldonado and E. Shihab. [n. d.]. tse.satd.data: Manually-labelled dataset of self-admitted technical debt. GitHub repository. https://github.com/maldonado /tse.satd.data [20] Everton da Maldonado and Emad Shihab. 2015. Detecting and quantifying different types of self-admitted technical debt. In 2015 IEEE 7Th international workshop on managing technical debt (MTD). IEEE, 915. [21] Eduardo S. Maldonado, Emad Shihab, and Nikolaos Tsantalis. 2017. Using Natural Language Processing to Automatically Detect Self-Admitted Technical Debt. IEEE Transactions on Software Engineering 43, 11 (2017), 10441062. doi:10.1109/TSE. 2017.2654243 [22] Eric Melin and Nasir Eisty. 2025. Exploring the advances in using machine learning to identify technical debt and self-admitted technical debt. In 2025 IEEE/ACIS 23rd International Conference on Software Engineering Research, Management and Applications (SERA). IEEE, 1522. [23] Abdullah Al Mujahid. 2026. \"TODO: Fix the Mess Gemini Created\": Towards Understanding GenAI-Induced Self-Admitted Technical Debt. Zenodo. doi:10.5 281/zenodo.18194031 [24] Aniket Potdar and Emad Shihab. 2014. An Exploratory Study on Self-Admitted Technical Debt. In Proceedings of the 30th IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, 91100. doi:10.1109/ICSME.2014.31 [25] Leevi Rantala, Mika M√§ntyl√§, and Valentina Lenarduzzi. 2024. Keyword-labeled self-admitted technical debt and static code analysis have significant relationship but limited overlap. Software Quality Journal 32, 2 (2024), 391429. [26] Leevi Rantala, Mika M√§ntyl√§, and David Lo. 2020. Prevalence, contents and automatic detection of KL-SATD. In 2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA). IEEE, 385388. [27] Charvi Rastogi, Yunfeng Zhang, Dennis Wei, Kush Varshney, Amit Dhurandhar, and Richard Tomsett. 2022. Deciding fast and slow: The role of cognitive biases in ai-assisted decision-making. Proceedings of the ACM on Human-computer Interaction 6, CSCW1 (2022), 122. [28] Jaakko Sauvola, Sasu Tarkoma, Mika Klemettinen, Jukka Riekki, and David Doermann. 2024. Future of software development with generative AI. Automated Software Engineering 31, 1 (2024), 26. [29] Carolyn B. Seaman. 1999. Qualitative methods in empirical studies of software engineering. IEEE Transactions on software engineering 25, 4 (1999), 557572. [30] Tree sitter Contributors. [n. d.]. Tree-sitter: An Incremental Parsing System for Programming Tools. https://github.com/tree-sitter/tree-sitter [GitHub repository]. [31] Stack Overflow. 2024. Technology 2024 Stack Overflow Developer Survey. https://survey.stackoverflow.co/2024/technology [Available Online]. [32] Anselm Strauss and Juliet Corbin. 1990. Basics of qualitative research. Sage publications. [33] Tim Lewis Wingerter, Tim Straub, and Sascha Schweitzer. 2025. Mitigating automation bias in generative AI through nudges: cognitive reflection test study. Procedia computer science 270 (2025), 21062114. [34] Fiorella Zampetti, Gianmarco Fucci, Alexander Serebrenik, and Massimiliano Di Penta. 2021. Self-admitted technical debt practices: comparison between industry and open-source. Empirical Software Engineering 26, 6 (2021), 131."
        }
    ],
    "affiliations": [
        "Missouri University of Science and Technology"
    ]
}