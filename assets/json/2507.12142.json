{
    "paper_title": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization",
    "authors": [
        "Vladimir Bogachev",
        "Vladimir Aletov",
        "Alexander Molozhavenko",
        "Denis Bobkov",
        "Vera Soboleva",
        "Aibek Alanov",
        "Maxim Rakhuba"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Low-Rank Adaptation (LoRA) has become a widely adopted standard for parameter-efficient fine-tuning of large language models (LLMs), significantly reducing memory and computational demands. However, challenges remain, including finding optimal initialization strategies or mitigating overparametrization in low-rank matrix factorization. In this work, we propose a novel approach that addresses both of the challenges simultaneously within a unified framework. Our method treats a set of fixed-rank LoRA matrices as a smooth manifold. Considering adapters as elements on this manifold removes overparametrization, while determining the direction of the fastest loss decrease along the manifold provides initialization. Special care is taken to obtain numerically stable and computationally efficient implementation of our method, using best practices from numerical linear algebra and Riemannian optimization. Experimental results on LLM and diffusion model architectures demonstrate that RiemannLoRA consistently improves both convergence speed and final performance over standard LoRA and its state-of-the-art modifications."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 6 1 ] . [ 1 2 4 1 2 1 . 7 0 5 2 : r RiemannLoRA: Unified Riemannian Framework for Ambiguity-Free LoRA Optimization Vladimir Bogachev HSE University vabogachev@hse.ru Vladimir Aletov MIPT, ISPRAS aletov.v@phystech.edu Alexander Molozhavenko HSE University amolojavenko@hse.ru Denis Bobkov AIRI, HSE University dnbobkov@edu.hse.ru Vera Soboleva AIRI, HSE University vvsoboleva@airi.net Aibek Alanov HSE University, AIRI alanov.aibek@gmail.com Maxim Rakhuba HSE University"
        },
        {
            "title": "Abstract",
            "content": "Low-Rank Adaptation (LoRA) has become widely adopted standard for parameter-efficient fine-tuning of large language models (LLMs), significantly reducing memory and computational demands. However, challenges remain, including finding optimal initialization strategies or mitigating overparametrization in low-rank matrix factorization. In this work, we propose novel approach that addresses both of the challenges simultaneously within unified framework. Our method treats set of fixed-rank LoRA matrices as smooth manifold. Considering adapters as elements on this manifold removes overparametrization, while determining the direction of the fastest loss decrease along the manifold provides initialization. Special care is taken to obtain numerically stable and computationally efficient implementation of our method, using best practices from numerical linear algebra and Riemannian optimization. Experimental results on LLM and diffusion model architectures demonstrate that RiemannLoRA consistently improves both convergence speed and final performance over standard LoRA and its state-of-the-art modifications."
        },
        {
            "title": "Introduction",
            "content": "Large language models (LLMs) have demonstrated remarkable capabilities across wide range of natural language processing tasks Brown et al. [2020], Touvron et al. [2023a,b]. However, the computational and storage costs associated with training and deploying such models at scale pose significant challenges. To reduce these costs, parameter-efficient fine-tuning techniques such as low-rank adaptation (LoRA) Hu et al. [2022] have emerged as practical solution. LoRA enables efficient adaptation of pre-trained models by embedding learnable low-rank matrices into specific weight updates, allowing most of the original parameters to remain frozen. In particular, the main idea of LoRA is to fine-tune pretrained model using rank-r correction matrix : + = + AB, Rmr, Rnr, where remains constant during training and A, are optimized via gradient-based optimization methods. Due to its widespread adoption and utility, numerous efforts have been made to further enhance the quality of low-rank fine-tuning. Various ambiguities have inspired multiple techniques that leverage Preprint. Under review. them for performance gains. The two primary sources of ambiguity in low-rank adaptation are as follows. First, we can improve LoRA initialization by finding better starting matrices A0 Rmr and B0 Rnr. This is done by replacing the original weight matrix with modified version using the following splitting: = (W A0B 0 ) (cid:125) (cid:124) (cid:123)(cid:122) +A0B 0 = + A0B 0 , (1) with (A0, B0) chosen based on low-rank approximation of weight matrices or gradients [Meng et al., 2024, Wang et al., 2025, 2024] and one of the matrices is chosen to be zero is standard LoRA. On the other hand, there is problem in overparametrization of low-rank matrices during training. Indeed, for any U1 Rmr,V1 Rnr and any invertible matrix Rrr, we may write: AB = (cid:101)A (cid:101)B, where (cid:101)A = AS, (cid:101)B = BS. (2) Widely used optimization methods such SGD [Robbins and Monro, 1951], Adam [Kingma and Ba, 2014], Adagrad [Duchi et al., 2011], RMSProp [Tieleman, 2012] neither account for nor exploit these inherent ambiguities. In this work, we propose novel framework that naturally eliminates all ambiguities within unified approach. To the best of our knowledge, this is the first such attempt. In particular, we introduce new method called Riemannian LoRA (RiemannLoRA). This approach replaces the standard Euclidean optimization of low-rank matrices with one on Riemannian manifold of fixed-rank matrices, thereby respecting the intrinsic geometry of low-rank matrices. On this manifold, every point is considered as an element of Rmn, so it does not depend on particular parametrization choice (2). The Riemannian framework also allows us to initialize the method in geometrically meaningful way by choosing the splitting that yields the fastest loss decrease along the manifold. The contributions of this work are as follows. We propose new framework, called RiemannLoRA, which natively resolves ambiguities of previous LoRA-based approaches using Riemannian optimization. It combines two essential ingredients: initialization (Section 4.2) and parametrization-free optimization (Sections 4.1, 4.3), that is based on inversion-free robust formulas and reliable matrix decompositions. We propose an efficient way to initialize matrices by using randomized SVD algorithm with implicit matrix multiplication (Section 4.2). We showcase the performance of our framework for fine-tuning LLMs and in subject-driven generation using diffusion models. Among positive effects that we observe are: boost in target metrics, improved convergence, and reduction of variance (Section 5)."
        },
        {
            "title": "2 Related Work",
            "content": "The problem of an optimal initial guess selection for low-rank LLM adaptation has been addressed in sequence of works: the authors Meng et al. [2024, PiSSA] have suggested heuristic that involves using low-rank truncated SVD of pretrained parameters as an initial point for LoRA and its orthogonal complement as frozen layers parameters, so that the tuning process starts without changing the starting value of the loss function. similar approach was implemented by Wang et al. [2025, MiLoRA] with the main difference of optimizing the smallest singular components of unadapted parameter matrix. context-aware initialization was considered in [Yang et al., 2024, CorDA] and [Parkina and Rakhuba, 2025, COALA] proposes numerically robust inversion-free framework for low-rank weighted approximations for this setting. Another idea is to initialize LoRA with subset of left and right singular vectors of doubled-rank truncated SVD of the loss function gradient at the starting parameters, proposed by Wang et al. [2024, LoRA-GA]. We show direct connection of this method to our Riemannian initialization strategy and propose how to additionally significantly accelerate the computation of SVD using our approach. Attempting to overcome the asymmetry in the initialization of vanilla LoRA fine-tuning process, [Hayou et al., 2024, LoRA+] introduced scale-free step size selection for LoRA factors. Riemannian optimization is widely used for algorithms on matrix manifolds and allows for exploiting task geometry or imposing additional constraints. For example, Riemannian solution for the extreme 2 eigenpairs search problem was described in Absil et al. [2009], Baker [2008], matrix completion task, which is common in collaborative filtering for recommender systems, via optimization on the fixed-rank manifold [Vandereycken, 2013]), Riemannian approach on the manifold of matrices with orthonormal columns (the Stiefel manifold) was used by Wisdom et al. [2016] for diminishing the problem of vanishing and exploding gradients in recurrent neural networks, etc. The book Trendafilov and Gallo [2021] also presents comprehensive description of useful manifolds for solutions of the data science problems. For the deeper understanding of applied differential geometry techniques see the books Absil et al. [2009] and Boumal [2023]. The idea of using Riemannian optimization has recently started to emerge for the large language models. For example, the fine-tuning of LLMs with the help of the Stiefel manifold was considered in the work Hu et al. [2024]. The authors of [Zhang and Pilanci, 2024] introduced the Riemannian inspired modification of Adam. The authors of Mo et al. [2025, LORO] applied the Riemannian optimization techniques for pretraining LLMs on the fixed-rank manifold. Parametrization that is used in our work can potentially help in this setting as well, by additionally avoiding potential overheads and instabilities, arising due the explicit inversion of Gram matrices."
        },
        {
            "title": "3 Riemannian optimization on a fixed-rank manifold",
            "content": "If we only fine-tune the parameter matrix of one layer, the optimization problem becomes: L(W + AB) min A,B . In the Riemannian optimization approach, we treat each low-rank matrix = AB as an element of the manifold of fixed-rank matrices Mr (formal definitions are provided later): L(W + ) min Mr . Consequently, rather than relying on specific parameterization, we traverse from one point on Mr to another. Thus, in exact arithmetic, all valid representations of Mr lead to equivalent methods. Nevertheless, the choice of parameterization is important for computational efficiency and numerical stability, and we pay attention to these aspects as well. 3.1 Fixed-rank manifold Let < min(m, n) be matrix rank, and consider the set Mr = (cid:8)X Rmnrank (X) = r(cid:9) Rmn. (3) Mr forms smooth embedded into linear space Rmn manifold [Lee, 2003, Example 8.14] of dimension dim Mr = (m + n)r r2. Every rank-r matrix Mr can be represented using certain full-rank matrices Rmr, Rnr as = AB. By orthogonalizing the columns of or B, we can parametrize the manifold of fixed-rank in the following two ways: = ALB = AB , Mr, (4) where A, AL Rmr, B, BR Rnr and AL, BR have orthonormal columns AL = Ir, Ir Rrr. BR = Ir, This representation is particular case of the representation of elements of the fixed tensor train rank manifold [Holtz et al., 2012] and can be achieved, for example, with the help of the QR decomposition. Several alternative parameterizations of the fixed-rank matrix manifold exist (see [Boumal, 2023, Chap. 7.5]), though we do not employ them in this work. The smoothness of the embedded manifold ensures that, locally, it is well-approximated by linear subspace called tangent space, which resembles local linearization of smooth functions. If Mr then the tangent space at that point can be represented as TXMr = (cid:110) ξ(cid:12) (cid:12) ξ = AB + AL B, = ALB, AAL = 0r (cid:111) Rmn. (5) Just as points on fixed-rank manifold can be represented as pair of matrices (A, B), tangent vectors can also be represented in similar format, though with the ranks twice as large. In particular, for any ξ TXMr: ξ = (cid:2) AL (cid:3) (cid:21) (cid:20)BR , rank ξ 2r. (6) Interestingly, the point Mr itself lies in the TXMr with = 0, = B. Given matrix Rmn, its orthogonal projection PTXMr onto the tangent space TXMr (with the parameterization given in (5)) can be computed as follows: PTXMr = AZB AZ = (I ALA + AL , BZ = AL. )ZBR, Rmn, (7) 3.2 Riemannian optimization techniques Let Mr Rmn be smooth submanifold and : Rmn differentiable function with the Euclidean gradient Rmn. Within the Riemannian optimization framework, we solve the following task via gradient-based optimization min XMr (X). The Euclidean gradient is direction of the fastest local increase . Therefore, it is common to use the Riemannian gradient the direction of local increase of corresponding smooth function value along the manifold, which lies in the tangent space [Absil et al., 2009, chap. 3.6]. Given the Euclidean gradient , one may endow the tangent space TXMr with natural scalar product and derive formula for the direction of the local steepest ascent of alongside the manfold. This unique direction is called the Riemannian gradient and assuming that is defined on the whole Rmn, can be computed as follows: grad (X) = PTXMr (X), Mr, (8) where PTXMr is the orthogonal projection operator onto TXMr. One may also use momentum vectors that are reprojected to the current tangent plane (vector transort, see [Absil et al., 2009, chap. 8.1]) and combine it with the Riemannian gradient at the i-th iteration: d(i) = β PT (cid:124) X(i) Mr d(i1) (cid:123)(cid:122) (cid:125) momentum +(1 β) grad (X (i)) (cid:125) (cid:124) (cid:123)(cid:122) gradient . Next, we want to move along the manifold in the chosen direction ξ = d(i) TXMr. This operation is commonly handled by the retraction function RX (ξ). The retraction, informally speaking, returns + ξ (of the rank 2r in general) back to the manifold of rank-r matrices. In our case, we use projection-type retraction ([Lewis and Malick, 2008, Lemma 2.1], see [Absil and Oseledets, 2015] for other variants of retraction functions): Mr, where UrΣrV is rank-r truncated SVD of the matrix + ξ. Since TXMr, one may obtain that rank (X + ξ) 2r, and the truncated SVD can be computed in low-rank format without forming dense matrices (see (6)). The asymptotic complexity of this retraction operation is O((m+n)r2 +r3). RX (ξ) = UrΣrV (9) Finalizing the optimization step, one may select step size parameter η(i) and obtain the final expression: (i+1) = RX (i) (cid:16) η(i) d(i)(cid:17) ."
        },
        {
            "title": "4 RiemannLoRA",
            "content": "4.1 Efficient computation of the Riemannian gradient Recall that we represent from + in two ways: = ALB = AB Mr. 4 Let be the loss function of model and η be step size, then L(W + ) = +W (W + ) = (Y ) , = + W, so according to (7) and (8), the Riemannian gradient can be derived as gradW L(W + ) = (I ALAL)Y (Y ) BRB + ALA (Y ) . (10) The calculation of full loss gradient (Y ) is computationally expensive. At the same time, we actually need to compute (Y ) BR and Y (Y ). Using the trick from [Novikov et al., 2022], we may calculate both quantities using single forward and backward passes with doubled rank representation: Z1L (cid:0)W + Z1B Z2L (cid:0)W + Z1B + ALZ 2 + ALZ 2 (cid:1) Z1=0,Z2=B = L(Y )BR, (cid:1) Z1=0,Z2=B = L(Y )AL. (11) Clearly, this approach can also be used to compute (Y ) and (Y ) for arbitrary matrices Rnk or Rmk. We will use this as key building block for randomized SVD initialization in the next section. 4.2 Locally optimal initialization (LOI) Given any Mr, we may write L(W ) = L(W (cid:125) (cid:124) (cid:123)(cid:122) +W ) = (W + ) . This raises the question: how should be chosen to ensure the fastest loss decrease along the manifold? The solution is to consider the following optimization task: PTW Mr L(W )2 (0) (12) . Argmax Mr Since PTW Mr is an orthogonal projection matrix to the tangent plane, the task (12) essentially seeks for the point on the fixed-rank manifold, whose tangent space has most alignment with the Euclidean gradient. In other words, this means that the direction of the steepest local function decrease alongside the manifold is aligned with the full model tuning direction. The solution to this task is presented in Theorem 4.1. Theorem 4.1. Let the SVD of L(W ) be: L(W ) = [U1,r Ur,2r U] (cid:34)Σ1,r 0 0 0 Σr,2r 0 (cid:35) 0 0 Σ [V1,r Vr,2r V] , and let also σ2r = σ2r+1. Then any optimal solution (0) (cid:40) (0) [U1,r, Ur,2rΣr,2r] (cid:21) (cid:20)S11 S21 [C21 C22] = (cid:21) (cid:20)S11 S12 S21 GL2r(R), S1 = 1,r to the problem (12) has the form: (cid:21) (cid:12) (cid:20)Σ1,rV (cid:12) (cid:12) (cid:12) Vr,2r (cid:12) (cid:20)C11 C12 C21 C22 (cid:21) (cid:41) , Where GL2r (R) denotes the set of all non-singular matrices in R2r2r. Proof. See Appendix A. In our experiments, we choose = (cid:20)αIr 0 0 Ir (cid:21) , obtaining: (0) = αU1,rV r,2r Mr, α {0}. (13) (14) Surprisingly, the result of Theorem 4.1 is related to [Wang et al., 2024], where the authors did not consider the Riemannian setting and were not concerned with parametrization-free optimization. Randomized SVD for efficient initialization. The computation of the 2r-truncated SVD from Theorem 4.1 of the full loss gradient has asymptotical complexity O(min{m, n}mn), which can represent significant computational demand for larger models. To overcome this problem, we propose to use randomized SVD with power iterations (see [Halko et al., 2011]), as is described in the Algorithm 1. In nutshell, we need to compute (cid:0)W L(W )W L(W )(cid:1)q , where = L(W )Ω and Ω is sampled from standard normal distribution. This iteration can be done in robust manner with the help of QR decompositions. The steps 2, 5, 7, and 10 correspond to matrix multiplications with gradients and are computed using the trick from (11). The larger the hyperparameters and are, the more accurate approximation we obtain. This method has asymptotic complexity of O((m + n)r2) and in addition 2(q + 1) backward calls. Algorithm 1 BackPropRSVD Require: Weights Rmn, rank N, oversampling parameter p, power-step parameter q. Ensure: Randomized r-truncated SVD (Ur, Σr, Vr) of L(W ). Function: 1: Choose = + p, Sample Ω Rnk (0, 1). 2: := L(W + AΩ)A=0 = L(W )Ω. 3: := qr(Y ).Q. 4: for := 1, . . . , do 5: 6: 7: 8: 9: end for 10: QW L(W ) := L(W + QB)B=0. 11: U, Σ, := truncSVD (cid:0)QW L(W ), r(cid:1) 12: return QU, Σ, := [B L(W + B)B=0] = L(W )Y. := qr(Y ).Q. := L(W + AY )A=0 = L(W )Y. := qr(Y ).Q. // (cid:0)nr2(cid:1) // (cid:0)mr2(cid:1) // (nr) // (cid:0)mr2(cid:1) // (cid:0)nr2(cid:1) // (cid:0)mr2(cid:1) 4.3 RiemannLoRA Optimization Algorithms In Algorithm 3, we present the SGD with Heavy-Ball [Polyak, 1964] version of the RiemannLoRA fine-tuning algorithm. The first 3 steps are dedicated to the computation of the initial guess for RiemannLoRA via BackPropRSVD for given layer weights and oversampling parameter p, that increases the accuracy of the singular approximation. The 4-th step initializes Heavy-Ball momentum matrices and exponentially smoothed momentum norms. The part from step 5 to step 18 encapsulates the Riemannian optimization cycle on the fixed-rank manifold. First of all, in the 6-th step, we calculate representation of the manifold point with different orthogonalization (see the equation (4)) required for the subsequent calculation of the Riemannian gradient components at the current point in one backward call (steps 7, 8). Then the algorithm transports the Heavy-Ball tangent direction to the current point via the Algorithm 2 that provides simple but effective implementation of (7). In the steps 9, 10, we compute the final optimization direction on the tangent space of the given point with Heavy-Ball momentum coefficient β. Steps from 11 to 14 are dedicated to accumulating the momentums norm, similar to how it is done in the standard Adam. The step 15 implements the SVD retraction step via vanilla truncated SVD (see (9)). The optimization cycle finalizes with saving the obtained minimization direction for momentum in the step 16 and calculation of the new point representation in the step 17. This approach has asymptotical complexity of O((m + n)r2 + r3) and (2(q + 1) + max_iters) amount of backward calls. Algorithm 2 VectorTransport Require: Tangent vector (A, B), Rm2r, Rn2r from other tangent space in 2r representation (see (6)), current tangent vector foot point factors AL, BR with orthonormal columns. Ensure: ( A, B) parameters of orthoprojection of (A, B) onto the current tangent space. Function: 1: return (A AR(A // (cid:0)(m + n)r2(cid:1) RA))(BBR), B(AAL) 6 Algorithm 3 RiemannLoRA Require: Weights Rmn, rank N, step size η, momentum coefficient β, oversampling parameter p, power-step parameter q, simulate_Adam, Adam momentum coefficient γ. Ensure: Tuning parameters Mr. Function: 1: AL, _, := BackPropRSVD(2r, p, q, L, ). 2: AL, := AL[ : , : r], B[ : , : ]. 3: := ALB. 4: AHB, BHB, SA, SB := 0. 5: for := 0, . . . , max_iters do 6: BR := qr (B) .Q. 7: // (cid:0)(m + n)r2(cid:1) // (cid:0)nr2(cid:1) // (mn) := Z1 (cid:0)W + Z1B + ALZ 2 := Z2L (cid:0)W + Z1B + ALZ 2 Aprev, Bprev := VectorTransport ((AHB, BHB), AL, BR) . A, := β Aprev + (1 β)(I ALA if simulate_Adam then (cid:1) Z1=0,Z2=B. (cid:1) Z1=0,Z2=B. ) A, β Bprev + (1 β) SA, SB := γ AF + (1 γ)SA, γ BF + (1 γ)SB A, := A/SA, B/SB // (cid:0)(m + n)r2(cid:1) // (cid:0)nr2(cid:1) // ((m + n)r) // ((m + n)r) end if U, Σ, := truncSVD AHB, BHB := [ A, AL], [BR, B] AL, := U, ΣV (cid:16)(cid:104) η A, AL (cid:105) (cid:104) BR, η + , (cid:105)(cid:17) // (cid:0)(m + n)r2 + r3(cid:1) // (cid:0)nr2(cid:1) 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: end for 19: return AL, B. Also note that each step of the vanilla LoRA can be considered as moving in certain subparts of the tangent plane, i.e., along the vectors ( A, 0) TW Mr and (0, B) TW Mr. In the RiemannLoRA we seek for the direction in the whole tangent space."
        },
        {
            "title": "5 Experiments",
            "content": "In this section, we also employ the term LOI (Locally Optimal Initialization), referring to the proposed initialization scheme described in Section 4.2. This is done to distinguish between using RiemannLoRA as an optimizer with zero initialization (as in basic LoRA) and RiemannLoRA-LOI, which is the proposed combination of initialization and optimization. We conduct series of LLM fine-tuning experiments for different tasks. All of the experiments were computed on NVIDIA V100-SXM2-32Gb GPU and NVIDIA A100-SXM-80Gb GPU. We ran all the experiments within 2000 GPU hours. 5.1 Commonsense reasoning fine-tuning The results were obtained for the benchmark (Clark et al. [2019, BoolQ], Bisk et al. [2020, PIQA], Sap et al. [2019, SIQA], Zellers et al. [2019, hellaswag], Sakaguchi et al. [2021, winogrande],Clark et al. [2018, ARC], Mihaylov et al. [2018, OBQA]) common reasoning. The structure of the dataset is described in Appendix B. In the following experiments we conduct fine-tuning procedures for multilayer perceptron (MLP) and attention layers of Llama 3.2 1b model (Dubey et al. [2024]). The commonsense reasoning tasks comprise of 8 sub-tasks, each of them contains predefined training and testing set. We follow the setting of Hu et al. [2023] and amalgamate the training datasets from all 8 tasks to create the final training dataset and conduct evaluations on the individual testing dataset for each task. 7 Figure 1: The train loss of fine-tuning Llama 3.2-1b vs optimization step using different SGD variants on Commonsense Reasoning benchmark. The Rprefix stands for Riemannian, the postfix -LOI stands for locally optimal initialization. LoRA rank is set to 16. In all experiments excpet for -LOI the factor in AB has orthonormal columns and is zero. 5.1.1 Fine-tuning optimizers comparison For every fine-tuning method we preselected suitable optimization step sizes. For RiemannLoRA Adam (see the Algorithm 3 with simulate_Adam flag enabled) we also selected the hyperparameter β, γ. The table 1 contains the accuracy of the trained via SGD without Heavy-Ball momentum models responses on the test dataset. In the frame of SGD-like optimizers the exploitation of the proposed Riemannian fine-tuning framework demonstrates performance increase with and without local optimal initialization: the RiemannLoRA with local optimal initialization outperforms LoRA, DoRA, RSLoRA. The standard derivation of the presented method is the least among all other methods. Table 2 contains results for Adam-like optimizers. The proposed method demonstrates the best (together with LoRA-LOI) mean metric value. It is also notable that our method produces least variance compared with all other approaches. Note also, that our Riemannian version is for simplified Adam optimizer. more advanced version, better aligned with Adam is subject for future work. Table 1: The average accuracy (in %) among 8 tasks of fine-tuned Llama 3.2-1b using different SGD variants, tested on Commonsense Reasoning benchmark. The Rprefix stands for Riemannian, the postfix -LOI stands for locally optimal initialization. LoRA rank is set to 16. In all experiments excpet for -LOI the factor in AB has orthonormal columns and is zero. Task Initialization BoolQ PIQA SIQA hellaswag winogrande ARC-E ARC-C OBQA All 46.0 Raw 67.90.4 LoRA 70.11.6 LoRA-LOI 70.00.8 RSLoRA 69.60.9 RiemannLoRA RiemannLoRA-LOI 65.20.4 79.40.4 75.60.4 87.30.1 62.40.4 79.90.8 63.61.9 73.80.5 73.40.3 40.1 64.00.2 64.90.4 64.50.2 65.10.4 50.3 69.60.4 71.22.2 68.10.8 69.11.5 61.9 75.41.7 77.04.2 76.51.5 74.41. 42.8 67.12.3 68.93.3 70.01.9 69.32.5 55.4 75.30.3 76.80.3 77.20.3 77.70.3 25.8 82.20.1 84.10.1 86.30.1 85.80.2 50.0 53.01.0 56.70.6 58.20.5 58.50.4 41.8 56.50.6 61.13.6 58.62.9 56.91.3 Table 2: The average accuracy (in %) among 8 tasks of fine-tuned Llama 3.2-1b using different Adam variants, tested on Commonsense Reasoning benchmark. The Rprefix stands for Riemannian, the postfix -LOI stands for locally optimal initialization. LoRA rank is set to 16. Task Initialization BoolQ PIQA SIQA hellaswag winogrande ARC-E ARC-C OBQA All 25.8 50.3 55.4 40.1 Raw 87.20.5 74.90.3 65.41.7 79.51.1 LoRA 87.70.6 65.72.4 75.70.6 65.61.4 81.30.9 LoRA-LOI 63.52.6 87.50.6 74.60.6 79.90.8 66.01.8 LoRA-QR 63.10.5 87.60.3 75.60.9 80.10.4 66.40.6 Pissa 62.61.0 79.50.4 87.40.3 76.20.4 65.90.7 RiemannLoRA 63.70.8 81.00.4 76.60.4 88.20.3 RiemannLoRA-LOI 65.80.2 46.0 42.8 61.9 75.50.5 73.30.7 62.41.8 79.30.6 75.20.9 74.30.9 77.91.0 73.71.0 75.60.8 79.02.3 73.70.9 75.01.1 77.64.0 78.21.7 73.70.4 75.70.8 78.81.4 64.61.7 76.10.7 74.30. 41.8 62.31.2 65.01.7 63.01.8 64.32.6 64.31.7 50.0 8 Figure 2: Comparison of text and image similarities for LoRA and our method at different training steps. Larger dots indicate higher training step Figure 3: Visual results for Subject-driven generation on 600 training step 5.2 Subject-driven generation Subject-driven generation [Ruiz et al., 2023, Gal et al., 2023] is task in which the user provides several reference photos of an object, called concept, and uses diffusion model to generate this concept with certain conditions (e.g., textual prompt). One way to solve this task is to fine-tune pre-trained diffusion model using this small set of reference images. However, this technique leads to degradation in understanding of the conditions and to fast overfitting of the concept. Furthermore, it requires high computational cost due to the large number of trainable parameters. This is why previous works, such as [Qiu et al., 2023, Liu et al., 2024, Hu et al., 2022, Tewel et al., 2023, Han et al., 2023, Gorbunov et al., 2024], propose training only lightweight parameterization for the base model. In this section, we demonstrate the performance of our parameterization in this task. In our experiments, we used Stable Diffusion 2 [Rombach et al., 2022] as the base model. We choose LoRA Hu et al. [2022] as baseline and train both models with ranks of 4, 8 and 16. We predict the parameterization of the q, k, v, and out.0 matrices in all attention layers. The Dreambooth dataset [Ruiz et al., 2023] was used in all our experiments. LoRA was trained using the Adam optimizer, while our model was trained using our version of the Adam optimizer with the Riemannian optimization (see the Algorithm 3 with simulate_Adam flag enabled). We used the CLIP model to measure both the text and image similarities of the generated images. Figure 2 shows the training curves of these metrics, where larger dots indicate higher training step. As can be seen, our method requires fewer steps to learn the concept while preserving the appropriate text similarity. This is also confirmed by the visual comparison presented in Figure 3, for which training step of 600 was used to generate images. More quantitative and visual comparisons can be found in the Appendix and Appendix E."
        },
        {
            "title": "6 Limitations",
            "content": "Since the presented algorithm is modification of LoRA it inherits the vanilla LoRA limitations, e.g., the problem of underperforming in comparison to full fine-tuning (see [Biderman et al., 2024]), potentially larger amount of learning parameters in contrast to some other approaches, see, e.g., [Kopiczko et al., 2024]. One may also think that our method is constrained by the particular choice of the fixed rank manifold, but generally speaking the approach remains applicable as long as the geometry of the adapter is described by smooth manifold."
        },
        {
            "title": "7 Conclusion",
            "content": "In this work, we propose new Riemannian framework that addresses the ambiguities inherent in LoRA. In particular, our method is parametrization free and selects the initialization based on the geometric interpretation of Riemannian manifolds. We observe that the proposed method boosts the metric values for different optimization strategies, has small variance and also speeds up convergence in some scenarios. As future work, it would be interesting to explore other optimization strategies and manifolds based on our framework."
        },
        {
            "title": "References",
            "content": "P.-A. Absil and I. V. Oseledets. Low-rank retractions: survey and new results. Computational Optimization and Applications, 62(1):529, 2015. P.-A. Absil, R. Mahony, and R. Sepulchre. Optimization algorithms on matrix manifolds. In Optimization Algorithms on Matrix Manifolds. Princeton University Press, 2009. C. G. Baker. Riemannian manifold trust-region methods with applications to eigenproblems. The Florida State University, 2008. D. Biderman, J. P. Portes, J. J. G. Ortiz, M. Paul, P. Greengard, C. Jennings, D. King, S. Havens, V. Chiley, J. Frankle, C. Blakeney, and J. P. Cunningham. LoRA learns less and forgets less. Trans. Mach. Learn. Res., 2024, 2024. URL https://openreview.net/forum?id=aloEru2qCG. Y. Bisk, R. Zellers, J. Gao, Y. Choi, et al. PIQA: Reasoning about Physical Commonsense in Natural Language. In Proceedings of the AAAI conference on artificial intelligence, number 05 in 34, pages 74327439, 2020. N. Boumal. An introduction to optimization on smooth manifolds. Cambridge University Press, 2023. T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:18771901, 2020. C. Clark, K. Lee, M. Chang, T. Kwiatkowski, M. Collins, and K. Toutanova. BoolQ: Exploring the surprising difficulty of natural yes/no questions. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 29242936. Association for Computational Linguistics, 2019. doi: 10.18653/ V1/N19-1300. URL https://doi.org/10.18653/v1/n19-1300. P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think you have solved question answering? try ARC, the AI2 reasoning challenge. CoRR, abs/1803.05457, 2018. URL http://arxiv.org/abs/1803.05457. A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan, A. Goyal, A. Hartshorn, A. Yang, A. Mitra, A. Sravankumar, A. Korenev, A. Hinsvark, A. Rao, A. Zhang, A. Rodriguez, A. Gregerson, A. Spataru, B. Rozière, B. Biron, B. Tang, B. Chern, C. Caucheteux, C. Nayak, C. Bi, C. Marra, C. McConnell, C. Keller, C. Touret, C. Wu, C. Wong, C. C. Ferrer, C. Nikolaidis, D. Allonsius, D. Song, D. Pintz, D. Livshits, D. Esiobu, D. Choudhary, D. Mahajan, D. Garcia-Olano, D. Perino, D. Hupkes, E. Lakomkin, E. AlBadawy, E. Lobanova, E. Dinan, E. M. Smith, F. Radenovic, F. Zhang, G. Synnaeve, G. Lee, 10 G. L. Anderson, G. Nail, G. Mialon, G. Pang, G. Cucurell, H. Nguyen, H. Korevaar, H. Xu, H. Touvron, I. Zarov, I. A. Ibarra, I. M. Kloumann, I. Misra, I. Evtimov, J. Copet, J. Lee, J. Geffert, J. Vranes, J. Park, J. Mahadeokar, J. Shah, J. van der Linde, J. Billock, J. Hong, J. Lee, J. Fu, J. Chi, J. Huang, J. Liu, J. Wang, J. Yu, J. Bitton, J. Spisak, J. Park, J. Rocca, J. Johnstun, J. Saxe, J. Jia, K. V. Alwala, K. Upasani, K. Plawiak, K. Li, K. Heafield, K. Stone, and et al. The Llama 3 herd of models. CoRR, abs/2407.21783, 2024. doi: 10.48550/ARXIV.2407.21783. URL https://doi.org/10.48550/arXiv.2407.21783. J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(7), 2011. C. Eckart and G. Young. The approximation of one matrix by another of lower rank. Psychometrika, 1(3):211218, 1936. R. Gal, Y. Alaluf, Y. Atzmon, O. Patashnik, A. H. Bermano, G. Chechik, and D. Cohen-Or. An image is worth one word: Personalizing text-to-image generation using textual inversion. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/forum?id=NAQvF08TcyG. M. Gorbunov, N. Yudin, V. Soboleva, A. Alanov, A. Naumov, and M. Rakhuba. Group and shuffle: Efficient structured orthogonal parametrization. In Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024, 2024. N. Halko, P. G. Martinsson, and J. A. Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. SIAM Review, 53(2):217288, 2011. doi: 10.1137/090771806. URL https://doi.org/10.1137/090771806. L. Han, Y. Li, H. Zhang, P. Milanfar, D. Metaxas, and F. Yang. Svdiff: Compact parameter space for diffusion fine-tuning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 73237334, 2023. S. Hayou, N. Ghosh, and B. Yu. LoRA+: Efficient Low Rank Adaptation of Large Models. In Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024. URL https://openreview.net/forum?id=NEv8YqBROO. S. Holtz, T. Rohwedder, and R. Schneider. On manifolds of tensors of fixed tt-rank. Numerische Mathematik, 120(4):701731, 2012. E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen, et al. LoRA: Low-Rank Adaptation of Large Language Models. ICLR, 1(2):3, 2022. J. Hu, J. Cui, L. Lin, Z. Wen, Q. Li, et al. Retraction-free optimization over the Stiefel manifold with application to the loRA fine-tuning, 2024. Z. Hu, L. Wang, Y. Lan, W. Xu, E. Lim, L. Bing, X. Xu, S. Poria, and R. K. Lee. LLM-adapters: An adapter family for parameter-efficient fine-tuning of large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 52545276. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.EMNLP-MAIN.319. URL https://doi.org/10.18653/v1/ 2023.emnlp-main.319. D. Kingma and J. Ba. Adam: method for stochastic optimization. International Conference on Learning Representations, 12 2014. D. J. Kopiczko, T. Blankevoort, and Y. M. Asano. VeRA: Vector-based random matrix adaptation. In The Twelfth International Conference on Learning Representations, 2024. URL https:// openreview.net/forum?id=NjNfLdxr3A. J. M. Lee. Smooth manifolds. Springer, 2003. A. S. Lewis and J. Malick. Alternating projections on manifolds. Mathematics of Operations Research, 33(1):216234, 2008. 11 W. Liu, Z. Qiu, Y. Feng, Y. Xiu, Y. Xue, L. Yu, H. Feng, Z. Liu, J. Heo, S. Peng, Y. Wen, M. J. Black, A. Weller, and B. Schölkopf. Parameter-efficient orthogonal finetuning via butterfly factorization. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=7NzgkEdGyr. I. Loshchilov and F. Hutter. Decoupled Weight Decay Regularization. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019. URL https://openreview.net/forum?id=Bkg6RiCqY7. F. Meng, Z. Wang, and M. Zhang. PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models. Advances in Neural Information Processing Systems, 37:121038 121072, 2024. T. Mihaylov, P. Clark, T. Khot, and A. Sabharwal. Can suit of armor conduct electricity? new dataset for open book question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 23812391. Association for Computational Linguistics, 2018. doi: 10.18653/V1/D18-1260. URL https://doi.org/10.18653/v1/d18-1260. Z. Mo, L.-K. Huang, and S. J. Pan. Parameter and Memory Efficient Pretraining via Low-rank Riemannian Optimization. In The Thirteenth International Conference on Learning Representations, 2025. A. Novikov, M. Rakhuba, and I. Oseledets. Automatic differentiation for Riemannian optimization on low-rank matrix and tensor-train manifolds. SIAM Journal on Scientific Computing, 44(2): A843A869, 2022. U. Parkina and M. Rakhuba. Coala: Numerically stable and efficient framework for context-aware low-rank approximation, 2025. URL https://arxiv.org/abs/2507.07580. B. T. Polyak. Some methods of speeding up the convergence of iteration methods. Ussr computational mathematics and mathematical physics, 4(5):117, 1964. Z. Qiu, W. Liu, H. Feng, Y. Xue, Y. Feng, Z. Liu, D. Zhang, A. Weller, and B. Schölkopf. Controlling text-to-image diffusion by orthogonal finetuning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=K30wTdIIYc. H. Robbins and S. Monro. stochastic approximation method. The annals of mathematical statistics, pages 400407, 1951. R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1068410695, June 2022. N. Ruiz, Y. Li, V. Jampani, Y. Pritch, M. Rubinstein, and K. Aberman. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2250022510, 2023. K. Sakaguchi, R. L. Bras, C. Bhagavatula, and Y. Choi. WinoGrande: An Adversarial Winograd Schema Challenge at Scale. Communications of the ACM, 64(9):99106, 2021. M. Sap, H. Rashkin, D. Chen, R. L. Bras, and Y. Choi. SocialIQa: Commonsense Reasoning about Social Interactions. CoRR, abs/1904.09728, 2019. URL http://arxiv.org/abs/1904.09728. Y. Tewel, R. Gal, G. Chechik, and Y. Atzmon. Key-locked rank one editing for text-to-image personalization. In ACM SIGGRAPH 2023 Conference Proceedings, pages 111, 2023. T. Tieleman. Lecture 6.5-rmsprop: Divide the gradient by running average of its recent magnitude. COURSERA: Neural networks for machine learning, 4(2):26, 2012. H. Touvron, T. Lavril, G. Izacard, X. Martinet, M. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample. LLaMA: Open and efficient foundation language models. CoRR, abs/2302.13971, 2023a. doi: 10.48550/ARXIV.2302. 13971. URL https://doi.org/10.48550/arXiv.2302.13971. 12 H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, D. Bikel, L. Blecher, C. Canton-Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami, N. Goyal, A. Hartshorn, S. Hosseini, R. Hou, H. Inan, M. Kardas, V. Kerkez, M. Khabsa, I. Kloumann, A. Korenev, P. S. Koura, M. Lachaux, T. Lavril, J. Lee, D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra, I. Molybog, Y. Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic, S. Edunov, and T. Scialom. Llama 2: Open foundation and fine-tuned chat models. CoRR, abs/2307.09288, 2023b. doi: 10.48550/ARXIV.2307.09288. URL https://doi.org/10.48550/arXiv.2307.09288. N. Trendafilov and M. Gallo. Multivariate data analysis on matrix manifolds. Springer, 2021. B. Vandereycken. Low-rank matrix completion by Riemannian optimization. SIAM Journal on Optimization, 23(2):12141236, 2013. H. Wang, Y. Li, S. Wang, G. Chen, and Y. Chen. MiLoRA: Harnessing minor singular components for parameter-efficient LLM finetuning. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2025 - Volume 1: Long Papers, Albuquerque, New Mexico, USA, April 29 - May 4, 2025, pages 48234836. Association for Computational Linguistics, 2025. doi: 10.18653/V1/ 2025.NAACL-LONG.248. URL https://doi.org/10.18653/v1/2025.naacl-long.248. S. Wang, L. Yu, and J. Li. LoRA-GA: Low-rank adaptation with gradient approximation. Advances in Neural Information Processing Systems, 37:5490554931, 2024. S. Wisdom, T. Powers, J. Hershey, J. Le Roux, and L. Atlas. Full-Capacity Unitary Recurrent Neural Networks. Advances in neural information processing systems, 29, 2016. Y. Yang, X. Li, Z. Zhou, S. Song, J. Wu, L. Nie, and B. Ghanem. CorDA: Context-oriented decomposition adaptation of large language models for task-aware parameter-efficient fine-tuning. Advances in Neural Information Processing Systems, 37:7176871791, 2024. L. Yu, W. Jiang, H. Shi, J. Yu, Z. Liu, Y. Zhang, J. T. Kwok, Z. Li, A. Weller, and W. Liu. Metamath: Bootstrap your own mathematical questions for large language models. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/forum?id=N8N0hgNDRt. R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi. HellaSwag: Can machine really finish your sentence? In Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28August 2, 2019, Volume 1: Long Papers, pages 47914800. Association for Computational Linguistics, 2019. doi: 10.18653/V1/P19-1472. URL https://doi.org/10.18653/v1/p19-1472. F. Zhang and M. Pilanci. Riemannian preconditioned loRA for fine-tuning foundation models. In Proceedings of the 41st International Conference on Machine Learning, ICML24. JMLR.org, 2024."
        },
        {
            "title": "A Inital point search",
            "content": "Proof. In order to represent the optimization task (12) in more simple way, we will use slightly different formula for the projection of the full loss gradient onto the tangent space of the fixed-rank manifold. Let = ALB = AB Mr, and the tangent space is parametrized as follows + AL TW Mr = { AB Rnr, Rmr, A = 0}, then one may derive an orthogonal projection formula for any matrix (see, e.g. [Boumal, 2023, eq. 7.53]) PTW Mr = (I ALA )Z(I BRB ) TW Mr. 13 As the tangent space is linear space, the operation of orthogonal projection can be written as an optimization task PTW Mr = argmin ξTW Mr ξ2 . (15)"
        },
        {
            "title": "Since",
            "content": "L2 = PTW Mr L2 + PTW Mr L2 , so the optimization task (12) is equivalent to PTW Mr L2 min , which, in turn, using (15) is equivalent to the task min min ξTW Mr ξ2 . Due to the fact that every vector of the tangent space is an element of set of all matrices with 2r-bounded rank M2r, one may use the Eckart-Young-Mirsky theorem (see [Eckart and Young, 1936]) to obtain the following lower bound: PTW Mr L2 truncSVD (L, 2r)F , Mr, ξ TW Mr. (16) But it is possible to ensure (0) the equality. One may take Mr and ξ TW (0) Mr which turn the inequality (16) into = AL(αB) = αU1,rV r,2r = (αA)B , α R, (0) ξ = AB + AL = (Ur,2rΣr,2r) AAL = 0. So the initialization (0) Note, that tangent space TW (0) the Riemannian gradient equal to truncSVD (L, 2r). ensures that truncSVD (L, 2r) lies in the Mr, which means that the first step of the RiemannLoRA Algorithm 3 will get + AL (Σ1,rV1,r) = truncSVD (L, 2r). To generalize the result, we should change the parametrization of the tangent space. Because of the fact that each of the tangent vectors ξ lies in M2r, we may use an unconstrained skeleton decomposition (without constraints for and AL): (cid:21) ξ = (cid:2)A, (cid:3) (cid:20) B = (cid:2)A, (cid:3) = (cid:2)A, (cid:21) (cid:20) B (cid:3) I2r (cid:21) (cid:20) B = , R2r2r, det = 0. Representing and its inverse as block matrices: = (cid:21) (cid:20)S11 S12 S21 S22 , S1 = (cid:21) (cid:20)C11 C12 C21 C22 , one arrives to 13: ξ = (cid:2)A, (cid:3) (cid:21) (cid:20)C11 C12 C21 C22 (cid:21) (cid:2) B (cid:3) , (cid:20)S11 S12 S21 S22 (cid:21) (cid:20)S11 (cid:3) , W (0) = (cid:2)A [C21 C22] (cid:2) B (cid:3) . To derive (14), one may take to be block-diagonal with S11 = αIr, S22 = Ir, α R."
        },
        {
            "title": "B Dataset",
            "content": "B.1 Commonsense reasoning Following the approach of Hu et al. [2023], we combine the training datasets from all 8 tasks to form the final training set and evaluate performance on each tasks individual test dataset. We adopt queries structure from Hu et al. [2023] to Llama 3.2 instruct template. The prompt structure is demonstrated in Table 3. 14 Table 3: The structure of the queries for the Commonsense reasoning dataset Task BoolQ PIQA SIQA hellaswag winogrande Role system user assistant system user assistant system user assistant system user assistant system user assistant ARC-e & ARC-c system OBQA user assistant system user assistant Fine-tuning Data Template Please answer the following question with True or False. Follow the answer format, full answer not needed. Question: [QUESTION] Answer format: True/False The correct answer is [ANSWER] Please choose the correct solution to the question. Follow the answer format, full answer not needed. Question: [QUESTION] Solution1: [SOLUTION_1] Solution2: [SOLUTION_2] Answer format: Solution1/Solution2 The correct answer is [ANSWER] Please choose the correct answer to the question based on the context provided. Follow the answer format, full answer not needed. Context: [CONTEXT] Question: [QUESTION] A: [ANSWER_A] B: [ANSWER_B] C: [ANSWER_C] Answer format: A/B/C The correct answer is [ANSWER] Please choose the correct ending to complete the given sentence. Follow the answer format, full answer not needed. [ACTIVITY_lABEL]: [CONTEXT] Ending1: [ENDING_1] Ending2: [ENDING_2] Ending3: [ENDING_3] Ending4: [ENDING_4] Answer format: Ending1/Ending2/Ending3/Ending4 The correct answer is [ANSWER] Please choose the correct answer to fill in the blank to complete the given sentence. Follow the answer format, full answer not needed. Sentence: [SENTENCE] Option1: [OPTION_1] Option2: [OPTION_2] Answer format: Option1/Option2 The correct answer is [ANSWER] Please choose the correct answer to the question. Follow the answer format, full answer not needed. Question: [QUESTION] Answer1: [ANSWER_1] Answer2: [ANSWER_2] Answer3: [ANSWER_3] Answer4: [ANSWER_4] Answer format: Answer1/Answer2/Answer3/Answer4 The correct answer is [ANSWER] Please choose the correct answer to the question. Follow the answer format, full answer not needed. Question: [QUESTION] Answer1: [ANSWER_1] Answer2: [ANSWER_2] Answer3: [ANSWER_3] Answer4: [ANSWER_4] Answer format: Answer1/Answer2/Answer3/Answer4 The correct answer is [ANSWER] 15 B.2 GSM8K and MetaMathQA The model fine-tuning results on MetaMathQA dataset presented by Yu et al. [2024] are demonstrated in Section E.2. The full dataset can be found here: https://huggingface.co/datasets/ meta-math/MetaMathQA. For fine-tuning, we used the MetaMathQA dataset, with validation conducted on GSM8Ks test set. For training and validation, we employed the queries declared in Table 4. Table 4: The structure of the queries for the MetaMathQA dataset Task Role Fine-tuning Data Template MetaMathQA system GSM8K user assistant system user assistant Below is an instruction that describes math task. Solve the problems and use \"The answer is:\" at the end of your answer. [QUERY] [RESPONSE] Below is an instruction that describes math task. Solve the problems and use \"The answer is:\" at the end of your answer. [QUESTION] [ANSWER] Following the validation approach in [Yu et al., 2024], we treated all text after the The answer is: as the models answer. The resulting text was additionally cleared of LaTeX symbols using the regular expression python package. First of all, \"$\" and backtick signs are removed then we use the following regexp boxed{([ˆ{}]*)} to get values."
        },
        {
            "title": "C Hyperparameters",
            "content": "For every method, we carefully preselected learning rate (optimization step size). For the RiemannLoRA with simulate_Adam flag enabled we also preselected parameters β and γ (see Algorithm 3). For the benchmark on the Commonsense reasoning dataset the hyperparameters are exhibited in Table 5 for SGD-like methods and in Table 6 for Adam-like methods. We selected β = 0.7, γ = 0.9 for the RiemannLoRA with simulate_Adam flag enabled without LOI and β = 0.85, γ = 0.995 for this algorithm with LOI. Table 5: The parameters for different SGD variants (RiemannLoRA with simulate_Adam flag disabled) for fine-tuning on the Commonsense reasoning dataset Optimizer learning rate LoRA LoRA-LOI RSLoRA RiemannLoRA RiemannLoRA-LOI 0.1 0.06 0.1 0.1 0. Table 6: The parameters for different Adam variants (RiemannLoRA with simulate_Adam flag enabled) for fine-tuning on the Commonsense reasoning dataset Optimizer LoRA LoRA-LOI LoRA-QR Pissa RiemannLoRA RiemannLoRA-LOI learning rate 2 104 2 104 2 104 5 105 0.04 0.04 16 For the benchmark on the MetaMathQA dataset the hyperparameters are exhibited in Table 7 for SGDlike and Adam-like methods simultaneously. We selected β = 0.7, γ = 0.9 for the RiemannLoRA with simulate_Adam flag enabled without LOI and β = 0.85, γ = 0.995 for this algorithm with LOI. Table 7: The parameters for different SGD and Adam variants (RiemannLoRA with simulate_Adam flag disabled and enabled correspondingly) for fine-tuning on the MetaMathQA dataset"
        },
        {
            "title": "Optimizer",
            "content": "LoRA LoRA-LOI DoRA RiemannLoRA RiemannLoRA-LOI"
        },
        {
            "title": "SGD",
            "content": "learning rate Adam 3 104 7.5 105 1 104 0.02 0.01 0.05 0.08 0.08 0.08 0.08 The non-tuned hyperparameters used for experiments on the Commonsense Reasoning and MetaMathQA datasets are presented in 8. Table 8: Other non-tuned hyperparameter configurations for experiments on Commonsense reasoning and MetaMathQA datasets Dataset Hyperparameters Rank Dropout LR Scheduler Batch size Epochs Warmup ratio Commonsense reasoning MetaMathQA 16 0.05 Linear 64 0.1 2 1 Subject-driven generation To evaluate the effectiveness of our parameterization for subject-driven generation, two sets of experiments were conducted: one for the Adam optimizer and one for the SGD optimizer. Details for both sets of experiments are provided below. Training details We used Stable Diffusion-2-base model for all experiments. For the Adam optimizer setup, we used learning rate of 2e-5 for LoRA and 2e-3 for our method. The difference in learning rates is due to the fact that our method uses exponentially smoothed gradient norms as the second momentum, meanwhile the vanilla Adam uses elementwise matrix division by the second momentum. The betas = (0.9, 0.999) are identical for both methods. For the SGD setup, we used the same learning rate of 10 for both LoRA and our method. We set = 15 and = rank in all variations of our approach. We used batch size of 4 in all our experiments. Evaluation details We used the DreamBooth dataset, which contains 25 different prompts and 30 various concepts. Due to computational costs, we only used half of the proposed concepts: can, candle, cat, cat2, colorful_sneaker, dog2, dog3, dog5, dog6, dog7, dog8, fancy_boot, grey_sloth_plushie, pink_sunglasses, vase. To measure the similarity between the original concept and the generated images, we used BaseIS: we synthesized 30 images for the base prompt photo of V* and measured the average pairwise cosine similarity with reference photos of the concept using the CLIP ViTB/32 model. To check the correspondence between the generated images and the textual prompts, we calculated Text Similarity (TS): we evaluated each concept with each of 25 prompts, synthesizing 10 images per prompt, and calculating the average pairwise cosine similarity with the prompts using the CLIP ViTB/32 model. 17 Figure 4: Comparison of text and image similarities for LoRA and our method at different training steps with SGD optimizers. Larger dots indicate higher training step Figure 5: Additional visual comparison of our method and LoRA in Adam optimizers setup, checkpoint 18 Figure 6: Additional visual comparison of our method and LoRA in Adam optimizers setup, checkpoint 1400 Results Figures 2 and 3 (from the main text) represent the quantitative and qualitative results for the Adam setup. Figures 5 and 6 also present additional visual results for the Adam setup with checkpoints at 600 and 1400 steps. Figure 4 shows the metrics for the SGD setup experiments. In this figure we do not report metrics at the 2000 step due to both original LoRA and our method starting to generate noisy images and dropping metrics significantly. Figure 7 contains visual comparison of the SGD setup for various prompts and concepts at 1000 step. Both the visual and numerical results show that our method outperforms LoRA in both the Adam and SGD setups. This is especially evident in experiments with SGD, which naturally generalizes to the Riemannian setting. However, there is also an increase in image similarity and faster concept learning in the Adam setup."
        },
        {
            "title": "E Additional experimental results",
            "content": "E.1 Ablation study on initialization The fine-tuning optimization was carried out by AdamW (Loshchilov and Hutter [2019]) First of the first, for every approach tested we preselected suitable optimization step sizes. The list of all selected hyper-parameters for each method is specified in the Appendix C. Table 9 contains the accuracy of the trained models responses on the test dataset. The notation LoRA-A in the table 19 Figure 7: Additional visual comparison of our method and LoRA in SGD optimizers setup, checkpoint 1000 means the utilization of the vanilla LoRA with non-zero A, the notation LoRA-B means the same with non-zero B, the notations Stiefel-A and Stiefel-B indicate vanilla LoRA with orthonormal initialization (for matrix and respectively). The naming of Stiefel-both involves taking the factors A, with orthonormal columns and with initialization like in (1). E.2 Math In addition to the experiments on Commonsense reasoning, we fine-tuned Llama 3.2 1b on 128k subset (2000 steps with batch size equal to 64) of the MetaMathQA dataset (see Section B.2). The accuracy is reported on the GSM8K evaluation set. Table 10 contains the accuracy of the trained via SGD without Heavy-Ball momentum models responses on the test dataset. 20 Table 9: The average accuracy among 8 tasks of fine-tuned Llama 3.2-1b via Adam using different LoRA initialization variants, tested on Commonsense reasoning benchmark. LOI stands for locally optimal initialization. LoRA rank is set to 16."
        },
        {
            "title": "Task\nInitialization",
            "content": "Raw LoRA-A LoRA-B Pissa Stiefel-A Stiefel-B Stiefel-both LOI LoRA-GA BoolQ PIQA SIQA hellawinoARCARC- OBQA All swag grande 40.1 66.2 65.9 66.4 65.4 66.4 66.3 65.6 65.4 55.4 80.2 77.9 80.1 79.5 80.6 79.7 81.3 77.1 50.3 76.0 74.2 75.6 74.9 76.0 75.8 75.7 74. 25.8 87.0 82.9 87.6 87.2 87.5 86.4 87.7 84.5 50.0 65.1 61.2 63.1 62.4 64.3 64.0 65.7 58.3 61.9 78.4 73.9 77.6 79.3 78.5 78.3 77.9 75.4 41.8 63.6 60.6 64.3 62.3 64.9 62.4 65.0 61. 42.8 46.0 76.3 74.1 72.2 71.1 75.0 73.7 75.5 73.3 74.6 74.1 73.9 73.4 75.2 74.3 72.2 71.2 Table 10: The accuracy (in %) of fine-tuned Llama 3.2-1b using different SGD variants, tested on GSM8K and Commonsense Reasoning benchmarks. The Rprefix stands for Riemannian, the postfix -LOI stands for locally optimal initialization. LoRA rank is set to 16. In all experiments excpet for -LOI the factor in AB (for the first step) has orthonormal columns and is zero. Setup GSM8K accuracy CR accuracy LoRA LoRA-LOI DoRA RiemannLoRA RiemannLoRA-LOI 46.8 50.0 42.5 49.3 51. 67.9 70.1 60.4 69.6 73."
        }
    ],
    "affiliations": [
        "AIRI, HSE University",
        "HSE University",
        "MIPT, ISPRAS"
    ]
}