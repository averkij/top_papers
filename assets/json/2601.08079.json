{
    "paper_title": "MemoBrain: Executive Memory as an Agentic Brain for Reasoning",
    "authors": [
        "Hongjin Qian",
        "Zhao Cao",
        "Zheng Liu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate and strain the bounded working context of large language models. Without explicit memory mechanisms, such accumulation disrupts logical continuity and undermines task alignment. This positions memory not as an auxiliary efficiency concern, but as a core component for sustaining coherent, goal-directed reasoning over long horizons. We propose MemoBrain, an executive memory model for tool-augmented agents that constructs a dependency-aware memory over reasoning steps, capturing salient intermediate states and their logical relations. Operating as a co-pilot alongside the reasoning agent, MemoBrain organizes reasoning progress without blocking execution and actively manages the working context. Specifically, it prunes invalid steps, folds completed sub-trajectories, and preserves a compact, high-salience reasoning backbone under a fixed context budget. Together, these mechanisms enable explicit cognitive control over reasoning trajectories rather than passive context accumulation. We evaluate MemoBrain on challenging long-horizon benchmarks, including GAIA, WebWalker, and BrowseComp-Plus, demonstrating consistent improvements over strong baselines."
        },
        {
            "title": "Start",
            "content": "MemoBrain: Executive Memory as an Agentic Brain for Reasoning Hongjin Qian1, Zhao Cao2, Zheng Liu1* 1 Beijing Academy of Artificial Intelligence 2 Gaoling School of Artificial Intelligence, Renmin University of China {chienqhj,zhengliu1026}@gmail.com 6 2 0 2 2 1 ] . [ 1 9 7 0 8 0 . 1 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate and strain the bounded working context of large language models. Without explicit memory mechanisms, such accumulation disrupts logical continuity and undermines task alignment. This positions memory not as an auxiliary efficiency concern, but as core component for sustaining coherent, goal-directed reasoning over long horizons. We propose MemoBrain, an executive memory model for tool-augmented agents that constructs dependency-aware memory over reasoning steps, capturing salient intermediate states and their logical relations. Operating as co-pilot alongside the reasoning agent, MemoBrain organizes reasoning progress without blocking execution and actively manages the working context. Specifically, it prunes invalid steps, folds completed sub-trajectories, and preserves compact, high-salience reasoning backbone under fixed context budget. Together, these mechanisms enable explicit cognitive control over reasoning trajectories rather than passive context accumulation. We evaluate MemoBrain on challenging longhorizon benchmarks, including GAIA, WebWalker, and BrowseComp-Plus, demonstrating consistent improvements over strong baselines. Our codes are in this repository."
        },
        {
            "title": "Introduction",
            "content": "Large language models (LLMs) have advanced rapidly in recent years, enabling increasingly complex applications in reasoning, decision making, and information seeking (Zhao et al., 2024; Wang et al., 2024). Tool-augmented agent frameworks further extend these capabilities by interleaving reasoning with calls to external tools such as search *Corresponding author. 1 engines and code executors (Zhang et al., 2025a; Qian et al., 2025a). However, long-horizon toolintegrated interactions inevitably accumulate contextual information, including intermediate reasoning traces and tool-generated artifacts (Ye et al., 2025). As context grows, the bounded working context of LLMs becomes strained, allowing transient information to dominate and distract from task-relevant evidence, leading to cognitive overload and degraded task alignment (Hu et al., 2025). As result, introducing explicit memory mechanisms has become widely recognized as critical factor in scaling agent-based frameworks to complex, long-horizon tasks (Zhang et al., 2025b). Existing agent memory mainly takes two forms. Cross-task memory focuses on persistence across tasks, accumulating experience, preferences, and user-specific knowledge to support personalization, adaptation, and learning from past interactions (Gao et al., 2025). Long-term memory, in contrast, is designed to retain and organize information over long interactions, such as long-term dialogue or large collections of documents, and is commonly instantiated through summarization, parametric storage, or graph-based representations (Xu et al., 2025; Yan et al., 2025a; Yu et al., 2025; Kang et al., 2025). While effective at preserving and accessing prior information, both forms are not natively adaptive to complex reasoning settings, where memory must actively track reasoning progress, capture dependencies among intermediate conclusions, and manage information flow to sustain coherence and task alignment. In this work, we focus on distinct form of memory, which we term executive memory. Executive memory is task-specific, in-process memory mechanism dedicated to complex reasoning in tool-augmented agent systems, initialized from scratch for each task and evolving online alongside the reasoning trajectory. Unlike cross-task memory, it does not persist beyond task completion Figure 1: MemoBrain asynchronously abstracts transient reasoning sessions into compact, dependency-aware memory units and maintains global reasoning memory. Upon reaching the memory budget, it constructs memory-managed context by folding or flushing past information, enabling coherent long-horizon reasoning. or encode persistent priors. Unlike long-term memory, it is not merely conditioning context that is incrementally maintained, but an actively managed representation that adapts to the evolving structure of the reasoning process. From an engineering perspective, executive memory functions as an explicit context control mechanism, delivering task-relevant information to the reasoning agent in just-in-time manner under bounded context budget. From cognitive perspective, it serves an executive role by modeling logical dependencies among reasoning steps, maintaining global and hierarchical view of task progress, and guiding subsequent actions to preserve coherent, goal-directed reasoning. growing body of recent work has highlighted the importance of managing large and evolving contexts in complex reasoning tasks. Representative approaches reduce context overhead by abstracting or compressing intermediate reasoning steps (Wu et al., 2025c; Ye et al., 2025), while others decompose tasks into auxiliary subtasks whose outcomes are summarized and reintegrated (Li et al., 2025d,c). These methods have shown strong empirical gains on long-horizon reasoning benchmarks, underscoring the practical value of memory from an engineering perspective. However, most existing approaches frame memory as an efficiencyoriented mechanism for context reduction, leaving it largely passive with respect to global task alignment, trajectory-level control, and cognitive modeling of the reasoning process (Hu et al., 2025). These observations suggest that sustaining taskaligned reasoning under bounded context budget requires explicit control over information flow. Accordingly, we treat memory as framework-level component that collaborates with the reasoning agent, rather than an internal byproduct of single model. Based on this perspective, we propose MemoBrain, an executive memory model that operates in copilot-like manner alongside the reasoning agent. MemoBrain maintains global memory over the full reasoning trajectory and exerts executive control over the working context, delivering just-in-time, task-relevant information while suppressing unnecessary cognitive load. By controlling what information is exposed at each step, MemoBrain enables goal-directed reasoning over long horizons under bounded context budget. As illustrated in Figure 1, MemoBrain organizes memory around two complementary processes: memory construction and memory management. During memory construction, completed reasoning episodes are incrementally abstracted from transient execution sessions into compact memory units, referred to as thoughts. Each thought encodes the subproblem addressed, the information or tools used, and the resulting outcome, and is linked to prior thoughts through explicit dependency relations. This process yields structured, dependencyaware trajectory memory that preserves the logical backbone of long-horizon reasoning while discarding short-lived execution artifacts. Building on this global trajectory memory, MemoBrain performs active context management for the reasoning agent. Under fixed context budget, it selectively folds completed sub-trajectories, flushes low-utility memory elements, and prioritizes highsalience reasoning backbones. Together, these operations ensure that the working context remains compact yet logically sufficient, allowing the agent to sustain coherent and task-aligned reasoning as the reasoning horizon grows. To optimize memory construction and memory management for their distinct functional demands, MemoBrain adopts task-specific optimization strategy that aligns learning objectives with downstream reasoning behavior, enabling memory to function as an active and adaptive component for long-horizon reasoning. We evaluate MemoBrain across model scales ranging from 4B to 14B by integrating it into tool-augmented agents with strong long-horizon reasoning capabilities. Across challenging benchmarks including BrowseCompPlus (Chen et al., 2025), GAIA (Mialon et al., 2023), and WebWalker (Wu et al., 2025b), MemoBrain consistently improves performance on complex information-seeking and reasoning tasks under bounded context budget. Our contributions are threefold: (1) We introduce executive memory as new memory paradigm dedicated to complex reasoning in tool-augmented agent frameworks, formalizing memory as an explicit control mechanism for context management and cognitive modeling under bounded context budget. (2) We propose MemoBrain, standalone executive memory model that operates as copilot alongside the reasoning agent, constructing dependency-aware in-task memories and actively manages the working context through explicit memory operations. (3) We empirically demonstrate that integrating executive memory into diverse tool-augmented agent frameworks consistently improves performance across multiple model scales and challenging benchmarks, highlighting its generality and effectiveness across agent ecosystems."
        },
        {
            "title": "2 Related Work",
            "content": "Memory has emerged as foundational mechanism for scaling large language models (Packer et al., 2023; Zhang et al., 2025b; Chhikara et al., 2025), particularly in settings involving long contexts and complex information access (Hu et al., 2025). large body of work focuses on agentic long-term memory, where models are equipped with mechanisms to retain and organize information across extended interactions in agent frameworks (Zhang et al., 2025a). In these settings, memory is typically constructed over long documents, retrieved passage collections, or multi-turn dialogue histories, and is realized through structured abstractions such as graph-based organization, keyvalue compression, or hierarchical storage (Zhong et al., 2024; Wang et al., 2023; Chhikara et al., 2025; Edge et al., 2024; Qian et al., 2025b; Kang et al., 2025; Yan et al., 2025a). Such memory mechanisms are primarily designed to support persistent knowledge accumulation and reuse, serving as long-term priors for tasks including conversational agents, long-context question answering, and interactive assistants (Li et al., 2025e; Yan et al., 2025b; Xu et al., 2025). Accordingly, they are commonly evaluated on benchmarks such as LoCoMo (Maharana et al., 2024), LongBench (Bai et al., 2025), and RULER (Hsieh et al., 2024), where memory is built from provided interaction histories or long contexts and accessed during inference. In tool-augmented complex reasoning, prior work has highlighted the importance of context management (Mei et al., 2025). Methods such as AgentFold and ContextFolding reduce context overhead by folding or abstracting redundant reasoning steps (Ye et al., 2025; Sun et al., 2025), while approaches like DeepAgent delegate subtasks to auxiliary agents and reintegrate only summarized outcomes (Li et al., 2025d,c). Although effective, these methods focus on the engineering aspect of memory and do not model it as cognitive control mechanism for global task awareness or reasoning guidance. In contrast, we formalize memory in tool-augmented reasoning as executive memory, an online mechanism that constructs structured representations of reasoning trajectories and explicitly controls information flow. By unifying context management with cognitive modeling, executive memory enables coherent long-horizon reasoning beyond purely engineering-level optimizations."
        },
        {
            "title": "3.1 Overview of MemoBrain",
            "content": "Consider complex reasoning task that requires sequence of reasoning episodes {x1, x2, . . . , xT } to collect sufficient evidence and produce final answer Y. As illustrated in Figure 1, each reasoning episode xt constitutes self-contained unit of progress, typically involving task reasoning, interaction with external tools (e.g., web search or code execution), and the tool feedback, together producing diverse and evolving execution traces. Memory Construction. MemoBrain incrementally transforms the sequence of reasoning episodes into structured trajectory memory. Each completed episode xt is abstracted into compact mem3 ory unit, referred to as thought vt, capturing its semantic contribution to task progress. As reasoning proceeds, newly generated thoughts are integrated into global, dependency-aware memory structure, Gt = Gt1 {vt}, (1) yielding an evolving memory graph that represents the high-level reasoning trajectory beyond transient execution details. Memory Management. The reasoning agent operates under bounded context budget. When contextual accumulation approaches the budget limit, MemoBrain activates an executive memory management process to regulate how the accumulated reasoning structure is maintained and exposed. At high level, MemoBrain conditions on the current trajectory memory Gt and invokes the memory model ϕ() to produce set of executive operations: Ot = ϕ(Gt), (2) which specify how parts of the trajectory memory should be reorganized. Applying these operations yields an updated memory state: Gt+1 = Apply(Gt, Ot). (3) Based on Gt+1, MemoBrain reorganizes the working context to retain compact yet semantically sufficient representation for subsequent reasoning."
        },
        {
            "title": "3.2 Memory Construction",
            "content": "Thought Formation. After reasoning episode completes, MemoBrain abstracts it into thought. Each reasoning episode xt is represented as: xt = (τt, ωt), (4) where τt denotes transient execution-level information (e.g., tool calls and raw outputs), and ωt denotes the resolved semantic outcome that advances the task. Rather than retaining execution details, MemoBrain focuses on capturing the taskrelevant contribution of ωt. Conditioned on the current memory state Gt1 and dedicated memorization instruct (see Table 3), MemoBrain applies: vt = ϕ(xt, Gt1), (5) where ϕ() maps the completed episode into an executive-level abstraction, capturing what information was used to address which subproblem and with what outcome. Each thought encodes the functional role of the episode within the overall reasoning trajectory, preserving its contribution to task progress while discarding short-lived execution artifacts. The newly formed thought vt is then integrated into memory by updating the global state from Gt1 to Gt. This process runs asynchronously alongside the reasoning agent, enabling MemoBrain to operate as copilot that continuously records and structures reasoning progress without interrupting reasoning execution. Each newly created thought is initialized as active, indicating its participation in the current reasoning trajectory. Thoughts can take one of two activation states, active or inactive, which may be updated during memory management. This allows completed, superseded, or unproductive reasoning paths to be deactivated without removing their structural role in the memory graph. Dependency Modeling. To preserve the logical structure of reasoning, MemoBrain models how new thoughts build upon existing ones: Dep(vt) {v1, . . . , vt1}, (6) representing the earlier conclusions on which the current thought depends. These dependency relations encode causal and semantic structure beyond mere temporal order. As reasoning proceeds, accumulated thoughts and dependencies form an evolving directed memory graph Gt = (Vt, Et), where Vt = Vt1 {vt} and Et = Et1 {(vi, vt) vi Dep(vt)}. This graph provides global, trajectory-level representation of the reasoning process that extends beyond the agents local context window."
        },
        {
            "title": "3.3 Memory Management",
            "content": "Memory management specifies how executive operations are applied to the trajectory memory to regulate the persistence and exposure of reasoning structure under bounded context. At each management step, MemoBrain produces set of executive operations Ot over the current trajectory memory Gt, instructed by the management prompt (see Table 4). Each operation in Ot acts on selected nodes or subgraphs and rewrites the memory structure accordingly. In this work, we consider two classes of operations: Ot {FOLD(), FLUSH()}. (7) 4 Sequential Trajectory Folding. The FOLD operation targets sub-trajectories whose associated subtasks have reached decisive resolution. Formally, MemoBrain identifies connected subgraph Ti:j Gt composed of sequence of thoughts {vi, . . . , vj} that jointly address the same subproblem. If the terminal thought vj encodes conclusive outcome (e.g., target information verified, or evidence consistently absent), then the intermediate reasoning episodes in Ti:j no longer provide additional informational gain. In such cases, MemoBrain applies folding operation: Ti:j v, (8) collapsing the entire sub-trajectory into single summary thought that records the resolved conclusion. All thoughts in Ti:j are removed from the active reasoning context. Because the subtask has been conclusively settled, the corresponding reasoning sessions can be safely eliminated without compromising task-relevant semantics. Selective Memory Flush. The FLUSH operation targets individual thoughts whose informational utility has expired with respect to the current reasoning state. Specifically, MemoBrain identifies thoughts vk that fall into one of the following categories: (i) invalid reasoning steps that failed to yield meaningful feedback, (ii) exploratory attempts superseded by subsequent refinements, or (iii) steps whose conclusions are no longer relevant to the active trajectory. Unlike folding, flush operations do not assume subtask resolution. Instead of removing such nodes entirely, MemoBrain applies: vk ˆvk, (9) replacing vk with compact thought ˆvk that preserves high-level structural information while discarding execution-level detail. These compact thoughts record the existence and outcome of prior attempts, preventing redundant exploration while avoiding unnecessary contextual load. Context Reorganization. Following executive memory transformation, MemoBrain reorganizes the working context by projecting the updated trajectory memory Gt+1 into new context Ct+1: folded trajectories, all associated reasoning steps in Ct are replaced by their summary thought v. For flushed nodes, verbose execution traces are substituted with compact thoughts ˆv. The resulting context is substantially smaller than Ct, while preserving the logical structure required for coherent and goal-directed reasoning."
        },
        {
            "title": "3.4 Optimization",
            "content": "MemoBrain is optimized with two-stage training strategy that reflects the distinct learning characteristics of memory construction and memory management. Both functionalities are implemented by single memory model ϕ, which is promptconditioned to operate under different roles. Stage I: Memory Construction. Memory construction is treated as high-frequency semantic abstraction problem. Since this process mainly involves extracting salient outcomes from execution traces and exhibits low decision ambiguity, we optimize ϕ using supervised fine-tuning with highquality thought annotations generated by strong teacher model (DeepSeek V3.2): Lconst = Ext log ϕ(vt xt). (11) This stage equips MemoBrain with stable and consistent abstraction capability, which serves as the foundation for downstream memory control. Stage II: Memory Management. Memory management is sparse, decision-driven process that operates over the trajectory memory Gt under bounded context budget. At each trigger point, MemoBrain predicts set of memory operations Ot (e.g., FOLD or FLUSH) conditioned on the current memory state. Because these decisions involve global trade-offs between compression and semantic sufficiency, direct supervision is inadequate. We therefore optimize memory management using Direct Preference Optimization (Rafailov et al., 2024). For each memory state Gt, we sample multiple candidate operation sets, evaluate their downstream reasoning behavior, and construct preference pairs (O+, O): Lmgmt = log σ (cid:18) log ϕ(O+ Gt) ϕ(O Gt) (cid:19) . (12)"
        },
        {
            "title": "4 Experiment",
            "content": "Ct+1 = ψ(Gt+1), (10)"
        },
        {
            "title": "4.1 Datasets and Baselines",
            "content": "where ψ() maps active thoughts in Gt+1 to their corresponding contextual representations. For Datasets. We evaluate MemoBrain and baslines on three benchmarks: (1) GAIA (Mialon et al., 5 Method General AI Assistant WebWalkerQA L1 L2 L3 Avg. Easy Med. Hard Avg. Direct Reasoning (w/o Retrieval) QwQ-32B GPT-4o DeepSeek-R1-671B Retrieval-Augmented Generation Vanilla RAG (QwQ-32B) Query Planning (QwQ-32B) Iterative RAG (QwQ-32B) Tool-Integrated Reasoning ReAct (QwQ-32B) ReAct (GPT-4o) ReAct (Qwen3-30B-A3B) WebThinker-32B WebDancer (QwQ-32B) ReSum-GRPO DeepAgent-RL AgentFold-30B-A3B GLM-4.6 DeepResearch-30B-A3B MemoBrain-8B w/ GLM-4.6 w/ DeepResearch-30B-A3B 25.6 23.1 43.6 33.3 48.7 51.3 48.7 51.2 48.7 56.4 56.4 66.7 76.9 79. 79.5 82.1 9.6 15.4 26.9 36.5 25.0 28.8 34.6 34.6 26.9 50.0 48.1 59.6 59.6 67.3 71.2 69.2 16.7 8.3 8. 8.3 8.3 8.3 16.7 8.3 8.3 16.7 25.0 25.0 33.3 41.7 50.0 58.3 16.5 17.5 31.1 32.0 32.0 35.0 37.8 34.6 33.0 48.5 46.6 48.5 58.3 67.0 63.1 68. 71.8 74.5 7.5 6.7 5.0 36.9 28.8 29.4 35.6 34.6 26.3 58.8 49.4 64.4 72.5 68.8 73.1 2.1 6.0 11. 26.1 35.7 32.9 29.1 42.0 27.5 44.6 55.0 62.9 71.8 69.6 72.1 3.8 4.2 11.3 33.5 30.8 31.3 13.2 23.9 21.7 40.4 29.6 48.8 61. 61.3 64.2 4.0 5.5 10.0 31.2 32.5 31.5 24.1 33.8 25.2 46.5 43.2 58.2 68.2 66.5 69.6 Table 1: Main experimental results. Best scores are shown in bold, and second-best are underlined. We report Pass@1. Results marked with are cited from the original papers. MemoBrain results are obtained by integrating MemoBrain-8B into the corresponding base agents (GLM-4.6 and DeepResearch-30B-A3B). LLM Acc Search Calls Sonnet 4 Kimi-K2 oss-120b-high GLM-4.6 DeepResearch-30B-A3B MemoBrain 37.35 35.42 44.10 48.19 51. w/ GLM-4.6 55.06 w/ DeepResearch-30B-A3B 60.36 9.03 11.22 18.35 25.60 17.14 24.62 27.12 Table 2: Performance Comparison under Identical Retrieval Settings on BrowseComp-Plus 2023) (General AI Assistant) consists of over 450 real-world queries covering multi-step reasoning, tool use, and multimodal understanding. Following prior work (Ye et al., 2025; Wu et al., 2025c; Li et al., 2025c), we evaluate on 103 text-only validation questions. (2) WebWalker (Wu et al., 2025b) comprises 680 queries across domains, requiring agents to traverse linked webpages and integrate evidence dispersed across multiple subpages. For GAIA and WebWalkerQA, Google Search is used as the online search tool. (3) BrowseComp-Plus (Chen et al., 2025) is derived from the BrowseComp benchmark (Wei et al., 2025) and contains 830 questions whose answers are short and verifiable. For BrowseCompPlus, fixed candidate webpage corpus is provided, and agents perform local dense retrieval over this corpus as the search tool. Baselines. We evaluate MemoBrain against representative baselines spanning three categories. Direct Reasoning includes strong standalone LLMs without external tools, such as QwQ-32B, GPT4o, and DeepSeek-R1-671B (DeepSeek-AI, 2025; Yang et al., 2025; OpenAI, 2024). RetrievalAugmented Generation covers methods that inject retrieved evidence into the context, including vanilla RAG and enhanced variants with query planning or iterative refinement (Shao et al., 2023; Chan et al., 2024). Tool-Integrated Reasoning comprises approaches that interleave reasoning with retrieval actions, such as ReAct, Search-o1, and WebThinker (Yao et al., 2023; Li et al., 2025b,d), as well as more recent systems including WebDancer, ReSum, AgentFold, and DeepAgent (Wu et al., 2025a,c; Ye et al., 2025; Li et al., 2025c). Notably, ReSum, AgentFold, and DeepAgent introduce explicit forms of context management, such as summarization, trajectory compression, or learned control, which represent the engineering realization 6 of agent memory in existing agent frameworks. We further include GLM-4.6 and DeepResearch30B-A3B as strong tool-augmented agent baselines (Li et al., 2025a; GLM et al., 2024). MemoBrain is integrated into these agents as an external memory component. Implementation details are provided in Appendix A.1."
        },
        {
            "title": "4.2 Main Results",
            "content": "We summarize the main experimental results in Table 1 and Table 2, from which several consistent observations can be drawn. (1) MemoBrain consistently improves the performance of its base agents when integrated with both GLM-4.6 and DeepResearch-30B-A3B. Across all evaluated benchmarks, MemoBrain yields clear gains over the original agent frameworks, demonstrating that introducing an explicit executive memory component is broadly beneficial for tool-augmented reasoning. In particular, when combined with DeepResearch-30B-A3B, MemoBrain achieves the best overall performance across all benchmarks, outperforming all baselines. These results indicate that MemoBrain is adaptive to different reasoning agents and can be effectively incorporated as plug-in memory module without architecture-specific customization. (2) MemoBrain yields larger gains in harder reasoning regimes, notably on BrowseComp-Plus and the Level-3 split of GAIA, where long-horizon reasoning and extensive tool interaction strain the raw context window of the reasoning agent. By explicitly modeling reasoning structure and providing just-in-time, task-relevant context, MemoBrain mitigates cognitive overload and enables deeper exploration. This is further evidenced in Table 2, where MemoBrain-augmented agents make more valid tools therefore achieving obvious improvement, indicating more effective and sustained tool use under bounded context constraints. (3) Compared to prior context management approaches such as DeepAgent and AgentFold, MemoBrain is more effective by decoupling memory from the reasoning agent. Existing methods embed folding or summarization directly into single agent, entangling memory control with reasoning execution. In contrast, MemoBrain adopts copilot-style design with an explicit executive memory that externally manages reasoning trajectories, yielding stronger empirical performance and more flexible, reusable memory module across diverse tool-augmented agent frameworks. Figure 2: Ablation studies of MemoBrain. All experiments are conducted on 100 randomly sampled instances from BrowseComp-Plus, using DeepResearch30B-A3B as the base reasoning agent."
        },
        {
            "title": "4.3 Ablation Study",
            "content": "To justify the technical validity of MemoBrain, we conduct comprehensive ablation studies along three dimensions: (a) executive memory design choices, (b) memory model selection, and (c) sensitivity to memory budget size. The results are in Figure 2. Impact of Executive Memory Design. We first ablate key design components of MemoBrain to assess their individual contributions. Removing any major component consistently leads to performance degradation, indicating that MemoBrains effectiveness arises from their joint design. Specifically, when retaining the memory graph structure and enabling only one operation, either trajectory folding or selective flush, performance improves over the baseline without executive memory. In contrast, strategies such as directly deleting flushed sessions or randomly removing reasoning steps significantly undermine performance. These highlight that MemoBrains gains stem not merely from reducing context length, but from structured and semantics-aware memory operations that preserve the logical backbone of reasoning trajectories. Impact of Memory Model Choice. We evaluate MemoBrain instantiated with Qwen3 backbones of different scales (4B, 8B, and 14B). In all cases, integrating MemoBrain leads to clear performance improvements over using the reasoning"
        },
        {
            "title": "4.4 Efficiency Analysis.",
            "content": "We evaluate the efficiency of MemoBrain with respect to effective reasoning context length (Figure 3). Figure 3 (a) presents latency breakdown into reasoning time (reasoning agent runtime), memorization time (asynchronous memory construction), and total time, which additionally includes memory management when triggered. Because memorization operates asynchronously, it incurs no end-to-end latency overhead as long as its cost remains below the reasoning time. For trajectories up to 128K tokens, both memorization and management overheads are negligible compared to reasoning. Although memory-related latency increases for longer trajectories as the memory graph grows, memorization remains consistently nonblocking even beyond 256K tokens, confirming that MemoBrain scales efficiently under copilotstyle, asynchronous execution regime. Figure 3 (b) reports token consumption and tool usage. Although the base agent is limited to 128K context window, integrating MemoBrain enables effective reasoning over hundreds of thousand tokens and supports substantially more tool calls, while operating under smaller fixed context budget. This result indicates that MemoBrain extends the practical reasoning horizon of tool-augmented agents by delivering compact, just-in-time contextual support that preserves essential reasoning structure, rather than relying on unbounded raw context expansion."
        },
        {
            "title": "5 Conclusion",
            "content": "In this paper, we study complex reasoning in toolaugmented agent frameworks, where long-horizon tool interactions lead to the accumulation of reasoning traces and transient artifacts that strain bounded LLM contexts and impair task alignment and reasoning coherence. To address this challenge, we introduce executive memory, which reconceptualizes memory as an explicit control mechanism over reasoning structure rather than passive context storage. Building on this perspective, we propose MemoBrain, copilot-style memory system that maintains global reasoning graph and applies budgetaware folding and flushing to provide compact, just-in-time context. Experiments on multiple challenging benchmarks demonstrate consistent and substantial performance gains, while ablation and efficiency studies further validate the effectiveness and scalability of the proposed design. Additional case studies are provided in Appendix A.3. Figure 3: Efficiency Analysis of MemoBrain. Endto-end runtime statistics on the full BrowseComp-Plus benchmark under 32K memory budget, using 4H100 GPUs for the reasoning model and 2H100 GPUs for the memory model with batch size of 8. agent alone, demonstrating that the benefits of executive memory are not tied to specific model scale. While employing stronger memory model such as DeepSeek-V3.2 achieves the best overall results, MemoBrain with 8B or 14B backbones exhibits comparable performance. Considering this trade-off between efficiency and effectiveness, we adopt MemoBrain-8B in most experiments. Moreover, we observe that models lacking taskspecific optimization exhibit weaker instructionfollowing behavior (e.g., Qwen3-14B), often producing invalid memory updates or inappropriate management operations that disrupt reasoning trajectories. This suggests that effective executive memory relies more on targeted optimization than on model scale alone. Sensitivity to Memory Budget Size. Finally, we analyze MemoBrains sensitivity to the context budget. Across all settings, larger budgets generally lead to better performance. When the budget is set below 16K, performance can drop below the baseline, as the retained context becomes insufficient to support meaningful reasoning expansion. Beyond 64K, however, performance gains begin to saturate, suggesting that the memory budget is sufficient for most tasks and that memory management may be triggered less frequently. This trend indicates that MemoBrain is robust to budget selection within reasonable range and does not require excessively large memory to be effective."
        },
        {
            "title": "Limitations",
            "content": "Despite the demonstrated effectiveness of MemoBrain across multiple benchmarks, several limitations remain that are important to acknowledge. (1) MemoBrain assumes that the underlying reasoning agent is capable of sustained, long-horizon tool use and iterative reasoning. However, many current LLMs tend to terminate reasoning prematurely after limited number of tool calls, often drawing conclusions before sufficient evidence is In such cases, the accumulated concollected. text does not reach the threshold required to trigger memory management, and MemoBrain has little opportunity to intervene. We observe this limitation in experiments with both Qwen3-30BA3B-2507-Instruct and Qwen3-30B-A3B-2507Thinking, where early termination restricts the practical benefits of executive memory. (2) While the memory graph maintained by MemoBrain naturally supports richer cognitive operations inspired by human memory, such as reactivating previously flushed reasoning episodes or partitioning the memory graph for parallel exploration, this work focuses on only two core operations: folding and selective flush. These design choices are intended to isolate the fundamental effects of executive memory control. Exploring more advanced memory operations and their coordination remains an important direction for future work. (3) Our experimental comparison does not include all potentially relevant baselines. Some memory-augmented methods are designed mainly for long-context settings and cannot be readily adapted to dynamic reasoning trajectories. Others lack public implementations or require computational resources beyond our constraints. Additionally, our reproduced results for DeepResearch-30BA3B on GAIA and WebWalker are slightly lower than those reported in the original paper, partly due to differences in tool implementations (e.g., search quality and code execution). Nevertheless, all comparative experiments are conducted under identical settings, ensuring that the relative improvements by MemoBrain remain valid and meaningful."
        },
        {
            "title": "References",
            "content": "Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. 2025. Longbench v2: Towards deeper understanding and reasoning on realistic long-context multitasks. Preprint, arXiv:2412.15204. Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo, and Jie Fu. 2024. Rq-rag: Learning to refine queries for retrieval augmented generation. In First Conference on Language Modeling. Zijian Chen, Xueguang Ma, Shengyao Zhuang, Ping Nie, Kai Zou, Andrew Liu, Joshua Green, Kshama Patel, Ruoxi Meng, Mingyi Su, Sahel Sharifymoghaddam, Yanxi Li, Haoran Hong, Xinyu Shi, Xuye Liu, Nandan Thakur, Crystina Zhang, Luyu Gao, Wenhu Chen, and Jimmy Lin. 2025. Browsecomp-plus: more fair and transparent evaluation benchmark of deep-research agent. CoRR, abs/2508.06600. Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh, and Deshraj Yadav. 2025. Mem0: Building production-ready AI agents with scalable long-term memory. CoRR, abs/2504.19413. DeepSeek-AI. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. CoRR, abs/2501.12948. Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. 2024. From local to global: graph rag approach to query-focused summarization. Preprint, arXiv:2404.16130. Huan-ang Gao, Jiayi Geng, Wenyue Hua, Mengkang Hu, Xinzhe Juan, Hongzhang Liu, Shilong Liu, Jiahao Qiu, Xuan Qi, Yiran Wu, Hongru Wang, Han Xiao, Yuhang Zhou, Shaokun Zhang, Jiayi Zhang, Jinyu Xiang, Yixiong Fang, Qiwen Zhao, Dongrui Liu, Qihan Ren, Cheng Qian, Zhenhailong Wang, Minda Hu, Huazheng Wang, Qingyun Wu, Heng Ji, and Mengdi Wang. 2025. survey of self-evolving agents: On path to artificial super intelligence. CoRR, abs/2507.21046. Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, and Zihan Wang. 2024. Chatglm: family of large language models from glm-130b to glm-4 all tools. Preprint, arXiv:2406.12793. Cheng-Ping Hsieh, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, and Boris Ginsburg. 2024. Ruler: Whats the real context size 9 of your long-context language models? Preprint, arXiv:2404.06654. Yuyang Hu, Shichun Liu, Yanwei Yue, Guibin Zhang, Boyang Liu, Fangyi Zhu, Jiahang Lin, Honglin Guo, Shihan Dou, Zhiheng Xi, Senjie Jin, Jiejun Tan, Yanbin Yin, Jiongnan Liu, Zeyu Zhang, Zhongxiang Sun, Yutao Zhu, Hao Sun, Boci Peng, Zhenrong Cheng, Xuanbo Fan, Jiaxin Guo, Xinlei Yu, Zhenhong Zhou, Zewen Hu, Jiahao Huo, Junhao Wang, Yuwei Niu, Yu Wang, Zhenfei Yin, Xiaobin Hu, Yue Liao, Qiankun Li, Kun Wang, Wangchunshu Zhou, Yixin Liu, Dawei Cheng, Qi Zhang, Tao Gui, Shirui Pan, Yan Zhang, Philip Torr, Zhicheng Dou, Ji-Rong Wen, Xuanjing Huang, Yu-Gang Jiang, and Shuicheng Yan. 2025. Memory in the age of ai agents. Preprint, arXiv:2512.13564. Jiazheng Kang, Mingming Ji, Zhe Zhao, and Ting Bai. 2025. Memory os of ai agent. Preprint, arXiv:2506.06326. Baixuan Li, Bo Zhang, Dingchu Zhang, Fei Huang, Guangyu Li, Guoxin Chen, Huifeng Yin, Jialong Wu, Jingren Zhou, Kuan Li, Liangcai Su, Litu Ou, Liwen Zhang, Pengjun Xie, Rui Ye, Wenbiao Yin, Xinmiao Yu, Xinyu Wang, Xixi Wu, Xuanzhong Chen, Yida Zhao, Zhen Zhang, Zhengwei Tao, Zhongwang Zhang, Zile Qiao, Chenxi Wang, Donglei Yu, Gang Fu, Haiyang Shen, Jiayin Yang, Jun Lin, Junkai Zhang, Kui Zeng, Li Yang, Hailong Yin, Maojia Song, Ming Yan, Peng Xia, Qian Xiao, Rui Min, Ruixue Ding, Runnan Fang, Shaowei Chen, Shen Huang, Shihang Wang, Shihao Cai, Weizhou Shen, Xiaobin Wang, Xin Guan, Xinyu Geng, Yingcheng Shi, Yuning Wu, Zhuo Chen, Zijian Li, and Yong Jiang. 2025a. Tongyi deepresearch technical report. CoRR, abs/2510.24701. Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, and Zhicheng Dou. 2025b. Search-o1: Agentic search-enhanced large reasoning models. CoRR, abs/2501.05366. Xiaoxi Li, Wenxiang Jiao, Jiarui Jin, Guanting Dong, Jiajie Jin, Yinuo Wang, Hao Wang, Yutao Zhu, JiRong Wen, Yuan Lu, and Zhicheng Dou. 2025c. Deepagent: general reasoning agent with scalable toolsets. CoRR, abs/2510.21618. Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, and Zhicheng Dou. 2025d. Webthinker: Empowering large reasoning models with deep research capability. arXiv preprint arXiv:2504.21776. Zhiyu Li, Shichao Song, Hanyu Wang, Simin Niu, Ding Chen, Jiawei Yang, Chenyang Xi, Huayi Lai, Jihao Zhao, Yezhaohui Wang, Junpeng Ren, Zehao Lin, Jiahao Huo, Tianyi Chen, Kai Chen, Kehang Li, Zhiqiang Yin, Qingchen Yu, Bo Tang, Hongkang Yang, Zhi-Qin John Xu, and Feiyu Xiong. 2025e. Memos: An operating system for memoryaugmented generation (mag) in large language models. Preprint, arXiv:2505.22101. Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, and Yuwei Fang. 2024. Evaluating very long-term conversational memory of llm agents. Preprint, arXiv:2402.17753. Lingrui Mei, Jiayu Yao, Yuyao Ge, Yiwei Wang, Baolong Bi, Yujun Cai, Jiazhi Liu, Mingyu Li, Zhong-Zhi Li, Duzhen Zhang, et al. 2025. survey of context engineering for large language models. arXiv preprint arXiv:2507.13334. Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. 2023. Gaia: benchmark for general ai assistants. In The Twelfth International Conference on Learning Representations. OpenAI. 2024. Gpt-4 technical report. Preprint, arXiv:2303.08774. Charles Packer, Vivian Fang, Shishir Patil, Kevin Lin, Sarah Wooders, and Joseph Gonzalez. 2023. Memgpt: Towards llms as operating systems. arXiv preprint arXiv:2310.08560. Cheng Qian, Emre Can Acikgoz, Qi He, Hongru Wang, Xiusi Chen, Dilek Hakkani-Tür, Gokhan Tur, and Heng Ji. 2025a. Toolrl: Reward is all tool learning needs. Preprint, arXiv:2504.13958. Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Defu Lian, Zhicheng Dou, and Tiejun Huang. 2025b. Memorag: Boosting long context processing with global memory-enhanced retrieval augmentation. In Proceedings of the ACM on Web Conference 2025, WWW 25, page 23662377, New York, NY, USA. Association for Computing Machinery. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher Manning, Stefano Ermon, and Chelsea Finn. 2024. Direct preference optimization: Your language model is secretly reward model. Advances in Neural Information Processing Systems, 36. Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023. Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 92489274. Weiwei Sun, Miao Lu, Zhan Ling, Kang Liu, Xuesong Yao, Yiming Yang, and Jiecao Chen. 2025. Scaling long-horizon llm agent via context-folding. Preprint, arXiv:2510.11967. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Jirong Wen. 2024. survey on large language model based autonomous agents. Frontiers Comput. Sci., 18(6):186345. Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, and Furu Wei. 2023. Augmenting language models with long-term memory. 10 In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Jason Wei, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, and Amelia Glaese. 2025. Browsecomp: simple yet challenging benchmark for browsing agents. arXiv preprint arXiv:2504.12516. Jialong Wu, Baixuan Li, Runnan Fang, Wenbiao Yin, Liwen Zhang, Zhengwei Tao, Dingchu Zhang, Zekun Xi, Yong Jiang, Pengjun Xie, Fei Huang, and Jingren Zhou. 2025a. Webdancer: Towards autonomous information seeking agency. CoRR, abs/2505.22648. Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Linhai Zhang, Yulan He, Deyu Zhou, Pengjun Xie, et al. 2025b. Webwalker: Benchmarking llms in web traversal. arXiv preprint arXiv:2501.07572. Xixi Wu, Kuan Li, Yida Zhao, Liwen Zhang, Litu Ou, Huifeng Yin, Zhongwang Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Minhao Cheng, Shuai Wang, Hong Cheng, and Jingren Zhou. 2025c. Resum: Unlocking long-horizon search intelligence via context summarization. CoRR, abs/2509.13313. Ziyi Xia, Kun Luo, Hongjin Qian, and Zheng Liu. 2025. Open data synthesis for deep research. Preprint, arXiv:2509.00375. Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, and Yongfeng Zhang. 2025. A-mem: Agentic memory for llm agents. Preprint, arXiv:2502.12110. B. Y. Yan, Chaofan Li, Hongjin Qian, Shuqi Lu, and Zheng Liu. 2025a. General agentic memory via deep research. Preprint, arXiv:2511.18423. Sikuan Yan, Xiufeng Yang, Zuchao Huang, Ercong Nie, Zifeng Ding, Zonggen Li, Xiaowen Ma, Kristian Kersting, Jeff Z. Pan, Hinrich Schütze, Volker Tresp, and Yunpu Ma. 2025b. Memory-r1: Enhancing large language model agents to manage and utilize memories via reinforcement learning. Preprint, arXiv:2508.19828. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jian Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu. 2025. Qwen3 technical report. CoRR, abs/2505.09388. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023. React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR). Rui Ye, Zhongwang Zhang, Kuan Li, Huifeng Yin, Zhengwei Tao, Yida Zhao, Liangcai Su, Liwen Zhang, Zile Qiao, Xinyu Wang, Pengjun Xie, Fei Huang, Siheng Chen, Jingren Zhou, and Yong Jiang. 2025. Agentfold: Long-horizon web agents with proactive context management. CoRR, abs/2510.24699. Hongli Yu, Tinghong Chen, Jiangtao Feng, Jiangjie Chen, Weinan Dai, Qiying Yu, Ya-Qin Zhang, WeiYing Ma, Jingjing Liu, Mingxuan Wang, and Hao Zhou. 2025. Memagent: Reshaping long-context llm with multi-conv rl-based memory agent. Preprint, arXiv:2507.02259. Guibin Zhang, Hejia Geng, Xiaohang Yu, Zhenfei Yin, Zaibin Zhang, Zelin Tan, Heng Zhou, Zhongzhi Li, Xiangyuan Xue, Yijiang Li, Yifan Zhou, Yang Chen, Chen Zhang, Yutao Fan, Zihu Wang, Songtao Huang, Yue Liao, Hongru Wang, Mengyue Yang, Heng Ji, Michael Littman, Jun Wang, Shuicheng Yan, Philip Torr, and Lei Bai. 2025a. The landscape of agentic reinforcement learning for llms: survey. CoRR, abs/2509.02547. Zeyu Zhang, Quanyu Dai, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Jieming Zhu, Zhenhua Dong, and Ji-Rong Wen. 2025b. survey on the memory mechanism of large language model-based agents. ACM Trans. Inf. Syst., 43(6):155:1155:47. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2024. survey of large language models. Preprint, arXiv:2303.18223. Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. 2024. Memorybank: Enhancing large language models with long-term memory. In Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024, Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence, IAAI 2024, Fourteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2014, February 20-27, 2024, Vancouver, Canada, pages 19724 19731. AAAI Press. 11 You are Memory Agent collaborating on complex multi-step research task. Your job is to append the latest reasoning step to the ongoing reasoning graph by creating new node(s) and edge(s) as needed. The reasoning graph is composed of: - Nodes: - \"task\": the original user question or main task. - \"subtask\": subproblem decomposed during the reasoning process. - \"evidence\": factual answer or conclusion obtained during reasoning to address (sub)task. - \"summary\": summary node synthesizing set of previous nodes. (NOTE: You will NOT create new summary node in this step.) - Edges: - links \"task\" node to newly created \"subtask\" nodes (breaking down task). - links \"task\" or \"subtask\" node to more precise/reformulated \"subtask\". - links an \"evidence\" node to the task or subtask it supports or answers. Input (You will be given): 1. The current state of the reasoning graph (in human-readable or JSON form), including all current nodes and their types and edges. 2. new reasoning step (subtask, intermediate result, or evidence) that must be appended to the graph. Your goals: 1. Decide what new node(s) (subtask or evidence) should be created from the current reasoning step. - Clearly identify the node \"kind\": \"subtask\" or \"evidence\". - Take notes to summarize the core information of the reasoning step in the form of list like [\"role\": \"\", \"content\": \"\", ...], - Do NOT create \"summary\" type nodes in this step. 2. Decide what new edge(s) are needed to connect the new node(s) to existing nodes or to other new nodes: - For each edge, specify the \"src\" and \"dst\" (src is the node id, dst is the tmp_id), and optionally short \"rationale\" for this edge. 3. Output your update as single JSON object with the following fields: - \"add_edges\": list of new edge objects with at least \"src\", \"dst\", and optionally \"rationale\". Rules: - Output must be strictly valid JSON; do NOT include any commentary or explanation. - You may use existing node ids as the src of edges as appropriate. - Avoid creating cycles in the graph. - Only create new nodes corresponding to meaningful new steps in the reasoning. Table 3: System prompt used for executive memory construction in MemoBrain."
        },
        {
            "title": "A Appendix",
            "content": "A."
        },
        {
            "title": "Implementation Details",
            "content": "MemoBrain is initialized from the Qwen3 instruction-tuned model family (Yang et al., 2025), including Qwen3-4B-Instruct-2507, Qwen3-8B, and Qwen3-14B. Training data are synthesized from the InfoSeek benchmark (Xia et al., 2025), which contains over 50K complex reasoning QA pairs; during synthesis, we use DeepSeek-V3.2 as the memory oracle to generate executive supervision signals, resulting in 37,719 memory construction samples and 3,016 memory management samples. Data synthesis incurs an API cost of $389. All models are trained using LlamaFactory with learning rate of 2 105, gradient accumulation steps of 8, per-device batch size of 1, maximum gradient norm of 1.0, AdamW optimizer, 3 training epochs, and maximum sequence length of 32K tokens. Memory construction is optimized via supervised fine-tuning, while memory management is optimized using preference-based learning.The total training time is 17, 21, and 27 hours for the 4B, 8B, and 14B models, respectively. For GAIA and WebWalker, we employ the Google Custom Search API to retrieve the top-10 results and use Jina.AIs web reader API to obtain webpage content, which is refined using Qwen330B-A3B-Instruct-2507. Code execution is handled via Pythons built-in exec() function. For BrowseComp-Plus, dense retrieval is performed using Qwen3-Embed-8B. In the main experiments, MemoBrains memory budget is set to 32K tokens for GAIA and WebWalker and 64K tokens for BrowseComp-Plus, triggering memory management once the accumulated context reaches the budget, while baseline methods retain their original context limits (e.g., 128K for DeepResearch-30B-A3B). We report Pass@1 as the evaluation metric and use GPT-4o-2024-0806 as the LLM-based judge. All experiments are conducted on 8 NVIDIA H100 80G GPUs. 12 In Table 7, we present concrete example of the memory management operation applied to the constructed memory graph. As the reasoning trajectory expands and the working context approaches the predefined budget, MemoBrain evaluates the global memory structure and performs executive operations to regulate information exposure. Specifically, completed sub-trajectories whose associated subtasks have reached conclusive outcomes are folded into compact summary thoughts, while low-utility or superseded thoughts are selectively flushed to reduce contextual redundancy. Crucially, these operations preserve the dependency structure among the remaining thoughts, ensuring that the global reasoning process remains coherent and aligned with the task objective. By folding and flushing execution-level traces, MemoBrain condenses hundreds of tokens into small set of high-salience memory units, enabling sustained long-horizon reasoning under bounded context budget without sacrificing critical intermediate conclusions. A.2 Prompts In Table 3 and Table 4, we present the memorization prompt and the memory management prompt used by MemoBrain, respectively. Additional prompts employed in this work, including the system prompt for complex reasoning and the evaluation prompt, are provided in our codes, available at this repository. A.3 Case Study In Table 5, we present representative memory graph composed of six reasoning episodes, with the root node corresponding to the original input task. This case demonstrates how MemoBrain restructures long and entangled reasoning trajectory into set of semantically coherent episodes, while explicitly encoding their dependency relations within the memory graph. Through executive memory construction and management, MemoBrain abstracts the evolving problem-solving process, including subtask decomposition, evidence validation, and hypothesis elimination, rather than retaining raw execution traces. The resulting memory graph offers cognitively interpretable representation of the reasoning process, preserving only high-salience conclusions and essential logical dependencies. Notably, trajectory that originally spans tens of thousands of tokens is compactly represented by only few hundred tokens in the memory graph, highlighting MemoBrains ability to maintain reasoning coherence and task alignment under bounded context budget. In Table 6, we further illustrate concrete example of the memory construction operation in MemoBrain. Each reasoning episode, comprising internal deliberation, tool invocation, and tool responses, is abstracted into single thought unit with temporary identifier prior to integration into the global memory graph. During this process, MemoBrain extracts the episodes semantic outcome, assigns an appropriate thought type and activation state, and establishes explicit dependency relations with predecessor thoughts. This construction procedure transforms transient traces into stable and interpretable memory units, forming the structural foundation for subsequent memory management and context regulation. As shown in the case, memory construction enables MemoBrain to incrementally build dependency-aware representation of the reasoning trajectory while discarding low-level details that are unnecessary for future reasoning. Below is memory graph for complex task, detailing the key steps and their dependencies. The graph is presented in an indented structure, for example: Node 1 [node type] [status] [node info] [->] Node 2 (an edge) [edge rationale (explaining the reasoning to Node 2)] Each node includes its current status (active or inactive). Your tasks: 1. For the current reasoning status, identify which nodes are redundant and can be flushed. Redundant nodes include: invalid reasoning steps (e.g., those that did not yield meaningful feedback), or nodes that have been superseded and refined by later steps. This operation is called \"flush\". 2. Identify which paths in the graph can be folded. If subtask, after multiple reasoning steps, has arrived at conclusive reasoning result (e.g., target information found, or evidence clearly unavailable as indicated by an evidence node), you may collapse the preceding related reasoning steps. This operation is called \"folding\". Important constraint: - Do not include the same node in both flush_ops and fold_ops. Each node may only be the target of one operation, since both flush and fold operations result in the node becoming inactive. examples Guidelines: - Only consider nodes whose status is \"active\" for flush and fold operations; ignore other status nodes for these operations. - Do not assign the same node to more than one of flush_ops or fold_ops. You must ensure each active node appears in at most one operation. - For \"flush_ops\", provide concise rationale for why each node is redundant or superseded within the current reasoning context. - For \"fold_ops\", group sequential related node ids that can be folded, and provide summary notes (as list of dicts, each with role and content). - Do NOT include any extra explanation or commentary outside the JSON. - Output only the JSON object, no additional formatting or text. Table 4: System prompt used for executive memory management in MemoBrain. - Node 1: [task] [Active] Begin to solve the task: Could you provide the name of the individual who: - As of December 2023, the individual was the coordinator of research group founded in 2009. - Co-edited book published in 2018 by Routledge. - The individual with whom they co-edited the book was keynote speaker at conference in 2019. - Served as the convenor of panel before 2020. - Published an article in 2012. - Completed their PhD on the writings of an English writer. [input task] [->] Node 2 [Rationale: Break down the main task into subtask to search for relevant information based on initial criteria.] - Node 2: [subtask] [Active] [role: assistant, content: \"Search for individuals co-editing Routledge book in 2018, focusing on those with PhD on an English writers writings and other criteria.\", role: user, content: Return search results from queries about co-edited book 2018 Routledge, research group founded in 2009 coordinator 2023, and convenor panel 2019 keynote.] [->] Node 3 [Rationale: The evidence from search results supports the subtask by providing potential leads or data to analyze further.] - Node 3: [evidence] [Active] [role: assistant, content: Analyze search results to identify potential candidates matching the criteria., role: user, content: Found multiple results including Mathew Abbott (editor of Michael Fried and Philosophy: Modernism, Intention, and Theatricality, Routledge 2018), but need to check other details like research group coordinator, convenor of panel, article in 2012, and PhD on English writer.] [->] Node 4 [Rationale: Break down the subtask into more precise search queries to find the individual matching all criteria.] - Node 4: [subtask] [Active] [role: assistant, content: Refine search queries to focus on specific criteria: co-edited Routledge book in 2018, research group coordinator founded in 2009, and other details like convenor of panel befor 2020, article in 2012, PhD on English writer., role: user, content: \"Search for co-edited Routledge book 2018, research group founded 2009 coordinator, convenor panel 2019 keynote speaker, article published 2012, PhD thesis on English writer.\"] [->] Node 5 [Rationale: The evidence from search results supports the subtask by providing data to analyze for potential candidates matching the criteria.] - Node 5: [evidence] [Active] [role: assistant, content: Search results from refined queries show potential matches, such as Mona Baker (co-coordinator of Genealogies of Knowledge Research Network founded in 2009) and Pooyan Ta mimi Arab (co-edited Routledge Handbook of Material Religion in 2023, not 2018). Need to verify other criteria like convenor of panel before 2020, article in 2012, and PhD on English writer., role: user, content: Results include various faculty profiles but none clearly match all criteria; further analysis required.] [->] Node 6 [Rationale: Break down the subtask into more specific search query to find co-edited Routledge book in 2018 with keynote speaker in 2019.] - Node 6: [subtask] [Active] [role: assistant, content: \"Search for Routledge 2018 co-edited Keynote 2019 to find books published in 2018 by Routledge that are co-edited, with one co-editor giving keynote at conference in 2019.\", role: user, content: Return search results from query about Routledge 2018 co-edited book and keynote speaker in 2019.] [->] Node 7 [Rationale: The evidence from search results supports the subtask by providing data to analyze for potential candidates matching the criteria.] - Node 7: [evidence] [Active] [role: assistant, content: Analyze search results from the query to identify potential matches for the criteria, such as co-edited Routledge book in 2018 and keynote speaker in 2019., role: user, content: Search results show various faculty profiles and pages but no direct matches; need to refine further or check other sources.] [Memory Graph: 482 tokens; Original Reasoning Trajectory: 17,268 tokens.] Table 5: Memory graph example. Nodes correspond to memory thoughts produced by MemoBrain, each labeled with its thought type, activation state, and compressed representation. Directed edges ([->]) denote dependency relations that capture how reasoning steps build upon one another. { \"add_nodes\": [ { \"tmp_id\": \"tmp6\", \"kind\": \"subtask\", \"thought\": [ { \"role\": \"assistant\", \"content\": \"Search for Routledge 2018 co-edited Keynote 2019 to find books published in 2018 by Routledge that are co-edited, with one co-editor giving keynote at conference in 2019.\" }, { \"role\": \"user\", \"content\": \"Return search results from query about Routledge 2018 co-edited book and keynote speaker in 2019.\" } ] }, { \"tmp_id\": \"tmp7\", \"kind\": \"evidence\", \"thought\": [ { \"role\": \"assistant\", \"content\": \"Analyze search results from the query to identify potential matches for the criteria, such as co-edited Routledge book in 2018 and keynote speaker in 2019.\" }, { \"role\": \"user\", \"content\": \"Search results show various faculty profiles and pages but no direct matches; further refinement or alternative sources are required.\" } ] } ], \"add_edges\": [ { \"src\": 4, \"dst\": \"tmp6\", \"rationale\": \"Decompose the original task into focused search for Routledge co-edited book published in 2018 with keynote speaker in 2019.\" }, { \"src\": \"tmp6\", \"dst\": \"tmp7\", \"rationale\": \"The retrieved search results provide evidence to evaluate whether the subtask criteria are satisfied.\" } ] } Table 6: Illustration of memory construction. Newly generated thoughts are first assigned temporary IDs and later reindexed upon insertion into the memory graph. Directed edges represent dependency relations between thoughts. { \"flush_ops\": [ { \"id\": 2, \"rationale\": \"This node is superseded by Node 20, which provides conclusive evidence that Laura Lojo-Rodriguez is the coordinator of the Discourse and Identity (D&I) research group, matching the first clue. Node 2s subtask has been successfully addressed.\" }, { \"id\": 3, \"rationale\": \"This node is superseded by Node 30 and subsequent nodes (31-52), which provide comprehensive summary and detailed evidence regarding the co-edited book clue. Node 3s subtask has been refined and addressed through more specific searches.\" }, { \"id\": 47, \"rationale\": \"This node is redundant because its subtask to verify the 2012 article publication has been addressed by evidence nodes (48-50), which consistently show no direct evidence of 2012 article, making further exploration unnecessary.\" } ], \"fold_ops\": [ { \"ids\": [48, 49, 50], \"rationale\": \"These nodes provide conclusive evidence regarding the 2012 article publication subtask. All searches consistently indicate no confirmed publication in 2012.\", \"notes\": [ { \"role\": \"assistant\", \"content\": \"The objective was to determine whether Laura Lojo-Rodriguez published an academic article in 2012. The investigation involved targeted name-year search queries and systematic review of her publicly available publication records.\" }, { \"role\": \"user\", \"content\": \"No evidence of 2012 publication was identified. While publications from other years are documented, the 2012 criterion is conclusively ruled out based on consistent negative findings across all sources.\" } ] } ] } Table 7: Illustration of memory management. MemoBrain applies executive operations to the memory graph by flushing low-utility thoughts and folding completed sub-trajectories into compact summary nodes."
        }
    ],
    "affiliations": [
        "Beijing Academy of Artificial Intelligence",
        "Gaoling School of Artificial Intelligence, Renmin University of China"
    ]
}