{
    "paper_title": "From Commands to Prompts: LLM-based Semantic File System for AIOS",
    "authors": [
        "Zeru Shi",
        "Kai Mei",
        "Mingyu Jin",
        "Yongye Su",
        "Chaoji Zuo",
        "Wenyue Hua",
        "Wujiang Xu",
        "Yujie Ren",
        "Zirui Liu",
        "Mengnan Du",
        "Dong Deng",
        "Yongfeng Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have demonstrated significant potential in the development of intelligent applications and systems such as LLM-based agents and agent operating systems (AIOS). However, when these applications and systems interact with the underlying file system, the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based semantic file system ( LSFS ) for prompt-driven file management. Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating semantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update monitoring and summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations (e.g., CRUD, group by, join) powered by vector database. Our experiments show that LSFS offers significant improvements over traditional file systems in terms of user convenience, the diversity of supported functions, and the accuracy and efficiency of file operations. Additionally, with the integration of LLM, our system enables more intelligent file management tasks, such as content summarization and version comparison, further enhancing its capabilities."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 3 2 ] . [ 1 3 4 8 1 1 . 0 1 4 2 : r From Commands to Prompts: LLM-based Semantic File System for AIOS Zeru Shi, Kai Mei, Mingyu Jin, Yongye Su, Chaoji Zuo, Wenyue Hua, Wujiang Xu, Yujie Ren, Zirui Liu, Mengnan Du, Dong Deng, Yongfeng Zhang Dalian University of Technology Rutgers University Purdue University New Jersey Institute of Technology EPFL University of Minnesota"
        },
        {
            "title": "Abstract",
            "content": "Large language models (LLMs) have demonstrated significant potential in the development of intelligent applications and systems such as LLM-based agents and agent operating systems (AIOS). However, when these applications and systems interact with the underlying file system, the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based semantic file system (LSFS) for promptdriven file management. Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating semantic file management. At the macro-level, we develop comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update monitoring and summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations (e.g., CRUD, group by, join) powered by vector database. Our experiments show that LSFS offers significant improvements over traditional file systems in terms of user convenience, the diversity of supported functions, and the accuracy and efficiency of file operations. Additionally, with the integration of LLM, our system enables more intelligent file management tasks, such as content summarization and version comparison, further enhancing its capabilities. The code is open-source at https://github.com/agiresearch/AIOS-LSFS."
        },
        {
            "title": "Introduction",
            "content": "In recent years, researchers have integrated AI with operating systems to create innovative, efficiencyboosting applications [3, 30]. For example, machine learning algorithms can dynamically adjust system resource allocation [14,36]. Besides, by monitoring application performance and user behavior, AI models can predict future resource needs and pre-allocate CPU, memory, and other resources, enhancing overall system performance and response speed [25]. With the recent developments of generative AI, researchers have envisioned Large Language Models (LLMs) based operating systems [12]. At present, LLMs have demonstrated great planning and reasoning ability [16, 23, 40, 45, 48], which facilitates the development of LLM-based agents, including single-agent applications [8, 15, 44, 47] 1Zeru Shi and Kai Mei contribute equally to this paper. Preprint. Under review. and collaborative multi-agent applications [11, 18, 37, 42]. Nowadays, researchers have been trying to embed LLMs from the application-level to the system-level to serve users and AI agent applications, enabling LLM-based artificial intelligent operating system (AIOS) [30]. Through such integration, the powerful understanding and generation ability of LLMs not only can help to complete tasks on the application-level, but also can help to intelligently manage various resources such as memory and storage on the system-level. File system is one of the most fundamental and essential components of an operating system, yet it comes with significant limitations in terms of AIOS. Currently, file management primarily relies on index structures that organize files based on attributes like file name, size, and timestamps. However, this approach does not leverage the semantic meaning of the files themselves. ❶ For instance, if two files have similar contentsuch as different versions of the same documenttraditional file systems lack the capability to organize or retrieve these files based on their content similarity. ❷ User interactions with traditional file systems require complex operating system commands or manual navigation through the user interface, forcing users to precisely recall file names or locations. For systems with numerous files, this retrieval process can be inefficient and time-consuming, reducing overall system usability. Nowadays, based on the strong language understanding capability of LLMs, we can make better use of the file content and semantic information for file management by introducing LLMs into the system. However, existing works on using LLMs to facilitate file management are mostly conducted on the application level, which targets at designing specific agent for file retrieval and manipulation [28, 38]. The community still lacks more general LSFS to serve as common foundation that can be used by various agents on the application-level. To solve the above problems, we propose LSFS, an LLM-based semantic file system, to enhance the interaction between LLM and traditional file system for better semantic file management. For problem ❶, our LSFS introduces semantic-based index structure that leverages vector database for file storage. By extracting semantic features from the file content and generating corresponding embedding vectors, LSFS incorporates semantic information into its file operations. Additionally, we have designed numerous reusable syscall interfaces for LSFS, modeled after traditional file system functions. At the same time, we design several APIs that can realize complex file functions based on the syscalls. These syscalls and APIs not only can realize the basic functions of the file system but also can provide the operations that the traditional file systems do not include. To address problem ❷, we integrate LLM into the API for complex functions and introduce template system prompt. This allows us to utilize LLM to extract keywords from the users natural language input and map them directly as input parameters for the API or syscall, streamlining the interaction between users and the system. The comparison of commands executed by users in traditional file systems and LSFS is shown in Figure 1. In Figure 1(a), When user wishes to modify files content, they must input specific command in the terminal, requiring them to remember the correct operator and the exact paths for both the target and source files. This approach places significant burden on the users memory. However, LSFS can effectively solve this problem. Users only need to manage files by typing natural language prompt as command. For example, as shown in Figure Figure 1(b), the user needs to input simple natural language description, our LSFS is able to understand prompts and perform the corresponding operation. This approach greatly simplifies the complexity of the users operation and improves the efficiency of the users operation. Furthermore, to reduce the LLMs hallucination problem of generating inaccurate instructions, especially those irreversible operations, we design Figure 1: The pipeline of changing file function in traditional system and our file management system 2 systematic safety insurance mechanisms in LSFS, such as safety checks for irreversible operations and user verification before instruction execution. Overall, our research contributes as follows: We introduce LLM-based Semantic File System (LSFS) to manage files in semantic way. By altering the file storage structure and method, LSFS incorporates the semantic context of files, optimizing the fundamental functions of traditional file systems. Additionally, we develop variety of reusable syscalls and APIs within LSFS, allowing for extended functionality and enabling future developments based on this system. Our system provides LSFS parser, which can parse natural language prompts into executable APIs supported by LSFS, enabling the execution of relevant file management tasks. This allows users to control and manage files using simple natural language prompts, acting as bridge that translates user/agent instructions into system actions. By doing so, this approach greatly simplifies file system operations and enhances overall efficiency. To avoid unintended operations in LSFS, especially those irreversible operations, we design systematic safety insurance mechanisms, such as safety checks for irreversible operations and user verification before instruction execution, ensuring the safety and accuracy of LSFS. Through our experiments, we validate the completeness of LSFSs functions, while also demonstrating its innovation and superiority in handling specific tasks compared to traditional file systems. Furthermore, the experiments suggest that the LSFS enhances the execution of file management operations, making it more intelligent and efficient."
        },
        {
            "title": "2 Related Work",
            "content": "2.1 Semantic File System Currently, file storage and retrieval primarily rely on an index structure maintained by the system, where file metadata points to the files location on the disk [7]. While optimizing the index structure can enhance retrieval efficiency, the current storage model is still largely dependent on the keywords extracted from the files content. Gifford et al. [13] were the first to propose semantic file system, which introduced layer that generates directories by extracting attributes from files, enabling users to query file attributes through navigation. [9] proposed semantic file system to manage the data. Many subsequent works have integrated semantics into metadata [17, 19, 20, 29, 31]. Mahalingam et al. [29] proposed semantic deep file management system called Sedar, which embeds semantic features into file metadata, allowing retrieval to be matched with semantic vectors. However, Sedar faces challenges with the similarity of extracted semantic vectors. Hua et al. [20] further integrated semantic information into metadata, restricting complex queries to related metadata group. The same authors [21] also utilized semantics to reduce the relevance of queries using the semantic similarity between files based on the semantic naming system. Leung et al. [26] used semantic information combined with the file system design of graphs to provide scalable search and navigation. On the other hand, Bloehdorn et al. [4] proposed to manage files through semantic tags. Schandl et al. [35] developed an approach for managing desktop data using semantic vocabulary. In contrast, our semantic file system is based on the strong language understanding ability of LLMs. Besides, it integrates comprehensive semantic information across all aspects of the file systemfrom storage and file operations to practical applications. This holistic approach enhances the systems ability to understand and manage files, significantly improving functionality beyond what traditional systems and earlier semantic file systems offer. 2.2 Semantic Parser Researchers have also devoted efforts to developing semantic parsers [6, 24, 32, 41, 46] capable of transforming natural language into machine-interpretable format. Mooney et al. [32] pioneered this area by introducing suite of machine learning-based semantic parsers designed for specific tasks. Iyer et al. [22] subsequently focused on parsing database commands, while Berant et al. [1] proposed question-answer pair learning approach to enhance parsing efficiency. In further work, the same authors explored paraphrasing technique [2] to improve semantic parsing performance. Poon et al. [33] introduced Markov logic-based approach, and Wang et al. [39] addressed the challenge of building parsers from scratch in new domains. Ge et al. [10] proposed parse tree-based 3 method for more accurate semantic analysis. Notably, Lin et al. [27] were the first to integrate semantic parser into an operating system, leveraging dataset of bash commands and expert-written natural language to establish mapping between the two. However, this approach faced limitations in handling complex semantics and unseen natural language. In contrast, our LSFS is built upon more constructing more semantic index as the format of embedding vectors, improving its generation ability to understand and process diverse natural language inputs. 2.3 OS-related LLMs and Agents To enhance user experience and improve task completion efficiency, many LLM-based AI agents have been introduced to fulfill operating system related tasks such as software development [34, 44] and manipulating resources on traditional OS [5, 43]. Wu et al. [43] developed LLM-based agents for co-piloting users interaction with computers, such as drawing charts and creating web pages. MetaGPT [18] employs sophisticated large language model in multi-agent conversational setting to automate software development, assigning specific roles to various GPTs for seamless collaboration. CHATDEV [34] presents framework for software development, utilizing agents to enhance cooperation among different roles within the development process. Beyond the applicationlevel research on LLM-based agents, researchers also explored integrating LLMs into the systemlevel [5, 30], which enables LLM-based agent operating system (AIOS) that provides fundamental services to the agent applications on top of it, such as agent scheduling, memory and storage management, tool management, security features, and access control."
        },
        {
            "title": "3 Architecture of LSFS",
            "content": "Traditional file systems primarily rely on file attributes to build metadata. These attributes, typically obtained by scanning the file, include file size, creation and modification timestamps. The actual file content is stored as binary data, with traditional file systems leveraging index structures such as B+ trees to efficiently locate this data. While these designs continue to evolve and improve, they generally overlook the semantic content information within files, making it difficult for traditional file systems to support tasks that require deeper semantic understanding. To address this limitation, we propose semantic file management system powered by LLMs and vector databases. This system Figure 2: (a) provides overview of the LSFS architecture, and (b) shows the internal APIs and syscalls in LSFS. retains traditional file attributes and integrates semantic information derived from the files content. Unlike traditional file systems, our system enhances metadata by including user-defined keywords that capture the essence of the files content, in addition to standard file attributes. Our semantic file management system employs embedding models to convert textual content into semantic vector representations. These vectors enable the construction of semantic-based data index, facilitating the structured storage of data and enabling robust, semantically-driven file retrieval and management. This optimized architecture allows for more intelligent and semantic interactions with file data, enhancing the systems functionality and making it particularly well-suited for modern file management tasks. 4 Figure 2(a) outlines the overall architecture of our LSFS. LSFS operates as an additional layer on top of traditional file systems, which constructs semantic index of the file in the format of embedding vectors, thereby enabling more advanced content-based file management operations. LSFS provides range of system calls (syscalls) that support complex file operations and reuse. The system also includes supervisor that works in tandem with the traditional file management system. This supervisor continuously monitors changes in the traditional file system and synchronizes those changes in LSFS, ensuring that the contents of LSFS remain consistent with the underlying file system. Figure 2(b) presents an overview of the syscall structure in LSFS. These syscalls are primarily categorized into two types: atomic syscalls and composite syscalls. The former handles basic operations such as adding, deleting, modifying, and searching files, while the latter builds upon atomic syscalls to execute more complex functions. On the top of the syscalls, LSFS APIs are constructed by utilizing one or more syscalls and integrating LLMs. These APIs facilitate more advanced yet general-purpose file operations, demonstrating the superiority of LSFS in handling such tasks. Further details on these capabilities will be discussed in Section 4.3."
        },
        {
            "title": "Implementation of LSFS",
            "content": "In this section, we introduce our implementation of the LSFS. We present the key functions implemented in our LSFS and compare the counterparts with traditional file systems, which can be seen from the Table 1. Table 1: Comparison of some key functions between our LSFS and traditional file system (TFS). Function create new directory open file read file get file state and metadata delete directory delete file write data overwrite data update the access time automatic comparison generate link lock or unlock file rollback file translation file group merge file keyword retrieve semantic retrieve Hybrid retrieval TFS mkdir() open() read() stat() rmdir() unlink() / remove() write() write() utime() symlink() / link() / readlink() flock() snapshot + rollback cat grep LSFS (Ours) create_or_get_file() create_or_get_file() create_or_get_file() create_or_get_file() del_() del_() insert() overwrite() update_access_time() compare_change() generate_link() lock_file() / unlock_file() rollback() file_translate() group_text() / group_se() join() keyword_retrieve() semantic_retrieve() integrated_retrieve() We introduce the implementation of LSFS from the bottom to the top in the LSFS architecture shown in the Figure 2. We start by introducing the basic syscalls implemented in LSFS and introduce the supervisor which interacts between LSFS syscalls and traditional file systems. Then we present the APIs that built upon the syscalls to achieve more complex functionalities. After that, we introduce the LSFS parser on top to show how natural language prompts have been decoded into executable LSFS APIs. At last, we use different concrete prompts to show how different modules in the LSFS are executed to achieve functionalities. 4.1 Basic Syscall of LSFS In this section, we introduce the syscalls implemented for LSFS. These syscalls are primarily categorized into two types: atomic syscalls and composite syscalls. Atomic syscalls involve operations covering the most basic operations, e.g., create, retrieve and write of files. Composite syscalls are combinations of two or more atomic syscalls to execute composite functions, e.g., join and group by. Atomic Syscall of LSFS. These syscalls involve the atomic operations that cannot be divided further into sub operations, i.e., creation, retrieval, write, and deletion of files. create_or_get_file() This syscall integrates various functions of traditional file systems, including creating, reading, and opening files, and performs specific operations based on the pro5 vided parameters. The return value of this syscall can be used to retrieve file metadata, modification timestamps, the files memory path, and other essential information. add_() This syscall is used to write new content to the end of specified file within the LSFS. overwrite() This syscall is used to overwrite the contents of the original file with the new file and generate new metadata for this file as required by the user. del_() This syscall is designed to delete specified files and offers two methods of deletion. First, it allows deletion by specifying the file name or file path. Second, it supports keyword-based deletion, identifying and removing files that contain given keyword. Additionally, if all files within directory are deleted, the syscall automatically remove the directory itself. keywords_retrieve() This syscall is used to implement keyword search function that retrieves files containing keyword in specified directory. It supports single condition matching and multi-condition matching, and returns the filename and file contents. semantic_retrieve() This syscall is used to implement the semantic matching function to retrieve the top-n highest semantic similarity files in directory and retrieval conditions according to the similarity score. It returns the filename and file contents. Composite Syscall of LSFS. These syscalls involve composite operations that are built by combining two or more atomic syscalls to perform operations. create() This syscall is used to create files in bulk in LSFS by importing the path of the folder in memory and importing all the files in the folder under the corresponding directory. lock_file() / unlock_file() The two syscalls are used to lock/unlock file by changing the file state to read-only via lock_file and changing the file permission to read-write via unlock_file. group_semantic() The syscall can select the content in the specified directory and retrieve the files that have high similarity with the query, create new directory, and place the selected files in the directory to facilitate the operation of the files that have the same subject. group_keywords() This syscall can select the files that contain the retrieved keywords in the specified directory, create new directory, and place the selected files in the directory to facilitate the operation of the files that contain the same keywords. integrated_retrieve() This syscall combines two retrieval methods to retrieve the files that contain particular keyword and that are similar in content to the retrieval query. The order of retrieval is keyword search first, and then semantic search. file_join() This syscall can be used to concatenate two files into single file, either by creating new file to concatenate or by concatenating the original file directly. 4.2 Supervisor The supervisor is implemented to track the changes in the files in the disk and sync the changes to the LSFS. The supervisor periodically scans the files within its specified directory. When it detects any change or deletion of the file content, it automatically synchronizes this information with the LSFS by invoking the appropriate syscall. This ensures that the state of the file in the LSFS reflects the current state of the file in memory. In order to ensure the accuracy of other syscall operations on the file after Supervisor modifies the internal file status of LSFS, LSFS introduces the process lock mechanism to ensure that multiple processes can access the file correctly. When asked, the supervisor can generate status change reports. For example, when file is modified, the supervisor invokes LLMs to generate detailed modification log, compares the contents of the file before and after modification, and presents this log to the user. 4.3 API of LSFS In this module, we introduce the APIs that are implemented on top of the syscalls mentioned in Section 3 to support higher-level semantic file management functions. Specifically, we provide the following APIs that cover the basic semantic file management requirements, i.e., semantic CRUD (create, read, update, and delete) of files. 6 Retrieve-Summary API. This API retrieves files based on user-specified conditions and provides concise summaries. Unlike traditional systems, it offers both keyword and semantic search, along with LLM-powered content summarization. The API supports three retrieval methods: keyword, semantic, and integrated, which are built on top of the keywords_retrieve(), semantic_retrieve(). and integrated_retrieve() syscalls. In this API, an interaction interface is also provided for users to refine the results by excluding irrelevant files, which are then passed to LLMs for summarization. Change-Summary API. This API is used to modify the contents of file and compare them before and after to summarize the changes. At the same time, the Supervisor module is introduced to monitor the file changes in the traditional file system. Unlike traditional file systems that require tedious operating system commands, this API allows users to locate target files using natural language and automatically generate summary of file changes through LLMs integration. The API is implemented by leveraging the supervisor and the overwrite() and del_() syscalls. In the change-summary API, when the target file is updated with the content of the source file, it will generate summary of the modifications. Meanwhile, the filename is used as the key in the version recorder, while the metadata and contents of the file are stored as the corresponding values for the version control use. Rollback API. This API is designed to achieve version restoration by utilizing the version recorder from the change-summary API, making version rollbacks more manageable. In this API, the overwrite() and create_or_get_file() syscalls are employed. Traditional file systems like ZFS, BtrFS, and NTFS offer rollback capabilities, but they primarily rely on snapshots, where the system captures the state of files at specific point in time and restores them to that version. Our rollback API in the LSFS introduces two rollback methods for greater flexibility and ease of use. The first is time-based rollback, where the LLMs parses the rollback time from the users input and reverts the file to the corresponding version. The second is version-based rollback, allowing users to specify in the prompt how many versions backward they wish to revert. This dual approach makes it easier for users to rollback to the target version of files. Link API. This API is designed to enable the creation of shareable file links. In traditional file systems, links can only be generated for local access, limiting collaboration. However, with the LSFSs link API, shareable links can be generated for broader accessibility. Specifically, the API leverages cloud database, e.g., Google Drive, to upload files and generate the shareable link. Additionally, validity period can be passed as an argument for this API, once the period expires, the link API automatically revokes the link and terminates access for secure and time-bound file sharing. 4.4 LSFS Parser We design an LSFS parser to guide this conversion process and create general prompt template for future API designs to extract parameters from natural language prompts. As illustrated in the accompanying Figure 3, we leverage large language model to parse natural language commands. For each API, we design distinct system prompt words, which, when input alongside the users command, allow the language model to automatically detect and extract the key parameters, outputting them in commaseparated format. By applying simple regex to this output, we can directly convert the extracted keywords into syscall parameters, enabling seamless execution of the API command. This allows us to efficiently map natural language commands to the exacted parameters required by the system calls, benefiting interactions between natural language prompts and LSFS. Figure 3: The example of using LLMs to extract the key information from natural language prompt. 7 Figure 4: Details of different API callings inside the LSFS. In this figure, (a)-(d) show interactive examples of how LSFS solves file management tasks step by step. 4.5 The Interaction between Modules In Figure 4, we present the examples to demonstrate how components of LSFS interact with each other to achieve different functionalities. The upper section of Figure 4 depicts the workflow of the retrieve-summary API, while the lower section outlines the workflows of the change-summary API and rollback API. In the upper part of Figure 4, the LSFS parser decodes prompts into API calls with API name and API arguments. Then LSFS executes the API to check vector database to get results. This API also provides user-interaction interface for the users to verify results. After the verification, the content will be summarized by leveraging LLM. In the lower part of Figure 4, when modification request is submitted, the LSFS parser decodes the file information (name and location) that is to be modified. The LSFS then modifies the semantic changes in both the vector database and the files stored in the disk. Meanwhile, the supervisor of the LSFS is kept running to ensure consistency between the semantic index of files in the LSFS and the files stored in the disk. Upon updated, the summarization API compares the file contents before and after the change to generate detailed change log. Additionally, the API stores the pre-modification content in the version recorder. If rollback is requested, the API retrieves the specific version from the version recorder and synchronizes it in both the LSFS and files in the disk."
        },
        {
            "title": "5 Evaluation",
            "content": "In this section, we propose the following research questions regarding the performance of LSFS and conduct experiments to answer these research questions. RQ1: What is the success rate of the LSFS parser to parse natural language prompts into executable API calls? RQ2: How does LSFS perform in semantic file management tasks, e.g., semantic file retrieval and semantic file rollback? RQ3: Can LSFS still maintain good performance in non-semantic file management tasks, such as keyword-based file retrieval and file sharing? 5.1 RQ1: Effectiveness of LSFS Parser For RQ1, we assess the accuracy of the LSFS parser in translating user natural language prompt into executable LSFS API calls. We evaluate the accuracy of LSFS parser with 30 different samples for each API on different LLM backbones, i.e., Gemmi-1.5-Flash, GPT-4o-mini, Qwen-2, and Gemma-2. The results, illustrated in Figure 5, reveal that the LSFS parser performs exceptionally well on parsing prompts related to change-summary API and link API (for which the semantic information in the user prompt is relatively simple), achieving high accuracy across all LLMs, with some reaching 100% accuracy. For more complex prompts, such as those intended for the rollback API and retrievesummary API (for which the semantic information in the user prompt is complex), accuracy remains above 85% for most models, except for Gemma-2. The average parsing accuracy reaches 90%. These results show that the LSFS parser can effectively translate natural language information into executable API calls, showcasing its reliability in diverse scenarios. In all cases, the translated command is provided to users for approval before real execution, ensuring safety when executing commands in the file system. Figure 5: The accuracy of LSFS parser in translating natural language prompt to executable API calls. 5.2 RQ2: Analysis of LSFS in Semantic File Management Tasks Table 2: Comparison of the accuracy and execution time between using LSFS and the baseline which incorporates LLM into traditional file system without using LSFS. LLMs backbone # files Accuracy of target file retrieval Retrieval time Gemini-1.5-flash GPT-4o-mini w/o LSFS 75.0% 77.3% 70.91% 80% 69.1% 69.2% w/ LSFS 95.0%(20.0%) 91.3%(14.0%) 93.4%(22.5%) 95.0%(15.0%) 91.3%(22.2%) 93.4%(24.2%) 10 20 40 10 20 40 w/o LSFS 97.40(s) 213.69(s) 312.39(s) 61.14(s) 129.92(s) 239.49(s) w/ LSFS 14.39(s)(85.2%) 116.69(s)(92.2%) 123.86(s)(92.4%) 30.64(s)(49.9%) 40.39(s)(68.9%) 57.1(s)(76.2%) Performance Analysis in Semantic File Retrieval. In our experiments, we compare the performance of using LSFS and without using LSFS under the same LLM backbone. The details of the prompts we use for the comparison are in the Appendix B. Specifically, we use Gemini-1.5-flash and GPT-4o-mini as the LLM backbone, respectively, for the comparison. As shown in Table 2, using LSFS to implement the retrieval function significantly enhances both the accuracy and the efficiency compared to only leveraging LLM for retrieval without using LSFS. As file number increases, the retrieval accuracy tends to drop significantly when using LLM for retrieval without LSFS. This is because more files can lead to longer context for the LLM, which degrades the LLMs performance of identifying information in the long context. By contrast, using LSFS can still achieve good retrieval accuracy and have much better retrieval efficiency when file number increases, because lsfs replaces the reasoning process of LLM by using keyword matching and semantic similarity matching, it saves lot of time and avoids the errors of LLM when facing complex input text. We conduct case study using the example prompt Please search for the two papers most related to LLMs Uncertainty from folder named example to better illustrate the retrieval results, which is shown in the Figure 6. For the method without using LSFS, the answer to the intermediate result is GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning , which fails to 9 Figure 6: file summarization agent instance to illustrate the comparison between LLM-leveraged methods without using LSFS and using LSFS. identify target paper that is relevant to LLMs Uncertainty due to the long-context that makes it difficult for LLM to understand and retrieve the correct information. Furthermore, the input length limitation of LLM necessitates batch-processing strategy for file input, which can result in selecting the best of the worst candidates. This may lead to inaccurate intermediate results that ultimately impact the final output. In contrast, LSFS avoids this issue by evaluating all files holistically, scoring and sorting the final results without intermediate outputs, thus bypassing the constraints of limited search scope. Experimental results show that LSFS consistently delivers more accurate results. Scalability Analysis in Semantic File Rollback. LSFS supports semantic file rollback, which enables the restoration of file to particular version specified by the time requested by the user or number of versions, recorded by the Version Recorder. We vary the the number of rollback versions and calculate their corresponding rollback time, to evaluate the stability and efficiency of the version rollback process, The results, shown in Figure 7, illustrate the consistency in the time consumed during version rollbacks. We use Gemmi-1.5-Flash, GPT-4o-mini, Qwen2 as the LLM backbones for the experiments. In our experiment, we set the file version rollback process to begin from the newest one version, with rollback occurring every last 5 versions. The experiment continues until maximum of 40 versions had been rolled back. Each rollback is simultaneously updated in both the LSFS and file of the computers local disk. As shown in the Figure 7, across all three LLM backbones, the rollback time does not increase exponentially with the number of versions rolled back. Instead, it tends to plateau. This is because the rollback API stores each version of the file independently, thereby avoiding long rollback paths to implement rollbacks and achieving stable rollback time. Figure 7: The relationship between the number of versions of rolled back file and the rollback time. 5.3 RQ3: Analysis of LSFS in Non-Semantic File Management Tasks For RQ3, we evaluate on non-semantic file management tasks to measure whether LSFS can still maintain good performance as traditional file systems in these tasks. Performance Analysis in Keyword-based File Retrieval. In this section, we compare LSFS and traditional file system in keyword-based file retrieval task. The task is to use keywords existing in the filename or file content to retrieve files. We build hierarchical file folder with file numbers as 10, 10 20, and 40, respectively, for this task. We use two types of retrieval prompts, i.e., single-condition and multi-condition, to evaluate LSFS and traditional file systems to retrieve relevant files containing specific keywords. The details of how we construct prompts for this task can be seen at Appendix B. We consider the following methods as the retrieval baselines in the traditional file system. It is important to note that the original grep command can only deal with plain text files, such as .txt and .md files, and cannot support binary files, such as .pdf and .doc files. Therefore, we make two enhanced versions, named as TFS-grep and TFS-grep* to make the comparison. TFS search window: We use the default search window in the computers file folder to retrieve files (i.e., Spotlight in MacOS) which supports retrieving by keywords in the file content. TFS-grep: We use Python program to convert the binary file to plain text file and then perform grep operation on the converted plain text file. TFS-grep*: After converting binary files into plain text, issues such as missing spaces, incorrect line breaks, and formatting errors may arise. In the TFS-grep* process, we correct the format of the converted files and then run the grep operation on the properly formatted versions. Table 3: Comparison between LSFS and methods in the traditional file system (TFS) in retrieving files by keywords in the names and content of files. Metric Precision Recall F1-score # files TFS search window TFS-grep TFS-grep* LSFS 0.950 0.870 0.863 0.833 0.933 0.960 0.891 0.900 0.909 0.389 0.396 0.403 0.416 0.292 0.306 0.402 0.337 0.348 0.708 0.724 0.691 1.000 1.000 1.000 0.829 0.840 0. 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 10 20 40 10 20 40 10 20 40 We use precision, recall and F1-score to measure the retrieval performance. From the results presented in Table 3, we can find that LSFS outperforms TFS search window and TFS-grep, only second to the TFS-grep*. We find that the built-in retrieval tool in the TFS (e.g., the system search window) can not generate stable retrieval results, although it has higher recall. Due to the fuzzy search feature in the built-in search window, it can easily retrieve inaccurate results for which the retrieved file content can only match part of the keywords. For example, if we search for an article written by John Smith, any other article with name of John can be returned as search result, thus the results may often include many irrelevant results, which complicates the process for users to filter through them. The TFS-grep* command, although achieving perfect results, still has several limitations. First, the commands can be too difficult to construct, especially when the file retrieval queries have multiple conditions. For instance, when user requests to retrieve all files containing the keywords and B, the command would be as follows: find /path -type -exec grep -l \"keyword1\" ; -exec grep -l \"keyword2\" ;. Second, since the grep command itself does not support retrieval of binary files, it is necessary to manually adjust the format of each file, which is time-consuming and greatly reduces the efficiency of the retrieval process for users. Our LSFS can retrieve all types of text files, from plain text to binary files, while maintaining high precision and recall. The LSFS read operation is capable of processing both plain text and binary text, converting them into the systems vector database. This enables seamless retrieval operations across various types of files. Furthermore, LSFS allows users to describe their retrieval tasks in natural language, eliminating the need to write complex commands. Performance Analysis in File Sharing. For the file sharing task, we evaluate whether system can output shareable link with an expiration time according to the prompts. Specifically, we compare LSFS with four different baselines as following. Gemini-1.5-flash: We use Gemini-1.5-flash as the LLM backbone to write the code that generates the link for the target file, and then use the Python compiler to check the validity of the code. GPT-4o-mini: We employ GPT-4o-mini as the LLM backbone to generate code for creating links of the target file, followed by using the Python compiler to verify the codes validity. 11 AutoGPT: We create CoderGPT agent by initializing GPT as an expert on coding, which is used to generate the code. Code Interpreter: We use the Code Interpreter module of the OpenAI web client to generate relevant code and subsequently check the validity of the code. Table 4: Comparison between LSFS and other LLM-leveraged methods in File Sharing. Method Gemini-1.5-flash GPT-4o-mini AutoGPT Code Interpreter LSFS Code Generation Rate 65% 60% 50% 100% 100% Success rate of generating sharable links (#20) Link Validness Rate 45% 30% 15% 65% 100% Link Generation Rate 45% 35% 45% 75% 100% Final Success Rate 10% 5% 5% 0% 100% In the experiments, four key metrics are used to evaluate the effectiveness of whether the system can successfully fulfill the file sharing task: whether the LLM generates code, the correctness of the generated code, the effectiveness of the generated links, and whether the links are actually shareable. We evaluate with 20 file sharing task prompts for all the methods. The results show that although all methods even vanilla LLMs can successfully generate code, they do not consistently generate valid links. In many cases, these links are local rather than shareable links, and only small fraction of the links for files are shareable. In contrast, our LSFS system achieves 100% link generation success rate, showing strong task fulfillment ability on the file sharing task."
        },
        {
            "title": "6 Conclusions",
            "content": "In this paper, we present an LLM-based semantic file system (LSFS), which offers advancement over traditional file systems by enabling files to be stored and managed based on their semantic information. This enhancement improves the systems ability to comprehend and utilize the semantics embedded in file contents. Additionally, we introduce series of reusable semantic syscalls and framework for mapping natural language into LSFS parameters. These innovations provide foundation for future research and development in the area of semantic file management systems. Looking ahead, future work can further explore and expand the application of LSFS across wider scope of user environments and integrate semantic file management into everyday computing. This can help to simplify user operations and pave the way for more intelligent and user-friendly operating system."
        },
        {
            "title": "7 Acknowledgement",
            "content": "We thank Minghua Ma and Sam Lin for the useful discussions with them."
        },
        {
            "title": "References",
            "content": "[1] Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 conference on empirical methods in natural language processing, pages 15331544, 2013. [2] Jonathan Berant and Percy Liang. Semantic parsing via paraphrasing. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14151425, 2014. [3] Gordon S. Blair, John A. Mariani, John R. Nicol, and Doug Shepherd. knowledge-based operating system. The Computer Journal, 30(3):193200, 1987. [4] Stephan Bloehdorn, Olaf Görlitz, Simon Schenk, Max Völkel, et al. Tagfs-tag semantics for hierarchical file systems. In Proceedings of the 6th International Conference on Knowledge Management (I-KNOW 06), Graz, Austria, volume 8, pages 68, 2006. [5] Rogerio Bonatti, Dan Zhao, Francesco Bonacci, Dillon Dupont, Sara Abdali, Yinheng Li, Justin Wagle, Kazuhito Koishida, Arthur Bucker, Lawrence Jang, et al. Windows agent arena: Evaluating multi-modal os agents at scale. arXiv preprint arXiv:2409.08264, 2024. 12 [6] James Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. Driving semantic parsing from the worlds response. In Proceedings of the fourteenth conference on computational natural language learning, pages 1827, 2010. [7] Hao Dai, Yang Wang, Kenneth Kent, Lingfang Zeng, and Chengzhong Xu. The state of the art of metadata managements in large-scale distributed file systemsscalability, performance and availability. IEEE Transactions on Parallel and Distributed Systems, 33(12):38503869, 2022. [8] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam Stevens, Boshi Wang, Huan Sun, and Yu Su. Mind2web: Towards generalist agent for the web. Advances in Neural Information Processing Systems, 36, 2024. [9] Oliver Eck and Dirk Schaefer. semantic file system for integrated product data management. Advanced Engineering Informatics, 25(2):177184, 2011. [10] Ruifang Ge and Raymond Mooney. statistical semantic parser that integrates syntax and In Proceedings of the Ninth Conference on Computational Natural Language semantics. Learning (CoNLL-2005), pages 916, 2005. [11] Yingqiang Ge, Wenyue Hua, Kai Mei, Juntao Tan, Shuyuan Xu, Zelong Li, Yongfeng Zhang, et al. Openagi: When llm meets domain experts. Advances in Neural Information Processing Systems, 36, 2024. [12] Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan, and Yongfeng Zhang. LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem. arXiv:2312.03815, 2023. [13] David Gifford, Pierre Jouvelot, Mark Sheldon, and James OToole Jr. Semantic file systems. ACM SIGOPS operating systems review, 25(5):1625, 1991. [14] Yulu Gong, Jiaxin Huang, Bo Liu, Jingyu Xu, Binbin Wu, and Yifan Zhang. Dynamic resource allocation for virtual machine migration optimization using machine learning. arXiv preprint arXiv:2403.13619, 2024. [15] Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, and Aleksandra Faust. real-world webagent with planning, long context understanding, and program synthesis. arXiv preprint arXiv:2307.12856, 2023. [16] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu. Reasoning with language model is planning with world model. arXiv preprint arXiv:2305.14992, 2023. [17] Darren Hardy and Michael Schwartz. Essence: resource discovery system based on semantic file indexing. In USENIX Winter, pages 361374. Citeseer, 1993. [18] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt: Meta programming for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352, 2023. [19] Yu Hua, Hong Jiang, Yifeng Zhu, Dan Feng, and Lei Tian. Smartstore: new metadata organization paradigm with semantic-awareness for next-generation file systems. In Proceedings of the conference on high performance computing networking, storage and analysis, pages 112, 2009. [20] Yu Hua, Hong Jiang, Yifeng Zhu, Dan Feng, and Lei Tian. Semantic-aware metadata organization paradigm in next-generation file systems. IEEE Transactions on Parallel and Distributed Systems, 23(2):337344, 2011. [21] Yu Hua, Hong Jiang, Yifeng Zhu, Dan Feng, and Lei Xu. Sane: Semantic-aware namespacein ultra-large-scale file systems. IEEE Transactions on Parallel and Distributed Systems, 25(5):13281338, 2013. [22] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy, and Luke Zettlemoyer. Learning neural semantic parser from user feedback. arXiv preprint arXiv:1704.08760, 2017. [23] Mingyu Jin, Qinkai Yu, Haiyan Zhao, Wenyue Hua, Yanda Meng, Yongfeng Zhang, Mengnan Du, et al. The impact of reasoning step length on large language models. ACL, 2024. [24] Aishwarya Kamath and Rajarshi Das. survey on semantic parsing. arXiv preprint arXiv:1812.00978, 2018. 13 [25] Ramanpreet Kaur, Dušan Gabrijelˇciˇc, and Tomaž Klobuˇcar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023. [26] Andrew Leung, Aleatha Parker-Wood, and Ethan Miller. Copernicus: scalable, highperformance semantic file system. University of California, Santa Cruz, UCSC-SSRC-09, 6, 2009. [27] Xi Victoria Lin, Chenglong Wang, Luke Zettlemoyer, and Michael Ernst. Nl2bash: corpus and semantic parser for natural language interface to the linux operating system. arXiv preprint arXiv:1802.08979, 2018. [28] Zhiwei Liu, Weiran Yao, Jianguo Zhang, Liangwei Yang, Zuxin Liu, Juntao Tan, Prafulla Choubey, Tian Lan, Jason Wu, Huan Wang, et al. Agentlite: lightweight library for building and advancing task-oriented llm agent system. arXiv preprint arXiv:2402.15538, 2024. [29] Mallik Mahalingam, Chunqiang Tang, and Zhichen Xu. Towards semantic, deep archival file system. In The Ninth IEEE Workshop on Future Trends of Distributed Computing Systems, 2003. FTDCS 2003. Proceedings., pages 115121. IEEE, 2003. [30] Kai Mei, Zelong Li, Shuyuan Xu, Ruosong Ye, Yingqiang Ge, and Yongfeng Zhang. Aios: Llm agent operating system. arXiv e-prints, pp. arXiv2403, 2024. [31] Prashanth Mohan, Venkateswaran Raghuraman, and Arul Siromoney. Semantic file retrieval in file systems using virtual directories. In the Poster Session of the 13th Annual IEEE International Conference on High Performance Computing (HiPC), Bangalore, India. Citeseer, 2006. [32] Raymond Mooney. Learning for semantic parsing. In International Conference on Intelligent Text Processing and Computational Linguistics, pages 311324. Springer, 2007. [33] Hoifung Poon and Pedro Domingos. Unsupervised semantic parsing. In Proceedings of the 2009 conference on empirical methods in natural language processing, pages 110, 2009. [34] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, arXiv preprint and Maosong Sun. Communicative agents for software development. arXiv:2307.07924, 2023. [35] Bernhard Schandl and Bernhard Haslhofer. The sile modela semantic file system infrastructure for the desktop. In European Semantic Web Conference, pages 5165. Springer, 2009. [36] Stefan Schneider, Narayanan Puthenpurayil Satheeschandran, Manuel Peuster, and Holger Karl. Machine learning for dynamic resource allocation in network function virtualization. In 2020 6th IEEE conference on network softwarization (NetSoft), pages 122130. IEEE, 2020. [37] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. Advances in Neural Information Processing Systems, 36, 2024. [38] Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of intelligent llm agents. arXiv e-prints, pages arXiv2306, 2023. [39] Yushi Wang, Jonathan Berant, and Percy Liang. Building semantic parser overnight. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 13321342, 2015. [40] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837, 2022. [41] Yuk Wah Wong and Raymond Mooney. Learning for semantic parsing with statistical machine translation. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 439446, 2006. [42] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. Autogen: Enabling next-gen llm applications via multi-agent conversation. In ICLR 2024 Workshop on Large Language Model (LLM) Agents, 2024. [43] Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumianze Liu, Shunyu Yao, Tao Yu, and Lingpeng Kong. Os-copilot: Towards generalist computer agents with self-improvement. arXiv preprint arXiv:2402.07456, 2024. [44] John Yang, Carlos Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, and Ofir Press. Swe-agent: Agent-computer interfaces enable automated software engineering. arXiv preprint arXiv:2405.15793, 2024. [45] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022. [46] Wen-tau Yih, Xiaodong He, and Christopher Meek. Semantic parsing for single-relation question answering. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 643648, 2014. [47] Zhuosheng Zhang and Aston Zhang. You only look at screens: Multimodal chain-of-action agents. arXiv preprint arXiv:2309.11436, 2023. [48] Zirui Zhao, Wee Sun Lee, and David Hsu. Large language models as commonsense knowledge for large-scale task planning. Advances in Neural Information Processing Systems, 36, 2024."
        },
        {
            "title": "A The Implementation Details of Syscall",
            "content": "create_or_get_file() This syscall integrates multiple traditional file system functions such as creating files, reading files, and opening files, enabling different operations based on the parameters provided. The function accepts four parameters: the LSFS path, the target directory name, the target filename, and the import file. The first two parameters are positional, while the latter two are default parameters. When all four parameters are provided, if the target file does not exist within LSFS, the system will create an imported file using the specified target directory name, target filename, and the import file. The import file can be supplied as string or file path, and our system supports various text file formats, including PDF, DOCX, TXT and so on. If the target filename is not passed, the syscall returns list of files within the target directory. If the content of the import file is not provided, the syscall will return the target file, allowing access to its content, metadata, embedding vector, and other associated information. add_() This syscall facilitates appending content to file by accepting four positional parameters: the LSFS path, the target directory name, the target filename, and the content of the import file. The import file content can be provided either as string or text file in various formats. When all four parameters are supplied, the syscall appends the specified content to the designated file within the system. overwrite() This syscall implements the overwriting of the file contents. The passed Parameters are also LSFS path, target directory name, target filename, import file, all of which are Positional Parameters. When passed in, LSFS will overwrite everything in the source file with the contents of the imported file. del_() This syscall performs the deletion of files and directories by accepting four parameters: the LSFS path, the target directory name, the target filename, and the key text. The first two parameters are positional, while the last two are default parameters. If neither of the last two parameters is provided, the syscall raises an error, indicating that at least one must be passed. When the target filename is provided, LSFS deletes the specified file. If the key text is provided instead, the system searches for files containing the key text within the target directory and deletes them if found. Additionally, once all files within directory are deleted, LSFS will automatically remove the directory. keywords_retrieve() This syscall implements LSFSs keyword search functionality, retrieving all files within specified directory that contain given keyword. The arguments passed include the LSFS path, directory name, keyword, and matching condition. The LSFS path and keyword are Positional Parameters, while the directory name and condition are Default Parameters. If directory name is provided, the syscall retrieves files within that directory that match the keyword; otherwise, it searches across the entire system. To match multiple keywords, the matching condition must be passed, specifying the relationship between keywords, such as and or or. The search results return list of file names and list of file contents. semantic_retrieve() This syscall implements the semantic similarity search function within the LSFS, allowing retrieval of files that semantically match given query within specified directory. The parameters for this function include the LSFS path, the target directory, the search keyword, and the number of results to return. The LSFS path and search keyword are Positional Parameters, while the target directory and number of results are Default Parameters. Similar to keyword-based retrieval, the search directory will be determined based on whether target directory is provided. The number of results to return dictates how many of the top-scoring matches are retrieved. Our semantic retrieval leverages the LlamaIndex framework. During file creation, LlamaIndex vector store is generated alongside the index, enabling more intelligent and efficient data retrieval. This setup ensures that semantic queries can return highly relevant results with improved accuracy. The search results return list of file names and list of file contents. create() This syscall function facilitates batch directory creation and bulk file reading. It accepts the LSFS path, directory name, and the import file path as Positional Parameters. This function can read multiple files at once and store them in the specified target directory. If the filenames are not explicitly provided, they will default to the original filenames from the filesystem. 16 lock_file() / unlock_file() These syscalls handle the locking and unlocking of files within the LSFS, allowing files to be placed in read-only mode to prevent modification. Both syscalls accept the LSFS pathname, directory name, and filename as parameters. Upon execution, the lock_file() syscall updates the files metadata to reflect read-only state, effectively restricting any modifications. Conversely, the unlock_file() syscall modifies the metadata to restore read and write permissions, enabling the file to be edited again. These operations provide granular control over file access and modification rights. group_keywords() This syscall groups all files containing common keyword and creates new directory for them. The parameters passed are the LSFS name, the keyword, the name of the new directory, the target directory, and the search criteria. Among these, the LSFS name, keyword, and new directory name are Positional Parameters, while the target directory and search criteria are Default Parameters. The syscall first performs search using the keyword through an atomic syscall to identify all matching files. It then uses these files to create the specified new directory, facilitating easier file management and organization. group_semantic() This syscall facilitates the organization of files by grouping all those containing common keyword into new directory. It takes the following parameters: the LSFS path, the keyword, the new directory name, the target directory, and the search criteria. Here, the LSFS path, keyword, and new directory name are Positional Parameters, while the target directory and search criteria are Default Parameters. The syscall first performs keyword search through an atomic syscall to identify all files that match the keyword. It then creates new directory with the specified name and moves the identified files into this directory. This functionality streamlines file management and enhances organizational efficiency. integrated_retrieve() This syscall is designed for composite searches, combining both semantic and keyword search functionalities. The parameters are distributed as follows: the LSFS path, keyword, new directory name, and search criteria are Positional Parameters, while the target directory and additional search conditions are Default Parameters. The syscall first invokes the keyword grouping function to retrieve all files associated with the compound keyword and organizes them into new directory. It then performs semantic search within this directory, ultimately returning the filenames and contents of the files that match the search criteria. This integrated approach allows for more comprehensive and flexible search capabilities. file_join() This syscall facilitates the connection of two files, with the parameters including the LSFS path, the directory name and filename of both files, and the connection conditions. The Default Parameters are the destination directory for file 2 and the connection condition, while the LSFS path, directory names, and filenames are Positional Parameters. If the destination directory for file 2 does not exist, the two files will be placed in the same directory. If the destination directory exists, the files will be placed in their respective directories. If the join condition is set to new, the syscall will preserve the original files, concatenate their text contents, and create new file in the destination directory of file 1. The new files name will be combination of the two target filenames. If the join condition is not new, the contents of file 2 will be appended directly to the contents of file 1, and file 2 will then be deleted. 17 Details of keyword-based and semantic retrieval. Table 5: The example of instruction of keyword-based retrieval with single-condition and multicondition in LSFS and in LLM without LSFS. Task Task Example Method Keyword-based Retrieval (Single-condition) Find papers in the computervision category authored by Emily Zhang. LLM w/o LSFS LSFS Keyword-based Retrieval (Multi-condition) Find papers from either Cambridge University or Columbia University. LLM w/o LSFS LSFS Instruction At current step, you need to judge if the input paper satisfy [retrieve condition]. If yes, you should summarize the paper, if no you dont need to output anything. The paper is [file content] LSFS input: Find papers in the computervision category authored by Emily Zhang. LLM input: You need to summary the content. The content is [file content] At current step, you need to judge if the input paper satisfy [retrieve condition]. If yes, you should summarize the paper, if no you dont need to output anything. The paper is [file content] LSFS input: Find papers from either Cambridge University or Columbia University. LLM input: You need to summary the content. The content is [file content]. Table 6: The example of instruction of semantic-based retrieval with single-condition and multicondition in LSFS and in LLM without LSFS. Task Task Example Method Instruction Fixed prompt: In the next step, you need to accept and remember the paper, but do not generate any outputs. Until you are told to output something. Each input: The paper is [content]. Semantic-based Retrieval Locate the 3 papers showing the highest correlation with reinforcement learning in LLMtraining. LLM w/o LSFS After every five entries: Now you can to output the answer. You need to find [retrieve number] papers which most relate to [retrieve condition] from previous record and summary them respectively. Final input: Now you can to output the answer. You need to choose from memory cache to find the [retrieve number] papers that is most relevant to [retrieve condition] LSFS input: Locate the 3 papers showing the highest correlation with reinforcement learning in LLM-training. LLM input: You need to summary the content. The content is [file content] LSFS"
        },
        {
            "title": "C The Instruction of API",
            "content": "Table 7: Some examples of instruction of API in Section 4.3. For every API, we provide different instructions in different task condition. The instruction of retrieve-summary API is in Appendix B. API Type Instruction LSFS Input: w/ directory: Change the content of /xxxx/xxxx.txt to old-file under llm-directory. Change-Summary API w/o directory: Modify /xxxx/xxxx.txt to contain change-file. Rollback API Link API LLM Input: At current step, you need to summary differences between the two contents, the content before the update is [old file], the content after the update is [new file] LSFS Input: By date: Revert the file named syntax to its version from 2023-6-15. By version number: Rollback the cnn file to the state it was in 3 versions ago. LSFS Input: w/ period of validity: Provide link for llm-base that will be active for 3 months. w/o period of validity: Generate link for system-architecture."
        },
        {
            "title": "D Experiment Details of File Sharing",
            "content": "In this module, we show some examples that the LLM execution results in failure to correctly generate shareable links. We give each LLM the following input:You are good at writing code, please write code to generate shared links for the file path. D.1 The code cannot generate link In the experiment, the code generated by LLMs may not produce the correct link or link address. For instance, even after successfully installing the required file packages, the following code block demonstrates that the generated link does not direct to the intended target file. The pseudo-code is in Algorithm 1 Algorithm 1 Pseudo-code of D.1. app = Flask(__name__) # Path to the PDF file pdf_file_path = /xxxx/xxx.pdf @app.route(/download) def download_file(): if __name__ == __main__: app.run(debug=True) return send_file(pdf_file_path, as_attachment=True) D.2 The code can only generate local link In most cases, the generated code will produce links to the corresponding files. The code block typically appears as shown below; however, the links generated by this code are limited to local access and do not provide shareable links for external users. The pseudo-code is in Alg. 2 Algorithm 2 Pseudo-code of D.2. # Define the file path file_path = Path(/xxxx/xxx.pdf) # Check if the file exists if not file_path.exists(): raise FileNotFoundError(f\"The file {file_path} does not exist.\") # Copy the file to shareable directory (e.g., public folder) shareable_directory = Path(/mnt/data/shareable_files) shareable_directory.mkdir(parents=True, exist_ok=True) # Define the new path in the shareable directory shared_file_path = shareable_directory / file_path.name # Copy the file to the shareable directory shutil.copy(file_path, shared_file_path) # Generate shareable link (assuming file server is available at /mnt/ data) shareable_link = f\"http://file-server-url/shareable_files/{file_path.name}\" print(shareable_link) D.3 The code can generate shareable link In our experiments, the code generated by LLMs can occasionally produce shareable link. However, generating such link often involves complex configuration steps. For instance, users need to authorize the Dropbox app, obtain an access token, and perform other setup tasks, as illustrated in the following code block. Moreover, due to the variety of platforms for generating shareable links, LLMs may switch between different platforms with each code generation, leading to considerable user configuration time. The Steps and Pseudo-code in Alg. 3 20 Algorithm 3 Procedures of D.3. 1: Install the DropBox SDK. 2: Once logged in, use the APP Console to create new app and select the appropriate permissions. 3: Configure application permissions on demand. 4: Create an access token using OAuth2. 5: File generator: Import the private token of OAuth2: accesstoken = Your token Create dropbox client: dpclient = Dropbox(accesstoken) Import file path: path = xxx/xxxx.pdf Use dropbox to create shared link: link = dpclient.share(path) 6: Get the link In contrast, our Link API simplifies this process: users only need to provide Google Drive credentials, and they can effortlessly generate shareable links without the need for extensive configuration."
        },
        {
            "title": "E Further Discussions",
            "content": "File system is one of the most important components of an operating system. Enhancing and expanding its capability based on LLMs can help to increase its usability for users. Building on the foundation of LSFS, there are numerous avenues for future research to explore. This section highlights key areas of study that could extend and enhance the core capabilities of LSFS. Multi-modal, Multi-extension File Manipulation Currently, LSFS primarily supports operations on text files. While it also provides basic functionality for handling other types of files, such as XLSX, JPG, MP3, and MP4, through writing and deletion, it lacks dedicated syscall interfaces tailored to these formats. Future work could focus on leveraging the semantic information embedded in these non-text file types to design and optimize file management operations, enabling more intelligent and context-aware file management across broader directory of formats. Security and Privacy Enhancements LSFS must implement robust protection measures to defend against variety of security threats, such as file data leakage, tampering, and unauthorized access. Additionally, incorporating encryption techniques is essential to secure data interactions and transmissions between LSFS and LLMs, ensuring that file privacy remains protected at all stages of processing and communication. Optimized Retrieval Strategies The core functionality of LSFS lies in its keyword and semantic retrieval capabilities. In future work, these retrieval methods can be further optimized by integrating more advanced and precise algorithms, enhancing the overall accuracy and effectiveness of LSFSs retrieval performance. More Instantiated APIs and syscalls There are two main directions for future optimization of LSFS design. First, further deepening the integration of traditional file system functions into LSFS. While this paper focuses on the design of the most essential and commonly used syscalls within LSFS, many additional functionalities remain unexplored and can be developed in the future. Second, as user demands for file systems continue to grow, there are numerous operations that traditional file systems are unable to support. To address these needs, LSFS can be expanded to instantiate APIs for related operations, providing users with more versatile and advanced capabilities."
        }
    ],
    "affiliations": [
        "Dalian University of Technology",
        "EPFL",
        "New Jersey Institute of Technology",
        "Purdue University",
        "Rutgers University",
        "University of Minnesota"
    ]
}