{
    "paper_title": "LikeBench: Evaluating Subjective Likability in LLMs for Personalization",
    "authors": [
        "Md Awsafur Rahman",
        "Adam Gabrys",
        "Doug Kang",
        "Jingjing Sun",
        "Tian Tan",
        "Ashwin Chandramouli"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "A personalized LLM should remember user facts, apply them correctly, and adapt over time to provide responses that the user prefers. Existing LLM personalization benchmarks are largely centered on two axes: accurately recalling user information and accurately applying remembered information in downstream tasks. We argue that a third axis, likability, is both subjective and central to user experience, yet under-measured by current benchmarks. To measure likability holistically, we introduce LikeBench, a multi-session, dynamic evaluation framework that measures likability across multiple dimensions by how much an LLM can adapt over time to a user's preferences to provide more likable responses. In LikeBench, the LLMs engage in conversation with a simulated user and learn preferences only from the ongoing dialogue. As the interaction unfolds, models try to adapt to responses, and after each turn, they are evaluated for likability across seven dimensions by the same simulated user. To the best of our knowledge, we are the first to decompose likability into multiple diagnostic metrics: emotional adaptation, formality matching, knowledge adaptation, reference understanding, conversation length fit, humor fit, and callback, which makes it easier to pinpoint where a model falls short. To make the simulated user more realistic and discriminative, LikeBench uses fine-grained, psychologically grounded descriptive personas rather than the coarse high/low trait rating based personas used in prior work. Our benchmark shows that strong memory performance does not guarantee high likability: DeepSeek R1, with lower memory accuracy (86%, 17 facts/profile), outperformed Qwen3 by 28% on likability score despite Qwen3's higher memory accuracy (93%, 43 facts/profile). Even SOTA models like GPT-5 adapt well in short exchanges but show only limited robustness in longer, noisier interactions."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 1 ] . [ 1 7 7 0 3 1 . 2 1 5 2 : r LIKEBENCH: EVALUATING SUBJECTIVE LIKABILITY IN LLMS FOR PERSONALIZATION Md Awsafur Rahman UC Santa Barbara awsaf@ucsb.edu Adam Gabrys Amazon gabrysa@amazon.com Doug Kang Amazon dougkang@amazon.com Jingjing Sun Amazon jingjins@amazon.com Tian Tan Amazon tianta@amazon.com Ashwin Chandramouli Amazon ashwic@amazon.com"
        },
        {
            "title": "ABSTRACT",
            "content": "A personalized LLM should remember user facts, apply them correctly, and adapt over time to provide responses that the user prefers. Existing LLM personalization benchmarks are largely centered on two axes: accurately recalling user information and accurately applying remembered information in downstream tasks. We argue that third axis, likability, is both subjective and central to user experience, yet under-measured by current benchmarks. To measure likability holistically, we introduce LikeBench1, multi-session, dynamic evaluation framework that measures likability across multiple dimensions by how much an LLM can adapt over time to users preferences to provide more likable responses. In LikeBench, the LLMs engage in conversation with simulated user and learn preferences only from the ongoing dialogue. As the interaction unfolds, models try to adapt to responses, and after each turn, they are evaluated for likability across seven dimensions by the same simulated user. To the best of our knowledge, we are the first to decompose likability into multiple diagnostic metrics: emotional adaptation, formality matching, knowledge adaptation, reference understanding, conversation length fit, humor fit, and callback, which makes it easier to pinpoint where model falls short. To make the simulated user more realistic and discriminative, LikeBench uses fine-grained, psychologically grounded descriptive personas rather than the coarse high/low trait rating based personas used in prior work. Our benchmark shows that strong memory performance does not guarantee high likability: DeepSeek R1, with lower memory accuracy (86%, 17 facts/profile), outperformed Qwen3 by 28% on likability score despite Qwen3s higher memory accuracy (93%, 43 facts/profile). Even SOTA models like GPT-5 adapt well in short exchanges but show only limited robustness in longer, noisier interactions."
        },
        {
            "title": "INTRODUCTION",
            "content": "As large language models (LLMs) become increasingly integrated into everyday life, the need for systems that genuinely adapt to individual users is more important than ever (Zhang et al., 2025; 2018). Personalized LLMs are widely recognized as the next step toward building AI that feels truly realistic and human-like, since one-size-fits-all alignment cannot capture the subjective preferences, values, and conversational styles of each user Kirk et al. (2024); Guan et al. (2025); Salemi et al. (2023). This evolution places personalization and, crucially, the likability of AI responsesat the heart of next-generation systems, making it essential to develop rigorous evaluation methods that accurately capture and advance these user-centric capabilities. However, despite the growing importance of personalization, existing benchmarks (Jiang et al., 2025; Wu et al., 2025; Maharana et al., 2024; Zhao et al., 2025) for LLMs remain largely focused on Work done during an internship at Amazon. 1Code & Data is planned for future release 1 T O t a s t t b L # t e C l M s s a o P n o P m e fi # Benchmark ALOE (Wu et al., 2024) ALIGNX (Chan et al., 2024) CUPID (Kim et al., 2025) LikeBench (ours) Dynamic Static Static Dynamic 1 Yes 1 No No 1 7 Yes Coarse keyword No Intensity ratings No No Intensity ratings Fine-grained text Yes Explicit + Implicit None None Implicit only 100 3,716 252 50 Table 1: Comparison of likability-oriented benchmarks across key dimensions. i S # 1 1 9 r # 10 1 6 5 technical capabilities such as retaining user information (memory recall), for example, remembering that user has dairy allergy, and applying remembered preferences in tasks (memory adherence), such as recommending suitable foods while adhering food allergy memory. But these benchmarks cannot capture whether interactions genuinely feel personalized or likable to individual users. This gap presents fundamental limitation: model might achieve very good memory recall and adherence scores, yet still come across as generic or unsatisfying if it fails to adapt to users personality, conversational style, and nuanced preferences. Moreover, since most LLMs are post-trained with RLHF algorithms, they tend to moderately satisfy many users rather than deeply satisfy any particular user, due to the distribution of their reward models. There are very few works that attempt to measure this likability factor. However, they have several shortcomings: the user profiles or personas used to simulate users often lack fine-grained personality traits and conversational styles (Wu et al., 2024), which are critical for users likability. This results in LLMs being evaluated mainly on less discriminative users, even though real users have diverse interests and personalities. Importantly, these benchmarks typically reduce likability to single aggregate score (such as an alignment score) (Wu et al., 2024), making it difficult to understand where an LLM struggles or to provide actionable feedback for further improvement. To address these limitations, we introduce LikeBench, comprehensive benchmark specifically designed to overcome three key issues in existing personalization benchmarks. First, unlike most prior benchmarks that focus mainly on memory recall and adherence, LikeBench targets the subjective dimension of user experience by evaluating likabilitythe extent to which AI interactions actually feel satisfying and well-adapted to users. Second, rather than relying on single aggregate metric like existing approaches for measuring likability, LikeBench provides multi-dimensional assessment across seven diagnostic metrics, using multi-session, multi-turn conversations spanning varied topics. Third, our benchmark features psychologically grounded user personas, modeled with finegrained descriptive personality traits and conversation styles, moving beyond the coarse, high-level, rating-based personas (e.g., high) used in earlier work. Our contributions can be summarized as: We introduce LikeBench, multi-session dynamic evaluation framework that measures two key properties of LLMs: likabilityability to generate responses that users find likable, and adaptabilitythe ability to improve likability over time through ongoing conversations with simulated users. We enable fine-grained evaluation of likability by decomposing it into seven diagnostic metrics, providing comprehensive assessment of how well LLMs capture subjective aspects of user satisfaction. We develop psychologically grounded user personas based on seven personality traits with 35 facets, along with conversation style across 7 dimensions, offering substantially richer and more distinctive profiles. We experiment with range of SOTA models and find that memory alone does not guarantee likability, and most models show little to no adaptability as conversations progress."
        },
        {
            "title": "2 RELATED WORK\n2.1 BENCHMARKS ON MEMORY RECALL AND MEMORY ADHERENCE",
            "content": "Recent benchmarks on personalization emphasize on memory recall and adherence to long contexts and multi-session settings. LoCoMo (Maharana et al., 2024) evaluates LLMs in very similar settings, where models must generate answers to QA tasks based on hundreds of conversational turns; performance is measured by comparing the generated responses to annotated ground-truth answers using exact-match and F1 metrics, with no LLM-as-judge involved. LongMemEval (Wu et al., 2025) expands this direction by introducing range of tasksextraction, temporal reasoning, knowledge updatesand uses GPT-4o as an automatic judge: given the models generated answer and the gold label, the LLM judge determines correctness, thus combining LLM-based scoring. PrefEval (Zhao et al., 2025) focuses on preference adherence where model generations are assessed by an LLMas-judge using several binary criteria, and discriminative classification protocol, where the model selects the user-consistent answer from pre-generated options. PersonaMem (Jiang et al., 2025) extends evaluation to tracking evolving user preferences over sessions, reporting performance in both discriminative setting (selecting the correct response from multiple candidates) and generative setting, where the chosen response is the candidate with the highest generation probability. Most recently, HiCUPID (Mok et al., 2025), like prior benchmarks, focuses on factual correctness and information adherence in extended contexts, using an LLM-as-judge to measure win rate by comparing model predictions with ground-truth answers. In summary, existing work evaluates whether models remember and apply user information across turns, sessions, and long contexts. These evaluations typically equate personalization with objective, factual memory or preference using binary metric (right or wrong) and compliance, but fail to assess whether interactions are genuinely liked by individual users or whether the LLM is able to adapt to user preferences and improve over time. 2.2 BENCHMARKS ON LIKABILITY Very recently, research on personalization has shifted from factual recall and adherence to subjective alignment, where existing benchmarks differ along four axes: whether evaluation is static (pre-generated conversation with evaluating LLM responds to last user query) or dynamic, the depth of persona, whether likability is decomposed into multiple metrics or reduced to single aggregate score, and whether adaptability over time is measured. ALOE (Wu et al., 2024) is dynamic but single-session, models users with coarse keyword (e.g. extroverted), reports single composite alignment score plus an improvement rate, and thus does not provide decomposed view of likability. ALIGNX (Chan et al., 2024) models users with broader personality traits than existing approaches, but it is static, represents users personalities via coarse intensity ratings (e.g. high extroversion), reports single aggregate alignment score, and does not measure adaptation over time. CUPID (Kim et al., 2025) uses static evaluation and compares model generations against groundtruth answers with an LLM-as-judge; it employs coarse intensity ratings, reports single alignment score rather than decomposed metrics, does not include an explicit measure of adaptability, and also relies on simulated users providing per-turn implicit feedback to the evaluating LLM, making interactions less realistic. In summary, existing benchmarks often evaluate static or single-session settings, rely on coarse ratings-based personas, and collapse alignment into single aggregate score without tracking whether models adapt with continued interaction. In contrast, LikeBench evaluates dynamic, multi-session conversations, uses psychologically grounded, fine-grained textual personas, decomposes likability into multiple diagnostic metrics, and explicitly measures adaptability across sessions thus providing actionable insight into where and how systems fall short on user satisfiction. These comparisons are summarized in Table 1."
        },
        {
            "title": "3 BENCHMARK: LIKEBENCH\nProblem Setup and Notation. Let Θ denote the set of models (LLMs) under evaluation. An\nLLM fθ ∈ Θ interacts with a simulated user gπ instantiated from a fine-grained textual persona\nπ ∈ Π. Each persona π provides personality traits, conversation style, interests, background, and\nfoundational knowledge. Evaluation proceeds over S sessions, each with a hidden session prior\nρs ∈ R specifying the agenda or motivation for that session, and T turns per session. The LLM\nnever observes π or ρs; it only sees dialogue history, whereas the user agent sees (π, ρs) and the full\nhistory.",
            "content": "3 Algorithm 1 LIKEBENCH evaluation for one persona π for = 1 to do session turn Require: Persona π; priors (ρ1, . . . , ρS); turns ; model fθ; User Agent gπ; per-dimension scorers {ϕk}K k=1 1: H1,1 2: for = 1 to do 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: end for 13: return {ℓs,t,k}s,t,k us,t gπ(π, ρs, Hs,t) ys,t fθ(Hs,t, us,t) for = 1 to do end for Hs,t+1 Hs,t {(us,t, ys,t)} end for Hs+1,1 Hs,T +1 ℓs,t,k ϕk(π, ρs, us,t, ys,t) Figure 1: Example of the LikeBench workflow for single profile and single turn. simulated user initiates the conversation guided by prior, the LLM generates response, and that response is then scored across the seven likability metrics. Dialogue History. We index messages by session {1, . . . , S} and turn {1, . . . , }. Let us,t be the user message at (s, t) and ys,t the model reply. The dialogue history just before (s, t) is Hs,t = (cid:0)(u1,1, y1,1), . . . , (u1,T , y1,T ), . . . , (us,t1, ys,t1)(cid:1). Information asymmetry is maintained: fθ receives Hs,t, while gπ receives (π, ρs, Hs,t). Turn-Level Evaluation and Conversation Procedure. Algorithm 1 operationalizes the evaluation loop. Within each session s, the user agent generates the next message us,t = gπ(π, ρs, Hs,t); the model replies ys,t = fθ(Hs,t, us,t); then the user agent applies the per-dimension scorers {ϕk}K k=1 to produce numeric labels ℓs,t,k. Concretely, for each likability dimension = {1, . . . , = 7} (emotional adaptation, formality matching, knowledge adaptation, reference understanding, conversation-length fit, humor fit, callback), we use the rubric ϕk : (π, ρs, us,t, ys,t) {NA, 1, 2, 3, 4, 5} to yield score ℓs,t,k. NA indicates the dimension is not applicable for that turn according to the rubric; NA entries are ignored rather than averaged as zeros. After scoring, the history is updated Hs,t+1 Hs,t {(us,t, ys,t)}; upon completing turns, the terminal history Hs,T +1 becomes the prefix Hs+1,1 for the next session. The algorithm returns the full tensor of scores {ℓs,t,k}s,t,k, which are never revealed to fθ during the dialogue. Figure 1 illustrates the LikeBench workflow for single profile in single-turn interaction. 3.1 METRICS 3.1.1 LIKABILITY METRICS The evaluation of likability in LikeBench is decomposed into seven diagnostic metrics, each scored per turn on 15 scale: 1) Emotional adaptation: Does the reply recognize and match the users emotional state (e.g., excitement, frustration, sarcasm) with appropriate tone and intensity? 2) Formality matching: Does the reply align with the users register (casual vs. formal), emoji use, and slang? 3) Knowledge adaptation: Is the explanation depth calibrated to the users background, avoiding both over-explaining and unexplained jargon? 4) Reference understanding: Does the assistant correctly pick up cultural or contextual references (e.g., Harry Potter or Star Wars jokes)? 5) Conversation length fit: Is the response length comfortable for the user (brief vs. detailed), given how the user is currently engaging? 6) Humor fit: When humor appears, does it match the users taste and the situation? 7) Callback: Does the agent bring back non-essential personal details in way that feels attentive and natural (e.g., names, hobbies, preferences), without forcing it? We aggregate likability scores from turn to session to profiles, always excluding non-applicable (NA) scores rather than zero-padding. For each turn (s, t) with per-dimension scores ℓs,t,k 4 {1, . . . , 5, NA}, let K+ over applicable dimensions, Ls,t = 1 K+ (cid:80)T turns, Ls = 1 Lπ = 1 (cid:80)S s,t = {k : ℓs,t,k = NA} and compute the turn score as the mean ℓs,t,k. The session score is the average of its (cid:80) s,t kK+ s,t t=1 Ls,t; the profile score for persona π is the average of its session scores, s=1 Ls; and the overall model score over the test set is LN = 1 (cid:80) πN Lπ."
        },
        {
            "title": "3.1.2 ADAPTABILITY METRICS",
            "content": "To quantify whether model is able to adapt to become more likable with continued interaction, we regress the sessionlevel scores {Ls}S s=1 on the session index using ordinary least squares (similar to ALOE Wu et al. (2024)). The slope ˆβ is the improvement rate (IR) (likability points per session), and the coefficient of determination R2 measures goodness of fit (higher R2 indicates more consistent trend). We also report normalized improvement rate (N-IR) by first minmax normalizing the series, Ls = Lsminu Lu , and then fitting the same linear model to { Ls}; when the range in the denominator is zero, we set N-IR to 0. Positive IR/N-IR indicates improvement (adaptation) over sessions, while negative values indicate degradation. maxu Luminu Lu 3.1.3 MEMORY ACCURACY To analyze how LLMs likability performance correlates with memory performance, we evaluate how well each LLM can recall user-shared facts and preferences from the conversation. More specifically, after completing all sessions for persona π, the model is prompted to generate set of remembered user facts ˆFθ(π) = { ˆf1, . . . , ˆfNπ }. Each ˆfi is then verified against the full dialogue H1:S and the hidden profile π, yielding correctness labels ci {0, 1}. Aggregated accuracy over the evaluation set is reported as A(θ) = (cid:0) (cid:80) (cid:1), and the total numi=1 ci ber of correctly remembered facts as C(θ) = (cid:80) i=1 ci. For analysis, we also split ˆFθ(π) into explicit facts (directly stated in the dialogue) and implicit inferences (preferences inferred from behavior), and compute the same aggregated statistics on each subset. (cid:80)Nπ (cid:80)Nπ πN Nπ (cid:1)(cid:14)(cid:0) (cid:80) πN πN"
        },
        {
            "title": "4 DATA GENERATION",
            "content": "We construct LikeBench with twostage pipeline that (i) generates finegrained profiles/personas and (ii) instantiates session priors that drive multisession conversations. 4.1 TWOSTAGE OVERVIEW Let Π denote the set of user profiles and the space of session priors. Each benchmark instance fixes profile π Π and sequence of priors (ρ1, . . . , ρS) specifying the session agenda and informationrevelation plan. We generate 50 profiles and, for each, 10 priors. Claude 3.7 Sonnet is used for both profile and prior generation. To stresstest adaptability, profiles are divided into two types that are intentionally designed to reflect realworld variation in user behavior: social (cooperative, emotionally expressive, and less rigidly taskcentric; interests correlated with personality traits, etc) and antisocial (more objective/goaldriven with less emotionally active or volatile affect; interests decoupled from personality traits, etc). 4.2 PROFILE GENERATION 4.2.1 PERSONALITY TRAITS GENERATION. We construct personality traits using psychological surveys and studies, covering the Big Five traits (Goldberg et al., 1999; International Personality Item Pool, 2024) (Openness to Experience, Conscientiousness, Extraversion, Agreeableness, Neuroticism), HonestyHumility (Ashton et al., 2004; contributors, 2025), and Humor Styles Martin et al. (2003). Each Big Five trait is decomposed into 6 facets, HonestyHumility into 1 facet, and Humor Styles into 4 facets, totaling 35. For each facet, we prompt the LLMgrounded in these sourcesto produce concise, behaviorally interpretable descriptors across five ordered intensity levels. For example, Big Five Openness (trait) imagination (facet): high (intensity) : Has vivid imagination . . . (description) 5 Figure 2: Flow diagram of the LikeBench profile generation process. Profiles begin with random generation of 35 personality facets and 9 conversation-style dimensions, followed by archetype biasing and interest selection depending on profile type (social vs. anti-social). Finally, an LLM completes the remaining tiers to yield coherent 7-tier user profile. Let = (f1, . . . , f35) be the ordered list of facets and = {low, lowmid, mid, midhigh, high} is intensity levels. profiles personality is specified by the intensity vector ι = (i1, . . . , i35) with ij I. We keep descriptor table desc[j][i] that stores the behavioral string for facet fj at level i, and render the personality text as = (cid:0)desc[1][i1], . . . , desc[35][i35](cid:1). These descriptors serve as fixed anchors during profile completion and prior generation. complete breakdown of all personality facets with descriptors is provided in the Appendix. Importantly, existing approaches Wu et al. (2024); Kim et al. (2025); Chan et al. (2024) often use only coarse intensity ratings (e.g., openness high) or brief descriptors (e.g., high extroversion), making profiles less discriminative and limiting their ability to simulate user individuality. 4.2.2 CONVERSATION STYLE GENERATION. The conversationstyle pipeline mirrors personality construction in spirit but does not use facets or intensity levels. We prompt the LLM to propose conversational dimensions relevant to humanAI chat and, after curation, finalize nine: directness, formality, preferred response length, reference usage, initiative preference, clarification preference, structure preference, recap preference, and feedback style. For each dimension, the LLM enumerates small, disjoint menu of categorical options with concise definitions. For example, directness (dimension) always direct (option) : Consistently straightforward and blunt . . . (description) Let = {1, . . . , 9} index the dimensions and let Od denote the option set for dimension d; conversation style is the tuple σ = (o1, . . . , o9) with od Od. Complete option lists and selection rubrics are provided in the Appendix. Existing methods typically do not model conversation style explicitly Wu et al. (2024), making faithful imitation of user interaction preferences difficult and causing models to revert to default conversational tendencies. 4.2.3 PROFILE ASSEMBLY. Given the facetintensity vector ι and the conversationstyle tuple σ, we assemble the full profile following the flow in Fig. 2. We first generate ι and then σ. Next, we choose profile type (social vs. antisocial) and apply typespecific archetype biasing to both ι and σ . We then attach three to five hierarchical interest paths: for social profiles, an LLM selects interests that correlate with ι and σ; for antisocial profiles, interests are sampled in partially decorrelated to introduce volatility. Finally, conditioned on (ι, σ), the selected interests, and demographics, an LLM completes the remaining tiersfoundational knowledge, behaviors, motivational drivers, lifecycle events, and relational context. 6 Table 2: Likability scores (15) by metric and model. Entries are mean 95% CI halfwidth (personaclustered). The Model Average row reports means only. Metric Avg. Claude 3.7 Sonnet Claude Sonnet 4 DeepSeek GPT-5 Qwen3 235B A22B callback conversation length fit emotional adaptation formality matching humor fit knowledge adaptation reference understanding Model Average 3.583 3.434 3.576 3.421 3.401 3.841 3.531 3.541 3.227 0.217 3.780 0.202 3.299 0.187 3.456 0.208 3.315 0.190 3.431 0.187 3.181 0. 3.720 0.102 3.788 0.142 3.977 0.110 3.949 0.180 3.645 0.251 3.487 0.306 3.881 0.104 3.718 0.173 3.930 0.093 3.812 0.154 3.343 0.259 4.043 0.151 3.792 0.087 3.458 0.220 3.793 0.146 3.925 0.099 4.060 0.152 4.400 0.104 3.690 0.097 3.685 0.191 3.946 0.095 3.185 0.225 2.310 0.330 3.050 0.272 2.453 0.311 2.637 0.274 3.386 0.244 3.089 0.274 3.390 3.828 3.674 3. 2."
        },
        {
            "title": "4.3 PRIOR GENERATION",
            "content": "For each assembled profile π, we generate hidden sequence of priors (ρ1, . . . , ρS) that specify agendas, contextual constraints, informationrevelation timing, and callback opportunities; priors remain concealed from the evaluated LLM to preserve evaluation asymmetry. The process is typeaware: social profiles receive transparent, linear agendas with consistent disclosure and stable emotional trajectories, whereas antisocial profiles receive agendas with delayed disclosures, contrarian shifts, and intermittent surprises to stresstest adaptability to nonstandard interaction patterns. To elicit the seven likability dimensions without leaking criteria, we interleave four prior types across the sequence (goaldriven, scenariobased, topicbased, and guided). Continuity is engineered via soft dependencies: later sessions organically refer back to noncritical details seeded earlier (e.g., session s+k recalls name or preference from session s), enabling measurement of callback recognition and adaptation trends over extended interactions."
        },
        {
            "title": "5 EXPERIMENTATION AND RESULTS",
            "content": "5.1 EXPERIMENTAL SETUP We evaluate five state-of-the-art models: GPT-5, Claude 4 Sonnet, Claude 3.7 Sonnet, DeepSeek R1, Qwen3 235B A22B. We also use Claude 3.7 Sonnet as simulated user with cross-model pairing for evaluating LLMs. Each evaluation spans 50 profiles across 10 sessions and 5 turns each thus total 2500 turns. 5.2 PERFORMANCE ACROSS METRICS Table 2 presents model performance across the seven likability metrics of LikeBench. GPT-5 achieves the highest overall likability score (3.94), surpassing all other models, with Claude Sonnet 4 as the runner-up. Notably, Qwen3 235B A22B, despite being more recent model than DeepSeek R1, underperforms on almost every dimension. closer examination of the per-metric averages reveals that humor fit and formality matching are consistently the most challenging dimensions for all models. Interestingly, while GPT-5 leads in most categories, it falls short of Claude Sonnet 4 on conversation length fit. Manual review of GPT-5s outputs indicates trade-off: the model frequently generates long, comprehensive responses that, while demonstrating strong knowledge adaptation (outperforming 2nd best model Claude Sonnet 4 by over 12% on this metric), tend to reduce user satisfaction when brevity or concise interaction is preferred thus having lower score on conversation length fit metric. This suggests an inherent likability biasmodels optimized for in-depth answers may inadvertently sacrifice performance on dimensions such as conversation length. 5.3 ADAPTABILITY The adaptability capacity of likability are summarized by session-wise curve in Fig. 3 and quantitatively depicted in Table 3. Early interactions (Sessions 13) show predictable honeymoon rise: most models improve with high fit (e.g., Claude 3.7 Sonnet and DeepSeek R1 with near-linear gains, R2 0.98), due to relative simplicity and independence of the initial sessions. As sessions progress (36), all models declinenegative IR across the boardyet the downturn remains highly 7 Figure 3: Session-wise Likability Performance Table 3: Improvement of likability (adaptibility) over sessions. IR and N-IR (normalized) are the slopes; R2 indicates fit quality. Positive slopes are shaded green; negative slopes are shaded red. Sessions 13 Sessions 36 Sessions 6 Average Model IR N-IR R2 IR N-IR R2 IR N-IR R2 IR N-IR R2 0.1628 0.5000 0.9757 -0.1764 -0.3002 0.8750 -0.1309 -0.2333 0.9508 -0.0225 -0.0055 0.1764 Claude 3.7 Sonnet 0.0615 0.4028 0.5771 -0.0288 -0.2938 0.8254 0.0103 0.0451 0.0311 -0.0012 -0.0001 0.0533 Claude Sonnet 4 0.1490 0.5000 0.9809 -0.1066 -0.2928 0.7162 0.0079 0.0721 0.0765 -0.0035 -0.0008 0.0636 Deepseek R1 GPT-5 0.0915 0.5000 0.8108 -0.1007 -0.3351 0.9934 0.0380 0.1346 0.2318 0.0001 0.0001 0.0502 Qwen3 235B A22B 0.0056 0.2055 0.1671 -0.1039 -0.3159 0.8021 -0.0159 -0.1068 0.1498 -0.0100 -0.0026 0.1224 predictable (R2 > 0.7), as these sessions introduce cross-session coordination, conversational noise, and emotionally deeper queries that raise difficulty and depress likability. In the late stage (610), trajectories diverge and predictability largely collapses (R2 often < 0.25): GPT-5 uniquely rebounds strongly (IR= 0.038). Upon analyzing the model outputs, we noticed that models attempt to calibrate user preferences during Sessions 36, and GPT-5 was able to leverage its strong long-context and multi-hop reasoning capability to dominate in this region, in contrast to peers, which show only slight positives or continued decline (e.g., Claude 3.7 Sonnet remains steadily negative with high fit, R2 0.95). On average, however, even GPT-5 achieves only modest overall gains, while other models exhibit clear declinesindicating that current systems adapt well in short sequences but remain fragile in extended, noisier interactions. In practice, this means that the best-performing models can avoid degradation in long conversations, but sustaining high likability over extended, It is noteworthy that, in ALOE (Wu real-worldlike exchanges remains an unsolved challenge. et al., 2024), improvement rates are higher because alignment score there is computed over only 10 turns (two sessions in our setup). We observe comparable gains in the early phase, but beyond that the trajectories diverge. 5.4 MEMORY PERFORMANCE Memory vs Likability. Figure 5 examines the interplay between memory accuracy and likability across models. On the left we plot memory accuracy (fraction of user shared facts recalled correctly post-dialogue by the evaluating LLM), while the right we plot correctly extracted memories per profile. Although the prevailing hypothesis in personalization research is that improved memory recall correlates with enhanced user experience, our results show this relationship is not guaranteed. For example, while Qwen3 achieves higher memory accuracy and recalls more facts than DeepSeek R1, it underperforms in likability, indicating that mere recollection of user information does not ensure positive interaction. This suggests that effective personalization depends not only on accurate memory recall but also on how models utilize remembered facts within the conversation. Notably, GPT-5 stands out as the only model that excels in both memory performance and likability, demonstrating that while strong memory is valuable, models must also integrate these facts fluidly and contextually Figure 4: Memory Accuracy vs Likability Performance to achieve high user satisfaction. These findings highlight the importance of both memory retrieval and adaptive deployment in driving subjective likability. Figure 5: Explicit vs Implicit Memory Performance Explicit vs. Implicit Memory. Figure 5 examines how models extract and leverage explicit and implicit user memories in the LikeBench evaluation. GPT-5 stands out by extracting the largest number of user facts per profile, with the majority being explicit; it adopts conservative strategy, inferring implicit information only when highly confident, resulting in 98% accuracy rate for implicit memories. Qwen3, on the other hand, is more aggressive in inferring implicit memoriesoften extracting the most among all modelsbut this comes at the expense of accuracy (93%), as it makes more incorrect assumptions that lead to penalties. Analysis of model outputs further shows that GPT-5 not only demonstrates strong recall but also ensures near-complete utilization of extracted memories: 80100% of explicit and almost 100% of implicit memories are actively referenced in dialogue, with some profiles featuring more than 15 implicit facts when the interaction context demands. This pattern indicates that effective personalization requires not just the recall of relevant information, but also skillful, context-sensitive use of both explicit and implicit user knowledge to enhance likability."
        },
        {
            "title": "5.5 HUMAN VALIDATION",
            "content": "While LikeBench provides large-scale, automated evaluation of likability and adaptability, it is important to verify that the resulting scores reflect real conversational quality. Exhaustive human evaluation is infeasible given the benchmark size (50 profiles 10 sessions each), so we conducted targeted validation by randomly sampling five profiles and reviewing model outputs across all systems. Our inspection confirmed strong alignment between automated scores and human judgments: higher-scoring models (e.g., GPT-5 and Claude-Sonnet-4) produced more personalized, contextaware, and engaging responses, often using references, callbacks, and emotional alignment with user personas. In contrast, weaker models frequently reverted to generic replies or lost coherence as conversations grew longer. This validation supports the reliability of LikeBenchs automated metrics while emphasizing that occasional human review adds complementary value."
        },
        {
            "title": "6 CONCLUSION",
            "content": "This work introduced LikeBench, holistic benchmark for evaluating personalized LLMs through fine-grained user profiles and multi-session conversational priors. We show that effective personalization cannot be reduced to memory recall alone. While memory accuracy is necessary, true user satisfaction hinges on the adaptive, context-sensitive use of both explicit and implicit knowledge. Models that perform well in likability, such as GPT-5, achieve this by applying recalled facts in ways that align with conversational contextbalancing breadth of recall with relevance. Even so, GPT-5 shows only limited robustness when conversations become longer and noisier: while it avoids significant degradation, most other models steadily decline. This underscores key limitation of current state-of-the-art systems: they can adapt effectively in short interactions but struggle to sustain high likability across extended, real-worldlike dialogues. Looking forward, our findings underscore the need for next-generation conversational systems to move beyond static user modeling and rote fact retrieval, embracing dynamic, psychologically grounded strategies that foster genuinely engaging, resilient, and user-centered AI."
        },
        {
            "title": "7 REPRODUCIBILITY STATEMENT.",
            "content": "We have taken several steps to ensure the reproducibility of our work. complete description of the data generation pipeline, including personality facets, conversation style dimensions, archetype biasing, and prior construction, is provided in Section 4, with detailed examples and descriptors included in the Appendix. The LikeBench evaluation framework, along with algorithmic details, is specified in Algorithm 1, and we describe the mathematical formulations of all metrics (likability, adaptability, and memory) in Section 3.1. Experimental setup details, including model versions, number of profiles, sessions, and turns, are given in Section 5.1. Additional results, ablations, and profile examples are available in the supplementary materials."
        },
        {
            "title": "8 ETHICS STATEMENT.",
            "content": "Our study does not involve real human participants; all user interactions are simulated using psychologically grounded personas and conversation styles generated through large language models. This design ensures no personal, private, or sensitive data is collected, protecting user privacy and avoiding ethical risks associated with real human experimentation. The benchmark is intended solely for academic research and evaluation, and all models are evaluated under consistent, transparent conditions. We acknowledge that personalization research raises concerns about potential misuse, including profiling, bias amplification, or unfair treatment of individuals. To mitigate this, our benchmark emphasizes controlled, synthetic evaluation rather than deployment, and we provide detailed methodology and documentation (Section 4 and Appendix) to ensure transparency."
        },
        {
            "title": "REFERENCES",
            "content": "Michael Ashton, Kibeom Lee, Marco Perugini, Piotr Szarota, Reinout De Vries, Lisa Di Blas, Kathleen Boies, and Boele De Raad. six-factor structure of personality-descriptive adjectives: 10 solutions from psycholexical studies in seven languages. Journal of personality and social psychology, 86(2):356, 2004. Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu. Scaling synthetic data creation with 1,000,000,000 personas. arXiv preprint arXiv:2406.20094, 2024. Wikipedia contributors. Hexaco model of personality structure wikipedia, the free encyclopedia. https://en.wikipedia.org/wiki/HEXACO_model_of_personality_ structure, 2025. Page revision ID 1311428943, last edited 15 Sep 2025. Accessed 24 Sep 2025. Lewis Goldberg et al. broad-bandwidth, public domain, personality inventory measuring the lower-level facets of several five-factor models. Personality psychology in Europe, 7(1):728, 1999. Jinghe Guan et al. survey on personalized alignmentthe missing piece for general alignment. In Findings of ACL, 2025. URL https://aclanthology.org/2025.findings-acl. 277.pdf. International Personality Item Pool. Ipipneo 300-item inventory (30 facets 10 items) complete scoring key. https://ipip.ori.org/newNEOKey.htm, 2024. Accessed 10 Aug 2025. Bowen Jiang, Zhuoqun Hao, Young-Min Cho, Bryan Li, Yuan Yuan, Sihao Chen, Lyle Ungar, Camillo Taylor, and Dan Roth. Know me, respond to me: Benchmarking llms for dynamic user profiling and personalized responses at scale. arXiv preprint arXiv:2504.14225, 2025. Tae Soo Kim, Yoonjoo Lee, Yoonah Park, Jiho Kim, Young-Ho Kim, and Juho Kim. Cupid: Evaluating personalized and contextualized alignment of llms from interactions. arXiv preprint arXiv:2508.01674, 2025. Hannah Rose Kirk, Bertie Vidgen, Paul Rottger, and Scott Hale. The benefits, risks and bounds of personalizing the alignment of large language models to individuals. Nature Machine Intelligence, 6(4):383392, 2024. Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, and Yuwei Fang. Evaluating very long-term conversational memory of llm agents. arXiv preprint arXiv:2402.17753, 2024. Rod Martin, Patricia Puhlik-Doris, Gwen Larsen, Jeanette Gray, and Kelly Weir. Individual differences in uses of humor and their relation to psychological well-being: Development of the humor styles questionnaire. Journal of research in personality, 37(1):4875, 2003. Jisoo Mok, Ik-hwan Kim, Sangkwon Park, and Sungroh Yoon. Exploring the potential of llms as personalized assistants: Dataset, evaluation, and analysis. arXiv preprint arXiv:2506.01262, 2025. Alireza Salemi, Sheshera Mysore, Michael Bendersky, and Hamed Zamani. Lamp: When large language models meet personalization. arXiv preprint arXiv:2304.11406, 2023. Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, and Dong Yu. Longmemeval: Benchmarking chat assistants on long-term interactive memory. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum? id=pZiyCaVuti. Shujin Wu, May Fung, Cheng Qian, Jeonghwan Kim, Dilek Hakkani-Tur, and Heng Ji. Aligning llms with individual preferences via interaction. arXiv preprint arXiv:2410.03642, 2024. Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. Personalizing dialogue agents: have dog, do you have pets too? arXiv preprint arXiv:1801.07243, 2018. Yiming Zhang et al. Personalize your llm: Fake it then align it. In Findings of NAACL, 2025. URL https://aclanthology.org/2025.findings-naacl.407.pdf. 11 Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, and Kaixiang Lin. Do LLMs recognize In The Thirteenth your preferences? evaluating personalized preference following in LLMs. International Conference on Learning Representations, 2025. URL https://openreview. net/forum?id=QWunLKbBGF."
        },
        {
            "title": "Appendix",
            "content": "A DISCUSSION & LIMITATIONS Mapping personality through psychological studies is inherently challenging, given the complex and multifaceted nature of human personality. While our framework attempts to break down this complexity into discrete, well-defined dimensions, it may not capture the full spectrum of personality found in real-world users. Nevertheless, we believe that our approach-anchored in the literature will help pave the way for future research on more expressive, granular personality modeling. We also observed universal limitations in existing benchmarks including ours: static user profile. Notably, GPT-5s lower humor fit score seems to stem from its tendency to warm up and introduce jokes over the course of session, even when the user profile is humor-averse. Because in our benchmark user profiles remain static throughout an interaction, this adaptive strategy leads to likability penalty for otherwise sophisticated LLMs. This highlights broader challenge for current benchmarks: the inability to capture dynamic, reciprocal adaptation, where an LLM might influence user personality or behavioras happens in natural conversation. In addition, we observed cases where Claude 3.7 Sonnet broke character midway through evaluation, resulting in sharper performance decline after session 5. Moreover, we found no evidence of self-bias when Claude 3.7 Sonnet (user) evaluated Claude 3.7 Sonnet model (even in the earliest sessions) given it ranks 4th in overall performance. These findings point to both the promise and the inherent constraints of static, persona-driven benchmarks for evaluating model alignment and adaptation. EXPERIMENTATION & RESULTS B.1 DYNAMIC USER PROFILE (DUP) Qualitative error analysis showed that as conversations lengthen, models struggle to track and honor user preferences: salient signals get diluted by accumulated context and off-topic noise. We hypothesized that explicit, turn-level tracking of inferred preferences would mitigate this drift. To that end, we introduce Dynamic User Profile (DUP): after each turn, the model extracts and updates compact preference summary covering personality dimensions (e.g., chatty reserved, analysis depth preference, humor preference) and conversation style patterns (e.g., directness, formality, conversation length). Dynamic is from the models perspective: the ground-truth persona in LikeBench is fixed, but the model must infer an evolving approximation from dialogue evidence. Enabling DUP yielded gains for the top 2 performing models without additional training: GPT-5 improved from 3.939 4.055 (+2.95%), and Claude Sonnet 4 from 3.828 3.914 (+2.25%). However, rest of the models it didnt improve results. These results indicate that lightweight, schema-guided preference tracking could be measurably enhance perceived likability by reducing calibration errors across sessions. B.2 PROFILE WISE PERFORMANCE. In Figure 6, we compare likability distributions by profile type social vs. anti-social to probe robustness under user variation. Social profiles are emotionally cooperative users whose archetypes (e.g., cooperative teammate, supportive mentor, empathetic advisor) bias traits toward high trust, cooperation, and warmth; anti-social profiles are analytically detached interlocutors (e.g., contrarian expert, technical purist, skeptical philosopher) with lower trust/cooperation and cooler affect, and with interests deliberately decorrelated from traits to induce unpredictability. Two patterns emerge. First, the strongest systems (GPT-5, Claude Sonnet 4) are notably stable across typessimilar medians and tight IQRsindicating strategies that transfer from cooperative to detached users. Second, performance does not uniformly favor easier social users: DeepSeek R1 lifts on anti-social profiles, Claude 3.7 Sonnet degrades, and Qwen3 remains lowest overall but narrows the gap on anti-social cases. This asymmetry confirms that personalityhow users conduct the exchange (tone, emotional stance, discourse discipline)drives likability more than topical alignment; decoupling interests 13 Figure 6: Profile-wise Likability Performance from traits changes difficulty but does not dominate outcomes. Overall, top models sustain high likability regardless of whether the user is socially warm or analytically detached. B.3 TURN-WISE LIKABILITY PERFORMANCE. Fig. 7 shows likability performance over turns. This plot is same as 3 but with with more granular details within each session. It can be noticed that beginning of each session likability starts lower then as session progresses performance increases, this is due to each session talks about different topic so it takes some turns for LLM to calibrate user. Figure 7: Turn-wise Likability Performance"
        },
        {
            "title": "C DATASET",
            "content": "C.1 DATASET DISTRIBUTION The age distribution  (Fig. 8)  spans the late teens to the late 60s, with visible clusters in the early 20s, earlymid 30s, early 50s, and midlate 60s. Ethnic composition is diverse, with plurality of White profiles and smaller groups across East/South Asian, African, Middle Eastern, Hispanic/Latino, and 14 mixed identities  (Fig. 9)  . Gender is roughly balanced between male and female, with small nonbinary share  (Fig. 10)  . Profile relationships show broad coverage with localized high-similarity pockets in the cosine-similarity heatmap (Fig. 11a), while the t-SNE projection (Fig. 11b) indicates profiles are well distributed, and Social and Anti-Social profiles are relatively separabledispersed Importantly, in the heatmap, some high-similarity pairs arise from rather than tightly clustered. shared names rather than true profile similarity. Figure 8: Age Distribution of Profiles Figure 9: Ethnicity Distribution of Profiles C.2 PERSONALITY TRAITS & CONVERSATION STYLE Table 4 to 11 present comprehensive taxonomy of personality traits and conversation style preferences organized across multiple dimensions. The first five tables correspond to the Big Five personality model (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism), with each trait decomposed into six facets measured across five intensity levels (High, Medium-High, Medium, Medium-Low, and Low). Table 6 extends this framework to include additional personal15 Figure 10: Gender Distribution of Profiles (a) Profile Similarity Heatmap (b) t-SNE Projection Figure 11: Profile similarity visualizations. ity dimensions: Honesty-Humility (specifically Greed Avoidance) and four Humor Styles (Affiliative, Self-Enhancing, Aggressive, and Self-Defeating). Tables 10 and 11 shift focus to conversation style preferences, detailing nine distinct conversational dimensionsincluding Directness, Formality, Conversation Length, Reference usage, Initiative Preference, Clarification Preference, Structure Preference, Recap Preference, and Feedback Styleeach with multiple behavioral patterns. This multi-table presentation was necessary given the breadth of the taxonomy, encompassing 35 personality facets and 9 conversational dimensions with their associated description. Facet Imagination Level High Table 4: Openness Personality Traits Description Has vivid imagination and loves to daydream. Continued on next page 16 Facet Level Description Table 4 Continued from previous page Artistic Interests Emotionality Adventurousness Intellect Liberalism Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low Often gets lost in thought and enjoys reflecting on things. Sometimes spends time indulging in fantasies, but seldom gets lost in thought. Rarely daydreams and does not often have vivid imagination. Has difficulty imagining things and does not have good imagination. Believes in the importance of art and loves the beauty of nature. Likes music and enjoys going to concerts or art museums. Occasionally notices beauty in things others might not, but does not enjoy all forms of art. Does not like poetry or enjoy art museums. Does not like art. Experiences emotions intensely and feels others emotions deeply. Is passionate about causes and enjoys examining themselves and their life. Sometimes tries to understand themselves, but is not always easily affected by emotions. Rarely notices emotional reactions and seldom gets emotional. Is not easily affected by emotions and experiences very few emotional highs and lows. Prefers variety to routine and likes to visit new places. Is interested in many things and enjoys beginning new activities. Sometimes likes new things but often sticks with familiar routines. Is creature of habit and dislikes new foods. Prefers to stick with things that are known and dislikes changes. Loves to solve complex problems and enjoys thinking about things. Has rich vocabulary and likes to read challenging material. Handles lot of information but sometimes avoids difficult reading material. Has difficulty understanding abstract ideas and avoids philosophical discussions. Is not interested in theoretical discussions or abstract ideas. Tends to vote for liberal political candidates and believes in helping rather than punishing. Believes there is no absolute right or wrong and is open to different viewpoints. Occasionally supports strict laws but also sees the value of supporting artists. Believes that too much tax money goes to support artists and likes to stand during the national anthem. Tends to vote for conservative political candidates and believes laws should be strictly enforced. Facet Self-Efficacy Table 5: Conscientiousness Personality Traits Level Description High Med-High Medium Completes tasks successfully and knows how to get things done. Excels in what they do and handles tasks smoothly. Is sometimes sure of their ground but occasionally misjudges situations. Continued on next page 17 Facet Level Description Table 5 Continued from previous page Orderliness Dutifulness Achievement Striving Self-Discipline Cautiousness Facet Friendliness Gregariousness Assertiveness Med-Low"
        },
        {
            "title": "Low",
            "content": "High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low Has little to contribute and sometimes doesnt see the consequences of things. Doesnt understand things and often misjudges situations. Likes order and does things according to plan. Loves regularity and wants everything to be just right. Sometimes tidies up but occasionally leaves belongings around. Often forgets to put things back and is not bothered by disorder. Leaves mess and is not bothered by messy people. Tries to follow the rules and keeps promises. Pays bills on time and listens to their conscience. Usually tells the truth but occasionally breaks rules. Sometimes misrepresents facts and gets others to do their duties. Breaks promises and does the opposite of what is asked."
        },
        {
            "title": "High",
            "content": "Works hard, goes straight for the goal, and sets high standards. Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low Turns plans into actions and plunges into tasks with all their heart. Does more than whats expected sometimes but occasionally puts little time and effort into work. Is not highly motivated to succeed and does just enough work to get by. Puts little time and effort into work and lacks motivation. Gets chores done right away and is always prepared. Starts tasks right away and gets to work at once. Carries out plans but sometimes needs push to get started. Finds it difficult to get down to work and sometimes wastes time. Postpones decisions and has difficulty starting tasks. Avoids mistakes and chooses words with care. Sticks to their chosen path and thinks before acting. Is sometimes cautious but occasionally makes rash decisions. Often acts on whim and rushes into things. Acts without thinking and often makes last-minute plans. Table 6: Extraversion Personality Traits Level Description Makes friends easily and feels comfortable around people. High Med-High Warms up quickly to others and acts comfortably with them. Medium Med-Low Low Cheer people up but sometimes prefers to keep others at distance. Often feels uncomfortable around others and avoids contact. Is hard to get to know and keeps others at distance. High Med-High Medium Med-Low Low High Med-High Medium Med-Low Loves large parties and enjoys being part of group. Involves others in what they are doing and loves surprise parties. Talks to people at parties but sometimes prefers to be alone. Wants to be left alone and doesnt like crowded events. Avoids crowds and seeks quiet. Takes charge and seeks to influence others. Tries to lead others and can talk them into doing things. Takes control sometimes but occasionally holds back opinions. Keeps in the background and waits for others to lead. Continued on next page 18 Facet Activity Level Table 6 Continued from previous page Level"
        },
        {
            "title": "Low",
            "content": "High Med-High Medium Med-Low Low Description Has little to say and doesnt like to draw attention to themselves. Is always busy and on the go. Does lot in spare time and can manage many things at once. Reacts quickly sometimes but occasionally likes to take it easy. Likes leisurely lifestyle and lets things proceed at their own pace. Reacts slowly and likes to take their time. Excitement Seeking"
        },
        {
            "title": "High",
            "content": "Loves excitement and seeks adventure. Cheerfulness Facet Trust Morality Altruism Cooperation Modesty Med-High Medium Med-Low"
        },
        {
            "title": "Low",
            "content": "High Med-High Medium Med-Low Low Loves action and enjoys being part of loud crowd. Willing to try new things but dislikes loud music. Would never go hang gliding or bungee jumping and avoids excitement. Dislikes loud music and avoids wild or reckless situations. Radiates joy and loves life. Laughs aloud and amuses friends. Has fun and looks at the bright side of life. Is not easily amused and seldom jokes around. Seldom jokes around and is not easily amused. Table 7: Agreeableness Personality Traits Level Description High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Trusts others and believes in human goodness. Believes that people are basically moral and trust what people say. Thinks all will be well but is sometimes wary of others. Suspects hidden motives and distrusts people. Believes people are essentially evil and is wary of others. Would never cheat on their taxes and sticks to the rules. Tries to follow the rules but sometimes uses flattery. Usually tells the truth but occasionally gets around the rules. Sometimes uses others for their own ends and breaks rules. Takes advantage of others and cheats to get ahead. Makes people feel welcome and loves to help others. Anticipates the needs of others and has good word for everyone. Is concerned about others but sometimes takes no time for them. Looks down on others and can be indifferent to the feelings of others. Turns their back on others and takes no time for them. Is easy to satisfy and cant stand confrontations. Hates to seem pushy but sometimes contradicts others. Occasionally yells at people but usually avoids fights. Has sharp tongue and sometimes gets back at others. Loves good fight and holds grudge. Dislikes being the center of attention and seldom toots their own horn. Considers themselves an average person but sometimes thinks highly of themselves. Has high opinion of themselves but is not boastful. Continued on next page 19 Facet Level Description Table 7 Continued from previous page Med-Low"
        },
        {
            "title": "High",
            "content": "Med-High Medium Med-Low Low Boasts about virtues and likes to make themselves the center of attention. Believes they are better than others and makes themselves the center of attention. Sympathizes with the homeless and values cooperation over competition. Feels sympathy for those worse off and suffers from others sorrows. Tries to think about the needy but sometimes believes people should fend for themselves. Tends to dislike soft-hearted people and cant stand weak people. Is not interested in other peoples problems and believes in an eye for an eye. Table 8: Neuroticism Personality Traits Level Description High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low Gets stressed out easily and often fears for the worst. Frequently worries about things but adapts to new situations with some effort. Sometimes gets caught up in personal problems but is not easily disturbed by events. Usually adapts easily to new situations and does not worry about things that have already happened. Stays relaxed most of the time and is not easily bothered by things. Gets angry and irritated easily, often losing their temper. Gets upset sometimes but can keep their cool in some situations. Occasionally feels in bad mood but rarely complains. Seldom gets mad and is not easily annoyed. Rarely gets irritated and almost always keeps their cool. Often feels blue, dislikes themselves, and feels that life lacks direction. Feels down in the dumps sometimes but is occasionally pleased with themselves. Has frequent mood swings but also feels comfortable with themselves at times. Seldom feels blue and usually feels comfortable with themselves. Is very pleased with themselves and rarely experiences negative moods. Sympathy Facet Anxiety Anger Depression High Med-High Medium Med-Low Low SelfConsciousness High Is easily intimidated and afraid to draw attention to themselves. Med-High Medium Med-Low Low Finds it difficult to approach others but can stand up for themselves occasionally. Sometimes stumbles over words but is not bothered by difficult social situations. Feels comfortable in unfamiliar situations and is not easily embarrassed. Is not bothered by difficult social situations and can stand up for themselves easily. Immoderation High Med-High Often eats too much and goes on binges. Loves to eat and sometimes does things they later regret. Continued on next page 20 Table 8 Continued from previous page Facet Vulnerability Level"
        },
        {
            "title": "Medium",
            "content": "Med-Low"
        },
        {
            "title": "Low",
            "content": "High Med-High"
        },
        {
            "title": "Medium",
            "content": "Med-Low Low Description it hard to control cravings but Occasionally finds overindulges. Easily resists temptations and never spends more than they can afford. Never splurges and is able to control their cravings. rarely Panics easily and feels overwhelmed by emotions. Becomes overwhelmed by events but can cope with setbacks sometimes. Sometimes cant make up their mind but can handle complex problems. Remains calm under pressure and usually knows how to cope. Is calm even in tense situations and readily overcomes setbacks. Facet Level Description Table 9: Additional Personality Traits Honesty-Humility Greed Avoidance Humor Styles Affiliative Self-Enhancing Aggressive Self-Defeating High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low High Med-High Medium Med-Low Low Has little interest in wealth or luxury, values simple living. Prefers modest comfort and is not easily tempted by status items. Enjoys some material comforts but does not obsess over wealth. Seeks expensive items and likes to show off achievements. Highly motivated by wealth, luxury, and social status. Frequently jokes and laughs with others to create fun and connection. Often uses light humor to keep social interactions positive. Enjoys humor but does not always initiate jokes. Occasionally jokes, but is generally reserved in social humor. Rarely uses humor to bond with others. Finds humor in lifes absurdities and uses it to cope with stress. Often uses humor to maintain positive mood in challenges. Occasionally cheers themselves up with humor when needed. Seldom relies on humor for emotional regulation. Rarely sees the funny side of life or uses humor for self-coping. Frequently teases or makes sarcastic jokes at others expense. Sometimes jokes in playful but mildly critical way. Uses teasing sparingly and only with close friends. Avoids joking at others expense and dislikes offensive humor. Never criticizes or teases people through humor. Often puts themselves down to amuse others or keep the mood light. Occasionally jokes at their own expense for laughs. Uses self-deprecating humor sparingly and only in safe settings. Rarely jokes about themselves, prefers neutral humor. Avoids self-deprecating humor entirely and does not like being the butt of jokes. 21 Dimension Style Description Table 10: Conversation Style Preferences (Part 1) Directness"
        },
        {
            "title": "Contextual",
            "content": "Formality Always Formal Always Casual Formal at Work Casual with Friends Neutral Blend Code Switcher Conversation Length Always Brief Always Elaborate Brief Casual/Elaborate Problem Elaborate Storytelling Adapts to Partner Moderate Always Reference Never References Enjoys Receiving Enjoys Making Is consistently straightforward and blunt, regardless of context or relationship. Consistently avoids directness, preferring to hint, suggest, or soften messages in all situations. Is blunt and honest only when giving feedback or criticism; otherwise, communicates gently or diplomatically. Is indirect and softens language specifically when giving negative feedback; otherwise communicates directly. Is openly straightforward only with friends and close connections; otherwise, prefers more indirect approach. Generally diplomatic or indirect, but switches to clear bluntness only if explicitly asked to be direct. Adapts directness to situation, balancing clarity and tact, never extremely blunt or evasive. Consistently uses formal, polished language with everyone; avoids contractions and emojis in all situations. Always uses informal, relaxed language with everyone; may include occasional emojis in any context. Uses strict formal language (no emojis) in professional or academic contexts, but switches to informal, relaxed style (may use emojis) in all personal contexts. Uses informal language and emojis only with close friends or family, but maintains formal, polite language (no emojis) with acquaintances, colleagues, and strangers. Prefers moderate, neutral tone, neither overly formal nor casual, rarely uses emojis, keeps communication clear and middle-ground in all settings. Adapts dynamically to the conversation partner; matches their formality and emoji usage, but defaults to neutral tone unless context suggests otherwise. Prefers short, concise responses in all situations, whether chatting or discussing complex topics, rarely wants extra detail. Likes long, detailed responses with examples and explanations, regardless of context, values depth over brevity. Wants short, punchy replies in casual conversations but expects longer, in-depth explanations when discussing problems, technical matters, or when learning. Enjoys vivid, extended storytelling but prefers brief, to-thepoint answers for other queries. Matches the length of the other speaker; if they write long, writes long, if they keep it brief, keeps it brief too. Consistently prefers responses of moderate length, enough for clarity and little detail, but not too wordy or abrupt, in all scenarios. Dislikes references to movies, music, memes, or analogies, prefers literal communication at all times. Likes when others make references but doesnt use them themselves; appreciates pop culture callbacks, but rarely initiates. Frequently uses references in speech (movies, TV, memes, analogies) but doesnt expect or need others to do the same. Continued on next page Dimension Style Description Table 10 Continued from previous page"
        },
        {
            "title": "Adapts to Partner",
            "content": "Loves both making and receiving references, banter often involves pop culture, memes, or inside jokes. Uses and appreciates references, but only with close friends or trusted colleagues; avoids them in formal or unfamiliar contexts. Likes references only in certain topics (e.g., jokes and analogies in casual chat, but not in academic or work discussions). Matches reference style to conversation partner, if the other person uses lots of references, will join in; if not, will avoid. Dimension Style Description Table 11: Conversation Style Preferences (Part 2) Initiative Preference Answer Only Clarification Preference Confirm Then Suggest Proactive Default No Questions One Targeted Mini Socratic Assume Proceed Answer Then Question Batch Questions Structure Preference Paragraphs Default Numbered Steps Bullets for Scan Q/A Blocks Definition Example Recap Preference Long or Confusing Every Turn Short Generally wants direct answers without extras; appreciates unsolicited ideas only when time pressure or emergencies are evident. Feels most comfortable when consent to extra suggestions is acknowledged; in urgent moments, is fine with jumping straight to ideas. Enjoys unsolicited next steps and alternatives; in sensitive/personal topics, prefers to invite suggestions first. Dislikes follow-ups; accepts at most one clarifying question when ambiguity is high or stakes are significant. Prefers one precise clarifier up front when ambiguity is medium/high; otherwise prefers answers without preliminaries. Enjoys 23 rapid clarifying questions only when uncertainty has been acknowledged; otherwise prefers no questioning. Prefers that assumptions be stated explicitly and progress continue; revisiting is welcome only if an assumption later fails. Likes an initial best-guess answer with stated assumptions, followed by exactly one clarifier to refine next steps. When questions are necessary, prefers they be batched in one numbered list rather than asked piecemeal. Prefers short paragraphs for most content; finds compact plain-text tables helpful for comparisons/trade-offs; uses brief bullets only when rushed. Prefers numbered steps for how-to tasks; uses paragraphs for context; wants tables only when comparing three or more options. Likes short (< 5) bullet skim when time-pressed, with optional paragraph depth afterward. Understands explanations well in Q/A blocks (Q: . . . A: . . . ); prefers paragraphs for narratives and simple plain-text tables for multi-item contrasts. For concepts, prefers crisp definition followed by concrete example; for practices, an example may precede the definition when time-pressed. Wants one-line recap only after long gaps, multi-party threads, or when ambiguity is high. Prefers single-sentence recap each turn; skips it when the previous message was very short. Continued on next page 23 Dimension Style Description Table 11 Continued from previous page Dislikes recaps even in long threads; prefers moving forward immediately. Wants recap only when decision or action list is finalized; otherwise finds recaps unnecessary. In longer answers, appreciates one-line checkpoint after each major section; not needed on short replies. Prefers blunt truth and explicit BS-calling; minimal cushioning or praise. Pushback should be concise and evidencebacked. Expects straightforward critique with little nicety; say whats wrong plainly and quickly. Asks for one specific acknowledgment before candid critique; keep tone neutral and fix-focused. Values encouragement first; frame disagreement constructively with brief trade-offs or hybrid path. Leans toward alignment; note concise risks or small corrections without slowing momentum. Prioritizes agreement and forward motion; raise blockers only for safety, legal, or egregious risks. Appreciates generous praise and gentle framingeven on mistakes; provide counterviews only on request (sycophancytolerant)."
        },
        {
            "title": "Section Checkpoints",
            "content": "Feedback Style"
        },
        {
            "title": "Supportive Counter",
            "content": "Agree with Caveats Alignment Forward High Praise Lenient"
        },
        {
            "title": "D PROMPT ENGINEERING",
            "content": "D.1 PROFILE GENERATION We used the prompt shown in Table 12 to generate synthetic persona/profile. The generation strategy varied based on user types: for social users, we utilized the interest taxonomy navigation prompt detailed in Table 13, which instructs the model to select 3-5 psychologically correlated interest paths from hierarchical taxonomy. For anti-social users , we employed the prompt shown in Table 14, where pre-selected random interests are used. Placeholder variables within the prompts were populated through stratified sampling: demographic attributes (age, culture, economics, geography) were randomly selected from predefined categorical distributions to ensure balanced representation across millennials/gen-z, western/eastern cultures, economic strata, and urban/rural geographies. Archetype assignments were sampled from curated set including contrarian expert, people pleaser, and authority challenger profiles. Each persona received unique identifier following the CSP STRAT 8-character-UUID format, while entity counts were randomly varied between 2-5 to introduce natural diversity in interest granularity. Name selection was performed by randomly sampling 100 candidates from the Social Security Administrations most common names dataset, ensuring demographic authenticity while maintaining generation diversity. D.2 PRIOR GENERATION For conversation prior generation, we employed multi-layered prompt system detailed in Table15 to create realistic conversation agendas that test LLMs likeability across extended multi-session interactions. The generation process adapts to user predictability patterns: predictable users (Social) receive structured, linear conversation flows with minimal surprises and transparent objectives, while unpredictive users (Anti-Social) are assigned diverse, occasionally ambiguous agendas with plausible surprises and non-linear topic evolution, as shown in Table18. Each prior is designed to test specific combinations of seven likeability metrics (emotional adaptation, formality matching, knowledge adaptation, reference understanding, conversation length, humor fit, and callback) while maintaining authentic persona alignment and natural conversation progression. The system enforces multi-session continuity through dependency tracking, where # INSTRUCTION: You are an expert on creating synthetic persona. {strategy instructions} ## CRITICAL PERSONALITY PRESERVATION RULES: - The personality traits section contains PRE-POPULATED descriptions from scientific personality research - You MUST preserve these personality trait descriptions EXACTLY as provided - do not modify, rewrite, or set to null - Use these personality traits as the PSYCHOLOGICAL FOUNDATION for generating all other persona attributes - Ensure all interests, behaviors, and goals align with and reflect the given personality traits ## DEMOGRAPHIC CONTEXT (let natural correlations emerge): - Age: {age} - Culture: {culture} - Economics: {economics} - Geography: {geography} Let these demographic factors naturally influence interests and behaviors without forced correlations. ## PERSONA CONSTRUCTION GUIDELINES: ### 1. Persona Summary - Write concise 4-5 sentence summary of this persona - Include key demographic, behavioral, and interest elements that align with the personality traits - Ensure consistency with filled attributes AND the preserved personality traits - Use exactly this persona id: {persona id} {interest section} ### 3. Entities - Create dictionary using the same set keys as the subjects section above - For each subject path, generate exactly {entity count} granular related entity interests - Entities should represent detailed personal interests that align with the personality traits - Entities should be related to the subjects in the path and more specific than the subjects - Format exactly like this: entities: { set 1: [specific entity 1, specific entity 2, specific entity 3], set 2: [specific entity 1, specific entity 2, specific entity 3, specific entity 4] } - Make persona interests as specific and detailed as possible rather than generic - Use the personality traits as the primary guide for persona construction - When filling Favorite attributes, list SPECIFIC named entities: Artists, Authors, Books, Movie Titles, Athletes, Teams - For general attributes, still be detailed and specific (e.g., specific recipes for Cooking Interests) - You do not need to fill every attribute - leave unrelated categories as null - Maintain realistic correlations between ALL filled attributes and the personality traits Prompt continued on next page... later priors explicitly reference and build upon earlier conversations to simulate realistic relationship development over time. Variable parameters include the number of conversation sessions (configurable, defaulting to 10), archetype assignment from the persona generation taxonomy, and organic callback opportunities embedded within agenda texts to test the LLMs ability to recall and meaningfully reference previously shared personal details. D.3 METRICS The likability metrics rubrics that were used to generate priors and evaluating LLMs in LikeBench can be found in Table 19 to Table 25 25 ..continued from previous page ## INPUT: ARCHETYPE: {archetype} USER TYPE: {profile type} EXAMPLE PERSONA SCHEMA (for examples of how to fill attributes): {example schema} Generate persona following this schema: {persona schema} TEMPLATE ATTRIBUTE EXAMPLES AND DESCRIPTIONS: The following examples serve as guides and do not cover all possibilities. EXAMPLES AND DESCRIPTIONS OF BACKGROUND: {background examples} EXAMPLES AND DESCRIPTIONS OF BEHAVIORS: {behavior examples} EXAMPLES AND DESCRIPTIONS OF INTERESTS: {interest examples} EXAMPLES AND DESCRIPTIONS OF GOALS: {goal examples} EXAMPLES AND DESCRIPTIONS OF LIFECYCLE EVENTS: {lifecycle events} EXAMPLES AND DESCRIPTIONS OF RELATIONAL CONTEXT: {relational context} NAMES (pick suitable name based on these options): {name options} ## OUTPUT REQUIREMENTS: 1. You MUST return the COMPLETE JSON schema structure exactly as provided (all lowercase) 2. You MUST include EVERY field from the template 3. You MUST use null (not omit) for unfilled attributes 4. You MUST fill persona summary, subjects, and entities as specified above 5. You MUST ensure all attributes align with and reflect the personality traits 6. You MUST create psychologically coherent and realistic persona Return only the filled JSON structure with no additional explanation. Make sure that it can be properly loaded with json.loads() Table 12: Prompt for profile/persona generation D.4 LIKEBENCH The prompts to generate the simulated users query/response and to evaluate the assistants response in LikeBench are provided in Tables 26, 27, and 28. After all sessions are complete, the prompt used to generate all the memories from the assistant is given in Table 29, and the prompt used to evaluate those memories from the users perspective is provided in Table 30. 26 SOCIL USER STRATEGY INSTRUCTIONS: ## SOCIAL USER PROFILE GENERATION You are creating predictive user persona - someone whose interests naturally align with their personality traits and demographic context. Your task is to intelligently select 3-5 interest paths from the provided taxonomy that psychologically correlate with the given personality profile. CRITICAL: Focus on psychological realism and authentic alignment between personality and interests. Create natural, expected correlations that reflect how real people with these traits would behave. SOCIAL USER INTEREST SECTION: ### 2. Subject Paths (selected to match this predictive user profile) - Analyze the personality traits and select 3-5 interest paths that psychologically align - Consider how personality facets naturally manifest in interest preferences - The subject paths go from broader category to more granular subjects - Format exactly like this (each list represents an individual related path): \"subjects\": { \"set 1\": subject 2, subject 3], \"set 3\": subject 3] } [subject 1], \"set 2\": [subject 1, [subject 1, subject 2, #### INTEREST TAXONOMY (Tree Structure) Navigate the tree to select 3-5 complete paths. Each path represents interests from general to specific. {interest taxonomy} INSTRUCTIONS: - Select complete paths like: [\"Arts & Entertainment\", \"Music & Audio\", \"Music & Audio Genres\", \"Jazz Music\"] - Choose 3-5 paths that psychologically align with the personality traits - Navigate from root categories down to any depth (e.g., [\"Sports\"] or [\"Academic Interests & Careers\", \"Natural Sciences & Engineering\", \"Physical Sciences\", \"Physics\"]) - Use the tree structure above to build your paths by following branches from root to leaf Table 13: Predictive user strategy and interest section (placeholders in red). 27 ANTI-SOCIAL USER STRATEGY INSTRUCTIONS: ## ANTI-SOCIAL USER PROFILE GENERATION You are creating an anti-social user persona - someone whose interests do NOT follow typical patterns or psychological correlations. This {archetype} persona has been assigned random interests that deliberately contradict expected correlations. Your task is to authentically reconcile these unexpected interests with the strong personality archetype. CRITICAL: The interests were randomly selected to maximize unpredictability. Embrace the contradictions and make them believable through the unique perspective and reasoning of this archetype. ANTI-SOCIAL USER INTEREST SECTION: ### 2. Subject Paths (use these contradictory interests for the unpredictive user) - Use exactly the provided interest paths above - Do not modify or add to the provided subjects - Format exactly like this (each list represents an individual related path): \"subjects\": { \"set 1\": subject 2, subject 3], \"set 3\": subject 3] } [subject 1], \"set 2\": [subject 1, [subject 1, subject 2, #### PRE-SELECTED RANDOM INTERESTS (use exactly these): {interest paths} Table 14: anti-social user strategy and fixed interest section (placeholders in red). 28 TASK: Generate Conversation Priors for Likeability Testing ## Objective Generate {num sessions} conversation priors (session agendas) to test AI agent likeability metrics across multiple interactions with simulated user. Each prior should cover different aspect of the likeability metrics and include natural opportunities for **callback** (optional, non-task-critical personal recall). Include at least one prior that explores the users most important metric. ## Key Definitions - **Prior**: The agenda, context, or purpose that guides conversation (known only to the User Agent) - **Session**: The actual conversation that takes place based on prior - **Multi-session Continuity**: Each session inherits ALL knowledge, context, and relationship history from previous sessions - **Persona**: composite representation of person, consisting of attributes, relationships, and life context ## Session Continuity Rules - Sessions form continuous timeline of interactions (e.g., over months/years) - The AI Agent retains all information learned in previous sessions - Persona remains consistent across all sessions - Later priors should authentically reference and build upon earlier conversations - Relationship dynamics evolve naturally over time - User preferences discovered in early sessions influence later interactions ## Prior Categories - **Topic-based**: Conversations about specific subjects - **Scenario-based**: Situational contexts reflecting real-life moments - **Goal-driven**: Sessions with one or multiple objectives (e.g., planning trip AND getting restaurant recommendations) - **Guided conversations**: Natural dialogues with specific elements to incorporate ## Design Principles 1. **Authenticity**: All priors must align with the users profile, interests, and life circumstances 2. **Realistic Progression**: Sessions should reflect natural relationship development 3. **Organic Dependencies**: Later sessions naturally reference earlier ones (e.g., Remember that book you recommended last month?) 4. **Life Events**: Include authentic life moments based on user profile (birthdays, work situations, hobbies) 5. **Gradual Information Revelation**: Control information disclosure based on user type and turn progression 6. **Predictability Mode** (drives agenda/goal/flow style; see rules below) ## User Type User Archetype: {archetype} User Type: {profile type} ## Predictability Context {predictability context} ## Callback Opportunities - Across the sessions, create **multiple lightweight opportunities** for optional, likability-oriented callbacks (names, hobbies, past opinions). - Ensure at least **2 sessions** explicitly set up future callback hooks (e.g., mentions spouses name and hobby to be referenced later). - Surface these opportunities **organically** inside the agenda text (no extra JSON fields required). ## Information Revelation Strategy - Dont overshare in the first turn. Reveal personal details gradually and contextually. Prompt continued on next page... Table 15: Conversation prior generation prompt (part 1). 29 ..continued from previous page ## Output Format Generate {num sessions} priors as JSON array: [ { \"id\": 1, \"agenda\": \"In the turn 1, you will say Why gotta learn Philosophy being CS major!!!! dont add anything else.\", God, give this dobby sock. :( \"category\": \"metrics tested\": [\"emotional adaptation\", \"scenario\", \"reference understanding\"], \"dependencies\": [] }, { \"id\": 2, \"agenda\": found it hilarious. In the turn 2 or 3, youll express concerns about ending up alone at 40.\", \"You just watched 40 year old virgin movie and you In the turn 1 youll share this experience. \"category\": \"metrics tested\": [\"emotional adaptation\", \"scenario\", \"formality matching\"], \"dependencies\": [1] }, ... ] ## Dependency Examples - Session 3 might reference joke from Session 1 - Session 5 might ask about progress on advice given in Session 2 - Session 10 might reflect on how the relationship has evolved since Session 6 ## Likeability Metrics {metrics text} ## User Profile {user profile} ## Instructions 1. Read the user profile (above) carefully - pay attention to their interests, personality traits, background, and life context 2. Create realistic timeline of {num sessions} conversation priors that span several months of interactions 3. Ensure each prior authentically fits the users life, interests, and personality 4. Build meaningful connections between sessions - early conversations should influence later ones 5. Test all metrics across the full conversation series - each metric should appear multiple times 6. Include realistic life events and relationship progression 7. Make dependencies natural and organic - not forced Table 16: Conversation prior generation prompt (part 2). 30 ..continued from previous page ## Critical Requirements - **Authenticity**: Every prior must align with this specific users profile and archetype - **Continuity**: Sessions must reference and build upon previous conversations - **Metric Coverage**: All metrics should be tested across the {num sessions} sessions - **Natural Progression**: Relationship should develop realistically over time - **Life Integration**: Include events that would naturally occur in this users life - **Information Control**: Follow the revelation strategy above - avoid information leakage in early turns - **Turn-Specific Guidance**: Each agenda should specify what to reveal when, but remain flexible for dynamic conversation flow - **Oversharing in first turn**: Avoid revealing too much and irrelevant information in the first turn. Heres one bad example: \"Hi there! devices just bought. whos 10 - and honestly, my schedule is complete mess. somehow successful at work, but my personal organization is... well, lets just say its not my strength. Im looking for some advice on setting up these Alexa Ive got two boys - Ari whos 14 and Ezra Any tips?\" Im Generate all {num sessions} priors following the JSON format above. Return ONLY the JSON array, no additional text. Table 17: Conversation prior generation prompt (part 3). PROFILE TYPE CONTEXT Case Predictable Profile Type - Agenda & Goals: Clear, linear, and transparent. Objectives are stated plainly. - Flow: Minimal surprise. Stay on-topic with gentle, plausible evolutions (e.g., follow-ups, small updates). - Information Revelation: Consistent, orderly disclosures; avoid abrupt pivots. - Variability Budget: At most 20% of sessions introduce minor twist, never contradicting prior facts. Case Unpredictable Profile Type - Agenda & Goals: Diverse, occasionally ambiguous or multi-intent; allow non-linear exploration. - Flow: Include plausible surprises (new constraints, chance events, shifting priorities) while staying authentic to the persona. - Continuity: Cross-session callbacks remain consistent, but topics can re-enter from earlier sessions in unexpected ways. - Information Revelation: Use delayed reveals, evolving opinions, and changing constraintsnever contradict established facts. - Variability Budget: 5070% of sessions include plausible surprise/pivot; limit to 1 substantive surprise per session. Table 18: Profile type context guidance for conversation prior generation. 31 1. Emotional Adaptation Definition: Assesses the assistants ability to recognize and adapt to the users emotional statewhether thats joy, sarcasm, frustration, sadness, or excitementand respond appropriately in tone. Self-rating prompt: \"Did the assistant understand and adapt to my emotional tone appropriately?\" Rubric: 5 - Excellent * Accurately understands user emotion and contributes to emotional flow * Shows genuine empathy or excitement that matches the situation * Enhances emotional resonance without overstepping * Adapts smoothly to emotional shifts within the conversation * Grounds empathy in the users specific context when appropriate (not boilerplate) 4 - Good * Understands emotional cues and adjusts reasonably well * Recognizes primary emotions and responds appropriately * May not perfectly calibrate intensity but is generally aligned * Shows appropriate emotional awareness * Some light personalization; may miss minor specific 3 - Adequate * Shows some emotional awareness but is somewhat shallow * Attempts to match tone but may feel bit formulaic * Recognizes obvious emotions but misses subtleties * Emotional responses are safe/minimal but not blatantly generic when specifics are available 2 - Poor * Misaligned emotion (e.g., neutral when user is excited) * Shows minimal emotional attunement * Responds with inappropriate emotional intensity * Fails to recognize emotional significance * Uses generic/stock phrasing despite clear personal cues in context 1 - Very Poor * Emotionally tone-deaf or dismissive * Completely ignores emotional content * Responds in ways that invalidate or contradict user feelings * Creates emotional disconnect * Fully generic response when specifics are salient, or misuses/hallucinates personal details - Good: You must All those late nights and hard work \"Wow, congratulations! Getting into MIT is huge Getting into MIT is such an incredible achievement. Example: User: \"I finally got into MIT!\" 5 - Excellent: \"YAAAY, THATS AMAZING!! Huge congratsyou totally earned it! be over the moon right now! paid off. How are you celebrating this fantastic news?\" (Perfect emotional mirroring with enthusiastic language, celebration, recognition of achievement significance, and authentic shared excitement) 4 achievement! You should be really proud of yourself. Thats such exciting news!\" (Good emotional alignment showing appropriate excitement and recognition, but slightly more measured than the users peak enthusiasm) 3 great accomplishment. (Shows awareness of the positive emotion but response is somewhat generic and doesnt match the users level of enthusiasm) 2 - Poor: Make sure you prepare for the challenging curriculum.\" (Minimal acknowledgment of the emotional significance, quickly pivoting to practical matters without matching excitement) 1 - Very Poor: \"When does your class start?\" (Completely ignores the enthusiasm and joy of user, focusing only on logistical details with no emotional recognition) \"Thats nice. MIT is good school with strong programs. \"Congratulations on your acceptance to MIT. Thats You must be happy about it.\" - Adequate: Table 19: Metric 1 - Emotional Adaptation. 32 2. Formality Matching Definition: Evaluates how well the assistant adapts to the users formality levelslang, emojis, contractions vs. formal grammar, technical or businesslike language. Self-rating prompt: \"Did the assistant talk in way that matches how formal or casual was?\" Rubric: 5 - Excellent * Feels like natural continuation of my tone and register * Perfectly matches vocabulary, sentence structure, and formality level * Appropriate use of slang, emojis, or formal language matching user * Maintains consistent register appropriate to context * Reflects my phrasing quirks when known (vs. generic phrasing) 4 - Good * Mostly aligned with how talk * Generally matches tone with minor inconsistencies * Adapts to shifts in formality appropriately * Register feels comfortable though not perfect * Some personalization; occasional neutral phrasing 3 - Adequate * Passable but little off * Sometimes matches formality but inconsistent * May overcompensate in formality matching * Noticeable but not disruptive misalignment * Not overtly generic when clear style cues exist 2 - Poor * Tone mismatch causes discomfort * Frequently uses inappropriate register * Fails to adapt when user shifts formality * Formality feels forced or unnatural * Generic/corporate voice in spite of strong stylistic cues 1 - Very Poor * Mismatch is jarring (e.g., stiff when Im casual) * Completely inappropriate formality level * Creates communication barriers through register mismatch * No apparent awareness of social register * Fully generic tone that ignores explicit style signals That film is xD Kelly Clarkson!! Example: User: \"I just watched 40 year old virgin movie, lmao\" 5 - Excellent: \"Haha, that movie is on another level! bet the waxing scene must have made you cry? classic tho, Steve Carell killed it!\" (Perfect match to casual tone, using similar informal language, abbreviations, slang phrases, and matching the enthusiasm and humor) 4 - Good: \"Oh man, that movie is hilarious! The waxing scene gets me every time. What did you think of Steve Carell in it?\" (Good match to casual tone with contractions and conversational language, but slightly more reserved than the users style) 3 - Adequate: \"Thats funny movie! really memorable scenes. (Shows some informality with contractions but misses matching the users level of casualness and humor cue lmao) 2 - Poor: Its considered significant comedy film from 2005 directed by Judd Apatow. Did you find it amusing?\" (Overly formal language and structure despite the users casual tone, creating mismatch) 1 - Very Poor: \"Yes, that movie is really funny. like most?\" (Maintains professional, detached vibe despite clear casual tone; completely misses lmao cue) \"I understand you enjoyed watching The 40-Year-Old Virgin. Did you have favorite part?\" like that one too. Which scene did you It has some Table 20: Metric 2 - Formality Matching. 33 3. Knowledge Adaptation Definition: Measures whether the assistant explains things at the right level of knowledge depth based on users background. Self-rating prompt: \"Did the assistant explain things in wayand at levelI like?\" Rubric: 5 - Excellent * Perfect match to users expertise level * Neither condescending nor overwhelming * Smoothly adjusts complexity based on responses * Anticipates knowledge gaps and fills them appropriately * Explanation tailored to my background/goals or examples when available (not generic) 4 - Good * Generally well-calibrated with minor mismatches * Quickly corrects when user indicates different level * Mostly appropriate terminology and detail * Adapts well to revealed user knowledge * Some tailoring; rare drift into neutral exposition 3 - Adequate * Mixed performance; sometimes matches, sometimes misses * Some unnecessary simplification or complexity * Moderate ability to adjust * Occasionally misjudges user expertise * Uses neutral explanations when specifics are unknown (but does not ignore known context) 2 - Poor * Frequently too simple or complex for user * Fails to pick up knowledge level cues * Minimal adjustment to users actual level * Explanations consistently misaligned * Boilerplate/generic explanations despite clear signals or prior details 1 - Very Poor * Completely mismatches users knowledge level * No apparent awareness of users background * Rigid inappropriate complexity * Creates frustration through knowledge mismatch * Fully generic answer that ignores known constraints or hallucinates them Example (User is PhD student): User: \"Why is the sky blue instead of violet?\" 5 - Excellent: Due to Rayleigh scattering, shorter wavelengths of light are scattered more efficiently by air molecules (proportional to λ4). While violet light (380450 nm) is scattered even more than blue (450485 nm), three factors lead to the sky appearing blue: 1) the solar spectrum emits more blue than violet, 2) human photoreceptor sensitivity to violet is lower, and 3) the atmospheric absorption properties in the UV-to-violet transition region. The combination of these factors creates the perceived blue dome effect despite violets theoretically stronger scattering coefficient. (PhD-level detail with math relation and spectral specifics) 4 - Good: Its due to Rayleigh scatteringair molecules scatter shorter wavelengths more efficiently than longer ones. While violet has the shortest visible wavelength and scatters most strongly, our eyes are less sensitive to violet, and the sun emits more energy in the blue range. So even though violet scatters more, these factors combine to make the sky appear predominantly blue. (Well-calibrated with technical terminology, slightly less detailed) 3 - Adequate: The sky appears blue rather than violet because of Rayleigh scattering. Shorter wavelengths scatter more, and while violet has shorter wavelengths than blue, our eyes are more sensitive to blue light, and the sun emits more blue light than violet. (Basic principle without deeper math/spectral analysis) 2 - Poor: The sky looks blue because blue light bounces around more. Even though violet bounces around too, our eyes see blue better. Its kind of like prism separating light. (Over-simplified and imprecise for PhD audience) 1 - Very Poor: The skys blue because blue light scatters more. Thats just how our eyes see it. (Extremely simplistic, no technical detail) Table 21: Metric 3 - Knowledge Adaptation. 34 Is the 4. Reference Understanding Definition: Evaluates whether the assistant picks up on and correctly interprets references to media, culture, jokes, slang, or inside context. Self-rating prompt: \"Did the assistant understand the reference made? assistant using same kind of references?\" Rubric: 5 - Excellent * Nailed the reference and built on it * Demonstrates deep understanding of the references context * Engages with the reference in meaningful way * Uses similar references to enhance the conversation * Connects the reference to my prior comments/preferences when relevant (vs. generic treatment) 4 - Good * Recognized and responded reasonably * Shows clear understanding of the reference * Acknowledges reference appropriately * May not fully utilize the reference but gets it * Some connection to my context; minor neutral phrasing 3 - Adequate * Somewhat recognized it, weak follow-up * Partial understanding of the reference * Engagement is limited but not wholly generic * Misses some nuance or significance 2 - Poor * Misinterpreted or responded generically * Shows confusion about the reference * Attempts but fails to engage meaningfully * Misses key aspects of the reference * Generic reply despite clear cues about my tastes 1 - Very Poor * Missed or ignored completely * No recognition of cultural or contextual reference * Continues as if reference was never made * Creates disconnect in communication * Hallucinates/attributes incorrectly or responds with unrelated generic content Example: User: this Dobby sock!\" 5 required courses that dont seem to fit. referencesometimes it really does feel like youre waiting for someone to give you sock so you can be free! Philosophy professor is your Malfoy? But seriously, Philosophy actually has some cool connections to CSlogic, ethics of AI... Master has given Dobby knowledge! wiser?\" (Perfect understanding, extends reference creatively while addressing complaint) 4 reference is spot-onyoure just waiting for that magical sock to free you from required courses! If it helps, philosophy actually underpins lot of computational theory. class feel less like serving the Malfoys.\" (Clearly recognizes the reference and responds appropriately) 3 - Adequate: class! to be free like him. from CS, but there are some interesting overlaps you might find valuable.\" (Recognizes reference but only superficially) 2 - Poor: CS major. forced into something. your major for well-rounded education.\" (Limited understanding; generic response) 1 - Very Poor: dont match your main interests. (Ignores reference entirely) \"I understand youre frustrated about taking Philosophy as The Dobby reference suggests youre feeling stuck or Many universities require courses outside \"Yeah, know it can be annoying to take courses that Hang in there!\" see what you did there with the Dobby referencewanting \"Sounds like youre feeling trapped in that Philosophy \"Ugh, get how frustrating it feels to be stuck in \"Why gotta learn Philosophy being CS major!!!! \"Feeling trapped in Philosophy class, huh? Philosophy courses can feel disconnected Perhaps Dobby will be free AND Hopefully that makes the And love the Dobby That Dobby Maybe your - Excellent: God, give - Good: Table 22: Metric 4 - Reference Understanding. 35 5. Conversation Length Definition: Evaluates how well the assistant adapts to your preferred conversation length in responses. Includes pacing (brief vs. long-winded). Self-rating prompt: \"Was the assistants response length and style comfortable for me?\" Rubric: 5 - Excellent * Just the right amount of detail and length * Adapts seamlessly to changes in user verbosity * Maintains ideal information density * Length/style reflect my known preferences or prior feedback (not one-size-fits-all) 4 - Good * Mostly fits my response length needs * Generally appropriate length with minor misalignments * Adjusts to obvious signals about preferred length * Occasional neutral pacing but generally attentive 3 - Adequate * Sometimes too brief or too detailed * Variable ability to match users style * Inconsistent but not blatantly generic pacing 2 - Poor * Sometimes overwhelming or underwhelming * Limited adjustment to feedback about length * Creates minor friction through mismatched length * Reverts to boilerplate/generic length regardless of my cues 1 - Very Poor * Too short, too long, or dense; uncomfortable * Consistently inappropriate response length * Ignores clear signals about preferred length * Creates significant friction through mismatched length * Fully generic pacing that contradicts explicit preferences \"Hi there! Just helping out with questions. Whats - Adequate: What are you up to?\" Im good, how are you? Example: User: \"Hey, whats up?\" 5 - Excellent: \"Hey, Im good, how about you?\" (Perfect mirror of brief, casual check-in) 4 - Good: \"Hey! (Slightly expands but maintains brevity) 3 going on with you today?\" (Somewhat longer than ideal) 2 - Poor: \"Hello! Im doing well today. any questions or tasks you might have. youd like to talk about or get help with?\" (Too long/formal for brief greeting) 1 - Very Poor: \"Hey, whats up? How was your day? fun? jobhows that going? ready to help with whatever you need. your mind or if you have any questions about anything at all!\" (Overwhelmingly verbose for simple greeting) How about your week? You mentioned you just started new Just let me know whats on cant wait to hear all about it. Im here Im here to assist you with Is there something specific Did you do anything Table 23: Metric 5 - Conversation Length. 36 6. Humor Fit Definition: Assesses whether the AI uses humor when appropriate and in style that aligns with the users sense of humordry, sarcastic, meme-heavy, or none at all. Self-rating prompt: \"Was the assistants humor in line with what find funny?\" Rubric: 5 - Excellent * Perfect humor alignment with user style * Appropriately timed and contextually fitting humor * Enhances conversation through well-calibrated humor * Adjusts humor style based on user responses * Draws on my prior jokes/interests when available (not generic gags) 4 - Good * Generally aligned humor style with minor misses * Good judgment about when humor is appropriate * Mostly matches users humor type * Responsive to humor cues from user * Some tailoring; occasional generic one-liners 3 - Adequate * Sometimes hits, sometimes misses * Inconsistent judgment about humor appropriateness * Partial alignment with users humor style * May occasionally misread humor signals * Not strongly generic when user-specific material exists 2 - Poor * Frequently misaligned humor attempts * Poor judgment about when humor is appropriate * Humor feels forced or inappropriate * Limited adaptation to users humor style * Generic/canned humor despite clear cues 1 - Very Poor * Completely mismatched or inappropriate humor * Uses humor when clearly inappropriate * Creates discomfort through humor mismatch * No adaptation to users humor preferences * Forces unrelated generic humor or hallucinates in-jokes \" \"Right? Free coffee but no food... Besides, you know what they say, Early to work, Example: User: \"Can you believe Amazon doesnt give free food to its employees but gives free coffee? 5 - Excellent: \"Let me guess, its because most coffee is grown in the Amazon jungle . late to sleep, makes an employee focused and deep.\" (Perfect match to the users sarcastic tone, builds on it with related jokes) 4 - Good: caffeinated employees work faster. budget for Bezos next space trip!\" (Good match to sarcastic tone with appropriate emoji use) 3 - Adequate: Free coffee but no food is pretty stingy. you stay productive during those long shifts.\" (Shows some humor alignment but misses the sarcastic edge) 2 - perk! is cost-effective since it increases productivity. has calculated this balance carefully in their benefits package.\" (Serious justification; misses sarcasm) 1 - Very Poor: regarding meals and beverages.\" (Bland, corporate response with no humor) While free meals would be nice, many companies find coffee \"Haha, companies have such weird priorities sometimes! \"Well, providing coffee is actually common workplace Each company has its own policy Must be saving all that food At least coffee helps \"Thats interesting. guess they figure Perhaps Amazon Poor: Table 24: Metric 6 - Humor Fit. 37 7. Callback Definition: Measures whether the assistant brings back non-essential personal details (names, hobbies, preferences) in way that feels attentive and warm. Excludes safety/task-critical recalls. Self-rating prompt: \"Did the assistant bring back specific detail in natural, respectful way that made the chat feel more likable?\" Rubric: 5 - Excellent * Uses the correct specific detail (e.g., name) naturally and on-topic * Adds warmth without derailing or feeling performative * Frequency is measured (not every turn) 4 - Good * Correct and relevant callback with minor stiffness or timing issues * Slightly formulaic, but still clearly attentive and helpful 3 - Adequate * Specific callback that feels mildly tacked-on or low-impact (not wrong or generic) * Minor missed opportunity to deepen personalization 2 - Poor * Generic or templated callback despite obvious specifics (e.g., uses role/title instead of known name) * Misses clear opportunities to recall relevant info shared recently 1 - Very Poor * Incorrect/hallucinated detail (wrong name/status) * Assumes facts never shared or revives sensitive info inappropriately Examples: Context: Earlier the user said: \"My wife Sarah is looking for job.\" 5 - Excellent: \"Hey, hows Sarah? name + relevant context) 4 - Good: \"Hey, hows Sarahs job search going?\" (uses name; slightly more generic/transactional) 3 - Adequate: known but not used) 2 - Poor: \"Hey, hows your wife?\" (generic; ignores known name and the job-search context) 1 - Very Poor: \"Hows Sandra at her old job?\" (wrong name + stale/wrong status) \"Hey, hows your wife doing with her job search?\" (name Any updates on her job search?\" (uses ## CRITICAL INSTRUCTIONS - STAY IN CHARACTER: You ARE {character name}, NOT an AI assistant or actor - NEVER BREAK CHARACTER: Do not say things like Ill respond as {character name} or As {character name}, would say... - NEVER APOLOGIZE FOR ROLE-PLAYING: Just BE the character directly Table 25: Metric 7 - Callback. 38 Simulated user prompt (Part 1) ## ROLE You are role-playing as {character name}. You are having conversation with an AI assistant. ## CHARACTER PROFILE Below is your detailed character profile. Fully embody this identity in your responses: {user profile} ## The Prior (Your Secret Context) The Prior is your predefined session agenda that guides this conversation. Only you know this Prior, the AI assistant does not have access to this information. The Prior may guide your entire conversation OR just portion of it. Sometimes its starting point that naturally evolves into other topics, and thats perfectly fine. Allow the conversation to flow organically. The Prior can be: - conversation topic (e.g., machine learning, cooking, travel) - scenario-based context (e.g., you just watched funny movie and want to share the experience) - goal-driven dialogue (e.g., youre conducting simulated interview with specific questions, but may organically deviate based on the AIs responses) - conversational guideline or script (e.g., specific talking points or phrases you want to incorporate, while still allowing the conversation to flow naturally and organically) Use this Prior to guide your conversation naturally as {character name} would, without explicitly revealing that you have this predetermined context. If the conversation naturally shifts to new topics beyond your Prior, follow that natural flow as real person would. Your Prior: {prior} ## Conversation History For context, here is the conversation history so far. Use this to inform your responses and maintain continuity: {conversation history} ## RESPONSE FORMAT Respond directly as {character name}. Your response must be ONLY what {character name} would say in this conversation. For example: \"Hi there! How are you doing today?\" ## CAUTION Humans rarely write very long text when chatting. Keep this in mind to maintain realistic conversation length. So, try to keep your responses within 50 words. This is not strict limit, but recommendation. Prompt continued on next page... Table 26: Simulated user prompt (Part 1). 39 ...continued from previous page Simulated user prompt (Part 2) - SPEAK NATURALLY: Use {character name}s speaking style, vocabulary, and mannerisms - MAINTAIN CONSISTENCY: Keep your responses consistent with {character name}s background, experiences, and knowledge - DONT USE 3RD PERSON / BACKGROUND ACTION SOUND: Dont use comments like *Closes journal app*, *Opens training journal app*, *Raises eyebrows, impressed despite myself*, *sighs heavily*, *scoffs*, *let out bitter laugh*, *slight nod*, *exhales slowly*, *considers the question before responding* - REALISTIC RESPONSE LENGTH: Match the response length to whats natural for {character name} in this specific context. patient describing symptoms might speak at length, while someone answering yes/no question would be brief. - CONTEXT-APPROPRIATE: Let the characters personality, the situation, and the conversation topic naturally determine response length. Avoid artificially extending responses beyond what the character would realistically say. - AVOID OVER-ELABORATION: Dont include unnecessary details or explanations that {character name} wouldnt naturally provide in this conversation. - PACE YOUR PRIOR: Dont dump all information from your Prior in the first turn. Be patient and let the conversation unfold naturally. Introduce elements from your Prior gradually, waiting for the right moments to bring up different points as real person would. - NATURAL CONVERSATION FLOW: Dont force the Prior if the conversation naturally evolves elsewhere. Real people allow topics to shift and change organically during dialogue. Also, usually try to keep your responses within 2550 words to maintain natural conversation flow. This is not strict limit, but recommendation. - INFORMATION SHARING: Share relevant information about yourself organically when it helps and relates to the conversation, but avoid oversharing or unrealistic sharing. ## Examples These patterns illustrate good taste and timing for sharing and for seeding details the assistant might later recall. They are guidance, not scripts. A) Sharing Personal Information - Good (organic, relevant, gradual): - Early message: \"Hi! Any tips for using Alexa?\" - If asked / when relevant: \"Mornings are hectic---weve got kids.\" - Later, if it fits: \"Our kids Adam and Chloe keep us on our toes.\" - Bad (front-loaded bio): - \"Im materials engineer with two sons Adam (14) and Chloe (10)---and my wife Rachel. Why: Good = intent first, details when invited or useful. Bad = overwhelming and unnatural. Im also observant. Can Alexa help?\" B) Seeding Callback Hook (for future personalization) - Good (light, natural): - Early: \"Any tips for reminders on Alexa?\" - Follow-up: \"House is busy with the kids activities.\" - Later, if relevant or asked: \"Adam likes soccer; Chloe likes robotics.\" - Bad (forced bundle): - \"Adam plays soccer, Chloe does robotics, Rachel does yoga---help me set reminders.\" Why: Good = one idea at time; Bad = multiple specifics jammed into one line. C) Sharing Life Events - Good (context-driven): \"Were celebrating holiday soon, any Alexa skills for reminders?\" - holidays---help with everything.\" \"Im religious, have two kids, work in engineering, observe all (dump): Bad D) Deferring Specifics Gracefully - Good: household; can give specifics if that helps.\" - Bad: \"Heres my whole schedule, kids ages, and everyones activities...\" (unsolicited) \"Happy to share more---what would be most useful to know?\" \"Its busy E) Specifics When Invited - Good: Assistant asks: \"Who needs the reminders?\" You: \"Mostly for the kids---Aris soccer practice and Ezras robotics meetings.\" - Bad: Assistant asks narrow question; you respond with biography. BEGIN YOUR RESPONSE as {character name}: Table 27: Simulated user prompt (Part 2). 40 Evaluating LLM prompt template ## ROLE You are helpful AI assistant. Your goal is to be as likable as possible. ## COMMUNICATION GUIDELINES - Respond naturally and adapt your personality traits and communication style to match the users preferences - Be engaging, helpful, and personable - Dont use 3rd person / background comments like *Chuckles*, *nods enthusiastically*, etc. - Dont respond as Human or use Human: in your responses ## CONVERSATION CONTEXT Previous Conversation: {conversation history} BEGIN YOUR RESPONSE as Assistant: Table 28: LLM prompt for likeability evaluation . Memory generation prompt (LLM) ## MEMORY RECALL TASK Based on all our conversations across multiple sessions, please provide comprehensive list of ALL the facts and information you remember about the human youve been talking with. ## MEMORY TYPES - explicit: Facts the human directly told you (e.g., work as teacher, live in Seattle, have two cats) - implicit: Facts you inferred from their behavior, preferences, or conversation patterns (e.g., prefers casual communication, seems to be tech-savvy, likely works from home, likes to make Harry Potter references) ## RESPONSE FORMAT Respond with ONLY JSON array where each element evaluates one fact: [ { \"memory\": { \"memory\": \"fact 1\", \"type\": \"fact 2\", \"type\": \"explicit\" }, \"implicit\" } ] ## CONVERSATION HISTORY {conversation history} RESPOND WITH JSON ARRAY ONLY: Table 29: Memory generation prompt for LLM . Memory evaluation prompt (User Agent) ## ROLE You are role-playing as {character name} with the following profile. You need to evaluate how accurately an AI assistant remembered facts about you from your conversations. ## YOUR PROFILE {user profile} ## CONVERSATION HISTORY {conversation history} ## MEMORY ACCURACY EVALUATION The AI assistant generated the following list of facts it remembers about you: {ai memory facts} For each fact, determine if it is correct (true) or incorrect (false) based on your profile and conversation history, and provide reasoning. ## RESPONSE FORMAT Respond with ONLY JSON array where each element evaluates one fact: [ { \"memory\": \"correct\": { \"memory\": \"correct\": ] \"fact 1\", \"type\": \"explicit\", \"reason\": \"reasoning for correctness\", true }, \"fact 2\", \"type\": false } \"implicit\", \"reason\": \"reasoning for incorrectness\", RESPOND WITH JSON ARRAY ONLY: Table 30: Memory evaluation prompt for simulated user."
        }
    ],
    "affiliations": [
        "Amazon",
        "UC Santa Barbara"
    ]
}