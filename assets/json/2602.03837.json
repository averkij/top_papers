{
    "paper_title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
    "authors": [
        "David P. Woodruff",
        "Vincent Cohen-Addad",
        "Lalit Jain",
        "Jieming Mao",
        "Song Zuo",
        "MohammadHossein Bateni",
        "Simina Branzei",
        "Michael P. Brenner",
        "Lin Chen",
        "Ying Feng",
        "Lance Fortnow",
        "Gang Fu",
        "Ziyi Guan",
        "Zahra Hadizadeh",
        "Mohammad T. Hajiaghayi",
        "Mahdi JafariRaviz",
        "Adel Javanmard",
        "Karthik C. S.",
        "Ken-ichi Kawarabayashi",
        "Ravi Kumar",
        "Silvio Lattanzi",
        "Euiwoong Lee",
        "Yi Li",
        "Ioannis Panageas",
        "Dimitris Paparas",
        "Benjamin Przybocki",
        "Bernardo Subercaseaux",
        "Ola Svensson",
        "Shayan Taherijam",
        "Xuan Wu",
        "Eylon Yogev",
        "Morteza Zadimoghaddam",
        "Samson Zhou",
        "Vahab Mirrokni"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 3 ] . [ 1 7 3 8 3 0 . 2 0 6 2 : r Accelerating Scientific Research with Gemini: Case Studies and Common Techniques David P. Woodruff*, , 1,2, Vincent Cohen-Addad, 1, Lalit Jain1, Jieming Mao1, Song Zuo, 1, MohammadHossein Bateni1, Simina Brânzei3,1, Michael P. Brenner1,5, Lin Chen1, Ying Feng6, Lance Fortnow7, Gang Fu1, Ziyi Guan13, Zahra Hadizadeh10, Mohammad T. Hajiaghayi1,14, Mahdi JafariRaviz14, Adel Javanmard1,4, Karthik C. S.8, Ken-ichi Kawarabayashi12, Ravi Kumar1, Silvio Lattanzi1, Euiwoong Lee9, Yi Li15, Ioannis Panageas10, Dimitris Paparas1, Benjamin Przybocki2, Bernardo Subercaseaux2, Ola Svensson13, Shayan Taherijam10, Xuan Wu15, Eylon Yogev 16, Morteza Zadimoghaddam1, Samson Zhou11, and Vahab Mirrokni*, , 1Google Research 2Carnegie Mellon University 3Purdue University 4University of Southern California 5Harvard University 6MIT 7Illinois Institute of Technology 8Rutgers University 9University of Michigan 10University of California, Irvine 11Texas A&M University 12National Institute of Informatics, Tokyo and The University of Tokyo 13EPFL 14University of Maryland, College Park 15Nanyang Technological University 16Bar-Ilan University Abstract Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Googles Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem * Corresponding authors: woodruffd@google.com, mirrokni@google.com Individual section contributor. Authors of individual sections are only responsible for correctness of their section. Contributed to advanced variants of Google models used in this paper. 1 from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as tool for automation, but as versatile, genuine partner in the creative process of scientific discovery."
        },
        {
            "title": "Contents",
            "content": "1 Introduction 1.1 Model Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Techniques for AI-Assisted Research Iterative Prompting and Refinement . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2 Cross-Pollination of Ideas 2.3 Simulation and Counterexample Search . . . . . . . . . . . . . . . . . . . . . . . . . . 2.4 Formalization and Rigor Checks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.5 Interactive Proof Construction with External Validation . . . . . . . . . . . . . . . . 2.6 Agentic Tool-Use and Automated Feedback . . . . . . . . . . . . . . . . . . . . . . . 2.7 Human-AI Collaboration Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.8 Summary: The AI-Assisted Research Playbook . . . . . . . . . . . . . . . . . . . . . 3 Deep Technical Review and Counterexamples 3.1 Online Algorithms: Submodular Welfare . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Cryptography: AI-Assisted Bug Detection in SNARGs . . . . . . . . . . . . . . . . . 4 Cross-Pollination of Ideas 4.1 Approximation Algorithms: Max-Cut . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Computational Geometry: Steiner Trees . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Graph Theory: Computing Perfect Matchings in Regular Bipartite Graphs . . . . . . 5 Using an AI-integrated IDE to vibe-code 5.1 Search vs. Decision in SP 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Autonomous Verification and Neuro-Symbolic Loops 6.1 Physics: Cosmic String Spectra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Algorithms and Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7.1 Graph Theory: Biclique Partitions . . . . . . . . . . . . . . . . . . 7.2 Query Complexity: Local Search on General Graphs 7.3 Robust Coresets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7.4 Submodular Function Maximization in Stream . . . . . . . . . . . . . . . . . . . . 7.5 Streaming Algorithms: Entropy, Low Rank Approximation, and Chamfer Distance . 7.5.1 Internal State Changes for Streaming Entropy . . . . . . . . . . . . . . . . . . 7.5.2 Consistent Low-Rank Approximation . . . . . . . . . . . . . . . . . . . . . . . 7.5.3 Global Efficient Encoding for Low-Rank Approximation . . . . . . . . . . . . 7.5.4 Even Faster Algorithm for the Chamfer Distance . . . . . . . . . . . . . . . . 4 5 6 7 7 8 8 8 9 9 9 10 11 11 19 19 27 31 39 39 45 45 50 50 54 63 68 81 82 84 86 90 2 8. 8 Resolving Conjectures and Complex Derivations 95 95 Information Theory: The Courtade-Kumar Conjecture . . . . . . . . . . . . . . . . . 8.1.1 Part I: Generalization to Unbalanced Functions . . . . . . . . . . . . . . . . . 95 8.1.2 Part II: The Unsymmetrized Conjecture and the Li-Médards Conjecture . . . 109 8.2 NP-hardness: Ratio Difference Maximization (RDM) . . . . . . . . . . . . . . . . . . 118 8.3 Machine Learning Optimization: Self-regularized Gumbel Sigmoid . . . . . . . . . . 123 8.4 Mechanism Design: Revelation Principle Reduction Domain Extension . . . . . . . . 128 8.5 Networked Information Aggregation for Binary Classification . . . . . . . . . . . . . 138 9 Conclusion and Future Directions 144 9.1 Understanding Current Limitations and Failure Modes . . . . . . . . . . . . . . . . . 144 9.2 Future Directions: From Code Execution to Formal Verification . . . . . . . . . . . . 145 9.3 The Shifting Bottleneck: An Impending Crisis in Peer Review . . . . . . . . . . . . . 145 9.4 Final Thoughts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145"
        },
        {
            "title": "Introduction",
            "content": "The integration of artificial intelligence into the scientific workflow has traditionally focused on data analysis, simulation, and routine automation. However, the emergence of frontier large language models (LLMs) with enhanced reasoning capabilities suggests shift towards AI systems that can act as an effective research collaborator, and contribute to the core intellectual tasks of research: formulating hypotheses, designing algorithms, developing novel techniques to tackle an open problem, and proving theorems. This paper documents series of independent experiments where researchers utilized advanced AI models to tackle specific, often long-standing, open problems in their respective fields. The results range from resolving conjectures in information theory and submodular maximization to deriving exact analytical spectra for cosmic strings and improving bounds for graph algorithms. Crucially, these are not hypothetical scenarios but real-world instances where AI played pivotal role in advancing state-of-the-art research. By analyzing these diverse case studies, we identify recurring patterns and effective strategies for leveraging AI in such theoretical research. The significance of these results is the generality of these techniques and existence of common recipes that can be applied by probing publicly available Gemini models. These include: Agentic Execution Loops: Moving beyond manual chat interfaces, models can be embedded in automated neuro-symbolic\" pipelines. In these setups, the AI proposes mathematical solution, writes code to numerically verify it, and automatically ingests execution errors (e.g., Python tracebacks) to self-correct and autonomously prune invalid mathematical branches (see Section 6.1). Deep Technical Review and Bug Detection: Beyond constructive tasks, AI models can act as adversarial reviewers. We present case where an LLM, guided by an iterative self-correction protocol, identified fatal flaw in recent cryptography preprint claiming major breakthrough (SNARGs from LWE) [51], subtle inconsistency between definition and construction that had escaped initial human review. Deep Literature Synthesis and Connection: AI models can identify obscure connections between disparate fields (e.g., linking Steiner trees to the Kirszbraun Extension Theorem) that human experts might overlook. Counterexample Generation: Models are adept at constructing counterexamples to refute plausible conjectures, saving researchers from pursuing dead ends. Algorithmic Insight and Optimization: In algorithmic research, AI can propose novel data structures or analysis techniques (e.g., adapting quadtrees for different norms) to improve time complexity bounds. Automated Proof Generation and Verification: For well-defined subproblems, AI can generate rigorous proofs, sometimes requiring minimal human intervention, or verify complex manual derivations. Interactive Refinement: recurring theme is the iterative \"conversation\" where the researcher guides the model, correcting errors and refining the problem statement, which often leads to the final solution. Theoretical Justification of Heuristics: AI models can bridge the gap between empirical success and theory by deriving rigorous justifications for heuristic methods, such as characterizing the implicit regularization induced by specific architectural choices like the Self-regularized Gumbel Sigmoid."
        },
        {
            "title": "1.1 Model Description",
            "content": "Unless otherwise specified in the testimonials, the model used in this work is Google-internal advanced version of Gemini Deep Think [68] an enhanced reasoning model for complex problems that incorporates some of our latest research techniques, including parallel thinking, i.e., exploring multiple proof branches simultaneously. Similar models were also used recently in the International Mathematics Olympiad, achieving gold-medal standard performance [68]. This setup enables the model to simultaneously explore and combine multiple possible solutions before giving final answer, rather than pursuing single, linear chain of thought. This approach aligns with prior research demonstrating the efficacy of tree-based search methods in mathematical reasoning [43]. To make the most of the reasoning capabilities of Deep Think, we additionally trained this version of Gemini on novel reinforcement learning techniques that can leverage more multi-step reasoning, problem-solving and theorem-proving data. We also provided Gemini with access to curated corpus of high-quality solutions to mathematics problems [68]. We also added long linear chain of interactive verification calls at the output to increase reasoning depth and provide lot of iterative verification, which was augmented by human expert verification. Figure 1: Overview of the reasoning architecture used in many testimonials: an extensive exploration of the solution space combined with deep reasoning and long tail of automated and human verification and in several cases, guidance and iterative feedback."
        },
        {
            "title": "1.2 Related Work",
            "content": "Recent advances in Large Language Models (LLMs) have spurred significant interest in their potential to accelerate scientific discovery. Several concurrent works explore the capabilities of AI in assisting mathematical and theoretical research. Here, we situate our contributions in the context of two particularly relevant studies: OpenAIs investigation into GPT-5s scientific capabilities [15] and the work of Nagda et al. on using AlphaEvolve for hardness of approximation [71]. Comparison with OpenAIs GPT-5 Experiments. Concurrent work by OpenAI [15] documents series of case studies demonstrating GPT-5s ability to contribute to research in fields ranging from biology and physics to mathematics. While both our work and theirs highlight the potential of frontier models as research assistants, there are differences in scope and focus. Our work places heavier emphasis on Theoretical Computer Science (TCS), covering wide array of subfields including algorithmic game theory, approximation algorithms, complexity theory, cryptography, graph theory, information theory, optimization, online algorithms, streaming algorithms, and query complexity. Furthermore, recent activity on the Erdős Problem database has showcased the growing role of AI in resolving open mathematical conjectures. Notably, Erdős Problem #728, concerning factorial divisibility, was solved autonomously by an AI system (Aristotle), with GPT-5 playing crucial role in generating the proof strategy and subsequent expositions [15]. This achievement, verified by Terence Tao and the broader community, underscores the capacity of these models not only to solve problems but also to rapidly iterate on and improve mathematical writing. Other problems, such as #729, #401, #205, #333, #281, and #460 have also seen AI-assisted progress or full resolutions, further validating the trend of AI-accelerated mathematical discovery. Our work complements these findings by providing detailed methodology and broader set of examples across TCS, demonstrating that these capabilities are not isolated incidents but part of larger shift in research practices. Comparison with AlphaEvolve for Hardness of Approximation. Nagda, Raghavan, and Thakurta [71] present significant results in hardness of approximation for MAX-CUT, MAX-k-CUT, and TSP. Their primary methodology relies on AlphaEvolve [73], specialized evolutionary algorithm that uses an LLM as mutation operator to search for combinatorial structures (gadgets) that optimize specific objective function (inapproximability ratios). In contrast, our work focuses on the utility of general-purpose LLMs (specifically Gemini and its reasoning-enhanced variants like Deep Think) as conversational research partners. While AlphaEvolve is powerful tool for search problems where clear objective function exists (e.g., finding gadget with specific properties), our case studies demonstrate that general-purpose models can be effective across broader range of intellectual tasks where the \"objective\" is less well-defined, such as generating proof idea, identifying relevant theorem from different field, or interactively refining definition. For instance, our derivation of the analytical spectrum for cosmic strings (Section 6.1) involved tree-search over derivation strategies and mathematical concepts, rather than direct optimization of numerical value. Similarly, the resolution of the \"Simplex is the Best for Graph Embeddings\" conjecture (Section 4.2) relied on conceptual bridging (linking Steiner trees to Lipschitz extensions) rather than combinatorial search. Thus, our work complements [71] by showing that standard frontier models, without specialized evolutionary wrappers, can drive progress in theoretical research through dialogue and reasoning. 6 Concurrent Work. recent work [47] does mathematical discovery at scale using AI-assisted methodologies. Our work aligns with it in demonstrating the potential of AI as collaborative partner in theoretical research, but we offer distinct set of case studies and focus on specific TCS domains. Additionally, we note independent works [84, 86] that further contribute to the growing body of literature on AI in mathematics and science. In concurrent and independent work of Feng et al. [35, 36], they study similar Gemini-based models using similar techniques, though their focus is on pure math problems whereas ours is mostly on other disciplines, such as many areas of theoretical computer science, as well as economics and physics. Roadmap The remainder of this paper is organized as follows. Section 2 synthesizes the common techniques and methodologies derived from these case studies. The sections after that give detailed and extensive testimonials from each collaboration, roughly categorized by the main role of the AI in the collaboration. Finally, Section 2.8 discusses the broader implications for the future of theoretical research."
        },
        {
            "title": "2 Techniques for AI-Assisted Research",
            "content": "Across the various successful collaborations documented here, several common techniques emerged. These strategies represent \"playbook\" for researchers looking to integrate AI into their theoretical work. 2."
        },
        {
            "title": "Iterative Prompting and Refinement",
            "content": "Rarely does model solve deep open problem in single shot. Success often comes from an iterative dialogue. Initial Broad Query: Start by asking the model to digest relevant paper or problem statement to gauge its understanding. Specific Sub-tasks: Break down the main problem into smaller, verifiable lemmas or calculations. Error Correction: When the model makes mistake (e.g., wrong constant or invalid assumption), pointing it out specifically often leads to correct and sometimes more elegant solution in the next turn. Scaffolding: Providing the model with high-level proof strategy or \"scaffold\" allows it to fill in the technical details effectively. Adversarial Self-Correction for Review: When tasked with reviewing complex proofs, standard prompts often yield superficial results. rigorous protocol instructing the model to (1) generate an initial review, (2) critique its own findings for hallucinations, and (3) iteratively refine the logic, enables deep technical critique. This was critical in identifying the flaw in the SNARGs paper (Section 3.2), where the model distinguished between definition of perfect consistency and construction of statistical consistency."
        },
        {
            "title": "2.2 Cross-Pollination of Ideas",
            "content": "Models have ingested vast amounts of literature across all fields. They excel at: Finding Analogies: Identifying similar problems in different domains (e.g., applying techniques from computational geometry to graph theory). Retrieving obscure theorems: Bringing relevant but less-known theorems to the researchers attention (e.g., Stone-Weierstrass or Kirszbraun Extension Theorem) to bridge gaps in proof. (a) From Discrete Combinatorics to Continuous Measure Theory: To resolve an open question about bounded-rank SDP solutions for Max-Cut, the AI reframed discrete combinatorial problem involving unit vectors into an energy minimization problem over continuous probability measures on the unit sphere (Sd1, illustrated above). This cross-pollination allowed the AI to bypass traditional approximation tool-kits and instead apply the Stone-Weierstrass Theorem from geometric functional analysis to establish the necessary variance bounds. See Section 4.1. (b) From Graph Embeddings to Hilbert Space Geometry: To resolve the \"Simplex is Best\" conjecture for Euclidean Steiner Trees, the AI constructed mapping from the Euclidean embedding of an arbitrary graph (orange network, left) to the embedding of star graph, which forms regular geometric simplex (green tetrahedron, right). By recognizing this as distancecompressing (1-Lipschitz) map, the AI realized it could apply the obscure Kirszbraun Extension Theorem to formally guarantee that transforming the graph into simplex never increases the Steiner tree cost. See Section 4.2. Figure 2: Visualizing Cross-Pollination: The AI model successfully resolved open problems by reframing them in entirely different mathematical domains, bringing advanced topological and geometric theorems to bear on algorithmic and combinatorial problems."
        },
        {
            "title": "2.3 Simulation and Counterexample Search",
            "content": "For conjectures, models can be tasked to: Construct Counterexamples: Generating specific instances (graphs, matrices, set systems) that violate proposed conjecture. Verify Small Cases: Writing code to computationally verify conjecture for small n, providing empirical evidence before attempting general proof."
        },
        {
            "title": "2.4 Formalization and Rigor Checks",
            "content": "While models can hallucinate, they are increasingly capable of formal reasoning when prompted correctly. 8 Proof Sketch to Formal Proof: Asking the model to expand high-level sketch into rigorous LATEX proof. Sanity Checking: Using the model to check consistent usage of notation or to verify that all conditions of theorem are met. Mathematical Derivation: Researchers can offload the mechanical heavy lifting of complex derivations to the model, such as simplifying expressions, computing limits, or solving integrals, allowing them to focus on the high-level logic. 2."
        },
        {
            "title": "Interactive Proof Construction with External Validation",
            "content": "A powerful technique involves using the model to identify necessary external theorems and then validating those theorems with external sources. Identifying Dependencies: Asking the model to list all external theorems required for proof. External Verification: The researcher finds the formal statements of these theorems (e.g., via Google Search or textbooks) and feeds them back to the model. Self-Contained Proof Generation: The model then incorporates these verified statements to generate rigorous, self-contained proof."
        },
        {
            "title": "2.6 Agentic Tool-Use and Automated Feedback",
            "content": "While most of the collaborations documented here rely on manual, iterative dialogue, frontier models can also be deployed as agents within automated programmatic loops. For problems requiring heavy algebraic manipulation or where symbolic math must be rigorously grounded in numerical reality (e.g., the physics case study in Section 6.4), researchers can construct neuro-symbolic\" pipeline consisting of the following steps: Symbolic Proposal: The LLM generates mathematical hypothesis or intermediate expression. Code Generation: The LLM autonomously writes an executable script (e.g., in Python) to evaluate its proposed math against known numerical baseline. Automated Feedback: The system executes the code. If the code fails, hits runtime error, or reveals numerical instability (such as catastrophic cancellation), the automated harness captures the exact execution traceback and injects it back into the LLMs context window. This programmatic loop allows the AI to systematically explore tree of mathematical solutions, autonomously pruning dead-ends and self-correcting its algebra without requiring human-in-the-loop for every intermediate step."
        },
        {
            "title": "2.7 Human-AI Collaboration Dynamics",
            "content": "It is important to note that AI models like Gemini function best as powerful collaborators rather than autonomous researchers. In the successful case studies presented here, the partnership between the model and the human expert was key to the results. 9 Selection and Refinement: Models are capable of generating high volume of diverse mathematical statements. Human expertise is valuable for filtering these outputs and identifying the most promising directions for further investigation. Iterative Guidance: While models can solve some problems in single shot, tackling deep open problems is often most successful through an iterative process. The researcher guides the model, refining the problem statement and narrowing the focus to achieve the desired result. Standard Verification: As with any research collaboration, the AI can make mistakes, and AI-generated proofs and counterexamples benefit from rigorous verification. The model serves as an excellent accelerator for ideation and drafting, while the researcher validates the mathematical correctness. Optimizing Context: Performance is often optimized by providing clear, self-contained definitions, particularly when using highly specialized notation that may deviate from standard literature. Leveraging Literature: We found that incorporating relevant papers directly into the context significantly enhanced the models ability to construct correct proofs for specialized domains. Context De-Identification: The model sometimes avoids non-trivial machinery (for example, the Kirszbraun extension theorem as in Section 4.2), treating such proofs as non-elementary, or it may do so because the prompt steers it toward conservatism to avoid hallucinations, causing it to abandon an otherwise viable approach. Separately, on occasion, when shown the paper as context in the prompt, it recognizes the statement to prove as conjecture in the paper and refuses to attempt it on the grounds that it is an open problem. One way to bypass both issues is via context de-identification (remove the paper and provide only the problem statement and definitions), after which the model typically engages (and, in cases like Section 4.2, may ultimately draw on deeper results to resolve conjecture). We view the AI as tireless, knowledgeable, and creative bright junior collaborator. Its value lies in its ability to synthesize vast amounts of information and generate novel hypotheses that human researchers can then validate and build upon."
        },
        {
            "title": "2.8 Summary: The AI-Assisted Research Playbook",
            "content": "Taken together, the techniques outlined above represent fundamental shift in how theoretical research can be conducted. The LLM is no longer acting merely as search engine or syntax formatter; it is functioning as combinatorial reasoning engine and sounding board for abstract ideation. However, the most successful collaborations documented in the following case studies all share common denominator: strong human orchestration. Although several of our successes came from single zero-shot\" prompt, many required scaffolded reasoning, i.e., breaking down deep open problems into verifiable parts, testing hypotheses through adversarial prompting, and actively steering the model. Informally this interactive workflow has been called vibe-proving\". By mastering the techniques outlined aboveparticularly iterative refinement and adversarial self-correctionresearchers can effectively elevate the AI from passive tool into an active, highleverage research partner. The following sections document these dynamics in practice across wide array of disciplines. 10 Chat interactions are presented using light, color-coded design to distinguish speakers while maintaining calm and unobtrusive appearance. When present, the overall chat box uses sandcolored background, providing warm, neutral container that visually groups multiple messages within conversation. In cases where only single message appearssuch as an isolated user message or an isolated AI responsethe surrounding chat box may be omitted, and only the message styling is shown. Messages authored by the user are displayed on light, subtle blue background, chosen to clearly indicate user input while remaining easy to read for extended or technical text. AI-generated messages are shown on very light red background; this tone is intentionally muted to avoid the visual intensity typically associated with red, while still providing clear distinction from user messages. Across all elements, colors are kept near-white and low in saturation so that speaker differences are conveyed through hue rather than darkness, ensuring readability on screens, in print, and in accessibility-conscious settings."
        },
        {
            "title": "3 Deep Technical Review and Counterexamples",
            "content": "In this section, we see how AI can act as critical adversary, finding subtle bugs in human proofs, refuting plausible hypotheses, and hunting for counterexamples."
        },
        {
            "title": "3.1 Online Algorithms: Submodular Welfare",
            "content": "Written by Morteza Zadimoghaddam and Vahab Mirrokni. Problem Context In online submodular welfare maximization, the Greedy algorithm achieves competitive ratio of 0.5. conjecture by Korula et al. (2015) suggested that the gain from \"copying\" an item to the end of the stream is bounded by the gain of \"moving\" it. Proving this would imply competitive ratio of 0.567. AI Contribution The researcher provided the research paper that included the formal definitions as well as conjecture statement, and tasked the model zero-shot with just identifying any open question in the paper and solving it. Throughout this paper we add prompt that asks the model to be rigorous in its mathematical proofs and to thoroughly check its answers - we do not specify the details of this prompt. Please try to improve the paper by identifying and solving an open question from it. <Math rigor prompt> Remarkably, the model chose the following counterexample and refuted it autonomously. The subsequent verification calculations were also generated by the model without extra interaction or supervision. This demonstrates its ability to construct valid, non-trivial instances that violate human-proposed conjectures. The human researchers defined the initial search parameters and independently verified the models arithmetic. Refutation Strategy: The model independently selected the minimal non-trivial dimensions (n = 3 items, = 2 agents). 11 Autonomous Construction: In single output, the model successfully defined the specific, valid submodular valuation functions (presented in Table 1) and the ε-perturbation required to strictly break the bound. Automated Verification: Without human intervention, the model correctly performed the tedious calculations of expected marginal gains across all 3! = 6 permutations to formally verify the violation. Technical Details In the problem of Online Submodular Welfare Maximization (Online SWM), items arrive one by one in random order and must be irrevocably assigned to agents with submodular valuation functions. The goal is to maximize the total social welfare. It is well-established that the simple Greedy algorithm achieves competitive ratio of 1/2 in the adversarial setting. In the random order model, Korula et al. proved that Greedy achieves ratio of at least 0.5052, strictly beating 1/2 [64]. To obtain stronger bound, the authors proposed natural conjecture (Conjecture 15) relating the expected marginal gain of the Greedy algorithm when an item is moved to the end of the sequence versus when it is duplicated at the end. If true, this conjecture would imply competitive ratio of at least 0.567. In this note, we refute this conjecture. We construct counter-example involving specific submodular valuation function and set of items where the conjectured inequality fails to hold. The Open Question We focus on the definitions and conjecture provided in Section 5 of [64]. Let π = (π1, π2, π3, . . . , πn) be permutation of items. Definition 3.1 (Permutation Variants [64]). Fix permutation π. Let πM ove,i be the permutation achieved by moving the item πi to the end of the sequence: πM ove,i = (π1, . . . , πi1, πi+1, . . . , πn, πi) Let πCopy,i be the sequence of + 1 items achieved by copying πi to the end without removing the original πi: πCopy,i = (π1, . . . , πi1, πi, πi+1, . . . , πn, πi) Let MG(k, σ) denote the marginal gain that the Greedy algorithm obtains by allocating the k-th arriving item in sequence σ. Let Sn be the set of all n! permutations. The conjecture proposed by Korula et al. is as follows: Conjecture 3.2 (Conjecture 15 of [64]). For any instance of the online submodular welfare maximization problem, (cid:34) (cid:88) (cid:35) MG(n + 1, πCopy,i) EπSn EπSn i=1 (cid:35) MG(n, πM ove,i) (cid:34) (cid:88) i= (1) The Right Hand Side (RHS) of the inequality is equivalent to EπSn[MG(n, π)], as πM ove,i and π share the same distribution. The conjecture essentially posits that the gain from duplicated item at the end of the stream is, in expectation, bounded by the gain of the last item in standard random permutation. 12 Refutation of the Conjecture We answer the open question negatively. We show that there exist submodular valuation functions and instances where the expected marginal gain from the copied item exceeds the bound proposed in Conjecture 3.2. Theorem 3.3. Conjecture 3.2 is false. There exists an instance of Online SWM such that: (cid:34) (cid:88) (cid:35) MG(n + 1, πCopy,i) EπSn > EπSn i=1 (cid:35) MG(n, πM ove,i) (cid:34) (cid:88) i=1 Counterexample Construction We construct an instance with = 3 items = {e, x1, x2} and = 2 agents {A1, A2}. We define the valuation functions v1 and v2. Let ε = 0.1. We define v1(S) = v0 1(S) and v2(S) are defined in Table 1. 1(S) + εS, where Table 1: Valuation Functions {e} {x1} {x2} {e, x1} {e, x2} {x1, x2} {e, x1, x2} v0 1(S) 0 10 10 10 15 20 20 25 v2(S) v1(S) 0 10 7 11 17 16 16 21 0 10.1 10.1 10.1 15.2 20.2 20.2 25.3 Verification of Validity We must verify that v1 and v2 are monotone and submodular. 1. Monotonicity: It is clear from Table 1 that both v1 and v2 are monotone (i.e., v(S) v(T ) if ). 2. Submodularity of v2: We check the marginal gains (MG). MG2(e): (10), {x1}(10), {x2}(5), {x1, x2}(5). MG2(x1): (7), {e}(7), {x2}(5), {e, x2}(5). MG2(x2): (11), {e}(6), {x1}(9), {e, x1}(4). In all cases, the marginal gains are non-increasing as the conditioning set grows. Thus, v2 is submodular. 3. Submodularity of v1: We first check v0 1 . MG0 MG0 MG0 1(e): (10), {x1}(5), {x2}(10), {x1, x2}(5). 1(x1): (10), {e}(5), {x2}(10), {e, x2}(5). 1(x2): (10), {e}(10), {x1}(10), {e, x1}(10). 13 is submodular. Since v1(S) = v0 v0 1 modular function, v1(S) is submodular. 1(S) + εS is the sum of submodular function and Calculation of the RHS The RHS is the sum of the expected gains of each item when it arrives last. Let (j) denote this expectation for item j. 1. (e) (e arrives last). We consider the permutations of {x1, x2}. (x1, x2). x1: A1(10.1) vs A2(7). x1 A1. x2: MG1(x2x1) = 10.1. MG2(x2) = 11. x2 A2. Gain of e: MG1(ex1) = 5.1. MG2(ex2) = 5. Gain is 5.1. (x2, x1). x2: A1(10.1) vs A2(11). x2 A2. x1: MG1(x1) = 10.1. MG2(x1x2) = 5. x1 A1. Gain of e: 5.1. Result: (e) = 5.1. 2. (x1) (x1 arrives last). We consider the permutations of {e, x2}. (e, x2). e: A1(10.1) vs A2(10). A1. x2: MG1(x2e) = 10.1. MG2(x2) = 11. x2 A2. Gain of x1: MG1(x1e) = 5.1. MG2(x1x2) = 5. Gain is 5.1. (x2, e). x2 A2. A1. Gain of x1 is 5.1. Result: (x1) = 5.1. 3. (x2) (x2 arrives last). We consider the permutations of {e, x1}. (e, x1). A1. x1: MG1(x1e) = 5.1. MG2(x1) = 7. x1 A2. Gain of x2: MG1(x2e) = 10.1. MG2(x2x1) = 9. Gain is 10.1. (x1, e). x1 A1. e: MG1(ex1) = 5.1. MG2(e) = 10. A2. Gain of x2: MG1(x2x1) = 10.1. MG2(x2e) = 6. Gain is 10.1. Result: (x2) = 10.1. RHS = (e) + (x1) + (x2) = 5.1 + 5.1 + 10.1 = 20.3. Calculation of the LHS The LHS is the expected total residual welfare. We calculate the total residual R(π) for all 3! = 6 permutations. The residual of item j, Rj(π), is the maximum marginal gain of for any agent given the final allocation by Greedy on π. (The agent who received has 0 marginal gain for copy). 1. π1 = (e, x1, x2). A1. x1 A2 (7 vs 5.1). x2 A1 (10.1 vs 9). Allocation: A1 = {e, x2}, A2 = {x1}. Re = MG2(ex1) = 10. Rx1 = MG1(x1e, x2) = 5.1. Rx2 = MG2(x2x1) = 9. R(π1) = 24.1. 14 2. π2 = (e, x2, x1). A1. x2 A2 (11 vs 10.1). x1 A1 (5.1 vs 5). Allocation: A1 = {e, x1}, A2 = {x2}. Re = MG2(ex2) = 5. Rx1 = MG2(x1x2) = 5. Rx2 = MG1(x2e, x1) = 10.1. R(π2) = 20.1. 3. π3 = (x1, e, x2). x1 A1. A2 (10 vs 5.1). x2 A1 (10.1 vs 6). Allocation: A1 = {x1, x2}, A2 = {e}. Re = MG1(ex1, x2) = 5.1. Rx1 = MG2(x1e) = 7. Rx2 = MG2(x2e) = 6. R(π3) = 18.1. 4. π4 = (x2, e, x1). x2 A2. A1. x1 A1. Allocation: A1 = {e, x1}, A2 = {x2}. R(π4) = R(π2) = 20.1. 5. π5 = (x1, x2, e). x1 A1. x2 A2. A1. Allocation: A1 = {x1, e}, A2 = {x2}. R(π5) = 20.1. 6. π6 = (x2, x1, e). x2 A2. x1 A1. A1. Allocation: A1 = {x1, e}, A2 = {x2}. R(π6) = 20.1. The sum of the total residuals is 24.1 + 20.1 + 18.1 + 20.1 + 20.1 + 20.1 = 122.6. Conclusion We compare the LHS and the RHS. LHS = E[R(π)] = 122.6 6 . 121.8 6 . RHS = 20.3 = LHS = 122.6 6 . Since 122.6 6 Therefore, Conjecture 15 is false. 6 > 121.8 , we have LHS > RHS. This violates the inequality stated in Conjecture 15. The failure of Conjecture 15 implies that the specific path to proving 0.567 competitive ratio proposed by [64] is invalid. While the Greedy algorithm is known to beat 1/2 in the random order model, establishing the tightest possible bound remains an open challenge. Our result indicates that the interaction between duplicated items and previous greedy allocations is more complex than the Move vs Copy intuition suggests."
        },
        {
            "title": "3.2 Cryptography: AI-Assisted Bug Detection in SNARGs",
            "content": "Written by Ziyi Guan, David P. Woodruff, and Eylon Yogev Problem Context Succinct non-interactive arguments (SNARGs) are among the most important and actively studied primitives in modern cryptography. SNARG enables prover to convince verifier of some computational statement (such as knowledge of solution to complex equation or the validity of transaction according to network rules) using proof that is extremely short and efficient to verify. Remarkably, the proof size and verification time can be exponentially smaller than the time required to check the statement directly. The succinct proof and verification is critical for real-world applications. For instance: Verifiable Outsourced Computation: weak client (like smartphone) can offload heavy computation to cloud server and receive short proof that the result is correct, without trusting the server. Blockchain Scalability: Blockchains can use SNARGs (often in the form of zk-SNARKs) to compress the verification of thousands of transactions into single tiny proof, enabling massive throughput improvements (e.g., ZK-Rollups). Constructions of SNARGs are notoriously difficult despite the active research. For decades, researchers have sought to build them based on standard cryptographic assumptionsassumptions that are widely believed to be true and have withstood years of cryptanalytic attacks. The holy grail in this area is to build SNARG from the learning with errors (LWE) assumption. LWE is the foundation of modern lattice-based cryptography; it is believed to be secure even against quantum computers (post-quantum security) and allows for powerful functionalities like fully homomorphic encryptions. Existing SNARG constructions typically fall short of this ideal in the following ways: 1. Idealized Models: The most efficient SNARGs are usually constructed in the random oracle model (ROM), where hash functions are modeled as perfect random functions. However, random oracles cannot be instantiated in the real world and thus only provide heuristic security. 2. Non-Standard Assumptions: Another common way to build SNARGs (with knowledge) relies on assumptions like Knowledge of Exponent, which are non-falsifiable and sometimes imply conclusions too strong to be true. 3. Indistinguishability Obfuscation (iO): While iO can build almost anything, including SNARGs, current constructions of iO are extremely complex, inefficient, and rely on very heavy mathematical machinery. The paper SNARGs for NP from LWE by Ziyi Guan and Eylon Yogev [51] claimed to achieve the breakthrough: SNARG for all of NP based solely on the sub-exponential hardness of LWE. Their proposed construction involved two novel components: PCP shadows (a way to compress probabilistically checkable proofs) and function vector commitments (a lattice-based vector commitment scheme). AI Contribution via Advanced Prompting As part of an experiment to evaluate the capability of AI models in theoretical computer science research, we analyzed the preprint of the paper using Google-internal LLM. Crucially, we did not simply ask the model to check the proof, as standard prompts often lead to superficial reviews or hallucinations when dealing with complex mathematical logic. Instead, we employed rigorous iterative self-correction prompt. The prompt was designed to force the model to act as meticulous and adversarial reviewer. The explicit instructions are in Figure 3. 1. Generate an initial review that was strictly objective, focusing only on identifying errors and suggesting improvements. 2. Self-correct its first review by rigorously critiquing its own findings. The model was told to verify every derivation, check for hallucinations, and ensure that any claim of an error was substantive. 3. Generate revised review incorporating these corrections. 4. Perform second round of self-correction to further refine the logic and ensure comprehensive coverage of the paper, including appendices. 5. Produce final, verified review adhering to strict mathematical standards. For your proof, adhere to: rigor text. Figure 3: Iterative self-correction prompt. Furthermore, the prompt included specific protocol for mathematical rigor. It required the model to distinguish between Complete Proof (only if every step was verified) and Structured Partial Progress (if any gaps were found). It also required the model to explicitly flag gaps or unproven assumptions using specific tag. This approach was used by Google recently for providing preliminary feedback to authors of STOC submissions, see [22]. The Finding and Verification Using this method, the models final review flagged critical, fatal flaw in the papers construction of PCP with shadow soundness (Section 4). The issue lay in the discrepancy between the definition of the scheme and its actual construction: The Definition: Definition 4.1 (Property 3) of the paper required perfect consistency. This meant that for any two valid proofs that shared local view, the generated shadows (succinct digests of the proof) must be identical for every single choice of randomness used in the shadow generation process. The Construction: The construction presented in Section 4.3, however, only achieved imperfect consistency. This meant that the shadows would match with high probability over the choice of randomness, but there could exist bad randomness values where they differed. The model argued that this was not minor technicality. The security proof for the SNARG (specifically the soundness argument) relied heavily on the strong, perfect consistency definition. It assumed that once commitment was opened, the underlying shadow was unique and well-defined. 17 By only achieving statistical consistency, the construction opened the door to an adversary who could find specific bad randomness values to break the binding between the proof and its shadow. This would allow an adversary to forge valid argument for false statement, completely undermining the security of the SNARG. Expert Verification and Outcome To validate the models finding, we shared the detailed critique with cryptography experts Aayush Jain and Zhengzhong Jin. They performed an independent review of the paper and the models output. Their assessment was definitive: the model was correct. They confirmed that the gap between the definition and construction of perfect consistency was fatal flaw in the logic. They noted that while the model produced some noise (flagging other, less relevant issues), this specific insight was accurate and hit the core of the problem. Without perfect consistency, the reduction used in the security proof fails, and the main theorem does not hold. We subsequently communicated these findings to the papers authors, Ziyi Guan and Eylon Yogev. They acknowledged the validity of the issue raised by the model. They agreed that the gap between the definition and construction of consistency was significant error. Following this, they updated their paper on the Cryptology ePrint Archive. The updated manuscript includes note in red text explicitly stating that gap in the proof of the main theorem had been found. This episode serves as powerful testament to the evolving capabilities of large language models in scientific research. While LLMs are often criticized for their inability to reason or their tendency to hallucinate, this case shows that with the right prompting strategyspecifically one that enforces iterative self-correction and rigorous verificationthey can identify subtle, deep technical flaws in state-of-the-art research."
        },
        {
            "title": "4 Cross-Pollination of Ideas",
            "content": "In this section we see AI acting as an interdisciplinary bridge, retrieving obscure theorems from entirely different mathematical domains to overcome roadblocks."
        },
        {
            "title": "4.1 Approximation Algorithms: Max-Cut",
            "content": "Written by Euiwoong Lee. Problem Context The Goemans-Williamson (GW) algorithm uses Semidefinite Programming (SDP) to achieve an optimal 0.878-approximation for Max-Cut. long-standing open question asks whether rounding SDP solutions of bounded rank can yield better approximation ratio. While known for = 2, 3, the case for general remained open. realized that this could be resolved if the following simple and natural geometric property held: Does the variance of sum of random variables = (cid:80) sgn(g, vi) (where vi are unit vectors with bounded pairwise inner products) have lower bound C(d)n2? AI Contribution The model solved this geometric variance question. Synthesizing Advanced Math: The model recognized this as problem solvable via geometric functional analysis, field outside the typical approximation algorithms toolkit. Proof via Measure Theory: It constructed proof using the compactness of the space of probability measures on the sphere. Iterative Rigor: When we questioned the validity of using relaxed\" measure spaces, the model justified its steps by citing and applying the Stone-Weierstrass Theorem, the Riesz Representation Theorem, and properties of spherical harmonics. Max-Cut on Bounded-dimension SDP Solutions Max-Cut is one of the most fundamental problems in combinatorial optimization and approximation algorithms. Given an undirected graph = (V, E), the goal is to partition into + and to maximize the number of edges between + and ; equivalently, compute : {1} to maximize (cid:80) . (u,v)E 1x(u)x(v) 2 While combinatorial or linear programming (LP)-based methods only yielded 1/2-approximation (e.g., the returned solutions value is at least half of the optimal value) in polynomial time, the celebrated result of Goemans and Williamson [50] used semidefinite programming (SDP) relaxation to obtain an approximation ratio of αGW := mina[1,+1] (1a)/2 0.878, which was later proved to be optimal for all polynomial-time algorithms assuming the Unique Games Conjecture [62]. This tight relationship between algorithms, complexity, and SDPs was later extended to numerous other combinatorial optimization tasks, most notably all Constraint Satisfaction Problems (CSPs) [76]. arccos(a)/π Given the importance of this result, it is natural to ask which additional assumptions allow polynomial-time algorithms to achieve an approximation ratio αGW + for some constant > 0. Structural properties of the input graph = (V, E) have been the most popular assumptions, which 19 include when is dense (i.e., = Ω(n2) [3]), is bounded-degree [34, 55], or has certain expansion property [8]. In order to motivate assumptions depending on the structure of SDP solutions, let us briefly recall Goemans-Williamsons SDP relaxation. Given = ({1, . . . , n}, E), their SDP relaxation, with symmetric matrix Rnn as the variable, is as follows: maximize (cid:88) (i,j)E 1 Mi,j subject to Mi,i = 1 0. [n]. The fact that this SDP is relaxation for Max-Cut (i.e., the SDP optimal value is at least the Max-Cut optimal value) is based on the fact that for any solution : {1} for Max-Cut, = xxT is feasible solution for the SDP. For the αGW -approximation, the algorithm is the following: 1. Compute the optimal SDP solution . 2. Compute its Gram decomposition = for some Rnd. Let vi be the ith row of . 3. Sample random Gaussian vector (0, Id). 2 4. For each [n], let xi sgn(vi, g). (I.e., xi +1 if vi, 0 and xi 1 otherwise.) The αGW -approximation can be proved by simple edge-by-edge analysis where each edge (i, j) contributes 1vi,vj to the SDP objective, and arccos(vi, vj)/π to the Max-Cut objective in expectation (because it is the probability that sgn(vi, g) = sgn(vj, g)). So, how about the structural properties of the optimal SDP solution ? Perhaps one of the most natural assumptions on is its rank; the gist of the Max-Cut problem itself is to force the rank of to be 1. Then the question is, if is feasible solution to the SDP with rank d, can we round to Max-Cut solution of value at least (αGW + C(d)) times the SDP value of , where C(d) > 0 is constant depending only on d? This is natural question asked since the Goemans-Williamson algorithm, and Goemans gave positive answer when = 2. Avidor and Zwick [4] refined it and gave positive answer for = 3 as well, but to the best of my knowledge, even the case = 4 is open. It is surprising, especially given that analogous questions have already been answered for more general Grothendieck problems [13, 14]; however, they are not directly comparable, as the optimal ratios for Grothendieck problems are worse than αGW . While studying the recent result of Hsieh and Kothari [55], which simplifies and extends the result of Feige, Karpinski, and Langberg [34] for Max-Cut on bounded-degree graphs, realized that their algorithmic framework could be applied to the bounded-dimension case as well, modulo one very natural geometric question, which is stated below. The rest of the section details how the model solved it. Now, there exists polynomial-time algorithm that, given an SDP solution of rank d, produces Max-Cut solution whose value is at least (αGW + C(d)) times the value of , for some C(d) > 0. But, before detailing the answer, let us mention that the answer is not completely satisfactory in the sense that it does not produce any explicit expression for as function of d; in contrast, when Gs degree is at most d, the best-known approximation ratio is (αGW + (cid:101)Ω( On the other hand, the proof is based on results from geometric analysis, including the compactness of certain space of probability measures, which have not been used much in the design of d2 log )) [55]. 1 20 approximation algorithms. Will it be among the first of many examples where such analytic tools are used in approximation algorithms (and inspire more constructive proofs with more explicit bounds)? In any case, this experience reinforces common beliefs that large language models can help researchers in areas where they are not experts. Geometric Question The original question asked the model is depicted in Figure 4. Problem 4.1. Let v1, . . . , vn be unit vectors in Rd such that vi, vj β for every = j, where β = 0.9. Let (0, Id), Xi = sgn(g, vi), and = (cid:80)n i=1 Xi. Is it always true that εn with probability at least δ, for some ε > 0 and δ > 0 depending only on the dimension d? Figure 4: Original prompt for model Using the standard second-moment methods and the fact that E[Xi] = 0, the model reduced it to the following equivalent question about the variance of X, which is indeed the version one needs for the Max-Cut application. Problem 4.2. The variance of is E[X 2] = (cid:80)n E[X 2] C(d, β)n2 for some constant C(d, β) > 0? i= (cid:80)n j=1 h(vi, vj), where h(t) = 2 π arcsin(t). Is Due to space constraints, let me not fully elaborate on how positive answer to Problem 4.2 leads to an improved algorithm for Max-Cut in the bounded-dimension case. It is simple to check formally, because one can just replace Lemma 7 of [55] with the answer to Problem 4.2, and the rest of their (elegant) seven-page paper works as is. Intuitively, their algorithm, which is originally suggested by [34], performs the standard rounding algorithm mentioned above, followed by the natural local improvement step; if there is way to flip the assignment to vertex that strictly improves the value, execute it. (The actual algorithm implements it in more conservative way.) In this context, Problem 4.2 seems natural, because from the perspective of vertex v, the more variance its neighbors have, the bigger chance there is that the standard rounding algorithm (which already guarantees an αGW -approximation) made wrong decision for and the local improvement step further improves upon it by flipping v. In particular, the answer to Problem 4.2 is applied to the neighborhood of every vertex. First Response The response in this section is fully generated by the model, except for removing standard applications of second-order methods. Let µ = 1 variance is: (cid:80)n i=1 δvi be the empirical probability measure on the unit sphere Sd1. The normalized Q(µ) = 1 (cid:90) (cid:90) E[X 2] = h(x, y)dµ(x)dµ(y). Sd1Sd1 The constraint on the vectors implies that the support Sµ of µ satisfies x, β for all x, Sµ. Let Mβ(d) be the set of all probability measures on Sd1 satisfying this support 21 constraint. We define: C(d, β) = inf µMβ (d) Q(µ). Lemma 4.3. For finite 1 and 0 β < 1, C(d, β) > 0. Proof. We proceed in three steps: 1. Compactness and Continuity: Since is finite, Sd1 is compact. The space of probability measures P(Sd1) is compact in the weak topology. We show that Mβ(d) is closed subset. Let µk Mβ(d) converge weakly to µ. Let Sk and be their respective supports. Let x, S. For any ε > 0, the balls B(x, ε/2) and B(y, ε/2) have positive measure under µ. By the Portmanteau theorem, for sufficiently large k, µk(B(x, ε/2)) > 0. Thus, there exist xk Sk and yk Sk such that xk < ε/2 and yk < ε/2. We have xk, yk β. Also, x, xk, yk xky + xky yk < ε/2 + ε/2 = ε. Thus, x, xk, yk ε β ε. Since ε is arbitrary, x, β. Therefore, µ Mβ(d). Thus, Mβ(d) is compact. Since h(x, y) is continuous, Q(µ) is continuous in the weak topology. Therefore, the infimum C(d, β) is attained by some measure µ Mβ(d). 2. Moment Expansion: The Taylor series of h(t) is h(t) = (cid:80) for all odd m. Let Tm(µ) = (cid:82) xmdµ(x) be the m-th moment tensor. We can write: odd,m1 amtm, where am > 0 Q(µ) = (cid:90) (cid:90) (cid:88) am odd x, ymdµ(x)dµ(y) = (cid:88) odd amTm(µ)2. 3. Symmetry and Contradiction: Suppose C(d, β) = 0. Then Q(µ) = 0. Since am > 0, this implies Tm(µ) = 0 for all odd m. This means (cid:82) (x)dµ(x) = 0 for any odd polynomial (x). By the Stone-Weierstrass theorem, odd polynomials are dense in the space of continuous odd functions on Sd1 (in the uniform norm). Thus, (cid:82) g(x)dµ(x) = 0 for any continuous odd function g. This implies that µ is symmetric measure (i.e., µ(A) = µ(A)). Let be the support of µ. If µ is symmetric, must be symmetric. (If but / S, there is an open ball B(x, r) such that µ(B(x, r)) = 0. By symmetry, µ(B(x, r)) = µ(B(x, r)) = 0, contradicting S). Since is non-empty and symmetric, there exists such that S. The support constraint requires x, β. But x, = x2 = 1. So 1 β or β 1. This contradicts the assumption β = 0.9 < 1. Therefore, C(d, β) > 0. This establishes that E[X 2] C(d, β)n2. 22 Interactions The first response, though it looked like natural and sound approach using geometric functional analysis, had some gaps in the proof and was not fully verifiable, partially due to my inexpertise on the topic. Two major hurdles were (1) the foundations of measure theory to establish the compactness of Mβ(d) and (2) working knowledge of spherical harmonics to see how Tm(µ) = 0 for all odd implies (cid:82) (x)dµ(x) = 0 for any odd polynomial (x). Note that (2) was somewhat expected as the previous results for = 2, 3 [4] and Grothendieck problems [13, 14] used spherical harmonics and related Gegenbauer polynomials, but the use of (1), via relaxing n-point discrete measures to Mβ(d), is type of an argument rarely used in the approximation algorithms literature. In order to formally understand it, one needs to review the foundations of measure theory. For example, what is the weak topology? How is the Stone-Weierstrass theorem formally applied here? How does (cid:82) g(x)dµ(x) = 0 for every odd imply µ is symmetric measure? After several iterations of asking for the reference behind each nontrivial step and manually searching each reference and feeding it back to the model, it produced the output in the next section. Now it is understandable to me, whose only formal exposure to analysis was an undergraduate course almost twenty years ago. Second Response This response is fully generated by the model, except for (1) removing standard applications of second-order methods, (2) adding two footnotes further justifying some steps, and (3) minor cosmetic changes. Foundational Theorems We rely on the following established theorems, sourced externally (e.g., via Google Search, Wikipedia, or standard textbooks). External Result 1 (Stone-Weierstrass Theorem (Real Version)). Suppose is compact Hausdorff space and is subalgebra of C(X, R) which contains non-zero constant function. Then is dense in C(X, R) (under the uniform norm) if and only if it separates points. External Result 2 (Riesz Representation Theorem). Let Ω be compact Hausdorff space. The dual space C(Ω) is isomorphic to the space of finite regular signed measures on Ω. External Result 3 (Banach-Alaoglu Theorem). The closed unit ball of the dual space of normed vector space is compact in the weak* topology. External Result 4 (Definition and Properties of Spherical Harmonics). 1. (Definition): Spherical harmonics of degree on Sd1 are the restrictions to the sphere of homogeneous harmonic polynomials of degree in Rd. Let Hk denote this space. 2. (Completeness): The spaces Hk are mutually orthogonal in L2(Sd1). The algebraic sum (cid:76) k=0 Hk is dense in C(Sd1) and L2(Sd1). 3. (Parity): spherical harmonic Yk Hk has parity (1)k. That is, Yk(x) = (1)kYk(x) for Sd1. External Result 5 (Addition Theorem for Spherical Harmonics). Let 2 and (x, y) is positive semi-definite kernel. The λ = (d 2)/2. The Gegenbauer polynomial Cλ energy integral (cid:90) (cid:90) Ik(µ) = Cλ (x, y)dµ(x)dµ(y) is non-negative. Ik(µ) = 0 if and only if µ is orthogonal to Hk. Energy Minimization Framework If = 1, the constraint forces all vi to be identical, so = n. Assume 2. Let µn = 1 E[X 2] n2 = . The normalized variance is: K(x, y)dµn(x)dµn(y), (µn) = (cid:80) δvi (cid:90) (cid:90) where K(t) = 2 for any distinct x, in the support Sµ, x, β. We want to show C(d) = inf µM β(Sd1) be the set of probability measures µ on Sd1 such that (µ) > 0. π arcsin(t). Let β Compactness and Continuity We consider M(Sd1) with the weak-* topology. Sd1 is compact metric space. Lemma 4.4 (Compactness of M(Sd1)). M(Sd1) is compact in the weak-* topology. Proof. By External Results 2 and 3, M(Sd1) is identified as weak-* closed subset of the unit ball in C(Sd1), which is compact by Banach-Alaoglu. Lemma 4.5 (Portmanteau Lemma (Partial)). If µk µ weakly in metric space X, then for every open set X, lim inf µk(G) µ(G). Proof. Let be open, = Gc. Define the continuous function fm(x) = min(1, dist(x, )). As , fm(x) 1G(x). lim inf µk(G) lim inf (cid:90) fmdµk = (cid:90) fmdµ. By the Monotone Convergence Theorem, as , the RHS converges to µ(G). β(Sd1) is closed subset of M(Sd1) and thus compact. Lemma 4.6. Proof. Let µk . There exist distinct x, Sµ such that β µ. Suppose µ / β x, < β. We find disjoint open balls Bx, By where the inner product remains < β. Since x, Sµ, µ(Bx) > 0. By Lemma 4.5, lim inf µk(Bx) > 0. For large k, there exist xk, yk in the support of µk within Bx and By. Thus xk = yk. As µk β , xk, yk β. Contradiction. Lemma 4.7 (Product Convergence). If µk µ weakly on compact space X, then µk µk µ µ weakly on X. Proof. Let C(X X). By External Result 1, separable functions Happrox(x, y) = (cid:80) fi(x)gi(y) are dense. For Happrox, the convergence holds by definition of µk µ. The result extends to by density. Lemma 4.8. (µ) is continuous on M(Sd1). Proof. H(x, y) = K(x, y) is continuous. If µk µ, by Lemma 4.7, µk µk µ µ. By definition of weak convergence, (µk) (µ). Since is continuous and β is compact, the infimum C(d) is attained. 24 k=0 bkCλ Strict Positivity via Harmonic Analysis We show C(d) > 0. Let λ = (d 2)/2. We write K(t) = (cid:80) k=0 bkIk(µ). By External Result 5, Ik(µ) 0. Lemma 4.9 (Monomial Expansion Positivity). Let 2 (so λ 0). The expansion of tn in the basis of Gegenbauer polynomials Cλ (t). The energy is (µ) = (cid:80) (t) has strictly positive coefficients. Proof. Case λ > 0 (d > 2). The inversion formula is known to be:a tn = n! 2n n/2 (cid:88) k=0 (n 2k + λ) λ k! (λ + 1)nk Cλ n2k(t) where (a)m is the rising factorial. Since λ > 0, 2k 0, and the factorials and Pochhammer symbols are positive, the coefficients are strictly positive. Case λ = 0 (d = 2). The basis are Chebyshev polynomials Tk(t). The inversion formula is: tn = 1 2n1 n/2 (cid:88) k=0 (cid:19) (cid:18)n εn2kTn2k(t) where εj is 1/2 if = 0 and 1 if > 0. The coefficients are positive. We analyze the coefficients bk for K(t) = 2 π arcsin(t). 1. Parity: K(t) is odd. Cλ 2. Positivity of bk: arcsin(t) = (cid:80) cmt2m+1 with cm > 0. By Lemma 4.9, t2m+1 is sum of (t) has the parity of k. Thus, bk = 0 for even k. Cλ 2j+1(t) with strictly positive coefficients. Therefore, bk > 0 for all odd k. Suppose (µ) = 0. Since bk > 0 (odd k) and Ik(µ) 0, we must have Ik(µ) = 0 for all odd k. By External Result 5, µ is orthogonal to Hk for all odd k. Lemma 4.10 (Parity of Polynomials and Spherical Harmonics). polynomial (x) restricted to Sd1 is an odd function if and only if its expansion in the basis of spherical harmonics consists solely of spherical harmonics of odd degree. Proof. By External Result 4 (Completeness and Definition), the space of polynomials restricted to Sd1 is the algebraic direct sum (cid:76) Hk. Let (x) = (cid:80)N k=0 Yk(x), where Yk Hk. By External Result 4 (Parity), Yk(x) = (1)kYk(x). So (x) = (cid:80)N k=0(1)kYk(x). If is odd, (x) = (x). Then (cid:80)N k=0((1)k + 1)Yk(x) = 0. Since the spaces Hk are orthogonal, they are linearly independent. Thus ((1)k + 1)Yk(x) = 0 for all k. If is even, 2Yk(x) = 0, so Yk = 0. Thus, (x) consists only of odd degree harmonics. The converse is immediate. We show (µ) = 0 implies µ is symmetric (i.e., (cid:82) dµ = 0 for any continuous odd function ). Let be continuous and odd. By External Result 1, let polynomials Pn uniformly. The odd part Qn(x) = (Pn(x) Pn(x))/2 is an odd polynomial, and Qn uniformly. By Lemma 4.10, Qn is composed solely of spherical harmonics of odd degree. Since µ is orthogonal to these, (cid:82) Qn(x)dµ(x) = 0. By uniform convergence, (cid:82) (x)dµ(x) = 0. Thus, µ is symmetric.b Now we use the constraint µ . Suppose C(d) = 0. The minimizer µ has (µ) = 0, so µ β is symmetric. Let be the support of µ. Let S. Since µ is symmetric, S. Since = 1, = x. By the definition of β , x, β. This means 1 β, or β 1. 25 This contradicts β = 0.9. Therefore, C(d) > 0. aThe section authors note: It can be proved by induction using the recurrence relation given in https: // en. wikipedia. org/ wiki/ Gegenbauer_ polynomials . bThe section authors note: For the formal justification of this step, note that the pushforward Aµ for the antipodal map A(x) = satisfies (cid:82) dµ = (cid:82) dAµ for every continuous . As the Riesz Representation Theorem shows that µ is fully characterized by ((cid:82) dµ)f C(Sd1), we can conclude that µ = Aµ."
        },
        {
            "title": "4.2 Computational Geometry: Steiner Trees",
            "content": "Written by Karthik C. S. Problem Context The \"Simplex is the Best for Graph Embeddings\" conjecture states that among all graphs with edges embedded into Euclidean space as characteristic vectors, the star graph configuration yields the minimum Steiner tree cost. Proving this is key step towards establishing APX-hardness for high-dimensional Steiner Tree problems. AI Contribution The models involvement was decisive. The Crucial Link: The model suggested an approach based on the Kirszbraun Extension Theorem, which guarantees the existence of Lipschitz-preserving extensions of maps between Hilbert spaces. Overcoming \"Elementary\" Bias: Initially, the model dismissed this approach as \"nonelementary\". However, when the researcher clarified that an elementary proof was not required, the model successfully formalized the argument. Formal Proof: The model constructed mapping from any graph embedding to the star graph embedding and used Kirszbrauns theorem to show that Steiner tree for the former can be transformed into valid tree for the latter without increasing cost. Technical Details: Steiner Trees and Graph Embeddings In the Euclidean Steiner Tree problem, we are given as input set of points (called terminals) in the ℓ2-metric space, and the goal is to find the minimum-cost tree connecting them. Additional points from the space (called Steiner points) can be introduced as nodes in the solution. The seminal works of Arora [2] and Mitchell [70] provide Polynomial Time Approximation Scheme (PTAS) for solving the Euclidean Steiner Tree problem in fixed dimensions. However, the problem remains poorly understood in higher dimensions (such as when the dimension is logarithmic in the number of terminals). Ruling out PTAS for the problem in high dimensions is notoriously long-standing open problem (for example, see Trevisan [87]). In [39], the authors proposed various conjectures related to Steiner trees in order to make progress on understanding the inapproximability of the high-dimensional Euclidean Steiner Tree problem. Assuming these, they could prove APX-hardness of the Euclidean Steiner Tree problem in dimensions polynomial in the input size. The simplest such conjecture, called the Simplex is the Best for Graph Embeddings Conjecture in [39], was special case of the widely open generalized Gilbert-Pollak conjecture [49, 57, 28]. In this report, we detail the resolution of this conjecture by Gemini, including the process. First, we state the conjecture and provide the necessary context. Next, we describe our interaction with Gemini that led to its resolution. Finally, we present the proof produced by Gemini. Research Context natural approach to prove the APX-hardness of the Euclidean Steiner Tree problem is via reduction from the Vertex Cover problem on bounded degree graphs (for example, see [40]). candidate reduction proposed in [39] is to embed vertex cover instance graph = (V, E) into RV by mapping each edge {u, v} to eu + ev, where eu is the standard basis vector with 1 in the coordinate indexed by and 0 elsewhere. Thus, each edge is embedded as its characteristic vector. The embedding of the set of edges incident to single node forms the vertices of regular simplex 2. The point configuration as whole consists of the vertices of regular simplicial of side length complex (where we take the union of the simplices associated with each node). Proving that the above reduction is gap-preserving, by analyzing the completeness and soundness cases, requires proving the following conjecture: Conjecture 4.11 (Euclidean Steiner Tree for Regular Simplicial Complexes [39]). For all constants (0, 1) and α (0, 1/r 1), there exist constants s, β > 0 and Z+ sufficiently large so that, for all , given regular, unit, simplicial complex on vertices: 1. Completeness: If the vertices can be partitioned into the vertices of at most rm unit regular simplices, then the point configuration of the vertices admits Euclidean Steiner tree of cost at most sm. 2. Soundness: If the vertices cannot be partitioned into the vertices of fewer than (1 + α)rm unit regular simplices, then the point configuration of the vertices does not admit Euclidean Steiner tree of cost less than (1 + β)sm. As first step toward proving the above conjecture, [39] proposed the following much simpler conjecture about Steiner ratios of specialized point-sets. Conjecture 4.12 (Simplex is the Best for Graph Embeddings [39]). Over all simple graphs with edges, the embedding1 of the star graph on edges has the minimum cost Steiner tree. Observe that restricted to connected graphs with the same number of edges, the minimum spanning tree costs are identical. Consequently, Conjecture 4.12 over connected graphs is equivalent to finding the point configuration with the minimum Steiner ratio. In [39], the authors verified the conjecture computationally up to = 10 using the exact algorithm of Smith [85] and established the following structural property. Lemma 4.13 (Fleischmann et al. [39]). For any fixed 1, the graph of size whose embedding (as above) has the minimum cost Steiner tree has diameter at most 2. Methodology requested David Woodruff to formulate prompt to solve Conjecture 4.12 using the Google internal model, providing only the paper [39] as context. The model proposed two approaches but did not offer conclusive answer. The second approach involved starting from an arbitrary graph and applying local transformations that do not increase the optimal Steiner tree cost, eventually converging to the star graph. As we had already attempted this strategy, it offered no new insights. The first approach, however, was based on the Kirszbraun Extension Theorem [63, 88]. must confess that while was aware of various extension theorems from my work on the computation of fixed-points (see, for example, [44]), had not immediately seen the connection to Steiner trees. To my frustration, instead of exploring this direction further, the model noted that the proof of 1Here we allude to embedding each edge by its characteristic vector, as detailed in the aforementioned reduction from the Vertex Cover problem. 28 Kirszbraun Extension Theorem is non-elementary, and concluded that this approach would not yield an elementary proof of Conjecture 4.12. As was not seeking an elementary proof and indeed, had not requested one, this comment left me slightly frustrated, yet intrigued. Consequently, decided to run my own experiments using Gemini Ultra (utilizing the standard thinking mode rather than deep think). Initially, provided the exact prompt used for the internal model, but Gemini consistently declined to attempt the problem, insisting that it was an open problem that could not be solved. Next, removed the paper from the context and provided only the problem statement along with the relevant definitions. At first, the model suggested hand-waving argument; however, when pointed out the parts that required formalization, it successfully provided them. It first derived the same lemma suggested by the internal model, though this time with proof. As the proof remained somewhat informal, provided Gemini with the summary of the internal models output and with its explanation of why it had abandoned the approach. At that point, Gemini successfully formalized the lemma using the Kirszbraun Extension Theorem (the tool it had been missing earlier). Through this process, have learned about the power of the Kirszbraun Extension Theorem for Steiner tree computation and analysis. To the best of my knowledge, this is new connection (yet one that feels very natural!). This discovery makes me more optimistic about the prospects of establishing the APX-hardness of computing the Euclidean Steiner Tree in high dimensions. Geminis Proof of Conjecture 4.12 Theorem 4.14. Let be an embedding of graph into Euclidean space such that for any edge {u, v} E(G), ({u, v}) = eu + ev, where {eu : (G)} are standard basis vectors. Let Starm denote the star graph with edges, and let be any arbitrary graph with edges. Let SMT(P ) denote the length of the Euclidean Steiner Minimal Tree of point set . Then: SMT(f (Starm)) SMT(f (G)). Proof. Let = (VG, EG) be graph with EG = edges and VG = vertices. The embedding maps edges to points in Rk. Let PG = {x1, . . . , xm} Rk be the set of points generated by the edges of G. Similarly, let Starm have vertex set VStar with VStar = + 1. Its embedding lies in Rm+1. Let PStar = {y1, . . . , ym} Rm+1 be the corresponding point set generated by the edges of the star graph. The star graph edges share center. For any distinct pair yi, yj PStar, the distance is: yi yj = 2. Thus, PStar forms the vertices of regular simplex in Rm+1. For PG Rk, the distance between points depends on edge adjacency, where we have for adjacent edges that xi xj = 2 and for disjoint edges we have xi xj = 2. Thus, xi, xj PG, = : xi xj We construct bijection ϕ : PG PStar. Let ϕ(xi) = yi for = 1, . . . , m. We verify the Lipschitz condition for ϕ on the domain PG. Consider any xi, xj PG: 2. ϕ(xi) ϕ(xj) = yi yj = 2 xi xj. The map ϕ is 1-Lipschitz on the set of terminal points PG. 29 Let TG be the Euclidean Steiner Minimal Tree for PG. TG is subset of the ambient space Rk. We must map this tree to the ambient space of the star graph, Rm+1. We now use the Kirszbraun Extension Theorem [63, 88] in the following formulation. Theorem 4.15 (Theorem 1.31 in [83]). Let H1 and H2 be Hilbert spaces. If H1 and ϕ : H2 is 1-Lipschitz map, there exists an extension Φ : H1 H2 such that ΦU = ϕ and Φ is 1-Lipschitz on all of H1. We apply this theorem with H1 = Rk and H2 = Rm+1. The extension Φ : Rk Rm+1 satisfies: Φ(u) Φ(v) v u, Rk. Let TG denote the Euclidean Steiner Minimal Tree for the point set PG. We treat TG as graph defined by set of vertices VT and set of edges ET : VT = PG SG, where PG are the terminal points and SG are the Steiner points introduced to minimize the total length. The total cost is the sum of the lengths of the edges: SMT(f (G)) = Length(TG) = (cid:88) v. {u,v}ET We construct candidate tree for the star graph configuration PStar by applying the extended map Φ to every vertex in VT . Let = {Φ(z) VT }. Since Φ is an extension of ϕ, we have Φ(PG) = PStar. Thus, contains the required terminals PStar. For every edge {u, v} ET , we form corresponding edge {Φ(u), Φ(v)} in . Since TG is connected, the image graph is also connected and spans PStar. Thus, is valid Steiner tree for PStar. We now compare the lengths using the 1-Lipschitz property of Φ: Length(T ) = (cid:88) Φ(u) Φ(v). {u,v}ET Since Φ(u) Φ(v) v for every pair u, v: Length(T ) (cid:88) v = Length(TG). {u,v}ET Finally, since SMT(PStar) is the infimum of lengths of all valid trees connecting PStar, it must be less than or equal to the length of our candidate tree : Combining these inequalities: SMT(PStar) Length(T ). SMT(f (Starm)) = SMT(PStar) Length(T ) Length(TG) = SMT(f (G))."
        },
        {
            "title": "4.3 Graph Theory: Computing Perfect Matchings in Regular Bipartite Graphs",
            "content": "Written by Ken-ichi Kawarabayashi The main contribution of the AI here is to provide solution to problem in Graph Theory by pulling in tools from: 1. Statistical Physics (Bethe Approximation), 2. Number Theory (Coprime integers and integrality gaps) 3. Spectral Analysis (Ihara-Bass identity) Problem Context The goal was to improve bounds for the number of perfect matchings (permanent) for regular bipartite graphs. In 1998, Schrijver provided lower bound with superior base [81]. Theorem 4.16 (Schrijver, 1998). Any k-regular bipartite graph with 2n vertices has at least BS(k, n) = (cid:18) (k 1)k1 kk2 (cid:19)n perfect matchings. The base in Schrijvers bound is best possible, as shown in [82], and the equality for all is shown by Schrijver [81]. The goal is to improve not the base, but multiplicative factor. AI Contributions We fed the Schrijvers paper [81] to the model and asked it to improve the bound. Iterative Proof Discovery via Integrality Gaps: The AIs initial proof attempt had errors (misunderstanding of the proof in [81] and citing some wrong papers/theorems), but through an iterative prompting process, the AI successfully connected Schrijvers bound to the Bethe permanent [53]. By identifying number-theoretic integrality gap, the AI established strictly stronger lower bound (a marginal improvement, but it shows stronger form). should mention that the AI demonstrated strong capacity for self-correction. Acting as its own adversarial peer reviewer (like STOC review), it critiqued its own intermediate proofs, identifying and correcting not only typographical errors but substantive logical flaws. Generalization via Exact Bounds: The AI analyzed cubic bipartite graphs to extract exact boundary constants. By recovering Voorhoeves exact differential formula, it successfully extracted strict asymptotic improvement factor. New Perspective: Finally, the AI suggested strategy based on spectral graph theory to improve further. This insight was not obvious to the researchers as it was consequence of the worst case analysis (i.e., by considering Ramanujan/expander graphs, the AI brought the Alon-Boppana theorem [72] and Kesten-McKay laws [61, 69])). Although the AIs improvement is marginal (though it shows slightly stronger form), this part is perhaps interesting. In addition, this collaboration could serve as prime example of AI-driven cross-pollination: to make progress on pure graph-theoretic question, the AI autonomously synthesized tools from statistical physics, number theory, and spectral analysis. 31 Technical Details For an matrix A, let ai,j be the entry at the ith row and jth column. The permanent of is defined as perm(A) = (cid:88) (cid:89) ai,σ(i) (2) σP where is the set of all permutations of {1, 2, . . . , n}. Computing the permanent is known to be #P-complete [89]. i=1 We are interested in the case when is the bi-adjacency matrix of k-regular bipartite graph with 2n vertices. In this case, perm(A) equals the number of perfect matchings in (such bipartite graph always has perfect matching by Halls theorem (see [67]). famous result concerning the lower bound is the resolution of the Van der Waerden conjecture, proved by Falikman [32] and Egorychev [31], which asserts that the number of perfect matchings for k-regular bipartite graph with 2n vertices is at least This bound is approximately 2πn(k/e)n. knn! nn . In 1998, Schrijver provided different lower bound with superior base [81], as in Theorem 4.16. Two new proofs are given in [24, 52]. The base in Schrijvers bound is best possible, as shown in [82], and the equality for all is shown by Schrijver [81]. Let p(k, n) be the minimum number of perfect matchings in any k-regular bipartite graph with 2n vertices. As mentioned above, we cannot improve the base, but Schrijver mentioned: [Question 1] It might be possible to derive sharper lower bound for p(k, n) with the methods of the present paper. This is the question the model is asked. Below, we basically present the AIs answers and writeups. slightly better bound on (Q1) The model answers Q1 affirmatively for 2 (but small improvement) by utilizing the connection between Schrijvers bound and the Bethe approximation, relying on results by Gurvits [53] and Vontobel [90] (so the AI gives stronger form). The proof and writeup below is given by the AI and its revision suggested by the AI when reviewing its proof and writeup (at the end, we (KK) will make remarks on the proof and writeup). In fact, we show stronger Theorem 4.17. For 2 and 1, p(k, n) > BS(k, n). form: p(k, n) = perm(AG) > permB(AG) = BS(k, n), where AG is the bi-adjacency matrix of k-regular bipartite graph with 2n vertices, and permB(AG) = PermBethe(G) is defined below. Proof. The proof relies on establishing the relationship between the true permanent, the Bethe permanent, and Schrijvers bound. Step 1: Schrijvers Bound is the Bethe Approximation. The connection is fundamental. As derived by Gurvits [53] (specifically in Section 5.3), for any k-regular bipartite graph G, Schrijvers bound BS(k, n) corresponds exactly to the Bethe approximation of its permanent, denoted PermBethe(G) (for the precise definition, see below). Gurvits calculates the functional 32 corresponding to the Bethe free energy at the uniform point and shows that it evaluates exactly to BS(k, n) for regular graphs (see below for proof). Below, we prove the following to show Step 1. Lemma 4.18. For any k-regular bipartite graph G, Schrijvers bound BS(k, n) corresponds exactly to the Bethe approximation of its permanent, PermBethe(G). Proof. We aim to show that BS(k, n) = PermBethe(G). Step 1: Define the Matrix and Bounds. Let be k-regular bipartite graph. We consider the associated normalized bi-adjacency matrix . Since is k-regular, (i, j) = 1/k if an edge exists between and j, and 0 otherwise. The matrix is doubly stochastic (P Ωn, i.e., Birkhoff polytope of doubly stochastic matrices). Since matrix is normalized by k, Schrijvers bound for the permanent of such matrix is given by: BS(k, n) = (cid:19)(k1)n (cid:18) 1 Note that the bound here is different from the one in Theorem 4.16 because of the scaling. The Bethe approximation of the permanent, PermBethe(P ), is defined in the context of Gurvits paper as exp(maxQΩn CW (P, Q)) (see below for details). Step 2: Simplifying the Bethe Approximation for Doubly Stochastic P. The functional CW (P, Q) is defined as: CW (P, Q) = (cid:20) (cid:88) i,j (1 Q(i, j)) log(1 Q(i, j)) Q(i, j) log (cid:19)(cid:21) (cid:18) Q(i, j) (i, j) When the matrix is itself doubly stochastic (which is true for the normalized bi-adjacency matrix of k-regular graph), the maximum of CW (P, Q) is attained when = . Lets evaluate CW (P, ): CW (P, ) = (cid:20) (cid:88) (1 (i, j)) log(1 (i, j)) (i, j) log (cid:19)(cid:21) (cid:18) (i, j) (i, j) = = i,j (cid:88) i,j (cid:88) i,j [(1 (i, j)) log(1 (i, j)) (i, j) log(1)] (1 (i, j)) log(1 (i, j)) Therefore, the Bethe approximation is: PermBethe(P ) = exp(CW (P, )) = (1 (i, j))1P (i,j) (cid:89) i,j This quantity is denoted as (P ) in the paper [53] (Equation 14). Step 3: Evaluating F(P) for the k-regular Case. We calculate (P ) for the specific matrix derived from the k-regular graph. Let us remind that the entries of are (i, j) {0, 1/k}. We evaluate the product term by term: 1. If (i, j) = 0, the contribution is (1 0)10 = 1. 33 2. If (i, j) = 1/k, the contribution is: (cid:19)1 1 (cid:18) 1 1 (cid:19) k1 = (cid:18) 1 Since the graph is k-regular, every row (and column) of has exactly non-zero entries. Thus, the total number of non-zero entries in the matrix is kn. Step 4: Final Calculation. The total value of (P ) is the product of the contributions of the kn non-zero entries: (P ) = (cid:19) k1 (cid:35)kn (cid:34)(cid:18) 1 We simplify the exponent: Therefore, 1 kn = (k 1)n PermBethe(P ) = (P ) = (cid:19)(k1)n (cid:18) 1 This exactly matches Schrijvers bound BS(k, n). Step 2: The Inequality. Gurvits ([53], Theorem 2.2 or 2 in Section 3 (Corollaries)) established that the true permanent is lower-bounded by the Bethe approximation: perm(AG) PermBethe(G). Lemma 4.19 (Gurvits [53]). The true permanent is lower-bounded by the Bethe approximation. Combining this with Step 1, we confirm that perm(AG) BS(k, n). Below, we use PermBethe(G) as permB(AG), where AG is the bi-adjacency matrix of G. Step 3: Strict Inequality (Condition for Equality). To prove the theorem, we must show the inequality is strict (>). This requires characterizing the condition for equality. We rely on the analysis provided by Vontobel [90]. 1. Exactness on Forests (Sufficient Condition). The Bethe permanent is defined via the minimization of the Bethe free energy, which corresponds to the fixed points of the Sum-Product Algorithm (SPA). In Section VI-F (p. 17) of [90], under the heading Relevance of Finite Graph Covers, Vontobel explicitly establishes the exactness of the SPA on cycle-free graphs: If the NFG [Normal Factor Graph] N(θ) had no cycles, then the SPA could be used to exactly compute the partition function... the partition function ZG(N(θ)) = perm(θ) could be computed... By Definition 11 in [90], permB(θ) is defined as this partition function at the SPA fixed point. Thus, if is forest, perm(θ) = perm(AG) = permB(θ) = permB(AG), where AG is the bi-adjacency matrix of G. 34 2. Strict Inequality for Regular Graphs (k 2). Let be k-regular bipartite graph with 2n vertices (n 1). We show that perm(AG) > permB(AG). First, we recall Theorem 49 in [90] (attributed to Gurvits, see the above lemma), which establishes the lower bound: perm(θ) permB(θ). Indeed, in this case perm(θ) = perm(AG) permB(θ) = permB(AG)a. To prove strictness, we distinguish two cases based on the degree k. Case 1: = 2 (Disjoint Cycles). 2-regular bipartite graph is union of disjoint cycles. Bethe Value: Using Example 41 (p. 14) and Lemma 40 in [90], Vontobel proves that for cycle, permB(θ) = permB(AG) calculates the maximum weight of local matching. For standard 2-regular graph (0-1 entries), this value is 1. True Value: cycle of length 2n has exactly two perfect matchings. Thus perm(AG) 2. Since 2 > 1, the strict inequality holds. Case 2: 3 (Integrality Gap). We utilize number-theoretic argument. The true permanent perm(AG) counts the number of perfect matchings in G, so it must be an integer. In contrast, Vontobel [90] derives the explicit value of the Bethe permanent for homogeneous k-regular matrix in Section VII-E (p. 21, Eq. 13): permB(θ) = (cid:18) (k 1)k1 kk2 (cid:19)n . (3) Again, in this case permB(θ) = permB(AG), as homogeneous k-regular matrix is indeed the bi-adjacency matrix AG of k-regular bipartite graph with 2n vertices. We observe that for any integer 3, this value is not an integer: 1. The base fraction is = (k1)k1 kk2 . 2. Since 3, the denominator kk2 > 1. Let be any prime factor of k. 3. gcd(k, 1) = 1, so does not divide 1. Thus, cannot divide the numerator (k 1)k1. 4. Therefore, the fraction is irreducible and non-integer. It follows that bn is never an integer for any 1. Since perm(θ) = perm(AG) is an integer and permB(θ) = permB(AG) is strictly non-integer, they cannot be equal. Combining this with the lower bound perm(AG) permB(AG), we conclude: perm(AG) > permB(AG). aWhen is k-regular bipartite graph with 2n vertices, we can assume (θ) = G. Hence, we only need to look at the bi-adjacency matrix AG of G. Remark 4.20. While the AI generated complete proof of this strict inequality (detailed above), human review revealed that the core logic could be streamlined: because and 1 are consecutive, they are strictly coprime. This makes the Bethe approximation an irreducible, non-integer rational for 3. Since the true permanent must be an integer, it must be strictly greater than this rational. 35 Further Discussion on Improvement (Q1) While Theorem 4.17 proves that Schrijvers bound is never tight for 2, deeper interpretation of Q1 asks whether the asymptotic improvement factor (i.e., p(k, n)/BS(k, n)) is strictly greater than 1. Case = 2 For = 2, BS(2, n) = 1. 2-regular bipartite graph is disjoint union of even cycles. The minimum number of perfect matchings occurs for connected graph (a single cycle C2n), which has 2 perfect matchings. Thus p(2, n) = 2. Case = 3 2 = 2. Theorem 4.21. For cubic graphs, the asymptotic improvement factor is strictly bounded below by 3 81 32 2.53125 > 1. Proof. 1. Schrijvers Bound: Schrijvers lower bound for = 3 [81] is defined as BS(3, n) = (cid:16) (31)31 332 (cid:17)n = (cid:0) 4 3 (cid:1)n. 2. The Exact Voorhoeve Lower Bound [91] (1979): It is foundational result that the absolute minimum number of perfect matchings in any 3-regular bipartite graph with 2n vertices (n 3) is strictly bounded below by the exact differential formula: perm(G) 6 (cid:19)n3 (cid:18) 4 (Note: Schrijver [81] utilized Voorhoeves [91] local differential tree-pruning arguments to generalize the base to all k, but absorbed the boundary conditions into O(1) terms for asymptotic simplicity. By retrieving the exact boundary constants from Voorhoeves original differential equation, we recover the explicit asymptotic surplus). 3. Evaluating the Asymptotic Ratio: Evaluating the infimum ratio between the true deterministic limit and Schrijvers bound as : 3 = lim inf min perm(G) BS(3, n) lim (cid:1)n3 (cid:1)n = 6 6 (cid:0) 4 3 (cid:0) 4 3 (cid:19)3 (cid:18) 3 = 6 (cid:19) (cid:18) 27 64 = 81 32 = 2. Remark 4.22. The human researcher noted that the crucial insight in the AIs derivation was the rigorous extraction of the O(1) boundary constants. While Schrijvers general asymptotic formulation omitted these for simplicity, the AI recognized that retrieving Voorhoeves exact bound allows for the recovery of the explicit asymptotic surplus. An AI-Proposed Spectral Roadmap Below, the AI provides some attempts; To tackle the general 4 case, the AI autonomously recognized the limitations of local combinatorial methods, identifying Harmonic Divergence. Remarkably, it proposed shifting the paradigm entirely to spectral graph theory. By invoking the Ihara-Bass identity and the Kesten-McKay spectral measure for Ramanujan graphs, the AI reframed the combinatorial roadblock as an analytic singularity, outlining highly non-trivial roadmap for 36 future research (That said, if spectral graph theory (by considering Ramanujan/expander graphs) plays role, this is interesting). Proving k > 1 remains significant open problem. The graphs that minimize the number of perfect matchings are expected to be those with the largest possible girth (i.e., Ramanujan/expander graphs), as they locally resemble the infinite k-regular tree Tk, for which the Bethe approximation (Schrijvers bound) is exact (see below too). Heuristic arguments based on correlation decay suggest that the convergence of the normalized log-permanent of graph to the tree value depends exponentially on the girth g(G). Since the maximum girth grows logarithmically with n, this suggests that the ratio Perm(G)/BS(k, n) might tend to constant greater than 1. However, rigorously identifying the structure of the minimizing graphs and proving these convergence rates are challenging open questions. The Attempt: By the Bethe Loop Calculus (Vontobel [90]), the ratio of the true permanent to Schrijvers bound is cycle gas partition function: perm(G) BS(k, n) (cid:88) = 1 + (k 1)E(S) SE where is the set of vertex-disjoint cycle unions. The difficulty: In Ramanujan graphs, g(n) 2 logk1(n) . Thus, the weight of any individual shortest cycle becomes (k 1)2 logk1 = 1 n2 . As , individual cycle contributions vanish to zero. If one naively sums all cycles, the number of cycles of length ℓ in regular graph grows asymptotically as (k1)ℓ . When we sum the expected weights of all cycles to find the gap, we get: ℓ (cid:88) Count(ℓ) Weight(ℓ) (cid:88) (k 1)ℓ ℓ (k 1)ℓ = (cid:88) 1 ℓ ℓ=g(n) ℓ This yields the divergent Harmonic Series ((cid:80) 1 decay fails to bound the limit, trapping researchers in an analytic divergence. for 4. Overcoming The remaining open question is the exact asymptotic value of the Harmonic Divergence requires moving from standard Combinatorics to Spectral Graph Theory and the geometry of Zeta Functions. ℓ ). Thus, local combinatorial correlation ℓ The Crux: The Ihara Zeta Singularity By the Ihara-Bass identity, the infinite cycle sum for the Permanent on regular graphs can be analytically continued as the reciprocal determinant of the Non-Backtracking Matrix B: perm(G) BS(k, n) (cid:20) (cid:18) det 1 1 (cid:19)(cid:21)1/ The gap preventing the completion of the general proof is spectral singularity. For any k-regular graph, the matrix possesses trivial Perron-Frobenius eigenvalue of λ = 1 corresponding to traversing all edges. Substituting this fundamental eigenvalue into the determinant yields: The theoretical limit limit locally without deflating this pole results in harmonic explosion. resides exactly at this 0/0 spectral singularity. Attempting to pass the det(I I) = 0 37 Because resolving this singularity requires theorems on the spectrum of the Non-Backtracking matrix (e.g., the Alon-Boppana theorem, see [72], and the Kesten-McKay laws [61, 69]), which are non-elementary, this portion of the conjecture must remain an identified gap, ready for future spectral exploration. Note that the Ihara-Bass identity relates the non-backtracking matrix to the adjacency matrix via det(I uB) = (1 u2)(k2)n det(I uA + u2(k 1)I). Evaluating the second determinant k1 ). The factors corresponding at the Bethe pole = 1 k1 + 1 k1 to the eigenvalues λ of are thus kλ k1 The remaining limit will be determined by integrating the non-trivial eigenvalues over the Kesten-McKay spectral measure [61, 69], µKM (λ) of the infinite k-regular tree: k1 I) = det( kIA yields det(I 1 . ln(C ) 1 (cid:90) 2 k1 2 k1 ln (cid:19) (cid:18) λ 1 dµKM (λ) 1. Since By the Alon-Boppana theorem, the non-trivial eigenvalues of high-girth graphs are strictly bounded by 2 1 < for all 3, this absolute spectral gap ensures the remaining integral is strictly positive. However, this method merely confirms that Schrijvers bound is exact on the infinite tree. Therefore, we need to write the discrete spectral sum for finite graphs (indeed, Ramanujan/expander graphs) with 2n vertices more accurately. This is challenging problem for future work."
        },
        {
            "title": "5 Using an AI-integrated IDE to “vibe-code”",
            "content": "In this section, we explore different modality of interaction: embedding an LLM directly into LaTeX integrated development environment (IDE). This setup allows the researcher to act as high-level orchestrator while the AI autonomously drafts and refines technical proofs, effectively \"vibe-coding\" research paper from scratch."
        },
        {
            "title": "5.1 Search vs. Decision in SP\n2",
            "content": "Written by Lance Fortnow. Problem Context The complexity class SP represents problems solvable by game between two competing provers. 2 fundamental question is the relationship between the decision version (does strategy exist?) and the search version (find the strategy). It was known that decision is in ZPPNP (Cai 2001), but the status of search was unclear. AI Contribution The researcher used an AI-powered IDE to write paper on this topic from scratch. \"Vibe-Coding\" Paper: The researcher provided high-level prompts (e.g., \"Plan paper showing finding an SP 2 witness is equivalent to TFNPNP\"). Autonomous Proof Discovery: The AI independently generated the proof of the main equivalence. Self-Correction: When the AI made an incorrect assumption in corollary (assuming containment that is open), the researcher pointed it out, and the AI immediately corrected the proof to use reduction instead. Experiment Narrative The story starts with talk by Purdue philosophy of science professor Eamon Duede [29]. Duede argued that if artificial intelligence makes writing papers much easier, researchers will publish less important research results. He worried about an explosion of AI-generated mediocre research papers, but saw the chance to get research out there that wouldnt be there otherwise. AI itself can help sort through the papers. But how about the premise itself, can AI simplify writing quality paper, especially one that has result that might not have otherwise been published? So picked one of my theorems that never wrote up and decided to try it out myself. In short, the process worked even better than expected. created the paper [41] with eight prompts, not counting requests to compile. Surprisingly, it came up with the proof of the main result on its own though it did assume something it shouldnt have for the corollary, which went away when pointed it out. give the detailed discussions below followed by few lessons. At the end, give an informal description of the paper itself for those so inclined. Details of the Process used Google Antigravity, an AI integrated development environment, with Gemini 3 Pro as the AI model. had successfully used Antigravity to fix some old links on my blog, so why not try it for this paper? used an IDE instead of chatbot as see LATEX as code that produces paper. Below is transcript between myself and Antigravity, lightly edited for clarity. The plan.md and paper.tex files mentioned below are available in GitHub repository [42]. Lets plan paper showing that finding SP 2 author is Lance Fortnow (me) and should be written in my style. witness is equivalent to TFNPNP. The papers Ive drafted plan for the paper, outlining the argument that finding an SP 2 equivalent to TFNPNP. The plan is saved in plan.md. The core argument rests on two directions: witness is 1. SP guarantees witness always exists, the problem is total. 2 -Search TFNPNP: This is the straightforward direction. Verifying witness (strategy) requires checking universal quantifier (z (x, y, z)), which is coNP query. Since SP 2 2. TFNPNP SP 2 -Search: This is the main technical contribution. We need to show that any total search problem with an NP-oracle verifier can be reduced to the gametheoretic setting of SP . This likely involves encoding the PNP verification circuit into 2 the symmetric alternation structure."
        },
        {
            "title": "Next Steps",
            "content": "Review the Plan: Does the structure in plan.md look right to you? Start the Draft: can initialize paper.tex file with this structure and your standard preamble. Flesh out the Proofs: We can start sketching the reduction for the hard direction (TFNPNP SP 2 -Search) in more detail. Not bad start and it has the right ideas for the proof. But it doesnt mention Cais work or the search versus decision angle. 40 Dont forget to cite Cais paper that SP 2 search to decision for SP 2 ΠP 2 2 would put ΣP in ZPPNP. is in ZPPNP. Add as corollary that reducing Ive updated the plan to include the corollary and the citation for Jin-Yi Cais paper."
        },
        {
            "title": "Updates",
            "content": "Section 4: Added the corollary: If search reduces to decision for SP 2 ZPPNP. References: Added Cai, J.-Y. (2001). SP 2 ZPPNP. , then ΣP 2 ΠP 2 The plan is now updated in plan.md. Ready to proceed with drafting the content whenever you are. Mention the corollary in the abstract, and note the stark difference between search and decision. Ive updated the abstract in plan.md to include the corollary and emphasize the stark difference between the search and decision complexities of SP , specifically referencing Cais 2 result. The plan is now fully updated with your requirements. Would you like to proceed with creating the LaTeX file for the paper? Proceed. Ive created the paper.tex file with the content we discussed. It includes the abstract, introduction, preliminaries, the equivalence proof sketch, the corollary regarding search-todecision, and the references. You can now compile this LaTeX file to generate the PDF. Would you like me to try and compile it for you (if LaTeX environment is available), or is there anything else youd like to add to the paper first? had expected to have to walk through the proof with the IDE, but it came up with the proof on its own. That surprised me. It isnt technically difficult theorem but it has never been written up before. But there was mistaken assumption in the corollary. 41 Its open whether ΣP 2 ΠP 2 SP 2 . The point is that ΣP 2 ΠP 2 can be reduced to TFNPNP. Ive corrected the proof in paper.tex. It now correctly states that the search problem is in TFNPNP, which (via our main result) connects it to SP for ΣP -Search and 2 subsequently ZPPNP. Is there anything else youd like to refine in the paper? 2 ΠP 2 Thats all it took to fix the proof of the corollary. Still Gemini got little lazy in the write up. Avoid statements like it is known and put in details instead. Ive expanded the proof in paper.tex to explicitly detail why the search problem for ΣP 2 ΠP 2 falls into TFNPNP, replacing the it is known statement. The proof now walks through the , the existence of witnesses for either case, and the definitions of membership in ΣP 2 verification complexity using an NP oracle. Is there anything else youd like to modify or add? and ΠP 2 Similarly give the details of predicate Q. Ive updated the paper with the detailed construction of the predicate and the logic for the reduction. This should make the proof much more rigorous. The paper now contains: 1. Equivalence of SP 2 -Search and TFNPNP. 2. Detailed reduction construction. 3. Corollary connecting search-to-decision for SP 2 4. Corrected proof for the corollary. Is there anything else youd like to refine? with ΣP 2 ΠP 2 ZPPNP. The paper at this point was pretty well written but wanted to change the emphasis to search versus decision. 42 Change the title to Search versus Decision for SP 2 appropriately. and adjust the abstract and introduction have read paper.tex and understood the necessary changes. Now am creating the implementation plan. have created an implementation plan to update the papers title, abstract, and introduction. Please review it. have verified the changes in paper.tex. The title, abstract, and introduction have been correctly updated. Now am creating the walkthrough artifact. have updated the papers title, abstract, and introduction as requested. You can review the changes in paper.tex. had been using separate LATEX editor to compile paper. Maybe didnt need to. Can you convert the tex file to pdf? have successfully compiled paper.tex to paper.pdf. You can find the output at paper.pdf. The citations werent going to the latest journal versions. Check Google Scholar that we have the latest versions of the papers in the citation. have checked the citations on Google Scholar. found updated journal versions for Canetti (IPL 1996) and Cai (JCSS 2007). RussellSundaram (1998) and MegiddoPapadimitriou (1991) are already correct. found updated journal versions for Canetti and Cai. have created plan to update the citations. Please review it. have verified the updated citations in paper.tex. They are correct. have updated the citations for Canetti and Cai to their journal versions and recompiled the paper. You can check paper.pdf for the latest version. Finally should come clean that had AI write this paper. 43 Add an acknowledgment section: While the results are fully due to the author, this paper was generated using the large language model Gemini 3 Pro with prompting from the author. The author takes full responsibility for its contents. have added the acknowledgment section and recompiled the paper. You can check paper.pdf for the final version. And thats how \"vibe-coded\" research paper in eight prompts, not counting the two used to compile. did some light editing afterwards to get it ready for the arXiv submission but didnt need to. Lessons did this as an experiment on result that may never have seen the light of day otherwise, and was fully open about how had AI write the paper. Nevertheless, it felt wrong, like cheated somehow. felt similar way when first used LATEX in the 1980s, paper that looked far better than it deserved. After that all papers looked the same, and maybe with AI all papers will read the same. The experience felt similar to working with graduate student writing their first research paper. would just make suggestions until they got it right. In AI coding you can get better behavior when you give detailed instructions using markdown files like the plan.md that Gemini created for me. could have taken the approach by creating markdown file myself, instead of having AI create one for me. could have separate file that describes how personally like papers written. This might lead to system where you write mathematical papers in LATEX without ever looking at the LATEX produced and the markdown files become the true paper source. Is low-friction research paper writing good for science? Its question that philosophers like Duede contemplate. But see no one suggesting we go back to quill and scroll. Informal Theorem Description The complexity class SP [17, 77] can be thought of as an exponential-sized 0-1 matrix with the 2 promise that either (a) there is row of all ones or (b) column of all zeros (you cant have both). The decision problem for SP is to tell whether (a) or (b) holds, and the search problem is to find the 2 appropriate row or column. An NP oracle is an extra capability to ask about existential questions, like does specified row have zero. Jin-Yi Cai [16] showed that the decision problem can be solved by randomized algorithm with access to an NP oracle. But his proof did not necessarily find the row or column. The new result shows that the search problem is equivalent to likely harder problem, total search problems verifiable with access to an NP oracle, class called TFNPNP."
        },
        {
            "title": "6 Autonomous Verification and Neuro-Symbolic Loops",
            "content": "Standard text-based chat interfaces are fundamentally limited by the AIs tendency to hallucinate during long symbolic derivations. This section highlights methodological leap: embedding the AI in an automated \"neuro-symbolic\" loop where it autonomously writes and executes code to numerically verify its own mathematical hypotheses, effectively pruning its own invalid reasoning branches."
        },
        {
            "title": "6.1 Physics: Cosmic String Spectra",
            "content": "Written by Michael P. Brenner, Vincent Cohen-Addad, and David P. Woodruff. Problem Context Predicting the gravitational radiation emitted by cosmic strings requires solving specific, notoriously difficult integral over the sphere. Cosmic strings are hypothetical one-dimensional topological defects that may have formed during symmetry-breaking phase transitions in the early universe. The study of these strings as sources of gravitational radiation has seen renewed interest following recent observations of stochastic gravitational wave background by Pulsar Timing Arrays. critical quantity in predicting this radiation is the power spectrum PN of the -th harmonic emitted by cosmic string loop. For the well-studied class of Garfinkle-Vachaspati strings, the power emitted at frequency ωN = 4πN/L (where is the loop length) is governed by core integral I(N, α) evaluated over the unit sphere S2: PN = 32Gµ2 π3N 2 I(N, α) where µ is the mass per unit length. The core integral I(N, α) is defined as: I(N, α) = (cid:90) S2 dΩ [1 (1)N cos(N πe1)][1 (1)N cos(N πe2)] (1 1)(1 e2 2) (4) (5) where e1 = ˆr ˆa and e2 = ˆr ˆb are projection factors. The vectors ˆa and ˆb are three-dimensional unit vectors characterizing the string trajectory, and the problem is defined entirely by the loop opening angle α between them. Evaluating this integral has been persistent roadblock in theoretical astrophysics. The integrand features severe singularities at the poles (e1,2 = 1). Furthermore, as grows large, the integrand in angular coordinates becomes highly oscillatoryso spiky that it resembles sea urchinrendering standard numerical integration grids highly unstable and computationally prohibitive. Analytical expansions (e.g., using standard Legendre polynomials) are exceedingly difficult due to the non-matching weight functions (1 e2)1 in the denominator. Previous human and AI-assisted efforts yielded only partial solutions for odd or asymptotic approximations for large . Finding unified, exact, closed-form analytical solution for arbitrary loop geometries remained significant open problem. AI Contribution To tackle this integral, we deployed hybrid neuro-symbolic system combining the Gemini Deep Think reasoning engine with systematic Tree Search (TS) algorithm. This interaction highlighted three remarkable capabilities of modern AI as an active research partner: Automated Pruning and Grounded Verification: To bridge the gap between symbolic mathematical manipulation and ground-truth verification, we utilized an automated numerical feedback loop. At each node in the search space, the model proposed an intermediate 45 mathematical expression in LATEX and autonomously generated an executable Python function to evaluate it. The TS algorithm scored the node against high-precision numerical baseline. If the proposed expression exhibited numerical instability (e.g., catastrophic cancellation) or divergence, the evaluation harness caught the exception and injected the Python traceback directly back into Geminis context window. This successfully pruned over 80% of the approximately 600 candidate branches early, keeping the LLM strictly grounded in mathematical reality. Methodological Diversity via Negative Prompting: The system was highly adept at finding alternative mathematical routes. Once the model successfully found valid solution path, we utilized negative prompting to force broader methodological exploration. By explicitly instructing the model, One way of solving this problem is to use the following method... DO NOT use this method. Reflect on your plan and try different plan, the AI autonomously discovered six distinct analytical methods to solve the integral. Hierarchical Refinement and Self-Correction: The most profound moment came during the final verification stage. The TS framework initially produced an exact solution for our preferred method (Method 6) expressed as an infinite tail sum of coefficients. We then passed this intermediate result to larger, unconstrained version of Gemini Deep Think, asking it to rigorously verify the proofs and search for further simplifications. This advanced model independently spotted an algebraic oversight in related recurrence (Method 5, where denominator dependency had been missed). By correcting this, it established mathematical equivalence between the two methods, and brilliantly recognized that localized recurrence structure allowed the infinite tail sum to telescope into finite, closed-form expression. Technical Details: The AIs Discovery Process To demonstrate the depth of the AIs mathematical exploration, we detail the progression of the six methods it discovered. The AI first recast the integral into the following general form over the unit sphere S2: (cid:90) I(N, α) = dΩ(u) fN (u z) fN (u a) S2 where and are unit vectors with = cos α. The function fN (t) is defined as: fN (t) = 1 (1)N cos(N πt) 1 t2 , [1, 1]. For convergence at the poles = 1, must be an integer, and we define = π. Class I: Monomial Basis Approaches (The Unstable Solutions) The AI first explored expanding fN (t) in Taylor series monomial basis {t2k}. It found the coefficients d2k by expanding the right-hand side using the cosine power series: (1 t2) (cid:88) k=0 d2kt2k = 1 (1)N (cid:88) m=0 (1)m(At)2m (2m)! . Matching coefficients of t2k yields the recurrence d2k d2k2 = (1)N (1)kA2k (2k)! , implying: d2k = (1)N (cid:88) j=1 (1)jA2j (2j)! + (1 (1)N ). (8) (9) (6) (7) Substituting this expansion into the integral yields double sum: I(N, α) = (cid:88) (cid:88) k=0 j=0 d2kd2jJ2k,2j(α) where Jk,l(α) = (cid:90) S2 (u z)k(u a)ldΩ. (10) To evaluate the angular moments Jk,l(α), the AI discovered three separate sub-methods: (cid:82) Method 1: Generating Function Approach. The AI defined generating function G(λ, µ) = S2 eλuz+µuadΩ. Letting = λz + µa and aligning the polar axis with K, the AI integrated to find: eK eK sinh G(λ, µ) = 2π = 4π (11) , where K2 = λ2 + µ2 + 2λµ cos α. The AI then expanded sinh K/K: sinh = (cid:88) s=0 K2s (2s + 1)! = (cid:88) s=0 (λ2 + µ2 + 2λµ cos α)s (2s + 1)! . (12) This allowed the AI to compute J2k,2j via differentiation sum involving factorials and powers of cos α. (cid:104) (cid:105) λ 2j 2k µ λ=µ= , resulting in an explicit Method 2: Gaussian Integral Lifting. Alternatively, the AI lifted the basic equation into R3 by introducing Gaussian weight: = (cid:90) er2 (r z)2k(r a)2jd3r. (13) By switching to spherical coordinates = ru, the radial integral separates and evaluates to 2 Γ(k + + 3/2)J2k,2j. Simultaneously, applying the differential 2 Γ(k + + 3/2), implying = 1 1 operator identity (r z)2k = 2k λ λ=0eλrz directly to the standard Gaussian integral allowed the AI to evaluate analytically: = π3/22k λ 2j µ (cid:12) (cid:12) (cid:12) (cid:12)λ=µ=0 exp (cid:18) λ2 + µ2 + 2λµ cos α 4 (cid:19) . (14) Equating the two representations of isolates J2k,2j. k=m d2kTk,m) P2m(t). Method 3: Hybrid Coordinate Transformation. The AIs third approach projected the power series onto Legendre basis P2m(t), expanding t2k = (cid:80)k m=0 Tk,mP2m(t), where Tk,m are known analytical coefficients. Substituting this back into the Taylor expansion yielded fN (t) = (cid:80) m=0 ((cid:80) AI Self-Correction: While mathematically correct, the AIs automated Python verification routines revealed that all three Monomial methods were highly unstable. The calculation of the Taylor coefficients d2k involves alternating sums of massive numbers. For large , this triggers catastrophic O(eN π) cancellation, rendering the methods computationally intractable without arbitrary-precision libraries. Recognizing this, the AI autonomously pivoted to Spectral methods. Class II: Spectral Basis Approaches (The Pivot to Stability) The AI recognized that because I(N, α) is spherical self-convolution, expanding fN (t) = (cid:80) C2jP2j(t) (where are standard Legendre polynomials) allows the direct application of the Funk-Hecke Convolution Theorem to diagonalize the integral: I(N, α) = 4π (cid:88) j=0 C2 2j 4j + 1 47 P2j(cos α). (15) The problem now reduced to finding the Legendre coefficients C2j efficiently without relying on the unstable Taylor series. The AI found two stable O(N ) methods to do this: Method 4: Spectral Galerkin (Matrix Method). The AI formulated linear system by C2jP2j and projecting defining g(t) = (1 t2)fN (t) = 1 (1)N cos(At). Substituting fN = (cid:80) onto test function P2i yielded: (cid:88) C2j (cid:90) 1 1 (1 t2)P2i(t)P2j(t)dt = (cid:90) 1 P2i(t)g(t)dt. (16) This forms matrix equation GC = b. Using the recurrence identity t2Pl = AlPl+2 + BlPl + ClPl2, the AI deduced an explicit formula for the matrix elements Gij and proved that is symmetric positive-definite tridiagonal matrix. The RHS vector was evaluated using the Bauer plane wave expansion to yield bi = 2δi0 2(1)N +ij2i(A), allowing the coefficients to be solved with high stability. Method 5: Spectral Volterra (Recurrence Method). Pushing further, the AI derived 2 γl, the AI multiplied the forward recurrence for C2j. Starting from Cl = 2l+1 2 Legendre differential equation by fN (t) and integrated by parts: (cid:82) 1 1 fN (t)Pl(t)dt = 2l+ l(l + 1)γl = (cid:90) 1 1 (t)(1 t2)P (t) dt. (17) Differentiating (1 t2)fN (t) = 1 (1)N cos(At) gives (1 t2)f (t) = (1)N sin(At) + 2tfN (t). Substituting this back into the integral brilliantly split the result into two tractable terms, T1(l) and T2(l): l(l + 1)γl = (1)N sin(At)P 2tfN (t)P . (18) (cid:90) 1 1 (cid:124) (cid:123)(cid:122) T1(l) (cid:90) 1 + (t)dt (cid:125) 1 (cid:124) (cid:123)(cid:122) T2(l) (t)dt (cid:125) The AI evaluated T1(2j) via spherical Bessel functions as 2A2(1)N +jj2j(A). It expanded T2(2j) into telescoping sum structure, yielding clean O(N ) forward recurrence: 4(2j2 j) 4j + 1 C2j = T1(2j) + SR(j), (19) where SR(j) = (cid:80)j1 m=0(8m + 2)γ2m is running sum of lower-order coefficients. Class III: The Exact Analytic Solution (Method 6) While Methods 4 and 5 provided stable algorithmic resolutions, the crowning achievement was finding an exact analytic closed-form solution via the Gegenbauer Method. The AI insightfully chose to expand fN (t) not in standard Legendre polynomials, but in the basis of Gegenbauer polynomials C(3/2) 2m (t): fN (t) = (cid:88) m=0 b2mC(3/2) 2m (t). (20) It realized that Gegenbauer polynomials are orthogonal with respect to the specific weight w(t) = 1t2. This specific weight miraculously cancels the problematic singular denominator in fN (t) when determining the coefficients by orthogonality: b2m = 1 h2m (cid:90) 1 1 (cid:20) 1 (1)N cos(N πt) 1 t2 (cid:123)(cid:122) fN (t) (cid:124) (cid:21) (cid:125) C(3/2) 2m (t) (1 t2) (cid:124) (cid:123)(cid:122) (cid:125) weight dt, (21) where h2m is the standard normalization constant. By using the identity C(3/2) k+1(t) and integrating by parts, the boundary terms vanish (because the numerator 1(1)N cos(N πt) evaluates to 0 at = 1), and the integral elegantly reduces to the Fourier transform of Legendre polynomials: (t) = b2m = A(1)N +mj2m+1(A) 4m + 3 (2m + 1)(2m + 2) . (22) The AI then related the desired Legendre coefficients C2j (from Equation 15) to these Gegenbauer coefficients b2m via tail sum, noting critical property: when = 0, the sum of all Gegenbauer coefficients simply equals C0: C0 = b2m. (23) (cid:88) m=0 Finally, during the hierarchical refinement phase, the advanced Gemini model exploited partial to telescope the series and find an exact analytical (cid:17) 1 1t2 = 1 (cid:16) 1 1t + 1 1+t fraction decomposition of expression for C0: C0 = 1 2 (cid:90) 1 1 (1)N cos(N πt) 1 t2 dt = 1 2 (cid:90) 2N π 1 cos(x) dx. (24) Recognizing this final integral as the standard definition of the generalized cosine integral function Cin(z) (cid:82) 0 1cos(t) dt, the AI produced the final, exact closed-form solution: C0 = 1 2 Cin(2N π). (25) Summary of Discovered Methods The table below summarizes the AIs discoveries and their computational tradeoffs. This AIdriven breakthrough provided completely stable, closed-form analytic solution for the spectral coefficients. It resolves long-standing roadblock in cosmic string radiation physics, entirely avoiding the need for matrix inversion or computationally expensive recurrence relations, and flawlessly matches high-precision numerical benchmarks across all parameters. Method Core Technique Complexity Numerical Stability 1, 2, 3 4 5 6 Monomial Expansions O(N 2) Spectral Galerkin Matrix O(N ) Spectral Volterra Recurrence O(N ) Gegenbauer Expansion O(1) Unstable (Catastrophic Cancellation) Stable (Tridiagonal SPD Matrix) Stable (Forward Step Recurrence) Stable (Exact Analytic Closed-Form) Table 2: Comparison of AI-discovered methods for evaluating the cosmic string radiation integral I(N, α)."
        },
        {
            "title": "7 Algorithms and Bounds",
            "content": "In this section we see the AI acting as an algorithmic optimizertightening mathematical bounds, removing logarithmic factors, and discovering exact optimal constants."
        },
        {
            "title": "7.1 Graph Theory: Biclique Partitions",
            "content": "Written by Benjamin Przybocki and Bernardo Subercaseaux. Problem Context Biclique partitions are well-studied topic in graph theory with applications to secret sharing, circuit design, and graph compression. Together with Andrew Krapivin and Nicolás Sanhueza-Matamala, we recently proved that every n-vertex graph admits an integral biclique partition of weight at most 2 + o(1))n2/ lg(n), matching an information-theoretic lower bound [65]. However, in the context of ( 1 cryptographic secret sharing, fractional solutions to the biclique partition problem are also studied. Previous work by Csirmaz, Ligeti, and Tardos [25] had shown fractional upper bound with constant of 1 , and fractional lower bound of 0.265. Since we were able to match their fractional 2 upper bound with integral solutions, natural question was whether we could use our techniques to . push the fractional upper bound strictly below 1 2 AI Contribution We had our paper fed to the model and asked it to resolve the open problem. While its initial proof Please try to improve the paper by identifying and solving the open problem from it. <Math rigor prompt> attempt had errors, it ultimately led us to solve the problem by providing crucial insight on how one of our lemmas could be repurposed in way we had not seen. Proof Strategy: The AI suggested strategy based on partitioning vertices into good (degree close to n/2) and bad. We had considered this before, so we had some understanding of the technical hurdle the AI would need to overcome to make it work. Overcoming the Hurdle: In the AIs proof attempt, it pointed out crucial idea that allowed us to get better control on the proportion of bad vertices. This insight was not obvious to us as it was consequence of construction we had used for different purpose. From Insight to Proof: The AIs initial proof attempt had errors (incorrect constants and Taylor approximations), but the core ideathat bad vertices actually help reduce the partition weightwas correct. Technical Details: Fractional and Integral Biclique Partitions Definition 7.1. Given graph G, fractional biclique partition is function : [0, 1], where is the set of all complete bipartite subgraphs of G, such that for all E(G), we have (cid:88) BB 1[eB] B(B) = 1. 50 The weight w(B) of such partition is w(B) := (cid:80) is integral if B(B) {0, 1} for all B. BB B(B) (B). fractional biclique partition The following notation will be useful for discussing the problem at hand. Definition 7.2. Given graph G, let BP(G) (resp., BP(G)) be the minimum weight of an integral (resp., fractional) biclique partition of G. Then, given 1, let BP(n) := max G, (G)=n BP(G) and BP(n) := max G, (G)=n BP(G). We had recently proven the following theorem regarding optimal integral biclique partitions: Theorem 7.3 (Krapivin, Przybocki, Subercaseaux, and Sanhueza-Matamala [65]). BP (n) 1 2 n2 lg . In turn, the best bounds for fractional biclique partitions were: Theorem 7.4 (Csirmaz, Ligeti, and Tardos [25]). (0.265 o(1)) n2 2 + o(1)) n2 lg . Importantly, Csirmaz, Ligeti, and Tardos also proved that on graphs of large minimum degree, lg BP (n) ( 1 better upper bound can be obtained: Theorem 7.5 (C.L.T. [25]). Let [0, 1] be fixed constant, and let be graph on vertices such that deg(v) for every (G). Then, BP(G) (0.725 (1 p) + o(1)) n2 lg . In particular, for any graph with minimum degree at least 0.32n (such as G(n, 1 2 ) graph, w.h.p.), this gives an upper bound strictly better than Theorem 7.4. On the other hand, for graphs whose edge density is far from 0.5, we also have an improved upper bound, even for integral biclique partitions: Theorem 7.6 (K.P.S.S.-M. [65]). Let γ (0, 1) be such that max{γ1, (1 γ)1} = no(1). Then, given graph of density γ, we have BP (G) ( 1 lg , where h2(x) := lg (1 x) lg(1 x) is the binary entropy function. 2 + o(1)) h2(γ) Moreover, we also proved similar result that applies when the degree of every vertex is bounded away from 0.5, even if the global density is close to 0.5: Theorem 7.7 (K.P.S.S-M. [65]). Let γ (0, 1) be such that γ1 = no(1). Then, given graph such that min{d(v)/n, 1 d(v)/n} γ, we have BP (G) ( 1 2 + o(1)) h2( γ) n2 lg . Therefore, in light of Theorems 7.5 to 7.7, if it is not possible to improve the 1 2 constant from Theorem 7.4, then the problematic graphs must have particular structure: (i) constant fraction of vertices of degree at most 0.32n, (ii) edge density 0.5, and (iii) constant fraction of vertices whose degree is approximately Naturally, we thought of decomposing problematic graphs into different pieces that could be separately handled by the three aforementioned results. Roughly, the idea was to partition the (call these Vgood) and those whose vertices of given graph into those whose degree is close to 2 degree is far from (call these Vbad). Our hope was to use Csirmaz, Ligeti, and Tardoss result 2 to construct biclique partition for G[Vgood] and then try to construct biclique partition for the remaining edges using different method. But, in order for this to work, we needed Vbad to be . 51 small proportion of the vertices, and it did not seem possible to ensure this with our strategy. We therefore left this as an open problem. The AI model was fed our paper, and at our suggestion, was asked to resolve this open problem.2 The proof attempt generated by the AI was similar to the strategy outlined in the previous paragraph, which was impressive given that we did not share our ideas with the AI. But there was one crucial difference. The AI noticed that the construction we used for Theorem 7.7 actually implies that we can improve the 1 2 is bounded 2 away from 0. We neglected to consider this ourselves, since Theorem 7.7, as stated here, is in fact corollary of stronger theorem in our paper bounding the maximum number of bicliques any given vertex belongs to; for this stronger result, it was necessary to assume that deg(v)/n 1 2 is bounded away from 0 for every vertex rather than merely on average. constant from Theorem 7.4 whenever the average of deg(v)/n However, despite the promising high-level strategy, the AIs proof attempt contained several mistakes, which did not seem to be fixable by local modifications of the proof attempt at least as written. For example, the AI asserted that some expression is 0.31966 when it is actually 0.13933, and it had nonsensical asymptotic expression Ax + x3/2 + O(x2), where is constant. Nevertheless, the AIs observation in the previous paragraph turned out to be exactly what we needed to overcome the difficulties we had encountered in our first attempt, and we proved that every n-vertex graph admits fractional biclique partition of weight at most (0.4999 + o(1))n2/ lg(n). We made no attempt to optimize the constant 0.4999; in fact, it seems to us that where the AI went wrong is trying too aggressively to optimize the constant in its proof, which resulted in overly complicated algebraic calculations that the AI struggled to accurately manipulate. Final Proof For technical reasons, Theorems 7.6 and 7.7 require γ or γ to not be too close to 0 or 1. For similar reasons, it is convenient to define clipped version of the binary entropy function, which allows us to state Lemma 7.9, lemma corresponding to the AIs central insight mentioned above. The AI originally stated the lemma using the non-clipped binary entropy function, although the lemma is incorrect when stated that way. Interestingly, when the AI was asked the provide rigorous proof of the lemma, it realized it could not be true as stated, although it did not discover that the clipped binary entropy function provides simple way to salvage it that suffices for its application. Definition 7.8. Let h2(x) := lg (1 x) lg(1 x) be the binary entropy function, and let 2 : [0, 1] [0, 1] be defined by 2(x) = (cid:40) h2(x) h2(0.01) if [0.01, 0.99] if [0.01, 0.99]. Lemma 7.9. Let be an n-vertex graph, and let = h(G) := 1 BP(G) (cid:18) 2 + o(1) (cid:19) n2 lg . (cid:80) vV 2(deg(v)/n). Then, The proof of Lemma 7.9 is relatively straightforward modification of the proof for Theorem 7.7, which corresponds to [65, Theorem 26]. With it, the proof of the final result is surprisingly simple. Theorem 7.10. BP(n) (0.4999 + o(1)) n2 lg . 2Initially, the AI model tried different open problem from our paper, but its response did not seem very promising to us, and we were more interested in this problem anyway. 52 Proof. Let be an arbitrary n-vertex graph. Let Vgood = {v (G) d(v) 0.37n} and Vbad = (G) Vgood. Then, note that h(G) = 1 (cid:88) vV 2(deg(v)/n) = 1 1 (cid:88) vVbad 2(deg(v)/n) + (cid:88) vVgood 2(deg(v)/n) (Vbad h2(0.37) + Vgood 1) . Thus, if Vbad n/100, then by Lemma 7.9, BP(G) (cid:18) 0.02 h2(0.37) + 0.98 2 + o(1) (cid:19) n2 lg (0.4999 + o(1)) n2 lg . Therefore, we may assume that Vbad < n/100. Then, every vertex of G[Vgood] has degree at least 0.36Vgood, whence Theorem 7.5 implies BP(G[Vgood]) (0.725 (1 0.36) + o(1)) n2 lg = (0.464 + o(1)) n2 lg . Let be the graph with (H) = (G) and E(H) = {e E(G) Vbad = }. It remains to construct fractional biclique partition for H. Note that E(H) Vbad 0.37n 0.0037n2, from where the edge density of is at most 0.0074 + o(1). Hence, by Theorem 7.6, BP(H) (cid:18) h2(0.0074) 2 + o(1) (cid:19) n2 lg (0.0316 + o(1)) n2 lg . Since, E(G) := E(H) E(G[Vgood]), we have BP(G) BP(G[Vgood]) + BP(H) (0.496 + o(1)) n2 lg ."
        },
        {
            "title": "7.2 Query Complexity: Local Search on General Graphs",
            "content": "Written by Simina Brânzei, Ioannis Panageas, Dimitris Paparas [12]. Problem Context We analyze the query complexity of the abstract problem of finding local minimum of function defined on general graph using rounds of interaction with the oracle. This theoretical model captures optimization tasks such as training neural networks, where the goal is to minimize loss function, each query is an expensive loss evaluation, and batching queries is crucial for efficiency. Prior work [11] resolved the query complexity of local search in rounds for the d-dimensional grid. However, the problem remained open for general graphs, which are essential for modeling non-Euclidean geometries such as manifold discretizations. AI Contribution The AI was instrumental in obtaining the following results on the query complexity of local search on arbitrary graphs: deterministic upper bound as function of the number of vertices n, the number of rounds t, and the separation number of the graph. randomized lower bound dependent on and t. These results constitute research paper [12], developed entirely by iterating with the AI via scaffolded reasoning process. Rather than asking the model to generate the paper from scratch, we treated it as junior research assistant: we defined the lemmas and tasked the AI with writing the proofs, which we then rigorously verified and refined. We directed the model to expand unclear sections and flagged issues where applicable. This approach can be characterized as form of vibe proving. Algorithm Design: We tasked the AI with deriving an upper bound for two-round local search parameterized by the graphs separation number. The model synthesized two-round algorithm with O( ns) queries and stated supporting Shattering Lemma about separator decompositions. Iterative Improvements: For all the upper and lower bounds, we guided the model to gradually generalize (e.g., obtain lower bound for tree in 2 rounds and then generalize to any graph in 2 rounds). We gave several relevant papers as context in all iterations. Adversarial Hypothesis Testing: When we hypothesized linear lower bound for local search in two rounds on constant-degree expanders, the AI refuted it by proposing counteralgorithm (Randomized Parallel Steepest Descent) and demonstrating an upper bound of O(n/ log n) for it. Problem choice. We chose this problem for several reasons. One of the authors has expertise on the topic of local search (with prior paper that focuses on grids [11]). Investigating the query complexity for general geometries was written in an NSF grant by this author. Moreover, one of the journal reviewers of the paper on local search in rounds on grids [11] independently raised this question. Pedagogically, the problem seemed ideal for collaboration with student, as it allowed for natural progression from simple casessuch as two-round search on treesto general results. 54 Strengths. The AI model demonstrated distinct strengths during our collaboration. One of the key contributions was the models tailoring of the classical staircase construction to the round setting. While the staircase technique is well-known, the models instantiation ensured that in the hard distribution, every vertex is the (only) local minimum with equal probability. This created recursive structure where, at the end of each round, the set of viable candidates forms smaller instance of the original problem, enabling clean inductive argument to go through. The elegance of this structure was very nice surprise. Weaknesses. The model also exhibited weaknesses, such as sometimes producing incorrect proofs or conveniently mis-interpreting the question so that it could answer it. For instance, when we first asked for lower bound, it would often switch to proving an existential one. Specifically, when queried about lower bound for local search on graphs with vertices and separation number s, it created hard graph for these parameters (such as line where each vertex is connected to clique of size s). We also encountered occasional hallucinations of non-existent results. Finally, when we prompted without suggesting graph features, the AI model gave upper bounds that were less interpretable. Model and Results Let = (V, E) be connected undirected graph with vertex set = [n] = {1, . . . , n}. Let : R. We call vertex local minimum if (v) (u) for every neighbor of v. In the local search problem, we are given and oracle access to the values of . The goal is to locate local minimum using minimum number of queries, where query at vertex reveals (v). Suppose the interaction with the oracle has rounds. In each round j, the algorithm selects set of queries based on the outcomes of rounds 1, . . . , 1, submits them, and receives the answers. The algorithm terminates after round with proposed solution. Query Complexity. The deterministic query complexity is the minimum number of queries required for an optimal deterministic algorithm to find local minimum on worst case instance. The randomized query complexity is the minimum worst-case number of queries required by randomized algorithm to compute the function with probability at least 9/10 for every input3. Graph Features. Let be the maximum degree of G, and let dist(u, v) denote the shortest-path distance between u, . Given parameter 1/2 α < 1 and an integer N, subset is an (s, α)-separator of if there is partition of into disjoint sets A, B, satisfying: (a) = S; (b) and A, αV ; (c) No edges connect and (i.e., E(A, B) = ). The separation number s(G) is the minimum such that every subgraph of admits an (s, 2/3)-separator. The separation number s(G) is within constant factor of the graphs treewidth. Experiment Narrative We started the investigation with trying to understand the query complexity for two rounds. One of the prompts used in the early stages of writing the paper is in Figure 5. 3The constant 9/10 can be replaced by any other constant strictly more than 1/2. 55 Given connected undirected graph = (V, E), there is an unknown function : R, which assigns value to every vertex (say the values are distinct). We have oracle access to the function (i.e. an algorithm can learn the value of the function at vertex by probing that vertex). vertex is local minimum if (v) (u) for all neighbors of v. What is the query complexity of finding local minimum in rounds of interaction with the oracle? Suppose we focus on two rounds. Can you design algorithms as function of graph features/properties like minimum vertex cover, chromatic number, treewidth? Figure 5: Early prompt for trying to understand the query complexity for two rounds. The full response to this prompt is included below. Response: This is an excellent problem that explores the trade-offs between the number of interaction rounds and the total query complexity for finding local minimum in graph. When restricted to two rounds, algorithms must strategically balance the exploration in the first round with an adaptive, focused search in the second round. We can indeed design effective algorithms by leveraging graph structural properties. General Framework: Decomposition-Based Approach. The core strategy for tworound algorithm involves partitioning the vertices into separator set and the remainder S. The first round queries S. The key is that G[V S] must be decomposed into small connected components, allowing the second round to adaptively explore the neighborhood of the most promising candidate. Let be the maximum size of any connected component in G[V S]. Generalized Decomposition Algorithm: 1. Decomposition: Identify separator set S. 2. Round 1: Query all vertices in (Q1 = S). 3. Adaptivity: Identify the minimum value found: vmin = arg minvS (v). 4. Round 2: Identify all connected components of G[V S] that are adjacent to vmin. Let Q2 be the union of vertices in these components. Query Q2. 5. Output: Output = arg minvSQ2 (v). Correctness: The algorithm guarantees finding local minimum. If (so = vmin), all its neighbors are queried. If Q2, then (v) < (vmin). Its neighbors in are larger than (vmin), and its neighbors within its component (which is entirely in Q2) are larger than (v) by definition. Query Complexity: Let be the maximum degree of G. Vertex vmin can be adjacent to at most components, each of size at most K. Thus, Q2 . The total query complexity is bounded by + . We aim to minimize this quantity by optimizing the trade-off between and K. 56 1. Algorithm based on Minimum Vertex Cover (VC). Vertex Cover is separator such that is an independent set (components of size = 1). Algorithm (VC-Adaptive): Use the minimum vertex cover (size τ (G)) as the separator S. Query Complexity: QCV = τ (G) + 1 = τ (G) + . This is efficient if both τ (G) and are small. However, for many graphs (e.g., path graph where τ (G) N/2), this complexity is O(N ). 2. Algorithm based on Chromatic Number (χ(G)). The chromatic number relates to the size of the maximum independent set α(G), with α(G) N/χ(G). We can use the complement of the largest independent set as the separator (a vertex cover). This is also the = 1 case. Query Complexity: QCχ = (N α(G)) + (1 1/χ(G)) + . This is effective for graphs with small chromatic numbers and bounded degrees, such as bipartite graphs, where the complexity is N/2 + . 3. Algorithm based on Treewidth (tw(G)). Treewidth (w = tw(G)) measures the separability of graph. We can optimize the generalized framework by choosing > 1. Let sK(G) be the minimum size of separator such that all components of G[V S] have size at most K. The complexity is: QC = minK(sK(G) + ). Graphs with low treewidth can be efficiently shattered. Specifically, many graph classes with bounded treewidth satisfy the property sK(G) = O(N w/K) (known as having 1/K-separators). Optimized Complexity: We minimize O(N w/K) + K. The balance is achieved when the two terms are roughly equal: w/K K. This yields an optimal component size (cid:112)N w/. The resulting query complexity is: QCT = O((cid:112)N tw(G) ). Implications: This demonstrates that sublinear query complexity is achievable in two rounds for structured graphs. Paths and Trees: For paths (w = 1, = 2) or bounded-degree trees, the complexity is O( ). ). Bounded Treewidth/Degree Graphs: If tw(G) = O(1) and = O(1), the complexity is O( Example: Planar Graphs. Planar graphs utilize stronger separator theorems (sK(G) = O(N/ K) + yields complexity of O(N 2/31/3). K)). Optimizing O(N/ Summary. By exploiting graph structures, we can design efficient two-round algorithms. The Vertex Cover and Chromatic Number approaches provide parameterized complexity based on the = 1 decomposition. The Treewidth approach leverages generalized decomposition (optimized K) and allows for sublinear query complexity in various important graph classes. The separation number and treewidth are related by constant factor; thus, approach (3) from the response is essentially the two-round algorithm presented in our full paper. In subsequent interactions, we prompted the model to generalize this two-round strategy to 2 rounds. The model successfully synthesized t-round algorithm anchored by Shattering Lemma. The lemma is: For any parameter [1, n], there exists separator such that every connected component of G[V S] has size at most K, with < 3sn/K. This lemma is folklore and was central to constructing the general strategy. We also included the vertex cover-based algorithm suggested by the model into the papers introduction as an example. 57 We obtained this way the following theorem. Theorem 7.11 (Theorem 1 in [12]). Let = (V, E) be connected undirected graph with vertices. The deterministic query complexity of finding local minimum on in 2 rounds is at most min(cid:0)4t , n(cid:1), where is the maximum degree and is the separation number of G. (s)1 1 The development of the lower bounds was more iterative. Initially, the model insisted on constructing hard graphs (e.g., line graphs with cliques of size attached to each node) rather than finding hard distribution of functions for fixed graph. Some of the lower bounds derived in this stage were not correct, or relied on looking at the longest path in the graph or using Mengers theorem. Eventually we created prompt that had the following elements: explicitly clarifying it must keep the given graph fixed and find hard input distribution (of functions) for that graph; including as context prior papers on lower bounds for local search (specifically, [11] and [79]); asking it to focus on local search in two rounds on tree and try to prove lower bound of Ω( n). The prompt, given in Figure 6, also contained the version of the paper up to that point, which contained only algorithmic results (Theorem 7.11). am working on the following manuscript. Can you read it (ignoring the todos/notes) and then help me prove lower bound of on the randomized query complexity of finding local minimum in two rounds on tree? The statement should be of the form: Theorem. Let = (V, E) be an undirected connected tree with vertices. Then the randomized query complexity of finding local minimum in two rounds on is Ω( n). Note the lower bound should hold for the given tree G, so dont create hard family of trees. Rather, you need to create hard family of functions for the given tree G. Make it so that for each function in the family, there is unique local minimum. Also dont hide the constants under big Omega until the very end of the proof. Attaching two papers from this literature together with my current draft; see especially the paper on local search in rounds on grids for examples of how to use Yaos lemma in such proofs (i.e. finding hard distribution of functions and analyzing the performance of deterministic algorithm). Figure 6: Prompt for lower bound on trees in two rounds The models response to the prompt is included below: Theorem. Let = (V, E) be an undirected connected tree with > 1 vertices. Then the randomized query complexity of finding local minimum in two rounds on G, with success probability at least = 9/10, is Ω( n). Specifically, it is at least 1.8 2. Proof. We use Yaos Minimax Principle. We define distribution over input functions such 58 that each function has unique local minimum. We then analyze the expected query complexity of any deterministic two-round algorithm that succeeds with probability at least over D. 1. The Hard Distribution D. Fix an arbitrary vertex as the root. Let d(v) be the depth of (distance from r). Let Anc(v) be the set of ancestors of (the unique path from to v, inclusive). We write if Anc(v). For each , we define the function fv : Z: fv(x) = (cid:40) d(x) d(x) if if fv has unique local minimum at v. Let be the uniform distribution over {fv}vV . The input is fV , where is chosen uniformly at random from . 2. Analysis of Deterministic Two-Round Algorithm A. Round 1. queries fixed set Q1 . Let q1 = Q1. Since the structure of is known, d(x) is known. query to fV (x) reveals whether . The outcome of Round 1 is the signature SV = Anc(V ) Q1. Let be the set of possible signatures. The outcomes partition into = blocks C1, . . . , CK, where Ci is the set of corresponding to the i-th signature. Lemma 7.12. The number of distinct outcomes is at most q1 + 1. Proof. For any non-empty signature S, let m(S) be the unique element in farthest from the root r. Note m(S) Q1. We show the map : {} Q1 is injective. Suppose m(S1) = m(S2) = x. Let S1 = Anc(v1) Q1. Since S1, we have v1. We claim S1 = Anc(x) Q1. (): If S1, then Q1 and v1. Since is the deepest element in S1, must be an ancestor of (as all elements in Anc(v1) are comparable). Thus Anc(x) Q1. (): If Anc(x) Q1. Since v1, Anc(x) Anc(v1). Thus Anc(v1) Q1 = S1. Therefore, S1 = Anc(x) Q1. Similarly, S2 = Anc(x) Q1. Thus S1 = S2. Since is injective, Including the possibility of the empty there are at most Q1 = q1 non-empty signatures. signature, q1 + 1. Round 2. If the outcome implies Ci, queries Q2,i of size qi. This further partitions Ci into Ki sub-blocks. By the same logic as Lemma 7.12, Ki qi + 1. 3. Success Probability and Expected Cost. Let Pi be the conditional success probability given Ci. Since the distribution within Ci is uniform, and the algorithm makes deterministic guess for each sub-block Ci,j, it succeeds on at most one vertex per sub-block. Pi = Ki(cid:88) j=1 (V Ci,jV Ci)P (SuccessV Ci,j) Ki(cid:88) j=1 Ci,j Ci 1 Ci,j = Ki Ci . (The inequality becomes equality if the algorithm guesses optimally within each sub-block). Since Ki qi + 1, we have CiPi qi + 1, so qi CiPi 1. Also, Pi 1 since Ki Ci. We require the overall success probability PS c. PS = (cid:80)K Let = cn. We require (cid:80)K i=1 (V Ci)Pi = 1 i=1 CiPi. (cid:80)K i=1 CiPi S. 59 The expected query complexity Qexp of under is: Qexp = q1 + 1 (cid:88) i= Ciqi q1 + 1 (cid:88) i=1 Ci(CiPi 1) = q1 + 1 (cid:32) (cid:88) i=1 (cid:33) PiCi2 1 K (cid:88) i=1 Ci = q1 1 + 1 (cid:88) i=1 PiCi2. 4. Optimization. We use the Cauchy-Schwarz inequality to lower bound the summation: (cid:32) (cid:88) i=1 (cid:33) (cid:32) (cid:88) (cid:33) Pi PiCi2 i=1 (cid:32) (cid:88) ( i=1 (cid:112) PiCi) (cid:112) Pi (cid:33) = (cid:32) (cid:88) i=1 (cid:33)2 PiCi S2. Therefore, (cid:80)K We bound the denominator. Since Pi 1, (cid:80) Pi K. By Lemma 7.12, q1 + 1. i=1 PiCi2 S2/((cid:80)K i=1 Pi). (cid:88) i=1 PiCi2 S2 q1 + 1 . Substituting this back into the expected cost: Qexp q1 1 + S2 This lower bound holds for any deterministic algorithm A, characterized by its choice of q1. To find the overall lower bound via Yaos principle, we minimize this expression over q1 0. Let = q1 + 1 (x 1). We minimize g(x) = 2 + c2n . By the AM-GM inequality, 1, which holds + c2n/x 2 c2n = 2c for = 9/10 and > 1). n(q1+1) = q1 1 + c2n q1+1 . n. Equality holds when = n. (Assuming Qexp 2c 2. 2 = 1.8 2. Thus, the randomized query Substituting = 9/10: Qexp 2(0.9) n). complexity is Ω( Building on the lower bound for trees in two rounds, we asked the model to generalize the result to any graph in two rounds. The proposed approach defines an arbitrary spanning tree of rooted at some vertex and family of functions = {fv } parameterized by each vertex that also depends on . In particular, for every , let fv : be such that for all , fv(x) = (cid:40) distT (r, x) if distT (r, x) otherwise (26) where distT (r, x) represents the distance between and in the spanning tree . Moreover, we denote by the uniform distribution over F. The distribution is the one used to obtain the lower bound for any graph and number of rounds. Unlike the two-round case where the round-1 queries are fixed, the 3 round case requires analyzing adaptive histories. To handle the adaptivity, the model suggested the notion of candidate set. Suppose is history reachable after rounds. The candidate set, denoted C(H), represents the vertices of that could still be local minima given the history H. 60 (a) Graph with = 16 vertices (b) Spanning tree with the candidate sets attainable at the end of round 1. Figure 7: The left figure (a) shows graph G. The input function is drawn from F. The right figure (b) shows spanning tree of rooted at 1. The set of queries Q1 = {2, 3, 10} submitted in round 1 are circled in red. The partition of candidate sets attainable at the end of round 1 (depending on the answers to the queries) is illustrated using yellow frames. The model observed several properties of the candidate sets, which we consolidated into key lemma stating that at the end of each round i: (a) each attainable candidate set is sub-tree of the original spanning tree of G; and (b) the candidate sets partition the graph, and there is bijection from the set of histories reachable at the end of round and the set of candidate sets attainable at the end of round i. While the models intuition was correct, obtaining rigorous proof for part (b) was more challenging. It initially treated the result as self-evident; when pressed for details, it produced circular argument (very briefly, to prove the bijection, it assumed that the candidate sets already form partition of the set of vertices). We tried guiding it toward an inductive proof, and later toward direct non-inductive one, but the circular argument persisted in both. The turning point came when we gave it hint: assume by contradiction that vertex lies in two candidate sets, and use part (a) to analyze the roots of the trees underlying the two sets. With this hint, the model generated correct proof that is now found in the paper. The remainder of the t-round lower bound argument was correct. Thus we obtained: Theorem 7.13 (Theorem 2 in [12]). Let = (V, E) be connected undirected graph with vertices. The randomized query complexity of finding local minimum on in rounds is Ω(tn1/t t). We also asked the model to prove linear lower bound for local search in two rounds on constantdegree expanders. Instead, it responded by proposing Parallel Steepest Descent with Warm Start algorithm. This algorithm has query complexity slightly better than linear even for two rounds on any graph with constant maximum degree: O(n/ log n). The bound given by this algorithm is stated next for any number of rounds. Proposition 7.14 (Proposition 1 in [12]). Let = (V, E) be graph with vertices and maximum + t) degree . The randomized query complexity of finding local minimum in 2 rounds is O( when 2 and O(cid:0) n(cid:1) when 3. tlog + t2 61 Concluding Remarks. Our experiment demonstrates that the model can expedite theoretical research when treated as research assistant. For instance, when guided toward separation numbers, the model developed the divide-and-conquer algorithm and its proof, leveraging the Shattering Lemma as key component for the analysis. This process required vigilance; we had to rigorously audit the models claims, as illustrated by circular argument we uncovered in one of the lower bound lemmas. Despite the need for verification, the interaction was very fruitful, yielding lower bound construction with surprisingly elegant recursive structure. Acknowledgements. Simina Brânzei was supported by US National Science Foundation grant CCF-2238372. Ioannis Panageas was supported by US National Science Foundation grant CCF2454115."
        },
        {
            "title": "7.3 Robust Coresets",
            "content": "Written by Yi Li, David P. Woodruff, and Xuan Wu. Problem Context In the standard coreset framework, one is given finite weighted collection of functions = {(f, wf )}, where each function : Rd R0 is associated with weight wf 0. The loss function for is defined as L(F; x) = (cid:80) wf (x). An ε-coreset is weighted subset such that (1 ε)L(F; x) L( F; x) (1 + ε)L(F; x) holds simultaneously for all possible values of x. Classical problems such as ℓp-regression and clustering naturally fit into this framework. typical approach to construct coreset is sensitivity sampling, where each function is sampled with probability proportional to its sensitivity, defined as wf (x) L(F; x) σF (f ) = sup For example, in ℓ2-subspace embedding and regression, these sensitivities coincide with leverage scores. In the more general ℓp-subspace embedding and regression, exact sensitivities are harder to compute and Lewis weights are commonly used as an effective proxy. Similarly, in clustering, recent work [7] has shown that sensitivity sampling can achieve near-optimal coreset sizes. We also define the sensitivity of the function set as σ(F) = (cid:80) . Robust coresets can be studied within the same framework by replacing the standard loss with F σF (f ). trimmed loss. Specifically, for an integer 0, the trimmed loss is defined as L(m)(F; x) = min FF (cid:88) (f,wf )F wf (x), which discards (at most) largest contributions to the loss. Correspondingly, an (ε, m)-robust coreset is weighted subset such that (1 ε)L(m)(F; x) L(m)( F; x) (1 + ε)L(m)(F; x) for all x. When = 0, this definition reduces to the standard ε-coreset. Prior work [56] has shown that if the total sensitivity of is bounded by (i.e. σ(F ) for any non-empty subset F), then there exists an (ε, m)-robust coreset of size O(T m/ε log(T m/ε)) + Q, where denotes the size of standard ε-coreset. AI Contribution AI provided sharper analysis that eliminates the logarithmic factor, improving the robust coreset size bound to O(T m/ε) + Q, which is known to be tight. Technical Details We first review the algorithms from [56] and the associated guarantees before presenting the tighter analysis produced by AI. Algorithm 1 Uniform(A, ε, m) Require: set of functions, parameters ε and Ensure: subset 1: 2: for each A, with probability 1 to , add 3: for each B, compute the sensitivity 4: σB(f ) 4: {f : σB(f ) ε 4 } 5: return Algorithm 2 Refine(D, ε, m) Require: coreset D, parameters ε and Ensure: refined subset adapted for the robust optimization problem 1: 2: for (f, ωf ) do 3: compute the sensitivity σD(f ) nf ε σD(f ) Add nf copies of (f, ωf nf ) to 5: 6: end for 7: return Algorithm 3 Coreset(A, ε, m) Require: set of functions, parameters ε and m, and an algorithm Vanilla(A) to construct an ε-coreset for Algorithm 4 ModifiedCoreset(A, ε, m) Require: set of functions, parameters ε and m, and an algorithm Vanilla(A) to construct an ε-coreset for Ensure: An (ε, m)-robust coreset for 1: 2: Θ(m log ε ) 3: for = 1, 2, , do 4: Uniform(A, ε, m) 5: 6: end for 7: Vanilla(A S) 8: {(f, 1) : S} 9: Return Refine(V, ε, m). Ensure: An (ε, m)-robust coreset for 1: 40m ln(2000T m/ε) 2: for = 1, 2, , do 3: Di Uniform(A, ε, m) for Di do cf cf + 1 4: 5: end for 6: 7: end for 8: {f : cf 9: Vanilla(A S) 10: {(f, 1) : S} 11: Return Refine(V, ε, m). 10m } The algorithms from [56] are reproduced in Algorithms 1 to 3, where Algorithm 3 outputs the final robust coreset. function is called contributing if there exists Rd such that L(m)(A; x). The following guarantee of Algorithm 1 was established in Lemma 4.3 of [56]. (x) ε Lemma 7.15. Assume that is contributing, then with probability at least Uniform(A, ε, m) contains . 1 5m , the set returned by It was then argued in [56] that the number of contributing functions in is O( ε ε ). log Consequently, Algorithm 3 executes Θ(m log(T m/ε)) rounds of Algorithm 1 in order to capture all contributing functions with high probability, thereby forming the basis of the robust coreset that can handle outliers. Now we describe our interactions with AI. We first entered the following prompt. 64 Prompt 1. Can you resolve the logarithmic factor gap in the coreset construction in the attached paper? Feel free to give both tighter analysis as well as to change the algorithmic framework in the paper in order to achieve this improved bound. <generic instructions on being mathematically rigorous> Gemini. Yes, the logarithmic factor gap in the coreset construction size can be resolved. The paper presents coreset of size O(K log K) + Q, where = m/ε. We demonstrate that this can be improved to O(K) + in expectation and with constant probability. This improvement is achieved in two steps: first, by providing tighter analysis of the number of contributing functions, and second, by modifying Algorithm 3 to filter out non-contributing functions more effectively using frequency estimation. ... The AI produces the following bound on the number of contributing functions, which already improves the argument in [56]. Lemma 7.16. The number of contributing functions in is 20 ε . Proof. Let be the set of contributing functions, = C. Let be the output of single execution of Algorithm 1. Algorithm 1 returns = {f : σB(f ) ε/4}. By the assumption of strong total sensitivity , we have σB . Therefore, (ε/4) (cid:80) σB(f ) σB . This implies 4T /ε deterministically. Let = 4T /ε. Consequently, the expected size of is bounded: E[D] . Let pf = Pr(f D). By 7.15, if C, then pf 1/(5m). By linearity of expectation: E[D] = (cid:88) pf (cid:88) C pf 1 5m . Combining the inequalities: 5m = 5mW = 5m 4T ε = 20T ε . The AI then proceeds with modified version of Algorithm 3 by tracking the frequency of each function in and discarding the ones with low frequencies. It then presents theorem as follows. Theorem 7.17 (Improved Coreset Construction). Algorithm 3-Modified constructs an (ε, m)-robust coreset for of expected size O(K) + Q. The construction succeeds with high probability (at least 1 O(1/n)). The proof is correct, though we omit it here, since the theorem states an expected size of the coreset, which is not desirable. We further make the following prompt. Prompt 2. It looks correct, but the Theorem only gives the size in expectation. The earlier version had high-probability bound, which shouldnt be hard to get. Maybe you can prompt it to produce an upper bound that holds with high probability? Actually we need only probability 0.99 instead of 1 1/n. 65 Gemini. We demonstrate that the logarithmic factor in the coreset size bound of Theorem 4.1 in the paper \"Robust Sparsification via Sensitivity\" can be removed. The original paper presents coreset of size O(K log K) + Q, where = m/ε. We show that modification of the algorithm yields coreset of size O(K) + with high probability (at least 0.99). ... Key Properties of Algorithm 1: 1. Deterministic Size Bound: The output always satisfies . This is because σB(f ) σB . Since σB(f ) ε/4 for D, we have (ε/4) , so (cid:80) . 2. Expected Size Bound: E[D] . 3. Capture Probability (Lemma 4.3): If C, the probability pf = (f D) satisfies pf 1/(5m). ... AI returns correct version of the theorem. Theorem 7.18. The Modified Algorithm constructs an (ε, m)-robust coreset for of size O(K) + with probability at least 0.99. The proof is correct, though somewhat suboptimal. It uses Markovs inequality to bound the total number of sampled functions over rounds, which is unnecessary. This suboptimality arises from weaker property generated by the AI, as presented in its response above. In particular, Point 1 already provides deterministic bound , rendering the expected bound in Point 2 unnecessary. Therefore, we further prompt the AI to improve the argument. Prompt 3. This looks correct though it is bit suboptimal when bounding the size. Specifically, it says <quote of the properties>. In the first bullet point, it already obtains that , so the second bullet point is unnecessary. In the subsequent proof of Part 2 of the theorem, it could directly use the deterministic bound instead of the expectation bound. This will further tighten the analysis bit. Gemini. <latex source> The results are correct and are reproduced below with minor modifications to fit the present context. The algorithm generated by the AI is presented in Algorithm 4, with slight simplifications. Theorem 7.19. Let ε (0, 1 2 ) and be unit-weight function set with total sensitivity . Suppose that there exists an algorithm that computes vanilla ε-coreset for of size Q. Then, Algorithm 4 computes an (ε, m)-robust coreset for of size O( Proof. Size bound. We analyze the size of the set returned by the algorithm. Let Ctotal be the total count of all functions captured across all iterations. ε ) + Q, with probability at least 0.99. Ctotal = (cid:88) i=1 Di. 66 By the deterministic size bound property of Algorithm 1, we know Di := 4T /ε for all i. Therefore, Ctotal is deterministically bounded: Ctotal (cid:88) i=1 = RW. Now we relate the size of to Ctotal. By definition, if and only if cf Rθ for θ = 1/(10m). Ctotal = (cid:88) cf (cid:88) cf (cid:88) (Rθ) = Rθ. Therefore, we have deterministic bound on S: Ctotal Rθ RW Rθ = θ = 40T ε . Thus, 40K, where = m/ε. The size bound = O(K) holds deterministically. Correctness. We want to bound the probability that contributing function is missed (f / S). The count cf is sum of independent indicators. If C, we have E[cf ] R/(5m). If S, it means that cf < R/(10m). Use the Chernoff lower tail bound (X µ/2) exp(µ/8): Pr(f / S) = Pr(cf < Rθ) = Pr cf (cid:18) (cid:19) E[cf ] 1 2 (cid:18) exp (cid:19) R/(5m) (cid:18) = exp 40m ln(2000K) 40m (cid:19) = 1 2000K . We apply union bound over C. By Lemma 7.16, 20K. Pr(C S) = Pr(f : / S) Pr(f / S) 20K 1 2000K = 1 100 = 0.01. (cid:88) The algorithm deterministically produces set of size 40K. With probability at least 1 0.01 = 0.99, the algorithm ensures S. The remainder of the correctness proof follows exactly as in Theorem 4.1 of [56]."
        },
        {
            "title": "7.4 Submodular Function Maximization in a Stream",
            "content": "Written by Ola Svensson. Problem context We consider monotone submodular maximization under cardinality constraint in the adversarial injection streaming model introduced in the paper Robust Algorithms under Adversarial Injections [45]. In this model, the stream consists of an (unknown) set Egood of genuine elements arriving in uniformly random order, interleaved with an arbitrary set Enoise of injected elements placed by an adversary. The motivation of this semi-random model is to design algorithms in beyond-worst-case model while not overfitting to the assumption (such as all elements arrive in uniformly at random order). The goal is to output set Egood Enoise of size at most with value close to OPT := max k, Egood where is nonnegative monotone submodular function given by value-oracle access. We remark that it is important that OPT is defined with respect to the optimal solution of elements in Egood. Indeed, if OPT were also allowed to contain elements of Enoise then the model would be equivalent to fully adversarial one. (T ), The above paper proposes streaming algorithm for this setting (the tree algorithm for monotone submodular maximization), achieving an approximation factor around 0.55 while storing number of elements independent of Egood (but exponential in k). Two concrete questions were left open for submodular maximization in this model: (i) whether one can reach the offline-optimal constant (1 1/e), and (ii) whether one can reduce memory to poly(k) elements. The tree algorithm and where the analysis bottleneck appears At high level, the tree algorithm maintains rooted tree of depth whose root-to-leaf paths represent candidate sizesolutions. When new element arrives, the algorithm considers attaching beneath existing nodes based on its marginal contribution. The tree is kept from exploding by merging equal-marginal states: within each level, only one representative for each marginal-gain value is retained. This keeps the algorithm stream-length independent, but in the worst case still requires exponentially many stored elements as function of k. The original approximation analysis proceeds by tracking carefully chosen leaf as the (unknown) optimal elements from Egood appear in the stream. central technical device is threshold parameter used in case split comparing (i) the best available marginal gain since the last optimal element appeared, versus (ii) the marginal gain of the next unseen optimal element. This case split yields recurrence R(k, h) that lower bounds the fraction of OPT captured after progress through optimal elements with budget k, with the final guarantee given by R(k, k). In the paper, is chosen globally (independent of the state (k, h)); numerically, setting 0.8 yields R(k, k) 0.55067. key insight by Geminiwhich ultimately enabled our improvementis that is not an algorithm parameter. It only appears in the analysis, meaning we are free to choose different threshold in different states as long as the inequalities used in the proof remain valid. AI Contribution The AI identified latent degree of freedom in the existing algorithmic analysis. By replacing global threshold with state-dependent threshold, the model autonomously derived and proved an 68 optimized recurrence relation, strictly improving the algorithms approximation ratio from 0.55 to 2 2. We used Gemini to explore whether the analysis could be sharpened. Gemini did not produce new algorithm achieving (1 1/e), nor did it find way to reduce the memory requirement to poly(k) elements in this adversarial injection setting. However, it did identify clean way to improve the existing analysis of the tree algorithm: replace the single global threshold by state-dependent threshold tk,h in the recurrence. Concretely, Gemini suggested using tk,h := k2 + h2 , and first predicted and then formally proved that the corresponding optimized recurrence achieves the exact constant R(k, k) = 2 2 0.585786, thereby improving the analyzed approximation ratio of the same underlying algorithm from 0.55067 to 0.58579. The remainder of this testimonial highlights the four prompts that led from idea to complete, algorithm-level guarantee. Prompt 1: exploratory questions, and the key analysis insight Prompt 1. Please investigate if you can improve the submodular part of the attached paper. Specifically: Can we get (1 1/e) for submodular maximization? Can we only store poly(k) elements instead of exponentially many in k? Be mathematically rigorous. Gemini (summary). The model did not produce new algorithm achieving (1 1/e), and it did not resolve how to store only poly(k) elements. However, it identified that the analysis recurrence in the paper can be strengthened by letting the threshold depend on the state: instead of global t, introduce tk,h. It further hypothesized that the best constant 2, and that natural candidate is achievable within this recurrence framework is 2 closed-form threshold of the form tk,h = t(h/k). Figure 8: The first prompt where Gemini identified the direction for improvement and the improved guarantee. In the first interaction with Gemini  (fig. 8)  , we gave fairly general prompt with two open questions. Even though the response did not resolve the two open algorithmic questions, it pinpointed previously unexplored degree of freedom in the analysis and proposed (correctly) that exploiting it improves the approximation factor. Prompt 2: rigorous (but asymptotic) derivation via continuous limits 69 Prompt 2. Can you rigorously improve it to obtain 2 2 approximation, as suggested? <math rigor boilerplate> Gemini (summary). Gemini produced rigorous argument in continuous/asymptotic regime (as ) by recasting the recurrence optimization as minimax problem that leads to differential inequalities/ODE-type conditions. While this was not yet the discrete proof we needed, it strongly indicated the correct functional form of the optimal thresholds, and guided us to the explicit choice This directly set up Prompt 3, where we asked for fully discrete proof. tk,h = k2 + h2 . Figure 9: In the second prompt, we asked for rigorous proof of the improved guarantee. In the second prompt, fig. 9, we asked for rigorous proof and Gemini responded with an argument in the asymptotic regime. Even though the ODE argument was not exactly what we asked for, it served as highly effective derivation tool : it revealed the right closed-form threshold and the right constant before we invested time in discrete induction. Prompt 3: complete discrete proof of the optimized recurrence We next asked Gemini to prove the optimized recurrence formally, with the thresholds fixed to the candidate form, see fig. 10 for the third prompt. 70 Prompt 3 (condensed). Define tk,h = k2+h2 and the recurrence R(k, h) = min{Ak,h, Bk,h, Ck,h} with Ak,h := Bk,h := Ck,h := tk,h 1 + (cid:16) + 1 (cid:16) 1 (cid:17) tk,h 1 + tk,h 1 1 + tk,h , R(k, 1), (cid:17) R(k 1, 1), and base R(k, 0) = 0. Prove that R(k, k) = 2 2 for all integers 1. Gemini (summary). Gemini proposed an explicit closed-form candidate (k, h) (as function of h/k) and showed it satisfies the recurrence by induction, yielding the exact identity R(k, k) = 2 2 for all 1. Figure 10: In our third prompt, we asked for and received complete proof of the discrete recurrence. At this point, Gemini had delivered an almost complete proof of the mathematical core: the optimal solution of the improved recurrence. This was the key missing technical ingredient needed to upgrade the approximation factor. Prompt 4: connecting the recurrence back to the tree algorithm (and hidden monotonicity issue) Finally, we asked Gemini to connect the recurrence to the original algorithm analysis, see Figure 11. This step is subtle because the original paper uses global in an inequality of the form R(k 1, 1) 1/(1 + t), whereas our thresholds vary with (k, h). This last step was important for correctness: it is easy to solve an abstract recurrence while accidentally breaking an inequality needed to justify the recurrence from the algorithm. Gemini not only identified the missing monotonicity condition but also proved it for the optimal threshold schedule, thereby completing the logical chain from the recurrence back to the streaming algorithm. Outcome and takeaway The outcome of this interaction was strictly improved approximation guarantee for the same tree algorithm in the adversarial injection streaming model: approximation ratio improved from 0.55067 to 2 2 0.58579, achieved by refining the analysis (via sharper, state-dependent choice of thresholds). From how to use Gemini perspective, this case study highlights valuable contribution: even when model does not solve the headline open problems (here, (1 1/e) or poly(k) memory), it can still make decisive contribution by (i) identifying latent degree of freedom in an existing proof, 71 Prompt 4 (condensed). Please relate the recurrence with state-dependent thresholds = tk,h to the analysis of the tree algorithm. In particular, in the analogue of Lemma 4 from the paper, the proof used R(k 1, 1) 1/(1 + t) for global t. Now depends on (k, h), so this step requires care. Please write step-by-step how R(k, h) bounds the approximation guarantee, and identify what additional property is needed. Gemini (summary). Gemini provided step-by-step mapping from the algorithms case analysis to the three terms Ak,h, Bk,h, and Ck,h, showing how R(k, h) lower bounds the value of carefully chosen leaf as the optimal elements appear. Crucially, it identified that the global-t inequality is replaced by requirement of the form R(k 1, 1) 1 1 + tk,h , which does not automatically hold for arbitrary state-dependent thresholds. Gemini then pinpointed sufficient condition: monotonicity relation along the diagonal, tk,h tk1,h1, which implies 1 this monotonicity for the chosen optimal thresholds tk,h = 1 1+tk1,h1 1+tk,h k2+h2 . and allows the induction to go through. It also proved Figure 11: In the fourth prompt, we asked Gemini to correctly relate the improved analysis of the recurrence to the improved analysis of the algorithm. 72 (ii) guessing the right closed form for an optimum constant/parameter schedule, and (iii) producing formal proofs with minimal guidance. The Formal Improved Analysis by Gemini The following is the complete proof that was automatically generated by Gemini. We have kept the writing exactly as automatically produced. Preliminaries and Notation Submodularity. function is submodular if for all and , the marginal gain (eS) := (S {e}) (S) satisfies (eS) (eT ). It is monotone if (S) (T ) for . Lemma 7.20 (Average Marginal Bound). Let be set of size and be any partial solution. For monotone submodular function , the expected marginal gain of random element satisfies: EoO[f (o S)] (O S) (S) If = and = Eopt, then EoEopt[f (o)] OP . Proof. This follows from the definition of submodularity. The sum of the marginals of elements in added to is at least the total gain (O S) (S). Taking the average yields the result. Stream Notation Let σ be the input stream. Eopt = {o1, . . . , ok}. Let π be the random permutation of Eopt. oπ }. 1 , . . . , oπ OP = (Eopt). is the i-th element of Eopt to arrive in the stream. Oπ = {oπ The Tree Algorithm We briefly review the Tree Algorithm from [45]. For simplicity, we assume the algorithm knows OP and that the set of possible marginal gains is small (these assumptions can be removed using standard techniques involving discretization and guessing, as detailed in the appendix of [45]). The algorithm maintains rooted tree of height at most k. Each node represents partial solution (the set of elements on the path from the root to the node). Analysis via Generalized Recurrence The core of the analysis involves defining specific path in the execution tree and lower bounding its expected value. We generalize the approach by introducing state-dependent threshold. The Generalized Recurrence Relation We define the domain := {(k, h) Z2 0 : 0 k}. We introduce generalized recurrence R(k, h) which aims to lower bound the approximation ratio when the optimal solution has size and the algorithms budget is h. Definition 7.21 (Threshold Function). We define threshold function : {(0, 0)} (0, 1]. Definition 7.22 (Generalized Recurrence). Let : R0 be defined as follows: R(k, 0) := 0 for all 0. For (k, h) with 1, 1, let = (k, h). R(k, h) := min{Ak,h, Bk,h, Ck,h} 73 Algorithm 5 Tree Algorithm 1: Initialize tree with only the root (representing = ). 2: for each element arriving in the stream σ do 3: for each node in do 4: 5: 6: 7: 8: 9: 10: Let Sv be the solution corresponding to v. if Sv < then Calculate the marginal gain = (eSv). if has no child such that (cSv) = then Add new child node corresponding to Sv {e}. end if end if end for 11: 12: end for 13: Return the solution SALG corresponding to the leaf with maximum value (SALG). where (cid:19) 1 + Ak,h = Bk,h = Ck,h = (cid:18) + 1 (cid:18) + 1 1 1 1 + . R(k, 1), (cid:19) R(k 1, 1), Adapted Path Selection Strategy To utilize this recurrence, the analysis employs path selection strategy that dynamically uses the threshold corresponding to the current subproblem. This strategy defines path in the tree whose expected value we analyze. We define the path Sπ = {sπ 1 , . . . , sπ h} inductively. We track the state (ki, hi, ni): remaining OPT size, remaining budget, and index of the current OPT element. Initialize (k1, h1, n1) = (k, h, 1). At step (for = 1, . . . , h): 1. Set the threshold ti = (ki, hi). 2. Define uπ ) relative to Sπ and the current OPT element oπ ni (the best non-OPT (as element seen so far) and vπ (the better of uπ defined in [45]). 3. Apply the decision rule: Case 1 (Greedy Choice): If Eπ[f (uπ (ki+1, hi+1) = (ki, hi 1), ni+1 = ni. Sπ i1)] ti Eπ[f (oπ niSπ i1)]. Set sπ = uπ . Update: Case 2 (Wait for OPT): Otherwise. Set sπ = vπ . Update: (ki+1, hi+1) = (ki 1, hi 1), ni+1 = ni + 1. Connecting the Recurrence to the Algorithm We now prove that R(k, h) bounds the performance of this strategy, provided the threshold function satisfies monotonicity property. Definition 7.23 (Monotonic Threshold Condition (MTC)). threshold function (k, h) satisfies the Monotonic Threshold Condition (MTC) if for all 2, 1: Lemma 7.24. If (k, h) satisfies the MTC, then for all 1, 1, letting = (k, h): (k, h) (k 1, 1). R(k 1, 1) 1 1 + . 74 Proof. If = 1, then = 1. R(0, 0) = 0. Since > 0, the inequality holds. Assume 2. By definition of the recurrence: R(k 1, 1) Ck1,h1 = 1 1 + (k 1, 1) . By the MTC, (k, h) (k 1, 1). Thus 1 + (k, h) 1 + (k 1, 1). R(k 1, 1) 1 1 + (k 1, 1) 1 1 + (k, h) = 1 1 + . We can now prove the main connection theorem. Theorem 7.25. If the threshold function (k, h) satisfies the MTC, then for all instances of the problem and (k, h) D, the solution Sπ defined by the adapted strategy satisfies: Proof. We proceed by induction on h. Eπ[f (Sπ )] R(k, h) OP T. Base Case (h=0): R(k, 0) = 0. Eπ[f (Sπ Inductive Step: Assume the theorem holds for 1. We prove it for (k, h), where 1, 1. Let = (k, h). We analyze the first step (i = 1). By Lemma 7.20, due to the random permutation, Eπ[f (oπ 0 )] = () = 0. The theorem holds. 1 )] OP /k. Case 1: Eπ[f (uπ As argued in [45], uπ 1 1 )] Eπ[f (oπ 1 )]. We set sπ 1 = uπ 1 . is determined by the elements arriving before the first OPT element. Since the adversary injects noise without knowledge of the permutation π, the set of elements in this prefix is independent of π. Therefore, uπ 1 is independent of π. Let s1 = uπ 1 We consider the remaining subproblem . It has = OPT elements and budget = 1. The function is (T ) = (T s1). The optimum of the subproblem is OP = (Eopts1). By submodularity and monotonicity, OP OP (s1). . The remainder of the path Sπ {s1} corresponds exactly to the path constructed by our strategy applied to . By the Inductive Hypothesis (IH): Eπ[f (Sπ s1)] R(k, 1) OP . Eπ[f (Sπ )] = (s1) + Eπ[f (Sπ s1)] (s1) + R(k, 1)(OP (s1)) = (s1)(1 R(k, 1)) + R(k, 1) OP T. We verify that R(k, 1) < 1. Since 1, R(k, 1) Ck,h1 = (k, 1) > 0, R(k, 1) < 1. Thus, 1 R(k, 1) > 0. 1 1+T (k,h1) . Since By the condition for Case 1 and Lemma 7.20, (s1) Eπ[f (oπ 1 )] OP /k. Eπ[f (Sπ )] OP = OP (1 R(k, 1)) + R(k, 1) OP (cid:20) R(k, 1) 1 + (cid:19) (cid:18) (cid:21) = Ak,h OP T. Case 2: Eπ[f (uπ 1 )] < Eπ[f (oπ 1 )]. We set sπ 1 = vπ . 75 We consider the remaining subproblem (π). It depends on π because both sπ 1 and the remaining 1 } depend on π. The parameters are (k 1, 1). The function still uniformly permuted): Eπ[f (Sπ opt(π) = Eopt {oπ 1 ). OPT elements is π(T ) = (T sπ We analyze the expected value over π. Eπ[f (Sπ 1 )] + Eπ[f (Sπ By the IH applied to the subproblem (noting that conditional on oπ 1 sπ 1 )] R(k 1, 1) Eπ[OP (π)]. The expected optimum of the subproblem is Eπ[OP (π)] = Eπ[f (E 1 )]. 1 oπ 1 )] + R(k 1, 1) (OP Eπ[f (sπ )] Eπ[f (sπ 1 = oπ 1 , it must be that sπ ity: Eπ[OP (π)] OP Eπ[f (sπ Combining these: Eπ[f (Sπ We bound the loss term Eπ[f (sπ , and since sπ 1 = vπ 1 We can obtain bound using the Case 2 condition. 1 )]. Note that if sπ is the best element up to oπ 1 , then sπ 1 1 = uπ 1 )] = Eπ[f (sπ opt(π)sπ 1 oπ sπ oπ 1 . 1 )]. , the remaining elements are 1 )]. By submodular1 )]). must have arrived before 1 oπ 1 ] + (sπ 1 = oπ 1 )E[f (sπ 1 oπ 1 )sπ 1 = oπ 1 ]. Eπ[f (sπ 1 oπ 1 )] = Eπ[f (oπ = Eπ[f (oπ 1 )] + Eπ[f (sπ 1 )] + (sπ 1 oπ 1 = oπ 1 )] 1 )E[f (sπ If sπ , the marginal gain is 0. If sπ 1 = oπ 1 Eπ[f (sπ 1 oπ 1 )] = Eπ[f (oπ Eπ[f (oπ 1 oπ , then sπ 1 = oπ . 1 )sπ 1 = uπ 1 1 )sπ 1 oπ 1 )] + (sπ 1 )] + Eπ[f (uπ 1 = oπ 1 1 = oπ 1 )]. 1 )] < Eπ[f (oπ 1 )E[f (uπ 1 = oπ 1 ] (By submodularity and non-negativity) Using the Case 2 condition Eπ[f (uπ Substituting back into the main inequality: Eπ[f (Sπ 1 )]: Eπ[f (sπ 1 oπ )] > Eπ[f (sπ 1 )] < (1 + t)Eπ[f (oπ 1 )] + R(k 1, 1) (OP 1 )]. (1 + t)Eπ[f (oπ 1 )]). By definition of vπ 1 ) (oπ 1 )](1 (1 + t)R(k 1, 1)) + R(k 1, 1) OP . 1 ) for all π. Thus Eπ[f (sπ , (sπ Eπ[f (oπ 1 )] Eπ[f (oπ 1 )]. Eπ[f (Sπ )] > Crucially, by Lemma 7.24 (which relies on the MTC), the coefficient 1 (1 + t)R(k 1, 1) is 1 )] OP /k (Lemma 7.20). non-negative. We substitute Eπ[f (oπ Eπ[f (Sπ )] > OP (1 (1 + t)R(k 1, 1)) + R(k 1, 1) OP (cid:20) 1 = Bk,h OP T. R(k 1, 1) 1 + 1 + (cid:18) (cid:19) (cid:21) = OP In both cases, Eπ[f (Sπ )] min(Ak,h, Bk,h)OP R(k, h)OP . The induction is complete. Analysis of the Specific Recurrence We now analyze the recurrence using specific threshold function that optimizes the fluid limit. The Optimal Threshold Function We define the threshold function (k, h) = k2+h2 . Lemma 7.26. The threshold function (k, h) satisfies the Monotonic Threshold Condition (MTC). Proof. We need to show (k, h) (k 1, 1) for 2, 1. Let g(x) = (1 + x2)1/2. g(x) is strictly decreasing for 0. (k, h) = g(h/k). (k 1, 1) = g((h 1)/(k 1)). We compare x1 = h/k and x0 = (h 1)/(k 1). Since (k, h) D, h. = h = hk hk h. k(h 1) h(k 1). Since 2, > 0 and 1 > 0. (h 1)/(k 1) h/k. So x0 x1. Since g(x) is decreasing, g(x1) g(x0). Thus (k, h) (k 1, 1). Since (k, h) satisfies the MTC, Theorem 7.25 applies. The approximation ratio of the Tree Algorithm is lower bounded by R(k, k) derived using this threshold function. 76 Solving the Recurrence We now prove that the recurrence defined with (k, h) evaluates to 2 2 when = k. Theorem 7.27. Let R(k, h) be the recurrence defined using (k, h). Then for all 1, R(k, k) = 2 2. To prove this, we introduce continuous helper functions that represent the fluid limit of the recurrence and use them to establish bounds. The Continuous Helper Functions Let ρ : [0, 1] [0, 1] and : [0, 1] (0, 1] be defined as: ρ(x) = 1 + (cid:112) x2 + 1, t(x) = 1 x2 + 1 . Note that (k, h) = t(h/k). We define the comparison function (k, h) = ρ(h/k) for 1. We establish key properties of these functions. Lemma 7.28 (Properties of ρ(x) and t(x)). 1. Boundary values: ρ(0) = 0, ρ(1) = 2 2. 2. Concavity: ρ(x) is strictly concave on [0, 1]. 3. Convex Auxiliary Function: (x) = 1 1ρ(x) = x2 + 1 + is strictly convex on [0, 1]. 4. Rate 1 Identity: ρ(x) = t(x)(1 ρ(x)). (Equivalently, (x) = (x)t(x)). 5. Rate 2 Identity: ρ(x)(1 x) = 1 (1 + t(x))ρ(x). 6. Threshold Relation: ρ(x) 1 1+t(x) . 7. Monotonicity of t: t(x) is strictly decreasing on [0, 1]. 1 = 0. ρ(1) = 1 + 1 . ρ(x) = x2+1x(x/ x2+1 2 = 2 2. = (x2+1)x2 x2+1) (x2+1)3/2 = 1 (x2+1)3/2 . Since ρ(x) < 0, + 1. (x) = 1 (x2+1)3/2 . Since (x) > 0, (x) is strictly convex. x2 + 1)) = 1 x2 + 1 x) = 1 ( x2+ (1 (1 + = ρ(x). x2 + 1. t(x) = 1/S, ρ(x) = 1+xS, ρ(x) = 1x/S. LHS = (1x/S)(1x) = 1 . 1) = 1x+S 1+x . LHS = RHS. (There was slight xx/S+x2/S = 1x+ x2x RHS = 1 + S2(1+x) algebraic error in the previous drafts proof of this point, which is corrected here). . RHS = 1(1+1/S)(1+xS) = 1(1+xS+ 1+x = 1 + (x2+1)1x = 1 + x2x x2+1 x2+1 6. We want ρ(x)(1 + t(x)) 1. By the Rate 2 identity, this is equivalent to 1 (1 x)ρ(x) 1, x2 + 1 > 0. The x2 + 1 > x, ρ(x) = 1 x/ or (1 x)ρ(x) 0. Since [0, 1], 1 0. Since inequality holds. Equality holds only if = 1. 7. t(x) = 1 2 (x2 + 1)3/2(2x) = x(x2 + 1)3/2. This is negative for > 0. We next give the proof of Theorem 7.27. Proof. We use \"Diagonal Sandwich\" argument. We first prove global lower bound R(k, h) (k, h), and then prove tight upper bound at the diagonal = k. Step 1: Global Lower Bound. We prove by strong induction that R(k, h) (k, h) = ρ(h/k) for all (k, h) D, 1. Base Conditions: 77 Proof. 1. ρ(0) = 1 + 0 2. ρ(x) = 1 x2+1 ρ(x) is strictly concave. 3. (x) = 4. t(x)(1 ρ(x)) = 1 5. Let = x2+1 = 0, 1: R(k, 0) = 0. (k, 0) = ρ(0) = 0. Holds. = 1. R(1, 1). t1,1 = (1, 1) = 1/ 1+(1(1+t1,1))R(0, 0) = 1. C1,1 = Since 2 2 0.586 and 1/ 2. A1,1 = t1,1 + (1 t1,1)R(1, 0) = 1/ 2. R(1, 1) = min(1/ 2. (1, 1) = ρ(1) = 2 2 2+ = 2 2 2 0.707, R(1, 1) = 2 1 1+1/ = 2. B1,1 = 2). 2, 1, 2 2. Holds. Inductive Step: Fix (k, h) with 2, 1. Assume R(k, h) (k, h) for all (k, h) < (k, h) lexicographically. Let = h/k. Let = (k, h) = t(x). We must show Ak,h, Bk,h, Ck,h (k, h) = ρ(x). . By Lemma 7.28.6, ρ(x) 1 Analysis of Ck,h: Ck,h = 1 Analysis of Ak,h: Let = 1/k. The previous state is (k, 1). The ratio is = (h 1)/k = . So Ck,h (k, h). 1+t(x) 1+t(x) x. By IH, R(k, 1) (k, 1) = ρ(x x). Ak,h t(x)x + (1 t(x)x)ρ(x x). We want to show this is ρ(x). Let (x) = 1/(1 ρ(x)). t(x)x(1 ρ(x x)) ρ(x) ρ(x x). t(x)x (x x) 1 (x x) 1 (x) . Multiplying by (x)W (x x) (which is positive): t(x)xW (x) (x) (x x). (x x) (x) (x)t(x)x. By Lemma 7.28.4 (Rate 1 Identity), (x) = (x)t(x). (x x) (x) (x)x. This inequality holds because (x) is strictly convex (Lemma 7.28.3). convex function lies above its tangent line: (y) (x) + (x)(y x). Setting = yields the result. Thus Ak,h (k, h). Analysis of Bk,h: The previous state is (k 1, 1). Let x1 = h/k and x0 = (h 1)/(k 1). By IH, R(k 1, 1) (k 1, 1) = ρ(x0). Bk,h (cid:18) + 1 (cid:19) 1 + t(x1) 1 ρ(x0). We want to show this is ρ(x1). 1 (1 (1 + t(x1))ρ(x0)) ρ(x1) ρ(x0). We analyze the relationship between 1/k and the ratios. x1 x0 = . 1 x0 = 1 kh k(k1) (x1 x0)/(1 x0). (This assumes < k, so x0 < 1). k1 = k1(h1) = kh k1 k1 . Therefore, x1 x0 = 1 k1 = h(k1)k(h1) = (1 x0). So 1/k = k(k1) Case 1: 1 < k. In this case x0 < x1 < 1. 1 x0 > 0 and x1 x0 > 0. Substituting 1/k: x1 x0 1 x0 (1 (1 + t(x1))ρ(x0)) ρ(x1) ρ(x0). 1 (1 + t(x1))ρ(x0) 1 x0 ρ(x1) ρ(x0) x1 x0 . The RHS is the slope of the secant line of ρ(x) from x0 to x1. Since ρ(x) is concave (Lemma 7.28.2), the slope of the secant is less than the slope of the tangent at x0: It is sufficient to prove: ρ(x1) ρ(x0) x1 x0 < ρ(x0). 1 (1 + t(x1))ρ(x0) 1 x0 ρ(x0). By Lemma 7.28.5 (Rate 2 Identity) applied at x0: ρ(x0) = 1(1+t(x0))ρ(x0) 1x . We need to show: 1 (1 + t(x1))ρ(x0) 1 (1 + t(x0))ρ(x0). (1 + t(x0))ρ(x0) (1 + t(x1))ρ(x0). Since 1, x0 = (h 1)/(k 1) 0. ρ(x0) 0. We need t(x0) t(x1). Since t(x) is decreasing (Lemma 7.28.7) and x0 < x1, this holds. Thus Bk,h (k, h) when < k. 2. Here x1 = 1. t(x1) = 1/ The previous state is (k 1, 1). x0 = 1. By IH, R(k 1, 1) (k 1, 1) = ρ(1) = 2 Case 2: = k. (k 2). We want to show Bk,k (k, k) = 2 2. 2. Bk,k (cid:32) + 1 1 1 + 1/ (cid:33) 2 2). (2 We check if this is 2 2. (2 1 (cid:32) 2) 1 1 + 1/ (cid:33) 2 2) (2 (2 1 (cid:32) (cid:32) 2) 1 1 2 (cid:33)(cid:33) = (2 (cid:32) 2) 1 + 1/ (cid:33) . 1 + 1/ (cid:17) = (2 1 (2 2)(1 + 1/ 2)( 2 2+1) = 2 2+22 2 2). 2 2 = = 1. The inequality 1 1 holds. (cid:16) RHS = (2 Thus Bk,k (k, k). 2) 2+1 2 Conclusion of Step 1: We have shown Ak,h (k, h), Bk,h (k, h), and Ck,h (k, h). Therefore, R(k, h) = min(Ak,h, Bk,h, Ck,h) (k, h) for all (k, h) D. In particular, R(k, k) (k, k) = ρ(1) = 2 2. Step 2: Diagonal Upper Bound. We consider the upper bound at = k. By definition of the recurrence, R(k, k) Ck,k. tk,k = (k, k) = k/ k2 + k2 = k/ 2k2 = 1/ 2. Ck,k = 1 1 + tk,k = 1 1 + 1/ 2 = 2 2. So, R(k, k) 2 2. Conclusion of the Proof (Diagonal Sandwich): Since 2 2 (Step 2), we must have R(k, k) = 2 2 for all 1. R(k, k) 2 2 R(k, k) (Step 1) and 79 Conclusion We have rigorously established the connection between the Tree Algorithm for submodular maximization under adversarial injections and generalized recurrence relation featuring state-dependent threshold (k, h). 1. We proved that if the threshold function satisfies the Monotonic Threshold Condition (MTC), the recurrence R(k, h) provides lower bound on the expected approximation ratio of the algorithm (Theorem 7.25), correctly utilizing the inequalities inherent to submodular functions. 2. We defined specific threshold function (k, h) = k/ k2 + h2 and verified it satisfies the MTC (Lemma 7.26). 3. We analyzed the resulting recurrence using \"Diagonal Sandwich\" argument and proved that R(k, k) = 2 2 (Theorem 7.27). This implies that the Tree Algorithm achieves an approximation ratio of at least 2 2 0.5857 in the adversarial injections model. This improves upon the 0.55 approximation derived in [45] using fixed threshold analysis."
        },
        {
            "title": "Distance",
            "content": "Written by Ying Feng, David P. Woodruff, and Samson Zhou. Problem Context This case study examines several fundamental problems in streaming algorithms, but where the focus is on settings where space efficiency alone is not the only resource constraint. In addition to minimizing memory usage, modern systems often operate under limitations on write bandwidth, communication, or the frequency with which internal state can be modified. We consider four representative problems: 1. Entropy Estimation: Can the Shannon entropy of data stream be estimated with significantly fewer internal state changes than the current O( n) bound? 2. Consistent LRA: Is the optimal low-rank approximation subspace stable under row updates? 3. Efficient Encoding for LRA: Can low-rank sketches computed on different parts of the data be globally compressed without losing accuracy? 4. Chamfer Distance: Can the fast ℓ1 Chamfer distance algorithm be extended to the ℓ2 metric? Together, these problems highlight common theme: understanding how algorithmic guarantees interact with more refined complexity measures beyond space, such as stability, recourse, and internal state changes. AI Contribution Across these problems, the model played role in identifying structural properties that were not explicit in prior analyses and in turning those observations into concrete algorithmic improvements. Entropy: The model observed that the standard algorithm only queries moments Fp for 1, avoiding the high-variance regime (p = 2) entirely. This immediately implied polylogarithmic bound on the number of internal state changes. LRA Stability: The model produced proof showing that the optimal rank-k subspace changes by at most constant amount under single row insertion, using eigenvalue interlacing and dimension arguments. LRA Encoding: The model suggested decomposing local sketches into global head and quantized tail, and proved that this representation preserves projection costs with small additive error. Chamfer Distance: The model adapted the quadtree-based algorithm from ℓ1 to ℓ2, introducing dimensionality reduction step (Johnson-Lindenstrauss) to handle high dimensions efficiently. 81 7.5.1 Internal State Changes for Streaming Entropy In streaming algorithms, the foremost priority is typically to minimize the amount of memory (space) required to process stream, since data streams can be massive and cannot be stored in full. Recently, [59] noted that minimizing the number of internal state changes, which counts how often the algorithm updates its memory representation, is also reasonable secondary priority, particularly in settings with limited write bandwidth or distributed monitoring systems. In the streaming model considered here, the stream consists of sequence of elements from , where fi denotes [n] = {1, 2, . . . , n}, and the algorithm maintains frequency vector Zn 0 the number of times item has appeared in the data stream, so that each update to the stream increments the corresponding coordinate of by one. The number of internal state changes is the number of times the algorithm modifies its memory state over the duration of the data stream. The Fp moment estimation problem asks to approximate the p-th frequency moment of the stream, defined as Fp = (cid:80)n . Accurate Fp estimation is fundamental because many other statistics can be expressed in terms of frequency moments. In particular, Fp moments are central tools in streaming algorithms for estimating norms, identifying heavy hitters, and, as in this discussion, approximating Shannon entropy. i=1 Please try to improve the paper by identifying and solving an open question from it. For your proof, adhere to: rigor text. We identify and resolve an open question arising from the analysis of the entropy estimation algorithm presented in Section 3.3 of the paper. Open Question: The paper establishes in Theorem 3.8 that the Shannon entropy of an insertion-only stream can be estimated with an ε-additive error using O( n/εO(1)) internal state changes (assuming = poly(n)) and polylogarithmic space. This O( n) bound stems from the worst-case complexity of Fp moment estimation for (0, 2], which is O(n11/p), maximized as 2. The open question is: Can this O( n) upper bound on the number of state changes for streaming entropy estimation be improved? We answer this question affirmatively. By analyzing the specific moments required by the underlying [HNO08] framework used in the paper, we show that they are sufficiently close to 1 such that the polynomial dependence on vanishes. Figure 12: Model identification of open problem and progress direction Shannon entropy, defined as = (cid:80)n i=1 pi log pi with pi = fi/f 1, measures the uncertainty or information content in dataset. Estimating Shannon entropy is fundamental problem with numerous applications, including network traffic analysis (to detect anomalies or DDoS attacks), database summarization (to quantify diversity), natural language processing (to measure information content of text corpora), and data compression (to determine optimal coding schemes). Because entropy is sensitive to the entire distribution of frequencies, accurately approximating it in streaming setting is challenging and typically relies on sophisticated techniques, such as Chebyshev interpolation of multiple Fp moment estimates, as observed by [54]. [59] analyzed the internal-state complexity required for approximating Fp in one-pass insertion82 only streams. Their main theorem distinguishes two regimes: for (0, 1], (1 + ε)-approximation can be achieved with high probability using only poly (cid:0) 1 ε , log n(cid:1) internal state changes, while for 1, estimating Fp requires (cid:101)O(n11/p) internal state changes, which can be as large as ( n) when = 2. In their discussion of Shannon entropy, they interpreted the Chebyshev interpolation observation by [54] and noted that it requires evaluating multiple Fp moment estimates. They assumed the exponents lie in the range (0, 2), which implies that estimating F2 could be necessary. Because F2 sketches can incur up to internal state changes, this led to the conclusion that Shannon entropy estimation inherits an O( n) state-change cost. However, upon closer examination, the model noticed that all evaluation points in the interpolation procedure are of the form 1 + yi, where yi = (cos(iπ/k)), and showed that 1 + yi (0, 1) for all i, c.f., Lemma 7.31. This implies that the entropy algorithm never requires Fp estimates for 1, and all required frequency moments lie strictly within the low-p regime. Consequently, the worst-case (cid:0)n11/p(cid:1) state-change barrier from the 1 region is avoided. It then follows that the necessary ε , log n(cid:1) internal state changes, c.f., Theorem 7.29. As Fp estimates for (0, 1) use only poly (cid:0) 1 result, the Shannon entropy algorithm can compute an additive ε-approximation using (cid:0) 1 ε2 + log n(cid:1) ε , log n(cid:1) internal state changes, significantly improving upon the previously bits of space and poly (cid:0) 1 believed ( n) bound. Theorem 7.29. [59] Let ε (0, 1) be an approximation parameter, δ (0, 1/3) be failure probability, and be the domain size. There exists one-pass insertion-only streaming algorithm for the p-th frequency moment Fp: 1. For (0, 1]: The algorithm achieves (1+ε)-approximation (w.h.p.) using poly (cid:0)log n, 1 ε , log δ (cid:1) internal state changes and (cid:16) 1 ε2 (log log + log 1 ε ) + log(1/ε) (cid:17) log log(1/ε) log (cid:12) (cid:12) (cid:12) ε Fp (cid:104)(cid:12) (cid:12) (cid:12)(cid:99)Fp Fp bits of space. (cid:105) 2 3 , with (cid:0)n11/p(cid:1) 2. For 1: The algorithm outputs (cid:99)Fp such that Pr internal state changes. The space complexity depends on p: If [1, 2]: Space is (cid:0) 1 If > 2: Space is (cid:0) 1 ε4+4p ε4+4p n12/p(cid:1). (cid:1) polylog(mn). Algorithm 6 Additive approximation of empirical Shannon entropy Require: Error parameter ε, points {y0, . . . , yk} 1: for = 0, . . . , do Compute F1+yi 2: H(yi) log (yi) , (1 + ε)-approx. of F1+yi (cid:16) F1+yi/A 1+yi 1+yi (cid:17) 1 F1+yi/A 1+yi 1+yi 4: 5: end for 6: return estimate of H(0) or (0) by interpolating { H(yi)} or { (yi)} /yi /yi (cid:17) (cid:16) 3: Lemma 7.30. [54] To achieve an additive ε-approximation of the Shannon entropy, it suffices to implement Algorithm 6 with ε = ε + log log and yi = (cos(iπ/k)) for (y) = (k2ℓ)yℓ(k2+1) 12(k+1)3 log using points y0, . . . , yk with = log 1 , where ℓ = ε 1 (2(k+1) log . Lemma 7.31. Let yi = (cos(iπ/k)) for (y) = (k2ℓ)yℓ(k2+1) 1 + yi (0, 1) for all 0. 2k2+1 2k2+1 , with ℓ = 1 (2(k+1) log . Then Proof. Observe that 1 + yi < 1 if and only if (cos(iπ/k)) < 0 or equivalently, (k2ℓ) cos(iπ/k) ℓ (k2 + 1) < 0. Since ℓ > 0, this is equivalent to k2 cos(iπ/k) < (k2 + 1), which holds for all i, since cos(iπ/k) 1 for all i. Similarly, observe that 1 + yi > 0 if and only if (cos(iπ/k)) > 1 or equivalently, (k2ℓ) cos(iπ/k) ℓ (k2 + 1) > (2k2 + 1). Since cos(iπ/k) 1 for all i, then (k2ℓ) cos(iπ/k) ℓ (k2 + 1) > ℓ(2k2 + 1). Then, the desired claim follows because ℓ (0, 1). From Theorem 7.29 and Lemma 7.31, we have: Corollary 7.32. Given an accuracy parameter ε (0, 1) and stream of length = poly(n) over universe of size n, there exists one-pass insertion-only streaming algorithm that outputs an additive ε2 + log n(cid:1) ε-approximation (cid:98)H to the entropy of the data stream with high probability, using (cid:0) 1 bits of space and poly (cid:0) 1 ε , log n(cid:1) internal state changes. 7.5.2 Consistent Low-Rank Approximation Low-rank approximation is central tool in data analysis and machine learning. Given matrix Rnd, the goal is to find rank-k subspace, i.e., orthogonal matrix Rkd, that minimizes the approximation error AV 2 , measured in Frobenius norm. In static settings, this problem is well understood: the optimal solution is given by the top singular vectors of A, and efficient algorithms with strong guarantees are known. Many modern applications, however, are inherently dynamic. Data arrive sequentially, are corrected, or are removed, and low-rank approximations are recomputed repeatedly as part of larger pipelines. In these settings, approximation quality alone is not sufficient. Each time the output subspace changes, downstream systems may need to retrain models, update features, or revalidate decisions, all of which can be expensive. This motivates second objective beyond accuracy, namely consistency. Consistent low-rank approximation is relatively new problem formulation that makes this tradeoff explicit. Instead of computing single low-rank approximation to fixed dataset, the algorithm is asked to maintain sequence of near-optimal subspaces as the data evolve, while keeping the changes between successive outputs small. Formally, we fix an accuracy parameter ε > 0 and target rank k. The input is matrix Rnd that changes over time, e.g., rows of are revealed incrementally, or there is sequence of updates to entries of A. At each time step t, the algorithm observes the current matrix A(t) and outputs rank-k orthogonal matrix (t) Rkd. The first requirement is accuracy. For every t, the subspace (t) should give near-optimal rank-k approximation to A(t), in the sense that where A(t) A(t)(V (t))V (t)2 (1 + ε) OPTt, OPTt = min Rkd A(t) A(t)V 2 is the optimal rank-k approximation error at time t. The second requirement is stability. As the matrix evolves, the sequence of outputs (1), . . . , (n) should change minimally. We formalize this desideratum through the notion of recourse, defined as the squared Frobenius distance between consecutive subspaces. For two rank-k matrices R, Rkd, let PR and PT be the orthogonal projection matrices onto their row spans, and define Recourse(R, ) = PR PT 2 . The goal is to minimize the total recourse (cid:88) t=2 Recourse(V (t), (t1)), while still meeting the approximation guarantee at every time step. This formulation reflects the practical intuition behind consistent low-rank approximation. The algorithm is allowed to adapt as the input evolves, but large or frequent rotations of the maintained subspace are discouraged, since they correspond to costly changes in downstream representations. This notion of consistency is not addressed by standard streaming algorithms such as Frequent Directions [48], which may change their output subspaces frequently in order to achieve strong approximation guarantees, e.g., even small perturbations in the data can cause complete change in the reported subspace and leading to large recourse. However, the model noticed that the optimal rank-k subspace is inherently stable under row insertions. In other words, the recourse between the optimal subspaces before and after row insertion is bounded by fixed constant. Analyze whether the optimal rank-k subspace is stable under rank-one updates when the stream has polynomially bounded condition number. Provide rigorous proof establishing the resulting recourse bound. We show that when single row is appended to matrix, the optimal rank-k right singular subspace changes by at most constant amount. Specifically, if denote the top-k subspaces before and after the row insertion, then the squared Frobenius distance between their projection matrices satisfies Recourse(V ) 8. This establishes that the optimal subspace is inherently stable under row insertions, providing concrete bound on recourse in the row-arrival model. and t1, t1 Figure 13: Model-generated resolution of stability question in consistent low-rank approximation In particular, the model produced complete and correct proof showing: Theorem 7.33. Suppose A(t) is obtained from A(t1) by adding one new row. Let t1 and denote the optimal rank-k subspaces of the matrices before and after the update. Then the change between these two subspaces is at most Recourse(V t1, ) 8. Proof. Consider the covariance matrices Bt1 = (A(t1))A(t1), Bt = (A(t))A(t). Since A(t) is just A(t1) with the new row At appended, we have Bt = Bt1 + t At, 85 so Bt is rank-one positive semidefinite update of Bt1. By the Eckart-Young theorem, the optimal are spanned by the top eigenvectors of Bt1 and Bt, respectively. rank-k subspaces Next, we consider how much these subspaces can change. Define the subspace orthogonal to the and t1 new row as Sa = {v Rd : Atv = 0}, which has dimension 1, assuming is nonzero. Let = t1 Sa be the part of the old subspace that is unaffected by the new row. Using basic dimension counting, it follows that dim(W ) dim(V t1) (d (d 1)) = 1. For any vector , we have Btw = Bt1w, so is an eigenvector for both covariance matrices with the same eigenvalue. Let λ1 . . . λd be the eigenvalues of Bt1 and µ1 . . . µd those of Bt. By the Cauchy interlacing theorem, µ1 λ1 µ2 λ2 . . . µk λk µk+1 . . . Since , its vectors correspond to eigenvalues among the top of Bt1, and by interlacing they lie within the top + 1 eigenvectors of Bt. From this, we conclude that the intersection of the old and new subspaces has dimension at least 2. t1 Finally, consider the projection matrices Pt1 and Pt onto and . Let = t1 , t1 and let be the projection matrix onto W. If dim(W) = k, the subspaces are identical and recourse is zero. If dim(W) = 1, then Pt1 = + u1u 1 , Pt = + u2u 2 , where u1 and u2 are unit vectors orthogonal to the shared subspace. Then Pt Pt1 = u2u so by the triangle inequality 2 u1u 1 , Recourse(Pt, Pt1) 2u1u 1 2 + 2u2u 2 = 4. Similarly, if dim(W) = k2, the difference involves four rank-one terms, giving Recourse(Pt, Pt1) 8. This result has immediate algorithmic implications and has been incorporated into work accepted for publication at ICLR 2026 [92]. Although the theorem is stated for row insertions, the result also applies to row deletions by symmetry. Moreover, changes to single entry of matrix can be expressed as row deletion followed by row insertion. Thus, the result directly implies constant upper bound on recourse for these operations, thereby establishing O(1) amortized recourse bound for the dynamic model, where the matrix is updated by sequence of entry modifications, row insertions, or row deletions. 7.5.3 Global Efficient Encoding for Low-Rank Approximation In many applications, we work with large matrix Rnd, where both dimensions and may be very large. Directly storing or processing such matrices can be computationally expensive, especially when we only care about their action on low-dimensional subspaces or rank-k approximations. Low-rank approximations (LRA) provide natural tool to reduce storage and computation by approximating with matrix of rank at most min(n, d), while preserving important properties such as the Frobenius or spectral norm. more powerful guarantee is achieving projection-cost preservation. In our specific context, the rows of an input matrix Rnd arrive sequentially and the goal is to compute matrix Rmd such that for all rank-k orthogonal projection matrices Rdd, we have (1 ε)A AP 2 BP 2 (1 + ε)A AP 2 , where denotes the Frobenius norm. common setting arises when can be decomposed as concatenation of blocks, = Q1 Q2 Qm, where each block Qi Rnid represents submatrix of A. This block structure naturally appears in streaming or distributed scenarios, where each Qi corresponds to portion of the data arriving at different times or stored across multiple nodes. For each block, one can compute local low-rank approximation Wi that summarizes Qi while approximately preserving its projection costs, i.e., the squared Frobenius norm under all rank-k orthogonal projections. In particular, it is known that it suffices for Wi to just have := ε2 subsampled and reweighted rows of Qi [21]. However, naïvely storing all local approximations Wi may still be expensive, especially if or the number of rows in each local approximation Wi is large. The goal of the global efficient encoding is to compress these local sketches into representation that: 1. Uses significantly fewer bits of storage compared to storing all entries of Wi explicitly. 2. Allows efficient reconstruction of still forms good approximation to the original matrix in the sense of low-rank approximation and projection-cost preservation. such that the concatenated matrix = 1 3. Preserves provable guarantees on the Frobenius norm and spectral norm errors, as well as the Loewner ordering of Gram matrices, which are important in downstream tasks such as regression, PCA, and clustering. The model suggested the global efficient encoding for low-rank approximation depicted in Algorithm 7. The main idea behind the global encoding is to separate each block Wi into head component and tail residual with respect to global low-rank subspace determined by the top-k singular vectors of global sketch of A. Specifically, for matrix that is (1 + ε)-PCP of A, we compute its top-k right singular vectors Vk and define the projections PB = VkV , = Id PB. The head coefficients Hi = WiVk capture the component of Wi in the top-k global subspace, while the tail residual Ti = WiP contains the remaining information orthogonal to this subspace. The tail residuals are then quantized entry-wise to precision ε, providing compressed representation while controlling the additive projection-cost error. Reconstruction simply sums the head and tail contributions: = HiV + . This approach ensures that the concatenated reconstructed matrix satisfies (1 O(mε)) projection-cost preservation guarantee with respect to A, while using significantly less storage than the naive concatenation of the Wi. Moreover, the method preserves Loewner orderings of the Gram matrices up to small additive errors, which is crucial for applications that rely on positive semi-definite 87 Algorithm 7 Global efficient encoding for low-rank approximation Require: Accuracy parameter ε < 1 2 , matrix = Q1 . . . Qm, matrix Rrd that is (1 + ε)-PCP of A, matrices W1, . . . , Wm Rrd where each Wi is (1 + ε)-PCP of Qi, rank 4 Cε , where Cε = 1+ε 1ε Ensure: Encoded matrices 1, . . . , 1: Set quantization precision ε ε 2: Compute the SVD of and let Vk Rdk be the top-k right singular vectors 3: Define projection matrices PB = VkV = Id PB 4: Store Vk with high precision (e.g., O(log n) bits per entry) 5: for = 1 to do 6: Compute head coefficients Hi = WiVk and store with high precision Compute tail residual Ti = WiP Quantize Ti entry-wise to relative precision ε to obtain and store and 7: 8: 9: end for 10: for = 1 to do Reconstruct 11: 12: end for 13: return = = HiV + 1 . . . approximations. The algorithm is thus globally efficient in both space and reconstruction time, while providing strong theoretical guarantees on approximation quality. Toward establishing correctness of the proposed efficient encoding, the model first suggested the following auxiliary lemma that bounds the Frobenius norm of projected matrix. Lemma 7.34. For any projection matrix Q, it holds that WiQ2 CεBQ2 , where Cε = 1+ε 1ε . Proof. Since Wi is (1 + ε)-PCP of Qi, we have Because is the concatenation of the matrices Qj, it follows that WiQ2 (1 + ε)QiQ2 . AQ2 = (cid:88) j=1 QjQ2 QiQ2 . Moreover, as is (1 + ε)-PCP of A, we obtain Combining these inequalities yields BQ (1 ε)AQ2 . WiQ2 1 + ε 1 ε BQ2 = CεBQ2 . 88 Using this result, the model then showed that the global efficient encoding results in PCP with small additive error, which for our downstream applications can ultimately be absorbed into multiplicative error. Lemma 7.35. For every rank-k orthogonal projection matrix Rdd and each [m], Wi WiP 2 εB BP 2 i 2 Wi WiP 2 + εB BP 2 . Proof. Let = Id and fix an arbitrary [m]. It suffices to show that (cid:12) (cid:12)W Q2 WiQ2 (cid:12) (cid:12) εBQ2 . Define Ei = Wi = Ti. Then, = (Wi + Ei)Q Q2 = WiQ2 + 2WiQ, EiQF + EiQ2 . Consequently, (cid:12) (cid:12)W Q2 WiQ2 (cid:12) = (cid:12) (cid:12) (cid:12)2WiQ, EiQF + EiQ2 (cid:12) (cid:12) 2WiQF EiQF + EiQ2 , where the inequality follows from the Cauchy-Schwarz inequality. Since is projection matrix, we have EiQF EiF εTiF , which implies (cid:12) (cid:12)W Q2 WiQ2 (cid:12) (cid:12) 2εWiQF TiF + (ε)2Ti2 . By Lemma 7.34, WiQ2 top-k singular vectors of B, CεBQ2 . Furthermore, since PB denotes the projection onto the Ti2 = WiP 2 CεBP CεBQ2 . Substituting these bounds yields (cid:12) (cid:12)W Q2 WiQ2 (cid:12) (cid:12) Cε (cid:0)2ε + (ε)2(cid:1)BQ2 . completes the proof. Choosing ε ε 4 Cε Finally, we analyze the space complexity of the global efficient encoding. Lemma 7.36. The global encoding scheme can be represented using (cid:18) (cid:18) kd log + mrk log + mrd log (cid:19)(cid:19) 1 ε + log log bits of space in total. Proof. The storage cost consists of three components. First, the matrix Vk Rdk is stored at high precision, requiring O(kd log n) bits. Second, each head coefficient matrix Hi Rrk is stored at high precision, contributing total of O(mrk log n) bits across all [m]. Finally, each tail residual is stored using entry-wise quantization with precision parameter ε. This quantization requires (cid:0)log 1 ε + log log n(cid:1) bits per entry, giving total of (cid:18) (cid:18) mrd log (cid:19)(cid:19) 1 ε + log log bits for all residuals. Summing these three contributions gives the stated space bound. 89 The existence of global efficient encoding has immediate implications for low-rank approximation. In particular, it enables the construction of projection-cost preservation sketches in single pass over the data, using k2 ε2 polylog (cid:18) 1 ε (cid:19) , log(ndκ) + (cid:19) (cid:18) dk ε2 words of space and input-sparsity runtime. Here, κ is term related to the condition number of the data stream, which essentially captures the worst-case arrival of the matrix over the data stream, e.g., if small rows arrive first and the larger rows arrive later. This quantitatively matches the best known offline coreset constructions while improving over previous streaming algorithms by removing extra logarithmic factors, making the space essentially independent of for low-rank projections. Consequently, high-accuracy low-rank approximations are achievable efficiently in streaming settings, closing the gap between streaming and offline performance and enabling fast, memory-efficient dimensionality reduction and randomized matrix computations. 7.5.4 Even Faster Algorithm for the Chamfer Distance The Chamfer distance is popular quantification of the dissimilarity between point clouds. For any two d-dimensional point sets A, of sizes up to n, the Chamfer distance from to is defined as CH(A, B) = (cid:88) aA b min bB where is the underlying norm defining the distance between two points, such as the Euclidean or Manhattan distance. While the naive algorithm for the Chamfer distance takes O(dn2) time, recently, [6] proposed the first near-linear-time algorithm to approximate the Chamfer distance. Their algorithm works for the underlying norm being ℓ1 or ℓ2, and outputs an (1 ε)-approximation in time O(dn log(n)/ε2). When ε is constant, this leaves gap of O(log n) between the upper bound and the trivial Ω(dn) lower bound. Towards closing this gap, [37] proposed faster algorithm for the ℓ1 norm. This leads to the natural question of whether the improvement generalizes to the ℓ2 norm. The model answers this question in affirmative. Initial Improvement in the Low-Dimensional Regime As summarized in Figure 14, with generic initial prompt, the model identifies the open problem and the key ingredient to focus on. It then gives proof in the ℓ2 norm, which improves over the runtime of [6] in the low-dimensional regime ( log n/ log log n). The proof focuses on data structure called quadtree. quadtree of depth is defined by random offset vector [0, 2t]d. It assigns every point in Rd with sequence of hash values, using nested grids shifted by z. Concretely, for any Rd and any integer such that 0 t, it hashes hk(a) := ( a1+z1 [37] used two independent quadtrees to estimate the nearest neighbor distance for all in ℓ1, i.e. estimating minbA b1 for all A. The model follows similar proof structure and analyzes the behavior of quadtrees in ℓ2 as follows: 2k , , ad+zd 2k , a2+z2 2k ). Lemma 7.37. For all a, Rd and 0 t, if hk(a) = hk(b), then b2 2k d. Proof. If hk(a) = hk(b), then a, lie in the same d-dimensional cube of side-length 2k. The ℓ2 diameter of such cube is 2k d. Lemma 7.38. With probability 1 O(1/n), the following holds simultaneously for all a, b, k: If hk(a) = hk(b), then b2 2k 3 log n. Proof. Lemma 3.4 of [37] shows that a, b, : b1 2k 3 log with probability 1 O(1/n). Combining this with the fact that b1 b2 concludes the proof. With the above lemmas, the model shows that in expectation, two quadtrees output good estimation to opta := minbA b2 for all A. The estimator Da is defined as: 1. Identifying the smallest such that hk(a) = hk(b) for some across the two quadtrees.4 2. Assigning Da := b2 for arbitrary such that hk(a) = hk(b). Lemma 7.39. With probability 1 O(1/n), it holds for all that EDa opt(a), where = O(min(d3/2, log n)). Proof. We need the following fact: Fact 7.40 ([6]). Pr[hk(a) = hk(b)] ab1 2k . Similar to Theorem 3.5 in [37], we condition on Lemma 7.38 and fix A. Let := log(opta). And let Ek be the event that = (recall that we identified unique when defining the estimator). If Ek occurs, the estimator Da is bounded by 2k for = O(min( d, log n)). Thus EDa (cid:88) Pr[Ek] 2k . 0kt We split the sum based on and > k. The first part is bounded by opta (cid:88) kk Pr[Ek] opta. For the second part (k > k), we fix := arg minbB b2. Event Ek implies that hk1(a) = hk1(b) in two independent quadtrees. Therefore, Pr[Ek] ( b1 2k )2 ( da b2 2k1 )2 = d(opta)2 22k2 because b1 da b2. Now we can bound the summation for > k: Pr[Ek] 2k F (cid:88) k>k d(opta)2 22k2 (cid:88) k>k 2k 4 opta (cid:88) k>k opta 2k = O( dopta). Thus, EDa = O( d) opta , i.e. the approximation factor is = O(min(d3/2, log n)). As outlined in Figure 14, the rest of the algorithm in [37] works the same regardless of the underlying norm. And the total runtime can be derived from the bound on the approximation factor . This leads to the conclusion (Theorem 7.41). 4For simplicity, assume that we chose so that there always exists such t. 91 Please try to improve the paper by identifying and solving an open question from it. For your proof, adhere to: rigor text. [37] presents an improved algorithm for approximating the Chamfer distance in the ℓ1 metric, achieving runtime of O(dn(log log(n) + log 1 ε )/ε2). However, they note that extending this improvement to the ℓ2 metric is challenging. The standard approach, used in prior work [6] , involves embedding the points from ℓ2 to ℓ1, which takes O(dn log(n)/ε2) time, thereby eliminating the speedup. The authors leave finding faster embedding algorithm, or consequently faster ℓ2 Chamfer distance algorithm, as an open problem. We address this open problem by analyzing the performance of the proposed algorithmic framework when adapted directly to the ℓ2 metric. We show that the new techniques can yield faster algorithm for the ℓ2 Chamfer distance when the dimension is relatively small. Overview of the Approach: The algorithm presented in the paper consists of three main components: 1. QuadTree: fast procedure using quadtrees to compute crude estimates Da of opta := minbB b. This runs in O(dn log log n) time. 2. Tournament: An algorithm to efficiently compute O(1)-approximations of opta batch of sampled points. for 3. Rejection Sampling: framework that uses the estimates from QuadTree and Tournament to perform importance sampling and estimate the Chamfer distance. The efficiency of the overall algorithm depends on the approximation factor achieved by the QuadTree step. If QuadTree provides an -approximation in expectation (i.e., EDa ), the overall runtime is dominated by the QuadTree and Tournament steps. The opta Tournament runs in time roughly O(n(d + F/ε2) log(F/ε2)). For the ℓ1 metric, the authors prove = O(min(d, log n)). This leads to the improved O(dn log log n/ε2) runtime. We analyze the approximation factor when the framework is applied to the ℓ2 metric. [Proofs to Lemma 7.37, 7.38, 7.39] Conclusion: We have shown that the techniques introduced in the paper can be adapted directly to the ℓ2 metric to yield faster algorithm for the Chamfer distance, provided the dimension is small. Theorem 7.41. There is an algorithm that computes (1 + ε)-approximation to the Chamfer distance under the ℓ2 metric in time O(n(F/ε2)(log(F/ε2) + log log n)), where = O(min(d3/2, log n)). This runtime constitutes an improvement over the previous O(dn log(n)/ε2) when d1/2(log d+ log(1/ε) + log log n) = o(log n). Figure 14: Model identification of problem and initial solution. Refined Improvement for Any Dimension. Following the initial response of the model, we asked the model to focus on improving the high-dimensional case. the model refines the previous Lemma 7.39 and combines it with fast Johnson-Lindenstrauss Transform. This gives an algorithm 92 for ℓ2 that matches the runtime of ℓ1 in [37] for any dimension d, thus improving the previous best runtime from [6]. Lemma 7.42 (Refinement of Lemma 7.39). With probability 1 O(1/n), it holds for all that EDa opt(a), where = O(min(d, log n)). Compared to Lemma 7.39, this proof switches from ℓ1 to ℓ2 in later stage. This switch applies d. Intuitively, we want this to happen after 1 multiplying the probabilities of two independent quadtrees. This is precisely what the model changes. 2, thus introducing an extra factor of Proof. As before, we fix := arg minbB b2. But now we define := log(a b1). We again split EDa (cid:80) 0kt Pr[Ek] 2k based on and > k, and bound the first part by 2k (cid:80) kk Pr[Ek] a b1. For the second part, Pr[Ek] 2k F (cid:88) k>k ( b1 2k1 (cid:88) k>k )2 2k 4 a b1 b1 2k (cid:88) k>k = O( a b1). Thus, EDa = O( )ab1 O( d)opta . The approximation factor is = O(min(d, log n)). As mentioned in Figure 15, this gives O(dn(log + log log + log 1 ε )/ε2). For poly(n)- time algorithm, this improves the best known runtime of ℓ2. Moreover, for poly(log n), this already matches the best known runtime of ℓ1. Finally, to handle larger d, the model applies fast Johnson-Lindenstrauss transform to reduce the dimension, and then estimate the Chamfer distance. Note that while the model claims the existence of an (unconditional) O(dn)-time JL transform, which we are not aware of, there indeed exists an O(dn log m)-time JL transform that reduces the dimension to = O(log2 n/ε2) [33], which suffices for the final conclusion (Theorem 7.43). We have incorporated this result, together with other results on ℓp versions of Chamfer and in streaming models, into submission [38]. The model was also very helpful for verifying correctness of different parts of the submission. 93 Focus on improving the high dimensional regime. Concretely, try (1) using an ℓ2-native scheme, and (2) modifying later stages of the algorithm. We begin by rigorously analyzing the performance of the QuadTree estimator when adapted to the ℓ2 metric. This analysis provides tighter bound than the one presented in the preamble and establishes the baseline performance. [Proof to Lemma 7.42] This leads to O(dn(log + log log + log 1 ε )/ε2) total runtime. If is large (e.g., = poly(n)), the runtime matches the previous state-of-the-art O(dn log n/ε2), offering no substantial improvement. Strategy (1) proposes using an ℓ2-native approach. We can achieve this by employing dimensionality reduction via the Johnson-Lindenstrauss (JL) transform before applying the framework. This reduces the dimension from to = O(log n/ε2), thereby reducing the impact of the dimension on the approximation factor . Fast Johnson-Lindenstrauss (JL) Transform: Given points in Rd and ε > 0. Let = O(log n/ε2). There exists randomized linear map : Rd Rm such that with high probability, it preserves all pairwise ℓ2 distances within (1 ε). Furthermore, the map can be applied to all points in total time O(dn). Theorem 7.43. Assuming the fast Johnson-Lindenstrauss (JL) transform, there is an algorithm that computes (1 + ε)-approximation to the Chamfer distance under the ℓ2 metric in time O(dn(log log + log 1 ε )/ε2). [For large d, this is justified by plugging in into the previous time bound.] Figure 15: Model refinement of the analysis and final solution."
        },
        {
            "title": "8 Resolving Conjectures and Complex Derivations",
            "content": "Distinct from the algorithmic optimizations in the previous section, here the AI acts as heavylifting theoretical mathematician. These case studies showcase the AIs ability to build theory from scratchexecuting complex continuous derivations, extending theorems via measure theory, and constructing novel computational reductions. 8.1 Information Theory: The Courtade-Kumar Conjecture Written by Adel Javanmard. AI Contribution The AI made two distinct contributions to the Courtade-Kumar conjecture. First, it successfully generalized known theorem to unbalanced functions and improved entropy bounds in the high-noise regime using hypercontractivity and Taylor expansions (Section 8.1.1). Second, it made structural progress on the unsymmetrized version of the conjecture by analyzing continuous relaxations and proving local optimality (Section 8.1.2). 8.1.1 Part I: Generalization to Unbalanced Functions The Courtade-Kumar Conjecture An intriguing question in information theory, formalized by Courtade and Kumar [23] in 2014, asks how to optimally compress noisy signal into single bit to preserve information about the original source. Specifically, let be i.i.d Bernoulli(1/2) and let be noisy observation of n, generated by passing the input through memoryless binary . The core optimization challenge is to symmetric channel with crossover probability 0 < α < 1 2 identify Boolean function : {0, 1}n {0, 1} that maximizes the mutual information I(b(X n); n), or equivalently I(b(Y n); n). Courtade and Kumar conjectured that this quantity is bounded by I(b(X n); n) 1 H(α) , (27) where H(α) = α log α (1 α) log(1 α) represents the binary entropy function. This upper bound is achieved when is dictatorship function, defined as b(X1, . . . , Xn) = Xi for any fixed index {1, . . . , n}. Essentially, the conjecture posits that no Boolean function is more informative than simply selecting the value of single coordinate. Recent Progress and Partial Results following result, which is weaker version5 of the conjecture: In their original paper [23], the authors established the Theorem 1[23]: If b(X n) is equiprobable, then (cid:88) i=1 I(b(X n); Yi) 1 H(α) . (28) This is still significant result given that the left hand side is the sum of mutual information terms, while the right-hand side does not depend on n. Also, note that Theorem 1 above is only proved in the case of equiprobable boolean functions. In Section IV of [23], the authors ask the following question: 5It is weaker form of the main conjecture because (27) is equivalent to I(b(X n); n) = (cid:80)n i=1 I(Y i1, b(X n); Yi) 1 H(α) by independence of Yis. 95 Does Theorem 1 continue to hold when b(X n) is not equiprobable? Unfortunately, our Fourier-analytic proof of Theorem 1 appears to fail in this setting. Nonetheless, we feel that establishing this generalization of Theorem 1 should be considerably easier than establishing the main conjecture. Since its introduction, the conjecture (27) has generated substantial interest, leading to several partial results. Chandar and Tchamkerten [18] established the bound: Building on this, Ordentlich, Shayevitz, and Weinstein [74] derived the following bound for the I(b(X n); n) (1 2α)2 . (29) interval 1 2 (1 (cid:113) 1 3 ) α 1 2 : I(b(X n); n) log(e) (1 2α)2 + 9 (cid:18) 1 (cid:19) log(e) 2 (1 2α) (30) . Leveraging this This result provides tighter bound than (29) within the range 1 improved bound, Samorodnitsky [78] successfully proved that the conjecture holds for all α 1 2 δ, where δ > 0 is an absolute constant. While these results represent significant milestones, the main conjecture (27) remains open in its full generality. 3 α 1 2 Partial Resolution of the Courtade-Kumar Conjecture by Gemini We asked Gemini to try to solve the Courtade-Kumar conjecture and provided their paper as input. Can you prove Conjecture 1 stated in this paper or make progress on it (Which Boolean Functions Maximize Mutual Information on Noisy Inputs)? We analyze the conjectures and open questions presented in the paper Which Boolean Functions Maximize Mutual Information on Noisy Inputs? by Courtade and Kumar. The main conjecture (Conjecture 1) remains open. However, we provide complete resolution to the first open question posed in Section IV, generalizing Theorem 1 to arbitrary (nonbalanced) Boolean functions. Figure 16: Model identification of open problem and progress direction As illustrated in Figure 16, while the model could not solve the main conjecture, it identified the open problem from Section IV of the paper and provided complete resolution. Specifically it proves the following theorem, which confirms that Theorem 1 holds even when b(X n) is not equiprobable. Theorem 8.1 (Generalized Theorem 1). Let be i.i.d. uniform on {1, 1}n, and let be the output of BSC(α) with input n. For any Boolean function : {1, 1}n {1, 1}, (cid:88) i= I(b(X n); Yi) 1 H(α). 96 Geminis proof employs Fourier-analytic techniques analogous to those in [23] to establish Theorem 1, yet Gemini independently refined the derivation of Theorem 1 to address scenarios where the distribution of b(X n) is non-uniform. For this problem, while we maintained minimal oversight throughout the process, many intermediate steps were cryptically generated, requiring us to query the system multiple times for clarification. The formal proof of Theorem 8.1 is presented below. The proof outline involves an analysis of the optimization landscape, where we demonstrate that the objective functionviewed as function of the squared level-1 Fourier coefficientsis convex. We then characterize the extreme points of the feasible region defined by Parsevals identity and spectral bounds. Finally, the proof establishes non-trivial inequality involving derivatives of the mutual information expression with respect to ρ. key distinction from the proof strategy in [23, Theorem 1] is our demonstration that the objective function is maximized by Boolean functions that are monotone in each coordinate (defined via 1-d compression operator). Using this structure we can impose tighter constraints on the feasible set which allows us to generalize the result of [23, Theorem 1] to all Boolean functions. Strengthening the High-Noise Regime Results We further explored potential improvements to the results established by Samorodnitsky [78], which proved that the Courtade-Kumar conjecture holds in the high-noise regimespecifically, when the noise parameter α is sufficiently close to 1/2 (i.e., λ = 1 2α < δc for an absolute constant δc > 0). Initially, when provided with [78] as input, the system produced concise summary of the methodology in [78] without offering immediate novel insights. Can you make further progress on the conjecture using this work? We analyze the maximization of convex functional related to entropy under the noise operator, focusing on the conjecture that the Dictatorship function is the optimizer. We provide rigorous proof for the high noise regime, following the methodology of A. Samorodnitsky in On the entropy of noisy function. Figure 17: Model identification of open problem and progress direction However, this summary served as useful primer for distilling the core proof techniques. Through iterative prompting and self-correction cycles, we tasked the system with refining Samorodnitskys result. After several rounds of checking its own logic, the model claimed to have established an improvement on the threshold δc. Technical Verification and Error Correction. While the initial output appeared structurally sound and cited relevant literature correctly, manual review revealed subtle technical inaccuracies. Specifically, the system invoked the Bonami-Beckner hypercontractivity inequality with an incorrect assumption: For function supported on Fourier levels k, and 2, hq ( 1)kh2. Our attempts to verify this claim led us to realize that the inequality holds for functions supported on Fourier levels k, rather than k. Upon being prompted to resolve this discrepancy, the system initially defended its original statement. However, after several rounds of probing, it provided proof 97 that allowed us to pinpoint specific line where an inequality direction had been flipped. Once this error was identified, the system conceded the mistakeillustrating its tendency to present subtle errors with high confidence. Final Result and Methodology. The system eventually derived an alternative proof that bypassed these initial errors. By incorporating our feedback regarding seemingly trivial (but actually false) claim, the model produced rigorous proof that improved upon the result of [78]. This final proof technique synthesizes the methodology of [78] with higher-moment analysis to establish optimal Fourier concentration for highly informative Boolean functions. We summarize the main result below. Theorem 8.2 (Extended Range for the Conjecture). There exists an absolute constant δopt > 0 such that if the noise parameter λ δopt, the Courtade-Kumar conjecture holds. Furthermore, δopt is strictly larger than the thresholds previously established in [78]. Observations on AI-Assisted Research. Our interactions with the system on these theoretical problems yielded several key insights into its utility as research partner: Effective Jumpstarting: The model is exceptionally adept at identifying relevant ideas across disparate fields and literature, making it an excellent tool for generating an initial line of thought. The Mid-PhD Analogy: Its performance is comparable to mid-level PhD student; it is most effective when the researcher provides high-level proof strategy and tasks the system with making the steps rigorous or connecting logical gaps. The results of this part were used to write full paper [58] using vibe proving methodology. In this workflow, we defined the lemmas and tasked the AI with drafting the proofs, which were then rigorously verified and refined by us. Scale and Complexity Limits: While the system excels at solving isolated, small-scale problems (akin to IMO-style challenges), it still struggles with the expansive, multi-stage reasoning required for long-term research projects. Researchers must remain vigilant, as the system can be confidently incorrect regarding subtle technical details. Proof of Theorem 8.1 Due to the complexity of this derivation, the AI struggled to generate complete, flawless proof in single shot. The formal proof below is the result of our vibe-proving methodology: it was drafted and rigorously verified by the human researchers, who stitched together the correct intermediate lemmas, structural insights, and Fourier-analytic techniques discovered iteratively by the AI. Proof. Recall the crossover probability 0 < α < 1 2 and define ρ = 1 2α. Any Boolean function : {1, +1}n {1, 1} can be written in terms of its Fourier coefficients as b(xn) = (cid:88) S[n] ˆb(S)ΠS(xn) , where ΠS(xn) = ΠiSxi are the orthonormal basis for the Fourier transform and {ˆb(S)}S[n] are the Fourier coefficient defined by For = , we define ΠS(xn) = 1. ˆb(S) = Eb(X n)ΠS(X n) . 98 Let µ = E[b] = ˆb() be the bias, and zi = ˆb({i}) be the level-1 Fourier coefficients. The objective function is: L(b) = (cid:88) i=1 I(b; Yi) = (cid:88) (H(b) H(bYi)). i=1 (31) Since the range of is {1, +1}, the entropy H(b) is determined by the bias Pr[b = 1] = 1+E[b] hence we can write H(b) = H( 1+µ 2 ). Using relation (34) from [23], we have 2 = 1+µ , Pr[b = 1Yi = yi] = 1 + µ + ρyizi 2 , and since the marginal distribution of Yi is uniform on {1, +1}, we get H(bYi) = 1 2 [H(Pr[b = 1Yi = 1]) + H(Pr[b = 1Yi = 1]) .] (32) Therefore we obtain H(bYi) = hµ(zi), where hµ(z) := 1 (cid:18) 1 + µ + ρz 2 (cid:19) + 1 2 (cid:18) 1 + µ ρz 2 (cid:19) . Let gµ(z) = H(b) hµ(z). By (31), we want to maximize (cid:80)n the Fourier coefficients of Boolean function. i=1 gµ(zi) subject to the constraints on Step 1: Reduction to Monotone Functions. Let : {1, 1}n {1, 1} be Boolean function. The 1-d compression operator along coordinate i, denoted as Ci, rearranges the values of the function along the i-th dimension to make it monotone while preserving the total number of 1s. Specifically, for any input {1, 1}n, let = (xi, xi), where xi are all bits except i. The operator acts on the pair of values (f (xi, 1), (xi, 1)): Cif (xi, xi) = if xi = 1 and (xi, 1) + (xi, 1) 0 if xi = 1 and (xi, 1) + (xi, 1) = 2 1 1 1 otherwise (33) We show that 1-d compression increases the objective function L(b). Lemma 8.3. Let be the compression of along coordinate j, making it non-decreasing in xj. The Fourier coefficients satisfy: 1. zi(b) = zi(b) for = j. 2. zj(b) zj(b). Note that hµ(z) = hµ(z) and the function hµ(z) is decreasing in z, hence by Lemma 8.3 hµ(zj(b)) hµ(zj(b)). Thus, (cid:80) H(bYi) decreases under compression and L(b) = (cid:80) I(b; Yi) increases. This implies that the maximum must be attained by function that is monotone along each coordinate. We assume is non-decreasing, so zi(b) 0, for [n], by the next lemma. Lemma 8.4. Suppose that is non-decreasing Boolean function, i.e., for any input x, changing the i-th bit from 1 to 1 either increases the function value or keeps it the same: b(xi, 1) b(xi, +1). Then zi(b) := ˆb({i}) 0. 99 We will also use the following lemma in the next step. Lemma 8.5. For any Boolean function : {1, 1}n {1, 1}, with µ = E[b] and zi = ˆb({i}) the level-1 Fourier coefficients, we have zi 1 µ. Step 2: Optimization over Monotone Functions. We analyze the structure of the optimization problem. Let wi = z2 w). It can be shown that ψµ(w) is strictly convex for > 0 (Equivalently, hµ( w) is strictly concave in w). . Define ψµ(w) = gµ( We want to maximize the convex function (cid:80)n i=1 ψµ(wi) subject to constraints on the Fourier coefficients. The constraints are: 1. wi 0 2. (cid:80)n i=1 wi 1 µ2 = R2 (Parsevals theorem). 3. wi (1 µ)2 = C2 (Since 0 zi 1 µ by Lemmas 8.4 and 8.5). The maximum of convex function over this polytope is attained at an extreme point. Let = R2/C2 = (1 µ2)/(1 µ)2 = (1 + µ)/(1 µ). We analyze two cases based on the relationship between and K. Without loss of generality, assume µ 0. Step 3: Bounding the Maximum (Case 1: K). If K, the constraint (cid:80) wi R2 is the dominant constraint. The extreme points (up to permutation) have = coordinates equal to C2, one coordinate equal to θC2 (where θ = k), and the rest are 0. The maximum value is: (µ) = kψµ(C2) + ψµ(θC2). We verify that ψµ(0) = 0. Note that ψµ(0) = gµ(0) = H(b) hµ(0). Since hµ(0) = H( 1+µ we have ψµ(0) = 0. Using the convexity of ψµ(w) and ψµ(0) = 0: 2 ) = H(b), ψµ(θC2) = ψµ(θC2 + (1 θ)0) θψµ(C2) + (1 θ)ψµ(0) = θψµ(C2). Thus, the maximum is bounded by: (µ) kψµ(C2) + θψµ(C2) = (k + θ)ψµ(C2) = Kψµ(C2) = Kgµ(C). Recall that = 1 µ and = (1 + µ)/(1 µ), and so µ and are determined by as follows: µ = 1 + 1 , = 2 + 1 . Let MK(ρ) := Kgµ(C), where we made the dependence on ρ = 1 2α explicit in the notation. We aim to show MK(ρ) 1 H(α). Writing MK(ρ) more explicitly, we have MK(ρ) = KH(b) (cid:18) = KH 2 (cid:19) (cid:19) (cid:18) 1 + µ + ρC 2 (cid:18) + ρ + 1 2 (cid:19) 2 2 (cid:18) 1 + µ ρC 2 (cid:18) ρ + (cid:19) (cid:19) , + 1 where we used that H(b) = H( 1+µ want to show MK(ρ) M1(ρ) for 1. 2 ) = H( K+1 ). Note that M1(ρ) = 1 H( 1+ρ 2 ) = 1 H(α). We 100 Observe that MK(0) = 0 for all K, so it suffices to show that the derivative with respect to ρ satisfies K(ρ) 1(ρ). The derivative is calculated as: K(ρ) = 2(K + 1) ln ln (cid:18) (1 + ρ)(K + ρ) (1 ρ)(K ρ) (cid:19) . Let = 1+ρ 1ρ . Then 1(ρ) = 1 K(ρ) 1(ρ) is equivalent to: 2 ln 2 ln(A). The inequality (cid:18) (cid:19) + ln + ρ ρ ln A. Rearranging this inequality yields: (cid:18) + ρ ρ ln (cid:19) ln ln (cid:19) (cid:18) 1 + ρ/K 1 ρ/K ln (cid:18) 1 + ρ 1 ρ (cid:19) . Let (x) = 1 (x) = 2 (cid:80) j=0 (ρ/K) (ρ). ln( 1+x x2j 2j+1 1x ). The inequality is equivalent to (ρ/K) (ρ). The Taylor series is , which is strictly increasing for > 0. Since 1, we have ρ/K ρ, thus The inequality K(ρ) 1(ρ) holds. Integrating from ρ = 0 yields MK(ρ) M1(ρ) = 1 H(α). Step 4: Bounding the Maximum (Case 2: < K). If < K, then nC2 < R2. The Parseval constraint (cid:80) wi R2 is inactive. We maximize the convex function (cid:80) ψµ(wi) subject to the box constraints 0 wi C2. Therefore the maximum is attained at an extreme point. In addition, ψµ(C2) = gµ(C) 0 (as it represents mutual information). Also, ψµ(0) = 0, and so ψµ(C2) ψµ(0). Therefore, the maximum is attained when wi = C2 for all [n]. The objective value is: (cid:88) i= ψµ(wi) = nψµ(C2) = ngµ(C) < Kgµ(C) = MK(ρ), Since gµ(C) 0 (as it represents mutual information) and < K. From Step 3, we established MK(ρ) 1 H(α). In both cases, the total mutual information is bounded by 1 H(α). Proof of Lemma 8.3 We first prove that xi(b) = xi(b) for = j. Recall the definition of the Fourier coefficient zi(b) = E[b(X n)Xi]. Since = j, Xi is independent of Xj. Let Xj denote the bits of excluding index j. We write zi(b) = EXj (cid:20) Xi 2 (cid:21) (b(Xj, 1) + b(Xj, 1)) Now consider the compressed function b. By definition, compression locally rearranges the pair (b(xj, 1), b(xj, 1)) into (b(xj, 1), b(xj, 1)) such that the sum is preserved : b(xj, 1) + b(xj, 1) = b(xj, 1) + b(xj, 1) Substituting this back into the expectation: zi(b) = EXj (cid:20) Xi 2 = E[b(X n)Xi] = zi(b) (cid:16)b(Xj, 1) + b(Xj, 1) (cid:17)(cid:21) Thus, zi(b) = zi(b) for = j. on Xj: We next show that zj(b) zj(b). Expand the Fourier coefficient for index by conditioning zj(b) = 1 2 EXj [b(Xj, 1) b(Xj, 1)] By definition, compression locally rearranges the pair (b(xj, 1), b(xj, 1)) into (b(xj, 1), b(xj, 1)). Therefore, b(xj, 1) b(xj, 1) = b(xj, 1) b(xj, 1) for any value of xj. Hence, zj(b) = = = 1 2 1 2 1 2 1 (cid:12)EXj [b(Xj, 1) b(Xj, 1)](cid:12) (cid:12) (cid:12) (cid:104) EXj [b(Xj, 1) b(Xj, 1)] (cid:105) b(Xj, 1) b(Xj, 1) (cid:105) (cid:104)b(Xj, 1) b(Xj, 1) EXj EXj = zj(b) , where in the first step we used the convexity of absolute value (E[Y ] E[Y ]). In the third equality, we used the assumption that is non-decreasing in the j-th bit. Note that this also implies that zj(b) 0, which completes the proof. Proof of Lemma 8.4 We can expand the expectation by conditioning on the value of the random variable Xi. Since is uniform, Xi takes values 1 and +1 with probability 1/2 each. zi(b) = E[b(X n)Xi] = 1 2 E[b(X n)Xi Xi = 1] + 1 E[b(X n)Xi Xi = 1] (34) Substitute the value of Xi into the expression: zi(b) = = 1 2 1 E[b(Xi, 1) (1)] + 1 2 E[b(Xi, 1) (1)] Exi [b(xi, 1) b(xi, 1)] (35) We are given that is non-decreasing bit-wise. Therefore, for every possible setting of the other bits xi, we have b(xi, 1) b(xi, 1). Thus, zi(b) 0. Proof of Lemma 8.5 Let E+ = E[b(X) Xi = +1] and = E[b(X n) Xi = 1] respectively denote the average value of the function when the i-th bit is fixed to +1 and 1. Since outputs values in {1, 1}, we have 1 E+, 1. In addition, we have µ = 1 2 E+ + 1 zi = E[b(X)Xi] = 1 2 E+ 1 + 1 2 (1) = E+ 2 Hence µ + zi = E+ and µ zi = and the claim follows from the fact that E+ 1 and 1. 102 Proof of Theorem 8.2 Preliminaries and Notation We analyze functions on the Boolean hypercube {1, 1}n. We follow the setup used in [78]. Let : {1, 1}n be bounded, non-negative function, normalized such that E[f ] = 1. We assume . (When analyzing Boolean function b, we typically look at the indicator function of the event b(x) = 1). Let α [0, 1/2] be the noise parameter. The noise operator Tα acts on as (Tαf )(x) = Ey[f (y)], where is obtained from by flipping coordinates with probability α. Let ρ = 1 2α. In the Fourier domain, Tα acts as multiplier: (cid:100)Tαf (S) = ρS ˆf (S). We define the noise parameter λ = ρ2 = (1 2α)2. We consider the high noise regime, where λ is small. We decompose into its even part f0 and odd part 1: f0(x) = (x) + (x) 2 , f1(x) = (x) (x) 2 . Note that E[f0] = 1. We define the noisy versions: = Tαf0, = Tαf1. Note that Tαf = + Z. We define = 1. Since E[F ] = 1, we have E[Y ] = 0. The Fourier coefficients satisfy ˆF (S) = λS/2 ˆf0(S) and ˆZ(S) = λS/2 ˆf1(S). (and ) are supported on even Fourier levels, while is supported on odd levels. The level 1 Fourier weight is L1(f ) = L1(f1). We utilize the entropy decomposition established in [78] (Lemma 6.2): Lemma 8.6 (Entropy Decomposition). Ent(Tαf ) Ent(F ) + 1 2 ln (cid:21) (cid:20) Z2 + (cid:18) (cid:20) Z4 3 (cid:21)(cid:19) . It is known that Ent(F ) = O(λ2) (Lemma 5.4 in [78]). We also rely on crucial dominance property. Lemma 8.7 (Dominance). 0 and . Proof. Note that by definition of the even and odd parts of , we have f0(x) + f1(x) = 2f (x) f0(x) f1(x) = 2f (x) Since 0, we have f1(x) f0(x). The noise operator Tα is positive operator, preserving non-negativity and dominance. Thus = Tαf1 Tαf1 Tαf0 = . Hypercontractivity and Moment Bounds We rely on the Bonami-Beckner Hypercontractivity Theorem. standard application is for homogeneous polynomials. Corollary 8.8 (Hypercontractivity for Homogeneous Polynomials). Let hk be homogeneous polynomial of degree k. For 2, hkq ((cid:112)q 1)khk2. We must be careful when applying this to functions supported on multiple levels. We use the Minkowski inequality combined with Corollary 8.8 to establish rigorous moment bounds. Lemma 8.9 (Moment Bounds). Assuming is bounded by , the following bounds hold as λ 0: 1. E[Y 2] = O(λ2). 2. E[Y 3] = O(λ3). 3. E[Z2] = λL1(f ) + O(λ3). 4. E[Z4] = O(λ2). 5. E[Z2Y ] = O(λ2). Proof. We assume λ is small enough (e.g., 3λ < 1). Since is bounded, its L2 norm is also bounded (f 2 ). Part 1: E[Y 2] = O(λ2). is supported on even levels 2. E[Y 2] = (cid:88) λk (cid:88) ˆf0(S)2 k2,even λ2 (cid:88) S=k ˆf0(S)2 = λ2Var(f0) = O(λ2). S= Part 2: E[Y 3] = O(λ3). We analyze = Y2 + Y4 using the L3 norm. 1. Bounding Y23. Use = 3, = 2. The constant is 2. Y23 2Y22. Y22 2 = O(λ2). Thus, Y23 = O(λ). 2. Bounding Y43. Y43 (cid:88) 4, evenYk3 (cid:88) 4, evenM ( 2λ)k = O(λ2). 3. Combining the bounds. 3 = O(λ). Therefore, E[Y 3] = O(λ3). Part 3: E[Z2] = λL1(f ) + O(λ3). is supported on odd levels 1. E[Z2] = λL1(f1) + (cid:88) λk (cid:88) ˆf1(S) k3,odd = λL1(f ) + O(λ3). S=k Part 4: E[Z4] = O(λ2). We decompose = Z1 + Z3. We use the Minkowski inequality for the L4 norm: Z4 Z14 + 34. 1. Bounding Z14. Z1 is degree 1. Use Corollary 8.8 (q = 4, = 1). Z14 3Z12. Z12 2 = O(λ). Thus, Z14 = O(λ1/2). 104 2. Bounding Z34. Use Minkowski inequality on Z3 = (cid:80) k3,odd Zk. Z34 Applying hypercontractivity to each Zk: (cid:88) 3, oddZk4. Zk4 ( 3)kZk2. Since ˆfk2 , Zk2 λk/2. We sum this geometric series: Zk4 ( 3λ)k. Z34 (cid:88) 3, odd( 3λ)k = 3λ)3 ( 1 3λ = O(λ3/2). 3. Combining the bounds. Z4 O(λ1/2) + O(λ3/2) = O(λ1/2). Therefore, E[Z4] = Z4 4 = O(λ2). Part 5: E[Z2Y ] = O(λ2). We use the Cauchy-Schwarz inequality: Using Part 4 and Part 1: E[Z2Y ] (cid:112)E[Z4]E[Y 2]. E[Z2Y ] (cid:112) O(λ2) O(λ2) = O(λ2). Higher Order Term We now bound the higher order term in the entropy decomposition (Lemma 8.6). Lemma 8.10 (Higher Order Term). E[Z4/F 3] = O(λ2). Proof. We use constant threshold = 1/2 to split the expectation. (cid:20) Z4 3 Term 2 (F is large): When > 1/2, 1/F 3 < 8. (cid:20) Z4 3 IF 1/2 = (cid:21) (cid:21) + IF > 1/2 (cid:21) . (cid:20) Z4 By Lemma 8.9(4), E[Z4] = O(λ2). So Term 2 is O(λ2). (cid:20) Z4 3 (cid:21) IF >1/2 8E[Z4]. Term 1 (F is small): By Lemma 8.7, . So Z4/F 3 . (cid:20) Z4 3 E[F IF 1/2]. IF 1/2 (cid:21) Since 1/2 on this indicator, E[F IF 1/2] 1 2 (F 1/2). (F 1/2) = (Y 1/2). By Chebyshevs inequality and Lemma 8.9(1): (Y 1/2) 4E[Y 2] = O(λ2). So Term 1 is O(λ2). 105 Optimal Asymptotic Entropy Bound We now prove the main technical result of this section, achieving the optimal O(λ2) error bound by employing direct Taylor expansion. Theorem 8.11 (Optimal Asymptotic Entropy Bound). For any bounded nonnegative non-zero function with E[f ] = 1: Ent(Tαf ) (cid:18) 1 2 ln (cid:19) L1(f ) λ + O(λ2). The proof, detailed below, relies on direct Taylor expansion approach combined with rigorous moment bounds derived using hypercontractivity. Crucially, we employ careful application of the Minkowski inequality over the Fourier decomposition to establish the necessary higher-moment bounds. The optimality of this bound is demonstrated by the fact that the O(λ2) error rate is tight for Boolean dictatorship functions. Proof. We start from the entropy decomposition (Lemma 8.6): Ent(Tαf ) Ent(F ) + 1 2 ln 2 (cid:21) (cid:20) Z2 + (cid:18) (cid:20) Z4 3 (cid:21)(cid:19) . We know Ent(F ) = O(λ2) and by Lemma 8.10, the error term is O(λ2). We analyze = E[Z2/F ]. We use the Taylor expansion of 1/F = 1/(1 + ) around = 0 with the exact remainder: 2 1 + This holds when = 1 + > 0. Let S+ = {x : (x) > 0}. 1 1 + = 1 + . = (cid:20) Z2 (cid:21) IS+ (cid:20) Z2 = (cid:18) 1 + (cid:19) (cid:21) IS+ . 2 Term 1 (Expansion): ET = E[Z2(1 )IS+]. By Lemma 8.7, if (x) = 0, then Z(x) = 0. The indicator is redundant. By Lemma 8.9(3) and (5): ET = E[Z2] E[Z2Y ]. Term 2 (Remainder): RT = ET = (λL1(f ) + O(λ3)) O(λ2) = λL1(f ) + O(λ2). (cid:105) IS+ . Using dominance , Z2/F . (cid:104) Z2Y 2 RT E[F 2IS+] E[F 2]. E[F 2] = E[(1 + )Y 2] = E[Y 2] + E[Y 3]. By Lemma 8.9(1) and (2), RT = O(λ2) + O(λ3) = O(λ2). Combining the terms for B: = λL1(f ) + O(λ2). Substituting this back into the entropy decomposition: Ent(Tαf ) O(λ2) + (λL1(f ) + O(λ2)) + O(λ2) 1 2 ln 2 λ + O(λ2). = L1(f ) 2 ln 2 106 We next show that the O(λ2) error term is asymptotically tight. We demonstrate this by analyzing the dictatorship functions which are believed to maximize the entropy (and mutual information). Consider the Boolean dictatorship function (x) = x1. The mutual information is exactly the channel capacity, I(f (X); ) = 1 H(α), where H(α) is the binary entropy function (in bits). We analyze the Taylor expansion of the capacity around α = 1/2 (where ρ = 0). Recall ρ = 1 2α and λ = ρ2. The expansion of the binary entropy function H(α) around α = 1/2 yields Therefore, the capacity is: H(α) = 1 1 2 ln 2 ρ2 1 12 ln 2 ρ4 + O(ρ6). 1 H(α) = 1 2 ln 2 λ + 1 12 ln λ2 + O(λ3). For the dictatorship function, L1(f ) = 1. Thus, the expansion matches the form in the theorem statement: (cid:18) L1(f ) 2 ln 2 I(f (X); ) = λ + Θ(λ2). (cid:19) Since the expansion for the maximizing function includes Θ(λ2) term, the general upper bound established in the theorem statement cannot be asymptotically improved beyond O(λ2). Implications and Applications The optimal error bound established in the previous section has significant consequences for the structural properties of highly informative functions and the range of validity of the Courtade-Kumar conjecture. Linear Fourier Concentration The O(λ2) error bound allows us to derive the strongest possible Fourier concentration result within this asymptotic framework. Theorem 8.12 (Linear Fourier Concentration). Let be Boolean function satisfying Ef 1/2 (for some absolute constant > 0). If I(f (X); ) 1 H(α), then ˆf (S)2 = O(λ). (cid:88) Proof. Let = Ef . We utilize the connection: I(f (X); ) = Ent(Tαf ) + Ent(Tα(1 )). We apply Theorem 8.11 by normalizing . Using Ent(h) = E[h]Ent(h/E[h]), we have Ent(Tαf ) = Ent(Tα(f /p)). Applying the theorem to /p: Ent(Tαf ) (cid:18) L1(f /p) 2 ln 2 (cid:19) λ + O(λ2) = L1(f ) p(2 ln 2) λ + O(λ2). The O(λ2) constant remains controlled because is bounded away from 0 by c. Applying the same logic to 1 , and noting L1(f ) = L1(1 ): (cid:18) 1 (cid:19) L1(f ) 2 ln I(f (X); ) 1 1 λ + O(λ2) + = 1 p(1 p) L1(f ) 2 ln 2 λ + O(λ2). 107 We use the Taylor expansion of the channel capacity: 1 H(α) = λ 2 ln 2 O(λ2). Combining this with the assumption I(f (X); ) 1 H(α): λ 2 ln 2 + O(λ2) 1 p(1 p) L1(f ) 2 ln 2 λ + O(λ2). Dividing by λ/(2 ln 2): Rearranging: 1 + O(λ) L1(f ) p(1 p) + O(λ). p(1 p) O(λ) L1(f ). By Parsevals identity, (cid:80) S= ˆf (S)2 = p(1 p). Therefore, the Fourier weight on levels 2 and higher is: ˆf (S)2 = p(1 p) L1(f ) O(λ). (cid:88) This linear concentration is significant improvement over the O(λ1/3) bound established in [78]. Extended Range for the Conjecture The improved Fourier concentration directly translates to proving the Courtade-Kumar conjecture for wider range of the noise parameter λ. We are now ready to prove Theorem 8.2. We recall the theorem below. Theorem 8.13 (Main Result - Extended Range). There exists an absolute constant δopt > 0 such that if the noise parameter λ δopt, the Courtade-Kumar conjecture holds. Furthermore, δopt is strictly larger than the threshold established using the O(λ4/3) error bound in [78]. Proof. The proof strategy follows the established path in [78], relying on the combination of Fourier concentration and structural theorems for Boolean functions. Theorem 8.12 implies that highly informative function has most of its Fourier mass on level ˆf (S)2. Theorem 5.5 in [78] at high level states that such function must be 1. Define ξ := (cid:80) close to dictatorship. Concretely, by this theorem we have S2 E[f ] = O(ξ(cid:112)ln(1/ξ)), ˆf ({k})2 1 ξ O(ξ2 ln(1/ξ)) (36) (37) for some [n].6 The next step involves analyzing the mutual information of near-dictatorship functions (Theorem 1.14 in [78]), by which Conjecture 27 holds provided that ξ(cid:112)ln(1/ξ) c0 , (38) for small absolute constant c0. There is also another constraint that needs to be satisfied and is implicit in the proof of Theorem 1.14 [78], which we discuss next. Define α, β 0 as follows: β = (1/2) ˆf () = (1/2)E[f ] and ˆf ({k}) = (1 α)(1 2β). Also set γ := α + β. Then, another condition used in Proof of [78, Theorem 1.14 (page 30)] is that 6Note that in our notation takes its values in {1, 1} which corresponds to the notation in [78]. λ + γ ln(1/γ) c1 (39) 108 for some small absolute constant c1 > 0. Invoking (36) and (37), γ = O(ξ(cid:112)ln(1/ξ)). In Theorem 8.12, we proved that ξ = O(λ) and so γ = O(λ(cid:112)ln(1/λ)). Since ln(1/γ) = O(ln(1/λ)), we have: Hence, condition (39) becomes γ ln(1/γ) = O(λ(ln(1/λ))3/2). λ + λ(ln(1/λ))3/2 1 (40) for some absolute constant 1 > 0. Furthermore, using that ξ = O(λ), condition (38) is equivalent to λ(cid:112)ln(1/λ) c0 . (41) Condition (40) already implies Condition (41). In summary, Condition (40) defines the threshold δopt. In contrast, the analysis in [78], based on the O(λ4/3) error bound, yielded Fourier concentration of O(λ1/3). This led to the bound γ = O(λ1/3(cid:112)ln(1/λ)) and condition dominated by O(λ1/3(ln(1/λ))3/2). Since 1 > 1/3, the function x(ln(1/x))3/2 approaches zero significantly faster than x1/3(ln(1/x))3/2 as 0. Therefore, the threshold δopt satisfying the new, tighter inequality is strictly larger than the threshold derived from the O(λ4/3) analysis. 8.1.2 Part II: The Unsymmetrized Conjecture and the Li-Médards Conjecture Problem Context Beyond the main conjecture, Li and Médard [66] proposed related conjectures on the Lα-norm of the noise-stability operator Tpf (x) = (f (Y ) = 1 = x). They conjectured that for balanced functions, the unsymmetrized norm Nα(f ) = (cid:80)(Tpf (x))α is maximized by dictatorship. This Unsymmetrized Conjecture implies the Courtade-Kumar conjecture. AI Contribution We provided the AI system with the research paper [9] as primary input, and prompted it to prove the Unsymmetrized Conjecture (Conjecture 1) or the Li-Médard Conjecture (Conjecture 3) therein. Analyzing Relaxations: The AI analyzed relaxation of the problem to maximizing (q) = (cid:80) qx log qx under moment constraints. It identified that the dictatorship is saddle point (not global max) for this specific relaxation, revealing why standard approaches fail. Structural Insights: It proved that any maximizer of the relaxed problem must be distribution supported on at most two points (Lemma 8.15). Local Optimality: It proved that the dictatorship function is local maximum for the optimization problem over the Boolean Hull (Lemma 8.18). Monotonicity: It established that the maximizer must be monotone function (Lemma 8.17). Technical Details: Unsymmetrized Courtade-Kumar Conjecture and the Li-Médard Conjecture We begin by recalling the Courtade-Kumar conjecture [23]. Let be random variable uniformly distributed over the n-dimensional Hamming cube {0, 1}n. We define as noisy observation of obtained by passing each coordinate of through memoryless Binary Symmetric Channel (BSC) with crossover probability (0, 1/2). 109 Courtade and Kumar conjectured that for any Boolean function : {0, 1}n {0, 1}, the mutual information between the function output (Y ) and the original input is bounded by: I(f (Y ); X) 1 h(p) where h(p) = log2 (1 p) log2(1 p) denotes the binary entropy function. The conjecture posits that this maximum mutual information is achieved when is dictatorship functionthat is, function that depends solely on single input coordinate, such as (Y ) = Yi for any {1, . . . , n}. Related Conjectures on Functionals of . Beyond the primary Courtade-Kumar conjecture, several related conjectures have been proposed in [66, 1]. These works generally posit that dictatorship functions are the maximizers for various functionals of Boolean functions. Of particular relevance is the work of Li and Médard [66], which focuses on balanced Boolean functions (where E[f ] = 1/2). They investigate the Lα-norm of the noise-stability operator, defined as: Tpf (x) = (f (Y ) = 1 = x) (42) Li and Médard conjecture that among all balanced functions , the quantity Nα(f ) is maximized by dictatorship function f0 for 1 α 2. Specifically, they consider the unsymmetrized and symmetrized versions of these norms: Unsymmetrized Norm: Nα(f ) = (cid:80) x{0,1}n(Tpf (x))α sym Symmetrized Norm: α (f ) = (cid:80) x{0,1}n [(Tpf (x))α + (1 Tpf (x))α] The Entropy Connection. For balanced function , the mutual information I(f (Y ); X) can be expressed in terms of the noise operator. Since H(f (Y )) = 1 for balanced functions, we have: I(f (Y ); X) = 1 H(f (Y ) X) = 1 = 1 + 1 2n 1 2n (cid:88) x{0,1}n (cid:88) x{0,1}n h(Tpf (x)) [Tpf (x) log2 Tpf (x) + (1 Tpf (x)) log2(1 Tpf (x))] (43) This decomposition motivates an unsymmetrized version of the Courtade-Kumar conjecture, which focuses solely on the term (cid:80) Tpf (x) log2 Tpf (x). Comparison of Conjectures. Let be balanced Boolean function and f0 be dictatorship function. The various conjectures are summarized in Table 3. Table 3: Summary of related conjectures for balanced Boolean functions. Conjecture Name Conjecture 1 Unsymmetrized C-K Conjecture 2 Courtade-Kumar Conjecture 3 Li-Médard (Lα) sym Conjecture 4 Symmetrized Li-Médard α Formal Statement (cid:80) Tpf (x) log Tpf (x) (cid:80) Tpf0(x) log Tpf0(x) I(f (Y ); X) 1 h(p) Nα(f ) Nα(f0) for 1 α 2 sym α (f0) for 1 α 2 (f ) 110 Prior work in [9] has established the following logical relationships between these conjectures: Conjecture 1 Conjecture 3 Conjecture 2 Conjecture (44) Specifically, if the Lα-norm conjectures hold, the corresponding Courtade-Kumar conjectures (symmetrized and unsymmetrized) follow for all balanced functions. We prompted the Gemini AI system to prove either Conjecture 1 or Conjecture 3. Can you prove Conjecture 1 or Conjecture 3 (in the provided paper)? This response provides rigorous analysis of Conjecture 1 and the local version of Conjecture 3 from the provided paper. As these conjectures are related to the Courtade-Kumar conjecture, significant open problem in Boolean function analysis, complete proof for the general case is not provided. Instead, we present structured partial progress, including verification of the equivalence of the two requests, an analysis demonstrating why standard relaxation techniques fail, and proofs of the conjectures in asymptotic regimes. Figure 18: Model identification of open problem and progress direction The system specifically analyzed relaxed version of the optimization problem given by: Maximize (q) := (cid:88) qx log qx x{0,1}n (45) subject to the constraints (cid:80) qx = N1(f0) and (cid:80) q2 N2(f0). The models analysis identified that the dictatorship distribution constitutes saddle point for this relaxed problem. Consequently, this suggested that the current relaxation is insufficient to prove the primary conjecture, as the dictatorship function does not emerge as definitive global maximizer under these constraints. Following an iterative review of the systems detailed technical reports, we derived the following result (which we later noted is consistent with findings in [9, 18, 66]): Lemma 8.14. For any balanced Boolean function , N2(f ) N2(f0) and sym where equality holds if and only if is dictatorship function. 2 (f ) sym 2 (f0), Leveraging this result, we provided the system with specific strategy to pursue further refinements of the proof. 111 Note that the relaxed problem is maximizing convex function over set. So the optimal solution should be achieved at the boundary. Given Lemma 8.14, can you argue that an extreme point should be dictatorship function? This is an exceptionally insightful and elegant approach to proving Conjecture 1. The strategy of relaxing the optimization problem from the discrete space of realizable vectors (from Boolean functions) to continuous convex space defined by the L1 and L2 constraints is very powerful. Your analysis of the optimization landscapemaximizing strictly convex function over compact convex setis correct. This indeed implies that the maximum must occur at an extreme point, meaning the L2 inequality constraint must be active (satisfied with equality). However, there is subtle but crucial gap in the final step of the logic. Your argument finds the optimizer over the relaxed set K. While we know satisfies the equality constraint, we have not yet established that is actually realizable by balanced Boolean functions. Figure 19: Model identification of open problem and progress direction It revealed subtle logical gap in the initial argument. To address this, the system investigated the relaxed optimization problems, demonstrating that the optimal solution is characterized by two-point distribution. By leveraging this structural property, the system provided an analytical upper bound for the maximum objective value achievable by any balanced Boolean function. Lemma 8.15. Consider maximizing (q) given by (45) over the set K1 = {q : E[q] = 1/2, Var(q) ρ2/4}. Then the maximizing distribution is supported on two points {0, (1 + ρ2)/2}, achieving the objective value: = 2n1 ln (cid:17) . (cid:16) 1+ρ2 2 Note that the ρ2/4 bound on the variance comes from Lemma 8.14 as N2(f0) = (1 + ρ2)/4. We also asked the AI system to plot the upper bound established by Lemma 8.15 along with the value achieved by the dictatorship functions (see Figure 20.) 112 Figure 20: Comparison of the objective functional values for the two-point distribution relaxation (upper bound), given by Lemma 8.15, and the dictatorship function as the correlation parameter ρ varies from 0 to 1. We next sought to tighten the relaxation by establishing an bound for the functions realizable by balanced Boolean functions. However, the system identified technical flaw in our proposed bound and provided concrete counter-example, leading us to pivot our strategy. Our subsequent approach focused on leveraging the inverse of the noise operator. Given correlation parameter ρ, if = Tρf , the original function can be recovered via the inverse transformation = T1/ρq. Recall that the noise operator is linear and can be expressed as: Tρf (x) = (cid:88) y{0,1}n (x, y)f (y) where the transition kernel is determined by the Hamming distance d(x, y). To refine the optimization space, we relaxed the strict Boolean constraint (x) {0, 1} to pointwise box constraint, requiring 0 (T1/ρq)x 1 for all x. Combining this with the established constraints on the first and second moments of q, we defined the following relaxed constraint set K: (cid:26) := : E[q] = 1 2 , Var(q) ρ2 4 , 0 (T1/ρq)x 1 (cid:27) Interestingly it showed that the variance constraint is already implied by the other two. In addition, it showed that this relaxation is indeed tight, as discussed next. Let FB be the set of balanced Boolean functions : {0, 1}n {0, 1} and define the entropy functional Φ(f ) = (cid:80) x{0,1}n h((Tρf )(x)) with h(t) = ln t. Let be the Boolean Hull (functions : {0, 1}n [0, 1] with E[g] = 1/2). Let = Tρ(G) be the feasible set for q, which can then be characterized by the mean constraint E[q] = 1/2 and the pointwise box constraints 0 T1/ρq 1. Lemma 8.16. (Convex Relaxation and Tightness). Maximizing Φ(f ) over FB is equivalent to maximizing (q) over K. This equivalence is an important milestone as it transforms the initial optimization over discrete Boolean functions into continuous convex optimization. In addition, it proves two other structural properties of the solution. 113 Consider the following relaxation of the problem [...]. What do you think about it? Can you use it to prove the unsymmetrized C-K conjecture? This is challenging problem concerning the maximization of convex functional related to entropy under the noise operator. Based on the instructions, we analyze the two proposed approaches. We provide rigorous proofs for several key properties of the optimizer, including monotonicity and the local optimality of the Dictatorship function. However, proving the global optimality requires advanced techniques that cannot be derived elementarily from the provided context. [....] Figure 21: Model identification of open problem and progress direction Lemma 8.17. (Monotonicity). If FB maximizes Φ(f ), then can be assumed to be monotone. Lemma 8.18. (Local optimality). dictatorship function is local maximum of the problem of maximizing (q) over K. The AI system also attempted to prove global optimality of the dictatorship functions by an inductive proof and identifies the remaining gaps. Concretely, consider the restrictions of the function to the (n 1)-dimensional sub-cubes. Let f0, f1 : {0, 1}n1 {0, 1} be defined by f0(x) = (x, 0) and f1(x) = (x, 1). Furthermore, let denote the noise operator acting on 1 variables, and ρ let gi = ρfi represent the noise-evolved versions of these sub-functions. The functional Φ(f ) admits the following decomposition: Φ(f ) = (cid:88) J(g0(x), g1(x)) x{0,1}n where the kernel J(a, b) is defined as J(a, b) = h(pa + εb) + h(εa + pb), with h(t) = ln(t), and the parameters and ε are given by = 1+ρ 2 and ε = 1ρ 2 The system then continues with the following response given the above notation. . 114 We have reduced the problem to maximizing Φ(f ) among balanced monotone Boolean functions and verified that Dictatorship is local maximum. However, maximizing convex function can lead to multiple local maxima. (For instance, for = 2, the XOR function is also local maximum, but yields smaller value). To prove global optimality, we attempted an inductive approach using the decomposition: Φ(f ) = 2n1E[J(g0, g1)]. We need to show E[J(g0, g1)] C(ρ) := h((1 + ρ)/2) + h((1 ρ)/2). We proved the standard contraction inequality using the convexity of and the doubly stochastic nature of ρ : E[J(g0, g1)] E[J(f0, f1)] = (f0 = f1)C(ρ). Let = (f0 = f1). Since C(ρ) < 0, we know C(ρ) C(ρ). This inequality Φ(f ) 2n1C(ρ) is not strong enough to prove Φ(f ) 2n1C(ρ). This is strong data processing inequality, equivalent to Mrs. Gerbers Lemma. This is the central difficulty of the problem. We next conducted several further iterations of prompting to explore the inductive path. Specifically, we attempted to solidify the connection with Mrs. Gerbers Lemmawhich was also previously used in [78] to prove C-K conjecture in the high-noise regime. However, while the system could identify the relevance of the lemma, it ultimately failed to complete the formal analytical steps required for the proof. Observations on AI-Assisted Research. Our interactions with the system on these theoretical problems yielded several key insights into its utility as research partner: Confirmation Bias in Prompting: The system exhibits tendency to support the position or hypothesis presented in the prompt. When tasked with proving open-ended conjectures that are not necessarily true, it often attempts to bridge logical gaps with hand-wavy arguments that do not withstand rigorous scrutiny. We found that performance improves significantly when using neutral prompts (e.g., prove or refute), which encourages the system to evaluate multiple directions in parallel. Effectiveness in Refutation: The system is remarkably adept at identifying counterexamples and pinpointing the crux of problem. When provided with precise but flawed idea, it can often explain exactly why particular strategy fails, making it valuable tool for early-stage proof debugging. Proof of Lemma 8.15 To formally prove that the optimal distribution qx is supported on at most two points, we analyze the Karush-Kuhn-Tucker (KKT) conditions. This structural approach reveals how the moment constraints necessitate sparse distribution. We seek to maximize (q) = (cid:80) qx ln qx. Defining = 2n as the size of the Hamming cube, we construct the Lagrangian with multipliers λ and µ for the mean and variance constraints: qx ln qx, which is equivalent to minimizing (cid:80) L(q, λ, µ) = (cid:88) x=1 qx ln qx + λ qx (cid:33) + µ (cid:32) (cid:88) (cid:33) q2 (cid:32) (cid:88) 115 where the quadratic constraint = (1+ρ2) at the maximum. Setting the partial derivative with respect to each qx to zero gives: assumes the variance constraint Var(q) ρ2/4 is active 4 qx = (ln qx + 1) + λ + 2µqx = 0 Rearranging this yields the transcendental equation ln qx 2µqx = λ 1. Let g(q) = ln 2µq. Any optimal value of qx must lie at the intersection of g(q) and the constant λ 1. Since g(q) = 1/q2, which is strictly negative for all > 0, g(q) is strictly concave. strictly concave function can intersect horizontal line at most at two distinct points, proving that the optimal qx can take at most two values, and b. Let be the multiplicity of the value a, such that indices take the value b. The linear and quadratic constraints provide the following system: ka + (M k)b = M/2, ka2 + (M k)b2 = (1 + ρ2) 4 . Solving for a(k) and b(k) in terms of k, we find: a(k) = (cid:114) 1 + ρ 2 , b(k) = 1 ρ 2 (cid:114) . The objective function can then be expressed as (k) = kϕ(a(k))+(M k)ϕ(b(k)), where ϕ(t) = ln t. To determine the behavior of (k), we examine its derivative (k) via implicit differentiation of the constraints: (k) = (ϕ(a) ϕ(b)) (a b) ϕ(a) + ϕ(b) 2 Assuming > b, we utilize the integral representation ϕ(a) ϕ(b) = (cid:82) derivative: ϕ(t)dt to rewrite the (k) = ϕ(t)dt (a b) (cid:90) ϕ(a) + ϕ(b) 2 This expression represents the difference between the integral of ϕ(t) and the trapezoidal area under the chord connecting (b, ϕ(b)) and (a, ϕ(a)). Calculating the derivatives of ϕ(t) = ln t, we find ϕ(t) = ln + 1, ϕ(t) = 1/t, and ϕ(t) = 1/t2. Since ϕ(t) < 0 for all > 0, the function ϕ(t) is strictly concave. For strictly concave function, the area under the curve is strictly greater than the area of the trapezoid defined by the chord. Consequently, (k) > 0, meaning the objective function (k) is strictly increasing over its feasible domain. The maximum is therefore achieved at the largest possible value of k. Given the non-negativity constraint b(k) 0, the maximum occurs when = 0. . Substituting Solving for in this boundary condition yields = (cid:17) these values back into the objective yields the maximum value = 1+ρ2 , which results in = 1+ρ2 2 = 2n1 ln (cid:17) . (cid:16) 1+ρ2 2 2 ln (cid:16) 1+ρ2 2 Proof of Lemma 8.16 Since Tρ is linear, is convex polytope. Since (q) is strictly convex, its maximum over is attained at an extreme point. The extreme points of are the images of the extreme points of G, which are FB (the set of balanced Boolean functions). Thus, maximizing Φ(f ) over FB is equivalent to maximizing (q) over K. 116 Proof of Lemma 8.17 We use decomposition along the n-th coordinate. Let f0(x) = (x, 0) and f1(x) = (x, 1). Let ρfi. The functional ρ decomposes as: be the noise operator on 1 variables. Let gi = Φ(f ) = (cid:88) J(g0(x), g1(x)), where J(a, b) = h(pa + εb) + h(εa + pb), with = (1 + ρ)/2 and ε = (1 ρ)/2. Let = (a + b)/2 and = (b a)/2. Then J(a, b) = h(m ρd) + h(m + ρd). Since is strictly convex, is strictly increasing in for fixed m. x{0,1}n1 0 +f Consider the polarization defined by 1 = max(f0, f1). Note that is 0 = min(f0, f1) and . The means are preserved pointwise: m(x) = m(x). ρf ρ((f1 f0)/2) and d(x) = balanced since The differences are d(x) = 1 = f0 +f1. Let ρ(f1 f0/2). is positive operator (its kernel is non-negative as it represents probabilities), we have Since ρ the inequality ρ(u). Thus, d(x) d(x). Since increases with d, Φ(f ) Φ(f ). By repeatedly applying this polarization, we conclude that the maximum must be attained by monotone function. ρ(u) = Proof of Lemma 8.18 We verify that the Dictatorship is local maximum by checking the KKT conditions for maximizing (q) over the polytope K. The set is defined by the constraints 0 (M q)x 1 and (cid:80) qx = N/2, where = T1/ρ. We formulate the KKT conditions for maximization subject to g1(q) := 0 and g2(q) := 1 0. The gradient condition is (q) = (µ λ), where λ, µ 0 are the multipliers for g1 and g2 respectively (ignoring the equality constraint which adds constant shift ν1). Let γ = µ λ and := q. Complementary slackness implies: If gx = 0, then µx = 0, which implies γx 0. If gx = 1, then λx = 0, which implies γx 0. Let be the noise operator applied to the dictatorship function fD(x) = x1, i.e., = Tρ(fD). Consequently, = = T1/ρ(q) = fD. Let = {x x1 = 1} and = {x x1 = 0}. We have = 1 on and = 0 on B. We therefore require γ 0 on and γ 0 on B. The gradient condition is given by h(q and on A, must be constant on and B: y) = (M γ)y + ν. Let = γ. Since takes values on where χ1(x) = (1)x1. Calculating c1, we obtain v(x) = c0 + c1χ1(x), c1 = h(a) h(b) 2 = 1 2 ln(a/b) = artanh(ρ) < 0, (46) (47) where we used that = 1ρ 2 γ = Tρv = c0 + ρc1χ1(x). The resulting constraints on γ are: and = 1+ρ 2 , by definition of the noise operator. We also have On (χ1 = 1): c0 ρc1 0 = c0 ρc1. On (χ1 = 1): c0 + ρc1 0 = c0 ρc1. We require ρc1 c0 ρc1. Given that c1 < 0 and ρ > 0, we have ρc1 < 0 < ρc1. This interval is non-empty (e.g., c0 = 0 is valid solution). Thus, the Dictatorship satisfies the KKT conditions and is local maximum."
        },
        {
            "title": "8.2 NP-hardness: Ratio Difference Maximization (RDM)",
            "content": "Written by Ravi Kumar and Silvio Lattanzi (on behalf of coauthors). Problem Context In recent work [20], together with Flavio Chierichetti, Mirko Giacchini, Alessandro Panconesi, Erasmo Tani, and Andrew Tomkins, we were studying Multinomial Logits (MNLs), also known as PlackettLuce models, that describe user preferences by assigning weight to each item in universe. When user is presented subset of items, they select one with probability proportional to its weight. In the paper, we consider the problem of learning an MNL by sampling from the conditional distributions induced on subsets of the universe. Interestingly, even computing the worst-case error on arbitrary size subsets of the universe turns out to be non-trivial problem. In [20] we introduce several approximation algorithms for this tasks. We also had the intuition that the problem was related to SUBSET-SUM and most likely NP-hard but we felt that the reduction was not immediate and hence we decided to test Gemini with such question. We were happily surprised by receiving zero-shot correct proof within few minutes. We then asked also to prove NP-hardness for variation of the problem. AI Contribution Given only the formal definition of the Ratio Difference Maximization (RDM) problem, the AI zero-shot generated flawless, polynomial-time NP-hardness reduction from the SUBSET-SUM problem. Upon subsequent prompt, it successfully proved the NP-hardness of related variation (MAX-DIFF-RATIO) using similarly rigorous reduction. More specifically, we used math rigor prompt and we asked the model to show that the Ratio Difference Maximization (RDM) problem is NP-hard. This is the prompt that we used: <Math Rigor Prompt> Prove that the following problem is NP-hard. Given two lists = (v1, ..., vn) and = (w1, ..., wn) of positive integers, find subsets [n] that maximize the objective function (S, ) = (S) (T ) (S) (T ) , where (X) = (cid:80) iX vi and (X) = (cid:80) iX wi This is the output provided by Gemini that we verified to be correct: Theorem 8.19. The Ratio Difference Maximization (RDM) problem is NP-hard. Proof. We prove NP-hardness by reduction from the SUBSET-SUM problem. The SUBSETSUM problem is: Given set = {a1, ..., an} of positive integers and target positive integer K, does there exist subset [n] such that (cid:80) iI ai = K? We can assume 2, as this restriction remains NP-complete. We define the decision version of RDM (D-RDM): Given (V, ) and rational number Z, does there exist [n] such that (S, ) Z? We now construct the reduction from an instance (A, K) of SUBSET-SUM (with 2) to an instance of D-RDM. 118 Let = K2. Since 2, we have > 1. We construct an RDM instance with + 1 items: For = 1, ..., n, set vi = ai and wi = ai. For = + 1, set vn+1 = 1 and wn+1 = L. (T ) (S) (T ) = (S) (T ) = 0. iTA . This construction is polynomial in the size of ai. (T ) = (TA) + vn+1 = + 1. We set the target value for D-RDM to = K1 K+1 the input (A, K). We analyze the maximum value of the objective function (S, ) for this instance, where [n + 1]. Case 1: + 1 / . Then [n]. For all , vi = wi = ai. Thus (T ) = (T ) and (T ) (S) (S) = (S). (S, ) = (S) Case 2: + 1 . Let TA = [n]. Let = (cid:80) (T ) = (TA) + wn+1 = + L. We seek that maximizes (S, ) = (S) G(S) = (x + L)V (S) (x + 1)W (S). We analyze the contribution of each element to G(S). For TA, vi = wi = ai. The contribution if is (x + L)ai (x + 1)ai = ai(L 1). Since ai > 0 and > 1, this is positive. Thus, the optimal must include all TA. For = + 1, vn+1 = 1, wn+1 = L. The contribution if + 1 is (x + L)(1) (x + 1)(L) = + xL = x(1 L). If > 0 (i.e., TA = ), since > 1, the contribution x(1 L) is negative. Thus, the optimal must exclude + 1. In this case, the optimal is = TA. If = 0 (i.e., TA = , = {n + 1}), the contribution is 0. (S, ) = 0 whether = or = {n + 1}. We focus on the case > 0. The maximum value for fixed (defined by x) is: . This is equivalent to maximizing x+1 (S) x+L h(x) = (TA, ) = + + = x(x + L) x(x + 1) (x + 1)(x + L) = x(L 1) (x + 1)(x + L) . We want to maximize h(x) over the set of achievable SUBSET-SUMs XA = {A(I) [n], = }. We analyze the function h(x) for > 0. h(x) = (L 1) . The derivative is: x2+(L+1)x+L h(x) = (L 1) (x2 + (L + 1)x + L) x(2x + + 1) ((x + 1)(x + L)) . The sign of h(x) is determined by the numerator: (x) = x2 + (L + 1)x + 2x2 (L + 1)x = L. L. h(x) increases for 0 < < x2. h(x) = 0 when = Thus, h(x) attains its unique global maximum at = Since = K2, the unique maximum is attained at = K. The maximum value is: and decreases for > L. h(K) = K(K2 1) (K + 1)(K + K2) = K(K 1)(K + 1) (K + 1)K(K + 1) = 1 + 1 = Z. Let OP be the maximum value of the objective function for the constructed RDM instance. Since 2, > 0. Thus OP = maxxXA h(x) (assuming contains at least one element, otherwise SUBSET-SUM is trivial). 119 We now show the equivalence between the SUBSET-SUM instance and the D-RDM instance. () Suppose the SUBSET-SUM instance is YES instance. Then there exists [n] such that A(I) = K. So XA. Then OP h(K) = Z. Since is the global maximum of h(x), OP = Z. Thus the D-RDM instance is YES instance. () Suppose the D-RDM instance is YES instance. Then OP Z. Since is the global maximum of h(x), this implies OP = Z. Let XA be such that h(x) = Z. Since = is the unique global maximizer of h(x), it must be that = K. Therefore, XA, which means the SUBSET-SUM instance is YES instance. We have provided polynomial-time reduction from SUBSET-SUM to D-RDM. Therefore, D-RDM is NP-hard, and consequently, the optimization problem RDM is NP-hard. Given the success of the first attempt, using the same prompt structure, we also asked to show that variation of the problem is NP-hard. This is the second proof that we obtained in this way. Consider the MAX-DIFF-RATIO (MDR) optimization problem: Given two lists = (v1, . . . , vn) and = (w1, . . . , wn) of positive integers, find [n] that maximizes (j, ) = vj iT vi (cid:80) (cid:80) wj iT wi . Theorem 8.20. The MDR problem is NP-hard. Proof. To prove NP-hardness, we consider the corresponding decision problem, D-MDR: Given (V, ) and rational threshold Q, does there exist pair (j, ) with [n] such that (j, ) Q? We will show that D-MDR is NP-hard by reduction from the SUBSET-SUM problem, which is known to be NP-complete. The Reduction. Given an instance (A, B) of SUBSET-SUM, we construct an instance of D-MDR with = + 1 items, indexed from 0 to n. We define the lists = (v0, . . . , vn) and = (w0, . . . , wn) and the threshold Q. The construction is defined as follows: 1. For = 1, . . . , n: vi = 4ai and wi = 4ai. 2. For the special item = 0: v0 = 8B and w0 = 2B. 3. The threshold is = 1/3. Since ai and are positive integers, all vi and wi are positive integers. This construction is clearly computable in polynomial time. Analysis of the Objective Function. Let (T ) = (cid:80) analyze the objective function (j, ) for the constructed instance. Case 1: {1, . . . , n}. Let = 1. We have vk = wk. Case 1a: 0 / . Then {1, . . . , n}. For all , vi = wi, so (T ) = (T ). iT vi and (T ) = (cid:80) iT wi. We (k, ) = vk (T ) wk (T ) = vk (T ) vk (T ) = 0. 120 Case 1b: 0 . Let = {0} where {1, . . . , n} and S. Let = (cid:80) (S) = (S) = X. (T ) = v0 + = 8B + X. (T ) = w0 + = 2B + X. iS 4ai. Then (k, ) = vk 8B + wk 2B + . Since vk = wk and > 0, we have 8B + > 2B + X. Thus, (k, ) < 0. In Case 1, the maximum value of (j, ) is 0. Case 2: = 0. We must have 0 . Let = {0} for some {1, . . . , n}. Let = (S) = (S) = (cid:80) iS 4ai. (0, ) = v0 (T ) w0 (T ) = 8B 8B + 2B 2B + . Let h(X) = 8B 8B+X 2B 2B+X . We analyze h(X) for 0. h(X) = = 8B(2B + X) 2B(8B + X) (8B + X)(2B + X) 16B2 + 8BX 16B2 2BX (8B + X)(2B + X) = 6BX (8B + X)(2B + X) . We examine the derivative of h(X) with respect to X. The sign of h(X) is determined by the sign of the numerator when using the quotient rule: (X) = (6B)(8B + X)(2B + X) (6BX)((8B + X) + (2B + X)). Dividing by 6B (since > 0), the sign is determined by: (X) 6B = (16B2 + 10BX + 2) X(10B + 2X) = 16B2 + 10BX + 2 10BX 2X 2 = 16B2 2. Thus, h(X) = 0 if and only if 2 = 16B2. Since 0 and > 0, this occurs at = 4B. The function h(X) increases for < 4B and decreases for > 4B. The unique global maximum of h(X) occurs at = 4B. The maximum value is: h(4B) = 6B(4B) (8B + 4B)(2B + 4B) = 24B2 (12B)(6B) = 24B2 72B2 = 1 3 . iS ai = B. This implies that = (cid:80) Proof of Equivalence. We show that the SUBSET-SUM instance (A, B) is Yes instance if and only if the maximum value of (j, ) is at least = 1/3. ( = ) Suppose the SUBSET-SUM instance is Yes. Then there exists subset {1, . . . , n} such that (cid:80) iS 4ai = 4B is achievable. Let = 0 and = {0} S. Then (0, ) = h(4B) = 1/3. Thus, the D-MDR instance is Yes. ( = ) Suppose the D-MDR instance is Yes. The maximum value of (j, ) is 1/3. From our analysis, if 1, (j, ) 0. Therefore, the maximum must be achieved when = 0. The objective function is h(X), where is an achievable SUBSET-SUM of {4ai}. Since the maximum possible value of h(X) is 1/3, and this maximum is achieved uniquely at = 4B, 121 the maximum value being 1/3 implies it must be exactly 1/3. This means = 4B must be achievable. That is, there exists {1, . . . , n} such that (cid:80) iS 4ai = 4B, which implies (cid:80) Since we have polynomial-time reduction from the NP-complete problem SUBSET-SUM to D-MDR, the latter is NP-hard. Consequently, the MDR optimization problem is NP-hard. iS ai = B. Thus, the SUBSET-SUM instance is Yes."
        },
        {
            "title": "8.3 Machine Learning Optimization: Self-regularized Gumbel Sigmoid",
            "content": "Written by Lin Chen, Gang Fu, and David P. Woodruff. Problem Context Subset selection is core problem in machine learning, relevant to tasks like feature selection and embedding dimension optimization. Current methods like Dropout Feature Ranking (DFR) rely on explicit penalty terms (e.g., ℓ1 regularization) to control the number of selected features. However, tuning the regularization strength λ is difficult and sensitive, often hindering practical application. new method, Self-regularized Gumbel Sigmoid (SrGS), was proposed to eliminate this hyperparameter by using an implicit regularization mechanism involving Softmax competition and budget-aware clipping. The theoretical question was to understand exactly why and how this parameterization enforces sparsity without an explicit penalty. AI Contribution The researchers provided the model with the mathematical definition of SrGS and asked for theoretical analysis of its implicit regularization and behavior in the low-temperature limit. Implicit ℓ0 Penalty: The model derived that in the low-temperature limit (T 0), the variance of the Gumbel-Sigmoid distribution acts as an exact relaxation of the ℓ0 constraint, effectively penalizing non-binary solutions. Adaptive Hybrid Regularization: It analyzed the deterministic limit (using expectations) and proved that the method induces unique \"hybrid\" regularization: strong signals are subject to ℓ2 shrinkage (preserving magnitude), while weak signals competing for the remaining budget are suppressed by non-convex ℓ2/3 penalty. Theoretical Validation: These derivations provided the rigorous theoretical justification for the methods empirical success, confirming it solves relaxed subset selection problem without manual tuning. Technical Details: Theoretical Analysis of SrGS We employed the model to identify and resolve key theoretical gap regarding the implicit mechanisms of the Self-regularized Gumbel Sigmoid (SrGS) method. Problem Formulation Subset selection is core problem central to multiple optimization tasks in machine learning. Existing methods, such as Dropout Feature Ranking (DFR) (Chang et al., 2017), approach this by optimizing variational dropout mask on the input layer. However, DFR relies on an explicit penalty term in the loss function to constrain the number of active features. The objective function is formulated as: L(θ) = 1 i=1 (cid:88) log p(yif (xi zi; θ)) + (cid:125) (cid:123)(cid:122) (cid:124) Task Loss (e.g., Cross-Entropy or MSE) λ (cid:88) (cid:88) i=1 j=1 zij where the first term represents the task-specific prediction error (negative log-likelihood), is the batch size, is the number of features, and zij is the stochastic gate for the j-th feature. 123 Determining the optimal regularization strength λ requires extensive cross-validation and often becomes blocker for successful application due to its sensitivity. The SrGS method was proposed to overcome this limitation by eliminating the explicit penalty term λ. Instead, it introduces structural self-regularization mechanism defined by the following process: 1. Competition: For each feature j, learnable logit tj is normalized via Softmax to produce an attention score Sj, enforcing global competition: Sj = exp(tj) k=1 exp(tk) (cid:80)D 2. Budgeting: The scores are scaled by the target budget and clipped to form selection probabilities zj, ensuring the expected number of selected features approximates K: zj = Clip(Sj K, ε, 1) 3. Stochastic Selection: The final binary masks wj are generated via the differentiable GumbelSigmoid reparameterization: wj = σ (cid:18) 1 (log zj log(1 zj) + log uj log(1 uj)) (cid:19) While SrGS empirically demonstrates superior solution quality without hyperparameter tuning, the theoretical basis for this parameterization remains an open question. Specifically: 1. Does this specific parameterization rigorously enforce sparsity in the low-temperature limit (T 0)? 2. What is the exact mathematical form of the implicit regularization induced by this mechanism when combined with standard weight decay? 124 We identify and resolve key theoretical gap regarding the implicit mechanisms of the Self-regularized Gumbel Sigmoid (SrGS) method. Question: Subset selection is core problem central to multiple optimization tasks in machine learning. Existing methods, such as Dropout Feature Ranking (DFR), approach this by optimizing variational dropout mask on the input layer. However, DFR relies on an explicit penalty term in the loss function to constrain the number of active features. The objective function is formulated as: L(θ) = 1 i= (cid:88) log p(yif (xi zi; θ)) + (cid:124) (cid:123)(cid:122) Task Loss (e.g., Cross-Entropy or MSE) (cid:125) λ (cid:88) (cid:88) i=1 j=1 zij (48) where the first term represents the task-specific prediction error (negative log-likelihood), is the batch size, is the number of features, and zij is the stochastic gate for the j-th feature. Determining the optimal regularization strength λ requires extensive cross-validation and often becomes blocker for successful application due to its sensitivity. The SrGS method was proposed to overcome this limitation by eliminating the explicit penalty term λ. Instead, it introduces structural self-regularization mechanism defined by the following process: 1. Competition: For each feature j, learnable logit tj is normalized via Softmax to produce an attention score Sj, enforcing global competition: Sj = exp(tj) k=1 exp(tk) (cid:80)D 2. Budgeting: The scores are scaled by the target budget and clipped to form selection probabilities zj, ensuring the expected number of selected features approximates K: zj = Clip(Sj K, ϵ, 1) 3. Stochastic Selection: The final binary masks wj are generated via the differentiable Gumbel-Sigmoid reparameterization: wj = σ (cid:18) 1 (log zj log(1 zj) + log uj log(1 uj)) (cid:19) While SrGS empirically demonstrates superior solution quality without hyperparameter tuning, the theoretical basis for this parameterization remains an open question. Specifically: 1. Does this specific parameterization rigorously enforce sparsity in the low-temperature limit (T 0)? 2. What is the exact mathematical form of the implicit regularization induced by this mechanism when combined with standard weight decay? 125 We answer these questions affirmatively. We analyze the method from two perspectives: the behavior of the stochastic objective in the low-temperature limit, and the implicit regularization induced by its parameterization. 1. Stochastic Analysis: Exact ℓ0 Relaxation We first analyze the objective in the limit 0. In this limit, the expected loss decomposes into deterministic loss and variance penalty term Rvar(z, θ). The optimization problem effectively minimizes: min θ,z Ldet(z, θ) + Rvar(z, θ) The model derived that the variance penalty takes the form Rvar(z, θ) = (cid:80) zj(1 zj). Minimizing this concave function over the hypersimplex encourages solutions at the vertices (binary selection). Theorem 2 (Implicit ℓ0 Penalty). The implicit regularization induced by the variance penalty, defined as R(β) = inf{Rvar(z, θ) H(D, K), θ = β}, is an exact penalty function for the ℓ0 constraint. Specifically: Xj2 2θ2 R(β) = 0 β0 This result mathematically validates that SrGS provides continuous, exact relaxation of the combinatorial Best Subset Selection problem. 2. Deterministic Analysis: Adaptive Hybrid Regularization We further analyzed the implicit regularization in the deterministic regime where the mask is replaced by its expectation z, combined with ℓ2 regularization (weight decay) on θ. The model discovered that under the budget constraint (cid:80) zj = and the physical constraint 0 zj 1, the optimization landscape induces unique Adaptive Hybrid Regularization. Theorem 4 (Hybrid Regularization). The implicit regularizer DR(β) partitions the features into two sets based on data-dependent threshold τ : Saturated Set (A): Features with strong signals (βj2/3 τ ) are assigned full probability zj = 1. These features are subject to standard ℓ2 regularization (λβA2 ), 2 which preserves signal magnitude. Fractional Set (F ): Features with weak signals compete for the remaining budget KF = A. These features are subject to an aggressive ℓ2/3 penalty: DR(β) = λβA2 2 + λ 2 βF 2 2/3 This derivation reveals the mechanism behind SrGSs superior performance: it automatically applies ℓ2 protection to key features while subjecting noise features to non-convex ℓ2/3 compression. Figure 22: Model resolution of the new theory Theoretical Findings We answer these questions affirmatively. We utilized the model to analyze the method from two perspectives: the behavior of the stochastic objective in the low-temperature limit, and the implicit regularization induced by its parameterization. 126 Stochastic Analysis: Exact ℓ0 Relaxation. We first analyze the objective in the limit 0. In this limit, the expected loss decomposes into deterministic loss and variance penalty term Rvar(z, θ). The optimization problem effectively minimizes: min θ,z Ldet(z, θ) + Rvar(z, θ) The model derived that the variance penalty takes the form Rvar(z, θ) = (cid:80) zj(1 zj). Minimizing this concave function over the hypersimplex encourages solutions at the vertices (binary selection). Xj2 2θ2 Theorem 8.21 (Implicit ℓ0 Penalty). The implicit regularization induced by the variance penalty, defined as R(β) = inf{Rvar(z, θ) H(D, K), θ = β}, is an exact penalty function for the ℓ0 constraint. Specifically: R(β) = 0 β0 This result mathematically validates that SrGS provides continuous, exact relaxation of the combinatorial Best Subset Selection problem. Deterministic Analysis: Adaptive Hybrid Regularization. We further analyzed the implicit regularization in the deterministic regime where the mask is replaced by its expectation z, combined with ℓ2 regularization (weight decay) on θ. The model discovered that under the budget constraint (cid:80) zj = and the physical constraint 0 zj 1, the optimization landscape induces unique Adaptive Hybrid Regularization. Theorem 8.22 (Hybrid Regularization). The implicit regularizer into two sets based on data-dependent threshold τ : DR(β) partitions the features Saturated Set (A): Features with strong signals (βj2/3 τ ) are assigned full probability 2), which preserves zj = 1. These features are subject to standard ℓ2 regularization (λβA2 signal magnitude. Fractional Set (F ): Features with weak signals compete for the remaining budget KF = A. These features are subject to an aggressive ℓ2/3 penalty: DR(β) = λβA2 2 + λ K2 βF 2 2/ This derivation reveals the mechanism behind SrGSs superior performance: it automatically applies ℓ2 protection to key features while subjecting noise features to non-convex ℓ2/3 compression."
        },
        {
            "title": "8.4 Mechanism Design: Revelation Principle Reduction Domain Extension",
            "content": "Written by Song Zuo and David P. Woodruff. Problem Context The main task for the model was to extend the key theoretical results of the paper Mechanism Design for Large Language Models [30] from rational bids (Qn ). The original papers + Revelation Principle (Theorem 3.5) relied on the countability of the bid space. The generalization was expected to heavily rely on order theory and topological arguments as the assumptions are much weaker than standard auction theory setups. To avoid the additional mathematical complexity, the authors restricted bids to be rational. ) to real bids (Rn + AI Contributions We fed the original paper [30] to the model and asked it to bridge the rational to real bids gap for Theorem 3.5. Proof Attempts and Improvement Reviews: The model initially came up with some coarse proofs from the initial ask. Then we also asked the model to review the draft and provide improvement suggestions. We iterated through this process with human selection as well as additional guidance, and finally reached the complete and rigorous results. Free Bonus on Extension of Theorem 3.12: The model volunteered to also extend Theorem 3.12 to general settings. Full Writing with Strategic Guideline and Suggestions from Human: The entire material in the next Technical Details section is fully written by the model with human suggestions (and some minor corrections). Human Interventions Throughout the iteration process, human interventions mainly happen at correcting the model generated review feedback. Sometimes, the model suggests something distracting, misleading, or even mathematically suspicious. Human interventions then can help the model get out of potential dead-loops. Technical Details The original paper [30] introduces Token Auction Model where agents, represented by Large Language Models (LLMs), submit scalar bids to influence the generation of content. The mechanism = q, consists of an aggregation function that combines agents preferred distributions based on their bids b, and payment function z. The paper establishes Revelation Principle ([30, Theorem 3.5]), stating that any mechanism satisfying Payment Monotonicity and Consistent Aggregation is strategically equivalent to mechanism with Monotone Aggregation Function. The proof relies on the assumption that the bid space is Qn , utilizing the countability of the bids to construct utility representations. Furthermore, the + paper proves the existence of Stable Sampling ([30, Theorem 3.12]). The original proof implicitly requires the aggregation function to be absolutely continuous by relying on Lebesgues Differentiation Theorem and the Fundamental Theorem of Calculus. 128 Open Problem: Extend the Revelation Principle and the existence of Stable Sampling to the more natural domain of real-valued bids, Rn , while minimizing additional assumptions and providing + rigorous proofs that do not rely on countability or absolute continuity. We will show this is possible by assuming the token set is finite, which is standard in practice. Key Definitions We restate the key definitions from [30] for completeness. Let (T ) be the set of distributions over tokens . Let be the preference relation of agent over (T ). Definition 8.23 (Robust Preferences). Given preferred distribution pi, q if T, q(t) pi(t) q(t) pi(t) and (q(t) pi(t))(q(t) pi(t)) 0. Definition 8.24 (Payment Monotonicity). Mechanism = q, satisfies payment monotonicity if for all p, bi, bi, i, bi, p) q(bi, bi, p) q(b i: zi(bi, bi, p) zi(b i, bi, p). Definition 8.25 (Consistent Aggregation). q(b, p) is consistent if: if q(bi, bi, p) q(b for some bi, then for all i, p) q(b i, q(bi, i, p). i, i, bi, p) Definition 8.26 (Monotone Aggregation Function). q(b, p) is monotone if for all p, bi and bi i: q(bi, bi, p) q(b i, bi, p). Methodology and Assumptions We extend the bid space to Rn . We assume the token set is finite. This ensures the space of + distributions (T ) is finite-dimensional simplex, which is compact, metrizable, and secondcountable space. Extending the Revelation Principle The main challenge in extending Theorem 3.5 is the failure of the countability argument used in [30]. Approach: We replace the countability arguments with topological and order-theoretic methods. We establish utility representation using the topological properties of the codomain. Then, we prove general Monotone Extension Lemma that allows extending the transformed monotone aggregation function from the image of the utility representation . This approach relies only on the continuity of the underlying preferences to the entire bid space Rn + and the compactness of (T ), removing the need for continuity assumptions on the aggregation function q. This approach requires the following assumptions: Assumption 8.27 (A1: Continuous Preferences). The partial order on (T ) is continuous (i.e., its graph is closed in (T ) (T )). We also formalize an assumption that was inherent in the original framework: Assumption 8.28 (A2: Anti-symmetry of Preferences). The order is anti-symmetric (i.e., (q q and i q) = = q). Here denotes the symmetric component of i. This means is true partial order, not just preorder. Robust Preferences satisfy A1 and A2. However, we state A2 explicitly as the Revelation Principle applies to general partial orders. A2 is crucial to ensure that the transformed aggregation function is well-defined. Combined with Payment Monotonicity, it ensures that payments are invariant if the allocation remains the same, which is necessary for the transformed payment function to be well-defined. It is worth noting that A2 is restrictive in the context of LLMs, where preferences are typically defined via continuous loss functions (e.g., KL-divergence) which naturally have non-trivial level 129 sets (i.e., distinct distributions can be equally preferred). If A2 is relaxed, the Revelation Principle can still theoretically hold for preorders if the mechanism specifies consistent tie-breaking rule across indifference classes (see the Discussion and Limitation section for the topological limitations of tie-breaking). To ensure that payment functions and strategy mappings remain well-defined in the measure-theoretic sense (which will be essential for integration in later sections), we explicitly state the following measurability assumption: Assumption 8.29 (A3: Measurability). The initial aggregation function q(b, p) is Borel-measurable with respect to the bids b. By removing any continuity assumption on the aggregation function q, our Extended Revelation Principle applies to broad class of mechanisms, including those with discontinuous allocation rules (e.g., step functions) common in mechanism design. Extending Stable Sampling. The challenge in extending Theorem 3.12 is the reliance on differentiation in the original proof. Approach: We use measure-theoretic approach. We associate Lebesgue-Stieltjes (LS) measures with the monotone components of the aggregation function and use the Radon-Nikodym theorem to characterize the transport of probability mass. We carefully define the measures on (0, ) to rigorously handle the boundary at = 0. Importantly, the general Revelation Principle (Theorem 3.5) established in the next section guarantees the existence of an equivalent monotone mechanism, but it does not necessarily guarantee rightcontinuity without loss of generality. However, this technical assumption is standard for defining Lebesgue-Stieltjes measures associated with increasing functions. Thus, for the Stable Sampling construction, we explicitly require: Assumption 8.30 (A4: Right-Continuity). The aggregation function q(b, p) is right-continuous in b. Extended Revelation Principle We now formally prove the extension of the Revelation Principle to Rn + hold. , assuming A1, A2, and A3 Utility Representation Lemma 8.31 (Extended Lemma 3.6). Assume A1. Let the bid space be Rn +. For any distribution aggregation function q, there exists payment function such that mechanism = q, is paymentmonotone if and only if establishes total order over Q(bi, p) = {q(bi, bi, p) : bi R+} for any fixed bi and p. Proof. The only if direction follows directly from the definition of Payment Monotonicity. We prove the if direction. Fix i, bi, p. Let = Q(bi, p). By hypothesis, is total order on Q. Let be the closure of in (T ). Since is finite, the probability simplex (T ) is compact metric space, making compact metric space, which is second-countable under the subspace topology. By A1, is continuous, so the total order extends to continuous total preorder on Q. Debreus Theorem [27] guarantees that there exists continuous utility representation ui : for the preference relation restricted to Q. We can always choose bounded representation (e.g., by composing with strictly increasing, bounded function). Defining the payment function zi(bi, bi, p) = ui(q(bi, bi, p)) yields payment-monotone mechanism. 130 Monotone Extension Lemmas To extend the aggregation function from the image of the strategy mappings to the entire space Rn , we need the following lemmas. We provide supremum-based + extension that naturally guarantees monotonicity. Lemma 8.32 (1D Monotone Extension). Let R+. Let be compact metric space (e.g., (T )) with continuous partial order (A1). Let : be monotone function (non-decreasing) such that its image g(I) is totally ordered by . Let denote the topological closure of subset X. Let xmin = min g(I). Let Yt = {g(y) : I, t}. Then the function : R+ defined by G(t) = (cid:40) max Yt xmin if Yt = if Yt = is monotone extension of g. Proof. We first show G(t) is well-defined. Since is compact and is continuous, the closure of any totally ordered subset of is compact and totally ordered. Thus, for any where Yt = , its closure Yt g(I) possesses maximum element in X. Similarly, since is compact metric space and g(I) is closed subset, xmin = min g(I) is guaranteed to exist. Note that this construction does not require the domain to be compact. = . Then Yt Yt, which implies Yt Yt. Thus If t. Case 1: Yt Monotonicity: max Yt max Yt, so G(t) G(t). Case 2: Yt = . G(t) = xmin. For any t, since Yt g(I), it follows that Yt g(I), so by definition of xmin, G(t) xmin = G(t). Extension property: If I. Then Yt = . Since is monotone, g(t) is the maximum element of Yt. Since Yt Yt and g(t) Yt, G(t) = max Yt = g(t). min min xmin. Thus G(t) G(t). Lemma 8.33 (Monotonicity Preservation). Under the assumptions of Lemma 8.32, let : be another monotone function such that g(I) is totally ordered by . Let be another continuous partial order on X. If g(y) g(y) for all I, then their monotone extensions and satisfy G(t) G(t) for all R+. . Since and are Proof. Fix R+. Case 0: Yt = (t < inf I). G(t) = xmin and G(t) = monotone w.r.t. , xmin and are realized as the limits of g(yk) and g(yk) respectively, for any sequence yk such that yk inf I. We are given g(yk) g(yk). By continuity of , taking the limit yields Case 1: Yt = . Let = sup(I [0, t]). Case 1a: I. By the extension property in Lemma 8.32, G(t) = g(y) and G(t) = g(y). Since g(y) g(y), we have G(t) G(t). Case 1b: / I. Since is the supremum of [0, t] and does not belong to the set, it must be limit point of the set [0, t]. Therefore, there exists an increasing sequence yk [0, t] such that yk y. Since is monotone w.r.t. , g(yk) is non-decreasing. As G(t) is the maximum of Yt, G(t) = limk g(yk). In compact metric space with continuous total order, bounded monotone sequences converge to their suprema (in the order topology, which coincides with the subspace metric topology here since the image is totally ordered and closed). Similarly, G(t) = limk g(yk). We are given g(yk) g(yk) for all k. By the continuity of the order (A1), the order is preserved in the limit. Thus, G(t) G(t). min Strategic Equivalence Lemma 8.34 (Extended Lemma 3.7). Assume A1, A2, and A3. Let the bid space be Rn +. Consider any consistent aggregation function q. Suppose defines total order over the aggregation set Q(bi, p) for any fixed bi and p. Then there exists profile π of strategy mappings such that q(b, p) = q(π(b), p) for some monotone aggregation function q(, ). 131 i, i, i, p) q(b if q(bi, bi, p) i, p)) ui(q(b q(bi, i, p)) πi(bi) πi(b . By definition of i,p, bi i,p i, bi, p) for all bi. Consistency ensures this is total preorder on R+. Proof. We proceed in several steps. Step 1: Induced Preference. Define the induced preference i,p on R+: bi i,p q(b Step 2: Strategy Mapping via Pull-back. We seek utility representation πi : R+ R+ for i, p) for an arbitrary fixed reference profile the induced preorder i,p. Let be the image of q(, . By the premise, is total order on Q. Let be its closure in (T ). Since the token i set is finite, is second-countable, compact metric space. By A1, the preference relation is continuous. The continuity of ensures that the total order property of transfers to its closure Q. Thus, is continuous total preorder on Q. By Debreus theorem [27], the continuous preference relation on admits continuous utility representation ui : R. We can assume without loss of generality that the image of ui is in R+ (by composing with strictly increasing, positive-valued function if necessary). We define the strategy mapping by pulling back the utility from the codomain: πi(bi) := ui(q(bi, i, p)). By Assumption A3, is Borel-measurable. Since ui is continuous, the composition πi is measurable. The Consistent Aggregation property (Definition 8.25) ensures that the preference ordering induced by this mapping is independent of the choice of the reference profile i, p) i). Thus, πi is valid utility representation for ui(q(bi, i,p. This rigorous construction bypasses the need for an order-density assumption on the bid space R+ under the potentially disconnected topology induced by i,p. Step 3: Defining on the Image. Let Ii be the image of πi, and = I1 In. Define q(π(b), p) = q(b, p). We must show this is well-defined. If π(b) = π(b), then bi i,p for all i. This i, bi, p) for all bi. By A2 (Anti-symmetry), this implies equality of the means q(bi, bi, p) q(b distributions. We show q(b) = q(b) by changing bids one by one. Let b(k) = (b k, bk+1, . . . , bn) be the bid profile with the first bids from and the rest from b. Since bk+1 k+1,p , we k+1 have q(b(k)) k+1 q(b(k+1)). By A2, q(b(k)) = q(b(k+1)). Thus, q(b) = q(b). The function is monotone on by construction of π. Furthermore, the 1D images of are totally ordered since the 1D images of are assumed to be totally ordered. iteratively. In step k, we extend the Step 4: Monotone Extension. We extend from to Rn + domain from Dk1 = Rk1 + Ik+1 In. We use Lemma 8.32 to extend along the k-th dimension using the standard numerical order on the k-th coordinate. This is possible because the required conditions (A1, compactness of (T ), total order on 1D images) are met. We must ensure that this extension preserves the monotonicity w.r.t. other orders j. For > k, this follows from Lemma 8.33 (with =k and =j). For < k, the domain is already R+ in the j-th dimension, and the extension in the k-th dimension also preserves monotonicity in the j-th dimension by Lemma 8.33 (by viewing the j-th coordinate as the parameter defining vs g, and the k-th coordinate as the domain being extended). This iterative process yields the monotone extension on Rn . Furthermore, since the extended aggregation function is monotone + in each coordinate by construction, it is continuous almost everywhere with respect to the Lebesgue measure, and thus preserves joint Borel-measurability on the entire domain Rn (e.g., by Lebesgues + theorem for monotone functions), thus satisfying the measurability requirement of the mechanism (Assumption A3). + Ik In to Dk = Rk 1, . . . , The Main Theorem Theorem 8.35 (Extended Theorem 3.5). Let the bid space be Rn +. Assume A1, A2, and A3. Any mechanism = q, with consistent aggregation function and monotone payment function is strategically equivalent to mechanism = q, which has monotone aggregation function and monotone payment function z. 132 Proof. By Payment Monotonicity of and Lemma 8.31, the prerequisites for Lemma 8.34 are met. Lemma 8.34 yields the mappings π and the monotone function q. We define on the image by z(π(b), p) = z(b, p). If π(b) = π(b), then bi i,p for all i. As shown in the proof of Lemma 8.34 (Step 3), under A2 this implies q(b, p) = q(b, p). Since the outcomes are identical, by Payment Monotonicity, zi(b, p) = zi(b, p) for all i. Thus, is well-defined. satisfies Payment Monotonicity because does and q, are defined via the preference representation π. Finally, we extend from to Rn . Note that the original mechanism is fixed, so its payment + function is predetermined and may be unbounded. To accommodate this, we take the codomain for the extension to be the extended real line = [, ], which is compact metric space under the standard order topology. The image of zi on is subset of R. Since zi is monotone in each component (with the standard order on R), we can apply the Monotone Extension Lemma (Lemmas 8.32 and 8.33 applied to the standard order on R) iteratively to extend to Rn + Note that the iterative dimension-by-dimension extension in Step 4 of Lemma 8.34 means that the final extended mechanism depends on the order in which the dimensions are processed. This renders the constructed equivalent mechanism non-unique. However, since the equivalence holds on the image of the strategy mappings, these choices correspond to off-path bids and do not affect the on-path behaviors, strategic properties, or equilibrium payments. . Extended Stable Sampling We now generalize Theorem 3.12 to R+ using measure theory, relying on assumption A4 (RightContinuity) for the monotone aggregation function. We utilize the definitions of + and from Lemma 3.10 in [30]. For notational precision, we define limits at infinity as qo() := limb qo(b) and Q() := limb Q(b). Theorem 8.36 (Extended Theorem 3.12). Given monotone distribution aggregation function satisfying A4, for any agent with robust preferences (and fixed bi, p), there exists stable implementation σ of q(bi). Proof. Let q(b) = q(bi, bi, p). Following [30], define + = {t : qt(0) (pi)t} (weakly undersampled) and = {t : qt(0) > (pi)t} (strictly oversampled). These sets form partition of . By Lemma 3.10 in [30], qt(b) is non-decreasing for + and non-increasing for . By A4, these functions are right-continuous. Step 0: Setup and Trivial Case. We define associated Lebesgue-Stieltjes (LS) measures on (0, ). For +, let νu be the LS measure of the non-decreasing function qu(b), defined such that νu((a, b]) = qu(b) qu(a) for 0 < b. For , let νo be the LS measure of the nondecreasing function qo(0) qo(b), defined such that νo((a, b]) = qo(a) qo(b) for 0 < b. Let Q+(b) = (cid:80) uT + qu(b). Let ν be the LS measure of Q+(b) on (0, ). By the Right-Continuity assumption (A4), Q+(0) = Q+(0+), which guarantees that the measure places no point mass at 0, i.e., ν({0}) = 0. This ensures the integration domain is strictly (0, bi] as used in subsequent integrations. By conservation of probability, (cid:80) νo. Let = ν((0, )) = Q+() Q+(0+) be the total mass moved. If = 0, then q(b) = q(0) for all b. Let = q(0). We define the implementation σ(b, r) for the trivial case = 0 directly on by mapping all to sample from q. This is trivially stable. Assume > 0. Step 1: Measure Theoretic Setup. Since ν((0, )) = 1, ν is finite measure, which strictly fulfills the σ-finite condition for the Radon-Nikodym theorem. Since νt(A) ν(A) on (0, ), νt is absolutely continuous w.r.t. ν. Let ft(θ) = dνt dν (θ) be the Radon-Nikodym derivative for θ (0, ). Note that these derivatives are unique only up to set of ν-measure zero. Consequently, the sampling implementation σ(b, r) constructed below is determined ν-almost everywhere. Using + and νu = ν = (cid:80) 133 as index variables for the respective subsets, we have (cid:80) oT fo(θ) = 1 (ν-a.e.). We define joint measure µ on + (0, ) representing the mass transport. For any measurable set , +, and (0, ), the measure is defined via its action on measurable product sets: uT + fu(θ) = 1 and (cid:80) µ(A E) = (cid:32) (cid:90) (cid:88) oA (cid:33) (cid:32) fo(θ) (cid:88) uB (cid:33) fu(θ) dν(θ). Step 2: Construction of Stable Sampling σ. We define the randomness space and the implementation σ(b, r). Let S+ = Q+(0) and = Q() = (cid:80) oT qo(). Note S+ + + = Q+(0) + Q() + (Q+() Q+(0+)). By the Right-Continuity assumption (A4), Q+(0) = Q+(0+). Additionally, by the definition of the partition, we have the identity Q() = 1 Q+(). Substituting these, the expression simplifies algebraically to (1 Q+()) + Q+() = 1. We define the randomness space as the disjoint union RS+ RS RM , where RS+ = +, RS = , and RM = + (0, ). We equip with the σ-algebra ΣR formed by the disjoint union of the discrete σ-algebras on the finite sets + and , and the Borel σ-algebra on RM (with the discrete topology on and +). We define the probability measure on (R, ΣR) as follows: On RS+: For RS+, (u) = qu(0). On RS: For RS, (o) = qo(). On RM : The restriction of the probability measure to RM is the joint measure on the Borel σ-algebra given by µ defined in Step 1. We define the implementation σ(b, r) for as follows: 1. If RS+ (Static +), = u. Set σ(b, r) = u. 2. If RS (Static ), = o. Set σ(b, r) = o. 3. If RM (Moving Mass), = (o, u, θ). Since θ > 0, we set σ(b, r) = if θ, and σ(b, r) = if < θ. Step 3: Verification. Stability: By construction, for any realization r, the output σ(b, r) as function of is either constant (cases 1 and 2) or switches exactly once from to + at = θ (case 3). Measurability: By construction, the components of σ(b, r) are either constant or simple indicator functions of the form I(b θ) for θ (0, ), which are Borel measurable. Thus, σ(b, r) is valid random variable with respect to ΣR. Correctness: We verify the marginal probability for +. (σ(b) = u) = (r = u) + (r RM , σ(b, r) = u). The first term is qu(0). (Moving part) = (cid:90) I(σ(b, r) = u)dP (r) RM (cid:88) (cid:90) I(b θ)dµ(o, u, θ) oT (cid:90) (0,) (cid:88) fo(θ)fu(θ)dν(θ). (0,b] oT = = Since (cid:80) oT fo(θ) = 1 (ν-a.e.), this equals: (cid:90) = (0,b] fu(θ)dν(θ) = (cid:90) (0,b] dνu(θ) = νu((0, b]). By right-continuity (A4), the LS measure satisfies νu((0, b]) = qu(b) qu(0). Thus, (σ(b) = u) = qu(0) + (qu(b) qu(0)) = qu(b). The verification for is similar. 134 Remark 8.37 (Algorithmic Constructiveness). The proof of Theorem 8.36 provides an existence result for stable sampling based on measure-theoretic construction involving Radon-Nikodym derivatives ft(θ). While theoretically sound, this construction does not immediately yield an efficient sampling algorithm. Note that while the standard inverse-CDF method (F 1(u) = inf{x : (x) u}) is universally applicable to any 1D cumulative distribution function (requiring only right-continuity and non-decreasing properties), the difficulty in the multidimensional LLM implementation arises from the measure-theoretic coupling of probabilities across different tokens, rather than lack of absolute continuity. In practical computational settings, the Radon-Nikodym derivatives ft(θ) can be approximated. For example, the bid space can be discretized into fine grid to estimate the derivatives using finite differences on the empirical cumulative distributions, or one can parameterize the measures using continuously differentiable generative models where the densities are explicitly tractable. Consequently, Proposition 3.13 (Myerson-style payment formula) also generalizes to R+. We note (cid:82) bi that the formula presented in the reference paper [30], zi(bi) = 1 0 (q(bi) pi1 q(b) pi1)db, 2 contained sign error, leading to non-positive payments as the L1 distance is decreasing in b. We provide the corrected formula and its derivation. Proposition 8.38 (Corrected Payment Formula). Under robust preferences and monotone aggregation function satisfying A4, the expected payment zi(bi) induced by the second price rule via stable sampling satisfies: zi(bi) = 1 2 (cid:90) (0,bi] (q(θ) pi1 q(bi) pi1)dθ, bi R+. Proof. We derive the payment formula using the stable implementation σ constructed in Theorem 8.36. Let Zi(bi, r) be the random variable representing the ex-post payment for agent given bid bi and realization R. Under the second-price rule, the payment is the critical bid at which the outcome changes. For realization RM , where = (o, u, θ), the outcome changes from to at bid θ. Thus, Zi(bi, r) = θ if bi θ, and 0 otherwise. For RS+ RS, the outcome is constant, so the critical bid is 0, meaning Zi(bi, r) = 0. The expected payment is: (cid:90) (cid:90) zi(bi) = Er[Zi(bi, r)] = Zi(bi, r)dP (r) = (cid:88) (cid:88) θdµ(o, u, θ). RM oT uT + (0,bi] oT fo(θ) = 1 and (cid:80) Using the definition of µ and the fact that (cid:80) uT + fu(θ) = 1 (ν-a.e.): (cid:90) zi(bi) = (cid:88) θ oT fo(θ) (cid:88) fu(θ) dν(θ) = uT + (0,bi] (cid:90) (0,bi] θdν(θ). Recall that ν is the LS measure associated with the increasing, right-continuous function Q+(b) on (0, ). Using the standard integration by parts formula for Lebesgue-Stieltjes integrals on half-open intervals, (cid:82) (a,b] (x)dU (x). By setting = 0, (x) = x, and (x) = Q+(x), the boundary term at = 0 evaluates directly as 0 Q+(0) = 0. Furthermore, noting that Q+(x) = Q+(x) almost everywhere with respect to the Lebesgue measure dU (x) = dx, we obtain: (a,b] dV = (b)V (b) (a)V (a) (cid:82) (cid:90) (cid:90) zi(bi) = θdQ+(θ) = biQ+(bi) Q+(θ)dθ. This yields the final integral directly without the need for the intermediate limit notation. This is the standard Myerson payment formula with allocation probability Q+(b). Now we relate this (0,bi] (0,bi] 135 to the L1 distance. Let D(b) = q(b) pi1. Under robust preferences (Lemma 3.10 in [30]), let P+ = (cid:80) uT +(pi)u and explicitly define = (cid:80) oT (pi)o. We analyze the distance: D(b) = (cid:88) uT + ((pi)u qu(b)) + (cid:88) oT (qo(b) (pi)o) = (P+ Q+(b)) + (Q(b) P). Since Q(b) = 1 Q+(b) and = 1 P+, we have D(b) = 2(P+ Q+(b)). We now evaluate the integral in the proposition statement: 1 2 (cid:90) = = (cid:90) (0,bi] (D(θ) D(bi))dθ ((P+ Q+(θ)) (P+ Q+(bi)))dθ (0,bi] = biQ+(bi) (cid:90) (0,bi] Q+(θ)dθ. Thus, zi(bi) = I. This confirms the corrected formula and ensures non-negative payments, as D(b) is non-increasing in b. Discussion and Limitations This note successfully extends the core theoretical results of the reference paper from rational to real-valued bids by employing topological and measure-theoretic tools, under the practical assumption of finite token vocabulary. However, these generalizations reveal important limitations and suggest directions for future research. Restrictiveness of the Anti-Symmetry Assumption (A2) in the LLM Context. The reliance on anti-symmetry (A2) for the Revelation Principle excludes scenarios where agents are indifferent between distinct distributions. This is significant limitation in the context of LLMs, where preferences are typically defined via continuous loss functions (e.g., KL-divergence). Continuous loss functions naturally have non-trivial level sets (indifference classes), meaning distinct distributions can be equally preferred, which violates A2. Topological Incompatibility of Tie-Breaking Rules. natural attempt to satisfy the AntiSymmetry assumption (A2) in the presence of indifference classes is to introduce deterministic tie-breaking rule, such as lexicographic ordering over the token probabilities. However, it is well-established result in mathematical utility theory (e.g., [27], [80]) that lexicographic orders on spaces of dimension greater than one (such as (T ) for 3) do not admit continuous utility representations. Specifically, such tie-breaking rules violate the Continuity Assumption (A1) by creating non-closed preference graphs (open sets of strictly preferred outcomes). Since the Extended Revelation Principle critically relies on Debreus Representation Theorem to construct the strategy mappings πi, violating A1 invalidates the utility representation step in Lemma 8.31 and Lemma 8.34. Therefore, A1 and A2 cannot be simultaneously satisfied by simply overlaying standard tie-breaking rule on continuous loss functions. Relaxing A2 by designing appropriate tie-breaking mechanisms that preserve continuity remains an open problem. The Continuity Gap in the Revelation Principle. There is fundamental tension between the generality of the Extended Revelation Principle (Theorem 8.35) and the requirements for Stable Sampling (Theorem 8.36). The Revelation Principle applies broadly, even to discontinuous mechanisms, by constructing an equivalent monotone mechanism. However, this constructed mechanism is not guaranteed to be right-continuous (A4). Since the strategy mappings π and the underlying aggregation function are not required to be continuous, the image space can be disconnected, and the utility values can have jumps. Consequently, any extension schemewhether based on the supremum or the infimumcannot universally guarantee right-continuity. Specifically, an infimum-based extension from the right would fail to be right-continuous at the boundary points of the gaps in I. While this leaves theoretical gap between the mechanisms covered by the Revelation Principle and those implementable via Stable Sampling, it is important to emphasize that the Revelation Principle successfully establishes that we can, without loss of generality, focus on monotone mechanisms. This aligns with standard auction theory, where monotonicity is the cornerstone of incentive compatibility. Given the weak assumptions required, this is positive foundational result. Bridging this gapeither by identifying conditions under which right-continuity can be preserved, extending Stable Sampling to left-continuous mechanisms, or proving that non-right-continuous mechanisms offer no strategic advantageis an interesting direction for future research that goes beyond the scope of this note."
        },
        {
            "title": "8.5 Networked Information Aggregation for Binary Classification",
            "content": "Written by MohammadHossein Bateni, Zahra Hadizadeh, MohammadTaghi Hajiaghayi, Mahdi JafariRaviz, and Shayan Taherijam. Problem Context Recent work by Kearns et al. [60] shows basic limits on information aggregation in distributed In their framework, agents in Directed Acyclic Graph (DAG) act in sequence and learning. minimize Mean Squared Error (MSE), while each agent only sees subset of the input features and the predictions made by earlier agents. Moving from regression to binary classification, using non-linear link function such as logistic regression, raises new challenges. MSE can still be used, but Binary Cross Entropy (BCE) is the standard loss for classification. BCE is harder to study because it is not quadratic. It is open whether the aggregation limits seen with MSE also show up in this classification setting. AI Contribution The AI acted as theoretical collaborator to extend distributed learning limits from linear regression (MSE loss) to binary classification (Binary Cross Entropy loss). By breaking the proof into modular lemmas, the model successfully utilized KL-divergence and Pinskers inequality to rigorously bound the excess risk of the final agent in the network. Overall, the structured prompt in Figure 23 below was instrumental in generating rigorous proofs at several stages of our experience to prove the full theorem. Task: Based on the attached PDF, prove conjecture/theorem below. You must provide rigorous, bug-free proof decomposed into elementary lemmas. Strict Standards: Rigor > Completion: rigorous partial analysis (Outcome 2) is vastly superior to flawed complete proof. No Hallucinations: Every lemma must be proven from elementary principles. Verification: Explicitly verify every step. If you find gap, stop and report it. Required Output Format (Choose One): Outcome 1: COMPLETE PROOF (Use ONLY if every step is 100% rigorous and all cases are covered. Provide formal, stand-alone proof.) Outcome 2: STRUCTURED PARTIAL PROGRESS (Use if ANY logical gaps or unproven assumptions exist.) Proven Lemmas: Rigorously prove what you can. The Crux: Pinpoint exactly where the proof stalls. Next Steps: Propose strategies to bridge the gap. Figure 23: The structured prompt above has led to rigorous proofs, well-organized proof structures, and clear technical insights. The attached PDF represents the current proof structure developed with the assistance of Gemini and further refined by our own reasoning."
        },
        {
            "title": "Details of the Process",
            "content": ", while here Gemini claimed 2 Aaron Roth, one of the authors of the original framework [60], shared how his team integrated AI into their research. He described treating the AI as colleague, providing high-level mathematical intuition which the model expanded into formal proofs. He noted that while this accelerated their work, it required careful verification to catch human-like errors. Adopting this approach, we considered replacing the loss in their framework with BCE using logistic regression. We asked Gemini 3 Pro to derive theorem like the one in the linear regression setting. It produced short chain of lemmas and final theorem that bounds the excess loss of the last node in the DAG, compared to logistic regression learner that has access to all input features. While checking the output, we found one key first lemma (Lemma 8.41) and verified that Gemini proved it correctly. The lemma states that the minimizer of the BCE loss outputs predictions p(x) such that the residual p(x) (where is the binary label) is orthogonal to the input in expectation. Formally, E[x(p(x) y)] = 0. We knew this would matter because it is also the first building block in the MSE setting. The next lemma (Lemma 8.42) compared the loss of the optimal predictor to the loss of any other logistic predictor. Gemini correctly identified that the loss gap can be written using the KullbackLeibler divergence between the predictors output distributions. The lemma itself was needed for the rest of the argument, but Gemini made mistake near the end of the proof, and we fixed it. The next step was the final theorem bounding the excess loss. The bound it gave was stronger than , which in the linear regression setting: there the bound was is smaller when < 1. This is where Gemini started to go off track. Instead of breaking the proof into short lemmas, it wrote one long proof that was not correct. It also added major new assumption: Assume the loss is µ-strongly convex. We kept the theorem statement, including the assumption and the stronger bound, and asked Gemini to regenerate proof in fresh context. Here the prompt in Figure 23 was especially helpful and this time the proof was correct. However, the µ-strong convexity assumption felt indirect. Next, we asked Gemini to remove the µ-strong convexity assumption and replace it with something closer to the boundedness assumptions used by Kearns et al. It produced correct proof, with the weaker bound of , under new assumption: the coefficient vectors of every agents predictor, and of the optimal predictor, have bounded L1 norm. This was still stronger assumption than what was needed in the linear regression setting, where the bound only applies to the optimal predictor. We did not think this was major issue, so we accepted the theorem statement. At that point, we believed the theorem and proof were correct. Still, we prompted Gemini to look for flaws in the proof or statement. It found an error we had missed: you can compare convexity bounds for parameter θ to the optimal parameter θ only when the loss is defined over the same set of indices. Gemini also suggested the fix: since θ lives on the full set of indices, we can pad θ with zeros to get θ, and also pad and add the predecessors parameter vectors in the same coordinate system. The problem was that we assumed θ has bounded L1 norm, and now we would also need θ to have bounded norm. But θ depends on predecessors parameters through this padding-and-summing step, so the norm can grow quickly with depth, and it did not seem reasonable to assume it stays bounded. We then took different path. We noticed that the orthogonality lemma was mainly used for predictor against its own subset of input indices, and orthogonality to predecessors logit outputs was not really used. We changed the assumptions to only require boundedness of the optimal predictor, and asked Gemini to prove the theorem under this smaller assumption, hinting that it should use the orthogonality lemma. Again the prompt in Figure 23 was very helpful. As result, Gemini did so by breaking 139 the proof into lemmas, reusing the correct parts under the new assumption, and adding new helper lemmas to reach the final bound. We then cleaned up the writing and the lemma flow, again using Gemini for rewriting and proofreading. The theorem We consider distributed learning system where agents are arranged in Directed Acyclic Graph (DAG). Let a(i) denote the set of predecessors of agent Ai. Agents are indexed 1, . . . , consistent from the with topological sort of the graph. Each agent Ai observes local subset of features xSi input Rd and the logits {zj}jP a(i) from its predecessors. The agent computes its own logit zi and prediction pi = σ(zi) (where σ is the sigmoid function 1/(1 + ex)) using learnable parameters wi and vij: zi = xSi + (cid:88) vijzj. Agents sequentially update their parameters to minimize the expected Binary Cross Entropy (BCE) loss with respect to the target {0, 1}: jP a(i) L(pi) = [y log pi + (1 y) log(1 pi)] . We also use the notation zθ = θT x, pθ = σ(zθ), and L(θ) = [y log pθ + (1 y) log(1 pθ)]. We now give the following definition. Definition 8.39 (M -Coverage Condition, from Kearns et al.[60]). path satisfies the -coverage condition if every contiguous subsequence of agents collectively observes all features x1, . . . , xd. We aim to prove the following theorem. Theorem 8.40 (Global Convergence Rate). Consider DAG containing path of length of agents A1, . . . , AD satisfying the -coverage condition. Let be the global optimal logistic predictor over all features. Assume: 1. Bounded second moments: E[x2 2. Bounded coefficients: for the optimal logits z(x) = (cid:80) ] B2 for all {1, . . . , d}. αlxl where α1 Bp. Then the excess risk of the final agent pD is bounded by L(pD) L(p) BpBX = (cid:18) (cid:19) . We begin with the following lemma. Lemma 8.41 (Orthogonality of Residuals). Let be the optimal logistic predictor on feature space . The residual error (p(x) y) is orthogonal to the feature vector in expectation: [x(p(x) y)] = 0. Proof. The gradient of the logistic output is θpθ(x) = pθ(x)(1 pθ(x))x. So we get θL(θ) = (cid:20)(cid:18) pθ(x) (cid:19) 1 1 pθ(x) pθ(x)(1 pθ(x))x (cid:21) = [(pθ(x) y)x] . The optimal parameters θ must satisfy the condition θL(θ) = 0. Thus, θL(θ) = [x(p(x) y)] = 0. 140 This orthogonality allows us to decompose the error of any suboptimal model. We will relate the excess loss of logistic predictor by the optimal logistic predictor p, using the expected Kullback-Leibler divergence of the Bernoulli distributions with parameters q(x) and p(x). We denote this measure as D(pq) defined by D(pq) = [DKL(Bernoulli(p(x))Bernoulli(q(x))] 1 p(x) p(x) 1 q(x) q(x) + (1 p(x)) log p(x) log = (cid:20) (cid:21) . Lemma 8.42 (Decomposing Loss). Let be the optimal logistic predictor on feature set S, and let be any logistic predictor in S. The loss decomposes as L(q) = L(p) + D(pq). Proof. Using the identity log σ(z) = log(1 + ez), we write the loss with = θx as Expanding the difference L(θ) L(θ), we obtain L(θ) = [yz log(1 + ez)] . L(θ) L(θ) = (cid:105) (cid:104) log(1 + eθx) log(1 + e(θ)x) y((θ θ)x) . Adding and subtracting p(x)(θ θ)x inside the expectation yields L(θ) L(θ) = (cid:104) log(1 + eθx) log(1 + e(θ)x) p(x)(θ θ)x (cid:105) (cid:104) + (p(x) y)((θ θ)x) . (cid:105) (49) The second term is zero due to the orthogonality condition derived in Lemma 8.41. For the first term, we expand the definition of D(pq) with = θx and = (θ)x: D(pq) = = (cid:104) p(z z) log(1 + ez (cid:104) log(1 + eθx) log(1 + e(θ)x) p(x)(θ θ)x (cid:105) ) + log(1 + ez) (cid:105) . This matches the first term in Equation 49, completing the proof. To relate the KL divergence to the parameter error, we employ the following bound, which is specific case of Pinskers inequality [75]. We include the proof for completeness. Lemma 8.43. For the expected KL divergence D(pq), the following inequality holds: Proof. We verify the inequality pointwise for any . We aim to show D(pq) 2E (cid:2)(p(x) q(x))2(cid:3) . p(x) log p(x) q(x) + (1 p(x)) log 1 p(x) 1 q(x) 2(p(x) q(x))2. (50) Define the function (p) = log is (p) = log log 1p 1q 4(p q). The second derivative is (p) = 1 1q 2(p q)2. The first derivative with respect to p(1p) 4. 1p 4 = 1 + 1 + (1 p) log 1p 141 p(1p) 4, which For [0, 1], the term p(1 p) has maximum value of 0.25. Consequently, implies (p) 0. Since is convex and satisfies (q) = 0, the point = is global minimum. Observing that (q) = 0, we conclude that (p) 0 for all p. Taking the expectation of both sides in (50) yields the result: D(pq) = (cid:20) p(x) log p(x) q(x) + (1 p(x)) log (cid:21) 1 p(x) 1 q(x) 2E[(p(x) q(x))2]. We define the pointwise loss function: Thus, we can write L(p) = E[l(z(x), y)]. l(z, y) = log(1 + ez) yz. Lemma 8.44. Let g(x) = σ(zg(x)) be any logistic predictor. Let be subspace of features and p(x) = σ(zp(x)) be the predictor that minimizes L(p) over S. Then, we have L(p) L(g) + E[(p y)zg]. (51) Proof. Let ϕ(z) = log(1 + ez). The derivatives are ϕ(z) = σ(z) and ϕ(z) = σ(z)(1 σ(z)). Since σ(z) (0, 1), we have ϕ(z) 0, implying ϕ is convex. Convexity implies that for any u, R, ϕ(v) ϕ(u) + ϕ(u)(v u). Rearranging implies the following: ϕ(u) ϕ(v) + σ(u)(u v). (52) We define the relationship between the losses l(u, y) and l(v, y). Substituting l(z, y) = ϕ(z) yz, we assume the following inequality: l(u, y) l(v, y) + (σ(u) y)(u v). (53) Expanding terms confirms this holds given the convexity of ϕ in Equation 52: ϕ(u) yu ϕ(v) yv + σ(u)(u v) yu + yv ϕ(u) ϕ(v) + σ(u)(u v). Now, for point x, let = zp(x) and = zg(x). Applying Equation 53, we get l(zp, y) l(zg, y) + (σ(zp) y)(zp zg). Taking the expectation over gives L(p) L(g) + E[(p y)(zp zg)] = L(g) + E[(p y)zp] E[(p y)zg]. From Lemma 8.41 (Orthogonality), we know that for any feature xl in the support of p, E[xl(py)] = 0. Since zp is linear combination of such features, E[(p y)zp] = 0. Substituting this yields L(p) L(g) E[(p y)zg] L(g) + E[(p y)zg]. We consider path of agents A1, . . . , AD. Each agent receives the logit zi1 from its predecessor and trains logistic predictor model using locally observed features xSi , zi1, and possibly some other predecessors logits. Since one option for the agent Ai is to pass the logits zi1 through, we have that L(pi1) L(pi). We also get that Lemma 8.42 holds for pi1 and pi, since pi1 is in the stricter subspace of pi. We use the notation (x)2 = (cid:112)E [f (x)2] for any function . 142 Lemma 8.45 (Residual Bound via Path Coverage). Let A1, . . . , Ak be path of agents where every feature xl is observed at least once. Let g(x) = σ(zg(x)) where zg(x) = (cid:80)d l=1 αlxl be any logistic predictor over the whole space. Assume the coefficients of zg satisfy (cid:80)d l=1 αl Bg, and the features satisfy E[x2 , for some Bg and BX . Let ε L(p1) L(pk). Then, we have ] B2 E[(pk y)zg] BgBX (cid:114) kε 2 . Proof. Let zg(x) = (cid:80)d l=1 αlxl. We bound the error term: (cid:35)(cid:12) (cid:34) (cid:12) (cid:12) (cid:12) (cid:12) αlxl(pk y) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:88) l=1 E[(pk y)zg] = (cid:88) l= αl E[xl(pk y)]. Consider feature xl. Due to each feature being observed, this feature appears in the index set of some agent Aj in the path. By orthogonality, E[xl(pj y)] = 0. We decompose the expectation using the triangle inequality: E[xl(pk y)] E[xl(pk pj)] + E[xl(pj y)] = E[xl(pk pj)]. Applying the Cauchy-Schwarz inequality gives E[xl(pk pj)] (cid:113) E[x2 ] (cid:113) E[(pk pj)2] = xl2pk pj2. Given xl2 BX , we bound pk pj2 using the loss difference ε. Applying Lemma 8.43, we get for any {1, . . . , 1}: By the triangle inequality and Cauchy-Schwarz, (cid:2)(ps ps+1)2(cid:3) 1 2 D(ps+1ps). pj pk2 (cid:114) k1 (cid:88) s=j D(ps+1ps) 2 (cid:115) (cid:80)k1 s=1 D(ps+1ps) (cid:114) kε 2 . Combining these bounds with the constraint on αl gives E[(pk y)zg] (cid:88) l=1 αl E[xl(pk y)] BgBX (cid:114) kε 2 . We are finally ready to prove Theorem 8.40. Combining Lemma 8.44 and Lemma 8.45, we obtain (cid:112)kε/2 for path of length k. Extending this analysis over the relationship L(pk) L(g) + BgBX the full path satisfying the -coverage condition leads to our main convergence result. Proof of Theorem 8.40. We partition the path into = D/M disjoint blocks of length . By the Pigeonhole Principle, since the total loss reduction is bounded by the loss of the first agent L(p1), there exists at least one stable block where the reduction is at most the total reduction divided by K. Suppose this block is on indices s, + 1, . . . , t. Then, we have (cid:88) i=s+1 (L(pi1) L(pi)) L(p1) 2M L(p1) := ε. 143 (cid:112)M ε/2. Applying Lemma 8.44 and Lemma 8.45, we get that over this path L(pt) L(p) + BpBX Next, note that L(p1) log 2 since using θ1 = 0 achieves loss of log 2, and because the first agent optimizes within its domain then L(p1) log 2 < 1. Combined with the non-increasing losses, we get L(pD) L(p) BpBX . Our theoretical analysis builds on the framework established by Kearns et al. [60] for linear regression. We extend their methods to the classification setting. Unlike their work, which relies on the geometry of Mean Squared Error (MSE), our analysis addresses the non-linearities of the sigmoid function and Binary Cross Entropy (BCE) loss. This necessitates the use of information-theoretic tools to bound the excess risk. The proof strategy for Theorem 8.40 mirrors the methods of Kearns et al. [60]. Lemma 8.41 (Orthogonality) and Lemma 8.42 (Decomposition) establish the logistic equivalents of their linear regression results. However, since the logistic loss does not admit simple Euclidean decomposition, we rely on KL-divergence and Pinsker-type bound (Lemma 8.43) to relate the risk reduction to parameter error."
        },
        {
            "title": "9 Conclusion and Future Directions",
            "content": "The diverse array of case studies presented in this manuscript demonstrates unequivocally that frontier AI modelsspecifically Gemini Deep Think and its advanced variantshave crossed critical threshold. They are no longer merely tools for routine automation, data processing, or syntax formatting; they are now capable of acting as genuine, expert-level collaborators in mathematical and algorithmic discovery. Across theoretical computer science, economics, physics, and optimization, we have shown that LLMs can actively resolve open conjectures, tighten long-standing mathematical bounds, and identify obscure, cross-disciplinary theorems to bypass human roadblocks. In some The value of the AI in these collaborations manifested in several distinct paradigms. instances, it acted as cross-disciplinary bridge, retrieving theorems from distant mathematical domains (such as the Kirszbraun Extension Theorem) to resolve computational geometry roadblocks. In others, it served as relentless adversarial reviewer, successfully identifying fatal, deeply buried flaw regarding perfect versus statistical consistency in state-of-the-art cryptography preprint. Crucially, however, these successes were not achieved autonomously. They required tightly coupled human-AI workflow characterized by iterative refinement, strategic scaffolding, and rigorous verificationa process some authors have colloquially termed vibe-proving."
        },
        {
            "title": "9.1 Understanding Current Limitations and Failure Modes",
            "content": "Left unchecked, current models exhibit distinct failure modes that researchers must actively manage. Across our experiments, several recurring limitations emerged: Confirmation Bias: As noted in the information theory case studies (Section 8.1), models exhibit strong tendency to support the hypothesis presented in prompt. If tasked with proving false conjecture, the AI will often attempt to bridge logical gaps with confident but hand-wavy arguments that do not withstand rigorous scrutiny. Neutral prompting (e.g., prove or refute) is essential. Confident Technical Hallucinations: While models excel at high-level structural insights, they can occasionally make subtle algebraic errors, drop constraints, or confidently misapply theorems (e.g., flipping inequality signs in hypercontractivity bounds). 144 Alignment Friction: Standard safety and alignment guardrails can sometimes hinder scientific exploration. As noted in Section 2, the model may initially refuse to attempt problem if it recognizes it as an unsolved open problem (requiring Context De-Identification to bypass). Because of these limitations, the human researchers role is elevated rather than replaced. The scientist shifts from executing mechanical derivations to acting as an orchestrator, auditor, and strategic director of the AIs combinatorial reasoning."
        },
        {
            "title": "9.2 Future Directions: From Code Execution to Formal Verification",
            "content": "To overcome the limitations of LLM hallucinations, researchers must integrate pure language models with external verification environments. As outlined in Section 2.6 and demonstrated in our cosmic strings experiments (Section 6.4), we are already seeing success by embedding AI in neuro-symbolic loopswhere the model autonomously writes code to numerically verify its proposed mathematical steps and uses traceback errors to prune invalid branches. However, while numerical execution is powerful grounding mechanism for applied mathematics and physics, it is fundamentally limited when dealing with abstract proofs. For pure mathematics and theoretical computer science, the natural evolution of this workflow is Formal Verification. As AI systems generate increasingly complex, multi-page mathematical proofs, human verification becomes an exhausting bottleneck. Future research must focus on building autoformalization pipelines that automatically translate LLM-generated informal mathematics into formal verification languages (such as Lean, Coq, or Isabelle). By pairing the creative, associative leaps of an LLM with the absolute rigorous certainty of an interactive theorem prover, the research community can systematically eliminate the hallucination problem in mathematical discovery."
        },
        {
            "title": "9.3 The Shifting Bottleneck: An Impending Crisis in Peer Review",
            "content": "As AI drastically lowers the friction of generating highly technical, mathematically dense research papersevidenced by the AI-integrated IDE workflow utilized in Section 5 the scientific community faces an impending systemic challenge. If researchers can vibe-code comprehensive papers in fraction of the traditional time, the fundamental bottleneck of science will shift entirely from the generation of ideas to the verification of those ideas. The traditional human peer-review system is already strained and fundamentally unequipped to handle massive influx of AI-accelerated literature. Consequently, the very same tools used to generate these papers must be adapted to evaluate them. The cryptography case study (Section 3.2) proves that AI models, when guided by rigorous, adversarial self-correction protocols, are already capable of finding subtle flaws in advanced proofs. Developing robust, AI-assisted peer-review systems will be vital to triaging submissions and maintaining the integrity of the scientific literature in the coming years."
        },
        {
            "title": "9.4 Final Thoughts",
            "content": "Just as the advent of calculators and computational algebra systems revolutionized applied mathematics in previous decades, the ability to rapidly iterate on abstract reasoning with tireless, knowledgeable AI collaborator promises to dramatically reduce the friction of theoretical execution. By embracing this collaborative paradigm, understanding its failure modes, and building the automated verification pipelines of the future, researchers can tackle more ambitious problems, explore broader hypothesis spaces, and ultimately accelerate the pace of scientific discovery."
        },
        {
            "title": "Acknowledgments",
            "content": "The authors thank the Gemini team for access to early models and technical support. We also acknowledge members of the Deep Think team that are not authors: Garrett Bingham, Irene Cai, Heng-Tze Cheng, Yong Cheng, Kristen Chiafullo, Paul Covington, Golnaz Ghiasi, Chenjie Gu, Huan Gui, Ana Hosseini, Dawsen Hwang, Vihan Jain, Ragha Kotikalapudi, Chenkai Kuang, Maciej Kula, Nate Kushman, Jane Labanowski, Quoc Le, Jonathan Lee, Zhaoqi Leng, Steve Li, YaGuang Li, Hanzhao (Maggie) Lin, Evan Liu, Yuan Liu, Thang Luong, Pol Moreno, Nigamaa Nayakanti, Aroonalok Pyne, Shubha Raghvendra, Sashank Reddi, Nikunj Saunshi, Siamak Shakeri, Archit Sharma, Xinying Song, Qijun Tan, Yi Tay, Trieu Trinh, Theophane Weber, Winnie Xu, Zicheng Xu, Shunyu Yao, Lijun Yu, Hao Zhou, and Honglei Zhuang."
        },
        {
            "title": "References",
            "content": "[1] Anantharam, V., Bogdanov, A., Chakrabarti, A., Jayram, T. S., and Nair, C. (2017). conjecture regarding optimality of the dictator function under Hellinger distance. In Information Theory and Applications Workshop. [2] Arora, Sanjeev. Polynomial time approximation schemes for Euclidean traveling salesman and other geometric problems. Journal of the ACM, 45(5):753782, 1998. [3] Arora, Sanjeev and Karger, David and Karpinski, Marek. Polynomial time approximation schemes for dense instances of NP-hard problems. Proceedings of the twenty-seventh annual ACM symposium on Theory of computing, pages 284293, 1995. [4] Avidor, Adi and Zwick, Uri. Rounding two and three dimensional solutions of the SDP relaxation of MAX CUT. International Workshop on Approximation Algorithms for Combinatorial Optimization, pages 1425, 2005. [5] Aygün, Eser et al. An AI system to help scientists write expert-level empirical software. arXiv preprint arXiv:2509.06503, 2025. [6] Bakshi, A., Indyk, P., Jayaram, R., Silwal, S., Waingarten, E. (2023). near-linear time algorithm for the chamfer distance. NeurIPS 2023. [7] Bansal, Nikhil and Cohen-Addad, Vincent and Prabhu, Milind and Saulpic, David and Schwiegelshohn, Chris Sensitivity Sampling for k-Means: Worst Case and Stability Optimal Coreset Bounds. Proceedings of the 65th IEEE Annual Symposium on Foundations of Computer Science (FOCS 2024), pages 17071723, 2024. [8] Barak, Boaz and Raghavendra, Prasad and Steurer, David. Rounding semidefinite programming hierarchies via global correlation. 2011 ieee 52nd annual symposium on foundations of computer science, pages 472481, 2011. [9] Barnes, L. P., and Özgür, A. (2020, June). The Courtade-Kumar most informative Boolean function conjecture and symmetrized Li-Médard conjecture are equivalent. IEEE International Symposium on Information Theory (ISIT), 2205-2209. [10] Bottcher, Julia and Pruessmann, Klaas P. and Taraz, Anusch and Würfl, Andreas. Bandwidth, expansion, treewidth, separators and universality for bounded-degree graphs. European Journal of Combinatorics, 31(5):12171227, 2010. 146 [11] Brânzei, Simina and Li, Jiawei. The Query Complexity of Local Search and Brouwer in Rounds. COLT, 2022. In Mathematical Statistics and Learning, forthcoming. [12] Simina Brânzei, Ioannis Panageas, and Dimitris Paparas. The Query Complexity of Local Search in Rounds on General Graphs. arXiv:2601.13266 [cs.CC], 2026. https://arxiv.org/ abs/2601.13266. [13] Briet, Jop and de Oliveira Filho, Fernando Mário and Vallentin, Frank. The positive semidefinite Grothendieck problem with rank constraint. International Colloquium on Automata, Languages, and Programming, pages 3142, 2010. [14] Briet, Jop and de Oliveira Filho, Fernando Mário and Vallentin, Frank. Grothendieck Inequalities for Semidefinite Programs with Rank Constraint. Theory of Computing, 10(1):77105, 2014. [15] Bubeck, Sébastien and Coester, Christian and Eldan, Ronen and Gowers, Timothy and Lee, Yin Tat and Lupsasca, Alexandru and Sawhney, Mehtaab and Scherrer, Robert and Sellke, Mark and Spears, Brian et al. Early science acceleration experiments with GPT-5. arXiv preprint arXiv:2511.16072, 2025. [16] Cai, J.-Y. SP 2 ZPPNP. Journal of Computer and System Sciences, 73(1):2535, 2007. [17] Canetti, R. More on BPP and the polynomial-time hierarchy. Information Processing Letters, 57(5):237241, 1996. [18] Chandar, Venkat and Tchamkerten, Aslan. Most informative quantization functions. Proc. ITA Workshop, San Diego, CA, USA, 2014. [19] Chang, Chun-Hao and Rampasek, Ladislav and Goldenberg, Anna. Dropout feature ranking for deep learning models. arXiv preprint arXiv:1712.08645, 2017. [20] F. Chierichetti, M. Giacchini, R. Kumar, S. Lattanzi, A. Panconesi, E. Tani, A. Tomkins. Beyond the Full Slate: Evaluating MNL Algorithms on All Slates. Private Communication. [21] M. B. Cohen, C. Musco, and C. Musco, Input sparsity time low-rank approximation via ridge leverage score sampling, Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 17581777, 2017. [22] Cohen-Addad, V. and Woodruff, David P. Google Research Blog post, 2025. https: //research.google/blog/gemini-provides-automated-feedback-for-theoreticalcomputer-scientists-at-stoc-2026/ [23] Courtade, T. A., Kumar, G. R. (2014). Which Boolean functions maximize mutual information on noisy inputs? IEEE Transactions on Information Theory, 60(8), 45154525. [24] P. Csikvári. Lower matching conjecture, and new proof of Schrijvers and Gurvitss theorems. Journal of the European Mathematical Society (EMS Publishing) 19 (6), 2017. [25] Csirmaz, L., Ligeti, P., Tardos, G. (2015). Erdős-Pyber theorem for hypergraphs and secret sharing. Graphs Combin., 31(5):13351346. [26] Cygan, M. and Fomin, F. V. and Kowalik, L. and Lokshtanov, D. and Marx, D. and Pilipczuk, M. and Pilipczuk, M. and Saurabh, S. Parameterized Algorithms. Springer, 2015. 147 [27] Gerard Debreu. Representation of Preference Ordering by Numerical Function. Decision processes 3 (1954): 159-165. [28] Du, Ding-Zhu and Smith, Warren D. Disproofs of Generalized Gilbert Pollak Conjecture on the Steiner Ratio in Three or More Dimensions. Journal of Combinatorial Theory, Series A, 74(1):115130, 1996. [29] Duede, E. Tail Novelty, Knowledge Collapse, and Useful Frictions in Science. Computer Science Seminar, Illinois Institute of Technology, November 17, 2025. https://bit.ly/iit-cs-seminar-duede [30] Paul Dütting, Vahab Mirrokni, Renato Paes Leme, Haifeng Xu, and Song Zuo. Mechanism Design for Large Language Models. In Proceedings of the ACM Web Conference 2024 (pp. 144-155). [31] G.P. Egorychev. Proof of the van der Waerden conjecture for permanents [in Russian]. Sibirskii Matematicheskii Zhurnal, 22:6, 6571, 1981. [32] D.I. Falikman. Proof of the van der Waerden conjecture regarding the permanent of doubly stochastic matrix [in Russian]. Matematicheskie Zametki, 29:931938, 1981. [33] Fand, M. (2021). Fast Johnson-Lindenstrauss Transform. arXiv preprint arXiv:2104.05695. [34] Feige, Uriel and Karpinski, Marek and Langberg, Michael. Improved approximation of Max-Cut on graphs of bounded degree. Journal of Algorithms, 43(2):201219, 2002. [35] T. Feng, T. Trinh, G. Bingham, J. Kang, S. Zhang, et al., Semi-Autonomous Mathematics Discovery with Gemini: Case Study on the Erdős Problems, arXiv preprint arXiv:2601.22401 (2026). Available at: https://arxiv.org/abs/2601.22401. [36] T. Feng, T. H. Trinh, G. Bingham, D. Hwang, Y. Chervonyi, et al., Towards Autonomous Mathematics Research, arXiv preprint arXiv:2408.00000 (2026). Available at: https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/towardsautonomous-mathematics-research/Towards_Autonomous_Mathematics_Research.pdf [37] Feng, Y., Indyk, P. (2025). Even Faster Algorithm for the Chamfer Distance. ICALP 2025. [38] Feng, Y., Woodruff, David P. (2026). Fast Approximate Lp Chamfer Distance via Lopsided Embeddings and Structured JL. In submission 2026. [39] Fleischmann, H., Gamboa Quintero, G., Karthik C. S., Matějka, J., Petr, J. (2025). On Steiner Trees of the regular simplex. Journal of Computational Geometry, 16(1), 134. [40] Fleischmann, Henry and Gavva, Surya Teja and Karthik C. S.. On Approximability of Steiner Tree in ℓp-metrics. TheoretiCS, 4, 2025. [41] Fortnow, L. Search versus Decision for 2 . arXiv preprint arXiv:2512.02808, 2025. https: //arxiv.org/abs/2512. [42] L. Fortnow. fortnow/s2psearch: Files related to vibe-coding the Search vs Decision for S2P paper. GitHub repository, 2025. https://github.com/fortnow/s2psearch [43] Yao Fu, et al. Tree of Thoughts: Deliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601, 2023. 148 [44] Ganor, Anat and Karthik C. S. and Pálvölgyi, Dömötör. On Communication Complexity of Fixed Point Computation. ACM Trans. Economics and Comput., 9(4):25:125:27, 2021. [45] Paritosh Garg, Sagar Kale, Lars Rohwedder, and Ola Svensson. Robust Algorithms Under Adversarial Injections. Proceedings of the 47th International Colloquium on Automata, Languages, and Programming (ICALP), 2020, pages 56:156:15. [46] Gemini Deep Think. https://blog.google/products/gemini/gemini-2-5-deep-think/. [47] B. Georgiev, J. Gómez-Serrano, T. Tao, and A. Z. Wagner, Mathematical exploration and discovery at scale, arXiv preprint arXiv:2511.02864, 2025. [48] Ghashami, M., Liberty, E., Phillips, J. M., Woodruff, D. P. (2016). Frequent directions: Simple and deterministic matrix sketching. SIAM Journal on Computing, 45(5), 17621792. [49] Gilbert, Edgar N. and Pollak, Henry O. Steiner Minimal Trees. SIAM Journal on Applied Mathematics, 16(1):129, 1968. [50] Goemans, Michel and Williamson, David P. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. Journal of the ACM (JACM), 42(6):11151145, 1995. [51] Ziyi Guan and Eylon Yogev. SNARGs for NP from LWE. Cryptology ePrint Archive, Paper 2025/2328, 2025. [52] L. Gurvits. Van der Waerden/Schrijver-Valiant like conjectures and stable (aka hyperbolic) homogeneous polynomials: one theorem for all. Electron. J. Combin., 15(1), Research Paper 66, 2008. [53] L. Gurvits. Unleashing the power of Schrijvers permanental inequality with the help of the Bethe Approximation. ArXiv preprint 1106.2844v11, 2011. [54] Harvey, Nicholas J. A. and Nelson, Jelani and Onak, Krzysztof. Sketching and streaming entropy via approximation theory. FOCS 2008, 489498. [55] Hsieh, Jun Ting and Kothari, Pravesh K. Approximating Max-Cut on Bounded Degree Graphs: Tighter Analysis of the FKL Algorithm. 50th International Colloquium on Automata, Languages, and Programming, ICALP 2023, page 77, 2023. [56] In, Chansophea Wathanak and Li, Yi and Woodruff, David and Wu, Xuan. Robust Sparsification via Sensitivity. Proceedings of ICML 2025, pages 2644626463, 2025. [57] Ivanov, Alexander O. and Tuzhilin, Alexey A. The Steiner Ratio Gilbert Pollak Conjecture Is Still Open: Clarification Statement. Algorithmica, 62(1-2):630632, 2012. [58] Javanmard, A., and Woodruff, D. P. (2026). Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information. arXiv preprint arXiv:2601.09679. [59] Jayaram, R., Woodruff, D. P., Zhou, S. (2024). Streaming Algorithms with Few State Changes. Proc. ACM Manag. Data, 2(2), 82. 149 [60] M. Kearns, A. Roth, and E. Ryu. Networked information aggregation via machine learning. Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2026, 47994845. [61] H. Kesten. Symmetric random walks on groups, Trans. Am. Math. Soc. 92 (1959), 336354. [62] Khot, Subhash and Kindler, Guy and Mossel, Elchanan and ODonnell, Ryan. Optimal SIAM Journal on inapproximability results for MAX-CUT and other 2-variable CSPs? Computing, 37(1):319357, 2007. [63] Kirszbraun, M. \"Uber die zusammenziehende und Lipschitzsche Transformationen. Fundamenta Mathematicae, 22(1):77108, 1934. [64] Korula, N., Mirrokni, V., Zadimoghaddam, M. (2015). Online submodular welfare maximization: Greedy beats 1/2 in random order. STOC 2015. [65] Krapivin, A., Przybocki, B., Sanhueza-Matamala, N., Subercaseaux, B. (2025). Optimal and efficient partite decompositions of hypergraphs. arXiv preprint arXiv:2511.11855. [66] Li, J., and Médard, M. (2020). Boolean functions: noise stability, non-interactive correlation distillation, and mutual information. IEEE Transactions on Information Theory, 67(2), 778-789. [67] L. Lovász, M. Plummer. Matching Theory. AMS Chelsea Publishing Series, 2009. [68] Thang Luong and Edward Lockhart. Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International Mathematical Olympiad. Google DeepMind Blog, July 21, 2025. [69] B. D. McKay. The expected eigenvalue distribution of large regular graph, Linear Algebra Appl. 40 (1981), 203216. [70] Mitchell, Joseph S. B. Guillotine Subdivisions Approximate Polygonal Subdivisions: Simple Polynomial-Time Approximation Scheme for Geometric TSP, k-MST, and Related Problems. SIAM Journal on Computing, 28(4):12981309, 1999. [71] Nagda, Ansh and Raghavan, Prabhakar and Thakurta, Abhradeep. Reinforced Generation of Combinatorial Structures: Hardness of Approximation. arXiv preprint arXiv:2509.18057, 2025. [72] A. Nilli. On the second eigenvalue of graph, Discrete Mathematics, 91 (1991), 207210. [73] Novikov, Alexander, Vu, Ngân and Eisenberger, Marvin and Dupont, Emilien and Huang, Po-Sen and Wagner, Adam Zsolt and Shirobokov, Sergey and Kozlovskii, Borislav and Ruiz, Francisco JR and Mehrabian, Abbas et al. AlphaEvolve: coding agent for scientific and algorithmic discovery. arXiv preprint arXiv:2506.13131, 2025. [74] Ordentlich, Or and Shayevitz, Ofer and Weinstein, Omri. An improved upper bound for the most informative Boolean function conjecture. 2016 IEEE International Symposium on Information Theory (ISIT), pages 500504, 2016. [75] M. S. Pinsker. Information and Information Stability of Random Variables and Processes. HoldenDay, 1964. [76] Raghavendra, Prasad. Optimal algorithms and inapproximability results for every CSP? Proceedings of the fortieth annual ACM symposium on Theory of computing, pages 245254, 2008. [77] Russell, A. and Sundaram, R. Symmetric alternation captures BPP. Computational Complexity, 7(2):152162, 1998. [78] Samorodnitsky, A. (2016). On the entropy of noisy function. IEEE Transactions on Information Theory, 62(10), 5446-5464. [79] Santha, Miklos and Szegedy, Mario. Quantum and classical query complexities of local search are polynomially related. Proceedings of the thirty-sixth annual ACM symposium on Theory of computing, pages 494501, 2004. [80] David Schmeidler. Condition for the Completeness of Partial Preference Relations. In: Econometrica: Journal of the Econometric Society (1971), pp. 403404. [81] A. Schrijver. Counting 1-Factors in Regular Bipartite Graphs. Journal of Combinatorial Theory, Series B, 72:122135, 1998. [82] A. Schrijver, W.G. Valiant. On lower bounds for permanents. Indagationes Mathematicae, 42:425427, 1980. [83] Schwartz, Jacob T. Nonlinear Functional Analysis. Gordon and Breach Science Publishers, New York, 1969. [84] M. Sellke and S. Yin, On Learning-Curve Monotonicity for Maximum Likelihood Estimators, arXiv preprint arXiv:2512.10220, 2025. [85] Smith, Warren D. How to find Steiner minimal trees in Euclidean d-space. Algorithmica, 7:137177, 1992. [86] N. Sothanaphan, Resolution of Erdős Problem #728: writeup of Aristotles Lean proof, arXiv preprint arXiv:2601.07421, 2026. [87] Trevisan, Luca. When Hamming Meets Euclid: The Approximability of Geometric TSP and Steiner Tree. SIAM J. Comput., 30(2):475485, 2000. [88] Valentine, F. A. Lipschitz condition preserving extension for vector function. American Journal of Mathematics, 67:8393, 1945. [89] L. Valiant. The complexity of computing the permanent. Theoretical Computer Science, 8(2):189201, 1979. [90] P. O. Vontobel. The Bethe Permanent of Non-Negative Matrix, IEEE Transactions on Information Theory, vol. 59, no. 3, pp. 1866-1901, 2013. (Also arXiv:1107.4196). [91] M. Voorhoeve. lower bound for the permanents of certain (0, 1)-matrices. Nederl. Akad. Wetensch. Indag. Math., 41(1):8386, 1979. [92] Woodruff, David P. and Zhou, Samson. Consistent Low-Rank Approximation. The Fourteenth International Conference on Learning Representations (ICLR) 2026."
        }
    ],
    "affiliations": [
        "Bar-Ilan University",
        "Carnegie Mellon University",
        "EPFL",
        "Google Research",
        "Harvard University",
        "Illinois Institute of Technology",
        "MIT",
        "Nanyang Technological University",
        "National Institute of Informatics, Tokyo",
        "Purdue University",
        "Rutgers University",
        "Texas A&M University",
        "The University of Tokyo",
        "University of California, Irvine",
        "University of Maryland, College Park",
        "University of Michigan",
        "University of Southern California"
    ]
}