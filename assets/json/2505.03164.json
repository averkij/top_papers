{
    "paper_title": "InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships",
    "authors": [
        "Ji Won Chung",
        "Tongyu Zhou",
        "Ivy Chen",
        "Kevin Hsu",
        "Ryan A. Rossi",
        "Alexa Siu",
        "Shunan Guo",
        "Franck Dernoncourt",
        "James Tompkin",
        "Jeff Huang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Traditional data presentations typically separate the presenter and visualization into two separate spaces--the 3D world and a 2D screen--enforcing visualization-centric stories. To create a more human-centric viewing experience, we establish a more equitable relationship between the visualization and the presenter through our InfoVids. These infographics-inspired informational videos are crafted to redefine relationships between the presenter and visualizations. As we design InfoVids, we explore how the use of layout, form, and interactions affects the viewer experience. We compare InfoVids against their baseline 2D `slides' equivalents across 9 metrics with 30 participants and provide practical, long-term insights from an autobiographical perspective. Our mixed methods analyses reveal that this paradigm reduced viewer attention splitting, shifted the focus from the visualization to the presenter, and led to more interactive, natural, and engaging full-body data performances for viewers. Ultimately, InfoVids helped viewers re-imagine traditional dynamics between the presenter and visualizations."
        },
        {
            "title": "Start",
            "content": "InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships JI WON CHUNG, Brown University TONGYU ZHOU, Brown University IVY CHEN, Brown University KEVIN HSU, Brown University RYAN A. ROSSI, Adobe Research ALEXA SIU, Adobe Research SHUNAN GUO, Adobe Research FRANCK DERNONCOURT, Adobe Research JAMES TOMPKIN, Brown University JEFF HUANG, Brown University 5 2 0 2 6 ] . [ 1 4 6 1 3 0 . 5 0 5 2 : r Fig. 1. InfoVids provide viewers with new visualization-presenter paradigm. By visualizing the presenter and the data within shared 3D space, InfoVids redefine the relationship between them. Film Strip Left: virtual plane enters from the sky. Film Strip Center: The background and clouds immerse the presenter within the frame and contextualize the plane. Film Strip Right: The presenters full-body next to the plane emphasizes their relative sizes. The presenter is an external, hired actor. Ji Won Chung et al. Traditional data presentations typically separate the presenter and visualization into two separate spacesthe 3D world and 2D screen enforcing visualization-centric stories. To create more human-centric viewing experience, we establish more equitable relationship between the visualization and the presenter through our InfoVids. These infographics-inspired informational videos are crafted to redefine relationships between the presenter and visualizations. As we design InfoVids, we explore how the use of layout, form, and interactions affects the viewer experience. We compare InfoVids against their baseline 2D slides equivalents across 9 metrics with 30 participants and provide practical, long-term insights from an autobiographical perspective. Our mixed methods analyses reveal that this paradigm reduced viewer attention splitting, shifted the focus from the visualization to the presenter, and led to more interactive, natural, and engaging full-body data performances for viewers. Ultimately, InfoVids helped viewers re-imagine traditional dynamics between the presenter and visualizations. Additional Key Words and Phrases: Mobile AR, Data Visualization-based AR, Interactions 1 INTRODUCTION Now Im going to try something Ive never done before: Animating the data in real space. Prof. Hans Rosling Data visualizations convey both the data and the ideas behind them. As Rosling demonstrates in his widely-viewed presentation 200 Countries, 200 Years, 4 minutes [58], how you narrate the story behind the data can be just as important as the visualization itselfor even more soin conveying the ideas. Roslings body and the data co-exist in the video space, letting him synchronize his body movements with animated 2D visualizations. His passion is evident as he kneels and gesticulates to demonstrate rises in life expectancy. Despite Roslings captivating performance in 2011, modern visualization presentations by design typically separate presenters from the content to draw viewers attention towards the visualizations. In many commercial, teleconferencing presentations (e.g. Zoom, Teams, Google Meet), presenters are compartmentalized away in little box in the corner to maximize view of the visualizations. Such visualization-centric formats implicitly send the viewer message to prioritize the visualization over the presenter. However, establishing an imbalanced relationship is design choice and comes with trade-offs. The viewer misses the human element, an opportunity to fully connect with the presenter as the presenters body language and expressions are minimized. Imagine Roslings performance restricted to little boxwould we, as viewers, feel the same level of passion and engagement? What if we offer viewers an alternative presentation paradigm that by design establishes an equitable relationship between the visualization and presenter? Rather than having the two compete for screen space, what if we integrate the visualization within the same space of the presenter, allowing the viewer to see both within the same frame? How would this shift impact the way viewers engage with the content, the presenter, and the overall experience compared to more traditional formats? And in the process of designing and evaluating such presentations, what can we learn about designing for alternative visualization presentation systems? To answer these questions, we conduct an exploratory investigation of the viewer experience with four custom-constructed case technology probes [33], InfoVids. These are informational videos inspired by shorts and infographics, iteratively designed over the span of four months. Each InfoVid showcases the viewer unique spatial arrangement of the visualization and presenter, while ensuring the viewer has full view of both at all times. To understand the potential advantages and challenges of the InfoVid from the viewers perspective, we ask 30 viewers in public to compare an InfoVid with its baseline equivalent. The latter includes the same content as the InfoVid, but adapts the format of more traditional, videoconferencing presentation with visualizations. The baseline is not used InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships to evaluate whether our probes are better, but as method to help viewers articulate the differences between the two formats, which may be difficult with the probe alone given that they are encountering new medium. Viewers compare the two based on eight metrics that may influence the viewing experience: perceived presenter immersion, engagement, and co-presence with the visualization, natural body movement, enjoyability, storytelling, information understanding, and viewers attention between the presentation and the visualization. We conduct semi-structured interview to understand what elements in the InfoVid affected their viewing experience. Finally, we share the lessons learned from our viewer evaluations and the process of designing the InfoVids from an autobiographical perspective. Our exploratory investigation with InfoVids reveals valuable design implications for alternative, visualization presentation systems. First, we learn that the simple design condition of having both the presenter and the visualization in the same frame affects the viewing experience by compelling the presentation designer to be more conscious of the relationship between the visualization and the presenter an overlooked factor when the presenter is sidelined to small box. In addition, while most viewers find InfoVids more enjoyable and pay more attention to the presenter over the visualization than the baseline, we discover how varying social expectations among the presenter, visualization, and viewer influence the viewing experience. Lastly, situating the presenter and the visualization in the same space enables viewers to consider the presenters body as connected to the flow of the story, an experience that is otherwise absent when the two are not co-located. 2 RELATED WORK 2.1 Different Ways to Communicate Visual Data Data is more than just numbersit tells story, message through the numbers. To tell an effective story, we need the right tools. Different tools change how we present information to the viewer. To interactively explore data stories, viewer can use web-based visualizations such as D3.js [8], Vega [62], or PortalInk [77]. To unfold story in real-time with the viewers, the presenter can draw story using SketchStory [39]. To visually captivate viewers and convey singular, simple message to them, we can create infographics [40, 42, 44, 76]. More recently, as tools have evolved, new paradigm for the viewing experience has emerged. Information now disseminates on social media platforms via short-form videos, or shorts. To engage viewers, shorts situate the presenter in the same space as the augmented virtual content, allow the presenter to interact directly with the virtual elements, and even use hard cuts and quick transitions to capture the viewer attention [30, 7274]. This format stands apart from data videos [1, 2, 59], as it places the presenter themselves at the core function of the videos narration and storytelling. In addition to the presenters voice, their body language and facial expressions are central to the viewing experience. Such shorts aim to engage day-to-day viewers and inform them in short amount of time. They often employ more casual, and even playful narrative style and visualizations (e.g. memes, GIFs) and are not as formal as traditional presentations with visualizations [72, 78]. They are like the infographic equivalent of videos; both use visual embellishments and focus on delivering simple and engaging data narratives to reach wider audience [3, 29, 40]. Inspired by such shorts, we design new informational videos, or InfoVids, that integrate presenters and visualizations in the same frame. Question is, how do viewers respond to the integration of visualizations into shorts new layout, different from traditional presentation styles? The literature has limited understanding on these new forms of presentations, and on what factors impact the viewer experience. This is, in part, because AR data visualization tools have traditionally focused on using augmented reality to explore multidimensional scientific data [32, 46, 61, 70, 75], enhance human information processing capabilities [13, 15, 56], or enhance immersion with the data [14, 18, 38, 63]. They do not explore how the Ji Won Chung et al. viewing experience is affected when AR is leveraged to convey information in more casual, presentation settingsthis is the very gap in knowledge this paper seeks to fill. 2.2 Implicit Relationships Defined by Presenter-Visualization Interactions To transform and enhance the viewing experience, previous works have explored innovative ways presenter could interact with visual graphics. Both ChalkTalk [55] and Saquib et al. [60] allow the presenter to interact with 2D graphics and sketches. CLIO [20] and Reality Talk [41] demonstrate new viewing experience by allowing the presenter to interact with 2D visuals with their voice and hand gesture interactions. Hall et al. designs their own hand gesture language and experiments with different layouts of the visualization to ensure the scientific integrity of the visualizations for the viewers [28]. Other works investigate how to enhance and transform the viewing experience by coupling or binding visualizations with the presnters body. BodyVis engages the viewers with anatomy visualizations by using wearable e-textile shirt [52]. Within the realms of AR, MagicMirror [67] and mirracle [5] both overlay medical or biodata visualizations over the presenters body. RealitySketch uses AR to analyze different physical motions, including those of people [68]. In other cases, the coupling provides viewers with more to creative and artistic presentations. HandAvatar enables the presenter to create non-humanoid puppet performances by binding virtual animals to the hand [35]. Pei et al.s Hand Interfaces framework uses hands to generate an associated virtual object such as wands and healing potions [54]. Such interactions not only transform the viewing experience, but more importantly, these interactions also implicitly define the relationship between the presenter and the visualization. Interactions establish who can affect what, and the parties involved in the interaction imply the nature of the relationship between them. For example, the presenters ability to move around visualization means the visualization is secondary, at will, to the presenter. Understanding the nature of the relationship is crucial because the relationship itself can convey message to the viewers. However, this aspect is overlooked in previous works, and this paper aims to explore the factors that shape such relationships and understand how they may affect the viewing experience. 3 DESIGNING INFOVIDS To inform the development of the tools needed to build and design four case InfoVids, we engaged in an iterative design process over the course of nine months. Each InfoVid serves as technology probe, used to find out about the unknown and we adopt this approach to explore how we can challenge pre-existing ideas and influenc[e] future [33] visualization presentation technologies. This section outlines the development of our iterations and the lessons learned throughout the process. Because this design process required interdisciplinary knowledge of augmented reality, visualizations, and presentations an intersectional expertise not commonly found among participantswe chose to draw our insights from an autobiographical perspective [22, 31, 50, 77] to offer deeper understanding of the challenges and decisions involved in the process. 3.1 Designing for an Equitable Relationship Our primary aim was to design format that establishes an equitable relationship with presenter and the visualization, from both the presenter and the viewers perspective. To achieve this, we first integrated the spatial dimensions of the visualizations with that of the presenter. Drawing from previous works [20, 28, 41, 55, 58, 60], we overlaid 2D visualization of bar charts and scatter plots onto the same screen of the presenter using augmented reality (ARKit on iPhone). While, from the viewers perspective, this setup placed the presenter at the center of the frame and resolved the visual divide between the presenter and the visualization (e.g. how the presenter is compartmentalized in box in teleconferencing systems), we observed from our own experiences acting as presenter that this design still did not fully establish an equitable relationship. InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships 3.1.1 Redefining Relationships Using the Third Dimension. The flat 2D form of the visualization warranted that we, as the presenters, compromise our movements in 3D space for the visualizations. When we took viewers perspective, and reviewed recordings of ourselves presenting with this design, we frequently observed ourselves miming. As presenters, we were moving around the virtual visualization and using awkward body language only in the horizontal dimension. We never utilized the third, ùëß-dimension, as we might in real-life presentation in 3D space. These awkward body movements are noticeable distractions, or breaks in presence [64, 65], that disrupt the viewer experience. In other words, integrating spaces was not enough to establish an equitable relationship; we were compromising bodily freedom and still prioritizing the visualization by design. To create an equitable relationship, we had to also ensure that the interactions between the visualizations and presenter appeared balanced the presenters body movements should not look compromised to the viewer. Following our lesson from the previous iteration, we introduced three-dimensionality to the form of the visualization. Our objective was to understand whether having the visualization occupy the same physical space as the presenter would reduce awkwardness in body movements and interactions. While the added third dimension allowed for more staging flexibility and enabled us, as the presenters, to move beyond the constraints 2D plane, we still found ourselves walking and moving around the visualizations. The visualization continued to affect our interactions. However, we realized that this was not the crux of the issue. 3.1.2 Teeter the Balance with Wearable Visualizations. The imbalance continued because the interaction was not bidirectional the visualization affected our interactions as presenters, but not vice versa. Thus, to equalize their relationship and send the message to the viewers that the two were of equal standing, we incorporated gestures that allowed the presenter to control the visualization, as informed by previous works [20, 28, 41, 68]. As result, we now had two primary directions of interaction: the presenter could affect the visualization and vice versa. However, this process raised another question: could we design an even more equitable interaction, where control was not unidirectional, but mutual, or simultaneously bidirectional? Referencing previous works on body-augmented visualizations [5, 23, 35, 52, 54, 60, 67], we found that this was indeed possible if we allowed the presenter to wear the visualizations, or attach them directly to the body like costumes from theater. The visualization could influence the presenter by restricting certain body movements (similar to how different costumes could affect the actors movements), while the presenter simultaneously influence the visualization through their movements (costumes move as the actor moves). 3.2 Tool to Implement InfoVids To offer the viewer with InfoVids that place the presenter and the visualization on an equal footing, we needed to consider both their spatial layout, form, and interactions. Because there were no off-the-shelf tools that would allow us to create such InfoVids, we developed new tool called the Body Object Model (BOM) to help create our probes. While the tool itself is means to an end, and not our contribution, we discuss it because it plays key role in the process of creating our probes, InfoVids. More detailed implementation details are in the Appendix. We implemented the Body Object Model using ARKit, an augmented reality package, on the iPhone as this enabled us to merge the virtual visualizations with the physical space of the presenter. To create presentation where we could control the presenter-visualization relationship, we implemented three components: the VisNode, BodyAnchors, and the VisHandler (Figure 2). VisNodes are containers for 3D visualizations. The BodyAnchors represent locations on the presenters body. The tracking system provides the location of the VisNode and BodyAnchors in 3D space. The VisHandler allows us to script the interactions between the visualization (VisNode) and the presenter (BodyAnchor). Ji Won Chung et al. Fig. 2. Demonstrates system implementation of Body Object Model (BOM). There are three main components: (1) BodyAnchors that represent locations in the presenters body (2) VisNode which contain the visualizations and (3) VisHandler which is used to define relationships between the presenter and visualization using the BodyAnchors and VisNodes. These building blocks enable the design of presentations with equitable relationships between the visualization and presentation with the following three features: F1. Use of 3D Physical Space C1 ARKit and the segmentation of the presenter from the physical background allows the designer to integrate 3D visualizations and place visualizations in different 3D locations. These new setups enhance the sense of depth and open new creative ways to integrate the physical surroundings with the presenter. The added z-dimension provides more space flexibility than 2D spaces, enabling more stagings in which the presenters body does not compete for space with the visualization. F2. Body-vis Attachments C2 The performance designer can attach VisNode to BodyAnchor, almost like wearable costume, and use the presenters body as an integral part of the performance. These body-vis attachments enable simultaneously bidirectional interactions. F3. Body-vis Interactions C3 The presenter can attach actions to the VisNodes and use their body to control or interact with them. 3.3 Creating Four InfoVids With the tools to create InfoVids in place, we then explored how different combinations of form and interactions (F1F3) would affect the viewers experience. We design four case InfoVids with varying conditions (C1C3). To understand how the merged spaces of the visualizations and presenters affected the visualizations, for each InfoVid, we created its baseline equivalent representing 2D videoconferencing style presentation. To investigate how the three-dimensionality of the visualizations would affect the viewing experience, we made two InfoVids with visualizations that looked two-dimensional (InjuryVis, WalmartVis) and two InfoVids with three-dimensional visualizations (AirplaneVis, NapoleonVis). To understand how different types of interactions may affect the viewer, we strategically created one InfoVid where the InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships visualization induced the presenter to move around it (AirplaneVis), one where it was evident the presenter moved the visualization (NapoleonVis), and one where the presenter and visualization were bound to each other physically and interaction wise (InjuryVis). The content for each InfoVid was selected with these conditions in mind. We narrowed our search scope to infographics [24, 26, 49], because they are known for their simple and engaging data narratives [3, 29, 40]. This eliminated the need to craft captivating storyline for the viewers from scratch. To refine the design of our InfoVids and ensure that they were engaging from viewers perspective, we conducted internal critiques with 15 HCI researchers over 4 months with alternative designs [69] before evaluating them with viewers in public. The following paragraphs provide brief description of each InfoVid, the reason behind its selection, and what elements reflect the conditions C1C3. Additionally, we describe how we make the baseline, or each InfoVids equivalent in videoconferencing format. summary on how the conditions C1C3 are applied is available in Table 1. Visualization Name C1. Visualizations Use 3D Physical Space C2. Body-Vis Attachments for Simultaneous, Bidirectional Interactions C3. Unilateral Body-Vis Interactions by the Presenter Baseline AirplaneVis NapoleonVis InjuryVis WalmartVis * - - - - - - - Table 1. Describes how InfoVids apply the three interactions for each visualization design. Comparing each visualization with baseline version of itself helps investigate the effects of merged spatial layout. *WalmartVis is intentionally designed to have no major benefits from the body binding to provide sample case that merely does body-vis binding. AirplaneVis (C1). Based on commercial airplane crash infographic [26], this uses 3D airplane and the physical surroundings (C1), such as the sky, to accentuate the sense of depth and present scenario where the presenter must step to the side of the visualization because it takes 3D space (Figure 1). NapoleonVis (C1, C3). This references Charles Minards depiction of the catastrophic march across Russia in 1812 and Numberphiles presentation [24, 27, 37]. The 3D army and the physical surroundings, the grass, reinforces the outdoor setting of the event as the army parts into the z-axis (Figure 3, Frame 1). Mid performance (Figure 3, Frames 2 & 3), the presenter uses their full-body to move back and forth the French army to simulate the French following the Russians (C3). InjuryVis (C2, C3). direct homage to the New York Times infographic [49], InjuryVis fuses the presenter and the visualization with multiple body-vis bindings, making the presenter inseprable from the visualization, and act as an integral narrative device of the visualization (C2). The presenter points to their own body (C3) to demonstrate the dangers of football. Translucent red bubbles appear on the presenters ankle and head to indicate the number of injuries at that region of the body (Figure 4). WalmartVis (C2, C3). The animated geoplot, replica of Bostocks D3.js animation [7], is controlled counterexample. It is crafted to understand when body-vis bindings are useful or harmful for viewers. The animated map is bound to the presenters torso, but serves little narrative purpose, unlike the InjuryVis. Ji Won Chung et al. Fig. 3. NapoleonVis shows the consequences of Napoleons march. The two compared versions are shown: one where slides with the animation is positioned to the left of their presentation (top), and one where the animation is positioned in the presenters environment with InfoVids (bottom). In frames 2 and 3, the presenter binds the French army to their body to control army movements directly. This presents an engaging way to perform the chase of the French after the Russian army (Table 1 Criteria 3). The background reinforces the outdoors setting of the march and provides depth when the initial army parts into the distance in Frame 1 (Criteria 1). These design choices made NapoleonVis significantly more enjoyable to watch for the viewer. Baseline. The baseline is the equivalent InfoVid as 2D videoconferencing style presentation with slides. Comparing the baseline with the InfoVids will allow us to understand the effects of the new stagings enabled from the added flexibility of 3D space (F1). We minimized confounding factors between the baseline and InfoVids by using the same take of the performance and scripting common body language that worked for both formats. Given the limited screen size of mobile phone, we chose horizontal video orientation for the baseline such that the presenters upper body, including their face and hands, would remain visible. To make aesthetically pleasing layouts, we used video composition technique called the rule-of-thirds. We summarize this in Figure 6. However, making baseline format that enables fair comparison between the baseline and the InfoVids using the same performance takes is challenging and requires detailed discussion of its own. Therefore, we provide detailed discussion of the trade-offs and the reasons behind our choices in the Appendix. 4 COMPARATIVE PROBING WITH INFOVIDS We conducted street interviews to evaluate the InfoVids with members of the public. To poll diverse people, we followed Denning et al.s methodologyinterviews were conducted at three different cafes and mall because of their reasonable throughput of traffic and ability to attract different demographics [21]. Two interviewers worked in parallel each for 10 hours to ask potential participants whether they would like to participate in 15-minute evaluation of visual performances in exchange for pastry. Demographic information was not collected to encourage interviewees to respond more and to provide honest feedback. Out of respect of peoples time and space, we only approached people who appeared to InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships Fig. 4. InjuryVis uses the presenters body as context as the presenter points to their own body to explain football injury statistics (bottom). These body-vis bindings engage the viewers by presenting more personalized way to display data (Table 1 C3 & C4). Viewers express mixed feelings with InjuryViss ability to be enjoyed more. This is partially attributed to mismatches in participant expectations and the capability of regular slides (top) presentation to present information in more familiar way. Fig. 5. WalmartVis binding of the visualization to the body serves no major benefits to the narrative  (Table 1)  . It frees the hands of the presenter and lets them walk forward to view the visualization closer within the capturing camera. While viewers overall believe presenter immersion, engagement, and sense of co-location with the presence is overall higher than in the baseline, body movement constantly tilts the map, making the performance less enjoyable to watch. Ji Won Chung et al. be waiting or not preoccupied. total of 74 people were approached, of which 44 declined to participate. Subsequent analyses are based on the 30 participants who voluntarily consented to participate. 4.1 Interview Procedure Participants were shown 4 pairs of performances on smartphone. Each pair showed the same topic with one in video conferencing format and another with InfoVid. As shorthand, we called the baseline condition the slides version and the latter the non-slides one. Both videos had 8861920 resolution and maximum length of 35 seconds. To minimize ordering and recency bias, we took random permutations of the 4 pairs of videos and randomly chose which version of the presentation was shown first. After each pair of viewings, participants filled an anonymous online 9-question survey on laptop. Question orderings were randomized to mitigate ordering bias. We ask the following 9 questions in the survey: (1) Which presentation makes the presenter look more immersed with the visualization? (2) Which presentation makes the presenter look more engaged with the visualizations? (3) Which presentation makes it more believable is that the presenter is in the same room as the visualizations? (4) Which presentation does the presenter look more natural, body movement wise? (5) Which presentation is more enjoyable to watch? (6) Which presentation style is better for telling story? (7) Which presentation style is better for understanding the information? (8) For the NON-SLIDES version, did you view the presenter or the visualization more? (9) For the SLIDES version, did you view the presenter or the visualization more? The questions are designed as two-alternative forced choice test (2AFC), but participants were presented with 6-point Likert scale to discourage random selection bias. The analysis, however, treats the answers as 2AFC, as this was the intended framework from the onset of the study design. After all 4 surveys, we conducted short semi-structured Fig. 6. Making the Baseline Video Format To use the same rendition, or takes, of the performance, two phones are used simultaneously to record the presenterone uses InfoVids and the other is absent of the augmented visualizations. The latter is used to sync the presenter with the slides and animation. presenter body language and visualization views are maximized with 3:1 slide format and use of rule-of-thirds, video composition technique to direct viewer attention to the presenter. InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships interview to ask what elements in the performances affected their decisions. The interviewer transcribed notes in real-time to record the participant responses. 4.2 Method of Analyses There were four major parts to the mixed methods analyses. First, to analyze the overall efficacy of InfoVids for each visualization, we first investigated participants overall preferences between the baseline and the InfoVid and the presenter and visualization. For each of the 9 survey questions for given visualization, binomial test was conducted with (ùõº = 0.05), because each question was designed as 2AFC test with 2 possible outcomes. The null hypothesis ùêª0 assumed both outcomes were equally likely (ùëù = 0.5). Rejecting the null hypothesis signified the observed preference over one outcome or the other was not random and was statistically significant. Next, to understand if the different survey results among visualization types were significant, we ran the Friedmans Chi-square tests for each of the question. The Friedman test (ùõº = 0.05) was used because the same viewers ordinally rated each question using 6-point Likert scale on 4 different conditions. The ùêª0 in this case assumes there is no difference in the medians, or that the results across different visualization types were comparable. To further investigate whether pair of groups significantly different from each other, we ran the Wilcoxon Signed-Rank test to see if the distribution of differences between the two groups were approximately normal, else we ran weaker signed test. We also analyzed how the new staging format introduced by InfoVids affects viewer attention to the presenter and visualization prop. For each visualization type, we twice asked participants whether they viewed the presenter or the visualization moreonce for the InfoVid and another for the baseline. For each visualization, we compare whether the InfoVid made significant differences in visualization-presenter attention from the baseline. As we have fewer than 50 participants and paired, binary outcomes (visualization/presenter), we conduct the Fishers exact test with ùõº = 0.05 and summarize the results in Figure 8. To evaluate how many viewers switched their focus more to the presenter with InfoVids, in comparison to the baseline, we also analyze the directionality of change using contingency tables. Lastly, to understand the factors that affected the viewers decisions, we thematically analyzed the semi-structured interviews using deductive coding [9]. Given the short interviews, only three iterations were needed to generate the following 9 themes: captivating, aesthetics, distracting, attention split, helpful for information understanding, breaks in presence, body language and interaction, body as context, and situational context. 5 FINDINGS AND LESSONS LEARNED FROM THE VIEWERS PERSPECTIVE By asking participants to compare among different InfoVids and between the baseline and the InfoVids, we aim to understand the following questions: (1) How do InfoVids affect the viewing experience compared to traditional videoconferencing formats? (2) Does the merging of spaces make viewers focus on the presenter more than the visualization (survey Q8-9)? (3) How do the different conditions (C1C3) in the InfoVids affect their viewing experiences (survey Q1-Q7)? We hope the answers to these questions can better guide the future design and presentation of InfoVids-like visualizations. According to survey results, InfoVids enhances the stories and makes the experience more enjoyable for viewers in some cases than the baseline. From the rationale given, the viewers perceived the presenter to use more of their natural body movements and looked more immersed, engaged, and physically present with the visual props (Figure 7). While viewers primarily focus on the visualizations in the baseline, InfoVids make the viewer focus on the presenter more by blending the presenter into the same space with the visual props (Figure 8). Ji Won Chung et al. Fig. 7. Participants were asked about which version of presentation format immersed and engaged the presenter with the visualization more, felt like the presenter was in the same room as the visualization, had more natural body movement, was more enjoyable to watch, better storytelling, and better information understanding. Across all four visualizations, participants chose the InfoVid version for immersion, engagement, and being in the same room as the visualization. Their responses to the other four questions depended on the visualization, as shown in the charts. InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships Body Language is All You Need: InfoVids Enable Engaging and Enjoyable Full-Body Performances. The results suggest that InfoVids were more engaging and enjoyable to viewers because the layout designed to foster an equal standing between the visualization and presenter encouraged the use of the full-body with the blended space. While the baseline had the same animations and performance takes, synced to the presenters movements, the presenters body was cut off, making the presentation visualization-centric by design. Participants couldnt really see her [the presenters] whole body (P8). The baseline format prevented viewers from fully seeing the presenters actions directly related to the visualizations, such as pointing to different parts of the plane. However, by co-locating the presenter and visualization in the same 3D space (C1), we changed the relationship between them, and could send the message to the viewers that the presenters body holds more meaning in the presentations than traditional ones. The presenters body, scripted to move to the side for crashing plane in AirplaneVis, emphasizes that the plane is taking up the presenters 3D space. The presenters body is the visualization itself in InjuryVis and symbol for the Russians that the French were following in NapoleonVis. As P14, strong advocate for InfoVids, states: Even for WalmartVis, body language is all you need; you dont need different languagesFrench, English, Spanishits understandable for anyone its eye grabbing and it just pulls your attention and makes you focus on the presenter all the time and its engaging. The body-vis bindings in NapoleonVis (C3) and InjuryVis (C2) emphasized the use of the full-body by enhancing direct interactivity with the visualizations. As result, participants liked how the soldiers [from NapoleonVis ] were going back and forth and [that] the presenter was moving with them (P1). Some felt it connected the story with the movement (P22) of the presenter. InjuryVis was engaging because the presenter is pointing at their own body (P25) and refer[ring] to her own body (P23) and some were even wow[ed] (P29). As P17 states: The body one, it was really appropriatewhat better way to talk about the body than to use the body? Even AirplaneVis (C1) was preferred over the baseline because of the way the presenter moved to the side and occupied the space of the frame...made it more cohesive (P17). Moving to the side of the frame was scripted, but did not involve any direct body-vis bindings or interactions (C2, C3). Thus, this indicates that the presenters full-body on its own acts critical narrative device and occluding the body in the baseline makes the presentations less engaging. We corroborate this sentiment in the quantitative findings (Figure 7). Viewers found presenters in AirplaneVis, NapoleonVis, and InjuryVis to look more natural and better at storytelling than the baseline. Furthermore, the majority of viewers found the AirplaneVis and NapoleonVis InfoVids to be more enjoyable to watch than the baseline. InfoVids Reduce Split Viewer Attention and Increase Attention on the Presenter. Viewers preferred InfoVids because the blending of props and presenters reduced the need to split their attention between them. Multiple participants (P8, P12, P15, P20, P22, P24, P30) found the equitable, spatial layout of InfoVids easier to follow alongsee both the presenter and the visualizations (P15) while the slides version felt like two videos were fighting for their attention (P20). Even for participants who prefer seeing data rather than people [it was] good to see person and data at the same time (P25). Thus, it is not only evident that the new layout changed the relationship dynamics between the visualizations and presenters for viewers, but also, at times, even preferred. Furthermore, more than half the participants switched from focusing on the visualizations to the presenter with InfoVids (WalmartVis 19/30, InjuryVis 17/30, NapoleonVis 17/30, AirplaneVis 16/30; Figure 8). These results are non-obvious because many of the visualizations, other than InjuryVis, were not directly overlaid over the presenter Ji Won Chung et al. Fig. 8. InfoVids disrupt this traditional visual flow as demonstrated by overall ratio of presenter to visualization ratio for the InfoVids. Binomial tests indicate statistical significance for InjuryVis because the presenter and visualization are infused with each other by design. Bolded in the contingency tables are the number of converts, or viewers who focused on the visualizations in the baseline but the presenter with InfoVids. at all timesthe airplane was detached from the presenter, the French army was at the side and in front of the presenter many of the times, and the map for WalmartVis was located at the torso. At the same time, we also learn from comparing WalmartVis and InjuryVis that how we integrate visualizations with the presenters also affect the viewers experience. We designed WalmartVis as controlled counterxample to showcae instances of improper integration of presenter and visualization. This was to understand when visualizations should not be combined with the presenter and to assess whether participants would recognize these issues. As expected, viewers significantly preferred the baseline WalmartVis over the InfoVid version in all measures. significant number of viewers thought the presenters body movement looked unnatural (WalmartVis 21/30, Figure 7), and for some even awkward (P10). The map was not only distracting (P20) but also not very acceptable when youre trying to learn (P4). Consequently, WalmartVis is the only performance in which viewers significantly preferred the baseline over InfoVids on the metrics of enjoyability, storytelling, and information understanding. However, our results indicate that the merging of spaces did not warrant such negative reactions. Viewers perceived the presenter in WalmartVis as immersed, engaged, and co-existing in the same space as the visualization. Given that many viewers InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships had positive reactions with InjuryVis, we also know that viewers are not necessarily opposed to the act of attaching visualizations to the body. Thus, the results suggest that the viewers are being affected by how the presenter uses the props. These findings indicate need to develop new tools that help us investigate viewer attention in 3D presentations. Such tools can help presentation designers understand how they can optimize 3D space and orient visualization props in relation to presenters to enhance storytelling. Similar to how studies investigate visual attention and flow in static information layouts with eye-tracking [6, 12, 44, 53], more research needs to be conducted to fully understand what components split the viewer attention from the presenter and the visualization when they co-exist on the same 2D screen and 3D space. These visual design patterns can then inform how to create authoring tools that help with strategic blocking to enhance the narrative of the performance. Merging Spaces Necessitates New Social Engineering Considerations. While most people enjoyed InfoVids, some did not, as their expectations of presentations did not align with their pre-existing mental models. Some viewers did not like the NapoleonVis InfoVid because their brain associates [presentations] with more academic setting (P17). Participants believed historical data should be presented in the lecture hall settings and not like an InfoVid. P19 believed that for any presentations, The [presenter] is not essential to understanding information, human connection isnt that necessary. While we anticipated the new relationship dynamics introduced by InfoVids would impact the viewers, we did not foresee that these relational dynamics would conflict with the pre-existing ones in the viewers. Thus, these results indicate that there may first need to be change in viewers mental model and norms of social acceptability associated with presentations on data before such InfoVids can be fully accepted by broader audience. In addition, we find that visual preferences also affected viewer expectations. The AR elements, while enjoyed by many, for some [were] disorienting... clarity of the visual separation [by the slides] made it more immersive as learning experience (P21). While the red bubbles of InjuryVis were effective storytelling devices for most, others preferred the baseline because they thought the red graphic overtook too much of the body (P26) and thought the presenter looked comical when its moving (P19). This explains why InjuryVis tied with the baseline on the metric of enjoyability and preferred on the baseline for information understanding. Thus, future tools should guide designers on how to design visualizations in relation to the presenter, such that they are not too distracting to the performance. These tools should also ensure that the presenter does not compete with the visualization to muddy the message. As P12 points out: Maybe in [certain] situations...you should be aware of the applicability [to] all kinds of people...[if] it focuses more on the presenter themselves and their identity, maybe there could be tension in that. Similar to how character appearance in game design and face filters affect the self-portrayal and identity of individuals in mixed reality [4, 17, 23, 48], future authoring systems for visual performances should consider the social and visual context that the presenter brings into the performance. Else, mismatches in presentation content and the context the presenter brings will lead to discomfort. While these were considerations we did not anticipate, the positive reception to the AirplaneVis, NapoleonVis, and InjuryVis InfoVids indicate that with proper social engineering, InfoVids offer unique experience that traditional videoconferencing formats cannot provide. 6 LESSONS LEARNED FROM DESIGING INFOVIDS: AN AUTOBIOGRAPHICAL PERSPECTIVE In this section we discuss the lessons learned from the findings and from our nine-month experience designing InfoVids. While we cannot claim generalizability, as Neustaedter and Sengers state [50], we include insights from an autobiographical standpoint because they provide practical and long-term insights [22, 31, 77] for future visualization presentation tools. Ji Won Chung et al. Fig. 9. Self-facing cameras make users, or presenters, spectators of themselves. Thus, this paper modifies the original framework proposed by Dalsgaard et al. [19] framework by adding self-looping arrow for the user to highlight new user-system-viewer dynamics. Changing Presenter-System-Viewer Dynamics. To articulate the experience of spectators in emerging public performances, Reeves et al. [57] formalizes classification and taxonomy for performative interfaces. Dalsgaard et al. [19] later on extends Reeves et al.s framework to emphasize the user-spectator relationship more than the spectator and user-system relationship and the traditionally-investigated user-system relationships. In spirit, both Reeves et al. and Dalsgaard et al. describe the emerging role of spectators as active participants affecting the users performance. However, as we were filming ourselves as the presenter and simultaneously looking at the augmented visualizations overlaid to our body as viewer, we found that the division between the spectator and the presenter blurred. The relationship between the presenter and viewer was being redefined. As viewers, we could both perform and view ourselves in real-time with the self-facing camera. This suggests that similar presentation systems found on streaming platforms, such as Twitch, TikTok, and Discord and videoconferencing platforms such as Skype, Teams, and Zoom have also introduced new user-system-spectator dynamics. These setups, however, cannot be fully explained by pre-existing frameworks of user-system-spectator relationships [19, 57]. As we demonstrate in Figure 9, we may need to update pre-existing performance theories to account for self-facing cameras and streaming [16, 43, 45] which have now muddied the division between the user and the spectator in the opposite direction suggested by Reeves et al. and Dalsgaard et al. [19, 57]. Thus, as virtual and physical spaces start to blend, our probe with InfoVids prompts the need for future work to investigate the emerging tensions not only between presenter and visualization, but also among the self-spectating presenter, system, and viewer. InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships Dynamic Presenter-Visualization Relationships. We also learn that InfoVids do more than blend spaceInfoVids change the presenters relationship with the visualization and influence the message conveyed to the viewers. At times, the presenter blends in with and becomes one with the prop. For example, the presenters full body acts as the visual highlight in AirplaneVis to indicate where the viewer should look. Presenters are the context and information in InjuryVis and the starter of an engaging visual animation in NapoleonVis. However, these relationships can also be dynamic and evolve over time. As we used augmented reality to visually place data in real life settings, the data physicalized [34]. However, unlike physical data visualizations, which remain relatively static, the properties of virtual data can be dynamicthey can change in size, location, material, and style. As result, the relationship between visualization and presenter can constantly change. Visualizations that change in size can change how they occupy space, and ultimately alter how presenter can interact with them. All of these factors redefines the relationship with the presenter and transforms the types of presentations viewer can experience [71]. On the other hand, such changing affordances can be cognitively tiring to maintain. While the presenter has view of their augmented self with the visualizations, the visualizations are not tangible like physical objects. The intangible form and changing affordances [51] warrant different interactions from the presenter [10, 25, 36], which means presenters have to memorize how to interact with the visualizations. Even if the presentations were brief, single presenter had to present in four different InfoVids. This required context switching and the ability to memorize various details and body language for each presentation, all of which can be mentally taxing. Yet, this lesson prompts us to consider how future technologies can be designed to better support extended and multiple presentationsscenarios that are often overlooked in prior works. This could lead to new hidden cue systems customized for the presenter, but hidden from the viewers. For example, in the process of designing InfoVids, we started to develop system in which presenter triggered animations based on the spatial location of the presenter. This freed up the hands, reduced the need to memorize different interactions, and allowed the presenter to command the stage more. All of these components can enhance the viewers experience, as less fatigued presenter can positively impact the quality and engagement of the presentation. And as we show in our findings, if executed well, InfoVids can prove to be more engaging than traditional formats for the viewer. 7 CONCLUSION We approached our investigation to introduce more equitable presentation paradigm using InfoVids from two distinct angles: one from the perspective of the viewers and another from autobiographical perspective as long-term designers and users of InfoVids. Our study findings suggest that viewers may find InfoVids to be more engaging and preferable format than traditional, 2D presentations, if the relationship of the visualization to the presenter is appropriately considered. In the process of designing and implementing InfoVids, we learn how spatial layout, form, and interactions affect how viewers perceive presenter-visualization relationships. Our insights into the process of making InfoVids will hopefully inform future data performance systems that nurture new generation of data presenters who dance with data to tell sophisticated stories for broader audience, carrying on the legacy of Prof. Hans Rosling. REFERENCES [1] Fereshteh Amini, Nathalie Henry Riche, Bongshin Lee, Christophe Hurter, and Pourang Irani. 2015. Understanding data videos: Looking at narrative visualization through the cinematography lens. In Proceedings of the 33rd Annual ACM conference on human factors in computing systems. 14591468. [2] Fereshteh Amini, Nathalie Henry Riche, Bongshin Lee, Jason Leboe-McGowan, and Pourang Irani. 2018. Hooked on data videos: assessing the effect of animation and pictographs on viewer engagement. In Proceedings of the 2018 international conference on advanced visual interfaces. 19. Ji Won Chung et al. [3] Scott Bateman, Regan Mandryk, Carl Gutwin, Aaron Genest, David McDine, and Christopher Brooks. 2010. Useful junk? The effects of visual embellishment on comprehension and memorability of charts. In Proceedings of the SIGCHI conference on human factors in computing systems. 25732582. [4] Max Birk and Regan Mandryk. 2013. Control your game-self: effects of controller type on enjoyment, motivation, and personality in game. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 685694. [5] Tobias Blum, Valerie Kleeberger, Christoph Bichlmeier, and Nassir Navab. 2012. mirracle: An augmented reality magic mirror system for anatomy education. In 2012 IEEE Virtual Reality Workshops (VRW). IEEE, 115116. https://doi.org/10.1109/VR.2012. [6] Michelle Borkin, Zoya Bylinskii, Nam Wook Kim, Constance May Bainbridge, Chelsea Yeh, Daniel Borkin, Hanspeter Pfister, and Aude Oliva. 2015. Beyond memorability: Visualization recognition and recall. IEEE transactions on visualization and computer graphics 22, 1 (2015), 519528. [7] Mike Bostock. Accessed in 2023. Walmarts Growth. https://observablehq.com/@d3/walmarts-growth [8] Michael Bostock, Vadim Ogievetsky, and Jeffrey Heer. 2011. D3 data-driven documents. IEEE transactions on visualization and computer graphics 17, 12 (2011), 23012309. [9] Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qualitative research in psychology 3, 2 (2006), 77101. [10] F. P. Brooks. 1988. Grasping Reality through Illusioninteractive Graphics Serving Science. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Washington, D.C., USA) (CHI 88). 111. https://doi.org/10.1145/57167.57168 [11] Marion Buchenau and Jane Fulton Suri. 2000. Experience prototyping. In Proceedings of the 3rd conference on Designing interactive systems: processes, practices, methods, and techniques. 424433. [12] Zoya Bylinskii, Lore Goetschalckx, Anelise Newman, and Aude Oliva. 2022. Memorability: An Image-Computable Measure of Information Utility. Springer International Publishing, Cham, 207239. https://doi.org/10.1007/978-3-030-81465-6_8 [13] Junjie Chen, Chenhui Li, Sicheng Song, and Changbo Wang. 2023. iARVis: Mobile AR Based Declarative Information Visualization Authoring, Exploring and Sharing. In 2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR). 1121. [14] Zhutian Chen, Yijia Su, Yifang Wang, Qianwen Wang, Huamin Qu, and Yingcai Wu. 2019. Marvist: Authoring glyph-based visualization in mobile augmented reality. IEEE transactions on visualization and computer graphics 26, 8 (2019), 26452658. [15] Zhutian Chen, Wai Tong, Qianwen Wang, Benjamin Bach, and Huamin Qu. 2020. Augmenting static visualizations with paparvis designer. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 112. [16] Gifford Cheung and Jeff Huang. 2011. Starcraft from the stands: understanding the game spectator. In Proceedings of the SIGCHI conference on human factors in computing systems. 763772. [17] Ji Won Chung, Xiyu Jenny Fu, Zachary Deocadiz-Smith, Malte Jung, and Jeff Huang. 2023. Negotiating Dyadic Interactions through the Lens of Augmented Reality Glasses. In Proceedings of the 2023 ACM Designing Interactive Systems Conference. 493508. [18] Maxime Cordeil, Andrew Cunningham, Benjamin Bach, Christophe Hurter, Bruce Thomas, Kim Marriott, and Tim Dwyer. 2019. IATK: An immersive analytics toolkit. In 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). IEEE, 200209. [19] Peter Dalsgaard and Lone Koefoed Hansen. 2008. Performing perceptionstaging aesthetics of interaction. ACM Transactions on Computer-Human Interaction (TOCHI) 15, 3 (2008), 133. [20] Josh Urban Davis, Paul Asente, and Xing-Dong Yang. 2023. Multimodal Direct Manipulation in Video Conferencing: Challenges and Opportunities. In Proceedings of the 2023 ACM Designing Interactive Systems Conference. 11741193. [21] Tamara Denning, Zakariya Dehlawi, and Tadayoshi Kohno. 2014. In situ with bystanders of augmented reality glasses: Perspectives on recording and privacy-mediating technologies. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 23772386. https://doi.org/10.1145/2556288.2557352 [22] Audrey Desjardins and Aubree Ball. 2018. Revealing tensions in autobiographical design in HCI. In proceedings of the 2018 designing interactive systems conference. 753764. [23] Rebecca Fribourg, Etienne Peillard, and Rachel Mcdonnell. 2021. Mirror, mirror on my phone: Investigating dimensions of self-face perception induced by augmented reality filters. In 2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEE, 470478. [24] Michael Friendly. Accessed in 2023. Minards Graphic Works. https://www.datavis.ca/gallery/re-minard.php [25] Weilun Gong, Stephanie Santosa, Tovi Grossman, Michael Glueck, Daniel Clarke, and Frances Lai. 2023. Affordance-Based and User-Defined Gestures for Spatial Tangible Interaction. In Proceedings of the 2023 ACM Designing Interactive Systems Conference. 15001514. [26] Tim Graham. Accessed in 2024. The Safest Seat to Sit In On Plane is. . . . https://flowingdata.com/2008/05/20/the-safest-seat-to-sit-in-on-a-plane-is/ [27] James Grime. 2015. The Greatest Ever Infographic - Numberphile. https://www.youtube.com/watch?v=3T7jMcstxY0&ab_channel=Numberphile [28] Brian Hall, Lyn Bartram, and Matthew Brehmer. 2022. Augmented chironomia for presenting data to remote audiences. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. 114. [29] Lane Harrison, Katharina Reinecke, and Remco Chang. 2015. Infographic aesthetics: Designing for the first impression. In Proceedings of the 33rd Annual ACM conference on human factors in computing systems. 11871190. [30] Amelia Hassoun, Ian Beacock, Sunny Consolvo, Beth Goldberg, Patrick Gage Kelley, and Daniel Russell. 2023. Practicing Information Sensibility: How Gen Engages with Online Information. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 117. [31] Jeff Huang and Jing Qian. 2023. irchiver: Full-Resolution Personal Web Archive for Users and Researchers. In Proceedings of the 2023 Conference on Human Information Interaction and Retrieval. 449453. [32] Sebastian Hubenschmid, Johannes Zagermann, Simon Butscher, and Harald Reiterer. 2021. Stream: Exploring the combination of spatially-aware tablets with augmented reality head-mounted displays for immersive analytics. In Proceedings of the 2021 CHI Conference on Human Factors in InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships Computing Systems. 114. [33] Hilary Hutchinson, Wendy Mackay, Bo Westerlund, Benjamin Bederson, Allison Druin, Catherine Plaisant, Michel Beaudouin-Lafon, St√©phane Conversy, Helen Evans, Heiko Hansen, et al. 2003. Technology probes: inspiring design for and with families. In Proceedings of the SIGCHI conference on Human factors in computing systems. 1724. [34] Yvonne Jansen, Pierre Dragicevic, Petra Isenberg, Jason Alexander, Abhijit Karnik, Johan Kildal, Sriram Subramanian, and Kasper Hornb√¶k. 2015. Opportunities and challenges for data physicalization. In proceedings of the 33rd annual acm conference on human factors in computing systems. 32273236. [35] Yu Jiang, Zhipeng Li, Mufei He, David Lindlbauer, and Yukang Yan. 2023. HandAvatar: Embodying Non-Humanoid Virtual Avatars through Hands. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 117. [36] Ulrike Kister, Konstantin Klamka, Christian Tominski, and Raimund Dachselt. 2017. GraSp: Combining Spatially-aware Mobile Devices and Display Wall for Graph Visualization and Interaction. Computer Graphics Forum 36, 3 (2017), 503514. [37] Robert Kosara and Jock Mackinlay. 2013. Storytelling: The Next Step for Visualization. Computer 46, 5 (2013), 4450. https://doi.org/10.1109/MC.2013.36 [38] Ricardo Langner, Marc Satkowski, Wolfgang B√ºschel, and Raimund Dachselt. 2021. Marvis: Combining mobile devices and augmented reality for visual data analysis. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 117. [39] Bongshin Lee, Rubaiat Habib Kazi, and Greg Smith. 2013. SketchStory: Telling more engaging stories with data through freeform sketching. IEEE transactions on visualization and computer graphics 19, 12 (2013), 24162425. [40] Huiyang Li and Nadine Moacdieh. 2014. Is chart junk useful? An extended examination of visual embellishment. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, Vol. 58. Sage Publications Sage CA: Los Angeles, CA, 15161520. [41] Jian Liao, Adnan Karim, Shivesh Singh Jadon, Rubaiat Habib Kazi, and Ryo Suzuki. 2022. RealityTalk: Real-Time Speech-Driven Augmented Presentation for AR Live Storytelling. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. 112. [42] Leo Yu-Ho Lo, Ayush Gupta, Kento Shigyo, Aoyu Wu, Enrico Bertini, and Huamin Qu. 2022. Misinformed by visualization: What do we learn from misinformative visualizations? Computer Graphics Forum 41, 3 (2022), 515525. [43] Danielle Lottridge, Frank Bentley, Matt Wheeler, Jason Lee, Janet Cheung, Katherine Ong, and Cristy Rowley. 2017. Third-wave livestreaming: teens long form selfie. In Proceedings of the 19th international conference on human-computer interaction with mobile devices and services. 112. [44] Min Lu, Chufeng Wang, Joel Lanir, Nanxuan Zhao, Hanspeter Pfister, Daniel Cohen-Or, and Hui Huang. 2020. Exploring Visual Information Flows in Infographics. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI 20). 112. https://doi.org/10.1145/3313831.3376263 [45] Zhicong Lu, Haijun Xia, Seongkook Heo, and Daniel Wigdor. 2018. You watch, you give, and you engage: study of live streaming practices in China. In Proceedings of the 2018 CHI conference on human factors in computing systems. 113. [46] Weizhou Luo, Eva Goebel, Patrick Reipschl√§ger, Mats Ole Ellenberg, and Raimund Dachselt. 2021. Exploring and slicing volumetric medical data in augmented reality using spatially-aware mobile device. In 2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). IEEE, 334339. [47] Yiwen Luo and Xiaoou Tang. 2008. Photo and video quality evaluation: Focusing on the subject. In Computer VisionECCV 2008: 10th European Conference on Computer Vision, Marseille, France, October 12-18, 2008, Proceedings, Part III 10. Springer, 386399. [48] Margaret Morris, Daniela Rosner, Paula Nurius, and Hadar Dolev. 2023. Dont Want to Hide Behind an Avatar: Self-Representation in Social VR Among Women in Midlife. In Proceedings of the 2023 ACM Designing Interactive Systems Conference (Pittsburgh, PA, USA) (DIS 23). 537546. https://doi.org/10.1145/3563657.3596129 [49] The Learning Network. 2020. Whats going on in this graph? high-school sports injuries. https://www.nytimes.com/2020/01/23/learning/whatsgoing-on-in-this-graph-high-school-sports-injuries.html [50] Carman Neustaedter and Phoebe Sengers. 2012. Autobiographical design in HCI research: designing and learning through use-it-yourself. In Proceedings of the Designing Interactive Systems Conference. 514523. [51] Don Norman. 2013. The design of everyday things: Revised and expanded edition. Basic books, New York, New York. [52] Leyla Norooz, Matthew Louis Mauriello, Anita Jorgensen, Brenna McNally, and Jon Froehlich. 2015. BodyVis: new approach to body learning through wearable sensing and visualization. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 10251034. [53] Alexandra Papoutsaki, James Laskey, and Jeff Huang. 2017. Searchgazer: Webcam eye tracking for remote studies of web search. In Proceedings of the 2017 conference on conference human information interaction and retrieval. 1726. [54] Siyou Pei, Alexander Chen, Jaewook Lee, and Yang Zhang. 2022. Hand interfaces: Using hands to imitate objects in AR/VR for expressive interactions. In Proceedings of the 2022 CHI conference on human factors in computing systems. 116. [55] Ken Perlin, Zhenyi He, and Karl Rosenberg. 2018. Chalktalk: Visualization and Communication LanguageAs Tool in the Domain of Computer Science Education. arXiv:1809.07166 [cs.HC] [56] Shwetha Rajaram and Michael Nebeling. 2022. Paper trail: An immersive authoring system for augmented reality instructional experiences. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 116. [57] Stuart Reeves, Steve Benford, Claire OMalley, and Mike Fraser. 2005. Designing the spectator experience. In Proceedings of the SIGCHI conference on Human factors in computing systems. 741750. [58] Hans Rolsing. 2011. Hans Roslings 200 Countries, 200 Years, 4 Minutes. https://www.youtube.com/watch?v=jbkSRLYSojo&t=54s&ab_channel=BBC [59] Samar Sallam, Yumiko Sakamoto, Jason Leboe-McGowan, Celine Latulipe, and Pourang Irani. 2022. Towards design guidelines for effective health-related data videos: An empirical investigation of affect, personality, and video content. In Proceedings of the 2022 CHI Conference on Human Ji Won Chung et al. Factors in Computing Systems. 122. [60] Nazmus Saquib, Rubaiat Habib Kazi, Li-Yi Wei, and Wilmot Li. 2019. Interactive body-driven graphics for augmented video performance. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 112. [61] Kadek Ananta Satriadi, Jim Smiley, Barrett Ens, Maxime Cordeil, Tobias Czauderna, Benjamin Lee, Ying Yang, Tim Dwyer, and Bernhard Jenny. 2022. Tangible globes for data visualisation in augmented reality. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 116. [62] Arvind Satyanarayan, Dominik Moritz, Kanit Wongsuphasawat, and Jeffrey Heer. 2016. Vega-lite: grammar of interactive graphics. IEEE transactions on visualization and computer graphics 23, 1 (2016), 341350. [63] Ronell Sicat, Jiabao Li, Junyoung Choi, Maxime Cordeil, Won-Ki Jeong, Benjamin Bach, and Hanspeter Pfister. 2018. DXR: toolkit for building immersive data visualizations. IEEE transactions on visualization and computer graphics 25, 1 (2018), 715725. [64] Mel Slater, Andrea Brogni, and Anthony Steed. 2003. Physiological responses to breaks in presence: pilot study. In Presence 2003: The 6th annual international workshop on presence, Vol. 157. Citeseer. [65] Mel Slater and Anthony Steed. 2000. virtual presence counter. Presence 9, 5 (2000), 413434. [66] sqadia.com. Accessed in 2024. Introduction to Anatomy SUBDIVISIONS Made Easy for Medical Students. https://www.youtube.com/watch? v=q6fQf6VLDOY [67] Hariharan Subramonyam. 2015. SIGCHI: magic mirror-embodied interactions for the quantified self. In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems. 16991704. [68] Ryo Suzuki, Rubaiat Habib Kazi, Li-Yi Wei, Stephen DiVerdi, Wilmot Li, and Daniel Leithinger. 2020. Realitysketch: Embedding responsive graphics and visualizations in AR through dynamic sketching. In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology. 166181. [69] Maryam Tohidi, William Buxton, Ronald Baecker, and Abigail Sellen. 2006. Getting the right design and the design right. In Proceedings of the SIGCHI conference on Human Factors in computing systems. 12431252. [70] Wai Tong, Zhutian Chen, Meng Xia, Leo Yu-Ho Lo, Linping Yuan, Benjamin Bach, and Huamin Qu. 2023. Exploring interactions with printed data visualizations in augmented reality. IEEE Transactions on Visualization and Computer Graphics 29 (2023), 418 428. Issue 1. [71] DAVOD VEGJ. Last accessed in 2023. BLOCKING 101 How directors tell stories with movement. https://dramatics.org/blocking-101/ [72] Yunwen Wang. 2020. Humor and camera view on mobile short-form video apps influence user experience and technology-adoption intent, an example of TikTok (DouYin). Computers in human behavior 110 (2020), 106373. [73] Zezhong Wang, Shunming Wang, Matteo Farinella, Dave Murray-Rust, Nathalie Henry Riche, and Benjamin Bach. 2019. Comparing effectiveness and engagement of data comics and infographics. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 112. [74] Saelyne Yang, Sangkyung Kwak, Juhoon Lee, and Juho Kim. 2023. Beyond Instructions: Taxonomy of Information Types in How-to Videos. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 121. [75] Yalong Yang, Tim Dwyer, Kim Marriott, Bernhard Jenny, and Sarah Goodwin. 2020. Tilt map: Interactive transitions between choropleth map, prism map and bar chart in immersive environments. IEEE Transactions on Visualization and Computer Graphics 27, 12 (2020), 45074519. [76] Tongyu Zhou, Jeff Huang, and Gromit Chan. 2024. Epigraphics: Message-Driven Infographics Authoring. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI 24). https://doi.org/10.1145/3613904.3642172 [77] Tongyu Zhou, Joshua Kong Yang, Vivian Hsinyueh Chan, Ji Won Chung, and Jeff Huang. 2024. PortalInk: 2.5D Visual Storytelling with SVG Parallax and Waypoint Transitions. In Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology (Pittsburgh, PA, USA) (UIST 24). 16. https://doi.org/10.1145/3654777.3676376 [78] Chengyan Zhu, Xiaolin Xu, Wei Zhang, Jianmin Chen, and Richard Evans. 2020. How health communication via Tik Tok makes difference: content analysis of Tik Tok accounts run by Chinese provincial health committees. International journal of environmental research and public health 17, 1 (2020), 192. InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships HOW TO CREATE INFOVIDS WITH THE BODY OBJECT MODEL The Body Object Model (BOM) treats the full-body as series of nestable anchor points, similar to HTML tags, in which the designer can nest, or bind, visual props to the body. This nested structure serves two purposes. First, it reinforces the idea that the visualization is an element that can be nested, or blended in, with the presenter, effectively blurring the boundaries between the visualization and the presenter. Second, it forces the designer of the visual performance to define the visualizations in relation to the presenter, with parent-child hierarchy, making the presenter the primary focus even in its language. We implement BOM with Swift and ARKit as they naturally align with the nestable tree structure that we aim to achieve. The iPhones TrueDepth and ARKit software detect and segment the presenters face from the background within 3 of the devices front camera. This provides relative, proxy depth from the presenters face, enabling us to incorporate three-dimensional form into the visualizations. Using the self-facing camera, ARKit, VNDetectHumanBodyPose3DReqest, VNDetecthumanHandPoseReqest respectively generate the body anchors, or the face node, body joints, and hand joints. All body anchors are inherited from SCNNode and the node positions are overlaid on the diagram of the person and hand. Body anchors or the locations that one can bind VisNode with using bind. Each face, body, and hand joint is managed by the FacialCueTracker, SkeletonTracker, and HandTracker respectively. HandTracker also manages GestureStates which then is used to build an Action Seqence. System provides 10 GestureStates and 5 ActionSeqences. Using Vishandler the scripts interactions with VisNode and the body. The prototype is proof-of-concept tool for experts to design and perform InfoVids. Using this system requires multidisciplinary knowledge of AR, visualization, and performance. Before programming, the designer needs to design simple narrative for the visualizations. Then, they need to detail how they will stage the interactions between the visualizations and presenter, much like how blocking is done in theater [71]. Then, after creating the body-vis bindings, all interactions and gestures to trigger visualization are coded. Based on our nine-month experience with the system, we find that gestures are dictated by the narrative the designer wishes to convey and need to flexibly adapt to suit each unique presentation (Sec. 6). Thus, at this time, there is no fixed gestural language defined and this is design choice. After designing the InfoVid, the smartphone is positioned such that the front-facing camera faces the presenter. The phone screen provides mirrored view of the presenter with the visualizations such that they can see how they are engaging with the visualizations in real-time, much like AR filters. This setup allows us to evaluate our research questions with InfoVids that have genuine interactions from the presenter [11], unlike Wizard-of-Oz styled setups which use post-processing to overlay the augmentations. BASELINE VIDEO FORMAT This section outlines how we made the baseline, 2D videoconferencing style presentation with slides, as comparable as the presentation with InfoVids. From our external critiques we found there were two major factors to consider to make the baseline. First, different takes, or renditions of the performance, and the authors biased knowledge of the system generated different performances. Minute changes in facial expressions, enthusiasm, and dialogue changed the perceived narrative. To account for this, we hired an external actor with no prior knowledge of the study to perform in the videos and ensured that both versions of the presentations used the same take of the performance. Next, the differences in presenter body movements caused by the added depth were too subtle. If the differences were hard to find by researchers who were actively critiquing, they would be even less discernible to non-researcher. To make Ji Won Chung et al. the differences more apparent, we chose more traditional 2D video-conferencing style presentation as the baseline, referencing the studies of previous interactive visual systems [20, 39]. We controlled for the actors body language, the layout, and the visualizations and its interactive effects with the presenter. The overall process is summarized in Figure 6. B.1 Scripting for Common Body Language To incorporate feedback from the critique, we recorded the performance with two iPhone 13 minis simultaneously. As demonstrated in Figure 6, this setup provided two videos with the same performance, one InfoVid and the other with no overlaid visualizations for the baseline. The setup to control for confounding factors, however, introduced new problems. Simultaneous recording stipulated pre-planning process such that the body language could be shared in both presentations. For example, an actor looking directly up towards or at the plane would look awkward and aberrant in typical slides presentation without the plane, because the actor would be looking into the void (Figure 10). Thus, to minimize such distractions for the viewer, we provided script that used common body language to preserve semantic meaning in both. We instructed the actor to (1) use large, open hand movements with no specific hand or finger gestures and (2) face the camera. As depicted in Figure 10, these modifications detracted from InfoVid benefits and made the presenter look less immersed, but allowed for fairer comparisons with the baseline. B.2 Layouts to Preserve Presenter Body Language and Maximize Visualization View Because we are interested in the effects of perceived performer body language with the visualizations using InfoVids, we chose videoconferencing layout that would clearly capture presenter body language and the visualizations for the baseline. We referenced pre-existing videoconferencing formats in-the-wild and disregarded formats that removed or minimized the size of the presenter to make the visualization the main view. While it is possible to stage visual performance where the full-body is shown, we decided to opt for version that only showed the upper torso for few reasons. First, we wanted the baseline to reflect realistic problem that commonly happens in videoconferencing systems: the cut-off of body language because of the boxing out of the presenter. In addition, we needed to use the same take of the performance for the experiment, but some body movements while using InfoVids were impossible to translate in 2D setting even with scripted common body language. For example, InfoVids encouraged use of full-body movements such as walking back and forth in 3D space or pointing to different parts of the plane, but these movements obstructed the narrative in 2D videoconferencing setting. However, we kept the upper-half of the torso, so that viewers could still have view of the performers hand gestures and facial expressions. We also controlled for how much the presenters body occupied the video frame across different videos. We chose horizontal baseline layout that placed slides to the left of the presenter at 3:1 ratio [66] to maximize views of the presenter and the visualization. We also applied rule of thirds, video composition technique often applied in professional videos to create videos that direct the viewer attention to the presenter [47]. As the orange overlay shows (Figure 6), we divided the presenter video horizontally and vertically into three parts and placed the presenters face just above the top vertical line while leaving some space above the head. If the presenter moved around in the video, we zoomed in or translated the video with the presenter to maintain the rule of thirds, using post-hoc video editing. The end effect is comparable to auto zoom-in techniques following moving presenter in videoconferencing. However, the horizontal setup is trade-off. We exchanged control over phone orientation to maximize screen real estate. Using the vertical orientation of the phone limits the size of the slides and the presenter. Horizontal orientation InfoVids: Reimagining the Viewer Experience with Alternative Visualization-Presenter Relationships Fig. 10. Modifications made to original script to preserve common body language for fair comparisons with slides. Presenter looks less immersed in versions modified for the study because they no longer can look directly at the plane visualizations as body language such as looking up to the sky or directly to the plane would contextually make no sense in videoconferencing presentation with slideswithout the visualizations, performer will be staring into the void. of the InfoVid version cuts off half the presenters body and unfairly disadvantage InfoVids, which enables full-body performances. On the other hand, as seen in Figure 6, the horizontal layout enables full view of the slides and sizable view of the presenter and their hand gestures for the baseline. While this setup clips the lower body and some of the presenters hands at times, these are not atypical formats in video conferencing. Thus, the horizontal layout is compromise that was necessary for more equitable comparison between the InfoVids and the baseline. B.3 Post-hoc Synchronization In typical slide presentation, the performer does not have direct control over the visualizations. They can only sync their movements with it. However, because one of the benefits of InfoVids is the performers ability to directly control the visualization we synced the animations with the presenters movements to simulate well-rehearsed presentation. Using Adobe Premiere Pro, we post-hoc synced the video of the presenter with no virtual overlays with the timings of the animations, gesture triggers, and performers movements in InfoVids. To control for effects caused by different visualization props, we also used the same visualization props and animation effects used for InfoVids, except for InjuryVis where the presenters body was replaced by silhouette. These choices dilute InfoVids advantage to bind visualizations to the body as many presentations in-the-wild dont sync meticulously with the visualizations, but it reduces confounds for the study."
        }
    ],
    "affiliations": [
        "Adobe Research",
        "Brown University"
    ]
}