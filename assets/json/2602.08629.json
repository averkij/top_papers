{
    "paper_title": "CauScale: Neural Causal Discovery at Scale",
    "authors": [
        "Bo Peng",
        "Sirui Chen",
        "Jiaguo Tian",
        "Yu Qiao",
        "Chaochao Lu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts a two-stream design: a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale."
        },
        {
            "title": "Start",
            "content": "CauScale: Neural Causal Discovery at Scale Bo Peng 1 2 3 Sirui Chen 1 4 Jiaguo Tian 3 Yu Qiao 1 2 Chaochao Lu 1 6 2 0 2 9 ] . [ 1 9 2 6 8 0 . 2 0 6 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Causal discovery is essential for advancing datadriven fields such as scientific AI and data analysis, yet existing approaches face significant timeand space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts two-stream design: data stream extracts relational evidence from high-dimensional observations, while graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on indistribution data and 84.4% on out-of-distribution data, while delivering 413,000 inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale. 1. Introduction Causal discovery aims at uncovering causal relationships and mechanisms from observational data (Spirtes et al., 2000; Pearl, 2009; Glymour et al., 2019). central component of causal discovery is causal structure learning, which identifies the underlying structural causal models (SCMs) and learns directed acyclic graphs (DAGs) where edges represent direct causal relationships between variables (Peters et al., 2017). The inference of causal relationships is an 1Shanghai Artificial Intelligence Laboratory 2Shanghai Innovation Institute 3Shanghai Jiao Tong University 4Tongji University. Correspondence to: Chaochao Lu <luchaochao@pjlab.org.cn>. 1 important problem across many fields including bioinformatics (Sachs et al., 2005; Zhang et al., 2013), epidemiology (Vandenbroucke et al., 2016), and economics (Hicks et al., 1980). As data grow increasingly complex, discovering causal relationships from massive datasets has become an urgent challenge. However, existing causal discovery algorithms face major timeand space-efficiency bottlenecks, particularly when scaling to large graphs. Constraint-based algorithms (e.g., PC and FCI (Spirtes et al., 2000)) can become time-prohibitive because they rely on large numbers of conditional-independence tests, whose count grows exponentially in the worst case. In contrast, score-based methods such as NOTEARS (Zheng et al., 2018) and RL-BIC (Zhu et al., 2019) avoid explicit combinatorial search but typically require solving fresh continuous optimization problem for each dataset, which remains computationally expensive at scale. To reduce runtime, AVICI (Lorch et al., 2022) amortizes causal discovery by pretraining supervised model on simulated data and performing zero-shot graph prediction at test time. However, its attention mechanism scales unfavorably with the number of variables, often leading to substantial memory pressure on large graphs. To overcome these timeand space-efficiency bottlenecks, we propose CauScale, an efficient neural architecture for causal discovery. Overall, CauScale adopts two-stream design with data stream and graph stream. For time efficiency, we introduce reduction unit that compresses the data embeddings during network processing. For space efficiency, we adopt tied attention weights (Rao et al., 2021) in both streams: sharing attention weights across axis avoids maintaining axis-specific attention maps and substantially reduces the memory footprint of attention. To improve efficiency without sacrificing discovery quality, we further design data-graph block that (i) injects graph-prior information and (ii) mitigates information loss from data reduction. Specifically, it distills relational evidence from high-dimensional data into graph message to guide representation learning in the graph stream. Moreover, it fuses the two streams by injecting the data stream into the graph embedding before reduction, so that the model preserves key relational signals and alleviates information loss. We conduct extensive experiments on synthetic and singleCauScale: Neural Causal Discovery at Scale cell expression datasets with varying sizes and causal structures. The results demonstrate that CauScale achieves superior accuracy with markedly improved efficiency. Specifically, CauScale achieves an mAP of 99.6% on indistribution data and 84.4% on out-of-distribution (OOD) It stand out as the fastest method, outperforming data. previous approaches by 4 to 13,000. Furthermore, during training, CauScale scales successfully to 500-node graphs, setting where AVICI fails due to limited memory and excessive space costs. In summary, our contributions are: We present one of the first studies on pre-training neural networks for efficient causal discovery at scale, offering scalable step toward uncovering causal relations from increasingly complex data. We introduce CauScale, neural architecture that jointly improves time and memory efficiency with high causal discovery accuracy. We conduct comprehensive experiments to validate the effectiveness of CauScale across varying graph scales and causal mechanisms, demonstrating that CauScale improves both efficiency and causal discovery performance. 2. Related Work Existing causal structure learning methods can be broadly categorized into non-amortized and amortized (zero-shot) approaches, relying on whether inference on new dataset requires solving dataset-specific optimization problem. Non-amortized causal discovery. Non-amortized methods perform causal discovery by solving an optimization or search problem independently for each dataset, leading to high computational cost and limited scalability. 1) Constraint-based algorithms, such as PC and FCI (Spirtes et al., 2000), infer graph structures via conditional independence tests but suffer from exponential complexity as the number of variables grows. 2) Score-based algorithms optimize predefined score over the space of graph structures (Tsamardinos et al., 2006; Goudet et al., 2017). Classical approaches rely on greedy combinatorial search, including GES (Chickering, 2002) and GIES (Hauser & Buhlmann, 2012). To improve scalability, recent work reformulates causal discovery as continuous optimization with differentiable acyclicity constraints (Zheng et al., 2018; Lachapelle et al., 2019; Ke et al., 2019; Zhu et al., 2019; Brouillard et al., 2020). NOTEARS (Zheng et al., 2018) introduces smooth acyclicity constraint, while SDCD (Nazaret et al.) further improves stability via spectral constraints and staged optimization. 3) Functional Causal Model (FCM) based methods exploit asymmetries in the data-generating process for identifiability. Early approaches such as LiNGAM (Shimizu et al., 2006) rely on Independent Component Analysis (ICA) (Hyvarinen et al., 2001), whereas recent methods integrate deep generative models. For example, DiffAN (Sanchez et al., 2023) frames causal discovery as topological sorting using diffusion-based score estimators. Despite their diversity, non-amortized methods require dataset-specific optimization, making them computationally expensive and unsuitable for large-scale or real-time inference. Amortized (zero-shot) causal discovery. Amortized approaches aim to eliminate dataset-specific optimization by learning shared inference model that maps datasets directly to causal graphs, enabling zero-shot inference on unseen data (Lorch et al., 2022; Ke et al., 2023; Wu et al., 2025; Dhir et al., 2025). Lorch et al. (2022); Ke et al. (2023) pioneer amortized variational inference for causal discovery. However, these methods rely on high-dimensional embeddings that scale poorly with graph size. SEA (Wu et al., 2025) mitigates this issue by decomposing large graphs into subproblems, but its reliance on classical estimators such as GIES and extensive sub-batch sampling limits inference speed and causes information loss across variable partitions. 3. Preliminary Causal graphical models. causal graphical model (CGM) (Peters et al., 2017) consists of (i) joint distribution PX over random variables = (X1, . . . , Xn) and (ii) directed acyclic graph = (V, E). Each node corresponds to variable xi, and each directed edge (i, j) encodes direct causal influence from xi to xj. The distribution PX is Markov with respect to G, i.e., p(x1, . . . , xn) = (cid:81)n j=1 p(xj PAj), where PAj denotes the parent set of node j. Causal sufficiency is assumed, meaning there are no unobserved common causes that jointly affect multiple variables in X. Interventions. CGMs support interventions by modifying the conditional mechanism of target variables. An intervention on node replaces the conditional distribution p(xj PAj) with p(xj PAj). Two settings are considered: the observational setting (no interventions), and perfect interventions, where the intervened variable is randomized independently of its parents, i.e., p(xj PAj) = p(xj). 4. CauScale 4.1. Overall Architecture Let denote the number of graph nodes and the number of observational samples. The input data Rmn2 concatenates observational variables Rmn and binary intervention indicator {0, 1}mn, where = 1 indicates that variable is intervened. The model takes 2 CauScale: Neural Causal Discovery at Scale Figure 1: The architecture of CauScale. (a) The overall architecture and the changes of data embedding size during network processing. (b) The reduce operation in reduction unit. Between each data-graph blocks, the reduction unit pool the data embedding along the observation dimension to reduce it with fraction of r. and statistical graph prior ρ Rnn computed from as inputs, and outputs probabilistic adjacency matrix ˆG Rnn representing the likelihood of directed causal relations. The prior ρ is defined as the inverse covariance matrix: ρ = (cid:16) E(cid:2)(D µ)(D µ)(cid:3)(cid:17)1 , µ = E[D] The inputs and ρ are encoded into initial embeddings hD Rmnd and hG Rnnd via linear layers, where is the embedding dimension. These embeddings are then processed by alternating stacks of data-graph block and reduction unit. Each data-graph block updates both the data and graph streams (Section 4.2). Every blocks, the reduction unit pools the data-stream embedding along the sample dimension to reduce its length by factor of (Section 4.3). Within each data-graph block, we employ tied attention weights to reduce memory overhead (Section 4.4). Finally, the graph-stream output is fed into prediction head to produce ˆG (Section 4.5). Figure 1 shows the overall architecture of CauScale. 4.2. DataGraph Block As shown in Figure 2, each data-graph block consists of three modules: data layer, data2graph layer, and graph layer. Given the incoming data and graph embeddings (hD b1), the block proceeds in three steps: (1) The data layer updates the data stream embedding, producb1, hG ing hD . This updated embedding is forwarded to the next data-graph block and, when applicable, to the reduction unit for compression. (2) The data2graph layer summarizes Rmnd into an observation-compressed relation hD Rnn, which captures node relationship matrix ωDG information. (3) The graph layer injects this message into the graph stream by concatenating ωDG with the previb1 Rnnd, and produces the ous graph embedding hG updated graph embedding hG . Data2Graph layer. The data2graph layer extracts pairwise relational evidence from the data stream and summarizes it into graph message. Given the data embedding Rmnd, we first apply data axial-attention layer hD to obtain hDG Rmnd. We then map hDG to two node-level embeddings uDG, vDG Rnd using two separate PoolingFFN modules, each performing average pooling over the observation dimension followed by an MLP. Finally, we form: ωDG = uDG (vDG) Rnn, which represents directed pairwise relations between variables. Graph layer. The graph layer injects ωDG into the graph stream by concatenating it with the previous graph b1 Rnnd, yielding hG Rnn(d+1). embedding hG linear projection maps hG back to Rnnd, which is CauScale: Neural Causal Discovery at Scale Figure 2: Structure of the DaraGraph Block. The data-graph block process information on data and graph stream. On data stream, after being processed by the data axial attention layer, data embedding hD is sent to both the next module on data stream and summarized by the data2graph layer to graph message ωDG . The message will be concatenated with previous graph embedding hG b1 and processed by graph layer in graph stream. then processed by graph axial-attention layer to produce the updated graph embedding hG Rnnd. convenience (replacing with ˆm). Specifically, we reshape hD : d, 4.3. Reduction Unit Naively subsampling observations for estimation can discard informative samples and degrade causal discovery. Instead, we compress the data-stream embedding during network processing, reducing computation while preserving the variable-wise embedding. This design is motivated by three considerations. (1) Efficiency: in typical causal discovery datasets, the number of observational samples is often one to three orders of magnitude larger than the number of nodes n. Compressing along the observation dimension therefore yields substantial computational savings. (2) Dependency structure: causal signals are primarily expressed through dependencies among nodes within each observational sample. Under the standard i.i.d. assumption across samples, aggregating embeddings across observational samples is generally less destructive than collapsing the variable dimension. (3) Reduced information loss: the reduction is applied after several data-graph blocks have transformed raw inputs into more informative representations. Moreover, Data2Graph module is executed before reduction to distill local relational signals into the graph stream, allowing the data stream to be compressed without losing critical structural evidence. Accordingly, CauScale applies the reduction unit every Rmnd data-graph blocks. Given data embedding hD after block {0, . . . , B1} and reduction factor r, we group the observation dimension into chunks of size and average-pool within each chunk. When m, we set ˆm = rm/r and discard the last ˆm samples for and apply average pooling over the group dimension of size r, yielding the reduced embedding hD nd. 4.4. Tied Attention Weights The core component in each stream within data-graph block is an axial-attention layer, which applies self-attention along two axis (row-wise and column-wise), followed by an FFN. Each sub-layer is wrapped with layer normalization, dropout, and residual connections. To improve space efficiency, we adopt the tied attention weight mechanism from Rao et al. (2021), which avoids maintaining axis-specific attention maps and substantially reduces attention memory. For illustration, consider attention along row-axis with Q, K, RRCHdhead , where and denote the row and column dimensions (e.g., R=m, C=n for the data stream), is the number of heads, and dhead is the head dimension. Following Rao et al. (2021), we tie attention weights across rows and only store RHCC, while keeping the output shape unchanged: (cid:88) dhead(cid:88) Ah,i,j = Qr,i,h,t Kr,j,h,t, r=1 t=1 Or,i = j=1 4.5. Prediction Head (cid:88) softmaxj(Ah,i,j) Vr,j,h,: + bO, After the final data-graph block, we take the graph-stream B1 Rnnd, apply layer normalization, and output hG 4 CauScale: Neural Causal Discovery at Scale feed it into pairwise graph prediction head. Following Wu et al. (2025) and Lippe et al. (2021), we do not explicitly enforce acyclicity during prediction, since imposing DAG constraints typically requires additional constrained optimization or post-processing and can be computationally expensive. Moreover, real-world data sometimes contain cycles. We adopt the decomposed head in Lippe et al. (2021). For each unordered node pair {i, j} with < j, we compute logits over three edge states (no edge, j, i) by g{i,j} = FFN(cid:0)[hG B1,i,j, hG B1,j,i](cid:1) R3, (1) 2 where [, ] denotes concatenation. Collecting all pairs yields (N 1) 3, and we obtain probabilities via softmax over the three states for each pair. In our experiments, this decomposed head achieves accuracy comparable to the AVICI prediction head while empirically producing fewer cycles in the decoded graphs. 4.6. Efficiency Analysis Time efficiency. The dominant cost of data-stream axial attention comes from two terms: (i) sample-axis attention over samples for each of the variables, with cost O(nm2); and (ii) node-axis attention over variables for each of the samples, with cost O(mn2). With reduction factor applied every blocks, the effective sample length at block becomes mb = m/rb/k. The average per-block compute is therefore Csample 1 B1 (cid:88) b= nm2 = Cnode 1 B1 (cid:88) b= n2mb = nm2 n2m B1 (cid:88) b=0 B1 (cid:88) b=0 r2b/k, rb/k. b=0 rb/k = (cid:80)B/k1 When is multiple of k, these sums reduce to geometric series: (cid:80)B1 r2i and (cid:80)B1 In our experiments (B=10, k=2, r=2), this yields 26.64% of the baseline sample-axis compute and 38.75% of the baseline node-axis compute. b=0 r2b/k = (cid:80)B/k1 ri. i=0 i=0 Space efficiency. Given attention on row axis, standard attention mechanism stores axis-specific attention maps RRHCC, resulting in O(RHC 2) memory. With tied attention weights (Rao et al., 2021), attention weights are shared across target axis and only RHCC is stored, reducing attention-map memory to O(HC 2). Analogously, for column-axis attention, the memory cost is reduced from O(CHR2) to O(HR2). 5 5. Experiment 5.1. Settings Baselines. We evaluate our approach against several baselines spanning different paradigms: (1) constraint-based methods: Fast Causal Inference (FCI) (Spirtes et al., 2013); (2) score-based methods: NOTEARS (Zheng et al., 2018), SDCD (Nazaret et al.) (3) FCM-based methods: DiffAN (Sanchez et al., 2023) (4) pre-training-based methods: AVICI (Lorch et al., 2022), SEA (Wu et al., 2025). We additionally include two fundamental statistical measures as reference points: global Pearson correlation (CORR) (Benesty et al., 2009) and inverse covariance matrix (INVCOV) (Hartlap et al., 2007). Evaluation metrics. To evaluate causal discovery performance, we adopt four standard metrics for causal structure learning: Structural Hamming Distance (SHD), Mean Average Precision (mAP), Area Under the ROC Curve (AUC), and Orientation Accuracy (OA). To evaluate causal discovery efficiency, we report two metrics: inference time and peak GPU memory. 5.2. Datasets We consider two types of data: synthetic datasets generated from SCMs and semi-synthetic single-cell expression datasets simulated from gene regulatory networks (GRNs). Training data. For synthetic data, we generate datasets based on Erdos-Renyi and Scale-Free graphs. The graph size ranges from 10 to 500, with edge counts {n, 2n, 3n, 4n}. The causal mechanisms include both linear and neural network (NN) functions with additive or nonadditive Gaussian noise. For each graph, we sample 1,000 observations, consisting of observational and single-node interventional data in 1 : ratio. For single-cell GRNs, we utilize the SERGIO GRN simulator (Dibaeinia & Sinha, 2020) to generate gene expression data. The underlying graph topologies are initialized using Erdos-Renyi, ScaleFree, and Stochastic Block Models. Given the complexity of gene regulatory dynamics, we increase the sample size to 5,000 to ensure reliable structure learning. Consequently, to balance the computational overhead introduced by this larger sample size, we restrict the maximum graph size to = 200. Details are provided in Appendix B. Tesing data. We construct separate benchmarks to assess scalability and robustness. For synthetic data, we assess the model on graphs of varying scales, with (n, E) {(100, 400), (1000, 2000)} and sample size of 1,000. We also introduce two out-of-distribution causal mechanisms: sigmoid and polynomial functions. For GRN data, we evaluate on graphs with (n, E) {(100, 400), (200, 400)}, using larger sample size of 20,000. For each testing conCauScale: Neural Causal Discovery at Scale Synthetic (sample size= 1000) Model Linear NN non-add. Sigmoid Polynomial Time mAP SHD AUC OA mAP SHD AUC OA mAP SHD AUC OA mAP SHD AUC OA (s) Setting: = 100, = 400 CORR INVCOV 20.1 578.0 79.8 34.1 491.2 93. - - 14.7 605.4 74.0 23.6 530.8 82.5 - - 28.4 501.2 86.7 32.9 477.8 90.5 - - 23.1 532.8 76.9 23.7 504.6 72. - - 0.0008 0.0275 FCI NOTEARS SDCD DiffAN AVICI SEA-gies 12.4 372.0 55.3 10.7 11.1 359.8 55.3 11.0 15.1 348.2 56.3 12.6 9.0 368.4 53.0 6.1 84.987 29.4 300.8 51.8 27.8 17.8 337.0 50.4 19.5 11.3 366.0 49.1 8.3 8.6 371.8 52.5 4.9 2170.2 42.3 400.2 89.3 81.6 65.7 272.6 89.0 79.8 61.9 327.8 87.6 76.5 41.9 303.8 70.9 42.8 67.428 8.4 465.2 53.6 9.3 12.3 389.4 57.4 12.3 11.6 378.9 50.3 11.1 1973.4 10.6 475.4 51.3 25.9 394.0 80.2 81.4 32.3 361.2 81.1 81.5 22.7 371.8 68.4 63.2 5.6 384.6 45.9 36.8 0.2974 92.1 108.6 99.2 94.8 51.2 306.2 88.4 86.6 72.7 192.2 92.2 85.4 36.2 319.2 74.2 70.8 8.7759 CauScale (Ours) 99.6 15.2 100.0 100.0 89.0 105.6 98.5 99.5 84.4 125.8 95.0 94.6 50.3 252.2 79.4 81.7 0.0384 8.5 Setting: = 1000, = 2000 CORR INVCOV 34.3 2376.6 99.5 46.7 1996.6 99.8 - - 16.2 3031.0 93.9 28.0 2432.2 92.6 - - 34.7 2304.2 97.7 40.6 2056.6 97. - - 25.0 2472.6 83.7 26.4 2359.0 83.9 - - 0.0455 0.4412 FCI NOTEARS SDCD AVICI SEA-gies 32.9 1309.0 67.2 34.4 12.7 1721.2 58.7 17.4 8.6 1828.6 54.5 9.0 1.5 2008.8 50.7 1.4 2005.2 30.5 1388.6 50.6 30.5 20.5 1677.8 50.0 23.2 11.0 1790.4 50.0 10.9 7.3 1893.2 53.6 7.1 10896 54.1 1793.2 99.3 98.6 59.6 2015.0 87.9 76.0 48.5 1649.2 89.2 78.5 29.8 1798.4 74.6 49.2 65.386 0.2 1985.8 47.5 46.2 0.9 1980.2 56.8 54.6 0.2 2006.8 39.6 41.9 0.1 2037.0 37.0 40.3 3.3407 66.3 2944.8 98.2 80.2 11.9 3227.4 73.9 66.2 48.1 1359.0 88.8 70.1 20.6 6814.2 72.0 58.9 218.23 CauScale (Ours) 96.6 230.0 100.0 96.5 79.7 835.0 98.2 96.6 64.5 1064.6 95.3 79.0 18.9 3985.0 78.1 59.7 0. SERGIO-GRN (sample size= 20000) Model CORR INVCOV NOTEARS SDCD AVICI SEA-gies CauScale (Ours) mAP 4.5 5. 4.1 4.0 5.6 71.4 = 100, = 400 OA AUC SHD 403.4 403.0 51.9 52.3 - - 492.8 764.6 400.2 290.8 2.0 5.1 50.5 49.0 Out of memory 58.8 95.1 61.6 94.2 Time mAP 0.0128 0.0793 5040.8 579.68 1.1 1.2 1.0 2.1 11.769 1. 1.2 34.5 = 200, = 400 OA AUC SHD 409.8 409.8 52.7 52.4 - - 591.0 1265.0 407.8 336.8 0.4 3.7 49.8 49.9 Out of memory 55.0 90.3 57.07 90.9 Time 0.0147 0.0995 5805.9 670.10 17.288 2.5195 Table 1: Model performance comparison. indicates o.o.d settings. Time represents inference time. Note: DiffAN and FCI are excluded from large node or large sample size settings due to excessive time costs. figuration, we generate 5 independent Erdos-Renyi graph instances, and report the averaged results. 5.3. Model Performance Table 1 compares CauScale against other baselines. CauScale demonstrates superior accuracy and efficiency across varying graph sizes and mechanisms. Accuracy On the synthetic dataset with = 100, our model achieves near-perfect causal discovery on linear data (99.6% mAP) and consistently outperforms baselines in non-linear settings. Notably, on large-scale graphs with 1000 nodes (a size unseen during training), CauScale maintains high performance (96.6% mAP for linear), despite our model being trained on graphs with at most 500 nodes. CauScale also exhibits strong generalization capabilities on OOD mechanisms. Specifically, on the polynomial dataset (n = 100) with more complex mechanisms, CauScale achieves 50.3% mAP, whereas the second and third best methods, SEA and SDCD, drop to 36.2% and 41.9%, respectively. On the SERGIO-GRN dataset, CauScale achieves the best performance across all metrics and settings among all causal discovery baselines. Time and space efficiency CauScale achieves the shortest inference time among all evaluated causal discovery algorithms. Even on graphs with = 1000, our inference takes less than 1 second (0.8288s), achieving speedup of over 13,000 compared to NOTEARS (10,896s), 200 compared to SEA-gies (218s), and 4 compared to AVICI (3.34s). Regarding space efficiency, on SERGIO-GRN dataset, AVICI fails with an Out-of-Memory error even at = 100. In contrast, CauScale successfully scales to 6 CauScale: Neural Causal Discovery at Scale Figure 3: Comparison of w/ and w/o Reduction Unit. Graph Stream). We retrain the two ablation versions on our synthetic train set. Figure 4 demonstrates the performance comparison on our synthetic benchmark. Removing the graph stream causes the most significant performance degradation, highlighting the importance of it. Removing the graph prior causes less performance degradation but still yields inferior results compared to our full model, validating the importance of the inductive bias. Attention shape and output head We conduct an ablation study to analyze the components of our model relative to AVICI. Specifically, we evaluate two variants: (1) replacing the tied-attention mechanism in CauScale with the vanilla attention from (Lorch et al., 2022) (Vanilla Attn), and (2) replacing our prediction head in Equation 1 with the vanilla prediction head from (Lorch et al., 2022) (Vanilla Head). B1 Rnnd to The latter projects the graph embedding hG logit Rnn using Feed-Forward Network, followed by sigmoid function to obtain edge probabilities. Due to the high space complexity of vanilla self-attention, we limited this study to subset of the training set with node counts {10, 20, 100}. Figure 5 illustrates the results averaged across all causal mechanisms. The results show the advantage of our implemented components. First, the tiedattention mechanism demonstrates superior computational efficiency, achieving an inference speed six times faster than vanilla attention on graphs with (n = 100, = 400). It also yields higher mean average precision score, striking perfect balance between efficiency and accuracy. Second, our pairwise processing head leads to much more lower degree of cyclicity (0.0%) compared to the vanilla prediction head used in AVICI (0.0-0.25%). Pooling strategy of reduction unit We conduct lightweight ablation study using graphs with node counts of = {10, 20, 50} during training and testing to efficiently evaluate different pooling strategies within the reduction unit. In addition to the average pooling employed in CauScale, we compare two alternative downsampling techniques: strided pooling and max pooling. Table 2 demonstrates that average pooling consistently achieves superior performance across experimented graph sizes. Figure 4: Advantage of data-graph block over the block containing the data layer only. = 200 with 20,000 samples. 5.4. Ablation Studies W/ and w/o reduction unit We remove the reduction unitand retrain the model on synthetic dataset to validate its importance. Since the network encounters Out-of-Memory errors on the original training set without the reduction unit, we use training subset with node number limited to {10, 20, 100}. We train both CauScale and the architecture w/o reduction uniton this subset and evaluate their performance on synthetic test set with the same node number. Other settings in test set are the same with the evaluation benchmark. Results are averaged across all four distributions (linear, NN, sigmoid, and polynomial). Figure 3 illustrates the mean average precision, inference time, and peak GPU memory usage. The benefits of the reduction unit become increasingly pronounced as the number of nodes increases, enabling the model to maintain high accuracy while achieving significantly faster inference speeds and lower GPU memory usage. Graph components We conduct ablation studies by (1) removing the input graph prior by setting the graph input to an all-ones vector (w/o Graph Prior) and (2) removing the graph stream while retaining only the data stream (w/o 7 CauScale: Neural Causal Discovery at Scale Figure 5: Ablation on components: Ours vs. AVICI. (Nodes, Edges) Max Strided Average (10,10) (20,80) (50,200) 94.3 76.0 71.2 100.0 84.6 78. 100.0 92.6 85.4 Table 2: Mean Average Precision (%) comparison across different pooling strategies in the Reduction Unit. We use average pooling in CauScale. Figure 7: Sample size analysis by mean average precision. 5.6. Sample Size analysis We conduct sample size analysis on our trained models in Section 5.3, with inference sample sizes varying from 500 to 4000 for synthetic data and from 1000 to 20000 for SERGIO-GRN data. Figure 7 shows that the model trained on synthetic data achieves peak performance with sample size of 2000, while the model for SERGIO-GRN achieves the best performance with sample size of 20000. This suggests that more complex causal mechanisms necessitate larger sample sizes for accurate inference. 6. Conclusion We presented CauScale, an efficient neural architecture for large-scale causal discovery that addresses the time and memory bottlenecks of prior methods. CauScale combines reduction unit for time efficiency, tied attention weights for space efficiency, and two-stream design that preserves structural signals under compression. Extensive experiments on synthetic and semi-synthetic single-cell benchmarks show that CauScale scales training to 500node graphs and enables inference on graphs with up to Figure 6: Generalization property of CauScale on OOD graphs, noise, and mechanism functions. 5.5. Generalization Analysis We further evaluate the generalization capability of the synthetic-data-trained model described in Section 5.3 across OOD graph structures generated by Stochastic Block Models, OOD noise distributions (uniform and Laplace), and OOD functions (sigmoid and polynomial). Figure 6 reveals that the model demonstrates strong generalization to OOD graph structures but exhibits greater sensitivity to OOD noise patterns and mechanism functions. These findings indicate that future model training should prioritize generating datasets with more diverse noise distributions and mechanism functions to enhance robustness. 8 CauScale: Neural Causal Discovery at Scale 1,000 nodes, achieving strong accuracy with 413,000 speedups over existing approaches. These results suggest practical direction for pre-training efficient neural models for causal discovery at scale. Hartlap, J., Simon, P., and Schneider, P. Why your model parameter confidences might be too optimistic. unbiased estimation of the inverse covariance matrix. Astronomy & Astrophysics, 464(1):399404, 2007."
        },
        {
            "title": "Impact Statement",
            "content": "This paper presents CauScale, neural architecture for efficient and scalable causal discovery on large graphs. The primary impact is to make causal structure learning more computationally accessiblereducing runtime and memory requirementsand thereby supporting faster hypothesis generation in data-intensive scientific domains. As with any causal discovery method, results can be sensitive to data quality, modeling assumptions, and distribution shift; spurious edges may arise if the input data are noisy or misspecified. We emphasize that the predicted graphs should be treated as hypotheses and validated by domain experts and, where applicable, downstream experiments before being used in high-stakes decision-making."
        },
        {
            "title": "References",
            "content": "Benesty, J., Chen, J., Huang, Y., and Cohen, I. Pearson correlation coefficient. In Noise reduction in speech processing, pp. 14. Springer, 2009. Brouillard, P., Lachapelle, S., Lacoste, A., Lacoste-Julien, S., and Drouin, A. Differentiable causal discovery from interventional data. Advances in Neural Information Processing Systems, 33:2186521877, 2020. Hauser, A. and Buhlmann, P. Characterization and greedy learning of interventional markov equivalence classes of directed acyclic graphs. The Journal of Machine Learning Research, 13(1):24092464, 2012. Hicks, J. et al. Causality in economics. Australian National University Press, 1980. Hyvarinen, A., Hurri, J., and Hoyer, P. O. Independent component analysis. In Natural Image Statistics: Probabilistic Approach to Early Computational Vision, pp. 151175. Springer, 2001. Ke, N. R., Bilaniuk, O., Goyal, A., Bauer, S., Larochelle, H., Scholkopf, B., Mozer, M. C., Pal, C., and Bengio, Y. Learning neural causal models from unknown interventions. arXiv preprint arXiv:1910.01075, 2019. Ke, N. R., Chiappa, S., Wang, J. X., Bornschein, J., Goyal, A., Rey, M., Weber, T., Botvinick, M., Mozer, M. C., and Rezende, D. J. Learning to induce causal structure. In International Conference on Learning Representations, 2023. Lachapelle, S., Brouillard, P., Deleu, T., and Lacoste-Julien, S. Gradient-based neural dag learning. arXiv preprint arXiv:1906.02226, 2019. Chickering, D. M. Optimal structure identification with greedy search. Journal of machine learning research, 3 (Nov):507554, 2002. Lippe, P., Cohen, T., and Gavves, E. Efficient neural causal discovery without acyclicity constraints. arXiv preprint arXiv:2107.10483, 2021. Chu, D., Zabet, N. R., and Mitavskiy, B. Models of transcription factor binding: sensitivity of activation functions to model assumptions. Journal of Theoretical Biology, 257 (3):419429, 2009. Dhir, A., Ashman, M., Requeima, J., and van der Wilk, M. meta-learning approach to bayesian causal discovery. In The Thirteenth International Conference on Learning Representations, 2025. Dibaeinia, P. and Sinha, S. Sergio: single-cell expression simulator guided by gene regulatory networks. Cell systems, 11(3):252271, 2020. Glymour, C., Zhang, K., and Spirtes, P. Review of causal discovery methods based on graphical models. Frontiers in genetics, 10:524, 2019. Goudet, O., Kalainathan, D., Caillou, P., Guyon, I., LopezPaz, D., and Sebag, M. Causal generative neural networks. arXiv preprint arXiv:1711.08936, 2017. Lorch, L., Sussex, S., Rothfuss, J., Krause, A., and Scholkopf, B. Amortized inference for causal structure learning. Advances in Neural Information Processing Systems, 35, 2022. Nazaret, A., Hong, J., Azizi, E., and Blei, D. Stable differentiable causal discovery. In Forty-first International Conference on Machine Learning. Pearl, J. Causality. Cambridge university press, 2009. Peters, J., Janzing, D., and Scholkopf, B. Elements of causal inference: foundations and learning algorithms. The MIT press, 2017. Rao, R., Liu, J., Verkuil, R., Meier, J., Canny, J. F., Abbeel, P., Sercu, T., and Rives, A. Msa transformer. 10.1101/2021.02. 12.430858. URL https://www.biorxiv.org/ content/10.1101/2021.02.12.430858v1. bioRxiv, 2021. doi: CauScale: Neural Causal Discovery at Scale Sachs, K., Perez, O., Peer, D., Lauffenburger, D. A., and Nolan, G. P. Causal protein-signaling networks derived from multiparameter single-cell data. Science, 308(5721): 523529, 2005. Sanchez, P., Liu, X., ONeil, A. Q., and Tsaftaris, S. A. Diffusion models for causal discovery via topological In The Eleventh International Conference ordering. on Learning Representations, 2023. URL https:// openreview.net/forum?id=Idusfje4-Wq. Shimizu, S., Hoyer, P. O., Hyvarinen, A., Kerminen, A., and Jordan, M. linear non-gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(10), 2006. Spirtes, P., Glymour, C., and Scheines, R. Causation, prediction, and search. adaptive computation and machine learning series. The MIT Press, 49:7778, 2000. Spirtes, P. L., Meek, C., and Richardson, T. S. Causal inference in the presence of latent variables and selection bias. arXiv preprint arXiv:1302.4983, 2013. Tsamardinos, I., Brown, L. E., and Aliferis, C. F. The maxmin hill-climbing bayesian network structure learning algorithm. Machine learning, 65(1):3178, 2006. Vandenbroucke, J. P., Broadbent, A., and Pearce, N. Causality and causal inference in epidemiology: the need for pluralistic approach. International journal of epidemiology, 45(6):17761786, 2016. Wu, M., Bao, Y., Barzilay, R., and Jaakkola, T. S. Sample, estimate, aggregate: recipe for causal discovery foundation models. Trans. Mach. Learn. Res., 2025, 2025. Zhang, B., Gaiteri, C., Bodea, L.-G., Wang, Z., McElwee, J., Podtelezhnikov, A. A., Zhang, C., Xie, T., Tran, L., Dobrin, R., et al. Integrated systems approach identifies genetic nodes and networks in late-onset alzheimers disease. Cell, 153(3):707720, 2013. Zheng, X., Aragam, B., Ravikumar, P., and Xing, E. P. DAGs with NO TEARS: Continuous Optimization for Structure Learning. In Advances in Neural Information Processing Systems, 2018. Zhu, S., Ng, I., and Chen, Z. Causal discovery with reinforcement learning. arXiv preprint arXiv:1906.04477, 2019. 10 A. Evaluation metrics. CauScale: Neural Causal Discovery at Scale To evaluate causal discovery performance, we adopt four standard metrics for causal structure learning: (1) Structural Hamming Distance (SHD): the minimum number of edge insertions, deletions, and reversals required to transform the predicted graph into the ground-truth graph. (2) Mean Average Precision (mAP): the area under the precision-recall curve computed over all candidate edges, averaged across the graph. (3) Area Under the ROC Curve (AUC): the area under the ROC curve computed over all candidate edges, averaged across the graph. (4) Orientation Accuracy (OA): the fraction of ground-truth directed edges for which the model assigns higher probability to the correct direction. B. Data Generation Details B.1. Causal Graph Details We evaluate our method on various causal graphs. Below, we provide detailed description of the graph models used in this study. Both the synthetic data and SERGIO-GRN data are generated based on these Directed Acyclic Graph (DAG) structures. Erdos-Renyi (ER): standard random graph model where edges are added between any pair of nodes with fixed probability p. This results in graph where the degree distribution is approximately Poissonian, representing networks with uniform connectivity patterns. Scale-Free (SF): Generated using the Barabasi-Albert preferential attachment process. New nodes are more likely to attach to existing nodes with high degrees. This topology creates networks with hubs and follows power-law degree distribution, simulating real-world biological (e.g., gene regulatory networks) or social networks. Stochastic Block Model (SBM): generative model for graphs with community structure. Nodes are assigned to one of latent blocks (clusters). Edge probabilities depend on the block membership of the nodes (high probability within blocks, low probability between blocks). This is particularly useful for modeling modular systems, such as protein-protein interaction networks with functional modules. B.2. Synthetic Data Generation The details of the distribution settings for the synthetic data are explained below. We generate data following the code and settings in Wu et al. (2025) and Brouillard et al. (2020). Let Xi denote the target node, PAi its parents, Ni an independent noise variable, and the randomly initialized weights. Linear: The most fundamental assumption where dependencies are linear: Xi = WiPAi + Ni. Neural Networks (NN-Add): The mechanism follows Xi = MLP(PAi) + Ni, where MLP is random initialized Multi-Layer Perceptron (MLP) with single hidden layer and nonlinear activations (PReLU). Neural Networks (NN): The noise is concatenated with the parents as input to the neural network: Xi = MLP(PAi, Ni). Sigmoid Additive: Xi = (cid:80) Wjσ(P Aij) + Ni, simulating biological saturation effects. Polynomial: Xi = (cid:80)2 k=0 WkPAk + Ni, modeling polynomial dependencies. Root nodes are initialized using Uniform distribution of Uniform(-1,1). We set noise to Ni 0.4 (0, σ2), where σ2 Uniform(1, 2). We apply interventions (hard intervention) one node at time, covering all node and setting their mechanisms to Uniform(-1,1). For smaller graphs (N {10, 20, 100}), we generate 600 distinct graph structures for each parameter combination. For larger graphs (N {150, 200, 300, 500}), we generate 300 distinct structures per combination due to the increasing computational time required for generation. CauScale: Neural Causal Discovery at Scale B.3. SERGIO-GRN Data Generation We generated the data using slightly modified version of the SERGIO-GRN (Dibaeinia & Sinha, 2020) code from AVICI (Lorch et al., 2022). The simulator generates gene expression data by sampling from the steady state of dynamic system, described by Stochastic Differential Equations (SDEs) (Dibaeinia & Sinha, 2020). Downstream regulatory interactions are modeled using Hill functions (Chu et al., 2009), ensuring the realistic gene behavior. All samples are generated under gene intervention settings. Specifically, we conduct gene knockouts by setting the target gene expression level to zero. Regarding graph structures, we employ Erdos-Renyi (ER), Scale-Free, and Stochastic Block Models for training. The number of cell types is set between 5 and 10. We generate 200 distinct graph structures for each setting. We consider training graphs with sizes {10, 20, 30, 50, 80, 100, 150, 200}, where the number of edges {2N, 4N, 6N }. C. Baseline Implementation Details INVCOV and CORR For both INVCOV and CORR, we discretize the predicted continuous values to match the sparsity of the ground truth. The threshold is set to the (1 n2 )-th quantile of the predictions, where and represent the number of edges and nodes in the ground truth, respectively. FCI We implement the Fast Causal Inference (FCI) algorithm using the causal-learn library1. FCI is constraint-based causal discovery algorithm that identify causal relationships in the presence of latent confounders and selection bias. We use Fisher-Z test with α = 0.05 significance Level during experiment. NOTEARS We utilize the official implementation of the NOTEARS algorithm2. Following the default setting in the repository, we apply threshold of 0.3 to the estimated weight matrix to filter out weak edges before computing the Structural Hamming Distance (SHD). DiffAN We implemented DiffAN by adopting the official hyperparameter configurations, which the original authors (Sanchez et al., 2023) noted are largely hard-coded and robust across diverse datasets. To strictly adhere to the nonapproximated version of the algorithm, the residue parameter was set to True. For downstream evaluation requiring continuous scores such as AUC and mAP, we extracted the edge existence p-values and applied log10 transformation to derive the final confidence estimates. For metrics requiring binary adjacency matrix such as SHD, we followed the hyperparameters α = 0.05 as the threshold for edge pruning. SDCD We utilized the official implementation of SDCD3. All hyperparameters followed the default settings provided in the official repository. We specified GPU as the computing device to ensure efficiency. To compute SHD, we apply discretization threshold of 0.5. AVICI Due to the high memory requirements encountered when attempting to train AVICI on our datasets (resulting in Out-of-Memory errors), we utilized the pre-trained checkpoints provided in the official repository4. For synthetic data, we employed the scm-v0 model, which was pre-trained on diverse linear and non-linear datasets. For the SERGIO-GRN dataset, we utilized the neurips-grn checkpoint. All other settings remained consistent with our experimental setup, utilizing both interventional and observational data. We apply discretization threshold of 0.5. SEA We trained SEA using the same training data as ours, including both synthetic and SERGIO-GRN datasets. We use the GIES-based architecture. All training and testing configurations followed the default settings of SEA. We apply discretization threshold of 0.5. D. CauScale Implementation Details Model Configuration. The model consists of 10 layers with 128-dimensional embeddings and 16 attention heads. This configuration was determined through hyperparameter tuning across layers {8, 10} and embedding dimensions 1https://causal-learn.readthedocs.io 2https://github.com/xunzheng/notears 3https://github.com/azizilab/sdcd 4https://github.com/larslorch/avici 12 {64, 128, 256}. CauScale: Neural Causal Discovery at Scale Data Preprocessing. Each set of data is standardized variable-wise. For each variable xi, we compute the normalized value via ˆxi = (xi µi)/σi, where µi represents the empirical mean and σi is the standard deviation. Hardware Details All training and inference tasks are conducted on NVIDIA H200 GPUs (141GB memory per GPU) and 164 CPU cores. Note that the baselines (e.g., AVICI) detailed in Section are also evaluated in this environment. Training Strategy We use the Adam optimizer with learning rate of 1 104. Training is performed on 8 GPUs using distributed data parallelism. For synthetic data, we adopt two-stage training strategy. This design is motivated by two key factors: (1) It allows the model to capture fundamental causal relationships on simpler graphs (10100 nodes) before generalizing to complex structures (up to 500 nodes). (2) Grouping graphs by size significantly reduces memory waste caused by excessive zero-padding when batching graphs of vastly different scales (e.g., mixing 10-node and 500-node graphs). Based on this, the training proceeds as follows: Stage 1 (10100 nodes): Batch size of 8 for 37 hours. Stage 2 (150500 nodes): Batch size of 1 for 2.75 hours. For the SERGIO-GRN dataset, as the graph sizes vary within narrower range (10200 nodes), we train the model in single stage with batch size of 1 for 44 hours."
        }
    ],
    "affiliations": [
        "Shanghai Artificial Intelligence Laboratory",
        "Shanghai Innovation Institute",
        "Shanghai Jiao Tong University",
        "Tongji University"
    ]
}