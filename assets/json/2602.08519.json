{
    "paper_title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering",
    "authors": [
        "Yunhui Liu",
        "Pengyu Qiu",
        "Yu Xing",
        "Yongchao Liu",
        "Peng Du",
        "Chuntao Hong",
        "Jiajun Zheng",
        "Tao Zheng",
        "Tieke He"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Attributed Graph Clustering (AGC) is a fundamental unsupervised task that integrates structural topology and node attributes to uncover latent patterns in graph-structured data. Despite its significance in industrial applications such as fraud detection and user segmentation, a significant chasm persists between academic research and real-world deployment. Current evaluation protocols suffer from the small-scale, high-homophily citation datasets, non-scalable full-batch training paradigms, and a reliance on supervised metrics that fail to reflect performance in label-scarce environments. To bridge these gaps, we present PyAGC, a comprehensive, production-ready benchmark and library designed to stress-test AGC methods across diverse scales and structural properties. We unify existing methodologies into a modular Encode-Cluster-Optimize framework and, for the first time, provide memory-efficient, mini-batch implementations for a wide array of state-of-the-art AGC algorithms. Our benchmark curates 12 diverse datasets, ranging from 2.7K to 111M nodes, specifically incorporating industrial graphs with complex tabular features and low homophily. Furthermore, we advocate for a holistic evaluation protocol that mandates unsupervised structural metrics and efficiency profiling alongside traditional supervised metrics. Battle-tested in high-stakes industrial workflows at Ant Group, this benchmark offers the community a robust, reproducible, and scalable platform to advance AGC research towards realistic deployment. The code and resources are publicly available via GitHub (https://github.com/Cloudy1225/PyAGC), PyPI (https://pypi.org/project/pyagc), and Documentation (https://pyagc.readthedocs.io)."
        },
        {
            "title": "Start",
            "content": "Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering Pengyu Qiu pengyu.qpy@antgroup.com Ant Group Hangzhou, China Yunhui Liu lyhcloudy1225@gmail.com Nanjing University & Ant Group Nanjing, China Yu Xing wake.xingyu@gmail.com Nanjing University Nanjing, China 6 2 0 2 9 ] . [ 1 9 1 5 8 0 . 2 0 6 2 : r Yongchao Liu yongchao.ly@antgroup.com Ant Group Hangzhou, China Jiajun Zheng zjj517361@antgroup.com Ant Group Shanghai, China Peng Du dupeng.du@antgroup.com Ant Group Hangzhou, China Chuntao Hong chuntao.hct@antgroup.com Ant Group Beijing, China Tao Zheng zt@nju.edu.cn Nanjing University Nanjing, China Tieke He hetieke@gmail.com Nanjing University Nanjing, China Abstract Attributed Graph Clustering (AGC) is fundamental unsupervised task that integrates structural topology and node attributes to uncover latent patterns in graph-structured data. Despite its significance in industrial applications such as fraud detection and user segmentation, significant chasm persists between academic research and real-world deployment. Current evaluation protocols suffer from the small-scale, high-homophily citation datasets, nonscalable full-batch training paradigms, and reliance on supervised metrics that fail to reflect performance in label-scarce environments. To bridge these gaps, we present PyAGC, comprehensive, production-ready benchmark and library designed to stresstest AGC methods across diverse scales and structural properties. We unify existing methodologies into modular Encode-ClusterOptimize framework and, for the first time, provide memory-efficient, mini-batch implementations for wide array of state-of-the-art AGC algorithms. Our benchmark curates 12 diverse datasets, ranging from 2.7 103 to 1.1 108 nodes, specifically incorporating industrial graphs with complex tabular features and low homophily. Furthermore, we advocate for holistic evaluation protocol that mandates unsupervised structural metrics and efficiency profiling alongside traditional supervised metrics. Battle-tested in highstakes industrial workflows at Ant Group, this benchmark offers the community robust, reproducible, and scalable platform to advance AGC research towards realistic deployment. The code and resources are publicly available via GitHub, PyPI, and Docs. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference acronym XX, Woodstock, NY 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/2018/06 https://doi.org/XXXXXXX.XXXXXXX CCS Concepts Computing methodologies Cluster analysis. Keywords Attributed Graph Clustering, Graph Neural Networks, Scalability, Benchmark, Large-Scale Graphs ACM Reference Format: Yunhui Liu, Pengyu Qiu, Yu Xing, Yongchao Liu, Peng Du, Chuntao Hong, Jiajun Zheng, Tao Zheng, and Tieke He. 2018. Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering. In Proceedings of Make sure to enter the correct conference title from your rights confirmation email (Conference acronym XX). ACM, New York, NY, USA, 14 pages. https://doi.org/XXXXXXX.XXXXXXX"
        },
        {
            "title": "1 Introduction\nThe proliferation of graph-structured data across diverse domains,\nfrom billion-scale social networks and e-commerce platforms to\ncomplex protein interaction maps, has cemented the importance of\nextracting structure from unlabeled data. Attributed Graph Clus-\ntering (AGC), which aims to partition nodes into disjoint groups\nby synergizing structural topology and node attributes, stands as a\npivotal unsupervised learning task in this landscape [24]. Unlike\ntraditional community detection [31] (which ignores attributes) or\nKMeans clustering [29] (which ignores topology), AGC algorithms\nmust integrate these heterogeneous signals to uncover latent pat-\nterns. This capability makes it indispensable for industrial applica-\ntions where ground-truth labels are notoriously scarce or expensive\nto obtain, such as detecting communities in social networks [32],\nidentifying fraud rings in transaction networks [44], or segmenting\nusers for personalized recommendation [26].",
            "content": "Driven by the success of Graph Neural Networks (GNNs) [14] and Self-Supervised Learning (SSL) [20], the landscape of AGC has evolved rapidly. Existing AGC methodologies can be unified under an Encode-Cluster-Optimize framework, which dissects existing algorithms into three conceptual pillars: representation learning, cluster assignment, and optimization objectives. Regarding Conference acronym XX, June 0305, 2018, Woodstock, NY Yunhui Liu et al. encoders, approaches range from non-parametric spectral filters that smooth node features over the graph topology [18, 48] to parametric GNNs that fuse structure and attributes into deep latent embeddings [6, 23]. For cluster projection, strategies diverge significantly: neural centroid-based models align embeddings with learnable prototypes [22, 38], subspace methods rely on self-expressive coefficients to reveal global segmentation [7, 16], while recent community-centric approaches employ differentiable pooling layers to directly map nodes to probabilistic assignments [4, 34]. Finally, the optimization paradigms dictate how these components interact, shifting from disjoint two-stage training, where clustering is post-hoc operation (e.g., KMeans) on fixed embeddings, to endto-end joint learning that supervises representation quality with graph reconstruction [13, 38], contrastive learning [17, 21], feature decorrelation [19, 46], or clustering-specific objectives [22, 41]. Despite these algorithmic strides, chasmic gap remains between academic research and industrial reality. Through rigorous survey of existing literature, we identify that the current evaluation ecosystem for AGC is brittle, biased, and largely disconnected from the challenges of real-world deployment. We summarize the critical limitations of the current landscape as follows: The Cora-fication of Datasets: The vast majority of AGC models are evaluated almost exclusively on canonical set of small academic citation networks (e.g., Cora, CiteSeer, PubMed) [2]. These datasets are characterized by small scale, textual features, and high homophily (where connected nodes share similar labels). This creates path dependency where algorithms are over-fitted to clean, academic scenarios, failing to generalize to industrial graphs (e.g., transaction or web networks) that are often largescale, heterophilous, noisy, and dominated by heterogeneous tabular features [1]. The Scalability Bottleneck: Most state-of-the-art AGC methods rely on full-batch matrix operations (e.g., constructing adjacency matrix [30, 38] or pairwise contrastive learning [17, 23]) that scale quadratically with the number of nodes. This restricts their applicability to toy graphs with few hundred thousand nodes. There is glaring absence of production-ready, minibatch compatible implementations that can handle the memory constraints of modern GPUs when processing graphs with millions of nodes. Consequently, the behavior of deep clustering on industrial-scale graphs is largely unexplored. The Supervised Metric Paradox: Although AGC is fundamentally an unsupervised task, the community defaults to supervised evaluation metrics such as Accuracy, Normalized Mutual Information, and Adjusted Rand Index [24, 39]. This creates label-fitting incentive, where models are tuned to recover human-annotated classes rather than discovering intrinsic clusters themselves. In realistic industrial settings where labels are unavailable, practitioners may require algorithms that optimize intrinsic structural density or separability, yet these unsupervised quality metrics are systematically underreported [42]. The Reproducibility and Benchmarking Gap: While recent DGCBench [39] has attempted to standardize the evaluation landscape by providing unified codebase, it fails to resolve the fundamental dilemmas outlined above. It largely inherits the traditional academic evaluation paradigm, retaining full-batch training mechanisms and focusing on standard, smaller-scale datasets. Consequently, the critical \"last mile\" challenges of industrial application, specifically massive scalability via mini-batch training, robustness to feature/structure heterogeneity, and purely unsupervised structural validation, remain open problems that require dedicated, production-oriented benchmark. To bridge these gaps, we introduce comprehensive benchmark and evaluation framework designed to rigorously stress-test AGC methods across diverse domains, scales, and structural properties. Our work is anchored by PyAGC, production-ready library that systematizes the chaotic landscape of clustering algorithms into unified Encode-Cluster-Optimize framework. Crucially, PyAGC is not merely research prototype; it has been battle-tested in highstakes industrial environments at Ant Group, supporting critical workflows in Fraud Detection, Anti-Money Laundering, and User Profiling. This industrial validation ensures that our benchmark addresses genuine scalability and robustness challenges. Our contributions are summarized as follows: Diverse and Challenging Data Atlas: We curate benchmark of 12 datasets ranging from 2.7 103 to 1.1 108 nodes, spanning diverse domains (citation, social, e-commerce, web). We deliberately introduce industrial datasets (e.g., HM, Pokec, WebTopic) [1] that challenge models with low homophily, tabular attributes, and massive scale, moving beyond the comfort zone of academic datasets. From Full-Graph to Production-Grade Scalability: We break the scalability barrier by providing standardized, memory-efficient mini-batch implementations for diverse AGC algorithms. We demonstrate that methods previously limited to small graphs can be scaled to 111 million nodes with promising performance, paving the way for industrial adoption. From Supervised Metric to Holistic Evaluation: We advocate for holistic evaluation protocol that prioritizes practical utility. In addition to traditional supervised metrics, we mandate the reporting of unsupervised structural metrics (Modularity [31], Conductance [15]) to assess intrinsic cluster quality in the absence of labels. Furthermore, we introduce comprehensive efficiency profiling, tracking training time, inference latency, and memory consumption. Unified, Scalable, and Reproducible Framework: We release PyAGC, modular PyTorch-based library that unifies data processing, model initialization, and evaluation. Crucially, PyAGC refactors state-of-the-art AGC algorithms into efficient minibatch implementations, enabling the training of deep clustering models on graphs with over 111 million nodes in under 2 hours on single 32GB V100 GPU. By addressing these challenges, this benchmark serves as bridge between academic innovation and industrial application, setting new standard for the evaluation of Attributed Graph Clustering."
        },
        {
            "title": "2 Preliminaries\nIn this section, we formalize the problem of Attributed Graph Clus-\ntering and introduce the Encode-Cluster-Optimize framework. This\nunified taxonomy allows us to systematically categorize the di-\nverse methodologies evaluated in this benchmark, dissecting them\ninto composable components to better understand their behaviors\nacross varying scales and domains.",
            "content": "Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering Conference acronym XX, June 0305, 2018, Woodstock, NY Figure 1: Overview of our benchmark. It unifies (1) diverse data atlas spanning academic and industrial domains, (2) the modular Encode-Cluster-Optimize methodology with memory-efficient mini-batch support, and (3) holistic evaluation protocol covering supervised alignment, structural quality, and efficiency."
        },
        {
            "title": "2.1 Problem Formalization\nLet G = (V, E, ùëø ) denote an attributed graph, where V = {ùë£1, . . . , ùë£ùëÅ }\nis the set of ùëÅ nodes, and E ‚äÜ V√óV is the set of edges. The topolog-\nical structure is represented by an adjacency matrix ùë® ‚àà {0, 1}ùëÅ √óùëÅ ,\nwhere ùë®ùëñ ùëó = 1 if (ùë£ùëñ, ùë£ ùëó ) ‚àà E and 0 otherwise. Each node ùë£ùëñ is asso-\nciated with a ùê∑-dimensional feature vector ùíôùëñ ‚àà Rùê∑ , collectively\nforming the attribute matrix ùëø ‚àà RùëÅ √óùê∑ . Graph homophily [27] can\nbe measured by edge homophily Hùëí (the proportion of edges that\nconnect two nodes in the same class) and node homophily Hùëõ (the\naverage proportion of edge-label consistency of all nodes).",
            "content": "The goal of attributed graph clustering is to partition the node set into ùêæ disjoint clusters = {ùê∂1, . . . , ùê∂ùêæ }, such that nodes within the same cluster exhibit high similarity in terms of both structural connectivity and attribute information, without the guidance of ground-truth labels. Formally, the task is to learn mapping function : (ùë®, ùëø ) RùëÅ ùêæ that assigns each node to cluster, often represented by soft assignment matrix ùë∑ [0, 1]ùëÅ ùêæ where ùë∑ ùëñùëò represents the probability of node ùë£ùëñ belonging to cluster ùê∂ùëò ."
        },
        {
            "title": "2.2 The Encode-Cluster-Optimize Framework\nTo organize the disparate landscape of AGC algorithms, we unify\nthem under the Encode-Cluster-Optimize (ECO) framework,\nwhich decomposes the clustering process into three distinct mod-\nules: Representation Encoding, Cluster Projection, and Optimiza-\ntion Strategy. Table 5 provides a detailed classification of represen-\ntative methods within this framework.",
            "content": "The Representation Encoding Module (E). The encoder is responsible for fusing structural topology and node attributes into latent representation space ùíÅ RùëÅ ùêª : ùíÅ = (ùë®, ùëø ; ŒòE ), where ŒòE denotes the learnable parameters. Existing methods diverge in their parameterization of E: Parametric Encoders: Typically instantiated as graph neural networks such as GCN [14] or GAT [35]. These models learn complex non-linear mappings by fusing topology and attributes via message passing [6, 21, 38]. (1) Non-Parametric Encoders: These involve fixed filtering operations that smooth features over the graph topology without training weights, such as low-pass graph filters or adaptive smoothing [16, 47, 48]. In this case, ŒòE = . The Cluster Projection Module (C). The clusterer transforms the latent embeddings ùíÅ into cluster assignment matrix ùë∑ RùëÅ ùêæ , representing either soft probabilities or hard partitions: (2) ùë∑ = C(ùíÅ ; ŒòC). Based on the differentiability of this mapping, which dictates the feasibility of end-to-end optimization, we categorize clustering mechanisms into two fundamental paradigms: Differentiable Projection: This category treats clustering as differentiable layer within neural network, allowing gradients to flow from the loss back to the encoder. It encompasses discriminative approaches [4, 34] that use Softmax-activated MLPs/GNNs to output probabilities directly, and prototypical approaches [22, 38] that compute soft assignments via differentiable kernels (e.g., Students ùë°-distribution [41]) over learnable prototypes. Conference acronym XX, June 0305, 2018, Woodstock, NY Yunhui Liu et al. Discrete / Post-hoc Projection: This category applies discrete clustering algorithm to the fixed representations generated by the encoder. Since the mapping is non-differentiable, the clustering process is decoupled from representation learning. Common instantiations include KMeans [17, 21], Spectral Clustering [18, 48], and Subspace Clustering [7, 16]. The Optimization Strategy (O). The optimization strategy defines the objective function and the interaction between encoding ŒòE and clustering ŒòC. The general objective is formulated as: min ŒòE,ŒòC Ltotal = Lrep (ùë®, ùëø, ùíÅ ) + ùúÜLclust (ùë∑, ùë®). (3) where Lrep supervises the quality of embeddings (e.g., via graph reconstruction [11, 13] or contrastive loss [17, 21]) and Lclust enforces clustering structure (e.g., KL divergence [41], Modularity maximization [34], or Dilation+Shrink [22]). Crucially, the coordination of these components defines two distinct training paradigms: Decoupled Training: The encoder is pre-trained using only the self-supervised objective Lrep, followed by disjoint application of the post-hoc clusterer [17, 21, 25]. Joint Training: The encoder and clusterer are optimized end-toend [22, 34, 38]. The clustering objective Lclust provides supervisory signals to refine the embeddings."
        },
        {
            "title": "2.3 Scalable Optimization via Mini-Batching\nA critical contribution of this benchmark is evaluating the transition\nfrom full-batch to mini-batch training to support industrial-scale\ngraphs. Standard deep AGC methods [17, 37, 38] often requires full-\ngraph processing, incurring ùëÇ (ùëÅ 2) or ùëÇ (|E |) memory complexity.\nIn the ECO framework, we formalize the scalable adaptation of these\nmethods via mini-batch sampling. The objective is approximated\nover a subgraph Gùêµ = (Vùêµ, Eùêµ) sampled from the full graph:",
            "content": "Ltotal EGùêµ [L (Gùêµ; ŒòE, ŒòC)]. (4) This formulation allows us to benchmark the trade-off between the approximation error introduced by sampling strategies (e.g., neighbor sampling, subgraph sampling) [9, 10] and the gains in computational throughput and memory efficiency, which are prerequisite for processing graphs with hundreds of millions of nodes."
        },
        {
            "title": "3.1 Modular Architecture\nPyAGC decouples the clustering lifecycle into interchangeable mod-\nules. This design allows researchers to rapidly prototype new meth-\nods by swapping components without rewriting the training loop:",
            "content": "Encoders (pyagc.encoders): This module houses the representation learning backbones. We follow [28] to provide optimized implementations of standard GNNs [10, 14, 35, 36] that support both full-batch processing for small graphs and neighborsampling-based mini-batching for massive graphs. We also support graph transformers [5, 40] implemented by PyTorch Geometric [8]. This allows any clustering head to be easily paired with varying backbones without code duplication. Clusters (pyagc.clusters): We refactor clustering mechanisms into standalone Cluster Heads. Whether it is the differentiable pooling [4, 34], the prototypical assignment [22, 38], or the discrete partitioning [29], each module inherits from base class ensuring consistent input/output interfaces. This abstraction allows single encoder to be easily paired with different clustering mechanisms to isolate performance gains. Models (pyagc.models): The high-level model classes orchestrate the interaction between the encoder and the cluster head. They define the optimization strategy, managing the forward pass and the computation of joint losses (e.g., reconstruction loss + clustering loss). This design facilitates plug-and-play experimentation; for instance, swapping GCN encoder for GAT within the DAEGC framework requires changing single line in the configuration file. Unified Evaluation: PyAGC integrates data processing, metric computation, and experiment management. It provides unified data loaders and graph augmentations, alongside an optimized suite of label-based and structural metrics. All experiments are strictly configuration-driven via YAML files, decoupling hyperparameters from implementation to ensure full reproducibility and seamless transition between different graph datasets."
        },
        {
            "title": "3.2 Engineering for Efficiency\nTo mitigate the computational barriers of deep graph clustering,\nPyAGC incorporates two critical design optimizations targeting\nspeed and memory efficiency:",
            "content": "1. GPU-Accelerated Clustering: Standard CPU-based implementations (e.g., Sklearn) of KMeans are strictly single-threaded and become prohibitively slow when ùëÅ > 106. To resolve this, we implement GPU-accelerated clustering modules using PyTorch and OpenAI Triton1, which achieve multi-fold speedups over CPU counterparts, enabling faster clustering during training or testing. 2. Mini-Batch Training Protocol: We refactor full-batch algorithms (e.g., DAEGC, NS4GC) into mini-batch compatible versions. By utilizing neighbor sampling and subgraph-based objective approximations, PyAGC decouples GPU memory consumption from graph size. This optimization allows complex models to be trained on the massive Papers100M dataset (111M nodes) on single 32GB GPU, breaking the scalability ceiling of prior benchmarks."
        },
        {
            "title": "4 Benchmark Setup\n4.1 Dataset Curation\nTo provide a rigorous and comprehensive evaluation, we curate a\ndiverse collection of 12 attributed graph datasets, summarized in\nTable 4. Our selection criteria move beyond the traditional \"Cora-\ncentric\" paradigm, deliberately incorporating large-scale graphs\nfrom the Open Graph Benchmark [12] and industrial graphs from\nthe recent GraphLand benchmark [1]. We provide detailed dataset",
            "content": "1https://github.com/triton-lang/triton Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering Conference acronym XX, June 0305, 2018, Woodstock, NY descriptions in Appendix A. The dataset collection is characterized by four core dimensions of diversity: Scale Diversity. Recognizing existing benchmarks often cap at ùëÅ 105, our atlas spans five orders of magnitude. While we include canonical Tiny benchmarks like Cora and Photo for sanity checking, the core of our benchmark focuses on Medium to Large productionscale graphs (105 ùëÅ < 107) such as Reddit and WebTopic. The collection culminates in the Massive Papers100M dataset, which contains over 111 million nodes and 1.6 billion edges. This hierarchy serves as the ultimate stress test for mini-batching strategies, allowing us to evaluate the transition from memory-intensive full-batch methods to industrial-grade scalable implementations. Attribute Diversity. critical gap in existing AGC research is the over-reliance on textual graphs, where features are clean bag-ofwords or sentence embeddings. However, industrial nodes are frequently described by tabular metadata consisting of heterogeneous categorical and numerical features. Our benchmark introduces tabular graphs HM, Pokec, and WebTopic [1]. These present unique challenge as tabular distributions are often skewed, multi-modal, and noise-heavy. Unlike textual graphs where language models provide common latent space, tabular graphs require models to handle arbitrary feature types and distributions, reflecting the true complexity of real-world tabular metadata (e.g., user demographics and transaction counts). Structural Diversity. While classical benchmark datasets provide essential environments for method testing, industrial graphs often exhibit distinct topological profiles that extend the requirements for model robustness. Our atlas captures broad homophily-heterophily spectrum: while classic datasets often display high homophily (e.g., Physics, edge homophily Hùëí = 0.93), industrial graphs like HM and WebTopic are characterized by heterophilous patterns (Hùëí < 0.25), where edges frequently bridge nodes from different latent clusters. Furthermore, we account for varying levels of structural density; the benchmark spans from sparse citation graphs (e.g., ArXiv, Avg. Deg. 6.9) to the dense, high-order connectivity found in co-purchase networks (e.g., HM, Avg. Deg. 460.9). These diverse structural regimes ensure that AGC models are tested for their ability to combat oversmoothing in sparse, homophilous settings while effectively identifying latent structures in dense, heterophilous, and potentially noisy industrial topologies. Domain Diversity. By integrating industrial data, we extend the evaluation domain from narrow Citation and Co-author networks to E-commerce (Products, HM), Social Networks (Reddit, Pokec, Flickr), and the Web Graph (WebTopic). This ensures that the discovered insights are not domain-specific but are generalizable to the broader ecosystem of graph machine learning applications where ground-truth clusters are intrinsically tied to specific industrial behaviors like fraud, co-purchasing, or user navigation. GAE [13], DGI [37], CCASSG [46], S3GC [6], NS4GC [17] and MAGI [21]; 4) Deep Joint Methods: DAEGC [38], DinkNet [22], MinCut [3], DMoN [34], and Neuromap [4]. Table 5 provides detailed classification of these methods within the ECO framework, while more detailed descriptions are presented in Appendix B. Scalable Adaptation. major contribution of this benchmark is the refactoring of these representative algorithms. For Medium, Large, and Massive datasets, standard implementations result in Out-Of-Memory errors. We re-implement all deep learning algorithms within PyAGC to support neighbor sampling and mini-batch training, allowing methods like DAEGC to run on 100M+ node graphs for the first time."
        },
        {
            "title": "4.3 Holistic Evaluation Protocol\nTo rectify the Supervised Metric Paradox and Scalability Bottleneck,\nwe institute a multi-view evaluation protocol comprising supervised\nalignment, unsupervised quality, and computational efficiency:",
            "content": "Supervised Alignment Metrics. To maintain backward compatibility with existing literature, we report Accuracy (ACC), MacroF1 Score (F1), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI). These metrics measure how well the discovered clusters align with human-annotated labels. However, we explicitly warn that on industrial datasets (e.g., WebTopic), ground truth labels often represent only one specific view (e.g., website topic) of multi-faceted entity, and low ACC does not necessarily imply poor structural clustering. Unsupervised Structural Metrics. Recognizing that real-world clustering is often label-free, we mandate the reporting of structural metrics to assess the intrinsic quality of the partition = {ùê∂1, . . . , ùê∂ùêæ }. These metrics evaluate the community structure based purely on topological connectivity: Modularity (Q) [31]: Measures the strength of the division of network into communities. It compares the density of edges within clusters to the expected density in random graph with the same degree distribution: = 1 2E (cid:18) ùëñ,ùëó ùë®ùëñ ùëó (cid:19) ùëëùëñùëë ùëó 2E ùõø (ùëêùëñ, ùëê ùëó ) (5) where is the total number of edges, ùëëùëñ is the degree of node ùë£ùëñ , ùëêùëñ is the cluster assignment of node ùë£ùëñ , and ùõø (ùëêùëñ, ùëê ùëó ) = 1 if ùë£ùëñ and ùë£ ùëó are in the same cluster. Higher modularity indicates stronger community structure. Conductance (K) [15]: Measures the separability of clusters by quantifying the fraction of total edge volume that points outside the cluster. We report the average conductance over all ùêæ clusters: = 1 ùêæ ùêæ ùëò=1 ùëêùê∂ùëò 2ùëöùê∂ùëò + ùëêùê∂ùëò (6)"
        },
        {
            "title": "4.2 Evaluated Representative Algorithms\nWe evaluate a comprehensive suite of 17 representative AGC meth-\nods, selected to cover the entire spectrum of the ECO framework: 1)\nTraditional Methods: attribute-only KMeans [29] and structure-\nonly Node2Vec [9]; 2) Non-Parametric Methods: SSGC [49],\nSAGSC [7] and MS2CAG [16]; 3) Deep Decoupled Methods:",
            "content": "where for given cluster ùê∂ùëò , ùëêùê∂ùëò = {(ùë¢, ùë£) : ùë¢ ùê∂ùëò, ùë£ ùê∂ùëò } represents the number of edges on the boundary (cut size), and ùëöùê∂ùëò = {(ùë¢, ùë£) : ùë¢ ùê∂ùëò, ùë£ ùê∂ùëò } represents the number of effectively represents internal edges. The denominator 2ùëöùê∂ùëò +ùëêùê∂ùëò the total volume (sum of degrees) of nodes in set ùê∂ùëò . Lower conductance implies better isolation of communities. Conference acronym XX, June 0305, 2018, Woodstock, NY Yunhui Liu et al. Table 1: Clustering performance comparison measured by NMI and ACC (%) (Mean SD). The best and second-best results are highlighted. \"\" denotes OOM errors as these methods strictly require full-graph processing. Model Metric Tiny o d c e a - d u D D o e KMeans Node2Vec SSGC SAGSC MS2CAG GAE DGI CCASSG S3GC NS4GC MAGI DAEGC DinkNet MinCut DMoN Neuromap NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC NMI ACC Cora 13.894.46 33.094.00 44.951.49 60.522.81 51.851.05 65.381.47 44.350.06 63.450. 53.640.64 70.290.66 50.090.07 67.530.13 56.220.87 72.222.92 58.740.87 73.351.92 55.451.12 70.331.98 59.400.48 74.920.59 58.940.41 74.220. 46.881.71 64.063.18 55.560.18 72.490.50 40.801.83 52.956.65 43.842.29 52.994.70 46.982.61 56.963.98 Photo 31.700.49 42.542. 66.021.05 73.081.06 70.751.39 76.344.04 58.400.02 67.910.01 72.490.79 79.130.05 61.360.14 71.540.08 67.770.54 77.570. 64.543.23 70.902.27 68.272.22 75.923.26 72.620.79 79.210.03 68.650.16 76.660.18 63.600.02 77.780.01 64.740.06 74.030.25 62.342.39 69.462. 62.742.67 72.681.87 61.842.34 71.894.19 Physics 52.000.13 53.410.13 54.940.01 57.550.01 64.494.20 65.0412.1 55.950.04 60.150. 72.450.03 90.450.04 68.150.03 84.990.05 74.390.35 89.870.32 70.940.04 87.570.05 70.870.05 87.300.05 75.380.08 90.150.07 66.080.13 62.820. 57.040.03 58.110.06 57.340.06 55.670.26 56.942.06 54.962.46 58.300.37 57.870.34 56.531.63 55.002.32 Small HM 10.170.11 14.120.25 7.600.13 13.280.41 12.150.11 15.570.07 12.470.13 17.830.11 9.750.36 15.060.28 13.580.12 16.580. 11.670.06 15.780.32 11.930.15 15.780.14 11.570.08 16.490.22 15.280.17 18.400.42 11.240.46 18.490.83 11.460.09 17.370.31 11.260.06 15.790. 7.420.37 13.870.43 7.590.92 12.320.58 7.440.17 12.730.25 Flickr 1.210.07 26.021.73 5.590.00 24.440.01 4.480.19 25.950. 6.860.00 26.720.01 7.320.02 28.290.06 4.070.05 38.421.07 6.880.01 24.920.17 4.670.01 23.030.35 7.840.00 28.480.00 6.190.01 24.270. 6.310.16 24.280.46 4.230.03 28.510.35 6.670.05 29.940.38 7.590.19 27.641.87 7.890.09 28.640.69 7.770.57 28.862. ArXiv 22.590.03 16.950.38 38.930.15 25.970.57 46.120.16 38.580.56 43.270.19 30.870.83 44.200.18 35.850.21 40.860.15 24.390. 42.290.08 30.490.64 44.690.04 30.680.27 47.110.12 35.570.60 48.390.24 39.011.07 46.530.16 37.320.74 39.810.29 28.680.64 37.240.57 25.470. 39.001.02 27.881.20 38.770.28 25.891.12 40.700.80 33.311.07 Medium Reddit 11.080.14 8.590.06 79.230.38 70.671. 51.610.36 40.001.79 80.020.38 72.791.57 72.850.53 60.402.40 45.900.27 34.560.81 72.930.14 62.520.34 49.630.07 37.910. 83.450.39 81.861.59 56.710.05 43.800.52 72.530.19 64.781.38 40.840.76 27.570.33 54.950.24 38.510.82 48.853.58 34.092.08 50.660.38 39.291. 47.810.28 32.640.20 MAG 28.320.06 7.090.03 37.730.03 10.860.09 41.520.04 11.890.10 40.150.03 11.900.16 40.390.07 11.700. 39.300.03 11.210.07 39.390.03 10.600.11 40.400.02 11.900.05 39.800.03 12.150.05 41.640.01 13.280.09 41.340.02 13.250. 29.002.17 10.830.51 37.120.05 10.140.08 38.210.12 11.600.32 38.300.12 10.810.08 39.140.20 15.950.32 Pokec 1.410.00 1.910. 31.920.02 16.620.19 4.330.01 2.930.04 38.330.03 19.860.23 2.770.05 2.270.09 3.790.04 2.490.02 4.200.01 2.230.02 1.350.01 1.950. 6.040.00 2.970.03 7.190.04 3.190.01 8.760.02 3.900.03 3.850.21 3.990.03 3.910.01 2.730.04 5.780.18 3.170. 8.420.08 4.400.07 8.530.25 5.120.21 Large Products WebTop. 2.450.05 29.240.11 9.630.34 21.230.74 50.970.20 36.590.74 52.040.17 37.020. 51.780.24 38.110.69 50.710.31 35.410.62 42.550.09 27.700.43 41.280.13 28.990.52 50.890.31 37.990.42 53.430.16 40.450. 54.630.14 41.830.40 44.580.14 33.150.34 9.183.05 14.832.09 38.430.18 26.780.37 35.800.71 24.880.74 34.800.85 25.401.37 34.801.46 31.871. 5.800.09 10.710.12 3.920.11 11.340.18 9.110.26 13.660.53 7.770.08 12.380.12 3.890.14 11.860.06 5.910.02 11.690. 3.790.18 11.650.91 7.830.02 12.750.07 10.050.04 15.690.14 9.270.20 14.370.76 4.790.29 16.420.61 5.470.04 11.520. 6.070.52 11.670.95 7.490.37 12.700.73 7.190.51 16.821.69 Massive Papers. 37.770.07 15.160.21 51.290.05 25.310.26 42.840.02 15.710.08 49.280.07 20.700.14 53.820.05 25.180.14 44.180.04 17.980. 49.830.04 22.520.16 53.060.04 24.610.13 28.590.06 16.660.35 45.860.04 18.630.25 Efficiency and Scalability Profiling. We mandate the reporting of the total training and clustering time and peak GPU memory consumption to provide practitioners with clear understanding of the trade-offs between model complexity and operational cost."
        },
        {
            "title": "4.4 Implementation Details",
            "content": "Hardware Environment. To ensure fair comparisons and demonstrate the accessibility of our benchmark to standard research laboratories, all experiments are conducted on Linux workstation equipped with an Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz, 480GB RAM, and single NVIDIA Tesla V100 (32GB) GPU. By restricting evaluation to single GPU, we stress-test the memory efficiency of the proposed mini-batch implementations, verifying that our scalable solutions are relevant to standard industrial and academic settings without reliance on massive multi-GPU clusters. Training Protocol. All deep learning methods are optimized using the Adam optimizer. To ensure statistical reliability and mitigate the impact of random initialization, we report the mean and standard deviation of all metrics across 5 independent runs with different random seeds. Regarding the massive Papers100M dataset, due to its prohibitive computational cost, we restrict the training of deep methods to single epoch. For all other datasets, models are trained until convergence or for fixed number of epochs. Reproducibility and Hyperparameters. To resolve the reproducibility crisis often observed in clustering research, we do not hard-code parameters. Instead, all specific hyperparameters (e.g., learning rate, encoder depth, hidden dimensions) are strictly managed via configuration files (YAML) located in each methods directory (e.g., benchmark/DMoN/train.conf.yaml). The code and resources are publicly available via GitHub, PyPI, and Docs."
        },
        {
            "title": "5 Benchmark Results\nIn this section, we present a comprehensive analysis of the 17 evalu-\nated methods across our 12 datasets. We aim to answer three critical\nquestions: (1) How well do current AGC methods generalize from\nacademic datasets to complex industrial graphs? (2) Do supervised\nmetrics (e.g., NMI) accurately reflect intrinsic clustering quality in",
            "content": "Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering Conference acronym XX, June 0305, 2018, Woodstock, NY Table 2: Clustering performance comparison measured by Modularity (Mod) and Conductance (Cond) (%) (Mean SD). The best and second-best results are highlighted. \"\" denotes OOM errors as these methods strictly require full-graph processing. Model Metric Tiny n i T t r - d u D D o e KMeans Node2Vec SSGC SAGSC MS2CAG GAE DGI CCASSG S3GC NS4GC MAGI DAEGC DinkNet MinCut DMoN Neuromap Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Mod Cond Cora 18.733.05 57.495.83 71.520.15 11.990.14 72.600.35 10.840.09 55.760.05 27.610.06 74.670.15 9.490.09 72.390.11 11.720. 71.490.28 12.430.78 73.460.42 10.180.22 74.490.07 9.120.20 75.080.25 8.490.12 71.190.06 12.310.05 73.450.62 11.080.65 72.260.16 11.470. 72.991.28 12.281.23 71.811.40 12.630.86 74.020.95 10.960.93 Photo 16.850.40 66.600.47 71.650.14 10.760.10 70.131.91 9.041.23 65.110.01 17.160. 71.080.05 10.110.08 66.940.17 15.270.27 64.990.37 18.241.07 68.541.69 13.242.12 71.040.07 9.440.22 71.400.01 9.120. 68.690.09 13.740.11 65.340.01 16.790.02 64.980.21 18.150.22 67.001.75 15.522.57 70.320.28 13.070.20 69.101.96 12.210. Physics 51.560.07 24.550.04 59.190.00 15.540.00 57.594.45 11.442.72 45.400.01 20.600.01 49.600.02 6.270.02 49.970.02 8.230. 48.440.09 6.800.11 49.120.03 6.910.02 49.720.01 6.640.01 48.940.01 5.610.01 60.530.19 13.630.12 61.950.02 14.350.01 60.920.06 15.080. 61.470.20 14.180.41 62.900.11 13.910.12 57.350.33 11.551.62 Small HM 2.840.05 90.800.42 -5.890.08 81.800. 4.850.03 69.420.33 -2.960.39 75.530.60 2.500.10 90.940.22 3.490.18 88.660.22 5.530.10 67.221.10 6.480.76 68.211. 11.140.30 64.030.90 5.110.19 85.630.38 -4.150.18 82.990.46 4.400.21 79.050.70 5.930.22 67.050.71 4.252.35 26.3814. 12.540.25 66.990.99 6.290.17 20.280.45 Flickr 0.900.08 74.780.69 41.930.01 40.240.01 20.860.30 60.130.44 24.730.03 57.190. 44.400.03 39.110.03 21.660.53 47.062.26 6.810.25 75.680.25 -4.170.46 85.640.10 39.960.01 45.300.01 -5.150.05 74.840.06 47.350.08 36.420.37 19.450.09 64.140. 4.370.52 69.020.98 29.504.82 49.401.61 37.170.74 46.190.82 34.352.98 47.552.23 ArXiv 13.230.31 83.620.38 55.480.56 39.800. 60.210.12 26.940.15 53.042.24 38.272.81 64.060.27 26.870.33 58.220.26 37.820.39 54.300.50 39.150.69 49.950.16 45.830.24 57.980.39 35.260. 62.370.27 29.250.67 61.710.23 30.040.34 62.650.18 33.130.24 31.870.36 62.350.47 61.801.08 32.051.30 61.141.19 33.530. 64.540.66 27.761.09 Medium Reddit 4.480.15 91.600.32 61.410.58 35.050.59 33.831.19 61.751.39 68.430.63 27.460. 48.581.89 47.722.04 36.960.35 58.480.32 62.190.27 33.440.39 37.920.34 57.980.39 70.941.25 24.451.41 41.980.14 54.280. 55.800.43 39.970.56 49.831.08 21.361.87 42.730.38 52.260.47 42.381.55 51.945.08 47.781.70 46.652.04 41.110.27 54.200.32 MAG 14.530.06 85.020. 45.080.26 54.420.28 64.640.07 34.610.05 70.880.31 28.430.34 63.420.41 35.980.42 54.260.22 45.070.23 56.430.48 42.760. 57.570.16 41.650.17 49.450.26 49.370.29 62.800.21 36.400.22 64.730.18 34.550.19 61.721.31 37.601.31 34.560.27 64.640. 68.970.25 30.220.28 69.580.15 29.770.14 Pokec 0.890.04 98.050.05 30.440.16 68.840.16 16.940.41 80.090.54 50.010.27 49.020. 3.540.17 95.760.19 11.660.07 85.780.08 6.650.04 92.400.03 0.840.00 98.340.01 13.530.15 85.140.16 15.980.09 82.720. 19.640.07 79.440.08 10.260.31 87.470.29 12.470.34 84.400.70 14.550.43 84.460.44 22.670.28 76.060.30 76.250.15 21.750. 31.710.56 65.390.65 Large Products WebTop. 0.560.19 28.880.28 90.760.35 67.920.40 77.170.66 20.230.66 80.580.16 16.410.11 84.560.17 12.620.19 83.800.14 13.580. 62.170.17 35.360.16 61.540.25 35.600.23 74.640.17 22.330.20 73.930.33 23.280.42 77.890.18 19.340.20 68.510.03 28.800. 35.593.73 58.713.05 59.750.25 36.490.34 73.380.30 24.170.30 68.350.53 28.760.43 70.590.43 23.490.52 3.240.12 69.740. 17.820.79 62.671.82 16.811.17 67.470.71 35.330.46 54.680.69 5.240.24 80.570.21 -1.070.44 88.340.23 0.760.71 88.460. 29.060.26 60.560.45 24.510.06 52.270.69 34.961.23 48.180.71 27.161.13 46.112.53 -2.340.28 92.270.05 24.861.25 50.802. 33.900.23 52.970.84 31.961.39 38.200.72 Massive Papers. 15.790.09 83.180.10 42.230.48 55.660.54 25.790.05 72.380.05 32.210.20 66.610.19 50.060.28 46.690.34 37.520.21 60.150.25 42.440.55 54.510. 47.630.61 49.310.78 41.130.57 52.171.94 32.510.43 65.100.48 label-scarce settings? (3) Can the proposed PyAGC library effectively scale deep clustering algorithms to massive graphs?"
        },
        {
            "title": "5.1 Generalization Gap: Academia vs. Industry\nTables 1 and 6 present the clustering performance measured by\nsupervised alignment metrics (NMI, ACC, ARI, F1). A compara-\ntive analysis reveals a stark dichotomy between performance on\ntraditional academic datasets and industrial-scale graphs.",
            "content": "The \"Cora\" Comfort Zone. On classic small-scale, high-homophily datasets (Cora, Photo, Physics), most methods achieve high performance. For instance, on Photo, simple baselines like Node2Vec and sophisticated methods like NS4GC both achieve NMI scores > 65%. This confirms that in clean, homophilous environments, structure and attributes are highly correlated, making the clustering task relatively trivial. Collapse on Industrial Graphs. Performance degrades largely when moving to industrial environments (HM, Pokec, WebTopic). On Pokec (a large social network), the best performing method (SAGSC) only achieves an NMI of 38.33%, while most deep learning methods (e.g., DAEGC, DGI) fail to surpass 5% NMI. This collapse is attributed to two factors: (1) Heterophily and Noise: Industrial graphs like HM (Hùëí = 0.16) are highly heterophilous. Methods relying on GNN encoders tend to over-smooth features across class boundaries, rendering the learned embeddings indistinguishable. (2) Tabular Complexity: Unlike the clean text features, the tabular features contain heterogeneous distributions and noise. Traditional KMeans and spectral filtering methods struggle to capture the complex dependencies in this feature space without learnable non-linear transformations. Robustness of Deep Decoupled Methods. Among the evaluated categories, Deep Decoupled methods (e.g., NS4GC, MAGI, S3GC) demonstrate the most consistent robustness. By separating representation learning from clustering, these methods benefit from stable self-supervised pre-training, avoiding the clustering collapse phenomenon often observed in joint training (where the clusterer forces the encoder into trivial solution). Conference acronym XX, June 0305, 2018, Woodstock, NY Yunhui Liu et al. Table 3: Efficiency profiling results for larger datasets. Mem: Peak GPU Memory, Time: Total Training and Clustering Time. Category Method Reddit MAG Pokec Products WebTopic Papers100M Mem(GB) Time(m) Mem(GB) Time(m) Mem(GB) Time(m) Mem(GB) Time(m) Mem(GB) Time(m) Mem(GB) Time(h) Traditional NonParametric Deep Decoupled Deep Joint KMeans Node2Vec SSGC SAGSC MS2CAG GAE DGI CCASSG S3GC NS4GC MAGI DAEGC DinkNet MinCut DMoN Neuromap - 0.70 - - - 14.18 24.16 27.50 2.82 10.90 20.41 31.20 24.16 18.56 18.56 18.57 0.27 22.67 5.36 5.99 0. 30.58 1.93 1.21 32.38 12.84 56.98 14.28 4.49 6.73 1.22 6.73 - 1.90 - - - 10.16 22.46 28.64 5.12 17.71 30.77 26.18 23.66 18.16 18.16 18. 6.59 77.58 6.51 23.35 15.10 26.54 10.54 31.14 41.78 41.04 86.99 27.52 5.46 16.01 15.46 14.56 - 4.04 - - - 27.97 30.90 30.75 9.01 30.12 21.44 30.90 24.84 19.32 19.32 19.32 3.09 236.53 4.43 4.72 13.68 10.16 10.37 117.43 71.17 55.88 176.43 14.28 6.18 24.15 22.91 23. - 15.05 - - - 13.33 29.52 30.30 29.46 24.10 31.08 15.37 30.63 30.14 30.14 24.50 5.87 64.94 8.05 5.29 1. 26.12 50.32 45.16 29.68 37.24 375.99 37.28 85.27 32.55 22.88 23.00 - 11.80 - - - 1.63 8.96 6.16 18.98 8.95 5.23 11.71 29.98 28.27 28.27 28. 3.98 75.92 10.38 2.77 16.81 6.18 6.16 122.30 145.98 30.75 115.36 11.11 4.27 8.37 6.75 4.97 - 7.20 - - - 7.58 30.89 31.09 15.85 13.97 29.28 15.96 31.11 - - - 0.05 12.38 - - - 0.67 2.42 1.29 5.85 1.24 6.04 1.40 5.13 - - -"
        },
        {
            "title": "5.2 The Metric Paradox: Labels vs. Structure\nA core premise of this benchmark is that supervised metrics are\ninsufficient for evaluating unsupervised graph clustering. Table 2\n(Modularity and Conductance) highlights the disconnect between\nstructural quality and label alignment.",
            "content": "Structure vs. Semantics Misalignment. We observe instances where supervised metrics and structural metrics diverge. For example, on Products, SAGSC achieves the highest Modularity (84.56%) and lowest Conductance (12.62%), indicating it finds extremely dense, well-separated communities. However, its NMI (51.78%) is lower than NS4GC (54.63%). This highlights critical nuance: ground-truth labels do not always reflect topological communities. In practical applications like fraud detection, partition with high modularity (isolating dense cliques) may be more valuable than one aligning with broad semantic labels. Failure Modes in Heterophily. On the highly heterophilous HM dataset (Hùëí = 0.16), standard GNN methods yield low or even negative Modularity scores, implying they fail to detect non-trivial community structures. Interestingly, DMoN, which directly optimizes spectral modularity objective, achieves the highest structural quality (Q = 12.54%), despite having mediocre supervised scores. This underscores the necessity of including structural metrics in evaluation; relying solely on Accuracy would mask DMoNs utility in detecting latent structure in label-poor environments."
        },
        {
            "title": "5.3 Scalability and Efficiency Profiling\nFinally, we analyze the computational efficiency of these methods,\nenabled by the PyAGC mini-batch framework. Tables 7 and 3 detail\npeak memory usage and total runtime.",
            "content": "Breaking the Memory Wall. Standard implementations of methods like DAEGC or NS4GC typically scale quadratically or require the full adjacency matrix, making them infeasible for graphs larger than Physics. Our mini-batch implementations clamp GPU memory usage effectively. As shown in Table 3, training NS4GC on Papers100M consumes only 14GB of GPU memory, well within the limits of standard V100 (32GB), whereas the full-batch equivalent would require terabytes of RAM. Training Throughput. PyAGC achieves production-grade throughput. We successfully train deep clustering models on Papers100M (111M nodes) in remarkably short windows: GAE completes an epoch in 0.67 hours, and contrastive methods like NS4GC take 1.24 hours. This proves that deep graph clustering is no longer limited to toy datasets and is ready for high-frequency industrial retraining cycles. Among deep joint methods, DMoN and Neuromap are particularly efficient due to their compact matrix formulations, processing WebTopic in under 7 minutes. Trade-offs. Non-parametric methods like MS2CAG are extremely fast on medium datasets (0.16 min on Reddit) but hit hard scalability wall on Massive graphs. Conversely, deep mini-batch methods incur time overhead due to sampling and data loading but offer linear scalability to virtually infinite graph sizes. This distinction allows practitioners to choose the right tool: non-parametric solvers for rapid prototyping on medium graphs, and PyAGC mini-batch deep models for massive-scale deployment."
        },
        {
            "title": "6 Conclusion and Future Work\nIn this work, we bridged the widening chasm between academic\nresearch and industrial application in AGC. We introduced PyAGC,\na production-ready benchmark library that systematizes the field\nunder the Encode-Cluster-Optimize framework and democratizes\naccess to massive-scale evaluations. Our rigorous benchmarking\nacross 12 datasets and 17 representative algorithms yields three\ncritical insights. Looking forward, PyAGC opens several avenues\nfor future research. The community must move beyond the \"Cora-\nverse\" to develop robust encoders that can handle heterophily and\ntabular noise without over-smoothing. Furthermore, as industrial\napplications are often label-scarce, developing reliable unsuper-\nvised model selection criteria remains an urgent open problem.\nBy releasing this benchmark, we invite researchers to test their\nmethods against the realities of scale and complexity, ultimately\nadvancing AGC towards reliable, high-stakes deployment.",
            "content": "Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering Conference acronym XX, June 0305, 2018, Woodstock, NY Acknowledgments This work was supported by the National Science and Technology Major Project (2026ZD16011200), National Key Research and Development Plan of China (2023YFB4502305), National Natural Science Foundation of China (62306137), and the Ant Group Research Intern Program. References [1] Gleb Bazhenov, Oleg Platonov, and Liudmila Prokhorenkova. 2025. GraphLand: Evaluating Graph Machine Learning Models on Diverse Industrial Data. In The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track. [2] Maya Bechler-Speicher, Ben Finkelshtein, Fabrizio Frasca, Luis M√ºller, Jan T√∂nshoff, Antoine Siraudin, Viktor Zaverkin, Michael M. Bronstein, Mathias Niepert, Bryan Perozzi, Mikhail Galkin, and Christopher Morris. 2025. Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks. In Forty-second International Conference on Machine Learning Position Paper Track. [3] Filippo Maria Bianchi, Daniele Grattarola, and Cesare Alippi. 2020. Spectral clustering with graph neural networks for graph pooling. In International conference on machine learning. PMLR, 874883. [4] Christopher Bl√∂cker, Chester Tan, and Ingo Scholtes. 2024. The map equation goes neural: Mapping network flows with graph neural networks. Advances in Neural Information Processing Systems 37 (2024), 1742817456. [5] Chenhui Deng, Zichao Yue, and Zhiru Zhang. 2024. Polynormer: PolynomialExpressive Graph Transformer in Linear Time. In The Twelfth International Conference on Learning Representations. [6] Fnu Devvrit, Aditya Sinha, Inderjit Dhillon, and Prateek Jain. 2022. S3GC: Scalable self-supervised graph clustering. Advances in Neural Information Processing Systems 35 (2022), 32483261. [7] Chakib Fettal, Lazhar Labiod, and Mohamed Nadif. 2023. Scalable attributedgraph subspace clustering. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 37. 75597567. [8] Matthias Fey, Jinu Sunil, Akihiro Nitta, Rishi Puri, Manan Shah, Bla≈æ Stojanoviƒç, Ramona Bendias, Alexandria Barghi, Vid Kocijan, Zecheng Zhang, et al. 2025. PyG 2.0: Scalable Learning on Real World Graphs. arXiv preprint arXiv:2507.16991 (2025). [9] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 855864. [10] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. Advances in neural information processing systems 30 (2017). [11] Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang, and Jie Tang. 2022. Graphmae: Self-supervised masked graph autoencoders. In Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining. 594604. [12] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. 2020. Open graph benchmark: Datasets for machine learning on graphs. Advances in neural information processing systems 33 (2020), 2211822133. [13] Thomas Kipf and Max Welling. 2016. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308 (2016). [14] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In International Conference on Learning Representations. [15] Jure Leskovec, Kevin Lang, Anirban Dasgupta, and Michael Mahoney. 2008. Statistical properties of community structure in large social and information networks. In Proceedings of the 17th international conference on World Wide Web. 695704. [16] Xiaoyang Lin, Renchi Yang, Haoran Zheng, and Xiangyu Ke. 2025. Spectral Subspace Clustering for Attributed Graphs. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 1. 789799. [17] Yunhui Liu, Xinyi Gao, Tieke He, Tao Zheng, Jianhua Zhao, and Hongzhi Yin. 2024. Reliable node similarity matrix guided contrastive graph clustering. IEEE Transactions on Knowledge and Data Engineering (2024). [18] Yunhui Liu, Tieke He, Qing Wu, Tao Zheng, and Jianhua Zhao. 2024. Scalable and Adaptive Spectral Embedding for Attributed Graph Clustering. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. 39123916. [19] Yunhui Liu, Tieke He, Tao Zheng, and Jianhua Zhao. 2025. Negative-free selfsupervised gaussian embedding of graphs. Neural Networks 181 (2025), 106846. [20] Yixin Liu, Ming Jin, Shirui Pan, Chuan Zhou, Yu Zheng, Feng Xia, and Philip S. Yu. 2023. Graph Self-Supervised Learning: Survey. IEEE Transactions on Knowledge and Data Engineering 35, 6 (2023), 58795900. [21] Yunfei Liu, Jintang Li, Yuehe Chen, Ruofan Wu, Ericbk Wang, Jing Zhou, Sheng Tian, Shuheng Shen, Xing Fu, Changhua Meng, et al. 2024. Revisiting modularity maximization for graph clustering: contrastive learning perspective. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 19681979. [22] Yue Liu, Ke Liang, Jun Xia, Sihang Zhou, Xihong Yang, Xinwang Liu, and Stan Li. 2023. Dink-net: Neural clustering on large graphs. In International conference on machine learning. PMLR, 2179421812. [23] Yue Liu, Wenxuan Tu, Sihang Zhou, Xinwang Liu, Linxuan Song, Xihong Yang, and En Zhu. 2022. Deep graph clustering via dual correlation reduction. In Proceedings of the AAAI conference on artificial intelligence, Vol. 36. 76037611. [24] Yue Liu, Jun Xia, Sihang Zhou, Xihong Yang, Ke Liang, Chenchen Fan, Yan Zhuang, Stan Z. Li, Xinwang Liu, and Kunlun He. 2023. Survey of Deep Graph Clustering: Taxonomy, Challenge, Application, and Open Resource. arXiv:2211.12875 [25] Yunhui Liu, Huaisong Zhang, Tieke He, Tao Zheng, and Jianhua Zhao. 2024. Bootstrap Latents of Nodes and Neighbors for Graph Self-Supervised Learning. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer. [26] Yue Liu, Shihao Zhu, Jun Xia, Yingwei Ma, Jian Ma, Xinwang Liu, Shengju Yu, Kejun Zhang, and Wenliang Zhong. 2024. End-to-end learnable clustering for intent learning in recommendation. Advances in Neural Information Processing Systems 37 (2024), 59135949. [27] Sitao Luan, Chenqing Hua, Qincheng Lu, Jiaqi Zhu, Mingde Zhao, Shuyuan Zhang, Xiao-Wen Chang, and Doina Precup. 2022. Revisiting heterophily for graph neural networks. Advances in neural information processing systems 35 (2022), 13621375. [28] Yuankai Luo, Lei Shi, and Xiao-Ming Wu. 2024. Classic gnns are strong baselines: Reassessing gnns for node classification. Advances in Neural Information Processing Systems 37 (2024), 9765097669. [29] James McQueen. 1967. Some methods of classification and analysis of multivariate observations. In Proc. of 5th Berkeley Symposium on Math. Stat. and Prob. 281297. [30] Nairouz Mrabah, Mohamed Bouguessa, Mohamed Fawzi Touati, and Riadh Ksantini. 2023. Rethinking Graph Auto-Encoder Models for Attributed Graph Clustering. IEEE Transactions on Knowledge and Data Engineering 35, 9 (2023), 90379053. [31] Mark EJ Newman. 2006. Modularity and community structure in networks. Proceedings of the national academy of sciences 103, 23 (2006), 85778582. [32] Namyong Park, Ryan Rossi, Eunyee Koh, Iftikhar Ahamath Burhanuddin, Sungchul Kim, Fan Du, Nesreen Ahmed, and Christos Faloutsos. 2022. CGC: Contrastive graph clustering forcommunity detection and tracking. In Proceedings of the ACM Web Conference 2022. 11151126. [33] Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan G√ºnnemann. 2018. Pitfalls of Graph Neural Network Evaluation. ArXiv abs/1811.05868 (2018). [34] Anton Tsitsulin, John Palowitch, Bryan Perozzi, and Emmanuel M√ºller. 2023. Graph clustering with graph neural networks. Journal of Machine Learning Research 24, 127 (2023), 121. [35] Petar Veliƒçkoviƒá, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li√≤, and Yoshua Bengio. 2018. Graph Attention Networks. In International Conference on Learning Representations. [36] Petar Veliƒçkoviƒá, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li√≤, and Yoshua Bengio. 2019. How Powerful are Graph Neural Networks?. In International Conference on Learning Representations. [37] Petar Veliƒçkoviƒá, William Fedus, William L. Hamilton, Pietro Li√≤, Yoshua Bengio, and Devon Hjelm. 2019. Deep Graph Infomax. In International Conference on Learning Representations. [38] Chun Wang, Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019. Attributed Graph Clustering: Deep Attentional Embedding Approach. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI19). 36703676. [39] Benyu Wu, Yue Liu, Qiaoyu Tan, Xinwang Liu, Wei Du, Jun Wang, and Guoxian Yu. 2025. DGCBench: Deep Graph Clustering Benchmark. In The Thirtyninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track. [40] Qitian Wu, Wentao Zhao, Chenxiao Yang, Hengrui Zhang, Fan Nie, Haitian Jiang, Yatao Bian, and Junchi Yan. 2023. SGFormer: Simplifying and empowering transformers for large-graph representations. Advances in Neural Information Processing Systems 36 (2023), 6475364773. [41] Junyuan Xie, Ross Girshick, and Ali Farhadi. 2016. Unsupervised deep embedding for clustering analysis. In International conference on machine learning. PMLR, 478487. [42] Jaewon Yang and Jure Leskovec. 2015. Defining and evaluating network communities based on ground-truth. Knowledge and Information Systems 42, 1 (2015), 181213. [43] Renchi Yang and Jieming Shi. 2024. Efficient high-quality clustering for large bipartite graphs. Proceedings of the ACM on Management of Data 2, 1 (2024), 127. Conference acronym XX, June 0305, 2018, Woodstock, NY Yunhui Liu et al. [44] Jianke Yu, Hanchen Wang, Xiaoyang Wang, Zhao Li, Lu Qin, Wenjie Zhang, Jian Liao, and Ying Zhang. 2023. Group-based fraud detection network on e-commerce platforms. In Proceedings of the 29th ACM SIGKDD conference on knowledge discovery and data mining. 54635475. [45] Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor Prasanna. 2020. GraphSAINT: Graph Sampling Based Inductive Learning Method. In International Conference on Learning Representations. [46] Hengrui Zhang, Qitian Wu, Junchi Yan, David Wipf, and Philip Yu. 2021. From Canonical Correlation Analysis to Self-supervised Graph Neural Networks. In Advances in Neural Information Processing Systems, Vol. 34. 7689. [47] Wentao Zhang, Zeang Sheng, Mingyu Yang, Yang Li, Yu Shen, Zhi Yang, and Bin Cui. 2022. NAFS: Simple yet Tough-to-beat Baseline for Graph Representation Learning. In International conference on machine learning. PMLR, 2646726483. [48] Xiaotong Zhang, Han Liu, Qimai Li, and Xiao-Ming Wu. 2019. Attributed graph clustering via adaptive graph convolution. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. 43274333. [49] Hao Zhu and Piotr Koniusz. 2020. Simple spectral graph convolution. In International conference on learning representations. Dataset Descriptions In this section, we provide detailed descriptions of the 12 datasets curated for our benchmark. To comprehensively evaluate AGC algorithms, we selected datasets spanning diverse domains (Citation, Co-purchase, Social, Web) and feature modalities (Textual, Tabular). The datasets are categorized by scale, corresponding to the taxonomy presented in Table 4. A.1 Tiny Scale Datasets (ùëÅ < 104) Cora [14]. This is standard citation network frequently used in graph clustering literature. Nodes represent machine learning papers, and edges represent citation links. The node attributes are sparse bag-of-words vectors indicating the presence of specific keywords in the paper. The clustering task involves grouping papers into seven distinct research topics. Photo [33]. segment of the Amazon co-purchase graph. Nodes represent goods (photo), and edges connect two products if they are frequently bought together. Node features are bag-of-words vectors extracted from product reviews. The goal is to cluster products into eight categories based on the product type. A.2 Small Scale Datasets (104 ùëÅ < 105) Physics [33]. This is co-authorship graph constructed from the Microsoft Academic Graph. Nodes are authors, and edges are established if two authors have co-authored paper. Node features are bag-of-words representations of paper keywords. The authors are clustered into five research fields. HM [1]. This dataset is derived from the H&M Kaggle competition. The graph represents co-purchasing network where nodes are products, and undirected edges connect products that are frequently bought by the same customers. The features are tabular, including product metadata (e.g., categorical features like color) and purchasing statistics (e.g., numerical features representing the proportion of purchases occurring on different weekdays). The task is to partition products into 21 distinct product categories. Flickr [45]. An image-sharing social network dataset. Nodes represent images uploaded to Flickr, and edges reflect common metadata (e.g., same location, same gallery, or shared by the same user). Node features are 500-dimensional bag-of-words vectors based on userprovided tags. The clustering target is to group images into seven classes based on their tags. A.3 Medium Scale Datasets (105 ùëÅ < 106) ArXiv [12]. citation network representing Computer Science papers in arXiv. Nodes represent papers, and edges represent citations. Node features are 128-dimensional feature vectors obtained by averaging the embeddings of words in the papers title and abstract. The task is to cluster papers into 40 subject areas. Reddit [10]. This dataset is constructed from Reddit posts made in the month of September 2014. Each node represents post, and the ground-truth labels represent the community (subreddit) that the post belongs to. Nodes are connected based on common users commenting on both posts. Node features are 300-dimensional GloVe word vectors averaged over the content associated with the posts, including the title, comments, score, and number of comments. MAG [12]. Extracted from the Microsoft Academic Graph, this is heterogeneous network containing papers, authors, institutions, and fields of study. For the purpose of this benchmark, we utilize the homogeneous subgraph of papers connected by citation links. The node features are 128-dimensional Word2Vec embeddings of paper abstracts. The clustering task involves distinguishing between 349 venue categories (journals or conferences). A.4 Large Scale Datasets (106 ùëÅ < 108) Pokec [1]. Based on data from the popular social network in Pokec. Nodes represent users, and directed edges connect users who have marked others as friends. The node features are tabular and derived from user profile information, including numerical features (e.g., profile completion proportion) and categorical indicators (e.g., whether specific profile fields are filled). The task is to predict which region user belongs to, presenting an extreme multi-class clustering challenge with 183 classes and moderate heterophily. Products [12]. large-scale co-purchase network from Amazon. Nodes represent products, and edges connect products that are purchased together. Node features are generated from the product descriptions using dimensionality-reduced bag-of-words approach. The clustering task is to group products into 47 top-level categories. WebTopic [1]. This dataset represents segment of the Internet (Web Graph) obtained from the Yandex search engine. Nodes are websites, and directed edges exist if user followed link from one website to another within selected period. The features are tabular and highly heterogeneous, including numerical features (e.g., number of videos on the site) and categorical features (e.g., the websites zone, free hosting status). The goal is to cluster websites into 28 topics. This dataset is notable for its low homophily and complex feature distribution. A.5 Massive Scale Datasets (ùëÅ > 108) Papers100M [12]. Currently one of the largest public graph benchmarks available. It is citation network of approximately 111 million papers indexed by MAG. Directed edges represent citations. Node features are 128-dimensional embeddings averaged from the word embeddings of titles and abstracts. The task is to cluster papers into 172 subject areas. Note that approximately 1.5 million of nodes are labeled with one of arXivs subject areas. Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering Conference acronym XX, June 0305, 2018, Woodstock, NY Table 4: Summary of the benchmark datasets. The collection is categorized by scale, spanning five orders of magnitude from Tiny to Massive. The datasets cover wide range of domains and feature types (Textual, Tabular). Hùëí and Hùëõ denote edge homophily and node homophily, respectively. #Edges Avg. Deg. 3.9 31.1 10,556 238,"
        },
        {
            "title": "ArXiv\nReddit\nMAG",
            "content": "Domain Citation Co-purchase Co-author Co-purchase Social"
        },
        {
            "title": "Citation\nSocial\nCitation",
            "content": "#Nodes 2,708 7,650 34,493 46,563 89,250 169,343 232,965 736,"
        },
        {
            "title": "Pokec\nProducts\nWebTopic",
            "content": "Social Co-purchase Web 1,632,803 2,449,029 2,890,331 495,924 21,461,990 899,756 1,166,243 23,213,838 10,792,672 44,603,928 61,859,140 24,754,"
        },
        {
            "title": "Massive",
            "content": "Papers100M Citation 111,059,956 1,615,685,872 #Feat. 1,433 745 8,415 120 500 128 602 56 100 528 128 Feat. Type Textual Textual #Clus. Hùëí 0.81 0.83"
        },
        {
            "title": "Tabular\nTextual\nTabular\nTextual",
            "content": "5 21 7 40 41 349 183 47 28 172 0.93 0.16 0.32 0.65 0.78 0. 0.43 0.81 0.22 0.57 Hùëõ 0.83 0.84 0.92 0.35 0.32 0.64 0.81 0. 0.39 0.82 0.18 0.50 14.4 460.9 10.1 6.9 99.6 14.7 27.3 25.4 8.6 14. Note: For Papers100M, ground-truth labels are available for subset of 1.5M arXiv papers. The reported homophily metrics (Hùëí, Hùëõ ) are calculated based on the induced subgraph of these labeled nodes. Table 5: taxonomy of representative Attributed Graph Clustering methods under the Encode-Cluster-Optimize framework. E: Encoder Type (Parametric vs. Non-Parametric); C: Clusterer Type (Differentiable vs. Discrete); O: Optimization Strategy (Joint vs. Decoupled). Complexity denotes the time/space complexity, where ùëÅ = and ùëÄ = . ùëÇ (ùëÅ + ùëÄ) indicates linear scalability on sparse graphs, while ùëÇ (ùëÅ 2) indicates quadratic bottlenecks."
        },
        {
            "title": "Venue",
            "content": "Encode (E) Cluster (C) Optimize (O) Core Objective"
        },
        {
            "title": "Complexity",
            "content": "Non-Parametric & Decoupled Methods AGC [48] SSGC [49] NAFS [47] SAGSC [7] MS2CAG [16] IJCAI19 ICLR21 ICML22 AAAI23 KDD"
        },
        {
            "title": "Fixed Filter\nAdaptive Filter\nAdaptive Filter\nFixed Filter\nFixed Filter",
            "content": "Decoupled Discrete (Spectral) Decoupled Discrete (KMeans) Decoupled Discrete (KMeans) Discrete (Subspace) Decoupled Discrete (SNEM [43]) Decoupled Adaptive Smoothing Markov Diffusion Smoothing + Ensemble Self-Expressive Subspace Rank-Constrained SVD ùëÇ (ùëÅ 2) ùëÇ (ùëÅ + ùëÄ) ùëÇ (ùëÅ + ùëÄ) ùëÇ (ùëÅ + ùëÄ) ùëÇ (ùëÅ + ùëÄ) GAE [13] DGI [37] CCASSG [46] S3GC [6] NS4GC [17] MAGI [21] NIPS-W16 ICLR19 NeurIPS21 NeurIPS22 TKDE24 KDD24 DAEGC [38] DinkNet [22] MinCut [3] DMoN [34] Neuromap [4] NeurIPS IJCAI19 ICML23 ICML20 JMLR23 Deep Decoupled Methods (Parametric Encoder + Post-hoc Clustering) Parametric (GCN) Discrete (KMeans) Parametric (GCN) Discrete (KMeans) Parametric (GCN) Discrete (KMeans) Parametric (GCN) Discrete (KMeans) Parametric (GCN) Discrete (KMeans) Parametric (GNN) Discrete (KMeans)"
        },
        {
            "title": "Decoupled\nDecoupled\nDecoupled\nDecoupled\nDecoupled\nDecoupled",
            "content": "ùëÇ (ùëÅ 2) Graph Reconstruction Mutual Info Maximization ùëÇ (ùëÅ + ùëÄ) Redundancy Reduction ùëÇ (ùëÅ + ùëÄ) ùëÇ (ùëÅ 2) Contrastive (Random Walk) Contrastive (Node Similarity) ùëÇ (ùëÅ 2) ùëÇ (ùëÅ 2) Contrastive (Modularity) Deep Joint Methods (Parametric Encoder + Differentiable Clustering) Parametric (GAT) Differen. (Prototype) Parametric (GCN) Differen. (Prototype) Parametric (GCN) Differen. (Softmax) Parametric (GCN) Differen. (Softmax) Parametric (GCN) Differen. (Softmax) Reconstruction + KL Div. Dilation + Shrink Loss Cut Minimization Modularity Maximization Map Equation"
        },
        {
            "title": "Joint\nJoint\nJoint\nJoint\nJoint",
            "content": "ùëÇ (ùëÅ 2) ùëÇ (ùëÅ + ùëÄ) ùëÇ (ùëÅ + ùëÄ) ùëÇ (ùëÅ + ùëÄ) ùëÇ (ùëÅ + ùëÄ) Detailed Description of Evaluated Algorithms In this section, we provide detailed descriptions of the benchmark AGC methods. To facilitate systematic comparison, we categorize these methods based on the Encode-Cluster-Optimize framework introduced in Section 2. B.1 Traditional and Non-Parametric Methods These methods typically employ fixed or simplified encoding mechanisms and decouple the clustering process from representation learning. Conference acronym XX, June 0305, 2018, Woodstock, NY Yunhui Liu et al. Node Similarity Matrix which guides the representation learning. The method aligns node neighbors and performs semantic-aware sparsification to ensure the learned embeddings preserve intrinsic semantic structures suited for clustering. MAGI [21]: MAGI bridges the gap between community detection and contrastive learning. It uses modularity maximization as pretext task. Positive and negative pairs are defined not by random corruption, but by modularity-based communities, effectively using the GNN to maximize the modularity of the resulting partitions. This aligns the representation learning objective directly with the clustering goal. B.3 Deep Joint Methods These methods optimize the encoder and the cluster assignments simultaneously in an end-to-end fashion. DAEGC [38]: DAEGC employs Graph Attention Network as the encoder to capture neighbor importance. It combines reconstruction loss with clustering guidance loss (KL divergence between soft assignments and target distribution). The selftraining process iteratively refines the clusters and the embeddings. DinkNet [22]: DinkNet is designed explicitly for scalability. It replaces the traditional KL-divergence loss with Dilation (separating different clusters) and Shrink (compacting same-cluster nodes) loss. It initializes cluster centers as learnable parameters and uses an adversarial mechanism to optimize the distribution. MinCut [3]: This method provides continuous relaxation of the normalized min-cut problem. GNN projects nodes directly into soft cluster assignment matrix. The loss function minimizes the cut value (edge connections between clusters) while enforcing orthogonality to prevent trivial solutions (all nodes in one cluster). DMoN [34]: DMoN optimizes the spectral modularity objective. It essentially acts as differentiable pooling operator that coarsens the graph. Unlike MinCut, it does not require orthogonality constraints because the modularity metric naturally penalizes trivial partitions. Neuromap [4]: Neuromap creates differentiable formulation of the Map Equation, an information-theoretic measure for community detection based on flow dynamics. It optimizes the code length required to describe random walks on the graph, naturally balancing cluster internal density with external separation without requiring pre-specified number of clusters, though we fix ùêæ for consistent benchmarking. KMeans [29] & Node2Vec [9]: We include these as fundamental representatives to assess the value of attribute-structure fusion. KMeans clusters raw node features (ignoring topology), while Node2Vec clusters structural embeddings learned via random walks (ignoring attributes). SSGC [49]: SSGC addresses the over-smoothing and scalability issues of deep GCNs. It utilizes modified Markov Diffusion Kernel to derive spectral graph convolution that balances lowand high-pass filter bands. In our framework, SSGC acts as non-parametric encoder that aggregates features over multiple hops in single step, followed by standard KMeans clustering. Its linearity allows for efficient processing, though it lacks the expressivity of deep non-linear encoders. SAGSC [7]: SAGSC combines Laplacian smoothing with subspace clustering. It first smooths attributes over the graph to incorporate structural information. It then employs self-expressive subspace clustering procedure that learns factored coefficient matrix, projecting factors into new space to generate valid affinity matrix for spectral clustering. This method represents hybrid approach where the encoding is fixed smoothing operation, and the optimization targets self-expressiveness. MS2CAG [16]: MS2CAG improves upon subspace graph clustering by formulating rank-constrained SVD problem. It introduces linear-time optimization solver that avoids the explicit construction of the ùëÅ ùëÅ self-expressive matrix, which is common bottleneck in subspace clustering. Theoretical analysis links its objective to modularity maximization. B.2 Deep Decoupled Methods These methods utilize parametric Graph Neural Networks to learn node embeddings via self-supervised tasks, followed by post-hoc application of discrete clusterer (typically KMeans). GAE [13]: foundational generative method that uses GNN encoder to parameterize the latent distribution of node embeddings. The objective is to reconstruct the adjacency matrix via decoder. Clustering is performed on the learned representations. DGI [37]: DGI relies on maximizing mutual information between local node patches and global graph summary vector. It learns representations by contrasting true graph patches with corrupted counterparts (negative sampling). This contrastive objective encourages the encoder to capture global structural properties without explicit reconstruction. CCASSG [46]: Unlike contrastive methods requiring negative pairs, CCASSG optimizes feature-level objective inspired by Canonical Correlation Analysis. It generates two views via augmentation and minimizes the correlation between different feature dimensions while maximizing invariance across views. This decorrelation prevents collapse and removes the need for costly negative sampling. S3GC [6]: S3GC utilizes contrastive learning framework specifically designed to enhance clusterability. It employs random walks to define positive neighborhoods and optimizes contrastive loss that sharpens the decision boundaries between potential clusters. It effectively scales to massive-scale datasets. NS4GC [17]: NS4GC argues that standard contrastive learning may neglect semantic node relations. It introduces Reliable Bridging Academia and Industry: Comprehensive Benchmark for Attributed Graph Clustering Conference acronym XX, June 0305, 2018, Woodstock, NY Table 6: Clustering performance comparison measured by ARI and F1 (%) (Mean SD). The best and second-best results are highlighted. \"\" denotes OOM errors as these methods strictly require full-graph processing."
        },
        {
            "title": "Tiny",
            "content": "l i a i m P - d u D D o e D"
        },
        {
            "title": "KMeans",
            "content": "Node2Vec"
        },
        {
            "title": "SAGSC",
            "content": "MS2CAG"
        },
        {
            "title": "CCASSG",
            "content": "S3GC NS4GC"
        },
        {
            "title": "Neuromap",
            "content": "ARI F1 ARI F1 ARI F1 ARI F1 ARI F1 ARI ARI F1 ARI F1 ARI F1 ARI F1 ARI F1 ARI ARI F1 ARI F1 ARI F1 ARI F1 Cora 6.952.61 25.992.91 33.612.49 61.662. 41.251.69 65.161.32 38.830.02 61.030.02 45.760.98 69.170.65 45.630.15 64.480.11 52.033.22 70.072.56 51.843.32 72.291. 48.122.56 69.041.57 56.631.20 72.810.38 53.511.09 72.650.36 38.362.67 64.542.32 52.450.41 70.120.59 28.602.86 51.886.97 33.353.35 49.573. 36.693.25 54.693.95 Photo 20.011.01 42.683.32 57.111.39 69.331.18 59.173.81 70.173.78 43.660.01 69.400.01 63.880.54 74.940. 52.390.12 67.520.09 58.380.46 72.771.71 51.804.28 69.691.95 59.092.86 70.212.55 62.640.62 73.731.11 58.530.32 70.820. 56.370.02 76.260.01 53.540.23 67.200.27 50.992.33 66.992.97 51.552.41 70.862.44 53.013.67 69.133.76 Physics 32.340.29 52.120.11 39.860.01 57.910. 56.5013.07 63.5710.46 46.370.02 60.870.02 80.890.05 87.600.05 74.250.11 80.040.04 83.050.20 85.360.58 79.390.11 82.450.07 79.380.08 81.820. 85.150.06 84.930.12 49.760.83 64.080.22 37.880.05 54.390.05 40.790.23 55.050.54 39.892.65 52.572.83 39.810.21 54.980. 43.523.94 40.410."
        },
        {
            "title": "Small",
            "content": "HM 2.960.09 12.500.20 1.840.07 11.650.46 3.180.02 14.840.13 4.120.08 16.080.10 3.500.11 12.950.27 4.210.23 15.200. 3.110.06 14.200.23 3.200.05 14.290.24 3.300.05 14.590.29 4.720.10 17.230.28 2.460.27 14.330.78 3.470.07 14.730.05 2.960.03 14.300. 1.220.30 9.540.68 2.050.28 10.580.44 1.450.07 9.370."
        },
        {
            "title": "Large",
            "content": "Flickr 1.060.15 15.160.85 1.520.00 19.680.01 3.290.11 18.640.48 3.270.00 20.970.01 3.840.03 21.810.03 5.530.30 18.830. 4.980.01 19.920.15 3.340.03 16.670.26 5.450.00 23.210.00 3.370.01 19.440.03 3.160.27 20.810.36 4.610.10 19.240.09 1.560.33 16.500. 3.730.66 21.221.17 5.010.52 22.760.48 4.991.28 22.391.57 ArXiv 7.230.15 12.970.18 16.690.73 20.960.29 33.040.29 25.440. 20.690.69 25.370.85 28.840.18 24.580.50 15.950.40 18.570.22 22.770.28 21.470.30 19.180.18 23.780.25 27.080.55 24.090. 31.842.30 26.670.57 30.381.33 25.170.59 17.530.40 20.640.28 14.930.50 16.940.73 17.470.98 21.850.73 15.440.37 20.370.61 21.921.08 21.290. Reddit 2.930.05 7.250.08 64.341.64 68.612.12 33.611.29 29.151.33 65.931.44 70.431.60 56.562.89 55.371.78 27.880.46 26.890. 59.280.54 51.970.79 31.280.32 30.090.32 83.272.36 71.351.60 39.120.19 34.950.63 62.271.24 55.261.62 13.431.24 8.230.93 33.701.24 27.890. 25.421.67 26.395.74 32.391.40 26.520.76 25.320.26 25.700.43 MAG 2.770.03 5.710.07 4.750.07 8.900.09 5.840.09 9.780. 4.890.11 9.670.20 5.160.09 9.970.14 5.340.08 8.970.09 5.550.07 8.560.05 6.110.05 8.560.06 7.510.11 7.910.05 6.850.06 9.140. 6.440.06 9.460.06 4.290.36 7.250.43 5.100.04 7.650.11 5.560.15 8.040.12 4.930.02 8.970.14 9.850.36 6.200. Pokec 0.230.00 0.980.01 9.270.08 12.660.15 0.420.01 1.600.03 11.580.18 16.120.26 0.420.03 1.510.02 0.340.01 1.530. 0.320.00 1.590.01 0.230.00 0.980.01 0.670.01 2.020.01 0.740.01 2.330.02 1.060.01 2.900.02 0.610.04 1.730. 0.290.02 1.650.01 0.610.04 2.300.05 1.170.04 3.040.04 1.840.11 2.620.14 Products WebTop. 0.870.04 9.220.33 4.640.04 12.770.41 18.531.05 25.410. 18.840.40 24.010.71 19.360.29 25.560.53 17.970.65 24.670.31 14.490.25 18.350.47 14.670.21 17.870.32 22.430.70 22.830. 23.570.28 25.190.41 23.820.23 26.520.28 16.670.37 21.120.19 2.350.90 8.021.81 13.670.40 14.140.12 10.640.32 17.530.54 10.930.41 16.431. 16.521.56 13.091.04 1.530.03 7.400.16 1.750.04 5.660.04 2.910.10 9.000.30 2.360.03 8.520.07 1.980.06 5.810. 2.180.06 7.100.06 1.400.29 5.170.16 2.560.04 8.070.02 3.860.05 8.800.15 2.920.29 9.530.27 2.580.38 7.340.19 1.860.25 5.710. 2.000.20 6.920.46 2.430.21 7.800.21 3.310.56 7.960."
        },
        {
            "title": "Massive",
            "content": "Papers. 7.630.08 11.020.19 16.170.15 19.380.19 9.800.06 11.840.10 12.170.16 15.530. 19.020.17 17.410.12 13.010.16 11.830.12 16.580.20 15.360.09 18.250.26 17.100.23 8.681.39 4.080.26 14.210.19 12.580. Table 7: Efficiency profiling results for smaller datasets. Mem: Peak GPU Memory, Time: Total Training and Clustering Time. Category Method Traditional NonParametric Deep Decoupled Deep Joint KMeans Node2Vec SSGC SAGSC MS2CAG GAE DGI CCASSG S3GC NS4GC MAGI DAEGC DinkNet MinCut DMoN Neuromap Cora Photo Physics HM Flickr ArXiv Mem(MB) Time(s) Mem(GB) Time(s) Mem(GB) Time(m) Mem(GB) Time(m) Mem(GB) Time(m) Mem(GB) Time(m) - 46.0 - - - 60.0 152.0 46.0 438.0 278.0 210.0 68.0 192.0 62.0 62.0 62. 0.28 24.57 0.56 0.86 0.78 32.03 15.50 0.46 124.74 9.77 51.25 35.80 13.31 5.51 3.58 4.73 - 0.07 - - - 1.48 1.51 1.17 1.73 1.46 1.06 2.17 2.95 0.25 0.25 0.80 0.69 27.96 0.62 1.02 0.85 178.93 11.14 27.92 148.44 64.36 18.68 156.84 36.07 6.78 6.99 12. - 0.16 - - - 2.86 5.40 4.36 11.59 9.96 12.66 6.13 5.40 1.34 1.34 1.34 0.19 15.52 2.25 2.13 0. 1.17 1.55 0.08 50.11 3.12 26.22 5.56 1.93 0.23 0.21 0.23 - 0.19 - - - 0.38 16.55 26.30 0.35 6.53 1.24 22.29 16.56 16.55 16.55 16. 0.05 1.50 0.04 0.07 0.03 0.81 0.54 0.18 0.98 4.47 41.84 1.10 0.14 5.11 5.08 5.17 - 0.36 - - - 2.86 6.25 1.51 2.12 7.10 14.97 4.24 6.45 0.99 0.99 1.74 0.08 20.97 0.10 0.04 0.03 2.56 1.12 0.09 15.49 0.85 43.31 4.87 1.40 0.34 0.34 0. - 0.49 - - - 1.76 15.11 13.55 1.21 11.69 30.54 6.13 19.88 3.95 3.95 3.96 0.32 5.05 0.17 0.28 0. 12.77 2.76 3.04 3.91 22.94 28.80 9.06 3.72 1.00 1.37 1.62 Conference acronym XX, June 0305, 2018, Woodstock, NY Yunhui Liu et al. Table 8: Clustering performance comparison measured by Homogeneity (Homo) and Completeness (Comp) (%) (Mean SD). The best and second-best results are highlighted. \"\" denotes OOM errors as these methods strictly require full-graph processing. Model Metric Tiny . KMeans T Node2Vec . P - N l c e n p SSGC SAGSC MS2CAG GAE DGI CCASSG S3GC NS4GC MAGI DAEGC DinkNet MinCut DMoN Neuromap Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Homo Comp Cora 12.843.78 15.195.37 44.761.49 45.141.49 52.391.18 51.330.99 45.480.06 43.270. 54.310.67 52.980.62 51.280.07 48.960.07 56.810.52 55.661.27 59.061.03 58.430.76 55.720.81 55.181.42 59.880.33 58.930.66 59.200.39 58.690. 47.681.58 46.111.84 55.950.23 55.180.13 42.041.90 39.641.78 44.952.33 42.782.27 48.342.67 45.702.56 Photo 32.660.61 30.800. 68.021.20 64.130.91 71.052.42 70.490.35 60.200.02 56.710.01 73.730.85 71.280.74 62.970.15 59.830.13 68.400.12 67.160. 65.992.80 63.153.63 69.322.19 67.252.26 73.470.88 71.790.71 69.890.17 67.470.16 65.160.02 62.110.02 65.670.04 63.830.09 64.382.47 60.422. 65.122.78 60.522.57 63.202.76 60.541.96 Physics 55.660.17 48.790.10 58.810.01 51.550.01 68.582.64 60.925.50 60.090.04 52.350. 73.340.04 71.580.04 70.350.02 66.080.04 75.110.34 73.680.36 72.240.04 69.690.05 72.210.05 69.580.05 75.910.07 74.850.09 70.590.27 62.110. 61.960.03 52.840.03 62.090.07 53.270.06 62.142.23 52.541.91 63.540.40 53.850.34 57.500.17 55.672.89 Small HM 10.800.13 9.600.10 7.970.13 7.260.13 12.800.11 11.570.10 13.240.12 11.790.14 10.370.38 9.200.35 14.440.13 12.830. 12.200.08 11.180.04 12.490.15 11.420.15 12.120.08 11.060.09 16.210.17 14.450.18 11.020.52 11.460.40 11.910.07 11.050.12 11.720.07 10.830. 7.130.57 7.760.17 8.080.97 7.160.87 7.510.20 7.370.15 Flickr 1.200.07 1.220.07 6.040.00 5.200.00 4.800.23 4.200. 7.440.00 6.360.00 7.980.02 6.760.02 3.870.04 4.290.14 7.580.01 6.300.02 5.080.02 4.320.01 8.720.00 7.110. 6.780.01 5.690.01 6.940.19 5.780.14 4.620.02 3.900.03 6.260.06 7.150.07 8.170.21 7.090.26 8.670.09 7.230.11 8.470.66 7.190. ArXiv 25.080.02 20.540.04 42.930.16 35.610.15 49.160.12 43.430.19 47.530.24 39.720.18 47.770.21 41.120.16 45.470.15 37.110. 46.460.08 38.810.09 49.500.06 40.730.05 51.420.12 43.470.12 52.550.17 44.830.31 50.430.12 43.190.19 44.050.32 36.320.27 40.080.74 34.780. 43.211.28 35.530.83 43.040.43 35.270.19 43.870.72 37.960.88 Medium Reddit 11.490.16 10.690.13 81.690.35 76.930. 52.410.27 50.830.52 81.800.29 78.310.46 75.150.39 70.680.68 47.140.28 44.730.26 74.490.15 71.430.15 50.800.10 48.510. 83.230.19 83.670.62 58.150.05 55.340.08 73.830.21 71.280.22 29.191.11 68.191.84 55.990.40 53.960.12 49.176.15 48.900.89 51.120.36 50.210. 49.700.32 46.070.25 MAG 30.560.05 26.380.06 40.740.03 35.130.03 44.590.03 38.840.04 42.920.03 37.710.03 43.240.07 37.890. 42.380.04 36.640.03 42.330.02 36.820.03 43.330.00 37.850.03 42.180.02 37.680.04 44.500.02 39.130.02 44.250.03 38.790.01 30.632.33 27.532. 39.640.06 34.900.05 40.190.14 36.420.17 41.450.13 35.590.11 38.620.20 39.680.24 Pokec 1.440.00 1.370.00 33.710.02 30.320. 4.360.02 4.310.01 40.180.02 36.640.03 2.910.05 2.640.04 3.920.05 3.660.04 4.350.01 4.050.01 1.380.01 1.320.01 6.270.01 5.830. 7.500.04 6.910.04 9.200.03 8.360.02 3.660.24 4.050.17 3.980.02 3.850.01 6.060.18 5.530.17 8.880.09 8.000. 8.810.26 8.270.23 Large Products WebTop 2.830.06 33.930.19 2.160.05 25.680.10 60.220.18 44.180.24 61.170.28 45.280.13 61.250.29 44.850. 60.170.40 43.830.26 50.810.10 36.600.08 48.810.19 35.760.10 59.330.39 44.550.31 62.920.12 46.440.19 64.270.20 47.510.11 52.890.16 38.530. 10.063.55 8.442.67 44.350.19 33.910.18 42.760.91 30.790.59 41.641.02 29.890.72 37.261.83 32.661.23 6.730.10 5.090. 4.490.13 3.470.10 10.520.30 8.040.24 9.020.10 6.820.07 4.390.17 3.490.12 6.820.03 5.220.03 4.180.19 3.470. 9.070.03 6.890.02 11.550.05 8.890.05 10.690.30 8.180.15 5.340.31 4.340.27 6.180.03 4.910.05 7.010.70 5.350.41 8.770.48 6.540. 8.000.58 6.530.46 Massive Papers. 41.090.07 34.950.07 55.430.06 47.730.05 46.130.02 39.990.02 53.590.07 45.620.07 57.350.08 50.700.04 46.900.07 41.760.09 52.430.05 47.470.08 56.330.04 50.150. 25.270.13 32.920.39 48.440.04 43.540."
        }
    ],
    "affiliations": [
        "Ant Group",
        "Nanjing University"
    ]
}