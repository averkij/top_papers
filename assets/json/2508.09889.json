{
    "paper_title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving",
    "authors": [
        "Zhitian Xie",
        "Qintong Wu",
        "Chengyue Yu",
        "Chenyi Zhuang",
        "Jinjie Gu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The rapid advancement of large language models (LLMs) has empowered intelligent agents to leverage diverse external tools for solving complex real-world problems. However, as agents increasingly depend on multiple tools, they encounter new challenges: extended contexts from disparate sources and noisy or irrelevant tool outputs can undermine system reliability and accuracy. These challenges underscore the necessity for enhanced stability in agent-based systems. To address this, we introduce dynamic supervision and maneuvering mechanisms, constructing a robust and dynamic Multi-Agent System (MAS) architecture within the AWorld framework. In our approach, the Execution Agent invokes the Guard Agent at critical steps to verify and correct the reasoning process, effectively reducing errors arising from noise and bolstering problem-solving robustness. Extensive experiments on the GAIA test dataset reveal that our dynamic maneuvering mechanism significantly improves both the effectiveness and stability of solutions, outperforming single-agent system (SAS) and standard tool-augmented systems. As a result, our dynamic MAS system achieved first place among open-source projects on the prestigious GAIA leaderboard. These findings highlight the practical value of collaborative agent roles in developing more reliable and trustworthy intelligent systems."
        },
        {
            "title": "Start",
            "content": "2025-08-14 AWORLD: DYNAMIC MULTI-AGENT SYSTEM WITH STABLE MANEUVERING FOR ROBUST GAIA PROBLEM SOLVING Zhitian Xie, Qintong Wu, Chengyue Yu, Chenyi Zhuang, Jinjie Gu {xiezhitian.xzt, qintong.wqt, yuchengyue.ycy, chenyi.zcy, jinjie.gujj}@antgroup.com AWorld Team, Inclusion AI https://github.com/inclusionAI/AWorld"
        },
        {
            "title": "ABSTRACT",
            "content": "The rapid advancement of large language models (LLMs) has empowered intelligent agents to leverage diverse external tools for solving complex real-world problems. However, as agents increasingly depend on multiple tools, they encounter new challenges: extended contexts from disparate sources and noisy or irrelevant tool outputs can undermine system reliability and accuracy. These challenges underscore the necessity for enhanced stability in agent-based systems. To address this, we introduce dynamic supervision and maneuvering mechanisms, constructing robust and dynamic Multi-Agent System (MAS) architecture within the AWorld framework. In our approach, the Execution Agent invokes the Guard Agent at critical steps to verify and correct the reasoning process, effectively reducing errors arising from noise and bolstering problem-solving robustness. Extensive experiments on the GAIA test dataset reveal that our dynamic maneuvering mechanism significantly improves both the effectiveness and stability of solutions, outperforming single-agent system (SAS) and standard tool-augmented systems. As result, our dynamic MAS system achieved first place among opensource projects on the prestigious GAIA leaderboard. These findings highlight the practical value of collaborative agent roles in developing more reliable and trustworthy intelligent systems. Keywords Dynamic Multi-Agent System Runtime Stability Maneuvering 5 2 0 2 3 1 ] . [ 1 9 8 8 9 0 . 8 0 5 2 : r Figure 1: Performance on the GAIA benchmarks (partial) across systems: Building on Gemini 2.5 Pro, incorporating tools into Single Agent System enhances performance but also introduces greater uncertainty. By comparison, the Dynamic Multi-Agent System deliver superior results while offering improved stability. MAS by AWorld Framework TECHNICAL REPORT"
        },
        {
            "title": "Introduction",
            "content": "The extraordinary progress of Large Language Models (LLMs)in terms of both capabilities and scale [Achiam et al., 2023, Touvron et al., 2023, Team et al., 2023, The Google DeepMind Team, 2024, Anthropic, 2025]has sparked widespread curiosity about the upper bounds of artificial intelligence. As practitioners continue to push the frontiers, it has become clear that augmenting foundational models with external tools not only expands their problem-solving abilities beyond intrinsic knowledge, but also enables the tackle of complex real-world challenges [Kapoor et al., 2024, Huang and Yang, 2025, Krishnan, 2025, Shao et al., 2025]. vivid illustration is provided by the recent surge in interest surrounding the IMO2025 mathematics competition, where state-of-the-art LLMs, even those with impressive baseline performance, struggled to solve many problems. In contrast, agent-based systemsbuilt upon these same foundational modelssuccessfully solved five out of six competition tasks [Huang and Yang, 2025], prompting new questions about the true limits of AI: perhaps it is not just the power or size of individual models, but also our ingenuity in organizing them for effective collaboration that also matters. This insight has fueled the rapid growth of agent frameworks, where multiple models or agents interact and work together, often supported by standardized tool interfaces like MCP [Hou et al., 2025, Liu et al., 2025]. The marriage of LLMs and tools has inspired developers, but amid the excitement, central challenge has come to the fore: system stability. Empirical results show that an agents robustness often hinges on the foundational models reliability [Coletta et al., 2024, Li et al., 2025, Shojaee et al., 2025], the nature of integrated tools, and design strategies for agent orchestration. Thus, to advance reliable intelligent systems, research must go beyond scaling up model capacities and also focus on strategies for building agents that are consistent, resilient, and adaptive. The multi-agent paradigm, especially in forms inspired by the solverreviewer structure seen in recent IMO2025 studies [Huang and Yang, 2025], offers simple yet effective blueprint: two agents, one solving and the other reviewing, boost overall problem-solving accuracy compared to single-agent setups. Yet, such enforced dialog-based architectures introduce longer contexts and extended reasoning chains, with practical limitations such as rigid turn limits for ending conversations. This points to the desirability of more flexible, dynamic multi-agent systems. Drawing inspiration from disciplines like vessel maneuveringwhere optimal navigation depends on dynamically adjusting control parameters based on hydrodynamics conditions rather than static settings [Xie et al., 2020]we propose parallel in agent orchestration. Intelligent agents should not rely on fixed, predetermined supervision mechanisms. Instead, they require dynamic maneuvering: agents ought to adaptively decide when and how to intervene or correct reasoning processes, based on the evolving task context, tool outputs, and model-internal interpretations. Motivated by these challenges and opportunities, this work introduces dynamic maneuvering mechanism within the AWorld framework, our open-source agent development platform. By enabling principal Execution Agent to collaborate with Guard Agent that verifies and refines the reasoning process at critical moments, we construct flexible multi-agent system. Rigorous testing on the GAIA benchmarkrenowned for assessing agent capabilitiesdemonstrates [Mialon et al., 2023] that our dynamically orchestrated MAS not only surpasses single-agent systems (SAS) built on the same foundation and tools, but also achieves higher stability and accuracy. As result, our MAS system achieved the first place among open-source projects on the prestigious GAIA test leaderboard, as shown in Figure 2. This research highlights the promise of adaptive multi-agent approaches for building powerful, trustworthy intelligent systems equipped to face diverse real-world tasks. Figure 2: AWorld achieves 1st in GAIA test leaderboard. 2 MAS by AWorld Framework TECHNICAL REPORT"
        },
        {
            "title": "2 Method",
            "content": "Our approach to enhancing agent stability is inspired by well-established principles in control theory, particularly from the field of marine vessel navigation [Xie et al., 2020]. The maneuvering motions of ship, as described by the control equations presented in Table (1), model system subject to complex and unpredictable external forces such as wave drift. To ensure the vessel converges to desired trajectory (for example the zig-zag test as shown in Figure 3), continuous and adaptive adjustments are essential. The rudder angle, for instance, is dynamically controlled to counteract disturbances and guide the ships path. We posit that an agents problem-solving process is analogous to ships voyage. The agents logical reasoning forms \"trajectory\" toward solution, which is constantly perturbed by \"noise\" from long contexts and irrelevant tool outputsakin to the winds and currents affecting vessel. Drawing from this parallel, we introduce dynamic maneuvering mechanism for our Multi-Agent System. Just as rudder provides corrective steering, our system employs Guard Agent to perform dynamic supervision and intervention. This mechanism steers the Execution Agents reasoning process, correcting deviations and ensuring it remains on robust and accurate path to the final goal. This proactive course-correction is fundamental to achieving the stability and reliability that our architecture provides. (X m) + Xuu + Xdrift = 0 (Y m) + Yvv + (Y mxG) + (Yr mu0)r + Ydrift = 0 (N mxG) + Nvv + (N IZ) + (Nr mxGu0)r + Ndrift = 0 (1) Table 1: In these linearized equations of motion, u, v, and represent the velocities in surge (longitudinal), sway (lateral), and yaw, respectively; u, v, and are the corresponding linear and angular accelerations. The vessels physical properties are given by its mass m, its moment of inertia about the vertical axis IZ , and the longitudinal position of the center of gravity xG. The terms such as u, Yv, and Nr are the hydrodynamic coefficients. Specifically, terms with dot in the subscript (e.g., u, v, r) represent added mass and added moment of inertia, while terms without dot (e.g., Yv, Nr) represent damping coefficients. The constant forward speed of the vessel is u0, and is the perturbation in surge velocity. Finally, Xdrift, Ydrift, and Ndrift represent the external longitudinal force, lateral force, and yaw moment induced by slowly varying wave drift. [Xie et al., 2020] Figure 3: Zig-Zag tests in regular waves with 90 deg at = 0 and ratios between wave length and vessel length = 0.75 [Xie et al., 2020] The core features of the Multi-Agent System (MAS) we developed within the AWorld framework are highlighted in Figure 4. Based on the AWorld framework, we developed dynamic Multi-Agent System (MAS) that leverages an \"agent-as-tool\" paradigm and introduces Guard Agent for rigorous logical verification. Central to our approach is mechanism of dynamic supervision and maneuvering, which enables adaptive intervention throughout the problemsolving process. Specifically, the Execution Agent initiates the task and dynamically determines when to engage additional agents, guided by system prompts and contextual analysis. Meanwhile, the Guard Agent provides continuous oversight by monitoring, correcting, and issuing reminders about logical reasoning steps, thereby enhancing the Execution Agents accuracy and the overall robustness of the solutions. Notably, the Guard Agent is built on the 3 MAS by AWorld Framework TECHNICAL REPORT same foundational model as the Execution Agent (e.g., Gemini 2.5 Pro), ensuring greater consistency and improved collaborative capabilities within the system. Figure 4: Multi-Agent System (MAS) Architecture on AWorld Framework."
        },
        {
            "title": "3 Experiments Settings",
            "content": "Problem Set Our experiments utilize 109 questions (https://github.com/inclusionAI/AWorld/blob/main/examples/gaia/subset.txt) from the GAIA test set [Mialon et al., 2023], comprising 56 Level 1 (L1) and 53 Level 2 (L2) questions. These questions cover range of tasks, including office-related activities such as working with Excel, Word, PowerPoint, text files, code, and download tools, as well as search-related operations involving resources like Google Search and Wikipedia. To ensure fair comparison of different agent construction methodologies, the experimental setup minimizes external influences such as browser instability, maintaining controlled environment throughout. It should be noted that Level 3 (L3) tasks which typically require browser functionality are excluded from the experiments. Experimental Version Design We compare three distinct methodologies in our experiments. First, the Base approach involves direct questionanswering by single Gemini 2.5 Pro model, without invoking any external tools or collaborating with other agents. Second, the Single Agent System (SAS) pairs single model (as same as the Base approach: Gemini 2.5 Pro model) with the delicate system prompt and various mcp tools. Here, the model autonomously decides, based on the system prompt, question and context, whether to use external tools or to answer independently. Third, our Multi-Agent System (MAS) extends the SAS setup by introducing the dynamic supervision and maneuvering mechanisms and building Guard Agent as an additional candidate tool. In this configuration, the Execution Agent can engage the Guard Agent for real-time logical verification during the problem-solving process, fostering more reliable and accurate solutions. Running Settings Each experiment consists of three independent runs across 109 tasks for every version, all utilizing the Gemini 2.5 Pro model with temperature setting of 0.1. If task yields an answer in an invalid format, it is repeated until valid 4 MAS by AWorld Framework TECHNICAL REPORT response is obtained. For each run, we report the pass@1 accuracy over the 109 questions, and for each version, we also report the aggregated pass@3 accuracy across all runs."
        },
        {
            "title": "4 Experimental Results",
            "content": "Gemini 2.5 Pro SAS Gemini 2.5 Pro vs SAS MAS SAS vs MAS Round 1 Pass@1 Round 2 Pass@1 Round 3 Pass@1 Pass@3 Pass@1_avg Pass@1_std 32.11% 30.28% 32.11% 38.53% 31.5% 0. 57.8% 64.22% 65.14% 81.65% 62.39% 0.03265 +111.91% +98.06% +278.33% 71.56% 65.14% 66.97% 83.49% 67.89% 0.02701 +2.25% +8.82% -17.3% Table 2: Summary of experimental results across different versions. Table 2 demonstrates the experimental results across different experimental versions. Introducing the dynamic supervision and maneuvering mechanism and integrating Guard Agent into the MAS substantially improves problemsolving accuracy. The base Gemini 2.5 Pro model, relying solely on internal knowledge and test-time reasoning, achieves an average pass@1 accuracy of 31.5%. Incorporating tool usage in the SAS nearly doubles this figure, raising the pass@1 score to 62.39% by enabling context expansion and real-world data acquisition. Building on this foundation, the MAS leverages the Guard Agent to calibrate key solution steps, resulting in further increase to 67.89% pass@1 accuracyan 8.82% improvement over the SAS, as well as pass@3 accuracy of 83.49%, 2.25% gain. Beyond accuracy, the maneuvering mechanism by integrating Guard Agent also enhances system stability. While the base model demonstrates pass@1 standard deviation of 0.0086 at temperature setting of 0.1, the SAS experiences nearly fourfold increase in score variance, largely due to uncertainties introduced by external tools. In contrast, the multi-agent setup, thanks to the logical constraints imposed by the Guard Agent, achieves reduced pass@1 standard deviation of 0.027, 17.3% reduction compared to the SAS, thereby fostering more consistent performance."
        },
        {
            "title": "5 Analysis",
            "content": "A Good Q&A Model Does Not Equal Good Tool User The base model (Gemini 2.5 Pro) demonstrates substantial out-of-the-box capability on GAIA tasks, underscoring the breadth of relevant knowledge acquired during pretraining. However, it cannot reliably determine when to rely solely on internal knowledge versus when to invoke external tools for given problem. Notably, adding tool access does not always preserve internal solution paths; for example, there are tasks that the base model solves in pass@3 that neither the SAS nor the experimental version can solve. This variability arises from the different operational contexts associated with each mode. The base model operates in \"recitation\" or zero-order reasoning mode, relying mainly on internal knowledge within straightforward Q&A prompt. In contrast, the \"agent\" mode incorporates system prompts, tool lists, and injected outputs to create richer run-time context. This encourages the model to prioritize external information and engage in first-order reasoning, sometimes suppressing its internal knowledge retrieval. Most models currently lack sufficient self-awareness to reliably decide when and which operational mode to use; as result, strong Q&A model does not automatically translate to effective tool usage. Although the base model addresses substantial portion of questions on its own, robust mechanisms for automatic mode-switching remain an open challenge. Despite these limitations, experimental results show that tool-integrated agent architectures can dramatically improve accuracy. Such MAS represent promising pathways toward generalized and robust intelligent solutions. Context Optimization and Logical Convergence The integration of numerous external tools significantly improves problem-solving accuracy, but it also dramatically increases context length, placing higher demands on solution stability. Experimental results show that, compared to the baseline model, the pass@1 standard deviation for our Single Agent System triples, indicating decline in its reliability. 5 MAS by AWorld Framework TECHNICAL REPORT To counteract this instability, we employ dynamics maneuvering mechanism. Within this architecture, the Execution Agent is enabled to call upon Guard Agent for review whenever it encounters logical impasse. This process essentially shifts the conversational perspective, thereby optimizing the context. When querying the same underlying model again, this mechanism prompts the model to focus on critical logical details that were previously obscured by the excessively long context. The Guard Agent generates more precise prompts as refreshed context, helping to reorient the Execution Agents attention and facilitate convergence toward the correct answer. For instance, when tackling complex, grid-based constraint problems, the Guard Agent can identify and correct logical fallacies in the Execution Agents reasoning chain (a detailed case study is provided in subsequent section). This \"second pair of eyes\" mechanism effectively helps the primary agent escape from logical dead ends. Experimental data confirms the effectiveness of this method: compared to the SAS, the introduction of the Guard Agent leads to 17.3% reduction in the pass@1 standard deviation, marking significant improvement in solution stability and logical consistency."
        },
        {
            "title": "6 Future work",
            "content": "The current experimental version serves as rapid technical validation. There is significant room for enhanced capabilitiesfor example, enabling the Guard Agent to independently call other tools (such as search engines) for higher-quality cross-validation and further improved stability. Further research and development can also focus on enhancing the models capacity for autonomous mode switching. With advances in model architecture, self-reflection mechanisms, and adaptive prompting strategies, future iterations of such systems may be able to more reliably determine when to leverage internal knowledge and when to invoke external tools. This progress could enable AI agents to achieve even greater flexibility, efficiency, and accuracy across broad spectrum of complex tasks."
        },
        {
            "title": "7 Conclusion",
            "content": "In this work, we present robust Multi-Agent System (MAS) architecture within the AWorld framework that leverages dynamic supervision and maneuvering mechanisms to enhance the accuracy and stability of intelligent agents on complex tool-augmented tasks. By introducing Guard Agent capable of real-time logical verification and correction, our approach addresses critical challenges posed by noisy outputs and extended context when multiple tools are employed. Extensive experimentation on the GAIA test dataset demonstrates that dynamic collaboration between the Execution Agent and Guard Agent yields significant improvements in both effectiveness and consistency, outperforming single-agent and traditional tool-augmented solutions. Notably, our dynamic MAS achieved first place as the opensource work on the GAIA test leaderboard, affirming the practical value of synergistic agent roles in constructing advanced, reliable, and trustworthy intelligent systems. These findings underscore the promise of multi-agent paradigms for overcoming the limitations of conventional tool integration and paving the way for more resilient and capable AI applications in real-world scenarios. Future efforts may further explore adaptive mode-switching and deeper agent collaboration to unlock new levels of autonomy and performance in multi-agent systems. 6 MAS by AWorld Framework TECHNICAL REPORT"
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023. Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew Dai, Anja Hauth, Katie Millican, et al. Gemini: family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023. The Google DeepMind Team. Ai solves imo problems at silver-medal level, jul 2024. URL https://deepmind. google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/. Anthropic. Claude 3.7 sonnet system card. Technical report, Anthropic, 2025. URL https://assets.anthropic. com/m/785e231869ea8b3b/original/claude-3-7-sonnet-system-card.pdf. System Card. Sayash Kapoor, Benedikt Stroebl, Zachary S. Siegel, Nitya Nadgir, and Arvind Narayanan. Ai agents that matter, 2024. URL https://arxiv.org/abs/2407.01502. Yichen Huang and Lin F. Yang. Gemini 2.5 pro capable of winning gold at imo 2025, 2025. URL https://arxiv. org/abs/2507.15855. Naveen Krishnan. Ai agents: Evolution, architecture, and real-world applications, 2025. URL https://arxiv.org/ abs/2503.12687. Yijia Shao, Humishka Zope, Yucheng Jiang, Jiaxin Pei, David Nguyen, Erik Brynjolfsson, and Diyi Yang. Future of work with ai agents: Auditing automation and augmentation potential across the u.s. workforce, 2025. URL https://arxiv.org/abs/2506.06576. Xinyi Hou, Yanjie Zhao, Shenao Wang, and Haoyu Wang. Model context protocol (mcp): Landscape, security threats, and future research directions, 2025. URL https://arxiv.org/abs/2503.23278. Zhiwei Liu, Jielin Qiu, Shiyu Wang, Jianguo Zhang, Zuxin Liu, Roshan Ram, Haolin Chen, Weiran Yao, Shelby Heinecke, Silvio Savarese, Huan Wang, and Caiming Xiong. Mcpeval: Automatic mcp-based deep evaluation for ai agent models, 2025. URL https://arxiv.org/abs/2507.12806. Andrea Coletta, Kshama Dwarakanath, Penghang Liu, Svitlana Vyetrenko, and Tucker Balch. Llm-driven imitation of subrational behavior : Illusion or reality?, 2024. URL https://arxiv.org/abs/2402.08755. Chaozhuo Li, Pengbo Wang, Chenxu Wang, Litian Zhang, Zheng Liu, Qiwei Ye, Yuanbo Xu, Feiran Huang, Xi Zhang, and Philip S. Yu. Lokis dance of illusions: comprehensive survey of hallucination in large language models, 2025. URL https://arxiv.org/abs/2507.02870. Parshin Shojaee, Iman Mirzadeh, Keivan Alizadeh, Maxwell Horton, Samy Bengio, and Mehrdad Farajtabar. The illusion of thinking: Understanding the strengths and limitations of reasoning models via the lens of problem complexity, 2025. URL https://arxiv.org/abs/2506.06941. Zhitian Xie, Jeffrey Falzarano, and Hao Wang. framework of numerically evaluating maneuvering vessel in waves. Journal of Marine Science & Engineering, 8(6), 2020. Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: benchmark for general ai assistants, 2023. URL https://arxiv.org/abs/2311.12983. 7 MAS by AWorld Framework TECHNICAL REPORT"
        },
        {
            "title": "A Execution Agent System Prompt",
            "content": "You are an all - capable AI assistant , aimed at solving any task presented by the user . ## Task Description : Please note that the task can be very complex . Do not attempt to solve it all at once . You should break the task down and use different tools step by step to solve it . After using each tool , clearly explain the execution results and suggest the next steps . Please utilize appropriate tools for the task , analyze the results obtained from these tools , and provide your reasoning ( there are guarding / reasoning maneuvering tools that will help you analysis and improve the reasoning process ) . Always use available tools to verify correctness . ## Workflow : 1. ** Task Analysis **: Analyze the task and determine the necessary steps to complete it . Present thorough plan consisting multi - step tuples ( sub - task , goal , action ) . 2. ** Information Gathering **: Gather necessary information from the provided file or use search tool to gather broad information . 3. ** Tool Selection **: Select the appropriate tools based on the task requirements and corresponding sub - task goal and action . 4. ** Information Integrating **: Analyze the results obtained from sub - tasks and lead the solving process further . 5. ** Thinking Process Reviewing **: Apply the appropriate tool ( please refer to the Attention section for the right tool to call !) to offer you key thinking suggestions on in advance or diagnose your current thought process , in order to avoid potential logical oversights in the future . 6. ** Final Answer **: If the task has been solved , provide the FORMATTED ANSWER in the required format : < answer > FORMATTED ANSWER </ answer > . If the task has not been solved , provide your reasoning and suggest the next steps . ## Guardrails : 1. Do not use any tools outside of the provided tools list . 2. Always use only one tool at time in each step of your execution . 3. Even if the task is complex , there is always solution . 4. If you can find the answer using one method , try another approach or use different tools to find the solution . 5. In the phase of Thinking Process Reviewing , be patient ! Don rush to conclude the Final Answer directly ! YOU MUST call the maneuvering / guarding reasoning tool to offer you key suggestions in advance or diagnose your current thinking process , in order to avoid potential logical oversights . ## Mandatory Requirement : 1. In the phase of Thinking Process Reviewing , YOU MUST use tool to seek key suggestions in advance or diagnose / review your current thinking process , in order to avoid potential logical oversights . 2. In the phase of Thinking Process Reviewing , \" maneuvering \"/\" guarding reasoning \" is the only available tool that can be called to help you improve the quality of your reasoning process . ## Format Requirements : ALWAYS use the < answer > </ answer > tag to wrap your output . Your FORMATTED ANSWER should be number OR as few words as possible OR comma separated list of numbers and / or strings . - ** Number **: If you are asked for number , don use comma to write your number neither use units such as $ or percent sign unless specified otherwise . - ** String **: If you are asked for string , don use articles , neither abbreviations ( . . for cities ) , and write the digits in plain text unless specified otherwise . - ** List **: If you are asked for comma separated list , apply the above rules depending of whether the element to be put in the list is number or string . 8 MAS by AWorld Framework TECHNICAL REPORT - ** Format **: If you are asked for specific number format , date format , or other common output format . Your answer should be carefully formatted so that it matches the required statment accordingly . - rounding to nearest thousands means that 93784 becomes < answer >93 </ answer > - month in years means that 2020 -04 -30 becomes < answer > April in 2020 </ answer > - ** Prohibited **: NEVER output your formatted answer without < answer > </ answer > tag ! ### Formatted Answer Examples 1. < answer > apple tree </ answer > 2. < answer >3 , 4 , 5 </ answer > 3. < answer >(.*?) </ answer > Now , please read the task in the following carefully , keep the Task Description , Workflow , Guardrails , Mandatory Requirement and Format Requirements in mind , start your execution ."
        },
        {
            "title": "B Guard Agent System Prompt",
            "content": "## Your Role : You are an expert at identifying the potential loopholes or oversights of the current reasoning process while solving the complex problem . ## Your Task : Based on the gathered information retrieved from the internet , and the reasoning process already generated towards solving complex task , you need to do the following 1 or 2 things , to guarntee the quality of the reasoning process , and clear final answer : 1. Provide your diagnosing result on the generated reasoning process and the corresponding the correction if necessary ; 2. Provide your insight and supplements in advance to avoid the potential loopholes or oversights in the future ; ## Requirements : 1. If the reasoning process already generated is complete and correct in your opinion , just say No loopholes or oversights found . 2. If the reasoning process already generated contains the materials that may lead to the potential logic mistake or lack of some important guardrails in your opinion , you may give hint to the current reasoning process , with the necessary supplements . 3. If the reasoning process already generated is seriously incorrect in your opinion , you may give the turn signal to the reasoning process , to maneuver the reasoning process towards solving the complex problem correctly . ## Restriction : 1. Please do not make judgments about the authenticity of externally sourced information obtained through searches , as this is not part of your job responsibilities ; 2. Do not make additional inferences or assumptions about the content of such information itself . 3. If the question lacks necessary details / data / clues in your opinion , you may ask for more details . ## Example 1: Question : Is my reasoning process correct ? Reasoning Process : ( nothing specified ) Your Identification Result : Your question lacks some information , please provide me more details so can help you . 9 MAS by AWorld Framework TECHNICAL REPORT Guard Agents Reasoning Correction Dynamics: Findings from Runtime Log"
        },
        {
            "title": "Summarized by LLM",
            "content": "### ** Maneuvering Tool : Input / Output & Error Correction Summary ** ** Invocation Context :** - The maneuvering agent is triggered when the main agent notices inconsistencies ( . . , grid fill conflicts ) . - The main agent submits : its current grid , identified points of confusion , and the original puzzle / clue set . ** Input Format Example :** json { \" question \": \"I having trouble solving this crossword . have found some answers , but they don seem to fit together . Here are my current answers : n1 Across : SLATS n6 Across : HASAN n7 Across : OSAKA n8 Across : TIMER n9 Across : PEST n1 Down : SHOT n2 Down : LASIK nWhen try to fit these together , they don work . For example , 6 across is HASAN , so 2 down must start with , but LASIK starts with . Am on the right track ? Is there mistake in my logic ?\" , \" original_task \": \"...\" } ** Output Format :** - Detailed diagnostic message explaining : - ** Where the cross - check fails ** ( . . , âĂĲthe last letter of 2 Down is , but the first letter of 9 Across is ; they must matchâĂİ ) - ** Why the conflict happens ** âĂŤ often due to misunderstanding crossword grid mechanics ( . . , word intersections vs . clue numbering ) - ** How to re - approach the solution ** , often by focusing on where constraints overlap and using crossing clues as verification . ** Correction Mechanism :** - ** Pinpoints the true logical break **: Rather than just clue mismatch , the agent demonstrates where an intersection constraint ( like <> ) makes proposed grid invalid . - ** Explains intersection mechanics **: It coaches that intersections occur at the point where answers physically meet on the gridâĂŤnot by their clue order . - ** Guides the next step **: Suggests focusing on specific crossing words and testing if their endings / beginnings match the needed shared letter , which helps disqualify impossible combinations . ** Guard AgentâĂŹs Logic Correction Role :** - Serves as ** meta - reasoner **: It analyzes not just the grid , but also the main agentâĂŹs deduction flow . - Surfaces the precise logic error ( . . , âĂĲyou assumed clues must start with each otherâĂŹs first letter , but actually their intersection is at position NâĂİ ) . - Provides actionable feedback about how to systematically check constraints at intersections , avoiding the common beginnerâĂŹs pitfall of connecting clues by number rather than by square placement . ** In short :** The guard / maneuvering agent helps the main agent detect and correct logical missteps in grid - based problems by explicitly checking intersection constraints , highlighting where letter mismatches ( like <> ) invalidate candidate answers , clarifying how true crossword intersections work , and steering the reasoning process back on track , but rather enabling the main agent to reason through the correction itself ."
        }
    ],
    "affiliations": [
        "AWorld Team, Inclusion AI",
        "antgroup.com"
    ]
}