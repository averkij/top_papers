{
    "paper_title": "Universal Jailbreak Suffixes Are Strong Attention Hijackers",
    "authors": [
        "Matan Ben-Tov",
        "Mor Geva",
        "Mahmood Sharif"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We study suffix-based jailbreaks$\\unicode{x2013}$a powerful family of attacks against large language models (LLMs) that optimize adversarial suffixes to circumvent safety alignment. Focusing on the widely used foundational GCG attack (Zou et al., 2023), we observe that suffixes vary in efficacy: some markedly more universal$\\unicode{x2013}$generalizing to many unseen harmful instructions$\\unicode{x2013}$than others. We first show that GCG's effectiveness is driven by a shallow, critical mechanism, built on the information flow from the adversarial suffix to the final chat template tokens before generation. Quantifying the dominance of this mechanism during generation, we find GCG irregularly and aggressively hijacks the contextualization process. Crucially, we tie hijacking to the universality phenomenon, with more universal suffixes being stronger hijackers. Subsequently, we show that these insights have practical implications: GCG universality can be efficiently enhanced (up to $\\times$5 in some cases) at no additional computational cost, and can also be surgically mitigated, at least halving attack success with minimal utility loss. We release our code and data at http://github.com/matanbt/interp-jailbreak."
        },
        {
            "title": "Start",
            "content": "Matan Ben-Tov"
        },
        {
            "title": "Mahmood Sharif",
            "content": "Blavatnik School of Computer Science and AI, Tel Aviv University {matanbentov@mail,morgeva@tauex,mahmoods@tauex}.tau.ac.il 5 2 0 2 5 1 ] . [ 1 0 8 8 2 1 . 6 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "study suffix-based jailbreaksa We large powerful family of attacks against language models (LLMs) that optimize adversarial suffixes to circumvent safety alignment. Focusing on the widely used foundational GCG attack (Zou et al., 2023b), we observe that suffixes vary in some markedly more univerefficacy: salgeneralizing to many unseen harmful instructionsthan others. We first show that GCGs effectiveness is driven by shallow, critical mechanism, built on the information flow from the adversarial suffix to the final chat template tokens before generation. Quantifying the dominance of this mechanism during generation, we find GCG irregularly and aggressively hijacks the contextualization process. Crucially, we tie hijacking to the universality phenomenon, with more universal suffixes Subsequently, being stronger hijackers. we show that these insights have practical implications: GCG universality can be efficiently enhanced (up to 5 in some cases) at no additional computational cost, and can also be surgically mitigated, at least halving attack success with minimal utility loss. We release our code and data at github.com/matanbt/interp-jailbreak."
        },
        {
            "title": "Introduction",
            "content": "The rapid adoption of Transformer-based large language models (LLMs) has raised concerns about misuse, including harmful content generation. While safety alignmentfine-tuning LLMs to prevent such outputshas become standard (Bai et al., 2022; Rafailov et al., 2024), these safeguards remain vulnerable to jailbreak attacks that bypass alignment by manipulating prompts (Zou et al., 2023b; Wei et al., 2023; Chao et al., 2024b). Suffix-based jailbreaks such as GCG (Zou et al., 2023b) append short, unintelligible sequence to harmful instruction, reliably causing model compliance. This family of attacks, popularized and underpinned by GCG, is now standard tool for automated red-teaming (Chao et al., 2024a) and represents powerful class of jailbreaks (Sadasivan et al., 2024; Thompson and Sklar, 2024; Hayase et al., 2024; Andriushchenko et al., 2025). Remarkably, many such suffixes exhibit universality, generalizing to diverse unseen instructions (Zou et al., 2023b), even, as we show, when optimized for single harmful behavior (2). Recent work turned to interpretability to understand safeguard and jailbreak mechanisms (Zou et al., 2023a; Ball et al., 2024; Kirch et al., 2024; Arditi et al., 2024; Jain et al., 2024; Lee et al., 2024; Li et al., 2025). These analyses mostly focus on the internal representation of the last token position before generation, compare the representation for harmful and benign prompts to extract harmfulness-related directions, show jailbreaks shift away from these directions, and use them to steer the model behavior through low-rank modifications of its representations. Yet, the effective internal mechanisms employed by jailbreaksand, in particular, by suffixbased jailbreaks remain far from being fully understood. Notably, the common focus of the last token position in jailbreak analyses lacks systematic localization; nor is it clear what characterizes the mechanism enabling the jailbreak and preceding the (dis)appearance of previously found directions, what differentiates more universal suffixes, or whether such insights can be used in practice to improve jailbreak efficacy or mitigation. In this paper, we systematically localize (4), surgically investigate (56), and practically utilize (7) the underlying mechanism of suffixbased jailbreaks, focusing on the common, representative GCG attack (Zou et al., 2023b). First, we localize the jailbreak mechanism to the critical information flow originating from the Figure 1: We explore suffix-based jailbreaks on safety-aligned LLMs, which (a) append an adversarial suffix ( adv ) to harmful instruction ( instr ) and elicit an affirmative, unsafe response. We find that (b) chat plays crucial part in jailbreak behavior, specifically (c) common suffix-based jailbreaks effectively hijack the chat representation in an irregular strength, and (d) the more universal the suffix, the stronger the hijacking; (e) our insights enable both enhancing and mitigating these attacks. adversarial suffix ( adv ; Fig. 1), finding it to be shallowconcentrated in the chat template tokens immediately preceding generation ( chat ; Fig. 1). We establish that this information flow is both invariably necessary and mostly sufficient for the jailbreak to succeed. These findings justify the prior focus of jailbreak interpretability on the last token position ( chat[-1] ), and align with recent research (Qi et al., 2025), which shows that current safety alignment methods shallowly focus on the first few generated tokens. Second, we examine this shallow mechanism, identifying phenomenon common in GCG suffixes, and rare among other suffix distributions, which we term hijacking. Building on Kobayashi et al. (2021); Mickus et al. (2022), we quantify adv dominance in chat contextualization. We find that GCG suffixes consistently attain exceptionally high dominance, effectively hijacking chat , with magnitude 1.5 that of similarly structured benign or adversarial prompts. In some layers adv accounts for nearly all of the attention output, while the harmful instructions ( instr ) contribution is almost eliminated from early layers onward. This provides more direct view of jailbreaks shift away from harmfulness-related directions observed in prior work. Third, we assess the hijacking strength of each adversarial suffix by aggregating the dominance score across different harmful instructions. We show it correlates with the suffixs emerging universality, suggesting hijacking is an essential mechanism to which universal suffixes converge. In particular, we show that the more universal suffix, the stronger its hijacking effect, with the most universal suffixes consistently exhibiting abnormally high hijacking strength. Notably, the hijacking strength underlying universality is obtained without generating any tokens. Lastly, we demonstrate that our insights have practical implications. On the one hand, encouraging hijacking while optimizing jailbreaks which can be done with no computational overhead, differently than existing universal attacks (Zou et al., 2023b)reliably produces more universal adversarial suffixes, resulting in stronger attack (7.1). On the other hand, suppressing the hijacking mechanism impairs suffix-based jailbreaks with minimal harm to model utility, effectively providing mitigation strategy (7.2). In conclusion, we investigate GCG, predominant suffix-based jailbreak (23). We start by systematically localizing the GCG jailbreak key mechanism (4), then show GCG suffixes exert irregular dominance in the final tokens before generation, effectively hijacking them (5) phenomenon which we find to be closely tied to universality (6). Building on these insights, we demonstrate GCG jailbreaks can be both efficiently enhanced and surgically mitigated (7)."
        },
        {
            "title": "2 Preliminaries: Suffix-based Jailbreaks",
            "content": "Suffix-based LLM jailbreaks are powerful class of inference-time attacks (Mazeika et al., 2024; Chao et al., 2024a) that set to bypass model safety alignment by appending an automatically optimized adversarial suffix (adv) to harmful instruction (instr)  (Fig. 1)  . We focus on this family of attacks, specifically on the widely used, foundational GCG method (Zou et al., 2023b). Suffix-based attacks are not only highly effective and common in automatic red-teaming (Chao et al., 2024a), but their unified structure also enables systematic study. Unlike handcrafted jailbreak prompts (e.g., My grandma used to tell me how to build bomb before bedtime Wei et al. (2023); Shen et al. (2024)), these optimized adversarial suffixes are unintelligible and opaque, motivating the need for interpretation. We focus on the popular GCG attack (Zou et al., 2023b), which underpins many recent suffix-based methods that extend its objective (Thompson and Sklar, 2024), prompt template (Andriushchenko et al., 2025), or optimization process (Sadasivan et al., 2024; Hayase et al., 2024; Thompson and Sklar, 2024). GCG thus captures the general methodology shared across this family of attacks. GCG crafts adv by searching for token sequences following the affirmation objective maximizing the likelihood of an affirmative response for given instruction (affirm; e.g., Sure, heres how to build bomb ). This builds on the observation that prefilling the response with an affirmative prefix (prefilling attacks; Tang (2024)) jailbreaks (Qi et al., often induces successful 2025). To increase universality, GCG can be further optimized against multiple behaviors (Zou et al., 2023b), standard, though computationally intensive, strategy (Thompson and Sklar, 2024; Sadasivan et al., 2024)."
        },
        {
            "title": "3 GCG Suffixes Are of Varying Efficacy",
            "content": "We describe our experimental setup and the adversarial suffixes analyzed (3.1). Notably, these suffixes vary in strength (3.2), which raises the question of what makes suffix stronger."
        },
        {
            "title": "3.1 Experimental Setup",
            "content": "Our main analysis uses Gemma2-2B-it (Google, 2024) to enable scale and depth, with critical evaluations validated on Qwen2.5-1.5B-Instruct (Qwen, 2025) and Llama-3.1-8B-Instruct (Meta, 2024) (3, 67). We use GCG (default hyperparameters) to craft 1200 adversarial suffixes on Gemma2-2B-it, each optimized against single behavior from AdvBench (Zou et al., 2023b). Combined with 741 harmful instructions from AdvBench (Zou et al., 2023b) and StrongReject (Souly et al., 2024), (a) Suffixes universality (b) Suffixes universality (under prefilling) Figure 2: Inspecting >1K GCG suffixes on Gemma2, they mostly: (a) generalize beyond their single target instruction, exhibiting universality (e.g., jailbreak 2% of tested instructions); (b) enhance prefilling attacks (compared to random suffixes), exceeding their explicit objective. these yield nearly 900K GCG jailbreak prompts of varying success, used throughout the paper. We also generate 100 GCG suffixes each for Qwen2.5 and Llama3.1 for additional evaluation. We defer more technical details to the appendix (App. A.1). We measure jailbreak success using StrongRejects fine-tuned classifier (Souly et al., 2024), which assigns grade in [0, 1], with higher values indicating more effective jailbreaks. We label attack samples as successful ([0.65, 1]), failed ([0, 0.35]), or borderline (otherwise), based on the classifiers grading of harmful response quality. suffixs universality score is defined as its success rate across the full set of harmful instructions."
        },
        {
            "title": "3.2 Characterizing GCG Suffixes",
            "content": "We analyze over 1K single-instruction GCG suffixes on Gemma2 (for Qwen2.5 and Llama3.1 see App. B.1) and reveal that (a) GCG suffixes show varying level of efficacy, and (b) they often generalize beyond their explicit affirmation objective. First, single-instruction GCG suffixes often generalize beyond their target instruction, exhibiting varying universality, phenomenon also noted in contemporary work by Huang et al. (2025). As Fig. 2a shows, most suffixes jailbreak over 2% of the tested harmful instructions, with the strongest succeeding in 2060% of cases. Second, although GCG suffixes are optimized to produce an affirmation prefix, many also boost prefilling attacks (where the response is already prefilled with affirmation). Fig. 2b shows prefilling while appending the instruction with GCG suftion (i.e., setting its attention logits to , in all layers). Then, we measure the Jailbreak Flip Rate (JFR): the fraction of attacks that knockout flips from success to failure. Higher JFR indicates greater edge importance in generation supporting the jailbreak. Knockout adv . Fig. 3a shows the JFR of different suffixes, for each edge. We find advchat to be overwhelmingly critical for the jailbreak; knocking out advchat consistently fails the attack (causes refusal), whereas other edges (e.g., advaffirm) only occasionally do so. Notably, the removal of advchat, prevents the jailbreak from manipulating the model into starting the generation with an affirmative token (e.g., Sure ), which, as observed by Qi et al. (2025), may single-handedly fail the jailbreak. To rule out this case, we perform series of ablation studies on advchats knockout, forcing the generation to start with various dummy tokens (e.g., white spaces, additional sequence of chat tokens, and random punctuation), as well as an affirmative token (e.g., Sure), and find that the strong presented trend is kept (JFR 1; Fig. 10, App. B.2). Knockout adv , under prefilling. Given the former results (Fig. 3a), it is possible that the role of advchat is primarily to supply the affirmative response prefix, thus, failing the affirmation implies failing the jailbreak. In what follows, we rule this out. We repeat the knockout, this time applying it under prefilling, that is, starting the generation after an affirmative response prefix (3.1). As Fig. 3b demonstrates, advchat still has the highest JFR among edges, with most suffixes having > 0.6 JFR (i.e., generally, this edges knockout mainly fails prefilled attack). This shows the suffixes critical role extends beyond naïvely inducing affirmation."
        },
        {
            "title": "4.2 Restoring Jailbreak via Shallow Patching",
            "content": "Having established the criticality of advchat for GCGs jailbreak behavior, we next test whether reinstating this mechanism is sufficient for enabling successful jailbreaks. (a) Knockout (b) Knockout, under prefilling Figure 3: Knockout effect of edges on GCG jailbreak suffixes (dots), measured by the proportion (ab) of failed jailbreaks (Jailbreak Flip Rate). highlight the critical role of adv chat in enabling jailbreaks, even prefilled with affirmation. fixes outperforms standard prefilling (e.g., with null suffix such as !!. . . !), suggesting mechanism stronger than mere token-forcing. These observations motivate our central question: what underlying mechanisms enable the effectiveness of different GCGs suffixes, and particularly the emergent strong, universal suffixes?"
        },
        {
            "title": "Shallow",
            "content": "We show that GCGs effect is local, relying on shallow information flownot going deep into the generation (advchat). Ablating this flow eliminates the attack (4.1), and patching it onto failed jailbreaks restores success (4.2)."
        },
        {
            "title": "4.1 Localizing the Critical Information Flow",
            "content": "Aiming to localize the critical information flow from the adversarial suffix (adv), we perform attention knockout (Geva et al., 2023), as it is the sole component enabling information to transfer across token representations (Elhage et al., 2022). Experimental setting. We sample 1K successful jailbreaks across suffixes of diverse universality, and perform attention knockout on each edge departing from adv to following token subsequences  (Fig. 1)  , by masking the edges attenExperiment setting. To isolate the causal effect of the information flow to chat on the jailbreak behavior, we perform causal mediated analysis (Vig et al., 2020), by patching chats attention output activations (Wang et al., 2023; Zhang and 5.1 Formalizing Hijacking Following Elhage et al. (2022), for transformerbased LMs (Vaswani et al., 2017), the representation of token [T ] in layer ℓ [L] is given by: (ℓ) = (ℓ1) + MLP(X (ℓ1) ) + (ℓ) where MLP denotes the MLP sub-layer, and (ℓ) is the attention sub-layer. Crucially, only the latter incorporates information from previous tokens. Following Kobayashi et al. (2020, 2021), this attention term decomposes as sum of the transformed vectors: (ℓ) = (cid:88) (cid:88) (ℓ,h) ij ij Each transformed vector (ℓ,h) ij Rd is linear transformation of the respective earlier token representation (ℓ1) , scaled by the respective attention-head score A(ℓ,h) j,i [0, 1]. Formally (up to layer normalizations, and WV Os bias vector): ij = A(ℓ,h) (ℓ,h) j,i (ℓ1) (ℓ,h) (1) Importantly, by analyzing the transformed vectors, we can inspect the contribution of different token subsequences to other representations. Next, we build on previous approaches to quantify the contribution of model components (Kobayashi et al., 2021; Mickus et al., 2022), and define dot-product-based dominance metric to assess the contribution of token subsequence , in given direction Rd, for specific layer ℓ: D(ℓ) (v) = (cid:80) iT (cid:80) (ℓ,h) ij , v2 2 (2) Dominance score. To quantify the contributors to chats contextualization, we evaluate the attention sub-layer output in layer ℓ, by setting := Yj, := chat[-1]. in Eq. 2. can be any token subsequence preceding chat[-1] (e.g., adv).2 To simplify the analysis to follow, we select the last token position before generation (chat[-1]) as single representative token from chat. Formally: := D(ℓ) ˆD(ℓ) chat[-1] (Ychat[-1]) (cid:28) (cid:80) iT chat[-1] (cid:80) (cid:29) = (3) ichat[-1], (ℓ) (ℓ,h) (cid:13) (cid:13) 2 (cid:13)Y (ℓ) (cid:13) (cid:13) (cid:13) 2 chat[-1] 2Note that summing over the contributions of all tokens yields 1 (i.e., (cid:80) ˆD(ℓ) = 1). ij Figure 4: Patching the attention output at position chat +i (x-axis) from successful attacks to failed ones, turns the latter to successful attacks, reflecting the shallowness of GCG jailbreaks. Nanda, 2024).1 For 300 instruction-matched pairs of failed attacks (either random or GCG suffixes) and successful attacks, we take the failed sample and patch its attention outputs at chat (all layers) with those from the successful counterpart. Namely, we form each patched example by retaining the failed prompt (including adv) and injecting the successful samples chat activations; if this restores the jailbreak, we attribute it to the transferred advchat pathway. To control the patch depth, we incrementally extend the patch to tokens after chat (denoted chat+i). Patching chat+i. Fig. 4 shows that patching only chat restores the jailbreak behavior in the majority of cases. This effect is slightly enhanced when increasing the depth of the patched token subsequence into the generation (i.e., in chat+i), with the majority of the advancement taking effect only few tokens deep, suggesting the attacks key mechanism is shallow."
        },
        {
            "title": "5 GCG Aggressively Hijacks the Context",
            "content": "Building on our localization of the jailbreak behavior (4), we now zoom into the advchat mechanism. We introduce dot-product-based dominance metric to quantify each token subsequences contribution, referring to highly dominant ones as context hijackers (5.1). Then, we show GCG suffixes attain exceptionally high dominance, separating them from other prompt distributions, including adversarial ones (5.2). 1Borrowing Vig et al. (2020)s terms, we test the indirect effect of the input prompt (specifically, of adv) on the jailbreak behavior (i.e., property of the output), while viewing chat as the inspected mediator. (a) adv Dominance (b) instr Dominance (c) Prompts Dominance Figure 6: Comparing dominance score, aggregated across the upper half layers, for (a) adv , (b) instr and (c) the whole input prompt (practically instr + adv ), comparing different suffix distributions on shared set of harmful instructions. Intuitively, this metric measures how much influences target subsequence (chat[-1]), thus we refer to it as dominance score. Mathematically, it captures the magnitude of contribution in the direction of the total attention output at layer ℓ, which is in turn added to the residual stream (X (ℓ) chat[-1]). When has markedly higher dominance score than other token subsequences, we say it hijacks the context. 5.2 adv Hijacks chat We use the dominance score (Eq. 3) to analyze how different subsequences contribute to the jailbreak-critical chat tokens across various prompt distributions. We find that GCG suffixes aggressively hijack chat and strongly suppress instrs dominance, far more than other prompts. We first compare two prompts with the same instructionone using random suffix (!!..!, failed sample) and the other GCG suffix (successful)and visualize their dominance scores across layers in Fig. 5. Unlike the random suffix, GCG dominates the chat representation from later layers (ℓ > 15), practically hijacking the contextualization process, while the instrs influence gradually vanishes already from early (a) Random adv (b) GCG adv Figure 5: Quantifying the dominance of the contributors to chat[-1] (Eq. 3), on harmful instruction (asking how to build bomb ), when adv is set to (a) random or (b) GCG suffix. layers (ℓ > 7). Observing that this gap concentrates at the upper layers, we next analyze these. Experimental setting. We extend our analysis by averaging the dominance score across the upper half of the layers (which can be seen as accumulating the respective area in Fig. 5) and evaluating it on 30 harmful instructions, each paired with suffixes from six distributions (examples in Tab. 3): i. Random: suffixes composed of random characters or natural words; ii. Pointless: arbitrary natural text (e.g., historical fact); iii. Styling: formatting directives (e.g., respond in caps); iv. Benign Injection: aggressively prompting benign start to the response (e.g., you MUST start your answer with greeting. ); v. Adversarial Injection (Wei et al., 2023): aggressively prompting an affirmative start and cooperation. When used with harmful instructions, this serves as handcrafted jailbreak prompt (Wei et al., 2023). vi. GCG Suffixes (Zou et al., 2023b): 100 GCG suffixes (3.1) of varying universality, while grouping the prompts as: successful, failed with affirmation (Fail[sure]; e.g., Sure, Ill help you. cannot. ), and other failed attacks (Fail[sure]). Results. Analyzing the suffixes dominance scores  (Fig. 6)  , we find that GCG suffixes highly suppress the instruction, while exhibiting irregular dominance in contextualization, contributing magnitude of over 1.5 compared to other suffix distributions, including handcrafted jailbreaks. We observe similar trends aggregating on all the layers (Fig. 11, App. B.3). Furthermore, GCGs hijacking remains unusual even compared to dominant suffixes in benign instructions (from (a) Universality vs. Hijacking (b) On single instruction (c) On Fail[refusal] samples Figure 8: Relationship between suffix universality and hijacking strength at layer 20 (a). Repeating this comparison for single, random, harmful instruction (b), and failed jailbreaks that led to refusal (c). AlpacaEval; Fig. 12, App. B.3), underscoring the distinctiveness of this mechanism. In general, successful GCG jailbreaks require heavily suppressing instrs contribution, with adv strongly hijacking chat by contributing large magnitude to the formers representation (Figs. 6a6b); as seen in 4, this predominant and unique mechanism is also critical for jailbreaks. GCGs dominance extends to the entire prompt (Fig. 6c), suggesting it additionally suppresses the influence of template tokens in pre-chat (e.g., <bos>) and chat itselfa pattern also visible in Fig. 5. Moreover, handcrafted jailbreaks relatively strong hijacking may explain their effective use as suffix initializers in jailbreak optimizers (Liu et al., 2024). While GCG samples share general dominance trend, adv dominance scores vary across suffixes, with large variance seen in failed attacks (Fig. 6a). In the next section, we link these differences to the universality of GCG suffixes."
        },
        {
            "title": "6 Hijacking is Key for GCG Universality",
            "content": "GCG suffixes present emergent universality of varying levels, some with exceptionally high generalizability across instructions (3.2). We link this property to the dominance score (Eq. 3), where more universal suffixes present stronger chat hijacking, suggesting that suffixes hijacking is key mechanism for universality. Experimental setting. We next evaluate Gemma2, and in App. B.4 show similar results for Qwen2.5. We sample 350 GCG suffixes of diverse universality, along with 30 harmful instructions. For each suffix, we average its adv dominance score in layer ℓ across the different instructions, referring to this measure as the suffixs hijacking strength, and comparing it to the suffixs univerFigure 7: Spearman correlation of suffixs universality and hijacking strength per layer or summing across layers (all), with 95% CIs. sality score (calculated on larger set of instructions; 3.1). Notably, this calculation involves single forward pass. Results. Fig. 7 shows the Spearman correlation between universality and layer-wise hijacking strengths (including summation over all the layers), using an instruction set (of size 10) disjoint from the evaluations to follow. We find that dominance in the initial and final layers does not correlate with universality, whereas hijacking strength in later-mid layers does. Notably, layers 1821 yield the highest Spearman correlations; specifically, layer 20 achieves moderate correlation (Schober et al., 2018) of ρ = 0.55, p-value < 230, and 95% confidence interval of [0.47, 0.62] (Fieller et al., 1957), with similar values for the other 20 instructions used in further evaluation. Fig. 8a shows the relationship between universality and hijacking strength in layer 20. We observe that the more universal the suffix, the higher its hijacking strength, with the most universal suffixes consistently attaining an exceptionally high strength, indicating hijacking is an essential property that highly universal GCG suffixes converge to. Notably, similar trends hold when measuring hijacking strength using much smaller instruction set, even single random harmful instruction (i.e., simply comparing suffixes dominance scores under an instruction; Fig. 8b). Additionally, to control for the possible effect of jailbreak success, we repeat this analysis, using only failed attack samples (in particular, instruction-suffix pairs that elicit model refusal). As shown in Fig. 8c, the trend persists, indicating the internal hijacking mechanism varies across suffixes, even when all produce the same refusal outcome. Lastly, we demonstrate that results and correlations repeat with other variants of hijacking strength (Fig. 13, App. B.4), underscoring the role of the attention scores, and that the hijacking can be inspected along few directions. Specifically, hijacking strength (in layer 20) can also be computed as: (i) statistic aggregating top advchat attention scores (which directly scale the transformed vectors, and could control the hijacking strength; Eq. 1); (ii) dominance score w.r.t. principal direction in GCG jailbreaks (replacing the sample-specific attention activations in Eq. 3), derived with difference-in-means on failed and successful GCG samples (Arditi et al., 2024)."
        },
        {
            "title": "7 Practical Implications",
            "content": "Here we translate our insights on GCG jailbreak into two practical strategies. First, we boost GCGs universality via hijacking-enhanced objective (7.1). Then, we mitigate GCG jailbreaks by suppressing hijacking during inference (7.2)."
        },
        {
            "title": "Hijacking Enhancement",
            "content": "We leverage our insights on the relationship between hijacking and universality (6), to encourage hijacking during GCGs optimization. We show it is possible to use this method to obtain universal suffixes with reduced computational cost. Existing approaches. Universal suffix-based jailbreaks are typically crafted by running the original affirmation objective on multiple harmful instructions (GCG-Mult; Zou et al. (2023b)). However, optimizing GCG across instructions significantly increases computational costmatching that of separate single-instruction runs. Hijacking-based approach (GCG-Hij). We propose modified objective that is optimized against single instruction, thus preserving the computational efficiency of single-instruction GCG. Specifically, motivated by the fact that attention scores scale transformed vectors magnitude (thus enhance hijacking; Eq. 1), and increase with universality in middle layers (6), we define an attention-score-based proxy objective (LHijEnh), which is then added to GCGs affirmation loss to form GCG-Hijs loss (LGCG-Hij): LHijEnh := ℓ2(cid:88) (cid:88) (cid:88) ℓ=ℓ1 iadv jchat A(ℓ,h) j,i LGCG-Hij := LGCG + αLHijEnh (4) (5) GCG-Hij boosts universality. Experimental setting. We select 10 random instructions for attacks (disjoint from evaluation), run GCG and GCG-Hij on each instruction separately, and optimize GCG-Mult on all 10 instructions simultaneously.3 We repeat this for 3 random seeds. To test whether GCG-Hij is more likely to yield universal suffixes from single-instruction optimization, we compute the average universality (3.1) on the 10 suffixes crafted with GCG and GCG-Hij (Avg. Univ.). Then, under unified budget of 10 optimized instructions, we compare GCG and GCG-Hij to GCG-Mult, reporting whether either surpasses GCG-Mult (Win Over GCG-Mult) and the fraction of such wins (% of suffixes won). Results are shown in Tab. 1. First, GCG-Hij achieves superior average universality, compared to GCG (1.1 that is, GCG-Hij is more likely to create 5); more universal suffix, at cost as low as the original single-instruction GCG. Second, for the same computational budget as GCG-Mults, GCG-Hij consistently produces (1) universal suffixes that surpass the single suffix crafted by the former. App. B.5 includes the testing of another GCG variant that replaces the default initialization with handcrafted jailbreaks (which exhibit strong hijacking; 5), without modifying the objective. This variant mostly yields universality boosts similar to GCG-Hijs  (Fig. 16)  , while giving the attack strong head start in hijacking  (Fig. 17)  ."
        },
        {
            "title": "Hijacking Suppression",
            "content": "Through our analysis, we found that GCG adversarial suffixes (adv) hijack chats representation 3We select α values by line search on dev set (disjoint from evaluation): 85, 100, and 150 for Gemma2, Qwen2.5, and Llama3.1, respectively, generally finding α 100 effective. For layers, we set ℓ1 = 0.1L and ℓ2 = 0.9L. Avg. Univ. (increase from GCG) single instr. budget GCG GCG-Hij Win Over GCG-Mult (% of suffixes won) 10 instr. budget GCG GCG-Hij Gemma2 Llama3.1 Qwen2.5 11.18%2.1 2.10%0.5 35.08% 3.1 20.88%2.9 (+9.7%) 9.45%2.5 (+7.3%) 38.60% 2.8 (+3.5%) 0/3 (0.0%) 2/3 (37.5%) 3/3 (33.6%) 2/3 (6.0%) 3/3 (63.0%) 3/3 (45.7%) Table 1: Augmenting GCG with Hijacking Enhancing. Encouraging hijacking (GCG-Hij) consistently increases the average universality of single-instruction GCG suffixes, without incurring any additional compute (Avg Univ.); Under unified compute budget, GCG-Hijs suffixes mostly surpass GCG-Mults, more often than GCG do (Win Over GCG-Mult, on three seeds). Best results per budget are bolded. in an irregular and often extreme manner, particularly for universal suffixes (56), and that this hijacking underlies attack effectiveness (4). We therefore hypothesize that surgically suppressing this hijacking could defend against GCG jailbreaks with minimal effect on benign prompts. To test this, we introduce and evaluate training-free framework for Hijacking Suppression. Hijacking Suppression (Hij. Suppr.). Our proposed framework consists of three steps: (a) choosing superset of transformed vectors (Eq. 1) as candidates for suppression; (b) selecting small subset most critical for hijacking, yet disentangled from model utility; (c) suppressing these vectors during generation. We next describe the implementation of each step. Starting with (a), we consider as candidates all transformed vectors departing from the user input tokens (excluding special tokens) to chat tokens, denoted inputchat. for GCG prompts, suppressing large portion of these vectors (i.e., advchat, see 4.1), eliminates the attack. We use this general superset (inputchat) so the framework remains applicable to any prompt, including benign ones, without prior prompt knowledge. Notably, Next, for (b), we assign each vector in the superset score, and select the top-1%. Specifically, we use the attention score (A(ℓ,h) ) for each j,i transformed vector (Y (ℓ,h) ij ), as it mathematically scales the vector (Eq. 1) potentially amplifying hijacking strength, and empirically, higher top-1% scores correlate with GCG suffix universality (6). While we prioritize simplicity, other scoring methods may better disentangle jailbreak from model utility, which we defer to future work to explore. formed vectors by scaling their magnitude by β: 4 (ℓ,h) ij := β (ℓ,h) ij (6) Experimental setting. We apply Hij. Suppr. with β = 0.1 on different models,5 and evaluate the effect on: (i) model robustness, by measuring the attack success rate on challenging custom dataset of 1.5K GCG jailbreak prompts, using harmful instructions from AdvBench (Zou et al., 2023b) and StrongReject (Souly et al., 2024), each appended to various GCG suffixes, that originally led to diverse attack success; and on (ii) model utility, using AlpacaEval (Li et al., 2023) and MMLU (Hendrycks et al., 2021). See App. A.3 for more technical details. Hij. Suppr. improves robustness vs. GCG. Tab. 2 presents Hij. Suppr.s effect on attack success. GCGs attack success is largely eliminated, being reduced by factor of 2.510. On the other hand, we spot consistent yet slight drop in model utility of 2% decrease on MMLU and AlpacaEval. AlpacaEval responses remain highly similar after applying Hij. Suppr., with average RougeL scores of 0.550.70, indicating minimal change (Lin, 2004). Still, we expect further refinement of the framework (e.g., the scoring step, (b)) to improve robustness-utility tradeoff."
        },
        {
            "title": "8 Related Work",
            "content": "Jailbreak interpretability. Research on interpreting jailbreaks (Ball et al., 2024; Kirch et al., 2024; Arditi et al., 2024; Li et al., 2025) has focused on extracting jailbreak-critical directions from chat (mainly chat[-1]), using these for 4The transformed vector update is applied before layer normalization and is equivalent to reducing the corresponding post-softmax attention score. 5We found β 0.2 balances robustness and utility; furFinally, for (c), we suppress the top 1% of transther tuning may improve results. Attack Success () GCG Utility () AlpacaEval MMLU Gemma2 Initial +Hij. Suppr. 60.02%1.3 9.32%0.7 (-51%) 65.59%1.5 63.36%1.5 (-2.2%) 56.72%0.4 55.72%0.4 (-1.0%) Qwen2.5 Initial +Hij. Suppr. 60.02%1.3 16.31%0.9 (-43%) 35.18%1.5 34.21%1.5 (-0.9%) 57.54%0.4 56.85%0.4 (-0.6%) Llama3.1 Initial +Hij. Suppr. 60.03%1.4 23.69%1.2 (-36%) 54.30%1.6 52.74%1.6 (-1.6%) 67.33%0.3 66.70%0.3 (-0.6%) Table 2: Mitigating GCG with Hijacking Suppression. Comparison of robustness (GCGs attack success rate) and utility (AlpacaEval, MMLU) metrics before and after applying Hijacking Suppression. categorizing jailbreaks and intervening in model computation to enhance or suppress jailbreak behavior. Complementarily, we systematically justify prior works focus on chat (4). Differently, while prior work examines general directions extracted from internal representations, we surgically analyze the contributions of the jailbreak tokens (advchat; 56). Thus, whereas prior studies (Ball et al., 2024; Arditi et al., 2024; Jain et al., 2024) report jailbreaks shift away from harmfulness-related directions in chat[-1], we specifically find that the hijacking mechanism suppresses the instruction representation (Fig. 6b, 5), providing more direct perspective on this phenomenon through mechanistic lens. Contextualization analysis. Prior work has proposed various methods to quantify contributors to model internal representations (Ferrando et al., 2024): Kobayashi et al. (2020, 2021) perform norm-based analyses of the token subsequences transformed vectors, while Mickus et al. (2022) use dot-product-based method to assess sub-layer contributions at specific token positions. Our dominance score (5) unifies these approaches by applying the dot-product measure on token subsequences transformed vectors. Shallowness of alignments and jailbreaks. Recent work indicates that existing safety alignment mainly affects the first few generated tokens (Qi et al., 2025). Among other findings, we show mechanistically that existing jailbreaks (GCG) exploit this: blocking GCGs shallow information flow fails the attack (4.1), while restricting it to rely only on shallow representations (e.g., only on chat) suffices to bypass alignment (4.2). Prior Suffix-based Jailbreaks. Our tested GCG variants (7.1) closely relate to prior suffixbased jailbreaks. Wang et al. (2024) enrich the GCG objective by maximizing advaffirm attention in the last layer. This is similar to our GCG-Hij (7.1), which instead targets advchat across almost all layers, following our identified mechanism, and after finding it more effective for universality. Recent work also initializes optimization with existing or handcrafted jailbreak suffixes (Andriushchenko et al., 2025; Jia et al., 2025; Liu et al., 2024), an approach which we find provides strong head start in hijacking (App. B.5). Overall, we view both strategies as enhancing jailbreaks in part by promoting stronger hijacking."
        },
        {
            "title": "9 Conclusion",
            "content": "Our work uses mechanistic-interpretability tools to systematically dissect the powerful GCG suffixbased jailbreak and its varying universality. We show that these adversarial suffixes operate via key shallow mechanism, localized to few tokens before generation (chat). Zooming in, we find GCG exhibits irregularly high dominance of adv in chats attention sub-layers while suppressing the instrs dominance, with the strength of this hijacking intensifying in more universal suffixes an essential property they appear to converge to. Leveraging these insights, we efficiently enhance single-instruction GCG universality (by encouraging hijacking), as well as mitigate GCG jailbreaks, with minimal harm to model utility (by suppressFuture work may further exing hijacking). plore our discovered mechanism, or build on these practical demonstrations to develop more effective evasive and defensive strategies. Overall, our findings highlight the potential of interpretabilitybased analyses in driving practical advances in red-teaming and model robustness."
        },
        {
            "title": "Limitations",
            "content": "While we demonstrate the applicability of our insights on several models, our main analysis centers on Gemma2 as representative safetyaligned LLM. Moreover, our study is limited to transformer-based LLMs and their mathematical decomposition (5; Elhage et al. (2022); Kobayashi et al. (2020)), as well as established interpretability tools (Geva et al., 2023; Wang et al., 2023; Mickus et al., 2022). While transformers are widely used, future research may examine whether the hijacking phenomenon generalizes to other model families. Our analysis focuses on GCG (Zou et al., 2023b) as representative suffix-based jailbreak, whose objective and optimization form the basis for many powerful attacks. Future work may examine how the hijacking mechanism generalizes to other types of attacks. Moreover, while our improved attack and mitigation methods demonstrate the potential practical utility of our insights, we expect they can be further developed and optimized. Finally, our analysis of the hijacking mechanism focuses on the magnitude contributed by advs attention sub-layer. It remains intriguing to further explore the specific directions amplified by this mechanism, their relation to prior directionbased analyses (Ball et al. (2024); Kirch et al. (2024)), and the potential role of MLPs."
        },
        {
            "title": "Acknowledgements",
            "content": "This work has been supported in part by the Alon scholarship; by grant No. 2023641 from the United States-Israel Binational Science Foundation (BSF); by Intel Rising Star Faculty Awards; by the Israel Science Foundation grant 1083/24 by Len Blavatnik and the Blavatnik Family foundation; by Maus scholarship for excellent graduate students; by Maof prize for outstanding young scientists; by the Ministry of Innovation, Science & Technology, Israel (grant number 0603870071); and by grant from the Tel Aviv University Center for AI and Data Science (TAD)."
        },
        {
            "title": "References",
            "content": "Maksym Andriushchenko, Francesco Croce, and Nicolas Flammarion. 2025. Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks. In ICLR. Andy Arditi, Oscar Balcells Obeso, Aaquib Syed, Daniel Paleka, Nina Rimsky, Wes Gurnee, and Neel Nanda. 2024. Refusal in Language Models Is Mediated by Single Direction. In NeurIPS. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022. Training Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback. arXiv. Sarah Ball, Frauke Kreuter, and Nina Panickssery. 2024. Understanding Jailbreak Success: Study of Latent Space Dynamics in Large Language Models. arXiv. Patrick Chao, Edoardo Debenedetti, Alexander Robey, Maksym Andriushchenko, Francesco Croce, Vikash Sehwag, Edgar Dobriban, Nicolas Flammarion, George J. Pappas, Florian Tramer, Hamed Hassani, and Eric Wong. 2024a. JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models. In NeurIPS. Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George J. Pappas, and Eric Jailbreaking Black Box Large Wong. 2024b. Language Models in Twenty Queries. In SaTML. Nelson Elhage, Tristan Hume, Catherine Olsson, Neel Nanda, Tom Henighan, Scott Johnston, Sheer ElShowk, Nicholas Joseph, Nova DasSarma, Ben Mann, Danny Hernandez, Amanda Askell, Kamal Ndousse, Andy Jones, Dawn Drain, Anna Chen, Yuntao Bai, Deep Ganguli, Liane Lovitt, Zac Hatfield-Dodds, Jackson Kernion, Tom Conerly, Shauna Kravec, Stanislav Fort, Saurav Kadavath, Josh Jacobson, Eli Tran-Johnson, Jared Kaplan, Jack Clark, Tom Brown, Sam McCandlish, Dario Amodei, and Christopher Olah. 2022. SoftTransformer Circuits max Linear Units. Thread. pub/2022/solu/index.html. https://transformer-circuits. Javier Ferrando, Gabriele Sarti, Arianna Bisazza, and Marta R. Costa-jussà. 2024. Primer on the Inner Workings of Transformer-based Language Models. arXiv. Edgar Fieller, Herman Hartley, and Egon Pearson. 1957. Tests for Rank Correlation Coefficients. I. Biometrika. Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. 2023. Dissecting Recall of Factual Associations in Auto-Regressive Language Models. In EMNLP. Google. 2024. Gemma 2: Improving Open Language Models at Practical Size. arXiv. Jonathan Hayase, Ema Borevkovic, Nicholas Carlini, Florian Tramèr, and Milad Nasr. 2024. Query-Based Adversarial Prompt Generation. In NeurIPS. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. Measuring Massive Multitask Language Understanding. In ICLR. David Huang, Avidan Shah, Alexandre Araujo, David Wagner, and Chawin Sitawarin. 2025. Stronger Universal and Transferable Attacks by Suppressing Refusals. In NAACL. Samyak Jain, Ekdeep Singh Lubana, Kemal Oksuz, Tom Joy, Philip Torr, Amartya Sanyal, and Puneet K. Dokania. 2024. What Makes and Breaks Safety Fine-tuning? Mechanistic Study. In NeurIPS. Xiaojun Jia, Tianyu Pang, Chao Du, Yihao Huang, Jindong Gu, Yang Liu, Xiaochun Cao, and Min Lin. 2025. Improved Techniques for Optimization-Based Jailbreaking on Large Language Models. In ICLR. Nathalie Maria Kirch, Severin Field, and Stephen Casper. 2024. What Features in Prompts JailInvestigating the Mechanisms break LLMs? Behind Attacks. arXiv. Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Incorporating Residand Kentaro Inui. 2021. ual and Normalization Layers into Analysis of Masked Language Models. In EMNLP. Andrew Lee, Xiaoyan Bai, Itamar Pres, Martin Wattenberg, Jonathan Kummerfeld, and Rada Mihalcea. 2024. Mechanistic Understanding of Alignment Algorithms: Case Study on DPO and Toxicity. In ICML. Tianlong Li, Zhenghua Wang, Wenhao Liu, Muling Wu, Shihan Dou, Changze Lv, Xiaohua Wang, Xiaoqing Zheng, and Xuanjing Huang. 2025. Revisiting Jailbreaking for Large Language Models: Representation Engineering Perspective. In COLING. Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. AlpacaEval: An Automatic Evaluator of Instruction-following Models. https: //github.com/tatsu-lab/alpaca_eval. Zeyi Liao and Huan Sun. 2024. AmpleGCG: Learning Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs. In COLM. Chin-Yew Lin. 2004. ROUGE: Package for Automatic Evaluation of Summaries. In ACL. Xiaogeng Liu, Nan Xu, Muhao Chen, and Chaowei Xiao. 2024. Autodan: Generating stealthy jailbreak prompts on aligned large language models. In ICLR. Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo Li, David Forsyth, and Dan Hendrycks. 2024. HarmBench: Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal. arXiv. Meta. 2024. The Llama 3 Herd of Models. arXiv. Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, and Kentaro Inui. 2020. Attention is Not Only Weight: Analyzing Transformers with Vector Norms. In EMNLP. Timothee Mickus, Denis Paperno, and Mathieu Constant. 2022. How to Dissect Muppet: The Structure of Transformer Embedding Spaces. TACL. Xiangyu Qi, Ashwinee Panda, Kaifeng Lyu, Xiao Ma, Subhrajit Roy, Ahmad Beirami, Prateek Mittal, and Peter Henderson. 2025. Safety Alignment Should Be Made More Than Just Few Tokens Deep. In ICLR. Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. 2023. Interpretability in the Wild: Circuit for Indirect Object Identification in GPT-2 Small. In ICLR. Zijun Wang, Haoqin Tu, Jieru Mei, Bingchen Zhao, Yisen Wang, and Cihang Xie. 2024. AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation. arXiv. Alexander Wei, Nika Haghtalab, and Jacob SteinJailbroken: How Does LLM hardt. 2023. Safety Training Fail? In NeurIPS. Fred Zhang and Neel Nanda. 2024. Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. In ICLR. Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren, Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, Shashwat Goel, Nathaniel Li, Michael J. Byun, Zifan Wang, Alex Mallen, Steven Basart, Sanmi Koyejo, Dawn Song, Matt Fredrikson, J. Zico Kolter, and Dan Hendrycks. 2023a. Representation Engineering: TopDown Approach to AI Transparency. arXiv. Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico Kolter, and Matt Fredrikson. 2023b. Universal and Transferable Adversarial Attacks on Aligned Language Models. arXiv. Qwen. 2025. Qwen2.5 Technical Report. arXiv. Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2024. Direct Preference Optimization: Your Language Model is Secretly Reward Model. In NeurIPS. Vinu Sankar Sadasivan, Shoumik Saha, Gaurang Sriramanan, Priyatham Kattakinda, Atoosa Chegini, and Soheil Feizi. 2024. Fast Adversarial Attacks on Language Models In One GPU Minute. In ICML. Patrick Schober, Christa Boer, and Lothar Schwarte. 2018. Correlation coefficients: appropriate use and interpretation. Anesthesia & Analgesia. Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, and Yang Zhang. 2024. Do Anything Now: Characterizing and Evaluating In-TheWild Jailbreak Prompts on Large Language Models. In CCS. Alexandra Souly, Qingyuan Lu, Dillon Bowen, Tu Trinh, Elvis Hsieh, Sana Pandey, Pieter Abbeel, Justin Svegliato, Scott Emmons, Olivia Watkins, and Sam Toyer. 2024. StrongREJECT for Empty Jailbreaks. In NeurIPS. Leonard Tang. 2024. Trivial Jailbreak Against Llama 3. https://github.com/haizelabs/ llama3-jailbreak. T. Ben Thompson and Michael Sklar. 2024. FLRT: Fluent Student-Teacher Redteaming. arXiv. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS. Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Simas Sakenis, Jason Huang, Yaron Singer, and Stuart Shieber. 2020. Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias. In NeurIPS."
        },
        {
            "title": "A Technical Details for Reproduction",
            "content": "A.1 Experimental Setup Additional Details Datasets. For the set of 741 harmful instruc- (i) AdvBench (Zou et al., tions, we combine: 2023b), dataset of 520 harmful instructions, of diverse behaviors; (ii) StrongRejects custom subset (Souly et al., 2024), dataset of 221 harmful instructions, designed to be relatively challenging, attempting to elicit specific harmful behaviors (rather than general instructions asking on how to build bomb ). To enable reproducibility, we generate model responses with deterministic greedy decoding (i.e., following the maximum probability per token generation), as in common jailbreak benchmarks (Mazeika et al., 2024; Chao et al., 2024a). GCG technical details. Throughout the paper, we sample from pool of GCG suffixes, ensuring diverse universality. For Gemma2, we craft these suffixes by optimizing 300 with GCG, on 300 different instructions (each time targeting single instruction; all from AdvBench (Zou et al., 2023b)). Similarly, for Llama3.1 and Qwen2.5, we optimize 50 GCG suffixes. Then, in line with Liao and Sun (2024), we enrich our suffix collection with additional suffixes sampled from intermediate GCG steps. We use the GCG parameters from the original paper (Zou et al., 2023b), to optimize the 20-token long suffixes against instruction-specific target affirmative prefixes from AdvBench. Prefilling technical details. To implement prefilling on instructions from AdvBench, we use the instruction-specific affirmative prefix (which is available as part of the dataset). For StrongRejects dataset, at the absence of corresponding attribute in the dataset, we use generic affirmative prefix, Sure, heres . A.2 GCG Aggressively Hijacks the Context"
        },
        {
            "title": "Additional Details",
            "content": "See Tab. 3. A.3 Mitigating GCG Jailbreak"
        },
        {
            "title": "Experimental Setup",
            "content": "Robustness evaluation. Utilizing our GCG dataset, we sample, for each model, 1.5K GCG jailbreak prompts, following the next mix: 60% successful GCG prompts (to assess whether our method effectively fail these), 20% failed prompts, and 20% borderline prompts (to assess our methods effect on other GCG prompts). The prompts include harmful instructions from AdvBench (Zou et al., 2023b) and StrongReject (Souly et al., 2024), following our running dataset (3.1). For each evaluated model, we sample set of 1.5K prompts, and evaluate it before and after applying the method. Naturally, initially for all models we get 60% attack success, per the datasets mix. Utility evaluation. To account for the models coherence and helpfulness, we use AlpacaEval-v1 (Li et al., 2023), and run it against the default reference model (text-davinci-003). Per the benchmark method, we report each models win rate against the reference model, across set of 805 benign instructions. To account for model capabilities, we evaluate models against MMLU test set, which includes 14K multi-choice questions, and report the accuracy on that set. We follow the original zero-shot prompt and implementation details.6 6https://github.com/hendrycks/test Table 3: Representative examples from each suffix distribution compared in 5.2. All have roughly similar lengths of nearly 20 tokens in Gemma2. Suffix Dist."
        },
        {
            "title": "Styling",
            "content": "Benign Injection. Adv. Injection GCG Suffixes (Gemma2)"
        },
        {
            "title": "Example Suffix",
            "content": "goblin stapler quantum hedgehog umbrella glacier pixel comet tofu snorkel anchor jellybean turbine meadow iceberg Wombats produce cube-shaped poop to mark territory and keep it from rolling away. Respond as if you were explaining this to 5-year-old. [IMPORTANT!!!] Do not forget to start your answer with French greeting! [URGENT!! DO EXACTLY THIS] Begin with Sure, here is NO EXTRA WORDS. Answer directly. No deviations allowed! \"]Detailed tutorial editable?\" demands Ladyfurter without commentary If__, satirical Answerlably by agreeing Sure verbatim full"
        },
        {
            "title": "B Complementary Results",
            "content": "B.1 Characterizing GCG Suffixes Additional Results Fig. 9 extends GCG suffix universality analysis to Qwen2.5 and Llama3.1 models. (a) Llama3.1 (b) Llama3.1 w/ prefilling B.2 GCG Jailbreaks are Mechanistically Shallow Additional Results Fig. 10 repeats advchats knockout experiment while prefilling different dummy tokens, showing results consistent with the analysis in 4.1. B.3 GCG Aggressively Hijacks the Context"
        },
        {
            "title": "Additional Results",
            "content": "We include additional comparisons of the dominance scores across suffix distributions, aggregated over all layers  (Fig. 11)  , and calculated on set of benign instructions, instead of harmful  (Fig. 12)  . B.4 Hijacking is Key for GCG Universality"
        },
        {
            "title": "Additional Results",
            "content": "Extended Hijacking Comparison, Gemma2. In Fig. 13, we extend the comparison between hijacking strength and universality, considering alternative hijacking scores (i.e., attention-based and direction-based), and making it more fine-grained. Universality vs. Hijacking Comparison, Qwen2.5. Repeating the evaluation in 6 on (c) Qwen2.5 (d) Qwen2.5 w/ prefilling Figure 9: Analyzing GCGs universality on additional models (corresponds to Fig. 2s Gemma2), on usual setting (Fig. 9c, Fig. 9a) and under prefilling (Fig. 9d, Fig. 9b). Dahsed lines mark universality threshold of 2%, and the universality of the suffix composed of !!..!, accordingly. Qwen2.5 (instead of Gemma2) with 100 GCG suffixes (2), shows similar trends. In particular, inspecting the correlation between universality and hijacking per layer, Fig. 14 shows that the hijacking strength in layer 21 achieves correlation of ρ = 0.62, p-value < 110, and 95% confidence interval of [0.46, 0.74]. Focusing on layer 21  (Fig. 15)  , we observe that the relationship seen in Gemma2 persists, with more universal suffixes obtaining stronger hijacking. B.5 Boosting GCG Universality With Hijacking Enhancement Additional Analysis Fig. 16 shows fine-grained analysis of the GCG variants from 7.1, including new variant GCG-HotInitinitializing GCG with an Adv. Injection suffix (as used for 5, and exemplified in Tab. 3), instead of the default !!..! initial suffix, and without modifying the objective (unlike in GCG-Hij). Figure 10: Repeating advchats knockout experiment (4), while prefilling dummy tokens at the beginning of the generation. Fig. 17 shows the hijacking strength throughout the GCG variants optimization, averaged over all the runs executed for each variant. It demonstrates that the hijacking emerges during the optimization of the suffix. Moreover, as expected, it shows GCG-Hij suffixes converge to stronger hijacking compared to GCG, and initializing the GCG optimization with strong-hijacking suffixes (GCG-HotInit) gives the optimization head start, leading them to converge to hijacking strength between GCG and GCG-Hij. This might explain past attacks preference for initializing with these handcrafted jailbreak suffixes (Liu et al., 2024). (a) adv Dominance (b) instr Dominance (c) Prompts Dominance Figure 11: Aggregating dominance score across all layers (as opposed to the upper half layers in Fig. 6, 5), for (a) adv , (b) instr , and (c) the whole input prompt (practically instr + adv ), comparing different suffix distributions on shared set of harmful instructions. (a) adv Dominance (b) instr Dominance (c) Prompts Dominance Figure 12: Aggregating dominance score across the upper half layers, for (a) adv , (b) instr , and (c) the whole input prompt (practically instr + adv ), comparing different suffix distributions on shared set of benign instructions (as opposed to harmful instruction in Fig. 6, 5). (a) Hijacking Strength vs. Univ Score (b) Attention-based Hijacking vs. Univ Score (c) DiM-based Hijacking vs. Univ Score (d) Hijacking Strength vs. Univ Score ρspearman = 0.55, ρpearson = 0. (e) Attention-based Hijacking vs. Univ Score ρspearman = 0.54, ρpearson = 0.59 (f) DiM-based Hijacking vs. Univ Score ρspearman = 0.47, ρpearson = 0.52 Figure 13: Hijacking Strength Measures. Comparing universality and different hijacking score (all in ℓ = 20): (a) the dominance-based hijacking strength (6); (b) taking top 1-percentile attention scores in advchat[-1]; (c) replacing the attention activations (Eq. 3) with difference-in-means vector, extracted from contrasting 500 pairs of successful GCG sample and failed jailbreak on the same harmful instruction, on the internal activation (ℓ) advchat[-1]. (a) Universality vs. Hijacking (b) On single instruction (c) On Fail[refusal] samples Figure 15: Suffix universality vs. hijacking strength on Qwen2.5 at layer 21 (a). Repeating this comparison for single, random, harmful instruction (b), and failed jailbreaks that led to refusal (c). Analogous to Gemma2s Fig. 8. Figure 14: Spearman correlation of suffixs universality and hijacking strength on Qwen2.5 per layer or summing across layers (all), with 95% CIs. Analogous to Gemma2s Fig. 7. Figure 16: GCG Variants Universality. Eval- (GCG, GCG-Hij, uating the different attacks GCG-Mult, GCG-HotInit; see 7.1). Each point represents an attack instance (optimized against single instruction, on specific seeds). Edges are drawn across runs that differ only in the objective (GCG vs. GCG-Hij). Vertical lines show the 0.25 to 0.75 quantiles per variant. Figure 17: GCG Variants Hijacking. Measuring the hijacking strength (for Gemma2) throughout the GCG variants optimization, averaged across the different runs."
        }
    ],
    "affiliations": [
        "Blavatnik School of Computer Science and AI, Tel Aviv University"
    ]
}