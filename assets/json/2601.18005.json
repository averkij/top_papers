{
    "paper_title": "Flow-based Extremal Mathematical Structure Discovery",
    "authors": [
        "Gergely BÃ©rczi",
        "Baran Hashemi",
        "Jonas KlÃ¼ver"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The discovery of extremal structures in mathematics requires navigating vast and nonconvex landscapes where analytical methods offer little guidance and brute-force search becomes intractable. We introduce FlowBoost, a closed-loop generative framework that learns to discover rare and extremal geometric structures by combining three components: (i) a geometry-aware conditional flow-matching model that learns to sample high-quality configurations, (ii) reward-guided policy optimization with action exploration that directly optimizes the generation process toward the objective while maintaining diversity, and (iii) stochastic local search for both training-data generation and final refinement. Unlike prior open-loop approaches, such as PatternBoost that retrains on filtered discrete samples, or AlphaEvolve which relies on frozen Large Language Models (LLMs) as evolutionary mutation operators, FlowBoost enforces geometric feasibility during sampling, and propagates reward signal directly into the generative model, closing the optimization loop and requiring much smaller training sets and shorter training times, and reducing the required outer-loop iterations by orders of magnitude, while eliminating dependence on LLMs. We demonstrate the framework on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. For circle packings, we improve the best known lower bounds, surpassing the LLM-based system AlphaEvolve while using substantially fewer computational resources."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 5 2 ] . m [ 1 5 0 0 8 1 . 1 0 6 2 : r FLOW-BASED EXTREMAL MATHEMATICAL STRUCTURE DISCOVERY GERGELY BÃ‰RCZI, BARAN HASHEMI, AND JONAS KLÃœVER Abstract. The discovery of extremal structures in mathematics requires navigating vast and nonconvex landscapes where analytical methods offer little guidance and brute-force search becomes intractable. We introduce FlowBoost, closed-loop generative framework that learns to discover rare and extremal combinatorial structures by combining three components: (i) geometry-aware conditional flow-matching model that learns to sample high-quality configurations, (ii) reward-guided policy optimization with action exploration that directly optimizes the generation process toward the objective while maintaining diversity, and (iii) stochastic local search (Stochastic Relaxation with Perturbations) for both training-data generation and final refinement. Unlike prior open-loop approaches, such as PatternBoost [1] that either retrains on filtered discrete samples, or AlphaEvolve [2] where they rely on frozen Large Language Models (LLMs) as evolutionary mutation operators, FlowBoost enforces geometric feasibility during sampling, and propagates reward signal directly into the generative model, closing the optimization loop and requiring much smaller training sets and shorter training times, and reducing the required outer-loop iterations by orders of magnitude, while eliminating dependence on LLMs. We demonstrate the framework on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. For circle packings, we improve the best known lower bounds, surpassing the LLM-based system AlphaEvolve while using substantially fewer computational resources. For the Heilbronn problem, FlowBoost improves the minimum triangle area approaching the best known numerical values. For sphere packing in dimension 12, our method finds configurations denser than those produced by classical heuristics. To our knowledge, FlowBoost is the first systematic application of flow-based generative models with Reinforcement Learning to extremal structure discovery in pure mathematics. We term this paradigm de novo mathematical structure design. Our results demonstrate that lightweight, domain-specific generative models, when equipped with geometric inductive biases and reward-guided learning, can match or exceed the performance of LLM-based systems at fraction of the computational cost. The code is available at https://github.com/berczig/FlowBoost. Contents Introduction 1. 2. Methods 2.1. Simulation-Based Optimization (SBO): Learning Stochastic Policy 2.2. Conditional Flow Matching for Configuration Generation 2.3. Geometry-Aware Sampling (GAS) 2.4. Reward-Guided Fine-Tuning 2.5. Closing the Loop: Convergence Properties 2.6. The FlowBoost Pipeline 2.7. Local Search: Stochastic Relaxation with Perturbations 3. Results 3.1. Overview 3.2. Sphere Packing in Hypercube 3.3. The Heilbronn Problem 3.4. Circles in Unit Square with Maximal Sum of Radii 3.5. Star Discrepancy Minimization 4. Conclusion 4.1. Discussion and Future Directions Acknowledgment References Date: January 27, 2026. 1 2 5 5 7 7 8 10 10 11 12 12 13 17 20 22 25 26 28 28 1. Introduction AI-driven mathematics [3] has advanced in two main directions: (i) formal reasoning and verification [49], where machine learning is integrated with proof assistants to propose proof steps and complete formal proofs, and (ii) discovery via interpretability analysis [1014] in human-AI collaboration, and search [1, 1522], where neural networks either propose counter-examples, relations, and candidates (programs or constructions) that are evaluated by human mathematicians. While these approaches have achieved notable successes in symbolic and discrete domains, distinct class of problems lies at their boundary, namely continuous optimization over geometric configurations, where objectives are not normalized (there is no access to likelihood), admit no closed-form gradient, constraints encode hard geometric feasibility, and the landscape admits exponentially many local optima. Such problems are extremely common in combinatorial geometry and algebra, but they resist brute-force search because the search domain is continuous. This is precisely where deep generative models, trained to capture complex distributions over high-dimensional spaces, may offer distinctive advantage. Many structure discovery problems in extremal geometry can be re-formulated as finite-dimensional continuous Simulation Based Optimization (SBO) [23] problem. These problems share common setup: configuration space Rğ‘‘ ğ‘ of geometric objects, an objective functional ğ½ : to be optimized, and hard constraints (geometric or algebraic) defining feasibility. Typical examples include packing problems (configurations of spheres or circles maximizing density or coverage), discrepancy problems (point sets minimizing irregularity of distribution), and extremal point configurations (maximizing minimum distances or triangle areas). More broadly, our pipeline can be efficiently used to discover rare candidates in constrained algebraiccombinatorial search spaces, such as graph, or polytope encoded generators. Analytically, these problems are often intractable beyond low dimensions or small instance sizes. Computationally, they exhibit rugged energy landscapes with exponentially many local optima separated by high barriers. Progress has historically relied on combination of mathematical insight and carefully designed heuristic search. Modern deep generative models, such as Transformer [24], Diffusion [25], Normalizing Flows [26], Generative Adversarial networks [27], Variational Auto Encoders (VAEs) [28] and Flow Matching [29] models, have shown remarkable capacity at learning complex distributions in high-dimensional spaces. These methods have transformed domains from image synthesis [30] to protein structure prediction[31], and physics simulation [32], demonstrating an ability to capture intricate structural regularities from data. Hence, natural question arises: Can deep generative models accelerate mathematical discovery and exploration by learning to generate high-quality Out-of-Distribution (OOD) configurations directly? We call this paradigm De Novo Mathematical Structure Design. Recent work has begun to explore this direction by combining generative discovery with explicit search-and-evaluate loops. These evolutionary search models are used to iteratively boost the quality of mathematical constructions, progressively reshaping the search process toward better solutions. The PatternBoost framework [1] alternates between local classical optimization phase and global generative modeling phase. problem-specific local search heuristic generates high-scoring objects; sequence-to-sequence transformer model [24] is then trained on the best objects and sampled to provide seeds that restart the local search, iterating this local-global search to discover improved constructions. FunSearch [33] replaces local search of PatternBoost by explicit program evolution. It searches directly in the space of functions/programs where pretrained LLM proposes variants of python script (by editing specific function), while an automatic evaluator executes the code on set of instances to assign deterministic score. Candidates scripts are retained, clustered (e.g. by behavioral signatures on the evaluation set), and iteratively recombined/mutated through further LLM proposals, yielding an evolutionary procedure in which the LLM acts as powerful mutation operator and the evaluator enforces correctness and selection pressure. More recently, AlphaEvolve [2, 18] scales this paradigm into more general-purpose evolutionary coding agent. Rather than evolving single short function, AlphaEvolve provides pipeline in which LLMs propose code edits, the fixed problem-specific scoring system in the evaluation harness measures fitness, and population-based selection retains and refines the most promising candidates across many generations, enabling algorithm discovery and optimization across diverse domains. 2 In short, FunSearch and AlphaEvolve are evolutionary search models with states represented by python scripts, values are given by fixed scoring system and actions are LLM-suggested modifications of scripts. However, these models can face limitations when applied for continuous geometric optimization problems. Here we list four type of problem which arises. (1) Discrete representations for continuous problems. PatternBoost operates on tokenized sequences, requiring geometric configurations to be discretized. As result, it loses the smooth and high-precision structure of the optimization landscape and complicates constraint satisfaction. (2) Open-loop iteration without convergence guarantees. PatternBoost and AlphaEvolve iterate generate-evaluate-select system, but the generative model receives no direct feedback from the objective. They learn to match the distribution of current best solutions rather than to optimize or rely on evolutionary selection with frozen LLM. This can require significantly amount of iterations without any guarantee of improvement. (3) Dependence on Large Language Models. AlphaEvolves power derives from frontier LLMs (Gemini Pro, 10B+ parameters), requiring substantial computational infrastructure and API access beyond the reach of most researchers. (4) Post-hoc constraint handling. Geometric constraints (non-overlap, boundary containment, symmetries, algebraic relations, etc.) are typically enforced through rejection sampling, repair heuristics after generation, or prompt engineering, rather than being incorporated into the generative process itself. In this work we introduce FlowBoost, framework that addresses each of these limitations through three innovations: Continuous generation via CFM. We operate directly in configuration space Rğ‘‘ ğ‘ , learning time-dependent vector field that transports prior to the distribution of high-quality configurations. This preserves the geometric structure of the problem and enables gradient-based reasoning about constraints. Geometry-Aware sampling (GAS). Rather than generating configurations and filtering invalid ones, we interleave flow integration with projection onto the constraint manifold. This generates feasible samples throughout the generative process, dramatically improving sample efficiency. Closed-loop Reward-Guided optimization. We close the optimization loop by fine-tuning the flow model with direct feedback from the objective. Using online reward-guided flow matching with problem-specific action exploration, we upweight high-reward rare samples in the training objective while trust-region self-distillation term prevents distribution collapse. This transforms open-loop iteration into closed-loop optimization, reducing required iterations from (100) to (10). The fundamental distinction between our approach and LLM-based systems lies in how structure is represented and exploited. AlphaEvolve-family of models [2, 34, 35] operate in program space: the LLM proposes syntactic modifications to code, and an evaluator checks whether the resulting program produces valid, high-scoring solutions. This approach inherits the power of language models where they can generate human-readable algorithms. However, for many mathematical problems where the moduli of solutions admits natural algebraic and geometric structures and follow certain set of sharp optimization objectives, this indirection introduces huge complexity and over-reliance on SOTA LLMs. While AlphaEvolve requires access to frontier LLMs and substantial computational infrastructure, FlowBoost can be trained and deployed by individual researchers on commodity hardware. When this framework is instantiated with domain-appropriate generative models with few simulated data, comparable or superior results can be achieved at fraction of the computational cost. Our pipeline is largely reusable across problems, with only modest adjustments to the penalty structure, conditioning variables, and reward definition. In short, when the problem domain admits natural geometric structure within continuous or discrete optimization problems, encoding this structure directly into the generative model as an inductive bias, yields superior results with far less computation. This parallels developments in computational biology, where domain-specific architectures such as AlphaFold [36] and ESM [37], and equivariant diffusion models for molecular generation [31] have largely supplanted general-purpose language models for protein structure prediction and synthesis. The contributions of this paper are threefold: 3 Generative Model Model Scale Search Space PatternBoost Autoregressive Transformer (Makemore) 10M parameters Discrete token sequences AlphaEvolve Frontier LLMs FlowBoost Conditional Flow Matching (CFM) 10B+ parameters (frozen) 2M parameters Program space (code) Inductive Bias Sequential structure LLM priors Random Sampling Exploration mechanism LLM Required? Constraint Handling Greedy repair heuristics Iterations verge Loop structure (10100) to conNo mutation, LLM-guided MAP-Elites Yes (essential) Post-hoc verification (10106) Open (No Direct Feedback) Open (Evolutionary SelecCompute Requirements Single GPU (10100 h) Objective + Tokenization tion) Cluster + API (1000 h) Evaluator + Prompt engineering Continuous configuration space Permutation Equivariance, Geometric Consraints Online Reward-guidance + Action Exploration No Geometry-Aware Sampling (110) Closed (Reward-Weighted Updates) Single GPU (110 h) Objective Table 1. Comparison of AI-driven mathematical structure discovery systems. We compare architectural choices, computational requirements, and demonstrated capabilities. FlowBoost achieves competitive or superior results on continuous geometric problems with 2-5 orders of magnitude less compute, and no reliance on LLMs. (1) closed-loop deep generative framework for mathematical structure discovery. We introduce FlowBoost, combining conditional flow matching, Transformers, geometry-aware sampling, and reward-guided policy optimization into unified pipeline for rare structure discovery. The framework is problem-agnostic: the same architecture applies across problem domains with only changes to the constraint structure and reward function. (2) First systematic application of flow-based models to extremal mathematics. We demonstrate that modern generative models, when properly adapted, can tackle problems in combinatorial geometry, not as benchmarks, but as genuine research tools capable of discovering new constructions. (3) New records and near-optimal constructions across multiple problems: Circle packing (sum of radii): New best constructions for ğ‘› = 26 and ğ‘› = 32 circles, surpassing AlphaEvolve. Sphere packing in hypercubes: High-density configurations in dimension 3 (ğ‘ = 50-200) and dimension 12 (ğ‘ = 31), matching or improving known constructions. Heilbronn problem: For ğ‘› = 13 points, improvement from ğ´min = 0.025236 to 0.025727 in four iterations, approaching the best known value. (4) Bridging two separate research areas. We identify unifying perspective showing that, despite superficial differences in problem formulation, rare structure discovery in mathematics and OOD generative design in domains such as molecular and materials discovery share the same underlying SBO blueprint, constrained and likelihood-free generative OOD sampling. This bridge enables direct transfer of methods, theoretical tools, and practical heuristics between the two communities. The paper is organized as follows. Section 2 formalizes the simulation-based optimization framework and our closed-loop extension, details the FlowBoost architecture: conditional flow matching, geometryconstrained sampling, and reward-guided policy optimization. Sections 3 present applications to sphere packing, circle packing, the Heilbronn problem, and star discrepancy. Section 4 discusses implications and future directions. 2. Methods 2.1. Simulation-Based Optimization (SBO): Learning Stochastic Policy. The discovery of rare and extremal mathematical structures, from dense sphere packings to point configurations maximizing geometric functionals, requires navigating high-dimensional, non-convex landscapes with rugged local optima. We introduce FlowBoost, unified framework that combines conditional flow matching with geometry-aware sampling and reward-guided fine-tuning. This methodology goes under the hood broader paradigm, namely Simulation-Based Optimization (SBO) [23, 3840], the iterative alternation between local refinement and global generative exploration. SBO is closely related to the paradigm of Simulation-Based Inference (SBI) [41, 42], but the two differ in what is being learned and what the simulator is used for. In SBI, one assumes access to simulator (or implicit model) ğ‘(ğ‘¥ ğœƒ) and aims to infer latent parameters ğœƒ from observations ğ‘¥ by learning an approximation to the posterior ğ‘(ğœƒ ğ‘¥) or surrogate for the likelihood ğ‘(ğ‘¥ ğœƒ). Hence, the simulator is treated as generative process that produces data, and the learned model is used for statistical inference under fixed data generating mechanism. SBO instead treats simulation and evaluation as an optimization oracle. Here the latent variable is the candidate solution itself, and the objective induces target distribution over solutions. Hence one can define an energy-based (Boltzmann/Gibbs) target ğœ‹ğ›½ (ğ‘¥) = 1 ğ‘ğ›½ ğ‘0(ğ‘¥) exp (cid:0)ğ›½ ğ½ (ğ‘¥)(cid:1) ğ‘ğ›½ = ğ‘0(ğ‘¥) exp (cid:0)ğ›½ ğ½ (ğ‘¥)(cid:1) ğ‘‘ğ‘¥, where ğ‘0(ğ‘¥) is prior over configurations (e.g. simple base distribution), and exp(ğ›½ğ½ (ğ‘¥)) is an (unnormalized) objective-induced measure that upweights high-scoring configurations. Equivalently, defining an energy ğ¸ (ğ‘¥) = ğ½ (ğ‘¥) yields ğœ‹ğ›½ (ğ‘¥) ğ‘0(ğ‘¥) exp(ğ›½ğ¸ (ğ‘¥)). In this view, SBO is not posterior inference over parameters; it is posterior sampling over solutions under an objective-induced measure. The central task is therefore to learn generative model ğ‘ ğœƒ (ğ‘¥) (amortized sampler) so that it concentrates mass near ğœ‹ğ›½ (with the amortized sampler playing the role that variational posteriors play in SBI), with larger ğ›½ corresponding to stronger optimization pressure. This problem, converting an energy function into generative distribution, admits several classical solutions. Markov Chain Monte Carlo (MCMC) methods can sample from ğœ‹ğ›½ given only the unnormalized density, but they are computationally expensive (requiring many iterations per sample) and fundamentally local in their exploration: mixing between distant modes is slow, and discovering new modes requires the chain to traverse low-probability regions [39]. When the modes occupy tiny volume of the configuration space (extremal regions), the probability of initializing chain near an unknown mode becomes negligible, rendering MCMC unsatisfactory for rare structure discovery. Deep generative models offer an alternative to amortize the cost of sampling by training neural network to map noise to high-quality configurations directly. Sampling then becomes single forward pass, the model can generalize to propose candidates in regions it has never explicitly visited, provided there is learnable structure relating known modes to undiscovered ones. This amortization fundamentally changes the exploration-exploitation trade-off: whereas MCMC or heuristic algorithms must mix between modes (a slow, iterative process), generative model can jump to new modes if its inductive biases and training procedure enable appropriate generalization. Both SBI and SBO rely on repeated simulation and amortized learning, and both may use the same modern generative machinery (flows, diffusion/flow matching) to represent complex distributions. The key distinction is the feedback signal. SBI updates the model to match the simulator-implied data distribution (likelihood or posterior consistency), whereas SBO updates the model to concentrate probability mass on rare, high-scoring regions defined by the objective function and the constraints. This distinction also explains why neither local search nor global generation alone suffices for hard extremal problems. local search provides high-precision refinement but is basin-limited, while pure generation provides exploration but struggles with tight feasibility and extrapolative OOD discovery. By embedding both within boosting loop where generative model proposes diverse candidates and local refinement sharpens them, SBO can escape local minima while progressively shifting the proposal toward the objective-induced posterior over solutions. From statistical perspective, FlowBoost is related and complimentary to Boltzmann-generator approaches in molecular and materials modeling [43], which learn flow-based transports from simple prior to Gibbs target ğœ‹(ğ‘¥) exp(ğ›½ğ¸ (ğ‘¥)); in our setting we induce an analogous target by taking ğ¸ (ğ‘¥) = ğ½ (ğ‘¥) (along with geometric feasibility constraints), and extend 5 the paradigm with geometry-aware sampling and closed-loop reward-guided updates for extrapolative discovery. Comparison to prior work. Our pipeline differs from prior classical SBO method in mathematical structure discovery, PatternBoost, in two critical respects. First, we replace discrete autoregressive sequence models with continuous conditional flow matching, natural choice for geometric problems where the configuration space admits both continuous coordinates and geometric constraint functions. Second, we close the optimization loop through online reward-guided policy updates, transforming an open iterative scheme into convergent closed-loop control system. For example, PatternBoost is open-loop where the generator is retrained on selected solutions, but does not receive direct objective feedback during the update. Therefore, there is no mechanism guaranteeing convergence to optimal or near-optimal solutions. In PatternBoost, one only hopes that an extremal and rare construction would emerge after (100) iterations of the local-global cycle. In practice, however, the distribution of generated solutions can plateau, oscillate, or drift without systematic improvement. The generative model learns to mimic the current best solutions but receives no direct signal pushing it toward better solutions, it matches distribution rather than optimizing an objective. In contrast, FlowBoost introduces closed-loop update in which generated candidates are scored and immediately used to fine-tune the generator via self-distillation reward-guidance with trust region. As result, we formalize FlowBoost as closed-loop instance of SBO for rare mathematical structure discovery in generic configuration spaces. retrain (open loop) Open-loop baseline: (102 ) retrain cycles Local Search (SRP) training data Geometry-Aware Sampling (GAS) samples Selection & Evaluation ğ‘… ( ğ‘¥ ) ğœƒ ğœƒ Action Exploration (ğ‘¥ğ‘¥) move & repair Reward-Guided Fine-Tuning (RG-CFM) Closed-loop (Ours): (110) update steps ğœƒ arg min ğœƒ Eğ‘¥ ğ‘ğœƒ (cid:104) ğ‘¤(cid:0)ğ‘…(ğ‘¥)(cid:1) ğ‘£ ğœƒ (ğ‘¥ğ‘¡ , ğ‘¡) ğ‘£ ğ‘¡ 2(cid:105) + ğ›¼ ğ‘£ ğœƒ ğ‘£ref 2 Figure 1. Simulation-based optimization with closed-loop updates and action exploration. Gray dashed arrows indicate the open-loop baseline: generate candidates, select, and retrain on the selected set over many cycles. Green arrows indicate our closedloop pipeline: samples produced by geometry-aware sampling are perturbed by an action exploration operator (ğ‘¥ğ‘¥), scored by rewards ğ‘…(ğ‘¥), and used for online reward-guided fine-tuning of the flow model. The reward-weighted objective upweights high-reward samples via ğ‘¤(ğ‘…(ğ‘¥)), while the teacher, student consistency term ğ‘£ ğœƒ ğ‘£ref 2 limits distribution shift and mitigates generative collapse. Empirically, this converts slow, stochastic improvement across many outer cycles into small number of effective update rounds, because the generator update is explicitly biased by the objective functional rather than implicitly by imitation of the current elite set. 6 dğ‘¥ğ‘¡ dğ‘¡ 2.2. Conditional Flow Matching for Configuration Generation. Let Rğ‘‘ ğ‘ denote configuration space of ğ‘ objects in ğ‘‘-dimensional Euclidean space, equipped with an objective functional ğ½ : to be maximized. Rather than directly optimizing ğ½, we learn generative model whose samples concentrate on high-quality (exceptional) regions of X. We adopt the conditional flow matching (CFM) [29] framework, which learns time-dependent vector field ğ‘£ ğœƒ : [0, 1] ğ‘‡X that transports simple prior distribution ğ‘0 on (e.g., uniform points in bounding box) to data distribution ğœ‡data of high-quality configurations. The flow is defined by the ordinary differential equation (2.1) with the objective that the push-forward of ğ‘0 under this flow approximates ğœ‡data at ğ‘¡ = 1. Training proceeds via regression onto the conditional velocity field of an optimal transport interpolation. Given paired samples (ğ‘¥0, ğ‘¥1) with ğ‘¥0 ğ‘0 and ğ‘¥1 ğœ‡data, and the linear interpolant ğ‘¥ğ‘¡ = (1 ğ‘¡)ğ‘¥0 + ğ‘¡ ğ‘¥1, the target velocity is simply ğ‘£ = ğ‘£ ğœƒ (ğ‘¥ğ‘¡ , ğ‘¡), ğ‘¥0 ğ‘0, ğ‘¡ = ğ‘¥1 ğ‘¥0. The CFM training objective takes the form LCFM(ğœƒ) = Eğ‘¡U (0,1) Eğ‘¥0 ğ‘0, ğ‘¥1ğœ‡data (cid:13) (cid:13)ğ‘£ ğœƒ (ğ‘¥ğ‘¡ , ğ‘¡) ğ‘£ ğ‘¡ (cid:13) 2. (cid:13) (2.2) Unlike diffusion models that rely on stochastic noise schedules and iterative denoising, flow matching learns deterministic vector field enabling direct, efficient sampling via ODE integration. Auxiliary Geometric Penalties. Pure distribution matching can under-penalize rare but catastrophic constraint violations. Following the principle of fusing geometric inductive bias into training [44], we augment the CFM loss with geometric-aware penalty. For packing problems, we define an overlap energy on the projected data endpoint: ğ¸overlap(ğ‘¥) = ğ‘–< ğ‘— ğœ“ (cid:0)2ğ‘Ÿ ğ‘¥ğ‘– ğ‘¥ ğ‘— (cid:1), ğœ“(ğ‘¢) = 1 ğ›½ log(cid:0)1 + ğ‘’ğ›½ğ‘¢(cid:1), (2.3) where ğ‘Ÿ is the object radius and ğœ“ is Softplus function penalizing violations. Given the predicted velocity ğ‘£ ğœƒ (ğ‘¥ğ‘¡ , ğ‘¡) and the affine path coefficients (ğ›¼ğ‘¡ , ğœğ‘¡ ) defining the interpolation ğ‘¥ğ‘¡ = ğ›¼ğ‘¡ ğ‘¥1 + ğœğ‘¡ ğ‘¥0 (with ğ›¼ğ‘¡ = ğ‘¡, ğœğ‘¡ = 1 ğ‘¡ for optimal transport), we project back to the data endpoint via Ë†ğ‘¥1 = (ğ‘£ğœƒ (ğ‘¥ğ‘¡ , ğ‘¡) (cid:164)ğœğ‘¡ ğ‘¥0)/ (cid:164)ğ›¼ğ‘¡ = ğ‘£ğœƒ (ğ‘¥ğ‘¡ , ğ‘¡) + ğ‘¥0. The total training loss becomes (ğœƒ) = LCFM(ğœƒ) + ğœ†(ğ‘¡, epoch) ğ¸overlap( Ë†ğ‘¥1), (2.4) with ğœ† following cosine warm-up schedule that prioritises distribution matching early in training and constraint satisfaction thereafter. 2.3. Geometry-Aware Sampling (GAS). Standard ODE integration of the learned flow (2.1) can drift off the feasible set and produce samples violating hard geometric constraints [45, 46], particularly for packing problems where non-overlap is essential. We introduce Geometry-Aware Sampling (GAS) algorithm that interleaves flow integration with constraint projection, analogous to the use of molecular dynamics corrections and energy minimization in protein structure refinement [47]. GAS is tangent-space projection-corrected sampler that pushes learned transport with explicit constraint correction during inference. Conceptually, GAS can be viewed as geometric specialization of physics-constrained sampling [48, 49], where in our setting we target wide range of geometric feasibility hypersurfaces. In this section, we describe the GAS model specifically for the sphere packing problem. Details for the other problems studied in this paper are provided in Section 3. Let denote the feasible set defined by non-overlap constraints. Rather than fixing boundary margins to the sphere radius ğ‘Ÿ, we employ an adaptive wall constraint that depends on the configurations minimum separation: (cid:110) = ğ‘¥ : ğ‘¥ğ‘– ğ‘¥ ğ‘— 2ğ‘Ÿ ğ‘– < ğ‘—, ğ‘š(ğ‘¥) ğ‘¥ (ğ‘˜ ) ğ‘– ğ¿ ğ‘š(ğ‘¥) ğ‘–, ğ‘˜ (cid:111) , (2.5) where ğ‘š(ğ‘¥) = 1 2 minğ‘–< ğ‘— ğ‘¥ğ‘– ğ‘¥ ğ‘— is half the minimum pairwise distance. This adaptive formulation ensures that wall margins scale with the effective radius supported by the current configuration, enabling the sampling process to discover tighter packings without imposing fixed radius constraint during sampling. GAS maintains approximate feasibility throughout the sampling trajectory via iterative projection, without requiring gradient information for the constraints during training. 7 The algorithm is the following. We discretize the flow time ğœ [0, 1] into ğ¾ steps with ğœğ‘˜ = ğ‘˜/ğ¾, where ğœ = 0 corresponds to the prior distribution and ğœ = 1 to the data distribution. The models internal time coordinate is ğ‘¡ = 1 ğœ, so integration proceeds from ğ‘¡ = 1 toward ğ‘¡ = 0. At each step: (i) Flow Integration: Advance the state via ODE integration using an adaptive midpoint or higher-order solver: ğ‘¥ğ‘˜+1 = ğ‘¥ğ‘˜ + ğœğ‘˜+1 ğœğ‘˜ ğ‘£ ğœƒ (ğ‘¥, 1 ğœ)dğœ. (2.6) After each integration step, we enforce the adaptive box constraint ğ‘¥ [ğ‘š(ğ‘¥), ğ¿ ğ‘š(ğ‘¥)] ğ‘‘ via iterative reflection, which preserves the minimum pairwise separation while preventing boundary violations. (ii) GaussNewton Projection: Project onto the constraint manifold via linearised constraint enforcement. For active constraint pairs (ğ‘–, ğ‘—) with overlap â„ğ‘– ğ‘— = 2ğ‘Ÿ ğ‘¥ğ‘– ğ‘¥ ğ‘— > 0, let ğ½ denote the Jacobian of the constraint residuals â„. The projection step computes Î”ğ‘¥ = ğ½(ğ½ğ½) 1â„, which we approximate efficiently via degree-normalized pairwise updates: Î”ğ‘¥ğ‘– = 1 deg(ğ‘–) ğ‘—:â„ğ‘– ğ‘— >0 â„ğ‘– ğ‘— 2 Ë†ğ‘›ğ‘– ğ‘—, Ë†ğ‘›ğ‘– ğ‘— = ğ‘¥ğ‘– ğ‘¥ ğ‘— ğ‘¥ğ‘– ğ‘¥ ğ‘— . (2.7) (2.8) Boundary violations are handled analogously with wall-normal corrections. (iii) Proximal Relaxation: To prevent projection from deviating excessively from the learned flow manifold, we apply proximal correction that balances constraint satisfaction with fidelity to the flow trajectory. Given the anchor point Ë†ğ‘¥ = (1 ğœ)ğ‘¥0 + ğœğ‘¥proj on the optimal transport path, we iteratively minimise ğ‘¥ ğ‘¥ ğœ‚ (cid:16) (ğ‘¥ Ë†ğ‘¥) + ğœ†prox ğ½â„(ğ‘¥next) (cid:17) , (2.9) where ğ‘¥next = ğ‘¥ + (1 ğœ)ğ‘£ ğœƒ (ğ‘¥, 1 ğœ) is the forward-projected terminal state, â„ is the constraint residual, and ğ½ is its Jacobian. This couples the proximal anchor with lookahead penalty on constraint violations at the predicted endpoint. (iv) Terminal Refinement: After completing flow integration, we apply additional projection passes with tightened tolerances to ensure strict feasibility. The algorithm terminates when the maximum overlap residual falls below prescribed tolerance: (cid:0)2ğ‘Ÿ ğ‘¥ğ‘– ğ‘¥ ğ‘— (cid:1) + ğœ–tol, max ğ‘–< ğ‘— (2.10) where ()+ = max(, 0) denotes the positive part. This criterion is independent of any fixed radius assumption, yielding samples that are both distributionally faithful and geometrically valid for the effective radius ğ‘Ÿeff = 1 2 minğ‘–< ğ‘— ğ‘¥ğ‘– ğ‘¥ ğ‘— supported by the configuration. This projection-relaxation scheme is conceptually similar to constraint satisfaction in molecular dynamics [50], where forces from bonded interactions (analogous to our flow field) are balanced against non-bonded repulsions (our overlap penalties). 2.4. Reward-Guided Fine-Tuning. While the base CFM model learns to sample from the distribution of training configurations, the discovery of extremal structures requires improving upon this distribution towards OOD regions, generating configurations with higher objective values than any in the training set. In other words, rare structure discovery, is intrinsically extrapolative. This challenge is very similar to de novo molecular design, where one seeks to extrapolatively generate molecules with properties exceeding those in known databases. As result, we introduce Reward-Guided CFM (RG-CFM), an online fine-tuning procedure that synthesizes: (i) importance-weighted policy optimization from reinforcement learning, and (ii) consistency regularization from self-supervised learning (SSL) [51]. This synthesis addresses fundamental in pure reward-guided generation [39]. Pure reward maximization drives the model toward high-scoring configurations, but without regularization it collapses to degenerate policy that produces only single output, losing the diversity necessary for continued exploration and discovery. Reward Function. For each problem, we define reward ğ‘… : aligned with the optimization objective. For sphere packing, we use the effective radius, half the minimal separation distance, normalized by the box length: ğ‘…(ğ‘¥) = ğ‘Ÿeff (ğ‘¥) = which directly measures packing quality: larger ğ‘… supports larger sphere radii. This formulation is agnostic to any predetermined target radius, allowing the model to discover configurations that exceed the quality of training data. ğ‘¥ğ‘– ğ‘¥ ğ‘— , min ğ‘–< ğ‘— (2.11) , ğ‘Ÿeff (ğ‘¥) ğ¿ 1 2 Online Reward-Guided Flow Matching. RG-CFM adopts teacher-student framework inspired by selfsupervised methods such as DINO [52] and Mean Teacher [53]. We maintain two copies of the velocity field, student model ğ‘£ ğœƒ that is actively fine-tuned, and teacher model ğ‘£ref that remains frozen at the pretrained weights. The teacher serves as an anchor, providing consistency targets that prevent the student from drifting into degenerate solutions, phenomenon we term generative collapse, analogous to representation collapse in contrastive learning [54]. To push generation toward high-reward regions, we adopt importance weighting from offline RL [55, 56]. If ğ‘(ğ‘¥) denotes the distribution of training endpoints and ğ‘¤(ğ‘¥) 0 is weighting function, then minimizing weighted flow matching loss yields learned terminal distribution proportional to ğ‘¤(ğ‘¥) ğ‘(ğ‘¥). Repeated cycles of sampling from the current model and retraining with the same weighting amplify mass by successive powers of ğ‘¤, progressively concentrating the distribution around reward-maximizing modes. This observation motivates both (i) reward-weighted updates for systematic improvement, and (ii) explicit regularization to prevent degeneracy. Concretely, given batch of samples {ğ‘¥ (ğ‘) }ğµ ğ‘=1 generated by the current student model via GAS, along with their reward scores {ğ‘… (ğ‘) }, we compute importance weights through ğ‘§-score normalization followed by exponentiation: ğ‘¤ (ğ‘) = (cid:16) 1 ğ‘ exp ğœ ğ‘… (ğ‘) ğ‘… ğœğ‘… + ğœ– (cid:17) , ğ‘ = 1 ğµ (cid:16) ğœ exp ğ‘ ğ‘… (ğ‘ ) ğ‘… ğœğ‘… + ğœ– (cid:17) , (2.12) where ğ‘… and ğœğ‘… are the batch mean and standard deviation of rewards, ğœ > 0 is temperature controlling selection pressure, and weights are clipped to [0, ğ‘¤max] for numerical stability. This scheme ensures that samples with above-average rewards receive amplified influence during training, while below-average samples are downweighted but not discarded entirely, reminiscent of Advantage-Weighted Regression (AWR), where policy updates take the form of weighted maximum likelihood with weights exponential in the advantage. Without regularization, pure reward maximization leads to well-known failure mode. Given sufficient training, the student model converges to degenerate policy that produces only single high-reward output, losing the diversity necessary for continued exploration. Each retraining round amplifies probability mass on the current best modes, and the model eventually converges to delta distribution concentrated on one or few configurations. This generative collapse is catastrophic for optimization: once the model produces only one configuration, it cannot explore alternative basins, and the search terminates prematurely at local optimum. We prevent collapse through consistency regularization, penalising deviation of the students velocity field from the frozen teachers predictions. At each training step, both models are evaluated on the same interpolated states ğ‘¥ğ‘¡ , and we minimize their squared discrepancy: ğµ (cid:13) (cid:13)ğ‘£ ğœƒ (ğ‘¥ (ğ‘) , ğ‘¡) ğ‘£ref (ğ‘¥ (ğ‘) Lconsist = , ğ‘¡)(cid:13) 2. (cid:13) (2.13) ğ‘¡ ğ‘¡ 1 ğµ ğ‘=1 This term acts as soft constraint in function space, bounding how far the fine-tuned velocity field can deviate from the pretrained baseline. The mechanism mirrors the role of the exponential moving average (EMA) teacher in DINO [52] and BYOL [57], which provides stable targets that anchor the students learning and maintain output diversity through implicit regularization. As result, the total RG-CFM loss combines reward-weighted flow matching with consistency regularization: (2.14) where ğ›¼ > 0 controls the exploration-exploitation trade-off. Small ğ›¼ permits aggressive reward optimization at the risk of collapse and large ğ›¼ preserves diversity but limits improvement over the 9 FM + ğ›¼ Lconsist, LRG = Lw baseline. In practice, we find that ğ›¼ [0.1, 1.0] provides robust operating regime, analogous to the KL penalty coefficient in proximal policy Optimisation (PPO) [58] or the trust region in TRPO [59] methods where the new policy is the old policy reweighted by exponentiated advantages, regularized to stay close to reference and RLHF [60] for LLMs. Geometry-Aware Action Exploration. An important limitation of pure reward-guidance is support suboptimality, meaning that weighted training cannot assign probability mass to configurations that are essentially absent from the distribution used to generate training endpoints. In other words, if the current policy (or current elite dataset) has negligible density in region containing better solutions, reweighting alone cannot reliably discover it. This motivated us to have an explicit exploration operators that propose structured perturbations beyond the current support. Moreover, naive continuous-action online RL methods encourage exploration by sampling actions from normal distribution when collecting episodes, but simply adding noise to the action trajectories produces non-smooth trajectories and does not efficiently explore the action space. Thus, to further enhance sample diversity during fine-tuning, during on-policy data collection for RG-CFM we introduce an exploration operator (ğ‘¥ğ‘¥) that proposes smooth, constraint-informed moves: ğ‘¥ = ğ‘¥ + Î”ğ‘¥, Î”ğ‘¥ = (ğ‘€ğ‘Ÿ) ğ‘ (ğ‘¥) (cid:98)ğ‘‘ (ğ‘¥), (cid:98)ğ‘‘ (ğ‘¥) = ğ‘ Î”contact(ğ‘¥) + (1 ğ‘) Î”wall(ğ‘¥) ğ‘ Î”contact(ğ‘¥) + (1 ğ‘) Î”wall(ğ‘¥)F + ğœ€ . (2.15) Here is the Frobenius norm on Rğ‘‘ ğ‘ , ğ‘€ is dimensionless exploration magnitude, ğ‘ [0, 1] mixes contactand wall-driven directions, and ğ‘ (ğ‘¥) is an overlap-severity scalar (set to 1 by default, and increased when overlaps are large in order to push more strongly out of infeasible tangles). Î”contact is computed from the contact graph (directions that relieve overlaps), Î”wall from boundary proximity, and ğ‘€ controls the exploration magnitude. After exploration, repair step projects the perturbed configuration back onto the feasible manifold, ensuring that rewards are evaluated on geometrically valid samples. This exploration mechanism plays the same conceptual role as guided MCMC moves in molecular sampling [61] that prevent uniform collapse, it explicitly expands the effective support of the policy so that reward-weighted updates can amplify genuinely novel, higher-reward structures once they are encountered. 2.5. Closing the Loop: Convergence Properties. critical limitation of prior SBO system for mathematical structure discovery, notably PatternBoost [1], is that the boosting loop remains open: there is no mechanism guaranteeing convergence to optimal or near-optimal solutions. In open-loop methods, the generative model learns to mimic the current best solutions but receives no direct signal pushing it toward better and OOD solutions, it matches distribution rather than optimizing an objective. We have addressed this fundamental gap through online reward-guided policy optimization, where rather than treating the generative model as passive density estimator retrained on filtered samples, we fine-tune it with direct feedback from the optimization objective. This transforms the open iterative scheme into closed-loop control system: Open loop: The generative model approximates ğ‘data, the distribution of current best solutions. Improvement relies on sampling and local search occasionally escaping to better basins, an indirect, stochastic process with no gradient signal toward the objective that prompts to lengthy and blind search. Closed loop (ours): The generative model is fine-tuned to maximize expected reward Eğ‘¥ ğ‘ğœƒ [ğ‘…(ğ‘¥)] while remaining close to reference policy. This provides direct optimization signal, where configurations with higher objective values receive higher weight in the policy update, systematically guiding sampling toward better and OOD solutions. The closure mechanism operates through the reward-guided flow matching objective where samples from the current policy are evaluated, and the model is updated to increase the likelihood of high-reward trajectories while the consistency regularization and action exploration prevents mode collapse. Combined with geometry-aware sampling, which maintains geometric feasibility throughout the generative process, this closed-loop formulation enables convergence to near-optimal solutions in much fewer iterations, (110) boosting rounds rather than the (100) iterations characteristic of open-loop methods. 2.6. The FlowBoost Pipeline. The complete FlowBoost pipeline integrates the above components in an iterative boosting loop: 10 (i) Initialization. Generate an initial dataset D0 of configurations by running stochastic relaxation with perturbations (SRP) from random initial conditions. Retain the top fraction (typically 2550%) according to the objective ğ½. (ii) Training. Train conditional flow matching model ğ‘£ (0) ğœƒ on D0 using the combined flow matching and geometric penalty objectives. (iii) Sampling. Sample batch of configurations from ğ‘£ (0) ğœƒ projection-corrected integration. using geometry-aware sampling with (iv) Reward-Guided Fine-Tuning. Evaluate rewards on the refined samples. Apply reward-guided fine-tuning with consistency regularization and geometry-aware action exploration to update the model parameters. (v) Refinement & Selection. Apply local search (SRP followed by L-BFGS optimization) to each generated configuration, obtaining refined batch. (vi) Iteration. Repeat steps 15, obtaining successive model updates ğ‘£ (1) ğœƒ , ğ‘£ (2) ğœƒ , . . . with progressively improving sample quality. Empirically, we observe that in each iteration the distribution of ğ½ over the samples shifts upward, and the best configurations improve over time. The closed-loop structure ensures systematic improvement rather than stochastic drift, with convergence typically achieved within 13 boosting rounds. Remark 2.1. Note that with the closed-loop pipeline, we do not require the extremely long outer boosting iterations of PatternBoost. In such open-loop schemes, the generator is retrained only to imitate the current elite set; improvement is therefore indirect and essentially stochastic as one must repeatedly sample and re-run local search in the hope of occasionally landing in better basin. This makes progress heavily dependent on hundreds to thousands of outer iterations and offers no principled mechanism for systematic ascent. By contrast, our FlowBoost closes the loop, meaning that rewards computed on newly generated (and repaired) configurations directly drive an online update of the generator via reward-guided fine-tuning. As result, the optimization signal is injected where it matters, namely into the parameters of the generative policy, so the dominant driver of improvement becomes small number of targeted inner updates rather than large number of blind outer retrain cycles. 2.7. Local Search: Stochastic Relaxation with Perturbations. The local search component employs variant of stochastic relaxation with perturbations (SRP). Given an initial configuration ğ‘¥ X, we consider smooth surrogate objective (cid:101)ğ½ (ğ‘¥) ğ½ (ğ‘¥) that is differentiable in the ambient Euclidean coordinates. For packing problems, this comprises an overlap energy penalizing sphere intersections and boundary violations, combined with terms proportional to the negative sum of radii. SRP alternates between two phases: (i) random perturbation, adding small random displacements to the configuration, and (ii) gradient relaxation, performing several steps of normalized gradient descent on (cid:101)ğ½, often with an annealing schedule for the step size. For packing problems, SRP is followed by L-BFGS-B optimization over the same surrogate to polish the configuration while respecting box constraints. The key properties of SRP are that it is computationally inexpensive and parallel, robust to initial conditions due to the perturbation and annealing, and captures fine geometric features that may be difficult for global model to learn purely from data. In FlowBoost, we use SRP in two modes: as training-data generator starting from random configurations, and as final refinement step on samples produced by the flow model. In continuous optimization settings, local search simply refers to fast local fixing (or local improvement) procedure: starting from an initial configuration, it repeatedly applies small, inexpensive updates that reduce constraint violations and improve the objective, until it reaches locally stable configuration. In practice, one often has several plausible local search heuristics that all produce near-feasible, near-bestknown configurations, but with markedly different reliability and final quality. This choice is crucial: since our goal is to surpass the best known constructions, the local search mechanism must produce samples that are as strong as possible, both to supply high-quality training data and to provide an effective refinement step for generative samples. Figure 2 illustrates how different geometric heuristics can explore different regions of configuration space and yield radically different solution quality. In this example (circle packing in the unit square), simple physics-push baseline (where each center is iteratively displaced along repulsion direction given 11 Figure 2. Comparison of the minimum-excess metric for two local search heuristics (common circle counts). The physics-push heuristic yields consistently higher minimumexcess values than SRP/SRS, indicating worse configurations across the tested regime. by weighted sum of vectors pointing away from neighbouring centers, with weights proportional to the reciprocal of the inter-center distances) consistently produces substantially worse configurations than SRP across common circle counts. This section contains detailed description of the results of our FlowBoost experiments on geometric 3. Results optimization problems. 3.1. Overview. Sphere Packing. We evaluate FlowBoost on the classical problem of packing ğ‘ non-overlapping spheres of radius ğ‘Ÿ inside ğ‘‘-dimensional unit hypercube, problem that combines geometric rigidity with combinatorial complexity. The objective is to maximize ğ‘Ÿ (equivalently, the packing fraction ğœ™ = ğ‘ volğ‘‘ (ğµğ‘Ÿ )) subject to non-overlap constraints ğ‘¥ğ‘– ğ‘¥ ğ‘— 2ğ‘Ÿ for all pairs and containment constraints ğ‘¥ğ‘– [ğ‘Ÿ, 1 ğ‘Ÿ] ğ‘‘ for all centres. This problem admits no closed-form solution for general ğ‘; even verifying local optimality is NP-hard, and the best known packings for most ğ‘ have been found through extensive computational search. Our investigation of high-dimensional packings is motivated by recent breakthroughs in the asymptotic theory. Viazovska [62] proved that the ğ¸8 lattice achieves the optimal sphere packing density in R8, and together with collaborators [63] established optimality of the Leech lattice in R24. These remain the only dimensions ğ‘‘ > 3 where the densest packing is known. Dimension ğ‘‘ = 12 is particularly interesting as it lies between the solved cases, admits rich lattice structure [64] (e.g., the Coxeter-Todd lattice ğ¾12), yet the optimal packing density remains unknown, making it natural testbed for computational exploration. We report experiments in two regimes: (i) three-dimensional packings for ğ‘ {50, . . . , 89} and ğ‘ {191, 200}, where high-quality reference packings exist from decades of prior work; and (ii) twelve-dimensional packings for ğ‘ 31, where the geometry is far from lattice-like and classical heuristics struggle. In several instances, FlowBoost matches or exceeds the best previously reported packing fractions, and in high-dimensional settings it consistently discovers configurations denser than those produced by simulated annealing or basin-hopping alone. 12 1ğ‘–< ğ‘—<ğ‘˜ ğ‘› ğ´min(ğ‘‹) := min (cid:12)det( ğ‘ ğ‘— ğ‘ğ‘–, ğ‘ğ‘˜ ğ‘ğ‘–)(cid:12) (cid:12) (cid:12), The Heilbronn Problem. We study the classical Heilbronn triangle problem in the unit square: for point set ğ‘‹ = {ğ‘1, . . . , ğ‘ğ‘›} [0, 1]2 one considers the minimum area over all triangles spanned by triples, 1 2 and the goal is to maximize ğ´min(ğ‘‹) over all ğ‘›-point configurations. In our FlowBoost installation, SRP produces an initial elite set by maximizing smooth soft-min surrogate of ğ´min, followed by deterministic L-BFGS-B polish and an active max-min push (SLSQP on the currently smallest-area triangles). conditional flow-matching model is then trained on the top portion of these SRP-refined configurations and used to propose new point sets; each generated candidate is again refined by the same SRP final push before selection. Empirically, the raw generator underperforms the SRP elite distribution, but the final push reliably recovers near-elite configurations, and the closed-loop iteration can exceed the previous best. In our runs we obtain ğ´min = 0.0259285 for ğ‘› = 13 (beating the training maximum in that experiment) and ğ´min = 0.0187494 for ğ‘› = 15, with clear right-shifts in the distributions of ğ´min across FlowBoost iterations. These results approach the best known constructions in [65] ğ´min = 0.0270 for ğ‘› = 13 and ğ´min = 0.0211 for ğ‘› = 15. Circle packing with maximal sum of radii. We study circle packings in the unit square where the objective is to maximize the sum of radii for fixed number ğ‘ of circles, subject to non-overlap and boundary constraints. This problem has been recently attacked by AlphaEvolve and its open-source variants using LLM-based genetic programming to evolve code that produces good packings. In our approach, SRP generates an initial dataset of circle arrangements, and flow-matching model on centers learns to propose new center configurations. The final push stage solves convex optimization problem (via linear programming) to maximize the sum of radii subject to constraints for the given centres, and combines this with an SRP-based refinement. For ğ‘ = 26 and ğ‘ = 32 circles, we obtain configurations whose sum of radii strictly exceeds the best values reported for AlphaEvolve-type methods, while using considerably smaller computational budget. Star discrepancy problem. We also apply FlowBoost to constructing low star-discrepancy point sets in [0, 1]2, central objective in quasi-Monte Carlo integration [6668]. For ğ‘ƒ = {ğ‘1, . . . , ğ‘ ğ‘ } [0, 1]2, the (anchored) star discrepancy is the minimax quantity ğ·(ğ‘ƒ) := sup (ğ‘,ğ‘) [0,1] (cid:12) (cid:12) (cid:12) (cid:12) 1 ğ‘ #(cid:0)ğ‘ƒ ([0, ğ‘) [0, ğ‘))(cid:1) ğ‘ğ‘ (cid:12) (cid:12) (cid:12) (cid:12) , (smaller is better), (3.1) i.e. the worst deviation between empirical mass and volume over anchored axis-aligned boxes. Our local SRP search minimizes differentiable soft-max surrogate of ğ· based on sigmoid-smoothed box indicators and log-sum-exp over grid of anchored boxes; this is followed by L-BFGS-B and exact evaluation of ğ· on the critical grid. conditional flow-matching model (conditioned on (ğ‘, ğ·)) is then trained on the best half of the pushed samples, and sampling interleaves ODE integration with short projection/proximal steps that directly decrease the smooth discrepancy surrogate before the final push. As with Heilbronn, generation alone is not sufficient, but the final push recovers and slightly improves the best tail. In our experiments we obtain ğ· = 0.06290897 for ğ‘ = 20 and ğ· = 0.02943972 for ğ‘ = 60, and the pushed distributions consistently shift left relative to the initial SRP training set. 3.2. Sphere Packing in Hypercube. Model architecture. The velocity field ğ‘£ ğœƒ (ğ‘¥, ğ‘¡) is parameterized by permutation-equivariant Transformer [24, 69] operating on the point-cloud ğ‘¥ = (ğ‘¥1, . . . , ğ‘¥ ğ‘ ) (Rğ‘‘) ğ‘ , where each configuration ğ‘¥ Rğ‘‘ ğ‘ is treated as set of ğ‘ tokens with ğ‘‘-dimensional coordinates. Time information is embedded via random Fourier features combined with polynomial basis functions [70], ğœ™(ğ‘¡) = (cid:2)sin(2ğœ‹ğœ” ğ‘—ğ‘¡), cos(2ğœ‹ğœ” ğ‘—ğ‘¡), ğ‘¡, ğ‘¡2, ğ‘¡3, log(1 + ğ‘¡)(cid:3) ğ¹ , where {ğœ” ğ‘— } are fixed random frequencies. ğ‘—=1 This embedding is projected to conditioning vector and injected into transformer layers via Featurewise Linear Modulation (FiLM) [71]: â„ â„ (1 + ğ›¾) + ğ›½, where (ğ›¾, ğ›½) are predicted from the time-condition embedding. Our architecture further incorporates problem-specific conditioning variable ğ‘¦ = (ğ‘Ÿ/ğ¿, ğ‘, face-contact ratio, min-separation/ğ¿), enabling single to generalize across problem instances by learning conditional probability density ğ‘(Xğ‘¦). For packing in box [ğ‘Ÿ, ğ¿ ğ‘Ÿ] ğ‘‘, the 13 base distribution is uniform in the feasible box but does not enforce non-overlap. As result, we have geometry-aware prior that improves coverage of boundary-touching structures by placing each point on randomly chosen box, then adding small jitter. This prior is conditional on ğ‘¦ and improves sample efficiency in regimes where high-quality solutions exhibit frequent face contacts. Key hyperparameters are: model dimension 512, depth 2 layers, 8 attention heads, and GLU [72] feed-forward blocks with RMSNorm [73]. The output layer is zero-initialized to ensure the initial velocity field is near-constant, stabilizing early training. Total parameter count is approximately 2M. Training. Initial datasets are generated via Stochastic Repulsion Push (SRP), physics-inspired local search that eliminates overlaps through annealed gradient descent on soft-overlap energy. We retain the top 510% of configurations ranked by packing fraction. The flow-matching model is trained for 200500 epochs using the AdamW variant with schedule-free learning rate adaptation, batch size 128, and gradient clipping at norm 1.0. An auxiliary penalty encouraging large pairwise separations is ramped in over the first half of training via cosine schedule. Time sampling is biased toward small ğ‘¡ (near-data regime) using mixture distribution with weight 0.5 on power-law component (ğ›¾ = 2). Sampling. Geometry-Aware Sampling (GAS) integrates the learned velocity field from ğœ = 0 (prior) to ğœ = 1 (data) using midpoint ODE solver with 40 60 steps. At each step, GaussNewton projection enforces non-overlap and wall constraints, followed by proximal relaxation that anchors the trajectory to the optimal-transport path. Terminal refinement applies additional projection passes until the maximum overlap residual falls below 108. The prior distribution places centers uniformly on box faces with small jitter, providing geometric diversity while respecting approximate containment. We then fine-tune the pretrained model using reward guidance. The teacher model (frozen at pretrained weights) provides consistency targets while the student model is updated via importance-weighted flow matching with temperature ğœ [0.5, 2.0] and consistency coefficient ğ›¼ [0.1, 0.5]. Each fine-tuning epoch samples batch of 128256 configurations from the current student policy via GAS, evaluates their effective radii ğ‘Ÿeff = 1 2 minğ‘–< ğ‘— ğ‘¥ğ‘– ğ‘¥ ğ‘— , computes ğ‘§-scored importance weights, and performs ten gradient step. Fine-tuning typically converges within 210 epochs, after which the best configurations are passed to SRP for final polishing. The required steps for single GAS sample plus projection overhead, is comparable in wall-clock time to 100 L-BFGS-B iterations. However, the important things is that the generative model produces diverse samples that explore multiple basins simultaneously, whereas local search must be restarted from scratch to escape given basin. In practice, 103 GAS samples explore the configuration space more thoroughly than 104 SRP restarts, yielding both higher peak quality and better coverage of near-optimal configurations. 3.2.1. Results. We benchmark against the Packomania database [74] , which compiles the best known packings for ğ‘ 200 spheres in the unit hypercube, obtained through decades of simulated annealing, genetic algorithms, and manual refinement. For ğ‘ = 50 200, we apply the FlowBoost pipeline: train on SRP-generated data, sample with GAS, fine-tune with reward guidance, and refine with SRP, and iterate. Across 15 boosting rounds, the generative model progressively shifts probability mass toward higher-quality basins. We also provide comparision against PatternBoost. Figure 4 directly compares FlowBoost against PatternBoost for ğ‘ = 89 spheres. Two findings stand out. First, RG-CFM without local refinement achieves comparable peak quality to PatternBoost even with SRP push demonstrating that reward-guided flow matching partially internalizes the refinement that PatternBoost delegates entirely to post-hoc search. Second, RG-CFM with push exceeds both the training maximum and PatternBoosts best result, while requiring less outer iterations and sampling time. This reduction in convergence time, combined with the elimination of LLM dependencies, constitutes the primary computational advantage of the closed-loop formulation. 12D Sphere Packing. High-dimensional sphere packing presents qualitatively different challenges: the configuration space grows exponentially, local search becomes trapped in shallow basins, and there is no lattice structure to exploit for small ğ‘. We test FlowBoost on ğ‘ = 31 spheres in the 12-dimensional hypercube cube, regime where even generating feasible packings is nontrivial. In high-dimensional packing, any improvement over extensive local search is noteworthy. The training dataset comprises (103) configurations generated by SRP with random restarts that is strong baseline that has been refined over many iterations. That single round of RG-CFM fine-tuning yields configuration exceeding 14 Table 2. Computational comparison for ğ‘ = 89, ğ‘‘ = 3. Wall-clock times on single A100 GPU. FLOPs exclude local search. Method Parameters PatternBoost FlowBoost 8M 2M Iterations FLOPs Wall-clock (10100) 1012 108 (110) 10100 0.52 this entire datasets maximum suggests that the learned surrogate captures geometric structure invisible to coordinate-wise local search. (a) ğ‘ = 55: training vs. RG-CFM (pushed). (b) ğ‘ = 83: training vs. RG-CFM (pushed). (c) ğ‘ = 191: training vs. RG-CFM (pushed). (d) ğ‘ = 83: ablation of reward guidance. Figure 3. Sphere packing in ğ‘‘ = 3. (ac) Normalized histograms of minimum pairwise distance (log scale). In all cases, RG-CFM with final push (blue) recovers the training distribution and yields configurations exceeding the training maximum: ğ‘‘min = 0.261231 vs. 0.261027 for ğ‘ = 55; 0.232539 vs. 0.232529 for ğ‘ = 83; 0.180671 vs. 0.180350 for ğ‘ = 191. (d) Ablation comparing vanilla CFM (orange) against reward-guided CFM (green) for ğ‘ = 83: reward guidance with action exploration shifts the distribution toward min = 0.2236 vs. 0.2157), demonstrating that direct objective higher-quality samples (ğ‘‘max feedback improves generation quality prior to local refinement. The pattern mirrors lower-dimensional results: raw flow samples require geometric repair, but the pushed distribution matches the training regime while the closed-loop update enables discovery of configurations exceeding the training maximum. For ğ‘ = 31, starting from SRP-generated packings with best minimum separation ğ‘‘min = 0.673721, single round of RG-CFM fine-tuning yields ğ‘‘min = 0.673819, an improvement in regime where any progress is nontrivial. Large-training-set runs (long per-iteration training). Figure 6 summarizes runs with large SRP-generated training set and long per-iteration flow matching model training (3000 epochs) for ğ‘ {71, 73, 79, 97, 191}. In each case the main effect of boosting is strong right-shift and concentration of the distribution: Figure 4. 3D Sphere Packing in Cube, ğ‘› = 89. The comparison between PatternBoost, RG-CFM, and their pushed version with the training data. Our Reward-guided fine tuning alone could provide the same performance as the expensive PatternBoost and SRP Push combined, while the pushed version of RG-CFM could improve the max over the training data. (a) Training vs. generated vs. pushed. (b) Training vs. pushed (zoomed). Figure 5. Sphere packing in ğ‘‘ = 12, ğ‘ = 31. Normalized histograms of minimum pairwise distance (log scale). high-ğ‘‘min configurations become substantially more frequent, and the mean improves monotonically, while the absolute best value typically improves only slightly (or stays essentially fixed). Concretely, ğ‘ = 71: mean improves from 0.239324 (training) to 0.245881 (iteration 4), while the best improves marginally from 0.246022 to 0.246030. ğ‘ = 73: mean improves from 0.239102 (training) to 0.242334 (iteration 4), with best improves from ğ‘ = 79: mean improves from 0.232706 (training) to 0.234299 (iteration 4), with best unchanged at ğ‘ = 97: mean improves from 0.217635 (training) to 0.222428 (iteration 4), and the best improves ğ‘ = 191: mean improves from 0.172388 (training) to 0.176189 (iteration 7), and the best improves 0.243537 to 0.243545. 0.235913. from 0.222983 to 0.223019. from 0.180148 to 0.180671. 16 Thus, even if the best value is hard to move, FlowBoost substantially increases the probability of sampling near-record configurations after the final push. For context, best-known values for spheres-in-a-cube are often benchmarked against the Packomania database.1 Many-iteration test for ğ‘ = 191: short training per step. Figure 7 shows complementary experiment at ğ‘ = 191 with smaller per-iteration budget (500 samples; 300 epochs per iteration) but more than 100 pipeline iterations. Here the maximum effective radius remains essentially flat, while the average effective radius increases steadily across iterations. This is the behavior one expects from stable closed-loop booster under limited compute: the pipeline learns to place more mass in good basins (raising the mean) even when discovering strictly better extreme configuration is rare. 3.3. The Heilbronn Problem. We test FlowBoost on the classical Heilbronn triangle problem in the unit square. 3.3.1. Local search. As described in Section 2, we use an SRP local search algorithm both for generating training data and for the final push applied to model samples. For Heilbronn we use differentiable surrogate that interpolates between smooth global objective and the hard minimum. We replace the ğ‘¢2 + ğœ€ (ğœ€ = 1012), and define the smoothed non-differentiable absolute value by the smooth proxy ğ‘¢ triangle area ğ´( ğœ€) ğ‘– ğ‘— ğ‘˜ (ğ‘‹) := 1 2 det( ğ‘ ğ‘— ğ‘ğ‘–, ğ‘ğ‘˜ ğ‘ğ‘–)2 + ğœ€, 1 ğ‘– < ğ‘— < ğ‘˜ ğ‘›. To approximate the hard minimum ğ´min(ğ‘‹) = minğ‘–< ğ‘—<ğ‘˜ ğ´ğ‘– ğ‘— ğ‘˜ (ğ‘‹) in differentiable way, we use the soft-min (log-sum-exp) at sharpness ğ›½ > 0: sminğ›½ (ğ‘‹) := 1 ğ›½ log ğ‘–< ğ‘—<ğ‘˜ exp(cid:0)ğ›½ ğ´( ğœ€) ğ‘– ğ‘— ğ‘˜ (ğ‘‹)(cid:1). Let ğ‘‡ = (cid:0)ğ‘› 3 (cid:1) and ğ‘š(ğ‘‹) := minğ‘–< ğ‘—<ğ‘˜ ğ´( ğœ€) ğ‘– ğ‘— ğ‘˜ (ğ‘‹). Then the standard log-sum-exp bounds give ğ‘š(ğ‘‹) log ğ‘‡ ğ›½ sminğ›½ (ğ‘‹) ğ‘š(ğ‘‹), (3.2) (3.3) so increasing ğ›½ tightens the approximation (up to an explicit log ğ‘‡/ğ›½ gap). In practice we anneal ğ›½ geometrically from ğ›½0 to ğ›½ğ¹, which has the effect of starting with smoother objective (many triangles contribute) and gradually concentrating optimization pressure on the worst triangle(s). We optimize the SRP surrogate loss Lğ›½ (ğ‘‹) = ğ‘¤wallğ‘Š (ğ‘‹) sminğ›½ (ğ‘‹), (3.4) where ğ‘Š (ğ‘‹) is quadratic wall penalty that discourages leaving [0, 1]2 (and we additionally clamp coordinates after each SRP step) and ğ‘¤wall > 0 is the penalty weight that controls how strongly SRP discourages leaving the unit square: larger ğ‘¤wall makes boundary violations more expensive (a standard quadratic-penalty mechanism for constraints). In the reported runs we use geometric annealing ğ›½0 ğ›½ğ¹ with ğ›½0 = 40 and ğ›½ğ¹ = 300. For large ğ›½ the sum in (3.2) is dominated by the smallest triangle areas. To reduce computation we optionally restrict the log-sum-exp to the ğ¾ smallest triangles under the current iterate ğ‘‹ (with small tolerance), i.e. we replace the full index set by an active subset of size ğ¾ (here ğ¾ = 100). This keeps the dominant terms while avoiding work on clearly non-critical triangles. After SRP we apply deterministic L-BFGS-B polish to (locally) minimize Lğ›½ğ¹ under box constraints. L-BFGS-B is quasi-Newton method implemented in scipy.optimize.minimize(method=\"L-BFGS-B\"), that stores only low-rank approximation of curvature information, making it well suited to highdimensional problems with simple bounds. To target the true max-min objective more directly, we then solve lifted nonlinear program in variables (ğ‘‹, ğ‘¡): max ğ‘¡ s.t. ğ´ğ‘– ğ‘— ğ‘˜ (ğ‘‹) ğ‘¡ ğ‘– < ğ‘— < ğ‘˜, ğ‘‹ [0, 1]2ğ‘›. Since only few constraints are typically tight at good solution, we enforce this system only for an active set consisting of the ğ¾active currently smallest-area triangles (here ğ¾active = 25), and run an SLSQP step 1https://www.packomania.com/. 17 ğ‘ = 71 ğ‘ = 73 ğ‘ = 79 ğ‘ = ğ‘ = 191 Figure 6. 3D unit-cube packing proxy: large training set; long per-iteration training. The distribution of ğ‘‘min shifts right over iterations, improving both the mean and the best observed value. on these constraints.2This active max-min pass is applied only to small elite subset of candidates (top 10 configurations) during training-set generation, and again as the final push on flow-generated samples. 2SLSQP stands for Sequential scipy.optimize.minimize(method=\"SLSQP\"). bound constraints and general equality/inequality constraints. Least Squares in It is standard nonlinear constrained optimizer supporting both Programming, implemented as 18 (a) Distribution snapshots (ğ‘ = 191). (b) Mean/max ğ‘Ÿeff vs. iteration. Figure 7. Many-iteration regime for ğ‘ = 191: small per-iteration budget. (a) shows histogram snapshots of ğ‘Ÿeff = 1 ğ‘‘min at selected iterations. (b) tracks the average and 2 maximum ğ‘Ÿeff across > 100 pipeline steps: the maximum remains stable, while the average improves monotonically, indicating steady shift of mass toward better basins. 3.3.2. Training and sampling. We use the conditional flow matching setup from Section 2, with permutation-equivariant set transformer velocity field. The conditioning encodes the problem size and the target quality ğ‘(ğ‘‹) = , and an auxiliary penalty encourages the projected endpoint (as in Section 2) to achieve soft-min triangle area at least as large as the target. , ğ´min(ğ‘‹) (cid:16) ğ‘› 128 (cid:17) At sampling we follow the same geometry-aware sampling principle as GAS (Section 2), specialized to the Heilbronn objective: between ODE steps we perform short projected gradient-ascent moves on the soft-min triangle area (with an annealed temperature ğœstart = 5 103 ğœend = 5 104), and we end with brief polishing stage. Finally, every generated configuration is passed through the SRP final push above, and only then compared using exact ğ´min. 3.3.3. Experimental settings. For ğ‘› = 15 we generate 1000 SRP samples for training, keeping the top 50% by ğ´min for model fitting. SRP uses ğ¼max = 500 outer iterations, ğ‘š = 60 inner steps, step size 0.035 with decay 0.994, and backtracking budget 6; L-BFGS-B uses gtol 108, ftol 1012, maxiter 2000. The flow model uses set transformer of width 256, depth 6, and 8 heads, trained for 500 epochs with batch size 64 and learning rate 104. Sampling uses 30 PCFM steps (Euler, step cap 0.05), with 2 projection and 2 proximal steps per PCFM step, plus 20-step terminal polish. 3.3.4. Results. Figures 89 show the empirical distributions of ğ´min for ğ‘› = 13 and ğ‘› = 15. The main pattern is consistent across both sizes: Raw flow samples are worse than SRP elites. Without final push (local refinement), generated samples are left-shifted (many near-degenerate triangles remain). The final push repairs samples effectively and moves the distribution back toward the training regime and recovers near-elite maxima. Boosting can exceed the training maximum. Across iterations, the best observed ğ´min improves and the histogram mass shifts right, indicating that the closed-loop trainsamplepushselect cycle can produce configurations that beat the previous elite set. Concretely, for ğ‘› = 13 (Figure 8): the training max is 0.0257271, raw generation reaches 0.0210753, while pushing recovers 0.0254702; over iterations the maximum improves to 0.0259285 (iteration 2), exceeding the training maximum in that run. For ğ‘› = 15 (Figure 9): the training max is 0.0184912 19 (a) Training vs. generated vs. pushed. (b) Iterations 13. Figure 8. Heilbronn, ğ‘› = 13. Normalized histograms of exact ğ´min. Legends report the best achieved ğ´min in each set. (a) Training vs. generated vs. pushed. (b) Iterations 13. Figure 9. Heilbronn, ğ‘› = 15. Normalized histograms of exact ğ´min. The final push converts \"almost-good\" samples into strong local optima, enabling iterative improvement. (resp. 0.0181293 in the iterative plot), raw generation is 0.0142529, pushing recovers 0.0183984, and the iterative run improves to 0.0187494 by iteration 2 (matched again in iteration 3). 3.4. Circles in Unit Square with Maximal Sum of Radii. Given ğ‘› circles in the unit square, the objective is to maximize the total sum of radii. Improving the sum typically requires coordinated global rearrangements of the contact graph, while feasibility is defined by large family of hard inequalities. configuration consists of centers and radii ğ‘‹ = (cid:0)( ğ‘1, ğ‘Ÿ1), . . . , ( ğ‘ğ‘›, ğ‘Ÿğ‘›)(cid:1), ğ‘ğ‘– = (ğ‘¥ğ‘–, ğ‘¦ğ‘–) [0, 1]2, ğ‘Ÿğ‘– 0. We require containment and non-overlap: ğ‘Ÿğ‘– ğ‘¥ğ‘–, ğ‘Ÿğ‘– 1 ğ‘¥ğ‘–, ğ‘Ÿğ‘– ğ‘¦ğ‘–, ğ‘Ÿğ‘– 1 ğ‘¦ğ‘– and ğ‘ğ‘– ğ‘ ğ‘— ğ‘Ÿğ‘– + ğ‘Ÿ ğ‘— (ğ‘– ğ‘—). (3.5) 3.4.1. Local search. As in Section 2, SRP is used both to generate the training set and as the final push applied to flow samples. In the sum-of-radii setting SRP acts on the full variable vector ğ‘‹ = (cid:0)ğ‘1, . . . , ğ‘ğ‘›, ğ‘Ÿ1, . . . , ğ‘Ÿğ‘›(cid:1) ([0, 1]2)ğ‘› [0, 1 2 ] ğ‘›, ğ‘ğ‘– = (ğ‘¥ğ‘–, ğ‘¦ğ‘–), 20 ğ‘› = 13, ğ´min = 0.0259285138 ğ‘› = 15, ğ´min = 0.0187493936 Figure 10. Best Heilbronn configurations found by FlowBoost (after final push). The highlighted triangle(s) attain the minimum area. The best known constructions are ğ´min = 0.0270 for ğ‘› = 13 and ğ´min = 0.0211 for ğ‘› = 15 in [65]. and minimizes the smooth penalty objective (cid:101)L (ğ‘‹) = ğ‘¤wall ğ‘› (cid:16) [ğ‘Ÿğ‘–ğ‘¥ğ‘–]2 ++[ğ‘Ÿğ‘–(1ğ‘¥ğ‘–)]2 ++[ğ‘Ÿğ‘–ğ‘¦ğ‘–] ++[ğ‘Ÿğ‘–(1ğ‘¦ğ‘–)]2 + (cid:17) +ğ‘¤ov [ğ‘Ÿğ‘–+ğ‘Ÿ ğ‘— ğ‘ğ‘–ğ‘ ğ‘— ]2 +ğ›¼ ğ‘› ğ‘Ÿğ‘–, ğ‘–=1 ğ‘–=1 (3.6) followed by deterministic L-BFGS-B polish (SciPy) under the box bounds ğ‘ğ‘– [0, 1]2 and ğ‘Ÿğ‘– [0, 1/2]. Heuristically, the first two (quadratic) terms drive constraint violations to zero (walls and overlaps), while the last term encourages large total radius. ğ‘–< ğ‘— After SRP+L-BFGS-B we apply post-processing step: we freeze the centers ğ‘1, . . . , ğ‘ğ‘› produced by the local search and then recompute radii by solving the exact max-sum-radii linear program: ğ‘› ğ‘–=1 max ğ‘Ÿ Rğ‘› 0 ğ‘Ÿğ‘– s.t. ğ‘Ÿğ‘– min{ğ‘¥ğ‘–, 1 ğ‘¥ğ‘–, ğ‘¦ğ‘–, 1 ğ‘¦ğ‘– }, ğ‘Ÿğ‘– + ğ‘Ÿ ğ‘— ğ‘ğ‘– ğ‘ ğ‘— (ğ‘– < ğ‘—). (3.7) This LP is solved with the HiGHS backend via scipy.optimize.linprog(method=\"highs\"). The LP (3.7) returns vector ğ‘Ÿ that is (weakly) feasible by construction for the frozen centers ğ‘1, . . . , ğ‘ğ‘›: the circles are allowed to be tangent to each other or to the boundary. Since the objective is (cid:205)ğ‘– ğ‘Ÿğ‘–, this ğ‘Ÿ maximizes the total radius among all radii compatible with the given centers. In practice we then apply tiny safety shrink before saving/plotting: ğ‘Ÿğ‘– max{0, ğ‘Ÿ ğ‘– ğ›¿} (ğ›¿ 109), so that strict inequalities ğ‘Ÿğ‘– + ğ‘Ÿ ğ‘— < ğ‘ğ‘– ğ‘ ğ‘— and ğ‘Ÿğ‘– < min{ğ‘¥ğ‘–, 1 ğ‘¥ğ‘–, ğ‘¦ğ‘–, 1 ğ‘¦ğ‘– } hold numerically. This does not change the geometry in any meaningful way (it perturbs (cid:205)ğ‘– ğ‘Ÿğ‘– by at most ğ‘›ğ›¿), but it prevents borderline tangencies from appearing as tiny overlaps due to rounding error in downstream evaluation and visualization. Note that the LP is not used instead of SRP; rather, SRP (and the polish) searches for good geometry of centers, while the LP performs an exact hard projection of the radii to the best feasible values compatible with that geometry. This plays the same conceptual role as projection step in GAS: it enforces the hard constraints and optimizes the objective in subproblem that becomes convex/linear once the centers are fixed. For pushed flow samples we use slightly more robust variant: keeping the flow-generated centers fixed, we run SRP+polish+LP twice, once initialized from the flow radii and once from small random radii, and keep the better outcome by (cid:205) ğ‘Ÿğ‘–. This mitigates occasional poor radius initialization from the generator. 21 3.4.2. Training and sampling. Our flow model generates centers only. Concretely, the set-transformer velocity field is trained on (ğ‘¥, ğ‘¦)-tokens (two channels), while radii are treated as auxiliary data used only to compute conditioning statistics and to evaluate/push samples. This decoupling is deliberate: radii are highly constrained by the contact graph and are cheaply recovered by the LP (3.7) once good centers are found. Each training sample carries the summary statistics ğ‘(ğ‘‹) = (cid:16) ğ‘› 128 , ğ‘– ğ‘Ÿğ‘–, min ğ‘–< ğ‘— (cid:0) ğ‘ğ‘– ğ‘ ğ‘— (ğ‘Ÿğ‘– + ğ‘Ÿ ğ‘—)(cid:1), min ğ‘– min{ğ‘¥ğ‘– ğ‘Ÿğ‘–, 1 ğ‘¥ğ‘– ğ‘Ÿğ‘–, ğ‘¦ğ‘– ğ‘Ÿğ‘–, 1 ğ‘¦ğ‘– ğ‘Ÿğ‘– } (cid:17) , so the model sees both target quality ((cid:205) ğ‘Ÿğ‘–) and slack information (pair and wall clearances). Sampling follows the PCFM-style loop used throughout (Section 2): we integrate the learned ODE for centers and interleave with simple box projection for feasibility of centers. Radii are then set to zero at generation time and recovered by the final push (SRP+LP) before scoring. 3.4.3. Experimental settings. In the runs shown below we use 3000 samples per iteration for each ğ‘› {26, 30, 32}. representative configuration (used for ğ‘› = 26 centers-only retrain-and-sample) is: batch size 64, learning rate 2 104, 1000 epochs, and train_top_fraction= 0.5; sampling uses pcfm_steps= 40 with midpoint integration and small projection/proximal schedule. 3.4.4. Results. Figures 11-13 show the empirical distributions of (cid:205)ğ‘– ğ‘Ÿğ‘– over successive FlowBoost iterations. Across all three ğ‘›, the main effect of boosting is to shift probability mass toward the right tail: the mean increases slightly and the low-score mass is reduced, while the best observed configurations remain at the extreme right edge of the distribution. For ğ‘› = 26 the training distribution has mean 2.6156 and maximum 2.635809. After one FlowBoost iteration the mean increases to 2.6183 (and remains 2.6177 in the second), with visible right-shift and reduced variance, while the maximum is maintained at 2.635809. In particular, the pipeline reliably reproduces near-record configurations and increases their frequency. For ğ‘› = 30 the distributions are already tight around (cid:205) ğ‘Ÿğ‘– 2.82. Boosting primarily trims the left tail; the mean is stable ( 2.820) and the maximum stays at 2.842435 across three iterations. For ğ‘› = 32 we observe the clearest sustained right-shift at ğ‘› = 32: the mean increases from 2.9161 (training) to 2.9180 (iteration 2), and the upper tail becomes denser while maintaining the maximum 2.939349. This regime is particularly sensitive to global rearrangements of the contact graph, and the \"centers-only\" generator plus LP/SRP push appears to be an effective division of labor. Remark 3.1. The AlphaEvolve report states (cid:205) ğ‘Ÿğ‘– 2.635 for ğ‘› = 26 and (cid:205) ğ‘Ÿğ‘– 2.937 for ğ‘› = 32 (rounded/thresholded in the paper figure). Our best values in Figures 11 and 13 beat these reported thresholds, and the main benefit of FlowBoost is that such near-extremal solutions occur with substantially higher frequency in the generated-and-pushed distribution. 3.5. Star Discrepancy Minimization. The star discrepancy problem asks to place ğ‘› points in the unit square so that they are as uniformly distributed as possible, i.e. minimizing the worst-case deviation between the fraction of points in any axis-aligned box anchored at the origin and that boxs area. 3.5.1. Local search. As in the previous problems, SRP serves both as training-set generator and as the final push (local search) to repair flow samples (Section 2). Here the local search is driven by smooth approximation of the minimax objective in (3.1), obtained by (i) smoothing the box indicators and (ii) replacing the supremum over all anchored boxes by soft-max over finite set of candidate boxes. An anchored box is parametrized by its upper-right corner ğ‘ = (ğ‘, ğ‘) [0, 1]2, i.e. [0, ğ‘) [0, ğ‘). In the smooth surrogate we do not optimize over continuum of corners ğ‘; instead we choose two finite grids ğ´ğ‘¥ (0, 1], ğ´ğ‘¦ (0, 1], and restrict attention to the discrete family of boxes with corners (ğ‘, ğ‘) ğ´ğ‘¥ ğ´ğ‘¦. We refer to ğ´ğ‘¥ and ğ´ğ‘¦ as the evaluation grids (or anchored grids) for the surrogate: they specify which anchored boxes are probed when approximating the worst-case discrepancy. In our implementation ğ´ğ‘¥, ğ´ğ‘¦ are either (a) fixed uniform grid (for stable comparisons), or (b) critical grid obtained from the current point coordinates (unique ğ‘¥and ğ‘¦-coordinates, with 1 included), refreshed periodically during SRP. 22 Figure 11. Sum-of-radii circle packing, ğ‘› = 26. Normalized histograms of (cid:205)ğ‘– ğ‘Ÿğ‘– over the training set and two FlowBoost iterations (each with 3000 samples, after final push). For an anchored box (ğ‘, ğ‘) we approximate the indicator 1ğ‘¥ğ‘– <ğ‘1ğ‘¦ğ‘– <ğ‘ by product of sigmoids 1ğ‘¥ğ‘– <ğ‘ ğœ (cid:16) ğ‘ ğ‘¥ğ‘– ğœ (cid:17) , 1ğ‘¦ğ‘– <ğ‘ ğœ (cid:18) ğ‘ ğ‘¦ğ‘– ğœ (cid:19) , with gate temperature ğœ = tau_sigmoid. For (ğ‘, ğ‘) ğ´ğ‘¥ ğ´ğ‘¦ we then define the smoothed discrepancy at that box by Î”(ğ‘, ğ‘) := 1 ğ‘ ğ‘ ğ‘–=1 ğœ (cid:16) ğ‘ ğ‘¥ğ‘– ğœ (cid:17) ğœ (cid:19) (cid:18) ğ‘ ğ‘¦ğ‘– ğœ ğ‘ğ‘, Î” Î”2 + ğœ€, Î”2 + ğœ€ term (with small ğœ€) provides differentiable proxy for Î”. The SRP objective then where the aggregates these values over the grid (via log-sum-exp soft-max, as described next), so that improving the surrogate corresponds to reducing the worst anchored-box error among the boxes on the chosen grid. We then approximate the supremum in (3.1) by log-sum-exp (softmax) at sharpness ğ›½: (cid:101)ğ· ğ›½, ğœ (ğ‘ƒ) := 1 ğ›½ log (cid:16) exp ğ›½ Î”(ğ‘, ğ‘)2 + ğœ€ (cid:17) . (ğ‘,ğ‘) ğ´ğ‘¥ ğ´ğ‘¦ (3.8) SRP anneals ğ›½ from beta_softmax_start to beta_softmax_final, so early iterations smooth over many boxes, while later iterations concentrate on near-worst boxes. For efficiency we optionally restrict to the top-ğ¾ boxes with largest Î” (Top-ğ¾ mode), and we update the \"critical\" grid periodically during SRP. The push stage is SRP on (cid:101)ğ· ğ›½, ğœ (with clipping to [0, 1]2), followed by L-BFGS-B on the same surrogate. The exact ğ· is then recomputed and used for selection and sorting. 3.5.2. Training and sampling. The flow model is the same permutation-equivariant set-transformer , where ğ·(ğ‘ƒ) is the exact velocity field as in Section 2, now conditioned by ğ‘(ğ‘ƒ) = discrepancy of the training sample. In addition to the standard flow-matching regression, we include an auxiliary penalty (again as in Section 2) that discourages the projected endpoint from having larger smooth discrepancy than its target, i.e. it penalizes ( (cid:101)ğ· ğ›½, ğœ ğ·(ğ‘ƒ))+. , ğ·(ğ‘ƒ) (cid:16) ğ‘ (cid:17) 23 Figure 12. Sum-of-radii circle packing, ğ‘› = 30. Normalized histograms of (cid:205)ğ‘– ğ‘Ÿğ‘– over the training set and three FlowBoost iterations (each with 3000 samples, after final push). Sampling uses PCFM-style loop: we integrate the learned ODE and interleave short gradient steps that decrease the differentiable surrogate (3.8) (projection) plus proximal relaxation toward the path blend. The initial noise distribution ğ‘¥1 is taken to be Latin hypercube sampling (LHS), which provides stronger geometric baseline than i.i.d. uniform points. As with other tasks, all samples are evaluated only after the SRP final push. 3.5.3. Results. Figures 15 and 16 summarize experiments for ğ‘ = 20 and ğ‘ = 60 points (each histogram uses the sample counts stated in the legends). Two consistent effects stand out like for the other tested problems: Generation alone is not enough. The raw flow samples (green) have substantially worse discrepancy (larger ğ·), reflecting that minimax structure is hard to hit without local correction. The final push closes the gap (and can slightly improve records). After SRP+L-BFGS-B, the pushed distribution (blue) essentially matches the training regime and modestly improves the best observed values. For ğ‘ = 20, the training set has mean 0.070105 with best (minimum) 0.063117. Raw generation degrades badly (mean 0.089340). After the final push, the mean improves to 0.069120 and the best value improves slightly to 0.062909 (Figure 15a). In the iterative view (Figure 15b), the first iteration produces the best tail; the second iteration remains better on average than training but does not further improve the minimum. For ğ‘ = 60 the same phenomenon is more dramatic: raw generation produces discrepancies around 0.08 (mean 0.080165), while the pushed distribution returns to the training scale 0.035 (Figure 16a). Across iterations (Figure 16b), improvements are necessarily small because the training distribution is already tight; nevertheless, iteration 2 improves the best observed value from 0.029515 to 0.029440 and slightly reduces the worst tail (max drops from 0.041322 to 0.040977). 24 Figure 13. Sum-of-radii circle packing, ğ‘› = 32. Normalized histograms of (cid:205)ğ‘– ğ‘Ÿğ‘– over the training set and three FlowBoost iterations (each with 3000 samples, after final push). 4. Conclusion We have introduced FlowBoost, reward-guided closed-loop generative framework for continuous simulation-based optimization that synthesizes ideas from flow-based generative modeling, self-supervised representation learning, and reinforcement learning. The core insight is that generative models need not be passive density estimators trained on static datasets; instead, they can be active participants in the optimization process, receiving direct feedback from the objective function and adapting their sampling distribution accordingly. The framework rests on three components. First, Conditional Flow Matching learns velocity field that transports source distribution to the empirical distribution of high-quality solutions, providing smooth, low-dimensional parameterisation of the solution manifold. Second, Geometry-Aware Sampling integrates this vector field while enforcing hard constraints through interleaved projection and proximal relaxation, ensuring that generated samples are geometrically valid without sacrificing fidelity to the learned distribution. Third, Reward-Guided CFM fine-tunes the generative model online using importance-weighted reward, with consistency regulariser, inspired by teacherstudent architectures in self-supervised learning, that prevents the failure mode of generative collapse. The transition from open-loop to closed-loop optimization is the key conceptual advance. In previous open-loop methods, the generative model approximates the distribution of current best solutions, and improvement relies on mere stochastic hope that sampling occasionally escapes to better basins. In our closed-loop method, the model is fine-tuned online with direct gradient signal from the reward function, systematically guiding sampling toward higher-quality regions while the consistency term maintains the diversity necessary for continued exploration. This transforms the boosting loop from an indirect, variance-driven process into principled policy-optimization algorithm with controllable convergence behaviour. We have demonstrated the effectiveness of FlowBoost on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, 25 ğ‘› = 26, (cid:205) ğ‘Ÿğ‘– = 2.6358 (A) ğ‘› = 26, (cid:205) ğ‘Ÿğ‘– = 2.6358 (B) ğ‘› = 30, (cid:205) ğ‘Ÿğ‘– = 2.8424 (A) ğ‘› = 30, (cid:205) ğ‘Ÿğ‘– = 2.8424 (B) ğ‘› = 32, (cid:205) ğ‘Ÿğ‘– = 2.9393 (A) ğ‘› = 32, (cid:205) ğ‘Ÿğ‘– = 2.9393 (B) Figure 14. Best sum-of-radii circle packings found by FlowBoost (after final push). For each ğ‘› {26, 30, 32} we show two distinct arrangements (A/B) attaining the same best objective value (cid:205)ğ‘› ğ‘Ÿğ‘–. For ğ‘› = 26 and ğ‘› = 32 these beat the best known result ğ‘–=1 found by AlphaEvolve [2]. (a) Training vs. generated vs. pushed. (b) Training vs. pushed iterations 12. Figure 15. Exact star discrepancy, ğ‘ = 20. Normalized histograms of ğ· (smaller is better). and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. Crucially, the closed-loop variant achieves these results in remarkably few iterations, beating the available data within single boosting round, whereas open-loop methods require orders of magnitude more samples to reach comparable quality. 4.1. Discussion and Future Directions. Several directions for future work emerge from this study. FlowBoost is suitable to study broad family of extremal problems in algebra, geometry, combinatorics 26 (a) Training vs. generated vs. pushed. (b) Training vs. pushed iterations 12. Figure 16. Exact star discrepancy, ğ‘ = 60. The final push is essential: raw generation is far off-scale, but pushing recovers and slightly improves the best tail. ğ‘ = 20, ğ· = 0.06290897 ğ‘ = 60, ğ· = 0.02943972 Figure 17. Best star-discrepancy point sets found by FlowBoost: they beat the best known constructions 0.073086 (ğ‘ = 20) and 0.032772 (ğ‘ = 60) in [67] and for ğ‘ = 20 it approaches the optimal 0.0604 proved in [66]. and number theory, such as covering problems, discrepancy minimization in higher dimensions, energy minimization on manifolds, optimal transport, constraint-satisfaction problems with continuous variables (e.g. counter-example mining). Many of these share the structure that makes FlowBoost effective, smooth objective landscape with many local optima, hard constraints that define complex feasible region, and lack of exploitable algebraic structure. We anticipate that the same pipeline, with problem-specific adaptations to the projection operator and reward function, will prove effective across this family. The current framework treats the reward function as black box, querying it only at generated samples. Incorporating gradient information from differentiable objectives, or learning surrogate reward model for expensive-to-evaluate functions, could substantially accelerate convergence. Similarly, the teacher-student architecture admits natural extensions, namely an exponential moving average (EMA) teacher, as in DINO [52] and BYOL [57], might provide smoother consistency targets than frozen checkpoint, and curriculum strategies that progressively tighten the consistency constraint could enable more aggressive exploration in early stages. From broader perspective, our experiments suggest that flow-based generative models are not merely tools for image or signal synthesis, but can serve as robust and flexible components in computational and experimental mathematics. The key enabling insight is that the same architectures and training objectives that capture complex data distributions can, with appropriate closed-loop feedback, be repurposed to improve upon those distributions toward extremal configurations. We hope that FlowBoost contributes to growing paradigm in which machine learning and experimental mathematics are not separate disciplines but mutually reinforcing tools for discovery. Acknowledgment The authors would like to thank the Center of Mathematical Sciences and Applications (CMSA) at Harvard University for running the 2024 Mathematics and Machine Learning program, the organizers of the Machine Learning and Mathematics workshop at the Korea Institute for Advanced Study (KIAS), and the organizers of the 2025 MATRIXMFO Tandem Workshop Machine Learning and AI for Mathematics. Our work benefited greatly from the inspiration and discussions at these events. G.B. gratefully acknowledges help and long discussions with FranÃ§ois Charton, Jordan Ellenberg, Geordie Williamson, Adam Zsolt Wagner, Mike Douglas and Amaury Hayat. G.B. and J.K. were supported by the Independent Research Fund Denmark. B.H. was supported by the Excellence Cluster ORIGINS, funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germanys Excellence Strategy EXC-2094390783311. B.H. extends his gratitude to Lukas Heinrich. References [1] FranÃ§ois Charton, Jordan Ellenberg, Adam Zsolt Wagner, and Geordie Williamson. Patternboost: Constructions in mathematics with little help from AI. arXiv preprint arXiv:2411.00566, 2024. (document), 1, 2.5 [2] Alexander Novikov, NgÃ¢n Vu, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco JR Ruiz, Abbas Mehrabian, et al. Alphaevolve: coding agent for scientific and algorithmic discovery. arXiv preprint arXiv:2506.13131, 2025. (document), 1, 1, 14 [3] Yang-Hui He. Ai-driven research in pure mathematics and theoretical physics. Nature Reviews Physics, 6(9):546553, 2024. 1 [4] Leonardo De Moura, Soonho Kong, Jeremy Avigad, Floris Van Doorn, and Jakob von Raumer. The lean theorem prover (system description). In International Conference on Automated Deduction, pages 378388. Springer, 2015. 1 [5] Kshitij Bansal, Sarah Loos, Markus Rabe, Christian Szegedy, and Stewart Wilcox. Holist: An environment for machine learning of higher order logic theorem proving. In International Conference on Machine Learning, pages 454463. PMLR, 2019. [6] Ayush Agrawal, Siddhartha Gadgil, Navin Goyal, Ashvni Narayanan, and Anand Tadipatri. Towards mathematics formalisation assistant using large language models (2022). URL https://arxiv. org/abs/2211.07524, 2022. [7] Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward Ayers, Dragomir Radev, and Jeremy Avigad. Proofnet: Autoformalizing and formally proving undergraduate-level mathematics. arXiv preprint arXiv:2302.12433, 2023. [8] Kaiyu Yang, Gabriel Poesia, Jingxuan He, Wenda Li, Kristin E. Lauter, Swarat Chaudhuri, and Dawn Song. Position: Formal mathematical reasoninga new frontier in AI. In Forty-second International Conference on Machine Learning Position Paper Track, 2025. [9] Johannes Schmitt, Gergely BÃ©rczi, Jasper Dekoninck, Jeremy Feusi, Tim Gehrunger, Raphael Improofbench: Appenzeller, Jim Bryan, Niklas Canova, Timo de Wolff, Filippo Gaia, et al. Benchmarking ai on research-level mathematical proof generation. arXiv preprint arXiv:2509.26076, 2025. 1 [10] Alex Davies, Petar VeliÄkoviÄ‡, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad TomaÅ¡ev, Richard Tanburn, Peter Battaglia, Charles Blundell, AndrÃ¡s JuhÃ¡sz, et al. Advancing mathematics by guiding human intuition with ai. Nature, 600(7887):7074, 2021. 1 [11] Bin Dong, Xuhua He, Pengfei Jin, Felix Schremmer, and Qingchao Yu. Machine learning assisted exploration for affine delignelusztig varieties. Peking Mathematical Journal, pages 150, 2024. 28 [12] Baran Hashemi, Roderic Guigo Corominas, and Alessandro Giacchetto. Can transformers do enumerative geometry? In The Thirteenth International Conference on Learning Representations, 2024. [13] Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver, and Alexey Pozdnyakov. Murmurations of elliptic curves. Experimental Mathematics, 34(3):528540, 2025. [14] Johannes Schmitt. Extremal descendant integrals on moduli spaces of curves: An inequality discovered and proved in collaboration with ai. arXiv preprint arXiv:2512.14575, 2025. 1 [15] Adam Zsolt Wagner. Constructions in combinatorics via neural networks. arXiv preprint arXiv:2104.14516, 2021. 1 [16] Gergely BÃ©rczi, Honglu Fan, and Mingcong Zeng. An ml approach to resolution of singularities. In Proceeding of ICML TAG Workshop 2023, 2023. [17] Sergei Gukov, James Halverson, Ciprian Manolescu, and Fabian Ruehle. Searching for ribbons with machine learning. Machine Learning: Science and Technology, 2023. [18] Bogdan Georgiev, Javier GÃ³mez-Serrano, Terence Tao, and Adam Zsolt Wagner. Mathematical exploration and discovery at scale. arXiv preprint arXiv:2511.02864, 2025. 1 [19] Chervov, Soibelman, Lytkin, Kiselev, Fironov, Lukyanenko, Dolgorukova, Ogurtsov, Petrov, Krymskii, et al. Cayleypy rl: Pathfinding and reinforcement learning on cayley graphs. arXiv preprint arXiv:2502.18663, 2025. [20] Alberto Alfarano, FranÃ§ois Charton, and Amaury Hayat. Global lyapunov functions: long-standing open problem in mathematics, with symbolic transformers. Advances in Neural Information Processing Systems, 37:9364393670, 2024. [21] Ali Shehper, Anibal M. Medina-Mardones, Lucas Fagan, BartÅ‚omiej Lewandowski, Angus Gruen, Yang Qiu, Piotr Kucharski, Zhenghan Wang, and Sergei Gukov. WHAT MAKES MATH PROBLEMS HARD FOR REINFORCEMENT LEARNING: CASE STUDY. In The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025. [22] Gergely BÃ©rczi and Adam Zsolt Wagner. note on small percolating sets on hypercubes via generative AI, 2024. arXiv:2411.19734. 1 [23] Satyajith Amaran, Nikolaos Sahinidis, Bikram Sharda, and Scott Bury. Simulation optimization: review of algorithms and applications. Annals of Operations Research, 240:351380, 2016. 1, 2.1 [24] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Åukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. 1, 3.2 [25] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:68406851, 2020. 1 [26] Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In International conference on machine learning, pages 15301538. PMLR, 2015. 1 [27] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 63(11):139144, 2020. 1 [28] Diederik Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013. 1 [29] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative modeling. arXiv preprint arXiv:2210.02747, 2022. 1, 2.2 [30] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas MÃ¼ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for high-resolution image synthesis. In Forty-first international conference on machine learning, 2024. 1 [31] Joseph Watson, David Juergens, Nathaniel Bennett, Brian Trippe, Jason Yim, Helen Eisenach, Woody Ahern, Andrew Borst, Robert Ragotte, Lukas Milles, et al. De novo design of protein structure and function with rfdiffusion. Nature, 620(7976):10891100, 2023. 1, 1 [32] Baran Hashemi and Claudius Krause. Deep generative models for detector signature simulation: taxonomic review. Reviews in Physics, 12:100092, 2024. 1 [33] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan Ellenberg, Pengming Wang, Omar Fawzi, et al. Mathematical discoveries from program search with large language models. Nature, 625(7995):468475, 2024. 1 [34] Asankhaya Sharma. Openevolve: an open-source evolutionary coding agent, 2025. 1 [35] Robert Tjarko Lange, Yuki Imajuku, and Edoardo Cetin. Shinkaevolve: Towards open-ended and sample-efficient program evolution. arXiv preprint arXiv:2509.19349, 2025. 1 [36] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Å½Ã­dek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. nature, 596(7873):583589, 2021. 1 [37] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et al. Evolutionary-scale prediction of atomic-level protein structure with language model. Science, 379(6637):11231130, 2023. 1 [38] Abhijit Gosavi and Abhijit Gosavi. Simulation-based optimization, volume 62. Springer, 2015. 2.1 [39] Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio. Flow network based generative models for non-iterative diverse candidate generation. Advances in neural information processing systems, 34:2738127394, 2021. 2.1, 2. [40] Moksh Jain, Emmanuel Bengio, Alex Hernandez-Garcia, Jarrid Rector-Brooks, Bonaventure FP Dossou, Chanakya Ajit Ekbote, Jie Fu, Tianyu Zhang, Michael Kilgour, Dinghuai Zhang, et al. Biological sequence design with gflownets. In International Conference on Machine Learning, pages 97869801. PMLR, 2022. 2.1 [41] Kyle Cranmer, Johann Brehmer, and Gilles Louppe. The frontier of simulation-based inference. Proceedings of the National Academy of Sciences, 117(48):3005530062, 2020. 2.1 [42] Michael Deistler, Jan Boelts, Peter Steinbach, Guy Moss, Thomas Moreau, Manuel Gloeckler, Pedro LC Rodrigues, Julia Linhart, Janne Lappalainen, Benjamin Kurt Miller, et al. Simulationbased inference: practical guide. arXiv preprint arXiv:2508.12939, 2025. 2.1 [43] Frank NoÃ©, Simon Olsson, Jonas KÃ¶hler, and Hao Wu. Boltzmann generators: Sampling equilibrium states of many-body systems with deep learning. Science, 365(6457):eaaw1147, 2019. 2.1 [44] Peter Battaglia, Jessica Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018. 2. [45] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why pinns fail to train: neural tangent kernel perspective. Journal of Computational Physics, 449:110768, 2022. 2.3 [46] Ricky TQ Chen and Yaron Lipman. Flow matching on general geometries. arXiv preprint arXiv:2302.03660, 2023. 2.3 [47] Wenyin Zhou, Christopher Iliffe Sprague, Vsevolod Viliuga, Matteo Tadiello, Arne Elofsson, and Hossein Azizpour. Energy-based flow matching for generating 3d molecular structure. arXiv preprint arXiv:2508.18949, 2025. 2.3 [48] Utkarsh Utkarsh, Pengfei Cai, Alan Edelman, Rafael Gomez-Bombarelli, and Christopher Vincent Rackauckas. Physics-constrained flow matching: Sampling generative models with hard constraints. arXiv preprint arXiv:2506.04171, 2025. 2. [49] Chaoran Cheng, Boran Han, Danielle Maddix, Abdul Fatir Ansari, Andrew Stuart, Michael Mahoney, and Yuyang Wang. Gradient-free generation for hard-constrained systems. arXiv preprint arXiv:2412.01786, 2024. 2.3 [50] Juno Nam, Sulin Liu, Gavin Winter, KyuJung Jun, Soojung Yang, and Rafael GÃ³mez-Bombarelli. Flow matching for accelerated simulation of atomic transport in materials. arXiv preprint arXiv:2410.01464, 2024. 2.3 [51] Randall Balestriero, Mark Ibrahim, Vlad Sobal, Ari Morcos, Shashank Shekhar, Tom Goldstein, Florian Bordes, Adrien Bardes, Gregoire Mialon, Yuandong Tian, et al. cookbook of selfsupervised learning. arXiv preprint arXiv:2304.12210, 2023. 2.4 [52] Mathilde Caron, Hugo Touvron, Ishan Misra, HervÃ© JÃ©gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF international conference on computer vision, pages 96509660, 2021. 2.4, 2.4, 4.1 [53] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. Advances in neural information 30 processing systems, 30, 2017. 2. [54] Li Jing, Pascal Vincent, Yann LeCun, and Yuandong Tian. Understanding dimensional collapse in contrastive self-supervised learning. arXiv preprint arXiv:2110.09348, 2021. 2.4 [55] Xue Bin Peng, Aviral Kumar, Grace Zhang, and Sergey Levine. Advantage-weighted regression: Simple and scalable off-policy reinforcement learning. arXiv preprint arXiv:1910.00177, 2019. 2.4 [56] Ashvin Nair, Abhishek Gupta, Murtaza Dalal, and Sergey Levine. Awac: Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359, 2020. 2.4 [57] Jean-Bastien Grill, Florian Strub, Florent AltchÃ©, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information processing systems, 33:2127121284, 2020. 2.4, 4.1 [58] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017. 2.4 [59] John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy optimization. In International conference on machine learning, pages 18891897. PMLR, 2015. 2.4 [60] Paul Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep reinforcement learning from human preferences. Advances in neural information processing systems, 30, 2017. 2.4 [61] Michael Plainer, Hannes StÃ¤rk, Charlotte Bunne, and Stephan GÃ¼nnemann. Transition path sampling with boltzmann generator-based mcmc moves. arXiv preprint arXiv:2312.05340, 2023. 2.4 [62] Maryna Viazovska. The sphere packing problem in dimension 8. Annals of mathematics, pages 9911015, 2017. 3.1 [63] Henry Cohn, Abhinav Kumar, Stephen Miller, Danylo Radchenko, and Maryna Viazovska. The sphere packing problem in dimension 24. Annals of mathematics, 185(3):10171033, 2017. 3.1 [64] John Horton Conway and Neil JA Sloane. The coxetertodd lattice, the mitchell group, and related sphere packings. In Mathematical Proceedings of the Cambridge Philosophical Society, volume 93, pages 421440. Cambridge University Press, 1983. 3.1 [65] Erich Friedman. The Heilbronn problem for squares. https://erich-friedman.github.io/ packing/heilbronn/. Online benchmark collection. 3.1, 10 [66] FranÃ§ois ClÃ©ment, Carola Doerr, Kathrin Klamroth, and LuÃ­s Paquete. Constructing optimal star discrepancy sets. Proceedings of the American Mathematical Society, Series B, 12:7890, 2025. 3.1, 17 [67] ALGO Lab. Star discrepancy benchmark. https://algo.dei.uc.pt/star/. 17 [68] FranÃ§ois ClÃ©ment, Carola Doerr, and LuÃ­s Paquete. Star discrepancy subset selection: Problem formulation and efficient approaches for low dimensions. Journal of Complexity, 70:101645, 2022. 3. [69] Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee Whye Teh. Set transformer: framework for attention-based permutation-invariant neural networks. In International conference on machine learning, pages 37443753. PMLR, 2019. 3.2 [70] Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. Advances in neural information processing systems, 20, 2007. 3.2 [71] Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning with general conditioning layer. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018. 3.2 [72] Noam Shazeer. Glu variants improve transformer. arXiv preprint arXiv:2002.05202, 2020. 3.2 [73] Biao Zhang and Rico Sennrich. Root mean square layer normalization. Advances in neural information processing systems, 32, 2019. 3. [74] Packomania. Packomania: Database of circle packings. https://www.packomania.com. 3.2.1 31 Aarhus University, Denmark Email address: gergely.berczi@math.au.dk Max Planck Institute for Mathematics in the Sciences, Leipzig, Germany Email address: baran.hashemi@mis.mpg.de Aarhus University, Denmark Email address: jonas.kluever@gmail.com"
        }
    ],
    "affiliations": []
}