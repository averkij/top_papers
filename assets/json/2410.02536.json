{
    "paper_title": "Intelligence at the Edge of Chaos",
    "authors": [
        "Shiyang Zhang",
        "Aakash Patel",
        "Syed A Rizvi",
        "Nianchen Liu",
        "Sizhuang He",
        "Amin Karbasi",
        "Emanuele Zappala",
        "David van Dijk"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We explore the emergence of intelligent behavior in artificial systems by investigating how the complexity of rule-based systems influences the capabilities of models trained to predict these rules. Our study focuses on elementary cellular automata (ECA), simple yet powerful one-dimensional systems that generate behaviors ranging from trivial to highly complex. By training distinct Large Language Models (LLMs) on different ECAs, we evaluated the relationship between the complexity of the rules' behavior and the intelligence exhibited by the LLMs, as reflected in their performance on downstream tasks. Our findings reveal that rules with higher complexity lead to models exhibiting greater intelligence, as demonstrated by their performance on reasoning and chess move prediction tasks. Both uniform and periodic systems, and often also highly chaotic systems, resulted in poorer downstream performance, highlighting a sweet spot of complexity conducive to intelligence. We conjecture that intelligence arises from the ability to predict complexity and that creating intelligence may require only exposure to complexity."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 8 ] . [ 2 6 3 5 2 0 . 0 1 4 2 : r a"
        },
        {
            "title": "Intelligence at the Edge of Chaos",
            "content": "Shiyang Zhang* Yale University, Columbia University sz3209@columbia.edu Aakash Patel* Yale University aakash.patel.ap2853@yale.edu Syed Rizvi Yale University syed.rizvi@yale.edu Nianchen Liu Northwestern University nianchenliu2029@u.northwestern.edu Sizhuang He Yale University sizhuang.he@yale.edu Amin Karbasi Yale University amin.karbasi@yale.edu Emanuele Zappala Idaho State University emanuelezappala@isu.edu David van Dijk Yale University david.vandijk@yale.edu Abstract We explore the emergence of intelligent behavior in artificial systems by investigating how the complexity of rule-based systems influences the capabilities of models trained to predict these rules. Our study focuses on elementary cellular automata (ECA), simple yet powerful one-dimensional systems that generate behaviors ranging from trivial to highly complex. By training distinct Large Language Models (LLMs) on different ECAs, we evaluated the relationship between the complexity of the rules behavior and the intelligence exhibited by the LLMs, as reflected in their performance on downstream tasks. Our findings reveal that rules with higher complexity lead to models exhibiting greater intelligence, as demonstrated by their performance on reasoning and chess move prediction tasks. Both uniform and periodic systems, and often also highly chaotic systems, resulted in poorer downstream performance, highlighting sweet spot of complexity conducive to intelligence. We conjecture that intelligence arises from the ability to predict complexity and that creating intelligence may require only exposure to complexity."
        },
        {
            "title": "1 Introduction",
            "content": "The emergence and nature of intelligence within computational systems have long been subjects of fascination and rigorous study in the fields of artificial intelligence (AI) and theoretical computation. Traditional AI methodologies predominantly involve training models on high-quality datasets inherently imbued with human intelligencesuch as natural language corpora, expert-annotated datasets, or data reflecting human cognitive processes (Coleman et al., 2019). This approach operates under the assumption that creating intelligent behavior necessitates exposure to intelligent data sources. In contrast, this paper explores an alternative hypothesis: that intelligence can emerge from modeling simple systems as long as they exhibit complex behaviors, even when the process that generates the data lacks inherent intelligence. To investigate this hypothesis, we utilize Stephen Wolframs elementary cellular automata (ECA) as our experimental framework. ECAs are one-dimensional, binary-state, discrete computational systems defined by 256 possible 8-bit rules. They generate diverse spectrum of behaviors ranging *These authors contributed equally. Corresponding author 1 from simple, repetitive patterns to highly complex and chaotic structures (Wolfram, 1983). Despite their simple rule-based definitions, certain ECAs produce patterns of significant complexity, making them ideal for examining the relationship between intelligence and complexity. Our methodology involves training separate instances of the GPT-2 language model (Radford et al., 2019) on datasets generated by individual ECAs. The models are tasked with predicting future states of the automata. Following this pretraining phase, we evaluate the models intelligence by quantifying performance on downstream logical reasoning and chess move prediction tasks. This paper presents an extensive study exploring the relationship between system complexity and the emergence of intelligence in large language models (LLMs). We discover positive correlation between the complexity of the ECA rules and the downstream performance of models trained on them, highlighting the role of complexity in fostering intelligent behavior. Surprisingly, we find that models can learn complex solutions when trained on simple rules. Our results point to an optimal complexity level, or edge of chaos, conducive to intelligence, where the system is structured yet challenging to predict. These findings enhance our understanding of intelligence in artificial systems and provide framework for future research focused on the importance of complexity in developing these systems."
        },
        {
            "title": "2.1 Elementary Cellular Automata",
            "content": "Cellular automata (CAs) are computational models of complex systems, consisting of grid of cells that evolve over time based on simple rules. They were first introduced by John von Neumann in the 1940s (von Neumann, 1966). CAs have been widely used to simulate various physical, biological, and computational systems due to their simplicity and ability to produce complex behavior. Elementary Cellular Automata (ECAs) (Wolfram & Mallinckrodt, 1994) are type of onedimensional cellular automaton where each cell has binary state, and its next state is determined by simple rule that depends only on the current state of the cell and its two immediate neighbors. There are 256 possible ECA rules, 88 of which are unique after accounting for symmetries (CastilloRamirez & Magana-Chavez, 2023). Notable examples include Rule 110, which has been proven to be Turing complete (Cook, 2009), and Rule 90, which generates the fractal-like Sierpinski triangle. These rules are categorized into four classes based on their behavior when initialized with random conditions: Class I, which evolves to homogeneous state; Class II, which forms simple periodic structures; Class III, which produces chaotic and aperiodic patterns; and Class IV, which exhibits complex structures (Castillo-Ramirez & Magana-Chavez, 2023). ECAs are valuable computational models used to explore complex systems and emergent behaviors arising from simple rules. Their usefulness lies in their simplicity and the variety of patterns they can produce, making them ideal for studying pattern formation in computation (Meunier, 2016), physics (Banerjee & Dalui, 2024), and mathematical biology (Rasolonjanahary & Vasiev, 2020). Additionally, ECAs have been utilized in cryptography as basis of certain security frameworks (Corona-Bermudez et al., 2022) and in computer science education (Staubitz et al., 2016) to illustrate concepts in algorithms and computational theory. Their ability to model intricate systems with minimal computational resources has made ECAs popular tool across scientific disciplines."
        },
        {
            "title": "2.2 Large Language Models",
            "content": "Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text based on vast datasets (Brown et al., 2020). By leveraging deep learning techniques, these models analyze patterns in language to perform tasks such as translation, summarization, and conversational dialogue (Devlin et al., 2018). Notable examples like OpenAIs GPT-4 have demonstrated remarkable capabilities in producing coherent and contextually relevant responses across wide range of topics (Achiam et al., 2023). The development of LLMs represents significant advancement in natural language processing, opening up new possibilities for applications in education, research, and industry (Katz et al., 2023). 2 Incorporating synthetic data into the training of large language models (LLMs) has been shown to significantly boost their performance. Synthetic data generation enables the creation of large, diverse, and high-quality datasets that may not be readily available in the real world (Anaby-Tavor et al., 2019). By augmenting training data with synthetic examples, models can learn from broader range of linguistic patterns and rare occurrences, improving their ability to generalize to unseen scenarios (Edunov, 2018). As result, LLMs trained with synthetic data exhibit enhanced robustness, accuracy, and adaptability across various downstream tasks (Feng et al., 2021)."
        },
        {
            "title": "2.3 Complexity Measures",
            "content": "Various complexity measures have been proposed to assess the behavior of dynamical systems. In this work, we employ the following measures: 1. Lempel-Ziv Complexity assesses the compressibility of sequence by counting the number of unique substrings in the sequence (Lempel & Ziv, 1976). 2. Compression Complexity quantifies how effectively sequence can be compressed using data compression algorithm such as Zlib (Zli). 3. Lyapunov Exponent gauges systems sensitivity to initial conditions. Higher Lyapunov exponents indicate that small variations in initial states result in rapidly diverging outcomes. We adopt the method proposed by Wolf (1986) for computing this metric. 4. Krylov Complexity evaluates how information propagates in systems Hilbert space, measuring how quickly an operator spans larger regions of the state space over time (Parker et al., 2019). 5. Wolfram Classification categorizes ECA rules into four categories based on behavior and complexity (see Section 2.1). While these measures are correlated with one another, each measures different aspects of complexity. For most analyses, we focus on Lempel-Ziv Complexity and the Wolfram Classification. Additional complexity measures are shown for performance on downstream tasks (Section 5.1)."
        },
        {
            "title": "3 Methodology",
            "content": "In this study, we systematically investigate the relationship between system complexity and emergent intelligence. This section outlines our methodology, including the steps for data generation and model pretraining. An overview of the training process and task evaluations is provided in Figure 1."
        },
        {
            "title": "3.1 Data Generation",
            "content": "To train our models, we simulate selection of ECA rules. Each simulation generates sequence of binary vectors, where each vector represents the systems state at specific time step. For each sample, we begin with randomly initialized vector as the automatons initial state. The system is then evolved over 1000 time steps by repeatedly applying the chosen ECA rule. This process produces sequence of binary vectors that capture the evolving dynamics of the ECA over time. To increase the diversity of the training data, we extract random spatiotemporal windows from the full sequences. Specifically, we sample subsequences by selecting random windows of 60 time steps and 100 spatial dimensions from the binary vectors. This method exposes the model to variety of contexts and state configurations, enhancing its ability to learn the dynamics of the ECA rules and generalize to new sequences. Each training sequence represents randomly selected segment in space and time of the automatons evolution. We train models predicting either 1 or 5 steps in the future, to vary the difficulty of the task. 3 Figure 1: Our framework for investigating the link between complexity and intelligence. We pretrain Large Language Models (LLMs) on Elementary Cellular Automata (ECAs) from different complexity classes using next-token prediction, then evaluate them on downstream reasoning and chess move prediction tasks. We use various measures to analyze the complexity of ECA rules, and quantify the relationship between complexity and downstream performance."
        },
        {
            "title": "3.2 Training Procedure for GPT-2 Models",
            "content": "We utilized modified GPT-2 architecture (Radford et al., 2019) adapted for binary input and output data, enabling it to perform next-token prediction on sequences of binary states. Instead of using traditional token embedding layer followed by softmax over vocabulary, we replaced the token embeddings with linear projection layer that directly maps binary vectors into the models embedding space. The GPT-2 model processes these embeddings to capture temporal dependencies and patterns within the sequences. At the output, we apply linear projection layer to map the models hidden states back to the data dimensionality, generating the prediction for the next state of binary variables at each time step. This adaptation allows the GPT-2 model to handle binary data directly and perform next-token prediction without relying on predefined vocabulary. This also makes the model deterministic, in line with the deterministic nature of ECAs."
        },
        {
            "title": "3.3 Pretraining Setup",
            "content": "Each model was pretrained on next-token prediction using data generated from single ECA rule for up to 10,000 epochs. Early stopping based on validation loss was utilized to prevent overfitting and conserve computational resources. The training data were organized into batches of 64 sequences, each comprising 60 time steps and 100 spatial dimensions. We employed the Adam optimizer with an initial learning rate η = 2 106and weight decay of 0.01. learning rate scheduler with linear warm-up over the first 10% of the total steps was implemented to stabilize the initial stages of training and improve convergence rates. After the warm-up phase, we applied cosine annealing to gradually decay the learning rate over the remaining training steps. Gradient accumulation was used to handle larger effective batch sizes within the constraints of GPU memory, allowing us to simulate larger batch sizes by accumulating gradients over multiple mini-batches. To prevent exploding gradients, we applied gradient clipping with maximum norm of 1.0."
        },
        {
            "title": "4 Experiments",
            "content": "To evaluate the emergent intelligence of models trained on cellular automata, we conducted experiments on three downstream tasks: one easy and one hard reasoning task inspired by the Abstraction 4 and Reasoning Corpus (ARC) (Chollet, 2019), and challenging chess move prediction task (Ruoss et al., 2024). These tasks were designed to quantify the models abilities in reasoning, abstraction, and long-term prediction, thereby assessing the level of intelligence encoded during pretraining on ECA rules of varying complexities. We freeze the layers of the pretrained GPT-2 models and train only the input and output projection layers for downstream tasks to ensure that performance differences reflect the inherent capabilities of the models. Our central hypothesis is that models pretrained on complex rules will exhibit superior performance on downstream tasks compared to those pretrained on simple rules. The inclusion of both easy and hard tasks allows us to observe different performance trends and better understand the relationship between pretraining complexity, task difficulty, and emergent intelligence. The chess move prediction task, in particular, serves as an excellent system to test reasoning due to its inherent complexity and requirement for strategic thinking."
        },
        {
            "title": "4.1 Downstream Task: Reasoning",
            "content": "We developed downstream task inspired by the ARC (Chollet, 2019) to evaluate models problemsolving and reasoning abilities. Our approach utilizes sequence completion problems that require the model to infer transformation rules from provided examples and apply them to novel scenarios. The data consists of fixed number of shapes on grid. At each time step, any of the following transformations can be applied to each shape: changing the color, rotating the shape by 90, or shifting the shapes by one position. We designed two versions of the reasoning task, differing in complexity based on the number and type of transformations applied. In the easy task, we only use 3 Easy only possible transformation is color change, which we perform in predetermined order. 3 squares that are fixed in position and orientation. The Hard The hard task involves more complex patterns where all transformations are applied simultaneously. We used four distinct base shapes, each represented by 5 5 matrix. This results in complex sequences where shapes change color, orientation, and position over time. The combination of these transformations requires the model to reason over multiple simultaneous changes to accurately predict the next pattern in the sequence. Data Preparation and Training on the Downstream Tasks For the easy reasoning task, models 104. For the hard reasoning task, due were trained for 1,000 epochs with learning rate of 1 to its increased complexity and difficulty, we post trained for 10,000 epochs with learning rate of 1 105. Early stopping based on validation loss was again used to prevent overfitting."
        },
        {
            "title": "4.2 Downstream Task: Chess Move Prediction",
            "content": "For the chess experiment, we evaluated the capability of the different ECA-pretrained models to predict next moves in chess games represented using Standard Algebraic Notation (SAN) (Alg). We use chess games from the Lichess Elite database (Lic), focusing on games played between January and April 2016 by Grandmasters with ratings of 2200 and above. Each game was represented as sequence of SAN moves. We split this collection into training, validation, and test sets using an 80-10-10 split to facilitate model training and evaluation. Each game sequence was segmented into subsequences of 60 moves each, and any subsequence shorter than this length was padded sequences to length 60. We added an embedding layer to convert the SAN tokens into vector representations, which were then processed using the frozen ECA-pretrained model. linear output layer was used to transform the outputs to the vocabulary size corresponding to the SAN tokens. These input and output layers were trained while the rest of the model was frozen. The model was trained using cross-entropy loss, the Adam optimizer (Kingma, 2014), and learning rate scheduler with warm-up. Early stopping was also implemented. 5 Figure 2: Relationship between downstream task performance and rule complexity. Left: Eight representative ECA rules, two from each of Wolframs four complexity classes. Performance of models trained on these rules is highlighted in the top row. Top: Model performance in relation to the Lempel-Ziv complexity of each rule. The left and center panels show efficiency (1 divided by number of epochs to reach 80% validation accuracy) for the easy and hard reasoning tasks, respectively. The right panel shows move prediction accuracy for the chess task. The rules depicted on the left are highlighted in the plot with triangles and annotated with the rule number. The correlation coefficient is shown in the top-left corner of each plot. An asterisk next to the value indicates significant relationship (p < 0.05). Bottom: Downstream task performance based on Wolfram classification of each rule. Models trained on chaotic and complex rules perform better than models trained on uniform and simple rules."
        },
        {
            "title": "4.3 Hardware and Software",
            "content": "The experiments were conducted using PyTorch version 2.1.2 and the Transformers library (version 4.41.0), with CUDA version 12.4 for GPU acceleration. The models were trained on 12 NVIDIA H100 GPUs, each with 80 GB of memory, running on Red Hat Enterprise Linux 8.8."
        },
        {
            "title": "5 Results",
            "content": "In this section, we present our results exploring the relationship between system complexity and emergent intelligence in LLMs. The following sections detail our analyses of task performance and attention patterns across models trained on varying rule complexities."
        },
        {
            "title": "5.1 Relationship between Intelligence and Complexity",
            "content": "Figure 2 presents the model performance across three downstream tasks (easy reasoning, hard reasoning, and chess move prediction) as function of the complexity of the ECA rules the models were pretrained on. The top row highlights the relationship between performance and the LempelZiv complexity of the rules, while the bottom row categorizes the performance by Wolframs complexity classes. For clarity, two representative rules from each complexity class are displayed on the left, with their corresponding performance annotated in the top plots. For the reasoning tasks, models generally achieve near-perfect accuracy when trained for sufficient long time. Therefore, instead of reporting absolute accuracy, we focus on model efficiency, defined as the inverse of the number of epochs required to reach 80% accuracy. The chess task is sufficiently difficult that models do not achieve perfect performance, and so we report the final accuracy. As rule complexity increases, we observe clear positive correlation in all tasks, with 6 Figure 3: Relationship between downstream task performance and rule complexity for other complexity measures. Rows depict easy reasoning, hard reasoning, and chess move prediction tasks, while columns show compression complexity, Lyapunov exponent, and Krylov complexity, respectively. We observe the same general patterns that we see with the Lempel-Ziv complexity in Figure 2. more complex rules leading to greater efficiency. This correlation is significant for each of the tasks (p < 0.05). In terms of Wolframs classification, rules from Classes and II (uniform and periodic) show lower average efficiency in the reasoning tasks compared to those from Classes III and IV (chaotic and complex). Complex rules especially outperform the other classes on the chess move prediction task. This pattern suggests that models trained on more complex rules tend to perform better on harder downstream tasks. Results with respect to other complexity measures are shown in Figure 3. We observe that models trained on certain Class III (Chaotic) rules, such as Rules 105, 146, and 150, have poorer performance on the hard reasoning and chess move prediction tasks. This behavior is expected due to chaotic systems lacking the structured patterns necessary for effective learning. In other words, they may be too random to predict, leading to weaker downstream performance. These results highlight the existence of sweet spot of complexity conducive to intelligence, where the system is still predictable yet hard to predict."
        },
        {
            "title": "5.2 Models Learn Complex Solutions For Simple Rules",
            "content": "The elementary cellular automata (ECA) are inherently memoryless, meaning the state at the next time point is determined only by the current time point, without any consideration of past states. For each model, straightforward solution exists: simply learning the 8-bit ECA rule and applying it to the current state to predict the next state. However, alternative solutions may also be possible, where the model leverages historical states for its predictions. The key question is whether the model is merely learning the trivial solution or if it is integrating information from the state history. 7 Figure 4: Attention scores for the final 10 states prior to the target state, showing that models trained on more complex rules rely more heavily on past states for prediction. Left: Visualization of the last 10 states and the target state for representative rules from each of Wolframs complexity classes. Center: Attention scores for each of the last 10 states, highlighting that models trained on complex and chaotic rules focus more on recent states, while models trained on uniform rules exhibit consistently low attention. Periodic rules demonstrate repeating attention pattern, suggesting that the model is learning to attend to earlier cycles of the same state rather than general state history. Right: Average attention across the final 10 states for all rules, plotted against Lempel-Ziv complexity. strong positive correlation (r=0.66) indicates that models trained on higher complexity rules attend more highly to historical states during prediction. To explore this, we analyze the self-attention scores with respect to the last state in the input sequence, which the model uses to predict the next state (see Section 3.2). Specifically, we examine the attention values corresponding to the final ten states before the target state. Figure 4 illustrates the average attention across all layers and heads for the different ECA rules, as well as the attention at each of the last 10 states for one rule from each complexity class. Our findings reveal that models trained on rules that produce more complex dynamics tend to allocate higher attention to the last ten states, with strong positive correlation (r=0.66) between rule complexity and average attention. This suggests that models trained on complex rules integrate information from past states to make their predictions. In contrast, models trained on simpler rules display lower attention across the last ten states. For example, Rule 168 (uniform) shows consistently low attention, indicating that previous states are not being utilized in the prediction process. Rule 179 (periodic) demonstrates recurring pattern in its attention scores, where the model focuses on every other state. This behavior is expected by the nature of Rule 179, which produces an alternating pattern that repeats every two time steps (Figure 4). Thus, the model appears to be learning only this alternating cycle, rather than general state history. The simpler attention structure suggests that these models learn trivial solution, which is in line with their downstream performance. We emphasize that for both simple and complex rules, trivial solution exists: learning the 8-bit instantaneous rule and applying it to only the current state. Such model would have no attention on previous states, as it only needs the current state to make its prediction. The fact that the complex models are attending to previous states indicate that they are learning more complex solution to this simple problem, and we conjecture that this complexity is what makes the model intelligent and capable of repurposing learned reasoning to downstream tasks. We had initially expected that predicting one step in the future would be too easy, and would result in every model learning the trivial (8-bit rule) solution. As such, we trained models to predict 5 steps ahead. Surprisingly, we found that models predicting only the next step not only learned nontrivial solutions, but even outperformed models predicting five steps ahead (Figure 5). This result suggests that even when predicting the immediate next state, the models are learning nontrivial solutions (provided that the underlying rule is complex), capable of capturing complex patterns beyond the trivial rule-based approach. 8 Figure 5: Performance comparison between models trained on short-term and long-term prediction tasks. Each point represents an ECA rule, with the x-axis showing the performance of models trained on short-term (1-step) prediction and the y-axis showing performance of models trained on long-term (5-step) prediction. The points are colored by the Lempel-Ziv complexity of each rule. The dashed line represents equal performance between the two models. Points below the line indicate better performance for short-term prediction models. In this section, we explored the relationship between system complexity and emergent intelligence. Our results show that downstream model performance improves with pretraining on more complex rules, but can deteriorate with excessive complexity or chaotic behavior, signifying sweet spot of complexity conducive to intelligence. Attention patterns further reveal that models trained on complex rules integrate historical information into their predictions, suggesting that they are learning more sophisticated solutions to relatively simple problems. We hypothesize that this complexity in the learned representations is key factor enabling models to generalize and perform well on downstream tasks."
        },
        {
            "title": "6 Related Work",
            "content": "Elementary Cellular Automata and Complexity Elementary Cellular Automata (ECA) serve as foundational models for exploring complexity arising from simple rules. Early research demonstrated that even minimalistic CA systems, governed by basic and local interaction rules, could generate intricate patterns over time (Wolfram, 1983). Wolframs extensive investigations into onedimensional CA revealed that certain rules produce behaviors ranging from stable and periodic to chaotic and complex (Wolfram, 1984). In his work Cellular Automata and Complexity, Wolfram classified one-dimensional CA into four classes based on their dynamic behaviors, highlighting the rich complexity that simple systems can exhibit (Wolfram & Mallinckrodt, 1994). Computation at the Edge of Chaos The concept of computation at the edge of chaos suggests that systems poised between order and disorder exhibit maximal computational capabilities and complex behavior. Langton (1990) introduced this idea, demonstrating that cellular automata operating at this critical transition can perform complex computations. Packard (1988) explored how systems adapt toward the edge of chaos, suggesting that evolution may favor systems that balance between stability and chaos. Mitchell et al. (1993) investigated evolving cellular automata to perform computations, finding that rules near the edge of chaos are more capable of complex tasks. These studies provide theoretical foundation for our work, as we observe that models trained on rules with higher complexity exhibit greater intelligence in downstream tasks. 9 Emergence of Intelligence Through Complexity Exposure The hypothesis that intelligence can arise from exposure to complexity is supported by studies in artificial life and complexity science. Bedau (2003) discusses how complex behaviors and adaptation emerge from simple rules in artificial life systems. Langton (1990) introduced the concept of computation at the edge of chaos, proposing that systems poised between order and disorder exhibit maximal computational capabilities and complex behavior. Our conjecture that creating intelligence may require only exposure to complexity aligns with these perspectives. Crutchfield & Mitchell (1995) explored how evolutionary processes can lead to emergent computation in cellular automata, demonstrating that complexity in the environment can drive the evolution of computational abilities. Kauffman (1992) discussed self-organization and complexity in biological systems, suggesting that complex interactions can lead to emergent properties like intelligence. Emergent Abilities in Large Language Models Recent advancements in large language models (LLMs) have shown that not only increasing model size but also exposing models to more complex and diverse data can lead to the emergence of new capabilities not present in smaller models or models trained on simpler data. Wei et al. (2022) discuss emergent abilities in LLMs, highlighting that certain reasoning tasks become solvable only when models reach certain scale and are trained on sufficiently complex data. Brown (2020) demonstrate that LLMs like GPT-3 can perform few-shot learning, indicating that exposure to wide range of linguistic contexts and complexities enhances the models adaptability and understanding. Hoffmann et al. (2022) emphasize the importance of data scaling laws, showing that increasing the amount and complexity of training data can lead to better performance than merely increasing model size, suggesting trade-off between model capacity and data complexity. Kaplan et al. (2020) introduce scaling laws for neural language models, illustrating how performance improves predictably with model size, dataset size, and computational resources, but also noting that the nature of the data plays crucial role."
        },
        {
            "title": "7 Discussion",
            "content": "In this work, we utilize LLMs trained on elementary cellular automata (ECA) to study how intelligent behavior may emerge in large language models (LLMs) when trained on increasingly complex systems. Our findings reveal several important trends that contribute to understanding the relationship between complexity and model behavior. Optimal Complexity: The Edge of Chaos We observe that the best model performance occurs in systems operating at high but not excessive complexity, previously referred to as the edge of chaos (Langton, 1990). Models trained on Class IV ECA rules, which exhibit structured yet complex behaviors, perform optimally, suggesting that intelligence may emerge in systems that balance predictability and complexity. On the one hand, if system is too simple and predictable, like those governed by Class and II rules, the model quickly learns trivial solution and fails to develop more sophisticated reasoning. On the other hand, highly chaotic rules from Class III provide too much randomness, akin to training on noise, where the lack of meaningful patterns prevents the model from finding useful structure. The sweet spot arises when complexity is high enough to challenge the model but still retains underlying patterns that the model can exploit. This balance between order and randomness seems particularly conducive to fostering intelligent behavior, as it forces the model to develop more effective reasoning and processing strategies. Complex Solutions for Irreducible Systems Our findings demonstrate that large models are capable of learning complex, non-trivial solutions even when simpler, more trivial ones are available, likely because they are overparametrized. For lower-complexity ECA rules, the models often adopt trivial solution, focusing only on the current state since no history is needed. However, when exposed to more complex rules, models tend to leverage prior states, as indicated by the attention patterns in Figure 4. Despite the memoryless nature of ECA systems, overparameterized models 10 explore broader search space, and solutions that integrate historical information may be more robust. We hypothesize that by learning to incorporate past states, the model develops generalizable logic that can be reused across tasks. In contrast, model relying solely on trivial, state-specific rule would struggle to transfer its knowledge to more complex downstream tasks. Thus, the ability to learn from past states may be key to the models success in adapting to diverse problems. Certain ECA rules, such as Rule 110, are known to be computationally irreducible, meaning their behavior cannot be predicted without directly computing each step (Wolfram, 1997). However, some studies suggest that even in these systems, partial predictability can be achieved under certain conditions (Israeli & Goldenfeld, 2004). This implies that models learning more complex, nontrivial solutions can actually outperform simpler, irreducible approaches by leveraging approximate but efficient predictions. Rather than directly calculating each state, models can explore patterns and generalize from past states, potentially leading to solutions that are not only more robust across tasks but also more efficient than the irreducible solution. Broader Impact Our findings connect to larger body of work on the emergence of intelligence in large language models (LLMs). Understanding how LLMs develop sophisticated reasoning capabilities when trained on relatively simple data could offer new insights into why and how intelligence emerges in these models. This research may help shed light on some of the open questions surrounding LLMs, particularly how their internal representations evolve and how certain training conditions lead to more transferrable reasoning abilities. In future work, this framework can be further explored by training larger LLMs on synthetic data generated by simple rule-based systems. Incorporating measures of complexity, such as those used in this study, could provide valuable tool for prioritizing and curating data, ensuring that models are exposed to information with the right balance of structure and randomness. This aligns with recent advances in data curation, where data quality and complexity, rather than quantity, is increasingly emphasized in improving model performance (Zhao et al., 2023; Cao et al., 2023; Liu et al., 2023). Additionally, this work may have implications for our understanding of human intelligence, which is proposed to have evolved as mechanism for interacting with complex and hard-topredict world (Euler, 2018). The idea that intelligence arises in systems operating at the edge of chaos parallels cognitive science theories suggesting that human brains function at critical state between different dynamics (Cocchi et al., 2017; Hesse & Gross, 2014; OByrne & Jerbi, 2022). By exploring the conditions under which LLMs develop intelligence, we may gain new insights into the fundamental processes that underlie both artificial and human cognition."
        },
        {
            "title": "References",
            "content": "Algebraic chess notation - chessprogramming wiki. https://www.chessprogramming. org/Algebraic_Chess_Notation. Accessed: 2024-09-30. Lichess elite database. https://database.nikonoel.fr/. Accessed: 2024-09-30. Zlib: massively spiffy yet delicately unobtrusive compression library. https://www.zlib. net/. Accessed: 2024-09-30. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor, George Kour, Segev Shlomov, Naama Tepper, and Naama Zwerdling. Not enough data? deep learning to the rescue!, 2019. URL https://arxiv.org/abs/1911.03118. Som Banerjee and Mamata Dalui. Identification of ECA rules forming MACA in periodic boundary condition. International Journal of Modern Physics C, pp. 2450173, July 2024. ISSN 0129-1831, 11 1793-6586. doi: 10.1142/S0129183124501730. URL https://www.worldscientific. com/doi/10.1142/S0129183124501730. Mark Bedau. Artificial life: organization, adaptation and complexity from the bottom up. Trends in cognitive sciences, 7(11):505512, 2003. Tom Brown. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. CoRR, abs/2005.14165, 2020. URL https://arxiv.org/abs/2005.14165. Yihan Cao, Yanbin Kang, and Lichao Sun. Instruction mining: High-quality instruction data selection for large language models. arXiv preprint arXiv:2307.06290, 2023. Alonso Castillo-Ramirez and Maria G. Magana-Chavez. study on the composition of elementary cellular automata, 2023. URL https://arxiv.org/abs/2305.02947. Francois Chollet. On the measure of intelligence, 2019. URL https://arxiv.org/abs/ 1911.01547. Luca Cocchi, Leonardo Gollo, Andrew Zalesky, and Michael Breakspear. Criticality in the brain: synthesis of neurobiology, models and cognition. Progress in neurobiology, 158:132152, 2017. Cody Coleman, Christopher Yeh, Stephen Mussmann, Baharan Mirzasoleiman, Peter Bailis, Percy Liang, Jure Leskovec, and Matei Zaharia. Selection via proxy: Efficient data selection for deep learning. arXiv preprint arXiv:1906.11829, 2019. Matthew Cook. concrete view of rule 110 computation. arXiv preprint arXiv:0906.3248, 2009. Erendira Corona-Bermudez, Juan Carlos Chimal-Eguıa, and German Tellez-Castillo. Cryptographic Services Based on Elementary and Chaotic Cellular Automata. Electronics, 11(4):613, February 2022. ISSN 2079-9292. doi: 10.3390/electronics11040613. URL https://www.mdpi.com/ 2079-9292/11/4/613. James Crutchfield and Melanie Mitchell. The evolution of emergent computation. Proceedings of the National Academy of Sciences, 92(23):1074210746, 1995. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. CoRR, abs/1810.04805, 2018. URL http://arxiv.org/abs/1810.04805. Sergey Edunov. Understanding back-translation at scale. arXiv preprint arXiv:1808.09381, 2018. Matthew Euler. Intelligence and uncertainty: Implications of hierarchical predictive processing for the neuroscience of cognitive ability. Neuroscience & Biobehavioral Reviews, 94:93112, 2018. Steven Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, and Eduard Hovy. survey of data augmentation approaches for nlp. arXiv preprint arXiv:2105.03075, 2021. Janina Hesse and Thilo Gross. Self-organized criticality as fundamental property of neural systems. Frontiers in systems neuroscience, 8:166, 2014. 12 Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022. Navot Israeli and Nigel Goldenfeld. Computational irreducibility and the predictability of complex physical systems. Physical review letters, 92(7):074105, 2004. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020. Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. GPT-4 Passes the Bar Exam, March 2023. URL https://papers.ssrn.com/abstract=4389233. Stuart Kauffman. Origins of order in evolution: self-organization and selection. In Understanding origins: Contemporary views on the origin of life, mind and society, pp. 153181. Springer, 1992. Diederik Kingma. Adam: method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton. Similarity of neural network representations revisited. In International conference on machine learning, pp. 3519 3529. PMLR, 2019. Chris G. Langton. Computation at the edge of chaos: Phase transitions and emergent computation. Physica D: Nonlinear Phenomena, 42(1):1237, 1990. ISSN 0167-2789. doi: https://doi.org/ 10.1016/0167-2789(90)90064-V. URL https://www.sciencedirect.com/science/ article/pii/016727899090064V. A. Lempel and J. Ziv. On the complexity of finite sequences. IEEE Transactions on Information Theory, 22(1):7581, 1976. doi: 10.1109/TIT.1976.1055501. Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, and Junxian He. What makes good data for alignment? comprehensive study of automatic data selection in instruction tuning. arXiv preprint arXiv:2312.15685, 2023. PierreEtienne Meunier. Unraveling simplicity in elementary cellular automata. Theoretical Computer Science, 641:210, August 2016. ISSN 03043975. doi: 10.1016/j.tcs.2016.01.004. URL https://linkinghub.elsevier.com/retrieve/pii/S0304397516000050. Melanie Mitchell, Peter Hraber, and James Crutchfield. Revisiting the edge of chaos: Evolving cellular automata to perform computations. arXiv preprint adap-org/9303003, 1993. Jordan OByrne and Karim Jerbi. How critical is brain criticality? Trends in Neurosciences, 45(11): 820837, 2022. N.H. Packard. Adaptation Toward the Edge of Chaos. University of Illinois at UrbanaChampaign, Center for Complex Systems Research, 1988. URL https://books.google. com/books?id=8prgtgAACAAJ. Daniel Parker, Xiangyu Cao, Alexander Avdoshkin, Thomas Scaffidi, and Ehud Altman. universal operator growth hypothesis. Physical Review X, 9(4):041017, 2019. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019. MananIarivo Rasolonjanahary and Bakhtier Vasiev. Formation of Morphogenetic Patterns in CelIn Valeria V. Krzhizhanovskaya, Gabor Zavodszky, Michael H. Lees, Jack J. lular Automata. Dongarra, Peter M. A. Sloot, Sergio Brissos, and Joao Teixeira (eds.), Computational Science ICCS 2020, volume 12142, pp. 359373. Springer International Publishing, Cham, 13 ISBN 9783030504328 9783030504335. doi: 10.1007/978-3-030-50433-5 28. URL 2020. https://link.springer.com/10.1007/978-3-030-50433-5_28. Anian Ruoss, Gregoire Deletang, Sourabh Medapati, Jordi Grau-Moya, Li Kevin Wenliang, Elliot Catt, John Reid, and Tim Genewein. Grandmaster-level chess without search. arXiv preprint arXiv:2402.04494, 2024. Thomas Staubitz, Ralf Teusner, Christoph Meinel, and Nishanth Prakash. Cellular automata as basis for programming exercises in mooc on test driven development. In 2016 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE), pp. 374380, 2016. doi: 10.1109/TALE.2016.7851824. J. von Neumann. Theory of Self-Reproducing Automata. University of Illionois Press, Champain, IL, 1966. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022. In Arun V. Holden (ed.), Chaos, A. Wolf. 13. Quantifying chaos with Lyapunov exponents. pp. 273290. Princeton University Press, December 1986. ISBN 9781400858156. doi: 10. 1515/9781400858156.273. URL https://www.degruyter.com/document/doi/10. 1515/9781400858156.273/html. Stephen Wolfram. Statistical mechanics of cellular automata. Rev. Mod. Phys., 55:601644, Jul 1983. doi: 10.1103/RevModPhys.55.601. URL https://link.aps.org/doi/10.1103/ RevModPhys.55.601. Stephen Wolfram. Physica D: Nonlinear Phenomena, 10(1):135, 1984. https://doi.org/10. 1016/0167-2789(84)90245-8. URL https://www.sciencedirect.com/science/ article/pii/0167278984902458. Universality and complexity in cellular automata. doi: ISSN 0167-2789. Stephen Wolfram. New kind of science, 1997. Stephen Wolfram and Alexander Mallinckrodt. Cellular automata and complexity. 1994. URL https://api.semanticscholar.org/CorpusID:62571078. Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu, Fei Huang, Yongbin Li, and Nevin Zhang. preliminary study of the intrinsic relationship between complexity and alignment. arXiv preprint arXiv:2308.05696, 2023. 14 Figure 6: UMAP projection of CKA similarities between models trained on ECA rules. Each point represents model, colored by its corresponding rule complexity (Lempel-Ziv, Compression, Lyapunov, and Krylov complexities). Models trained on rules with similar complexities cluster together, indicating that they learn similar representations. Chaotic rules like Rule 105 and 150 are notably closer to models trained on lower complexity rules, while models trained on complex, non-chaotic rules cluster more distinctly."
        },
        {
            "title": "A Visualizing Learned Representations Using CKA Similarities",
            "content": "To investigate the learned representations of the pre-trained models, we use center kernel alignment (CKA) to compute similarities between each pair of models. CKA is method for comparing representations learned by neural networks, measuring how well the internal weight matrices of two models align (Kornblith et al., 2019). In our analysis, we compute pairwise similarities across all models trained on different ECA rules, with complexity levels ranging from low to high. To visualize these similarities, we project the CKA similarity embeddings into two dimensions using UMAP, popular dimensionality reduction technique. The resulting plots, shown in Figures 6 and 7, reveal that models trained on rules with similar complexity tend to cluster together, indicating that they have learned similar internal representations. Interestingly, models trained on highly chaotic rules, such as Rule 105 and Rule 150, are located closer to models trained on lower-complexity rules, suggesting that despite the high complexity of their training data, their learned representations are more akin to those trained on simpler dynamics. In contrast, models trained on complex but not chaotic rules tend to form distinct clusters, indicating that they develop more unique internal structures compared to models trained on either simple or highly chaotic rules. These results suggest that complexity plays significant role in shaping model representations. Models trained on rules with moderate complexity tend to develop distinct, well-formed internal 15 Figure 7: UMAP projection of CKA similarities between models trained on ECA rules, annotated with the rule number. representations, while chaotic rules may push models toward more generic representations, aligning them with simpler rules. Long vs Short Term Prediction with other complexity measures Figure 8 presents an efficiency comparison between models trained on short-term (1-step) and longterm (5-step) prediction tasks akin to Figure 5, but with the remaining complexity measures. We observe the same trend as with the Lempel-Ziv complexity. Models tend to perform better when trained on shorter prediction horizons, challenging the assumption that longer prediction horizons lead to better understanding of underlying structures. 16 Figure 8: Efficiency comparison between models trained on short-term and long-term prediction tasks, colored by the other complexity measures. We observe the same trend as with Lempel-Ziv complexity in Figure 5."
        }
    ],
    "affiliations": [
        "Columbia University",
        "Idaho State University",
        "Northwestern University",
        "Yale University"
    ]
}