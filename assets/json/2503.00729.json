{
    "paper_title": "CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic Environments",
    "authors": [
        "Mingcong Lei",
        "Ge Wang",
        "Yiming Zhao",
        "Zhixin Mai",
        "Qing Zhao",
        "Yao Guo",
        "Zhen Li",
        "Shuguang Cui",
        "Yatong Han",
        "Jinke Ren"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) exhibit remarkable capabilities in the hierarchical decomposition of complex tasks through semantic reasoning. However, their application in embodied systems faces challenges in ensuring reliable execution of subtask sequences and achieving one-shot success in long-term task completion. To address these limitations in dynamic environments, we propose Closed-Loop Embodied Agent (CLEA) -- a novel architecture incorporating four specialized open-source LLMs with functional decoupling for closed-loop task management. The framework features two core innovations: (1) Interactive task planner that dynamically generates executable subtasks based on the environmental memory, and (2) Multimodal execution critic employing an evaluation framework to conduct a probabilistic assessment of action feasibility, triggering hierarchical re-planning mechanisms when environmental perturbations exceed preset thresholds. To validate CLEA's effectiveness, we conduct experiments in a real environment with manipulable objects, using two heterogeneous robots for object search, manipulation, and search-manipulation integration tasks. Across 12 task trials, CLEA outperforms the baseline model, achieving a 67.3% improvement in success rate and a 52.8% increase in task completion rate. These results demonstrate that CLEA significantly enhances the robustness of task planning and execution in dynamic environments."
        },
        {
            "title": "Start",
            "content": "CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic Environments Mingcong Lei, Ge Wang, Yiming Zhao, Zhixin Mai, Qing Zhao, Yao Guo, Zhen Li, Shuguang Cui, Yatong Han, and Jinke Ren 5 2 0 2 2 ] . [ 1 9 2 7 0 0 . 3 0 5 2 : r Fig. 1: Task execution processes of CLEA. (1) Search task: CLEA facilitates adaptive strategy adjustments in partially observable environments. By analyzing visual inputs from robot 2, which remains stationary on the table, CLEA directs robot 1, the mobile unit, to explore alternative locationssuch as the interior of the refrigeratorin search of water. (2) Manipulation task: CLEA evaluates the feasibility of each action and dynamically refines its strategy. Upon opening the oven, it determines that placing the apple directly inside is infeasible. Consequently, CLEA adjusts the next step to more appropriate action: pulling out the grill to create sufficient space, thereby successfully completing the manipulation task. Abstract Large Language Models (LLMs) exhibit remarkable capabilities in the hierarchical decomposition of complex tasks through semantic reasoning. However, their application in embodied systems faces challenges in ensuring reliable execution of subtask sequences and achieving one-shot success in long-term task completion. To address these limitations in dynamic environments, we propose Closed-Loop Embodied Agent (CLEA)a novel architecture incorporating four specialized open-source LLMs with functional decoupling for closed-loop task management. The framework features two core innovations: (1) Interactive task planner that dynamically generates executable subtasks based on the environmental memory, and (2) Multimodal execution critic employing an evaluation framework to conduct probabilistic assessment of action feasibility, triggering hierarchical re-planning mechanisms when environ- * These authors contributed equally to this work. Corresponding authors: Jinke Ren (jinkeren@cuhk.edu.cn); Yatong Han (hanyatong@cuhk.edu.cn) M. Lei, G. Wang, Y. Zhao, Z. Mai, Q. Zhao, Y. Han are with the Shenzhen Future Network of Intelligence Institute (FNii-Shenzhen) and Guangdong Provincial Key Laboratory of Future Networks of Intelligence, The Chinese University of Hong Kong, Shenzhen 518172, China, and also with Infused Synapse AI, Shenzhen 518048, China. Y. Zhao is also with Harbin Engineering University, Harbin 15006, China. Yao Guo is with the Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China. Z. Li, S. Cui and J. Ren are with the School of Science and Engineering (SSE), FNii-Shenzhen, and Guangdong Provincial Key Laboratory of Future Networks of Intelligence, The Chinese University of Hong Kong, Shenzhen 518172, China. mental perturbations exceed preset thresholds. To validate CLEAs effectiveness, we conduct experiments in real environment with manipulable objects, using two heterogeneous robots for object search, manipulation, and search-manipulation integration tasks. Across 12 task trials, CLEA outperforms the baseline model, achieving 67.3% improvement in success rate and 52.8% increase in task completion rate. These results demonstrate that CLEA significantly enhances the robustness of task planning and execution in dynamic environments. Our code is available at https://sp4595.github.io/CLEA/. I. INTRODUCTION In recent years, Large Language Models (LLMs) have language understanding advanced significantly in natural and hierarchical task decomposition, demonstrating strong capabilities in embodied task planning [1]. They can interpret complex instructions and generate executable action sequences for multi-step tasks such as object rearrangement and interactive cooking [2]. However, LLMs struggle with long-horizon tasks due to context window limitations, preventing continuous task state tracking. Additionally, their static action sequences lack adaptability to dynamic environments where object states and spatial relationships change unpredictably, hindering robustness in real-world applications [3], [4]. To overcome these challenges, recent work integrates LLMs with external planning frameworks. One approach translates LLM-generated plans into structured formats like Planning Domain Definition Language (PDDL) [5] or Behavior Trees (BTs) [6], enhancing precision but relying on static task definitions and manual tuning. Another direction combines LLMs with dynamic planning techniques, such as Monte Carlo Tree Search (MCTS) [7] for commonsensedriven reasoning, though its iterative search constraints limit scalability. Similarly, LLM-Task and Motion Planning (TAMP) [8] improves task feasibility but faces exponential planning complexity in multi-agent systems, complicating coordination in dynamic environments. To address these limitations, we propose Closed-Loop Embodied Agents (CLEA), novel framework designed to enable adaptive decision-making in dynamic, multi-robot environments. Its effectiveness across diverse tasks is demonstrated in Fig. 1. CLEA establishes closed-loop planning paradigm by integrating four decoupled LLM modules, allowing for continuous adaptation based on real-time environmental feedback. The key contributions of this work are as follows. Closed-loop planner-critic reasoning: We propose novel planner-critic architecture that establishes closed-loop perception-reasoning-execution framework. The planner generates temporally coherent action sequences by leveraging historical environmental states and summarized memory, ensuring consistency with the critic conducts real-world dynamics. Meanwhile, online feasibility assessments through event-triggered evaluations, enabling adaptive task execution based on robot capabilities and sub-task constraints. Open-source VLMs and LLMs powered agent framework: To enhance reproducibility and extensibility, we develop the agent system using open-source Visual Language Models (VLMs) and LLMs. The entire framework is successfully deployed on real robotic platforms, demonstrating its practicality in real-world applications. Experiment evaluation in real-world environment: We evaluate CLEA in real-world setting, where two robots execute three types of complex, long-horizon tasks: object search, multi-object manipulation, and integration tasks. Experimental results indicate that CLEA significantly outperforms the open-loop baseline, achieving substantial improvements in task planning accuracy and execution robustness. II. RELATED WORK LLMs for embodied task planning: LLMs can effectively decompose complex embodied tasks after understanding human intent. Existing approaches follow two paradigms: open-loop and closed-loop planning. Open-loop methods (e.g., HuggingGPT [9]) generate complete action sequences in single inference, offering efficiency but lacking adaptability in dynamic environments. Closed-loop systems (e.g., LLM-Planner [10]) iteratively replan based on environmental feedback, improving robustness at the cost of efficiency. However, existing closed-loop systems have stringent requirements for the quality of environmental feedback. As result, most current approaches can only achieve successful execution in simulated environments. To enhance feasibility, prior work integrates multimodal prompts and hierarchical frameworks with PDDL, BTs, MCTS, and TAMP [5][8]. While these methods improve accuracy and standardization, they rely on static task definitions and prior knowledge, limiting real-time adaptability. Environment description with VLMs: Vision is crucial in robotic systems, aiding object recognition and segmentation. VLMs enhance this by describing spatial relationships through language [11]. Leveraging their textual output, researchers explore task planning in simulated environments by decoupling environmental feedback, narrowing the sim-toreal gap [8], [12]. While promising for autonomous planning in complex settings, real-world deployment remains challenging. Multi-agent collaboration: Multi-agent systems tackle complex tasks by distributing responsibilities among agents with similar or distinct capabilities [13], [14]. In largescale navigation, agents may share mobility functions, while inspection tasks require obstacle avoidance and operational checks [15]. In dynamic, partially observable environments like kitchens, key challenge in embodied intelligence is autonomously updating strategies based on heterogeneous agent interactions. III. PROBLEM FORMULATION"
        },
        {
            "title": "Traditional",
            "content": "robotic systems rely on predefined error correction strategies, which become inadequate for highdimensional, embodied tasks in partially observable environments. Anticipating all possible errors in advance is impractical, requiring robots to dynamically adapt during execution. To address this, we model the problem using Partially Observable Markov Decision Process (POMDP) [16]. Robots perceive the environment through onboard cameras, receiving partial sensory inputs as JPEG images. The true state introducing decision-making uncertainty. remains hidden, Robots interact via predefined action APIs, mapping to lowlevel operations. Formally, the POMDP is defined by the tuple (S, A, Ω, T, O), where denotes the state space, is the action space of executable function calls, Ω is the visual observation space, (ss, a) is the state transition dynamics, and O(os, a) is the observation function that generates camera images from environmental states. At each time step i, the agent receives visual observation oi O(si, ai1) and maintains belief state bi (S)a probability distribution over latent states conditioned on the interaction history: bi = P(si = so1:i, a1:i1). (1) Following the principles of predictive processing [16], the belief state serves as the agents internal estimate of the true environmental state, continuously refined through sequential visual observations and action outcomes. The image-based Fig. 2. Overview of CLEA. The observer (VLM) provides environmental data, which the summarizer (LLM) processes into memory. The planner (LLM) generates an initial action sequence based on the robots skill pool and memory, while the critic (VLM) evaluates action feasibility and offers re-plan recommendations in response to environmental dynamics. observation space inherently reflects embodiment constraints, as the robots egocentric perspective limits its perceptual field. This formulation provides principled approach to reasoning under uncertainty while aligning with the perceptual characteristics of real-world robotic systems. Our objective is to generate bi based on the prior trajectory and subsequently formulate sequence of actions within the closed-loop framework. Using bi, the agent iteratively plans further actions to achieve the designated task. Fig. 3. The reasoning and output of CLEA. Unlike traditional failuredetection classification systems, CLEA performs internal reasoning upon receiving visual input and provides structured outputs. In the case where no medication is found in an empty drawer, the planner does not halt its intent. Instead, the critic suggests exploring alternative locations and provides the correct advice to check other compartments of the drawer, thereby guiding the successful completion of the task. The components of the CLEA framework work in unison to form closed-loop planning model. This enables the system to handle dynamic and partially observable realworld environments by leveraging LLMs internal reasoning ability to analyze the robots actions, detect discrepancies, and generate structured outputs. For example, in task such as medication retrieval (as shown in Fig. 3), CLEA helps the robot understand its own behavior, recognize when its current strategy is suboptimal, and correct it in real-time. IV. CLOSED LOOP EMBODIED AGENT B. Observer A. Overview of CLEA As illustrated in Fig. 2, CLEA consists of three key components: an observer, memory module, and plannercritic agent. The observer bridges the image observations from the environment to the language model-based modules, converting visual input into textual descriptions. The memory module provides the agent with belief of the current state, consisting of history buffer to manage past interactions and summarizer that generates beliefs based on this history. The planner-critic agent addresses dynamic planning in realworld embodied tasks. It is divided into two parts: the planner and the critic. The planner first sets sub-goal and plans sequence of actions to achieve it, focusing on shorter action sequences rather than the entire task. During execution, the critic evaluates the ongoing plan at each step based on the belief state and the current observation. If the planned sequence is no longer suitable in the current situation, the planner will re-adjust the sub-goal and re-plan the action sequence accordingly. Open-source VLMs, while effective in image description and summarization [17], have inherent limitations in multimodal planning. As result, CLEA employs an open-source LLM without multimodal capabilities for its planning and memory modules. To compensate for this, dedicated VLM module serves as an observer, converting visual inputs into structured textual representations. The observer reconstructs the environment by selectively identifying task-relevant objects and capturing their spatial relationships, ensuring that the extracted information is both concise and semantically meaningful. We formally denote this text-based observation as ot i. The observer module consists of single VLM agent that processes an input image along with additional taskspecific information and generates structured textual output defined as: Obs : oi ot i. (2) C. Memory We introduce memory module to enable the agent to maintain structured belief about the environment throughout its interactions. This module consists of two key components: history buffer and summarizer. The history buffer operates in conjunction with the observer to systematically record the robots interactions with the environment in textual form. It functions as first-infirst-out (FIFO) queue, where each entry is represented as an observation-action-feedback tuple (ot i, ai, fi). The observation ot is derived from the observer, the action ai corresponds to the command executed by the agent at iteration i, and the feedback fi encapsulates the systems response, including internal errors and task completion status. This buffer serves as repository for raw memory data, facilitating subsequent summarization. Formally, the history buffer is defined as: = {hi}n i=1, (3) where each element hi = (ot i, ai, fi) records the interaction history between the robot and its environment at each iteration. The summarizer constructs belief representation of the current environment based on the stored history H. Leveraging the summarization capabilities of LLMs, the summarizer distills essential information from past interactions to infer the environment state si and the robots task progress. This information is consolidated into structured textual representation, which is subsequently provided to the planning module. The summarization process transforms raw interaction histories into belief states, formally expressed as: Sum : h[1:i1] bi, (4) where bi represents the belief state, capturing compressed yet semantically rich historical information for CLEA. By maintaining concise but informative belief representation, the summarizer facilitates efficient reasoning while preserving crucial temporal dependencies, thereby ensuring both memory efficiency and robust decision-making. D. Planner-Critic Agent The planner-critic agent module is responsible for closedloop decision-making and consists of two key components: the planner and the critic. The planner module employs hierarchical planning mechanism, leveraging the belief state and available environmental information to generate new sub-goal along with the corresponding action sequence. The planner is implemented as single LLM agent utilizing Chain-of-Thought (CoT) prompting [18] to infer sub-goals and associated action sequences. By providing structured prompts, the LLM receives relevant contextual information and subsequently outputs the current sub-goal along with sequence of executable actions. These actions are selected from predefined skill pool, as illustrated in Fig. 2, enabling the CLEA agent to interact with the robotic platform in real-world scenarios. Formally, at time step i, the planner generates sub-goal gi and an action sequence { ˆai:k}m k=1 based on the belief state bi, which can be expressed as: P(bi, oi) (gi, { ˆai:k}m k=i). (5) Each action ai within the sequence corresponds to predefined function call from the skill pool, which consists of modular Python functions. For each action, the planner invokes the appropriate skill function with relevant parameters, ensuring structured execution. The critic module incorporates VLM agent with CoT prompting to assess the feasibility of the proposed actions in real time. The critic determines whether the planned action at each iteration is appropriate given the current state of the environment. Through empirical analysis, we observe that providing the critic with the original image, rather than textbased observation, is crucial for accurate evaluation. Since the critic must infer spatial relationships, object states, and potential occlusions from fine-grained visual details, relying solely on abstract textual descriptions proves insufficient. Prior to the execution of each action, the critic evaluates its validity by considering the belief state and the current visual observation. If the action is deemed feasible, the agent proceeds with execution. Conversely, if the action is found to be unsuitable, the critic generates corrective feedback, prompting the planner to refine the sub-goal and recompute the action sequence. This iterative validation process is formally defined as follows: C( ˆai, bi, oi) (pi, fi), (6) where pi is binary validity flag (pi {true, false}), and fi represents the feedback signal. If pi = false, the planner utilizes fi along with the updated belief state bi to regenerate an improved action sequence { ˆa j:k}, thereby forming an adaptive refinement loop that dynamically adjusts the plan in response to environmental variations. By integrating memory-driven reasoning with real-time environmental feedback, the planner-critic framework facilitates adaptive task execution, enhancing the robustness and flexibility of the planning process. The synergy between belief states, visual observations, and iterative planning ensures that the agent can effectively navigate dynamic environments while adhering to the constraints of real-world robotic systems. V. EXPERIMENTS A. Experimental Settings Environment description. In this study, we deploy two robots in real-world environment. We require CLEA to simultaneously control both robots, receiving feedback and image observations from each robots actions. The two robots consist of dual-arm robot and single-arm robot. The dualarm robot is capable of both movement and manipulation, while the single-arm robot remains stationary but covers areas that are difficult for the dual-arm robot to reach. By testing CLEAs ability to leverage the distinct characteristics of both robots and dynamically plan actions, we demonstrate CLEAs capacity for long-term closed-loop planning in dynamic and partially observable environment. Our test environment is small, open kitchen setup. This environment contains 10 manipulable objects, 4 closed containers (e.g., refrigerator, two drawers and an oven), two open spaces such as object misplacement or environmental changes. The inability to perform real-time plan refinement underscores the critical role of the critic module in ensuring adaptive task execution. These evaluations provide empirical validation of both CLEAs superiority over existing methods and the necessity of its core components. TABLE PREDEFINED SKILL POOL IN THE ENVIRONMENT Skill pool open(robot, openable object) close(robot, openable object) pick from(robot, object, space) release to(robot, space) go to(robot, navi point) Description robot open object robot close object robot pick object from space robot release the object on its hand to space robot navigate to navigation point Implementation details. Our framework leverages opensource LLM and VLM models to power its core modules. the Qwen2.5-72B-Instruct model [8] is emSpecifically, ployed for LLM-based components, including the summarizer and planner, while the Qwen2.5-72B-VL-Instruct model [19] is used for VLM-driven modules, such as the observer and critic. The action space is defined by predefined skill pool, as detailed in Table I. The experimental hardware setup consists of Kinova Gen3 7-DoF fixed-base manipulator, an RM65-B dual-arm mobile manipulator, and multiple depth cameras. For motion planning, we employ the RRT-Connect algorithm, implemented within the MoveIt framework [20], across all robotic platforms. The robots perception system integrates the YOLOv11 segmentation model [21] alongside particle filter-based localization and mapping techniques, ensuring robust scene understanding and navigation. B. Comparison Results Fig. 5. agent. Comparisons among the CLEA, the ablation, and the baseline Fig. 4. Visualization of the experimental environment. (a table and sink), and 3 interactive devices (an oven, refrigerator and garbage can). The overall environment is shown in Fig. 4. Task definition. To thoroughly evaluate CLEAs long-term planning ability, we define three types of tasks: (1) Search task: CLEA coordinates the two robots in collaborative search for two distinct objects. Direct visualization of objects is confirmed as find. (2) Manipulation task: Given the locations of two objects (which may be partially occluded), CLEA is required to manipulate both objects. (3) Integration task: This task integrates the search and manipulation tasks. CLEA must find and manipulate one or two distinct objects within the environment. Evaluation metric. We conduct three trials for each task under varying environmental conditions to evaluate the robustness of the planning system. These trials enable comprehensive assessment of CLEAs capability for longterm closed-loop planning within kitchen environment. To quantitatively measure performance, we define two evaluation metrics: (1) Success Rate (SR), which represents the proportion of successfully completed tasks; (2) Average Score (AS), calculated as the mean performance score across all trials, where each correctly executed action contributes one point. Baseline agent. To benchmark performance, we implement an open-loop planning agent that generates action sequences using VLM with additional refinement [8]. The agent follows predefined plan until either the sequence is fully executed or an erroneous action is encountered. In the latter case, the VLM is granted single opportunity to replan its actions. This baseline highlights the limitations of static planning approaches and demonstrates CLEAs ability to enhance robustness through closed-loop adaptation. Ablation studies. To systematically assess the impact of our proposed framework, we conduct an ablation study by evaluating degraded variant, CLEA w/o critic, in which the critic module is removed. While this variant maintains the ability to generate sub-goals, lacks the capability to detect execution errors or adapt to unexpected failures, it TABLE II REASONS AND RATIOS WHEN CRITIC RAISE pi = FALSE"
        },
        {
            "title": "Outdated actions\nRedundant actions\nInvalid actions\nWrong planning",
            "content": "8 6 2 2 44.4% 33.3% 11.1% 11.1% We conduct total of 12 real-world experiments. Based on the data from (a) SR and (b) AS. Our experimental results are shown in Fig. 5. The proposed CLEA framework demonstrated significant improvements over baseline methods. On average, CLEA outperformed the baseline by an increase of 67.3% in SR and 53.8% in AC. Additionally, CLEA was also more effective than CLEA w/o critic, showing marked improvement of 42.0% in SR and 26.3% in AC. These results underscore the effectiveness of the CLEA framework. Comparing CLEA with the baseline, we observe that while the baseline agent can accomplish basic searching and manipulation tasks, it consistently fails in the integration 1 & 2 tasks. In contrast, CLEA successfully completes the majority of tasks, demonstrating the effectiveness of closedloop planning in dynamic real-world environments. In the search task, the baseline agent often fails to locations where target comprehensively explore potential objects may be located. This limitation likely arises from the absence of memory mechanism, which prevents the agent from reconstructing past experiences. Memory is particularly crucial for search tasks where target object locations remain uncertain. In the manipulation task, we find that the openloop long-term planning capabilities of the baseline LLM are insufficient, occasionally leading to logical inconsistencies in the planned action sequence. In the integration task, which requires both searching and manipulation, the baselines inability to effectively perform both subtasks results in complete task failure. For CLEA without the absence of dynamic action evaluation leads to the execution of redundant operations, some of which directly result in task failure. In long-horizon searching and manipulation tasks, the lack of real-time correction from the critic causes CLEA to frequently encounter issues such as attempting to grasp non-existent objects or interacting with unopened containers (e.g., trying to retrieve an item from closed refrigerator). These errors significantly reduce both the success rate and the overall task performance score, highlighting the necessity of the critic module in refining action sequences and ensuring task feasibility. the critic module, As shown in Table II, we examine several common errors detected by the critic module: the environment 1) Outdated actions: The planner may make assumptions about later prove to be incorrect. For instance, the planner might assume that an object is located in specific place, such as inside the refrigerator. that to be false, If this assumption turns out the subsequent plan becomes outdated. This is common issue in dynamic environments, and the critic plays vital role in detecting such outdated actions, which highlights its importance in improving CLEAs performance in ever-changing contexts. 2) Redundant actions: Occasionally, the planner overlooks information provided by the belief state, leading to planning actions that have already been executed or are no longer necessary. The critic can identify these redundant actions, preventing unnecessary task execution and improving overall efficiency. 3) Invalid actions: CLEA may output actions that do not conform to the required API format. Table II reveals that the critic detected two invalid actions. This suggests that the critic is able to detect invalid actions that remain imperfect. 4) Incorrect planning: Due to limitations in the LLM planner, some generated plans may be unfeasible. The critic can detect these planning errors and, in some cases, provide suggestions for creating more practical plans, helping to guide the planning process toward more effective solutions. importance of closed-loop planning with dynamic evaluation in robotic systems operating in complex, real-world environments. The integration of dynamic feedback loop between the planner and the critic proves essential for the robustness and adaptability of CLEA in such settings."
        },
        {
            "title": "These findings emphasize the critical",
            "content": "C. Failure Analysis REASONS AND RATIOS OF FAILURE CAUSED BY CLEA TABLE III"
        },
        {
            "title": "Failure",
            "content": "Invalid actions Critic failures Multi-robot collaboration 9 8 3 45% 26.7% 15% As shown in Table III, we identify and analyze three common failure modes within the CLEA framework. While these anomalies may not directly cause task failure, they can hinder overall task completion. 1) Action API limitations in real robots: The most frequent failure occurs due to invalid actions. These arise when the LLM fails to generate actions in the correct Python function call format. Although invalid actions do not immediately lead to task failure, they reduce the efficiency of CLEAs performance. This issue likely stems from the limitations of the predefined action format, which restricts the planners flexibility and limits its ability to generate optimal action sequences. 2) Critic failures: While the critic is generally effective in detecting execution errors, there are instances where it fails to identify improper actions. For example, the critic may erroneously halt valid plan or fail to recognize an error in the action sequence. This limitation is likely due to the constraints in the VLMs perceptual capabilities, which may [10] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, and Y. Su, Llm-planner: Few-shot grounded planning for embodied agents with large language models, in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 29983009. [11] X. Fu, M. Zhang, H. Jianye, P. Han, H. Zhang, L. Shi, and H. Tang, What can vlms do for zero-shot embodied task planning? in ICML 2024 Workshop on LLMs and Cognition, 2024. [12] Z. Wu, Z. Wang, X. Xu, J. Lu, and H. Yan, Embodied task planning with large language models, arXiv preprint arXiv:2307.01848, 2023. [13] P. Li, Z. An, S. Abrar, and L. Zhou, Large language models for multirobot systems: survey, arXiv preprint arXiv:2502.03814, 2025. [14] I. Singh, D. Traum, and J. Thomason, Twostep: Multi-agent task planning using classical planners and large language models, arXiv preprint arXiv:2403.17246, 2024. [15] S. S. Kannan, V. L. Venkatesh, and B.-C. Min, Smart-llm: Smart multi-agent robot task planning using large language models, in 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2024, pp. 12 14012 147. [16] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra, Planning and acting in partially observable stochastic domains, Artificial intelligence, vol. 101, no. 1-2, pp. 99134, 1998. [17] W.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D. Li, H. Zhang, B. Zhu, M. Jordan, J. E. Gonzalez, et al., Chatbot arena: An open platform for evaluating llms by human preference, arXiv preprint arXiv:2403.04132, 2024. [18] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al., Chain-of-thought prompting elicits reasoning in large language models, Advances in neural information processing systems, vol. 35, pp. 24 82424 837, 2022. [19] S. Bai, K. Chen, X. Liu, J. Wang, W. Ge, S. Song, K. Dang, P. Wang, S. Wang, J. Tang, et al., Qwen2. 5-vl technical report, arXiv preprint arXiv:2502.13923, 2025. [20] D. Coleman, I. Sucan, S. Chitta, and N. Correll, Reducing the barrier to entry of complex robotic software: moveit! case study, arXiv preprint arXiv:1404.3785, 2014. [21] R. Khanam and M. Hussain, Yolov11: An overview of the key architectural enhancements, arXiv preprint arXiv:2410.17725, 2024. not always capture the full range of environmental nuances required for accurate error detection. 3) Multi-robot collaboration issues: Certain tasks necessitate coordination between two robots. In these scenarios, we observe that CLEA occasionally struggles to correctly interpret and manage inter-robot collaboration. For example, CLEA may assign actions intended for one robot to another. This issue may arise because LLMs are not particularly adept at understanding and managing complex inter-robot relationships. VI. CONCLUSION AND FUTURE WORK We introduce CLEA, closed-loop framework designed for strategy adjustment in embodied systems, and evaluate it through search, manipulation, and integration tasks in real-world kitchen environment. In comparison to open-loop frameworks, CLEA demonstrates significant improvements in both task completion and error recovery for long-horizon tasks. Looking ahead, we aim to integrate more advanced reasoning models to enhance the planning capabilities of the system while also experimenting with smaller models to improve the efficiency of LLM/VLM. Furthermore, we intend to incorporate Visual Language Action (VLA) models to bolster the robots operational robustness during task execution. Currently, the limited action space poses challenges; even when errors and their causes are identified, recovering from failures at the action level remains difficult without function calls. To address this, we plan to leverage VLA technology at the lower levels, providing richer and more flexible action space for improved error recovery."
        },
        {
            "title": "REFERENCES",
            "content": "[1] A. Zeng, M. Attarian, B. Ichter, K. Choromanski, A. Wong, S. Welker, F. Tombari, A. Purohit, M. Ryoo, V. Sindhwani, et al., Socratic models: Composing zero-shot multimodal reasoning with language, arXiv preprint arXiv:2204.00598, 2022. [2] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar, et al., Inner monologue: Embodied reasoning through planning with language models, arXiv preprint arXiv:2207.05608, 2022. [3] Y. Jiang, A. Gupta, Z. Zhang, G. Wang, Y. Dou, Y. Chen, L. Fei-Fei, A. Anandkumar, Y. Zhu, and L. Fan, Vima: General robot manipulation with multimodal prompts, arXiv preprint arXiv:2210.03094, vol. 2, no. 3, p. 6, 2022. [4] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, C. Fu, K. Gopalakrishnan, K. Hausman, et al., Do as can, not as say: Grounding language in robotic affordances, arXiv preprint arXiv:2204.01691, 2022. [5] Z. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma, Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning, in 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024, pp. 20812088. [6] J. Ao, F. Wu, Y. Wu, A. Swikir, and S. Haddadin, Llm as bt-planner: Leveraging llms for behavior tree generation in robot task planning, arXiv preprint arXiv:2409.10444, 2024. [7] Z. Zhao, W. S. Lee, and D. Hsu, Large language models as commonsense knowledge for large-scale task planning, Advances in Neural Information Processing Systems, vol. 36, 2024. [8] Z. Yang, C. Garrett, D. Fox, T. Lozano-Perez, and L. P. Kaelbling, Guiding long-horizon task and motion planning with vision language models, arXiv preprint arXiv:2410.02193, 2024. [9] Y. Shen, K. Song, X. Tan, D. Li, W. Lu, and Y. Zhuang, Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face, Advances in Neural Information Processing Systems, vol. 36, 2024."
        }
    ],
    "affiliations": [
        "Guangdong Provincial Key Laboratory of Future Networks of Intelligence, The Chinese University of Hong Kong, Shenzhen",
        "Harbin Engineering University, Harbin",
        "Infused Synapse AI, Shenzhen",
        "Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai",
        "School of Science and Engineering (SSE), FNii-Shenzhen",
        "Shenzhen Future Network of Intelligence Institute (FNii-Shenzhen)"
    ]
}