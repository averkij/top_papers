{
    "paper_title": "Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases",
    "authors": [
        "Yongjia Lei",
        "Haoyu Han",
        "Ryan A. Rossi",
        "Franck Dernoncourt",
        "Nedim Lipka",
        "Mahantesh M Halappanavar",
        "Jiliang Tang",
        "Yu Wang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for answering queries by providing textual and structural knowledge. However, current retrieval methods often retrieve these two types of knowledge in isolation without considering their mutual reinforcement and some hybrid methods even bypass structural retrieval entirely after neighboring aggregation. To fill in this gap, we propose a Mixture of Structural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge via a Planning-Reasoning-Organizing framework. In the Planning stage, MoR generates textual planning graphs delineating the logic for answering queries. Following planning graphs, in the Reasoning stage, MoR interweaves structural traversal and textual matching to obtain candidates from TG-KBs. In the Organizing stage, MoR further reranks fetched candidates based on their structural trajectory. Extensive experiments demonstrate the superiority of MoR in harmonizing structural and textual retrieval with insights, including uneven retrieving performance across different query logics and the benefits of integrating structural trajectories for candidate reranking. Our code is available at https://github.com/Yoega/MoR."
        },
        {
            "title": "Start",
            "content": "Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases Yongjia Lei1, Haoyu Han2, Ryan A. Rossi3, Franck Dernoncourt3, Nedim Lipka3, Mahantesh Halappanavar4, Jiliang Tang2, Yu Wang1 1University of Oregon, 2Michigan State University, 3Adobe Research, 4Pacific Northwest National Laboratory {yuwang, yongjia}@uoregon.edu, {hanhaoy1, tangjili}@msu.edu {ryrossi, dernonco, lipka}@adobe.com, hala@pnnl.gov 5 2 0 2 1 ] . [ 2 7 1 3 0 2 . 2 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for answering queries by providing textual and structural knowledge. However, current retrieval methods often retrieve these two types of knowledge in isolation without considering their mutual reinforcement and some hybrid methods even bypass structural retrieval entirely after neighboring aggregation. To fill in this gap, we propose Mixture of Structural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge via Planning-Reasoning-Organizing framework. In the Planning stage, MoR generates textual planning graphs delineating the logic for answering queries. Following planning graphs, in the Reasoning stage, MoR interweaves structural traversal and textual matching to obtain candidates from TG-KBs. In the Organizing stage, MoR further reranks fetched candidates based on their structural trajectory. Extensive experiments demonstrate the superiority of MoR in harmonizing structural and textual retrieval with insights, including uneven retrieving performance across different query logics and the benefits of integrating structural trajectories for candidate reranking. Our code is available at https://github.com/Yoega/MoR."
        },
        {
            "title": "Introduction",
            "content": "Text-rich Graph Knowledge Bases (TG-KBs), due to their structured representation of textual documents, ubiquitously store textual and structural knowledge (Jin et al., 2024b). For example, scholars retrieve relevant research from paper management systems to advance scientific discoveries where nodes represent papers and edges denote references (Lu et al., 2024). With large language models (LLMs)-powered generators approaching human intelligence in language comprehension and generation, retrieving supporting knowledge from TG-KBs to contextualize and ground generation has become increasingly crucial for correctly answering queries (Gao et al., 2023b; Ni et al., 2025). 1 Figure 1: (a) Textual retrieval and structural retrieval. (b) The effectiveness of retrieval methods varies across different TG-KBs. (c) Within the same TG-KB, queries addressed by textual (i.e., QText) and structural retrieval (i.e., QStruct) exhibit both overlaps and distinctiveness. Since supporting knowledge in TG-KBs typically exhibits in both the textual and structural formats (Jin et al., 2024b; Kolomiyets and Moens, 2011), retrieval methods should be tailored to both formats effectively as shown in Figure 1(a). Textual retrieval methods retrieve textual knowledge such as indexed documents based on its similarity to the given query and can be broadly categorized into lexical methods (e.g., BM25) and semantic methods (e.g., Contriever) (Karpukhin et al., 2020; Izacard et al., 2022). Structural retrieval methods retrieve structural knowledge such as neighboring entities (Edge et al., 2024; Jiang et al., 2023; Wang et al., 2024) by applying graph traversal and graph machine learning (Tian et al., 2024; Yasunaga et al., 2021). Despite the advancements in both textual and structural retrieval, they are often applied independently and fail to mutually reinforce each other. As shown by Figure 1(b), neither structural retrieval by following the logical structure of the query nor textual retrieval by conducting Top-K BM25 matching can achieve better performance on both Amazon and MAG datasets simultaneously. To effectively retrieve both textual and structural knowledge from TG-KBs, recent works (Xia et al., 2024; Li et al., 2024) aggregate neighboring documents to fuse structural knowledge into textual narratives followed by textual retrieval, with Xia et al. (2024) filtering irrelevant neighbors by their relations and Li et al. (2024) weighted aggregating neighbors based on their fields. However, three challenges remain. First, rewording aggregated neighbors requires frequently invoking LLMs, resulting in prohibitive resources for long documents with exponentially growing neighbors. Second, structural signals humans use to form logical plans are completely discarded after neighbor aggregation. Third, rigid neighbor aggregation overlooks varying desires for structural and textual knowledge for different queries and TG-KBs. In Figure 1(c), even within MAG, queries answered by textual retrieval (i.e., QText) are different from queries answered by structural retrieval (i.e., QStruct). To address the above three challenges, we infuse the mixture-of-expert philosophy into retrieval design and propose Mixture of Structural-andTextual Retrieval (MoR) in Figure 2. MoR begins with planning module that generates planning graphs outlining query logics that preserve structural signals without rewording aggregated neighbors, overcoming the first and second challenges. Next, MoR interleaves structural traversal and textual matching in the reasoning module, enabling these two retrieval to reinforce each other. Finally, MoR devises structure-aware reranker in the organization module that adaptively adjusts the importance of retrieved textual/structural knowledge, addressing the third challenge. Via PlanningReasoningOrganizing, MoR intelligently retrieves structural and textual knowledge based on query logical structure. Our key contributions are: Planning via Textual Graph Generation: We define retrieval planning as generating textual graphs that outline the logical structure, i.e., the plan, for identifying entities relevant to the query. Reasoning via Mixture of Structural-andTextual Traversal: We devise mixed traversal by interweaving textual matching and structural traversal to retrieve knowledge following query logical structure depicted by the generated plan. Organizing via Structure-aware Rerank: With candidates obtained from mixed traversal, we propose Structure-aware Rerank to select TopK candidates based on their traversal trajectory."
        },
        {
            "title": "2 Preliminary",
            "content": "Notations: Text-rich Graph Knowledge Base (TG-KB) generally consists of set of connected nodes in the graph with each node associated with its corresponding document Dv and category Ev E. When retrieving nodes with supporting documents from for answering given query Q, we typically follow certain rationale encapsulating the underlying logic of that query (Xu et al., 2024; Xue et al., 2024), which can be characterized by text-attributed planning graph G. In many existing works (Jin et al., 2024a; Wu et al.), this planning graph can be usually decomposed into multiple reasoning paths = {Pi}G i=1 where the ith reasoning path Pi = (pi1 pi2 , ..., piLi) is distinctive reasoning chain of length Li encoding unique logic and the jth node pij corresponds to an entity in with its own category Epij and textual restriction Tpij extracted from the query. For example, in Figure 1(a), the query Publications by Point... has planning graph with two paths, i.e., P1 = (Institution Author Paper) and P2 = (Field-of-Study Paper), where the category and textual restriction of the first node on P1 are Ep11 = Institution and Tp11 =< Point Park Univerisity >, respectively. Comprehensive notations are summarized in Table 4 in Appendix A. Problem Setup: With the above notations, the investigated problem here is to retrieve entities supporting answering given query Q. Textual Retrieval retrieves candidates based on the textual signals of both the query and documents. One common strategy is to retrieve candidates (cid:101)C from the whole documents that have Top-K textual similarity to query measured by lexical or semantic similarity (Vijaymeena and Kavitha, 2016). The textual retrieval used in MoR retrieves documents for given query by matching them with textual descriptions in the query, e.g., matching stellar populations in tidal tails shown in Figure 1. Structural Retrieval retrieves candidates by applying prescribed rules to structured databases such as knowledge graphs and SQL (Guo et al., 2023). Common strategies include graph-based traversal (e.g., BFS, DFS) and rule fetching (Jiang et al., 2023). Specifically, MoR conducts structural retrieval by traversing neighbors of certain categories from the generated planning graph. For example, in Figure 1(a), only \"Paper\" typed neighbors of the Author can be traversed by our structural retrieval. 2 Figure 2: Our MoR framework consists of planning module to generate planning graph, reasoning module to conduct mixed traversal, and an organizing module to rerank the retrieved candidates."
        },
        {
            "title": "3 Framework",
            "content": "In nutshell, we formulate our MoR as the conditional distribution PΘ(CQ, B) of retrieved candidates given the user input query over TG-KB B, which is further factorized into three distributions corresponding to our proposed three modules: planning via generating the text-attributed planning graph G, reasoning via conducting mixture of structural-and-textual traversal to obtain intermediate candidates (cid:101)C following the generated planning graph G, and organizing via applying structureaware reranking to the obtained candidates (cid:101)C, obtaining final candidates C: PΘ(CQ, B) = (cid:88) (cid:104)(cid:88) PΘ3(C (cid:101)C, G, Q, B) (cid:123)(cid:122) (cid:125) (cid:124) Organizing GG (cid:101)CC (cid:105) PΘ2( (cid:101)CG, Q, B) (cid:123)(cid:122) (cid:125) Reasoning (cid:124) PΘ1(GQ, B) (cid:123)(cid:122) (cid:125) Planning (cid:124) where PΘ1(GQ, B) is the probability distribution of generating the text-attributed planning graph given the input query and TG-KB B; PΘ2( (cid:101)CG, Q, B) is the probability distribution of retrieving intermediate candidates (cid:101)C given the planning graph and the query via our mixed traversal; PΘ3(C (cid:101)C, G, Q, B) is the probability distribution of reranking the intermediate candidates so that Top-K positions form the ground-truth entities C. G/C denotes the space of all possible planning graphs and all possible configurations of size-K candidate node sets from all nodes in TG-KB B. The overall objective is to maximize the likelihood of retrieving ground-truth candidates for each input query Q: Θ = arg max Θ (cid:89) QQ PΘ(CQ, B) (1) Following the above paradigm, we next introduce the three components: Planning via textual graph generation in Section 3.1, Reasoning via mixed traversal in Section 3.2, and Organizing via structure-aware reranking in Section 3.3."
        },
        {
            "title": "3.1 Planning via Textual Graph Generation",
            "content": "To effectively reason over the underlying logic of queries and answer them, we propose planning module that constructs planning graph to capture their underlying logical structures. Unlike conventional approaches relying on rigid heuristics, e.g., shortest-path retrieval in knowledge graphs (Luo et al.; Delile et al., 2024), or step-by-step prompting of LLMs, which incurs high computational costs (Sun et al., 2023; Wang et al., 2024), our method generates the entire planning graph in one shot, eliminating repeated LLM calls. More importantly, as planning graphs integrate entity restrictions encoding query-specific constraints and entity categories capturing broader logical structure, our MoR can generalize learned patterns and efficiently adapt to new queries with the same underlying logic. For example, any query with the form Papers associated with <institution> and are in the field of <field> shares the same patterns with the query in Figure 2. Below, we first formalize the planning graph and then optimize its generation."
        },
        {
            "title": "3.1.1 Planning Graph Formulation",
            "content": "A planning graph is structured representation where nodes represent entities and edges denote their logical relations. Each entity is associated with both category and query-specific restriction. For example, given the query Can you give me publications by Point Park University authors on stellar populations in tidal tails, the generated planning graph is: = (Institution<Point Park University> Author Paper Field-of-Study<Stellar Population>) with Institution, Author, Paper, Fieldof-Study as categories and <Point Park University>, <Stellar Populations> as restrictions. Note that edges in our planning graph can also possess different categories. For example, in the biomedical TG-KBs, the relation between Disease and Drug entities could be Indication or Contra-indication (Wu et al.), adding finer level of semantic distinction to the relation."
        },
        {
            "title": "3.1.2 Planning Graph Optimization",
            "content": "To ensure that our generated planning graph captures the query logic, we train textual graph generator to maximize the likelihood of generating ground-truth planning graphs given their queries. Formally, given the joint distribution of the training pairs between queries and planning graphs Train QG, we optimize the planning module PΘ1 by solving: arg max Θ1 (Q,G)P Train QG log PΘ1(GQ, B) (2) To avoid the combinatorial explosion of exponentially growing planning graph candidates (You et al.), we decompose each planning graph into multiple reasoning paths = {Pi}G i=1. Each path Pi = (pi1 , ..., piLi) represents distinct reasoning chain, where node pij denotes an entity in TG-KB sharing the same textual category Epij and satisfying the restriction Tpij from the query. Given the sequential nature and textual formats of these decomposed reasoning paths, LLMs can be naturally employed here as the planning graph generator, which conducts next-token prediction by predicting jth token tj conditioned on preceding tokens t<j, the query and the TG-KB B: PΘ1(GQ) = (cid:89) j=1 PΘ1(tjt<j, Q, B). (3) Note that our proposed planning graph generator is not limited to LLMs. Any graph generative model preserving both structural dependencies and textual associations can be employed (Zhu et al.)."
        },
        {
            "title": "3.2 Reasoning via Mixed Traversal",
            "content": "Following the reasoning paths of the above planning graph = {Pi}G i=1, the reasoning module conducts mixed traversal by interweaving neighbor fetching and textual matching to form intermediate candidates (cid:101)C, which are introduced next."
        },
        {
            "title": "3.2.1 Structural Traversal",
            "content": "Following the definition in Section 2 that structural retrieval follows prescribed rules for knowledge retrieval, here we set these prescribed rules to be iteratively performing layer-wise breadth-first-search that traverses neighboring entities with categories aligning with those in the reasoning paths. Concretely, reasoning at the lth-step of the planning path Pi, we check for each node in candidates set of last layer (cid:101)Cl1 and fetch its neighbors Nv with the same category as the corresponding node pil (i.e., Eu = Epil) in the reasoning path, which can be mathematically formulated as: (cid:101)Cl,Struct = (cid:101)Cl1 {uu Nv, Eu = Epil} (4) where (cid:101)Cl,Struct denotes the set of structurally rei trieved entities at the lth reasoning step according to the path Pi and Eu = Epil ensures that the category of the traversed neighbor matches the corresponding entity category routine by the planning graph, resonating the nature of rule-based structural retrieval. Note that the seeding candidates (cid:101)C1,Struct at the very first layer are initialized by rei trieving Top-K entities through textual matching, i.e., (cid:101)C1,Struct , which is introduced next. = (cid:101)C1,Text i"
        },
        {
            "title": "3.2.2 Textual Matching\nIn addition to retrieving structural knowledge, our\nMoR also retrieves textual knowledge via Tex-\ntual Matching, which retrieves candidates based\non their textual similarity to queries. For each\nreasoning node pil at lth reasoning step along the\nreasoning path Pi, we concatenate the query and\nthe textual restriction of pil, i.e., Q′ = [Q : Tpil],\nthen compute its textual similarity to documents\nof nodes in TG-KB, i.e., ϕ(Q′, Dv), ∀v ∈ V, and\nfinally retrieve the Top-K scored candidates:",
            "content": "(cid:101)Cl,Text = TopK({v V, Ev = Epil}, ϕ(Q, Dv)) (5) Integrating candidates from structural traversal and textual matching together, the final candidates at lth-step of Pi are formed as: = (cid:101)Cl,Struct (cid:101)Cl (cid:101)Cl,Text , {1, 2, ..., Li} (6) The integrated candidates (cid:101)Cl serve as seeding nodes initializing the next round of planning graphguided structural traversal and textual matching, which creates mutual reinforcement between structural and textual knowledge since previously retrieved two knowledge can both inform next round of structural/textual knowledge retrieval. We iteratively conduct mixed traversal for every reasoning path Pi and integrate retrieved entities together by taking their intersection, i.e., (cid:101)C = PiG (cid:101)CLi , adhering to the fact that candidates should simultaneously satisfy the logic routine by all reasoning paths. Note that no training is involved in the mixed graph traversal, i.e., PΘ2( (cid:101)CG, Q, B) = ( (cid:101)CG, Q, B). Future works could explore optimizing graph traversal by rewards from agent-environment interactions (Nguyen et al., 2024)."
        },
        {
            "title": "4 Experiment",
            "content": "Although the retrieved candidates from Section 3.2 strictly adhere to the prescribed rule given by the planning graph, the sheer volume of candidates misaligns with realistic constraints (e.g., Top-20 retrieval budget (Zeng et al., 2024)) and may even cause difficulty to downstream executors such as long-context challenges for LLMs. To better emulate human reasoning, where multiple clues are gathered, analyzed in relation to the query, and synthesized into coherent answer, we propose structure-aware reranker to organize and rerank the candidates (cid:101)C, and select Top-K ones as the final retrieved answers C. Instead of relying only on textual features (Hu et al., 2019), our reranker assigns ranking score based on features of structural trajectories obtained from the mixed traversal in Section 3.2, innovatively leveraging both structural and textual knowledge in reranking. Previously, (cid:101)C is defined as intermediate retrieved entities. To consider structural features in reranking, we pair each retrieved candidate in (cid:101)C with its corresponding traversal trajectory obtained from the reasoning module. Specifically, each trajectory Pi of length Li is featuring three types of attributes: Textual Fingerprint (TF): Concatenation of similarity scores between the expanded query and each node on the path: (cid:13) Li l=1ϕ(Q, Dpil). (cid:13) Structural Fingerprint (SF): Concatenation of node categories at each step on the path: (cid:13) Li l=1Epil (cid:13) Traversal Identifier (TI): Concatenation of the indicator specifying whether each step uses structural or textual retrieval: (cid:13) Li l=1Ipil. (cid:13) We then train reranker on these trajectories using the cross-entropy loss. For training query and its associated candidate trajectory Pi, the loss is computed as follows: (cid:88) 2 (cid:88) LΘ3 = yi log(σ(f ( j=1 (Pi,Q) (cid:101)C : (cid:13) Li l=1ϕ(Q, Dpil) (cid:13) (cid:125) (cid:123)(cid:122) (cid:124) Textual Fingerprint : (cid:13) Li l=1Epil (cid:13) (cid:124) (cid:123)(cid:122) (cid:125) Structural Fingerprint (cid:13) Li l=1Ipil (cid:13) (cid:124) (cid:123)(cid:122) (cid:125) Traversal Identifier ))j). (7) where () is the reranker producing score for each (Q, Pi) pair, σ() denotes the softmax function, and yi {0, 1} indicates whether the i-th candidate is correct (positive) or incorrect (negative) match for Q. This formulation encourages the reranker to assign higher scores to positive trajectories, thereby improving ranking performance."
        },
        {
            "title": "4.1 Experimental Setup",
            "content": "We briefly introduce experimental settings to verify our proposed MoR, including Datasets & Baselines, Implementation Details, and Evaluation Metrics. More details are in Appendix B. Datasets & Baselines: We use three TG-KBs from STaRK (Wu et al.) covering three knowledge domains, including E-commerce Products (Amazon), Academic Papers (MAG), and Biomedicine (Prime). We compare our MoR with baselines established by Wu et al. and categorize them into textual/structural/hybrid-based ones. More recent state-of-the-art hybird retrieval approaches fro TG-KBs such as KAR (Xia et al., 2024) and MFAR (Li et al., 2024) are also compared. Implementation Details: To enhance the planning capability of our planning module, we finetune the Llama 3.2 (3B) on 1000 sampled queries with their corresponding ground-truth planning graphs, serving as the textual graph generator. In the absence of ground-truths, we synthesize them using LLMs. For the Prime dataset, we empirically find that directly prompting LLMs can hardly generate accurate planning graphs due to the lack of biomedical domain knowledge (Shen et al.). Therefore, we adopt an alternative approach. First, we instruct LLMs to extract triplets from each query and then construct the planning graphs by merging triplets with shared entities. During mixed traversal, textual matching can be implemented using any lexical or semantic methods. For this study, we employ BM25 for Amazon and MAG and finetune contriever to complement the biomedical knowledge for Prime. To initialize the structural traversal, we employ textual matching to locate the top 5 nodes that are most relevant to the query as seeds. Additionally, at each layer, we incorporate the top 10 nodes retrieved via textual matching and append them to the current candidate set for the next round of traversal. Notably, due to the uncertainty of LLMs, the generated planning graphs can be invalid. In this case, we will directly conduct textual matching to retrieve candidates. For our ablations without reranker, we employ Ada-002 (Wu et al.) with cosine similarity as the scorer to rank candidates for evaluating performance. Evaluation Metrics: We follow Wu et al. for evaluation by reporting Hit@1 (H@1), Hit@5 (H@5), Recall@20 (R@20), and mean reciprocal rank MRR to evaluate in the full spectrum. Category Retrieval Baseline AMAZON MAG PRIME AVERAGE H@1 H@5 R@20 MRR H@1 H@5 R@20 MRR H@1 H@5 R@20 MRR H@1 H@5 R@20 MRR Textual BM25 (Wu et al.) Ada-002 (Wu et al.) Multi-ada-002 (Wu et al.) DPR (Karpukhin et al., 2020) 44.94 39.16 40.07 15.29 Structural (KG) QAGNN (Yasunaga et al., 2021) ToG (Sun et al., 2023) 26.56 - Hybrid Ablation AvaTaR (Wu et al., 2025) KAR (Xia et al., 2024) MFAR (Li et al., 2024) MoR MoRw/o MoRw/o RT MoRw/o RS 49.87 54.20 41.20 52.19 44.21 34.04 43.05 67.42 62.73 64.98 47. 50.01 - 69.16 68.70 70.00 74.65 68.87 53.41 69.36 53.77 53.29 55.12 44.49 52.05 - 60.57 57.24 58.50 59. 56.50 45.16 57.38 55.30 50.35 51.55 30.20 37.75 - 58.70 61.29 54.20 62.24 55.28 42.85 54.69 25.85 29.08 25.92 10. 12.88 13.16 44.36 50.47 49.00 58.19 34.33 51.81 31.05 45.25 49.61 50.43 35.23 39.01 16.17 59.66 69.57 69.60 78. 62.55 73.54 51.84 45.69 48.36 50.80 42.11 46.97 11.30 50.63 60.28 71.70 75.01 67.55 74.17 50.56 34.91 38.62 36.94 21. 29.12 14.18 51.15 58.65 58.20 67.14 47.40 61.68 40.64 12.75 12.63 15.10 4.46 8.85 6.07 18.44 30.35 40.90 36. 31.59 28.95 22.27 27.92 31.49 33.56 21.85 21.35 15.71 36.73 49.30 62.80 60.01 53.48 46.12 38.45 31.25 36.00 38.05 30. 29.63 13.07 39.31 50.81 68.30 63.48 60.74 49.54 39.21 19.84 21.41 23.49 12.38 14.73 10.17 26.73 39.22 51.20 46. 41.81 36.56 29.41 27.85 26.96 27.03 10.09 16.10 9.62 37.56 45.01 43.70 48.93 31.07 36.39 28.95 46.86 47.94 49.66 35. 36.79 15.94 55.18 62.52 67.47 71.00 57.04 56.73 51.28 43.57 45.88 47.99 38.91 42.88 12.18 50.17 56.11 66.17 66. 57.73 55.73 48.02 36.68 36.79 37.33 21.31 27.20 12.18 45.53 53.05 54.53 58.77 43.03 45.53 38.98 Table 1: Comparing different retrieval methods with our proposed MoR and its ablations on Amazon, MAG, and Prime datasets. The best and runner-up results are in bold and underlined. Overall, MoR achieves the best performance. Note that MFAR denotes the best model variant proposed in (Li et al., 2024)"
        },
        {
            "title": "4.3 Ablation Study",
            "content": "We compare MoR with other baselines on three TG-KBs in Table 1. Generally, hybrid methods, AvaTAR, KAR, MFAR, and our MoR, achieve better performance than purely textual or structural methods owing to their ability to integrate both structural and textual knowledge. Among all baselines, our proposed MoR achieves the overall best performance with substantial margin on average, with the first ranking on MAG and the second ranking on Amazon/Prime datasets. This demonstrates the effectiveness of our proposed mixture of structural and textual knowledge retrieval. Textual retrieval performs better on Amazon than on MAG, suggesting that Amazon queries rely more on texIn contrast, its weaker perfortual knowledge. mance on MAG is due to MAGs lower textual richness and stronger structural signals. This disparity aligns with the distribution analysis presented by Wu et al. and supports our hypothesis that queries in different TG-KB datasets require varying desires for textual and structural knowledge. Meanwhile, structural retrieval methods such as conventional knowledge graph-based ones perform poorly because they are designed for graphs with minimal textual information compared to TG-KBs. Different from Amazon and MAG, all existing methods without supervised tuning (e.g., Ada-002) exhibit significantly lower performance on Prime. This is due to the extreme domain expertise required in biology, where word-count-based, pre-trained textual similarity-based, and even more powerful LLMs are all poorly applicable here. Through fine-tuning, MFAR and our proposed MoR generally achieve better performance, demonstrating the necessity of domain-specific knowledge for answering queries in knowledge-intensive domains. After verifying the superiority of MoR, we conduct ablation studies to assess its different components, including module and feature ablation."
        },
        {
            "title": "4.3.1 Module Ablation",
            "content": "To assess the contribution of each module in MoR, namely, Text Matching-based Retrieval, Neighborhood-Fetching-based Structural Retrieval, and Reranker, we conduct series of ablation experiments. First, we remove the Reranker, resulting in the variant MoRw/o R. On top of that, we further separately eliminate Text Retrieval and Structural Retrieval, yielding MoRw/o RT and MoRw/o RS, respectively. As shown in Table 1, the complete MoR framework consistently achieves the highest performance across all datasets, demonstrating the synergistic effect of the Textual Retriever, Structural Retriever, and Reranker. After removing Reranker, MoRw/o exhibits consistent performance drop across all datasets and evaluation metrics. This underscores the importance of the Reranker in refining retrieval by filtering noisy candidates from the intermediate reasoning stage. Eliminating Text Retrieval, i.e., MoRw/o RT, leads to notable performance drop on Amazon but an unexpected improvement on MAG. This suggests that while textual knowledge benefits Amazon, it introduces misleading hard negatives that compromise the ranking method (e.g., Ada-002) for MAG. Conversely, removing Structural Retrieval, MoRw/o RS, results in slight performance decrease further on MAG, reinforcing the importance of structural knowledge in MAG-related queries. These results underscore the Rerankers crucial role in adaptively harmonizing, balancing, and selecting knowledge from both structural and textual retrieval experts."
        },
        {
            "title": "Dataset",
            "content": "TF SF TI H@1 H@5 R@20 MRR"
        },
        {
            "title": "Amazon",
            "content": "48.96 73.02 18.79 41.91 18.16 41.53 58.04 77.14 58.16 77.59 17.93 38.01 58.19 78.34 51.21 74.05 24.48 8.09 5.84 16.62 50.91 73.38 51.09 73.56 8.09 24.48 52.19 74.65 72.44 52.85 52.78 74.42 74.96 46.79 75.01 59.79 25.62 12.94 59.58 59.61 25.62 59.92 59.79 29.84 29.31 66.75 66.85 27.48 67.14 61.27 16.94 11.57 61.15 61.14 16.94 62.24 Table 2: Ablation study investigating the importance of three features, Textual Fingerprint (TF), Structural Fingerprint (SF), and Traversal Identifier (TI), of the traversal trajectories used in our Structure-aware Reranker."
        },
        {
            "title": "4.3.2 Feature Ablation",
            "content": "The above ablation study highlights the crucial role of Structure-aware Reranker in adaptively integrating structural and textual knowledge. To further analyze the contributions of its three key features, Textual Fingerprint (TF), Structural Fingerprint (SF), and Traversal Identifier (TI) defined in Section 3.3, we conduct feature ablation analysis and report retrieval performance across different feature configurations in Table 2. Overall, using three features together yields the best performance on both MAG and Amazon, highlighting their synIndividually, TF contributes the ergistic effect. most and outperforms SF and TI on both datasets. The reason is that based on the definition in Section 3.3, TF directly captures the relevance between the query and the retrieved nodes along the trajectory, whereas SF and TI primarily characterize the structural patterns and retrieval types, serving more as complementary factors. Therefore, equipping TF with these complementary factors (i.e., SF or TI) yields around 10% additional gains on MAG. This is because SF and TI help the reranker selectively emphasize the relevance scores given by TF for certain nodes along the path. However, this boost is not observed on Amazon. We hypothesize that the textual knowledge needed there is predominantly derived from the final node on each path, making the structural cues provided by SF and TI less beneficial and even prone to overfitting. deeper analysis to further justify this hypothesis is in Section 4.4. Overall, these findings underscore the varying importance of structural features in ranking across datasets."
        },
        {
            "title": "Amazon",
            "content": "H@1 R@20 MRR H@1 R@20 MRR Last Node 49.91 58.19 Full Path 73.49 75.01 59.92 50.36 67.14 52.19 59.62 59.92 61.05 62. Table 3: Comparing reranking performance using last node in the retrieved trajectory and the whole trajectory. Figure 3: Imbalance number of queries and performance of different retrievers across different logical structures."
        },
        {
            "title": "4.4 Further Analysis",
            "content": "This section understands MoRs behavior by examining three questions, each of which enriches our insight into MoRs functionality and offers novel perspectives inspiring future query retrieval research. Do structure signals affect reranking? To assess the impact of trajectory information on the Rerankers decision-making, we introduce nodebased Reranker that constructs trajectory features using only TF/SF/TI of the last node. In Table 3, the path-based Reranker outperforms the nodebased variant, especially on MAG. This highlights the critical role of trajectory features/structural knowledge in reranking. The minor performance boost on Amazon after switching to the full path trajectory indicates its textual knowledge preference over the last node rather than the whole trajectory. How does MoR perform on different logical structures? Figure 3 shows the average performance of MoR on each query group categorized by their logical structures, where \"Others\" refer to queries with undefined logical structures in Wu et al. MoR consistently outperforms structural and textual retrievers across different logical structures. Among all queries, MoR performs the worst on \"P P\" queries due to the ambiguity, although well-known, uniquely caused by repeated product entities from multi-step traversal. The averageperforming Others\" group underscores the utility of diverse planning strategies for the same query. Lastly, the skewed query distribution and retrieval performance across planning patterns reflect the varying nature of real-world planning needs. We hope these insights inspire research on data-centric reasoning designs and error control of planning."
        },
        {
            "title": "5 Related Work",
            "content": "Retrieval-augmented Generation (RAG): RAG enhances generative tasks by retrieving relevant information from external knowledge sources (He et al., 2025; Gao et al., 2023c) and has been widely used to improve question-answering (Liu et al., 2023). With LLMs, RAG has been used for mitigating hallucinations (Yao et al., 2023), enhancing interpretability (Gao et al., 2023a), and enabling dynamic knowledge updates (Wang et al., 2024). This work essentially leverages the idea of RAG to retrieve supporting entities from TG-KBs to contextualize answer generation. Depending on concrete types of knowledge being retrieved, existing retrievers can be categorized into structural and textual retrieval, which are reviewed next. Textual and Structural Retrieval: Early textual such as TF-IDF and BM25 (Robertson et al., 2009), rely on lexical similarity and keyword matching (Chen et al., 2017; Yang et al., 2019; Mao et al., 2021). Modern approaches address this limitation by learning dense representations (Karpukhin et al., 2020). Beyond textual retrieval, structural retrieval leverages graph-based techniques to extract structured knowledge. Methods such as graph traversal (Wang et al., 2024; Jiang et al., 2023), community detection (Edge et al., 2024), and graph machine learning models, including graph neural networks (Yasunaga et al., 2021; Mavromatis and Karypis, 2024), play crucial role in structural retrieval. Our approach integrates the strengths of both textual and structural retrieval by infusing the mixtureof-expert philosophy into retrieval design. retrieval models, Due to page limitation, comprehensive version of the related work is attached in Appendix D."
        },
        {
            "title": "6 Conclusion",
            "content": "In this work, we propose mixture of structural and textual retrieval (MoR) to adaptively retrieve structural and textual knowledge based on query desire, which first utilizes textual graph generator to generate the planning graph, then performs mixed traversal and conducts organizing via structureaware reranker to obtain final candidates. Experiments demonstrate the advantages of our MoR in harmonizing the retrieval of both textual and structural knowledge with insightful discoveries, including balancing retrieval performance across queries with different patterns and query-adaptive knowledge desire for structural/textual knowledge. Figure 4: Saliency map visualization of query attention over three entities along the retrieved paths Does MoR indeed adaptively leverage the trajectory knowledge? To understand how our proposed reranker prioritizes candidates in the Top-K results, we visualize the saliency map by computing the gradient of ranking scores with respect to the textual fingerprint (TF) of three nodes along the traversed path, which quantifies their importance for answering given query. Figure 4 illustrates this by analyzing trajectories for 100 ground-truth candidates across 100 queries on the Amazon and MAG datasets. Each dimension corresponds to traversed node, with the final one representing the candidate itself. While the saliency score is concentrated in the last dimension for Amazon, MAG exhibits more evenly distributed saliency pattern, where multiple nodes along the path contribute significantly to ranking score computation. This suggests that structural knowledge is more critical for answering queries in MAG, aligning with the previously observed lower performance of purely textual retrieval on MAG in Table 1. Further case studies explain why the reranker attends different nodes for different queries. In Figure 4(a), the reranker favors the last two dimensions as the rich textual restriction (i.e., \"Northwest Company...\" and \"NFL Seattle...\") aids in identifying the correct node at the corresponding reasoning step, as discussed in Section 3.2. The correct nodes, having higher similarity scores with the query, help guide the retrieval process toward the ground truth. Conversely, in Figure 4(b), since the first node (\"University of Lausanne\") helps narrow the search space and the last node (\"frameless...\") further filter candidates, both nodes have high saliency scores. Overall, our findings demonstrate that the reranker dynamically adapts its reliance on structural and textual knowledge depending on the dataset and query."
        },
        {
            "title": "7 Limitations",
            "content": "In this paper, we integrate mixture of expert philosophy into retrieval design and propose Mixture of structural-and-textual Retrieval (MoR) to adaptively retrieve textual and structural knowledge. The limitations of MoR can be categorized into two main aspects in the following: Lack of Domain-Specific Knowledge: Our proposed MoR, similar to other baselines, does not exhibit significantly higher performance on PRIME than AMAZON and MAG. The reason is the lack of biomedical knowledge required to comprehend biomedical questions, extract key information, navigate relevant entities and relations, and rerank retrieved candidates. This suggests that current state-of-the-art retrieval models, even paired with LLMs intelligence, still struggle to handle domainspecific knowledge effectively. Such limitations may extend to other specialized domains, such as finance and law. Future research could integrate domain-specific knowledge into retrieval. Reranking at Every Traversal Layer: Our current MoR adaptively routes retrieved candidates into the Top-K positions at the final layer via reranking, effectively implementing conventional Mixture of Experts (MoE) routing mechanism. Despite the state-of-the-art performance we have achieved in Table 1, this routing mechanism could also be applied to intermediate layers, where after each retrieval step, candidates are reranked, and only Top-K proceeds to the next round of traversal and retrieval. This enables every layer of mixed traversal to emulate the router design of the MoE. Multi-Trajectory Reranking: While our current Structural Reranker is designed to compute ranking scores by leveraging the full spectrum of trajectory information from multiple traversed paths ending at each candidate (as illustrated in Figure 2), our implementation currently utilizes only the most informative trajectory (i.e., the one with the longest traversed path) due to implementation complexity. Future work should explore adaptive methods to fully integrate the complete set of traversed paths into the candidate ranking process and compare the effectiveness of leveraging traversed paths at different levels."
        },
        {
            "title": "References",
            "content": "Payal Chandak, Kexin Huang, and Marinka Zitnik. 2023. Building knowledge graph to enable precision medicine. Scientific Data, 10(1):67. Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading Wikipedia to answer opendomain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 18701879, Vancouver, Canada. Association for Computational Linguistics. Julien Delile, Srayanta Mukherjee, Anton Van Pamel, and Leonid Zhukov. 2024. Graph-based retriever captures the long tail of biomedical knowledge. ArXiv, abs/2402.12352. Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. 2024. From local to global: graph rag approach to query-focused summarization. ArXiv, abs/2404.16130. Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang. 2023a. Chatrec: Towards interactive and explainable llmsaugmented recommender system. arXiv preprint arXiv:2303.14524. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, and Haofen Wang. 2023b. Retrievalaugmented generation for large language models: survey. ArXiv, abs/2312.10997. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023c. Retrieval-augmented generation for large language models: survey. arXiv preprint arXiv:2312.10997. Chunxi Guo, Zhiliang Tian, Jintao Tang, Shasha Li, Zhihua Wen, Kaixuan Wang, and Ting Wang. 2023. Retrieval-augmented gpt-3.5-based text-to-sql framework with sample-aware prompting and dynamic revision chain. In International Conference on Neural Information Processing, pages 341356. Springer. Haoyu Han, Yu Wang, Harry Shomer, Kai Guo, Jiayuan Ding, Yongjia Lei, Mahantesh Halappanavar, Ryan Rossi, Subhabrata Mukherjee, Xianfeng Tang, et al. 2024. Retrieval-augmented generation with graphs (graphrag). arXiv preprint arXiv:2501.00309. Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh Chawla, Thomas Laurent, Yann LeCun, Xavier Bresson, and Bryan Hooi. 2025. G-retriever: Retrieval-augmented generation for textual graph understanding and question answering. Advances in Neural Information Processing Systems, 37:132876132907. Minghao Hu, Yuxing Peng, Zhen Huang, and Dongsheng Li. 2019. Retrieve, read, rerank: Towards end-to-end multi-document reading comprehension. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2022. Unsupervised dense information retrieval with contrastive learning. Transactions on Machine Learning Research. 9 Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji rong Wen. 2023. Structgpt: general framework for large language model In Conference on to reason over structured data. Empirical Methods in Natural Language Processing. Dang Nguyen, Viet Dac Lai, Seunghyun Yoon, Ryan Rossi, Handong Zhao, Ruiyi Zhang, Puneet Mathur, Nedim Lipka, Yu Wang, Trung Bui, et al. 2024. Dynasaur: Large language agents beyond predefined actions. arXiv preprint arXiv:2411.01747. Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Suhang Wang, Yu Meng, and Jiawei Han. 2024a. Graph chain-of-thought: Augmenting large language models by reasoning on graphs. In Annual Meeting of the Association for Computational Linguistics. Bo Ni, Zheyuan Liu, Leyao Wang, Yongjia Lei, Yuying Zhao, Xueqi Cheng, Qingkai Zeng, Luna Dong, Yinglong Xia, Krishnaram Kenthapadi, et al. 2025. Towards trustworthy retrieval augmented generation for large language models: survey. arXiv preprint arXiv:2502.06872. Bowen Jin, Yu Zhang, Sha Li, and Jiawei Han. 2024b. Bridging text data and graph data: Towards semantics and structure-aware knowledge discovery. In Proceedings of the 17th ACM International Conference on Web Search and Data Mining, pages 11221125. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for opendomain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 67696781. Oleksandr Kolomiyets and Marie-Francine Moens. 2011. survey on question answering technology from an information retrieval perspective. Information Sciences, 181(24):54125434. Stephen Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: Bm25 and beyond. Foundations and Trends in Information Retrieval, 3(4):333389. Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis, and Nicolo Fusi. Tag-llm: Repurposing general-purpose llms for specialized doIn Forty-first International Conference on mains. Machine Learning. Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Sai Wang, Chen Lin, Yeyun Gong, Lionel M. Ni, Heung yeung Shum, and Jian Guo. 2023. Think-on-graph: Deep and responsible reasoning of large language model on knowledge graph. In International Conference on Learning Representations. Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, and Christos Faloutsos. 2024. Hybgrag: Hybrid retrieval-augmented generation on textual and relational knowledge bases. ArXiv, abs/2412.16311. Dhaval Taunk, Lakshya Khanna, Pavan Kandru, Vasudeva Varma, Charu Sharma, and Makarand Tapaswi. 2023. Grapeqa: Graph augmentation and pruning to enhance question-answering. Companion Proceedings of the ACM Web Conference 2023. Millicent Li, Tongfei Chen, Benjamin Van Durme, and Patrick Xia. 2024. Multi-field adaptive retrieval. arXiv preprint arXiv:2410.20056. Lihui Liu, Yuzhong Chen, Mahashweta Das, Hao Yang, and Hanghang Tong. 2023. Knowledge graph question answering with ambiguous query. In Proceedings of the ACM Web Conference 2023. Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. 2024. The ai scientist: Towards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292. Linhao Luo, Yuan-Fang Li, Reza Haf, and Shirui Pan. Reasoning on graphs: Faithful and interpretable large language model reasoning. In The Twelfth International Conference on Learning Representations. Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen. 2021. Generation-augmented retrieval for opendomain question answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Costas Mavromatis and George Karypis. 2024. Gnnrag: Graph neural retrieval for large language model reasoning. ArXiv, abs/2405.20139. Yijun Tian, Huan Song, Zichen Wang, Haozhu Wang, Ziqing Hu, Fang Wang, Nitesh Chawla, and Panpan Xu. 2024. Graph neural prompting with large language models. In Proceedings of the AAAI Conference on Artificial Intelligence. MK Vijaymeena and Kavitha. 2016. survey on similarity measures in text mining. Machine Learning and Applications: An International Journal. Yu Wang, Nedim Lipka, Ryan Rossi, Alexa Siu, Ruiyi Zhang, and Tyler Derr. 2024. Knowledge graph prompting for multi-document question answering. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 1920619214. Shirley Wu, Shiyu Zhao, Qian Huang, Kexin Huang, Michihiro Yasunaga, Kaidi Cao, Vassilis Ioannidis, Karthik Subbian, Jure Leskovec, and James Zou. 2025. Avatar: Optimizing llm agents for tool usage via contrastive reasoning. Advances in Neural Information Processing Systems, 37:2598126010. Shirley Wu, Shiyu Zhao, Michihiro Yasunaga, Kexin Huang, Kaidi Cao, Qian Huang, Vassilis Ioannidis, Karthik Subbian, James Zou, and Jure Leskovec. Stark: Benchmarking llm retrieval on textual and relational knowledge bases. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 10 Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan Rossi, Haoliang Wang, and Julian McAuley. 2024. Knowledge-aware query expansion with large language models for textual and relational retrieval. arXiv preprint arXiv:2410.13765. Mayi Xu, Yongqi Li, Ke Sun, and Tieyun Qian. 2024. Adaption-of-thought: Learning question difficulty improves large language models for reasoning. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 54685495, Miami, Florida, USA. Association for Computational Linguistics. Shangzi Xue, Zhenya Huang, Xin Lin, Jiayu Liu, Longhu Qin, Tianhuang Su, Haifeng Liu, and Qi Liu. 2024. Enhancing the completeness of rationales for multi-step question answering. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pages 27532763. Wei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen Tan, Kun Xiong, Ming Li, and Jimmy Lin. 2019. End-to-end open-domain question answering with bertserini. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics, pages 7277."
        },
        {
            "title": "A Summary of Notations",
            "content": "Table 4: Notations and the corresponding descriptions. Notations Definitions or Descriptions V, E, Dv , Ev QStruct, QText = {Pi} i=1 Pi = (pi1 ... piLi Epij , Tpij (cid:101)C Text-rich Graph Knowledge Base (TG-KB) Set of Nodes, Categories and Documents of TG-KB Document and Category of Node Query from Query set Query targeted by structural and textual retrieval Planning Graph consisting of multiple reasoning paths ) Reasoning path consisting of Li sequential entities Textual category and restriction of path entity pij Retrieved candidates after reasoning module. = (cid:101)Cl,Struct (cid:101)Cl (cid:101)Cl,Text Retrieved candidates at lth layer for ith path including structurally retrieved ones and textually retrieved ones. PQG Nv Ipil PΘ1 PΘ2 PΘ3 Final retrieved candidates after organizing module. Joint distribution of query and planning graph. Neighborhood of entity Traversal Identifier of Structural and Textual Retrieval Planning module with its parameters Θ1 Reasoning module with its parameters Θ2 Organizing module with its parameters Θ"
        },
        {
            "title": "Dataset",
            "content": "# Entities # Text Tokens # Relations Avg. Degree"
        },
        {
            "title": "AMAZON\nMAG\nPRIME",
            "content": "1,035,542 1,872,968 129,375 592,067,882 212,602,571 31,844,769 9,443,802 39,802,116 8,100,498 18.2 43.5 125.2 Table 5: Statistics of text-rich graph knowledge bases in STaRK benchmark (Wu et al.). Jia-Yu Yao, Kun-Peng Ning, Zhen-Hui Liu, Mu-Nan Ning, and Li Yuan. 2023. Llm lies: Hallucinations are not bugs, but features as adversarial examples. arXiv preprint arXiv:2310.01469."
        },
        {
            "title": "B Experimental Details",
            "content": "B.1 Datasets Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, and Jure Leskovec. 2021. Qa-gnn: Reasoning with language models and knowledge graphs for question answering. In North American Chapter of the Association for Computational Linguistics. Jiaxuan You, Rex Ying, Xiang Ren, William Hamilton, and Jure Leskovec. Graphrnn: Generating realistic graphs with deep auto-regressive models. In International conference on machine learning. PMLR. Huimin Zeng, Zhenrui Yue, Qian Jiang, and Dong Wang. 2024. Federated recommendation via hybrid retrieval augmented generation. 2024 IEEE International Conference on Big Data (BigData). Xikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher Manning, and Jure Leskovec. Greaselm: Graph reasoning enhanced language models. In International Conference on Learning Representations. Yanqiao Zhu, Yuanqi Du, Yinkai Wang, Yichen Xu, Jieyu Zhang, Qiang Liu, and Shu Wu. survey on deep graph generation: Methods and applications. In Learning on Graphs Conference. PMLR. To evaluate the effectiveness of our proposed framework, we conduct experiments using three Text-rich Graph Knowledge Bases (TG-KBs) from STaRK (Wu et al.). These TG-KBs cover wide range of domains, including product reviews (Amazon), academic papers (MAG), and biomedical knowledge (Prime). Each TG-KB comprises textual graph and an associated corpus, with the corpus containing documents linked to the nodes in the graph. Queries are meticulously crafted for each TG-KB and encompass varying levels of complexity, which desire different levels of textual and structural knowledge to answer. Amazon: dataset provides realistic simulation of product search and recommendation. Its textual graph consists of four categories of nodes: product, category, color, and brand. Nodes are interconnected through relations such as has_brand and has_category. Textual documents encapsulate properties of corresponding nodes, such as product descriptions and customer reviews. MAG: comprehensive resource for academic paper retrieval. In the textual graph, papers can be connected to other nodes, such as field_of_study 11 via the paper_has_topic_field_of_study relation and institution through combination of relations like author_affiliated_with_institution and author_writes_paper. Each paper document includes the title, abstract, and metadata, such as the publication date and venue, providing rich contextual knowledge for retrieval and analysis. Prime: highly domain-specific dataset. It focuses on medical inquiries and is sourced from the PrimeKG knowledge graph (Chandak et al., 2023), which comprises ten entity types and eighteen relation types, offering multiple target node categories, such as disease, gene/protein, and drug. The associated documents are aggregated from various databases, providing rich and diverse source of medical knowledge. Detailed dataset statistics are in Table 5. B."
        },
        {
            "title": "Implementation Details",
            "content": "Prompt for Planning Graph Generation: For planning graph generation in Section 3.1, we follow previous works (Luo et al.; Wu et al.) to linearize the planning process by decomposing the planning graph into sequential reasoning paths, which can be generated by LLMs via next token prediction. Given the lack of ground-truth planning graphs for training, we prompt LLMs to synthesize these ground-truth planning graphs due to their superior reasoning capability. The prompt for generating the ground-truth planning graph is: Prompt 1: Planning Graph Generation System Message: You are planning graph finder agent. Your role is to: 1. Identify the underlying **meta-path** from given question, which consists of the **entity types** at each reasoning step. 2. Extract the **content restriction** for each **entity type** based on the question. If there is no restriction for an entity type, leave its value empty. You will be provided with predefined **Entity Type List**. Only use the entity types from this list when constructing the meta-path and restrictions. Your response must be concise and strictly adhere to the specified **output format**. Entity Type List: Provide the entity type list. Demonstrations: Examples for in-context learning. Output Fromat: Metapath: \"\", Restriction: {}. Trajectory Collection: As mentioned in Section 3.3, our reranker reorders the intermediate retrieved candidates based on their trajectory. To achieve this, we collect three key features: Textual Fingerprint (TF), Structural Fingerprint (SF), and Traversal Identifier (TI). Textual Fingerprint (TF): We record the BM25 similarity scores between the query and the traversed nodes computed. Since empirical observations indicate that the length of reasoning paths is typically less than three, we fix the textual fingerprint to the length of three by padding additional 0 similarity scores for those reasoning paths whose length is less than three, allowing for batch-wise training. Additionally, we append the initial semantic ranking score of the candidate computed using cosine similarity coupled with Ada-002 embedding to the end of three BM25-based similarity scores to complement the lexical perspective. This vector is then passed through linear layer to be transformed into an embedding of size 256. Note that this initial ranking score is also used to select the intermediate retrieved candidates used for reranking. Structural Fingerprint (SF): We concatenate the categories of all nodes in the corresponding reasoning path as text sequence. If the reasoning path is shorter than three nodes, we prepend the sequence with \"padding\" tokens to ensure fixed length. The structural fingerprint is then processed using transformer model, which converts the sequence into an embedding of size 768, followed by linear layer that projects it down to size 256. Traversal Identifier (TI): We track whether each node is retrieved via textual matching or structural traversal and encoding them with distinct values by initializing learnable embedding matrix mapping each traversal identifier encoding to 3x256-dimensional embedding vector. After obtaining all above three trajectory features, we concatenate their obtained vectors into unified vector (256 + 256 + 256x3 = 1280) and apply two fully connected layers to transform the combined representation into reranking score. This score determines the final ranking."
        },
        {
            "title": "C Additional Results",
            "content": "C.1 Query Pattern Analysis Figure 5 illustrates the analysis of query patterns in the MAG dataset. With richer relational information, queries in this dataset form wider variety of patterns, including longer and more diverse structures. Similar to the Amazon dataset, we observe general trend where the performance of MoR declines as the query count decreases across different patterns. Beyond this overall trend, certain query patterns in the MAG dataset stand out, such as \"P P\" (Product-to-Author-to-Product) and 12 Moens, 2011), such as indexed texts and knowledge graphs, each requires retrieval method tailored to its unique representation. Textual retriever retrieves knowledge based on its similarity to the lexigiven query and can be categorized into: cal methods (e.g., TF-IDF and BM25 (Robertson et al., 2009)) and semantic methods (e.g., DPR and Contriever (Karpukhin et al., 2020; Izacard et al., 2022)). Despite their broad applicability, the predefined linguistic rules and embedding-based semantics may struggle to capture the structural knowledge stored in graph-structured knowledge bases such as knowledge graphs and text-rich networks. To address this challenge, structural retrieval has been proposed by using graph analysis techniques (e.g., graph traversal (Wang et al., 2024; Jiang et al., 2023; Zhang et al.; Edge et al., 2024)) and graph machine learning models (e.g., graph neural networks (Yasunaga et al., 2021; Mavromatis and Karypis, 2024)). Early methods extract local subgraphs of seeding nodes (Yasunaga et al., 2021; Taunk et al., 2023) or pre-define paths approaching answers (e.g., shortest paths (Luo et al.; Delile et al., 2024)). To avoid exponentially expanding neighbors in the local subgraphs and break the rigid logic routined by pre-defined paths, recent advancements integrated LLMs to dynamically adjust graph traversal (Sun et al., 2023; Wang et al., 2024; Jin et al., 2024a). While promising, frequently invoking LLMs introduces prohibitive resource overhead. Despite the above advancements in both textual and structural retrieval, they are often applied independently and fail to mutually reinforce each other. This motivates the recent research trend of developing hybrid retrieval, which is reviewed next. D.3 Hybrid Retrieval Recently, several works have explored hybrid knowledge retrieval from TG-KBs. One approach (Xia et al., 2024; Li et al., 2024) aggregate documents from neighboring nodes, with Xia et al. (2024) applying relational filtering to remove irrelevant neighbors and Li et al. (2024) weighting neighbors based on field importance. Another approach (Lee et al., 2024) uses LLMs to choose either structural or textual retrieval. In contrast, our proposed MoR fully leverages the graph structure and rich texts by integrating textual matching and graph traversal into unified framework, enabling more seamless and interpretable interaction between structural and textual knowledge Figure 5: Imbalance number of queries and performance of different retrievers across different logic patterns. \"P P\" (Paper-to-Paper). Despite their relatively high occurrence, MoR still performs worse on these patterns. This is similar to low performance on the \"Product Product\" pattern observed in the Amazon dataset, where repeated entity types appear within single query. Such repetition causes the textual retriever to shift focus from the target to the repeated entities, leading to lower performance."
        },
        {
            "title": "D Comprehensive Related Work",
            "content": "D.1 Retrieval-augmented Generation (RAG) With the unprecedented success of recent LLMs in approaching human-level intelligence, retrieving relevant knowledge to support downstream generation has become increasingly crucial. Retrievalaugmented generation enhances generative tasks by integrating relevant information from external knowledge sources (He et al., 2025; Gao et al., 2023c; Han et al., 2024) and has been widely adopted to improve question-answering (Liu et al., 2023). In the context of LLMs, RAG has been utilized to mitigate hallucinations (Yao et al., 2023), enhance interpretability (Gao et al., 2023a), and enable dynamic knowledge updates (Wang et al., 2024). This work leverages RAG to retrieve supporting entities from TG-KBs, providing contextual grounding for answer generation. Depending on the type of knowledge retrieved, existing retrievers can be classified into structural and textual retrieval approaches, which are reviewed next. D.2 Textual and Structural Retrieval Since real-world knowledge is commonly stored in both textual and structural formats (Kolomiyets and"
        }
    ],
    "affiliations": [
        "Adobe Research",
        "Michigan State University",
        "Pacific Northwest National Laboratory",
        "University of Oregon"
    ]
}