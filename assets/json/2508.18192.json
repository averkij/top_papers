{
    "paper_title": "Unraveling the cognitive patterns of Large Language Models through module communities",
    "authors": [
        "Kushal Raj Bhandari",
        "Pin-Yu Chen",
        "Jianxi Gao"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) have reshaped our world with significant advancements in science, engineering, and society through applications ranging from scientific discoveries and medical diagnostics to Chatbots. Despite their ubiquity and utility, the underlying mechanisms of LLM remain concealed within billions of parameters and complex structures, making their inner architecture and cognitive processes challenging to comprehend. We address this gap by adopting approaches to understanding emerging cognition in biology and developing a network-based framework that links cognitive skills, LLM architectures, and datasets, ushering in a paradigm shift in foundation model analysis. The skill distribution in the module communities demonstrates that while LLMs do not strictly parallel the focalized specialization observed in specific biological systems, they exhibit unique communities of modules whose emergent skill patterns partially mirror the distributed yet interconnected cognitive organization seen in avian and small mammalian brains. Our numerical results highlight a key divergence from biological systems to LLMs, where skill acquisition benefits substantially from dynamic, cross-regional interactions and neural plasticity. By integrating cognitive science principles with machine learning, our framework provides new insights into LLM interpretability and suggests that effective fine-tuning strategies should leverage distributed learning dynamics rather than rigid modular interventions."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 2 ] . [ 1 2 9 1 8 1 . 8 0 5 2 : r Kushal Raj Bhandari Department of Computer Science Rensselaer Polytechnic Institute Troy, NY, USA bhandk@rpi.edu Pin-Yu Chen IBM Research Yorktown Heights, NY, USA pin-yu.chen@ibm.com Jianxi Gao Department of Computer Science Rensselaer Polytechnic Institute Troy, NY, USA gaoj8@rpi.edu"
        },
        {
            "title": "ABSTRACT",
            "content": "Large Language Models (LLMs) have reshaped our world with significant advancements in science, engineering, and society through applications ranging from scientific discoveries and medical diagnostics to Chatbots. Despite their ubiquity and utility, the underlying mechanisms of LLM remain concealed within billions of parameters and complex structures, making their inner architecture and cognitive processes challenging to comprehend. We address this gap by adopting approaches to understanding emerging cognition in biology and developing network-based framework that links cognitive skills, LLM architectures, and datasets, ushering in paradigm shift in foundation model analysis. The skill distribution in the module communities demonstrates that while LLMs do not strictly parallel the focalized specialization observed in specific biological systems, they exhibit unique communities of modules whose emergent skill patterns partially mirror the distributed yet interconnected cognitive organization seen in avian and small mammalian brains. Our numerical results highlight key divergence from biological systems to LLMs, where skill acquisition benefits substantially from dynamic, cross-regional interactions and neural plasticity. By integrating cognitive science principles with machine learning, our framework provides new insights into LLM interpretability and suggests that effective fine-tuning strategies should leverage distributed learning dynamics rather than rigid modular interventions. Keywords Large Language Models Network Community Structure Cognitive Skills AI interpretability"
        },
        {
            "title": "Introduction",
            "content": "The widespread adoption of LLMs is testament to their impressive capabilities in generating coherent and contextaware text [1], which has led to their use in everything from customer service chatbots[2] and automated content creation[3] to advanced data analysis[4] and even scientific research [5]. While the practical benefits of LLMs are recognized, significant gap remains in our understanding of what drives their impressive performance. This imbalance, where the focus is predominantly on leveraging their utility rather than studying their working mechanism, has spurred many questions about the underlying principles that drive their success[5]. Bridging the gap between the widespread use of LLMs and the fundamental principles that drive their performance is critical challenge. Much like the complexities of the human brain, these systems operate as black boxes, making it difficult to uncover the mechanisms behind their decision-making. The complexities of understanding LLMs involve exploring the intriguing parallels and distinctions between artificial neural architectures and the human brain (Figure 1a), revealing captivating patterns of resemblance [6, 7] despite their inherent differences [8]. Neuroscientists have long used brain mapping to identify discrete regions with synchronous activity linked to cognitive processes, memory, language, and motor control[9, 10]. We illustrate the distribution of cognitive skills (i.e., cognitive process memory, executive function, language communication, and social cognition) alongside their associated datasets (Figure 1b), highlighting the diversity of tasks and the strong alignment between dataset categories and core cognitive functions. Moreover, network science approaches have substantially enriched neuroscience by illuminating how large-scale brain networks exhibit modular structures, small-world properties, and dynamic connectivity patterns [11, 12]. Building on such insights, recent studies on LLMs have adopted techniques, employing systematic benchmarks like CogBench[13], psychological tests such as cognitive reflection and semantic illusions[14], and even neuroimaging comparisons to evaluate their cognitive capabilities[15]. Yet, many of these efforts remain unsupported by cohesive framework rooted in cognitive science and neuroscience, highlighting the importance of systematically mapping the alignment between LLMs and abstract cognitive skills. Expanding upon this growing interest, recent studies have explored how cognitive skills are encoded and localized within these models. For instance, aligning datasets with linguistic and cognitive skills facilitates targeted training and evaluation of LLM capabilities [16], though such approaches often overlook the role of neural mechanisms that generate these skills. Efforts to map specific tasks onto localized regions of fine-tuned LLMs architecture [17] reveal the emergence of task-specialized modules, yet they fall short of explaining the structural neural dynamics that support this localization. Similarly, linking in-context learning with cognitive skills has offered insights into the meta-cognitive capabilities of LLMs[18], but these studies primarily focused on behavioral outputs and self-assessment metrics rather than deeper structural explanations. Despite such advancements in understanding cognition in LLMs, prior works lack exploration of inter-skill relationships, dynamic adaptability, cross-domain generalizability, and detailed interpretability of underlying mechanisms. Figure 1: Connecting cognitive skills, datasets, and LLMs to form multipartite network. (a) The schematic figure illustrates the relationships between cognitive skills, datasets, and LLM weight parameters as multipartite network, drawing an analogy to the interconnected organization of the human brain. (b) The bar plots illustrate how different cognitive functions are categorized by the frequency of their associated skills and how often they appear across multiple-choice question datasets. Figure 2: Multipartite Network of Skills, Dataset and Modules of Llama2 model. The network depicts modules (squares), datasets (triangles), and skills (circles) as nodes. Edges are weighted by the normalized values derived from the bipartite relationships between skills and datasets and between datasets and modules, reflecting the structural importance and interactions within the multiple types of nodes. The projection network simplifies the multipartite structure by collapsing intermediary nodes(datasets) to focus on the direct interactions between skills and modules using Block-based pruning strategy. This projection highlights key dependencies and structural patterns within the model, offering insights into which modules are most influential for specific skills."
        },
        {
            "title": "2 Emerging community structures in skill and module networks",
            "content": "The architecture of emerging LLMs reflects the self-organization of neural assemblies [19], where local activity and interactions drive the emergence of specific, stereotyped connectivity patterns, such as modularity. Constructing the overall network topology becomes essential. It involves integrating the dataset that captures domain knowledge, the architectural modules of LLMs, and the emerging cognitive functions. The methodology for building these networks is detailed in the Supplementary Information (SI 1 and SI 2). Network visualization reveals the structural and functional relationships among skills, datasets, and modules, and illustrates the process used to generate the Skills and Modules projection networks, as shown in Figure 2. These networks exhibit distinct connectivity patterns that can be leveraged to study the localization of skills within LLM modules, an essential step toward understanding the emergence of intelligence. Growing observations demonstrate that neural networks often exhibit meaningful community organization. Therefore, we leverage Louvain community detection techniques[23] to uncover latent interdependencies and organizational 3 patterns among cognitive skills (Figure 3a) and LLM modules (Figure 3b). The resulting community structures reveal hierarchical and modular architecture within LLMs, shedding light on how localized and distributed processing underpins their cognitive capabilities. This insight carries significant implications for model design, interpretability, and optimization. Surprisingly, while groups of LLM modules are tightly interconnected through shared skill distributions, there is no precise alignment between the predefined cognitive functions and the communities identified in the skills network (Figure 3c). Chi-square test comparing the distribution of skills across communities is illustrated in Figure 3d, indicating that skill allocation is statistically independent of the predefined cognitive categories. Next, we quantify the contribution of specific model components to performance across datasets under different pruning strategies and task distributions [17]. We use Adjusted Rand Index (ARI) scores to evaluate the normalized agreement between clusters by assessing all pairs of elements (see SI Section 4). Figure 3(e) shows the ARI scores for communities of skills and cognitive functions across various sparsity levels used in pruning the model [21]. Despite performance degradation with increased pruning or across different Llama2 model variants, ARI scores do not improve under any pruning strategy. This contrasts with the human brain, where specific skill types tend to localize within distinct cognitive regions [11, 23, 12, 24], suggesting that LLMs exhibit different structural-functional organization. Across all pruning strategies, sparsity levels, and Llama2 model variants, p-values remained consistently and significantly low (<0.05), indicating that each community possesses distinct skill distribution (Figure 3f). This implies that although specific skill types are not localized according to cognitive function the module localization still reflects unique combinations of skills. Figure 3: Community structure comparison between skills and modules networks. (a) The skills projection network with nodes (skills) grouped based on the Louvain community detection algorithm, and colored with the cognitive-function label taken from Table SI1, allowing direct visual comparison between detected communities and domain ground truth. (b) The Modules projection network, where each node (module) is assigned community label based on Louvain partitioning applied at multiple resolutions, subsequently consolidated using average-linkage hierarchical clustering.(c) Color legend of cognitive function for node color in skills network in (a). (d) Schematic figure to represent the frequency of cognitive skills within each community for the Modules network(b). (e) Adjusted Rand Score (ARS) between the Louvain communities in the Skills network and the cognitive-function labels, plotted against different sparsity ratio for pruning and three base models (Llama, Llama-Chat, and Vicuna). (f) The chi-squared T-test statistically assessed the distinctiveness of skill distributions within each community of Modules networks, with their p-value for those three different models for different sparsity ratios. 4 Figure 4: Spectral property and influence of modules within each community of Modules Network.(a-c) The frequency distributions of eigenvalues reveal the spectral characteristics of the network, where the presence of distinct eigenvalue gaps signifies well-defined community structures.(d-f) Participation coefficients and Z-scores quantify the roles of modules within and across communities, where higher coefficients highlight bridge modules and Z-scores identify influential or peripheral roles."
        },
        {
            "title": "3 Modular localization characterizes the structure and function of module network",
            "content": "Studies in neuroscience have shown that the brain is both modular and functionally specialized. Different regions form tightly connected groups (i.e., modules) that are linked to specific tasks, such as vision, language, memory, and attention [9, 25]. This architecture, observed across species from C. elegans to primates, supports the brain process information efficiently within each module while still communicating across the whole network [26, 27, 28]. Inspired by this, we examine how skills are distributed across different parts of LLM to better understand their specialized regions and global connectivity of modules through three network metrics of the Modules network: (1) spectral property of PM for understanding the global structural connectivity and robustness; (2) the participation coefficient that quantifies the extent to which individual modules bridge across community boundaries [26]; and (3) the Z-score for the local connectivity [26]. Figures 4(ac) show the Eigenvalue distribution of the Llama, Llama Chat, and Vicuna models, respectively. All three LLMs consistently show that the modules within communities interact extensively with other communities, indicating that the modules within these networks are tightly knit within communities but loosely connected across different communities. The participation coefficient quantifies the extent of cross-community interactions, while the Z-score captures the relative importance of nodes within their respective communities. Together, these measures provide more detailed understanding of the roles individual modules play in the community structure of LLM architecture, as shown in Figures 4(df). The broader distribution of participation coefficient values reflects diverse and well-integrated community dynamics, consistent with the spectral gap, and suggests network topology that facilitates robust intercommunity communication. This pattern is consistent across all three models and is further supported by extended analyses presented in the Supplementary Information(see SI Section 5). There, we explore the effects of channel-versus block-level pruning, provide theoretical justification and robustness checks for the observed network properties, and present additional simulations and visualizations that reinforce these findings. The brains modular architecture balances functional specialization and global integration, supporting complex yet stable cognitive functions[9]. Our three metrics illustrate comparable patterns of modular localization in LLMs, indicating similar organizational principles emerging across biological and artificial systems [30]. These findings carry 5 significant implications for both fields. In AI, they highlight the potential for designing more efficient and adaptable models by leveraging modularity, mimicking how the brain organizes specialized functions while maintaining flexible interconnectivity. For neuroscience, understanding the extent to which artificial systems replicate biological modularity could inform the study of brain function and network organization, offering insights into how cognitive processes emerge from modular networks. Figure 5: Comparison of accuracy and magnitude of weight change across fine-tuned LLMs using different cognitive skilled-based finetuning. (a-d) Schematic representation of community-specific fine-tuning to assess the influence of targeted adaptation. (a) Community targets community-specific modules aligned with particular cognitive skills, reflecting focused, skill-driven approach; (b) Random uses random module subsets matched in size to the community-specific selections, serving as baseline to isolate the effects of structural organization versus random variation; (c) All represents fine-tuning across all modules, representing broad, undifferentiated adaptation strategy; (d) Without Finetuning depicts models without any fine-tuning, reflecting the unaltered original state of the model. (e) Average L2 weight difference for models (Llama, Llama-Chat, Vicuna) across community-aligned datasets using block-pruning strategy. Each bar represents different fine-tuning condition. (f) Accuracy for the same fine-tuning configurations as (e), capturing the models performance by fine-tuning on community-based datasets using blockbased pruning strategy."
        },
        {
            "title": "4 Reveal the functional specialization through cognitive Skill-Based Fine-Tuning",
            "content": "To rigorously validate and deepen the impact of our analysis, we must extend our focus beyond network topology and cognitive skills, examining how module communities inform fine-tuning strategies aimed at emulating neural behaviors. In biological systems, we observe three distinct neural architectures: (1) the strong-localization architecture, characterized by isolated subgraphs executing autonomous tasks like octopus [31, 32]; (2) the small-world architecture, which includes few interconnectivity between communities as seen in the human brain [27, 30]; and (3) the weaklocalization architecture, with extensive interconnectivity between communities, typical of avian and small mammalian brains [33]. According to our theoretical analysis and biological observations, key question emerges: How can insights from the functional specialization observed in biological brains help us better understand how cognitive-skill-specific network communities in LLMs promote targeted learningthrough deeper analysis of the relationship between model performance and their modular structures? To answer this question and validate the impact of the module communities on LLM performance, we fine-tune the models under four distinct configurations, shown in Figure 5(a-d). Learning strengthens synaptic connections via Hebbian learning[34] and long-term potentiation[35], improving neural communication and supporting memory and skill acquisition. Similarly, weight changes after fine-tuning reveal that community-based fine-tuning induces the most substantial adjustments, whereas all-module and random fine-tuning exhibit comparable but lower sensitivity (Figure 5e). However, fine-tuning across all modules yields the highest overall accuracy compared among all configurations (Figure 5f), indicating distinguishment of distributed knowledge representation in LLMs from the highly localized organization observed in the human brain. However, it aligns with prior findings that task-relevant knowledge in LLMs is redundantly encoded across multiple attention heads in Transformer models [36, 37]. The discrepancy between the extent of structural modifications and the resulting accuracy gains suggests that, although targeting the modules 6 associated with specific cognitive skills induces pronounced parameter changes, these changes do not confer clear performance advantage. While learning-induced neural plasticity in the human brain is task-specific and efficiencydriven minimizing disruption to unrelated cognitive functions [38] community-based fine-tuning in LLMs does not exhibit explicit modular specialization. This result aligns with characteristics of weak-localization architectures, reflecting the compensatory plasticity and cross-regional adaptation observed in large-scale brain networks [10]. Although pre-trained LLMs encode cognitive skills within module communities, targeted interventions do not result in strict functional specialization, prompting reevaluation of the relative advantages of the three architectural paradigms. In strong-localization architectures like the octopus nervous system, subgraphs function independently, enabling localized learning but limiting global intelligence due to the lack of inter-module support. Small-world architectures, exemplified by the human brain, support task-specific, efficiency-driven learning while minimizing interference with unrelated cognitive functions. Weak-localization architectures, as seen in avian and small mammalian brains, feature specialized neural modules that process distinct cognitive functions but rely heavily on dynamic, cross-regional integration for intelligent behavior [39, 25]. These biological insights align with our observations in LLMs, suggesting that cognitive capabilities do not necessarily benefit from strictly localized fine-tuning. Instead, in weak-localization-like systems, functionality arises from distributed yet interdependent interactions among modular components, underscoring the importance of network-wide coordination for robust cognitive performance."
        },
        {
            "title": "5 Discussion",
            "content": "This work lays the groundwork for new direction in understanding LLMs not merely explaining their outputs but uncovering the mechanisms by which they form, organize, and express cognitive functions. Our findings illuminate the interplay between cognitive skills, datasets, and model modules, offering novel perspective grounded in insights from network theory, neuroscience, and cognitive science. By constructing and analyzing multipartite network, we mapped skills and datasets onto specific model components to examine their alignment with cognitive function organization observed in biological systems. We found that skill clusters consistently co-occur and activate similar modules pattern also seen in human and animal brains. Community-based fine-tuning induces the most substantial weight changes, mirroring the strengthening of synaptic connections during learning in biological systems. Although the module architecture of LLMs exhibits skill-associated community structure, fine-tuning skill-relevant modules does not yield clear accuracy advantage over randomly selected subsets of equal size. Consequently, cognitive skills in LLMs are more rigidly localized within specialized cortical regions, exhibiting distinct localization of skill-specific distribution of modules. In contrast to the human brain where localized neural plasticity supports efficient, task-specific learning LLMs adapt broadly across their parameter space, even when fine-tuning is restricted to specific module clusters. These findings underscore the need to move beyond skill-module mappings and instead explore network-wide dependencies, inter-layer connectivity, and adaptive optimization strategies that better leverage the models distributed learning dynamics. While this study provides valuable insights into the distribution of cognitive skills within LLMs through network analysis, several avenues remain for further exploration. The abstract cognitive skills defined here could be further refined to capture more nuanced spectrum of human cognition, potentially deepening the analysis of skillmodule associations. Although computational constraints influenced model selection, the scalability of the proposed methodology offers strong foundation for future studies involving larger architectures and datasets. The comparable performance between randomly selected modules and community-specific fine-tuning reveals complex interplay between module specialization and task performance. This finding underscores the inherent flexibility and adaptability of LLMs, pointing to promising direction for investigating the subtleties of modular interactions. Beyond the goals of explainable AI, our study moves toward deeper functional understanding of how LLMs internalize, organize, and give rise to cognitive abilities, uncovering fundamental learning principles and architecture-associated intelligence with far-reaching implications. This has significant implications for interpretability and fine-tuning strategies: rather than rigidly selecting modules based on skill mappings, future work should explore network-wide dependencies, inter-layer connectivity, and adaptive optimization strategies that harness the models distributed learning potential more effectively."
        },
        {
            "title": "6 Network Formulation",
            "content": "While cognitive science and neuroscience have long benefited from clearly defined network nodes and edges to uncover the brains modular organization, where distinct regions support specific cognitive functions [11, 23, 12], establishing 7 an analogous structural topology for LLMs remains significant challenge. In particular, mapping predefined abstract cognitive skills onto discrete modules within an LLMs architecture, such as attention heads, feedforward blocks, and layer-wise substructures, introduces novel frontier that challenges conventional approaches to understanding their internal dynamics. 6.1 Skills-Dataset Network (BSD) To explore such premise, we employ multi-layered network analysis to study the pattern of interconnected LLM modules based on cognitive skills. This analysis examines the complex interactions between cognitive skills, datasets, and modules, providing detailed perspective on the functional organization within LLMs. As illustrated in Figure 1a., we map different cognitive skills si S, previously studied in the cognitive science domain (Table S1), to individual multiple-choice problem datasets. Formally, let si denote set of abstract cognitive skills and Dj collection of multiple-choice question datasets. Each question in dataset Dj is annotated with binary skill vector over indicating which skills are required. We define the matrix BSD Rnm such that:"
        },
        {
            "title": "BSD",
            "content": "ij = rj (cid:88) k=1 q(x) , (1) where q(x) which skill si is required to solve questions within dataset Dj. = 1 if skill si is required to solve question Qx, and 0 otherwise. Thus, BSD ij quantifies the frequency with This mapping results in Skill Dataset bipartite network, where cognitive skills, sampled using ChatGPT 3.5, are linked to specific datasets, with the connections weighted by the count of matched skills (detailed in SI 1). The empirical results in Figure 1b show that memory and executive-related skills, such as reasoning, working memory, problem-solving, and planning, are well-represented in multiple-choice problems. This highlights the strong alignment of datasets with cognitive functions that lend themselves to structured evaluation. We also observe notable frequencies in other cognitive domains, such as language and communication, and certain aspects of social cognition, reflecting broader yet still uneven coverage. Importantly, the bar plot on the right of figure 1b underscores the diversity within these datasets, showcasing how they are not uniformly distributed but instead target specific clusters of cognitive functions. This reveals an opportunity to leverage these datasets for analyzing models across wide range of cognitive abilities. Didolkar et al. provided similar analysis on utilizing another pre-trained model to generate different abstract cognitive skills for mathematical datasets. Our approach provides more general skills and dataset mapping using existing cognitive science domain literature [18]. 6.2 Dataset-Modules Network (BDM) Subsequently, we construct the Datasets vs. Modules network using LLM-Pruner [17], where the modules, defined as subsets of weights, Mk W, {1, 2, . . . , M}, representing structural units of the model (e.g., layers or blocks), are analyzed to assess the impact of datasets on these modules (detailed in SI 2). We quantify the impact of individual multiple-choice question datasets, Dj D, on the individual weight modules of LLM, Mk, using two parameters: change in accuracy after pruning the model to the dataset and fraction of weights pruned within each module. That is, the importance of modules, BDM, is defined as, jk = (cid:0)1 acc(Dj)(cid:1) Mk Wessential BDM Mk (2) where acc(Dj) denotes the change in accuracy caused by pruning the model with dataset Dj, and Wessential refers to the set of essential weights identified as critical after pruning the model. The integration of these two bipartite networks yields Skills and Modules network, illustrating the relationship between skills and modules and highlighting which modules are influenced by which specific skills. Utilizing equation 1 and 2, we define projection bipartite network BSM, to project relationship between individual skill Sk and individual modules Mk, BSM ik = (cid:88) Dj BSD ij BDM jk (3) Further analysis projects these into Modules and Skills networks, revealing the inter-dependencies and collaborative dynamics between modules and the co-dependencies among cognitive skills within the LLM. From equation 3, we 8 describe the relationship between two skills(si1 and si2) as PS i1i2 , and two modules (Mk1 , Mk2 ) as PM k1k2 PS i1i2 = PM k1k2 = (cid:88) S (cid:88) i"
        },
        {
            "title": "BSM",
            "content": "i1k BSM i2k. where, PS Rnn BSM ik1 BSM ik2 . where, PM Rkk. . (4) Expanding on these definitions, the inter-dependencies between skills and modules are quantitatively analyzed to uncover the underlying patterns of association and specialization within the modules. The function PS captures the degree of overlap between skills, offering insights into how cognitive skills rely on shared or distinct modules. Similarly, PM highlights the co-activation of modules, revealing the extent to which modules work in sync to support various skills. These relationships quantify metric to identify clusters of skills and modules that exhibit tight integration, shedding light on the modular architecture of LLMs and their alignment with cognitive frameworks. Code and Data Availability Data files and the Python script have been deposited in https://github.com/KBhandari11/LLMNeuron The finetuned weights of all the models have been uploaded in https://huggingface.co/KBhandari11/collections."
        },
        {
            "title": "Acknowledgment",
            "content": "We acknowledge the support of the US National Science Foundation under Grant No. 2047488 and by the RPI-IBM Future of Computing Research Collaboration(FCRC)."
        },
        {
            "title": "References",
            "content": "[1] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS 20, pages 18771901, Red Hook, NY, USA, December 2020. Curran Associates Inc. [2] Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston. Recipes for Building an Open-Domain Chatbot. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 300325. Association for Computational Linguistics, 2021. [3] Xudong Hong, Asad Sayeed, Khushboo Mehra, Vera Demberg, and Bernt Schiele. Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences. Transactions of the Association for Computational Linguistics, 11:565581, 2023. [4] Bosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken Chia, Boyang Li, Shafiq Joty, and Lidong Bing. Is GPT-3 Good Data Annotator? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1117311195. Association for Computational Linguistics, 2023. [5] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li FeiFei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel Orr, 9 Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, and Percy Liang. On the opportunities and risks of foundation models, 2022. [6] Martin Schrimpf, Idan Asher Blank, Greta Tuckute, Carina Kauf, Eghbal A. Hosseini, Nancy Kanwisher, Joshua B. Tenenbaum, and Evelina Fedorenko. The neural architecture of language: Integrative modeling converges on predictive processing. Proceedings of the National Academy of Sciences, 118(45):e2105646118, November 2021. [7] Khai Loong Aw, Syrielle Montariol, Badr AlKhamissi, Martin Schrimpf, and Antoine Bosselut. Instruction-tuning aligns LLMs to the human brain. In First Conference on Language Modeling, 2024. [8] Yuchen Zhou, Emmy Liu, Graham Neubig, Michael J. Tarr, and Leila Wehbe. Divergences between language models and human brains. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. [9] Matthew F. Glasser, Timothy S. Coalson, Emma C. Robinson, Carl D. Hacker, John Harwell, Essa Yacoub, Kamil Ugurbil, Jesper Andersson, Christian F. Beckmann, Mark Jenkinson, Stephen M. Smith, and David C. Van Essen. multi-modal parcellation of human cerebral cortex. Nature, 536(7615):171178, August 2016. [10] James M. Shine, Michael Breakspear, Peter T. Bell, Kaylena A. Ehgoetz Martens, Richard Shine, Oluwasanmi Koyejo, Olaf Sporns, and Russell A. Poldrack. Human cognition involves the dynamic integration of neural activity and neuromodulatory systems. Nature Neuroscience, 22(2):289296, February 2019. [11] Hae-Jeong Park and Karl Friston. Structural and Functional Brain Networks: From Connections to Cognition. Science, 342(6158):1238411, November 2013. [12] Caio Seguin, Olaf Sporns, and Andrew Zalesky. Brain network communication: Concepts, models and applications. Nature Reviews Neuroscience, 24(9):557574, September 2023. [13] Julian Coda-Forno, Marcel Binz, Jane X. Wang, and Eric Schulz. CogBench: large language model walks into psychology lab. In Proceedings of the 41st International Conference on Machine Learning, volume 235 of ICML24, pages 90769108, Vienna, Austria, July 2024. JMLR.org. [14] Thilo Hagendorff, Sarah Fabi, and Michal Kosinski. Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT. Nature Computational Science, 3(10):833838, October 2023. [15] Charlotte Caucheteux and Jean-Rémi King. Brains and algorithms partially converge in natural language processing. Communications Biology, 5(1):110, February 2022. [16] Mayee Chen, Nicholas Roberts, Kush Bhatia, Jue WANG, Ce Zhang, Frederic Sala, and Christopher Re. Skill-it! data-driven skills framework for understanding and training language models. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. [17] Abhishek Panigrahi, Nikunj Saunshi, Haoyu Zhao, and Sanjeev Arora. Task-specific skill localization in fine-tuned language models. In Proceedings of the 40th International Conference on Machine Learning, ICML23. JMLR.org, 2023. [18] Aniket Rajiv Didolkar, Anirudh Goyal, Nan Rosemary Ke, Siyuan Guo, Michal Valko, Timothy Lillicrap, Danilo Jimenez Rezende, Yoshua Bengio, Michael Curtis Mozer, and Sanjeev Arora. Metacognitive capabilities of LLMs: An exploration in mathematical problem solving. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. [19] Wolf Singer, Andreas K. Engel, Andreas K. Kreiter, Matthias H. J. Munk, Sergio Neuenschwander, and Pieter R. Roelfsema. Neuronal assemblies: Necessity, signature and detectability. Trends in Cognitive Sciences, 1(7):252 261, October 1997. [20] Vincent Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, October 2008. [21] Xinyin Ma, Gongfan Fang, and Xinchao Wang. LLM-pruner: On the structural pruning of large language models. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. [22] José E. Chacón and Ana I. Rastrojo. Minimum adjusted Rand index for two clusterings of given size. Advances in Data Analysis and Classification, 17(1):125133, 2023. [23] Nessa V. Bryce, John C. Flournoy, João F. Guassi Moreira, Maya L. Rosen, Kelly A. Sambook, Patrick Mair, and Katie A. McLaughlin. Brain parcellation selection: An overlooked decision point with meaningful effects on individual differences in resting-state functional connectivity. NeuroImage, 243:118487, November 2021. [24] Ed Bullmore and Olaf Sporns. Complex brain networks: Graph theoretical analysis of structural and functional systems. Nature Reviews Neuroscience, 10(3):186198, March 2009. [25] Nathan J. Emery and Nicola S. Clayton. The mentality of crows: Convergent evolution of intelligence in corvids and apes. Science, 306(5703):19031907, 2004. [26] Hilgetag, Burns, ONeill, Scannell, and Young. Anatomical connectivity defines the organization of clusters of cortical areas in the macaque monkey and the cat. Philosophical Transactions of the Royal Society B: Biological Sciences, 355(1393):91110, 2000. [27] Lazaros K. Gallos, Hernán A. Makse, and Mariano Sigman. small world of weak ties provides optimal global integration of self-similar modules in functional brain networks. Proceedings of the National Academy of Sciences, 109(8):28252830, February 2012. [28] Gang Yan, Petra E. Vértes, Emma K. Towlson, Yee Lian Chew, Denise S. Walker, William R. Schafer, and AlbertLászló Barabási. Network control principles predict neuron function in the Caenorhabditis elegans connectome. Nature, 550(7677):519523, October 2017. [29] Jonathan Power, Bradley Schlaggar, Christina Lessov-Schlaggar, and Steven Petersen. Evidence for hubs in human functional brain networks. Neuron, 79(4):10.1016/j.neuron.2013.07.035, August 2013. [30] Olaf Sporns and Richard F. Betzel. Modular brain networks. Annual Review of Psychology, 67(1):613640, January 2016. [31] Frank W. Grasso. The octopus with two brains: How are distributed and central representations integrated in the octopus central nervous system? In Anne-Sophie Darmaillacq, Ludovic Dickel, and Jennifer Mather, editors, Cephalopod Cognition, pages 94122. Cambridge University Press, 1 edition, July 2014. [32] G. O. Mackie. Special Invertebrate: The Anatomy of the Nervous System of Octopus. Science, 177(4055):1183 1183, September 1972. [33] Murray Shanahan. The brains connective core and its role in animal cognition. Philosophical Transactions of the Royal Society B: Biological Sciences, 367(1603):27042714, October 2012. [34] Ralf Der and Georg Martius. Novel plasticity rule can explain the development of sensorimotor intelligence. Proceedings of the National Academy of Sciences, 112(45):E6224E6232, November 2015. [35] Trine Waage Rygvold, Christoffer Hatlestad-Hall, Torbjørn Elvsåshagen, Torgeir Moberget, and Stein Andersson. Long term potentiation-like neural plasticity and performance-based memory function. Neurobiology of Learning and Memory, 196:107696, December 2022. [36] Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D. Manning, and Quoc V. Le. BAM! Born-Again Multi-Task Networks for Natural Language Understanding. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 59315937, Florence, Italy, 2019. Association for Computational Linguistics. [37] Paul Michel, Omer Levy, and Graham Neubig. Are Sixteen Heads Really Better than One? In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. [38] Bogdan Draganski, Christian Gaser, Volker Busch, Gerhard Schuierer, Ulrich Bogdahn, and Arne May. Changes in grey matter induced by training. Nature, 427(6972):311312, January 2004. [39] Onur Güntürkün and Thomas Bugnyar. Cognition without Cortex. Trends in Cognitive Sciences, 20(4):291303, April 2016. 11 Supplementary Note 1: Skills vs Dataset Network Skills Skills can be conceptualized as abstract cognitive abilities that are essential for solving specific tasks. Formally, we define the set of these abstract skills, denoted by (S), as, = {s1, s2, s3, ..., sn}, (5) where is the total number of skills. Given the inherently abstract nature of si S, we empirically ground subset of predefined skills as identified in prior literature. In addition, we also categorize cognitive function as higher-order cognitive skills representing different lower-order cognitive skills (si) that have been characterized across various domains within cognitive science. Table 1 provides an overview of the subsets of abstract skills considered in this study. Dataset Prior research has been extensively studied to showcase how multiple-choice-based problems can be used to assess different lowerand higher-order cognitive skills [1, 2, 3, 4, 5]. Building on this foundation, we formally define framework to characterize the relationship between datasets of multiple-choice questions and the cognitive skills required to answer them. Let = {D1, D2, . . . , Dm} denote collection of multiple-choice question datasets, where = D. Each dataset Dj contains rj multiple-choice questions, denoted as Dj = {Q1, Q2, . . . , Qrj }. Each question Qx Dj is associated with binary skill requirement vector: Qx = (q1, q2, . . . , qn), (6) where = and is the set of all skills. The value of each component qi indicates whether skill si is necessary to solve question Qx: (cid:26)1 qi = 0 Otherwise. if skill si is required to answer Qx, We then define BSD ij as the frequency with which skill si appears across all questions in dataset Dj: BSD ij = rj (cid:88) x=1 q(x) , BSD Rnm where q(x) = is the number of datasets. denotes the ith component of the skill vector for question Qx, = is the number of distinct skills, and .0.1 Mapping Skills to Dataset To ensure comprehensive analysis, we select 174 multiple-choice problem datasets (m = 174) spanning diverse range of domains(MMLU[6], BigBench[7], MathQA[8], CommonsenseQA[9], ScienceQA[10], and TruthfulQA[11]). For each dataset, we select up to rmax questions (or all available questions if the dataset contains fewer than rmax) and utilize ChatGPT 3.5 to identify and sample the specific skills required to solve each individual question. That is, for dataset, Dj, number of question we select is (cid:26) (cid:27) rj = min Dj, rmax . (9) This approach enables systematic exploration of the cognitive skills associated with problem-solving across various domains. In this study, rmax = 100. Using this sampling approach, we construct the skills dataset bipartite network BSD ij , which represents the number of times different skills si are required for solving each dataset within the set of datasets D. This distribution captures the likelihood of each subset of skills being required for solving questions in given dataset. Figure 6, provides better visualization of how different skills are associated with different datasets. To validate the mapping, 8, defined using ChatGPT Prompt utilized for mapping to D: (7) (8) Supplementary Note 2: Dataset vs Modules Pruning To systematically study how different datasets Dj influence the internal modular structure of LLMs, we utilize pruning framework. Prior research has demonstrated that subset of parameters within neural network can achieve satisfactory performance [12, 13, 14, 15, 16]. Building on this insight, we prune redundant weight parameters to isolate the critical nodes for each dataset. This approach identifies the most activated parameters specific to each dataset. We replicate the pruning strategy across all 174 available datasets, resulting in 174 uniquely pruned models, each tailored to the specific skills required for its respective dataset. Given the large size of LLMs (approximately 7 billion parameters), handling individual parameters directly is computationally prohibitive. Therefore, we focus on individual modules within LLMs. Each module represents distinct functional component of the model. Our objective is to analyze how the connections between these modules influence the dependencies required for each skill. .0.2 LLM-Pruner LLMs possess intricate, modularized architectures, where computation is distributed across various weight matrices, including attention projections (e.g., attn.q_proj, attn.k_proj, attn.v_proj, attn.o_proj) and feedforward components (e.g., mlp.gate_proj, mlp.down_proj, mlp.up_proj). To systematically study the relative importance of these modules in dataset-specific settings, we leverage networked architecture representation of LLMs by constructing task-dependent dependency graph, following the LLM-Pruner framework [17]. Ma et al. abstracts LLMs as directed acyclic graph (DAG), where each node corresponds to an intermediate neuron activation, and each directed edge represents the application of learnable weight matrix within specific functional module of the model (e.g., attention projections or feedforward projections). The dependency graph is constructed by statically tracing the models forward computation, encoding how each activation depends on earlier transformations [17]. We utilize Taylor expansion-based importance score to rank the significance of each edge for given dataset. Specifically, the Taylor approximation of the loss change with respect to each edges removal is computed, providing an efficient estimate of the modules contribution to model performance. We apply both the construction of the dependency graph and the computation of pruning importance, following the original algorithm outlined in [17]. Each individual weight parameter is indexed by p, where identifies scalar element within the models collection of weight matrices The importance of each individual weight parameter wk is computed based on the estimated change in loss L(Dj) for dataset Dj D, approximated using Taylor series expansion: Iwp = L(Dj) = (cid:12) (cid:12) (cid:12) (cid:12) L(Dj) wp wp (cid:12) (cid:12) (wp)Hppwp + O(wp3) (cid:12) (cid:12) 1 2 , (10) where denotes the Hessian matrix with respect to wp. From equation 10, the importance of weight can be computed efficiently by approximating the Hessian matrix using the Fisher Information method: Iwp (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) L(Dj) wp wp 1 rj (cid:88) k=1 (cid:18) L(Qx) wp wp (cid:19)2 (cid:12) (cid:12) + O(wp3) (cid:12) (cid:12) (cid:12) , (11) where, Qx is an individual question within dataset Dj = {Qx}rj Using the computed importance scores Iwp for all parameters, pruning is performed on the dependency graph following two distinct strategies as defined by Ma et al. [17]: x=1, Dj D. Block-Based pruning strategy targets groups of neurons (blocks) associated with specific functional components, such as an entire attention head or an MLP module. Neurons within these blocks are pruned together, preserving functional coherence while reducing complexity. Channel-Based pruning strategy systematically removes channels across multiple layers, affecting neurons connected through vertical paths of the network. This method targets entire feature channels, cutting across layer boundaries, and simplifying inter-layer dependencies. Following pruning, we analyze the induced sparsity across specific architectural modules, including the attention projections and feedforward projections for each transformer layer. Sparsity for each module is computed as the fraction of weights wp within that module that have been pruned. 13 By quantifying the sparsity patterns per dataset Dj D, we capture how different cognitive skill demands associated with each dataset map onto the LLMs internal modular structure. This allows principled exploration of skills-specific modular specialization without modifying the original pruning algorithm of LLM-Pruner. .0.3 Importance of Module The importance of the module quantifies the impact of each dataset on individual modules based on the accuracy and sparsity of the modules before and after pruning. Let the individual weight of the LLM be defined as wp W. Then, modules are subset of weights, Mk W, where Mk represents all the structural unit (i.e., attn.q_proj, attn.k_proj, attn.v_proj, attn.o_proj, mlp.gate_proj, mlp.down_proj, and mlp.up_proj) within all layers of pretrained model. From equation 10, weights are filtered based on the sparsity ratio threshold: Wpruned = {wp WIwp < τ } (12) where τ is threshold based on the sparsity ratio, and L(Dj) is the loss function on dataset Dj D. Thereby, all the essential weights for particular dataset, Dj, with τ sparsity ratio are given by, Wessential = Wpruned. (13) The importance of module is determined by the fraction of its essential weights, those unaffected by pruning, scaled by the complement of the absolute change in accuracy resulting from pruning. This is mathematically expressed as: jk = (cid:0)1 acc(Dj)(cid:1) Mk Wessential BDM (14) Mk Here, Mk Wessential represents the count of essential weights in the module, while Mk is the total number of weights in the module. The term acc(Dj) measures the absolute change in the models accuracy caused by pruning. The complement, 1 acc(Dj), reflects how much accuracy is preserved, emphasizing the modules robustness. larger change in accuracy indicates more adverse effect on performance, reducing the importance of the module. Conversely, higher sparsity ratio suggests less pruning of the module, thereby increasing its importance. By leveraging the importance of modules, we construct bipartite network connecting each dataset to all the modules, capturing the relationship between tasks and model components. Figure 9a, demonstrates the negative correlation between the average BDM j,k and the magnitude of acc(Dj)the performance drop for the model after pruning. This empirically highlights that datasets with higher acc(Dj) (i.e., larger drops in accuracy) are associated with lower BDM j,k , indicating that modules influence for such datasets are less essential. Such discussion pertains to how much contribution the module makes to the overall performance of solving the task within dataset Dj. If the performance decrease is sharp, then regardless of how significant the pruning, the modules contribution is significantly less to quantify the importance of the modules. In figure 9(b and c), the distributions of the sparsity ratio for individual modules and BDM j,k in the Llama2 model with 25% pruning illustrate the differences between two pruning strategies. These differences arise from the inherent structural characteristics of each strategy. The dependency graph for weight parameters using the block-based pruning strategy is independent of the modules, meaning each dependency graph distinguishes different modules, like attentionbased modules, from MLP-based modules more distinctly, resulting in bimodal distribution for the sparsity ratio and BDM j,k . In contrast, the channel-based pruning strategy leads to Gaussian distribution, as its dependency graph is more interconnected across all modules. This finding emphasizes how the structural pruning process reveals the sensitivity of model performance to specific datasets and their associated modules, offering framework to assess dataset dependencies and module importance. Compare Activation Pattern with Dataset association Foremost, we focus on empirically verifying that the gradient-based structural pruning method applied to LLMs is valid method for studying the influence of each dataset on the modules. Gradient-based pruning can selectively deactivate neural network weights by identifying and pruning those that contribute the least to the models performance on specific datasets using weights that activate the least for the dataset [12, 13, 14, 15, 16, 17]. This method generates distinct activation pathways for different datasets, effectively separating module activation based on input characteristics, i.e., skills required to solve the multiple-choice problem. We utilize LLM-Pruner, state-of-the-art pruning method that utilizes structural and gradient-based methods for large language models (detailed in SI 2). The influence of each dataset on individual modules is quantitatively assessed using sparsity values, which serve as metric to gauge the extent of impact. The pruning method inversely exhibits the effect of datasets on the modules, meaning that higher sparsity values indicate more significant effect of the dataset on the respective modules. Given the high dimensions of sparsity values across all modules and datasets, we utilize Principal Component Analysis (PCA) to comprehensively reduce the dimensions to represent the sparsity patterns. Following PCA, K-Means clustering is applied to the reduced data to identify and group similar patterns. Figure 10 (a), represents the optimal number of K-Means clusters that separate different datasets based on their sparsity value of the modules. Figure 10 (b), visualizes the scatter plot of different datasets differentiated by the optimal clusters. In addition, we include random structural pruning to highlight the difference between gradient-based pruning using all the datasets. This clustering process highlights how different groups or clusters are characterized and distinguished based on the underlying sparsity patterns, providing insights into the variation in dataset impact across modules. We further analyze the effectiveness of the pruning approach using Hotellings T-squared statistic, comparing PCA values of each cluster, including the randomly pruned models. Figure 10(c,d) presents the p-values and statistical results obtained using Hotellings T-squared test, offering robust evidence that different modules of sparsity value of different modules. The results with p-value below 0.001 indicate statistically significant distinction between the clusters produced by the pruning method, including those formed through random pruning. This notable difference implies that the pruning method successfully captures and retains the LLMs information processing characteristics, which are specific to different datasets. Supplementary Note 3: Skill Weight Function Utilizing equation 8 and 14, we define projected bipartite network, BSM module Mk and the skill si. This network projects the skill dataset bipartite network BSD the importance of modules BDM expressed as: ik , which quantifies the relationship between ij of dataset Dj with jk , providing unified measure of module relevance for skills. Mathematically, it is BSM ik = (cid:88) Dj BSD ij BDM jk (15) ij represents the skills, si S, required to solve questions within the dataset Dj D, and BDM where BSD jk measures the importance of module Mk based on the fraction of its essential weights scaled by the complement of the accuracy drop caused by pruning the dataset Dj D. This formulation enables targeted analysis of module relevance for specific skills and datasets, offering insights into skill-specific module contributions, dataset selection, and pruning strategies. The projected bipartite network bridges the gap between skill requirements and model architecture, facilitating informed decisions in model optimization. In addition, the bipartite network(BDM and BSM ) connects skills to datasets and modules, with projections providing detailed view of the interdependencies. However, summing two different bipartite networks results in significantly dense network. Projecting this dense network would further amplify its density. To address this, we employ spectral sparsification [18] to reduce the networks density while preserving the largest eigenvalue, thereby maintaining the spectral topology of the original network. Given the stochastic nature of spectral sparsification, the resultant networks vary across different iterations. Skills and modules frequently interacting through common datasets form projection network, indicating shared functionality or reliance on overlapping cognitive processes. Supplementary Note 4: Skills Connectivity Network From equation 15, we define projected relationship between two skills, si1 and si2, using the metric PS i1i2 : PS i1i2 = (cid:88) BSM i1k BSM i2k. where, PS Rnn (16) The dependency, PS i1i2, aggregates the product of the associations of each skill with individual modules, reflecting how frequently two distinct cognitive skills activate the same underlying modules within the models architecture. high value of PS i1i2 indicates that the underlying computations required for both skills are not independent but instead share representational resources. Conversely, lower value implies that the skills are interdependent and likely utilize standard cognitive processes within the LLM. 15 To assess how closely the empirically detected communities of skills align with cognitive functions as defined in Section 6.2, we use the Adjusted Rand Score (ARS) as robust clustering comparison metric. Specifically, we compute ARS values between the skill communities obtained via Louvain community detection and the predefined cognitive-function labels across different sparsity levels used in pruning the model [19, 20, 21]. The ARS extends the Rand Index(RI)[20] by correcting for chance agreement, providing normalized measure that accounts for the expected similarity of two random partitions. This makes it particularly useful when comparing communities of cognitive skills of different sizes, since the number of clusters is not fixed. The Rand Index, RI, measures the proportion of agreement between two clusters by evaluating all pairs of elements and counting how many are assigned together or separately in both partitions. It is defined as: RI = + (cid:1) , (cid:0)n 2 (17) where is the number of pairs of elements that are in the same cluster in both partitions, is the number of pairs that are (cid:1) is the total number of possible pairs. The Adjusted Rand Score corrects in different clusters in both partitions, and (cid:0)n this index for chance. Formally, 2 ARS = RI E[RI] max(RI) E[RI] , (18) where E[RI] is RIs expected value under random labeling, and max(RI) is the maximum possible value of the index. The ARS ranges from -1 to 1, with 1 indicating perfect alignment, 0 suggesting random alignment, and negative values indicating less alignment than expected by chance. Similarly, we also evaluate the agreement between the skill communities and the cognitive function with the Adjusted Normalized Mutual Information (Adjusted NMI), an informationtheoretic metric that quantifies the reduction in uncertainty about one partition given knowledge of the other while correcting for chance overlap [19]. (19) The (unnormalized) mutual information between the two partitions(U and V) is (cid:17) (cid:88) (cid:88) MI(U, ) = Ncℓ log (cid:16) Ncℓ Nc Nℓ , ℓV where is the number of skills, Nc and Nℓ denote the sizes of cluster and label class ℓ, and Ncℓ counts skills common to both. Mutual information is normalized to [0, 1] by cU NMI(U, ) = 2 MI(U, ) H(U ) + H(V ) , H(U ) = (cid:88) cU Nc (cid:16) Nc log (cid:17) , (20) yet this value remains biased upward when partitions coincide merely by chance. The adjusted form removes such bias: Adjusted NMI = MI(U, ) E[MI] max(cid:8)H(U ), H(V )(cid:9) E[MI] , (21) where E[MI] is the expected mutual information under random labelings. Adjusted NMI equals 1 for identical partitions, approaches 0 when alignment is no better than chance, and can be negative for non-correlated assignments. We further utilize the Jaccard Similarity Index, which focuses exclusively on the reproducibility of positive coassignments. The Jaccard Similarity between the two partitions (U and V) is defined as Jaccard Similarity(U, ) = U . (22) By applying this metric, we quantitatively evaluate how well the modular structure inferred from the projection matrix PS aligns with functional cognitive function. Figure 11 reveals that alignment between the community of skills and cognitive function defined in .0.1 remains weak across multiple different pruning strategies. For both block-based (ac) and channel-based (df) strategies, the adjusted NMI, ARS, and Jaccard Similarity cluster around the level (0) for every sparsity ratio and all three models. Adjusted NMI values oscillate between roughly 0.05 and 0.10, ARS between 0.05 and 0.08, and the Jaccard Similarity score never exceeds 0.15. We find that for any pruning strategy or ratio, it either leaves the scores unchanged or causes minor fluctuations. Because adjusted NMI and ARS are adjusted for chance, these near-zero trajectories indicate that the skill communities are, at best, only as informative as random partition. The consistently low Jaccard Index reinforces this conclusion, showing that very few skill pairs classified together by the model correspond to the same cognitive functions. 16 Supplementary Note 4: Modules Connectivity Network Similarly, to extend the bipartite network BSM ik and establish relationship between two modules, Mk1 and Mk2 , we project the skill-based importance to measure their connectivity. This projection is formulated by summing over all skills in S, capturing the shared importance of both modules across the skill space. The connection strength between modules is given by: PM k1k2 = (cid:88) BSM ik1 BSM ik2 . where, PM Rkk, (23) and BSM ik where BSM represent the bipartite skills modules network Mk1 and Mk2 influenced, respectively, for skill ik1 si S. This projection emphasizes modules relevant to overlapping skills, effectively creating skill-informed connectivity measure. The resulting metric can be interpreted as the degree of alignment or complementarity between modules in addressing the same skill requirements. This approach enables the construction of network of modules, where edges between modules are weighted based on their shared skill-based connectivity. Such projection allows for detailed analysis of inter-module interactions. It facilitates the identification of communities within the network, revealing clusters of modules that collectively contribute to specific skill sets. This community detection can further inform optimization strategies by highlighting interdependency and structural relationships within the model architecture, enabling targeted enhancements or pruning. Spectral Analysis of Module Connectivity To analyze the structural properties of the module connectivity network, we utilize the projection network matrix, PM. The matrix PM is positive semi-definite, we verify that for any non-zero vector Rk, the following condition holds: We know, xPMx 0. by substituting PM with BSMBSM, since the module connectivity network is projection network of skills modules bipartite network, 23, we have: xPMx = x(BSMBSM )x = (BSM x)(BSM x). The term (BSM x)(BSM x) represents the Euclidean norm squared of the vector BSM x: (BSM x)(BSM x) = BSM x2. Since the squared Euclidean norm of any vector is always non-negative, it follows that: Hence, xPMx 0 for all Rm. BSM x2 0. Thus, the matrix PM is positive semi-definite. Since PM is symmetric and positive semi-definite, it can be decomposed using its spectral decomposition: PM = UΛU, where: is an orthogonal matrix (UU = I), whose columns are the eigenvectors of PM. Λ is diagonal matrix containing the eigenvalues of PM, denoted as λ1, λ2, . . . , λm. Since PM is positive semi-definite, all eigenvalues λi 0. The rank of PM equals the rank of BSM, implying that the number of non-zero eigenvalues corresponds to the linearly independent columns of BSM. Eigenvectors associated with larger eigenvalues capture directions in the module connectivity space that reflect dominant patterns of variance, with the largest eigenvalue λmax indicating the most significant connectivity pattern. Conversely, eigenvalues close to zero represent negligible or orthogonal contributions to the connectivity structure. Spectral properties of PM can be analyzed to infer community structures: clusters in the connectivity network correspond to large eigenvalues, with coherent eigenvector components highlighting interconnected groups of modules[22]. Relationship Between BSD, Iwp , and Community Formation The skill mapping BSD acts as weighting factor for PM. PM emphasizes connections between modules that contribute to the subsets of skills that activate together when solving the task in datasets Dj that require overlapping skills, Conversely, when BSD is highly diverse across datasets, PM exhibits weaker block structures. Similarly, the gradient-based importance measure, Iwp , affects PM via its influence on BDM: BDM"
        },
        {
            "title": "Essential Weights in Mk\nTotal Weights in Mk",
            "content": ". (24) Large Iwp values indicate critical weights that enhance BDM, creating strong module-skill connections and increasing community cohesiveness. Combining Iwp and BSD, the matrix PM encodes community structures that balance: Skill Association (via BSD): Modules with similar skill profiles are more likely to cluster together. Weight Importance (via Iwp ): Essential weights amplify module importance, creating stronger module-skill connections. For given skill subset Sg S, the contribution of dataset Dj to module community formation is proportional to: (cid:34) j wp wp BSD 2 ij PM (cid:88) wp (cid:35) , (25) Dj The dense blocks in PM emerge when modules share overlapping skills and retain essential weights (Iwp ), highlighting the importance of both skill association and weight importance. The diversity or concentration of BSD dictates the sharpness of community boundaries, while pruning affects the structure by potentially weakening connections for aggressive thresholds (high τ ). Balanced pruning, however, preserves meaningful differentiation, enabling PM to effectively bridge module importance and skill association, driving community formation in weight and skill spaces. Community Detection within Modules Network In this study, we employ robust community detection approach leveraging the Louvain algorithm[23], followed by hierarchical clustering[24], to enhance the stability and reliability of the detected communities. The methodology consists of running the Louvain community detection algorithm 100 times on the same network to capture different possible community structures due to the stochastic nature of the algorithm. Using the results from these multiple runs, co-assignment matrix is constructed to quantify the frequency with which pairs of nodes are assigned to the same community across different iterations. This co-assignment matrix is then processed using hierarchical clustering with Wards linkage method to identify clusters of nodes based on their co-assignment frequencies. The final number of communities is determined by selecting the maximum cluster count from the hierarchical clustering results, representing the final community structure of the network. This multi-step procedure improves the consistency of community detection by reducing the impact of stochastic variations and ensures more reliable partitioning of the network into meaningful communities. Figures 13, 14, 15, 16, 17, and 18, depicts the community cluster using hierarchical clustering for modules network,PM . Supplementary Note 5: Influence of Modules with each community of Modules Network Within-Module Degree Z-Score Degree Z-Score indicates how module compares connectivity to others within the same community [25, 26]. high Z-score means the module has more connections than typical for its community, suggesting central or dominant role within that group. The Z-Score of module within its community: Where: Zi = ki µCi σCi 18 Zi is the Within-Module Degree Z-Score for module i. ki is the degree of module i. µCi is the mean degree of the community Ci to which module belongs. σCi is the standard deviation of the degrees within community Ci. Participation Coefficient The Participation Coefficient is measure used to quantify how module is connected to multiple communities within the network[25, 26]. The Participation Coefficient for module in network is given by: Pi = 1 (cid:19)2 (cid:88) s=1 (cid:18) kis ki Where: Pi is the Participation Coefficient of module i. kis is the number of edges (or degree) that module has with nodes in community s. ki is the total degree (number of edges) of module i. The sum is taken over all communities in the network. Figure 19, highlights the distribution of edge-weight as well as the the within-module degree Z-score analysis of different communities formed using different pruning strategies for different models. Th within-module degree Z-score analysis highlights modules that exhibit significantly greater connectivity compared to other modules within the same community. high Z-score identifies module as central or dominant within its community, reflecting its critical role in facilitating internal communication and coherence. In parallel, the participation coefficient provides insights into the inter-community connectivity of modules, measuring the extent to which module is interconnected across different communities. higher participation coefficient indicates that module bridges multiple communities, acting as an integrative or intermediary component within the broader network structure. Together, these metrics reveal nuanced roles of individual modules, distinguishing between community-specific hubs and those crucial for inter-community communication and network integration. From the figure we see that, in both pruning strategies, most modules exhibit relatively high participation coefficients (typically between 0.6 and 1.0), suggesting network where modules generally maintain connections across multiple communities rather than being strictly confined to their local communities. The within-module Z-scores display considerable variability across the modules, ranging approximately between -3 and +3 for block-based pruning and between -4 and +3 for channel-based pruning. Higher positive Z-scores (above zero) indicate modules functioning as local community hubs with stronger intra-community connections. Conversely, negative Z-scores suggest peripheral roles with fewer local connections. The distinct clustering and spread patterns indicate that the block-based pruning strategy leads to network with more defined module roles (either community-centric or integrative), enabling clearer interpretability of how skills might be localized within specific modules or communities. Conversely, the channel-based pruning strategy yields networks with uniformly high cross-community integration, suggesting that this strategy may reduce clarity about functional specialization but highlights the distributed and interconnected nature of module interactions. These observations underscore the structural complexity in LLMs, where network modules exhibit diverse roles. Such roles likely influence how abstract cognitive skills are encoded and integrated throughout the model architecture, reflecting an interplay between local specialization and global integration."
        },
        {
            "title": "Finetuning Details",
            "content": "Drawing from the hypothesis that modules associated with distinct skill distributions play specialized roles, we aligned task datasets with corresponding module communities using KL divergence to capture the closest match between dataset and module specialization. Figure 20 illustrates the methodology for how communities based on specific distribution of skills can be used to fine-tune the model based on their cognitive skill relevance. We employ distributed training and evaluation to analyze the performance of LLMs, including Llama, Llama-chat, and Vicuna, fine-tuned using datasets aligned with cognitive skill-based module communities. Models are initialized with pre-trained weights, with specific modules (e.g., attn.q, map.up) selectively frozen or fine-tuned based on three 19 strategies: community-specific, random, or all modules. We froze all the parameters not included when creating the communities. Randomized module subsets are generated by replacing community modules with non-community equivalents to evaluate robustness. Random modules closely relate to the community of modules, i.e., if an attn.q module is in the community, then the random subset contains attn.q module that is 1 or 2 layers different. Distributed training leverages NVIDIAs NCCL backend for inter-GPU communication, with AdamW as the optimizer and hyperparameters set to five epochs, batch size of two, and learning rate of 0.00001. Mixed precision (bfloat16) and Fully Sharded Data Parallel (FSDP) strategies, including CPU offloading, ensure computational efficiency and memory optimization. Skill-aligned datasets are used for fine-tuning, with validation size of 100 samples and top-skill selection strategy to match datasets to community skill profiles. Model evaluation computes accuracy by comparing predicted logits with true labels alongside metrics such as Euclidean magnitude of weight changes and L2 norm for weight sparsity. This integrated approach enables detailed understanding of how cognitive skill alignment influences LLM performance. Performance on Targeted Finetuning Figure 21 and 22 show the impact of targeted finetuning using the community of modules as depicted in figure 20. The results demonstrate crucial insights into the comparative effects of targeted finetuning using communities formed through two pruning strategiesblock-wise and channel-wiseon the performance and structural adaptation of finetuned LLMs. In both pruning conditions, fine-tuning across all modules consistently achieved the highest accuracy for all models tested (Llama, Llama-Chat, and Vicuna), clearly surpassing both community-based and random-module fine-tuning. Intriguingly, the accuracy obtained through fine-tuning community-based modules, selected based on cognitive skill associations, did not significantly differ from that achieved by randomly selected modules under either pruning strategy. This result underscores that the assumed specialization of LLM modules tied explicitly to cognitive functions does not translate into enhanced performance relative to random module selection, irrespective of pruning strategy. The L2 norm differences in weight updates reveal nuanced distinctions between the two pruning methods. Since we fixed the hyperparameter to be the same for finetuning, the learning rate remains the same. Hence, the magnitude difference represents the gradient norm. Under both block-wise and channel-wise pruning, community-based fine-tuning led to notably more significant magnitude change compared to all-module or random-module fine-tuning. This suggests that community-based fine-tuning is more sensitive to fine-tuning than other finetuning. Nevertheless, despite the sensitivity, community-based fine-tuning did not yield proportional improvements in accuracy over random selections, an observation consistent across both pruning approaches. Moreover, the magnitude of weight updates under block-wise pruning generally exceeded that observed in channel-wise pruning, suggesting that block-wise pruning induces more pronounced structural modifications within targeted modules. Figures 23, 24, and 25 illustrated individual magnitude differences of each module within the community to the original pre-trained modules for different models and pruning strategies. Collectively, these findings highlight two important insights: first, the limited efficacy of predefined cognitive-skill module selection for enhancing fine-tuning performance remains consistent across different pruning strategies; second, block-wise pruning triggers more substantial structural updates than channel-wise pruning, yet this greater magnitude of change does not translate into superior accuracy gains. These results reinforce the broader conclusion that LLMs encode knowledge through distributed rather than strictly modular specializations. 20 Table 1: Cognitive Functions with their corresponding cognitive skills. The total number of cognitive skills considered is = 53, with each skill si categorized into broader higher-order cognitive domains based on classifications from prior literature. Category Cognitive Skills (S) Cognitive Process (Memory)"
        },
        {
            "title": "Executive Function",
            "content": "Language Communication sustained attention, selective attention, divided attention, vigilance attention, attention shifting, processing speed, visual processing speed, auditory processing speed, prospective memory, working memory, episodic memory, semantic memory, procedural memory, iconic memory, echoic memory, spatial memory planning, organization, goal setting, time management, problemsolving, mental flexibility, strategic thinking, adaptability, impulse control, decision making, emotional regulation, risk assessment, abstract thinking, reasoning, concept formation, cognitive flexibility, creativity expressive language, receptive language, naming, fluency, comprehension, repetition, reading, writing, pragmatics, discourse ability, expressive language, receptive language, linguistic analysis, narrative skills Citation [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40] [41, 42, 43, 44, 45, 46, 47, 48] [49, 50, 51, 52, 53, 54, 55] Social Cognition recognition of social cues, theory of mind, empathy, social judgment, intercultural competence, conflict resolution, self-awareness, relationship management [56, 57, 58, 59, 60, 61, 62, 63] Figure 6: Heatmap of Skills vs. Datasets (BSD ij represents the number of times skill si is required for dataset Dj. Datasets that require similar cognitive skills exhibit strong associations, as indicated by the clustered patterns in the heatmap. ij ) with Hierarchical Clustering. The bipartite matrix BSD 22 Model: gpt-3.5-turbo Message: System: You are linguistic and cognitive scientist skilled in analyzing texts for their cognitive properties Role: Given different cognitive skills: {all cognitive skills} Select applicable cognitive skills as an unordered list separated by commas, which is necessary to answer this question without explanation. {question} Figure 7: Prompt Template for Cognitive Skill Mapping. The prompt provides the structure for querying gpt-3.5-turbo to identify cognitive skills necessary for answering specific question. The instruction specifies the context, role, and task, prompting the model to select five relevant cognitive skills from predefined set of abstract skills. Figure 8: Average Performance of the pruned model after pruning with different sparsity ratios. Average accuracy performance of all datasets with different pruning ratios utilizing different pruning strategies, (a), block-based pruning strategy and, (b), channel-based pruning strategy. Figure 9: Average Performance of the pruned model after pruning with different sparsity ratios. (a) Importance of Modules quantifies the relationship between each dataset and the weight modules of LLMs (Llama2 with 25% pruning ratio). The scatter plot with the line of best fit shows the relationship between the average BDM :k of all LLM modules(Mk) and the change in overall model performance before and after pruning. (b) The module sparsity ratio distribution of Llama2 with 25% pruning ratio is shown for two pruning strategies.(c) The variation of BDM (edge weight between datasets and individual LLM modules) is shown for two pruning strategies. 24 Figure 10: Evaluating clustering of pruned Llama models using Davies-Bouldin Score and Hotellings T-squared test.(a) The Davies-Bouldin Score determines the optimal number of K-Means clusters for grouping 174 PCA values derived from module sparsity values, obtained by pruning the Llama2 model using 174 different datasets. (b) scatter plot showing the pruned Llama2 model, grouped by the optimal number of clusters identified in a, alongside randomly pruned models with the 174 datasets. (c) P-values from Hotellings T-squared test between different clusters, including random pruning, are all significantly small (< 0.05), indicating dissimilarity in information processing between different clusters. (d) Hotellings T-squared statistics highlight the differences between clusters. 25 Figure 11: Comparison of community alignment measures between communities in the Skills network and ground-truth cognitive-function labels, across different sparsity levels. Subplots (ac) show results for the blockbased pruning strategy, while (df) display the same for channel-based pruning. Each row visualizes the trends for three base models (Llama, Llama-Chat, and Vicuna), using (a, d) Adjusted Normalized Mutual Information (NMI), (b, e) Adjusted Rand Index (ARI), and (c, f) Jaccard Index as similarity metrics. The x-axis denotes the sparsity ratio applied during pruning, enabling evaluation of how sparsity for pruning the LLMs impacts community alignment within cognitive function labels. Figure 12: Multi-Layered Network: This diagram highlights the cognitive skills rooted in human cognition, mapped to individual datasets. The modules within LLMs are represented as distinct components, illustrating how different datasets influence these modules. The projection network of modules at the end reflects the localization of cognitive skills across the network. 26 Figure 13: Heat map clustering of modules network (PM ) for the llama model with block-based pruning, where leaf colors in the dendrograms represent distinct communities formed through hierarchical clustering of the co-assignment matrix, revealing structural patterns among attention modules across layers. 27 Figure 14: Heat map clustering of modules network (PM ) for the llama-chat model with block-based pruning, where leaf colors in the dendrograms represent distinct communities formed through hierarchical clustering of the co-assignment matrix, revealing structural patterns among attention modules across layers. 28 Figure 15: Heat map clustering of modules network (PM ) for the vicuna model with block-based pruning, where leaf colors in the dendrograms represent distinct communities formed through hierarchical clustering of the co-assignment matrix, revealing structural patterns among attention modules across layers. 29 Figure 16: Heat map clustering of modules network (PM ) for the llama model with channel-based pruning, where leaf colors in the dendrograms represent distinct communities formed through hierarchical clustering of the co-assignment matrix, revealing structural patterns among attention modules across layers. 30 Figure 17: Heat map clustering of modules network (PM ) for the llama-chat model with channel-based pruning, where leaf colors in the dendrograms represent distinct communities formed through hierarchical clustering of the co-assignment matrix, revealing structural patterns among attention modules across layers. 31 Figure 18: Heat map clustering of modules network (PM ) for the vicuna model with channel-based pruning, where leaf colors in the dendrograms represent distinct communities formed through hierarchical clustering of the co-assignment matrix, revealing structural patterns among attention modules across layers. 32 Figure 19: Influence of Modules within each community of Modules Network.(a-b) The distribution of edge weight within different communities of modules network for Block and Channel based modules.(c-d) The scatter plot for different modules over two metrics, participation coefficient and degree z-score metric. 33 Figure 20: Community-based fine-tuning aligned with cognitive skill relevance The influence of skill distributions within identified module communities is examined by selecting datasets matching the skill profiles of these communities. Figure 21: Performance of Targeted Finetuning Accuracy and weight difference magnitude of fine-tuned models (Llama, Llama-Chat, Vicuna) across two datasets aligned with each community that were created using block-based pruning strategy. Figure 22: Performance of Targeted Finetuning Accuracy and weight difference magnitude of fine-tuned models (Llama, Llama-Chat, Vicuna) across two datasets aligned with each community that were created using channel-based pruning strategy. Figure 23: Visualization of changes in weight modules of the Llama model after fine-tuning, highlighting task associations such as disambiguation_qa (Block) and identify_odd_metaphor (Channel). 35 Figure 24: Visualization of changes in weight modules of the Llama-Chat model after fine-tuning, highlighting task associations such as high_school_psychology (Block) and electrical_engineering (Channel). Figure 25: Visualization of changes in weight modules of the Vicuna model after fine-tuning, highlighting task associations such as implicatures (Block) and electrical_engineering (Channel)."
        },
        {
            "title": "References",
            "content": "[1] Susan Case and Swanson, David B. Constructing Written Test Questions for the Basic and Clinical Sciences. National Board of Medical Examiners Philadelphia, 1998. [2] Nikki L. Bibler Zaidi, Karri L. Grob, Seetha M. Monrad, Joshua B. Kurtz, Andrew Tai, Asra Z. Ahmed, Larry D. Gruppen, and Sally A. Santen. Pushing Critical Thinking Skills With Multiple-Choice Questions: Does Blooms Taxonomy Work? Academic Medicine, 93(6):856859, June 2018. [3] Alex Y. Zheng, Janessa K. Lawhorn, Thomas Lumley, and Scott Freeman. Application of Blooms Taxonomy Debunks the \"MCAT Myth\". Science, 319(5862):414415, January 2008. [4] Nikki L. Bibler Zaidi, Karri L. Grob, Jun Yang, Sally A. Santen, Seetha U. Monrad, Jill M. Miller, and Joel A. Purkiss. Theory, Process, and Validation Evidence for Staff-Driven Medical Education Exam Quality Improvement Process. Medical Science Educator, 26(3):331336, September 2016. [5] Eeva S.H. Haataja, Asko Tolvanen, Henna Vilppu, Manne Kallio, Jouni Peltonen, and Riitta-Leena Metsäpelto. Measuring higher-order cognitive skills with multiple choice questions potentials and pitfalls of Finnish teacher education entrance. Teaching and Teacher Education, 122:103943, February 2023. [6] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring Massive Multitask Language Understanding. In International Conference on Learning Representations, October 2020. [7] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Johan Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew M. Dai, Andrew La, Andrew Kyle Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, B. Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bartłomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, Cesar Ferri, Chandan Singh, Charles Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Christopher Waites, Christian Voigt, Christopher Manning, Christopher Potts, Cindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, C. Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Moseguí González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader, Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodolà, Emma Lam, Eric Chu, Eric Tang, Erkut Erdem, Ernie Chang, Ethan Chi, Ethan Dyer, Ethan Jerzak, Ethan Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar, Fernando Martínez-Plumed, Francesca Happé, Francois Chollet, Frieda Rong, Gaurav Mishra, Genta Indra Winata, Gerard de Melo, Germàn Kruszewski, Giambattista Parascandolo, Giorgio Mariani, Gloria Xinyue Wang, Gonzalo Jaimovitch-Lopez, Gregor Betz, Guy Gur-Ari, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry Francis Anthony Shevlin, Hinrich Schuetze, Hiromu Yakura, Hongming Zhang, Hugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James Simon, James Koppel, James Zheng, James Zou, Jan Kocon, Jana Thompson, Janelle Wingfield, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason Wei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming Song, Jillian Tang, Joan Waweru, John Burden, John Miller, John U. Balis, Jonathan Batchelder, Jonathan Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph Boudeman, Joseph Guerr, Joseph Jones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan, Katerina Ignatyeva, Katja Markert, Kaustubh Dhole, Kevin Gimpel, Kevin Omondi, Kory Wallace Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar Shridhar, Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, LouisPhilippe Morency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros-Colón, Luke Metz, Lütfi Kerem Senel, Maarten Bosma, Maarten Sap, Maartje Ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan, Marco Marelli, Marco Maru, Maria Jose Ramirez-Quintana, Marie Tolkiehn, Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew Leavitt, Matthias Hagen, Mátyás Schubert, 37 Medina Orduna Baitemirova, Melody Arnaud, Melvin McElrath, Michael Andrew Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt, Michael Strube, Michał Swedrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mitch Walker, Mo Tiwari, Mohit Bansal, Moin Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan Andrew Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron, Nicholas Roberts, Nick Doiron, Nicole Martinez, Nikita Nangia, Niklas Deckers, Niklas Muennighoff, Nitish Shirish Keskar, Niveditha S. Iyer, Noah Constant, Noah Fiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio Moreno Casares, Parth Doshi, Pascale Fung, Paul Pu Liang, Paul Vicol, Pegah Alipoormolabashi, Peiyuan Liao, Percy Liang, Peter Chang, Peter Eckersley, Phu Mon Htut, Pinyu Hwang, Piotr Miłkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel, Rahel Habacker, Ramon Risco, Raphaël Millière, Rhythm Garg, Richard Barnes, Rif A. Saurous, Riku Arakawa, Robbe Raymaekers, Robert Frank, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan Le Bras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Russ Salakhutdinov, Ryan Andrew Chi, Seungjae Ryan Lee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman, Samuel Gruetter, Samuel R. Bowman, Samuel Stern Schoenholz, Sanghyun Han, Sanjeev Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh, Sean Casey, Sebastian Bischoff, Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon Zhou, Shashank Srivastava, Sherry Shi, Shikhar Singh, Shima Asaadi, Shixiang Shane Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima Shammie Debnath, Siamak Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic, Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven Piantadosi, Stuart Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsunori Hashimoto, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay Venkatesh Ramasesh, vinay uday prabhu, Vishakh Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang Ren, Xiaoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi, Yichi Yang, Sophie Hao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning Research, 2023. Featured Certification. [8] Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms. In Proceedings of the 2019 Conference of the North, pages 23572367, Minneapolis, Minnesota, 2019. Association for Computational Linguistics. [9] Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: question answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 41494158, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. [10] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering. In Advances in Neural Information Processing Systems, October 2022. [11] Stephanie Lin, Jacob Hilton, and Owain Evans. TruthfulQA: Measuring how models mimic human falsehoods. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 32143252, Dublin, Ireland, May 2022. Association for Computational Linguistics. [12] Yann LeCun, John Denker, and Sara Solla. Optimal brain damage. In D. Touretzky, editor, Advances in Neural Information Processing Systems, volume 2. Morgan-Kaufmann, 1989. [13] B. Hassibi, D.G. Stork, and G.J. Wolff. Optimal Brain Surgeon and general network pruning. In IEEE International Conference on Neural Networks, pages 293299, San Francisco, CA, USA, 1993. IEEE. [14] Mingjie Sun, Zhuang Liu, Anna Bair, and J. Zico Kolter. Simple and Effective Pruning Approach for Large Language Models, June 2023. [15] Elias Frantar and Dan Alistarh. SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot. In Proceedings of the 40th International Conference on Machine Learning, pages 1032310337. PMLR, July 2023. [16] Chaoqi Wang, Roger Grosse, Sanja Fidler, and Guodong Zhang. EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis. In Proceedings of the 36th International Conference on Machine Learning, pages 65666575. PMLR, May 2019. 38 [17] Xinyin Ma, Gongfan Fang, and Xinchao Wang. LLM-pruner: On the structural pruning of large language models. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. [18] Daniel A. Spielman and Shang-Hua Teng. Spectral Sparsification of Graphs. SIAM Journal on Computing, 40(4):9811025, January 2011. [19] Nguyen Xuan Vinh, Julien Epps, and James Bailey. Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance. Journal of Machine Learning Research, 11(95):2837 2854, 2010. [20] Lawrence Hubert and Phipps Arabie. Comparing partitions. Journal of Classification, 2(1):193218, December 1985. [21] José E. Chacón and Ana I. Rastrojo. Minimum adjusted Rand index for two clusterings of given size. Advances in Data Analysis and Classification, 17(1):125133, 2023. [22] Daniel Spielman. Spectral graph theory. Combinatorial Scientific Computing, 18:18, 2012. [23] Vincent Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, October 2008. [24] Joe H. Ward. Hierarchical Grouping to Optimize an Objective Function. Journal of the American Statistical Association, 58(301):236244, March 1963. [25] Roger Guimerà and Luís A. Nunes Amaral. Functional cartography of complex metabolic networks. Nature, 433(7028):895900, February 2005. [26] Jonathan Power, Bradley Schlaggar, Christina Lessov-Schlaggar, and Steven Petersen. Evidence for hubs in human functional brain networks. Neuron, 79(4):10.1016/j.neuron.2013.07.035, August 2013. [27] Steven E. Petersen and Michael I. Posner. The Attention System of the Human Brain: 20 Years After. Annual Review of Neuroscience, 35(1):7389, July 2012. [28] Michael I. Posner, Gregory J. DiGirolamo, and Diego Fernandez-Duque. Brain Mechanisms of Cognitive Skills. Consciousness and Cognition, 6(2-3):267290, June 1997. [29] William A. Johnston and Steven P. Heinz. Flexibility and capacity demands of attention. Journal of Experimental Psychology: General, 107(4):420435, December 1978. [30] Raja Parasuraman. Memory Load and Event Rate Control Sensitivity Decrements in Sustained Attention. Science, 205(4409):924927, August 1979. [31] Stephen Monsell. Task switching. Trends in Cognitive Sciences, 7(3):134140, March 2003. [32] R. Kail and T. A. Salthouse. Processing speed as mental capacity. Acta Psychologica, 86(2-3):199225, August 1994. [33] Robert Kail. Developmental change in speed of processing during childhood and adolescence. Psychological Bulletin, 109(3):490501, 1991. [34] Ulric Neisser. Cognitive Psychology. Cognitive Psychology. Appleton-Century-Crofts, East Norwalk, CT, US, 1967. [35] Endel Tulving. Episodic and semantic memory. In Organization of Memory, pages xiii, 423xiii, 423. Academic Press, Oxford, England, 1972. [36] A. Baddeley. Working memory. Science (New York, N.Y.), 255(5044):556559, January 1992. [37] N. J. Cohen and L. R. Squire. Preserved learning and retention of pattern-analyzing skill in amnesia: Dissociation of knowing how and knowing that. Science (New York, N.Y.), 210(4466):207210, October 1980. [38] George Sperling. The information available in brief visual presentations. Psychological Monographs: General and Applied, 74(11):129, 1960. [39] Christopher J. Darwin, Michael T. Turvey, and Robert G. Crowder. An auditory analogue of the sperling partial report procedure: Evidence for brief auditory storage. Cognitive Psychology, 3(2):255267, April 1972. [40] J. OKeefe and L. Nadel. The Hippocampus as Cognitive Map. Oxford University Press, Oxford, UK, 1978. [41] Muriel Deutsch Lezak. Neuropsychological Assessment, 3rd Ed. Neuropsychological Assessment, 3rd Ed. Oxford University Press, New York, NY, US, 1995. [42] Edwin A. Locke and Gary P. Latham. Building practically useful theory of goal setting and task motivation: 35-year odyssey. American Psychologist, 57(9):705717, 2002. 39 [43] Brigitte J. C. Claessens, Wendelien van Eerde, Christel G. Rutte, and Robert A. Roe. review of the time management literature. Personnel Review, 36(2):255276, 2007. [44] Elaine D. Pulakos, Sharon Arad, Michelle A. Donovan, and Kevin E. Plamondon. Adaptability in the workplace: Development of taxonomy of adaptive performance. Journal of Applied Psychology, 85(4):612624, 2000. [45] Bechara A, Damasio Ar, Damasio H, and Anderson Sw. Insensitivity to future consequences following damage to human prefrontal cortex. Cognition, 50(1-3), 1994 Apr-Jun. [46] James J. Gross. The emerging field of emotion regulation: An integrative review. Review of General Psychology, 2(3):271299, 1998. [47] Amos Tversky and Daniel Kahneman. Judgment under uncertainty: Heuristics and biases. Science, 185(4157):11241131, 1974. [48] J. P. Guilford. Creativity. American Psychologist, 5(9):444454, 1950. [49] David Caplan. Neurolinguistics and Linguistic Aphasiology: An Introduction. Neurolinguistics and Linguistic Aphasiology: An Introduction. Cambridge University Press, New York, NY, US, 1987. [50] Stephen C. Levinson. Pragmatics. Cambridge University Press, June 1983. [51] James Paul Gee. An Introduction to Discourse Analysis: Theory and Method. Routledge, London, 4 edition, February 2014. [52] A. R. Luria. The functional organization of the brain. Scientific American, 222(3):6672 passim, March 1970. [53] Max Coltheart, Kathleen Rastle, Conrad Perry, Robyn Langdon, and Johannes Ziegler. DRC: dual route cascaded model of visual word recognition and reading aloud. Psychological Review, 108(1):204256, 2001. [54] Noem Chomsky. Syntactic Structures. Syntactic Structures. Mouton, Oxford, England, 1957. [55] Jerome Bruner. The Narrative Construction of Reality. Critical Inquiry, 18(1):121, October 1991. [56] S. Baron-Cohen, A. M. Leslie, and U. Frith. Does the autistic child have \"theory of mind\"? Cognition, 21(1):3746, October 1985. [57] Mark H. Davis. Measuring individual differences in empathy: Evidence for multidimensional approach. Journal of Personality and Social Psychology, 44(1):113126, 1983. [58] R. Adolphs. The neurobiology of social cognition. Current Opinion in Neurobiology, 11(2):231239, April 2001. [59] Milton J. Bennett. Developmental Model of Intercultural Sensitivity. In Young Y. Kim, editor, The International Encyclopedia of Intercultural Communication, pages 110. Wiley, 1 edition, June 2017. [60] R. Michael Paige. Education for the Intercultural Experience. Intercultural Press, 1993. [61] Roger Fisher, William Ury, and Bruce Patton. Getting to Yes: Negotiating Agreement Without Giving In. Houghton Mifflin Harcourt, 1991. [62] Daniel Goleman. Emotional Intelligence. Emotional Intelligence. Bantam Books, Inc, New York, NY, England, 1995. [63] Reuven Bar-On. The Bar-On model of emotional-social intelligence (ESI). Psicothema, 18(Suppl):1325, 2006."
        }
    ],
    "affiliations": [
        "IBM Research",
        "Rensselaer Polytechnic Institute"
    ]
}