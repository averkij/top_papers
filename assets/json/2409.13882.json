{
    "paper_title": "Tabular Data Generation using Binary Diffusion",
    "authors": [
        "Vitaliy Kinakh",
        "Slava Voloshynovskiy"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Generating synthetic tabular data is critical in machine learning, especially when real data is limited or sensitive. Traditional generative models often face challenges due to the unique characteristics of tabular data, such as mixed data types and varied distributions, and require complex preprocessing or large pretrained models. In this paper, we introduce a novel, lossless binary transformation method that converts any tabular data into fixed-size binary representations, and a corresponding new generative model called Binary Diffusion, specifically designed for binary data. Binary Diffusion leverages the simplicity of XOR operations for noise addition and removal and employs binary cross-entropy loss for training. Our approach eliminates the need for extensive preprocessing, complex noise parameter tuning, and pretraining on large datasets. We evaluate our model on several popular tabular benchmark datasets, demonstrating that Binary Diffusion outperforms existing state-of-the-art models on Travel, Adult Income, and Diabetes datasets while being significantly smaller in size. Code and models are available at: https://github.com/vkinakh/binary-diffusion-tabular"
        },
        {
            "title": "Start",
            "content": "4 2 0 2 8 2 ] . [ 2 2 8 8 3 1 . 9 0 4 2 : r a"
        },
        {
            "title": "Tabular Data Generation using Binary Diffusion",
            "content": "Vitaliy Kinakh Department of Computer Science University of Geneva Geneva, Switzerland vitaliy.kinakh@unige.ch Slava Voloshynovskiy Department of Computer Science University of Geneva Geneva, Switzerland"
        },
        {
            "title": "Abstract",
            "content": "Generating synthetic tabular data is critical in machine learning, especially when real data is limited or sensitive. Traditional generative models often face challenges due to the unique characteristics of tabular data, such as mixed data types and varied distributions, and require complex preprocessing or large pretrained models. In this paper, we introduce novel, lossless binary transformation method that converts any tabular data into fixed-size binary representations, and corresponding new generative model called Binary Diffusion, specifically designed for binary data. Binary Diffusion leverages the simplicity of XOR operations for noise addition and removal and employs binary cross-entropy loss for training. Our approach eliminates the need for extensive preprocessing, complex noise parameter tuning, and pretraining on large datasets. We evaluate our model on several popular tabular benchmark datasets, demonstrating that Binary Diffusion outperforms existing state-of-the-art models on Travel, Adult Income, and Diabetes datasets while being significantly smaller in size. Code and models are available at: https: //github.com/vkinakh/binary-diffusion-tabular"
        },
        {
            "title": "Introduction",
            "content": "The generation of synthetic tabular data is critical task in machine learning, particularly when dealing with sensitive, private, or scarce real-world data. Traditional generative models often struggle with the inherent complexity and diversity of tabular data, which typically encompasses mixed data types and complex distributions. In this paper, we introduce method to transform generic tabular data into binary representation, and generative model named Binary Diffusion, specifically designed for binary data. Binary Diffusion leverages the simplicity of XOR operations for noise addition and removal, fundamental components of probabilistic diffusion models. This method eliminates the need for extensive preprocessing and complex noise parameter tuning, streamlining the data preparation process. Our approach offers several key advantages. First, by converting all columns into unified binary representations, the proposed transformation removes the necessity for column-specific preprocessing commonly required in handling mixed-type tabular data. Secondly, the Binary Diffusion model itself is optimized for binary data, utilizing binary cross-entropy (BCE) loss for predictions during the training of the denoising network. We evaluate our model on several popular tabular benchmark datasets, including Travel [tej21], Sick [SED+88], HELOC [lia18, FIC18], Adult Income [BK96], California Housing [PB97, nug17], and Diabetes [SDG+14, Kag21] tabular datasets. The Binary Diffusion model outperforms existing state-of-the-art models on Travel, Adult Income and Dianetes datasets. Additionally, our model is significantly smaller in size compared to contemporary models and does not require pretraining Table Representation Learning Workshop at NeurIPS 2024. on other data modalities, unlike methods based on large language models (LLMs) such as GReaT [BSL+22]."
        },
        {
            "title": "2 Related Work",
            "content": "TVAE (Tabular Variational Autoencoder) adapts the Variational Autoencoder (VAE) framework to handle mixed-type tabular data by separately modeling continuous and categorical variables. CTGAN (Conditional Tabular GAN) employs conditional generator to address imbalanced categorical columns, ensuring the generation of diverse and realistic samples by conditioning on categorical data distributions. CopulaGAN integrates copulas with GANs to capture dependencies between variables, ensuring that synthetic data preserves the complex relationships present in the original dataset [XSCIV19]. GReaT (Generation of Realistic Tabular data) [BSL+22] leverages pretrained auto-regressive language model (LLM) to generate highly realistic synthetic tabular data. The process involves fine-tuning the LLM on textually encoded tabular data, transforming each row into sequence of words. This approach allows the model to condition on any subset of features and generate the remaining data without additional overhead. Existing data generation methods show several shortcomings. Models such as CopulaGAN, CTGAN, and TVAE attempt to generate columns with both continuous and categorical data simultaneously, employing activation functions like softmax and tanh in the outputs. These models also require complex preprocessing of continuous values and rely on restrictive approximations using Gaussian mixture models and mode-specific normalization. Additionally, large language model-based generators like GReaT need extensive pretraining on text data, making them computationally intensive with large parameter counts with potential bias from the pretraining data. The proposed data transformation and generative model address these shortcomings as follows: (i) by converting all columns to unified binary representations; (ii) the proposed generative model for binary data, with fewer than 2M parameters, does not require pretraining on large datasets and offers both fast training and sampling capabilities."
        },
        {
            "title": "3 Data transformation",
            "content": "To apply the Binary Diffusion model to tabular data, we propose an invertible lossless transformation , shown on the Figure 1, that converts tabular data columns into fixed-size binary representations. The transformations is essential for preparing tabular data for the Binary Diffusion model, enabling it to process and generate tabular data without the need for extensive preprocessing. This approach ensures that the data retains its original characteristics. Figure 1: Transformation of tabular data t0 into the binary form x0. The considered transformation is reversible. The continuous column records are presented with the length dcont = 32 and the categorical ones with dcat = log2 K, where stands for the number of categorical classes. 2 The transformation method converts each column of the table into binary format. For continuous data, this process includes applying min-max normalization to the columns, followed by converting these normalized values into binary representation via 32-bit floating-point encoding. For categorical data, binary encoding is used. The encoded columns are concatenated into fixed-size rows. 1 converts the binary representations back into their original form. For The inverse transformation continuous data, the decoded values are rescaled to their original range using metadata generated during the initial transformation. For categorical data, the binary codes are mapped back to their respective categories using predefined mapping scheme."
        },
        {
            "title": "4 Binary Diffusion",
            "content": "Binary Diffusion shown in Figure 2 is novel approach for generative modeling that leverages the simplicity and robustness of binary data representations. This method involves adding and removing noise through XOR operation, which makes it particularly well-suited for handling binary data. Below, we describe the key aspects of the Binary Diffusion methodology in detail. Figure 2: Binary Diffusion training (left) and sampling (right) schemes. In Binary Diffusion, noise is added to the data by flipping bits using the XOR operation with random binary mask. The amount of noise added is quantified by the proportion of bits flipped. Let be random binary noise be the original binary vector of dimension d, and zt { x0 { 0, 1 0, 1 } } zt , where vector at timestep t. The noisy vector xt is obtained as: xt = x0 denotes the XOR operation. The noise level is defined as the fraction of bits flipped in zt in the mapper Mt at step t, with the number of bits flipped ranging within [0, 0.5] as function of the timestep. xt, t, ye) is trained to predict both the added noise zt and the cleanThe denoising network qθ(ˆx0, ˆzt denoised vector x0 from the noisy vector xt. We employ binary cross-entropy (BCE) loss (1) to train the denoising network. The loss function is averaged over both the batch of samples and the dimensions of the vectors: (θ) = L"
        },
        {
            "title": "1\nB",
            "content": "B (cid:88) (cid:104) b=1 Lx(ˆx(b) 0 , x(b) 0 ) + (cid:105) , z(b) ) Lz(ˆz(b) ="
        },
        {
            "title": "1\nB",
            "content": ""
        },
        {
            "title": "1\nB",
            "content": "(cid:88) (cid:88) (cid:104) 0i log ˆx(b) x(b) 0i + ( b=1 i=1 (cid:88) (cid:88) (cid:104) b= i=1 z(b) ti log ˆz(b) ti + (1 x(b) 0i ) log(1 z(b) ti ) log( (cid:105) ˆx(b) 0i ) (cid:105) ˆz(b) ti ) , (1) where is the batch size, θ represents the parameters of the denoising network, x(b) -th samples of the true clean vectors and the predicted clean vectors, respectively. Similarly, z(b) ˆz(b) ye = for regression. to the i-th dimension of the vectors and the b-th sample in the batch, respectively. 0 are the and are the b-th samples of the true added noise vectors and the predicted noise vectors, respectively. Ey(y) denotes the encoded label y, one-hot encoded for classification and min-max normalized Lz denotes binary cross-entropy (BCE) loss. The indices and correspond 0 and ˆx(b)"
        },
        {
            "title": "Lx and",
            "content": "t During training (Figure 2 left), we use classifier-free guidance [HS22]. For classification tasks, the conditioning input class label is one-hot encoded label ye. For regression tasks, consists of 3 min-max normalized target values ye, allowing the model to generate data conditioned on specific numerical outcomes. In unconditional training, we use an all-zeros conditioning vector for classification tasks and value of 1 for regression tasks to indicate the absence of conditioning. When sampling (Figure 2 right), we start from random binary vector xt at timestep = , along with the conditioning variable y, encoded into ye. For each selected timestep in the sequence [T, . . . , 0], denoising is applied to the vector. The denoised vector ˆx0 and the estimated binary noise ˆzt are predicted by the denoising network. These predictions are then processed using sigmoid function and binarized with threshold. During sampling, we use the denoised vector ˆx0 directly. Then, zt. The sampling random noise zt is generated and added to ˆx0 via the XOR operation: xt = ˆx0 algorithm is summarized in Algorithm 1."
        },
        {
            "title": "5 Results",
            "content": "We evaluate the performance of Binary Diffusion on widely-recognized tabular benchmark datasets, including Travel [tej21], Sick [SED+88], HELOC [lia18, FIC18], Adult Income [BK96], California Housing [PB97, nug17], and Diabetes [SDG+14, Kag21]. For classification tasks (Travel, Sick, HELOC, Adult Income, and Diabetes), classification accuracy was used as metric, while mean squared error (MSE) was used for the regression task (California Housing). Following the evaluation protocol established in [BSL+22], we employed Linear/Logistic Regression (LR), Decision Tree (DT), and Random Forest (RF) as downstream models to assess the quality of the synthetic data. The datasets were split into training and test sets with an 80/20 split. The generative models were trained on the training set, and the test set was reserved for evaluation. To ensure robustness, 5 sets of synthetic training data were generated, and the results are reported as average performances with corresponding standard deviations. Table 1 shows the detailed results. Binary Diffusion achieved superior performance compared to existing state-of-the-art models on the Travel, Adult Income, and Diabetes datasets. Notably, Binary Diffusion maintained competitive results on the HELOC and Sick datasets, despite having significantly smaller parameter footprint (ranging from 1.1M to 2.6M parameters) compared to models like GReaT, which utilize large language models with hundreds of millions of parameters. Binary Diffusion does not require pretraining on external data modalities, enhancing its efficiency and reducing potential biases associated with pretraining data. In the regression task (California Housing), Binary Diffusion demonstrated competitive MSE scores. Additionally, Binary Diffusion offers faster training and sampling times, as detailed in Appendix C. Implementation details are summarized in Appendix D. Table 1: Quantitative results on table dataset benchmarks. The best results are marked in bold, second-best are underlined. The number of parameters for every model and dataset are provided in 4-th row for every dataset. Dataset Travel ( ) Sick ( ) HELOC ( ) Adult Income ( ) Diabetes ( ) California Housing ( ) Model LR DT RF Params LR DT RF Params LR DT RF Params LR DT RF Params LR DT RF Params LR DT RF Params Original TVAE 0.00 0.00 0.53 0.00 0.12 0.06 0.00 1.06 0.71 0.00 0.01 0.11 0.00 0.03 0.08 82.72 89.01 85.03 - 96.69 98.94 98.28 - 71.80 81.90 83.19 - 85.00 85.27 85.93 - 58.76 57.29 59.00 - 0.00 0.01 0.01 0.40 0.32 0.21 - 0.00 1.28 1.19 79.58 81.68 81.68 36K 0.00 0.18 0.06 94.70 95.39 94.91 46K 0.00 0.50 0.25 71.04 76.39 77.24 62K 0.00 0.08 0.11 80.53 82.80 83.48 53K 0.00 0.08 0.10 56.34 53.30 55.17 369K 0.65 0.45 0.35 0.00 0.01 0.01 45K CopulaGAN 0.00 73.30 0.26 73.61 0.00 73.30 157K 0.00 0.01 0. 94.57 93.77 94.57 226K 0.00 0.10 0.34 42.03 42.36 42.35 276K 0.00 0.06 0. 80.61 76.29 80.46 300K 0.00 0.02 0.31 40.27 38.50 37.59 9.4M CTGAN 0.00 0.00 0.53 73.30 73.30 71.41 155K Distill-GReaT 0.00 78.53 0.51 77.38 0.53 79.50 82M 0.00 0.41 0. 94.44 92.05 94.57 222K 0.00 0.09 0.35 57.72 61.34 62.35 277K 0.00 0.02 0. 83.20 81.32 83.53 302K 0.00 0.02 0.17 50.93 49.73 52.23 9.6M 0.00 0.18 0. 96.56 95.39 97.72 82M 0.00 0.15 0.13 70.58 81.40 82.14 82M 0.00 0.04 0. 84.65 84.49 85.25 82M 0.00 0.04 0.16 57.33 54.10 58.03 82M GReaT Binary Diffusion 0.00 0.42 0.33 80.10 83.56 84.30 355M 0.00 0.00 0.13 97.72 97.72 98. 355M 0.00 0.07 0.28 71.90 79.10 80.93 355M 0.00 0.04 0.05 84.77 84.81 85. 355M 0.00 0.04 0.09 57.34 55.23 58.34 355M 0.08 0.57 0.44 83.79 88.90 89. 1.1M 0.63 0.24 0.55 96.14 97.07 96.59 1.4M 0.30 0.43 0.32 71.76 70.25 70. 2.6M 0.11 0.11 0.11 85.45 85.27 85.74 1.4M 0.04 0.15 0.12 57.75 57.13 57. 1.8M 0.57 0.43 0.32 0.00 0.01 0.01 82M 0.34 0.39 0.28 0.00 0.01 0. 355M 0.55 0.45 0.39 0.00 0.00 0.00 1.5M 0.61 0.82 0.62 0.00 0.01 0. 197K 0.00 0.01 0.01 0.98 1.19 0.99 201K"
        },
        {
            "title": "6 Conclusions",
            "content": "This paper proposed novel lossless binary transformation method for tabular data, which converts any data into fixed-size binary representations. Building upon this transformation, we introduced the Binary Diffusion model, generative model specifically designed for binary data that utilizes XOR operations for noise addition and removal and is trained using binary cross-entropy loss. Our approach addresses several shortcomings of existing methods, such as the need for complex preprocessing, reliance on large pretrained models, and computational inefficiency. We evaluated our model on several tabular benchmark datasets, and demonstrated that Binary Diffusion achieves state-of-the-art performance on these datasets while being significantly smaller in size compared to existing models. Our model does not require pretraining on other data modalities, which simplifies the training process and avoids potential biases from pretraining data. Our findings indicate that the proposed model works particularly well with datasets that have high proportion of categorical columns."
        },
        {
            "title": "References",
            "content": "[BK96] Barry Becker and Ronny Kohavi. Adult. UCI Machine Learning Repository, 1996. DOI: https://doi.org/10.24432/C5XW20. [BSL+22] Vadim Borisov, Kathrin Seßler, Tobias Leemann, Martin Pawelczyk, and Gjergji Kasneci. Language models are realistic tabular data generators. arXiv preprint arXiv:2210.06280, 2022. [FIC18] FICO. explainable-machine-learning-challenge, 2018. Accessed: 2024-09-13. Explainable machine learning challenge. https://community.fico.com/s/ [GDW+22] Sylvain Gugger, Lysandre Debut, Thomas Wolf, Philipp Schmid, Zachary Mueller, Sourab Mangrulkar, Marc Sun, and Benjamin Bossan. Accelerate: Training and inference at scale made simple, efficient and adaptable. https://github.com/huggingface/accelerate, 2022. [HG16] [HS22] [Kag21] [KB14] [lia18] [nug17] [PB97] Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (gelus). arXiv:1606.08415, 2016. arXiv preprint Jonathan Ho and Tim Salimans. arXiv:2207.12598, 2022. Classifier-free diffusion guidance. arXiv preprint Kaggle. 1056lab-diabetes-readmission-prediction, 2021. Accessed: 2024-09-13. readmission prediction."
        },
        {
            "title": "Lab diabetes",
            "content": "https://www.kaggle.com/c/ Diederik Kingma and Jimmy Ba. Adam: method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. Home equity line of credit averkiyoliabev/home-equity-line-of-creditheloc, 2018. Accessed: 2024-09-13. https://www.kaggle.com/datasets/ (heloc) dataset. California california-housing-prices, 2017. Accessed: 2024-09-13. housing prices. https://www.kaggle.com/datasets/camnugent/ R. Kelley Pace and Ronald Barry. Sparse spatial autoregressions. Statistics & Probability Letters, 33(3):291297, 1997. [PGM+19] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems, pages 80248035, 2019. [PVG+11] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in python. Journal of Machine Learning Research, 12:28252830, 2011. [SDG+14] Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore. Impact of hba1c measurement on hospital readmission rates: Analysis of 70,000 clinical database patient records. BioMed Research International, 2014:111, 2014. [SED+88] Jack W. Smith, James E. Everhart, William C. Dickson, William C. Knowler, and Robert S. Johannes. Using the adap learning algorithm to forecast the onset of diabetes mellitus. Proceedings of the Annual Symposium on Computer Application in Medical Care, pages 261265, 1988. [tej21] Tour travels customer churn prediction dataset. tejashvi14/tour-travels-customer-churn-prediction, 2021. Accessed: 2024-09-13. https://www.kaggle.com/datasets/ 5 [XSCIV19] Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. Modeling tabular data using conditional gan. Advances in neural information processing systems, 32, 2019."
        },
        {
            "title": "A Sampling algorithm",
            "content": "threshold value to binarize pre-trained denoiser network random binary tensor condition/label apply condition enxoding Algorithm 1 Sampling algorithm. 1: xt 2: 3: ye 4: threshold 5: qθ(ˆx0, ˆzt 6: for { ˆx0, ˆzt 7: ˆx0 8: zt 9: xt 10: 11: end for 12: return xt xt, t, ye) do T, . . . , 0 } xt, t, ye) qθ(ˆx0, ˆzt σ(ˆx0) > threshold get_binary_noise(t) ˆx0 zt Default 0.5 Selected timesteps Apply sigmoid and compare to threshold Generate random noise Update xt using XOR with zt"
        },
        {
            "title": "B Evaluation models hyperparameters",
            "content": "During evaluation, we follow the evaluation proposed in [BSL+22]. The hyperparameter configuration of the evaluation models for the ML efficiency experiments are provided in Table 2. Table 2: Evaluation models hyperparameters. LR DT max_iter max_depth max_depth 6 10 6 8 10 10 100 200 500 1000 500 - 12 12 12 12 20 RF n_estimators 75 90 78 85"
        },
        {
            "title": "C Runtime comparison",
            "content": "We compare the training and sampling times, the number of training epochs, batch sizes, and peak VRAM utilization of generative models. The results, including the number of training epochs and batch sizes required for each model to converge, are summarized in Table 3. Specifically, for TVAE, CopulaGAN, and CTGAN, we employed the default batch size of 500 and trained for 200 epochs; for Distill-GReaT and GReaT, we used batch size of 32 and trained for 200 epochs; and for Binary Diffusion, batch size of 256 and 500 epochs were utilized to ensure model convergence. For this study, we utilized the Adult Income dataset. All experiments were conducted on PC with single RTX 2080 Ti GPU, an Intel Core i9-9900K CPU 3.60 GHz with 16 threads, 64 GB of RAM, and Ubuntu 20.04 LTS as the operating system. Table 3: Comparison of training and sampling times, and peak VRAM utilization. Model TVAE CopulaGAN CTGAN Distill-GReaT GReaT Binary Diffusion Epochs Batch size Training time 2 min 21 sec 4 min 26 sec 4 min 33 sec 5 7 min 7 33 min 53 min 2 sec 200 200 200 200 200 5000 500 500 500 32 32 Sampling time (s) 0.036 0.101 0.055 7.104 11.441 0.347 0.001 0.003 0.005 0.025 0.034 0.006 Peak VRAM use 240 MiB 258 MiB 258 MiB 8184 MiB 8548 MiB 266 MiB"
        },
        {
            "title": "D Implementation details",
            "content": "Denoiser Architecture. We use similar denoiser architecture across all datasets, which takes as input noisy vector xt of size d, timestep t, and an input condition y. The input size corresponds to the size of the binary vector in each dataset. The input vector xt is projected through linear layer with 256 output units. The timestep is processed using sinusoidal positional embedding, followed by two linear layers with 256 output units each, interleaved with GELU activation functions [HG16]. The input condition is processed through linear projector with 256 output units. The outputs of the timestep embedding and the condition projector are then combined via element-wise addition. This combined representation is subsequently processed by three ResNet blocks that incorporate timestep embeddings. Depending on the size of the binary representation for each dataset, the number of parameters varies between 1.1 million and 1.4 million. 10 Training and Sampling Details. We trained the denoiser for 50,000 steps using the Adam optimizer 4, weight decay of 0, and batch size of 256. To maintain [KB14] with learning rate of 1 distilled version of the denoiser, we employed an Exponential Moving Average (EMA) with decay rate of 0.995, updating it every 10 training steps. This distilled model was subsequently used for sampling. During training, we utilized classifier-free guidance with 10% probability of using zero token. The diffusion model was configured to perform 1,000 denoising steps during training. Given the relatively small size of our models, we opted for full-precision training. All training parameters are summarized in Table 4. Table 4: Binary Diffusion training details. value Adam 1e-4 0 256 500000 0.995 10 0.1 fp32 1000 config optimizer learning rate weight decay batch size training steps EMA decay EMA update frequency classifier-free guidance zero token precision diffusion timesteps We empirically observed that model performance, measured by accuracy for classification tasks and mean squared error (MSE) for regression tasks deteriorates as the number of sampling steps increases. We selected 5 sampling steps and guidance scale of 5 for all datasets to optimize performance. Table 5: Binary Diffusion sampling details. config sampling steps guidance scale EMA value 5 5 True Environment. All experiments were conducted on PC with single RTX 2080 Ti GPU, an Intel Core i9-9900K CPU 3.60 GHz with 16 threads, 64 GB of RAM, and Ubuntu 20.04 LTS as the operating system. We utilized PyTorch [PGM+19] with the Accelerate [GDW+22] library for training generative models, and the scikit-learn [PVG+11] library for evaluating models."
        },
        {
            "title": "E Effect of sampling steps",
            "content": "We empirically observed that model performance, measured by accuracy for classification tasks and mean squared error (MSE) for regression tasks, deteriorates as the number of sampling steps increases. Notably, for regression tasks, linear regression models show significantly poorer performance with an increasing number of sampling steps. For our analysis, we utilized an Exponential Moving Average (EMA) denoiser with guidance scale of 5. Across all datasets, the optimal results were consistently 8 achieved when the number of sampling steps was 5. The relationship between the number of sampling steps and model performance is illustrated in Figure 3. (a) Travel (b) Sick (c) HELOC (d) Adult Income (e) Diabetes (f) California Housing Figure 3: Analysis of model performance for different numbers of sampling steps. DT stands for Decision Tree model, RF stands for Random Forest model and LR stands for Linear/Logistic regression model."
        }
    ],
    "affiliations": [
        "Department of Computer Science, University of Geneva, Geneva, Switzerland"
    ]
}