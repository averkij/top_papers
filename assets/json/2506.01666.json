{
    "paper_title": "Synthesis of discrete-continuous quantum circuits with multimodal diffusion models",
    "authors": [
        "Florian Fürrutter",
        "Zohim Chandani",
        "Ikko Hamamura",
        "Hans J. Briegel",
        "Gorka Muñoz-Gil"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Efficiently compiling quantum operations remains a major bottleneck in scaling quantum computing. Today's state-of-the-art methods achieve low compilation error by combining search algorithms with gradient-based parameter optimization, but they incur long runtimes and require multiple calls to quantum hardware or expensive classical simulations, making their scaling prohibitive. Recently, machine-learning models have emerged as an alternative, though they are currently restricted to discrete gate sets. Here, we introduce a multimodal denoising diffusion model that simultaneously generates a circuit's structure and its continuous parameters for compiling a target unitary. It leverages two independent diffusion processes, one for discrete gate selection and one for parameter prediction. We benchmark the model over different experiments, analyzing the method's accuracy across varying qubit counts, circuit depths, and proportions of parameterized gates. Finally, by exploiting its rapid circuit generation, we create large datasets of circuits for particular operations and use these to extract valuable heuristics that can help us discover new insights into quantum circuit synthesis."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 ] - u [ 1 6 6 6 1 0 . 6 0 5 2 : r Synthesis of discrete-continuous quantum circuits with multimodal diffusion models Florian Fürrutter Institute for Theoretical Physics University of Innsbruck Zohim Chandani Quantum Algorithm Engineering NVIDIA Corporation Ikko Hamamura Quantum Algorithm Engineering NVIDIA Corporation Hans J. Briegel Institute for Theoretical Physics University of Innsbruck Gorka Muñoz-Gil Institute for Theoretical Physics University of Innsbruck"
        },
        {
            "title": "Abstract",
            "content": "Efficiently compiling quantum operations remains major bottleneck in scaling quantum computing. Todays state-of-the-art methods achieve low compilation error by combining search algorithms with gradient-based parameter optimization, but they incur long runtimes and require multiple calls to quantum hardware or expensive classical simulations, making their scaling prohibitive. Recently, machine-learning models have emerged as an alternative, though they are currently restricted to discrete gate sets. Here, we introduce multimodal denoising diffusion model that simultaneously generates circuits structure and its continuous parameters for compiling target unitary. It leverages two independent diffusion processes, one for discrete gate selection and one for parameter prediction. We benchmark the model over different experiments, analyzing the methods accuracy across varying qubit counts, circuit depths, and proportions of parameterized gates. Finally, by exploiting its rapid circuit generation, we create large datasets of circuits for particular operations and use these to extract valuable heuristics that can help us discover new insights into quantum circuit synthesis. Code, models and tutorials are publicly available at https://github.com/FlorianFuerrutter/genQC."
        },
        {
            "title": "Introduction",
            "content": "Synthesizing quantum circuits for given quantum operations is highly non-trivial task, and stands as one of the key challenges in the pursuit of large-scale quantum computation. As quantum hardware continues to improve, with increasing qubit counts and lower error rates, we move closer to regimes where quantum advantage may become feasible. Indeed, quantum computational advantage has now been widely demonstrated, as for instance in Shors factoring algorithm [1] and Grovers search [2], or in applications such as optimization [3] and machine learning [4]. However, many of these algorithms rely on large, fault-tolerant quantum computers, which remain out of reach. Despite notable advances in hardware, we are still in the era of Noisy Intermediate-Scale Quantum (NISQ) devices [5], where limited qubit connectivity and different error sources hinder quantum computation. Another practical challenge arises from the diversity of quantum computing paradigms, from gate-based quantum computers realized by photonic [6], superconducting [7], neutral atoms [8] and trapped ions [9] architectures to measurement-based quantum computation [10]. While this variety is promising and enriches the field, it also introduces difficulties: each platform features different native gate sets and qubit connectivity constraints, meaning that the optimal compilation of given operation can vary significantly from one architecture to another. To address these challenges, various powerful compilation techniques have been developed, typically involving complex pipelines composed of multiple modules [1113]. While they are able to output highly accurate circuits, these methods tend to be slow and rely on heuristics, search algorithms and gradient-based optimization, often resulting in runtimes that scale prohibitively with qubit count [12, 14]. Nonetheless, from fundamental and theoretical perspective, improving circuit synthesis depends on deeper understanding of quantum circuits and how different gate combinations give rise to different computations. Beyond purely theoretical study, achieving this requires methods that can generate circuits not only accurately but also efficiently, enabling the creation of datasets from which, when combined with expert knowledge in quantum information and computation, better compilation strategies can be discovered. In this work, we build on recent advances in machine learning-assisted quantum circuit synthesis to develop such model. Specifically, we leverage denoising diffusion models (DMs) to generate quantum circuits consisting of both discrete and parameterized gates that compile given unitary operation. Our main contributions are as follows: 1. We present method that compiles input unitaries into quantum circuits, predicting simultaneously the circuits structure (i.e., gate types and distribution) and its continuous parameters. It is based on multimodal diffusion model that couples two independent diffusion processes: one addresses the discrete task of selecting gate types, while the other proposes the corresponding continuous gate parameters. 2. We propose strategy to pre-learn noise schedules for the discrete data part of the diffusion, ensuring proper mixing of discrete classes throughout the forward diffusion processes. 3. We benchmark our model on the unitary compilation problem, showcasing its capabilities across varying qubit counts and circuit depths. 4. Leveraging the fast generation capabilities of our method, we generate large circuit datasets for specific unitaries and use these to reveal interesting structural patterns."
        },
        {
            "title": "2 Preliminaries",
            "content": "Unitary compilation The unitary compilation problem is defined by two inputs: unitary matrix of size 2n 2n, where is the number of qubits, and finite gate set, often related to the available physical operations of the quantum hardware onto which we aim to compile the unitary. Gates can be either discrete (e.g., the Hadamard or CNOT gates) or parameterized, in which case they are defined by type and parameter θ that can vary continuously (e.g., the X-rotation gate Rx(θ), with θ [0, 4π] [15]). The output of the problem is quantum circuit, i.e., sequence of quantum gates drawn from the specified gate set that implements on quantum hardware. Given circuit C, we define its distance to the target unitary via its unitary representation UC, using the infidelity: = 1 1 4n Tr(U CU)2, with = 0 for UC = up to global phase, and 0 1. (1) Unitary compilation is fundamental task in quantum computation and has therefore received significant attention. While the Solovay-Kitaev theorem ensures efficient compilation for singlequbit gates [16], no guarantees exist for multi-qubit systems. In this regime, variety of heuristic, search-based, gradient-based, and machine learning methods have been explored. Approaches such as [1214, 17] alternate between searching for circuit structure and optimizing gate parameters until they reach desired error threshold. These methods achieve high fidelity but at the expense of long runtimes and deep circuits. In recent years, machine learning has had substantial impact on the field [18]. For example, Ref. [19] proposed the use of graph neural networks to improve the ansatz selection within the aforementioned iterative framework, while [20] achieves this via reinforcement learning. In the latter, an agent is trained to sequentially place gates in circuit and is rewarded when the resulting unitary closely approximates the target (see also [2126]). Importantly, all previous methods consider cost functions or rewards that require the simulation of the proposed circuit, classically hard computation which motivated the development of methods working natively on quantum computers [27]. Another approach to circumvent this bottleneck is to 2 Figure 1: Multimodal quantum circuit synthesis pipeline scheme. a) An input circuit is first tokenized and then embedded into two separate modes, from which the forward and backward diffusion processes are defined. b) Schematic of the generative model. See Section 3.1 and Section 3.2 for details. train generative model on dataset of labeled circuits, as done for instance in Ref. [28]. Although generating and labeling such dataset is computationally expensive, once it is built, all further training is purely classical. In this direction, Ref. [29] proposed the use of DMs for quantum circuit synthesis, albeit demonstrated only on discrete gate sets and circuits with up to three qubits for unitary compilation. Gaussian diffusion models Diffusion models (DM) are class of generative models that aim to learn the underlying probability distribution pdata(x) of dataset. Starting from clean data sample x, the forward diffusion process defines sequence of latent variables {zt}t[0,1] := z0:1, where each zt is progressively noisier version of starting at = 0. The objective of the model is to recover the original sample from noisy observation zt. In continuous domains, this process can be formalized either as stochastic differential equation (SDE) [30] or equivalently as discrete-time Markov chain [31]. In the case of Gaussian diffusion, the transition probability from zt given is defined as q(ztx) = (zt; (2) where the components of are independently corrupted and αt, βt [0, 1] are the noise schedule coefficients, monotonically decreasing and increasing functions of t. common choice is the variancepreserving model, where βt = 1 αt. From here, one defines the signal-to-noise-ratio (SNR) as SNR(t) := αt/ (1 αt). In this notation, the diffusion process maps samples with negligible noise at small times (limt0 SNR(t) ) to fully noisy representations (SNR(t = 1) = 0). αtx, βtI), Diffusion models are trained by maximizing the evidence lower bound (ELBO) of the log-likelihood of [31]. Once the DM is trained, sampling is typically performed via ancestral sampling: starting from fully complete noisy latent z1 (0, I), one follows the reverse transitions p(zszt) for 0 < 1 until reaching clean sample at = 0, as for instance described in Ref. [31]. Multimodal diffusion models Multimodal diffusion models (DMs) address the generation of samples composed of multiple modes. Recent works explored embedding multimodal data into joint latent representation and applying single Gaussian diffusion process [32, 33]. Other approaches rather consider two identical Gaussian processes [34, 35]. On the other hand, previous works have also explored generation via separated diffusion processes as, e.g., in Ref. [36] by combining Gaussian with multinomial diffusion or in Ref. [37] using Gaussian and masked diffusion process."
        },
        {
            "title": "3 Methods",
            "content": "3.1 Multimodal diffusion process To perform simultaneous generation of discrete and parameterized gates, we represent each quantum circuit as combination of two different modes: discrete (categorical) mode h0 that encodes the gate types, and continuous mode w0 that specifies the values of the parameterized gates. We then design the forward process of the DM as two independent diffusion processes, each acting on its respective data mode (Fig. 1a). This separation allows us to construct mode-specific embeddings, tailored to the characteristics of each data type. In particular, we set the joint probability of the 3 trajectories h0:1 and w0:1 of the forward process as the product of the independent joint distributions: q(h0:1, w0:1x) = q(h0:1x) q(w0:1x), (3) and αw /(1 αh where the separate distributions are defined via the standard Gaussian diffusion (see Eq. (2)). Although the forward process in Eq. (2) is already component-independent, we further consider here that each diffusion process has different noise schedule, namely αh , with the corresponding signalt ) and SNRw(t) := αw to-noise ratios SNRh(t) := αh This mode separation is motivated by the observation that both the choice of diffusion schedule and the design of data embeddings play crucial role in shaping the behavior of the diffusion process. In particular, as categorical data are sparsely distributed in the latent space, it requires tuned noise schedules that gradually mix the different classes before reaching full noise. In this sense, accurately selecting both the noise schedule and its weighting in the loss has significant influence on the training efficiency of DMs, as often studied [3842]. In this direction, we show in Section 3.2 and Section 3.3 that to effectively model discrete data in Gaussian diffusion model, it is crucial to choose suitable noise schedule, and present learning procedure to appropriately match the token embeddings. /(1 αw ). Generative model Given condition c, we set our conditional generative model pθ(x, h0:1, w0:1c) to general formulation: pθ(x, h0:1, w0:1c) = p(xh0, w0) pθ(h0:1, w0:1c), (4) where p(xh0, w0) is the embedding decoder transforming the latent representation back to the circuit picture, and pθ(h0:1, w0:1c) depends on our sampling approach (see App. A.1). Following Ref. [34], we define reverse transition model that accounts for: (i) all marginal distributions pθ(h0:1c) and pθ(w0:1c); (ii) all conditional distributions pθ(h0:1w0, c) and pθ(w0:1h0, c); (iii) and the joint pθ(h0:1, w0:1c). Specifically, pθ(hs, wsht, wt, c) = q(hs, wsht, wt, = ˆxθ(ht, wt, t, t, c)), (5) where 0 < 1 and 0 < 1 are independent diffusion times, and q(hs, wsht, wt, x) is the true top-down posterior given data sample (see App. A.2 for the exact derivation). Here, we note that the diffusion model ˆxθ predicts the denoised circuit implicitly by predicting both modes (see Fig. 1b). This is possible as the top-down posterior splits up for given due to the independent forward diffusion, allowing us to rewrite pθ(hs, wsht, wt, c) = pθ(hsht, wt, c) pθ(wswt, ht, c), where the model captures the correlations between hs and ws by jointly predicting [h0(x), w0(x)] = ˆxθ(ht, wt, t, t, c). Following the independent forward diffusion in Eq. (3), the joint distribution at the final timestep = 1 is the product of two independent standard normal distributions, p(h1, w1) = p(h1) p(w1). In addition, we sample the marginal distributions in (i) by conditioning on the fully noisy version of the other mode. For instance, pθ(h0:1c) is sampled via pθ(hsht, w1, c) and vice versa. On the other hand, following the classifier-free guidance (CFG) approach [43], the condition is randomly replaced with an empty condition ϕ during training with fixed probability, enabling condition-free sampling. (6) Loss Using the velocity parametrization picture [44], the model presented in Eq. (6) is trained by minimizing the loss function (see details in App. A.3) (x,c)pdata, (t,t)U (0,1), (ht,wt)q(ht,wtx) (cid:104) ωh(t)(cid:13) (cid:13)vh vh θ 2 + ωw(t)(cid:13) (cid:13) 2 (cid:13) (cid:13)vw vw θ (cid:105) , (cid:13) 2 (cid:13) 2 (7) where the labeled pairs (x, c) are samples from the dataset distribution pdata. The two diffusion times, and t, are independently drawn from uniform distribution. The noisy latents ht and wt are sampled from the independent Gaussian forward processes (see Eq. (3)), each being sampled via Eq. (2). The velocity parametrization replaces the predictor ˆxθ by ˆvθ, which outputs jointly ϵh θ , vw [vh (cid:112)1 αh = (cid:112)αw w0. This choice of the target velocities ensures that the model outputs have unit variance, i.e., Var[vh w] = 1, assuming that the embeddings are normalized such that Var[h0] = Var[w0] = 1. θ ] = ˆvθ(ht, wt, t, t, c) (see Fig. 1b). The corresponding targets are then set to vh ϵw (cid:112)1 αw = (cid:112)αh h0 and vw ] = Var[vt 4 For the weighting terms ωh(t) and ωw(t), we use the sigmoid method introduced in [42], which relates the weight in the denoising prediction view ˆxθ to the SNR, given by ωx(t) = sigmoid [log(SNR(t))]. For velocity prediction, this relation has to be translated with ωx(t) = (SNR(t) + 1) ωv(t) (see App. A.4). Since we only use velocity prediction, we omit the subscript from here on, and incorporate the corresponding factor (SNRi(t) + 1)1 = (1 αi t) into ωi(t) for {h, w} when defining the weights in Eq. (7). In Section 3.2 and Section 3.3, we generalize the log-SNR to both discrete and continuous modes, providing definitions for ωh(t) and ωw(t) accordingly. Unitary condition In this work, the models conditioning consists of two parts: the unitary to be compiled and text prompt specifying the available gates (see Fig. 1b). We first create the embeddings of the text prompts with pretrained OpenCLIP [45]. Second, we train custom UnitaryCLIP which contrastively learns to encode quantum circuit and unitary together with the gate set embedding into joint latent space (see App. G). After that, the unitary encoder model is frozen and the latent embeddings arising from given unitaries and prompts are used as conditioning of the DM. 3.2 Circuit encoding and embedding In this section, we describe the method used to transform quantum circuit into suitable embedding. For each mode, we consider fixed deterministic encoders q(h0x) and q(w0x). The decoder p(xh0, w0) is likewise fixed. Following Ref. [29], the gates of given circuit are first tokenized (see Fig. 1a). Then, each gate is represented by tuple (k, λ), where is the token and λ [1, 1] the normalized continuous parameter, equal to zero for discrete gates. Token embedding Token embeddings are typically implemented as look-up tables containing dh-dimensional entries h(i) 0 Rdh , where = 0, . . . , 1 indexes the different classes. During decoding, given embedding is mapped to the closest token in the table based on distance metric. To ensure that all embeddings are equidistant and undergo uniform mixing throughout the diffusion process, we construct them as an orthogonal basis of Rdh (more in App. B.1). This orthogonality not only balances the embedding space but also enables us to leverage the duality between uniform discrete-state diffusion and continuous-state Gaussian diffusion [46]. To study the impact of the noise schedule αh on these embeddings, we plot in Fig. 2a the averaged Hamming distance between the decoded embedding at each step and the original token. We observe that standard schedules, such as the cosine schedule [38], fail to sufficiently mix the embeddings, causing the decoded token to remain unchanged over extended times of the diffusion process. This behavior leads to inefficient training, as little signal is provided for learning. Ideally, the noise schedule should induce gradual and consistent mixing across time. To this end, in Section 3.3 we introduce method for learning noise schedule tailored to the desired token embeddings mixing. Parameter embedding The continuous parameters λ are embedded into two-dimensional plane following w0(λ) = cos(λπ)v1 + sin(λπ)v2, where v1, v2 Rdw . This accounts for the periodic rotation angles of the gates. An encoded noisy wt(λ) can be decoded back to parameter ˆλt by using the arctanh2 (see App. B.2). As done above, we study the effect of different noise schedules on such an embedding. We analyze in this case the CircularLoss(t) := 1 cos((λ ˆλt)π) (Fig. 2b). As expected, the choice of noise schedule influences the rate at which the decoded parameter ˆλt approaches the uniform distribution. Following the previous definition, the SNR associated with this embedding can be estimated as SNRλ(t) := SNRw(t) π2dw. Following this, we set ωw(t) := (1 αw ) sigmoid[log(SNRλ(t))] in Eq. (7) (see full derivation in App. A.5). 3.3 Learned noise schedule for discrete tokens Following the observations of the previous section, we construct here noise schedule αh that gradually mixes the input gate tokens, minimizing the time of trivial denoising. Using the duality between uniform discrete-state diffusion and continuous-state Gaussian diffusion [46], we write the probability of finding decoded, one-hot encoded token kt RN for discrete schedule at as p(ktk) = Cat(kt; atk + (1 at)I/N ). (8) 5 Figure 2: Noise schedules and loss weighting. a) Averaged Hamming distance between an initial token h0 and the decoded embedding of ht over the diffusion time t. Dashed lines represent target schedules and solid lines represent the learned ones (see Section 3.3). b) Circular loss between initial parameter λ and the decoded parameter ˆλt over the diffusion time for different noise schedules. c) Loss weighting for the discrete (ωh(t)) and continuous (ωw(t)) modes used in Eq. (7) over the diffusion time, chosen such that their total areas roughly match. From this, we define the SNR of the discrete mode as the fraction of the original amplitude to the one of the uniform distribution: SNRdiscrete(t) := at/(1 at). In previous approaches [46], one first specifies the Gaussian diffusion schedule αh , to then obtain at. Here, we take the reverse approach: we begin by specifying the desired level of mixing among discrete tokens, and then infer the corresponding αh . To this end, we define an analogue to the average Hamming distance (t), namely the probability pflip(t) of token initially belonging to class being decoded as any other class = at time t: pflip(t) = 1 q(h(i) h(i) (cid:20) softmaxj (cid:18) 1 τ (cid:68) h(j) 0 (cid:12) (cid:12)h(i) (cid:12) (cid:69)(cid:19)(cid:21) , h(i) 0 ) (9) where τ > 0 is temperature. Analogous to the average Hamming distance, this probability is upper bounded by 1 1/N , i.e., when h(i) is sampled from the uniform distribution (see = 1 at Fig. 2a). in q(h(i) We then use this definition to learn the appropriate coefficients αh 0 ) (see Eq. (2)) for desired Hamming distance ftarget(t). This is achieved by minimizing the mean-squared error loss E[pflip(t) ftarget(t)2] w.r.t. αh . In Fig. 2a we show few examples of desired ftarget(t) (dashed lines) and their corresponding optimized Hamming distance profiles (solid lines). This training occurs prior to the training of the diffusion model itself, and offers the advantage of directly enforcing the desired token mixing behavior, bypassing the need for manual tuning of known schedules. Next, to determine the appropriate weight ωh(t) in Eq. (7), we combine Eq. (8) and Eq. (9) to find that we get the relation at = 1 pflip(t)/pflip(1) (see App. A.6). From this, we derive SNRdiscrete(t) (ftarget(1) ftarget(t))/ftarget(t), which we then use to define ωh(t) := (1 αh ) sigmoid[log(SNRdiscrete(t))]. h(i) Finally, to balance the two loss terms in Eq. (7), we compute the area under each weighting curve ωh(t) and ωw(t) (Fig. 2c). We then select noise schedules for the discrete and continuous modes such that their corresponding areas are approximately equal, thereby implicitly balancing the two expectations without requiring an additional weighting factor. 3.4 Gate-Pair tokenization In natural language processing, Byte-Pair Encoding (BPE) [47] is widely used technique for subword tokenization. Since our circuits are already tokenized, it is natural to extend BPE to the domain of quantum circuits. To this end, we generalize the notion of byte pairs to pairs of consecutive quantum gates that are sequentiali.e., those acting on at least one common qubit. Once candidate gate pairs are identified, we normalize their qubit connections to account for permutations, ensuring that we capture generalizable patterns of higher-order gates rather than qubit-specific configurations. We then count the frequency of each pair, select the most frequent one, assign it new token, and replace all occurrences in the current dataset, repeating the process until reaching predefined minimum frequency threshold. In Section 4.4, we demonstrate how this Gate-Pair Encoding (GPE) scheme can be employed to automatically extract reusable substructures (gadgets) from generated circuits corresponding to specific unitaries."
        },
        {
            "title": "4 Experiments",
            "content": "4.1 Experimental Setup We present here the main information on the training of the model discussed in previous sections. Further details can be found in App. D. Training dataset Using CUDA-Q [48], we generate training dataset of random 3 to 5 qubit circuits. To that end, we uniformly sample 4 to 32 gates from the gate set {h, cx, ccx, swap, rx, ry, rz, cp}. The continuous parameters of the parameterized gates are also sampled uniformly on their support. The model used throughout this work is trained on dataset of 63 million unitary-circuit pairs. Models, training and inference The model presented here, named Circuit-Diffusion-Transformer (CirDiT), is based on the diffusion transformer architecture [49], and contains 257 million parameters. Training is performed on 16 NVIDIA A100 GPUs for 500k update steps, with an effective batch size of 2048. The training time is roughly 800 GPU hours. We use the Adam optimizer [50] together with one-cycle learning rate strategy [51]. We use learned linear noise schedule for the discrete mode (see Section 3.3) and fixed schedule for the continuous mode. Once trained, we sample from the model using the CFG++ [52] variant of DPM++2M [53] for 40 time steps. 4.2 Benchmark on random unitaries We first benchmark the model by compiling circuits from test set of unitaries mimicking the properties of the training dataset (see App. E.1 for details). We then compute the infidelity, Eq. (1), between the unitary representation of the output circuit and the target one. We present in Fig. 3a and the distribution of infidelities for all generated circuits and that of the circuits with the lowest infidelity, respectively, using target unitaries of 3 to 5 qubit circuits consisting of up to 16 gates, demonstrating that the model successfully compiles these unitaries with low infidelity. We observe characteristic peaks in the infidelity distribution around = 0.4, 0.8, and 1, which are attributed to the misplacement of one or two discrete gates, rather than errors in the continuous parameters of parameterized gates (see App. I). Moreover, we also observe that the models accuracy remains stable with increasing qubit count. However, we observe significant drop in performance as gate count increases. To further investigate these trends, we show in Fig. 3c the infidelity as function of the gate count and the percentage of parameterized gates. As mentioned, we observe strong dependence on the number of gates: deeper circuits are harder to compile accurately. In contrast, we find no significant Figure 3: Compilation of random unitaries. a) Histogram of infidelities for 1024 unitaries and 128 circuits sampled per unitary (up to 16 gates). b) Histogram of minimum infidelity for each of the 1024 unitaries in a). The insets showcase the same plot but in logarithmic scale. c) Best infidelity over 128 circuits for unitaries of varying gate count and percentage of parameterized gates. 7 Figure 4: Hamiltonian evolution. a, b) Minimum infidelities over 128 circuits for different parameters of the Ising and XXZ Hamiltonian, respectively, at τ = 0.25. c) Minimum infidelities over 128 circuits for different evolution times τ for both Hamiltonians with 3 qubits and various parameters, color matching the highlighted points in and panels. The vertical dashed is placed at τ = 0.25. correlation between accuracy and the percentage of parameterized gates, indicating that the model handles both discrete and continuous gates with comparable effectiveness. 4.3 Hamiltonian evolution We now evaluate the models performance in practical setting. We consider here the compilation of unitary, U(τ ) = exp(iτ H), that encodes the evolution of system under Hamiltonian for time τ . This task, which involves decomposing the exponential operator into smaller operations, is commonly referred to as trotterization, and plays central role in simulating quantum dynamics on quantum computers. We consider here two paradigmatic: the Ising and Heisenberg XXZ models (see App. J). In Fig. 4a, b, we show that the model generates accurate circuits across the phase space of both models and for different qubit counts. We observe that the infidelity slightly increases in regions of the phase space where the evolved state exhibits higher entanglement, causing the need to deeper circuits, following the trend observed in Section 4.2. In Fig. 4c, d, we display the infidelity as function of τ for various points in the phase space. As before, larger values of τ typically result in more entangled states and, consequently, more complex circuits, which increases the infidelity. However, in some cases, the evolution induces an oscillatory behavior in the entanglement of the resulting state. This effect is especially pronounced for the Ising model at and for the XXZ at J, = 0.8, where accuracy improves due to the lower circuit complexity. 4.4 Identifying structures in generated circuits One of the advantages of the proposed model with respect to previous approaches is its sampling efficiency, enabling the fast generation of large numbers of candidate circuits for an input unitary. While not all of these circuits may have the desired infidelity, we find that the errors typically arise from the misplacement of single or few gates, with the overall circuit structure being generally correct. In this section, we demonstrate how to exploit the full set of generated circuits for specific unitaries to uncover hidden structural patterns, gadgets, and distributions over continuous parameters. Quantum Fourier transform The QFT is quantum algorithm that exhibits an exponential advantage over its classical counterpart, the discrete Fourier transform [54]. From circuit perspective, the algorithm provides an efficient construction composed of three types of gates: Hadamard (H), Swap, and parameterized controlled-phase gates (CP(θ)). When generating 2048 circuits from the QFT unitary, we obtain circuits with minimum infidelities of 5 103, 1.9 102, and 6.2 102 for 3, 4 and 5 qubits, respectively. For the remainder of this analysis, however, we consider all generated circuits regardless of their infidelity. Examining the histogram of gate types (Fig. 5a), we find that the model predominantly predicts the expected gates. 8 Figure 5: Circuit structure analysis. a, b, c) Gate distribution, angle distribution for the CP(θ) gates and most recurring gate sequences for circuits generated for the 4-qubit QFT. c, d, f) and g, h, i) Gate distribution for two points of the phase space (see titles) and most recurring gate sequences for the Ising (left) and XXZ (right) Hamiltonians, each for 4-qubits. Furthermore, the distribution of predicted angles for the controlled-phase gate (Fig. 5b) approximately matches the known target distribution (dashed lines). By performing GPE (see Section 3.4), we are able to recover the building blocks of the standard QFT compilation protocol (see Fig. 5c and App. for further examples). These findings suggest that, under the considered gate set, no alternative compilation strategies exist or may offer limited improvement over the canonical construction. Hamiltonian evolution We now examine the circuits generated for the Hamiltonian evolutions introduced in Section 4.3. First, we focus on the Ising model. At = 0 (Fig. 5d), the Hamiltonian contains only the transverse-field term, consisting solely of single-qubit operators, that the model correctly compiles with single-qubit rotations (Rx) and Swap gates. The latter gate is redundant and we believe it is placed by the model due to its slight bias on producing longer circuits. Conversely, when = 0 (Fig. 5e), the unitary reduces to parameterized interaction, which the model decomposes via CNOTs together with parameterized Rz(θ) and CP(θ). The gadgets extracted via GPE visually highlight the previous findings (Fig. 5f). Second, we analyze the circuits generated for the XXZ model. Here, we fix the transverse field at = 0.2 and vary coupling and (see App. J). For = 0, the Hamiltonian contains an + interaction, known in quantum computing as an iSWAP gate. Because iSWAP is not in our gate set, the model instead decomposes this interaction using CNOTs, Toffoli and CP(θ) gates (Fig. 5g), which interestingly differs from the usual decomposition with Rz(π/2), CNOT and gates [55]. On the other hand, when both = 0 and = 0 , term enters the dynamics, and we observe marked increase in the usage of and CP(θ) gates, which surprisingly varies from this terms decomposition in the Ising case (Fig. 5h). Again, by inspecting the GPE (Fig. 5i), we observe clearly the striking differences between the properties of the same Hamiltonian in two different points of its phase space."
        },
        {
            "title": "5 Discussion",
            "content": "In this work we introduced multimodal diffusion model that jointly synthesizes the gate sequence and continuous parameters of quantum circuit. To do so, we leverage two independent diffusion processes, one for the discrete mode and one for the continuous mode. This separation lets each mode be sampled and potentially improved in isolation. For example, we envision that masked diffusion and autoregressive decoding could further improve the discrete mode prediction. From an application perspective, although we focused on unitary compilation, the same pipeline can be adapted to tasks such as state preparation, eigensolvers, error-correction decoding, or circuit design for photonic and measurement-based platforms. Two main limitations remain: accuracy and scalability. On the former, we have shown that the models fidelity still trails full search-plus-gradient pipelines [1113], and its performance degrades with increasing gate counts (Section 4.2). We expect that better training protocols and sampling improvements as mentioned above will close much of this gap. Moreover, existing pipelines can leverage the sampling efficiency of the model, proposing already accurate candidate circuits from which further optimization can be performed. On the other hand, the quantum nature of the problem makes scalability an important bottleneck. For instance, the input unitary matrix grows exponentially 9 with qubit count. Future work should explore better conditionings, as for instance directly inputting the Hamiltonians used in Section 4.3 in text form. Moreover, compared with DMs that handle images consisting of thousands of pixels, our circuits are much smaller in token count, so scaling the architecture is plausible. The real challenge is conceptual: deeper circuits encode harder quantum tasks and will likely require smarter representations, e.g., compressing the dataset with the gate-pair encodings discussed in Section 4.4 or similar approaches [5658]."
        },
        {
            "title": "Acknowledgments",
            "content": "This research was funded in part by the Austrian Science Fund (FWF) [SFB BeyondC F7102, 10.55776/F71]. For open access purposes, the author has applied CC BY public copyright license to any author accepted manuscript version arising from this submission. This work was also supported by the European Union (ERC Advanced Grant, QuantAI, No. 101055129). The views and opinions expressed in this article are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council - neither the European Union nor the granting authority can be held responsible for them. This research used resources of the National Energy Research Scientific Computing Center (NERSC), Department of Energy User Facility using NERSC award ERCAP0032002."
        },
        {
            "title": "Code and data availability",
            "content": "All the resources necessary to reproduce the results in this paper are accessible in Ref. [59]. The code is given in the form of Python library, genQC, which allows the user to train new models or generate circuits from pre-trained models. The library also contains multiple tutorials that will guide the user through the various applications of the proposed method. The training dataset is not shared due to space constraints, but can be generated with the released code. All necessary details are provided in Section 3, Section 4 and the Supplementary Material."
        },
        {
            "title": "References",
            "content": "[1] P. W. Shor. Algorithms for quantum computation: discrete logarithms and factoring. In: Proceedings 35th annual symposium on foundations of computer science. Ieee. 1994, pp. 124 134. [2] L. K. Grover. fast quantum mechanical algorithm for database search. In: Proceedings of the twenty-eighth annual ACM symposium on Theory of computing. 1996, pp. 212219. [3] H. Munoz-Bauza and D. Lidar. Scaling advantage in approximate optimization with quantum annealing. In: Physical Review Letters 134.16 (2025), p. 160601. [4] Y. Liu, S. Arunachalam, and K. Temme. rigorous and robust quantum speed-up in super- [5] vised machine learning. In: Nature Physics 17.9 (2021), pp. 10131017. J. Preskill. Quantum computing in the NISQ era and beyond. In: Quantum 2 (2018), p. 79. DOI: 10.22331/q-2018-08-06-79. [6] L. S. Madsen et al. Quantum computational advantage with programmable photonic processor. In: Nature 606.7912 (2022), pp. 7581. [7] F. Arute et al. Quantum supremacy using programmable superconducting processor. In: Nature 574.7779 (2019), pp. 505510. [8] D. Bluvstein et al. Logical quantum processor based on reconfigurable atom arrays. In: Nature 626.7997 (2024), pp. 5865. [9] T. Monz et al. Realization of scalable Shor algorithm. In: Science 351.6277 (2016), pp. 10681070. [10] H. J. Briegel et al. Measurement-based quantum computation. In: Nature Physics 5.1 (2009), pp. 1926. DOI: 10.1038/nphys1157. [11] E. Younis et al. Qfast: Conflating search and numerical optimization for scalable quantum circuit synthesis. In: 2021 IEEE International Conference on Quantum Computing and Engineering (QCE). IEEE. 2021, pp. 232243. [12] L. Madden and A. Simonetto. Best approximate quantum compiling problems. In: ACM Transactions on Quantum Computing 3.2 (2022), pp. 129. 10 [13] H. R. Grimsley et al. An adaptive variational algorithm for exact molecular simulations on quantum computer. In: Nature communications 10.1 (2019), p. 3007. [14] M. G. Davis et al. Towards optimal topology aware quantum circuit synthesis. In: 2020 IEEE International Conference on Quantum Computing and Engineering (QCE). IEEE. 2020, pp. 223234. [15] M. A. Nielsen and I. L. Chuang. Quantum computation and quantum information. Cambridge university press, 2010. [16] C. M. Dawson and M. A. Nielsen. The solovay-kitaev algorithm. In: arXiv preprint quantph/0505030 (2005). [17] Y. Du et al. Quantum circuit architecture search for variational quantum algorithms. In: npj Quantum Information 8.1 (2022), p. 62. [18] M. Krenn et al. Artificial intelligence and machine learning for quantum technologies. In: Physical Review 107.1 (2023), p. 010101. [19] Z. He et al. GNN-based predictor for quantum architecture search. In: Quantum Information Processing 22.2 (2023), p. 128. DOI: 10.1007/s11128-023-03881-x. [20] M. Ostaszewski et al. Reinforcement learning for optimization of variational quantum circuit architectures. In: Advances in Neural Information Processing Systems 34 (2021), pp. 18182 18194. DOI: 10.48550/arXiv.2103.16089. [21] A. Bolens and M. Heyl. Reinforcement learning for digital quantum simulation. In: Physical Review Letters 127.11 (2021), p. 110502. DOI: 10.1103/PhysRevLett.127.110502. [22] A. A. Melnikov et al. Active learning machine learns to create new quantum experiments. In: Proceedings of the National Academy of Sciences 115.6 (2018), pp. 12211226. DOI: 10.1073/pnas.1714936115. [23] S. Rietsch et al. Unitary synthesis of clifford+ circuits with reinforcement learning. In: 2024 IEEE International Conference on Quantum Computing and Engineering (QCE). Vol. 1. IEEE. 2024, pp. 824835. [24] L. Moro et al. Quantum compiling by deep reinforcement learning. In: Communications [25] Physics 4.1 (2021), p. 178. DOI: 10.1038/s42005-021-00684-3. J. Olle et al. Simultaneous discovery of quantum error correction codes and encoders with noise-aware reinforcement learning agent. In: npj Quantum Information 10.1 (2024), pp. 1 17. [26] F. Preti et al. Hybrid discrete-continuous compilation of trapped-ion quantum circuits with deep reinforcement learning. In: Quantum 8 (2024), p. 1343. [27] S. Khatri et al. Quantum-assisted quantum compiling. In: Quantum 3 (2019), p. 140. DOI: 10.22331/q-2019-05-13-140. [28] K. Nakaji et al. The generative quantum eigensolver (GQE) and its application for ground state search. In: arXiv preprint arXiv:2401.09253 (2024). [29] F. Fürrutter, G. Muñoz-Gil, and H. J. Briegel. Quantum circuit synthesis with diffusion models. In: Nature Machine Intelligence 6.5 (2024), pp. 515524. [30] T. Karras et al. Elucidating the design space of diffusion-based generative models. In: [31] Advances in neural information processing systems 35 (2022), pp. 2656526577. J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models. In: Advances in neural information processing systems 33 (2020), pp. 68406851. [32] C. Chen et al. Diffusion Models for Multi-Task Generative Modeling. In: The Twelfth International Conference on Learning Representations. 2024. URL: https://openreview. net/forum?id=cbv0sBIZh9. J. Si et al. TabRep: Training Tabular Diffusion Models with Simple and Effective Continuous Representation. In: arXiv preprint arXiv:2504.04798 (2025). [33] [34] F. Bao et al. One transformer fits all distributions in multi-modal diffusion at scale. In: International Conference on Machine Learning. PMLR. 2023, pp. 16921717. [35] L. Ruan et al. Mm-diffusion: Learning multi-modal diffusion models for joint audio and video generation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023, pp. 1021910228. [36] A. Kotelnikov et al. Tabddpm: Modelling tabular data with diffusion models. In: International Conference on Machine Learning. PMLR. 2023, pp. 1756417579. 11 [37] J. Shi et al. TabDiff: Multi-Modal Diffusion Model for Tabular Data Generation. In: arXiv preprint arXiv:2410.20626 (2024). [38] A. Q. Nichol and P. Dhariwal. Improved denoising diffusion probabilistic models. In: International conference on machine learning. PMLR. 2021, pp. 81628171. [39] D. Kingma and R. Gao. Understanding diffusion objectives as the elbo with simple data augmentation. In: Advances in Neural Information Processing Systems 36 (2023), pp. 65484 65516. [40] T. Hang et al. Efficient diffusion training via min-snr weighting strategy. In: Proceedings of the IEEE/CVF international conference on computer vision. 2023, pp. 74417451. [41] T. Hang et al. Improved noise schedule for diffusion training. In: arXiv preprint arXiv:2407.03297 (2024). [42] E. Hoogeboom et al. Simpler diffusion (sid2): 1.5 fid on imagenet512 with pixel-space [43] diffusion. In: arXiv preprint arXiv:2410.19324 (2024). J. Ho and T. Salimans. Classifier-free diffusion guidance. arXiv:2207.12598 (2022). In: arXiv preprint [44] T. Salimans and J. Ho. Progressive Distillation for Fast Sampling of Diffusion Models. In: International Conference on Learning Representations. [45] G. Ilharco et al. OpenCLIP. July 2021. DOI: 10 . 5281 / zenodo . 5143772. URL: https : //doi.org/10.5281/zenodo.5143772. [46] S. S. Sahoo et al. The Diffusion Duality. In: ICLR 2025 Workshop on Deep Generative Model in Machine Learning: Theory, Principle and Efficacy. [47] P. Gage. new algorithm for data compression. In: The Users Journal 12.2 (1994), pp. 2338. [48] NVIDIA. CUDA-Q. 2025. URL: https://nvidia.github.io/cuda-quantum/latest/ index.html (visited on 05/14/2025). [49] W. Peebles and S. Xie. Scalable diffusion models with transformers. In: Proceedings of the IEEE/CVF international conference on computer vision. 2023, pp. 41954205. [50] D. P. Kingma and J. Ba. Adam: method for stochastic optimization. In: arXiv preprint arXiv:1412.6980 (2014). [51] L. N. Smith and N. Topin. Super-convergence: Very fast training of neural networks using large learning rates. In: Artificial intelligence and machine learning for multi-domain operations applications. Vol. 11006. SPIE. 2019, pp. 369386. [52] H. Chung et al. Cfg++: Manifold-constrained classifier free guidance for diffusion models. In: arXiv preprint arXiv:2406.08070 (2024). [53] C. Lu et al. Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models. In: arXiv preprint arXiv:2211.01095 (2022). [54] D. Coppersmith. An approximate Fourier transform useful in quantum factoring. In: arXiv preprint quant-ph/0201067 (2002). [55] N. Schuch and J. Siewert. Natural two-qubit gate for quantum computation using the XY interaction. In: Physical Review 67.3 (2003), p. 032301. [56] L. M. Trenkwalder et al. Automated gadget discovery in the quantum domain. In: Machine Learning: Science and Technology 4.3 (2023), p. 035043. [57] A. Kundu and L. Sarra. From Easy to Hard: Tackling Quantum Problems with Learned [58] Gadgets For Real Hardware. In: arXiv preprint arXiv:2411.00230 (2024). J. Olle, O. M. Yevtushenko, and F. Marquardt. Scaling the Automated Discovery of Quantum Circuits via Reinforcement Learning with Gadgets. In: arXiv preprint arXiv:2503.11638 (2025). [59] F. Fürrutter and G. Muñoz-Gil. genQC v0.2: Synthesis of discrete-continuous quantum circuits with multimodal diffusion models. Version v0.2.0. 2025. DOI: 10.5281/zenodo.10282060. URL: https://doi.org/10.5281/zenodo.10282060. [60] D. Kingma et al. Variational diffusion models. In: Advances in neural information processing systems 34 (2021), pp. 2169621707. [61] X. Liu, C. Gong, and Q. Liu. Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow. In: The Eleventh International Conference on Learning Representations (ICLR). 2023. 12 [62] H. Cramér. Mathematical methods of statistics. Princeton university press, 1946. [63] P. Zhang et al. Tackling the singularities at the endpoints of time intervals in diffusion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024, pp. 69456954. [64] S. Lin et al. Common diffusion noise schedules and sample steps are flawed. In: Proceedings of the IEEE/CVF winter conference on applications of computer vision. 2024, pp. 54045411. [65] S. Sahoo et al. Simple and effective masked diffusion language models. In: Advances in Neural Information Processing Systems 37 (2024), pp. 130136130184. [66] A. Hatamizadeh et al. Diffit: Diffusion vision transformers for image generation. In: European Conference on Computer Vision. Springer. 2024, pp. 3755. [67] F. Barbero et al. Round and Round We Go! What makes Rotary Positional Encodings useful? In: The Thirteenth International Conference on Learning Representations. 2025. URL: https://openreview.net/forum?id=GtvuNrk58a. [68] B. Zhang and R. Sennrich. Root mean square layer normalization. In: Advances in Neural Information Processing Systems 32 (2019). [69] R. Xiong et al. On Layer Normalization in the Transformer Architecture. In: Proceedings of the 37th International Conference on Machine Learning. Ed. by H. D. III and A. Singh. Vol. 119. Proceedings of Machine Learning Research. PMLR, 2020, pp. 1052410533. URL: https://proceedings.mlr.press/v119/xiong20b.html. [70] L. Zhuo et al. Lumina-next: Making lumina-t2x stronger and faster with next-dit. In: arXiv preprint arXiv:2406.18583 (2024). [71] A. Radford et al. Learning Transferable Visual Models From Natural Language Supervision. In: Proceedings of the 38th International Conference on Machine Learning. Ed. by M. Meila and T. Zhang. Vol. 139. Proceedings of Machine Learning Research. PMLR, 2021, pp. 8748 8763. URL: https://proceedings.mlr.press/v139/radford21a.html. [72] A. Vaswani et al. Attention is All you Need. In: Advances in Neural Information Processing Systems. Ed. by I. Guyon et al. Vol. 30. Curran Associates, Inc., 2017. URL: https : / / proceedings . neurips . cc / paper _ files / paper / 2017 / file / 3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf. 13 Synthesis of discrete-continuous quantum circuits with multimodal diffusion models"
        },
        {
            "title": "Supplementary Material",
            "content": "Figure 6: Multimodal diffusion. Overview of the tokenization, embedding and forward diffusion process of our pipeline. See App. and App. for details."
        },
        {
            "title": "A Multimodal diffusion details",
            "content": "In this section, we detail the design of our pipeline for the generation of quantum circuits, which consist of discrete (categorical) and continuous data. Generally, we use the notation of discrete time diffusion for times t(i) = i/T and s(i) = (i 1)/T such that 0 < 1, where is the number of timesteps and time index running from 1 to . Further, we assume that denotes quantum circuit with its embedding split into token embedding h0, encoding the gate type, and continuous embedding w0, describing the angle of the parameterized gates (see Fig. 1a and Fig. 6). As described in Section 3.1 and Eq. (3), we model the forward diffusion as two independent Gaussian diffusion processes q(h0:1, w0:1x) = q(h0:1x) q(w0:1x), The joint forward distributions are the usual discrete-time Markov chains [31, 60], defined as q(h0:1x) = q(h1) q(h0x) Th(cid:89) i=1 q(ht(i)hs(i)) and q(w0:1x) = q(w1) q(w0x) Tw(cid:89) i= q(wt(i)ws(i)), (10) (11) where q(h1) = (0, I) and q(w1) = (0, I). Further, we set Th = Tw = and for each mode consider fixed deterministic encoders q(h0x) and q(w0x). Following from the definition Eq. (2), the Markov transitions are specified by q(ht(i)hs(i)) = (ht(i); q(ht(i)h0) = (ht(i); (cid:113) (cid:113) t(i)I) t(i)hs(i), βh αh t(i)h0, βh αh t(i)I). and (12) (13) The same approach is then followed for q(wt(i)ws(i)) and q(wt(i)w0) with their respective parameters αw t(i), βw k=0 αt(k) and βt(i) = (cid:81)i t(i). Additionally, Eq. (12) and Eq. (13) are related by αt(i) = (cid:81)i t(i), βw k=0 βt(k) = (cid:81)i (cid:0)1 αt(k) t(i) and αw k=0 (cid:1). 14 A.1 Generative model sampling modes Here, we show how to define the generative model pθ(h0:1, w0:1c) of Eq. (4), using the appropriate reverse transitions stemming from Eq. (5) and Eq. (6), as explained in the main text. For the sake of clarity, we drop the condition on c. The multimodal model can be sampled in multiple valid ways: (i) Joint modes: Assuming that we want to sample jointly the gate types and the continuous parameters, we write pθ(h0:1, w0:1) = p(h1, w1) (cid:89) i= pθ(hs(i), ws(i)ht(i), wt(i)) = p(h1) p(w1) (cid:89) i=1 pθ(hs(i)ht(i), wt(i)) pθ(ws(i)wt(i), ht(i)). (14) (ii) Sequential modes: Equivalently to Eq. (14), we can sample first the discrete tokens h0 independently, and sequentially generate the corresponding parameters w0 by pθ(h0:1, w0:1) = pθ(h0:1) pθ(w0:1h0) = p(h1) (cid:89) i= pθ(hs(i)ht(i)) p(w1) (cid:89) j=1 pθ(ws(j)wt(j), h0). (15) (iii) Single mode: Building upon Eq. (15), we can also assume that we are given gate Ansatz, which means given, fixed h0. If we want to generate the corresponding parameters, we can then just use the second part of previous equation, namely, p(w0:1h0) = p(w1) (cid:89) j=1 pθ(ws(j)wt(j), h0). (16) (iv) Independent modes: Finally, the use of classifier-free guidance (CFG) [43] requires the definition of unconditional marginals, i.e. p(h0) and p(w0), which here we can sampled using pθ(h0:1) = p(h1) (cid:89) i=1 pθ(hs(i)ht(i)) and pθ(w0:1) = p(w1) (cid:89) i=1 pθ(ws(i)wt(i)). (17) (18) As (ii) requires double the number of model evaluations, we only use (i) for joint sampling in Section 4. A.2 Multimodal top-down posterior We show here that the top-down posterior from Eq. (5) splits to Eq. (6). Considering 0 < 1 and 0 < 1, we analyze the multimodal posterior by splitting the joint distribution q(hs, wsht, wt, x) = q(hsht, wt, x) q(wshs, ht, wt, x). We can simplify the second term of the previous equation using Bayes law and the Markov property of the diffusion process, finding (19) q(wshs, ht, wt, x) = q(hths, ws, wt, x) q(hths, wt, x) q(wshs, wt, x) = q(hths) q(hths) q(wshs, wt, x) = q(wshs, wt, x). (20) In the previous equation, the second equality was done by means of the forward process Eq. (3), that allows us to derive q(hths, ws, wt, x) = q(ht, hs, ws, wt, x) q(hs, ws, wt, x) = = q(ht, hsx) q(ws, wtx) q(hsx) q(ws, wtx) q(hths, x) q(hsx) q(hsx) = q(hths), (21) similar derivation can be done for the term q(hths, wt, x) in the denominator in Eq. (20). We are using similar variants of Eq. (21) below, i.e. for q(hsws, wt, x) and q(hswt, x) in Eq. (22), and for q(wtht, hs, x) and q(wtht, x) in Eq. (23) . Further, we simplify Eq. (20) by q(wshs, wt, x) = q(hsws, wt, x) q(hswt, x) q(wswt, x) q(hsx) q(hsx) = q(wswt, x), which is the usual top-down posterior for ws for standard Gaussian DMs, as used for instance in DDPM [31]. In the same direction as done above, for the top-down posterior of hs (the first part of Eq. (19)) we derive q(wswt, x) (22) = q(hsht, wt, x) = q(wtht, hs, x) q(wtht, x) q(hsht, x) = q(wtx) q(wtx) = q(hsht, x). q(hsht, x) Now, using Eq. (20), Eq. (22) and Eq. (23), we rewrite Eq. (19) to q(hs, wsht, wt, x) = q(hsht, wt, x) q(wshs, ht, wt, x) = q(hsht, wt, x) q(wshs, wt, x) = q(hsht, x) q(wswt, x). (23) (24) The Eq. (24) proves the splitting of the reverse transitions of Eq. (6). Specifically, we set for the model pθ(hs, wsht, wt, c) = pθ(hsht, wt, c) pθ(wswt, ht, c) = q(hsht, ˆxθ(ht, wt, t, t, c)) q(wswt, ˆxθ(ht, wt, t, t, c)). (25) A.3 Multimodal ELBO In order to train the diffusion model defined in the main text and above, we optimize the log-likelihood of for the multimodal diffusion model with the evidence lower bound (ELBO), which can be derived as log p(x) = log = log (cid:90) pθ(x, h0:1, w0:1) dh0:1 dw0:1 (cid:90) pθ(x, h0:1, w0:1) q(h0:1, w0:1x) q(h0:1, w0:1x) dh0:1 dw0:1 = log Eq(h0:1,w0:1x) Eq(h0:1,w0:1x) log (cid:20) (cid:20) pθ(x, h0:1, w0:1) q(h0:1, w0:1x) pθ(x, h0:1, w0:1) q(h0:1, w0:1x) (cid:21) (cid:21) . (26) 16 The loss L(x) used for training is then defined as L(x) := Eq(h0:1,w0:1x) (cid:20) log p(xh0, w0) pθ(h0:1, w0:1) q(h0:1x) q(w0:1x) (cid:21) , (27) which reduces to the loss of the main paper (see Eq. (7)) when accounting for: 1) all sampling modes from App. A.1; 2) the use of the multimodal top-down posterior of App. A.2. A.4 Velocity loss weight As described in Section 3.1, we use the velocity target [44] vt := αt ϵ 1 αt x, (28) ensuring that the model outputs have unit variance. In contrast, the rectified flow-based velocity [61], defined as vflow := ϵ x, does not guarantee this property. For Gaussian diffusion process (see Eq. (2)), we sample latent zt at time using zt = αt + 1 αt ϵ, (29) where ϵ (0, I). Next, we combine Eq. (28) and Eq. (29) to = αt zt 1 αt vt. (30) Next, we derive the conversion factor ωx(t) = (SNR(t) + 1) ωv(t), mentioned in Section 3.1, that arises when one translates the loss from denoising prediction ˆxθ to velocity predictor ˆvθ. For this, we insert Eq. (30) into the MSE ωx(t)x ˆxθ2 2 = ωx(t)(cid:13) 1 αt (vt ˆvθ)(cid:13) 2 (cid:13) (cid:13) 2 := ωv(t)(vt ˆvθ)2 2, (31) where one can show for variance-preserving diffusion process the relation (SNR(t) + 1)1 = (1 αt). Hence, we get the final relation which we use for the loss weights in Eq. (7), as introduced in the main text. ωv(t) = (1 αt) ωx(t), A.5 Signal-to-noise ratio for continuous parameters As mentioned above, the forward process of the continuous embeddings wt is given as q(wtw0) = (wt; (cid:112)αw w0, βw I), (32) (33) where βw = 1 αw Section 3.2 and App. B.2) . Moreover, we consider an embedding of the parameter λ [1, 1] via (see w0 = cos(λπ)v1 + sin(λπ)v2. As explained in Section 3.1, we use sigmoid log-SNR weighting from Ref. [42] ωw(t) = sigmoid [log(SNR(t))] . (34) (35) Notably, due to the encoding of the parameter λ (see Eq. (34) and App. B.2), we have to alter the normal SNR in Eq. (35), initially given by SNRw(t) := αw ). This redefinition is required because the signal is now encoded into two correlated dimensions, i.e. v1 and v2, and is therefore more robust to the noise of Eq. (33). The new SNRλ for the continuous parameters λ, with its noisy reconstruction ˆλt (see App. B.2), is defined as /(1 αw (cid:2)λ2(cid:3) Var ˆλt Here, we assume that the samples of λ from the prior p(λ) are bounded and normalized. Since λ is periodic in [1, 1] the absolute value is not relevant and we treat (cid:2)λ2(cid:3) as constant, as it does not const. Var ˆλt SNRλ(t) := (36) = . 17 depend on the diffusion time t. Indeed, we can view it as constant shift for the sigmoid weighting in Eq. (35). Given the previous definition, we can get an upper bound of Eq. (36) by using the CramérRao bound [62] for an estimator of the parameter λ, where I() is the Fisher information. We do so by first, calculating the score function s(λ, wt) of Eq. (33)"
        },
        {
            "title": "1\nVar ˆλt",
            "content": "I(λ), (37) s(λ, wt) = log(p(wtλ)) λ λ (cid:104) 1 βw αw βw = = = (cid:13) (cid:13)wt (cid:112)αw (cid:13) 1 2 βw wt (cid:112)αw w0(λ) (cid:13) 2 (cid:13) w0(λ) (cid:13) (cid:104)(cid:112)αw (cid:105) w0(λ) (cid:104) wt (cid:112)αw w0(λ) w0(λ), (cid:105)T λ (cid:105)T λ with evaluating the derivative of Eq. (34) λ w0(λ) = π sin(λπ)v1 + π cos(λπ)v2. Using the relation Ep(wtλ) (cid:20)(cid:104) wt (cid:112)αw w0(λ) (cid:105)T (cid:104) wt (cid:112)αw w0(λ) (cid:105)(cid:21) = Var [wt] = βw , we now can calculate the Fisher information directly (cid:90) I(λ) = s(λ, wt)2 p(wtλ) dwt (cid:105)T [π sin(λπ)v1 + π cos(λπ)v2] (cid:19)2(cid:35) w0(λ) π2sin(λπ)v1 cos(λπ)v22 Var [wt] (cid:34)(cid:18)(cid:104) Ep(wtλ) wt (cid:112)αw αw ( βw )2 αw ( βw )2 αw π2sin(λπ)v1 cos(λπ)v22 βw αw βw αw βw π2 (cid:16) π2dw = = = = = sin(λπ)2v12 + cos(λπ)2v22 2 sin(λπ) cos(λπ) v1v2 (cid:17) = SNRw(t) π2dw, (50) where we used our orthogonal unit-variance normalized basis for v1 and v2 (see App. B.2). Given the previous, we define SNRλ(t) := SNRw(t) π2dw Therefore, for velocity prediction (see App. A.4), we set the weighting to ωw(t) := (1 αw = (1 αw ) sigmoid[log(SNRλ(t))] ) sigmoid[log(SNRw(t)) b], where = log(cid:0)π2dw (cid:1) 3.39 with dimension dw = 3. A.6 Learned noise schedule for discrete tokens In this section, we present the details on the method used to learn the appropriate noise schedule for the discrete mode based on the given token embeddings. 18 (38) (39) (40) (41) (42) (43) (44) (45) (46) (47) (48) (49) (51) (52) Token mixing in continuous-state Gaussian diffusion The problem of too-weak-noise schedulers for diffusing discrete token embeddings is visualized in Fig. 2a, e.g. for the cosine schedule [38], typically used for images. As explained in Section 3.2, we aim to learn noise schedule with desired average Hamming distance profile, such that the time of trivial denoising is minimized. Note that the Hamming distance for single token can only be either 0 (not flipped) or 1 (flipped). Instead, when averaging w.r.t. to sampling process, we can use the average Hamming distance, which is effectively the probability of token flipping into any other token. Hence, instead of working directly with the Hamming distance, we define instead an analogous of its averaged version, namely the probability pflip(t) of token initially belonging to class being decoded as any of the other classes, i.e. = i, at time t: pflip(t) = 1 q(h(i) h(i) = 1 q(h(i) h(i) h(i) 0 ) h(i) 0 ) (cid:68) h(j) 0 (cid:12) (cid:12)h(i) (cid:12) (cid:69)(cid:17) (cid:69)(cid:19)(cid:21) (cid:20) softmaxj exp (cid:16) 1 τ (cid:80) 1 τ (cid:68) (cid:18) 1 τ h(i) 0 (cid:68) h(j) 0 (cid:12) (cid:12)h(i) (cid:12) (cid:12) (cid:12)h(i) (cid:12) , (cid:69) (53) dh for token embedding where τ > 0 is temperature, which we generally set to τ = 1/ dimension of dh. Analogous to the average Hamming distance, this probability pflip(t) is upper bounded by 1 1/N , i.e., when h(i) is sampled from the uniform distribution (see = 1 at Fig. 2a). Learned discrete schedule we optimize the noise schedule αh In order to match pflip(t) to desired Hamming distance target ftarget(t), appearing in Eq. (53) by minimizing Ldiscrete-schedule = 1 (cid:88) i=0 tU (0,1), h(i) q(h(i) pflip(t) ftarget(t)2(cid:105) (cid:104) , h(i) 0 ) where we use p(h(i) h(i) 0 ) = (ht; (cid:113) h(i) αh 0 , (1 αh )I). (54) (55) In practice, we found it easier to optimize αh cumulative product relation αh k=0 αh learnable parameters. Before optimization, we initialize the schedule values αh schedule [38]. indirectly by parameterizing it with αh t(k) (see Eq. (12) and Eq. (13)) and treating αh , using the t(k) as t(k) with the cosine t(i) = (cid:81)i Visualization of different schedules In Fig. 2a we show the average Hamming distance of different optimized schedules according to Eq. (54). The curves plotted correspond to the following noise schedules: (i) Linear: flin(t) = (1 1/N ) (ii) Sinus: fsin(t) = (1 1/N ) sin(tπ/2) (iii) Sinus squared: fsin2(t) = (1 1/N ) sin(tπ/2)2 In Section 4, we use for all experiments learned discrete noise schedule for the linear target (see Fig. 2a and c). Uniform discrete-state diffusion As shown in Section 3.3, we use the duality between uniform discrete-state diffusion and continuous-state Gaussian diffusion [46] to write the probability of finding decoded, one-hot encoded token kt RN for discrete schedule at as p(ktk) = Cat(kt; atk + (1 at)I/N ). (56) From this, we define the SNR of the discrete mode as the fraction of the original amplitude to the one of the uniform distribution . (57) at 1 at SNRdiscrete(t) := 19 Just as the continuous SNR (see Eq. (2)), we have the same boundary behavior of no noise at small diffusion times (limt0 SNRdiscrete(t) ) to full noise at time = 1 (SNRdiscrete(t = 1) = 0). Here, full noise means uniform distribution across the classes. Similar to the continuous mode, we use the sigmoid log-SNR weighting of Eq. (35) (see Section 3.1). In order to account for the discrete nature of the embeddings, which embody high correlations across the embedding dimensions, we adjust the normal SNRh(t) (Section 3.1) to the discrete one SNRdiscrete(t) of Eq. (57). To determine the appropriate weight ωh(t) in Eq. (7), we relate the Gaussian flip probabilities pflip(t) (Eq. (53)) to the discrete schedule at of Eq. (56). As all tokens are equivalently encoded, it suffices to look at only one token i. Hence, following Eq. (56), we write the probability of finding the token not to be flipped as {atk + (1 at)I/N }i = at + (1 at)"
        },
        {
            "title": "1\nN",
            "content": "!= pnot flipped(t) = 1 pflip(t), resulting in the claimed relation of Section 3.3 at = 1 pflip(t) 1 1/N = 1 pflip(t) pflip(1) . (58) (59) Therefore, assuming well optimized learned schedule with Hamming target ftarget(t) (see Eq. (54)), we can rewrite the discrete SNR as SNRdiscrete(t) = = = at 1 at 1 [pflip(t)/pflip(1)] pflip(t)/pflip(1) pflip(1) pflip(t) pflip(t) ftarget(1) ftarget(t) ftarget(t) , Finally, for the velocity prediction (see App. A.4), we set the weighting to ωh(t) := (1 αh ) sigmoid[log(SNRdiscrete(t))] = (1 αh ) sigmoid"
        },
        {
            "title": "B Circuit encoding and embedding",
            "content": "(cid:20) log (cid:18) ftarget(1) ftarget(t) ftarget(t) (60) (61) (cid:19)(cid:21) . Starting from quantum circuit x, we first tokenize the gates into an integer-matrix representation (see Fig. 6), following the method of Ref. [29]. For this, each gate is assigned to distinct token. Moreover, sign is added to specify the connection type, e.g. control connections are implemented as negative tokens and target connections as positive ones. The resulting matrix has then dimension equal to the number of qubits times the number of gates t, i.e. tokenize(x) Znt, which is the format we use to store the circuits of the dataset (see App. C). In this work, extending from the previous representation, we consider additional continuous parameters for the parameterized gates. We store them alongside the token matrix as one dimensional array matching the sequence length (see Fig. 6), i.e. parameters(x) Rt. Importantly, the values of this array for non-parametrized gates are set to zero. After tokenization, in order to diffuse circuit via the forward process defined in Eq. (3), we embed it into continuous representation [h0, w0], which we discuss in the following App. B.1 and App. B.2. B.1 Discrete token embedding As described in Section 3.2, we implement the token embeddings as dh-dimensional entries h(i) 0 Rdh of look-up table, where = 0, . . . , 1 indexes the different classes. To ensure that 20 all embeddings are equidistant and undergo uniform mixing throughout the diffusion process, we construct them as an orthogonal basis of Rdh. In addition, we set further constraints on our embeddings, {0, . . . , 1} E[h(i) Var[h(i) 0 ] = 0 and 0 ] = 1, (62) (63) where the expectation and variance are taken over the vector elements. The first point Eq. (62) addresses the known average brightness issue of DMs [63, 64], where they conserve the same mean as that of the starting noise latent (at = 1) during the whole ancestral sampling process. This property is attributed to the fact that the low frequency information of the original data survives the forward diffusion process longer than high frequency details, enabling the DM to use the low frequencies as help to lower the loss. For instance, as images have rarely zero mean, the latent initialization of ϵ (0, I) at = 1 biases the DM towards very specific images, i.e. those with zero average brightness. For circuit generation, we found the low frequency information results in the circuit length to be easily predicable during training, stemming from the fact that the padding token count offsets the mean of whole circuit embedding linearly, when not guaranteeing property Eq. (62). The second point Eq. (63) accounts for variance preserving diffusion process [30], where we require normalized data with unit variance. Remarkably, by considering the constraints Eq. (62) and Eq. (63) for single token embeddings, all possible circuits are always embedded with zero-mean and unit-variance by construction. Note, the orthogonality together with the constraints (Eq. (62) and Eq. (63)) allow maximum of = dh 1 classes, as the zero-sum reduces one dimension. For the gate set of Section 4 (i.e. tokens {empty, h, cx, ccx, swap, rx, ry, rz, cp, padding}) we have = 12 connection types in total. Therefore, we use the embedding dimension of dh = 13. B.2 Continuous parameter embedding The normalized continuous parameters λ [1, 1] are encoded as w0 = cos(λπ)v1 + sin(λπ)v2, (64) where both v1, v2 Rdw fulfill the conditions Eq. (62) and Eq. (63). Further, we set v1 and v2 to be orthogonal, fixing dw = 3. Given noisy embedding wt, we can decode the parameter using the estimator ˆλt = 1 π arctanh (cid:19) (cid:18) v2wt v1wt . (65) To analyze the diffusion behavior induced by this encoding, we define distance which accounts for the periodicity of the parameters CircularLoss(t) := 1 cos (cid:16) (λ ˆλt)π (cid:17) . (66) In Fig. 2b we show the CircularLoss(t) of different noise schedules, which are defined as follows: (i) Linear: The linear beta schedule of DDPM [31]: βw = (1 t)β0 + tβ1, with βw 0 = 104 and βw 1 = 0.02. (ii) CosineAlpha: The cosine schedule [38]: αw = cos(tπ/2). (iii) CosineAlpha2: The squared version of the cosine schedule: αw = cos(tπ/2)2. In Section 4, we use for all experiments the CosineAlpha2 noise schedule for the continuous mode (see Fig. 2b and c)."
        },
        {
            "title": "C Dataset details",
            "content": "In this section, we present the details of the training dataset used to train the model in Section 4. 21 Dataset generation We create the dataset by generating random circuits consisting of the gates {h, cx, ccx, swap, rx, ry, rz, cp} with CUDA-Q [48] (see details on the latter below). For this, we first sample subset of the gates from the previous set, and then append these gates uniformly to an empty circuit. We do this randomly from 4 to 32 gates and for 3 to 5 qubits. Once the gate type is fixed, we sample the continuous parameters, of the parameterized gates, following uniform distribution. After circuit is sampled, we evaluate the implemented unitary and store the circuit-unitary pair. Additionally, we parse the sampled gate subset into text prompt and store it alongside the circuits. We sample random circuits until our dataset consists of 11 million (M) unique circuit ansätze. Sequentially, we expand the dataset by resampling the continuous parameters of circuits consisting of at least one parameterized gate six times. Note that this step means we have multiple copies of the same circuits in the dataset, but each with different parameters. With this method we increased the dataset size of 11M unique circuits to 63M unitaries, which we then use to train the model presented in Section 4. Our final dataset has memory size of 290 GB in total. Notably, to reduce training time and storage space, we store the unitaries in half precision (float16), which introduces mean absolute error of MAE(U , I) 105 into the unitary property = I. We assume that this is the potential reason of why the infidelities presented in Fig. 3b are mostly distributed above 105. Future works can explore training with higher precision unitaries. Circuit simulation The dataset creation and verification was done via CUDA-Q [48], an opensource QPU-agnostic platform designed for accelerated quantum supercomputing. By offering unified programming model in Python and C++ for co-located GPUs, QPUs, and CPUs, CUDAQ enables the integration of classical and quantum resources within single application, ensuring optimal performance and efficiency. The platform includes the NVQ++ compiler, which supports split compilation by lowering quantum kernels into multi-level intermediate representation (MLIR) and quantum intermediate representation (QIR). This approach ensures tight coupling between classical and quantum operations, facilitating accelerated execution of large-scale quantum workloads. CUDA-Qs circuit simulation engine leverages NVIDIAs cuQuantum library, which supports state vector, density matrix, and tensor network simulations, enabling scaling to supercomputing scales. Users can with it switch the execution of their code from simulation to QPU hardware consisting of rich variety of ionic, superconducting, photonic, neutral atoms and others as their hardware roadmap mature. Moreover, all executables have parallelization built into their functionality, hence execution of quantum kernels can be parallelized across multi-GPU architectures today, and multiQPU architectures in the future. Recent additions to the platform have included specialized libraries for quantum error correction and quantum algorithm solvers, interoperability with the broader CUDA ecosystem and AI software, and cloud-based hardware access via services like Amazon Braket."
        },
        {
            "title": "D Training details",
            "content": "We train the Circuit-Diffusion-Transformer (CirDiT) (see App. F) from Section 4 with the dataset detailed in App. C. For this, we optimize the loss defined in Eq. (7) using the Adam optimizer [50], with learning rate of 104, β1 = 0.9 and β2 = 0.999, together with one-cycle learning rate strategy [51]. Training is performed on 16 NVIDIA A100 GPUs for 500k update steps, with an effective batch size of 2048. The training time is roughly 800 GPU hours. Additionally, as mentioned in Section 3.1, we drop the condition with probability of 10%, following classifier-free guidance (CFG) [43]. For the multimodal diffusion process, we use for both modes the same number of times steps Th = Tw = = 1000 (see details in App. A). We use for the discrete mode learned discrete noise schedule for the linear target (see Fig. 2ac and App. A.6) and the CosineAlpha2 schedule for the continuous mode (see Fig. 2bc and App. B.2). During training, to reduce the variance of the ELBO estimation, we sample the timesteps and of Eq. (7) using low-discrepancy sampling method, as done in Refs. [60, 65]. Considering batch size of m, we sample both diffusion times for each batch sample by ti, ti (cid:21) (cid:20) 1 , for [1, . . . , m] . (67) As the loss in Eq. (7) requires two independent times, i.e. and t, we shuffle across the batch samples after sampling them. Furthermore, to increase the training time spend on similar times t, we do not shuffle the time step bins of with probability of 5%, leaving and close together as they are sampled from the same bins, which means they differ by maximal value of 1/m."
        },
        {
            "title": "E Inference details",
            "content": "We sample the results from Section 4 using the joint sampling model, as explained in App. A.1, for 40 time steps. As diffusion sampler, we use the CFG++ [52] variant of DPM++2M [53]. E.1 Balanced testset In Section 4.2, we showed the compilation of random unitaries from test set. This test set is split from the training dataset (detailed in App. C), ensuring that the test unitaries are indeed compilable with the available gate set. Importantly, we do this before starting training and before resampling the parameters of the parametrized gates (see App. C), guaranteeing benchmark set of unitaries resulting from unique circuits the model has never seen during training. Additionally, we balance the test set such that we have an equal amount of circuits per gate count. E.2 Multimodal CFG As explained in Section 3.1, the reverse transitions for each of the modes (see Eq. (6)) have two conditions: one related to the opposite mode, and another one accounting for the external condition c. For sampling using CFG [43], we extend the guidance to two conditions. Considering the guidance scales γh, γw and λh, λw, we can write the guided velocity prediction (see App. A.4) for the discrete mode as θ (ht, wt, t, t, c) = vh vh θ (ht, ϵw, t, 1, ϕ) + γh + λh (cid:2)vh (cid:2)vh θ (ht, wt, t, t, ϕ) vh θ (ht, wt, t, t, c) vh θ (ht, ϵw, t, 1, ϕ)(cid:3) θ (ht, wt, t, t, ϕ)(cid:3) , Analogously, for the continuous mode we write θ (ht, wt, t, t, c) = vw vw θ (ϵh, wt, 1, t, ϕ) + γw + λw (cid:2)vw (cid:2)vw θ (ht, wt, t, t, ϕ) vw θ (ht, wt, t, t, c) vw θ (ϵh, wt, 1, t, ϕ)(cid:3) θ (ht, wt, t, t, ϕ)(cid:3) , (68) (69) where ϵh, ϵw (0, I) and ϕ represents an empty condition. In practice, we implement ϕ as trainable latent vector. Empirically, we found the values γh = 0.3, γw = 0.1, λh = 1.0 and λw = 0.35 work well for circuit generation, which we then use for the results presented in Section 4."
        },
        {
            "title": "F Model architecture",
            "content": "In Fig. 7 we present the model architecture considered in this work, named Circuit-DiffusionTransformer (CirDiT). Our model choice is based on the diffusion transformer (DiT) architecture [49], and contains 257 million trainable parameters. For the encoder and decoder blocks, we use channel size of 384, number of blocks Ne = Nd = 6 and number of 12 heads. The core transformer has 1024 channels, Nc = 12 blocks and 16 heads. We inject the diffusion times and using Time-dependent Self-Attention (TMSA) [66], using temb size of 512 channels. The time dimension of the circuit embeddings (see App. B) is encoded using the rotational position encoding p-RoPE of Ref. [67], setting the parameter of the latter to = 0.9. In addition, for the qubit dimension, we add learned position encoding before the encoder blocks. As visualized in Fig. 7, we replace the Layer-Norm layers with RMS-Norms [68] and push them to the end of the blocks, mitigating the divergence problem of large scale DiTs, as discussed in [69, 70]. We use in some layers the adaptive version AdaRMS-Norm, where we scale the normalized output by an external signal which is constrained by the tanh activation [70]. 23 Figure 7: Circuit Diffusion Transformer (CirDiT) architecture. a) Overview of the encoder-coredecoder structure. After passing the inputs through the encoder, the latent state is averaged across the qubit dimension, yielding sequence of latent vectors. This sequence is then passed into the core transformer blocks, which inject the condition c. Finally, the core output is passed alongside skip connection of the encoder to the decoder. b) Design of the encoder blocks. c) Design of the core blocks. The condition is passed through multimodal full attention layer, where we concatenate the output of the previous layer with c. Then, the output is split and the portion is averaged and used as gating for the following AdaRMS layer. d) Design of the decoder blocks. The core output is utilized by scaling and shifting operations on the main branch. Unitary encoder pre-training As explained in Section 3.1, in order to create an appropriate unitary conditioning, we pre-train unitary encoder which encodes given unitary together with prompt into condition c. The main goal of this encoding is to align the representation of given unitary to its circuit representation, ensuring that the information passed to the DM is as expressive as possible given the generation task. Inspired by the contrastive loss of the CLIP framework [71], we match the latent encodings of circuit encoder and unitary-prompt encoder, as presented in Fig. 8a. Additionally, we first encode the text prompts using frozen pre-trained OpenCLIP [45] model, specifically the architecture ViT-B-32 trained on the dataset datacomp_xl_s13b_b90k. The circuit and unitary encoder are based on the diffusion transformer architecture [49]. The whole UnitaryCLIP (both encoders) we use in Section 24 contains 38 million trainable parameters. We use an additive absolute position encoding [72] for the unitary matrix elements. We optimize the UnitaryCLIP using the Adam optimizer [50], with learning rate of 3.2 104, β1 = 0.9 and β2 = 0.999, together with one-cycle learning rate strategy [51]. We train for 500k updates steps, with an effective batch size of 4096, on the dataset of App. C. We find that the trained UnitaryCLIP is able to achieve 99% correct matching of unseen unitary-circuit pairs. Figure 8: UnitaryCLIP. a) Overview of the contrastive unitary encoder pre-training. b) Conditioning of the diffusion model using the output of the unitary-prompt encoder as condition c."
        },
        {
            "title": "H Additional figure parameters",
            "content": "We list in Table 1 additional sample parameters of the figures presented throughout this paper. Table 1: Figure sampling parameters. Figure Number of unitaries Circuit samples per unitary Notes Fig. 3 Fig. 4ab Fig. 4cd Fig. 5abc Fig. 5defghi Fig. 2048 - - 1 -"
        },
        {
            "title": "I Circuit corruption test",
            "content": "128 128 128 2048 - 1 # unitaries per qubit count unitary per grid point unitary per time step QFT for 4 qubits Same circuits as in Fig. 4ab for 4 qubits Here # unitaries is # ciruits In Fig. 3a we observed the appearance of some characteristic peaks in the infidelity distribution. In order to further investigate the origin of such peaks, we perform different corruptions on test set circuits and record the resulting infidelities between corrupted and original circuits. We show in Fig. 9 the infidelities for the following discrete and continuous corruptions: 1. Drop single random gate from the circuit. 2. Append single random gate from the gate set, with random connections. 3. Replace single random gate with random one from the gate set, with random connections. 4. Add Gaussian noise to the normalized parameters λ [1, 1] of all continuous gates in circuit, i.e. λ = λ + (0, 1), (70) for {0.05, 0.1, 0.15} (see Fig. 9b). Note, we always take only single corruption per circuit from the list above. 25 Comparing the peaks in the discrete corruptions of Fig. 9a to the ones observed in the random unitary compilation (see Section 4.2), we see the same peaks appearing at 0.4 and 0.8. Hence, we attribute the peaks arising in Fig. 3a to cases in which the model incorrectly places gates in similar way as our corruption tests, this means, by misplacing single gate. On the other hand, corrupting the continuous values of the parameterized gates causes wide continuous distribution around zero (Fig. 9b), where the peak at zero infidelity corresponds to circuits which have no parameterized gates. This highlights an important result: comparing this distribution to that in Fig. 3a showcases the fact that the model predicts the continouous parameters rather accurately, as no broad distribution arises, and the error arise mainly from misplacements of single gate. Figure 9: Circuit corruptions. a) Infidelity distribution for circuits with discrete corruptions (see App. I). b) Infidelity distribution for circuits with continuous corruption, as defined in Eq. (70)."
        },
        {
            "title": "J Hamiltonians",
            "content": "In Section 4.3 we showed the compilation of the evolution operators of the Ising and XXZ Hamiltonians. Here we define these Hamiltonians in terms of the Pauli operators, which are defined as = (cid:19) (cid:18)0 1 1 0 , = (cid:19) (cid:18)0 0 (cid:19) (cid:18)1 0 0 1 and = . (71) For both Hamiltonians, we consider here the case in which the qubits of the quantum circuit represent the spins of non-periodic one-dimensional chain, where we write neighboring spins and as i, j. Ising Hamiltonian: Defined as Hising = (cid:88) i,j ZiZj n1 (cid:88) i=0 Xi, where is the coupling constant and magnetic field. XXZ Hamiltonian: Defined as Hxxz = (cid:88) i,j (XiXj + YiYj + ZiZj) n1 (cid:88) i= Xi, (72) (73) where is the coupling constant, perturbation and magnetic field. In Section 4, we fix = 0.2 for the XXZ Hamitonian."
        },
        {
            "title": "K Additional GPE structures",
            "content": "In this section, we present additional circuit structures extracted using our proposed Gate-Pair Encoding (GPE) scheme (see Section 3.4), extending the results presented in Section 4.4. We follow the exact same recipe as in the main text, and take all circuits generated by the DM, without any selection or filtering for wrong circuits. Notably, this means all structures are extracted without any circuit evaluation, keeping all computations of the process purely classic. For the structures shown in Fig. 10, Fig. 11 and Fig. 12, we run GPE for maximum of 250 iterations, or until there are no pairs left to be matched into new token. We present structures for different token depths, where depth 0 is defined as the elementary tokens, being here the original gate set (e.g. or cx). Then, depth 1 structures are gate-pairs (i.e. pairs of depth 0 tokens). Further, depth 2 tokens are constructed from at least one depth 1 token together with either one depth 1 or 0 token. More generally, depth token always consists of one depth 1 token and another one with depth 1. 27 Figure 10: QFT Gate-Pair Encodings. GPE (see Section 3.4) on generated circuits for the QFT unitary for a) 3 qubits, b) 4 qubits and c) 5 qubits. The rows correspond to the token depth (see App. K). The circuits shown represent the top-5 most occurring structures, from most occurring (left) to less often occurring (right). 28 Figure 11: Ising Hamiltonian Gate-Pair Encodings. GPE (see Section 3.4) on generated circuits for the 4-qubit Ising Hamiltonian (defined in Eq. (72)) evolution unitary for τ = 0.25. We use in a) circuits for the parameters [0.5, 0.9] and = 0, and in b) [0.5, 0.9] and = 0. The rows correspond to the token depth (see App. K). The circuits shown represent the top-5 most occurring structures, from most occurring (left) to less often occurring (right). 29 Figure 12: XXZ Hamiltonian Gate-Pair Encodings. GPE (see Section 3.4) on generated circuits for the 4-qubit XXZ Hamiltonian (defined in Eq. (73)) evolution unitary for τ = 0.25. We use in a) circuits for the parameters [0.5, 0.9] and = 0, and in b) [0.5, 0.9] and [0.5, 0.9]. The rows correspond to the token depth (see App. K). The circuits shown represent the top-5 most occurring structures, from most occurring (left) to less often occurring (right)."
        }
    ],
    "affiliations": [
        "Institute for Theoretical Physics University of Innsbruck",
        "NVIDIA Corporation"
    ]
}