{
    "paper_title": "Are they lovers or friends? Evaluating LLMs' Social Reasoning in English and Korean Dialogues",
    "authors": [
        "Eunsu Kim",
        "Junyeong Park",
        "Juhyun Oh",
        "Kiwoong Park",
        "Seyoung Song",
        "A. Seza Dogruoz",
        "Najoung Kim",
        "Alice Oh"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As large language models (LLMs) are increasingly used in human-AI interactions, their social reasoning capabilities in interpersonal contexts are critical. We introduce SCRIPTS, a 1k-dialogue dataset in English and Korean, sourced from movie scripts. The task involves evaluating models' social reasoning capability to infer the interpersonal relationships (e.g., friends, sisters, lovers) between speakers in each dialogue. Each dialogue is annotated with probabilistic relational labels (Highly Likely, Less Likely, Unlikely) by native (or equivalent) Korean and English speakers from Korea and the U.S. Evaluating nine models on our task, current proprietary LLMs achieve around 75-80% on the English dataset, whereas their performance on Korean drops to 58-69%. More strikingly, models select Unlikely relationships in 10-25% of their responses. Furthermore, we find that thinking models and chain-of-thought prompting, effective for general reasoning, provide minimal benefits for social reasoning and occasionally amplify social biases. Our findings reveal significant limitations in current LLMs' social reasoning capabilities, highlighting the need for efforts to develop socially-aware language models."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 2 ] . [ 1 8 2 0 9 1 . 0 1 5 2 : r Are they lovers or friends? Evaluating LLMs Social Reasoning in English and Korean Dialogues Eunsu Kim1 , Junyeong Park1 , Juhyun Oh1, Kiwoong Park1, Seyoung Song1, A.Seza DogruÃ¶z 2, Najoung Kim3, Alice Oh1 1KAIST, 2University of Ghent, 3Boston University kes0317@kaist.ac.kr, najoung@bu.edu, alice.oh@kaist.edu"
        },
        {
            "title": "Abstract",
            "content": "As large language models (LLMs) are increasingly used in human-AI interactions, their social reasoning capabilities in interpersonal contexts are critical. We introduce SCRIPTS, 1kdialogue dataset in English and Korean, sourced from movie scripts. The task involves evaluating models social reasoning capability to infer the interpersonal relationships (e.g., friends, sisters, lovers) between speakers in each dialogue. Each dialogue is annotated with probabilistic relational labels (HIGHLY LIKELY, LESS LIKELY, UNLIKELY) by native (or equivalent) Korean and English speakers from Korea and the U.S. Evaluating nine models on our task, current proprietary LLMs achieve around 75-80% on the English dataset, whereas their performance on Korean drops to 58-69%. More strikingly, models select UNLIKELY relationships in 10-25% of their responses. Furthermore, we find that thinking models and chain-of-thought prompting, effective for general reasoning, provide minimal benefits for social reasoning and occasionally amplify social biases. Our findings reveal significant limitations in current LLMs social reasoning capabilities, highlighting the need for efforts to develop socially-aware language models."
        },
        {
            "title": "Introduction",
            "content": "LLMs increasingly operate as agents in everyday settings (e.g., classrooms, workplaces), and such interactions between LLM agents and humans are expected to grow (Cai et al., 2024; Liu et al., 2024). To provide appropriate assistance, LLMs should understand human dynamics and infer participant relationships from sociolinguistic cues, much as humans do when navigating social interactions (Sehl et al., 2023; Nguyen et al., 2016). We refer to this social reasoning ability as social relationship reasoning, which includes identifying who holds authority, who is peer, family member, or stranger in conversation. If LLMs fail at this reasoning, they risk producing responses Equal Contribution. 1The dataset and code are available on https://github. com/rladmstn1714/SCRIPTS. that violate social norms and/or cause safety issues (e.g., privacy leakage (see Figure 1)). Despite its importance and relevance in everyday life, existing evaluations of social relationship reasoning have major shortcomings. Prior works often oversimplify the task, frame it as multiplechoice classification (Jia et al., 2021a; Li et al., 2023), cover narrow set of relationship types (often around ten) (Jia et al., 2021b; Tigunova et al., 2021), or focus exclusively on simple dyadic conversations (Jurgens et al., 2023). More importantly, these frameworks ignore the inherent uncertainty of social reasoning, which rarely yields single definitive answer. For example, remark like You never listen to me could signal playful banter between friends, frustration between coworkers, or deeper tension in romantic relationship, depending on the context and the participants. Such interpretations may further diverge across languages and cultures, underscoring the need for more robust evaluation frameworks. To explore this topic further, we introduce SCRIPTS, novel benchmark for evaluating LLMs social relationship reasoning abilities, featuring an answer schema that incorporates inherent uncertainty (Figure 1). It contains 1k dialogues (English 580, Korean 567), derived from U.S. and Korean movie scripts, ensuring conversations are realistic and culturally grounded. We adopt soft labeling, where each relationship type is annotated with likelihood-based categories: HIGHLY LIKELY, LESS LIKELY, UNLIKELY. By distinguishing relationship labels by likelihood, our dataset supports fine-grained evaluation that differentiates nonsensical responses from plausible but contextually less prominent ones. We evaluate 9 models and find that current LLMs perform poorly on social relationship reasoning regardless of the language. The models frequently select UNLIKELY relationships, indicating inappropriate inferences about the social sitFigure 1: Illustration of SCRIPTS and potential risks from failures in Social Relationship Reasoning. SCRIPTS provides three human-annotated relationship labels: HIGHLY LIKELY, LESS LIKELY, and UNLIKELY. In this example, Gemini-2.5-Flash incorrectly predicts store clerk-customer relationship as mother-child. Such misleading relational reasoning can lead to inappropriate responses and unsafe decisions, such as privacy leakage. Examples are from Korean dialogues, translated into English. uations. Even the best-performing model (GPT4o) still produces UNLIKELY responses in 10% of cases, settles on LESS LIKELY responses in 11%, and predicts HIGHLY LIKELY relationships in 79% of cases. Lower-performing models, such as Llama-3.1-8B-Instruct, achieve HIGHLY LIKELY predictions in only 45% of cases. Surprisingly, chain-of-thought (CoT) prompting and thinking models, effective for logical reasoning, provide minimal benefits for social reasoning and occasionally amplify social biases. We qualitatively analyze where LLMs fail, focusing on cases where models respond with UNLIKELY relationships, and identify four failure modes across English and Korean, often rooted in cultural context. We further investigate whether the socio-demographic backgrounds (e.g., age, gender, relationship), formality, hierarchy and intimacy between human conversational partners enhance social relationship reasoning and find that these factors reduce UNLIKELY outputs and mitigate nonsensical behavior for LLMs in general. In summary, our contributions are as follows: We introduce SCRIPTS, benchmark for evaluating LLMs social relationship reasoning in English and Korean. Evaluation across 9 LLMs reveal their limited social reasoning ability, with models inferring UNLIKELY relationships in 10-25% of cases, and showing substantial variation in their ability to infer HIGHLY LIKELY relationships. We show that CoT reasoning or thinking models do not consistently improve performance. Instead, incorporating relational information that humans naturally rely on facilitate more likely inferences."
        },
        {
            "title": "2 Related Work",
            "content": "Evaluating Social Relationship Reasoning in LLMs Recent evaluations of social relationship reasoning in LLMs largely focus on Theory of Mind and inferring mental states (Jung et al., 2024; Kim et al., 2025). While important, this line of work does not evaluate the capacity to integrate social contexts into the reasoning process (Hilton, 1995). Our work addresses complementary but underexplored component of social intelligence: inferring interpersonal relationships that shape interaction, accounting for context, and participants. Existing research on computational models for social relationship reasoning is often constrained by simplified tasks and datasets  (Table 1)  . Many studies frame the problem as classification or multiple-choice, which fails to capture nuanced reasoning process (Li et al., 2023; Jia et al., 2021a; Chen et al., 2020). Some datasets are built from single utterances rather than multi-turn conversations, limiting contextual variation (Jurgens et al., 2023). Other studies using conversational data have methodological limitations. For instance, PRIDE (Tigunova et al., 2021) gathered annotations from movie summaries instead of dialogues, and Rashid and Blanco (2018) used static, Dataset Multi-turn Labeling Strategy Relational Dimensions Fine-grained Relationship Task Languages Rashid and Blanco (2018) Zhan et al. (2023) Jurgens et al. (2023) Chen et al. (2020) Jia et al. (2021b) Tigunova et al. (2021) SCRIPT (Ours) single single multiple single single multiple prob.-based (49) (24) (13) (12) (>250) Classification Classification Classification Classification Classification Classification Open-ended Generation En En En Zh En En En, Ko Table 1: Comparison of social relations dataset. SCRIPTS supports over 250 fine-grained relationships in dialogues, covers multiple languages, and provides probabilistic labeling and relational dimensions. episode-wide labels that fail to reflect what can be inferred from an interaction. In contrast, our benchmark uses multi-turn dialogues with labels directly inferred by humans, capturing relationships as they actually manifest. We evaluate with open-ended generation rather than fixed-choice classification, allowing wider range of relationships and better reflecting the social complexity. Cultural Dependency in Social Relationship Reasoning social relationship reasoning is tied to linguistic and cultural context. For example, Korean and English are differ typologically and in their use of terms of address and honorifics, which play central role in encoding relational information in Korean dialogue (Chung, 2010; Hwang, 1991). Nevertheless, prior studies typically focus on single language (mostly English). Terms of address (ToA) are words or phrases used to refer directly to another person, carrying important discourse implications (Hwang, 1991). In Korean, these terms are diverse, including kinship terms, titles, pronouns, and other culturally grounded forms. For instance, instead of using an adults name, Korean speakers may prefer Minsoos dad, reflecting norms that avoid direct name use in certain contexts. By contrast, English ToA rely mainly on personal names, with limited titles (Mr., Mrs.), professional markers (Professor), and kinship terms (Mom, Dad). Honorifics are another key site of cultural divergence, encoding social relationships directly into linguistic forms (Ide, 1989). While many languages employ politeness strategies, Korean is distinct in its extensive grammaticalization of honorifics (Harada, 1976; Brown et al., 2014), whereby roles, status, and formality are conveyed through verbal morphology (Fukada and Asato, 2004; Brown, 2015; Pizziconi, 2011). In English, by contrast, no equivalent system exists. Instead, politeness is expressed through speech acts or pragmatic choices. Given these cultural and linguistic differences, social relationship reasoning should be evaluated cross-linguistically and crossculturally. Our study represents first step with dataset spanning two languages and cultures. Evaluating Tasks with Multiple Answers of Varying Plausibility Unlike domains with verifiable answers (e.g. mathematics), social relationship reasoning is inherently subjective (Hilton, 1995), operating on spectrum of plausible interpretations across contexts and participants. robust evaluation should credit likely answers and penalize socially inappropriate ones. Error severity-aware evaluations are common in ambiguous NLP tasks like machine translation (Freitag et al., 2021) and dialogue generation (Zhang et al., 2022), yet remain largely absent in social relationship reasoning. Prior work acknowledges ambiguity by allowing multiple labels (Jurgens et al., 2023; Tigunova et al., 2021; Yu et al., 2020) but does not model their probabilistic nature. We extend these paradigms by separating plausible secondary interpretations from outright failures, enabling more granular evaluation."
        },
        {
            "title": "Relationship Reasoning",
            "content": "We introduce SCRIPTS, benchmark for social relationship reasoning in multi-turn dialogues across two languages (English, Korean). We outline the datasets motivation ( 3.1), design ( 3.2), and construction ( 3.3)."
        },
        {
            "title": "Reasoning in LLMs",
            "content": "As humans naturally engage in social relationship reasoning in their daily interactions, we argue that LLMs should also be able to perform such reasoning to generate contextually appropriate utterances and to prevent potential social harm. The right side of Figure 1 shows how misinterpreted social relationships could lead to undesirable outcomes. In this example, model (Gemini-2.5-flash) misinterprets the social relationship between and (i.e., misidentifying an store clerkcustomer interaction for family relationship). This misidentification leads to nextresponse generation that distorts their relationship and even suggests that sharing personal information is acceptable."
        },
        {
            "title": "3.2 Dataset Design",
            "content": "To capture the complexity and diversity of realworld social dynamics, we leverage movie scripts, which provide natural interactions among humans across wide spectrum of relationships  (Table 9)  . Our benchmark makes two key contributions: It (1) dynamically models how social relationships emerge within conversations, rather than relying on static role labels, and (2) employs three-tiered probabilistic labeling schemeHIGHLY LIKELY, LESS LIKELY, and UNLIKELYenabling more granular evaluation of social relationship reasoning capabilities. Dialogue-Level Labeling key design choice of SCRIPTS is its focus on relationships as manifested within specific conversational contexts. Previous benchmarks often rely on fixed character roles derived from movie metadata (e.g., motherson) (Jia et al., 2021b). However, social relationships are dynamic: speakers may shift roles based on context and/or hold multiple relationships simultaneously. For example, the same conversational partners may interact as friends and as co-workers in different scenes. To validate our context-centric approach, we compare our human-annotated labels against these static movie labels. The comparison reveals two critical findings: (1) 19% of static movie labels are not considered relevant by human annotators for given dialogue, suggesting that single global label can be misleading. (2) Even when the annotator labels include movie label, our annotations contain an average of 3.6 HIGHLY LIKELY relationships per dialogue. This result shows that single conversation often reflects multiple social facets, highlighting the limitations of singlelabel approach and the necessity of contextaware method. Probabilistic Labeling As social situations are inherently ambiguous, one dialogue may suggest multiple relationships with varying plausibility (Figure 1). We adopt three-tier probabilistic schemeHIGHLY LIKELY, LESS LIKELY, and UNLIKELY. This design offers two key benefits: (1) granularity, allowing metrics to reward models for identifying the most salient relation (HIGHLY LIKELY) rather than just plausible ones (LESS LIKELY); and (2) nonsense penalty, which penalizes contextually inappropriate predictions (UNLIKELY)a critical failure in social relationship reasoning."
        },
        {
            "title": "3.3.1 Collecting dialogues from movie scripts",
            "content": "We collect 60 movie scripts: 28 English movies through online web crawling from IMSDb,2 32 Korean movies from an onsite visit to the Korean Film Archive3 and crawling through Korean online film script community (open access).4 Table 16 in the Appendix presents the complete movie list along with the corresponding metadata. We then filter the scenes by the following criteria: (1) having sufficient numbers of turns ( 3) and (2) containing two or three participants. Among the scenes that meet criteria (1) and (2), we selected those that feature interactions across the most diverse range of speaker combinations, rather than concentrating on repeated exchanges between the same few participants. From 23k initial scenes, this leads to 1,322 high-quality dialogues (698 English, 624 Korean) for human annotation. For further details on the data collection and filtering process, please refer to the Appendix A. While prior work has focused primarily on dyadic interactions, SCRIPTS also includes dialogues with three speakers (41.8% of the dataset) to reflect more complex social scenarios. For these multi-participant scenes, the task remains to infer the dyadic relationship between two interlocutors, for which we randomly select pair of speakers."
        },
        {
            "title": "3.3.2 Collecting Human Annotations",
            "content": "Each dialogue is annotated by three annotators who are native or near-native speakers with extensive cultural familiarity (10+ years of residence in 2https://imsdb.com 3http://www.kmdb.or.kr/ 4https://www.filmmakers.co.kr/ # of Movies Dialogues 3-Person Dialogues (%) Avg. Turns Unique Highly-Likely Relationships Avg. # of Highly-Likely Relationship Avg. # of Unlikely Relationship English Korean Total 28 580 38.45 10.21 230 3.62 18.50 32 567 45.15 9.89 617 3.72 23. 60 1,147 41.80 10.05 3.67 20.79 Table 2: Statistics of the SCRIPTS. Figure 2: Comparative Analysis of Relational Dimension Distributions for Six Relationship Types Present in Both English and Korean Top10 Relations. Legend labels denote intimacy (O: intimate, X: unintimate, : neutral), formality (O: formal, X: informal, : neutral), and hierarchy (<: hierarchical, =: equal). U.S. and South Korea each). We recruit 17 annotators for English and 14 annotators for Korean (see Appendix A.5 for details). For human annotation, we employ four-phase annotation process (See Appendix for details). Phase 1: Labeling UNLIKELY Relationships. From predefined list of 50 common relationships from PRIDE (Tigunova et al., 2021) (see Appendix Table 9), annotators select all relationships that are definitively contradicted by the dialogues content. relationship is marked as UNLIKELY only if majority of annotators agree, ensuring high-confidence threshold. Phase 2: Open-ended Labeling for HIGHLY LIKELY Relationships. The annotators then provide open-ended text labels for the relationship(s) that they believe are most clearly demonstrated in the dialogue. After normalization step (e.g., merging co-worker and colleague), the union of the labels forms the HIGHLY LIKELY set. Phase 3: Deriving LESS LIKELY Relationships. All remaining relationships from the prethat are neither HIGHLY LIKELY defined list nor UNLIKELY are automatically categorized as LESS LIKELY. Phase 4: Annotating Auxiliary Labels In this phase, annotators provide auxiliary labels for socio-demographic information (age, gender) and relational dimensions (formality of communication, hierarchy, and intimacy between conversational partners). We collect this information to conduct more detailed analyses of factors that influence relationship inferences; we focus on ones that humans have been shown to rely on for social relationship reasoning (Wish et al., 1981; Nguyen et al., 2016). Quality Control To ensure annotation quality, we conduct initial training sessions and pilot study among the annotators. We exclude dialogues in which the three annotators HIGHLY LIKELY labels had no overlap (i.e., mutually exclusive), as such cases indicate low reliability. This results in total of 1,147 dialogues (580 English, 567 Korean), deleting 13.2% samples from initial dataset. Table 2 shows the statistics of our final dataset."
        },
        {
            "title": "3.4 Diversity of SCRIPTS",
            "content": "As shown in Table 2, our dataset comprises more than 230 unique relationships in English and 617 in Korean. On average, each dialogue is annotated with 3.7 HIGHLY LIKELY relationships and 20.8 UNLIKELY relationships. Further statistical comparisons between English and Korean datasets are provided in Appendix A.6. Figure 2 illustrates that our dataset can capture diverse interpersonal dynamics by labeling relational dimensions. The typicality of certain relationships is often defined by their levels of intimacy, formality, and hierarchy (Wish et al., 1981). For instance, friendship is generally characterized as intimate, non-hierarchical (equal), and informal. Yet, our dataset also includes atypical relationships. For instance, over 40% of friend relationships in our dataset deviate from these typical dimensions."
        },
        {
            "title": "4 Evaluating LLMs with SCRIPTS",
            "content": "three proprietary modWe evaluate 9 LLMs: els (GPT-4o, o3, Gemini-2.5-flash), three widely used open-source models (Qwen-3-{8B/14b}, Llama-3.1-8B-instruct), and three open-source (a) English (b) Korean Figure 3: Comparison of model performance in English and Korean datasets. HIGHLY LIKELY represents the accuracy of the models majority response being highly likely response, while UNLIKELY indicates the error rate where the model generate an unlikely response. multilingual models specialized for Korean (A.X4.0-light-7B, Kanana-8B, and Exaone-4.0-30B).5 prove general reasoning abilities (e.g., Math/Coding) (Wei et al., 2022). Evaluation and Metrics Considering the probabilistic nature of the task, we run each model five times per dialogue and take the models majority response among them. We then compute two metrics: the proportion of samples whose majority response falls into the HIGHLY LIKELY relation set, and the proportion whose majority response falls into the UNLIKELY relation set. We use GPT4o to evaluate each models short-form answers. GPT-4os role is to compare model outputs with ground-truth labels without relying on any internal knowledge, and we confirm it is accurate in 92.0% of cases (see Appendix B.3)."
        },
        {
            "title": "4.1 Overall Performance",
            "content": "Figure 3 shows the performances of five multilingual models: GPT-4o, Gemini-2.5-Flash, Qwen3-{8/14}B, and Llama-3.1-8B-Instruct. Our results show that GPT-4o achieves the best performance, with HIGHLY LIKELY rate of 79% and 69% in English and Korean, respectively. The models incorrectly infer an UNLIKELY relationship in 10.8-31.9% of their responses and this tendency is amplified in the Korean dataset, with the rate increasing by an additional 7.23-16.5%p. We provide case study of these behaviors with the frequent failure modes of the models in 5. Table 10 in Appendix reports the detailed results."
        },
        {
            "title": "4.2 Does Thinking Help?",
            "content": "We analyze the performance of models when Chain-of-Thought (CoT) prompting or internal thinking processes are incorporated. These methods are known to be effective ways to im5See Appendix B.1 for model configurations. Effectiveness of Chain of Thought Prompting We investigate the impact of CoT prompting on the performance of four models: GPT4o, Gemini-2.5-Flash, Qwen-3-8B, and Llama3.1-8B-instruct. As shown in Table 11, applying CoT does not always help. In some cases, performance worsens, as Gemini-2.5-flash shows 1.7%p decrease in the rate of HIGHLY LIKELY responses in English and Llama-3.1-instruct exhibits 3.06%p increase in unlikely responses in Korean. This pattern contrasts with general reasoning tasks, where CoT typically improves performance, suggesting that the nature of social reasoning may be fundamentally different and therefore may limit its effectiveness. Effectiveness of Thinking Process We evaluate three reasoning models: o3, Gemini-2.5-Flash, and Qwen-3-14B, comparing the latter two with- /without an internal thinking process. Here, due to budget constraints, we compare performance in single-run setting. As shown in Table 3, the results vary significantly by language. For the English dataset, thinking-enabled models generally achieve higher performance. However, for the Korean dataset, the impact of the thinking process is negligible (e.g., Qwen-3-14b), and in the case of Gemini-2.5-flash, enabling the thinking process even leads to 4.39%p decrease in the rate of HIGHLY LIKELY."
        },
        {
            "title": "4.3 Do Korean-specialized models perform",
            "content": "better in the Korean context? We evaluate three Korean-specialized models: A.X-4.0-light (7B), Kanana-8B, and Exaone-4.0Model Thinking En Ko HIGHLY LIKELY () UNLIKELY () HIGHLY LIKELY () UNLIKELY () OpenAI/GPT-4o OpenAI/o3 Gemini-2.5-flash Gemini-2.5-flash Qwen-3-14b Qwen-3-14b 0.767 0.807 0.759 0.776 0.623 0.673 0.116 0.086 0.154 0. 0.164 0.107 0.642 0.742 0.582 0.538 0.455 0.467 0.215 0.152 0.318 0. 0.444 0.443 Table 3: Model comparison with and without Thinking mode across English (En) and Korean (Ko). Rank En Ko"
        },
        {
            "title": "5 Why do Models Fail?",
            "content": "1 2 3 4 5 A.X-4.0-Light (0.589) A.X-4.0-Light (0.467) Qwen-3 (0.423) EXAONE-4.0 (0.409) kanana-1.5 (0.328) Llama-3.1 (0.321) Qwen-3 (0.565) Llama-3.1 (0.413) kanana-1.5 (0.406) EXAONE-4.0 (0.318) Table 4: Model ranking of Korean-specialized and open-source models in Korean and English, based on the HIGHLY LIKELY response rate (numbers in parentheses indicate the corresponding values). 32B. A.X-4.0 6 is reported to be further trained on Korean corpus based on the Qwen model, whereas the training datasets for Kanana and Exaone are not disclosed. Nonetheless, their technical reports suggest that their Korean performance rivals or surpasses their English performance (Kanana LLM Team et al., 2025; LG AI Research, 2025). The models support both Korean and English. To compare the performance of three Koreanspecialized models in Korean and English against similarly sized open-source models (Qwen-3-8B and Llama-3.1-8B-instruct), we present the ranking of five models across the two languages in Table 4 (detailed results are provided in Table 12 of Appendix B.4). The results show that A.X4.0-Light and Qwen-3-8B achieve the best and second-best performance in both English and Korean, but the 3rd5th rankings differ. In English, Llama-3.1-Instruct-8B ranks 3rd, while in Korean, Exaone and Kanana take 3rd and 4th, with Llama ranking last. This implies that languageand culture-specific approach to model training may be beneficial, given the culturally dependent nature of the task. 6https://github.com/SKT-AI/A.X-4.0/ Based on manual analysis of models reasoning processes in CoT experiments ( 4.2), we classify the key failure modes of LLMs into four types.7 Failure to Distinguish Terms of Address and References We find that models often misinterpret term of reference (a word used to refer to someone) as term of address (a word used to call someone directly), leading to fundamental misunderstanding of the social context. Dialogue 1 (English): [A]: Hi Officer, can help you? [B]: Yes, Im hoping you can. An elderly gentleman went missing from the nursing home down the street. Staff seems to think he came here. (...) [A]: (Pause, then) Oh....thats my Dad. He cant talk. Had major stroke few years back. But hes doing well. Aint ya Pop? [B]: OK, well, thanks for your time. Heres my number in case you hear of anything. Sorry to bother you. (...) Ground Truth: Police officerCivilian, Strangers Prediction: ParentChildren / Fatherson (Llama, Gemini, GPT) In Dialogue 1, speaker [A] says, thats my Dad, using Dad as reference to identify third person for the police officer [B]. However, the models latch onto this keyword and misinterpret it as term of address from [A] to [B], leading to the incorrect inference of Parent-Child relationship. This failure leads the models to ignore clear cues (e.g., [B] being called Officer) that contradict this interpretation. In Korean, this type of error is more pronounced because speakers often use addressing terms to refer to themselves. For example, teacher might say, Teacher told you to do this, 7Although analyzing CoT reasoning traces is informative, we acknowledge that they are often unfaithful and may not reflect the models actual reasoning behind its final answer. Failure to Recognize Atypical Relationships Models frequently struggle to recognize relationships that deviate from conventional or stereotypical patterns, such as non-hierarchical (equal) exchanges between parents and children or hierarchical conversation between married couple. Dialogue 3 (English): [A]: So youre seeing Mom tomorrow, huh? At my parent-teacher thing? [B]: Yeah. [A]: First time in while. [B]: Yeah, but no biggie. [B]: Hey, whats with the moping? [A]: Nothing. Its just... theres this girl. [B]: Oh yeah? You like her? [A]: like [C]. This girls my soulmate. Im like crazy, stupid, in love with her. And she wants someone else. [B]: But shes your soulmate? [A]: Yeah. Ground Truth: Parent-Children Prediction: Siblings (Llama, GPT, Gemini) In Dialogue 3, all human annotators agree on the parentchild relationship, yet the models reject it: less likely since the conversation feels more peer-like rather than hierarchical or guiding (GPT-4o), the casual tone and discussion about crush imply more peer-like relationship (Qwen-3-8b), and if [B] is the parent, they might not discuss the girl in such casual way (Llama-3.1-8b-instruct). Gemini-2.5flash likewise dismisses the parentchild relationship, reasoning that is bachelor and As parents are deceased, concluding it is not traditional parentchild relationship, revealing stereotyped conception of family roles. Failure to Understand Languageor CultureSpecific Features (Ko) In Korean, this error type accounts for the largest share of failures. Most confusions stem from the misinterpretation of terms of address and honorifics. For example, unlike English, eomeoni, literally mother, can also refer to friends mother or an older woman, yet the model often predicts parentchild relationship whenever it appears. This issue is especially pronounced in dialogues containing culturally specific terms, such as kinship expressions. For instance, Qwen misinterprets Hyungsoo (older brothers wife) as older brother, and Hyungnim as father, resulting in complete relational failure. Honorifics, another cue for social hierarchy, are also frequently misinterpretedfor example, equal relationships (e.g., friendships) predicted as hierarchical, and vice versa. Figure 4: Distribution of GPT-4os 30 failure cases by error type in English and Korean. where Teacher actually refers to oneself. However, the model incorrectly interprets Teacher as third party. Failure to Aggregate Multiple Cues Social reasoning requires the ability to identify multiple cues within the context and integrate them to arrive at conclusion. However, models fail to integrate cues, especially when their combination is atypical. Dialogue 2 (Translated from Korean): (...) [B]: (Salutes) Hey. [C]: Hey. [B]: Hey... Whats this? drowned body? Doesnt even look that deep to me. [A]: Doesnt seem like he drowned. [B]: Then what, dumped body? [A]: Nah... doesnt look dumped either. Go take closer look. Go on. [B]: Then what the hell is it? [A]: Hey B, you know, brace yourself before you look. [B]: You kidding me? Damn it... shit... Ground Truth: Friend/Coworker Prediction: Supervisor-Subordinate GPT) (Qwen, Gemini, In Dialogue 2, GPT-4o identifies three cues: (1) and converse casually without honorifics, (2) the topic concerns work, and (3) complies with As instruction. The model places greatest weight on the last cue, interpreting the interaction as hierarchical and labeling them as supervisorsubordinate. For Korean speakers, this is implausible, since subordinates are expected to use honorifics when addressing superior. The absence of honorifics indicates the relationship is not hierarchical, but rather that of coworkers or friends. This shows that even when the models detect relevant cues, they are unable to prioritize and integrate them. Additionally, we manually examine 30 failure cases of GPT-4o (best performing model), and Figure 4 presents their distribution across error types in English and Korean. In English, the majority of errors arise from Failure to Aggregate Multiple Cues (36.7%). In contrast, Korean errors are predominantly caused by difficulties in handling Languageor Culture-Specific Features (46%), with smaller proportions attributed to the other categories."
        },
        {
            "title": "6 Does Providing Additional Social",
            "content": "Information Help? Humans interpret social relationships using demographic cues and relational dimensions (Nguyen et al., 2016). We investigate whether such social information can similarly enhance the social relationship reasoning abilities of LLMs using four modelsGPT-4o, Gemini-2.5-flash, Qwen-3-8B, and Llama-3.1-8B-instructeach representing different model family while excluding thinkingenabled and Korean-specialized models.8 Specifically, we examine how providing social information influences performance in inferring social relationships, considering two types of information: demographic cues (age, gender) and relational dimensions (intimacy, hierarchy, formality). Experimental Setting We structure six experimental settings with two variables. First, we vary the type of social information: (i) age/gender only, (ii) relational dimensions only, or (iii) both. Second, we vary the source of social information: (a) human-annotated gold data, available in the dataset as metadata (see 3.3.2 for illustration), or (b) model-generated predictions, where the model infers each type of social information and incorporates these predictions into the social relationship reasoning. The accuracy of these predictions is reported in Table 15 in the appendix. Detailed experimental settings, including the prompt, appear in Appendix B.2.3. Results With Ground Truth Labels Table 5 shows GPT-4o results across six settings on the English dataset. Providing human gold information yields no substantial or consistent performance gains, but it reduces the proportion of UNLIKELY predictions. This suggests that while such information may not directly guide identification 8We find that models often rely on relational dimensions when inferring relationships; see Appendix C.1 for examples. Rel. Info. Highly Likely () Unlikely () Age & Gender Rel. Dims Both -0.0411 -0.0975 -0.0754 -0.0479 -0.0047 -0.0121 (a) With Ground Truth Labels Rel. Info. Highly Likely () Unlikely () Age & Gender Sub Dims Both -0.1507 -0.1344 -0.1529 -0.0137 -0.0084 0.0285 (b) With Model-Generated Labels Table 5: Impact of Relational Information on GPT-4os Performance. Blue indicates positive change, while Red indicates negative change. of HIGHLY LIKELY relationships, it helps models avoid UNLIKELY ones. The tendency holds across models, except for Qwen-3-8B. For instance, when models initial inference of an UNLIKELY relationship is refined into more plausible one, the label Intimate often shifts toward labels that are typically more intimate: Strangers Romantic Interest (3.3%). Similarly, when given the label No hierarchy, the most common change is also ParentChildren Friends (2.9%). Thus, dimension labels provide additional cues about relationships, enabling the model to incorporate them and reduce implausible predictions. However, these changes do not always yield correct reasoning. Sometimes models over-rely on dimensional labels rather than context. For instance, in an atypical close superiorsubordinate relationship, GPT-4o misinterprets the interaction due to the intimate tone, even when clear terms of address are present. Results With Model-Generated Labels When using model-generated information, the additional labels do not always help, as they are often inaccurateGPT-4o shows lower accuracy than 60% for age and gender inference and less than 75% for relation dimensions inference (Table 15 for detailed accuracy of four models). Specifically, when comparing the accuracy of social information inference, we find that accuracy is higher in cases where additional information improves social relationship reasoning, compared to cases where it leads to deterioration  (Table 6)  . These results suggest that demographic cues and relational dimensions, which humans naturally rely on, can facilitate social relationship reaSHIPS. We find four key failure modes in English and Korean: Models (1) confuse whether an address term refers to the speaker, the addressee, or third party, (2) fail to aggregate multiple contextual cues when they contradict each other, (3) exhibit stereotyping in relational interpretations, failing to recognize beyond typical relationships, and (4) fail to capture culture-specific nuances in social relationship reasoning, which is highly culture-dependent task. Our cross-linguistic results, including improved performance of Koreanspecific models on Korean dataset relative to that in English, demonstrates the importance of languageand culture-specific approaches to advance LLMs social reasoning abilities. We hope that SCRIPTS serves as starting point for exploring how to improve LLMs social relationship reasoning in diverse contexts."
        },
        {
            "title": "8 Limitations",
            "content": "While our dataset includes dialogues in two languages (English and Korean), thereby offering greater linguistic diversity than prior studies, the scope of our analysis remains limited to these two languages. Our findings may not fully generalize to interpersonal interactions in other languages or cultural contexts since social norms and practices vary significantly across cultures. Future work should extend this research to broader range of languages in order to more comprehensively evaluate LLMs interpersonal social reasoning abilities."
        },
        {
            "title": "9 Ethics Statement",
            "content": "This study involves human annotation, which may contain harmful or offensive content due to the nature of the source material. The study was approved by KAISTs Institutional Review Board (IRB, approved number: KAISTIRB-202561) and informed consent was obtained from all annotators prior to their involvement following the IRB-approved protocol. Social. Info. Age&gender Rel. dims. Improved (UnlikelyLikely) Deteriorated (LikelyUnlikely) 72.8 53. 65.5 50.7 Table 6: Accuracy comparison for social information inference between improved and deteriorated cases of social relationship reasoning. Rel. Info. Gemini2.5 GPT4o Llama3.1 Qwen3 Age Gender Intimacy Formality Hierarchy 0.033 -0.023 0.044 0.109 0.217 0.001 0.116 0.095 0.080 0.164 -0.051 0.074 0.134 0.099 -0. -0.079 0.085 0.070 0.029 0.150 Table 7: Regression coefficients for social information inference and social relationship reasoning performance. soning. However, current LLMs are limited in their ability to infer these dimensions, and therefore instructing LLMs to infer these factors before identifying the social relationships is ineffective. Results for other models are provided in Table 1314 in the Appendix D. Associations Between Social Information and Social Relationship Reasoning Performance To further examine the link between social information inference and relationship reasoning, we run separate logistic regressions for each factor. Table 7 shows that most factors are positively associated with social relationship reasoning. This suggests that models performing well on age, gender, and relational dimension inferences also tend to perform better on overall social relationship reasoning, highlighting the interconnections among these dimensions."
        },
        {
            "title": "7 Conclusion",
            "content": "We introduce SCRIPTS to investigate the limitations of current LLMs in social relationship reasoning. Our experiments show that most models perform suboptimally across English and Korean, and often assigns UNLIKELY relationships. Our analyses ( 4) reveal that current reasoning techniques such as CoT, while effective in other domains, do not consistently benefit social reasoning tasks. We further provide an analysis on where LLMs fail, especially focusing on cases where models respond with UNLIKELY RELATION-"
        },
        {
            "title": "References",
            "content": "Lucien Brown. 2015. Honorifics and politeness. The handbook of Korean linguistics, pages 303319. Lucien Brown, Bodo Winter, Kaori Idemaru, and Sven Grawunder. 2014. Phonetics and politeness: Perceiving korean honorific and non-honorific speech Journal of Pragmatics, through phonetic cues. 66:4560. Zhenyao Cai, Seehee Park, Nia Nixon, and Shayan Doroudi. 2024. Advancing knowledge together: integrating large language model-based conversaIn tional ai in small group collaborative learning. Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pages 19. Yi-Ting Chen, Hen-Hsen Huang, and Hsin-Hsi Chen. 2020. MPDD: multi-party dialogue dataset for analysis of emotions and interpersonal relationships. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 610614, Marseille, France. European Language Resources Association. Kyung-Sook Chung. 2010. Korean evidentials and assertion. Lingua, 120(4):932952. Markus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. Experts, errors, and context: large-scale study of human evaluation for machine translation. Transactions of the Association for Computational Linguistics, 9:14601474. Atsushi Fukada and Noriko Asato. 2004. Universal politeness theory: application to the use of japanese Journal of pragmatics, 36(11):1991 honorifics. 2002. Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad AlDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Shin-Ichi Harada. 1976. Honorifics. In Japanese generative grammar, pages 499561. Brill. Denis J. Hilton. 1995. The social context of reasoning: Conversational inference and rational judgment. Psychological Bulletin, 118(2):248271. Shin Ja Hwang. 1991. Terms of address in korean Intercultural Communicaand american cultures. tion Studies, 1(2):117136. Sachiko Ide. 1989. Formal forms and discernment: Two neglected aspects of universals of linguistic politeness. Multilingua - Journal of CrossCultural and Interlanguage Communication, 8(23):223248. Qi Jia, Hongru Huang, and Kenny Q. Zhu. 2021a. Ddrel: new dataset for interpersonal relation Proceedings classification in dyadic dialogues. of the AAAI Conference on Artificial Intelligence, 35(14):1312513133. Qi Jia, Hongru Huang, and Kenny Zhu. 2021b. Ddrel: new dataset for interpersonal relation clasIn Proceedings of sification in dyadic dialogues. the AAAI Conference on Artificial Intelligence, volume 35, pages 1312513133. Chani Jung, Dongkwan Kim, Jiho Jin, Jiseon Kim, Yeon Seonwoo, Yejin Choi, Alice Oh, and Hyunwoo Kim. 2024. Perceptions to beliefs: Exploring precursory inferences for theory of mind in large language models. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 1979419809, Miami, Florida, USA. Association for Computational Linguistics. David Jurgens, Agrima Seth, Jackson Sargent, Athena Aghighi, and Michael Geraci. 2023. Your spouse needs professional help: Determining the contextual appropriateness of messages through modeling soIn Proceedings of the 61st Ancial relationships. nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10994 11013, Toronto, Canada. Association for Computational Linguistics. Kanana LLM Team, Yunju Bak, Hojin Lee, Minho Ryu, Jiyeon Ham, Seungjae Jung, Daniel Wontae Nam, Taegyeong Eo, Donghun Lee, Doohae Jung, Boseop Kim, Nayeon Kim, Jaesun Park, Hyunho Kim, Hyunwoong Ko, Changmin Lee, KyoungWoon On, Seulye Baeg, Junrae Cho, Sunghee Jung, Jieun Kang, EungGyun Kim, Eunhwa Kim, Byeongil Ko, Daniel Lee, Minchul Lee, Miok Lee, Shinbok Lee, and Gaeun Seo. 2025. Kanana: Compute-efficient bilingual language models. Hyunwoo Kim, Melanie Sclar, Tan Zhi-Xuan, Lance Ying, Sydney Levine, Yang Liu, Joshua Tenenbaum, and Yejin Choi. 2025. Hypothesis-driven theory-of-mind reasoning for large language models. arXiv preprint arXiv:2502.11881. LG AI Research. 2025. Exaone 4.0: Unified large language models integrating non-reasoning and reasoning modes. Hengli Li, Song-Chun Zhu, and Zilong Zheng. 2023. Diplomat: dialogue dataset for situated pragmatic reasoning. Advances in Neural Information Processing Systems, 36:4685646884. Jiawen Liu, Yuanyuan Yao, Pengcheng An, and Qi Wang. 2024. Peergpt: Probing the roles of llmbased peer agents as team moderators and particiIn Expants in childrens collaborative learning. tended abstracts of the CHI conference on human factors in computing systems, pages 16. pages 33363355, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Dong Nguyen, A. Seza DogruÃ¶z, Carolyn P. RosÃ©, and Franciska de Jong. 2016. Computational sociolinguistics: Survey. Computational Linguistics, 42(3):537593. Barbara Pizziconi. 2011. Honorifics: The cultural specificity of universal mechanism in japanese. In DÃ¡niel Z. KÃ¡dÃ¡r and Sara Mills, editors, Politeness in East Asia, pages 4570. Cambridge University Press. Farzana Rashid and Eduardo Blanco. 2018. Characterizing interactions and relationships between people. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 43954404, Brussels, Belgium. Association for Computational Linguistics. Claudia G. Sehl, Ori Friedman, and Stephanie Denison. 2023. The social network: How people infer relationships from mutual connections. Journal of Experimental Psychology: General, 152(4):925934. Anna Tigunova, Paramita Mirza, Andrew Yates, and Gerhard Weikum. 2021. PRIDE: Predicting RelaIn Proceedings of the tionships in Conversations. 2021 Conference on Empirical Methods in Natural Language Processing, pages 46364650, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824 24837. Myron Wish, Morton Deutsch, and Susan Kaplan. 1981. Perceived dimensions of interpersonal relations. In The Psychology of Social Situations, pages 113129. Elsevier. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. 2025. Qwen3 technical report. arXiv preprint arXiv:2505.09388. Dian Yu, Kai Sun, Claire Cardie, and Dong Yu. 2020. Dialogue-based relation extraction. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 49274940, Online. Association for Computational Linguistics. Haolan Zhan, Zhuang Li, Yufei Wang, Linhao Luo, Tao Feng, Xiaoxi Kang, Yuncheng Hua, Lizhen Qu, Lay-Ki Soon, Suraj Sharma, et al. 2023. Socialdial: benchmark for socially-aware dialogue systems. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 27122722. Chen Zhang, Luis Fernando DHaro, Qiquan Zhang, Thomas Friedrichs, and Haizhou Li. 2022. FineDeval: Fine-grained automatic dialogue-level evaluation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, Figure 5: Annotation Platform. The annotators can read the dialogue on the left side and annotate the relationships and relational dimensions on the right side."
        },
        {
            "title": "A Dataset",
            "content": "We source dialogues from movie scripts. The collection process consist of the following steps: (1) movie selection, (2) raw scene collection, (3) OCR processing and human verification, (4) scene filtering (5) anonymization, and (6) relationship annotation. A.1 Movie Selection We select the movies based on the following criteria to capture daily real-life interactions. Only modern-day movies released after 2000 are included, excluding medieval fantasy or alien sci-fi. We consider age limits, only including movies up to PG-13 for English movies and up to 15ì¸ ê´ë ê° (suitable for audiences aged 15 and above) for Korean movies. We collect English movie scripts from IMSDb.9 For Korean movies, due to the limited online dialogue resources, we visited the Korean Film Archive (KOFA)10 to collect physical copies of movie scripts. From KOFA, we only collect onethird of each movie script to adhere to the data use policy. Also, we collect additional movie scripts 9https://imsdb.com 10http://www.kmdb.or.kr/ from Filmmakers Online Community.11 In total, we collect 60 movies (28 English, 32 Korean) across various genres. A.2 Raw Scene Collection and Processing For physical copies of Korean movies from KOFA, we use NAVER CLOVA OCR API to extract dialogue texts.12 After OCR, we use GPT-4o to further process and clean the text into structured format. Human annotators then verify and modify the outputs with the original PDF files. As result, we obtain 16k English and 7k Korean scenes. A.3 Scene Filtering Scenes are filtered to include at least four utterances, and involve two to three speakers. To maximize speaker diversity, we prioritize scenes with unique set of speakers. Using these criteria, we select 1,322 scenes from an initial pool of 23k scenes, comprising 698 English and 624 Korean evaluation sets. The selected movies and the number of scenes per movie are listed in Table 16. A.4 Anonymization To mitigate potential data contamination (e.g., identifying the source movie) and reduce bias 11https://www.filmmakers.co.kr/ 12https://www.ncloud.com/product/aiService/ocr (e.g., gender inference), all character names are automatically replaced with placeholders such as [A] and [B]. Any names not covered by this process are further verified and anonymized manually. A.5 Human Annotation We construct golden answer set with human annotators who have over ten years of experience in the target language and culture. Annotators include undergraduate and graduate students in South Korea and the United States, compensated at 1.5 times the minimum hourly wage in their country. Before annotation, they attend an introductory session covering data usage policies and guidelines. For social relationships, annotators are given an initial set of possible relationships  (Table 9)  , adapted from Tigunova et al. (2021), and asked to mark UNLIKELY ones. To reduce workload, annotators first choose LIKELY relationship categories for each dialogue, then select the UNLIKELY relationships from the list of specific relationships in those categories. They also provide up to five open-ended answers describing relationships that best characterize the interaction. These serve as candidates for LIKELY relationships. For relational dimensions, we provide annotators with definitions of each dimension and ask them to rate dialogues on 5-point scale: intimacy (from strongly intimate to strongly unintimate), formality (from strongly formal to strongly informal), and hierarchy (from AB to AB). When constructing the golden labels, we collapse the ratings into 3-point scale (e.g., intimate, neutral, unintimate) and assign the majority-voted label. The inter-annotator agreement is reported in Table 8. Figure 5 shows the human annotation platform: the anonymized scene appears on the left, and annotation questions on the right. All annotations were conducted with IRB approval. We recruited 17 English annotators (7 male, 10 female) and 14 Korean annotators (5 male, 9 female). All annotators were undergraduate or graduate students enrolled at universities in the United States or Korea. The Korean annotators were all native speakers, while the English annotators were either U.S. citizens or individuals who had lived in the United States for over ten years. For quality control, applicants were asked to complete the task on three sample items during recruitment, and their responses were reviewed by the authors to select the final annotators. After selection, annotators participated in an orientation session and training phase designed to support them in performing the task as effectively as possible. A.6 Diversity of SCRIPTS Figure 6 presents the ten most common relationships in each language. Both the English and Korean datasets frequently include social (e.g., friends, acquaintances), organizational (e.g., coworkers, supervisor-subordinate), and familial (e.g., parent-child, siblings) relationships. Beyond these shared categories, we also examine which relationship types appear exclusively in Korean or English. Each dataset contains culturally specific relationships that reflect distinct social roles and lexicalizations. Korean-only relations include North Korean soldiercitizen (1), shamanclient (2), shaman assistant (1), private tutorstudent (1), and students family acquaintancetutor (1). In addition, kinship terms are more fine-grained in Korean: for example, distinctions such as older brother younger brother (1) and older brothersister-inlaw (1), whereas in English these are typically generalized under single siblings category. English-only relations include roles such as father figurechild, mother figurechild, co-parents, and babysitterchild, reflecting cultural and social roles that are more explicitly lexicalized in English. These findings highlight how cultural context shapes the granularity and salience of social relationships represented in dialogue datasets."
        },
        {
            "title": "All",
            "content": "2>"
        },
        {
            "title": "All",
            "content": "2>"
        },
        {
            "title": "All",
            "content": "2> EN 0.333 KO 0.462 0.416 0.550 0.408 0.469 0.513 0.562 0.314 0. 0.426 0.458 Table 8: Inter-annotator agreement (Fleiss Îº) by relational dimension. 2> indicates samples with at least two annotators in agreement. We used these filtered samples in our experiments. Figure 6: Top 10 Relationships in each Language dataset. Category Specific Relationships B.2 Prompt Family Social Romance Parent-Children, Brothers/Sisters, Grandparent-Grandchildren, Cousins, Uncle/Aunt-Niece Friends, Acquaintances, Neighbors, Strangers Romantic Interest, Dating, Married, Engaged, Friends wth benifits, Affair, Ex-relationship Organizational Coworkers, Professonal colleagues, Supervisor-Subordinate relationship Role-based Antagonist Mentor-Mentee, Teacher-Student, Lawyer-Client, Doctor-Patient, Landlord-Tenant Competitive relationship, Rivalry, Arch-enemies Table 9: Initial Relationship Categories and Specific Relationships"
        },
        {
            "title": "B Experiment",
            "content": "B.1 Model Configuration We use total nine models, GPT-4o13, o314, Gemini-2.5-flash, Qwen-3-{8B/14b} (Yang et al., 2025), Llama-3.1-8B-instruct (Grattafiori et al., 2024), A.X-4.0-light-7B15, Kanana-8B16 , and Exaone-4.0-30B (LG AI Research, 2025). For GPT-4o, we use the gpt-4o-2024-05-13 version via the OpenAI API. For Gemini-2.5-Flash, we use OpenRouter (openrouter.ai). We set the temperature of the models to 1. 13https://platform.openai.com/docs/models/gpt-4o 14https://platform.openai.com/docs/models/o3 15https://github.com/SKT-AI/A.X-4.0 16https://github.com/kakao/kanana B.2.1 Prompt for Evaluation"
        },
        {
            "title": "Prompts for Evaluation",
            "content": "You are judge that evaluates the correctness of relation classification outputs from the model. Your task is to check each relation in the models output and determine whether it belongs to the *Possible* or *Impossible Relation Sets* provided. For each relation: If it is included in the Possible Relation Sets, mark \"is_in_possible\": 1, otherwise mark it as 0. Similarly, if it is included in the Impossible Relation Sets, mark \"is_in_impossible\": 1, otherwise mark it as 0. Answer **only** in the following JSON format (no explanations): Possible Relation Sets: {gt_list} Impossible Relation Sets: {impossible_gt_list} Model output: {model_outputs} Output in JSON format: { relation1 : { \"is_in_possible\": 1, \"is_in_impossible\": 0 }, relation2 : { \"is_in_possible\": 0, \"is_in_impossible\": 1 }, ... } Output: B.2.2 Prompt for Inference Prompt for Inference(EN) Read the following conversation and guess the relationship of the participants [A] and [B]. When guessing the relationship, refer to the following examples of relationships: {example_relations} If the relationship matches one of the examples above, use it as is, but if the relationship does not fit any of the examples, describe the relationship yourself. Your answer about the relationship must be in JSON format: { } \"relation\": \"\" {Additional Information} Conversation: {dialogue} Output (JSON): Prompt for Inference(KO) ë¤ì ëíë¥¼ ì½ê³ , ë±ì¥ì¸ë¬¼ Aì Bì ê´ê³ë¥¼ ì¶ì¸¡ íìì¤. ê´ê³ë¥¼ ì¶ì¸¡í  ëë ë¤ìì ê´ê³ ììë¥¼ ì°¸ê³ íì ì¤: {example_relations} ë§ì½ ìì ììì í´ë¹íë ê´ê³ë¼ë©´ ê·¸ëë¡ ì¬ì© íê³ , ììì ìë ê´ê³ë¼ê³  íë¨ëë©´ í´ë¹ ê´ê³ë¥¼ ì§ì  ìì íìì¤. ê´ê³ì ëí ìµì¢ ëµì ë°ëì JSON íìì¼ë¡ ëµ ë³íìì¤: { \"relation\": \"\" } {Additional Information} ëí: {dialogue} Output (JSON):"
        },
        {
            "title": "English Relations",
            "content": "[ \"Parent-Children\", \"Brothers/Sisters\", \"Grandparent-Grandchildren\", \"Cousins\", \"Uncle/Aunt-Niece\", \"Friends\", \"Acquaintances\", \"Neighbors\", \"Strangers\", \"Romantic Interest\", \"Dating\", \"Married\", \"Engaged\", \"Friends with benefits\", \"Affair\", \"Ex-relationship\", \"Coworkers\", \"Professional colleagues\", \"Supervisor-Subordinate relationship\", \"Mentor-Mentee\", \"Teacher-Student\", \"Lawyer-Client\", \"Doctor-Patient\", \"Landlord-Tenant\", \"Competitive relationship\", \"Rivalry\", \"Arch-enemies\" ]"
        },
        {
            "title": "Korean Relations",
            "content": "[ \"ë¶ëª¨-ìì\", \"íì /ìë§¤/ë¨ë§¤\", \"ì¡°ë¶ëª¨-ìì£¼\", \"ì¬ì´\", \"ì¼ì´/ì´ëª¨/ê³ ëª¨-ì¡°ì¹´\", \"ë¨ì§ ì¹êµ¬\", \"ì¹êµ¬\", \"ì§ì¸\", \"ì´ì\", \"ëª¨ë¥´ë ì¬ì´\", \"ì¸\", \"ì°ì \", \"ë¶ë¶\", \"ì½í¼ê´ê³\", \"Friends with benefits\", \"ë¶ë¥ê´ê³\", \"ì ì ì¸ ê´ê³\", \"ëë£\", \"ì§ì¥ ëë£\", \"ìê´-ë¶íì§ì ê´ê³\", \"ë©í -ë©í°\", \"ì ì-ì ì\", \"ë³í¸ì¬-ê³ ê°\", \"ìì¬-íì\", \"ì§ì£¼ì¸-ì¸ìì\", \"ê²½ìê´ê³\", \"ë¼ì´ë² ê´ê³\", \"ìì \" ] CoT setting: We append Think step by step at the end of the prompt to encourage chain-ofthought reasoning. B.2.3 Prompts Used in 6 For the experiment in 6, we add additional information to the prompt. The additional information consists of two types: Age & Gender and Relational Dimensions. The prompts for each type are as follows. In the Ground Truth Labels setting, we fill the placeholders {age_gender_info} and {relational_dimensions_info} with human-annotated gold labels. In the Model-Generated Labels setting, the model is first asked to separately infer each type of information, and the infer results are then inserted back into the corresponding placeholders. Model English Korean Highly Likely () Unlikely () Highly Likely () Unlikely () GPT-4o Gemini-2.5-flash Qwen-3-8b Llama-3.1-8b 0.7910 0.7582 0.5648 0.4128 0.1088 0.1554 0.2360 0.3074 0.6931 0.5894 0.4233 0.3210 0.2187 0.3204 0.3351 0.5220 Table 10: Comparison of model performance in English (En) and Korean (Ko) datasets. HIGHLY LIKELY represents the accuracy of the models majority response being highly likely response, while UNLIKELY indicates the error rate where the model generate an unlikely response. Additional Information(EN) Qualitative Analysis - Cues Base setting: None C.1 What cues do LLMs rely on in social Age & Gender: The age and gender information of the participants [A] and [B] are as follows. Please refer to them when inferring the nature of their relationship. {age_gender_info} Relational Dimensions: The Intimacy level, Pleasure level, and Hierarchy level between and in the conversation are as follows. Please refer to them when inferring the nature of their relationship. {Relational Dimensions_info} Additional Information(Ko) Base setting: None Age & Gender: ë±ì¥ì¸ë¬¼ Aì Bì ëì´ì ì±ë³ì ë¤ìê³¼ ê°ë¤. ê·¸ë¤ì ê´ê³ì ì±ê²©ì ì¶ë¡ í  ë ì°¸ê³  íë¼. {age_gender_info} Relational Dimensions: ëíìì Aì ì¬ì´ì ì¹ë°ê°(Intimacy) ìì¤, ê²©ì(Formality) ìì¤, ê·¸ë¦¬ ê³  ìê³(Hierarchy) ìì¤ì ë¤ìê³¼ ê°ë¤. ê·¸ë¤ì ê´ ê³ì ì±ê²©ì ì¶ë¡ í  ë ì°¸ê³ íë¼. {Relational Dimensions_info} B.3 Validating LLM-as-a-Judge To validate the accuracy of GPT-4o as an evaluator, we sample 100 questionanswer pairs for each language, and two authors independently verify the results. As result, GPT-4o has accurately evaluated in 97.85% of the responses in English and 86.2% in Korean, with an inter-annotator agreement of 96% (Cohens Îº = 0.58) between the two authors. B.4 Results See Table 10 for the complete results, Table 11 for results with CoT prompting, and Table 12 for results from Korean-specialized models. reasoning? To understand how models use and integrate cues to infer social relationships, we conduct qualitative analysis on their CoT reasoning. Terms of Address and Reference LLMs frequently leverage terms of address and references as explicit cues to infer social relationships. For instance, when speaker use terms like Daddy or Professor [B], the models infer familybased or professional relationship. Self-reference also provide valuable information. For example, speaker introducing themselves as Doctor [A] signals their professional identity as medical practitioner, leading to LLMs suggesting relationships such as Doctor-Patient or Doctor-Doctor. Furthermore, LLMs analyze how individuals refer to third parties to understand the relationship between the referring individuals themselves. For example, if both and refer to third person as Sergeant [C], the LLM can infer that and are likely colleagues within military context, and that their shared use of formal title suggests potentially task-oriented conversation. Conversation context and background LLMs also take into account the context of the conversation (e.g., school, church, workplace, home). They then utilize this background information to infer the social relationship or level of intimacy between the individuals involved in the dialogue. Tone or Atmosphere LLMs also assess the emotional tone of individuals in dialogue to judge their social dimensions, particularly intimacy and formality, utilizing that information to infer their social relationship. The models often associate casual, friendly, teasing, empathetic, or supportive tones with more intimate relationships Model En Ko High Probable () Impossible () High Probable () Impossible () GPT-4o Gemini-2.5-flash Qwen-3-8b Llama-3.1-8b 0.8024 (0.0114) 0.7412 (-0.0170) 0.6882 (0.1332) 0.5410 (0.0868) 0.0971 (-0.0117) 0.1265 (-0.0289) 0.1513 (-0.1261) 0.2667 (-0.0410) 0.6953 (0.0022) 0.6031 (0.0137) 0.4974 (0.023) 0.2996 (-0.0578) 0.2025 (-0.0162) 0.2010 (-0.1194) 0.3651 (-0.0259) 0.5769 (0.0306) Table 11: Comparison of model performance with Chain of Thought Prompting across English (En) and Korean (Ko) with deltas in parentheses. Model En High Probable () Ko Impossible () High Probable () Impossible () ax-4.0-light exaone-4.0-32b kanana-1.5-8b 0.5889 0.3178 0.4059 0.1934 0.3074 0.2884 0.4674 0.4092 0.328 0.4127 0.4674 0.3739 Table 12: Performance of Korean Specialized models in English and Korean. while aggressive, frustrated, or angry expressions are linked to less intimate or strained relationships. Similarly, emotional expressions, whether friendly or hostile, are often connected to informal relationships while the models associate serious, indifferent, dismissive, or emotionally neutral expressions with formal relationships. Relational Dimensions When inferring social relationships, models often consider relational dimensions (intimacy, hierarchy, formality) in their rationale. For instance, in dialogue where playfully jokes with while shares personal concerns, the model infers strong intimacy and suggests close tie such as friendship or siblinghood. However, it is important to note that while using social dimensions as cue, particularly hierarchy, LLMs often reveal social stereotypes, defining typical relational dimensions to certain relationships. For example, models assume that parent-child inherently shares hierarchical relationship while married couple would generally have non-hierarchical(equal) relationship. This lead to failures when the social interaction deviate from these norms, real-life atypical relationships."
        },
        {
            "title": "D Does Providing Additional Social",
            "content": "Information Help? This section provides supplementary material for Section 6. Tables 1314 present the results across models, while Table 15 report the accuracy of inferring social information."
        },
        {
            "title": "Model",
            "content": "GPT-4o Age & Gender Rel. Dims Both Gemini-2.5-flash Age & Gender Rel. Dims Both Qwen-3-8b Age & Gender Rel. Dims Both Llama-3.1-8b Age & Gender Rel. Dims Both Highly Likely () Unlikely ()"
        },
        {
            "title": "Model",
            "content": "Highly Likely () Unlikely () -0.0411 -0.0975 -0.0754 -0.0411 -0.1563 -0.1452 0.0127 -0.1580 -0.1138 0.0205 -0.0123 0.0505 -0.0479 -0.0047 -0. -0.0343 -0.0570 -0.0534 0.0392 0.1209 0.0398 -0.1027 -0.0735 -0."
        },
        {
            "title": "GPT",
            "content": "Age & Gender Sub Dims Both"
        },
        {
            "title": "Gemini",
            "content": "Age & Gender Sub Dims Both"
        },
        {
            "title": "Qwen",
            "content": "Age & Gender Sub Dims Both"
        },
        {
            "title": "Llama",
            "content": "Age & Gender Sub Dims Both -0.1507 -0.1344 -0.1529 -0.1027 -0.1194 -0.1711 -0.0395 -0.0237 -0.0916 0.0548 0.0099 -0.0492 -0.0137 -0.0084 0. -0.0137 -0.0460 -0.0017 0.0321 0.0442 0.0435 -0.0137 -0.0514 -0.0145 (a) With Ground Truth Labels (b) With Model-Generated Labels Table 13: Impact of Relational Information on Model Performance (English)."
        },
        {
            "title": "Model",
            "content": "GPT-4o Age & Gender Sub Relation Both Gemini-2.5-flash Age & Gender Sub Relation Both Qwen-3-8b Age & Gender Sub Relation Both Llama-3.1-8b Age & Gender Sub Relation Both High Prob. () Impossible ()"
        },
        {
            "title": "Model",
            "content": "High Prob. () Impossible () -0.0122 0.0356 0.0383 0.0123 0.0795 0.0932 -0.1021 -0.0740 -0.0631 -0.0285 -0.0274 0.0082 0.0041 -0.0328 -0. -0.0285 -0.0740 -0.0904 0.1796 0.0795 0.0384 -0.0735 -0.1644 -0.1315 GPT-4o Age & Gender Sub Relation Both Gemini-2.5-flash Age & Gender Sub Relation Both Qwen-3-8b Age & Gender Sub Relation Both Llama-3.1-8b Age & Gender Sub Relation Both -0.0285 0.0329 -0.0055 0.0123 -0.0466 0. -0.1796 -0.0055 -0.0905 -0.1061 -0.0932 -0.0165 0.0490 0.0028 0.0165 -0.0244 0.0795 -0.0137 0.1877 0.0329 0.1014 -0.0245 0.1315 -0. (a) With Ground Truth Labels (b) With Model-Generated Labels Table 14: Impact of Relational Information on Model Performance (Korean)."
        },
        {
            "title": "Formality Hierarchy Overall",
            "content": "GPT-4o Gemini-2.5-Flash Qwen3-8b Llama-3.1-8b 49.1% 51.65% 41.45% 30.25% 44.45% 36.2% 42.7% 57.85% 62.7% 78.3% 42.5% 61.6% 73.8% 76.8% 40.0% 71.1% 71.5% 69.9% 54.4% 47.4% 60.1% 57.5% 40.9% 47.8% Table 15: Accuracy of Inferring Relational Information. Language Movie Title Movie Title (Ko) Genre Year # of Scenes EN KO Amelia Autumn in New York Big Fish Bruce Almighty Crazy Love Crazy, Stupid, Love. Date Night Easy Hes Just Not That Into You Larry Crowne Monte Carlo Moonrise Kingdom New York Minute Somethings Gotta Give Speed Racer The Blind Side The Bounty Hunter The Brothers Bloom The Curious Case of Benjamin Button The Fault in Our Stars The Italian Job The Invention of Lying The Next Three Days The Pacifier The Secret Life of Walter Mitty The Theory of Everything Water for Elephants Wild Hogs - - - - - - - - - - - - - - - - - - - - - - - - - - - - Adventure, Biography, Drama Drama, Romance Adventure, Epic, Drama Comedy, Fantasy Documentary, Romance Romance, Comedy, Drama Romance, Comedy, Crime Comedy, Drama, Romance Romance, Comedy, Drama Comedy, Drama, Romance Adventure, Comedy, Family Romance, Adventure, Comedy Comedy, Adventure, Crime Comedy, Drama, Romance Action, Adventure, Comedy Drama, Biography, Sport Comedy, Action, Romance Comedy, Action, Adventure Drama, Fantasy, Romance Drama, Romance Action, Crime, Thriller Comedy, Fantasy, Romance Thriller, Action, Drama Action, Comedy, Drama Adventure, Comedy, Romance Drama, Biography, Romance Drama, Romance Action, Adventure, Comedy ë¯¸ëë ê´´ë¡ì ê²ì¬ì¸ì  Comedy, Drama, Music Action, Comedy, Crime Action, Drama, History Action, Crime, Thriller Drama, Sci-Fi, Thriller Comedy Comedy, Crime Horror, Mystery, Thriller Action, Adventure, Comedy Biography, Drama, Sport Drama, History Comedy, Fantasy, Music 200 Pounds Beauty Violent Prosecutor Battle for Incheon: Operation Chromite ì¸ì²ìë¥ìì  Cold Eyes Deranged Exit Extreme Job Hide and Seek Jeon Woochi Marathon May 18 Miss Granny My Tutor Friend Northern Limit Line Ode to My Father Pandora Punch Secret Reunion Secretly, Greatly Silmido Sunny Take Off The Attorney The Berlin File The Himalayas The Neighbors The Priests The Roundup The Thieves Tidal Wave Tunnel Veteran ê°ììë¤ ì°ê°ì ììí¸ ê·¹íì§ì ì¨ë°ê¼­ì§ ì ì°ì¹ ë§ìí¤ íë ¤í í´ê° ììí ê·¸ë ëê°ë´ê¸° ê³¼ì¸íê¸° Action, Comedy, Romance ì°íí´ì  Drama, War êµ­ì ìì¥ Drama, War íëë¼ Disaster, Action, Drama ìëì´ Comedy, Drama, Sport ìíì  Action, Drama, Thriller ìë°íê² ìëíê² Drama, Action, Comedy ì¤ë¯¸ë ì¨ë êµ­ê°ëí ë³í¸ì¸ ë² ë¥¼ë¦° íë§ë¼ì¼ ì´ìì¬ë ê²ì ì¬ì ë¤ ë²ì£ëì2 ëëë¤ í´ì´ë í°ë ë² íë Action, Drama Comedy, Drama Comedy, Drama, Sport Crime, Drama, History Spy, Action, Thriller Adventure, Biography, Drama Thriller, Mystery Horror, Mystery, Thriller Action, Crime, Thriller Action, Comedy, Crime Action, Drama, Sci-Fi Disaster, Drama Action, Comedy, Crime 2009 2000 2003 2003 2007 2011 2010 2010 2009 2011 2011 2012 2004 2003 2008 2009 2010 2008 2008 2014 2003 2009 2010 2005 2013 2014 2011 2007 2006 2016 2016 2013 2012 2019 2019 2013 2009 2005 2007 2014 2003 2015 2014 2016 2011 2010 2013 2003 2011 2009 2013 2013 2015 2012 2015 2022 2012 2009 2016 17 26 27 32 21 39 24 45 16 15 6 6 59 21 7 16 21 15 22 17 22 20 12 16 12 13 15 18 28 8 9 13 15 19 1 3 3 20 13 15 36 11 11 29 25 24 13 24 31 31 7 18 5 36 9 21 31 17 35 6 Table 16: List of movies in SCRIPTS. The genre (top three) and release year are sourced from IMDb. The dataset contains 60 movies (English 28 / Korean 32) spanning various genres."
        }
    ],
    "affiliations": [
        "Boston University",
        "KAIST",
        "University of Ghent"
    ]
}