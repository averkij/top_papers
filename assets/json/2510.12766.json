{
    "paper_title": "Language Models Model Language",
    "authors": [
        "Łukasz Borchmann"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Linguistic commentary on LLMs, heavily influenced by the theoretical frameworks of de Saussure and Chomsky, is often speculative and unproductive. Critics challenge whether LLMs can legitimately model language, citing the need for \"deep structure\" or \"grounding\" to achieve an idealized linguistic \"competence.\" We argue for a radical shift in perspective towards the empiricist principles of Witold Ma\\'nczak, a prominent general and historical linguist. He defines language not as a \"system of signs\" or a \"computational system of the brain\" but as the totality of all that is said and written. Above all, he identifies frequency of use of particular language elements as language's primary governing principle. Using his framework, we challenge prior critiques of LLMs and provide a constructive guide for designing, evaluating, and interpreting language models."
        },
        {
            "title": "Start",
            "content": "Łukasz Borchmann Snowflake AI Research lukasz.borchmann@snowflake.com 5 2 0 2 4 1 ] . [ 1 6 6 7 2 1 . 0 1 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Linguistic commentary on LLMs, heavily influenced by the theoretical frameworks of de Saussure and Chomsky, is often speculative and unproductive. Critics challenge whether LLMs can legitimately model language, citing the need for deep structure or grounding to achieve an idealized linguistic competence. We argue for radical shift in perspective towards the empiricist principles of Witold Manczak, prominent general and historical linguist. He defines language not as system of signs or computational system of the brain but as the totality of all that is said and written. Above all, he identifies frequency of use of particular language elements as languages primary governing principle. Using his framework, we challenge prior critiques of LLMs and provide constructive guide for designing, evaluating, and interpreting language models."
        },
        {
            "title": "Introduction",
            "content": "For two thousand years, language scholars have produced myriad works without clearly defining way to validate their claims (Manczak, 1981, 1996c). This lack of rigor left the field uniquely unprepared for the empirical success of Large Language Models (LLMs). When GPT or Claude synthesizes complex responses, most users of LLMs perceive this ability as sign of linguistic competence. At the same time, orthodox linguists rush to claim that apparent competence is merely an illusion, because LLMs architecture and training techniques do not fit established theories of language. These objections reveal more about current linguistic dogma than about the capabilities of LLMs. Debate remains anchored in theoretical frameworks inherited from de Saussures abstract system of signs, Chomskys postulated innate mental grammar, and even Platos conception of language as communication tool. When scholars criticize LLMs for failing to explain the rules of English syntax (Chomsky et al., 2023), point out that they dont distinguish between correctness and likelihood (Fox and Katzir, 2024), or question whether they can have access to meaning despite experiencing only form (Bender et al., 2021), these researchers apply criteria derived from specificand contestabletheories. Such critiques function less as objective assessments of LLMs capacities than defenses of linguistic paradigm that has been challenged by new empirical evidence. We propose radical theoretical reorientation and turn to Witold Manczak (1924-2016), whose critique of abstract, dualistic linguistics offers an alternative foundation. While Bender et al. (2021) advocate constraining the LLMs tendency to act like stochastic parrots, we call for new science of ornithology that is equipped to understand what has actually taken flight."
        },
        {
            "title": "2 The Ma ´nczakian Framework",
            "content": "The Manczakian framework is best understood as response to what its author saw as foundational crisis in linguistics: the absence of scientific criteria for determining truth. Manczak argued that the field had long substituted the authority of famous scholars for the authority of verifiable evidence (Manczak, 1980, 1981, 1982, 1988a, 1996c). The central goal of his work was to reground linguistics as an inductive, quantitative science. He insisted that any valid claim must be subject to statistical or experimental verification and explained by observable phenomena rather than abstract speculation. Applying quantitative methods to vast corpora, he discovered that frequency of use of language elements is primary force shaping language. We will now unpack these core tenets, demonstrating how the empiricist lens of Manczak reScience of Language Language Definition Frequent Errors Become Norms frames long-standing linguistic debates and provides robust foundation for the science of language and language models. 2.1 The Map Is Not the Territory Manczak found it absurd that people would claim to study an intangible system of signs or mental competence when their actual work involved poring over concrete texts. He proposed simple, naturalistic definition: language is the totality of all that is said and written. The fundamental error of modern linguistics is the false equivalence between the product of particular analysis and the object of the study itself (Manczak, 1969a). The Primacy of Frequency. Where structuralists and their successors saw dichotomies, Manczak saw continuum governed by statistics. For example, in his view, the dichotomy between grammar and lexicon is false, because grammar is the quintessence, condensation, abbreviation, or generalization of lexicography (Manczak, 1996h). Grammar covers only high-frequency patterns that apply to large classes of words. Lexicography, in contrast, handles the information for all individual words, including the less frequent and more idiosyncratic. Even the distinction between rule and exception is quantitative, not qualitative: highfrequency patterns are rules, while low-frequency patterns are exceptions. We can interpret Manczaks perspective in the light of Jaynes theory, according to which the absolute True/False statements of classic logic are seen as special case of more general, probabilistic logic (Jaynes, 2003). In this framing, Manczakian rule corresponds to high-plausibility inference, while an exception represents low-plausibility inference. Importantly, according to Manczak (1969a) the rules of grammar, once abstracted from texts, do not prevent the subsequent evolution of language. This evolution consists of errors which, if their frequency increases sufficiently, become new norms. Conversely, old norms, if their frequency diminishes, become errors. Example 1 presents three examples from the evolution of Latin into Romance languages that illustrate how frequency drives linguistic change and, crucially, how grammatical rules themselves are merely abstractions from this ongoing evolution. Language Acquisition. Manczaks claim that frequency of use in language is primary organizing principle is strongly supported by decades of research in cognitive science. Studies show that frequency affects nearly every level of language processing in humans, from the recognition of sounds and words to the processing of syntax (Saffran et al., 1996; Romberg and Saffran, 2010; Fló et al., 2025, inter alia). High-frequency patterns are processed more quickly and accurately, and learned earlier by children, confirming that the human mind is finely tuned to the frequency of exposure to particular language elements (Ellis, 2002). This statistics-based view of language contrasts strikingly with dominant linguistic paradigms. As Manczak noted, the fact that, in the three hundred pages of [de Saussures] Course in General Linguistics the term frequency of use does not appear even once, has serious implications (Manczak, 1969a). When frequency is ignored, linguists must invent increasingly elaborate theoretical constructsdeep structures, innate faculties, universal grammars to explain what simple statistical patterns readily predict."
        },
        {
            "title": "2.2 Talkin’ All About That Syntax When You",
            "content": "Cant Even Generate Haiku Once invented, these constructs then take on life of their own. Critics of LLMs now assert that true linguistic competence requires an innate deep structure or internal form of language. This claim mistakenly interprets the linguists abstract analysis as the functional prerequisite of language itself. As Manczak (1996a) puts it: If layman were to try to convince chemist that water is composed not of two elements (i.e., oxygen and hydrogen) but of four, the chemist would shrug his shoulders and conclude that the third and fourth elements exist only in the laymans imagination, because chemists have succeeded countless times in synthesizing water from only two elements. Now, the principle that synthesis [reconstructing coherent whole] is required to validate analysis [breaking things down into components] . . . should be applied to linguistics. Linguists who analyze text should look for only those components that are essential for its synthesis and must validate their analyses by means of synthesis. He similarly criticized proponents of the generative and transformational grammars that dominated Result of Ignoring Frequency Table 1: Comparison of dominant and Manczakian linguistic paradigms. Aspect Dominant Paradigms Ma nczakian Paradigm Definition of Language An abstract system of signs (de Saussure) or mental competence distinct from performance (Chomsky). The material totality of all that is said and writtenthe actual corpus of texts. Organizing Principle Innate universal grammar; binary structural oppositions; algebraic rules for generating well-formed sentences. Status of Grammar pre-existing mental mechanism in the mind. Frequency of use. High-frequency patterns become rules; low-frequency patterns are exceptions on the same continuum. post-hoc descriptive abstraction created by linguists from observed patterns in texts. Validation Method View of Meaning Assessment of LLMs Subjective sense of grammaticality; theoretical elegance; appeal to linguistic intuition and dogma. Synthesis validates analysis. theory is valid only if it can be used to reconstruct what it claims to explain. Requires grounding in deep structure or real-world referents. Form and meaning are fundamentally separate. Primarily relational, derived from network of connections between words. Most meanings exist within the axiomatic system of language. Fundamentally flawed stochastic parrots lacking access to deep structure or grounded meaning. large-scale, empirical validation. Not broken in principle but incomplete in practice. Three studies from Latins evolution into Romance languages (A) Analogical Regularization. Classical Latin used mix of rules to form words representing quantities. While 17 was additive (septendecim seven-ten), 18 and 19 were subtractive (duodeviginti two-from-twenty, undeviginti one-from-twenty). In the evolution of Latin to the Romance languages, these irregular subtractive forms were almost universally abandoned. These were replaced by more regular, compound forms analogically derived from simpler additive rules (e.g., Italian diciotto ten-and-eight). Additive rules served as the model for simplifying the rarer, more complex subtractive ones (Manczak, 1958, 1978, 1996e). (B) Irregular Development due to Frequency. The evolution of the Latin verb ambulare to walk illustrates how usage frequency shapes language. The form of the word diverged based on its function. Everyday use resulted in significant irregular shortening, leading to French aller, Italian andare, and Spanish andar. Infrequent use in specific contexte.g., to amble, which began as specialized equestrian termretained more regular and archaic form: French ambler, Italian ambiare, and Spanish amblar. The fact that high-frequency words are prone to irregular change, while less common words often preserve their regular, historical forms, is common linguistic phenomenon (Manczak, 1969b,c, 1987, 1988b, 1996d, inter alia). (C) Grammaticalization. fundamental shift in the history of Romance languages is the emergence of the have + participle construction to express the perfect tense (e.g., French il chanté he has sung). This developed from Classical Latin, where the verb habere was normal lexical verb meaning to possess or to hold. This new, constant grammatical use created functional split. The words original meaning has been mostly replaced by its modern role as grammatical tense marker (Manczak, 1996g). Example 1: Examples from the evolution of Latin into the Romance languages, demonstrating the impact of frequency and temporal character of grammar: (A) analogical regularization of numerals, (B) divergent evolution depending on usage frequency, and (C) grammaticalization from lexical verb to perfect tense marker. 20th-century linguistics. Manczak noted with irony that while champions of these theories filled entire volumes with abstract formalisms, their analysis was never validated by synthesis. More than half century after the generative turn, its adherents had not yet written single generative or transformational grammar of concrete language (Manczak, 1996b). The roar of generative theory LLMs and Frequency Failure to Synthesize had produced not even whisper of practical synthesis. This failure becomes evident if we review the actual analyses. As Manczak pointed out, Chomsky, to analyze sentence as simple as sincerity may frighten the boy, needed 10 pages in his book Aspects of the Theory of Syntax, whereas to reconstruct this sentence, it is enough to cite only five simple positional rules as illustrated in Example 2 (Manczak, 1996b). The principle that should guide any scientific grammarsynthesis validates analysiswas, as Manczak observed, completely unknown to Chomsky. Yet linguists tolerated lack of validation for decades, mistaking Chomskys theoretical complexity for demonstrated accuracy. At the same time, when they needed to assess grammaticality, they searched corpora or polled native speakers instead of consulting generative rule system. Today, practitioners of linguistics already operate in Manczaks world, even if linguistic theorists havent caught up."
        },
        {
            "title": "Validation through synthesis",
            "content": "The analysis of simple sentence. Manczak examined how linguists with competing methodologies analyze simple English sentence: Sincerity may frighten the boy. He observed that creating such sentence using generative grammar required long, convoluted process. In contrast, to synthesize the sentence, one needs only few simple rules: 1) Every noun can be accompanied by third-person verb that agrees with it in number. 2) Certain verbs, including may, can be accompanied by infinitives without the particle to. Since these verbs are rare, grammars enumerate them. 3) Transitive verbs (including frighten) are accompanied by noun. Since these verbs are common, grammars refer to dictionaries for detailed information. 4) Every noun can be accompanied by an article under certain conditions. Grammars enumerate these conditions. 5) The article precedes the noun, the infinitive follows the verb it accompanies, etc. (Manczak, 1996b). These straightforward rules highlight the gap between the theoretical complexity of Chomskys analysis and the practical utility of Manczaks alternative approach. Example 2: The theory requiring immense abstract machinery to analyze simple sentence that can be generated with few practical rules has failed the fundamental test of synthesis. Stunningly effective LLMs have arrived as the answer to the unfulfilled promise of generative grammar. Their capacity to synthesize coherent language based on probabilistic analysis of text rather than abstract rules or postulated deep structures is the ultimate vindication of Manczaks approach. Empirically, LLM performance increases smoothly with the amount of pretraining data (Kaplan et al., 2020; Hoffmann et al., 2022). Pretraining minimizes expected next-token surprisal (cross-entropy), pushing the models conditional predictions to match empirical next-token frequencies. Estimation of the languages frequency structure improves and sharpens with larger training set, especially in the long tail. Interestingly, models naturally retain the useful token frequency information in embeddings (Zhou et al., 2021; Gong et al., 2018). LLMs success is not mystery or stochastic parrot trick. It is large-scale validation of Manczaks central thesis: language is text, and frequency is not secondary, peripheral aspect, but its primary organizing force."
        },
        {
            "title": "2.3 An Obituary for the Language Organ",
            "content": "According to the Chomskyan paradigm, language acquisition requires specialized language organ because children lack sufficient linguistic input to develop language from pattern recognition alone. Manczak rejected this view, arguing that debates about hypothetical brain structures fell outside the proper naturalistic focus of linguistics (Grochowski, 2017; Manczak, 1969a). We see now that his skepticism was justified. The Chomskyan paradigm has been challenged by evidence from cross-linguistic research and developmental psychology, causing many experts to abandon it (Ibbotson and Tomasello, 2016; Pullum and Scholz, 2002; Christiansen and Chater, 2008; Snow, 1972; Tomasello, 2003; Bybee, 2006, inter alia). Instead, usage-based alternative has emerged. Its proponents argue that children learn grammar from the ground up by applying general cognitive tools like pattern recognition and categorization to the sounds they hear. This evidencebased theory sees grammar as an emergent property of history and psychologya set of templates discovered by observing that some sentences or word forms are built analogically. It aligns perfectly with 1For complementary view, see Piantadosi (2024), who argues that LLMs refute Chomskys theory. Table 2: Architectural evolution and its impact on analogical capability. Model Core Mechanism Representation of Words Analogical Capability N-gram Surface-level counting of token co-occurrence; (word previous 1 words). CBOW Learning vector representation of meaning by predicting word from its context. LLMs Learning relationships between learned vector representations of meaning. Atomic, discrete symbols. No notion of similarity between words. Sentences Anna likes cats and Lily loves dogs are not similar. None. Can reproduce frequent sequences but cannot grasp words or sentences similarity. Dense, low-dimensional vectors. Words occurring in similar contexts are mapped to nearby points in geometric space. External to model. Series of analogous word pairs can be demonstrated to share similar geometric relationship. Dense, high-dimensional vectors that are dynamically adjusted based on the specific context of the entire sequence. Inherent, core mechanism. The model operates on series of embeddings and generalizes patterns. Manczaks insistence on an empirical, text-first science of language.2 To criticize the ability of LLMs to generate plausible human speech as mere application of learned patterns is to miss the point that use of analogy is an essential aspect of linguistic competence. LLMs can generate plausible real-time answers in part because they recognizeduring previous training the same frequency patterns that created human grammar in the first place."
        },
        {
            "title": "The",
            "content": "success of modern LLMs stems from crucial architectural innovation: the replacement of flat, surface-level n-gram counts with highdimensional embeddings  (Table 2)  . Earlier n-gram models, limited by their reliance on simple tables of memorized word combinations, failed to recognize that the sentences Anna likes cats and Lily loves dogs are analogous. While CBOW models could demonstrate that analogous word pairs share similar geometric relationship, the breakthrough improvement was to operate on sequences of learned vector representations. When presented with novel problem to solve, Transformer uses its vast internalized map of relationships to find and apply the closest learned analogy. This ability to represent and manipulate relationshipsthe very essence of analogyis the key to genuine linguistic generalization."
        },
        {
            "title": "Ungrounded",
            "content": "Perhaps the most persistent criticism of LLMs is that they are ungrounded: they manipulate sym2See Goldberg (2024) for usage-based constructionist account explicitly linking constructions to LLMs. Axiomatic Meaning bols (form) without access to their real-world referents (meaning).3 While Manczak did not directly engage with modern semantic theories, his view aligns with core assumption of componential and reductionist semantics: the necessity of undefinable primitives (Grochowski, 2017). Manczak argued that attempting to describe language without external reference (ignoring meaning entirely) was descent into nebulous darkness. He proposed simple resolution (Manczak, 1996h): Just as in mathematics, most but not all statements can be proved (with the help of other statements) . . . most words in given language can be defined with the help of other words, with the unavoidable exception that [to avoid circularity] the meaning of certain words must be taken as self-evident (axiomatic). Nevertheless, he recognized that the meaning of most words is relational, derived from an intricate web of connections between terms.4 An LLM correctly using concept like justice requires only mastery of the vast, multidimensional web of relationships that connect that word to fairness, law, equality, crime, and thousands of other terms. Whether this represents human-like understanding is irrelevant. We do not demand that calculator understands what 1+2 truly means to accept its utility. We do 3See Bender and Koller (2020) for representative formulation of the form-vs-meaning objection. 4Concepts without referentssuch as perpetual motion machine or king of San Franciscofurther illustrate how meaning can exist purely through relational networks (Piantadosi and Hill, 2022). Key Leap: Relations Between Embeddings not dismiss the results of theorem-proving software because it cannot understand the philosophical basis of Zermelo-Fraenkel set theory. While simple counting may be grounded in early childhood experiences, advanced mathematical reasoning involves manipulation of highly formal system according to set of rules. For most people, including professional mathematicians, the meaning of an axiom lies in its role within that formal system, rather than an intuitive or sensory experience. Demanding that language model meet higher standard of grounded meaning is misguided. In the Manczakian view, the relevant test for LLM quality is not whether the model has access to an outside world, but whether it has mastered the internal, relational logic of the textual world it was given."
        },
        {
            "title": "3 Conclusion",
            "content": "LLM users often feel amazed, disappointed, or mixture of both. Theyre amazed that LLMs can produce human-like text about any topic. Theyre disappointed when models confidently present factually incorrect information. Beyond these reactions, prominent linguists argue that LLMs are intrinsically flawed because of gaps in linguistic competence and inability to understand language. They call for models to demonstrate knowledge of deep structure or reliance on grounded meaningconcepts their theories treat as requirements of language. We argue that by applying these theory-laden standards, such critics interfere with useful analysis. The stochastic parrots do not merely mimic language but in fact reveal what language has been all along. LLMs are imperfect tools not because they fail to model language but because they only model language. The implications of our proposed shift in perspective extend beyond theoretical linguistics. The path to improving linguistic competence of LLMs is to design, evaluate, and deploy systems that have already proven mastery of languages relational logic. Satisfying abstract theoretical requirements for language competencedemanded by the vocal critics of LLMswill neither improve linguistic 5This textual world might suffice. Mandelkern and Linzen (2024) argue that LLMs can use words to talk about real things because training texts already link those words to the physical world. In their view, the key issue is whether the model counts as part of our speech community. competence nor bring us closer to Artificial General Intelligence. Manczak saw it clearly: language is the totality of texts, and frequency is its organizing principle. Decades later, engineers unknowingly built LLMs on this very foundation. Their models now draft our contracts, structure our arguments, and increasingly impact our futuresmaking Manczaks case more powerfully than any argument could."
        },
        {
            "title": "4 Limitations",
            "content": "We acknowledge that proposing novel theoretical lens for understanding language and LLMs leaves some critical questions unaddressed. Your paper ignores urgent ethical dilemmas. Carefully defining technology is prerequisite for ethical debate. We address the former to set the stage for the latter. text-only definition of language excludes some linguistic subfields, such as pragmatics, psycholinguistics, etc. To qualify as linguistic, claim must generate falsifiable predictions about distributions over texts or about observable properties of utterances, all of which must be testable by corpus statistics or experiments. Pragmatics satisfies these conditions when it predicts context-conditioned choices among forms (e.g., Witold Ma nczak (19242016) Witold Manczak was Polish linguist specializing in Indo-European, Romance, and Slavic studies. Over his career, he published 24 books and more than 960 other texts, developing distinct theoretical framework for language analysis (Debowiak, 2014, 2016; Grochowski, 2017). defining feature of Manczaks work was his application of statistical methods to verify linguistic hypotheses. He argued that linguistic analysis should be based on quantifiable data, and proposed that language development is driven by three factors: regular phonetic development, analogical development, and irregular phonetic development caused by frequency of use. With his data-centric approach, Manczak challenged several foundational linguistic theories (see Appendix A). His lifes work stands as testament to tireless pursuit of verifiable statements, establishing him as the creator of coherent, statistics-based theory of language and one of the most significant linguists of his era. LLMs Merely Model Language after this primary, non-metaphorical evaluation is established. The Manczakian framework provides necessary baseline. Many of Ma nczaks core ideas are central to the well-established usage-based linguistics. While Manczaks ideas do align with modern usagebased linguistics, he reached similar conclusions decades earlier through the empirical analysis of contemporary and historical texts. First, Manczaks radical, text-only simplicity provides direct rebuttal to critiques of LLMs grounded in Saussurean or generative theories: his framework simply discards abstractions that cannot be found in the textual record. Second, his focus on the structure of the input text itselfrather than human cognitive processingaligns directly with how text-trained models actually function. The fact that Manczaks textual analysis independently yielded insights that are now central to cognitivism makes his framework particularly compelling. If linguistic competence requires merely applying frequency-weighted patterns, how do you explain creativity? High-frequency patterns dont mechanically reproduce themselves; they serve as templates for novel combinations. LLMs demonstrate this empirically. Creativity isnt the opposite of pattern utilizationits pattern mastery."
        },
        {
            "title": "Acknowledgments",
            "content": "I am grateful to Geoffrey Laff for his insightful comments and suggestions, which significantly improved the style and clarity of this paper. also thank Daniel Dzienisiewicz, Filip Gralinski, Michał Pietruszka, Michał Turski, and Jordy Van Landeghem for reading draft and offering valuable remarks. hedging, politeness markers). Sociolinguistics does so when it predicts socially conditioned alternations in variants and styles across communities. Ethnolinguistics is linguistic when it predicts culturally conditioned textual patterns in community corpus (e.g., motifs, metaphor families, collocational frames). Claims that fail to meet these conditions may still be valuablein sociology, psychology, or cultural studiesbut they do not count as linguistic in the Manczakian sense. Your focus on relational meaning seems to embrace purely structuralist view of semantics. We do not claim to offer complete theory of meaning. Our central thesis is that the vast majority of the time meaning can be inferred (and in the case of LLMs is inferred) solely from the relational structure of the text. The success of LLMs demonstrates how much linguistic competence can be achieved by assigning central role to distributional semantics, and limited roleif anyto direct grounding. LLMs are trained on unrepresentative corpora, very distant from the totality of all that is said and written. This is true and aligns with our view that LLMs are not fundamentally flawed, but incomplete in practice. The Manczakian framework offers clear path forward, favoring rational selection of texts based on circulation and influence (Manczak, 1996f, 1961). truly Manczakian approach is principled, frequency-weighted corpus construction that reflects how language is actually used. LLMs lack world model. The Manczakian framework we adopt posits that language is not map of the physical world but self-contained universe of texts. From this perspective, the demand for grounding in physical reality is misplaced. Our model should be seen not as flawed attempt to simulate mind interacting with physical world but as successful and direct model of language itself. You are closing off valuable inquiry into the cognitive plausibility of LLMs. Our goal is not to declare cognitive comparisons invalid but to argue that they should not be the primary benchmark. An LLM is, first and foremost, direct model of textual corpus. This is not metaphor; it is description of its construction and function. We argue that any comparison to human cognition must come"
        },
        {
            "title": "A Selected Contributions to Historical",
            "content": "and Comparative Linguistics This summary was initially published by Manczak in French and served as foreword to Linguistique générale et linguistique indo-européenne. It outlines his career-long pursuit against fundamental methodological flaws of modern linguistics. Some of these findings oppose prevailing viewsand that is precisely why his methodological proposal cannot be ignored. strongly encourage the reader to seek out the original publications. English Translation The fundamental problem of linguistics is that of the criteria of truth. Unfortunately, this problem is taboo. Given that linguistics has existed for two thousand years and that the Linguistic Bibliography recorded 21,000 works for the year 2001, it follows that linguists have published, in total, several hundreds of thousands of works, and yet none of these has been devoted to the criteria of truth. Even the term criteria of truth is never used by linguists. This is an extraordinary thing, considering that linguists unanimously agree that linguistics is science, and that science is search for truth. Why do linguists keep the question of distinguishing true from false in their discipline secret? This enigma has intrigued me for long time. As linguistic works provide no information capable of resolving this question, began to observe how linguists react when they learn an opinion previously unknown. To my great astonishment, found that linguists never intend to verify the opinion in question, but are interested only in the question of who shares this opinion. If they learn that this opinion is shared by one or more authorities, they If, on the contrary, they learn consider it true. that this opinion comes from someone who does not have the reputation of being an authority, this view appears false to them. The criterion of truth used by linguists is the following: has formulated an opinion, is an authority, therefore this opinion is true; has formulated an opinion, is not an authority, consequently this opinion is false. Obviously, this criterion of truth is medieval and unscientific, which is why linguists prefer not to talk about it. In this state of affairs, reflected on the criteria of truth likely to be employed in linguistics. came to the conclusion that linguists can resort to statistics (and, exceptionally, to experiment) and that, in the science of language, many opinions rely on faith in the infallibility of authorities and are invalidated by statistical data. Here are some examples: 1. In all languages, the form of words depends on three main factors, not only on regular phonetic development and analogical development, but also on what call irregular phonetic development due to frequency (Le développement phonétique des langues romanes et la fréquence, Kraków, 1969; Słowianska fonetyka historyczna frekwencja, Kraków, 1977; Frequenzbedingter unregelmäßiger Lautwandel in den germanischen Sprachen, Wrocław, 1987). According to professor of applied mathematics, the chance that the theory of irregular phonetic development due to frequency is erroneous is less than 1 in 10 million (Etymologia przyimka dla nieregularny rozwój fonetyczny spowodowany frekwencj a, Prace Filologiczne 60, 2011, p. 189195). 2. Bartolis norm according to which lateral areas are more archaic than central areas is invalidated by statistical data (La Roumanie et lEspagne sont-elles des territoires archaïques de la Romania?, Limba românˇa, limbˇa romanicˇa. Omagiu acad. M. Sala la împlinirea 75 de ani, Bucuresti, p. 313317). 3. Since 1925, when Meillet introduced the notion of empty slot (case vide), it has been imagined that phonetic evolution consists of filling empty slots in phonological systems. But have examined large number of facts and have come to the conclusion that it is not symmetry, but asymmetry that characterizes languages, that it is possible to formulate law according to which more frequently used linguistic elements are more differentiated than less used elements (Do the cases vides exist?, Linguistique générale et linguistique indo-européenne, Kraków, 2008, p. 5962). theory is invalidated by statisti4. Laryngeal cal data (Critique de la théorie des laryngales, Analecta Indoeuropaea Cracoviensia I. Safarewicz memoriae dicata, Cracoviae, 1995, p. 237247; Encore un argument contre la théorie des laryngales, Lingua Posnaniensis 46, 2004, p. 4144). 5. In my opinion, Verners law requires revision (La restriction de la règle de Verner à la position médiane et le sort du final en germanique, Historische Sprachforschung 103, 1990, p. 92101; La règle de Verner sapplique-t-elle à la position finale?, Historische Sprachforschung 109, 1996, p. 110116). de Philologie Romanes, t. VI, Berlin, 2010, p. 207 211). 6. In light of statistical data, Old Church Slavonic is compromise between the Macedono-Bulgarian dialect and the Moravo-Pannonian speech (Przedhistoryczne migracje Słowian pochodzenie jezyka staro-cerkiewno-słowianskiego, Kraków, 2004; Pochodzenie jezyka staro-cerkiewno-słowianskiego Kodeks zografski, Warszawa, 2006). 7. In light of statistical data, the original homeland of the Indo-Europeans is identical with that of the Slavs (De la préhistoire des peuples indoeuropéens, Kraków, 1992; Lhabitat primitif des Indo-Européens se trouvait-il vraiment en Arménie?, Folia Orientalia 33, 1997, p. 6574). 8. The German orientalist Ludolf (17th c.) was the first to affirm that die Sprachverwandtschaft offenbart sich nicht im Wörterbuch, sondern in der Grammatik [language relationship reveals itself not in the dictionary, but in grammar]. But one can justify the division of Indo-European languages into Germanic, Slavic, Baltic, Romance, etc. only through lexical convergences, and not inflectional or phonetic ones (La classification des langues romanes, Kraków, 1991, p. 2236). 9. The number one problem of Romance etymology is that of verbs meaning to go: Fr. aller, It. andare, Sp. andar, Prov. ana, etc. Since the 16th century, about sixty etymologies have been proposed in total, which is record, and not only for Romance etymology. Among researchers, there are adherents to monogenesis (affirming that all these forms come from, for example, ambulare) and advocates of polygenesis (claiming, for example, that aller < *advehulare, andar < *am(bi)vehitare, ana < *amvehinare). Probability calculus allows this question to be decided in favor of monogenesis (Une étymologie romane controversée: aller, andar, etc., Revue roumaine de linguistique 19, 1974, p. 89101; Étymologie de fr. aller, esp. andar, etc. et calcul des probabilités, Revue roumaine de linguistique 20, 1975, p. 735739). 10. Since 1435, it has been affirmed that Romance languages derive from Vulgar Latin, but, in light of statistical data, they derive from Classical Latin (Le problème de lorigine des langues romanes dans le livre de H. Lüdtke et celui de R. Kiesler, Actes du XXVe Congrès International de Linguistique et 11. Since Jordanes, that is, for 1400 years, it has been estimated that the original homeland of the Goths was in Scandinavia. But comparison of parallel texts in Gothic, High German, Middle German, Low German, Danish and Swedish revealed that the original homeland of the Goths was in the southernmost part of ancient Germania (Le mythe de lorigine scandinave des Goths, Lart de la philologie. Mélanges en lhonneur de L. Löfstedt, Helsinki, 2007, p. 137145). 12. The division of words into stressed and unstressed (articles, pronouns, prepositions, etc.), which dates back to Antiquity, is the result of false generalization. It is true that there are homonymies le vent = levant, à voir = avoir, and moi = émoi and that the syllables le-, a-, éin levant, avoir, émoi are unstressed, but it is erroneous to conclude from this that le, à, and are unstressed because stressed words are treated in the same way. Dix vers, vingt cœurs, va tôt, pronounced without pauses, are homonymous with divers, vainqueur, Watteau, where the syllables di-, vain-, Waare unstressed. It is affirmed that Long vient = stressed word + stressed word, while lon vient = proclitic + stressed word, but very simple experiment proves that these expressions are homonymous (La division des mots en toniques et atones est-elle justifiée?, Lingua Posnaniensis 3233, 1991, p. 181 185). 13. Since Antiquity, the question of what constitutes the difference between proper nouns and common nouns has been discussed. About ten definitions of the proper noun have been proposed so far, none of which applies to all proper nouns. In my opinion, the difference between proper nouns and common nouns consists in the fact that common nouns are, in the vast majority of cases, translated from one language to another, while proper nouns almost never are. For example, common noun like ville is translated into Italian as città, into English as town, etc., whereas proper noun like Paris is not, cf. It. Parigi, Eng. Paris, etc. Among all definitions of the proper noun, mine suffers the fewest exceptions (La notion de nom propre, Proceedings of 13th International Congress of Onomastic Sciences, Kraków, 1982, p. 101106). French Original Le problème fondamental de la linguistique est celui des critères de vérité. Malheureusement, cette question constitue un tabou. Étant donné que la linguistique existe depuis deux mille ans et que la Bibliographie linguistique enregistré, pour lannée 2001, 21 000 travaux, il en résulte que les linguistes en ont publié, au total, plusieurs centaines de milliers, et pourtant aucun de ces derniers na été consacré aux critères de vérité. Même le terme critères de vérité nest jamais employé par les linguistes. Cest une chose extrêmement étrange, si lon considère que les linguistes sont unanimes pour dire que la linguistique est une science, et que la science nest pas autre chose quune recherche de la vérité. Pourquoi donc les linguistes gardentils un secret sur la question de savoir comment ils distinguent le vrai du faux dans leur discipline? Cette énigme ma intrigué depuis longtemps. Comme les travaux linguistiques ne fournissent aucun renseignement susceptible de résoudre cette question, jai commencé à observer comment les linguistes réagissent quand ils apprennent une opinion qui leur était inconnue auparavent. mon grand étonnement, jai constaté que les linguistes nont jamais lintention de vérifier lopinion en question, mais sintéressent uniquement à la question de savoir qui partage cette opinion. Sils apprennent que cette opinion est partagée par une ou plusieurs autorités, ils considèrent cette opinion comme vraie. Si, au contraire, ils apprennent que cette opinion provient de quelquun qui na pas la réputation dêtre une autorité, cette vue leur paraît fausse. Il en résulte que le critère de vérité utilisé par les linguistes est le suivant: formulé une opinion, est une autorité, par conséquent cette opinion est vraie; formulé une opinion, nest pas une autorité, par conséquent cette opinion est fausse. Évidemment, ce critère de vérité est médiéval, non scientifique, et cest la raison pour laquelle les linguistes préfèrent ne pas en parler. Dans cet état de choses, il mest venu à lesprit de réfléchir sur les critères de vérité susceptibles dêtre employés en linguistique et je suis arrivé à la conclusion que les linguistes peuvent recourir à la statistique (et, exceptionnellement, à lexpérience) et que, dans la science du langage, il beaucoup dopinions qui sappuient sur la foi en linfaillibilité des autorités et qui sont infirmées par des données statistiques. Voici quelques exemples. 1. Dans toutes les langues, la forme des mots dépend de trois facteurs principaux, non seulement du développement phonétique régulier et du développement analogique, mais aussi de ce que jappelle un développement phonétique irrégulier dû à la fréquence (Le développement phonétique des langues romanes et la fréquence, Kraków, 1969; Słowianska fonetyka historyczna frekwencja, Kraków, 1977; Frequenzbedingter unregelmäßiger Lautwandel in den germanischen Sprachen, Wrocław, 1987). De lavis dun professeur de mathématiques appliquées, la chance que la théorie du développement phonétique irrégulier dû à la fréquence soit erronée, est moindre que 1 sur 10 millions (Etymologia przyimka dla nieregularny rozwój fonetyczny spowodowany frekwencj a, Prace Filologiczne 60, 2011, p. 189195). 2. La norme de Bartoli daprès laquelle les aires latérales sont plus archaïques que les aires centrales, est infirmée par des données statistiques (La Roumanie et lEspagne sont-elles des territoires archaïques de la Romania?, Limba românˇa, limbˇa romanicˇa. Omagiu acad. M. Sala la împlinirea 75 de ani, Bucuresti, p. 313317). 3. Depuis 1925, où Meillet introduit la notion de case vide , on imagine que lévolution phonétique consiste à remplir des cases vides dans les systèmes phonologiques. Mais jai examiné un grand nombre de faits et suis arrivé à la conclusion que ce nest pas la symétrie, mais lasymétrie qui caractérise les langues, quil est possible de formuler une loi daprès laquelle les éléments linguistiques plus employés sont plus différenciés que les éléments moins utilisés (Do the cases vides exist?, Linguistique générale et linguistique indoeuropéenne, Kraków, 2008, p. 5962). 4. La théorie des laryngales est infirmée par des données statistiques (Critique de la théorie des laryngales, Analecta Indoeuropaea Cracoviensia I. Safarewicz memoriae dicata, Cracoviae, 1995, p. 237247; Encore un argument contre la théorie des laryngales, Lingua Posnaniensis 46, 2004, p. 4144). 5. mon avis, la règle de Verner exige une révision (La restriction de la règle de Verner à la position médiane et le sort du final en germanique, Historische Sprachforschung 103, 1990, p. 92101; La règle de Verner sapplique-t-elle à la position finale?, Historische Sprachforschung 109, 1996, p. 110116). 6. la lumière de données statistiques, le vieux slave est un compromis entre le dialecte macédobulgare et le parler moravo-pannonien (Przedhistoryczne migracje Słowian pochodzenie jezyka staro-cerkiewno-słowianskiego, Kraków, 2004; Pochodzenie jezyka staro-cerkiewno-słowianskiego Kodeks zografski, Warszawa, 2006). 7. la lumière de données statistiques, lhabitat primitif des Indo-Européens est identique avec celui des Slaves (De la préhistoire des peuples indo-européens, Kraków, 1992; Lhabitat primitif des Indo-Européens se trouvait-il vraiment en Arménie?; Folia Orientalia 33, 1997, p. 6574). 8. Lorientaliste allemand Ludolf (17e s.) été le premier à affirmer que die Sprachverwandtschaft offenbart sich nicht im Wörterbuch, sondern in der Grammatik . Mais on peut justifier la division des langues indo-européennes en germaniques, slaves, baltes, romanes, etc. uniquement par des convergences lexicales, et non flexionnelles ou phonétiques (La classification des langues romanes, Kraków, 1991, p. 2236). 9. Le problème numéro un de létymologie romane est celui des verbes ayant pour sens aller : fr. aller, it. andare, esp. andar, prov. ana, etc. Depuis le 16e siècle, on a, au total, proposé une soixantaine détymologies, ce qui est un record, et cela non seulement pour létymologie romane. Parmi les chercheurs, il des adhérents à la monogenèse (affirmant que toutes ces formes proviennent, par exemple, de ambulare) et des adeptes de la polygenèse (prétendant, par exemple, que aller < *advehulare, andar < *am(bi)vehitare, ana < *amvehinare). Le calcul des probabilités permet de trancher cette question en faveur de la monogenèse (Une étymologie romane controversée: aller, andar, etc., Revue roumaine de linguistique 19, 1974, p. 89101 ; Étymologie de fr. aller, esp. andar, etc. et calcul des probabilités, Revue roumaine de linguistique 20, 1975, p. 735739). 10. Depuis 1435, on affirme que les langues romanes proviennent du latin vulgaire, mais, à la lumière de données statistiques, elles sont issues du latin classique (Le problème de lorigine des langues romanes dans le livre de H. Lüdtke et celui de R. Kiesler, Actes du XXVe Congrès International de Linguistique et de Philologie Romanes, t. VI, Berlin, 2010, p. 207211). 11. Depuis Jordanès, cest-à-dire depuis 1400 ans, on estime que lhabitat primitif des Goths se trouvait en Scandinavie. Mais la comparaison de textes parallèles en gotique, allemand supérieur, moyen allemand, bas allemand, danois et suédois révélé que lhabitat primitif des Goths se trouvait dans la partie la plus méridionale de la Germanie ancienne (Le mythe de lorigine scandinave des Goths, Lart de la philologie. Mélanges en lhonneur de L. Löfstedt, Helsinki, 2007, p. 137145). 12. La division des mots en toniques et atones (articles, pronoms, prépositions, etc.), qui remonte à lAntiquité, est le résultat dune fausse généralisation. Il est vrai quil des homonymies le vent = levant, à voir = avoir, et moi = émoi et que les syllabes le-, a-, édans levant, avoir, émoi sont atones, mais il est erroné den conclure que le, à, et sont atones parce que les mots toniques sont traités de la même manière. Dix vers, vingt cœurs, va tôt, prononcés sans pauses, sont homonymes de divers, vainqueur, Watteau, où les syllabes di- , vain-, Wasont atones. On affirme que Long vient = mot tonique + mot tonique, alors que lon vient = proclitique + mot tonique, mais une expérience bien simple prouve que ces expressions sont homonymes (La division des mots en toniques et atones est-elle justifiée?, Lingua Posnaniensis 3233, 1991, p. 181185). 13. Depuis lAntiquité, on discute la question de savoir en quoi consiste la différence entre noms propres et noms communs. On jusquici proposé une dizaine de définitions du nom propre, dont aucune ne sapplique à tous les noms propres. mon avis, la différence entre noms propres et noms communs consiste en ce que les noms communs sont, dans la grande majorité des cas, traduits dune langue à lautre, tandis que les noms propres ne le sont presque jamais. Par exemple, un nom commun comme ville est traduit en italien par città, en anglais par town, etc., alors quun nom propre comme Paris ne lest pas, cf. it. Parigi, angl. Paris, etc. Parmi toutes les définitions du nom propre, la mienne souffre le moins dexceptions (La notion de nom propre, Proceedings of 13th International Congress of Onomastic Sciences, Kraków, 1982, p. 101106)."
        },
        {
            "title": "References",
            "content": "Emily M. Bender, Timnit Gebru, Angelina McMillanMajor, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT 21, page 610623, New York, NY, USA. Association for Computing Machinery. Emily M. Bender and Alexander Koller. 2020. Climbing towards NLU: On meaning, form, and understanding in the age of data. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 51855198, Online. Association for Computational Linguistics. Joan L. Bybee. 2006. From usage to grammar: The minds response to repetition. Language, 82(4):711 733. Noam Chomsky, Ian Roberts, and Jeffrey Watumull. 2023. The false promise of ChatGPT. The New York Times. M. H. Christiansen and N. Chater. 2008. Language as shaped by the brain. Behavioral and Brain Sciences, 31(5):489558. Przemysław Debowiak. 2014. dorobku naukowym profesora witolda manczaka okazji jubileuszu 90. urodzin. Jezyk Polski, XCIV(3):194199. Przemysław Debowiak. 2016. Witold Manczak (12 VIII 192412 2016). Onomastica, (No 60):510. Nick C. Ellis. 2002. Frequency effects in language processing: review with implications for theories of implicit and explicit language acquisition. Studies in Second Language Acquisition, 24(2):143188. Ana Fló, Lucas Benjamin, Marie Palu, and Ghislaine Dehaene-Lambertz. 2025. Statistical learning beyond words in human neonates. eLife, 13:RP101802. Danny Fox and Roni Katzir. 2024. Large language models and theoretical linguistics. Theoretical Linguistics, 50(1-2):7176. Adele E. Goldberg. 2024. Usage-based constructionist approaches and large language models. Constructions and Frames, 16(2):220254. ChengYue Gong, Di He, Xu Tan, Tao Qin, Liwei Wang, and Tie-Yan Liu. 2018. FRAGE: Frequency-agnostic word representation. CoRR, abs/1809.06858. Maciej Grochowski. 2017. pogl adach profesora Witolda Manczaka na paradygmaty jezykoznawstwa. LingVaria, 12(spec):1928. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, and 3 others. 2022. Training compute-optimal large language models. Preprint, arXiv:2203.15556. Paul Ibbotson and Michael Tomasello. 2016. Evidence rebuts Chomskys theory of language learning. Scientific American. E.T. Jaynes. 2003. Probability theory: The logic of science. Cambridge University Press. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. Preprint, arXiv:2001.08361. Matthew Mandelkern and Tal Linzen. 2024. Do language models words refer? Computational Linguistics, 50(3):11911200. Witold Manczak. 1958. Tendances générales des changements analogiques. Lingua, 7:298325, 387 420. Witold Manczak. 1961. racjonalny dobór haseł słownikach. Poradnik Jezykowy, pages 471476. Witold Manczak. 1969a. Critique du structuralisme. Folia Linguistica, 3(3-4):169177. Witold Manczak. 1969b. Le développement phonétique des langues romanes et la fréquence. Zeszyty naukowe Uniwersytetu Jagiellonskiego 205, Kraków. Nakładem Uniwersytetu Jagiellónskiego. Witold Manczak. 1969c. Nieregularny rozwój fonetyczny spowodowany czestosci uzycia prasłowianskim. Slavia, 38:5262. Witold Manczak. 1978. Les lois du développement analogique. Linguistics, 205:5360. Witold Manczak. 1980. Critères de vérité dans la linguistique. General Linguistics, 20:140145. Witold Manczak. 1981. Kryteria prawdy jezykoznawstwie. Biuletyn Polskiego Towarzystwa Jezykoznawczego, 38:135142. Witold Manczak. 1982. Linguistique et autres sciences. Biuletyn Polskiego Towarzystwa Jezykoznawczego, 39:147152. Witold Manczak. 1987. regelmäßiger Lautwandel Sprachen. Ossolineum, Wrocław. Frequenzbedingter unin den germanischen Witold Manczak. 1988a. Critères de vérité. leurs conséquences pour la linguistique. Langages, 89:5164. Witold Manczak. 1988b. nieregularnym rozwoju fonetycznym spowodowanym frekwencj a. Biuletyn Polskiego Towarzystwa Jezykoznawczego, 41:105 111. Witold Manczak. 1996a. Gramatyka opisowa. In Problemy jezykoznawstwa ogólnego, pages 139146. Wrocław. Kaitlyn Zhou, Kawin Ethayarajh, and Dan Jurafsky. 2021. Frequency-based distortions in contextualized word embeddings. Preprint, arXiv:2104.08465. Witold Manczak. 1996b. Gramatyka transformacyjnogeneratywna. In Problemy jezykoznawstwa ogólnego, pages 183190. Wrocław. Witold Manczak. 1996c. Najwiekszy problem jezykoznawstwa: kryteria prawdy. In Problemy jezykoznawstwa ogólnego, pages 1319. Wrocław. Witold Manczak. 1996d. Nieregularny rozwój fonetyczny spowodowany frekwencj a. In Problemy jezykoznawstwa ogólnego, pages 5276. Wrocław. Witold Manczak. 1996e. Prawa rozwoju analogicznego. In Problemy jezykoznawstwa ogólnego, pages 8197. Wrocław. Witold Manczak. 1996f. Racjonalny dobór haseł słownikach. In Problemy jezykoznawstwa ogólnego, pages 147149. Zakład Narodowy im. Ossolinskich - Wydawnictwo, Wrocław. Witold Manczak. 1996g. Rozwój semantyczny frekIn Problemy jezykoznawstwa ogólnego, wencja. pages 121127. Wrocław. Witold Manczak. 1996h. Słownik gramatyka. In Problemy jezykoznawstwa ogólnego, pages 128132. Zakład Narodowy im. Ossolinskich - Wydawnictwo, Wrocław. Steven T. Piantadosi. 2024. Modern language models refute chomskys approach to language. In Edward Gibson and Moshe Poliak, editors, From fieldwork to linguistic theory: tribute to Dan Everett (Empirically Oriented Theoretical Morphology and Syntax 15), pages 353414. Berlin: Language Science Press. Steven T. Piantadosi and Felix Hill. 2022. Meaning without reference in large language models. Preprint, arXiv:2208.02957. G. K. Pullum and B. C. Scholz. 2002. Empirical assessment of stimulus poverty arguments. The Linguistic Review, 19(1-2):950. Alexa Romberg and Jenny Saffran. 2010. Statistical learning and language acquisition. Wiley Interdisciplinary Reviews: Cognitive Science, 1(6):906914. Jenny R. Saffran, Elissa L. Newport, and Richard N. Aslin. 1996. Word segmentation: The role of distributional cues. Journal of Memory and Language, 35(4):606621. Catherine E. Snow. 1972. Mothers speech to children learning language. Child Development, 43(2):549 565. Michael Tomasello. 2003. Constructing language: usage-based theory of language Acquisition. Harvard University Press."
        }
    ],
    "affiliations": [
        "Snowflake AI Research"
    ]
}