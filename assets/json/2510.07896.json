{
    "paper_title": "ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall",
    "authors": [
        "Jiayu Yang",
        "Yuxuan Fan",
        "Songning Lai",
        "Shengen Wu",
        "Jiaqi Tang",
        "Chun Kang",
        "Zhijiang Guo",
        "Yutao Yue"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) require efficient knowledge editing (KE) to update factual information, yet existing methods exhibit significant performance decay in multi-hop factual recall. This failure is particularly acute when edits involve intermediate implicit subjects within reasoning chains. Through causal analysis, we reveal that this limitation stems from an oversight of how chained knowledge is dynamically represented and utilized at the neuron level. We discover that during multi hop reasoning, implicit subjects function as query neurons, which sequentially activate corresponding value neurons across transformer layers to accumulate information toward the final answer, a dynamic prior KE work has overlooked. Guided by this insight, we propose ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall, a framework that leverages neuron-level attribution to identify and edit these critical query-value (Q-V) pathways. ACE provides a mechanistically grounded solution for multi-hop KE, empirically outperforming state-of-the-art methods by 9.44% on GPT-J and 37.46% on Qwen3-8B. Our analysis further reveals more fine-grained activation patterns in Qwen3 and demonstrates that the semantic interpretability of value neurons is orchestrated by query-driven accumulation. These findings establish a new pathway for advancing KE capabilities based on the principled understanding of internal reasoning mechanisms."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 ] . [ 1 6 9 8 7 0 . 0 1 5 2 : r Preprint. ACE: ATTRIBUTION-CONTROLLED KNOWLEDGE EDITING FOR MULTI-HOP FACTUAL RECALL Jiayu YANG HKUST(GZ) Deep Interdisciplinary Intelligence Lab jyang729@connect.hkust-gz.edu.cn Yuxuan FAN HKUST(GZ) yfan546@connect.hkust-gz.edu.cn Songning LAI HKUST(GZ) Deep Interdisciplinary Intelligence Lab songninglai@hkust-gz.edu.cn Shengen WU HKUST(GZ) Deep Interdisciplinary Intelligence Lab wu.shengen@outlook.com Jiaqi TANG HKUST jtang092@connect.hkust-gz.edu.cn Chun KANG BUAA kicoforstudy@gmail.com Zhijiang GUO HKUST(GZ) HKUST zg283@cam.ac.uk Yutao YUE HKUST(GZ) Institute of Deep Perception Technology, JITRI Deep Interdisciplinary Intelligence Lab yutaoyue@hkust-gz.edu.cn"
        },
        {
            "title": "ABSTRACT",
            "content": "Large Language Models (LLMs) require efficient knowledge editing (KE) to update factual information, yet existing methods exhibit significant performance decay in multi-hop factual recall. This failure is particularly acute when edits involve intermediate implicit subjects within reasoning chains. Through causal analysis, we reveal that this limitation stems from an oversight of how chained knowledge is dynamically represented and utilized at the neuron level. We discover that during multi-hop reasoning, implicit subjects function as query neurons, which sequentially activate corresponding value neurons across transformer layers to accumulate information toward the final answera dynamic prior KE work has overlooked. Guided by this insight, we propose ACE (Attribution-Controlled Knowledge Editing), framework that leverages neuron-level attribution to identify and edit these critical query-value (Q-V) pathways. ACE provides mechanistically grounded solution for multi-hop KE, empirically outperforming state-of-the-art methods by 9.44% on GPT-J and 37.46% on Qwen3-8B. Our analysis further reveals more fine-grained activation patterns in Qwen3 and demonstrates that the semantic interpretability of value neurons is orchestrated by query-driven accumulation. These findings establish new pathway for advancing KE capabilities based on the principled understanding of internal reasoning mechanisms."
        },
        {
            "title": "INTRODUCTION",
            "content": "Large Language Models (LLMs) have demonstrated remarkable capabilities in storing and retrieving vast amounts of factual knowledge (Hu et al., 2024; Mousavi et al., 2025), underpinning their success in diverse downstream tasks such as question answering and reasoning (Mamaghan et al., 2024; Ke et al., 2025). However, the knowledge encapsulated within these models is static and Equal contribution Correspondence to Zhijiang GUO and Yutao YUE {zg283@cam.ac.uk},{yutaoyue@hkust-gz.edu.cn} 1 Preprint. can become outdated or incorrect, necessitating mechanisms for efficient updates. Full retraining is computationally prohibitive, motivating the development of Knowledge Editing (KE) techniques, which aim to modify specific factual associations within LLMs cost-effectively and with minimal impact on unrelated knowledge (Yao et al., 2023; Mazzia et al., 2024). While the locate-then-edit paradigm, exemplified by methods like ROME (Meng et al., 2022a) and MEMIT (Meng et al., 2022b), has proven effective for editing facts in LMs by successfully targeting components like Feed-Forward Networks (FFNs), its efficacy significantly diminishes when confronting multi-hop factual recall (Zhong et al., 2023; Zhang et al., 2024b). This challenge is particularly acute when the edited knowledge involves an implicit subject an intermediate entity in reasoning chain that leads to the final answers explicit subject (Zhong et al., 2023). As illustrated in Figure 1, multi-hop query like What country is Mark Trumbos sport originates from? requires the model to react as chain: starting with the initial subject Mark Trumbo, it must first identify his sport (the implicit subject, e.g., Basketball in the original knowledge) and then recall the country where that sport originated (the explicit subject, e.g., USA). Figure 1 depicts editing the knowledge so that Mark Trumbos sport becomes Football, which is then linked to originating from Italy. Standard single-hop editing methods, often focusing on deeper FFN layers (Meng et al., 2022a;b; Li et al., 2024). Although recent work like IFMET (Zhang et al., 2024b) has demonstrated improved multi-hop performance, particularly for implicit subjects, by editing deeper FFN layers via constructing multi-hop prompts, the underlying mechanisms explaining why these deeper edits are crucial for correctly retrieving and utilizing the implicit subject information remain unexplored. Figure 1: Illustration of multi-hop factual recall. multi-hop query requires traversing multiple facts. The diagram shows the original knowledge path (e.g., Mark Trumbo Basketball USA) and how knowledge edit (green arrow) can target an intermediate fact, which then requires the model to follow potentially new chain (Mark Trumbo Football Italy). The intermediate entity Football serves as the implicit subject. key limitation of existing KE methods in multi-hop scenarios stems from an incomplete understanding of how knowledgeparticularly intermediate reasoning stepsis dynamically represented and accessed at the neuron level. Through systematic causal analysis, we discover that successful multi-hop recall relies on coordinated interactions between neurons across layers, where implicit subjects trigger cascading activations that progressively accumulate information through query-value interactions. Our experiments reveal two critical properties: (i) In multi-hop factual recall, intermediate implicit subjects function as query neurons, sequentially accumulating and activating relevant value neurons for subsequent reasoning hops. (ii) LLMs store semantically analogous knowledge in structurally similar transformer components, with query and value neurons for specific knowledge types exhibiting consistent localization patterns across layers. Building upon these two initial properties, we systematically analyze the mechanisms of multi-hop reasoning through experiments in Section 4. These properties provide clear answers to two fundamental questions: How LLMs Store the Semantics Knowledge? and How is the information accumulated?. These mechanistic insights motivate ACE (Attribution-Controlled Knowledge Editing), framework that moves from layer-level heuristics to neuron-level interventions. As shown in Figure 4, ACE employs novel attribution techniques to identify and edit critical query-value pathways. Extensive experiments demonstrate that ACE outperforms the state-of-the-art method PMET by 9.44% on GPTJ and 37.46% on Qwen3-8B in terms of multi-hop accuracy. Ablation studies confirm the necessity of both components: skipping query layers causes 16.51% performance drop, while omitting value layers leads to more severe 40.45% decrease. Our analysis reveals that existing KE methods fail in multi-hop reasoning by overlooking both deeper value layers and critical query-layer activation patterns. We further discover distinct architectural differences: while GPT-J maintains fixed layer separation, Qwen3-8B exhibits dynamic, domain-specific alignment. Crucially, correct predictions depend on sparse interpretable neuronsablating just 27 critical neurons causes an accuracy drop to 3.2%, demonstrating the neural coordination required for multi-hop reasoning. 2 Preprint."
        },
        {
            "title": "2 RELATED WORK",
            "content": "Knowledge Editing and Multi-hop Reasoning in LLMs. To avoid the high cost of retraining, recent work focuses on efficient knowledge editing by directly modifying model weights (Zhang et al., 2024a; Yao et al., 2023). The locate-then-edit paradigm identifies key parameters storing target facts, with methods like ROME Meng et al. (2022a) and MEMIT Meng et al. (2022b) updating FFN weights via causal tracing and closed-form optimization, while PMET Li et al. (2024) distinguishes MHSA for general patterns and FFNs for factual content. Other approaches include tuning small subsets (Mitchell et al., 2021) or using hypernetworks (Gupta et al., 2024). However, these methods face significant challenges in multi-hop reasoning scenarios, where editing intermediate facts can break reasoning chains (Yao et al., 2023; Cohen et al., 2024). The MQuAKE benchmark (Zhong et al., 2023) highlights the failure of existing methods to propagate such edits effectively. While IFMET (Zhang et al., 2024b) advances multi-hop performance through layer-level interventions, ACE addresses these limitations by introducing neuron-level mechanism that leverages activation dynamics for robust multi-hop edits. Mechanistic Interpretability and Knowledge Localization. Effective knowledge editing depends on understanding how LLMs store information. FFN layers have been shown to act as key-value stores, with values encoding semantic content (Geva et al., 2020), and recent work has localized factual knowledge at finer granularity (Dai et al., 2021; Hernandez et al., 2023). Yu & Ananiadou (2023) revealed that predictions are driven by interactions between query and value neurons, with value neurons exhibiting consistent relational semantics. Building on this, ACE employs neuronlevel approach to trace and modulate these activation pathways, enabling targeted and interpretable editing in multi-hop reasoning."
        },
        {
            "title": "3 PRELIMINARIES",
            "content": "3.1 MODELING AND TASK Definition of Neurons in LLMs. Autoregressive decoder-only LLMs Fθ process input into tokens = [t1, . . . , tT ], predicting next-token distributions over . Tokens are embedded via to h0 , then processed through transformer layers (MHSA + FFN). Layer hidden states are: + , where hl1 mean the previous layers output, the attention output, and the FFN output. Finally, the last positions Lth layer output is used to compute the probability distribution with unembedding matrix Eu RBd: = hl1 hl + Al i, , Al (1) = softmax(EuhL (2) The attention layer outputs weighted sum across heads, while the FFN applies nonlinear activation σ to two linear transformations. ). (cid:88) Al = fAT j(hl1 1 , hl1 2 , ..., hl ), (3) where can be expressed as weighted sum of FFN neurons: c1 RN and i)), (4) c2 RdN are two matrices. Geva et al. (2020) finds that FFN output c1(hl + Al c2σ(W j=1 = l (cid:88) = ml i,k c2l k, (5) k=1 i,k = σ(f c1l ml + Al Following the same notation as in (Yu & Ananiadou, 2023), c2l column kth of FFN subkey c1l c2, and its coefficient score ml c1. Similarly, the attention output Al k, the th row of (cid:88) i)). (6) is the subvalue of FFN which is the and can be represented as: i,k is calculated by residual output hl1 + Al (hl1 (cid:88) Al = i,j,pW αl j,l(W j,lhl1 ), (7) j=1 p=1 3 Preprint. i,j,p = softmax(W αl j,l, j,l, (8) where j,l, j,l are the query, key, value and output matrices. As discussed in Eq. 5-6, the kth FFN neuron is the kth subvalue c2l and its corresponding subkey c1l k, including all the query and value neurons mentioned later. Similar to FFN neurons, we regard the kth column of j,l as the kth attention subvalue, whose subkey is the kth row of j,l. j,lhl1 j,lhl1 ), Factual Recall Tasks. Define knowledge set = {(s, r, o)} E, where (entities) and (relations) form triplets (s, r, o) indicating subject relates to object via r. An edit instance = (s, r, o) represents replacing with o. We evaluate model through factual recall tasks, which assess its ability to answer both single-hop and multi-hop factual questions requiring 1 reasoning steps. reasoning chain is formally defined as = (s1, r1, o1) (sn, rn, on), starting from an explicit subject s1 and concluding with the target answer on. To illustrate, consider the two-hop question: What country is Mark Trumbos sport originates from? This corresponds to the knowledge chain (Mark Trumbo, Sport, Basketball) (Basketball, Created, USA). We employ two question formats in our evaluation: Cloze Format (Qcloze): The country that Mark Trumbos sport originates from is and QA Format (Qqa): What country is Mark Trumbos sport originates from?. The multi-hop recall process consists of two distinct phases: the explicit recall step (s1, r1, o1) to retrieve the initial fact, followed by implicit recall steps {(si, ri, oi)}n i=2 to traverse subsequent hops. factual recall is considered successful if the model generates the correct final answer, i.e., M(Qcloze) = on or M(Qqa) = on. Figure 1 shows the overall process of the task. Factual Recall Tasks evaluate if the post-edited model can utilize updated knowledge for multi-hop reasoning. Given an edit = (s, r, o), edit prompt Te, and fact chain Ce containing (s, r, o), the model must answer multi-hop queries using the updated fact (s, r, o). For example: After editing (Mark Trumbo, Sport, Basketball Football), the multi query The country that Mark Trumbos sport originates from is should shift from USA to Italy. 3.2 ATTRIBUTION METRICS Distribution Change. The final hidden state hL aggregates critical information for token prediction through summation of neuron-level vectors, implying that essential predictive signals are encoded in specific neurons. By decomposing hl = + (where denotes target neurons contribution and = hl represents residual components), we quantify vs causal influence via probability distribution shift p(w) = p(wx + v) p(wx) for token w. This framework enables systematic identification of neuronal components that maximally amplify p(w), establishing methodology for pivotal neurons in static way, measuring the importance level of neurons. as hl Importance Score for Value Neurons and Layers. To jointly account for both the variable neuron and the conditioning variable in the probabilistic framework. Based on Yu & Ananiadou (2023), we find log probability increase could efficiently evaluate the models distribution change by neuron. Define the log probability increase as importance score for vectors, which satisfies I(x + v) I(x) + I(v). If vl is vector in lth attention layer, the importance score of vl is: I(vl) = log (cid:0)p(w vl + hl1)(cid:1) log (cid:0)p(w hl1)(cid:1), I(l) = I(vl), (cid:88) vl (9) where the probability is computed from vocabulary in Eq.2, layer denotes the index set of varying neuron v. When vector vl in lth FFN layer, is computed by replacing hl1 as hl1 + Al. Importance Score for Query Neurons and Layers. We find that query neurons exist in the transformer while solving multi-hop tasks aims to activate value neurons, even if they do not directly contain information about the target token w. We use the inner product between its subkey and itself to measure the importance of the query neuron, showing the ability activating value neurons: Iquery = c1l k, Iquery(l) = I(vl), (cid:88) vl (10) where layer denotes the index set of varying neuron v, since the c2 vectors do not change, the coefficient scores will be the only varying element. Therefore, if query neuron exhibits larger inner product with the subkey, it activates the value neurons more. Preprint."
        },
        {
            "title": "4 MECHANISM OF MULTI-HOP REASONING",
            "content": "How do language models store and retrieve knowledge when performing complex multi-hop reasoning? We begin by examining how semantically related knowledge is organized within transformer components (Section 4.1), revealing consistent patterns that challenge conventional wisdom about knowledge storage. Building on these structural insights, we then trace how information propagates through reasoning chains (Section 4.2), uncovering sophisticated query-value activation mechanism that progressively accumulates evidence toward final answers. Our analysis spans both GPT-J (Wang & Komatsuzaki, 2021) and the more advanced Qwen3-8B (Team, 2025), with the latter exhibiting even more fine-grained activation patterns that offer new insights into reasoning dynamics."
        },
        {
            "title": "4.1 HOW LLMS STORE THE SEMANTICS KNOWLEDGE?",
            "content": "A fundamental question underpinning effective knowledge editing is: How do LLMs internally store knowledge? Addressing this question is crucial for clarifying the models reasoning logic in multi-hop scenarios and enhancing their internal interpretability. By systematically investigating knowledge representation mechanisms, we can uncover how information propagates through transformer architectures, thereby identifying the root causes of existing KE methods failures in multi-hop reasoning. This understanding provides the foundation for developing more effective KE techniques. To this end, we use dataset MQuAKE-3K (Zhong et al., 2023) to explore the mechanism of semantics knowledge storage. MQuAKE is challenging knowledge editing benchmark which comprises over 3000 multi-hop edit instances. Considering the challenging factual recall queries, we extract subset from original dataset by systematically evaluating the vanilla GPT-J model then scale to Qwen3-8B, using all single-hop factual recall queries to characterize its inherent knowledge retention capabilities. This controlled experimentation protocol isolates the models capacity to store the knowledge. Both attention and FFN layers exhibit inherent capabilities for knowledge storage. We use GPT-4o (Hurst et al., 2024) to classify the knowledge types in the dataset, and conducting analysis across eight semantic categories: Nationality (NN), Continent (CT), Language (LG), Capital (CP), Leadership (LS), Author (AT), Sports Team (ST), and Company Founder (CF). Table 1: Top 9 important attention layers (left block) and FFN layers (right block) in GPT-J. Top 9 important attention layers and FFN layers NN a27 a26 a7 a10 a9 a25 a8 a11 a5 f20 f24 f16 f18 f15 f22 f23 f26 f25 CT a27 a26 a7 a10 a8 a5 a9 a11 a25 f22 f24 f16 f21 f15 f17 f26 f25 f23 f1 f26 f9 LG a27 a7 a5 a6 a8 a4 a1 a26 a9 f27 f7 f4 f6 f5 CP a27 a26 a7 a10 a8 a9 a12 a5 a6 f27 f26 f7 f10 f12 f8 f9 f5 LS a27 a26 a25 a7 a10 a6 a8 a6 a5 f27 f26 f25 f24 f7 f10 f6 f8 f6 f8 f10 f27 f26 f25 f5 AT a27 a26 a25 a7 a9 a8 a10 a5 a6 f5 f25 f4 ST a26 a27 a7 a10 a8 a6 a5 a25 a4 f26 f27 f7 f10 f8 f5 f6 f9 CF a26 a27 a24 a25 a7 a8 a9 a6 a5 f26 f27 f24 f25 f7 f6 f9 f5 f6 f7 f8 To find critical neurons and layers, we performed forward passes on all single-hop questions in the dataset and computed the sum of the importance scores at last position in the residual stream. We select top 9 most important layers to analysis the knowledge attribution as Table 1. Our analysis reveals that information with similar semantics tends to be stored in proximate neural modules, while semantically unrelated information is distributed across disparate modules. Specifically, MHSA components are activated in similar positions, for instance, a27, a26, a7 ranks top in all knowledge. This suggests that MHSA stores general knowledge and capabilities in LLMs. Differently, FFN layers tends to primarily extracts its own knowledge. For instance, f24, f27, f16 ranks top for similar semantics (NN, CT, LG, CP, LS), dissimilar semantics (AT, ST, CF) resides in distinct layers. We set the top critical semantic-related neurons to zero in GPT-J and Qwen3-8B, Figure 2 shows that only 1% intervention on important neurons causes over 90% accuracy decrease in semanticrelated subsets. Compared to 1% random intervention, only 9.47% and 8.19% accuracy decrease in GPT-J and Qwen3-8B. Based on our observations, we formalize Takeaway 1: LLMs tend to store semantically analogous knowledge in structurally similar components. 5 Preprint. Figure 2: The Impact of Causal Intervention with semantic-related requests upon LLMs of most important layer, including Nationality, Continent, Capital and Language requests."
        },
        {
            "title": "4.2 HOW IS THE INFORMATION ACCUMULATED?",
            "content": "Building on Takeaway 1, which identifies the locations and distribution patterns of knowledge storage in LLMs, we now investigate the dynamic process of information accumulation during multi-hop reasoning. Specifically, we aim to address the question: How is the information pertaining to the final answer accumulated through implicit subjects? To this end, we conduct causal interventions and statistical analyses on the critical layers identified previously, examining the interactions between query and value neurons across the reasoning chain. Building on the observation that implicit subject information accumulates through shallow FFN layers (Zhang et al., 2024b), we investigate the mechanistic details of this accumulation process. While Hou et al. (2023) suggests that models process multi-hop reasoning by segmenting it into individual single-hop recalls, the specific neural mechanisms underlying information integration remain unclear. This gap leads us to examine two fundamental questions: How is information pertaining to the final answer progressively accumulated through implicit subjects? Through which transformer components is this cumulative effect primarily mediated? Our investigation begins with an analysis of value neuron distributions in GPT-Js FFN layers. Contrary to the prevailing assumption that deeper layers predominantly determine model outputs, we observe more complex pattern. Value neurons exhibit peak density in middleto-deeper layers, with distribution maxima not aligning with the final residual stream positions. Most strikingly, we find an abrupt depletion of neurons in the deepest layersa finding that challenges conventional understanding. Further analysis reveals systematic relationship between query and value neuron activation patterns. As shown in Figure 3, the significance variation of query FFN layers closely tracks the progressive accumulation of implicit subject information during reasoning. Layer-wise probing demonstrates that query neuron activation (blue curve) consistently precedes value neuron activation (red histogram) by 1-2 layers, indicating structured information flow mechanism. Figure 3: Query layers log increase and value neurons count by layers in GPT-J. Layer log increase is the importance score calculated by logarithmic difference in Eq. 9. To validate the functional importance of these patterns, we conducted targeted interventions on query neurons. When we ablated the top 100 query neurons from two layers showing peak activation for 2-hop requests (fq16 and fq18), model capability decreased by 46.2% and 61.9%, respectively. Moreover, the number of activated value neurons in subsequent layers (f17,18,19) dropped dramatically from (28,16,33) to (6,4,7), while other value neurons showed minimal change (12 neurons decreased). We show more details on Qwen3 while we explore the forward processes in Appendix E. These experimental results lead us to two key observations: (1) Final answer information is progressively encoded through early-stage query-value activation pairs throughout the reasoning chain; (2) Implicit subjects functionally operate as query neurons that orchestrate the activation of value neurons for subsequent reasoning steps. Based on these consistent experimental findings, we formulate Preprint. Takeaway 2: Information of the final answer is accumulated through implicit query neurons that sequentially activate corresponding value neurons across the reasoning chain."
        },
        {
            "title": "5 ACE: ATTRIBUTION-CONTROLLED KNOWLEDGE EDITING",
            "content": "Based on our findings and validations concerning the mechanisms of LLMs knowledge storage and reasoning in multi-hop factual recall tasks, we introduce Attribution-Controlled Knowledge Editing (ACE) for Multi-hop Factual Recall. As Figure 4 demonstrated, ACE extends the established locatethen-edit paradigm through three sequential operations: first identifying latent query neurons to verify critical query FFN layers that activate explicit subjects value neurons; second, applying model editing via multi-hop prompts to modify explicit subject knowledge by targeting FFN value components in deeper layers; and third, executing complementary edits targeting FFN query mechanisms in middleto-shallow layers to adjust the implicit reasoning path originating from the updated explicit fact. ACE strategically emphasizes the significance of FFN query mechanisms for successful multi-hop reasoning while also properly considering the FFN values within the residual stream computation. Stage 1: Identifying. Using the definition of neurons and importance in Section 3, we employ importance score I, Iquery in Eq. 9 and 10 to identify critical q/v neurons and their corresponding layers. In the identifying process, we performed forward passes on all multi-hop questions in the dataset and computed the sum of the importance scores at the last token position in the residual stream. After the identifying, we rank the query and value layers and select the top layers to edit. Figure 4: ACE edits Q-V neurons via attribution: (a) The existing locate-then-edit KE method updates new fact using single-hop prompt; (b) For multi-hop factual recall tasks, traditional locate-then-edit failed to correct edit the knowledge on query layers, overlooking value neurons; (c) Our ACE identifies critical query layers which activates the value neurons most to edit the knowledge. Stage 2: Locate-then-edit. Building upon identified critical layers, we conducted sequential knowledge editing to demonstrate the models enhanced knowledge acquisition through intensified activation patterns. Based on previous locate-then-edit paradigm (Li et al., 2024), we apply editing on FFNs and keep attention heads unchanged, while the general semantic information saved in attention heads should not be changed. For lth layer FFN, its output of the ith token would be c2σ(W ), and theres no attention input in GPT-J, where σ is the non-linear activation function. σ(W ) take the responsibility as keys, denoted as ki. Whole FFN output is the value vi = c2 denotes the weight of the models values needs to be modified. So we aim to modify subvalue matrix c2k = v, where represents the new values (factual knowledge). We use backbone PMET (Li et al., 2024) to complete editing process, details shown in Algorithm C. ), whose subvalue matrix c2 s.t. c2σ(W f c2hl1 c2hl1 c2hl1 The ACE framework accomplishes knowledge editing through two sequential stages. In Stage 1, we identify critical query layers and value layers within the model architecture. The critical query and value layers represent the precise locations where target knowledge is stored. In Stage 2, we edit these components enables efficient integration of new factual information into the models parameters. In all, ACE incorporates complementary edits to the often-overlooked query layers, ensuring that the 7 Preprint. updated knowledge can be properly activated and traversed during multi-step reasoning processes, making information accumulates progressively via query-value interactions."
        },
        {
            "title": "6.1 EXPERIMENTAL SETUP",
            "content": "Dataset. MQuAKE-3K (Zhong et al., 2023) is benchmark dataset for evaluating large language models multi-hop fact recall capability after knowledge editing. Each instance contains multi-hop fact recall chain (interconnected triples) and corresponding textual questions, requiring models to maintain coherent reasoning after applying single-hop knowledge edits via edit prompts. This design simulates cascading effects of real-world knowledge updates, providing systematic framework to assess models dynamic knowledge management. To faithfully evaluate the models capabilities and assess its capacity to assimilate edited knowledge, we applied filtering to the original dataset, resulting in curated subset where the base model consistently achieves accurate reasoning. Baselines. Baselines are Base, refers to the original GPT-J (6B) and Qwen3-8B without any edit; FT refers to fine-tuning method, ROME Meng et al. (2022a) refers to the vanilla locote-then-edit method; MEMIT Meng et al. (2022b), extends ROME with updating weights by set of facts, and PMET Li et al. (2024) claims optimizations on FFN layers based on MEMIT. Metric and Setup. We apply our ACE on the model GPT-J (6B) and Qwen3-8B. We use Multi-hop requests answering accuracy as the metric to evaluate the performance of our edited model. We use PMET as our models primary backbone for editing. More settings details see in Appendix F. 6.2 MAIN RESULTS Table 2 demonstrates the general performance of various established methods and ACE under the different classes of data settings on our subset of MQuAKE-3K. To enable precise identification of critical layers store the knowledge and activation patterns during model editing, we systematically integrated in-context priming and Chain-of-Thought reasoning across all editing prompts. This dual-strategy architecture ensures optimal knowledge editing efficacy through targeted activation within the models parameter space. # Edits refers to the number of how many individual facts in the reasoning chain are edits, its maximum equals to the number of hops in the dataset. As evidenced in Table 2, the proposed ACE framework demonstrates consistent superiority over existing methodologies across various evaluation metrics. Our method outperformances 9.44% and 37.46% on GPT-J and Qwen3-8B. Traditional Locate-then Edit paradigm performances even worse on Qwen3-8B due to the fixed editing positions, and ACE shows much flexibility on reasoning models due to the unfixed q-v positions as discussed in Section 6.4. We also show detailed metrics of our experiments in Table 3. Efficacy metric, measures whether the model can successfully answer the single-hop fact recall prompt, Paraphrase metric, measures the model can answer the same original question in different statements. Specificity metric, measures the whether the edit of specific fact affects other facts stored within the model. ACE demonstrates superior performance over SOTA across multiple metrics, highlighting its multiple capabilities. 6.3 ABLATION STUDY We performed an ablation study on the edited query and value FFNs in ACE by sequentially skipping edits to the identified critical layers within the model, aiming to elucidate the impact of these critical layers within the ACE editor. As shown in Table 4, for both GPT-J-6B and Qwen3-8B, skipping the layers targeted for editing significantly impaired the editors performance. After skipping the three most important query layers, model performance decreased by 16.51%, while skipping the two most important value layers led to performance drop of 40.45%. The performance degradation resulting from skipping query layers was slightly less pronounced than that from skipping value layers, which validates our takeaways: query layers transmit information by activating value layers. Skipping query layers results in incomplete activation of the corresponding 8 Preprint. Table 2: Multi-hop accuracy comparison of different KE methods on the MQuAKE-3K dataset in few-shot setting, Base shows the models performance on the unedited answers and edited models performance on edited answers. Our model outperformances than other models significantly. Editor Avg.(GPT/Qwen) GPT-J / # Edits = Qwen3-8B / # Edits ="
        },
        {
            "title": "FT\nROME\nMEMIT\nPMET\nACE",
            "content": "98.42 / 99.17 1-edit 2-edit 3-edit 4-edit 1-edit 2-edit 3-edit 4-edit 99.7 95.48 97.51 97.23 99.81 97.46 98.14 97.64 2.63 3.54 / 2.18 0.00 0.00 4.17 7.08 35.04 / 28.79 44.51 38.93 17.52 38.58 / 18.67 64.30 16.87 17.25 4.20 37.01 / 20.78 49.26 36.30 24.34 17.01 28.64 14.08 12.56 11.20 46.45 / 58.24 45.26 50.24 36.17 43.29 60.22 59.48 51.62 47.61 0.00 0.00 5.06 35.09 32.48 18.97 8.16 29.84 19.18 12. 2.79 3.14 Table 3: The detailed results of more metrics in experiments on GPT-J and Qwen3-8B. Editor Efficacy Paraphrase Specificity FT (GPT-J/Qwen3) ROME (GPT-J/Qwen3) MEMIT (GPT-J/Qwen3) PMET (GPT-J/Qwen3) ACE (GPT-J/Qwen3) 98.4 / 97.1 64.2 / 51.8 62.8 / 53.6 81.6 / 75.6 99.8 / 99.4 74.5 / 73.2 61.6 / 49.3 66.2 / 61.8 65.8 / 68.9 91.2 / 94.2 83.8 / 79.6 66.8 / 57.2 70.0 / 64.7 74.6 / 64.4 79.2 / 81.8 Table 4: The results of ablation experiments on GPT-J-6B and Qwen3-8B model. The column Editor shows which layer(s) are skipped in the editing process, the index # of the layer refers to the importance rank. The percentage of decrease() is calculated relative to ACE as the baseline. Editor Avg. Efficacy Paraphrase Specificity #1 #1,2 #1,2,3 #1 #1,2 #1 #1,2 #1,2,3 #1 #1,2 (GPT-J-6B) (GPT-J-6B) (GPT-J-6B) (GPT-J-6B) (GPT-J-6B) (Qwen3-8B) (Qwen3-8B) (Qwen3-8B) (Qwen3-8B) (Qwen3-8B) 43.26( 6.87%) 41.19( 11.32%) 38.78( 16.51%) 42.14( 9.28%) 33.97( 26.87%) 52.61( 9.67%) 47.34( 18.71%) 45.26( 22.29%) 51.39( 11.76%) 34.68( 40.45%) 96.2 94.8 90.6 91.5 84.6 96.6 92.4 91.3 94.8 71.9 90.4 91.0 91.6 88.7 81.8 91.3 89.3 85.8 90.2 73.1 77.6 75.2 74.3 74.9 70.3 74.3 72.7 71.5 73.6 72.3 value layers, whereas skipping the editing of value layers leads to less knowledge being incorporated. 6.4 ANALYSIS Now we can explain why the existing KE methods failed in multi-hop reasoning. Existing KE methods overlooked the value layers in deeper locations, even regarded the output generation layers as the value layers, where the knowledge truly be stored in latter ones (details in Appendix E). And the worst is, these KE methods ignored the importance of editing the query layers. Fine-Grained Activation Pattern. In Table 4, Qwen3-8B exhibits greater sensitivity to the number of layers being edited compared to GPT-J. Qwen3-8B demonstrates more fine-grained activation patterns during the forward pass, which imposes stricter requirements on the coherence of information within the reasoning chain.In GPT-J, the active query layers are predominantly located in the middle layers, while the deeper FFN value layers are activated by queries. There exists consistent layerwise separation between these two families of layers, and their positions (fq16,q17,q18, fv28,v29,v30) remain invariant across different domains. In contrast, in Qwen3-8B, the query layers are situated in middle-to-deeper layers and are closely alignedand at times partially overlappingwith the value layers they activate (e.g., fq27,q28,q29, fv30,v31,v32). Moreover, the absolute positions of these query and value layers are not statically fixed, they shift dynamically depending on the knowledge domain. Case Study. As case study, we examined the residual stream for the single-hop request: Tim Duncan plays the sport of. The model exhibited the largest increase in importance at tokens where Preprint. semantics converge, such as plays and of, with reaching 0.9932 and 0.8469, respectively. The top predicted tokens were highly interpretable (e.g., basketball, ball, NBA). Meanwhile, at other transitional tokens, the model demonstrated stronger exploratory capabilities by predicting incoherent tokens. We select 27 neurons whose associated vocabulary included the correct target token and performed 1000 sampling trials with these neurons removed. The models accuracy under this condition dropped to merely 3.2%, indicating the crucial role these interpretable neurons play in generating correct responses. In contrast, when we ablated 27 neurons with high importance scores but lacking correct semantic interpretability, the model maintained 59.4% accuracy. This suggests the final generation of correct output tokens depends on sparse set of highly specialized, interpretable neurons.We also observe some neurons serve as q-v shared neurons at the same time, which are highly interpretable, the details of this residual stream see in Appendix D. We consider that this alternating pattern of semantic divergence and convergence during in-text token prediction constitutes more fine-grained activation behavior, which is modulated by the knowledge domain. Furthermore, these semantically convergent tokens, and neurons which serve as shared neurons also are aligned in recent RL research concerning token entropy (Wang et al., 2025), represents promising focus for future studies of critical tokens in RL."
        },
        {
            "title": "7 CONCLUSION",
            "content": "In this study, we systematically investigate the q-v activation mechanism underlying multi-hop factual recall in LMs. Through extensive experiments on both GPT-J and Qwen3-8B, our analysis reveals sophisticated neural coordination pattern: query neuronswhether representing implicit subjects or components of the final answerorchestrate the sequential activation of semantically interpretable value neurons throughout the reasoning chain. This mechanistic understanding resolves long-standing questions about how information propagates in multi-hop scenarios. Our work contributes to the broader understanding of how LLMs organize and process knowledge. These insights open new avenues for developing more interpretable LMs. 10 Preprint."
        },
        {
            "title": "REFERENCES",
            "content": "Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva. Evaluating the ripple effects of knowledge editing in language models. Transactions of the Association for Computational Linguistics, 12:283298, 2024. Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons in pretrained transformers. arXiv preprint arXiv:2104.08696, 2021. Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. Transformer feed-forward layers are key-value memories. arXiv preprint arXiv:2012.14913, 2020. Akshat Gupta, Dev Sajnani, and Gopala Anumanchipalli. unified framework for model editing. arXiv preprint arXiv:2403.14236, 2024. Evan Hernandez, Belinda Li, and Jacob Andreas. Inspecting and editing knowledge representations in language models. arXiv preprint arXiv:2304.00740, 2023. Yifan Hou, Jiaoda Li, Yu Fei, Alessandro Stolfo, Wangchunshu Zhou, Guangtao Zeng, Antoine Bosselut, and Mrinmaya Sachan. Towards mechanistic interpretation of multi-step reasoning capabilities of language models. arXiv preprint arXiv:2310.14491, 2023. Xuming Hu, Junzhe Chen, Xiaochuan Li, Yufei Guo, Lijie Wen, Philip Yu, and Zhijiang Guo. Towards understanding factual knowledge of large language models. In The Twelfth International Conference on Learning Representations, 2024. Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024. Zixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do Xuan Long, Minzhi Li, Chengwei Qin, Peifeng Wang, Silvio Savarese, et al. survey of frontiers in llm reasoning: Inference scaling, learning to reason, and agentic systems. arXiv preprint arXiv:2504.09037, 2025. Xiaopeng Li, Shasha Li, Shezheng Song, Jing Yang, Jun Ma, and Jie Yu. Pmet: Precise model editing in transformer. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pp. 1856418572, 2024. Amir Mohammad Karimi Mamaghan, Samuele Papa, Karl Henrik Johansson, Stefan Bauer, and Andrea Dittadi. Exploring the effectiveness of object-centric representations in visual question answering: Comparative insights with foundation models. arXiv preprint arXiv:2407.15589, 2024. Vittorio Mazzia, Alessandro Pedrani, Andrea Caciolai, Kay Rottmann, and Davide Bernardi. survey on knowledge editing of neural networks. IEEE Transactions on Neural Networks and Learning Systems, 2024. Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. Locating and editing factual associations in gpt. Advances in neural information processing systems, 35:1735917372, 2022a. Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. Mass-editing memory in transformer. arXiv preprint arXiv:2210.07229, 2022b. Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher Manning. Fast model editing at scale. arXiv preprint arXiv:2110.11309, 2021. Seyed Mahed Mousavi, Simone Alghisi, and Giuseppe Riccardi. Llms as repositories of factual knowledge: Limitations and solutions. arXiv preprint arXiv:2501.12774, 2025. Qwen Team. Qwen3 technical report, 2025. URL https://arxiv.org/abs/2505.09388. Ben Wang and Aran Komatsuzaki. Gpt-j-6b: 6 billion parameter autoregressive language model, 2021. 11 Preprint. Shenzhi Wang, Le Yu, Chang Gao, Chujie Zheng, Shixuan Liu, Rui Lu, Kai Dang, Xionghui Chen, Jianxin Yang, Zhenru Zhang, Yuqiong Liu, An Yang, Andrew Zhao, Yang Yue, Shiji Song, Bowen Yu, Gao Huang, and Junyang Lin. Beyond the 80/20 rule: High-entropy minority tokens drive effective reinforcement learning for llm reasoning, 2025. URL https://arxiv.org/abs/ 2506.01939. Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, and Ningyu Zhang. Editing large language models: Problems, methods, and opportunities. arXiv preprint arXiv:2305.13172, 2023. Zeping Yu and Sophia Ananiadou. Neuron-level knowledge attribution in large language models. arXiv preprint arXiv:2312.12141, 2023. Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, et al. comprehensive study of knowledge editing for large language models. arXiv preprint arXiv:2401.01286, 2024a. Zhuoran Zhang, Yongxiang Li, Zijian Kan, Keyuan Cheng, Lijie Hu, and Di Wang. Locate-then-edit for multi-hop factual recall under knowledge editing. arXiv preprint arXiv:2410.06331, 2024b. Zexuan Zhong, Zhengxuan Wu, Christopher Manning, Christopher Potts, and Danqi Chen. Mquake: Assessing knowledge editing in language models via multi-hop questions. arXiv preprint arXiv:2305.14795, 2023. Preprint."
        },
        {
            "title": "APPENDIX CONTENTS",
            "content": "A Related Work in Details Subset of MQuAKE Dataset B.1 Subset Construction . B.2 Dataset Labeling . . . . . . ACE Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Details of Internal Fine-Grained Reasoning Q-V Pairs Flow in Qwen3-8B More Details of the Analysis Experimental Settings Prompts G.1 Few-shot and Chain-of-Thought Evaluation Prompts . . . . . . . . . . . . . . . . G.2 Prompts to recall single-hop fact . . . . . . . . . . . . . . . . . . . . . . . . . . . G.3 Dataset Annotation Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 14 15 15 16 16 17 19 19 19 13 Preprint."
        },
        {
            "title": "A RELATED WORK IN DETAILS",
            "content": "Knowledge Editing in LLMs. The inherent difficulty and computational expense of retraining LLMs to incorporate new or corrected information (Zhang et al., 2024a; Yao et al., 2023) have spurred significant research in KE. The dominant paradigm, locate-then-edit, aims to identify specific model parameters responsible for storing target fact and modify them precisely. Seminal works like ROME Meng et al. (2022a) employed causal tracing to locate critical states in FFN layers and updated their weights via rank-one modifications. MEMIT Meng et al. (2022b) extended this by efficiently editing thousands of facts simultaneously using closed-form optimization objective. Building on these, PMET Li et al. (2024) proposed that Multi-Head Self-Attention (MHSA) layers encode general knowledge extraction patterns, while FFNs store specific factual details, thus focusing updates on FFNs. Other approaches include fine-tuning small set of parameters (Mitchell et al., 2021) or training external hypernetworks to predict parameter updates (Gupta et al., 2024). While these methods have shown strong performance in single-hop factual editing, their effectiveness often declines in multi-hop scenarios, as they overlook how knowledge is chained and how intermediate reasoning steps are utilized. Our work, ACE, directly addresses this limitation by focusing on neuron-level mechanisms underlying multi-hop knowledge retrieval. Mechanistic Interpretability and Knowledge Localization. Effective knowledge editing is intrinsically linked to understanding where and how LLMs store knowledge. growing body of work in mechanistic interpretability aims to unravel these internal workings. Geva et al. (2020) and Geva et al. (2020) identified FFN layers as key-value memories, where keys correspond to input patterns and values represent output distributions. More pertinent to our approach, Dai et al. (2021) and Hernandez et al. (2023) explored techniques to locate factual knowledge at finer granularity. The work by Yu & Ananiadou (2023) provides crucial foundation for our methodology. They demonstrated that both attention and FFN layers operate via query neurons that activate specific value neurons to produce final predictions. These value neurons were found to be semantically interpretable when projected into the vocabulary space, and similar types of relations (e.g., capital of X, birthplace of Y) were shown to activate neurons in structurally consistent locations across different subjects. While IFMET focused on attribution and interpretation, ACE leverages these neuron-level insights to develop more targeted and mechanistically grounded KE strategy, particularly for the complex dynamics of multi-hop reasoning where intermediate implicit subjects act as activators. Multi-hop Reasoning and Knowledge Editing. Multi-hop reasoning, requires LLMs to chain multiple pieces of information to arrive at an answer, poses significant challenge for KE (Yao et al., 2023; Cohen et al., 2024). Editing single fact involved in multi-hop chain can inadvertently disrupt the models ability to perform the entire reasoning chain. The MQuAKE benchmark Zhong et al. (2023) highlighted the poor performance of existing KE methods on multi-hop requests, revealing that edits often fail to propagate effectively when the edited fact is an intermediate step. ACE advances IFMET (Zhang et al., 2024b) by proposing neuron-level editing mechanism: While IFMET observed that multi-hop editing via deeper FFN layers enhances performance, it lacked mechanistic insights into why deeper layers matter. Through query-value activation dynamics analysis, we reveal that deeper layers host value neurons processing multi-hop reasoning triggered by implicit subjects (acting as query-like activators) resolved in earlier layers. Unlike IFMETs layer-level heuristic approach, ACE establishes an interpretable neuron-editing framework guided by attribution analysis it achieves robust multi-hop knowledge updates by precisely identifying and modulating query-value activation pathways. This shift from layer-centric to neuron-centric mechanism interpretation constitutes our core innovation."
        },
        {
            "title": "B SUBSET OF MQUAKE DATASET",
            "content": "B.1 SUBSET CONSTRUCTION This investigation into the cognitive mechanisms underlying single-hop and multi-hop fact retrieval employed controlled experimental paradigm using cloze-style query templates. Our methodology involved curating knowledge triples from MQuAKE that were demonstrably answerable by GPT-J-6B in zero-shot configurations. This rigorous selection protocol achieved dual objectives: (1) establishing 14 Preprint. baseline for knowledge recall under maximally constrained conditions, and (2) systematically mitigating potential confounding effects from response ambiguity in experimental outcomes. B.2 DATASET LABELING We use GPT-4o to label the knowledge in the dataset. We show the prompts we used in Appendix G.3. We labeled the dataset related to the knowledge, which are Geographic location, Organization, Personal attributes, Sports, Entertainment, Language and culture, Education, Religion, Literature and Event, which consists of more detailed smaller classes."
        },
        {
            "title": "C ACE OPTIMIZATION",
            "content": "Input: Requested edits = {(si, ri, oi model M, all layers lall, value layers lv Output: Modified model ME containing edits from for (si, ri, )}N ) do i=1, Search(Tri(si)) ; Generate the single edit prompt Tri(si) Optimize ; end for lv do 1, . . . , ]) ; Calculate([v l + ; ; end for lall do lq Search in residual([l1, . . . , lL], lv) ; end for lq do Calculate([v l + ; ; end 1, . . . , ]) ; // for every new knowledge // edit value layers // update new weights // Find critical query layers // edit query layers // update new weights Algorithm 1: ACE Algorithm Our method primarily consists of first edit (value neurons edit) and furtherance edit (query neurons edit). Each single edit process obtains target weights through optimization of the knowledge preservation and editing objective: λ ˆW K0 (cid:123)(cid:122) Preservation (cid:124) c2K02 (cid:125) , + ˆW KE VE2 (cid:123)(cid:122) (cid:125) Editing (cid:124) (11) arg min ˆW 0 k2 0 kN 0 ] and V0 = where K0 = [k1 . . . ] represents edit matrices, and Ve = [v kE k2 eE e1 new knowledge. The edited fact set corresponds to {(si, ri, ) = 1, 2, , E}. Following the parameterization ˆW = derived as: c2K0 encapsulate preserved knowledge, KE = [k1 ] denotes target representations for c2 + , the closed-form solution for incremental weights is = RK (C0 + KEK )1, := (VE c2KE), C0 := K0K 0 . (12) The optimization of value vector perturbations δ follows: 15 Preprint. δ = arg min δ L(δ) = µDKL (PMe[t ] PM[t ])+φ"
        },
        {
            "title": "1\nP",
            "content": "P (cid:88) j=1 log PMe[o prefj Te], (13) where denotes KL prompts (e.g., is a), excludes answer tokens o, and Te represents editing prompts (e.g., The capital of Spain is ). DETAILS OF INTERNAL FINE-GRAINED REASONING Q-V PAIRS FLOW IN QWEN3-8B We examined the residual stream for the single-hop request: Tim Duncan plays the sport of. We show the importance score increase with forward process here. In table 5, we identify distinct patterns of semantic divergence and convergence in the residual stream. At the tokens plays and of, the model exhibits stronger tendency to conclude the current prediction, narrowing the semantic flow to end the sentence, while demonstrating high interpretability. These tokens also correspond to the largest increase in importance scores. In contrast, at other token positions, the model exhibits greater potential for exploration and reasoning, favoring semantic divergence and losing almost all interpretability. We hypothesize that this intra-sentence semantic activation pattern is capability conferred by post-training reinforcement learning, enabling the model to rapidly predict correct tokens at critical positions while maintaining strong exploratory behavior elsewhere. In studies related to token entropy in RL, such highly interpretable and semantically convergent regions are likely to play decisive role during training. Table 6 demonstrates the neurons interpretability in vocabulary space. In query neurons, we could not find much interpretabilities after projecting neurons, most logits are unrelated to the request, but much interpretable neurons appears in the value neurons. Based on this observation, we could claim that the query layers enhance knowledge editing not through direct modification of knowledge representations or token embeddings, but by amplifying activations in value neurons through q-v pairs. Table 5: Token Increase in Qwen3-8B on Residual Stream. Token Importance increase Top tokens in vocabulary space Tim FFN: 0.0021, attn: 0.0014 Duncan FFN: 0.0014, attn: 0.0009 plays the sport of FFN: 0.9932, attn: 0.8167 basketball, NBA, career, ball, -playing FFN: 0.4894, attn: 0.4159 FFN: 0.1478, attn: 0.0948 FFN: 0.8469, attn: 0.6198 epit, inaugural, bidding, dream, etr tennis, of, ful, arena, basketball, ball basketball, NBA, balls, ball, Olympia an, os, ise, Exactly, R, ore, at, rot era, allen, stad, oret, hit, -led Table 6: Interpretable neurons in vocabulary space, bold refers to the interpretable tokens. Neurons Top tokens in vocabulary space f15 5495 (query neuron) f18 3584 (value neuron) outwe, expries, LESS, retaliate, <, Himself, ALSO football, sports, players, soccer player, baseball, sport f31 2097(shared neuron in Qwen3) basketball, sports, balls, players soccer, baseball, NBA"
        },
        {
            "title": "E MORE DETAILS OF THE ANALYSIS",
            "content": "This section provides additional experimental details supporting the analysis in Section 4.2, using the query Tim Duncan plays the sport of as case study. We analyze the attribution patterns across both FFN and attention layers throughout the forward pass. Figure 5 presents the layer-level log increase 16 Preprint. across all layers, revealing that in Qwen3-8B, activated layers are concentrated in deeper regions of the network. Notably, the activation levels in the final layers remain relatively low, indicating that knowledge is not primarily stored in these terminal layers. Instead, these layers appear primarily responsible for generating model outputs rather than knowledge storage. key observation is the rapid decrease in attention log increase around layer 25, followed by corresponding drop in FFN layer 27. This pattern supports the conclusion that attention mechanisms (and their associated query-value activations) facilitate factual recall by activating progressively deeper FFN layers. The attention heatmap in Figure 6 further corroborates this finding, with darker coloration indicating higher importance scores. These results demonstrate how knowledge accumulation begins in shallower attention layers and culminates in complete activation within deeper network regions. We observe that during the forward pass of the query Tim Duncan plays the sport of in Qwen3-8B, unlike GPT-J which distributes query-value activation across shallower layers, Qwen3-8B executes this process continuously within deeper layers. As previously analyzed, this pattern arises from Qwen3-8Bs more fine-grained intra-sentence activation behavior, where active query layers are positioned immediately preceding their corresponding value layers, which typically reside in deeper network regions. Table 7 shows the top value neurons details in Qwen3-8B while processing this forward case. We select four neurons, representing different important position in the model. Our analysis reveals clear distinction in the interpretability of neurons across different layers. Neurons in shallower and less critical regions typically exhibit minimal semantic interpretability, whereas those with the highest importance scores demonstrate strong correspondence to meaningful vocabulary tokens. To quantify the functional significance of these interpretable neurons, we conducted systematic ablation study. We selected 27 neurons whose associated vocabulary included the correct target token and performed 1000 sampling trials with these neurons removed. The models accuracy under this condition dropped to merely 3.2%, indicating the crucial role these interpretable neurons play in generating correct responses. In contrast, when we ablated 27 neurons with high importance scores but lacking correct semantic interpretability, the model maintained 59.4% accuracy. This striking disparity suggests that while the reasoning chain involves dense information propagation and accumulation across numerous neurons throughout the network, the final generation of correct output tokens depends on sparse set of highly specialized, interpretable neurons. These findings have important implications for future work on token entropy in reinforcement learning, particularly regarding how models allocate computational resources during reasoning processes. Figure 5: The layer-level log increase through all layer upon one case on Qwen3-8B."
        },
        {
            "title": "F EXPERIMENTAL SETTINGS",
            "content": "The critical layers for GPT-J-6B and Qwen3-8B have been identified as Rq = {3, 4, 5, 6, 7, 8}, Rv = {26, 27, 28} and Rq = {25, 26, 27}, Rv = {28, 29, 30, 31, 32}. Therefore, we mainly update the FFNs components of these critical layers of GPT-J and Qwen3-8B. 17 Preprint. Figure 6: The attenton head heatmap through all layer upon one case on Qwen3-8B. Table 7: FFN Value Neuron Increase and Vocabulary in Qwen3-8B on Residual Stream. Neuron Importance increase Top tokens in vocabulary space fv29 5709 fv27 4542 fv29 7550 fv28 8055 1.1542 0.4716 0.4421 0.1866 basketball, baskets, Basket, Baskets, ball, -BASKET fire, licer, phu, shutdown, IAM, arez information, INFORMATION, information, informac ao school, sniff, originals, baseball, balls In our edits, our configuration for PMET adheres to the settings specified by (Li et al., 2024). Initially, we set φ = 1 and 0 µ 1 to manage the retention of the models original knowledge. As µ increases, the retention level also increases, while φ exhibits the opposite trend. After maximizing the probability of the target knowledge, we reduce φ to 0.1 to preserve the original knowledge as much as possible. Optimization is halted when DKL < 0.01. On GPT-J and Qwen3-8B, for estimating the covariance matrix (i.e., the set of previously memorized keys C0), we sample 10,0000 times on Wikitext in fp32 precision and set λ = 6000. When optimizing, we limit the total optimization steps to 30 with learning rate of 0.2. All our experiments were conducted using the MQuAKE dataset. To test the accuracy of answers to multi-hop questions, we adhered to the few-shot and Chain of Thought (CoT) templates in Appendix G.1 and procedures. 18 Preprint."
        },
        {
            "title": "G PROMPTS",
            "content": "This appendix details the various prompt templates used in our experiments. These templates are used to evaluate the models multi-hop fact recall ability after knowledge editing, as well as for automatic classification and annotation of the dataset. G.1 FEW-SHOT AND CHAIN-OF-THOUGHT EVALUATION PROMPTS The following is an example of few-shot and Chain of Thought (CoT) prompt used for the main experiment evaluation. We guide the model to answer complex multi-hop questions by showing reasoning process containing Thoughts. Question: What is the capital of the country where Plainfield Town Hall is located? Thoughts: Plainfield Town Hall is located in the country of the United States of America. The capital of United States is Washington, D.C. Answer: Washington, D.C. Question: In which country is the company that created Nissan 200SX located? Thoughts: Nissan 200SX was created by Nissan. Nissan is located in the country of Japan. Answer: Japan Question: Which continent is the country where the director of \"My House Husband: Ikaw Na !\" was educated located in? Thoughts: The director of \"My House Husband: Ikaw Na!\" is Jose Javier Reyes. Jose Javier Reyes was educated at De La Salle University. De La Salle University is located in the country of Philippines. Philippines is located in the continent if Asia. Answer: Asia Question: Who is the spouse of the US president? Thoughts: The US president is Joe Biden. The spouse of Joe Biden is Jill Biden Answer: Jill Biden Question: Who has ownership of the developer of the Chevrolet Corvette (C4)? Thoughts: The developer of Chevrolet Corvette (C4) is Chevrolet. Chevrolet is owned by General Motors. Answer: General Motors Question:{Multi-hop questions...} G.2 PROMPTS TO RECALL SINGLE-HOP FACT The following prompt templates are used in our dataset screening and construction process, as described in Appendix B.1. Before formally conducting multi-hop knowledge editing experiments, we use these straightforward, single-hop factual questions to probe the inherent knowledge reserves of base models (such as GPT-J-6B). This step allows us to identify knowledge chains from the MQuAKE dataset where the model has accurately grasped the ground truth, ensuring the reliability of subsequent experiments and avoiding interference caused by the models inherent lack of foundational knowledge. Q: What is the country of citizenship of Fernando Santos? A: Portugal Q: What is the name of the current head of state in Portugal? A: Marcelo Rebelo de Sousa Q: Who was Aslan created by? A: C. S. Lewis Q: Which city was C. S. Lewis born in? A: Belfast Q: Which city was Hari Kunzru born in? A: London Q: Which continent is London located in? A: Europe Q: Who was Nick Bottom created by? A: William Shakespeare Q: What kind of work does William Shakespeare do? A: playwright Q: Who is the head coach of Iran national football team? A: Carlos Queiroz Q: Which sport is Carlos Queiroz associated with? A: association football Q:{Single-hop questions...} G.3 DATASET ANNOTATION PROMPT The following is prompt template for requesting GPT-4o to semantically classify questions in the MQuAKE dataset, as described in Appendix B.2. This template ensures consistency and automation of data annotation by providing strict format requirements. 19 Preprint. Please analyze the type of the following question and return two categories strictly in the following format, separated by : [Main category][Subcategory] Question: {question} Category:"
        }
    ],
    "affiliations": [
        "HKUST",
        "HKUST(GZ)",
        "HKUST(GZ) Deep Interdisciplinary Intelligence Lab",
        "Institute of Deep Perception Technology, JITRI"
    ]
}