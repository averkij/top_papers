{
    "paper_title": "SIMSPINE: A Biomechanics-Aware Simulation Framework for 3D Spine Motion Annotation and Benchmarking",
    "authors": [
        "Muhammad Saif Ullah Khan",
        "Didier Stricker"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Modeling spinal motion is fundamental to understanding human biomechanics, yet remains underexplored in computer vision due to the spine's complex multi-joint kinematics and the lack of large-scale 3D annotations. We present a biomechanics-aware keypoint simulation framework that augments existing human pose datasets with anatomically consistent 3D spinal keypoints derived from musculoskeletal modeling. Using this framework, we create the first open dataset, named SIMSPINE, which provides sparse vertebra-level 3D spinal annotations for natural full-body motions in indoor multi-camera capture without external restraints. With 2.14 million frames, this enables data-driven learning of vertebral kinematics from subtle posture variations and bridges the gap between musculoskeletal simulation and computer vision. In addition, we release pretrained baselines covering fine-tuned 2D detectors, monocular 3D pose lifting models, and multi-view reconstruction pipelines, establishing a unified benchmark for biomechanically valid spine motion estimation. Specifically, our 2D spine baselines improve the state-of-the-art from 0.63 to 0.80 AUC in controlled environments, and from 0.91 to 0.93 AP for in-the-wild spine tracking. Together, the simulation framework and SIMSPINE dataset advance research in vision-based biomechanics, motion analysis, and digital human modeling by enabling reproducible, anatomically grounded 3D spine estimation under natural conditions."
        },
        {
            "title": "Start",
            "content": "SIMSPINE: Biomechanics-Aware Simulation Framework for 3D Spine Motion Annotation and Benchmarking Muhammad Saif Ullah Khan Didier Stricker German Research Center for Artificial Intelligence (DFKI) https://saifkhichi96.github.io/research/simspine/ 6 2 0 2 4 2 ] . [ 1 2 9 7 0 2 . 2 0 6 2 : r Modeling spinal motion is fundamental to understanding human biomechanics, yet remains underexplored in computer vision due to the spines complex multi-joint kinematics and the lack of large-scale 3D annotations. We present biomechanics-aware keypoint simulation framework that augments existing human pose datasets with anatomically consistent 3D spinal keypoints derived from musculoskeletal modeling. Using this framework, we create the first open dataset, named SIMSPINE, which provides sparse vertebralevel 3D spinal annotations for natural full-body motions in indoor multi-camera capture without external restraints. With 2.14 million frames, this enables data-driven learning of vertebral kinematics from subtle posture variations and bridges the gap between musculoskeletal simulation and computer vision. In addition, we release pretrained baselines covering fine-tuned 2D detectors, monocular 3D pose lifting models, and multi-view reconstruction pipelines, establishing unified benchmark for biomechanically valid spine motion estimation. Specifically, our 2D spine baselines improve the state-of-the-art from 0.63 to 0.80 AUC in controlled environments, and from 0.91 to 0.93 AP for in-the-wild spine tracking. Together, the simulation framework and SIMSPINE dataset advance research in visionbased biomechanics, motion analysis, and digital human modeling by enabling reproducible, anatomically grounded 3D spine estimation under natural conditions. 1. Introduction The vertebral column, together with the pelvic girdle, forms the biomechanical core of the human skeletonbearing axial loads, enabling locomotion, and protecting the spinal cord. Comprised of over two dozen articulating vertebrae and intervertebral joints, each with multiple degrees of freedom, the spine exhibits highly nonlinear, interdependent motion patterns [71]. Despite decades of work across anatomy, biomechanics, neuromechanics, and rehabilitation science, precise intervertebral kinematics remain debated [18, 30, 51], with poor agreement on ranges of motion across in vivo studies [34, 61, 73], cadaveric experiFigure 1. SIMSPINE annotations. Neutral pose of the simulated spine model (left), divided into three anatomical regionscervical (pink), thoracic (blue), and lumbar (green)with 15 annotated landmarks: 9 along the vertebral column, 2 on the skull, 2 at the clavicle joints, and 2 on the shoulder blades (last 4 not shown). Cervical and thoracic motion is limited to transition junctions (indicated by anatomical axis markers), while intermediate vertebrae remain rigidly coupled. The lumbar segment (L1L5) is fully articulated, with intervertebral rotations simulated for all degrees of freedom (bottom right). Overall spinal curvature is characterized by thoracic kyphosis (θk) and lumbar lordosis (θl) angles. Motion was generated using Beaucage-Gauvreau et al.s musculoskeletal model [5] as function of full-body movement in Human3.6M, with 5 training and 2 validation subjects performing 15 actions. ments [52, 65], and computational models. Among these, in vivo imaging (fluoroscopy, MRI, X-ray) and motion capture are most relevant for vision-based human motion research. Traditional motion capture excels at tracking large-scale limb motion for applications such as action recognition and 1 humancomputer interaction, but it misses subtle movementsvertebral rotations, postural sway, compensatory pelvic tiltsthat influence spinal stability, load distribution, and injury risk. This limits use in sports injury prevention, ergonomics, rehabilitation, and clinical contexts. Recent RGB approaches include marker-assisted tracking with perforated kinesiology tape [19] and real-world dataset/model for 2D spinal keypoint tracking [31]. The former is difficult to deploy outside controlled settings; the latter, while scalable, remains 2D with opaque annotations and limited biomechanical verification. Thus, achieving biomechanically accurate, clinically relevant, and unconstrained 3D estimation of healthy and pathological spine motion remains open, where unconstrained means not restricted to stationary subjects, close-up unclothed views, or fixed camera angles. Following [31], we argue that the first step towards solving this problem is to curate comprehensive 3D spine motion dataset that can serve both as baseline and stepping stone towards finding robust solution. In this work, we use biomechanics-aware keypoint simulation to annotate an existing large-scale 3D pose dataset [27] with vertebra-level keypoints, enabling learning of spinal micro-movements from subtle whole-body posture shifts. We release: (1) SIMSPINE, comprehensive dataset containing anatomically valid 3D spinal annotations for unconstrained motions, (2) simulation pipeline for generating biomechanically consistent spinal motion using musculoskeletal models, and (3) set of pretrained baselines including fine-tuned 2D and 3D pose estimation models. Together, these resources provide the first open benchmark for vision-based spinal motion analysis. Scope and limitations. Annotations are simulation-derived rather than measured in vivo. The cervical and thoracic regions are modeled as rigid segments with motion permitted only at transition junctions  (Fig. 1)  ; the lumbar spine (L1L5) is fully articulated. Motions are sourced from Human3.6M indoor activities, so appearance diversity and clinical pathologies are out of scope, and the resource is intended for researchnot diagnosticuse. The biomechanically constrained 3D spine motion also supports improved realism in downstream animation and avatar synthesis tasks. Contributions: Biomechanics-aware simulation framework that generates anatomically valid 3D spine motion data, augmenting existing human pose datasets with precise spinal labels. Pretrained spine motion baselines, including 6 fine-tuned 2D detectors for in-the-wild full-body pose estimation with state-of-the-art spine tracking, 2 monocular 3D baselines for root-relative 3D, and one multi-view 3D method for high-precision 3D in absolute metric coordinate space. Public release of the full simulation pipeline, pretrained models, and datasetthe first open 3D resource for spine motion estimationsupporting reliability, reproducibility, and benchmarking in spine-aware pose estimation. 2. Related Work The Human Spine. The human spine  (Fig. 1)  consists of 33 vertebrae forming an S-shaped curve in the sagittal plane and appearing straight coronally in neutral posture [18]. Of these, 24 are mobile (7 cervical, 12 thoracic, 5 lumbar). Each functional motion segment permits three rotations (flexion/extension, lateral bending, axial rotation) with small, constrained translations [51]. Reported ranges of motion (ROM) vary widely across cadaveric, in vivo, and computational studies [18, 52, 65], highlighting the lack of single ground-truth kinematic profile. Cervical (neck). Most mobile region: C0C1 mainly flexionextension, C1C2 primarily axial rotation, and C3C7 distributed coupled motion [41, 51]. Dual-fluoroscopy with model-based tracking (MBT) measures sub-degree motions but reveals taskand level-specific coupling [3, 39, 43]. Thoracic (upper back). Constrained by the rib cage and coronal facets, it allows moderate lateral bending and greater axial rotation in upper levels, decreasing toward the thoracolumbar junction [18, 38]. Upright biplanar radiography shows posture-dependent coupling not visible in supine imaging [15, 26]. Lumbar (lower back). Large flexion/extension but limited axial rotation due to sagittal facet orientation and tall discs; rotation and lateral bending generally decrease caudally [18, 51]. Imaging studies report small per-segment rotations and load-dependent coupling [39, 49]. Clinical Spine Tracking. Clinical assessment of static shape and function relies on radiographs using metrics such as Cobbs angle and regional curvature [11]. Low-dose EOS enables upright 3D reconstructions from simultaneous AP/lateral views with improved reproducibility [15, 17, 26, 48]. CT/MRI segmentation supports vertebra-level analysis and planning but typically in static postures [8, 37, 64]. For dynamic motion, time-varying vertebral motion is measured with biplane fluoroscopy plus MBT, achieving sub-millimeter accuracy when validated against RSA [25, 29, 39]. Dynamic MRI offers non-ionizing alternatives for posture-dependent deformation, but frame rate and artifacts limit kinematic fidelity [35, 43, 49]. Indirect RGB-based gait biomarkers for scoliosis screening [22, 32, 57, 77] scale to large cohorts but lack vertebra-level precision. Medical Imaging-Based Spine Analysis. Radiographs remain standard for global alignment and deformity metrics [11]. EOS extends these to upright 3D reconstructions [15, 26]. CT provides detailed bone morphology with strong performance on segmentation benchmarks [8, 37, 64]. MRI captures soft-tissue and some dynamic changes but with lower geometric fidelity for bone [35, 49]. Dual-fluoroscopy with MBT yields the most accurate in Table 1. Comparison of existing spine datasets. Summary of public datasets relevant to spinal imaging, scoliosis analysis, and motion estimation. Our proposed dataset uniquely provides vertebra-level 3D kinematics from RGB videos, bridging clinical imaging, biomechanics, and computer vision domains. Availability: Public, On request, Private. Dataset Year Input(s) Label(s) Kim et al. [33] Horng et al. [24] 2019 Radiographs Lumbar spine positions (sagittal, 2D) 2019 Radiographs Vertebral segmentation masks (coronal, 2D) # Samples 797 images 595 images VinDr-SpineXR [58] VerSe [64] 2021 Radiographs ROI boxes for 13 abnormalities 10k images / 5k cases Vertebra centroid / segmenta2021 CT Scans tion masks (sagittal, 2D) 374 scans / 355 patients Tasks Annotation Notes Avail. Lumbar vertebrae segmentation Vertebral segmentation 2 expert (radiologists) Multi-expert (clinical) Lesion detection Vertebral segmentation Expert annotations Hybrid (voxel) Scoliosis1K [77] USTC&SYSUScoliosis [79] SpineTrack [31] SIMSPINE (Ours) 2024 Silhouette Images 2025 Radiographs, RGB Demographics, Scoliosis Diagnosis, 2D Body Pose Regional Cobbs angles 1.5k videos (447k frames) from 1k walking subjects 1898 images / 1067 patients aged 10-18 Scoliosis detection Scoliosis detection 2025 Images (RGB) 2025 Videos (RGB) (various 9 spine keypoints viewpoints, 2D) 3D spine position, vertebral rotations 33k images Keypoint Estimation 1.56M train, 0.58M test images / 7 people, 15 actions Keypoint Estimation, Rotation Regression Evaluation by medical professionals Multi-expert agreement 2D, Hybrid, non-expert, outdoor, inconsistent Real+sim, biomech. plausible, indoor vivo kinematics, though costly and dose-intensive; synthetic CT approaches seek to mitigate this [36, 39]. RGB-Based Spine Motion Tracking. RGB systems use marker-assisted tracking for structured back motion capture [19], but require exposed skin and controlled views. Markerless models estimate 2D spinal keypoints in natural scenes [31], facing projection ambiguity and limited biomechanical validity. No RGB-only method yet reconstructs biomechanically consistent 3D vertebral motion under unconstrained conditions, motivating simulation-driven supervision with kinematic priors. To provide further context, Tab. 1 compares key spine datasets across imaging, clinical, and vision domains. Our dataset uniquely combines real RGB sequences with anatomically constrained 3D motion. OpenSim Simulation. OpenSim [12] is standard platform for musculoskeletal modeling, inverse kinematics/dynamics, and forward simulation. Widely used baselines [59] and SimTK repositories provide spine-focused models such as: full-body and lumbar-detailed variants [5, 10], thoracolumbar and rib-cage models with articulated T1L5 [6], personalizable and pediatric spines [2, 63], and cervical/neck and impact-oriented models [7, 50]. Toolchains like Pose2Sim [53] connect RGB-derived trajectories with OpenSim for simulation-ready kinematics. AddBiomechanics [70] provides datasets and tool to automatically add kinematics and dynamics to joint trajectories. These provide components which our framework links with vision for large-scale image annotation. 3D Pose Estimation. 2D-to-3D lifting predicts absolute or root-relative 3D coordinates from monocular keypoints, most often trained on Human3.6M [27]. Foundational models range from simple MLP baselines [46] to temporal convolutional networks with semi-supervision [54]. Recent transformer-based approaches integrate motion priors for spatialtemporal consistency, such as MotionBERT [78], MotionAGFormer [47], EvoPose with structure priors [76], and PriorFormer for real-time geometric lifting [1]. While these achieve scalable full-body reconstruction, they overlook anatomical validity and intervertebral coherence. 3. Methodology Biomechanics-aware keypoint simulation, illustrated in Fig. 2, augments Human3.6M with sparse 3D positions of vertebral bodies, per-vertebra rotational kinematics, and subject-scaled biomechanical models. We follow the standard Human3.6M splits (train: S1, S5, S6, S7, S8; test: S9, S11), preserving Human3.6M time stamps. 3.1. Biomechanics-aware keypoint simulation (1) Multi-view spinal detection and triangulation. For each synchronized frame and view v, pretrained detector [31] predicts 2D spinal keypoints ˆuv,t R2Ks (with Ks = 9). Using calibrated intrinsics/extrinsics {Kv, Rv, tv} from Human3.6M, we recover pseudo-3D points Xt R3Ks by robust triangulation: Xt = arg min (cid:88) vV (cid:16)(cid:13) (cid:13)Π(Kv[Rvtv]X) ˆuv,t ρ (cid:17) , (cid:13) 2 (cid:13) 2 where Π() denotes perspective projection and ρ is robust penalty (Huber). We prune outliers by view-consistency and reprojection-error thresholds, and apply zero-phase low-pass filtering to suppress frame-to-frame jitter. (2) Merging with ground-truth body markers. Let Yt R3Kh be the Human3.6M 3D markers1 (Kh joints) in the camera/world frame. We align the pseudo-3D spinal set Xt and Yt into common OpenSim marker set by (i) 1Pelvis, Spine, Neck, HeadTop, and Nose from Human3.6M are not used because of overlap with our spinal points and, for the latter two points, inconsistent labels [42]. Figure 2. Biomechanics-aware keypoint simulation pipeline. From synchronized multi-view RGB, 2D detector [31] predicts spinal landmarks that are robustly triangulated using calibrated cameras to obtain pseudo-3D spinal keypoints. These pseudo labels are temporally aligned and merged with known Human3.6M [27] 3D markers (GT 3D Pose). OpenSim inverse kinematics (IK) [12] fits subject-scaled full-body model [5, 53, 59] to the merged trajectories. We attach virtual markers to vertebral bodies and, using the IK joint angles and subject-specific anthropometrics, generate anatomically consistent spine keypoints via forward kinematics (FK). The pipeline also outputs biomechanical parameters (e.g., per-vertebra rotations). selecting semantic correspondences, (ii) temporal synchronization at Human3.6M frame times, and (iii) filling missing views by short-horizon interpolation. The merged markers Zt = {Yt, Xt} R3K serve as IK targets. (3) Subject scaling and inverse kinematics. We adopt full-body OpenSim model based on Rajagopal et al. [59] with lumbar spine details adapted from Beaucage-Gauvreau et al. [5]; we use Pose2Sim [53] for data I/O and utilities. Scaling uses subject height/mass estimates derived from TRC anthropometrics (with conservative outlier trimming). IK solves, per time t, the weighted least-squares problem = arg min qt (cid:88) mM wm zm,t ˆzm(qt)2 2 + λDq2 2, where ˆzm(qt) are model marker positions from FK of joint state qt, wm are per-marker confidences (higher for Human3.6M markers, lower for pseudo spinal points), and penalizes joint-velocity/acceleration for temporal smoothness. The model includes fully articulated lumbar spine with three rotational DOFs at intervertebral joints from T12L1 through L5S1; single 3-DOF joint at the cervicothoracic junction provides an aggregate neck DOF. Thoracic and cervical bodies beyond this aggregate are treated as rigid segments with neutral baseline curvature. This choice approximates thoracic rib-cage constraints while keeping the model identifiable with RGB-derived inputs. (4) Virtual vertebral markers and forward kinematics. We attach virtual markers to vertebral bodies (centroidal locations) and compute their 3D trajectories from the IK solution {q } via FK. These markers define the 3D spinal keypoints distributed along the column (sacral base to lower cervical). In parallel, we export per-vertebra Euler rotations about anatomical axes (flexion/extension, lateral bending, axial rotation) as biomechanical parameters. (5) Quality control and curation. We (i) reject frames with implausible curvature, (ii) clamp rare angle discontinuities from gimbal wrap, and (iii) apply temporal smoothing and interpolation to fill small gaps and ensure motion continuity. Subject-specific scaled OpenSim models, marker positions, and joint angles, time synchronized with RGB frames from Human3.6M, are generated. Markers: 37 total, with 12 limb points from Human3.6M, 15 high-precision new points that directly model the spine, and 10 pseudo-labels on feet and face. Kinematic axes: 62, including 56 Euler angles. Further details are in Supplementary Sec. B. 3.2. Biomechanical validity of simulated data We use statistical analysis to understand the simulated spine kinematics, and compare with biomechanics literature to determine the datasets suitability for downstream tasks. Thoracolumbar spine curvature. The violin plots in Fig. 3 (left) show distributions of the Lumbar Lordotic Angle (LLA) and Thoracic Kyphotic Angle (TKA), computed using Cobbs method [11] between L1S1 and T3T12 endplates, respectively. Outliers were conservatively removed. The observed distributions align with in vivo studies and reveal activity-specific trends: seated motions (e.g., Sitting, SittingDown) exhibit reduced lumbar lordosis compared to standing actions (e.g., Walking, Greeting) due to gravitational effects on intervertebral spacing [4, 9, 66, 69], while actions involving arm elevation (e.g., Photo, Posing, Greeting) show reduced thoracic kyphosis from posterior shoulder displacement [60]. Across all actions, mean lordosis (3339) and kyphosis (2937) fall within normative adult Figure 3. Thoracolumbar spine in SIMSPINE. Left: Distributions of thoracolumbar curvature across actions, defined by the Lumbar Lordotic Angle (LLA, θl) in the lower back and Thoracic Kyphotic Angle (TKA, θk) in the upper back. LLA and TKA average within 1 SD at 3339 and 2937, respectively, indicating greater curvature in the lower spine but higher variability in the upper. Values fall within reported biomechanical ranges [16, 40], confirming that SIMSPINE produces anatomically plausible curvatures and captures expected action-specific postural trends [4, 9, 60, 66, 69]. Right: Per-vertebra range of motion (ROM) on y-axis for the three lumbar rotational DOFs. Our simulated data (solid) follows similar trends as reported by White and Panjabi (1978) [72] (dashed). These monotone or near-monotone trends match widely reported patterns [72] for upright motion and are difficult to reproduce with unconstrained pose-only priors; their presence suggests the IK solution respects both morphology and motion constraints. Simulated values follow similar trends as the reference data. It should be noted that exact ROM values for lumbar vertebrae are debated [62]. Cervical proxy. Despite modeling the cervical spine as single aggregate 3-DOF joint, action-conditioned neck ROM distributions in Fig. 4 stay within physiologically credible envelopes and broaden for tasks with head motion. For example, the Phone action has the largest lateral bending range indicative of sideways head tilt typical during phone conversations. This supports usefulness for coarse headneck kinematics and for supervising 2D-to-3D lifting in the absence of vertebra-resolved cervical detail. These graphs jointly indicate that our simulation yields anatomically plausible and action-sensitive kinematics. This supports the datasets suitability as supervision for learning vertebral motion from natural movements and as benchmark for biomechanics-aware spine motion models. 4. Baselines and Experiments Figure 4. Cervical spine in SIMSPINE. The distributions (per action) remain centered near neutral with task-dependent spread, reflecting that our model uses single 3-DOF aggregate neck joint while keeping the thoracic/cervical bodies rigid beyond the cervicothoracic junction. This is within the neck ROM reported in [14] with approximately half coverage, which indicates the presence of only small head movements in the dataset. ranges [16, 40]. These bounded, unimodal, and actionsensitive distributions reflect realistic postural variability in healthy adults, underscoring the biomechanical fidelity of the simulated data. Details of subject and action-specific ranges is provided in Supplementary Tab. B2. Lumbar spine ROM trends. The lumbar ROM curves in Fig. 3, (right) display known qualitative gradients: flexion/extension increases from the thoracolumbar junction toward the caudal levels with peak near L4L5, then reduces at L5S1; lateral bending peaks mid-lumbar; axial rotation is modest overall and highest in mid-lumbar segments. We benchmark three tasks enabled by SIMSPINE: (1) 2D pose estimation from RGB, (2) multiview 3D pose reconstruction, and (3) monocular 3D pose lifting. We formally define each task, describe the baselines, training methods, evaluation protocols, and present ablation studies. The aim is to provide deployment-ready, robust pretrained models, and quantitative results which future spine research can use as reference. Known limitations are also discussed. Notation. Let be batch size, frames per clip (T =1 for image-based; >1 for video-based), vertebral keypoints, and Cimg=3 image channels. For each sequence, RBT CimgHW are RGB frame(s), RBT K2 are 2D keypoints, and RBT K3 are 3D coordinates in global camera or anatomical frame. 4.1. 2D Pose Estimation Definition. This task aims to learn function f2D : RBT CimgHW RBT K2, predicting (cid:98)U from images with supervision and visibility weights [0, 1]BT K. Baselines. We fine-tune three variants of SpinePose [31] and compare them with representative architectures from both CNN and transformer families: HRNet-w32 [67], RTMPose-m [28], and ViTPose-b [74]. HRNet and ViTPose are heatmap-based methods while RTMPose is coordinate classification method. Training. All models are initialized with pretrained weights and fine-tuned on balanced combination of outdoor (SpineTrack) and indoor (SIMSPINE) images, with equal samples per batch. Only 2% of SIMSPINE train split are used to avoid overfitting while still transferring simulationderived knowledge. Each model is fine-tuned for 10 epochs with three-stage curriculum where data augmentation transitions from hard to easy (see Supplementary Sec. A). Optimizers and losses follow SpinePose [31]. Table 2. Baselines for 2D Spine Pose Estimation. Performance of various CNN and transformer architectures on the SpineTrack and SIMSPINE benchmarks."
        },
        {
            "title": "Finetune APB ARB APS ARS AUC",
            "content": "SpinePose-s SpinePose-m SpinePose-l SpinePose-s-ft SpinePose-m-ft SpinePose-l-ft HRNet-w32 RTMPose-m ViTPose-b"
        },
        {
            "title": "SpineTrack",
            "content": "-"
        },
        {
            "title": "SpineTrack",
            "content": "SpineTrack + Ours"
        },
        {
            "title": "COCO",
            "content": "SpineTrack + Ours 0.792 0.840 0.854 0.788 0.821 0.840 0.776 0.832 0.835 0.821 0.864 0.877 0.815 0.846 0. 0.806 0.858 0.866 0.896 0.914 0.910 0.920 0.928 0.917 0.905 0.925 0.921 0.908 0.611 0.926 0.633 0.922 0.633 0.929 0.790 0.937 0.798 0.927 0. 0.918 0.769 0.935 0.794 0.933 0.794 Evaluation. On SpineTrack we report AP/AR using COCO-style OKS with body (B) and spine (S) subsets following [31]. On SIMSPINE we report AUC of PCK over thresholds τ [0, 0.5], with distances normalized by the shorter side of the person bounding box. Higher is better for all metrics. Comparisons with the original SpinePose [31] quantify the effect of consistent labeling in SIMSPINE. 4.2. Multiview 3D Reconstruction Definition. Given synchronized detections { (cid:98)U(m)}M and calibrated projections {P (m)}M m=1, triangulate m= (cid:98)Y = ftri({ (cid:98)U(m), (m)}M m=1), by minimizing multi-view reprojection error. Baselines. We use weighted linear least-squares triangulation with confidence-based outlier rejection [20, 21]. Two 2D detectors are compared: the zero-shot SpinePosem pretrained on SpineTrack [31], and its fine-tuned variant SpinePose-m-ft adapted on SIMSPINE. Table 3. Multiview 3D Spine Reconstruction. MPJPE (mm) across actions and spinal regions using linear triangulation. SC : Cervical, ST : Thoracic, SL: Lumbar, S: Full spine, B: Body, and All: Complete skeleton."
        },
        {
            "title": "Action",
            "content": "Mean (GT 2D) Directions Discussion Eating Greeting Phoning Photo Posing Purchases Sitting SittingDown Smoking Waiting WalkDog WalkTogether Walking Mean (Finetuned) Mean (Zero-Shot) SC 12.36 33.69 36.35 38.47 30.66 42.41 36.40 33.48 34.81 40.94 34.85 38.51 35.17 35.53 34.05 33. 36.50 54.39 ST 8.80 39.86 40.55 43.04 35.19 44.64 42.13 37.46 35.67 43.16 35.95 44.83 37.40 41.44 43.88 43.80 41.07 69.90 SL 5.09 40.16 41.44 35.40 33.73 39.14 42.27 40.14 39.63 31.21 23.63 35.66 33.22 40.83 40.40 41.53 37.13 48.13 9.00 37.88 39.39 39.48 33.29 42.43 40.25 36.85 36.44 39.23 32.30 40.28 35.54 39.31 39.68 39. 38.50 58.92 7.07 27.63 28.33 27.44 25.57 27.23 30.35 28.02 26.64 25.42 23.31 27.26 24.78 29.49 29.28 29.06 27.27 42.74 All 7.85 31.79 32.81 32.32 28.70 33.40 34.37 31.60 30.61 31.02 26.95 32.54 29.14 33.47 33.50 33.33 31.82 49.30 Evaluation. For triangulated poses in global world coordinates, we report Mean Per-Joint Position Error (MPJPE): MPJPE ="
        },
        {
            "title": "1\nBT K",
            "content": "(cid:88) b,t,j (cid:13) (cid:13)Ypred b,t,j,: Yb,t,j,: (cid:13) (cid:13)2. Results are summarized in Tab. 3. To further isolate geometric shape from global alignment, Tab. 4 reports Procrustes-aligned MPJPE (P-MPJPE). Table 4. Triangulation Baseline: P-MPJPE (mm). Same setup as Table 3, evaluated after similarity alignment. Action Mean (GT 2D) Mean (Finetuned) Mean (Zero-Shot) SC 0. 19.68 26.88 ST 0.43 20.67 23.40 SL 0. 12.21 9.92 0.67 26.67 39.01 1. 24.21 42."
        },
        {
            "title": "All",
            "content": "1.79 29.53 46.48 Sub-millimeter values when using GT 2D confirm geometric consistency within floating-point precision. However, detector-based reconstructions remain in the 2040 mm range because alignment corrects translation and rotation but not inter-view noise. Table 5. Simple Baselines for Monocular 3D Spine Pose Lifting. Evaluation of Martinez et al.s lifting model trained on spine-only (15 joints) and full-body (37 joints) keypoint sets. Reported metric: Procrustes-aligned MPJPE (P-MPJPE, mm) per action. Training on full-body joints improves spine localization accuracy. Evaluation is on 15 spine joints only. Train Set 2D Direct Discuss Eating Greet Phone Photo Pose Purchase Sit SitD Smoke Wait WalkD WalkT Walk Avg Spine Only Det. Det. Full-Body Spine Only GT GT Full-Body 16.58 15.55 15.66 11.56 17.92 16.40 17.01 13. 17.79 14.45 16.05 11.36 18.32 15.98 17.43 13.61 21.81 19.84 20.64 18. 19.74 17.66 18.34 14.61 15.69 14.25 14.87 10.60 17.70 15.68 16.40 12. 19.28 15.97 17.91 13.64 22.32 19.23 22.10 17.36 18.43 16.38 16.92 13. 18.82 17.17 17.78 14.47 18.91 17.41 17.96 14.51 16.24 12.24 15.39 9. 15.96 12.12 15.28 9.98 18.58 16.28 17.52 13.48 Table 6. Monocular 3D Spine Pose Lifting (Component-Wise). Same experimental setup as Table 5, but results are aggregated across actions and broken down by spine components. Columns report P-MPJPE (mm) for SC (cervical), ST (thoracic), SL (lumbar), and (full spine). Rows compare training on spine-only (15 joints) vs. full-body (37 joints); 2D inputs are either detected (Det.) or ground truth (GT). P-MPJPE MPJPE Train Set 2D SC ST Spine Only Det. Det. Full-Body 12.98 14.29 12.81 10.12 Spine Only GT GT Full-Body 12.03 13.45 7.98 10.94 SL 3.32 3.51 3.32 2. SC ST SL 18.58 96.88 75.96 18.83 67.70 16.28 100.50 72.61 18.16 67. 17.52 77.93 58.70 15.54 53.60 25.94 13.48 39.24 26.97 7."
        },
        {
            "title": "This experiment quantifies the geometric upper bound",
            "content": "achievable conditioned on 2D detection accuracy alone. 4.3. Monocular 3D Lifting Definition. Learn flift : RBT K2 RBT (K1)3, mapping 2D keypoints to root-centered 3D. Let For frame t, be the root (cid:80) yb,t= 1 rR Yb,t,r,: and (cid:101)Yb,t,j,:=Yb,t,j,:yb,t; the netR index set (here R={0}). work minimizes (cid:98)(cid:101)Y (cid:101)Y2 2. Baselines. We adopt SimpleBaseline3D [46] as the reference architecture due to its simplicity and interpretability. It encodes per-joint features through linear layers with residual connections, operating on either spine-only or full-body keypoints. Training. 3D targets are root-centered and standardized per joint. The root joint is excluded during training and reinserted at inference. Frames are sampled at 1 Hz to preserve motion diversity while maintaining manageable sequence length. Optimization uses AdamW [44] with step scheduling. As in [46], standard MSE loss is used for training. Evaluation. We report root-relative Mean Per-Joint Position Error (MPJPE) and Procrustes-aligned MPJPE (PMPJPE) on decoded 3D predictions. For P-MPJPE, each predicted frame is first aligned to the ground truth using the Procrustes similarity alignment (s, R, t). All metrics are reported in millimeters. Tab. 5 summarizes the P-MPJPE of spine keypoints across all dataset actions, and Tab. 6 compares both P-MPJPE and root-relative MPJPE with further breakdown of three key spinal regions. Exact keypoints evaluated in each region are listed in Supplementary Sec. B. 4.4. Ablation Studies We report here controlled studies isolating the effect of data mixing, sampling, and training choices. n o P 0.8 0.7 0.6 Indoor Outdoor PB PE 2 4 6"
        },
        {
            "title": "SIMSPINE Fraction",
            "content": "Figure 5. Ablation Study: Mixup Composition. We examine how the fraction of SIMSPINE used in training influences indoor (AUC) and outdoor (AP) performance. Increasing the SIMSPINE fraction improves indoor performance up to 10%, while outdoor gains saturate by 25%. Per-batch (PB) mixup maintains the best balance between indoor and outdoor metrics, whereas per-epoch (PE) alternation favors one domain at the expense of the other. Sampling only 2% of SIMSPINE achieves near-saturated results on both datasets, indicating diminishing returns from larger fractions. Mixup Composition and Dataset Fraction. Figure 5 analyzes how the fraction of SIMSPINE contributes to 2D finetuning performance under different data mixing strategies. This ablation is motivated by the need for stable and accurate 2D keypoint detectors, which form the foundation for reliable 3D triangulation and lifting. Existing off-the-shelf 2D detectors trained on manually annotated spine datasets often exhibit label noise and jitter due to inconsistent supervision, making it essential to study how synthetic and real data can be best combined. Increasing the proportion of SIMSPINE from 0% to 10% steadily improves indoor AUC (from 0.61 to 0.79), with minimal degradation on outdoor AP. Beyond 25%, however, outdoor AP plateaus around 0.84, suggesting that only small subset of high-quality indoor samples is sufficient to enhance generalization. Comparing mixing strategies, per-batch (PB) mixup consistently outperforms per-epoch (PE) alternation, yielding the most stable trade-off across domains. PB works better because the model and optimizer jointly observe samples from both datasets in each iteration, allowing AdamW to maintain smoother gradient statistics and consistent momentum estimates across domains. These results justify using 2% of SIMSPINE about 31k indoor images, roughly matching the 33k outdoor samples in SpineTrackwith per-batch mixing as the default configuration, achieving balanced exposure across domains and efficient use of synthetic data while preserving real-world performance. 4.5. Discussion Across our three experiments2D detection, multiview triangulation, and monocular liftingwe establish referIn 2D, ence baselines for spine-aware pose estimation. fine-tuning across SpineTrack and SIMSPINE consistently improves spine metrics (indoor AUC from 0.61 to 0.80; SpineTrack APS from 0.91 to 0.93), with small trade-off on body APB relative to the strongest SpinePose pretrained model. The multiview triangulation baseline attains 31.8 mm MPJPE and 29.5 mm P-MPJPE, and our oracle using GT 2D reaches sub-millimeter P-MPJPE, conFor monocular lifting, firming geometric consistency. the full-body variant outperforms the spine-only variant (detected 2D: 18.6 mm 16.3 mm P-MPJPE; GT 2D: 17.5 mm 13.5 mm), indicating that global context aids vertebral localization. Together, these results provide practical baseline suite that links strong 2D cues to geometrically faithful 3D reconstructions and highlights where temporal or biomechanical priors add the most value. Limitations. Our simulation framework is kinematicsonly, simulation-derived resource and carries several limitations. Anatomically, we articulate five intervertebral lumbar joints and single 3-DOF cervicothoracic joint, while treating the remaining thoracic and cervical segments as rigid. This choice, made for numerical stability and identifiability from RGB inputs, neglects rib-cage coupling and soft-tissue effects that materially constrain and distribute Intervertebral translations are not thoracic motion [38]. modeled; although small in healthy spines, nonzero translations have been measured in vivo with stereoradiography [55, 56]. Pelvislumbar coupling is also simplified, which can underrepresent lumbopelvic rhythm during trunk motion [68]. Subjects are implicitly healthy and scaled by height/mass; age-, sex-, and pathology-dependent variation in sagittal alignment is not modeled, so the dataset encodes nominal healthy-motion priors rather than the diversity seen clinically [45, 75]. Because all motions are sourced from Human3.6M, the visual domain is limited to indoor captures with fixed multi-view cameras and restricted action set [27]. This may limit generalization to fully unconstrained, in-the-wild scenarios. Our OpenSim step solves inverse kinematics only; muscle actuation, ground-reaction forces, and load equilibria are not enforced, so trajectories are geometrically plausible but not physically validated [23]. Extending to dynamics-consistent optimal control would allow force-consistent motion generation [13]. Our empirical validation (Sec. 3.2) target geometric plausibility (curvature envelopes, ROM profiles) rather than absolute accuracy against in vivo ground truth such as dual-fluoroscopy/biplane tracking or standing biplanar reconstructions, which provide the most precise in vivo vertebral kinematics and alignment [3, 48]. Accordingly, biomechanics-aware keypoint simulation framework should be regarded as scalable proxy for method development and benchmarking rather than clinical measurement, while SIMSPINE serves best as large-scale pretraining resource for spine pose estimation models later fine-tuned on smaller, biomechanically validated datasets. Future work. Angular annotations in SIMSPINE, not evaluated in this work because of additional design choices (representation, normalization, interpretation) orthogonal to this initial benchmark, should be benchmarked. In addition, we see three priorities: (i) expand anatomical fidelity by adding rib-cage articulation and small intervertebral translations, (ii) couple IK with dynamics (inverse dynamics or optimal control) to ensure force-consistent motion [13], and (iii) broaden the visual domain with in-the-wild sequences and pathology-specific cohorts. Longer term, combining upright clinical imaging (EOS/fluoroscopy) with RGB could anchor subject-specific spine priors and reduce ambiguity in vertebra-level motion. 5. Conclusion We introduced biomechanics-aware keypoint simulation, pipeline that fuses calibrated RGB, subject-scaled musculoskeletal models, and virtual vertebral markers to produce anatomically constrained 3D spine motion from standard multi-view footage. The resulting SIMSPINE provides 15 keypoints driving spine with per-segment rotations over 2.14M frames and set of pretrained baselines spanning 2D detection, multiview triangulation, and monocular lifting. The evidencenear-oracle P-MPJPE under GT 2D, consistent thoracolumbar curvature envelopes, and action-sensitive ROM profilesshows that simulation-driven annotation can extend existing datasets with biomechanically meaningful structure. While simplified and domain-limited, the framework offers practical bridge between computer vision and musculoskeletal modeling, enabling models that reason about posture and vertebral kinematics, not only joint geometry. Availability and licensing. Code, models, and SIMSPINE annotations for the spine markers and kinematic parameters will be released for research use only. Due to licensing, full-body keypoints are reproducible by running our pipeline on the licensed Human3.6M data."
        },
        {
            "title": "Acknowledgement",
            "content": "The work leading to this publication was co-funded by the European Unions Horizon Europe research and innovation programme under Grant Agreement No 101135724 (project LUMINOUS) and Grant Agreement No 101092889 (project SHARESPACE)."
        },
        {
            "title": "References",
            "content": "[1] Mohamed Adjel and Vincent Bonnet. Priorformer: transformer for real-time monocular 3d human pose esarXiv preprint timation with versatile geometric priors. arXiv:2508.18238, 2025. 3 [2] Dennis Anderson, Hossein Mokhtarzadeh, Brett Allaire, Katelyn Burkhart, and Bouxsein. Subject-specific spine models for 250 individuals from the framingham heart study. Harvard Dataverse. doi: doi/10.7910/DVN/SJ5MVM, 2020. 3 [3] William Anderst, Emma Baillargeon, William Donaldson III, Joon Lee, and James Kang. Validation of noninvasive technique to precisely measure in vivo threedimensional cervical spine movement. Spine, 36(6):E393 E400, 2011. 2, 8 [4] Jun Seok Bae, Jee-Soo Jang, Sang-Ho Lee, and Jin Uk Kim. comparison study on the change in lumbar lordosis when standing, sitting on chair, and sitting on the floor in normal individuals. Journal of Korean Neurosurgical Society, 51(1): 2023, 2012. 4, 5 [5] Erica Beaucage-Gauvreau, William SP Robertson, Scott CE Brandon, Robert Fraser, Brian JC Freeman, Ryan Graham, Dominic Thewlis, and Claire Jones. Validation of an opensim full-body model with detailed lumbar spine for estimating lower lumbar spine loads during symmetric and asymmetric lifting tasks. Computer methods in biomechanics and biomedical engineering, 22(5):451464, 2019. 1, 3, 4 [6] Alexander Bruno, Mary Bouxsein, and Dennis Anderson. Development and validation of musculoskeletal model of the fully articulated thoracolumbar spine and rib cage. Journal of biomechanical engineering, 137(8):081003, 2015. [7] Dario Cazzola, Timothy Holsgrove, Ezio Preatoni, Harinderjit Gill, and Grant Trewartha. Cervical spine injuries: whole-body musculoskeletal model for the analysis of spinal loading. PloS one, 12(1):e0169329, 2017. 3 [8] Pengfei Cheng, Yusheng Yang, Huiqiang Yu, and Yongyi He. Automatic vertebrae localization and segmentation in ct with two-stage dense-u-net. Scientific Reports, 11(1): 22156, 2021. 2 [9] Il Youp Cho, Si Young Park, Jong Hoon Park, Tae Kwon Kim, Tae Wan Jung, and Hyun Min Lee. The effect of standing and different sitting positions on lumbar lordosis: radiographic study of 30 healthy volunteers. Asian spine journal, 9(5):762, 2015. 4, 5 [10] Miguel Christophy, Nur Adila Faruk Senan, Jeffrey Lotz, and Oliver OReilly. musculoskeletal model for the lumbar spine. Biomechanics and modeling in mechanobiology, 11(1):1934, 2012. 3 [11] JR Cobb. Outline for the study of scoliosis."
        },
        {
            "title": "Instructional",
            "content": "course lecture, 1948. 2, 4 [12] Scott Delp, Frank Anderson, Allison Arnold, Peter Loan, Ayman Habib, Chand John, Eran Guendelman, and Darryl Thelen. Opensim: open-source software to creIEEE ate and analyze dynamic simulations of movement. transactions on biomedical engineering, 54(11):19401950, 2007. 3, 4 [13] Christopher Dembia, Nicholas Bianco, Antoine Falisse, Jennifer Hicks, and Scott Delp. Opensim moco: Musculoskeletal optimal control. PLOS Computational Biology, 16(12):e1008493, 2020. 8 [14] Arockia Selvakumar Arockia Doss, Pavan Kalyan Lingampally, Gia Minh Thao Nguyen, and Daniel Schilberg. comprehensive review of wearable assistive robotic devices used for head and neck rehabilitation. Results in Engineering, 19: 101306, 2023. 5 [15] Jean Dubousset, Georges Charpak, Irene Dorion, Wafa Skalli, Francois Lavaste, Jacques Deguise, Gabriel Kalifa, and Solene Ferey. new 2d and 3d imaging approach to musculoskeletal physiology and pathology with low-dose radiation and the standing position: the eos system. Bulletin de lAcademie nationale de medecine, 189(2):28797, 2005. 2 [16] Gerald Fon, Michael Pitt, and Cole Thies Jr. Thoracic kyphosis: range in normal subjects. American Journal of Roentgenology, 134(5):979983, 1980. 5 [17] Laurent Gajny, Shahin Ebrahimi, Claudio Vergari, Elsa Angelini, and Wafa Skalli. Quasi-automatic 3d reconstruction of the full spine from low-dose biplanar x-rays based on statistical inferences and image analysis. European Spine Journal, 28(4):658664, 2019. [18] Fabio Galbusera and Hans-Joachim Wilke. Biomechanics of the spine: Basic concepts, spinal disorders and treatments. Academic Press, 2018. 1, 2 [19] Hendrik Hachmann and Bodo Rosenhahn. Human spine motion capture using perforated kinesiology tape. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 51495157, 2023. 2, 3 [20] Richard Hartley. Multiple view geometry in computer vision. Cambridge university press, 2003. 6 [21] Richard Hartley and Peter Sturm. Triangulation. Computer vision and image understanding, 68(2):146157, 1997. 6 [22] Zhong He, Neng Lu, Yi Chen, Elvis Chun-Sing Chui, Zhen Liu, Xiaodong Qin, Jie Li, Shengru Wang, Junlin Yang, Zhiwei Wang, et al. Conditional generative adversarial networkassisted system for radiation-free evaluation of scoliosis using single smartphone photograph: model development and validation study. Eclinicalmedicine, 75, 2024. 2 [23] Jennifer Hicks, Thomas Uchida, Ajay Seth, Apoorva Rajagopal, and Scott Delp. Is my model good enough? best practices for verification and validation of musculoskeletal models and simulations of movement. Journal of biomechanical engineering, 137(2):020905, 2015. 8 [24] Ming-Huwi Horng, Chan-Pang Kuok, Min-Jun Fu, Chii-Jen Lin, and Yung-Nien Sun. Cobb angle measurement of spine from x-ray images using convolutional neural network. Computational and mathematical methods in medicine, 2019(1): 6357171, 2019. 3 [25] Ali Humadi, Sulaf Dawood, Klas Halldin, and Brian Freeman. Rsa in spine: review. Global Spine Journal, 7(8): 811820, 2017. [38] Christian Liebsch and Hans-Joachim Wilke. Basic biomechanics of the thoracic spine and rib cage. In Biomechanics of the Spine, pages 3550. Elsevier, 2018. 2, 8 [26] Ludovic Humbert, Jacques De Guise, Benjamin Aubert, Benoˆıt Godbout, and Wafa Skalli. 3d reconstruction of the spine from biplanar x-rays using parametric models based on transversal and longitudinal inferences. Medical engineering & physics, 31(6):681687, 2009. 2 [27] Catalin Ionescu, Dragos Papava, Vlad Olaru, and Cristian Sminchisescu. Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(7):13251339, 2014. 2, 3, 4, 8 [28] Tao Jiang, Peng Lu, Li Zhang, Ningsheng Ma, Rui Han, Chengqi Lyu, Yining Li, and Kai Chen. Rtmpose: Real-time multi-person pose estimation based on mmpose, 2023. 6 [29] Craig Kage, Mohsen Akbari-Shandiz, Mary Foltz, Rebekah Lawrence, Taycia Brandon, Nathaniel Helwig, and Arin Ellingson. Validation of an automated shape-matching algorithm for biplane radiographic spine osteokinematics and radiostereometric analysis error quantification. PLoS One, 15(2):e0228594, 2020. 2 [30] Ibrahim Kapandji. The physiology of the joints, volume i, upper limb. American Journal of Physical Medicine & Rehabilitation, 50(2):96, 1971. 1 [31] Muhammad Saif Ullah Khan, Stephan Krauß, and Didier Stricker. Towards unconstrained 2d pose estimation of the human spine. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 61716180, 2025. 2, 3, 4, [32] Dong Suk Kim, Shi Hwan Park, Tae Sik Goh, Seung Min Son, and Jung Sub Lee. meta-analysis of gait in adolescent idiopathic scoliosis. Journal of Clinical Neuroscience, 81: 196200, 2020. 2 [33] Kang Cheol Kim, Hyun Cheol Cho, Tae Jun Jang, Jong Mun Choi, and Jin Keun Seo. Automatic detection and segmentation of lumbar vertebrae from x-ray images for compression fracture evaluation. Computer Methods and Programs in Biomedicine, 200:105833, 2021. 3 [34] Michal Kozanek, Shaobai Wang, Peter Passias, Qun Xia, Gang Li, Christopher Bono, Kirkham Wood, and Guoan Li. Range of motion and orientation of the lumbar facet joints in vivo. Spine, 34(19):E689E696, 2009. 1 [35] Kornelia Kulig, Robert Landel, and Christopher Powers. Assessment of lumbar spine kinematics using dynamic mri: proposed mechanism of sagittal plane motion induced by manual posterior-to-anterior mobilization. Journal of Orthopaedic & Sports Physical Therapy, 34(2):5764, 2004. 2 [36] Seth Kussow, Jared Zitnay, Penny Atkins, and Andrew Anderson. Accuracy and reliability of synthetic computed tomography for model-based tracking of biplane videoradiography data: Sj kussow et al. Annals of Biomedical Engineering, pages 114, 2025. 3 [37] Nikolas Lessmann, Bram Van Ginneken, Pim De Jong, and Ivana Iˇsgum. Iterative fully convolutional neural networks for automatic vertebra segmentation and identification. Medical image analysis, 53:142155, 2019. 2 [39] Cheng-Chung Lin, Tung-Wu Lu, Ting-Ming Wang, ChaoYu Hsu, Shih-Jung Hsu, and Ting-Fang Shih. In vivo threedimensional intervertebral kinematics of the subaxial cervical spine during seated axial rotation and lateral bending via fluoroscopy-to-ct registration approach. Journal of biomechanics, 47(13):33103317, 2014. 2, [40] RM Lin, I-Ming Jou, and Chin-Yin Yu. Lumbar lordosis: normal adults. Journal of the Formosan Medical Association= Taiwan yi zhi, 91(3):329333, 1992. 5 [41] Sara Lindenmann, Christos Tsagkaris, Mazda Farshad, and Jonas Widmer. Kinematics of the cervical spine under healthy and degenerative conditions: systematic review. Annals of Biomedical Engineering, 50(12):17051733, 2022. 2 [42] Filipa Lino, Carlos Santiago, and Manuel Marques. Benchmarking 3d human pose estimation models under occlusions. arXiv preprint arXiv:2504.10350, 2025. 3 [43] Ao Liu, Nan-Hai Qiu, Xue-Ren Zhong, Xiang Fang, JunJian Liao, Zhi-Peng Zhang, Pei-Feng Zheng, Yong-Yu Hu, Kong-He Hu, Ying-Hui Xiong, et al. Dynamic evaluation of the cervical spine by kinematic mri in patients with cervical spinal cord injury without fracture and dislocation. Journal of Orthopaedic Surgery and Research, 18(1):249, 2023. 2 [44] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017. [45] Oliver Ludwig, Carlo Dindorf, Jens Kelm, Steven Simon, Felix Nimmrichter, and Michael Frohlich. Reference values for sagittal clinical posture assessment in people aged 10 to 69 years. International Journal of Environmental Research and Public Health, 20(5):4131, 2023. 8 [46] Julieta Martinez, Rayat Hossain, Javier Romero, and James Little. simple yet effective baseline for 3d human pose estimation. In Proceedings of the IEEE international conference on computer vision, pages 26402649, 2017. 3, 7 [47] Soroush Mehraban, Vida Adeli, and Babak Taati. Motionagformer: Enhancing 3d human pose estimation with In Proceedings of the transformer-gcnformer network. IEEE/CVF winter conference on applications of computer vision, pages 69206930, 2024. 3 [48] Elias Melhem, Ayman Assi, Rami El Rachkidi, and Ismat Ghanem. Eos biplanar x-ray imaging: concept, developments, benefits, and limitations. Journal of childrens orthopaedics, 10(1):114, 2016. 2, 8 [49] Giulia Michelini, Antonella Corridore, Silvia Torlone, Federico Bruno, Claudia Marsecano, Raffaella Capasso, Ferdinando Caranci, Antonio Barile, Carlo Masciocchi, and Alessandra Splendiani. Dynamic mri in the evaluation of the spine: state of the art. Acta Bio Medica: Atenei Parmensis, 89(Suppl 1):89, 2018. 2 [50] Jonathan Mortensen, Anita Vasavada, and Andrew Merryweather. The inclusion of hyoid muscles improve moment generating capacity and dynamic simulations in musculoskeletal models of the head and neck. PloS one, 13(6): e0199912, 2018. [51] Donald Neumann. Kinesiology of the musculoskeletal system: foundations for rehabilitation. Mosby Elsevier, 2010. 1, 2 [52] Itaru Oda, Kuniyoshi Abumi, Bryan Cunningham, Kiyoshi Kaneda, and Paul McAfee. An in vitro human cadaveric study investigating the biomechanical properties of the thoracic spine. Spine, 27(3):E64E70, 2002. 1, 2 [53] David Pagnon, Mathieu Domalain, and Lionel Reveret. Pose2sim: an end-to-end workflow for 3d markerless sports kinematicspart 2: accuracy. Sensors, 22(7):2712, 2022. 3, 4 [54] Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 77537762, 2019. 3 [55] Mark Pearcy, IAN Portek, and Janis Shepherd. Threedimensional x-ray analysis of normal movement in the lumbar spine. Spine, 9(3):294297, 1984. 8 [56] Mark Pearcy. Stereo radiography of lumbar spine motion. Acta Orthopaedica Scandinavica, 56(sup212):145, 1985. 8 [57] Zizhao Peng, Zihan Wang, Mengying Sun, Zheng Lv, Yan Wang, Ping Li, and Fengwei An. Graph convolutional networks for 3d skeleton-based scoliosis screening using gait sequences: Z. peng et al. The Visual Computer, pages 113, 2025. 2 [58] Hieu Huy Pham, Nguyen Trung, and Ha Quy Nguyen. Vindr-spinexr: large annotated medical image dataset for spinal lesions detection and classification from radiographs. PhysioNet, pages RRIDSCR 007345, 2021. [59] Apoorva Rajagopal, Christopher Dembia, Matthew DeMers, Denny Delp, Jennifer Hicks, and Scott Delp. Full-body musculoskeletal model for muscle-driven simulation of human gait. IEEE transactions on biomedical engineering, 63(10):20682079, 2016. 3, 4 [60] Alexandra Roren, Robin Ogiez, Laurent Gajny, Aurore Blasco, Fadila Mihoubi Bouvier, Antoine Feydy, Francois Rannou, Marie-Martine Lef`evre-Colau, and Agn`es RobyBrami. Arm elevation involves changes in the whole spine: an exploratory study using eos imaging. BMC Musculoskeletal Disorders, 25(1):993, 2024. 4, 5 [61] Adam Rozumalski, Michael Schwartz, Roy Wervey, Andrew Swanson, Daryll Dykes, and Tom Novacheck. The in vivo three-dimensional motion of the human lumbar spine during gait. Gait & posture, 28(3):378384, 2008. 1 [62] Janis Savlovskis. Range of the motion (rom) of the cervical, thoracic and lumbar spine in the traditional anatomical planes. Anatomy Standard, 2020. 5 [63] Stefan Schmid, Katelyn Burkhart, Brett Allaire, Daniel Grindle, and Dennis Anderson. Musculoskeletal full-body models including detailed thoracolumbar spine for children and adolescents aged 618 years. Journal of biomechanics, 102:109305, 2020. 3 [64] Anjany Sekuboyina, Malek Husseini, Amirhossein Bayat, Maximilian Loffler, Hans Liebl, Hongwei Li, Giles Tetteh, Jan Kukaˇcka, Christian Payer, Darko ˇStern, et al. Verse: vertebrae labelling and segmentation benchmark for multidetector ct images. Medical image analysis, 73:102166, 2021. 2, [65] Jeremy Shaw, Daniel Shaw, Daniel Cooperman, Jason Eubanks, Ling Li, and David Kim. Characterization of lumbar spinous process morphology: cadaveric study of 2,955 human lumbar vertebrae. The Spine Journal, 15(7): 16451652, 2015. 1, 2 [66] Tomasz Sipko, Katarzyna Barczyk-Pawelec, Mirela Piksa, and Joanna Mencel. Impact of standing and sitting postures on spinal curvature and muscle mechanical properties in young women: photogrammetric and myotonpro analysis. Medical Science Monitor: International Medical Journal of Experimental and Clinical Research, 30:e9449301, 2024. 4, 5 [67] Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang. Deep high-resolution representation learning for human pose estimation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 56935703, 2019. 6 [68] Tafazzol, Arjmand, Aboulfazl Shirazi-Adl, and Parnianpour. Lumbopelvic rhythm during forward and backward sagittal trunk rotations: combined in vivo measurement with inertial tracking device and biomechanical modeling. Clinical Biomechanics, 29(1):713, 2014. 8 [69] Christos Tsagkaris, Jonas Widmer, Florian Wanivenhaus, Andrea Redaelli, Claudio Lamartina, and Mazda Farshad. The sitting vs standing spine. North American Spine Society Journal (NASSJ), 9:100108, 2022. 4, 5 [70] Keenon Werling, Nicholas Bianco, Michael Raitor, Jon Stingel, Jennifer Hicks, Steven Collins, Scott Delp, and Karen Liu. Addbiomechanics: Automating model scaling, inverse kinematics, and inverse dynamics from human motion data through sequential optimization. Plos one, 18(11):e0295152, 2023. [71] AUGUSTUS WHITE III. Clinical biomechanics of cervical spine implants. Spine, 14(10):10401045, 1989. 1 [72] AUGUSTUS WHITE III and Manohar Panjabi. The basic kinematics of the human spine: review of past and current knowledge. Spine, 3(1):1220, 1978. 5 [73] Qun Xia, Shaobai Wang, Peter Passias, Michal Kozanek, Gang Li, Brian Grottkau, Kirkham Wood, and Guoan Li. In vivo range of motion of the lumbar spinous processes. European Spine Journal, 18(9):13551362, 2009. 1 [74] Yufei Xu, Jing Zhang, Qiming Zhang, and Dacheng Tao. ViTPose: Simple vision transformer baselines for human In Advances in Neural Information Propose estimation. cessing Systems, 2022. 6 [75] Mattia Zappala, Stephen Lightbourne, and Nicola Heneghan. The relationship between thoracic kyphosis and age, and normative values across age groups: systematic review of healthy adults. Journal of orthopaedic surgery and research, 16(1):447, 2021. 8 [76] Yaqi Zhang, Yan Lu, Bin Liu, Zhiwei Zhao, Qi Chu, and Nenghai Yu. Evopose: recursive transformer for 3d human pose estimation with kinematic structure priors. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 15. IEEE, 2023. [77] Zirui Zhou, Junhao Liang, Zizhao Peng, Chao Fan, Fengwei An, and Shiqi Yu. Gait patterns as biomarkers: videoIn International based approach for classifying scoliosis. Conference on Medical Image Computing and ComputerAssisted Intervention, pages 284294. Springer, 2024. 2, 3 [78] Wentao Zhu, Xiaoxuan Ma, Zhaoyang Liu, Libin Liu, Wayne Wu, and Yizhou Wang. Motionbert: unified perspective on In Proceedings of learning human motion representations. the IEEE/CVF international conference on computer vision, pages 1508515099, 2023. 3 [79] Xiaojia Zhu, Rui Chen, Zhiwen Shao, Ming Zhang, Yuhu Dai, Wenzhi Zhang, and Chuandong Lang. Mgscoliosis: Multi-grained scoliosis detection with joint ordinal regression from natural image. Alexandria Engineering Journal, 111:329340, 2025. 3 SIMSPINE: Biomechanics-Aware Simulation Framework for 3D Spine Motion Annotation and Benchmarking"
        },
        {
            "title": "Supplementary Material",
            "content": "A. Data Augmentation Curriculum Motivation. We employ three-phase augmentation schedule that transitions from heavy appearance and occlusion randomization to geometry-focused fine-tuning. This curriculum combines domain randomization with posespecific augmentations such as half-body cropping and occlusion masking. The aim is to first promote invariance, then stabilize spatial priors, and finally refine keypoints with clean, low-noise data. Schedule. Given fine-tuning epochs (E=10), augmentation stages switch at e1 = 0.33E, e2 = 0.67E, producing intervals [0, e1), Stages 13. A.1. Pipeline Overview [e1, e2), and [e2, E) for All stages share standard top-down cropping and affine normalization to fixed input size (192256), followed by target generation from augmented keypoints. Augmentation parameters are applied per sample with fixed random seeds for reproducibility. Stage 1 (hard) Strong spatial and photometric perturbations for invariance: Random flip; half-body crop. Bounding-box transform: scale [0.5, 1.5], rotation Table A1. Augmentation curriculum Probabilities (p) are persample. CoarseDropout sizes are specified as fractions of the (pretarget) image after TopdownAffine. Parameter Epochs Rotation Scale Shift HalfBody Photometric Occlusion / Stage 1 [0, e1) 180 [0.5, 1.5] (default) Photometric; Blur (p=0.1); MedianBlur (p=0.1); CoarseDropout (p=1.0, 1 hole, h, [0.2, 0.4]) Stage 2 [e1, e2) 90 Stage 3 [e2, E) 60 [0.5, 1.5] [0.5, 1.5] 0.0 none 0.0 Blur (p=0.1); MedianBlur (p=0.1); CoarseDropout (p=0.5, same sizes) Stage 2: global skeletal cues and lighting invariance. Milder noise allows consolidation of geometric structure without overfitting to easy samples. Stage 3: Clean inputs promote precise coordinate optimization and whole-body consistency, improving AUC while maintaining robustness to real-world variation. B. SIMSPINE Details Table B2. Lordosis and Kyphosis stats by Action and Subject 180. Photometric distortions (exposure, contrast, saturation, hue). Occlusion via CoarseDropout (p=1.0, one hole, height/width [0.2, 0.4]). Stage 2 (medium) Reduced occlusion and rotation for geometric stability: Random flip; half-body crop. Scale [0.5, 1.5], rotation 90. CoarseDropout (p=0.5, same hole size). Stage 3 (easy) Geometry-only refinement with minimal noise: Random flip only. Scale [0.5, 1.5], rotation 60. No occlusion, blur, or photometric perturbation. Scale factors are relative to person crops. A.2. Rationale Stage 1: Large rotations and masking simulate extreme viewpoints and occlusions , driving the model to exploit"
        },
        {
            "title": "Action",
            "content": "LLA (θl) TKA (θk) Directions Discussion Eating Greeting Phoning Photo Posing Purchases Sitting SittingDown Smoking TakingPhoto Waiting WalkDog WalkTogether Walking WalkingDog 36.09 2.10 36.40 2.69 36.86 2.53 36.42 2.59 35.41 3.28 36.97 2.86 36.78 2.87 37.60 2.95 34.53 4.38 35.41 4.75 34.94 3.24 36.67 1.79 36.48 2.81 36.68 3.30 35.98 2.22 36.08 2.43 36.13 3.34 33.26 4.34 34.04 3.52 32.34 3.90 31.00 3.89 35.46 4.56 32.10 3.61 32.27 5.22 33.29 3.93 35.56 3.95 35.34 6.21 35.07 4.11 31.41 2.84 32.37 3.73 31.82 4.49 31.03 3.77 32.05 3.92 30.68 3."
        },
        {
            "title": "Avg",
            "content": "36.20 2.95 32.89 4.10 Subject LLA (θl) TKA (θk) S1 S5 S6 S7 S8 S9 35.21 2.88 38.14 2.71 37.50 3.15 36.77 3.12 34.51 2.46 33.94 2.53 35.08 2.90 32.38 3.86 31.89 3.95 37.17 4.23 32.85 4.83 33.65 4.02 32.84 4.83 34.28 3."
        },
        {
            "title": "Avg",
            "content": "35.88 2.82 33.58 4.18 Table B3. SimSpine Anatomical Keypoints, Kinematic Axes, and Hierarchical Parent Links. The dataset defines 37 anatomical keypoints covering full-body and spine-specific markers, grouped into Lumbar, Thoracic, Cervical, and Peripheral regions. Kinematic axes correspond to OpenSim-style rotational and translational degrees of freedom in the musculoskeletal model. Parent indices follow the hierarchical linkage used in forward kinematics. Note: Due to licensing reasons, only 15 spine annotations are included in the released dataset. Body and feet annotations can be obtained from Human3.6M and H3WB datasets, respectively."
        },
        {
            "title": "Region",
            "content": "Parent ID Swap / Side Associated Kinematic Axes (if any) Nose 0 LEye 1 REye 2 LEar 3 REar 4 LShoulder 5 RShoulder 6 LElbow 7 RElbow 8 9 LWrist 10 RWrist LHip 11 12 RHip 13 LKnee 14 RKnee 15 LAnkle 16 RAnkle 17 Head 18 Neck 19 Hip (Root)"
        },
        {
            "title": "20\nLBigToe\n21 RBigToe\n22\nLSmallToe\n23 RSmallToe\nLHeel\n24\n25 RHeel\n26",
            "content": "Spine"
        },
        {
            "title": "Body\nBody\nBody\nBody\nBody\nBody\nLumbar",
            "content": "17 0 0 1 2 33 34 5 6 7 8 19 19 11 12 13 14 36 30 -1 15 16 20 21 15 16 19 27 Spine"
        },
        {
            "title": "Lumbar",
            "content": "26 28 Spine"
        },
        {
            "title": "Lumbar",
            "content": "Spine 04 Spine 05 LLatissimus"
        },
        {
            "title": "Cervical",
            "content": "27 28 29 29 29 30 30 18 35 REye LEye REar LEar RShoulder LShoulder RElbow LElbow RWrist LWrist RHip LHip RKnee LKnee RAnkle LAnkle RBigToe LBigToe RSmallToe LSmallToe RHeel LHeel RLatissimus LLatissimus RClavicle LClavicle Spine markers by region: Lumbar (4): Hip, Spine 01, Spine 02, Spine 03. Thoracic (6): Spine 04, Spine 05, 2Latissimus, 2Clavicles. Cervical (5): Nose, Head, Neck, Neck 02, Neck 03. Total keypoints: 37 (Spine: 15 Body: 22). pelvis ty, pelvis tz, neck flexion, neck bending, neck rotation arm flex l, arm add l, arm rot arm flex r, arm add r, arm rot elbow flex l, pro sup elbow flex r, pro sup wrist flex l, wrist dev wrist flex r, wrist dev hip flexion l, hip adduction l, hip rotation hip flexion r, hip adduction r, hip rotation knee angle l, knee angle beta knee angle r, knee angle beta ankle angle l, subtalar angle l, mtp angle ankle angle r, subtalar angle r, mtp angle neck flexion, neck bending, neck rotation pelvis tx, pelvis rotation L5 S1 Flex Ext, L5 S1 axial rotation, L4 L5 Lat Bending, L4 L5 axial rotation L3 L4 Flex Ext, L3 L4 axial rotation, L2 L3 Lat Bending, L2 L3 axial rotation L1 L2 Flex Ext, L1 L2 axial rotation L1 T12 Flex Ext, L1 T12 axial rotation pelvis tilt, pelvis list, L5 S1 Lat Bending, L4 L5 Flex Ext, L3 L4 Lat Bending, L2 L3 Flex Ext, L1 L2 Lat Bending, L1 T12 Lat Bending, (a) Directions (b) Discussion (c) Eating (d) Greeting (e) Phoning (f) Posing (g) Purchases (h) Sitting (i) Smoking (j) TakingPhoto (k) Waiting (l) Walking Figure B1. Sagittal (YZ) and Frontal (XZ) Distributions of Upper-Body Joint Positions Across Actions. Each pair of panels shows the sagittal (left) and frontal (right) kernel-density contours of root-relative joint coordinates aggregated over all motion-capture frames of that action. Colored circles denote mean joint centers, and connecting lines depict the average kinematic chain. Sagittal views highlight action-specific curvature and torso inclinatione.g., pronounced flexion in Sitting and near-vertical alignment in Walkingwhereas frontal views emphasize lateral symmetry and limited sideward spread, reflecting the bilateral consistency of the upper torso. C. Additional Results Figure C2 shows additional qualitative comparisons with the previous SOTA 2D tracker for spine pose estimation [31]. Figure C2. Qualitative Evidence: Comparison of the 2D tracker from [31] (top, blue) and our fine-tuned tracker on SIMSPINE (bottom, green). Best viewed zoomed-in on screen. Left: On an internet frontal-view image with lateral bending, [31]s tracker produces noisy, implausible locations for lower spine, upper neck, and clavicle points (circled in red), which our tracker corrects. Middle: On H36M validation samples using 2D tracking + multiview triangulation, [31] underestimates sagittal curves, and places clavicles behind the spine, which is anatomically impossible. Right: On two self-recorded front-facing bicycle views (novel motion), we compare sagittal curvature in 3D from [31] with our 2D-based reconstruction: [31] exhibits discontinuities, while our model yields more realistic back posture, showing that our method and data go beyond simple 2D pose [31]."
        }
    ],
    "affiliations": [
        "German Research Center for Artificial Intelligence (DFKI)"
    ]
}