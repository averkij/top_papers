{
    "paper_title": "Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution",
    "authors": [
        "Chenghao Li",
        "Chaoning Zhang",
        "Yi Lu",
        "Jiaquan Zhang",
        "Qigan Sun",
        "Xudong Wang",
        "Jiwei Wei",
        "Guoqing Wang",
        "Yang Yang",
        "Heng Tao Shen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Chain-of-Thought (CoT) prompting enhances the reasoning of large language models (LLMs) by decomposing problems into sequential steps, mimicking human logic and reducing errors. However, complex tasks with vast solution spaces and vague constraints often exceed the capacity of a single reasoning chain. Inspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic geometry, we propose Syzygy of Thoughts (SoT)-a novel framework that extends CoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper logical dependencies, enabling more robust and structured problem-solving. MFR decomposes a module into a sequence of free modules with minimal rank, providing a structured analytical approach to complex systems. This method introduces the concepts of \"Module\", \"Betti numbers\",\"Freeness\", \"Mapping\", \"Exactness\" and \"Minimality\", enabling the systematic decomposition of the original complex problem into logically complete minimal subproblems while preserving key problem features and reducing reasoning length. We tested SoT across diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini, Qwen2.5), achieving inference accuracy that matches or surpasses mainstream CoTs standards. Additionally, by aligning the sampling process with algebraic constraints, our approach enhances the scalability of inference time in LLMs, ensuring both transparent reasoning and high performance. Our code will be publicly available at https://github.com/dlMARiA/Syzygy-of-thoughts."
        },
        {
            "title": "Start",
            "content": "Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution Chenghao Li1, Chaoning Zhang1, Yi Lu2,3, Jiaquan Zhang1, Qigan Sun4, Xudong Wang4, Jiwei Wei1, Guoqing Wang1, Yang Yang1, Heng Tao Shen5,1 1University of Electronic Science and Technology of China, Chengdu, China; 2Capital Normal University, Beijing, China; 3University of Liverpool, Liverpool, United Kingdom; 4Kyung Hee University, Yongin-si, Republic of Korea; 5Tongji University, Shanghai, China {lch17692405449, chaoningzhang1990, sunqigan0206, wangcurry33, mathematic6, gqwang0420}@gmail.com; 2230501004@cnu.edu.cn; 2024091202001@std.uestc.edu.cn; yang.yang@uestc.edu.cn; shenhengtao@hotmail.com 5 2 0 2 6 1 ] . [ 2 6 6 5 9 0 . 4 0 5 2 : r ABSTRACT Chain-of-Thought (CoT) prompting enhances the reasoning of large language models (LLMs) by decomposing problems into sequential steps, mimicking human logic and reducing errors. However, complex tasks with vast solution spaces and vague constraints often exceed the capacity of single reasoning chain. Inspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic geometry, we propose Syzygy of Thoughts (SoT)a novel framework that extends CoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper logical dependencies, enabling more robust and structured problem-solving. MFR decomposes module into sequence of free modules with minimal rank, providing structured analytical approach to complex systems. This method introduces the concepts of \"Module\", \"Betti numbers\",\"Freeness\", \"Mapping\", \"Exactness\" and \"Minimality\", enabling the systematic decomposition of the original complex problem into logically complete minimal subproblems while preserving key problem features and reducing reasoning length. We tested SoT across diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini, Qwen2.5), achieving inference accuracy that matches or surpasses mainstream CoTs standards. Additionally, by aligning the sampling process with algebraic constraints, our approach enhances the scalability of inference time in LLMs, ensuring both transparent reasoning and high performance. Our code will be publicly available at https://github.com/dlMARiA/Syzygyof-thoughts"
        },
        {
            "title": "1 INTRODUCTION\nThe rapid advancements in natural language processing [3, 12, 35,\n43] have demonstrated outstanding reasoning capabilities across\nvarious tasks [30, 64]. In recent years, the Chain of Thought (CoT)\nprompting method [49] has emerged as an effective strategy for\nsimulating human reasoning by generating intermediate reasoning\nsteps, significantly enhancing model performance in solving com-\nplex problems [5, 27, 34, 42, 50, 52]. The core advantage of the CoT\nframework lies in its ability to decompose problems into a series of\nexplicit and easily interpretable intermediate steps, thereby improv-\ning the transparency and explainability of the reasoning process.",
            "content": "Corresponding Author: Chaoning Zhang. Figure 1: SoT (Ours) achieved performance improvements compared to CoT and CoT-SC on two models across nine datasets. The inner circle shows three methods of Qwen2.5, while the outer circle shows three methods of 4o-mini. This explicit stepwise reasoning not only facilitates in-depth analysis and debugging of model outputs but also provides clear logical pathway for solving complex problems. However, despite its success in many tasks, CoT exhibits inherent limitations when dealing with high-dimensional, nonlinear, and abstract logical problems [21, 39, 44]. First, traditional CoT methods often rely on fixed or heuristic decomposition strategies, which struggle to capture essential details and intrinsic connections in multidimensional problems [44]. Second, due to the lack of systematic structural planning in intermediate steps, the reasoning process tends to include redundant computations and repetitive paths, leading to increased computational resource consumption and inference latency [21]. Although existing improvements have alleviated these issues to some extent, introducing techniques such as multi-path exploration, voting mechanisms, and hierarchical decomposition strategies to enhance robustness [1, 47, 55, 56, 66], however, they have yet to fully address logical incompleteness and the inadequate decomposition of high-dimensional information. As result, when handling highly complex reasoning tasks, model robustness and accuracy still face significant challenges. To address these challenges, we propose novel reasoning frameworkSyzygy of Thoughts (SoT). This method draws inspiration from the concept of MFR in algebraic geometry and computational algebra [2, 13, 37], systematically decomposing and reconstructing problems by constructing minimal free module sequences. The incorporation of MFR theory ensures more rigorous and efficient problem decomposition process while preserving the core characteristics of the problem, effectively reducing redundant computations and logical inconsistencies. Specifically, SoT retains the stepwise reasoning advantages of CoT while introducing algebraic tools such as \"module\", \"Betti numbers\", \"freeness\", \"mapping\", \"exactness\" and \"minimality\" to deeply explore and systematically express the intrinsic structure of complex problems. This approach provides novel theoretical perspective for analyzing high-dimensional and multivariable problems. To validate the effectiveness of SoT, we conducted extensive experiments across diverse datasets, including GSM8K, MATH, and others, spanning mathematical reasoning and high-dimensional problem domains. These datasets, with their complex structures and multifaceted features, provide robust testbed for evaluating reasoning frameworks in real-world scenarios. Experimental results show that SoT achieves inference accuracy that matches or surpasses mainstream CoTs standards, demonstrating its superior performance and practical potential. Finally, the SoT framework exhibits multiple advantages, including an intuitive and transparent reasoning path and improved interpretability of intermediate information. The main contributions of this work are as follows: (1) Pioneering the integration of MFR into LLM reasoning, enabling structured decomposition of complex problems. (2) Developing novel framework that builds on CoTs strengths while substantially improving reasoning clarity and structural efficiency. (3) Providing theoretical insights and empirical evidence that SoT significantly enhances performance in high-dimensional reasoning tasks. Li et al. Structured prompting strategies further enhance reasoning. Leastto-Most Prompting (LtM)[66] breaks tasks into manageable subproblems, reducing single-step errors. Programmatic methods, including Program of Thought (PoT)[7], Chain of Code (CoC)[24], and Buffer of Thought (BoT)[54], integrate discrete variables and procedural steps. Building on these, Algorithm of Thought (AoT) [38] iteratively synthesizes and refines solutions, boosting token efficiency. Treeand graph-based paradigms offer alternative exploration. Tree-of-Thought (ToT)[55] employs hierarchical structure to explore multiple decision paths, though exponential growth limits deep efficiency. Graph-of-Thought (GoT)[1] extends this with flexible graph configurations, enabling path recalibration and information aggregation. Meanwhile, Skeleton-of-Thought (SoT)[32] generates high-level outlines before detailing, balancing speed and quality, while recursive methods like Self-Refine[29] and Step-Back Prompting [65] refine outputs iteratively for higher accuracy."
        },
        {
            "title": "2.2 Minimal Free Resolution\nMFR is a core tool in homological algebra [16] and algebraic geom-\netry [2], used to analyze the algebraic structure of modules [13, 37],\nrevealing properties such as rank, symmetry, and relationships [6].\nIn computational algebraic geometry, MFR analyzes singularities\nand invariants of algebraic varieties through syzygies [15], opti-\nmizing the complexity and efficiency of Gröbner basis computa-\ntions [4, 14, 41, 51].",
            "content": "In Topological Data Analysis (TDA), MFR accelerates persistent homology computations [48], enhancing the stability of topological analysis for high-dimensional data. In physics and bioinformatics, MFR is used to analyze Calabi-Yau manifold singularities [33], gauge field structures [19], and the modular properties of gene regulatory networks [26]. The advantages of MFR in optimizing computational complexity and revealing algebraic structures provide new perspective for its integration into the study of CoT in LLM. In CoT, structured reasoning steps are required, but often face challenges of inefficiency and redundancy. We innovatively introduce MFR into CoT by decomposing the symbolic dependencies between reasoning steps, eliminating redundant calculations, optimizing intermediate processes, and enhancing transparency. This approach opens up more efficient and structured technical pathway for LLM applications in solving complex problems."
        },
        {
            "title": "3 METHOD\n3.1 Preliminaries\nIn algebraic geometry and homological algebra, minimal free resolu-\ntion is an essential tool for studying the structure and properties of\nmodules, especially when dealing with finitely generated modules\nover a ring.\nKey Properties: In algebraic geometry and homological algebra, a\n\"syzygy\" refers to the relations among the relations that generate a\nmodule. A syzygy is a relation among the generators. For example,\nif a module 𝑀 is defined by generators 𝑓1, 𝑓2, . . . , 𝑓𝑘 , then a syzygy\nis a relation of the form:",
            "content": "Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution Figure 2: SoT Overview. Through the six modules: Module Freeness, Mapping, Exactness, Minimality, and Betti, MFR can decompose and deconstruct complex reasoning problem, aiding LLMs in generating more accurate answers. 𝑎1 𝑓1 + 𝑎2 𝑓2 + + 𝑎𝑘 𝑓𝑘 = 0, (1) where 𝑎𝑖 𝑅. These relations themselves can form module, which is called the \"first syzygy module.\" module 𝑀 over ring 𝑅 is an algebraic structure similar to vector space, but the scalars come from 𝑅 instead of field. module 𝑀 is called free if it has basis, i.e., 𝑀 (cid:27) 𝑅𝑛 for some dimension 𝑛 (finite or infinite). Free modules are analogous to free vector spaces in linear algebra. module is finitely generated if there exists finite set {𝑚1, 𝑚2, . . . , 𝑚𝑛 } 𝑀 such that 𝑀 = (cid:205)𝑛 𝑖=1 𝑅𝑚𝑖 . MFR of finitely generated module 𝑀 over 𝑅 is an exact sequence: (2) 𝐹2 𝐹1 𝐹0 𝑀 0, Where each 𝐹𝑖 is free (𝐹𝑖 (cid:27) 𝑅𝑛𝑖 ), the matrices of the maps contain no units, and the resolution is \"minimal,\" meaning the number of free generators is the smallest possible. This resolution provides standardized way to describe the structure of 𝑀, reflecting both its complexity and its homological properties. MFR is characterized by its minimality, where each 𝐹𝑖 uses the smallest number of generators, and the matrices in the maps contain no units. It is unique up to isomorphism, meaning any two MFRs of 𝑀 are naturally isomorphic. The 𝑖-th Betti number of 𝑀, defined as 𝛽𝑖 (𝑀) = rank(𝐹𝑖 ), counts the number of free generators in 𝐹𝑖 and reflects the complexity of the resolution."
        },
        {
            "title": "3.2 Minimal Free Resolution enhanced CoT\nAs shown in Figure 3, the SoT reasoning paradigm employs the\nMFR framework to model the structure of CoT reasoning paths in\nLLMs. Each reasoning step—such as problem interpretation, task\ndecomposition, subgoal chaining, and final inference—is abstracted\nas generators or relations within modules, reinterpreting CoT as al-\ngebraic objects with generative structures and latent dependencies,\nrather than merely a flat sequence of symbols.",
            "content": "Module: Initial Complex Problem Complex problems often exhibit high-dimensional structures, intricate logical dependencies, and ambiguous constraints, rendering direct solutions intractable. In this initial module, we conceptualize the problem as unified entity of interdependent substructures, necessitating systematic decomposition. The goal is not immediate resolution but to unravel latent complexity, identify core logical components, and establish foundation for subsequent modular reasoning. This stage ensures that downstream processes operate within well-defined boundaries, setting the stage for structured analysis. Li et al. Betti numbers thus guide reasoning efficiency, balancing structural complexity with computational simplicity. Freeness : Auxiliary Conditions Freeness involves generating auxiliary conditions to simplify problems and clarify logical relationships. By introducing intermediate variables, hypotheses, or formalized constraints, complex problems are partitioned into smaller, independent subproblems. This reduces dimensionality and provides clear entry points for resolution, enhancing the tractability of subsequent steps while maintaining logical coherence. Mapping: Solving Strategies Effective problem-solving requires systematic strategies that map auxiliary conditions to actionable reasoning paths. These paths must exhibit (i) directness, minimizing redundant operations, and (ii) logical soundness, grounding each step in explicit premises). LLMs iteratively solve subproblems along these paths, linking current conditions to new conclusions, ensuring continuity and interpretability throughout the reasoning chain. Exactness: Logical Completeness Logical completeness is critical for rigor, preventing gaps or leaps in the reasoning chain. Each step must derive from explicit premises, with implicit assumptions formalized to avoid invalid conclusions. LLMs verify consistency across auxiliary conditions, subproblems, and the final solution, systematically reviewing the chain against original constraints. This ensures coherent and reliable framework, minimizing errors from incomplete logic. Minimality: Optimal Solutions Minimality optimizes efficiency by deriving solutions with the fewest auxiliary conditions and simplest strategies, without sacrificing correctness. Redundant conditions are filtered, and reasoning paths are pruned of unnecessary steps. LLMs prioritize straightforward approaches over complex transformations, yielding concise, clear solutions. This reduces overall complexity, enhancing both computational efficiency and solution transparency. After introducing the above six concepts, LLMs can be directly stimulated in conversational manner. Figure 4 illustrates the conversational framework of these six concepts. First, complex reasoning problems are defined as free module. Then, through the Betti number and auxiliary conditions of degrees of freedom, the complex problem is reduced and decomposed. By analyzing both the module and degrees of freedom simultaneously, the model can construct multiple mappings to solve the problem. Finally, minimality and accuracy are used to select the optimal solution. Figure 3: The mathematical, abstract analogy, and CoT analogy of Module, Freeness, Mapping, Exactness, Minimality, and Betti Number. Algorithm 1 LLM MFR of Reasoning Module 𝑀 1: function LLMMinimalFreeResolution(𝑀, 𝐷) 2: 𝑀: Reasoning Question; 𝐷: Metadata of 𝑀 (𝛽, 𝜇) Analyse(𝑀, 𝐶) 𝛽,𝜇: Regularity, Projective Dimension Generate Auxiliary Conditions Initialize Empty Freeness List Ψ Ψ [ ] for 𝑗 = 1 to 𝛽 do 𝜓 𝑗 LLM(𝐹0, . . . , 𝐹 𝑗 1, 𝜑0, . . . , 𝜑 𝑗 1) Ψ Ψ {𝜓 𝑗 } end for 12: 13: [ ] 14: for 𝑘 = 1 to 𝜇 do S𝑘 LLM(𝑀, Ψ) {S𝑘 } Construct Solutions Initialize Empty Solution List Repeated Resolution end for Select Optimal Resolution from Syzygies 𝑘 = arg min𝑘 : S𝑘 𝜙 (S𝑘 ) 𝜙 () : LLM reasoning with Scoring prompt Sopt S𝑘 Answer ExtractFinalAnswer(Sopt, 𝐶) Pattern Matching: Regex, JSON etc. 3: 4: 5: 6: 7: 8: 9: 10: 11: 15: 16: 17: 18: 19: 20: 21: 22: 23: return Answer 24: 25: end function Betti Numbers: Quantifying Complexity To measure decomposition complexity, we introduce Betti numbers as quantitative metric, where each number reflects the count of auxiliary conditions at reasoning level. Higher Betti numbers indicate greater intricacy, signaling potential optimization opportunities. We leverage LLMs to minimize these numbers by regenerating or filtering conditions, streamlining the decomposition process."
        },
        {
            "title": "3.3 Syzygy of Thoughts\nThe process of LLM reasoning for complex problems can be viewed\nas solving a complex reasoning problem 𝑀 through MFR. The entire\nprocess is formalized via a MFR sequence, where the structured\nrepresentation of the reasoning process is a set of mappings 𝜑𝑖\ninduced by the LLM, forming the following sequence:",
            "content": "Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution Figure 4: Conceptual framework illustrating the process of navigating LLMs latent space through modular reasoning. The diagram highlights key components, including Module Freeness, Betti Numbers, Mappings, Exactness, and Minimality, to decompose and solve complex problem. While the figure aids in understanding the theoretical underpinnings and logical flow of the methodology, it does not represent the exact procedural steps of the method. LLM(𝜑2 ) 𝐹2 LLM(𝜑1 ) 𝐹1 LLM(𝜑0 ) 𝐹0 𝑀 0. (3) Moreover, we define the intermediate space 𝐹𝑖 as free module constructed from basic reasoning units: (cid:202) 𝐹𝑖 = 𝑅 𝑚𝑖 𝑗 𝑗 (4) where: - 𝑅 is the reasoning space (LLM Reasoning Space), - 𝑚𝑖 𝑗 are the basic units (Tokens) used in the reasoning construction, - Each 𝜑𝑖 is induced by the LLM, representing single-step logical deduction in the CoT. SoT Reasoning. The Algorithm 1 and Figure 3 explain the 3.3.1 entire process of SoT. The SoT framework begins with an initial complex problem 𝑀, characterized by high-dimensional structure, intricate logical dependencies, and ambiguous constraint relationships. We treat 𝑀 as unified representation of interdependent substructures, setting the stage for systematic decomposition. To analyze the inherent complexity of 𝑀, we introduce Betti numbers as quantitative indicators of structural complexity. Specifically, the Betti number corresponds to the number of auxiliary conditions required for decomposition, with higher values suggesting deeper structural intricacy. These values guide the subsequent generation of auxiliary components and indicate potential optimization points. We then introduce the notion of Freeness, which refers to the generation of auxiliary conditions that serve to simplify and structurally reorganize the problem. These conditionsdenoted as Ψ = {𝜓1, . . . ,𝜓𝛽 }include intermediate hypotheses, latent constraints, or explicit sub-conclusions, and are generated via autoregressive reasoning using LLMs conditioned on previously established states. Each 𝜓 𝑗 decomposes the original problem into finergrained logical units, reducing its dimensional complexity and establishing solvable subspaces. To resolve the decomposed problem, the framework constructs set of mappings = {S1, . . . , S𝜇 }, each corresponding to distinct reasoning path. These mappings are designed to satisfy two essential properties: directness, ensuring that each inference step avoids redundant operations, and logical soundness, ensuring that every conclusion is firmly grounded in its premises. Each mapping S𝑘 is generated using LLMs to traverse from auxiliary conditions to intermediate or final conclusions, thereby forming continuous and interpretable reasoning chain. To ensure logical completeness (Exactness) of the reasoning process, all steps within each reasoning path are verified for inferential closure. Implicit assumptions are formalized, and the consistency of auxiliary conditions, mappings, and final conclusions is evaluated. This validation step leverages the LLMs reasoning and scoring capabilities via scoring function 𝜙 (). Finally, the optimal reasoning sequence Sopt is parsed using structured patternmatching strategies (e.g., regular expressions, JSON parsing) to extract the final solution. Table 1: Performance comparison of CoT, CoT-SC (n=5), and the proposed SoT method across various tasks, including mathematical reasoning, general knowledge, multitask QA, temporal, and logical reasoning. Results are grouped by model architectures, with SoT consistently achieving the best performance across benchmarks. Li et al. Method Math Reasoning Gene. Multitask Temporal GSM8K SVAMP MultiArith ASDiv AQUA MMLU BBH Date Log. CLUTRR CoT CoT-SC (n=5) SoT (Ours) CoT CoT-SC (n=5) SoT (Ours) CoT CoT-SC (n=5) SoT (Ours) CoT CoT-SC (n=5) SoT (Ours) CoT CoT-SC (n=5) SoT (Ours) 85.1% 90.1% 96.0% 77.2% 80.2% 89.1% 86.1% 89.1% 96.0% 83.1% 87.1% 96.0% 83.2% 86.1% 92.1% 84.4% 86.0% 92.2% 82.4% 84.1% 90.6% 86.9% 88.2% 95.8% 85.9% 87.0% 95.8% 79.0% 81.0% 92.5% 99.2% 99.5% 99.7% GPT-4o-mini 97.0% 98.5% 99.8% 65.0% 70.9% 75.6% 63.1% 67.3% 75.2% Qwen2.5-Coder-7B-Instruct 92.3% 95.0% 97.0% 92.0% 95.0% 99.8% 60.6% 62.2% 63.3% 55.1% 56.3% 57.1% Qwen2.5-VL-72B-Instruct 98.8% 99.3% 99.7% 91.9% 92.3% 99.7% 90.4% 93.3% 96.1% 98.0% 98.4% 99.2% 81.1% 83.9% 89.4% Gemma-3-27b-it 80.3% 85.4% 89.4% 98.5% 99.2% 99.2% Gemma-3-12b-it 68.9% 71.7% 77.2% 97.7% 98.0% 99.2% 80.1% 82.9% 84.3% 70.8% 73.2% 84.3% 68.1% 70.6% 72.3% 66.3% 69.2% 72.8% 47.1% 49.3% 57.3% 77.3% 79.0% 85.3% 70.7% 73.2% 85.3% 64.6% 66.7% 69.1% 51.8% 54.9% 75.2% 31.0% 32.9% 36.2% 75.2% 78.0% 80.2% 76.9% 80.2% 80.2% 77.7% 80.2% 82.5% 65.9% 72.4% 75.7% 20.1% 21.0% 26.3% 70.1% 75.0% 78.9% 65.3% 66.4% 78.9% 49.0% 52.2% 55.0%"
        },
        {
            "title": "4.1 Applicability Evaluation\nThe reasoning performance of chain-of-thought methods (such as\nCoT and CoT-SC) varies significantly across models of different\nsizes, especially on lightweight models. We aim to validate whether\nSoT can consistently enhance the reasoning capabilities of various\nLLMs and demonstrate its generalization and stability across mod-\nels and task scenarios. For this purpose, we applied CoT, CoT-SC\n(n=5), and SoT to each model, with the default Betti number set to 7\nand mapping set to 3, recording the accuracy across nine datasets.",
            "content": "Experimental Configuration: The test model was GPT-4o-mini, with the Betti number set to 7 and mapping set to 3. We selected five different scales of LLMs, including GPT-4o-mini (lightweight), Qwen2.5-Coder-7B-Instruct (7B), Gemma-3-12b-it (12B), Gemma-327b-it (27B), and Qwen2.5-VL-72B-Instruct (72B), covering models from lightweight to large-scale. The baseline models were standard CoT and CoT-SC (n=5). The test datasets included GSM8K, SVAMP, MultiArith, ASDiv, AQUA (mathematical reasoning), MMLU (generalization), BBH (multi-task answering), Data (date prediction), and CLUTRR (logical reasoning), covering nine datasets in total. Experimental Results: The results are shown in Table 1. SoT significantly outperforms the baselines across all models and datasets. For example, on GSM8K with GPT-4o-mini, SoT achieved 96.0%, improving by 10.9% over CoT (85.1%) and 5.9% over CoT-SC (90.1%). On the logical reasoning task CLUTRR, SoT achieved 75.7%, surpassing CoT (65.9%) and CoT-SC (72.4%). On Qwen2.5-VL-72B-Instruct, SoT achieved 89.4% on AQUA, outperforming CoT (81.1%) and CoTSC (83.9%). For the lightweight model Qwen2.5-Coder-7B-Instruct, SoT improved GSM8K accuracy to 89.1%, 11.9% higher than CoT (77.2%), showing its superiority in resource-constrained scenarios. Furthermore, on Gemma-3-12b-it, SoT achieved 92.5% on SVAMP, close to the 95.8% achieved by Gemma-3-27b-it, indicating that its generalization ability is not limited by model scale. This result Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution demonstrates the significant advantage of SoTs structured design in improving reasoning performance and stability across models."
        },
        {
            "title": "4.2 Complex Reasoning Evaluation\nTo compare the complex problem reasoning capabilities of SoT\nwith mainstream methods, we evaluated SoT and compared it with\nextensive open-source data from various papers [5] . Specifically,\nwe applied the SoT reasoning chain to GPT-4o-mini and tested\nits reasoning accuracy on the GSM8K and MATH datasets, while\ncomparing it with other methods from the literature.\nExperimental Configuration: The test model was GPT-4o-mini,\nwith the Betti number set to 7 and mapping set to 3. The baselines\nincluded CoT and various popular chain-of-thought variants (such\nas MathPrompter, QuaSAR, MathDivide, etc.). The datasets used\nwere GSM8K [10] and MATH [18].",
            "content": "Table 2: AI Model Performance on Different Benchmarks Method No-CoT [11] ICoT-SI [11] - MathCoder-CL [45] MAmmoTH [60] Brain [8] SQ-VAE [46] Self-Rewarding [9] STaR [61] ENVISIONS [53] MetaMath [59] ToRA-Code [17] OVM [58] - - - - - - - SIaM [57] - OMI2 [25] CODEI/O++ [25] PyEdu [25] CODEI/O [25] OC-SFT-1 [25] WI [25] WI (Full) [25] OMI2 (Full) [25] - CoMAT [23] CoT [36] FCoT [28] MathPrompter [20] QuaSAR [35] MathDivide [40] SoT (Ours) Model Mistral-7B Mistral-7B RecurrentBlock-3.5B Code-Llama-7B Code-Llama-7B Code-Llama-7B Llama-2-7B Llama-2-7B Llama-2-7B Llama-2-7B Llama-2-7B Llama-2-7B Llama-2-7B Llama-3.1-8B Llama-3.1-70B Llama-3.1-405B NuminaMath-7B-CoT DeepSeek-Coder-7B Qwen2-7B Qwen2-Math-7B Qwen-2-Math-Base Internlm2-math-plus-7B Qwen2.5-Coder-7B Qwen2.5-Coder-7B Qwen2.5-Coder-7B Qwen2.5-Coder-7B Qwen2.5-Coder-7B Qwen2.5-Coder-7B Qwen2.5-Coder-7B Qwen2.5-Coder-7B DeepSeekMath-7B-RL GPT-4 GPT-4 GPT-4 GPT-4 GPT-4 GPT-4 GPT-4o-mini GSM8k MATH 38.0% 51.0% 42.1% 67.8% 59.4% 74.0% 40.0% 40.0% 58.2% 59.0% 66.5% 72.6% 73.7% 56.7% 85.5% 89.0% 75.4% 77.4% 79.9% 80.4% 81.5% 84.0% 84.1% 85.7% 85.8% 86.4% 86.7% 87.0% 87.0% 88.5% 88.2% 93.7% 94.5% 95.0% 95.6% 96.5% 96.8% 96.0% - - - 30.2% - - 7.0% 10.7% 16.0% 19.0% - - - 20.3% 41.4% 53.8% 55.2% 44.4% 44.2% 50.4% 50.0% 54.4% 72.3% 72.1% 71.4% 71.9% 70.9% 71.4% 71.1% 73.2% 51.7% - - - - - - 79.1% Experimental Results: As shown in Table 2, SoT achieved 96.0% on GSM8K and 79.1% on MATH on GPT-4o-mini. On GSM8K, SoTs Figure 5: Betti Number Sensitivity Analysis performance is close to the best result achieved by GPT-4 (e.g., MathDivides 96.8%) [5] and outperforms the best 7B model (e.g., OMI2 Fulls 88.5%) [5]. On MATH, SoTs 79.1% significantly outperforms the best mainstream 7B models (e.g., OMI2 Fulls 73.2%). This result indicates that SoT can achieve reasoning capabilities close to those of closed-source large models on lightweight models, significantly narrowing the performance gap between open-source models and GPT-4, validating its superiority in complex mathematical reasoning."
        },
        {
            "title": "4.3 Betti Number Sensitivity\nThe SoT reasoning chain regulates topological constraints through\nthe Betti number, and its value directly affects performance. To\ninvestigate the optimal configuration of the Betti number and its\ndynamic impact on structural expressiveness and regularization\neffects, we designed ablation experiments to reveal its key role\nin optimizing the reasoning process. For this, we systematically\nadjusted the Betti number and recorded accuracy changes under\ndifferent mapping configurations. The goal of the experiment was\nto analyze the impact of the Betti number on the reasoning chain’s\nexpressiveness and identify the performance saturation point. The\nresults are presented in Figure 5, showing the trend of accuracy\nchanges with varying Betti numbers, with particular attention to\nits non-monotonic properties and optimal configuration.\nExperimental Configuration: The experiment was based on GPT-\n4o-mini and conducted on the GSM8K dataset. The Betti number\nwas incremented from 1 to 10, with mapping set to 1, 2, and 3 to\nevaluate performance under different topological decomposition\ngranularities.\nExperimental Results: As shown in Figure 5, accuracy changed\nnon-monotonically as the Betti number increased under mapping\nconfigurations of 1, 2, and 3. Specifically, when the Betti number\nstarted from 1, accuracy improved significantly, indicating that\na small number of topological constraints effectively enhanced\nstructural expressiveness. However, as the Betti number increased\nfurther, the performance gain gradually diminished and stabilized.\nThe optimal saturation point was reached at 7, beyond which there\nwas no noticeable improvement. The results reveal the dynamic\nregulatory effect of the Betti number in reasoning chain modeling,\nand that moderate topological constraints are crucial for optimizing",
            "content": "SoTs structured design, providing strong support for its theoretical foundation."
        },
        {
            "title": "4.4 Stability Analysis",
            "content": "Li et al. Figure 6: Accuracy(%) of the SoT method under different temperatures. The temperature parameter influences the diversity of content generated by LLMs, which may challenge reasoning stability. We aimed to explore whether the SoT method could maintain its performance advantage under varying temperature conditions, thereby validating the adaptability of its structured design. To this end, we systematically evaluated SoT and CoT under different temperature conditions, focusing on the stability of accuracy and the relationship between reasoning diversity and consistency. The experiment involved adjusting the temperature step by step and observing the performance trends of the two methods under changing diversity. Experimental Configuration: The experiment was based on GPT4o-mini, with the Betti number fixed at 7 and mapping set to 3. The nine test datasets included GSM8K, SVAMP, MultiArith, ASDiv, AQUA (mathematical reasoning), MMLU (generalization), BBH, Date (multi-task QA), and CLUTRR (logical reasoning). The temperature parameter was adjusted from 0.0 to 1.0 in steps of 0.1, and the performance of SoT and CoT was compared. Five reasoning paths Figure 7: Box plot comparison of accuracy (%) between SoT (Ours) and CoT methods across multiple tasks. Figure 8: Accuracy(%) of the CoT method under different temperatures. were generated in each experiment, and the average accuracy was recorded to reduce the impact of randomness. Experimental Results:As shown in Figure 6, the accuracy of SoT across multiple datasets varies minimally with temperature (from 0.0 to 1.0), exhibiting stability with small amplitude. Figure 8indicates that the accuracy of CoT fluctuates significantly within the same temperature range, with the amplitude increasing as the temperature rises, especially at high temperatures (close to 1.0), where the fluctuations become more pronounced. The boxplot in Figure 7further compares the accuracy distributions of both methods across datasets: the box of SoT is relatively small, with few outliers, and its accuracy is concentrated with high consistency across datasets, even at high temperatures, without significant outliers. In contrast, the box of CoT is larger, with more scattered distribution and more outliers, especially at high temperatures, where the reasoning consistency diminishes. Analysis suggests that the high temperature-induced diversity in CoT weakens logical coherence, while SoT maintains reasoning stability."
        },
        {
            "title": "5 CONCLUSION\nIn this paper, we introduce the SoT reasoning framework, integrat-\ning the MFR principle from algebraic geometry and homological\nalgebra into the CoT paradigm, significantly enhancing LLM perfor-\nmance in complex reasoning tasks. SoT addresses traditional CoT\nlimitations in high-dimensional, nonlinear, and logical scenarios by\nemploying a structured decomposition strategy—utilizing Module,\nFreeness, Mapping, Exactness, Minimality, and Betti numbers—to\ncreate compact, logically consistent reasoning units.",
            "content": "While SoT has shown excellent reasoning capabilities with LLMs, further exploration is needed. We plan to extend the topological decomposition to multimodal reasoning, including inputs like images and tables, to verify its adaptability in cross-modal tasks. Additionally, incorporating iterative MFR concepts will enhance step-bystep problem refinement, optimizing reasoning paths dynamically and improving SoTs efficiency and accuracy in multimodal and high-dimensional tasks. Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution REFERENCES [1] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, et al. 2024. Graph of thoughts: Solving elaborate problems with large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 38. 1768217690. [2] Nicolás Botbol, Alicia Dickenstein, and Hal Schenck. 2021. The Simplest Minimal Free Resolutions in 1 1. In Commutative Algebra: Expository Papers Dedicated to David Eisenbud on the Occasion of his 75th Birthday. Springer, 113145. [3] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 18771901. [4] Antonio Capani, Gabriel De Dominicis, Gianfranco Niesi, and Lorenzo Robbiano. 1997. Computing minimal finite free resolutions. Journal of Pure and Applied Algebra 117 (1997), 105117. [5] Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, and Wangxiang Che. 2025. Towards reasoning era: survey of long chain-of-thought for reasoning large language models. arXiv preprint arXiv:2503.09567 (2025). [6] Ri-Xiang Chen. 2011. Hilbert functions and free resolutions. (2011). [7] Wenhu Chen, Xueguang Ma, Xinyi Wang, and William Cohen. 2022. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588 (2022). [8] Yezeng Chen, Zui Chen, and Yi Zhou. 2024. Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes. arXiv preprint arXiv:2403.00800 (2024). [9] Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan Gu. 2024. Self-play fine-tuning converts weak language models to strong language models. arXiv preprint arXiv:2401.01335 (2024). [10] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 (2021). [11] Yuntian Deng, Yejin Choi, and Stuart Shieber. 2024. From explicit cot to implicit cot: Learning to internalize cot step by step. arXiv preprint arXiv:2405.14838 (2024). Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers). 41714186. [13] David Eisenbud. 2013. Commutative algebra: with view toward algebraic geom- [12] etry. Vol. 150. Springer Science & Business Media. [14] David Eisenbud, Daniel Grayson, Mike Stillman, and Bernd Sturmfels. 2001. Computations in algebraic geometry with Macaulay 2. Vol. 8. Springer Science & Business Media. [15] Graham Evans and Phillip Griffith. 1981. The syzygy problem. Annals of mathematics 114, 2 (1981), 323333. [16] Nathan Fieldsteel and Uwe Nagel. 2021. Minimal and cellular free resolutions over polynomial OI-algebras. arXiv preprint arXiv:2105.08603 (2021). [17] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen. 2023. Tora: tool-integrated reasoning agent for mathematical problem solving. arXiv preprint arXiv:2309.17452 (2023). [18] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring Mathematical Problem Solving With the MATH Dataset. NeurIPS (2021). [19] Nigel Hitchin. 2003. Generalized calabiyau manifolds. Quarterly Journal of Mathematics 54, 3 (2003), 281308. [20] Shima Imani, Liang Du, and Harsh Shrivastava. 2023. Mathprompter: Mathematical reasoning using large language models. arXiv preprint arXiv:2303.05398 (2023). [23] [21] Mingyu Jin, Qinkai Yu, Dong Shu, Haiyan Zhao, Wenyue Hua, Yanda Meng, Yongfeng Zhang, and Mengnan Du. 2024. The impact of reasoning step length on large language models. arXiv preprint arXiv:2401.04925 (2024). [22] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems 35 (2022), 2219922213. Joshua Ong Jun Leang, Aryo Pradipta Gema, and Shay Cohen. 2024. CoMAT: Chain of mathematically annotated thought improves mathematical reasoning. arXiv preprint arXiv:2410.10336 (2024). [24] Chengshu Li, Jacky Liang, Andy Zeng, Xinyun Chen, Karol Hausman, Dorsa Sadigh, Sergey Levine, Li Fei-Fei, Fei Xia, and Brian Ichter. 2023. Chain of code: Reasoning with language model-augmented code emulator. arXiv preprint arXiv:2312.04474 (2023). Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, and Junxian He. 2025. CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction. [25] arXiv preprint arXiv:2502.07316 (2025). [26] Xiaoliang Li, Chenqi Mou, Wei Niu, and Dongming Wang. 2011. Stability analysis for discrete biological models using algebraic methods. Mathematics in Computer Science 5 (2011), 247262. [27] Yue Liu, Jiaying Wu, Yufei He, Hongcheng Gao, Hongyu Chen, Baolong Bi, Jiaheng Zhang, Zhiqi Huang, and Bryan Hooi. 2025. Efficient Inference for Large Reasoning Models: Survey. arXiv preprint arXiv:2503.23077 (2025). [28] Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023. Faithful chain-of-thought reasoning. In The 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL 2023). [29] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. 2023. Self-refine: Iterative refinement with self-feedback. Advances in Neural Information Processing Systems 36 (2023), 4653446594. [30] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth. 2023. Recent advances in natural language processing via large pre-trained language models: survey. Comput. Surveys 56, 2 (2023), 140. [31] Hoang Nguyen, Ye Liu, Chenwei Zhang, Tao Zhang, and Philip Yu. 2023. CoF-CoT: Enhancing large language models with coarse-to-fine chain-of-thought prompting for multi-domain NLU tasks. arXiv preprint arXiv:2310.14623 (2023). [32] Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, and Yu Wang. 2023. Skeleton-of-thought: Large language models can do parallel decoding. Proceedings ENLSP-III (2023). Joseph Polchinski. 1994. What is string theory? arXiv preprint hep-th/9411028 (1994). [33] [34] Xiaoye Qu, Yafu Li, Zhaochen Su, Weigao Sun, Jianhao Yan, Dongrui Liu, Ganqu Cui, Daizong Liu, Shuxian Liang, Junxian He, et al. 2025. Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond. arXiv preprint arXiv:2503.21614 (2025). [35] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018. Improving language understanding by generative pre-training. (2018). [36] Leonardo Ranaldi, Marco Valentino, Alexander Polonsky, and Andrè Freitas. 2025. Improving chain-of-thought reasoning via quasi-symbolic abstractions. arXiv preprint arXiv:2502.12616 (2025). [37] Maria Evelina Rossi and Leila Sharifan. 2009. Minimal free resolution of finitely generated module over regular local ring. Journal of Algebra 322, 10 (2009), 36933712. [38] Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin. 2023. Algorithm of thoughts: Enhancing exploration of ideas in large language models. arXiv preprint arXiv:2308.10379 (2023). [39] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Schärli, and Denny Zhou. 2023. Large language models can be easily distracted by irrelevant context. In International Conference on Machine Learning. PMLR, 3121031227. [40] Saksham Sahai Srivastava and Ashutosh Gandhi. 2024. MathDivide: Improved mathematical reasoning by large language models. arXiv preprint arXiv:2405.13004 (2024). [41] Gilbert Stewart. 1993. On the early history of the singular value decomposition. SIAM review 35, 4 (1993), 551566. [42] Yang Sui, Yu-Neng Chuang, Guanchu Wang, Jiamu Zhang, Tianyi Zhang, Jiayi Yuan, Hongyi Liu, Andrew Wen, Hanjie Chen, Xia Hu, et al. 2025. Stop Overthinking: Survey on Efficient Reasoning for Large Language Models. arXiv preprint arXiv:2503.16419 (2025). [43] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017). [44] Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and Huan Sun. 2022. Towards understanding chain-of-thought prompting: An empirical study of what matters. arXiv preprint arXiv:2212.10001 (2022). [45] Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2023. Mathcoder: Seamless code integration in llms for enhanced mathematical reasoning. arXiv preprint arXiv:2310.03731 (2023). [46] Xinyi Wang, Lucas Caccia, Oleksiy Ostapenko, Xingdi Yuan, William Yang Wang, and Alessandro Sordoni. 2023. Guiding language model reasoning with planning tokens. arXiv preprint arXiv:2310.05707 (2023). [47] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 (2022). [48] Larry Wasserman. 2018. Topological data analysis. Annual review of statistics and its application 5, 2018 (2018), 501532. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems 35 (2022), 2482424837. [49] [50] Ting-Ruen Wei, Haowei Liu, Xuyang Wu, and Yi Fang. 2025. survey on feedback-based multi-step reasoning for large language models on mathematics. arXiv preprint arXiv:2502.14333 (2025). [51] Volker Weispfenning. 1992. Comprehensive gröbner bases. Journal of symbolic computation 14, 1 (1992), 129. [52] Yu Xia, Rui Wang, Xu Liu, Mingyan Li, Tong Yu, Xiang Chen, Julian McAuley, and Shuai Li. 2024. Beyond chain-of-thought: survey of chain-of-x paradigms for llms. arXiv preprint arXiv:2404.15676 (2024). [53] Fangzhi Xu, Qiushi Sun, Kanzhi Cheng, Jun Liu, Yu Qiao, and Zhiyong Wu. 2024. Interactive evolution: neural-symbolic self-training framework for large language models. arXiv preprint arXiv:2406.11736 (2024). [54] Ling Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph Gonzalez, and Bin Cui. 2025. Buffer of thoughts: Thought-augmented reasoning with large language models. Advances in Neural Information Processing Systems 37 (2025), 113519113544. [55] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving with large language models. Advances in neural information processing systems 36 (2023), 1180911822. [56] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023. React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR). [57] Dian Yu, Baolin Peng, Ye Tian, Linfeng Song, Haitao Mi, and Dong Yu. 2024. Siam: Self-improving code-assisted mathematical reasoning of large language models. arXiv preprint arXiv:2408.15565 (2024). [58] Fei Yu, Anningzhe Gao, and Benyou Wang. 2023. Ovm, outcome-supervised value models for planning in mathematical reasoning. arXiv preprint arXiv:2311.09724 (2023). Li et al. [59] Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023. Metamath: Bootstrap your own mathematical questions for large language models. arXiv preprint arXiv:2309.12284 (2023). [60] Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2023. Mammoth: Building math generalist models through hybrid instruction tuning. arXiv preprint arXiv:2309.05653 (2023). [61] Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. 2022. Star: Bootstrapping reasoning with reasoning. Advances in Neural Information Processing Systems 35 (2022), 1547615488. [62] Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493 (2022). [63] Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing. 2023. Verify-and-edit: knowledge-enhanced chain-of-thought framework. arXiv preprint arXiv:2305.03268 (2023). [64] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. survey of large language models. arXiv preprint arXiv:2303.18223 1, 2 (2023). [65] Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed Chi, Quoc Le, and Denny Zhou. 2023. Take step back: Evoking reasoning via abstraction in large language models. arXiv preprint arXiv:2310.06117 (2023). [66] Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. 2022. Least-tomost prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625 (2022)."
        }
    ],
    "affiliations": [
        "Capital Normal University, Beijing, China",
        "Kyung Hee University, Yongin-si, Republic of Korea",
        "Tongji University, Shanghai, China",
        "University of Electronic Science and Technology of China, Chengdu, China",
        "University of Liverpool, Liverpool, United Kingdom"
    ]
}