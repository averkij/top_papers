{
    "paper_title": "mStyleDistance: Multilingual Style Embeddings and their Evaluation",
    "authors": [
        "Justin Qiu",
        "Jiacheng Zhu",
        "Ajay Patel",
        "Marianna Apidianaki",
        "Chris Callison-Burch"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Style embeddings are useful for stylistic analysis and style transfer; however, only English style embeddings have been made available. We introduce Multilingual StyleDistance (mStyleDistance), a multilingual style embedding model trained using synthetic data and contrastive learning. We train the model on data from nine languages and create a multilingual STEL-or-Content benchmark (Wegmann et al., 2022) that serves to assess the embeddings' quality. We also employ our embeddings in an authorship verification task involving different languages. Our results show that mStyleDistance embeddings outperform existing models on these multilingual style benchmarks and generalize well to unseen features and languages. We make our model publicly available at https://huggingface.co/StyleDistance/mstyledistance ."
        },
        {
            "title": "Start",
            "content": "MSTYLEDISTANCE: Multilingual Style Embeddings and their Evaluation Justin Qiu* Jiacheng Zhu*"
        },
        {
            "title": "Marianna Apidianaki",
            "content": "Chris Callison-Burch University of Pennsylvania {jsq, jiachzhu, ajayp, marapi, ccb}@seas.upenn.edu 5 2 0 2 1 2 ] . [ 1 8 6 1 5 1 . 2 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Style embeddings are useful for stylistic analysis and style transfer; however, only English style embeddings have been made available. We introduce Multilingual STYLEDISTANCE (MSTYLEDISTANCE), multilingual style embedding model trained using synthetic data and contrastive learning. We train the model on data from nine languages and create multilingual STEL-or-Content benchmark (Wegmann et al., 2022) that serves to assess the embeddings quality. We also employ our embeddings in an authorship verification task involving different languages. Our results show that MSTYLEDISTANCE embeddings outperform existing models on these multilingual style benchmarks and generalize well to unseen features and languages. We make our model publicly available at https://huggingface. co/StyleDistance/mstyledistance."
        },
        {
            "title": "Introduction",
            "content": "Style embedding models seek to embed texts with similar style closer in the embedding space regardless of their content. Style embeddings are useful for tasks like style transfer and authorship attribution, but only exist for English (Wegmann et al., 2022; Patel et al., 2024b). Multilingual style embeddings could also serve to automatically evaluate style preservation in machine translation. Models like XLM-RoBERTa (Conneau et al., 2019) and E5 (Wang et al., 2024) create multilingual representations for semantic tasks, but have not addressed style mainly due to the scarcity of style datasets. We propose procedure, called multilingual STYLEDISTANCE (MSTYLEDISTANCE), to train style embeddings using contrastive learning with synthetic data in multiple languages. Early work on style representations learning often involved unlabeled social media data (Hay et al., 2020; Wegmann et al., 2022; Rivera-Soto et al., 2021; Patel *Denotes equal contribution 1 Figure 1: MSTYLEDISTANCE is trained using contrastive learning from synthetic positive and negative examples of 40 style features in 9 languages to form both multilingual and cross-lingual training triplets. et al., 2023), but Patel et al. (2024b) showed that contrastive learning objective with synthetic examples (sentence pairs with similar content and different style) can generate high quality style representations for English. We create MSYNTHSTEL, synthetic dataset of paraphrases addressing various style features in nine languages, and use it to create our multilingual style embeddings. In order to evaluate their quality, we contribute new multilingual and cross-lingual STEL-orContent (SoC) evaluation benchmark which, following the original SoC evaluation task (Wegmann et al., 2022), measures the ability of model to embed sentences with the same style closer in the embedding space than sentences with the same content. We show that MSTYLEDISTANCE embeddings outperform other representations on these evaluations, and demonstrate their usefulness in downstream setting addressing multilingual authorship verification task. We publicly release our model, data, and evaluation benchmarks."
        },
        {
            "title": "2 Multilingual Synthetic Data",
            "content": "We extend the Patel et al. (2024b) dataset to nine languages (L): Arabic, German, Spanish, French, Hindi, Japanese, Korean, Russian, and Chinese.1 Style Feature Selection We use the set of 40 features addressed in Patel et al. (2024b), leaving out features not applicable to specific languages. For example, articles are not relevant for Chinese and Japanese so the corresponding features have been discarded. Our set of features (F ) includes syntactic features (e.g., active/passive voice, contractions, frequent use of function words), emotional and cognitive features (e.g., words indicating sentiment or cognitive processes), stylistic and aesthetic features (e.g., metaphors, formal tone), social and interpersonal features (e.g., polite or offensive tone), graphical and digital features (e.g., capitalization, emojis, numerical digits), temporal and aspectual features (e.g., focus on present or future).2 Data Generation For each retained feature for language L, we generate 100 pairs of positive (pos) and negative (neg) examples (paraphrases). In each pair, pos is sentence that contains the style feature (e.g., formal sentence or metaphorical one) while neg does not. This is illustrated in Figure 1 for the feature Active Voice. Features that cannot be removed completely (e.g., usage of articles) are present with higher frequency in pos than in neg examples. Using the same prompting workflow as Patel et al. (2024b), we generate sentence pairs by prompting GPT-4 with the DataDreamer library and an attributed prompt (Yu et al., 2023) illustrated in Figure 2 (OpenAI et al., 2024; Patel et al., 2024a). For diversity, Topic for each generation is sampled by extracting random sentence from random document in the C4 corpus (Raffel et al., 2020), and prompting GPT-4 to identify the topic. For further details on all prompts, see Appendix B. We experiment with two approaches to multilingual data generation. In our first approach, sentence pairs are directly generated in each using language-specific instruction in the prompt, as illustrated in Figure 2. In our second approach, English 1These languages were chosen because they align with the linguistic background of our annotators. 2A full list of features and details is given in Appendix A. Generate pair of active and passive Russian sentences with the following attributes: 1. Topic: Brake parts and components 2. Length: 15-20 words 3. Point of view: second-person 4. Tense: past 5. Type of Sentence: Exclamation Figure 2: Example prompt for generating pair of sentences in Russian. sentence pairs are generated using the prompting workflow and then translated into each target language L.3 We generate data using both methods and conduct human validation on random 10% split in order to determine the best approach for each language. Each sentence pair for style feature creates two annotation task instances. For each task instance of given style feature and the positive or negative sentence, we asked annotators4 to provide: 1) judgment on if the style feature is present in the sentence, and 2) rating of the fluency. We only considered instances annotated by at least three annotators. Inter-annotator agreement was Î± = 0.4247 (Krippendorff, 2011). More details on the annotation can be found in Appendix C. We calculate an aggregate feature presence accuracy score for each by calculating whether the average feature presence score over all annotations is higher for the positive sentence than for the negative sentence in pair.5 We calculate an aggregate fluency score by taking an average of the fluency scores that each annotator gave each text.6 We selected the best approach (direct generation v.s. English MT) for each as the one that produced the most fluent sentences, or the highest feature presence score if both produced similarly fluent generations. The direct approach was selected for all languages in except for Japanese and Hindi. Our final average feature presence and fluency scores over all L, with the best generation approach selected for each l, are 0.79 and 0.93, respectively, both above random chance (0.5). Detailed results by language are given in Appendix D. 3We use DeepL for all languages except for Hindi which is not supported, where we use Google Translate instead. 4MS and undergraduate students native speakers of language, who were offered extra credit for participation. 5We assign 1 for Yes, 0.5 for Possibly, and 0 for No. 6We assign score of 1 for \"Fluent\", 0.67 for Mostly Fluent, 0.33 for Mostly Disfluent, and 0 for Disfluent. 2 Data Validation Following Patel et al. (2024b), we also perform automatic validations of the generated data. We validate whether our parallel examples are indeed paraphrases by computing their average cosine similarity7 (Reimers and Gurevych, 2019). For comparison, we calculate the similarity of gold-standard paraphrases in the multilingual dataset compiled by Scherrer (2020)8 for each language. The average similarity of our parallel examples is 0.91 which is comparable to that calculated on the Scherrer (2020) natural data (0.88), indicating that our pairs are reasonable paraphrases. We measure topic diversity across generated sentences for using the metric proposed by Yang et al. (2024) which relies on cosine distance.9 For comparison, we also compute the diversity score for texts from Scherrer (2020). Again, the two scores are comparable (0.83 vs. 0.85), showing that our examples approach the diversity of natural data. Detailed results can be found in Appendix D."
        },
        {
            "title": "3 Training MSTYLEDISTANCE",
            "content": "Following the contrastive training approach of Patel et al. (2024b), we construct feature-specific triples for each language which contain: an anchor text (a); text with the same style as but different content (pos); distractor text (neg) which is paraphrase of or pos, but different in style from a. We use the multilingual xlm-roberta-base as our base model and train with triplet loss (Conneau et al., 2019; Schroff et al., 2015). We ensure half of our triplets are cross-lingual, i.e. the pos and neg texts are randomly sampled from different language than the anchor text. Full training details can be found in Appendix E."
        },
        {
            "title": "4 Evaluation",
            "content": "STEL-or-Content (SoC) Benchmark In order to evaluate our style embeddings, we construct multilingual version of the SoC benchmark (Wegmann et al., 2022).10 SoC measures the ability of model to embed sentences with the same style closer in the embedding space than sentences with the same content. We construct our multilingual SoC benchmark by sampling 100 pairs of parallel pos-neg examples for each language from four 7We use paraphrase-multilingual-mpnet-base-v2. 8We sample 100 rows of paraphrases from Scherrer (2020). 9In this case, we only evaluate the pos sentence which contains the style feature for each pair. 10The English SoC benchmark covered formality, complexity, number usage, contraction usage, and emoji usage. ground-truth datasets covering four style features and 22 languages: simplicity (Ryan et al., 2023), formality (Briakou et al., 2021), toxicity (Dementieva et al., 2024), and positivity (Mukherjee et al., 2024).11 Each instance in our multilingual SoC benchmark consists of triplet (a, pos, neg) constructed as explained in Section 3. However, following Wegmann et al. (2022), the distractor text in our SoC benchmark is always paraphrase of pos. model tested on this benchmark is expected to embed and pos closer than and neg. We rate model by computing the percent of instances it achieves this goal for across all instances. We form test instances for each in language corresponding to all possible triplets, resulting in 4,950 instances for each language-style combination. We also construct cross-lingual SoC benchmark that addresses embeddings ability to capture style similarity across languages. This can be useful, for example, to evaluate style preservation in translations. We construct the benchmark with the XFormal dataset (Briakou et al., 2021), which includes parallel data in French, Italian and Portuguese. We again create triplets as described above, but instead of using pos and neg texts from the same language as the anchor (a), we sample them from different language than a. We end up with 19,800 instances for each style in each language. Appendix contains illustrative examples from each benchmark. SoC Evaluation Results The results obtained by MSTYLEDISTANCE on the multilingual and crosslingual SoC benchmarks are presented in Table 1. As no general multilingual style embeddings are currently available, we compare with base multilingual encoder model xlm-roberta-base (Conneau et al., 2019) as well as number of English-trained style embedding models applied in zero-shot fashion to multilingual text: Wegmann et al. (2022), STYLEDISTANCE embeddings (Patel et al., 2024b), and LISA (Patel et al., 2023). MSTYLEDISTANCE embeddings outperform these models on multilingual and cross-lingual SoC tasks confirming its suitability for multilingual applications. The other models perform slightly better than the untrained xlm-roberta-base but still worse than MSTYLEDISTANCE. 11Combined, these datasets cover the following languages: Amharic, Arabic, Bengali, German, English, Spanish, French, Hindi, Italian, Japanese, Magahi, Malayalam, Marathi, Odia, Punjabi, Portuguese (Brazil), Russian, Slovenian, Telugu, Ukrainian, Urdu, and Chinese."
        },
        {
            "title": "Model",
            "content": "Simplicity Formality Toxicity Positivity Formality (cross-lingual) Wegmann et al. (2022) STYLEDISTANCE xlm-roberta-base LISA MSTYLEDISTANCE 0.23 0.21 0.12 0.15 0.36 0.63 0.67 0.16 0.09 0.71 0.19 0.15 0.09 0.09 0.37 0.23 0.18 0.07 0.21 0. 0.45 0.49 0.19 0.27 0.53 Table 1: Performance on the multilingual and cross-lingual STEL-or-content benchmarks, averaged across languages for each style feature. MSTYLEDISTANCE leads in cross-lingual and overall performance. PAN 2013 PAN 2014 PAN"
        },
        {
            "title": "Greek Spanish Greek Spanish Dutch Greek Spanish Dutch Greek Spanish Dutch Overall",
            "content": "Wegmann et al. (2022) STYLEDISTANCE LISA MSTYLEDISTANCE 0.66 0.61 0.51 0.41 0.87 0.62 0.64 0.78 0.56 0.48 0.46 0.53 0.54 0.51 0.56 0.56 0.59 0.65 0.62 0. 0.47 0.47 0.48 0.58 0.61 0.73 0.66 0.53 0.59 0.59 0.48 0.38 0.56 0.52 0.48 0.64 0.67 0.62 0.62 0.73 0.59 0.62 0.55 0. 0.61 0.59 0.55 0.66 Table 2: Results on the PAN 2013-2015 AV shared task for Greek, Spanish, and Dutch. We report performance separately on each PAN dataset and average performance across datasets for the same language. We use the standard ROC-AUC metric for AV."
        },
        {
            "title": "Features Tested",
            "content": "m avg avg In-Domain Out of Domain Out of Distribution No Language Overlap 0.38 0.31 0.31 0.35 0.53 0.44 0.40 0.52 Retained Perf (%) 100% 75% 75% 89% 100% 74% 62% 97% Table 3: MSTYLEDISTANCE embeddings under three generalization conditions on the multilingual (m avg) and cross-lingual (c avg) STEL-or-Content tasks. Ablation Experiments Following (Patel et al., 2024b), we run several ablation experiments to evaluate how well our model generalizes to unseen style features and languages. In the In-Domain condition, all style features are included in the training data for every language. To test generalization to unseen style features, in the Out of Domain condition, any style feature directly equivalent to those features tested in the Multilingual and Crosslingual SoC benchmarks are excluded from the training data. Out of Distribution further removes any style features indirectly similar or related to those tested in the benchmarks. Finally, No Language Overlap removes the languages present in the benchmark from the training data, in order to test generalization to new languages. Our results are given in Table 3 where we measure how much of the performance increase on SoC benchmarks over the base model is retained, despite ablating training data. The results indicate that our method generalizes reasonably well to both out of domain and out of distribution style features, and very well to languages not in the training data. Further details on features and languages ablated and full results are provided in Appendices and H. et Downstream Task Following Patel al. (2024b), we also evaluate our MSTYLEDISTANCE embeddings in the authorship verification (AV) task, where the goal is to determine if two documents were written by the same author using stylistic features (Koppel and Winter, 2014). We use the datasets released by PAN12 between 2013 and 2015 in Greek, Spanish, and Dutch. Our results are given in Table 2. MSTYLEDISTANCE vectors outperform existing English style embedding models on Spanish and Greek, while Dutch shows similar performance to English STYLEDISTANCE. the linguistic proximity We hypothesize that (West Germanic roots) of the two languages helps STYLEDISTANCE to generalize to Dutch."
        },
        {
            "title": "5 Conclusion",
            "content": "We introduced novel approach to learning multilingual style embeddings from synthetic examples, and contribute two benchmarks for evaluating the quality of multilingual style representations. We show that MSTYLEDISTANCE embeddings are able to distinguish style from content better than other English and multilingual embeddings, and generalize well to unseen features and languages. The authorship verification evaluation shows that MSTYLEDISTANCE embeddings also offer strong performance on multilingual downstream tasks. 12https://pan.webis.de"
        },
        {
            "title": "Limitations",
            "content": "Our synthetic data generation approaches rely on direct generation or machine translation techniques, both of which have limitations for languages other than English. Most of the languages included in our multilingual and cross-lingual STEL-orContent and authorship evaluations are not really low-resource, so our evaluations may not reflect performance in languages with less resources. Furthermore, our approach only targets the 33-40 style features (depending on the language) we generated data for, and cannot account for the wide range of possibilities for style. While these drawbacks may limit our approach, our ablation experiments show strong generalization capabilities to unseen languages and style features indicating promising generalized performance."
        },
        {
            "title": "Ethical Considerations",
            "content": "This work demonstrates the potential of using synthetic data for creating style embeddings in languages lacking such resources, increasing access to broader communities. However, it is important to recognize that the synthetic data generated by large language models may reflect and reinforce existing biases inherent in these models (Patel et al., 2023). While our approach shows significant promise, ongoing efforts should ensure that such synthetic datasets are evaluated for fairness and bias to promote more equitable outcomes."
        },
        {
            "title": "Contribution Statement",
            "content": "Justin Qiu created the SoC benchmarks and performed most of the evaluations. Jiacheng Zhu created MSYNTHSTEL by carrying out data generation and human annotation collection. Ajay Patel trained MSTYLEDISTANCE. Marianna Apidianaki helped greatly with advising and the final version of the manuscript. Chris Callison-Burch also gave us valuable advice as our advisor. All authors contributed to the final manuscript."
        },
        {
            "title": "Acknowledgements",
            "content": "This research is supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via the HIATUS Program contract #2022-22072200005. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein."
        },
        {
            "title": "References",
            "content": "Eleftheria Briakou, Di Lu, Ke Zhang, and Joel Tetreault. 2021. OlÃ¡, bonjour, salve! XFORMAL: benchmark for multilingual formality style transfer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 31993216, Online. Association for Computational Linguistics. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. In Annual Meeting of the Association for Computational Linguistics. Daryna Dementieva, Daniil Moskovskiy, Nikolay Babakov, Abinew Ali Ayele, Naquee Rizwan, Frolian Schneider, Xintog Wang, Seid Muhie Yimam, Dmitry Ustalov, Elisei Stakovskii, Alisa Smirnova, Ashraf Elnagar, Animesh Mukherjee, and Alexander Panchenko. 2024. Overview of the multilingual text detoxification task at pan 2024. In Working Notes of CLEF 2024 - Conference and Labs of the Evaluation Forum. CEUR-WS.org. Julien Hay, Bich-LiÃªn Doan, Fabrice Popineau, and Ouassim Ait Elhara. 2020. Representation learning of writing style. In Proceedings of the 6th Workshop on Noisy User-generated Text (W-NUT 2020). Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. Preprint, arXiv:2106.09685. Moshe Koppel and Yaron Winter. 2014. Determining if two documents are written by the same author. Journal of the Association for Information Science and Technology, 65(1):178187. Klaus Krippendorff. 2011. Computing krippendorffs alpha-reliability. Sourabrata Mukherjee, Atul Kr. Ojha, Akanksha Bansal, Deepak Alok, John P. McCrae, and OndËrej DuÅ¡ek. 2024. Multilingual text style transfer: Datasets i& models for indian languages. Preprint, arXiv:2405.20805. OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, 5 Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, SimÃ³n Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha GontijoLopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Åukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Åukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David MÃ©ly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen OKeefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe CerÃ³n Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2024. Gpt-4 technical report. Preprint, arXiv:2303.08774. Ajay Patel, Colin Raffel, and Chris Callison-Burch. 2024a. DataDreamer: tool for synthetic data generation and reproducible LLM workflows. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 37813799, Bangkok, Thailand. Association for Computational Linguistics. Ajay Patel, Delip Rao, Ansh Kothary, Kathleen McKeown, and Chris Callison-Burch. 2023. Learning interpretable style embeddings via prompting LLMs. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1527015290, Singapore. Association for Computational Linguistics. Ajay Patel, Jiacheng Zhu, Justin Qiu, Zachary Horvitz, Marianna Apidianaki, Kathleen McKeown, and Chris Callison-Burch. 2024b. Styledistance: Stronger content-independent style embeddings with synthetic parallel examples. Preprint, arXiv:2410.12757. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter Liu. 2020. Exploring the limits of transfer learning with unified text-to-text transformer. Journal of Machine Learning Research, 21:16. Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 39823992. Rafael Rivera-Soto, Olivia Elizabeth Miano, Juanita Ordonez, Barry Chen, Aleem Khan, Marcus Bishop, and Nicholas Andrews. 2021. Learning universal authorship representations. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 913919. Michael Ryan, Tarek Naous, and Wei Xu. 2023. Revisiting non-English text simplification: unified 6 multilingual benchmark. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4898 4927, Toronto, Canada. Association for Computational Linguistics. Yves Scherrer. 2020. TaPaCo: corpus of sentential paraphrases for 73 languages. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 68686873, Marseille, France. European Language Resources Association. Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. Facenet: unified embedding for face recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 815823. Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei. 2024. Multilingual e5 text embeddings: technical report. Preprint, arXiv:2402.05672. Anna Wegmann, Marijn Schraagen, Dong Nguyen, et al. 2022. Same author or just same topic? towards content-independent style representations. In Proceedings of the 7th Workshop on Representation Learning for NLP, page 249. Association for Computational Linguistics. Yue Yang, Mona Gandhi, Yufei Wang, Yifan Wu, Michael Yao, Chris Callison-Burch, James Gee, and Mark Yatskar. 2024. textbook remedy for domain shifts: Knowledge priors for medical image analysis. arXiv preprint arXiv:2405.14839. Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander Ratner, Ranjay Krishna, Jiaming Shen, and Chao Zhang. 2023. Large language model as attributed training data generator: tale of diversity and bias. In Advances in Neural Information Processing Systems, volume 36, pages 5573455784. Curran Associates, Inc."
        },
        {
            "title": "A Style Features and Definitions",
            "content": "The style features addressed in our experiments included most of the 40 style features in the Patel et al. (2024b) dataset. In Table 9, we list the 40 style features with an Excluded in column indicating the languages where each feature is not applicable and was therefore omitted from our dataset."
        },
        {
            "title": "B Generation Prompts and Details",
            "content": "Below we detail the structure of our prompts and inference parameters used for two multilingual synthetic data generation methods. B.1 Extracting Topics from C4 We use the same topic extraction method as Patel et al. (2024b), which is derived from the C4 dataset (Raffel et al., 2020), to identify 50,000 topics through zero-shot prompting with GPT-4 (OpenAI et al., 2024). These 50,000 fine-grained, unique topics ensure that each sentence pair has distinct context across various features and languages. We perform topic sampling with temperature setting of 1.0 and top_p = 0.0. What is the fine-grained topic of the following text: {sentence} Only return the topic. The fine-grained topic is used as part of the attributed prompt in Section B.3 to ensure diverse generations. B.2 Generating Positive and Negative Example Sentences for Each Style We use the same prompt as Patel et al. (2024b) to generate positive and negative example sentences in English. We then translate these sentence pairs into the target languages using the DeepL API. The only exception is Hindi, which we translate using Google Translate API due to DeepLs limited language support. B.3 Direct Generating Positive and Negative Example Sentences for Each Style Feature into Target Language For direct generation in target language method (method 2), we use the following prompt with temperature setting of 1.0 and top_p = 1.0 Generate pair of {target language} sentences with and without sarcasm with the following attributes: 1. Topic: {topic} 2. Length: {sentence_length} 3. Point of view: {point_of_view} 4. Tense: {tense} 5. Type of Sentence: {sentence_type} Ensure that the generated sentences meet the following conditions: 1. There is no extra information in one sentence that is not in the other. 2. The difference between the two sentences is subtle. 3. The two sentences have the same length. {special_conditions_for_style_feature} Use Format: With sarcasm: [sentence in {target language}] Without sarcasm: [sentence in {target language}] Your response should only consist of the two sentences, without quotation marks."
        },
        {
            "title": "C Human Annotation Details",
            "content": "Figure 3: Instances from the annotation interface."
        },
        {
            "title": "Similarity",
            "content": "ar de es fr hi ja ko ru zh-hans"
        },
        {
            "title": "Average",
            "content": "0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.7475 1.0000 0.8125 0.7391 0.7595 0.6667 0.8000 0.8000 0.7475 0.7859 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0. 0.9526 0.7708 0.9853 0.9855 0.9958 0.8889 0.8972 0.8972 0.9526 0.8278 0.8345 0.8449 0.8483 0.8588 0.8528 0.8540 0.8542 0.8571 0.8245 0.8341 0.8478 0.8404 0.8253 0.8321 0.8214 0.8097 0.8220 0.9232 0.8799 0.8567 0.8573 0.9468 0.8514 0.8652 0.8713 0.8729 0.9156 0.9171 0.9298 0.9224 0.8903 0.8761 0.9286 0.9171 0.9322 0. 0.8480 0.8286 0.8805 0.9144 Table 4: Human and synthetic evaluations on our synthetic dataset. We show above in Figure 3 an instance from the human annotation interface. We first asked annotators whether given style feature was present in sentence in their chosen language. We also provided definition for each style feature to help annotators in their decision. The annotators then had to rate the fluency of the sentence be selecting one of Fluent, Mostly Fluent, Mostly Disfluent, or Disfluent. Our annotators are undergraduate and graduate students from NLP class and were offered extra credit for their participation in the study. Each instance was annotated by at least three annotators: three for languages with fewer native speakers such as Arabic and Russian; over ten for languages with large number of native speakers, such as Chinese. We used Krippendorffs Alpha (Krippendorff, 2011) to measure inter-annotator agreement, which indicated moderate agreement of 0.4247 0.1719."
        },
        {
            "title": "D Dataset Evaluation",
            "content": "In Table 4, we show the full results of human and synthetic evaluations on our synthetic dataset. Our synthetic dataset is comparable to reference dataset compiled by Scherrer (2020) on feature presence, fluency, diversity, and similarity. Note that baselines shown for feature presence and fluency are just 0.5 to represent random guessing."
        },
        {
            "title": "E Training Details",
            "content": "Table 5 contains details for our hyperparameters for training. More exact training details can be found in the source code provided in the supplementary materials for this work."
        },
        {
            "title": "Triplet Loss Margin",
            "content": "LoRA (Hu et al., 2021) Optimizer Learning Rate Weight Decay Learning Rate Scheduler Warmup Steps Batch Size Train-Validation Split Early Stopping Threshold Early Stopping Patience xlm-roberta-base 4x or 8x NVIDIA RTX A6000 PyTorch FSDP torch.bfloat16 TripletLoss (Schroff et al., 2015) 0.1 all-linear, r=8, lora_alpha=8, lora_dropout=0.0 adamw_torch 1e-4 0.01 linear 0 384 90/10% 0.0 1 epoch Table 5: Hyperparameters selected for contrastive learning training experiments. Instances from the Multilingual and Cross-lingual SoC Benchmarks In our multilingual SoC benchmark, anchor (a) has the same style and different content from positive example (pos), and the same content but different style from negative example (neg). The anchor and the pos and neg sentences are in the same language. The tested model needs to successfully pair with pos (rather than and neg). Crosslingual SoC has the same setup as multilingual SoC, except that the pos and neg examples are in different language than the anchor. Figure 4 contains instances of each benchmark."
        },
        {
            "title": "Ablated Features and Languages",
            "content": "Out-of-Domain Ablated Style Features: Usage of Formal Tone, Usage of Contractions, Usage of Numerical Substitution, Complex Sentence Structure, Usage of Positive Tone, Usage of Offensive Tone, Usage of Polite Tone Out-of-Distribution Ablated Style Features: Usage of Formal Tone, Usage of Polite Tone, Fluency in Sentence Construction, Usage of Only Uppercase Letters, Usage of Only Lowercase Letters, Incorporation of Humor, Usage of Sarcasm, Usage of Contractions, Usage of Numerical Substitution, Usage of Text Emojis, Usage of Emojis, Presence of Misspelled Words, Complex Sentence Structure, Usage of Long Words, Usage of Polite Tone, Usage of Offensive Tone"
        },
        {
            "title": "No Language Overlap",
            "content": "Ablated Languages: ar (Arabic), de (German), es (Spanish), fr (French), hi (Hindi), ja (Japanese), ru (Russian) Table 6: Style features and languages ablated for Out-of-Domain, Out-of-Distribution, and No Language Overlap, the three ablation conditions in our ablation study."
        },
        {
            "title": "Formality",
            "content": "Retained Perf (%) Multi-lingual SoC Cross-lingual SoC In-Domain Out of Domain Out of Distribution No Language Overlap 0.36 0.29 0.33 0.27 0.71 0.63 0.39 0. 0.37 0.31 0.26 0.41 0.30 0.23 0.32 0.32 0.53 0.44 0.40 0.52 100% 75% 75% 89% 100% 74% 62% 97% Table 7: Full results of the ablation study for MSTYLEDISTANCE embeddings on the SoC benchmarks."
        },
        {
            "title": "Details",
            "content": "Full ablation results can be found in Table 6."
        },
        {
            "title": "H Ablation Full Results",
            "content": "Table 7 contains full results of the ablation study for MSTYLEDISTANCE embeddings on the SoC benchmarks under three generalization conditions: Out of Domain, Out of Distribution, and No Language Overlap. For multilingual SoC, we use all four style features: simplicity, formality, toxicity, and positivity. For the cross-lingual variant, we only use formality. Figure 4: Instances from our multilingual and crosslingual SoC benchmarks. For multilingual SoC, the anchor is in the same language as the pos and neg sentences. For cross-lingual SoC, the anchor is in different language from the pos and neg sentences."
        },
        {
            "title": "I Full SoC Results",
            "content": "Language Wegmann et al."
        },
        {
            "title": "STYLEDISTANCE",
            "content": "xlm-roberta-base"
        },
        {
            "title": "MSTYLEDISTANCE",
            "content": "(2022)"
        },
        {
            "title": "Simplicity",
            "content": "de en fr it ja pt-br ru sl average"
        },
        {
            "title": "Formality",
            "content": "fr it pt-br average"
        },
        {
            "title": "Toxicity",
            "content": "am ar de en es hi ru uk zh average"
        },
        {
            "title": "Positivity",
            "content": "bn en hi mag ml mr or pa te ur average 0.23 0.26 0.29 0.21 0.09 0.10 0.26 0.43 0.23 0.70 0.64 0.56 0. 0.35 0.05 0.01 0.56 0.26 0.15 0.18 0.07 0.05 0.19 0.27 0.21 0.11 0.09 0.32 0.19 0.27 0.18 0.39 0.24 0.23 Formality (cross-lingual) fr-it fr-pt it-fr it-pt pt-fr pt-it average 0.47 0.45 0.48 0.41 0.46 0.42 0.45 0.06 0.32 0.33 0.15 0.05 0.07 0.24 0.43 0.21 0.81 0.63 0. 0.67 0.29 0.04 0.02 0.48 0.20 0.09 0.16 0.05 0.02 0.15 0.13 0.20 0.10 0.08 0.28 0.18 0.19 0.15 0.34 0.20 0.18 0.51 0.48 0.53 0.45 0.53 0. 0.49 0.00 0.05 0.22 0.08 0.01 0.04 0.07 0.46 0.12 0.16 0.18 0.15 0.16 0.24 0.02 0.01 0.09 0.13 0.09 0.13 0.04 0. 0.09 0.04 0.03 0.04 0.08 0.10 0.03 0.08 0.06 0.20 0.08 0.07 0.22 0.19 0.18 0.19 0.17 0.21 0.19 0.00 0.00 0.12 0.03 0.48 0.03 0.15 0. 0.15 0.06 0.10 0.11 0.09 0.21 0.10 0.00 0.08 0.05 0.15 0.09 0.02 0.07 0.09 0.23 0.19 0.14 0.13 0.27 0.17 0.24 0.17 0.29 0. 0.21 0.28 0.29 0.26 0.27 0.27 0.27 0.27 0.24 0.36 0.46 0.48 0.14 0.15 0.38 0.69 0.36 0.82 0.69 0. 0.71 0.53 0.18 0.28 0.51 0.35 0.37 0.61 0.25 0.23 0.37 0.32 0.18 0.22 0.41 0.39 0.22 0.35 0.23 0.40 0.26 0.30 0.53 0.52 0.53 0.52 0.53 0. 0.53 Table 8: Full performance on the multilingual and cross-lingual STEL-or-content benchmarks. For the cross-lingual SoC evaluation, \"a-b\" means that the anchor sentences were all in language and alternative sentences were all in language b. MSTYLEDISTANCE leads in cross-lingual and overall performance. 11 Style Feature Positive and Negative Prompts Style Feature Definition Excluded In"
        },
        {
            "title": "Usage of Conjunctions",
            "content": "Positive: With conjunctions Negative: Less frequent conjunctions The \"Usage of Conjunctions\" text style feature refers to the use of words that connect clauses or sentences. Conjunctions are words like \"and\", \"but\", \"or\", \"so\", \"because\", etc. They are used to make sentences longer, more complex, or to show the relationship between different parts of sentence."
        },
        {
            "title": "Usage of Numerical Substitution",
            "content": "Positive: With number substitution Negative: Without number substitution Numerical substitution refers to the practice of replacing certain letters in words with numbers that visually resemble those letters. For example, replacing the letter with the number 3 in the word hello to make it h3llo. This is common feature in internet slang and informal digital communication. Arabic, Hindi, Japanese, Korean, Chinese"
        },
        {
            "title": "Usage of Words Indicating Affective\nProcesses",
            "content": "Positive: Affective processes Negative: Cognitive processes"
        },
        {
            "title": "Usage of Metaphors",
            "content": "Positive: With metaphor Negative: Without metaphor"
        },
        {
            "title": "Usage of Long Words",
            "content": "Positive: Long average word length Negative: Short average word length"
        },
        {
            "title": "Usage of Uppercase Letters",
            "content": "Positive: With uppercase letters Negative: Without uppercase letters The text style feature \"Usage of Words Indicating Affective Processes\" refers to the use of words that express emotions, feelings, or attitudes. These could be words that show happiness, sadness, anger, fear, surprise, or any other emotional state. The presence of such words in text indicates that the writer is expressing some form of emotional reaction or sentiment. The \"Usage of Metaphors\" text style feature refers to the presence of phrases or sentences in the text that describe something by comparing it indirectly to something else. This is often done to make description more vivid or to explain complex ideas in more understandable way. For example, saying \"time is thief\" is metaphor because its not literally true but it helps to convey the idea that time passes quickly and cant be regained. The \"Usage of Long Words\" text style feature refers to the frequency or prevalence of long words, typically those with more than six or seven letters, in given text. This style feature is often used to measure the complexity or sophistication of the text. If text has many long words, it is said to have high usage of long words. The usage of uppercase letters as text style feature refers to the frequency or manner in which capital letters are used in text. This could be for emphasis, to denote shouting or strong emotions, or to highlight specific words or phrases. Its not just about the start of sentences or proper nouns, but also about other uses of capital letters in the text. Arabic, Japanese, Korean, Chinese Arabic, Hindi, Japanese, Korean, Chinese Usage of Articles Positive: With articles Negative: Less frequent articles The \"Usage of Articles\" text style feature refers to how often text uses words like \"a\", \"an\", and \"the\". These words are called articles and they are used before nouns. This feature measures the frequency of these articles in given text. Arabic, Hindi, Japanese, Korean, Russian, Chinese Usage of Text Emojis Positive: Text Emojis Negative: No Emojis Usage of Nominalizations Positive: With nominalizations Negative: Without nominalizations Frequent Usage of Function Words Positive: With function words Negative: Less frequent function words Usage of Self-Focused Perspective or Words Positive: Self-focused Negative: Third-person singular Usage of Formal Tone Positive: Formal Negative: Informal Usage of Emojis Positive: With Emojis Negative: No Emojis"
        },
        {
            "title": "Usage of Offensive Language",
            "content": "Positive: Offensive Negative: Non-Offensive Usage of Present Tense and PresentFocused Words Positive: Present-focused Negative: Future-focused The text style feature \"Usage of Text Emojis\" refers to the inclusion of emoticons or smileys in the text. These are combinations of keyboard characters that represent facial expressions or emotions, such as :-D for big grin or happy face. The presence of these symbols in text indicates the use of this style feature. Nominalizations refer to the use of verbs, adjectives, or adverbs as nouns in sentence. This style feature is often used to make sentences more concise or formal. For example, \"the investigation of the crime\" is nominalization of \"investigate the crime\". The text style feature \"Frequent Usage of Function Words\" refers to the regular use of words that have little meaning on their own but work in combination with other words to express grammatical relationships. These words include prepositions (like in, at, on), conjunctions (like and, but, or), articles (like a, an, the), and pronouns (like he, they, it). The \"Usage of Self-Focused Perspective or Words\" text style feature refers to the use of words or phrases that focus on the speaker or writer themselves. This includes the use of first-person pronouns like \"I\", \"me\", \"my\", \"mine\", and \"myself\", or statements that express the speakers personal thoughts, feelings, or experiences. The \"Usage of Formal Tone\" text style feature refers to the use of language that is polite, impersonal and adheres to established conventions in grammar and syntax. It avoids slang, contractions, colloquialisms, and often uses more complex sentence structures. This style is typically used in professional, academic, or official communications. The \"Usage of Emojis\" text style feature refers to the inclusion of emojis, or digital icons, in text. Emojis are often used to express emotions, ideas, or objects without using words. If text contains emojis, it has this style feature. The \"Usage of Offensive Language\" text style feature refers to the presence of words or phrases in the text that are considered rude, disrespectful, or inappropriate. These can include swear words, slurs, or any language that could be seen as insulting or derogatory. The text style feature \"Usage of Present Tense and Present-Focused Words\" refers to the use of verbs in the present tense and words that focus on the current moment or situation. This means the text is primarily discussing events, actions, or states that are happening now or general truths. Its like the text is talking about what is happening in the present time. Presence of Misspelled Words Positive: Sentence With Few Misspelled Words Negative: Normal Sentence The text style feature \"Presence of Misspelled Words\" refers to the occurrence of words in text that are not spelled correctly according to standard dictionary spelling. This could be due to typing errors, lack of knowledge about the correct spelling, or intentional for stylistic or informal communication purposes. Incorporation of Humor Positive: With Humor Negative: Without Humor The \"Incorporation of Humor\" text style feature refers to the use of language, phrases, or expressions in text that are intended to make the reader laugh or feel amused. This could include jokes, puns, funny anecdotes, or witty remarks. Its all about adding touch of comedy or light-heartedness to the text. Style Feature Name Positive and Negative Prompts Style Feature Definition Excluded In Arabic, Hindi, Japanese, Korean, Chinese Arabic, Hindi, Japanese, Korean, Chinese"
        },
        {
            "title": "Usage of Personal Pronouns",
            "content": "Positive: With personal pronouns Negative: Less frequent pronouns"
        },
        {
            "title": "Fluency in Sentence Construction",
            "content": "Positive: Fluent sentence Negative: Disfluent sentence"
        },
        {
            "title": "Usage of Only Uppercase Letters",
            "content": "Positive: All Upper Case Negative: Proper Capitalization Usage of Self-Focused Perspective or Words Positive: Self-focused Negative: Inclusive-focused"
        },
        {
            "title": "Usage of Pronouns",
            "content": "Positive: With pronouns Negative: Less frequent pronouns Usage of Words Indicating Cognitive Processes Positive: Cognitive process Negative: Perceptual process Complex Sentence Structure Positive: Complex Negative: Simple Positive Sentiment Expression Positive: Positive Negative: Negative Usage of Numerical Digits Positive: With digits Negative: Less frequent digits Usage of Words Indicating Affective Process Positive: Affective process Negative: Perceptual process Usage of Active Voice Positive: Active Negative: Passive Usage of Only Lowercase Letters Positive: All Lower Case Negative: Proper Capitalization The \"Usage of Personal Pronouns\" text style feature refers to the use of words in text that refer to specific person or group of people. These words include \"I\", \"you\", \"he\", \"she\", \"it\", \"we\", and \"they\". The presence of these words in text can indicate more personal or direct style of communication. \"Fluency in Sentence Construction\" refers to the smoothness and ease with which sentences are formed and flow together. It involves using correct grammar, appropriate vocabulary, and logical connections between ideas. text with this feature would read smoothly, without abrupt changes or awkward phrasing. The usage of only uppercase letters style feature refers to the practice of writing all the letters in text in capital letters. This means that every single letter in the text, whether at the beginning, middle, or end of sentence, is capitalized. Its like the Caps Lock key on your keyboard is always turned on while typing the text. The \"Usage of Self-Focused Perspective or Words\" text style feature refers to the use of words or phrases that focus on the speaker or writer themselves. This includes the use of first-person pronouns like \"I\", \"me\", \"my\", \"mine\", and \"myself\", or statements that express the speakers personal thoughts, feelings, or experiences. The \"Usage of Pronouns\" text style feature refers to the frequency and types of pronouns used in text. Pronouns are words like he, she, it, they, we, you, I, etc., that stand in place of names or nouns in sentences. This feature can indicate the level of personalization, formality, or perspective in text. The text style feature \"Usage of Words Indicating Cognitive Processes\" refers to the use of words that show thinking or mental processes. These words can express understanding, knowledge, belief or doubt. For example, words like think, know, believe, understand are used to indicate cognitive processes. The \"Complex Sentence Structure\" text style feature refers to sentences that contain multiple ideas or points, often connected by conjunctions (like and, but, or) or punctuation (like commas, semicolons). These sentences often include dependent clauses, which are parts of the sentence that cant stand alone as complete thought, alongside independent clauses, which can stand alone. In simpler terms, if sentence has more than one part and these parts are linked together in way that they give more detailed information or express multiple thoughts, it has complex sentence structure. Positive Sentiment Expression is text style feature that refers to the use of words, phrases, or expressions that convey positive or optimistic viewpoint or emotion. This could include expressions of happiness, joy, excitement, love, or any other positive feelings. The text is considered to have this feature if it makes the reader feel good or positive after reading it. The \"Usage of Numerical Digits\" text style feature refers to the presence and use of numbers in text. This includes any digit from 0-9 used alone or in combination to represent quantities, dates, times, or any other numerical information. The \"Usage of Words Indicating Affective Process\" text style feature refers to the use of words that express emotions, feelings, or attitudes. These words can show positive or negative sentiments, like happiness, anger, love, or hate. If text uses lot of these words, it means the writer is expressing lot of emotion or personal feelings. The usage of active voice in text style feature refers to sentences where the subject performs the action stated by the verb. In other words, the subject is active and directly involved in the action. For example, in the sentence \"The cat chased the mouse\", the cat is the subject that is actively doing the chasing. The style feature \"usage of only lowercase letters\" refers to the practice of writing all words in text with small letters only, without using any capital letters. This means that even the first word of sentence, proper nouns, or the pronoun are not capitalized. Its like writing whole text without ever pressing the shift key on your keyboard. Frequent Usage of Common Verbs Positive: With common verbs Negative: Less frequent common verbs The text style feature \"Frequent Usage of Common Verbs\" refers to the regular use of basic action words in text. These are often simple, everyday verbs that are widely used in language, such as is, have, do, say, go, etc. If text frequently uses these common verbs, it has this style feature. Usage of Prepositions Positive: With prepositions Negative: Less frequent prepositions The \"Usage of Prepositions\" text style feature refers to the use of words that link nouns, pronouns, or phrases to other words within sentence. These words often indicate location, direction, time, or manner. Examples of prepositions include words like \"in\", \"at\", \"on\", \"over\", \"under\", \"after\", and \"before\". Usage of Self-Focused Language Positive: Self-focused Negative: Audience-focused Usage of Certain Tone Positive: Certain Negative: Uncertain Usage of Present-Focused Tense and Words Positive: Present-focused Negative: Past-focused The \"Usage of Self-Focused Language\" text style feature refers to the use of words or phrases that focus on the speaker or writer themselves. This includes the use of first-person pronouns like \"I\", \"me\", \"my\", \"mine\", and \"myself\". Its way of writing or speaking where the person is often referring to their own thoughts, feelings, or experiences. This text style feature refers to the use of confident tone in writing, where the author avoids using uncertain words or phrases such as think, might, or seems. This results in text that appears more assertive and sure of the information being presented. The \"Usage of Present-Focused Tense and Words\" text style feature refers to the use of verbs in the present tense and words that focus on the current moment or situation. This means the text is primarily discussing events, actions, or states that are happening right now or generally true. 13 Style Feature Name Positive and Negative Prompts Style Feature Definition Excluded In"
        },
        {
            "title": "Usage of Sarcasm",
            "content": "Positive: With sarcasm Negative: Without sarcasm Usage of Self-Focused Perspective or Words Positive: Self-focused Negative: You-focused"
        },
        {
            "title": "Frequent Usage of Punctuation",
            "content": "Positive: With frequent punctuation Negative: Less Frequent punctuation"
        },
        {
            "title": "Usage of Polite Tone",
            "content": "Positive: Polite Negative: Impolite"
        },
        {
            "title": "Usage of Contractions",
            "content": "Positive: With contractions Negative: Without contractions The \"Usage of Sarcasm\" text style feature refers to the presence of statements or expressions in the text that mean the opposite of what they literally say, often used to mock or show irritation. This style is often characterized by irony, ridicule, or mockery, and is used to express contempt or to criticize something or someone in humorous way. The \"Usage of Self-Focused Perspective or Words\" text style feature refers to the use of words or phrases that focus on the speaker or writer themselves. This includes the use of first-person pronouns like \"I\", \"me\", \"my\", \"mine\", and \"myself\", or statements that express the speakers personal thoughts, feelings, or experiences. The text style feature \"Frequent Usage of Punctuation\" refers to the regular and abundant use of punctuation marks such as commas, periods, exclamation points, question marks, etc., in piece of text. This style feature is present when the writer often uses these symbols to structure their sentences, express emotions, or emphasize certain points. The \"Usage of Polite Tone\" text style feature refers to the use of respectful and considerate language in text. This can include using words like please, thank you, or phrases that show deference or respect to the reader. Its about making the text sound courteous and respectful, rather than demanding or rude. The \"Usage of Contractions\" text style feature refers to the use of shortened forms of words or phrases in text. These are typically formed by omitting certain letters or sounds and replacing them with an apostrophe, such as \"dont\" for \"do not\" or \"Im\" for \"I am\". If text frequently uses such shortened forms, it has this style feature. Arabic, Hindi, Japanese, Korean, Russian, Chinese"
        },
        {
            "title": "Frequent Usage of Determiners",
            "content": "Positive: With determiners Negative: Less frequent determiners The text style feature \"Frequent Usage of Determiners\" refers to the regular use of words that introduce noun and give information about its quantity, proximity, definiteness, etc. These words include the, a, an, this, that, these, those, my, your, his, her, its, our, their. If text often uses such words, it has this style feature. Table 9: 40 style features, with the Excluded in column indicating that particular feature was omitted from our dataset due to its inapplicability to specific language."
        }
    ],
    "affiliations": [
        "University of Pennsylvania"
    ]
}