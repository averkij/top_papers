{
    "paper_title": "GIMMICK -- Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking",
    "authors": [
        "Florian Schneider",
        "Carolin Holtermann",
        "Chris Biemann",
        "Anne Lauscher"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Vision-Language Models (LVLMs) have recently gained attention due to their distinctive performance and broad applicability. While it has been previously shown that their efficacy in usage scenarios involving non-Western contexts falls short, existing studies are limited in scope, covering just a narrow range of cultures, focusing exclusively on a small number of cultural aspects, or evaluating a limited selection of models on a single task only. Towards globally inclusive LVLM research, we introduce GIMMICK, an extensive multimodal benchmark designed to assess a broad spectrum of cultural knowledge across 144 countries representing six global macro-regions. GIMMICK comprises six tasks built upon three new datasets that span 728 unique cultural events or facets on which we evaluated 20 LVLMs and 11 LLMs, including five proprietary and 26 open-weight models of all sizes. We systematically examine (1) regional cultural biases, (2) the influence of model size, (3) input modalities, and (4) external cues. Our analyses reveal strong biases toward Western cultures across models and tasks and highlight strong correlations between model size and performance, as well as the effectiveness of multimodal input and external geographic cues. We further find that models have more knowledge of tangible than intangible aspects (e.g., food vs. rituals) and that they excel in recognizing broad cultural origins but struggle with a more nuanced understanding."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 1 ] . [ 1 6 6 7 3 1 . 2 0 5 2 : r a"
        },
        {
            "title": "GIMMICK\nGlobally Inclusive Multimodal Multitask Cultural Knowledge\nBenchmarking",
            "content": "Florian Schneider1, Carolin Holtermann2, Chris Biemann1, Anne Lauscher2 1Language Technology Group, University of Hamburg 2Data Science Group, University of Hamburg florian.schneider-1@uni-hamburg.de"
        },
        {
            "title": "Abstract",
            "content": "Large Vision-Language Models (LVLMs) have recently gained attention due to their distinctive performance and broad applicability. While it has been previously shown that their efficacy in usage scenarios involving non-Western contexts falls short, existing studies are limited in scope, covering just narrow range of cultures, focusing exclusively on small number of cultural aspects, or evaluating limited selection of models on single task only. Towards globally inclusive LVLM research, we introduce GIMMICK, an extensive multimodal benchmark designed to assess broad spectrum of cultural knowledge across 144 countries representing six global macro-regions. GIMMICK comprises six tasks built upon three new datasets that span 728 unique cultural events or facets on which we evaluated 20 LVLMs and 11 LLMs, including five proprietary and 26 open-weight models of all sizes. We systematically examine (1) regional cultural biases, (2) the influence of model size, (3) input modalities, and (4) external cues. Our analyses reveal strong biases toward Western cultures across models and tasks and highlight strong correlations between model size and performance, as well as the effectiveness of multimodal input and external geographic cues. We further find that models have more knowledge of tangible than intangible aspects (e.g., food vs. rituals) and that they excel in recognizing broad cultural origins but struggle with more nuanced understanding."
        },
        {
            "title": "Introduction",
            "content": "Recently, proprietary as well as open-weight Large Vision-Language Models (LVLMs) (OpenAI, 2023; Liu et al., 2023; Wang et al., 2024; Chen et al., inter alia) have attracted marked atten2023, tion due to their broad applicability across various domains. Several large-scale holistic benchmarks (Duan et al., 2024; Yue et al., 2024; Fu et al., 1http://github.com/floschne/gimmick 1 2023) demonstrate LVLMs remarkable performances in wide range of multimodal tasks. However, most benchmarks concentrate on Westerncentric English tasks, and multilingual benchmarks (Ahuja et al., 2024; Schneider and Sitaram, 2024) reveal significant deterioration in performance on non-English tasks. While multilingualism is essential for globally equitable AI, multiculturalism (Gabriel, 2020; Adilazuarda et al., 2024) is equally crucial for models to reflect and respect the diverse cultural backgrounds of users In this context, it has been shown worldwide. that current LLMs (Myung et al., 2024; Chiu et al., 2024) and LVLMs suffer in tasks involving knowledge from non-Western cultures. However, the scope of existing multimodal cultural studies is still severely limited: Existing research often focuses only on specific concepts like food or dance (Winata et al., 2024; Burda-Lassen et al., 2024), covers limited number of cultures (Urailertprasert et al., 2024; Baek et al., 2024), evaluates only small selection of LVLM models (Cao et al., 2024; Nayak et al., 2024), or tests only single combination of input modalities. To address these gaps, we introduce GIMMICK, comprehensive evaluation framework assessing 31 state-of-the-art models, ranging from proprietary LVLMs to open-weight LLMs and LVLMs of all sizesfrom 500M to 78B parametersacross multiple model families. It comprises six tasks built on three novel datasets that contain 728 unique cultural events or facets (CEFs) from 144 countries in six global macro-regions and target both high-level and nuanced cultural knowledge through multimodal and unimodal tasks. Our VQA tasks span total of 57 cultural aspects (see B.2) Ultimately, GIMMICK enables us to answer four research questions: (RQ1) Are there regional biases in LLMs and LVLMs cultural knowledge, and if so, which? For the most complex tasks, we observe consisFigure 1: An overview of the GIMMICK benchmark and its tasks. tent cultural regional biases (up to 14.72pp difference between instances targeting Western Europe & North America vs. Subsaharian Africa; 5.1) even for the largest models. For less complex tasks, these differences flatten out. (RQ2) To what degree does model size influence performance? We show that increasing the number of parameters significantly boosts performance on complex tasks, with larger models exhibiting less regional biases (5.2). Still, even the largest models still struggle with nuanced cultural understanding. (RQ3) How do input modalities affect cultural understanding? We observe that providing input in multiple modalities typically leads to the best results, as models leverage the cultural cues present in the visual inputs we provide (5.3). Interestingly, on text-only tasks, LVLMs perform consistently worse than their LLM backbones, indicating loss of cultural knowledge during integration training. (RQ4) What is the influence of external cultural cues? We demonstrate that providing country information consistently guides the models towards better answers, especially for regions for which the models perform poorly (5.4). Overall, with GIMMICK, we hope to encourage more research on culturally-aware and more globally-inclusive AI."
        },
        {
            "title": "2 Related Work",
            "content": "Multicultural LLM Benchmarks. Naous et al. (2024) introduce CAMeL, dataset that contrasts Arab and Western cultures to measure cultural biases in LLMs through extrinsic and intrinsic evaluations on core NLP tasks. With CultureAtlas, Fung et al. (2024) introduced an approach for massively multicultural knowledge acquisition and benchmarking of 5 LLMs from Wikipedia articles on cultural topics. BLEnD (Myung et al., 2024) is large benchmark to evaluate LLMs everyday knowledge across diverse cultures and from"
        },
        {
            "title": "BENCHMARK",
            "content": "#M #DS #T #S #C #R MODS SEA-VQA Urailertprasert et al. (2024) WorldCuisines Winata et al. (2024) CROPE Nikandrou et al. (2024) CulturalVQA Nayak et al. (2024) Ananthram et al. (2024) GlobalRG Bhatia et al. (2024) MOSAIC-1.5K Burda-Lassen et al. (2024) FoodieQA Li et al. (2024) Cao et al. (2024) K-VISCUIT Baek et al. (2024) CVQA Romero et al. (2024) CulturalBench Chiu et al. (2024) GIMMICK (ours) 2 18 17 8 12 4 8 1 13 30 31 1 1 1 2 1 1 1 2 3 1 2 1 3 2 1 3 1 1 1 6 1,999 1.15M 189 1,060 2,378 3,591 1, 1,839 657 6 11 51 1 5 1 10, 6,135 30 45 7,239 144 6 3 5 2 6 1 3 1 6 6 T+I T+I T+I T+I T+I T+I T+I T+I T+I T+I T+I T+I T+I V+T T, Table 1: comparative overview of recent benchmarks assessing cultural knowledge of LVLMs. The abbreviations in the columns stand for the (combined) number of: (unique) Models, Datasets, Tasks, Samples, Countries, or Regions contained. The Modalities column lists the input modalitiesText, Image, Videocontained. . countries in 13 different languages. (Mukherjee et al., 2024) test four popular LLMs with culturally sensitive and non-sensitive prompts on both sensitive and neutral datasets. Instead of assessing models intrinsic cultural knowledge, (Bhatt and Diaz, 2024) focuses on the extrinsic evaluation of cultural competence, e.g., in user-interaction, in two text generation tasks, open-ended question answering, and story generation of 6 LLMs. Multicultural LVLM Benchmarks. Bhatia et al. (2024) introduced the GlobalRG benchmark, which comprises two tasks: retrieving culturally diverse images for universal concepts from 50 countries and grounding culture-specific concepts within images from 15 countries. Karamolegkou et al. (2024) proposed culture-centric evaluation benchmark investigating the reliability of LVLMs as visual assistants for blind people in culturally diverse setting. Using the CulturalVQA (Nayak et al., 2024), the authors assessed geo-diverse cultural understanding of nine 1st-Gen LVLMs on curated dataset of 2,378 VQA pairs representing cultures from 11 countries and five cultural aspects. CulturalBench (Chiu et al., 2024) is dataset of 1,227 human-written and human-verified questions for evaluating LLMs cultural knowledge, covering 45 global regions. Nikandrou et al. (2024) propose CROPE, VQA benchmark designed to probe the knowledge of culture-specific concepts and evaluate the capacity for cultural adaptation through contextual information featuring over 1M data points across 30 languages and dialects.See Table 1 for an overview and comparison or related work with GIMMICK. Multilingual Multicultural LVLM Benchmarks. Several studies evaluate the cultural awareness and capabilities of LVLMs in multilingual setting. Geigle et al. (2025) extensively benchmarked stateof-the-art LVLMs across multiple multilingual and multicultural datasets, including MaRVL (Liu et al., 2021), XM3600 (Thapliyal et al., 2022) and MaXM(Changpinyo et al., 2023), M5B-VGR and M5B-VLOD (Schneider and Sitaram, 2024), CVQA (Romero et al., 2024) Winata et al. (2024) created WorldCuisines, large-scale benchmark for multilingual and multicultural VQA on global cuisines. However, in GIMMICK, we focus on the English language, considering English performance as an upper bound."
        },
        {
            "title": "3 The GIMMICK Benchmark",
            "content": "Cultural Benchmark Positioning Adilazuarda et al. (2024) surveyed 90+ recent papers on cultural awareness in LLMs and found that none explicitly define culture. Instead, these studies evaluate models on datasets capturing only specific cultural aspects, which the authors organize into two dimensions: demographic and semantic proxies (with seven and five subsets, respectively). In GIMMICK, we adopt the proposed taxonomy by using countries and regions as demographic cultural proxies. Our tasks span all five semantic proxies: emotions and values, food and drink, social and political relations, basic actions and technology, and names. We implement primarily black-box generative and discriminative probing approaches. UNESCO Intangible Cultural Heritage. All tasks in GIMMICK are based on high-quality open-"
        },
        {
            "title": "REGION",
            "content": "Arab Asia & Pacific Eastern Europe Latin-America & Caribbean Subsaharian Africa Western Europe & North America"
        },
        {
            "title": "Unique",
            "content": "ABBRV. AP LAC SA #C #CEF 18 35 25 28 40 23 144 76 226 150 98 73 728 Table 2: Regions within GIMMICK. #C and #CEF stand for the number of Countries and CEFs related to the respective region. Some CEFs may span multiple regions. access data from the UNESCO Intangible Cultural Heritage (ICH) project2, which aims to safeguard cultural traditions and practices vital to the identity and heritage of communities worldwide while honoring cultural diversity.Intangible cultural heritage encompasses oral traditions, performing arts, rituals, festive events, traditional craftsmanship, and cultural knowledge. The open-access dataset is structured as knowledge graph, where most nodes represent cultural events or facets (CEFs; e.g., Yukitsumugi, silk fabric production technique from Japan3), with additional nodes including countries, regions, case studies in which the CEFs occur. For GIMMICK, we extract the CEFs, each together with their title, description, associated macro-regions and countries, and several images depicting different aspects of the CEF. Moreover, each CEF is detailed in one or more YouTube videos. In total, GIMMICK contains 728 CEFs from 144 countries represented by 6,887 images and 993 videos4. While most CEFs (88.60%) are associated with one country, some are associated with two or more countries.The UNESCO ICH project groups the countries into six global macro-regions5, which we adopt in this work. Throughout the paper including all figures and tableswe use the region abbreviations listed in Table 2."
        },
        {
            "title": "3.1 Datasets and Tasks",
            "content": "We created three novel multimodal datasets that serve as the foundation for six tasks designed to evaluate the cultural knowledge of models. See Figure 1 for an overview of the different tasks.6 2https://ich.unesco.org 3More examples including images are shown in A.2.1 4We provide licensing details in A.1 5We provide comprehensive list in Table 4 in A.3 6Sample counts per task & region are shown in A.3."
        },
        {
            "title": "3.2 Cultural Image VQA",
            "content": "In the Cultural Image VQA (CIVQA) task, models are presented with an image depicting CEF and question that relates to particular CEF aspect (see B.1 for examples). Models are evaluated based on answer correctness. To create the data for CIVQA, we couple synthetic data generation with two-stage annotation process. Synthetic Data Generation. Building on the highquality UNESCO ICH data, we applied synthetic data generation by prompting GPT-4o7 to construct the basis for our dataset.Each VQA pair is related to CEF and consists of an image depicting one aspect of the CEF, question related to the CEF and the image, and an answer. Maximizing the quality of the generated silver data, we applied extensive prompt engineering combining techniques such as Few-Shot, Chain-of-Thought, ReAct (Wei et al., 2022; Zhang et al., 2023; Zheng et al., 2024; Sahoo et al., 2024) to craft the prompt. Key aspects of the prompt are role description, general task description, detailed annotation guidelines, step-by-step strategy, an expected output format, few-shot examples, and the information of the target CEF (see B.4 for the full prompt). We then generated silver VQA pairs for each of the 6,827 images contained in the ICH data source, which resulted in 17,369 pairs. Afterward, we automatically removed pairs where 1) the question contained words that introduce subjectiveness or ambiguity (could, should, maybe, etc.); 2) the answer contained abstract words that are hard to depict visually; and 3) where the answer is not substring of the description of the related CEF. This way, we obtained 9,900 silver VQA samples related to 5,517 images from all 728 CEFs. Annotation Process. Opting for high-quality VQA pairs as well as cultural diversity, we devised twostage annotation process with 18 trained experts from various cultural backgrounds covering all six regions (see Table 8 in B.5). Each silver pair was evaluated using two questionnairesone with seven question-related requirements and another with four answer-related requirements. Questions had to target the CEF and image content directly, require cultural knowledge, and depend on visual evidence (Chen et al., 2024a). Answers needed to be clear, objective, concise, and depictable. For details on the annotation process, see B.5. 7gpt-4o-2024-08-06 In the first round, we annotated each sample once, resulting in 4,114 samples, of which 2,826 (68.69%) met all criteria. In the second round, five annotators re-evaluated these, retaining only samples with concordant approval. This process finally yielded 2,233 samples for 1,928 images from 728 CEFs across 144 countries in six global regions."
        },
        {
            "title": "3.3 Cultural Video VQA",
            "content": "In this task, models are evaluated on questions relating to videos instead of single images, again employing accuracy as the metric. To this end, we extend CIVQA in two steps: synthetic data generation and quality annotation. Synthetic Data Generation. First, we adjusted the CIVQA questions by replacing the term image with video. We then coupled the question with short video clip, for which we started from the CEFs associated YouTube video. We ensured that the shortened clip contains relevant information for answering the question as follows: From each video, we extracted one frame per second, and computed image embeddings for both the frames and the CIVQA image, using DINOv28 (Oquab et al., 2024; Darcet et al., 2024). We then identified the frame that best matches the original image by calculating Cosine similarity. We selected this frame as the center (at = 0) for 10-second clip9 (from = 5 to = 5). We only include clips with best-matching frame similarity > 0.5, which we found to yield high-quality instances based on manual inspection of random samples. Overall, this procedure resulted in 2,001 silver samples. Annotation Process. For additional quality control, trained expert annotated 20% of the silver data (400 samples). Each sample was evaluated using three-item questionnaire10 assessing whether (1) the video contained frames resembling the CEF image, (2) it clearly answered the question, or (3) neither condition was met. Overall, 95% of the annotated samples were accepted. For closer inspection, we stratified the annotated samples into four similarity bins, revealing that roughly 10% of those in the lower bins ([0.5, 0.75[) were rejected, while nearly all, i.e., 99% and 100%, in the higher bins ([0.75, 1.0]) were retained. The residual 5% label noise was considered acceptable based on further manual analysis. Notably, we found that of 8facebook/dinov2-with-registers-large 9We do not include the audio stream in our clips. 10cf. for details. 4 the 20 rejected samples, only 9 were unanswerable based on the video, while the remaining 11 exhibited only suboptimal frame match w.r.t. the CIVQA image. The final GIMMICK CVVQA dataset contains 1,809 samples (see C.1 for examples) linked to 553 CEFs from 139 countries."
        },
        {
            "title": "4 Experimental Setup",
            "content": "Models and Inference. We evaluate total of 31 models, including five proprietary LVLMs, 15 open-weight LVLMs, and 11 open-weight LLMs the backbones of the respective LVLMscovering"
        },
        {
            "title": "GROUP",
            "content": "PARAMETERS (B)"
        },
        {
            "title": "LVLMS",
            "content": "0.5 4 7 11 26 38 72 78 unkown"
        },
        {
            "title": "Total",
            "content": "5 3 2 1 0 11 5 6 2 2 5 20 Table 3: The size groups we define for result aggregation according to models number of parameters."
        },
        {
            "title": "9 LVLM and 4 LLM model families. The sizes of\nthe open-weight models vary, categorized as small,\nmedium, large, and extra-large (see Table 3). A\ncomprehensive list of models is provided in Table 6\nin §A.4. For our experiments, we download open\nweights from the respective Huggingface (Wolf\net al., 2019) repositories (see Table 6) and generate\nresponses employing greedy decoding. For pro-\nprietary models, we use the official Python SDKs.\nMore details are reported in §F.\nMetrics. For the CIVQA, CVVQA, and COQA tasks,\nwe report relaxed answer accuracy, for which we\nconsider a generated answer correct if it starts with\nthe ground truth answer. For CKQAD and CKQAN,\ndue to their generative nature, we use GPT-4o11 in\nan “LVLM-as-a-Judge” (Zheng et al., 2023; Xiong\net al., 2024) setup to judge responses with a score\ns ∈ [0, 100]. Where s = 0, s = 50, and s = 100\nindicate completely incorrect or irrelevant, par-\ntially correct or relevant, and perfectly correct and\ncomplete answers, respectively.",
            "content": "Video Processing. The 10-second video clips from CVVQA do not contain an audio stream, and we only use the visual information. Following established praxis (e.g., Wang et al., 2024), we extract one frame per second from the videos and provide them to the models as input alongside the textual prompt. Specifics about the image and video processing of the individual models are documented in the code."
        },
        {
            "title": "5 Results and Analyses",
            "content": "In this section, we present series of in-depth analyses based on the outcomes of our benchmark. We show aggregated results: open-weight models are grouped and averaged by parameter size, and proprietary models are averaged together (see Table 3). We provide the complete numerical results for all tasks and models in G. In the following, we use abbreviations for regions as defined in Table 2. 11gpt-4o-2024-11-20 5 know the cultural concepts discussed. Here, we focus on the QWENVL models on CIVQA and the compute perplexity of ground truth answers (conditioned on the input context) as proxy of model cultural knowledge (details in G.1.2). Figure 3 shows that for the 7B and 72B models, perplexity is consistently lower for W, E, and AP compared to and SA, aligning with our performance findings. For the 2B model, however, and SA yield the highest perplexities, which we attribute to the overall brittleness of the model. Moreover, we revisit the performance on questions about the prevalent cultural aspects in CIVQA (details in G.1.2) and find that models perform notably better on tangible cultural aspects than on intangible ones. For instance, closed models achieve an accuracy of 30% for food-related questions and only 8% and 10% for questions concerning rituals or festivals. This highlights biases along the cultural dimension, which are particularly pronounced in non-Western contexts. CKQAN & CKQAD. For CKQAN, regional differences are minor, though proprietary models significantly outperform open-weight ones (see Figure 2c). The large error bars for closed models indicate inconsistent performance particularly from GPT-4O MINI and GEMINI FLASH models, which perform similarly to large openweight models. XL and models perform and worst on E. For CKQAD (Figure 6c), performance is 1020% higher than on CKQAN, likely because describing CEF is easier than exactly naming it. However, regional biases are larger, with consistently higher scores on than on SA, primarily for closed models like GPT-4O, which reaches 53.66 for and 43.70 on SA. COQAC & COQAR. Figure 6a shows minimal regional differences for COQAC.Average accuracies range from close to or above 90% for closed, XL, and models to 77.42% for models. However, performance on COQAR is lower than on COQAC85.02% vs. 81.17% on average over all models and regions with AP. models achieving the highest scores in Notably, the regional ranking is mostly inA, verted compared to other tasks SA,"
        },
        {
            "title": "W and",
            "content": "(a) CIVQA Accuracy (b) CVVQA Accuracy (c) CKQAN Accuracy Figure 2: Aggregated results of the VQA tasks. Figure 3: CIVQA ground-truth answer perplexity."
        },
        {
            "title": "5.1 General Trends and Cultural Bias",
            "content": "E, and AP) and lowest for We discuss general trends and investigate cultural bias across regions (Figures 2 and 3). CIVQA & CVVQA. Figures 2ac show clear regional performance disparities. Across all models proprietary and open-weight, regardless of size scores are highest for Western and Asian targets ( W, SA. XL models, e.g., reach 24.04 on and 9.32 on and LAC fall in between, SA on average. with model performance varying by size. Since CIVQA is an open-answer task, often with rare culturally specific terms, we also evaluated the task with GPT-4o as LVLM-as-a-Judge to account for imperfect naming or spelling. While this method yields higher scores, it confirms the same trend: models exhibit strong bias toward Western contexts. However, even the best model (GPT-4O) scores only 31.58% on and 25.44% on average, highlighting GIMMICK as challenging benchmark and the lack of finegrained cultural knowledge in current models. We supplement our analysis with more fine-grained investigation of how well models 6 mance on COQAC, COQAR, and CKQAD. Further, we compare LVLMs to their LLM backbones to assess potential losses in cultural knowledge during multimodal training. Input Modalities. Figure 6 shows that text+image (I+T) inputs consistently yield the highest performance across all tasks, confirming that textual and visual data provide complementary cultural cues. The gap between I+T and text-only (T) is slightly more prominent for COQAC than COQAR, suggesting that visual information aids in inferring fine-grained, countrylevel details. In contrast, image-only (I) inputs perform poorly, indicating that textual information, such as CEF titles, carries more cultural context. The high variance in results for the COQA tasks stems from the performance disparity between GEMINI PRO and CLAUDE 3.5 SONNET (e.g., 59.38 vs. 83.75 for W). LVLM vs. LLM-Backbone. Comparing LVLMs with their LLM backbones reveals that multimodal training can impair the acquisition of detailed cultural knowledge (notably in CKQAD) while having minimal impact on coarsegrained cultural understanding (COQA). For large models, significant performance gaps 50.62 for QWEN2.5 72B vs. 40.02 for QWEN2VL APon the CKQAD task between the 72B on LVLMS and their LLM backbones can be observed, whereas, for smaller models, the effect is subtle. Overall, our findings highlight that while images complement text for culturally grounded tasks, it is ultimately the synergy between both modalities that leads to robust and broad cultural understanding. 5."
        },
        {
            "title": "Influence of External Cues",
            "content": "We examine how external hints, i.e., informing model about the country or region of CEF, affect VQA performance. For CIVQA (Figure 7a), country hints consistently boost performance across model sizes and regions, while regional cues yield only modestor even slightly adverseeffects in larger models. Gains from country hints are around 50% SA, improvements for most regions, but in nearly double (e.g., 97.48% for INTERNVL 2.5 78B and 97.13% for INTERNVL 2.5 38B). similar pattern emerges for CVVQA (Figure 7b). Hints generally enhance performance across regions (a) CIVQA, r=0.62* (b) CVVQA, r=0.36* (c) COQAC, r=0.39* (d) COQAR, r=0.16* (e) CKQAD, r=0.46* (f) CKQAN, r=0.39* Figure 4: Model size vs. performance on GIMMICK tasks. The x-axis is in log scale. The trend line was computed using OLS regression. We report the Pearson correlation coefficient ( * indicates statistical significance). Figure 5: Relative Difference to for CIVQA. LAC, E, and suggesting more distinct visual and linguistic features in non-Western regions."
        },
        {
            "title": "AP score higher than",
            "content": "5."
        },
        {
            "title": "Influence of Model Size",
            "content": "We assess how model size impacts performance and whether it affects regions equally. Figure 4 shows that model size12 significantly influences performance, with moderate to strong Pearson correlations and steep regression lines across tasks except COQAR, where the effect is minimal. Figure 5 shows that relative performance declines from the bestperforming region ( W) to others, particularly the drops are 63.39 (S), 63.85 (M), 50.60 (L), 54.57 (XL), and 41.52 (Closed). We conclude that bigger sizes tend to result in smaller gaps without size presenting strict ordering criterion. SA, varying by model size: 5."
        },
        {
            "title": "Influence of Modalities",
            "content": "We explore how input modalitytext-only, image-only, or text+imageaffects perfor12For closed source models, we manually set the number of parameters to 1T, except for Gemini Flash and GPT-4o mini, for which we set the number to 500B. 7 (a) COQAC (b) COQAR (c) CKQAD Figure 6: Aggregated results including multimodal input variations: Text-only, Image-only, Text+Image. gories, they struggle with nuanced understanding. This suggests that GIMMICK poses challenging benchmark and highlights the need for further advances in modeling broad cultural awareness. and models, with SA showing the most significant gains. Proprietary and small models exhibit subtle improvements, whereas and XL models see much higher relative gainsup to 240.7% for INTERN VL 38B. Notably, regional cues have more positive impact on CVVQA than on CIVQA."
        },
        {
            "title": "6 Conclusion",
            "content": "We introduce GIMMICK, comprehensive benchmark to assess various aspects of cultural knowledge of current LVLMs and LLMs and introduce six tasks built upon three novel datasets, which span 728 unique cultural events or facets (CEFs) from 144 countries grouped into six global macro-regions. Through extensive analyses, we study general cultural biases and the influence of model size, input modalities, and external cues. Our results consistently reveal prominent bias toward Western cultures across all models. Interestingly, when only coarse cultural knowledge is requiredsuch as regional origins models performed remarkably better. Across all tasks, significant correlations between models performance and its size are evident, with substantial gap between proprietary and open-weight models. Our analyses show that while models grasp broad cultural cate8 (a) SIVQA (b) VVQA Figure 7: Relative gains on VQA tasks from providing external geographical hints."
        },
        {
            "title": "Limitations",
            "content": "English-Only Benchmark Although we consider the performance on tasks requiring cultural understanding in English as an upper bound for the majority of models, it is yet to be tested if that hypothesis generally holds across tasks, model size, and model family. Especially for models like QWENVL and INTERNVL, which were pretrained on large portions of Chinese textual data, Chinese could be pivotal instead of English. Moreover, some cultural nuances might not be translatable to other languages. Open-Ended VQA. CIVQA and CVVQA comprise open-ended answers to their questions, imposing challenges for adequate evaluation, especially when employing binary metrics like accuracy. This is especially true for rare, culturally specific answer terms, such as in our tasks, which are prone to spelling inaccuracies or might have different names in different cultures or languages. Although we alleviate this issue by computing scores using GPT-4o in an LVLM-as-a-Judge setting and thereby confirm our findings, this requires additional computational and financial resources. typical solution for this is transforming the questions into multiple choice questions, which, however, requires culturally expert annotators, which are complicated to find or train and expensive if hired via professional annotation companies. Small Number of Samples. With total of 7239 unique samples across all tasks in GIMMICK2233 (CIVQA), 1809 (CVVQA), 982 (COQAC), 759 (COQAR), 728 (CKQAD), and 728 (CKQAN), the benchmark itself as the third most samples compared to other recent benchmarks. However, the per-task number falls relatively low, leading to even fewer counts per country or culture, making judgments about single countries not informative."
        },
        {
            "title": "Ethical Considerations",
            "content": "Country and Region Definitions. GIMMICK adopts the country and region classifications from the UNESCO ICH dataset. While these classifications are widely used, we recognize the potential for differing interpretations. Potentially Offensive Questions. We employed semi-automatic data generation strategies to create the CIVQA dataset. Here, the silver data was generated using GPT-4o, which we showed displays significant cultural biases towards Western contexts. Although we provided the model with high-quality ground-truth information from the UNESCO ICH project and trained expert annotators with diverse cultural backgrounds to filter low-quality VQA samples, certain questions or their answers might still be offensive to people with certain cultural origins. Since this is subjective, we need to accept it as is for now. Nevertheless, we encourage contacting us if any offensive or otherwise harmful sample raises someones attention."
        },
        {
            "title": "Acknowledgements",
            "content": "We thank our annotators for the CIVQA and CVVQA tasks with special thanks to Timm Dill, Narges Baba Ahmadi, Niloufar Baba Ahmadi, and Abdullah Abdelhafez for their extra efforts. The work of Carolin Holtermann and Anne Lauscher is funded by the Excellence Strategy of the German Federal Government and the Federal States."
        },
        {
            "title": "References",
            "content": "Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat S. Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, Sébastien Bubeck, Martin Cai, Caio César Teodoro Mendes, Weizhu Chen, Vishrav Chaudhary, Parul Chopra, and 68 others. 2024. Phi-3 Technical Report: Highly Capable Language Model Locally on Your Phone. CoRR, abs/2404.14219. Muhammad Farid Adilazuarda, Sagnik Mukherjee, Pradhyumna Lavania, Siddhant Shivdutt Singh, Alham Fikri Aji, Jacki ONeill, Ashutosh Modi, and Monojit Choudhury. 2024. Towards Measuring and Modeling culture in LLMs: Survey. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 1576315784, Miami, Florida, USA. Association for Computational Linguistics. Sanchit Ahuja, Divyanshu Aggarwal, Varun Gumma, Ishaan Watts, Ashutosh Sathe, Millicent Ochieng, Rishav Hada, Prachi Jain, Mohamed Ahmed, Kalika Bali, and Sunayana Sitaram. 2024. MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), NAACL 2024, Mexico City, Mexico, June 16-21, 2024, pages 25982637. Association for Computational Linguistics. Meta AI. 2024. Llama 3.2: Revolutionizing edge ai and vision with open, customizable models. Amith Ananthram, Elias Stengel-Eskin, Carl Vondrick, Mohit Bansal, and Kathleen R. McKeown. 2024. See It from My Perspective: Diagnosing the Western Cultural Bias of Large Vision-language Models in Image Understanding. CoRR, abs/2406.11665. AI Anthropic. 2024. The Claude 3 Model Family: Opus, Sonnet, Haiku. Claude-3 Model Card, 1. Yujin Baek, ChaeHun Park, Jaeseok Kim, YuJung Heo, Du-Seong Chang, and Jaegul Choo. 2024. Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration. CoRR, abs/2406.16469. Mehar Bhatia, Sahithya Ravi, Aditya Chinchure, Eunjeong Hwang, and Vered Shwartz. 2024. From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-language Models. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024, pages 67636782. Association for Computational Linguistics. Shaily Bhatt and Fernando Diaz. 2024. Extrinsic Evaluation of Cultural Competence in Large Language Models. In Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024, pages 1605516074. Association for Computational Linguistics. Olena Burda-Lassen, Aman Chadha, Shashank Goswami, and Vinija Jain. 2024. How Culturally Aware are Vision-language Models? CoRR, abs/2405.17475. Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, Xiaoyi Dong, Haodong Duan, Qi Fan, Zhaoye Fei, Yang Gao, Jiaye Ge, Chenya Gu, Yuzhe Gu, Tao Gui, and 52 others. 2024. InternLM2 Technical Report. CoRR, abs/2403.17297. Yong Cao, Wenyan Li, Jiaang Li, Yifei Yuan, Antonia Karamolegkou, and Daniel Hershcovich. 2024. Exploring Visual Culture Awareness in GPT-4V: Comprehensive Probing. CoRR, abs/2402.06015. Soravit Changpinyo, Linting Xue, Michal Yarom, Ashish Thapliyal, Idan Szpektor, Julien Amelot, Xi Chen, and Radu Soricut. 2023. MaXM: Towards Multilingual Visual 11 In Findings of the Question Answering. Association for Computational Linguistics: EMNLP 2023, pages 26672682, Singapore. Association for Computational Linguistics. Grinsztajn, Yannis Flet-Berliac, and 26 others. 2024. Aya Expanse: Combining Research Breakthroughs for New Multilingual Frontier. CoRR, abs/2412.04261. Lin Chen, Jinsong Li, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Zehui Chen, Haodong Duan, Jiaqi Wang, Yu Qiao, Dahua Lin, and Feng Zhao. 2024a. Are We on the Right Way for Evaluating Large Vision-language Models? In Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024. Zhe Chen, Weiyun Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Erfei Cui, Jinguo Zhu, Shenglong Ye, Hao Tian, Zhaoyang Liu, Lixin Gu, Xuehui Wang, Qingyun Li, Yimin Ren, Zixuan Chen, Jiapeng Luo, Jiahao Wang, Tan Jiang, Bo Wang, and 21 others. 2024b. Expanding Performance Boundaries of Open-source Multimodal Models with Model, Data, and Test-time Scaling. CoRR, abs/2412.05271. Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, Bin Li, Ping Luo, Tong Lu, Yu Qiao, and Jifeng Dai. 2023. InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-linguistic Tasks. CoRR, abs/2312.14238. Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin, Chan Young Park, Shuyue Stella Li, Sahithya Ravi, Mehar Bhatia, Maria Antoniak, Yulia Tsvetkov, Vered Shwartz, and Yejin Choi. 2024. CulturalBench: Robust, Diverse and Challenging Benchmark on Measuring the (Lack of) Cultural Knowledge of LLMs. CoRR, abs/2410.02677. John Dang, Shivalika Singh, Daniel Dsouza, Arash Ahmadian, Alejandro Salamanca, Madeline Smith, Aidan Peppin, Sungjin Hong, Manoj Govindassamy, Terrence Zhao, Sandra Kublik, Meor Amer, Viraat Aryabumi, Jon Ander Campos, Yi Chern Tan, Tom Kocmi, Florian Strub, Nathan Tri Dao. 2024. FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net. Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022. FlashAttention: Fast and Memory-efficient Exact Attention with IO-awareness. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022. Timothée Darcet, Maxime Oquab, Julien Mairal, and Piotr Bojanowski. 2024. Vision Transformers Need Registers. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net. Haodong Duan, Junming Yang, Yuxuan Qiao, Xinyu Fang, Lin Chen, Yuan Liu, Xiaoyi Dong, Yuhang Zang, Pan Zhang, Jiaqi Wang, Dahua Lin, and Kai Chen. 2024. VLMEvalKit: An Open-source ToolKit for Evaluating Large Multi-modality Models. In Proceedings of the 32nd ACM International Conference on Multimedia, MM 2024, Melbourne, VIC, Australia, 28 October 2024 - 1 November 2024, pages 1119811201. ACM. Chaoyou Fu, Peixian Chen, Yunhang Shen, Yulei Qin, Mengdan Zhang, Xu Lin, Zhenyu Qiu, Wei Lin, Jinrui Yang, Xiawu Zheng, Ke Li, Xing Sun, and Rongrong Ji. 2023. MME: Comprehensive Evaluation Benchmark for Multimodal Large Language Models. CoRR, abs/2306.13394. Yi Fung, Ruining Zhao, Jae Doo, Chenkai Sun, and Heng Ji. 2024. Massively Multi-cultural Knowledge Acquisition & LM Benchmarking. CoRR, abs/2402.09369. 12 Iason Gabriel. 2020. Artificial Intelligence, Values, and Alignment. Minds Mach., 30(3):411437. Gregor Geigle, Florian Schneider, Carolin Holtermann, Chris Biemann, Radu Timofte, Anne Lauscher, and Goran Glavaš. 2025. Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model. arXiv, abs/2501.05122. Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, Aleksander Madry, Alex Baker-Whitcomb, Alex Beutel, Alex Borzunov, Alex Carney, Alex Chow, Alex Kirillov, Alex Nichol, Alex Paino, and 79 others. 2024. GPT-4o System Card. CoRR, abs/2410.21276. Antonia Karamolegkou, Phillip Rust, Yong Cao, Ruixiang Cui, Anders Søgaard, and Daniel Hershcovich. 2024. Vision-language Models under Cultural and Inclusive Considerations. CoRR, abs/2407.06177. Wenyan Li, Crystina Zhang, Jiaang Li, Qiwei Peng, Raphael Tang, Li Zhou, Weijia Zhang, Guimin Hu, Yifei Yuan, Anders Søgaard, Daniel Hershcovich, and Desmond Elliott. 2024. FoodieQA: Multimodal Dataset for Fine-grained Understanding of Chinese Food Culture. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 19077 19095, Miami, Florida, USA. Association for Computational Linguistics."
        },
        {
            "title": "Fangyu",
            "content": "Liu,"
        },
        {
            "title": "Emanuele",
            "content": "Bugliarello, Edoardo Maria Ponti, Siva Reddy, Nigel Collier, and Desmond Elliott. 2021. Visually Grounded Reasoning across In Proceedings Languages and Cultures. of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pages 1046710485. Association for Computational Linguistics. In Advances in Neural Information ing. Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023. Sagnik Mukherjee, Muhammad Farid Adilazuarda, Sunayana Sitaram, Kalika Bali, Alham Fikri Aji, and Monojit Choudhury. 2024. Cultural Conditioning or Placebo? On the Effectiveness of Socio-demographic In Proceedings of the 2024 Prompting. Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024, pages 1581115837. Association for Computational Linguistics. Junho Myung, Nayeon Lee, Yi Zhou, Jiho Jin, Rifki Afina Putri, Dimosthenis Antypas, Hsuvas Borkakoty, Eunsu Kim, Carla Perez-Almendros, Abinew Ali Ayele, and 1 others. 2024. BLEnD: Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages. arXiv preprint arXiv:2406.09948. Tarek Naous, Michael J. Ryan, Alan Ritter, and Wei Xu. 2024. Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 1116, 2024, pages 1636616393. Association for Computational Linguistics. Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva Reddy, Sjoerd van Steenkiste, Lisa Anne Hendricks, Karolina Stanczak, and Aishwarya Agrawal. 2024. Benchmarking Vision Language Models for Cultural the Understanding. 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024, pages 57695790. Association for Computational Linguistics."
        },
        {
            "title": "In Proceedings of",
            "content": "Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023. Visual Instruction TunMalvina Nikandrou, Georgios Pantazopoulos, Nikolas Vitsakis, Ioannis Konstas, and 13 Alessandro Suglia. 2024. CROPE: Evaluating In-context Adaptation of Vision and Language Models to Culture-specific Concepts. CoRR, abs/2410.15453. OpenAI. 2023. GPT-4 Vision System Card. Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy V. Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel HAZIZA, Francisco Massa, Alaaeldin ElNouby, Mido Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, PoYao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, and 7 others. 2024. DINOv2: Learning Robust Visual Features without Supervision. Transactions on Machine Learning Research. Featured Certification. David Romero, Chenyang Lyu, Haryo Akbarianto Wibowo, Santiago Góngora, Aishik Mandal, Sukannya Purkayastha, Jesús-Germán Ortiz-Barajas, Emilio Villa-Cueva, Jinheon Baek, Soyeong Jeong, Injy Hamed, Zheng Xin Yong, Zheng Wei Lim, Paula Mónica Silva, Jocelyn Dunstan, Mélanie Jouitteau, David Le Meur, Joan Nwatu, Ganzorig Batnasan, and 57 others. 2024. CVQA: Culturally-diverse Multilingual Visual Question Answering In Advances in Neural Benchmark. Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024. Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal, and Aman Chadha. 2024. Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications. CoRR, abs/2402.07927. Florian Schneider and Sunayana Sitaram. 2024. M5 - Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-language Tasks. In Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024, pages 43094345. Association for Computational Linguistics. Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, and 1 others. 2024. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530. Ashish V. Thapliyal, Jordi Pont-Tuset, Xi Chen, and Radu Soricut. 2022. Crossmodal-3600: Massively MultilinIn gual Multimodal Evaluation Dataset. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 715729. Association for Computational Linguistics. Norawit Urailertprasert, Peerat Limkonchotiwat, Supasorn Suwajanakorn, and Sarana Nutanong. 2024. SEA-VQA: Southeast Asian Cultural Context Dataset For Visual Question Answering. In Proceedings of the 3rd Workshop on Advances in Language and Vision Research (ALVR), pages 173185, Bangkok, Thailand. Association for Computational Linguistics. Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, and Junyang Lin. 2024. Qwen2-VL: Enhancing Visionlanguage Models Perception of the World at Any Resolution. CoRR, abs/2409.12191. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. Chain-of-thought Prompting Elicits Reasoning in Large Language Models. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022. 14 Zhenzhu Yang, Yibo Liu, Wenhao Huang, and 3 others. 2024. MMMU: Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2024, Seattle, WA, USA, June 16-22, 2024, pages 95569567. IEEE. Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2023. Automatic Chain of Thought Prompting in Large Language Models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net. Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2024. Take Step Back: Evoking Reasoning via Abstraction in Large Language Models. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging LLM-asa-judge with MT-bench and Chatbot Arena. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023."
        },
        {
            "title": "Genta",
            "content": "Indra Winata, Frederikus Hudi, Patrick Amadeus Irawan, David Anugraha, Rifki Afina Putri, Yutong Wang, Adam Nohejl, Ubaidillah Ariq Prathama, Nedjma Ousidhoum, Afifa Amriani, Anar Rzayev, Anirban Das, Ashmari Pramodya, Aulia Adila, Bryan Wilie, Candy Olivia Mawalim, Ching Lam Cheng, Daud Abolade, Emmanuele Chersoni, and 32 others. 2024. WorldCuisines: Massive-scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines. CoRR, abs/2410.12705. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, and Jamie Brew. 2019. HuggingFaces Transformers: Stateof-the-art Natural Language Processing. CoRR, abs/1910.03771. Tianyi Xiong, Xiyao Wang, Dong Guo, Qinghao Ye, Haoqi Fan, Quanquan Gu, Heng Huang, and Chunyuan Li. 2024. LLaVACritic: Learning to Evaluate Multimodal Models. CoRR, abs/2410.02712. An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, and 22 others. 2024. Qwen2.5 Technical Report. CoRR, abs/2412.15115. Yuan Yao, Tianyu Yu, Ao Zhang, Chongyi Wang, Junbo Cui, Hongji Zhu, Tianchi Cai, Haoyu Li, Weilin Zhao, Zhihui He, Qianyu Chen, Huarong Zhou, Zhensheng Zou, Haoye Zhang, Shengding Hu, Zhi Zheng, Jie Zhou, Jie Cai, Xu Han, and 4 others. 2024. MiniCPM-V: GPT-4V Level MLLM on Your Phone. CoRR, abs/2408.01800. Xiang Yue, Yuansheng Ni, Tianyu Zheng, Kai Zhang, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng,"
        },
        {
            "title": "A GIMMICK Benchmark Details",
            "content": "A.1 Data License GIMMICK is built upon the open-access data from the UNESCO Intangible Cultural Heritage (ICH) project, which is organized as knowledge graph. The graph can be downloaded in English, French, and Spanish on the ICH project website: https://ich.unesco.org/en/open-accessto-dive-data-01218, with details about its structure and subsets also provided. In GIMMICK, we work with the English graph only. The open-access license of the knowledge graph is defined on the UNESCO website13 as follows: By open access to the literature, we mean its free availability on the public internet, permitting any users to read, download, copy, distribute, print, search, or link to the full texts of these articles, crawl them for indexing, pass them as data to software, or use them for any other lawful purpose, without financial, legal, or technical barriers other than those inseparable from gaining access to the internet itself. The images and videos within the data are shared via URLs and hosted by UNESCO or on YouTube, respectively. Further, each image and video node in the knowledge graph has individual copyright information attached. However, the licenses themselves are not discussed, and merely the name of the photographer or institution or UNESCO itself is stated. Unfortunately, we did not receive an answer to multiple emails in which we asked for clarification. Hence, we assume that the image and video content also fall under the definition of open access. If you are copyright holder of any of the images or videos and do not want your intellectual property to be used or shared by us, please reach out via email: florian.schneider-1@uni-hamburg.de. A.2 Cultural Event or Facets (CEFs) A.2.1 Examples In the following, we provide one example of CEFs per region from the UNESCO ICH project. We also use the same information for the CKQAN and CKQAD tasks. 13https://www.unesco.org/en/open-access 16 Western Europe ( W) Title: The skills related to perfume in Pays de Grasse: the cultivation of perfume plants, the knowledge and processing of natural raw materials, and the art of perfume composition Countries: France Regions: Western European and North American States Description: The skills related to perfume in Pays de Grasse cover three different aspects: the cultivation of perfume plants; the knowledge and processing of natural raw materials; and the art of perfume composition. The practice involves wide range of communities and groups, brought together under the Association du Patrimoine Vivant du Pays de Grasse (Living Heritage Association of the Region of Grasse). Since at least the sixteenth century, the practices of growing and processing perfume plants and creating fragrant blends have been developed in Pays de Grasse, in craft industry long dominated by leather tanning. Perfume plant cultivation involves wide range of skills and knowledge, for instance pertaining to nature, soil, weather, biology, plant physiology and horticultural practices, as well as specific techniques such as extraction and hydraulic distillation methods. The inhabitants of Grasse have made these techniques their own and helped improve them. In addition to technical skills, however, the art also calls for imagination, memory and creativity. Perfume forges social bonds and provides an important source of seasonal labour. Related knowledge is mostly transmitted informally through long learning process that still takes place primarily in perfumeries. In recent decades, however, there has been growing interest in standardizing learning through formalized teaching. UNESCO ICH URL: https://ich.unesco.org/en/RL/the-skills-related-to-perfume-i... Copyrigth: APVPG JM. Ghibaudo Copyrigth: Musées de Grasse 2011 Copyrigth: N. Bédar APVPG 2015 Copyrigth: C. Barbiero/Musées de Grasse 2010 Copyrigth: Daniel, Serre, M. Roudnitska APVPG 2014 Copyrigth: Musées de Grasse Copyrigth: G. Voinot/Université Sophia Antiopolis 2011 Copyrigth: Esat Les Restanques 2013 Copyrigth: Forum des Associations Pays de Grasse 2014 Copyrigth: PH. Massé APVPG 2014 17 Eastern Europe ( E) Title: Cultural Heritage of Boka Navy Kotor: festive representation of memory and cultural identity Countries: Montenegro Regions: Eastern European States Description: Boka Navy is traditional, non-governmental maritime organization founded in Kotor, Montenegro in 809. Its origin is linked to the arrival of the relics of St. Tryphon, the patron saint of the city of Kotor. Comprised of community of seafarers with military, economic, educational and humanitarian functions, Boka Navy has played memorial role for two centuries, preserving and promoting maritime history and tradition. Membership is voluntary and open to men, women and children of all ages. The organization is founded on the respect of human rights and of religious, national and cultural diversity. During formal celebrations, members wear colourful traditional uniforms, carry historic weapons and perform the traditional circle kolo dance. Boka Navy is the backbone of the annual St. Tryphon festivities, which take place from 13 January through 3 February and include procession and series of rituals in the cathedral. The external festivities begin with the Boka Navys traditional kolo circle dance and are followed by procession carrying the relics of St. Tryphon through the main town squares and streets. Thousands of spectators attend the processions in the historic centre and observe the festive events. Hundreds of women, men and children also participate in preparations of the activities. UNESCO ICH URL: https://ich.unesco.org/en/RL/cultural-heritage-of-boka-navy-... Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Copyrigth: Ministry of Culture of Montenegro Arab ( A) Title: Arts, skills and practices associated with engraving on metals (gold, silver and copper) Countries: Algeria, Saudi Arabia, Egypt, Iraq, Morocco, Mauritania, Palestine, Sudan, Tunisia, Yemen Regions: Arab States Description: Engraving on metals such as gold, silver and copper is centuries-old practice that entails manually cutting words, symbols or patterns into the surfaces of decorative, utilitarian, religious or ceremonial objects. The craftsperson uses different tools to manually cut symbols, names, Quran verses, prayers and geometric patterns into the objects. Engravings can be concave (recessed) or convex (elevated), or the result of combination of different types of metals, such as gold and silver. Their social and symbolic meanings and functions vary according to the communities concerned. Engraved objects, such as jewelry or household objects, are often presented as traditional gifts for weddings or used in religious rituals and alternative medicine. For instance, certain types of metals are believed to have healing properties. Engraving on metals is transmitted within families, through observation and hands-on practice. It is also transmitted through workshops organized by training centres, organizations and universities, among others. Publications, cultural events and social media further contribute to the transmission of the related knowledge and skills. Practised by people of all ages and genders, metal engraving and the use of engraved objects are means of expressing the cultural, religious and geographical identity and the socioeconomic status of the communities concerned. UNESCO ICH URL: https://ich.unesco.org/en/RL/arts-skills-and-practices-assoc... Copyrigth: Huzaifa Ayad Bahaa El Din, Iraq, 2021 Copyrigth: Huzaifa Ayad Bahaa El Din, Iraq, 2021 Copyrigth: Huzaifa Ayad Bahaa El Din, Iraq, 2021 Copyrigth: Zahia Benabdallah, Algeria, Copyrigth: Azza Fahmi, Egypt, 2021 Copyrigth: Mustafa Kamil, Egypt, 2021 Copyrigth: National Heritage Preservation, Ministry of Culture, Youth and Sport and Relations with the Parliament, Egypt, 2022 Copyrigth: Direction du Patrimoine Culturel, Morocco, 2021 Copyrigth: Direction du Patrimoine Culturel, Morocco, 2021 Copyrigth: Ministry of Culture, Palestine, 19 Asia and Pacific ( AP) Title: Tugging rituals and games Countries: Cambodia, Korea, Philippines, Vietnam Regions: Asian and Pacific States Description: Tugging rituals and games in the rice-farming cultures of East Asia and Southeast Asia are enacted among communities to ensure abundant harvests and prosperity. They promote social solidarity, provide entertainment and mark the start of new agricultural cycle. Many tugging rituals and games also have profound religious significance. Most variations include two teams, each of which pulls one end of rope attempting to tug it from the other. The intentionally uncompetitive nature of the event removes the emphasis on winning or losing, affirming that these traditions are performed to promote the well-being of the community, and reminding members of the importance of cooperation. Many tugging games bear the traces of agricultural rituals, symbolizing the strength of natural forces, such as the sun and rain while also incorporating mythological elements or purification rites. Tugging rituals and games are often organized in front of villages communal house or shrine, preceded by commemorative rites to local protective deities. Village elders play active roles in leading and organizing younger people in playing the game and holding accompanying rituals. Tugging rituals and games also serve to strengthen unity and solidarity and sense of belonging and identity among community members. UNESCO ICH URL: https://ich.unesco.org/en/RL/tugging-rituals-and-games-01080... Copyrigth: Siyonn Sophearith, 2013 Copyrigth: Siyonn Sophearith, 2013 Copyrigth: Siyonn Sophearith, Copyrigth: Renato S. Rastrollo, NCCA Copyrigth: Renato S. Rastrollo, NCCA Copyrigth: Vietnam Institute of Culture and Arts Studies, 2013 Copyrigth: Vietnam Institute of Culture and Arts Studies, 2013 Copyrigth: 2006 Joo Byung Soo, Copyrigth: 2006 Joo Byung Soo, 20 Latin America & Caribbean ( LAC) Title: Ancestral system of knowledge of the four indigenous peoples, Arhuaco, Kankuamo, Kogui and Wiwa of the Sierra Nevada de Santa Marta Countries: Colombia Regions: Latin-American and Caribbean States Description: The Ancestral System of Knowledge of the Arhuaco, Kankuamo, Kogui and Wiwa peoples of the Sierra Nevada de Santa Marta is comprised of sacred mandates that keep the existence of the Through many years of four peoples in harmony with the physical and spiritual universe. dedication, the knowledgeable men (Mamos) and women (Sagas) acquire the necessary skills and sensitivity to communicate with the snow-capped peaks, connect with the knowledge of the rivers and decipher the messages of nature. Based on the Law of Origin, philosophy that governs human relationships to nature and the universe, the Ancestral System of Knowledge entails caring for sacred sites and partaking in baptism rituals, marriage rites, traditional dances and songs, and retributions or offerings to spiritual powers. This ancestral wisdom is believed to play fundamental role in protecting the Sierra Nevada ecosystem and avoiding the loss of the cultural identity of the four peoples of the region. The Ancestral System of Knowledge is transmitted from generation to generation through cultural practice, community activities, the use of the indigenous language and the implementation of the sacred mandates. The transmission process includes the understanding of physical and spiritual relationships with Mother Nature and sacred sites. UNESCO ICH URL: https://ich.unesco.org/en/RL/ancestral-system-of-knowledge-o... Copyrigth: William Diaz, Copyrigth: Suarez/Government Magdalena,"
        },
        {
            "title": "Jorge Mario\nof",
            "content": "Copyrigth: Suarez/Government Magdalena,"
        },
        {
            "title": "Jorge Mario\nof",
            "content": "Copyrigth: William Diaz, 2021 Copyrigth: Suarez/Government Magdalena,"
        },
        {
            "title": "Jorge Mario\nof",
            "content": "Copyrigth: Suarez/Government Magdalena,"
        },
        {
            "title": "Jorge Mario\nof",
            "content": "Copyrigth: Suarez/Government Magdalena,"
        },
        {
            "title": "Jorge Mario\nof",
            "content": "Copyrigth: Suarez/Government Magdalena,"
        },
        {
            "title": "Jorge Mario\nof",
            "content": "Copyrigth: Suarez/Government Magdalena,"
        },
        {
            "title": "Jorge Mario\nof",
            "content": "Copyrigth: William Diaz, 2021 21 Subsaharian Africa ( SA) Title: Gada system, an indigenous democratic socio-political system of the Oromo Countries: Ethiopia Regions: Subsaharian African States Description: Gada is traditional system of governance used by the Oromo people in Ethiopia developed from knowledge gained by community experience over generations. The system regulates political, economic, social and religious activities of the community dealing with issues such as conflict resolution, reparation and protecting womens rights. It serves as mechanism for enforcing moral conduct, building social cohesion, and expressing forms of community culture. Gada is organized into five classes with one of these functioning as the ruling class consisting of chairperson, officials and an assembly. Each class progresses through series of grades before it can function in authority with the leadership changing on rotational basis every eight years. Class membership is open to men, whose fathers are already members, while women are consulted for decision-making on protecting womens rights. The classes are taught by oral historians covering history, laws, rituals, time reckoning, cosmology, myths, rules of conduct, and the function of the Gada system. Meetings and ceremonies take place under sycamore tree (considered the Gada symbol) while major clans have established Gada centres and ceremonial spaces according to territory. Knowledge about the Gada system is transmitted to children in the home and at school. UNESCO ICH URL: https://ich.unesco.org/en/RL/gada-system-an-indigenous-democ... Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 Copyrigth: Authority for Research and Conservation of Cultural Heritage (ARCCH), Ethiopia, 2014 A.2.2 CEFs as Python dataclass Listing 1 presents CEF implemented as Python dataclass. from dataclasses import dataclass @dataclass class CEF: title: str description: str countries: list[str] regions: list[str] images: list[str] # URLs videos: list[str] # URLs Listing 1: Python pseudo-code for dataclass representing CEF."
        },
        {
            "title": "Arab",
            "content": "Asia & Pacific"
        },
        {
            "title": "Eastern Europe",
            "content": "A AP Latin-America & Caribbean"
        },
        {
            "title": "Subsaharian Africa",
            "content": "SA Western Europe & North America Abbrv. Countries Countries"
        },
        {
            "title": "23 Andorra, Austria, Belgium, Canada, Cyprus, Denmark, Finland,\nFrance, Germany, Greece, Iceland, Ireland, Italy, Luxembourg,\nMalta, Netherlands, Norway, Portugal, Spain, Sweden, Switzer-\nland, Türkiye, United Kingdom of Great Britain and Northern\nIreland",
            "content": "Table 4: Caption A.3 Regions A.3.1 Number of Samples per Task per Region A.4 Models We present the comprehensive list of all 31 models evaluated in GIMMICK in Table 6."
        },
        {
            "title": "B CIVQA Details",
            "content": ""
        },
        {
            "title": "A\nA AP\nA AP E W\nA E W\nA SA\nAP\nAP E\nAP E LAC SA W\nAP E W\nAP W\nE\nE W\nLAC\nLAC W\nSA\nW",
            "content": "375 4 5 1 8 444 7 1 10 4 302 21 420 2 388 241 296 4 5 0 0 407 7 1 7 3 242 20 341 2 299 175 COQAR 71 2 0 3 2 211 6 0 21 2 125 22 96 2 71 125 COQAC 127 2 36 7 3 222 6 8 35 3 136 56 106 2 80 153 CKQAD 71 1 2 1 1 211 3 1 7 1 125 11 96 1 71 125 CKQAN 71 1 2 1 1 211 3 1 7 1 125 11 96 1 71 Table 5: Number of samples per region(s) in GIMMICK tasks."
        },
        {
            "title": "PAPER NAME",
            "content": "OPEN-WEIGHT"
        },
        {
            "title": "IMAGE INPUT VIDEO INPUT TEXT INPUT LLM BACKBONE",
            "content": "claude-3-5-sonnet-20241022 gemini-1.5-pro-002 gemini-1.5-flash-002 gpt-4o-2024-11-20 gpt-4o-mini-2024-07-18 Claude 3.5 Sonnet (Anthropic, 2024) Gemini Pro (Team et al., 2024) Gemini Flash (Team et al., 2024) GPT-4o (Hurst et al., 2024) GPT-4o Mini (Hurst et al., 2024) opengvlab/internvl2_5-78b qwen/qwen2-vl-72b-instruct InternVL2.5 78B (Chen et al., 2024b) Qwen2 VL 72B (Wang et al., 2024) InternVL2.5 26B (Chen et al., 2024b) InternVL2.5 38B (Chen et al., 2024b) meta-llama/llama-3.2-11b-vision-instruct Llama 3.2 11B Vision opengvlab/internvl2_5-38b opengvlab/internvl2_5-26b qwen/qwen2-vl-7b-instruct openbmb/minicpm-v-2_6 wuenlp/centurio_aya opengvlab/internvl2_5-8b wuenlp/centurio_qwen qwen/qwen2-vl-2b-instruct microsoft/phi-3.5-vision-instruct opengvlab/internvl2_5-4b opengvlab/internvl2_5-1b opengvlab/internvl2_5-2b qwen/qwen2.5-72b-instruct qwen/qwen2.5-32b-instruct internlm/internlm2_5-20b-chat cohereforai/aya-expanse-8b internlm/internlm2_5-7b-chat qwen/qwen2.5-7b-instruct qwen/qwen2.5-0.5b-instruct qwen/qwen2.5-3b-instruct qwen/qwen2.5-1.5b-instruct internlm/internlm2_5-1_8b-chat microsoft/phi-3.5-mini-instruct (AI, 2024) Qwen2 VL 7B (Wang et al., 2024) MiniCPM 2.6 (Yao et al., 2024) Centurio Aya (Geigle et al., 2025) InternVL2.5 8B (Chen et al., 2024b) Centurio Qwen (Geigle et al., 2025) Qwen2 VL 2B (Wang et al., 2024) Phi 3.5 Vision (Abdin et al., 2024) InternVL2.5 4B (Chen et al., 2024b) InternVL2.5 1B (Chen et al., 2024b) InternVL2.5 2B (Chen et al., 2024b) Qwen2.5 72B (Yang et al., 2024) Qwen2.5 32B (Yang et al., 2024) InternLM2.5 20B (Cai et al., 2024) Aya Expanse 8B (Dang et al., 2024) InternLM2.5 7B (Cai et al., 2024) Qwen2.5 7B (Yang et al., 2024) Qwen2.5 0.5B (Yang et al., 2024) Qwen2.5 3B (Yang et al., 2024) Qwen2.5 1.5B (Yang et al., 2024) InternLM2.5 1.8B (Cai et al., 2024) Phi 3.5 Mini (Abdin et al., 2024) No No No No No"
        },
        {
            "title": "Yes",
            "content": "A A XL XL M M S S XL M S S S"
        },
        {
            "title": "Yes",
            "content": "No No No No No No No No No No No"
        },
        {
            "title": "Yes",
            "content": "No No No No No No No No No No No"
        },
        {
            "title": "Yes",
            "content": "qwen/qwen2.5-72b-instruct qwen/qwen2.5-72b-instruct internlm/internlm2_5-20b-chat qwen/qwen2.5-32b-instruct qwen/qwen2.5-7b-instruct cohereforai/aya-expanse-8b internlm/internlm2_5-7b-chat qwen/qwen2.5-7b-instruct qwen/qwen2.5-1.5b-instruct microsoft/phi-3.5-mini-instruct qwen/qwen2.5-3b-instruct qwen/qwen2.5-0.5b-instruct internlm/internlm2_5-1_8b-chat Table 6: Details about the models evaluated within the GIMMICK benchmark. The size indicates that the model is proprietary API model with unknown size. 25 B.1 Examples In the following, we provide one random sample per region for the CIVQA task. Note that the lower part of the examples, where the related CEF is provided, is not part of the actual sample. Question: What title is given to the woman wearing the sash in the image? Answer: Cherry Queen Copyrigth: Conseil municipal de Sefrou,"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Cherry festival in Sefrou Countries: Morocco Regions: Arab States Description: For three days in June each year, the local population of Sefrou celebrates the natural and cultural beauty of the region, symbolized by the cherry fruit and that years newly chosen Cherry Queen, selected during pageant that draws competitors from the region and entire country. The highlight of the festival is parade with performing troupes, rural and urban music, majorettes and bands, and floats featuring local producers. At the centre is the Cherry Queen, who offers cherries to onlookers while dressed ornately and surrounded by attendants. The whole population contributes to the success of the festival: craftswomen make silk buttons for traditional dresses, fruit growers supply cherries, local sports clubs participate in competitions, and music and dancing troupes animate the entire festival. The cherry festival provides an opportunity for the entire city to present its activities and achievements. The younger generation are also integrated into festival activities to ensure their sustainability. The festival is source of pride and belonging that enhances the self-esteem of the city and its people and constitutes fundamental contribution to their local identity. UNESCO ICH URL: https://ich.unesco.org/en/RL/cherry-festival-in-sefrou-00641... 26 AP Copyrigth: 2010 by Centre for Research and Development of Culture, Indonesia Question: What traditional dance are the performers engaging in, as seen in the image? Answer: Saman dance"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Saman dance Countries: Indonesia Regions: Asian and Pacific States Description: The Saman dance is part of the cultural heritage of the Gayo people of Aceh province in Sumatra. Boys and young men perform the Saman sitting on their heels or kneeling in tight rows. Each wears black costume embroidered with colourful Gayo motifs symbolizing nature and noble values. The leader sits in the middle of the row and leads the singing of verses, mostly in the Gayo language. These offer guidance and can be religious, romantic or humorous in tone. Dancers clap their hands, slap their chests, thighs and the ground, click their fingers, and sway and twist their bodies and heads in time with the shifting rhythm in unison or alternating with the moves of opposing dancers. These movements symbolize the daily lives of the Gayo people and their natural environment. The Saman is performed to celebrate national and religious holidays, cementing relationships between village groups who invite each other for performances. The frequency of Saman performances and its transmission are decreasing, however. Many leaders with knowledge of the Saman are now elderly and without successors. Other forms of entertainment and new games are replacing informal transmission, and many young people now emigrate to further their education. Lack of funds is also constraint, as Saman costumes and performances involve considerable expense. UNESCO ICH URL: https://ich.unesco.org/en/USL/saman-dance-00509... 27 Copyrigth: 2010 by M.Rahimov/Ministry of Culture and Tourism Question: What is the name of the musical instrument observed by the man in the image? Answer: Tar"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Craftsmanship and performance art of the Tar, long-necked string musical instrument Countries: Azerbaijan Regions: Eastern European States Description: The Tar is long-necked plucked lute, traditionally crafted and performed in communities throughout Azerbaijan. Considered by many to be the countrys leading musical instrument, it features alone or with other instruments in numerous traditional musical styles. Tar makers transmit their skills to apprentices, often within the family. Craftsmanship begins with careful selection of materials for the instrument: mulberry wood for the body, nut wood for the neck, and pear wood for the tuning pegs. Using various tools, crafters create hollow body in the form of figure eight, which is then covered with the thin pericardium of an ox. The fretted neck is affixed, metal strings are added and the body is inlaid with mother-of-pearl. Performers hold the instrument horizontally against the chest and pluck the strings with plectrum, while using trills and variety of techniques and strokes to add colour. Tar performance has an essential place in weddings and different social gatherings, festive events and public concerts. Players transmit their skills to young people within their community by word of mouth and demonstration, and at educational musical institutions. Craftsmanship and performance of the tar and the skills related to this tradition play significant role in shaping the cultural identity of Azerbaijanis. UNESCO ICH URL: https://ich.unesco.org/en/RL/craftsmanship-and-performance-a..."
        },
        {
            "title": "LAC",
            "content": "Question: What traditional tool from the Guaraní culture is depicted in the image for drinking Terere? Answer: Bombilla Copyrigth: Py,"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Practices and traditional knowledge of Terere in the culture of Pohã Ñana, Guaraní ancestral drink in Paraguay Countries: Paraguay Regions: Latin-American and Caribbean States Description: The practices and traditional knowledge of Terere in the culture of Pohã Ñana, Guaraní ancestral drink in Paraguay, are widespread in the Paraguayan territory and involve variety of bearers. Terere is traditional drink prepared in jug or thermos, in which cold water is mixed with Pohã Ñana crushed in mortar. It is served in glass pre-filled with yerba mate and sucked with bombilla (metal or cane straw). Preparing the Terere is an intimate ritual involving series of pre-established codes and each Pohã Ñana herb has health benefits linked to popular wisdom passed down through the generations. Terere practices in the culture of Pohã Ñana have been transmitted in Paraguayan families since approximately the sixteenth century. Traditional knowledge about the healing attributes of the medicinal herbs that make up the Pohã Ñana and their correct use are also transmitted spontaneously within the family. In recent years, the figure of apprentices has risen, but family transmission remains the main mode of transmission. The practice of the Terere in the culture of Pohã Ñana fosters social cohesion as the time and space dedicated to preparing and consuming the Terere promote inclusion, friendship, dialogue, respect and solidarity. The practice also strengthens new generations appreciation of the rich cultural and botanical heritage of Guaraní origin. UNESCO ICH URL: https://ich.unesco.org/en/RL/practices-and-traditional-knowl... 29 SA Copyrigth: The Authority for Research and Conservation of Cultural Heritage (ARCCH), 2013 Question: What festival are the people in the image celebrating? Answer: Fichee-Chambalaalla"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Fichee-Chambalaalla, New Year festival of the Sidama people Countries: Ethiopia Regions: Subsaharian African States Description: Fichee-Chambalaalla is New Year festival celebrated among the Sidama people. According to the oral tradition, Fichee commemorates Sidama woman who visited her parents and relatives once year after her marriage, bringing buurisame, meal prepared from false banana, milk and butter, which was shared with neighbours. Fichee has since become unifying symbol of the Sidama people. Each year, astrologers determine the correct date for the festival, which is then announced to the clans. Communal events take place throughout the festival, including traditional songs and dances. Every member participates irrespective of age, gender and social status. On the first day, children go from house to house to greet their neighbours, who serve them buurisame. During the festival, clan leaders advise the Sidama people to work hard, respect and support the elders, and abstain from cutting down indigenous trees, begging, indolence, false testimony and theft. The festival therefore enhances equity, good governance, social cohesion, peaceful co-existence and integration among Sidama clans and the diverse ethnic groups in Ethiopia. Parents transmit the tradition to their children orally and through participation in events during the celebration. Women in particular, transfer knowledge and skills associated with hairdressing and preparation of buurisame to their daughters and other girls in their respective villages. UNESCO ICH URL: https://ich.unesco.org/en/RL/fichee-chambalaalla-new-year-fe... 30 Question: What specific regions attire is represented by the figures in the image? Answer: Alentejo Copyrigth: Município de Estremoz,"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Craftmanship of Estremoz clay figures Countries: Portugal Regions: Western European and North American States Description: The Craftsmanship of Estremoz Clay Figures involves production process lasting several days: the elements of the figures are assembled before being fired in an electric oven and then painted by the artisan and covered with colourless varnish. The clay figures are dressed in the regional attires of Alentejo or the clothing of religious Christian iconography, and follow specific themes. The production of clay figures in Estremoz dates back to the seventeenth century, and the very characteristic aesthetic features of the figures make them immediately identifiable. The craft is strongly attached to the Alentejo region, since the vast majority of the figures depict natural elements, local trades and events, popular traditions and devotions. The viability and recognition of the craft are ensured through non-formal education workshops and pedagogical initiatives by the artisans, as well as by the Centre for the Appreciation and Safeguarding of the Estremoz Clay Figure. Fairs are organized at the local, national and international levels. Knowledge and skills are transmitted both in family workshops and professional contexts, and artisans teach the basics of their craft through non-formal training initiatives. Artisans are actively involved in awareness-raising activities organized in schools, museums, fairs and other events. UNESCO ICH URL: https://ich.unesco.org/en/RL/craftmanship-of-estremoz-clay-f... B.2 Cultural Aspects During the synthetic data generation phase of the CIVQA, we also obtained target aspect per question (see B.4 and B.4.1). We report these aspects in the following. B.3 External Hint Variations For the CIVQA (and CVVQA) task, we ablate the effect of external cues or hints on the task performance of models. In the following, we provide the Python pseudo-code snippet to generate the prompt for given sample. B.4 Synthetic Data Generation"
        },
        {
            "title": "Questions",
            "content": "traditions rituals art music craftsmanship instruments festivals dance tools food clothing architecture sports location symbols drinks customs cultural significance theatre 390 241 233 210 177 155 151 150 108 96 93 52 38 28 19 14 13 6 4 education culture games performing arts language performance characters practices skills origin cultural identity technology people community identity environment traditional medicine nature communication 3 3 3 3 3 3 2 2 2 2 2 1 1 1 1 1 1 1 1 jewelry objects animal plants process agriculture celebrations details historical function or usage symbolism healthcare knowledge social status religion cultural space social space cultural practice unknown Table 7: Cultural aspects targeted by the questions within the CIVQA task. 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Python Pseudo-Code for the external cue settings of the CIVQA and CVVQA tasks. def apply_gimmick_prompt_template( sample: dict[str, Any], regions_hint: bool, countries_hint: bool, ) -> str: prompt_template = \"{QUESTION}n{HINTS}n\" hints = \"\" if regions_hint: hints += ( \"Hint: The question is related to cultural event or facet from the following region(s): \" (cid:44) f\"{', '.join(sample['regions'])}n\" ) if countries_hint: hints += ( \"Hint: The question is related to cultural event or facet from the following country or countries: \" (cid:44) f\"{', '.join(sample['countries'])}n\" ) return prompt_template.format( QUESTION=sample[\"prompt\"], HINTS=hints, ) Figure 73: Python Pseudo-Code to generate the prompt for given CIVQA (or CVVQA) sample for the external cues settings. 32 B.4.1 System Prompt # Your Role"
        },
        {
            "title": "You are a professional annotator specialized in creating VQA samples based on a provided",
            "content": "(cid:44) (cid:44) intangible cultural heritage(ICH) item. You will be given the following information related to the item: - Image: An image representing one aspect of the ICH item. - Countries of Origin: The country or countries where this ICH is recognized. - Regions of Origin: The country or countries where this ICH is recognized. - Title: The official title of the ICH item. - Description: detailed description of the ICH item, including relevant details. # Your Task (cid:44) Your task is it to generate high-quality question-answer pairs in VQA style to assess the cultural knowledge of the intangible cultural heritage (ICH) item of state-of-the-art multimodal AI models. Be sure to follow the annotation guidelines provided below to ensure the quality and relevance of the question-answer pairs. (cid:44) (cid:44) # Annotation Guidelines ## Question Requirements Make sure the question meets all of the following requirements: 1. Clear and Concise The question is clear and concise and no longer than single sentence. 2. Directly related to the ICH item The question is directly related to the ICH item. 3. Directly related to the visible content"
        },
        {
            "title": "The question is directly related to the visible content in the image and requires visual",
            "content": "(cid:44) analysis to answer. 4. Does not (partially) contain the answer"
        },
        {
            "title": "The question does not contain any hints or clues to or parts of the answer that would make",
            "content": "(cid:44) the answer obvious. 5. Does not contain subjective words (cid:44) (cid:44) The question does not contain subjective words like 'likely', 'possibly', 'probably', 'eventually', 'might', 'could', 'should', etc., which could introduce ambiguity. 6. Requires both image and cultural knowledge to answer The question requires both image and cultural knowledge to answer and is not answerable by looking only at the image or only knowing about the ICH item or reading the textual description. (cid:44) 7. (optional) Includes specific cultural terms The answer includes specific cultural terms, names, or phrases related to the ICH item. (cid:44) E.g., particular names mentioned in the description or parts of the title. ## Answer Requirements Make sure the answer meets all of the following requirements: 1. Single Word or Multiword Expression The answer is single word or multiword expression. 2. Clear, Objective, and Correct The answer is clear, objective, and unambiguously correct. 3. Directly Related to Visual Content The answer is directly related to the visual content of the image. 4. No General or Abstract Words (cid:44) The answer does not contain general, abstract, or non-depictable words like \"Traditional\", \"Cooperation\", \"Gathering\", \"Solidarity\", \"Community\", \"Indoor\", \"Outdoor\", \"Urban\", \"Rural\", etc. 5. Verifiable by Text and Image (cid:44)"
        },
        {
            "title": "The answer is unambiguously verifiable by reading the textual information and inspecting",
            "content": "(cid:44) the image. 6. (optional) Includes specific cultural terms The answer includes specific cultural terms, names, or phrases related to the ICH item. (cid:44) E.g., particular names mentioned in the description or parts of the title. 33 ## Question Characteristics ### Target Aspects Make sure the question targets different aspects of the ICH item, such as: - Food - Drinks - Clothing - Art - Tools - Sports - Instruments - Dance - Music - Rituals - Traditions - Festivals - Customs - Symbols - Architecture - Other ### Question Categories Make sure the question falls into different categories, such as: - Identification Questions that ask for the identification of objects, people, or elements in the image. E.g.: What is the name of the instrument shown in the image? (cid:44) - Origin (cid:44) (cid:44) (cid:44) (cid:44) - Location (cid:44) - Symbolism (cid:44) - Historical (cid:44) - Details (cid:44) - Other Questions that inquire about the origin or source of the CEF. E.g.: Which culture or country does this artifact belong to? - Cultural Significance Questions that explore the cultural or religious significance of the depicted element. E.g.: What cultural or religious significance does this item hold in its native context? - Function or Usage - Material and Craftsmanship"
        },
        {
            "title": "Questions that ask about the traditional or historical function or usage of the depicted",
            "content": "element. E.g.: What was this object traditionally used for?"
        },
        {
            "title": "Questions that focus on the materials used and the craftsmanship involved in creating the",
            "content": "depicted element. E.g.: What material is used to construct this artifact?"
        },
        {
            "title": "Questions that ask about the geographical location where the cultural event or facet takes",
            "content": "place. E.g.: In which place does this dance take place? Questions that delve into the symbolic meanings associated with the depicted element. E.g.: What does the color red symbolize in this cultural context? Questions that relate to historical events or contexts depicted in the image. E.g.: What historical event is depicted in this image? Questions that ask for specific details about the formation, arrangement, or other aspects of the depicted element. E.g.: What formation are the dancers in? Questions that do not fall into the above categories but are relevant to the ICH item. # Task Strategy Before generating question-answer pair, first think step-by-step and analyse the image: 1. What is visible in the image? Generate highly detailed description of the key elements, objects, or people in the image. Take into account the textual description provided to (cid:44) identify details. (cid:44) 2. How does the visible content relate to the intangible cultural heritage item? Identify the connection between the contents of the image and the intangible cultural heritage item. (cid:44) 34 Then, think step-by-step about potential questions: intangible cultural heritage item? 1. What can be asked about the image that is directly related to the visible content and the (cid:44) 2. Can concise and clear answer to the questions be inferred from the image and the provided (cid:44) information? Finally, think step-by-step before generating the final question-answer pairs: 1. Does the question-answer pair strictly adhere to the guidelines provided above? Percisly check every part of the guidelines and drop the question-answer pair if it does not meet (cid:44) the criteria. (cid:44) 2. What aspect of the intangible cultural heritage item is targeted with the question? 3. What category does the question fall into? # Output Format For each question-answer pair, provide the following information in the following format: ```xml <vqa-task> <image-analysis> <description> <!-- PUT YOUR DETAILED DESCRIPTION OF THE IMAGE HERE --> </description> <cultural-relatetness> <!-- PUT YOUR ANALYSIS OF HOW THE CONTENTS OF THE IMAGE RELATE TO THE INTANGIBLE (cid:44) CULTURAL HERITAGE ITEM HERE --> </cultural-relatetness> </image-analysis> <potential-questions> <qa-candidate> <question> <!-- PUT YOUR QUESTION HERE --> </question> <answer> <!-- PUT YOUR ANSWER HERE --> </answer> <guideline-adherence> <question-requirments> <clear-and-concise> <!-- YES OR NO --> </clear-and-concise> <directly-related-to-ich> <!-- YES OR NO --> </directly-related-to-ich> <directly-related-to-visual-content> <!-- YES OR NO --> </directly-related-to-visual-content> <does-not-contain-answer> <!-- YES OR NO --> </does-not-contain-answer> <does-not-contain-subjective-words> <!-- YES OR NO --> </does-not-contain-subjective-words> <requires-both-image-and-cultural-knowledge> <!-- YES OR NO --> </requires-both-image-and-cultural-knowledge> <includes-specific-cultural-terms> <!-- YES OR NO --> </includes-specific-cultural-terms> </question-requirments> <answer-requirments> <single-word-or-multiword-expression> <!-- YES OR NO --> </single-word-or-multiword-expression> <clear-objective-and-correct> <!-- YES OR NO --> 35 </clear-objective-and-correct> <directly-related-to-visual-content> <!-- YES OR NO --> </directly-related-to-visual-content> <no-general-or-abstract-words> <!-- YES OR NO --> </no-general-or-abstract-words> <verifiable-by-text-and-image> <!-- YES OR NO --> </verifiable-by-text-and-image> <includes-specific-cultural-terms> <!-- YES OR NO --> </includes-specific-cultural-terms> </answer-requirments> </guideline-adherence> </qa-candidate> ... </potential-questions> <final-qa-pairs> <!-- PUT ALL QA PAIRS THAT MEET ALL MANDATORY REQUIREMENTS HERE --> <qa-pair> <meets-requirements> <!-- DOES YOUR QUESTION-ANSWER PAIR MEET ALL MANDATORY REQUIREMENTS? YES OR NO --> (cid:44) </meets-requirements> <final-result-json> <!-- PUT YOUR FINAL RESULT AS JSON HERE --> { \"question\": <insert question here>, \"answer\": <insert answer here>, \"target_aspect\": <insert target aspect here> \"question_category\": <insert question category here> } </final-result-json> </qa-pair> ... </final-qa-pairs> </vqa-task> ``` B.4.2 User Prompt Template # Intangible Cultural Heritage Item ### Image {IMAGE_PLACEHOLDER} ### Countries of Origin: {LIST_OF_COUNTRIES} ### Regions of Origin {LIST_OF_REGIONS} ### Title {TITLE} ### Description {DESCRIPTION} 36 labeling interface (see Figure 74) for all annotation projects. B.5 Annotation Project Details We first conducted several internal pilot studies to iteratively create straightforward annotation task, guidelines, and an intuitive interface for the final annotation project. To find annotators, we advertised the task in our faculty research network, emphasizing our goal of creating culturally diverse benchmark for assessing the cultural awareness of current AI models. Therefore, we targeted primarily individuals from non-Western cultural backgrounds. We found 18 volunteers who have spent most of their lives in 10 different countries from all six regions and thus cover diverse cultural backgrounds (see Table 8). To train the annotators, we provided detailed annotation guidelines, followed by an oral introduction to the task. For more details, refer to the (anonymized) original annotation guidelines we shared here. For the second annotation round, we hired 5 of the previous volunteering annotators (0, 1, 8, 15, 17) who assessed the kept samples from the first round to obtain two annotations (from distinct annotators) per sample. We paid the second-round annotators salary of roughly 12.5C per hour."
        },
        {
            "title": "PRONOUNS EDUCATION COUNTRY",
            "content": "REGION ROUND(S) 0 1 2 3 5 6 7 8 9 10 11 12 13 14 15 16 17 23 23 28 35 29 29 42 23 33 29 23 33 22 27 29 22 26 she/her she/her she/her he/him he/him he/him he/him he/him she/her she/her she/her he/him she/her he/him she/her she/her he/him"
        },
        {
            "title": "AP\nAP\nE\nW\nLAC\nW\nSA\nA\nAP\nAP\nAP\nW\nAP\nAP\nW\nAP\nW",
            "content": "1, 2 1, 2 1 1 1 1 1 1, 2 1 1 1 1 1 1 1, 2 1 1, 2, 3 Table 8: Demographics of the annotators who participated in our VQA annotation project. For the country, we asked the question, Where did you spend most of your life?. The Round(s) column indicates which annotation rounds the annotator participated in. B.5.1 CIVQA Annotation Interface For the annotation project, we used selfhosted Label Studio14 instance with custom 14https://labelstud.io/ Figure 74: Three screenshots showing examples of the Label Studio interface used in our CIVQA annotation tasks. 38 B.5.2 First Annotation Round Statistics"
        },
        {
            "title": "Count",
            "content": "United Arab Emirates China Oman Saudi Arabia France Croatia Algeria Morocco Türkiye Peru Spain Azerbaijan Colombia Islamic Republic of Iran Mali Mexico Republic of Korea Egypt Tunisia Iraq Japan Brazil Italy Belgium Plurinational State of Bolivia Mauritania Bolivarian Republic of Venezuela Nigeria India Malawi Palestine Greece Uzbekistan Kuwait Kyrgyzstan Cuba Mauritius Mongolia Czechia Jordan Zambia Côte dIvoire Syrian Arab Republic Kazakhstan Portugal Switzerland Uganda Ethiopia Botswana Viet Nam Argentina Armenia Yemen Turkmenistan Sudan Bahrain Indonesia Ecuador Mozambique Tajikistan Austria Hungary Slovakia Lebanon Cyprus Slovenia Paraguay Germany Romania Guatemala Kenya Poland 101 98 91 87 86 84 82 81 78 75 74 69 68 66 65 64 62 62 56 54 52 50 50 50 49 49 47 46 45 43 40 38 37 37 36 35 34 34 34 32 31 31 31 30 29 29 29 29 28 28 28 28 28 26 26 26 26 25 25 25 24 24 23 23 22 22 21 21 21 20 20 20 Nicaragua Chile Serbia Cambodia Bangladesh Bulgaria Qatar Ireland Panama Ukraine Malaysia Namibia Philippines Bosnia and Herzegovina Niger Estonia Netherlands Zimbabwe Senegal Madagascar Belarus Luxembourg Togo Burundi Dominican Republic Congo Democratic Republic of the Congo Benin Finland Angola Afghanistan Seychelles Democratic Peoples Republic of Korea Norway Lao Peoples Democratic Republic Burkina Faso Sweden Bahamas Georgia Albania Republic of Moldova Cabo Verde North Macedonia Jamaica Honduras Latvia Denmark Pakistan Belize Uruguay Timor-Leste Montenegro Sri Lanka Thailand Guinea Malta Andorra Russian Federation Lithuania Tonga Costa Rica Cameroon Vanuatu Singapore Gambia Iceland Federated States of Micronesia Grenada Samoa Bhutan Djibouti Central African Republic 18 17 17 17 17 17 17 17 16 16 16 16 15 15 15 14 14 14 14 14 13 13 12 12 12 11 11 11 11 10 10 10 10 9 9 9 9 9 9 9 9 8 8 8 7 7 7 7 7 7 6 6 6 6 6 5 5 5 5 4 4 4 3 3 3 3 2 2 2 1 1 1 Table 9: The number of countries related to the QA pairs collected in the first annotation round for CIVQA."
        },
        {
            "title": "C VVQA Details",
            "content": "C.1 Examples In the following, we provide one random sample per region for the CVVQA task. Note that the lower part of the examples, where the related CEF is provided, is not part of the actual sample. Question: What event are the women in the video participating in? Answer: Moussem of Tan-Tan"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Moussem of Tan-Tan Countries: Morocco Regions: Arab States Description: The Moussem of Tan-Tan in southwest Morocco is an annual gathering of nomadic peoples of the Sahara that brings together more than thirty tribes from southern Morocco and other parts of northwest Africa. Originally this was an annual event around the month of May. Part of the agricultural and herding calendar of the nomads, these gatherings were an opportunity to group together, buy, sell and exchange foodstuffs and other products, organize camel and horse-breeding competitions, celebrate weddings and consult herbalists. The Moussem also included range of cultural expressions such as musical performances, popular chanting, games, poetry contests and other Hassanie oral traditions. These gatherings took the form of Moussem (a type of annual fair with economic, cultural and social functions) in 1963 when the first Moussem of Tan-Tan was organized to promote local traditions and provide place for exchange, meeting and celebration. The Moussem is said to have been initially associated with Mohamed Laghdaf, who resisted the Franco-Spanish occupation. He died in 1960, and his tomb lies near the town. However, between 1979 and 2004 it was not possible to hold the Moussem because of security problems in the region. Today, the nomadic populations are particularly concerned to protect their way of life. Economic and technical upheavals in the region have profoundly altered the lifestyle of the nomadic Bedouin communities, forcing many of them to settle. Moreover, urbanization and rural exodus have contributed to the loss of many aspects of the traditional culture of these populations, such as crafts and poetry. Because of these risks, Bedouin communities rely strongly on the renewed Moussem of Tan-Tan to assist them in ensuring the survival of their know-how and traditions. UNESCO ICH URL: https://ich.unesco.org/en/RL/moussem-of-tan-tan-00168... 40 AP Question: What traditional Japanese performance art is depicted by the performers in the video? Answer: Gagaku"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Gagaku Countries: Japan Regions: Asian and Pacific States Description: Gagaku, characterized by long, slow songs and dance-like movements, is the oldest of the Japanese traditional performing arts. It is performed at banquets and ceremonies in the Imperial Palace and in theatres throughout the country, and encompasses three distinct arts. The first, Kuniburi no Utamai, features ancient Japanese songs, partial accompaniment by harp and flute and simple choreography. The second consists of instrumental music (especially wind instruments) and ceremonial dance developed on the Asian continent and subsequently adapted by Japanese artists. The third, Utamono, is danced to vocal music whose texts include Japanese folk songs and Chinese poems. Influenced by the politics and culture of different periods over its long evolution, Gagaku continues to be transmitted to apprentices by masters in the Music Department of the Imperial Household Agency, many of whom are the descendants of families with deep roots in the art. It is not only an important cultural tool in confirming Japanese identity and crystallization of the history of Japanese society, but also demonstration of how multiple cultural traditions can be fused into unique heritage through constant recreation over time. UNESCO ICH URL: https://ich.unesco.org/en/RL/gagaku-00265... 41 Question: What instrument is the individual playing in the video? Answer: Tar"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Craftsmanship and performance art of the Tar, long-necked string musical instrument Countries: Azerbaijan Regions: Eastern European States Description: The Tar is long-necked plucked lute, traditionally crafted and performed in communities throughout Azerbaijan. Considered by many to be the countrys leading musical instrument, it features alone or with other instruments in numerous traditional musical styles. Tar makers transmit their skills to apprentices, often within the family. Craftsmanship begins with careful selection of materials for the instrument: mulberry wood for the body, nut wood for the neck, and pear wood for the tuning pegs. Using various tools, crafters create hollow body in the form of figure eight, which is then covered with the thin pericardium of an ox. The fretted neck is affixed, metal strings are added and the body is inlaid with mother-of-pearl. Performers hold the instrument horizontally against the chest and pluck the strings with plectrum, while using trills and variety of techniques and strokes to add colour. Tar performance has an essential place in weddings and different social gatherings, festive events and public concerts. Players transmit their skills to young people within their community by word of mouth and demonstration, and at educational musical institutions. Craftsmanship and performance of the tar and the skills related to this tradition play significant role in shaping the cultural identity of Azerbaijanis. UNESCO ICH URL: https://ich.unesco.org/en/RL/craftsmanship-and-performance-a..."
        },
        {
            "title": "LAC",
            "content": "Question: In which environment do the cultural practices depicted in the video typically occur? Answer: Llanos"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Colombian-Venezuelan llano work songs Countries: Colombia, Venezuela (Bolivarian Republic of) Regions: Latin-American and Caribbean States Description: Colombian-Venezuelan llano work songs are practice of vocal communication consisting of tunes sung individually, capella, on the themes of herding and milking. The practice emerged from the close relationship between human communities and cattle and horses and is in harmony with the environmental conditions and the dynamics of nature, forming part of the traditional animal husbandry system of the Llanos. Transmitted orally from childhood, the songs are repositories of the individual and collective stories of the llaneros. Llano work songs have been gradually affected by economic, political and social processes that, modifying the llanero cultural universe, have significantly weakened the practice. For example, ambitious government plans conceived from developmental perspective have led to profound changes in the use of the land and in ownership systems, and the modification of the social, cultural and natural sites of the songs have resulted in loss of interest in the values and techniques of llano work. Llanero work songs thus face various threats to their viability. Efforts to safeguard the element are nonetheless widespread, including pedagogical strategy involving more than twenty meetings for bearers and young people in the region, training projects for schoolteachers and proliferation of festivals. UNESCO ICH URL: https://ich.unesco.org/en/USL/colombian-venezuelan-llano-wor... 43 SA Question: What type of theatre is depicted in the video, known for using elaborate costumes and performances? Answer: Kwagh-Hir"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Kwagh-Hir theatrical performance Countries: Nigeria Regions: Subsaharian African States Description: Kwagh-Hir theatrical performance is composite art form encompassing spectacle that is both visually stimulating and culturally edifying. Kwagh-hir has its roots in the story-telling tradition of the Tiv people called kwagh-alom, practice where the family was treated to storytelling session by creative storytellers, usually in the early hours of the night after the days farming work. With time, creative storytellers began to dramatize these stories, culminating in the present stage and status of Kwagh-hir. The practice is social performance with the potential to entertain and teach moral lessons through the dramatization and performance of past and current social realities. As form of total theatre, Kwagh-hir incorporates puppetry, masquerading, poetry, music, dance and animated narratives in articulating the reality of the Tiv people. Peoples daily struggles, aspirations, successes and failures are all given expression through creative dramatization. Khwagh-hir theatre is owned by the community, with knowledge and skills being transmitted through apprenticeship. People who indicate an interest in the troupes activities are trained and mentored until they reach certain level of proficiency; they are then accepted into the troupe. Regular performances are held to ensure the art is kept alive and that the younger generation continues to identify with it. UNESCO ICH URL: https://ich.unesco.org/en/RL/kwagh-hir-theatrical-performanc... 44 Question: What traditional practice is depicted with the herders and sheep in the video? Answer: Transhumance"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Transhumance, the seasonal droving of livestock Countries: Albania, Andorra, Austria, Croatia, Spain, France, Greece, Italy, Luxembourg, Romania Regions: Western European and North American States, Eastern European States Description: Transhumance refers to the seasonal movement of people with their livestock between geographical or climatic regions. Each year, in spring and autumn, men and women herders organise the movement of thousands of animals along traditional pastoral paths. They move on foot or horseback, leading with their dogs and sometimes accompanied by their families. An ancestral practice, transhumance stems from deep knowledge about the environment and entails social practices and rituals related to the care, breeding and training of animals and the management of natural resources. An entire socio-economic system has been developed around transhumance, from gastronomy to local handicrafts and festivities marking the beginning and end of season. Families have been enacting and transmitting transhumance through observation and practice for many generations. Communities living along transhumance routes also play an important role in its transmission, such as by celebrating herd crossings and organising festivals. The practice is also transmitted through workshops organised by local communities, associations and networks of herders and farmers, as well as through universities and research institutes. Transhumance thus contributes to social inclusion, strengthening cultural identity and ties between families, communities and territories while counteracting the effects of rural depopulation. UNESCO ICH URL: https://ich.unesco.org/en/RL/transhumance-the-seasonal-drovi... C.2 Annotation Project Details The expert who annotated the samples was Annotator 17 from Table 8. As for the CIVQA task, we used self-hosted Label Studio instance with custom labeling interface. The UI is depicted in Figure 75."
        },
        {
            "title": "D COQA Details",
            "content": "D.1 Prompts In the following, the prompts for the COQAR and COQAC tasks are provided. For the variations involving images, the image placeholder gets replaced times, where is the number of images related to the target CEF. 45 Figure 75: Two screenshots showing examples of the Label Studio interface used in our VVQA annotation tasks. 46 Region Text-Only From which of the following regions does the cultural event or facet with the title `{TITLE}` originate? (cid:44) Choose from the following options and output only the corresponding letter. A. {REGION_OPTION_A} B. {REGION_OPTION_B} C. {REGION_OPTION_C} D. {REGION_OPTION_D} Your answer letter: Region Image-Only <IMAGE_PLACEHOLDER>"
        },
        {
            "title": "From which of the following countries does the cultural event or facet shown in the images",
            "content": "originate? (cid:44) Choose from the following options and output only the corresponding letter. A. {REGION_OPTION_A} B. {REGION_OPTION_B} C. {REGION_OPTION_C} D. {REGION_OPTION_D} Your answer letter: Region Text-Image <IMAGE_PLACEHOLDER> From which of the following regions does the cultural event or facet with the title `{TITLE}` shown in the images originate? (cid:44) Choose from the following options and output only the corresponding letter. A. {REGION_OPTION_A} B. {REGION_OPTION_B} C. {REGION_OPTION_C} D. {REGION_OPTION_D} Your answer letter: Figure 76: Prompts for the COQAR task. 47 Country Text-Only"
        },
        {
            "title": "From which of the following countries does the cultural event or facet with the title",
            "content": "`{TITLE}` originate? (cid:44) Choose from the following options and output only the corresponding letter. A. {COUNTRY_OPTION_A} B. {COUNTRY_OPTION_B} C. {COUNTRY_OPTION_C} D. {COUNTRY_OPTION_D} Your answer letter: Country Image-Only <IMAGE_PLACEHOLDER>"
        },
        {
            "title": "From which of the following countries does the cultural event or facet with the title",
            "content": "`{TITLE}` originate? (cid:44) Choose from the following options and output only the corresponding letter. A. {COUNTRY_OPTION_A} B. {COUNTRY_OPTION_B} C. {COUNTRY_OPTION_C} D. {COUNTRY_OPTION_D} Your answer letter: Country Text-Image <IMAGE_PLACEHOLDER>"
        },
        {
            "title": "From which of the following countries does the cultural event or facet with the title",
            "content": "`{TITLE}` shown in the images originate? (cid:44) Choose from the following options and output only the corresponding letter. A. {COUNTRY_OPTION_A} B. {COUNTRY_OPTION_B} C. {COUNTRY_OPTION_C} D. {COUNTRY_OPTION_D} Your answer letter: Figure 77: Prompts for the COQAC task. D.2 Examples In the following, we provide one random sample per region for the COQAC task in the image-only setting. For the other settings and the COQA tasks, the same pattern applies using the respective prompts from above. Note that the lower part of the examples, where the related CEF is provided, is not part of the actual sample. 49 Copyrigth: Huzaifa Ayad Bahaa El Din, Iraq, 2021 Copyrigth: Huzaifa Ayad Bahaa El Din, Iraq, Copyrigth: Huzaifa Ayad Bahaa El Din, Iraq, 2021 Copyrigth: Zahia Benabdallah, Algeria, 2021 Copyrigth: Azza Fahmi, Egypt, 2021 Copyrigth: Mustafa Kamil, Egypt, 2021 Copyrigth: National Heritage Preservation, Ministry of Culture, Youth and Sport and Relations with the Parliament, Egypt, 2022 Copyrigth: Direction du Patrimoine Culturel, Morocco, Copyrigth: Direction du Patrimoine Culturel, Morocco, 2021 Copyrigth: Ministry of Culture, Palestine, 2021 Question: In which of the following countries does the event shown in the images take place? Choose from the following options and output only the corresponding letter. A. Kuwait B. Jordan C. Egypt D. United Arab Emirates Your answer letter: Answer: C"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Arts, skills and practices associated with engraving on metals (gold, silver and copper) Countries: Algeria, Saudi Arabia, Egypt, Iraq, Morocco, Mauritania, Palestine, Sudan, Tunisia, Yemen Regions: Arab States Description: Engraving on metals such as gold, silver and copper is centuries-old practice that entails manually cutting words, symbols or patterns into the surfaces of decorative, utilitarian, religious or ceremonial objects. The craftsperson uses different tools to manually cut symbols, names, Quran verses, prayers and geometric patterns into the objects. Engravings can be concave (recessed) or convex (elevated), or the result of combination of different types of metals, such as gold and silver. Their social and symbolic meanings and functions vary according to the communities concerned. Engraved objects, such as jewelry or household objects, are often presented as traditional gifts for weddings or used in religious rituals and alternative medicine. For instance, certain types of metals are believed to have healing properties. Engraving on metals is transmitted within families, through observation and hands-on practice. It is also transmitted through workshops organized by training centres, organizations and universities, among others. Publications, cultural events and social media further contribute to the transmission of the related knowledge and skills. Practised by people of all ages and genders, metal engraving and the use of engraved objects are means of expressing the cultural, religious and geographical identity and the socioeconomic status of the communities concerned. UNESCO ICH URL: https://ich.unesco.org/en/RL/arts-skills-and-practices-assoc... 50 AP Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, Copyrigth: Public Foundation Min Kiyal, Kyrgyzstan, 2018 Question: In which of the following countries does the event shown in the images take place? Choose from the following options and output only the corresponding letter. A. Kyrgyzstan B. Timor-Leste C. Thailand D. Turkmenistan Your answer letter: Answer: A"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Ak-kalpak craftsmanship, traditional knowledge and skills in making and wearing Kyrgyz mens headwear Countries: Kyrgyzstan Regions: Asian and Pacific States Description: Ak-kalpak craftsmanship is traditional Kyrgyz handicraft. The Ak-kalpak is traditional male hat made with white felt, which bears deep sacral meanings. Ak-kalpak craftsmanship is cumulative, ever-evolving body of knowledge and skills passed down by craftswomen in the communities concerned comprising felting, cutting and sewing and pattern embroidery. Related knowledge and skills are transmitted via oral coaching, hands-on training and joint making in workshops. More than eighty kinds of Ak-kalpak can be distinguished, decorated with various patterns bearing sacred meaning and history. Environmentally friendly and comfortable, the Ak-kalpak resembles snow peak, with four sides representing the four elements: air, water, fire and earth. The four edging lines symbolize life, with the tassels on the top symbolizing ancestors posterity and memory, and the pattern symbolizing the family tree. Ak-kalpak unites different Kyrgyz tribes and communities and makes Kyrgyz people recognizable to other ethnic groups. It also fosters inclusivity when representatives of other ethnic groups wear it on holidays or days of mourning to express unity and sympathy. There are workshops all over the country where related knowledge and skills are passed down, and in 2013 project entitled From generation to generation was conducted on traditional Ak-kalpak-making techniques nationwide, resulting in an exhibition and published book. UNESCO ICH URL: https://ich.unesco.org/en/RL/ak-kalpak-craftsmanship-traditi... 51 Copyrigth: Lithuanian National Culture Centre, Archive, 2021 Copyrigth: Lithuanian National Culture Centre, Archive, 2021 Copyrigth: Vilnius Ethnic Culture Centre, Archive, Copyrigth: Vilnius Ethnic Culture Centre, Archive, 2021 Copyrigth: Vilnius Ethnic Culture Centre, Archive, 2021 Copyrigth: Vilnius Ethnic Culture Centre, Archive, 2021 Copyrigth: Vilnius Ethnic Culture Centre, Archive, 2021 Copyrigth: Lithuanian National Culture Centre, Archive, 2021 Copyrigth: Lithuanian National Culture Centre, Archive, Copyrigth: Marija Liugiene, Archive, 2003 Question: In which of the following countries does the event shown in the images take place? Choose from the following options and output only the corresponding letter. A. Lithuania B. Bosnia and Herzegovina C. Russia D. Poland Your answer letter: Answer: A"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Sodai straw garden making in Lithuania Countries: Lithuania Regions: Eastern European States Description: Sodai straw gardens are hanging ornaments made from the stalks of grains. This practice involves the cultivation of grain (typically rye), the treatment of straw and the creation of geometric structures of varying sizes. The structures are then decorated with details symbolizing fertility and prosperity. Sodai gardens are believed to reflect the pattern of the universe and are associated with well-being and spirituality. They are hung over the cradles of babies and over wedding or family table to wish happiness to newborns, fertility to newlyweds or harmony to the family. Lithuanian homes are also frequently decorated with sodai gardens for Easter and Christmas. Some sodai-making families have been practising the tradition for generations. Although most of the practitioners are women, workshops exist and are open to people of all ages and genders. The practice is passed on informally within families or during events such as festivals, exhibitions, conferences and summer camps. An integral part of traditional wooden home interiors, sodai gardens are viewed as spiritual gifts. They provide sense of shared cultural heritage and continuity to the practising communities while strengthening communal partnerships, intergenerational bonds and cultural diversity. UNESCO ICH URL: https://ich.unesco.org/en/RL/sodai-straw-garden-making-in-li..."
        },
        {
            "title": "LAC",
            "content": "Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Copyrigth: ca/Ministry Colombia, 2018 Gerson Fonseof of Culture Question: In which of the following countries does the event shown in the images take place? Choose from the following options and output only the corresponding letter. A. Dominican Republic B. Chile C. Colombia D. Grenada Your answer letter: Answer: C"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Safeguarding strategy of traditional crafts for peace building Countries: Colombia Regions: Latin-American and Caribbean States Description: The safeguarding strategy of traditional crafts for peace building addresses the weakening of traditional crafts through system of intergenerational transmission of knowledge between master and apprentice based on the non-formal learning by doing method. The safeguarding strategy aims to train different sectors of the population, create labour connections and foster cultural entrepreneurship. It establishes link between bearers of traditional crafts and skills who are recognized by their communities for their empirical knowledge of the peculiarities of their region and apprentices aged between fourteen and thirty-five who become builders of peace by learning skill or craft, seeking to transform their situation of vulnerability. The safeguarding strategy is therefore geared at: allowing for the qualification of traditional crafts, thereby improving employment opportunities; implementing Traditional Crafts Policy to guide and ensure continuity in the transmission and practice of these crafts; and enhancing the Workshop Schools Programme. Priority is accorded to young people who are exposed to the effects of armed conflict, lack of opportunities, school desertion and unemployment. Training is also combined with work, guaranteeing apprentices future employability. The strategy thus aims to foster the safeguarding of traditional crafts as tool for social inclusion, employment and cultural entrepreneurship. In turn, the community can recognize the cultural and societal value of safeguarding different traditional skills and crafts. UNESCO ICH URL: https://ich.unesco.org/en/BSP/safeguarding-strategy-of-tradi... 53 SA Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2018 Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2019 Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2018 Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2018 Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2017 Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2018 Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2020 Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, Copyrigth: Etienne Kokolo, Kinshasa, République du Congo, 2020 Question: In which of the following countries does the event shown in the images take place? Choose from the following options and output only the corresponding letter. A. Congo B. Togo C. Namibia D. Nigeria Your answer letter: Answer: A"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Congolese rumba Countries: Congo, Democratic Republic of the Congo Regions: Subsaharian African States Description: Congolese rumba is musical genre and dance common in urban areas of the Democratic Republic of the Congo and the Republic of the Congo. Generally danced by male-female couple, it is multicultural form of expression originating from an ancient dance called nkumba (meaning waist in Kikongo). The rumba is used for celebration and mourning, in private, public and religious spaces. It is performed by professional and amateur orchestras, choirs, dancers and individual musicians, and women have played predominant role in the development of religious and romantic styles. The tradition of Congolese rumba is passed down to younger generations through neighbourhood clubs, formal training schools and community organisations. For instance, rumba musicians maintain clubs and apprentice artists to carry on the practice and the manufacture of instruments. The rumba also plays an important economic role, as orchestras are increasingly developing cultural entrepreneurship aimed at reducing poverty. The rumba is considered an essential and representative part of the identity of Congolese people and its diaspora. It is perceived as means of conveying the social and cultural values of the region and of promoting intergenerational and social cohesion and solidarity. UNESCO ICH URL: https://ich.unesco.org/en/RL/congolese-rumba-01711... 54 Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, 2005 Copyrigth: Generalitat Valenciana, 2005 Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, Copyrigth: Generalitat Valenciana, 2005 Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, 2005 Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, 2005 Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, 2005 Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, 2005 Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, Copyrigth: Servicio de Patrimonio Histórico de la Región de Murcia, 2005 Question: In which of the following countries does the event shown in the images take place? Choose from the following options and output only the corresponding letter. A. Austria B. Spain C. Cyprus D. United Kingdom of Great Britain and Northern Ireland Your answer letter: Answer: B"
        },
        {
            "title": "Related Cultural Event or Facet",
            "content": "Title: Irrigators tribunals of the Spanish Mediterranean coast: the Council of Wise Men of the plain of Murcia and the Water Tribunal of the plain of Valencia Countries: Spain Regions: Western European and North American States Description: The irrigators tribunals of the Spanish Mediterranean coast are traditional law courts for water management that date back to the al-Andalus period (ninth to thirteenth centuries). The two main tribunals the Council of Wise Men of the Plain of Murcia and the Water Tribunal of the Plain of Valencia are recognized under Spanish law. Inspiring authority and respect, these two courts, whose members are elected democratically, settle disputes orally in swift, transparent and impartial manner. The Council of Wise Men has seven geographically representative members, and has jurisdiction over landowners assembly of 23,313 members. The Water Tribunal comprises eight elected administrators representing total of 11,691 members from nine communities. In addition to their legal role the irrigators tribunals play key part in the communities of which they are visible symbol, as apparent from the rites performed when judgments are handed down and the fact that the tribunals often feature in local iconography. They provide cohesion among traditional communities and synergy between occupations (wardens, inspectors, pruners, etc.), contribute to the oral transmission of knowledge derived from centuries-old cultural exchanges, and have their own specialist vocabulary peppered with Arabic borrowings. In short, the courts are long-standing repositories of local and regional identity and are of special significance to local inhabitants. UNESCO ICH URL: https://ich.unesco.org/en/RL/irrigators-tribunals-of-the-spa..."
        },
        {
            "title": "E CKQA Details",
            "content": "E.1 Prompts In the following, the prompts for the CKQAN and CKQAD tasks are provided. For the variations involving images, the image placeholder gets replaced times, where is the number of images related to the target CEF. Examples without the respective prompts, i.e., only the related CEFs, are provided in A.2.1. Naming Image-Only Name the cultural event or facet depicted by the following images. Answer briefly and (cid:44) concisely. <IMAGE_PLACEHOLDER> Your answer: Figure 138: Prompt for the CKQAN task. Describing Text-Only Write brief essay about the cultural event or facet with the title `{TITLE}`. Your answer: Describing Image-Only Write brief essay about the cultural event or facet depicted by the following images. <IMAGE_PLACEHOLDER> Your answer: Describing Text-Image Write brief essay about the cultural event or facet depicted by the following images. It has (cid:44) the title `{TITLE}`. <IMAGE_PLACEHOLDER> Your answer: Figure 139: Prompts for the CKQAD task."
        },
        {
            "title": "F Experimental Setup",
            "content": "For inference, we load all models using the transformers library (v.4.48.0) in 16-bit with Flash Attention 2 (Dao et al., 2022; Dao, 2024) (v.2.7.3), PyTorch (v.2.4.0), and CUDA (v12.1). We used A40 (46GB) GPUs for models up to 26B parameters, A100 (80GB) GPUs for models up to 38B parameters, and two H100 (96GB) GPUs for 70B+ models in multi-GPU setup. To generate responses, we use greedy decoding, i.e., we use the following arguments for the generation method: generation_kwargs = { \"max_new_tokens\": 512, \"do_sample\": False, \"temperature\": None, \"top_p\": None, \"top_k\": None, }"
        },
        {
            "title": "More details",
            "content": "and exact hyperparameters are documented in the code base: https://github.com/floschne/gimmick."
        },
        {
            "title": "G Results and Analyses",
            "content": "G.1 CIVQA G.1.1 Results"
        },
        {
            "title": "Relaxed Accuracy",
            "content": "Model GPT-4o Gemini Pro GPT-4o Mini Gemini Flash InternVL2.5 78B Qwen2 VL 72B InternVL2.5 38B Claude 3.5 Sonnet InternVL2.5 26B Llama 3.2 11B Vision InternVL2.5 8B Qwen2 VL 7B Phi 3.5 Vision MiniCPM 2.6 InternVL2.5 4B Qwen2 VL 2B Centurio Qwen InternVL2.5 2B InternVL2.5 1B Centurio Aya Average X-Large Average Large Average Medium Average Small Average Open Average Proprietary Average West EU & North America Asia & Pacific Subsaharian Africa Arab East EU Latin-America & Caribbean Average C C N N C C N N C 31.58 27.02 23.86 22.81 25.61 22.46 23.86 19.65 20.00 16.49 19.30 17.19 14.39 12.98 14.04 13.33 11.23 6.67 7.02 3.16 24.04 21.93 13.39 11.09 15.18 24.98 17.63 34.39 30.53 25.26 25.96 23.86 22.81 23.16 17.19 19.65 18.95 17.89 17.19 12.63 14.39 16.49 12.28 9.12 7.37 7.37 7.37 23.33 21.40 14.15 11.23 15.37 26.67 18. 41.05 31.23 30.18 27.02 29.82 29.82 28.77 22.11 25.61 20.70 23.16 20.35 20.00 14.39 16.84 13.68 14.39 10.18 10.53 8.77 29.82 27.19 16.96 14.25 19.13 30.32 21.93 40.70 32.28 29.82 24.91 29.12 29.12 29.82 24.21 25.96 20.35 23.51 18.95 18.95 17.19 14.39 14.39 14.39 9.47 11.58 8.77 29.12 27.89 17.19 13.75 19.06 30.39 21.89 29.89 22.53 21.05 18.95 20.21 17.47 17.26 16.42 13.26 13.26 11.79 9.47 8.84 10.74 9.47 9.68 9.05 4.21 4.21 2.95 18.84 15.26 9.54 7.28 10.79 21.77 13. 31.37 26.11 21.89 20.21 19.79 19.16 17.89 12.84 14.95 12.84 12.00 9.47 10.74 10.32 14.53 9.47 8.42 4.63 3.58 5.68 19.47 16.42 9.79 8.59 11.56 22.48 14.29 36.63 31.16 26.74 26.11 26.32 21.47 22.32 18.11 18.95 15.79 16.42 12.00 13.89 13.68 13.47 11.79 10.32 6.95 4.84 9.05 23.89 20.63 12.88 10.19 14.48 27.75 17.80 37.68 29.68 26.53 25.89 27.58 23.37 23.16 22.95 18.74 16.84 16.84 11.37 13.47 14.74 9.05 10.95 9.68 5.89 4.63 9.68 25.47 20.95 13.19 8.80 14.40 28.55 17. 17.38 16.84 9.32 12.91 10.33 8.31 9.07 6.30 6.30 5.29 5.04 5.79 6.05 2.52 3.53 4.03 3.02 2.27 2.52 1.76 9.32 7.68 3.90 3.68 5.05 12.55 6.93 17.63 14.61 10.58 10.83 11.08 8.56 8.82 4.53 6.80 5.54 6.30 6.30 6.05 3.27 7.05 3.78 1.76 2.02 0.76 1.51 9.82 7.81 4.11 3.93 5.31 11.64 6.89 32.49 26.20 16.12 20.40 20.40 12.85 17.88 10.58 11.59 9.07 10.58 8.56 8.31 6.55 7.56 5.54 6.05 3.53 2.77 4.79 16.62 14.74 7.60 5.54 9.07 21.16 12. 31.74 24.18 15.37 18.89 20.40 13.10 16.62 11.59 12.34 8.31 9.57 8.31 8.82 6.05 4.03 4.28 6.05 5.29 2.77 3.53 16.75 14.48 6.97 5.04 8.63 20.35 11.56 25.70 19.85 17.30 15.27 17.81 13.99 14.25 13.99 12.98 7.89 9.41 8.91 6.62 6.36 7.89 6.11 6.87 2.80 3.56 1.27 15.90 13.61 6.79 5.39 8.45 18.42 10.94 30.53 22.39 19.85 17.56 19.85 16.28 17.30 11.20 14.76 7.89 9.67 9.92 8.14 6.36 9.16 5.09 5.34 3.56 3.82 3.56 18.07 16.03 7.12 5.95 9.38 20.31 12. 39.19 28.50 25.45 20.36 27.74 20.10 23.16 17.81 20.61 10.18 14.50 11.45 9.41 9.67 9.16 6.11 9.92 5.34 5.09 5.60 23.92 21.88 10.22 7.02 12.54 26.26 15.97 39.95 28.50 25.95 20.61 27.99 19.85 22.65 20.61 21.12 10.18 14.25 11.45 9.92 9.67 6.87 6.11 8.91 5.60 4.07 6.11 23.92 21.88 10.09 6.51 12.32 27.12 16.02 26.80 25.07 19.02 20.17 19.02 21.04 16.14 16.71 15.56 12.68 9.80 10.95 8.93 10.09 8.07 8.36 6.34 3.17 4.61 2.02 20.03 15.85 8.65 6.63 10.45 21.56 13. 32.56 25.94 19.02 19.31 17.58 20.46 17.29 14.12 14.41 13.54 9.80 12.10 8.65 9.80 11.53 8.93 5.48 3.75 3.46 3.46 19.02 15.85 9.03 7.26 10.68 22.19 13.56 42.94 31.12 28.53 24.78 24.50 28.53 24.78 21.90 21.04 17.29 15.27 15.56 14.70 13.26 10.66 12.97 11.24 7.49 6.63 7.20 26.51 22.91 13.30 10.49 15.41 29.86 19.02 41.79 32.56 28.24 24.50 23.63 29.39 23.92 21.61 21.04 19.02 15.56 14.41 14.70 14.70 8.07 12.10 11.24 6.92 7.49 7.20 26.51 22.48 13.69 9.86 15.29 29.74 18. 23.17 22.46 16.31 14.66 13.95 13.00 11.82 13.48 13.00 11.82 9.46 9.69 8.27 9.46 8.04 7.33 6.62 5.44 4.02 2.84 13.48 12.41 8.31 6.62 8.98 18.01 11.24 25.77 19.86 17.73 16.55 15.13 14.66 12.29 13.00 14.89 11.82 9.69 11.11 9.93 9.22 11.58 8.27 5.67 5.44 5.67 5.44 14.89 13.59 8.83 8.18 10.06 18.58 12.19 30.26 24.35 23.64 22.22 20.80 19.86 17.97 17.97 19.62 13.95 13.71 13.00 13.71 12.77 11.82 10.40 9.22 8.04 6.86 6.38 20.33 18.79 11.51 10.17 13.21 23.69 15. 32.39 27.19 22.93 20.57 21.51 19.62 17.49 22.93 19.39 14.66 14.89 13.24 12.77 13.24 7.33 9.69 9.46 6.15 6.15 7.09 20.57 18.44 12.10 8.42 12.84 25.20 15.93 25.44 21.50 17.38 16.85 16.75 15.32 14.55 14.02 13.03 10.61 10.34 9.63 8.55 8.11 7.97 7.97 6.81 4.03 4.03 2.24 16.03 13.79 7.96 6.51 9.33 19.04 11.76 28.17 22.84 18.54 18.00 16.97 16.26 15.41 11.64 14.15 11.06 10.39 10.26 9.18 8.15 11.42 7.88 5.69 4.39 4.03 4.39 16.61 14.78 8.32 7.38 9.97 19.84 12. 36.59 28.30 24.81 23.29 24.45 21.45 21.99 17.60 19.44 13.97 15.41 12.76 12.99 11.60 11.29 9.94 9.85 6.85 5.96 6.99 22.95 20.71 11.76 9.40 13.66 26.12 16.78 37.08 28.30 24.59 22.44 24.72 21.59 21.63 20.24 19.61 14.20 15.41 12.36 12.85 11.96 7.79 9.49 9.76 6.45 5.87 7.17 23.15 20.62 11.81 8.49 13.39 26.53 16.67 Table 10: Cultural Image Visual Question Answering (CIVQA) scores. The reported score is relaxed accuracy. The columns N, R, C, and stand for the hints None, Region, Country, and Both, respectively."
        },
        {
            "title": "Judge Score",
            "content": "Figure 140: An overview of aggregated CIVQA Judge Score results. 57 Model GPT-4o Gemini Pro Claude 3.5 Sonnet Gemini Flash GPT-4o Mini Qwen2 VL 72B InternVL2.5 78B InternVL2.5 26B InternVL2.5 38B Qwen2 VL 7B Llama 3.2 11B Vision MiniCPM 2.6 Qwen2 VL 2B Centurio Aya InternVL2.5 8B Phi 3.5 Vision Centurio Qwen InternVL2.5 4B InternVL2.5 1B InternVL2.5 2B Average X-Large Average Large Average Medium Average Small Average Open Average Proprietary Average West EU & North America Asia & Pacific Subsaharian Africa Arab East EU Latin-America & Caribbean Average C R N B C R N B C 55.86 55.44 50.65 50.49 48.98 40.28 39.88 37.00 37.55 33.36 35.16 30.61 28.86 29.84 30.12 24.84 27.32 25.18 19.67 18.19 40.08 37.28 31.07 23.35 30.52 52.28 35. 55.46 56.30 51.35 49.93 48.47 40.05 39.52 34.65 37.51 34.84 36.56 32.35 28.30 30.21 32.19 26.93 26.32 26.06 20.32 19.35 39.79 36.08 32.08 24.19 31.01 52.30 36.33 64.33 63.15 65.33 56.29 53.10 48.04 46.43 39.75 45.58 38.64 37.22 32.73 28.94 30.67 35.35 33.43 29.21 26.71 20.90 20.25 47.23 42.67 33.97 26.05 34.26 60.44 40.80 64.49 62.06 64.14 56.11 54.28 46.90 47.01 41.00 45.49 38.12 37.81 35.48 30.85 32.31 36.47 33.45 30.42 29.67 23.91 21.95 46.95 43.25 35.10 27.96 35.39 60.22 41. 56.91 54.23 50.11 48.19 44.83 38.65 39.93 32.64 35.45 28.19 27.06 27.73 25.18 26.64 23.62 23.46 25.84 20.67 14.46 14.75 39.29 34.05 26.51 19.70 26.95 50.85 32.93 56.42 54.15 51.07 47.42 44.24 39.25 38.01 32.97 36.26 28.97 27.59 25.88 24.06 25.51 23.93 25.36 26.54 22.04 13.92 15.99 38.63 34.61 26.40 20.27 27.08 50.66 32.98 63.09 59.84 63.70 53.20 49.96 43.02 47.78 39.10 42.65 31.23 31.14 31.13 26.32 28.70 29.75 29.18 26.88 26.29 14.95 16.42 45.40 40.88 29.80 22.63 30.97 57.96 37. 63.20 59.14 63.59 53.11 49.05 44.15 49.26 39.47 43.88 31.13 33.09 33.25 26.31 28.81 29.92 29.02 28.63 27.53 17.03 18.36 46.71 41.68 30.80 23.65 31.99 57.62 38.40 39.13 38.74 35.06 35.60 32.78 25.79 22.18 22.63 22.98 21.31 19.24 20.29 21.02 18.81 16.70 21.28 18.12 12.32 12.05 13.14 23.99 22.81 19.08 15.96 19.19 36.26 23.46 35.97 39.51 39.90 31.32 35.06 26.30 20.79 21.71 22.52 25.25 17.97 18.92 19.32 17.87 17.20 21.65 17.91 14.45 13.50 10.52 23.55 22.12 19.19 15.89 19.06 36.35 23. 48.90 47.63 57.56 39.58 35.49 31.52 30.15 29.40 29.11 25.09 24.38 25.31 23.06 21.23 20.54 23.63 20.14 14.99 16.60 12.88 30.83 29.25 22.78 18.23 23.20 45.83 28.86 47.93 46.74 56.52 38.54 35.98 30.57 30.42 27.22 28.35 26.26 26.42 24.58 21.94 20.97 21.81 25.92 22.69 17.91 15.86 14.96 30.49 27.79 23.79 19.32 23.73 45.14 29.08 51.89 49.83 48.99 44.04 42.24 32.77 33.72 30.89 28.71 28.72 25.09 24.52 20.92 19.75 23.61 21.06 23.46 18.42 16.48 15.55 33.25 29.80 24.19 18.48 24.24 47.40 30. 56.53 52.96 55.34 44.25 43.83 35.27 35.80 31.39 31.78 28.45 26.53 24.57 20.32 20.43 23.46 23.26 22.32 21.62 16.31 14.08 35.54 31.58 24.29 19.12 25.04 50.58 31.42 65.71 58.10 67.49 50.85 47.98 42.89 46.82 38.10 38.96 32.00 31.43 28.47 22.98 24.02 30.65 26.18 27.19 24.43 16.88 16.69 44.86 38.53 28.96 21.43 29.85 58.03 36.89 67.59 57.65 67.86 49.03 48.58 41.64 47.86 38.81 38.63 32.28 30.47 28.19 23.30 24.01 29.92 26.48 27.72 25.80 17.42 18.03 44.75 38.72 28.77 22.21 30.04 58.14 37. 54.26 51.67 50.42 46.66 46.57 38.95 34.57 34.34 32.08 29.19 28.34 28.13 25.10 25.42 24.94 24.70 20.84 20.22 16.10 14.77 36.76 33.21 26.14 20.18 26.51 49.92 32.36 55.62 52.23 51.80 47.34 43.40 39.44 32.63 32.38 31.69 31.13 27.88 25.07 26.01 24.93 24.67 24.88 20.56 22.07 14.90 13.73 36.03 32.04 25.71 20.32 26.13 50.08 32.12 67.56 62.48 70.12 57.24 55.06 50.55 41.89 41.14 41.98 35.53 33.96 34.31 32.90 28.79 32.73 31.32 26.53 26.43 18.27 17.43 46.22 41.56 31.98 25.27 32.92 62.49 40. 67.33 63.77 70.20 55.22 53.76 49.74 40.73 41.53 41.21 37.11 36.73 36.27 31.34 30.72 33.66 31.82 28.83 28.43 20.82 18.32 45.24 41.37 33.89 26.15 33.82 62.05 40.88 48.32 46.54 41.49 43.59 40.74 30.64 31.42 29.34 28.39 27.84 26.89 26.74 23.91 23.58 22.80 24.47 21.21 17.56 14.94 15.57 31.03 28.86 24.84 19.29 24.35 44.14 29.30 46.69 45.32 46.10 41.58 38.24 33.06 30.40 29.69 29.15 28.61 28.82 26.04 24.07 24.65 22.13 25.73 21.74 20.93 15.64 15.86 31.73 29.42 25.33 20.45 25.10 43.59 29. 53.05 51.95 57.85 47.74 44.21 39.66 39.09 37.05 36.46 31.45 32.14 29.16 26.73 25.66 26.78 29.67 23.19 23.45 16.75 18.04 39.37 36.75 28.06 22.93 29.02 50.96 34.50 54.09 52.03 59.53 46.88 44.19 40.27 38.84 37.78 35.18 32.87 32.88 30.37 25.85 26.68 27.99 30.56 23.82 24.29 17.59 18.77 39.56 36.48 29.10 23.41 29.58 51.34 35.02 51.06 49.41 46.12 44.76 42.69 34.51 33.62 31.14 30.86 28.10 26.96 26.34 24.16 24.01 23.63 23.30 22.80 19.06 15.62 15.33 34.06 31.00 25.31 19.49 25.30 46.81 30. 51.12 50.08 49.26 43.64 42.21 35.56 32.86 30.47 31.48 29.54 27.56 25.47 23.68 23.93 23.93 24.64 22.56 21.19 15.76 14.92 34.21 30.98 25.50 20.04 25.57 47.26 30.99 60.44 57.19 63.68 50.82 47.63 42.61 42.03 37.42 39.12 32.33 31.71 30.18 26.82 26.51 29.30 28.90 25.52 23.72 17.39 16.95 42.32 38.27 29.26 22.76 30.03 55.95 36.51 60.77 56.90 63.64 49.81 47.64 42.21 42.35 37.64 38.79 32.96 32.90 31.36 26.60 27.25 29.96 29.54 27.02 25.61 18.77 18.40 42.28 38.22 30.24 23.78 30.76 55.75 37. Table 11: Cultural Image Visual Question Answering (CIVQA) scores. The reported score is the average judge score. The columns N, R, C, and stand for the hints None, Region, Country, and Both, respectively. G.1.2 Ground-Truth Answer Perplexity The perplexity for every sample is computed as follows: (cid:32) PPL(y x) = exp"
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) t=0 (cid:33) log (yt yt1, x) (1) where = {s, v} are the textual (s) and visual (v) prompt (prefix) tokens and are the ground-truth answer tokens. Results Per Cultural Aspect We computed the average accuracy for questions targeting one of the ten most frequent cultural aspects (see B.2), grouped by model size and region. For better interpretation, Table 12 reports the counts of questions associated with each cultural aspect per region. As shown in Table 13, our results reveal consistent trend: models perform significantly better on tangible cultural aspects (e.g., food) than on intangible ones. For instance, across all regions, closed models achieve an average accuracy of 30% for food-related questions, compared to only 8% and 10% for questions concerning rituals and festivals, respectively. These findings highlight not only regional biases but also biases along the cultural dimension, the latter being particularly pronounced in non-Western contexts. aspect art craftsmanship dance festivals food instruments music rituals tools traditions"
        },
        {
            "title": "A\nAP\nE\nLAC\nSA\nW",
            "content": "45 57 53 31 14 33 32 44 36 22 16 27 20 31 18 31 40 10 6 14 19 66 16 30 33 12 10 6 22 13 20 25 19 13 64 37 32 26 51 41 23 32 53 18 47 73 18 30 22 20 12 7 17 76 68 49 78 70 49 Table 12: Number of questions targeting one of the top-10 cultural aspects per region in CIVQA. G.2 CVVQA G.2.1 Results 58 food instruments craftsmanship music tools traditions art dance festivals rituals XL 0.28 0.29 0.15 0.20 0.19 0.19 0.15 0.07 0.18 0. 0.23 0.27 0.17 0.32 0.29 0.18 0.17 0.07 0.20 0.08 AP 0.21 0.25 0.15 0.26 0.18 0.15 0.13 0.04 0.18 0.09 0.07 0.05 0.04 0.07 0.09 0.06 0.07 0.01 0.09 0. XL 0.10 0.07 0.07 0.09 0.11 0.07 0.07 0.00 0.08 0.03 0.28 0.20 0.18 0.10 0.18 0.11 0.18 0.02 0.02 0.06 0.35 0.15 0.24 0.09 0.17 0.09 0.13 0.00 0.06 0. 0.31 0.12 0.22 0.12 0.18 0.09 0.14 0.00 0.00 0.05 0.06 0.03 0.08 0.03 0.05 0.04 0.04 0.00 0.00 0.02 A XL 0.09 0.04 0.08 0.04 0.06 0.05 0.04 0.00 0.00 0.03 0.21 0.16 0.11 0.13 0.00 0.06 0.07 0.05 0.02 0.06 0.16 0.15 0.09 0.11 0.05 0.07 0.09 0.04 0.00 0.07 SA 0.07 0.16 0.08 0.13 0.04 0.06 0.06 0.02 0.00 0.04 0.03 0.03 0.04 0.03 0.00 0.04 0.01 0.01 0.00 0.02 XL 0.04 0.04 0.02 0.03 0.04 0.04 0.00 0.01 0.00 0.04 0.18 0.26 0.14 0.25 0.22 0.21 0.16 0.26 0.10 0.12 0.12 0.37 0.19 0.27 0.15 0.25 0.27 0.39 0.10 0.10 0.19 0.32 0.12 0.28 0.19 0.21 0.23 0.35 0.10 0.08 0.07 0.05 0.10 0.10 0.09 0.09 0.10 0.17 0.04 0.02 XL 0.09 0.11 0.08 0.13 0.11 0.09 0.13 0.11 0.06 0.02 0.18 0.32 0.26 0.10 0.14 0.16 0.13 0.22 0.13 0.13 0.36 0.31 0.28 0.10 0.17 0.16 0.20 0.23 0.11 0.16 0.31 0.26 0.27 0.05 0.17 0.15 0.12 0.17 0.05 0. 0.10 0.04 0.13 0.02 0.04 0.06 0.06 0.04 0.02 0."
        },
        {
            "title": "LAC",
            "content": "OVERALL XL S XL S 0.12 0.05 0.17 0.02 0.04 0.08 0.07 0.03 0.01 0.01 0.68 0.45 0.12 0.19 0.23 0.14 0.10 0.14 0.13 0.04 0.54 0.44 0.12 0.22 0.17 0.16 0.11 0.11 0.11 0.06 0.71 0.31 0.12 0.22 0.30 0.13 0.11 0.08 0.11 0.03 0.31 0.15 0.06 0.08 0.05 0.06 0.06 0.04 0.04 0.01 0.39 0.20 0.07 0.12 0.05 0.08 0.09 0.03 0.04 0. 0.30 0.28 0.16 0.16 0.16 0.14 0.13 0.13 0.10 0.08 0.29 0.28 0.18 0.19 0.17 0.15 0.16 0.14 0.10 0.09 0.30 0.24 0.16 0.18 0.18 0.13 0.13 0.11 0.07 0.06 0.11 0.06 0.08 0.06 0.05 0.06 0.06 0.05 0.03 0.02 0.14 0.08 0.08 0.07 0.07 0.07 0.07 0.03 0.03 0.02 Average 0.18 0.20 0.16 0.06 0.07 0. 0.13 0.12 0.03 0.04 0.09 0. 0.07 0.02 0.03 0.19 0.22 0. 0.08 0.09 0.18 0.21 0.16 0. 0.06 0.22 0.20 0.21 0.09 0. 0.16 0.17 0.16 0.06 0.07 Table 13: The averaged accuracy per region per model size group (A, XL, L, M, S) per target cultural aspect for samples in the CIVQA task."
        },
        {
            "title": "Model",
            "content": "GPT-4o GPT-4o Mini Gemini Pro Gemini Flash Claude 3.5 Sonnet Qwen2 VL 72B InternVL2.5 78B InternVL2.5 38B Qwen2 VL 2B Qwen2 VL 7B InternVL2.5 26B MiniCPM 2.6 Phi 3.5 Vision Centurio Qwen InternVL2.5 8B InternVL2.5 4B Centurio Aya InternVL2.5 1B Average X-Large Average Large Average Medium Average Small Average Open Average Proprietary Average West EU & North America Asia & Pacific"
        },
        {
            "title": "East EU",
            "content": "Latin-America & Caribbean"
        },
        {
            "title": "Average",
            "content": "N N C C N N C C N 38.97 38.06 33.80 29.55 21.86 25.35 23.94 22.07 19.72 18.78 20.66 16.90 16.43 20.19 14.55 14.55 11.74 8.45 24.65 21.36 16.43 14.79 17.95 32.45 21. 39.91 31.58 37.09 29.96 19.84 27.23 29.11 28.64 18.78 18.78 25.35 19.25 14.55 17.84 19.25 15.96 12.21 9.86 28.17 27.00 17.46 14.79 19.75 31.67 23.07 41.31 34.01 40.85 30.36 25.91 33.33 31.92 32.86 21.13 22.07 28.64 18.31 16.90 23.00 20.66 18.78 15.49 11.27 32.63 30.75 19.91 17.02 22.64 34.49 25.93 44.13 38.87 39.91 34.82 24.29 34.27 31.46 32.86 23.00 21.60 29.11 19.72 16.90 21.13 23.00 18.31 12.21 12.21 32.86 30.99 19.53 17.61 22.75 36.40 26. 34.56 29.45 30.41 22.67 22.46 18.43 19.12 18.66 13.13 14.06 16.36 14.75 13.82 15.67 11.98 12.67 9.68 5.76 18.78 17.51 13.23 11.35 14.16 27.91 17.98 36.41 25.64 31.34 24.36 19.92 19.12 24.19 24.19 14.75 14.06 19.35 16.82 14.06 15.44 15.44 14.29 9.91 8.29 21.66 21.77 14.33 12.85 16.15 27.53 19.31 35.71 25.64 34.10 26.69 25.21 23.73 28.11 27.19 16.59 17.05 23.27 17.28 17.51 18.43 18.43 17.74 12.21 9.22 25.92 25.23 16.68 15.26 18.98 29.47 21. 39.17 29.66 34.79 26.69 25.85 23.73 29.49 26.73 15.67 16.59 24.88 18.43 17.28 17.74 18.43 16.59 11.06 7.60 26.61 25.81 16.45 14.29 18.79 31.23 22.24 23.67 20.32 20.07 12.06 9.21 9.00 7.33 6.33 6.67 5.00 3.33 5.67 8.67 6.00 3.33 5.67 4.67 1.67 8.17 4.83 4.93 5.67 5.64 17.06 8.81 26.33 13.33 22.33 12.06 6.03 10.00 12.33 13.00 4.67 6.00 7.33 10.00 8.33 6.33 6.33 6.33 4.67 2.33 11.17 10.17 6.67 5.42 7.51 16.02 9. 36.67 15.56 28.67 15.87 12.38 16.33 18.67 21.67 7.00 7.67 9.33 11.33 10.67 7.33 9.33 9.00 6.67 4.00 17.50 15.50 8.47 7.67 10.69 21.83 13.79 36.00 20.63 28.67 19.05 11.11 17.00 19.67 21.33 6.67 7.33 10.33 11.00 10.33 7.33 9.00 9.00 5.33 2.67 18.33 15.83 8.00 7.17 10.54 23.09 14.03 29.18 28.61 26.56 20.18 16.87 17.05 13.44 13.77 13.11 13.11 11.80 12.13 9.84 9.51 9.84 8.52 6.89 5.90 15.25 12.79 10.30 9.34 11.15 24.28 14. 32.46 24.40 28.85 20.78 14.16 18.36 22.30 22.95 11.15 15.08 15.41 13.44 10.16 10.82 13.77 9.84 7.54 7.87 20.33 19.18 12.13 9.75 13.75 24.13 16.63 36.72 25.60 32.13 21.39 16.87 22.62 25.90 24.59 13.44 17.05 19.67 14.75 11.15 10.16 15.08 13.11 7.54 8.85 24.26 22.13 12.92 11.64 15.69 26.54 18.70 36.39 29.52 32.13 23.49 18.37 21.64 25.90 27.54 12.46 17.70 20.00 14.75 10.82 10.49 16.07 12.46 7.54 8.85 23.77 23.77 13.31 11.15 15.86 27.98 19. 37.59 35.37 32.27 26.52 23.17 25.53 19.50 19.86 16.67 15.25 17.73 19.15 15.60 14.89 15.25 11.35 9.93 6.74 22.52 18.79 14.89 12.59 15.96 30.98 20.13 40.43 29.27 33.33 27.74 20.12 25.53 24.82 26.24 16.67 17.73 21.63 20.21 15.25 15.96 17.73 15.25 9.57 7.45 25.18 23.94 16.24 13.65 18.00 30.18 21.39 47.16 30.18 36.52 32.01 26.52 32.27 30.14 30.85 17.38 18.79 24.82 22.34 19.15 22.34 23.05 19.50 12.77 10.99 31.21 27.84 19.86 16.76 21.88 34.48 25. 45.74 38.72 36.88 31.71 24.70 31.91 29.43 30.50 17.38 19.50 24.11 21.99 19.86 20.92 23.05 18.09 10.64 10.64 30.67 27.30 19.22 16.49 21.39 35.55 25.32 31.98 25.13 28.78 23.30 19.11 16.57 15.41 13.37 15.70 15.70 13.66 15.41 13.95 11.63 10.17 11.34 7.56 7.27 15.99 13.52 12.09 12.06 12.90 25.66 16.45 32.56 21.20 30.52 24.61 15.45 20.93 21.22 20.93 15.12 18.60 18.31 17.44 15.12 11.92 12.21 14.24 9.01 8.72 21.08 19.62 13.84 13.30 15.68 24.87 18. 38.95 23.04 33.43 26.18 21.47 23.55 24.42 26.16 16.28 19.48 21.51 16.28 18.60 15.70 16.28 15.70 10.17 9.01 23.98 23.84 15.58 14.90 17.93 28.61 20.90 39.24 25.65 32.85 27.49 22.25 24.42 26.45 24.71 16.28 20.06 22.97 19.19 18.90 14.53 16.57 15.12 9.59 9.01 25.44 23.84 15.99 14.83 18.29 29.50 21.40 32.67 28.69 28.32 21.64 18.74 18.13 15.75 14.98 13.88 13.54 13.32 13.16 12.82 12.38 10.61 10.45 8.46 5.86 16.94 14.15 11.63 10.75 12.57 26.01 16. 34.49 23.89 29.91 22.59 15.89 19.62 21.56 21.78 13.27 14.76 17.30 15.37 12.88 12.55 13.82 12.38 8.96 7.46 20.59 19.54 13.09 11.50 14.75 25.35 17.69 39.19 24.84 33.67 24.89 21.44 24.27 25.98 26.31 15.26 16.86 20.78 16.14 16.09 15.70 16.92 15.70 10.95 8.90 25.12 23.55 15.31 13.99 17.68 28.80 20.77 39.97 29.69 33.78 26.29 21.24 24.65 26.70 26.37 14.98 16.92 21.61 17.03 15.87 15.15 17.36 14.70 9.62 8.35 25.68 23.99 15.21 13.47 17.64 30.19 21. Table 14: GIMMICK Video Visual Question Answering (VVQA) results. The reported score is relaxed accuracy. The columns N, R, C, and stand for the hints None, Region, Country, and Both, respectively. G.3 COQA Details G.3.1 Results 59 WEST EU & NORTH AM."
        },
        {
            "title": "EAST EU",
            "content": "ASIA & PACIFIC LAT. AM. & CARIB."
        },
        {
            "title": "ARAB",
            "content": "SUBS. AFRICA"
        },
        {
            "title": "AVERAGE",
            "content": "GPT-4o Claude 3.5 Sonnet InternVL2.5 78B Qwen2.5 72B GPT-4o Mini InternVL2.5 38B Qwen2 VL 72B Gemini Flash Qwen2.5 32B Qwen2 VL 7B MiniCPM 2.6 InternVL2.5 26B Phi 3.5 Mini InternLM2.5 7B Centurio Qwen InternLM2.5 20B Qwen2.5 7B Aya Expanse 8B InternVL2.5 8B Centurio Aya Phi 3.5 Vision InternVL2.5 4B Qwen2 VL 2B Qwen2.5 3B Qwen2.5 1.5B Qwen2.5 0.5B InternLM2.5 1.8B InternVL2.5 2B InternVL2.5 1B Gemini Pro Average X-Large LVLMs Average Large LVLMs Average Medium LVLMs Average Small LVLMs Average LVLMs Average X-Large LLMs Average Large LLMs Average Medium LLMs Average Small LLMs Average LLMs Average X-Large Average Large Average Medium Average Small Average Open Average Proprietary Average 82.50 72.50 77.50 76.25 81.25 79.38 82.50 71.25 72.50 77.50 75.63 68.12 80.62 65.62 66.88 77.50 70.62 63.75 76.25 78.44 79.38 73.62 68.88 73.44 78.44 79.38 73.62 68.88 73.44 78.00 74. 83.75 83.75 80.00 81.25 82.50 81.25 80.62 78.75 76.88 74.38 72.50 74.38 74.38 74.38 74.38 74.38 71.88 68.12 72.50 68.12 72.50 66.88 72.50 68.75 61.88 68.12 56.25 51.88 58.75 59.38 80.31 77.81 72.38 64.50 71.47 81.25 75.62 71.46 65.88 70.57 80.62 76.72 72.03 65.19 71.08 77.62 72.17 I+T 85.00 81.25 86.88 86.25 84.38 81.25 78.13 76.25 75.00 80.62 80.00 75.63 78.75 75.63 76.25 78.75 72.50 66.88 78.13 84.06 82.50 77.12 74.00 77.77 84.06 82.50 77.12 74.00 77.77 81.75 78.82 T I+T I+T T I+T I+T T I+T I+T Avg. 85.89 76.69 83.44 84.66 85.89 88.34 85.28 82.82 81.60 87.12 79.75 83.44 82.21 69.94 84.66 84.05 76.69 62.58 68.10 85.89 86.50 81.96 75.58 80.89 85.89 86.50 81.96 75.58 80.89 80.12 80.69 90.18 85.89 82.21 84.05 82.21 84.66 84.66 80.37 79.75 80.37 79.14 75.46 72.39 76.69 76.69 75.46 72.39 77.30 76.07 75.46 70.55 75.46 64.42 73.01 65.03 72.39 65.03 58.28 60.74 55.21 83.44 80.06 77.55 65.89 74.58 84.05 77.61 75.46 69.57 73.95 83.64 78.83 76.76 67.73 74.31 78.77 75.05 88.34 82.21 88.96 84.66 85.28 88.34 84.66 84.05 80.37 87.12 82.82 83.44 80.37 76.69 84.05 84.05 71.78 74.23 82.21 88.65 86.20 82.21 78.16 82.25 88.65 86.20 82.21 78.16 82.25 84.42 82. 94.37 87.88 94.37 94.37 90.04 90.48 87.01 92.64 88.74 91.77 86.58 87.88 90.91 89.18 87.01 91.77 77.92 64.50 82.25 92.42 90.91 89.35 82.08 87.41 92.42 90.91 89.35 82.08 87.41 89.18 87.88 96.54 95.67 94.81 96.10 95.67 95.24 94.81 91.34 94.37 93.51 90.48 91.77 88.31 90.48 92.64 89.18 93.51 91.77 89.61 85.71 91.34 86.15 82.68 83.12 82.25 67.53 65.37 72.29 61.90 56.28 94.81 93.51 90.39 78.87 87.35 96.10 91.77 91.92 77.32 85.64 95.24 92.64 90.96 78.10 86.60 87.10 86.68 97.40 95.67 96.97 96.54 92.64 96.97 94.81 93.51 93.07 96.54 92.21 94.37 92.21 95.24 93.07 92.21 82.68 80.09 89.61 96.97 94.59 93.07 88.66 92.27 96.97 94.59 93.07 88.66 92.27 94.81 92. 93.68 83.16 88.42 87.37 86.32 86.32 85.11 85.26 80.00 88.42 83.16 84.21 84.21 80.00 83.16 88.42 83.16 77.89 79.79 87.37 87.37 83.37 82.53 84.21 87.37 87.37 83.37 82.53 84.21 85.82 84.63 92.63 89.47 92.63 89.47 90.53 86.32 88.42 87.37 87.37 88.42 87.37 84.21 83.16 80.00 86.32 86.32 85.26 81.05 83.16 82.11 81.05 78.95 81.05 73.68 78.95 65.26 60.00 62.11 57.89 61.05 90.53 85.26 85.47 72.21 81.43 89.47 86.84 82.11 72.21 79.14 90.18 86.05 84.21 72.21 80.42 84.21 81.05 92.63 87.37 92.63 90.53 92.63 92.63 90.53 92.63 90.53 93.68 89.47 92.63 85.26 86.32 87.37 86.32 83.16 87.37 85.11 92.63 93.16 90.11 86.11 89.47 92.63 93.16 90.11 86.11 89.47 89.23 89. 88.00 84.00 88.00 85.33 89.33 86.67 89.19 80.00 80.00 84.00 78.67 84.00 81.33 72.00 80.00 84.00 73.33 62.67 79.73 87.33 86.67 80.80 74.40 80.29 87.33 86.67 80.80 74.40 80.29 85.25 81.59 88.00 90.67 90.67 86.67 86.67 90.67 88.00 86.67 84.00 82.67 77.33 85.33 81.33 78.67 77.33 76.00 77.33 80.00 73.33 82.67 80.00 82.67 70.67 74.67 72.00 70.67 66.67 66.67 68.00 61.33 89.33 88.00 78.67 73.60 79.71 86.67 80.00 78.67 73.07 77.09 88.44 84.00 78.67 73.33 78.56 82.67 79.24 92.00 90.67 92.00 86.67 92.00 89.33 90.67 84.00 86.67 88.00 88.00 89.33 85.33 86.67 86.67 89.33 82.67 82.67 84.00 90.67 90.00 86.67 85.60 87.33 90.67 90.00 86.67 85.60 87.33 88.80 87. 91.30 82.61 92.75 91.30 89.86 91.30 89.86 86.96 88.41 91.30 86.96 88.41 85.51 85.51 86.96 88.41 84.06 75.36 72.46 92.03 90.58 87.25 84.06 87.27 92.03 90.58 87.25 84.06 87.27 85.51 86.80 91.30 89.86 91.30 89.86 89.86 86.96 85.51 91.30 89.86 85.51 85.51 79.71 86.96 85.51 76.81 82.61 81.16 81.16 81.16 81.16 79.71 84.06 79.71 75.36 78.26 55.07 66.67 60.87 59.42 65.22 88.41 83.33 82.03 72.75 79.81 89.86 86.23 82.61 72.46 79.31 88.89 84.78 82.25 72.61 79.59 85.51 80.58 94.20 88.41 92.75 92.75 91.30 91.30 91.30 84.06 86.96 86.96 89.86 92.75 91.30 88.41 89.86 91.30 89.86 82.61 95.65 92.03 89.13 88.99 88.41 89.23 92.03 89.13 88.99 88.41 89.23 92.46 90. 89.29 81.14 87.41 86.55 87.11 87.08 86.49 83.16 81.87 86.69 81.79 82.68 84.13 77.04 81.44 85.69 77.63 67.79 76.43 87.24 86.90 82.73 77.92 82.25 87.24 86.90 82.73 77.92 82.25 83.98 82.71 90.40 89.22 88.60 87.90 87.90 87.51 87.00 85.97 85.37 84.14 82.05 81.81 81.09 80.95 80.69 80.66 80.26 79.90 79.31 79.21 79.19 79.03 75.17 74.76 73.06 66.51 63.33 62.02 61.12 59.75 87.80 84.66 81.08 71.31 79.06 87.90 83.02 80.37 71.75 77.62 87.83 83.84 80.81 71.53 78.43 82.65 79.13 91.60 87.60 91.70 89.57 89.70 89.97 88.35 85.75 85.43 88.82 87.06 88.03 85.54 84.82 86.21 86.99 80.44 78.97 85.78 90.84 89.26 86.36 83.49 86.39 90.84 89.26 86.36 83.49 86.39 88.58 86. 90.43 85.98 89.24 87.90 88.01 88.11 88.02 86.94 85.37 84.35 83.12 85.77 81.09 80.95 83.18 80.66 80.26 79.90 83.34 82.96 80.35 82.23 82.62 74.76 73.06 66.51 63.33 73.36 69.29 73.99 88.63 86.94 83.39 77.57 82.57 87.90 83.02 80.37 71.75 77.62 88.39 84.98 82.26 74.66 80.39 85.07 81.17 Table 15: GIMMICK Cultural Origin Question Answering Regions (COQAR) results. The reported score is relaxed accuracy. The columns and stand for image-only and text-only inputs to the model. 60 WEST EU & NORTH AM."
        },
        {
            "title": "EAST EU",
            "content": "ASIA & PACIFIC LAT. AM. & CARIB."
        },
        {
            "title": "ARAB",
            "content": "SUBS. AFRICA"
        },
        {
            "title": "AVERAGE",
            "content": "Claude 3.5 Sonnet GPT-4o InternVL2.5 78B Qwen2.5 72B GPT-4o Mini Qwen2.5 32B InternVL2.5 38B Qwen2 VL 72B Gemini Flash InternVL2.5 26B Qwen2.5 7B Aya Expanse 8B InternLM2.5 20B MiniCPM 2.6 Qwen2 VL 7B Qwen2.5 3B InternLM2.5 7B Centurio Qwen Centurio Aya InternVL2.5 8B Phi 3.5 Mini InternVL2.5 4B Phi 3.5 Vision Qwen2.5 1.5B Qwen2 VL 2B Qwen2.5 0.5B InternVL2.5 1B InternLM2.5 1.8B InternVL2.5 2B Gemini Pro Average X-Large LVLMs Average Large LVLMs Average Medium LVLMs Average Small LVLMs Average LVLMs Average X-Large LLMs Average Large LLMs Average Medium LLMs Average Small LLMs Average LLMs Average X-Large Average Large Average Medium Average Small Average Open Average Proprietary Average 79.23 93.44 83.06 89.07 78.69 87.98 90.56 78.14 81.97 87.43 78.69 65.57 68.31 68.85 72.13 83.06 61.20 62.84 76.67 85.52 78.42 76.39 69.62 75.57 85.52 78.42 76.39 69.62 75.57 85.79 78. 96.72 95.08 94.54 93.44 93.99 91.26 91.80 87.43 89.01 87.98 86.34 87.43 86.89 84.70 83.61 81.42 83.61 82.51 83.61 82.51 80.87 77.05 79.78 78.69 74.32 65.03 66.12 63.39 65.57 43.17 90.98 89.89 83.39 72.57 81.54 93.44 89.07 85.79 73.88 81.67 91.80 89.48 84.29 73.22 81.60 83.59 81.93 I+T 95.63 96.17 97.81 95.63 92.35 95.08 97.27 92.90 90.16 90.71 89.07 85.79 88.52 89.62 86.89 87.43 73.77 74.32 92.70 96.45 92.62 88.85 82.40 88.17 96.45 92.62 88.85 82.40 88.17 95.48 90.10 T I+T I+T T I+T I+T T I+T I+T Avg. 82.35 94.71 80.59 90.00 77.06 94.12 90.59 78.24 81.18 82.35 78.82 72.35 70.59 72.35 68.82 84.71 59.41 61.76 75.88 87.35 77.65 77.06 69.41 75.88 87.35 77.65 77.06 69.41 75.88 86.71 78.73 97.65 98.24 95.88 96.47 95.29 93.53 91.18 90.59 88.82 88.24 88.24 88.24 87.06 86.47 85.29 85.88 85.88 82.94 81.76 84.71 82.94 82.94 82.94 81.18 77.06 68.82 65.88 66.47 64.71 39.41 93.24 89.71 84.24 74.71 82.90 96.47 90.29 87.45 77.06 84.06 94.31 90.00 85.44 75.88 83.41 83.88 83.49 96.47 98.24 97.65 97.65 92.94 96.47 97.06 94.71 92.94 92.94 89.41 85.88 90.00 89.41 92.35 87.65 73.53 72.35 92.94 97.06 93.82 90.24 83.06 89.16 97.06 93.82 90.24 83.06 89.16 96.47 91. 76.62 93.51 83.12 90.48 77.49 90.04 91.77 76.19 78.79 87.01 78.79 75.76 75.32 71.43 69.70 83.55 62.34 61.04 78.79 86.58 76.84 79.13 69.61 76.47 86.58 76.84 79.13 69.61 76.47 86.23 79.04 97.84 97.40 93.51 94.81 93.51 91.77 93.07 90.04 90.48 90.48 85.28 90.04 90.91 87.45 84.85 84.85 85.71 84.42 85.71 86.58 83.98 86.15 81.82 82.68 80.95 72.29 75.76 71.00 68.40 34.20 91.77 91.77 85.80 78.61 84.94 94.81 91.34 87.01 78.96 84.85 92.78 91.56 86.26 78.79 84.90 82.68 84.53 95.67 98.27 96.54 96.97 93.94 97.84 98.70 93.94 92.21 94.37 92.64 88.31 91.34 90.48 89.61 90.48 77.06 80.95 92.64 97.19 93.94 91.77 85.71 90.69 97.19 93.94 91.77 85.71 90.69 96.45 92. 70.21 97.87 81.91 90.43 79.79 91.49 90.43 80.85 86.17 91.49 76.60 74.47 75.53 76.60 74.47 92.55 67.02 67.02 78.72 86.70 80.32 80.85 75.53 79.71 86.70 80.32 80.85 75.53 79.71 85.53 81.24 98.94 98.94 98.94 98.94 95.74 94.68 95.74 97.87 93.62 94.68 95.74 93.62 90.43 87.23 88.30 92.55 90.43 85.11 87.23 87.23 84.04 87.23 91.49 82.98 81.91 75.53 74.47 67.02 68.09 39.36 98.40 95.21 87.02 80.64 87.54 98.94 92.55 93.26 80.43 87.81 98.58 93.88 89.36 80.53 87.66 85.32 87.27 100.00 98.94 98.94 100.00 96.81 98.94 97.87 94.68 92.55 94.68 91.49 82.98 94.68 89.36 91.49 94.68 76.60 80.85 93.62 98.94 95.74 91.28 86.60 91.34 98.94 95.74 91.28 86.60 91.34 98.09 93. 76.47 95.29 90.59 94.12 84.71 92.94 90.59 81.18 82.35 84.71 80.00 70.59 76.47 72.94 81.18 83.53 56.47 67.06 78.82 91.76 82.94 78.82 72.24 78.91 91.76 82.94 78.82 72.24 78.91 87.06 81.05 97.65 95.29 97.65 97.65 88.24 95.29 94.12 89.41 88.24 91.76 90.59 88.24 85.88 89.41 88.24 88.24 77.65 83.53 80.00 83.53 82.35 81.18 77.65 75.29 76.47 69.41 63.53 58.82 55.29 35.29 93.53 92.94 84.94 70.82 82.27 97.65 90.59 85.49 74.82 82.67 94.90 91.76 85.15 72.82 82.45 80.94 82.20 96.47 98.82 97.65 97.65 95.29 98.82 97.65 91.76 96.47 96.47 88.24 89.41 90.59 84.71 90.59 91.76 75.29 74.12 91.76 98.24 93.53 92.24 83.29 90.08 98.24 93.53 92.24 83.29 90.08 96.47 91. 83.82 95.59 83.82 91.18 88.24 91.18 88.24 80.88 88.24 92.65 79.41 66.18 82.35 76.47 76.47 89.71 55.88 73.53 82.35 87.50 84.56 81.76 74.41 80.36 87.50 84.56 81.76 74.41 80.36 88.24 82.43 97.06 97.06 97.06 94.12 95.59 92.65 92.65 97.06 95.59 91.18 94.12 89.71 89.71 92.65 94.12 86.76 88.24 91.18 89.71 82.35 88.24 82.35 82.35 80.88 80.88 77.94 72.06 64.71 63.24 19.12 97.06 91.91 90.00 76.18 86.34 94.12 91.18 90.69 79.71 86.10 96.08 91.54 90.26 77.94 86.24 80.88 85.34 91.18 100.00 98.53 98.53 98.53 98.53 97.06 95.59 94.12 97.06 92.65 89.71 89.71 97.06 95.59 94.12 70.59 77.94 94.12 98.53 97.06 92.65 87.06 92.12 98.53 97.06 92.65 87.06 92.12 96.18 93. 78.12 95.07 83.85 90.88 80.99 91.29 90.36 79.25 83.12 87.61 78.72 70.82 74.76 73.11 73.79 86.18 60.39 65.54 78.54 87.57 80.12 79.01 71.80 77.82 87.57 80.12 79.01 71.80 77.82 86.59 80.13 97.64 97.00 96.26 95.90 93.73 93.20 93.09 92.07 90.96 90.72 90.05 89.54 88.48 87.98 87.40 86.62 85.25 84.95 84.67 84.49 83.74 82.82 82.67 80.28 78.60 71.51 69.64 65.23 64.22 35.09 94.16 91.90 85.90 75.59 84.26 95.90 90.84 88.28 77.48 84.53 94.74 91.37 86.79 76.53 84.38 82.88 84.13 95.90 98.41 97.85 97.74 94.98 97.61 97.60 93.93 93.08 94.37 90.58 87.01 90.81 90.11 91.09 91.02 74.47 76.76 92.96 97.73 94.46 91.17 84.69 90.26 97.73 94.46 91.17 84.69 90.26 96.52 91. 90.55 96.83 92.65 95.90 94.11 93.20 89.69 93.66 92.97 87.96 90.05 89.54 88.48 88.06 89.79 86.62 85.25 84.75 80.83 83.35 83.74 82.01 82.52 80.28 85.27 71.51 68.17 65.23 68.84 68.86 93.16 88.82 85.36 77.36 84.11 95.90 90.84 88.28 77.48 84.53 94.07 89.83 86.45 77.42 84.29 88.66 85.02 Table 16: GIMMICK Cultural Origin Question Answering Country (COQAC) results. The reported score is relaxed accuracy. The columns and stand for image-only and text-only inputs to the model. G.4 CKQA G.4.1 LLM-as-a-Judge Evaluation To evaluate the CKQAD and CKQAN tasks, we used GPT-4o (gpt-4o-2024-11-20) as judge using the prompts shown in the next section. For each sample, we used the same system prompt and generated user prompts per sample individually."
        },
        {
            "title": "System Prompt",
            "content": "# Your Role You are an impartial judge who excels at critical and analytical thinking. # Your Task"
        },
        {
            "title": "Your task is it to thoroughly analyze and evaluate the correctness of a generated answer to a",
            "content": "Cultural Knowledge Test. (cid:44) 1. Carefully analyze the ground truth and the generated answer. 2. Provide brief summary (1 - 3 sentences) of your analysis, covering the accuracy, (cid:44) 3. Provide one or two-sentence explanation justifying your final score. Ensure that your (cid:44) explanation and score are consistent with each other and accurately reflect the quality of the generated answer in relation to the ground truth. relevance, and completeness of the generated answer. (cid:44) 4. Provide single number from 0 to 100 representing the correctness of the generated answer, (cid:44) where: 0 = Completely incorrect or irrelevant. 25 = Mostly incorrect or irrelevant. 50 = Partially correct or relevant. 75 = Mostly correct and relevant. 100 = Perfectly correct and complete. You may use any whole number within this range to reflect nuanced judgments. # Output Format Provide your evaluation in the following format: ```xml <evaluation> <analysis> <!-- Put your analysis summary here --> </analysis> <explanation> <!-- Put your explanation here --> </explanation> <score> <!-- Put your score here --> </score> </evaluation> ```"
        },
        {
            "title": "User Prompt Template",
            "content": "Evaluate the correctness of the generated answer with respect to Ground Truth. # Ground Truth ``` {GROUND_TRUTH} ``` # Generated Answer ``` {GENERATED_ANSWER} ``` # Evaluation G.4.2 Results 62 WEST EU & NORTH AM."
        },
        {
            "title": "EAST EU",
            "content": "ASIA & PACIFIC LAT. AM. & CARIB."
        },
        {
            "title": "ARAB",
            "content": "SUBS. AFRICA"
        },
        {
            "title": "AVERAGE",
            "content": "GPT-4o Claude 3.5 Sonnet Gemini Pro Qwen2.5 72B Qwen2.5 32B GPT-4o Mini Gemini Flash Phi 3.5 Mini Aya Expanse 8B Qwen2.5 7B InternLM2.5 20B Llama 3.2 11B Vision InternVL2.5 38B InternVL2.5 78B Qwen2 VL 72B InternLM2.5 7B Qwen2.5 3B InternVL2.5 26B Qwen2 VL 7B MiniCPM 2.6 Centurio Qwen Phi 3.5 Vision InternVL2.5 8B InternVL2.5 4B Qwen2.5 1.5B InternLM2.5 1.8B Qwen2 VL 2B InternVL2.5 1B InternVL2.5 2B Centurio Aya Qwen2.5 0.5B Average X-Large LVLMs Average Large LVLMs Average Medium LVLMs Average Small LVLMs Average LVLMs Average X-Large LLMs Average Large LLMs Average Medium LLMs Average Small LLMs Average LLMs Average X-Large Average Large Average Medium Average Small Average Open Average Proprietary Average 46.98 43.05 42.28 34.36 36.54 23.72 19.33 20.67 11.91 14.09 18.49 14.87 12.08 6.81 5.44 11.41 9.87 5.30 4.80 20.00 17.81 11.81 8.82 12.77 20.00 17.81 11.81 8.82 12.77 40.64 20. 56.78 56.64 53.29 47.55 47.89 48.89 52.75 40.40 40.17 38.39 37.01 36.44 41.21 40.84 40.81 34.33 32.75 39.97 32.82 34.70 31.38 36.64 36.28 35.81 24.03 23.56 23.29 24.09 23.26 29.33 13.96 40.83 40.59 33.49 28.62 33.79 47.55 42.45 37.63 26.94 34.55 43.07 41.52 34.87 27.78 34.11 53.67 37.27 I+T 57.21 55.60 57.21 55.70 54.70 37.62 36.28 41.01 34.43 38.09 36.28 32.05 35.03 29.97 27.89 31.95 16.51 18.72 5.94 38.64 36.02 28.47 26.02 30.13 38.64 36.02 28.47 26.02 30.13 56.08 36.96 T I+T I+T T I+T I+T T I+T I+T Avg. 38.20 35.20 36.80 27.70 29.67 18.63 17.63 17.37 12.63 14.27 13.60 14.47 12.43 6.80 5.40 11.57 8.50 4.80 5.30 17.50 15.63 10.89 8.54 11.67 17.50 15.63 10.89 8.54 11.67 33.51 17.42 54.30 55.97 50.07 45.17 43.73 46.63 46.87 35.23 36.13 36.50 34.13 32.77 38.80 37.73 37.03 32.30 28.90 36.10 29.53 30.47 29.23 32.10 31.33 33.07 20.77 22.30 20.03 20.43 19.50 25.50 11.77 37.38 37.45 29.80 25.03 30.24 45.17 38.93 34.98 23.79 31.54 39.98 38.19 31.53 24.41 30.79 50.77 34.01 54.87 50.07 53.67 54.00 51.30 37.03 37.10 42.13 34.07 37.17 34.60 29.97 35.23 29.13 27.80 28.90 16.83 21.90 7.53 39.62 35.55 27.68 26.13 29.96 39.62 35.55 27.68 26.13 29.96 52.78 35. 44.71 39.54 37.47 30.73 31.78 20.51 19.16 18.23 13.76 12.72 15.88 15.07 10.09 9.07 5.97 12.48 9.78 4.47 2.94 18.70 17.14 11.14 8.56 12.15 18.70 17.14 11.14 8.56 12.15 36.85 18.65 59.20 59.67 52.94 50.62 48.45 49.05 50.40 38.27 39.42 38.78 36.59 35.75 41.55 41.57 40.02 34.62 33.05 38.92 33.12 33.76 31.57 33.36 33.72 35.71 26.66 22.94 20.97 21.28 22.26 28.85 14.40 40.80 40.24 32.79 26.72 32.83 50.62 42.52 37.61 27.06 34.89 44.07 41.38 34.40 26.89 33.70 54.25 37.02 58.56 54.05 55.18 53.61 51.62 39.96 38.23 42.10 34.00 37.43 34.96 34.76 32.30 30.49 28.08 29.00 18.50 20.58 5.02 40.16 36.98 28.53 25.69 30.39 40.16 36.98 28.53 25.69 30.39 54.60 36. 34.08 26.84 29.18 24.95 23.20 23.72 19.64 14.08 13.11 17.09 18.67 16.38 13.78 6.58 7.14 14.18 11.22 7.30 7.50 16.86 18.42 13.24 10.72 13.60 16.86 18.42 13.24 10.72 13.60 27.65 17.30 51.53 53.32 49.44 42.70 40.71 43.72 46.07 34.80 34.18 34.23 31.17 30.00 33.32 37.50 36.02 31.17 28.47 34.18 28.32 29.03 27.40 29.74 29.74 34.29 20.87 18.52 20.51 20.41 21.48 24.23 11.43 36.76 33.75 28.12 25.29 29.08 42.70 35.94 33.19 22.82 29.84 38.74 34.84 29.81 24.05 29.40 48.82 32.53 52.45 49.23 50.00 49.44 49.07 38.72 36.58 37.60 28.98 35.97 34.34 35.77 29.80 30.36 27.24 28.16 16.07 19.95 8.47 37.09 33.85 28.98 24.24 29.14 37.09 33.85 28.98 24.24 29.14 50.04 34. 44.41 41.45 38.68 36.84 32.43 24.08 22.89 23.42 15.33 17.17 17.50 18.62 16.97 12.11 9.01 16.32 12.83 9.34 4.28 23.16 19.70 13.94 12.89 15.70 23.16 19.70 13.94 12.89 15.70 38.76 21.77 57.76 56.78 48.68 44.47 42.17 47.50 46.64 34.87 36.32 34.01 32.83 33.68 35.46 35.66 36.12 29.93 26.58 34.01 29.28 30.20 27.30 31.97 30.53 28.62 21.45 21.78 18.29 16.51 21.38 24.21 8.29 35.89 34.74 29.20 23.35 28.88 44.47 37.50 33.42 22.59 30.25 38.75 36.12 30.61 22.97 29.46 51.47 33.01 56.91 53.68 54.08 54.21 51.45 39.67 42.57 41.91 36.38 35.46 36.84 36.32 33.42 30.26 29.54 29.47 18.75 20.72 4.21 42.24 38.03 28.62 26.38 31.11 42.24 38.03 28.62 26.38 31.11 54.07 37. 29.04 24.73 22.05 21.03 16.44 15.96 14.86 10.62 9.38 9.38 9.93 13.01 11.99 2.53 4.79 11.92 9.93 5.68 4.45 12.74 12.67 7.86 8.86 9.60 12.74 12.67 7.86 8.86 9.60 22.66 13.04 50.68 50.34 41.23 37.95 39.25 39.25 36.37 30.00 26.71 29.04 27.53 27.40 32.47 33.22 29.38 23.49 22.81 29.59 20.55 18.42 20.41 25.75 22.67 25.68 16.23 14.66 13.63 14.93 15.96 19.38 8.70 31.30 31.03 21.47 19.19 23.30 37.95 33.39 26.41 18.48 25.12 33.52 32.21 23.12 18.84 24.07 43.57 27.22 51.37 44.79 46.23 46.78 42.12 33.49 35.34 35.14 27.95 30.96 24.52 32.60 26.78 20.96 23.63 25.96 17.60 18.77 5.89 35.24 30.72 22.99 22.55 25.68 35.24 30.72 22.99 22.55 25.68 46.26 31. 39.57 35.14 34.41 29.27 28.34 21.10 18.92 17.40 12.69 14.12 15.68 15.40 12.89 7.32 6.29 12.98 10.35 6.15 4.88 18.16 16.90 11.48 9.73 12.58 18.16 16.90 11.48 9.73 12.58 33.35 18.05 55.04 55.45 49.28 44.74 43.70 45.84 46.52 35.60 35.49 35.16 33.21 32.67 37.14 37.75 36.56 30.97 28.76 35.46 28.94 29.43 27.88 31.59 30.71 32.20 21.67 20.63 19.45 19.61 20.64 25.25 11.42 37.16 36.30 29.15 24.70 29.69 44.74 38.46 33.87 23.62 31.03 39.68 37.38 30.72 24.16 30.26 50.43 33.51 55.23 51.24 52.73 52.29 50.04 37.75 37.68 39.98 32.64 35.85 33.59 33.58 32.09 28.53 27.36 28.91 17.38 20.11 6.18 38.83 35.20 27.55 25.17 29.40 38.83 35.20 27.55 25.17 29.40 52.31 35. 49.95 47.28 45.47 44.74 43.70 42.47 41.63 35.60 35.49 35.16 33.21 32.67 32.00 31.45 31.31 30.97 28.76 26.93 26.30 26.23 25.62 25.53 22.19 21.95 21.67 20.63 20.45 15.78 15.63 12.10 11.42 31.38 29.46 24.18 19.87 24.41 44.74 38.46 33.87 23.62 31.03 35.83 33.96 27.41 21.74 27.21 45.36 30.14 Table 17: Average Judge Score for the GIMMICK Cultural Knowledge Question Answering (CKQA) Describing. The columns I, T, and I+T stand for image-only, text-only, and image+text input to the model. WEST EU & NORTH AM. EAST EU ASIAN & PACIFIC LATIN-AMERICA & CARIBBEAN ARAB"
        },
        {
            "title": "SUBSAHARIAN AFRICA AVERAGE",
            "content": "GPT-4o Claude 3.5 Sonnet GPT-4o Mini Centurio Qwen Gemini Pro Gemini Flash InternVL2.5 38B Phi 3.5 Vision InternVL2.5 78B InternVL2.5 26B InternVL2.5 1B Qwen2 VL 72B MiniCPM 2.6 Centurio Aya InternVL2.5 2B InternVL2.5 4B InternVL2.5 8B Qwen2 VL 2B Qwen2 VL 7B Average X-Large LVLMs Average Large LVLMs Average Medium LVLMs Average Small LVLMs Average LVLMs Average X-Large Average Large Average Medium Average Small Average Open Average Proprietary Average 37.79 40.27 34.46 18.69 16.91 15.77 14.06 15.17 12.08 11.51 10.20 11.04 8.89 6.95 6.31 6.28 6.51 5.40 5.27 11.56 12.78 9.26 8.67 9.88 11.56 12.78 9.26 8.67 9.88 29.04 14.92 32.57 33.63 28.73 19.10 15.60 16.27 12.60 13.67 14.73 10.50 9.43 10.07 8.60 6.57 6.80 5.47 5.30 4.27 5.63 12.40 11.55 9.04 7.93 9.48 12.40 11.55 9.04 7.93 9.48 25.36 13. 37.68 39.29 33.08 21.97 16.71 14.87 16.24 13.54 14.89 13.16 10.42 9.96 11.42 6.06 6.17 5.07 4.54 7.35 4.78 12.42 14.70 9.75 8.51 10.40 12.42 14.70 9.75 8.51 10.40 28.33 15.12 30.15 25.71 23.67 18.67 11.13 11.60 10.71 12.45 7.35 7.65 10.71 7.40 4.74 8.78 7.14 6.02 6.48 3.62 4.03 7.38 9.18 8.54 7.99 8.27 7.38 9.18 8.54 7.99 8.27 20.45 11.47 38.03 38.16 34.87 25.46 17.30 14.61 21.12 14.28 15.72 14.34 14.80 11.45 10.99 5.20 8.49 9.28 9.28 5.53 6.32 13.58 17.73 11.45 10.48 12.30 13.58 17.73 11.45 10.48 12.30 28.59 16. 28.42 24.25 25.89 15.96 10.55 11.30 8.36 10.75 7.53 7.74 8.22 8.56 9.79 7.40 3.08 5.00 3.77 3.63 3.70 8.04 8.05 8.12 6.14 7.39 8.04 8.05 8.12 6.14 7.39 20.08 10.73 34.11 33.55 30.12 19.98 14.70 14.07 13.85 13.31 12.05 10.82 10.63 9.75 9.07 6.83 6.33 6.19 5.98 4.97 4.96 10.90 12.34 9.36 8.29 9.62 10.90 12.34 9.36 8.29 9.62 25.31 13.75 Table 18: Average Judge Score for the GIMMICK Cultural Knowledge Question Answering (CKQA) Naming."
        }
    ],
    "affiliations": [
        "Data Science Group, University of Hamburg",
        "Language Technology Group, University of Hamburg"
    ]
}