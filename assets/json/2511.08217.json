{
    "paper_title": "MADD: Multi-Agent Drug Discovery Orchestra",
    "authors": [
        "Gleb V. Solovev",
        "Alina B. Zhidkovskaya",
        "Anastasia Orlova",
        "Nina Gubina",
        "Anastasia Vepreva",
        "Rodion Golovinskii",
        "Ilya Tonkii",
        "Ivan Dubrovsky",
        "Ivan Gurev",
        "Dmitry Gilemkhanov",
        "Denis Chistiakov",
        "Timur A. Aliev",
        "Ivan Poddiakov",
        "Galina Zubkova",
        "Ekaterina V. Skorb",
        "Vladimir Vinogradov",
        "Alexander Boukhanovsky",
        "Nikolay Nikitin",
        "Andrei Dmitrenko",
        "Anna Kalyuzhnaya",
        "Andrey Savchenko"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Hit identification is a central challenge in early drug discovery, traditionally requiring substantial experimental resources. Recent advances in artificial intelligence, particularly large language models (LLMs), have enabled virtual screening methods that reduce costs and improve efficiency. However, the growing complexity of these tools has limited their accessibility to wet-lab researchers. Multi-agent systems offer a promising solution by combining the interpretability of LLMs with the precision of specialized models and tools. In this work, we present MADD, a multi-agent system that builds and executes customized hit identification pipelines from natural language queries. MADD employs four coordinated agents to handle key subtasks in de novo compound generation and screening. We evaluate MADD across seven drug discovery cases and demonstrate its superior performance compared to existing LLM-based solutions. Using MADD, we pioneer the application of AI-first drug design to five biological targets and release the identified hit molecules. Finally, we introduce a new benchmark of query-molecule pairs and docking scores for over three million compounds to contribute to the agentic future of drug design."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 1 1 ] . [ 1 7 1 2 8 0 . 1 1 5 2 : r MADD: Multi-Agent Drug Discovery Orchestra Gleb V. Solovev *1, Alina B. Zhidkovskaya1, Anastasia Orlova1, Nina Gubina1, Anastasia Vepreva1, Rodion Golovinskii1, Ilya Tonkii1, Ivan Dubrovsky1, Ivan Gurev1, Dmitry Gilemkhanov1, Denis Chistiakov1, Timur A. Aliev1, Ivan Poddiakov2, Galina Zubkova2, Ekaterina V. Skorb1, Vladimir Vinogradov1, Alexander Boukhanovsky1, Nikolay O. Nikitin1, Andrei Dmitrenko 1,3, Anna V. Kalyuzhnaya 1, and Andrey Savchenko2, 1ITMO University, Saint Petersburg, Russia 2Sber AI Lab, Moscow, Russia 3D ONE AG, Zurich, Switzerland 4HSE University, Moscow, Russia"
        },
        {
            "title": "Abstract",
            "content": "Hit identification is central challenge in early drug discovery, traditionally requiring substantial experimental resources. Recent advances in artificial intelligence, particularly large language models (LLMs), have enabled virtual screening methods that reduce costs and improve efficiency. However, the growing complexity of these tools has limited their accessibility to wet-lab researchers. Multi-agent systems offer promising solution by combining the interpretability of LLMs with the precision of specialized models and tools. In this work, we present MADD, multi-agent system that builds and executes customized hit identification pipelines from natural language queries. MADD employs four coordinated agents to handle key subtasks in de novo compound generation and screening. We evaluate MADD across seven drug discovery cases and demonstrate its superior performance compared to existing LLM-based solutions. Using MADD, we pioneer the application of AI-first drug design to five biological targets and release the identified hit molecules. Finally, we introduce new benchmark of query-molecule pairs and docking scores for over three million compounds to contribute to the agentic future of drug design."
        },
        {
            "title": "Introduction",
            "content": "Identifying hit molecules is at the core of drug discovery (Ashraf et al., 2024). Hits are commonly defined as chemical compounds with several desired properties, such as biological activity against particular target associated with disease, stability, synthetic accessibility, and others (Walters and Namchuk, 2003). With significant advances and widespread of artificial intelligence (AI) in the *glebsolo46@gmail.com dmitrenko@pish.itmo.ru anna.kalyuzhnaya@itmo.ru last decade, virtual screening has become an essential part of drug discovery (Maya Ramírez et al., 2024; Chikhale et al., 2024). AI methods for hit identification aim to reduce the resources required for high-throughput wet-lab experimentation and improve their success rate. Significant progress has been made in the adoption of such methods in the pharmaceutical industry all around the world (Yang et al., 2021; Zeng et al., 2022). However, the complexity of AI methods has also grown dramatically, resulting in limited accessibility of these tools for wet-lab researchers to pursue their drug discovery hypotheses (Bettanti et al., 2024). LLMs have emerged as powerful tools for bridging this gap, offering impressive capabilities for interpreting natural language descriptions of desired molecular properties and generating candidate molecules (Guan and Wang, 2024; Vert, 2023). Several promising LLM-based tools have been proposed recently, including DrugLLM (Liu et al., 2024b) for zero-shot molecular generation, ChemLLM (Zhang et al., 2024a) for chemistry-related Q&A, LlasMol (Yu et al., 2024a) for molecular property prediction, and X-LoRA-Gemma (Stewart and Buehler, 2024) for molecular optimization. However, LLMs alone are not competitive in molecule generation and molecular property prediction specific to early drug discovery. Combining an LLM with highly specialized tools gave rise to agentic architectures. The first examples, such as ChemAgent (Yu et al., 2024b), ChemCrow (M. Bran et al., 2024), and CACTUS (McNaughton et al., 2024), demonstrated high potential of this approach, but also highlighted the challenges of integrating numerous AI-based tools and automatic assembly of effective processing pipelines. Finally, multi-agent systems have been introduced (Skarlinski et al., 2024a; Odobesku et al.; Skarlinski et al., 2025). We were wondering whether multi-agent system could, in principle, be an effective end-to-end solution for hit identification in early drug discovery and overcome limitations of existing solutions by providing comprehensive execution of all stages: semantic query analysis, target-adaptive molecule generation, property calculation (binding affinity, synthetic accessibility), which is particularly crucial for drug discovery tasks. More specifically, we formulated the following research hypothesis: Multi-agent architecture, by distributing complex tasks across specialized agents with distinct roles, can significantly outperform both singleagent approaches and pure LLM generators in automating the complete drug discovery workflow through improved task coordination and domainspecific expertise (through domain pipelines and tools) integration. To pursue this hypothesis, we developed MADD, Multi-Agent Drug Discovery orchestra that employs four specialized agents to coordinate and execute hit identification subtasks. To inform the architecture design choices and validate the systems overall performance, we formulated six drug discovery cases related to the following conditions: Alzheimers disease, Parkinsons disease, multiple sclerosis, lung cancer, dyslipidemia, and drug resistance. For each condition, we assembled unique dataset, trained machine learning models, and implemented logic to validate the generated molecules. We compared MADD to existing LLMbased solutions and demonstrated its superior performance. As additional validation case studies, we compared the molecules produced by MADD with experimentally validated GSK-3β inhibitors and applied MADD to recently published (and, therefore, unseen) case of thrombocytopenia. Our empirical results demonstrate that MADD is one of the most effective multi-agent solutions for hit identification in drug discovery to date. In summary, the contributions of this paper are: 1. We present MADD, an effective end-to-end agentic solution for hit identification, and demonstrate its effectiveness in 7 drug discovery cases, including the case of thrombocytopenia, which was not available during the systems design. 2. We produce novel benchmark for future drug design agents, consisting of two synchronized datasets: the first, with pairs of user queries (inputs) and generated molecules (outputs) related to drug discovery, and the second, with docking scores calculated for over 3M molecules related to the 6 conditions considered in this work. 3. We pioneer the application of AI-first drug design to the following biological targets: STAT3, ABL, COMT, ACL, and PCSK9. As result, we identified several molecule hits with favorable bioactivity, binding affinity, and other physicochemical properties. The results of our study are open source (code and data): https://github.com/ITMO-NSS-team/MADD https://huggingface.co/datasets/ ITMO-NSS/MADD_Benchmark_and_results"
        },
        {
            "title": "2 Related work",
            "content": "Recent advances highlight the growing role of LLMs in chemistry, including predictive modeling, compound generation, and drug discovery. ChemDFM (Zhao et al., 2024), LlasMol (Yu et al., 2024a), X-Lora-Gemma (Stewart and Buehler, 2024), and CancerGPT (Li et al., 2024b) exemplify applications in data analysis, molecular optimization, and synergy prediction. Ye (Ye, 2024) proposed de novo molecule generation method, and M. Bran et al. (M. Bran et al., 2024) showed improved molecular property predictions by integrating LLMs with chemical tools. Agent-based LLM frameworks such as DrugAgent (Liu et al., 2024a), ChemCrow (M. Bran et al., 2024), CACTUS (McNaughton et al., 2024), and ChemAgent (Yu et al., 2024b) automate various steps in chemical research, from synthesis planning to molecular property analysis. Broader surveys (Zhang et al., 2024b; Jablonka et al., 2023) confirm the efficiency and scalability of these systems. These studies highlight that LLMs can accelerate scientific progress in chemistry and related fields, unlocking new material and drug development opportunities. Nevertheless, none demonstrate successful automation of the whole drug discovery pipeline. Possible reasons are (1) the absence of readily accessible dataset with complete pipeline for training and validating new models and approaches, and (2) the weakness of existing separated models and agent architectures for solving the whole task at high-quality level. Based on these conclusions, we propose our vision of stronger approach and valuable newly farmed dataset with state-of-the-art pharmaceutical research tasks and their solutions. design principles, reducing the space of possible actions for each agent. Specialization of agents has at least two advantages:"
        },
        {
            "title": "3 MADD orchestra",
            "content": "Figure 1: Overview of MADD architecture. We set out to develop system that harnesses advanced drug design methodologies and enhances their accessibility to domain experts by integrating LLM-based agents. These agents can autonomously operate molecular generation and property prediction tools, enabling more efficient and systematic hypothesis testing for identifying promising drug candidates. This strategy aims to significantly reduce research costs while allowing human experts to focus on more complex and valuecreating aspects of the pharmaceutical development process. To this end, we introduce the MADD approach, which integrates various generative and predictive tools into coherent, end-to-end drug discovery pipeline. The system is built upon multi-agent architecture (Figure 1) specifically designed to manage the complexity of automating early drug discovery workflows. The systems architecture isolates key functions in specialized agents, each optimized for specific tasks in the overall workflow. We define four agents and two LLM-tools to achieve high operational accuracy and ground their roles in modular software Mitigates the accumulation of errors in complex pipelines by improving the accuracy of individual steps. Provides more flexibility in constructing multi-step pipelines, which is essential for scalable system. 3.1 Agents Four specialized agents were developed to address complex, multi-step queries that require coordination across various tools. By distributing cognitive responsibilities among these agents, the system solves intricate tasks efficiently, resolving user queries in single processing attempt. The pipeline receives text query from the user and passes it to the Decomposer agent. In the case of complex tasks, this agent decomposes the original query into simpler subtasks. If the query is ambiguous, chat agent is called to clarify it and enrich the context with additional data provided by the user. Each task from the Decomposer agent is sent to the Orchestrator in sequence. The Orchestrator builds an action plan and calls tools to achieve complete response. It interacts with our generative tools to generate molecules (using pre-trained models or training from scratch) that match the desired properties and uses the property prediction tools to determine the properties of the molecules. The Summarizer compiles the results into coherent response and presents the generated molecules with their calculated properties in structured format. The Chat Agent helps the user formulate query, request missing data, and consult on system capabilities. More details about the proposed agents are described in Appendix E.1, E.2, E.4.1. 3."
        },
        {
            "title": "Integrated tools",
            "content": "Our research addresses the complex challenge of real-world drug discovery, which demands sophisticated integration of multiple specialized tools beyond basic chemical analysis. To meet these requirements, we developed toolset combining deep generative models for creating molecules, ML models for property prediction, and methods for evaluating synthetic accessibility, drug similarity, and other structural properties of molecules. As illustrated in Figure 1, the tools are organized into three logical categories: Molecular Generation Algorithms, Property Prediction Algorithms, and Data Processing. In automated learning experiments, tools within these groups were controlled via two specialized LLM-based tools, i.e. AutoMLDL and DatasetBuilder, rather than directly by the Orchestrator. These components directly call the necessary specialized tools to execute the tasks specified by the Orchestrator. more detailed account of these experiments can be found in the Appendix C.1. The DatasetBuilder tool prepares datasets for model training. Its functionality includes removing irrelevant data and table columns, filtering data based on specified conditions, and loading data containing molecules and their binding affinity properties. It has access to the BindingDB and ChEMBL databases. The AutoML-DL tool is capable of generating molecules, predicting molecular properties, initiating training procedures, and monitoring the training status of both predictive and generative models. Molecule generation algorithms. This toolset includes pre-trained generative models and algorithms for automatic fine-tuning for new disease cases. Currently, MADD supports two generative models: LSTM-based GAN and transformer-based CVAE. These models were pre-trained on datasets of 500k ChEMBL molecules for each disease (Appendix C.4.4), for which we calculated Docking scores and other desired properties. These generative approaches were selected by their proven efficacy in the previous study (Gubina et al., 2024). In addition, we treat GAN as fast, lightweight generator compared to transformer, which is beneficial for real-time processing. Both implementations are detailed in the Appendix C.9.1. Property prediction algorithms. This toolset includes pre-trained machine learning models and methods for predicting and calculating the required disease properties. Furthermore, this toolkit features an AutoML framework FEDOT (Nikitin et al., 2022) designed to automatically train machine learning pipelines using custom datasets to predict molecular properties for new disease cases. MADD can use the tool to predict the halfmaximal inhibitory concentration (IC50), which is the concentration of drug required to inhibit biological process or response by 50% and is the most widely used and informative measure of drugs efficacy. Appendices C.6, D.4 describe the training and selection of the best model for each case study in more detail. One of the target properties we used as training data was the binding energy of the target protein to ligand. This energy can be estimated using molecular docking, typically called the docking score. Details on docking score estimation are presented in the Appendix D.4.2. The Orchestrator can use several RDKit-based functions: synthetic accessibility (SA), druglikeness estimation (QED), and structural filters such as Brenk, SurehEMBL, Glaxo, and PAINS. Data Processing. Tools for data retrieval via API from the ChEMBL and BindingDB databases are presented. Data acquisition requires specifying target protein (or its respective database ID) and an affinity measurement type (Ki, Kd, or IC50). The retrieved data can be preprocessed before training, including filtering by affinity value and removing missing values."
        },
        {
            "title": "4 Experimental studies",
            "content": "In this section, we present series of experimental results that informed the design of MADD architecture and proved the overall effectiveness of our approach."
        },
        {
            "title": "4.1 Benchmark creation",
            "content": "Existing chemical datasets possess significant limitations to benchmarking LLM-based agents for drug design. While Chembench (Mirza et al., 2024) and PharmaBench (Niu et al., 2024) cover textbased tasks and property prediction, respectively, they lack the complexity of real-world screening scenarios, which often involve multiple subtasks such as identifying biological targets, generating molecules, and evaluating their properties. To fill this gap, we introduce new benchmark featuring linked datasets of user queries, target molecular structures, and their properties, based on the six drug discovery cases related to Alzheimers and Parkinsons diseases, multiple sclerosis, lung cancer, dyslipidemia, and drug resistance (Figure 2). The datasets of user queries are of particular importance for natural language processing, while the other datasets are essential for evaluating hit identification capabilities. The datasets of user queries were created as follows. First, 30 realistic queries were manually composed to reflect inputs from both experts and Figure 2: Overview of the proposed benchmark non-experts. The latter included vague or imprecise instructions mimicking real user behavior. Next, the set of queries was augmented with few-shot prompting of GPT-4o, o1-mini, Claude Sonnet 3.5, and Gemini 1.5 Pro to increase semantic diversity. Highly similar queries were filtered out using sentence embeddings (Stankeviˇcius and Lukoševiˇcius, 2024; Devika et al., 2021). Finally, human experts validated the outputs, resulting in curated set of high-quality queries. These queries were divided into three datasets according to the complexity of the underlying scenario: Dataset (single-task queries), Dataset (13 tasks per query), and Dataset (45 tasks). More details, examples, and visualizations are provided in Appendix C.4."
        },
        {
            "title": "4.2 Comparison of underlying LLMs",
            "content": "Orchestration is critical component of multiagent system. Therefore, we evaluated several LLMs ability to play an orchestrator role. For that, we defined the orchestrator accuracy (OA) as the percentage of the correctly selected tools in the query (see Appendix D.8), and used Dataset to compare the models. Additionally, we included two prompting strategies for an objective comparison: using unified system prompt that was identical for all the models and using optimized individual prompts, where model-specific prompts were engineered to ensure top performance, using function-specific keywords and more precise instructions. We found that Llama-3.1-70b with the optimized system prompt was the best model, achieving an OA metric of 92.3%. Notably, this model outperformed o1-mini (67.5%), DeepSeekTable 1: Comparison of MADD with other candidate architectures for multi-agent systems by TS, SSA, and FA metrics. TS Metric 83.7 MADD 42.5 MADD-v1 MADD-v2A 35.0 MADD-v2B 76.7 MADD-v2C 81.4 46.5 MADD-v3 SSA FA 79.8 95.3 29.8 70.0 22.8 65.1 73.0 95.3 43.7 53.7 35.2 75. R1 (88.11%), and even the next generation Llama3.2-90b (90.7%), while also being cheaper. Figure 9 in Appendix C.5 presents more experimental results on orchestration accuracy. Based on this empirical evidence, we selected Llama-3.1-70b as the default LLM behind agents in MADD."
        },
        {
            "title": "4.3 Ablation study",
            "content": "To motivate the design of the multi-agent architecture and demonstrate its ability to deliver sensible responses to user requests, MADD was compared with five alternative versions, in which one to several agents were removed. Those included: MADD-v1 (single-agent with CoT-based reasoning), MADD-v2A (two-agent system with Decomposer and Orchestrator but no summarization), MADD-v2B (two-agent system where Orchestrator handles both tool selection and summarization), MADD-v2C (unified OrchestratorDecomposer with separate Summarizer), and MADD-v3 (RAG-based three-agent system without answer revision). More detailed descriptions are in Appendix C.2, and schematics are in Appendix D.9 We used Dataset and evaluated the following metrics: tool selection (TS) accuracy, system response summarization (SSA) accuracy, and final system accuracy (FA), that accounts for both TS and SSA metrics (see formulas in Appendix D.8.2). The results are given in Table 1. key observation across all systems that did not incorporate dedicated Summarizer was the issue of inconsistent response delivery. This challenge manifested itself in the inability of the systems to effectively consolidate information and provide coherent, comprehensive answers to the user. Consequently, this limitation significantly impacted the final metric (FA) for most alternative versions. Another conclusion is that the more roles the Orchestrator agent takes on, the worse it performs. This observation underscores the need for clear division of roles between agents to ensure optimal performance and successful task completion. Overall, MADD achieves almost 80% in FA, evaluated on the most complex scenarios (Dataset L). Another conclusion from our ablation study is that the more roles the Orchestrator agent takes on, the worse it performs. This observation further underscores the need for clear division of roles between agents to ensure optimal performance and successful task completion. Overall, the current implementation of MADD achieves almost 80% in FA, evaluated on the most complex scenarios among all tested (Dataset L)."
        },
        {
            "title": "4.4 Analysis of generative models",
            "content": "There are many strong generative models in drug design that are capable of producing molecules in SMILES notation. comprehensive evaluation of those is beyond the scope of this study. Nevertheless, we included limited number of recently published generative models for comparison with MADD to showcase its generative capabilities, executed by the integrated GAN and Transformer models. More specifically, we compared MADD against an evolutionary optimization MTDD-EF (Cerveira et al., 2024), Monte Carlo tree search ChatChemTSv2 (Ishida et al., 2024), as well as the previously discussed X-LoRA-Gemma, LlaSMoL, ChemDFM, and ChemAgent. As performance metric, we used the percentage of hit moleculesthose meeting the desired propertiesout of the total number of generated molecules. The set of desired properties is defined by five filters corresponding to bioactivity, synthetic accessibility, druglikeness, and other properties (see descriptions in Figure 3). Each successive filtering criterion includes all the previous ones, imposing progressively stricter property requirements. More details on filter groups are presented in Appendix D.5. The most stringent criterion corresponds to filter group 5 (GR5). Table 8 indicates that the Transformer used in MADD achieved top performance in three of six tested cases corresponding to different conditions. On the other hand, GAN never delivered the top scores. Still, it was the second most consistent generative model after Transformer, producing non-zero percent of hit molecules in five of six tested cases. As follows from Tables 9 and 8, the other generative approaches occasionally showed better results on individual cases, but the overall performance of MADD remained superior. More details are available in Appendices C.9 and C.10."
        },
        {
            "title": "4.5 Comparison with existing solutions",
            "content": "We probed several existing LLM-based solutions on three query datasets from our benchmark and compared their performance with MADD. We selected three state-of-the-art chemistry LLMs, namely, X-LoRA-Gemma, LlaSMoL, and ChemDFM, as well as the recently proposed ChemAgent for comparison. The results are summarized in Table 2. In contrast to agent-based systems, standalone LLMs (LlasMol, ChemDFM, X-Lora-Gemma) practically failed to produce structured answers with valid chemical compounds in all datasets. This is most likely due to insufficient domain knowledge in the training set and missing access to specialized molecular generation and screening tools. In turn, ChemAgent suffers from the problems associated with the limitations of generation tools, predicting no more than 2.5% hit molecules passing the first group of filters (GR1), as shown in Figure 3. Moreover, ChemAgent makes errors in summarizing and structuring the output to the user (19.1% of SSA), reducing the final accuracy of the system to 16.4%, as indicated in Table 3. ChemAgent often fails to present key results (e.g., missing SMILES representations), likely due to inaccurate agent prompting, highlighting orchestration struggles in complex tasks. In contrast, the multiagent design of MADD allows for avoiding these shortcomings and demonstrates at least 80% of the final system accuracy on multi-task benchmarkTable 2: Comparison of the Final Accuracy (%) of MADD and baseline methods on datasets of different complexity. Dataset MADD ChemAgent LlasMol X-Lora-Gemma ChemDFM 86.9 12.4 0.46 0.44 5. 84.3 15.3 0.24 0.12 0.33 79.8 16.4 0 0 0 ing datasets. Examples of the resulting questionanswer pairs for different systems are presented in the Appendix E.4. MADD utilizes comparable set of tools to ChemAgent; however, as shown in Table 2, it outperforms ChemAgent by up to 29.1% in tool selection accuracy when applied to the Dataset and Dataset M. However, both approaches demonstrate similar accuracy in tool selection evaluated on Dataset L. In addition, we briefly compared two fresh solutions for chemical problems: TxGemma (Wang et al., 2025) and Phoenix from the FutureHouse platform. We found that Phoenix managed to create single molecule that satisfied the GR2 filter, but no more. The molecules produced by TxGemma did not pass any filters. Detailed results for these methods are proposed in Appendices C.3.1-C.3.2."
        },
        {
            "title": "4.6 End-to-end hit identification with MADD",
            "content": "Figure 3 shows that the end-to-end generation process, from query to molecule search, demonstrates that MADD outperforms LLM-based approaches in all filter groups and mean values of Docking score. The other models can generate valid SMILES but are not unambiguously able to construct relationship between properties and molecules. More detailed discussions of the novelty of the created molecules are described in Appendix C.11 (Table 9 compares all systems for all seven diseases)."
        },
        {
            "title": "5 AutoML features of MADD",
            "content": "We evaluated the effectiveness of MADDs automatic training generative model by comparing it to Table 3: Comparison of MADD with ChemAgent on dataset Metric MADD ChemAgent TS 83.7 85.8 SSA FA 79.8 95.3 16.4 19.1 Figure 3: Comparison of drug discovery approaches using average metrics across considered diseases. The filtration groups (GR) are based on molecule properties such as Docking score and IC50 (GR1), SA (GR2), BRENK (GR3), and the latter groups additionally include SurehEMBL, Glaxo, PAINS (GR4), and QED (GR5). Figure 4: Comparison of F1 score for the MADD automatically created and trained ML pipeline and manually pre-trained models for IC50 predictions. manual training on Alzheimers disease. Predictive performance was assessed across all six diseases. Predictive models were used in the automatic learning process of generative models to stop learning early and select the best learning epoch, considering the value of the loss function and the error in matching the required properties in the generated molecules. As shown in Figure 4, by automatically running the AutoML framework, MADD can train machine learning pipelines for molecular property prediction tasks that outperform pre-trained manual models in most cases. The efficiency of generative models trained automatically by MADD is comparable in terms of the number of target molecules generated and the average docking score on the Alzheimers disease example. As result, the study significantly outperformed the average Docking Score in terms of the percentage of target molecules generated. The results of training the generative models are shown in Table 4. Additionally, we evaluated whether the tool selection (TS) metric is retained when adding tool for running generative or predictive model training. As result of this evaluation, tool selection accuracy decreased slightly from 83.7%  (Table 1)  to 80.5% on average. For more detailed description of this study, see Appendix C.8."
        },
        {
            "title": "6 Case studies",
            "content": "Alzheimers disease case study. We conducted case study on Alzheimers disease to compare molecules generated by MADD with experimentally validated GSK-3β inhibitors from ChEMBL (Figure 5A). The MADD-generated molecules exhibited higher mean SA and QED scores compared to the ChEMBL compounds. In addition, the MADD molecules showed improved binding affinities to the target protein. Moreover, generated compounds demonstrated high structural diversity, with an average Tanimoto similarity of 0.43. This suggests that MADD can be an effective tool for de novo drug design, potentially producing candidates that surpass existing ligands in terms of key drug-relevant properties. Figure 5: Results of case studies: a). Alzheimers disease case study; ChEMBL - experimentally validated GSK-3β inhibitors from ChEMBL, MADD - molecules generated by our approach. b). Thrombocytopenia case study; SYK-FBRL - molecules generated by SYK-FBRL approach, MADD - molecules generated by our approach. Thrombocytopenia case study. This study involved validation using one of the recently explored drug design cases on thrombocytopenia (Zavadskaya et al., 2025), where fragment-based RL was employed for the generation of novel SYK-inhibitors (hereafter, SYK-FBRL). MADD was provided the dataset containing 3.2k SYKinhibitors to train new generative and predictive models for this case automatically. Using the AutoML framework, MADD could derive pipeline to predict pIC50, achieving metric value of R2=0.75, compared to 0.78 in SYK-FBRL. More details about the resulting machine learning pipelines are described in the Appendix C.7 Besides the predictive models for pIC50 and docking score, MADD managed to fine-tune the Transformer model. Ultimately, MADD generated 10k molecules, of which 132 matched all five of our property filters. In contrast, the original SYKFBRL approach generated 76k molecules, of which 139 corresponded to the required pIC50 and DS properties. This outcome highlights the superior efficiency of MADD in hit identification. Table 4 summarizes the results of comparing the MADD and SYK-FBRL approaches for thrombocytopenia. Additionally, Figure 5b compares MADDgenerated molecules with compounds produced by SYK-FBRL. The fully automatic pipeline of MADD resulted in molecules with improved docking scores, QED, and SA properties. Notably, these results were obtained without any adjustments to MADD configuration and with no additional inputs from human experts (e.g., medicinal chemists) (Kumichev et al., 2024). This outcome is the most substantial evidence in support of the hypothesis formulated in this work. It also highlights the excellent potential for MADD to streamline and enhance early-stage drug discovery."
        },
        {
            "title": "7 Discussion",
            "content": "While MADD demonstrates promising generalization capabilities in the thrombocytopenia case, which was not part of the original design, several limitations regarding its applicability to new cases should be further explored. In its current implementation, users are required to provide their own dataset of molecules and corresponding target properties to train MADDs generative and predictive tools. In practice, many users may lack access to well-curated datasets, impacting both model performance and reproducibility. Moreover, MADDs pipeline assumes prior knowledge of the biological target or relevant properties, which limits the discovery of ligands for fundamentally novel targets. meet eight key drug criteria. Validation on two case studies, including an unseen thrombocytopenia case, further confirms its autonomous discovery capabilities. We contribute to the future of drug design agents by presenting novel benchmark and discussing current generalization and wet lab experimentation challenges."
        },
        {
            "title": "Acknowledgments",
            "content": "This work supported by the Ministry of Economic Development of the Russian Federation (IGK 000000C313925P4C0002), agreement No139-152025-010. Table 4: Comparison of an automatically trained MADD models ability to create hit molecules, compared to pretrained models for Alzheimers disease and Thrombocytopenia. The Novelty was compared to the dataset of compounds reported in the SYK-FBRL study for thrombocytopenia. Case Alzheimer Thrombocytopenia Model MADD Mean DS Novelty Validity GR1,% GR2,% GR3,% GR4, % GR5,% -7.46 78.21 87.47 20.30 17.56 13.72 13.40 13.40 MADD Auto -7.57 73.47 89.5 15.99 14.43 13.14 12.34 12.34 SYK-FBRL -7.76 100 100 0.18 0.07 0.06 0.06 0.06 MADD Auto -8.02 100 90.71 1.54 1.35 1.32 1.32 1. To address these issues, future work should focus on integrating automated data curation pipelines and incorporating modules for hypothesis generation to enable more open-ended discovery. Additionally, the systems current generalization is predominantly demonstrated in silico without broader experimental validation. We tried to ensure in silico validation of generated hits. However, translating these predictions into real-world outcomes requires experimental validation through biochemical assays, cell-based screens, and animal studies, which are inherently time-consuming, costly, and resource-intensive processes. This imbalance creates bottleneck: while AI systems can explore chemical space at unprecedented scale and speed, only small fraction of candidates can realistically be tested in the lab. Nevertheless, future efforts will focus on extending this work through experimental collaborations to confirm the predicted activities and refine the model based on empirical results. Integrating wet lab validation into the MADD pipeline would strengthen the biological relevance of its outputs and enable constant iterative improvement, further bridging the gap between AI-driven design and practical drug development."
        },
        {
            "title": "8 Conclusion",
            "content": "This paper introduces MADD, multi-agent system tackling the challenge of hit identification. MADD coordinates multiple tools to design molecules and assess their properties, achieving 79.8% overall pipeline accuracy. MADD consistently outperforms baselines in hit identification efficiency, yielding up to 6.63% novel hits that"
        },
        {
            "title": "References",
            "content": "Beyond the limitations discussed earlier, we outline several other considerations that may impact the use of MADD: Training Time for New Disease Cases When adapting the system to new disease, significant time is required for data preparation, generative model training, and predictive model fine-tuning. While we estimate this process should not exceed one day, reasonable timeframe for hit identification, it remains practical constraint for users seeking rapid deployment. Interpretability of the Black-Box Pipeline MADD operates as closed system (black box) in chat mode, handling queries without exposing its internal workflows. While expert chemists may prioritize results over methodological transparency, the inclusion of RDKit-based tools allows users to evaluate them partially. Future iterations could incorporate agent decision logging to enhance interpretability, explicitly detailing the tools and actions selected during execution. Tool Integration Barriers Extending MADDs functionality with new tools requires direct system code modification. Despite its open-source nature, users with limited programming expertise may face challenges integrating external tools, even those that could be seamlessly incorporated. Dependence on User-Defined Filtering Effective hit identification relies on userspecified thresholds to determine diseaserelevant molecules. This demands domain expertise to define appropriate molecular characteristics, which may limit accessibility for non-specialists. Additionally, we discussed the risks of our study in the Appendix A.1. We have further analyzed potential failure modes of our and similar LLM-based agent systems in the Appendix D.10. Dony Ang, Cyril Rakovski, and Hagop Atamian. 2024. De novo drug design using transformer-based machine translation and reinforcement learning of an adaptive monte carlo tree search. Pharmaceuticals, 17(2):161. Neha Ashraf, Henry Blackwell, Geoffrey Holdgate, Simon CC Lucas, Alisa Solovyeva, Ian Storer, and Benjamin Whitehurst. 2024. Hit me with your best shot: Integrated hit discovery for the next generation of drug targets. Drug Discovery Today, page 104143. Dávid Bajusz, Anita Rácz, and Károly Héberger. 2015. Why is tanimoto index an appropriate choice for fingerprint-based similarity calculations? Journal of cheminformatics, 7:113. Christie Ballantyne, James McKenney, Diane MacDougall, Janice Margulies, Paula Robinson, Jeffrey Hanselman, and Narendra Lalwani. 2016. Effect of etc-1002 on serum low-density lipoprotein cholesterol in hypercholesterolemic patients receiving statin therapy. The American journal of cardiology, 117(12):19281933. Jenny Beebe, Jing-Yuan Liu, and Jian-Ting Zhang. 2018. Two decades of research in discovery of anticancer drugs targeting stat3, how close are we? Pharmacology & therapeutics, 191:7491. Theo Berkhout, Louis Havekes, NJ Pearce, and PHE Groot. 1990. The effect of (-)-hydroxycitrate on the activity of the low-density-lipoprotein receptor and 3-hydroxy-3-methylglutaryl-coa reductase levels in the human hepatoma cell line hep g2. Biochemical journal, 272(1):181186. Alberto Bettanti, Andrea Rosario Beccari, and Marco Biccarino. 2024. Exploring the future of biopharmaceutical drug discovery: can advanced ai platforms overcome current challenges? Discover Artificial Intelligence, 4(1):116. Arun Singh Bhadwal, Kamal Kumar, and Neeraj Kumar. 2023. Gmg-ncdvae: guided de novo molecule generation using nlp techniques and constrained diverse variational autoencoder. ACM Transactions on Asian and Low-Resource Language Information Processing. Ozlem Bilen and Christie Ballantyne. 2016. Bempedoic acid (etc-1002): an investigational inhibitor of atp citrate lyase. Current atherosclerosis reports, 18:17. Andres Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew White, and Philippe Schwaller. 2023. Chemcrow: Augmenting large-language models with chemistry tools. arXiv preprint arXiv:2304.05376. Leo Breiman. 2001. Random forests. Machine learning, 45:532. Katharina Buerger, Michael Ewers, Tuula Pirttilä, Raymond Zinkowski, Irina Alafuzoff, Stefan Teipel, John DeBernardis, Daniel Kerkman, Cheryl McCulloch, Hilkka Soininen, and 1 others. 2006. Csf phosphorylated tau protein correlates with neocortical neurofibrillary pathology in alzheimers disease. Brain, 129(11):30353041. Maria Cencioni, Miriam Mattoscio, Roberta Magliozzi, Amit Bar-Or, and Paolo Muraro. 2021. cells in multiple sclerosisfrom targeted depletion to immune reconstitution therapies. Nature Reviews Neurology, 17(7):399414. Arthur Cerveira, Frederico Kremer, Darling Lourenço, and Ulisses Corrêa. 2024. Evaluation framework for ai-driven molecular design of multi-target In 2024 drugs: Brain diseases as case study. IEEE Congress on Evolutionary Computation (CEC), pages 18. IEEE. Tianqi Chen and Carlos Guestrin. 2016. Xgboost: In Proceedings of scalable tree boosting system. the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785 794. Rupesh Chikhale, Rinku Choudhary, Jagriti Malhotra, Gaber Eldesoky, Parth Mangal, and Pritee Chunarkar Patil. 2024. Identification of novel hit molecules targeting m. tuberculosis polyketide synthase 13 by combining generative ai and physicsbased methods. Computers in Biology and Medicine, 176:108573. Jonathan Cohen, Eric Boerwinkle, Thomas Mosley Jr, and Helen Hobbs. 2006. Sequence variations in pcsk9, low ldl, and protection against coronary heart disease. New England Journal of Medicine, 354(12):12641272. Devika, Subramaniyaswamy Vairavasundaram, Sakthi Jay Mahenthar, Vijayakumar Varadarajan, and Ketan Kotecha. 2021. deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data. IEEE Access, 9:165252 165261. Orion Dollar, Nisarg Joshi, David AC Beck, and Jim Pfaendtner. 2021. Attention-based generative models for de novo molecular design. Chemical Science, 12(24):83628372. Juan Manuel Domínguez, Ana Fuertes, Leyre Orozco, María del Monte-Millán, Elena Delgado, and Miguel Medina. 2012. Evidence for irreversible inhibition of glycogen synthase kinase-3β by tideglusib. Journal of Biological Chemistry, 287(2):893904. Jerome Eberhardt, Diogo Santos-Martins, Andreas Tillack, and Stefano Forli. 2021. Autodock vina 1.2. 0: New docking methods, expanded force field, and python bindings. Journal of chemical information and modeling, 61(8):38913898. Veronika Ganeeva, Kuzma Khrabrov, Artur Kadurin, Andrey Savchenko, and Elena Tutubalina. 2024a. Chemical language models have problems with chemistry: case study on molecule captioning task. In The Second Tiny Papers Track at ICLR 2024. Veronika Ganeeva, Andrey Sakhovskiy, Kuzma Khrabrov, Andrey Savchenko, Artur Kadurin, and Elena Tutubalina. 2024b. Lost in translation: Chemical language models and the misunderstanding of molecule structures. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 1299413013. Pierre Geurts, Damien Ernst, and Louis Wehenkel. 2006. Extremely randomized trees. Machine learning, 63:342. Rafael Gómez-Bombarelli, Jennifer Wei, David Duvenaud, José Miguel Hernández-Lobato, Benjamín Sánchez-Lengeling, Dennis Sheberla, Jorge AguileraIparraguirre, Timothy Hirzel, Ryan Adams, and Alán Aspuru-Guzik. 2018. Automatic chemical design using data-driven continuous representation of molecules. ACS central science, 4(2):268276. Shenghui Guan and Guanyu Wang. 2024. Drug discovery and development in the era of artificial intelligence: From machine learning to large language models. Artificial Intelligence Chemistry, 2(1):100070. Nina Gubina, Andrei Dmitrenko, Gleb Solovev, Lyubov Yamshchikova, Oleg Petrov, Ivan Lebedev, Nikita Serov, Grigorii Kirgizov, Nikolay Nikitin, and Vladimir Vinogradov. 2024. Hybrid generative ai for de novo design of co-crystals with enhanced tabletability. Advances in Neural Information Processing Systems, 37:8460684644. Gabriel Lima Guimaraes, Benjamin Sanchez-Lengeling, Carlos Outeiral, Pedro Luis Cunha Farias, and Alán Aspuru-Guzik. 2017. Objective-reinforced generative adversarial networks (organ) for sequence generation models. arXiv preprint arXiv:1705.10843. Suhail Haroon, CA Hafsath, and AS Jereesh. 2023. Generative pre-trained transformer (gpt) based model with relative attention for de novo drug design. Computational Biology and Chemistry, 106:107911. Yoshitaka Inoue, Tianci Song, and Tianfan Fu. 2024. Drugagent: Explainable drug repurposing agent with large language model-based reasoning. arXiv preprint arXiv:2408.13378. Zohaib Iqbal, Shaishav Dhage, Jamal Basheer Mohamad, Alaa Abdel-Razik, Rachelle Donn, Rayaz Malik, Jan Hoong Ho, Yifen Liu, Safwaan Adam, Basil Isa, and 1 others. 2019. Efficacy and safety of pcsk9 monoclonal antibodies. Expert opinion on drug safety, 18(12):11911201. Tamara Isermann, Christine Sers, Channing Der, and Bjoern Papke. 2024. Kras inhibitors: resistance drivers and combinatorial strategies. Trends in cancer. Shoichi Ishida, Tomohiro Sato, Teruki Honma, and Kei Terayama. 2024. Large language models open new way of ai-assisted molecule design for chemists. Kevin Maik Jablonka, Qianxiang Ai, Alexander AlFeghali, Shruti Badhwar, Joshua Bocarsly, Andres Bran, Stefan Bringuier, Catherine Brinson, Kamal Choudhary, Defne Circi, and 1 others. 2023. 14 examples of how llms can transform materials science and chemistry: reflection on large language model hackathon. Digital Discovery, 2(5):1233 1250. Jan Jensen. 2019. graph-based genetic algorithm and generative model/monte carlo tree search for the exploration of chemical space. Chemical science, 10(12):35673572. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: highly efficient gradient boosting decision tree. Advances in neural information processing systems, 30. Alan Kerstjens and Hans De Winter. 2022. Leadd: Lamarckian evolutionary algorithm for de novo drug design. Journal of Cheminformatics, 14(1):3. Dongsung Kim, Lorenz Herdeis, Dorothea Rudolph, Yulei Zhao, Jark Böttcher, Alberto Vides, Carlos Ayala-Santos, Yasin Pourfarjam, Antonio CuevasNavarro, Jenny Xue, and 1 others. 2023. Pan-kras inhibitor disables oncogenic signalling and tumour growth. Nature, 619(7968):160166. Hyunseung Kim, Jonggeol Na, and Won Bo Lee. 2021. Generative chemical transformer: neural machine learning of molecular geometric structures from chemical language via attention. Journal of chemical information and modeling, 61(12):58045814. Julia Krämer, Amit Bar-Or, Timothy Turner, and Heinz Wiendl. 2023. Bruton tyrosine kinase inhibitors for multiple sclerosis. Nature Reviews Neurology, 19(5):289304. Yanbin Kuang, Wenzheng Guo, Jing Ling, Dongliang Xu, Yueling Liao, Hui Zhao, Xiaohui Du, Han Wang, Mingxin Xu, Hongyong Song, and 1 others. 2019. Iron-dependent cdk1 activity promotes lung carcinogenesis via activation of the gp130/stat3 signaling pathway. Cell Death & Disease, 10(4):297. Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, and Andrey Savchenko. 2024. MedSyn: LLM-based synthetic medical text generation framework. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 215230. Springer. Matt Kusner, Brooks Paige, and José Miguel Hernández-Lobato. 2017. Grammar variational autoencoder. In International conference on machine learning, pages 19451954. PMLR. Seung-Hwan Kwon, Sangjune Kim, Yeong Park, Saebom Lee, Changdev Gorakshnath Gadhe, Bo Am Seo, Jong-Sung Park, Suyeon Jo, Yumin Oh, Sin Ho Kweon, and 1 others. 2021. novel, selective c-abl inhibitor, compound 5, prevents neurodegeneration in parkinsons disease. Journal of medicinal chemistry, 64(20):1509115110. Myeonghun Lee and Kyoungmin Min. 2022. Mgcvae: multi-objective inverse design via molecular graph conditional variational autoencoder. Journal of chemical information and modeling, 62(12):29432950. Jules Leguy, Thomas Cauchy, Marta Glavatskikh, Béatrice Duval, and Benoit Da Mota. 2020. Evomol: flexible and interpretable evolutionary algorithm for unbiased de novo molecular generation. Journal of cheminformatics, 12:119. Guo Li, Jiaxuan Li, Yujia Tian, Yunyang Zhao, Xiaoyang Pang, and Aixia Yan. 2024a. Machine learning-based classification models for noncovalent brutons tyrosine kinase inhibitors: Predictive ability and interpretability. Molecular Diversity, 28(4):24292447. Rui Li, Hao Tang, Jeremy Burns, Brian Hopkins, Carole Le Coz, Bo Zhang, Isabella Peixoto de Barcelos, Neil Romberg, Amy Goldstein, Brenda Banwell, and 1 others. 2022. Btk inhibition limits bcellt-cell interaction through modulation of b-cell metabolism: implications for multiple sclerosis therapy. Acta neuropathologica, 143(4):505521. Tianhao Li, Sandesh Shetty, Advaith Kamath, Ajay Jaiswal, Xiaoqian Jiang, Ying Ding, and Yejin Kim. 2024b. Cancergpt for few shot drug pair synergy prediction using large pretrained language models. NPJ Digital Medicine, 7(1):40. Christopher Lipinski. 2016. Rule of five in 2015 and beyond: Target and ligand structural limitations, ligand chemistry structure and drug discovery project decisions. Advanced drug delivery reviews, 101:34 41. Sizhe Liu, Yizhou Lu, Siyu Chen, Xiyang Hu, Jieyu Zhao, Tianfan Fu, and Yue Zhao. 2024a. Drugagent: Automating ai-aided drug discovery programming through llm multi-agent collaboration. arXiv preprint arXiv:2411.15692. Xianggen Liu, Yan Guo, Haoran Li, Jin Liu, Shudong Huang, Bowen Ke, and Jiancheng Lv. 2024b. DrugLLM: Open large language model for few-shot molecule generation. arXiv preprint arXiv:2405.06690. Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew White, and Philippe Schwaller. 2024. Augmenting large language models with chemistry tools. Nature Machine Intelligence, pages 111. Bruno Macedo, and Tiago Taveira Gomes. 2024. Medgan: optimized generative adversarial network with graph convolutional Inês Ribeiro Vaz, networks for novel molecule design. Scientific Reports, 14(1):1212. Openai OpenAI. 2022. Openai: Introducing chatgpt. URL https://openai. com/blog/chatgpt. Jiashun Mao, Jianmin Wang, Amir Zeb, Kwang-Hwi Cho, Haiyan Jin, Jongwan Kim, Onju Lee, Yunyun Wang, and Kyoung Tai No. 2023. Transformer-based molecular generative model for antiviral drug design. Journal of chemical information and modeling, 64(7):27332745. Carlos Eliel Maya Ramírez, Zeeshan Shokat, Muhammad Sufyan, Md Tabish Rehman, Mohamed AlAjmi, and Gulam Rather. 2024. Identification of novel scaffolds targeting sirt3 through molecular modeling techniques for the treatment of hepatocellular carcinoma. Journal of Biomolecular Structure and Dynamics, 42(19):1016510174. Marisa McGinley, Carolyn Goldschmidt, and Alexander Rae-Grant. 2021. Diagnosis and Jama, treatment of multiple sclerosis: review. 325(8):765779. Andrew McNaughton, Gautham Krishna Sankar Ramalaxmi, Agustin Kruel, Carter Knutson, Rohith Varikoti, and Neeraj Kumar. 2024. Cactus: Chemistry agent connecting tool usage to science. ACS Omega. Adrian Mirza, Nawaf Alampara, Sreekanth Kunchapu, Martiño Ríos-García, Benedict Emoekabu, Aswanth Krishnan, Tanya Gupta, Mara Schilling-Wilhelmi, Macjonathan Okereke, Anagha Aneesh, and 1 others. 2024. Are large language models superhuman chemists? arXiv preprint arXiv:2404.01475. Nikolay Nikitin, Pavel Vychuzhanin, Mikhail Sarafanov, Iana Polonskaia, Ilia Revin, Irina Barabanova, Gleb Maximov, Anna Kalyuzhnaya, and Alexander Boukhanovsky. 2022. Automated evolutionary approach for the design of composite machine learning pipelines. Future Generation Computer Systems, 127:109125. Zhangming Niu, Xianglu Xiao, Wenfan Wu, Qiwei Cai, Yinghui Jiang, Wangzhen Jin, Minhao Wang, Guojian Yang, Lingkang Kong, Xurui Jin, and 1 others. 2024. Pharmabench: Enhancing admet benchmarks with large language models. Scientific Data, 11(1):985. Toshiki Ochiai, Tensei Inukai, Manato Akiyama, Kairi Furui, Masahito Ohue, Nobuaki Matsumori, Shinsuke Inuki, Motonari Uesugi, Toshiaki Sunazuka, Kazuya Kikuchi, and 1 others. 2023. Variational autoencoder-based chemical latent space for large molecular structures with 3d complexity. Communications Chemistry, 6(1):249. Roman Odobesku, Karina Romanova, Sabina Mirzaeva, Oleg Zagorulko, Roman Sim, Rustem Khakimullin, Julia Razlivina, Andrei Dmitrenko, and Vladimir Vinogradov. nanominer: Multimodal information extraction for nanomaterials. In AI for Accelerated Materials Design-ICLR 2025. Chao Pang, Jianbo Qiao, Xiangxiang Zeng, Quan Zou, and Leyi Wei. 2023. Deep generative models in de novo drug molecule generation. Journal of Chemical Information and Modeling, 64(7):21742194. Nathaniel Park, Tiffany Callahan, James Hedrick, Tim Erdmann, and Sara Capponi. 2024. Leveraging chemistry foundation models to facilitate structure focused retrieval augmented generation in multi-agent workflows for catalyst and materials design. arXiv preprint arXiv:2408.11793. Liudmila Prokhorenkova, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, and Andrey Gulin. 2018. Catboost: unbiased boosting with categorical features. Advances in neural information processing systems, 31. Oleksii Prykhodko, Simon Viet Johansson, PanagiotisChristos Kotsias, Josep Arús-Pous, Esben Jannik Bjerrum, Ola Engkvist, and Hongming Chen. 2019. de novo molecular generation method using latent vector based generative adversarial network. Journal of Cheminformatics, 11:113. Evgeny Putin, Arip Asadulaev, Yan Ivanenkov, Vladimir Aladinskiy, Benjamin Sanchez-Lengeling, Alán Aspuru-Guzik, and Alex Zhavoronkov. 2018. Reinforced adversarial neural computer for de novo molecular design. Journal of chemical information and modeling, 58(6):11941204. Reck, DP Carbone, Garassino, and Barlesi. 2021. Targeting kras in non-small-cell lung cancer: recent progress and new approaches. Annals of Oncology, 32(9):11011110. Darius Saberi, Anastasia Geladaris, Sarah Dybowski, and Martin Weber. 2023. Brutons tyrosine kinase as promising therapeutic target for multiple sclerosis. Expert Opinion on Therapeutic Targets, 27(4-5):347359. Yu Shi, Weina Gao, Nikki Lytle, Peiwu Huang, Xiao Yuan, Amanda Dann, Maya Ridinger-Saison, Kathleen DelGiorno, Corina Antal, Gaoyang Liang, and 1 others. 2019. Targeting lif-mediated paracrine interaction for pancreatic cancer therapy and monitoring. Nature, 569(7754):131135. Michael Skarlinski, Nadolski Tyler, Braza James, Storni Remo, Caldas Mayk, Mitchener Ludovico, Hinks Michaela, White Andrew, and Rodriques Sam. 2025. FutureHouse Platform: Superintelligent AI Agents for Scientific Discovery. https://www. futurehouse.org/research-announcements/ launching-futurehouse-platform-ai-agents/. [Online; accessed 18-May-2025]. Michael Skarlinski, Sam Cox, Jon Laurent, James Braza, Michaela Hinks, Michael Hammerling, Manvitha Ponnapati, Samuel Rodriques, and Andrew White. 2024a. Language agents achieve superhuman synthesis of scientific knowledge. arXiv preprint arXiv:2409.13740. Michael D. Skarlinski, Sam Cox, Jon M. Laurent, James D. Braza, Michaela Hinks, Michael J. Hammerling, Manvitha Ponnapati, Samuel G. Rodriques, and Andrew D. White. 2024b. Language agents achieve superhuman synthesis of scientific knowledge. Preprint, arXiv:2409.13740. Lukas Stankeviˇcius and Mantas Lukoševiˇcius. 2024. Extracting sentence embeddings from pretrained transformer models. Applied Sciences, 14(19):8887. Isabella Stewart and Markus Buehler. 2024. Molecular analysis and design using generative artificial intelligence via multi-agent modeling. Molecular Systems Design & Engineering. Neil Stone, Jennifer Robinson, Alice Lichtenstein, Noel Bairey Merz, Conrad Blum, Robert Eckel, Anne Goldberg, David Gordon, Daniel Levy, Donald Lloyd-Jones, and 1 others. 2014. 2013 acc/aha guideline on the treatment of blood cholesterol to reduce atherosclerotic cardiovascular risk in adults: report of the american college of cardiology/american heart association task force on practice guidelines. Circulation, 129(25_suppl_2):S1S45. Naveen Suresh, Neelesh Chinnakonda Ashok Kumar, Srikumar Subramanian, and Gowri Srinivasa. 2022. Memory augmented recurrent neural networks for de-novo drug design. Plos one, 17(6):e0269461. Shidi Tang, Ji Ding, Xiangyu Zhu, Zheng Wang, Haitao Zhao, and Jiansheng Wu. 2024. Vina-gpu 2.1: towards further optimizing docking speed and precision of autodock vina and its derivatives. IEEE/ACM Transactions on Computational Biology and Bioinformatics. Morgan Thomas, Noel OBoyle, Andreas Bender, and Chris De Graaf. 2022. Augmented hillclimb increases reinforcement learning efficiency for language-based de novo molecule generation. Journal of cheminformatics, 14(1):68. Eduardo Tolosa, Alicia Garrido, Sonja Scholz, and Werner Poewe. 2021. Challenges in the diagnosis of parkinsons disease. The Lancet Neurology, 20(5):385397. Austin Tripp and José Miguel Hernández-Lobato. 2023. Genetic algorithms are strong baselines for molecule generation. arXiv preprint arXiv:2310.09267. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention arXiv preprint is all you need.(nips), 2017. arXiv:1706.03762, 10:S0140525X16001837. Jean-Philippe Vert. 2023. How will generative AI disrupt data science in drug discovery? Nature Biotechnology, 41(6):750751. Patrick Walters and Mark Namchuk. 2003. Designing screens: how to make your hits hit. Nature reviews Drug discovery, 2(4):259266. Eric Wang, Samuel Schmidgall, Paul Jaeger, Fan Zhang, Rory Pilgrim, Yossi Matias, Joelle Barral, David Fleet, and Shekoofeh Azizi. 2025. Txgemma: Efficient and agentic llms for therapeutics. arXiv preprint arXiv:2504.06196. Milton Werner and Warren Olanow. 2022. Parkinsons disease modification through abl kinase inhibition: an opportunity. Movement Disorders, 37(1):6 15. Soojung Yang, Doyeong Hwang, Seul Lee, Seongok Ryu, and Sung Ju Hwang. 2021. Hit and lead discovery with explorative rl and fragment-based molecule generation. Advances in Neural Information Processing Systems, 34:79247936. Xiufeng Yang, Tanuj Kr Aasawat, and Kazuki Yoshizoe. 2020. Practical massively parallel monte-carlo tree search applied to molecular design. arXiv preprint arXiv:2006.10504. Xiufeng Yang, Jinzhe Zhang, Kazuki Yoshizoe, Kei Terayama, and Koji Tsuda. 2017. Chemts: an efficient python library for de novo molecular generation. Science and technology of advanced materials, 18(1):972976. Gavin Ye. 2024. De novo drug design as gpt language modeling: large chemistry models with supervised and reinforcement learning. Journal of ComputerAided Molecular Design, 38(1):20. Naruki Yoshikawa, Kei Terayama, Masato Sumita, Teruki Homma, Kenta Oono, and Koji Tsuda. 2018. Population-based de novo molecule generation, usChemistry Letters, ing grammatical evolution. 47(11):14311434. Botao Yu, Frazier Baker, Ziqi Chen, Xia Ning, and Huan Sun. 2024a. Llasmol: Advancing large language models for chemistry with large-scale, comprehensive, high-quality instruction tuning dataset. arXiv preprint arXiv:2402.09391. Botao Yu, Frazier Baker, Ziru Chen, Garrett Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, and Huan Sun. 2024b. Tooling or not tooling? the impact of tools on language agents for chemistry problem solving. arXiv preprint arXiv:2411.07228. Hua Yu, Heehyoung Lee, Andreas Herrmann, Ralf Buettner, and Richard Jove. 2014. Revisiting stat3 signalling in cancer: new and unexpected biological functions. Nature reviews cancer, 14(11):736746. Maria Zavadskaya, Anastasia Orlova, Andrei Dmitrenko, and Vladimir Vinogradov. 2025. Integrating qsar modelling with reinforcement Journal of learning for syk inhibitor discovery. Cheminformatics, 17(1):52. Xiangxiang Zeng, Fei Wang, Yuan Luo, Seung-gu Kang, Jian Tang, Felice Lightstone, Evandro Fang, Wendy Cornell, Ruth Nussinov, and Feixiong Cheng. 2022. Deep generative molecular design reshapes drug discovery. Cell Reports Medicine, 3(12). Di Zhang, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, Weiran Huang, Xiangyu Yue, Dongzhan Zhou, and 1 others. 2024a. Chemllm: chemical large language model. arXiv preprint arXiv:2402.06852. Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and JiRong Wen. 2024b. survey on the memory mechanism of large language model based agents. arXiv preprint arXiv:2404.13501. Chengguang Zhao, Huameng Li, Huey-Jen Lin, Shulin Yang, Jiayuh Lin, and Guang Liang. 2016. Feedback activation of stat3 as cancer drug-resistance mechanism. Trends in pharmacological sciences, 37(1):4761. Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Hongshen Xu, Zichen Zhu, Su Zhu, Shuai Fan, Guodong Shen, and 1 others. 2024. Chemdfm: Dialogue foundation model for chemistry. arXiv preprint arXiv:2401.14818. Alex Zhavoronkov, Yan Ivanenkov, Alex Aliper, Mark Veselov, Vladimir Aladinskiy, Anastasiya Aladinskaya, Victor Terentiev, Daniil Polykovskiy, Maksim Kuznetsov, Arip Asadulaev, and 1 others. 2019. Deep learning enables rapid identification of potent ddr1 kinase inhibitors. Nature biotechnology, 37(9):10381040."
        },
        {
            "title": "A Appendix",
            "content": "A.1 Impact Statement and Potential Risks This paper presents comprehensive method for drug discovery based on large language models, various deep learning methods, and evolutionary optimization. Based on experimental results, this approach simplifies drug search by automatically using the best solution from the integrations. Thus, the proposed solution can reduce the time to search for candidate molecules that can potentially be drugs. In addition, MADD can be used by many users with different levels of expertise (Including in the field of AI) due to the possibility of interacting with the multi-agent system via chat. Additionally, our ability to utilize the systems research experience can accelerate future research by connecting the system to central database, which facilitates the development of an entire research system that accumulates its effectiveness over time. However, the widespread adoption of multiagent systems in drug discovery presents potential challenges. Firstly, automation of traditionally human-driven processes may contribute to job displacement. However, in our opinion, this problem should not be critical. MADD can help free up the time of highly skilled researchers for tasks that only humans can perform, while junior staff can take on the responsibility of selecting candidate molecules. As result, the efficiency of drug discovery will improve without the risk of job loss, provided that tasks are appropriately assigned. Secondly, one particularly concerning risk is the potential misuse of MADD to design harmful substances. This risk can also be mitigated at the generative tool level by comparing molecules with existing databases during generation and excluding unwanted ones. Additionally, multi-agent system allows for the integration of filtering methods for content returned to the user. For instance, ChatGPT (OpenAI, 2022) uses moderation tool 1 to filter out inappropriate content. The authors recognize these challenges and undertake to do everything possible to minimize potential risks of misuse when the framework is released. A.2 Declaration of AI assistance We utilized ChatGPT only for grammatical checking and LaTeX support of the content presented in 1https://platform.openai.com/docs/guides/moderation /overview this study. The authors have reviewed and edited all content. one-step tasks, which seems insufficient for many real-world research tasks."
        },
        {
            "title": "B Additional Related Work",
            "content": "B.1 LLM-based drug design Interest in using LLMs in chemistry is growing as they demonstrate potential in predictive analytics, molecular modeling, and developing new compounds. For instance, ChemDFM, conversational platform powered by LLMs, was proposed for working with chemical data (Zhao et al., 2024). Research by M. Bran A. et al. (M. Bran et al., 2024) showed that integrating LLMs with chemical tools improves molecular property predictions. Also, Ye G. (Ye, 2024) proposed novel approach for de novo drug design using LLMs, enabling the automation of new chemical compound generation. CancerGPT (Li et al., 2024b) model for predicting drug pair synergy using few-shot learning was introduced to accelerate the development of new therapies. Chemical LLM LlasMol (Yu et al., 2024a) was trained on the SMolInstruct dataset and can solve many chemical problems. Another recent example is X-Lora-Gemma (Stewart and Buehler, 2024), whose main task is molecular optimization. B.2 Chemical agent-based LLM pipelines Agent-based pipelines have been widely used in chemistry and pharmacology (M. Bran et al., 2024; Zhang et al., 2024b; McNaughton et al., 2024; Li et al., 2024b; Jablonka et al., 2023) since late 2023. These systems automate experiments, significantly reducing time and financial costs and enabling professionals to achieve their objectives more efficiently. One way to improve the results is to use multiagent system. Here are several multi-agent solutions that are mostly related to the proposed MADD. DrugAgent (Liu et al., 2024a) implements an LLM-based multi-agent pipeline for drug discovery. This solution does not generate molecules according to the given properties from scratch, but optimizes the proposed ones. ChemCrow (M. Bran et al., 2024) is focused on autonomous planning and executing chemical synthesis using robotics platform. This solution supports 18 applied chemical tools, which are no longer supported. Another example is chemical agent CACTUS (McNaughton et al., 2024), which can solve tasks such as molecular property prediction, similarity searching, and drug-likeness assessment. Still, it supports only One of the most recent solutions is Phoenix, an AI-based platform developed by FutureHouse (Skarlinski et al., 2024b) to accelerate chemistry and drug discovery research. It combines LLM agents, chemoinformatics tools, and molecular generators in an interactive environment. Users can define tasks in natural language, and the system performs multi-step reasoning to generate or optimize compounds, plan experiments, and predict ADMET properties. key strength of Phoenix is its support for both de novo design and multi-target optimization. The most relevant to MADD is ChemAgent (Yu et al., 2024b), which can generate new molecules and predict reaction results. It has 29 tools at its disposal - calculation tools, web search, access to chemical databases, and molecular generator. However, experiments show low validity generated by ChemAgent molecules (Figure 3). These studies highlight that LLMs can accelerate scientific progress in chemistry and related fields, unlocking new material and drug development opportunities. Nevertheless, none demonstrate successful automation of the whole drug discovery pipeline. Possible reasons are (1) the absence of readily accessible dataset with complete drug discovery pipeline for training and validating new models and approaches, and (2) the weakness of existing separated models and agent architectures for solving the whole task with high-quality level. Based on these conclusions, we propose our vision of stronger approach and valuable newly farmed dataset with state-of-the-art pharmaceutical research tasks and their solutions. B.3 Data-driven drug design methods Drug design is rapidly growing field combining chemistry and machine learning. Traditionally, discovering new molecules or selecting chemical structures to solve particular problem relies on existing experimental data and subjective research experience, which limits the number and variety of possible compounds that can be considered. Generative models allow efficient exploration of the molecular space, which has already fueled the explosive growth of molecular generative design. Recurrent neural networks (Suresh et al., 2022; Dollar et al., 2021), variational autoencoders (Gómez-Bombarelli et al., 2018; Lee and Min, 2022; Ochiai et al., 2023; Bhadwal et al., 2023), generative-adversarial networks (Guimaraes et al., 2017; Prykhodko et al., 2019; Pang et al., 2023; Macedo et al., 2024), evolutionary algorithms (Yoshikawa et al., 2018; Leguy et al., 2020; Kerstjens and De Winter, 2022; Jensen, 2019; Tripp and Hernández-Lobato, 2023), and hybrid models using reinforcement learning (RL) methods (Putin et al., 2018; Thomas et al., 2022; Zhavoronkov et al., 2019) have been successfully applied to solve various problems in chemistry. Also, there are approaches for generating molecules using Monte Carlo tree search (Yang et al., 2020, 2017). These methods perform well compared to recurrent neural networks and variational autoencoders, including Bayesian optimization (Kusner et al., 2017). Another advanced model for sequence generation is Transformer (Vaswani et al., 2017), which is based on the attention mechanism. For molecule generation tasks, this model has successfully shown high performance in several studies (Ang et al., 2024; Mao et al., 2023; Haroon et al., 2023). Researchers attribute this architectures high performance to its ability to handle long sequences, which applies to chemical structures as they are usually treated as sequence of atoms and bonds."
        },
        {
            "title": "C Additional Case Studies",
            "content": "C.1 Description of related experiments conducted outside the benchmark. To assess the generalizability of the MADD system to new use cases, we conducted series of experiments outside the main system framework using the Orchestrator agent. These experiments specifically focused on data preparation and the training of both generative and predictive models. This separate evaluation was necessary because the experiments conducted on the benchmark discussed in the main article did not require automated model training. The primary objective was to determine whether the systems accuracy would degrade upon the integration of additional tools for automated training into the Orchestrator agent. Our findings indicate that the introduction of tool capable of launching the sequential training predictive and generative models on user-prepared dataset does not compromise the systems accuracy. Consequently, these experiments confirm the potential for extending the MADD system to other disease-related use cases beyond the original seven on which it was tested. However, from technical perspective of multiagent system architecture, several challenges must be addressed to enable automatic expansion to new cases. These include implementing automated monitoring of model training for new case, analyzing the readiness of predictive models before initiating generative model training, and keeping the user informed about the training status for given case. The creation of training data necessitates the search, download, and processing of data into the format required by both the predictive and generative models. Addressing all these tasks requires an expanded set of tools and increases system complexity. These functionalities were implemented within the LLM-based tools AutoML-DL and DatasetBuilder (which in subsequent research will be utilized as standalone agents). Implementations of these agents already exist in our MADD code as separate agents for additional studies. This implementation, in turn, necessitated the use of more advanced LLMs and modifications to the multi-agent system schema. This ongoing research is being conducted on new system version and falls outside the scope of the present article. Despite the aforementioned complexities and the need for system optimization, MADD successfully handles all the described tasks. Optimization is primarily required to enhance user interaction and usability. Furthermore, the necessity for optimization is driven by the rapid advancement of AI and LLM technologies, which demands continuous system development and relevance analysis. We look forward to demonstrating our future developments in subsequent publications. C.2 Multi-agent system ablation study The simplest system for comparison is single-agent system (MADD-v1), which uses CoT-based reasoning with reflection enabled. two-agent variant MADD-v2A with Decomposer and Orchestrator allowed intermediate user-facing outputs but lacked final summarization and did not permit answer revision. Another two-agent system MADD-v2B assigned tool selection and summarization to the Orchestrator. The third variant MADD-v2C delegated decomposition and tool selection to unified Orchestrator-Decomposer, with separate Summarizer. The RAG-based three-agent system MADD-v3 incorporated Chemical RAG agent alongside Decomposer and Orchestrator, following CoT logic without revision. Unlike these, MADD integrates summarization and Figure 6: Tanimoto similarity (maximum values) for all generated molecules user interaction as distinct, modular steps, enabling more structured and complete workflow. The above-mentioned variations of the MADD system are shown in Figures 12 and 13. single system prompt was used throughout the experiments, except for agent-specific instructions. Prompts were updated depending on the responsibilities of the specific agent. All agents used LLM Llama-3.1-70b, as it was the one that showed the best result in past experiments. Explicit CoT Implementation: The prompt enforces sequential reasoning mirroring the multiagent process: Question Thought (decomposition) Action (tool selection and execution) Observation (tool output analysis) Final Answer (synthesis and tabular presentation) This CoT sequence ensures the agent: Decomposition: The \"Thought\" step breaks down the query, akin to the Decomposers role. Orchestration: JSON-blob tool calls replicate the Orchestrator. Summarization: The final out. The full prompt and agent logic are available in the repository: https://github.com/ ITMO-NSS-team/MADD/blob/main/multi_ agent_system/run_singleAgentSystem.py C.3 Comparisons with existing LLM solutions The aim was to evaluate the performance of these systems in handling our specific task across all our datasets. The answer was assumed correct if the molecule proposed by LLM passed through the GR1 filter. In contrast, for ChemAgent, the presence of generator tool call, the absence of unnecessary calls, and the summarization of the final answer were checked. ChemAgent settings: We evaluated the system ChemAgent on all datasets. The high computational cost of generating responses was major limitation. Specifically, using the GPT-4o model in ChemAgent requires multiple queries per example, greatly escalating the systems financial cost. To determine the correct selection of tools by the system, we categorized them into several groups. MoleculeGenerator was considered the appropriate tool since all the tasks in our benchmark included molecule generation. The inappropriate tools were HIVInhibitorPredictor and LogDPredictor, as their usage meant that the model misunderstood the prompt. All other tools were considered neutral, as they could be used to solve problems in the benchmark, but were not mandatory. Thus, we considered that the model correctly selected tools if it did not use the inappropriate ones and used the appropriate ones at least once. To determine the summarization quality, we checked whether the molecules generated with the generator agent were present in the final response to the user. The molecules in the answer had to be in SMILES format, and their number had to be greater than or equal to the number of tasks in the prompt. C.3.1 Phoenix We also evaluated the system Phoenix across representative set of our benchmark tasks. Phoenix offers powerful multi-agent architecture capable of solving complex chains of reasoning, from molecular generation to retrosynthetic analysis and cost estimation. The system dynamically selects agents for specific subtasks, enabling deep integration of tools such as structure generators, property predictors, and synthesis planners. However, this complexity may also be its weakness. The system failed to deliver final answer Table 5: Comparing MADD with ChemAgent, LlasMol, X-Lora-Gemma, and ChemDFM on datasets of different complexity. Dataset Dataset Dataset Metric Tool Selection Summarization Final Acc. (%) Tool Selection Summarization Final Acc. (%) Tool Selection Summarization Final Acc. (%) MADD ChemAgent LlasMol X-Lora-Gemma ChemDFM 86.9 100 86.9 86 98 84.3 83.7 95.3 79.8 - - 0.44 - - 0.12 - - 57.8 21.5 12.4 68.3 22.4 15.3 85.8 19.1 16.4 - - 5.31 - - 0.33 - - 0 - - 0.46 - - 0.24 - - 0 in multiple test cases, likely due to interruptions or breakdowns during the reasoning process. While intermediate outputs (e.g., molecules or partial plans) were often correct, Phoenix sometimes terminated without producing complete or actionable response. Despite these limitations, Phoenix has strong potential for real-world applications in automated drug discovery and chemistry workflows, provided further robustness improvements are implemented. Results. Final results were obtained for slightly more than half of the questions, with the rest failing due to system interruptions during multi-agent reasoning. The generated molecules were evaluated using our in-house filtering criteria. Out of 40 generated structures, only 6 passed the GR1 filter group, and just one Alzheimer-focused molecule satisfied the more stringent GR2 filters. Notably, many proposed molecules were identified as known compounds from the ChEMBL database, indicating the systems tendency to rely on existing chemical space. However, subset of generated structures appeared to be unique, showing no matches in either PubChem or ChEMBL, which suggests the potential of Phoenix to explore novel chemical scaffolds. C.3.2 TxGemma We also evaluated the TxGemma models (9B-chat and 27B-chat) on representative subset of our benchmark. TxGemma is family of open-source models developed by Google DeepMind, fine-tuned from the Gemma 2 foundation to support broad spectrum of therapeutic development tasks. These include classification (e.g., BBB permeability), regression (e.g., binding affinity prediction), and generation (e.g., retrosynthesis). The chat variants, which we evaluated, are instruction-tuned for conversational use and scientific reasoning, making them wellsuited for exploratory dialogues and hypothesisdriven research. Despite their strengths in structured therapeutic tasks and interactive reasoning, the TxGemma-chat models underperformed in our benchmarks. Specifically, the 9B and 27B-chat models failed to generate valid molecular structures that passed our GR1 or GR2 filters. This underperformance is likely rooted in the models training focus. While TxGemma excels in task-specific predictive settingsparticularly in retrosynthesis and toxicity classificationthe broader, unguided generation of novel molecular structures was not primary training objective. Consequently, the models struggled with generic SMILES generation tasks beyond narrow, supervised domains. Results. Across all evaluated prompts, neither TxGemma-9B-chat nor TxGemma-27B-chat produced structures that met filtering thresholds. These results suggest that, while TxGemma-chat holds promise as reasoning and explanation engine for therapeutic R&D, it currently lacks the generative robustness required for open-ended de novo molecule design. C.4 Dataset preparing studies C.4.1 Benchmark Preparation Pipeline The initial validation dataset, subsequently used to generate modified versions for experimental purposes, consists of 245 potential user queries containing mentions of target proteins, properties, and disease symptoms. The dataset was designed in the following steps: Initial query design. Thirty queries were created manually, representing cases that users with different levels of chemistry expertise could pose. Each query was labeled with corresponding disease/property name. Most of these queries did not explicitly specify the type of task, e.g., generation/properties calculation or request the invocation of specific function. Dataset expansion via few-shot learning. The dataset was expanded using few-shot learning techniques applied to several LLMs, including GPT-4o, o1-mini, Claude Sonnet 3.5, and Gemini 1.5 Pro. The LLMs were provided with few examples and instructions to generate similar but non-redundant examples. Instructions included explicit requests to generate some examples from the perspective of an experienced professional and beginner. Also, we excluded uniform queries from the dataset by analyzing the similarity of query embeddings using sentence transformers (Stankeviˇcius and Lukoševiˇcius, 2024; Devika et al., 2021). Upon completion, the dataset was expanded to total of 400 queries. Validation by chemistry experts. Chemistry experts reviewed the synthetically generated queries and selected the most plausible ones. This step yielded the final dataset of 245 queries. The resulting dataset is called Dataset S. It is the easiest because each query consists of one task. From the examples of this dataset, two subsequent datasets were collected using combinations of several tasks in single query. Medium difficulty Dataset is combined dataset containing both easy samples and samples of higher complexity. Each query can have from 1 to 3 tasks that require calling different functions. Finally, the most complex dataset is called Dataset L. All queries consist of minimum of 4 tasks and maximum of 5. C.4.2 Dataset diversity The presented datasets are pretty diverse. We checked their diversity by calculating the Cosine similarity for each pair of embeddings. Figure 8 shows the correlation matrix between dataset queries. C.4.3 Examples of queries from each dataset Sample from Dataset S: Generate molecules for highly efficient inhibition of Brutons tyrosine kinase by non-covalent binding that is highly selective for BMX simultaneously. Sample from Dataset M: Generate GSK-3β inhibitors with high docking score and low brain-blood barrier permeability. Generate inhibitors of KRAS protein with G12C mutation. The inhibitors should be selective and not bind with HRAS and NRAS proteins. Sample from Dataset L: Suggest several molecules with high docking affinity with KRAS G12C protein. Molecules should possess common drug-like properties, including low toxicity, high QED score, and high level of synthesizability. Generate highly potent non-covalent BTK tyrosine kinase inhibitors from the TEC family of tyrosine kinases that can potentially affect cells as therapeutic target for treating multiple sclerosis. Can you suggest molecules that inhibit Proprotein Convertase Subtilisin/Kexin Type 9 with enhanced bioavailability and the ability to cross the BBB? Generate new drug that enhances neurotransmitter balance, promotes neuroprotection, and reduces oxidative stress. These compounds should possess high bioavailability, cross the blood-brain barrier efficiently, and show minimal metabolic degradation. C.4.4 Dataset Preparation for Generative"
        },
        {
            "title": "Model Training",
            "content": "A dataset of 500,000 unique small molecules for each disease was assembled from the public ChEMBL database. To select these molecules, we chose those with low molecular weight. According to Lipinskis rule (Lipinski, 2016), to which drug molecule should ideally conform, the molecular mass of compound should not exceed 500 g/- mol. This was necessary because such compounds tend to have better penetration ability, increased bioavailability, and greater synthetic availability, making them more promising drug candidates. Structural and physicochemical descriptors were calculated for each molecule, representing compact quantitative description of the molecular properties. First, molecular docking simulations were performed for each molecule using AutoDock Vina GPU 2.1, from which the minimum binding energy value was calculated (Appendix D.4.2. This index reflects the degree of affinity of the molecule to Figure 7: The process of obtaining validation dataset for an experimental study. given protein target, which is essential for evaluating its potential as an inhibitor. binary label IC50 (inhibition efficiency) was generated by training machine learning models on open biological data from specialized databases such as ChEMBL and BindingDB to predict the molecules biological activity. Relevant protein targets were selected for each of the six diseases under consideration, and binary classification tasks were generated based on them to identify potentially active compounds. The calculation of the remaining descriptors was performed using the RDKit library and included the following metrics: QED (Quantitative Estimate of Drug-likeness) - comprehensive metric reflecting the druglikeness of molecule and taking into account multiple parameters such as molecular mass, number of hydrogen bond donors and acceptors, number of fragments, lipophilicity (logP), etc.; Synthetic Accessibility Score (SAS) - numerical assessment of the difficulty of synthesizing compound (the higher the value, the more laborious the synthesis); Toxicity and unwanted fragment filters including: PAINS (Pan-Assay INterference compoundS) - indicator of potentially false positive results in biological tests; Brenk, Glaxo, and SureChEMBL filters identify known structural fragments associated with toxicity, reactivity, and other undesirable effects. Thus, six datasets of approximately 500k molecules (totaling over 3M) were obtained for generative model training. C.5 Comparing LLM accuracy and costs The cheapest model with price of 0.01$ per 1000 tokens was llama3.1-70b-int4, showing the worst accuracy of 26.5%. The most expensive model priced at 6$ per 1000 tokens was o1-mini, while its accuracy was low (only 67.5%). The optimal solution was Llama3.1-70b: with the highest accuracy of 92.3%, the cost was 1.2$. That is why we chose this LLM for MADD pipelines. The price was taken from the resellers website, which provided the models with API. C.6 Properties prediction by manual pre-trained ML models experimental studies Settings: To be confident in the results of generating molecules of the whole system, it is necessary to verify the accuracy of the predictive models and select the best one. To select the best models for lgIC50 prediction, cross-validation was performed for CatBoost (Prokhorenkova et al., 2018), XGBoost (Chen and Guestrin, 2016), Random Forest (Breiman, 2001), Extra Trees (Geurts et al., 2006), and LightGBM (Ke et al., 2017) models. The best models for each task were selected from 5 candidates. Results: The best predictive model selection resulted in selecting the top 3 best models. For Dyslipidemia, Drug resistance, and Parkinsons disease, CatBoost performed best, achieving values of F1 scores of 0.82, 0.85, and 0.92, respectively. For Alzheimers disease and lung cancer, Extra Trees was the most effective model, achieving F1 scores of 0.83 and 0.84, respectively. Finally, the Random Forest model showed the best result for multiple sclerosis, with an F1 score equal to 0.92. These results are detailed in Table 6 from Appendix C.7. C.7 Additional AutoML tool results Using multi-agent systems capability to run automatic ML model training, we conducted model training experiment using MADD to predict IC50 values on the considered diseases and the SYK protein. MADD AutoML is based on the open-source framework F. The Morgan fingerprints (2048, radius=2) were used for data preprocessing, namely, translation of SMILES molecules into vector embedding. Our system autonomously selects optimized pipelines for each disease, leveraging ensemble strategies and hyperparameter tuning to outperform or closely match baseline models. Specifically, it employs stacking (stacked generalization) and bagging (bootstrap aggregation). Stacking improves predictions by combining multiple models through meta-model trained on their outputs, while bagging reduces variance by training models on different data subsets and aggregating their results. The results demonstrate MADDs flexibility in adapting pipelines to diverse datasets: Alzheimers disease: stacking ensemble of gradient-boosted models (CatBoost, LightGBM, XGBoost) with an L2-regularized linear meta-model achieved an accuracy of 0.963 and F1-score of 0.978, surpassing all individual baselines (e.g., Extra Trees: 0.823 F1). Multiple sclerosis: Weighted averaging of gradient boosts yielded competitive performance (0.889 accuracy, 0.921 F1), closely matching the best baseline (Random Forest: 0.887 accuracy). Parkinsons disease: Despite using similar as Alzheimers disease case stacking pipeline (accuracy: 0.872), CatBoost alone performed better (0.910 accuracy), suggesting simpler models may suffice for certain datasets. Dyslipidemia: Bootstrap-aggregated stacking with L2 regularization achieved 0.767 accuracy, while CatBoost (0.778 accuracy, 0.818 F1) remained the strongest standalone model. Drug resistance: single, hyperparameteroptimized Random Forest under MADD outperformed its vanilla counterpart (0.845 vs. 0.828 accuracy), highlighting the value of automated tuning. Lung cancer: The stacking pipeline (0.780 accuracy) underperformed versus Extra Trees (0.843 accuracy), indicating potential overcomplexity for this case. Thrombocytopenia (SYK): The system selected stacked generalization with L2regularized linear regression as the metalearner and base learners CatBoost Regressor, XGBoost Regressor, and LightGBM Regressor, achieved an MSE of 0.32 and R2 of 0.75 on the test set.. The specialized SYK-FBRL method slightly outperformed our approach (MSE: 0.27, R2: 0.78). The more detailed results for ML experiments are provided in Table 6. C.8 Training tool selection Additionally, we tested the tools ability to autonomously select appropriate training strategies when no pre-trained models were available upon user request. In this experiment, the orchestrator, in addition to his prompt, also received dictionary containing the names and descriptions of already trained generative models that could be used for inference. We conducted experiments on two cases, Alzheimers disease and thrombocytopenia. We prepared 28 queries for each disease to generate molecules to treat that disease. We conducted two experiments for each case. In the first one, we did not add the case from the dataset to the dictionary with trained models; in the second, we did. Thus, in the first case, the orchestrator had to call an agent to train new generative model and select optimal training parameters. In the second case, it had to call tool to generate molecules using parameters corresponding to the disease from the query. As result, having obtained metrics for each disease, we took an average of the two experiments. We obtained tool selection metric equal to 0.79 in the case of Alzheimers disease and 0.82 in the case of Thrombocytopenia. This shows that the system can determine the necessary tool depending on the query and choose between training new generative model and using an already trained one if it is available and presented in the trained models dictionary provided to the orchestrator. Analyzing the automatic selection of generative tools based on previous experience. comparison of the MADD framework and other LLM-based systems is performed on all Table 6: Comparison of Accuracy and F1 score for the considered machine learning models. Molecular representations used as features: Alzheimers disease case - MACCS fingerprints; multiple sclerosis - Morgan fingerprints (1024, radius=2); Parkinsons disease - RDKit descriptors and Avalon fingerprints; lung cancer - Morgan fingerprints (512, radius=2); dislipidemia - RDKit descriptors and Avalon fingerprints; drug resistance - RDKit descriptors and Avalon fingerprints. Case Alzheimers disease Model MADD Auto CatBoost Random Forest XGBoost Extra Trees LightGBM Mupltiple sclerosis MADD Auto CatBoost Random Forest XGBoost Extra Trees LightGBM Parkinsons disease MADD Auto"
        },
        {
            "title": "CatBoost\nRandom Forest\nXGBoost\nExtra Trees\nLightGBM\nMADD Auto\nCatBoost\nRandom Forest\nXGBoost\nExtra Trees\nLightGBM\nMADD Auto\nCatBoost\nRandom Forest\nXGBoost\nExtra Trees\nLightGBM\nMADD Auto\nCatBoost\nRandom Forest\nXGBoost\nExtra Trees\nLightGBM",
            "content": "Accuracy F1 score 0.963 0.810 0.822 0.803 0.823 0.810 0.889 0.865 0.887 0.876 0.886 0.885 0.872 0.910 0.890 0.910 0.890 0.900 0.767 0.778 0.775 0.725 0.750 0.725 0.845 0.838 0.828 0.823 0.837 0.832 0.780 0.822 0.838 0.827 0.843 0.811 0.978 0.810 0.829 0.803 0.829 0.820 0.921 0.905 0.920 0.912 0.919 0.918 0.856 0.920 0.900 0.910 0.900 0.910 0.694 0.818 0.813 0.772 0.782 0.775 0.896 0.848 0.836 0.826 0.844 0.835 0.770 0.822 0.835 0.826 0.842 0.809 queries of our dataset. In this case, MADD could use all available generative tools and select them based on the results of the generative models performance evaluation experiment. The Appendix E.5 presents an example of the instructions and the results that were passed. MADD selected suitable generative method to reduce the experimentation time using tools with already trained models. C.9 Generative model comparisons study Settings. We used the percentage of remaining target molecules after filtering by criterion groups as metric. It was decided to make five such filters; the higher the filter level, the stricter the filtering by properties. Each subsequent filter group includes all previous filter groups. This was done to understand better how accurately the generated molecules could match the requested properties to be drug candidate for the selected disease. detailed explanation of the choice of filter groups is presented in Appendix D.5. Results. The results of experiments with generative tools show that different models perform differently on different tasks. Non-LLM-based models show stable results, sometimes outperforming all other solutions. LLM-based solutions are generally able to generate molecules that are between 27.7% and 99.84% chemically valid, which is shown in Table 9. However, if it is necessary to create molecule that meets two or more properties, the results do not exceed 2.56 percent of the target molecules. Only ChemDFM showed relatively good results, generating up to 10.71% of target molecules passing the fifth filter group for Alzheimers disease. It is worth noting that this model is pre-trained, and it is difficult to verify how many new molecules were generated that were not in the training dataset. Among the generative methods that do not use LLM, the transformer implemented in MADD is the most stable solution, outperforming the other solutions for three diseases and giving satisfactory results in the other cases, as shown in Table 8. Other considered generative approaches may show much better results in different cases. For example, MTDD-EF generates up to 28% of target drugs corresponding to the fifth filter group for Multiple sclerosis disease. However, the resulting molecules are similar in Tanimoto similarity (Diversity) (Bajusz et al., 2015), and this high result was not reproduced in other diseases. C.9.1 Our developed generative models Our GAN implementation consists of 2 LSTM blocks with one bidirectional layer, input layer, and hidden layer of size 128. Inspired by the transformer-based conditional VAE (Kim et al., 2021), we implemented our transformer for targeted generation with property control. We trained this model with seven properties in the conditional block and vocabulary size of 126 to encode SMILES molecules. The number of transformer layers and heads in the encoder and decoder was also increased to 12. The architecture of our transformer is shown in Figure 10. In the context of our study, generating 10,000 molecules using the Transformer model took approximately 45 minutes on an NVIDIA RTX A6000 GPU, while the GAN completed the same task in just 1.88 seconds  (Table 7)  . On more commonly available NVIDIA GeForce RTX 2070, the generation times were 3.73 hours for the Transformer and 3.37 seconds for the GAN. However, combination of generative models is required to enable more comprehensive exploration of the target chemical space. C.10 Analysis of an evolutionary approach for hit molecule generation Testing MTDD-EF as tool for molecule generation allowed us to evaluate the potential of EO for drug-candidate design. Table 8 presents the performance indicators in solving the proposed cases. The low performance in non-brain disease cases (Drug resistance, Dyslipidemia, Lung cancer) was expected, as MTDD-EF is not adapted to solve cases based on diseases of this type. Otherwise, the evolutionary algorithm looks promising in the molecule generation task, as shown in the Alzheimers and Parkinsons cases. However, an interesting one is the case of Multiple Sclerosis, for which no molecules with satisfactory performance criteria were obtained in the generation result. This shows that EO is very sensitive to the initial approximation. This fact can be further confirmed by the substantial difference in molecular mass (as an indirect criterion of structural complexity) between experimentally validated molecules and those generated using MTDD-EF (Figure 11a for Alzheimers disease 16%, Figure 11b for Multiple sclerosis 35%). Thus, to use EO effectively, it is necessary to use methods other than those used in MTDD-EF to create an initial approximation for the initial population. C.11 Overall efficiency analysis is important It to note that we also exclude molecules that existed in the generative tools training dataset for MADD. For other solutions, it is impossible to calculate the novelty of the generated molecules because we do not have the data on which the solutions were trained. For example, ChemDFM has chemical data because it was Table 7: Comparison of GPU memory usage, training, and generation times. Model GPU memory (GB) Training time (hours) Generation time (ms/molecule) GAN Transformer 6.40 2.82 0.19 8.43 23.73 295. Table 8: Percentage of target molecules across filter groups obtained during the generation series by each model. Case Alzheimers disease Multiple sclerosis Parkinsons disease"
        },
        {
            "title": "Lung cancer",
            "content": "Model GAN Transformer RL MTDD-EF ChemTSv2 GAN Transformer RL MTDD-EF ChemTSv2 GAN Transformer RL MTDD-EF ChemTSv2 GAN Transformer RL MTDD-EF ChemTSv2 GAN Transformer RL MTDD-EF ChemTSv2 GAN Transformer RL MTDD-EF ChemTSv2 GR1, % GR2, % GR3, % GR4, % GR5, % Diversity 19.03 26.06 15.8 69.00 9.03 5.90 15.43 22.81 0.00 2.44 14.45 3.32 0.03 24.00 24.21 0.23 8.32 0.63 0.00 0.14 7.27 28.87 0.02 0.00 0.12 5.53 6.12 0.57 1.00 6.65 14.75 23.58 14.34 69.00 9.03 4.35 13.75 20.34 0.00 2.44 11.48 3.06 0.03 24.00 24.21 0.15 6.92 0.52 0.00 0.14 6.15 28.27 0.02 0.00 0.12 4.41 5.72 0.53 1.00 6.65 11.70 18.47 10.99 37.00 0.53 3.49 13.32 18.39 0.00 1.66 8.92 2.69 0.00 12.00 14.39 0.10 6.14 0.40 0.00 0.09 4.92 25.07 0.02 0.00 0.06 3.43 4.97 0.51 1.00 4.06 11.32 18.15 10.74 28.00 0.50 3.36 13.29 18.22 0.00 1.55 8.57 2.65 0.00 12.00 13.47 0.10 6.05 0.38 0.00 0.09 4.72 24.50 0.02 0.00 0.06 3.31 4.76 0.51 1.00 3.53 11.32 18.15 10.74 28.00 0.50 3.36 13.29 18.22 0.00 1.55 8.57 2.65 0.00 12.00 13.47 0.10 6.05 0.38 0.00 0.09 4.72 13.16 0.02 0.00 0.06 3.31 4.76 0.51 1.00 3. 0.37 0.24 0.21 0.18 0.12 0.39 0.25 0.11 0.14 0.44 0.36 0.24 0.17 0.16 0.44 0.39 0.77 0.13 0.11 0.43 0.34 0.21 0.05 0.06 0.44 0.39 0.8 0.09 0.11 0.43 explicitly trained for chemical problems, but it is difficult to say how novel the molecules it creates are. To assess the novelty of the molecules created, MADD was compared with the training dataset on which GAN and Transformer were trained. Thus, we counted the number of chemically valid molecules for MADD and how many potentially new ones our system could create. Of course, if we train models on larger dataset, it becomes more challenging to develop new ones. On the other hand, Transformers can become more efficient by training on larger dataset. Thus, the fact that it is possible to create new molecules with the desired properties emphasizes the efficiency of our proposed system. The novelty and validity of the molecules for each disease are described in Table 9. Alternatively, for other LLM-based approaches, we cannot the novelty of the molecules, and these solutions are doubtful in creating new molecules. test Table 9: Full table of Mean Docking score, novelty, validity, and percentage of target molecules across filter groups obtained during the generation series by each approach. * filtered Case Model MADD MADD Auto Llasmol X-LoRA Gemma ChemAgent ChemDFM MADD Llasmol X-LoRA Gemma ChemAgent ChemDFM MADD Llasmol X-LoRA Gemma ChemAgent ChemDFM MADD Llasmol X-LoRA Gemma ChemAgent ChemDFM MADD Llasmol X-LoRA Gemma ChemAgent ChemDFM MADD Llasmol X-LoRA Gemma ChemAgent ChemDFM MADD Auto SYK-FBRL Alzheimer Sclerosis"
        },
        {
            "title": "Lung\ncancer",
            "content": "Thrombocytopenia Novelty % 78.21 Validity % 87.47 Mean DS -7.46 GR1, % 20.30 GR2, % 17. GR3, % 13.72 GR4, % 13.40 GR5, % 13.40 73.47 89.5 -7. 15.99 14.43 13.14 12.34 12.34 - - - - 73.45 - 64.00 -5.36 4.54 43. -4.14 0.00 23.50 99.84 84.32 58.00 -6.42 -6.80 -9.24 -6.08 2.50 28.57 14.71 0.00 4. 0.00 0.00 17.86 12.81 0.00 4.54 0.00 0.00 10.71 11.73 0.00 0. 0.00 0.00 10.71 11.62 0.00 0.00 0.00 0.00 10.71 11.62 0.00 - 43.60 -5.81 5.12 - - 61.21 - 29.20 85.70 78.21 68.00 -6.50 -8.13 -6.04 -6. 1.04 11.11 5.93 0.00 - 45.50 -5.01 0.00 - - 67.17 - 27.70 94.60 63.21 69.00 -3.41 -6.03 -6.97 -3.89 0.00 2.50 3.06 0.00 - 42.80 -3. 0.00 2.56 0.52 5.56 4.86 0.00 0.00 0.00 2.50 2.53 0.00 0. 2.56 0.52 5.56 3.87 0.00 0.00 0.00 0.00 2.21 0.00 0.00 - - 71.21 - 31.00 94.70 73.21 60.12 -4.96 -6.08 -7.68 -3.97 0.00 2.78 12.05 0.00 0.00 2.78 11.48 0.00 0.00 0.00 10.00 0.00 - 44.80 -4.65 0.00 - - 60.12 - - - - 29.04 97.50 67.21 59.12 -5.75 -5.68 -6.32 -3.9 0.00 0.00 4.07 0.00 43.10 -4.73 0. 33.50 97.60 -6.54 -5.18 0.00 0.00 90.71 -8.02 1. 0.00 0.00 0.00 3.55 0.00 0.00 0.00 0.00 1.35 0. 0.00 0.00 2.97 0.00 0.00 0.00 0.00 1.32 2.56 0.52 5.56 3.74 0. 0.00 0.00 0.00 2.18 0.00 0.00 0.00 0.00 9.75 0.00 0.00 0.00 0.00 2.86 0. 0.00 0.00 0.00 1.32 2.56 0.52 0.00 3.74 0.00 0. 0.00 0.00 2.18 0.00 0.00 0.00 0.00 5.97 0.00 0.00 0.00 0.00 2.86 0.00 0. 0.00 0.00 1.32 100* -7.76 0.70 0. 0.26 0.25 0."
        },
        {
            "title": "D Supporting information",
            "content": "D.1 Examples of Queries: D.1.1 Manually Composed Queries by"
        },
        {
            "title": "Experts",
            "content": "Alzheimers disease: Generate GSK-3β inhibitors with high docking score and low brain-blood barrier permeability. Generate GSK-3β inhibitors with high activity. Lung cancer: Generate inhibitors of KRAS protein with G12C mutation. The inhibitors should be selective and not bind with HRAS and NRAS proteins. Suggest some small molecules that inhibit KRAS G12C - target responsible for non-small cell lung cancer. Sclerosis: Generate molecules for highly efficient inhibition of Brutons tyrosine kinase by non-covalent binding that is highly selective for BMX simultaneously. Generate high activity tyrosine-protein kinase BTK inhibitors. Parkinson: Can you suggest molecules that inhibit ABL tyrosine-protein kinase with an LD50 toxicity of 501 mg/kg or more and half-life of 4 hours? am writing to you with an important question. For my work, need to come up with 6 new molecules that would have an affinity to the tyrosine-protein kinase ABL. Can you suggest molecules that inhibit signal transducer and activator of transcription 3 (STAT3) with water solubility greater than 60 mg/mL and inhibitory ability to P450 CYP1A2? Generate me 2 molecules that could overcome chemotherapeutic resistance in cancer treatment, specifically targeting mechanisms such as increased drug efflux, enhanced DNA repair, or apoptosis evasion. It is important that these compounds avoid toxicity to healthy cells and minimize side effects like immunosuppression or gastrointestinal distress. D.1.2 Synthetic Queries Generated by LLMs Alzheimers disease: Generate structures with many aromatic rings to facilitate π-π stacking interactions with beta-amyloid aggregates. Generate compounds with flexible linkers to allow conformational adaptability in binding to amyloid-beta. Lung cancer: Develop potential drug candidates to inhibit KRAS G12C in non-small cell lung cancer, taking into account selectivity and avoiding cross-reactivity with other RAS proteins. Generate 4 tight-binding inhibitors for KRAS G12C, making sure they avoid HRAS and NRAS. Dyslipidemia: Sclerosis: Generate me 2 molecules that would help me with my blood lipid spectrum disorder, which is manifested by an increase in cholesterol, triglycerides, low and very low-density lipoproteins, and decrease in high-density lipoproteins, or alpha lipoproteins. It is important that medications do not produce side effects such as muscle pain and liver problems. Can you suggest molecules that inhibit Proprotein Convertase Subtilisin/Kexin Type 9 with enhanced bioavailability and the ability to cross the BBB? Formulate novel small-molecule drugs that disrupt abnormal immune signaling to slow the progression of multiple sclerosis. Develop immune-modulating agents to dampen the overactive immune response in multiple sclerosis patients selectively. Parkinson: Synthesize novel tyrosine hydroxylase activator with cellular specificity. Design BBB-permeable antioxidant with mitochondrial tropism. Drug Resistance: Dyslipidemia: Create compounds with dual inhibition of CETP and HMG-CoA reductase to enhance HDL cholesterol levels. Generate ligands that selectively activate the AMPK pathway to promote fatty acid oxidation. Drug Resistance: Generate potential anti-resistance agents targeting the Ras-Raf-MEK-ERK signaling pathway. Design one unique molecular entity that specifically targets the primary mechanisms of drug resistance in malignant cells. This compound should exhibit high binding affinity and selectivity towards the resistance pathways prevalent in various cancer types. D.2 More detailed discussion on LLM-based solutions Before comparing MADD with other solutions, we searched for similar pipelines. However, not all of them could be directly compared due to significant differences in pipeline logic, discontinuation of tools used in the solutions, or lack of available code accompanying the paper. ChemCrow (Bran et al., 2023). We could not compare ChemCrow with our approach because the tools integrated into ChemCrow are no longer supported. Therefore, it is impossible to show its effectiveness with our dataset. This information can be confirmed in the official ChemCrow repository on GitHub (https://github.com/ ur-whitelab/chemcrow-public). The visualization of the agent architecture is shown in Figure 15. DrugLLM (Liu et al., 2024b). LLM solves the problems of generation and optimization of pharmacological molecules (based on two submitted molecules). It would be interesting to compare it with it, but the papers authors did not publish the model weights. DrugAgent: Automating AI-aided Drug Discovery Programming through LLM (Liu et al., 2024a). DrugAgent addresses three key challenges in drug development: predicting ADMET properties, predicting drug-target interactions (DTIs), and molecular optimization. It focuses on small-molecule drugs, which account for more than 90% of approved drugs. This solution was hard to match, as it does not generate molecules from scratch according to the given properties. It optimizes the proposed one because the authors have not made the code freely available. DrugAgent: Explainable Drug Repurposing Agent with Large Language Model-Based Reasoning (Inoue et al., 2024). There is no molecule generation here; instead, only chemical databases are searched. The proposed predictive tools cannot identify the targeting molecule requested in our dataset examples. Therefore, no comparison was performed. Large Language Models Open New Way of AI-Assisted Molecule Design for Chemists (Ishida et al., 2024). This agent system has only one scenario: user data preparation and model refinement using the AutoML block, running generative model. The systems logic is very different from MADDs to make comparison. Leveraging Chemistry Foundation Models to Facilitate Structure-Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design (Park et al., 2024). The system can optimize users molecule by blog radar searching for similar embedding molecule in database and updating the original molecule to reflect the found one. Unfortunately, the authors did not publish the code. The visualization of the agent architecture is shown in Figure 14. D.3 More detailed description of the tools D.4 Properties prediction algorithms IC50 D.4.1 IC50 is the concentration of substance required to inhibit biological process by 50%. Data from ChEMBL and BindingDB were used to create machine-learning models for predicting the efficacy of inhibitors of GSK-3β, BTK, and ABL2. In the case of BTK inhibitors, the data were supplemented from recent paper (Li et al., 2024a) that also utilizes ML for this task. The original data set was presented as molecules in SMILES format and IC50 values (nmol/L). The necessary data pre-processing was performed in each case, including data normalization and duplicate removal. The IC50 prediction task was formulated as binary classification. The molecules in the data set were divided into two classes by the median of the lgIC50 distribution. Thus, molecules with lgIC50 less than the median were defined as active and all others as inactive. The structures of the molecules were represented in various ways, particularly Morgan fingerprints, Avalon, and RDKit descriptors. D.4.2 Docking score We calculated docking scores for the diseasespecific target proteins using AutoDock Vina (Eberhardt et al., 2021) and QuickVina GPU 2.1 (Tang et al., 2024) frameworks. The latter allowed us to significantly reduce the time required for docking score calculations, averaging just 0.14 seconds compared to 5 seconds with AutoDock Vina. As result, the total time needed to calculate molecular docking scores for our dataset dropped from 1667 hours to 19 hours. D."
        },
        {
            "title": "Justification of the choice of filter groups",
            "content": "The filtering groups have the following structure: Group 1 (GR1): Docking score -7 and IC50 = 1 Group 2 (GR2): SA score 3 Group 3 (GR3): Brenk = 0 Group 4 (GR4): SureChEMBL = 0, Glaxo = 0, and PAINS = 0 Group 5 (GR5): QED > 0.6 Group 1 (GR1): This is the main group of filters that considers the biological activity of the generated molecules, the properties of which are proposed to be used as primary focus. Group 2 (GR2): Here, filtering by the possibility of synthesizing substances (SA) to the filters in the first group. This level of filtering additionally shows how many of the generated molecules can potentially be synthesized. Group 3 (GR3): The Brenk filter removes molecules that contain substructures with undesirable pharmacokinetics or toxicity. Group 4 (GR4): SureChEMBL is publicly available resource containing compounds extracted from patent documents. Glaxo filters are designed to exclude unstable and other problematic compound classes. Pan-assay interference compounds (PAINS) are chemical compounds that often give false positive results in high-throughput screens. PAINS react non-specifically with numerous biological targets, often leading to side effects. Group 5 (GR5): The most stringent group in terms of filtering includes restrictions on the QED property. Thus, when requiring the inclusion of an assessment of molecules by drug similarity, it is necessary to focus on the fifth group. D.6 Analyzed disease cases D.6.1 Alzheimers disease Currently, there are no medications that entirely prevent or halt Alzheimers disease (AD). Existing drugs only reduce symptoms. Tau proteins play role in stabilizing microtubules, which maintain the healthy state of neurons (Buerger et al., 2006). In healthy brain, tau proteins undergo phosphorylation and dephosphorylation, processes regulated by various kinases. Glycogen synthase kinase-3 (GSK-3β) is serine/threonine kinase that plays key role in cellular metabolism and signal transduction. It is associated with various diseases, including AD, by promoting tau protein hyperphosphorylation, significant component of neurofibrillary tangles, one of the hallmarks of AD. One of the inhibitors of this kinase, tideglusib, has completed phase and II clinical trials, during which it was found that cognitive function in patients improved slightly compared to placebo (insufficient efficacy), and gastrointestinal side effects (toxicity) were observed (Domínguez et al., 2012). Thus, developing novel GSK-3β inhibitors with enhanced properties is of great importance. D.6.2 Multiple sclerosis Multiple sclerosis (MS) is chronic autoimmune disorder affecting the central nervous system, characterized by inflammation, demyelination, gliosis, and neuroaxonal degeneration (McGinley et al., 2021). While it is traditionally thought that MS is primarily mediated by T-cells, B-cells and almost all types of innate immune cells appear to play significant role in both the initiation and propagation of the disease. Peripheral immune cells that cross the blood-brain barrier (BBB) induce relapses and the formation of focal demyelinating plaques (Cencioni et al., 2021). Brutons tyrosine kinase (BTK) is protein that plays critical role in the development and function of immune cells. The use of BTK inhibitors for treating MS is promising area of research, as these drugs have been shown to reduce B-cell activity and decrease inflammation in the brain and spinal cord (Krämer et al., 2023). By targeting BTK, these drugs may slow or halt the progression of MS, improve symptoms, and enhance the quality of life of patients (Li et al., 2022). Currently, at least six BTK inhibitors (BIIB091, Evobrutinib, Fenebrutinib, Orelabrutinib, Remibrutinib, Tolebrutinib) are in phase II-III clinical trials. Despite promising results, there are still areas for improvement in BTK inhibitors, such as binding mechanism (non-covalent inhibitors are less potent and require higher doses, but they offer increased selectivity and lower propensity for resistance) and blood-brain barrier permeability (Saberi et al., 2023). This case aims to generate noncovalent BTK inhibitors with improved IC50 values and enhanced BBB permeability. D.6.3 Parkinsons disease Parkinsons disease is progressive neurodegenerative disorder, which is characterized by the loss of dopaminergic neurons (Tolosa et al., 2021). The primary causes and mechanisms of development include mitochondrial dysfunction, oxidative stress, genetic mutations, protein manifolding and aggregation, and disruptions in cellular clearance processes. These factors contribute to neuronal degeneration and make them key targets for therapeutic approaches. Two primary targets are being investigated for treating Parkinsons disease: tyrosineprotein kinase ABL and catecholamines. Inhibition of ABL is considered promising approach to slowing neurodegenerative processes (Werner and Olanow, 2022). This protein kinase regulates cellular metabolism, and its hyperactivation is associated with increased oxidative stress and the accumulation of damaged proteins, which contribute to neuronal death (Kwon et al., 2021). This case study focuses on generating new ABL inhibitors with improved properties. D.6.4 Drug resistance STAT3 (Signal Transducer and Activator of Transcription 3) is pivotal regulator in cancer biology, associated with cell proliferation, survival, and immune evasion, making it an attractive pharmaceutical target (Yu et al., 2014). Aberrant STAT3 signaling, driven by overexpression or activation through factors like LIF, CDK1/9, and miRNAs, is implicated in various cancers, with emerging studies uncovering additional mechanisms and tumor types linked to its dysregulation (Shi et al., 2019; Kuang et al., 2019). While several STAT3 inhibitors are in clinical or preclinical development, challenges such as toxicity, adverse reactions, and limited selectivity persist, constraining their therapeutic potential (Beebe et al., 2018). Addressing these issues requires discovering highly selective agents that spare healthy cells and identifying predictive biomarkers to stratify responsive patients (Zhao et al., 2016). The promising strategy of combining STAT3 inhibitors with RTK-targeting therapies could further mitigate drug resistance. Continued exploration of STAT3s biological role and crosstalk with other signaling pathways is expected to drive innovations in targeted cancer treatments. D.6.5 Dyslipidemia Dyslipidemia, major contributor to atherosclerotic cardiovascular disease (ASCVD), has driven the search for innovative therapeutic targets to achieve effective lipid regulation (Stone et al., 2014). Among the most promising approaches are ATP citrate lyase (ACL) inhibitors and proprotein convertase subtilisin/kexin type 9 (PCSK9) inhibitors (Berkhout et al., 1990; Ballantyne et al., 2016; Cohen et al., 2006). Existing ACL inhibitors, such as bempedoic acid, have demonstrated efficacy in LDL cholesterol (LDL-C) reduction, yet their reliance on overlapping mechanisms with statins can limit their additive effect (Bilen and Ballantyne, 2016). Developing new ligands with unique binding properties may increase efficacy, reduce side effects, and improve compatibility with other lipid-lowering drugs. Similarly, monoclonal antibodies against PCSK9, including everocumab and alirocumab, have demonstrated significant clinical success but have problems with these drugs cost-effectiveness and long-term safety. (Iqbal et al., 2019). These novel ligands could provide more accessible, durable, and convenient treatment options, enabling broader application across diverse patient populations and addressing unmet needs in dyslipidemia management. D.6.6 Lung cancer KRAS is protein that helps control cell growth by acting like an on/off switch. When KRAS has specific mutations, it gets stuck in the on position, causing uncontrolled cell growth without external signals (Isermann et al., 2024). These mutations are D.8.2 Formulas for calculating the accuracy per query as whole Final Accuracy (FA, %) was measured at several steps. It was calculated separately after tool selection and separately for summarization. Then, the probabilities were multiplied, and the final accuracy was obtained. TS = Number of Correct Queries Total Number of Queries SSA = Correct Responses Total Responses Final Accuracy = TS SSA(%) Here, Correct Response refers to response in which no molecules or property values are lost, while Correct Query refers to case in which the tool was defined correctly. D.9 Schemes of the considered agent architectures visualization of the 2-agent and 3-agent systems is shown in Figure 12 and Figure 13. widespread in non-small cell lung cancer, which makes up over 80% of all lung cancer cases (Reck et al., 2021). New drugs, like KRAS G12C inhibitors (such as sotorasib and adagrasib), have shown promise. Still, they have some drawbacks, including working only for some patients, causing unintended side effects, and leading to resistance over time (Kim et al., 2023). This case study focuses on developing better KRAS inhibitors with improved effectiveness. D.7 Additional results analysis of generated molecules D.7.1 Detailed evaluation: Alzheimers disease In addition to evaluating individual molecular properties, we comprehensively analyzed the drug candidates generated through our benchmark. Due to the limited volume, we present detailed validation results for Alzheimers disease cases only. 16,082 novel GSK-3β inhibitors were generated using the transformer model. To validate generated molecules with already known compounds, we compared novel inhibitors with active inhibitors from the ChEMBL dataset, which was used to create the IC50 prediction model (see Figure 5). The average SA Score of the generated molecules is lower than that of experimentally validated compounds, suggesting easier laboratory synthesis methods. Moreover, the average QED score of generated molecules increased 11.8%, which indicated enhanced pharmacological properties. Lower toxicity can also be reported since all the generated molecules have passed the Brenk filter. At the same time, the Tanimoto similarity of 0.43 between novel and ChEMBL molecules leads to the conclusion that, along with improved properties, the obtained compounds make up different chemical space, which can potentially result in unconventional and effective solutions for this case (Ganeeva et al., 2024a,b). D.8 Formulas for calculating agent pipeline metrics: D.8.1 Formula for calculating the"
        },
        {
            "title": "Orchestrator accuracy",
            "content": "OA ="
        },
        {
            "title": "Number of Correct Tools\nNumber of Tools",
            "content": "(%) D.10 MADD failure cases examples inhibit the KRAS G12C mutation. As discussed in the main body of the paper, our experiments demonstrate that the system achieves an accuracy of 79.8% on complex queries. This result significantly outperforms competing systems (e.g., ChemAgent, which attains maximum accuracy of 16.4%). In Sections 4.24.6, we outline the key criteria explaining why other LLM-based approaches and alternative multi-agent systems are prone to higher error rates. However, researchers interested in applying our methodology may require more detailed analysis of the limitations inherent to MADD-like systems, which can lead to erroneous outcomes. The generative model may occasionally produce molecules unsuitable for target properties, as the probability of generating hit molecules is not absolute. This probability was quantified as percentage across filter groups GR1GR5, reaching 18.3% for our custom-developed models integrated into MADD. However, this issue is mitigated by incorporating validation methods within the multi-agent system, including iterative resampling of generative tools until user-specified criteria are met. To ensure transparent evaluation of the systems baseline performance, all experiments were conducted without this validation function. Generated molecules may exhibit low synthetic feasibility despite rigorous validation for chemical validity, drug-likeness, and target protein activity. Nevertheless, such occurrences are statistically rare, and recent studies (e.g., [Atz, Kenneth, et al. Nature Communications 15.1 (2024): 3408]) demonstrate that computational filtering methods can reliably prioritize synthetically tractable candidates for laboratory synthesis. Most errors in the agent system occur at the step of decomposing the input query into tasks, that is, during the invocation of the Decomposer agent. But there are also errors when selecting the right tool in the Orchestrator agent. Example 1: Initial query from dataset: Generate small molecules that specifically inhibit the KRAS G12C mutation. Ensure they do not interact with HRAS and NRAS proteins. Formulate novel small-molecule drugs that disrupt abnormal immune signaling to slow the progression of multiple sclerosis. Decomposer identifies the following tasks: Generate small molecules that specifically Ensure they do not interact with HRAS and NRAS proteins. Formulate novel small-molecule drugs that disrupt abnormal immune signaling to slow the progression of multiple sclerosis. True tasks: Generate small molecules that specifically inhibit the KRAS G12C mutation. Ensure they do not interact with HRAS and NRAS proteins. Formulate novel small-molecule drugs that disrupt abnormal immune signaling to slow the progression of multiple sclerosis. Thus, the Decomposer creates 1 invalid task, which will be further processed by the Orchestrator agent, and will make an extra call of tool. Example 2: Initial query from dataset: Generate ligands that selectively inhibit the FTO enzyme to influence energy balance and lipid levels. Decomposer correctly selects the following task: Generate ligands that selectively inhibit the FTO enzyme to influence energy balance and lipid levels Then the task goes to the Orchestrator agent, and it makes mistake by choosing model for generating drug molecule for the treatment of Drug Resistance, instead of treating Dyslipidemia. Decomposer errors are less critical, as users will ultimately receive correct answersalbeit with one additional response to nonexistent query. In contrast, Orchestrator errors are significantly more critical. However, we can assure you that the correct selection rate is high, making such errors rare. To address your request about reducing agent errors impact on pipeline quality, we implemented feature using LLM-driven answer reflection. This can mitigate errors, even for complex questions. Notably, queries from Datasets and are inherently more complex, whereas our system handles simpler queries from Dataset with far greater ease. As shown in Table 5, pipeline performance declines with increasing query complexity: Final Accuracy is 86.9% for Dataset but drops to 79.8% for Dataset L. Agents prompts and examples of multi-agent system workflow Notably, no existing LLM-based system achieves absolute reliability. For instance, our analysis of the Phoenix model (Future House) revealed critical vulnerabilities: SMILES Processing Failure: When designing an ACC2 inhibitor, the system initiates correct reasoning but generates an invalid SMILES string containing two disconnected molecules. Despite the \"No modifications found\" error, it repeats the request without correction. Invalid Structure Generation: string modified SMILES (C1CCC2(CC1)CCCC2=OCCN3C=NC=CC3=O) passes basic checks but contains trivalent oxygen (RDKit valence error). This highlights how insufficient validation can yield formally \"correct\" but chemically impossible outputsa key limitation of multi-agent architectures (see Appendix C2.1-C2.2 for edge-case analyses of competing systems). The described edge cases demonstrate that even advanced Multi-Agent Cognitive (MAC) systems, such as MADD, may occasionally misinterpret user queries. However, MADD exhibits significantly higher reliability than alternatives, with pipeline errors being sporadic. Extended error case studies will be provided in the Appendix of the final article to facilitate deeper technical understanding of MADD-like systems. We would like to draw the reviewers attention to the fact that agentic solutions is rapidly evolving field. To our knowledge, MADD is the first of its kind multi-agent solution that effectively addresses the problem of hit molecule identification in fully automated way, as multiple case studies in our paper show. It is not free of practical restrictions at this moment, but we are actively working to address them. We intend to have released several major updates by the paper decision date, such as dataset collection feature, logging exports, improved UI, and others. Therefore, we would like to ask the reviewer to consider increasing the score to support our ambitious effort and help promote the work of our team. E.1 Results of system workflow. An example of user dialogue with the MADD is shown in Figure 17. Note that the response is structured and divided into paragraphs depending on the number of requests in one message. E.2 Examples of prompts extracts for the main agents in the system. The Orchestrator agent is the main agent that calls functions corresponding to other agents and tools. Our system receives two dictionaries stored in JSON format. The first dictionary contains information about available functions, e.g., for calling existing generative models or training new generative models. The second dictionary contains information about generative models that have checkpoints and are currently available for inference. The prompt for the orchestrator, therefore, consists of several parts. First, the agent receives basic instructions on function calling: You are orchestrator with tool calling capabilities. When you are using tools, respond in the format {\"name\": function name, \"parameters\": dictionary of function arguments}... The agent then receives dictionary containing the available tools with instructions for each and descriptions of their arguments. Dictionary with the description of one of the tools: name: gen_mols, description: Generate molecules by generthe ative models. Only use this function if user asks to generate molecules for cases with already available generative models that can be found in special dictionary AVAILthe user ABLE_TRAINED_GEN_MODELS. If wants to generate molecules for another case you should train new model., arguments: name: case, type: str, description: Name of the case same as in AVAILABLE_TRAINED_GEN_MODELS dictionary, for example Cnsr - generation of molecules for the treatment of lung cancer. name: num, type: int, description: Number of molecules for generation. name: model, type: str, for generation, can be: description: Model CVAE, LSTM, RL, GraphGA, each model can be used depending on the case, default model CVAE. Another example of dictionary with tool description: name: train_gen_models, description: Train generative model with custom dataset (use if the user requests generation for case that is not presented in the current generative models dictionary AVAILABLE_TRAINED_GEN_MODELS), arguments: name: model, type: str, description: Model for finetuning for specific case. RL, CVAE, LSTM, GraphGA. Available: Default model CVAE, name: epoch, type: int, description: Number of train epochs. Default value 100, name: case_name, type: str, description: The name of the disease for which the model will be trained (in the future, the user will ask for inference using this name). Default to Short word for users prompt, After all tools have been defined, the orchestrator receives dictionary that contains information about all trained and available generative models for inference. This dictionary is automatically updated when generative model training is used. Example of dictionary for the case of trained model for Alzheimers disease: name: Alzhmr, description: Generation of drug molecules for the treatment of Alzheimers disease. GSK-3beta inhibitors with high activity. These molecules can bind to GSK-3beta protein, molecules has low brain-blood barrier permeability.\" The agent is then given more general instructions on interacting with the user and prioritizing calling different agents and tools. The Orchestrator then receives the following examples of requests and expected responses: Query from user: What can you do? You: parameters: {msg: What can you do?}} {name: make_answer_chat_model, Query from user: Generate highly potent non-covalent BTK tyrosine kinase inhibitors from the TEC family of tyrosine kinases that have the potential to affect cells as therapeutic target for the treatment of multiple sclerosis. # If you have trained generative model for this case and you recognize from description that you have this generative model in AVAILABLE_TRAINED_GEN_MODELS You: {name: gen_mols, parameters: {case: Sclrerosis, num: 1}} Query from user: Suggest several molecules that have high docking affinity with KRAS G12C protein. # If you dont have trained generative model for this case and you do not see it in AVAILABLE_TRAINED_GEN_MODELS You: {name: train_gen_models, parameters: {model: CVAE, epoch: 100, case_name: Cancer}} Full prompts can be found in the reposi- (https://github.com/ITMO-NSS-team/ tory MADD-CoScientist/blob/main/MADD/mas/ prompts/prompts.py). E.3 Examples of Agents decision. System Logs. logs can be Full //github.com/ITMO-NSS-team/MADD/blob/ main/examples/logs_example.txt) found at link (https: For clarity, all steps are separated by the separator: new step Lets examine step by step. Initially, the state contains only input data: input: Generate molecule of GSK-3beta inhibitors with high docking score After calling the Decomposer agent, the Orchestrator is called with task: Input: Generate GSK-3β inhibitors with high docking score and low blood-brain barrier permeability. Generate inhibitors of KRAS protein with G12C mutation. The inhibitors should be selective, meaning they should not bind with HRAS and NRAS proteins. plan: [Generate molecule of GSK-3beta inhibitors with high docking score] The Orchestrator select tool for generation: TOOL: gen mols alzheimer, num: 1 Molecule generation results: 1 2 3 5 6 7 8 { Smiles : { 0 : OC12C3C =C( Br ) C4 = NCC5 ( CN6CC65 ) C4N1CC2CC3 , 1 : COC1 ( OC ) C2C3C4CCN ( C#N) C3C41c1nncn12 } , Brenk : {...} , QED : {...} , Synthetic Accessibility : {...} , LogP : {...} , Polar Surface Area : {...} , - bond Donors : {...} , - bond Acceptors : {...} , Rotatable Bonds : {...} , Aromatic Rings : {...} , Glaxo : {...} , SureChEMBL : {...} , PAINS : {...} , Validity : {...} , Duplicates : {...} , docking_score : {...} , IC50 : {...}} FINAL ANSWER: Generated Molecules for GSK3beta Inhibitors with High Docking Score Molecule 1: SMILES: OC12C3C=C(Br)C4=NCC5(CN6CC65)C4N1CC2CC3 Docking Score: -6.36 Molecule 2: SMILES: COC1(OC)C2C3C4CCN(C#N)C3C41c1nncn12 Docking Score: -6. E.4 Examples of Agent systems/LLMs answers E.4.1 MADD answers Examples of the dialogue with MADD are shown in Figures 17-18. Decomposer with inhibitors Response: {\"steps\": [[\"Generate GSK-3β high docking score and low blood-brain permeability.\", barrier KRAS of inhibitors \"Generate protein with G12C mutation. The inhibitors should be selective, meaning bind with HRAS and NRAS proteins\"]]} should they not DataGathering Input: Execute the following task: Download data from ChEMBL for GSK with IC50 values using the available tools. Response: entries MADD/ds/molecules_GSK.csv\" \"Found GSK. for Saved 653 to E.4.2 ChemAgent answers Question 1: Can you suggest molecules that inhibit ABL tyrosine-protein kinase with an LD50 toxicity of 501 mg/kg or more and half-life of 4 hours? Response 1: Dasatinib is suggested as an ABL tyrosine-protein kinase inhibitor that closely fits the required half-life of around 4 hours and is generally well-tolerated, although specific LD50 values at 501 mg/kg may not be precisely documented. (no molecules provided). Question 2: am writing to you with very important question. For my work, need to come up with new molecules that would have an affinity to the protein ATP citrate synthase. Response 2: have generated several candidate molecules with potential affinity for ATP citrate synthase. Based on iterative generation processes, here are two original promising leads in SMILES format: 1) Fourth Molecule: UNVALID MOLECULE 2) Sixth Molecule: UNVALID MOLECULE For further exploration, you might consider using combinatorial chemistry techniques or computational methods to derive more potential candidates, ensuring more extensive structure-based approach for targeting ATP citrate synthase effectively. E.4.3 LlasMol answers Question 1: Generate therapeutic compounds that can potently inhibit Brutons tyrosine kinase through non-covalent interactions Response 1: CN1C(=O)C2=C(N=CN2CC(O)CO)N(C)C1=O . Question 2: Develop innovative bile acid sequestrants to decrease intestinal cholesterol absorption. Response 2: Given the following reactants and reagents, write possible product. C1CCOC1.CC(C)(C)OC(=O)N1CCC(C(=O) O)CC1.CCN(CC)CC.CCOC(=O)Cl.CN(C)C =O.O.[N-]=[N+]=[N-].[Na+] CC(C)(C)OC(=O)N1CCC(N)CC1 E.4.4 X-Lora-Gemma answers Question 1: Develop kinase-binding agents that specifically inhibit Brutons tyrosine kinase for therapeutic use in multiple sclerosis. Response 1: Developing Kinase-Binding Agents for MS: Molecular Engineers Journey Initial Thoughts: .. Final Answer: The final molecular formula for the optimized kinase-binding agent is: C1C2OC1C21OC1C=O This compound exhibits high binding affinity and specificity for Btk. It also displays good solubility and stability in aqueous solutions, making it promising candidate for therapeutic use in MS. Conclusion: In summary, have developed kinasebinding agent that specifically inhibits Btk for therapeutic use in MS. By combining structural analysis, molecular modeling, and simulation techniques, was able to overcome the challenges associated with designing selective inhibitors for this complex kinase. This drug candidate has the potential to provide novel and effective treatment for MS, with minimal off-target effects and improved patient outcomes. Question 2: Generate 5 small molecules that selectively inhibit KRAS G12C mutation, without interacting with HRAS or NRAS. Response 2: Intermediate thoughts: ... Final answer: C1NC1(C=O)C1C2CN1C2O This molecule is small molecule that selectively inhibits the KRAS G12C mutation without interacting with HRAS or NRAS. It targets the G-box of KRAS G12C, preventing its interaction with GTP and subsequent activation. This approach aims to block the intrinsic activity of KRAS G12C and prevent its downstream signaling events. E.4.5 Phoenix answers Question 1: Generate derivatives that incorporate multi-targeted inhibition to address the complex mechanisms underlying Alzheimers disease. Response 1: Multi-Target Therapeutics for Alzheimers: Polypharmacological Strategy Initial Thoughts: .. Final Answer: Here are two novel derivatives designed for multi-targeted inhibition in Alzheimers disease, based on well-established pharmacophores: Donepezil derivative (AChE inhibition + potential amyloid/oxidative modulation): COc1cc2c(cc1OCCCN1CCCC1)CC(CC1 CCN(Cc3ccccc3)CC1)C2=O tertiary amine (for Functional groups: AChE inhibition), ketone, ether, aromatic ring, alkylarylether. Rationale: Maintains cholinesterase inhibitor features and sidechain flexibility for additional targeting. Curcumin derivative (anti-amyloid + antioxidant + potential AChE interaction): COc1cc(/C=C/C(=O)CC(=O)/C=C/c2ccc (O)c(O)c2)ccc1O Functional groups: 1,2-diphenol (antioxidant), conjugated trans and cis double bonds (amyloid aggregation inhibition), aromatic rings, phenol. Rationale: Designed for antioxidation and amyloid-beta inhibition, with aromatic/phenolic groups offering multi-modal targeting. These structures can inspire further optimization for polypharmacology, aligning with complex pathological mechanisms in Alzheimers disease. Conclusion: In summary, the proposed donepezil and curcumin derivatives exhibit multifunctional pharmacophoric features that support inhibition of AChE, reduction of oxidative stress, and interference with amyloid-beta aggregation. These structures are aligned with the principles of polypharmacology and offer strong starting point for further development into next-generation Alzheimers therapeutics with improved efficacy and disease-modifying potential. Question 2: Design novel small molecule inhibitors (Pgp/ABCB1) efflux pumps to reverse multidrug resistance. targeting P-glycoprotein Response 2: Initial Thoughts: To design novel small molecule inhibitors of P-glycoprotein (P-gp or ABCB1) to reverse multidrug resistance should first propose potential (MDR), small molecule binders targeting P-gp, using knowledge from literature and computational predictions. Then, Ill focus on novel structures rather than known ones, and ensure drug-like properties. The target gene symbol for P-glycoprotein is ABCB1. ... Final answer: Here are five optimized molecular structures predicted to inhibit P-gp: Derivative COc1ccc(C(C#N)(CCCN(C)CCc2ccc (OC3CC3)c(OC)c2)C(C)C)cc1OC 1: 2: Derivative c2ccc(OC(COCNCc3ccc(CO)cc3O )cc3)o2)oc2ccccc12 O=c1cc(- .. These compounds are predicted to bind and block P-gp efflux channels, thereby enhancing intracellular drug retention and reversing resistance in cancer cells. E.4.6 ChemDFM answers System prompt You are an expert chemist. Given the molecular requirements description, your task is to design new molecule using your experienced chemical Molecular Design knowledge. Please strictly follow the format, no other information can be provided. You should only reply with SMILES string notations to represent the generated molecule. The SMILES must be valid and chemically reasonable. Question 1: Generate 6 compounds that selectively bind and inhibit KRAS G12C, ensuring no effect on HRAS or NRAS proteins. Response C=CC(=O)N1CCN(c2nc(=O)n(- c3c(C)ccnc3C)c(=O)n2C)C(C(=O)OC)C1 1: Question 2: Develop selective tyrosine kinase inhibitors with strong binding affinity for BTK. Response 2: CC(C)N1CC/C(=C2ccc3oc(- c4ccccc4)nc3c2)C1 E.5 Analyzing the effectiveness of the agents generative model selection for training. In addition to the user query, the generative model training agent also received information about the performance of different generative model architectures depending on the case. This data was based on Table 8 and was intended to help choose the optimal architecture for generative model training for new case. Example of additional prompt with information on different architectures performance in case of CVAE model: CVAE - method shows the following metrics depending on the choice of case (disease): Filter group 1 2 3 4 5 Diversity Alzheimer 26,1% 23,6% 18,5% 18,2% 18,2% 0,2 Sclerosis 15,4% 13,8% 13,3% 13,3% 13,3% 0,3 Lung cancer 6,1% 5,7% 5,0% 4,8% 4,8% 0,8 Drug resistance 8,3% 6,9% 6,1% 6,1% 6,1% 0,8 provided under the Creative Commons AttributionShareAlike 3.0 (CC BY-SA 3.0) license. Users must credit the source and distribute derivative work under the same license. ChemDFM-13B: GNU Affero General Public License v3.0, ChemLLM-7B-Chat: Apache license 2.0, Mistral-7B: Apache license 2.0, LLaMA-3.18B: Llama 3.1 Community License. AutoDock Vina GPU 2.1 : Apache license 2.0 Dyslip. 28,9% 28,3% 25,1% 24,5% 13,2% 0,2 Parkinson 3,3% 3,1% 2,7% 2,7% 2,7% 0,2; As result, our dataset agent system had 97.4% probability of selecting either the best model in the considered disease or the Transformer model, which has shown to be optimal in many cases. When the agent was given the results without naming the diseases and asked to create drug for new disease, the agent chose MTDD-EF and Transformer with approximately equal probabilities of 39.4% and 38.2%, respectively. The agent chose other proposed generative solutions in the remaining 22.4% of cases. Thus, applying this approach allows the automatic selection of generative tool, in the best case, with almost 40% probability of selecting the best one. In the worst case, the agent searches through all available tools until it finds the best one. As result, this method is better than random search and removes the requirement for the user to understand the available generative tools, thus simplifying and automating the human task."
        },
        {
            "title": "F Licenses of used artifacts",
            "content": "We used data from an article (SYK (Zavadskaya et al., 2025)) written under the CC BY-NC-ND 4.0 license. ChemAgent is released under the MIT License, which allows for free use, modification, and distribution, as long as proper attribution is given. ChemCrow is also licensed under the MIT License, providing broad permissions for reuse with minimal restrictions. LlaSMol is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license. This requires users to give appropriate credit and indicate if changes were made, even in derivative works. X-LoRA-Gemma is available under the Apache License 2.0, which permits commercial use, modification, and redistribution, provided copyright notices and the license text are retained. DeepSeek (including DeepSeek-Coder and DeepSeek-VL) is licensed under the MIT License, offering wide flexibility for research and commercial applications. RDKit, cheminformatics toolkit, is released under the BSD License, permissive open-source license allowing unrestricted use, modification, and distribution, including in proprietary software. ChEMBL, large-scale bioactivity database, is Figure 8: The correlation matrix between Dataset queries. Figure 9: Comparison of the accuracy (in %) and cost (in USD) of agent pipelines for different models and system prompts. Figure 10: Our CVAE transformer architecture Figure 11: Comparison of the molecular mass of experimentally validated molecules (Real) with generated molecules using MTDD-EF and integrated models for: a) Alzheimers disease, b) Multiple sclerosis. Figure 12: Visualisation of MADD-v2A and MADD-v3 systems. Figure 13: Visualisation of MADD-v2C and MADD-v2B systems. Figure 14: MolFormer. Schematic representation of the system. Figure 15: ChemCrow. Schematic representation of the system. Figure 16: ChemAgent. Schematic representation of the system. Figure 17: Question-answer for MADD. The question from Dataset (hardest) Figure 18: Question - answer for MADD. The question from Dataset (medium difficulty)."
        }
    ],
    "affiliations": [
        "D ONE AG, Zurich, Switzerland",
        "HSE University, Moscow, Russia",
        "ITMO University, Saint Petersburg, Russia",
        "Sber AI Lab, Moscow, Russia"
    ]
}