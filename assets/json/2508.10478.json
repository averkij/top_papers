{
    "paper_title": "Semantic IDs for Joint Generative Search and Recommendation",
    "authors": [
        "Gustavo Penha",
        "Edoardo D'Amico",
        "Marco De Nadai",
        "Enrico Palumbo",
        "Alexandre Tamborrino",
        "Ali Vardasbi",
        "Max Lefarov",
        "Shawn Lin",
        "Timothy Heath",
        "Francesco Fabbri",
        "Hugues Bouchard"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Generative models powered by Large Language Models (LLMs) are emerging as a unified solution for powering both recommendation and search tasks. A key design choice in these models is how to represent items, traditionally through unique identifiers (IDs) and more recently with Semantic IDs composed of discrete codes, obtained from embeddings. While task-specific embedding models can improve performance for individual tasks, they may not generalize well in a joint setting. In this paper, we explore how to construct Semantic IDs that perform well both in search and recommendation when using a unified model. We compare a range of strategies to construct Semantic IDs, looking into task-specific and cross-tasks approaches, and also whether each task should have its own semantic ID tokens in a joint search and recommendation generative model. Our results show that using a bi-encoder model fine-tuned on both search and recommendation tasks to obtain item embeddings, followed by the construction of a unified Semantic ID space provides an effective trade-off, enabling strong performance in both tasks. We hope these findings spark follow-up work on generalisable, semantically grounded ID schemes and inform the next wave of unified generative recommender architectures."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 4 1 ] . [ 1 8 7 4 0 1 . 8 0 5 2 : r a"
        },
        {
            "title": "Semantic IDs for Joint Generative Search and Recommendation",
            "content": "Gustavo Penha gustavop@spotify.com Spotify Delft, Netherlands Enrico Palumbo enricop@spotify.com Spotify Turin, Italy Max Lefarov mlefarov@spotify.com Spotify Munich, Germany Edoardo DAmico edoardod@spotify.com Spotify Madrid, Spain Alexandre Tamborrino alexandret@spotify.com Spotify Paris, France Shawn Lin weihsiangl@spotify.com Spotify New York, United States Marco De Nadai mdenadai@spotify.com Spotify Copenhagen, Denmark Ali Vardasbi aliv@spotify.com Spotify Amsterdam, Netherlands Timothy Heath theath@spotify.com Spotify New York, United States Francesco Fabbri francescof@spotify.com Spotify Barcelona, Spain Hugues Bouchard hb@spotify.com Spotify Barcelona, Spain Abstract Generative models powered by Large Language Models (LLMs) are emerging as unified solution for powering both recommendation and search tasks. key design choice in these models is how to represent items, traditionally through unique identifiers (IDs) and more recently with Semantic IDs composed of discrete codes, obtained from embeddings. While task-specific embedding models can improve performance for individual tasks, they may not generalize well in joint setting. In this paper, we explore how to construct Semantic IDs that perform well both in search and recommendation when using unified model. We compare range of strategies to construct Semantic IDs, looking into task-specific and cross-tasks approaches, and also whether each task should have its own semantic ID tokens in joint search and recommendation generative model. Our results show that using bi-encoder model fine-tuned on both search and recommendation tasks to obtain item embeddings, followed by the construction of unified Semantic ID space provides an effective trade-off, enabling strong performance in both tasks. We hope these findings spark follow-up work on generalisable, semantically grounded ID schemes and inform the next wave of unified generative recommender architectures. ACM Reference Format: Gustavo Penha, Edoardo DAmico, Marco De Nadai, Enrico Palumbo, Alexandre Tamborrino, Ali Vardasbi, Max Lefarov, Shawn Lin, Timothy Heath, Francesco Fabbri, and Hugues Bouchard. 2025. Semantic IDs for Joint Generative Search and Recommendation. In Proceedings of the Nineteenth Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). RecSys 25, Prague, Czech Republic 2025 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-1364-4/2025/09 https://doi.org/10.1145/3705328.3759300 ACM Conference on Recommender Systems (RecSys 25), September 2226, 2025, Prague, Czech Republic. ACM, New York, NY, USA, 6 pages. https: //doi.org/10.1145/3705328."
        },
        {
            "title": "1 Introduction\nGenerative models powered by Large Language Models (LLMs) are\ntransforming how we approach both recommendation and search\ntasks. Rather than building task-specific models, recent work have\nexplored unified generative frameworks that simplify system design\nand potentially improve generalization across tasks.",
            "content": "In generative models, item representations must be mapped to discrete tokens that LLMs can consume and produce [4, 9, 12, 12, 15]. Traditional recommender systems often use unique item identifiers (IDs) that are added to the models vocabulary, such as in SASRec [10], while others use sequential IDs (e.g. P5 [6]) based on heuristics, or less token-efficient solutions such as title of the entities involved [3]. Most of these approaches require re-training the model whenever new cold start items are added and fall short in industrial settings. To address this, recent work have proposed using Semantic IDs, sets of discrete tokens generated from pre-trained item embeddings [18, 21]. These IDs allow items with similar content (embeddings) to share tokens, improving generalization and enabling cold start settings. However, generating effective Semantic IDs critically depends on the embedding space used to construct them. Prior work has shown that fine-tuning embeddings for specific task, such as recommendation or search, yields the most effective Semantic IDs for that task [16, 26]. However, this raises an important question: Can we create Semantic IDs that perform well for both search and recommendation in joint generative model? This is particularly relevant as joint search and recommedation (Joint S&R) approach has emerged as promising strategy to RecSys 25, September 2226, 2025, Prague, Czech Republic Penha et al. Table 1: Fine-tuning the embeddingsused for Semantic ID constructionfor search and recommendation is effective in joint generative model. However, choosing one of the fine-tuned embedding spaces comes at the expense of the other task effectiveness. Bold indicates highest effectiveness while the superscripts denote statistical significance using paired t-tests and Bonferroni correction. Embedding space Search R@30 ( std.) Recommendation R@30 ( std.) 1 3 Content-based (e.g. DSI [21], TIGER [18]) Search based (e.g. RIPOR [26]) Rec. based (e.g. TokenRec [16]) 0.013 (0.009) 0.023 (0.017) 0.072 (0.028)13 0.026 (0.017) 0.004 (0.001) 0.062 (0.015)12 (1) Content-based: text embeddings such as TIGER [18] and DSI [21], not fine-tuned for either search or recommendation. (2) Search-tuned IDs: embeddings fine-tuned for retrieval effectiveness similarly to Zeng et al. [26] (3) Recommendation-tuned IDs: collaborative-filtering model embeddings fine-tuned for recommendation similarly to Qu et al. [16]. After calculating such embeddings for each item of the catalogue, semantic IDs are obtained by applying an ID strategy that tokenizes each item embedding into set of discrete tokens. Table 1 shows the performance of the semantic IDs coming from each embedding space when plugged into our Joint S&R model. The pattern is clear: optimizing for one task sacrifices the other. Searchtuned IDs boost retrieval by 5x but reduces recommendation performance by 60%. IDs fine-tuned for recommendation flip the effect. Concurrent work reports the same tension [20]. These observations set the stage for our contribution: Can we build single set of semantic IDs that balances both sides? In the next section we introduce bi-encoder jointly fine-tuned on both tasks and demonstrate how its shared embedding space reconciles the trade-off without increasing the computational costs of the Joint S&R model."
        },
        {
            "title": "3.1 Task-Specific Approaches\nFigure 2 depicts the pipeline shared by the two task-specific base-\nlines. Each trains an embedding model on a single supervision\nsignal and then discretizes that embedding with a quantizer model.",
            "content": "Search-based. Following the relevance-based ID construction [26] we train bi-encoder model on search data ùê∑ùëÜ , composed of query and relevant item pairs using in-batch cross negative samples. We use the concatenated item metadata (e.g. title, description) of the item as its document representation. The resulting embeddings Figure 1: Effectiveness of joint generative model for search an recommendation using different approaches to construct Semantic IDs. We investigate embeddings that take into account both search and recommendation when representing items and constructing Semantic IDs. reduce engineering overhead and improve performance [1, 14, 25, 27, 29] by unifying data sources and models that have traditionally been treated as separated silos. In this paper, we investigate the construction of Semantic IDs in the context of joint search and recommendation generative model. Specifically, we study how different embedding sources, finetuned for search, recommendation or both, impact the downstream performance of the model. We also consider whether it is more beneficial to share or to have task specific tokens to represent each item. Our findings confirm that there is fundamental trade-off in constructing Semantic IDs: embeddings finetuned for one task (e.g. recommendation) degrade performance on the other (e.g. search), and vice-versa. This calls into question the growing trend of using task-specific embedding spaces as priors to ID generation in generative models [16, 26]. We show that bi-encoder model jointly fine-tuned on both search and recommendation offers compelling compromise (see Figure 1), yielding Semantic IDs that generalize across tasks with minimal loss in individual task effectiveness. This challenges the conventional wisdom that optimal performance requires the construction of per-task ID. In contrast, our result suggest that shared representation space can streamline generative model design without sacrificing quality, especially in multi-task systems. As LLM-based recommendation continues to evolve, we believe this work offers timely signal: that better generative performance may come not from task-specific specialization, but from wellconstructed, generalizable semantic IDs."
        },
        {
            "title": "2 Motivation\nGenerative models promise a single architecture for both search\nand recommendation, yet the previous work optimizes IDs in a\ntask-specific space. We ask: What happens when those separate opti-\nmizations collide in a unified model?. To answer this, we reproduce\nthe three ID-construction pipelines:",
            "content": "Semantic IDs for Joint Generative Search and Recommendation RecSys 25, September 2226, 2025, Prague, Czech Republic Figure 2: Task specific Semantic ID construction methods for joint generative search and recommendation model. On the left we have Semantic IDs based on bi-encoder model fine-tuned for search (Search based), whereas on the right we have Semantic IDs based on the embeddings of collaborative-filtering model fine-tuned for recommendation (Rec. based). vsearch are then discretized to generate Semantic IDs, which are used for both search and recommendation tasks. Recommendation-based. Analogously, following TokenRec [16], we train an Efficient Neural Matrix Factorization (ENMF) model [2] on dataset ùê∑ùëÖ of interacted items of users to create collaborativefiltering based embeddings vrec. The embedding of each item is discretized and supplied to the generative model for both tasks."
        },
        {
            "title": "3.2 Cross-Task Approaches\nWe now describe five methods that explicitly incorporate informa-\ntion from both tasks.",
            "content": "Token-separated IDs. Figure 3 shows the Separate variant. We simply prepend task tags to the two task-specific IDs above, yielding tokens: IDsep . This strategy ùëñ doubles the ID vocabulary size but keeps training simple: search prompts may only output search tokens, while recommendation prompts only recommendation ones. = SEARCH:IDsearch , REC:IDrec ùëñ ùëñ Prefix-Share IDs. Adapting the idea of Shi et al. [20], Prefixshare allocates three codebooks: one shared (SHARED) plus the two task-specific prefixes above. single encoder ingests the concatenated embeddings [vsearch ]; two decoders learn codebookspecific reconstructions. The final ID is the concatenation of shared tokens followed by task-specific ones. ; vrec ùëñ ùëñ Figure 3: Token-separated Semantic IDs approach (Separate), where each task has its own set of semantic IDs constructed from search and recommendation speficic embeddings. Embedding-Combined IDs. Figure 4 illustrates three embeddinglevel fusion strategies. Fusedconcat. We ‚Ñì2-normalize vsearch = [vsearch ùëñ them: vconcat ùëñ ; vrec ùëñ ]. ùëñ and vrec ùëñ and concatenate FusedSVD. We again normalize the two embeddings but first reduce the higher-dimensional space with truncated SVD so that both have equal dimensionality ùëë. We then element-wise add them: vsvd = vsearch ùëñ + vrec ùëñ . ùëñ Multi-task. We train the bi-encoder on both supervision signals: queryitem pairs from ùê∑ùëÜ and co-occurring item pairs from ùê∑ùëÖ. The shared encoder is optimized with the sum of the two contrastive losses, producing embeddings vmt that carry retrieval and collaborative filtering cues. ùëñ"
        },
        {
            "title": "4 Experimental Setup",
            "content": "Dataset. Following Penha et al [14] we build S&R dataset from MovieLens25M [7]. The dataset contains 62 138 movies, 1.24 useritem interactions (chronologically split; last interaction per user for test) and exactly 20 natural-language queries per item (10 train / 10 test) generated with Gemini-2.0-flash1. We note that having 10/10 queries for train/test for each item removes the popularity bias of the search dataset. Given that we do not know the true distribution of popularity in search, i.e. there are no real user logs for the MovieLens data, we decided on using the uniform distribution. This means that the search popularity distribution is quite different from the recommendation distribution, and thus we might expect results to be more favorable in real-life distributions with some similarity between popularity distributions. Approaches that use the content of the items (content-based, search based and cross-task ones) use the title, year, description, genres, tags and genome tags [23] to calculate their embeddings. Evaluation Metrics. Given our focus on the retrieval task, we rely on Recall@30. We run every model five times with different random seeds and report the mean recall across different runs. We assess the statistical significance of our results using paired Students t-tests with 95% confidence interval. Embedding models. We use the following models to generate item embeddings: 1We use the following prompt: Your task is to return list with 10 queries for given movie (title of the movie, year and description and tags) After generating the initial set of queries, you should also generate list of the same size with paraphrased of the first queries. The paraphrased queries should be similar to the original queries, but with different words, structure and slight variations in the meaning. The queries should be realistic things that user would ask to find the movie. The queries should be diverse and cover different aspects of the movie. The queries should not include the title of the movie, but be broader descriptions of the movie and its content. The queries should also contain broad topics, themes and genres of the movie. Movie: {METADATA}. RecSys 25, September 2226, 2025, Prague, Czech Republic Penha et al. Figure 4: Embedding combined approaches where both tasks are considered. On the left we have Multi-task which first trains Bi-encoder for both search and recommendation and then generates Semantic IDs. On the right we have Fused which combines both embeddings coming from search and recommendation models and then uses the combination to generate Semantic IDs. Content-based: we use the pre-trained all-mpnet-base-v2 from sentence transformers [19] on top of the concatenated metadata described in the dataset subsection. For search: we start from the same pre-trained model, and further fine-tune it on search data with in-batch random negatives (MultipleNegativesRankingLoss) using sentence transformers for 5 epochs, batch 512, LR 2e-5, Adam. For recommendation: We train ENMF [2] via RecBole [28], 30 epochs, batch 512, embedding 256, LR 0.001, Adam. Generative model. google/flan-t5-base [17], trained jointly on S&R for 3 epochs (LR 0.002, batch 128, AdamW, weight-decay 0.01). To increase the number of distinct items retrieved for all generative retrieval models we resort to diversified beam search approach [24]: beam 60, diversity penalty 0.25, 30 groups. ID tokenisation. Unless otherwise stated we use two codebooks of size 256 (512 tokens total). Some cross-task methods require additional tokens. Separate adds in total 1024 new tokens to the vocabulary as each semantic ID space is treated separatedly. Prefixshare has 256 shared tokens and 512 task-specific tokens. The tokens are constructed using RQ-KMeans2 (FAISS residual quantiser [5]) for all models. For ablations we additionally evaluate MiniBatchDictionaryLearning (through Sklearn [13]), ResidualLFQ and RQ-VAE from vector-quantize-pytorch3."
        },
        {
            "title": "5 Results",
            "content": "Semantic IDs for Joint Search and Recommendation. Table 2 displays our results for different Semantic ID construction methods, for search and recommendation. Task-Specific Approaches. The first two rows show the top performers per task, as anticipated in the motivation. However, they are based on specialized IDs and cannot provide satisfactory trade-off for unified S&R generative model, as each semantic ID is overfitted to the target task. Interestingly, we see that for the Torso entities, the search based embeddings are effective, demonstrating that the popularity of each entity plays an important role in the recommendation data and that for less popular items leaning more on content is effective. Table 2: R@30 of the joint generative model using different Semantic ID construction methods that consider both objectives (search and recommendation). Head indicates the effectiveness for the top 1% most popular items in the train set, where Torso is the remaining set of items. Search data does not have popularity bias, i.e. all items have the same number of queries. Bold indicates highest scores, while underline indicates second highest. Search Recommendation Semantic ID construction All All Head Torso Task-specific Search based Rec. based 0.072 0. 0.026 0.062 0.090 0.170 0.070 0.035 Cross-task Separate Prefix-share Fusedùëêùëúùëõùëêùëéùë° FusedùëÜùëâ ùê∑ Multi-task 0.028 0.007 0.048 0.033 0.046 0.032 0.021 0.018 0.038 0.049 0.120 0.058 0.045 0.105 0. 0.051 0.010 0.041 0.060 0.024 Cross-Task Approaches. The remaining rows are methods that use embeddings from both tasks. Separate leverages distinct tokens for each task, adding more tokens to the vocabulary of the generative model (task-specific Semantic ID tokens). This means that the knowledge learned from one task cannot be used for the task-specific tokens of the other task, negating the regularization effect in item representations discussed by Penha et al. [14]. Prefix-share also underperforms the other methods, due to the underlying quantization approach not performing well here (see next section on the tokenization method ablation). We observe that both methods under perform methods that first combine the embeddings and then construct Semantic IDs (last three rows). The results for the fusion methods show that the concatenation of the embeddings can be problematic if one of the embedding spaces is larger than the other (the Bi-encoder model is 386 dimensional while the ENMF has 256 dimensions). The embedding space with larger dimensionality might become more represented. By making the dimensionality the same with FusedùëÜùëâ ùê∑ we improve the effectiveness of the model for recommendation, while degrading the search effectiveness compared to Fusedùëêùëúùëõùëêùëéùë° 4. 2https://github.com/facebookresearch/faiss/wiki/Additive-quantizers 3https://github.com/lucidrains/vector-quantize-pytorch 4Another solution to have embedding spaces with equal size that we did not explore is to train models with Matryoshka objective [11], and using the first dimensions only. Semantic IDs for Joint Generative Search and Recommendation RecSys 25, September 2226, 2025, Prague, Czech Republic Table 3: R@30 of the joint generative search and recommendation model for different tokenization methods using embeddings from Multi-task approach (similar results were found when performing the same ablation with the other approaches for Semantic ID construction). Method Search Rec. RQ-KMeans Dictionary encoding ResidualLFQ RQ-VAE 0.046 0.019 0.018 0.002 0.049 0.029 0.023 0.024 Finally, we see that training the encoding model for both search and recommendation tasks (Multi-task) offers an effective trade-off of the search and recommendation effectiveness. similar solution to inject collaborative filtering embeddings into content-based model has been proposed by Vanƒçura et al. [22]. We believe this is promising direction to obtain item representations that work well across search and recommendation problems. Tokenization Method Ablation. Table 3 shows the results for the ablation of the tokenization methods that receive as input embeddings and outputs discrete tokens, while keeping the embedding space fixed coming from Multi-task (similar results were found when performing the same ablation with the other approaches for Semantic ID construction). We see that RQ-KMeans is the best method to construct IDs for our dataset, outperforming common approaches such as RQ-VAE. Hong et al. [8] also found RQ-VAE unstable and opted for hierarchical k-means in their experiments. We leave for future work the investigation of the reasons why it outperforms learned auto-encoder approaches in this experimental setting."
        },
        {
            "title": "6 Conclusion\nIn this paper we show that the way Semantic IDs are built is a\ndecisive factor for the effectiveness of a unified generative model\nthat serves both search and recommendation tasks, systematically\ncomparing task-specific, token-separated, and embedding-combined\nconstructions.",
            "content": "We find that task-specific Semantic IDs excel only in isolation, whereas the cross-task ones deliver balanced, high-quality solution without inflating the token budget. Ablation of discretisation methods further shows that lightweight RQ-KMeans tokeniser outperforms VQ-VAE variants. These observations provide early empirical evidence that unifying item representations is not only feasible but advantageous. This insight is critical as LLM-based retrieval and recommendation systems are converging in practice [1]. By highlighting practical route toward shared Semantic IDs, our study offers timely snapshot of where the field is heading and points to several open questions on representation learning, token efficiency and cold-start robustness. We hope these findings spark follow-up work on generalisable, semantically grounded ID schemes and inform the next wave of unified generative recommender architectures. References [1] Moumita Bhattacharya, Vito Ostuni, and Sudarshan Lamkhede. 2024. Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn). In Proceedings of the 18th ACM Conference on Recommender Systems. 793795. [2] Chong Chen, Min Zhang, Yongfeng Zhang, Yiqun Liu, and Shaoping Ma. 2020. Efficient neural matrix factorization without sampling for recommendation. ACM Transactions on Information Systems (TOIS) 38, 2 (2020), 128. [3] Nicola De Cao, Gautier Izacard, Sebastian Riedel, and Fabio Petroni. 2020. Autoregressive entity retrieval. arXiv preprint arXiv:2010.00904 (2020). [4] Seungheon Doh, Keunwoo Choi, and Juhan Nam. 2025. TALKPLAY: Multimodal Music Recommendation with Large Language Models. arXiv preprint arXiv:2502.13713 (2025). [5] Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazar√©, Maria Lomeli, Lucas Hosseini, and Herv√© J√©gou. 2024. The Faiss library. (2024). arXiv:2401.08281 [cs.LG] [6] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM conference on recommender systems. 299315. [7] Maxwell Harper and Joseph Konstan. 2015. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis) 5, 4 (2015), 119. [8] Minjie Hong, Yan Xia, Zehan Wang, Jieming Zhu, Ye Wang, Sihang Cai, Xiaoda Yang, Quanyu Dai, Zhenhua Dong, Zhimeng Zhang, et al. 2025. EAGERLLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration. In Proceedings of the ACM on Web Conference 2025. 27542762. [9] Wenyue Hua, Shuyuan Xu, Yingqiang Ge, and Yongfeng Zhang. 2023. How to index item ids for recommendation foundation models. In Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region. 195204. [10] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM). IEEE, 197206. [11] Aditya Kusupati, Gantavya Bhatt, Aniket Rege, Matthew Wallingford, Aditya Sinha, Vivek Ramanujan, William Howard-Snyder, Kaifeng Chen, Sham Kakade, Prateek Jain, et al. 2022. Matryoshka representation learning. Advances in Neural Information Processing Systems 35 (2022), 3023330249. [12] Enrico Palumbo, Gustavo Penha, Andreas Damianou, Jos√© Luis Redondo Garc√≠a, Timothy Christopher Heath, Alice Wang, Hugues Bouchard, and Mounia Lalmas. 2025. Text2Tracks: Prompt-based Music Recommendation via Generative Retrieval. arXiv preprint arXiv:2503.24193 (2025). [13] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 28252830. [14] Gustavo Penha, Ali Vardasbi, Enrico Palumbo, Marco De Nadai, and Hugues Bouchard. 2024. Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other?. In Proceedings of the 18th ACM Conference on Recommender Systems. 340349. [15] Aleksandr Petrov and Craig Macdonald. 2023. Generative sequential recommendation with gptrec. arXiv preprint arXiv:2306.11114 (2023). [16] Haohao Qu, Wenqi Fan, Zihuai Zhao, and Qing Li. 2024. TokenRec: Learning to Tokenize ID for LLM-based Generative Recommendation. arXiv:2406.10450 [cs.IR] https://arxiv.org/abs/2406.10450 [17] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter Liu. 2020. Exploring the limits of transfer learning with unified text-to-text transformer. Journal of machine learning research 21, 140 (2020), 167. [18] Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan Hulikal Keshavan, Trung Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Tran, Jonah Samost, et al. 2023. Recommender systems with generative retrieval. Advances in Neural Information Processing Systems 36 (2023), 1029910315. [19] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. https://arxiv.org/abs/1908.10084 [20] Teng Shi, Jun Xu, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, and Enyun Yu. 2025. Unified Generative Search and Recommendation. arXiv preprint arXiv:2504.05730 (2025). [21] Yi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, et al. 2022. Transformer memory as differentiable search index. Advances in Neural Information Processing Systems 35 (2022), 2183121843. [22] Vojtƒõch Vanƒçura, Pavel Kord√≠k, and Milan Straka. 2024. beeFormer: Bridging the Gap Between Semantic and Interaction Similarity in Recommender Systems. In RecSys 25, September 2226, 2025, Prague, Czech Republic Penha et al. Proceedings of the 18th ACM Conference on Recommender Systems. 11021107. doi:10.1145/3589334.3645477 [23] Jesse Vig, Shilad Sen, and John Riedl. 2012. The tag genome: Encoding community knowledge to support novel interaction. ACM Transactions on Interactive Intelligent Systems (TiiS) 2, 3 (2012), 144. [24] Ashwin Vijayakumar, Michael Cogswell, Ramprasath Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra. 2016. Diverse beam search: Decoding diverse solutions from neural sequence models. arXiv preprint arXiv:1610.02424 (2016). [25] Hamed Zamani and Bruce Croft. 2018. Joint modeling and optimization of search and recommendation. arXiv preprint arXiv:1807.05631 (2018). [26] Hansi Zeng, Chen Luo, Bowen Jin, Sheikh Muhammad Sarwar, Tianxin Wei, and Hamed Zamani. 2024. Scalable and Effective Generative Information Retrieval. In Proceedings of the ACM Web Conference 2024 (Singapore, Singapore) (WWW 24). Association for Computing Machinery, New York, NY, USA, 14411452. [27] Jujia Zhao, Wenjie Wang, Chen Xu, Xiuying Chen, Zhaochun Ren, and Suzan Verberne. 2025. Unifying Search and Recommendation: Generative Paradigm Inspired by Information Theory. arXiv preprint arXiv:2504.06714 (2025). [28] Wayne Xin Zhao, Yupeng Hou, Xingyu Pan, Chen Yang, Zeyu Zhang, Zihan Lin, Jingsen Zhang, Shuqing Bian, Jiakai Tang, Wenqi Sun, Yushuo Chen, Lanling Xu, Gaowei Zhang, Zhen Tian, Changxin Tian, Shanlei Mu, Xinyan Fan, Xu Chen, and Ji-Rong Wen. 2022. RecBole 2.0: Towards More Up-to-Date Recommendation Library. In CIKM. ACM, 47224726. [29] Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, Ming Chen, and Ji-Rong Wen. 2024. Adapting large language models by integrating collaborative semantics for recommendation. In 2024 IEEE 40th International Conference on Data Engineering (ICDE). IEEE, 14351448."
        }
    ],
    "affiliations": [
        "Spotify Amsterdam, Netherlands",
        "Spotify Barcelona, Spain",
        "Spotify Copenhagen, Denmark",
        "Spotify Delft, Netherlands",
        "Spotify Madrid, Spain",
        "Spotify Munich, Germany",
        "Spotify New York, United States",
        "Spotify Paris, France",
        "Spotify Turin, Italy"
    ]
}