{
    "paper_title": "WavePulse: Real-time Content Analytics of Radio Livestreams",
    "authors": [
        "Govind Mittal",
        "Sarthak Gupta",
        "Shruti Wagle",
        "Chirag Chopra",
        "Anthony J DeMattee",
        "Nasir Memon",
        "Mustaque Ahamad",
        "Chinmay Hegde"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Radio remains a pervasive medium for mass information dissemination, with AM/FM stations reaching more Americans than either smartphone-based social networking or live television. Increasingly, radio broadcasts are also streamed online and accessed over the Internet. We present WavePulse, a framework that records, documents, and analyzes radio content in real-time. While our framework is generally applicable, we showcase the efficacy of WavePulse in a collaborative project with a team of political scientists focusing on the 2024 Presidential Elections. We use WavePulse to monitor livestreams of 396 news radio stations over a period of three months, processing close to 500,000 hours of audio streams. These streams were converted into time-stamped, diarized transcripts and analyzed to track answer key political science questions at both the national and state levels. Our analysis revealed how local issues interacted with national trends, providing insights into information flow. Our results demonstrate WavePulse's efficacy in capturing and analyzing content from radio livestreams sourced from the Web. Code and dataset can be accessed at \\url{https://wave-pulse.io}."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 3 2 ] . [ 1 8 9 9 7 1 . 2 1 4 2 : r WavePulse: Real-time Content Analytics of Radio Livestreams Govind Mittal New York University Tandon School of Engineering Brooklyn, NY, USA mittal@nyu.edu Chirag Chopra New York University Tandon School of Engineering Brooklyn, NY, USA cc7083@nyu.edu Sarthak Gupta New York University Tandon School of Engineering Brooklyn, NY, USA sg8304@nyu.edu Anthony DeMattee The Carter Center Atlanta, GA, USA anthony.demattee@cartercenter.org Shruti Wagle New York University Tandon School of Engineering Brooklyn, NY, USA sgw6735@nyu.edu Nasir Memon New York University, Tandon School of Engineering Brooklyn, NY, USA memon@nyu.edu Mustaque Ahamad Georgia Institute of Technology Atlanta, GA, USA mustaque.ahamad@cc.gatech.edu Chinmay Hegde New York University, Tandon School of Engineering Brooklyn, NY, USA chinmay.h@nyu.edu ABSTRACT Radio remains pervasive medium for mass information dissemination, with AM/FM stations reaching more Americans than either smartphone-based social networking or live television. Increasingly, radio broadcasts are also streamed online and accessed over the Internet. We present WavePulse, framework that records, documents, and analyzes radio content in real-time. While our framework is generally applicable, we showcase the efficacy of WavePulse in collaborative project with team of political scientists focusing on the 2024 Presidential Election. We use WavePulse to monitor livestreams of 396 news radio stations over period of three months, processing close to 500,000 hours of audio streams. These streams were converted into time-stamped, diarized transcripts and analyzed to answer key political science questions at both the national and state levels. Our analysis revealed how local issues interacted with national trends, providing insights into information flow. Our results demonstrate WavePulses efficacy in capturing and analyzing content from radio livestreams sourced from the Web. Code and dataset can be accessed at https://wave-pulse.io CCS CONCEPTS General and reference Measurement; Information systems Multimedia streaming; Computing methodologies Information extraction. KEYWORDS Web content analytics, Radio livestreams, Large language models"
        },
        {
            "title": "1 INTRODUCTION\nDespite the rise of the World Wide Web and the emergence of social\nmedia networks, radio as a cornerstone of mass media has demon-\nstrated remarkable staying power. Since 2018, even though televi-\nsion viewership and print readership have plummeted by 29%, radio",
            "content": "listenership has experienced mere 7% decrease [33]. This resilience is further underscored by radios dominance in terms of its reach among the public. In 2023, AM/FM radio can be freely accessed by over 84% of U.S. adults, outperforming both smartphone-based social networking (78%) and live TV (72%) [22, 33]. Radios enduring relevance stems from its unique attributes. In contrast to global social media platforms, radios focus is primarily hyperlocal, and fosters deep community connections through content tailored to specific geographical areas (such as towns, counties, and states). Radios primary function is as one-way communication channel, allowing listeners to passively engage during their everyday activities, such as during commutes and/or at work. Many radio broadcasts are spontaneous and ephemeral, and the irreversible nature of radio broadcasts lends authenticity and immediacy to its content, particularly crucial in political discourse. These features have positioned radio as trusted, community-oriented medium which provides an alternative to the deluge of social media content, and gives (to some) welcome respite during digital fatigue. While these distinctions make radio unique as medium, they also make radio content much more challenging to monitor. In the United States, these features take on heightened significance. Radio serves as vital link across diverse urban and rural landscapes, functioning primary information source in remote areas and during long drives. Media exposure, especially through radio, plays crucial role in shaping political attitudes by both reinforcing and challenging existing beliefs. Theories of opinion formation suggest intensity of competing media messages is crucial in explaining changes in opinions over time [11, 35]. While partisan news tends to modestly reinforce existing beliefs, it is also shown to activate and convert individuals when they are continually exposed to opposing viewpoints, leading them to shift away from their original affiliations and preferences [12]. Resistance to these opposing viewpoints requires the ability and motivation to recognize discrepancies between the message and ones values and beliefs [35]. ArXiv, Preprint, Under Review Mittal et al. Figure 1: Overview of WavePulse. It streams radio, transcribes, diarizes, classifies, timestamps and summarizes content on the radio, making available for analytics. We derive political trends, match claims The deregulation and livestreaming of talk radio content over the Web have contributed to its rise and the corresponding increase in conservative public opinion [6]. Researchers have found that exposure to talk radio can be more powerful predictor of attitudes than political knowledge [19] with information received via news radio strongly influencing policy beliefs [32] and promoting memory-based political information processing more effectively than entertainment media [18]. This paper introduces WavePulse, an end-to-end system for real-time acquisition, transcription, speaker diarization, curation, and content analysis of hundreds of radio livestreams sourced from URLs accessible via the Web. The key feature of WavePulse is that most of the system components are built using powerful AI tools such as modern, multimodal large language models (LLMs) which have witnessed significant advances in 2024. This feature enables rapid design and deployment, and showcases AIs potential as valuable tool for worldwide broadcast media analysis. We report our findings from pilot deployment of WavePulse that encompassed 396 AM/FM radio streams spanning all 50 US states, where we placed strong emphasis on political news broadcasts recorded continuously over 100-day period from late June to late September 2024. This time period captures significant period of American political history, which included pivotal events such as controversial debates, two assassination attempts on presidential candidate, an unexpected campaign withdrawal by the sitting US President, and several other key political milestones. key outcome of our pilot deployment of WavePulse is large-scale, timestamped, speaker-diarized dataset of raw radio transcripts. This dataset provides rich and unique glimpse on the pulse of the American public (as recorded on the airwaves) during this period. The corpus of transcripts was derived from over 485,090 hours of speech content,1 comprising of 329 million text segments (1-3 sentences each) or approximately 4.5 billion words (in comparison, it matches size of the English Wikipedia as of Oct 13th, 1This is equivalent to 55 years of continuous speech. 2024 [34])2. We intend to publicly release this dataset for review and follow-up work by the research community. We envision that our system (and the associated dataset) can be leveraged by diverse researchers who are interested in analyzing patterns in national public discourse, media narratives, formation of public opinions, and the science of misinformation. To showcase WavePulse, we present three case studies: Monitoring narratives and rumors: In our first case study, we collaborated with team of political scientists studying election integrity and trying to identify the provenance of very specific rumor concerning the legitimacy of the 2020 Presidential Election (which continues to echo through the political discourse 4 years later). Our system enabled us to identify positive matches for this rumor and track it across the US over period of several months. Understanding content syndication patterns: In our second case study, we study content syndication across geographically dispersed radio stations. Using techniques from transcript de-duplication and hashing-based matching, we construct virtual radio syndication graph and find communities/clusters in this graph that frequently mirror each others (sometimes even niche) content. Such tools can potentially be used to study nationwide media diversity and analyze longitudinal information spread. Measuring political trends: In our third case study, we perform NLP-based sentiment analysis of chunks of transcripts related to specific candidates in the US Presidential Election, curate them into scalar time series, and visualize national and state-wise trends over given time periods. Remarkably, we find that our sentiment scores (gathered in purely passive manner) mirror national polling trends, showing that WavePulse can be used as supplementary tool for tracking public opinion over the web. The above showcase applications illustrate the utility of WavePulse as system for curating and comprehending content broadcast over radio. It also illuminates specific corner of the Web (livestreamed audio) which has been remained somewhat hard to access, until the development of modern multimodal LLMs. 2We acknowledge that this comparison requires careful interpretation due to the nature of spoken language and content repetition due to syndicated broadcasts. WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review To summarize, our contributions include the following: (1) An end-to-end framework for recording, transcribing and performing analytics on the radio. (2) data pipeline to convert raw transcripts into their rich counterparts, by time-stamping, diarizing, summarizing and classifying into ads, news and discussion, and ancilliary content. (3) Rich analysis including topic modeling to distill top emerging narratives, sentiment analysis to gauge political temperament across the United states stratified by state and time interval. (4) Three case studies, stemming from collaboration with nonprofit center for monitoring election integrity. (5) self-updating interactive website for our analytics. The rest of this paper is organized as follows. We first describe the WavePulse framework, followed by details about the data acquisition process. Next, we provide our qualitative and quantitative findings from the three case studies described above. We provide discussion of related work, and conclude with potential directions of future research."
        },
        {
            "title": "2 FRAMEWORK AND DATA COLLECTION\n2.1 Design of WavePulse\nThe proposed framework comprises three primary components, as\nillustrated in Fig. 1. Each component serves a distinct function in\nthe process of capturing, processing, and analyzing radio content:",
            "content": "Radio Streamer is responsible for acquiring audio feeds from webbased radio broadcasts [1]. It operates on configurable schedule, enabling parallel recording of multiple audio streams at predetermined intervals throughout the day. The streamer segments incoming audio into manageable chunks to facilitate batch processing. Upon completion of each chunk, the component transfers the file to the audio buffer of the subsequent component. The Radio Streamer continuously records all configured radio streams in parallel and segments them into 30-minute MP3 files. These files are then forwarded to the systems audio buffers for further processing. To optimize capture of relevant content while allowing time for system maintenance and backup, the streamer automatically initiates operations at 05:00 and concludes at 03:00 the following day (UTC-4). Audio Processor transforms the recorded audio chunks into timestamped, diarized transcripts through multi-stage process: Diarization and Transcription: We first utilize WhisperX [4], which integrates OpenAIs Whisper-large-v3 [25] model with PyAnnotate [23] for speaker diarization; this converts each audio file into structured JSON format. The resulting output contains spoken text segments, speaker indices, and precise start and end times for each segment (typically sentence long, see Fig. 3 for examples). Content Classification: Radio broadcasts intermix political news and discussion with ads and apolitical content. We process the radio broadcast in the JSON output using Googles Gemini-1.5Flash model [30], which categorizes each segment as either political or apolitical. In alignment with the projects focus on political discourse, apolitical segments are archived in cold storage. Advertisement Identification: Political segments undergo second round of classification using Gemini to distinguish advertisements Figure 2: Coverage of Radio Stations. Each marker is an AM / FM station. We clubbed News/Talk/Business-News into \"News/Talk\", and Public-Radio/College/Religious/Others into \"Other\". Counts: \"News / Talk\" : 347, \"Other\": 49. For rest of the US plots, we will use above state labels as reference. from substantive content. The remaining material consists of news reports and political discussions. Having labeled each segment as apolitical, political ad, or political content (implicitly news and discussions), we split each JSON transcript into three mutually-exclusive parts. The filtered political content is then sent for final processing. While we started with classifying audio to segment out music and delete segments that were devoid of speech, we ended up removing this step because music was rare in news-oriented stations and radio stations tend to keep any gaps to minimum in order to not waste air-time. Final Transcript Generation: The system generates timestamped transcripts that include speaker indices using the start time of each transcript, offset with the segment-specific stamp (as illustrated in Fig. 3). Additionally, we split the transcript into three mutuallyexclusive parts news/discussion, ads, apolitical and append continuation markers in these transcripts to prevent temporal discontinuities. For example, we insert \"political ad...\" between two segments of political discussion. For more details, see Sec. A.1."
        },
        {
            "title": "2.2 A Dataset of Nationwide Radio Transcripts\nWavePulse produces a comprehensive, segmented record of ra-\ndio content, categorized into mutually exclusive, chronologically\nordered, speaker-tagged, chat-like transcripts. This approach pre-\nserves the temporal integrity of the original broadcast, clearly delin-\neating transitions between political discourse, advertisements, and\napolitical content. Consequently, users can navigate the transcribed\ncontent with a clear understanding of its structure and context, even\nwhen encountering interruptions such as advertisements within\npolitical discussions. Please refer to Sec. A for details.",
            "content": "We collected the dataset for period of 100 days starting June 26th, 2024 with cutoff on Oct 3rd, 2024. In this period, we started ArXiv, Preprint, Under Review Mittal et al. Table 1: Word-error-rate and Avg. Inference Time for 30-min audio clips of ASR models, from our representative dataset. Model WER (%) Inference Time (s) RNN-T MMS-1B WhisperX 14.58.2 15.0 35.113.2 17.8 8.44.6 9.5 Azure as the ground truth on this dataset. WhisperX performed most accurately and fastest (see Tab. 1). Condensing the dataset. Radio discussions and news reporting are essentially conversations. Each radio station presents the news selectively, brings guests to discuss them, and broadcasts their opinions to listeners. To create concise summaries of each conversation, preserving relevant discussion and news threads while reducing erroneous text predictions, we summarize each 30 minute transcript using Gemini [30]. This step also enhances suitability of our dataset for open research by filtering out irrelevant information, such as phone numbers and host names, to have cleaner transcripts and future-proof from changing terms of services. Fig 3 illustrates sample summary. Embedding the dataset. As the dataset has nearly million data points, it warranted an efficient search mechanism. Therefore, we converted the summarized version of our dataset into 1024dimensional vector database using dense embeddings from BGEM3 [10]. Each embedding vector contains metadata like state, call sign, date, and time. We used LLaMa-3.1-8B-Instruct [15] to query the database, which in turn used FAISS [13] to search through the vector space and retrieve top matches. This resulted in QuestionAnswering Retrieval Augmented Generation (QA-RAG) pipeline."
        },
        {
            "title": "3.1 Case Study: Spread of a Political Narrative\nOverview. We collaborated with a democracy group at the Carter\nCenter which champions social causes including election integrity.\nOur goal was to understand how a system like WavePulse could\nbe useful to gain insights into the political/election discourse.",
            "content": "The center aimed to track narrative that revolved around the integrity of the 2020 US Presidential election in Fulton County, Georgia (US), that stemmed from report analyzing the election in Georgia, published by campaign spokesperson, claiming that the election was stolen from Trump. Taking this narrative as an example, we searched through our corpus for matching pieces of the narrative. Our dataset came out positive with at least 50 positive samples, including majority amplifying the claim in this narrative, handful reporting and few debunking it. Figure 3: Samples of (Top left) JSON segments (Bottom Right) Corresponding Diarized Time-stamped Political News (Top right) Discussion, (Bottom Left) Advert., and (Bottom) Summary. with 158 News/Talk stations and scaled up to 396 stations to get wide coverage, over course of four weeks to include stations with News, Religious, Public-Radio, Business-News, and College formats. Fig. 2 illustrates the coverage of 396 radio stations. Holes in our coverage exist where streaming station does not exist or they do not allow recording. Any potential selection bias that might be present in the dataset, would effectively represent the bias across the distribution of radio stations themselves The dataset comprises of 485,090.5 hours of speech recordings, which resulted in 970,181 raw JSON transcripts. This data had approximately 4.5 billion words and 329 million text segments, each are 1-3 sentences long. Quality of Transcripts. Each recording goes through several steps before being converted into the final transcripts. Out of these steps, speech recognition is the most important as we discard audio recordings after successful transcription, making this step irreversible. In order to make evaluation of downstream baselines feasible, we filtered representative dataset comprising two weeks worth of recordings, i.e., totaling 672. We varied time-of-day, U.S. state of station, format, wave modulation (AM/FM). We also ran checks to ensure that no filtered recording was cutoff and held full 30 minute worth of speech. We evaluated Nvidias RNN-T-Parakeet1.1B [21], MMS-1B [24], WhisperX [4], while considering Microsoft WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review Figure 4: Occurrence of Neutral Reporting (51.0%), Debunking (36.3%) and Promoting broadcasts (10.4%) related to the 2020 Election narrative (2.3% were unknowns). We encoded number mentions in the size of bubbles and use identical scale throughout. Summarized narrative: There were discrepancies in the 2020 Presidential election vote count in Fulton County, Georgia. Specifically, 17,000 votes needed to be reconciled before certification. group called The Elections Group was involved in various aspects of the 2020 election across multiple states. The Georgia State Election Board investigated the recount process and confirmed some rule violations by Fulton County. Over 20,000 ballots were added to both the original results and the machine recount without proper justification. There were missing ballot images and duplicate ballots, which makes the election suspicious. The Secretary of States office investigated, and there was lack of transparency and accountability. Since the 2020 election in Georgia was inaccurate, therefore the Presidential election was stolen. Context and Background. major focus area of the democracy group at this non-profit is to perform election monitoring worldwide. specific current goal of theirs is to track election related claims across the U.S. Prior to WavePulse, their reach was limited in scope to social media posts, blogs, news articles, podcasts and comments. Political scientists at the center provided us with narrative that appeared on the airwaves just after the Biden-Trump debate on June 27th, 2024; this date coincided with the start of our data collection. The main rhetoric was that there were inconsistencies in the logic and accuracy tests conducted on voting machines. They also provided us with list of keywords, which we converted to rules for filtering transcripts: logic AND accuracy AND test OR logic test* AND election OR logic testing AND vot* OR accuracy testing AND vot* OR accuracy test* AND election OR voting machine test* OR <Claimants name> Manual Methodology: Using the above keywords, we first filtered transcripts of stations in Georgia. E.g., filtered transcript should have \"logic\" AND \"accuracy\" AND \"test\" keywords. However, this resulted in only few matches. We expanded our search nation-wide, which revealed 120 samples. As keywords acted as OR Logic and accuracy OR and OR logic/accuracy OR logic / accuracy OR LA testing OR Elections group OR <Websites name> broad net and we needed exact citations, we did an internal human study amongst four individuals. We split the 120 samples into four overlapping sets so that each transcript gets seen atleast twice. Then, we aggregated the responses and received ground truth with 53 transcripts 34 supporting the claim, 16 neutrally reporting and 3 actively debunking this claim. An excerpt from June 2024 transcript that matched: matching transcript from Ohio (US) reads: You know, here, the must-read of the day, [Claimants name] on how Georgia was stolen. longtime spokesperson for President Trump, published must-read analysis of the 2020 stolen Georgia election on [website], Wednesday. This is the most comprehensive investigative piece of the fraudulent election in Georgia to date. Biden allegedly received the most votes of president in U.S. history, yet simultaneously could only sneak up in Georgia by some 13,558 votes. It didnt add up. It just didnt add up, and neither did the numbers in Fulton County. Automated Methodology: As the manual method depends on curated filtration rules to reduce search space, which is non-trivial for arbitrary narratives, we employ QA-RAG. We started by querying it, which gave us positive answer: Question to LLM: Were there discrepancies in the 2020 Presidential election vote count in Fulton County, Georgia? Answer: Yes, there were claims of discrepancies which reported that Fulton County had double-counted thousands of ballots during recount, resulting in discrepancies in the vote count. This issue was brought up by whistle blower and led to an investigation. The Georgia Election Board voted 3-2 to request an investigation by Attorney General Chris Carr into the matter. Though, the outcome of the election was not altered by these discrepancies, but the incident raised concerns about the accuracy and reliability of the Georgia election process in 2020. While the retrieval mechanism yielded solid leads, we did not have ground truth to compare it against. Therefore, to get holistic ArXiv, Preprint, Under Review Mittal et al. Methodology: Connecting and Categorizing Stations. To investigate information sharing patterns, we developed an algorithm to identify unique broadcasts and their repeats, comprising the following steps: Hashing and Similarity Computation: We computed locality-sensitive hashes of text-only portions of all transcripts using MinHash. We considered transcript pairs with Jaccard similarity exceeding predefined threshold (𝜃 = 0.8) related and thus added to each others adjacency list. As causality is hard to predict, we consider such content-based match to only suggest symmetric connection. Subgroup Identification: Utilizing these adjacency lists, we expanded our search to identify distinct subgroups through Breadth-First Search (BFS) approach. We started with the initial list of unvisited transcripts, and BFS all connected transcripts, forming exhaustive lists of resonating broadcasts which matched thematically. Network Refinement: To identify long-term collaborations and information propagation hubs, we implemented the following steps: (1) Merged broadcasters in the same subgroup on consecutive dates (e.g., We would consolidate KM_WXYZ_2024_07_15_13_30 and LM_WABC_2024_07_16_02_00 broadcasted identical content). (2) Discarded single-broadcaster subgroups, eliminating instances of content repetition on two-consecutive days. (3) In the remaining subgroups, extracted only the station names, such as KLMN and KOPQ, for each unique station. (4) Removed single-station lists, further refining the network by eliminating stations who broadcast their own content several days apart. (5) Created bidirectional edges between stations in each subgroup (e.g., for stations KLMN, KOPQ, and KRST, edges were created between all pairs). (6) Ensured uniqueness across rows and order invariance, standardizing edge representation. (7) Generated pair-wise connections, excluding self-connections. Results and Discussion. Our analysis initially identified 22,149 unique subgroups broadcasting similar content. Post-refinement, this reduced to 1,776 subgroups with 2,684 unique edges. This content mirroring pattern suggests coordinated messaging strategies transcending geographical and temporal boundaries. Figure 5 illustrates this broadcasting station network. Notable findings include: Fifteen stations exhibiting over 40 connections, suggesting key information exchanges. ten-station network spanning 10 mid-western and southern states shared content several times, indicating regional syndication network. 50 stations remained disconnected in our final network, potentially indicating non-participation in syndicates, self-broadcasters or representing false negatives in our analysis. For instance, station in New Jersey, despite being major broadcaster, showed no connections in our network, suggesting it might prioritize original content or use syndication methods our analysis could not capture. Content propagation chains, such as station in Iowa broadcasted story, another one in Tennessee echoed it ten days later, and followed by Illinois after another eight days. Figure 5: The Syndication Social Network among Radio. We do not show edges for clarity. Here, each marker is station and color encodes its degree category. understanding of the scope of this narrative, we searched through the whole dataset. For each summarized transcript, we prompted Llama to count the number of mentions related to \"2020 election being stolen, rigged, or false.\" If transcript came out positive, we subsequently obtained label for its stance, i.e., Promoting, Neutral Reporting, or Debunking. We obtained 3,497 mentions across the corpus. Fig. 4 illustrates the occurrence of such mentions and provides breakdown across the stances. For prompts see A.2. Findings and Discussion: While the manual method yielded 53 matches, the automated method extracted 3,497 matches, providing superior estimate of the media landscape covering contentious narrative. Majority of mentions were examples of neutral reporting, followed by 36.3% of debunking the narrative, with only 10.4% minority promoting it. This case study serves as an example of how one can gauge the level of traction narrative gets on the radio. While we have used the manual approach to explore options during prototyping, the QA-RAG approach offers distinct advantages. It overcomes two key limitations of traditional methods: the need for extensive domain expertise in rule creation and the challenges of language ambiguity. By leveraging semantic context understanding, the QA-RAG system scales efficiently without requiring manual rule development."
        },
        {
            "title": "Radio Stations",
            "content": "Our analysis of radio station transcripts revealed extensive verbatim duplications across geographically dispersed stations, suggesting the existence of complex social network among broadcasters. This phenomenon, observed across state boundaries and varying time frames, indicates structured information sharing among media outlets. For instance, specific claim regarding presidential candidates alleged substance use before debate was simultaneously broadcast by 31 distinct stations. While this synchronicity in content dissemination does not establish causality between broadcasts, it strongly suggests coordinated information sharing. WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review To validate our results, we employed the Louvain Community Detection Algorithm [7] on the US radio station graph, basing our analysis exclusively on edges derived from spoken content similarity. By coloring the resulting community detection graph according to station formats, we observed distinct clustering patterns where similar content types naturally grouped together while differing content types displayed greater separation in the network structure (See Fig. 13). These validation efforts substantially reinforced our confidence in WavePulses capabilities to accurately identify both narrative spread and content syndication patterns throughout radio networks. Results and Discussion.This study enhances our understanding of information propagation in legacy media networks. The observed patterns raise important questions about media diversity, centralization of narrative control by major syndicates, and the potential for rapid, wide-scale dissemination of specific viewpoints across seemingly independent broadcast radio channels. This methodology also provides simple approach to map information flow and identifying potential echo chambers in the broadcasting landscape."
        },
        {
            "title": "Favorability Trends",
            "content": "The summer of 2024 marked pivotal period in American politics, with public perception of presidential candidates fluctuating in response to unfolding events. This study delves into these dynamics through sentiment analysis of the dataset, focusing on the three most prominent figures: Harris, Biden, and Trump, with Biden dropping out in mid-July. We isolated relevant text segments by keyword matching, carefully excluding instances of multiple candidate mentions to ensure sentiment clarity3. The Twitter-roBERTa-base model [9], denoted as S, served as the foundation for sentiment analysis, generating positive (𝑆), neutral (𝑆), and negative (𝑆) sentiment counts. To distill these multifaceted sentiment counts into single, comprehensible metric, we developed normalized sentiment score 𝑆 [0, 1]: 𝑆 = (2 𝑆 + 1 𝑆 + 0 𝑆)/(2 𝑆𝑇 ) where 𝑆, 𝑆, 𝑆 Z+ and 𝑆 + 𝑆 + 𝑆 = 𝑆𝑇 This formulation captures the nuances of all three sentiment categories, while providing holistic view of content sentiment and enables day-to-day sentiment comparisons independent of mention frequency. The lower part of Fig. 6 illustrates the ebb and flow of nationwide sentiment as computed from the radio content, smoothed with 7-day moving average to reveal underlying trends, as radio shows had less programming during weekends which caused weekly dips. Annotated political events offer context for significant shifts, painting picture of how key moments shaped public perception. We derive the upper part of the figure from raw data of Nate Silvers model [29].4 Diving deeper, Fig. 7 breaks the trends down according 3Name variations (e.g., \"Kamala\" for Harris) were aggregated under primary identifiers for consistency. 4Nate Silver is renowned American statistician and data journalist, famous for accurate election predictions and founding the influential website FiveThirtyEight. This website focuses on opinion poll analysis, politics, and economics. Their data (accessed Oct 13) is displayed in the upper part of Fig 6. to state-specific sentiments, reflecting local political climates or the impact of targeted campaign strategies. Findings and Discussion: Our sentiment predictions demonstrate similarity with the 2024 Presidential polling averages, which in turn is based on reputable national polls and summarized by competitive model from prominent pollster. This alignment suggests that radio content analysis can serve as valuable proxy for public sentiment, offering real-time insights into political trends. The state-wise sentiment analysis reveals granular view of political leanings across the country. However, some anomalies emerged, such as the surprisingly strong Democratic lead in Wisconsin (D+12). This discrepancy between state-level and nationwide trends warrants further investigation."
        },
        {
            "title": "4 RELATED WORK\nRadio Content Analytics. While radio has a century-long history\nas a broadcasting medium for entertainment and information dis-\nsemination, modern radio in the U.S. has its roots in the deregulation\nadopted in the Telecommunications Act of 1996 that fundamen-\ntally reshaped the U.S. radio industry. The deregulation altered\nthe industry’s economics, with large conglomerates implementing\ncost-cutting measures such as staff reductions and automated pro-\ngramming, while also changing advertising dynamics by offering\nmulti-station, multi-market packages to advertisers [14]. Also, due\nto the rise in online music streaming and piracy making music\nexpensive to broadcast, talk shows gained popularity. We did not\ninclude iHeartMedia stations in this study as they have restrictive\nterms of service, but still found several other syndicates [6].",
            "content": "Hofstetter [16, 17] studied how radio shows shape public opinion and found that they play several roles for their listeners, including seeking information, contextualizing, interpreting the information, and serving as proxy for interaction with the hosts and guests. From 2006-2011, DARPA undertook efforts to collect and transcribe cross-lingual broadcast news and talk shows under its GALE project [31]. In 2019, RadioTalk [5] was the first work that created large corpus of talk radio transcripts comprising 284,000 hours of radio and 2.8 billion words. The authors conducted transcription using TDNN model which produced noisy samples with WER of 13.1%. Using this dataset, Brannon and Roy [8] compared the speed of news on Twitter versus radio during 2019-2021 and found that Twitter news circulates and evaporates faster and is more negative than radio. follow-up work assembled the Interview media dialog dataset [20] comprising of collection of 20 years of NPR radio transcripts that enables discourse pattern analysis. Our work simultaneously provides an end-to-end pipeline, based on modern LLMs with 8.3% WER, which continuously produces rich dataset while being able to run real-time analytics to poll it. Social Media Analytics Frameworks. Aggarwal et al. [2] developed multimodal framework to track bias and incivility on Indian TV news. Saez-Trumper et al. [28] used unsupervised methods on geographically diverse set of news sources by examining gatekeeping, coverage, and statement bias to find bias in online news. Ribeiro et al. [27] employed scalable methodologies that leverage social medias advertiser interfaces to infer the ideological slant of thousands of news outlets. Allen et al. [3] analyzed Facebook posts during the COVID pandemic for content in the grey area and found ArXiv, Preprint, Under Review Mittal et al. Figure 6: (Top) National Polling Averages from the Silver Bulletin blog [29] for presidential candidates Trump and Harris, starting on Jul 19, 2024 just before Bidens withdrawal. (Bottom) Normalized sentiment for political candidates obtained via the radio. The plot was averaged using seven-day sliding window, with annotations indicating key political events. There is an anomalous peak for Harris, when Biden dropped out, because before that date there was lesser mentions about Harris, which peaked when she was brought forward as the Democratic Presidential Candidate. The national polls are derived by soliciting the polls from the public and weighting them according to their influence, while the sentiment plot reflects the temperament of the radio content. We observe similar trends in both, suggesting that the radio content can be used as proxy of its listeners sentiment. Figure 7: State-wise normalized sentiment towards Trump (red) and Harris (blue) in the period of Jul 21st - Oct 3rd, 2024 on 14-day rolling average. Each state is annotated with either Republicans (R) or Democrats (D), along with number which represents mean percentage gain of one party candidate over another throughout the considered period. If gain was < 1, we label it as Tie. New Jersey (NJ) had data anomaly because there were only few stations which streamed online that did not have restrictive terms-of-service. WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review that this unflagged content cast doubts on vaccine safety or efficacy and was 46-fold more consequential for driving vaccine hesitancy than flagged misinformation. Contrary to them, WavePulse provides tool to measure radio content in real-time, with the case studies performed primarily to showcase its capabilities, and it does not provide any subjective labeling."
        },
        {
            "title": "5 DISCUSSION AND CONCLUSION\nEthics statement. We have maintained strict ethical principles\nduring the data collection, usage, and analysis conducted in this\nwork. Our research utilizes data broadcast to the web on public\nradio streams, which falls under fair use unless explicitly restricted\nunder terms of service. We meticulously reviewed broadcasters’ li-\ncense agreements where applicable and excluded stations with such\nrestrictions. The dataset does not contain personally identifying\ninformation (PII) about listeners.",
            "content": "The dataset may include PII about advertisers (e.g., names and contact information of organizational representatives) and show hosts. Given our focus on political topics, we have strived to avoid political bias by using politically neutral prompts and presenting case studies without subjective labeling. We acknowledge that the usage of LLMs in our analysis may inherently exhibit some biases due to their respective training data. We leave the study of any political bias to political scientists. Limitations and Future Directions. Our analysis does not incorporate population data along with reach of each stations waves to calculate exposure to each station. Nielsen Audio sells exposure ratings and FCC hosts ground conductivity data. We also included only stations which are livestreamed over the Internet. Terrestrial-only radio broadcasts would require dedicated hardware (an antenna, transceiver, and recording equipment). Finally, while WavePulse is widely applicable, our analysis derives results and conclusions from only US radios. An important direction of future work is to broaden the scope to worldwide radio livestreams; due to the multilingual nature of LLMs we anticipate our system to scale up with no significant design changes. While we are confident about WavePulses scalability and error rates, our analyses should be considered within the context of case studies. comprehensive evaluation would require interdisciplinary collaboration and usage-based assessment. Our case studies demonstrate non-exhaustive variants of general-purpose tasks search, finding syndicate network, sentiment analysis that WavePulse can perform. Conclusions. We introduce WavePulse, an end-to-end pipeline for gathering and analyzing live-stream radio broadcasts which can increasingly be accessed via the Web. Using this system, we collected nearly half million hours of news/talk radio content over 100-day period of significant political activity in the United States. We conducted three case studies: tracking political narratives with political scientists, building social network of radio stations, and predicting political trends in real-time. Our findings highlight the depth of insights derivable from WavePulses comprehensive dataset. REFERENCES [1] Radio locator, 2024. Accessed on October 13, 2024. [2] Agarwal, A., Priyadarshi, P., Sinha, S., Gupta, S., Jangra, H., Kumaraguru, P., and Garimella, K. Television discourse decoded: Comprehensive multimodal analytics at scale. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (New York, NY, USA, 2024), KDD 24, Association for Computing Machinery, p. 47524763. [3] Allen, J., Watts, D. J., and Rand, D. G. Quantifying the impact of misinformation and vaccine-skeptical content on facebook. Science 384, 6699 (2024), eadk3451. [4] Bain, M., Huh, J., Han, T., and Zisserman, A. Whisperx: Time-accurate speech transcription of long-form audio. INTERSPEECH 2023 (2023). [5] Beeferman, D., Brannon, W., and Roy, D. Radiotalk: large-scale corpus of talk radio transcripts. In Interspeech 2019 (2019), pp. 564568. [6] Berry, J. M., and Sobieraj, S. Understanding the rise of talk radio. PS: Political Science & Politics 44, 4 (2011), 762767. [7] Blondel, V. D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. Fast unfolding of communities in large networks. Journal of statistical mechanics: theory and experiment 2008, 10 (2008), P10008. [8] Brannon, W., and Roy, D. The speed of news in twitter (x) versus radio. Scientific Reports 14, 1 (2024), 11939. [9] Camacho-collados, J., Rezaee, K., Riahi, T., Ushio, A., Loureiro, D., Antypas, D., Boisson, J., Espinosa Anke, L., et al. TweetNLP: Cutting-edge natural language processing for social media. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (Abu Dhabi, UAE, Dec. 2022), Association for Computational Linguistics, pp. 3849. [10] Chen, J., Xiao, S., Zhang, P., Luo, K., Lian, D., and Liu, Z. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation, 2024. [11] Chong, D., and Druckman, J. N. theory of framing and opinion formation in competitive elite environments. Journal of communication 57, 1 (2007), 99118. [12] Dilliplane, S. Activation, conversion, or reinforcement? the impact of partisan news exposure on vote choice. American Journal of Political Science 58, 1 (2014), 7994. [13] Douze, M., Guzhva, A., Deng, C., Johnson, J., Szilvasy, G., Mazaré, P.-E., Lomeli, M., Hosseini, L., and Jégou, H. The faiss library. [14] Drushel, B. E. The telecommunications act of 1996 and radio market structure. Journal of Media Economics 11, 3 (1998), 320. [15] Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Yang, A., Fan, A., et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 (2024). [16] Hofstetter, C. R., Barker, D. C., Smith, J. T., Zari, G. M., and Ingrassia, T. A. Information, misinformation, and political talk radio. In Rushed to Judgment: Talk Radio, Persuasion, and American Political Behavior. Columbia University Press, 2002, pp. 106118. [17] Hofstetter, C. R., and Gianos, C. L. Political talk radio: Actions speak louder than words. Journal of Broadcasting & Electronic Media 41, 4 (1997), 501515. [18] Kim, Y. M., and Vishak, J. Just laugh! you dont need to remember: The effects of entertainment media on political information acquisition and information processing in political judgment. Journal of communication 58, 2 (2008), 338360. [19] Lee, G., and Cappella, J. N. The effects of political talk radio on political attitude formation: Exposure versus knowledge. Political Communication 18, 4 (2001), 369394. [20] Majumder, B. P., Li, S., Ni, J., and McAuley, J. Interview: Large-scale modeling of media dialog with discourse patterns and knowledge grounding. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (Online, Nov. 2020), B. Webber, T. Cohn, Y. He, and Y. Liu, Eds., Association for Computational Linguistics, pp. 81298141. [21] NVIDIA. Parakeet-rnnt-1.1b. https://huggingface.co/nvidia/parakeet-rnnt-1.1b, 2024. Accessed on October 13, 2024. [22] Pew Research Center. News platform fact sheet, 2024. Accessed October 10, 2024. [23] Plaqet, A., and Bredin, H. Powerset multi-class cross entropy loss for neural speaker diarization. In Proc. INTERSPEECH 2023 (2023). [24] Pratap, V., Tjandra, A., Shi, B., Tomasello, P., Babu, A., Kundu, S., Elkahky, A., Ni, Z., Vyas, A., Fazel-Zarandi, M., Baevski, A., Adi, Y., Zhang, X., Hsu, W.-N., Conneau, A., and Auli, M. Scaling speech technology to 1,000+ languages. arXiv (2023). [25] Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., and Sutskever, I. Robust speech recognition via large-scale weak supervision. In International conference on machine learning (2023), PMLR, pp. 2849228518. [26] Rekesh, D., Koluguri, N. R., Kriman, S., Majumdar, S., Noroozi, V., Huang, H., Hrinchuk, O., Puvvada, K., Kumar, A., Balam, J., et al. Fast conformer with linearly scalable attention for efficient speech recognition. In 2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU) (2023), IEEE, pp. 18. [27] Ribeiro, F., Henriqe, L., Benevenuto, F., Chakraborty, A., Kulshrestha, J., Babaei, M., and Gummadi, K. Media bias monitor: Quantifying biases of social media news outlets at large-scale. In Proceedings of the International AAAI Conference on Web and Social Media (2018), vol. 12. ArXiv, Preprint, Under Review Mittal et al. [28] Saez-Trumper, D., Castillo, C., and Lalmas, M. Social media news commuIn Proceedings of the 22nd nities: gatekeeping, coverage, and statement bias. ACM international conference on Information & Knowledge Management (2013), pp. 16791684. [29] Silver, N. Nate silver 2024 president election polls model, 2024. Accessed on October 13, 2024. [30] Team, G., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., et al. Gemini: family of highly capable multimodal models. arXiv preprint arXiv:2312.11805 (2023). [31] Technica, A. Defense department funds massive speech recognition and translation program. Accessed on October 13, 2024. [32] Tesler, M. Elite domination of public doubts about climate change (not evolution). Political Communication 35, 2 (2018), 306326. [33] Westwood One. Nielsen: Am/fm radio expands its ratings lead over tv and smashing am/fm radios drive time myth, 3 2024. Accessed October 10, 2024. [34] Wikipedia contributors. Wikipedia:size of wikipedia. https://en.wikipedia. org/wiki/Wikipedia:Size_of_Wikipedia, 2024. Accessed on October 13, 2024. [35] Zaller, J. The nature and origins of mass opinion. Cambridge University (1992). WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review"
        },
        {
            "title": "FOR WAVEPULSE",
            "content": "Table of Contents: A.1: Data Collection Pipeline A.2: Summarization A.3: Embedding Summaries A.4: Semantic Similarity Search with FAISS A.5: Unique Narrative Network A.6: Wave-Pulse.io Frontend A.7: Wave-Pulse.io Backend A.8: Extension: Fact Checker A.9: Extension: Audio Classifier A.1 Data Collection Pipeline A.1.1 Radio Streamer. This component is used to stream and record audio streams from multiple parallel radio broadcasts. It takes as input configurable schedule in the form of JSON file, for when to stream and from which radio. There will be one entry per radio stream, its live URL, name, record times, and the state in which it is located along with list start and end times for streaming for that particular radio stream, as shown in Listing 1. The component processes the schedule to get unique start times across all the stations and durations specific for each station and then create cron jobs appropriately to achieve its objective. Conventionally, radio stations are referred to by their call signs (3-4 letter string) with the starting letter being either (Stations east of the Mississippi River), (Stations west of the Mississipi River), (military stations), (Army or Air Force stations). See Table 2, Table 3, and Table 4 for the full list of stations that have been streamed successfully. The audio files are recorded and saved in chunks of 30 minutes to facilitate batch transcription and analysis. The recorded audio files are distributed into buffer folders for running transcription in parallel. Buffer folders are created based on the number of GPUs available in the system to run transcription. The files are named in format 𝑆𝑆_𝑅𝑅𝑅𝑅_𝑦𝑦𝑦𝑦_𝑚𝑚_𝑑𝑑_𝐻𝐻 _𝑀𝑀.𝑚𝑝3 where SS stands for State Abbreviation, RRRR stands for Radio Call Sign which is unique for each radio station , followed by year, month, day, hour, and minute, such as 𝐶𝐴_𝐾𝐴𝐻𝐼 _2024_07_16_13_30.𝑚𝑝3. This naming format allows us to be able to easily filter files based on state, radio station or dates. { } \" url \": \" https :// stream . revma . ihrhls . com / zc3014 \", \" radio_name \": \" KENI \", \" time \": [\" 08:00 \", \" 14:00 \", \" 17:00 \", \" 21:30 \"], \" state \": \" AK \" Listing 1: Example for schedule of one radio stream. As per schedule radio streamer will record the audio from 8:00 AM to 2:00 PM then from 5:00 PM to 9:30 PM Figure 8: Crontab Schedule in the data collection pipeline to transcribe on the cloud and retrieve back. whisper-large-v3. Fig. 2 has sample outputs of these models for same input audio. We found word error rate of mms-1b to be significantly higher compared to Parakeet-RNNT and whisper-large-v3, for the latter two it was comparable. Ultimately we decided to go ahead with WhisperX implementation of Whisper as it provides built-in pipeline for transcription using Whisper, accurate timestamps using Wav2Vec2 and Speaker Diarization using PyAnnote at reasonable inference speed. Listing 1. shows snippet of output using WhisperX pipeline. { }, { }, { }, { }, { } \" start \": 946.93, \" end \": 948.391, \" text \": \" Here ' Anna with headlines . \", \" speaker \": \" SPEAKER_04 \" \" start \": 948.532, \" end \": 959.54, \" text \": \" Pope Francis today has accepted the retirement of the longtime Archbishop of Boston , Cardinal Sean ' Malley and chosen Providence Bishop Richard Henning to be his successor .\", \" speaker \": \" SPEAKER_19 \" \" start \": 960.601, \" end \": 964.004, \" text \": \" Tropical Storm Debbie is now hurricane .\", \" speaker \": \" SPEAKER_19 \" \" start \": 964.585, \" end \": 965.045, \" text \": \" What , Matt ?\", \" speaker \": \" SPEAKER_19 \" \" start \": 966.766, \" end \": 968.087, \" text \": \"Oh , no , my mic is still alive . \", \" speaker \": \" SPEAKER_04 \" Listing 2: Sample Transcript Segments A.1.2 Audio Processor. This component is responsible for the transcription, adding punctuation and capitalization to the text, providing time stamps, and diarization of the speakers of the recorded audio files. We tried multiple ASR models for transcription like facebooks MMS-1B, Nvidias Parakeet-RNNT-1.1B and OpenAIs One H100 GPU takes around 30 seconds to process one audio file of 30 minutes. So one GPU can process 60 audio files of 30 minute length, in other words one GPU can process 60 radio streams without resulting in any backlog. Since we were trying to process 400+ streams so we had to use 7 H100 GPUs. Due to resource ArXiv, Preprint, Under Review Mittal et al. constraints in our local server we used cloud services to get access to GPUs to be able to process all the radio streams. One instance of the application runs on local server and its job is to only record the streams and store audio files in recordings folder and their copies to audio buffer folder. Normally, files in recordings folder are sent to backup regularly and the ones in audio buffer are used for transcription and then deleted. In this case we setup corn trigger to periodically transfer files from audio buffer folders to hpc audio buffer folders with load distribution. Then next cron job periodically transfers files from hpc audio buffer folders to the audio buffer folders of cloud compute service. We have another instance of application running on cloud server with 7 H100 GPUs that does only transcription part and saves the result in transcripts folder. Then another cron trigger transfers files from the transcripts folder on cloud server to local server. If the audio streams are less and can be processed by local server than one can enable both recording and transcription on local server without needing to use cloud resources and creating data pipelines. WavePulse Deployment Radio-streamer Configuration: Streams : 396 on 64 cores Daily Recordings : 17,000 (30-min each) GPU Processing : 7 GPUs for real-time ML Model : Google Gemini Resource Utilization: Transcription : 10,105 A100 GPU hours Gemini Cost : $4,000 (1.5-flash) Vectorization : 24 H100 GPU hours for 106 transcripts Storage Rate : 180 GB/day 18 TB/100 days Minimal Deployment Requirements (100 streams): Storage : 200 GB Computing : 2 GPUs + 24 CPU cores (16 streaming, 4 per GPU) Figure 10: Bar chart showing the number of radio stations by station format. (a) WhisperX [4] (b) RNN-T [26] (c) MMS-1B [24] Figure 11: Transcribed text for same audio clip using different speech recognition models. Figure 12: Sentiment for Ozempic, pharmaceutical product which has been gaining traction due to success in fat loss. This plot suggests that talk shows discuss variety of things and not just politics. Figure 9: Line chart showing the addition of radio stations over time. A.2 Summarization The summarization process is critical step in condensing lengthy conversation transcripts into concise, meaningful summaries. This WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review section outlines the prompts and techniques employed to achieve efficient and accurate summarization using the Google Gemini API, combined with dynamic conversation segmentation and embedding generation. Our unit of summarization is 30-min transcript. Summarization Prompt: You are concise and direct news summarizer. Given below is JSON with spoken text and its speaker ID recorded from radio livestream. Create summary that: Presents information directly, without phrases like \"I heard\" or \"The news reported.\" Uses factual, journalistic tone as if directly reporting the news. Retains key facts and information while making the content specific and granular. Removes personal identifiable information (PII), such as phone numbers and sensitive personal data, but keeps public figures names (e.g., politicians, celebrities) and other key proper nouns relevant to the context. Is clear and avoids vague language. Clarifies ambiguous words or phrases. Utilizes changes in speaker ID to understand the flow of conversation or different segments of news. Corresponds strictly to information derived from the provided text. Organizes information into coherent paragraphs, each focusing on distinct topic or news item. Maintains neutral, objective tone throughout the summary. Do not include any meta-commentary about the summarization process or the source of the information. Spoken Text Transcription: {conversation block} Prompt used for finding matching mentions/claims of the 2020 election narrative: Analyze the following document summary regarding mentions of the 2020 election being stolen, rigged, or false. Document summary: {content} Answer the following questions: - How many times was the 2020 election being stolen, rigged, or false mentioned? - Did the document promoting, neutral report, or debunk these claims? Provide your answer in the following format: \"mention_count\": <number of mentions>, \"stance\": \"<promote/neutral/debunk>\" A.3 Dense Embedding for Summaries A.3.1 Overview. Once the conversation segments are generated and summarized, the next step is to create embeddings for each summary. These embeddings serve as high-dimensional vector representations that capture the semantic meaning of the text. The embeddings are generated using BGE-M3 [10]. By converting textual summaries into vectors, we enable efficient operations like similarity comparisons, clustering, and semantic search. A.3.2 Mathematical Representation. The embedding function, denoted by 𝑓 , transforms given summary 𝑆 into high-dimensional vector R𝑑 , where 𝑑 represents the number of dimensions in the vector space. The process can be mathematically described as: 𝑓 : R𝑛 R𝑑 v𝑆 = 𝑓 (𝑆), (1) Here, 𝑆 is the summary, v𝑆 is its corresponding embedding, 𝑛 is the number of words in the summary, and 𝑑 is the dimensionality of the embedding space. This transformation allows each summary to be represented as vector, which can then be compared against other vectors in terms of cosine similarity or other distance measures. A.3.3 Cosine Similarity of Embeddings. To compare the semantic similarity between two summary embeddings, cosine similarity is used. The cosine similarity between two vectors v𝑖 and v𝑗 , representing summaries 𝑆𝑖 and 𝑆 𝑗 , is given by: Cosine Similarity(v𝑖, v𝑗 ) = v𝑖 v𝑗 v𝑖 v𝑗 (2) Where v𝑖 v𝑗 represents the dot product of the vectors, and v𝑖 and v𝑗 are the magnitudes (or norms) of the vectors. This similarity measure is particularly useful for clustering, retrieval, and semantic search tasks. A.3.4 Asynchronous Embedding Generation. Given the large number of summaries, the embeddings are generated asynchronously to improve performance and scalability. By parallelizing the generation process, we can significantly reduce the processing time, ensuring that embeddings are computed efficiently for each summary. The embedding function is queried asynchronously for each summary, as shown in the following pseudo-code: By leveraging the embeddings, we ensure that each summary is represented in vector space, allowing for more advanced semantic operations. A.3.5 Usage of Embeddings. The generated embeddings are then used for multiple downstream tasks, such as: Clustering: Grouping similar conversations based on their semantic embeddings. Retrieval: Efficiently finding summaries that are similar to given query. Semantic Search: Searching through conversation summaries based on the semantic content rather than exact matches. A.4 Semantic Similarity Search with FAISS A.4.1 Why FAISS?. FAISS (Facebook AI Similarity Search) was chosen for its ability to perform efficient nearest-neighbor search in high-dimensional vector spaces. Given the large number of summaries and their associated embeddings, FAISS provides highly scalable solution for searching through these embeddings. ArXiv, Preprint, Under Review Mittal et al. FAISS Workflow. The FAISS workflow consists of the followA.4.2 ing steps: (1) Initialize FAISS index with the appropriate dimension size 𝑑, where 𝑑 is the size of the embedding vectors. (2) Add the embeddings for each summary to the index. (3) Perform nearest-neighbor search queries on the index to find semantically similar summaries. The FAISS index is initialized as: FAISS Index = faiss.IndexFlatL2(𝑑) (3) Where 𝑑 is the dimension of the embedding vectors. The similarity search is then performed by querying the index with the query embedding 𝑞. Distances, Indices = FAISS Index.𝑠𝑒𝑎𝑟𝑐ℎ(𝑞, 𝑘) (4) Where 𝑘 is the number of nearest neighbors to retrieve. Algorithm 1 Finding unique narratives in broadcasts Require: Set of radio broadcast transcripts 𝑇 = {𝑡1, 𝑡2, ..., 𝑡𝑛 } Require: Similarity threshold 𝜃 Require: Time threshold Δ𝑡 1: function OptimizedAnalyzeBroadcasts(𝑇 , 𝜃, Δ𝑡) 2: 𝐻 ComputeLSH(𝑇 ) Compute LSH for all transcripts 𝐴 CreateAdjacencyList(𝑇 , 𝐻, 𝜃 ) 𝑁 IdentifyNarrativesDisjointSet(𝐴) 3: 4: 5: return 𝑁 6: end function 7: function CreateAdjacencyList(𝑇 , 𝐻, 𝜃 ) 8: 𝐴 empty dictionary for each 𝑡𝑖 𝑇 do 𝐶 GetCandidates(𝐻, 𝑡𝑖 ) for each 𝑡 𝑗 𝐶 do candidates from LSH if MinHashSimilarity(𝑡𝑖, 𝑡 𝑗 ) 𝜃 then add to matching set 𝐴[𝑡𝑖 ] 𝐴[𝑡𝑖 ] {𝑡 𝑗 } 𝐴[𝑡 𝑗 ] 𝐴[𝑡 𝑗 ] {𝑡𝑖 } maintain symmetric set end if end for end for 17: 18: return 𝐴 19: end function 20: function IdentifyNarrativesDisjointSet(𝐴) 21: 𝑁 𝑉 for each 𝑡 𝐴.Keys not in 𝑉 do Set of disjoint repeated narratives Set of visited nodes 9: 10: 11: 12: 13: 14: 15: 16: 22: 23: 24: 25: 𝑛 BFS(𝐴, 𝑡, 𝑉 ) 𝑁 𝑁 𝑛 end for 26: 27: return 𝑁 28: end function Figure 13: Network Analysis of Content-Based Communities in U.S. Broadcast Radio This network visualization illustrates the clustering of radio stations based on content similarity. The nodes represent individual radio stations, color-coded by their format. The graph reveals dominant cluster of Talk and News/Talk stations in the center, while Religious and Public Radio stations form distinct communities at the periphery. The connections between nodes indicate content similarity, demonstrating how stations with similar programming formats naturally cluster together. This visualization effectively demonstrates content syndication patterns and programming relationships across the American radio broadcasting landscape. A.5 Finding Unique Narrative Network Analysis of transcripts revealed that the same narrative, content, or show was often broadcast multiple times on radio station and across multiple stations, even when the stations appeared independent. An algorithm was developed to identify unique narratives that were shared multiple times and form network of radio stations for each narrative. MinHash with similarity threshold of 0.8 was used to check if any two transcripts contained the same content. This process identified approximately 22,000 unique narratives from the dataset. We use only part of it in WavePulse, where we perform LSH and BFS to find social network. The narratives from this subsection can help us answer: What is getting amplified in that network? WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review Output Summary of Common Content: This collection of text excerpts focuses on the upcoming US presidential election and the role of celebrities in influencing voters. Election Coverage: The Democratic National Convention concluded with Vice President Kamala Harris accepting the partys nomination for president. The convention featured speeches from prominent Democrats and celebrities, highlighting their support for the Harris-Biden ticket. The election is just two months away, with the first presidential debate scheduled for September 10th. Celebrity Endorsements: Celebrities are increasingly using their platforms to endorse political candidates. While some celebrities, like Oprah Winfrey, have been shown to have significant impact on voter turnout, others, like Taylor Swift, have not yet endorsed anyone. The rise of social media and AI-generated images has created new challenges for verifying the authenticity of celebrity endorsements. Other Topics: The text also includes information on the economy, specifically the role of data-driven decision-making in various industries. The text also touches on the importance of free speech and the potential risks of cancel culture. A.6 Wave-Pulse.io Frontend Wave-Pulse.io is comprehensive real-time data visualization platform that leverages React for the frontend and Django with PostgreSQL for the backend. The system is designed to create an intuitive and responsive user interface that facilitates data analysis and exploration. The frontend, built with React, establishes communication with the backend through REST API calls, utilizing Axios for data management. To enhance performance and user experience, the frontend implements asynchronous data fetching techniques and employs caching mechanisms. The platform comprises key components, each serving specific purpose in the data visualization ecosystem: A.6.1 Home Page. The Home Page functions as the central navigation hub for the Wave-Pulse.io application, providing users with access to various features and data visualization options. A.6.2 Map UI. The Map UI is built upon the ComposableMap component from react-simple-maps, offering users an interactive exploration of the United States map. This visualization includes state boundaries, county outlines, and markers representing population centers and radio station coverage areas. To enhance user interaction and data analysis capabilities, the map interface offers toggles and filters: Map level toggle. Figure 14: Wave-pulse USA Map illustrating state and county boundaries, with radio station markers (grey) and population centers (yellow) plotted according to their precise coordinates. State Party Toggle: Visualizes sentiment data for political parties at the state level, providing insights into political leanings across regions. State Candidate Toggle: Presents sentiment data for individual candidates at the state level, allowing for comparison of candidate popularity. State Party Absolute Toggle: Displays absolute sentiment counts for political parties at the state level, offering quantitative view of party support. State Candidate Absolute Toggle: Shows absolute sentiment counts for candidates at the state level, enabling direct numerical comparisons. Coverage toggle. Show County Toggle: Activates county-level data visualization, allowing for granular analysis of sentiment patterns. Show Coverage Toggle: Illustrates the approximate radio area coverage for each station, providing insights into broadcast reach. Show Population Toggle: Highlights population density markers for major U.S. cities, contextualizing sentiment data with demographic information. Narrative toggle. The Georgia Election Stolen option provides visualization of how information related to the 2020 Georgia election controversy propagated through the radio network, offering insights into information dissemination patterns. Date Picker. This feature empowers users to select specific date ranges for data visualization, enabling temporal analysis of sentiment trends and patterns. A.6.3 Plots UI. The Plots UI component features two primary line charts: nationwide combined sentiment analysis and nationwide sentiment count. These charts are designed to adjust based on user interactions, providing responsive data exploration experience. To ArXiv, Preprint, Under Review Mittal et al. Figure 15: Detailed map visualization showing Republican vs Democrat leaning states from August 1, 2024, to August 7, 2024, with particular emphasis on Pennsylvania data for the specified period. add depth to the visualizations, entropy is incorporated, providing context to the plotted data and illustrating the degree of uncertainty in the sentiment analysis. Sentiment Analysis. This chart focuses on presenting sentiment values for key political entities (Biden, Harris, Trump, Democrats, and Republicans) on daily basis. To smooth out short-term fluctuations and highlight longer-term trends, the system calculates and displays 3-day moving average. Sentiment Count. This visualization plots sentiment counts for both candidates and political parties. Users have the flexibility to toggle between different data lines, allowing them to focus on positive, neutral, or negative sentiments as needed for their analysis. Figure 16: Comprehensive sentiment plot for all parties and candidates, covering the period from June 26, 2024, to August 7, 2024. Figure 17: Detailed plot illustrating the frequency of sentiment occurrences for all candidates over the period from June 26, 2024, to August 7, 2024. Figure 18: Comprehensive plot showing the frequency of sentiment occurrences for both major political parties from June 26, 2024, to August 7, 2024. A.7 Wave-Pulse.io Backend The Django-powered backend is designed to expose APIs that facilitate interaction with the frontend. This backend infrastructure is responsible for processing, aggregating, and formatting data to enable real-time visualizations. The PostgreSQL database underpinning the system is optimized to handle complex queries and store time-series data, ensuring rapid data retrieval and analysis capabilities. Wave-Pulse.io employs hosting solution that leverages the strengths of multiple platforms. GitHub Pages is utilized to host the frontend, while the DigitalOcean App Platform is responsible for hosting the backend and PostgreSQL database. This setup ensures efficient resource utilization and cost-effectiveness, while maintaining high performance and scalability. WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review The deployment process is integrated with GitHub repositories, facilitating Continuous Integration/Continuous Deployment (CI/CD) pipeline. This integration allows for updates and ensures that the latest stable version of the application is available to users. A.7.1 GitHub Pages Frontend. GitHub Pages serves as the hosting platform for the frontend, providing key advantages: Performance. GitHub Pages delivers pre-built assets directly to the browser, resulting in fast load times for users. This approach eliminates the need for server-side rendering, enhancing the responsiveness of the application. Automated Deployment. Updates to the frontend trigger automatic deployment processes using GitHub Actions. This automation streamlines the development workflow and ensures that new features and improvements are made available to users. Advantages. Cost-effectiveness: GitHub Pages offers free hosting for public repositories, reducing operational costs. Seamless integration: The tight integration with the GitHub ecosystem facilitates smooth development and deployment process. Version control: Inherent version control capabilities allow for tracking of changes and rollbacks if necessary. A.7.2 DigitalOcean Backend. The DigitalOcean App Platform is employed to handle the Django backend and PostgreSQL database, offering robust and scalable solution for server-side operations. Functionality. The backend processes incoming requests, manages complex business logic, and interfaces with the database to serve real-time data to the frontend. This setup ensures efficient data management and enables the dynamic features of the WavePulse.io platform. Advantages. Dynamic resource allocation: DigitalOcean adjusts resource allocation based on the backends workload, ensuring optimal performance during peak usage periods. Comprehensive monitoring: Integrated monitoring tools provide real-time insights into system performance, allowing for proactive management and optimization. Streamlined deployment: Automatic deployment processes are triggered by GitHub pushes, ensuring that the backend remains synchronized with the latest code changes. Managed database services: DigitalOceans managed PostgreSQL service reduces the operational overhead of database management while maintaining high availability and performance. A.8 Extension: Scraping Fact Checks The fact-checking program is system designed for the automated collection, processing, and post-processing of fact-checking articles from various reputable websites. Developed using Python and leveraging the Scrapy framework for web scraping, the system incorporates specialized spiders for specific fact-checking websites, including FactCheck.org, Lead Stories, Politifact, Snopes, and TruthOrFiction. Although we do not use it in WavePulse, matching fact checks from authoritative resources with transcript embeddings can help automate fact-checking. A.8.1 Websites Overview. Our team developed Fact Check Web Crawler capable of scraping fact-checking articles from multiple authoritative websites. The data collection period spans from January 1, 2020, to August 6, 2024, providing substantial dataset for analysis. To ensure ethical and legal compliance, we reviewed the terms of service for each website prior to data collection. Scrapy Implementation. The core of our fact-checking sysA.8.2 tem utilizes Scrapy spiders to scrape fact-checking articles. These spiders are designed with flexibility, supporting various filtering options including date range, keywords, tags, and pagination. This adaptability allows for targeted data collection based on specific research needs. Post-crawling, the system employs data merging process that combines information from all scraped websites into unified dataset. key feature of our system is the standardization of factchecking rulings across different articles, ensuring consistency in our analysis. The merged dataset undergoes filtering process to isolate political content, enabling focused studies on political misinformation. A.8.3 Deduplication Process. To ensure data integrity and prevent redundancy, we implemented deduplication module. This component is designed to identify and manage duplicate fact-checking articles by conducting analysis of textual content and publication dates. The deduplication process employs natural language processing techniques, including TF-IDF (Term Frequency-Inverse Document Frequency) vectorization. This method transforms the text into numerical representation, enabling the calculation of cosine similarity between articles. By setting thresholds for similarity and considering publication date proximity, the system clusters and manages duplicate content. Figure 19: Illustrative example of misinformation factchecked across multiple reputable websites, demonstrating the need for effective deduplication. A.8.4 Results Visualization. To facilitate understanding and analysis of the collected fact-checking data, we developed visualization tools, including word clouds and histograms. ArXiv, Preprint, Under Review Mittal et al. Histogram Analysis. We created histogram to visualize the frequency distribution of various fact-checking rulings. This analysis provides insights into the landscape of misinformation and fact-checking efforts. For the year 2024, our findings include: The \"False\" category shows the highest frequency, with 1008 instances, indicating significant volume of debunked claims. \"True\" claims occur less frequently, with 320 instances, suggesting lower proportion of verified information in the fact-checking landscape. Categories such as \"Miscaptioned\", \"Satire\", and \"Outdated\" constitute notable portion of the dataset, highlighting the diverse nature of misinformation and the nuanced approach required in fact-checking. Figure 22: Word cloud showing frequency of occurrence of significant words with the ruling \"False\" across all the data scraped from fact-checking websites for 2024. Figure 20: Comprehensive histogram illustrating the frequency of occurrence for all fact-checking \"rulings\" across the scraped websites for the year 2024. Figure 23: Word cloud showing frequency of occurrence of significant words with the ruling \"Mostly True\", \"Mixed\", or \"Mostly False\" across all the data scraped from fact-checking websites for 2024. Figure 21: Word cloud showing frequency of occurrence of significant words with the ruling \"True\" across all the data scraped from fact-checking websites for 2024. Word Cloud Visualization. To provide representation of the fact-checking landscape, we generated word clouds that visually depict the most frequent words found in article titles, categorized by their fact-checking \"rulings\". This approach offers insights into recurring themes and topics within different truth categories. The titles were divided into four primary categories: Figure 24: Word cloud showing frequency of occurrence of significant words with the remaining rulings such as \"Satire\" or \"Outdated\" across all the data scraped from fact-checking websites for 2024. True: Word clouds for this category often feature prominent political figures and terms related to electoral processes, such as \"election\", \"president\", and \"vote\". False: While containing similar political keywords, this category notably includes terms like \"photo\", \"fake\", and \"real\", indicating prevalence of visual misinformation. Middle (including \"Mostly True\", \"Mixed\", or \"Mostly False\"): This category highlights words such as \"year\", \"million\", and WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review \"country\", suggesting focus on claims involving statistics or demographic information. Miscellaneous: Words like \"video\", \"claim\", \"fact-checking\", and \"evidence\" are more prominent in this category, reflecting the complex nature of these fact-checks. The resulting audio file, representing distilled version of the original input focusing on detected speech, is then saved in the specified output directory. This final product serves as resource for further analysis, transcription, or other downstream processing tasks. A.9 Extension: Audio Classifier As part of our data analysis toolkit, we developed system for segmenting and classifying speech from audio files. This system leverages the audio processing capabilities of MediaPipe, enabling us to extract and analyze spoken content with accuracy. Although we do not use it in WavePulse, we can use it to separate music from speech content. Audio Segmentation. The process begins with the loading of the audio file into our system. Once loaded, the audio data is converted into numpy array, allowing for manipulation and analysis. The system then employs segmentation approach, dividing the audio into fixed-length chunks with specified overlap between consecutive segments. This segmentation is crucial for analyzing smaller portions of the audio stream, enabling us to capture specific speech events with precision. The overlap between segments plays role in ensuring continuity and preventing the loss of important speech elements that might occur at segment boundaries. For instance, in scenario with sample rate of 44.1 kHz, one-second audio segment would contain 44,100 data points. If we set the segment length to 5 seconds, each segment would encompass 220,500 samples. With an overlap of 2 seconds, each segment would share 88,200 samples with its predecessor, ensuring smooth transitions and coverage. MediaPipe AudioClassifier Implementation. Following the segmentation process, each audio chunk is passed through MediaPipes AudioClassifier. This step begins with the loading of pre-trained classification model, which we configure to return the top classification result for each segment, optimizing for accuracy and processing efficiency. Prior to classification, each segment undergoes normalization process. This involves dividing the audio values by the maximum possible value for 16-bit audio (32,767), ensuring that the input data falls within the appropriate range for the classifier. This normalization step is crucial for maintaining consistency and improving the accuracy of our speech detection. The classifier evaluates each normalized segment, generating classification results that include both labels and confidence scores. We implement quality control measure by considering segment as containing valid speech only if the classifier assigns it confidence score exceeding 0.80. This threshold helps minimize false positives and ensures the reliability of our speech detection. Final Audio File Compilation. After processing all segments, our system combines the identified speech-containing segments into single audio file. During this compilation, we remove the overlap between consecutive segments to avoid any duplication of audio data. This approach ensures that the final combined audio maintains continuity without repeating any part of the speech, resulting in streamlined audio file containing only the relevant speech segments. ArXiv, Preprint, Under Review Mittal et al. Table 2: List of successfully streamed Radio Stations along with their location. Call Sign Location Call Sign Location Call Sign Location WACV WLBF KAGV KFNP KVNT KFNN KVOI KARV KOMT KURM KCAA KMET KPAY KSAC KYOS KGLN KPPF WDRC WICC WDEL WIHW WFED PRNN WDCF WFTL WNDB WPIK WWPR WYOO WDUN WJRB WLBB WSBB KANO KKCR KIDG WCGO WCPT WDWS WLUW WRPW WTAD WZUS WGCL WTRC KMA KXEL KIUL KSAL KWBW WHIR KFXZ WAVH WQSI KBKO KGSM KAWC KFNX KVWM KBEU KRZP KAHI KCNR KMYC KPRL KSCO KDGO Coosada, AL Montgomery, AL Big Lake, AK North Pole, AK Eagle River, AK Mesa, AZ Cortaro, AZ Russellville, AR Lakeview, AR Rogers, AR Loma Linda, CA Banning, CA Chico, CA Olivehurst, CA Merced, CA Glenwood Springs, CO KLZ KRDO Monument, CO WFOX Hartford, CT WLAD Bridgeport, CT WGMD Wilmington, DE WVCW Dover, DE WPFM Washington, DC WBOB Pensacola, FL WELE Dade City, FL WHBO West Palm Beach, FL WNRP Daytona Beach, FL WPSL Summerland Key, FL WWTK Bradenton, FL WCHM Springfield, FL WFOM Gainesville, GA Young Harris, GA WKWN CaWAUBrrollton, GA WRGA WVGA Doraville, GA KHJC Hilo, HI KAOX Hanalei, HI KOUW Shelley, ID WCIL Evanston, IL WCRA Willow Springs, IL WGGH Champaign, IL WMAY Chicago, IL WSDR Colfax, IL WTIM Quincy, IL WBIW Macon, IL WGL Bloomington, IN KBIZ Elkhart, IN KOKX Shenandoah, IA KGGF Waterloo, IA KLWN Garden City, KS KSCB Salina, KS KWKN Hutchinson, KS WKCT Danville, KY KSYL Lafayette, LA WGSV Daphne, AL WTLS Union Springs, AL KFAR Kodiak, AK KSRM Saint Marys, AK KDJI Yuma, AZ KQNA Cave Creek, AZ KYCA Show Low, AZ KBTM Bearden, AR KUAR Gassville, AR KBLA Auburn, CA KINS Shasta, CA KOMY Marysville, CA KQMS Paso Robles, CA KVTA Santa Cruz, CA KFKA Durango, CO Denver, CO KNFO Colorado Springs, CO KVFC Southport, CT Danbury, CT Reho. Beach, DE Wilmington, DE Washington, DC Jacksonville, FL Ormond Beach, FL Pinellas Park, FL Pensacola, FL Port Saint Lucie, FL Lake Placid, FL Clarkesville, GA Marietta, GA Trenton, GA Rome, GA Lakeland, GA Lihue, HI Shelley, ID Island Park, ID Carbondale, IL Effingham, IL Marion, IL Taylorville, IL Sterling, IL Assumption, IL Bedford, IN Fort Wayne, IN Ottumwa, IA Keokuk, IA Coffeyville, KS Lawrence, KS Liberal, KS Wakeeney, KS Bowling Green, KY Alexandria, LA WGCH WSTC WHMS WCSP WTOP WDBO WFSX WKEZ WNZF WWBA WXJB WDJY WGAC WLAQ WRWH WVOP KIHL KBOI WBGZ WCMY WDAN WJPF WMBD WSOY WTRH WFDM WIMS KFJB KWBG KINA KQAM KVGB WDOC WZXI KWLA Guntersville, AL Tallassee, AL Fairbanks, AK Soldotna, AK Holbrook, AZ Prescott Valley, AZ Presott, AZ Jonesboro, AR Little Rock, AR Santa Monica, CA Blue Lake, CA La Selva Beach, CA Redding, CA Ventura, CA Greeley, CO Basalt, CO Cortez, CO Greenwich, CT Stamford, CT Pine Creek, DE Washington, DC Washington, DC Orlando, FL Estero, FL Tavernier, FL Bunnell, FL Largo, FL Homosassa, FL Dallas, GA Harlem, GA Rome, GA Cleveland, GA Vidalia, GA Hilo, HI New Plymouth, ID Alton, IL Ottawa, IL Danville, IL Herrin, IL Peoria, IL Decatur, IL Ramsey, IL Franklin, IN Michigan City, IN Marshaltown, IA Boone, IA Salina, KS Wichita, KS Great Bend, KS Prestonsburg, KY Lancaster, KY Anacoco, LA WavePulse: Real-time Content Analytics of Radio Livestreams ArXiv, Preprint, Under Review Table 3: List of successfully streamed Radio Stations along with their location (continued). Call Sign Location Call Sign Location Call Sign Location WBOK WMEA WFMD WNBP WBRN WKHM WMIC WSJM KKBJ KROX WZFG WYAB KRMS KSWM KTUI KZIM KAFH KBGA KINX KLIN KOLT KAVB KLNR WNTK WFJS WVBV KINN KRSY WATN WFME WGVA WLNL WRHU WVBN WBT WHKY WRHT WTIB WDAY WHIO WLYV KCLI KQOB KWON KBND KFLS KPNW KVBL WATS WEEU WPSN WEGP New Orleans, LA Portland, ME WBAL WBNW Frederick, MD Newburyport, MA WSAR WCXI Big Rapids, MI WKNW Jackson, MI Sandusky, MI WMPL Benton Harbor, MI WTCM Bemidji, MN KLTF Crookston, MN KTRF Dilworth, MN WMXI Pocahontas, MS KFMO Osage Beach, MO KRTK Aurora, MO KTRS KWOC Sullivan, MO Cape Girardeau, MO KZRG KALS Great Falls, MT KBMC Missoula, MT KJJR Fairfield, MT KODY Lincoln, NE KRGI Terrytown, NE KELY Hawthorne, NV KNCC Panaca, NV WTSN New London, NH WFMU Trenton, NJ KEND Medford Lakes, NJ KKOB Alamogordo, NM KSVP Alamogordo, NM WAUB Watertown, NY WGBB Garden City, NY WJJF Geneva, NY WLVL Horseheads, NY WTBQ Hempstead, NY WWSK Bronxville, NY WEEB Charlotte, NC Hickory, NC WNOS Morehead City, NC WSJS KNOX Willamston, NC WCBE Fargo, ND WHTX Dayton, OH WNIR Bellaire, OH KGWA Cordell, OK KRMG Enid, OK WBBZ Bartlesville, OK KBNP Bend, OR KGAL Klamath Falls, OR KSLM Eugene, OR KWRO Union, OR WBVP Sayre, PA WFYL Reading, PA WRSC Honesdale, PA WLOB Presque Isle, ME WCBM Baltimore, MD WGAW Concord, MA WAAM Fall River, MA Fenton, MI WIOS Sault Sainte Marie, MI WLDN WPHM Hancock, MI KBRF Traverse City, MI KNSI Little Falls, MN KXRA Thief River Falls, MN WVBG Ellisville, MS KICK Flat River, MO KSIM Hermann, MO KTTR Saint Louis, MO KWPM Poplar Bluff, MO KZYM Joplin, MO KAPC Kalispell, MT KCAP Bozeman, MT KGFW Whitefish, MT KOIL North Platte, NE WJAG Grand Island, NE KKFT Ely, NV WEMJ Elko, NV WUVR Dover, NH WOND East Orange, NJ KENN Roswell, NM KOBE Albuquerque, NM KXKS Artesia, NM WBAI Auburn, NY WGDJ Freeport, NY WKCR Montauk, NY WNYU Lockport, NY WUTQ Warwick, NY WYSL Smithtown, NY WGNC Southern Pines, NC WOBX New Bern, NC WSPC Winston-Salem, NC KTGO Grand Forks, ND WDBZ Columbus, OH WINT Warren, OH WYOH Kent, OH KGYN Enid, OK KTLR Tulsa, OK KAGO Ponca City, OK KFIR Portland, OR KMED Lebanon, OR KUMA Salem, OR KYKN Coquille, OR WCED Beaver Falls, PA WKHB King of Prussia, PA WRTA Bellefonte, PA Portland, ME Baltimore, MD Gardner, MA Ann Arbor, MI Tawas City, MI Ludington, MI Port Huron, MI Fergus Falls, MN Saint Louis, MN Alexandria, MN Vicksburg, MS Springfield, MO Sikeston, MO Saint James, MO West Plains, MO Joplin, MO Butte, MT Helena, MT Kearney, NE Omaha, NE Norfolk, NE Gardnerville-Minden, NV Laconia, NH Lebanon, NH Pleasantville, NJ Farmington, NM Las Cruces, NM Albuquerque, NM New York, NY Rensselaer, NY New York, NY New York, NY Utica, NY Avon, NY Gastonia, NC Wanchese, NC Albemarle, NC Tioga, ND Cincinnati, OH Willoughby, OH Niles, OH Guymon, OK Oklahoma City, OK Klamath Falls, OR Sweet Home, OR Eagle Point, OR Pendleton, OR Keizer, OR Du Bois, PA Irwin, PA Altoona, PA ArXiv, Preprint, Under Review Mittal et al. Table 4: List of successfully streamed Radio Stations along with their location (continued). Call Sign Location Call Sign Location Call Sign Location WTRW WNPE WCRS WRHI KAUR KWAM WENO WUCT KKSA KRFE KZHN KBJA KOAL KVNU WJPL WVMT WGMN WLNI WRAD KELA KITZ KNWN KOZI KVI WRNR KFIZ WFHR WMDX WXCO KVOW WURD Carbondale, PA Narragansett Pier, RI WSJW WDXY Greenwoord, SC Rock Hill, SC WRNN KELQ Sioux Falls, SD WBFG Memphis, TN Nashville, TN WGNS KBST Algood, TN San Angelo, TX KLVT KWEL Lubbock, TX Paris, TX KZHN KJJC Sandy, UT Price, UT KSGO WBTN Logan, UT WJSY Barre, VT WCHV Burlington, VT WIQO Roanake, VA WMNA Lynchburg, VA WRCW Radford, VA Centralia-Chehalis, WA KGDC KKNW Silverdale, WA KODX Seattle, WA KSBN Chelan, WA KXLY Seattle, WA WSCW Martinsburg, WV Fond Du Lac, WI WAUK Wisconsin Rapids, WI WISS Columbus, WI Wausau, WI Riverton, WY WSAU KBUW WEAN Philadelphia, PA WAIM Pawtucket, RI WFRK Sumter, SC WTKN Socastee, SC Flandreau, SD KOTA Parkers Crossroads, TN WCMT WHUB Murfreesboro, TN KCRS Big Spring, TX KRDY Levelland, TX KXYL Midland, TX WTAW Paris, TX KMXD Murray, UT KSVC Saint George, UT WCKJ Bennington, VT WMTZ Newport, VT WFJX Charlottesville, VA WJFV Forest, VA WNIS Gretna, VA KEDO Warrenton, VA KGTK Walla Walla, WA KLCK Seattle, WA KONP Seattle, WA KTEL Spokane, WA WMOV Spokane, WA South Charleston, WV WWNR WCLO Jackson, WI WLCX Berlin, WI WTAQ Rudolph, WI KROE Buffalo, WY Wakefield-Peacedale, RI Anderson, SC Quinby, SC Murrells Inlet, SC Rapid City, SD Martin, TN Cookeville, TN Midland, TX San Antonio, TX Brownwood, TX College Station, TX Monroe, UT Richfield, UT Saint Johnsbury, VT Rutland, VT Roanake, VA Portsmouth, VA Norfolk, VA Longview, WA Olympia, WA Goldendale, WA Port Angeles, WA Walla Walla, WA Ravenswood, WV Beckley, WV Janesville, WI La Crosse, WI Glenmore, WI Sheridan, WY"
        }
    ],
    "affiliations": [
        "Georgia Institute of Technology Atlanta, GA, USA",
        "New York University Tandon School of Engineering Brooklyn, NY, USA",
        "The Carter Center Atlanta, GA, USA"
    ]
}