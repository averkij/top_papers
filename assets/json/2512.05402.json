{
    "paper_title": "Smart Timing for Mining: A Deep Learning Framework for Bitcoin Hardware ROI Prediction",
    "authors": [
        "Sithumi Wickramasinghe",
        "Bikramjit Das",
        "Dorien Herremans"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Bitcoin mining hardware acquisition requires strategic timing due to volatile markets, rapid technological obsolescence, and protocol-driven revenue cycles. Despite mining's evolution into a capital-intensive industry, there is little guidance on when to purchase new Application-Specific Integrated Circuit (ASIC) hardware, and no prior computational frameworks address this decision problem. We address this gap by formulating hardware acquisition as a time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) >= 1), marginal (0 < ROI < 1), or unprofitable (ROI <= 0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multi-scale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet baselines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers a practical, data-driven tool for timing mining hardware acquisitions, potentially reducing financial risk in capital-intensive mining operations. The model is available through: https://github.com/AMAAI-Lab/MineROI-Net."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 ] . [ 1 2 0 4 5 0 . 2 1 5 2 : r Smart Timing for Mining: Deep Learning Framework for Bitcoin Hardware ROI prediction Sithumi Wickramasinghe , Bikramjit Das , Dorien Herremans Singapore University of Technology and Design, Singapore Abstract. Bitcoin mining hardware acquisition requires strategic timing due to volatile markets, rapid technological obsolescence, and protocoldriven revenue cycles. Despite minings evolution into capital-intensive industry, there is little guidance on when to purchase new ApplicationSpecific Integrated Circuit (ASIC) hardware, and no prior computational frameworks address this decision problem. We address this gap by formulating hardware acquisition as time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) 1), marginal (0 < ROI < 1), or unprofitable (ROI 0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multiscale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet baselines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers practical, data-driven tool for timing mining hardware acquisitions, potentially reducing financial risk in capital-intensive mining operations. The model is available through https://github.com/AMAAI-Lab/MineROI-Net. Keywords: Bitcoin Mining Deep Learning Decision Making Hardware acquisition DeFi."
        },
        {
            "title": "Introduction",
            "content": "Bitcoin mining has become an industrial-scale activity requiring substantial investment in specialized hardware and energy infrastructure, where miners must strategically time hardware acquisition amid volatile markets, rapid technological obsolescence, and protocol-driven revenue cycles. Despite minings evolution into multi-billion-dollar industry critical to securing the Bitcoin network, the strategic timing of hardware purchases remains poorly understood. This paper addresses this gap by developing deep learning framework that predicts mining hardware profitability outcomes, enabling data-driven timing decisions. Corresponding author: sithumi_wickramasinghe@mymail.sutd.edu.sg 2 S. Wickramasinghe et al. Bitcoins proof-of-work consensus [16] requires miners to repeatedly compute SHA-256 hash values using specialized hardware, ASICs (Application Specific Integrated Circuits), until hash satisfies the networks difficulty target, effectively converting electrical energy into probabilistic chances of earning block rewards and transaction fees. Mining profitability depends on Bitcoins price, network difficulty, hardware efficiency, and electricity costs [9,13]. The protocols halving events, which cut block reward by 50% every four years [16], introduce cyclical revenue shocks that fundamentally impact investment timing. Empirical studies show that miners often anticipate halvings by upgrading equipment or scaling operations ahead of reward reductions [13]. The consequences of poorly timed hardware investments can be severe and long-lasting. Industry analyses show that miners who bought Antminer S19j Pro hardware during the 2021 bull market saw their expected payback period swell from approximately 13 months to around 107 months after mining margins collapsed [8]. Such miscalculations can render entire operations economically unviable, as operators continue paying electricity costs while hardware depreciates and newer, more efficient models enter the market. While prior research has examined mining efficiency optimization and hardware sale timing [14], the complementary question of when to acquire new hardware has received little attention. Without data-driven frameworks, miners often enter markets when conditions are least favourable, amplifying risk through pro-cyclical investment behaviour. To address this, we formulate mining hardware acquisition as multi-class time series classification problem. We construct comprehensive dataset covering 20 ASIC mining machine types from 2015 to 2024, integrating machine-specific attributes, Bitcoin market and price indicators, and Bitcoin network-level variables. We train and evaluate models that are based on the Long-short term memory (LSTM) [11], Transformer [21], and TSLANet [5] architectures, to classify whether hardware purchase on given day yields profitable return (ROI 1), moderate return (0 < ROI < 1), or negative return (ROI 0) within 365 day horizon. This multi-class data-driven framework enables actionable decision support for mining operators by predicting profitability outcomes. Our main contributions are as follows: (i) We introduce the novel task of Bitcoin mining hardware acquisition timing, framing it as multi-class time series classification problem; (ii) to enable this new task, we propose method for collating unique dataset from various sources, making it aptly suited for studying mining economics; and finally, (iii) we propose the MineROI-Net model that achieves 83.7% accuracy with 93.6%/98.5% precision for unprofitable/profitable predictions and was benchmarked against an LSTM-based baseline and TSLANet architectures. The remainder of this paper is organized as follows: first, in Section 2 we review related work, then, in Section 3 we detail our approach and model, followed by our experimental setup and results in Section 4 and Section 5. Finally, Section 6 offers conclusion. Deep Learning Framework for Bitcoin Hardware ROI prediction"
        },
        {
            "title": "2 Related work",
            "content": "Research on Bitcoin mining profitability has primarily focused on cost structure and market dynamics. According to industry analysis, electricity represents between 70% and 90% of operational costs for most Bitcoin mining operations [20]. Delgado et al. [4] showed that by mid-2018, mining became unprofitable for commodity miners paying above $0.14/kWh, driving geographic concentration toward low-cost regions such as China, Iran, Russia, and Ethiopia. Ethiopia has recently attracted attention for its mining industry with hydroelectricity rates as low as 3.2 cents per kWh [3]. Beyond cost analysis, researchers have developed dynamic economic models of the mining industry. Haliplii et al.[7] applied real option theory to simulate rewards and breakeven probabilities, revealing that miners failed to adjust to price signals after the 2017 bitcoin bubble. More recently, Prayoga et al.[18] employed boosting ensembles to predict daily mining device income using 60 days of market and machine-level data for 70 ASIC machines released between 2020 and 2024. However, this work predicts continuous revenue without incorporating hardware purchase prices, ROI horizons, or geographical electricity variability. Deep learning models excel at capturing temporal dependencies in volatile financial domains where traditional ARIMA models struggle. Long Short-Term Memory (LSTM) networks have become baseline architectures for cryptocurrency forecasting due to their capacity for sequential modelling [23]. Seabe et al.[19] compared LSTM variants, finding that Bi-LSTM yields lower prediction errors across multiple cryptocurrencies, while Chen and Zheng [2] employed multi-task LSTM networks for joint price forecasting and portfolio optimization. Hybrid architectures like MRC-LSTM [6] combine multiscale residual CNNs with LSTM for enhanced bitcoin price prediction. The PreBit model [26] combines FinBERT-based tweet embeddings with price and technical data through CNNSVM architecture to predict extreme Bitcoin price fluctuations. Transformer architectures further advance this trend through the self-attention mechanism, which captures long-range dependencies [21]. Herremans and Lows Synthesizer Transformer [10] that is able to predict volatility spikes, also demonstrates transformer-based models superiority over traditional econometric baselines. Recent CNN-transformer hybrids aim to balance expressiveness with robustness. TSLANet (Time Series Lightweight Adaptive Network) [5] is one notable work which exemplifies this approach, combining Adaptive spectral blocks with Interactive convolution blocks to capture both long-term and short-term patterns. On benchmark time-series classification and forecasting datasets, it outperforms or matches state-of-the-art models in accuracy, parameter efficiency, and robustness across noise levels. Prior research mostly focuses either price forecasting or directional prediction, no research has approached hardware purchase timing as classification problem. Using historical data, our model predicts one-year ROI to evaluate hardware acquisition timing before capital commitment, transforming profitability analysis into actionable decision support. 4 S. Wickramasinghe et al."
        },
        {
            "title": "3 Approach and model",
            "content": ", yM We formulate the Bitcoin mining hardware acquisition timing problem as multiclass time series classification task. Given sequence of historical observations up to day di, the objective is to predict the one-year Return on Investment (ROI) category for purchasing specific mining machine on that day. Let = RLF represents multivariate {(X time series window of length (look-back period) with features, yM {0, 1, 2} is the discrete ROI label for purchasing machine on day di and is the total contains the past Lnumber of samples (time windows). Each sequence day window of machine-specific attributes, market indicators, and network-level features up to day di. These features are discussed in more detail in Section 4.1. denote our dataset, where )}N i="
        },
        {
            "title": "3.1 ROI calculation and class labeling",
            "content": "The one-year (365 days) Return on Investment (ROI) is computed as in Eq. (1), where R(M, di, 365) is the cumulative mining revenue generated by machine over 365 days from purchase date di. ROI(M, di) = R(M, di, 365) CO(M, di, 365) CM (M, di) (1) Note that we assume that the miners sell their Bitcoin balance daily, and hence keep track of the revenue in USD. In future work, it would be interesting to explore different Bitcoin exchange strategies. The cumulative operational cost (primarily electricity) over the same period is denoted as CO(M, di, 365), and CM (M, di) represents the capital cost (purchase price) of machine on day di. The daily electricity cost was computed as (PM 24/1000) re, where PM denotes the power consumption of machine in watts and re is the electricity rate-USD/kWh .We discretize the continuous ROI values into three economically meaningful categories: yi = 0 : unprofitable, ROI(M, di) 0, 1 : marginal, 2 : profitable, ROI(M, di) 1 . 0 < ROI(M, di) < 1, (2) This three-class formulation provides actionable investment guidance: class 0 indicates unprofitable purchases failing to recover capital costs, class 1 represents marginal investments with partial capital recovery, and class 2 identifies profitable opportunities achieving full capital recovery with an ROI of 100% or more within year."
        },
        {
            "title": "3.2 Proposed model architecture",
            "content": "To predict the ROI of Bitcoin Mining machine purchased at certain time, it is essential to account for temporal dependencies, regime shifts, and multi-scale Deep Learning Framework for Bitcoin Hardware ROI prediction 5 patterns that span from daily fluctuations to multi-year cycles. Hence, deep learning models are better suited compared to traditional methods. We propose unified deep learning architecture for mining hardware ROI prediction, which we term MineROI-Net. Given an input sequence RBLF , where is batch size, {30, 60} is the look-back window in days, and is the number of features, this model processes sequences through three main components as shown in Figure 1: the Spectral Feature Extractor, the Channel Mixing module and the Transformer Encoder. Fig. 1: MineROI-Net architecture overview. Spectral Feature Extractor Bitcoin mining profitability exhibits cyclical patterns from halving events, difficulty adjustments, and market dynamics. Standard Transformer encoders process data point-wise in the time domain, making it difficult to capture these long-range periodic patterns. Following FEDformer [25] and FreTS [22], which demonstrate superior performance on periodic time series benchmarks , we employ Fast Fourier Transform (FFT)-based layer with learnable complex weights CF (one per feature) to adaptively enhance or suppress key frequency components: Xspectral = IFFT(cid:0)FFT(XT ) W(cid:1)T RBLF , (3) where denotes element-wise multiplication that broadcasts each weight across all frequency bins of its corresponding feature, and inverse FFT returns to the time domain. This provides explicit frequency representation of periodic patterns, enabling more efficient learning than implicit cycle modelling. Channel Mixing Module To capture cross-feature interactions that vary across regimes (e.g., price vs. electricity cost dominance), we employ channel mixing module inspired by Squeeze-and-Excitation networks [12]. Unlike cross-attention that computes pairwise feature interactions, this mechanism compresses temporal information via global average pooling, learns channel-wise S. Wickramasinghe et al. attention weights through bottleneck network, and re-weights features accordingly. Recent work has demonstrated that efficient channel-mixing architectures can achieve competitive performance compared to attention mechanisms in time series forecasting [1,17]. ="
        },
        {
            "title": "1\nL",
            "content": "L (cid:88) t=1 Xspectral[:, t, :] RBF , = W2 GELU(W1z) RBF (4) The mixed output is then computed as Xmixed = Xspectral s, where W1 R(F/r)F and W2 RF (F/r) are learnable projection matrices with reduction ratio = 4. This adaptive re-weighting emphasizes relevant features based on the current sequence context. Transformer Encoder Processed features Xmixed are first mapped to the model dimension dmodel using position-wise fully connected (FC) layer and then augmented with sinusoidal positional encodings (PE) [21]. Z0 = FC(Xmixed) + PE RBLdmodel (5) is then passed through stacked Transformer blocks, each consisting of multihead attention, feed-forward layer, and LayerNorm with residual connections. Classification and Training. The encoder output is then aggregated via global average pooling and passed through two-layer fully connected classification head to predict the three ROI classes. The model is trained using weighted cross-entropy loss with label smoothing. L(θ) ="
        },
        {
            "title": "1\nN",
            "content": "N (cid:88) 3 (cid:88) i=1 c=1 wc yi,c log pi,c ; where yi,c = (1 ε) yi,c + ε/3 (6) where is the number of training samples, indexes individual samples, indexes the three ROI classes, wc are class weights computed via inverse frequency, yi,c is the smoothed target label with ε = 0.1, and pi,c is the predicted probability for sample and class c."
        },
        {
            "title": "4.1 Dataset",
            "content": "We have collated dataset that spans from October 2015 to September 2024, thus covering multiple complete market, hash cycles as well as hardware generations. We integrate daily data from three sources to obtain total of 14 features: Deep Learning Framework for Bitcoin Hardware ROI prediction 7 1. ASIC Machine-data1 for 20 machines: Specification (hashrate, power requirements, efficiency, days since release date) and purchase price at various times. The machines include the Antminer S-series (S7, S9, S15, S17 Pro, S19 variants, S21), T-series (T17, T19), WhatsMiner M-series (M10s-M53), and AvalonMiner KA3. 2. Blockchain Data2: Bitcoin price, difficulty, network hashrate, network revenue, block reward, and transaction fees. 3. Energy prices3: Electricity rates for Ethiopia, China, and Texas. Critically, we also included days since the previous halving to track Bitcoins halving cycles and miners daily revenue potential. To ensure temporal validity and prevent data leakage, all 14 features at day di use only information available at or before di. Features are MinMax normalized, with the scaler fitted on the training split and applied unchanged to the validation and test splits."
        },
        {
            "title": "4.2 Baseline models.",
            "content": "We benchmark the proposed MineROI-Net against two benchmark models: an architecture based on LSTM and state-of-the-art TSLANet [5] model. We opted for these two benchmark models as they have shown good performance on similar tasks like stock predictions [24,5]. The LSTM-based architecture, developed as part of this work, employs the same spectral and channel-mixing feature extraction modules as the proposed MineROI-Net, followed by stacked LSTM layers and fully connected classification heads. This allows us to evaluate whether differences in performance arise from the LSTM-based versus attentionbased backbones rather than the input representation. In the second benchmark model, we use TSLANets original architecture. All models were trained with batch size of 64 for up to 20 epochs using the AdamW [15] optimizer (weight decay 0.00001)."
        },
        {
            "title": "4.3 Rolling cross-validation strategy and hyperparameter search",
            "content": "We adopt an expanding window strategy with cross-validation across diverse market regimes to preserve temporal causality and test generalization (see Figure 2(a)). The training data expands progressively through three validation phases: bear market (Split 1), range-bound market (Split 2), and bull market (Split 3), using all preceding data. The final test set (June 2023September 2024) remains unseen until after the hyperparameter selection. This contains 39.7% unprofitable, 27.6% marginal, and 32.7% profitable samples, reflecting moderate imbalance, which is handled by using class weights in the loss. 1 https://data.hashrateindex.com/asic-index-data/price-index https://camelcamelcamel.com/search?sq=antminer 2 https://www.blockchain.com/ 3 https://www.kaggle.com/datasets/alistairking/electricity-prices https://www.globalpetrolprices.com/electricity_prices/ S. Wickramasinghe et al. Fig. 2: Expanding window cross-validation strategy across market regimes. We performed hyperparameter optimization across the first three validation splits, evaluating 81 configurations for LSTM-baseline, 81 for TSLANet, and 144 for MineROI-Net. The best-performing configuration4 (in terms of macro F1-score) was retrained on the full training period (October 2015June 2023)."
        },
        {
            "title": "5.1 Performance across market regimes",
            "content": "Using 30-day look-back window, models were first trained with rolling expanding training set (Splits 1-3, as shown in Figure 2(a)) to evaluate the models performance across different market regimes (Figure 2(b,c,d)). Table 1 presents the validation results for each split under the configuration identified as bestperforming across the three validation splits during hyperparameter tuning. Since the training data is substantially reduced to create rolling validation sets representing various market types, performance is expected to be lower than the final results; nevertheless, it still provides valuable insights. The three validation splits cover bear (Split 1), range-bound (Split 2), and bull (Split 3) market regimes, exposing the models to different ROI drivers under varying conditions. As shown in Table 1, MineROI-Net achieves the highest average performance with 30-day window (0.681 0.024 accuracy, 0.562 0.114 F1), demonstrating more stable behaviour across market conditions. TSLANet demonstrates competitive accuracy and F1-score (0.647 0.138, 0.545 0.197), but exhibits high variance, performing well in bull markets while dropping sharply in range-bound periods. The LSTM-baseline also performs competitively with comparable stability and consistent results across three splits. Next, we train on the full training 4 30-day:LSTM-b:h=16, nl=2, lr=1e4, d=0.3; TSLANet: emb=32, depth=4, lr=1e 5, d=0.1; MineROI-Net: dm=64, nhead=2, nl=2, lr=1e4, d=0.2, dimf =256. 60-day:LSTM-b: h=16, nl=2, lr=1e4, d=0.3; TSLANet: emb=8, depth=6, lr=5e 5, d=0.3; MineROI-Net: dm=64, nhead=4, nl=2, lr=1e4, d=0.2, dimf =256. (h: heads, nl: layers, lr: learning rate d: dropout, emb: embedding dim, dm: model dim, dimf : feed forward dimension) Deep Learning Framework for Bitcoin Hardware ROI prediction 9 Table 1: Accuracy and macro F1-score on validation splits with 30-day and 60day look-back windows (mean std over 5 runs). Window Model Accuracy Macro F1-score Split 1 Split 2 Split 3 Avg Std Split 1 Split 2 Split 3 Avg Std 30-day 60-day LSTM-Baseline 0.649 0.708 0.623 0.6600.043 0.420 0.648 0.586 0.5510.118 TSLANet 0.645 0.510 0.786 0.6470.138 0.410 0.455 0.771 0.5450.197 MineROI-Net 0.662 0.709 0.673 0.6810.024 0.442 0.575 0.668 0.5620.114 LSTM-Baseline 0.644 0.684 0.574 0.6340.056 0.428 0.601 0.477 0.5020.089 0.632 0.470 0.795 0.6330.162 0.394 0.438 0.789 0.5400.216 TSLANet MineROI-Net 0.658 0.637 0.659 0.6510.012 0.441 0.584 0.639 0.5550.102 set, which encompasses mix of volatile, bear, and bull markets, and evaluate on the final test split (June 2023 to September 2024)."
        },
        {
            "title": "5.2 Performance on final split",
            "content": "After selecting optimal hyperparameters via cross-regime validation, each model was retrained on the final full training split and evaluated on the unseen test set(Figure 2(e)). We report overall accuracy and macro-averaged F1 score, computed by averaging the F1-score over the three classes. All values in Table 2 are the mean standard deviation over five random seeds. MineROI-Net achieves the strongest and most stable test performance, outperforming both the LSTMbaseline and TSLANet in terms of accuracy (0.837 0.044) and macro F1-score (0.831 0.048). The LSTM-baselines weaker results suggest that it struggles to capture the complex, multi-scale temporal dependencies present in mining profitability data. The window-size analysis is discussed next in Section 5.3. Table 2: Test-set performance for models (accuracy and macro f1-score) with 30-day and 60-day look-back windows (mean std over 5 runs). Model Look-back window 30 Look-back window 60 Accuracy (AvgStd) F1 (AvgStd) Accuracy (AvgStd) F1 (AvgStd) LSTM-Baseline TSLANet MineROI-Net 0.457 0.068 0.758 0.036 0.837 0.044 0.417 0.063 0.748 0.038 0.831 0.048 0.394 0.081 0.650 0.070 0.814 0.043 0.341 0.106 0.631 0.086 0.802 0.047 5. Influence of look-back window To investigate whether longer historical context improves prediction quality, we conducted an ablation study with 60-day look-back window, which captures 10 S. Wickramasinghe et al. approximately two months of market dynamics. We first explored the performance on the smaller splits with various market conditions. Table 1 shows that extending to 60-day (input) window generally reduces performance across all models. The LSTMs accuracy drops from 0.660 to 0.634, while TSLANets accuracy decreases from 0.647 to 0.633, with strong bull market performance (0.795) but poor range-bound results (0.470). The MineROI-Net model drops from 0.681 to 0.651, indicating that across diverse market regimes, longer sequences introduce noise that the attention mechanism struggles to filter. In addition, the dataset might not be large enough to enable proper training of the model with long input window. These validation results indicate that 30-day windows provide superior regime-invariant performance. Finally, on the final test split, the same procedure was followed as for the 30-day split: after selecting optimal hyperparameters through cross-validation, each model was retrained on the full training set and evaluated on the unseen test set across five random seeds  (Table 2)  . Extending to 60-day windows reduces performance across all models. MineROI-Nets accuracy drops from 0.837 to 0.814, TSLANet from 0.758 to 0.650, and LSTM-baseline from 0.457 to 0.394. These results suggest that longer sequences add noise and weaken ROI-relevant signals. Overall, MineROI-Net with 30-day window achieves the strongest and most stable results (0.837 0.044 accuracy, 0.831 0.048 macro F1), making it the best-performing configuration for predicting mining hardware ROI. (a) 30-day look-back window (b) 60-day look-back window Fig. 3: Confusion matrices for MineROI-Net. Figures 3a and 3b show the confusion matrices for the MineROI-Net model with 30and 60-day windows, and the corresponding class-wise metrics are reported in Table 3 (for seed=42). The model performs particularly well in detecting unprofitable (class 0) scenarios. For this class, it achieves exceptional precision (>0.930) and strong recall (0.80), reliably flagging risky purchases for both 30and 60-day windows. For class 2, the model achieves high precision (0.985 Deep Learning Framework for Bitcoin Hardware ROI prediction Table 3: Per-class precision, recall, F1-score, and AUC for MineROI-Net model with 30-day and 60-day look-back windows on test set. Look-back window 30 Look-back window 60 Class Precision Recall F1-score AUC Precision Recall F1-score AUC 0 (\"Unprofitable\") 1 (\"Marginal\") 2 (\"Profitable\") 0.936 0.744 0.985 0.803 0.903 0.977 0.864 0.816 0.981 0.980 0.921 0.997 0.937 0.880 0.686 0.794 0.603 0. 0.860 0.886 0.716 0.910 0.813 0.890 Macro Average 0.888 0.894 0.887 0.966 0.835 0.798 0.796 0.895 for 30-day, 0.686 for 60-day), with outstanding recall (0.977 for 30-day, 0.996 for 60-day), providing highly trustworthy buy signals with the 30-day window. The 30-day configuration achieves near-perfect performance for this critical class (F1-score: 0.981), effectively identifying profitable investment opportunities. Notably, with 30-day window, no profitable days are misclassified as unprofitable and vice versa (Figure 3a). For the 30-day window, class 1 (marginal) shows lower precision due to boundary overlap near decision boundaries but maintains high recall, effectively serving as an uncertainty buffer for ambiguous cases. Overall, the 30-day window pattern provides strong practical value: it accurately identifies clear avoid (unprofitable) and buy (profitable) scenarios, while marginal predictions serve as buffer that requires further human assessment. The ROC analysis further validates these findings: the 30-day window achieves balanced AUC (Area Under the Curve) scores across all classes (>0.90)  (Table 3)  , while the 60-day windows profitable and unprofitable classes AUC drops to below 0.90, indicating degraded ability to identify investment opportunities. Given its comparable performance and greater efficiency especially relevant for newly released machines with limited historical data, the 30-day window remains the preferred choice."
        },
        {
            "title": "6 Conclusion",
            "content": "This paper presents MineROI-Net, an open source data-driven model5 for predicting Bitcoin mining hardware ROI outcomes. To our knowledge, this is the first machine learning approach that directly addresses the timing of mining hardware investments, formulated as three-class classification problem (unprofitable, marginal, profitable). Evaluated on dataset covering 20 ASIC miners released between 2015 and 2024, MineROI-Net consistently outperforms LSTMbased and TSLANet baselines. Using 30-day look-back window, it achieves 83.7% accuracy and 83.1% macro F1 score. The model excels at economically critical decisions, reaching 93.6% precision for detecting unprofitable periods and 98.5% precision for profitable onesimportantly, without ever misclassifying profitable scenario as unprofitable and vice versa. Cross-regime validation 5 https://github.com/AMAAI-Lab/MineROI-Net 12 S. Wickramasinghe et al. further confirms that the model generalizes well across diverse market environments, quality reflected in the final test results. Our current formulation assumes daily Bitcoin selling when computing revenue, reflecting one standard operational strategy. natural direction for future work is to incorporate alternative selling behaviors (e.g., monthly selling or holding strategies), examine different investment horizons (such as 6or 18-month ROI), explore ensemble methods that combine multiple temporal windows, and extend the framework to additional cryptocurrency mining ecosystems. Overall, MineROI-Net offers clear practical value for capital-intensive mining decisions. It substantially improves over established baselines while maintaining high precision for risk-sensitive operations, providing reliable tool to support informed mining hardware investment timing. Acknowledgements. This work has received support from SUTDs Kickstart Initiative under grant number SKI 2021 04 06, MOE under grant number MOET2EP20124-0014. We acknowledge the use of ChatGPT for grammar improvements."
        },
        {
            "title": "References",
            "content": "1. Chen, S.A., Li, C.L., Yoder, N., Arik, S., Pfister, T.: Tsmixer: An all-mlp architecture for time series forecasting. Trans. Mach. Learn. Res. (2023) 2. Chen, W., Zheng, H.: Cryptocurrency price prediction and portfolio optimization via lstm and multitask nn. Quant. Finance Econ. 9(3), 658681 (2025) 3. CoinReporter.io: 18% of ethiopias electricity revenue from bitcoin mining. https: //www.coinreporter.io/2025/05/18-of-ethiopias-electricity-revenue-n ow-comes-from-bitcoin-mining-a-new-era-for-btc-and-the-global-grid/ (2025), accessed: 2025-10-12 4. Delgado-Mohatar, O., et al.: The bitcoin mining breakdown: Is mining still profitable? Econ. Lett. 184, 108492 (2019) 5. Eldele, E., et al.: Tslanet: Rethinking transformers for time-series representation learning. In: Proc. ICML. pp. 1240912428 (2024) 6. Guo, Q., et al.: Mrc-lstm: Multi-scale residual cnn-lstm for bitcoin prediction. In: Proc. IJCNN (2021) 7. Haliplii, R., et al.: To mine or not to mine? the bitcoin mining paradox. SSRN Preprint (2020) 8. Hashrate Index: Timing the market: Return of asic purchases at different dates in 2022 (2022), https://hashrateindex.com/blog/timing-the-market-analyzi ng-the-return-of-asic-purchases-at-different-dates-in-2022/, accessed: 2025-08-03 9. Hayes, A.: Cryptocurrency value formation: Cost-of-production model. Telemat. Inform. 34(7), 13081321 (2017) 10. Herremans, D., Low, K.: Forecasting bitcoin volatility spikes using synthesizer transformers. IEEE Access (2025) 11. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation 9(8), 17351780 (1997) 12. Hu, J., et al.: Squeeze-and-excitation networks. In: Proc. CVPR (2018) Deep Learning Framework for Bitcoin Hardware ROI prediction 13 13. Jablczynska, M., et al.: Energy and cost efficiency of bitcoin mining. PLoS One 18(3), e0283687 (2023) 14. Li, M., et al.: Sale timing of crypto miners. SSRN 4738619 (2024) 15. Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. In: Proc. ICLR (2019) 16. Nakamoto, S.: Bitcoin: peer-to-peer electronic cash system (2008) 17. Nie, Y., Nguyen, N.H., Sinthong, P., Kalagnanam, J.: time series is worth 64 words: Long-term forecasting with transformers. In: ICLR (2023) 18. Prayoga, D.S., et al.: Bitcoin mining profitability prediction via boosting algorithms. Indonesian J. Electron. Eng. Inform. 7(1), 167177 (2025) 19. Seabe, P., et al.: Forecasting cryptocurrency prices using lstm, gru, and bi-lstm. Fractal Fract. 7(2), 203 (2023) 20. Seo, S.: How energy prices impact bitcoin mining profits in australia (Jul 2025), https://www.miningstore.com.au/2025/07/energy-prices-bitcoin-mining-p rofitability/, accessed: 2025-11-11 21. Vaswani, A., et al.: Attention is all you need. NeurIPS 30 (2017) 22. Yi, K., et al.: Frequency-domain mlps are more effective learners in time series forecasting. Advances in Neural Information Processing Systems 36, 7665676679 (2023) 23. Zhang, J., et al.: Survey of deep learning applications in cryptocurrency. iScience 27(1) (2024) 24. Zhang, L., Aggarwal, C., Qi, G.J.: Stock price prediction via discovering multifrequency trading patterns. In: Proc. ACM SIGKDD. pp. 21412149 (2017) 25. Zhou, T., et al.: Fedformer: Frequency-enhanced decomposed transformer. In: Proc. ICML (2022) 26. Zou, Y., Herremans, D.: Prebit: Multimodal finbert-twitter model for bitcoin price prediction. Expert Syst. Appl. 233, 120838 (2023)"
        }
    ],
    "affiliations": [
        "Singapore University of Technology and Design, Singapore"
    ]
}