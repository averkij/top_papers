{
    "paper_title": "HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication",
    "authors": [
        "Heng Zhang",
        "Yuling Shi",
        "Xiaodong Gu",
        "Zijian Zhang",
        "Haochen You",
        "Lubin Gan",
        "Yilei Yuan",
        "Jin Huang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Recent advances in large language model-powered multi-agent systems have demonstrated remarkable collective intelligence through effective communication. However, existing approaches face two primary challenges: (i) \\textit{Ineffective group collaboration modeling}, as they rely on pairwise edge representations in graph structures, limiting their ability to capture relationships among multiple agents; and (ii) \\textit{Limited task-adaptiveness in communication topology design}, leading to excessive communication cost for simple tasks and insufficient coordination for complex scenarios. These issues restrict the scalability and practical deployment of adaptive collaboration frameworks. To address these challenges, we propose \\textbf{HyperAgent}, a hypergraph-based framework that optimizes communication topologies and effectively captures group collaboration patterns using direct hyperedge representations. Unlike edge-based approaches, HyperAgent uses hyperedges to link multiple agents within the same subtask and employs hypergraph convolutional layers to achieve one-step information aggregation in collaboration groups. Additionally, it incorporates a variational autoencoder framework with sparsity regularization to dynamically adjust hypergraph topologies based on task complexity. Experiments highlight the superiority of HyperAgent in both performance and efficiency. For instance, on GSM8K, HyperAgent achieves 95.07\\% accuracy while reducing token consumption by 25.33\\%, demonstrating the potential of hypergraph-based optimization for multi-agent communication."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 2 1 ]"
        },
        {
            "title": "A\nM",
            "content": ". [ 1 1 1 6 0 1 . 0 1 5 2 : r HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication Heng Zhang South China Normal University China 2024025450@m.scnu.edu.cn Yuling Shi Shanghai Jiao Tong University China yuling.shi@sjtu.edu.cn Xiaodong Gu Shanghai Jiao Tong University China xiaodong.gu@sjtu.edu.cn Zijian Zhang University of Pennsylvania USA zzjharry@alumni.upenn.edu Haochen You Columbia University USA hy2854@columbia.edu Lubin Gan University of Science and Technology of China China ganlubin@mail.ustc.edu.cn Yilei Yuan University of Michigan USA yiliey@umich.edu Jin Huang South China Normal University China huangjin@m.scnu.edu.cn Abstract Recent advances in large language model-powered multi-agent systems have demonstrated remarkable collective intelligence through effective communication. However, existing approaches face two primary challenges: (i) Ineffective group collaboration modeling, as they rely on pairwise edge representations in graph structures, limiting their ability to capture relationships among multiple agents; and (ii) Limited task-adaptiveness in communication topology design, leading to excessive communication cost for simple tasks and insufficient coordination for complex scenarios. These issues restrict the scalability and practical deployment of adaptive collaboration frameworks. To address these challenges, we propose HyperAgent, hypergraph-based framework that optimizes communication topologies and effectively captures group collaboration patterns using direct hyperedge representations. Unlike edge-based approaches, HyperAgent uses hyperedges to link multiple agents within the same subtask and employs hypergraph convolutional layers to achieve one-step information aggregation in collaboration groups. Additionally, it incorporates variational autoencoder framework with sparsity regularization to dynamically adjust hypergraph topologies based on task complexity. Experiments highlight the superiority of HyperAgent in both performance and efficiency. For instance, on GSM8K, HyperAgent achieves 95.07% accuracy while reducing token consumption by 25.33%, demonstrating the potential of hypergraph-based optimization for multi-agent communication. Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference17, Washington, DC, USA 2026 Copyright held by the owner/author(s). Publication rights licensed to ACM. Keywords Large Language Model, Multi-agent Systems, Multi-agent Communication, Graph Neural Networks"
        },
        {
            "title": "1 Introduction\nLarge language model-powered agents have demonstrated excep-\ntional capabilities across diverse tasks[6, 7, 52]. When multiple\nagents collaborate, their collective intelligence can surpass the\nperformance of individual agents[12, 17, 32]. The effectiveness\nof this collaboration depends on the design of communication\ntopologies[43, 77], which govern how information is exchanged and\nactions are coordinated among agents. Well-designed topologies\nallow information to flow efficiently, enabling agents to integrate\ntheir efforts and handle complex tasks such as problem solving and\ndecision making[53, 72]. Conversely, ineffective topologies increase\ncommunication inefficiency and hinder coordination[22, 42]. For\nexample, in software development, architects, programmers, and\ntesters must interact through structured communication to ensure\nsmooth workflows. As a result, optimizing communication topolo-\ngies to suit specific tasks has become a core focus in multi-agent\nsystem research[68].",
            "content": "Current research has explored various approaches to multi-agent topology design, resulting in several well-established paradigms. Static topology methods rely on predefined structures, such as chain, star, tree, and complete graph configurations, to ensure consistent task execution[43, 61, 64]. Template-based approaches modify existing graph structures by adding or removing edges to accommodate different scenarios[12, 77]. Optimization-driven methods use search algorithms to explore topology spaces and identify more effective configurations through iterative refinement[4, 71]. Recent developments have introduced dynamic approaches that adjust communication structures during task execution, aiming to balance performance and efficiency[14, 37, 74]. These methods share common foundation: agents are represented as graph nodes, and communication relationships are modeled as pairwise edges[5, 41]. Using degradation over intermediate steps. Additionally, this decomposition treats group interactions as emerging from separate edges, rather than unified structures. Algorithms then must infer these units, searching through an optimization space that grows quadratically with agent count. Hypergraphs overcome this limitation by treating collaborative units as first-class structures. hyperedge directly connects all agents in group, enabling unified information aggregation. All agents contribute to and receive from shared representation in single step, eliminating multi-hop delays and preserving semantic consistency. Moreover, hypergraphs reduce the optimization space from quadratic pairwise edges to linear collaborative units, allowing algorithms to directly work with meaningful structures rather than inferring them indirectly. Based on the above observations, we propose HyperAgent, hypergraph-based framework for optimizing communication topologies in multi-agent systems. HyperAgent models the system as hypergraph, where each hyperedge connects agents working on the same subtask, directly capturing group-level interactions. To process this structure, we introduce hypergraph convolutional layers that enable efficient information aggregation within collaboration units. For dynamic topology generation, HyperAgent uses variational autoencoder. The encoder transforms agent features and task information into latent representations, and the decoder constructs task-specific hypergraphs. Sparsity regularization controls the number of collaboration units, maintaining communication efficiency. This design allows HyperAgent to adapt topologies to task demands, creating sparse structures for simple tasks and denser ones for complex coordination. By balancing adaptability and efficiency, HyperAgent delivers robust solution for multi-agent communication. Our contributions can be concluded as: We observe that pairwise graph representations fail to capture multi-agent collaboration effectively. Existing methods force tradeoff between sparse topologies, which fragment coordination, and dense topologies, which increase communication overhead. We propose HyperAgent, hypergraph-based framework that uses hyperedges to represent group collaboration units. This representation enables direct synchronization within teams through unified node-edge-node transformations. We develop variational hypergraph autoencoder for taskadaptive topology generation. It encodes agent features and task semantics into latent representations and generates sparse hypergraphs, adjusting complexity according to task difficulty. Extensive experiments demonstrate HyperAgent outperforms state-of-the-art methods, achieving 88.50% accuracy on MMLU and 92.90% pass@1 on HumanEval, with up to 25.33% reduction in communication token consumption."
        },
        {
            "title": "2 Related Work\n2.1 LLMs-agent Collaboration\nLarge language models have driven a shift from single-agent to\ncollaborative multi-agent systems[6, 52]. Early works demonstrated\nthat multiple LLM-based agents working together can outperform",
            "content": "Figure 1: Comparison of communication topologies for multiagent collaboration. (a) Pairwise edges require multiple connections and multi-hop information propagation among agents. (b) Hyperedges enable direct one-step synchronization by connecting all collaborating agents within single structure. graph neural networks, these approaches learn connection patterns directly from task data[43, 60], enabling significant performance improvements in benchmarks such as code generation[10, 25], mathematical reasoning[54, 61], and question answering[1, 72, 78]. Despite their architectural variations, recent topology design methods share common foundation that limits scalability and efficiency. Approaches like G-Designer[31], GPTSwarm[77], and DyLAN[34] represent multi-agent systems as graphs, where agents are nodes and communication channels are modeled as edges. Our analysis of these methods on tasks with varying complexity in the MMLU benchmark reveals consistent trend: for simple tasks, such as basic multiple-choice questions, they naturally converge to sparse topologies, reducing unnecessary communication. However, as tasks grow more complex, these methods require denser topologies to maintain performance. For advanced reasoning tasks, effective configurations approach near-complete graphs to ensure sufficient information exchange, but this densification drives communication costs to scale quadratically with agent count, as every agent establishes edges with all others. More critically, graph-based representations can only model pairwise relationships, making it difficult to capture multi-agent collaborations as unified units. For example, three agents collaborating on the same subtask must be connected by multiple pairwise edges. This limitation forces topology design into tradeoff: sparse graphs reduce costs but fragment coordination, while dense graphs enable better communication but introduce high overhead. Existing methods tackle this balance differently, but the issue persists as consequence of graph-based modeling, not algorithmic choices. The core problem lies in how graph representations decompose collaborative units. Consider scenario in multi-agent problemsolving where mathematician derives formula, programmer implements it, and validator checks its correctness. Instead of treating this group as whole, graph models decompose these interactions into three pairwise edges, creating inefficiencies. When the mathematician updates the formula, the message must follow sequential path. The programmer receives the update first, but the validator must wait for the programmer to process and relay it. This multi-hop propagation increases latency and risks information Figure 2: The HyperAgent pipeline. We encode agents and tasks into hypergraph, then apply variational autoencoder with sparsity regularization to generate task-adaptive communication topologies. Agents interact through hyperedge-based collaboration for multiple rounds. The VAE is trained via policy gradients to maximize task performance while minimizing communication overhead. individual agents via methods like role specialization[32] and coordinated interactions[12]. Collaboration takes various forms. Sequential architectures, such as ChatDev and MetaGPT, organize agents in chains, where each processes prior outputs and refines results for its successor[22, 42]. Hierarchical systems, including AutoGen[63] and SecurityBot[57], employ star topologies with central coordinator directing subordinates. Some approaches involve debates, where agents iteratively argue to enhance reasoning and factuality[9, 17, 27]. Recent advances focus less on static structures and more on collaboration mechanisms, distinguishing between cooperative, competitive, and hybrid \"coopetition\" frameworks[41, 49]. CAMEL pioneered role-playing to enable autonomous cooperation using inception prompting[29]. Studies show that effective collaboration arises from well-designed communication protocols rather than mere aggregation of agents[23, 62]. Multi-agent systems also exhibit human-like behaviors such as consensus formation and adaptive negotiation[2, 56], hinting at deeper parallels with natural collective intelligence[62]. In software engineering domains, hierarchical debugging frameworks decompose complex code into multigranularity components for systematic error resolution[47], while competitive debate mechanisms enable diverse reasoning through structured agent interactions along fault propagation traces[30], and experience-driven approaches accumulate repair knowledge from historical trajectories[11]. Building on these foundations, understanding LLM-generated code patterns[48] and managing longcontext information through compression techniques[18, 46, 66] have become essential for scaling agent systems, alongside advances in reinforcement learning-based reasoning[35] and cross-language translation capabilities[55]."
        },
        {
            "title": "2.2 Graphs for Multi-agents\nGraphs naturally model relationships and communication struc-\ntures in multi-agent systems, a perspective rooted in multi-agent\nreinforcement learning[24, 36, 40]. The advent of LLMs extended\nthis approach to language-driven systems, where frameworks like",
            "content": "ChatEval and DSPy implicitly used graph structures without defining explicit topologies[8, 28]. Modern research explicitly represents multi-agent organizations as directed graphs, with nodes as agents and edges as communication links[37, 43, 77]. Predefined topologies like complete graphs allow unrestricted communication but incur high costs, while random graphs lack task-specific optimization[5, 43]. Chain and tree structures support hierarchical flows useful for sequential reasoning[61, 64, 75]. Graph neural networks now enable dynamic topology learning, with methods like G-Designer and variational graph autoencoders generating task-adaptive, efficient structures[45, 67]. Pruning techniques, such as in AgentPrune and AgentDropout, simplify dense graphs by removing redundant edges[59, 70]. Practical applications demonstrate task-aware coordination: repository-level code understanding leverages dependency graphs with agent tool invocation[39], issue resolution employs fault propagation graphs for collaborative diagnosis[30], and experience banks enable knowledge reuse across problem instances[11]. However, graph-based methods share common limitation: they represent only pairwise relationships, failing to model collaborative units where multiple agents work jointly on shared tasks[20, 69]. This gap highlights the need for richer frameworks to better capture group-level interactions."
        },
        {
            "title": "3 Preliminary\n3.1 Problem Formulation\nWe model the multi-agent system as a hypergraph H = (V, E, W).\nThe node set V = {𝑣1, . . . , 𝑣𝑁 } represents 𝑁 agents in the system.\nEach node 𝑣𝑖 ∈ V corresponds to an agent, formalized as:",
            "content": "𝑣𝑖 = {Base𝑖, Role𝑖, State𝑖, Plugin𝑖 } (1) Each agent 𝑣𝑖 is composed of four key elements: (1) Base𝑖 , the language model instance powering 𝑣𝑖 ; (2) Role𝑖 , the agents preassigned role or function; (3) State𝑖 , representing the agents accumulated knowledge and interaction history; and (4) Plugin𝑖 , set of external tools available to 𝑣𝑖 , such as web searchers, code compilers, or file readers. The hyperedge set contains collaboration units. Each hyperedge 𝑒 connects multiple agents participating in the same subtask. The weight matrix assigns importance scores to different collaboration units. We set = by default, treating all collaboration units equally. The hypergraph structure can be represented by an incidence matrix {0, 1} . Each element is defined as: ℎ𝑣,𝑒 = (cid:40) 1, 0, if 𝑣 𝑒 if 𝑣 𝑒 (2) This binary encoding directly captures group-wise collaboration patterns. The degree of node 𝑣𝑖 is 𝑑𝑖 = (cid:205)𝑒 W𝑒𝑒ℎ𝑖,𝑒 . The degree of hyperedge 𝑒 is 𝛿𝑒 = (cid:205)𝑣 ℎ𝑣,𝑒 . These statistics form diagonal matrices and respectively. Each LLM-based agent 𝑣𝑖 receives prompt and generates response R𝑖 : R𝑖 = 𝑣𝑖 (P) = 𝑣𝑖 (Psys, Pusr) (3) where Psys = {Role𝑖, State𝑖 } represents the system prompt, and Pusr denotes the user prompt including the given task, responses from other agents, and externally retrieved knowledge."
        },
        {
            "title": "3.2 Hypergraph Convolution\nGiven node feature matrix X(𝑙 ) ∈ R| V | ×𝐷 at layer 𝑙, the hypergraph\nconvolutional layer computes updated features through:",
            "content": "X(𝑙+1) = 𝜎 (D1/2HWB1HD1/2X(𝑙 ) 𝚯(𝑙 ) ) (4) The term HX(𝑙 ) performs node-to-edge aggregation. Each row represents one hyperedges aggregated feature computed as the sum of features from participating agents. The term B1 normalizes by dividing each hyperedge feature by the number of participating agents. The term H(B1HX(𝑙 ) ) performs edge-to-node propagation. Each node receives messages from all hyperedges it participates in through summation. The degree normalization D1/2 ensures balanced information flow. The learnable weight 𝚯(𝑙 ) R𝐷 𝐷 transforms features. The activation function 𝜎 () introduces nonlinearity. We use ReLU by default. This node-edgenode transformation naturally captures group-wise collaboration patterns."
        },
        {
            "title": "4.1 Multi-Agent Hypergraph Construction\nGiven input query Q and agent set V, HyperAgent aims to de-\nsign a task-adaptive communication topology Hcom. We begin by",
            "content": "assigning each agent unique role and profile. Previous research has shown that assigning distinct personas to LLM-based agents enhances cognitive synergy. Based on these roles, different external tools are allocated to agents. For example, Mathematica for math analyst, Python compiler for programmer. Thus we initialize each agent 𝑣𝑖 as {Base𝑖, Role𝑖, State𝑖, Plugin𝑖 }. We construct structured multi-agent hypergraph as input to HyperAgent, represented as = (Xagent, Hanchor). Here Xagent R𝑁 𝐷 is the node feature matrix. Hanchor {0, 1}𝑁 Eanchor is the initial incidence matrix. For the feature matrix, we employ node encoder to transform each agents profile into fixed-length embedding: x𝑖 NodeEncoder(T (Base𝑖 ), Role𝑖, (Plugin𝑖 )) (5) The function () extracts textual descriptions of the agents LLM backbone and assigned plugins. NodeEncoder can be realized using small text embedding models such as Sentence-BERT. After encoding individual agents, we ensure the hypergraph incorporates task-related information. This query-dependent approach enables HyperAgent to be task-aware and adaptive. We introduce task-specific virtual global node 𝑣task. This node connects bidirectionally to all agent nodes, enabling global storage mechanism and facilitating smoother information flow among agents. The task node is encoded as: xtask NodeEncoder(Q) (6) After obtaining agent node features Xagent = [x1, x2, . . . , x𝑁 ] and task embedding xtask, we provide simple anchor hypergraph structure Hanchor. This serves as starting point for topology design. For instance, given code generation task with three agents (manager, programmer, code reviewer), the anchor could configure sequential pipeline where each hyperedge connects adjacent agents. The anchor topology can be user-defined or automatically generated by LLMs. It is often simple and sub-optimal but provides foundational reference and prior knowledge. We incorporate the task-specific vertex 𝑣task and obtain Hanchor {0, 1} (𝑁 +1) ( Eanchor +𝑁 ) . The additional 𝑁 hyperedges represent bidirectional connections between 𝑣task and each agent. We establish task-specific multi-agent hypergraph: = (cid:21) (cid:18) (cid:20)Xagent task (cid:19) , Hanchor = ( V, E) (7) where = {𝑣task} and (cid:21) (cid:20)Xagent task can be denoted as X."
        },
        {
            "title": "Topology",
            "content": "Building upon the task-specific hypergraph , HyperAgent seeks to establish fine-grained communication topology Hcom. Drawing inspiration from the variational graph auto-encoder (VGAE) framework, HyperAgent employs VGAE-based encoder-decoder 𝑓𝑣 to generate the hypergraph topology: Hcom = 𝑓𝑣 ( ; Θ𝑣) = 𝑝 (HcomHlatent)𝑞(Hlatent X, Hanchor) (8) Here 𝑓𝑣 is the encoder-decoder architecture with parameters Θ𝑣. The encoder 𝑞() maps node embeddings to low-dimensional latent representations. The decoder 𝑝 () reconstructs hypergraph structure from these representations. The encoder consists of two hypergraph convolutional layers followed by sampling operations. Given node features and anchor structure Hanchor, the encoder computes mean vectors 𝝁 and variance vectors 𝝈 through separate paths: 𝝁 = HGCN𝜇 ( X, Hanchor), log 𝝈 = HGCN𝜎 ( X, Hanchor) (9) Both HGCN𝜇 and HGCN𝜎 are two-layer hypergraph convolutional networks with distinct parameters Θ𝜇 and Θ𝜎 . The encoder outputs latent representation matrix Hlatent R𝑁 𝐷 by sampling: 𝑞(Hlatent X, Hanchor) = 𝑁 (cid:214) 𝑖= 𝑞(h𝑖 X, Hanchor) (10) 𝑞(h𝑖 X, Hanchor) = (h𝑖 𝝁𝑖, diag(𝝈 2 Here h𝑖 , 𝝁𝑖 , and 𝝈𝑖 denote the 𝑖-th row of corresponding matrices. The encoder parameters are Θ𝑒 = {Θ𝜇, Θ𝜎 }. This stochastic encoding enables diverse topology generation while maintaining meaningful structure. 𝑖 )) The decoder transforms latent representations into hypergraph structure through two-phase process. The decoder 𝑝 () = 𝑝𝑐 𝑝𝑠 first constructs sketched pairwise affinity matrix S, then refines it into the final hypergraph topology: 𝑝 (HcomHlatent) = 𝑝𝑐 (HcomS)𝑝𝑠 (SHlatent)𝑑S (11) At the first step, 𝑝𝑠 () constructs sketched adjacency matrix [0, 1]𝑁 𝑁 from latent representations: The second term applies nuclear norm regularization = (cid:205)𝑖 𝜆𝑖 where 𝜆𝑖 are singular values of W. This encourages low-rank structure in W, translating to sparsity in since = holds due to ZZ = I𝑟 𝑟 . The hyperparameter 𝜁 controls sparsification strength. The refined adjacency matrix defines pairwise collaboration affinities. We convert this into hyperedge structure by grouping strongly connected agents. Specifically, for each agent 𝑖, we identify the 𝑘 agents with highest values in row S[𝑖, :] and form hyperedge connecting these 𝑘 +1 agents. This grouping produces the incidence matrix Hcom defining the final topology: Hcom = (V, Ecom), Ecom = {𝑒𝑖 𝑒𝑖 formed by top-𝑘 connections of agent 𝑖} (15) (16) The resulting structure captures group-wise collaboration patterns while maintaining sparsity for communication efficiency."
        },
        {
            "title": "4.3 Multi-Round Agent Interaction\nThe generated hypergraph topology Hcom guides information flow\nduring collaboration. At each round 𝑡, agents execute according to\na topological ordering. An agent 𝑣𝑖 can only execute after all agents\nin its in-neighborhood have produced responses. When agent 𝑣𝑖\nexecutes, it receives system prompt P (𝑡 )\nsys = {Role𝑖, State𝑖 } and\nusr = {Q, ∪𝑣𝑗 ∈ Nin (𝑣𝑖 ) R (𝑡 )\nuser prompt P (𝑡 )\n𝑗 }. The in-neighborhood\nNin (𝑣𝑖 ) includes agents sharing hyperedges with 𝑣𝑖 . The agent\ngenerates:",
            "content": "R (𝑡 ) 𝑖 = 𝑣𝑖 (P (𝑡 ) sys , (𝑡 ) usr ) (17) After 𝐾 rounds, an aggregation function produces the final an𝑝𝑠 (SHlatent) = 𝑁 (cid:214) 𝑁 (cid:214) 𝑖=1 𝑗=1 𝑝𝑠 (S𝑖 𝑗 h𝑖, h𝑗, htask; Θ𝑑 ) (12) swer: 𝑎 (𝐾 ) Aggregate(R (𝐾 ) 1 , (𝐾 ) 2 , . . . , (𝐾 ) 𝑁 ) (18) The detailed derivation is: 𝑝𝑠 (S𝑖 𝑗 = 1h𝑖, h𝑗, htask) = 𝑔(h𝑖, h𝑗, htask) = Sigmoid((log(𝜖) log(1 𝜖) + 𝜛𝑖 𝑗 )/𝜏) (13) where 𝜛𝑖 𝑗 = FFN𝑑 ([h𝑖, h𝑗, htask]) with parameters Θ𝑑 . The uniform random variable 𝜖 Uniform(0, 1) introduces stochasticity. The temperature 𝜏 controls the sharpness of the sigmoid function. When 𝜏 approaches zero, the output becomes increasingly discrete. The sketched matrix typically contains many nonzero entries, resulting in dense structure. The second decoder phase 𝑝𝑐 () refines into sparse hypergraph topology through structured regularization: = arg min S 1 2 ZWZ 2 𝐹 + 𝜁 + 1 2 Aanchor ZWZ 2 𝐹 (14) subject to = ZWZ The matrix R𝑁 𝑟 contains the top 𝑟 left singular vectors of S. The weight matrix R𝑟 𝑟 is optimized to balance three objectives. The first term keeps refined structure close to original sketch S. The third term maintains similarity to anchor topology Aanchor (derived by converting Hanchor to pairwise connections). The aggregation can be majority voting, weighted combination, or delegation to specific agent depending on the task type."
        },
        {
            "title": "4.4 Training Objective\nHyperAgent optimizes topology generation through policy gradient\nmethods. The training objective maximizes expected utility:",
            "content": "Lutility = EΘ [𝑢 (Hcom (Q))] (19) The utility function 𝑢 () evaluates the quality of final answer 𝑎 (𝐾 ) . We approximate the gradient using sampled topologies: ΘLutility 1 𝑀 𝑀 𝑚=1 𝑢 (𝑎 (𝐾 ) 𝑚 )Θ log 𝑃 (H𝑚) (20) The system samples 𝑀 different hypergraph topologies {H𝑚 } during training. Each produces answer 𝑎 (𝐾 ) 𝑚 . The complete training loss combines utility maximization with regularization: Ltotal = Lutility + Lanchor + Lsparse (21) The anchor regularization Lanchor = Aanchor S2 𝐹 keeps generated topologies grounded in reasonable prior structures. The sparsity regularization Lsparse = 𝜁 ensures communication efficiency. Table 1: Performance comparison with three types of baselines, including single-agent execution, static multi-agent topologies, and adaptive multi-agent frameworks. The best results are in bold, and the runner-ups are underlined. All multi-agent methods utilize five gpt-4-based agents. Mul., Ada., and Rob. indicate whether the method supports multi-agent setting, whether it is task-adaptive, and whether it is adversarially robust, respectively. (cid:37), and (cid:33) signifies no/partial/full support in these aspects. Method Mul. Ada. Rob. MMLU GSM8K MultiArith SVAMP AQuA HumanEval Avg. Vanilla CoT ComplexCoT SC (CoT) SC (ComplexCoT) AutoGPT PHP ReAct ToT GoT Chain Star Tree Complete Graph Random Graph (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:33) (cid:37) (cid:37) (cid:37) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) AutoGen (cid:33) MetaGPT (cid:33) LLM-Blender (cid:33) LLM-Debate (cid:33) DyLAN (cid:33) GPTSwarm (cid:33) AgentVerse (cid:33) COPPER (cid:33) AutoAgents (cid:33) G-Designer (cid:33) AgentPrune (cid:33) AgentDropout HyperAgent (Ours) (cid:33) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:37) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) Single-Agent Methods 82.14 (cid:37) (cid:37) 82.650.51 (cid:37) 83.781.64 (cid:37) 82.660.52 (cid:37) 83.651.51 (cid:37) 83.651.51 (cid:37) 83.451.31 (cid:37) 83.120.98 (cid:37) 83.891.75 (cid:37) 84.011.87 85.40 87.171.77 87.622.22 87.932.53 86.140.74 86.140.74 95.5010.1 88.242.84 89.063.66 89.474.07 93.15 94.791.64 95.862.71 96.883.73 96.943.79 96.943.79 98.102.84 95.372.22 96.523.37 96.733.58 Static Multi-Agent Topologies (cid:37) 82.350.21 (cid:37) 80.791.35 (cid:37) 81.890.25 (cid:37) 83.151.01 (cid:37) 83.761. 85.570.17 85.550.15 84.560.84 86.491.09 86.140.74 94.381.23 93.790.64 94.601.45 97.204.05 95.462.31 Adaptive Multi-Agent Frameworks 93.800.65 95.121.97 94.271.12 96.273.12 94.271.12 97.844.69 96.453.30 96.823.67 96.153.00 97.564.41 97.384.23 97.214.06 99.306.15 90.067.92 89.844.44 89.173.77 90.234.83 88.162.76 89.744.34 90.124.72 91.355.95 90.585.18 92.186.78 91.866.46 91.526.12 96.5711.17 (cid:37) 82.130.01 (cid:37) 83.241.10 (cid:37) 81.220.92 (cid:33) 83.691.55 (cid:33) 80.161.98 (cid:33) 83.981.84 (cid:37) 83.521.38 (cid:37) 83.761.62 (cid:37) 83.451.31 (cid:33) 84.252.11 (cid:33) 84.152.01 (cid:33) 84.081.94 (cid:33) 86.504.36 87.18 88.321.14 90.172.99 88.691.51 89.722.54 89.722.54 90.023.44 89.151.97 90.243.06 90.383.20 83.413.77 88.090.91 89.252.07 89.482.30 85.411. 88.441.26 89.562.38 88.771.59 90.563.38 87.400.22 86.420.76 89.872.69 90.183.00 89.642.46 91.023.84 90.733.55 90.453.27 93.856.67 70.34 73.913.57 77.587.24 75.084.74 77.697.35 77.697.35 79.008.66 76.426.08 77.957.61 78.247.90 70.940.60 68.571.77 72.842.50 79.218.87 74.073.73 73.653.31 76.185.84 77.056.71 77.527.18 74.163.82 78.167.82 77.837.49 78.428.08 77.296.95 78.948.60 78.658.31 78.518.17 81.9711.63 71.68 75.523.84 74.943.26 77.305.62 77.946.26 77.946.26 82.9611.36 78.356.67 80.128.44 81.269.58 80.889.20 75.653.97 77.385.70 83.7512.07 82.6610. 85.4113.73 85.9014.22 84.5212.84 83.7912.11 89.7018.02 88.4916.81 86.2414.56 87.5315.85 86.8715.19 88.7217.04 88.1516.47 87.6815.00 92.4020.72 81.65 83.73 84.99 84.75 85.35 85.35 88.17 85.11 86.30 86.68 82.92 82.07 83.42 86.55 84.58 85.58 86.64 85.83 87.01 85.64 87.44 87.34 88.01 87.33 88.78 88.49 88.24 91."
        },
        {
            "title": "5 Experiments\n5.1 Datasets\nWe evaluate HyperAgent on three categories of benchmarks span-\nning diverse reasoning and generation tasks. The general reasoning\ncategory includes MMLU[21], a comprehensive benchmark contain-\ning multiple-choice questions across 57 subjects. The mathematical\nreasoning category comprises GSM8K[15] for grade school math\nproblems, MultiArith[44] for arithmetic word problems, SVAMP[38]\nfor structurally diverse math questions, and AQuA[33] for algebraic\nreasoning. The code generation category uses HumanEval[10], con-\ntaining 164 programming tasks requiring function implementations.",
            "content": "These benchmarks exhibit varying task complexities and collaboration demands, enabling comprehensive evaluation of hypergraphbased topology optimization."
        },
        {
            "title": "5.2 Baselines\nWe compare HyperAgent against three categories of baselines.\nThe Single-agent methods include CoT[61] for chain-of-thought\nprompting, ComplexCoT[19] for complexity-based prompting, Self-\nConsistency[58] for multiple sampling with voting, PHP[73] for\nprogressive-hint prompting, AutoGPT[51] for autonomous task\nexecution, ReAct[65] for synergizing reasoning and acting, ToT[64]\nfor tree-based thought exploration, and GoT[3] for graph-based",
            "content": "Table 2: Ablation study of different components in HyperAgent. We evaluate the contribution of each key component across six benchmarks. Δ denotes the performance drop compared to the full model. The results demonstrate that the hypergraph structure is the most critical component, followed by the VAE framework and task node."
        },
        {
            "title": "Methods",
            "content": "MMLU GSM8K MultiArith SVAMP AQuA HumanEval Avg. Δ Avg. HyperAgent (Full) 86.50 96.57 99. 93.85 81.97 92.40 91.77 - w/o Hypergraph (Graph-based) w/o VAE (Fixed Topology) w/o Sparsity (𝜁 = 0) w/o Task Node w/o Anchor Regularization 84.80 85.20 86.30 85.65 85.80 93.50 94.80 96.20 94.95 95.30 97.85 98.50 99.15 98.65 98.80 91.50 92.80 93.60 92.45 92.70 79.20 80.85 81.75 80.50 80.72 89.15 90.50 91.80 90.85 91. 89.33 90.44 91.47 90.51 90.76 -2.44 -1.33 -0.30 -1.26 -1.01 Figure 3: Training dynamics of HyperAgent. (a) Loss components over training iterations. The utility loss (blue) steadily decreases while sparsity regularization (green) maintains stable constraint. (b) Validation accuracy improves and plateaus after 50 iterations. (c) Generated hypergraphs become progressively sparser during training, demonstrating the model learns efficient topologies. Figure 4: (a) Effect of hyperedge size parameter on performance and communication efficiency. (b) Impact of sparsity regularization coefficient on the performance-efficiency frontier. (c) Information propagation: graphs need multi-hop passing whereas hyperedges enable direct 1-step synchronization. (d) Visualization of the performance metrics and prompt token consumption. reasoning. Predefined multi-agent topologies include Chain, Star, Tree, Complete Graph, and Random Graph structures. Adaptive multi-agent frameworks include AutoGen[63] providing conversational coordination, MetaGPT[22] organizing software development agents, LLM-Blender[26] fusing multiple responses, LLMDebate[16] enabling multi-agent debate, DyLAN[37] constructing dynamic layered networks, GPTSwarm[76] optimizing graph structures, AgentVerse[13] facilitating multi-agent collaboration, and GDesigner[50] using graph-based design. These baselines represent state-of-the-art approaches in both static and dynamic topology design for multi-agent systems."
        },
        {
            "title": "5.3 Evaluation Models and Metrics\nWe conduct experiments using two base language models accessed\nvia OpenAI API: gpt-4-1106-preview and gpt-3.5-turbo-0125. Per-\nformance evaluation uses accuracy for multiple-choice questions\non MMLU and AQuA, as well as for mathematical reasoning on\nGSM8K, MultiArith, and SVAMP. Code generation on HumanEval\nreports pass@1, measuring the percentage of problems solved cor-\nrectly in the first attempt. Efficiency assessment measures prompt\ntoken consumption across all methods. Hypergraph structure anal-\nysis reports average hyperedge size and total collaboration units\ngenerated. All metrics are computed on test sets, with single-agent",
            "content": "profiling for multi-agent methods, following the classical configurations in LLM-MA systems, and use gpt-4 to generate agent profile pools. For all benchmarks, we merely use 𝐵 {40, 80} queries for optimization."
        },
        {
            "title": "5.7 Hyper-parameter Analysis\nFigure 5 investigates the impact of interaction rounds K on system\nperformance across three representative benchmarks. Accuracy\nconsistently improves as K increases from 1 to 3, with MMLU rising\nfrom 82.5% to 86.5%, HumanEval improving from 84.2% to 91.6%,",
            "content": "Figure 5: Performance vs. number of interaction rounds K. Accuracy improves with more rounds but exhibits diminishing returns after K=3. Figure 6: Training loss comparison between graph-based and hypergraph-based approaches. The hypergraph method achieves faster convergence and lower final loss compared to the graph-based method. Smoothed curves demonstrate that hypergraph structures exhibit more stable optimization trajectories with less oscillation. baselines using temperature 0 and multi-agent methods using temperature 1 to enable diverse responses."
        },
        {
            "title": "5.4 Implementation Details\nWe access GPT via the OpenAI API, and mainly test on gpt-4 and\ngpt-3.5-turbo. We set temperature to 0 for single execution and\nsingle agent baselines and 1 for multi-agent methods. We set a\nsummarizer agent to aggregate the dialogue history and produce\nthe final solution 𝑎 (𝐾 ) , with 𝐾 = 3 across all experiments. The\nNodeEncoder(·) is implemented using all-MiniLM-L6-v2, with\nthe embedding dimension set to 𝐷 = 384. The anchor hypergraph\nHanchor is predefined as a simple chain structure where each hy-\nperedge connects two adjacent agents. The hypergraph encoder\nHGCN𝜇 and HGCN𝜎 are two-layer hypergraph convolutional net-\nworks with hidden dimension 64. The decoder feedforward network\nFFN𝑑 has hidden dimension 128. We set the rank 𝑟 = 16 for low-\nrank approximation in Equation (14), the temperature 𝜏 = 1𝑒 − 2\nfor Gumbel-Softmax sampling in Equation (13), and the sparsity\ncoefficient 𝜁 = 1𝑒 − 1 for nuclear norm regularization. The hyper-\nedge grouping parameter 𝑘 = 2, meaning each collaboration unit\nconnects 3 agents on average. The sampling times 𝑀 are set as\n10 for policy gradient approximation. We provide explicit agent",
            "content": "and GSM8K advancing from 90.1% to 96.6%. However, the performance gains exhibit diminishing returns beyond equals 3, with only marginal improvements observed at equals 4 and 5. This phenomenon suggests that three interaction rounds provide sufficient capacity for effective collaboration, allowing agents to propose initial solutions, receive feedback, and produce refined outputs. Additional rounds contribute minimal value while incurring increased computational costs through redundant communication. The consistency of this pattern across diverse task types indicates that equals 3 represents an optimal balance between collaboration effectiveness and efficiency, supporting our design choice to fix at 3 throughout all experiments."
        },
        {
            "title": "6 Conclusion\nIn this work, we address limitations of graph-based multi-agent\ncommunication by introducing HyperAgent, a framework that uses\nhypergraphs to directly connect agents working on shared sub-\ntasks via hyperedges, enabling single-step information aggregation\nwithin collaboration units. A variational autoencoder with sparsity\nregularization generates task-adaptive topologies that balance ef-\nficiency and performance. Experiments on multiple benchmarks\ndemonstrate that HyperAgent outperforms state-of-the-art meth-\nods while significantly reducing communication overhead, high-\nlighting hypergraph-based optimization as a scalable solution for\nefficient multi-agent systems.",
            "content": "References [1] Omar Adjali, Olivier Ferret, Sahar Ghannay, and Hervé Le Borgne. 2024. MultiLevel Information Retrieval Augmented Generation for Knowledge-based Visual Question Answering. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 1649916513. [2] Abdullah Almaatouq, Mohammed Alsobay, Ming Yin, and Duncan Watts. 2021. Task Complexity Moderates Group Synergy. Proceedings of the National Academy of Sciences 118, 36 (2021). [3] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. 2024. Graph of Thoughts: Solving Elaborate Problems with Large Language Models. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 38. 1768217690. [4] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, et al. 2024. Graph of Thoughts: Solving Elaborate Problems with Large Language Models. AAAI Conference on Artificial Intelligence (2024). [5] Maciej Besta, Florim Memedi, Zhenyu Zhang, Robert Gerstenberger, Guangyuan Piao, Nils Blach, Piotr Nyczyk, Marcin Copik, Grzegorz Kwasniewski, Jurgen Muller, et al. 2024. Demystifying Chains, Trees, and Graphs of Thoughts. arXiv preprint arXiv:2401.14295 (2024). [6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems 33 (2020), 18771901. [7] Sebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of Artificial General Intelligence: Early Experiments with GPT-4. arXiv preprint arXiv:2303.12712 (2023). [8] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2024. ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate. In International Conference on Learning Representations. [9] Justin Chen, Swarnadeep Saha, and Mohit Bansal. 2024. ReConcile: RoundTable Conference Improves Reasoning via Consensus among Diverse LLMs. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. 68276844. [10] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating Large Language Models Trained on Code. arXiv preprint arXiv:2107.03374 (2021). [11] Silin Chen, Shaoxin Lin, Xiaodong Gu, Yuling Shi, Heng Lian, Longfei Yun, Dong Chen, Weiguo Sun, Lin Cao, and Qianxiang Wang. 2025. Swe-exp: Experiencedriven software issue resolution. arXiv preprint arXiv:2507.23361 (2025). [12] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. 2024. AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents. In International Conference on Learning Representations. [13] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. 2023. AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors. arXiv preprint arXiv:2308.10848 (2023). [14] Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, and Maosong Sun. 2024. Internet of Agents: Weaving Web of Heterogeneous Agents for Collaborative Intelligence. arXiv preprint arXiv:2407.07061 (2024). [15] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training Verifiers to Solve Math Word Problems. arXiv preprint arXiv:2110.14168 (2021). [16] Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. 2023. Improving Factuality and Reasoning in Language Models through Multiagent Debate. arXiv preprint arXiv:2305.14325 (2023). [17] Yilun Du, Shuang Li, Antonio Torralba, Joshua Tenenbaum, and Igor Mordatch. 2024. Improving Factuality and Reasoning in Language Models through Multiagent Debate. In International Conference on Machine Learning. [18] Yixiong Fang, Tianran Sun, Yuling Shi, and Xiaodong Gu. 2025. Attentionrag: Attention-guided context pruning in retrieval-augmented generation. arXiv preprint arXiv:2503.10720 (2025). [19] Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2022. arXiv preprint Complexity-Based Prompting for Multi-Step Reasoning. arXiv:2210.00720 (2022). [20] Mustafa Hajij, Ghada Zamzmi, Theodore Papamarkou, Aldo Guzman-Saenz, Tolga Birdal, and Michael Schaub. 2023. Combinatorial Complexes: Bridging the Gap Between Cell Complexes and Hypergraphs. 57th Asilomar Conference on Signals, Systems, and Computers (2023), 799803. [21] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. Measuring Massive Multitask Language Understanding. In International Conference on Learning Representations (ICLR). [22] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jurgen Schmidhuber. 2024. MetaGPT: Meta Programming for Multi-Agent Collaborative Framework. In The Twelfth International Conference on Learning Representations (ICLR). [23] John Hopfield. 1982. Neural Networks and Physical Systems with Emergent Collective Computational Abilities. Proceedings of the National Academy of Sciences 79, 8 (1982), 25542558. [24] Jianzhun Hu, Yihe Hu, Chang Zhou, Yaodong Wu, and Hongsheng Guan. 2024. HGAP: Boosting Permutation Invariant and Permutation Equivariant in MultiAgent Reinforcement Learning via Graph Attention Network. In International Conference on Machine Learning. [25] Yiming Huang, Jianwen Luo, Yan Yu, Yitong Zhang, Fangyu Lei, Yifan Wei, Shizhu He, Lifu Huang, Xiao Liu, Jun Zhao, and Kang Liu. 2024. DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 1348713521. [26] Dongfu Jiang, Xiang Ren, and Bill Yuchen Lin. 2023. LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL). 1416514178. [27] Akbir Khan, John Hughes, Dan Valentine, Laura Ruis, Kshitij Sachan, Ansh Radhakrishnan, Edward Grefenstette, Samuel Bowman, Tim Rocktaschel, and Ethan Perez. 2024. Debating with More Persuasive LLMs Leads to More Truthful Answers. In International Conference on Machine Learning. [28] Omar Khattab, Arnav Sinatra, Keshav Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Varshney, Mohammadreza Komeili, Nader Moazam, Yuval Kirstain, Matei Zaharia, and Christopher Ré. 2024. DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines. In International Conference on Learning Representations. [29] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society. In Advances in Neural Information Processing Systems, Vol. 36. 5199152008. [30] Han Li, Yuling Shi, Shaoxin Lin, Xiaodong Gu, Heng Lian, Xin Wang, Yantao Jia, Tao Huang, and Qianxiang Wang. 2025. Swe-debate: Competitive multi-agent debate for software issue resolution. arXiv preprint arXiv:2507.23348 (2025). [31] Yuan Li, Yilei Yao, Dong Li, Huazheng Zhang, and Tong Zhao. 2024. G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks. arXiv preprint arXiv:2410.11782 (2024). [32] Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2024. Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 1631016324. [33] Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), Vol. 1. 158167. [34] Hao Liu, Zhizhi Zhang, Zhiyuan Liu, Jia Wang, Hao Li, Yufan Chen, and Yizhou Sun. 2023. Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization. arXiv preprint arXiv:2310.02170 (2023). [35] Runze Liu, Jiakang Wang, Yuling Shi, Zhihui Xie, Chenxin An, Kaiyan Zhang, Jian Zhao, Xiaodong Gu, Lei Lin, Wenping Hu, et al. 2025. Attention as Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models. arXiv preprint arXiv:2509.26628 (2025). [36] Yaru Liu, Ziyi Wang, Jianyu Hu, and Zongqing Zhang. 2022. Multi-Agent Graph-Attention Communication and Teaming. In International Conference on Autonomous Agents and Multiagent Systems. 11291137. [37] Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. 2023. Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization. arXiv preprint arXiv:2310.02170 (2023). [38] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP Models Really Able to Solve Simple Math Word Problems?. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). 20802094. [39] Weihan Peng, Yuling Shi, Yuhang Wang, Xinyun Zhang, Beijun Shen, and Xiaodong Gu. 2025. SWE-QA: Can Language Models Answer Repository-level Code Questions? arXiv preprint arXiv:2509.14635 (2025). [40] Edoardo Pesce and Giovanni Montana. 2023. Attention-based Graph Neural Networks: Survey. Comput. Surveys 56, 1 (2023), 121. [41] Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard Scholkopf, Mrinmaya Sachan, and Rada Mihalcea. 2024. Cooperate or Collapse: Emergence of Sustainability Behaviors in Society of LLM Agents. arXiv preprint arXiv:2404.16698 (2024). [42] Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, et al. 2024. ChatDev: Communicative Agents for Software Development. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. 1417414190. [43] Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Kunlun Zhu, Hanchen Xia, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, and Maosong Sun. 2025. Scaling Large Language Model-based Multi-Agent Collaboration. In International Conference on Learning Representations. [44] Subhro Roy and Dan Roth. 2015. Solving General Arithmetic Word Problems. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). 17431752. [45] Yiming Shen, Guibin Zhang, Yanwei Yan, and Kun Wang. 2025. Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation. arXiv preprint arXiv:2507.18224 (2025). [46] Yuling Shi, Yichun Qian, Hongyu Zhang, Beijun Shen, and Xiaodong Gu. 2025. LongCodeZip: Compress Long Context for Code Language Models. arXiv preprint arXiv:2510.00446 (2025). [47] Yuling Shi, Songsong Wang, Chengcheng Wan, Min Wang, and Xiaodong Gu. 2024. From code to correctness: Closing the last mile of code generation with hierarchical debugging. arXiv preprint arXiv:2410.01215 (2024). [48] Yuling Shi, Hongyu Zhang, Chengcheng Wan, and Xiaodong Gu. 2024. Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. In 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE). IEEE Computer Society, 5162. [49] Yashar Talebirad and Amirhossein Nadiri. 2023. Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents. arXiv preprint arXiv:2306.03314 (2023). [50] Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein. 2024. MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning. arXiv preprint arXiv:2311.10537 (2024). [51] Torantulino and Contributors. 2023. AutoGPT: An Autonomous GPT-4 Experiment. https://github.com/Significant-Gravitas/AutoGPT. [52] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and Efficient Foundation Language Models. arXiv preprint arXiv:2302.13971 (2023). [53] Khanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, Barry OSullivan, and Hoang Nguyen. 2025. Multi-Agent Collaboration Mechanisms: Survey of LLMs. arXiv preprint arXiv:2501.06322 (2025). [54] Trieu Trinh, Yuhuai Wu, Quoc Le, He He, and Thang Luong. 2024. Solving Olympiad Geometry without Human Demonstrations. Nature 625 (2024), 476 482. [55] Chaofan Wang, Tingrui Yu, Jie Wang, Dong Chen, Wenrui Zhang, Yuling Shi, Xiaodong Gu, and Beijun Shen. 2025. EVOC2RUST: Skeleton-guided Framework for Project-Level C-to-Rust Translation. arXiv preprint arXiv:2508.04295 (2025). [56] Haotian Wang, Xiyuan Du, Weijiang Yu, Qianglong Chen, Kun Zhu, Zheng Chu, Lian Yan, and Yi Guan. 2024. Learning to Break: Knowledge-Enhanced Reasoning in Multi-Agent Debate System. In arXiv preprint arXiv:2312.04854. [57] Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, and Yangqiu Song. 2024. Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. 60246041. [58] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-Consistency Improves Chain of Thought Reasoning in Language Models. arXiv preprint arXiv:2203.11171 (2022). [59] Zhiyuan Wang, Xu Chen, Peng Li, Yang Liu, and Diyi Yang. 2025. AgentDropout: Enhancing Multi-Agent Collaboration via Adaptive Agent Pruning. arXiv preprint arXiv:2501.xxxxx (2025). [60] Zihao Wang, Zhe Lin, Xiang Li, Jianfeng Gao, and Muhan Zhang. 2024. MultiTrack Message Passing: Tackling Oversmoothing and Oversquashing in Graph Learning via Preventing Heterophily Mixing. International Conference on Machine Learning (2024). [61] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. Advances in Neural Information Processing Systems 35 (2022), 2482424837. [62] Anita Williams Woolley, Christopher Chabris, Alex Pentland, Nada Hashmi, and Thomas Malone. 2010. Evidence for Collective Intelligence Factor in the Performance of Human Groups. Science 330, 6004 (2010), 686688. [63] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. 2023. AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation. In ICLR 2024 Workshop on LLM Agents. [64] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of Thoughts: Deliberate Problem Solving with Large Language Models. Advances in Neural Information Processing Systems 36 (2023), 1180911822. [65] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023. ReAct: Synergizing Reasoning and Acting in Language Models. In International Conference on Learning Representations (ICLR). [66] Wenhao Zeng, Yaoning Wang, Chao Hu, Yuling Shi, Chengcheng Wan, Hongyu Zhang, and Xiaodong Gu. 2025. Pruning the unsurprising: Efficient code reasoning via first-token surprisal. arXiv preprint arXiv:2508.05988 (2025). [67] Guibin Zhang, Yanwei Yan, Ziwei Liu, Kun Wang, Xiangguo Sun, Yiming Yang, Xiaocheng Fan, Yong Huang, Hong Zhou, and Dawei Cheng. 2025. G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks. In International Conference on Machine Learning. [68] Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi, and Shumin Deng. 2024. Exploring Collaboration Mechanisms for LLM Agents: Social Psychology View. In ICLR 2024 Workshop on LLM Agents. [69] Kai Zhang, Min Li, Jia Liu, and Yue Wang. 2024. Hypergraph-enhanced Dual Semi-supervised Graph Classification. In International Conference on Machine Learning. [70] Yuxuan Zhang, Jun Li, Hao Wang, and Yifan Chen. 2025. AgentPrune: Adaptive Agent Pruning for Efficient Multi-Agent Systems. arXiv preprint arXiv:2501.xxxxx (2025). [71] Yifan Zhang, Yang Yuan, and Andrew Chi-Chih Yao. 2024. On the Diagram of Thought. arXiv preprint arXiv:2409.10038 (2024). [72] Jun Zhao, Can Zu, Xu Hao, Yi Lu, Wei He, Yiwen Ding, Tao Gui, Qi Zhang, and Xuanjing Huang. 2024. LONGAGENT: Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 1631016324. [73] Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and Yu Li. 2023. Progressive-Hint Prompting Improves Reasoning in Large Language Models. arXiv preprint arXiv:2304.09797 (2023). [74] Wangchunshu Zhou, Yixin Ou, Shengwei Ding, Long Li, Jialong Wu, Tiannan Wang, Jiamin Chen, Shuai Wang, Xiaohua Xu, Ningyu Zhang, et al. 2024. Symbolic Learning Enables Self-Evolving Agents. arXiv preprint arXiv:2406.18532 (2024). [75] Yuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor Bursztyn, Ryan Rossi, Somdeb Sarkhel, and Chao Zhang. 2024. ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search. In arXiv preprint arXiv:2310.13227. [76] Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan Ashley, Róbert Csordás, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki Irie, Dongxu Hao, Hitanshu Gupta, Ruini Zhang, Zhiheng Yang, Sung Bin Hong, Jong Yeob Park, Zhengkai Duan, Haoran Wang, Sizhe Yang, Yue Wang, Peizhuang Wei, Zhisheng Yang, Qian Chen, Chenrui Zhang, Peixuan Li, Yaodong Zhang, Chenglin Wu, and Jürgen Schmidhuber. 2024. MindAgent: Emergent Gaming Interaction. arXiv preprint arXiv:2309.09971 (2024). [77] Mingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and Jürgen Schmidhuber. 2024. Language Agents as Optimizable Graphs. In International Conference on Machine Learning. [78] Chang Zong, Yuchen Yan, Weiming Lu, Jian Shao, Yongfeng Huang, Heng Chang, and Yueting Zhuang. 2024. Triad: Framework Leveraging Multi-Role LLMbased Agent to Solve Knowledge Base Question Answering. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 16981710."
        }
    ],
    "affiliations": [
        "Columbia University, USA",
        "Shanghai Jiao Tong University, China",
        "South China Normal University, China",
        "University of Michigan, USA",
        "University of Pennsylvania, USA",
        "University of Science and Technology of China, China"
    ]
}