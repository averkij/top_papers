{
    "paper_title": "Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language",
    "authors": [
        "Mena Attia",
        "Aashiq Muhamed",
        "Mai Alkhamissi",
        "Thamar Solorio",
        "Mona Diab"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We present a comprehensive evaluation of the ability of large language models (LLMs) to process culturally grounded language, specifically to understand and pragmatically use figurative expressions that encode local knowledge and cultural nuance. Using figurative language as a proxy for cultural nuance and local knowledge, we design evaluation tasks for contextual understanding, pragmatic use, and connotation interpretation in Arabic and English. We evaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms, multidialectal Arabic proverbs, and English proverbs. Our results show a consistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower than for English proverbs, and performance for Egyptian idioms is 10.28% lower than for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07% relative to understanding, though providing contextual idiomatic sentences improves accuracy by 10.66%. Models also struggle with connotative meaning, reaching at most 85.58% agreement with human annotators on idioms with 100% inter-annotator agreement. These findings demonstrate that figurative language serves as an effective diagnostic for cultural reasoning: while LLMs can often interpret figurative meaning, they face challenges in using it appropriately. To support future research, we release Kinayat, the first dataset of Egyptian Arabic idioms designed for both figurative understanding and pragmatic use evaluation."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 7 2 ] . [ 1 8 2 8 3 2 . 0 1 5 2 : r Beyond Understanding: Evaluating the Pragmatic Gap in LLMs Cultural Processing of Figurative Language Mena Attia1, 2, Aashiq Muhamed1, Mai Alkhamissi1, Thamar Solorio 2, Mona Diab 1Carnegie Mellon University, 2MBZUAI {mattia, mdiab}@andrew.cmu.edu"
        },
        {
            "title": "Abstract",
            "content": "We present comprehensive evaluation of the ability of large language models (LLMs) to process culturally grounded language, specifically to understand and pragmatically use figurative expressions that encode local knowledge and cultural nuance. Using figurative language as proxy for cultural nuance and local knowledge, we design evaluation tasks for contextual understanding, pragmatic use, and connotation interpretation in Arabic and English. We evaluate 22 openand closed-source LLMs on Egyptian Arabic idioms, multidialectal Arabic proverbs, and English proverbs. Our results show consistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower than for English proverbs, and performance for Egyptian idioms is 10.28% lower than for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07% relative to understanding, though providing contextual idiomatic sentences improves accuracy by 10.66%. Models also struggle with connotative meaning, reaching at most 85.58% agreement with human annotators on idioms with 100% inter-annotator agreement. These findings demonstrate that figurative language serves as an effective diagnostic for cultural reasoning: while LLMs can often interpret figurative meaning, they face challenges in using it appropriately. To support future research, we release Kinayat, the first dataset of Egyptian Arabic idioms designed for both figurative understanding and pragmatic use evaluation."
        },
        {
            "title": "Introduction",
            "content": "Large language models (LLMs) have demonstrated remarkable progress in multilingual text understanding and generation. Yet their ability to process culturally grounded meaninghow language encodes local knowledge, social values, and pragmatic nuanceremains poorly understood. Figurative language offers natural lens for studying this capability. Idioms and proverbs are among the most pervasive forms of figurative expression, 1 Proverb Literal Translation Figurative Meaning Historical Context Cultural Significance (cid:9)(cid:225)(cid:30)(cid:10)(cid:75)(cid:10)(cid:65)(cid:16)(cid:174)(cid:130)(cid:203)(cid:64) (cid:16)(cid:232)(cid:80)(cid:65)(cid:103) (cid:250)(cid:10) (cid:9)(cid:175) (cid:16)(cid:233)(cid:74)(cid:10)(cid:214)(cid:207)(cid:64) (cid:169)(cid:74)(cid:10)(cid:28)(cid:46)(cid:16)(cid:75) (cid:17)(cid:129)(cid:107)(cid:240)(cid:81)(cid:16)(cid:75) (cid:65)(cid:211) Dont sell water in the village of watersellers Dont try to outsmart the experts. Historically, water-sellers in Egypt lived together in villages and brought water from the Nile to sell across neighborhoods. New sellers would mistakenly try to sell water in the water-sellers village, failing to realize the abundance of water there made it an unsuitable market. Featured in the popular song Haret ElSaayeen (1966) by Hussein Al-Sayed, sung by Sherifa Fadel, later by Mohammed Mounir with performance on Arab Idol (2013) surpassing 132 million views on YouTube as of August 2025 (MBC, 2013). Table 1: Egyptian Proverb: Water-Sellers Village deeply rooted in collective experience and cultural identity. They rely on shared world knowledge and pragmatic reasoning that extend beyond literal semantics. For instance, Table 1 presents an Egyptian proverb. Without contextual knowledge, the reference to the village of water-sellers offers little clue to its intended message or its appropriate use. For models to truly understand language, they must internalize this cultural substrate rather than rely solely on surface statistics or translation mappings. Most prior studies have centered on figurative comprehensionwhether model can explain an idiom or proverbbut not on pragmatic use, which requires context sensitivity, affective inference, and social appropriateness. In this work, we address these gaps by introducing comprehensive evaluation framework that uses figurative language as proxy for cultural nuance and knowledge. We design tasks that test models abilities to (1) interpret figurative expressions, (2) use them appropriately in context, and (3) infer their connotative and affective dimensions. Our evaluation covers 22 openand closed-source models spanning multiple architectures and parameter scales. While we leverage existing resources such as Jawaher (Arabic) and MAPS (English) for proverb interpretation, our central contribution is the introduction of Kinayat, new dataset of Egyptian Arabic idioms annotated for both figurative meaning and pragmatic use. Our work makes the following key contributions: 1. We introduce pragmatic use task to assess the ability of LLMs to employ figurative language appropriately in context; 2. We present unified cross-lingual evaluation suite probing figurative interpretation, contextual appropriateness, and connotative inference; 3. We present Kinayat, novel dataset of Egyptian Arabic idioms to evaluate figurative language understanding and pragmatic use. Our results demonstrate that performance consistently degrades from English proverbs to Arabic proverbs and finally to colloquial idioms, highlighting systemic weakness in handling culturallyspecific figurative language. We find that performance in Arabic proverbs is on average 4.29% lower than in English proverbs, indicating gap in cross-linguistic performance. Within Arabic, models performed 10.28% worse on idioms from our Kinayat dataset (Egyptian dialect) compared to Modern Standard Arabic (MSA) proverbs.1 In our novel pragmatic use task, we uncover significant Pragmatics Gap in LLMs. Our core finding shows that model accuracy drops by an average of 14 percentage points when tasked with applying an idiom in context compared to simply explaining its meaning. Namely, the average accuracy is 14.07% lower than in the corresponding understanding task, with maximum accuracy of 85.33%, suggesting that the use of idioms appropriately in context remains difficult for current models. However, providing the idiom sentence as additional context in the multiple-choice understanding prompt improves average accuracy by 10.66%. Finally, models exhibit notable limitations in grasping connotative meaning, achieving at most 85.58% agreement with humans on samples with 100% inter-annotator agreement."
        },
        {
            "title": "2 Related Work",
            "content": "Recent years have seen surge of interest in evaluating and improving the ability of LLMs to interpret and generate figurative language. Several 1MSA is the standard Arabic used in formal settings, while Egyptian dialect is spoken vernacular, related variant of MSA, used in Egypt. benchmarks have been proposed to assess various dimensions of figurative understanding, including metaphor, idiom, proverb, and poetry interpretation. Table 2 provides comparative summary of these datasets. Several English-focused datasets have been developed to evaluate literal versus figurative reasoning. The Fig-QA dataset (Liu et al., 2022) frames figurative language understanding as multiplechoice question answering task. Chakrabarty et al. (2022a) evaluate LLM ability to interpret idioms and similes plausibly by continuing narratives. Other efforts include FLUTE (Chakrabarty et al., 2022b) and follow-up work that explores metaphor interpretation using chain-of-thought prompting and psychologically informed reasoning (He et al., 2022; Prystawski et al., 2023; Jang et al., 2023), showing that while LLMs can often identify meaning at the surface level, they frequently fail to capture implicit moral or social connotations. The PUB benchmark (Sravanthi et al., 2024) specifically evaluates pragmatic competence, testing the models ability to distinguish between literal and contextually appropriate figurative meanings in conversation. In the multilingual setting, the MAPS dataset (Liu et al., 2024) evaluates figurative understanding across six languages on proverbs, and the ProverbEval dataset (Azime et al., 2025) evaluates LLMs of cultural proverbs for four Ethiopian languages and English, while MABL (Kabra et al., 2023) provides multilingual benchmark for metaphor and simile comprehension in underrepresented languages. Figurative language is an integral component of culture, yet Arabic language understanding and cultural benchmarks often omit it entirely. For example, widely used Arabic cultural benchmarks such as AraDiCE (Mousi et al., 2025), CAMEL-Bench (Ghaboura et al., 2025), and CIDAR (Alyafeai et al., 2024) do not include figurative language as an explicit category. Others incorporate it only in limited capacity, such as the ArabCulture dataset (Sadallah et al., 2025), which spans 13 countries and 12 topics with idioms as one topic but includes only five samples per country, and PALM (Alwajih et al., 2025), which covers 20 diverse topics from 22 Arab countries with proverbs as one of the topics. There are two recent benchmarks that focus specifically on Arabic figurative language: the Jawaher dataset (Magdy et al., 2025), the first largescale collection of Arabic proverbs across 20 di2 Dataset Languages Figurative Type MAPS (Liu et al., 2024) MABL (Kabra et al., 2023) Fig-QA (Liu et al., 2022) FLUTE (Chakrabarty et al., 2022b) PUB (Sravanthi et al., 2024) Jawaher (Magdy et al., 2025) Fann or Flop (Alghallabi et al., 2025) Arabic English, Chinese, German, Russian, Bengali, Indonesian Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, Yoruba Metaphors Metaphors English Sarcasm, Simile, Metaphor, and Idioms English Implied answers, Presuppositions, Metonymy English Proverbs Arabic (20 dialects) Poetry Proverbs Kinayat (ours) Arabic Idioms Table 2: Comparison of existing figurative language datasets. alects, and Fann or Flop (Alghallabi et al., 2025), benchmark for the interpretation of Arabic poetry that spans multiple genres and eras. However, the lack of datasets that focus on figurative language highlights the need for more comprehensive evaluation resources that integrate figurative language as an explicit component of cultural understanding. Recent work has also examined the affective and social dimensions of figurative expressions. Martínez et al. (2024) use LLMs to estimate valence, arousal, and concreteness of multi-word expressions, offering route to investigate deeper semantic features. In the Arabic context, Alsiyat and Piao (2020) demonstrate that metaphorical constructions significantly affect sentiment analysis performance, underscoring the need for connotative understanding in Arabic Natural Language Processing (NLP)."
        },
        {
            "title": "3 Methodology",
            "content": "To provide comprehensive evaluation of figurative language, we design framework of tasks that probe LLM capabilities beyond simple comprehension across Arabic idioms, Arabic proverbs, and English proverbs. Although prior work has benchmarked proverb understanding, our framework introduces suite of tasks, including negation, contextual reasoning, pragmatic use, and connotation labeling, that have not been systematically applied to the Arabic figurative language before. Pragmatic Use: We introduce new task to evaluate the pragmatic use of Arabic idioms in LLMs. Using subset of 150 idioms from the Kinayat dataset, we use model-in-the-loop approach (Chakrabarty et al., 2022b; Liu et al., 2024), prompting GPT-4.1 (OpenAI, 2025) with each idiom and its explanation to generate sentence in Egyptian Arabic, using the prompt shown in Figure 13. native Egyptian Arabic speaker then reviews the generated sentences and either: accepts them, make minor changes, or come up with new sentences to replace them. Of the 150 samples, 77 (51.3%) are modified, either by minor dialectal adjustments, rephrasing, the addition of feminine examples, or complete rewriting of the sentence. The unmodified generated samples appear in first person, first person plural, second person, or third person masculine. Many examples are work-related, with the word (cid:201) (cid:9)(cid:170) (cid:17)(cid:131) \"work\" appearing 29 times and (cid:81)(cid:75)(cid:10)(cid:89)(cid:211) \"manager\" appearing 7 times. As part of the task setup, for each idiom, the annotator selects plausible but incorrect idiom from the Kinayat set to serve as distractor in multiple-choice setting. We then evaluate LLMs, asking them to choose the correct idiom for given sentence, using the template in Figure 14. Representative examples of this task are shown in Figure 1. Figure 1: Sample questions from the Pragmatic Use task, along with their English translations. We evaluate the performance of LLMs on the following tasks using zero-shot prompting. All 3 prompts are included in Appendix A. Multiple Choice Question (MCQ) Understanding: To evaluate figurative comprehension, we construct multiple choice questions, inspired by the work of Liu et al. (2024); Kabra et al. (2023), where each item presents two candidate explanations for given idiom or proverb, one correct and one incorrect. Because understanding is assessed through multiple-choice format, the results are inherently influenced by the quality and difficulty of the incorrect explanations. When an incorrect explanation is implausible or obviously wrong, models can often eliminate it without genuinely understanding the meaning of the idiom or proverb. To try to mitigate this, incorrect explanations are generated using GPT-4.1 with two distinct strategies. First, we use general prompt template (Figure 7) to produce semantically plausible but incorrect explanation for each idiom or proverb. Second, we leverage semantic role labeling (SRL) with LLMs (Cheng et al., 2024) to generate more subtly incorrect explanations: we extract the semantic roles from the gold explanation and modify single role to alter the meaning, using the SRL-based prompt in Figure 8. Each model is prompted to choose the correct explanation in two separate evaluation settings: once with the general incorrect explanations, and once with the SRL-based alternatives. Human Verification of Generations To evaluate the quality of the generated explanations, native Arabic speaker manually assesses random sample of 50 incorrect explanations for idioms from Kinayat and another 50 for proverbs from Jawaher. Each explanation is rated on three-point scale from 0 to 2, where higher scores indicate explanations that are incorrect, but linguistically and culturally plausible, while lower scores correspond to explanations that are implausible or irrelevant. Detailed annotation guidelines are provided in the Appendix B. The average verification scores are 1.72 for idioms and 1.68 for proverbs, confirming that all the generations sampled were indeed incorrect, although they vary in clarity and plausibility. This slight difference suggests that it is slightly easier to produce plausible but incorrect explanations for idioms than for proverbs, although this likely reflects differences in the gold explanations provided as input rather than in the idioms or proverbs themselves. Contextual Understanding MCQ: We extend the MCQ Understanding Task by providing idiomatic sentences for subset of Arabic idioms from Kinayat as additional context. Models are then prompted to select the correct explanation given both the idiom and its usage in context, using the prompt shown in Figure 6. Negation: Building on the work of Liu et al. (2024), we adapt the MCQ understanding task in Arabic datasets by requiring the models to select the incorrect explanation rather than the correct one. This inversion introduces negation component to the task, as models must reject the correct option, which prior work in natural language inference has shown to degrade model performance (Truong et al., 2023; She et al., 2023). Explanation Generation: Beyond evaluating models ability to identify the correct explanation, we also assess their capability to generate explanations for Arabic idioms and proverbs. Models are prompted to produce explanations using the prompt template shown in Figure 11. Completing the Proverb: We evaluate the memorization of cultural knowledge of the models by masking the final word of each English and Arabic proverb, following Liu et al. (2024), and prompting the model to complete it using the prompt template shown in Figure 9. Connotation Understanding: Connotations of each Arabic proverb and idiom are labeled by three native Egyptian Arabic speakers as positive, negative, or neutral. Human annotators are provided with the same prompt template as the models to standardize task instructions. We then evaluate models only on samples with 100% agreement to minimize the impact of connotation subjectivity on model performance. We use two variants of the task employing the prompt template in Figure 15: (1) predicting the connotation given the proverb or idiom, and (2) predicting the connotation given its explanation. Model predictions are compared with human annotations to calculate accuracy."
        },
        {
            "title": "4.1 Datasets",
            "content": "Jawaher (Magdy et al., 2025): We use 198 test samples of multidialectal proverbs across 20 varieties and their Arabic explanations. 4 MulticulturAl Proverbs and Sayings (MAPS) (Liu et al., 2024): multilingual dataset of proverbs in 6 languages. We only use the English test set which consists of 394 proverbs. Kinayat: Dataset of Egyptian Arabic Colloquial Idioms We introduce the Kinayat dataset, which consists of 325 Egyptian idioms along with their MSA explanations. We extracted them from the book Al-Kinayat Al-Amiyya (Pasha, 1949).2 Some examples are shown in Table 18 in Appendix F. Data Preprocessing: During preprocessing, we removed inappropriate or incomplete idioms, resulting in the exclusion of 10 entries from the dataset. Citations appearing in parentheses within the text were deleted to ensure clarity and consistency. We also removed phonetic explanations, as well as similar idioms and sayings that were mentioned with the explanations. Examples and excerpts of poetry were excluded to maintain focus on the core figurative expressions. Finally, for idioms whose explanations merely referred to an equivalent idiom without further clarification, we supplemented the data by adding in full explanatory text."
        },
        {
            "title": "4.2 Models",
            "content": "Our experiments consider broad selection of LLMs, encompassing both open-source and closedsource options, as well as Arabic and non-Arabic models of varying size. We evaluate total of 22 models. The open-source multilingual models evaluated include LLaMA 3.1 (8B, 70B-Instruct) (Grattafiori et al., 2024), Gemma 2 (9B, 27B-IT) (Team et al., 2024b), Qwen-2.5 (7B, 14B, 32B-Instruct) (Qwen et al., 2025), and Mistral-7B-Instruct-v0.3 (Jiang et al., 2023). We further evaluate diverse set of open-source Arabic models, such as Aya-Expanse (8B, 32B) (Dang et al., 2024), Jais-family-6p7bchat, Jais-family-13b-chat (Sengupta et al., 2023), ALLaM-7B-Instruct-preview (Bari et al., 2025), SILMA-9B-Instruct-v1.0 (silma-ai, 2024), Fanar1-9B-Instruct (Team et al., 2025), and AceGPT-v28B-Chat (Huang et al., 2024). The closed-source models included in our evaluation are GPT-4o and 4o-mini (OpenAI et al., 2024), Gemini 1.5 Flash (Team et al., 2024a), Gemini 2.5 Flash Lite Preview (Comanici et al., 2025), as well 2The book is publicly available by the publisher. as Claude 3.5 Sonnet (Anthropic, 2024) and Sonnet 4 (Anthropic, 2025). 4.3 Evaluation We evaluate LLM performance across the different tasks using the lm-eval framework (Gao et al., 2024), which computes accuracy using loglikelihood for open-source models and modelgenerated outputs for closed-source APIs. For open-source models, lm-eval was configured with vLLM (Kwon et al., 2023) and tensor parallelism to distribute compute across 4 GPUs. For multiple-choice tasks, we report the mean accuracy standard error as the primary evaluation metrics. For generation-based tasks, we employ two complementary evaluation methods: 1. BERTScore (Zhang et al., 2020): Measures semantic similarity between modelgenerated explanations and gold references using contextual embeddings from bert-base-multilingual-cased, with the language set to Arabic (lang=\"ar\"). We report the F1 score as the main evaluation metric. 2. LLM-as-a-Judge (Zheng et al., 2023): Uses LLM to assess how well the generated explanation aligns with the intended meaning of the gold explanation. We use GPT-4.1 as the default system to score all models except for the evaluation of the GPT models, which are instead judged using Claude-3.5-Sonnet to avoid self-evaluation bias (Wataoka et al., 2024). The scoring prompt is shown in Figure 12."
        },
        {
            "title": "5.1 Knowledge and Understanding",
            "content": "Distinguishing Between Correct and Incorrect explanations In Figure 2, we observe clear difficulty hierarchy in understanding MCQ, with the highest model performance on MAPS with context (95.66%), followed by MAPS (90.86%), Jawaher (86.57%) and lowest on Kinayat (76.29%). Arabic proverbs consistently yield lower performance than English proverbs, both with context (95.66% vs. 86.57%) and without context (90.86% vs. 86.57%), indicating persistent gap in cross-lingual and cultural understanding. Furthermore, Arabic idioms are more challenging than Arabic proverbs (average accuracy of 76.29% vs. 86.57%), possibly because proverbs tend to be almost frozen mak5 Figure 2: Accuracy on MCQ Understanding task across different testsets ing them easier to memorize as they could have been seen in the training data as opposed to idioms. Additionally, idioms occur in shorter and less informative contexts, as shown by their length distributions in Figure 17 (Appendix C). Detailed results for the MCQ task and subsequent tasks are presented in Appendix D. Table 6 presents the results for the negation variant of the MCQ task. When models were asked to identify the incorrect explanation rather than the correct one. This inversion led to notable performance drop: for idioms, the average accuracy decreased from 76.29% to 70.97%, and for proverbs from 86.57% to 82.71%. Interestingly, GPT-4o outperformed the Claude models in this more challenging negation task, despite the Claude models achieving higher accuracy in the original MCQ understanding task. Knowledge and Memorization of Proverbs Results for the proverb completion task are presented in Table 7. Claude 3.5 achieved the highest accuracy for both English and Arabic proverbs, with scores of 93.91% and 36.36%, respectively. On average, the performance of the model was substantially higher for English proverbs (75.43%) compared to Arabic proverbs (10.65%). The low accuracy of Arabic completions suggests limited memorization, which may reflect lower representation of Arabic proverbs in the models training data. Despite low memorization, models perform well in the understanding task, suggesting that they can still reason effectively without relying on memorization (Liu et al., 2024). in both evaluation metrics, BERTScore-F1 and LLM-as-a-Judge, for both proverbs and idioms. For proverbs, it scored 0.70 on BERTScore-F1 and 3.89 on the LLM-as-a-Judge scale (15). For idioms, it scored 0.68 and 2.93, respectively. Although higher BERTScore-F1 values did not always correspond to higher LLM-as-a-Judge scores, the highest BERTScore-F1 outputs were consistently aligned with the highest humanaligned ratings. Overall, idioms proved to be more challenging for models to generate explanations for, with lower average scores across both metrics. Specifically, the average BERTScore-F1 and LLM-as-a-Judge scores were 0.65 and 2.19 for idioms, compared to 0.68 and 3.06 for proverbs."
        },
        {
            "title": "5.2 Pragmatic Use",
            "content": "As shown in Table 3, the highest accuracy of 85.33% on the pragmatic use task was achieved by Claude 3.5 Sonnet. The average accuracy on pragmatic use across all models was 64.45%, which is 14.07% lower than the average accuracy on the understanding task for the same set of 150 idioms. When the sentence containing the idiom was added as context to the MCQ understanding prompt, the average accuracy increased by 10.66% to 89.18%. These results demonstrate performance gap between understanding and pragmatic use even for frontier models, indicating that using idioms pragmatically in context is more challenging than choosing the correct explanation from multiple choice options."
        },
        {
            "title": "5.3 Connotations",
            "content": "Model Ability to Generate Explanations Claude 3.5 Sonnet achieved the highest scores Annotating connotation in Arabic figurative expressions reveals inherent subjectivities in cultural ex6 The resulting similarity distributions, shown in Figure 3 for idioms (and Figure 18 for proverbs in Appendix C), reveal noticeable shifts in distribution, but the impact on overall performance was minor. For proverbs, average accuracy slightly decreased with SRL-based distractors (86.57% 86.36%), while for idioms, performance slightly improved (76.29% 78.52%). This suggests that the semantic closeness of distractors can vary depending on the generation strategy, but does not largely affect model performance. Dialectal Breakdown The dialectal breakdown for the MCQ understanding results in Table 9 for the Jawaher dataset is shown in Tables 13 and 14 (as well as Figures 20 and 21 in Appendix D. The average of the two tables is presented in Figure 4 and Table 15. The top performing dialects on average were: UAE, MSA, Libya, and Oman. The lowest performing dialects were: Sudan, Mauritania, Qatar, and Yemen. Notably, UAE, Libya, and Oman performed unexpectedly well despite being low-resource dialects, while Egypt, highresource dialect, achieved only mid-range score. One possible explanation is that certain proverbs in the Jawaher dataset are culturally shared across multiple Arab countries, particularly Gulf and Levantine varieties, whereas others are highly localized or unique. Country-level performance varied depending on whether the incorrect distractor was generated with general or SRL-based prompt, but UAE and MSA consistently ranked in the top four, while Sudan and Mauritania consistently ranked among the lowest three. Figure 4: Country-level breakdown of MCQ Understanding Average Accuracy Arabic vs. Multilingual Models Table 12 in Appendix summarizes the average performance of open source multilingual, open source Arabic, and closed source models in all tasks. Multilingual models generally outperform Arabic models 7 Figure 3: Cosine similarity () between the correct and incorrect explanation choices for idioms (Kinayat) pressions. Assigning clear sentiment values is often reductive, as interpretation varies widely across individuals and groups (Sap et al., 2022; Aroyo and Welty, 2015). Out of the 198 multidialectal proverbs, 105 (53.03%) achieved full interannotator agreement on their connotations, while 104 out of 150 Egyptian idioms (69.3%) reached full agreement, underscoring the inherent subjectivity of connotation judgments. To reduce the confounding effect of subjectivity of connotations, models were evaluated only on the samples where all three annotators agreed, ensuring focus on stronger connotations. Claude-3.5-Sonnet achieved the highest accuracy in labeling the connotations of idioms (85.58% accuracy) and proverbs (74.04% accuracy), while Claude-Sonnet-4 achieved the highest accuracy in labeling the connotations of explanations, with accuracy scores of 89.42% for idioms and 86.54% for proverbs. On average, accuracy of explanations was higher by 22.11% for idioms and 18.46% for proverbs, which is expected given that the purpose of the explanations is to clarify figurative expressions. These results suggest that models struggle with connotations, which could be related to how they perform less on the pragmatic use task. All connotation results are presented in Table 11 (Appendix D)."
        },
        {
            "title": "Analysis",
            "content": "the correct incorrect semantic understand Variants of Incorrect Distractors To betrelationship ter between explanaand tions, we compute the cosine similarity between their sentence embeddings (using the paraphrase-multilingual-mpnet-base-v2 model (Reimers and Gurevych, 2019))comparincorrect explanations generated ing correct vs. using the general prompt (Figure 7), and correct vs. incorrect explanations using the SRL prompt (Figure 8), separately for proverbs and idioms. Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9B-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct-v0.3 Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite GPT-4o GPT-4o-mini Average Pragmatic Use 0.5400 0.0408 0.6333 0.0395 0.6000 0.0401 0.6933 0.0378 0.5267 0.0409 0.6467 0.0392 0.7133 0.0370 0.4400 0.0407 0.5667 0.0406 0.6067 0.0400 0.5800 0.0404 0.5600 0.0407 0.6867 0.0380 0.5600 0.0407 0.7533 0.0353 0.4667 0.0409 0.8333 0.0305 0.8533 0.0290 0.6533 0.0390 0.7800 0.0339 0.8400 0.0300 0.6467 0.0392 0. Understanding 0.6000 0.0401 0.8867 0.0260 0.7867 0.0336 0.8133 0.0319 0.7733 0.0343 0.8400 0.0300 0.8200 0.0315 0.4867 0.0409 0.7067 0.0373 0.7867 0.0336 0.7733 0.0343 0.5933 0.0402 0.8533 0.0290 0.6533 0.0390 0.8467 0.0295 0.5667 0.0406 0.9533 0.0173 0.9533 0.0173 0.8400 0.0300 0.9333 0.0204 0.9533 0.0173 0.8533 0.0290 0.7852 Contextual Understanding 0.7867 0.0336 0.9667 0.0147 0.8933 0.0253 0.9533 0.0173 0.8667 0.0278 0.9667 0.0147 0.9267 0.0214 0.6267 0.0396 0.8333 0.0305 0.8133 0.0319 0.9000 0.0246 0.8533 0.0290 0.9333 0.0204 0.8467 0.0295 0.9400 0.0195 0.7400 0.0359 0.9733 0.0132 0.9667 0.0147 0.9333 0.0204 0.9867 0.0094 0.9667 0.0147 0.9467 0.0184 0.8918 Table 3: Evaluation results for Pragmatic Use, Understanding, and Understanding with Context on subset of 150 sample idioms from the Kinayat dataset. in English tasks by an average of 5.47% and Arabic tasks by smaller margin of 0.72%. However, this trend is not consistent across all multilingual models; for example, Mistral-7B-Instruct performed worse than the Arabic models on most tasks. Closed-source models achieve the highest performance overall, surpassing both Arabic and multilingual models, which may in part be due to their larger size, as their exact parameter counts are not disclosed but they are estimated to be larger than the open-source models evaluated, where the latter models range from 6.7B to 32B parameters. However, Arabic models show notable strengths, outperforming in completion and pragmatic use tasks and achieving slightly higher average scores in generation. The higher completion performance of Arabic models could be partly explained by their pretraining on Arabic text, which likely exposed them to more Arabic proverbs during training. Model Size weak positive correlation between model size and performance was observed for understanding tasks, with values of R2 ranging from 0.189 to 0.424, as shown in Figure 23 and summarized in Table 16 (Appendix E). The most efficient model for the Arabic task, measured as performance per billion parameters, was ALLaM-7BInstruct-preview, while the most efficient model for the English task was Qwen2.5-7B-Instruct. The pragmatic use task exhibited stronger correlation with model size (R2 = 0.6) compared to the MCQ understanding task (R2 = 0.265), with ALLaM7B-Instruct-preview again being the most efficient model."
        },
        {
            "title": "7 Conclusion",
            "content": "We presented comprehensive evaluation of large language models ability to understand and pragmatically use figurative expressions that encode local knowledge and social nuance. We evaluated diverse LLMs on Egyptian Arabic idioms, multidialectal Arabic proverbs, and English proverbs across tasks assessing contextual understanding, pragmatic use, and connotation interpretation. Results revealed consistent performance hierarchy, with English proverbs outperforming Arabic proverbs, and both outperforming Egyptian idioms. Pragmatic use emerged as significantly more challenging than understanding, and models struggled to capture connotative meaning appropriately. Figurative language thus serves as an effective diagnostic for cultural reasoning, revealing that while LLMs often interpret figurative meaning, they face major challenges in using it appropriately. To support future research, we released Kinayat, the first dataset of Egyptian Arabic idioms designed for both figurative understanding and pragmatic use evaluation. Future work should extend pragmatic evaluation to proverbs and idioms in multiple dialects, and assess pragmatic use in free-form generation to better capture the ability of models to produce culturally and contextually appropriate figurative expressions."
        },
        {
            "title": "8 Limitations",
            "content": "Scope Although our study provides new insights into the ability of large language models to understand and use Egyptian Arabic idioms and proverbs, it is important to acknowledge several limitations. First, our benchmark focuses exclusively on Egyptian idioms. Although Egyptian Arabic is highresource dialect with significant representation online and in available datasets, the observed challenges that models face in the pragmatic use of figurative language underscore the necessity for similar resources and benchmarks in other Arabic dialects, many of which are lower-resource and may present even greater challenges. Second, our evaluation is limited to idioms and proverbs, which represent only subset of figurative language phenomena. Figurative language encompasses broader range of expressions, including metaphors, similes, hyperboles, irony, sarcasm, and other culturally specific figures of speech. Future work should extend the evaluation to these additional forms to provide more comprehensive assessment of model capabilities in the understanding and generation of Arabic figurative language. Evaluation Metric Constraints Our evaluation of generated explanations has inherent limitations. The automated metrics used (BERTScore and LLM-as-a-judge) may not fully capture semantic nuances or cultural appropriateness, and their scores can diverge from human judgments. Human annotation would provide more comprehensive assessment of the quality of the generated samples. Connotations Limitations The connotations task also carries assumptions and limitations: the human labeling of idioms and proverbs can be somewhat subjective, particularly when the connotation is weak or context-dependent. This ambiguity reflects broader challenges in NLP annotation, where guidelines may fail to account for the multiplicity of cultural perspectives, leading to mismatches between annotator intent and dataset construction (Liu et al., 2025). Research has repeatedly shown that annotator biasshaped by personal and cultural backgroundcan skew labeled data, embedding specific worldviews into machine learning systems and perpetuating representational inequalities (Sap et al., 2022; Bender et al., 2021; Aroyo and Welty, 2015). Attempts to enforce consistency through guidelines and inter-annotator agreement often overlook that language is deeply contextual and values are not universally shared (Bender et al., 2021). Anthropological critiques urge moving beyond the pursuit of an objective gold standard in annotation, advocating instead for multi-layered or perspectivist models that document the diversity of meanings and cultural nuances present in corpus (Bender et al., 2021; Aroyo and Welty, 2015). Struggling with annotation from an anthropological standpoint underscores the importance of recognizing cultural context, annotator subjectivity, and the limits of value assignment in NLP, serving as reminder that data is more than numbers: it is reflection of lived sociocultural realities (Liu et al., 2025; Aroyo and Welty, 2015)."
        },
        {
            "title": "9 Ethical Considerations",
            "content": "Offensive Content Elimination The complete list of idioms in the Al-Kinayat Al-Amiyya (Pasha, 1949) book was manually reviewed and seven samples were removed that we considered inappropriate or offensive. Licenses The Kinayat dataset will be released under CC-BY 4.0 license3, permitting use, distribution, and adaptation with attribution. Annotations Two of the annotators are coauthors of this paper, while the third annotator was compensated for their time at rate of 50 USD for an estimated three hours of work, which is slightly above the minimum wage in the US. No personal information from annotators is included in the Kinayat dataset."
        },
        {
            "title": "References",
            "content": "Wafa Alghallabi, Ritesh Thawkar, Sara Ghaboura, Ketan More, Omkar Thawakar, Hisham Cholakkal, Salman Khan, and Rao Muhammad Anwer. 2025. Fann or flop: multigenre, multiera benchmark for arabic poetry understanding in llms. Preprint, arXiv:2505.18152. Israa Alsiyat and Scott Piao. 2020. Metaphorical expressions in automatic Arabic sentiment analysis. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 49114916, Marseille, France. European Language Resources Association. Fakhraddin Alwajih, Abdellah El Mekki, Samar Mohamed Magdy, AbdelRahim A. Elmadany, Omer 3https://creativecommons.org/licenses/by/4.0/ 9 Nacar, El Moatez Billah Nagoudi, Reem AbdelSalam, Hanin Atwany, Youssef Nafea, Abdulfattah Mohammed Yahya, Rahaf Alhamouri, Hamzah A. Alsayadi, Hiba Zayed, Sara Shatnawi, Serry Sibaee, Yasir Ech-chammakhy, Walid Al-Dhabyani, Marwa Mohamed Ali, Imen Jarraya, and 25 others. 2025. Palm: culturally inclusive and linguistically diverse dataset for Arabic LLMs. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3287132894, Vienna, Austria. Association for Computational Linguistics. Zaid Alyafeai, Khalid Almubarak, Ahmed Ashraf, Deema Alnuhait, Saied Alshahrani, Gubran Abdulrahman, Gamil Ahmed, Qais Gawah, Zead Saleh, Mustafa Ghaleb, Yousef Ali, and Maged Al-shaibani. 2024. CIDAR: Culturally relevant instruction dataset for Arabic. In Findings of the Association for Computational Linguistics: ACL 2024, pages 1287812901, Bangkok, Thailand. Association for Computational Linguistics. Anthropic. 2024. Introducing claude 3.5 sonnet. Anthropic. 2025. Introducing claude 4. Lora Aroyo and Chris Welty. 2015. Truth is lie: Crowd truth and the seven myths of human annotation. AI Mag., 36(1):1524. Israel Abebe Azime, Atnafu Lambebo Tonja, Tadesse Destaw Belay, Yonas Chanie, Bontu Fufa Balcha, Negasi Haile Abadi, Henok Biadglign Ademtew, Mulubrhan Abebe Nerea, Debela Desalegn Yadeta, Derartu Dagne Geremew, Assefa Atsbiha Tesfu, Philipp Slusallek, Thamar Solorio, and Dietrich Klakow. 2025. ProverbEval: Exploring LLM evaluation challenges for low-resource language understanding. In Findings of the Association for Computational Linguistics: NAACL 2025, pages 62506266, Albuquerque, New Mexico. Association for Computational Linguistics. Saiful Bari, Yazeed Alnumay, Norah A. Alzahrani, Nouf M. Alotaibi, Hisham Abdullah Alyahya, Sultan AlRashed, Faisal Abdulrahman Mirza, Shaykhah Z. Alsubaie, Hassan A. Alahmed, Ghadah Alabduljabbar, Raghad Alkhathran, Yousef Almushayqih, Raneem Alnajim, Salman Alsubaihi, Maryam Al Mansour, Saad Amin Hassan, Dr. Majed Alrubaian, Ali Alammari, Zaki Alawami, and 7 others. 2025. ALLam: Large language models for arabic and english. In The Thirteenth International Conference on Learning Representations. Emily M. Bender, Timnit Gebru, Angelina McMillanMajor, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT 21, page 610623, New York, NY, USA. Association for Computing Machinery. Tuhin Chakrabarty, Yejin Choi, and Vered Shwartz. 2022a. Its not rocket science: Interpreting figurative language in narratives. Transactions of the Association for Computational Linguistics, 10:589606. Tuhin Chakrabarty, Arkadiy Saakyan, Debanjan Ghosh, and Smaranda Muresan. 2022b. FLUTE: Figurative language understanding through textual explanations. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 71397159, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Ning Cheng, Zhaohui Yan, Ziming Wang, Zhijie Li, Jiaming Yu, Zilong Zheng, Kewei Tu, Jinan Xu, and Wenjuan Han. 2024. Potential and limitations of llms in capturing structured semantics: case study on srl. Preprint, arXiv:2405.06410. Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan Szpektor, Nan-Jiang Jiang, and 3290 others. 2025. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. Preprint, arXiv:2507.06261. John Dang, Shivalika Singh, Daniel Dsouza, Arash Ahmadian, Alejandro Salamanca, Madeline Smith, Aidan Peppin, Sungjin Hong, Manoj Govindassamy, Terrence Zhao, Sandra Kublik, Meor Amer, Viraat Aryabumi, Jon Ander Campos, Yi-Chern Tan, Tom Kocmi, Florian Strub, Nathan Grinsztajn, Yannis FletBerliac, and 26 others. 2024. Aya expanse: Combining research breakthroughs for new multilingual frontier. Preprint, arXiv:2412.04261. Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noach, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, and 5 others. 2024. The language model evaluation harness. Sara Ghaboura, Ahmed Heakl, Omkar Thawakar, Ali Husain Salem Abdulla Alharthi, Ines Riahi, Abduljalil Radman, Jorma Laaksonen, Fahad Shahbaz Khan, Salman Khan, and Rao Muhammad Anwer. 2025. CAMEL-bench: comprehensive Arabic LMM benchmark. In Findings of the Association for Computational Linguistics: NAACL 2025, pages 19701980, Albuquerque, New Mexico. Association for Computational Linguistics. Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad AlDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, and 542 others. 2024. The llama 3 herd of models. Preprint, arXiv:2407.21783. 10 Qianyu He, Sijie Cheng, Zhixu Li, Rui Xie, and Yanghua Xiao. 2022. Can pre-trained language models interpret similes as smart as human? In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 78757887, Dublin, Ireland. Association for Computational Linguistics. Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Song Dingjie, Zhihong Chen, Mosen Alharthi, Bang An, Juncai He, Ziche Liu, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, and Jinchao Xu. 2024. AceGPT, localizing large language models in Arabic. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 81398163, Mexico City, Mexico. Association for Computational Linguistics. Hyewon Jang, Qi Yu, and Diego Frassinelli. 2023. Figurative language processing: linguistically informed feature analysis of the behavior of language models and humans. In Findings of the Association for Computational Linguistics: ACL 2023, pages 98169832, Toronto, Canada. Association for Computational Linguistics. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023. Mistral 7b. Preprint, arXiv:2310.06825. Anubha Kabra, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, and Graham Neubig. 2023. Multi-lingual and multi-cultural figurative In Findings of the Assolanguage understanding. ciation for Computational Linguistics: ACL 2023, pages 82698284, Toronto, Canada. Association for Computational Linguistics. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the 29th Symposium on Operating Systems Principles, SOSP 23, page 611626, New York, NY, USA. Association for Computing Machinery. Chen Liu, Fajri Koto, Timothy Baldwin, and Iryna Gurevych. 2024. Are multilingual LLMs culturallydiverse reasoners? an investigation into multicultural proverbs and sayings. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 20162039, Mexico City, Mexico. Association for Computational Linguistics. Chen Cecilia Liu, Iryna Gurevych, and Anna Korhonen. 2025. Culturally aware and adapted NLP: taxonomy and survey of the state of the art. Transactions of the Association for Computational Linguistics, 13:652689. Emmy Liu, Chenxuan Cui, Kenneth Zheng, and Graham Neubig. 2022. Testing the ability of language models to interpret figurative language. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 44374452, Seattle, United States. Association for Computational Linguistics. Samar Mohamed Magdy, Sang Yun Kwon, Fakhraddin Alwajih, Safaa Taher Abdelfadil, Shady Shehata, and Muhammad Abdul-Mageed. 2025. JAWAHER: multidialectal dataset of Arabic proverbs for LLM benchmarking. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 1232012341, Albuquerque, New Mexico. Association for Computational Linguistics. Gonzalo Martínez, Juan Diego Molero, Sandra González, Javier Conde, Marc Brysbaert, and Pedro Reviriego. 2024. Using large language models to estimate features of multi-word expressions: Concreteness, valence, arousal. Preprint, arXiv:2408.16012. MBC. 2013. Mohamed Mounir & Nancy Ajram - (cid:16)(cid:232)(cid:80)(cid:65)(cid:103) Arab Idol. YouTube video, accessed (cid:9)(cid:225)(cid:30)(cid:10)(cid:75)(cid:10)(cid:65)(cid:16)(cid:174)(cid:130)(cid:203)(cid:64) August 8, 2025. Basel Mousi, Nadir Durrani, Fatema Ahmad, Md. Arid Hasan, Maram Hasanain, Tameem Kabbani, Fahim Dalvi, Shammur Absar Chowdhury, and Firoj Alam. 2025. AraDiCE: Benchmarks for dialectal and cultural capabilities in LLMs. In Proceedings of the 31st International Conference on Computational Linguistics, pages 41864218, Abu Dhabi, UAE. Association for Computational Linguistics. OpenAI. 2025. Introducing gpt-4.1 in the api. OpenAI. OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, and 262 others. 2024. Gpt-4 technical report. Preprint, arXiv:2303.08774. Ahmad Taymour Pasha. 1949. Al-Kinayat Al-Amiyya, 2016 edition. Muassasat Hindawi. Available in EPUB, PDF, KFX formats. Pouya Pezeshkpour and Estevam Hruschka. 2023. Large language models sensitivity to the order of Preprint, options in multiple-choice questions. arXiv:2308.11483. 11 Ben Prystawski, Paul Thibodeau, Christopher Potts, and Noah D. Goodman. 2023. Psychologicallyinformed chain-of-thought prompts for metaphor understanding in large language models. Preprint, arXiv:2209.08141. 2024. PUB: pragmatics understanding benchmark for assessing LLMs pragmatics capabilities. In Findings of the Association for Computational Linguistics: ACL 2024, pages 1207512097, Bangkok, Thailand. Association for Computational Linguistics. Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, and 25 others. 2025. Qwen2.5 technical report. Preprint, arXiv:2412.15115. Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. Abdelrahman Sadallah, Junior Cedric Tonga, Khalid Almubarak, Saeed Almheiri, Farah Atif, Chatrine Qwaider, Karima Kadaoui, Sara Shatnawi, Yaser Alesh, and Fajri Koto. 2025. Commonsense reasoning in Arab culture. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7695 7710, Vienna, Austria. Association for Computational Linguistics. Maarten Sap, Swabha Swayamdipta, Laura Vianna, Xuhui Zhou, Yejin Choi, and Noah A. Smith. 2022. Annotators with attitudes: How annotator beliefs and identities bias toxic language detection. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 58845906, Seattle, United States. Association for Computational Linguistics. Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, William Marshall, Gurpreet Gosal, Cynthia Liu, Zhiming Chen, Osama Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal, Lalit Pradhan, Zain Muhammad Mujahid, Massa Baali, Xudong Han, Sondos Mahmoud Bsharat, and 13 others. 2023. Jais and jais-chat: Arabic-centric foundation and instruction-tuned open generative large language models. Preprint, arXiv:2308.16149. Jingyuan S. She, Christopher Potts, Samuel R. Bowman, and Atticus Geiger. 2023. ScoNe: Benchmarking negation reasoning in language models with finetuning and in-context learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 18031821, Toronto, Canada. Association for Computational Linguistics. silma-ai. 2024. Silma 9b instruct v1.0. https://huggingface.co/silma-ai/ SILMA-9B-Instruct-v1.0. Settaluri Sravanthi, Meet Doshi, Pavan Tankala, Rudra Murthy, Raj Dabre, and Pushpak Bhattacharyya. Fanar Team, Ummar Abbas, Mohammad Shahmeer Ahmad, Firoj Alam, Enes Altinisik, Ehsannedin Asgari, Yazan Boshmaf, Sabri Boughorbel, Sanjay Chawla, Shammur Chowdhury, Fahim Dalvi, Kareem Darwish, Nadir Durrani, Mohamed Elfeky, Ahmed Elmagarmid, Mohamed Eltabakh, Masoomali Fatehkia, Anastasios Fragkopoulos, Maram Hasanain, and 23 others. 2025. Fanar: An arabic-centric multimodal generative ai platform. Preprint, arXiv:2501.13944. Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, Soroosh Mariooryad, Yifan Ding, Xinyang Geng, Fred Alcober, Roy Frostig, Mark Omernick, Lexi Walker, Cosmin Paduraru, Christina Sorokin, and 1118 others. 2024a. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. Preprint, arXiv:2403.05530. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, and 179 others. 2024b. Gemma 2: Improving open language models at practical size. Preprint, arXiv:2408.00118. Thinh Hung Truong, Timothy Baldwin, Karin Verspoor, and Trevor Cohn. 2023. Language models are not naysayers: an analysis of language models on negation benchmarks. In Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023), pages 101114, Toronto, Canada. Association for Computational Linguistics. Koki Wataoka, Tsubasa Takahashi, and Ryokan Ri. 2024. Self-preference bias in LLM-as-a-judge. In Neurips Safe Generative AI Workshop 2024. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: EvalIn International uating text generation with bert. Conference on Learning Representations. Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang. 2024. Large language models are not robust multiple choice selectors. Preprint, arXiv:2309.03882. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track."
        },
        {
            "title": "A Prompt Templates",
            "content": "The prompts used across our evaluation tasks are illustrated in Figures 515. Figure 5 presents the prompt for the MCQ understanding task, while Figure 6 shows the version that includes the idioms sentence context. Figures 7 and 8 display the prompts used to generate incorrect distractors for the MCQ task, the latter leveraging semantic role labeling. Figure 9 illustrates the prompt used to complete proverbs by predicting the final word, and Figure 10 depicts the negated version of the MCQ understanding task. The generation-based prompt used to produce incorrect explanations is shown in Figure 11, with their evaluation guided by the judging prompt in Figure 12. Figure 13 displays the prompt used to generate example sentences containing idioms from Kinayat prior to human post-editing. Finally, Figures 14 and 15 show the prompts for the pragmatic use and connotation labeling tasks, respectively. In all prompt templates that include the word proverb, they refer to items from the Jawaher dataset of proverbs. For the Kinayat dataset of idioms, the word proverb in the templates was replaced with idiom to match the dataset content. You are tasked with selecting the correct explanation for the following proverb. Choose the correct explanation from the options provided. Only output the letter corresponding to the correct answer and nothing else. Proverb: [PROVERB] Options: A. [OPTION 1] B. [OPTION 2] Answer: Figure 5: Prompt used for the MCQ understanding task. You are tasked with selecting the correct explanation for the following idiom, given the idiom in sentence for context. Choose the correct explanation from the options provided. Only output the letter corresponding to the correct answer and nothing else. Idiom: [IDIOM] Sentence: [SENTENCE] Options: A. [OPTION 1] B. [OPTION 2] Answer: Figure 6: Prompt used for the Contextual MCQ Idiom Explanation task. Given the following correct explanation, generate an incorrect explanation that sounds plausible and is not trivially incorrect. Only output the incorrect explanation and nothing else Correct explanation: [correct explanation] Figure 7: Prompt used for the generating incorrect explanantions. Your task is to generate an incorrect explanation from the provided correct explanation by following the given steps: 1Find the semantic role labels for the sentence. 2Change one of the semantic role labels. 3Generate an explanation using the new semantic role labels. Only output the result in the following JSON format: {semantic_role_labels: , new_labels: , new_sentence:} Correct explanation: [correct explanation] Figure 8: Prompt used for generating incorrect explanations using semantic role labeling. 13 You are tasked with completing the proverb with the last word. Output the next word only. Incomplete Proverb: [incomplete proverb] Answer: Figure 9: Prompt used for last-word proverb completion. You are an expert in Arabic language and culture. Your task is to evaluate how well generated explanation matches the intended meaning of the reference explanation of an Arabic idiom/proverb. Below is reference (gold) explanation and generated explanation. Rate the accuracy of the generated explanation based on how well it preserves the intended meaning of the idiom/proverb. Gold Explanation: {gold_explanation} Generated ated_explanation} Explanation: {generYou are tasked with selecting the incorrect explanation for the following proverb. Choose the incorrect explanation from the options provided. Only output the letter corresponding to the incorrect answer and nothing else. Proverb: [PROVERB] Options: A. [OPTION 1] B. [OPTION 2] Answer: Figure 10: Prompt used for the MCQ negation task. Your task is to explain the meaning of the following Arabic proverb. Provide clear and concise explanation in Arabic, highlighting its figurative meaning and any cultural or contextual significance. Only output the Arabic explanation and nothing else. Proverb: [PROVERB] Arabic Explanation: Use the following rating scale: 5 = Excellent: Perfectly matches the gold explanation in meaning. 4 = Good: Minor omissions or phrasing differences, but the meaning is well preserved. 3 = Fair: Partial understanding, some inaccuracies or missing key aspects. 2 = Poor: Significant misunderstanding or loss of core meaning. 1 = Very Poor: Completely incorrect or irrelevant explanation. Only output numerical rating and nothing else. Rating (15): Figure 12: Prompt used for LLM-as-a-judge rating of idiom/proverb explanation quality. Generate sample sentence using the following idiom in the correct context in the Egyptian Arabic dialect given the following explanation of the idiom. Idiom: {idiom} Explanation: {explanation} Only output the sentence and nothing else. Figure 11: Prompt used for the task of generating explanations. Figure 13: Prompt for generating an Egyptian Arabic sentence using given idiom in context. 14 Your task is to fill in the blank with the correct idiom. Choose the correct idiom from the options provided. Only output the letter corresponding to the correct answer and nothing else. Sentence: [sentence with blank] Options: A. [OPTION 1] B. [OPTION 2] Answer: Figure 14: Prompt used for the idiom pragmatic use task. Determine the connotation of the following Arabic proverb or explanation. Classify the connotation as Positive, Negative, or Neutral based on the following guidelines: Positive Connotation: It conveys optimism, It hope, praise, or beneficial outcomes. highlights virtues such as kindness, success, loyalty, or happiness. It encourages or celebrates desirable behaviors or outcomes. Negative Connotation: It expresses pessimism, caution, loss, or undesirable consequences. It highlights flaws, mistakes, or risks and often reflects on the dangers or negative results of certain actions. Neutral Connotation: It provides general advice or observation without invoking strong feelings or judgment. Proverb/Explanation: EXPLANATION] [PROVERB OR Only output the connotation and nothing else. Connotation: Figure 15: Prompt used for connotation classification of Arabic proverbs and their explanations."
        },
        {
            "title": "C Data Analysis",
            "content": "Figure 16 shows the annotation guidelines for verifying the quality of the generated incorrect explanations used as distractors in the MCQ understanding task. Task Overview single annotator evaluated the quality of automatically generated incorrect explanations for idioms and proverbs. The goal was to determine whether each explanation was both plausible and incorrect, ensuring that it functioned as meaningful distractor rather than trivial or nonsensical option. Inputs For each sample, the annotator was provided with: the idioms/proverbs, the correct explanations (true meaning), and the corresponding generated incorrect explanations. Annotation Guidelines Each incorrect explanation was rated on 02 scale based on its plausibility, distinctness from the correct explanation, and linguistic coherence. Use the following rating scale: 2 = High-Quality Incorrect (Plausible but Wrong): The explanation is clearly incorrect yet plausible. It makes sense linguistically and culturally, could realistically confuse reader, and differs semantically from the correct meaning. 1 = Medium-Quality Incorrect (Too Similar or Slightly Off): The explanation is partially incorrect, implausible or too close in meaning to the correct one (e.g., paraphrase or mild variation). It shows partial understanding but fails to be strong distractor. (Implausible 0 = Low-Quality Incorrect or Unrelated): The explanation is either correct, or clearly irrelevant, nonsensical, or incomplete. It fails to make sense in context and would not plausibly be mistaken for the correct meaning. Figure 16: Guidelines for human verification of incorrect explanations generated by GPT-4.1. Figure 17 shows the sequence length distributions for idioms and proverbs, with corresponding statistics in Table 4, highlighting that proverbs exhibit higher mean sentence length than idioms. To assess semantic similarity, we compute cosine similarity between sentence embeddings using the paraphrase-multilingual-mpnet-base-v2 model (Reimers and Gurevych, 2019), comparing correct and incorrect explanations generated with the general prompt (Figure 7) and the SRLbased prompt (Figure 8). As shown in Figure 18, the incorrect explanations produced by the general prompt result in roughly normal-shaped distribution (mean = 0.6596), whereas the SRL-based prompt leads to highly right-skewed distribution (mean = 0.9239). Figure 19 presents the distribution of cosine similarity between the two idiom options in the pragmatic use task, with mean similarity of 0.743. Statistic Samples Mean Median Std Range Kinayat 325 2.79 3.0 1.08 1 8 Jawaher 198 5.21 5.0 1.98 2 Table 4: Dataset Statistics for Kinayat and Jawaher Figure 17: Sequence Length Distributions for Idioms and Proverbs"
        },
        {
            "title": "D Additional Results",
            "content": "MCQ Positional Selection Bias Research has shown that LLMs can favor certain answer choices due to token-level prior probabilities (Zheng et al., 2024; Pezeshkpour and Hruschka, 2023). We ran the evaluation with both permutations of the correct and incorrect answers. When the correct answer was always listed first, models performed better 16 MCQ Model 0.8182 0.0275 Llama-3.1-8B-Instruct 0.9343 0.0176 Gemma-2-9B-it 0.9141 0.0200 Qwen2.5-7B-Instruct 0.9192 0.0194 Qwen2.5-14B-Instruct 0.9293 0.0183 Mistral-7B-Instruct-v0.3 0.6212 0.0346 Jais-family-6p7b-chat 0.9444 0.0163 Fanar-1-9B-Instruct 0.9444 0.0163 SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview 0.9141 0.0200 0.8838 0.0228 Aya-expanse-8b 0.9293 0.0183 Aya-expanse-32b 0.9697 0.0122 AceGPT-v2-8B-Chat 0.9848 0.0087 Claude-Sonnet-4 0.9949 0.0051 Claude-3.5-Sonnet 0.9545 0.0148 Gemini-1.5-flash 0.9899 0.0071 GPT-4o 0.9848 0.0087 GPT-4o-mini Average 0.9195 MCQ 0.6667 0.0336 0.8788 0.0233 0.7828 0.0294 0.9091 0.0205 0.2475 0.0307 0.8182 0.0275 0.8434 0.0259 0.7475 0.0310 0.8737 0.0237 0.6667 0.0336 0.8838 0.0228 0.5202 0.0356 0.9798 0.0100 0.9747 0.0112 0.9091 0.0205 0.9646 0.0132 0.8737 0.0237 0.7965 Difference 0.1515 0.0556 0.1313 0.0101 0.6818 -0.1970 0.1010 0.1970 0.0404 0.2172 0.0455 0.4495 0.0051 0.0202 0.0455 0.0253 0.1111 0.1230 Table 5: Accuracy ()stderr () on the positional bias MCQ understanding task for variants and B, and their difference (A B) on the Jawaher dataset (general prompt used for generating incorrect choices) for subset of models. and SRL-based prompts, respectively. Mauritania and Sudan consistently appear among the lowestperforming dialects in both settings, whereas UAE and MSA remain within the top-performing group across both prompting strategies. Tables 13 and 14 provide detailed country-level results for the Jawaher dataset under each prompt condition, and Table 15 reports the average accuracy across the two settings. Pragmatic Use: Figure 22 visualizes model performance on the pragmatic use, MCQ understanding, and contextual MCQ understanding tasks using 150-idiom subset from the Kinayat dataset, corresponding to the results reported in Table 3. consistent performance gradient emerges, with the pragmatic use task yielding the lowest scores, followed by MCQ understanding, and the highest performance observed in contextual MCQ understanding. Connotations: Table 11 presents the connotation task results for the Jawaher and Kinayat datasets, restricted to samples with full inter-annotator agreement (105 entries for Jawaher and 104 for Kinayat). Among all models, the Claude family (Claude Sonnet 4 and Claude 3.5 Sonnet) achieved the highest performance. Overall, proverb connotations were slightly harder to identify than idiomatic ones, with lower average model agreement (49.71% vs. 50.10%). However, models demonstrated stronger performance when inferring connotations from the explanations, achieving average accuracies of 68.17% for proverbs and 72.21% for idioms. Figure 18: Cosine similarity () between the correct and incorrect explanation choices for proverbs (Jawaher) Figure 19: Cosine similarity () between the correct and incorrect idiom choices for the pragmatic use task (91.95% vs. 79.65% average accuracy), as shown in Table 5. For the remaining experiments, the order of the options was randomized to mitigate this bias. Knowledge and Understanding: Table 8 reports MCQ understanding performance across all datasets (MAPS, Kinayat, and Jawaher), while Table 9 compares results on Kinayat and Jawaher under both the general and SRL-based prompting strategies. The highest accuracy is observed on English proverbs with context (95.66%), followed by English proverbs without context (90.86%), multidialectal Arabic proverbs (86.57%), and Egyptian Arabic idioms, which yield the lowest accuracy (76.29%). Table 6 presents results for the task in which models are asked to identify the incorrect explanation (generated using the general prompt), showing decline in performance compared to selecting the correct explanation. Table 7 summarizes results for the completion task, where substantial performance gap emerges between Arabic and English proverb completion (10.64% vs. 75.43%). Country Breakdown: Figures 20 and 21 illustrate country-level accuracies in descending order for the MCQ Understanding task using the general 17 Overall Performance: Table 12 presents the average performance of multilingual open-source, Arabic open-source, and closed-source models across all tasks. On average, multilingual opensource models slightly outperformed Arabic models on most tasks; however, Arabic models led on proverb completion, Kinayat MCQ (SRL-prompt), Kinayat pragmatic use, and explanation generation for both proverbs and idioms. These averages, however, mask variation within each category. For example, the multilingual model Mistral-7BInstruct performed below most Arabic models on several tasks. In contrast, closed-source models consistently outperformed both Arabic and multilingual open-source models across all evaluations. One potential contributing factor is model scale, as closed-source systems are generally assumed to be larger than the open-source models evaluated, though their exact sizes are not publicly disclosed. Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9B-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct-v0.3 Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite-preview-06-17 GPT-4o GPT-4o-mini Average Kinayat 0.6492 0.0265 0.5508 0.0276 0.6031 0.0272 0.8123 0.0217 0.6277 0.0269 0.7908 0.0226 0.8000 0.0222 0.4923 0.0278 0.6062 0.0271 0.5846 0.0274 0.5815 0.0274 0.5354 0.0277 0.8000 0.0222 0.5754 0.0275 0.8092 0.0218 0.5969 0.0273 0.9446 0.0127 0.9169 0.0153 0.7785 0.0231 0.8308 0.0208 0.9477 0.0124 0.7785 0.0231 0.7097 0. Jawaher 0.7424 0.0312 0.6919 0.0329 0.8384 0.0262 0.9192 0.0194 0.7677 0.0301 0.8737 0.0237 0.9141 0.0200 0.5808 0.0352 0.7374 0.0314 0.7020 0.0326 0.7980 0.0286 0.8131 0.0278 0.8990 0.0215 0.7020 0.0326 0.8586 0.0248 0.7374 0.0314 0.9697 0.0122 0.9747 0.0112 0.8939 0.0219 0.9242 0.0189 0.9798 0.0100 0.8788 0.0233 0.8271 0.0000 Table 6: Accuracy ()stderr () on the task of selecting the incorrect explanation for Kinayat and Jawaher datasets. Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9B-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct-v0.3 Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite-preview-06-17 GPT-4o GPT-4o-mini Average MAPS 0.6954 0.0232 0.8756 0.0166 0.8046 0.0200 0.6751 0.0236 0.6421 0.0242 0.7792 0.0209 0.8401 0.0185 0.7614 0.0215 0.2995 0.0231 0.3604 0.0242 0.8046 0.0200 0.8756 0.0166 0.7107 0.0229 0.5051 0.0252 0.7107 0.0229 0.7690 0.0213 0.9340 0.0125 0.9391 0.0121 0.9061 0.0147 0.8782 0.0165 0.9340 0.0125 0.8934 0.0156 0.7543 Jawaher 0.0253 0.0112 0.0707 0.0183 0.0556 0.0163 0.0808 0.0194 0.0253 0.0112 0.0354 0.0132 0.0606 0.0170 0.0000 0.0000 0.0303 0.0122 0.0152 0.0087 0.1111 0.0224 0.0354 0.0132 0.1313 0.0241 0.0556 0.0163 0.1364 0.0245 0.0808 0.0194 0.2980 0.0326 0.3636 0.0343 0.1212 0.0233 0.2273 0.0299 0.2879 0.0323 0.0960 0.0210 0.1065 Table 7: Evaluation results of completion task (accuracy ()stderr ()) for different models on MAPS and Jawaher datasets. Figure 20: Country-level breakdown of MCQ Understanding Accuracy (incorrect distractor generated with general prompt) Figure 21: Country-level breakdown of MCQ Understanding Accuracy (incorrect distractor generated with SRL-based prompt) 18 Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9B-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct-v0.3 Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite-preview-06-17 GPT-4o GPT-4o-mini Average MAPS 0.8655 0.0172 0.9239 0.0134 0.9365 0.0123 0.9340 0.0125 0.9239 0.0134 0.9391 0.0121 0.9391 0.0121 0.8579 0.0176 0.7640 0.0214 0.8376 0.0186 0.9010 0.0151 0.9492 0.0111 0.8807 0.0164 0.8858 0.0160 0.9340 0.0125 0.9112 0.0144 0.9340 0.0125 0.9543 0.0105 0.9239 0.0134 0.8832 0.0162 0.9619 0.0097 0.9492 0.0111 0.9086 MAPS + Context 0.9213 0.0136 0.9873 0.0056 0.9670 0.0090 0.9721 0.0083 0.9492 0.0111 0.9695 0.0087 0.9924 0.0044 0.9213 0.0136 0.8680 0.0171 0.9162 0.0140 0.9442 0.0116 0.9569 0.0102 0.9365 0.0123 0.9315 0.0127 0.9797 0.0071 0.9543 0.0105 0.9797 0.0071 0.9772 0.0075 0.9746 0.0079 0.9746 0.0079 0.9873 0.0056 0.9848 0.0062 0. Jawaher 0.7475 0.0310 0.8990 0.0215 0.9091 0.0205 0.8990 0.0215 0.8535 0.0252 0.8990 0.0215 0.9192 0.0194 0.6061 0.0348 0.7525 0.0307 0.7626 0.0303 0.8737 0.0237 0.8737 0.0237 0.8636 0.0245 0.7929 0.0289 0.8939 0.0219 0.7475 0.0310 0.9798 0.0100 0.9848 0.0087 0.9343 0.0176 0.9596 0.0140 0.9798 0.0100 0.9141 0.0200 0.8657 Kinayat 0.5754 0.0275 0.8831 0.0179 0.7354 0.0245 0.7908 0.0226 0.7262 0.0248 0.7938 0.0225 0.8000 0.0222 0.5169 0.0278 0.7046 0.0253 0.6769 0.0260 0.7508 0.0240 0.6277 0.0269 0.7846 0.0228 0.6338 0.0268 0.8154 0.0216 0.5754 0.0275 0.9662 0.0100 0.9415 0.0130 0.8185 0.0214 0.9077 0.0161 0.9415 0.0130 0.8185 0.0214 0.7629 Table 8: Evaluation results (accuracy ()stderr ()) of multiple choice understanding task on different test sets. The incorrect explanation choices for Jawaher and Kinayat for the results shown here were generated with the general prompt. Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9B-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct-v0.3 Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite-preview-06-17 GPT-4o GPT-4o-mini Average Jawaher (General) 0.7475 0.0310 0.8990 0.0215 0.9091 0.0205 0.8990 0.0215 0.8535 0.0252 0.8990 0.0215 0.9192 0.0194 0.6061 0.0348 0.7525 0.0307 0.7626 0.0303 0.8737 0.0237 0.8737 0.0237 0.8636 0.0245 0.7929 0.0289 0.8939 0.0219 0.7475 0.0310 0.9798 0.0100 0.9848 0.0087 0.9343 0.0176 0.9596 0.0140 0.9798 0.0100 0.9141 0.0200 0.8657 Jawaher (SRL) Kinayat (General) Kinayat (SRL) 0.6400 0.0267 0.5754 0.0275 0.7475 0.0310 0.8492 0.0199 0.8990 0.0215 0.9141 0.0200 0.7692 0.0234 0.7354 0.0245 0.8838 0.0228 0.8123 0.0217 0.7908 0.0226 0.8939 0.0219 0.7815 0.0230 0.7262 0.0248 0.8687 0.0241 0.8431 0.0202 0.7938 0.0225 0.9293 0.0183 0.8308 0.0208 0.8000 0.0222 0.9545 0.0148 0.5262 0.0277 0.5169 0.0278 0.5960 0.0350 0.7262 0.0248 0.7046 0.0253 0.7929 0.0289 0.7446 0.0242 0.6769 0.0260 0.7879 0.0291 0.7446 0.0242 0.7508 0.0240 0.8737 0.0237 0.7415 0.0243 0.6277 0.0269 0.8485 0.0255 0.8462 0.0200 0.7846 0.0228 0.8586 0.0248 0.7323 0.0246 0.6338 0.0268 0.7677 0.0301 0.8185 0.0214 0.8154 0.0216 0.9242 0.0189 0.6585 0.0263 0.5754 0.0275 0.7576 0.0305 0.9077 0.0161 0.9662 0.0100 0.9848 0.0087 0.9046 0.0163 0.9415 0.0130 0.9646 0.0132 0.8738 0.0184 0.8185 0.0214 0.8990 0.0215 0.8431 0.0202 0.9077 0.0161 0.9343 0.0176 0.9138 0.0156 0.9415 0.0130 0.9596 0.0140 0.7662 0.0235 0.8185 0.0214 0.8586 0.0248 0.7852 0.7629 0. Table 9: Accuracy ()stderr () on Jawaher and Kinayat datasets with incorrect explanations generated by general vs. SRL variant prompt. 19 Figure 22: Accuracy () on Pragmatic Use and Understanding tasks on 150 samples from the Kinayat dataset Model Jawaher Kinayat Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9B-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct-v0.3 Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite-preview-06-17 GPT-4o GPT-4o-mini Average BERT-F1 0.5988 0.0022 0.6816 0.0021 0.6774 0.0022 0.6893 0.0019 0.6759 0.0020 0.6651 0.0031 0.6737 0.0023 0.6695 0.0019 0.6762 0.0028 0.6598 0.0033 0.6799 0.0019 0.6856 0.0026 0.6893 0.0021 0.6794 0.0018 0.6820 0.0019 0.6730 0.0017 0.6990 0.0018 0.6998 0.0017 0.6700 0.0020 0.6827 0.0020 0.6811 0.0022 0.6813 0.0019 0.6759 LLM-Judge 2.1111 0.0701 3.1869 0.0934 2.9293 0.0899 3.0455 0.0921 2.5303 0.0793 2.8485 0.1071 3.2020 0.0974 2.1313 0.0528 2.2071 0.0703 2.4495 0.0812 3.3535 0.0899 2.5556 0.0824 3.2727 0.0902 2.9343 0.0859 3.4646 0.0935 3.0606 0.0870 3.7778 0.0848 3.8939 0.0887 3.5152 0.0911 3.6818 0.0921 3.6667 0.0982 3.4394 0.1029 3.0572 BERT-F1 0.5714 0.0015 0.6486 0.0017 0.6492 0.0018 0.6793 0.0012 0.6584 0.0012 0.6560 0.0013 0.6541 0.0016 0.6373 0.0019 0.6226 0.0028 0.6267 0.0023 0.6687 0.0011 0.6581 0.0025 0.6675 0.0011 0.6633 0.0012 0.6615 0.0014 0.6455 0.0010 0.6795 0.0012 0.6798 0.0013 0.6360 0.0028 0.6684 0.0013 0.6560 0.0011 0.6552 0.0010 0.6520 LLM-Judge 1.5292 0.0350 2.1138 0.0531 2.0862 0.0452 2.1877 0.0517 2.0646 0.0477 2.1662 0.0518 2.2092 0.0566 1.7415 0.0335 1.5200 0.0419 1.7108 0.0430 2.3200 0.0555 1.6923 0.0417 2.3077 0.0606 2.1815 0.0512 2.4123 0.0595 2.0031 0.0450 2.6646 0.0687 2.9262 0.0724 2.4769 0.0587 2.8400 0.0700 2.9046 0.0819 2.1231 0.0682 2.1901 Table 10: Explanation generation scores using BERTScore-F1 () and LLM-as-a-judge () for Jawaher and Kinayat. 20 Proverb Model 0.5577 0.0489 Llama-3.1-8B-Instruct 0.2788 0.0442 Llama-3.1-70B-Instruct 0.6058 0.0482 Gemma-2-9B-it 0.6250 0.0477 Gemma-2-27b-it 0.5288 0.0492 Qwen2.5-7B-Instruct 0.6442 0.0472 Qwen2.5-14B-Instruct 0.5673 0.0488 Qwen2.5-32B-Instruct 0.5096 0.0493 Mistral-7B-Instruct-v0.3 0.2019 0.0396 Jais-family-6p7b-chat 0.1635 0.0364 Jais-family-13b-chat 0.4327 0.0488 Fanar-1-9B-Instruct 0.3654 0.0474 SILMA-9B-Instruct-v1.0 ALLaM-7B-Instruct-preview 0.2308 0.0415 0.3462 0.0469 Aya-expanse-8b 0.5962 0.0483 Aya-expanse-32b 0.4808 0.0492 AceGPT-v2-8B-Chat 0.7115 0.0446 Claude-Sonnet-4 0.7404 0.0432 Claude-3.5-Sonnet 0.7115 0.0446 GPT-4o 0.6442 0.0472 GPT-4o-mini Average 0.4971 Proverb Explanation 0.7019 0.0451 0.7019 0.0451 0.7981 0.0396 0.7885 0.0402 0.7788 0.0409 0.7788 0.0409 0.8173 0.0381 0.7404 0.0432 0.2692 0.0437 0.1635 0.0364 0.7115 0.0446 0.7308 0.0437 0.3173 0.0459 0.6058 0.0482 0.7308 0.0437 0.7308 0.0437 0.8654 0.0336 0.8077 0.0388 0.7981 0.0396 0.7981 0.0396 0.6817 Idiom 0.7404 0.0432 0.2115 0.0402 0.7692 0.0415 0.8269 0.0373 0.5481 0.0490 0.7692 0.0415 0.5769 0.0487 0.4423 0.0489 0.0865 0.0277 0.0865 0.0277 0.3750 0.0477 0.2500 0.0427 0.1923 0.0388 0.2596 0.0432 0.3462 0.0469 0.2596 0.0432 0.8365 0.0364 0.8558 0.0346 0.8462 0.0356 0.7404 0.0432 0.5010 Idiom Explanation 0.7692 0.0415 0.8269 0.0373 0.8654 0.0336 0.8750 0.0326 0.8365 0.0364 0.8558 0.0346 0.8558 0.0346 0.8558 0.0346 0.1442 0.0346 0.0865 0.0277 0.8077 0.0388 0.8654 0.0336 0.1923 0.0388 0.5769 0.0487 0.7788 0.0409 0.7788 0.0409 0.8942 0.0303 0.9038 0.0290 0.8558 0.0346 0.8173 0.0381 0.7221 Table 11: Accuracy () and standard error () for the connotations of proverbs, their explanations (Jawaher dataset), idioms, and their explanations (Kinayat dataset). Task MAPS MCQ MAPS MCQ Context MAPS Completion English Average Accuracy Jawaher MCQ (general) Jawaher MCQ (SRL) Jawaher MCQ Negation Jawaher Completion Kinayat MCQ (general) Kinayat MCQ (SRL) Kinayat MCQ Negation Kinayat Pragmatic Use Kinayat MCQ (150 samples) Kinayat MCQ Context (150 samples) Arabic Average Accuracy Jawaher Generation BERTScore-F1 Kinayat Generation BERTScore-F1 Arabic Average BERTScore-F1 Jawaher Generation LLM-Judge Kinayat Generation LLM-Judge Arabic Average LLM-Judge Multilingual Average 0.9137 0.9561 0.7426 0.8708 0.8333 0.8391 0.8052 0.0404 0.7055 0.7433 0.6822 0.5943 0.7314 0.8600 0.6835 0.6642 0.6437 0.6539 2.6854 1.9978 2.3416 Arabic Average 0.8829 0.9359 0.6294 0.8161 0.8201 0.8264 0.7809 0.0745 0.6962 0.7515 0.6362 0.5975 0.7225 0.8575 0.6763 0.6699 0.6458 0.6578 2.7273 2.0023 2.3648 Closed-Source Average 0.9344 0.9797 0.9141 0.9428 0.9588 0.9335 0.9369 0.2323 0.8990 0.8682 0.8662 0.7678 0.9144 0.9622 0.8339 0.6857 0.6625 0.6741 3.6625 2.6559 3.1592 Table 12: Performance results () across different tasks and evaluation metrics (Multilingual Average exludes Llama-3.1 70B Instruct model). 21 Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9b-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct ALLaM-7B-Instruct Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite GPT-4o GPT-4o-mini Average EGY MSA UAE JOR MAU PAL ALG SYR IRQ LEB 0.444 0.778 0.778 0.778 0.889 0.889 0.778 1.000 0.889 1.000 1.000 0.889 1.000 1.000 0.556 0.889 0.556 0.556 0.889 0.889 1.000 0.778 0.889 0.778 0.667 1.000 0.556 0.889 1.000 0.889 0.778 0.778 0.889 1.000 1.000 1.000 1.000 0.889 1.000 1.000 1.000 1.000 1.000 0.889 0.869 0.798 0.900 1.000 0.900 0.900 1.000 0.900 1.000 0.800 1.000 1.000 0.900 0.900 0.900 1.000 1.000 0.700 1.000 1.000 0.900 1.000 0.900 1.000 0.936 0.400 0.900 0.900 0.800 0.600 0.900 0.800 0.300 0.800 0.500 0.700 0.600 1.000 0.600 0.600 0.400 1.000 1.000 0.800 0.900 1.000 0.600 0.791 0.455 0.909 0.909 0.909 0.909 0.818 0.909 0.636 0.455 0.636 1.000 0.818 0.545 0.727 0.818 0.545 1.000 1.000 0.909 1.000 1.000 0.909 0. 0.800 1.000 1.000 0.800 0.800 0.700 0.900 0.500 0.700 0.900 0.800 1.000 0.800 0.700 0.800 0.800 1.000 1.000 1.000 0.900 1.000 0.900 0.891 0.700 1.000 1.000 1.000 0.800 0.800 1.000 0.600 0.500 0.700 0.800 0.800 0.900 0.800 0.900 0.800 1.000 1.000 0.900 1.000 1.000 0.900 0.882 0.700 1.000 0.900 0.800 0.900 0.800 0.800 0.700 0.600 0.600 0.900 0.900 0.900 0.700 0.900 0.800 0.900 1.000 1.000 1.000 1.000 0.800 0.909 1.000 1.000 1.000 1.000 0.900 1.000 1.000 0.900 0.900 0.900 1.000 1.000 1.000 1.000 1.000 0.900 1.000 1.000 1.000 1.000 1.000 1.000 0.932 1.000 0.900 1.000 0.900 0.700 0.900 0.900 0.700 0.900 1.000 0.900 1.000 1.000 0.900 1.000 0.800 1.000 1.000 1.000 0.900 1.000 1.000 0.841 SAU YEM MOR QAT SUD KUW OMA TUN BAH LIB 0.900 0.800 1.000 1.000 0.900 1.000 1.000 1.000 0.800 0.800 1.000 0.900 0.900 1.000 0.700 0.400 0.900 0.900 0.700 0.500 0.900 1.000 1.000 0.800 0.800 0.900 0.900 0.500 1.000 0.800 0.900 0.600 1.000 1.000 1.000 1.000 1.000 0.900 1.000 1.000 1.000 1.000 1.000 1.000 0.918 0. 1.000 0.778 0.889 1.000 1.000 1.000 1.000 0.667 1.000 1.000 1.000 1.000 0.889 1.000 1.000 0.778 1.000 1.000 1.000 1.000 1.000 1.000 0.833 0.700 0.900 0.900 1.000 0.900 0.900 0.900 0.500 1.000 0.700 1.000 1.000 1.000 0.800 0.900 0.700 1.000 1.000 1.000 1.000 1.000 0.800 0.868 0.900 0.900 0.900 1.000 1.000 1.000 1.000 0.700 0.900 0.800 1.000 0.900 0.800 1.000 1.000 0.900 1.000 1.000 1.000 0.900 1.000 1.000 0.864 0.700 0.800 0.800 0.900 0.800 0.800 0.900 0.700 0.800 0.700 0.800 0.700 0.900 0.700 0.900 0.800 1.000 0.900 0.900 1.000 1.000 1.000 0.886 0.400 0.900 0.900 0.800 0.700 1.000 0.800 0.400 0.500 0.400 0.600 0.800 0.700 0.600 0.900 0.500 1.000 0.900 0.800 0.900 1.000 0.800 0.755 0.700 0.900 1.000 0.900 1.000 1.000 0.900 0.300 0.700 0.800 0.900 1.000 0.900 0.900 1.000 0.800 1.000 1.000 0.900 1.000 1.000 0.900 0. 0.900 0.900 0.700 0.800 0.800 0.800 0.900 0.500 0.700 0.800 0.800 1.000 0.900 0.600 0.800 0.900 0.900 1.000 0.900 0.900 0.800 0.800 0.836 0.800 1.000 0.800 0.800 0.800 0.900 0.800 0.800 0.600 0.800 0.800 0.800 0.800 1.000 0.800 0.900 0.900 0.900 0.900 0.800 0.900 1.000 0.941 Table 13: Accuracy () of models across Arabic dialects and countries (with the general prompt). Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9b-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct ALLaM-7B-Instruct Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite GPT-4o GPT-4o-mini Average EGY MSA UAE JOR MAU PAL ALG SYR IRQ LEB 0.778 0.444 1.000 1.000 0.889 0.778 0.778 0.667 1.000 0.667 0.889 0.778 1.000 0.889 0.556 1.000 0.667 0.778 0.778 0.556 0.889 0.778 1.000 0.889 0.778 0.889 0.889 0.667 0.889 0.889 0.778 0.778 1.000 1.000 1.000 1.000 0.889 0.778 1.000 0.889 1.000 1.000 0.889 0.889 0.879 0.808 0.700 0.900 0.800 1.000 0.900 1.000 0.900 0.500 0.900 0.900 1.000 0.900 0.900 0.900 0.900 0.800 0.900 1.000 0.900 1.000 1.000 0.800 0. 1.000 0.900 1.000 1.000 1.000 1.000 1.000 0.500 0.900 0.800 1.000 1.000 0.900 0.800 1.000 0.700 1.000 1.000 1.000 1.000 0.900 1.000 0.932 0.700 0.700 0.900 0.800 0.600 0.800 1.000 0.600 0.700 0.700 0.700 0.800 0.800 0.800 0.800 0.400 0.900 1.000 0.900 0.800 1.000 0.900 0.782 0.455 0.818 0.818 1.000 1.000 1.000 1.000 0.909 0.545 0.909 1.000 0.818 0.818 0.818 0.909 0.909 1.000 1.000 0.909 1.000 1.000 0.909 0.888 0.900 0.800 1.000 1.000 0.900 0.900 0.900 0.700 0.900 0.900 0.800 1.000 0.700 0.700 1.000 0.800 1.000 1.000 0.900 0.900 1.000 0.800 0.882 0.800 0.900 0.900 1.000 1.000 1.000 1.000 0.800 0.900 0.900 0.900 0.800 0.900 0.800 1.000 0.900 1.000 1.000 1.000 1.000 1.000 1.000 0.927 1.000 0.800 1.000 1.000 0.900 1.000 1.000 0.500 0.700 0.900 1.000 1.000 0.900 0.800 1.000 0.800 1.000 1.000 0.900 0.800 1.000 0.800 0. 0.700 0.600 0.900 0.800 0.700 0.800 1.000 0.600 0.600 0.800 0.900 1.000 0.800 0.700 0.900 0.700 1.000 1.000 0.900 0.900 1.000 1.000 0.827 SAU YEM MOR QAT SUD KUW OMA TUN BAH LIB 0.700 0.900 0.900 1.000 0.900 0.800 1.000 0.900 1.000 0.900 1.000 1.000 1.000 1.000 0.500 0.500 1.000 0.800 0.700 0.800 0.900 0.700 0.900 1.000 0.900 1.000 0.900 0.500 0.900 0.900 0.900 0.300 1.000 1.000 1.000 1.000 1.000 0.900 1.000 1.000 1.000 1.000 1.000 0.800 0.914 0.845 0.667 0.667 0.778 0.778 0.778 1.000 0.889 0.444 0.778 0.889 0.889 0.667 1.000 0.778 0.889 0.667 1.000 1.000 0.667 1.000 1.000 1.000 0.828 0.800 0.800 0.900 1.000 1.000 0.900 1.000 0.600 0.700 0.600 0.900 0.900 0.900 0.700 0.900 0.900 1.000 1.000 0.900 1.000 1.000 0.700 0.864 0.600 0.900 0.900 0.900 0.700 1.000 1.000 0.800 0.700 0.800 1.000 0.900 0.900 0.900 1.000 0.900 1.000 0.900 0.900 1.000 1.000 0.800 0.891 0.600 0.800 0.900 0.900 0.900 0.900 1.000 0.700 0.900 0.700 0.900 0.800 0.700 0.800 0.900 0.800 1.000 1.000 1.000 0.900 1.000 0.800 0. 0.600 0.600 0.700 0.700 0.800 0.800 0.800 0.300 0.800 0.700 0.800 0.700 0.600 0.700 1.000 0.700 0.900 0.900 0.800 0.900 1.000 0.800 0.741 0.800 0.700 0.900 0.800 0.800 0.900 0.900 0.300 0.700 0.600 0.600 0.700 0.800 0.700 0.900 0.800 1.000 1.000 0.800 1.000 1.000 0.600 0.768 0.900 1.000 1.000 1.000 0.900 1.000 1.000 0.700 0.900 0.900 0.900 0.900 0.900 0.900 1.000 0.800 1.000 0.900 1.000 0.800 0.900 1.000 0.941 0.800 0.600 0.800 0.800 0.800 1.000 0.900 0.400 0.900 0.800 0.800 0.800 0.900 0.600 0.900 0.800 1.000 1.000 0.900 0.900 0.800 0.800 0.823 Table 14: Accuracy () of models across Arabic dialects and countries (with incorrect explanations generated with SRL). Model Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Gemma-2-9b-it Gemma-2-27b-it Qwen2.5-7B-Instruct Qwen2.5-14B-Instruct Qwen2.5-32B-Instruct Mistral-7B-Instruct Jais-family-6p7b-chat Jais-family-13b-chat Fanar-1-9B-Instruct SILMA-9B-Instruct ALLaM-7B-Instruct Aya-expanse-8b Aya-expanse-32b AceGPT-v2-8B-Chat Claude-Sonnet-4 Claude-3.5-Sonnet Gemini-1.5-flash Gemini-2.5-flash-lite GPT-4o GPT-4o-mini Average EGY MSA UAE JOR MAU PAL ALG SYR IRQ LEB 0.611 0.611 0.778 0.833 0.889 0.833 0.778 0.833 1.000 0.833 0.944 0.833 1.000 0.944 0.556 1.000 0.611 0.667 0.833 0.722 0.889 0.778 1.000 0.833 0.722 0.944 0.722 0.778 0.944 0.889 0.778 0.778 1.000 1.000 1.000 0.944 0.944 0.833 1.000 0.944 1.000 0.944 0.944 0.889 0.856 0.846 0.850 1.000 1.000 0.900 0.850 0.800 0.900 0.600 0.800 0.900 0.800 1.000 0.750 0.700 0.900 0.800 1.000 1.000 0.950 0.900 1.000 0.850 0.873 0.950 0.950 0.950 0.950 1.000 0.950 1.000 0.500 0.950 0.900 1.000 1.000 0.900 0.900 1.000 0.700 1.000 1.000 0.950 1.000 0.950 1.000 0.934 0.455 0.955 0.864 0.955 0.955 0.909 0.955 0.773 0.500 0.773 1.000 0.818 0.682 0.773 0.864 0.727 1.000 1.000 0.909 1.000 1.000 0.909 0.853 0.550 0.900 0.900 0.800 0.600 0.850 0.900 0.450 0.750 0.600 0.700 0.700 0.900 0.700 0.700 0.400 0.950 0.950 0.850 0.850 1.000 0.750 0.761 0.700 0.800 0.900 1.000 0.850 0.900 0.950 0.550 0.700 0.800 1.000 0.850 0.900 0.850 0.900 0.800 0.950 0.950 0.900 1.000 1.000 0.850 0. 0.900 1.000 0.950 1.000 0.950 1.000 1.000 0.800 0.900 0.900 0.900 0.900 0.950 0.900 1.000 0.900 1.000 1.000 1.000 1.000 1.000 1.000 0.955 0.850 0.900 0.950 0.900 0.900 0.900 0.900 0.600 0.650 0.750 1.000 0.950 0.900 0.750 0.950 0.800 0.950 1.000 0.950 0.900 1.000 0.800 0.873 0.850 0.950 0.950 0.850 0.700 0.850 0.950 0.650 0.750 0.900 0.900 1.000 0.900 0.800 0.950 0.750 1.000 1.000 0.950 0.900 1.000 1.000 0.886 SAU YEM MOR QAT SUD KUW OMA TUN BAH LIB 0.800 0.850 0.900 1.000 0.900 0.900 1.000 0.950 1.000 0.900 1.000 0.950 0.950 1.000 0.600 0.450 0.950 0.850 0.700 0.650 0.900 0.700 0.900 1.000 0.850 0.950 0.900 0.500 0.950 0.850 0.900 0.450 1.000 1.000 1.000 1.000 1.000 0.900 1.000 1.000 1.000 1.000 1.000 0.900 0.916 0.850 0.750 0.950 0.900 0.950 0.900 0.950 1.000 0.700 0.900 0.750 0.900 0.800 0.750 0.800 0.950 0.800 1.000 1.000 1.000 0.900 1.000 0.900 0.902 0.650 0.750 0.850 0.900 0.700 0.900 1.000 0.750 0.750 0.750 1.000 0.900 0.900 0.900 0.950 0.850 1.000 0.950 0.900 1.000 1.000 0.900 0. 0.500 0.950 0.800 0.750 0.800 0.900 0.800 0.350 0.650 0.550 0.800 0.700 0.650 0.700 0.950 0.600 0.900 0.900 0.800 0.900 1.000 0.800 0.750 0.750 0.950 0.900 1.000 1.000 0.900 1.000 0.550 0.850 0.650 0.900 0.900 0.950 0.700 0.900 0.900 1.000 0.950 0.950 1.000 1.000 0.750 0.882 0.833 0.889 0.833 0.889 0.778 1.000 0.944 0.556 0.889 0.944 0.944 0.667 0.944 0.778 0.944 0.722 1.000 1.000 0.833 1.000 1.000 1.000 0.899 0.750 0.950 0.950 0.850 0.800 0.950 0.900 0.300 0.700 0.700 0.600 0.700 0.850 0.700 0.950 0.800 1.000 0.950 0.850 1.000 1.000 0.750 0.834 0.850 0.900 0.900 1.000 0.850 0.950 1.000 0.750 0.750 0.850 0.900 0.900 0.850 0.900 0.900 0.800 1.000 0.950 0.950 0.800 0.900 1.000 0.889 0.850 0.900 0.750 0.800 0.800 0.900 0.900 0.450 0.800 0.800 0.800 0.800 0.900 0.600 0.850 0.800 1.000 0.950 0.900 0.900 0.800 0.800 0. Table 15: Accuracy () of models across Arabic dialects and countries (average of two runs). 22 Figure 23: Model Size vs Accuracy () of Open Source Models (6.7B to 32B) on the MCQ Understanding task Figure 24: Model Size vs Accuracy () of Open Source Models (6.7B to 32B) on the Understanding and Pragmatic Use tasks"
        },
        {
            "title": "F Sample Idioms",
            "content": "Table 18 presents sample of idioms from the Kinayat dataset along with their corresponding explanations."
        },
        {
            "title": "E Ablation",
            "content": "Table 16 presents the relationship between model size and performance accuracy for open-source models ranging from 6.7B to 32B parameters on the MCQ Understanding task across different datasets, while Figure 23 provides the corresponding statistical correlation analysis illustrating the strength of this relationship. Across datasets, correlations were assessed using significance threshold of α = 0.05. For MAPS, the weak positive trend did not reach statistical significance (p = 0.1053), whereas adding context (MAPS + Context) resulted in significant correlation (p = 0.0086), suggesting that contextualization enhances the link between model size and performance. Jawaher showed borderline, yet non-significant, trend (p = 0.0529), while Kinayat demonstrated statistically significant correlation (p = 0.0178), indicating that larger models more reliably benefit in this dataset. Similarly, Table 17 reports the relationship between model size and accuracy for the Pragmatic Use tasks in Kinayat, with Figure 24 visualizing the emerging correlation pattern, further supporting the observation that larger models generally exhibit stronger pragmatic competence in figurative language understanding. Here, model size demonstrates moderate and statistically significant correlation with pragmatic competence (R2 = 0.600, = 0.0007), in contrast to very weak but significant trend observed in MCQ Understanding (R2 = 0.265, = 0.0497) and Contextual Understanding (R2 = 0.265, = 0.0495). These findings suggest that larger models not only benefit more clearly from scale in pragmatic reasoning but also gain modestly in interpretive understanding tasks. Task MAPS MAPS + Context Jawaher Kinayat R² 0.189 0.424 0.259 0.361 Slope 0.0024 0.0022 0.0049 0.0062 Interpretation P-value 0.1053 Very weak correlation 0.0086 Weak correlation 0.0529 Very weak correlation 0.0178 Weak correlation Table 16: Statistical Correlation Analysis for different datasets: Goodness of Fit, Slope, and Significance Testing Task Pragmatic Use Understanding Contextual Understanding R² 0.600 0.265 0.265 Slope 0.0075 0.0066 0.0051 Interpretation P-value 0.0007 Moderate correlation 0.0497 Very weak correlation 0.0495 Very weak correlation Table 17: Statistical Correlation Analysis: Goodness of Fit, Slope, and Significance Testing 23 Explanation Idiom (cid:21)(cid:208)(cid:64) (cid:12)(cid:15)(cid:89)(cid:203)(cid:64) (cid:21)(cid:16)(cid:174)(cid:16)(cid:75)(cid:11)(cid:240)(cid:11) (cid:21)(cid:9)(cid:75) (cid:21)(cid:9)(cid:148)(cid:16)(cid:74)(cid:11)(cid:75)(cid:46)(cid:11) (cid:65)(cid:11)(cid:74)(cid:10) (cid:21)(cid:72)(cid:46) (cid:21)(cid:73)(cid:46) (cid:202) (cid:11)(cid:81)(cid:229) (cid:11)(cid:15)(cid:89) (cid:12)(cid:16)(cid:175) (cid:21)(cid:89)(cid:75)(cid:10)(cid:64)(cid:13)(cid:11)(cid:240) (cid:64)(cid:80) (cid:11)(cid:240) (cid:21)(cid:89)(cid:75)(cid:10)(cid:64)(cid:13) (cid:21)(cid:169)(cid:107)(cid:46)(cid:11) (cid:80)(cid:11) (cid:11)(cid:15) (cid:21)(cid:9)(cid:225)(cid:30)(cid:10)(cid:163)(cid:11) (cid:15)(cid:11)(cid:240) (cid:11)(cid:9)(cid:80) (cid:21)(cid:233) (cid:202)(cid:11)(cid:74)(cid:46)(cid:214)(cid:11)(cid:207)(cid:64) (cid:88)(cid:11) (cid:16)(cid:232)(cid:88)(cid:65)(cid:75)(cid:10) (cid:9)(cid:80) (cid:21)(cid:232) (cid:12)(cid:89)(cid:75)(cid:10)(cid:64)(cid:13) (cid:21)(cid:81)(cid:21)(cid:238)(cid:68) (cid:11)(cid:9)(cid:149) (cid:250) (cid:11)(cid:17)(cid:133) (cid:11) (cid:206)(cid:11)(cid:171) (cid:213)(cid:230) (cid:9)(cid:109)(cid:204)(cid:39)(cid:64) (cid:81)(cid:30)(cid:46) (cid:64) (cid:9)(cid:89)(cid:234)(cid:203) (cid:9)(cid:225)(cid:186)(cid:75)(cid:10) (cid:213)(cid:203) (cid:248)(cid:10) (cid:21)(cid:232)(cid:11)(cid:81)(cid:21)(cid:75)(cid:10)(cid:65) (cid:11)(cid:163) (cid:11)(cid:15)(cid:249)(cid:10) (cid:235)(cid:240)(cid:11) (cid:65)(cid:11)(cid:234) (cid:21)(cid:9)(cid:175)(cid:81)(cid:11)(cid:171)(cid:11) (cid:9)(cid:225)(cid:211) (cid:232)(cid:65)(cid:9)(cid:74)(cid:170)(cid:211) (cid:188)(cid:80)(cid:88) (cid:13) (cid:64)(cid:240) (cid:200)(cid:65)(cid:16)(cid:174)(cid:75)(cid:10) (cid:9)(cid:175) (cid:209)(cid:238) (cid:13)(cid:68)(cid:74)(cid:10)(cid:109)(cid:46)(cid:215)(cid:240) (cid:209)(cid:238)(cid:69)(cid:46) (cid:65)(cid:235) (cid:9)(cid:88)(cid:240) (cid:9)(cid:224)(cid:65)(cid:190)(cid:211) (cid:250)(cid:10) (cid:46) (cid:233)(cid:74)(cid:10) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:44)(cid:65) (cid:9)(cid:109)(cid:204)(cid:39)(cid:65)(cid:75)(cid:46) (cid:168)(cid:241)(cid:107)(cid:46) (cid:81)(cid:203)(cid:64) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:44)(cid:64) (cid:19)(cid:88)(cid:65)(cid:130)(cid:9)(cid:175) (cid:65)(cid:235)(cid:88)(cid:64) (cid:9)(cid:80) (cid:89)(cid:16)(cid:174)(cid:9)(cid:175) (cid:65) (cid:46) (cid:16)(cid:233)(cid:74)(cid:46)(cid:74)(cid:10) (cid:13) (cid:64) (cid:13) (cid:64) (cid:65)(cid:211) (cid:44)(cid:90)(cid:65)(cid:191) (cid:9)(cid:89)(cid:203)(cid:64) (cid:44)(cid:73)(cid:46) (cid:74)(cid:10) (cid:9)(cid:170)(cid:203)(cid:64) (cid:9)(cid:172)(cid:81)(cid:171) (cid:248)(cid:10) (cid:9)(cid:175) (cid:128)(cid:65)(cid:9)(cid:74)(cid:203)(cid:64) (cid:208)(cid:65)(cid:103)(cid:88) (cid:9)(cid:80)(cid:64) (cid:19)(cid:9)(cid:74)(cid:74)(cid:10)(cid:163) (cid:65)(cid:235)(cid:88)(cid:64) (cid:9)(cid:80) (cid:64) (cid:9)(cid:88)(cid:64)(cid:13)(cid:240) (cid:44) (cid:9)(cid:224)(cid:65)(cid:16)(cid:74)(cid:186)(cid:203)(cid:64) (cid:169)(cid:16)(cid:174)(cid:9)(cid:75) (cid:169) (cid:9)(cid:147)(cid:241)(cid:211) (cid:16)(cid:233)(cid:202)(cid:74)(cid:46)(cid:214)(cid:207)(cid:65)(cid:75)(cid:46) (cid:16)(cid:233)(cid:9)(cid:175)(cid:81)(cid:170)(cid:211) (cid:208)(cid:89)(cid:171) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:248)(cid:10) (cid:89)(cid:75)(cid:10)(cid:64)(cid:13) (cid:81)(cid:238)(cid:68)(cid:9)(cid:149) (cid:250)(cid:206)(cid:171) (cid:13) (cid:9)(cid:175) (cid:65)(cid:234)(cid:214)(cid:222)(cid:17)(cid:133)(cid:13) (cid:46) (cid:233)(cid:16)(cid:74)(cid:9)(cid:175)(cid:81)(cid:170)(cid:211) (cid:250)(cid:10)(cid:205) (cid:9)(cid:225)(cid:75)(cid:10) (cid:9)(cid:225)(cid:212) (cid:64) (cid:16)(cid:232)(cid:89) (cid:17)(cid:131) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:44)(cid:65)(cid:238)(cid:69)(cid:46) (cid:16)(cid:232)(cid:81)(cid:17)(cid:30)(cid:187) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:13) (cid:19)(cid:13)(cid:74)(cid:28)(cid:10) (cid:17)(cid:131) (cid:201)(cid:210)(cid:109)(cid:26)(cid:39)(cid:10) (cid:66)(cid:240) (cid:233)(cid:74)(cid:10)(cid:171)(cid:64)(cid:80) (cid:9)(cid:88) (cid:188)(cid:15)(cid:11)(cid:81)(cid:109)(cid:26)(cid:39)(cid:10) (cid:169)(cid:107)(cid:46) (cid:80) (cid:248)(cid:10) (cid:64) (cid:9)(cid:224)(cid:240)(cid:89)(cid:75)(cid:10)(cid:81)(cid:75)(cid:10) (cid:46)(cid:64) (cid:19)(cid:88)(cid:65)(cid:130)(cid:9)(cid:175) (cid:89)(cid:131)(cid:65) (cid:9)(cid:174)(cid:203)(cid:64) (cid:90)(cid:250)(cid:10)(cid:230)(cid:17)(cid:132)(cid:203)(cid:64) (cid:17)(cid:129)(cid:16)(cid:28)(cid:214)(cid:222)(cid:17)(cid:133) (cid:65)(cid:211) (cid:58) (cid:9)(cid:224)(cid:241)(cid:203)(cid:241)(cid:16)(cid:174)(cid:75)(cid:10) (cid:65)(cid:9)(cid:175) (cid:248)(cid:10) (cid:89)(cid:75)(cid:10) (cid:81)(cid:234) (cid:9)(cid:163) (cid:250)(cid:206)(cid:171) (cid:16)(cid:233)(cid:109)(cid:26)(cid:13)(cid:39)(cid:64)(cid:80) (cid:65)(cid:234)(cid:202)(cid:13)(cid:75)(cid:65)(cid:16)(cid:175) (cid:168)(cid:81)(cid:229)(cid:132)(cid:29)(cid:10) (cid:16)(cid:233)(cid:210)(cid:202)(cid:190)(cid:203)(cid:64) (cid:88)(cid:64)(cid:81)(cid:214)(cid:207)(cid:64) (cid:13) (cid:46) (cid:16)(cid:233)(cid:202)(cid:235)(cid:240) (cid:200) (cid:11)(cid:15)(cid:240) (cid:64) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:16)(cid:232)(cid:81)(cid:17)(cid:30)(cid:187) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:65)(cid:9)(cid:74)(cid:235) (cid:88)(cid:64)(cid:81)(cid:214)(cid:207)(cid:64)(cid:240) (cid:44)(cid:189)(cid:203) (cid:9)(cid:88) (cid:88)(cid:241)(cid:170)(cid:16)(cid:75)(cid:240) (cid:128)(cid:65)(cid:9)(cid:74)(cid:203)(cid:64) (cid:250)(cid:206)(cid:171) (cid:168) (cid:9)(cid:89)(cid:16)(cid:174)(cid:203)(cid:65)(cid:75)(cid:46) (cid:200)(cid:240)(cid:65)(cid:162)(cid:16)(cid:74)(cid:203)(cid:64)(cid:240) (cid:16)(cid:233)(cid:235)(cid:65) (cid:9)(cid:174)(cid:130)(cid:203)(cid:64) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:12)(cid:15) (cid:13) (cid:9)(cid:175) (cid:250)(cid:10) (cid:9)(cid:175) (cid:9)(cid:224)(cid:65)(cid:210)(cid:16)(cid:74)(cid:187) (cid:208)(cid:89)(cid:171) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:44) (cid:16)(cid:233)(cid:203)(cid:241)(cid:9)(cid:175) (cid:233)(cid:212) (cid:9)(cid:175) (cid:168) (cid:12)(cid:15)(cid:81)(cid:229)(cid:132)(cid:16)(cid:74)(cid:203)(cid:64)(cid:240) (cid:15)(cid:11)(cid:81)(cid:229)(cid:132)(cid:203)(cid:64) (cid:16)(cid:135)(cid:12)(cid:74)(cid:46)(cid:203)(cid:64) (cid:44)(cid:213) (cid:9)(cid:174)(cid:203)(cid:64) (cid:201)(cid:74)(cid:46)(cid:16)(cid:75) (cid:66) (cid:248)(cid:10) (cid:64) (cid:11)(cid:15) (cid:13) (cid:13) (cid:9)(cid:175) (cid:250)(cid:10) (cid:46) (cid:233)(cid:16)(cid:174)(cid:75)(cid:10)(cid:81)(cid:75)(cid:46) (cid:9)(cid:175) (cid:81)(cid:16)(cid:174)(cid:16)(cid:74)(cid:130)(cid:16)(cid:29) (cid:66) (cid:16)(cid:232)(cid:90)(cid:67)(cid:16)(cid:175)(cid:65)(cid:74)(cid:46)(cid:203)(cid:64) (cid:16)(cid:175) (cid:65)(cid:234)(cid:107)(cid:46) (cid:64)(cid:81) (cid:9)(cid:107)(cid:64)(cid:13) (cid:250)(cid:10) (cid:65)(cid:238)(cid:9)(cid:69) (cid:9)(cid:224) (cid:201)(cid:74)(cid:46)(cid:16)(cid:75) (cid:65)(cid:191) (cid:233)(cid:212) (cid:64) (cid:201)(cid:74)(cid:46) (cid:13) (cid:9)(cid:175) (cid:80) (cid:9)(cid:89)(cid:109)(cid:204)(cid:39)(cid:64) (cid:9)(cid:175) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:17)(cid:128)(cid:19)(cid:65)(cid:211) (cid:233)(cid:13)(cid:74)(cid:163)(cid:65)(cid:74)(cid:46)(cid:16)(cid:75) (cid:250)(cid:10) (cid:9)(cid:145)(cid:74)(cid:10)(cid:75)(cid:46) (cid:250)(cid:206)(cid:171) (cid:233)(cid:9)(cid:75) (cid:13)(cid:249)(cid:163)(cid:65)(cid:74)(cid:46)(cid:16)(cid:74)(cid:214)(cid:207)(cid:64) (cid:65)(cid:191) (cid:248)(cid:10) (cid:232)(cid:81)(cid:229)(cid:17)(cid:132)(cid:16)(cid:175) (cid:46) (cid:233)(cid:74)(cid:10)(cid:202)(cid:171) (cid:233)(cid:13)(cid:74)(cid:163)(cid:241)(cid:75)(cid:46) (cid:9)(cid:173)(cid:74)(cid:10) (cid:17)(cid:130)(cid:9)(cid:28)(cid:16)(cid:74)(cid:203)(cid:64) (cid:9)(cid:225)(cid:30)(cid:10)(cid:75)(cid:46) (cid:46)(cid:128)(cid:65)(cid:9)(cid:74)(cid:203)(cid:64) (cid:16)(cid:233)(cid:202)(cid:16)(cid:175)(cid:240) (cid:9)(cid:81)(cid:106)(cid:46) (cid:170)(cid:203)(cid:64) (cid:46) (cid:16)(cid:233)(cid:202)(cid:74)(cid:10)(cid:109)(cid:204)(cid:39)(cid:64) (cid:16)(cid:175) (cid:65)(cid:211) (cid:16)(cid:232)(cid:88)(cid:65)(cid:171)(cid:64)(cid:13)(cid:240) (cid:233)(cid:202)(cid:75)(cid:10)(cid:241)(cid:162)(cid:16)(cid:29)(cid:240) (cid:208)(cid:67)(cid:190)(cid:203)(cid:64) (cid:90)(cid:250)(cid:10)(cid:230)(cid:17)(cid:132)(cid:203)(cid:65)(cid:75)(cid:46) (cid:81)(cid:234)(cid:109)(cid:46)(cid:204)(cid:39)(cid:64) (cid:9)(cid:225)(cid:211) (cid:188)(cid:65)(cid:74)(cid:46)(cid:16)(cid:75)(cid:80)(cid:66)(cid:64) (cid:9)(cid:175) (cid:168)(cid:81)(cid:229)(cid:132)(cid:29)(cid:10) (cid:13) (cid:64) (cid:9)(cid:174)(cid:106)(cid:46) (cid:16)(cid:74)(cid:203)(cid:64) (cid:58)(cid:209)(cid:235)(cid:89)(cid:9)(cid:74)(cid:171) (cid:9)(cid:225)(cid:171) (cid:16)(cid:233)(cid:75)(cid:10)(cid:65)(cid:9)(cid:74)(cid:187) (cid:44) (cid:44) (cid:233)(cid:74)(cid:10) (cid:17)(cid:130)(cid:211) (cid:250)(cid:10) (cid:46) (cid:16)(cid:233)(cid:202)(cid:163)(cid:65)(cid:210)(cid:214)(cid:207)(cid:65)(cid:75)(cid:46) (cid:16)(cid:232)(cid:89)(cid:75)(cid:10)(cid:89) (cid:17)(cid:130)(cid:203)(cid:64) (cid:16)(cid:233)(cid:16)(cid:174)(cid:75)(cid:10)(cid:65) (cid:9)(cid:146)(cid:214)(cid:207)(cid:64) (cid:9)(cid:173)(cid:74)(cid:10) (cid:9)(cid:172)(cid:240)(cid:81)(cid:170)(cid:211) (cid:9)(cid:225)(cid:106)(cid:46) (cid:170)(cid:203)(cid:64)(cid:240) (cid:16)(cid:73)(cid:202)(cid:203)(cid:64) (cid:250) (cid:9)(cid:230)(cid:170)(cid:211)(cid:240) (cid:44)(cid:201)(cid:74)(cid:10) (cid:46) (cid:46) (cid:12)(cid:15)(cid:248)(cid:10) (cid:241)(cid:9)(cid:74)(cid:170)(cid:214)(cid:207)(cid:64) (cid:200)(cid:241)(cid:162)(cid:203)(cid:64) (cid:16)(cid:233)(cid:210)(cid:202)(cid:190)(cid:203)(cid:65)(cid:9)(cid:175) (cid:44) (cid:233)(cid:13)(cid:75)(cid:65) (cid:17)(cid:130)(cid:9)(cid:175)(cid:64)(cid:13) (cid:250)(cid:10) (cid:21)(cid:233)(cid:11)(cid:15)(cid:74)(cid:10) (cid:21) (cid:189)(cid:9)(cid:74)(cid:11)(cid:74)(cid:10)(cid:171)(cid:11) (cid:250)(cid:10) (cid:9)(cid:230)(cid:11)(cid:74)(cid:10)(cid:171)(cid:11) (cid:11)(cid:211) (cid:21)(cid:81)(cid:21)(cid:30)(cid:46) (cid:17)(cid:131)(cid:11) (cid:250)(cid:10) (cid:9)(cid:171)(cid:11) (cid:16)(cid:134)(cid:81)(cid:11) (cid:9)(cid:175)(cid:11) (cid:11) (cid:15)(cid:11)(cid:16)(cid:73) (cid:9)(cid:225) (cid:21)(cid:106)(cid:46) (cid:11)(cid:171)(cid:21)(cid:240) (cid:203) (cid:21) (cid:12)(cid:9)(cid:75)(cid:65) (cid:11)(cid:130)(cid:203)(cid:11) (cid:11)(cid:163) (cid:233) (cid:201)(cid:75)(cid:10)(cid:241)(cid:11) (cid:15)(cid:11) (cid:12)(cid:15)(cid:16)(cid:174)(cid:12)(cid:75)(cid:46) (cid:250)(cid:10) (cid:21)(cid:9)(cid:28)(cid:16)(cid:75)(cid:11) (cid:21)(cid:17)(cid:129) (cid:65)(cid:11)(cid:211) (cid:9)(cid:175)(cid:11) (cid:202)(cid:11)(cid:74)(cid:46) (cid:12)(cid:9)(cid:175) (cid:21)(cid:233) (cid:21)(cid:233)(cid:203)(cid:241) (cid:21)(cid:9)(cid:145)(cid:74)(cid:10)(cid:75)(cid:46)(cid:11) (cid:21)(cid:17)(cid:132)(cid:16)(cid:175)(cid:11) (cid:250)(cid:206)(cid:11)(cid:171) (cid:250)(cid:10)(cid:230)(cid:17)(cid:133)(cid:11)(cid:65)(cid:11)(cid:211) (cid:21)(cid:81)(cid:229) (cid:9)(cid:224) (cid:13) (cid:64) (cid:250)(cid:230)(cid:17)(cid:132)(cid:9)(cid:109)(cid:26)(cid:39)(cid:10) (cid:81)(cid:229)(cid:132)(cid:186)(cid:75)(cid:10) (cid:21)(cid:16)(cid:135)(cid:75)(cid:10) (cid:15)(cid:11)(cid:81)(cid:203)(cid:64) (cid:15)(cid:11)(cid:17)(cid:130) (cid:11)(cid:9)(cid:29) (cid:9)(cid:173)(cid:11) Table 18: Examples of Egyptian Arabic idioms from the Kinayat dataset and their explanations"
        }
    ],
    "affiliations": [
        "Carnegie Mellon University",
        "MBZUAI"
    ]
}