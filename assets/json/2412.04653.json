{
    "paper_title": "Hidden in the Noise: Two-Stage Robust Watermarking for Images",
    "authors": [
        "Kasra Arabi",
        "Benjamin Feuer",
        "R. Teal Witter",
        "Chinmay Hegde",
        "Niv Cohen"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As the quality of image generators continues to improve, deepfakes become a topic of considerable societal debate. Image watermarking allows responsible model owners to detect and label their AI-generated content, which can mitigate the harm. Yet, current state-of-the-art methods in image watermarking remain vulnerable to forgery and removal attacks. This vulnerability occurs in part because watermarks distort the distribution of generated images, unintentionally revealing information about the watermarking techniques. In this work, we first demonstrate a distortion-free watermarking method for images, based on a diffusion model's initial noise. However, detecting the watermark requires comparing the initial noise reconstructed for an image to all previously used initial noises. To mitigate these issues, we propose a two-stage watermarking framework for efficient detection. During generation, we augment the initial noise with generated Fourier patterns to embed information about the group of initial noises we used. For detection, we (i) retrieve the relevant group of noises, and (ii) search within the given group for an initial noise that might match our image. This watermarking approach achieves state-of-the-art robustness to forgery and removal against a large battery of attacks."
        },
        {
            "title": "Start",
            "content": "Hidden in the Noise: Two-Stage Robust Watermarking for Images Kasra Arabi, Benjamin Feuer, R. Teal Witter, Chinmay Hegde, Niv Cohen New York University"
        },
        {
            "title": "Abstract",
            "content": "As the quality of image generators continues to improve, deepfakes become topic of considerable societal debate. Image watermarking allows responsible model owners to detect and label their AI-generated content, which can mitigate the harm. Yet, current state-of-the-art methods in image watermarking remain vulnerable to forgery and removal attacks. This vulnerability occurs in part because watermarks distort the distribution of generated images, unintentionally revealing information about the watermarking techniques. In this work, we first demonstrate distortion-free watermarking method for images, based on diffusion models initial noise. However, detecting the watermark requires comparing the initial noise reconstructed for an image to all previously used initial noises. To mitigate these issues, we propose two-stage watermarking framework for efficient detection. During generation, we augment the initial noise with generated Fourier patterns to embed information about the group of initial noises we used. For detection, we (i) retrieve the relevant group of noises, and (ii) search within the given group for an initial noise that might match our image. This watermarking approach achieves state-of-the-art robustness to forgery and removal against large battery of attacks."
        },
        {
            "title": "Introduction",
            "content": "Generative AI is capable of synthesizing high-quality images indistinguishable from real ones. This capability can be used to deliberately deceive. These fake image generations, called deepfakes, have the potential to cause severe societal harms through the spread of confusion and misinformation (Peebles & Xie, 2022; Esser et al., 2024; Chen et al., 2024; Ramesh et al., 2021). In addition, owners of different models and images may want to control the spread of their derivatives for copyright reasons and safeguard their intellectual property. One way to mitigate these harms is model watermarking. The study of watermarking has rich history and has recently been adopted for AI-generated content (Pun et al., 1997; Langelaar et al., 2000; Craver et al., 1998). For an extended discussion of recent work in this area, we direct the reader to Appendix B. Unfortunately, most current image watermarking methods are not robust to watermark removal attacks utilizing image diffusion generative models (Zhao et al., 2023a). Recently, new watermarking methods utilize the inversion property of DDIM to achieve more robust watermarking (Wen et al., 2023; Ci et al., 2024; Yang et al., 2024b). These methods embed patterns in diffusion models initial noise and then detect them in the noise pattern reconstructed from the generated image. This technique provides strong robustness against various attacks, making it effective at resisting watermark removal attempts. Yet, these prior methods are themselves vulnerable to new types of attacks. Tree-Ring Wen et al. (2023) add pattern to the initial noise, 1 4 2 0 2 5 ] . [ 1 3 5 6 4 0 . 2 1 4 2 : r a"
        },
        {
            "title": "Preprint",
            "content": "Figure 1: The WIND method for robust image watermaking. The method is designed to use possible initial noises splitted to groups. Generation: Using secret salt and an index i, we securely and reproducibly generate initial noise zi . We then embed group index of that noise to make easier retrieval possible and embed it using Fourier pattern. Finally, we run diffusion with the embedded latent noise to produce watermarked image. Detection: We reconstruct the initial noise z. Next, we search over the possible group indices for the closest Fourier pattern to the one embedded in z. We then look over initial noises in group to find the match. making it distinct from random Gaussian initial noise in way that an attacker can detect (Yang et al., 2024a). This may enable forgery attacks, aimed at applying the watermark without the owners permission. Such attacks are often even more concerning than removal attacks, as they can cause severe damage to model owners if their watermark is associated with illegal content. Therefore, there is need for image watermarking methods that generate images that are not distinct from non-watermarked images (to anyone but the model owner). As suggested by previous works, since the model already takes random noise as initialization, we may initialize it with pseudo-random noise pattern that we can detect later (Yang et al., 2024b; Kuditipudi et al., 2023). Namely, reconstructing an approximation of the initial noise used in the diffusion process from given image allows the detection of the noise pattern used by the model. Although this reconstructed noise is not completely identical to the used initial noise, it is much more similar to the initial noise than it is to other randomly distributed noise patterns. Thus, it can serve as watermark that can be identified in the generated images (see also Appendix for similar ideas used in previous works). While using pseudo-random initial noise does not distort the distribution of single-generated images, it may carry information about the watermark when groups of images are examined together. Specifically, works such as Yang et al. (2024b) embeds the watermark in an initial noise such that"
        },
        {
            "title": "Preprint",
            "content": "the resulting generated image comes from the same distribution as non-watermarked images. Yet, when many images generated from the same noise pattern are examined together, the correlation between them may expose that they are not distortion-free as set. E.g., the average of many similarly-watermarked images may differ from the average of non-watermarked ones (Yang et al., 2024a). natural solution to this distortion of sets is to use more than one initial noise for each watermark we deploy. Yet, given sufficiently small set of initial noises (denoted as ) and an enormous number of images generated by model, an attacker could potentially still collect many images sharing the same initial noise in order to perform removal and forgery attacks as was applied to previous methods (Yang et al., 2024a). Using many initial noises (a large value of ) will make such attacks much more difficult, if not infeasible. Surprisingly, we find that very large number of random initial noises remain distinguishable from one another, even after reconstructing the noise from generated image. However, large value of might incur negative effect on the runtime and accuracy of the approach. In order to lower the effective quantity of noises we need to scan at detection while retaining strong robustness, we propose two-stage efficient watermarking framework. We supplement our initial noise samples with Fourier patterns as group identifier - unique identifier of subset of initial noises we might have used for generating given image (Figure 1). During detection, we may first recover the group identifier (stage 1) and use it to find an exact match (stage 2). Thus, we reduce our search space to the number of initial noises per group (N/M ). Our key contributions are as follows: 1. We demonstrate that the initial noise used in the diffusion process is itself distortion-free watermarking method for images (Section 3). 2. We present WIND, our two-stage method for effectively using the initial noise as watermark (Section 4). 3. We demonstrate that WIND achieves state-of-the-art results for its robustness to removal and forgery attempts (Section 5)."
        },
        {
            "title": "2 Preliminaries",
            "content": "2.1 Threat Model In watermarking scheme we usually consider the owner, trying to mark images as an output of their model; and an attacker, trying to remove or forge the watermark on unrelated images. The Owner releases private model (diffusion model in our case) that clients can access through an API, allowing them to generate images that contain watermark. The watermark is designed to have negligible impact on the quality of the generated images. There are few settings regarding the watermark detection, including public infomation and private information watermarking (Cox et al., 2007; Wong & Memon, 2001). We focus on the setting where the watermark is detectable only by the owner, enabling them to verify whether given image was generated by their model using private information. The Attacker uses the API to generate an image and subsequently attempts to launch malicious attack aimed at either removing or forging the embedded watermark, with the intention of using the image or watermark for unauthorized purposes."
        },
        {
            "title": "Preprint",
            "content": "Figure 2: Cosine similarity distribution between initial noise, and: (i) noise reconstructed from watermarked image (reconstructed noise) (ii) noise reconstructed from forged image using public model to imitate our watermarked image (reconstruction attack, described in Section 3). (iii) Random noise. These results are reliant on the approximate inversion of DDIM without the ground-truth prompt. 2.2 Diffusion Models Inversion Diffusion model inversion aims to find the reconstructed noise representation of given data point, effectively reversing the generative process. Let be the number of diffusion steps, in both the In the standard generation process, we start with noise xT generation and inversion processes. drawn from an appropriately scaled Gaussian and iteratively apply xt = xt+1 + ϵΘ(xt+1), where ϵΘ is trained model that predicts the noise to be removed and [T ] is the time step describing how much noise should be removed in each stage. Conversely, the inversion process begins with data point ˆx0 and moves towards its reconstructed noise representation by applying ˆxt+1 = ˆxt ϵΘ(ˆxt). This process relies on the assumption that ϵΘ(ˆxt+1) ϵΘ(ˆxt), allowing us to approximately invert the diffusion process by adding the predicted noise (Ho et al., 2020; Song et al., 2022). DDIMs efficient sampling allows this technique to be particularly useful (Song et al., 2022). 2.3 Tree-Ring and RingID Watermarks In order to watermark images in human-imperceptible and robust way, previous works have encoded specific patterns in the Fourier space of the initial noise. Tree-Ring (Wen et al., 2023) first transforms the initial noise into the Fourier space. key pattern is then embedded into the center of the transformed noise. The noise is subsequently transformed back into the spatial domain. During the detection phase, the diffusion process is inverted, and the Fourier domain is examined to verify the presence of the imprinted pattern. RingID (Ci et al., 2024) shows that Tree-Ring struggles to distinguish between different keys. Therefore, the number of unique keys (distinguishable from one another) that can be embedded with Tree-Ring is low. They increase the possible number of unique keys that can be encoded using Fourier patterns."
        },
        {
            "title": "Preprint",
            "content": "Systematic Distribution Shifts in Generated Images Enable Attacks. Systematic distribution shifts in the generated content make it easier to verify the existence of watermark. However, in the case of Tree-Ring and other watermarking techniques, it also opens up an avenue of attack (Wen et al., 2023; Yang et al., 2024b; Xian et al., 2024; Bui et al., 2023). Emblematic is the method of Yang et al. (2024a), whose attack approximates the difference between watermarked and non-watermarked images. Increasing the number of images with the watermark can improve the accuracy of the approximation. The impact of distribution shifts is significant, as the attack remains effective even when the watermarked and non-watermarked images are not paired (Figure 3). Algorithm 1 Generation Algorithm 1: Input: : number of initial noises, : number of groups, s: secret salt, p: prompt, Θ: private model weights 2: Sample initial noise index Unif([N ]) 3: Compute group identifier = i%M 4: Calculate embedding of the group identifier gemb(g) 5: Securely generate seed = hash(i, s) 6: Sample zi (0, I) from pseudorandom generator with seed 7: Add the identifier embedding gemb(g) to zi to get zi emb 8: return image = GΘ(zi emb, p) Modulus of initial noise index Apply cryptographic hash function Diffusion process with weights Θ Algorithm 2 Detection Algorithm (WIND fast) 1: Input: image: (possibly) watermarked image, : number of initial noises, : number of groups, s: secret salt, Θ: private model weights, τ : threshold for detection Θ (image) Build initial noise zi using secret salt and hash Compare zi to after removing Fourier embedding 2: Recover reconstructed noise = G1 3: Extract closest group identifier from group identifier embedding in 4: for [N ] such that i%M = do 5: 6: 7: end for 8: if any noises are closer than threshold τ then 9: 10: else 11: 12: end if Declare not watermarked Declare watermarked Inverse diffusion with private weights Search over subset of initial noise indices As in Algorithm"
        },
        {
            "title": "Initial Noise is a Distortion Free Watermark",
            "content": "Watermarks which systematically perturb the distribution of image generations are more vulnerable to removal and forgery attacks. distortion-free watermarking method, by contrast, is more robust (Kuditipudi et al., 2023). Our first finding is that the initial noise already in standard use in diffusion models can be such watermark. Let be the number of initial noises we can generate. We will secure our watermarking process with long, secret salt s. We begin by sampling random (and reproducible) initial noise. Let Unif([N ]) be the index of the initial noise. We will use hash function to get seed hash(i, s). Plugging the seed into pseudorandom generator, we generate reproducible initial noise vector"
        },
        {
            "title": "Preprint",
            "content": "(a) Forgery Performance (b) Removal Performance Figure 3: Detection accuracy for forgery and removal attacks using Yang et al. (2024a). value of 0 represents complete failure (the attacker successfully removed the watermark or forged it onto another image), while 100 indicates perfect defense (no watermark removal or forgery occurred). zi (0, I) drawn from centered Gaussian distribution. When we generate fewer than images, we can use each initial noise at most once and the noise appears distortion-free. We discuss the case when the number of images exceeds in Appendix F. Empirical validation of initial noise watermarking. To empirically validate our claim that the initial noise can serve as watermark, we compute the cosine similarity between the initial noise zi and (i) random noise (0, I), (ii) the reconstructed noise when we have access to the private model weights, and (iii) the reconstructed noise zattack from an image imitating our noise pattern without access to the private model weights. The imitation attempt is done by inversing our watermarked image back into noise, and generating new image from it; where both steps are done using public model as described in reconstruction attack below (we used Stable Diffusion-v2 (Rombach et al., 2022) for the experiment, as it is the most similar model to our watermarking model). During the watermarking process, we create an image image through diffusion with the private model weights Θ conditioned on private text prompt p. Formally, image = GΘ(zi , p). We obtain the reconstructed noise that we use for detection via an inverse diffusion process G1. Formally, = Θ (image). Reconstruction Attack. An attacker trying to forge the watermarked image will not have access to our private weights, instead they will have some other weights Θ. Using the same starting watermarked image, they will attempt to recover the initial noise. Let = G1 Θ (image). Then, with this initial noise, they will generate forged image with (possibly offensive) text prompt p, producing image = GΘ(z, p). Finally, the model owner will attempt to detect whether the forged image is watermarked by applying the inverse diffusion process with the private model weights to the forged image. Let zattack = G1 Θ (image). As an upper bound on the capability of this attack, we perform it with the same prompt. Also, Keles & Hegde (2023) demonstrates that inverting generative model is significantly challenging task. Strikingly, we find that the similarity between the true noise and the noise reconstructed with the model weights is almost always greater than relatively large threshold τ = 0.5 (p value < 103, Figure 2). At the same time, the reconstructed similarity from the image made by an attacker using the reconstruction attack sim(zi , zattack), along with the similarity to random vectors sim(zi , z) are both much smaller. Namely, they are respectively = 5.3 and = 9.4 standard deviations"
        },
        {
            "title": "Preprint",
            "content": "away from the mean  (Table 4)  . Taken together, these results mean that the probability of nonwatermarked image mistakenly labeled as watermarked is very low in both cases. For the random noise, the probability to confuse it is as the initial noise is < e( τ 2 2σ2 ) < 1019, allowing practically perfect distinction between any pair of unrelated noises. Runtime considerations. Our method requires searching over all watermarks, leading to naive runtime complexity of O(N ). However, more efficient algorithms for similarity-based search, such as HNSW (Malkov & Yashunin, 2018), can reduce this complexity to O(log ), at the expense of additional memory usage. We provide empirical runtime analysis of our method in Appendix H. For large enough values of , this cost may eventually become undesirable. Together with our aim to maintain high robustness with an increasing number of keys, it motivates more efficient method, which is presented in the next section."
        },
        {
            "title": "4 Method",
            "content": "4.1 WIND: Two-stage Efficient Watermarking While always using single initial noise for our model might imply good robustness properties, to make forgery and removal more difficult, it is generally preferable to maintain large set of initial noises to be used by the model. More importantly, using large number of different noises may serve as different keys, encoding some metadata about each image. This metadata might include information about the specific model that generated it, as well as additional information about the generation for further validation of the image source, once detected. In order to make the search over large number of noises more efficient, we introduce two-stage efficient watermarking approach we name WIND (Watermarking with Indistinguishable and Robust Noise for First, we initialize Diffusion Models). groups of initial noise, each group associated with its own Fourier-pattern key. In contrast to prior work, we employ these Fourier patterns not as watermark, but as group identifier to reduce the search space. For each image generation, we randomly select an index for the initial noise, denoted as [N ]. We use group identifier = i%M , where % denotes the modulus operation. We embed in the Fourier space of the latent noise (similar to Wen et al. (2023)). During detection, we reconstruct the latent noise and find the group identifier that is closest to the Fourier pattern embedded in the image. We then search over all indices such that = i%M . In this way, the search space has size of N/M rather than . We include an algorithm box for generation (Algorithm 1) and detection (Algorithm 2). 7 Figure 4: Qualitative results of watermarked images generated using WIND, Tree-Ring, and RingID. See Appendix for quantitative results. See Appendix for additional qualitative results."
        },
        {
            "title": "Preprint",
            "content": "Table 1: Comparison of correct watermark detection accuracy between WIND and previous image watermarking approaches under various image transformation attacks. WINDM denotes the use of groups, with the total number of noises (N ) specified in the Keys column. broader comparison with additional methods can be found in Table 16."
        },
        {
            "title": "Clean Rotate",
            "content": "JPEG C&S Blur Noise Bright Avg Tree-Ring"
        },
        {
            "title": "RingID",
            "content": "32 128 2048 32 128 2048 WINDfast128 WINDfast2048 WINDfull128 WINDfull2048 100000 100000 100000 100000 0.790 0.450 0. 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.020 0.010 0.000 1.000 0.980 0.860 0.780 0. 0.780 0.880 0.420 0.120 0.040 1.000 1.000 1.000 1.000 0.960 1.000 1.000 0.040 0.020 0. 0.530 0.280 0.080 0.470 0.060 0.850 0.930 0.610 0.280 0.090 0.990 0.980 0.970 1.000 0. 1.000 1.000 0.530 0.230 0.070 1.000 1.000 0.950 1.000 0.950 1.000 0.990 0.420 0.170 0. 0.960 0.940 0.870 0.960 0.900 0.404 0.183 0.066 0.926 0.883 0.819 0.887 0.814 1.000 0. 0.947 0.969 In the following part, we refer to two variants of our method: (i) WINDfast where we assume the used initial noise belongs to the identified group and check similarity only to noise patterns in this group. (ii) WINDfull where we check all possible initial noises if we cant find match within the detected group (the gap between the similarity of the correct noise and random noises, as shown in Figure 2, allows us to determine whether the correct noise has been identified). This method is slower but more robust to removal attacks that might interfere with the Fourier pattern. Additional ablations and results can be found in Appendix D. 4.2 Resilience to Forgery In addition to empirical evaluations of specific attacks as in Figures 2 and 3; we discuss below the attackers ability to infer knowledge about the used noise pattern across different watermarked images. Even if the attacker is able to obtain information about specific initial noise zi for an index (which is an extreme case), the other noise vectors for = are still safe1. This is because we use cryptographic hash function and secret salt. Formally, Theorem 4.1 shows that, as long as the cryptographic hash function remains unbroken and the secret salt is kept private, the watermarking algorithm maintains its security properties against even very powerful adversaries. Theorem 4.1. [Cryptographic Security] Let hash: 0, 1 0, 1ℓ be an unbroken cryptographic hash function used in our watermarking algorithm, with inputs [N ] and secret salt s. Assume is sufficiently long and randomly generated. Then, even if an adversary obtains: the group number g, the initial noise index i, the initial noise zi , and even the corresponding output of the hash function seed, the adversary cannot: 1. Recover the secret salt s, 2. Generate valid reconstructed noise zj for any other initial noise index = We defer the proof to Appendix E. 1We note that obtaining single noise pattern might not be enough to effectively forge the watermark, as the model owner may encode this pattern with additional metadata as described in Section 4."
        },
        {
            "title": "Preprint",
            "content": "Table 2: Cosine similarity between the initial noise and the inversed noise before and after the regeneration attack. Also see Appendix D"
        },
        {
            "title": "Original Image\nAttacked Image\nUnrelated Image",
            "content": "0.888 0.824 0.000 0.053 0.062 0.008 Table 3: FID scores of WIND compared to previous watermarking approaches."
        },
        {
            "title": "Method",
            "content": "FID DwtDctSvd RivaGAN Tree-Ring RingID WIND 25.01 24.51 25.93 26.13 24.33 4.3 Watermarking Non-Synthetic Images. Until now, we have addressed watermarking only for AI-generated synthetic images. Yet, protecting copyrights, or preventing the spread of misinformation, may also apply to modified natural images. Most previous approaches to watermark diffusion models overlook attempting to expand their method to non-generated images. To allow using our framework for non-generated images, we expand our framework. By using diffusion inpainting, our watermark can be applied to natural image. Later, by inverting the inpainted image we can verify the presence of the watermark. As demonstrated in Figure 5, our inpainting method injects watermark with minimal visual impact, preserving the original images integrity. Please see Appendix for additional results."
        },
        {
            "title": "5 Experiments",
            "content": "5.1 Watermark Robustness Setting. For fair comparison with previous methods (Ci et al., 2024; Wen et al., 2023), we employed Stable Diffusion-v2 (Rombach et al., 2022), with 50 inference steps for both generation and inversion. Other implementation-details can be found in ??. Image Transformation Attacks. Following previous methods (Wen et al., 2023; Ci et al., 2024) we applied these image transformations to the generated images: 75 rotation, 25% JPEG compression, 75% random cropping and scaling (C & S), Gaussian blur with an 8 8 filter size, Gaussian noise with σ = 0.1, and color jitter with brightness factor uniformly sampled between 0 and 6. In Table 1 we compare our methods to both Tree-Ring and RingID. As the results demonstrate, using multiple keys with RingID (Ci et al., 2024) is possible. Yet, it remains vulnerable to cropping and scaling attacks. In contrast, WIND effectively addresses this challenge. It enables accurate watermark detection under all image transformation attacks. We note that the incorporation of the keys in the RingID method not only allows us to embed keys but also increases the robustness of the full method to certain attacks. Steganalysis Attack. We assess the robustness of our method against the attack proposed by Yang et al. (2024a), which is capable of forging and removing the Tree-Ring and RingID keys. As discussed in Section 2.3, this attack attempts to approximate the watermark by subtracting watermarked images from non-watermarked images. The results, presented in Figure 3, indicate that while the attack could be able to forge or remove our group identifier, it is unable to forge or remove our watermark (initial noises). Even when the Fourier pattern type key is removed through an exhaustive search, our method remains robust in identifying the correct initial noise."
        },
        {
            "title": "Preprint",
            "content": "Table 4: Cosine similarity between the first initial noise used for generation and the inversed noise obtained through three inversion approaches. Private refers to models owners model, while Public denotes external model."
        },
        {
            "title": "Std",
            "content": "Gen (private) Rev (private) Gen (private) Rev (public) Gen (public) Rev (private) Random Noise 0.888 0.166 0.000 0.053 0.063 0.053 Regeneration Attacks. Recently, Zhao et al. (2023a) introduced two-stage regeneration attack: (i) adding noise to the representation of watermarked image, and (ii) reconstructing the image from this noisy representation. To assess the resilience of our approach to regeneration attacks, we applied the attack from Zhao et al. (2023a) to watermarked images generated by our model. As shown in Table 2, the attack has minimal impact on the distribution of the cosine similarities between the initial noise and the inverted noise. The attacked noise similarity still maintains significant gap compared to random noise. To examine the performance of our inpainting method, we report the Frechet Inception Distance (FID) (Heusel et al., 2018) on the MS-COCO-2017 (Lin et al., 2015) training dataset in Table 3. Notably, our method achieves the lowest FID among the compared methods, indicating closer alignment with real images. Additionally we include some images generated by our framework in Figure 4."
        },
        {
            "title": "6 Discussion and Limitations",
            "content": "Editing Given Image vs. Forging. While forging our watermark by obtaining the initial noise is hard (Section 3), an easier path to obtaining harmful watermarked images might be to apply slight edit to an already watermarked image. An harmful image in this context might include copy-right infringing image, NSFW image, or any other content the model owner wish to avoid being associated with. Naturally, there is trade-off between the severity of the applied edit, and the edit ability to preserve the initial watermark. We present one solution to mitigating this issue in the next discussion point. Storing Database of Generations. Model owners wishing to protect themselves from an attacker modifying watermark image may keep database of the past generations by their model. For these extreme cases, the model owner might only save the used prompts and initial noiseseeds, and use the reconstructed noise to retrieve the entire set of prompts used with that specific seed (Huang & Wan, 2024). While this process may be resource-intensive, it is only required in the rare event that an attacker intentionally modifies benign image into harmful one while preserving the watermark. Private Model. Our watermark robustness is based to large extent on the inability of an attacker to invert model, which is empirically validated but not mathematically proven. Yet, as discussed in Section 2.2, the ability to successfully invert our model may be nearly equivalent to the ability to steal the forward diffusion process, effectively stealing the model (in which case, any watermarking attempt might be deemed quite useless anyhow). Still, better framing of the mathematical assumptions behind this claim is limitation of this work, as well as of previous works on watermarking using inversion of the diffusion generative process."
        },
        {
            "title": "After",
            "content": "Figure 5: Comparison of COCO images before and after watermarking via inpainting. Attackers Advantage. There exists large set of diverse attacks aimed at watermark removal (Zhang et al., 2023; Yang et al., 2024a; Zhao et al., 2023a), along with image transformations such as rotation and crops that also achieve some limited success against our watermark. As in many security applications, we suspect that an attacker capable enough will still be able to remove the watermark using new techniques we might not expect. However, more robust watermark may nevertheless help to decrease the spread of false information. Additional discussion and limitations can be found in Appendix C."
        },
        {
            "title": "7 Conclusion",
            "content": "In this work, we present robust and distortion-free watermarking method that leverages the initial noises employed in diffusion models for image generation. By integrating existing techniques, we enhanced the approach to achieve improved efficiency and robustness against various types of attacks. Furthermore, we outlined strategy for applying our method to non-generated images through inpainting."
        },
        {
            "title": "References",
            "content": "Ali Al-Haj. Combined dwt-dct digital image watermarking. Journal of computer science, 3(9): 740746, 2007. Bang An, Mucong Ding, Tahseen Rabbani, Aakriti Agrawal, Yuancheng Xu, Chenghao Deng, Sicheng Zhu, Abdirisak Mohamed, Yuxin Wen, Tom Goldstein, and Furong Huang. Waves: Benchmarking the robustness of image watermarks, 2024. URL https://arxiv.org/abs/2401. 08573. Alexandr Andoni, Piotr Indyk, and Ilya Razenshteyn. Approximate nearest neighbor search in high In Proceedings of the International Congress of Mathematicians: Rio de Janeiro dimensions. 2018, pp. 32873318. World Scientific, 2018. Maksym Andriushchenko, Francesco Croce, and Nicolas Flammarion. Jailbreaking leading safetyaligned llms with simple adaptive attacks. arXiv preprint arXiv:2404.02151, 2024. Tu Bui, Shruti Agarwal, Ning Yu, and John Collomosse. Rosteals: Robust steganography using autoencoder latent space, 2023. URL https://arxiv.org/abs/2304.03400. Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram`er, Borja Balle, Daphne Ippolito, and Eric Wallace. Extracting training data from diffusion models, 2023a. URL https://arxiv.org/abs/2301.13188. Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ippolito, and Eric Wallace. Extracting training data from diffusion models. In 32nd USENIX Security Symposium (USENIX Security 23), pp. 52535270, 2023b. Chin-Chen Chang, Piyu Tsai, and Chia-Chen Lin. Svd-based digital image watermarking scheme. Pattern Recognition Letters, 26(10):15771586, 2005. Junsong Chen, Chongjian Ge, Enze Xie, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, and Zhenguo Li. Pixart-σ: Weak-to-strong training of diffusion transformer for 4k text-to-image generation, 2024. Hai Ci, Pei Yang, Yiren Song, and Mike Zheng Shou. Ringid: Rethinking tree-ring watermarking for enhanced multi-key identification. arXiv preprint arXiv:2404.14055, 2024. Ingemar Cox, Matthew Miller, Jeffrey Bloom, Jessica Fridrich, and Ton Kalker. Digital watermarking and steganography. Morgan kaufmann, 2007. Scott Craver, Nasir Memon, B-L Yeo, and Minerva Yeung. Resolving rightful ownerships with IEEE Journal on invisible watermarking techniques: Limitations, attacks, and implications. Selected areas in Communications, 16(4):573586, 1998. Yingqian Cui, Jie Ren, Han Xu, Pengfei He, Hui Liu, Lichao Sun, Yue Xing, and Jiliang Tang. Diffusionshield: watermark for copyright protection against generative diffusion models. arXiv preprint arXiv:2306.04642, 2023. Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazare, Maria Lomeli, Lucas Hosseini, and Herve Jegou. The faiss library. arXiv preprint arXiv:2401.08281, 2024. Noureddine El Karoui. Concentration of measure and spectra of random matrices: Applications to correlation matrices, elliptical distributions and beyond. 2009."
        },
        {
            "title": "Preprint",
            "content": "Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Muller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, and Robin Rombach. Scaling rectified flow transformers for high-resolution image synthesis, 2024. URL https://arxiv.org/abs/2403. 03206. Pierre Fernandez, Guillaume Couairon, Herve Jegou, Matthijs Douze, and Teddy Furon. The stable In Proceedings of the IEEE/CVF signature: Rooting watermarks in latent diffusion models. International Conference on Computer Vision, pp. 2246622477, 2023a. Pierre Fernandez, Guillaume Couairon, Herve Jegou, Matthijs Douze, and Teddy Furon. The stable signature: Rooting watermarks in latent diffusion models, 2023b. URL https://arxiv. org/abs/2303.15435. Xiangming Gu, Chao Du, Tianyu Pang, Chongxuan Li, Min Lin, and Ye Wang. On memorization in diffusion models, 2023. URL https://arxiv.org/abs/2310.02664. Gustavosta. Stable-Diffusion-Prompts kernel description. https://huggingface.co/datasets/ Gustavosta/Stable-Diffusion-Prompts, 2024. Accessed: 2024-11-20. Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, and Yejin Choi. Clipscore: referencefree evaluation metric for image captioning. arXiv preprint arXiv:2104.08718, 2021. Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by two time-scale update rule converge to local nash equilibrium, 2018. URL https://arxiv.org/abs/1706.08500. Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:68406851, 2020. Yuepeng Hu, Zhengyuan Jiang, Moyang Guo, and Neil Gong. transfer attack to image watermarks. arXiv preprint arXiv:2403.15365, 2024. Baizhou Huang and Xiaojun Wan. Waterpool: watermark mitigating trade-offs among imperceptibility, efficacy and robustness. arXiv preprint arXiv:2405.13517, 2024. Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin. Black-box adversarial attacks with limited queries and information. In International conference on machine learning, pp. 21372146. PMLR, 2018. Zhengyuan Jiang, Jinghuai Zhang, and Neil Zhenqiang Gong. Evading watermark based detection of ai-generated content. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security, pp. 11681181, 2023. Feyza Duman Keles and Chinmay Hegde. On the fine-grained hardness of inverting generative models, 2023. URL https://arxiv.org/abs/2309.05795. Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, and Percy Liang. Robust distortion-free watermarks for language models. arXiv preprint arXiv:2307.15593, 2023. Gerhard Langelaar, Iwan Setyawan, and Reginald Lagendijk. Watermarking digital image and video data. state-of-the-art overview. IEEE Signal processing magazine, 17(5):2046, 2000. Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Dollar. Microsoft coco: Common objects in context, 2015. URL https://arxiv.org/abs/1405.0312."
        },
        {
            "title": "Preprint",
            "content": "Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, and Yang Zhang. Watermarking diffusion model. arXiv preprint arXiv:2305.12502, 2023. Nils Lukas and Florian Kerschbaum. Ptw: Pivotal tuning watermarking for pre-trained image generators, 2023. URL https://arxiv.org/abs/2304.07361. Yu. A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs, 2018. URL https://arxiv.org/abs/1603.09320. William Peebles and Saining Xie. Scalable diffusion models with transformers. arXiv preprint arXiv:2212.09748, 2022. Vidyasagar Potdar, Song Han, and Elizabeth Chang. survey of digital image watermarking techniques. In INDIN05. 2005 3rd IEEE International Conference on Industrial Informatics, 2005., pp. 709716. IEEE, 2005. Pun et al. Rotation, translation and scale invariant digital image watermarking. In icip, pp. 536. IEEE, 1997. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation, 2021. URL https://arxiv.org/abs/ 2102.12092. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. Highresolution image synthesis with latent diffusion models, 2022. URL https://arxiv.org/abs/ 2112.10752. Claude Elwood Shannon. Communication in the presence of noise. Proceedings of the IRE, 37(1): 1021, 1949. Himanshu Kumar Singh and Amit Kumar Singh. Comprehensive review of watermarking techniques in deep-learning environments. Journal of Electronic Imaging, 32(3):031804031804, 2023. Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning, pp. 22562265. PMLR, 2015. Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Understanding and mitigating copying in diffusion models. Advances in Neural Information Processing Systems, 36:4778347803, 2023a. Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Understanding and mitigating copying in diffusion models, 2023b. URL https://arxiv.org/abs/ 2305.20086. Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models, 2022. URL https://arxiv.org/abs/2010.02502. Jiuqi Wei, Botao Peng, Xiaodong Lee, and Themis Palpanas. Det-lsh: locality-sensitive hashing scheme with dynamic encoding tree for approximate nearest neighbor search. arXiv preprint arXiv:2406.10938, 2024. Yuxin Wen, John Kirchenbauer, Jonas Geiping, and Tom Goldstein. Tree-ring watermarks: Fingerprints for diffusion images that are invisible and robust. arXiv preprint arXiv:2305.20030, 2023."
        },
        {
            "title": "Preprint",
            "content": "Raymond Wolfgang and Edward Delp. watermark for digital images. In Proceedings of 3rd IEEE International Conference on Image Processing, volume 3, pp. 219222. IEEE, 1996. Ping Wah Wong and Nasir Memon. Secret and public key image watermarking schemes for image authentication and ownership verification. IEEE transactions on image processing, 10(10):1593 1601, 2001. Xun Xian, Ganghua Wang, Xuan Bi, Jayanth Srinivasa, Ashish Kundu, Mingyi Hong, and Jie Ding. Raw: robust and agile plug-and-play watermark framework for ai-generated images with provable guarantees. arXiv preprint arXiv:2403.18774, 2024. Cheng Xiong, Chuan Qin, Guorui Feng, and Xinpeng Zhang. Flexible and secure watermarking for latent diffusion model. In Proceedings of the 31st ACM International Conference on Multimedia, pp. 16681676, 2023. Pei Yang, Hai Ci, Yiren Song, and Mike Zheng Shou. Steganalysis on digital watermarking: Is your defense truly impervious?, 2024a. URL https://arxiv.org/abs/2406.09026. Zijin Yang, Kai Zeng, Kejiang Chen, Han Fang, Weiming Zhang, and Nenghai Yu. Gaussian shading: Provable performance-lossless image watermarking for diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1216212171, 2024b. Hanlin Zhang, Benjamin Edelman, Danilo Francati, Daniele Venturi, Giuseppe Ateniese, and Boaz Barak. Watermarks in the sand: Impossibility of strong watermarking for generative models. arXiv preprint arXiv:2311.04378, 2023. Kevin Alex Zhang, Lei Xu, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. Robust invisible video watermarking with attention, 2019. URL https://arxiv.org/abs/1909.01285. Xuandong Zhao, Kexun Zhang, Zihao Su, Saastha Vasan, Ilya Grishchenko, Christopher Kruegel, Giovanni Vigna, Yu-Xiang Wang, and Lei Li. Invisible image watermarks are provably removable using generative ai, 2023a. URL https://arxiv.org/abs/2306.01953. Xuandong Zhao, Kexun Zhang, Yu-Xiang Wang, and Lei Li. Generative autoencoders as watermark attackers: Analyses of vulnerabilities and threats. 2023b. Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Ngai-Man Cheung, and Min Lin. recipe for watermarking diffusion models. arXiv preprint arXiv:2303.10137, 2023c. Jiren Zhu, Russell Kaplan, Justin Johnson, and Li Fei-Fei. Hidden: Hiding data with deep networks, 2018. URL https://arxiv.org/abs/1807.09937."
        },
        {
            "title": "4 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.1 WIND: Two-stage Efficient Watermarking . . . . . . . . . . . . . . . . . . . . . . . .\n4.2 Resilience to Forgery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n4.3 Watermarking Non-Synthetic Images.",
            "content": "5 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1 Watermark Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 3 3 4 4 5 7 7 8 9 9 6 Discussion and Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Additional Discussion and Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . 19 Additional Results D.1 Applicability to Other Types of Models . . . . . . . . . . . . . . . . . . . . . . . . . D.2 Non-Synthetic Images Watermark Detection . . . . . . . . . . . . . . . . . . . . . . . D.3 Further Exploration of the Regeneration Attack Perturbation Strength . . . . . . . . D.4 Quantitative Analysis of the Effect on Image Quality . . . . . . . . . . . . . . . . . . D.5 Robustness Comparison to Different Number of Inference Steps . . . . . . . . . . . . D.6 True Positive and AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.7 Evaluation Against Additional Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 21 21 21 22 22 22 22 Proof of Resilience to Forgery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Further Discussion on Distortion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Number of Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 Empirical Runtime Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "Preprint",
            "content": "I Implementation Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Additional Qualitative Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "A Notation",
            "content": "Table 5: Notations used in the paper. i g"
        },
        {
            "title": "Secret salt for cryptographic security",
            "content": "Index of initial noise: [N ] Index of group: = i%M hash cryptographic hash function τ Θ GΘ G1 Θ"
        },
        {
            "title": "Threshold for declaring an image is watermarked",
            "content": "Number of diffusion steps Weights of diffusion model Text prompt for diffusion Diffusion model with weights Θ Inverse diffusion model with weights Θ"
        },
        {
            "title": "B Related Works",
            "content": "Memorization in Diffusion Models. Diffusion models (Ho et al., 2020; Sohl-Dickstein et al., 2015) have demonstrated capacity not only to generalize but also to memorize training data. This can lead to the reproduction of specific patterns or, in some cases, exact content from the training set, including sensitive or proprietary information. This memorization poses significant risks of unintended intellectual property leakage, particularly in large-scale generative models. Several studies have shown that information from training data can be extracted from diffusion models (Carlini et al., 2023b; Somepalli et al., 2023b; Carlini et al., 2023a; Gu et al., 2023; Somepalli et al., 2023a). Image Watermarking. Image watermarking is essential for protecting intellectual property, verifying content authenticity, and maintaining the integrity of digital media. The field has ranged from traditional signal processing techniques to recent deep learning methods (Potdar et al., 2005; Singh & Singh, 2023). Among Early watermarking strategies, one of the simplest methods was Least Significant Bit (LSB) embedding, which modifies the least significant bits of image pixels to imperceptibly embed watermarks (Wolfgang & Delp, 1996). Another classical approach utilized frequency-domain transformations and Singular Value Decomposition (SVD) to hide watermarks within image coefficients. (Chang et al., 2005; Al-Haj, 2007). Recent developments leverage deep learning for watermarking. For instance, HiDDeN (Zhu et al., 2018) introduced an end-to-end trainable framework for data hiding. RivaGAN (Zhang et al., 2019) utilizes adversarial training to embed watermarks, while Lukas & Kerschbaum (2023) proposed an embedding technique that optimizes efficiency by avoiding full generator retraining."
        },
        {
            "title": "Preprint",
            "content": "Table 6: Inpainting correct watermark detection accuracy."
        },
        {
            "title": "Clean Rotate",
            "content": "JPEG C&S Blur Noise Bright Avg 1.000 1.000 1.000 0.880 1. 0.950 0.950 0.969 Watermarking for Diffusion Models. Existing watermark methods for diffusion models can be divided into three categories: (i) Post-processing methods which adjust image features to embed watermarks (Zhao et al., 2023c; Fernandez et al., 2023b). This approach alters the image and its distribution, which can result in significant changes to the generated image. However, recent work by Zhao et al. (2023b) shows that pixel-level perturbations are removable by regeneration attacks makes. To date, this approach is not robust. (ii) Fine-tuning-based approaches combine the watermark within the generation process (Zhao et al., 2023c; Xiong et al., 2023; Liu et al., 2023; Fernandez et al., 2023a; Cui et al., 2023). To date, these methods have robustness issues as well (Zhao et al., 2023a). (iii) Tree-Ring introduced an approach to proposing method to imprint tree-ring pattern into the initial noise of diffusion model (Wen et al., 2023). Each pattern is used as key, which is added in the Fourier space of the noise. The verification of the presence of the key involves recovering the initial noise from the generated image and checking if the key is still detectable in Fourier space. This approach makes Tree-Ring and its follow-up works the most robust approach against attacks (Zhao et al., 2023a; An et al., 2024). Recently, Yang et al. (2024a) took advantage of the distribution shift present in Tree-Ring that occurs with impainting keys and arranged the first successful black box attack against it, as we detailed in Section 2.3."
        },
        {
            "title": "C Additional Discussion and Limitations",
            "content": "Relation to Other Initial Noise Watermarking Methods. The seminal work by Wen et al. (2023) innovated the use of initial noise in DDIM for watermarking. Most related to our work, Yang et al. (2024b) also embeds watermark in the initial noise already used by DDIM diffusion model. Yet, while Yang et al. (2024b) proposes watermark that is distortion-free for single image, it is not distortion-free when examining sets of images; therefore it is vulnerable to attacks such as Yang et al. (2024a). We aim to be robust to attacks even when many images are examined together. There are additional technical differences between our approach and Yang et al. (2024b). Most notably: (i) Our work also studies applying our watermark to non-synthetic (natural) images, or images coming from other generative models. (ii) While Yang et al. (2024b) design function to embed specific bits into the initial noise, we take another approach. Namely, we view the entire initial noise (with generation and inversion) as noisy channel. Inspired by Shannon (1949), we use random encoding of the watermark identities into the channel. Computational Requirements. As discussed in Section 3 our similarity search can be accelerated given well-known methods. Yet, the computational requirements of our method might be limiting when trying to use our method on edge devices. However, similarly to Tree-Ring and Ring-ID (Wen et al., 2023; Ci et al., 2024) our method assumes private model, which is usually not deployed on edge devices anyhow."
        },
        {
            "title": "Preprint",
            "content": "Figure 6: Image sequence from 0 to 50 regeneration attack iterations. Trade-Offs Between the Watermarking Overhead, and Detection Accuracy. We suggest the following variants of our method for different possible requirements of runtime scaling, detection robustness, and ease of adaptation. A. Detection of the group identifier alone: This operation takes search of O(M ), but is vulnerable to both removal and forgery attempts, as we use weaker watermark for group identifiers. B. Detection of the Fourier pattern, followed by validation of the exact initial noise (WINDfast): within the group. This operation takes O(N/M ) search. It is vulnerable to removal attempts, but more resilient to forgery attempts (see Table 1). C. An exhaustive search of the initial noise, also outside the identified group (WINDfull): This operation takes O(N ) search. It is more resilient to both removal and forgery attempts (see Figure 3, and Table 1). This method, while slower is also easier to adapt. user that wishes to use fast version of this variant may apply similar algorithm to the one described above using only few possible random noises. This would replace the distinguishability of many different watermarks with the ability to rapidly and simply detect the watermarked images. Practically, an NN search can be accelerated using many methods and can be scaled to tens of millions without significantly affecting the detection time (Wei et al., 2024; Douze et al., 2024; Malkov & Yashunin, 2018; Andoni et al., 2018). Image Quality Considerations. Our method relies on using an initial random noise, drawn from the same distribution of initial noises already used by the model. Therefore, the core of our method (the initial noise stage) is not compromising the visual quality of the generated images at all. The only effect on visual quality comes from the group identifier, where we use existing off-the-shelf watermarking images. In our implementation, we used the RingID (Ci et al., 2024) method that adds the Fourier pattern to the initial noise. When model owner wishes to preserve image quality even better, they may use any other existing watermarking method for the group identifier stage. This will still not compromise the security provided by the initial noise stage. Inversion Attack. As discussed in Section 2.2 in our paper, accurately inverting the model is as difficult as copying the forward process of the model (image generation). While hard, an attacker able to do so is effectively also capable of generating novel images using the same diffusion process. Therefore, At this stage, the model itself is effectively compromised (and not only the watermark signature). We believe that being as hard to forge as the model itself, is reasonable level of security for almost all use cases."
        },
        {
            "title": "Preprint",
            "content": "Table 7: Impact of different inference steps on detection accuracy."
        },
        {
            "title": "Steps Clean Rotate",
            "content": "JPEG C&S Blur Noise Bright Avg 20 50 100 200 1.000 1.000 1.000 1.000 0.780 0.930 0.930 0.850 1.000 1.000 1.000 1.000 0.880 0.940 0.940 0. 0.920 1.000 1.000 1.000 1.000 0.980 1.000 1.000 0.960 0.980 0.990 1.000 0.934 0.976 0.980 0.970 Yet, approximately inverting the model might also be threat. While even approximately inverting model is also very hard, it might be easier than stealing the model. Still, we would like to emphasize that our method is more secure than other diffusion-process-based watermarking techniques, where image distortion themselves may allow easier forging (Yang et al., 2024a)."
        },
        {
            "title": "D Additional Results",
            "content": "D.1 Applicability to Other Types of Models We expect our watermark to be effective directly for any model for which some inversion to the original noise is possible. Namely, as the correlation between random noises in very high dimension is very much concentrated around 0, even very slight success in the inversion process is enough to be distinguishable. In higher generation resolutions the dimensionality of the noise is even higher, and therefore the separation would be even better (El Karoui, 2009). Empirically, to validate the generality of our method, we also report results for the SD 1.4 model (Rombach et al., 2022). Using = 10000 noises and = 2048 group identifiers, our method achieved detection accuracy of 97% to identify the correct watermark (initial noise). In any case, our method of the reported SD 2.1 model can also be used to watermark images collected from other sources (please see Section 4.3, Appendix D.2). D.2 Non-Synthetic Images Watermark Detection Our inpainting method allows us to watermark both images generated by any model and nongenerated images. To evaluate the robustness of the inpainting watermarking approach, we present results in Table 1 for this method, utilizing = 100 noises. Results are shown in Table 6. D.3 Further Exploration of the Regeneration Attack Perturbation Strength In Section 5.1, we discussed the robustness of WIND against regeneration attacks. However, using it iteratively might still be stronger adversary. We applied the regeneration attack proposed by Zhao et al. (2023a), up to 50 times. We see that iterative regeneration indeed decreases the similarity between the original noise and the reconstructed one. This happens as the image becomes less and less correlated to the original generation Figure 6. Yet, the detection rate of our algorithm remains very high Table 14. We attribute this to the fact that even slight remaining correlation between the attacked image and the initial noise remains significant with respect to the correlation expected from non-watermarked images. This happens because of the very low correlation between random (non-watermarked) noises (Figure 2)."
        },
        {
            "title": "Preprint",
            "content": "D.4 Quantitative Analysis of the Effect on Image Quality We reported the FID of our model on Table 3. To further assess the effect of WIND watermark on image quality we report the CLIP score Hessel et al. (2021) before and after watermarking on Table 10. Results indicate that adding the watermark has negligible effect on the CLIP score for generated images. To further quantify the distortion introduced by each model, we report pixel-base matrices, SSIM and PSNR in the two settings we study: Images Generated by the Diffusion Model. WINDs distortion arises from using group identifiers, enabling faster detection. To disentangle this effect, we also evaluate WINDw/o, which omits group identifiers. As can be seen in Table 11, the image quality generated using our full method is comparable to that of previous techniques. Users who wish to generate distortion-free images, without affecting image quality, can do so by omitting the group identifier (at the cost of slower detection phase for very large values of ). Watermarking Non-Synthetic Images. Additionally, we present results for WINDinpainting, our inpainting-based approach capable of watermarking both non-synthetic images and outputs from other generative models  (Table 15)  . Although other watermarking methods may preserve image quality better, our image quality remains high. Importantly, to the best of our knowledge, our approach is the only one capable of watermarking non-synthetic images while remaining robust against the regeneration attack (Zhao et al., 2023a). Therefore, it is preferable when an adversary may try to remove the watermark. In addition, the inpainting technique can be applied selectively to specific parts of the image if the copyright owner wishes to perfectly preserve fine details in certain areas. D.5 Robustness Comparison to Different Number of Inference Steps We evaluate the impact of inference steps on detection accuracy, as shown in Table 7. The results indicate that using 100 steps yields better detection accuracy compared to other step counts, including the 50 steps used in our main experiments. Table 8: Error bars of WIND. AUC TP@1% 0.971 1. D.6 True Positive and AUC Expanding on the detection assessment settings discussed in Section 5, we reported WINDs error bars. AUC and True Positive (TPR@1%FPR) results are available on Table 8. Demonstrate strong performance, emphasizing WINDs robustness and reliability. D.7 Evaluation Against Additional Attacks We evaluate WIND against diverse set of attacks, including transfer-based, query-based, and white-box methods. Specifically, we employ the WeVade white-box attack (Jiang et al., 2023), the transfer attack described in Hu et al. (2024), black-box attack utilizing NES queries (Ilyas et al., 2018), and random search approach discussed in Andriushchenko et al. (2024), adopted to"
        },
        {
            "title": "Preprint",
            "content": "Table 9: Success rate of additional attacks."
        },
        {
            "title": "WeVade Random Search Transfer Attack NES Query",
            "content": "1% 2% 3% 2% attempt watermark removal. The success rates of these attacks are detailed in Table 9. Notably, none of these methods succeed against WIND, as the correct watermark remains detectable in over 97% of cases even after applying these attacks."
        },
        {
            "title": "E Proof of Resilience to Forgery",
            "content": "The WIND method is an approach for generating multiple watermarked images. Theorem 4.1 tells us that compromising one or more watermarked images does not give away any information about any other watermarked images. E.g., the adversary cannot generate valid reconstructed noise for any other initial noise index = i. That said, Theorem 4.1 does leave open the possibility that an adversary can take watermarked image, reconstruct the initial noise only for that image, and use it to attack the method, which we evaluate empirically. Cryptographic Background Consider cryptographic hash function hash: {0, 1} {0, 1}ℓ with ℓ output bits. E.g., ℓ = 256 for SHA-256. We will describe properties of the hash function in terms of difficulty; we say task is difficult if, as far as we know, finding solution is almost certainly beyond the computational capabilities of any reasonable adversary. An unbroken cryptographic hash function satisfies the following properties: Pre-image resistance requires that given hashed value v, it is difficult to find any message such that =hash(m). Second preimage resistance requires that given an input m1, it is difficult to find different input m2 such that hash(m1)= hash(m2). Collision resistance requires that it is difficult to find two different messages m1 and m2 such that hash(m1)= hash(m2). Theorem 4.1. [Cryptographic Security] Let hash: 0, 1 0, 1ℓ be an unbroken cryptographic hash function used in our watermarking algorithm, with inputs [N ] and secret salt s. Assume is sufficiently long and randomly generated. Then, even if an adversary obtains: the group number g, the initial noise index i, the initial noise zi , and even the corresponding output of the hash function seed, the adversary cannot: 1. Recover the secret salt s, 2. Generate valid reconstructed noise zj for any other initial noise index = Proof of Theorem 4.1. We will prove each part of the theorem separately: 1. The adversary cannot recover the secret salt s: Given the output seed = hash(i, s) and partial input the adversary aims to find s. This is equivalent to finding pre-image of given partial information about the input. By the pre-image resistance property of cryptographic hash functions, this task is computationally infeasible. Even if the adversary knows all possible values of i, the space of possible secret salts is too large to search exhaustively (as is sufficiently long random string). Therefore, the adversary cannot recover s. 2. The adversary cannot generate valid reconstructed noise for any other initial noise index = i. This security guarantee is ensured by two properties of hash: a) Second pre-image resistance: Given"
        },
        {
            "title": "Preprint",
            "content": "Figure 7: Cosine Similarity from 0 to 50 regeneration attack iterations. (i, s), its computationally infeasible to find (i, s) where = such that hash(i, s) = hash(i, s). b) Collision resistance: Its computationally infeasible to find any two distinct inputs that hash to the same output. These properties ensure that the adversary cannot find alternative inputs that produce the same hash output, and thus cannot generate valid reconstructed noise for different index numbers j. Table 10: Effect of WIND on CLIP score. CLIP Before Watermark CLIP After Watermark 0.366 0. Theorem 4.1 leaves open the possibility that an adversary can recover the noise from watermarked image and use that noise to forge new watermarked image. However, empirically we show that this attack fails without access to the weights of the private diffusion model. Table 11: SSIM and PSNR values of initial noise-based watermarking approaches. WINDw/o refers to the method without group identifiers Method SSIM PSNR . WINDw/o WINDfull RingID Tree-Ring 1.000 0.494 0.454 0.545 14.647 13.560 15."
        },
        {
            "title": "F Further Discussion on Distortion",
            "content": "Using the same initial noise for multiple generations is not distortion-free when examining groups of images. For example, all images with the same prompt and the same initial noise will"
        },
        {
            "title": "Preprint",
            "content": "Figure 8: Effect of the number of groups on the average accuracy of retrieving initial noise from 10,000 samples under various image transformation attacks. be identical, distorted away from the distribution of groups of images generated with i.i.d noises. Luckily, the huge gap between the similarities distribution of (i) reconstructed vs. used noise and (ii) reconstructed vs. another noise, allows us to use as many different noise patterns, while still keeping the noise we used distinguishable more similar to the reconstructed noises. Therefore, limiting the level of distortion in practice. Table 12: Detection time (second) WIND Tree-Ring RingID 22 14 Table 13: Accuracy of retrieving the initial noise from 10,000 noise samples, divided into varying numbers of groups, under different image transformation attacks. Groups Clean Rotate JPEG C&S Blur Noise Bright Avg 32 128 512 2048 1.000 1.000 1.000 1. 0.540 0.810 0.890 0.930 1.000 1.000 1.000 1.000 0.700 0.820 0.880 0.940 1.000 1.000 1.000 1.000 0.990 1.000 0.980 0.980 0.960 0.980 1.000 0. 0.884 0.944 0.964 0."
        },
        {
            "title": "G Number of Groups",
            "content": "In our framework, we divide the initial noises into groups and associate Tree-Ring-type key with each group. The use of Fourier Pattern keys enables robustness against rotation, and grouping reduces the search space for inverted noise. To investigate the impact of the number of groups, we performed an experiment with 10, 000 noises and varied the number of groups from 32 to 2048. As expected, Figure 8 demonstrates that increasing the number of groups leads to better accuracy in detecting the correct initial noise. This is because larger number of groups results in fewer noises per group, which facilitates more"
        },
        {
            "title": "Preprint",
            "content": "Table 14: Correct watermark detection after iterative regeneration attack."
        },
        {
            "title": "Iteration Cosine Similarity Detection Rate",
            "content": "10 20 30 40 50 0.493 0.342 0.243 0.170 0.121 100% 100% 100% 100% 100% Table 15: SSIM and PSNR values for non-synthetic image watermarking approaches."
        },
        {
            "title": "Method",
            "content": "SSIM PSNR"
        },
        {
            "title": "WINDinpainting\nDwtDctSvd\nRivaGAN\nSSL\nStegaStamp",
            "content": "0.768 0.983 0.978 0.984 0.911 26.806 39.381 40.550 41.795 28.503 accurate detection. Detailed results for each number of groups under transformation attacks are reported in Table 13."
        },
        {
            "title": "H Empirical Runtime Analysis",
            "content": "However, the runtime is highly sensitive to the available computational resources. To provide practical estimate, we measured the detection time using single NVIDIA GeForce RTX 3090. Specifically, we divided 100,000 initial noise samples into 32 groups and reported the detection. Under these conditions, the detection phase for 100,000 noise samples takes approximately 22 seconds per detection. We include comparison with other methods in Table 12. I"
        },
        {
            "title": "Implementation Details",
            "content": "Prompts. For all evaluations we used the set of prompts taken from Gustavosta (2024). Threshold for Detection. For the first variant WINDfast (see Section 4) we use threshold of min ℓ2 norm > 160. The second variant (WINDfull) does not use threshold, but rather, we choose the noise pattern within the group that has the lowest ℓ2 as our candidates for the identified noise. General Retrieval Details. We included simple rotation (using intervals of 2 degrees) and sliding window (window size of 32, stride of 8) searches as part of the retrieval process. These searches do not involve directly optimizing for the specific degrees of rotation or cropping encountered, ensuring that robustness remains intrinsic to the method."
        },
        {
            "title": "Preprint",
            "content": "Table 16: Comparison of correct watermark detection accuracy between WIND and previous image watermarking approaches under various image transformation attacks. WINDM denotes the use of groups, with the total number of noises (N ) specified in the Keys column. Method Keys Clean Rotate JPEG C&S Blur Noise Bright Avg DwtDct DwtDctSvd RivaGan 1 1 1 Tree-Ring RingID 32 128 2048 32 128 2048 WINDfast128 WINDfast2048 WINDfull128 WINDfull 100000 100000 100000 100000 0.974 1.000 0.999 0.790 0.450 0.200 1.000 1.000 1.000 1.000 1. 1.000 1.000 0.596 0.431 0.173 0.020 0.010 0.000 1.000 0.980 0.860 0.780 0.870 0.780 0. 0.492 0.753 0.981 0.420 0.120 0.040 1.000 1.000 1.000 1.000 0.960 1.000 1.000 0.640 0.511 0. 0.040 0.020 0.000 0.530 0.280 0.080 0.470 0.060 0.850 0.930 0.503 0.979 0.974 0.610 0.280 0. 0.990 0.980 0.970 1.000 0.960 1.000 1.000 0.293 0.706 0.888 0.530 0.230 0.070 1.000 1.000 0. 1.000 0.950 1.000 0.990 0.519 0.517 0.963 0.420 0.170 0.060 0.960 0.940 0.870 0.960 0. 0.574 0.702 0.854 0.404 0.183 0.066 0.926 0.883 0.819 0.887 0.814 1.000 0.980 0.947 0."
        },
        {
            "title": "J Additional Qualitative Results",
            "content": "Figure 9: More watermarked images generated with WIND."
        },
        {
            "title": "Preprint",
            "content": "Figure 10: More watermarked images generated with WIND."
        },
        {
            "title": "After",
            "content": "Figure 11: More comparisons of COCO images before and after watermarking with WIND."
        },
        {
            "title": "Preprint",
            "content": "Figure 12: More qualitative results of watermarked images generated using WIND, Tree-Ring, and RingID."
        },
        {
            "title": "Preprint",
            "content": "Figure 13: More qualitative results of watermarked images generated using WIND, Tree-Ring, and RingID."
        },
        {
            "title": "Preprint",
            "content": "Figure 14: More qualitative results of watermarked images generated using WIND, Tree-Ring, and RingID."
        },
        {
            "title": "Preprint",
            "content": "Figure 15: More qualitative results of watermarked images generated using WIND, Tree-Ring, and RingID."
        },
        {
            "title": "Preprint",
            "content": "Figure 16: More qualitative results of watermarked images generated using WIND, Tree-Ring, and RingID."
        },
        {
            "title": "Preprint",
            "content": "Figure 17: More qualitative results of watermarked images generated using WIND, Tree-Ring, and RingID."
        }
    ],
    "affiliations": [
        "New York University"
    ]
}