{
    "paper_title": "The Geometry of Reasoning: Flowing Logics in Representation Space",
    "authors": [
        "Yufa Zhou",
        "Yixiao Wang",
        "Xunjian Yin",
        "Shuyan Zhou",
        "Anru R. Zhang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We study how large language models (LLMs) ``think'' through their representation space. We propose a novel geometric framework that models an LLM's reasoning as flows -- embedding trajectories evolving where logic goes. We disentangle logical structure from semantics by employing the same natural deduction propositions with varied semantic carriers, allowing us to test whether LLMs internalize logic beyond surface form. This perspective connects reasoning with geometric quantities such as position, velocity, and curvature, enabling formal analysis in representation and concept spaces. Our theory establishes: (1) LLM reasoning corresponds to smooth flows in representation space, and (2) logical statements act as local controllers of these flows' velocities. Using learned representation proxies, we design controlled experiments to visualize and quantify reasoning flows, providing empirical validation of our theoretical framework. Our work serves as both a conceptual foundation and practical tools for studying reasoning phenomenon, offering a new lens for interpretability and formal analysis of LLMs' behavior."
        },
        {
            "title": "Start",
            "content": "The Geometry of Reasoning: Flowing Logics in Representation Space Yufa Zhou*, Yixiao Wang*, Xunjian Yin*, Shuyan Zhou, Anru R. Zhang Duke University {yufa.zhou,yixiao.wang,xunjian.yin,shuyan.zhou,anru.zhang}@duke.edu *Equal contribution. 5 2 0 2 0 1 ] . [ 1 2 8 7 9 0 . 0 1 5 2 : r We study how large language models (LLMs) think through their representation space. We propose novel geometric framework that models an LLMs reasoning as flowsembedding trajectories evolving where logic goes. We disentangle logical structure from semantics by employing the same natural deduction propositions with varied semantic carriers, allowing us to test whether LLMs internalize logic beyond surface form. This perspective connects reasoning with geometric quantities such as position, velocity, and curvature, enabling formal analysis in representation and concept spaces. Our theory establishes: (1) LLM reasoning corresponds to smooth flows in representation space, and (2) logical statements act as local controllers of these flows velocities. Using learned representation proxies, we design controlled experiments to visualize and quantify reasoning flows, providing empirical validation of our theoretical framework. Our work serves as both conceptual foundation and practical tools for studying reasoning phenomenon, offering new lens for interpretability and formal analysis of LLMs behavior. Code: https://github.com/MasterZhou1/Reasoning-Flow Dataset: https://huggingface.co/datasets/MasterZhou/Reasoning-Flow Reasoning is nothing but reckoning. Thomas Hobbes 1. Introduction The geometry of concept space, i.e., the idea that meaning can be represented as positions in structured geometric space, has long served as unifying perspective across AI, cognitive science, and linguistic philosophy [15, 59, 16]. Early work in this tradition was limited by the absence of precise and scalable semantic representations. With the rise of large language models (LLMs) [28, 52, 19, 21, 75], we revisit this geometric lens: pretrained embeddings now offer high-dimensional vector representations of words, sentences, and concepts [44, 49, 79, 35, 34], enabling geometric analysis of semantic and cognitive phenomena at scale. seminal recent work [46] formalizes the notion that learned representations in LLMs lie on low-dimensional concept manifolds. Building on this view, we hypothesize that reasoning unfolds as trajectory, potentially flow, along such manifolds. To explore this idea, we draw on classical tools from differential geometry [42, 25, 20, 9] and propose novel geometric framework for analyzing reasoning dynamics in language models. Concretely, we view reasoning as context-cumulative trajectory in embedding space: at each step, the reasoning prefix is extended, and the models representation is recorded to trace the evolving flow (Figures 1a and 1b). Our results suggest that LLM reasoning is not merely random walk on graphs [67, 45]. At the isolated embedding level, trajectories exhibit stochasticity reminiscent of graph-based views; however, when viewed cumulatively, structured flow emerges on low-dimensional concept manifold, where local velocities are governed by logical operations. To the best of our knowledge, this is the first work to formalize and empirically validate such dynamical perspective, offering quantitative evidence together with broad insights and implications. We further rigorously define and formalize The Geometry of Reasoning: Flowing Logics in Representation Space ğ’³ Î“ Î¨ Curves(ğ’) ğ´ = Î¨ Î“1 Curves(â„›) ğ¹ğ’ â„’form ? ğ·â„› â„’rep (a) Reasoning flows visualized using PCA in 3 dimensions. (b) Reasoning flows visualized using PCA in 2 dimensions. (c) Schematic illustration of mappings between spaces. Figure 1: Reasoning Flow. (ab) Visualizations on selected problem from MATH500 with six distinct answers. (c) Our geometric framework of mapping relationships among input space ğ’³ , concept space ğ’, logic space â„’, and representation space â„›. See Section 4 for more details. concept, logic, and representation spaces (Figure 1c), and relate them through carefully designed experiments. From Aristotles syllogistics to Freges predicate calculus and modern math foundations [4, 8, 11], formal logic isolates validity as form independent of content. Wittgensteins Tractatus sharpened this viewthe world is the totality of facts, not of things [72]underscoring logical form as the substrate of language and reality. In this spirit, we treat logic as carrier-invariant skeleton of reasoning and test whether LLMs, trained on massive corpora, have internalized such structural invariants on the embedding manifold, effectively rediscovering in data the universal logic that took humans two millennia to formalize. We deliberately construct dataset that isolates formal logic from its semantic carriers (e.g., topics and languages) to validate our geometric perspective. Our experiments, conducted with Qwen3 [75] hidden states on our newly constructed dataset, reveal that LLMs exhibit structured logical behavior. In the original (0-order) representation space, semantic properties dominate, with sentences on the same topic clustering together. However, when we analyze differences (1and 2-order representations), logical structure emerges as the dominant factor. Specifically, we find that velocity similarity and Menger curvature similarity remain highly consistent between flows sharing the same logical skeleton, even across unrelated topics and languages. In contrast, flows with different logical structures exhibit lower similarity, even when they share the same semantic carrier. These findings provide quantifiable evidence for our hypothesis that logic governs the velocity of reasoning flows. While interpretability research on LLMs has made substantial empirical progress [1, 58, 48, 61, 40, 13], rigorous theoretical understanding remains comparatively limited, with only few recent efforts in this direction [31, 54, 46, 55]. Our work contributes to this emerging line by introducing mathematically grounded framework with formal definitions and analytic tools for quantifying and analyzing how LLMs behave and reason. We hope our theory and empirical evidence open new perspective for interpretability community and spark practical applications. Our contributions are: We introduce geometric perspective that models LLM reasoning as flows, providing formal definitions and analytic tools to study reasoning dynamics. We design formal logic dataset that disentangles logical structure from semantic surface, enabling direct tests of whether LLMs internalize logic beyond semantics. We empirically validate our framework through experiments and analysis, demonstrating its utility and offering practical insights. The Geometry of Reasoning: Flowing Logics in Representation Space 2. Related Work Concept Space Geometry. The Linear Representation Hypothesis (LRH) proposes that concepts align with linear directions in embedding space, view supported by theoretical analyses and empirically validated in categorical, hierarchical, and truthfalse settings [54, 32, 55, 31, 41]. However, strict linearity is limited: features may be multi-dimensional or manifold-like, as seen in concepts like colors, years, dates, and antonym pairs. [12, 46, 34]. Other works emphasize compositionality, showing that concepts require explicit constraints or algebraic subspace operations to compose meaningfully [63, 70]. At broader scale, hidden-state geometry follows expansioncontraction patterns across layers and exhibits training trajectories whose sharp shifts coincide with emergent capabilities and grokking [65, 53, 39]. Sparse autoencoders further reveal multi-scale structure, from analogy-like crystals to anisotropic spectra [36]. Collectively, these results suggest that concept spaces are locally linear yet globally curved, compositional, and dynamic, motivating our perspective of reasoning as flows on such manifolds. Mechanistic Interpretability. LLMs have exhibited unprecedented intelligence ever since their debut [51]. Yet the underlying mechanisms remain opaque, as transformers are neural networks not readily interpretable by humansmotivating efforts to uncover why such capabilities emerge [61, 40]. Mechanistic Interpretability (MI) pursues this goal by reverse-engineering transformer internals into circuits, features, and algorithms [58, 13, 3]. The Transformer Circuits program at Anthropic exemplifies this agenda, systematically cataloging reusable computational subroutines [1]. Empirical studies reveal concrete algorithmic mechanisms: grokking progresses along Fourier-like structures [48], training can yield divergent solutions for the same task (Clock vs. Pizza) [81], arithmetic emerges via trigonometric embeddings on helical manifolds [33], and spatiotemporal structure is encoded through identifiable neurons [22]. Beyond circuits, in-context learning and fine-tuning yield distinct representational geometries despite comparable performance [10], while safety studies reveal polysemantic vulnerabilities where small-model interventions transfer to larger LLMs [18]. Understanding Reasoning Phenomenon. LLMs benefit from test-time scaling, where allocating more inference compute boosts accuracy on hard tasks [62]. Explanations span expressivityCoT enabling serial computation [37], reasoning as superposed trajectories [82], and hidden planning in scratch-trained math models [78]to inductive biases, where small initialization favors deeper chains [77]. Structural analyses view reasoning as path aggregation or graph dynamics with small-world properties [67, 45], while attribution highlights key thought anchors [5]. Empirical work shows inverted-U performance with CoT length and quantifiable reasoning boundaries [73, 6], and embedding-trajectory geometry supports OOD detection [68]. Moving beyond text, latent-reasoning methods scale compute through recurrent depth, continuous soft thinking, and latent CoT for branch exploration and self-evaluation [80, 17, 23, 69]. Applications exploit these insights for steering and efficiency: steering vectors and calibration shape thought processes [66, 7], manifold steering mitigates overthinking [27], and adaptive indices enable early exit [14]. Formal Logic with LLMs. Recent work links transformer computation directly to logic. Log-precision transformers are expressible in first-order logic with majority quantifiers, providing an upper bound on expressivity [43], while temporal counting logic compiles into softmax-attention architectures, giving constructive lower bound [76]. Beyond these characterizations, pre-pretraining on formal languages with hierarchical structure (e.g., Dyck) imparts syntactic inductive biases and improves efficiency [26]. Synthetic logic corpora and proof-generation frameworks further strengthen reasoning, though benefits diminish as proofs lengthen [47, 74]. Systematic evaluations, including LogicBench and surveys, highlight persistent failures on negation and inductive reasoning, despite partial gains from thinking models and rejection finetuning [56, 30, 38]. In contrast, our work employs formal logic not as an end task, but as tool to validate our geometric framework in LLMs representation space, distinguishing our contribution from prior lines of work. 3 The Geometry of Reasoning: Flowing Logics in Representation Space 3. Preliminaries 3.1. Large Language Models Let ğ’± denote finite vocabulary of tokens, and let ğœƒ denote the parameters of large language model (LLM). An LLM defines conditional probability distribution ğ‘ğœƒ(ğ‘¢ğ‘¡ ğ‘¢<ğ‘¡, ğ‘ƒ ), ğ‘¢ğ‘¡ ğ’±, where ğ‘¢<ğ‘¡ := (ğ‘¢1, . . . , ğ‘¢ğ‘¡1) is the prefix of previously generated tokens and ğ‘ƒ ğ’± ğ‘› is the tokenized problem prompt. At each step ğ‘¡, inference proceeds by sampling ğ‘¢ğ‘¡ ğ‘ğœƒ( ğ‘¢<ğ‘¡, ğ‘ƒ ). Definition 3.1 (Chain-of-Thought Reasoning). Given prompt ğ‘ƒ ğ’± ğ‘›, Chain-of-Thought (CoT) reasoning is an iterative stochastic process that generates sequence ğ’° = (ğ‘¢1, ğ‘¢2, . . . , ğ‘¢ğ‘‡ ), ğ‘¢ğ‘¡ ğ’±, via recursive sampling ğ‘¢ğ‘¡ ğ‘ğœƒ( ğ‘ƒ, ğ‘¢<ğ‘¡), ğ‘¡ = 1, . . . , ğ‘‡. To enable geometric analysis of reasoning, we need mapping from discrete token sequences into continuous vectors, transformation that modern LLMs naturally provide. Definition 3.2 (Representation Operator). Representation Operator is mapping â„° : ğ’± * â„ Rğ‘‘, where ğ‘¥ = (ğ‘¥1, . . . , ğ‘¥ğ‘›) ğ’± * is token sequence and ğœ„ â„ is an index specifying the representation type (e.g., token position, prefix, pooling rule, or an internal layer state). The output â„°(ğ‘¥, ğœ„) Rğ‘‘ is the embedding/representaion of ğ‘  under the selection rule ğœ„. For notational simplicity, we omit the index ğœ„ unless explicitly required. The range of this operator defines the ambient space of reasoning: Definition 3.3 (Representation Space). Given an representation operator â„°, the representation space is â„› := {â„°(ğ‘¥) : ğ‘¥ ğ’± *} Rğ‘‘. Elements of â„› are continuous embeddings of discrete language inputs, serving as the foundation and empirical proxy for our geometric analysis of reasoning. In practice, â„° may be instantiated by pretrained encoder such as Qwen3 Embedding [79] or OpenAIs text-embedding-3-large [49], or by extracting hidden states directly from an LLM. Typical choices of ğœ„ include mean pooling, the hidden state of the final token, or specific layerposition pair within the model [79, 35, 24, 50]. We interpret â„° as projecting discrete language sequences into continuous semantic space, potentially lying on low-dimensional manifold embedded in Rğ‘‘ [46, 12, 34]. 3.2. Menger Curvature We adopt Menger curvature [42] to quantitatively capture the geometric structure of reasoning flows. As metricbased notion of curvature, Menger curvature simultaneously reflects both angular deviation and distance variation, making it particularly suitable for reasoning trajectories represented as discrete embeddings. We leave more details to Appendix C.2. Definition 3.4 (Menger Curvature). Let ğ‘¥1, ğ‘¥2, ğ‘¥3 Rğ‘› be three distinct points. The Menger curvature of the triple (ğ‘¥1, ğ‘¥2, ğ‘¥3) is defined as the reciprocal of the radius ğ‘…(ğ‘¥1, ğ‘¥2, ğ‘¥3) of the unique circle passing through the three points: ğ‘(ğ‘¥1, ğ‘¥2, ğ‘¥3) = . 1 ğ‘…(ğ‘¥1,ğ‘¥2,ğ‘¥3) 4. Reasoning as Geometric Flows in Representation Space We formalize the view that LLMs reason by tracing trajectories in their representation space. central question is whether LLMs exhibit intrinsic control over these flows, mirroring the human perspective. We hypothesize semantic content as curve on concept manifold, and logical structure acts as local controller of the trajectory. In this section, we introduce the spaces, maps, and geometric quantities that underpin the paper. We then rigorously formalize this construction and establish the correspondence between the LLMs representation space and the human concept space. 4 The Geometry of Reasoning: Flowing Logics in Representation Space 4.1. Concept Space and Semantic Trajectories Definition 4.1 (Concept Space). The concept space ğ’ is an abstract semantic space that models human-level cognitive structures such as ideas, reasoning states, and problem-solving subtasks. We assume ğ’ is endowed with smooth geometric structure, allowing continuous trajectories to represent the evolution of conceptual content. This assumption can be traced back to the classical insight of William James [29], who famously argued that consciousness does not appear to itself chopped up in bits. Chains or trains of thought are, in his words, inadequate metaphors; instead, it is nothing jointed; it flows. river or stream are the metaphors by which it is most naturally described. Definition 4.2 (Semantic Subspace as Cognitive Trajectories). Let â„³ ğ’ denote semantic subspace corresponding to coherent domain of meaning (e.g., temporal concepts, colors, or causal relations). Let ğ’³ * denote the set of all finite input sequences over ğ’³ . We introduce trajectory map that assigns each sentence ğ‘‹ğ‘‡ = (ğ‘¥1, . . . , ğ‘¥ğ‘‡ ) to continuous curve ğ›¾ğ‘‹ within â„³. Formally, Î“ : ğ’³ * Curves(â„³), ğ‘‹ ğ›¾ğ‘‹ , ğ›¾ğ‘‹ : [0, 1] â„³, ğ‘  ğ›¾ğ‘‹ (ğ‘ ), where ğ‘  [0, 1] is continuous progress parameter along the reasoning flow. For each discrete prefix (ğ‘¥1, . . . , ğ‘¥ğ‘¡), ) on the curve. The curve ğ›¾ğ‘‹ thus traces the gradual unfolding of semantic content, we align it with the point ğ›¾ğ‘‹ formalizing the view that human cognition operates as continuous flow of concepts rather than as sequence of isolated symbols. ( ğ‘¡ ğ‘‡ We then define the logic space that mirrors the human view of logic. Definition 4.3 (Formal Logical Space). The formal logical space â„’ is an abstract domain that captures structural dynamics of reasoning (natural deduction [64, 57]; see Definition 5.1). Define the flow operator which maps semantic trajectory to its formal counterpart. Semantically different expressions that correspond to the same natural-deduction proposition map to the same element in â„’form. ğ¹ğ’ : Curves(ğ’) â„’form, 4.2. Representation Space We use LLM representations/embeddings as proxies to study human cognition and to investigate why LLMs exhibit reasoning phenomenon. We build on the multidimensional linear representation hypothesis [46], which posits that representations decompose linearly into superposition of features. Each feature corresponds to basis direction within feature-specific subspace of the embedding space, weighted by non-negative activation coefficient encoding its salience. Hypothesis 4.4 (Multidimensional Linear Representation Hypothesis [46]). Let ğ’³ denote the input space (e.g., natural language sentences). Let â„± be set of semantic features. For each feature ğ‘“ â„±, let ğ’²ğ‘“ Rğ‘‘ denote feature-specific subspace of the embedding space. Then the representation map Î¨ : ğ’³ Rğ‘‘ of an input ğ‘¥ ğ’³ is assumed to take the form Î¨(ğ‘¥) = ğœŒğ‘“ (ğ‘¥)ğ‘¤ğ‘“ (ğ‘¥), ğ‘“ ğ¹ (ğ‘¥) where ğ¹ (ğ‘¥) = {ğ‘“ â„± : ğœŒğ‘“ (ğ‘¥) > 0} is the set of active features in ğ‘¥, ğœŒğ‘“ (ğ‘¥) R0 is non-negative scaling coefficient encoding the intensity or salience of feature ğ‘“ in ğ‘¥, ğ‘¤ğ‘“ (ğ‘¥) ğ’²ğ‘“ is unit vector (ğ‘¤ğ‘“ (ğ‘¥)2 = 1) specifying the direction of feature ğ‘“ within its subspace ğ’²ğ‘“ . 5 The Geometry of Reasoning: Flowing Logics in Representation Space Algorithm 1: Get Context Cumulative Reasoning Trajectory ğ’±: vocabulary space; ğ‘ƒ ğ’± ğ‘›: tokenized problem prompt; ğ‘‡ : number of reasoning steps; ğ‘¥ğ‘¡ ğ’± *: tokens for step ğ‘¡; â„° : ğ’± * Rğ‘‘: representation operator; ğ‘¦ğ‘¡ Rğ‘‘: embedding at step ğ‘¡. Input: ğ‘ƒ ğ’± ğ‘›; ğ‘‹ = [ğ‘¥1, . . . , ğ‘¥ğ‘‡ ] with ğ‘¥ğ‘¡ ğ’± * Output: ğ‘Œ = [ğ‘¦1, . . . , ğ‘¦ğ‘‡ ] Rğ‘‘ğ‘‡ ğ‘Œ [ ], ğ‘†0 [ğ‘ƒ ]; for ğ‘¡ 1 to ğ‘‡ do ğ‘†ğ‘¡ Concat(ğ‘†ğ‘¡1, ğ‘¥ğ‘¡); ğ‘¦ğ‘¡ â„°(ğ‘†ğ‘¡); Append ğ‘¦ğ‘¡ to ğ‘Œ ; return ğ‘Œ ; // Concatenate with previous context // Get embedding of current step Building on this compositional picture, we now move from single inputs to growing contexts. As model reasons, its internal representation evolves. The next definition formalizes this evolution as cumulative flow in embedding space. Definition 4.5 (Reasoning Trajectory / Context Cumulative Flow). Let ğ’³ be the input space, and Î¨ : ğ’³ Rğ‘‘ the representation map from finite input sequences to the embedding space defined in Hypothesis 4.4. Given prompt ğ‘ƒ ğ’³ and Chain-of-Thought sequence ğ‘‹ğ‘‡ = (ğ‘¥1, . . . , ğ‘¥ğ‘‡ ) with ğ‘¥ğ‘¡ ğ’³ , define ğ‘†ğ‘¡ := (ğ‘ƒ, ğ‘¥1, . . . , ğ‘¥ğ‘¡), ğ‘¦ğ‘¡ := Î¨(ğ‘†ğ‘¡) Rğ‘‘, ğ‘¡ = 1, . . . , ğ‘‡. When focusing solely on the reasoning process (ignoring the prompt), we set ğ‘¦ğ‘¡ := Î¨(ğ‘‹ğ‘¡) Rğ‘‘, ğ‘¡ = 1, . . . , ğ‘‡. The sequence ğ‘Œ = [ğ‘¦1, . . . , ğ‘¦ğ‘‡ ] Rğ‘‘ğ‘‡ is called the context cumulative flow. The construction of ğ‘Œ follows Algorithm 1. The embeddings we observe along sentence are discrete, while reasoning itself is naturally understood to unfold as continuous process. It is therefore natural to posit an underlying smooth curve from which these discrete points arise as samples, thereby enabling the use of geometric tools such as velocity and curvature. Hypothesis 4.6 (Smooth Representation Trajectory). The discrete representations {ğ‘¦ğ‘¡}ğ‘‡ accumulation intrinsically lie on ğ¶ 1 curve Î¨ : [0, 1] Rğ‘‘ satisfying ğ‘¡=1 produced by context Î¨(ğ‘ ğ‘¡) = ğ‘¦ğ‘¡ for an increasing schedule ğ‘ 1 < < ğ‘ ğ‘‡ . In other words, the sequence is not merely fitted by smooth curve, but should be regarded as samples from an underlying smooth trajectory. This assumption is reasonable: in Appendix C.1 we show an explicit construction of such ğ¶ 1 trajectory via relaxed prefix-mask mechanism. Once smooth trajectory exists, we can canonically align symbolic progress (e.g., how far along the derivation we are) with geometric progress in representation space. The following corollary formalizes this alignment on domains where the symbolic schedule is well-behaved. Corollary 4.7 (Canonical Alignment). On domain where Î“ is injective and Î¨ is defined, there exists canonical alignment ğ´ : Curves(ğ’) Curves(â„›), ğ´ := Î¨ Î“1. 6 The Geometry of Reasoning: Flowing Logics in Representation Space 4.3. Logic as Differential Constraints on Flow We now turn from the structural hypotheses of representation trajectories to their dynamical regulation. In particular, we view logic not as an external add-on, but as set of differential constraints shaping how embeddings evolve step by step. This perspective enables us to couple discrete reasoning structure with continuous semantic motion. Definition 4.8 (Representation-Logic Space). Given representation trajectory ğ‘Œ = (ğ‘¦1, . . . , ğ‘¦ğ‘‡ ) defined in Definition 4.5, define local increments ğ‘¦ğ‘¡ := ğ‘¦ğ‘¡ ğ‘¦ğ‘¡1 for ğ‘¡ 2. The representation-logic space is â„’rep := { (ğ‘¦2, . . . , ğ‘¦ğ‘‡ ) ğ‘Œ context-cumulative trajectory }. The above constructs discrete object: sequence of increments capturing how representations change from one reasoning step to the next. To connect this discrete view with continuous account of semantic evolution, we next introduce the notion of velocity along embedding trajectories. Definition 4.9 (Flow Velocity). Let Î¨ : [0, 1] Rğ‘‘ be the continuous embedding trajectory associated with sentence. The flow velocity at progress ğ‘  is defined as ğ‘£(ğ‘ ) = dğ‘  Î¨(ğ‘ ), which captures the instantaneous rate of change of the embedding w.r.t. the unfolding of the sentence. By relating local increments in representation space (Definition 3.3) to the derivative of continuous trajectory, we can interpret each discrete reasoning step as an integrated outcome of infinitesimal semantic motion. Proposition 4.10 (Logic as Integrated Thought). By the fundamental theorem of calculus, the cumulative semantic shift between two successive reasoning steps ğ‘ ğ‘¡ and ğ‘ ğ‘¡+1 is ğ‘ ğ‘¡+1 ğ‘ ğ‘¡ ğ‘£(ğ‘ ) dğ‘  = Î¨(ğ‘ ğ‘¡+1) Î¨(ğ‘ ğ‘¡) = ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡ = ğ‘¦ğ‘¡+1. Thus, we could view each representationlogic step as the integration of local semantic velocity, which aggregates infinitesimal variations of meaning into discrete reasoning transition. Definition 4.9 captures the central principle that semantic representations evolve continuously, whereas logical steps are inherently discrete: logic acts as the controller of semantic velocity, governing both its magnitude and its direction. Having established this continuousdiscrete correspondence, we can now ask: what properties of reasoning flows should persist across changes in surface semantics? We posit that reasoning instances sharing the same natural-deduction skeleton but differing in semantic carriers (e.g., topics or languages) should yield reasoning flows whose trajectories exhibit highly correlated curvature (Definition 3.4). If logic governs flow velocity (magnitude and direction) then flows instantiated with different carriers may undergo translations or rotations, reflecting dominant semantic components of the original space. Nevertheless, their overall curvature should remain invariant. more detailed discussion of curvature is provided in Appendix C.2. Such correlation would indicate that the accumulation of semantic variation produces turning points aligned with both LLM reasoning and human logical thought. This directly corresponds to the central research objective of this paper, namely clarifying the relationship between the two logical spaces â„’form and â„’rep as illustrated in Figure 1c. Empirical evidence for this claim will be provided later, where we demonstrate cross-carrier similarity in both first-order differences and curvature. In summary, logic functions as the differential regulator of semantic flow, discretizing continuous variations into meaningful steps. For clarity and reference, all mappings and derivational relationships introduced in this subsection are systematically summarized in Appendix B. 5. Formal Logic with Semantic Carriers 5.1. Logic and Natural Deduction System We construct dataset of reasoning tasks that instantiate the fundamental logical patterns formalized in Definition 5.1. Each task is presented step by step in both formal symbolic notation and natural language. To test 7 The Geometry of Reasoning: Flowing Logics in Representation Space Table 1: Comparison of reasoning-flow similarities across 4 models. We report mean cosine similarity (position, velocity) and Pearson correlation (curvature) under 3 grouping criteria: logic, topic, and language. Results show that position similarity is dominated by surface carriers, while velocity and curvature highlight logical structure as the primary invariant. See Section 6 for more. Model Position Similarity Velocity Similarity Curvature Similarity Logic Topic Lang. Logic Topic Lang. Logic Topic Lang. Qwen3 0.6B Qwen3 1.7B Qwen3 4B LLaMA3 8B 0.26 0.44 0.33 0.31 0.30 0.46 0.35 0.34 0.85 0.89 0.86 0.74 0.17 0.19 0.16 0. 0.07 0.08 0.07 0.06 0.08 0.09 0.08 0.07 0.53 0.46 0.53 0.58 0.11 0.13 0.11 0.13 0.13 0.15 0.13 0.17 whether reasoning relies on surface content or underlying structure, we express the same logical skeletons across diverse carriers, e.g., topics such as weather, education, and sports, as well as multiple languages (en, zh, de). This design disentangles logics from linguistic surface and provides controlled setting for analyzing how reasoning flows behave under varying contexts. Definition 5.1 (Natural Deduction System [64, 57]). natural deduction system is pair ND = (ğ¹, ğ‘…) where: ğ¹ : formal language of formulas (e.g., propositional or first-order logic), ğ‘…: finite set of inference rules with introduction and elimination rules for each logical constant. derivation (or proof) in ND is tree whose nodes are judgements of the form formula is derivable and whose edges follow inference rules from ğ‘…. Temporary assumptions may be introduced in sub-derivations and are discharged by certain rules (e.g., ğ¼, ğ¼). Each connective is governed by paired introduction and elimination rules, which together determine its proof-theoretic meaning. 5.2. Data Design To test whether LLM reasoning trajectories are governed by logical structure rather than semantic content, we generates parallel reasoning tasks that maintain identical logical scaffolding while systematically varying superficial characteristics, specifically topical domain and linguistic realization. Our dataset construction employs principled two-stage generation pipeline using GPT-5 [52]. It proceeds as follows: (i) abstract logical templates are first constructed, followed by (ii) domain-specific and language-specific rewriting. Our final dataset comprises 30 distinct logical structures, each containing between 8 and 16 reasoning steps. Each logical structure is instantiated across 20 topical domains and realized in four languages (English, Chinese, German, and Japanese), yielding total corpus of 2,430 reasoning sequences. This controlled design enables direct comparison of trajectories across logical forms and surface carriers, isolating the role of logical structure in embedding dynamics. Full generation prompts and sampled data cases are provided in Appendix D. 6. Play with LLMs 6.1. Experimental Setup We employ the Qwen3 [75] family models and LLaMA3 [19]. From the final transformer layer (before the LM head), we extract context-dependent hidden states {â„(ğ¿) ğ‘– Rğ‘‘ denotes the representation at layer ğ¿ and position ğ‘–. Each reasoning step ğ‘¥ğ‘¡ is set of tokens indexed by ğ’®ğ‘¡, and its step-level embedding is defined by mean pooling: ğ‘¦ğ‘¡ = 1 ğ‘¦ğ‘¡ Rğ‘‘. The resulting sequence ğ‘Œ = (ğ‘¦1, . . . , ğ‘¦ğ‘‡ ) forms the reasoning ğ‘–ğ’®ğ‘¡ ğ’®ğ‘¡ trajectory in representation space. ğ‘– }, where â„(ğ¿) â„(ğ¿) ğ‘– , 8 The Geometry of Reasoning: Flowing Logics in Representation Space (a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity. Figure 2: Similarity of reasoning flows on Qwen3 0.6B. Blocks correspond to logic templates (L:AE) instantiated with different topics and languages. (a) Position similarity (mean cosine): diagonals correspond to topics (e.g., Network Security), showing that positions are dominated by surface semantics. (b) Velocity similarity (mean cosine): semantic effects diminish, and flows with the same logical skeleton align while differing logics diverge. (c) Curvature similarity (Pearson): separation is further amplified, with logic emerging as the principal invariant and revealing close similarity between logics and C. See Section 6 for more details. 6.2. Results Analysis We evaluate four models (Qwen3 0.6B, 1.7B, 4B, and LLaMA3 8B) by extracting hidden states across our dataset (Section 5) and computing similarities under three criteria: (i) Logic, grouping by deduction skeleton and averaging across topics and languages; (ii) Topic; and (iii) Language, both capturing surface carriers. This yields position, velocity, and curvature similarities  (Table 1)  . Results show that logical similarity is low at zeroth order (position) but becomes dominant at first and second order (velocity and curvature), validating our hypothesis. Topic and language exhibit low velocity similarity, suggesting they might occupy orthogonal subspaces; by contrast, the high logical similarity at first and second order breaks this orthogonality, indicating that logical structure transcends surface carriers. For visualization, we also analyze Qwen3 0.6B on subset of our dataset (Figure 2). At the position level, embeddings cluster by topic and language. First-order differences reveal logical control: flows sharing the same skeleton align, while differing logics diverge even with identical carriers. Second-order curvature further amplifies this separation, and its strong cross-carrier consistency directly supports Proposition 4.10, confirming that logic governs reasoning velocity. Additional experiments across broader model families are presented in Appendix A. Together, these results show that LLMs internalize latent logical structure beyond surface form. They are not mere stochastic parrots [2]: whereas humans formalized logic only in the 20th century [4], LLMs acquire it emergently from large-scale dataa hallmark of genuine intelligence. 7. Discussion Contrast with Graph Perspective. Prior works have modeled chain-of-thought reasoning as graph structure [45, 67]. While this provides useful perspective, its predictive power is limited: graphs naturally suggest random walks between discrete nodes, which fits the noisy behavior of isolated embeddings but fails to capture the smooth, directed dynamics we observe under cumulative context. Our results in Section 6 show that well-trained LLMs learn flows governed by logical structure, transcending the surface semantics of language. Such continuity and logic-driven trajectories cannot be explained within purely graph-based framework, but arise naturally in our differential-geometric view. 9 The Geometry of Reasoning: Flowing Logics in Representation Space Other Components in Learned Representation. Beyond logical structure, learned representations also encode wide spectrum of factors such as semantic objects, discourse tone, natural language identity, and even signals of higher-level cognitive behavior. Extending our framework to systematically isolate these components and characterize their interactions presents major challenge for future work. promising direction is to develop methods that disentangle additional attributes, enabling finer-grained insights into how language components co-evolve in representation space. Practical Implications. Our results suggest that reasoning in LLMs unfolds as continuous flows, opening multiple directions. First, trajectory-level control offers principled tools for steering, alignment, and safety, extending vectorbased interventions to flow dynamics [66, 7, 18, 27, 3]. Second, our geometric view provides formal framework to study abstract language concepts, enabling first-principle analyses of reasoning efficiency, stability, and failure modes. Third, it motivates new approaches to retrieval and representation, where embeddings respect reasoning flows rather than mere similarity, potentially improving RAG, reranking, and search [71]. Finally, it hints at architectural advances, as models parameterizing latent flows may enable more efficient reasoning [23, 17, 80, 60]. 8. Conclusion We introduced novel geometric framework that models LLM reasoning as smooth flows in representation space, with logic acting as controller of local velocities. By disentangling logical structure from semantic carriers through controlled dataset, we showed that velocity and curvature invariants reveal logic as the principal organizing factor of reasoning trajectories, beyond surface form. Our theory and experiments provide both conceptual foundation and practical tools for analyzing reasoning, opening new avenues for interpretability."
        },
        {
            "title": "Acknowledgment",
            "content": "ARZ was partially supported by NSF Grant CAREER-2203741."
        },
        {
            "title": "References",
            "content": "[1] Anthropic. Transformer circuits. https://transformer-circuits.pub/, 2021. [2] Emily Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pages 610623, 2021. [3] Leonard F. Bereska and Efstratios Gavves. Mechanistic interpretability for ai safety review. TMLR, April 2024. [4] Joseph Bochenski and Ivo Thomas. history of formal logic. 1961. [5] Paul Bogdan, Uzay Macar, Neel Nanda, and Arthur Conmy. Thought anchors: Which llm reasoning steps matter? arXiv preprint arXiv:2506.19143, 2025. [6] Qiguang Chen, Libo Qin, Jiaqi Wang, Jingxuan Zhou, and Wanxiang Che. Unlocking the capabilities of thought: reasoning boundary framework to quantify and optimize chain-of-thought. Advances in Neural Information Processing Systems, 37:5487254904, 2024. [7] Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, and Zhangyang Wang. Seal: Steerable reasoning calibration of large language models for free. arXiv preprint arXiv:2504.07986, 2025. [8] Irving Copi, Carl Cohen, and Kenneth McMahon. Introduction to logic. Routledge, 2016. [9] Manfredo Do Carmo. Differential geometry of curves and surfaces: revised and updated second edition. Courier Dover Publications, 2016. 10 The Geometry of Reasoning: Flowing Logics in Representation Space [10] Diego Doimo, Alessandro Serra, Alessio Ansuini, and Alberto Cazzaniga. The representation landscape of few-shot learning and fine-tuning in large language models. Advances in Neural Information Processing Systems, 37:1812218165, 2024. [11] Herbert Enderton. mathematical introduction to logic. Elsevier, 2001. [12] Joshua Engels, Eric Michaud, Isaac Liao, Wes Gurnee, and Max Tegmark. Not all language model features are one-dimensionally linear. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=d63a4AM4hb. [13] Javier Ferrando, Gabriele Sarti, Arianna Bisazza, and Marta Costa-JussÃ . primer on the inner workings of transformer-based language models. arXiv preprint arXiv:2405.00208, 2024. [14] Yichao Fu, Junda Chen, Siqi Zhu, Zheyu Fu, Zhongdongming Dai, Yonghao Zhuang, Yian Ma, Aurick Qiao, Tajana Rosing, Ion Stoica, et al. Efficiently scaling llm reasoning with certaindex. arXiv preprint arXiv:2412.20993, 2024. [15] Peter Gardenfors. Conceptual spaces: The geometry of thought. MIT press, 2004. [16] Peter Gardenfors. The geometry of meaning: Semantics based on conceptual spaces. MIT press, 2014. [17] Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, and Tom Goldstein. Scaling up test-time compute with latent reasoning: recurrent depth approach. arXiv preprint arXiv:2502.05171, 2025. [18] Bofan Gong, Shiyang Lai, and Dawn Song. Probing the vulnerability of large language models to polysemantic interventions. arXiv preprint arXiv:2505.11611, 2025. [19] Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of models. arXiv e-prints, pages arXiv2407, 2024. [20] Heinrich Guggenheimer. Differential geometry. Courier Corporation, 2012. [21] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. [22] Wes Gurnee and Max Tegmark. Language models represent space and time. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=jE8xbmvFin. [23] Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, and Yuandong Tian. Training large language models to reason in continuous latent space. arXiv preprint arXiv:2412.06769, 2024. [24] Hesam Sheikh Hessani. Llm embeddings explained: visual and intuitive guide, 2025. [25] Noel Hicks. Notes on differential geometry, volume 1. van Nostrand Princeton, 1965. [26] Michael Hu, Jackson Petty, Chuan Shi, William Merrill, and Tal Linzen. Between circuits and chomsky: Pre-pretraining on formal languages imparts linguistic biases. arXiv preprint arXiv:2502.19249, 2025. [27] Yao Huang, Huanran Chen, Shouwei Ruan, Yichi Zhang, Xingxing Wei, and Yinpeng Dong. Mitigating overthinking in large reasoning models via manifold steering. arXiv preprint arXiv:2505.22411, 2025. [28] Aaron Hurst, Adam Lerer, Adam Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024. [29] William James, Frederick Burkhardt, Fredson Bowers, and Kestutis Skrupskelis. The principles of psychology, volume 1. Macmillan London, 1890. 11 The Geometry of Reasoning: Flowing Logics in Representation Space [30] Jin Jiang, Jianing Wang, Yuchen Yan, Yang Liu, Jianhua Zhu, Mengdi Zhang, Xunliang Cai, and Liangcai Gao. Do large language models excel in complex logical reasoning with formal language? arXiv preprint arXiv:2505.16998, 2025. [31] Yibo Jiang, Bryon Aragam, and Victor Veitch. Uncovering meanings of embeddings via partial orthogonality. Advances in Neural Information Processing Systems, 36:3198832005, 2023. [32] Yibo Jiang, Goutham Rajendran, Pradeep Kumar Ravikumar, Bryon Aragam, and Victor Veitch. On the origins of linear representations in large language models. In Forty-first International Conference on Machine Learning, 2024. URL https://openreview.net/forum?id=otuTw4Mghk. [33] Subhash Kantamneni and Max Tegmark. Language models use trigonometry to do addition. arXiv preprint arXiv:2502.00873, 2025. [34] Austin Kozlowski, Callin Dai, and Andrei Boutyline. Semantic structure in large language model embeddings. arXiv preprint arXiv:2508.10003, 2025. [35] Jinhyuk Lee, Feiyang Chen, Sahil Dua, Daniel Cer, Madhuri Shanbhogue, Iftekhar Naim, Gustavo HernÃ¡ndez Ãbrego, Zhe Li, Kaifeng Chen, Henrique Schechter Vera, et al. Gemini embedding: Generalizable embeddings from gemini. arXiv preprint arXiv:2503.07891, 2025. [36] Yuxiao Li, Eric Michaud, David Baek, Joshua Engels, Xiaoqing Sun, and Max Tegmark. The geometry of concepts: Sparse autoencoder feature structure. Entropy, 27(4):344, 2025. [37] Zhiyuan Li, Hong Liu, Denny Zhou, and Tengyu Ma. Chain of thought empowers transformers to solve inherently serial problems. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=3EWTEy9MTM. [38] Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, and Yue Zhang. Logical reasoning in large language models: survey. arXiv preprint arXiv:2502.09100, 2025. [39] Ziming Liu, Ouail Kitouni, Niklas Nolte, Eric Michaud, Max Tegmark, and Mike Williams. Towards understanding grokking: An effective theory of representation learning. Advances in Neural Information Processing Systems, 35:3465134663, 2022. [40] Andreas Madsen, Himabindu Lakkaraju, Siva Reddy, and Sarath Chandar. Interpretability needs new paradigm. arXiv preprint arXiv:2405.05386, 2024. [41] Samuel Marks and Max Tegmark. The geometry of truth: Emergent linear structure in large language model representations of true/false datasets. In First Conference on Language Modeling, 2024. URL https: //openreview.net/forum?id=aajyHYjjsk. [42] Karl Menger. Untersuchungen Ã¼ber allgemeine metrik. Mathematische Annalen, 100(1):75163, 1928. [43] William Merrill and Ashish Sabharwal. logic for expressing log-precision transformers. Advances in neural information processing systems, 36:5245352463, 2023. [44] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. In ICLR, 2013. [45] Gouki Minegishi, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa, and Yutaka Matsuo. Topology of reasoning: Understanding large reasoning models through reasoning graph properties. arXiv preprint arXiv:2506.05744, 2025. [46] Alexander Modell, Patrick Rubin-Delanchy, and Nick Whiteley. The origins of representation manifolds in large language models. arXiv preprint arXiv:2505.18235, 2025. 12 The Geometry of Reasoning: Flowing Logics in Representation Space [47] Terufumi Morishita, Gaku Morio, Atsuki Yamaguchi, and Yasuhiro Sogawa. Enhancing reasoning capabilities of llms via principled synthetic logic corpus. Advances in Neural Information Processing Systems, 37:7357273604, 2024. [48] Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. Progress measures for grokking via mechanistic interpretability. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=9XFSbDPmdW. [49] Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak, Jong Wook Kim, Chris Hallacy, et al. Text and code embeddings by contrastive pre-training. arXiv preprint arXiv:2201.10005, 2022. [50] Zhijie Nie, Zhangchi Feng, Mingxin Li, Cunwang Zhang, Yanzhao Zhang, Dingkun Long, and Richong Zhang. When text embedding meets large language model: comprehensive survey. arXiv preprint arXiv:2412.09165, 2024. [51] OpenAI. Introducing chatgpt. https://openai.com/index/chatgpt/, 2022. [52] OpenAI. Gpt-5 system card. Technical report, OpenAI, August 2025. [53] Core Francisco Park, Maya Okawa, Andrew Lee, Ekdeep Lubana, and Hidenori Tanaka. Emergence of hidden capabilities: Exploring learning dynamics in concept space. Advances in Neural Information Processing Systems, 37:8469884729, 2024. [54] Kiho Park, Yo Joong Choe, and Victor Veitch. The linear representation hypothesis and the geometry of large language models. In Forty-first International Conference on Machine Learning, 2024. URL https: //openreview.net/forum?id=UGpGkLzwpP. [55] Kiho Park, Yo Joong Choe, Yibo Jiang, and Victor Veitch. The geometry of categorical and hierarchical concepts in large language models. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=bVTM2QKYuA. [56] Mihir Parmar, Nisarg Patel, Neeraj Varshney, Mutsumi Nakamura, Man Luo, Santosh Mashetty, Arindam Mitra, and Chitta Baral. Logicbench: Towards systematic evaluation of logical reasoning ability of large language models. In 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024, pages 1367913707. Association for Computational Linguistics (ACL), 2024. [57] Francis Jeffry Pelletier and Allen Hazen. Natural Deduction Systems in Logic. In Edward N. Zalta and Uri Nodelman, editors, The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University, Spring 2024 edition, 2024. [58] Daking Rai, Yilun Zhou, Shi Feng, Abulhair Saparov, and Ziyu Yao. practical review of mechanistic interpretability for transformer-based language models. arXiv preprint arXiv:2407.02646, 2024. [59] John Rickard. concept geometry for conceptual spaces. Fuzzy optimization and decision making, 5: 311329, 2006. [60] Xuan Shen, Yizhou Wang, Xiangxi Shi, Yanzhi Wang, Pu Zhao, and Jiuxiang Gu. Efficient reasoning with hidden thinking. arXiv preprint arXiv:2501.19201, 2025. [61] Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, and Jianfeng Gao. Rethinking interpretability in the era of large language models. arXiv preprint arXiv:2402.01761, 2024. [62] Charlie Victor Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling LLM test-time compute optimally can be more effective than scaling parameters for reasoning. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=4FWAwZtd2n. The Geometry of Reasoning: Flowing Logics in Representation Space [63] Adam Stein, Aaditya Naik, Yinjun Wu, Mayur Naik, and Eric Wong. Towards compositionality in concept learning. In Forty-first International Conference on Machine Learning, 2024. URL https://openreview. net/forum?id=upO8FUwf92. [64] A. S. Troelstra and Helmut Schwichtenberg. Basic Proof Theory. Cambridge University Press, 2nd edition, 2000. [65] Lucrezia Valeriani, Diego Doimo, Francesca Cuturello, Alessandro Laio, Alessio Ansuini, and Alberto Cazzaniga. The geometry of hidden representations of large transformer models. Advances in Neural Information Processing Systems, 36:5123451252, 2023. [66] Constantin Venhoff, IvÃ¡n Arcuschin, Philip Torr, Arthur Conmy, and Neel Nanda. Understanding reasoning in thinking language models via steering vectors. In Workshop on Reasoning and Planning for Large Language Models, 2025. URL https://openreview.net/forum?id=OwhVWNOBcz. [67] Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan, Wenhu Chen, and William Yang Wang. Understanding reasoning ability of language models from the perspective of reasoning paths aggregation. In International Conference on Machine Learning, pages 5002650042. PMLR, 2024. [68] Yiming Wang, Pei Zhang, Baosong Yang, Derek Wong, Zhuosheng Zhang, and Rui Wang. Embedding trajectory for out-of-distribution detection in mathematical reasoning. Advances in Neural Information Processing Systems, 37:4296542999, 2024. [69] Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, and Rui Wang. Latent space chain-of-embedding enables output-free LLM self-evaluation. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=jxo70B9fQo. [70] Zihao Wang, Lin Gui, Jeffrey Negrea, and Victor Veitch. Concept algebra for (score-based) text-controlled generative models. Advances in Neural Information Processing Systems, 36:3533135349, 2023. [71] Orion Weller, Michael Boratko, Iftekhar Naim, and Jinhyuk Lee. On the theoretical limitations of embeddingbased retrieval. arXiv preprint arXiv:2508.21038, 2025. [72] Ludwig Wittgenstein. Tractatus Logico-Philosophicus. Kegan Paul, Trench, Trubner & Co., Ltd., London, 1922. [73] Yuyang Wu, Yifei Wang, Ziyu Ye, Tianqi Du, Stefanie Jegelka, and Yisen Wang. When more is less: Understanding chain-of-thought length in llms. arXiv preprint arXiv:2502.07266, 2025. [74] Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, and Kedar Namjoshi. Can large language models learn formal logic? data-driven training and evaluation framework. arXiv preprint arXiv:2504.20213, 2025. [75] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. [76] Andy Yang and David Chiang. Counting like transformers: Compiling temporal counting logic into softmax transformers. In First Conference on Language Modeling, 2024. URL https://openreview.net/forum? id=FmhPg4UJ9K. [77] Junjie Yao, Zhongwang Zhang, and Zhi-Qin John Xu. An analysis for reasoning bias of language models with small initialization. In Forty-second International Conference on Machine Learning, 2025. URL https: //openreview.net/forum?id=4HQaMUYWAT. [78] Tian Ye, Zicheng Xu, Yuanzhi Li, and Zeyuan Allen-Zhu. Physics of language models: Part 2.1, grade-school math and the hidden reasoning process. In The Thirteenth International Conference on Learning Representations, 2025. The Geometry of Reasoning: Flowing Logics in Representation Space [79] Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, et al. Qwen3 embedding: Advancing text embedding and reranking through foundation models. arXiv preprint arXiv:2506.05176, 2025. [80] Zhen Zhang, Xuehai He, Weixiang Yan, Ao Shen, Chenyang Zhao, Shuohang Wang, Yelong Shen, and Xin Eric Wang. Soft thinking: Unlocking the reasoning potential of llms in continuous concept space. arXiv preprint arXiv:2505.15778, 2025. [81] Ziqian Zhong, Ziming Liu, Max Tegmark, and Jacob Andreas. The clock and the pizza: Two stories in mechanistic explanation of neural networks. Advances in neural information processing systems, 36:27223 27250, 2023. [82] Hanlin Zhu, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, and Yuandong Tian. Reasoning by superposition: theoretical perspective on chain of continuous thought. arXiv preprint arXiv:2505.12514, 2025. The Geometry of Reasoning: Flowing Logics in Representation Space"
        },
        {
            "title": "3 Preliminaries",
            "content": "3.1 Large Language Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Menger Curvature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
        },
        {
            "title": "4 Reasoning as Geometric Flows in Representation Space",
            "content": "4.1 Concept Space and Semantic Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Representation Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Logic as Differential Constraints on Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Formal Logic with Semantic Carriers 5.1 Logic and Natural Deduction System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2 Data Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Play with LLMs 6.1 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.2 Results Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Discussion 8 Conclusion Additional Experiments Symbolic Glossary and Mapping Relations B.1 Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.2 Primary maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.3 Reasoning increments and curvature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.4 Roadmap diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Geometric Foundations of Reasoning Trajectories C.1 Continuity of Representation Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.2 Menger Curvature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Data Generation 1 3 4 4 4 5 5 7 7 8 8 8 9 10 18 18 18 20 20 20 21 23 16 The Geometry of Reasoning: Flowing Logics in Representation Space D.1 Prompts for Data Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.2 Data Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 17 The Geometry of Reasoning: Flowing Logics in Representation Space"
        },
        {
            "title": "Appendix",
            "content": "A. Additional Experiments We additionally evaluate LLaMA3 [19] and more Qwen3 [75] models (1.7B, 4B) to test robustness under the same experimental settings as in Section 6. The results (Figures 3, 4 and 5) confirm that our findings generalize across model sizes and families. (a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity. Figure 3: Similarity of reasoning flows on Qwen3 1.7B. (a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity. Figure 4: Similarity of reasoning flows on Qwen3 4B. B. Symbolic Glossary and Mapping Relations This section is standalone roadmap that summarizes the spaces, maps, and commutative structure underlying our geometric view of reasoning. B.1. Spaces Input space ğ’³ (often specialized to vocabulary ğ’±): discrete tokens/sentences. 18 The Geometry of Reasoning: Flowing Logics in Representation Space (a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity. Figure 5: Similarity of reasoning flows on Llama3 8B. Concept space ğ’: abstract semantic space. sentence ğ‘‹ is represented by smooth semantic trajectory where â„³ is semantic submanifold for coherent domain of meaning. Representation space â„› Rğ‘‘: the models embedding space. Each prefix ğ‘‹ğ‘¡ yields ğ›¾ğ‘‹ : [0, 1] â„³ ğ’, ğ‘¦ğ‘¡ = Î¨(ğ‘‹ğ‘¡) Rğ‘‘, sampling continuous representation trajectory Î¨ : [0, 1] Rğ‘‘. Formal logical space â„’form: symbolic/human logic governed by natural deduction system ND = (â„±, â„›), with formulas â„± and rules â„›. Judgements Î“ ğœ™ and rule-based derivations live here. Representation-based logical space â„’rep: the space of reasoning increments in the embedding space, defined by local variations of the trajectory, ğ‘¦ğ‘¡ := ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡. Geometric descriptors such as the Menger curvature ğœ…ğ‘¡ are evaluated here. This space is non-symbolic, and serves as the models internal analogue of logic. B.2. Primary maps Semantic interpretation: Neural representation: Î“ : ğ’³ Curves(ğ’), ğ‘‹ ğ›¾ğ‘‹ . Î¨ : ğ’³ Curves(â„›), realized by token embeddings â„° and contextual encoder Î¦, producing the continuous trajectory Î¨ and sampled states ğ‘Œ = (ğ‘¦1, . . . , ğ‘¦ğ‘‡ ). Canonical Alignment. Definition B.1 (Canonical alignment map). Assume ğ‘† and Î¨ are injective on the domain of interest. Define ğ´ := Î¨ Î“1 : Curves(ğ’) Curves(â„›). Then ğ´ is bijection between semantic curves and representation trajectories, and the top-level diagram commutes exactly: ğ´ Î“ = Î¨. The Geometry of Reasoning: Flowing Logics in Representation Space Flow vs. differential to logic. We distinguish human flow operator on concepts from differential operator on representations: ğ¹ğ’ : ğ›¾ (human reasoning flow in ğ’) â„’form, ğ·â„› : Î¨ (ğ‘¦ğ‘¡) â„’rep. The left operator ğ¹ğ’ is not discrete difference; it encodes how semantic trajectory induces formal reasoning steps under ND. The right operator ğ·â„› extracts local increments from the representation trajectory. B.3. Reasoning increments and curvature Formal side (concepts). Human reasoning flow is captured at the semantic level by ğ¹ğ’, which maps semantic curve ğ›¾ into sequence of formally valid steps in â„’form per the rules ND. Representation side (vectors). The local increment ğ‘¦ğ‘¡ = ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡ encodes step of representation flow in â„’rep. Curvature as geometric intensity. For three consecutive states (ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦ğ‘¡+1), the Menger curvature 21 CosSim(ğ‘¢, ğ‘£)2 ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡1 ğ‘¢ := ğ‘¦ğ‘¡ ğ‘¦ğ‘¡1, ğ‘£ := ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡, ğœ…ğ‘¡ = ğ‘ğ‘€ (ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦ğ‘¡+1) = , couples angular change with scale, providing geometry-aware proxy for the strength of reasoning step in the representation. B.4. Roadmap diagram The overall structure can be read from the commutative roadmap below. Here ğ’³ sits at the center; semantic and representation curves live to the left and right; formal and representation-based logics sit below. The top arrow is strict by definition of ğ´; the vertical arrows express how each curve induces its respective notion of reasoning. ğ’³ Î“ Î¨ Curves(ğ’) ğ´=Î¨Î“1 Curves(â„›) ğ¹ğ’ â„’form ğ·â„› â„’rep (1) Input sequences branch into semantic curve (left) and representation curve (right). (2) Reading guide. The canonical alignment ğ´ = Î¨ ğ‘†1 identifies the two curves one-to-one. (3) The semantic curve induces human, rule-constrained steps in â„’form via ğ¹ğ’, while the representation curve induces vector increments in â„’rep via ğ·â„›. (4) Curvature in â„’rep quantifies the geometric intensity of reasoning transitions and can be related back to formal steps under appropriate correspondences established elsewhere in the paper. C. Geometric Foundations of Reasoning Trajectories In this section, we establish the geometric foundations for analyzing reasoning as smooth flows in representation space. We first construct representation trajectories as ğ¶ 1 curves via relaxed prefix-mask mechanism, thereby justifying smoothness as working principle. Then, we introduce Menger curvature as computable descriptor that couples angular deviation with distance variation, providing principled measure of the intensity of reasoning turns. 20 The Geometry of Reasoning: Flowing Logics in Representation Space C.1. Continuity of Representation Trajectories In this section, we provide rigorous and explicit construction of ğ¶ 1 trajectory using relaxed prefix-mask mechanism. This construction justifies our working assumption that representation trajectories are ğ¶ 1. Note that the symbol â„ (Definition 3.2) is defined with slight variation compared to main paper: here it is specialized to encode positional information, while the remaining complexities of the model architecture are subsumed into single mapping Î¦. Definition C.1 (Neural Encoding View of Sentence Representation). Let ğ‘¥ = (ğ‘¢1, . . . , ğ‘¢ğ‘›) be sentence with tokens ğ‘¢ğ‘– drawn from vocabulary space ğ’±. Define an embedding map â„° : ğ’± Rğ‘‘, ğ‘¢ğ‘– â„°(ğ‘¢ğ‘–), which assigns each token ğ‘‘-dimensional vector. Augmenting â„°(ğ‘¢ğ‘–) with positional information yields the input sequence ğ‘§0 = (â„°(ğ‘¢1), â„°(ğ‘¢2), . . . , â„°(ğ‘¢ğ‘›)) (Rğ‘‘)ğ‘›. Let Î¦ : (Rğ‘‘)ğ‘› â„ Rğ‘‘ denote contextual encoder that maps sequence of token embeddings together with positional information to global sentence-level representation, where â„ is the positional encoding space and â„ğ‘› â„ denotes the set of encodings for the first ğ‘› positions. For fixed ğœ„ = (ğœ„1, . . . , ğœ„ğ‘›) â„ğ‘›, we define Î¨(ğ‘¥) := Î¦(ğ‘§0, ğœ„ğ‘› ) = Î¦(â„°(ğ‘¢1), . . . , â„°(ğ‘¢ğ‘›), ğœ„) Rğ‘‘. In this view, Î¨ subsumes both the static token embeddings and the contextual transformations carried out by the neural network. Hence the hidden state ğ‘¦ğ‘¡ = Î¨(ğ‘†ğ‘¡) in Definition 4.5 should be interpreted not merely as sum of embeddings, but as the outcome of the full encoding process applied to the prefix ğ‘†ğ‘¡. Mask-aware realization (for later use). Fix maximum length ğ‘ ğ‘› and consider the mask-aware realization of the same encoder, Î¦ğ‘š : (Rğ‘‘)ğ‘ â„ğ‘ {0, 1}ğ‘ Rğ‘‘, such that for any length ğ‘› ğ‘ , Î¦ğ‘š ((â„°(ğ‘¢1), . . . , â„°(ğ‘¢ğ‘›), 0, . . . , 0, ğœ„), 1{ğ‘–ğ‘›} ) := Î¦(â„°(ğ‘¢1), . . . , â„°(ğ‘¢ğ‘›), (1{ğ‘–ğ‘›}ğœ„ğ‘–)ğ‘ ğ‘–= ). When the mask is all ones on {1, . . . , ğ‘›}, this coincides with the above definition; when we pass mask explicitly we will write Î¦(, ğ‘€ ). Hypothesis C.2 (Smooth Trajectory Hypothesis). The sequence of representations ğ‘¦ğ‘¡ = Î¨(ğ‘‹ğ‘¡) generated during reasoning process lies on smooth, differentiable trajectory in the embedding space. Definition C.3 (Relaxed-Mask Sentence Representation). Let each sentence in Hypothesis 4.4 be ğ‘¥ğ‘¡ = (ğ‘¢ğ‘¡,1, . . . , ğ‘¢ğ‘¡,ğ‘›ğ‘¡) for ğ‘¡ = 1, . . . , ğ‘‡ , and let the full token stream be ğ‘ˆ1:ğ‘ = (ğ‘¢1,1, . . . , ğ‘¢1,ğ‘›1 , ğ‘¢2,1, . . . , ğ‘¢2,ğ‘›2, . . . , ğ‘¢ğ‘‡,1, . . . , ğ‘¢ğ‘‡,ğ‘›ğ‘‡ ), with total length ğ‘ = ğ‘‡ ğ‘  [0, 1] and relaxed prefix mask ğ‘¡=1 ğ‘›ğ‘¡ and cumulative lengths ğ‘ğ‘¡ = ğ‘¡ ğ‘—=1 ğ‘›ğ‘—. Introduce continuous progress parameter which specifies the fractional inclusion of each token at progress ğ‘ . ğ‘šğ‘  : {1, . . . , ğ‘ } [0, 1], Using the embedding map â„° and positional information â„ğ‘ from Definition C.1, define the masked input sequence at progress ğ‘  by ğ‘§ğ‘  = (ğ‘šğ‘ (ğ‘–) â„°(ğ‘¢ğ‘–))ğ‘ ğ‘–=1, ğœ„ğ‘  = (ğ‘šğ‘ (ğ‘–) ğœ„ğ‘– )ğ‘ ğ‘–=1. 21 The Geometry of Reasoning: Flowing Logics in Representation Space and the associated hard mask ğ‘€ğ‘ (ğ‘–) := 1{ğ‘šğ‘ (ğ‘–)=1}, ğ‘– = 1, . . . , ğ‘. Let ğ‘˜(ğ‘ ) := ğ‘ ğ‘ , denote the number of tokens included at progress ğ‘ . The truncated masked sequences are then defined as ğ‘§(ğ‘˜) ğ‘  := (ğ‘§ğ‘ (1), . . . , ğ‘§ğ‘ (ğ‘˜(ğ‘ ))) (Rğ‘‘)ğ‘˜(ğ‘ ), ğœ„ğ‘ ,(ğ‘˜) := (ğœ„ğ‘ (1), . . . , ğœ„ğ‘ (ğ‘˜(ğ‘ ))) â„ ğ‘˜(ğ‘ ). With the mask-aware encoder Î¦ğ‘š : (Rğ‘‘)ğ‘ â„ ğ‘ {0, 1}ğ‘ Rğ‘‘ introduced above, the continuous representation trajectory is defined by Î¨(ğ‘ ) := Î¦ğ‘š(ğ‘§ğ‘ , ğœ„ğ‘ , ğ‘€ğ‘ ) Rğ‘‘, where Î¦ğ‘š(ğ‘§ğ‘ , ğœ„ğ‘ , ğ‘€ğ‘ ) := Î¦(ğ‘§(ğ‘˜) ğ‘  , ğœ„ğ‘ ,(ğ‘˜)). At sentence boundaries ğ‘ ğ‘¡ := ğ‘ğ‘¡/ğ‘ , the hard prefix mask is recovered exactly by choosing smooth function with flat tails (see Proposition C.4); consequently, Proposition C.4 (Continuity of the Relaxed-Mask Trajectory). Suppose the relaxed mask takes the form ğ‘¦ğ‘¡ = Î¨(ğ‘†ğ‘¡) = Î¦(ğ‘§ğ‘ ğ‘¡, ğœ„ğ‘ ğ‘¡, ğ‘€ğ‘ ğ‘¡ ) = Î¨(ğ‘ ğ‘¡), ğ‘¡ = 1, . . . , ğ‘‡. ğ‘šğ‘ (ğ‘–) = ğ‘”(ğ‘ ğ‘ ğ‘–), where ğ‘” ğ¶(R) satisfies ğ‘”(ğ‘¥) = 0 for ğ‘¥ ğ›¿, ğ‘”(ğ‘¥) = 1 for ğ‘¥ ğ›¿, with some 0 < ğ›¿ < 1 (i.e., smoothstep/bump 2 with flat tails). Assume the encoder Î¦ is ğ¶ 1. Then the mapping Î¨ : [0, 1] Rğ‘‘ defines ğ¶ 1 trajectory in embedding space. Moreover, the discrete sentence embeddings (ğ‘¦ğ‘¡)ğ‘‡ are exactly samples of this trajectory at ğ‘ ğ‘¡ = ğ‘ğ‘¡/ğ‘ : ğ‘¡=1 Proof. For each token ğ‘ˆğ‘–, we define the masked embedding and positional encoding as ğ‘¦ğ‘¡ = Î¨(ğ‘ ğ‘¡), ğ‘¡ = 1, . . . , ğ‘‡. (ğ‘§ğ‘ (ğ‘–), ğœ„ğ‘ (ğ‘–)) = ğ‘šğ‘ (ğ‘–) (â„°(ğ‘ˆğ‘–), ğœ„ğ‘– ) = ğ‘”(ğ‘ ğ‘ ğ‘–) (â„°(ğ‘ˆğ‘–), ğœ„ğ‘– ). Since ğ‘” is ğ¶ and both â„°(ğ‘ˆğ‘–) and ğœ„ğ‘– are constant in ğ‘ , each coordinate pair (ğ‘§ğ‘ (ğ‘–), ğœ„ğ‘ (ğ‘–)) varies smoothly with ğ‘ . Hence the entire masked sequence (ğ‘§ğ‘ , ğœ„ğ‘ ) = (ğ‘§ğ‘ (1), . . . , ğ‘§ğ‘ (ğ‘ ); ğœ„ğ‘ (1), . . . , ğœ„ğ‘ (ğ‘ )) is smooth trajectory with respect to ğ‘ . The mask ğ‘€ğ‘ (ğ‘–) = 1{ğ‘šğ‘ (ğ‘–)=1} is piecewise constant in ğ‘  and equals the all-ones indicator on indices where ğ‘ ğ‘ ğ‘– ğ›¿, and zeros where ğ‘ ğ‘ ğ‘– ğ›¿; in particular, it is locally constant on neighborhoods that avoid the transition band ğ‘ ğ‘ ğ‘– < ğ›¿. By assumption, Î¦ is composition of affine maps, matrix multiplications, LayerNorm, residual connections, softmax attention, and smooth pointwise nonlinearities. As function of its inputs, such network is smooth; thus, on any interval where ğ‘€ğ‘  is fixed, the composite map is ğ¶ 1 by the chain rule. Î¨(ğ‘ ) = Î¦(ğ‘§ğ‘ , ğœ„ğ‘ , ğ‘€ğ‘  ) At sentence boundaries ğ‘ ğ‘¡ = ğ‘ğ‘¡/ğ‘ , choose ğ›¿ < 1 2 so that ğ‘”(ğ‘ğ‘¡ ğ‘–) = 1 for ğ‘– ğ‘ğ‘¡ and ğ‘”(ğ‘ğ‘¡ ğ‘–) = 0 for ğ‘– ğ‘ğ‘¡ + 1. Hence ğ‘šğ‘ ğ‘¡(ğ‘–) {0, 1} exactly and ğ‘€ğ‘ ğ‘¡(ğ‘–) = 1{ğ‘–ğ‘ğ‘¡}. Substituting into the definition, Î¨(ğ‘ ğ‘¡) = Î¦((â„°(ğ‘ˆ1), . . . , â„°(ğ‘ˆğ‘ğ‘¡), 0, . . . , 0, ğœ„), 1{ğ‘–ğ‘ğ‘¡} ) = Î¨(ğ‘†ğ‘¡) = ğ‘¦ğ‘¡, which shows that the discrete embeddings (ğ‘¦ğ‘¡)ğ‘‡ ğ‘¡= are precisely samples of the continuous trajectory Î¨(ğ‘ ). 22 The Geometry of Reasoning: Flowing Logics in Representation Space Remark C.5. Since Î¦() implemented with affine maps, matrix multiplications, LayerNorm, residual connections, softmax attention, and smooth pointwise nonlinearities (e.g., GELU/SiLU/Swish), its reasonable to assume that is ğ¶ 1. If ReLU activations (or other piecewise smooth nonlinearities) are used instead of smooth ones, the mapping Î¨ remains continuous and is differentiable almost everywhere. Since this does not affect the manifold-level geometric reasoning, we idealize Î¦ as smooth throughout our discussion. The construction above is merely one possible realization of continuous and ğ¶ 1 trajectory Î¨(ğ‘ ). In fact, many alternative constructions are possible. This abundance of realizations justifies our assumption that the sentence Î¨(ğ‘‹ğ‘‡ ), through its step-by-step variations, can be viewed as ğ‘‡ points lying on smooth, differentiable curve. On this basis, we can consistently define the notion of flow velocity in Definition 4.9. C.2. Menger Curvature Definition C.6 (Menger Curvature). Let ğ‘¥1, ğ‘¥2, ğ‘¥3 Rğ‘› be three distinct points. The Menger curvature of the triple (ğ‘¥1, ğ‘¥2, ğ‘¥3) is defined as the reciprocal of the radius ğ‘…(ğ‘¥1, ğ‘¥2, ğ‘¥3) of the unique circle passing through the three points: ğ‘(ğ‘¥1, ğ‘¥2, ğ‘¥3) = 1 ğ‘…(ğ‘¥1, ğ‘¥2, ğ‘¥3) . Proposition C.7 (Computation Formula). Let ğ‘ = ğ‘¥2 ğ‘¥3, ğ‘ = ğ‘¥1 ğ‘¥3, and ğ‘ = ğ‘¥1 ğ‘¥2. Denote by (ğ‘¥1, ğ‘¥2, ğ‘¥3) the area of the triangle spanned by the three points. Then the circumradius ğ‘… and the Menger curvature ğ‘(ğ‘¥1, ğ‘¥2, ğ‘¥3) are given by ğ‘…(ğ‘¥1, ğ‘¥2, ğ‘¥3) = ğ‘ğ‘ğ‘ 4(ğ‘¥1, ğ‘¥2, ğ‘¥3) , ğ‘(ğ‘¥1, ğ‘¥2, ğ‘¥3) = 4(ğ‘¥1, ğ‘¥2, ğ‘¥3) ğ‘ğ‘ğ‘ . Proof. The formula follows from classical Euclidean geometry: for triangle with side lengths ğ‘, ğ‘, ğ‘ and area , the circumradius satisfies ğ‘… = ğ‘ğ‘ğ‘ 4Î” . Taking the reciprocal yields the Menger curvature. ğ‘¥2 Center ğ‘… ğ‘¥1 ğ‘¥ Figure 6: Circumcircle through three points ğ‘¥1, ğ‘¥2, ğ‘¥3, with radius ğ‘… and Menger curvature 1/ğ‘…. Proposition C.8 (Menger curvature from three consecutive states). Let ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦ğ‘¡+1 Rğ‘‘ be three distinct points and set Write the side lengths ğ‘¢ := ğ‘¦ğ‘¡ ğ‘¦ğ‘¡1, ğ‘£ := ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡. ğ‘ = ğ‘¢, ğ‘ = ğ‘£, ğ‘ = ğ‘£ ğ‘¢ = ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡1. 23 The Geometry of Reasoning: Flowing Logics in Representation Space Center ğ‘… Center ğ‘… ğ‘¦(2) ğ‘¡+1 ğ‘¦(1) ğ‘¡+1 ğ‘¦ğ‘¡1 ğ‘¦ğ‘¡ Figure 7: Two circumcircles through {ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦(1) lie on the same ray from ğ‘¦ğ‘¡. ğ‘¡+1} and {ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦(2) ğ‘¡+1}, with radii ğ‘… and ğ‘…. Here ğ‘¦(1) ğ‘¡+1 and ğ‘¦(2) ğ‘¡+1 The Menger curvature of the triple (ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦ğ‘¡+1) equals ğ‘ğ‘€ (ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦ğ‘¡+1) = 4 (ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦ğ‘¡+1) ğ‘ğ‘ğ‘ = 21 CosSim(ğ‘¢, ğ‘£)2 ğ‘¦ğ‘¡+1 ğ‘¦ğ‘¡1 , where CosSim(ğ‘¢, ğ‘£) := ğ‘¢, ğ‘£ ğ‘¢ ğ‘£ . (If the three points are collinear, ğ‘ğ‘€ := 0.) Proof. By classical Euclidean geometry, for triangle with side lengths ğ‘, ğ‘, ğ‘ and area , the circumradius satisfies ğ‘… = ğ‘ğ‘ğ‘ 4 . The Menger curvature is the reciprocal ğ‘ğ‘€ = 1/ğ‘… = 4 ğ‘ğ‘ğ‘ . It remains to express in terms of ğ‘¢ and ğ‘£. The (unsigned) area of the triangle spanned by ğ‘¢ and ğ‘£ can be written in dimension-independent way via the Gram determinant: = 1 ğ‘¢ ğ‘£ = 1 2 det (ğ‘¢, ğ‘¢ ğ‘£, ğ‘¢ ) ğ‘¢, ğ‘£ ğ‘£, ğ‘£ = 1 2 ğ‘¢2ğ‘£2 ğ‘¢, ğ‘£2. Substituting ğ‘ = ğ‘¢, ğ‘ = ğ‘£, ğ‘ = ğ‘£ ğ‘¢ into ğ‘ğ‘€ = gives 4 ğ‘ğ‘ğ‘ 2ğ‘¢2ğ‘£2 ğ‘¢, ğ‘£2 ğ‘¢ ğ‘£ ğ‘£ ğ‘¢ . ğ‘ğ‘€ = Divide the numerator and denominator by ğ‘¢ ğ‘£ and denote ğ‘  := CosSim(ğ‘¢, ğ‘£) = ğ‘¢, ğ‘£ ğ‘¢ ğ‘£ . Then 24 The Geometry of Reasoning: Flowing Logics in Representation Space ğ‘ğ‘€ = 1 ğ‘ 2 2 ğ‘£ ğ‘¢ = 2 sin ğœƒ ğ‘ , where ğœƒ is the angle between ğ‘¢ and ğ‘£ (so sin ğœƒ = 1 ğ‘ 2). If the three points are collinear, = 0 and hence ğ‘ğ‘€ = 0, consistent with the convention. This proves the claim. Remark C.9. As illustrated in Figure 7, using the Menger curvature instead of cosine similarity is significant. Cosine similarity only depends on the angle at ğ‘¦ğ‘¡, so the two triples {ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦(1) ğ‘¡+1} would look identical. In contrast, their circumradii ğ‘… and ğ‘… are different, hence the Menger curvatures distinguish two different curvature regimes. This demonstrates how Menger curvature captures both angle and length information, enabling discrimination that cosine similarity alone cannot provide. ğ‘¡+1} and {ğ‘¦ğ‘¡1, ğ‘¦ğ‘¡, ğ‘¦(2) 25 The Geometry of Reasoning: Flowing Logics in Representation Space D. Data Generation We provide the exact prompt templates and the representative sampled data instances used in our data generation process. The two-stage pipeline is run with GPT-5. D.1. Prompts for Data Generation The following prompts are used for abstract logical templates construction and domain-specific and language-specific rewriting. Prompt for Logic Pattern Generation You are formal logic pattern generator. Goal: Create an abstract, domain-agnostic reasoning sequence of exactly steps, written in symbolic form, using standard propositional/first-order logic notation. Strict output format: Exactly lines, each line starts with bracketed index and single formula or conclusion, e.g.: [1] -> [2] -> [3] -> [4] (D & E) -> [5] forall x(H(x) -> J(x)) [6] [7] [8] H(a) [9] (from [1-3] and [6]) [10] & J(a) (from [4],[7],[5],[8],[9]) Use only symbols from: , , , , , , , parentheses, predicate letters with uppercase (A,B,C,. . . ) and predicate symbols like H(x), J(x). You may include brief justifications at the end of lines in parentheses referencing earlier step indices (e.g., (from [2] and [5])). The sequence must be internally coherent (later steps can be derived from earlier ones), but no proof of fixed target is required. No extra commentary before or after the lines. No natural-language sentences. Parameters (provided by caller): N: number of steps to output. logic: label for this abstract logic (optional). = {N} logic = {logic} Now produce exactly lines. 26 The Geometry of Reasoning: Flowing Logics in Representation Space Prompt for Reasoning Rewriter You are reasoning rewriter. Task: Given an abstract N-step reasoning scaffold (formal symbolic lines) and target topic, rewrite the scaffold into topic-specific natural-language reasoning sequence with exactly the same number of steps and the same dependency structure. Inputs (provided by caller): Topic: the target domain (e.g., weather, software). Abstract Steps (1..N): the neutral scaffold, numbered 1..N. N: the total number of steps. Output requirements: Produce exactly steps, each line begins with the same bracketed index as the abstract: [1] ... to [N] .... Keep step count and ordering identical to the abstract. Do not merge, split, add, or remove steps. Preserve the logical dependencies: if abstract step enables k+1, your rewrite must preserve that relationship in the topic. Use concrete domain terms appropriate to the topic, but keep sentences concise and precise. No extra commentary before or after the steps. Multilingual mode (when Languages: are specified by the caller): Create separate section for each requested language code. Each section starts with header line === <code> === (e.g., === en ===). Under each header, write the steps with bracketed indices [1] .. Keep the content aligned across languages (same meaning per step index). [N] in that language. Inputs you will receive: Topic: {topic} Abstract Steps (1..N): {ABSTRACT_STEPS} = {N} Now perform the rewrite. D.2. Data Examples Table 2 presents 9-step logical scaffold from our dataset. We illustrate its instantiation in two distinct domains, weather and finance, providing the corresponding statements in both English (EN) and German (DE). 27 The Geometry of Reasoning: Flowing Logics in Representation Space Table 2: Logic Example (9-Step) with Weather and Finance Topics in English and German Abstract Logic [1] ğ´ ğµ [2] ğµ ğ¶ Topic: Weather EN: If moisture converges over the city, then thunderclouds develop. DE: Wenn Ã¼ber der Stadt Feuchte konvergiert, dann bilden sich Gewitterwolken. EN: If thunderclouds develop, then heavy rain occurs. DE: Wenn sich Gewitterwolken bilden, dann tritt starker Regen auf. [3] ğ‘¥(ğ»(ğ‘¥) ğ½(ğ‘¥)) EN: For any location x, if cold front passes x, then temperatures drop at x. DE: FÃ¼r jeden Ort gilt: Wenn eine Kaltfront Ã¼berquert, dann sinkt dort die Temperatur. Topic: Finance EN: If the firms interest coverage ratio exceeds 3.0x, then the firm is deemed able to meet interest obligations. DE: Wenn die Zinsdeckungskennzahl des Unternehmens Ã¼ber 3,0x liegt, dann gilt das Unternehmen als fÃ¤hig, Zinszahlungen zu leisten. EN: If the firm is deemed able to meet interest obligations, then the bank will approve new term loan. DE: Wenn das Unternehmen als fÃ¤hig gilt, Zinszahlungen zu leisten, dann wird die Bank ein neues Laufzeitdarlehen genehmigen. EN: For any security x, if is U.S. Treasury, then is acceptable as repo collateral. DE: FÃ¼r jedes Wertpapier gilt: Wenn eine US-Staatsanleihe ist, dann ist als Repo-Sicherheit zulÃ¤ssig. [4] ğ»(ğ‘) [5] ğ´ EN: cold front is passing the airport. DE: Eine Kaltfront Ã¼berquert den Flughafen. EN: Moisture is converging over the city. DE: Ãœber der Stadt herrscht Feuchtekonvergenz. EN: Bond is U.S. Treasury. DE: Anleihe ist eine US-Staatsanleihe. EN: The firms interest coverage ratio exceeds 3.0x. DE: Die Zinsdeckungskennzahl des Unternehmens liegt Ã¼ber 3,0x. [6] ğµ (from [1], [5]) EN: From [1] and [5], thunderclouds develop. DE: Aus [1] und [5] folgt, dass sich Gewitterwolken bilden. EN: The firm is deemed able to meet interest obligations (from [1] and [5]). DE: Daher gilt das Unternehmen als fÃ¤hig, Zinszahlungen zu leisten (aus [1] und [5]). [7] ğ¶ (from [2], [6]) EN: From [2] and [6], heavy rain occurs. DE: Aus [2] und [6] folgt, dass starker Regen auftritt. [8] ğ½(ğ‘) (from [3], [4]) EN: From [3] and [4], temperatures drop at the airport. DE: Aus [3] und [4] folgt, dass am Flughafen die Temperatur sinkt. EN: The bank will approve new term loan (from [2] and [6]). DE: Daher wird die Bank ein neues Laufzeitdarlehen genehmigen (aus [2] und [6]). EN: Bond is acceptable as repo collateral (from [3] and [4]). DE: Daher ist Anleihe als Repo-Sicherheit zulÃ¤ssig (aus [3] und [4]). [9] ğ¶ ğ½(ğ‘) (from [7], [8]) EN: From [7] and [8], heavy rain occurs and temperatures drop at the airport. DE: Aus [7] und [8] folgt: Es tritt starker Regen auf und am Flughafen sinkt die Temperatur. EN: The bank will approve new term loan and Bond is acceptable as repo collateral (from [7] and [8]). DE: Somit wird die Bank ein neues Laufzeitdarlehen genehmigen und Anleihe ist als Repo-Sicherheit zulÃ¤ssig (aus [7] und [8])."
        }
    ],
    "affiliations": [
        "Duke University"
    ]
}