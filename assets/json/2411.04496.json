{
    "paper_title": "Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model",
    "authors": [
        "Young-Jun Lee",
        "Dokyong Lee",
        "Junyoung Youn",
        "Kyeongjin Oh",
        "Ho-Jin Choi"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "To increase social bonding with interlocutors, humans naturally acquire the ability to respond appropriately in a given situation by considering which conversational skill is most suitable for the response - a process we call skill-of-mind. For large language model (LLM)-based conversational agents, planning appropriate conversational skills, as humans do, is challenging due to the complexity of social dialogue, especially in interactive scenarios. To address this, we propose a skill-of-mind-annotated conversation dataset, named Multifaceted Skill-of-Mind, which includes multi-turn and multifaceted conversational skills across various interactive scenarios (e.g., long-term, counseling, task-oriented), grounded in diverse social contexts (e.g., demographics, persona, rules of thumb). This dataset consists of roughly 100K conversations. Using this dataset, we introduce a new family of skill-of-mind-infused LLMs, named Thanos, with model sizes of 1B, 3B, and 8B parameters. With extensive experiments, these models successfully demonstrate the skill-of-mind process and exhibit strong generalizability in inferring multifaceted skills across a variety of domains. Moreover, we show that Thanos significantly enhances the quality of responses generated by LLM-based conversational agents and promotes prosocial behavior in human evaluations."
        },
        {
            "title": "Start",
            "content": "THANOS : Enhancing Conversational Agents with Skill-of-Mind-Infused"
        },
        {
            "title": "Large Language Model",
            "content": "Young-Jun Lee 1 Dokyong Lee 2 Junyoung Youn 2 Kyeongjin Oh 2 Ho-Jin Choi"
        },
        {
            "title": "2 KT Corporation",
            "content": "{yj2961, hojinc}@kaist.ac.kr {dokyong.lee, junyoung.youn, kyeong-jin.oh}@kt.com 4 2 0 2 7 ] . [ 1 6 9 4 4 0 . 1 1 4 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "To increase social bonding with interlocutors, humans naturally acquire the ability to respond appropriately in given situation by considering which conversational skill is most suitable for the response process we call skill-of-mind 1. For large language model (LLM)-based conversational agents, planning appropriate conversational skills, as humans do, is challenging due to the complexity of social dialogue, especially in interactive scenarios. To address this, we propose skill-ofmind-annotated conversation dataset, named MULTIFACETED SKILL-OF-MIND, which includes multi-turn and multifaceted conversational skills across various interactive scenarios (e.g., long-term, counseling, task-oriented), grounded in diverse social contexts (e.g., demographics, persona, rules of thumb). This dataset consists of roughly 100K conversations. Using this dataset, we introduce new family of skill-of-mind-infused LLMs, named THANOS , with model sizes of 1B, 3B, and 8B parameters. With extensive experiments, these models successfully demonstrate the skillof-mind process and exhibit strong generalizability in inferring multifaceted skills across variety of domains. Moreover, we show that THANOS significantly enhances the quality of responses generated by LLM-based conversational agents and promotes prosocial behavior in human evaluations. Code: https: //github.com/passing2961/Thanos."
        },
        {
            "title": "Introduction",
            "content": "In everyday conversations, humans engage in diverse and complex interactions with their interlocutors (e.g., friends, colleagues) by understanding and 1We derive the term skill-of-mind from theory of mind (Premack and Woodruff, 1978), which refers to the ability to understand and infer others mental states, intentions, and beliefs from situational descriptions (e.g., narratives). Skill-of-mind refers to interpreting/understanding the current conversational context based on social dynamics (e.g., demographics, persona) and optimizing social interaction through conversational skills. Figure 1: An overview of skill-of-mind process. interpreting their interlocutors situations (Rashkin, 2018; Lee et al., 2022a) and personas (Zhang, 2018; Lee et al., 2022b), and by recalling memorable events or moments (Bae et al., 2022a; Jang et al., 2023; Lee et al., 2024d). Humans do not always know the most appropriate response for every turn in multi-turn conversation. Instead, they learn to choose suitable responses by internally considering the most appropriate conversational skills at that moment, based on the interlocutor and social context over time. As illustrated in Figure 1, for example, humans reflect on which skill to use for the next turn by internally reasoning about which skill would be most appropriate. This process evolves through self-reflection and feedback, as people assess the positive or negative reactions of their interlocutors. We refer to this entire process as skill-ofmind, which involves interpreting and understanding the current dialogue situation, planning the best skill strategy for the next response, and then selecting the most appropriate conversational skill. Recently, conversational agents powered by LLMs (Touvron et al., 2023; AI@Meta, 2024; Team et al., 2024) have demonstrated impressive capabilities in logical reasoning (Pan et al., 2023) and creativity (Franceschelli and Musolesi, 2023). However, these agents still struggle with social commonsense reasoning (Chae et al., 2023) and strategic communication skills in an interactive environment (Zhou et al., 2023). Additionally, despite interacting with hundreds of millions of individual users (Zhao et al., 2024), each possessing distinct perspective or persona, current agents do not effectively personalize their responses to users (Lee et al., 2024b). We posit that directly generating the next response is particularly challenging for LLM-based conversational agents due to the complexity of social dialogue, specifically: (1) the oneto-many problem (Li et al., 2015; Bao et al., 2019), where multiple plausible responses exist, and (2) the scattering of key evidence (Chae et al., 2023), where critical information or phrases are dispersed throughout the conversation. To address this, we suggest that before generating the next response, interpreting the dialogue situation and planning the most plausible conversational skill similar to how humans internal mind states operate can enhance response quality, even in interactive situations involving social dynamics, by acting as form of guidance. To this end, we introduce MULTIFACETED SKILL-OF-MIND, collection of multi-turn, multifaceted skill-of-mind annotated conversations. This dataset includes annotations for both explanations and conversational skills, covering wide range of conversational skills across one-sided turns within dialogues. The dataset is derived from 12 existing source dialogue datasets, which encompass diverse social contexts and scenarios (e.g., chitchat, counseling). To annotate skill-of-mind, we prompt GPT-4 (Achiam et al., 2023) (i.e., gpt-4-turbo) to generate explanations and identify conversational skills from predefined collection of conversational skills, organized hierarchically into five main categories: Interpersonal, Memory & Knowledge Management, Cognitive & Problem-Solving, Communication & Listening, Task-Oriented. Additionally, we propose new family of skillof-mind-infused LLMs, THANOS , which generate both an explanation and the most appropriate conversational skill in LLM-based conversational agents. Through extensive experiments, THANOS accurately predicts conversational skills and generates high-quality explanations across various dialogue scenarios, demonstrating strong generalizability in skill prediction. To further validate the effectiveness of THANOS , we incorporate the generated skill-of-mind as augmented input prompts for LLM-based conversational agents when responding to the next turn, resulting in significant improvements in response quality. Our contributions are summarized as follows: (1) We introduce new social concept, skill-ofmind, which involves interpreting dialogue situations, planning the best skill strategy, and selecting the appropriate conversational skill. (2) We present multi-turn, multifaceted skill-of-mind-annotated conversation dataset, MULTIFACETED SKILL-OFMIND, which encompasses diverse social dynamics and interactive scenarios. (3) Using MULTIFACETED SKILL-OF-MIND, we propose family of skill-of-mind-infused LLMs, THANOS , with model sizes of 1B, 3B, and 8B parameters. With extensive experiments, we demonstrate the effectiveness and generalizability of THANOS across various scenarios."
        },
        {
            "title": "2 MULTIFACETED SKILL-OF-MIND",
            "content": "In this section, we explain the definition of skillof-mind ( 2.1), why predicting skill-of-mind is necessary ( 2.2), the hierarchical taxonomy of conversational skills ( 2.3), and the data construction process ( 2.4). Lastly, we analyze the constructed dataset ( 2.5)."
        },
        {
            "title": "2.1 Definition of “Skill-of-Mind”",
            "content": "We begin by defining what skill-of-mind means in the context of this work. In the conversational AI literature (Smith, 2020; Kim et al., 2022c), these skills are sometimes regarded as communication strategies (Zhou et al., 2023), but generally refer to the desirable abilities required to maintain continuous and meaningful conversations with an interlocutor. These skills cover broad spectrum, ranging from general abilities (e.g., empathy, persona) to task-specific functions (e.g., making phone calls, booking hotel). In everyday social interactions, which are core component of human life, people typically reflect on the current situation and consider who the interlocutor is before selecting the most appropriate skill. This internal cognitive process is often represented as an explanation/rationale (Zhou et al., 2021; Wei et al., 2022). These explanations and skill choices are significantly influenced by the characteristics of the interlocutor, such as demographics, persona, and relationship."
        },
        {
            "title": "2.2 Why “Skill-of-Mind” is necessary?",
            "content": "At the heart of the conversation is social interaction (Myllyniemi, 1986), domain where current LLMs have limited understanding and struggle to effectively handle social interactive scenarios (Zhou et al., 2023; Liu et al., 2023). As result, generating more engaging and natural responses directly through LLM-based conversational agents is challenging. This is because LLMs are primarily designed to solve complex reasoning tasks as general agents through alignment tuning (Ouyang et al., 2022; Chung et al., 2024), making them illsuited to function as social dialogue agents. By introducing guidance based on the concept of skill-ofmind, LLM-based conversational agents can more effectively navigate social interactions. Current LLMs demonstrate better alignment and are capable of following user queries, so grounding responses in skill-of-mind can help narrow down the response options and focus on skill-specific aspects. This leads to more accurate outputs by reducing the range of possible responses (i.e., one-to-many problem). In practical applications, most conversational systems adopt modular approach (Lee et al., 2023) where multiple skill-specialized dialogue agents are used to strengthen user interaction. In these systems, several skill-specific agents generate responses simultaneously, and re-ranking module (Bae et al., 2022b) selects the best one for the given dialogue situation. While this approach is effective, it is also resource-intensive. In real-world scenarios, where multiple conversational skills are required, even with parallel processing, inference may not be as fast as using single skill-expert agent. By focusing on single agent grounded in skill-of-mind, we can potentially improve inference speed and reduce latency. 2.3 Ingredients for Skill-of-Mind The concept of skill-of-mind consists of three main components: (1) social context, (2) explanation, and (3) conversational skill, which are described as follows. Social Context Information. Socially interactive dialogues involve wide range of social dynamics, such as demographics, personal experiences, and relationships. We believe that these factors influence the skill-of-mind. For instance, emotional empathy is more appropriate in conversations with significant romantic partner than with an AI teaching mentor. Therefore, when considering social context information, we take into account various elements, such as the current situation or narrative, social relationships, persona, memory, and past dialogue histories. Explanation/Rationale. This involves interpreting and understanding the current situation to determine the most optimized conversational skill for generating an engaging response that strengthens social rapport (Zech and Rimé, 2005) with the interlocutor in the given dialogue. To achieve higher quality of explanation, similar to how human would respond, we adopt perspective-takingstyle (Davis, 1983; Ruby and Decety, 2004; Kim et al., 2021), which prompts GPT-4 to imagine the actual speaker in the dialogue. The explanation is represented in free-form sentences. Conversational Skill. As discussed in 2.1, there is broad range of conversational skills in real-world scenarios, such as empathy or persona management in chitchat, hotel reservations in taskoriented dialogues, and memory recall in long-term conversations. To account for this spectrum, we design taxonomy that covers fine-grained levels of conversational skills across diverse scenarios. We develop hierarchical taxonomy that encompasses distinct and non-overlapping 3 categories of skills. At the first level, we identify five main categories: (1) Interpersonal Skills, (2) Memory & Knowledge Management Skills, (3) Cognitive & Problem-Solving Skills, (4) Communication & Listening Skills, and (5) Task-Oriented Skills. Interpersonal Skills: These skills are essential for enhancing social interaction by requiring deep understanding of the interlocutors emotional state and adapting to their personality or relationship dynamics for more seamless and engaging communication. They also involve demonstrating prosocial behavior 2Note that we do not generate this information from scratch; rather, it originates from the source dialogue dataset used in this work. 3In reality, it is not always necessary to assign each conversational skill to single category since many skills share overlapping characteristics. For instance, the skill of Active Listening can also be categorized under Interpersonal Skills. However, for clarity in this work, we structure the taxonomy with non-overlapping conversational skill categories. in problematic situations. We also consider image-sharing behavior, which frequently occurs via instant messaging tools. This category includes Empathy, Personal Background, Persona Recall, Self-Disclosure, Negotiation, Conflict Resolution, Conflict Avoidance, Persuasion, Commonsense Understanding, Cultural Sensitivity, Ethics, Harmlessness, Avoiding Social Bias, Helpfulness, Mentoring, Image Commenting, and Image Sharing. Memory & Knowledge Management Skills: These skills are primarily used to provide knowledgeable responses by sharing or acquiring information and recalling memories, which is important for maintaining long-term communication, particularly in senior care services (Bae et al., 2022a,b). This category includes Memory Recall, Knowledge Sharing, Knowledge Acquisition, and Knowledge Searching. Cognitive & Problem-Solving Skills: These skills are required for solving complex problems or performing factual reasoning tasks. This category includes Critical Thinking, Logical Thinking, Creative Problem Solving, Factual Problem Solving, and Decision-Making. Communication & Listening Skills: Effective listening is critical in the communication process (Main, 1985; Castleberry and Shepherd, 1993). Therefore, we include these skills in our taxonomy, which encompasses Clarification, Confirmation, Rephrasing, Echoing, Topic Transition, Rhetoric, Active Listening, Reflective Listening, and Immediate Response. Task-Oriented Skills: In practical scenarios, humans often request conversational agents (e.g., Alexa 4) to perform tasks such as hotel or restaurant reservations, provide weather information, or offer movie recommendations. We also consider these skills, which include Recommendation, Task Execution, and Urgency Recognition."
        },
        {
            "title": "2.4 Dataset Construction Process",
            "content": "Based on the above ingredients of skill-of-mind ( 2.3), we first collect source dialogue datasets and annotate them with skill-of-mind, resulting in MULTIFACETED SKILL-OF-MIND. 4https://developer.amazon.com/en-US/alexa Step 1: Source Dataset Collection. To build more flexible and versatile skill-of-mind-infused LLM, as source data, we collect 12 multi-turn dialogue datasets, which are publicly available online: SODA (Kim et al., 2022a), CONVERSATIONCHRONICLES (Jang et al., 2023), PROSOCIALDIALOGUE (Kim et al., 2022b), EMPATHETICDIALOGUES (Rashkin, 2018), Wizard of Wikipedia (Dinan et al., 2018), CACTUS (Lee et al., 2024c), CASINO (Chawla et al., 2021), MultiWOZ 2.2 (Zang et al., 2020), PERSUASIONFORGOOD (Wang et al., 2019), PEARL (Kim et al., 2024), SYNPERSONACHAT (Jandaghi et al., 2023), and STARK (Lee et al., 2024d). In total, we collect source dialogues from the training sets. We then split each dialogue into sub-dialogues by focusing on one-sided exchanges. For example, given dialogue = {(si, ui)}4 i=1, we create two sub-dialogues: D1 = {(si, ui)}2 i=1 and D2 = {(si, ui)}4 i=1. We remove sub-dialogues with fewer than four turns, as we believe that early in the dialogue, there is higher distribution of non-informative skills, such as greetings, rather than informative skills. We then randomly sample sub-dialogues from each source dataset in specific proportions. As result, we obtain total of 100K dialogues. Step 2: Annotating Skill-of-Mind. We prompt GPT-4 (Achiam et al., 2023) (i.e., gpt-4-turbo) to annotate skill-of-mind into the collected source dialogues. Specifically, it provides internal reasoning about which skills are appropriate for the next turn response in the dialogue and identifies the relevant multifaceted conversational skills from the predefined taxonomy ( 2.3), taking into account the interlocutors perspective (i.e., perspectivetaking). Each instance in MULTIFACETED SKILLOF-MIND consists of three input components (social context information, dialogue, next response) and two output components (explanation, skill). The input components are described as follows: Dialogue: dialogue between two speakers from the collected source datasets in step (1). Next Response: The next response in the dialogue, which should align with the relevant explanation and conversational skill. Given the subjective nature of dialogue, if only the dialogue is provided without golden response, GPT-4 can still generate plausible explanations and skills that are not compatible with Dataset Train? Explanation? # of D. # of S. BST (Smith, 2020) BSBT (Kim et al., 2022c) FLASK (Ye et al., 2023) MULTIFACETED SKILL-OF-MIND 6,808 300, 1,740 99,997 3 3 12 38+ Table 1: Comparison of MULTIFACETED SKILL-OFMIND with existing datasets regarding skills: BlendedSkillTalk (BST), Blended Skill BotsTalk (BSBT), and FLASK. D. and S. denote the dialogue and skill, respectively. The + next to 38 indicates the potential for additional skills as GPT-4 sometimes generates new skills not present in the predefined collection (e.g., feedback giving). To build more flexible model, we include these cases in our training dataset. the natural flow of the original dialogue. Social Context Information: Social context information encompasses various social dynamics, which vary depending on the source dialogues. For example, this includes social narratives in SODA and demographic factors (e.g., age, gender, birthplace, residence), personal narratives, or past session dialogue summaries in STARK. The output components are described as follows: Explanation: rationale explaining which skill is necessary to maintain continuous interaction with the interlocutor, given the input dialogue and the next response. To create more realistic explanations, GPT-4 is induced to engage in perspective-taking process. Conversational Skill: Based on the explanation, one or more conversational skills relevant to the next response are selected from the predefined skill collections."
        },
        {
            "title": "The prompt",
            "content": "template is presented in Appendix E.We instruct GPT-4 to produce structured output in JSON format, excluding any cases that fail to parse correctly. In total, we obtain 99,997 annotations (approximately 100K) and split the data into 9:1 train/test ratio for evaluation. In instances with multiple skill-of-mind annotations, we randomly select one for training THANOS . An example of skill-of-mind annotation is presented in Table 2."
        },
        {
            "title": "2.5 Analysis",
            "content": "Comparison to Existing Datasets. In Table 1, we compare MULTIFACETED SKILL-OF-MIND with other existing datasets that include certain Figure 2: The ration (%) of Top-10 conversational skill categories in MULTIFACETED SKILL-OF-MIND. skills. In summary, MULTIFACETED SKILL-OFMIND is the first dataset to contain both explanations and skills. Although the number of dialogues is smaller than that of the BSBT dataset, we include greater number of conversational skills, which enhances the generalizability of the trained model. Compared to FLASK, our dataset also includes larger variety of skills, whereas FLASKis designed to evaluate fine-grained LLM capabilities and primarily focuses on instruction-based skills. In contrast, our dataset offers comparable dialogue size, and substantial number of skills, and includes both explanations and skills, making it robust resource for generalizable skill prediction. Distribution of Skill-of-Mind. Figure 2 shows the distribution of the Top-10 conversational skill categories generated by GPT-4 (as discussed in 2.4). We analyzed total of 109,591 skillof-mind annotations (considering multiple annotations per dialogue). The most prominent skill is Empathy, likely due to the presence of socially interactive datasets, such as SODA, CONVERSATIONCHRONICLES, and EMPATHETICDIALOGUES, which contain large proportion of empathetic interactions crucial in social dialogues. Additionally, Ethics and Helpfulness also occupy significant portions, indicating that the model trained on our dataset may serve as safeguard to promote prosocial behavior. Human Evaluation. To assess the quality of MULTIFACETED SKILL-OF-MIND, we conduct human evaluation based on five criteria: (1) relevance, (2) plausibility, (3) understanding, (4) skill alignment, and (5) skill adequacy. Each human evaluator rates 100 randomly sampled instances on 4-point Likert scale for all criteria. Criteria (1-3) measure the quality of the explanation, while criteria (4-5) assess the quality of the conversational skill. Further details about each evaluation criterion and the recruitment process for human evaluators are provided in the Appendix and Appendix D. Social Context Information: Sawyer tells Gregg that he needs help with groceries tonight since he has to cook dinner for everyone. They go together and purchase the items on the list including chicken, broccoli, and pasta. Dialogue: Sawyer: Hey Gregg, do you think you could help me out with groceries tonight? Ive got to cook dinner for everyone and its bit of hassle by myself. Gregg: Sure thing, Sawyer. What do you need to get? Sawyer: Well, lets see...we need chicken, broccoli, and pasta. Oh, and some bread too. Gregg: Alright, sounds like we can make pretty good meal out of that. Lets head to the store then. Sawyer: Thanks, Gregg. really appreciate it. Gregg: So, Sawyer, how come youre cooking dinner tonight? Sawyer: Oh, you know...just felt like it. Plus, love to cook so its not big deal. Gregg: Thats really nice of you. Im sure everyone will appreciate it. Sawyer: Yeah, hope so! just want to make something that everyone will enjoy. Skill-of-Mind: Explanation: In responding to Sawyer, want to show that Ive been attentively listening to his thoughts and appreciating the effort he is putting into cooking dinner. By affirming his efforts and expressing confidence that everyone will enjoy his cooking, am validating his feelings and intentions, which is key in making him feel supported. Conversational Skill: Active Listening input prompts. Since each source dialogue in our dataset contains varying levels of social context information, we design source-specific social context prompt templates. For each source dialogue, we create five different social context prompt templates, randomly sampling one during training for flexible generation. The social context prompt templates are presented in the Appendix A. For the output, THANOS is trained to sequentially generate an explanation, followed by conversational skill, similar to Chain-of-Thought (Wei et al., 2022) fine-tuning approach. To mitigate degeneration issues, we introduce [RESULT SKILL] token between the explanation and the conversational skill, as seen in prior work (Kim et al., 2023). Implementation Details. We fine-tune THANOS- {1, 3, 8}B using LoRA (Hu et al., 2021) and PyTorch Fully-Sharded Data Parallel (FSDP). LoRA is applied to all linear layers with rank of 256 and an alpha of 256. We set the maximum number of epochs to 3, with batch size of 8 per GPU, using StepLR scheduler and learning rate of 1e-5 with the AdamW optimizer. All experiments are conducted on 8 NVIDIA A100 GPUs (40 GB). Table 2: sample from MULTIFACETED SKILL-OFMIND."
        },
        {
            "title": "4 Experiments",
            "content": "On average, we achieve notably high scores: 3.72 for relevance, 3.75 for plausibility, 3.74 for understanding, 3.64 for skill alignment, and 3.59 for skill adequacy. Additionally, we compute interrater agreement (IA) using Krippendorffs α, yielding value of 0.62, which indicates substantial level of agreement. These results demonstrate the reliability and quality of MULTIFACETED SKILLOF-MIND, particularly with respect to generating human-like skill-of-mind in interactions. 3 THANOS : Skill-of-Mind-infused"
        },
        {
            "title": "LLM",
            "content": "Backbone LLM. To enhance performance across various applications, we introduce new family of skill-of-mind-infused LLMs with varying model THANOS -{1, 3, 8}B. For THANOS 1B, sizes: we fine-tune LLaMA-3.2-1B-Instruct; for THANOS 3B, we fine-tune LLaMA-3.2-3B-Instruct; and for THANOS 8B, we fine-tune LLaMA-3.1-8B-Instruct using MULTIFACETED SKILL-OF-MIND. Input & Output. During THANOS training, we provide social context information and dialogue as"
        },
        {
            "title": "4.1 Experimental Setup",
            "content": "Task Definition. To evaluate the effectiveness of THANOS, we conduct three tasks: (1) Skill Classification: assessing the accuracy of skills generated by LLM-based agents and THANOS across various dialogue scenarios; (2) Explanation Generation: evaluating the quality of explanations produced in these scenarios; and (3) Response Generation: determining whether the generated skills and explanations improve the response quality in LLM-based agents. Evaluation Datasets. We use different evaluation datasets for each of the three tasks: For (1) Skill Classification, we use BlendedSkillTalk (BST) (Smith, 2020), Blended Skill BotsTalk (BSBT) (Kim et al., 2022c), MULTIFACETED SKILL-OF-MIND, and PhotoChat (Zang et al., 2021) to assess image-sharing behavior in multi-modal interactions, and PROSOCIALDIALOGUE (Kim et al., 2022b) for skills related to prosocial behavior, acting as safeguard; For (2) Explanation Generation, we use MULTIFACETED SKILL-OF-MIND; For (3) Response Generation, we use out-of-domain dialogue datasets like DAILYDIALOG (Li et al., 2017), following previous methods (Kim et al., 2022a; Chae et al., 2023), and for in-domain settings, we use SODA and PROSOCIALDIALOGUES to evaluate how well THANOS promotes prosocial behavior. Baselines. Since our goal is to enhance the quality and sophistication of responses generated by open-sourced LLM-based conversational agents through the incorporation of skill-of-mind capabilities, we select three different, widely-adopted LLM-based conversational agents as baselines: 1) Gemma-2-2B, 2) LLaMA-3.1-8B (which also serves as the backbone for our THANOS 8B), and 3) COSMO-XL (Kim et al., 2022a) which is specialized to social dialogue. Evaluation Metrics. For (1), we measure accuracy (%). For (2), we evaluate using BLEU1/2/4 (Papineni et al., 2002) and ROUGE-L (Lin, 2004). For (3), we apply the same metrics as in (2). However, due to the inherently subjective nature of dialogue evaluation, in addition to BLEU and ROUGE, we conduct human evaluation based on four criteria: (1) naturalness, (2) engagingness, (3) consistency, and (4) overall quality."
        },
        {
            "title": "4.2 Results",
            "content": "THANOS effectively infers the skill-of-mind process. As shown in Table 3, we present the comparative performance of skill classification and explanation generation on the MULTIFACETED SKILLOF-MIND test set. Overall, THANOS demonstrates significantly better performance on both tasks compared to other LLM-based conversational agents. These results suggest that existing LLMbased conversational agents have limited understanding of interaction scenarios, leading to substantially reduced ability to infer the skill-of-mind. In contrast, THANOS effectively simulates the skill-of-mind process, similar to how humans do, benefiting from MULTIFACETED SKILL-OF-MIND. Furthermore, as the size of the backbone model increases, performance continues to improve. THANOS demonstrates strong generalizability. In Table 3, THANOS performs well in out-ofdomain settings. Compared to baselines, THANOS outperforms on the BST, which was not used during its training. Additionally, on the PROSOCIALDIALOGUE, our model achieves significant performance, indicating its potential for safety detection. Furthermore, THANOS shows comparable imagesharing capabilities on the PhotoChat. These results suggest that THANOS has strong generalization performance. THANOS enhances the quality of the generated responses. Table 4 presents the performance of the response generation task for LLM-based conversational agents with and without THANOS. Overall, THANOS significantly increases the quality of generated responses, suggesting the effectiveness of skill-of-mind as socially-aware guidance. Scaling up THANOS improves performance further, though the efficient 1B-size version also achieves notable improvements, indicating the potential for use in mobile environments. Surprisingly, THANOS significantly boosts the performance of Gemma-2-2B, demonstrating that skill-of-mind is effectively compatible with efficient LLM-based conversational agents without compromising generalizability. In addition, in the PROSOCIALDIALOGUE setting, THANOS significantly increases performance by large margin, suggesting that skill-of-mind successfully induces prosocial behavior in LLM-based agents, serving as safeguard. This highlights its potential as safety mechanism (Han et al., 2024). Furthermore, even in social conversational agents like COSMO-XL, THANOS enables the generation of more adaptive and higher-quality responses, implying that skill-of-mind is fully compatible with the socially aligned foundation model. THANOS enhances more human-friendly responses. Table 5 provides detailed analysis of the effect of THANOS on two datasets. THANOS induces agents to generate more human-like, empathetic responses, as evidenced by improvements in the accuracy of empathetic intent classification and emotion classification. Additionally, the diff-Ex score shows small difference between the golden human response and the predicted response. In the PROSOCIALDIALOGUEdataset, the frequency of the casual label increases, while the caution label decreases. These results suggest that THANOS helps LLM-based agents exhibit more human-like and prosocial behavior. Results of head-to-head evaluation. Table 6 shows the human evaluation results on the DAILYDIALOG dataset based on five evaluation criteria: (1) naturalness, (2) specificity, (3) consistency, (4) engagingness, and (5) overall quality. For this, we randomly sampled 70 dialogues and asked human evaluators to choose the better response between"
        },
        {
            "title": "Prosocial BST",
            "content": "PhotoChat Avg. B-1 B-2 B-4 R-L"
        },
        {
            "title": "BertScore",
            "content": "Gemma-2-2B LLaMA-3.1-8B 3.30 5.20 THANOS 1B 27.50 THANOS 3B 28. THANOS 8B 29.70 12.70 18.42 50.40 50.80 53. 1.97 7.10 24.16 24.85 23.08 5. 4.03 12.60 14.87 15.81 5.76 8. 8.00 10.90 2.40 3.90 0.30 0. 4.30 3.80 28.67 29.80 14.10 4. 18.70 29.83 30.90 14.70 4.90 19. 30.60 31.20 15.10 5.40 20.10 29. 26.18 88.49 88.45 88.53 Table 3: Comparison of skill classification accuracy (%) and explanation generation on MULTIFACETED SKILLOF-MIND (Ours), PROSOCIALDIALOGUE (Prosocial), BST, and PhotoChat datasets. B-1/2/4 refer to BLEU1/2/4 (Papineni et al., 2002), and R-L refers to ROUGE-L (Lin, 2004) for simplicity. DAILYDIALOG EMPATHETICDIALOGUES PROSOCIALDIALOGUE Models B-1 B-2 BR-L BertScore B-1 B-2 B-4 R-L BertScore B-1 B-2 B-4 R-L BertScore Gemma-2-2B 6.02 2.28 0.57 11.53 + THANOS 1B 10. 3.66 0.87 11.66 + THANOS 3B 11.01 3.63 0. 11.74 + THANOS 8B 11.16 3.94 0.97 12.46 LLaMA-3.1-8B + THANOS 1B + THANOS 3B 11.6 9.93 9.95 4. 1.16 11.5 3.49 0.85 10.82 3. 0.79 10.97 + THANOS 8B 10.95 4.09 1.06 11. COSMO-XL 3.92 0.64 0.12 + THANOS 1B 10.15 2. 0.33 + THANOS 3B 10.6 2.58 0.31 3. 6.95 6.45 + THANOS 8B 10.71 2.88 0.51 7. 82.71 83.86 83.72 83.82 83.51 83. 83.42 83.59 38.02 67.64 66.25 69. 5.75 1.76 0.37 10.12 13.37 4. 1.01 11.38 13.68 4.03 0.87 11. 13.67 4.01 0.76 11.76 9.74 3. 0.6 10.42 10.63 3.18 0.55 10. 10.94 3.27 0.78 10.94 10.65 2. 0.5 10.27 10.76 2.7 0.29 10. 2.81 0.32 10.15 2.71 0.46 10. 2.7 0.37 7.19 8.35 8.52 8. 84.03 85.47 85.52 85.54 84.73 84. 84.94 84.87 70.46 74.22 73.44 74. 13.77 4.32 0.76 12.25 85.53 18. 5.66 0.95 12.63 18.51 5.8 1. 12.98 18.54 5.84 1.01 12.8 15. 5.49 1.24 13.07 17.83 6.03 1. 13.17 17.44 5.89 1.22 13.13 17. 5.86 1.16 13.27 8.35 2.76 0. 10.2 13.71 4.49 0.91 10.73 15. 4.87 0.96 11.01 14.55 4.71 11.18 86.2 86.25 86.26 85.93 86. 86.02 86.06 72.92 73.1 73.23 75. Table 4: Automatic evaluation results of response generation task on DAILYDIALOG, EMPATHETICDIALOGUES, PROSOCIALDIALOGUE datasets. EMPATHETICDIALOGUES PROSOCIALDIALOGUE Natural Specific Consistent Engaging Overall Intent Emotion diff-EX Casual Caution Intervention Gemma-2-2B + THANOS 1B + THANOS 3B + THANOS 8B COSMO-XL + THANOS 1B + THANOS 3B + THANOS 8B 23.5 23.8 25. 24.1 20.5 20.6 20.4 20.5 14. 15.4 14.1 15.4 12.3 13.3 13. 13.6 1.42 1.08 1.06 1.06 1. 1.45 1.50 1.51 74.3 88.0 85. 87.2 70.3 70.6 70.8 74.1 22. 10.1 12.8 11.1 13.9 13.5 13. 12.4 2.2 1.9 1.5 1.7 1. 0.9 1.2 0.9 Table 5: Detailed performance comparison on empathyand prosocial-related datasets. The metrics Intent, Emotion, and diff-EX are designed to evaluate sophisticated aspects of empathetic responses. We refer to previous work (Lee et al., 2022a) for details on the evaluation process. lower diff-EX value indicates more humanlike response. For detailed analysis of prosocial behavior, we measure the ratio of safety labels using the Canary model (Kim et al., 2022b), safety classification model. If the sum of the safety label ratios does not equal 100, it indicates degeneration has occurred. Gemma-2-2B + THANOS 8B LLaMA-3.1-8B + THANOS 8B 38.6 61. 28.6 71.4 50 50 54.3 45. 47.2 52.8 41.4 58.6 44.3 55. 42.9 57.1 42.9 57.1 41.4 58. Table 6: Head-to-head evaluation between LLM-based agents and those equipped with THANOS 8B on response generation for the DAILYDIALOG dataset. the LLM and the LLM with THANOS. Overall, THANOS effectively helps LLM-based agents generate responses that are more preferred by real humans. However, in terms of specificity, THANOS does not help the LLM agent achieve better performance. These results suggest that current LLMbased agents are mainly trained to provide helpful and informative responses to users complex queries, thereby yielding better specificity. Future work should focus on building conversational agents possessing both social reasoning and complex reasoning."
        },
        {
            "title": "5 Related Work",
            "content": "Conversational Skills. There have been few studies that cover conversational skills. For example, BlendedSkillTalk (Smith, 2020) was the first to propose dialogue dataset encompassing multiple conversational skills, including persona, empathy, and knowledge. Blended Skill BotsTalk (Kim et al., 2022c) also addresses the same conversational skills as BlendedSkillTalkbut scales up the dataset size through an automatic dataset construction method. Unlike these two datasets, FLASK (Ye et al., 2023) focuses on finegrained skills for evaluating the multi-capabilities of instruction-aware LLMs, though it is not used for training purposes. In contrast, our work introduces the concept of skill-of-mind and presents MULTIFACETED SKILL-OF-MIND, where each dialogue includes both an explanation and conversational skill. Compared to other datasets, MULTIFACETED SKILL-OF-MIND incorporates explanation, which is grounded in perspective-taking approach, and covers larger number of conversational skills. LLM-based Conversational Agents. Recent LLM-based conversational agents, such as ChatGPT (OpenAI, 2023), GPT-4 (Achiam et al., 2023), and LLaMA-3 (AI@Meta, 2024), are built on top of large pre-trained LLMs via instruction finetuning or RLHF. These agents have been widely used to construct socially-aware dialogue datasets, such as SODA(Kim et al., 2022a) and STARK(Lee et al., 2024d), through symbolic knowledge distillation frameworks. However, as previous studies have reported (Zhou et al., 2023), these agents still show limited performance in socially interactive scenarios, especially in the case of open-source models where performance tends to degrade more than in closed-source models. We argue that, for open-source agents, directly generating sociallyaware responses poses greater challenge. To alleviate this burden, we propose that guiding response generation using the skill-of-mind concept can enhance the performance of open-source agents, particularly in terms of the quality of their responses."
        },
        {
            "title": "6 Conclusion",
            "content": "In this work, we introduce the concept of skillof-mind that involves interpreting social contexts and selecting appropriate conversational skills. We also present MULTIFACETED SKILL-OF-MIND, multi-turn dataset annotated with diverse skill-ofmind dynamics, and propose THANOS , family of skill-of-mind-infused LLMs, demonstrating their effectiveness across various tasks. Our work highlights the potential to enhance socially aware conversations in open-source models through skillbased guidance, paving the way for future advancements in skill-driven conversational AI."
        },
        {
            "title": "THANOS",
            "content": "Extending the Generalizability of Skill-of-Mind. Although is trained on MULTIFACETED SKILL-OF-MIND, which includes multifaceted skill-of-mind across diverse dialogue scenarios (e.g., counseling, task-oriented interactions), this work focuses on enhancing LLM-based conversational agents (i.e., LLaMA-3.1-8B, Gemma-2-2B) to generate more engaging and natural responses based on the skill-of-mind guidance provided by THANOS . To further verify the extensive generalization capabilities of THANOS , we need to conduct additional experiments in more varied dialogue scenarios (Zhang et al., 2023; Kim et al., THANOS 2024; Lee et al., 2024c). For instance, could be beneficial for psychological counseling services or adaptable to off-the-shelf home assistants (e.g., Alexa). We leave this for future work. Building Skill-of-Mind-Embedded Dialogue In this work, we build skill-of-mindAgent. infused LLM, THANOS , and demonstrate that incorporating skill-of-mind enhances the generation of more natural, socially aware responses in LLMbased conversational agents. However, the current approach still relies on providing skill-of-mind through the LLMs input prompt, which means the core of the LLM-based agent still lacks the inherent ability to fully comprehend social interactions (Zhou et al., 2023). Inspired by the recent success of knowledge-embedded, task-specific foundation models (Lee et al., 2024a; Yoon et al., 2024), we need to build more advanced skill-of-mindinfused dialogue agent by embedding skill-of-mind directly into the model."
        },
        {
            "title": "Ethical Considerations",
            "content": "In constructing MULTIFACETED SKILL-OF-MIND, we use the PROSOCIALDIALOGUE dataset as the source dialogue. Although this dataset focuses on promoting prosocial behavior, some instances may contain relatively unsuitable phrases (e.g., politics). Consequently, THANOS trained on MULTIFACETED SKILL-OF-MIND could be exposed to these harmful instances. However, the goal of this work is to generate skill-of-mind in various dialogue situations, including those involving prosocial behavior, rather than generating harmful or offensive responses. Nonetheless, it is important to use our model cautiously and with care to avoid unintended consequences."
        },
        {
            "title": "Acknowledgement",
            "content": "This work was supported by grant of the KAISTKT joint research project through AI Tech Lab, Institute of convergence Technology, funded by KT [Project No. G01230605, Development of Task-oriented Persona-based Dialogue Generation Combining Multi-modal Interaction and Knowledge Modeling]."
        },
        {
            "title": "References",
            "content": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. AI@Meta. 2024. Llama 3 model card. Sanghwan Bae, Donghyun Kwak, Soyoung Kang, Min Young Lee, Sungdong Kim, Yuin Jeong, Hyeri Kim, Sang-Woo Lee, Woomyoung Park, and Nako Sung. 2022a. Keep me updated! memory management in long-term conversations. arXiv preprint arXiv:2210.08750. Sanghwan Bae, Donghyun Kwak, Sungdong Kim, Donghoon Ham, Soyoung Kang, Sang-Woo Lee, and Woomyoung Park. 2022b. Building role specified open-domain dialogue system leveraging large-scale language models. arXiv preprint arXiv:2205.00176. Siqi Bao, Huang He, Fan Wang, Hua Wu, and Haifeng Wang. 2019. Plato: Pre-trained dialogue generation model with discrete latent variable. arXiv preprint arXiv:1910.07931. Stephen Castleberry and David Shepherd. 1993. Effective interpersonal listening and personal selling. Journal of Personal Selling & Sales Management, 13(1):3549. Hyungjoo Chae, Yongho Song, Kai Tzu-iunn Ong, Taeyoon Kwon, Minjin Kim, Youngjae Yu, Dongha Lee, Dongyeop Kang, and Jinyoung Yeo. 2023. Dialogue chain-of-thought distillation for commonsensearXiv preprint aware conversational agents. arXiv:2310.09343. for automatic negotiation systems. arXiv preprint arXiv:2103.15721. Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2024. Scaling instruction-finetuned language models. Journal of Machine Learning Research, 25(70):153. Mark Davis. 1983. Measuring individual differences in empathy: Evidence for multidimensional approach. Journal of personality and social psychology, 44(1):113. Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. 2018. Wizard of wikipedia: Knowledge-powered conversational agents. arXiv preprint arXiv:1811.01241. Giorgio Franceschelli and Mirco Musolesi. 2023. On arXiv the creativity of large language models. preprint arXiv:2304.00008. Seungju Han, Kavel Rao, Allyson Ettinger, Liwei Jiang, Bill Yuchen Lin, Nathan Lambert, Yejin Choi, and Nouha Dziri. 2024. Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms. arXiv preprint arXiv:2406.18495. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685. Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, and Hakim Sidahmed. 2023. Faithful persona-based conversational dataset generation with large language models. arXiv preprint arXiv:2312.10007. Jihyoung Jang, Minseong Boo, and Hyounghun Kim. 2023. Conversation chronicles: Towards diverse temporal and relational dynamics in multi-session conversations. arXiv preprint arXiv:2310.13420. Hyunwoo Kim, Jack Hessel, Liwei Jiang, Peter West, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Le Bras, Malihe Alikhani, Gunhee Kim, et al. 2022a. Soda: Million-scale dialogue distillation with social commonsense contextualization. arXiv preprint arXiv:2212.10465. Hyunwoo Kim, Byeongchang Kim, and Gunhee Kim. 2021. Perspective-taking and pragmatics for generating empathetic responses focused on emotion causes. arXiv preprint arXiv:2109.08828. Hyunwoo Kim, Youngjae Yu, Liwei Jiang, Ximing Lu, Daniel Khashabi, Gunhee Kim, Yejin Choi, and Maarten Sap. 2022b. Prosocialdialog: prosocial backbone for conversational agents. arXiv preprint arXiv:2205.12688. Kushal Chawla, Jaysa Ramirez, Rene Clever, Gale Lucas, Jonathan May, and Jonathan Gratch. 2021. Casino: corpus of campsite negotiation dialogues Minjin Kim, Minju Kim, Hana Kim, Beong-woo Kwak, Soyeon Chun, Hyunseo Kim, SeongKu Kang, Youngjae Yu, Jinyoung Yeo, and Dongha Lee. 2024. Pearl: review-driven persona-knowledge grounded conversational recommendation dataset. arXiv preprint arXiv:2403.04460. Minju Kim, Chaehyeong Kim, Yongho Song, Seungwon Hwang, and Jinyoung Yeo. 2022c. Botstalk: Machine-sourced framework for automatic curation of large-scale multi-skill dialogue datasets. arXiv preprint arXiv:2210.12687. Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, et al. 2023. Prometheus: Inducing fine-grained evaluation capability in language models. In The Twelfth International Conference on Learning Representations. Byung-Kwan Lee, Chae Won Kim, Beomchan Park, and Yong Man Ro. 2024a. Meteor: Mamba-based traversal of rationale for large language and vision models. arXiv preprint arXiv:2405.15574. Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos, and Kangwook Lee. 2023. Prompted llms as chatbot modules for long open-domain conversation. arXiv preprint arXiv:2305.04533. Seongyun Lee, Sue Hyun Park, Seungone Kim, and Minjoon Seo. 2024b. Aligning to thousands of preferences via system message generalization. arXiv preprint arXiv:2405.17977. Suyeon Lee, Sunghwan Kim, Minju Kim, Dongjin Kang, Dongil Yang, Harim Kim, Minseok Kang, Dayi Jung, Min Hee Kim, Seungbeen Lee, et al. 2024c. Cactus: Towards psychological counseling conversations using cognitive behavioral theory. arXiv preprint arXiv:2407.03103. Young-Jun Lee, Dokyong Lee, Junyoung Youn, Kyeongjin Oh, Byungsoo Ko, Jonghwan Hyeon, and Ho-Jin Choi. 2024d. Stark: Social long-term multi-modal conversation with persona commonsense knowledge. arXiv preprint arXiv:2407.03958. Young-Jun Lee, Chae-Gyun Lim, and Ho-Jin Choi. 2022a. Does gpt-3 generate empathetic dialogues? novel in-context example selection method and automatic evaluation metric for empathetic dialogue generation. In Proceedings of the 29th International Conference on Computational Linguistics, pages 669 683. Young-Jun Lee, Chae-Gyun Lim, Yunsu Choi, Ji-Hui Lm, and Ho-Jin Choi. 2022b. Personachatgen: Generating personalized dialogues using gpt-3. In Proceedings of the 1st Workshop on Customized Chat Grounding Persona and Knowledge, pages 2948. Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2015. diversity-promoting objective function for neural conversation models. arXiv preprint arXiv:1510.03055. Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. Dailydialog: manually labelled multi-turn dialogue dataset. arXiv preprint arXiv:1710.03957. Chin-Yew Lin. 2004. Rouge: package for automatic In Text summarization evaluation of summaries. branches out, pages 7481. Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew Dai, Diyi Yang, and Soroush Vosoughi. 2023. Training socially aligned language arXiv models on simulated social interactions. preprint arXiv:2305.16960. Jeremy Main. 1985. How to sell by listening. Fortune, 111(3):5254. Rauni Myllyniemi. 1986. Conversation as system of social interaction. Language & Communication. OpenAI. 2023. ChatGPT. https://openai.com/blo g/chatgpt/. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35:2773027744. Liangming Pan, Alon Albalak, Xinyi Wang, and William Yang Wang. 2023. Logic-lm: Empowering large language models with symbolic solvers arXiv preprint for faithful arXiv:2305.12295. logical reasoning. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311318. David Premack and Guy Woodruff. 1978. Does the chimpanzee have theory of mind? Behavioral and brain sciences, 1(4):515526. Hannah Rashkin. 2018. Towards empathetic opendomain conversation models: new benchmark and dataset. arXiv preprint arXiv:1811.00207. Perrine Ruby and Jean Decety. 2004. How would you feel versus how do you think she would feel? neuroimaging study of perspective-taking with social emotions. Journal of cognitive neuroscience, 16(6):988999. Eric Michael Smith. 2020. Can you put it all together: Evaluating conversational agents ability to blend skills. arXiv preprint arXiv:2004.08449. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. 2024. Gemma 2: Improving open language models at practical size. arXiv preprint arXiv:2408.00118. Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng. 2024. Wildchat: 1m chatgpt interaction logs in the wild. arXiv preprint arXiv:2405.01470. Pei Zhou, Karthik Gopalakrishnan, Behnam Hedayatnia, Seokhwan Kim, Jay Pujara, Xiang Ren, Yang Liu, and Dilek Hakkani-Tur. 2021. Think before you speak: Explicitly generating implicit commonsense knowledge for response generation. arXiv preprint arXiv:2110.08501. Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, et al. Interactive evaluation for social 2023. Sotopia: arXiv preprint intelligence in language agents. arXiv:2310.11667. Maxim Tkachenko, Mikhail Malyuk, Andrey 2020Data labeling softOpen source software available from Holmanyuk, 2022. ware. https://github.com/heartexlabs/label-studio. and Nikolai Liubimov. Label Studio: Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288. Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen Zhang, and Zhou Yu. 2019. Persuasion for good: Towards personalized persuasive dialogue system for social good. arXiv preprint arXiv:1906.06725. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:2482424837. Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, and Minjoon Seo. 2023. Flask: Fine-grained language model evaluation arXiv preprint based on alignment skill sets. arXiv:2307.10928. Dongkeun Yoon, Joel Jang, Sungdong Kim, Seungone Kim, Sheikh Shafayat, and Minjoon Seo. 2024. Langbridge: Multilingual reasoning without multilingual supervision. arXiv preprint arXiv:2401.10695. Xiaoxue Zang, Lijuan Liu, Maria Wang, Yang Song, Hao Zhang, and Jindong Chen. 2021. Photochat: human-human dialogue dataset with photo sharing behavior for joint image-text modeling. arXiv preprint arXiv:2108.01453. Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, and Jindong Chen. 2020. Multiwoz 2.2: dialogue dataset with additional annotation corrections and state tracking baselines. arXiv preprint arXiv:2007.12720. Emmanuelle Zech and Bernard Rimé. 2005. Is talking about an emotional experience helpful? effects on emotional recovery and perceived benefits. Clinical Psychology & Psychotherapy: An International Journal of Theory & Practice, 12(4):270287. Jianguo Zhang, Kun Qian, Zhiwei Liu, Shelby Heinecke, Rui Meng, Ye Liu, Zhou Yu, Huan Wang, Silvio Savarese, and Caiming Xiong. 2023. Dialogstudio: Towards richest and most diverse unified dataset collection for conversational ai. arXiv preprint arXiv:2307.10172. Saizheng Zhang. 2018. Personalizing dialogue agents: have dog, do you have pets too. arXiv preprint arXiv:1801.07243."
        },
        {
            "title": "Information",
            "content": "Table 7, Table 8, Table 9, Table 10, Table 11, Table 12, Table 13, Table 14, Table 15, Table 16 show social context template for PROSOCIALDIALOGUE (Kim et al., 2022b), STARK (Lee et al., 2024d) (first round session), STARK (Lee et al., 2024d) (N-th round session), CACTUS (Lee et al., 2024c), SYN-PERSONACHAT (Jandaghi et al., 2023), CASINO (Chawla et al., 2021) (sentence format), CASINO (Chawla et al., 2021) (structured format), PEARL (Kim et al., 2024), PERSUASIONFORGOOD (Wang et al., 2019), EMPATHETICDIALOGUES (Rashkin, 2018)."
        },
        {
            "title": "B Human Evaluation Questionnaire",
            "content": "This section presents the list of questions and multiple-choice options used for the human ratings represented in Section 2. B.1 Human Ratings Relevance: How relevant is the given explanation to the current dialogue situation and the social context? Options: 1: Not at all / 2: little / 3: Somewhat / 4: lot Plausibility: Does the given explanation seem plausible, as if human would think in real-world scenario? Figure 3: screenshot of human rating evaluation for MULTIFACETED SKILL-OF-MIND. B.2 Head-to-Head Comparison Naturalness: Which response is more natural? Options: Definitely / Slightly / Slightly / Definitely Consistent: Which response is more consistent? Options: Definitely / Slightly / Slightly / Definitely Specificity: Which response is more specific? Options: Definitely / Slightly / Slightly / Definitely Options: 1: Not at all / 2: little / 3: SomeEngagingness: Which response is more enwhat / 4: lot gaging? Understanding: How does the given explanation demonstrate understanding of the current dialogue situation and the social context? Options: Definitely / Slightly / Slightly / Definitely Overall: Which response do you like more Options: 1: Not at all / 2: little / 3: Someoverall? what / 4: lot Skill Alignment: Does the selected conversational skill align well with the provided explanation? Options: 1: Not at all / 2: little / 3: Somewhat / 4: lot Skill Adequacy: Do the conversational skills currently used seem appropriate for generating suitable response in the upcoming turn? Options: Definitely / Slightly / Slightly / Definitely B"
        },
        {
            "title": "C Human Evaluation System",
            "content": "We show screenshot of the human evaluation system in Figure 3 and Figure 4. We implement this system using Label Studio (Tkachenko et al., 2020-2022)."
        },
        {
            "title": "D Details of Human Evaluation",
            "content": "Options: 1: Not at all / 2: little / 3: Somewhat / 4: lot We recruited 15 individuals, unknown to us, who are either graduate or undergraduate students. Prior"
        },
        {
            "title": "Template for Social Context Information in PROSOCIALDIALOGUE",
            "content": "Speaker should foster prosocial behavior by providing constructive feedback based on these Rule-of-Thumbs:n- {rots} Speaker should encourage prosocial behavior by giving constructive feedback based on these Rule-of-Thumbs:n- {rots} To promote positive behavior, Speaker should offer constructive feedback following these Rule-of-Thumbs:n- {rots} Guided by these Rule-of-Thumbs, Speaker should encourage prosocial behavior through constructive feedback:n- {rots} Speaker is expected to provide constructive feedback to encourage positive interactions, using these Rule-of-Thumbs:n- {rots} Table 7: Template for social context information in PROSOCIALDIALOGUE (Kim et al., 2022b). {rots} denotes Rule-of-Thumbs (RoTs). Template for Social Context Information in STARK (First Round Session) {name} is {age} years old, born in {birthplace}, and currently lives in {residence}. {event} {name}, aged {age}, was born in {birthplace} and resides in {residence}. {event} {name}, who is {age}, was born in {birthplace} and now lives in {residence}. {event} {name} is {age}, originally from {birthplace}, and now living in {residence}. {event} {name} is {age} years old, born in {birthplace}, and resides in {residence}. {event} Table 8: Template for social context information in STARK (Lee et al., 2024d) (first round session). Template for Social Context Information in STARK (N-th Round Session) {name} is {age} years old, born in {birthplace}, and currently lives in {residence}. After {time_interval}, {name} has gone through {experience}, and now {event} {name}, aged {age}, was born in {birthplace} and now resides in {residence}. Following {time_interval}, {name} experienced {experience}, and {event} {name}, who is {age} years old, originally from {birthplace} and living in {residence}, went through {experience} after {time_interval}, and now {event} {name} is {age}, born in {birthplace}, and currently resides in {residence}. After {time_interval} of {experience}, {name} has now {event} {name}, {age} years old, from {birthplace} and residing in {residence}, has experienced {experience} over {time_interval}, and as result, {event} Table 9: Template for social context information in STARK (Lee et al., 2024d) (N-th round session)."
        },
        {
            "title": "Template for Social Context Information in CACTUS",
            "content": "Clients attitude is {client attitude}. The clients intake form is as follows:n{client intake form}. The client has an attitude of {client attitude}. Below is the clients intake form:n{client intake form}. With an attitude of {client attitude}, the clients intake form details are:n{client intake form}. Clients attitude: {client attitude}. Intake form information:n{client intake form}. The clients attitude is {client attitude}. Here is their intake form:n{client intake form}. Table 10: Template for social context information in CACTUS (Lee et al., 2024c). Template for Social Context Information in SYN-PERSONACHAT User 1s Persona Information:n- {user1 persona}nnUser 2s Persona Information:n- {user2 persona} User 1s Profile:n- {user1 persona}nnUser 2s Profile:n- {user2 persona} Details of User 1s Persona:n- {user1 persona}nnDetails of User 2s Persona:n- {user2 persona} Persona for User 1:n- {user1 persona}nnPersona for User 2:n- {user2 persona} Information about User 1s Persona:n- {user1 persona}nnInformation about User 2s Persona:n- {user2 persona} Table 11: Template for social context information in SYN-PERSONACHAT (Jandaghi et al., 2023). Template for social context information in CASINO (sentence format) Speaker is {speaker_a_age}-year-old {speaker_a_ethnicity} {speaker_a_gender} who has {speaker_a_education} education. Their social value orientation is {speaker_a_svo}. According to the Big Five personality traits, they score {speaker_a_extraversion} in extraversion, {speaker_a_agreeableness} in agreeableness, {speaker_a_conscientiousness} in conscientiousness, {speaker_a_emotional_stability} in emotional stability, and {speaker_a_openness_to_experiences} in openness to experiences. In the negotiation, Speaker As highest priority is {speaker_a_value2issue_high}, for which they reasoned: \"{speaker_a_value2reason_high}\". Their medium priority is {speaker_a_value2issue_medium}, with the reasoning: \"{speaker_a_value2reason_medium}\". Their lowest priority is {speaker_a_value2issue_low}, and they stated: \"{speaker_a_value2reason_low}\". Speaker is {speaker_b_age}-year-old {speaker_b_ethnicity} {speaker_b_gender} who has {speaker_b_education} education. Their social value orientation is {speaker_b_svo}. Their Big Five personality traits scores are {speaker_b_extraversion} in extraversion, {speaker_b_agreeableness} in agreeableness, {speaker_b_conscientiousness} in conscientiousness, {speaker_b_emotional_stability} in emotional stability, and {speaker_b_openness_to_experiences} in openness to experiences. During the negotiation, Speaker Bs top priority is {speaker_b_value2issue_high}, and they explained: \"{speaker_b_value2reason_high}\". Their medium priority is {speaker_b_value2issue_medium}, with the reason: \"{speaker_b_value2reason_medium}\". Their lowest priority is {speaker_b_value2issue_low}, about which they mentioned: \"{speaker_b_value2reason_low}\". Table 12: Template for social context information in CASINO (Chawla et al., 2021) (sentence format). Figure 4: screenshot of head-to-head comparison evaluation for DailyDialog (Li et al., 2017) to participating in the experiment, they were provided with comprehensive instruction on the task, an overview of the skill-of-mind-annotated dialogue dataset, and detailed explanation of the evaluation criteria. This preparatory phase lasted approximately roughly 15 minutes. Template for social context information in CASINO (structured format) Template for Social Context Information in PEARL Speaker As Demographic Information: - Age: {speaker_a_age} - Gender: {speaker_a_gender} - Ethnicity: {speaker_a_ethnicity} - Education: {speaker_a_education} Speaker As Personality Information: - Social Value Orientation (SVO): {speaker_a_svo} - Big Five Personality Traits: - Extraversion: {speaker_a_extraversion} - Agreeableness: {speaker_a_agreeableness} - Conscientiousness: {speaker_a_conscientiousness} - Emotional Stability: {speaker_a_emotional_stability} - Openness to Experiences: {speaker_a_openness_to_experiences} Speaker As Negotiation Information: - Priority Order (value2issue): - High: {speaker_a_value2issue_high} - Medium: {speaker_a_value2issue_medium} - Low: {speaker_a_value2issue_low} - Personal Arguments (value2reason): - High: {speaker_a_value2reason_high} - Medium: {speaker_a_value2reason_medium} - Low: {speaker_a_value2reason_low} Speaker Bs Demographic Information: - Age: {speaker_b_age} - Gender: {speaker_b_gender} - Ethnicity: {speaker_b_ethnicity} - Education: {speaker_b_education} Speaker Bs Personality Information: - Social Value Orientation (SVO): {speaker_b_svo} - Big Five Personality Traits: - Extraversion: {speaker_b_extraversion} - Agreeableness: {speaker_b_agreeableness} - Conscientiousness: {speaker_b_conscientiousness} - Emotional Stability: {speaker_b_emotional_stability} - Openness to Experiences: {speaker_b_openness_to_experiences} Speaker Bs Negotiation Information: - Priority Order (value2issue): - High: {speaker_b_value2issue_high} - Medium: {speaker_b_value2issue_medium} - Low: {speaker_b_value2issue_low} - Personal Arguments (value2reason): - High: {speaker_b_value2reason_high} - Medium: {speaker_b_value2reason_medium} - Low: {speaker_b_value2reason_low} Seekers overall movie preferences are represented as follows:n{user persona} Here is the seekers complete movie profile:n{user persona} The seekers general movie state is described below:n{user persona} Representation of seekers overall movie interests:n{user persona} Below is the seekers overall movie persona:n{user persona} Table 14: Template for social context information in PEARL (Kim et al., 2024). Template for Social Context Information in PERSUASIONFORGOOD Speaker is attempting to persuade Speaker B. In this scenario, Speaker is the Persuader and Speaker is the Persuadee. Speaker acts as Persuader, while Speaker plays the role of Persuadee. In the conversation, Speaker is persuading Speaker B. Speaker aims to convince Speaker B. Table 15: Template for social context information in PERSUASIONFORGOOD (Wang et al., 2019). Template for Social Context Information in EMPATHETICDIALOGUES Speaker is feeling {emotion} because {situation}. Due to {situation}, Speaker As emotion is {emotion}. Speaker As emotional state: {emotion}; Situation: {situation}. Because of {situation}, Speaker is in {emotion} mood. The situation is {situation}, so Speaker feels {emotion}. Table 13: Template for social context information in CASINO (Chawla et al., 2021) (structured format). Table 16: Template for social context information in EMPATHETICDIALOGUES (Rashkin, 2018). Prompt Template for MULTIFACETED SKILL-OF-MIND Prompt Template for Skill-of-Mind Generation System Message: You are helpful assistant that generates the most appropriate conversational skill and corresponding explanation. Read the provided instruction carefully. Instruction: In the given dialogue, two speakers are communicating with each other, and each speaker has their own information such as demographics, preferences, persona, current situation/narrative, past dialogue summaries, episodic memory, or other relevant details. This information is represented in the \"[Social Context]\" part. In this dialogue, image-sharing moments sometimes occur, represented in the format of \"[Sharing Image] <image_description>\", where <image_description> represents the description of the shared image. You are also given the ideal response for the next turn in the given dialogue. Your task is to identify the most appropriate conversational skill that would lead to the ideal response in the given dialogue from the skill collection below, and explain why this particular skill was chosen. When generating the explanation, you should adopt the perspective of the speaker in the dialogue, selecting the skill based solely on the context of the given conversation. Do not consider the ideal response when generating your explanation; focus only on the given dialogue itself and why the chosen skill is the most suitable in that specific situation. We provide the skill collection: [Skill Collections] - Empathy, Personal Background, Persona Recall, Self-disclosure, Negotiation, Conflict Resolution, Conflict Avoidance, Persuasion, Memory Recall, Topic Transition, Ethics, Harmlessness, Helpfulness, Avoiding Social Bias, Cultural Sensitivity, Commonsense Understanding, Rhetoric, Preference Elicitation, Knowledge Sharing, Knowledge Acquisition, Knowledge Searching, Active Listening, Factual Problem Solving, Logical Thinking, Critical Thinking, Creative Problem Solving, Immediate Response, Rephrasing, Echoing, Mentoring, Reflective Listening, Image-Sharing, Image-Commenting, Recommendation, Task Execution, Urgency Recognition, Clarification, Confirmation, Decision-making Given the dialogue, social context information, and the next response, please brainstorm the most appropriate conversation skill and corresponding explanation. [Social Context] {social_context} [Dialogue] {dialogue} [Next Response] {response} You should strictly follow the guidelines below: [Guidelines] - The answer should be represented in the form of JSON list. - Each entry in the list should be Python dictionary containing the following keys: \"skill\", \"explanation\". - The \"skill\" field should contain the one skill that is mostly required to generate the next response. - The \"explanation\" field should provide reason that occurs in the actual speakers mind before selecting the skill, from the speakers perspective. - The \"explanation\" should be written from the perspective of the actual speaker who made the next response. - You can choose one or multiple skills if necessary, but each skill must have its own explanation. [Generated Skills and Explanations ]"
        }
    ],
    "affiliations": [
        "KAIST",
        "KT Corporation"
    ]
}