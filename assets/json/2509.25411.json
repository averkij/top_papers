{
    "paper_title": "Boolean Satisfiability via Imitation Learning",
    "authors": [
        "Zewei Zhang",
        "Huan Liu",
        "Yuanhao Yu",
        "Jun Chen",
        "Xiangyu Xu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We propose ImitSAT, a branching policy for conflict-driven clause learning (CDCL) solvers based on imitation learning for the Boolean satisfiability problem (SAT). Unlike previous methods that predict instance-level signals to improve CDCL branching indirectly, or rely on reinforcement learning and insufficient CDCL information to enhance branching, ImitSAT learns from expert KeyTrace that collapses a full run into the sequence of surviving decisions. Replaying a KeyTrace on the same instance is nearly conflict-free, providing dense decision-level supervision and directly reducing propagations -- the dominant contributor to wall-clock time. This prefix-conditioned supervision enables ImitSAT to reproduce high-quality branches without exploration, yielding faster convergence, stable training, and seamless integration into CDCL. Extensive experiments demonstrate that ImitSAT reduces propagation counts and runtime, outperforming state-of-the-art learned approaches. We released the source code and trained model at https://github.com/zewei-Zhang/ImitSAT"
        },
        {
            "title": "Start",
            "content": "5 2 0 2 9 2 ] . [ 1 1 1 4 5 2 . 9 0 5 2 : r a"
        },
        {
            "title": "BOOLEAN SATISFIABILITY VIA IMITATION LEARNING",
            "content": "Zewei Zhang1 Huan Liu1 Yuanhao Yu1 1 McMaster University 2 Xian Jiaotong University Jun Chen1 Xiangyu Xu"
        },
        {
            "title": "ABSTRACT",
            "content": "We propose ImitSAT, branching policy for conflict-driven clause learning (CDCL) solvers based on imitation learning for the Boolean satisfiability problem (SAT). Unlike previous methods that predict instance-level signals to improve CDCL branching indirectly, or rely on reinforcement learning and insufficient CDCL information to enhance branching, ImitSAT learns from expert KeyTrace that collapses full run into the sequence of surviving decisions. Replaying KeyTrace on the same instance is nearly conflict-free, providing dense decisionlevel supervision and directly reducing propagationsthe dominant contributor to wall-clock time. This prefix-conditioned supervision enables ImitSAT to reproduce high-quality branches without exploration, yielding faster convergence, stable training, and seamless integration into CDCL. Extensive experiments demonstrate that ImitSAT reduces propagation counts and runtime, outperforming stateof-the-art learned approaches. We released the source code and trained model at https://github.com/zewei-Zhang/ImitSAT."
        },
        {
            "title": "INTRODUCTION",
            "content": "The Boolean satisfiability (SAT) problem is cornerstone of theoretical computer science and artificial intelligence (Cook, 1971; Karp, 1972). Beyond its foundational role, SAT serves as the computational backbone of numerous applications, including formal verification, planning, and combinatorial optimization. Modern solvers for SAT are dominated by the conflict-driven clause learning (CDCL) framework (Silva & Sakallah, 1996; Biere et al., 2009), which has scaled to industrial benchmarks of immense complexity. CDCL run interleaves branching, unit propagation, and conflict analysis. Among these components, the branching rule largely determines the search trajectory, while unit propagation often dominates runtime (Zhang & Malik, 2002; Davis et al., 2008; Moskewicz et al., 2001). As result, more informed branching decisions can translate directly into faster solving. Classical branching heuristics, however, are hand-crafted and limited in their adaptability. Recent work has sought to improve solver performance by integrating learning-based guidance. For example, SATformer (Shi et al., 2023) learns instance-level signals to adjust variable activities during initialization, but it exerts no influence once the branching loop begins. Graph-Q-SAT (Kurin et al., 2020) introduces an online agent within CDCL, yet it relies on reinforcement learning (RL), which requires extensive exploration and can be unstable due to sparse rewards and delayed feedback. Moreover, Graph-Q-SAT does not utilize the full CDCL execution history; each branching is conditioned only on compact graph snapshot of the current state, so the history influences the agent only indirectly. In contrast, we adopt imitation learning, which trains directly from expert traces. Specifically, we introduce ImitSAT, CDCL branching learner trained on expert trace replays. Replaying an expert trace on the same instance is nearly conflict-free, eliminating redundant propagations and providing clean training targets. Since branching is inherently prefix-conditioned, we formulate it as an autoregressive sequence modeling problem, and implement ImitSAT with Transformer-based learner (Vaswani et al., 2017). Our model captures long-context dependencies while keeping runtime costs practical through lightweight autoregressive attention (Hawthorne et al., 2022). To obtain expert traces, we collapse full solver runs into sequences of surviving decisions, yielding dense, step-level supervision at every branching point. This approach enables the learner to reproCorresponding author: xuxiangyu2014@gmail.com duce high-quality decisions without costly exploration, resulting in faster convergence, more stable training, and natural alignment with the prefix-conditioned structure of branching. During inference, ImitSAT reads the instance together with KeyTrace prefix and autoregressively predicts the next signed variable as the branch decision. The policy is queried under small budget, reverting to the native heuristic when uncertain, while all other CDCL components remain unchanged, preserving completeness and robustness. We evaluate ImitSAT on held-out random 3-SAT instances ranging from 5 to 100 variables, as well as on structured families including satisfiable and unsatisfiable instances and non-k-SAT formulas. Under limited query budgets, ImitSAT consistently reduces propagations relative to standard CDCL solver and outperforms prior learning-based methods, SATformer and Graph-Q-SAT, across most settings while matching their performance elsewhere. Wall-clock measurements show that ImitSAT achieves favorable runtime performance against SOTA methods (Shi et al., 2023; Kurin et al., 2020). Remarkably, although trained solely on simple random 3-SAT, ImitSAT transfers effectively to unsatisfiable and non-k-SAT benchmarks without modification. We summarize the contributions of this work as below. We propose ImitSAT, the first branching policy for CDCL solvers based on imitation learning. Unlike prior methods that rely on reinforcement learning, ImitSAT leverages dense, decision-level supervision from expert traces. We cast branching as sequential modeling problem by collapsing solver runs into compact sequences of surviving decisions. These sequences serve as clean, conflict-free training targets and align naturally with prefix-conditioned autoregressive modeling. Extensive experiments demonstrate that ImitSAT yields both practical efficiency and strong generalization."
        },
        {
            "title": "2 RELATED WORKS",
            "content": "Neural guidance for SAT and CDCL. Early learning approaches focused on instance-level prediction, using Graph Neural Network (GNNs) (Scarselli et al., 2008) to classify SAT or UNSAT, as seen in NeuroSAT (Selsam et al., 2019; Selsam & Bjørner, 2019) and (Cameron et al., 2020). Recent work has explored whether Transformers can learn solver behavior directly (Pan et al., 2025). In parallel with these model-based approaches, complementary efforts target data and benchmarking, including G2SAT (You et al., 2019) and G4SATBench (Li et al., 2024). Building on these foundations, second line integrates learning inside solvers to shape specific components: for example, NeuroSelect (Liu et al., 2024) learns clause deletion policies, NeuroBack (Wang et al., 2024) improves phase initialization with GNNs, and RDC-SAT (Zhai & Ge, 2025) adopts divide-andconquer strategy via reinforcement learning. This approach leads to targeted enhancements within solver mechanisms. More concretely, within the CDCL branching loop, several methods exemplify this integration: NeuroSAT (Selsam & Bjørner, 2019) has been used to guide variable selection; Graph-Q-SAT (Kurin et al., 2020) trains an RL agent queried online during search based on instance information; and SATformer (Shi et al., 2023) trains GNN Transformer model to initialize the CDCL that indirectly influences branching thereafter. Imitation learning for control. Imitation learning (IL) learns policies directly from expert demonstrations, that is, sequences of states with associated actions (Osa et al., 2018; Zare et al., 2024). simple example is behavior cloning (BC), which utilizes supervised learning to map observed situations to expert choices (Pomerleau, 1991). Building on the principles of imitation learning, the Decision Transformer (Chen et al., 2021) is similar to behavior cloning, framing reinforcement learning as sequence modeling, where an autoregressive Transformer is trained to predict the next action given sequence rollout of returns, states, and actions. This view connects control to next-token prediction and attains competitive performance without explicit value function learning. The application of imitation learning extends beyond traditional domains. For instance, beyond robotics and games, IL has guided decision-making in exact optimization solvers. In mixed-integer linear programming, policies learned to imitate strong branching can be used within branch-andbound and achieve strong results (Gasse et al., 2019). Related work also learns branching policies that integrate into branch-and-bound (Zarpellon et al., 2021). 2 Figure 1: From CDCL run to KeyTrace. The left pane sketches one run in three stages: (1) decide x4 = , then x3 = , hit conflict, backtrack to the decision on x3; (2) set x3 = , conflict again, backtrack to x4; (3) set x4 = , then decide x1 = and x2 = and solve. Unit assignments are omitted for clarity. Collapsing backtracks removes detours and keeps only the surviving roottocurrent decisions, yielding the compact KeyTrace on the right, which serves as the expert for imitation. step-by-step walkthrough is in Appendix H. Motivated by the limitations of neural guidance for SAT detailed above, and drawing inspiration from imitation learning, we propose ImitSAT. The branching policy for CDCL clones near conflictfree KeyTrace distilled from solver runs. To achieve this, we cast branching as prefix-conditioned sequence prediction and train an autoregressive next-decision model on compact sequences of surviving decisions. This provides dense, decision-level supervision at low per-query cost. These design choices help reduce propagation and improve wall-clock time under small query budgets."
        },
        {
            "title": "3 PRELIMINARIES ON SAT",
            "content": "Boolean Satisfiability Problem. The Boolean satisfiability problem (SAT) is the canonical decision problem in propositional logic. It asks whether Boolean formula over variables x1, . . . , xn can be made true by assigning each variable value in {, }, where denotes true and denotes false. literal is either variable xi or its negation xi. clause is disjunction of literals, Ci = (ℓi,1 ℓi,ki) , and formula is in conjunctive normal form (CNF) (Plaisted & Greenbaum, 1986) if it is conjunction of clauses: (1) = C1 C2 Cm . (2) An assignment is mapping σ : {x1, . . . , xn} {, }. It satisfies clause if at least one literal in the clause evaluates to under σ, and it satisfies the entire formula if every clause is satisfied. We say that is satisfiable (SAT) if such an assignment exists, and unsatisfiable (UNSAT) otherwise. special case is the k-SAT problem, where each clause contains exactly literals. The case = 3 (3-SAT) is of particular importance: it is NP-complete (Karp, 1972) and widely used in theoretical analysis and empirical benchmarks. For example, consider the CNF formula = (x1 x3 x4) (x1 x2 x3) (x2 x3 x4) . This formula is SAT, since the assignment x1 = , x2 = , x3 = , x4 = makes every clause true. If no assignment satisfies all clauses, the instance would be UNSAT. (3) In practice, SAT formulas are often represented in the standard DIMACS CNF format (Johnson & Trick, 1996). In this encoding, each clause is written as sequence of nonzero integers terminated by 0, where the integer denotes variable xi and denotes its negation xi. For the formula in Equation 3, the DIMACS form is: FDIMACS = 1 -3 4 0 -1 2 3 0 -2 -3 -4 0 . This compact numeric encoding is convenient for algorithmic solvers and sequence-based models. (4) 3 Conflict-driven Clause Learning. Conflict-driven clause learning (CDCL) is the dominant algorithmic framework for practical SAT solvers (Silva & Sakallah, 1996; Biere et al., 2009). CDCL solver incrementally explores branching search tree through three fundamental operations: decision (D), where the solver assigns value to chosen literal and thus extends the current partial assignment; unit propagation (A), also known as Boolean Constraint Propagation (BCP) (Moskewicz et al., 2001), where implied literals are deduced from unit clauses; and backtracking (BT), where detected conflict triggers clause learning and non-chronological jump to an earlier decision level. At each decision level, the solver selects decision literal, after which propagation infers additional assignments, possibly none. If clause is falsified, conflict analysis derives new learned clause, identifies its asserting literal, and adds the clause to the solvers database. The solver then backjumps to the highest decision level where the learned clause becomes unit and enqueues the asserting literal. conflict at decision level 0 establishes that the formula is UNSAT, while complete assignment with no conflicts proves SAT. Branching Heuristic and Implementation. Branching is the central operation in CDCL: at each step of the search, the solver selects variable and its polarity to branch on. The quality of these choices is critical. Strong decisions can greatly reduce the number of propagations and conflicts, whereas weak ones may cause the search to grow exponentially. Usually, the choice of the next decision variable, together with its phase, is determined by branching heuristic. The most influential family of heuristics is the Variable State Independent Decaying Sum (VSIDS) (Moskewicz et al., 2001). In VSIDS, variables are assigned activity scores that are increased whenever they appear in learned clauses. These scores are then periodically decayed, ensuring that recently relevant variables are favored for branching. This dynamic prioritization enables the solver to focus on the most promising parts of the search space. notable implementation is MiniSAT (Een & Sorensson, 2003), lightweight and extensible open-source CDCL solver. Despite its minimalistic codebase, MiniSAT has become standard platform for both research and industrial applications due to its clarity and effectiveness."
        },
        {
            "title": "IMITSAT",
            "content": "As reviewed in Section 3, branching plays pivotal role in CDCL: the quality of branching decisions largely determines the efficiency of unit propagation, which is the dominant cost in practice. Traditional heuristics such as VSIDS are highly effective but ultimately hand-crafted, leaving open the possibility of more principled approaches that can exploit structural patterns In this paper, we introduce in solver traces. ImitSAT, framework that leverages expertguided sequence modeling to learn high-quality branching policies for CDCL solvers. Figure 2: Propagation dominates CDCL time. MiniSAT spends about 88.9% in propagation, 9.2% in conflict analysis, and 1.9% in branching. Reducing propagation is therefore the main route to wall-clock gains. Our approach consists of two main components: (i) KeyTrace construction, which compresses solver runs by collapsing backtracks into concise sequence of expert decisions (Section 4.1); and (ii) an autoregressive learner, which imitates the KeyTrace to predict the next branching decision in sequence (Section 4.2). These components are seamlessly integrated into the CDCL framework. Together, they provide clean supervision signals and enable plug-and-play deployment. 4.1 EXPERT KEYTRACE REPLAY We seek an expert that guides the solver toward effective branching decisions while avoiding wasted detours. Raw CDCL trails are often long and contain many decisions that are later undone by backtracking. An ideal expert should preserve only the decisions that survive and discard detours, In thereby yielding clean training targets and eliminating steps that do not advance the search. CDCL, unit propagation dominates runtime, typically accounting for 80%90% of the total solving time (Zhang & Malik, 2002; Davis et al., 2008; Moskewicz et al., 2001), trend we also confirm in Figure 2. This observation suggests that an expert which avoids wasted branches can substantially reduce propagation and thereby improve overall efficiency. In order to extract expert supervision for branching, we first examine the execution trace of CDCL solver. Each run on an instance produces trail, namely chronological sequence of decision, propagation, and backtracking events annotated with decision levels: Tt = ((τ1, λ1, h1), . . . , (τt, λt, ht)) , (5) where τi {D, A, BT} representing decision, unit propagation assignment, or backtrack event, respectively. λi is signed variable with λi {1, . . . , n}. We interpret λi = +j as xj = and λi = as xj = . The value hi is the decision level after the event. Raw trails Tt are often long and contain numerous events that are eventually undone by backtracking. Such redundant segments do not contribute to solving progress, yet they inflate computational cost and inject noise into the context, making it harder to isolate the key decisions that drive the search. To remove these detours, we construct an expert KeyTrace through systematic extraction procedure. Specifically, we scan Tt from left to right while maintaining working sequence that starts empty: For each event (τi, λi, hi) we update . (D, λi, hi), (A, λi, hi), trimhi (K) (D, λi, hi), (6) (7) if τi = D, if τi = A, if τi = BT, where denotes concatenation. The operator trimh removes all suffix events whose level is above h. Restarts are handled by trimming to level 0, i.e., trim0(K). After the scan, the resulting sequence Kt = (8) is taken as the expert KeyTrace for trail Tt. It is worth noting that the above procedure preserves only the decision and propagation events that survive backtracking, effectively collapsing backtracks into prefix truncations while treating restarts as full resets. This results in considerably shorter and more stable trail representation, capturing the minimal necessary context for advancing the search. Empirical evidence demonstrates that replaying the decision sequence encoded in Kt on the same problem instance renders the solvers run nearly conflict-free, drastically reducing the number of propagation events to approximately 4% of those recorded in the raw MiniSAT trail ( see Figure 3). Since propagation constitutes the dominant runtime component of CDCL solvers, this reduction translates directly into significant improvements in solver efficiency. Figure 3: Compact KeyTrace replay. The expert replayed only small share of MiniSAT events: 0.2% conflicts, 19.6% decisions, and 4.3% propagations."
        },
        {
            "title": "4.2 AUTOREGRESSIVE IMITATION FOR CDCL BRANCHING",
            "content": "Given this compact expert KeyTrace, our goal is to train learner that can imitate expert-quality branching decisions. In this setting, the expert demonstrations are provided by KeyTraces: each surviving decision, together with its implied propagations, forms supervised training target. Unlike reinforcement-style exploration, this approach offers dense, step-level supervision and eliminates detours, allowing the learner to acquire high-quality decision policies with faster convergence and greater stability. Formally, since CDCL solver queries one branch at time, the learning task is to map the formula together with KeyTrace prefix Kt to the next signed variable, while operating under small computational budget. This task is inherently sequential, as each decision depends on the prefix of earlier assignments. An autoregressive (AR) model is therefore natural choice, as it conditions on the serialized prefix and predicts the next element in the sequence. To realize this, we first serialize the solver state into compact sequence tailored for autoregression, then specify the AR next-decision learner and its behavior-cloning objective, and finally describe how the learner is integrated into CDCL at inference time. Serialization. To make the AR learner effective, both the CNF and the KeyTrace prefix Kt are serialized into one deterministic sequence. The CNF is written in DIMACS integer format FDIMACS, followed by separator tokens [SEP]. The KeyTrace is then presented as blocks, where each decision literal is followed by the unit assignments produced by propagation. Level fields and assignment tags are omitted for compactness. The sequence ends with decision probe marker [D] that signals request for the next branch. Formally, with Kt = (cid:0)(τ1, λ1, h1), . . . , (τt, λt, ht)(cid:1), enc(Kt) = (cid:13) i=1 (D, di, ai,1, . . . , ai,ki), (cid:13) di, ai,k {1, . . . , n}, and the full serialized input is z(F, Kt) = [CNF] FDIMACS [SEP] enc(Kt) [D]. This compact representation aligns exactly with next-decision prediction for an AR learner. Next-decision AR learner. The learner implements the policy pθ(λnext F, Kt) , λnext {1, . . . , n}, (9) (10) (11) using an AR model defined over z(F, Kt). For generic sequence x1, . . . , xS, the AR factorization is pθ(x1, . . . , xS) = pθ(xs x<s) , (12) (cid:89) where is the index immediately following the decision probe marker [D]. Under this serialization, predicting the next CDCL decision is exactly next-symbol prediction at position s: s=1 pθ(λnext F, Kt) = pθ(xs = λnext x<s = z(F, Kt)) . Training follows the standard behavior cloning paradigm in imitation learning. Let be the set of triples (F, Kt, dt+1). Training minimizes the average negative log-likelihood of the expert decisions: (cid:104) log pθ(dt+1 z(F, Kt)) L(θ) = (13) (14) (cid:88) (cid:105) , 1 (F,Kt,dt+1)Q which is equivalent to cross-entropy at the decision probe positions. In other words, the learner directly imitates the expert policy encoded in the KeyTraces. Online integration into CDCL. At each decision point, the learner is queried under small budget. The current trail is collapsed into the KeyTrace, the instance and prefix are serialized, and the model predicts one signed variable. If the prediction is legal (i.e., within the variable range and currently unassigned), the solver accepts it and decrements the query budget. Otherwise, the solver immediately falls back to VSIDS heuristic. This design preserves completeness and keeps overhead small. front-loaded query schedule is particularly effective, as early decisions strongly shape most of the search as shown in Appendix E. complete Algorithm 1 description is provided in Appendix A."
        },
        {
            "title": "5 EXPERIMENTS",
            "content": "5."
        },
        {
            "title": "IMPLEMENTATION DETAILS",
            "content": "Baselines. We compare against SATformer (Shi et al., 2023) and Graph-Q-SAT (Kurin et al., 2020), which are trained with their public implementations and the training data specified in their papers. CDCL Solver. Python reimplementation of MiniSAT 2.2 (Een & Sorensson, 2003) is used and validated against the official C++ version on full trails Tt. This version streamlines the integration of learning methods, ensuring that all approaches are evaluated in consistent environment. Datasets. We generate the random 3SAT training dataset with planted assignment (Mezard & Montanari, 2009; Achlioptas et al., 2000; 2005). The clausevariable ratio is in [4.1, 4.4]. Variable ranges include 5 to 15, 16 to 30, 31 to 60, and 61 to 100, with additional fixed sizes of 50 and 100. For each formula, MiniSAT run yields the level-annotated trail as Equation 5. Then, the expert KeyTrace is extracted using Equation 7. Every decision position provides one supervision pair, KeyTrace prefix Kt, and its next decision dt+1. For evaluation, we first use the test set, which is drawn from the same generators and variable ranges as those used for training. Generalization is then assessed on different SAT families from SATLIB (Hoos & Stutzle, 2000). Further dataset details appear in Appendix B. AR learner and training. Perceiver AR (Hawthorne et al., 2022) serves as our architecture for predicting the next decision. Specifically, the model uses an output latent array that cross-attends to the input. Since only one output is needed for the next branching, we set the latent length to 1. This results in each query having O(N ) complexity in terms of input length, avoiding the O(N 2) cost associated with standard Transformer decoder. Furthermore, our model configuration follows the recommendations in (Hawthorne et al., 2022). We use 16 attention heads for cross-attention and self-attention, 12 Transformer blocks, an MLP expansion of 4, squared-ReLU activations, and cross-attention dropout 0.1. Metrics. Propagation dominates CDCL time (Zhang & Malik, 2002; Davis et al., 2008; Moskewicz et al., 2001), as seen in Figure 2 and Table 6. We therefore use the number of propagation as the primary signal. Since instances vary in size and difficulty, we normalize by MiniSAT on per-instance basis and aggregate with the median to reduce the influence of outliers. Let pi be the propagation count of the evaluated method on instance Fi, and let ing count for MiniSAT. We report the Median Relative Propagation Percentage (MRPP) be the correspondr = medi=1,...,N (cid:19) , (cid:18) pi values < 1 indicate fewer propagation than MiniSAT and hence an improvement. To capture instance-wise gains, we also report one-percent win rate. With margin δ = 0. Wδ = 1 (cid:88) i: i>0 1 [pi (1 δ) i] . (15) (16) This is the fraction of problems on which the method reduces the propagation number by at least 1% relative to MiniSAT; therefore, larger W1% is better. 5.2 COMPARISON ON TEST SETS We compare ImitSAT with Graph-Q-SAT and SATformer on held-out random 3-SAT. To align wallclock budgets, ImitSAT is queried at 3 or 5 times per instance. Graph-Q-SAT uses the same computational budgets. SATformer updates the VSIDS variable scores once at initialization. We report MRPP and the one percent win rate W1%. Table 1 (top) shows that ImitSAT achieves the lowest MRPP in nearly all ranges. With 3 or 5 calls, it is best on 515, 1630, 3160, 50, 100, and ties SATformer on 61100. These results indicate that 7 Table 1: MRPP () and one percent win ratio W1% () on 3-SAT test sets. GQSAT denotes GraphQ-SAT."
        },
        {
            "title": "Method",
            "content": "515 1630 3160 61100 50 MRPP () W1% () GQSAT-3calls GQSAT-5calls SATformer Ours-3calls Ours-5calls GQSAT-3calls GQSAT-5calls SATformer Ours-3calls Ours-5calls 1.00 1.00 1.00 0.75 0.73 0.45 0.46 0.48 0.68 0.67 0.94 0.90 0.89 0.83 0. 0.53 0.54 0.55 0.65 0.64 0.89 0.82 0.84 0.75 0.75 0.54 0.56 0.58 0.65 0.61 1.15 0.94 0.78 0.78 0.80 0.48 0.53 0.57 0.64 0.59 0.71 0.70 0.88 0.74 0. 0.57 0.59 0.60 0.69 0.64 100 0.85 0.80 0.81 0.76 0.83 0.55 0.58 0.57 0.60 0.56 Table 2: MRPP () and one percent win ratio W1% () on structured SAT families. Metric Method JNH AIM PARITY PHOLE PRET MRPP () W1% () GQSAT-3calls GQSAT-5calls SATformer Ours-3calls Ours-5calls GQSAT-3calls GQSAT-5calls SATformer Ours-3calls Ours-5calls 1.29 1.11 1.36 1.00 0.85 0.38 0.44 0.25 0.44 0.50 1.20 1.18 1.01 0.88 0.81 0.31 0.38 0.44 0.63 0.63 0.82 0.56 0.73 0.30 0.30 0.80 0.80 0.60 0.80 0. 1.03 0.82 1.00 1.00 0.82 0.50 0.75 0.00 0.50 0.75 0.88 0.92 1.00 0.42 0.42 0.50 0.50 0.00 1.00 1.00 imitation of the expert, as demonstrated by KeyTrace, consistently reduces propagation under small query budgets. Building on these MRPP results, Graph-Q-SAT increases propagation number on the 61-100 dataset, indicating weaker guidance under the same budget. Finally, in Table 1 (bottom), we report W1% to show instance-wise gains. ImitSAT with 3 calls achieves the highest win rate in all ranges. 5.3 GENERALIZATION ON SPECIAL SAT FAMILIES In this section, we assess the ability to transfer to structured families that differ from the training generator, covering SAT and UNSAT, 3-SAT, and non-k-SAT, without any retraining or tuning. Query budgets match the test sets, with 3 or 5 calls per instance for ImitSAT and Graph-Q-SAT, whereas SATformer adjusts the VSIDS variable scores only once at initialization. Across all families, ImitSAT attains the lowest MRPP or ties for best as shown in Table 2 (top). The gains are large on PARITY and PRET, and with 5 calls ImitSAT is best on JNH and AIM, and matches the best on PHOLE. Graph-Q-SAT does not reduce propagation number on JNH and AIM, and in fact increases the propagation number. SATformer only shows gain on the PARITY dataset; all other datasets exhibit no gain or worse performance than MiniSAT. Table 2 (bottom) reports the W1%. ImitSAT achieves the highest or tied win rate on all families, including perfect score on PRET and matching the best on PARITY and PHOLE. These outcomes indicate that imitation of the expert KeyTrace transfers from random 3-SAT to structured regimes without finetuning."
        },
        {
            "title": "5.4 WALL-CLOCK TIME",
            "content": "To measure practical impact, end-to-end solve time is recorded for each instance. The timer starts when the CDCL solve loop begins and stops when the instance is solved; CNF parsing and simImitSAT and plification are excluded from the timing. All model inference costs are included. Graph-Q-SAT receive 3 calls per instance to match compute budgets. SATformer adjusts VSIDS variable scores once at initialization. Across random 3-SAT test sets and structured families, ImitSAT traces the lowest curves under these budgets, which means more instances are solved in less time, as shown in Figure 4. Learning model-based branching introduces query overhead, so wall-clock gains appear only once propagation savings exceed this cost. Figure 4: Wall-clock time versus instances solved on random test sets and structured families. Curves show end-to-end solver time per instance with all model calls included and preprocessing excluded. ImitSAT and Graph-Q-SAT use 3 calls per instance. SATformer performs single VSIDS initialization. The lower curve is better. 5.5 IMPROVED TRAINING TECHNIQUES We observe that ImitaSAT is prone to overfitting. To address this issue, we introduce improved training techniques. First, we apply variable permutation augmentation, where variable IDs are randomly permuted when forming training examples. As shown in Figure 5, both training and validation losses decay steadily with augmentation, whereas without augmentation the validation loss peaks early and then rises despite continued decrease in training loss. Second, we employ staged curriculum learning strategy that gradually expands the variable range from small to large (Nagatsuka et al., 2021; Pouransari et al., 2024). This accelerates convergence on simple instances while ensuring comprehensive coverage of larger problem sizes. More details for variable permutation augmentation and curriculum learning are provided in Appendix and G."
        },
        {
            "title": "6 CONCLUSION",
            "content": "We presented ImitSAT, CDCL branching policy based on imitation learning. By collapsing solver runs into compact sequences of surviving decisions, we obtain expert traces that capture high-quality branching behavior. These traces allow us to formulate branching as an autoregressive prediction problem, yielding dense, conflict-free supervision that enables stable and efficient training. Extensive experiments show that ImitSAT reduces propogations, achieves favorable runtime, and generalizes well beyond 3-SAT, outperforming prior learning-based methods. Future work could extend this approach to richer expert demonstrations, hybrid imitationreinforcement learning schemes, or broader domains of combinatorial reasoning."
        },
        {
            "title": "REFERENCES",
            "content": "Dimitris Achlioptas, Carla Gomes, Henry Kautz, and Bart Selman. Generating satisfiable problem instances. In Proceedings of the AAAI/IAAI Conference, pp. 256261, 2000. Dimitris Achlioptas, Haixia Jia, and Cristopher Moore. Hiding satisfying assignments: two are better than one. Journal of Artificial Intelligence Research, 24:623639, 2005. Yuihci Asahiro, Kazuo Iwama, and Eiji Miyano. Random generation of test instances with controlled attributes. DIMACS Series in Discrete Mathematics and Theoretical Computer Science, pp. 377 393, 1996. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of satisfiability, volume 185. IOS press, 2009. Chris Cameron, Rex Chen, Jason Hartford, and Kevin Leyton-Brown. Predicting propositional satisfiability via end-to-end learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 33243331, 2020. Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling. In Advances in Neural Information Processing Systems, volume 34, pp. 1508415097, 2021. Stephen Cook. The complexity of theorem-proving procedures. In Proceedings of the third annual ACM symposium on Theory of computing, pp. 151158, 1971. John Davis, Zhangxi Tan, Fang Yu, and Lintao Zhang. practical reconfigurable hardware accelerator for boolean satisfiability solvers. In Proceedings of the 45th annual Design Automation Conference, pp. 780785, 2008. Niklas Een and Niklas Sorensson. An extensible sat-solver. In International conference on theory and applications of satisfiability testing, pp. 502518. Springer, 2003. Maxime Gasse, Didier Chetelat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi. Exact combinatorial optimization with graph convolutional neural networks. In Advances in Neural Information Processing Systems, volume 32, 2019. Armin Haken. The intractability of resolution. Theoretical computer science, 39:297308, 1985. Curtis Hawthorne, Andrew Jaegle, Catalina Cangea, Sebastian Borgeaud, Charlie Nash, Mateusz Malinowski, Sander Dieleman, Oriol Vinyals, Matthew Botvinick, Ian Simon, et al. Generalpurpose, long-context autoregressive modeling with perceiver ar. In International Conference on Machine Learning, pp. 85358558. PMLR, 2022. Holger H. Hoos and Thomas Stutzle. SATLIB: An online resource for research on SAT. In I. P. Gent, H. van Maaren, and T. Walsh (eds.), SAT 2000, pp. 283292. IOS Press, 2000. SATLIB is available online at http://www.satlib.org. David S. Johnson and Michael A. Trick (eds.). Cliques, Coloring, and Satisfiability: The Second DIMACS Implementation Challenge, volume 26 of DIMACS Series in Discrete Mathematics and Theoretical Computer Science. American Mathematical Society, 1996. Richard M. Karp. Reducibility among combinatorial problems. In Raymond E. Miller, James W. Thatcher, and Jean D. Bohlinger (eds.), Complexity of Computer Computations, The IBM Research Symposia Series, pp. 85103. Springer, Boston, MA, 1972. doi: 10.1007/ 978-1-4684-2001-2 9. Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Can q-learning with graph networks learn generalizable branching heuristic for sat solver? In Advances in Neural Information Processing Systems, pp. 96089621, 2020. Zhaoyu Li, Jinpei Guo, and Xujie Si. G4satbench: Benchmarking and advancing sat solving with graph neural networks. Transactions on Machine Learning Research, 2024. 10 Hongduo Liu, Peng Xu, Yuan Pu, Lihao Yin, Hui-Ling Zhen, Mingxuan Yuan, Tsung-Yi Ho, and Bei Yu. Neuroselect: Learning to select clauses in sat solvers. In Proceedings of the 61st ACM/IEEE Design Automation Conference, pp. 16, 2024. Marc Mezard and Andrea Montanari. Information, physics, and computation. Oxford University Press, 2009. Matthew Moskewicz, Conor Madigan, Ying Zhao, Lintao Zhang, and Sharad Malik. Chaff: Engineering an efficient sat solver. In Proceedings of the 38th annual Design Automation Conference, pp. 530535, 2001. Koichi Nagatsuka, Clifford Broni-Bediako, and Masayasu Atsumi. Pre-training bert with curriculum learning by increasing block-size of input text. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021), pp. 989996, 2021. Takayuki Osa, Joni Pajarinen, Gerhard Neumann, Andrew Bagnell, Pieter Abbeel, Jan Peters, et al. An algorithmic perspective on imitation learning. Foundations and Trends in Robotics, 7(1-2): 1179, 2018. Leyan Pan, Vijay Ganesh, Jacob Abernethy, Chris Esposo, and Wenke Lee. Can transformers reason logically? study in SAT solving. In International Conference on Machine Learning, 2025. URL https://openreview.net/forum?id=5BGC2I2fxx. David Plaisted and Steven Greenbaum. structure-preserving clause form translation. Journal of Symbolic Computation, 2(3):293304, 1986. Dean Pomerleau. Efficient training of artificial neural networks for autonomous navigation. Neural computation, 3(1):8897, 1991. Hadi Pouransari, Chun-Liang Li, Jen-Hao Chang, Pavan Kumar Anasosalu Vasu, Cem Koc, Vaishaal Shankar, and Oncel Tuzel. Dataset decomposition: Faster llm training with variable sequence In Advances in Neural Information Processing Systems, volume 37, pp. length curriculum. 3612136147, 2024. Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE transactions on neural networks, 20(1):6180, 2008. Bart Selman, David Mitchell, and Hector Levesque. Generating hard satisfiability problems. Artificial intelligence, 81(1-2):1729, 1996. Daniel Selsam and Nikolaj Bjørner. Guiding high-performance sat solvers with unsat-core predictions. In International conference on theory and applications of satisfiability testing, pp. 336353. Springer, 2019. Daniel Selsam, Matthew Lamm, Benedikt Bunz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning SAT solver from single-bit supervision. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=HJMC_iA5tm. Zhengyuan Shi, Min Li, Yi Liu, Sadaf Khan, Junhua Huang, Hui-Ling Zhen, Mingxuan Yuan, and Qiang Xu. Satformer: Transformer-based unsat core learning. In 2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD), pp. 14. IEEE, 2023. JP Marques Silva and Karem Sakallah. Grasp-a new search algorithm for satisfiability. In Proceedings of International Conference on Computer Aided Design, pp. 220227. IEEE, 1996. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, In Advances in Neural InforŁukasz Kaiser, and Illia Polosukhin. Attention is all you need. mation Processing Systems, volume 30, 2017. Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth McMillan, and Risto Miikkulainen. Neuroback: Improving CDCL SAT solving using graph neural networks. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview. net/forum?id=samyfu6G93. 11 Joost Warners and Hans Van Maaren. two-phase algorithm for solving class of hard satisfiability problems. Operations research letters, 23(3-5):8188, 1998. Jiaxuan You, Haoze Wu, Clark Barrett, Raghuram Ramanujan, and Jure Leskovec. G2sat: Learning In Advances in Neural Information Processing Systems, volume 32, to generate sat formulas. 2019. Maryam Zare, Parham Kebria, Abbas Khosravi, and Saeid Nahavandi. survey of imitation learning: Algorithms, recent developments, and challenges. IEEE Transactions on Cybernetics, 2024. Giulia Zarpellon, Jason Jo, Andrea Lodi, and Yoshua Bengio. Parameterizing branch-and-bound In Proceedings of the AAAI Conference on Artificial search trees to learn branching policies. Intelligence, volume 35, pp. 39313939, 2021. Shumao Zhai and Ning Ge. Learning splitting heuristics in divide-and-conquer SAT solvers with reinforcement learning. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=uUsL07BsMA. Lintao Zhang and Sharad Malik. The quest for efficient boolean satisfiability solvers. In International conference on computer aided verification, pp. 1736. Springer, 2002."
        },
        {
            "title": "A ALGORITHM",
            "content": "The integration of the CDCL and ImitSAT is shown in Algorithm 1. level-annotated trail as in Equation 5 return UNSAT Algorithm 1 Online CDCL branch with ImitSAT. Require: CNF , learner pθ, total query budget Ensure: terminal outcome (SAT/UNSAT) or next branching decision λnext 1: 2: Tt CURRENTTRAIL() 3: if CONFLICTATLEVELZERO(Tt) then 4: 5: end if 6: if ALLASSIGNED(Tt) then 7: 8: end if 9: Kt EXTRACTKEYTRACE(Tt) 10: if > 0 then 1 11: λnext arg maxλ pθ(λ z(F, Kt)) 12: if LEGAL(λnext; F, Tt) then 13: 14: 15: 16: end if 17: return VSIDS(F, Tt) return λnext return SAT end if collapse backtracks, Equation 7 consume one model query unassigned and within the variable range fallback decision"
        },
        {
            "title": "B DATASETS",
            "content": "This section details the training corpus, held-out test sets, and the structured SAT families used in evaluation. For the synthetic data, both train and test, all instances are random 3-SAT with planted assignment and clausevariable ratio in [4.1, 4.4] (Mezard & Montanari, 2009; Achlioptas et al., 2000; 2005). We categorize instances by the number of variables nv to control difficulty and balance the number of decision probes contributed by each category. Since larger nv produces longer trails and thus more supervision per instance, we allocate fewer instances at larger nv. This ensures each bucket contributes similar amount of training signal. We define buckets as ranges of variable counts (e.g., 515), with each bucket grouping instances by the number of variables nv they contain. Training dataset. Counts denote the number of CNF instances per bucket. Table 3: Training buckets for random 3-SAT with planted assignment. Bucket (variables nv) 515 1630 3160 61100 50 100 # Instances 2,000,000 1,000,000 500,000 100,000 1,000,000 100, Held-out test buckets. To keep evaluation time reasonable, we use fewer instances at larger nv. For nv=100, we increase the sample size to reduce variance. 13 Table 4: Held-out test buckets for random 3SAT. Bucket (variables nv) 515 1630 3160 61100 50 100 # Instances 5,000 5,000 1,000 100 100 Structured families from SATLIB. To assess cross-distribution generalization, we evaluate on classic structured benchmarks from SATLIB (Hoos & Stutzle, 2000). The suite spans both SAT and UNSAT, and includes 3-SAT and nonkSAT regimes. Specifically, we use AIM (Asahiro et al., 1996), which is equivalent to 3-SAT, focusing on the nv = 100 SAT portion. We also consider the SAT subset of JNH (Selman et al., 1996) with nv = 100 and PARITY (Warners & Van Maaren, 1998; Hoos & Stutzle, 2000) in the compressed series, both as structured SAT families distinct from our random generator. Additionally, PRET (Johnson & Trick, 1996; Hoos & Stutzle, 2000) is two-coloring UNSAT problem with nv = 60, and the pigeonhole principle (PHOLE) (Haken, 1985) is used as nonkSAT and UNSAT stress test. All subsets described above are considered with nv 100. Table 5 lists the families. Table 5: The structured families referenced in our generalization experiments are all sourced from SATLIB. Family AIM JNH PARITY PHOLE PRET kSAT ? SAT/UNSAT 3SAT nonkSAT nonkSAT nonkSAT nonkSAT SAT SAT SAT UNSAT UNSAT"
        },
        {
            "title": "C CDCL RUNTIME BREAKDOWN",
            "content": "To quantify the main cost drivers in CDCL, we instrument the Python MiniSAT on the 61100 test range and time each major component. Table 6 and Figure 2 show that propagation accounts for about 89% of the mean runtime, conflict analysis for about 9%, and decision selection for under 2%. Reducing needless propagation is therefore the most direct path to wall-clock gains. Table 6: The CDCL runtime breakdown on the 61100 test set. Propagation dominates the runtime, motivating metrics and methods that reduce propagation. Event mean ms median ms share of mean % Propagation Conflict Decision 65.624 6.809 1.400 38.378 3.999 0.975 88.88 9.22 1."
        },
        {
            "title": "D KEYTRACE REPLAY",
            "content": "We confirm KeyTrace is suitable expert because replaying it yields near conflict-free run with far fewer propagations. To demonstrate its effectiveness, for each instance, we replay the extracted KeyTrace by applying its decisions in order and running unit propagation after each step. As shown in Table 7 and Figure 3, the event counts during the KeyTrace replay can be compared to those of the 14 original MiniSAT run. Notably, conflicts are essentially eliminated, decisions drop by about 80%, and propagations fall to roughly 4% of the MiniSAT total. Together, these results support using KeyTrace as the expert for behavior cloning: it isolates the surviving branch sequence and removes the detours that drive most propagation. Table 7: Effect of KeyTrace replay on the 61100 range. Means over instances and the share relative to MiniSAT. Replay is nearly conflict-free and uses only small fraction of propagation."
        },
        {
            "title": "Event",
            "content": "MiniSAT mean KeyTrace mean KeyTrace as % of MiniSAT"
        },
        {
            "title": "Conflict\nDecision\nPropagation",
            "content": "71.96 103.94 1474.64 0.11 20.38 62.74 0.15% 19.61% 4.25%"
        },
        {
            "title": "E EARLY DECISIONS SHAPE CDCL",
            "content": "This section examines whether the time at which the model is queried affects the overall search. On the 515 test set, we compare two 1-call schedules under identical compute budgets: (1) query ImitSAT at the first branching decision, or (2) make three VSIDS decisions before querying ImitSAT once. All other decisions use the native VSIDS heuristic. We report MRPP and the 1% win rate W1%. Table 8 shows that delaying the single query (2) does not reduce propagations and greatly lowers the win rate. In contrast, front-loaded query (1) improves both metrics. This supports allocating the model budget to early decisions, as they significantly shape the search. Table 8: Early guidance is more effective. One model call on the 515 test set. Front-loading the call at the first decision yields larger gains than delaying it. Method call after 3 VSIDS call at first decision () 1.00 0. W1% () 0.27 0."
        },
        {
            "title": "F VARIABLE PERMUTATION AUGMENTATION",
            "content": "Permutation augmentation is designed to mitigate overfitting and enhance the robustness of the learner. We train models on 515 variables for 20 epochs, or about 300k steps. Figure 5 plots the training and validation losses. With permutation augmentation, the two curves track each other and decay steadily. Without augmentation, the training loss continues to decrease, while the validation loss peaks early and then rises, classic sign of overfitting to variable identities. The aggregate metrics confirm this, as in Table 9 that removing permutation leads to higher MRPP and low win rate, whereas the augmented model achieves strong MRPP and much higher win rate W1%. The slightly higher training loss under augmentation is expected, as the task is more challenging; however, the gain is evident in generalization. Table 9: Effect of variable-permutation augmentation. Models trained on 515 for 20 epochs. Augmentation prevents overfitting and improves test set metrics. Method w/o permutation w/ permutation () 1.00 0. W1% () 0.28 0.64 15 Figure 5: Training and validation loss curves with and without variable-permutation augmentation on the 515 range for 20 epochs. Permutation keeps training and validation closely aligned and prevents overfitting, while removing it lowers training loss but drives validation loss up."
        },
        {
            "title": "G STAGED CURRICULUM ACROSS VARIABLE RANGES",
            "content": "The staged curriculum is designed to accelerate learning and maintain competence across wide range of variables (Nagatsuka et al., 2021; Pouransari et al., 2024). The curriculum trains on 515 for 20 epochs, then continues on 1630 for 4 epochs, about 130k steps in the second stage. Two baselines are used on 1630 without any curriculum. The first matches the second-stage budget by only about 130k steps. The second uses total of 430k steps that match the curriculum training steps. Table 10 summarizes the results. At the matched 130k steps budget on 1630, the staged model achieves much lower and higher W1% than training the model w/o stage from scratch; this shows clear sample efficiency. When step counts are fully matched as w/o stage*, training from scratch on 1630 narrows the gap and slightly edges out the staged model in that range. This suggests that the primary benefit of the curriculum is faster and more stable convergence, rather than better performance. Crucially, when the curriculum progresses through all stages, it preserves strong performance on 515, whereas models trained only on 1630 fail to generalize to smaller instances. Table 10: Stage-training ablation. Ours uses curriculum that trains on 515 for 300k steps, then continues on 1630 for 130k steps. The w/o stage trains only on 1630 with the same second-stage budget, about 130k steps. And w/o stage* trains only on 1630 with total of about 430k steps that matches the overall curriculum steps. Curriculum improves sample efficiency and yields better coverage of the 515 range. Method 5-15 () 5-15 W1% () 16-30 () 16-15 W1% () w/o stage w/o stage* w/ stage 1.00 1.00 0.75 0.05 0.43 0.67 1.00 0.80 0. 0.49 0.66 0."
        },
        {
            "title": "H KEYTRACE EXAMPLE",
            "content": "This section walks through Figure 1 on an example instance, showing short CDCL run and how it collapses into KeyTrace. Consider the CNF over x1, x2, x3, x4, = (x1 x2 x3) (x4 x2 x3) (x1 x3 x4 x2) (x3 x1 x4) (x3 x4 x2) (x2 x4 x3). (17) 16 One CDCL trail. CDCL run interleaves decisions (D), unit propagations (A), and backtracks (BT), each annotated with the decision level. One plausible trail is = (cid:0)(D, +4, 1), (D, +3, 2), (BT, 3, 1), (BT, 4, 0), (D, +1, 1), (D, +2, 2), (A, 3, 2) (cid:1) (18) It can be read in three stages, matching the left panel of Figure 1. Stage 1: branch x4 = , then x3 = ; conflict is reached and the solver backtracks, forcing x3 = at lower level. Stage 2: second conflict occurs and the run backtracks to level 0, flipping the earlier choice to x4 = . Stage 3: branch x1 = and x2 = ; unit propagation assigns x3 = , and all clauses are satisfied, so is declared SAT. Collapsing to KeyTrace. Applying the extraction rule in Equation 7 trims away backtracked suffixes and keeps only the surviving roottocurrent decisions. For the trail above, the resulting expert KeyTrace is = (cid:0)(BT, 4, 0), (D, +1, 1), (D, +2, 2), (A, 3, 2)(cid:1), (19) i.e., the final branch x4 = x1 = x2 = and then propagate x3 = shown in the right panel of Figure 1. Replaying on the same instance with unit propagation between steps is nearly conflict-free and avoids the detours taken in the original run, which is why KeyTrace provides clean targets for imitation. LARGE LANGUAGE MODELS (LLMS) USAGE STATEMENT We used LLMs as general-purpose assistants to scaffold small analysis or plotting scripts, suggest debugging tips, and polish wording. All technical ideas, algorithms, model designs, experiments, and reported results are the sole responsibility of the authors. LLM outputs were reviewed and edited for correctness and clarity. No proprietary data were provided to LLMs, and LLMs are not authors."
        },
        {
            "title": "J ETHICS STATEMENT",
            "content": "This work uses procedurally generated SAT instances and public SATLIB benchmarks; no human subjects or personally identifiable information are involved. The research poses minimal foreseeable risks to society. We will release code and models under permissive license to encourage transparent and responsible use."
        },
        {
            "title": "K REPRODUCIBILITY STATEMENT",
            "content": "We will release the following: (i) pretrained models; (ii) our Python reimplementation of MiniSAT 2.2, as well as the integration code for ImitSAT; (iii) training code, including all hyperparameters; (iv) generators for random planted 3-SAT data, along with the exact train/test datasets; and (v) environment specifications. The dataset definitions and splits are detailed in Appendix B."
        },
        {
            "title": "L LIMITATIONS",
            "content": "The study was limited by computational resources, as all models were trained on four V100 GPUs, which restricted both model size and training duration. To address these constraints, staged curriculum learning was used to accelerate training. With greater access to GPUs, it would be possible to train models for longer periods on larger datasets and scale model size, potentially leading to improvements in imitation quality and wall-clock performance."
        }
    ],
    "affiliations": [
        "McMaster University",
        "Xian Jiaotong University"
    ]
}