{
    "paper_title": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI",
    "authors": [
        "Ranjan Sapkota",
        "Konstantinos I. Roumeliotis",
        "Manoj Karkee"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "This review presents a comprehensive analysis of two emerging paradigms in AI-assisted software development: vibe coding and agentic coding. While both leverage large language models (LLMs), they differ fundamentally in autonomy, architectural design, and the role of the developer. Vibe coding emphasizes intuitive, human-in-the-loop interaction through prompt-based, conversational workflows that support ideation, experimentation, and creative exploration. In contrast, agentic coding enables autonomous software development through goal-driven agents capable of planning, executing, testing, and iterating tasks with minimal human intervention. We propose a detailed taxonomy spanning conceptual foundations, execution models, feedback loops, safety mechanisms, debugging strategies, and real-world tool ecosystems. Through comparative workflow analysis and 20 detailed use cases, we illustrate how vibe systems thrive in early-stage prototyping and education, while agentic systems excel in enterprise-grade automation, codebase refactoring, and CI/CD integration. We further examine emerging trends in hybrid architectures, where natural language interfaces are coupled with autonomous execution pipelines. Finally, we articulate a future roadmap for agentic AI, outlining the infrastructure needed for trustworthy, explainable, and collaborative systems. Our findings suggest that successful AI software engineering will rely not on choosing one paradigm, but on harmonizing their strengths within a unified, human-centered development lifecycle."
        },
        {
            "title": "Start",
            "content": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee Cornell University, Department of Biological and Environmental Engineering, USA University of the Peloponnese, Department of Informatics and Telecommunications, Tripoli, Greece Corresponding authors: rs2672@cornell.edu, mk2684@cornell.edu 5 2 0 2 6 2 ] . [ 1 3 4 4 9 1 . 5 0 5 2 : r AbstractThis review presents comprehensive analysis of two emerging paradigms in AI-assisted software development: vibe coding and agentic coding. While both leverage large language models (LLMs), they differ fundamentally in autonomy, architectural design, and the role of the developer. Vibe coding emphasizes intuitive, human-inthe-loop interaction through prompt-based, conversational workflows that support ideation, experimentation, and creative exploration. In contrast, agentic coding enables autonomous software development through goal-driven agents capable of planning, executing, testing, and iterating tasks with minimal human intervention. We propose detailed taxonomy spanning conceptual foundations, execution models, feedback loops, safety mechanisms, debugging strategies, and real-world tool ecosystems. Through comparative workflow analysis and 20 detailed use cases, we illustrate how vibe systems thrive in early-stage prototyping and education, while agentic systems excel in enterprise-grade automation, codebase refactoring, and CI/CD integration. We further examine emerging trends in hybrid architectures, where natural language interfaces are coupled with autonomous execution pipelines. Finally, we articulate future roadmap for agentic AI, outlining the infrastructure needed for trustworthy, explainable, and collaborative systems. Our findings suggest that successful AI software engineering will rely not on choosing one paradigm, but on harmonizing their strengths within unified, human-centered development lifecycle. Index TermsAgentic AI, Vibe Coding, Code Generation, Autonomous Agents, Developer Tools, Software Engineering, LLMs, AI Code Assistants. I. INTRODUCTION Vibe coding refers to novel, emergent mode of software development in which the human programmer (1a) operates less as direct implementer of code and more as high-level coordinator who collaborates with LLMs through iterative prompting and strategic direction [1]. Coined by Andrej Karpathy Andrej Karpathy Wiki Page ,1, 2, in both mindset and methodology, where developers communicate desired outcomes the vibe via natural language instructions, conceptual overviews, and progressive refinements, rather than by specifying logic in syntactic detail. Unlike traditional paradigms, which emphasize mastery over syntax [2][4] and low-level operations [5][7], the term captures shift Fig. 1: Bird-eye-figure showing comparative illustration of (a) Vibe Coding, where human developer uses Natural Language to guide Code Generation followed by Manual Testing, and (b) Agentic Coding, where an AI agent performs Autonomous Actions within an execution Environment, enabling Independent Tests. This highlights key differences in input modality, execution autonomy, and testing workflow between the two paradigms. vibe coding reorients the focus toward intent specification, architectural vision, and interactive debugging [1]. At its core, vibe coding integrates principles from prompt engineering, agile design, and human-AI co-creation, while abstracting much of the linguistic burden onto the LLM [8]."
        },
        {
            "title": "This interactional",
            "content": "loop of guidance, AI response, human evaluation, and corrective feedback yields dynamic coding process that is simultaneously expressive, generative, and improvisational. It invites the question: can the act of software engineering become more intuitive, collaborative, and aligned with human reasoning, rather than merely transcription of formal logic into text? Vibe coding attempts to answer in the affirmative proposing new semiotic contract between the human mind and generative machines. The rise of vibe coding parallels the rapid advancement of foundation models and the growing availability of LLM-based development platforms like ChatGPT [9], Replit Replit AI, and Cursor CURSOR. Traditional software engineering emphasized rigid syntax [10][12], algorithmic structure [13], [14], and deterministic logic [15], [16]. In contrast, LLMs now allow developers to produce coherent, context-aware code using natural language transforming code creation into dialogue with the machine [17], [18]. Karpathys notion of embracing exponentials reflects this paradigm shift, where scale, abstraction, and expressiveness redefine programming practice Andrej Karpathy, Notion. While vibe coding represents leap in developer productivity and human-AI interaction, agentic coding signifies more advanced and autonomous evolution of AI-assisted programming. At its core, agentic coding (Figure 1b) is grounded in the deployment of agentic AI systems software agents capable of independently interpreting high-level goals, decomposing tasks into subtasks, planning execution strategies, and adapting behavior based on real-time feedback and outcomes [19], [20]. Unlike the prompt-response dynamic of vibe coding, agentic coding minimizes the need for continuous human oversight. It introduces paradigm wherein AI agents can initiate action, access tools and APIs, retrieve and process external data, and iteratively refine outputs through cycles of self-evaluation. These agents exhibit hallmark capabilities of agency, including intentionality, forethought, and adaptivity aligning with definitions proposed in cognitive systems and artificial general intelligence research. This level of autonomy enables agentic coding systems to tackle complex, multistep workflows, making them suitable for process automation, business operations, and dynamic, data-driven environments. Architecturally, agentic coding employs reinforcement learning and modular planning [21], often integrating specialized subagents that collaborate to complete broader missions [22]. In contrast to vibe codings focus on expressiveness and flow, agentic coding is outcome-oriented, resilient, and self-directed. If vibe coding equips developers with high-speed copilot, agentic coding gives them an intelligent collaborator capable of independently steering the aircraft. This distinction underscores not merely difference in tools, but fundamental rethinking of how software is authored, executed, and evolved. in the underlying assumptions about Understanding the distinction between vibe coding and agentic coding is crucial for navigating the future landscape of AI-assisted software development. These paradigms differ not just in their technical mechanisms, but the role of the human developer, the locus of agency, and the nature of control in the coding process. Vibe coding maintains human-centric model, where the developer is an ever-present conductor guiding the AIs output model well-suited to creative ideation, exploratory development, and rapid iteration. Agentic coding, on the other hand, introduces AI agents as semi-autonomous collaborators, shifting the human role to that of supervisor who defines goals and evaluates outcomes. it reconfigures This shift has profound implications: workflows, challenges traditional notions of authorship and accountability, and necessitates new interfaces for monitoring, debugging, and aligning agent behavior with human intent. Moreover, the increasing prevalence of agentic systems raises critical questions around safety, reliability, and trustworthiness in software generated or managed with minimal human oversight. As organizations, developers, and researchers embrace these technologies, dynamic understanding of the boundaries, affordances, and use cases of each paradigm becomes essential. By developing formal taxonomy of vibe coding and agentic coding as this paper aims to do we not only chart the evolution of AI in programming but also lay the groundwork for better tooling, clearer expectations, and more robust human-AI collaboration in both current and future systems. II. CONCEPTUAL FOUNDATIONS A. Vibe Coding: Code Generation Intuition-Driven, Developer-Centric Vibe Coding, term popularized by Andrej Karpathy Andrej Karpathy, describes software development methodology centered on the developers intuitive expression of intent to an LLM, which then acts as highly responsive co-pilot in generating code. The vibe refers to the desired outcome, functionality, or even the aesthetic feel of software component, which the developer communicates, often through natural language, for the LLM to translate into executable code. This paradigm fundamentally alters the traditional coding process by abstracting significant portions of syntactical detail and boilerplate, allowing developers to focus on higher-level design and rapid iteration. 1) The Semiotics of Vibe Coding: At its core, Vibe Coding introduces new semiotic layer in programming [23], [24]. Traditionally, developers use programming languages as direct, formal means of instructing computer [25][27]. In Vibe Coding, natural language, high-level descriptions, and even examples or visual mock-ups serve as primary inputs to an intermediary intelligent system (the LLM) [28]. The LLM, in turn, interprets these multi-modal signs and synthesizes corresponding formal code [29], [30]. This process is not one-way translation but an iterative dialogue. The developer provides an initial prompt; the LLM generates code artifact; the developer reviews, critiques, and refines the prompt or directly edits the code, continuing the cycle until the desired vibe is achieved [31], [32]. This iterative refinement loop is defining characteristic, reflecting co-constructive model of meaning-making between human and machine [33]. Fig. 2: Fundamental Skills and Cognitive Shifts in Vibe Coding. This diagram illustrates the five core competencies Thinking, Framework, Checkpoints, Debugging, and Context that enable effective collaboration with LLMs. Together, they represent cognitive shift from syntaxheavy implementation to high-level conceptual guidance and iterative co-creation with AI agents. 2) Fundamental Skills and Cognitive Shifts: Philosophically, Vibe Coding empowers the developer by augmenting their cognitive capabilities. It offloads the burden of low-level implementation details, allowing for greater focus on creative problem-solving, user experience design, and system architecture. The vibe is thus not merely an aesthetic preference but holistic representation of the developers intent, encompassing functionality, usability, and design. Effective Vibe Coding necessitates shift in developer skills, emphasizing conceptual articulation and strategic interaction over rote memorization of syntax [34], [35]. The five fundamental skills are as illustrated in Figure 2 and each skills are explained below: the LLM. Thinking (Strategic Problem Formulation): This involves multi-layered approach to defining the It begins with Logical problem for Thinking (the core what) [36], [37], progresses to Analytical Thinking (how users interact, highlevel components) [38][40], then to Computational Thinking [41] (structuring the problem into modules, rules, and data flows understandable by the AI) [42], [43], and finally to Procedural Thinking (considering optimal execution, best practices, and detailed features) [44], [45]. well-crafted Product Requirements Document (PRD) often emerges from this rigorous thinking process, serving as detailed contextual blueprint for the LLM. Framework (Architectural Awareness): While the LLM handles much of the implementation, the developer must possess an awareness of relevant software frameworks (e.g., React, Node.js, Django), libraries, and architectural patterns [46]. This knowledge allows the developer to guide the LLM towards using appropriate, robust, and industry-standard technologies, thereby constraining the solution space and improving code quality and maintainability [47]. The developer can also learn about new frameworks by querying the LLM for recommendations based on project requirements. Checkpoints (Version Control): Given the generative and sometimes unpredictable nature of LLM outputs, robust version control (e.g., Git) is paramount. Frequent commits create save points, enabling developers to revert to stable states if AI-generated code introduces errors or undesirable changes. Branching allows for safe experimentation imwith different AI-generated features without pacting the main codebase [48], [49]. This ensures safety net for the rapid, iterative cycles inherent in Vibe Coding. Debugging (Collaborative Error Resolution): Errors are inevitable. In Vibe Coding, debugging becomes collaborative process [50], [51]. The developer identifies an issue (runtime error, logical flaw, UI discrepancy) and then provides the LLM with rich context error messages, relevant code snippets, descriptions of expected vs. actual behavior, and sometimes screenshots [52], [53]. The LLM can then assist in diagnosing the problem and suggesting or implementing fixes. Human oversight is critical to guide this process and validate the AIs solutions. Context (Information Provision): The efficacy of Vibe Coding is directly proportional to the quality and comprehensiveness of the context provided to the LLM [28], [54]. This includes not only the initial PRD and prompts but also visual mockups, examples of desired output, existing codebase snippets, API documentation for integrations, and explicit statements about preferred libraries, coding styles, or security constraints [55], [56]. Rich context minimizes ambiguity and helps the LLM generate more accurate and relevant code. 3) Interaction Model and Workflow Integration: The interaction model in Vibe Coding is predominantly tight, iterative prompt-response loop. The developer initiates with high-level request, the LLM generates code, the developer reviews and refines either by editing the code directly or by providing new, more specific prompt [57], [58]. This cycle repeats, often rapidly, enabling quick prototyping and exploration of different solution paths. Vibe Coding tools, such as AI-enhanced IDEs (e.g., Cursor CURSOR, Windsurf Windsurf) or cloud-based platforms (e.g., Replit), integrate into the developers workflow by providing an interface for this interaction. However, the execution and final validation of the generated code typically occur within standard development environment, often managed by the developer. This separation between generation and execution necessitates careful testing and integration, as the LLM does not inherently possess runtime understanding of the code it produces in most Vibe Coding scenarios. This model thrives in creative and exploratory development phases but requires disciplined application of checkpointing and refactoring to manage potential technical debt accrued from rapid, less scrutinized code generation. B. Agentic Coding: Towards Autonomous Software Development Systems Agentic coding as illustrated in Figure 3 represents paradigmatic shift in AI-assisted software engineering. Unlike vibe coding, where LLMs operate as conversational co-pilots [59], [60], agentic coding systems delegate substantial cognitive and operational responsibility to autonomous or semi-autonomous software agents. These agents are capable of planning, executing, and verifying complex software tasks transforming natural testable code with language instructions into robust, minimal human guidance [61], [62]. Architecturally, this requires the convergence of goal planning, task decomposition, execution environments, safety infrastructure, and continuous feedback mechanisms [61], [63]. The core philosophy of agentic coding is delegated autonomy. Developers specify high-level objectives such as integrate an external API, refactor backend routing, or set up CI workflows, while the agent assumes responsibility for determining and executing the steps needed to accomplish those goals. This transforms the humans role from low-level implementer to systemlevel supervisor and goal-setter. Agentic agents exhibit the following core capabilities: Interpret High-Level Goals: Agentic systems parse natural language prompts that span multiple files, layers, or components [19]. For instance, Jules (developed by Google) Jules Link can respond to queries such as integrate the Google Gemini API into the R1 robot by identifying relevant entry points in the codebase. Plan and Decompose Tasks: Upon receiving request, agents create internal execution plans. Jules Jules, Google, for example, breaks down the task into subtasks such as API research, data structure design, code insertion, documentation updates, and test plan execution. Utilize Agents autonomously interact with file systems, compilers, Resources:"
        },
        {
            "title": "Tools",
            "content": "and Fig. 3: Core Capabilities in Agentic Coding: Illustrating the sequential and interconnected capabilities of agentic coding: Interpret High-Level Goals, Plan and Decompose Tasks, Utilize Tools and Resources, Execute and Iterate, Reason and Problem-Solve, Maintain LongTerm Context, and Self-Reflection and Correction within autonomous software agents test suites, Git repositories, APIs, interpreters, and even browsers. In Codex Codex, OpenAI, sandboxed environments are spun up for each task, with independent dependencies and runtime isolation. Execute and Iterate: Agents can modify source code (e.g., changing RoboLogic.cs), test their output, log failures, and retry iteratively. Codex Codex, OpenAI, for instance, can automatically run git diff, apply patches, and generate pull requests. Reason and Problem-Solve: When encountering edge cases, agents apply heuristics, run static analysis, or search documentation. In Juless integration task, error handling included adjusting response parsers and dynamically reconfiguring the Unity Inspector Jules, Google. README.md file to establish project context and configuration. It then autonomously identified relevant integration points namely RoboLogic.cs and RoboListen.cs as the scripts most suitable for modification. The agent proceeded to generate two new data classes, GeminiRequest and GeminiResponse, to support the structure of the APIs request/response handling. It injected the necessary code to parse responses from the Gemini API and configured model parameters to be adjustable via Unity Inspector fields, streamlining developer interaction with the AI integration. To ensure usability and reproducibility, Jules updated the documentation, outlining API key requirements and configuration steps. Finally, it committed all modifications to newly created Git branch and presented the changes for review. This sequence not only reflects an end-to-end software modification task performed autonomously but also highlights the value of agentic systems in managing complex API integrations, combining planning, reasoning, documentation, and version control in unified pipeline. Table provides structured taxonomy comparing the core characteristics, execution roles, and interaction patterns of Vibe Coding and Agentic Coding. It highlights how these paradigms differ in autonomy, developer responsibility, tool integration, and system maturity, offering comprehensive view of their conceptual and technical distinctions. 1) Conceptual Architecture of Agentic Systems: Agentic coding systems (Figure 3) are architecturally distinct from prompt-driven LLM tools, exhibiting modular and cognitively looped design tailored for autonomous software engineering. At their core, agentic platforms such as Codex and Jules integrate planning, execution, tool interaction, and evaluation into cohesive, goal-driven framework. The conceptual architecture typically comprises several interlinked components. core reasoning engine, powered by LLM, interprets high-level developer instructions and generates actionable plans. This is supported by planning module, which decomposes abstract goals into sequence of structured sub-tasks, using mechanisms such as chain-of-thought prompting or hierarchical task networks [19], [108], [109]. To enable environmental interaction, tool use module grants agents the ability to execute commands or access APIs via function calling [110], [111]. This includes capabilities such as modifying configuration files, running shell commands, or interacting with Git repositories [112]. critical feature is the presence of memory and context management [113], [114], facilitating persistent state tracking across multi-step workflows. Agents leverage both short-term working memory and longterm retrieval-augmented memory to maintain coherence Fig. 4: Agentic Coding Example-API Integration with Jules. This flowchart illustrates how Jules autonomously integrates the Google Gemini API, executing tasks from repository analysis and code modification to documentation and Git operations demonstrating complete, multistep software development workflow typical of advanced agentic coding systems. Maintain Long-Term Context: Codex maintains session state over complex multi-step tasks, managing API keys, dependencies, and environment variables Codex, OpenAI. Persistent memory and vector store integration enable agents to reference earlier instructions and code changes. Self-Reflection and Correction: Emerging systems implement internal evaluation. Agents like Codex log their decision trees, summarize actions, propose revisions, and retry failed steps autonomously presenting diffs and execution summaries to the user Codex, OpenAI. The human-agent interaction remains iterative but high-level. In Jules, for instance, developers are presented with reviewable summaries (Ready for Review) and given options to approve, revise, or publish branches. In Codex, task outcomes are presented with logs, diffs, and test results for validation before pushing to GitHub. When instructed to integrate the Google Gemini API into robotics codebase, the agentic coding system Jules demonstrated multi-step, autonomous workflow that exemplifies the principles of agentic software development. As illustrated in Figure 4, Jules began by cloning the target GitHub repository and analyzing the TABLE I: Comparative Taxonomy of Vibe Coding versus Agentic Coding Paradigms Aspect Vibe Coding Agentic Coding Core Philosophy AI Autonomy Level Developers Primary Role Human-AI co-creation and intuitive partnership. Developer guides AI with high-level vibes and iterative feedback [64]. Focus on augmenting individual developer productivity [65], [66]. AI as an autonomous or semi-autonomous task executor. Developer delegates complex goals, and AI plans and executes with higher-level human oversight [67], [68]. Focus on automating larger development tasks [69], [70]. Low to Moderate: Acts as responsive assistant, executing specific, developer-defined tasks [71], [72] (e.g., write this function, refactor this class). Requires continuous human prompting for sequential steps [73], [74]. Moderate to High: Acts as proactive executor [75], [76]. Can independently plan, decompose, and execute series of sub-tasks based on high-level goals with significantly less step-by-step human intervention. Can make intermediate decisions [19]. Director, Co-Pilot, Prompter: Actively involved in defining micro-tasks, prompting for code, reviewing each generated piece, debugging details, and integrating components [77]. Architect, Project Manager, Supervisor: Defines highlevel strategic goals, system architecture, constraints. Monitors agents progress, provides strategic guidance, and validates outcomes [78], [79]. Interaction Model Highly conversational and iterative prompt-response cycles [80]. Short, frequent feedback loops [81], [82]. Developer continuously refines prompts or code [83]. Planning & Task Decomposition Primarily human-led. Developer breaks down features into smaller, promptable tasks for the AI. AIs planning is mostly local to the current prompt [85]. Tool Utilization by AI Primarily code generation. Use of other development tools (compilers, Git, linters) is typically initiated and managed by the human based on AIs code output [58]. Goal delegation and monitoring. Human sets complex goal; agent plans, executes, and provides periodic updates or requests high-level clarification [77]. Longer, more complex execution cycles with less frequent, but more strategic, human check-ins [84]. Primarily AI-led within defined constraints. The agent autonomously decomposes high-level goals into an actionable sequence of sub-tasks and dependencies [19], [86]. Can autonomously interact with and orchestrate suite of development tools (e.g., compilers, interpreters, version control systems, package managers, APIs, web browsers for research/testing) as part of its execution plan [21], [87]. Execution Environment Often generates code for execution in an external IDE or minimally integrated environment [18]. The developer is responsible for setting up and managing the runtime [88]. Typically requires integrated or sandboxed execution environments with robust logging, resource management, and security guardrails to safely execute agentgenerated code and tool commands [89], [90]. Error Detection & Handling Typical Task Scope Errors are often identified by the developer postgeneration during manual code review, testing, or via IDE linters/compilers [69]. AI assists in fixing errors when prompted with specific error context [82], [91]. Component-level tasks: generating functions, UI elements, simple scripts, unit tests for specific functions, drafting documentation, refactoring small code sections [95]. Aims for more autonomous error detection by the agent (e.g., through automated test execution, static analysis, or internal consistency checks) [92] and may attempt self-correction, with human intervention required for complex or novel failures [93], [94]. Feature-level or even simple application-level tasks: end-to-end feature implementation (e.g., user authentication system), complex multi-file refactoring, system migrations, comprehensive test suite generation, CI/CD pipeline automation [96][98]. Context Management by AI Primarily relies on the developer to provide and maintain context within session, often limited by the LLMs inherent context window [28], [99]. Human bridges context across longer interactions. Designed for more sophisticated and persistent context management, enabling reasoning over more extensive project information [100], documentation, and past interactions across longer, multi-step tasks [66], [101]. Primary Output Focus Generation of code snippets, functions, or small modules that the developer then integrates and refines [28], [95], [102]. Maturity and Current Availability Widely adopted in tools like GitHub Copilot Link, Cursor Link, and Replit Agent Link. Generation of more complete, interconnected systems or features [77], [103], [104], potentially including code, tests, configurations, and documentation, requiring less manual integration by the developer [105][107]. Emerging and experimental; seen in platforms like AutoGen Microsoft AutoGen, CrewAI Crew AI link, Codex by OpenAI Codex Link LangChain Agents LangChain, and early products such as Devin Devin AI in extended tasks. All actions are executed within an isolated sandboxed environment that enforces system safety through resource constraints, permission scoping, and rollback mechanisms [19]. Feedback is central to the agentic paradigm where agents incorporate results from automated tests, logs, or human feedback through evaluation and learning mechanisms, adjusting future behavior accordingly [115], [116]. Architectures may further include an orchestration layer that coordinates specialized sub-agents (e.g., planner, coder, tester, documenter), facilitating parallelism and modular division of labor [112]. As illustrated in systems like Codex Codex, OpenAI, this architecture transitions AI from passive tool to an active collaborator capable of self-directed planning, decision-making, and refinement. These agents operate not merely as extensions of developer intent but as semiautonomous entities capable of transforming high-level specifications into verifiable software artifacts [117], [118]. Agentic coding thus lays the foundation for scalable, adaptable, and increasingly intelligent development pipelines in real-world programming ecosystems [119], [120]. 2) Shift in Developer Interaction and Control: The interaction paradigm in agentic coding represents fundamental departure from the co-piloting model of vibe coding [121], [122]. Rather than engaging in direct, iterative instruction at the function or line level, the developer assumes supervisory role defining the mission, monitoring system behavior, and validating outcomes [123]. This transition from procedural engagement to goal-level delegation reflects broader cognitive and operational realignment in human-AI collaboration. At the outset, the developer is responsible for mission specification, articulating high-level objectives, architectural constraints, and system-level requirements [124], [125]. These inputs may encompass functional targets (e.g., integrate external API for user analytics), nonfunctional constraints (e.g., security, latency, portability), or domain-specific standards. The agent then plans and initiates the execution process autonomously [126] [128]. Throughout execution, the developer assumes the role of an observer and strategic guide, reviewing real-time logs, intermediate artifacts, and agent-generated plans [129], [130]. This includes evaluating execution traces, test results, and change diffs [131], [132]. Intervention may be necessary when the agent encounters ambiguous requirements, edge cases beyond its training distribution, or tasks that involve ethical, legal, or architectural judgment. Critically, the developer also acts as the final verifier [133][135]. Before any integration or deployment, the human evaluates the full solution ensuring correctness, compliance, and alignment with project vision [136]. This oversight transforms the developers responsibilities from tactical implementation to strategic assurance and decision validation. This evolving model requires distinct set of cognitive and technical competencies. Developers must develop fluency in agent management understanding agent capabilities, interpreting failure modes, designing effective prompts and constraints, and deploying diagnostic tools when agents deviate from expected behavior [112]. The trust placed in the agent must be balanced with readiness to intercede, especially in high-risk or safety-critical contexts. Ultimately, the agentic interaction model foregrounds the human as system architect, supervisor, and ethical gatekeeper, overseeing semi-autonomous AI collaborator [19], [112]. This shift not only augments developer productivity but also redefines the nature of software engineering in AI-mediated environments. Additional detailed distinctions between Vibe Coding and Agentic Coding including differences in autonomy, task scope, error handling, and developer role are comprehensively summarized in Table I. III. TECHNICAL ARCHITECTURE AND CAPABILITIES Although both vibe coding and agentic coding harness LLMs to augment software development as depicted in Figure 5, their architectural intent and implementation are fundamentally distinct. Vibe Coding (Figure 5a) operates through developer-initiated, prompt-based interactions within IDEs or web-based environments, emphasizing conversational co-creation and low-friction prototyping. In contrast, Agentic Coding (Figure 5b) is grounded in delegated autonomy: developers specify high-level objectives, and intelligent agents often composed of planner, executor, and toolchain modules carry out multi-step coding workflows, potentially invoking compilers, APIs, test runners, and version control systems without continuous human supervision. To articulate these differences, this section presents detailed architectural analysis through layered diagrams, pseudocode abstractions, and systematic tabular comparisons. The core architectural contrasts ranging from context management and multi-agent orchestration to execution sandboxing and CI/CD integration are summarized in Table II, offering researchers and system designers clear framework for understanding the capabilities and trade-offs of each model. Additionally, we explore how feedback loops, validation protocols, and tool autonomy shape each paradigms suitability for different use cases, from rapid prototyping to enterprise-scale automation. By formalizing these architectural features, this section contributes foundational taxonomy for evaluating emerging AI coding frameworks, informing both engineering decisions and future research in agentic software systems. Fig. 5: Comparative Architecture of Vibe Coding and Agentic Coding (a) Vibe Coding: Developers provide prompts to an LLM within an IDE or web interface. The workflow relies on short-term context and manual execution, testing, and integration. (b) Agentic Coding: Developers define objectives processed by planner, longterm memory, and executor modules. Agents autonomously use tools within sandboxed environments to complete multi-step workflows. A. Execution Models: Comparative Analysis of Architectural Design stateless 1) Vibe Coding Interfaces and Developer-Driven Execution: Vibe coding architectures operate primarily through lightweight, interfaces where LLMs serve as code-generation engines embedded in developer-centric environments such as IDEs, browserbased editors (e.g., Replit Replit AI), or terminal integrations [92], [137]. The execution model is explicitly decoupled from the generation pipeline LLMs suggest or write code in response to high-level prompts, but the responsibility for integration, execution, testing, and debugging remains with the human developer [138] [140]. The developer copies generated snippets into their runtime environment, configures test cases, and manually interprets any resulting behavior. This model emphasizes flexibility and creativity during early-stage development or rapid prototyping, leveraging prompt-response cycles to accelerate code synthesis. However, from an architectural standpoint, it exhibits passive execution pipeline. There is no embedded runtime or agent-native validation loop [141], [142]. Instead, testing and validation are handled through external services unit test frameworks, CI/CD tools, or manual test execution within local or cloud IDEs [143]. This asynchronous, generation-first design allows LLMs to focus on semantic synthesis and reuse of learned patterns [144], but introduces latency in feedback loops and higher cognitive burden on the developer [145], [146]. The architecture lacks internal state management, agent memory, or runtime enforcement, reflecting its reliance on human-driven control over execution and validation. 2) Agentic Coding Architectures and Autonomous Execution Pipelines: Compared to vibe coding, agentic coding systems incorporate fully integrated execution TABLE II: Architectural Comparison Between Vibe Coding and Agentic Coding Systems Architectural Component Vibe Coding Agentic Coding System Orchestration Prompt Handling Layer Memory and Context Architecture Execution Engine Typically centralized around IDE-based LLM plugins or browser UIs. Multi-agent layers are lightweight and session-bound. Human initiates each cycle. Hierarchical agent controllers with plannerexecutor modules. Autonomy allows task spawning, recursive loops, and tool orchestration without new human prompts. Interactive, session-limited prompting with optional pre-prompts or in-context examples. Managed by user interface or IDE plugin. Semantic goal parsing with persistent memory modules, chaining of system, user, and tool prompts. Task graphs and agent routing handled internally. Short-term context via prompt window + optionally dynamic context via RAG (Retrieval-Augmented Generation). Persistent memory rare. Uses vector memory stores, session-level caching, external knowledge bases, and context prioritization queues for long-horizon state awareness. Human-managed execution loop; AI produces artifacts for IDEs, terminals, or hosted sandboxes. Limited or no write-access to environment. Embedded, sandboxed, or containerized runtime. Agents execute, modify, and validate code via system calls, test runners, compilers, or browsers. Multi-Agent Coordination Optional, and usually predefined (e.g., scaffolder + code generator). Agents do not independently collaborate or plan. Core architectural feature. Specialized sub-agents (e.g., coder, tester, reviewer, fixer) collaborate, pass state, and report to planner agent. Toolchain Integration Validation Pipeline Limited; human bridges between AI output and tools like Git, CI/CD, or package managers. Tool actions are suggested, not executed. Full-stack tool orchestration (e.g., Git commits, API calls, dependency management, monitoring). Agents autonomously trigger workflows. Linting, test generation, and review are humaninvoked or post-hoc. AI may help create tests, but does not own testing pipeline. Integrated QA loop with automatic test synthesis, execution, and patching. Agents evaluate outputs, revise plans, and regenerate on failure. Security and Guardrails Basic static analysis or organizational linters applied post-generation. Security remains human-enforced. Embedded static and dynamic scanners, policy-ascode integration, and gated deploy checkpoints. Security policies enforced during execution. Observability and Feedback Lightweight usage metrics via IDEs or logs. Feedback loop is implicit (developer adjusts prompt) and local. Telemetry-driven feedback to prompt-engineering layer. Continuous refinement via logs, metrics, exceptions, and outcome evaluations. Deployment and CI/CD Output consumed and deployed by human; CI/CD setup is manual or external. Agents may set up and trigger CI/CD workflows, generate configs (e.g., GitHub Actions), and validate deployment success or rollback. pipelines as first-class architectural feature [147], [148]. These systems embed containerized, policyconstrained runtime environments such as Docker instances [149][151], WASM runtimes [107], [152], or lightweight QEMU-based emulators directly into the development agents operational core [153]. Within these sandboxes, autonomous agents can not only generate code but also execute, test, and iteratively refine it without requiring human intervention for each step [87], [154]. Agentic execution architectures are characterized by modular task graphs where planner components decompose user goals into executable sub-tasks, and executor agents interact with the runtime to carry them out [155]. This allows for tight coupling between generation, execution, and feedback [156]. Agents dynamically manage system state, interact with file systems [157], perform queries [158], [159], analyze logs [86], and retry failed attempts based on real-time results [160], [161]. Security and control are maintained through fine-grained resource isolation sandboxing policies govern memory usage, file I/O, and network access [77], [162]."
        },
        {
            "title": "Agentic Coding Workflow",
            "content": "Developer prompt: Optimize SQL joins for user reporting. Agent loads sandbox environment. Analyzes ORM model structure. Refactors queries and validates execution plan. Deploys tested code to staging environment. This closed-loop, self-evaluating architecture reduces reliance on the human as runtime operator and increases system autonomy. It supports advanced use cases such as multi-file refactoring, regression analysis, and continuous integration with minimal human oversight. Architecturally, this marks transition from interactive co-programming to autonomous software engineering, where execution is proactive, contextual, and adaptively managed by intelligent agents. B. Autonomy and Feedback Loops in Vibe and Agentic Coding Paradigms 1) Vibe Coding: Human-Centric Control and Reactive Feedback: Vibe coding architectures operate under fundamentally reactive model, wherein the human developer remains the sole agent responsible for validation, error detection, and iterative refinement [66]. The LLM acts as stateless code synthesis engine generating outputs in response to prompt instructions but without any intrinsic feedback mechanism or selfevaluation capacity [97]. As such, the feedback loop exists entirely outside the system and is mediated by the developer through post-hoc testing, debugging, and prompt refinement [163], [164]. This model affords significant flexibility in exploratory or creative coding sessions. Developers may use short, expressive prompts (e.g., Add JWT authentication to the login flow) and immediately evaluate the output in their IDE or test environment. However, when prompts are vague or underspecified (e.g., Make this more secure), the LLMs lack of situational awareness and tasklevel memory often leads to hallucinated or ambiguous outputs."
        },
        {
            "title": "Prompt Engineering Insight",
            "content": "Specific prompt: Add role-based access control using JWTs and restrict admin endpoints. Vague prompt: Make this more secure. Outcome: The former yields focused middleware code with user returns generic suggestions like hashing passwords twice or limiting requests, often misaligned with project context. the latter roles; Due to its lack of autonomous validation [165], vibe coding systems are limited in production environments where reliability, regression testing, and integration constraints are critical [58], [166]. Developers must manually run tests, validate results, and reframe prompts for each iteration, rendering the process iterative but humandependent. While suitable for front-end prototyping, documentation drafting, or low-risk automation, the absence of self-driven error correction limits its robustness in complex systems. 2) Agentic Coding: Goal-Driven Autonomy with Feedback-Integrated Execution: In contrast, agentic coding frameworks are designed with feedback-driven autonomy as core architectural principle [167]. Agents operate through multi-level feedback loops that include planning, execution, testing, evaluation, and corrective iteration all orchestrated without human prompting between steps [19]. This architecture draws from reinforcement learning, symbolic planning, and black-box evaluation strategies to enable continuous improvement within coding session. typical agentic workflow begins with high-level task objective (e.g., Build PostgreSQL-backed user analytics dashboard), which is decomposed into subtasks using internal planning modules. Each subtask (e.g., schema generation, query writing, UI wiring) is independently implemented and validated via in-agent execution environments. Failures trigger internal debugging logic, resulting in retrials, log inspection, or substitution strategies."
        },
        {
            "title": "Agent Feedback Algorithm",
            "content": "Input: Task Objective (T) Output: Verified Implementation (I) Decompose(T) -> [t1, t2, ..., tn] For each ti: Implement(ti) Run Test(ti) if fail: Debug(ti), Repeat Aggregate([t1...tn]) -> Return This closed-loop feedback enables high fidelity in repetitive and deterministic programming contexts [19], [112], such as dependency management, CI/CD configuration, or auto-generating test suites for large-scale systems. For example, an agent tasked with Migrate project from JavaScript to TypeScript will iterate through module identification, static analysis, AST rewriting, and runtime testing without developer intervention at each step. Unlike vibe systems, agentic architectures support telemetry, traceability, and performance metrics at each layer, enabling outcome-aware re-planning and model fine-tuning. The result is an execution pipeline that resembles autonomous software engineering rather than assisted coding capable of aligning long-term goals with tactical implementation across multiple files, systems, and APIs. C. Safety, Explainability, and System Constraints 1) Vibe Coding: Limited Guardrails and Post-Hoc Safety Mitigation: Vibe coding environments, by design, prioritize fluidity of interaction and developer creativity over integrated safety controls. The underlying architecture does not include runtime enforcement mechanisms, making safety and explainability externalized concerns. Outputs are typically generated without runtime awareleading to several risks in security-sensitive or ness, regulated environments. critical architectural limitation is the absence of execution traceability. Since LLMs are stateless within session, they cannot record, annotate, or justify their decisions unless explicitly prompted to do so [168] [170]. This lack of interpretability becomes particularly concerning when the AI injects code with hardcoded credentials, insecure API calls [99], [171], or unsafe permission scopes problems often observed in rapid prototyping workflows [89]."
        },
        {
            "title": "Agentic Safety Features",
            "content": "Namespace isolation: Prevents unauthorized file system access. Resource limits: Controls execution via CPU/memory quotas. Logging hooks: Captures all agent actions, prompts, and test results. Rollback triggers: Reverts files or state if tests fail or errors occur."
        },
        {
            "title": "Common Vibe Coding Risks",
            "content": "Hardcoded secrets: Generated code may embed plaintext API keys or passwords. Insecure defaults: Lack of input sanitization, overly permissive CORS headers. No audit trails: Developer cannot inspect prior outputs unless manually documented. To mitigate these risks, developers often rely on external static analysis tools e.g., SonarQube Sonar, CodeQL Github link, or ESLint security plugins ESList to perform post-generation audits. These tools can flag anti-patterns, insecure imports, or style violations. However, these solutions operate independently of the LLM and require the developer to integrate them manually into their pipeline. As result, the responsibility for enforcing safety, explainability, and governance in Vibe Coding rests solely on the human-in-the-loop, limiting its applicability in high-assurance domains like finance, healthcare, or enterprise DevOps. 2) Agentic Coding: Embedded Safeguards and Transparent Execution: Agentic coding frameworks are designed with embedded safety constraints [172], [173], explainability mechanisms [19], [174], and runtime isolation policies [76], [175], [176]. These systems are designed to emulate production-grade deployment scenarios in microcosm allowing agents to safely execute, debug, and iterate while maintaining verifiable compliance with security and governance policies [177], [178]. The first tier of architectural safeguards involves resource and namespace isolation. Agent containers run within sandboxed environments where access to file systems, memory, CPU, and network interfaces is tightly scoped and rate-limited [107], [149]. For example, an agent modifying YAML configuration files may only access whitelisted directory tree, preventing accidental file system corruption or privilege escalation. Explainability is built into the execution graph [19], [86]. Tools like Claude Code Claude Code Link, Amazon Developer Amazon-Q-Developer Link, and Devika Devika AI log every decision node and code transformation, enabling post-hoc inspection and diff analysis. These logs not only serve as audit trails for compliance but also allow developers to interpret the agents reasoning chain for example, why it refactored function, replaced package, or reordered CI pipeline. Such mechanisms elevate agentic systems from mere automation engines to auditable [107], [179], controlled execution environments [156]. Furthermore, the rollback infrastructure ensures that the system can revert unintended side effects, thereby reducing the risk of silent failures or irreversible changes [180], [181]. These features make agentic coding architectures more aligned with enterprise-grade reliability and explainability standards, distinguishing them as preferable frameworks for autonomous software engineering in safety-critical domains."
        },
        {
            "title": "Application",
            "content": "To synthesize the architectural contrasts between vibe coding and agentic coding, we present comparative analysis focused on execution fidelity, safety, and autonomy. Table III summarizes key differences in system capabilities across multiple operational dimensions. Notably, agentic systems are characterized by in-sandbox execution, embedded validation, and robust safety mechanisms [19], whereas vibe coding tools operate in generation-first manner, relying on human oversight for execution, testing, and risk mitigation [182]. To illustrate these distinctions, consider the task of implementing RESTful (RESTful API JWT-based authentication system. In vibe coding workflow, the developer begins by prompting the LLM with natural language instruction [73], [145]. The model generates code snippet that directly reflects prior examples in its training data. For instance: TABLE III: Execution Capabilities and Safety Comparison Property Code Execution Testing Pipeline Feedback Loop Security Enforcement Explainability Prompt Sensitivity Ideal Use Cases test with retry Agentic Coding Autonomous, within containerized runtime environments Integrated agents recursive logic Embedded, aware with correction Namespace isolation, policy constraints, access controls execution Full trace, rollback logs, action graph inspection goaliteration selfrobust Lower; to ambiguity through planning CI/CD automation, infra provisioning, large-scale refactoring Vibe Coding Manual execution via IDE or terminal Developer-initiated tests, often ad hoc on native review Post-hoc, developercontrolled and re-prompting postRelies generation linting and external static analysis No traceability; depends developer or documentation vague High; produce prompts erratic or incomplete outputs Rapid prototyping, exploratory design, educational coding on recall Generated Output: Vibe from fastapi import Depends, HTTPException from jose import JWTError, jwt SECRET_KEY = \"mysecret\" def verify_token(token: str): try: payload = jwt.decode(token, SECRET_KEY) return payload except JWTError: raise HTTPException (status_code=403) The developer must then validate this implementation manually using tools like Postman or curl, inspect error behavior, and refine the prompt if improvements are needed. This feedback loop remains external and humandriven. In contrast, an agentic system initiates structured execution pipeline [183], [184]. The agent begins by analyzing route configurations, generates middleware for token validation, injects this into the FastAPI framework, executes automated tests via test client, logs any exceptions, and autonomously retries modifications [185]. This closed-loop approach supports reproducibility and validation at every step."
        },
        {
            "title": "Agentic Code Execution Flow",
            "content": "Step 1: Analyze API routes Step 2: Generate token middleware Step 3: Inject middleware into FastAPI Step 4: Run test client Step 5: Log errors and fix recursively This illustration highlights the architectural divergence in action: vibe coding emphasizes developer-led exploration, whereas agentic coding emphasizes autonomous, testable construction. The former thrives in low-stakes or creative contexts; the latter aligns with enterprise-grade reliability and scalable automation. Vibe coding and agentic coding are not competing paradigms but represent complementary trajectories in AI-assisted software engineering. Understanding their technical architecture, capabilities, and constraints is essential for designing effective toolchains and selecting the appropriate paradigm based on context. The next section evaluates these models across performance, efficiency, and deployment scalability dimensions. IV. PRACTICAL WORKFLOW DIFFERENCES The practical adoption of Vibe Coding and Agentic Coding paradigms reveals fundamental differences in developer interaction models, cognitive frameworks, workflow architectures, and application suitability. This section presents comparative investigation across four dimensions: developer roles and mental models, workflow patterns, engagement modes, and human-system factors. Through illustrative examples and comparative tables, we outline how each paradigm supports different stages of software development, from rapid prototyping to automated refactoring and large-scale system integration. A. Developer Roles and Mental Models 1) Vibe Coding: Dialogic Creation and Exploratory Interaction: Vibe Coding emphasizes an interactive, conversational dynamic between the developer and the LLM. Developers are engaged as co-creators, navigating design and implementation decisions through iterative prompt-response cycles [43], [186]. This approach lowers the activation threshold for idea exploration, enabling developers to articulate abstract requirements and progressively converge on working solutions. Primary Roles: B. Workflow Patterns Intent Architect: Formulates project goals in natural language, refining intent through prompt iteration. Creative Director: Evaluates, edits, and curates AIgenerated outputs to align with design intent and user experience. Explorer: Uses the AI to experiment with unknown APIs, test UI patterns, or scaffold new features with minimal prior knowledge. Cognitive Model: The developer operates with what-before-how mindset articulating high-level needs (e.g., Build login page with 2FA) and assessing the AIs proposed structural and syntactic solutions. This model promotes rapid feedback and creative experimentation but delegates testing and validation responsibilities to the developer."
        },
        {
            "title": "Example Prompt Loop",
            "content": "Developer: Create login API with password hashing and 2FA. AI: Generates FastAPI endpoint using JWT + pyotp. Developer: Add unit logic into middleware. tests and refactor 2FA 2) Agentic Coding: Task Delegation and Strategic Oversight: Agentic Coding reframes the developers role as that of systems architect, strategic planner, and supervisory reviewer. Developers define high-level tasks or objectives, which are parsed and decomposed by autonomous agents that execute software engineering workflows ranging from code modification to integration testing and version control [187], [188]. Primary Roles: Strategic Planner: Specifies tasks, objectives, and architectural constraints for the agent to act upon [19], [189]. Supervisor: Monitors execution trace logs, performance reports, and system outputs [130]. Reviewer: Validates the correctness, maintainability, and security of agent-generated changes before integration [77]. Cognitive Model: Developers think in terms of orchestration rather than direct implementation. single instruction such as Fix broken login and ensure OAuth2 compliance may be internally decomposed by the agent into authentication token migration, CI pipeline updates, test reruns, and dependency auditing. Human intervention is minimized to exception handling or ambiguity resolution. Vibe Coding: Conversational Exploration: Vibe coding workflows are inherently exploratory and non-linear. Developers issue prompts, inspect generated code, and provide incremental feedback [190], [191]. This model is optimal for interface prototyping, low-risk experimentation, or knowledge discovery [192]. Example Dashboard Prototyping 1) Developer: Build React dashboard with user count, revenue, and churn chart. 2) AI: Generates UI with Chart.js and dummy data. 3) Developer: Add tooltips and export to CSV. 4) AI: Adds hover logic and export buttons. 5) Developer: Write Cypress tests. 6) AI: Outputs E2E test coverage. Agentic Coding: Structured Execution Pipelines: Agentic coding follows structured workflows based on task planning [193], [194], state management [195], and recursive feedback loops [196], [197]. These workflows suit enterprise-grade tasks requiring correctness, traceability, and automation. Example Automated Dependency Upgrade 1) Developer: Upgrade all npm packages to latest secure versions. 2) Agent: Parses package.json Updates dependency versions Executes test suite Resolves compatibility issues Generates changelog 3) Developer: Reviews logs and approves pull request. C. Comparative Analysis: Developer Engagement and Workflow Suitability The differing interaction paradigms of Vibe Coding and Agentic Coding are reflected not only in architectural and cognitive models, but also in their practical workflow characteristics. From the role of the developer and interaction patterns to testing, documentation, and error resolution, each paradigm supports distinct modes of software creation. These differences have significant implications for project scale, team composition, and toolchain integration. Table IV presents structured comparison of key workflow dimensions, highlighting how each model aligns with specific development contexts and use cases, and guiding practitioners in selecting the appropriate strategy for their software engineering objectives. D. Scientific and Human Factors Cognitive Load and Developer Productivity: Vibe Coding reduces cognitive load associated with syntax and implementation details [82], [166], enabling rapid TABLE IV: Developer Roles and Workflow Comparisons Vibe in Practice: Social Highlights Dimension Developer Role Workflow Type Interaction Style Best Use Case Learning Curve Testing Documentation Error Resolution Architect, Vibe Coding Intent Creative Partner Conversational, Fluid Prompt-response loop Rapid Prototyping, UX Design Low (natural guage) Manual or promptbased On-demand prompt Developer-guided lanvia Agentic Coding Supervisor, Strategic Planner Structured, Recursive Task delegation and logging Refactoring, Maintenance, QA Moderate (agent supervision) Automated and integrated Auto-generated during execution Agent-driven fallback logic with ideation and creative flow. It is especially effective for solo developers, early prototyping, or teaching new frameworks through interaction. Agentic Coding introduces new cognitive demands in terms of system understanding, trust calibration, and supervision. However, it scales well in complex systems, enabling experienced developers to manage multiple asynchronous workflows and integrate formal validation into the pipeline [198][200]. Collaboration and Team Models: Vibe Coding is well-suited to collaborative scenarios such as hackathons or pair programming. Multiple developers may interact with the same agent in conversational loops to co-create ideas. Agentic Coding enables distributed responsibility across modular systems. Individual agents or agent groups may be assigned to subsystem-level tasks, supporting parallelism and pipeline scalability in team-based development. E. Real-World Scenarios Vibe Coding Social Media Feature Ideation: To illustrate the fluid, creative, and iterative nature of vibe coding, consider the development of new feature in mobile social media application. In this workflow, the developer incrementally guides the LLM through series of conversational prompts, shaping both frontend and backend functionality while maintaining control over design decisions. The example below demonstrates how story highlight feature is ideated, implemented, refined, and tested using natural language interaction. Prompt: Add story highlight feature to mobile app. AI: Creates backend schema, API endpoints, frontend UI (React Native). Follow-up: Allow drag-and-drop ordering. AI: Adds sortable list with gesture control. Prompt: Write tests. AI: Outputs Jest + E2E test scripts. Agentic Coding Legacy Migration: In contrast, agentic coding systems are designed for high-autonomy, structured workflows. The following example showcases an agentic system tasked with migrating legacy codebase from Python 2 to Python 3. Once the developer issues the high-level instruction, the agent autonomously scans the codebase, applies systematic refactoring, validates changes through testing, and reports results for human approval. This highlights how agentic systems can automate extensive codebase transformations with minimal oversight. Agentic in Practice: Python 2 to 3 Migration Prompt: Upgrade all Python code to version 3.x. Agent: Parses source files for deprecated syntax. Applies automatic and rule-based refactoring. Executes test suite. Reports diffs and unresolved issues. Developer: Reviews logs, patches edge cases, and approves merge. Vibe Coding and Agentic Coding represent two ends of the AI-assisted software development spectrum. Vibe Coding excels in human-in-the-loop, creative workflows where rapid feedback and flexibility are essential [123], [201], [202]. Agentic Coding, by contrast, emphasizes autonomy, reliability, and integration making it ideal for large-scale automation and enterprise deployment [19], [189]. Understanding the operational strengths and tradeoffs of both paradigms and hybridizing them effectively offers pathway toward more intelligent, efficient, and adaptive software development ecosystems. V. IMPLEMENTATION STRATEGIES The implementation strategies of Vibe Coding and Agentic Coding diverge fundamentally in how they translate developer instructions into executable software. While both rely on LLMs, the strategies they adopt for prompt handling, code verification, and tool integration reflect distinct philosophies. This section explores these dimensions in detail. A. Prompt Engineering Vibe Coding: Precision and Context for Creative Generation: Prompt engineering is the backbone of effective vibe coding. Here, developers provide explicit, intentfocused natural language prompts to guide the AI model in generating desired code outputs [203], [204]. The process is inherently iterative and dialogic [205], [206]. Key Characteristics: Intent-Focused: Prompts emphasize desired outcomes rather than procedures [207], [208]. Context-Sensitive: LLMs use extended context to retain semantic (16k32k tokens) windows awareness of the codebase [209][211]. Exploratory: Prompts may include multiple solution requests or alternative suggestions [212], [213]. Example: Iterative Prompt Refinement Developer: Create REST API with user login and JWT auth. AI: Returns FastAPI endpoint with pyjwt integration. Developer: Add 2FA with OTP. AI: Adds OTP-based validation logic with PyOTP. Vague prompts such as Make this more secure often result in ambiguous or generic outputs. Specific prompts significantly improve precision. Agentic Coding: Hierarchical and Multi-Step Instructions: Agentic coding requires hierarchical prompting suited to multi-phase task execution [19], [197], [214]. Developers issue macro-level instructions that agents deconstruct into subtasks [215]. Key Characteristics: Task Chaining: Prompts are designed to be decomposable. Execution-Ready: Prompts include constraints, file references, and expected outputs. Interactive Feedback: Agents may prompt for clarification before execution. Example: Agentic Prompt Workflow Prompt: Update all modules using Flask 1.x to Flask 2.x and resolve deprecation warnings. Agent Actions: 1) Parse imports and deprecated patterns. 2) Replace and test each submodule. 3) Run CI pipeline. 4) Log any exceptions or failed tests. 5) Compile migration report. Effective agentic prompts must encode enough structure to support independent agent decision-making while retaining flexibility for adaptive correction. B. Review and Debugging Debugging and validation workflows are critical in shaping the reliability and usability of AI-assisted software development. Vibe Coding and Agentic Coding differ fundamentally in how error detection, correction, and verification are handled. Vibe Coding emphasizes human-in-the-loop inspection, relying on manual review and iterative prompt refinement, making it conducive to exploratory development. In contrast, Agentic Coding shifts much of this responsibility to autonomous agents equipped with runtime monitoring, log analysis, and rollback mechanisms. This section systematically analyzes the validation strategies, developer effort, and debugging affordances inherent in each paradigm. In Vibe Coding, 1) Vibe Coding: Manual, Iterative, and Prompt-Based Validation: the developer plays an active role in identifying and resolving issues. Errors are detected through manual testing, visual inspection, and ad hoc interaction with the LLM. The absence of built-in feedback mechanism means the AI does not autonomously detect or act upon code failures. Instead, the developer diagnoses errors and re-engages the model with revised prompts. Key Techniques: Post-Generation Review: Developers visually examine AI-generated code, sometimes assisted by static analysis tools or linters. Manual Testing: Code is copied into local IDE or REPL, where tests are written and executed manually. Prompt Debugging: Errors are addressed by refining the original prompt or issuing follow-up questions to isolate root causes. Example: Prompt-Based Debugging Developer: Why does this throw 403 error? AI: JWT token decode fails due to missing audience field. Add aud claim. While time-consuming, this approach fosters high degree of developer engagement and intuition building. It is particularly effective in early-stage prototyping, learning new libraries, or customizing third-party tools, where interpretability and control are prioritized over automation. 2) Agentic Coding: Autonomous Debugging and Runtime Verification: Agentic Coding systems are equipped with autonomous verification mechanisms embedded into their runtime architecture [216][218]. Once task is defined, the agent is capable of not only executing it but also validating its correctness through runtime evaluation and internal logging systems (using systems such as runtime verifications [219][221]. These systems often include error-handling protocols such as rollback, patch substitution, or retry logic. Key Techniques: Runtime Evaluation: Tasks are executed in secure sandboxes or containers simulating production environments. Log Inspection: Execution traces, diffs, and system states are recorded and used for post-mortem analysis or decision trees. Error Rollback: On failure, agents automatically revert to prior stable state or reattempt execution with modified inputs."
        },
        {
            "title": "Agentic Debug Loop",
            "content": "Agent Workflow: Refactor class structure. Run full test suite. On failure: isolate diff, revert, and retry with alternate patch. Finalize changes only if all tests pass. This feedback-driven model supports CI/CD pipelines, automated patching, and enterprise-grade refactoring. It minimizes manual intervention, ensures reproducibility, and scales efficiently across larger codebases. However, it requires careful oversight to validate that the agents autonomous decisions align with project constraints and security standards. C. Tool Ecosystems The tooling landscape supporting Vibe Coding and Agentic Coding reflects the fundamental differences in their architectural goals and user interaction models. Vibe Coding tools are designed to support rapid prototyping, fluid human-AI interaction, and minimal onboarding, often operating within lightweight development environments. In contrast, Agentic Coding platforms are engineered to manage autonomous task execution, system orchestration, and compliance logging, often integrating deeply with infrastructure-level operations. This section summarizes key tools representative of each paradigm and their associated capabilities. Vibe Coding Tools: Conversational Interfaces and Creative Assistants: Vibe coding tools prioritize accessibility, immediacy, and seamless integration into the developers creative flow. These platforms typically use prompt-response loops and are embedded within IDEs, browsers, or chat interfaces, enabling on-the-fly code generation, inline explanations, and lightweight context sharing. Representative Platforms: ChatGPT: Provides flexible, conversational code generation and prompt debugging via natural language input [9]. Gemini: Combines code suggestion capabilities with contextual documentation references and visual UI integration [222]. Claude (Anthropic): Offers long-context code assistance with focus on safe interaction and persistent multimodal reasoning Claude anthropic. Replit Ghostwriter: Embeds code-generating real-time, LLM into browser-native IDE for context-aware assistance Replit. These tools excel in tasks requiring quick iteration, explanation, and ideation, supporting solo developers, learners, and early-phase design exploration. Agentic Coding Tools: Execution-Aware Agents and Autonomous Pipelines: Agentic coding tools embed intelligent agents within controlled execution environments, enabling autonomous code transformation, validation, and deployment. These platforms often integrate with containers, logs, and permission systems to support continuous development and robust system-level interaction. Representative Platforms: Codex (OpenAI): Supports full project-level task execution, including file system manipulation, test orchestration, and CI pipeline triggering in sandboxed cloud instances Codex OpenAI Link. Claude Code (Anthropic): Designed with explainability and oversight features, enabling developers to audit changes, trace reasoning, and rollback unsafe actions Claude Code Link. Jules: Google Jules is an autonomous AI coding agent powered by Gemini that handles tasks like bug fixes and feature updates asynchronously Google Jules. It operates on cloned GitHub repos in secure VMs, presenting results for review before integration. These agentic tools are suited for scenarios demanding auditability, security enforcement, and task autonomy across large and distributed codebases. Comparative Analysis: Implementation Strategies The practical implementation strategies of Vibe Coding and Agentic Coding reflect their divergent philosophies in autonomy, tooling, and workflow integration. While Vibe Coding emphasizes rapid ideation, creative prompting, and developer-centered iteration, Agentic Coding systems are designed for structured task decomposition, automated execution, and autonomous debugging. These contrasts are not merely stylistic but architectural, influencing everything from execution environments and review cycles to tool selection and deployment suitability. Table provides comparative overview of the key implementation dimensions, offering concise synthesis of how each paradigm operationalizes AI-assisted software development across prototyping, debugging, and production-scale maintenance tasks. TABLE V: Implementation Strategy Comparison: Vibe vs. Agentic Aspect Prompt Engineering Debugging Execution Context Tool Examples Review Cycle Suitability ad hoc, Vibe Coding Intent-based, iterative, creative Manual, prompt-driven External IDEs, local testing ChatGPT, Gemini, Replit Developerinspected Prototyping, experimentation taskagentAgentic Coding Hierarchical, oriented, detailed Automated, controlled Sandbox, container runtime Codex, Code, Roo Agent-audited logs Maintenance, integration, enterprisescale ops Claude + D. Scientific and Practical Implications The application of Vibe Coding and Agentic Coding reflects two distinct paradigms in AI-assisted software development. Vibe Coding facilitates rapid ideation and creative exploration through lightweight, prompt-driven workflows. Its primary strengths lie in minimal setup time, intuitive experimentation, and support for learning new tools or frameworks. However, its limitations such as the need for manual validation, reduced suitability for production environments, and lack of built-in quality assurance make it less ideal for scalable engineering tasks. In contrast, Agentic Coding emphasizes automation, structure, and reliability. Agents can autonomously perform task planning, testing, and code integration, reducing developer burden and increasing QA compliance. These systems are well-suited for CI/CD pipelines, legacy modernization, and enterprise-level code maintenance. Still, agentic workflows require secure execution environments, complex orchestration infrastructure, and careful oversight to prevent silent failures from misconfigurations. Ultimately, these paradigms are not mutually exclusive. Vibe Coding is optimal during early-stage design and prototyping, while Agentic Coding excels in implementation and operational phases. Hybrid workflows that leverage both beginning with creative prompting and transitioning to autonomous execution can maximize efficiency and robustness. As AI coding agents evolve, this blended strategy will likely define the next generation of intelligent development practices. VI. USE CASES AND APPLICATIONS led to the emergence of The evolution of AI-assisted software development has two complementary paradigms: Vibe Coding and Agentic Coding. Each presents distinct strengths, ideal workflow conditions, and technical affordances. Understanding where each paradigm excels enables developers and organizations lifecyto align tooling strategies with project goals, cle stages, and team expertise. This section explores the optimal application scenarios for both approaches based on functional characteristics, observed benefits, and empirical use. comparative summary of use case suitability is provided in Table VI. A. Ideal Scenarios for Vibe Coding Vibe Coding is most effective in early-stage development and exploratory contexts where creativity, rapid feedback, and flexible control are essential. It supports three dominant use cases: Creative Exploration: Vibe tools allow developers to experiment with high-level design ideas, generate multiple implementation variants, and visualize UI flows or logic strategies in real time. This makes them ideal for brainstorming sessions, algorithmic sandboxing, and feature sketching. Rapid Prototyping: Vibe coding excels in building functional MVPs from natural language prompts. Developers can generate full-stack components including REST APIs, frontend layouts, and test cases within hours using conversational iterations, making it suitable for agile environments and hackathons. Learning New Technologies: For onboarding or upskilling, vibe tools serve as real-time coding tutors. Developers can query LLMs for explanations, receive context-sensitive code snippets, and troubleshoot unfamiliar tools or frameworks like Next.js, WebAssembly, or Rust interactively. B. Ideal Scenarios for Agentic Coding Agentic Coding is engineered for structured, highreliability workflows where automation and scale are critical. It is best applied in production environments and enterprise operations:"
        },
        {
            "title": "Codebase",
            "content": "can autonomously analyze legacy systems, detect outdated Refactoring:"
        },
        {
            "title": "Agentic",
            "content": "tools code patterns, and apply systematic refactorings. For example, migrating Python 2.7 system to Python 3.x involves syntax updates, dependency rewrites, and full test coverage all achievable with minimal human oversight using agentic pipelines. Routine Engineering Tasks: These include automated dependency upgrades, code formatting, test regeneration, and CI/CD pipeline maintenance. Agents apply consistent standards across large codebases, improving maintainability and reducing manual engineering overhead. Regression Bug Fixing: Agentic systems excel at log-based error diagnosis, root-cause analysis, and autonomous code repair. They reduce mean time to resolution (MTTR) by running test suites, applying patches, and updating changelogs without developer intervention ideal for mission-critical services. C. Comparative Analysis: Vibe vs. Agentic in Practice TABLE VI: Practical Use Case Comparison of Agentic vs. Vibe Coding Scenario Codebase Refactoring Routine Tasks Regression Fixes Creative Exploration Prototyping Learning testAgentic Strengths Autonomous, scalable, integrated Fully automated and uniform Log-driven self-healing agents Predictable, adaptive Backend-ready automation Fast setup, context recall triage, less Vibe Strengths Limited to small, manual edits for hands-on Good for trial runs and local edits Useful debugging practice Highly freeform ideation End-to-end generation from prompts Interactive Q&A, stepwise clarification responsive, D. Real-World Applications Vibe Coding: 10 Practical Use Cases: Figure 6 illustrated the summary of 10 practical use cases of vibe coding, and each use cases are detailed into following points: 1) Personal Portfolio Website Development Vibe coding proves highly effective in generating professional personal websites with minimal manual effort [223][225]. For instance, developer may prompt, Create modern, responsive personal website with sections for About, Projects, and Contact. Use React and include dark mode toggle. The AI interprets this instruction and outputs full React-based project including reusable components, routing with React Router, state management for theme toggling, and styled-components for UI design. Importantly, the AI-generated code adheres to modern frontend architecture patterns, enabling responsiveness across screen sizes and semantic markup for accessibility. Developers can then refine colors, branding, or layout logic without spending time on boilerplate setup. This use case exemplifies how vibe coding empowers solo developers, students, or freelancers to launch polished portfolios in hours, promoting self-representation, employment outreach, or client engagement. Furthermore, it enables real-time customization: prompts like Add testimonials section with carousel can be appended iteratively. The ease of interaction and semantic clarity of natural language prompts transform what would traditionally take several days of setup, CSS tweaking, and component reuse into streamlined, conversational workflow making this flagship use case in frontend ideation through Vibe Coding [226], [227]. 2) Interactive Data Visualization Dashboards Another powerful use case for vibe coding lies in developing interactive data dashboards [46]. prompt such as Build an interactive dashboard that displays sales data as bar chart and pie chart, with filters for region and date activates the models ability to generate full JavaScript-based UI with integrated visualization libraries like Chart.js or D3.js. The AI constructs components to handle input state (e.g., dropdowns or sliders for region and date), binds them to data filters, and connects the outputs to responsive visual elements. This approach significantly accelerates prototyping for data scientists, product managers, or researchers who may lack the frontend expertise to translate insights into live web interfaces. Moreover, vibe coding allows iterative updates such as Add line chart for monthly revenue trends or Include export to CSV functionality, enabling flexible expansion without reworking foundational architecture. These dashboards can be powered by static JSON or APIbacked data sources, depending on the context. The AI-generated layout often includes accessibility features, tooltips, and mobile responsiveness by default. This use case demonstrates the integration of data fluency and visual storytelling [228], [229], helping domain experts bridge the gap between backend analytics and user-facing visualizations using conversational coding workflows. 3) Daily Email Report Automation Vibe coding excels in automating routine workflows such as scheduled email reports [156], [230]. Given prompt like Write Python script that pulls yesterdays sales from CSV file and emails summary to my team at 8am every day, the AI generates code using Python libraries including pandas for CSV parsing, smtplib for sending emails, and built-in modules like datetime for filtering data. The script typically formats metrics into human-readable summaries, attaches files if necessary, and configures recipient lists and message subjects. Beyond the core logic, the AI often includes instructions for setting up cron job or Windows Task Scheduler entry to automate execution. This workflow is particularly useful for small businesses, sales teams, or researchers who need daily reporting but lack access to enterprise-grade BI platforms. Further enhancements like Format summary as HTML table or Attach CSV of filtered data can be integrated seamlessly through subsequent prompts. Compared to traditional scripting workflows that require detailed knowledge of syntax and library APIs, vibe coding reduces setup time and encourages iterative improvements [231], [232]. This use case exemplifies how AI-enhanced scripting democratizes automation, enabling nonexpert programmers to implement robust reporting pipelines through natural language commands. 4) To-Do List Web Application Vibe coding provides streamlined approach to developing interactive, stateful web applications, such as to-do list managers [233], [234]. Given the prompt Make simple to-do list web app with add, remove, and mark-as-complete features. Use Vue.js, the AI generates project that includes reusable Vue components for task entry, task listing, and status toggling. It sets up reactive data binding via the Composition or Options API and persists the task list using browser localStorage or sessionStorage. This use case is particularly effective for frontend learners, rapid prototyping, and UI logic testing, where state management and component communication are essential. Developers can incrementally add features like task categorization, due dates, or UI transitions simply by prompting further e.g., Add color-coded categories for each tasks by due date. Importantly, task or Sort the AI typically follows modern Vue conventions, using scoped CSS, modular scripts, and semantic HTML structure. This hands-on feedback loop fosters both conceptual understanding and production ready outcomes [105]. Furthermore, the generated application can be easily deployed using platforms like Vercel Vercel Link or Netlify Netlify Link, showcasing vibe codings low barrier to full-cycle application development. In short, to-do list apps serve as an ideal sandbox to observe how AI interprets dynamic user interfaces and local state orchestration from natural language descriptions. 5) Startup Landing Page Generation Vibe coding significantly accelerates the creation of marketing-oriented landing pages an essential component for startups [235], product demos [170], [236], and digital campaigns [237]. prompt such as Generate landing page for new AI-powered note-taking app. Include hero section, features, testimonials, and signup form guides the AI to output semantically structured HTML and Tailwind CSS with clearly delineated sections. It generates layouts with responsive flexbox or grid-based positioning, embedded SVG icons, call-to-action (CTA) buttons, and form validation logic. The landing page is typically annotated with placeholder text and sample imagery, which the developer can replace for customization. This use case benefits nontechnical founders or small teams seeking to deploy marketing content quickly without hiring web designers. Moreover, it allows iterative refinement: prompts like Add newsletter opt-in with Mailchimp integration or Include pricing tiers with toggleable monthly/annual plans are easily interpreted by the model. The AIs outputs align with SEO best practices and accessibility guidelines, often including meta tags and ARIA attributes. This workflow illustrates how vibe coding transforms vague branding concepts into fully deployable pages, enabling rapid iteration on visual identity and user acquisition strategies through natural language co-design. 6) RESTful API Endpoint Development Vibe coding is increasingly effective for backend prototyping, particularly in generating modular RESTful APIs. prompt like Create Node.js Express endpoint for user registration, with email validation and password hashing leads to the generation of structured middleware logic using express, bcryptjs, and validator.js. The AI often scaffolds the file structure, initializes an app.js or index.js, and integrates JSON body parsing with standardized error handling. The resulting endpoint typically includes robust input validation, secure password storage, and informative response messages. This use case is particularly useful for full-stack developers prototyping backend logic without investing in boilerplate or configuration overhead. The generated code is modular enough to extend with authentication middleware like JWT, rate limiting, or database integration through MongoDB or PostgreSQL. Subsequent prompts e.g., Add input sanitization to prevent XSS or Integrate this with MongoDB user model can be layered seamlessly. This shows how vibe coding supports iterative back-end design with conversational refinement. More importantly, it empowers frontend-focused developers to extend their capabilities into API development, promoting end-to-end skill integration. Thus, REST endpoint generation exemplifies how vibe coding reduces friction in backend service scaffolding, enhancing both speed and security of early-stage API development. 7) Unit Test Generation for Frontend Components Testing is often overlooked in early-stage development, but vibe coding offers frictionless approach to generating unit test suites for React and other component-driven frameworks. prompt like Write Jest unit tests for this React component that displays user profiles initiates code that tests lifecycle methods, conditional rendering, prop validation, and event handling. The AI typically produces test files using react-testing-library or enzyme, defining mocks and asserting DOM state after simulated interactions. This functionality is invaluable for improving code coverage, debugging regressions, and maintaining confidence during refactors. Developers can extend the coverage by prompting Add tests for error boundaries or Include mock API calls. The generated test cases are often aligned with industry best practices, using descriptive test names and clear assertions. This use case demonstrates how vibe coding promotes quality assurance practices even in fast-paced prois particularly valuable for totyping contexts. It teams adopting test-driven development (TDD) or onboarding new engineers to legacy systems who need to create regression tests. By automating repetitive scaffolding of test logic, vibe coding helps enforce consistent testing structures, reducing the manual effort typically required for frontend validation and increasing reliability in component-driven architectures. 8) Framework Exploration and Onboarding Vibe coding serves as an effective tool for developers exploring unfamiliar frameworks or ecosystems. For instance, prompt such as Show me how to set up basic blog with Next.js, including routing and markdown support yields full scaffold of modern web project. The AI typically generates key files including pages/index.js, dynamic routing components using getStaticPaths and getStaticProps, and integrates Markdown rendering through libraries like remark or gray-matter. It also provides file structures, package dependencies, and minimal working examples for content loading and layout templating. This guided setup facilitates hands-on learning without requiring prolonged documentation review, making it particularly beneficial for bootcamp students, self-taught developers, or engineers transitioning to unfamiliar stacks. Follow-up prompts such as Add syntax highlighting for code blocks or Implement tag-based post filtering can be layered incrementally, simulating real-world development flow. This workflow encourages immediate experimentation, rapid iteration, and experiential learning. Unlike tutorials or static documentation, vibe coding fosters an interactive feedback loop that enhances conceptual understanding through example-driven guidance. Thus, framework exploration via vibe coding accelerates onboarding while empowering users to transition from novice to productive contributor in modern development ecosystems like Next.js, SvelteKit, or Astro. 9) Interactive Multimedia and Animation Prototyping Another high-value application of vibe coding lies in creating rich, interactive multimedia experiences. Given prompt such as Build JavaScript animation that reacts to music and user clicks, with smooth transitions and colorful visuals, the AI constructs canvas-based or WebGL animation pipeline using libraries such as p5.js, Tone.js, or raw requestAnimationFrame logic. It wires real-time audio input events to visual transformations and handles user interactions like mouse movement or click-based effects. The output typically includes smoothing functions, frame buffers, and conditional rendering for responsiveness. This use case is highly relevant for frontend engineers, game developers, and digital artists looking to prototype immersive interfaces or creative installations. Because such applications are rarely template-driven, vibe codings strength lies in enabling fast ideation loops developers can iterate by prompting Make colors change with beat intensity or Add particle trails to click animations. This approach significantly lowers the barrier to generative art, sound visualization, or interactive infographics, domains where traditionally high skill thresholds once constrained creative experimentation. Vibe coding thus democratizes access to dynamic front-end graphics programming, enabling more developers to explore creative coding with immediacy and expressive control through natural language. 10) Spreadsheet Automation with Google Apps Script Vibe coding extends beyond frontend and API development into automating productivity tools, such as spreadsheets. use case like Write Google Apps Script to automatically color rows in Google Sheet based on the value in the Status column triggers generation of JavaScript code tailored for the Apps Script environment. The model produces event-driven scripts using onEdit(e) handlers that evaluate cell values and apply conditional formatting via setBackground() methods. It also includes logic to optimize performance (e.g., range limiting) and optional enhancements like logging or undo triggers. This application is especially useful for educators, analysts, and administrative staff who manage large datasets and require visual cues for prioritization e.g., coloring tasks as Complete, In Progress, or Overdue. Additional prompts such as Send email when status is Blocked or Sort by last updated date on edit can expand the automation scope. Unlike manual scripting which requires prior knowledge of Google Apps Script APIs, vibe coding allows users to build task-specific automation routines through intuitive prompts. This use case illustrates how conversational AI can streamline routine digital workflows in office suites, bridging the gap between traditional spreadsheet usage and low-code enterprise automation. Agentic Coding: 10 Applied Use Cases: 1) Automated Codebase Refactoring large-scale, systematic Agentic coding excels at code transformation, especially in legacy modernization scenarios. For example, given the instruction Refactor all legacy authentication code to use OAuth2, update related tests, and ensure backward compatibility, the agent parses the authentication module across files, identifies deprecated authentication logic, and systematically replaces it with OAuth2-compliant handlers. It updates environment configurations, rewrites affected middleware, and adjusts API headers to match new security flows. Unit and integration tests are updated or regenerated to validate the changes, and backward compatibility layers are introduced where applicable. Finally, the agent commits these changes to Git branch and submits changelog for review. This minimizes manual intervention and supports safer refactorings in production-sensitive codebases, where human error could be costly. Agentic refactoring is especially suitable for frameworks undergoing deprecation, major version upgrades, or compliance updates (e.g., from cookie-based sessions to token-based authentication). 2) Routine Dependency Updates Maintaining up-to-date dependencies across large repositories is tedious and error-prone an ideal task for agentic automation. When prompted with Update all project dependencies to their latest secure versions, fix any compatibility issues, and document changes, the agent examines package.json, requirements.txt, or equivalent manifest files and upgrades each package to secure, stalaunches regression ble release. Post-upgrade, it test suites to detect breakages, applies required code patches, and flags any unresolved compatibility issues. human-readable changelog is autogenerated, listing updated packages, reasons for change (e.g., vulnerability fix, feature parity), and impacted modules. This workflow ensures software supply chain hygiene and aligns with security best practices such as SBOM (Software Bill of Materials) generation. 3) Regression Bug Fixing In enterprise-grade pipelines, where minimizing downtime is critical, agentic systems provide rapid response mechanisms for resolving regressions. Instructed with Identify and fix any regression bugs introduced in the last release, the agent fetches the latest commits, runs test pipelines, and maps failures to code changes using blame heuristics localization techniques. Upon or statistical fault identifying root causes, it proposes targeted patches and verifies fixes through retesting. If successful, the fix is committed with rollback metadata. This not only reduces mean time to resolution (MTTR) but also minimizes human debugging cycles during post-deployment phases. 4) CI/CD Pipeline Automation Setting up and maintaining CI/CD pipelines is essential but repetitive ideal for delegation to agentic systems. When asked to Set up and maintain CI/CD pipeline that builds, tests, and deploys our microservices to AWS, the agent scaffolds GitHub Actions or GitLab CI YAML files, configures secrets management (e.g., via AWS IAM), builds Docker containers, and deploys them to ECS or Lambda environments. It also implements rollback triggers, environment matrix testing, and artifact versioning. This workflow transforms DevOps setup into task-oriented scriptable process, freeing engineers to focus on application-level issues. 5) Automated Security Auditing Agentic coding tools are highly effective for security auditing. Given the prompt Scan the codebase for OWASP Top 10 vulnerabilities, apply fixes, and generate security report, the agent runs static analysis (e.g., CodeQL, Bandit), applies sanitization patches (e.g., escaping input fields), and produces PDF security report complete with fix diffs, severity scores, and coverage metrics. It also enforces policy-as-code integrations to flag future regressions. This is crucial for SOC 2 or GDPRcompliant organizations requiring continuous assurance mechanisms. 6) Large-Scale Code Migration Legacy code migrations, such as Migrate the codebase from Python 2.7 to Python 3.x, are complex Fig. 6: 10 use cases of Vibe Coding (Upper part) and Agentic Coding (Lower Part) and error-prone. The agent tokenizes source files into abstract syntax trees (ASTs), applies rule-based transformations (e.g., print statements to functions, Unicode updates), and updates dependency management (e.g., replacing pip2 libraries). After transformation, it runs and validates unit and integration tests, logging all conversions for developer audit. This use case illustrates how agentic systems can bridge large syntactic gaps and reduce organizational technical debt with traceable automation. 7) Automated Documentation Generation Documentation often lags development. Agentic systems solve this via prompts like Generate API documentation for all endpoints, including usage examples and parameter descriptions. The agent extracts function docstrings, converts them into OpenAPI-compliant specs, and deploys an interactive Swagger UI. If inline docs are missing, it infers descriptions from usage patterns or model inference. The documentation is versioned with the codebase and updated on every relevant commit. This ensures code maintainability, simplifies onboarding, and aligns with industry standards such as REST maturity models or GraphQL schema introspection. 8) Performance Optimization Performance profiling and optimization tasks are ideal candidates for agentic workflows. Given Profile the application, identify bottlenecks, and optimize slow database queries, the agent instruments performance probes using cProfile, perf, or Chrome DevTools depending on stack. It locates hotspots such as nested loops or unindexed queries, applies refactors (e.g., SQL indexing, memoization, pagination), and verifies performance gains with benchmarks. The final report includes before/after metrics, call graphs, and optimization rationale. This use case demonstrates how agentic coding tools can enforce non-functional requirements through measurable performance metrics. 9) End-to-End Feature Implementation Agentic coding systems are capable of implementing complex, multi-component features. For inthe prompt Implement new payment stance, gateway integration, update the UI, backend, and database, and ensure all workflows are tested triggers code generation for frontend forms (e.g., Stripe.js), backend API routes, database schema updates, and test coverage via Cypress or Postman. The agent updates configuration files, manages secrets, and deploys to staging environments. Human developers review logs, inspect schema diffs, and approve PRs. This end-to-end autonomy illustrates the promise of agentic systems in full-stack development. 10) Automated Rollback and Recovery For production environments, agentic systems serve as first responders. Prompted with Monitor production for critical errors, and if detected, automatically roll back to the last stable version and notify the team, the agent uses observability tools (e.g., Datadog, Sentry) to watch logs for error spikes. If conditions match critical failure signature, the agent initiates rollback via GitOps workflows (e.g., ArgoCD), verifies system health post-rollback, and dispatches alerts via Slack or email. This application reduces incident response time and adds resilience to mission-critical deployments. VII. INDUSTRY TRENDS AND CONVERGENCE The evolving interface between humans and artificial intelligence in software development has given rise to two prominent paradigms: Vibe Coding and Agentic Coding. Originally designed with distinct purposes vibe coding as an exploratory, conversational mode and agentic coding as structured, autonomous execution model these approaches are increasingly converging. This convergence is not coincidental; it reflects broader sociotechnical demands across domains such as enterprise automation, developer education, and creative software innovation. In this section, we examine the emerging hybrid architectures, adoption trajectories across industry sectors, and the synthesis of best practices that signal maturing AI-assisted development ecosystem. A. Emergence of Hybrid Models Contemporary platforms are beginning to blur the once-clear lines between reactive conversational assistants and autonomous agent frameworks. Vibe coding systems, initially confined to prompt-based generation in natural language interfaces, have started incorporating execution capabilities, persistent context, and basic planning modules. For instance, tools like Replit Ghostwriter now support inline execution and debugging, offering partial autonomy within conversational workflows. Conversely, agentic platforms such as OpenAI Codex, Claude Code, and Google Jules have introduced interface elements from vibe coding: accepting high-level natural language goals, providing step-by-step feedback, and engaging in clarifying dialogue. These developments illustrate an architectural fusion in which conversational flexibility is paired with autonomous execution, leading to hybrid systems capable of decomposing, planning, validating, and summarizing multi-step software tasks. Hybrid models allow users to issue abstract objectives (e.g., Build secure login system with 2FA and audit logging), which are parsed by the AI into discrete submodules. The agent then executes each step, verifies the results via tests, and presents logs and artifacts for review. This synthesis offers three distinct benefits: (i) conversational speed in ideation, (ii) execution precision with agent control, and (iii) continuous loop of refinement via real-time feedback. However, challenges remain in ensuring explainability, safe prompt handling, and seamless cross-platform integration. B. Enterprise and Educational Adoption The convergence of AI coding paradigms is not only theoretical but increasingly visible in industry and education. Agentic systems are gaining traction in enterprise environments due to their capacity for automating mission-critical tasks. Organizations such as Cisco employ agentic frameworks for regression testing, legacy code refactoring, and continuous integration workflows. Similarly, Kodiak Robotics leverages agentic tools for safety-critical verification in autonomous driving software. In contrast, vibe coding is widely adopted in education and individual development. Platforms such as VS Code and Replit embed vibe-oriented coding assistants directly into the IDE, allowing students and solo developers to explore new APIs, build prototypes, and debug through conversational interaction. Coding bootcamps use these systems for instructional scaffolding providing code suggestions, explanations, and project feedback. Adoption patterns exhibit dual structure: topdown implementation of agentic systems in enterprise pipelines, and bottom-up adoption of vibe tools among independent users. Despite their promise, adoption faces three main barriers: (i) governance concerns around AI decision transparency and security, (ii) skepticism toward black-box automation among seasoned developers, and (iii) the need for retraining teams in AI-centric workflows and agent supervision. C. Balanced Development Practices As these paradigms continue to merge, balanced model of human-AI collaboration is emerging. In this paradigm, developers use vibe interfaces to articulate system intent (e.g., Design multilingual registration form with spam filters), and agents execute subcomponents backend validation, frontend form generation, and anti-spam logic under the developers supervision. The human then reviews and refines outputs, enforces policy compliance (e.g., GDPR), and initiates deployment. Balanced practices offer the best of both paradigms: the creative freedom and speed of vibe coding, and the repeatability, quality assurance, and architectural rigor of agentic systems. Empowered by this synergy, non-programmers can initiate software logic via natural language, while engineers maintain control over architecture, policy, and integration. Still, three unresolved challenges remain: (i) ensuring runtime security against emerging prompt-based or model-exploitation vulnerabilities, (ii) implementing comprehensive and interpretable audit trails for AI decisions, and (iii) preserving and cultivating developer expertise in the face of rising abstraction and automation. The convergence of vibe and agentic coding represents paradigmatic shift in AI-assisted software engineering. Forward-looking organizations are embracing hybrid workflows that leverage intuitive ideation and autonomous execution. Those that invest in explainability, modular agent design, and developer empowerment are likely to lead the next era of resilient and scalable software innovation. VIII. CHALLENGES AND LIMITATIONS Despite their transformative potential, both Vibe Coding and Agentic Coding present critical limitations as illustrated in Figure 7 that must be understood for safe deployment, sustainable adoption, and long-term developer resilience. These challenges are architectural, procedural, and cognitive in nature arising not only from technical immaturity but also from systemic gaps in explainability, oversight, and security. This section provides detailed analysis of the emerging risks and constraints associated with both paradigms, grounded in real-world case studies and interdisciplinary insights from software engineering, human-computer interaction, and AI ethics. A. Limitations of Agentic Coding Agentic coding systems, while promising high degrees of autonomy, introduce risks that arise from reduced human oversight, opaque execution logic, and uncontrolled access to critical infrastructure. One of the most pressing concerns is the overdependence on agents for routine and high-stakes engineering tasks. As developers become increasingly reliant on autonomous systems, their engagement with core programming concepts and debugging strategies may diminish, leading to skill atrophy and reduced situational awareness. This is analogous to findings in aviation automation and clinical decision-support systems, where passive user roles have been shown to degrade cognitive vigilance. The longterm consequence in software engineering could be workforce that is poorly equipped to intervene during edge-case failures or system crises. Another serious concern is the potential for silent error propagation. Agentic systems operating across multiple modules can introduce logic faults or regressions that go undetected until deployment. Because these agents modify code, adjust configurations, and interface with APIs at runtime, fault introduced in one subsystem can cascade downstream particularly if agents are not equipped with rollback mechanisms or observability hooks. Examples include global refactors that destabilize microservice communication protocols or schema changes that disrupt dependent services. Robust mitigation requires explainable agent decisions, real-time anomaly detection, and strict version control governance. In addition, the expanded runtime privileges of agentic platforms create new vectors for security vulnerabilities. Autonomously acting agents may unwittingly expose sensitive data, mishandle authentication tokens, or install unverified dependencies. Threats such as prompt injection, dependency confusion, or secret leakage via AI-generated commits are increasingly documented in agentic pipelines. Defending against these vulnerabilities necessitates rigorous sandboxing, zero-trust security policies, prompt sanitization, and cryptographic verification for all actions taken by autonomous code agents. B. Limitations of Vibe Coding While vibe coding tools promote flexibility and creative exploration, they suffer from systemic challenges rooted in the opacity of model outputs and the lack of integration with formal software development lifecycles. Chief among these is the black-box nature of generation. Most LLM-based coding assistants do not expose their internal decision processes, making it difficult for developers to validate code correctness, interpret logic Opaque Logic Overdependence Vibe Coding Challenges Agentic Coding Challenges Code Quality Drift Integration Issues Security Risks Silent Errors Vibe Coding: creative but opaque and hard to integrate. Agentic Coding: powerful but risk-prone and autonomous. Fig. 7: Comparison of challenge domains for Vibe Coding (left) and Agentic Coding (right) using mindmap representation. decisions, or trace performance regressions. This undermines trust in high-stakes domains, especially when generated code is inserted into production pathways. Furthermore, the stochasticity of model outputs can lead to inconsistent quality even under near-identical prompts. Another prominent limitation of vibe coding is its poor compatibility with production-oriented development systems. Generated code often functions well in isolation but fails when incorporated into real-world environments due to missing context such as authentication flows, deployment configurations, or CI/CD hooks. Without access to full project state or execution context, LLMs are prone to suggesting solutions that ignore runtime dependencies or system architecture constraints. This makes them ideal for scaffolding or ideation, but suboptimal for system-level implementation unless paired with structured review protocols and toolchain integration. Finally, the rapid, iterative style of vibe coding can erode long-term code quality. Developers focused on short feedback cycles may forgo documentation, unit testing, or adherence to architectural principles. Over this contributes to codebases riddled with dutime, plication, inconsistent naming, security shortcuts, and unmaintainable logic an accumulation of technical debt with systemic consequences. Effective interventions include mandatory linting, automated test scaffolding, and enforced review pipelines for all AI-assisted code merges. Vibe tools should serve as accelerators, not replacements, for engineering best practices. IX. FUTURE ROADMAP: ADVANCING AGENTIC AI FOR AUTONOMOUS SOFTWARE ENGINEERING The future of AI-assisted programming (As depicted in Figure 8) will be increasingly shaped by the maturity and proliferation of agentic coding systems platforms that do not merely assist in code generation but autonomously plan, execute, test, and validate software development tasks across the engineering lifecycle. As organizations seek to scale automation, reduce technical debt, and manage complex digital ecosystems, agentic AI stands at the frontier of practical transformation. This roadmap outlines the core trajectories, challenges, and infrastructure required to operationalize agentic systems responsibly and at scale. A. Architecting Trustworthy Autonomy The next generation of agentic AI must prioritize trust, reliability, and governance. This entails shift from static model inference to dynamic, feedback-rich execution environments. Agents must be designed with embedded explainability generating transparent logs, semantic diffs, decision traces, and rollback records. As software teams integrate agents into CI/CD pipelines, static and dynamic analysis tools must be extended to interpret AI-generated logic and expose risks early. Moreover, agentic systems must comply with software assurance standards. This includes regulatory compliance (e.g., GDPR, ISO/IEC 27001), organizational policies (e.g., coding conventions, security models), and runtime safety guarantees. Future agentic frameworks will require built-in guardrails such as rule-based policy engines, automated rollback triggers, and runtime permisReal-Time Diagnostics Supervision Tools Vibe-Driven Ideation Agentic Scaling Visual Dashboards Human-AI Interface"
        },
        {
            "title": "Hybrid Workflow\nDesign",
            "content": "Continuous Feedback Explainable Logs & Diffs Runtime Policies & Sandboxes"
        },
        {
            "title": "Trustworthy\nAutonomy",
            "content": "Regulatory Compliance Context Continuity"
        },
        {
            "title": "Memory\nContext",
            "content": "Bug History Learning Long-Term Memory Multi-Agent Systems Communication Protocols Planner-TesterReviewer Task Graph Orchestration Fig. 8: Mindmap overview of the future roadmap for Agentic AI in autonomous software engineering, including key directions such as trustworthy autonomy, multi-agent systems, hybrid workflow integration, memory persistence, and human-AI supervision. sion sandboxes that enforce zero-trust principles during execution. backbone of future software education and organizational readiness. B. Multi-Agent Collaboration and Specialization Scalability in agentic coding will emerge not from single monolithic agent, but from constellation of specialized sub-agents planners, coders, testers, reviewers coordinated by an orchestrator. Inspired by distributed systems theory and modular programming paradigms, such multi-agent architectures will enable parallel task decomposition, resource optimization, and resilience through redundancy. To enable meaningful collaboration among agents, shared language and structured communication protocol will be necessary. Advancements in function-calling, task graph serialization, and contextual memory sharing will allow agents to synchronize states, pass artifacts, and coalesce outputs into consistent deliverables. This architectural pattern will mirror human software teams, enabling software construction to scale without linear increases in human supervision. C. Memory, Context, and Long-Term Adaptation Agentic AI will only succeed in production settings if it can reason across time, projects, and usage conintegrate both short-term texts. Future systems must (working) memory and persistent memory (organizational preferences, historical codebase patterns, bug history). Memory-augmented LLMs or retrieval-based hybrid agents will be critical in maintaining task continuity and avoiding context fragmentation over multi-hour or multi-day tasks. Additionally, learning from operational feedback will become central to agent refinement. Mechanisms such as reinforcement learning from human feedback (RLHF), offline evaluation from logs, and interactive model distillation will allow agents to align with evolving team practices, technology stacks, and user expectations. These capabilities will gradually shift agents from static models to continuously improving team members. D. Human-AI Collaboration Infrastructure Agentic coding should not replace developers but elevate them to higher-order roles strategic planners, architectural reviewers, and AI supervisors. To support this shift, integrated human-agent interfaces must evolve. Rich visualization dashboards, interpretability overlays, interactive agent simulations, and real-time progress diagnostics will empower humans to supervise AI workflows effectively. Training developers to interpret, configure, and intervene in agent behavior will be essential. AI literacy programs, sandbox testing environments, and debugging toolkits tailored for AI-generated systems will form the E. 5. Strategic Integration and Hybrid Workflow Design The future of software development lies not in choosing between vibe coding and agentic coding but in combining their strengths. Vibe coding ideal for earlystage ideation, UX design, and experimental workflows will serve as the creative front-end. Agentic coding engineered for precision, automation, and long-horizon planning will operationalize and scale those ideas into robust, production-grade systems. Hybrid workflows will increasingly rely on seamless transitions: vibe tools initiating conceptual drafts, agentic agents refining and deploying them, and human teams orchestrating this interplay through continuous feedback loops. These workflows will not only maximize efficiency and innovation but also create resilient software systems that adapt to future complexity. Agentic AI promises paradigm shift in software engineering transforming AI from passive assistant to an autonomous co-developer. Realizing this potential demands more than algorithmic power; it requires trustworthy infrastructure, human-centered design, and rigorous governance. The roadmap to agentic maturity is socio-technical journey one that redefines collaboration, responsibility, and intelligence in software creation. Those who invest early in this convergence will shape the foundational tools of the next engineering era. F. Historical Evolution of AI Agents: From Rule-Based Systems to Agentic AI The trajectory of AI agents reflects four-decade-long transformation from symbolic, rule-based automation to generative, goal-directed intelligence. Understanding this historical evolution is essential for grounding future developments in Agentic AI within the broader arc of artificial intelligence research. In the 1990s, AI agents were largely constructed as symbolic software entities [238][240], grounded in deterministic logic [241], [242] and finite-state control systems [243], [244]. Representative systems included intelligent tutoring agents like SHERLOCK [245][247] and Andes [248][250], which delivered domain-specific instruction using scripted pedagogical rules. Concurrently, mobile agents such as General Magics Telescript [251] facilitated lightweight task execution across distributed networks [252]. Behavioral models like the Belief-Desire-Intention (BDI) framework (e.g., PRS, JAM) formalized rational planning under constrained environments [253]. However, these early agents lacked learning capability, contextual reasoning, and autonomy beyond their initial programming. The 2000s and 2010s marked pivotal shift toward learning-based and networked agents [254], [255]. Advances in reinforcement learning (e.g., TD-Gammon [256] and Deep Q-Networks) enabled agents to optimize behavior through reward-driven feedback. Multiagent systems (MAS) using frameworks such as JADE enabled collaboration negotiation, and task allocation across agents [257][259]. These architectures found use in traffic systems, robotic swarms, and industrial simulation. Chatbots and NLP agents matured with systems like Siri and Alexa, offering human-AI dialogue capabilities grounded in statistical language models. While more adaptable, these systems remained bounded by taskspecific learning and lacked the emergent planning and reasoning evident in human cognition. The 2020s usher in new paradigm: agentic coding powered by large language models (LLMs). Unlike their predecessors, LLM-based agents (e.g., AutoGPT [260], BabyAGI Baby AGI, Devin Devin AI, Codex OpenAI Codex) demonstrate the ability to decompose abstract goals, synthesize code, invoke APIs, interact with development environments, and reason iteratively through planning-execution-feedback loops. These agents use components such as memory buffers, tool use modules, sandboxed execution environments, and self-verification routines to operate autonomously in complex, real-world software engineering tasks. For instance, Codex-based systems execute end-to-end pipelines cloning GitHub repositories, updating codebases, testing, and committing patches without line-by-line developer supervision. This level of autonomy and contextual awareness signals profound leap in agent capability. These trends signify not only an evolution in computational architecture but deepening of the cognitive model underlying artificial agents. The agent is no longer function executor or rule follower, but self-reflective, goal-seeking entity capable of autonomous software generation, debugging, and deployment. As we move forward, the synthesis of historical rule-based robustness with modern generative flexibility offers foundation for building trustworthy, transparent, and socially-aligned Agentic AI systems. By drawing on decades of agent modeling from BDI frameworks to LLM orchestration future systems can achieve both operational excellence and epistemic alignment with human objectives. X. CONCLUSION This review presented comprehensive comparative analysis of two emerging paradigms in AI-assisted software development: vibe coding and agentic coding. By systematically tracing their conceptual foundations, interaction models, technical architectures, and practical workflows, we highlighted how these approaches reflect distinct philosophies in human-AI collaboration. Vibe coding, as discussed, is rooted in intuitiondriven, prompt-based development that emphasizes cocreation, creativity, and flexibility. It foregrounds developer control, iterative experimentation, and converideation, supported by set of foundational sational cognitive skills that reorient programming as semiotic dialogue between human intent and machine synthesis. In contrast, agentic coding represents paradigm shift toward autonomous software engineering systems. These systems leverage architectural modules such as planners, executors, memory buffers, and feedback-integrated agents capable of operating across the software lifecycle. Our investigation into their execution models, safety protocols, and developer interaction revealed how agentic systems enable delegation of complex development tasks while introducing new challenges in explainability, governance, and secure operation. We further compared their autonomy mechanisms, debugging strategies, tool ecosystems, and implementation pathways. Through illustrative workflows and real-world applications from social media prototyping to automated legacy refactoring we demonstrated how vibe coding excels in ideation and learning environments, while agentic coding is wellsuited for scalable automation, CI/CD integration, and enterprise-grade reliability. The final sections synthesized industry trends, adoption barriers, and the convergence toward hybrid workflows, where conversational ideation is seamlessly fused with autonomous implementation. We also outlined future roadmap for advancing agentic AI emphasizing trustworthy autonomy, multiagent orchestration, contextual memory, and humancentered interfaces. Ultimately, this review frames vibe and agentic coding not as competing paradigms, but as complementary pillars in the future of AI-driven software engineering each contributing uniquely to the evolving landscape of human-machine co-development."
        },
        {
            "title": "ACKNOWLEDGEMENT",
            "content": "This work was supported by the National Science Foundation and the United States Department of Agriculture, National Institute of Food and Agriculture through the Artificial Intelligence (AI) Institute for Agriculture Program under Award AWD003473, and AWD004595, Accession Number 1029004, Robotic Blossom Thinning with Soft Manipulators. The publication of the article in OA mode was financially supported by HEALLink."
        },
        {
            "title": "DECLARATIONS",
            "content": "The authors declare no conflicts of interest."
        },
        {
            "title": "STATEMENT ON AI WRITING ASSISTANCE",
            "content": "ChatGPT and Perplexity were utilized to enhance grammatical accuracy and refine sentence structure; all AI-generated revisions were thoroughly reviewed and edited for relevance. Additionally, ChatGPT-4o was employed to generate realistic visualizations."
        },
        {
            "title": "REFERENCES",
            "content": "[1] M. Chow and O. Ng, From technology adopters to creators: Leveraging ai-assisted vibe coding to transform clinical teaching and learning, Medical Teacher, pp. 13, 2025. [2] D. Weise and R. Crew, Programmable syntax macros, in Proceedings of the ACM SIGPLAN 1993 conference on Programming language design and implementation, pp. 156165, 1993. [3] B. McCane, C. Ott, N. Meek, and A. Robins, Mastery learning in introductory programming, in Proceedings of the nineteenth australasian computing education conference, pp. 110, 2017. [4] A. Luxton-Reilly, B. A. Becker, Y. Cao, R. McDermott, C. Mirolo, A. Muhling, A. Petersen, K. Sanders, Simon, and J. Whalley, Developing assessments to determine mastery of programming fundamentals, in Proceedings of the 2017 ITiCSE Conference on Working Group Reports, pp. 4769, 2018. [5] J. Condit, M. Harren, Z. Anderson, D. Gay, and G. C. Necula, Dependent types for low-level programming, in Programming Languages and Systems: 16th European Symposium on Programming, ESOP 2007, Held as Part of the Joint European Conferences on Theory and Practics of Software, ETAPS 2007, Braga, Portugal, March 24-April 1, 2007. Proceedings 16, pp. 520535, Springer, 2007. [6] J. Protzenko, J.-K. Zinzindohoue, A. Rastogi, T. Ramananandro, P. Wang, S. Zanella-Beguelin, A. Delignat-Lavaud, C. Hritcu, K. Bhargavan, C. Fournet, et al., Verified low-level programming embedded in f, Proceedings of the ACM on Programming Languages, vol. 1, no. ICFP, pp. 129, 2017. [7] M. Balliu, M. Dam, and R. Guanciale, Automating information flow analysis of low level code, in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pp. 10801091, 2014. [8] A. Gadde, Democratizing software engineering through generative ai and vibe coding: The evolution of no-code development, Journal of Computer Science and Technology Studies, vol. 7, no. 4, pp. 556572, 2025. [9] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al., Gpt-4 technical report, arXiv preprint arXiv:2303.08774, 2023. [10] J. L. Fiadeiro, Categories for software engineering. Springer Science & Business Media, 2005. [11] T. Givon, Iconicity, isomorphism, and non-arbitrary coding in syntax, in Iconicity in syntax, pp. 187220, John Benjamins Publishing Company, 2011. [12] F. Maiorana, D. Giordano, and R. Morelli, Quizly: live coding assessment platform for app inventor, in 2015 IEEE Blocks and Beyond Workshop (Blocks and Beyond), pp. 2530, IEEE, 2015. [13] D. A. Tamburri, P. Lago, and H. v. Vliet, Organizational social structures for software engineering, ACM Computing Surveys (CSUR), vol. 46, no. 1, pp. 135, 2013. [14] P. Dourish, Algorithms and their others: Algorithmic culture in context, Big Data & Society, vol. 3, no. 2, p. 2053951716665128, 2016. [15] A. D. Gordon, T. A. Henzinger, A. V. Nori, and S. K. Rajamani, Probabilistic programming, in Future of software engineering proceedings, pp. 167181, ACM, 2014. [16] D. Jenson and M. Riedel, deterministic approach to stochastic computation, in 2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pp. 18, IEEE, 2016. [17] B. Liskavets, M. Ushakov, S. Roy, M. Klibanov, A. Etemad, and S. K. Luke, Prompt compression with context-aware sentence encoding for fast and improved llm inference, in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 39, pp. 2459524604, 2025. [18] Y. Li, Y. Peng, Y. Huo, and M. R. Lyu, Enhancing llm-based coding tools through native integration of ide-derived static context, in Proceedings of the 1st International Workshop on Large Language Models for Code, pp. 7074, 2024. [19] R. Sapkota, K. I. Roumeliotis, and M. Karkee, Ai agents vs. agentic ai: conceptual taxonomy, applications and challenges, arXiv preprint arXiv:2505.10468, 2025. [20] J. Pohler, N. Flegel, T. Mentler, and K. Van Laerhoven, Keeping the human in the loop: are autonomous decisions inevitable?, i-com, vol. 24, no. 1, pp. 925, 2025. [21] U. M. Borghoff, P. Bottoni, and R. Pareschi, Human-artificial interaction in the age of agentic ai: system-theoretical approach, Frontiers in Human Dynamics, vol. 7, p. 1579166, 2025. [22] F. Bousetouane, Agentic systems: guide to transformagents, arXiv preprint ai ing industries with vertical arXiv:2501.00881, 2025. [23] J. Yuan, K. Miao, H. Oh, I. Walker, Z. Xue, T. Katolikyan, and M. Cavallo, Vibe: visual analytics workflow for semantic error analysis of cvml models at subgroup level, in Proceedings of the 30th International Conference on Intelligent User Interfaces, pp. 15291547, 2025. [24] M. Yin and R. Xiao, Vibes: Exploring viewer spatial interactions as direct input for livestreamed content, arXiv preprint arXiv:2504.09016, 2025. [25] T. De Jong, Learning and instruction with computer simulations, Education and Computing, vol. 6, no. 3-4, pp. 217229, 1991. [26] W. D. Maurer, theory of computer instructions, Science of Computer Programming, vol. 60, no. 3, pp. 244273, 2006. [27] L. K. Smetana and R. L. Bell, Computer simulations to support science instruction and learning: critical review of the literature, International Journal of Science Education, vol. 34, no. 9, pp. 13371370, 2012. [28] D. Nam, A. Macvean, V. Hellendoorn, B. Vasilescu, and B. Myers, Using an llm to help with code understanding, in Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, pp. 113, 2024. [29] H. Liao, H. Shen, Z. Li, C. Wang, G. Li, Y. Bie, and C. Xu, Gpt-4 enhanced multimodal grounding for autonomous driving: Leveraging cross-modal attention with large language models, Communications in Transportation Research, vol. 4, p. 100116, 2024. [30] T. Coignion, C. Quinton, and R. Rouvoy, performance study of llm-generated code on leetcode, in Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering, pp. 7989, 2024. [31] Z. Rasheed, M. A. Sami, M. Waseem, K.-K. Kemell, X. Wang, A. Nguyen, K. Systa, and P. Abrahamsson, Aipowered code review with llms: Early results, arXiv preprint arXiv:2404.18496, 2024. [32] J. Wang and Y. Chen, review on code generation with llms: Application and evaluation, in 2023 IEEE International Conference on Medical Artificial Intelligence (MedAI), pp. 284 289, IEEE, 2023. [33] L. Fichtel, M. Spliethover, E. Hullermeier, P. Jimenez, N. Klowait, S. Kopp, A.-C. N. Ngomo, A. Robrecht, I. Scharlau, L. Terfloth, et al., Investigating co-constructive behavior of large language models in explanation dialogues, arXiv preprint arXiv:2504.18483, 2025. [34] B. Mesko, Prompt engineering as an important emerging skill for medical professionals: tutorial, Journal of medical Internet research, vol. 25, p. e50638, 2023. [35] J. White, Q. Fu, S. Hays, M. Sandborn, C. Olea, H. Gilbert, A. Elnashar, J. Spencer-Smith, and D. C. Schmidt, prompt pattern catalog to enhance prompt engineering with chatgpt, arXiv preprint arXiv:2302.11382, 2023. [36] E. Y. Chang, Prompting large language models with the socratic method, in 2023 IEEE 13th annual computing and communication workshop and conference (CCWC), pp. 0351 0360, IEEE, 2023. [37] A. Alfageeh, S. A. K. Zarkouei, D. Nam, D. Prol, M. Amoozadeh, S. Chattopadhyay, J. Prather, P. Denny, J. Leinonen, M. Hilton, et al., From prompts to propositions: logic-based lens on student-llm interactions, arXiv preprint arXiv:2504.18691, 2025. [38] Z. Xiao, D. Zhang, X. Han, X. Fu, W. Y. Yu, T. Zhong, S. Wu, Y. Wang, J. Yin, and G. Chen, Enhancing llm reasoning via vision-augmented prompting, Advances in Neural Information Processing Systems, vol. 37, pp. 2877228797, 2024. [39] J. Gao, S. A. Gebreegziabher, K. T. W. Choo, T. J.-J. Li, S. T. Perrault, and T. W. Malone, taxonomy for human-llm interaction modes: An initial exploration, in Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pp. 111, 2024. [40] X. Ma, S. Mishra, A. Liu, S. Y. Su, J. Chen, C. Kulkarni, H.- T. Cheng, Q. Le, and E. Chi, Beyond chatbots: Explorellm for structured thoughts and personalized model responses, in Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pp. 112, 2024. [41] Y.-M. Yan, C.-Q. Chen, Y.-B. Hu, and X.-D. Ye, Llm-based collaborative programming: impact on students computational thinking and self-efficacy, Humanities and Social Sciences Communications, vol. 12, no. 1, pp. 112, 2025. [42] A. Xenakis, I. Dimos, M. Feidakis, D. Sotiropoulos, K. Kalovrektis, and G. Nikolaou, An llm-based smart repository platform to support educators with computational thinking, ai, and stem activities, in Empowering STEM Educators With Digital Tools, pp. 107136, IGI Global Scientific Publishing, 2025. [43] D. Yang, T. Liu, D. Zhang, A. Simoulin, X. Liu, Y. Cao, Z. Teng, X. Qian, G. Yang, J. Luo, et al., Code to think, think to code: survey on code-enhanced reasoning and reasoning-driven code intelligence in llms, arXiv preprint arXiv:2502.19411, 2025. [44] H. Subramonyam, R. Pea, C. Pondoc, M. Agrawala, and C. Seifert, Bridging the gulf of envisioning: Cognitive challenges in prompt based interactions with llms, in Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, pp. 119, 2024. [45] T. Wu, J. Lan, W. Yuan, J. Jiao, J. Weston, and S. Sukhbaatar, instruction following with thought Thinking llms: General generation, arXiv preprint arXiv:2410.10630, 2024. [46] H. Xu and X.-Y. Yu, From powerpoint ui sketches to web-based applications: Pattern-driven code generation for gis dashboard development using knowledge-augmented llms, context-aware visual prompting, and the react framework, arXiv preprint arXiv:2502.08756, 2025. [47] Y. Yigit, M. A. Ferrag, M. C. Ghanem, I. H. Sarker, L. A. Maglaras, C. Chrysoulas, N. Moradpoor, N. Tihanyi, and H. Janicke, Generative ai and llms for critical infrastructure protection: evaluation benchmarks, agentic ai, challenges, and opportunities, Sensors, vol. 25, no. 6, p. 1666, 2025. [48] A. Wei, N. Haghtalab, and J. Steinhardt, Jailbroken: How does llm safety training fail?, Advances in Neural Information Processing Systems, vol. 36, pp. 8007980110, 2023. [49] Y. Mou, S. Zhang, and W. Ye, Sg-bench: Evaluating llm safety generalization across diverse tasks and prompt types, Advances in Neural Information Processing Systems, vol. 37, pp. 123032 123054, 2024. [50] V.-A. P? durean, P. Denny, and A. Singla, Bugspotter: Automated generation of code debugging exercises, in Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1, pp. 896902, 2025. [51] N. Jiang, X. Li, S. Wang, Q. Zhou, S. Hossain, B. Ray, V. Kumar, X. Ma, and A. Deoras, Ledex: Training llms to better self-debug and explain code, Advances in Neural Information Processing Systems, vol. 37, pp. 3551735543, 2024. [52] R. Tian, Y. Ye, Y. Qin, X. Cong, Y. Lin, Y. Pan, Y. Wu, H. Hui, W. Liu, Z. Liu, et al., Debugbench: Evaluating debugging capability of large language models, arXiv preprint arXiv:2401.04621, 2024. [53] C. Lee, C. S. Xia, L. Yang, J.-t. Huang, Z. Zhu, L. Zhang, and M. R. Lyu, unified debugging approach via llm-based multi-agent synergy, arXiv preprint arXiv:2404.17153, 2024. [54] S. An, Z. Ma, Z. Lin, N. Zheng, J.-G. Lou, and W. Chen, Make your llm fully utilize the context, Advances in Neural Information Processing Systems, vol. 37, pp. 6216062188, 2024. [55] M. X. Liu, F. Liu, A. J. Fiannaca, T. Koo, L. Dixon, M. Terry, and C. J. Cai, we need structured output: Towards usercentered constraints on large language model output, in Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pp. 19, 2024. [56] S. Kapania, R. Wang, T. J.-J. Li, T. Li, and H. Shen, im categorizing llm as productivity tool: Examining ethics of llm use in hci research practices, Proceedings of the ACM on Human-Computer Interaction, vol. 9, no. 2, pp. 126, 2025. [57] X. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo, D. Lo, J. Grundy, and H. Wang, Large language models for software engineering: systematic literature review, ACM Transactions on Software Engineering and Methodology, vol. 33, no. 8, pp. 179, 2024. [58] M. R. Lyu, B. Ray, A. Roychoudhury, S. H. Tan, and P. Thongtanunam, Automatic programming: Large language models and beyond, ACM Transactions on Software Engineering and Methodology, 2024. [59] S. Wijaya, J. Bolano, A. G. Soteres, S. Kode, Y. Huang, and A. Sahai, Readme. llm: framework to help llms understand your library, arXiv preprint arXiv:2504.09798, 2025. [60] S. H. Maes, The gotchas of ai coding and vibe coding. its all about support and maintenance, 2025. [61] M. Kumar, J. Xue, M. Zheng, and Q. Lou, Tfhe-coder: Evaluating llm-agentic fully homomorphic encryption code generation, arXiv preprint arXiv:2503.12217, 2025. [62] A. Roychoudhury, C. Pasareanu, M. Pradel, and B. Ray, Agentic ai software engineer: Programming with trust, arXiv preprint arXiv:2502.13767, 2025. [63] G. Zhang, W. Liang, O. Hsu, and K. Olukotun, Adaptive selfimprovement llm agentic system for ml library development, arXiv preprint arXiv:2502.02534, 2025. [64] B. Lou, T. Lu, R. Santanam, and Y. Zhang, Unraveling teaming: review and outlook, arXiv preprint human-ai arXiv:2504.05755, 2025. [65] H. Shen, L. Shen, W. Wu, and K. Zhang, Ideationweb: Tracking the evolution of design ideas in human-ai co-creation, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 119, 2025. [66] W. Wang, H. Ning, G. Zhang, L. Liu, and Y. Wang, Rocks coding, not development: human-centric, experimental evaluation of llm-supported se tasks, Proceedings of the ACM on Software Engineering, vol. 1, no. FSE, pp. 699721, 2024. [67] L. Hammond, A. Chan, J. Clifton, J. Hoelscher-Obermaier, A. Khan, E. McLean, C. Smith, W. Barfuss, J. Foerster, T. Gavenˇciak, et al., Multi-agent risks from advanced ai, arXiv preprint arXiv:2502.14143, 2025. [68] A. Kasirzadeh and I. Gabriel, Characterizing ai agents for alignment and governance, arXiv preprint arXiv:2504.21848, 2025. [69] M. Tufano, A. Agarwal, J. Jang, R. Z. Moghaddam, and N. Sundaresan, Autodev: Automated ai-driven development, arXiv preprint arXiv:2403.08299, 2024. [70] P. J. Sager, B. Meyer, P. Yan, R. von Wartburg-Kottler, L. Etaiwi, A. Enayati, G. Nobel, A. Abdulkadir, B. F. Grewe, and T. Stadelmann, Ai agents for computer use: review of instructionbased computer control, gui automation, and operator assistants, arXiv preprint arXiv:2501.16150, 2025. [71] H. Wen, Y. Li, G. Liu, S. Zhao, T. Yu, T. J.-J. Li, S. Jiang, Y. Liu, Y. Zhang, and Y. Liu, Autodroid: Llm-powered task automation in android, in Proceedings of the 30th Annual International Conference on Mobile Computing and Networking, pp. 543 557, 2024. [72] M. Xu, Every software as an agent: Blueprint and case study, arXiv preprint arXiv:2502.04747, 2025. [73] Q. Ma, W. Peng, C. Yang, H. Shen, K. Koedinger, and T. Wu, What should we engineer in prompts? training humans in requirement-driven llm use, ACM Transactions on ComputerHuman Interaction, 2025. [74] T. Wu, E. Jiang, A. Donsbach, J. Gray, A. Molina, M. Terry, and C. J. Cai, Promptchainer: Chaining large language model prompts through visual programming, in CHI Conference on Human Factors in Computing Systems Extended Abstracts, pp. 110, 2022. [75] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, and M. Sun, Communicative agents for software development, arXiv preprint arXiv:2307.07924, vol. 6, no. 3, 2023. [76] H. Triedman, R. Multi-agent systems execute arbitrary malicious code, arXiv preprint arXiv:2503.12188, 2025. and V. Shmatikov, Jha, [77] J. Luo, W. Zhang, Y. Yuan, Y. Zhao, J. Yang, Y. Gu, B. Wu, B. Chen, Z. Qiao, Q. Long, et al., Large language model agent: survey on methodology, applications and challenges, arXiv preprint arXiv:2503.21460, 2025. [78] N. Krishnan, Advancing multi-agent systems through model implementation, and applicacontext protocol: Architecture, tions, arXiv preprint arXiv:2504.21030, 2025. [79] I. Habler, K. Huang, V. S. Narajala, and P. Kulkarni, Building secure agentic ai application leveraging a2a protocol, arXiv preprint arXiv:2504.16902, 2025. [80] A. Rath, Structured prompting and feedback-guided reasoning with llms for data interpretation, arXiv preprint arXiv:2505.01636, 2025. [81] S.-C. Dai, A. Xiong, and L.-W. Ku, Llm-in-the-loop: Leveraging large language model for thematic analysis, arXiv preprint arXiv:2310.15100, 2023. [82] M. Kazemitabaar, X. Hou, A. Henley, B. J. Ericson, D. Weintrop, and T. Grossman, How novices use llm-based code generators to solve cs1 coding tasks in self-paced learning environment, in Proceedings of the 23rd Koli calling international conference on computing education research, pp. 112, 2023. [83] J. White, S. Hays, Q. Fu, J. Spencer-Smith, and D. C. Schmidt, Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design, in Generative ai for effective software development, pp. 71108, Springer, 2024. [84] J. Wang, Y. Dai, Y. Zhang, Z. Ma, W. Li, and J. Chai, Training turn-by-turn verifiers for dialogue tutoring agents: The curious case of llms as your coding tutors, arXiv preprint arXiv:2502.13311, 2025. [85] H. Ding, Z. Fan, I. Guehring, G. Gupta, W. Ha, J. Huan, L. Liu, B. Omidvar-Tehrani, S. Wang, and H. Zhou, Reasoning and planning with large language models in code development, in Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 64806490, 2024. [86] M. A. Ferrag, N. Tihanyi, and M. Debbah, From llm reasoning to autonomous ai agents: comprehensive review, arXiv preprint arXiv:2504.19678, 2025. [87] R. Pan, H. Zhang, and C. Liu, Codecor: An llm-based selfreflective multi-agent framework for code generation, arXiv preprint arXiv:2501.07811, 2025. [88] Z. Sun, H. Zhu, B. Xu, X. Du, L. Li, and D. Lo, Llm as runtime error handler: promising pathway to adaptive self-healing of software systems, arXiv preprint arXiv:2408.01055, 2024. [89] C. Guo, X. Liu, C. Xie, A. Zhou, Y. Zeng, Z. Lin, D. Song, and B. Li, Redcode: Risky code execution and generation benchmark for code agents, Advances in Neural Information Processing Systems, vol. 37, pp. 106190106236, 2024. [90] R. Qiang, Y. Zhuang, Y. Li, R. Zhang, C. Li, I. S.-H. Wong, S. Yang, P. Liang, C. Zhang, B. Dai, et al., Mle-dojo: Interactive environments for empowering llm agents in machine learning engineering, arXiv preprint arXiv:2505.07782, 2025. [91] E. Poitras, B. Crane, and A. Siegel, Generative ai in introductory programming instruction: Examining the assistance dilemma with llm-based code generators, in Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1, pp. 186192, 2024. [92] A. Nunez, N. T. Islam, S. K. Jha, and P. Najafirad, Autosafecoder: multi-agent framework for securing llm code generation through static analysis and fuzz testing, arXiv preprint arXiv:2409.10737, 2024. [93] X. Song, Y. Wu, W. Wang, J. Liu, W. Su, and B. Zheng, Progco: Program helps self-correction of large language models, arXiv preprint arXiv:2501.01264, 2025. [94] A. Askari, C. Poelitz, and X. Tang, Magic: Generating selfcorrection guideline for in-context text-to-sql, in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 39, pp. 2343323441, 2025. [95] B. Wei, Requirements are all you need: From requirements to code with llms, in 2024 IEEE 32nd International Requirements Engineering Conference (RE), pp. 416422, IEEE, 2024. [96] H. Fang, B. Han, N. Erickson, X. Zhang, S. Zhou, A. Dagar, J. Zhang, A. C. Turkmen, C. Hu, H. Rangwala, et al., Mlzero: multi-agent system for end-to-end machine learning automation, arXiv preprint arXiv:2505.13941, 2025. [97] S. Agashe, J. Han, S. Gan, J. Yang, A. Li, and X. E. Wang, Agent s: An open agentic framework that uses computers like human, arXiv preprint arXiv:2410.08164, 2024. [98] E. Tzanis and M. E. Klontzas, maistro: an open-source multiagentic system for automated end-to-end development of radiomics and deep learning models for medical imaging, arXiv preprint arXiv:2505.03785, 2025. [99] A. Mohsin, H. Janicke, A. Wood, I. H. Sarker, L. Maglaras, and N. Janjua, Can we trust large language models generated code? framework for in-context learning, security patterns, and code evaluations across diverse llms, arXiv preprint arXiv:2406.12513, 2024. [100] A. Tolzin and A. Janson, Uncovering the mechanisms of common ground in humanagent interaction: review and future directions for conversational agent research, Internet Research, 2025. [101] Y. Shentu, P. Wu, A. Rajeswaran, and P. Abbeel, From llms to actions: latent codes as bridges in hierarchical robot control, in 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 85398546, IEEE, 2024. [102] S. Joel, J. J. Wu, and F. H. Fard, survey on llm-based code generation for low-resource and domain-specific programming languages, arXiv preprint arXiv:2410.03981, 2024. [103] Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang, S. Zhang, J. Liu, et al., Autogen: Enabling next-gen llm applications via multi-agent conversation, arXiv preprint arXiv:2308.08155, 2023. [104] Y. Ishibashi and Y. Nishimura, Self-organized agents: llm multi-agent framework toward ultra large-scale code generation and optimization, arXiv preprint arXiv:2404.02183, 2024. [105] Z. Rasheed, M. A. Sami, K.-K. Kemell, M. Waseem, M. Saari, K. Systa, and P. Abrahamsson, Codepori: Large-scale system for autonomous software development using multi-agent technology, arXiv preprint arXiv:2402.01411, 2024. [106] M. Puvvadi, S. K. Arava, A. Santoria, S. S. P. Chennupati, and H. V. Puvvadi, Coding agents: comprehensive survey of automated bug fixing systems and benchmarks, in 2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT), pp. 680686, IEEE, 2025. [107] J. Tang, T. Fan, and C. Huang, Metachain: fully-automated llm agents, arXiv preprint and zero-code framework for arXiv:2502.05957, 2025. [108] Z. Liu, H. Li, J. Lu, G. Ma, X. Hong, G. Iacca, A. Kumar, S. Tang, and L. Wang, Natures insight: novel framework and comprehensive analysis of agentic reasoning through the lens of neuroscience, arXiv preprint arXiv:2505.05515, 2025. [109] J. Schneider, Generative to agentic ai: Survey, conceptualization, and challenges, arXiv preprint arXiv:2504.18875, 2025. [110] P. Bornet, J. Wirtz, T. H. Davenport, D. De Cremer, B. Evergreen, P. Fersht, R. Gohel, S. Khiyara, P. Sund, and N. Mullakara, Agentic Artificial Intelligence: Harnessing AI Agents to Reinvent Business, Work and Life. Irreplaceable Publishing, 2025. [111] B. Mohammadi, Pel, programming language for orchestrating ai agents, arXiv preprint arXiv:2505.13453, 2025. [112] B. Liu, X. Li, J. Zhang, J. Wang, T. He, S. Hong, H. Liu, S. Zhang, K. Song, K. Zhu, et al., Advances and challenges in foundation agents: From brain-inspired intelligence to evolutionary, collaborative, and safe systems, arXiv preprint arXiv:2504.01990, 2025. [113] W. Xu, K. Mei, H. Gao, J. Tan, Z. Liang, and Y. Zhang, A-mem: Agentic memory for llm agents, arXiv preprint arXiv:2502.12110, 2025. [114] E. Miehling, K. N. Ramamurthy, K. R. Varshney, M. Riemer, D. Bouneffouf, J. T. Richards, A. Dhurandhar, E. M. Daly, M. Hind, P. Sattigeri, et al., Agentic ai needs systems theory, arXiv preprint arXiv:2503.00237, 2025. [115] M. Fabian and M. Dold, Agentic preferences: foundation for nudging when preferences are endogenous, Behavioural Public Policy, vol. 9, no. 1, pp. 249269, 2025. [116] F. Kamalov, D. S. Calonge, L. Smail, D. Azizov, D. R. Thadani, T. Kwong, and A. Atif, Evolution of ai in education: Agentic workflows, arXiv preprint arXiv:2504.20082, 2025. [117] M. Worring, J. Zahalka, S. v. d. Elzen, M. Fischer, and D. Keim, multimedia analytics model for the foundation model era, arXiv preprint arXiv:2504.06138, 2025. [118] J. Feng, T. Yu, K. Zhang, and L. Cheng, Integration of multi-agent systems and artificial intelligence in self-healing subway power supply systems: Advancements in fault diagnosis, isolation, and recovery, Processes, vol. 13, no. 4, p. 1144, 2025. [119] Z. H. Goh and X. Zhang, Development and validation of the online agentic and communal behaviour scale: implications for emotional well-being, Behaviour & Information Technology, pp. 113, 2025. [120] N. Kshetri, Transforming cybersecurity with agentic ai to combat emerging cyber threats, Telecommunications Policy, p. 102976, 2025. [121] M. S. Patil, G. Ung, and M. Nyberg, Towards specificationdriven llm-based generation of embedded automotive software, in International Conference on Bridging the Gap between AI and Reality, pp. 125144, Springer, 2024. [122] G. Granberry, W. Ahrendt, and M. Johansson, Seeking specifications: The case for neuro-symbolic specification synthesis, arXiv preprint arXiv:2504.21061, 2025. [123] M. A. Haque, Llms: game-changer for software engineers?, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, p. 100204, 2025. [124] P. Yu, Y. Yang, J. Li, Z. Zhang, H. Wang, X. Feng, and F. Zhang, Multi-mission tool bench: Assessing the robustness of llm based agents through related and dynamic missions, arXiv preprint arXiv:2504.02623, 2025. [125] L. Deng, Q. Zhong, J. Song, H. Lei, and W. Li, Llm-based unknown function automated modeling in sensor-driven systems for multi-language software security verification, Sensors, vol. 25, no. 9, p. 2683, 2025. [126] Y. Zhang, Z. Ma, Y. Ma, Z. Han, Y. Wu, and V. Tresp, Webpilot: versatile and autonomous multi-agent system for web task execution with strategic exploration, in Proceedings the AAAI Conference on Artificial Intelligence, vol. 39, of pp. 2337823386, 2025. [127] H. Hexmoor, J. Lammens, G. Caicedo, and S. C. Shapiro, Behaviour based AI, cognitive processes, and emergent behaviors in autonomous agents, vol. 1. WIT Press, 2025. [128] Z. Wan, Y. Du, M. Ibrahim, J. Qian, J. Jabbour, Y. Zhao, T. Krishna, A. Raychowdhury, and V. J. Reddi, Reca: Integrated acceleration for real-time and efficient cooperative embodied autonomous agents, in Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, pp. 982997, 2025. [129] S. Chakraborty, S. Bhatt, U. M. Sehwag, S. S. Ghosal, J. Qiu, M. Wang, D. Manocha, F. Huang, A. Koppel, and S. Ganesh, Collab: Controlled decoding using mixture of agents for llm alignment, arXiv preprint arXiv:2503.21720, 2025. [130] D. Moshkovich, H. Mulian, S. Zeltyn, N. Eder, I. Skarbovsky, and R. Abitbol, Beyond black-box benchmarking: Observability, analytics, and optimization of agentic systems, arXiv preprint arXiv:2503.06745, 2025. [131] M. Robeyns, M. Szummer, and L. Aitchison, self-improving coding agent, arXiv preprint arXiv:2504.15228, 2025. [132] S. Gandhi, D. Shah, M. Patwardhan, L. Vig, and G. Shroff, Researchcodeagent: An llm multi-agent system for automated codification of research methodologies, arXiv preprint arXiv:2504.20117, 2025. [133] B. Nadimi, G. O. Boutaib, and H. Zheng, Verimind: Agentic llm for automated verilog generation with novel evaluation metric, arXiv preprint arXiv:2503.16514, 2025. [134] Y. Y. Sung, H. Kim, and D. Zhang, Verila: human-centered evaluation framework for interpretable verification of llm agent failures, arXiv preprint arXiv:2503.12651, 2025. [135] Y. Qi, H. Peng, X. Wang, A. Xin, Y. Liu, B. Xu, L. Hou, and J. Li, Agentif: Benchmarking instruction following of large language models in agentic scenarios, arXiv preprint arXiv:2505.16944, 2025. [136] K. Wang, G. Zhang, Z. Zhou, J. Wu, M. Yu, S. Zhao, C. Yin, J. Fu, Y. Yan, H. Luo, et al., comprehensive survey in llm (-agent) full stack safety: Data, training and deployment, arXiv preprint arXiv:2504.15585, 2025. [137] K. Zhang, J. Li, G. Li, X. Shi, and Z. Jin, Codeagent: Enhancing code generation with tool-integrated agent systems for real-world repo-level coding challenges, arXiv preprint arXiv:2401.07339, 2024. [138] J. Jiang, F. Wang, J. Shen, S. Kim, and S. Kim, survey on large language models for code generation, arXiv preprint arXiv:2406.00515, 2024. [139] L. Chen, Q. Guo, H. Jia, Z. Zeng, X. Wang, Y. Xu, J. Wu, Y. Wang, Q. Gao, J. Wang, et al., survey on evaluating large language models in code generation tasks, arXiv preprint arXiv:2408.16498, 2024. [140] A. Rahman, V. Cvetkovic, K. Reece, A. Walters, Y. Hassan, A. Tummeti, B. Torres, D. Cooney, M. Ellis, and D. S. Nikolopoulos, Marco: multi-agent system for optimizing hpc code generation using large language models, arXiv preprint arXiv:2505.03906, 2025. [141] Y. Wang, S. Guo, Y. Pan, Z. Su, F. Chen, T. H. Luan, P. Li, J. Kang, and D. Niyato, Internet of agents: Fundamentals, applications, and challenges, arXiv preprint arXiv:2505.07176, 2025. [142] M. Xu, J. Fan, X. Huang, C. Zhou, J. Kang, D. Niyato, S. Mao, Z. Han, K.-Y. Lam, et al., Forewarned is forearmed: survey on large language model-based agents in autonomous cyberattacks, arXiv preprint arXiv:2505.12786, 2025. [143] P. R. Kothamali et al., Ai-powered quality assurance: Revolutionizing automation frameworks for cloud applications, Journal of Advanced Computing Systems, vol. 5, no. 3, pp. 1 25, 2025. [144] K. Pu, D. Lazaro, I. Arawjo, H. Xia, Z. Xiao, T. Grossman, and Y. Chen, Assistance or disruption? exploring and evaluating the design and trade-offs of proactive ai programming support, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 121, 2025. [145] J. Zamfirescu-Pereira, E. Jun, M. Terry, Q. Yang, and B. Hartmann, Beyond code generation: Llm-supported exploration of the program design space, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 1 17, 2025. [146] A. Gu, N. Jain, W.-D. Li, M. Shetty, Y. Shao, Z. Li, D. Yang, K. Ellis, K. Sen, and A. Solar-Lezama, Challenges and paths towards ai for software engineering, arXiv preprint arXiv:2503.22625, 2025. prompt knowledge gaps for improved llm-guided issue resolution, arXiv preprint arXiv:2501.11709, 2025. [147] S. Walters, S. Gao, S. Nerd, F. Da, W. Williams, T.-C. Meng, A. Chow, H. Han, F. He, A. Zhang, et al., Eliza: web3 friendly ai agent operating system, arXiv preprint arXiv:2501.06781, 2025. [148] L. Berberi, V. Kozlov, G. Nguyen, J. Sainz-Pardo Dıaz, A. Calatrava, G. Molto, V. Tran, and A. Lopez Garcıa, Machine learning operations landscape: platforms and tools, Artificial Intelligence Review, vol. 58, no. 6, p. 167, 2025. [149] R. Hu, C. Peng, X. Wang, and C. Gao, An llm-based agent for reliable docker environment configuration, arXiv preprint arXiv:2502.13681, 2025. [150] S. Chauhan, Z. Rasheed, A. M. Sami, Z. Zhang, J. Rasku, K.- K. Kemell, and P. Abrahamsson, Llm-generated microservice implementations from restful api definitions, arXiv preprint arXiv:2502.09766, 2025. [151] G. Wolflein, D. Ferber, D. Truhn, O. Arandjelovic, and J. N. tools, arXiv preprint Kather, Llm agents making agent arXiv:2502.11705, 2025. [152] R. Ye, K. Huang, Q. Wu, Y. Cai, T. Jin, X. Pang, X. Liu, J. Su, C. Qian, B. Tang, et al., Maslab: unified and comprehensive codebase for llm-based multi-agent systems, arXiv preprint arXiv:2505.16988, 2025. [153] K. Kanellopoulos, K. Sgouras, F. N. Bostanci, A. K. Kakolyris, B. K. Konar, R. Bera, M. Sadrosadati, R. Kumar, N. Vijaykumar, and O. Mutlu, Virtuoso: Enabling fast and accurate virtual memory research via an imitation-based operating system simulation methodology, in Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, pp. 14001421, 2025. [154] A. Almorsi, M. Ahmed, and W. Gomaa, Guided code generation with llms: multi-agent framework for complex code tasks, arXiv preprint arXiv:2501.06625, 2025. [155] B. Miloradovic, B. uruklu, M. Ekstrom, and A. V. Papadopoulos, Optimizing parallel task execution for multi-agent mission planning, IEEE Access, vol. 11, pp. 2436724381, 2023. [156] X. Wang, Y. Chen, L. Yuan, Y. Zhang, Y. Li, H. Peng, and H. Ji, Executable code actions elicit better llm agents, in Forty-first International Conference on Machine Learning, 2024. [157] C. Cao, F. Wang, L. Lindley, and Z. Wang, Managing linux servers with llm-based ai agents: An empirical evaluation with gpt4, Machine Learning with Applications, vol. 17, p. 100570, 2024. [158] K. Mei, X. Zhu, W. Xu, W. Hua, M. Jin, Z. Li, S. Xu, R. Ye, Y. Ge, and Y. Zhang, Aios: Llm agent operating system, arXiv preprint arXiv:2403.16971, 2024. [159] Y. Li, H. Wen, W. Wang, X. Li, Y. Yuan, G. Liu, J. Liu, W. Xu, X. Wang, Y. Sun, et al., Personal llm agents: Insights and survey about the capability, efficiency and security, arXiv preprint arXiv:2401.05459, 2024. [160] J. Liu, C. Yu, J. Gao, Y. Xie, Q. Liao, Y. Wu, and Y. Wang, Llm-powered hierarchical language agent for real-time humanai coordination, arXiv preprint arXiv:2312.15224, 2023. [161] D. Roy, X. Zhang, R. Bhave, C. Bansal, P. Las-Casas, R. Fonseca, and S. Rajmohan, Exploring llm-based agents for root cause analysis, in Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, pp. 208219, 2024. [162] S. Long, J. Tan, B. Mao, F. Tang, Y. Li, M. Zhao, and N. Kato, survey on intelligent network operations and performance optimization based on large language models, IEEE Communications Surveys & Tutorials, 2025. [163] L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian, Waitgpt: Monitoring and steering conversational llm agent in data analysis with on-the-fly code visualization, in Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology, pp. 114, 2024. [164] R. Ehsani, S. Pathak, and P. Chatterjee, Towards detecting [165] A. Alami, V. V. Jensen, and N. A. Ernst, Accountability in code review: The role of intrinsic drivers and the impact of llms, ACM Transactions on Software Engineering and Methodology, 2025. [166] S. Fakhoury, A. Naik, G. Sakkas, S. Chakraborty, and S. K. Lahiri, Llm-based test-driven interactive code generation: User study and empirical evaluation, IEEE Transactions on Software Engineering, 2024. [167] C. Huang, J. Wu, Y. Xia, Z. Yu, R. Wang, T. Yu, R. Zhang, R. A. Rossi, B. Kveton, D. Zhou, et al., Towards agentic recommender systems in the era of multimodal large language models, arXiv preprint arXiv:2503.16734, 2025. [168] M. North, A. Atapour-Abarghouei, and N. Bencomo, Code gradients: Towards automated traceability of llm-generated code, in 2024 IEEE 32nd International Requirements Engineering Conference (RE), pp. 321329, IEEE, 2024. [169] J. Hassine, An llm-based approach to recover traceability links between security requirements and goal models, in Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering, pp. 643651, 2024. [170] R. Chew, J. Bollenbacher, M. Wenger, J. Speer, and A. Kim, Llm-assisted content analysis: Using large language models to support deductive coding, arXiv preprint arXiv:2306.14924, 2023. [171] Z. Mousavi, C. Islam, K. Moore, A. Abuadbba, and M. A. Babar, An investigation into misuse of java security apis by large language models, in Proceedings of the 19th ACM Asia Conference on Computer and Communications Security, pp. 12991315, 2024. [172] Z. Yang, S. S. Raman, A. Shah, and S. Tellex, Plug in the safety chip: Enforcing constraints for llm-driven robot agents, in 2024 IEEE International Conference on Robotics and Automation (ICRA), pp. 1443514442, IEEE, 2024. [173] J. He, R. Ghosh, K. Walia, J. Chen, T. Dhadiwal, A. Hazel, and C. Inguva, Frontiers of large language model-based agentic systems-construction, efficacy and safety, in Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pp. 55265529, 2024. [174] M. Sanwal, Layered chain-of-thought prompting for multiagent llm systems: comprehensive approach to explainable large language models, arXiv preprint arXiv:2501.18645, 2025. [175] Y. Wu, F. Roesner, T. Kohno, N. Zhang, and U. Iqbal, Isolategpt: An execution isolation architecture for llm-based agentic systems, arXiv preprint arXiv:2403.04960, 2024. [176] N. Ashrafi, S. Bouktif, and M. Mediani, Enhancing llm code generation: systematic evaluation of multi-agent collaboration and runtime debugging for improved accuracy, reliability, and latency, arXiv preprint arXiv:2505.02133, 2025. [177] C. S. de Witt, Open challenges in multi-agent security: Towards secure systems of interacting ai agents, arXiv preprint arXiv:2505.02077, 2025. [178] G. Syros, A. Suri, C. Nita-Rotaru, and A. Oprea, Saga: security architecture for governing ai agentic systems, arXiv preprint arXiv:2504.21034, 2025. [179] S. Barua, Exploring autonomous agents through the lens language models: review, arXiv preprint large of arXiv:2404.04442, 2024. [180] B. Zhang, Y. Tan, Y. Shen, A. Salem, M. Backes, S. Zannettou, and Y. Zhang, Breaking agents: Compromising autonomous llm agents through malfunction amplification, arXiv preprint arXiv:2407.20859, 2024. [181] M. Cemri, M. Z. Pan, S. Yang, L. A. Agrawal, B. Chopra, R. Tiwari, K. Keutzer, A. Parameswaran, D. Klein, K. Ramchandran, et al., Why do multi-agent llm systems fail?, arXiv preprint arXiv:2503.13657, 2025. [182] N. Rao, Navigating challenges with LLM-based code generation using software-specific insights. PhD thesis, Google INC, 2025. [183] J. Zhang and I. Arawjo, Chainbuddy: An ai-assisted agent system for generating llm pipelines, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 121, 2025. of prompt engineering on vision-language foundation models, arXiv preprint arXiv:2307.12980, 2023. [184] Z. Ke, F. Jiao, Y. Ming, X.-P. Nguyen, A. Xu, D. X. Long, M. Li, C. Qin, P. Wang, S. Savarese, et al., survey of frontiers in llm reasoning: Inference scaling, learning to reason, and agentic systems, arXiv preprint arXiv:2504.09037, 2025. [185] S. Ali, F. Nasim, and K. Haider, Secure middleware model for public restful apis, Al-Aasar, vol. 2, no. 1, pp. 5062, 2025. [186] H.-P. Hsu, From programming to prompting: Developing computational thinking through large language model-based generative artificial intelligence, TechTrends, pp. 122, 2025. [187] H. Jin, L. Huang, H. Cai, J. Yan, B. Li, and H. Chen, From llms to llm-based agents for software engineering: survey of current, challenges and future, arXiv preprint arXiv:2408.02479, 2024. [188] J. He, C. Treude, and D. Lo, Llm-based multi-agent systems for software engineering: Literature review, vision and the road ahead, ACM Transactions on Software Engineering and Methodology, 2024. [189] D. B. Acharya, K. Kuppan, and B. Divya, Agentic ai: Autonomous intelligence for complex goalsa comprehensive survey, IEEE Access, 2025. [190] D. Nam, A. Omran, A. Murillo, S. Thakur, A. Araujo, M. Blistein, A. Frommgen, V. Hellendoorn, and S. Chandra, Prompting llms for code editing: Struggles and remedies, arXiv preprint arXiv:2504.20196, 2025. [191] Y. Cui, Tests as prompt: test-driven-development benchmark for llm code generation, arXiv preprint arXiv:2505.09027, 2025. [192] M. Wu, Y. Zhao, S. Han, M. X. Liu, and H. Shen, Ai lego: Scaffolding cross-functional collaboration in industrial responsible ai practices during early design stages, arXiv preprint arXiv:2505.10300, 2025. [193] B. Niu, Y. Song, K. Lian, Y. Shen, Y. Yao, K. Zhang, and T. Liu, Flow: modular approach to automated agentic workflow generation, arXiv preprint arXiv:2501.07834, 2025. [194] A. Caetano, K. Verma, A. Taheri, R. Kumaran, Z. Chen, J. Chen, T. Hollerer, and M. Sra, Agentic workflows for conversational human-ai interaction design, arXiv preprint arXiv:2501.18002, 2025. [195] Z. Ding, Q. Zhang, M. Chi, and Z. Wang, Frontend diffusion: Empowering self-representation of junior researchers and designers through agentic workflows, arXiv preprint arXiv:2502.03788, 2025. [196] H. Dawid, P. Harting, H. Wang, Z. Wang, and J. Yi, Agentic workflows for economic research: Design and implementation, arXiv preprint arXiv:2504.09736, 2025. [197] M. J. Buehler, Preflexor: Preference-based recursive language modeling for exploratory optimization of reasoning and agentic thinking, npj Artificial Intelligence, vol. 1, no. 1, pp. 138, 2025. [198] P. Bobko, L. Hirshfield, L. Eloy, C. Spencer, E. Doherty, J. Driscoll, and H. Obolsky, Human-agent teaming and trust calibration: theoretical framework, configurable testbed, empirical illustration, and implications for the development of adaptive systems, Theoretical Issues in Ergonomics Science, vol. 24, no. 3, pp. 310334, 2023. [199] D. Secchi, R. Gahrn-Andersen, and M. Neumann, Complexity in systemic cognition: Theoretical explorations with agent-based modeling, Systems, vol. 12, no. 8, p. 287, 2024. [200] A. Tariverdi, Trust from ethical point of view: Exploring dynamics through multiagent-driven cognitive modeling, arXiv preprint arXiv:2401.07255, 2024. [201] P. Iyenghar, Clever hans in the loop? critical examination of chatgpt in human-in-the-loop framework for machinery functional safety risk analysis, Eng, vol. 6, no. 2, p. 31, 2025. [202] J. Sabbah and F. Li, When humans and large language models collaborate, problem-finding illuminates, Innovation, pp. 134, 2025. [203] J. Gu, Z. Han, S. Chen, A. Beirami, B. He, G. Zhang, R. Liao, Y. Qin, V. Tresp, and P. Torr, systematic survey [204] V. Geroimenko, The Essential Guide to Prompt Engineering: Key Principles, Techniques, Challenges, and Security Risks. Springer Nature, 2025. [205] G. Robino, Conversation routines: prompt engineering framework for task-oriented dialog systems, arXiv preprint arXiv:2501.11613, 2025. [206] J. D. Velasquez-Henao, C. J. Franco-Cardona, and L. CadavidHiguita, Prompt engineering: methodology for optimizing interactions with ai-language models in the field of engineering, Dyna, vol. 90, no. SPE230, pp. 917, 2023. [207] S. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, et al., The prompt report: systematic survey of prompting techniques, arXiv preprint arXiv:2406.06608, vol. 5, 2024. [208] J. Robertson, C. Ferreira, E. Botha, and K. Oosthuizen, Game changers: generative ai prompt protocol to enhance human-ai knowledge co-construction, Business Horizons, vol. 67, no. 5, pp. 499510, 2024. [209] J. Xu, B. Pang, J. Qu, H. Hayashi, C. Xiong, and Y. Zhou, Clover: test case generation benchmark with coverage, longcontext, and verification, arXiv preprint arXiv:2502.08806, 2025. [210] L. Chen, Z. Liu, W. He, Y. Li, R. Luo, and M. Yang, Long context is not long at all: prospector of long-dependency data for large language models, arXiv preprint arXiv:2405.17915, 2024. [211] Y. Zhang, R. Sun, Y. Chen, T. Pfister, R. Zhang, and S. Arik, Chain of agents: Large language models collaborating on long-context tasks, Advances in Neural Information Processing Systems, vol. 37, pp. 132208132237, 2024. [212] S. Mondal, S. D. Bappon, and C. K. Roy, Enhancing user interaction in chatgpt: Characterizing and consolidating multiple prompts for issue resolution, in Proceedings of the 21st International Conference on Mining Software Repositories, pp. 222 226, 2024. [213] J. Cao, M. Li, M. Wen, and S.-c. Cheung, study on prompt design, advantages and limitations of chatgpt for deep learning program repair, Automated Software Engineering, vol. 32, no. 1, pp. 129, 2025. [214] A. Fourney, G. Bansal, H. Mozannar, C. Tan, E. Salinas, F. Niedtner, G. Proebsting, G. Bassman, J. Gerrits, J. Alber, et al., Magentic-one: generalist multi-agent system for solving complex tasks, arXiv preprint arXiv:2411.04468, 2024. [215] N. Kant, Develop ai agents for system engineering in factorio, arXiv preprint arXiv:2502.01492, 2025. [216] L. A. Dennis, M. Fisher, N. K. Lincoln, A. Lisitsa, and S. M. Veres, Practical verification of decision-making in agentbased autonomous systems, Automated Software Engineering, vol. 23, pp. 305359, 2016. [217] M. Luckcuck, M. Farrell, L. A. Dennis, C. Dixon, and M. Fisher, Formal specification and verification of autonomous robotic systems: survey, ACM Computing Surveys (CSUR), vol. 52, no. 5, pp. 141, 2019. [218] L. A. Dennis and M. Fisher, Verifiable self-aware agent-based autonomous systems, Proceedings of the IEEE, vol. 108, no. 7, pp. 10111026, 2020. [219] K. Havelund, Rule-based runtime verification revisited, International Journal on Software Tools for Technology Transfer, vol. 17, no. 2, pp. 143170, 2015. [220] A. Francalanza, J. A. Perez, and C. Sanchez, Runtime verification for decentralised and distributed systems, Lectures on Runtime Verification: Introductory and Advanced Topics, pp. 176210, 2018. [221] N. R. Jennings and S. Bussmann, Agent-based control systems, IEEE control systems, vol. 23, no. 3, pp. 6174, 2003. [222] G. Team, R. Anil, S. Borgeaud, J.-B. Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M. Dai, A. Hauth, K. Millican, et al., Gemini: family of highly capable multimodal models, arXiv preprint arXiv:2312.11805, 2023. [245] S. Katz, A. Lesgold, G. Eggan, and M. Gordin, Modelling the student in sherlock ii, Journal of Interactive Learning Research, vol. 3, no. 4, p. 495, 1992. [246] A. Preece, W. Webberley, D. Braines, E. G. Zaroukian, and J. Z. Bakdash, Sherlock: Experimental evaluation of conversational agent for mobile information tasks, IEEE Transactions on Human-Machine Systems, vol. 47, no. 6, pp. 10171028, 2017. [247] S. Katz, A. Lesgold, E. Hughes, D. Peters, G. Eggan, M. Gordin, and L. Greenberg, Sherlock 2: An intelligent tutoring system built on the lrdc tutor framework, in Facilitating the development and use of interactive learning environments, pp. 227258, CRC Press, 2020. [248] K. Vanlehn, C. Lynch, K. Schulze, J. A. Shapiro, R. Shelby, L. Taylor, D. Treacy, A. Weinstein, and M. Wintersgill, The andes physics tutoring system: Lessons learned, International Journal of Artificial Intelligence in Education, vol. 15, no. 3, pp. 147204, 2005. [249] K. G. Schulze, R. N. Shelby, D. J. Treacy, M. C. Wintersgill, K. Vanlehn, and A. Gertner, Andes: An intelligent tutor for classical physics, Journal of Electronic Publishing, vol. 6, no. 1, 2000. [250] A. S. Gertner and K. VanLehn, Andes: coached problem solving environment for physics, in International conference on intelligent tutoring systems, pp. 133142, Springer, 2000. [251] D. Chess, C. Harrison, and A. Kershenbaum, Mobile agents: Are they good idea?, in International Workshop on Mobile Object Systems, pp. 2545, Springer, 1996. [252] D. Milojicic, Mobile agent applications, IEEE Concurrency (out of print), vol. 7, no. 03, pp. 8090, 1999. [253] G. Kardas, B. T. Tezel, and M. Challenger, Domain-specific modelling language for beliefdesireintention software agents, IET Software, vol. 12, no. 4, pp. 356364, 2018. [254] E. Gelenbe, E. Seref, and Z. Xu, Simulation with learning agents, Proceedings of the IEEE, vol. 89, no. 2, pp. 148157, 2001. [255] I. Arel, C. Liu, T. Urbanik, and A. G. Kohls, Reinforcement learning-based multi-agent system for network traffic signal control, IET Intelligent Transport Systems, vol. 4, no. 2, pp. 128135, 2010. [256] G. Tesauro, Programming backgammon using self-teaching neural nets, Artificial Intelligence, vol. 134, no. 1-2, pp. 181 199, 2002. [257] S. Vitabile, V. Conti, C. Militello, and F. Sorbello, An extended jade-s based framework for developing secure multiagent systems, Computer Standards & Interfaces, vol. 31, no. 5, pp. 913930, 2009. [258] F. Bellifemine, A. Poggi, and G. Rimassa, Developing multiagent systems with jade, in Intelligent Agents VII Agent Theories Architectures and Languages: 7th International Workshop, ATAL 2000 Boston, MA, USA, July 79, 2000 Proceedings 7, pp. 89103, Springer, 2001. [259] F. Bellifemine, G. Caire, A. Poggi, and G. Rimassa, Jade: software framework for developing multi-agent applications. lessons learned, Information and Software technology, vol. 50, no. 1-2, pp. 1021, 2008. [260] H. Yang, S. Yue, and Y. He, Auto-gpt for online decision making: Benchmarks and additional opinions, arXiv preprint arXiv:2306.02224, 2023. [223] D. Yuan, G. Yang, and T. Zhang, Ui2html: utilizing llm agents with chain of thought to convert ui into html code, Automated Software Engineering, vol. 32, no. 2, pp. 124, 2025. [224] R. Toth, T. Bisztray, and L. Erdodi, Llms in web development: Evaluating llm-generated php code unveiling vulnerabilities and limitations, in International Conference on Computer Safety, Reliability, and Security, pp. 425437, Springer, 2024. [225] K. Xu, Y. Mao, X. Guan, and Z. Feng, Web-bench: llm code benchmark based on web standards and frameworks, arXiv preprint arXiv:2505.07473, 2025. [226] F. Esposito, Programming Large Language Models with Azure Open AI: Conversational Programming and Prompt Engineering with LLMs. Microsoft Press, 2024. [227] M. Johnsen, Developing AI Applications With Large Language Models. Maria Johnsen, 2025. [228] L. Shen, H. Li, Y. Wang, and H. Qu, From data to story: Towards automatic animated data video creation with llm-based multi-agent systems, in 2024 IEEE VIS Workshop on Data Storytelling in an Era of Generative AI (GEN4DS), pp. 2027, IEEE, 2024. [229] Z. Shao, L. Shen, H. Li, Y. Shan, H. Qu, Y. Wang, and S. Chen, Narrative player: Reviving data narratives with visuals, IEEE Transactions on Visualization and Computer Graphics, 2025. [230] H. Joshi, S. Liu, J. Chen, R. Weigle, and M. S. Lam, Coding reliable llm-based integrated task and knowledge agents with genieworksheets, arXiv preprint arXiv:2407.05674, 2024. [231] T. Taulli, AI-Assisted Programming: Better Planning, Coding, Testing, and Deployment. OReilly Media, Inc., 2024. [232] C. Zhang, S. He, J. Qian, B. Li, L. Li, S. Qin, Y. Kang, M. Ma, G. Liu, Q. Lin, et al., Large language model-brained gui agents: survey, arXiv preprint arXiv:2411.18279, 2024. [233] D. N. Voronin, Development and Evaluation of an LLM-Based Tool for Automatically Building Web Applications. PhD thesis, Massachusetts Institute of Technology, 2024. [234] H. Trivedi, T. Khot, M. Hartmann, R. Manku, V. Dong, E. Li, S. Gupta, A. Sabharwal, and N. Balasubramanian, Appworld: controllable world of apps and people for benchmarking interactive coding agents, arXiv preprint arXiv:2407.18901, 2024. [235] R. Dale, Start-up activity in the llm ecosystem, Natural Language Engineering, vol. 30, no. 3, pp. 650659, 2024. [236] B. Tabarsi, H. Reichert, A. Limke, S. Kuttal, and T. Barnes, Llms reshaping of people, processes, products, and society in software development: comprehensive exploration with early adopters, arXiv preprint arXiv:2503.05012, 2025. [237] N. Sniegowski, Evaluating the effectiveness of llm-generated phishing campaigns, Masters thesis, Marquette University, 2025. [238] A. Eriksson and C. Pacoste, Symbolic software tools in the development of finite elements, Computers & structures, vol. 72, no. 4-5, pp. 579593, 1999. [239] J. M. Bradshaw, An introduction to software agents, Software agents, vol. 4, pp. 346, 1997. [240] N. Fenton, Software measurement: necessary scientific basis, IEEE Transactions on software engineering, vol. 20, no. 3, pp. 199206, 2002. [241] S. Abiteboul and V. Vianu, Non-determinism in logic-based languages, Annals of Mathematics and Artificial Intelligence, vol. 3, no. 2, pp. 151186, 1991. [242] S. Graf and J. Sifakis, logic for the description of nondeterministic programs and their properties, Information and control, vol. 68, no. 1-3, pp. 254270, 1986. [243] F. Wagner, R. Schmuki, T. Wagner, and P. Wolstenholme, Modeling software with finite state machines: practical approach. Auerbach Publications, 2006. [244] A. Drumea and C. Popescu, Finite state machines and their applications in software for industrial control, in 27th International Spring Seminar on Electronics Technology: Meeting the Challenges of Electronics Technology Progress, 2004., vol. 1, pp. 2529, IEEE, 2004."
        }
    ],
    "affiliations": [
        "Cornell University, Department of Biological and Environmental Engineering, USA",
        "University of the Peloponnese, Department of Informatics and Telecommunications, Tripoli, Greece"
    ]
}