{
    "paper_title": "Think While You Generate: Discrete Diffusion with Planned Denoising",
    "authors": [
        "Sulin Liu",
        "Juno Nam",
        "Andrew Campbell",
        "Hannes Stärk",
        "Yilun Xu",
        "Tommi Jaakkola",
        "Rafael Gómez-Bombarelli"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Discrete diffusion has achieved state-of-the-art performance, outperforming or approaching autoregressive models on standard benchmarks. In this work, we introduce Discrete Diffusion with Planned Denoising (DDPD), a novel framework that separates the generation process into two models: a planner and a denoiser. At inference time, the planner selects which positions to denoise next by identifying the most corrupted positions in need of denoising, including both initially corrupted and those requiring additional refinement. This plan-and-denoise approach enables more efficient reconstruction during generation by iteratively identifying and denoising corruptions in the optimal order. DDPD outperforms traditional denoiser-only mask diffusion methods, achieving superior results on language modeling benchmarks such as text8, OpenWebText, and token-based generation on ImageNet $256 \\times 256$. Notably, in language modeling, DDPD significantly reduces the performance gap between diffusion-based and autoregressive methods in terms of generative perplexity. Code is available at https://github.com/liusulin/DDPD."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 8 ] . [ 1 4 6 2 6 0 . 0 1 4 2 : r a"
        },
        {
            "title": "Preprint",
            "content": "THINK WHILE YOU GENERATE: DISCRETE DIFFUSION WITH PLANNED DENOISING Sulin Liu1, Juno Nam1, Andrew Campbell2, Hannes Stärk1, Yilun Xu3, Tommi Jaakkola1, Rafael Gómez-Bombarelli1 1Massachusetts Institute of Technology, 2University of Oxford, 3NVIDIA Research"
        },
        {
            "title": "ABSTRACT",
            "content": "Discrete diffusion has achieved state-of-the-art performance, outperforming or approaching autoregressive models on standard benchmarks. In this work, we introduce Discrete Diffusion with Planned Denoising (DDPD), novel framework that separates the generation process into two models: planner and denoiser. At inference time, the planner selects which positions to denoise next by identifying the most corrupted positions in need of denoising, including both initially corrupted and those requiring additional refinement. This plan-and-denoise approach enables more efficient reconstruction during generation by iteratively identifying and denoising corruptions in the optimal order. DDPD outperforms traditional denoiser-only mask diffusion methods, achieving superior results on language modeling benchmarks such as text8, OpenWebText, and token-based generation on ImageNet 256 256. Notably, in language modeling, DDPD significantly reduces the performance gap between diffusion-based and autoregressive methods in terms of generative perplexity. Code is available at github.com/liusulin/DDPD."
        },
        {
            "title": "INTRODUCTION",
            "content": "Generative modeling of discrete data has recently seen significant advances across various applications, including text generation [5], biological sequence modeling [25, 4], and image synthesis [8, 9]. Autoregressive transformer models have excelled in language modeling but are limited to sequential sampling, with performance degrading without annealing techniques such as nucleus (top-p) sampling [20]. In contrast, diffusion models offer more flexible and controllable generation, proving to be more effective for tasks that lack natural sequential orderings, such as biological sequence modeling [25, 1] and image token generation [8]. In language modeling, the performance gap between discrete diffusion and autoregressive models has further narrowed recently, thanks to improved training strategies [29, 36, 34, 13], however, gap still remains on some tasks [36, 29]. State-of-the-art discrete diffusion methods train denoiser (or score) model that determines the transition rate (or velocity) from the current state to predicted values. During inference, the generative process is discretized into finite number of steps. At each step, the state values are updated based on the transition probability, which is obtained by integrating the transition rate over the timestep period. In order to further close the performance gap with autoregressive models, we advocate for rethinking of the standard discrete diffusion design methodology. We propose new framework Discrete Diffusion with Planned Denoising (DDPD), that divides the generative process into two key components: planner and denoiser, facilitating more adaptive and efficient sampling procedure. The process starts with sequence of tokens initialized with random values. At each timestep, the planner model examines the sequence to identify the position most likely to be corrupted and in need of denoising. The denoiser then predicts the value for the selected position, based on the current noisy sequence. The key insight behind our plan-and-denoise approach is that the generative probability at each position can be factorized into two components: 1) the probability that position is corrupted, and 2) the probability of denoising it according to the data distribution. The advantages of our approach are two-fold, providing both simplified learning process and more effective sampling algorithm. First, by decomposing the originally complex task into two distinct Corresponding to sulinliu@mit.edu."
        },
        {
            "title": "Preprint",
            "content": "sub-tasks, the task becomes easier for each neural network model. In particular, the task of planning is simpler to learn compared to denoising. In contrast, the original uniform diffusion model relies on single neural network to perform both tasks simultaneously. Under our framework, the mask diffusion Figure 1: An example generation trajectory from = 0 to 1 with sequence of 5 letters. At each step, the planner predicts the probability of each token being corrupted (indicated by the numbers next to the tokens). Based on these probabilities, position is selected, and the denoiser makes its prediction. The actual time progression may not always align with the scheduled timestep, and is determined based on planners assessment of the noise level of the sequence. For instance, in step 2, the denoiser makes minimal improvement and time progresses slower than scheduled. In step 4, the denoiser made an unintended error, the time progression is effectively backward. Sampling continues until all corrupted tokens are reconstructed. approach achieves comparable decomposition by using mask token to indicate whether position contains noise or data. However, critical limitation of this is that once tokens are filled in, they cannot be further corrected, even if the denoiser makes errors. Furthermore, our plan-and-denoise framework enables an improved adaptive sampling scheme that leverages the planners predictions in two ways. Our sampling method employs finer discretization when the planner detects that the sequence is noisier than expected for the current timestep, i.e., more denoising moves are needed for the time left. Additionally, the planner can identify errors from previous steps, allowing the sampling process to adjust its time back and continue until the denoiser corrects all previously accumulated mistakes, resulting in more robust generation. Fig. 1 provides an illustrative example of how the planner operates during inference. Our contributions are as follows: We introduce Discrete Diffusion with Planning and Denoising (DDPD), novel framework for discrete generative modeling that decomposes the generation process into planning and denoising. Our proposed plan-and-denoise framework introduces an adaptive sampling scheme, guided by the planners output, enabling continuous self-correction of errors in an optimal order. This results in improved generation by scaling the number of sampling steps. We derive simple and effective training objectives for the planner and denoiser models, grounded in maximizing the Evidence Lower Bound (ELBO) for discrete diffusion processes. In experiments on GPT-2 scale language modeling and 256 256 image token generation, DDPD significantly outperforms its mask diffusion counterparts when using the same denoiser. Furthermore, we demonstrate that incorporating planner substantially enhances generation quality, even when using smaller or weaker denoiser model compared to baseline methods."
        },
        {
            "title": "2 PRELIMINARIES",
            "content": "We begin by introducing the problem setup and notations. Following [7, 13], we then explain the Continuous Time Markov Chain (CTMC) framework [31], which is used to define the forward and reverse processes of discrete diffusion, and how the discrete timestep version is derived from it. Setup and Notations. We aim to model discrete data where sequence {1, , S}D is D-dimensional and each element xd takes possible states. xd denotes all dimensions except d. For clarity in presentation, we assume = 1 and all results hold for > 1 (see Section 3.1). We"
        },
        {
            "title": "Preprint",
            "content": "use p(x) to denote the probability mass function (PMF). The δ {i, j} is the Kronecker delta function, which is 1 when = and 0 otherwise. Continuous Time Markov Chains and Discretization. We adopt the CTMC framework to define the discrete diffusion process. realization of the CTMC dynamics is defined by trajectory xt over time [0, 1] that makes jumps to another state after random waiting period known as the holding time. The transition rates and the next states are governed by the rate matrix Rt RSS (analogous to the velocity field νt in continuous state spaces), where the off-diagonal elements, representing jumps to different states, are non-negative. For an infinitesimal timestep dt, the probability of transitioning from xt to different state is given by Rt(xt, j)dt. In practice, the trajectory is simulated using finite time intervals t. As result, the transition probability follows categorical distribution with the PMF [39]: pt+tt(jxt) = δ {xt, j} + Rt(xt, j)t, (1) where we denote this as Cat(δ {xt, j} + Rt(xt, j)t), and Rt(xt, xt) := (cid:80) ensure that the transition probabilities sum to 1. Rt(xt, s) to s=xt Forward Corruption Process. Following [7, 34, 13], which were inspired by flow matching in continuous state space [26, 27, 2], we construct the forward process by interpolating from noise p0(x0) = pnoise(x0) to clean data p1(x1) = pdata(x1). Common choices for the noise distribution noise (xt) = δ {M, xt}, include: (i) punif delta PMF concentrated on an artificially introduced mask state M. Let αt be the noise schedule that introduces noise to the data over time t. For example, linear schedule is given by αt = t. The conditional marginal pt1(xtx1) is given in closed form: noise(xt) = 1/S, uniform distribution over {1, , S}; and (ii) pmask punif t1 (xtx1) = Cat(αtδ {x1, xt} + (1 αt) 1 ), pmask t1 (xtx1) = Cat(αtδ {x1, xt} + (1 αt)δ {M, xt}). (2) (3) At = 1, the conditional marginal converges to the datapoint x1, i.e. δ {x1, xt}. At = 0, the conditional marginal converges to the noise distribution pnoise(xt). Sampling from pdata is achieved by learning generative rate Reverse Generation Process. matrix Rt(xt, j) to reverse simulate the process from = 0 to = 1 using Eq. (1), such that we begin with samples of pnoise and end with samples of pdata. The datapoint conditional reverse rate Rt(xt, jx1) for = xt 1 under the uniform or mask noise distributions is given by [7, 13]: Runif (xt, jx1) = αt 1 αt δ {x1, j} (1δ {x1, xt}), Rmask (xt, jx1) = αt 1 αt δ {x1, j} δ {xt, M}. [7, 13] show that the rate we aim to learn for generating pdata is the expectation of the data-conditional rate, taken over the denoising distribution, i.e., Rt(xt, j) := Ep1t(x1xt) [Rt(xt, jx1)]: Runif (xt, j) = αt 1 αt p1t (x1 = jxt) , Rmask (xt, j) = αt 1 αt δ {xt, M}p1t (x1 = jxt) . (4) The goal is to approximate this rate using neural network. During inference, the generative process is simulated with the learned rate by taking finite timesteps, as described in Eq. (1)."
        },
        {
            "title": "3 METHOD",
            "content": "3.1 DECOMPOSING GENERATION INTO PLANNING AND DENOISING Recent state-of-the-art discrete diffusion methods [39, 29, 7, 36, 34, 13] have converged on parameterizing the generative rate using denoising neural network and deriving cross-entropy-based training objectives. This enables simplified and effective training, leading to better and SOTA performance in discrete generative modeling compared to earlier approaches [3, 6]. In Table 1, we summarize the commonalities and differences in the design choices across various methods. 1For simplicity, we only derive the rates for = xt. The rate for = xt can be computed as Rt(xt, xtx1) := (cid:80) Rt(xt, sx1). s=xt"
        },
        {
            "title": "Preprint",
            "content": "Table 1: Specific design choices employed by different discrete diffusion models. SDDM [39] SEDD [29] DFM [7] / Discrete FM [13] MDLM [34] / MD4 [36] Ours (DDPD) Sampling (Section 3.2) Method Time steps Tau-leaping i/N ti Tau-leaping i/N Tau-leaping i/N Tau-leaping i/N Noise schedule αt Generative rate parameterization (Section 3.1) , (cid:9) Masking δ (cid:8)xd αt αt sθ (xt)xd αt αt () αt () αtδ{xd (cid:0)xd pθ ,M}/1αt 1 = jxt (cid:1) αtδ{xd (cid:0)xd pθ ,M}/1αt 1 = jxt (cid:1) Adaptive Gillespie tθ(xi) + τi, τi Exp (λθ(xi)) () αt Uniform αt Sαt (cid:16) =jxd xd pθ (cid:16) xd =xd xd pθ (cid:17) (cid:17) αt Sαt sθ (xt)xd j αt/1αt (cid:0)xd pθ 1 = jxt (cid:1) αt/1αtpθ(zd pθ (cid:0)xd 1 = jxt, zd = xt) = (cid:1) DFM assumes linear schedule. MD4 also supports learnable schedule of αt. λθ(xi) is the total rate of jump determined by the planner. Based on the optimal generative rate in Eq. (4), we propose new approach to parameterizing the generative rate by dividing it into two distinct components: planning and denoising. We begin by examining how the generative rate in mask diffusion can be interpreted within our framework, followed by derivation of the decomposition for uniform diffusion. Mask Diffusion. For mask diffusion, is assigning probability of δ {xt, M}t for the data to be denoised with an actual value. δ {xt, M} tells if the data αt 1αt is noisy (M) or clean. is the rate of denoising, which is determined by the remaining time according to the noise schedule. The denoiser p1t assigns probabilities to the possible values to be filled in if this transition happens. the planning part αt 1αt Rmask (xt, j)t = αt δ {xt, M} 1 αt (cid:124) (cid:125) (cid:123)(cid:122) rate of making correction p1t (x1 = jxt) (cid:125) (cid:123)(cid:122) prob. of denoising (cid:124) (5) Uniform Diffusion. Similarly, we would want to decompose the transition probability into two parts: the planning probability based on if the data is corrupted and the denoising probability that determines which value to change to. But in contrast to the mask diffusion case, the noise/clean state of the data is not given to us during generation. We use zd {N, D} as latent variable to denote if dimension is corrupted, with denoting noise and denoting data. From Bayes rule, for = xt, since p1t (x1 = jxt, zt = D) = p(xtx1=j,zt=D)p(x1=j) = 0 p(xtzt=D) p1t (x1 = jxt) = (cid:88) zt{N,D} p(ztxt)p1t(x1 = jxt, zt) = p(zt = xt) (cid:125) (cid:123)(cid:122) prob. of being corrupted (cid:124) p1t(x1 = jxt, zt = ) (cid:125) (cid:123)(cid:122) (cid:124) prob. of denoising (6) The first part of the decomposition is the posterior probability of xt being corrupted, and the second part gives the denoising probability to recover the value of xt if xt is corrupted. Plugging Eq. (6) into Eq. (4), we arrive at: Runif (xt, j)t = p(zt = xt) αt 1 αt (cid:124) (cid:123)(cid:122) rate. of making correction (cid:125) p1t(x1 = jxt, zt = ) (cid:125) (cid:123)(cid:122) prob. of denoising (cid:124) (7) By comparing Eq. (7) and Eq. (5), we find that they share the same constant part which represents the rate determined by the current time left according to the noise schedule. The main difference is in the middle part that represents the probability of xt being corrupted. In mask diffusion case, this can be readily read out from the token. But in the uniform diffusion case, we need to compute/approximate this probability instead. The last part is the denoising probability conditioned on xt being corrupted, which again is shared by both and needs to be computed/approximated. αt 1αt"
        },
        {
            "title": "Preprint",
            "content": "Generative Rate for Multi-Dimensions. We have the following reverse generative rate [7, 13] for mask diffusion: The above mentioned decomposition extends to > 1."
        },
        {
            "title": "Rmask\nt",
            "content": "(xt, jd)t = αt 1 αt δ (cid:8)xd , M(cid:9)p1t (cid:0)xd 1 = jdxt (cid:1), jd = xd , (8) and we derive the following decomposition result for uniform diffusion (proof in Appendix A.1): Proposition 3.1. The reverse generative rate at d-th dimension can be decomposed into the product of recovery rate, probability of corruption and probability of denoising: (cid:0)xd (cid:1) (cid:0)xt, jd(cid:1) = αt 1αt"
        },
        {
            "title": "Runif\nt",
            "content": "(9) = p1t αt 1αt (cid:124) (cid:123)(cid:122) (cid:125) noise removal rate 1 = jdxt (cid:0)zd = xt (cid:125) (cid:123)(cid:122) (cid:124) prob. of corruption (cid:1) p1t (cid:124) (cid:0)xd 1 = jdxt, zd (cid:123)(cid:122) prob. of denoising = (cid:1) (cid:125) t, jd = xd where (cid:0)zd = xt p1t (cid:0)xd (cid:1) = 1 p1t (cid:0)xd 1 = jdxt, zd 1 = xd xt = (cid:1) = (cid:1) αt αt+(1αt)/S p1t(xd 1 =jdxt) =N xt) p(zd (10) (11) We observe that the term (cid:0)zd different rates, based on how likely the dimension is clean or noise given the current context. (cid:1) determines how different dimensions are reconstructed at = xt Previous Parameterization. In the case of mask diffusion, as studied in recent works [29, 7, 36, 34, 13], the most effective parameterization for learning is to directly model the denoising probability with neural network, as this is the only component that needs to be approximated. In the case of uniform diffusion, the conventional approach uses single model to approximate the (cid:1) as shown in Eq. (9). However, generative rate as whole, by modeling the posterior p1t despite its theoretically greater flexibility allowing token values to be corrected throughout sampling, akin to the original diffusion process in the continuous domain its performance has not always outperformed mask diffusion, particularly in tasks like image or language modeling. 1 = jdxt (cid:0)xd Plan-and-Denoise Parameterization. Based on the observation made in Proposition 3.1, we take the view that generation should consist of two models: planner model for deciding which position to denoise and denoiser model for making the denoising prediction for selected position. Runif t,jump (cid:0)xt, jd(cid:1) = αt 1 αt (cid:124) (cid:123)(cid:122) (cid:125) noise removal rate pθ (cid:124) (cid:0)zd = xt (cid:123)(cid:122) planner (cid:1) (cid:125) pθ 1t (cid:124) (cid:0)xd 1 = jdxt, zd (cid:123)(cid:122) denoiser = (cid:1) , (cid:125) xt = jd (12) This allows us to utilize the planners output to design an improved sampling algorithm that optimally identifies and corrects errors in the sequence in the most effective denoising order. Additionally, the task decomposition enables separate training of the planner and denoiser, simplifying the learning process for each neural network. Often, pretrained denoiser is already available, allowing for computational savings by only training the planner, which is generally faster and easier to train. Remark 3.2. Under this perspective, masked diffusion (Eq. (8)) can be interpreted as denoiser-only , M(cid:9), which assumes that modeling paradigm with fixed planner, i.e., pθ mask tokens represent noise while actual tokens represent clean data. This planner is optimal under the assumption of perfect denoiser, which rarely holds in practice. When the denoiser makes errors, this approach does not provide mechanism for correcting those mistakes. (cid:1) = δ (cid:8)xd = xt (cid:0)zd Next, we demonstrate how our plan-and-denoise framework enables an improved sampling algorithm that effectively leverages the planners predictions. From this point forward, we assume uniform diffusion by default and use Rt,jump to denote the reverse jump rate, unless explicitly stated otherwise. 3.2 SAMPLING Prior Works: Tau-leaping Sampler. The reverse generative process is CTMC that consists of sequence of jumps from = 0 to = 1. The most common way [6, 39, 29, 36, 34, 13] is to discretize it into equal timesteps and simulate each step following the reverse generative rate using"
        },
        {
            "title": "Preprint",
            "content": "an approximate simulation method called tau-leaping. During step [t, + t], all the transitions happening according to Eq. (1) are recorded first and simultaneously applied at the end of the step. When the discretization is finer than the number of denoising moves required, some steps may be wasted when no transitions occur during those steps. In such cases when no transition occurs during [t t, t], neural network forward pass can be saved for step [t, + t] by using the cached p1t(xd 1xtt) from the previous step [10, 34], assuming the denoising probabilities remain unchanged during [t t, t]. However, as discussed in literature [6, 39, 29, 7], such modeling of the reverse denoiser is predicting single dimension transitions but not joint transitions of all dimensions. Therefore, the tau-leaping simulation will introduce approximation errors if multiple dimensions are changed during the same step. Gillespie Sampler. Instead, we adopt the Gillespie algorithm [15, 16, 41], simulation method that iteratively repeats the following two-step procedure: (1) sampling t, the holding time spent at current state until the next jump and (2) sampling which state transition occurs. In the first step, the holding time is drawn from an exponential distribution, with the rate equal to the total jump rate, defined as the sum of all possible jump rates in Eq. (12): Rt,total(xt) := (cid:80) Rt,jump(xt, jd). jd=xd (cid:0)xt, jd(cid:1)/Rt,total(xt), For the second step, the event at the jump is sampled according to Rt,jump such that the likelihood of the next state is proportional to the rate from the current position. straightforward way is using ancestral sampling by first selecting the dimension d, followed by sampling the value to jump to d: (cid:80) Cat (cid:16)(cid:80) d=x (cid:17) Rt,jump(xt, d)/Rt,total(xt) , Cat (cid:16) Rt,jump(xt, d)/ (cid:80) d=x Rt,jump(xt, d) (cid:17) . We find we can simplify the calculation of the total jump rate and next state transition by introducing the possibility of self-loop jumps into the CTMC. These allow the trajectory to remain in the current state after jump occurs. This modification results in an equivalent but simpler simulated process with our plan-and-denoise method, formalized in the following proposition: Proposition 3.3. The original CTMC defined by the jump rate Rt,jump given by Eq. (12) has the same distribution over trajectories as the modified self-loop CTMC with rate matrix Rt(xt, jd) = αt 1αt pθ(zd = xt)pθ 1t(xd 1 = jdxt, zd = ), xt, jd For this self-loop Gillespie algorithm, the total jump rate and next state distribution have the form (cid:80) d,jd Cat (cid:16) Rt(xt, jd) = αt 1αt (cid:80) pθ(zd = xt) (cid:16) pθ(z = xt) (cid:17) , d Cat 1t(x pθ 1 = dxt, = ) (cid:17) . Intuitively, the modification preserves the inter-state jump rates, ensuring that the distribution of effective jumps remains unchanged. detailed proof is provided in Appendix A.3. Remark 3.4. The Gillespie algorithm sets adaptively, which is given by the holding time until the next transition. This enables more efficient discretization of timesteps, such that one step leads to one token denoised (if denoising is correct). In contrast, tau-leaping with equal timesteps can result in either no transitions or multiple transitions within the same step. Both scenarios are suboptimal: the former wastes step, while the latter introduces approximation errors. Adaptive Time Correction. According to the sampled timesteps t, the sampling starts from noise at = 0 and reaches data at 1. However, in practice, the actual time progression can be faster or slower than scheduled. For example, sometimes the progress is faster in the beginning when the starting sequence contains some clean tokens. More often, later in the process, the denoiser makes mistakes and hence time progression is slower than the scheduled or even negative for some steps. This raises the question: can we leverage the signal from the planner to make adaptive adjustments? For example, even if scheduled time is reaches = 1.0, but according to the planner 10% of the data is still corrupted, the actual time progression under linear schedule should be closer to = 0.9. The reasonable approach is to assume the process is not yet complete and continue the plan-anddenoise sampling. Under this time correction mechanism, the stopping criterion is defined as continuing the sampling procedure until the planner determines that all positions are denoised, i.e., (cid:1) 0. In practice, we dont need to know the exact time; instead, we can when pθ continue sampling until either the stopping criterion is satisfied or the maximum budget of steps, , = xt (cid:0)zd"
        },
        {
            "title": "Preprint",
            "content": "is reached. The pseudo-algorithm for our proposed sampling method is presented in Algorithm 1. In cases where the denoiser use time information as input, we find it helpful to use the estimated time from the planner. At time t, from the noise schedule, we expect there to be (1 αt)D noised positions. The estimate of the number of noised positions from the denoiser is (cid:80) = xt). Therefore, the planners estimate of the corruption time is = α1 = xt)/D) where α1 is the inverse noise schedule. This adjustment better aligns the time-data pair with the distribution that the denoiser was trained on. (1 (cid:80) pθ(zd pθ(zd Based on the decomposition of the generation into planning and denoising, the proposed sampling method maximally capitalizes on the available sampling steps budget. The Gillespie-based plan-anddenoise sampler allows for exact simulation and ensures no step is wasted by prioritizing the denoising of noisy tokens first. The time correction mechanism enables the planner to identify both initial and reintroduced noisy tokens, continuously denoising them until all are corrected. This mechanism shares similarities with the stochastic noise injection-correction step in EDM [22]. Instead of using hyperparameters for deciding how much to travel back, our time correction is based on the planners estimate of the noise removal progress. Algorithm 1 DDPD Sampler 1t, maximum steps , stopping criteria ϵ 1: init 0, x0 p0, planner pθ, denoiser pθ 2: while < or pθ(zd = xi) < ϵ, do 3: 4: 5: Plan sample dimension Cat if denoiser uses time as input then (cid:16) 1 (cid:80) α1 (cid:16) pθ(z = xi) (cid:17) (cid:17) pθ(zd = xt)/D (cid:16) 1t(x pθ 1 = dxi, = ) (cid:17) , i+1 Denoise sample Cat + 1 6: 7: 8: return xi Utilizing Pretrained Mask Diffusion Denoiser. In language modeling and image generation, mask diffusion denoisers have been found to be more accurate than uniform diffusion counterparts [3, 29], with recent efforts increasingly focused on training mask diffusion denoisers [36, 34, 13]. The following proposition offers principled way to sample from the uniform denoiser by leveraging strong pretrained mask diffusion denoiser, coupled with separately trained planner. Proposition 3.5. From the following marginalization over zt, which indicates if tokens are noise or data: p1t (cid:0)xd 1xt, zd (cid:0)xd samples from p1t,uniform and then using mask diffusion denoiser to sample xd version of xt according to zt. 1xt, zd = (cid:1) = (cid:80) zt (cid:0)ztxt, zd = (cid:1) p1t(xd 1 with p1t,mask (cid:0)xd 1xt = (cid:1) can be drawn by first sampling zt from p(ztxt, zd 1xt, zt), (13) = ) (cid:1), where xt is the masked In practice, we can approximately sample zd from p(ztxt, zd xt). This approximation becomes exact if p(zd xt) is either very close to 0 or 1, which holds true for most dimensions during generation. We validated this holds most of time in language modeling in Appendix E.4. Even if approximation errors in zt occasionally lead to increased denoising errors, our sampling algorithm can effectively mitigate this by using the planner to identify and correct these unintentional errors. In our controlled experiments, we validate this and observe improved generative performance by replacing the uniform denoiser with mask diffusion denoiser trained on the same total number of tokens, while keeping the planner fixed. d=d pθ(zd = ) (cid:81)"
        },
        {
            "title": "4 TRAINING",
            "content": "Training objectives. Our plan-and-denoise parameterization in Eq. (12) enables us to use two separate neural networks for modeling the planner and the denoiser. Alternatively, both the planner and denoiser outputs can be derived from single uniform diffusion model, pθ 1xt), as described in Proposition 3.1. This approach may offer an advantage on simpler tasks, where minimal approximation errors for neural network training can be achieved, avoiding the sampling approximation 1t(xd"
        },
        {
            "title": "Preprint",
            "content": "introduced in Proposition 3.5. However, in modern generative AI tasks, training is often constrained by neural network capacity and available training tokens, making approximation errors inevitable. By using two separate networks, we can better decompose the complex task, potentially enabling faster training especially since planning is generally easier than denoising. The major concern with decomposed modeling is that joint modeling could introduce unnecessarily coupled training dynamics, hindering effective backpropagation of the training signal across different models. However, as we prove in Theorem 4.1, the evidence lower bound (ELBO) of discrete diffusion decomposes neatly, allowing the use of direct training signals from the noise corruption process for independent training of the planner and denoiser (proof in Appendix A.2). Theorem 4.1. Let x1 be clean data point, and xt, zt represent noisy data point and its state of corruption drawn from pt1(xt, ztx1). The ELBO for uniform discrete diffusion simplifies into the sum of the following separate cross-entropy-type objectives. The training of the planner pθ reduces to binary classification, where the goal is to estimate the corruption probability by maximizing: Lplanner = EU (t;0,1)pdata(x1)pt1(zt,xtx1) (cid:104) αt 1αt (cid:80)D d=1 log pθ (cid:0)zd xt (cid:1)(cid:105) . (14) The denoiser pθ 1t is trained to predict clean data reconstruction distribution: Ldenoiser = EU (t;0,1)pdata(x1)p(xt,ztx1) (cid:104) αt 1αt (cid:80)D d=1 δ{zd , } log pθ 1t(xd 1xt, zd (cid:105) = ) . (15) Standard transformer architectures can be used to parameterize both the denoiser and the planner, where the denoiser outputs logits and the planner outputs single logit per dimension."
        },
        {
            "title": "5 RELATED WORK",
            "content": "Discrete Diffusion/Flow Models. Previous discrete diffusion/flow methods, whether in discrete time [3, 21, 34] or continuous time [6, 39, 29, 7, 36, 13], adopt the denoiser-only or score-modeling perspective. In contrast, we introduce theoretically grounded decomposition of the generative process into planning and denoising. DFM [7] and the Reparameterized Diffusion Model (RDM) [46] introduce stochasticity into the reverse flow/diffusion process, allowing for adjustable random jumps between states. This has been shown to improve the generation quality by providing denoiser more opportunities to correct previous errors. Additionally, RDM uses the denoisers prediction confidence as heuristic [14, 35, 8] for determining which tokens to denoise first. Lee et al. [24] introduces another heuristic in image generation that aims at correcting previous denoising errors by first generating all tokens and then randomly regenerating them in batches. Self-Correction Sampling. Predictor-corrector sampling methods are proposed for both continuous and discrete diffusion [37, 6] that employ MCMC steps for correction after each predictor step. However, for continuous diffusion, this approach has been found to be less effective compared to the noise-injection stochasticity scheme [22, 42]. In the case of discrete diffusion, an excessively large number of corrector steps is required, which limits the methods overall effectiveness."
        },
        {
            "title": "6 EXPERIMENT",
            "content": "Before going into details, we note that DDPD incurs 2 NFE v.s. 1 NFE per step in denoiser-only approaches, an extra cost we pay for planning. To ensure fair comparison, we also evaluate denoiseronly methods that are either 2 large or use 2 steps. Our findings show that spending compute on planning is more effective than doubling compute on denoising when cost is factor. Text8. We first evaluate DDPD on the small-scale character-level text modeling benchmark, text8 [30], which consists of 100 million characters extracted from Wikipedia, segmented into chunks of 256 letters. Our experimental setup follows that of [7]. Methods for comparison include 1) autoregressive model 2) DFM: discrete flow model (and 2 param. version) [7], the best available discrete diffusion/flow model for this task, 3) DFM-Uni: original DFM uniform diffusion using tau-leaping, 4) DDPD-DFM-Uni: DDPD using uniform diffusion model as planner and denoiser, 5) DDPD-UniD: DDPD with separately trained planner and uniform denoiser, 6) DDPD-MaskD: DDPD with separately planner and mask denoiser. Details in the sampling differences are summarized"
        },
        {
            "title": "Preprint",
            "content": "in Table 3. All models are of same size (86M) and trained for 750k iterations of batch size 2048, except for autoregressive model, which requires fewer iterations to converge. Generated samples are evaluated using the negative log-likelihood (NLL) under the larger language model GPT-J-6B [40]. Since NLL can be manipulated by repeating letters, we also measure token distribution entropy. High-quality samples should have both low NLL and entropy values close to the data distribution. Fig. 2 shows the performance of various methods with different sampling step budgets. DFM methods use tau-leaping while DDPD methods use our proposed adaptive Gillespie sampler. The original mask diffusion (DFM, η = 0) and uniform diffusion (DFM-Uni) perform similarly, and adding stochasticity (η = 15) improves DFMs sample quality. Our proposed plan-and-denoise DDPD sampler consistently enhances the quality vs. diversity trade-off and significantly outperforms significantly outperforms DFM with 2 parameters. Moreover, DDPD makes more efficient use of the inference-time budget (Fig. 2, middle), continuously refining the generated sequences. We observe that DDPD with single network (DDPD-DFM-Uni) outperforms using separately trained planner and denoiser, as the task simplicity allows all models to achieve 90% denoising accuracy at = 0.85. The benefit of reducing each models burden is outweighed by compounded approximation errors (Section 3.2). The weaker performance of τ -leaping (PMaskD in Fig. 7) confirms this issue lies in approximation errors, not the sampling scheme. To emulate practical largerscale task where the models are undertrained due to computational or capacity budget limitations, we reduced training steps from 750k to 20k (Fig. 2, right). With only 20k steps, using separate planner and denoiser performs comparably to DFM at 750k, while the single model suffers mode collapse due to larger approximation errors, highlighting the benefits of faster separate learning. Further ablation studies on imperfect training of either the planner or denoiser (Figs. 5 and 6) show that performance remains robust to varying levels of denoiser imperfection, thanks to the self-correction mechanism in the sampling process. An imperfect planner has greater impact, shifting the quality-diversity Pareto front. In this case, training separate models proves more robust in preserving diversity and preventing mode collapse compared to training single model. The ablation in Fig. 7 examines the individual effects of the modifications introduced in the DDPD sampler. We also measure the denoising error terms in the ELBO for the planner + denoiser setup vs. the single neural network approach, as shown in Tables 4 to 6 of Appendix E.1.3, which further validates the performance difference of various design choices. Figure 2: Negative log-likelihood measured with GPT-J versus sample entropy (in terms of tokens), with logit temperatures of the denoiser swept over {0.8, 0.9, 1.0}. Left: DDPD v.s. SOTA baselines. Middle: Varying sampling steps from 250 to 1000; both DFM and DDPD use the same mask-based denoiser. Right: DDPD single-neural-network v.s. DDPD planner + mask denoiser, both trained for 20k iterations. DFM at 750k iter. OpenWebText Language Modeling. In Fig. 3, we compare DDPD with SEDD [29], both trained on the larger OpenWebText dataset [18]. We maintained the same experimental settings as in SEDD, with token vocabulary size = 50257 and = 1024, to validate whether planning improves generative performance under controlled conditions. We use the same pretrained SEDD-small or SEDD-medium score model as mask diffusion denoiser, based on the conversion relationship outlined in Table 1. separate planner network, with the same configuration as SEDD-small (90M), is trained for 400k iterations with batch size 512. We evaluated the quality of unconditional samples using generative perplexity, measured by larger language models GPT-2-L (774M) [33] and GPT-J (6B) [40]. Both SEDD and DDPD were simulated using 1024 to 4096 steps, with top-p = 1.0. SEDD used tau-leaping, while DDPD employed our newly proposed sampler. We also include GPT-2 [33] as the autoregressive baseline, with top-p sweeping from 0.7 to 1.0. We experimented DDPD sampler with both softmax selection  (Fig. 8)  and proportional selection  (Fig. 9)  ."
        },
        {
            "title": "Preprint",
            "content": "SEDD shows marginal improvement with additional steps, similar to DFM in the text8 case. In contrast, DDPD leveraged planning to continuously improve sample quality, with the most improvements in early stages and diminishing returns in later steps as the sequence gets mostly corrected. This shows that the planner optimally selects the denoising order and adaptively corrects accumulated mistakes. Figure 3: Generative perplexity v.s. entropy (both plotted in log-scale) of SEDD, DDPD and GPT-2. ImageNet 256 256 Generation with Discrete Tokens. An image is represented using discretevalued tokens with pre-trained tokenizer and decoder. The generative model is used for generating sequences in the token space. We focus on understanding how DDPD compares to existing sampling methods using the same denoiser, instead of aiming for SOTA performance. The pretrained tokenizer and mask denoiser from Yu et al. [45] is used, where the token length of an image is = 128. We compare DDPD with two mask diffusion type baselines: 1) standard mask diffusion and 2) MaskGIT [8], which selects the next tokens based on the denoisers confidence of its predicted logits. To prevent MaskGIT from making overly greedy selections, random noise is added to the confidence scores, with its magnitude annealed to zero following linear schedule. We test all methods from 8 to 128 steps. Parallel sampling is used if # steps < 128. The results on FID scores ([19], lower is better) are presented in Table 2. More results on inception scores and comparison with SOTA are in Appendix E.3. Generated samples are in Appendix F.3. In DDPD, the sampling process is divided into two stages: the first half follows parallel sampling schedule, while the second half adopts an adaptive step size based on the noise level, allowing for finer discretization towards the end of sampling. Notably, we observe that the standard mask performs poorly, with no significant improvement even with more sampling steps. This is attributed to the low accuracy of the denoiser, which is much worse than in OpenWebText language modeling (3% v.s. 60% at = 0.85). The confidence-based sampling of MaskGIT proves effective, but its greedy selection, despite the added randomness, sacrifices the sample diversity for quality, leading to higher FID values compared to DDPD. This issue becomes particularly pronounced when more steps are used, resulting in an overly greedy sampling order. While DDPD requires minimum number of sampling steps to correct sampling errors from earlier stages, it achieves the best results and more steps do not lead to worse FID. We also conducted ablation to study the effect of increasing number of second-stage steps for DDPD in Fig. 11. To enhance the empirical performance in image token generation, we tested all methods with logit temperature annealing, common approach to lower sampling temperature τ for improved denoising accuracy. We found τ = 0.6 gives the best results among τ = 1.0, 0.9, 0.8, 0.7, 0.6, 0.5, greatly improving mask diffusion and resulting in competitive FID scores. However, for MaskGIT, this reduces sample diversity, leading to even higher FID scores compared to no annealing. We also tried another annealing trick from Yu et al. [45], where τ is linearly reduced from 1.0 to 0.0 during generation. This trick worked well for mask diffusion, allowing for further improvement over fixedtemperature annealing. For DDPD, performance remained relatively stable, with minor improvements or degradations compared to no annealing."
        },
        {
            "title": "Preprint",
            "content": "Table 2: FID score () on ImageNet 256 256. MaskD refers to mask diffusion. The denoiser and parallel sampling schedule are kept the same as [45], without classifier-free guidance. No Logit Annealing Logit temp 0.6 Logit temp 1.0 0.0 Steps MaskD MaskGIT DDPD MaskD MaskGIT DDPD MaskD MaskGIT DDPD 8 16 32 64 38.06 32.44 29.12 27.54 26.83 5.51 6.66 8.09 9.08 9.34 6.8 5.12 4.75 4.73 4.89 5.69 4.85 4.86 4.98 5.13 10.02 11.24 11.93 12.26 12.52 5.71 4.92 4.91 5.14 5. 4.99 4.69 4.62 4.6 4.89 8.53 9.21 9.9 10.35 10.2 5.99 5.03 4.98 5.26 5."
        },
        {
            "title": "7 CONCLUSION",
            "content": "We introduced Discrete Diffusion with Planned Denoising (DDPD), novel framework that decomposes the discrete generation process into planning and denoising. We propose new adaptive sampler that leverages the planner for more effective and robust generation by adjusting time step sizes and prioritizing the denoising of the most corrupted positions. Additionally, it simplifies the learning process by allowing each model to focus specifically on either planning or denoising. The incorporation of planning makes the generative process more robust to errors made by the denoiser during generation. On GPT-2 scale language modeling and ImageNet 256 256 token generation, DDPD enables significant performance boost compared to denoiser-only discrete diffusion models. ACKNOWLEDGMENTS We thank Jiaxin Shi for valuable discussions on evaluation of ELBO. SL and RGB acknowledge funding from MIT-IBM Watson AI Lab, NSF Award 2209892 and compute from NERSC GenAI award m4737. JN acknowledges support from Toyota Research Institute. AC acknowledges support from the EPSRC CDT in Modern Statistics and Statistical Machine Learning (EP/S023151/1)."
        },
        {
            "title": "REFERENCES",
            "content": "[1] Sarah Alamdari, Nitya Thakkar, Rianne van den Berg, Alex Lu, Nicolo Fusi, Ava Amini, and Kevin Yang. Protein generation with evolutionary diffusion: sequence is all you need. BioRxiv, pp. 202309, 2023. (page 1) [2] Michael Albergo and Eric Vanden-Eijnden. Building normalizing flows with stochastic (page 3) interpolants. International Conference on Learning Representations, 2023. [3] Jacob Austin, Daniel Johnson, Jonathan Ho, Daniel Tarlow, and Rianne Van Den Berg. Structured denoising diffusion models in discrete state-spaces. Advances in Neural Information Processing Systems, 2021. (pages 3, 7, 8, and 21) [4] Pavel Avdeyev, Chenlai Shi, Yuhao Tan, Kseniia Dudnyk, and Jian Zhou. Dirichlet diffusion In International Conference on Machine (page 1) score model for biological sequence generation. Learning, 2023. [5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. In Advances in neural information processing systems, 2020. (page 1) [6] Andrew Campbell, Joe Benton, Valentin De Bortoli, Thomas Rainforth, George Deligiannidis, and Arnaud Doucet. continuous time framework for discrete denoising models. Advances in Neural Information Processing Systems, 2022. (pages 3, 5, 6, 8, and 20) [7] Andrew Campbell, Jason Yim, Regina Barzilay, Tom Rainforth, and Tommi Jaakkola. Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design. International Conference on Machine Learning, 2024. (pages 2, 3, 4, 5, 6, 8, 16, 20, 21, and 23) [8] Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William Freeman. Maskgit: Masked generative image transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1131511325, 2022. (pages 1, 8, 10, 26, and 31) [9] Huiwen Chang, Han Zhang, Jarred Barber, Aaron Maschinot, Jose Lezama, Lu Jiang, MingHsuan Yang, Kevin Patrick Murphy, William Freeman, Michael Rubinstein, et al. Muse: Text-to-image generation via masked generative transformers. In International Conference on Machine Learning, 2023. (page 1) [10] Zixiang Chen, Huizhuo Yuan, Yongqian Li, Yiwen Kou, Junkai Zhang, and Quanquan Gu. Fast sampling via de-randomization for discrete diffusion models. arXiv preprint arXiv:2312.09193, (page 6) 2023. [11] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. (page 26) Advances in neural information processing systems, 34:87808794, 2021. [12] Patrick Esser, Robin Rombach, and Björn Ommer. Taming transformers for high-resolution image synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1287312883, 2021. (page 31) [13] Itai Gat, Tal Remez, Neta Shaul, Felix Kreuk, Ricky TQ Chen, Gabriel Synnaeve, Yossi Adi, and Yaron Lipman. Discrete flow matching. arXiv preprint arXiv:2407.15595, 2024. (pages 1, 2, 3, 4, 5, 7, and 8) [14] Marjan Ghazvininejad, Omer Levy, Yinhan Liu, and Luke Zettlemoyer. Mask-predict: Parallel (page 8) decoding of conditional masked language models. In EMNLP-IJCNLP, 2019. [15] Daniel Gillespie. general method for numerically simulating the stochastic time evolution of coupled chemical reactions. Journal of computational physics, 22(4):403434, 1976. (page 6) [16] Daniel Gillespie. Exact stochastic simulation of coupled chemical reactions. The journal of (page 6) physical chemistry, 81(25):23402361, 1977."
        },
        {
            "title": "Preprint",
            "content": "[17] A. Gokaslan and V. Cohen. Openwebtext corpus. OpenWebTextCorpus, 2019. http://Skylion007.github.io/ (page 26) [18] Aaron Gokaslan and Vanya Cohen. OpenWebText Corpus, 2019. URL http://Skylion007. (page 9) github.io/OpenWebTextCorpus. [19] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by two time-scale update rule converge to local Nash equilibrium. Advances in neural information processing systems, 30, 2017. (pages 10 and 26) [20] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neural (page 1) text degeneration. In International Conference on Learning Representations, 2019. [21] Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forré, and Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. Advances in Neural Information Processing Systems, 34:1245412465, 2021. (page 8) [22] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. Advances in neural information processing systems, 2022. (pages 7 and 8) [23] Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han. Autoregressive image generation using residual quantization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1145211461, 2022. (page 31) [24] Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and WOOK SHIN HAN. Draft-and-revise: Effective image generation with contextual rq-transformer. Advances in Neural Information Processing Systems, 35:3012730138, 2022. (page 8) [25] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et al. Evolutionary-scale prediction of atomic-level protein structure with language model. Science, 379(6637):11231130, 2023. (page 1) [26] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative modeling. International Conference on Learning Representations, (page 3) 2023. [27] Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. International Conference on Learning Representations, (page 3) 2023. [28] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint (pages 23 and 26) arXiv:1711.05101, 2019. [29] Aaron Lou, Chenlin Meng, and Stefano Ermon. Discrete diffusion language modeling by estimating the ratios of the data distribution. International Conference on Machine Learning, (pages 1, 3, 4, 5, 6, 7, 8, 9, 20, 21, 24, and 26) 2024. [30] Matt Mahoney. Large text compression benchmark, 2011. URL http://mattmahoney.net/ (page 8) dc/textdata.html. [31] James Norris. Markov chains. Number 2. Cambridge university press, 1998. (page 2) [32] William Peebles and Saining Xie. Scalable diffusion models with transformers, 2023. (page 24) [33] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019. (pages 9, 24, and 26) [34] Subham Sekhar Sahoo, Marianne Arriola, Yair Schiff, Aaron Gokaslan, Edgar Marroquin, Justin Chiu, Alexander Rush, and Volodymyr Kuleshov. Simple and effective masked diffusion language models. arXiv preprint arXiv:2406.07524, 2024. (pages 1, 3, 4, 5, 6, 7, 8, and 21)"
        },
        {
            "title": "Preprint",
            "content": "[35] Nikolay Savinov, Junyoung Chung, Mikolaj Binkowski, Erich Elsen, and Aaron van den Oord. In International Conference on (page 8) Step-unrolled denoising autoencoders for text generation. Learning Representations, 2022. [36] Jiaxin Shi, Kehang Han, Zhe Wang, Arnaud Doucet, and Michalis Titsias. Simplified and generalized masked diffusion for discrete data. arXiv preprint arXiv:2406.04329, 2024. (pages 1, 3, 4, 5, 7, 8, and 21) [37] Yang Song, Jascha Sohl-Dickstein, Diederik Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. International Conference on Learning Representations, 2020. (page 8) [38] Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. Neurocomputing, 568:127063, 2024. (page 24) [39] Haoran Sun, Lijun Yu, Bo Dai, Dale Schuurmans, and Hanjun Dai. Score-based continuoustime discrete diffusion models. International Conference on Learning Representations, 2023. (pages 3, 4, 5, 6, 8, and 20) [40] Ben Wang and Aran Komatsuzaki. GPT-J-6B: 6 billion parameter autoregressive language model, 2021. URL https://github.com/kingoflolz/mesh-transformer-jax. (pages 9, 24, and 26) [41] Darren Wilkinson. Stochastic modelling for systems biology. Chapman and Hall/CRC, 2018. (page 6) [42] Yilun Xu, Mingyang Deng, Xiang Cheng, Yonglong Tian, Ziming Liu, and Tommi Jaakkola. Restart sampling for improving generative processes. Advances in Neural Information Processing Systems, 36:7680676838, 2023. (page 8) [43] Jiahui Yu, Xin Li, Jing Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu. Vector-quantized image modeling with In International Conference on Learning Representations (ICLR), 2022. improved vqgan. (page 31) [44] Lijun Yu, José Lezama, Nitesh Gundavarapu, Luca Versari, Kihyuk Sohn, David Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander Hauptmann, et al. Language model beats diffusiontokenizer is key to visual generation. In International Conference on Learning Representations (ICLR), 2024. (page 31) [45] Qihang Yu, Mark Weber, Xueqing Deng, Xiaohui Shen, Daniel Cremers, and Liang-Chieh Chen. An image is worth 32 tokens for reconstruction and generation. arXiv preprint arXiv:2406.07550, (pages 10, 11, 26, and 31) 2024. [46] Lin Zheng, Jianbo Yuan, Lei Yu, and Lingpeng Kong. reparameterized discrete diffusion (page 8) model for text generation. arXiv preprint arXiv:2302.05737, 2023."
        },
        {
            "title": "Appendix",
            "content": "t = xt A.1 PROOF OF PROPOSITION 3.1 Part 1: Calculate (cid:0)zd We first derive how to calculate (cid:0)zd First, from law of total probability, (cid:1) = (cid:0)zd = xt (cid:1) in Eq. (10). = xt (cid:1) in Eq. (10) using p1t. (cid:88) p1t (cid:0)xd 1 = jdxt (cid:1) (cid:0)zd = xd 1 = jd, xt (cid:1) (16) Next we derive closed form of (cid:0)zd According to the noise schedule, = xd 1 = jd, xt (cid:1). jd Using Bayes rule (cid:0)zd xd , p (cid:0)zd , xd x1 (cid:1) = αt 0 (1αt)/S (1αt)/S = xd 1 = xd 1 = xd 1 = xd 1 if zd if zd if zd if zd = D, xd = D, xd = N, xd = N, xd (cid:1), we have x1 (cid:1) /p (cid:0)xd x1 (cid:1) = (cid:0)zd , xd (cid:1) = , x1 αt αt+(1αt)/S 0 (1αt)/S αt+(1αt)/S if zd if zd if zd if zd = D, xd = D, xd = N, xd = N, xd = xd 1 = xd 1 = xd 1 = xd 1 (cid:0)zd xd Plugging Eq. (18) into Eq. (16), we have (cid:1) = 1 = jdxt = xt (cid:0)xd (cid:0)zd (cid:88) (cid:1) (cid:0)zd = xd 1 = jd, xt (cid:1) jd (cid:88) jd=xd (cid:88) = = (cid:0)xd 1 = jdxt (cid:0)xd 1 = jdxt (cid:1) 1 + (cid:0)xd 1 = xd xt (cid:1) 1 + (cid:0)xd 1 = xd xt jd=xd = 1 (cid:0)xd 1 = xd xt (cid:1) αt αt + (1 αt)/S which gives us the form in Eq. (10). (cid:1) (1 αt)/S αt + (1 αt)/S (cid:18) 1 (cid:1) αt αt + (1 αt)/S (cid:19) Part 2: Calculate p1t (cid:0)xd 1 = jdxt, zd = (cid:1) in Eq. (11). From Bayes rule, we have p1t (cid:0)xd 1 = jdxt, zd = (cid:1) = = = (cid:1) (cid:0)xd (cid:0)xd 1 = jd, zd (cid:0)zd 1 = jdxt = xt = xt (cid:1) (cid:1) (cid:0)zd (cid:0)zd (cid:1) (cid:1) , xd (cid:0)xd (cid:0)zd 1 = jdxt = xt = jd = xt, xd (cid:1) = xt 1 = jd(cid:1) (17) (18) (19) (20) (21) (22) (23) (24) (25) Eq. (25) is by plugging in the following from Eq. (18) that (cid:0)zd Part 3: Verify equivalence to the original optimal rate in Eq. (9). = xt, xd 1 = jd(cid:1) = 1 if xd = jd."
        },
        {
            "title": "Preprint",
            "content": "By plugging in Eq. (10) and Eq. (11) into Eq. (9), we have"
        },
        {
            "title": "Runif\nt",
            "content": "(cid:0)xt, jd(cid:1) = αt 1 αt (cid:124) (cid:123)(cid:122) (cid:125) recovery rate (cid:1) (cid:0)zd = xt (cid:124) (cid:125) (cid:123)(cid:122) prob. of corruption p1t (cid:124) (cid:0)xd 1 = jdxt, zd (cid:123)(cid:122) prob. of denoising = (cid:1) (cid:125) = αt 1 αt (cid:124) (cid:123)(cid:122) (cid:125) recovery rate (cid:0)xd 1 = jdxt p1t (cid:124) (cid:125) (cid:123)(cid:122) composed denoising prob. (cid:1) (26) A.2 PROOF OF THEOREM 4.1: DERIVING THE ELBO FOR TRAINING This derivation follows the Continuous Time Markov Chain framework. We refer the readers to Appendix C.1 of Campbell et al. [7] for primer on CTMC. Here we provide the proof for = 1 case. The result holds for > 1 case following same arguments from Appendix of Campbell et al. [7]. Let be CTMC trajectory, fully described by its jump times T1, , Tn and state values between jumps W0, WT0 , , WTn . At time Tk, the state jumps from WTk1 to WTk . With its path measure properly defined, we start with the following result from Campbell et al. [7] Appendix C.1, the ELBO of Epdata(x1) [log pθ(x1)] is given by introducing the corruption process as the variational distribution: Epdata(x1) [log pθ(x1)] (cid:90) pdata(dx1)Qx1(dω) log dPθ dQx1 (ω), (27) where dPθ dQx1 (ω) = p0(W0) exp (cid:16) p01(W0x1) exp (cid:16) (cid:82) t=1 (cid:82) t= (W t=0 Rθ t=0 Rt(W (cid:17) (cid:81) )dt (cid:17) (cid:81) x1)dt t:Wt=W Rθ (W , Wt) t:Wt=W Rt(W , Wtx1) . (28) Intuitively, the measure (probability) of trajectory is determined by: the starting state from the prior distribution p0(W0), and the product of the probability of waiting from Tk1 to Tk (which follows an Exponential distribution) and the transition rate of the jump from to Wt. For our method, when simulating the data corruption process, we augment aug to record both state values Wt and its latent value Zt {N, D}D. The jump is defined to happen when the latent value jumps from Zk1 to Zk with one of the dimensions corrupted and the state value jumps from Wk1 to Wk. Similarly, the ELBO of Epdata(x1) [log pθ(x1)] can be defined as: Epdata(x1) [log pθ(x1)] (cid:90) pdata(dx1)Qx1(dωaug) log dPθ dQx1 (ωaug) (29) where the Radon-Nikodym derivative is given by: dPθ dQx (ωaug) = p0 (W0) exp (cid:16) (cid:82) t=1 (cid:0)W (cid:1) dt (cid:17) (cid:81) p01 (W0, Z0 x1) exp (cid:16) (cid:82) t=1 t=0 Rt , x1 (cid:1) dt t=0 Rθ (cid:0)W (cid:1) Rθ (cid:17) (cid:81) (cid:0)W , Wt (cid:0)W Rt , Wt, (cid:1) , Zt x1 (30) By plugging in Eq. (30) into Eq. (29), we arrive at"
        },
        {
            "title": "Preprint",
            "content": "LELBO = = (cid:90) (cid:90) pdata (dx1) pdata (dx1) (cid:90) ωaug:Qx1 (ωaug)>0 (cid:90) ωaug:Qx1 (ωaug)>0 (cid:40) Qx1(dωaug) (cid:40) Qx1(dωaug) (cid:90) t=1 t= (cid:90) t=1 t=0 Rθ (cid:0)W (cid:1) dt + (cid:88) log Rθ (cid:0)W , Wt (cid:1) (cid:41) αt 1 αt pθ (cid:0)Z = (cid:1) (cid:88) + log αt 1 αt pθ (cid:0)Z = (cid:1) pθ 1t (cid:0)x1 = WtW , = (cid:1) (cid:41) (cid:90) = + pdata (dx1) (cid:90) ωaug:Qx1 (ωaug)>0 (cid:40) Qx1(dωaug) (cid:90) t=1 t= αt 1 αt pθ (cid:0)Z = (cid:1) (cid:88) t{T1, ,TN } (cid:18) log αt 1 αt pθ (cid:0)Z = (cid:1) + log pθ 1t (cid:0)x1 = WtW , = (cid:1) (cid:19) (cid:41) (31) (31) contain terms that depend on the planner pθ (zt = xt) and the denoiser Eq. pθ 1t (x1 = jxt, zt = ). Next, we show those terms can be separated into two parts: Ldenoiser = EU (t;0,1)pdata(x1)p(xt,ztx1) (cid:20) δ{zt, } log pθ 1t(x1xt, zt = ) αt 1 αt (cid:20) αt 1 αt (cid:21) log pθ (ztxt) (cid:21) (32) (33) Lplanner = EU (t;0,1)pdata(x1)pt1(zt,xtx1) First part: cross-entropy loss on x1 denoising. , All terms associated with pθ 1t (cid:0)x1 = WtW = (cid:1) are: Ldenoising = = = = (cid:90) (cid:90) (cid:90) pdata (dx1) pdata (dx1) pdata (dx1) (cid:90) ωaug (cid:90) ωaug (cid:90) ωaug Qx1(dωaug) (cid:88) log pθ 1t (cid:0)x1 = WtW , = (cid:1) Qx1(dωaug) Qx1(dωaug) (cid:90) t= t=0 (cid:90) t=1 (cid:88) (y,u) (cid:88) t= (y,u) Rt ((Wt, Zt), (y, u)x1) log pθ 1t (cid:0)x1 = WtW , = (cid:1) Dynkin αt 1 αt δ{Zt, }δ{u, D}δ{y, x1} log pθ 1t (cid:0)x1 = WtW , = (cid:1) (cid:90) (cid:90) t=1 t= pdata (dx1) (cid:90) ωaug Qx1(dωaug) αt 1 αt δ{Zt, } log pθ 1t (cid:0)x1 = WtW (cid:21) , = (cid:1) = EU (t;0,1)pdata(x1)pt1(zt,xtx1) δ{zt, } log pθ 1t (x1xt, zt = ) (cid:20) αt 1 αt At the second equation, we use Dynkins formula (cid:90) pdata (dx1) Qx1(dω) (cid:88) (cid:0)W , Wt (cid:1) = (cid:90) pdata (dx1) Qx1 (dω) t:all jump times (cid:90) t=1 (cid:88) t=0 Rt (Wt, x1) (Wt, y) dt which allows us to switch from sum over jump times into full integral over time interval weighted by the probability of the jump happening and the next state the jump goes to. Second part: cross-entropy loss on zt = prediction. The remaining terms are associated with Rθ Rθ αt 1αt , j) = αt 1αt t,jump(W t,jump(W ) = (cid:80) (cid:0)Z pθ (cid:0)Z pθ = t = (cid:1) which is the jump rate at , i.e. (cid:1) according to Eq. (12). In this proof,"
        },
        {
            "title": "Preprint",
            "content": "we will use Rθ in short for Rθ t,jump. The remaining loss terms Lplanner = = (cid:90) (cid:90) pdata (dx1) pdata (dx1) (cid:90) = pdata (dx1) (cid:90) ωaug (cid:90) ωaug (cid:90) ωaug (cid:40) Qx1(dωaug) Qx1(dωaug) (cid:90) t=1 t=0 (cid:90) t=1 t=0 Qx1(dωaug) (cid:90) t=1 (cid:26) = EU (t;0,1)pdata(x1)p(xt,ztx1) Rθ (cid:0)W (cid:1) dt + (cid:88) log Rθ (cid:0)W (cid:1) (cid:41) Rθ (Wt) dt + (cid:90) t= (cid:88) t=0 (y,u) Rt ((Wt, Zt), (y, u)x1) log Rθ (Wt) dt δ{Zt, } log Rθ (Wt) dt"
        },
        {
            "title": "Dynkin",
            "content": "(cid:27) Rθ (Wt) dt + (cid:90) t=1 t=0 αt 1 αt (cid:21) (xt) δ{zt, } log Rθ t=0 (cid:20) Rθ (xt) + αt 1 αt We first rewrite the loss as (cid:20) Rθ EU (t;0,1)p(xt)p(x1,ztxt) (xt) + αt 1 αt δ{zt, } log Rθ (xt) (cid:21) =EU (t;0,1)p(xt)p(x1,ztxt) (cid:20) αt 1 αt pθ (zt = xt) + αt 1 αt δ{zt, } log (cid:21) pθ (zt = xt) αt 1 αt (34) If xt is given fixed, by taking the derivative of pθ (zt = xt) and setting it to zero, we have the optimal solution to be: pθ (zt = xt) = Ep(x1,ztxt)δ{zt, } This is equivalent to optimizing the cross-entropy loss, which has the same optimal solution: Ep(x1,ztxt) [δ{zt, } log pθ (zt = xt) + (1 δ{zt, }) log (1 pθ (zt = xt))] Plugging this xt-conditional loss back to Eq. (34), we arrive at the cross entropy training loss for the planner: Lplanner = EU (t;0,1)pdata(x1)pt1(zt,xtx1) (cid:20) αt 1 αt (cid:21) log pθ (ztxt) . A.3 PROOF OF PROPOSITION 3.3: CONTINUOUS TIME MARKOV CHAINS WITH SELF-CONNECTIONS We first describe the stochastic process that includes self-loops as this differs slightly from the standard CTMC formulation. We have rate matrix R(i, j) that is non-negative at all entries, R(i, j) 0. To simulate this process, we alternate between waiting for an exponentially distributed amount of time and sampling next state from transition distribution. The waiting time is exponentially distributed with rate (cid:80) R(i, k). The next state transition distribution is (ji) = . Note that (ii) can be non-zero due to the self-loops in this style of process. R(i,j) (cid:80) R(i,k) We can find an equivalent CTMC without self-loops that has the same distribution over trajectories as this self-loop process. To find this, we look at the infinitesimal transition distribution from time to time + t. We let denote the event that the exponential timer expires during the period [t, + t]. We let denote the no jump event. For the self-loop process, the infinitesimal transition distribution is pt+tt(ji) = P(J, ji) + P( J, ji) = P(Ji)P(jJ, i) + P( Ji)P(j J, i)"
        },
        {
            "title": "We have the following relations",
            "content": "P(Ji) = (cid:88) R(i, k)t property of exponential distribution P(jJ, i) = R(i, j) (cid:80) R(i, k) P(j J, i) = δ{j = i}"
        },
        {
            "title": "Our infinitesimal transition distribution therefore becomes",
            "content": "pt+tt(ji) = (cid:32) (cid:88) R(i, k)t (cid:33) R(i, j) (cid:80) R(i, k) (cid:32) + 1 (cid:88) (cid:33) R(i, k) δ{j = i} = R(i, j) + δ{j = i} δ{j = i}t (cid:88) R(i, k) = δ{i = j} + R(i, j) δ{i = j} (cid:32) (cid:88) (cid:33) R(i, k) We now note that for standard CTMC without self-loops and rate matrix R(i, j), the infinitesimal transition probability is pt+tt(ji) = δ{i = j} + tR(i, j) Therefore, we can see our self-loop process is equivalent to the CTMC with rate matrix equal to R(i, j) = R(i, j) (cid:88) R(i, i) = = R(i, k) In other words, the CTMC rate matrix is the same as the self-loop matrix except simply removing the diagonal entries and replacing them with negative row sums as is standard. In our case, the original CTMC without self-loops is defined by rate matrix Rt(xt, jd) = αt 1 αt pθ(zd = xt)pθ 1t(xd 1 = jdxt, zd = ), xd = jd We have free choice over the diagonal entries in our self-loop rate matrix and so we set the diagonal entries to be exactly the above equation evaluated at xd = jd. Rt(xt, jd) = αt 1 αt pθ(zd = xt)pθ 1t(xd 1 = jdxt, zd = ), xd , jd We can now evaluate the quantities needed for Gillespies Algorithm. The first is the total jump rate (cid:88) (cid:88) jd Rt(xt, jd) = = αt 1 αt αt 1 αt (cid:88) (cid:88) jd pθ(zd = xt)pθ 1t(x1 = jdxt, zd = ) pθ(zd = xt) (cid:88) We now need to find the next state jump distribution. To find the dimension to jump to we use (cid:80) jd (cid:80) (cid:80) Rt(xt, jd) Rt(xt, jd) jd αt 1αt = pθ(zd = xt) αt 1αt = pθ(zd = xt) To find the state within the chosen jump, the distribution is Rt(xt, jd) (cid:80) jd Rt(xt, jd) αt 1αt = pθ(zd = xt)pθ αt pθ(zd 1αt 1 = jdxt, zd = ) 1t(xd = xt) = pθ 1t(xd 1 = jdxt, zd = ) (35) (36) (37) (38) (39)"
        },
        {
            "title": "B GENERAL FORMULATION",
            "content": "B.1 SCORE-ENTROPY BASED: SDDM [39], SEDD [29] For coherence, we assume = 0 is noise and = 1 is data, while discrete diffusion literature consider flipped notion of time. Following Campbell et al. [6], (see Sec. H.1 of Campbell et al. [7]), the conditional reverse rate of discrete diffusion considered in [39, 29] is defined to be:"
        },
        {
            "title": "Rdiff\nt",
            "content": "(cid:0)xt, jd xd 1 (cid:1) = Rt(jd, xd ) (cid:0)jd xd 1 (cid:0)xd xd 1 (cid:0)11 SI(cid:1) for uniform diffusion or Rt = αt αt pt1 pt1 (cid:1) (cid:1) with the forward corruption rate Rt = αt Sαt for mask diffusion, such that the corruption schedule is according to αt. And the expected reverse rate for xd Rdiff (cid:0)xt, jd(cid:1) = (cid:0)xt, jd xd (cid:1) 1 p1t(xd = jd is given by: 1 xt)Rdiff (cid:0)xd 1 xt p1t (cid:1) Rt(jd, xd ) (cid:88) = xd 1 = Rt (cid:88) p1t (cid:0)xd 1 xt (cid:1) pt1 pt1 (cid:0)jd xd 1 (cid:0)xd xd 1 (cid:1) (cid:1) pt1 pt1 (cid:0)jd xd 1 (cid:0)xd xd 1 (cid:1) (cid:1) xd 1 (cid:88) xd 1 (cid:88) xd 1 (cid:16) (cid:16) (cid:16) = Rt = Rt 1, xd xd xd (cid:16) (cid:16) (cid:17) 1 xd xd (cid:17) (cid:17) pt1 pt1 (cid:0)jd xd 1 (cid:0)xd xd 1 (cid:1) (cid:1) xd xd (cid:17) 1 xd xd xd xd (cid:17) pt1 (cid:0)jd xd 1 (cid:1) (40) (cid:0)1e I(cid:1) (41) (42) (43) (44) (45) θ Parameterization in SDDM. [39] which uses neural network to parameterize pθ (cid:16) (cid:17) xd xd From here we can derive the rate derived in Eq. (16) in SDDM Rdiff (cid:0)xt, jd(cid:1) = Rt (cid:16) (cid:80) xd 1 (cid:17) 1 xd xd (cid:16) pt1 (cid:17) xd xd (cid:0)jd xd 1 (cid:1) = Rt (cid:16) jd xd (cid:17) (cid:16) xd xd (cid:17) pθ pθ Sθ Parameterization in SEDD. pt(jd,xd ) with sθ (xt)xd ,xd pt(xd ) j. Hence the reverse rate is parameterized by: SEDD [29] introduces the notion of score that directly models Rdiff (cid:0)xt, jd(cid:1) = Rt pt pt (cid:16) jd xd (cid:17) (cid:16) xd xd (cid:17) = Rt (cid:16) jd, xd (cid:17) (cid:16) , xd xd (cid:17) = Rtsθ (xt)xd pt pt pθ 1t Parameterization in SDDM. uses neural network to parameterize pθ 1t (cid:16) 1 xd xd (cid:17) and the rate is given by: In Eq. (24) of Sun et al. [39], the alternative parameterization Rdiff (cid:0)xt, jd(cid:1) = Rt (cid:16) (cid:16) jd xd (cid:17) (cid:17) xd xd (cid:16) pθ 1t xd 1 (cid:80) (cid:80) xd 1 pθ 1t = Rt (cid:17) 1 xd xd (cid:17) 1 xd xd pt pt1 1 (cid:0)jd xd (cid:0)xd xd 1 (cid:1) (cid:1) (cid:16)"
        },
        {
            "title": "Preprint",
            "content": "Connection to reverse rate in Campbell et al. [7]. In mask diffusion case, the rate of SDDM/SEDD coincides with the rate used in Eq. (42), i.e. rate of discrete diffusion and discrete flow = and formulation are the same for the mask diffusion case, Rdiff jd = M: = R,DFM . We have for xd t"
        },
        {
            "title": "Rdiff\nt",
            "content": "(cid:0)xt, jd(cid:1) = (cid:88) xd 1 p1t (cid:0)xd 1 xt (cid:1) Rt(jd, xd ) pt1 pt1 (cid:0)jd xd 1 (cid:0)xd xd 1 (cid:1) (cid:1) = Rtp1t (cid:0)xd 1 = jd xt = αt αt = αt p1t (cid:0)xd 1 = jd xt 1 1 αt p1t (cid:0)xd 1 = jd xt (cid:1) αt 1 αt (cid:1) αt 1 αt (cid:1) We can find that the parameterization of the generative rate used in DFM is only different from the SDDM/SEDDs parameterization by scalar. In the uniform diffusion case, the reverse rate used for discrete diffusion effectively generates the same marginal distribution pt1 and pt, but the difference lies in that the rate used for discrete diffusion is the sum of the rate introduced in Campbell et al. [7] plus special choice of the CTMC stochasticity that preserve detailed balance: Rdiff . Details are proved in H.1 in Campbell et al. [7] = R,DFM + RDB t"
        },
        {
            "title": "C ADDITIONAL TECHNICAL DETAILS",
            "content": "C.1 EVALUATING THE ELBO Note that the ELBO values are only comparable between uniform diffusion methods or mask diffusion methods, since they have different marginal distribution pt1 and hence different trajectory path distribution Q(W dω). Based on Eq. (29), we write out the ELBO terms for mask diffusion and uniform diffusion. Results about log-likelihood in prior works [3, 7, 29, 36, 34] are reporting the (denoising) rate transitioning term only, i.e., log pθ 1t 1 = xd (cid:16) (cid:17) . C.1.1 MASK DIFFUSION ELBO Term 1: Prior ratio log p0(W0) p01(W0x1) = 0. We observe that p0(W0) p01(W0x1) = 0. log p0(W0) p01(W0x1) = 1 since the starting noise distribution is the same. Hence Term 2: Rate Matching log exp( (cid:82) t=1 exp( (cid:82) t= t=0 Rθ t=0 Rt(W )dt) x1)dt) (W = 0. In the mask diffusion case, this term equals to 1, since Rθ (W ) = αt 1 αt (cid:88) d=1 δ (cid:110) ,d (cid:111) , , Rt(W x1) = αt 1 αt (cid:88) d=1 δ (cid:110) ,d (cid:111) , For any trajectory Wt, [0, 1), Rθ (W log exp( (cid:82) t=1 exp( (cid:82) t=1 t=0 Rθ t=0 Rt(W )dt) x1)dt) = 0. (W ) = Rt(W x1) and hence Term 2 equals to 0, i.e. Term 3: Rate Transitioning log Rθ (W ,Wt) ,Wtx1) Rt(W . Let the jump at happens at dimension d, we have (cid:110) ,d , Wt) = (W , pθ 1t Rθ (cid:111) (cid:16) δ αt 1 αt 1 = xd (cid:17) , Rt(W , Wtx1) = αt 1 αt (cid:110) ,d δ (cid:111) ,"
        },
        {
            "title": "Preprint",
            "content": "Since before the jump ,d simplifies to log Rθ ,Wt) ,Wtx1) Rt(W (W must be at mask state in order for jump to happen, hence this term = log pθ 1t xd 1 = W (cid:16) (cid:17) . C.1.2 UNIFORM DIFFUSION ELBO Term 1: Prior ratio log p0(W0) p01(W0x1) = 0."
        },
        {
            "title": "We observe that",
            "content": "p0(W0) p01(W0x1) = 1 since the starting noise distribution is the same uniform distribution."
        },
        {
            "title": "Hence log",
            "content": "p0(W0) p01(W0x1) = 0. Term 2: Rate Matching log If the generative process is parameterized by pθ 1xt) in Eq. (4): exp( (cid:82) t=1 exp( (cid:82) t= t=0 Rθ t=0 Rt(W (W . )dt) x1)dt) 1t(xd Rθ (W ) = αt 1 αt (cid:88) d=1 1t(xd pθ 1 = ,d xt), Rt(W x1) = αt 1 αt (cid:88) (1 δ (cid:110) ,d (cid:111) ) , xd 1 d=1 If the reverse generative process is parameterized as our approach in Eq. (12): Rθ (W ) = αt 1 αt (cid:88) d= pθ(z,d = xt), Rt(W , x1) = αt 1 αt (cid:88) d=1 δ (cid:110) ,d (cid:111) , Term 2 simplifies to: (cid:90) t=1 t=0 (cid:90) t=1 = Rt(W x1)dt (cid:90) t=1 t=0 Rθ (W )dt (cid:2)Rt (cid:0)W x1 (cid:0)W , (cid:2)Rt (cid:0)W x1 x1 t=0 =EU (t;0,1) (cid:2)Rt (cid:1) Rθ (cid:0)W (cid:1)(cid:3) dt (cid:1)(cid:3) (cid:1) Rθ (cid:1) Rθ (cid:0)W (cid:0)W (cid:1)(cid:3) for DDPD. Similarly, it simplifies to EU (t;0,1) For given Wt or aug Term 3: Rate Transitioning log Rθ (W ,Wt) ,Wtx1) Rt(W . If using parameterization pθ 1xt) in Eq. (4): 1t(xd (cid:16) , we can approximate this term with Monte-Carlo samples from U(t; 0, 1). Rθ (W , Wt) = αt 1 αt pθ 1t 1 = xd t (cid:17) , Rt(W , Wtx1) = (cid:16) αt 1 αt 1 δ (cid:110) ,d , xd 1 (cid:111)(cid:17) δ (cid:110) t , xd 1 (cid:111) We know for the trajectory Wt, before the jump ,d Rt(W . Hence the term simplifies to , Wtx1) = αt 1αt = xd 1 and after the jump = xd 1, therefore log (W Rθ Rt(W , Wt) , Wtx1) = log pθ 1t (cid:16) 1 = xd (cid:17) If using our parameterization in Eq. (12): pθ (cid:16) , Wt) = (W Rθ Rt(W , Wt, , Ztx1) = αt 1 αt αt 1 αt z,d = (cid:16) (cid:17) pθ 1t (cid:110) z,d δ (cid:111) δ , (cid:110) zd , (cid:111) δ 1 = xd (cid:111) (cid:110) d , xd 1 = , z,d αt 1 αt (cid:17) , = The term simplifies to log (W Rθ Rt(W , Wt) , Wtx1) = log (cid:104) pθ (cid:16) z,d = t (cid:16) (cid:17) pθ 1t 22 1 = xd t , z,d (cid:17)(cid:105) = N"
        },
        {
            "title": "D IMPLEMENTATION DETAILS",
            "content": "D.1 TEXT8 Models and training. We used the same transformer architecture from the DFM [7] for the denoiser model, with architectural details provided in Appendix of [7]. For the planner, we modified the final layer to output logit value representing the probability of noise. To prevent the planner model from exploiting the the current time step information to cheating on predicting the noise level, we find it necessary to not use time-embedding. Unlike the original DFM implementation, which uses self-conditioning inputs with previously predicted x1, we omit self-conditioning in all of our trained models, as we found it had minimal impact on the results. When training the planner and denoiser, we implemented the optimization objectives in Theorem 4.1 as the cross entropy between target and predicted noise state and tokens, averaged over the corrupted dimensions. linear noise schedule is to the training examples, as the signals used. We do not apply the time-dependent prefactor from each corrupted token are independent. All models follow Campbell et al. [7] which is based on the smallest GPT2 architecture (768 hidden dimensions, 12 transformer blocks, and 12 attention heads) and have 86M parameters. We increase the model size to 176M parameters for DFM-2 with 1024 hidden dimensions, 14 transformer blocks, and 16 attention heads. αt 1αt The following models were trained for text8: Autoregressive: p(xdx1:d1) Uniform diffusion denoiser (DFM-Uni): p1t(xd Planner: p(zd Noise-conditioned uniform diffusion denoiser (UniD): p1t(xd Mask diffusion denoiser (MaskD): p1t(xd = M) 1xt, xd xt) 1xt) 1xt, zd = ) We maintained the training procedure reported in [7], which we reproduce here for completeness. For all models, we used an effective batch size of 2048 with micro-batch 512 accumulated every 4 steps. For optimization, we used AdamW [28] with weight decay factor of 0.1. Learning rate was linearly warmed up to 104 over 1000 steps, and decayed using cosine schedule to 105 at 1M steps. We used the total training step budget of 750k steps. We saved checkpoints every 150k steps for ablation studies reported in Figs. 5 and 6. EMA was not used for text8 models. We trained our models on four A100 80GB GPUs, and it takes around 100 hours to finish training for 750k iterations. Table 3: Sampling schemes used for text8 experiments. Method Planner Denoiser Sampling Options N/A MaskD DFM-Uni DFM DFM-Uni DDPD-DFM-Uni DFM-Uni DFM-Uni PUniD PMaskD DDPD-UniD DDPD-MaskD Planner Planner Planner Planner UniD MaskD UniD MaskD tau-leaping tau-leaping Gillespie tau-leaping tau-leaping Gillespie Gillespie stochasticity η = 0, 15 A, A+B, A+B+C A, A+B, A+B+C A, A+B, A+B+C Sampling schemes. The sampling schemes used for experiments in the main text are outlined in Table 3. Gillespie Algorithm options A, B, and are defined as follows: A: Default DDPD Gillespie sampling in Algorithm 1 +B: Continue sampling until the maximum time step budget is reached +C: Use the softmax of noise prediction logits (over the dimension axis) instead of normalized prediction values to select the dimensions that will be denoised The implementation of these options when the uniform diffusion denoiser (DFM-Uni) is decomposed as planner and denoiser is presented in Listing 1. In Listing 2, we include the implementation of"
        },
        {
            "title": "Preprint",
            "content": "Listing 1: Gillespie Algorithm sampling loop with uniform diffusion denoiser (DFM-Uni) decomposed as planner and denoiser. import torch import torch.nn.functional as = batch_size = num_dimensions = mask_token_id = vocab_size eps = stopping_criteria samples = torch.randint(0, S, (B, D), dtype=torch.int64) time = torch.zeros(B, dtype=torch.float) is_time_up = torch.zeros(B, dtype=torch.bool) for in range(timesteps): # Planning: compute probabilities of changing each dimension logits = model(samples, time) # (B, D, S+1) logits[:, :, mask_token_id] = -1e4 pt_x1_probs = F.softmax(logits, dim=-1) pt_x1_probs_at_xt = torch.gather(pt_x1_probs, -1, samples[:, :, None]) # (B, D, 1) p_if_change = 1 - pt_x1_probs_at_xt.squeeze() p_if_change = torch.clamp(p_if_change, min=1e-20, max=1.0) # (B, D) total_noise = p_if_change.sum(-1) # Continue (Gillespie option B) or check stopping criteria if allow_time_backwards: pass else: is_time_up = (p_if_change < eps).all(-1) if is_time_up.all(): break # Planning: get dimensions that change if use_softmax_for_dim_change: # Use softmax instead (Gillespie option C) logits_dim_change = torch.logit(p_if_change.to(torch.float64), eps=1e-10) dim_change = torch.multinomial( torch.softmax(logits_dim_change, dim=-1), 1 ).squeeze() # (B,) else: dim_change = torch.multinomial(p_if_change, 1).squeeze() # Compute time input from planner output time = 1.0 - total_noise / # Denoising: sample new values for the dimensions that change logits = model(samples, time) logits[:, :, mask_token_id] = -1e4 pt_x1_probs = F.softmax(logits, dim=-1) # (B, D, S+1) probs_change = pt_x1_probs[torch.arange(B), dim_change, :] # (B, S+1) probs_change[torch.arange(B), samples[torch.arange(B), dim_change]] = 0.0 x1_values = torch.multinomial(probs_change, 1).squeeze() samples[is_time_up, dim_change[is_time_up]] = x1_values[is_time_up] # (B,) option and option when separate planner and separate denoiser are used. Option of using separate planner and denoiser follows the same logic of Listing 1 except using separate output from the planner and the denoiser. Evaluation. For each specified sampling scheme and sampling time step budget, we sampled 512 sequences with = 256. Using the GPT-J (6B) model [40], we computed the average negative loglikelihood for each sequence, and using the same tokenization scheme (BPE in [33]), we calculated sequence entropy as the sum over all dimensions. D.2 OPENWEBTEXT Models and training. We used the same model architectures from SEDD [29], which are based on the diffusion transformer (DiT) [32] and use rotary positional encodings [38]. We followed their training procedure closely for the OpenWebText experiments. Like the text8 models, we modified the final layer of DiT to serve as noise probability logit predictor for the planner model. SEDD models"
        },
        {
            "title": "Preprint",
            "content": "Listing 2: DDPD sampling loop with separate planner and denoiser. import torch import torch.nn.functional as timesteps = = batch_size = num_dimensions = mask_token_id = vocab_size eps = stopping_criteria samples = torch.randint(0, S, (B, D), dtype=torch.int64) time = torch.zeros(B, dtype=torch.float) for in range(timesteps): # Planning: compute probabilities of each dimension being corrupted if_noise_logits = planner_model(samples) # (B, D) # check for early stopping criteria: if every dimension is denoised prob_if_noise = torch.sigmoid(if_noise_logits) if (prob_if_noise < eps).all(): break if use_softmax_for_dim_change: # Option dim_change = torch.multinomial( torch.softmax(if_noise_logits, dim -1), 1 ).squeeze() else: # Option dim_change = torch.multinomial(prob_if_noise, 1).squeeze() # Denoising: sample new values for the dimensions that change # compute time input from planner output if use_mask_denoiser: mask = torch.bernoulli(prob_if_noise).bool().long() # sampling z_t mask[torch.arange(B), dim_change] = 1 # always mask the dimensions that are picked for denoising masked_sample = torch.where(mask, samples, mask_token_id) time = 1.0 - mask.sum(-1)/D logits = denoiser_model(masked_sample, time) logits[:, :, mask_token_id] = -1e4 else: time = 1.0 - prob_if_noise.sum(-1) / logits = denoiser_model(samples, time) pt_x1_probs = F.softmax(logits, dim=-1) # (B, D, S+1) probs_change = pt_x1_probs[torch.arange(B), dim_change, :] # (B, S+1) x1_values = torch.multinomial(probs_change, 1).squeeze() samples[torch.arange(B), dim_change] = x1_values # (B,)"
        },
        {
            "title": "Preprint",
            "content": "use the noise level σ instead of time for the time embeddings. While we retain this model input by using their σ(t), we replace it with zero when training the planner, similarly to the text8 models. All models were trained with batch size of 128 and gradients were accumulated every 4 steps. We used AdamW [28] with weight decay factor of 0, and the learning rate was linearly warmed up to 3 104 over the first 2500 steps and then held constant. EMA with decay factor of 0.9999 was applied to the model parameters. We validated the models on the OpenWebText dataset [17]. The mask denoisers are taken from the pretrained checkpoints of Lou et al. [29]. SEDD-small has 90M parameters and SEDD-medium has 320M parameters. We trained our planner models on nodes with four A100 80GB GPUs for 400k iterations. We only trained the planner models in the size of GPT-2-Small, which is 768 hidden dimensions, 12 layers, and 12 attention heads. Sampling and evaluation. We employed Tweedie tau-leaping denoising scheme for SEDD, and adaptive Gillespie sampler for DDPD, and different nucleus sampling thresholds (top-p values of 0.8, 0.85, 0.9, and 1.0) for GPT-2. For all models and sampling schemes, we generated 200 samples of sequence length 1024 and evaluated the generative perplexity using the GPT-2 Large [33] and GPT-J [40] models. D.3 IMAGE GENERATION WITH TOKENS Models and training. For tokenization and decoding of images, we use TiTok-S-128 model [45], which tokenizes 256 256 image into = 128 tokens with the codebook size of = 4096. Both mask diffusion denoiser and planner models use the U-Vit model architecture of MaskGIT [8] as implemented in the codebase of [45], with 768 hidden dimensions, 24 layers, and 16 attention heads. The mask denoisers are taken from pretrained checkpoints from Yu et al. [45]. The planner is trained with batch size 2048 for 400k iterations on 4 A100-80GB GPUs. We used AdamW [28] optimizer with weight decay factor of 0.03, β1 = 0.9, and β2 = 0.96, and learning rate of 2 104. The learning rate schedule included linear warmup over the first 10k steps, followed by cosine annealing down to final learning rate of 105. EMA was applied with decay factor of 0.999. Evaluation. We utilize the evaluation code from ADM [11] to compute the FID scores [19] and inception scores. For this evaluation, 50,000 images are generated across all classes. Each image is produced by first generating tokens, followed by decoding with the TiTok-S-128 decoder."
        },
        {
            "title": "E ADDITIONAL RESULTS",
            "content": "E.1 TEXT8 E.1.1 EFFECT OF APPROXIMATION ERRORS IN DENOISER AND PLANNER We conducted experiments to measure the effect of approximation errors in denoiser and planner on the generation quality. Results are summarized in Figs. 4 to 6. E.1.2 ABLATION OF CHANGES INTRODUCED IN DDPD SAMPLER We conducted controlled experiment to measure the individual effect of the changes we introduced to the sampling process. Results are summarized in Fig. E.1.3 MODEL LOG-LIKELIHOODS ON TEST DATA Following ELBO terms derived in Appendix C.1, we calculate them for three different design choices: single uniform diffusion neural network, but decomposed into planner and denoiser. Separate planner network and uniform diffusion denoiser network Separate planner network and mask diffusion denoiser network In Table 4, we evaluate the ELBO terms for three methods both trained for 750k iterations (near optimality). We observe that the mask diffusoin denoiser has better denonising performance even with mask approximation error introduced in the step of Proposition 3.5. In Table 5, We also observe"
        },
        {
            "title": "Preprint",
            "content": "Figure 4: Comparing DDPD sampling under imperfect learning: 1) single uniform diffusion model as planner + denoiser v.s. 2) separately trained planner + mask denoiser. The single uniform diffusion model converge slower in training and using DDPD sampler results in collapse in sample entropy. Using separate networks for planner and denoiser achieves results more close to SOTA methods in terms of quality v.s. diversity. Figure 5: Left: Denoiser checkpoints at 450k v.s. 750k iterations. Right: Denoiser checkpoints at 150k, 300k, 450k, 600k, 750k iterations. DDPD is able to use an imperfect denoiser to achieve the same performance as the best possible. mask diffusion denoiser performs better than uniform diffusion denoiser in terms the denoising log-likelihood. E.2 OPENWEBTEXT In Figs. 8 and 9, we measure generative perplexity of unconditional samples from GPT-2small, GPT-2-medium, SEDD-small, SEDD-medium, DDPD-Small: Planner-small + SEDDsmall-denoiser, DDPD-Medium: Planner-small + SEDD-small-denoiser. We also tested using sigmoid(logit_if_noise) and softmax(logit_if_noise) for planning. The difference is not as significant as in the text8 case. Using softmax(logit_if_noise) slightly increases entropy at the"
        },
        {
            "title": "Preprint",
            "content": "Figure 6: More ablation studies on pairing an imperfect denoiser with an imperfect planner. Figure 7: Ablation on introduced changes to discrete diffusion. A: Original Gillespie sampling. B: Timeadjustment based on the planner, continue sample until maximum number of steps is reached. C: Use softmax(logit_if_noise) instead of sigmoid(logit_if_noise) to pick which dimension to denoise next. The softmax trick makes the planning slightly more greedy than the original planning probability."
        },
        {
            "title": "Preprint",
            "content": "Table 4: ELBO terms computed on the test set of text8 in bits-per-character (BPC) with fully trained models. Denoising likelihood only evaluates the probability of correctly denoising, for Planer + Mask Diffusion Denoiser, mask is first sampled according to the planner. Method"
        },
        {
            "title": "Uniform Diffusion",
            "content": "Planner + Uniform Diffusion Denoiser Planner + Mask Diffusion Denoiser (given correct mask for denoising) Rate Matching (BPC) Transitioning (BPC) Combined (BPC) 0.0131 0.0176 2.252 2.284 2.265 2. 0.0176 2.226 2.302 Planner + Mask Diffusion Denoiser (use planner-predicted mask for denoising) 0. 2.605 2.623 Table 5: Denoising performance in bits-per-character (BPC). Mask Denoiser v.s. Uniform Diffusion Denoiser. Note that those are not entirely comparable as ELBO terms for uniform diffusion and mask diffusion are different. Method Denoising (BPC) Denoising Accuracy at αt = 0.85 Uniform Diffusion Denoiser Mask Diffusion Denoiser 2.063 1.367 92.2% 96.8% Table 6: ELBO terms computed on the test set of text8 in bits-per-character (BPC) with imperfect models trained at 20k iterations. Method Uniform Diffusion Planner + Mask Diffusion Denoiser (given correct mask for denoising) Planner + Mask Diffusion Denoiser (use planner-predicted mask for denoising) Transitioning (BPC) Combined (BPC) 3.060 2.854 3.166 3.076 2. 3.155 expense of perplexity. In Fig. 10, we find that DDPD using Planner-Small and SEDD-Denoiser-Small outperforms simply scaling up denoiser to SEDD-Medium. E.3 IMAGENET 256 256 We study the effect of planned denoising with an increased number of refinement steps in Table 9. The FID first increases and then converges. The inception score also improves with increased refinement steps and then converges. From the visualized samples, we can see that plan-and-denoise sampling is very effective at fixing errors without losing its original content."
        },
        {
            "title": "Preprint",
            "content": "Figure 8: Using softmax(logit_if_noise) for planning. Generative perplexity evaluated with GPT-2 Large (GPT-2-L) and GPT-J: SEDD v.s. DDPD using the same denoiser. Figure 9: Using sigmoid(logit_if_noise) for planning. Generative perplexity evaluated with GPT-2 Large (GPT-2-L) and GPT-J: SEDD v.s. DDPD using the same denoiser."
        },
        {
            "title": "Preprint",
            "content": "Figure 10: DDPD SEDD-small denoiser (90M) + Planner-small (90M) v.s. SEDD medium denoiser (320M) v.s. GPT-2-Medium (355M). DDPD with smaller (less perfect) denoiser achieve better performance than simply using larger (better) denoiser. Table 7: Inception Scores () on ImageNet 256 256. MaskD refers to mask diffusion. The denoiser and parallel sampling schedule are kept the same as [45], without classifier-free guidance. No Logit Annealing Logit temp 0.6 Logit temp 1.0 0.0 Steps MaskD MaskGIT DDPD MaskD MaskGIT DDPD MaskD MaskGIT DDPD 8 16 32 64 128 33.56 39.36 43.30 45.06 45.56 199.83 248.88 266.17 274.56 276.45 149.98 149.28 178.17 179.85 169.49 200.33 160.74 206.06 152.61 210.27 271.73 281.73 281.36 281.14 278.88 201.67 157.19 173.48 164.01 156.22 170.73 146.27 171.62 138.55 142. 249.86 263.47 268.88 269.45 272.73 213.03 185.25 158.14 145.95 137.19 Table 8: ImageNet 256 256 generation results Method FID Inception Score Model size # tokens codebook Taming-VQGAN [12] RQ-VAE [23] MaskGIT-VQGAN [8] ViT-VQGAN [43] MAGVIT-v2 [44] 1D-tokenizer [45] (annealing tricks) DDPD-1D-tokenizer (w/o annealing tricks) 15.78 8.71 6.18 4.17 3.65 4.61 4.63 78.3 119.0 182.1 175.1 200.5 166.7 176.28 1.4B 1.4B 177M 1.7B 307M 287M 287M + 287M 256 256 256 1024 2048 128 128 1024 16384 1024 8192 262144 4096 4096 E.4 NOISE ESTIMATION ERROR USING INDEPENDENT NOISE OUTPUT pθ(zd xt) We tested the assumption made in utilizing pretrained mask diffusion denoiser by sampling joint noise latent variables using independent marginal prediction from transformer for p(ztxt, zd = ) (cid:81) xt) in Table 10. We observe that the assumption holds almost perfectly in language modeling such as OpenWebText. On character modeling task text8, the assumption also d=d pθ(zd"
        },
        {
            "title": "Preprint",
            "content": "(a) DDPD 16 + 16 steps (b) DDPD 16 + 32 steps Figure 11: DDPD No Annealing, increasing number of refinement steps. The added refinement steps act as touch-up to improve the aesthetic quality without losing its original content. Table 9: FID Scores on ImageNet 256 256. Increasing the number of refinement steps. Refinement Steps FID Inception Score FID Inception Score Base steps = 8 Base steps = 16 8 16 32 5.12 4.92 4.93 4.94 178.17 187.59 192.93 192.99 5.12 4.75 4.63 4.71 161.17 169.49 176.28 176.22 holds most of the time, especially near the end of generation, but it is more complicated than word tokens due to much smaller vocabulary. This is also discovered in Table 4 where we observe the"
        },
        {
            "title": "Preprint",
            "content": "two-step sampling introduces approximation errors and hence makes the log-likelihood for denoising lower. Table 10: Accuracy on Mask Prediction for text8 and OpenWebText at fixed times. Mask accuracy measures if the independent sampling matches the joint noise variable values. Almost deterministic measures the assumption p(z = ) 1. We set the threshold to be logit.abs() > 3.0. xt, zd Fixed Time = 1 0 Mask Accuracy If Deterministic Mask Accuracy If Deterministic OpenWebText text8 (Data) 1.0 0.95 0.8 0.6 0.4 0.2 0.05 (Noise) 0.0 0.9988 0.9915 0.9623 0.8784 0.7416 0.7402 0.8878 0.9465 0.9975 0.9864 0.9238 0.6789 0.2261 0.2125 0.4800 0.5974 0.9999 0.9985 0.9943 0.9847 0.9679 0.9476 0.9599 0.9975 0.9997 0.9960 0.9851 0.9585 0.9100 0.8466 0.8817 0."
        },
        {
            "title": "F GENERATION EXAMPLES",
            "content": "F.1 GENERATED SAMPLES FROM MODELS TRAINED ON TEXT8 We compare samples between DFM and DDPD. For DDPD, we include samples from three models: 1) DDPD-DFM-Uni: planner and denoiser from single uniform diffusion denoiser model pθ 1xt) using Eq. (10) and Eq. (11); 2) DDPD-UniD: planner network p(zd xt) and uniform diffusion denoiser network p1t(xd xt) and mask diffusion denoiser network p1t(xd = ); 3) DDPD-MaskD: planner network p(zd 1xt, zd 1t(xd = ). 1xt, zd Samples from DFM, η = 15.0, Temp 0.8: are being damaged downtown plus the roads that are historical image map roads roads through hong kong shin te kwun mun avenue tansua tai tonlin gouhan and mengtusam there are several main freeways at the same station in the hong kong through caches on the ble everything basil mark to one nine two nine murmour about mirrored action making me worth one nine three nine lecture bird man one nine three nine the voice of law one nine three nine everything revived one nine three nine people with fears one nine fou eight one nine nine two stemming from people disaster one nine nine zero one nine nine five author john chemerzi wakis pbs troupe witnessing impact report one nine eight one jone bethy hopkins place wiley and jackson campaign begins one nine eight eigh Samples from DFM 2, η = 15.0, Temp 0.8: ero dinidol three one zero five two four three acritrine zero six zero eight four eight zero zero two three acetic acid one zero one seven not aspirin in vinnol two three nine hyproxyphenol zerolin references mda two virginia department of public saf he often shared at least some of these suggestions the priesthood of all the people of sparta hemischeres your father god and lord bound him among the priesthood of the lord with such interference preaching the probes of tribute and cannot believe they in etc time relief belongs to the preparation of funeo the time silenium and platarin the same rolled taste preparation by cooking wine from the gum is sped back the wine that is produced per pell concentration is nine two the taste is either rosin brac or"
        },
        {
            "title": "Preprint",
            "content": "1xt), Temp 0.8: Samples from DDPD, Planner + Denoiser decomposed from single uniform diffusion denoiser model p(xd dickey morris sam morris scott del man sam del man sam del del man brenda del simon simon fred rogers gregg dickey david dicks marcus dusshinsky douglas dickson steven dick douglas hartman harvey dickson scott kelly hartman mike duncan daniel harvey micha prochet pink or peanut proc pinky proche pink pigmy pig proche pigmy pigmy pig bear frog hornit horna horn wagon hornita wild fish hornit wagon griffon germanic florahornit horna ostrich wild fish flora horna wild island chicken horna horn winters winter park kitchen comfort fort gorge fort hills castle bay hills lakeland fort hamilton state park the park on ground hill bay forest reed brighton park stanley innocence small park protector hillfort edgeside statue greenwood woodfort st alban st columba stree Samples from DDPD, Planner + Uniform Denoiser, Temp 0.8: reported however in one eight six nine that natural carnivore would be bad man daily utilized his newspaper the best lighting embeddings of quiner sun warm and winter and warms france illegal bubbles first said lighting with quiner is greatly import well the composition of the entire borough was to be by the boiling of free communes of columbia were once filled and defined without separate antiphers and were antiphers each of these twin princess mournings made the term death as an antipher as defin in the work that is edward damascus across the cross from the flame of my career and the king is why like others here is there great aspect die die crossing that precedence of the star die literary die an aspect of murder may contact or rescue those Samples from DDPD, Planner + Mask Denoiser, Temp 0.8: of roy despite this in the franchise he was uncredited to put on club chatterhead big morocco theater and in the winston team hockey shot out for snap five sidekick notable player don allisto mike henning puncher jack may founder of roy puncher five four lithography logoliths littoral nonfiction lilitus confusion lit little dragon littorius love eye love crawlin love utopia lolita popula prose oracle populae populae anticharia prophecy leonida popula lepheus mycenaean super super dendron carbon lover dend rrorists criminals in gold the timing expressing only insisted by the endings of them rising six to ten days population of one thousand guessing holding potential risking dangers see falling and plasticizing goodman father of the town of guam effect only"
        },
        {
            "title": "Preprint",
            "content": "F.2 GENERATED SAMPLES FROM MODELS TRAINED ON OPENWEBTEXT In general, samples from DDPD demonstrate better ability to capture word correlations, leading to greater coherence compared to those generated by SEDD. However, both methods exhibit less coherence in longer contexts when compared to samples from GPT-2 models. Samples from DDPD-Planner-Small-Denoiser-Small, 4096 steps: tornadoes Space.com Read more:The disarray has reached an end, dragging the US political system into its turbulent period. Today looks to be the day of reckoning for Washington. Facebook Twitter Pinterest Men and women make an attempt to enter the Capitol building, which is part of the US State Department. Photograph: Nicky Boyce/AFP/Getty Images. While there has been some infighting of late, the sometimes-jaded new US Congress has also been shying from the usual trappings of parliamentary checks and balances, particularly on the appointment of secretary of state, and on immigration, as the Senate yesterday voted to vote no to bill. In the new session, Congress looks to seize the opportunity to form new government, replacing the old with new one, something that has been done in other countries. Work will start in April on new law that will change dramatically the political landscape across the country. The law was amended more than half dozen times over the two-week period, and will be announced in advance of private event hosted by Mr Obama. The law creates new legal system for states. In the US system, it treats state and local officials as the representatives of the people, with the federal government, including the president, in the process of forming the new government. Interior Senator Joe Lieberman, chairman of the so-called federal government lobby group, said it is time to come up with new government. If this is the rule of law, thats not the way weve done it. We have to think about that. We believe the result will be good for the people and the country, he said. In the past, Mr Durbin has been vocal in his desire to form new government. Firstly, he wanted the bill to take effect in 2008, then he vetoed the amendment in 2010. He was more outspoken in his desire to legislate further, just week before the new session, by arguing that lawmakers who failed to vote on the amendments to the law should have failed to attempt to form new government. French foreign minister, Laurent Fabius said: we look forward to election of the new president and taking on the important task of forming new government, Fabius said. The announcement of the presidents resignation from office, is seen as sign of the election of new secretary of state. Not vote of confidence. vote of confidence and it will happen,\" he added. Earlier, Irish Labour Party leader Mairnín ONaughin-Sullivan said the countrys attention was being diverted from immigration, saying: is only short period of time, and we have to come up with new government, especially in the course of the new session. She added: government in different way. And we need to work on making amendments to the law so the US government will not form new government and not raise the specter of new US government. Facebook Twitter Pinterest Concerns about immigration are rising in much of the country. Photograph: Politics and constitutional issues Ewen-Scott Brown, head of the US government under the Obama White House, had successfully pushed for legislation to create new legal system for states rather than the Republican-led federal government, 10 years ago. In the biggest political move in American history, Ewen-Scott Brown has described the issue as constitutional issue. \"I have said that the way it relates to secretary of state position is no different than the Secretary of State position. It has nothing to do with the Constitution, she has said. Deputy members of the administration, which included International Trade Secretary Michael Froman, and Justice Secretary Carole Wray, formed new congressional task force. But by the time at which Mr Obama was elected the US president, public opinion had tumbled in the opposite direction. He had introduced new immigration bill and became the first president ever to get the immigration bill passed in the US Senate, but the House refused to act and he resigned from the Senate in December 2011. Health care \"I think it is important for the president and the US government, to not form new do think this issue is not on our agenda at all. It We welcome the formation of new government and Marjorie Nougou/AFP/Getty Images. Mr Browns position as leader of the nations Republican Party has expanded under the Obama administration. He was one of only three members of the House to pass the health care reform bill in 2009-10 and took break from the Senate as head of the Department of Health and Human Services."
        },
        {
            "title": "Preprint",
            "content": "Samples from SEDD-Small, 4096 steps: to change, the second-in-one Cabinet minister, political correspondent Oliver North, told CNN on Sunday. This was the first such rally of the party controls campaign. Time to change course is now. new politics will begin in 2020. Even party leaders and prominent Labour figures are alert to this shift, including Boris Johnson who has left the party for the first time since rival candidates nomination for president of the Republican National Committee, pledging in his Saturday speech that he had to work for the end of Thatchers reign. The media, meanwhile, had predicted that former minister Margaret Thatcher would not vote for her and backed her in the current right-handed coalition with Mr Miliband and attacked Labour leaders as without party that could return them to the prime minister and at odds against across-the-ground austerity, which she personally has never said he wanted. Read more from CNN on Twitter In the absence of the party, Johnson has warned: Weve kind of destroyed our country if we dont talk about our future, so David Milibands attempts to replace our leader are selecting those who support Labour, who need to match voter turnout and are real threat that could have that in 2020.\" Corbyns say for Corbyn As Jeremy Corbyn addressed an exile party convention in West End, London on Saturday, Corbyn presided over the Tories in London who are in recent days leading the polls overall in the party. Corbyn, who used the black vote in his pool of 10 MPs to win theelections, also stood for Corbyn at packed rally outside the Democratic Central party. After London conference on the change in Labours management of the Labour Party, Mr Corbyn said earlier this month that the greatest person ever to decide Sir Jeremys former Labour leadership, the first woman to decide her leadership in more than 20 years, and called Jeremy Corbyn at that conference in 2012 remarkable individual. Mr Corbyn said in Westminster: condemn the hate to your name and cited him as being tough on racists, who the Liberal Democrats say are just white men shifting from white middle men, who already put 60 per cent and have stood down since the general election earlier this year. Mr: \"I condemn the hate to your name on the unWhiteList of #LabourCan. Yvette Caron... no one is racist\" https://t.co/JkRs5ICHbA8 Nicola Davidson (@GLGLa) September 14, 2017 David Cameron, the Corbyn leadership candidate, said having left the Carkey campaign opposed the real threat of racism. Im fan of this movement, he said after the press release, describing it as hed like to see in Manchester, which is Britains third biggest city. Weve got it. Get you ballot paper, and it will be man, with no woman, with no women. It will be you, so step up and vote for it for the first time. Mr Corbyn appears to have been saying the Tories should stop being down against discrimination and The Greens should go against it. Locations for Blue Brown memorial Earlier this week, the Conservative parliamentary party released another statement about protests for the death of Mrs Brown, young woman who carried opposition to free-gout programme government into the black market. Brown and tens of thousands of pensioners walked to the streets after her death. The great political path forward over the past 60 years has come without Labour leaving Blue Brown, and including any ones involved in that distinct occasion, it said in statement. Meanwhile, the Tories said in statement shem not left of politics and strong in my convictions. She stood for Jeremy Corbyn during Saturdays campaign: Democrats, in the last decade have been pushing their agenda and been trying to right the say they are complicit in sexism and racial inequality. The rest of the Democrats and Republicans have been playing similar roles in Americas history for decades. Im optimistic that beacon for liberalism can be brought back into this country. But seeing Mr Corbyn as father figure on the back of his election also moves her away from the partys platform as the dominant party in politics. Ms Corbyn has spent time across the country over the past 16 years and have seen public events as means by which she and Corbyn have won them at one point or another. Hillary, in her two years as Labours founder and parliamentary frontrunner, named race not factor in her election victories, but core legacy"
        },
        {
            "title": "Preprint",
            "content": "Samples from GPT-2-Small, 1024 steps: She wants Charlie to be safe, that he and his mother are safe, Because he knew how dangerous it was to get there. The two had been walking home, and when he came to, he saw two people standing outside the tree, each with large knife and rifle. The murderer stabbed them in the neck with bladed weapon, and the two of them both died. Why should look at movie when could just see the actual movie? Ill give you clue. The visual effects supervisor at the time, Donnie McCarthy, was not particularly interested in the movies, and decided that we should just get along with these actors, which is what this story follows. When Charlie, the first person Charlie can actually meet, is brought up to him by his mother, he has to help her and reunite her with her children. Now, she isnt about to be in home, but she wants him to be reunited with her. and that he doesnt need to go through so much trouble and regret for him and his mother. Its classic start to this story, so Im not going to lie. Its the complete opposite of what was made out there. But when Charlie was brought up, the whole story about how to build his own life and stay in the state of Kentucky, he didnt need to do that. He needed to make it up to his family. In that way, hes made everything right. That is, for him and his family. It all started with what first described in The Birth of Nation, when high school student named Emil Fowles tells him, \"You cant be that way.\" Hes no longer considered teenager by the state, and he lives in Louisville, Kentucky. He meets his father and fathers parents, and he helps himself to his bag and goes to the Best Buy. He keeps changing diapers. He helps his uncle, who doesnt have money, or himself, who doesnt have credit card. He gives up cigarettes, and he starts to tell his dad about that, about wanting to make his own choices, that hes finally in better place. He starts this story with how Emil told him to help himself. and now he can do his own thing, whether that means house, car, school, or even helping his grandmother. country. He has to, he says, to get out of here. The rest of the story is very much about woman whos trying to help herself. In this story, Emil is really going to his mother. Thats something he doesnt want to do, but its not what were seeing in the movie. Its more of his time with her, with his father, and he tries to get out of here, but at the end of the movie he tells her that hes going to make big deal out of the fact that shes going to miss him. Its kind of adaptation of the \"Selfish Girl\" from the original series. You dont get to see all the backstory and how these characters were raised, but the emotional moment is in the very end where Emil is helping his mother and now hes in country where the government is corrupt, and his mothers toiling away, trying to make things better for her children. To me, that is kind of my favorite part of the film, because its almost like, \"What if my mom is leaving me and Im going to have to fight with her every day?\" Its very rare, because have been around, but like being in country where have to fight for my kids. similar to the movie that was involved with in The Birth of Nation. was watching The Birth of Nation in London back in the 60s, and Im not sure if it was actually true sequel or remake, because cant say, \"Were not doing this because this is what we want to do.\" Thats what liked about that movie, because knew that this world would always be different from any of the other movies in that time, and the people who were created in that world. mean, thats the thing about movies like The Birth of Nation, and thought, \"Theres something about it that really makes it, and that, at the same time, really pushes me to think about what can do in this world and how can make world of my own.\" Its perfect illustration of that. He then tells his mother, who is some time in the past, that hes leaving his That was one of my most favorite aspects of the movie. The worlds aware of Emils freedom, And its very very saw that movie lot, and knew that this was going to be one of the most beautiful movies of all time. Its"
        },
        {
            "title": "Preprint",
            "content": "Samples from DDPD-Planner-Small-Denoiser-Medium, 4096 steps: SAUL LOEB, AFP/Getty Images) The app also allows you to select which channels to watch every time you open the app so you can watch those channels on Apple TV (iPhone and iPad only) or on your phone. For example, HBO Go, Showtime, AMC and other channels dont have to be on Apple TV because the Roku app can be paired with Apple TV to watch them, according to Scott Robinson, vice president of business development for PlayStation Network, Inc. 7. The Appflix With this app, you can connect your TV remote to your phone and watch new shows and movies that are being added to your TV collection, according to Amazon. The Appflix app lets you watch those channels on your phone without using the remote. It will work well with the new Apple TV remote when its released by Apple. Roku This was supposed to be companion app for DirecTV.TV, but its now being used by Roku. You cant set up your Roku as DVR if you have it on your set-top box. But Roku owners can use it as hub for their TV so that you have multiple channels and apps so you can look for the best content available. It also provides you with split-screen streaming feature that allows you to watch multiple channels. The app isnt connected to your TV if you have it on Apple TV, but you can use it on your Roku TV, or Chromecast, Amazon Fire or any Android device. Looking back at the apps released this week, this may just be all it takes to get some of the content from Roku on your TV.President Barack Obama speaks Thursday in Washington, accusing Moscow of undermining the alliance. (Photo11: MOSCOW German lawmaker said President Barack Obama should ask the United States to spend more money on military support and training in the region to prop up the Ukrainian government in the war against Russia. In the end, NATO will have to stop the Russian aggression in eastern and central Ukraine, according to statement from the German parliamentarian Robert Appel on Thursday from the alliances headquarters in Vilnius, Lithuania. Specifically, he said Washington needs to ask for more weapons and military assistance to fight the pro-Russia forces fighting in eastern Ukraine. That is position some NATO leaders have not been comfortable with since the U.S. has called for military help. The comments from the German lawmaker were put out in response to Obamas announcement this week of his plan to send more arms to the separatists in Ukraine and his call for the United States to join NATO. U.S. and European leaders condemned the victory of the separatists in this months elections. \"It is deeply disturbing to know that Ukraine elects leader that the U.S. appreciates and shares with the U.S. government,\" said Vice President Joe Biden. \"The president was elected on the very platform that legitimates aggression in Ukraine,\" he added. The U.N. Security Council is meeting to consider new ways to confront Russia, and Obama has urged President Vladimir Putin to pay attention to the issue. The U.S. has said the move is \"serious threat\" to the alliance. Obama said he is \"very serious about our security\" and that while the alliance is seeking help from Moscow, there are limits to that. \"If the pattern of Russian aggression continues, it places NATO, the alliance, and ultimately the security of Europe and its allies in danger,\" said the president at Thursday news conference. \"The Europeans face security crisis,\" said Secretary of State John Kerry. \"This is serious security crisis in eastern Europe.\" NATO in support of Ukraine Appel focused his statement on the \"turbulence factor,\" citing NATOs relationship with both Russia and the way in which counterinsurgency operations were waged against the Soviet Union. In addition to the support of the European Union, he said, the UN Security Council is required to act against Russia. \"Ukraine is not NATO member, and Russia as well, is not NATO member,\" he said, referring to the alliances membership under article 5 (a) of its constitution. In February 2014, the Ukrainian government declared itself to be member of the European Union, making it NATO member. Tipping away at the NATO alliance? \"You can raise the threat level with Russia,\" retired Adm. Mark Green, the top commander of the American forces in Europe, said on CBSs \"This Week.\" He said that if Russia ousted President Viktor Yanukovychs newly elected government, it would have to be supported by other members of the alliance \"through the use of force,\" in such \"persistent way.\" Green said the actions of the separatists"
        },
        {
            "title": "Preprint",
            "content": "Samples from SEDD-Medium, 4096 steps: was figuring them out later. said. To me, thats something that is going to happen to any of us. You never know who is more You know, if you get two guys off and prepared. If you give, the guys are up and out of there. theyre frustrated because they feel good, dont think its going to make the team any better. Im not comfortable, and should be, Im competitive. Im just blocking every shot the way do everything do. And that he plans to get even more aggressive out there. With each different knock to my body that happens against somebody in Tier 1, or better, Im going out there and pushing myself, Jordie said. appreciate that, and the better get, the greater an advantage it will make me feel because the schedule is better, so well see what happens. Since the injury finally more than year ago, you can be sure he has worked slowly to get better, but he has gone through his upsides as well. Initially they were pretty brutal before they happened, then they were pretty painful, McKenzie said. But it wasnt so bad. He knows how to improve and get tougher, ORegan added. Hes still long way to get there, but dont think theres anything hes done before. This is probably the time that worry hes going to have an issue like this from the off-season. \"Were going to go to another one-on-one contact test on his body to see what happens thats going to be the only way that we can trust, ORegan said. As of now, McKenzie is still trying to determine how he is going to play his best. Ill put myself to the tests, but everyone has the same struggles, and Im really just bad with losing, he said, with laugh. Thats when youre dealing with it you cant do anything else. Thats how Im kind of living. do need to deal with that, but its always done it for me. If it wasnt hard, if wasnt understand, wouldnt be able to. The way am now, can walk six feet. Im kind of thinking thats all bad, but dont know. understand thats taking so much of your time and your trust. Im not that kind of guy, and thats why think Im not as involved in camp as need to still be. Im damn hungry and Im going out to work every night. Thats why dont plan on staying home like normally would. McKenzie said having the kind of type of recovery that he really wants was worth the scare he had when he received from the start workout the morning the Morys started the trip. \"It kind of makes you sick thinking that,\" he said. \"That was an intense workout. When youre dealing with that you cant do anything.\" McKenzie said he underwent more than massage and he continues to play role in his body every single day. most of his time behind them from now on. All told, McKenzie has full season off his injury to be recovered and back into full-time hockey. He still knows he is far from unstoppable. \"Its frustrating but still am,\" McKenzie said. \"I know this has to give, and cant give this up right now.\" But even then, McKenzie is at loss for words, or really any words at all. In the dreamy way, you know, deal with that, he said. always keep that in mind. always have. But when it comes down to it just know that Im the best at what do when work through it. just work harder and get better every day.You If the setup there was not successful for him, he knows that he wont be getting the Im not Mr. The Ugly. You know?"
        },
        {
            "title": "Preprint",
            "content": "Samples from GPT-2-Medium, 1024 steps: \"As he is not defendant, we will not ask for any charges or plea.\" senior Russian prosecutor, summoned by President Vladimir Putin for questioning about his alleged links to the controversial bitcoin exchange Mt. Gox, has revealed he used the ill-gotten gains from the alleged theft of some $230m in the troubled digital currency to buy holiday home in California. Nassim Mikheev said he spent his weekend in California to buy $60m three-bedroom house with 6,900 sq ft kitchen, 600sq ft living room and 18ft ceilings and walls on luxury property in Malibu. On Wednesday, the judge presiding over Mikheevs preliminary hearing asked him about his finances, telling him he had invested \"roughly 200m roubles (179m) in Bitcoin,\" using the digital currency to purchase residence. \"I would like to make the remarks that when spent money in Bitcoin and put it into my property, the property value increased tenfold,\" Mikheev replied. The price increase, he said, came from Bitcoins used to buy the home, with one-year buyers contract for the property saying the currency had doubled in value. Mikheevs lawyer said he intended to mount defence of his clients conduct. \"As we have already explained, we expect that even if this amount was mistake, it was not justified,\" said lawyer Anatoly Semenov. Mikheev is currently under house arrest. Russias Federal Anti-Money Laundering Service (Banske) has named him and has requested access to all bank accounts in Russia and Kazakhstan, which cover at least half billion dollars. Mikheev said he first set up Mt Gox, controversial bitcoin exchange, in 2009. There, the chief operating officer, Sergey Karpeles, said he bought about one million bitcoins and used the money to pay people for work they did for him and other members of the Bitcoin community. After his father, Mikhail, the first owner of the Mt Gox company, sold the business to second company, he became disillusioned and had Mt Gox hacked. At least $230m was allegedly stolen. Karpeles eventually left the company and told media that he would be \"really happy to get it back, but in the meantime cant take it, so what do do.\" His father then moved to Luxembourg, where Mikheev now lives. believe he stole the money through hacking, and the company has since been under siege by authorities. Citing the US criminal case against Mt Gox founder Mark Karpeles, Semenov said that \"in this case it would be necessary to name and shame the cybercriminals who in exchange for stolen bitcoins gave them their services to discredit this investigation, of which the Mt. Gox CEO is key figure.\" He added: questioning, this decision would have been completely based on the trust that this person feels in the prosecutors in general.\" Mikheev said he would like to start new company or take up another career, but is concerned he will not be able to remain in Kazakhstan. \"Ive been lucky to live here for year, and want to continue this condition in the future. But my life is not going to be as easy as thought,\" he said. The 64-year-olds lawyer had urged the judge to immediately imprison him, adding that there are no limits to the amount of time businessman can be jailed for acting in \"dirty manner.\" Judge Ramy Azizov said his authority was constrained by an \"expedited\" schedule of prosecution against alleged bank thieves. Azizov added that decision on the \"witness role\" could take some time. But Mikheev stressed that he would not be intimidated by authorities, suggesting his ruling may help prevent others from falling victim to the same actions. \"Ive heard of people who did things after acquiring the wrong identity documents, using aliases or in certain cases turning the wrong corner and, even if they used the correct documents, this cant mean that Ive acted with gross negligence.\" In response to Mikheevs remarks, spokesman for the Mt Gox chief, Mark Karpeles, told the Russian press: We dont comment on personal matters.\" \"If at the time of one of his actions the prosecutor decided to introduce them for \"There are hundreds of people on our company payroll, some of them ex-employees. The case remains under investigation by the German tax authority. group of investigators now The case is \"totally complex and complicated,\" said Ross Mrazoff, head of compliance at KrebsOnSecurity, which monitors money-laundering cases. \"It is very important case, and the decision was taken to speed up this investigation in F.3 GENERATED SAMPLES FROM MODELS TRAINED ON IMAGENET 256 256 In Figs. 12 to 14, we visualize samples of DDPD, Mask Diffusion and MaskGIT. Without logit temperature annealing, Mask Diffusion captures diversity, but the sample quality suffers due to imperfections in the denoiser. On the other hand, MaskGITs confidence-based strategy significantly improves sample quality, but at the cost of reduced diversity. DDPD trades off diversity v.s. quality naturally without the need for any annealing or confidence-based tricks."
        },
        {
            "title": "G REPRODUCIBILITY STATEMENT",
            "content": "To facilitate reproducibility, we provide comprehensive details of our method in the main paper and Appendix D. This includes the model designs, hyper-parameters in training, sampling schemes and evaluation protocols for all the experiments. We further provide PyTorch pseudocode for the proposed adaptive Gillespie sampling algorithm."
        },
        {
            "title": "H ETHICS STATEMENT",
            "content": "This work raises ethical considerations common to deep generative models. While offering potential benefits such as generating high-quality text/image contents, these models can also be misused for malicious purposes like creating deepfakes or generating spam and misinformation. Mitigating these risks requires further research into guardrails for reducing harmful contents and collaboration with socio-technical experts. Furthermore, the substantial resource costs associated with training and deploying deep generative models, including energy and water consumption, present environmental concerns. This work is able save cost on training by reusing pretrained denoisers and just focusing on training different planner models for slightly different tasks. At inference time, our newly proposed sampler is able to generate at better quality as compared to existing methods that use same amount of compute."
        },
        {
            "title": "Preprint",
            "content": "(a) DDPD: No Annealing (b) Mask Diffusion: No Annealing (c) MaskGIT: No Annealing Figure 12: DDPD v.s. Mask Diffusion v.s. MaskGIT, No Logit Annealing"
        },
        {
            "title": "Preprint",
            "content": "(a) DDPD: Logit Annealing = 0.6 (b) Mask Diffusion: Logit Annealing = 0.6 (c) MaskGIT: No Logit Annealing 1.0 0.0 Figure 13: DDPD v.s. Mask Diffusion v.s. MaskGIT, Logit Annealing = 0."
        },
        {
            "title": "Preprint",
            "content": "(a) DDPD: Logit Annealing 1.0 0.0 (b) Mask Diffusion: Logit Annealing 1.0 0.0 (c) MaskGIT: Logit Annealing 1.0 0.0 Figure 14: DDPD v.s. Mask Diffusion v.s. MaskGIT, Logit Annealing 1.0 0."
        },
        {
            "title": "Preprint",
            "content": "(a) DDPD 32 steps (b) Mask Diffusion 32 steps (c) MaskGIT 32 steps Figure 15: DDPD v.s. Mask Diffusion v.s. MaskGIT, No Logit Annealing"
        },
        {
            "title": "Preprint",
            "content": "(a) DDPD 32 steps (b) Mask Diffusion 32 steps (c) MaskGIT 32 steps Figure 16: DDPD v.s. Mask Diffusion v.s. MaskGIT, Logit Annealing 1.0 0."
        },
        {
            "title": "Preprint",
            "content": "(a) DDPD 16 + 16 steps (b) DDPD 16 + 32 steps Figure 17: DDPD No Annealing, increasing number of refinement steps. The added refinement steps act as touch-up to improve the aesthetic quality without losing its original content."
        }
    ],
    "affiliations": [
        "Massachusetts Institute of Technology",
        "NVIDIA Research",
        "University of Oxford"
    ]
}