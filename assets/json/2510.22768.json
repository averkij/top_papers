{
    "paper_title": "MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion",
    "authors": [
        "Haoyi Qiu",
        "Yilun Zhou",
        "Pranav Narayanan Venkit",
        "Kung-Hsiang Huang",
        "Jiaxin Zhang",
        "Nanyun Peng",
        "Chien-Sheng Wu"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "As Large Vision-Language Models (LVLMs) are increasingly deployed in domains such as shopping, health, and news, they are exposed to pervasive persuasive content. A critical question is how these models function as persuadees-how and why they can be influenced by persuasive multimodal inputs. Understanding both their susceptibility to persuasion and the effectiveness of different persuasive strategies is crucial, as overly persuadable models may adopt misleading beliefs, override user preferences, or generate unethical or unsafe outputs when exposed to manipulative messages. We introduce MMPersuade, a unified framework for systematically studying multimodal persuasion dynamics in LVLMs. MMPersuade contributes (i) a comprehensive multimodal dataset that pairs images and videos with established persuasion principles across commercial, subjective and behavioral, and adversarial contexts, and (ii) an evaluation framework that quantifies both persuasion effectiveness and model susceptibility via third-party agreement scoring and self-estimated token probabilities on conversation histories. Our study of six leading LVLMs as persuadees yields three key insights: (i) multimodal inputs substantially increase persuasion effectiveness-and model susceptibility-compared to text alone, especially in misinformation scenarios; (ii) stated prior preferences decrease susceptibility, yet multimodal information maintains its persuasive advantage; and (iii) different strategies vary in effectiveness across contexts, with reciprocity being most potent in commercial and subjective contexts, and credibility and logic prevailing in adversarial contexts. By jointly analyzing persuasion effectiveness and susceptibility, MMPersuade provides a principled foundation for developing models that are robust, preference-consistent, and ethically aligned when engaging with persuasive multimodal content."
        },
        {
            "title": "Start",
            "content": "MMPERSUADE: DATASET AND EVALUATION FRAMEWORK FOR MULTIMODAL PERSUASION Haoyi Qiu1 Yilun Zhou2 Pranav Narayanan Venkit2 Kung-Hsiang Huang2 Jiaxin Zhang2 1University of California, Los Angeles haoyiqiu@cs.ucla.edu 2Salesforce AI Research Chien-Sheng Wu2 Nanyun Peng"
        },
        {
            "title": "ABSTRACT",
            "content": "As Large VisionLanguage Models (LVLMs) are increasingly deployed in domains such as shopping, health, and news, they are exposed to pervasive persuasive content. critical question is how these models function as persuadeeshow and why they can be influenced by persuasive multimodal inputs. Understanding both their susceptibility to persuasion and the effectiveness of different persuasive strategies is crucial, as overly persuadable models may adopt misleading beliefs, override user preferences, or generate unethical or unsafe outputs when exposed to manipulative messages. We introduce MMPERSUADE, unified framework for systematically studying multimodal persuasion dynamics in LVLMs. MMPERSUADE contributes (i) comprehensive multimodal dataset that pairs images and videos with established persuasion principles across commercial, subjective and behavioral, and adversarial contexts, and (ii) an evaluation framework that quantifies both persuasion effectiveness and model susceptibility via third-party agreement scoring and self-estimated token probabilities on conversation histories. Our study of six leading LVLMs as persuadees yields three key insights: (i) multimodal inputs substantially increase persuasion effectivenessand model susceptibilitycompared to text alone, especially in misinformation scenarios; (ii) stated prior preferences decrease susceptibility, yet multimodal information maintains its persuasive advantage; and (iii) different strategies vary in effectiveness across contexts, with reciprocity being most potent in commercial and subjective contexts, and credibility and logic prevailing in adversarial contexts. By jointly analyzing persuasion effectiveness and susceptibility, MMPERSUADE provides principled foundation for developing models that are robust, preference-consistent, and ethically aligned when engaging with persuasive multimodal content. 5 2 0 2 6 2 ] . [ 1 8 6 7 2 2 . 0 1 5 2 : r Figure 1: Unified framework for studying multimodal persuasion. (Left) Persuasion contexts are organized into three contexts, with theory-grounded strategies. (Center) dataset and dialogue setup where persuader leverages the multimodal persuasion strategies dataset to compose multimodal persuasive messages and influence an LVLM persuadees stance in multi-turn conversations, with shaded backgrounds indicating dataset-driven construction (left) versus LVLMs acting on behalf of human users (right). (Right) Persuasion effectiveness is evaluated by using two complementary stance evaluation methods, with metrics such as persuasion discounted cumulative gain measured across three dimensions: modality, stubbornness/preference, and strategy. Work done during internship at Salesforce AI Research. 1 RQ1: Susceptibility Across Modalities (4.1): How susceptible are LVLMs to human-grounded persuasive strategies when expressed through different modalities? Answer: Multimodal inputs consistently increase persuasion effectiveness compared to text-only, with captions providing partial gains but full multimodal input achieving the strongest effects. RQ2: Stubbornness Effect (4.2): How does susceptibility change when LVLMs are instructed to exhibit varying degrees of stubbornness or preference? Answer: Stronger prior preferences reduce persuasion across all models. However, multimodal input cushions this decline, preserving higher conviction rates and PDCG scores. RQ3: Persuasion Strategy Effect (4.3): Are certain persuasion strategies consistently more persuasive than others across different LVLMs? Answer: Reciprocity and consistency dominate Commercial and Subjective persuasion, whereas credibility and logic prevail in Adversarial persuasion. Table 1: Research questions on LVLM susceptibility to multimodal persuasion and summary answers."
        },
        {
            "title": "INTRODUCTION",
            "content": "Persuasion is pervasive force in human communication, shaping beliefs, attitudes, and decisions across public health, commerce, and politics (Wang et al., 2019; Tian et al., 2020; Samad et al., 2022; Jin et al., 2023; 2024; Xu et al., 2024; Singh et al., 2024; Bozdag et al., 2025a). Persuasion can serve beneficial purposes (e.g., promoting health or education) but can also be weaponized for manipulation and misinformation. As online discourse becomes increasingly multimodal, persuasive content now integrates text, images, videos, and audio to amplify its emotional and cognitive impact. However, recent works on persuasion have focused on the text modality with Large Language Models (LLMs) (Jin et al., 2024; Xu et al., 2024; Singh et al., 2024; Bozdag et al., 2025a). The behavior of Large VisionLanguage Models (LVLMs) as persuadeeshow and why they are influenced by persuasive multimodal inputsremains underexplored. LVLMs must not only comprehend multimodal messages but also demonstrate robustness in recognizing, interpreting, and resisting harmful persuasive attempts. As these models are increasingly deployed in high-stakes, visually grounded domains such as shopping, healthcare, and news, understanding their susceptibility to persuasion becomes essential. Overly persuadable models risk internalizing misinformation, overriding user preferences, or generating unsafe outputs when exposed to manipulative multimodal cues. In this paper, we aim to answer the following question: Can LVLMs understand, interpret, and appropriately resist human-grounded persuasive tactics that span modalities? We introduce unified framework MMPERSUADE for studying multimodal persuasion in LVLMs (as shown in Figure 1). Our framework consists of three main components: (i) large-scale multimodal dataset of multi-turn persuasion conversations constructed across Commercial, Subjective/Behavioral, and Adversarial contexts, with persuasive strategies grounded in Cialdinis six principles and Aristotles rhetorical appeals (450 scenarios, 62,160 images, 4,756 videos, quality-checked by both models and humans); (ii) persuasive conversation setup where persuader agent delivers multimodal persuasive messages under three controlled conditions (text-only, text+caption to ablate visual grounding, and multimodal) to influence an LVLM persuadees stance in dialogue; and (iii) an evaluation framework that combines expressed stance and implicit belief, summarized by our persuasion discounted cumulative gain (PDCG) metric, which rewards earlier and stronger persuasion. Our analysis yields three key insights (see Table 1). First, multimodal inputs consistently boost persuasion effectiveness relative to text-only, with captions offering partial grounding but full multimodal input achieving the strongest effects (RQ1). Second, prior preferences (stubbornness) reduce persuasion across models, though multimodal cues cushion this decline, preserving higher PDCG scores (RQ2). Third, persuasion strategies differ systematically: reciprocity and consistency dominate in Commercial and Subjective persuasion, while credibilityand logic-based strategies are most effective in Adversarial settings, with multimodal warmth cues amplifying affective strategies like liking (RQ3). These analyses reveal dual pattern: multimodality consistently enhances persuasion, while its impact is further shaped by initial preferences and the choice of strategy. Together, these findings provide the first systematic exploration of multimodal persuasion in LVLMs and offer guidance for designing models that engage with persuasive content more robustly, responsibly, and safely. 2 Figure 2: Illustration of our dataset and evaluation framework. Each persuasive message appears in three settings, with required elements: textual response, image/video caption, textual description, or multimodal content. Varying the modality alters persuadee responses within the same turn, which are then evaluated using two complementary methods to capture stance shifts."
        },
        {
            "title": "2 MULTIMODAL PERSUASION DATASET",
            "content": "LVLMs extend persuasion research beyond text into multimodal settings, yet no benchmark exists for multimodal persuasion despite recent progress on text-based evaluation. To fill this gap, we construct large-scale multimodal dataset via novel generation pipeline. Our benchmark evaluates how LVLMs act as persuadees the recipients of persuasive multimodal content. We extend multi-turn text-only persuasive dialogues with systematically generated images and videos grounded in human persuasion strategies, ensuring that added modalities both enrich the interaction and amplify persuasive force, enabling deeper study of how LVLMs process real-world multimodal cues. 2.1 PERSUASION CONTEXTS CLASSIFICATION Building on prior research in persuasion (Kumar et al., 2023; Jin et al., 2024; Xu et al., 2024; Singh et al., 2024; Liu et al., 2025; Bozdag et al., 2025a) and foundational principles from communication theory (OKeefe, 2015), we construct taxonomy of persuasion contexts tailored to the study of LVLMs in the persuadee role. This taxonomy enables systematic analysis of how models interpret, process, and respond to diverse persuasive strategies. We identify three broad persuasion contexts, each characterized by the persuaders core intention and application domain: Commercial Persuasion (e.g., Sales and Advertising): The persuaders primary goal is to motivate the persuadee to take specific commercial actions, such as suggesting purchase, signing up for service, or recommending engagement with product, by employing persuasive multimodal content designed to prompt concrete decisions. Subjective and Behavioral Persuasion (e.g., Health Nudges, Political Messaging, Emotional Appeals, Cultural or Religious Appeals, Education or Pro-Social Appeals): The persuader aims to influence the internal states or behaviors of the persuadee, seeking to shape its beliefs, attitudes, or responses and guide it toward desired behavioral patterns in sensitive domains such as health, politics, crisis response, or education. Adversarial Persuasion (e.g., Misinformation and Fabricated Claims): The persuader intentionally seeks to manipulate or exploit the persuadee by presenting deceptive or misleading content, aiming to misinform, confuse, or induce harmful outputs."
        },
        {
            "title": "2.2 DATA CONSTRUCTION PIPELINE",
            "content": "We construct each multimodal persuasion instance by extending conversations from existing multiturn text-only persuasive conversations datasets through delicate six-step pipeline (Figure 6). Prompts and illustrative examples are provided in B.2: Step 1: Context Classification. Identify the persuasion context of each conversation Commercial, Subjective and Behavioral, or Adversarial Persuasion. Step 2: Strategy Mapping. Assign each persuaders persuasive message to psychology-based persuasive strategy, organized under unified taxonomy derived from Cialdinis six principles of persuasion (Cialdini, 2021) and Aristotles three rhetorical appeals (Rapp, 2002). Step 3: Multimodal Conceptual Design. Instruct GPT-4o to convert each text-based persuasive strategy into multimodal prompt, specifying (i) content type (e.g., image, video), (ii) configuration (e.g., visuals, narration), and (iii) brief text cue linking the multimodal element to the dialogue. Step 4: Prompt Refinement. Iteratively refine the initial prompts into well-structured generation prompts, emphasizing clarity, creativity, and alignment with the intended persuasive objectives. Step 5: Multimodal Content Generation. Employ state-of-the-art generative models (e.g., gpt-image, Veo3) to produce the specified multimodal content using the finalized prompts. Step 6: Content Quality Assurance. Evaluate the generated outputs through both model-based and human assessments to ensure persuasiveness, contextual appropriateness, and overall quality. Source Datasets. We construct our dataset by augmenting it with data from two high-quality, multiturn text-only persuasion dialogue datasets: DAILYPERSUASION (Jin et al., 2024) and FARM (Xu et al., 2024). The process begins with Context Classification (Step 1), ensuring broad and balanced representation across major types of persuasion. Specifically, our dataset includes: 300 dialogues from DAILYPERSUASION, evenly split between 150 Commercial Persuasion dialogues and 150 Subjective Persuasion dialogues. In addition, 150 Adversarial Persuasion dialogues from FARM. Persuasion Strategy Taxonomy. For Commercial and Subjective Persuasion, we employ Cialdinis six principles of persuasion (Cialdini, 2021): reciprocity (the urge to return favors), consistency (the drive to act in accordance with previous commitments), social validation (the tendency to adopt behaviors modeled by others), authority (the weight given to perceived expertise or status), liking (the inclination to be influenced by those we find appealing or relatable), and scarcity (the increased perceived value of limited resources). For Adversarial Persuasion, we draw on Aristotles three rhetorical appeals (Rapp, 2002): logical appeal (persuasion through facts, evidence, and rational argumentation), credibility appeal (establishing trustworthiness via credentials or reputation), and emotional appeal (eliciting specific feelings to shape attitudes and decisions). Multimodal Content Details. We construct two categories of multimodal content: (i) Image-based content includes memes, infographics, photographs, social media posts, advertising posters, and screenshots of online discussions. Each prompt is paired with five distinct images to ensure diversity; (ii) Video-based content comprises materials such as YouTube clips, short-form videos, television advertisements, political campaign ads, and news segments. For each prompt, one video is generated due to computational constraints. Detailed configurations are provided in B.2. Data Quality Assurance Details. To ensure the quality of our generated multimodal content, we employ both model-based and human evaluation protocols. (i) Model-based evaluation: GPT-4o assigns an alignment score between each generation prompt and its corresponding textimage or textvideo output on 3-point scale: 0 (poor), 1 (neutral), and 2 (good). The overall average score is 1.965, with more than 96% of pairs receiving score of 2. (ii) Human evaluation: Three independent annotators assess both realism (how realistic and natural the content appears compared to real-world examples) and alignment (how well the content reflects the core information in the generation prompt) for 125 randomly selected examples, also on 3-point scale. Inter-annotator agreement is strong, with Fleiss κ = 0.8673 for realism and 0.7485 for alignment. Majority scores were 1.67 for realism and 1.93 for alignment, and humanmodel majority agreement on alignment reached 91.2%. Full model evaluation prompts and the human annotation interface are provided in B.2. Data Statistics. Our dataset comprises 62,160 images and 4,756 videos distributed across 450 dialogues, each tied to distinct scenario within three persuasion contexts. Figure 7 shows ten sample images and Figure 8 presents frames of two representative videos."
        },
        {
            "title": "3.1 PERSUASION EVALUATION SETUP",
            "content": "Our evaluation framework is designed to measure the persuasive efficacy of different communication modalities on LVLMs. We simulate multi-turn conversations between static Persuader and an LVLM acting as the Persuadee, systematically tracking changes in the Persuadees stance. Conversations Simulation. Each conversation focuses on specific claim under specific scenario. The process begins with the Persuader delivering an initial persuasive message. The Persuadee then replies (stance response), expressing their initial level of agreement. The discussion unfolds over alternating turns, during which the Persuader strategically presents selected arguments designed to shift the Persuadees stance. After each of the Persuadees responses, we employ our evaluation methods to quantitatively assess their agreement. Throughout the interaction, system prompts are employed to guide Persuadees replies generation. Evaluated LVLMs. We evaluate diverse set of six openand closed-source LVLMs as the Persuadee: Open-source models include Llama-4-Scout and Llama-4-Maverick. Closed-source models include GPT-4o, GPT-4.1, Gemini-2.5-Flash (without thinking ability), and Gemini-2.5-Pro. Persuader Persuasive Message Settings. To isolate the impact of modality, we test three distinct settings while holding the underlying textual arguments constant: (i) Text-only: messages consist solely of text; (ii) Multimodal: messages combine updated text (refined to pair naturally with the image) with generated, relevant image; (iii) Text-only with Captions (Ablation): in this ablation, the text is paired with descriptive caption of the image rather than the image itself, isolating the effect of adding descriptive information without full visual content. Example inputs and outputs for each condition are shown in Figure 2. Experimental Controls. We conduct experiments across 450 distinct scenarios, with three trials per scenario to ensure robustness and mitigate randomness. To eliminate confounds unrelated to modality, we adopt Static Persuader: rather than dynamically adapting to the Persuadees replies which could introduce compounding biases such as feedback loops (e.g., tailoring arguments to individual weaknesses and thereby inflating persuasion success) the Persuaders messages are sampled from topic-relevant subset of our dataset. While interactive adaptation may appear more realistic, it would introduce uncontrolled variability across conditions and undermine the comparability required to isolate modality effects. We include more detailed discussion in A. 3.2 PERSUADEE STANCE EVALUATION METHODS To robustly assess the stance of the persuadee, we adopt two complementary evaluation methods: third-party agreement scoring, which measures explicit verbal agreement, and self-estimated token probability, which gauges implicit belief. These two perspectives are grounded in distinct traditions: communication studies often emphasize observable verbal agreement, while psychological theories of persuasion highlight implicit belief shifts that may precede overt acknowledgment (Festinger, 1957; Marquart & Naderer, 1988; Chaiken et al., 1989; Eagly & Chaiken, 1993; Wood, 2000). By integrating both, our approach disentangles verbal-level compliance from implicit attitude change, yielding more nuanced and rigorous evaluation of persuasion outcomes. Agreement Scoring. We measure the persuadees expressed preference using GPT-4o as judge (Liu et al., 2023), extending Bozdag et al. (2025a). At each conversational turn, the judge assigns score (15) based on the complete dialogue context and both participants current utterances: 1 Completely Oppose (explicit, strong rejection); 2 Oppose (clear disagreement); 3 Neutral (no clear stance); 4 Support (active agreement); 5 Completely Support (strong, unequivocal agreement). We define threshold of 4 or above as evidence that the persuadee is convinced on verbal level. Token Probability. This method targets the persuadees implicit belif that is, the likelihood they would act on the persuaders suggestion. For each round, the persuadee model outputs logit probabilities for both the [target_option] (the persuaders desired outcome) and the [initial_option] (the persuadees starting preference), conditioned on the conversation so far. The persuadee is considered convinced if the probability assigned to the [target_option] overtakes that of the 5 [initial_option]. This operationalizes being persuaded not as surface agreement, but as shift in underlying preference or intended behavior, thus better reflecting practical influence."
        },
        {
            "title": "3.3 EVALUATION METRICS",
            "content": "Assessing persuasive effectiveness requires metrics that capture the dynamics of influence in dialogue. Yet prior work often relies on coarse measures like binary success or single-instance agreement that miss key aspects such as efficiency and conviction strength. In response, prior studies typically try three more detailed metrics: (1) Conviction rate, the proportion of conversations ending in persuasion; (2) Average conviction rounds, the turn at which persuasion occurs; and (3) First conviction agreement score or token probability, reflecting confidence at persuasion. However, considered in isolation, these metrics still fail to jointly capture the timing and quality of persuasion. For more holistic assessment capturing both the timing and strength of persuasion we introduce the Persuasion Discounted Cumulative Gain (PDCG) score. Inspired by the well-established Discounted Cumulative Gain (DCG) from information retrieval (Kameo & Mörtsell, 2004), PDCG rewards both early and high-quality persuasion. Formally, let Tc denote the conversational turn of the first conviction, and let Ppref be the probability of selecting the persuaders preferred option. The PDCG is formally defined as: PDCG = (cid:40) discount(Tc) Ppref, 0, if first convinced at turn Tc, otherwise. Here, discount(T ) is decreasing function that emphasizes early persuasion. We consider two forms: (i) Linear: discount(T )=1/T , which sharply reduces value with each additional turn and prioritizes the conviction round; (ii) Logarithmic: discount(T )=1/ log2(T + 1), which penalizes later persuasion less severely and emphasizes the conviction rate. The probability of selecting the persuaders preferred option, Ppref, is determined by the evaluation setup: (i) using the normalized agreement score (conviction agreement score divided by 5), or (ii) the token probability assigned to the [target_option]. By design, PDCG ranges from 0 (no conviction occurs) to 1 (immediate conviction at first turn with maximum agreement of 5 or token probability of 1), making it unified measure of persuasion effectiveness."
        },
        {
            "title": "4 EXPERIMENTAL RESULTS",
            "content": "4.1 SUSCEPTIBILITY ACROSS MODALITIES In this section, we assess the susceptibility of LVLMs to human-grounded persuasive strategies across various modalities on three persuasion contexts. By analyzing PDCG scores, we aim to uncover insights into how these models respond to persuasion when exposed to different modalities. This addresses RQ1: How susceptible are LVLMs to human-grounded persuasive strategies when expressed through different modalities? In both Commercial and Subjective Persuasion contexts, the LVLM acts as the persuadee, with persona set by the given background, goals, and role. Each dialogue consists of six turns, starting with persuasive message randomly selected from one of six strategic approaches. To maximize persuasive effectiveness, the persuader employs varied mix of strategies throughout the dialogue. After each turn, the persuadees stance is independently evaluater either by self-estimated token probabilities or third-party agreement scoring. Importantly, these assessments are performed separately and do not influence the ongoing conversation. All conversations run the full six turns even after early conviction to ensure consistent comparisons. The top and middle panels of Figure 3 reveal consistent and robust trend: incorporating visual input markedly enhances persuasive effectiveness, with the degree of improvement varying by model family and context. PDCG scores rise progressively as input shifts from text-only to text+caption to fully multimodal, independent of the discount scheme. While captions provide notable boost, the largest gains occur with complete multimodal input. Among models, GPT variants are the most susceptible to persuasion, whereas Gemini-2.5 remains the most resistant. Notably, Commercial Persuasion, which demands concrete and comparative reasoning, elicit lower susceptibility, whereas Subjective Persuasionallowing for more empathic and rhetorical strategiestend to sway models, 6 Figure 3: PDCG scores across three contexts: Commercial (top), Subjective/Behavioral (middle), and Adversarial (bottom) for three persuader response types under linear and logarithmic discounting. Higher PDCG scores indicate earlier and more effective persuasion. Higher PDCG = earlier, more effective persuasion. Cool colors = greater susceptibility; warm = stronger resistance. Scoring: agreement (Commercial, Subjective/Behavioral); token probability (Adversarial). especially GPT models, more effectively. These findings highlight both the unique value of visual information in persuasion and clear differences in how leading LVLMs respond to such strategies. We employ GPT-4o as an automatic judge, assigning persuadees agreement scores from 1 to 5 at each turn based on the dialogue context and current utterances. To evaluate reliability, three annotators labeled 104 randomly sampled examples spanning two contexts, three persuasive message settings, and six models. Majority-vote human labels strongly correlate with model scores (Pearson = 0.8701). Inter-annotator agreement is moderate (Fleiss κ = 0.4166), typical for subjective tasks, and majority agreement reached 91.3%, indicating robustness. Full model evaluation prompts and the human annotation interface are provided in D.1. In Adversarial Persuasion, we assess LVLM susceptibility using the persuadees self-estimated logit probabilities, following Xu et al. (2024). For each claim, we run three-stage protocol: (1) Initial belief check: proceed only when the models prior agrees with the ground truth; (2) Persuasive conversation: misinformation-oriented dialogue where each persuaders message is sampled from one of three strategies, interleaved to maximize pressure; and (3) Implicit belief check: covert QA probes excluded from the chat history to prevent test leakage. If the target belief is adopted, the dialogue still continues to fixed horizon of ten turns to enable fair cross-condition comparison. The bottom panel of Figure 3 highlights critical vulnerability in LVLMs: their susceptibility to misinformation increases notably when visual input is introduced. While most models exhibit solid resistance in text-only settings, the addition of multimodal content consistently amplifies persuasive effectiveness. Comparing our results with Xu et al. (2024), we observe that advancements in LLMs have improved robustness against text-only persuasion for example, GPT-4o achieves stronger resistance compared to their reported GPT-4 results. Yet, multimodal contexts significantly heighten adversarial success, with Llama-4 models proving especially impressionable. These findings underscore pressing challenge for model safety: defending against manipulation risks amplified by the visual modality, which represents key frontier in safeguarding LVLMs. 4.2 STUBBORNNESS/PREFERENCE EFFECT In 4.1, we analyzed the general performance of LVLMs in different persuasion contexts. Building on this, we now ask more nuanced question: how do these models behave when the persuadee is characterized by different levels of pre-existing preference or stubbornness (Li et al., 2024a; Shaikh et al., 2024; Lee et al., 2024; Zhao et al., 2025a)? This motivates our RQ2: How does susceptibility change when LVLMs are instructed to exhibit varying degrees of stubbornness or preference? Persuadee Preference Profile. We model persuadees preference as resistance to revising their initial belief (D.2). Operationally, we augment the profile with: [persuadee_name] has an 7 Figure 4: PDCG scores (logarithmic discount) for various models in Commercial Persuasion, evaluated via the agreement method. Preference strength levels range from 30 (weak) and 90 (strong). Table 2: Averaged first-conviction round agreement scores across persuasion strategies for Commercial (Comm.) and Subjective (Subj.) contexts, spanning different models and experimental settings. Highest values per row and column types are shaded light green; second largest are light purple. Strategy Reciprocity Consistency Liking Authority Scarcity Social Validation Comm. Subj. Comm. Subj. Comm. Subj. Comm. Subj. Comm. Subj. Comm. Subj. Models GPT-4.1 GPT-4o Llama-4-Maverick Llama-4-Scout Gemini-2.5-Flash Gemini-2.5-Pro 4.375 4.568 4.221 4.390 3.380 2.833 4.361 4.381 4.045 4.193 3.123 3.124 4.021 4.013 3.793 3.928 3.088 2.745 4.203 4.278 3.918 3.967 3.214 2. 3.720 3.825 3.609 3.686 3.044 2.674 4.019 4.078 3.644 3.719 3.066 2.656 3.500 3.599 3.350 3.575 2.625 2.257 3.782 3.867 3.258 3.392 2.685 2.485 3.816 3.890 3.641 3.789 2.934 2.404 Multimodal Text Only Text Only w/ Captions 4.478 3.648 4.042 4.104 3.643 4.160 3.743 3.203 3.469 3.927 3.390 3.761 3.764 3.030 3.434 3.829 3.219 3. 3.499 2.851 3.154 3.665 2.938 3.297 3.730 2.945 3.459 Experimental Settings - - - - - - - - - 3.738 3.780 3.535 3.711 2.924 2.510 3.583 2.888 3.293 4.083 4.108 3.562 3.708 3.010 2.538 3.728 2.984 3.474 X% chance of favoring [initial_option] over [target_option], where {30, 50, 70, 90}. Lower denotes greater openness to change; higher denotes stronger adherence to the initial option. This parameter lets us systematically vary stubbornness vs. open-mindedness and measure how preference strength modulates persuasion effectiveness, reflecting natural human variability. Model Performance. Figure 4 shows that persuasion effectiveness decreases as stubbornness (preference) increases, validating the use of preference profiles to control persuadee resistance. Two key observations emerge. First, multimodality cushions the effect of stubbornness. On average across model families, multimodal setups show substantially smaller drops in persuasion success compared to text-only settings, highlighting the robustness of richer input channels. Second, while absolute susceptibility varies across model families, the overall trend is consistent: GPT and Llama-4 models are more persuadable than Gemini-2.5 models, which remains comparatively resistant. Taken together, these findings indicate that although rising stubbornness reliably suppresses persuasion, multimodality provides consistent resilience boost across settings. 4.3 PERSUASION STRATEGY EFFECT Building on the modality-focused findings in 4.1, we now turn to the interplay between persuasion strategies and modality effects. This leads us to RQ3: Are certain persuasion strategies consistently more persuasive than others across different LVLMs? To address this question, we employ the taxonomy of strategies introduced in 2.2 and shift our evaluation metric from averaged PDCG scores to the averaged first-conviction round agreement score or token probability. Table 3: Averaged first-conviction round token probability persuasion strategies for Adversarial Persuasion. Strategy Credibility Emotional Logical GPT-4.1 GPT-4o Llama-4-Maverick Llama-4-Scout Gemini-2.5-Flash Gemini-2.5-Pro Models 0.031 0.037 0.122 0.112 0.203 0. 0.017 0.024 0.086 0.095 0.187 0.067 0.030 0.040 0.120 0.111 0.203 0.087 Table 2 shows that reciprocity and consistency are most effective in both Commercial and Subjective settings, with GPT-4o models exhibiting the largest gains. Multimodal inputs amplify these effectsespecially for reciprocityunderscoring the value of richer contextual cues. Liking also strengthens with multimodal input, likely because non-verbal cues (e.g., perceived friendliness) reinforce affective appeals beyond text alone. Adding captions to text partially restores Multimodal Text Only Text Only + Captions Experimental Settings 0.125 0.078 0.078 0.078 0.076 0. 0.116 0.083 0.080 8 the benefits of reciprocity and consistency relative to pure text, suggesting that even minimal visual grounding helps. Overall, LVLMs are most reliably swayed by exchangeand logic-based appeals when grounded in multimodal input, while affective strategies like liking gain traction when supported by non-verbal signals. Table 3 reveals that ethosand logos-based strategies dominate in Adversarial Persuasion: credibilityand logic-driven appeals consistently yield the highest success rates across most models, whereas emotional strategies remain comparatively weak. The benefit of multimodal input is clear, with credibility and logic outperforming other strategies, indicating that evidence-like cues substantially enhance persuasion. Figure 5: Persuasion dynamics under different system prompts in the Commercial Persuasion task. (Left) Convictions per round at preference level 50, comparing two evaluation methods: token probability and LLM agreement under persona-role prompt. (Right) Differences in PDCG scores between multimodal and text-only inputs with no specified preference, across three system prompts: persona-role, assistant-role (without flexibility), and assistant-role (with flexibility). 4.4 DISCUSSION How closely do the two evaluation methods align? We propose two complementary evaluation methodsself-estimated token probability (capturing implicit belief ) and third-party agreement scoring (capturing expressed agreement)and it is critical to assess whether persuadee performance diverges under these perspectives. Figure 5 illustrates this using Commercial Persuasion at preference=50. The left panel shows that the two methods capture persuasion in systematically different ways. Token probability yields slightly higher overall conviction rate (81.3% vs. 80.8%) and registers persuasion earlier, with mean conviction round of 2.8 compared to 3.2 under LLM agreement. In contrast, LLM agreement shifts later, concentrating more strongly in rounds 34. Although the two methods converge on nearly identical non-conviction totals, their temporal distributions diverge. These results suggest that models adjust their implicit beliefs before expressing overt agreement, echoing findings from human persuasion studies where individuals often update internal attitudes prior to verbal acknowledgment (Festinger, 1957; Marquart & Naderer, 1988; Chaiken et al., 1989). How sensitive is persuasion to system prompt design? Because persuadee behavior is directly shaped by system prompts (3.1), we investigate how different framings alter persuasion outcomes. Using the Commercial Persuasion task with no specified preference, the right panel of Figure 5 compares three system prompts: persona-role, where the LVLM adopts dialogue persona; assistantrole (without flexibility), where the LVLM acts as decision-making aide strictly aligned with the users stated preference; and assistant-role (with flexibility), where it may adjust if persuaded by stronger counterarguments (Figure 21 shows the difference in system prompts). Across settings, multimodal inputs generally outperform text-only inputs, with one exception: GPT-4o under the assistant-role (without flexibility) prompt shows slightly worse performance. These results indicate that prompt framing not only shapes overall persuasion effectiveness but also modulates the relative advantage of multimodal input. Future work should therefore test wider spectrum of prompts to ensure evaluation results remain both comprehensive and robust."
        },
        {
            "title": "5 RELATED WORK",
            "content": "Persuasive LLMs. Computational persuasion has long examined how arguments shape attitudes and decisions, and it now squarely includes AI systems (Bozdag et al., 2025b). Recent studies show that 9 LLMs can be as persuasive as humans (Durmus et al., 2024; OpenAI, 2024; Huang & Wang, 2023), while domain-specific datasets and persuasion-oriented models continue to advance the field (Jin et al., 2024). Applications span pro-social aims such as vaccine uptake and reducing conspiratorial beliefs (Karinshak et al., 2023; Costello et al., 2024) as well as risks including manipulation and safety threats (Salvi et al., 2024; Simchon et al., 2024; Hackenburg & Margetts, 2024; Liu et al., 2025). Evaluation and Susceptibility. Persuasion in LLMs has been measured via human judgments (Durmus et al., 2024; OpenAI, 2024) and automated approaches like PersuasionArena, ConvincerSkeptic simulations, and regression-based scoring (Singh et al., 2024; Breum et al., 2023; Pauli et al., 2024). Newer work jointly probes effectiveness and susceptibility and explores aligning models against persuasive counterarguments, yet most evaluations remain short or single-turn (Bozdag et al., 2025a; Zhao et al., 2025b). Concurrently, LLMs show clear vulnerabilities: adversarial prompts and jailbreaks can elicit harmful behavior and multi-turn attacks intensify risks (Zeng et al., 2024; Xu et al., 2024; Li et al., 2024b; Russinovich et al., 2024). How We Differ. Most prior work is text-only, human-judged, or tightly constrained. We instead study multimodal, multi-turn, agent-to-agent persuasion with the LVLM as the persuadee, measure both expressed agreement and implicit belief, and systematically vary domains (beneficial/harmful), preference strength, strategy, and prompt framingrevealing dynamics that text-only setups miss."
        },
        {
            "title": "6 CONCLUSION",
            "content": "We introduced MMPERSUADE, large-scale dataset and framework for evaluating multimodal persuasion in visionlanguage models. With 60k images and 5k videos spanning commercial, subjective, and adversarial contexts, it enables controlled, multi-turn analysis of LVLM susceptibility. Experiments with six models reveal three consistent trends: multimodality amplifies persuasion over text-only input; prior preferences reduce persuasion but are partly cushioned by multimodal cues; and strategy effectiveness varies by context, with reciprocity/consistency prevailing in commercial and subjective tasks, and credibility/logic dominating adversarial ones. These findings highlight both opportunities (e.g., sales, health, education) and risks (e.g., misinformation, manipulation), offering resource to probe, defend against, and responsibly design persuasive AI."
        },
        {
            "title": "ETHICS STATEMENT",
            "content": "Since our study analyzes multimodal persuasion, we anticipate concerns around human subjects, dataset release, potentially harmful applications, privacy, and legal compliance. Research scope and intent. Our goal is to rigorously measure LVLM susceptibility to humangrounded persuasive strategies in order to inform safer and more robust model design, not to enable manipulation. All experiments evaluate models acting as persuadees in controlled, synthetic dialogues; we do not deploy persuasive systems toward real people. Human subjects. This work does not involve experiments on human participants. Human involvement is limited to two tasks: (1) Quality assurance of synthetic media: annotators reviewed model-generated images, videos, and text for realism and alignment, as described in 2. (2) Validation of agreement scoring: annotators independently labeled persuadee agreement at the turn level based on the dialogue context and current utterances, as described in 3.2. Annotators did not provide personal or sensitive information. Data sources and generation. We augment two published text-only multi-turn persuasion corpora (DAILYPERSUASION and FARM) with synthetic multimodal assets produced by generative models through six-step pipeline detailed in 2 and the B.2. All images and videos in our benchmark are model-generated; we do not scrape or redistribute personal media. We cite all sources and respect their licenses. Sensitive content and potential harms. Our benchmark includes commercial, subjective and behavioral, as well as adversarial contexts. Adversarial scenarios include misinformation to test resistance, not to endorse any claim. Insights into what persuades models could be misused; therefore, we frame results as diagnostic evidence of vulnerabilities and recommend using them to develop safeguards (e.g., detection, calibration, and prompt/system-policy interventions) rather than to optimize persuasive impact on people. The dataset and paper do not target individuals or protected classes, and the persuadee is an LVLM configured with generic personas. Privacy, security, and legal compliance. No personally identifiable information is collected or released. All multimodal assets are synthetic, and we operate model APIs within their terms of use."
        },
        {
            "title": "REPRODUCIBILITY STATEMENT",
            "content": "We aim to make our results reproducible and verifiable. To that end, the paper and appendix specify the components required to replicate the benchmark and findings: Dataset construction. 2 describes the six-step pipeline (context classification, strategy mapping, multimodal conceptual design, prompt refinement, content generation, and quality assurance) used to augment published text-only persuasion dialogues with synthetic images and videos. Materials in provide representative prompts, example instances, and the human evaluation interface used for quality checks, along with dataset statistics. Evaluation protocol. 3 details the conversation simulation (PersuaderPersuadee turns), the three modality settings (text-only; text with caption; full multimodal), the set of evaluated LVLMs, and the two complementary stance measures (third-party agreement scoring for expressed stance and self-estimated token probability for implicit belief). Artifacts and instructions. We reference the prompts used to generate multimodal content and to configure persuadee system behavior in the B. Upon publication, we will release scripts for: (i) constructing multimodal instances from text-only dialogues using the provided prompts; (ii) running the evaluation under the three modality settings; and (iii) computing agreement, tokenprobabilitybased measures, and PDCG to reproduce the plots and tables reported in 4. Where closed-source LVLMs are used, we document model names and versions to facilitate comparable replication; open-source substitutes can be used to reproduce relative trends."
        },
        {
            "title": "REFERENCES",
            "content": "Nimet Beyza Bozdag, Shuhaib Mehri, Gokhan Tur, and Dilek Hakkani-Tür. Persuade me if you can: framework for evaluating persuasion effectiveness and susceptibility among large language models. arXiv preprint arXiv:2503.01829, 2025a. Nimet Beyza Bozdag, Shuhaib Mehri, Xiaocheng Yang, Hyeonjeong Ha, Zirui Cheng, Esin Durmus, Jiaxuan You, Heng Ji, Gokhan Tur, and Dilek Hakkani-Tur. Must read: systematic survey of computational persuasion. ArXiv, abs/2505.07775, 2025b. URL https://arxiv.org/pdf/2505. 07775. Simon Martin Breum, Daniel Vædele Egdal, Victor Gram Mortensen, Anders Giovanni Møller, and Luca Maria Aiello. The persuasive power of large language models, 2023. URL https: //arxiv.org/abs/2312.15523. Shelly Chaiken, Akiva Liberman, and Alice H. Eagly. Heuristic and systematic information processing within and beyond the persuasion context. In James S. Uleman and John A. Bargh (eds.), Unintended Thought, pp. 212252. Guilford Press, 1989. URL https://psycnet.apa.org/ record/1989-98015-007. Robert Cialdini. Influence, new and expanded: The psychology of persuasion. Harper Business, New York, NY, new and expanded edition, 2021. Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044, 2019. Thomas H. Costello, Gordon Pennycook, and David G. Rand. Durably reducing conspiracy beliefs through dialogues with ai. Science, 385(6714):eadq1814, 2024. doi: 10.1126/science.adq1814. URL https://www.science.org/doi/abs/10.1126/science.adq1814. 11 Esin Durmus, Liane Lovitt, Alex Tamkin, Stuart Ritchie, Jack Clark, and Deep Ganguli. Measuring the persuasiveness of language models, 2024. URL https://www.anthropic.com/news/ measuring-model-persuasiveness. Alice H. Eagly and Shelly Chaiken. The Psychology of Attitudes. Harcourt Brace Jovanovich College Publishers, 1993. URL https://discovered.ed.ac.uk/discovery/fulldisplay? vid=44UOE_INST:44UOE_VU2&tab=Everything&docid=alma9924147657402466&lang=en& context=L&query=creator,exact,%20Hirsh-Pasek,%20Kathy. Leon Festinger. Theory of Cognitive Dissonance. 1957. URL https://www.degruyterbrill. com/document/doi/10.1515/9781503620766/html. Kobi Hackenburg and Helen Margetts. Evaluating the persuasive influence of political microtargeting with large language models. Proceedings of the National Academy of Sciences, 121(24): e2403116121, 2024. doi: 10.1073/pnas.2403116121. URL https://www.pnas.org/doi/abs/ 10.1073/pnas.2403116121. Guanxiong Huang and Sai Wang. Is artificial intelligence more persuasive than humans? metaanalysis. Journal of Communication, 73(6):552562, 08 2023. ISSN 0021-9916. doi: 10.1093/joc/ jqad024. URL https://doi.org/10.1093/joc/jqad024. Chuhao Jin, Yutao Zhu, Lingzhen Kong, Shijie Li, Xiao Zhang, Ruihua Song, Xu Chen, Huan Chen, Yuchong Sun, Yu Chen, and Jun Xu. Joint semantic and strategy matching for persuasive dialogue. In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), Findings of the Association for Computational Linguistics: EMNLP 2023, pp. 41874197, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-emnlp.276. URL https:// aclanthology.org/2023.findings-emnlp.276/. Chuhao Jin, Kening Ren, Lingzhen Kong, Xiting Wang, Ruihua Song, and Huan Chen. Persuading across diverse domains: dataset and persuasion large language model. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.92. URL https://aclanthology. org/2024.acl-long.92/. A. Kameo and J. Mörtsell. Evaluating the search results ranking with discounted cumulative gain (dcg). J. Chem. Soc., 30:34853494, 2004. Elise Karinshak, Sunny Xun Liu, Joon Sung Park, and Jeffrey T. Hancock. Working with ai to persuade: Examining large language models ability to generate pro-vaccination messages. Proc. ACM Hum.-Comput. Interact., 7(CSCW1), April 2023. doi: 10.1145/3579592. URL https://doi.org/10.1145/3579592. Yaman Kumar, Rajat Jha, Arunim Gupta, Milan Aggarwal, Aditya Garg, Tushar Malyan, Ayush Bhardwaj, Rajiv Ratn Shah, Balaji Krishnamurthy, and Changyou Chen. Persuasion strategies in advertisements. In Proceedings of the AAAI conference on artificial intelligence, volume 37, pp. 5766, 2023. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452466, 2019. doi: 10.1162/tacl_a_00276. URL https://aclanthology.org/Q19-1026/. Seongyun Lee, Sue Hyun Park, Seungone Kim, and Minjoon Seo. Aligning to thousands of preferences via system message generalization. Advances in Neural Information Processing Systems, 37: 7378373829, 2024. Junlong Li, Fan Zhou, Shichao Sun, Yikai Zhang, Hai Zhao, and Pengfei Liu. Dissecting human and llm preferences. arXiv preprint arXiv:2402.11296, 2024a. 12 Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, and Summer Yue. Llm defenses are not robust to multi-turn human jailbreaks yet, 2024b. URL https://arxiv.org/abs/2408.15221. Stephanie Lin, Jacob Hilton, and Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods. arXiv preprint arXiv:2109.07958, 2021. Minqian Liu, Zhiyang Xu, Xinyi Zhang, Heajun An, Sarvech Qadir, Qi Zhang, Pamela Wisniewski, Jin-Hee Cho, Sang Won Lee, Ruoxi Jia, et al. Llm can be dangerous persuader: Empirical study of persuasion safety in large language models. arXiv preprint arXiv:2504.10430, 2025. Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. G-eval: Nlg evaluation using gpt-4 with better human alignment. arXiv preprint arXiv:2303.16634, 2023. Franziska Marquart and Brigitte Naderer. Communication and persuasion : central and peripheral routes to attitude change, volume 101. 1988. URL https://link.springer.com/chapter/10. 1007/978-3-658-09923-7_20. Daniel J. OKeefe. Persuasion: Theory and Research. SAGE Publications, Inc., Thousand Oaks, CA, 3rd edition, 2015. OpenAI. Openai o1 system card, December 2024. URL https://cdn.openai.com/ o1-system-card-20241205.pdf. Accessed: 2024-12-10. Amalie Brogaard Pauli, Isabelle Augenstein, and Ira Assent. Measuring and benchmarking large language models capabilities to generate persuasive language, 2024. URL https://arxiv.org/ abs/2406.17753. Christof Rapp. Aristotles rhetoric. In Edward N. Zalta (ed.), The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University, 2002. URL https://seop.illc. uva.nl/entries/aristotle-rhetoric/. Mark Russinovich, Ahmed Salem, and Ronen Eldan. Great, now write an article about that: The crescendo multi-turn llm jailbreak attack, 2024. URL https://arxiv.org/abs/2404.01833. Francesco Salvi, Manoel Horta Ribeiro, Riccardo Gallotti, and Robert West. On the conversational persuasiveness of large language models: randomized controlled trial, 2024. URL https: //arxiv.org/abs/2403.14380. Azlaan Mustafa Samad, Kshitij Mishra, Mauajama Firdaus, and Asif Ekbal. Empathetic persuasion: Reinforcing empathy and persuasiveness in dialogue systems. In Marine Carpuat, Marie-Catherine de Marneffe, and Ivan Vladimir Meza Ruiz (eds.), Findings of the Association for Computational Linguistics: NAACL 2022, pp. 844856, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-naacl.63. URL https://aclanthology.org/2022.findings-naacl.63/. Omar Shaikh, Michelle Lam, Joey Hejna, Yijia Shao, Hyundong Cho, Michael Bernstein, and Diyi Yang. Aligning language models with demonstrated feedback. arXiv preprint arXiv:2406.00888, 2024. Almog Simchon, Matthew Edwards, and Stephan Lewandowsky. The persuasive effects of political microtargeting in the age of generative artificial intelligence. PNAS Nexus, 3(2):pgae035, 01 2024. Somesh Singh, Yaman Singla, Harini SI, and Balaji Krishnamurthy. Measuring and improving persuasiveness of large language models. arXiv preprint arXiv:2410.02653, 2024. Youzhi Tian, Weiyan Shi, Chen Li, and Zhou Yu. Understanding user resistance strategies in In Trevor Cohn, Yulan He, and Yang Liu (eds.), Findings of the persuasive conversations. Association for Computational Linguistics: EMNLP 2020, pp. 47944798, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.431. URL https://aclanthology.org/2020.findings-emnlp.431/. 13 Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen Zhang, and Zhou Yu. Persuasion for good: Towards personalized persuasive dialogue system for social good. In Anna Korhonen, David Traum, and Lluis Marquez (eds.), Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 56355649, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1566. URL https: //aclanthology.org/P19-1566/. Wendy Wood. Attitude change: Persuasion and social influence. In Daniel T. Gilbert, Susan T. Fiske, and Gardner Lindzey (eds.), Handbook of Social Psychology, volume 2, pp. 539579. McGraw-Hill, 2000. Rongwu Xu, Brian Lin, Shujian Yang, Tianqi Zhang, Weiyan Shi, Tianwei Zhang, Zhixuan Fang, Wei Xu, and Han Qiu. The earth is flat because...: Investigating LLMs belief towards misinformation via persuasive conversation. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1625916303, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.858. URL https://aclanthology.org/2024.acl-long.858/. Yi Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, and Weiyan Shi. How johnny can persuade llms to jailbreak them: Rethinking persuasion to challenge ai safety by humanizing llms, 2024. URL https://arxiv.org/abs/2401.06373. Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, and Kaixiang Lin. Do llms recognize your preferences? evaluating personalized preference following in llms. arXiv preprint arXiv:2502.09597, 2025a. Yong Zhao, Yang Deng, See-Kiong Ng, and Tat-Seng Chua. Aligning large language models for faithful integrity against opposing argument. ArXiv, abs/2501.01336, 2025b. URL https: //arxiv.org/pdf/2501.01336."
        },
        {
            "title": "A LIMITATIONS",
            "content": "Our study employs Static Persuader with pre-sampled messages that do not change with the persuadees responses. This approach supports experimental control but limits the ecological validity of the interactions. Real-world persuasion requires dynamic adaptation, meaning our setup could underestimate the persuasive power of an adaptive agent on an LVLM. However, our work serves as foundational baseline, establishing controlled environment from which more complex, adaptive methods can be developed in future studies to better replicate real-world dynamics."
        },
        {
            "title": "B MULTIMODAL PERSUASION DATASET",
            "content": "LVLMs extend persuasion research beyond text into multimodal settings, yet no benchmark exists for multimodal persuasion despite recent progress on text-based evaluation (Kumar et al., 2023; Jin et al., 2024; Xu et al., 2024; Singh et al., 2024; Liu et al., 2025; Bozdag et al., 2025a). To fill this gap, we construct large-scale multimodal dataset via novel generation pipeline. Our benchmark evaluates how LVLMs act as persuadees the recipients of persuasive multimodal content. We extend multi-turn text-only persuasive dialogues with systematically generated images and videos grounded in human persuasion strategies, ensuring that added modalities both enrich the interaction and amplify persuasive force, enabling deeper study of how LVLMs process real-world multimodal cues. B.1 PERSUASION CONTEXTS CLASSIFICATION Building on prior research in persuasion (Kumar et al., 2023; Jin et al., 2024; Xu et al., 2024; Singh et al., 2024; Liu et al., 2025; Bozdag et al., 2025a) and foundational principles from communication theory (OKeefe, 2015), we construct taxonomy of persuasion contexts tailored to the study of LVLMs in the persuadee role. This taxonomy enables systematic analysis of how models interpret, process, and respond to diverse persuasive strategies. We identify three broad persuasion contexts, each characterized by the persuaders core intention and application domain: 14 Commercial Persuasion (e.g., Sales and Advertising): The persuaders primary goal is to motivate the persuadee to take specific commercial actions, such as suggesting purchase, signing up for service, or recommending engagement with product, by employing persuasive multimodal content designed to prompt concrete decisions. Subjective and Behavioral Persuasion (e.g., Health Nudges, Political Messaging, Emotional Appeals, Crisis Messaging, Cultural/Religious Appeals, Education/Pro-Social Appeals): In this context, the persuader aims to influence the internal states or behaviors of the persuadee, seeking to shape its beliefs, attitudes, or responses and guide it toward desired behavioral patterns in sensitive domains such as health, politics, crisis response, or education. Adversarial Persuasion (e.g., Misinformation and Fabricated Claims): Here, the persuader intentionally seeks to manipulate or exploit the persuadee by presenting deceptive or misleading content, aiming to misinform, confuse, or induce harmful outputs. Figure 6: Dataset construction pipeline in MMPERSUADE. B.2 DATA CONSTRUCTION PIPELINE We construct each multimodal persuasion instance by extending conversations from existing multiturn textual persuasive conversations datasets through delicated six-step pipeline (Figure 6 illustrates this process with an example): Step 1: Context Classification. Identify the persuasion context of each conversation Commercial, Subjective and Behavioral, or Adversarial Persuasion. Figure 9 shows the detailed prompts. Step 2: Strategy Mapping. Assign each persuaders persuasive message to psychology-based persuasive strategy, organized under unified taxonomy derived from Cialdinis six principles of persuasion (Cialdini, 2021) and Aristotles three rhetorical appeals (Rapp, 2002). Step 3: Multimodal Conceptual Design. Instruct GPT-4o to transform each text-based persuasive strategy into prompt for generating multimodal content. For each, specify: (i) the content type (e.g., image, short video), (ii) the multimedia configuration (e.g., scene composition, visual elements, narration style), and (iii) textual introduction that naturally incorporates the multimodal element into the conversation. Step 4: Prompt Refinement. Iteratively refine the initial prompts into well-structured generation prompts, emphasizing clarity, creativity, and alignment with the intended persuasive objectives. 15 Step 5: Multimodal Content Generation. Employ state-of-the-art generative models (e.g., gptimage, Veo3) to produce the specified multimodal content using the finalized prompts. Step 6: Content Quality Assurance. Evaluate the generated outputs through both model-based and human assessments to ensure persuasiveness, contextual appropriateness, and overall quality. Source Datasets. We construct our dataset by augmenting it with data from two high-quality, multiturn persuasion dialogue datasets: DAILYPERSUASION (Jin et al., 2024) and FARM (Xu et al., 2024). Our augmentation process begins with Context Classification (Step 1), ensuring broad and balanced representation across major types of persuasion. Specifically, our dataset includes: 300 dialogues from DAILYPERSUASION, evenly split between 150 Commercial Persuasion dialogues and 150 Subjective Persuasion dialogues. In addition, 150 Adversarial Persuasion dialogues from FARM. The two datasets are described in detail: DAILYPERSUASION: Featuring 78,000 GPT-4-generated multi-turn dialogues across 35 domains, each annotated for user intent and persuasive tactics, this dataset offers granular control for both commercial and subjective persuasion use cases. FARM: Including 1,500 dialogue sessions, each grounded in fact-driven question answering. Questions are drawn from established benchmarks such as BoolQ (Clark et al., 2019), Natural Questions (NQ) (Kwiatkowski et al., 2019), and TruthfulQA (Lin et al., 2021). Tables 4 to 6 show the domains and tags in context classification results. Persuasion Strategy Taxonomy. For both Commercial and Subjective persuasion, we employ Cialdinis six principles of persuasion (Cialdini, 2021): reciprocity (the urge to return favors), consistency (the drive to act in accordance with previous commitments), social validation (the tendency to adopt behaviors modeled by others), authority (the weight given to perceived expertise or status), liking (the inclination to be influenced by those we find appealing or relatable), and scarcity (the increased perceived value of limited opportunities or resources). For Adversarial persuasion, we draw on Aristotles three rhetorical appeals (Rapp, 2002): logical appeal (persuasion through facts, evidence, and rational argumentation), credibility appeal (establishing trustworthiness via credentials or reputation), and emotional appeal (eliciting specific feelings such as sympathy, fear, or anger to shape attitudes and decisions). Figure 10 demonstrates the detailed prompts. Multimodal Content Details. We construct two categories of multimodal content: (i) Imagebased content includes memes, infographics, photographs, social media posts (Instagram, Facebook, Twitter/X, and Threads), advertising posters, and screenshots of online discussions (Reddit, Quora, Instagram, Facebook, Twitter/X, and Threads). Each image is generated at resolution of 1024 1536 pixels, with five distinct images per prompt to promote diversity; (ii) Video-based content includes materials such as YouTube clips, short-form videos (TikTok and Reels), television advertisements, political campaign advertisements, and news segments. Each video is generated in 16:9 aspect ratio, with duration of eight seconds, at resolution of 720 pixels with audio. For each prompt, one video is generated, reflecting computational constraints. Figure 11 shows the generation prompt for Multimodal Conceptual Design (Step 3) and Figures 12 to 18 shows the generation prompts for Prompt Refinement (Step 4) across memes, infographics, photographs, social media posts, advertising posts, social discussion screenshots, and videos. Data Quality Assurance Details. To ensure the quality of our generated multimodal content, we employ both model-based and human evaluation protocols. (i) Model-based evaluation: GPT-4o assigns an alignment score between each generation prompt and its corresponding textimage or textvideo output on 3-point scale: 0 (poor), 1 (neutral), and 2 (good). The overall average agreement score is 1.965, with more than 96% of pairs receiving score of 2. Category-wise averages are 1.963 (Commercial), 1.961 (Subjective), and 1.972 (Adversarial). (ii) Human evaluation: Three independent annotators assess both realism (how realistic and natural the content is compared to realworld examples) and alignment (how well the content reflects the core information in the generation prompt), also on 3-point scale. Inter-annotator agreement was strong, with Fleiss kappa = 0.8673 for realism and 0.7485 for alignment. Majority scores were 1.57 for realism and 1.93 for alignment, and humanmodel majority agreement on alignment reached 91.2%. Full model evaluation prompts are shown in Figure 19 and Figure 20 displays the user interface we use for human evaluation, including multimodal contents, generation prompts, scoring panels. 16 Data Statistics. Our dataset comprises 62,160 images and 4,756 videos distributed across 450 dialogues, each tied to distinct scenario within three persuasion contexts. Figure 7 shows ten sample images and Figure 8 presents two representative videos. Figure 7: Examples of refined generation prompts abd generated images in MMPERSUADE. Persuasion Contexts Domains Commercial Persuasion Architecture (2), Art (8), Business (36), Career (7), Charity (2), Craftsmanship Subjective Persuasion (5), Culture (2), Ecology (8), Education (6), Family (5), Fashion (6), Finance (26), Health (6), History (3), Innovation (3), Leisure (7), Lifestyle (18), Literature (4), Marketing (16), Media (2), Psychology (2), Safety (2), Science (2), Sport (3), Technology (25), Travel (8), Welfare (2) Architecture (2), Art (6), Business (11), Career (9), Charity (9), Culture (11), Ecology (4), Economics (2), Education (13), Ethics (5), Family (6), Fashion (1), Finance (12), Health (14), Innovation (2), Law (1), Leisure (4), Lifestyle (25), Literature (4), Media (4), Philosophy (3), Politics (12), Psychology (15), Safety (16), Science (3), Sport (4), Technology (3), Travel (9), Welfare (3) Table 4: Domains by Persuasion Context (Commercial and Subjective Persuasion). 17 Persuasion Contexts Commercial Persuasion Tags 3d printing (2), 5g technology application (1), sense of humor (1), Academic achievement evaluation (1), Agricultural development (1), Animation appreciation (2), Animation production (1), Appreciation of calligraphy and painting (1), Architectural style (1), Adventure sports (1), Brand building (1), Brand image (1), Brand marketing (5), Business cooperation (3), Business expansion (1), Calligraphy art (1), Car purchase (2), Career planning (1), Citizen education (1), Choice of health products (1), Cloud computing (1), Credit card management (1), Cultural industry (1), Customer service (2), Data analysis (1), Daily exercise (1), Debt management (2), DIY skills (1), Donation to charity (1), Educational technology (1), Engineering technology (1), Enterprise management (1), Entrepreneurship (1), Entrepreneurship resources (2), Family economy (1), Family education (1), Family finance (1), Family travel (1), Fashion accessories (3), Fashion matching (3), Fishing techniques (1), Financial planning (1), Foreign trade cooperation (3), Game experience (1), Game selection (2), Green energy (1), Healthy diet (2), Healthcare (1), Handmade (3), Historical sites (1), Home improvement (1), Home security (1), Human resource management (1), Information technology (1), Innovative products (3), Insurance policy (4), Insurance purchase (1), Intelligent transportation (1), International exchange (1), International scientific research cooperation (2), International trade (1), Internet development (1), Interview with authors (1), Investing in stocks (1), Investment (1), Investment advice (1), Investment in real estate (1), Investment strategy (1), Job training (1), Language learning (1), Literary translation (1), Life consultation (1), Life skills (1), Local business support (1), Local cuisine (2), Love and marriage (2), Machine learning (1), Marketing (5), Market competition (2), Memories of time (2), Military technology (1), Music appreciation (1), Music lessons (1), Nature conservation (1), Network (2), New app (2), New business idea (3), New business strategy (3), New energy vehicles (1), New investment (1), New marketing strategy (6), New product adoption (2), New technology (1), News comments (1), Novel creation (1), Novel reading (1), Online privacy (1), Organic farming (2), Outsourced services (2), Participate in competitions (1), Personal boundaries (1), Personal brand building (2), Personal development (1), Personal finance (2), Personal hygiene (1), Personal image (1), Pet adoption (1), Photography skills (1), Plant farming (1), Product promotion (1), Production management (2), Professional networking (1), Public services (1), Real estate investment (2), Reduce waste (1), Recommended by photographers (2), Recommended tourist attractions (1), Robotics technology (1), Rural revitalization (1), Safety awareness (1), Smart home (2), Small business support (2), Social media presence (2), Socializing (1), Sports (1), Supply chain management (1), Sustainable development (1), Tax planning (1), The digital economy (1), The internet of things (1), The sports industry (1), Time management (1), Tourism industry (2), Traditional craftsmanship (1), Training institutions (1), Travel destination (2), Travel planning (2), Travel strategy (1), Urban construction (1), Utilization of old materials (1), Vehicle maintenance (1), Venture capital (5), Wealth management (1), Website design (1), Weight loss (1), Work from home (1), Yoga meditation (1) Table 5: Tags by Persuasion Context 18 Persuasion Contexts Tags Subjective Persuasion sense of humor and Stress reduction (1), Academic Competition (1), Academic Frontiers and Academic Innovation and Outsourced Services (1), Adventure Sports (1), Alternative Medicine (1), Anti-bullying and Local politics (1), architectural miracle (1), Art class (1), art appreciation (1), art therapy (1), Belief and Religion (1), birthday celebration (1), Birthday celebration and Emotional intelligence (1), Business partnership and Donation of Love (1), Car purchase (1), charitable donation (3), Circular Economy and Child care (1), Communication Skills (1), Community engagement and Information sharing (1), community involvement (1), Comparative Cultural Studies (1), credit card management (1), crowdfunding projects and local politics (1), Cultural exchange (1), cultural exchange (1), Cultural event attendance (1), Cultural event attendance and DIY Skills (1), Cultural Industry (1), Current Affairs Perspective (1), Daily exercise (1), Daily exercise and Travel Planning (1), Debt management (1), DIY Skills (1), Disaster preparedness and Cultural event attendance (1), Discipline Competition (1), donation to charity (2), Donation of Love (2), Earth Science (1), earthquake warning (1), Earthquake Warning and Business ethics (1), Education Policy (1), emotional communication (1), Emotional communication and Healthy habits (1), Emotional intelligence (1), Emotional Support and Outdoor sports and Literary Translation (1), Environmental conservation (1), equality of educational resources (1), ethics and morality (1), Event planning (1), Family education (1), family finance (1), Fashion trends (1), financial literacy (1), Folk Culture and Attend conference and Travel Plan (1), food safety (1), geographic exploration (1), Geographic Exploration (1), Health Care (1), health check (1), healthy diet (1), healthy habits (1), hiking (1), Home cooking and Home organization (1), Home Design (1), Home gardening and Earthquake Warning (1), Home stay experience and Business negotiations (1), insurance purchase (1), International Exchange and Critical thinking and Equality of educational resources (1), International scientific research cooperation (1), international cooperation (1), international relations (1), international travel (1), Internet Development and Urban Planning and Psychological adjustment (1), Internet of Things Applications and Astronomical Research (1), Investment Strategy and House Rental (1), Investing in stocks and Internship opportunities (1), interpersonal communication (1), interpersonal relationships (1), Innovative products (1), Innovative thinking (1), job training (1), keeping pets (1), Learning new skills and Home security and Fitness routine (1), Learning programming and Information Security and Career mentoring (1), Legal Aid (1), life habits (1), literary review (1), Literary Awards and Entrepreneurship Suggestions (1), Local politics (1), local politics (1), Market Research and Publishing industry (1), Modern Art and Circular Economy (1), Online dating (1), Parent Child Travel (1), Parent Child Travel and Studying Abroad and Pet Care (1), Participate in the performance and Political campaign and New parenting strategy (1), participate in the performance (1), Personal finance (1), Personal safety (1), Pet adoption and Attend meetings and Rural Development (1), playing instruments (1), Political campaign and Life advice (1), Political campaign and Social justice and Environmental Management (1), political perspectives (1), Presentation Skills (1), Public Services (1), public policy (1), public safety (1), publishing industry (1), Reading habit (1), Recommended Tourist Attractions and Yoga Practice (1), Relocation and Investment in collectibles and Language learning (1), Relocation and Political Perspectives and Physical therapy (1), Relationship communication (1), Religious Studies and Reduce stress and relax (1), Reduce waste and Family Education Methods (1), responding to emergency situations (1), Responding to Emergency Situations and The concept of love (1), Saving for retirement (1), Scenic Spots and Historic Sites and Movie recommendation and The sports industry (1), Security precautions (1), security precautions (1), Skill development and Support local artists and Personal Image Design (1), Safety awareness (2), Team collaboration and World Heritage Site (1), The Global Economy and Emotional Management (1), The lesson of failure (1), The process of globalization (1), Traditional Culture (1), transportation and travel and game experience (1), Travel planning and National Security (1), Travel Safety (1), Travel Safety and Academic Competition (1), utilization of old materials (1), Vehicle maintenance (1), Wedding Planning and New exercise and Employee training (1), Workplace conflict resolution (1), Workplace productivity (1), Workplace wellness (1), Writing Skills (1), Yoga practice (1) Table 6: Tags by Persuasion Context Figure 8: Examples of refined generation prompts and generated videos in MMPERSUADE. 20 Figure 9: Prompts for context classification (Step 1) of data construction pipeline in MMPERSUADE. 21 Figure 10: Prompts for strategy mapping (Step 2) of data construction pipeline in MMPERSUADE. Figure 11: Prompts for multimodal conceptual design (Step 3) of data construction pipeline. 23 Figure 12: Prompts for prompt refinement (Step 4; meme) of data construction pipeline. Figure 13: Prompts for prompt refinement (Step 4; infographic) of data construction pipeline. 24 Figure 14: Prompts for prompt refinement (Step 4; photograph) of data construction pipeline. Figure 15: Prompts for prompt refinement (Step 4; social media post) of data construction pipeline. 25 Figure 16: Prompts for prompt refinement (Step 4; advertising post) of data construction pipeline. Figure 17: Prompts for prompt refinement (Step 4; social discussion) of data construction pipeline. 26 Figure 18: Prompts for prompt refinement (Step 4; video) of data construction pipeline. 27 Figure 19: Evaluation prompt for text-image alignment in Quality Assurance (Step 6). 28 Figure 20: UI for human evaluation of textimage/video alignment in Quality Assurance (Step 6)."
        },
        {
            "title": "C EVALUATION FRAMEWORK",
            "content": "C.1 PERSUASION EVALUATION SETUP Our evaluation framework is designed to measure the persuasive efficacy of different communication modalities on LVLMs. We simulate multi-turn conversations between static Persuader and an LVLM acting as the Persuadee, systematically tracking changes in the Persuadees stance. Conversations Simulation. Each conversation focuses on specific claim under specific scenario. The process begins with the Persuader delivering an initial persuasive message. The Persuadee then replies (stance response), expressing their initial level of agreement. The discussion unfolds over alternating turns, during which the Persuader strategically presents selected arguments designed to shift the Persuadees stance. After each of the Persuadees responses, we employ our evaluation methods to quantitatively assess their agreement. Throughout the interaction, system prompts are employed to guide Persuadees replies generation. In particular, the system prompt weaves together the users background, objectives, and assigned role, creating detailed natural language persona that the Persuadee is instructed to inhabit for the duration of the conversation. We comparea three system prompts: persona-role, where the LVLM adopts dialogue persona; assistant-role (without flexibility), where the LVLM acts as decision-making aide strictly aligned with the users stated preference; and assistant-role (with flexibility),where it may adjust if persuaded by stronger counterarguments. Figure 21 shows the difference in system prompts. Evaluated LVLMs. We evaluate diverse set of six openand closed-source LVLMs as the Persuadee: Open-source models include Llama-4-Scout and Llama-4-Maverick. Closed-source models include GPT-4o, GPT-4.1, Gemini-2.5-Flash (without thinking ability), and Gemini-2.5-Pro. Table 7 shows the detailed model names. Models Detailed Names meta-llama/Llama-4-Scout-17B-16E-Instruct Llama-4-Scout Llama-4-Maverick meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8 GPT-4o GPT-4.1 Gemini-2.5-Flash Gemini-2.5-Pro gpt-4o-2024-08-06 gpt-4.1-2025-04-14 vertex_ai/gemini-2.5-flash vertex_ai/gemini-2.5-pro Table 7: LVLMs detailed model names. C.2 PERSUADEE STANCE EVALUATION METHODS To robustly assess the stance of the persuadee, we adopt two complementary evaluation methods: third-party agreement scoring, which measures explicit verbal agreement, and self-estimated token probability, which gauges implicit belief. These two perspectives are grounded in distinct traditions: communication studies often emphasize observable verbal agreement, while psychological theories of persuasion highlight implicit belief shifts that may precede overt acknowledgment (??Chaiken et al., 1989; Eagly & Chaiken, 1993; Wood, 2000). By integrating both, our approach disentangles verballevel compliance from implicit attitude change, yielding more nuanced and rigorous evaluation of persuasion outcomes. Agreement Scoring. We measure the persuadees expressed preference using GPT-4o as judge (Liu et al., 2023), extending Bozdag et al. (2025a). At each conversational turn, the judge assigns score (15) based on the complete dialogue context and both participants current utterances: 1 Completely Oppose (explicit, strong rejection); 2 Oppose (clear disagreement); 3 Neutral (no clear stance); 4 Support (active agreement); 5 Completely Support (strong, unequivocal agreement). We define threshold of 4 or above as evidence that the persuadee is convinced on verbal level. Figure 22 demonstrates the evaluation prompt. Token Probability. This method targets the persuadees implicit belif that is, the likelihood they would act on the persuaders suggestion. For each round, the persuadee model outputs probability estimates for both the [target_option] (the persuaders desired outcome) and the [initial_option] (the persuadees starting preference), conditioned on the conversation so far. The persuadee is 30 Figure 21: Our proposed three system prompts: persona-role, assistant-role (without flexibility), and assistant-role (with flexibility). considered convinced if the probability assigned to the [target_option] overtakes that of the [initial_option]. This operationalizes being persuaded not as surface agreement, but as shift in underlying preference or intended behavior, thus better reflecting practical influence. Figure 22: Evaluation prompt for third-party agreement scoring."
        },
        {
            "title": "D EXPERIMENTAL RESULTS",
            "content": "D.1 SUSCEPTIBILITY ACROSS MODALITIES In this section, we assess the susceptibility of LVLMs to human-grounded persuasive strategies across various modalities on three persuasion contexts. By analyzing PDCG scores, we aim to uncover insights into how these models respond to persuasion when exposed to different modalities. This addresses RQ1: How susceptible are LVLMs to human-grounded persuasive strategies when expressed through images, videos, or multimodal combinations? Figure 23 shows conviction rate, average conviction rounds, and average first conviction token probability of different models in Commercial Persuasion context using persona-role system prompt and agreement score evaluation method. To aggregate these outcomes into single measure, we apply our proposed PDCG metric, with the results shown in the top panel of Figure 3. Figure 24 shows conviction rate, average conviction rounds, and average first conviction agreement score of different models in Subjective and Behavioral Persuasion context using persona-role system prompt and agreement score evaluation method. To unify these outcomes into single measure, we apply our proposed PDCG metric, with results shown in the middle panel of Figure 3. We further break down these results by subset classification, as presented in Figure 25 and Figure 26. Figure 27 shows conviction rate, average conviction rounds, and average first conviction token probability of different models in Adversarial Persuasion context using token probability evaluation method. To aggregate these outcomes into single measure, we apply our proposed PDCG metric, with the results shown in the bottom panel of Figure 3. We further provide subset-level breakdown of these results in Figure 28, Figure 29, Figure 30, and Figure 31. Figure 23: Conviction rate, average conviction rounds, and average first conviction token probability of different models in Commercial Persuasion context using persona-role system prompt and agreement score evaluation method. Figure 24: Conviction rate, average conviction rounds, and average first conviction agreement score of different models in Subjective and Behavioral Persuasion context using persona-role system prompt and agreement score evaluation method. Figure 25: Conviction rate and average conviction rounds by classification in Subjective and Behavioral Persuasion context using persona-role system prompt and agreement score evaluation method. 33 Figure 26: PDCG scores under two discounting factors (linear and log) of different models by classification in Subjective and Behavioral Persuasion context using persona-role system prompt and agreement score evaluation method. Figure 27: Conviction rate, average conviction rounds, and average first conviction token probability of different models in Adversarial Persuasion context using token probability evaluation method. Annotator Annotator Annotator 2 Annotator 3 Pearson correlation Spearman correlation 0.8768 0.8949 0.7551 0.7547 0.8414 0. Human scores Model scores Mean: 3.22, Std: 1.10 Mean: 3.04, Std: 0.94 Mean: 3.03, Std: 1.19 Mean: 3.25, Std: 1.13 Table 8: Human-model agreement analysis (104 samples). Annotator Pairs A1 vs. A2 A2 vs. A3 A1 vs. A3 Pearson correlation Spearman correlation Cohens Kappa 0.7081 0.7109 0.3979 0.7358 0.7335 0.3816 0.7977 0.8104 0.4774 Table 9: Inter-annotator agreement analysis (104 samples). Human Evaluation. We use GPT-4o as an automatic judge, assigning persuadee agreement scores (15) at each turn based on dialogue context and utterances. To assess reliability, three annotators labeled 104 randomly sampled examples spanning two contexts, three persuasive message settings, and six models. Majority-vote human labels show strong correlation with model scores (Pearson = 0.8701). Inter-annotator agreement is moderate (Fleiss κ = 0.4166), typical for subjective tasks, while majority agreement reached 91.3%, demonstrating robustness. Figure 32 illustrates the annotation interface, and Table 8Table 9 report humanmodel correlation and inter-annotator agreement, respectively. Figure 28: Conviction rate of different models and subsets in Adversarial Persuasion context using token probability evaluation method. Figure 29: Average conviction rounds of different models and subsets in Adversarial Persuasion context using token probability evaluation method. Figure 30: PDCG scores with linear discounting factor of different models in Adversarial Persuasion context using token probability evaluation method. Figure 31: PDCG scores with log discounting factor of different models in Adversarial Persuasion context using token probability evaluation method. 35 Figure 32: User interface for human evaluation of agreement scoring method in MMPERSUADE. 36 D.2 STUBBORNNESS/PREFERENCE EFFECT In 4.1, we analyzed the general performance of LVLMs in different persuasion contexts. Building on this, we now ask more nuanced question: how do these models behave when the persuadee is characterized by different levels of pre-existing preference or stubbornness (Li et al., 2024a; Shaikh et al., 2024; Lee et al., 2024; Zhao et al., 2025a)? This motivates our second research question, RQ2: How does susceptibility change when LVLMs are instructed to exhibit varying degrees of stubbornness or prior preference? Figure 33: Comparison of two profile framings for modeling persuadee preference. The Stubbornness template (left) specifies the probability of favoring one option over another, producing probability curves that scale consistently with the stated preference level X%. The Preference template (right), which encodes preference as ratio (e.g., X/100), yields nearly flat probabilities across levels, suggesting the models disregard graded variation under this framing. Human-preferred options are shown in blue; alternative options in orange. Persuadee Preference Profile. We evaluate GPT-4o and GPT-4.1 on 10 randomly selected examples from commercial and subjective persuasion. For each case, we run an initial belief check using the token probabilities of [option]. To examine how different framings shape model behavior, we test two profile templates. The Stubbornness template specifies: [persuadee_name] has an X% chance of favoring [option_A] over [option_B], while the Preference template states: [persuadee_name] has preference of X/100 favoring [option_A]. Here, [option_A] is the human-preferred choice, [option_B] the alternative, and {30, 50, 70, 90}. The contrast between templates is striking. The probability-based framing (left) tracks the intended semantics: as increases, the likelihood of selecting the human-preferred option rises sharply while alternatives fall. By contrast, the ratio-based framing (right) produces nearly flat probabilities regardless of X, suggesting the models largely ignore graded variation under this format. Motivated by this observation, we model persuadees preference as resistance to revising their initial belief. Operationally, we augment the profile with: [persuadee_name] has an X% chance of favoring [initial_option] over [target_option], where {30, 50, 70, 90}. Lower denotes greater openness to change; higher denotes stronger adherence to the initial option. This parameter lets us systematically vary stubbornness vs. open-mindedness and measure how preference strength modulates persuasion effectiveness, reflecting natural human variability. Model Performance. Figure 4 shows that persuasion effectiveness decreases as stubbornness increases, validating the use of preference profiles to control persuadee resistance. Two key observations emerge. First, multimodality cushions the effect of stubbornness. On average across model families, multimodal setups show substantially smaller drops in persuasion success compared to text-only settings, highlighting the robustness of richer input channels. Second, while absolute susceptibility varies across model families, the overall trend is consistent: GPT and Llama models are more persuadable than Gemini, which remains comparatively resistant. Taken together, these findings indicate that although rising stubbornness reliably suppresses persuasion, multimodality provides consistent resilience boost across settings. Moreover, we report results with the assistant-role system prompt under two settings: without the flexibility condition (Figure 34) and with the flexibility condition (Figure 35), using token probability as the evaluation method. 37 Figure 34: PCDCG scores for various models on the Commercial Persuasion using assistant-role system prompt without the flexibility condition, evaluated via the token probability with logarithmic discount factor. Preference strength levels range from 30 (weak) and 90 (strong), reflecting increasing user preference strength. Figure 35: PCDCG scores for various models on the Commercial Persuasion using assistant-role system prompt with the flexibility condition, evaluated via the token probability with logarithmic discount factor. Preference strength levels range from 30 (weak) and 90 (strong), reflecting increasing user preference strength. D.3 DISCUSSION How closely do the two evaluation methods align? We introduce two complementary evaluation methods: self-estimated token probability (capturing implicit belief ) and third-party agreement scoring (capturing expressed agreement). key question is whether persuadee performance diverges between these perspectives. In 4.4, we reported results at preference level 50, comparing token probability with LLM agreement under persona-role prompt. Here, we extend the analysis by presenting results across all preference levels (30, 50, 70, 90) in Figure 36. We further compare convictions per round across all preference levels using the assistant-role prompt, both with and without flexibility, shown in Figure 37 and Figure 38. Finally, to provide more intuitive insight, we visualize alignment and misalignment at each turn under the assistant-role setup in Figure 39 and Figure 40. Figure 36: Alignment between token probability and agreement scores under the persona-role system prompt in Commercial Persuasion. Preference strength varies from 30 (weak) to 90 (strong)."
        },
        {
            "title": "E LARGE LANGUAGE MODELS USAGE STATEMENT",
            "content": "Large language models are used for evaluation purposes and polishing the content of this paper. 38 Figure 37: Alignment between token probability and agreement scores under the agentic operational setup (with flexible condition) for Commercial Persuasion. Preference strength varies from 30 (weak) to 90 (strong). Figure 38: Alignment between token probability and agreement scores under the agentic operational setup (without flexible condition) for Commercial Persuasion. Preference strength varies from 30 (weak) to 90 (strong). Figure 39: Alignment and misalignment between token probabilities and agreement scores across dialogue turns under the assistant-role setup with flexibility in Commercial Persuasion. Results are shown for preference strengths ranging from 30 (weak) to 90 (strong). Figure 40: Alignment and misalignment between token probabilities and agreement scores across dialogue turns under the assistant-role setup without flexibility in Commercial Persuasion. Results are shown for preference strengths ranging from 30 (weak) to 90 (strong)."
        }
    ],
    "affiliations": [
        "Salesforce AI Research",
        "University of California, Los Angeles"
    ]
}