{
    "paper_title": "ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation",
    "authors": [
        "Kun Yang",
        "Yuxuan Zhu",
        "Yazhe Chen",
        "Siyao Zheng",
        "Bangyang Hong",
        "Kangle Wu",
        "Yabo Ni",
        "Anxiang Zeng",
        "Cong Fu",
        "Hui Li"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Sequential recommendation increasingly employs latent multi-step reasoning to enhance test-time computation. Despite empirical gains, existing approaches largely drive intermediate reasoning states via target-dominant objectives without imposing explicit feasibility constraints. This results in latent drift, where reasoning trajectories deviate into implausible regions. We argue that effective recommendation reasoning should instead be viewed as navigation on a collaborative manifold rather than free-form latent refinement. To this end, we propose ManCAR (Manifold-Constrained Adaptive Reasoning), a principled framework that grounds reasoning within the topology of a global interaction graph. ManCAR constructs a local intent prior from the collaborative neighborhood of a user's recent actions, represented as a distribution over the item simplex. During training, the model progressively aligns its latent predictive distribution with this prior, forcing the reasoning trajectory to remain within the valid manifold. At test time, reasoning proceeds adaptively until the predictive distribution stabilizes, avoiding over-refinement. We provide a variational interpretation of ManCAR to theoretically validate its drift-prevention and adaptive test-time stopping mechanisms. Experiments on seven benchmarks demonstrate that ManCAR consistently outperforms state-of-the-art baselines, achieving up to a 46.88% relative improvement w.r.t. NDCG@10. Our code is available at https://github.com/FuCongResearchSquad/ManCAR."
        },
        {
            "title": "Start",
            "content": "ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Kun Yang1, Yuxuan Zhu2, Yazhe Chen1, Siyao Zheng3, Bangyang Hong2, Kangle Wu2, Yabo Ni2, Anxiang Zeng2, Cong Fu2, Hui Li1 6 2 0 2 3 2 ] . [ 1 3 9 0 0 2 . 2 0 6 2 : r Abstract Sequential recommendation increasingly employs latent multi-step reasoning to enhance test-time computation. Despite empirical gains, existing approaches largely drive intermediate reasoning states via target-dominant objectives without imposing explicit feasibility constraints. This results in latent drift, where reasoning trajectories deviate into implausible regions. We argue that effective recommendation reasoning should instead be viewed as navigation on collaborative manifold rather than free-form latent refinement. To this end, we propose ManCAR (ManifoldConstrained Adaptive Reasoning), principled framework that grounds reasoning within the topology of global interaction graph. ManCAR constructs local intent prior from the collaborative neighborhood of users recent actions, represented as distribution over the item simplex. During training, the model progressively aligns its latent predictive distribution with this prior, forcing the reasoning trajectory to remain within the valid manifold. At test time, reasoning proceeds adaptively until the predictive distribution stabilizes, avoiding over-refinement. We provide variational interpretation of ManCAR to theoretically validate its drift-prevention and adaptive test-time stopping mechanisms. Experiments on seven benchmarks demonstrate that ManCAR consistently outperforms state-of-the-art baselines, achieving up to 46.88% relative improvement w.r.t. NDCG@10. Our code is available at https://github.com/FuCongResearchSquad/ManCAR. CCS Concepts Information systems Recommender systems. Keywords Sequential Recommendation, Latent Reasoning ACM Reference Format: Kun Yang1, Yuxuan Zhu2, Yazhe Chen1, Siyao Zheng3, Bangyang Hong2, Kangle Wu2, Yabo Ni2, Anxiang Zeng2, Cong Fu2, Hui Li1 . 2026. ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time 1Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University, China. 2Shopee Pte. Ltd. 3School of Informatics, Xiamen University, China. Hui Li is the corresponding author. hui@xmu.edu.cn . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or fee. Request permissions from permissions@acm.org. Conference17, Washington, DC, USA 2026 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-x-xxxx-xxxx-x/YYYY/MM https://doi.org/10.1145/nnnnnnn.nnnnnnn Figure 1: Illustration of constrained versus unconstrained latent reasoning. Graph-conditioned reasoning trajectories remain within collaborative manifold defined by neighbor items, enabling stable and directed refinement toward the target. In contrast, unconstrained reasoning may drift outside feasible regions, leading to inefficient or unstable paths. Computation for Sequential Recommendation . In . ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn"
        },
        {
            "title": "1 Introduction\nSequential recommendation has been significantly reshaped by the\ngrowing adoption of generative modeling paradigms [4]. Inspired\nby Large Language Models (LLMs), recent work has begun to ex-\nplore latent multi-step reasoning in sequential recommendation to\nextend test-time computation [3, 20, 30, 31]. In LLMs, such reason-\ning is commonly realized through the recursive depth paradigm,\nwhere chain-of-thought (CoT) tokens are replaced by un-decoded\nlatent states produced by the model [5, 8, 17, 25]. These latent states\nare iteratively refined for multiple steps using shared model pa-\nrameters, and only decoded back to the output space at the final\nstep, effectively increasing the modelâ€™s computational depth with-\nout expanding its architecture. This paradigm offers a natural and\nefficient template for incorporating reasoning into sequential rec-\nommendation, without requiring explicit textual representations.\nDespite empirical gains, existing methods remain poorly under-\nstood. They typically guide latent reasoning using target-dominant\nobjectives [30, 31], such as supervising only the final reasoning\nstate with the target item, or mapping each intermediate state to\nan item probability distribution and progressively concentrating it\ntoward a target one-hot distribution. However, they impose no ex-\nplicit constraints on the evolution of intermediate reasoning states.\nAs a result, the latent reasoning trajectory is largely unconstrained\nand retains excessive degrees of freedom while â€œwalkingâ€ through\nthe item space. This often leads to latent drift (Fig. 1), where in-\ntermediate states migrate into regions that are poorly aligned with",
            "content": "Conference17, July 2017, Washington, DC, USA Kun Yang et al. user preferences. Such drift is particularly detrimental at test time, degrading model robustness and generalization. From recommendation perspective, an overlooked but fundamental property of user behavior is that interactions are inherently collaborative rather than independent. This naturally motivates guiding latent reasoning using an item interaction graph, which encodes collective patterns across users. Users with similar preferences tend to interact with similar items, and item transitions exhibit regularities shaped by population-level behaviors. These collaborative signals naturally define notion of plausibility: given users recent interactions, only subset of items is realistically relevant in the near future. Such assumptions are widely adopted in graph-based recommendation [2, 14, 35, 36, 39, 40, 43, 45], where users next interaction is expected to lie within the local neighborhood of their recent interests. In this paper, we propose ManCAR (Manifold-Constrained Adaptive Reasoning), principled framework that grounds latent reasoning within the topology of global interaction graph. Rather than naively enumerating graph traversal paths as reasoning trajectories, which is computationally expensive and unnecessary for latent reasoning, we leverage the interaction graph as feasibility constraint on the reasoning process. Specifically, we treat the neighborhood induced by the item graph as manifold constraint, restricting latent reasoning trajectories to evolve within collaboratively reachable regions while refining toward the target item. In probabilistic terms, this constraint corresponds to region on the item probability simplex where items connected to the users recent actions are assigned substantially higher probability mass than unrelated items. This feasibility view naturally admits variational interpretation of latent reasoning. Introducing latent reasoning states can be viewed as performing inference over an intermediate intent variable, with the graph-induced neighborhood serving as structure-aware prior. Latent reasoning can then be formulated using an objective similar to the Evidence Lower Bound (ELBO), which balances target prediction with reasoning feasibility. Besides, while the manifold constraint defines where latent reasoning can evolve, it leaves open the question of when reasoning should terminate. Since we train reasoning states to traverse collaboratively feasible regions on the item probability simplex toward the target, further refinement becomes uninformative once the item probability distribution produced by the latent state stabilizes. This motivates us to design convergence-based stopping criterion for MacCAR, allowing test-time computation to terminate adaptively when the model has sufficiently localized the target region. Our contributions can be summarized as follows: We propose ManCAR, framework guiding latent reasoning by interpreting collaborative neighborhoods in the interaction graph as feasibility constraints on the item probability simplex, mitigating latent drift. ManCAR further enables adaptive testtime computation via convergence-based stopping criterion. We theoretically establish variational interpretation of ManCAR, demonstrating how it prevents latent drift and confirm the validity of our adaptive test-time stopping mechanism. Experiments on benchmarks demonstrate that ManCAR consistently improves effectiveness over state-of-the-art baselines, achieving up to 46.88% relative improvement w.r.t. NDCG@10. Figure 2: Overview of ManCAR. ManCAR performs multistep latent reasoning constrained by graph-induced candidate set. At each step, the reasoning state is regularized toward scheduled teacher prior defined on collaboratively reachable items, ensuring manifold-consistent refinement. Adaptive test-time termination stops reasoning when the induced item distributions stabilize."
        },
        {
            "title": "2.1 Problem Setting and Notation\nLet I denote a finite set of items and U the set of users. We consider\nthe sequential recommendation setting, where each user ğ‘¢ âˆˆ U\ninteracts with items over time. For a given user, the interaction\nhistory is denoted by ğ» = (ğ‘–1, ğ‘–2, . . . , ğ‘–ğ‘‡ âˆ’1), ğ‘–ğ‘¡ âˆˆ I, where items are\nordered chronologically. The objective is to predict the next item\nğ‘–âˆ— = ğ‘–ğ‘‡ conditioned on the observed history ğ» .",
            "content": "We model collaborative signals among items using global item interaction graph = (I, E), where nodes correspond to items and edges encode co-interaction relationships aggregated across users. An edge (ğ‘–, ğ‘—) indicates that items ğ‘– and ğ‘— are frequently cointeracted or consecutively consumed by users. For an item ğ‘– I, we denote its ğ‘˜-hop graph neighborhood by (ğ‘–; G; ğ‘˜). ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Conference17, July 2017, Washington, DC, USA Following standard latent reasoning settings [31], we denote by hğ‘¡ Rğ‘‘ the hidden representation produced by the backbone encoder at step ğ‘¡, i.e., hğ‘¡ = ğ‘“ (ğ» [: ğ‘¡]), where ğ‘“ () is typically Transformer-based encoder. We further introduce rğ‘¡ Rğ‘‘ , ğ‘¡ {1, . . . ,ğ‘‡ }, to denote the latent reasoning states generated through iterative refinement. Unless otherwise specified, the initial reasoning state is set to the final encoder state, i.e., r1 = hğ‘‡ 1."
        },
        {
            "title": "2.2 Manifold-Constrained Latent Reasoning\nWe now articulate the core conceptual motivation behind ManCAR.\nAs discussed in Sec. 1, standard latent reasoning based methods\nsuffer from unconstrained degrees of freedom, leading to latent\ndrift. To address this, we propose a geometric perspective: reasoning\nshould not traverse the latent space freely but must be viewed as\nnavigation constrained to a â€œcollaborative manifoldâ€.",
            "content": "We adopt latent multi-step reasoning setting [31]. Starting from the final encoder state hğ‘‡ 1, the model generates sequence of reasoning states rğ‘¡ (ğ‘¡ {1, . . . ,ğ‘‡ }), each representing an intermediate hypothesis of user intent, and produces the final recommendation by decoding the last state. central challenge in this setting is that, without additional knowledge, the evolution of latent reasoning states is weakly constrained and exhibits excessive degrees of freedom, particularly in high-dimensional spaces. To address this issue, we introduce graph-conditioned feasibility constraint that explicitly restricts where latent reasoning can evolve. This design is motivated by fundamental property of recommender systems: user behavior is inherently collaborative, and given users most recent interactions ğ¼ğ‘› = (ğ‘–ğ‘‡ ğ‘›, . . . , ğ‘–ğ‘‡ 1) where ğ‘› denotes the window size of the recent interaction, only limited subset of items is plausibly relevant in the near future [36, 43]namely, those that are ğ‘˜-hop reachable on the collaborative item interaction graph G. From geometric perspective, this graph-conditioned neighborhood defines low-dimensional feasible region within the highdimensional item space. To operationalize this constraint during latent reasoning, we explicitly regulate how reasoning states are translated into item-level beliefs. Specifically, each reasoning state is mapped to an item probability distribution on the item probability simplex, and the graph-conditioned neighborhood restricts valid distributions to those that concentrate probability mass on collaboratively reachable items. This restriction defines structured subregion of the simplex, which we refer to as the collaborative manifold. Latent reasoning is therefore constrained to evolve along this manifold, rather than freely over the entire simplex as in unconstrained latent refinement  (Fig. 1)  . To make the collaborative manifold explicit and tractable, we instantiate it using finite set of collaboratively reachable items conditioned on the users most recent interactions. This set defines the feasible support of item probability distributions during latent reasoning. Concretely, we define finite candidate set: C(ğ¼ğ‘›, G, ğ‘˜) {ğ¼ğ‘› } (ğ¼ğ‘›; G; ğ‘˜). Unless otherwise specified, we use C(ğ‘˜) as shorthand for C(ğ¼ğ‘›, G, ğ‘˜), since the candidate set is always constructed from the most recent items ğ¼ğ‘› on the interaction graph in this paper. In the next subsection, we derive training objective from variational interpretation that leverages this graph-conditioned feasible set to regularize latent reasoning."
        },
        {
            "title": "2.3 Variational Training Objective\nWhile the manifold constraint provides a strong geometric intuition,\noptimizing it effectively requires a rigorous mathematical formu-\nlation. In this subsection, we translate the conceptual constraint\nfrom Sec. 2.2 into probabilistic variational inference. We derive\nan Evidence Lower Bound (ELBO)-like objective, treating latent\nreasoning as approximate inference over an intermediate intent\nvariable. This derivation introduces the â€œTeacher Priorâ€ distribution\ninduced from the interaction graph, guiding the implementation of\nthe loss function (Sec. 2.5) necessary to train the model.",
            "content": "Latent Variable Formulation. Given user history ğ» , we introduce discrete latent variable ğ‘ C(ğ‘˜) representing an intermediate intent prototype that mediates the prediction of the next item. The conditional likelihood of the target item can be written as ğ‘ğœƒ (ğ‘– ğ» ) = ğ‘ (ğ‘˜ ) ğ‘ğœƒ (ğ‘ ğ» ) ğ‘ğœƒ (ğ‘– ğ‘, ğ» ), where ğ‘ğœƒ (ğ‘ ğ» ) is history-conditioned intent distribution parameterized by ğœƒ , and ğ‘ğœƒ (ğ‘– ğ‘, ğ» ) models the likelihood of the target given the inferred intent. We restrict ğ‘ to lie in the graph-induced candidate set, reflecting the assumption that user intent at each reasoning step is best characterized by collaboratively reachable items. This design anchors latent intent to observable interaction patterns and aligns with the collaborative manifold constraint. Graph-Conditioned Variational Prior. Based on the above design, we introduce graph-conditioned teacher distribution ğ‘(ğ‘ ğ¼ğ‘›, G), defined over the candidate set C(ğ‘˜). It encodes prior knowledge about plausible intents reachable from the users most recent interaction, and is constructed independently of the model parameters ğœƒ . Intuitively, ğ‘ assigns higher probability mass to items that are strongly connected to ğ¼ğ‘› in the interaction graph. ELBO-like Objective. For any choice of ğ‘(ğ‘ likelihood admits the following lower bound: ğ¼ğ‘›, G), the loglog ğ‘ğœƒ (ğ‘– ğ» ) Eğ‘ (ğ‘ ğ¼ğ‘›,G) (cid:2) log ğ‘ğœƒ (ğ‘– ğ‘, ğ» )(cid:3) ğ·KL (ğ‘(ğ‘ ğ¼ğ‘›, G) ğ‘ğœƒ (ğ‘ ğ» )) , (1) where ğ·ğ¾ğ¿ ( ) is the KL-divergence. The derivation of Eq. 1 is provided in Appendix A. This formulation can be interpreted as an Evidence Lower Bound (ELBO). The first term encourages accurate target prediction under graph-feasible intents, while the KL term regularizes the models inferred intent distribution to align with the graph-conditioned prior. Connection to Context Engineering and Latent Reasoning. In practice, the first term in Eq. 1 encourages the model to predict the target item ğ‘– conditioned on both the user history ğ» and the intent prototype ğ‘. This requires injecting future candidate knowledge into the models input or conditioning pathway, which closely parallels Context Engineering for LLMs [22], where external or structured context is provided to guide prediction and reduce uncertainty. In our setting, the candidate set derived from the interaction graph serves as structured contextual knowledge that narrows the models predictive focus to collaboratively plausible regions. Conference17, July 2017, Washington, DC, USA Kun Yang et al. Meanwhile, the intent distribution ğ‘ğœƒ (ğ‘ ğ» ) is implicitly induced by latent reasoning states through models output layer, by projecting each latent state onto item probability simplex. Minimizing the KL divergence term aligns this induced distribution with the graph-conditioned prior, constraining each reasoning step to remain within the collaborative manifold supported by C(ğ‘˜). The variational regularization explicitly limits the freedom of latent refinement and mitigates latent drift during iterative reasoning."
        },
        {
            "title": "2.4 Local Graph Smoothness by KL Distillation\nThe variational objective in Eq. 1 introduces a KL-divergence regu-\nlarization term. To justify why this specific term is effective against\nlatent drift, we provide a theoretical analysis in this subsection.\nWe prove that minimizing this KL term induces a gradient flow\nthat promotes â€œlocal graph smoothnessâ€. This analysis bridges the\ngap between our probabilistic objective and the geometric mani-\nfold constraint, showing how the variational objective explicitly\nconfines the reasoning trajectory by collaboratively feasible items.",
            "content": "Proposition 2.1 (Local Graph Smoothness Induced by KL Distillation). Let be finite candidate set and eğ‘ Rğ‘‘ denote the embedding of item ğ‘ C. Given reasoning state Rğ‘‘ , define the induced predictive distribution as: ğ‘ƒ (ğ‘ ğ» ) = exp(reğ‘ ) (cid:205)ğ‘ exp(reğ‘ ) Let ğ‘„ be any fixed teacher distribution supported on C. Then the KL distillation loss (r) = ğ·KL (ğ‘„ ğ‘ƒ ( ğ» )) is differentiable with respect to r, with gradient ğ‘ C. , rL (r) = Eğ‘ƒ ( ğ» ) [eğ‘ ] Eğ‘„ [eğ‘ ]. The proof of Proposition 2.1 is provided in Appendix B. Interpretation. The distribution ğ‘ƒ ( ğ» ) defines point on the probability simplex over C, and its embedding expectation Eğ‘ƒ [eğ‘ ] lies in the convex hull of candidate embeddings conv{eğ‘ : ğ‘ C}. The teacher expectation Eğ‘„ [eğ‘ ] lies in the same region. Proposition 2.1 shows that KL distillation induces gradient flow that directly moves the prediction barycenter toward the teacher barycenter within this graph-restricted convex hull. As result, latent reasoning states are encouraged to evolve such that their induced predictions remain confined to graph-local embedding region defined by C. In ManCAR, is graph-conditioned candidate set derived from the most recent interactions, and ğ‘„ is scheduled teacher distribution supported on this set. Together, they impose local graph smoothness prior on latent reasoning: each refinement step reduces uncertainty while remaining restricted to collaboratively reachable items. Progressive sharpening of the teacher distribution yields stable coarse-to-fine trajectory on the simplex, mitigating latent drift during multi-step reasoning."
        },
        {
            "title": "2.5 Implementation of ManCAR Objective\nHaving established the theoretical validity of the variational train-\ning objective, we now turn to the implementation of ManCAR.\nIn this subsection, we describe how the variational objective in\nEq. 1 is instantiated in practice. Our implementation is designed to\nfaithfully realize the graph-conditioned manifold constraint while\nremaining compatible with standard latent reasoning paradigms.",
            "content": "Item Interaction Graph. We construct the item interaction graph using standard Swing-style item-to-item co-interaction algorithm that is widely adopted in industrial systems [38]. Each node corresponds to an item, and weighted edges encode collaborative strength measured by co-interaction frequency. As this graph construction follows established practice and is not contribution of this work, we defer algorithmic details to Appendix D. Concretely, the resulting graph associates each directed edge (ğ‘– ğ‘—) with weight ğ‘¤ğ‘– ğ‘— , indicating the strength of collaborative relevance of item ğ‘— with respect to item ğ‘–. Teacher Prior Construction. The variational objective in Equation (1) requires teacher distribution ğ‘(ğ‘ ğ¼ğ‘›, G) defined over the candidate set C(ğ‘˜). This distribution encodes prior knowledge about plausible intent prototypes that are collaboratively reachable from the users most recent interactions. In practice, we consider the following strategy to construct the teacher prior efficiently: Rank-Based Distribution Mass Assignment (RDMA). We construct the teacher prior based on the relative ranking of candidates. The target item ğ‘– is always assigned rank 0, while the remaining candidates in C(ğ‘˜) are ranked in descending order of their graph edge weights ğ‘¤ğ¼ğ‘›,ğ‘ (from recent interacted item in ğ¼ğ‘› to its neighbor ğ‘), receiving ranks [1, 2, . . . ]. The probability mass is then assigned using softmax over negative ranks, ğ‘(ğ‘ ğ¼ğ‘›, G) = exp(rank(ğ‘)/ğ›¾) (cid:205)ğ‘› (ğ‘˜ ) exp(rank(ğ‘›)/ğ›¾) , (2) where ğ›¾ > 0 controls the sharpness of the teacher distribution. Using negative ranks ensures that higher-ranked (i.e., more strongly connected) items and the target receive the larger probability mass. This strategy ensures that the teacher prior is strictly supported on the collaborative neighborhood while emphasizing the target item. By default, we assign zero probability mass to non-candidate items, resulting in teacher distribution that lies on sparse region of the item probability simplex with only small number of active entries. Alternatively, small amount of probability mass can be distributed over non-candidate items as form of label smoothing, which we find does not materially affect the main conclusions. dynamic scheduling is applied to the teacher prior distributions to guide latent reasoning progressively toward the target by adjusting the concentration of the teacher distribution across reasoning steps. As this scheduling mechanism is closely tied to adaptive test-time termination, we defer its detailed formulation to Sec. 2.6. Training Loss. The complete training objective instantiates the ELBO derived in Eq. 1 and consists of target prediction loss and graph-conditioned manifold regularization loss, both applied at each reasoning step. Latent Reasoning and Decoding. At reasoning step ğ‘¡ , the model produces latent reasoning state rğ‘¡ Rğ‘‘ , obtained by iteratively refining the initial state r1 = hğ‘‡ 1 = ğ‘“ğœƒ (ğ» ) through shared reasoning module ğ‘“ğœƒ (). Concretely, the refinement follows ğ‘Ÿğ‘¡ = ğ‘“ğœƒ (ğ» ; ğ‘Ÿ1:ğ‘¡ 1). Then each latent reasoning state rğ‘¡ is projected onto the item space to produce logits: zğ‘¡ = ğ‘¡ E, ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Conference17, July 2017, Washington, DC, USA where Rğ‘‘ denotes the item embedding matrix. The logits define an item probability distribution over via temperaturescaled softmax, ğ‘ (ğ‘¡ ) ğœƒ (ğ‘– ğ» ) = exp(cid:0)zğ‘¡ ,ğ‘– /ğœğ‘¡ (cid:1) (cid:205)ğ‘— exp(cid:0)zğ‘¡ ,ğ‘— /ğœğ‘¡ (cid:1) . (ğ‘ ğ» ) by restricting ğ‘ to the candidate set C(ğ‘˜). We use this same distribution to represent the intent distribution ğ‘ (ğ‘¡ ) ğœƒ Target Prediction Loss. Following the ELBO in Eq. 1, the target prediction term at reasoning step ğ‘¡ is given by (ğ‘¡ ) main = Eğ‘ğ‘ ( ğ¼ğ‘›,G) (cid:2) log ğ‘ (ğ‘¡ ) ğœƒ (ğ‘– ğ», ğ‘)(cid:3) . In practice, explicitly marginalizing over ğ‘ C(ğ‘˜) at each reasoning step is costly and unnecessary. Instead, we adopt standard conditioning strategy by exposing the entire candidate set C(ğ‘˜) to the model as additional contexts (like context engineering). Concretely, we approximate the above expectation by: main = log ğ‘ (ğ‘¡ ) (ğ‘¡ ) (ğ‘– ğ», C(ğ‘˜)), ğœƒ where C(ğ‘˜) is injected as auxiliary input alongside the history ğ» . (3) Graph-Conditioned Manifold Regularization. To enforce graphconditioned feasibility, the induced distribution at each step is regularized toward the teacher prior via (ğ‘¡ ) reg = ğ·KL (cid:16) ğ‘(ğ‘ ğ¼ğ‘›, G) ğ‘ (ğ‘¡ ) ğœƒ (ğ‘ ğ» ) (cid:17) . (4) This term restricts latent reasoning trajectories to remain within the collaborative manifold defined by C(ğ‘˜) and mitigates latent drift. To reduce computation, the student distribution ğ‘ (ğ‘¡ ) (ğ‘ ğ» ) can be obtained from the same forward pass used for target prediction ğœƒ Overall Objective. The complete training objective is as follows: = ğ‘‡ (cid:16) ğ‘¡ =1 main + ğœ†L (ğ‘¡ ) (ğ‘¡ ) reg (cid:17) , (5) where ğœ† controls the strength of graph-conditioned regularization. Appendix provides the detailed training algorithm of ManCAR."
        },
        {
            "title": "2.6 Training Scheduling and Adaptive",
            "content": "Test-Time Reasoning We now introduce dynamic scheduling mechanism that sharpens the teacher distribution over time and present theoretical proposition regarding bounded error. This analysis not only guides the training schedule but also naturally motivates our convergencebased stopping criterion, enabling adaptive test-time reasoning. Appendix provides the detailed adaptive reasoning algorithm. Proposition 2.2 (Continuation tracking under contraction and bounded teacher drift). Fix query ğ» and finite candidate set = C(ğ‘˜). Let Î”(C) denote the item probability simplex over C. Consider distribution sequences {ğ‘ğ‘¡ }ğ‘¡ 1 Î”(C) (student) and {ğ‘ğ‘¡ }ğ‘¡ 1 Î”(C) (scheduled teacher), and let ğ‘‘TV (ğ‘, ğ‘) := 1 2 ğ‘ ğ‘ (ğ‘) ğ‘(ğ‘) be the total variation distance. We assume: (1) Stepwise contraction toward the current teacher: There exists ğœ† (0, 1) such that for all ğ‘¡ 1, ğ‘‘TV (ğ‘ğ‘¡ +1, ğ‘ğ‘¡ ) (1 ğœ†) ğ‘‘TV (ğ‘ğ‘¡ , ğ‘ğ‘¡ ). (6) (2) Bounded teacher drift (controlled schedule): There exists ğ›¿ 0 such that for all ğ‘¡ 1, ğ‘‘TV (ğ‘ğ‘¡ +1, ğ‘ğ‘¡ ) ğ›¿. Then for all ğ‘¡ 1, ğ‘‘TV (ğ‘ğ‘¡ , ğ‘ğ‘¡ ) (1 ğœ†)ğ‘¡ 1 ğ‘‘TV (ğ‘1, ğ‘1) + ğ›¿ ğœ† . (7) (8) We provide the proof of Proposition 2.2 in Appendix C. Proposition 2.2 shows that, if each refinement step contracts the student toward the current teacher and the teacher distribution evolves smoothly, then the student distribution can track progressively changing teacher with bounded error. This provides formal motivation for using coarse-to-fine teacher schedule during training. The proposition is stated in total variation (TV) distance to leverage its metric properties. In ManCAR, refinement is trained via KL distillation rather than TV. To bridge this gap, we invoke Pinskers inequality, which guarantees that for any distributions ğ‘, ğ‘ on C, 1 ğ‘‘TV (ğ‘, ğ‘) 2 ğ·KL (ğ‘ ğ‘). Hence, minimizing the KL loss ensures small student-teacher mismatch in TV, providing conservative stability guarantee for the continuation tracking behavior described in Proposition 2.2. Teacher Scheduling Strategies. We extend the teacher construction (Sec. 2.5) into scheduled mechanism that generates smoothly evolving sequence of teacher distributions across reasoning steps. Adjustment for Strategy RDMA. We define the teacher as: ğ‘ğ‘¡ (ğ‘) exp(cid:0) rank(ğ‘)/ğ›¾ğ‘¡ (cid:1), ğ›¾ğ‘¡ = ğ›¾base (ğ‘‡ ğ‘¡ + 1), with ğ›¾base 1. As ğ›¾ğ‘¡ decreases linearly, the teacher distribution transitions smoothly from diffuse graph-aware prior to sharply peaked distribution centered on the target. Properly tuning ğ›¾base and total steps ğ‘‡ yields smoothly evolving teacher distribution with bounded drift across refinement steps (satisfying Assumption (2) in Proposition 2.2). Connection to Adaptive Test-Time Reasoning. The continuation view provided by Proposition 2.2 directly motivates adaptive termination at test time. Since the student distribution ğ‘ğ‘¡ tracks the scheduled teacher with bounded error, convergence of successive student distributions indicates that further refinement yields diminishing returns. We therefore terminate reasoning early when the change between consecutive steps falls below threshold, e.g., ğ·KL (ğ‘ğ‘¡ 1 ğ‘ğ‘¡ ) < ğœ€. Scheduling the Main Prediction Loss. In addition to scheduling the teacher prior, we apply step-dependent temperature schedule to the main target prediction loss to control the magnitude of distributional updates induced by target supervision at each reasoning step. Concretely, we use an exponential temperature schedule: ğœğ‘¡ = ğœbase ğ‘¡ ğ›¼, Conference17, July 2017, Washington, DC, USA Kun Yang et al. where ğ›¼ > 1 controls ğœğ‘¡ increasing magnitude, which yields an increasing temperature sequence across reasoning steps with flexible initial temperature base ğœbase. From the continuation perspective formalized in Proposition 2.2, supervising all refinement steps with an identical, sharply peaked target loss may induce overly large early updates that violate the bounded-drift and contraction conditions, potentially destabilizing manifold-constrained reasoning. By starting with low effective temperature, early refinement steps are encouraged to make conservative progress (near the local neighborhood of recent user interactions), while remaining within the graph-consistent manifold. This design is related in spirit to progressive refinement losses such as the PRL mechanism in ReaRec [31], but differs in directionality. Whereas ReaRec adopts decreasing temperature schedule to accelerate early-stage convergence, our increasing-temperature design aligns with our theoretical analysis and supports stable multi-step reasoning and adaptive test-time termination. Stabilizing Optimization via Latent State Norm Rescaling. In addition to scheduling-based control, we apply normalization to stabilize multi-step latent reasoning. After each refinement step, we rescale the latent reasoning state as: ğœ™ avg(E), where avg(E) denotes the average norm of item embeddings, and ğœ™ is learnable affine scaling parameter. This operation aligns the scale of latent states with that of the item embedding space. This rescaling alleviates the burden on the Transformer to simultaneously accommodate heterogeneous modalities with mismatched norms between original input items and latent reasoning states. By keeping latent states on scale comparable to item embeddings, this normalization mitigates empirical norm growth with (recursive) depth [27], improves stability in longhorizon reasoning, and complements the manifold-constrained and continuation-based design of ManCAR. In particular, it helps maintain well-conditioned softmax geometry during refinement, which empirically supports the stepwise contraction behavior assumed in Proposition 2.2 (facilitating Assumption (1))."
        },
        {
            "title": "3 Experiments\nOur empirical study is guided by the following research questions:\n(1) Overall performance. How does ManCAR perform compared with\nstrong sequential recommendation baselines across standard bench-\nmarks? (2) Effect of teacher scheduling and adaptive reasoning. How\ndo teacher scheduling and adaptive termination shape step-wise\nrefinement behavior and enable near-ceiling performance during\ninference? (3) Ablation analysis. What is the impact of individual\ncomponents in ManCAR? (4) Parameter sensitivity. How sensitive\nis ManCAR to key hyperparameters? (5) KL-Based Halting Analysis.\nHow does the KL divergence between steps reflect the stability of\nthe reasoning trajectory? (6) Attention Visualization Analysis. What\ndo attention patterns reveal about the information flow within the\nmanifold-constrained design?",
            "content": "Table 1: Dataset statistics. Dataset #Users #Items #Interactions #Avg. Inter./User #Avg. Inter./Item CDs Video Office Arts Music Toys Grocery 35,238 54,001 118,617 112,401 15,685 244,231 246,304 87,969 22,735 64,679 77,596 21,171 134,676 119,860 943,399 562,193 1,116,568 1,180,363 221,980 2,515,203 2,788,430 26.77 10.41 9.41 10.50 14.15 10.30 11. 10.72 24.73 17.3 15.21 10.49 18.68 23.26 3.1.1 Datasets and Preprocess. We evaluate ManCAR on seven subcategory datasets from the Amazon 2023 Reviews corpus [12]: CDs & Vinyl (CDs), Video & Games (Video), Office Products (Office), Arts, Crafts & Sewing (Arts), Grocery & Gourmet Food (Grocery), Musical Instruments (Music), and Toys & Games (Toys). Tab. 1 provides data statistics. Following prior work [20, 30, 31], useritem interactions with ratings above 3 are treated as positive feedback. To improve data quality, we remove users with fewer than 10 interactions in CDs and fewer than 5 interactions in the remaining datasets. We adopt the official absolute-timestamp split provided by the corpus.1 Consistent with previous studies [20, 30, 31], we truncate each users interaction history to maximum length of 50. 3.1.2 Evaluation Metrics. To evaluate the performance of our proposed model and the baselines, we employ two widely-used metrics: Recall@ğ¾ and Normalized Discounted Cumulative Gain (NDCG@ğ¾), with ğ¾ {5, 10}. Specifically, Recall@ğ¾ measures the models ability to include the ground-truth item within the top-ğ¾ recommendation list, reflecting its retrieval coverage. NDCG@ğ¾ further assesses the ranking quality by assigning higher weights to items at higher positions, thereby rewarding models that prioritize the correct item in more prominent ranks. 3.1.3 Baselines. We compare ManCAR with representative stateof-the-art baselines spanning different modeling paradigms. Specifically, we include: (1) SASRec [15]: Utilizing unidirectional Transformer encoder, SASRec represents users by the final item in their interaction sequence. (2) BERT4Rec [26]: adopts bidirectional approach inspired by BERT, training the model to reconstruct masked items within the sequence. (3) ContextBERT4Rec: extends BERT4Rec by using the same context engineering as ManCAR. (4) ReaRec-ERL [31]: As pioneer in latent space reasoning, this model treats the reasoning process as collective trajectory. Instead of relying on single state, it synthesizes the implicit information from all autoregressive steps using mean pooling mechanism to form comprehensive user representation. (5) ReaRec-PRL [31]: In contrast to ERL, this variant emphasizes iterative optimization. It leverages contrastive learning with noise injection to progressively distill the latent representation, discarding intermediate states to rely solely on the converged output of the final reasoning step."
        },
        {
            "title": "3.1 Experimental Setup",
            "content": "1https://amazon-reviews-2023.github.io/data_processing/5core.html ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Conference17, July 2017, Washington, DC, USA (6) LARES [20]: This framework introduces pre-blocks and coreblocks. To maximize reasoning fidelity, it adopts hybrid training pipeline that sequentially applies self-supervised pre-training followed by reinforcement learning-based fine-tuning. (7) PLR [30]: width-scaled (parallel) latent reasoning framework for sequential recommendation that launches multiple parallel reasoning streams via learnable trigger tokens, enforces interstream diversity with global reasoning regularization, and adaptively fuses the stream outputs (mixture-of-streams) to improve next-item prediction. Implementation. We conduct all experiments on eight 3.1.4 NVIDIA 3090 GPUs. To ensure fair comparison, we set the embedding size and batch size for all methods to 256 and 512, respectively. We optimize all models using the Adam optimizer with learning rate of 0.001. For baselines without open-source code, we conducted our own implementation. For those with available source code, we utilized the official implementations. All baselines were tuned via grid search based on the hyperparameters specified in their original papers, and the optimal results are reported. To mitigate overfitting, we employ early stopping, terminating training if NDCG@10 on the validation set shows no improvement for 5 consecutive epochs. Following prior work [31], we adopt pre-norm Transformer backbone. It consists of two Transformer layers, each with two-head multi-head self-attention and GeLU activation."
        },
        {
            "title": "3.2 Overall Performance (Tab. 2).\nManCAR outperforms all baselines. ManCAR achieves the best\nperformance across all datasets and evaluation metrics, demonstrat-\ning consistent improvements in both ranking and retrieval quality.\nCompared with the second-best method on each dataset, ManCAR\ndelivers up to a 46.88% relative improvement on certain metrics.\nNotably, the gains are more pronounced on NDCG, indicating that\nManCAR is particularly effective at ranking relevant items higher,\nwhich reflects a stronger ability to capture and refine user intent.",
            "content": "ContextBERT4Rec outperforms BERT4Rec, highlighting the benefit of graph-induced context. ContextBERT4Rec augments the input sequence with the same graph-conditioned candidate set used by ManCAR, enabling the model to leverage collaborative signals beyond the independent raw user interaction sequence. Its consistent improvement over BERT4Rec suggests that incorporating graph-induced context serves as an effective form of context engineering for sequential recommendation. Explicit latent reasoning consistently improves sequential recommendation. ContextBERT4Rec represents the strongest non-reasoning baseline by incorporating graph-conditioned context into the input. Across all datasets, ManCAR achieves notable gains over ContextBERT4Rec, demonstrating that explicit multistep reasoning provides additional modeling capacity beyond contextual encoding alone. More broadly, all reasoning-based methods (ManCAR, ERL, PRL, PLR, and LARES) outperform non-reasoning baselines like SASRec and BERT4Rec, suggesting that iterative refinement of intermediate hypotheses enables more effective uncertainty resolution and user intent modeling, particularly in sparse or challenging settings. Figure 3: Performance ceiling analysis on Office and Toys. ManCAR consistently outperforms existing latent reasoning approaches. Across all datasets, ManCAR achieves consistent gains over prior reasoning-based methods such as ERL, PRL, PLR, and LARES. While these methods introduce latent refinement or progressive reasoning, they typically lack explicit constraints on how reasoning trajectories evolve. In contrast, ManCAR integrates graph-conditioned manifolds, scheduled teacher supervision, and adaptive test-time control, which together provide more structured and stable reasoning process. By explicitly controlling the feasible manifold region and stepwise dynamics of latent refinement, ManCAR is better able to exploit collaborative signals and avoid unstable or suboptimal reasoning paths, leading to better performance with varying data sparsity and sequence lengths. Performance gains increase with higher interaction density. ManCAR exhibits larger performance margins over the second-best baseline on datasets with higher interaction density (average interactions per item). For instance, improvements are more pronounced on Video and Toys than on Music and Arts. This trend suggests that ManCAR benefits from reduced sparsity, where multi-step reasoning can more effectively refine user intent by leveraging more reliable item interaction graph and richer collaborative signals. When interactions are sparse, graph edge connection become noisier, which limits the advantage of graph-conditioned reasoning over strong baselines. Improving robustness under limited preference evidences (cold start) is left for future work."
        },
        {
            "title": "3.3 In-Depth Analysis in Adaptive Reasoning\nWe analyze ManCARâ€™s adaptive reasoning ability from two angles.",
            "content": "Data-Aware Train-Test Compute Allocation. Tab. 3 summarizes the reasoning-step configurations at which different reasoning methods achieve their best performance. Baselines adopt identical and shallow reasoning depths at both stages, typically limited to 2-3 steps, regardless of data characteristics. This indicates that reasoning depth is treated as static architectural hyperparameter. In contrast, ManCAR exhibits data-aware and asymmetric traintest computation. The optimal number of training and inference steps varies substantially across datasets, reflecting differences in data sparsity and sequence complexity. On datasets with complex interaction patterns, such as CDs and Toys, ManCAR employs deeper reasoning and achieves significantly larger performance gains, while prior methods are unable to adapt beyond 3 steps. Conference17, July 2017, Washington, DC, USA Kun Yang et al. Table 2: Performance comparison on seven datasets. The best results are in bold and the second best results are underlined. Dataset Metric SASRec BERT4Rec ContextBERT4Rec ERL CDs Video Office Arts Music Toys Grocery NDCG@5 NDCG@10 Recall@5 Recall@ NDCG@5 NDCG@10 Recall@5 Recall@10 NDCG@5 NDCG@10 Recall@5 Recall@10 NDCG@5 NDCG@10 Recall@5 Recall@10 NDCG@5 NDCG@10 Recall@5 Recall@10 NDCG@5 NDCG@10 Recall@5 Recall@10 NDCG@5 NDCG@10 Recall@5 Recall@ 0.0098 0.0132 0.0181 0.0286 0.0083 0.0104 0.0164 0.0226 0.0063 0.0077 0.0113 0.0157 0.0019 0.0026 0.0037 0.0057 0.0017 0.0027 0.0033 0.0061 0.0037 0.0048 0.0072 0. 0.0028 0.0038 0.0055 0.0085 0.0110 0.0130 0.0207 0.0269 0.0070 0.0091 0.0131 0.0196 0.0061 0.0078 0.0109 0.0160 0.0014 0.0023 0.0028 0.0055 0.0014 0.002 0.0026 0. 0.0045 0.0059 0.0086 0.0127 0.0026 0.0035 0.0085 0.0078 0.0148 0.0182 0.0243 0.0391 0.0119 0.0163 0.0190 0.0330 0.0076 0.0093 0.0129 0.0184 0.0044 0.0059 0.0082 0. 0.0049 0.0059 0.0086 0.0118 0.0051 0.0063 0.0089 0.0126 0.0044 0.0059 0.0079 0.0126 0.0099 0.0129 0.0190 0.0283 0.0149 0.0187 0.0217 0.0336 0.0079 0.0107 0.0144 0. 0.0052 0.0082 0.0086 0.0177 0.0066 0.0095 0.0124 0.0215 0.0054 0.0073 0.0102 0.0160 0.0062 0.0087 0.0102 0.0180 PRL 0.0122 0.0149 0.0227 0. 0.0165 0.0215 0.0253 0.0410 0.0071 0.0096 0.0127 0.0205 0.0072 0.0097 0.0118 0.0196 0.009 0.0117 0.0138 0.0225 0.0046 0.0064 0.0082 0.0136 0.0072 0.0098 0.0118 0. PLR LARES ManCAR 0.0131 0.0168 0.0249 0.0363 0.0159 0.0210 0.0312 0.0467 0.0082 0.0109 0.0139 0. 0.0068 0.0092 0.0106 0.0181 0.0058 0.0084 0.0111 0.0191 0.0052 0.0068 0.0096 0.0148 0.0078 0.0105 0.0124 0.0218 0.0159 0.0192 0.0235 0.0351 0.0162 0.0219 0.0277 0. 0.0090 0.0115 0.0161 0.0240 0.0077 0.0101 0.0119 0.0196 0.0063 0.0092 0.0117 0.0205 0.0061 0.0082 0.0115 0.0180 0.0063 0.0088 0.0119 0.0197 0.0198 0.0282 0.0346 0. 0.0217 0.0275 0.0339 0.0521 0.0108 0.0133 0.0174 0.0250 0.0087 0.0114 0.0141 0.0225 0.0097 0.0120 0.0147 0.0217 0.0086 0.0108 0.0136 0.0203 0.0095 0.0118 0.0149 0. Uplift 24.53 % 46.88 % 38.96 % 31.97 % 31.52 % 25.57 % 8.65 % 11.56 % 20.00 % 15.65 % 8.07 % 4.17 % 12.99 % 12.87 % 18.49 % 14.80 % 7.78 % 2.56 % 6.52 % -3.56 % 40.98 % 31.71 % 18.26 % 12.78 % 21.79 % 12.38 % 20.16 % 0.92 % Table 3: Best performing step setting of reasoning-based methods on four datasets. See Appendix F.1 for full results. Dataset CDs Arts Toys Grocery Reason step ERL Train step Infer step Train step Infer step Train step Infer step Train step Infer step 2 2 2 2 1 1 2 2 PRL 2 2 2 2 2 2 2 2 PLR LARES ManCAR 3 3 1 1 1 1 3 3 4 4 4 4 4 4 4 4 5 1.84 1 1 4 3.58 2 1.74 Conversely, on simpler datasets such as Arts and Grocery, ManCAR stops early at inference, avoiding unnecessary computation while still outperforming baselines which over-allocate reasoning steps. Overall, these results indicate that ManCAR performs genuine iterative refinement with adaptive inference depth, enabling an effective balance between reasoning expressiveness and computational efficiency across diverse data properties. that selects the best-performing step per sample using groundtruth labels (ManCAR-ceiling). These results are compared with ContextBERT4Rec, non-reasoning variant of ManCAR. When ManCAR is forced to use fixed (symmetric) number of reasoning steps, performance degrades relative to adaptive halting, though it remains closer to the ceiling than the non-reasoning variant. In contrast, adaptive reasoning consistently outperforms the symmetric setting and achieves performance that is very close to the oracle ceiling, indicating effective reasoning and termination. In contrast, prior reasoning-based methods such as PLR [30] and ReaRec [31] (including PRL and ERL) also report ceiling performance, but exhibit substantially larger gap between their actual inference performance and the ceiling. This highlights ManCARs ability to translate iterative refinement into near-optimal test-time behavior, rather than relying on fixed reasoning budget."
        },
        {
            "title": "3.4 Ablation Study (Tab. 4).",
            "content": "Near-Optimal Reasoning through the Lens of Ceiling Performance Analysis. Fig. 3 showcases step-wise performance analysis of ManCAR. We report three variants: (i) the prediction from the final reasoning step (ManCAR-last-step), (ii) adaptive halting based on convergence (ManCAR), and (iii) an oracle ceiling Graph-driven manifold constraint (w/o teacher prior) results in the largest performance drop among ManCAR variants, though it still outperforms ContextBERT4Rec. This indicates that graph context alone provides limited gains, while the absence of teacher guidance makes target-driven reasoning susceptible to latent drift. ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Conference17, July 2017, Washington, DC, USA Table 4: Ablation results on CDs and Video. Video CDs method ManCAR w/o Teacher Prior w/o Context w/o Norm Rescale w/o Schedule w/ Decrease Schedule N@10 0.0282 0.0212 0.0234 0.0277 0.0261 0.0273 R@10 0.0516 0.0436 0.0469 0.0513 0.0496 0.0490 N@10 0.0275 0.0231 0.0265 0.0271 0.0251 0.0250 R@10 0.0521 0.0445 0.0497 0.0515 0.0491 0. Context engineering (w/o context). Removing candidate-set context injection causes clear performance drop, though this variant still outperforms ReaRec-style baselines. This suggests that teacher guidance alone can partially steer reasoning, while injecting graph-conditioned candidates as auxiliary context further narrows the predictive search space and improves target localization. Latent state norm rescaling (w/o rescaling). Removing this module causes consistent performance drop, highlighting its role in aligning latent states with item embeddings. This normalization mitigates empirical norm growth and improves numerical stability, supporting stable stepwise refinement in multi-step reasoning. Loss scheduling (w/o schedule or decreasing schedule). Removing the schedule or adopting decreasing one in target prediction loss leads to clear performance degradation. This agrees with our analysis (Proposition 2.2) that conservative early updates helps to preserve manifold-walking stability and avoids premature convergence associated with decreasing schedules."
        },
        {
            "title": "3.6 KL-Based Halting Analysis\nWe report the KL divergence between consecutive reasoning steps\non two datasets, CDs and Video. For each test batch, we compute the\naverage KL divergence across samples and then report the mean and\nvariance across batches. As shown in Fig. 6, after sufficient training,\nthe KL divergence between adjacent reasoning steps decreases\nsharply, indicating stable convergence of the reasoning trajectory\nas expected.",
            "content": "Figure 4: Sensitivity analysis on Video and CDs. (a) and (b): NDCG@10 and Recall@10 w.r.t. #context items; (c) and (d): NDCG@10 and Recall@10 w.r.t. regularization loss weight ğœ†; (e) and (f): NDCG@10 and Recall@10 w.r.t. temperature ğœbase; (g) and (h): NDCG@10 and Recall@10 w.r.t. ğ›¾base. Figure 5: NDCG@10 w.r.t. reason step ğ‘‡ on CDs and Office."
        },
        {
            "title": "3.7 Attention Visualization Analysis\nThe attention heatmaps in Fig. 7 (two layers with two heads, with\ntokens partitioned into Context C, Interaction History H, and Rea-\nsoning Steps R) reveal a consistent routing pattern that aligns with\nManCARâ€™s manifold-constrained latent reasoning design. Across\nall heads, we observe a prominent concentration of attention mass\nfrom reasoning tokens toward a small subset of context positions\n(i.e., strong vertical bands within the ğ¶ region), while the H re-\ngion is comparatively diffuse and weaker. This indicates that the",
            "content": "Conference17, July 2017, Washington, DC, USA Kun Yang et al."
        },
        {
            "title": "4 Related Work\n4.1 Sequential Recommendation\nAs a core paradigm in recommendation, sequential recommendation\ncaptures user preferences to forecast the next item of interest.",
            "content": "Non-LLM-Based sequential recommendation evolves from sequential pattern mining [41] and Markov chains [10, 11] to recent deep learning approaches [15, 26]. Detailed surveys on non-LLMBased sequential recommendation are available in [6, 32]. Recently, the emergence of LLMs has greatly affected the field of sequential recommendation, diverging into two paradigms [13]: (1) LLM-Augmented sequential recommendation uses LLMs as feature extractors. LLMSeq [9] and SAID [13] utilize LLM-derived embeddings for initialization and semantic alignment. Meanwhile, LRD [37] and SERALM [24] leverage language knowledge to discover latent relations and refine generation via feedback from IDbased recommenders. (2) LLM-Centric sequential recommendation employs the LLM as the predictor. Methods range from processing item sentences (RecFormer [18]) and ID sequences (E4SRec [19]) to managing long sequences via summarization (LLM-TRSR [47]). Other works enhance reasoning through intent-driven prompting (LLM4ISR [28]) and self-reflection agents (Re2LLM [34]). Besides, there is burgeoning sequential recommendation paradigm called generative sequential recommendation [23, 29, 33, 46] that replaces pre-fixed item IDs with identifiers constructed from generated tokens. By synthesizing tokens, these methods better leverage content to encode item semantics directly into the ID structure. However, this direction remains under-explored due to optimization challenges, such as the difficulty of distinguishing similar items with identical token sequences [48]."
        },
        {
            "title": "4.2 Reasoning-Enhanced Recommendation\nReasoning-enhanced recommendation augments sequential rec-\nommendation with deliberative capabilities. It can be categorized\ninto Explicit Reasoning (using visible, text-based chains) and Latent\nReasoning (employing implicit, internal computation) to enhance\nrecommendation accuracy.",
            "content": "Explicit Reasoning-Enhanced Recommendation. Explicit reasoning approaches leverage the generative capabilities of LLMs to articulate the decision-making process through interpretable text or symbolic chains. R2ec [44] introduces unified dual-head architecture that simultaneously generates reasoning chains and predicts items. This design significantly reduces inference latency. ReasoningRec [1] bridges recommendations and explanations, and it uses CoT prompting to distill LLMs synthetic reasoning into smaller model. Reason4Rec [7] formulates the deliberative recommendation task that incorporates explicit reasoning about user preferences as an alignment goal and enhances models reasoning capabilities utilizing verbalized user feedback in step-wise manner. Figure 6: KL divergence between two adjacent step ğ‘¡ 1 and ğ‘¡ w.r.t. inference steps ğ‘¡ . Figure 7: Attention Analysis of ManCAR on CDs. Attention scores are averaged over 1024 randomly sampled user histories from the test set. intermediate reasoning states do not evolve in free-form manner; instead, they repeatedly query the injected candidate context C(ğ‘˜) during refinement. Moreover, the deeper layer exhibits sharper and more structured attention: the ğ‘… ğ¶ concentration becomes stronger, and we also see increased self-referential aggregation near the ğ‘… boundary (visible as emphasis close to the rightmost columns / bottom-right region). This suggests that later layers increasingly perform interstep consolidation, integrating previous reasoning states while still grounding each update in the graph-conditioned candidate set. Additionally, recent user interactionsparticularly the latest actionreceive consistently larger attention scores, reflecting the recency bias commonly observed in practical recommender systems. Together, this indicates that ManCAR is building the data channel: Recent Action Graph-Anchors (neighbors) Reasoning States to achieve adaptive, stable, and constrained refinement within the local intent manifold. ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Conference17, July 2017, Washington, DC, USA Exp3rt [16] distills reasoning capabilities into student LLM via three-step process: preference extraction, profile construction, and prediction. It effectively utilizes rich review data for personalized recommendation. OneRec-Think [21] introduces Think-Ahead architecture that seamlessly integrates dialogue, reasoning, and personalized recommendation. RecGPT [42] employs Hierarchical Multi-Agent System for agentic intent reasoning and hybrid representation for efficiency, thereby solving the scalability issues of its predecessor, yet the complex multi-agent coordination introduces new challenges in system stability and debugging. Latent Reasoning-Enhanced Recommendation. Inspired by latent reasoning for LLMs [8], recent sequential recommendation models have adopted latent reasoning to perform multi-step deliberation before prediction, without requiring explicit CoT data. ReaRec [31] pioneers inference-time computing by autoregressively feeding the last hidden state back into the encoder to enhance performance. OnePiece [3] applies latent reasoning to industrial retrieval and ranking by integrating context engineering with blockwise latent reasoning to progressively refine user intent. LARES [20] employs depth-recurrent latent reasoning that leverages all the input tokens to perform multi-step reasoning. PLR [30] introduces width-level scaling paradigm that explores diverse reasoning paths simultaneously via parallel streams to alleviate diminishing returns as reasoning depth increases."
        },
        {
            "title": "5 Conclusion\nWe proposed ManCAR, a manifold-constrained latent reasoning\nframework for sequential recommendation. By restricting latent\nrefinement to a graph-locality-induced manifold and guiding it with\nprogressive teacher supervision towards the target item, ManCAR\nenables stable and structured multi-step reasoning. A continuation-\nbased analysis motivates both the teacher scheduling strategy and\nadaptive test-time termination. Extensive experiments on seven\npublic datasets demonstrate that ManCAR consistently outperforms\nstrong sequential and reasoning-based baselines, yielding substan-\ntial improvements in retrieval and ranking quality. These results\nhighlight the importance of explicit constraints over latent rea-\nsoning with concrete collaborative signals, and position ManCAR\nas a principled approach for controllable reasoning in sequential\nrecommendation.",
            "content": "References [1] Millennium Bismay, Xiangjue Dong, and James Caverlee. 2025. ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning. In NAACL (Findings). 81328148. [2] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng Jin, and Yong Li. 2021. Sequential Recommendation with Graph Neural Networks. In SIGIR. 378387. [3] Sunhao Dai, Jiakai Tang, Jiahua Wu, Kun Wang, Yuxuan Zhu, Bingjun Chen, Bangyang Hong, Yu Zhao, Cong Fu, Kangle Wu, Yabo Ni, Anxiang Zeng, Wenjie Wang, Xu Chen, Jun Xu, and See-Kiong Ng. 2025. OnePiece: Bringing Context Engineering and Reasoning to Industrial Cascade Ranking System. arXiv Preprint (2025). https://arxiv.org/abs/2509.18091 [4] Yashar Deldjoo, Zhankui He, Julian J. McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, RenÃ© Vidal, Maheswaran Sathiamoorthy, Atoosa Kasirzadeh, and Silvia Milano. 2024. Review of Modern Recommender Systems Using Generative Models (Gen-RecSys). In KDD. 64486458. [5] Jingcheng Deng, Liang Pang, Zihao Wei, Shicheng Xu, Zenghao Duan, Kun Xu, Yang Song, Huawei Shen, and Xueqi Cheng. 2025. Latent Reasoning in LLMs as Vocabulary-Space Superposition. arXiv Preprint (2025). https://arxiv.org/abs/ 2510.15522 [6] Hui Fang, Danning Zhang, Yiheng Shu, and Guibing Guo. 2020. Deep Learning for Sequential Recommendation: Algorithms, Influential Factors, and Evaluations. ACM Trans. Inf. Syst. 39, 1 (2020), 10:110:42. [7] Yi Fang, Wenjie Wang, Yang Zhang, Fengbin Zhu, Qifan Wang, Fuli Feng, and Xiangnan He. 2025. Reason4Rec: Large Language Models for Recommendation with Deliberative User Preference Alignment. arXiv Preprint (2025). https: //arxiv.org/abs/2502.02061 [8] Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, and Yuandong Tian. 2024. Training Large Language Models to Reason in Continuous Latent Space. arXiv Preprint (2024). https://arxiv.org/abs/2412.06769 [9] Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Dietmar Jannach, and Marios Fragkoulis. 2023. Leveraging Large Language Models for Sequential Recommendation. In RecSys. 10961102. [10] Ruining He, Chen Fang, Zhaowen Wang, and Julian J. McAuley. 2016. Vista: Visually, Socially, and Temporally-aware Model for Artistic Recommendation. In RecSys. 309316. [11] Ruining He and Julian J. McAuley. 2016. Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation. In ICDM. 191200. [12] Yupeng Hou, Jiacheng Li, Zhankui He, An Yan, Xiusi Chen, and Julian J. McAuley. 2024. Bridging Language and Items for Retrieval and Recommendation. arXiv Preprint (2024). https://arxiv.org/abs/2403. [13] Jun Hu, Wenwen Xia, Xiaolu Zhang, Chilin Fu, Weichang Wu, Zhaoxin Huan, Ang Li, Zuoli Tang, and Jun Zhou. 2024. Enhancing Sequential Recommendation via LLM-based Semantic Embedding Learning. In WWW. 103111. [14] Wei Ju, Zheng Fang, Yiyang Gu, Zequn Liu, Qingqing Long, Ziyue Qiao, Yifang Qin, Jianhao Shen, Fang Sun, Zhiping Xiao, Junwei Yang, Jingyang Yuan, Yusheng Zhao, Yifan Wang, Xiao Luo, and Ming Zhang. 2024. Comprehensive Survey on Deep Graph Representation Learning. Neural Networks 173 (2024), 106207. [15] Wang-Cheng Kang and Julian J. McAuley. 2018. Self-Attentive Sequential Recommendation. In ICDM. 197206. [16] Jieyong Kim, Hyunseo Kim, Hyunjin Cho, SeongKu Kang, Buru Chang, Jinyoung Yeo, and Dongha Lee. 2025. Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation. In SIGIR. 16971706. [17] Jindong Li, Yali Fu, Li Fan, Jiahong Liu, Yao Shu, Chengwei Qin, Menglin Yang, Irwin King, and Rex Ying. 2025. Implicit Reasoning in Large Language Models: Comprehensive Survey. arXiv Preprint (2025). https://arxiv.org/abs/2509.02350 [18] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian J. McAuley. 2023. Text Is All You Need: Learning Language Representations for Sequential Recommendation. In KDD. 12581267. [19] Xinhang Li, Chong Chen, Xiangyu Zhao, Yong Zhang, and Chunxiao Xing. 2023. E4SRec: An Elegant Effective Efficient Extensible Solution of Large Language Models for Sequential Recommendation. arXiv Preprint (2023). https://arxiv.org/ abs/2312. [20] Enze Liu, Bowen Zheng, Xiaolei Wang, Wayne Xin Zhao, Jinpeng Wang, Sheng Chen, and Ji-Rong Wen. 2025. LARES: Latent Reasoning for Sequential Recommendation. arXiv Preprint (2025). https://arxiv.org/abs/2505.16865 [21] Zhanyu Liu, Shiyao Wang, Xingmei Wang, Rongzhou Zhang, Jiaxin Deng, Honghui Bao, Jinghao Zhang, Wuchao Li, Pengfei Zheng, Xiangyu Wu, Yifei Hu, Qigen Hu, Xinchen Luo, Lejian Ren, Zixing Zhang, Qianqian Wang, Kuo Cai, Yunfan Wu, Hongtao Cheng, Zexuan Cheng, Lu Ren, Huanjie Wang, Yi Su, Ruiming Tang, Kun Gai, and Guorui Zhou. 2025. OneRec-Think: In-Text Reasoning for Generative Recommendation. arXiv Preprint (2025). https://arxiv.org/abs/2510.11639 [22] Lingrui Mei, Jiayu Yao, Yuyao Ge, Yiwei Wang, Baolong Bi, Yujun Cai, Jiazhi Liu, Mingyu Li, Zhong-Zhi Li, Duzhen Zhang, Chenlin Zhou, Jiayi Mao, Tianze Xia, Jiafeng Guo, and Shenghua Liu. 2025. arXiv Preprint (2025). https://arxiv.org/ abs/2507.13334 [23] Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan Hulikal Keshavan, Trung Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Q. Tran, Jonah Samost, Maciej Kula, Ed H. Chi, and Mahesh Sathiamoorthy. 2023. Recommender Systems with Generative Retrieval. In NeurIPS. 1029910315. [24] Yankun Ren, Zhongde Chen, Xinxing Yang, Longfei Li, Cong Jiang, Lei Cheng, Bo Zhang, Linjian Mo, and Jun Zhou. 2024. Enhancing Sequential Recommenders with Augmented Knowledge from Aligned Large Language Models. In SIGIR. 345354. [25] Zhenyi Shen, Hanqi Yan, Linhai Zhang, Zhanghao Hu, Yali Du, and Yulan He. 2025. CODI: Compressing Chain-of-Thought into Continuous Space via SelfDistillation. In EMNLP. 677693. [26] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In CIKM. 14411450. [27] Wenfang Sun, Xinyuan Song, Pengxiang Li, Lu Yin, Yefeng Zheng, and Shiwei Liu. 2025. The Curse of Depth in Large Language Models. https://arxiv.org/abs/ 2502.05795 [28] Zhu Sun, Hongyang Liu, Xinghua Qu, Kaidong Feng, Yan Wang, and Yew Soon Ong. 2024. Large Language Models for Intent-Driven Session Recommendations. In SIGIR. 324334. [29] Juntao Tan, Shuyuan Xu, Wenyue Hua, Yingqiang Ge, Zelong Li, and Yongfeng Zhang. 2024. IDGenRec: LLM-RecSys Alignment with Textual ID Learning. In Conference17, July 2017, Washington, DC, USA Kun Yang et al. SIGIR. 355364. [30] Jiakai Tang, Xu Chen, Wen Chen, Jian Wu, Yuning Jiang, and Bo Zheng. 2026. Parallel Latent Reasoning for Sequential Recommendation. arXiv Preprint (2026). https://arxiv.org/abs/2601.03153 [31] Jiakai Tang, Sunhao Dai, Teng Shi, Jun Xu, Xu Chen, Wen Chen, Wu Jian, and Yuning Jiang. 2025. Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation. arXiv Preprint (2025). https://arxiv.org/ abs/2503.22675 [32] Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, and Mehmet A. Orgun. 2019. Sequential Recommender Systems: Challenges, Progress and Prospects. In IJCAI. 63326338. [33] Wenjie Wang, Honghui Bao, Xinyu Lin, Jizhi Zhang, Yongqi Li, Fuli Feng, SeeKiong Ng, and Tat-Seng Chua. 2024. Learnable Item Tokenization for Generative Recommendation. In CIKM. 24002409. [34] Ziyan Wang, Yingpeng Du, Zhu Sun, Haoyan Chua, Kaidong Feng, Wenya Wang, and Jie Zhang. 2025. Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation. (2025), 1282712835. [35] Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2024. LLMRec: Large Language Models with Graph Augmentation for Recommendation. In WSDM. 806815. [36] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-Based Recommendation with Graph Neural Networks. In AAAI. 346353. [37] Shenghao Yang, Weizhi Ma, Peijie Sun, Qingyao Ai, Yiqun Liu, Mingchen Cai, and Min Zhang. 2024. Sequential Recommendation with Latent Relations based on Large Language Model. In SIGIR. 335344. [38] Xiaoyong Yang, Yadong Zhu, Yi Zhang, Xiaobo Wang, and Quan Yuan. 2020. Large Scale Product Graph Construction for Recommendation in E-commerce. arXiv Preprint (2020). https://arxiv.org/abs/2010.05525 [39] Yuhao Yang, Chao Huang, Lianghao Xia, and Chenliang Li. 2022. Knowledge Graph Contrastive Learning for Recommendation. In SIGIR. 14341443. [40] Yonghui Yang, Le Wu, Zihan Wang, Zhuangzhuang He, Richang Hong, and Meng Wang. 2024. Graph Bottlenecked Social Recommendation. In KDD. 38533862. [41] Ghim-Eng Yap, Xiaoli Li, and Philip S. Yu. 2012. Effective Next-Items Recommendation via Personalized Sequential Pattern Mining. In DASFAA, Vol. 7239. 4864. [42] Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Mao Zhang, Wen Chen, Wenjun Yang, Yujie Luo, Yuning Jiang, Zhujin Gao, Bo Zheng, Binbin Cao, Changfa Wu, Dixuan Wang, Han Wu, Haoyi Hu, Kewei Zhu, Lang Tian, Lin Yang, Qiqi Huang, Siqi Yang, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Xiaowei Huang, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yujin Yuan, Yuliang Yan, and Zile Zhou. 2025. RecGPT-V2 Technical Report. arXiv Preprint (2025). https://arxiv.org/abs/2512.14503 [43] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In KDD. 974983. [44] Runyang You, Yongqi Li, Xinyu Lin, Xin Zhang, Wenjie Wang, Wenjie Li, and Liqiang Nie. 2025. R2ec: Towards Large Recommender Models with Reasoning. arXiv Preprint (2025). https://arxiv.org/abs/2505.16994 [45] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung Nguyen. 2022. Are Graph Augmentations Necessary?: Simple Graph Contrastive Learning for Recommendation. In SIGIR. 12941303. [46] Jianyang Zhai, Zi-Feng Mai, Chang-Dong Wang, Feidiao Yang, Xiawu Zheng, Hui Li, and Yonghong Tian. 2025. Multimodal Quantitative Language for Generative Recommendation. In ICLR. https://openreview.net/forum?id=v7YrIjpkTF [47] Zhi Zheng, Wenshuo Chao, Zhaopeng Qiu, Hengshu Zhu, and Hui Xiong. 2024. Harnessing Large Language Models for Text-Rich Sequential Recommendation. In WWW. 32073216. [48] Jieming Zhu, Mengqun Jin, Qijiong Liu, Zexuan Qiu, Zhenhua Dong, and Xiu Li. 2024. CoST: Contrastive Quantization based Semantic Tokenization for Generative Recommendation. In RecSys. 969974. ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Conference17, July 2017, Washington, DC, USA Derivation of Eq. 1 Proposition A.1 (Graph-Conditioned Variational Regularization Training Objective). Let ğ» denote user interaction history and ğ‘– the ground-truth next item observed at training time. Let C(ğ‘˜) be the candidate set induced by the ğ‘˜-hop neighborhood of the most recent items ğ¼ğ‘› on the interaction graph G. Consider the latent-variable formulation ğ‘ğœƒ (ğ‘– ğ» ) = ğ‘ (ğ‘˜ ) ğ‘ğœƒ (ğ‘ ğ» ) ğ‘ğœƒ (ğ‘– ğ‘, ğ» ), where ğ‘ is discrete latent intent prototype. Let ğ‘(ğ‘ ğ¼ğ‘›, G) be any categorical distribution supported on C(ğ‘˜) that does not depend on ğœƒ . Then, for all ğœƒ , the following inequality holds: log ğ‘ğœƒ (ğ‘– ğ» ) Eğ‘ (ğ‘ ğ¼ğ‘›,G) (cid:2) log ğ‘ğœƒ (ğ‘– ğ‘, ğ» )(cid:3) ğ·KL (ğ‘(ğ‘ ğ¼ğ‘›, G) ğ‘ğœƒ (ğ‘ ğ» )) . The right-hand side defines an ELBO-like objective that regularizes the inferred intent distribution toward the graph-conditioned prior. Proof. Starting from the marginal likelihood, ğ‘ğœƒ (ğ‘– ğ» ) = ğ‘ (ğ‘˜ ) ğ‘ğœƒ (ğ‘ ğ» ) ğ‘ğœƒ (ğ‘– ğ‘, ğ» ). For any categorical distribution ğ‘(ğ‘ ğ¼ğ‘›, G) supported on C(ğ‘˜), we rewrite the sum as an expectation: ğ‘ğœƒ (ğ‘– ğ» ) = ğ‘ (ğ‘˜ ) ğ‘(ğ‘ ğ¼ğ‘›, G) ğ‘ğœƒ (ğ‘ ğ» ) ğ‘ğœƒ (ğ‘– ğ‘, ğ» ) ğ‘(ğ‘ ğ¼ğ‘›, G) =Eğ‘ (cid:20) ğ‘ğœƒ (ğ‘ ğ» ) ğ‘ğœƒ (ğ‘– ğ‘, ğ» ) ğ‘(ğ‘ ğ¼ğ‘›, G) (cid:21) . Taking logarithm and applying Jensens inequality yields log ğ‘ğœƒ (ğ‘– ğ» ) Eğ‘ (cid:104) log ğ‘ğœƒ (ğ‘ ğ» ) + log ğ‘ğœƒ (ğ‘– ğ‘, ğ» ) log ğ‘(ğ‘ ğ¼ğ‘›, G) (cid:105) . Rearranging terms gives log ğ‘ğœƒ (ğ‘– ğ» ) Eğ‘ [log ğ‘ğœƒ (ğ‘– ğ‘, ğ» )] ğ·KL (ğ‘(ğ‘ ğ¼ğ‘›, G) ğ‘ğœƒ (ğ‘ ğ» )) , which completes the proof. Proof of Proposition 2.1 Proof. For fixed candidate set C, define ğ‘ƒ (ğ‘ ğ» ) = = ğ‘ (r) := exp(reğ‘ ) (cid:205)ğ‘ exp(reğ‘ ) exp(reğ‘ ) ğ‘ (r) , exp(cid:0)reğ‘ (cid:1) , ğ‘ where we suppress the dependence on ğ» in for notational simplicity. The KL distillation loss is (r) = Dğ¾ğ¿ (ğ‘„ ğ‘ƒ ( ğ» )) ğ‘„ (ğ‘) ğ‘ƒ (ğ‘ ğ» ) ğ‘„ (ğ‘) log = ğ‘ ğ‘ = ğ‘„ (ğ‘) log ğ‘„ (ğ‘) ğ‘ ğ‘„ (ğ‘) log ğ‘ƒ (ğ‘ ğ» ). The first term is constant with respect to ğ‘Ÿ , hence rL (r) = ğ‘ ğ‘„ (ğ‘) log ğ‘ƒ (ğ‘ ğ» ). Next, using log ğ‘ƒ (ğ‘ ğ» ) = reğ‘ log ğ‘ (r), we have log ğ‘ƒ (ğ‘ ğ» ) = (reğ‘ ) log ğ‘ (r) = eğ‘ 1 ğ‘ (r) rğ‘ (r). Moreover, rğ‘ (r) = ğ‘ exp(cid:0)reğ‘ (cid:1) = ğ‘ exp(cid:0)reğ‘ (cid:1) eğ‘ . Substituting back yields log ğ‘ƒ (ğ‘ ğ» ) = eğ‘ 1 ğ‘ (r) exp(cid:0)reğ‘ (cid:1) eğ‘ ğ‘ exp(reğ‘ ) ğ‘ (r) eğ‘ ğ‘ƒ (ğ‘ ğ» ) eğ‘ ğ‘ = eğ‘ = eğ‘ ğ‘ = eğ‘ Eğ‘ƒ ( ğ» ) [eğ‘ ]. Therefore, rL (r) = = ğ‘ ğ‘ ğ‘„ (ğ‘) (cid:0)eğ‘ Eğ‘ƒ ( ğ» ) [eğ‘ ](cid:1) ğ‘„ (ğ‘)eğ‘ + (cid:33) ğ‘„ (ğ‘) Eğ‘ƒ ( ğ» ) [eğ‘ ]. (cid:32) ğ‘ Since ğ‘„ is probability distribution on C, (cid:205)ğ‘ ğ‘„ (ğ‘) = 1, and thus rL (r) = Eğ‘ƒ ( ğ» ) [eğ‘ ] Eğ‘„ [eğ‘ ], which completes the proof. Proof of Proposition 2.2 Proof. By the triangle inequality of the total variation distance, we have ğ‘‘TV (ğ‘ğ‘¡ +1, ğ‘ğ‘¡ +1) ğ‘‘TV (ğ‘ğ‘¡ +1, ğ‘ğ‘¡ ) + ğ‘‘TV (ğ‘ğ‘¡ , ğ‘ğ‘¡ +1). Applying the bounded teacher drift assumption in Eq. 7 yields ğ‘‘TV (ğ‘ğ‘¡ +1, ğ‘ğ‘¡ +1) ğ‘‘TV (ğ‘ğ‘¡ +1, ğ‘ğ‘¡ ) + ğ›¿. Using the stepwise contraction assumption in Eq. 6, we obtain the recursive bound: ğ‘‘TV (ğ‘ğ‘¡ +1, ğ‘ğ‘¡ +1) (1 ğœ†) ğ‘‘TV (ğ‘ğ‘¡ , ğ‘ğ‘¡ ) + ğ›¿. Conference17, July 2017, Washington, DC, USA Kun Yang et al. Unrolling the recursion for ğ‘¡ 1 steps gives ğ‘‘TV (ğ‘ğ‘¡ , ğ‘ğ‘¡ ) (1 ğœ†)ğ‘¡ 1 ğ‘‘TV (ğ‘1, ğ‘1) + ğ›¿ ğ‘¡ 2 (1 ğœ†) ğ‘— ğ‘—=0 1 (1 ğœ†)ğ‘¡ 1 ğœ† = (1 ğœ†)ğ‘¡ 1 ğ‘‘TV (ğ‘1, ğ‘1) + ğ›¿ ğ›¿ ğœ† (1 ğœ†)ğ‘¡ 1 ğ‘‘TV (ğ‘1, ğ‘1) + , which establishes the desired bound in Eq. 8. Global Relation Modeling via Swing Graph To capture stable collaborative signals, we construct global item graph = (V, E) using an enhanced variant of the Swing algorithm used in industrial practice (e.g., Alibaba [38]). This variant incorporates user activity normalization and popularity smoothing to mitigate the impact of noise from hyper-active users and hot items. Formally, let Uğ‘– denote the set of users who interacted with item ğ‘–, and ğ¼ğ‘¢ denote the interaction history of user ğ‘¢. For pair of items (ğ‘–, ğ‘—), we first identify the set of common users Kğ‘– ğ‘— = Uğ‘– Uğ‘— . To improve efficiency, if Kğ‘– ğ‘— exceeds threshold ğ‘€, we perform random sampling to obtain subset Ë†Kğ‘– ğ‘— Kğ‘– ğ‘— . The similarity score ğ‘†ğ‘–ğ‘š(ğ‘–, ğ‘—) is defined as weighted summation over user pairs (ğ‘¢, ğ‘£) from Ë†Kğ‘– ğ‘— : ğ‘†ğ‘–ğ‘š(ğ‘–, ğ‘—) = 1 Uğ‘— ğ‘¤ğ‘¢ğ‘£, ğ‘¢ Ë†Kğ‘– ğ‘— ğ‘£ Ë†Kğ‘– ğ‘— ,ğ‘£ğ‘¢ where the pair weight ğ‘¤ğ‘¢ğ‘£ combines user activity decay and substructure strength: ğ‘¤ğ‘¢ğ‘£ = 1 (ğ¼ğ‘¢ + ğ›¼1)ğ›½ (ğ¼ğ‘£ + ğ›¼1)ğ›½ (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) (cid:123)(cid:122) (cid:124) User Activity Weight 1 ğ¼ğ‘¢ ğ¼ğ‘£ + ğ›¼2 (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:124) (cid:125) (cid:123)(cid:122) Overlap Penalty where ğ›¼1, ğ›¼2 are smoothing parameters, and ğ›½ controls the strength of user activity penalization. The term 1/Uğ‘— acts as normalization factor to prevent popular items from dominating the retrieval results. This formulation ensures that the Intent Anchors are derived from high-quality, non-trivial collaborative structures. ManCAR Algorithms We summarize the implementations of ManCARs training and adaptive reasoning in Algorithms 1 and 2, respectively. Notably, we find that ğ‘˜ = 1 is sufficient for all Amazon Reviews datasets and adopt this setting throughout our experiments. Increasing ğ‘˜ consistently degrades performance on these datasets, likely due to their high sparsity induced by the dataset construction process. In such settings, expanding to higher-order neighborhoods introduces noisy candidates that dilute useful collaborative signals. We note that larger ğ‘˜ may be beneficial in denser, real-world industrial scenarios, where higher-order relations are more reliable, and we recommend applying exponential decay to ğ‘˜-hop neighbor weights to mitigate noise when increasing ğ‘˜. Algorithm 1 ManCAR Training Algorithm Required: train set {ğ» ( ğ‘— ), ğ‘–( ğ‘— ) }ğ‘ interaction window size ğ‘›, reasoning step ğ‘‡ ğ‘—=1, batch size ğµ, #hops ğ‘˜, recent 1: Construct global interaction graph SWING({ğ» ( ğ‘— ) }ğ‘ 2: for randomly sampled mini-batch {ğ» ( ğ‘— ), ğ‘–( ğ‘— ) }ğµ ğ‘› ; G; ğ‘˜) 3: ğ‘—=1 do ğ‘—=1) ( ğ‘— ) (ğ‘˜) C(ğ¼ ( ğ‘— ) for ğ‘¡ = 1, . . . ğ‘‡ do Get teacher prior ğ‘ (ğ‘¡ ) (ğ‘ ( ğ‘— ) ğ¼ ( ğ‘— ) Compute the main loss (ğ‘¡ ) main via Eq. 3 Compute the regularization loss (ğ‘¡ ) ğ‘› , G) via Eq. 2 reg via Eq. 4 end for Compute the overall loss via Eq. 5 Minimize w.r.t. ğœƒ 10: 11: end for 12: return ğœƒ Algorithm 2 ManCAR Adaptive Reasoning Inference Algorithm Required: inference input ğ» , global interaction graph constructed on train set, #hops ğ‘˜, recent interaction window size ğ‘›, max reasoning step ğ‘‡max, early stop threshold ğœ– 1: Define ğ‘ (0) ğœƒ NULL 2: for ğ‘¡ = 1 . . . ğ‘‡max do 3: C(ğ‘˜) C(ğ¼ğ‘›; G; ğ‘˜) ğ‘ (ğ‘¡ ) ğœƒ ğ‘“ (ğ‘¡ ) if ğ‘ (ğ‘¡ 1) ğœƒ if ğ·KL (ğ‘ (ğ‘¡ 1) (ğ», C(ğ‘˜)) ğœƒ is not NULL then ğ‘ (ğ‘¡ ) ) < ğœ– then ğœƒ End the reasoning at step ğ‘¡ ğœƒ end if 4: 5: 6: 7: 8: 9: 4: 5: 6: 7: 8: end if 9: 10: end for 11: return ğ‘ (ğ‘¡ ) ğœƒ Additional Analyses F.1 More Results for Data-Aware Train-Test"
        },
        {
            "title": "Compute Allocation",
            "content": "Tab. 5 reports the reason step in train and inference phase of ERL, PRL, PLR, and ManCAR on seven datasets, providing supplementary results to Tab. 3 of Sec. 3.3. F.2 Computation Complexity Analysis Let ğ¶ and ğ» denote the length of context prompt and user history, respectively, ğ‘‘ denote the hidden dimension, ğ¿ denote the number of Transformer layers, ğ‘‡ denote the number of reasoning steps. Transformer Encoder. In multi-head self attention, the Q/K/V/out projection and weighted sum costs ((ğ¶ + ğ» )ğ‘‘ 2) and ((ğ¶ + ğ» )2ğ‘‘). In FFN, the two linear-layer costs ((ğ¶ + ğ» )ğ‘‘ 2). Thus, the total FLOPs for ğ¿-layer Transformer encoder is (ğ¿((ğ¶ + ğ» )2ğ‘‘ + (ğ¶ + ğ» )ğ‘‘ 2)). Autoregressive Reasoning. With KV cache enabled, for each step ğ‘¡ [1, ...,ğ‘‡ ], the cost of Q/K/V/out projection is (ğ‘‘ 2), the cost of attention weighted sum is ((ğ¶ + ğ» + ğ‘¡ 1)ğ‘‘), the cost of FFN ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation Conference17, July 2017, Washington, DC, USA (cid:0)(ğ» + ğ‘›ğ‘¡ ğ‘›)ğ‘›ğ‘‘ + ğ‘›ğ‘‘ 2(cid:1). reasoning iterations, the computational cost of the reasoning component scales as ğ¿core ğ‘‡ (cid:0)ğ» ğ‘‘ + ğ‘‘ 2(cid:1). For PLR, which adopts ğ‘› parallel reasoning streams, the cost of the reasoning component is ğ¿ (cid:205)ğ‘‡ ğ‘¡ =1 Tab. 6 summarizes the corresponding FLOPs for these methods. The additional computation in ManCAR mainly stems from processing this extra context, which has been shown in earlier experiments to yield substantial performance gains. We argue that this overhead is justified, especially in light of the effectiveness of test-time scaling strategies widely adopted in modern LLM systems. Table 5: Number of reasoning steps used during training and inference for ERL, PRL, PLR, and ManCAR across seven datasets. Note that LARES adopts loop-architecture-based method rather than forward step-wise reasoning; the reported step count for LARES corresponds to the number of loop iterations. Dataset CDs Video Office Arts Music Toys Grocery Reason step ERL Train step Infer step Train step Infer step Train step Infer step Train step Infer step Train step Infer step Train step Infer step Train step Infer step 2 2 2 2 2 2 2 2 2 2 1 1 2 2 PRL 2 2 2 2 2 2 2 2 2 2 2 2 2 2 PLR LARES ManCAR 3 3 2 2 2 2 1 1 2 2 1 1 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 5 1.84 4 3.68 2 1.93 1 1 2 1.84 4 3.58 2 1.74 Table 6: FLOPs for ERL, PRL, PLR, LARES, and ManCAR. Method ERL/PRL PLR LARES (cid:16) ManCAR FLOPs ğ¿ ( ğ» 2ğ‘‘ + ğ» ğ‘‘ 2 ) (cid:16) ğ‘‡ + ğ¿ (cid:0)( ğ» + ğ‘¡ 1)ğ‘‘ + ğ‘‘ 2(cid:1)(cid:17) (cid:16) ğ‘¡ =1 ğ¿ ( ğ» 2ğ‘‘ + ğ» ğ‘‘ 2 ) ğ‘‡ + ğ¿ (cid:0)( ğ» + ğ‘›ğ‘¡ ğ‘›)ğ‘›ğ‘‘ + ğ‘›ğ‘‘ 2(cid:1)(cid:17) (cid:16) ğ‘¡ =1 (ğ¿pre + ğ¿core ) ( ğ» 2ğ‘‘ + ğ» ğ‘‘ 2 ) + ğ¿coreğ‘‡ (cid:0)ğ» ğ‘‘ + ğ‘‘ 2(cid:1) (cid:17) ğ¿ (cid:0)( ğ¶ + ğ» ) 2ğ‘‘ + ( ğ¶ + ğ» )ğ‘‘ 2(cid:1) + ğ¿ ğ‘‡ ğ‘¡ =1 (cid:0)( ğ¶ + ğ» + ğ‘¡ 1)ğ‘‘ + ğ‘‘ 2(cid:1)(cid:17) is (ğ‘‘ 2). Thus for ğ¿-layer Transformer, the total FLOPs for ğ‘‡ -step autoregressive reasoning part is (ğ¿ (cid:205)ğ‘‡ ğ‘¡ =1 ((ğ¶ +ğ» +ğ‘¡ 1)ğ‘‘ +ğ‘‘ 2)). ManCAR Overall. Combining these two parts, the total FLOPs for ManCAR is (ğ¿((ğ¶ + ğ» )2ğ‘‘ + (ğ¶ + ğ» )ğ‘‘ 2) + ğ¿ (cid:205)ğ‘‡ ğ‘¡ =1 ((ğ¶ + ğ» + ğ‘¡ 1)ğ‘‘ + ğ‘‘ 2)). Among latent reasoning baselines such as ERL, PRL, PLR, and LARES, the primary architectural difference in ManCAR lies in the introduction of the graph-conditioned context prompt C, which extends the computation of sequential encoding. Specifically, for the recurrent reasoning method LARES, which consists of ğ¿prelayer pre-encoder and ğ¿core-layer core encoder reused across"
        }
    ],
    "affiliations": [
        "Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University, China",
        "School of Informatics, Xiamen University, China",
        "Shopee Pte. Ltd."
    ]
}