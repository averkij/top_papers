{
    "paper_title": "Empirical Study of Mutual Reinforcement Effect and Application in Few-shot Text Classification Tasks via Prompt",
    "authors": [
        "Chengguang Gan",
        "Tatsunori Mori"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The Mutual Reinforcement Effect (MRE) investigates the synergistic relationship between word-level and text-level classifications in text classification tasks. It posits that the performance of both classification levels can be mutually enhanced. However, this mechanism has not been adequately demonstrated or explained in prior research. To address this gap, we employ empirical experiment to observe and substantiate the MRE theory. Our experiments on 21 MRE mix datasets revealed the presence of MRE in the model and its impact. Specifically, we conducted compare experiments use fine-tune. The results of findings from comparison experiments corroborates the existence of MRE. Furthermore, we extended the application of MRE to prompt learning, utilizing word-level information as a verbalizer to bolster the model's prediction of text-level classification labels. In our final experiment, the F1-score significantly surpassed the baseline in 18 out of 21 MRE Mix datasets, further validating the notion that word-level information enhances the language model's comprehension of the text as a whole."
        },
        {
            "title": "Start",
            "content": "Empirical Study of Mutual Reinforcement Effect and Application in Few-shot Text Classification Tasks via Prompt Chengguang Gan1 Tatsunori Mori1 1Yokohama National University, Japan gan-chengguan-pw@ynu.jp, tmori@ynu.ac.jp 4 2 0 2 3 1 ] . [ 1 5 4 7 9 0 . 0 1 4 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "The Mutual Reinforcement Effect (MRE) investigates the synergistic relationship between word-level and text-level classifications in text classification tasks. It posits that the performance of both classification levels can be mutually enhanced. However, this mechanism has not been adequately demonstrated or explained in prior research. To address this gap, we employ empirical experiment to observe and substantiate the MRE theory. Our experiments on 21 MRE mix datasets revealed the presence of MRE in the model and its impact. Specifically, we conducted compare experiments use fine-tune. The results of findings from comparison experiments corroborates the existence of MRE. Furthermore, we extended the application of MRE to prompt learning, utilizing wordlevel information as verbalizer to bolster the models prediction of text-level classification labels. In our final experiment, the F1-score significantly surpassed the baseline in 18 out of 21 MRE Mix datasets, further validating the notion that word-level information enhances the language models comprehension of the text as whole."
        },
        {
            "title": "Introduction",
            "content": "The concept of Mutual Reinforcement Effect (MRE) Gan et al. (2023b) was initially introduced in the domains of text classification Kim (2014) and Named Entity Recognition (NER)(Nadeau and Sekine, 2007). This approach marked the first instance where text classification task and NER task were integrated within the same mixed dataset. Essentially, this necessitates that the model concurrently execute text-level classification and wordlevel information extraction (IE) for each sentence. Consequently, every text in the dataset is assigned both text-level classification labels and NER labelentity pairs. As shown in the bottom portion of Figure 1, Research indicates that the combined execution of these two tasks yields superior performance compared to addressing them separately. As illustrated in the middle section of Fig. 1, we provide concrete example of the MRE using sentiment analysis task. Initially, the overall sentiment polarity of the sentence is classified as negative. When the model identifies the overall sentiment as negative, it is more likely to infer that specific negative words (e.g., \"ugly,\" \"hate\") are present during the subsequent word-level classification task. Conversely, when the model detects the presence of these negative words, it will tend to classify the overall sentiment of the text as negative. This bidirectional reinforcement between sentencelevel and word-level classification exemplifies the core idea of MRE. This synergistic approach closely mirrors the human process of reading and comprehending text. Initially, humans decipher the meaning of individual words within text. Upon grasping the significance of each word, they can then comprehend the overall message of the text. These steps correspond to the NER task and the text classification task, respectively, where the former involves understanding individual words and the latter pertains to grasping the overall meaning of the text. Furthermore, knowing the general classification of text, such as identifying it as an advertisement, can aid in predicting the presence of specific entities like product names within the text. Similarly, in modeling, awareness of the texts overall classification can facilitate word-level information extraction. In summary, there exists mutual reinforcement effect between text-level and word-level tasks, enhancing the performance of both. Subsequent to its inception, MRE has been progressively adapted to variety of tasks within the IE domain, including sentiment classification, word sentiment polarity classification, relation extraction, and event extraction. The integration of these text-level and word-level tasks has resulted in noFigure 1: The figure illustrates the mutual reinforcement effect between text-level and word-level tasks in sentiment classification task. table performance enhancements. Moreover, these tasks have been effectively addressed through the use of generative IE techniques. The evolution of models in this domain has been marked by transition from the initial Sentence-to-label framework (SLG) Gan et al. (2023b) employing the T5 model, to the more advanced General Information Extraction Large Language Model (GIELLM) (Gan et al., 2023a). These models are adept at handling mixture of text-level and word-level tasks. The advent of Large Language Models (LLMs) Ouyang et al. (2022); OpenAI (2023); Touvron et al. (2023a,b) has further revolutionized the field, as the versatility of LLMs facilitates the training of single model to efficiently manage multiple tasks, thereby simplifying the process and yielding superior performance. Previous studies have explored ablation experiments by combining the outputs of two tasks, where the input was essentially just the text itself. This approach only confirms that the model can simultaneously improve the performance of both tasks by learning them together. However, it does not provide any insight into whether information at the wordor text-level contributes to the improvement of the other task. To address this limitation, we designed new empirical experiment with an innovative input-output format and evaluated it using the existing 21 MRE mixed datasets. Through straightforward and effective fine-tuning experiment, we compared the impact of incorporating wordor text-level information into the input on the performance of the corresponding output at different level. Our findings show that wordand text-level information significantly enhances the performance of the other task, thereby providing strong evidence in support of the MRE hypothesis. In the final, we extend the application of the MRE to few-shot learning. Specifically, we leverage word-level information as knowledgeable verbalizer Hu et al. (2022a) to enhance the performance of text classification tasks with limited samples. Our experimental results demonstrate substantial improvement in classification accuracy when using word-level information as verbalizer compared to not using it. The main contributions of this paper are summarized as follows: (1) Utilization of novelty input and output format for fine-tune ablation experiment to observe and validate the mutual reinforcement effect. (2) Application of the MRE concept to few-shot learning in text classification tasks, resulting in significant enhancement effect."
        },
        {
            "title": "2 Related Work",
            "content": "Mutual Reinforcement Effect. In traditional multi-task Zhang and Yang (2021); Liu et al. (2016); Collobert and Weston (2008); Radford et al. (2019) approaches that simply amalgamate disparate tasks, MRE integrates two inherently related tasks at the word and text levels. By curating novel dataset, enhance the performance of both tasks concurrently. Initially, the Sentence Classification and Named Entity Recognition (SCNM) Gan et al. (2023b) task was developed by combining sentence classification and named entity recognition. To address this integrated task, the Sentenceto-Label Generation (SLG) framework was proposed based on the T5 model. Subsequently, new task was formulated by merging text sentiment classification with word-level sentiment polarity classification (SCPOS) (Gan et al., 2023c), marking the first application of large language models (LLMs) to train on SCPOS tasks. Following this, text classification was integrated with relationship and event extraction (TCREE) (Gan et al., 2023a). comprehensive General Information Extraction Language Model (GIELLM) was then constructed by incorporating the SCNM and SCPOS tasks. Finally, open-domain NER mixed datasets (TCONER) (Gan et al., 2024) were created and extended to Chinese and English using dataset translation framework, thereby enhancing the multilingual capability of the original Japanese MRE mixed datasets. The effectiveness of the proposed Mutual Reinforcement Effect (MRE) is validated through series of ablation studies, where models were trained on each task independently and then jointly on combined tasks. Comparative analysis on test sets reveals that the joint training approach consistently outperforms single-task models, demonstrating the synergistic advantages of the MRE framework. Prompt in Information Extraction. The prompt-based approach was initially applied to text and sentence sentiment classification (Schick and Schütze, 2021; Zhong et al., 2021; Li and Liang, 2021; Shin et al., 2020). It achieves few-shot learning by aligning the downstream task format with the pre-training objective of the pre-trained language model (PLM), specifically the Masked Language Modeling (MLM) task (Devlin et al., 2019). The original prompt method relies on basic prompt template, wherein prompt questions are embedded within the models input sequence alongside the text to be classified. The model then outputs the corresponding predicted classification labels. Subsequent research introduced the concept of prompt-based label generation, known as the Knowledgeable Verbalizer (KV) (Hu et al., 2022b). This method utilizes words associated with classification labels to aid the model in predicting the appropriate labels, thereby enriching the representation and prediction capability of the model. In summary, the MRE is highly suitable for integration with the Knowledgeable Verbalizer. MRE not only enhances task performance but also serves as evidence that word-level information can effectively support text-level understanding."
        },
        {
            "title": "Reinforcement Effect",
            "content": "The three format of fine-tuned language models used for ablation experiments are shown in Figure 2. The sentence on the left represents the input, with the plus sign indicating the addition of Wordlevel Information (WLI. i.e. Word-level Task) or Text-level Information (TLI. i.e. Text-level Task), which are appended to the sentence to form the full input. The arrows represent the output produced by language model. The distinctions between the models are clearly illustrated. First, the top model in Figure 2 shows the inputoutput format for the traditional IE task, where language models are fine-tuned on basic input sentence. The model then outputs either classified labels or extracted label-entity pairs. This approach treats the two tasksword-level label extraction and text-level classificationindependently, with no shared information between them. In contrast, the middle section of Figure 2 illustrates the input-output format for the original MRE task. While the input remains single sentence, the model is expected to output both word-level label-entity pairs and text-level classification labels simultaneously. Thus, during MRE fine-tuning, the model learns to capture both levels of information, integrating the two tasks. Finally, the bottom section of Figure 2 presents Figure 2: The figure shows the inputs and outputs of the traditional ablation experiment for the MRE task and the new empirical MRE experiment proposed in this work. the input-output format of our proposed ablation experiment designed to validate MRE. Unlike the previous two formats, this approach aims to verify the existence of shared knowledge between wordlevel and text-level tasks. Specifically, we introduce WLI and TLI to both levels of tasks to assess whether enhancing one task also improves the other. For example, by adding word-level labelentity pairs to the input text and asking the model to output the text-level classification label, we can evaluate whether the additional word-level information assists in text classification. Similarly, if adding text-level information to the input improves the extraction of word-level label-entity pairs, it suggests the presence of an MRE between the two tasks. As showed in Figure 3, the LLM is fine-tuned with all parameters using revised input and output formats. The input sequence is directly concatenated with either WLI or TLI, while the output consists solely of TLI or WLI. No additional instruction templates or prompt words were incorporated in this process. We deliberately chose to concatenate the text with WLI or TLI without extra modifications to minimize the potential influence of extraneous words or sentences on the models output, which could affect the accuracy of our comparative experiments. By using only this basic spliced input and raw output, we aim to investigate whether tasks at one level facilitate tasks at another, while controlling for other confounding factors. To test this hypothesis, we conducted ablation experiments on 21 sub-datasets of Multilingual MRE Figure 3: The figure illustrates the flow of an empirical MRE experiment using the new approach. Mix (MMM) datasets(Gan et al., 2024). The results were analyzed to further deepen our understanding of MRE and its implications."
        },
        {
            "title": "4 Word-level Information as\nKnowledgeable Verbalizer",
            "content": "To enhance the application of the MRE approach in real-world contexts, we have selected the fewshot learning task for text classification as our experimental setup. In MRE, word-level information plays crucial role in text-level classification. Figure 4: The figure demonstrates how word-level information is utilized as Knowledgeable Verbalizer to assist in text-level classification tasks. Additionally, it provides detailed explanation of the functioning of the Knowledgeable Verbalizer. Hence, we utilize the high-frequency words from word-level information as knowledgeable verbalizers (KV) Hu et al. (2022a) to examine their impact on the performance of the text classification task. The entire process of prompt learning is illustrated in Figure 3. Initially, target classification text is provided, followed by the inclusion of prompt template to guide the model in predicting the label at the designated mask position. Our sample dataset comprises five labels. We employ the top 100 words from the word-level information as the knowledgeable verbalizer, meaning that each of the five categories has 100 high-frequency words selected from the word-level information. When calculating the actual probability of label, the model computes the probability of all these 500 words and then aggregates the total probability based on the respective broad classification. Ultimately, we obtain five probabilities that integrate the individual verbalizers. The label with the highest probability is chosen as the final predicted label. In conclusion, this outlines the detailed principle behind the KV. In the original experimental setup, label-related high-frequency words were sourced directly from relation word search website, where commonly used vocabulary was analyzed to identify relevant terms. While these words may be highly pertinent across wide range of web texts, not all of them are necessarily associated with the labels of specific dataset. As result, some of these words may not only fail to enhance label prediction but could potentially introduce negative effects. This highlights the suitability of the WLI component from the MRE-mixed dataset as replacement for the KV. Furthermore, if the performance of the WLI-based KV surpasses that of the original baseline KV, it would support the argument that WLI contributes positively to label prediction in text classification tasks. This, in turn, would verify the presence of the MRE."
        },
        {
            "title": "5 Experiment Setup",
            "content": "For the fine-tuning experiment, the entire training set was utilized to fully parameterize the fine-tuned LLMs. Subsequently, 1,000 samples were randomly selected from the test set three times, and the results from these three trials were averaged to produce the final performance score. The evaluation metric employed was the F1 score. The hyperparameters for training were configured as follows: the number of training epochs was set to 3, and the learning rate was initialized at 1e-5. The AdamW optimizer was used, with 100 warmup steps. Training was conducted on three RTX A6000 Ada GPUs, each with 48 GB of memory. To optimize GPU memory usage, BF16 precision Datasets SCNM SCPOS:RW SCPOS:N SCPOS:Adj SCPOS:N & Adj TCREE Text-level Society, Literature, Academia, Technology, Nature positive, negative positive, negative positive, negative positive, negative sports, film, women, IT, advertising Word-level people, corporations, political organizations, other organizations, places, facilities, products, and events positive, neutral, negative positive, neutral, negative positive, negative positive, neutral, negative affiliation, occupation, starring, director, age, product, goods, performances, wins, broadcasts, public appearances, launches, retirements date, location, organization TCONER Entertainment, Politics Medical, Health, education Title, Person, City Tech, Healthcare, News finance, Biolog, etc. Law, Number, Concept TV Show, Object, etc. Table 1: The table presents seven distinct types of MRE mixed datasets, each available in Chinese, English, and Japanese, resulting in total of 21 sub-datasets. Among them, the TCONER dataset corresponds to an open-domain dataset, where only subset of the labels is provided, rather than comprehensive list of all possible labels. (SCNM: Sentence Classification and Named Entity Recognition Mix Dataset. SCPOS: Sentiment Classification and Part-of-Speech Dataset. RW: Relation Word. N: Noun. Adj: Adjective. & Adj: Nous and Adjective. TCREE: Text Classification and Relation & Event Extraction Dataset. TCONER: Open-domain Text Classification and NER mix dataset) was applied during training, and FP16 precision was employed for inference."
        },
        {
            "title": "5.1 Datasets",
            "content": "Second, for the experiments involving the knowledgeable verbalizer, we utilized the OpenPromptDing et al. (2021)1 framework to efficiently set up the experimental environment. All datasets were divided into training and test sets. From the training set, we randomly selected 20 samples per category, based on the label types, to form the prompt experiments training subset. Each experiment was trained for 2 epochs, with all other hyperparameterssuch as the learning ratekept consistent across experiments. The only variation lay in the construction method of the KV. For the KVs based on the original approach, we leveraged ChatGPT-4o2 to generate the top 100 most relevant words for each label. In contrast, for KVs constructed using the WLI-based method, we developed custom processing script. The script segmented all words from the WLI section of each dataset, identified high-frequency terms, and used them to construct the WLI-based KVs. 1https://github.com/thunlp/OpenPrompt 2https://chatgpt.com/ In the selection of datasets, we focused on Multilingual MRE Mix (MMM) datasets3 due to their availability. We tested 21 such datasets, the statistics of which are presented in Table 1. These datasets include SCNM (Sentence Classification and NER mix dataset), SCPOS: RW/Adj&N/Adj/N (Sentiment Classification and Part-of-Speech dataset: Related Word/Adjective&Noun/ Adjective/Noun), TCREE (Text Classification and Relation Event Extraction dataset). and TCONER (Open-domain Text Classification and NER mix dataset). These datasets cover wide range of tasks, encompassing nearly all divisions of IE. Moreover, there is correlation between the word-level labels and textlevel labels within these datasets. For instance, the sentiment polarity of words is related to the sentiment polarity of the text. It is important to note that the TCONER dataset, being open-domain, contains labels with inherent uncertainty. Therefore, we excluded TCONER from the KV application experiments to ensure reliable evaluation. 56.04 56.75 73.73 75. 48.79 48.99 72.41 73.15 16.43 18.43 82.23 83.33 44.36 43.30 89.07 90.95 28.79 27.71 77.07 77.73 33.29 32.42 77.27 77.60 SCNM SCPOS:RW SCPOS:adj&n SCPOS:adj SCPOS:n TCREE English 80.97 w/o TLI 81.28 with TLI 82.40 w/o WLI 83.90 with WLI SCNM SCPOS:RW SCPOS:adj&n SCPOS:adj SCPOS:n TCREE Chinese 73.35 w/o TLI 72.81 with TLI 83.17 w/o WLI 83.93 with WLI SCNM SCPOS:RW SCPOS:adj&n SCPOS:adj SCPOS:n TCREE Japanese 87.92 w/o TLI 88.22 with TLI 83.60 w/o WLI 85.87 with WLI TCONER English 20.22 w/o TLI 19.85 with TLI 36.50 w/o WLI 35.53 with WLI 67.23 66.24 88.37 90.57 Japanese 13.19 13.39 38.97 43.30 63.80 63.89 88.13 89.17 Chinese 17.28 17.82 44.07 43.33 80.87 81.37 94.86 94.46 9.68 9.73 93.67 92.07 28.67 29.17 91.03 92.37 29.06 29.34 91.80 93. 55.10 56.31 93.64 94.85 50.70 51.03 87.93 89.90 69.47 69.92 87.10 89.50 Table 2: The results of text-level information (TLI) and word-level information (WLI) comparison experiments."
        },
        {
            "title": "5.2 Model",
            "content": "For the empirical experiments on fine-tuning, we selected the LLaMA3-8B4 model5 as the base model to perform series of fine-tuning and inference tasks. We opted not to use the LLaMA38B-Instruct version because it is more tailored for question-answering tasks, with prompts structured as instructions. Through comparative analysis of LLaMA3-8B and its instruct-tuned counterpart, we observed that the base LLaMA3-8B model achieved better performance on fundamental IE tasks. Therefore, we decided to use LLaMA3-8B as the foundation for our experiments. For the WLI as KV application comparison experiments, we employed the T5-base Raffel et al. (2020) model as the base model. Specifically, for the English portion of the MMM dataset, we used the original Google T5-base6. For the Chinese section, we selected the Mengzi-T5-base7, which is optimized for Chinese tasks. Lastly, for the Japanese part of the MMM dataset, we utilized T5-base3https://huggingface.co/datasets/ganchengguang/ MMMhttps://huggingface.co/datasets/ datasets-Testset ganchengguang/MMM-dataset-Trainset and 4https://ai.meta.com/blog/meta-llama-3/ 5https://huggingface.co/meta-llama/Meta-Llama-3-8B 6https://huggingface.co/google-t5/t5-base 7https://huggingface.co/Langboat/mengzi-t5-base Japanese8."
        },
        {
            "title": "Reinforcement Effect",
            "content": "As shown in Table 2, the results of our test set consist of 84 LLaMA3-8B models fine-tuned on 21 datasets in four distinct formats. The first column lists the names of seven core datasets, with the seventh dataset, TCONER, discussed separately at the bottom of the table due to its unique characteristics. The four formats are divided as follows: the first two involve TLI (text-level information), where it is either excluded or included in the input sequence, with the output mapped to WLI (word-level information). The remaining two formats address WLI, where it is similarly either excluded or included in the input sequence, with the output corresponding to WLI. From the results in Table 2, we observe that for the first six fixed-label datasets, models trained with the inclusion of additional information consistently outperform those trained without it. These findings strongly support the MRE hypothesis, demonstrating that mutual reinforcement exists between word-level and text-level classification tasks. 8https://huggingface.co/sonoisa/t5-base-japanese 80.42 83.99 80.40 87.40 SCNM SCPOS:RW SCPOS:adj&n SCPOS:adj SCPOS:n TCREE English Origin KV 62.95 63.24 WLI KV SCNM SCPOS:RW SCPOS:adj&n SCPOS:adj SCPOS:n TCREE Chinese Origin KV 67.38 71.96 WLI KV SCNM SCPOS:RW SCPOS:adj&n SCPOS:adj SCPOS:n TCREE Japanese Origin KV 73.26 73.91 WLI KV 91.90 82.92 86.52 85.82 78.37 87.97 67.23 81.74 30.20 52. 78.87 87.37 73.71 85.67 81.95 88.70 73.71 88.31 73.11 77.24 84.48 88. 84.45 87.23 93.04 93.95 Table 3: The results of word-level information (WLI) as knowledgeable verbalizer experiments. Compare with original KV construction method. Evaluation task is text classification task. well-balanced combination of both classification levels enhances the LLMs ability to understand and perform across tasks. Specifically, comprehension of one task level (e.g., text-level) facilitates and strengthens the understanding of the other (e.g., word-level). This insight not only advances our understanding of how LLMs tackle natural language tasks but also reflects broader principle underlying human cognition: the mutual reinforcement between different levels of text comprehension mirrors how humans naturally process and understand language. As illustrated by the results of the open-domain text classification and NER tasks at the bottom of Table 2, approximately half of the outcomes do not surpass those achieved by the model trained without Level Information. We attribute this to the nature of certain open-domain datasets, which contain multiple labels; in such cases, not all WLI contributes positively to TLI. The presence of these uncorrelated WLIs and TLIs leads to decline in overall performance. However, in the Chinese and Japanese TCONER datasets, we observe improved results after incorporating Level Information. This improvement suggests that the MRE is more effective in languages based on Chinese characters, in contrast to those that use alphabetic writing systems, such as English."
        },
        {
            "title": "Verbalizer",
            "content": "The next result involves the use of WLI as the relevant word for constructing KVs. We compare the performance of KVs constructed using the original method with those built using WLI in text classification task. Since KV construction requires fixed label structure, the open-domain TCONER dataset, which has an unfixed label schema, was excluded from this experiment. As shown in Table 3, across 18 sub-datasets the WLIin English, Chinese, and Japanese, based KVs achieved the highest performance in 16 datasets. Moreover, for most sentiment classification datasets, KVs constructed with WLI significantly outperformed those generated by the original method in terms of F1 scores. These results not only demonstrate the effectiveness of WLI in enhancing general text classification tasks but also highlight its particular value in sentiment classification. This is likely because sentiment classification heavily relies on correctly identifying the sentiment polarity of individual words within the text, which aligns with WLIs strengths."
        },
        {
            "title": "7 Conclusion",
            "content": "In this study, we propose novel input and output schemes to rigorously test and validate the Mutual Reinforcement Effect (MRE) hypothesis. Extensive empirical experiments are conducted using LLMs, with the results confirming both the existence and validity of MRE. Furthermore, we apply MRE to practical text classification tasks, demonstrating its effectiveness. Specifically, the knowledgeable Verbalizer (KV) structure constructed through the Word-Level Information (WLI) approach outperforms the original method in text classification tasks. We believe these findings will serve as valuable reference for future researchers, facilitating further exploration and application of MRE."
        },
        {
            "title": "8 Limitation",
            "content": "Due to constraints in resources and time, this study focused solely on experiments with the LLAMA38b model. In future work, we aim to extend our experiments to additional LLMs for broader validation. Furthermore, in this application of the MRE theory, we applied the WLI to TLI. However, the reverse interaction applying TLI to WLI was not explored. We plan to address these limitations and explore these directions in future research."
        },
        {
            "title": "References",
            "content": "Ronan Collobert and Jason Weston. 2008. unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160167. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 41714186, Minneapolis, Minnesota. Association for Computational Linguistics. Ning Ding, Shengding Hu, Weilin Zhao, Yulin Chen, Zhiyuan Liu, Hai-Tao Zheng, and Maosong Sun. 2021. Openprompt: An open-source framework for prompt-learning. arXiv preprint arXiv:2111.01998. Chengguang Gan, Qingyu Yin, Xinyang He, Hanjun Wei, Yunhao Liang, Younghun Lim, Shijian Wang, Hexiang Huang, Qinghao Zhang, Shiwen Ni, et al. 2024. Mmm: Multilingual mutual reinforcement effect mix datasets & test with open-domain information extraction large language models. arXiv preprint arXiv:2407.10953. Chengguang Gan, Qinghao Zhang, and Tatsunori Mori. 2023a. Giellm: Japanese general information extraction large language model utilizing mutual reinforcement effect. arXiv preprint arXiv:2311.06838. Chengguang Gan, Qinghao Zhang, and Tatsunori Mori. 2023b. Sentence-to-label generation framework for multi-task learning of japanese sentence classification and named entity recognition. In International Conference on Applications of Natural Language to Information Systems, pages 257270. Springer. Chengguang Gan, Qinghao Zhang, and Tatsunori Mori. 2023c. Usa: Universal sentiment analysis model & construction of japanese sentiment text classification and part of speech dataset. arXiv preprint arXiv:2309.03787. Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong Sun. 2022a. Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text In Proceedings of the 60th Annual classification. Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 22252240, Dublin, Ireland. Association for Computational Linguistics. Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong Sun. 2022b. Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text In Proceedings of the 60th Annual classification. Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 22252240. Yoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 17461751. Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4582 4597. Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Recurrent neural network for text classification with multi-task learning. arXiv preprint arXiv:1605.05101. David Nadeau and Satoshi Sekine. 2007. survey of named entity recognition and classification. Lingvisticae Investigationes, 30(1):326. OpenAI. 2023. Gpt-4 technical report. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:2773027744. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter Liu. 2020. Exploring the limits of transfer learning with unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):54855551. Timo Schick and Hinrich Schütze. 2021. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 255269. Taylor Shin, Yasaman Razeghi, Robert Logan IV, Eric Wallace, and Sameer Singh. 2020. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 42224235. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288. Yu Zhang and Qiang Yang. 2021. survey on multitask learning. IEEE Transactions on Knowledge and Data Engineering, 34(12):55865609. Zexuan Zhong, Dan Friedman, and Danqi Chen. 2021. Factual probing is [mask]: Learning vs. learning to In Proceedings of the 2021 Conference of recall. the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 50175033."
        }
    ],
    "affiliations": [
        "Yokohama National University, Japan"
    ]
}