{
    "paper_title": "SynthDetoxM: Modern LLMs are Few-Shot Parallel Detoxification Data Annotators",
    "authors": [
        "Daniil Moskovskiy",
        "Nikita Sushko",
        "Sergey Pletenev",
        "Elena Tutubalina",
        "Alexander Panchenko"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Existing approaches to multilingual text detoxification are hampered by the scarcity of parallel multilingual datasets. In this work, we introduce a pipeline for the generation of multilingual parallel detoxification data. We also introduce SynthDetoxM, a manually collected and synthetically generated multilingual parallel text detoxification dataset comprising 16,000 high-quality detoxification sentence pairs across German, French, Spanish and Russian. The data was sourced from different toxicity evaluation datasets and then rewritten with nine modern open-source LLMs in few-shot setting. Our experiments demonstrate that models trained on the produced synthetic datasets have superior performance to those trained on the human-annotated MultiParaDetox dataset even in data limited setting. Models trained on SynthDetoxM outperform all evaluated LLMs in few-shot setting. We release our dataset and code to help further research in multilingual text detoxification."
        },
        {
            "title": "Start",
            "content": "SynthDetoxM: Modern LLMs are Few-Shot Parallel Detoxification Data Annotators Daniil Moskovskiy1,2* Nikita Sushko1,2* Sergey Pletenev1,2 Elena Tutubalina1,3,4 Alexander Panchenko2,1 1AIRI 2Skoltech 3Sber AI 4ISP RAS Research Center for Trusted AI Correspondence: {d.moskovskiy, a.panchenko}@skol.tech 5 2 0 2 0 1 ] . [ 1 4 9 3 6 0 . 2 0 5 2 : r a"
        },
        {
            "title": "Abstract",
            "content": "Existing approaches to multilingual text detoxification are hampered by the scarcity of parallel multilingual datasets. In this work, we introduce pipeline for the generation of multilingual parallel detoxification data. We also introduce SynthDetoxM, manually collected and synthetically generated multilingual parallel text detoxification dataset comprising 16,000 high-quality detoxification sentence pairs across German, French, Spanish and Russian. The data was sourced from different toxicity evaluation datasets and then rewritten with nine modern open-source LLMs in few-shot setting. Our experiments demonstrate that models trained on the produced synthetic datasets have superior performance to those trained on the human-annotated MultiParaDetox dataset even in data limited setting. Models trained on SynthDetoxM outperform all evaluated LLMs in few-shot setting. We release our dataset and code to help further research in multilingual text detoxification. Warning: this paper contains illustrative examples of texts that readers may find offensive or disturbing."
        },
        {
            "title": "Introduction",
            "content": "The proliferation of social networks and text-based internet media has highlighted the issue of online toxicity and hate speech (Saha et al., 2019). This phenomenon not only creates an unpleasant environment for users but also deters advertisers, potentially impacting the economic viability of these platforms (Fortuna and Nunes, 2018). Consequently, there is an urgent need for effective mechanisms to measure and mitigate toxicity in online spaces. promising approach to addressing this challenge is text detoxification of text through paraphrasing (Krishna et al., 2020). Text detoxification is subtask of text style transfer (TST), which involves rewriting text while preserving its original *Equal contribution. Toxic Text Detoxified Text German Wie be**oppt muss man sein? Spanish Que os den por el French Russian c**o. cest moi at***dé ! je suis tombé ! я мужик а г**но вы Wie verwirrt muss man sein? Que os dé muy mala suerte. Cest moi qui suis tombé ! Я мужчина, а вы неправы Table 1: Examples of the source toxic texts across different languages and their respective synthetic detoxifications from our SynthDetoxM. meaning and altering specific style attribute, such as formality, bias, expressiveness, sentiment, or, in the case of detoxification, toxicity (Fu et al., 2018; Lai et al., 2021). While significant progress has been made in monolingual TST and detoxification, both in supervised and unsupervised settings (Dale et al., 2021; Logacheva et al., 2022; Pour et al., 2023), multilingual text detoxification remains largely unsolved problem. This is primarily due to two factors: the scarcity of parallel detoxification data across multiple languages and the suboptimal performance of unsupervised methods in cross-lingual settings (Dementieva et al., 2023). Manual or crowdsourced data collection is challenging and costly task (Rao and Tetreault, 2018; Reid and Artetxe, 2023; Konovalov et al., 2016b), creating parallel data with the use of modern LLMs, which already proven to work well for the tasks of text classification (Sun et al., 2023) and question answering (Ye et al., 2022), remains underexplored. To address these challenges and facilitate the development of multilingual text detoxification models and datasets, we propose framework for generating parallel multilingual synthetic detoxification data and SynthDetoxM, large-scale multilinugal synthetic parallel text detoxification dataset, which was created using this framework. Figure 1: An illustration of the proposed approach for collecting and generating the multilingual text detoxification dataset SynthDetoxM. Our dataset is comprised of 16,000 high-quality synthetic detoxification pairs across four languages: German, Spanish, French and Russian. The dataset was created using few-shot prompting and selecting the best generations of five different open-source LLMs. The answers were combined using handcrafted heuristic, providing the best answers from each model to ensure diversity and quality of the final data. Our contributions can be summarized as follows: 1. We propose framework for generating synthetic parallel multilingual detoxification data using few-shot prompting of LLMs. 2. We create SynthDetoxM, large-scale multilingual synthetic parallel dataset for text detoxification, helping to address the data scarcity issue in the detoxification task. 3. We conduct thorough empirical evaluation of the proposed dataset, including linguistic analysis of the data and benchmarking against the human-annotated MultiParaDetox. We openly release the generated data and code."
        },
        {
            "title": "2.1 Text Style Transfer",
            "content": "Text Style Transfer (TST), the task of rewriting the text in target style while preserving its semantic content and fluency, has garnered significant attention in the natural language processing community due to its potential applications in text generation (Fu et al., 2018). TST encompasses various subtasks, including formality style transfer (Wang et al., 2020; Lai et al., 2021), sentiment style transfer (Yu et al., 2021), authorship style transfer (Horvitz et al., 2024; Liu et al., 2024), and 1github.com/s-nlp/synthdetoxm detoxification (Dale et al., 2021; Atwell et al., 2022; Moskovskiy et al., 2022, 2024). With the advent of Large Language Models (LLMs), in-context learning methods have increasingly been utilized for TST and detoxification tasks. Suzgun et al. (2022) proposed novel approach to TST by prompting LLMs and then reranking the generated texts based on three TST metrics: text similarity, target style strength, and fluency. Similarly, Reif et al. (2022) demonstrated the effectiveness of prompting GPT-3, state-of-the-art LLM at the time, to rewrite texts in desired style."
        },
        {
            "title": "2.2 Text Detoxification",
            "content": "Text Detoxification, subtask of Text Style Transfer (TST), involves transforming an input text xi, identified as toxic through toxicity estimation models, into text yi that is non-toxic in style while maintaining semantic similarity and fluency. In this context, toxicity refers to language that is harmful, offensive, or inappropriate. Due to the lack of parallel training data, early research focused on unsupervised detoxification methods (dos Santos et al., 2018; Dale et al., 2021; Hallinan et al., 2023; Pour et al., 2023). For instance,(Logacheva et al., 2022) and APPDIA (Atwell et al., 2022), has enabled the training of sequence-to-sequence models (Logacheva et al., 2022; Pour et al., 2023) that outperform most unsupervised approaches in terms of rewritten toxicity, fluency, and semantic similarity. In parallel, Moskovskiy et al. (2024) explored the use of activation patching in LLMs to generate synthetic parallel detoxification data for English. Their results demonstrated that training detoxification models on this data yields performance comparable to models trained on manually annotated datasets in automatic evaluations, while achieving superior quality in human assessments."
        },
        {
            "title": "2.3 Multilingual Text Style Transfer",
            "content": "The scarcity of high-quality parallel multilingual detoxification data remains major challenge in the field. Recently, new non-English parallel datasets have been introduced for various TST tasks, including Bangla language parallel sentiment style transfer dataset (Mukherjee et al., 2023) and the extension of the GYAFC dataset to Portuguese, French, and Italian, resulting in XFORMAL (Briakou et al., 2021). Following the crowdsourcing pipeline introduced by (Logacheva et al., 2022), parallel text detoxification dataset for Russian was collected (Moskovskiy et al., 2022). Later, using the similar data annotation pipeline, Dementieva et al. (2024) collected 1000 sentence pairs across nine languages, resulting in the MultiParaDetox dataset for corresponding shared task on multilingual text detoxification. Furthermore, in more recent work Dementieva et al. (2025), provide an in-depth analysis of toxicity characteristics across languages, exploring descriptive linguistic features that influence detoxification quality. Nevertheless, the size of MultiParaDetox is far from satisfactory with 1000 sentence pairs per language, only 400 of which are publicly available. The remaining 600 pairs comprised the test set for the multilingual text detoxification shared task (Dementieva et al., 2024). Such relatively small dataset may be insufficient for training big multilingual language models for multilingual text detoxification. To bridge this gap, we present SynthDetoxM - synthetic parallel detoxification corpus for four European languages, namely, German, Spanish, French, and Russian, with 4000 samples for each language. The dataset creationg pipeline presented in our work can easily be transferred to other languages as well, drastically reducing the cost of annotation for parallel detoxification datasets."
        },
        {
            "title": "3 Methodology",
            "content": "In this section, we describe the pipeline introduced for collecting the multilingual parallel text detoxification dataset, SynthDetoxM. general illustration of our approach is shown in Figure 1."
        },
        {
            "title": "3.1 Data Collection",
            "content": "To create SynthDetoxM, we begin by selecting several thousand non-parallel toxic texts from publicly available toxicity identification datasets. We focus on four languages for SynthDetoxM: German, French, Spanish and Russian. From these datasets Figure 2: Number of accepted samples in the final SynthDetoxM dataset with respect to the LLM by language. we select only the texts that were marked as toxic by human annotators, excluding non-toxic examples. In cases of multiple annotations, we retained the sample where the majority of annotators classified the sentence as toxic. To enhance the final data quality, we employ sample-level filtering using the STA and SIM metrics2 and we also apply data augmentation techniques utilizing the Perspective API (Lees et al., 2022). Since the API returns both toxicity scores and toxic spans, we further improve data quality by splitting the source texts into sentences and removing those sentences that do not intersect with the detected toxic spans. This filtering process results in larger dataset of toxic sentences, and we also split overly long inputs into separate examples. Russian For the Russian dataset, we use data from the Jigsaw Toxic Comments Classification Challenge (Kivlichan et al., 2020), Russian Language Toxic Comments (Belchikov, 2019) and Toxic Russian Comments (Semiletov, 2020). From these sources, we select only those rows labeled as toxic, resulting in more than 15,697 toxic texts. We then calculate the STA and SIM metrics, applying threshold of 0.5 for filtering. After removing emojis, eliminating texts with fewer than five words or more than 30 words, and splitting the sentences using toxic spans from Perspective API, our final dataset consists of 15,697 texts. German For German, we use the toxicity identification data from the GermEval 2021 shared 2Evaluation metrics are described in Section 4.3 task (Risch et al., 2021) and RP-Mod and RPCrowd (Assenmacher et al., 2021) to create dataset of 4,946 toxic texts. We apply the same filtering and augmentation pipeline as for the Russian dataset, but with lower STA score threshold of 0.3. This resulted in dataset of 4,946 texts, which exceeds the original size of the raw dataset. We attribute this increase to the higher median length of German sentences, which leads to greater number of split texts. Spanish For Spanish, we utilize data from the Jigsaw Toxic Comments Classification Challenge (Kivlichan et al., 2020) and the Clandestino dataset (Capozzi et al., 2021). This results in an initial dataset of 10,260 toxic texts. We apply the same filtering and augmentation pipeline as for the German dataset, using the same STA threshold of 0.3. This process yields final dataset of 5,826 texts. French For French, we use the data from the Jigsaw Toxic Comments Classification Challenge (Kivlichan et al., 2020) and the MLMA Hate Speech Corpus (Ousidhoum et al., 2019) to generate dataset of 5,424 toxic texts. As the toxicity classifier used in other languages does not support French, we instead use the Perspective API to get toxicity scores. After applying STA score threshold of 0.25, we obtain dataset of 4,310 sentences."
        },
        {
            "title": "3.1.1 Parallel Data Generation Pipeline",
            "content": "To generate parallel detoxification data, we use various open-source LLMs in few-shot generation setup. Specifically, we employed the following models: Qwen 2.5 32B by Qwen (Yang et al., 2024; Team, 2024); Command-R 32B by Cohere (Cohere, 2024); Gemma 2 27B by Google (Rivière et al., 2024); Aya Expanse in 32B and 8B versions by Cohere (Dang et al., 2024); Mistral Small 22B, Mistral Nemo 12B by Mistral AI (Mistral, 2024a,b); and Llama 3.1 70B and 8B models respectively, by Meta (Dubey et al., 2024). While not all these models are explicitly designed for multilingual tasks, our experiments show that all of them support the languages considered in this work."
        },
        {
            "title": "3.1.2 Few-Shot Example Mining",
            "content": "To select the best toxic and non-toxic pairs for fewshot generation, we calculate the STA and SIM metrics for all sentences in Russian, German and Spanish from the multilingual toxicity detection dataset3. We then rank the top 10 sentencesbased on the following score: 1 (cid:18) 1 STA(xi) 1 STA(yi) Score(xi; yi) = (cid:19) (1 SIM(xi; yi)) where STA(xi) and STA(yi) represent the toxicity scores for the original and detoxified examples, respectively. SIM(xi; yi) is the cosine distance between the embeddings of toxic and detoxified sentences. This ranking criterion is chosen to ensure highquality detoxification without altering the original meaning of the sentences. Since the sentences used for few-shot prompting have been annotated by human experts, we expect the detoxification quality to be satisfactory. Additionally, the rewriting process of toxic words often leads to an expanded distance between toxic and non-toxic sentences, increasing the distinction in non-toxicity. To maximize both the distance and the distinction between the original and detoxified sentences, we select harder and more meaningful examples for few-shot prompting, which helps improve the detoxification process. For French, which is not represented in the MultiParaDetox dataset, we used human annotators to detoxify 10 randomly chosen sentences from the existing non-parallel data. After generating detoxified examples, we perform refusal filtering using refusal classification model (see details in Appendix D). Additionally, we use simple threshold-based non-detoxifiability metric, calculated by dividing the absolute reduction in the STA score by the original STA score. We compare the resulting detoxifiability scores to fixed threshold of 0.5. If the score falls below this threshold, the example is considered nondetoxifiable. After generating five detoxification datasets in each language using the selected models, we rank the sentences by their multiplied STA and SIM metrics and select the top-scoring examples. This metric helps mitigate issues such as refusal(where models refuse to generate text due to toxicity) and copy-paste generation (where the model generates the input toxic sentences without modification), as copy-paste generation typically results in low STA score, while refusal leads to low SIM score. 3hf.co/multilingual_toxicity_dataset STAT STAD SIM STADSIM German 0.389 0.853 0.793 Spanish 0.514 0.920 0.736 0.583 0.913 0.677 French Russian 0.467 0.924 0.731 0.675 0.681 0.624 0.678 Table 2: Average toxicity levels across different languages for source toxic (T) and generated detoxified (D) texts, along with similarity scores. STAT represents the toxicity level of the original text, while STAD corresponds to the detoxified text. In our work, for text the score STA(x) = 1 (toxicx)."
        },
        {
            "title": "3.2 Final Composed Dataset",
            "content": "After all preprocessing, cleaning and filtering steps we compose SynthDetoxM - manually collected and synthetically paraphrased parallel detoxification dataset on 16,000 toxic and non-toxic text pairs for Spanish, German, Russian and French. We show the statistics of detoxification candidate acceptance with respect to each LLM Languagewise in Table 5 and Figure 2. According to the statistics, Qwen 2.5 generated the most preferrable detoxifications among other models. However, upon manual examination we noticed that Qwen tended to occasionally insert tokens of Chinese text into the generated text though was prompted to answer only on the language of the source text. Therefore, the strict reranking and filtering criteria of generated detoxification candidates is necessary."
        },
        {
            "title": "3.3 Data Quality Evaluation Pipeline",
            "content": "To evaluate the quality of our generated detoxification data in Russian, German, and Spanish, we use our dataset for training and compare the performance of models trained on SynthDetoxMwith those trained on the human-annotated parallel detoxification dataset, MultiParaDetox Dementieva et al. (2024). Due to its absence in the MultiParaDetox dataset, French is excluded from this comparison. more detailed linguistic analysis of the dataset can be found in Appendix E."
        },
        {
            "title": "4.1 Data Quality Tests",
            "content": "To evaluate the efficacy of our SynthDetoxM for German, Spanish and Russian, weve trained series of sequence-to-sequence models on different folds from the dataset. Since MultiParaDetox consists of only 400 pairs of toxic texts with their humanwritten non-toxic rephrasings, we split our created SynthDetoxM dataset into 10 chunks of 400 pairs for German, Spanish and Russian. We trained 10 mT0 models on different chunks of the dataset and evaluated their average performance on the MultiParaDetox test set. Additionally, we test if using both our SynthDetoxM and MultiParaDetox for training would lead to improved performance."
        },
        {
            "title": "4.2 Toxicity and Similarity of Synthetic Texts",
            "content": "To further assess the quality of the generated data, we computed the STA and SIM scores using the Perspective API for Russian, German, Spanish, and French. These metrics were selected for their relevance to detoxification tasks and their ability to quantitatively assess our synthetic dataset. We also assessed the quality of the French subset of SynthDetoxM, as French is not represented in the MultiParaDetox dataset, and therefore cannot be evaluated through model training. The scores are presented in Figure 3 and Table 2. The results indicate that French achieves comparable automatic metric scores to other languages, suggesting that detoxification models trained on this data would perform similarly. Therefore, we hypothesize that the French subset of SynthDetoxM is valuable addition to the dataset, enabling the training of effective detoxification models for French language processing tasks."
        },
        {
            "title": "4.3 Automatic Evaluation Setup",
            "content": "To assess the quality of the generated Spanish, Russian, and German data, we follow the evaluation pipeline of Dementieva et al. (2024), developed for the multilingual text detoxification shared task. These metrics are inspired by prior work on monolingual text detoxification for English and Russian (Logacheva et al., 2022; Moskovskiy et al., 2022). Style Transfer Accuracy (STA) For computation of this metric we use multilingual toxicity classifier based on multilingual XLM-R4 (Conneau et al., 2020) text classification model, trained on binary toxicity detection dataset. Content Similarity (SIM) For computation of this metric we use the cosine distance between LaBSE5 embeddings (Feng et al., 2022) of the source texts and the generated texts. 4hf.co/textdetox/xlmr-large-toxicity-classifier 5hf.co/sentence-transformers/LaBSE Figure 3: Distribution of STA toxicity scores of toxic and neutral examples in the dataset. The original toxic texts are in orange, while detoxified texts are in blue. For readability we apply Gaussian smoothing. Fluency (FL) Fluency assesses how closely detoxified texts resemble human-written references. Previous works on English have employed CoLAbased classifiers to estimate text fluency (Logacheva et al., 2022; Moskovskiy et al., 2024). However, due to the absence of CoLA datasets for all considered languages Dementieva et al. (2024) used ChrF1 as substitute. While recent work has introduced MELA (Zhang et al., 2024), multilingual extension of CoLA covering all the languages in this study, we maintain the evaluation pipeline of Dementieva et al. (2024) and continue using ChrF1. Nonetheless, ChrF1 remains coarse approximation of text fluency, which may negatively impact the overall scores (see Appendix for details). Joint score (J) The metrics STA, SIM and FL are subsequently combined into the final score which is used for the final ranking of approaches. Given an input toxic text xi and its output detoxified version yi, for test set of samples: = 1 (cid:80) i=1 STA(yi) SIM(xi, yi) FL(xi, yi), where STA(yi), SIM(xi, yi), FL(xi, yi) [0, 1] for each text detoxification output yi."
        },
        {
            "title": "4.4 Baselines",
            "content": "In our work we adopt the baselines for multilingual detoxification described in MultiParaDetox (Dementieva et al., 2024) that are inspired by prior works on text detoxification (Logacheva et al., 2022; Dementieva et al., 2023). Duplicate is the simplest baseline possible which copies an input toxic sentence. This baseline has 1.0 (or 100%) SIM score by definition. Delete removes the toxic words according to predefined list of inappropriate words. Dementieva et al. (2024) collects the lists of such toxic keywords for all target languages based on openly available sources. These lists are available online6. Backtranslation has proven to be effective in previous works (Dementieva et al., 2023; Prabhumoye et al., 2018; Konovalov et al., 2016a). Following (Dementieva et al., 2023) we translate texts into English with NLLB translation model (Costajussà et al., 2022)7. The translated data is then detoxified with the ParaDetox BART (Logacheva et al., 2022) model8. After that, the detoxified texts are translated back into the source language using NLLB."
        },
        {
            "title": "4.5 Training Configuration",
            "content": "In our experimental evaluation, of the generated multilingual parallel detoxificiation dataset SynthDetoxM we follow the most efficient approaches used during the TextDetox 2024 Shared Task (Sushko, 2024; Protasov, 2024; Rykov et al., 2024), where top three solutions in automatic evaluations utilized fine-tuning of multilingual encoder-decoder language model mT0 (Muennighoff et al., 2023). 6hf.co/multilingual_toxic_lexicon 7hf.co/facebook/nllb-200-distilled-600M 8hf.co/s-nlp/bart-base-detox"
        },
        {
            "title": "STA SIM FL",
            "content": "J STASIM"
        },
        {
            "title": "Human References",
            "content": "0.733 0.709 0.732 0.722 0.848 0.602 0.383 MPD SDM (Subset) 0.681 0.912 0.745 0.463 0.728 0.899 0.734 0.484 SDM SDM+MPD 0.615 0.954 0.821 0.483 0.612 0.597 0.655 0."
        },
        {
            "title": "Russian",
            "content": "0.748 0.852 0.643 0.434 MPD SDM (Subset) 0.858 0.850 0.656 0.478 0.927 0.839 0.656 0.521 SDM SDM+MPD 0.815 0.886 0.726 0.540 0.637 0.729 0.778 0."
        },
        {
            "title": "Spanish",
            "content": "0.597 0.880 0.616 0.335 MPD SDM (Subset) 0.795 0.856 0.611 0.416 0.864 0.861 0.621 0.471 SDM SDM+MPD 0.681 0.907 0.653 0.413 0.525 0.681 0.744 0.618 Table 3: Results of the automatic evaluation for mT0-XL on German, Russian, and Spanish trained on original data (MPD stands for MultiParaDetox), our collected and synthetically generated data (SDM stands for SynthDetoxM) and on their combination (MultiParaDetox + SynthDetoxM). We use mT0-XL model9 and perform finetuning in full precision. We use AdaFactor optimizer (Shazeer and Stern, 2018) with batch size of 16, 50 warmup steps and set maximum sequence length to 512. We fine-tune mT0 for 2 epochs in all setups. According to our experiments, the increased number of training epochs does not increase the final performance of the model. This might be explained to the overall training data scarcity compared to the size of the model: mT0-XL has 3 billion parameters and is being fine-tuned on 1,200 samples (400 for each of the three languages)."
        },
        {
            "title": "5 Results",
            "content": "Table 3 presents the results of our experimental evaluation of SynthDetoxM. For clarity, the table is divided by language. We compare the performance of mT0-XL trained on human-annotated MultiParaDetox data (MPD) with mT0-XL fine-tuned on two subsets of SynthDetoxM: subset of 400 samples per language, matching the MPD size (denoted as SDM (Subset)), and the full SynthDetoxM dataset. Additionally, following prior work (Xu et al., 2023), 9hf.co/bigscience/mt0-xl"
        },
        {
            "title": "Duplicate\nDelete\nBacktranslation",
            "content": "0.287 0.362 0.233 0.090 0.319 0.275 0.048 0.255 0.223 mT0-XL supervised fine-tuning MultiParaDetox SDM (Subset) SDM 0.446 0.460 0. 0.472 0.344 0.402 0.475 0.470 0.546 10-shot LLM prediction Gemma 2 Mistral Nemo Mistral Small Command Qwen 2.5 Llama 3.1 8B Aya Expanse 8B Aya Expanse 32B 0.353 0.286 0.371 0.328 0.402 0.394 0.305 0.399 0.380 0.290 0.308 0.344 0.443 0.341 0.246 0.320 0.404 0.258 0.273 0.402 0.428 0.357 0.225 0. Table 4: Text detoxification results in terms of scores for German, Spanish, and Russian languages. The best overall results are boldfaced. The baselines and human references are from (Dementieva et al., 2024). we investigate whether two-stage fine-tuning approachfirst on SynthDetoxM, then on MPD (denoted as SDM + MPD)yields further improvements. The highest SIM scores for German and Russian are achieved by mT0-XL trained on MultiParaDetox (0.954 and 0.886, respectively), with the two-stage training approach (SDM + MPD) yielding slightly higher similarity in Russian but lower in German. However, for STA, models trained on SynthDetoxM consistently outperform MultiParaDetox across all languages, both when trained on the full dataset and on similarly sized subset. Models trained on SynthDetoxM exhibit slightly lower FL scores, likely due to the referencedependent nature of this metric. Despite this, the aggregated metricstrongly influenced by FLis significantly higher for models trained on both the full SynthDetoxM and its subset compared to MultiParaDetox. Notably, incorporating MultiParaDetox into the training process (SDM + MPD) results in drop in scores."
        },
        {
            "title": "To further illustrate the advantages of training on",
            "content": "Figure 4: Side-by-side comparison of model outputs across all languages, evaluated by GPT-4o. The results highlight the relative performance of the models in generating detoxified text for German, Russian, and Spanish. The notation is similar to the notation from Table 3. SynthDetoxM, Table 3 also presents the product of STA and SIM. Even without considering FL, models trained on SynthDetoxM outperform those trained on MultiParaDetox in all setups and languages. Additionally, Table 4 reports the scores of mT0-XL trained on MultiParaDetox, averaged across 10 subsets of SynthDetoxM and the full SynthDetoxM, compared to baselines and large language model (LLM)-based detoxification in 10-shot generation setting. Finally, we provide Side-by-Side (SBS) comparison of the fine-tuned mT0-XL models to evaluate their detoxification performance. Following (Moskovskiy et al., 2024), we employ GPT-4o as an evaluator to select the preferred detoxified outputs. The results of this comparison across German, Spanish, and Russian languages are summarized in Figure 4 and detailed in Appendix F. Our SBS evaluation shows clear preference for detoxifications produced by SDM over MultiParaDetox (MPD), with SDM winning in 59% of cases compared to 19% for MPD, and 22% resulting in ties. The subset of SDM also outperforms MPD in 58% of cases. When comparing SDM against its combination with MPD (SDM + MPD), SDM is preferred in 47% of cases, with 21% favoring SDM + MPD, and 33% tied. Additionally, the full SDM dataset is slightly preferred over the batch processing version in 55% of cases, with 35% ties. See Appendix for more details."
        },
        {
            "title": "6 Conclusions",
            "content": "We present several contributions to multilingual text detoxification technology. Firstly, we successfully extend the concept of few-shot prompting for detoxification to multilingual context, building upon previous monolingual approaches and propose framework for generation of multilingual synthetic detoxification data. Secondly, we introduce SynthDetoxM, large-scale multilingual synthetic parallel dataset designed to address the long-standing issue of data scarcity in text detoxification research. Notably, our dataset, created using our selection criteria, demonstrates competitive quality to existing human-annotated datasets, surpassing them in both low resource and high resource settings. Our comprehensive evaluation of SynthDetoxM reveals its effectiveness in training high-performing models for text detoxification. Specifically, our experiments show that models trained on our dataset outperform those, which were trained on similar amount of human-annotated data. Furthermore, training detoxification encoder-decoder model on full SynthDetoxM yields model, which surpasses the performance of most large language models in few-shot generation setups. Findings presented in our work, show usefulness of the generated data for the task of multilingual text detoxification and pave the way for future research and developments of related technologies."
        },
        {
            "title": "Acknowledgments",
            "content": "The contribution of E.T. was supported by grant for research centers in the field of artificial intelligence, provided by the Analytical Center for the Government of the Russian Federation in accordance with the subsidy agreement (agreement identifier 000000D730321P5Q0002) and the agreement with the Ivannikov Institute for System Programming of the Russian Academy of Sciences dated November 2, 2021 No. 70-2021-00142."
        },
        {
            "title": "7 Limitations",
            "content": "One of the limitations of our work is that we are focusing only on explicit type of toxicity. Additionally, definition and type of toxicity changes drastically between the language, e.g. things, that are toxic in one language may be perfectly normal in other language. Another limitation of this work is our constraint with computational resources, which led to our use of smaller and simpler models for synthetic data generation, which could fit into single NVIDIA A100 80GB GPU. Usage of larger could potentially result in higher quality and diversity of synthetic data. Moreover, the comparison with proprietary models would strengthen the evaluation as it is done in recent works Dementieva et al. (2025). Additionally, we were limited by the amount of annotated non-parallel toxic datasets in some of the languages, which limited the amount of possible generated synthetic data. In future, we plan to extend our work to other languages, such as Italian, Polish and others."
        },
        {
            "title": "8 Ethical Considerations",
            "content": "While working with the task detoxification we are fully aware of the ethical responsibilities involved. As researchers, we handle this sensitive area with care and integrity. The main goal of text detoxification is to make online interactions safer and more inclusive by reducing harmful or offensive language. While these datasets are meant to train models to detect and reduce toxic language, theres chance they could be used in the wrong waysuch as creating models that spread harmful or offensive content. This could lead to hate speech and harassment. Its also important to clarify that the goal of text detoxification isnt to suppress free speech or force Instead, we aim automatic changes to content. to build models that offer non-toxic alternatives, helping users choose better language on their own. By giving suggestions rather than enforcing edits, we respect peoples freedom while encouraging more positive online environment."
        },
        {
            "title": "References",
            "content": "Dennis Assenmacher, Marco Niemann, Kilian Müller, Moritz Seiler, Dennis M. Riehle, and Heike Trautmann. 2021. Rp-mod & rp-crowd: Moderatorand crowd-annotated german news comment datasets. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual. Katherine Atwell, Sabit Hassan, and Malihe Alikhani. 2022. APPDIA: discourse-aware transformerbased style transfer model for offensive social media conversations. In Proceedings of the 29th International Conference on Computational Linguistics, COLING 2022, Gyeongju, Republic of Korea, October 12-17, 2022, pages 60636074. International Committee on Computational Linguistics. Anatoly Belchikov. 2019. Russian language toxic comments. Accessed: 2024-10-14. Eleftheria Briakou, Di Lu, Ke Zhang, and Joel R. Tetreault. 2021. Olá, bonjour, salve! XFORMAL: benchmark for multilingual formality style transfer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, pages 31993216. Association for Computational Linguistics. Arthur Capozzi, Gianmarco De Francisci Morales, Yelena Mejova, Corrado Monti, André Panisson, and Daniela Paolotti. 2021. Clandestino or rifugiato? anti-immigration facebook ad targeting in italy. In CHI 21: CHI Conference on Human Factors in Computing Systems, Virtual Event / Yokohama, Japan, May 8-13, 2021, pages 179:1179:15. ACM. Cohere. 2024. Command series 0824. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 84408451. Association for Computational Linguistics. Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Y. Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loïc Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022. No language left behind: Scaling human-centered machine translation. CoRR, abs/2207.04672. David Dale, Anton Voronov, Daryna Dementieva, Varvara Logacheva, Olga Kozlova, Nikita Semenov, and Alexander Panchenko. 2021. Text detoxification using large pre-trained neural models. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pages 79797996. Association for Computational Linguistics. John Dang, Shivalika Singh, Daniel Dsouza, Arash Ahmadian, Alejandro Salamanca, Madeline Smith, Aidan Peppin, Sungjin Hong, Manoj Govindassamy, Terrence Zhao, Sandra Kublik, Meor Amer, Viraat Aryabumi, Jon Ander Campos, Yi-Chern Tan, Tom Kocmi, Florian Strub, Nathan Grinsztajn, Yannis Flet-Berliac, Acyr Locatelli, Hangyu Lin, Dwarak Talupuru, Bharat Venkitesh, David Cairuz, Bowen Yang, Tim Chung, Wei-Yin Ko, Sylvie Shang Shi, Amir Shukayev, Sammie Bae, Aleksandra Piktus, Roman Castagné, Felipe Cruz-Salinas, Eddie Kim, Lucas Crawhall-Stein, Adrien Morisot, Sudip Roy, Phil Blunsom, Ivan Zhang, Aidan Gomez, Nick Frosst, Marzieh Fadaee, Beyza Ermis, Ahmet Üstün, and Sara Hooker. 2024. Aya expanse: Combining research breakthroughs for new multilingual frontier. Preprint, arXiv:2412.04261. Daryna Dementieva, Nikolay Babakov, Amit Ronen, Abinew Ali Ayele, Naquee Rizwan, Florian Schneider, Xintong Wang, Seid Muhie Yimam, Daniil Alekhseevich Moskovskiy, Elisei Stakovskii, Eran Kaufman, Ashraf Elnagar, Animesh Mukherjee, and Alexander Panchenko. 2025. Multilingual and explainable text detoxification with parallel corpora. In Proceedings of the 31st International Conference on Computational Linguistics, COLING 2025, Abu Dhabi, UAE, January 19-24, 2025, pages 79988025. Association for Computational Linguistics. Daryna Dementieva, Daniil Moskovskiy, Nikolay Babakov, Abinew Ali Ayele, Naquee Rizwan, Florian Schneider, Xintong Wang, Seid Muhie Yimam, Dmitry Ustalov, Elisei Stakovskii, Alisa Smirnova, Ashraf Elnagar, Animesh Mukherjee, and Alexander Panchenko. 2024. Overview of the multilingual text detoxification task at PAN 2024. In Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024, volume 3740 of CEUR Workshop Proceedings, pages 24322461. CEUR-WS.org. Daryna Dementieva, Daniil Moskovskiy, David Dale, and Alexander Panchenko. 2023. Exploring methods for cross-lingual text style transfer: The case of text detoxification. In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics, IJCNLP 2023 -Volume 1: Long Papers, Nusa Dua, Bali, November 1 - 4, 2023, pages 1083 1101. Association for Computational Linguistics. media with unsupervised text style transfer. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 2: Short Papers, pages 189194. Association for Computational Linguistics. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurélien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Rozière, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Graeme Nail, Grégoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel M. Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Kartikeya Upasani, Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, and et al. 2024. The llama 3 herd of models. CoRR, abs/2407.21783. Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. 2022. Language-agnostic BERT sentence embedding. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 878 891. Association for Computational Linguistics. Paula Fortuna and Sérgio Nunes. 2018. survey on automatic detection of hate speech in text. ACM Computing Surveys (CSUR), 51(4):130. Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, and Rui Yan. 2018. Style transfer in text: Exploration and evaluation. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 663670. AAAI Press. Cícero Nogueira dos Santos, Igor Melnyk, and Inkit Padhi. 2018. Fighting offensive language on social Skyler Hallinan, Alisa Liu, Yejin Choi, and Maarten Sap. 2023. Detoxifying text with marco: Controllable revision with experts and anti-experts. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 228242. Association for Computational Linguistics. Zachary Horvitz, Ajay Patel, Kanishk Singh, Chris Callison-Burch, Kathleen R. McKeown, and Zhou Yu. 2024. Tinystyler: Efficient few-shot text style transfer with authorship embeddings. In Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024, pages 1337613390. Association for Computational Linguistics. Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, Aleksander Madry, Alex Baker-Whitcomb, Alex Beutel, Alex Borzunov, Alex Carney, Alex Chow, Alex Kirillov, Alex Nichol, Alex Paino, Alex Renzin, Alex Tachard Passos, Alexander Kirillov, Alexi Christakis, Alexis Conneau, Ali Kamali, Allan Jabri, Allison Moyer, Allison Tam, Amadou Crookes, Amin Tootoonchian, Ananya Kumar, Andrea Vallone, Andrej Karpathy, Andrew Braunstein, Andrew Cann, Andrew Codispoti, Andrew Galu, Andrew Kondrich, Andrew Tulloch, Andrey Mishchenko, Angela Baek, Angela Jiang, Antoine Pelisse, Antonia Woodford, Anuj Gosalia, Arka Dhar, Ashley Pantuliano, Avi Nayak, Avital Oliver, Barret Zoph, Behrooz Ghorbani, Ben Leimberger, Ben Rossen, Ben Sokolowsky, Ben Wang, Benjamin Zweig, Beth Hoover, Blake Samic, Bob McGrew, Bobby Spero, Bogo Giertler, Bowen Cheng, Brad Lightcap, Brandon Walkin, Brendan Quinn, Brian Guarraci, Brian Hsu, Bright Kellogg, Brydon Eastman, Camillo Lugaresi, Carroll L. Wainwright, Cary Bassin, Cary Hudson, Casey Chu, Chad Nelson, Chak Li, Chan Jun Shern, Channing Conger, Charlotte Barette, Chelsea Voss, Chen Ding, Cheng Lu, Chong Zhang, Chris Beaumont, Chris Hallacy, Chris Koch, Christian Gibson, Christina Kim, Christine Choi, Christine McLeavey, Christopher Hesse, Claudia Fischer, Clemens Winter, Coley Czarnecki, Colin Jarvis, Colin Wei, Constantin Koumouzelis, and Dane Sherburn. 2024. Gpt-4o system card. CoRR, abs/2410.21276. Md Tawkat Islam Khondaker, Muhammad AbdulMageed, and Laks V. S. Lakshmanan. 2024. Detoxllm: framework for detoxification with explanations. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024, pages 1911219139. Association for Computational Linguistics. Ian Kivlichan, Jeffrey Sorensen, Julia Elliott, Lucy Vasserman, Martin Görner, and Phil Culliton. 2020. Jigsaw multilingual toxic comment classification. Vasily Konovalov, Meni Adler, and Ido Dagan. 2016a. Effective paraphrase expansion in addressing lexical variability. In Proceedings of the Artificial Intelligence and Natural Language (AINL FRUCT 2016), page 8791, St.-Petersburg, Russia. Vasily Konovalov, Oren Melamud, Ron Artstein, and Ido Dagan. 2016b. Collecting Better Training Data using Biased Agent Policies in Negotiation DiaIn Proceedings of WOCHAT, the Second logues. Workshop on Chatbots and Conversational Agent Technologies, Los Angeles. Zerotype. Kalpesh Krishna, John Wieting, and Mohit Iyyer. 2020. Reformulating unsupervised style transfer as paraphrase generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 737762. Association for Computational Linguistics. Huiyuan Lai, Antonio Toral, and Malvina Nissim. 2021. Thank you bart! rewarding pre-trained models improves formality style transfer. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 2: Short Papers), Virtual Event, August 1-6, 2021, pages 484494. Association for Computational Linguistics. Alyssa Lees, Vinh Q. Tran, Yi Tay, Jeffrey Sorensen, Jai Gupta, Donald Metzler, and Lucy Vasserman. 2022. new generation of perspective api: Efficient multilingual character-level transformers. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 22, page 31973207, New York, NY, USA. Association for Computing Machinery. Shuai Liu, Shantanu Agarwal, and Jonathan May. 2024. Authorship style transfer with policy optimization. CoRR, abs/2403.08043. Varvara Logacheva, Daryna Dementieva, Sergey Ustyantsev, Daniil Moskovskiy, David Dale, Irina Krotova, Nikita Semenov, and Alexander Panchenko. 2022. Paradetox: Detoxification with parallel data. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 68046818. Association for Computational Linguistics. Mistral. 2024a. Ai in abundance mistral ai frontier ai in your hands. Mistral. 2024b. Mistral nemo mistral ai frontier ai in your hands. Daniil Moskovskiy, Daryna Dementieva, and Alexander Panchenko. 2022. Exploring cross-lingual text detoxification with large multilingual language models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 346354. Association for Computational Linguistics. Daniil Moskovskiy, Sergey Pletenev, and Alexander Panchenko. 2024. Llms to replace crowdsourcing for parallel data creation? the case of text detoxification. In Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024, pages 1436114373. Association for Computational Linguistics. Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M. Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel. 2023. Crosslingual generalization through multitask finetuning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 1599116111. Association for Computational Linguistics. Sourabrata Mukherjee, Akanksha Bansal, Pritha Majumdar, Atul Kr. Ojha, and Ondˇrej Dušek. 2023. Lowresource text style transfer for Bangla: Data & models. In Proceedings of the First Workshop on Bangla Language Processing (BLP-2023), pages 3447, Singapore. Association for Computational Linguistics. Nedjma Ousidhoum, Zizheng Lin, Hongming Zhang, Yangqiu Song, and Dit-Yan Yeung. 2019. Multilingual and multi-aspect hate speech analysis. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, pages 46744683. Association for Computational Linguistics. Maja Popovic. 2015. chrf: character n-gram f-score for automatic MT evaluation. In Proceedings of the Tenth Workshop on Statistical Machine Translation, WMT@EMNLP 2015, 17-18 September 2015, Lisbon, Portugal, pages 392395. The Association for Computer Linguistics. Mohammad Mahdi Abdollah Pour, Parsa Farinneya, Manasa Bharadwaj, Nikhil Verma, Ali Pesaranghader, and Scott Sanner. 2023. COUNT: contrastive unlikelihood text style transfer for text detoxification. In Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 86588666. Association for Computational Linguistics. Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, and Alan W. Black. 2018. Style transfer through back-translation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers, pages 866876. Association for Computational Linguistics. Vitaly Protasov. 2024. PAN 2024 multilingual textdetox: Exploring cross-lingual transfer using large language In Working Notes of the Conference and models. Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024, volume 3740 of CEUR Workshop Proceedings, pages 28522857. CEUR-WS.org. Sudha Rao and Joel R. Tetreault. 2018. Dear sir or madam, may introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers), pages 129 140. Association for Computational Linguistics. Machel Reid and Mikel Artetxe. 2023. On the role of parallel data in cross-lingual transfer learning. In Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023, pages 59996006. Association for Computational Linguistics. Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy P. Lillicrap, Jean-Baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, Ioannis Antonoglou, Rohan Anil, Sebastian Borgeaud, Andrew M. Dai, Katie Millican, Ethan Dyer, Mia Glaese, Thibault Sottiaux, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, James Molloy, Jilin Chen, Michael Isard, Paul Barham, Tom Hennigan, Ross McIlroy, Melvin Johnson, Johan Schalkwyk, Eli Collins, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, Clemens Meyer, Gregory Thornton, Zhen Yang, Henryk Michalewski, Zaheer Abbas, Nathan Schucher, Ankesh Anand, Richard Ives, James Keeling, Karel Lenc, Salem Haykal, Siamak Shakeri, Pranav Shyam, Aakanksha Chowdhery, Roman Ring, Stephen Spencer, Eren Sezener, and et al. 2024. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. CoRR, abs/2403.05530. Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022. recipe for arbitrary text style transfer with large language models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 837848. Association for Computational Linguistics. Julian Risch, Anke Stoll, Lena Wilms, and Michael Wiegand. 2021. Overview of the GermEval 2021 shared task on the identification of toxic, engaging, and factclaiming comments. In Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments, pages 112. Association for Computational Linguistics. Morgane Rivière, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier Bachem, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, Dimple Vijaykumar, Dominika Rogozinska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna Klimczak-Plucinska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjösund, Lauren Usui, Laurent Sifre, Lena Heuermann, Leticia Lago, and Lilly McNealus. 2024. Gemma 2: Improving open language models at practical size. CoRR, abs/2408.00118. Elisei Rykov, Konstantin Zaytsev, Ivan Anisimov, and Alexandr Voronin. 2024. Smurfcat at PAN 2024 textdetox: Alignment of multilingual transformers for text detoxification. In Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024, volume 3740 of CEUR Workshop Proceedings, pages 28662871. CEUR-WS.org. Koustuv Saha, Eshwar Chandrasekharan, and Munmun De Choudhury. 2019. Prevalence and psychological effects of hateful speech in online college communities. Proceedings of the 10th ACM Conference on Web Science. Alexander Semiletov. 2020. Toxic russian comments. Dataset. Noam Shazeer and Mitchell Stern. 2018. Adafactor: Adaptive learning rates with sublinear memory cost. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018, volume 80 of Proceedings of Machine Learning Research, pages 46034611. PMLR. Xiaofei Sun, Xiaoya Li, Jiwei Li, Fei Wu, Shangwei Guo, Tianwei Zhang, and Guoyin Wang. 2023. Text In Findclassification via large language models. ings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 89909005. Association for Computational Linguistics. Nikita Sushko. 2024. PAN 2024 multilingual textdetox: Exploring different regimes for synthetic data training for multilingual text detoxification. In Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024, volume 3740 of CEUR Workshop Proceedings, pages 28922900. CEUR-WS.org. Mirac Suzgun, Luke Melas-Kyriazi, and Dan Jurafsky. 2022. Prompt-and-rerank: method for zeroshot and few-shot arbitrary textual style transfer with small language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 2195 2222. Association for Computational Linguistics. Qwen Team. 2024. Qwen2.5: party of foundation models. Yunli Wang, Yu Wu, Lili Mou, Zhoujun Li, and WenHan Chao. 2020. Formality style transfer with shared latent space. In Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13, 2020, pages 22362249. International Committee on Computational Linguistics. Benfeng Xu, Quan Wang, Yajuan Lyu, Dai Dai, Yongdong Zhang, and Zhendong Mao. 2023. S2ynre: Two-stage self-training with synthetic data for lowresource relation extraction. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 8186 8207. Association for Computational Linguistics. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. 2024. Qwen2 technical report. arXiv preprint arXiv:2407.10671. Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong. 2022. Zerogen: Efficient zero-shot learning via dataset generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 1165311669. Association for Computational Linguistics. Ping Yu, Yang Zhao, Chunyuan Li, and Changyou Chen. 2021. Rethinking sentiment style transfer. In Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021, pages 1569 1582. Association for Computational Linguistics. Ziyin Zhang, Yikang Liu, Weifang Huang, Junyu Mao, Rui Wang, and Hai Hu. 2024. MELA: multilingual evaluation of linguistic acceptability. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024, pages 26582674. Association for Computational Linguistics. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric P. Xing, Joseph E. Gonzalez, Ion Stoica, and Hao Zhang. 2024. Lmsys-chat-1m: large-scale real-world LLM conversation dataset. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net."
        },
        {
            "title": "A Prompts",
            "content": "A.1 LLM Detoxification Prompt In our work, for all of the language models we use the Text Style Transfer prompt taken from work by Khondaker et al. (2024). Among others, this prompt shown to be giving better generation quality and helped to avoid additional content. Your task is text style transfer. Rewrite the following text into non-toxic language. You must match the target style and preserve the original meaning as much as possible. Do not include the input text in the response. Only generate the target text and nothing else. Make sure the response is completely non-toxic and neutral. Answer only in {language}. Here are few examples:\", Toxic text: {toxic_text}. Neutral text: Figure 5: Detoxification prompt we use for synthetic parallel data generation. {toxic_text} stands for placeholder for given toxic text being prompted into LLM. In few-shot setting we add few examples of detoxification before last two lines and write: Here are few examples:. We slightly adjust it specifically to text detoxification and provide the full text of the prompt in Figure 5. In this work, we do not use any advanced prompting techniques except few-shot prompting. A.2 mT0 Prompt We add specific prompt to mT0 during both training and predictions. In our work do not translate the prompt into the language of generation. Instead, we follow the promping approach from the original paper (Muennighoff et al., 2023). We show the prompt in Figure 6."
        },
        {
            "title": "German Spanish French Russian",
            "content": "Llama 3.1 8B 662 Llama 3.1 70B 898 Mistral Nemo 622 Mistral Small 862 Qwen 2.5 32B 477 Aya Exp. 32B 458 316 Aya Exp. 8B Command-R 32B 273 394 Gemma 2 27B 619 981 583 985 819 453 330 492 564 773 1114 392 565 513 142 143 308 360 1648 1354 1320 2237 3128 945 765 2294 2019 Table 5: Number of accepted samples in the final SynthDetoxM dataset, broken down by language and LLMs. Write non-toxic version of following {toxic_text} the {language}: text in Figure 6: Detoxification prompt we use for mT0."
        },
        {
            "title": "B Automatic evaluation results",
            "content": "The automatic evaluation results are presented in Table 6. Dataset STA SIM CHRF German 0.722 0.848 MPD SDM (Subset) 0.681 0.213 0.912 0.042 0.745 0.035 0.463 0.117 0.899 SDM (Full) 0.954 SDM+MPD 0.728 0.615 0.484 0.483 0.734 0. 0.383 0.602 Russian 0.748 0.852 MPD SDM (Subset) 0.858 0.034 0.850 0.020 0.656 0.021 0.478 0.014 0.839 SDM (Full) 0.886 SDM+MPD 0.927 0. 0.521 0.540 0.656 0.726 0.434 0.643 Spanish 0. 0.880 MPD SDM (Subset) 0.795 0.083 0.856 0.031 0.611 0.022 0.416 0.023 0.861 SDM (Full) 0.907 SDM+MPD 0.864 0.681 0.471 0.413 0.621 0.653 0.335 0. Table 6: Results of the automatic evaluation for mT0-XL on German, Russian, and Spanish trained on original data (MPD stands for MultiParaDetox), our collected and synthetically generated data (SDM stands for SynthDetoxM) and on their combination (MultiParaDetox + SynthDetoxM). Spanish German Russian"
        },
        {
            "title": "Toxic\nDetoxified",
            "content": "2089 27 323 102 4467 14 Table 7: Total amount of toxic words for toxic and detoxified subsets of SynthDetoxM with respect to language. Spanish German Russian"
        },
        {
            "title": "Toxic\nDetoxified",
            "content": "0.522 0.007 0.081 0.036 1.117 0.004 Table 8: Average number of toxic words per text in the toxic and detoxified SynthDetoxM with respect to language. Limitations of ChrF1 as Fluency"
        },
        {
            "title": "Metric",
            "content": "This section addresses the issues with using ChrF1 to evaluate fluency in text detoxification. While ChrF1 is commonly used in neural machine translation (Popovic, 2015), it has significant drawbacks for text style transfer tasks like detoxification. Reference-based metrics like ChrF1 are illsuited for assessing fluency in detoxification. The goal is to change the texts style while maintaining meaning and fluency, without limiting the extent of edits. Effective detoxification often involves substantial structural changes, making comparisons with the original toxic text using ChrF1 misleading. Though ChrF1 may produce low scores, manual evaluations frequently show that the detoxified output is fluent. ChrF1, based on character n-grams, is sensitive to word order and structural changes, which are often necessary for detoxification. It also fails to consider semantic content, meaning fluency can be high even when the ChrF1 score is low. Additionally, it tends to reward minimal edits, which undermines the goal of thorough detoxification. Recent research has shifted towards more appropriate fluency metrics. For example, CoLA-based classifiers, as used in Dementieva et al. (2023) and Logacheva et al. (2022), focus on linguistic acceptability, offering more accurate assessment of fluency without relying on comparisons to the toxic input. While ChrF1 has its merits in other tasks, it is not suitable for evaluating fluency in detoxification. Future work should prioritize methods that assess fluency based on grammaticality and naturalness, Politely refuse to answer this in {lang} and provide an explanation why you refuse. The refusal should be connected to the request topic. Do not add anything additional, only respond with refusal: {input_text} Figure 7: Refusal generation prompt for synthetic refusals dataset. Figure 8: Side-by-side comparison of model outputs across all languages, evaluated by GPT-4o. The results highlight the relative performance of the models in generating detoxified text for German. The notation is similar to the notation from Table 3. independent of the original text."
        },
        {
            "title": "D Refusal classifier training",
            "content": "To get rid of LLM refusals in SynthDetoxM, we trained separate refusal classifier, based on xlmr-base10. To train the model, high quality synthetic dataset was created11. It was based on randomly selected inputs from the LMSYS-Chat-1M (Zheng et al., 2024) dataset and then passed to the Gemini Flash 1.5 (Reid et al., 2024) and Llama 3.3 70B (Dubey et al., 2024) models, prompted to generate both responses to the prompts from the dataset and refusals. Prompt for synthetic refusal generation is presented in Figure 7."
        },
        {
            "title": "Classification model was trained using a batch",
            "content": "size of 64, learning rate of 1e-4 for one epoch."
        },
        {
            "title": "E Additional linguistic analysis of the",
            "content": "dataset To provide additional perspective about detoxification quality of our dataset, we used dataset12, 10hf.co/s-nlp/xlmr-base-refusal-classifier 11hf.co/datasets/chameleon-lizard/multilingual_refusals 12hf.co/datasets/textdetox/multilingual_toxic_lexicon of each of the trained mT0 models using GPT4o (Hurst et al., 2024) as judge. To lessen the positional bias, each side-by-side comparison was done twice, changing the positions of the answers and calculating mean score for all answers. The results are presented in the Figures 8, 9, 10. As demonstrated in the figures, models finetuned on SynthDetoxM achieve significantly higher win rates compared to those trained on the \"goldstandard\" MultiParaDetox dataset, as well as models trained using two-stage regime. We attribute this superior performance to the challenges posed by human-sourced samples, which may be too complex or nuanced for relatively simple and compact student models to learn effectively. This limitation likely contributes to the weaker performance of models trained on MultiParaDetox in both automatic evaluations and side-by-side comparisons. Figure 9: Side-by-side comparison of model outputs across all languages, evaluated by GPT-4o. The results highlight the relative performance of the models in generating detoxified text for Spanish. The notation is similar to the notation from Table 3. Figure 10: Side-by-side comparison of model outputs across all languages, evaluated by GPT-4o. The results highlight the relative performance of the models in generating detoxified text for Russian. The notation is similar to the notation from Table 3. which contains toxic lexicon in German, Spanish and Russian languages and calculated two metrics of our generated data: the amount and mean counts of toxic words in each sentence (presented in Tables 7 and 8 accordingly) in the toxic and generated detoxified subsets of SynthDetoxM. Due to the lack of French toxic lexicon dataset we did not do any evaluations in French. Furthermore, selected dataset is not comprehensive: for instance, German subset contains only 247 toxic words, which leaves some toxic sentences not having any toxic words detected and overall toxicity of German subset of our dataset is comparatively low. However, these evaluations still show that our detoxified data contains substantially less toxic lexicon than the original toxic data, indicating that overall explicit toxicity of the generated data is much lower after the detoxification. Side-by-side comparison of trained mT0 models To provide additional validation outside of methodology created by (Dementieva et al., 2024), we have evaluated the responses from the test dataset Per-Language Few-Shot Examples To ensure reproducibility we show all the few-shot prompts as is in Tables 9 10, 11, and 12. Type Text Perspective API Score XLM-R Score Toxic тварь присягу один раз,а проебал всю страну The bastard swore an oath once, but screwed over the whole country. Neutral Присягу дал один раз, а разрушил всю страну He took the oath once, but destroyed the whole country Toxic Neutral нахрена этого придурка клоуна сюда впихивают? why the fuck is this idiot clown being pushed in here? Зачем этого человека сюда впихивают? Why is this man being pushed in here? Toxic молись не молись,всё - равно получишь хуй. ну, разве что блядям на радость Pray or dont pray, youll get dick anyway. Well, except for the joy of whores. Neutral Молись не молись, всё - равно ничего не получишь. ну, разве что завистникам на радость. Pray or dont pray, you wont get anything anyway. well, except for the envy of the joy. Toxic её муженька козла на кол надо посадить Her scoundrel of husband needs to be impaled. Neutral Её муженька нужно сурово наказать Her hubby needs to be severely punished Toxic Neutral Toxic Neutral Toxic хорошо пизды не получил уёбок good thing the bastard didnt get his ass kicked. хорошо что он не был избит its good thing he wasnt beaten up да что ты доебалась до этих клумб? людям жрать нечего! по мусоркам лазают! why are you so fixated on those flower beds? people have nothing to eat! theyre rummaging through trash! да что ты докопалась до этих клумб? Людям есть нечего! по мусоркам лазают! why did you get to these flower beds? People have nothing to eat! theyre climbing through the trash! именно благодаря этому президенту, россия еще жива. а такие долбоёбы, только могут воду мутить. дебилоид. Its precisely thanks to this president that Russia is still alive. And idiots like you can only stir up trouble. Moron. 0.820 0.360 0.743 0.042 0. 0.156 0.553 0.029 0.853 0.037 0. 1.000 0.001 1.000 0.005 1.000 0. 0.999 0.988 1.000 0.000 1.000 0. 0.000 0.863 1.000 Neutral Именно благодаря этому президенту, Россия ещё жива, а 0.369 0. такие люди, как ты, только и могут, что наводить смуту. It is thanks to this president that Russia is still alive, and people like you can only cause trouble. ты просто пидор,а не немец.я за свои слова отвечу, youre just faggot, not german. stand by my words, but you wont, because youre couch scumbag. ты просто не немец. я за свои слова отвечу, а ты н youre just not german. ill answer for my words, but you wont, because youre writing from the couch да, блядь, кто это говнище постоянно сюда сливает?! Yeah, fuck, who keeps dumping this shit here all the time?! да кто эту ерунду постоянно сюда сливает?! who is constantly pouring this nonsense here?! да вы заебали этим постом уже, пидарасы!!! Im sick of this post already, you bastards!!! да вы надоели этим постом уже, люди!!! Yes, people, am tired of this post already!!! Toxic Neutral Toxic Neutral Toxic Neutral 0.906 0. 0.654 0.096 0.903 0.012 1.000 0. 1.000 0.001 1.000 0.001 Table 9: Selected few-shot examples for the Russian language with toxicity scores. Type Text Toxic Neutral In dem Schwarz Grün regierden Hessen werden jetzt 8 zusätzliche Psychologen nur für die Jugendlichen Invasoren eingestellt. Jetzt AFD wählen In the black-green governed Hesse, 8 additional psychologists are now being hired only for the young invader. Vote AFD now In dem Schwarz Grün regierden Hessen werden jetzt 8 zusätzliche Psychologen nur für die Jugendlichen Einwanderer eingestellt. Jetzt AFD wählen In the black-green governed Hesse, 8 additional psychologists are now being hired only for the young immigrants. Vote AFD now Toxic Moin, moin, seid Ihr alle noch gesund und munter bei all dem geistigen Dünnpfiff im \"Merkel-Propagandaschrott\"? Hello, hello, are you all still healthy and cheerful despite all the intellectual drivel in the \"Merkel propaganda junk\"? Perspective API Score XLM-R Score 0.397 0.486 0.313 0.004 0. 0.898 Neutral Moin, moin, seid Ihr alle noch gesund und munter bei all dem geistigen 0.427 0.999 Quatsch in der \"Merkel-Propaganda\"? Hello, hello, are you all still healthy and cheerful despite all the intellectual nonsense in the \"Merkel propaganda\"? Toxic Neutral Ich würde Grüne mit einem Geschwür am Arsch der Welt bezeichnen would describe Greens as boil on the ass of the world Ich würde Grüne mit einem Geschwür der Welt bezeichnen. would describe Greens as boil of the world. Toxic Dummes Gelaber, Kern. Stupid talk, Kern. Neutral Unsinnige Aussage, Kern Nonsensical statement, Kern Toxic wie kann man nur derart strunzdumme Moderatoren wie bei #taff auf #ProSieben beschäftigen how can you employ such extremely stupid presenters as at #taff on #ProSieben Neutral wie kann man nur solche Moderatoren wie bei #taff auf #ProSieben beschäftigen how can you employ such presenters as at #taff on #ProSieben Toxic Da macht sich die Bildung aus der Bild mal wieder bemerkbar. So ein Sau dummer Kommentar Thats where the education from Bild becomes noticeable again. Such pig stupid comment Neutral Da macht sich die Bildung aus der Bild mal wieder bemerkbar. Ein sehr unüberlegter Beitrag Thats where the education from Bild becomes noticeable again. very inconsiderate contribution Toxic Kurz lasst dich nicht von der Trulla aufs Glatteis führen! Kurz dont let the chick lead you astray! Neutral Kurz lasst dich nicht von der Frau aufs Glatteis führen! Kurz dont let the woman lead you astray! Toxic Younower zu werden ist der finale schritt um ein Hurensohn zu werden Becoming Younower is the final step to becoming son of bitch Neutral Younower zu werden ist der finale schritt um unsympathisch zu werden Becoming Younower is the final step to becoming unsympathetic Toxic Neutral Sehe ich Kathrin Göring Eckart, Merkel, Gysi, Petry, Wagenknecht und all die anderen Wendehälse die uns heute regieren. Frage ich mich. War der Fall der Mauer ein Fehler. When see Kathrin Göring Eckart, Merkel, Gysi, Petry, Wagenknecht and all the other turncoats who govern us today. ask myself. Was the fall of the wall mistake. Sehe ich Kathrin Göring Eckart, Merkel, Gysi, Petry, Wagenknecht und all die anderen wechselnhaften Politiker die uns heute regieren. Frage ich mich. War der Fall der Mauer ein Fehler. When see Kathrin Göring Eckart, Merkel, Gysi, Petry, Wagenknecht and all the other fickle politicians who govern us today. ask myself. Was the fall of the wall mistake. 0.548 0. 0.397 0.177 0.634 0.056 0.557 0. 0.224 0.185 0.638 0.231 0.339 0. 0.337 0.653 0.002 0.016 0.001 0. 0.000 0.384 0.012 0.999 0.676 0. 0.058 0.003 Toxic Hahaha vllt gönn ich mir das ma. Aber diese asiaten sind einfach freaks, das is nich menschlich Hahaha maybe Ill treat myself to that. But these Asians are just freaks, thats not human 0.572 Neutral Hahaha vllt gönn ich mir das ma. Aber diese asiaten sind einfach 0.235 0.273 0.995 unglaublich, fast übermenschlich Hahaha maybe Ill treat myself to that. But these Asians are just unbelievable, almost superhuman Table 10: Selected few-shot examples for German language with toxicity scores. Type Text Perspective API Score XLM-R Score Toxic lo bien que les va siendo fachas, que no es gratis And how well they are doing being fascists, which is not free Neutral lo bien que les va siendo conservadores, que no es gratis And how well they are doing being conservatives, which is not free Toxic mí qué me importa lo que tú \"notes\", facha? And what do care what you \"notice\", fascist? Neutral mí qué me importa lo que tú \"notes\"? And what do care what you \"notice\"? Toxic Neutral Toxic Neutral Toxic Neutral Toxic Neutral Toxic Neutral Toxic ya ves además los policías nazis que tendrá esa en el whatsapp. . . como para creerse algo. you see also the nazi policemen that she will have on whatsapp... as if to believe something. ya ves además los policías que tendrá esa en el whatsapp. . . como para creerse algo. you see also the policemen that she will have on whatsapp... as if to believe something. #YoSoyAnonymousUE basta de absurda represión victimista por parte del Estado Fascista #YoSoyAnonymousUE enough of absurd victimist repression by the Fascist State #YoSoyAnonymousUE basta de absurda represión victimista por parte del Estado #YoSoyAnonymousUE enough of absurd victimist repression by the State Supongo que Perro le dará asilo en la Moncloa suppose Dog will give him asylum in La Moncloa Supongo que el presidente le dara asilo en la Moncloa suppose the president will give him asylum in La Moncloa Los halagos buenos modales siempre hacen bien, menos los izquierdistas de la cultura del odio. Flattery and good manners are always good, except for the leftists of the culture of hatred. Los halagos buenos modales siempre hacen bien, menos los izquierdas de la cultura del odio. Flattery and good manners are always good, except for the leftists of the culture of hatred. Yo me quiero escapar también, dan paguita al llega want to escape too, they give small handout to the newcomer Ofrecen algún tipo de apoyo al llegar? Do they offer any kind of support upon arrival? Mire la saga de 50 sombras de Grey...casi todo eran.lectoras...les va el.morbillo no lo.nieguen Look at the 50 Shades of Grey saga...almost all were.readers...they like.morbid curiosity dont.deny it 0.184 0.012 0.427 0.080 0. 0.035 0.255 0.106 0.314 0.039 0. 0.280 0.011 0.002 0.039 0.002 0. 0.391 0.001 0.608 0.003 0.352 0. 0.283 0.004 0.969 0.236 0.423 0. 0.811 Neutral Miren la saga de 50 sombras de Grey.. casi todo eran lectoras... le 0.011 0.000 encanta Look at the 50 Shades of Grey saga... almost all were readers... they love it Toxic Neutral Cortocircuito buenrrollista, pobres inmigrantes vs chica atacada sexualmente. Good-natured short circuit, poor immigrants vs sexually attacked girl. Es un conflicto entre el enfoque positivo la compasión por los inmigrantes, frente la preocupación por una chica atacada sexualmente. It is conflict between the positive approach and compassion for immigrants, versus concern for sexually attacked girl. Toxic menudos fachas xD HIJOS DE PUTA what fascists xD SONS OF BITCHES Neutral menudos fachas xD what fascists xD 0.305 0.082 0.921 0.327 0. 0.002 0.802 0.982 Table 11: Selected few-shot examples for the Spanish language with toxicity scores. Type Text Perspective API Score XLM-R Score Toxic Neutral Toxic Neutral Toxic Neutral Toxic Neutral Toxic Neutral Toxic Neutral Toxic Pour le crétin qui remet à chaque fois une soi-disant citation de Nietzsche, lexpression \"tout senjuive\" est attribuée par Nietzsche à un librepenseur démocrate, autrement dit Nietzsche identifie lantisémitisme aux valeurs chrétiennes de la \"libre pensée\". For the idiot who always puts so-called quote from Nietzsche, the expression \"everything is becoming Jewish\" is attributed by Nietzsche to democratic freethinker, in other words Nietzsche identifies anti-Semitism with the Christian values of \"free thought\". Pour la personne qui remet à chacun une citation de Nietzsche lexpression tout senjuive est attribuée par Nietzsche à un libre-penseur démocrate, autrement dit Nietzsche identifie lantisémitisme aux valeurs chrétiennes de la libre pensée. For the person who gives everyone quote from Nietzsche, the expression \"everything is becoming Jewish\" is attributed by Nietzsche to democratic freethinker, in other words Nietzsche identifies anti-Semitism with the Christian values of free thought. Et toi aussi tu commences sérieusement à me gonfler. And you too are seriously starting to annoy me. Et toi aussi tu commences sérieusement à ménerver. And you too are seriously starting to irritate me. Tout est trop nul, tout est faux ou ou ou! Everything is too rubbish, everything is false or or or! Tout est médiocre et faux ! Everything is mediocre and false! Continuez tout seul si ça vous amuse. Je ne perdrai pas plus de temps avec un pénible de votre espèce. Continue on your own if that amuses you. wont waste any more time with pain in the ass like you. Continuez tout seul si ça vous amuse. Je ne perdrai pas plus de temps avec une telle personne. Continue on your own if that amuses you. wont waste any more time with such person. Salut, ai restauré cet article et réverté tes su Hi, restored this article and reverted your su Salut, ai restauré cet article et réverté tes su Hi, restored this article and reverted your su Encore un vieux qui fait chier, je ne fais plus attention à force. Another old man whos pain in the ass, dont pay attention anymore. Encore un vieux ennuyeux, je ne fais plus attention à force. Another boring old man, dont pay attention anymore. Oue et on en tape de ta façon toi et on en tape que as eu emmerdes avec personne est pas mon problème donc comme je ai dis tout heure je fais ma façon. Yeah and we dont care about your way and we dont care that you had troubles with anyone its not my problem so as said earlier do it my way. Neutral Oue et ça na rien à voir avec ta vie, le fait que tu aies eu des problèmes, ça ne me regarde pas, donc comme je ai dis tout heure je fais ma façon. Yeah and it has nothing to do with your life, the fact that you had problems, its none of my business, so as said earlier do it my way. Toxic Neutral Ta réponse est confondante. . . Et tu continues tes manigances ! Je te prie de arrêter immédiatement! Your answer is confusing... And you continue your schemes! beg you to stop immediately! Ta réponse est confondante. . . Et tu continues tes tricks! Je te prie de arrêter immédiatement ! Your answer is confusing... And you continue your tricks! beg you to stop immediately! Toxic Neutral Faut croire que les amateurs de musique sont des malades mentaux You have to believe that music lovers are mentally ill Faut croire que les amateurs de musique ont des préférences étranges You have to believe that music lovers have strange preferences 0.255 0. 0.238 0.285 0.167 0.195 0.498 0. 0.383 0.152 0.509 0.378 0.373 0. 0.304 0.255 0.386 0.046 Table 12: Selected few-shot examples for the French language with toxicity scores. - - - - - - - - - - - - - - - - - -"
        }
    ],
    "affiliations": [
        "AIRI",
        "ISP RAS Research Center for Trusted AI",
        "Sber AI",
        "Skoltech"
    ]
}