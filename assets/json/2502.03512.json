{
    "paper_title": "YINYANG-ALIGN: Benchmarking Contradictory Objectives and Proposing Multi-Objective Optimization based DPO for Text-to-Image Alignment",
    "authors": [
        "Amitava Das",
        "Yaswanth Narsupalli",
        "Gurpreet Singh",
        "Vinija Jain",
        "Vasu Sharma",
        "Suranjana Trivedy",
        "Aman Chadha",
        "Amit Sheth"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Precise alignment in Text-to-Image (T2I) systems is crucial to ensure that generated visuals not only accurately encapsulate user intents but also conform to stringent ethical and aesthetic benchmarks. Incidents like the Google Gemini fiasco, where misaligned outputs triggered significant public backlash, underscore the critical need for robust alignment mechanisms. In contrast, Large Language Models (LLMs) have achieved notable success in alignment. Building on these advancements, researchers are eager to apply similar alignment techniques, such as Direct Preference Optimization (DPO), to T2I systems to enhance image generation fidelity and reliability. We present YinYangAlign, an advanced benchmarking framework that systematically quantifies the alignment fidelity of T2I systems, addressing six fundamental and inherently contradictory design objectives. Each pair represents fundamental tensions in image generation, such as balancing adherence to user prompts with creative modifications or maintaining diversity alongside visual coherence. YinYangAlign includes detailed axiom datasets featuring human prompts, aligned (chosen) responses, misaligned (rejected) AI-generated outputs, and explanations of the underlying contradictions."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 5 ] . [ 1 2 1 5 3 0 . 2 0 5 2 : r Amitava Das1, Yaswanth Narsupalli1, Gurpreet Singh1, Vinija Jain2*, Vasu Sharma2*, Suranjana Trivedy1, Aman Chadha3, Amit Sheth1 1Artificial Intelligence Institute, University of South Carolina, USA, 2Meta AI, USA, 3Amazon AI, USA"
        },
        {
            "title": "Abstract",
            "content": "Precise alignment in Text-to-Image (T2I) systems is crucial to ensure that generated visuals not only accurately encapsulate user intents but also conform to stringent ethical and aesthetic benchmarks. Incidents like the Google Gemini fiasco, where misaligned outputs triggered significant public backlash, underscore the critical need for robust alignment mechanisms. In contrast, Large Language Models (LLMs) have achieved notable success in alignment. Building on these advancements, researchers are eager to apply similar alignment techniques, such as Direct Preference Optimization (DPO), to T2I systems to enhance image generation fidelity and reliability. We present YinYangAlign, an advanced benchmarking framework that systematically quantifies the alignment fidelity of T2I systems, addressing six fundamental and inherently contradictory design objectives. Each pair represents fundamental tensions in image generation, such as balancing adherence to user prompts with creative modifications or maintaining diversity alongside visual coherence. YinYangAlign includes detailed axiom datasets featuring human prompts, aligned (chosen) responses, misaligned (rejected) AI-generated outputs, and explanations of the underlying contradictions. In addition to presenting this benchmark, we introduce Contradictory Alignment Optimization (CAO), novel extension of DPO. The CAO framework incorporates per-axiom loss design to explicitly model and address competing objectives. Then it optimizes these objectives using multi-objective optimization techniques, including synergy-driven global preferences, axiom-specific regularization, and the novel synergy Jacobian for effectively balancing contradictory goals. By utilizing tools such * Work done outside of role at Meta. Work done outside of role at Amazon. Faithfulness to Prompt vs. Artistic Freedom Emotional Impact vs. Neutrality Visual Realism vs. Artistic Freedom Originality vs. Referentiality Verifiability vs. Artistic Freedom Cultural Sensitivity vs. Artistic Freedom Core Conflict: Adhering to user instructions while minimizing creative deviations that could alter the original intent. Core Conflict: Striking balance between evoking specific emotions and maintaining an unbiased, objective representation. Core Conflict: Create photorealistic images mimicking real-world visuals, incorporating artistic styles like impressionism or surrealism only when requested. Core Conflict: Maintain stylistic originality while avoiding over-reliance on established artistic styles that risks style plagiarism. Core Conflict: Balancing factual accuracy against creative freedom to minimize misinformation. Core Conflict: Respecting cultural representations while ensuring creative liberties do not lead to insensitivity or misrepresentation. Figure 1: The figure illustrates six core trade-offs (e.g., Faithfulness vs. Freedom, Emotional Impact vs. Neutrality), highlighting key conflicts and their implications. as the Sinkhorn-regularized Wasserstein Distance, CAO achieves both stability and scalability while setting new performance benchmarks across all six contradictory alignment objectives."
        },
        {
            "title": "1 Why and How T2I Models Must Be",
            "content": "Aligned? The alignment of T2I models is essential to ensure that generated visuals faithfully represent user intentions while adhering to ethical and aesthetic standards. This necessity is underscored by projections from EUROPOL, which estimate that by the end of 2026, approximately 90% of web content will be generated by AI (EUROPOL, 2023). The widespread use of AI-generated content underscores the need for robust alignment mechanisms to prevent misleading, biased, or unethical visuals. The recent announcement by social media Figure 2: Illustrative examples of all six contradictory alignment axioms, with each row highlighting specific trade-offs between competing objectives (e.g., Faithfulness to Prompt vs. Artistic Freedom, Emotional Impact vs. Neutrality). Chosen and rejected outputs demonstrate the inherent tensions during text-to-image generation, underscoring the need for multi-objective optimization framework. Examples of Originality vs. Referentiality are inspired by recent copyright disputes reviewed by the U.S. Copyright Office. The Verifiability vs. Artistic Freedom case reflects incidents like the dissemination of fake Pentagon explosion image by verified Twitter accounts, causing confusion (CNN report). To mitigate misinformation caused harm, the system should avoid unverifiable content or produce subdued visuals when necessary. Lastly, the Google Gemini fiasco underscores the need for Cultural Sensitivity in T2I systems, inspiring our Cultural Sensitivity vs. Artistic Freedom example. cf Fig. 12 depicts controls and Fig. 13 and Fig. 14 resultant genrations with varied control on generations. plarforms (Kaplan, 2025) to remove all third-party fact-checking tools and adopt more laissez-faire approach has sparked concerns about potential misinformation apocalypse. This shift not only amplifies the risk of unchecked falsehoods spreading across the platform but also places greater responsibility on AI systems to manage and mitigate the flow of misleading content. Alignment has been vibrant area of research in Large Language Models (LLMs), with substantial progress achieved. Techniques like Reinforcement Learning from Human Feedback (RLHF) (Christiano et al., 2017) and Direct Preference Optimization (DPO) (Ouyang et al., 2022) have been instrumental in enabling LLMs to generate responses that are both ethically sound and contextually appropriate. Moreover, several benchmarks (Bai et al., 2022; Wang et al., 2023; Zheng et al., 2023; Chiang et al., 2024; Dubois et al., 2024; Lightman et al., 2023; Cui et al., 2024; Zhu et al., 2023; Lv et al., 2023; Daniele and Suphavadeeprasit, 2023a,b; Guo et al., 2022) have been developed to comprehensively evaluate alignment dimensions such as accuracy, safety, reasoning, and instructionfollowing. In contrast, alignment research for multimodal systems, especially T2I models, remains nascent with limited studies (Yoon et al., 2024; Wallace et al., 2023; Lee et al., 2023; Yarom et al., 2023). The field lacks large-scale benchmarks and diverse alignment axioms, hindering holistic evaluation and optimization of T2I systems. Figure 3: Illustrative example of aligning T2I models with Faithfulness to Prompt vs. Artistic Freedom. The chosen outputs adhere closely to the prompt, depicting highly detailed and accurate portrait of Albert Einstein in realistic oil painting style, while the rejected outputs deviate significantly, introducing surreal or unrelated elements. This highlights the importance of balancing prompt adherence with artistic flexibility in alignment optimization."
        },
        {
            "title": "Alignment Objectives",
            "content": "Current research and benchmarking in T2I alignment primarily focus on isolated objectives (Guo et al., 2022), such as fidelity to prompts (Ramesh et al., 2021), aesthetic quality (Rombach et al., 2022), or bias mitigation (Zhao et al., 2023), often treating these goals independently. However, there is clear gap in benchmarks that evaluate how T2I systems balance multiple, often contradictory objectives. The lack of multi-objective benchmarks restricts the ability to holistically assess and improve T2I alignment, ultimately affecting their reliability and effectiveness in practical scenarios. Selection of Six Contradictory Objectives: YinYangAlign introduces six carefully selected pairs of contradictory objectives that capture the fundamental tensions in T2I image generation. These pairs are chosen for their relevance and significance in real-world applications. Fig. 1 introduces the core trade-offs central to the YinYangAlign framework, each representing critical conflict that T2I systems must navigate to balance user expectations and ethical considerations. The tradeoffs include: Faithfulness to Prompt vs. Artistic Freedom, which involves adhering to user instructions while minimizing creative deviations; Emotional Impact vs. Neutrality, requiring balance between evoking emotions and maintaining objective representation; and Visual Realism vs. Artistic Freedom, focusing on achieving photorealistic outputs without compromising artistic liberties. Additionally, Originality vs. Referentiality addresses the challenge of fostering stylistic innovation while avoiding reliance on established artistic styles to ensure uniqueness. Verifiability vs. Artistic Freedom emphasizes balancing factual accuracy with creative liberties to minimize misinformation. Finally, Cultural Sensitivity vs. Artistic Freedom underscores the need to respect cultural representations while ensuring that creative freedoms do not lead to misrepresentation or insensitivity. Fig. 2 provides illustrative examples of these alignment axioms. YinYangAlign serves as holistic benchmark for evaluating alignment performance, ensuring that T2I models are not only accurate and reliable but also adaptable, ethical, and capable of meeting complex user demands and societal expectations."
        },
        {
            "title": "3 YinYangAlign: Dataset and Annotation",
            "content": "The development of YinYangAlign employs carefully designed annotation pipeline to enable comprehensive evaluation of T2I systems. To overcome the inherent stochasticity of T2I models and the subjective complexities of visual alignment, we propose hybrid annotation pipeline. This pipeline leverages advanced vision-language models (VLMs) for automated identification of misalignments, augmented by meticulous human validation to ensure scalability and reliability. This hybrid strategy ensures scalability while maintaining high annotation reliability, resulting in robust and reliable benchmark. The subsequent sections outline the models, data sources, and annotation methodology utilized in the creation of YinYangAlign. T2I Models Utilized: For our data creation, we utilize state-of-the-art T2I models such as Stable Diffusion XL (Podell et al., 2023), and Midjourney 6 (Midjourney, 2024). Prompt Sources: To construct the YinYang dataset, we strategically selected diverse datasets to cover the six contradictory alignment axioms. For the first three axiomsFaithfulness to Prompt vs. Artistic Freedom, Emotional Impact vs. Neutrality, and Visual Realism vs. Artistic Freedomwe utilized the MS COCO dataset (Lin et al., 2014). The Originality vs. Referentiality axiom drew upon Googles Conceptual Captions dataset (Sharma et al., 2018), while the Verifiability vs. Artistic Freedom axiom relied on the FACTIFY 3M dataset (Chakraborty et al., 2023). Finally, for Cultural Sensitivity vs. Artistic Freedom, we employed the Facebook Hate Meme Challenge (Kiela et al., 2020) and Memotion datasets (Sharma et al., 2020), with careful filtering to ensure inclusion of culturally sensitive data points. 3.1 Annotation Pipeline Annotation process involves the following steps: 1. Multiple Outputs per Prompt: To account for the stochastic nature of T2I systems, we generate 10 distinct outputs for each prompt to capture the variability in the generated visuals. Fig. 3 illustrates an example of how the same prompt can produce diverse images due to this inherent randomness. 2. Automated Annotation Using VLMs: We employ two VLMs: GPT-4o (OpenAI, 2023) and LLaVA (Liu et al., 2023), to annotate the generated images. The annotation is guided by the following prompt. See more examples of prompts in Appendix B. cialized for grading tasks. This fine-tuning enables them to consistently and effectively assess the quality and relevance of generated content. Images were selected for human verification only when both VLMs produced consistent annotations, specifically when the scores for given axiom were 3. This approach ensured higher confidence in the automated annotation process before proceeding to manual review. 4. Human Verification: Ten human annotators evaluated approximately 50,000 images flagged by the VLMs. To measure inter-annotator agreement, subset of 5,000 images was annotated by all 10 annotators, achieving kappa score of 0.83, demonstrating high consistency and reliability in the annotation process. During the manual review, approximately 10,000 images were discarded due to quality issues, resulting in the final YinYangAlign benchmark consisting of 40,000 high-quality images. Fig. 4 presents the kappa scores comparing agreement levels between human annotators and machine (VLM) evaluations across six contradictory alignment axioms, highlighting areas of alignment and divergence. The entire annotation process, including model-based tagging and human verification, spanned 11 weeks. cf Appendix B. Faithfulness to Prompt vs . Artistic Freedom and Given the textual description ( prompt ) and an image , evaluate the alignment of the image . Instructions : 1. Faithfulness to Prompt : Evaluate how well the image adheres to the user 's prompt . 2. Artistic Freedom : Assess if the image introduces creative or artistic elements that deviate from , enhance , or reinterpret the original prompt . 3. Identify if artistic freedom significantly compromises faithfulness to the prompt . Output Format : Faithfulness Score (1 -5) , Artistic Freedom Score (1 -5) , Observations ( Text ). 3. Consensus Filtering: To improve annotation reliability, we utilized LLaVA-Critic (Xiong et al., 2024) and Prometheus-Vision (Lee et al., 2024), for independently scoring of each generated image. Since these models are fine-tuned on pointwise and/or pairwise ranking data, they are spe-"
        },
        {
            "title": "4 Contradictory Alignment Optimization",
            "content": "(CAO) The YinYangAlign framework, models the challenge of balancing inherently contradictory objectives. For example, prioritizing Faithfulness to Prompt can limit Artistic Freedom, while emphasizing Emotional Impact may erode Neutrality. To address these tensions, we introduce Contradictory Alignment Optimization (CAO), which employs per-axiom loss design to explicitly model competing goals. CAO employs dynamic weighting mechanism to prioritize sub-objectives within each axiom, facilitating granular control over tradeoffs and enabling adaptive optimization across diverse alignment paradigms. Additionally, CAO integrates Pareto optimality principles with the Bradley-Terry preference framework, introducing novel global synergy mechanism that unifies all contradictory objectives into cohesive optimization strategy. This unique combination of multiobjective synergy defines the core innovation of Figure 4: Annotation Agreement Heatmap: The VLM column represents the kappa score indicating the average agreement between GPT-4o and LLaVA across all axioms. Columns (H1H10) correspond to the kappa scores measuring the agreement between each specific human annotator and the consolidated VLM annotations. Higher scores (darker blue) signify stronger agreement, while lower scores (lighter shades) highlight areas of disagreement. CAO, distinguishing it from existing T2I alignment methods. 4.1 Axiom-Wise Loss Expansion and Synergy Local Axiom-Wise Loss : Below, we illustrate how each axioms loss is defined, before showing how these losses connect into global synergy framework. For each axiom a, CAO defines loss function fa(I) that blends two competing sub-objectives, Lp(I) and Lq(I), via mixing parameter αa: Multi-Objective Aggregator and Pareto Frontiers: Although fa(I) provides local control over each axiom a, reconciling multiple axioms at once requires global view. We thus define multi-objective synergy function: S(I) = (cid:88) a=1 ωa fa(I), fa(I) = αa Lp(I) + (1 αa) Lq(I). For example, Lp(I) might emphasize faithfulness to prompt, while Lq(I) favors artistic freedom, or any other pair of conflicting objectives. Varying αa adjusts the per-axiom balance according to domain or policy needs. where the {ωa} are global coefficients reflecting the relative priority of each axiom. By varying these synergy weights, we trace out Pareto frontier (Miettinen, 1999; Yang et al., 2021; Lin et al., 2023) in the T2I objective space, clarifying how small concessions in one axiom can yield major gains in another. Faithfulness to Prompt vs. Artistic Freedom ffaith_artistic(I) = α1 Lfaith + (1 α1) Lartistic Emotional Impact vs. Neutrality femotion_neutrality(I) = α2 Lemotion + (1 α2) Lneutrality Visual Realism vs. Artistic Freedom fvisual_style(I) = α3 Lrealism + (1 α3) Lartistic Originality vs. Referentiality foriginality_referentiality(I) = α4 Loriginality + (1 α4) Lreferentiality Verifiability vs. Artistic Freedom fverifiability_creative(I) = α5 Lverifiability + (1 α5) Lartistic Cultural Sensitivity vs. Artistic Freedom fcultural_artistic(I) = α6 Lcultural + (1 α6) Lartistic The resulting loss surfaces and their corresponding sweet spots, where competing objectives are in harmony, are visualized in Fig. 5. In multiInterpretation and Importance. objective optimization, the Pareto frontier is the set of all solutions where improving any one objective strictly worsens at least one other (?Zhou et al., 2022). By tuning {ωa}, we systematically explore these tradeoffs, finding, for example, that slight drop in visual realism could allow for notably higher stylistic freedom. Such multi-objective approaches have been central in multi-task learning (Ma et al., 2020; Navon et al., 2022; Yu et al., 2020) and modular/decomposed learning (Liebenwein et al., 2021; Lin et al., 2022), ensuring transparent control over each tension point (e.g., verifiability vs. creativity) and easy adaptation to new constraints. cf Appendix C. Figure 5: Visualization of error loss surface tension for six axiom pairs in YinYang alignment. Each pair highlights the inherent trade-offs between competing objectives using 3D surface plot (left) and 2D contour plot (right). Blue regions represent synergy (low tension), red regions indicate conflict (high tension), while Green markers highlight \"sweet spots\" where the tension is minimal. The first axiom pair, Faithfulness to Prompt vs. Artistic Freedom, shows sweet spots centered around moderate values, suggesting balanced trade-offs. For Emotional Impact vs. Neutrality, sweet spots are sparse, reflecting the difficulty in balancing emotional engagement and neutrality. The axiom pair Visual Realism vs. Artistic Freedom shows distributed sweet spots, indicating achievable trade-offs between realism and creative freedom. In Originality vs. Referentiality, sweet spots are concentrated, emphasizing the challenge of balancing uniqueness and references. The pair Verifiability vs. Artistic Freedom has central sweet spots, suggesting harmony between factual accuracy and creative expression. Lastly, Cultural Sensitivity vs. Artistic Freedom shows fewer sweet spots, reflecting the complexity of respecting cultural norms while granting artistic liberties. This visualization underscores the inherent trade-offs in T2I systems and identifies potential areas of optimization for aligning competing objectives."
        },
        {
            "title": "Preference",
            "content": "To fully implement both local axiom-wise guidance and global synergy-based tradeoffs, we integrate the synergy function into the DPO framework. Concretely, each fa(I) enters Bradley-Terry style preference:"
        },
        {
            "title": "P a",
            "content": "ij = exp(fa(Ii)) exp(fa(Ii)) + exp(fa(Ij)) , ensuring local interpretability for each axiom. Meanwhile, combined preference over S(I) expresses the global tradeoff: hyperparameter λ then balances how much this global synergy affects the final optimization vs. how much weight is given to local per-axiom preferences: LCAO = (cid:88) (cid:88) a=1 (i,j) log(P ij) + λ (cid:88) (cid:105) (cid:104) log(P ij ) . (i,j)"
        },
        {
            "title": "P S",
            "content": "ij = exp(S(Ii)) exp(S(Ii)) + exp(S(Ij)) . We can consolidate the local and global preferences into single loss function. One straightforward approach is: 4.5 Putting It All Together: Final CAO 6 (cid:88) (cid:88) LCAO = log(P ij) +λ log(P ij ) . (cid:88) (i,j) a=1 (cid:124) (i,j) (cid:123)(cid:122) Llocal (cid:125) (cid:124) (cid:123)(cid:122) Lsynergy (cid:125) Local Terms (Llocal). Each axiom retains interpretability and ensures the model handles faithfulness vs. artistry, emotional impact vs. neutrality, and so on, at granular level. Global Term (Lsynergy). This enforces coordinated tradeoffs by encouraging consistency with the aggregator S(I). larger λ implies stronger synergy constraints and places more emphasis on global equilibrium across axioms, while smaller λ prioritizes local alignment objectives. Why Keep Both Local and Global? Local Preferences (P ij) show how the model balances each contradictory pair (e.g., Did we favor faithfulness over artistry?), preserving interpretability at the axiom level. Global Preference (P ij ) ensures the T2I model, as whole, follows the overarching synergy profile, capturing all tensions in unison. Hence, λ dials in how much to respect the overall synergy aggregator vs. each per-axiom preference."
        },
        {
            "title": "4.4 Axiom-Specific Regularization in CAO",
            "content": "To stabilize the optimization and prevent overfitting to any single objective, CAO also provides regularization term for each axiom: LCAO = 6 (cid:104) (cid:88) a=1 fa(I) + τa Ra (cid:105) , where τa scales the influence of the regularizer Ra. While KL-divergence is common choice, it can be unstable in high-dimensional T2I scenarios; Wasserstein Distance (Arjovsky et al., 2017) or Sinkhorn regularization (Cuturi, 2013) typically offer more robust optimization. cf Appendix for the rationale behind Wasserstein Distance and Sinkhorn Regularization. Formulation Bringing together the synergy function, local Bradley-Terry preferences, and axiom-specific regularization leads to the final CAO objective: (cid:88) (cid:88) LCAO = log(P ij) λ (cid:88) log(P ij ) a= (i,j) (cid:124) (cid:125) (cid:123)(cid:122) Local Axiom Preferences (i,j) (cid:124) (cid:123)(cid:122) Global Synergy Preference (cid:125) + (cid:88) a=1 τa Ra. Role of the Synergy Jacobian (JS) : The Synergy Jacobian JS is vital component in managing gradient interactions across multiple axioms during training. While the regularization parameter λ balances local and global objectives, JS quantifies how updates to model parameters for one axiom impact the alignment of others. Mathematically, JS is defined as: JS = S(I) θ , where S(I) represents the synergy aggregator that measures overall alignment, denotes the input, and θ are the model parameters. This Jacobian provides structured view of the interdependencies among axioms, capturing how conflicting objectives influence each other (Navon et al., 2022; Yu et al., 2020). Intuition and Practical Role: During training, gradients for individual axioms often conflict, resulting in updates that disproportionately favor one objective at the expense of others. The Synergy Jacobian addresses this issue by scaling or adjusting gradients based on their interactions with the synergy aggregator S(I). Specifically: Gradients that align well with improving overall synergy are preserved to maintain their positive contribution. Gradients that disproportionately benefit single axiom while adversely affecting others are scaled back to ensure balance across objectives."
        },
        {
            "title": "The parameter update during training can be",
            "content": "expressed as: θ = η α JS, where is the standard gradient of the loss, η is the learning rate, and α is scaling factor controlling the influence of the Synergy Jacobian. This (A) Local Axiom Preferences log(P faith_artistic Llocal = ij (cid:104)(cid:88) (cid:88) ) + log(P emotion_neutrality ij (i,j) (i,j) ) + (cid:88) (i,j) Here, each term is negative log-likelihood over (B) Global Synergy Preference ij = log(P visual_style ij ) + (cid:88) log(P originality_referentiality ij ) + (i,j) exp(fa(Ii)) exp(fa(Ii))+exp(fa(Ij )) for axiom a. log(P verifiability_creative ij ) + (cid:88) (i,j) log(P cultural_artistic ij (cid:105) ) . (cid:88) (i,j) (cid:16) exp ω1ffaithArtistic(Ii) + . . . + ω6fculturalArtistic(Ii) (cid:17) ω1ffaithArtistic(Ii) + . . . + ω6fculturalArtistic(Ii) (cid:17) (cid:16) + exp ω1ffaithArtistic(Ij ) + . . . + ω6fculturalArtistic(Ij ) (cid:88) (cid:16) log Lsynergy = (i,j) (cid:16) exp This term encodes the preference for S(I) = (cid:80)6 (C) Axiom-Specific Regularizers (cid:90) (cid:90) a=1 ωa fa(I). 6 (cid:88) a=1 τa Ra = τ1 (cid:90) y Pfaith(x) Qartistic(y) dx dy (cid:90) Pfaith(x) dx Qartistic(y) dy (cid:90) (cid:90) (cid:90) + . . . + τ6 y Pcultural(x) Qartistic(y) dx dy (cid:90) Pcultural(x) dx Qartistic(y) dy (cid:17) . (cid:17) . Figure 6: modular breakdown of the CAO loss. (A) Local per-axiom preferences, (B) global synergy preference, (C) axiom-specific regularizers. Three error loss surfaces from the ablation study demonstrate the progressive impact of incorporating components of the YinYang alignment objective. The first plot, with only the Local Axiom Preferences, shows an unstable gradient landscape. Adding in the second plot smooths the loss surface significantly. Finally, introducing additional Regularization Terms in the third plot further stabilizes and smooths the surface, making optimization more efficient and robust. formulation ensures that the optimization process remains balanced, preventing any single axiom from dominating the alignment process. The impact of the Synergy Jacobian on resolving gradient conflicts and guiding optimization can be visualized in Fig. 7. Benefits: The incorporation of JS ensures: 1) Balanced Optimization: Prevents one axiom from overshadowing others, fostering holistic alignment across contradictory objectives. 2) Stability: Reduces the risk of oscillations or instability during training by moderating conflicting gradient interactions. 3) Cohesion: Facilitates stable and unified optimization process, ensuring that all objectives contribute meaningfully to the overall alignment. Further details, derivations, and examples are provided in Appendix G."
        },
        {
            "title": "Benefits and Scalability",
            "content": "Pareto-Aware Multi-Objective Control: By sweeping synergy weights {ωa}, we explore Pareto frontier of alignment solutions, clarifying how intensifying constraints for one axiom (e.g., cultural sensitivity) impacts another (e.g., artistic freedom). Global Alignment & Local Interpretability: ij offers coherij preserve The synergy-based preference ent global objective, while individual axiom-level clarity. Efficient Computation via Sinkhorn Regularization: Wasserstein-based distances are highly effective for aligning distributions but can be computationally expensive, particularly for largescale data, as their complexity often scales poorly. Sinkhorn regularization (Cuturi, 2013) addresses this issue by introducing an entropy-based reguFigure 7: Visualization of optimization paths and gradient dynamics with and without the Synergy Jacobian. 3D Plots (Top Row): The synergy score (z-axis) peaks at the Pareto-optimal point (black cross), representing the ideal balance between competing objectives. Without Jacobian Adjustment (left column): The optimization path (red circles) follows conflicting gradients (red arrows), leading to suboptimal convergence away from the Pareto-optimal point. With Jacobian Adjustment (right column): The gradients (blue arrows) are harmonized by the Synergy Jacobian, guiding the optimization path (blue circles) toward the synergy peak. 2D Plots (Bottom Row): The 2D plots provide top-down perspective of the same optimization dynamics, highlighting gradient directions and path alignment. Without Jacobian Adjustment (left column): Misaligned gradients cause the path to diverge from the Pareto-optimal region. With Jacobian Adjustment (right column): Adjusted gradients align consistently, enabling smooth convergence to the synergy peak. Together, these visualizations demonstrate the effectiveness of the Synergy Jacobian in resolving gradient conflicts, fostering cohesive and efficient optimization across competing objectives. larization term to the optimal transport problem, which smooths the optimization and significantly reduces computational overhead. The Sinkhorn distance is defined as: Wλ(P, Q) = min γ, λH(γ), γΠ(P,Q) where and are the distributions to be aligned, Π(P, Q) denotes the set of all valid couplings with marginals and Q, is the cost matrix, λ is the regularization parameter, and H(γ) is the entropy of the coupling γ, defined as: H(γ) = (cid:88) i,j γij log γij. By incorporating this entropy term, the optimization problem becomes smoother and computationally efficient, allowing for faster convergence through iterative scaling algorithms. This approach reduces complexity to near-linear time while retaining the core advantages of Wasserstein-based methods, making it scalable and robust for large-scale alignment tasks. Fig. 8 illustrates the practical impact of Sinkhorn regularization by comparing optimization paths and cost surfaces with and without regularization. 3. Content Difference: Measures deviation from the baseline image: ContentDiff = 1 cos(E(Igen), E(Ibase)). This term ensures the generated image does not diverge excessively from Ibase, acting as mild regularizer for subject fidelity. We define:"
        },
        {
            "title": "5 Axiom-Specific Loss Function Design",
            "content": "AFS = α StyleDiff + β ContentAbs + γ ContentDiff. We now expand each of the axiom-wise losses introduced previously: Lartistic, Lfaith, Lemotion, Lneutral, Loriginality, Lreferentiality, Lverifiability, Lcultural. Lartistic. Note that Lartistic appears in four of the six axioms, but the core design of the artistic loss remains consistent across all such instances. cf Appendix L. 5.1 Artistic Freedom: Lartistic The Artistic Freedom Score (AFS) measures how much creative enhancement generated image Igen receives, relative to baseline Ibase. It comprises three components: 1. Style Difference: Gauges stylistic deviation using VGG-based Gram features (Gatys et al., 2016; Johnson et al., 2016), widely adopted approach in neural style transfer for capturing higher-order correlations that define an images aesthetic characteristics: StyleDiff = S(Igen) S(Ibase)2. Here, S() represents pretrained style-extraction network. 2. Content Abstraction: Evaluates how abstractly Igen interprets the textual prompt . Formally, By default, we set α = 0.5, β = 0.3, and γ = 0.2 based on empirical tuning. Omitting ContentDiff may boost artistic freedom but risks straying too far from baseline subject matter, reflecting the inherent tension between creativity and fidelity. Calculating the AFS for the images in Fig. 3 using the first image as the reference yields: Chosen 1 and Chosen 2 with moderate AFS scores of 0.80 and 0.82, indicating minimal artistic deviation. In contrast, the Rejected images score higher, with Rejected 1, Rejected 2, and Rejected 3 achieving 0.99, 1.06, and 0.87 respectively, reflecting greater abstraction and stylistic deviation. AFS ranges are defined as Low (0.00.5), Moderate (0.51.0), and High (1.02.0), capturing the balance between prompt adherence and artistic creativity."
        },
        {
            "title": "5.2 Faithfulness to Prompt: Lfaith\nFaithfulness to the prompt is a cornerstone of T2I\nalignment, ensuring that generated images adhere\nto the semantic and visual details specified by the\nuser. To evaluate faithfulness, we leverage a seman-\ntic alignment metric based on the Sinkhorn-VAE\nWasserstein Distance, a robust measure of distribu-\ntional similarity that has gained traction in genera-\ntive modeling for its interpretability and effective-\nness (Arjovsky et al., 2017; Tolstikhin et al., 2018).",
            "content": "The Faithfulness Loss is formulated as: ContentAbs = 1 cos(E(P ), E(Igen)), Lf aith = λ (P (Zprompt), Q(Zimage)), where E() is multimodal embedding model (e.g., CLIP) (Radford et al., 2021). Higher ContentAbs indicates stronger abstraction away from literal prompt details. This concept of content abstraction draws inspiration from prior crossmodal research (Zhang et al., 2021; Mou et al., 2022), which highlights how multimodal embeddings can bridge prompt semantics and visual representations (Lei et al., 2023; Gupta et al., 2023). where: (Zprompt) and Q(Zimage) are the latent distributions of the textual prompt and the generated image, respectively, extracted using Variational Autoencoder (VAE). λ denotes the Sinkhorn-regularized Wasserstein Distance, which facilitates computational efficiency and stability (Cuturi, 2013). Figure 8: Visualization of optimization paths and cost landscapes with and without Sinkhorn regularization. The figure consists of two panels: Left Panel (Without Regularization): The jagged cost surface exhibits steep gradients and sharp valleys, as indicated by the tightly packed contour lines. The red path represents the chaotic optimization trajectory, characterized by oscillatory and inefficient updates due to the irregular gradients. The green star marks the starting point, and the black cross indicates the end point. The annotation \"Steep Gradient\" highlights areas where the optimization struggles to progress smoothly. Right Panel (With Sinkhorn Regularization): The smooth cost surface demonstrates gradual changes in cost, as shown by the widely spaced contour lines. The blue path represents the efficient and stable optimization trajectory. The green star marks the starting point, and the black cross indicates the end point. The annotation \"Smooth Gradient\" points to areas where regularization has flattened the landscape, enabling consistent and effective gradient updates. This comparison illustrates the effectiveness of Sinkhorn regularization in transforming jagged, computationally expensive optimization problem into smooth, scalable one. The blue-green-yellow colormap highlights gradient intensities while maintaining visual clarity across both panels. Key Advantages: Semantic Depth: Captures alignment at distributional level, accommodating nuanced semantic relationships. Robustness: Accounts for variability in generation without penalizing minor creative deviations. Scalability: Efficient for large-scale applications, making it suitable for real-world deployment. By adopting this approach, the Faithfulness Loss ensures that T2I systems effectively adhere to user prompts while integrating seamlessly into the broader CAO framework. To calculate Faithfulness Scores (Lfaith) for the images in Fig. 3, we compute the semantic alignment using the Sinkhorn-regularized Wasserstein Distance (W λ ) between the prompt and each image. Using the first image as the reference, the Faithfulness Scores are as follows: Chosen 1 and Chosen 2 achieve high faithfulness scores of 0.95 and 0.92, respectively, reflecting strong adherence to the prompt. In contrast, the Rejected images score lower, with Rejected 1, Rejected 2, and Rejected 3 receiving 0.70, 0.63, and 0.58, respectively, due to their increased stylistic and semantic deviation. Faithfulness Scores range from 0.0 (poor alignment) to 1.0 (perfect alignment), ensuring adherence to prompt semantics."
        },
        {
            "title": "5.3 Emotional Impact Score (EIS): Lemotion\nEIS quantifies the emotional intensity of gener-\nated images using emotion detection models (e.g.,\nDeepEmotion (Abidin and Shaarani, 2018)), pre-\ntrained on datasets labeled with emotions such as\nhappiness, sadness, anger, or fear. Higher ERS\nvalues indicate stronger emotional tones.",
            "content": "ERS ="
        },
        {
            "title": "1\nM",
            "content": "M (cid:88) i=1 EmotionIntensity(imgi) where: : Total number of images in the batch, EmotionIntensity(imgi): Scalar intensity of the dominant emotion in image imgi. Neutrality Score (N): Neutrality measures the degree of emotional balance or impartiality in generated images, complementing EIS by capturing the absence of dominant emotion. = 1 max(EmotionIntensity) where: max(EmotionIntensity): Intensity of the most dominant emotion detected in the image. Higher values (closer to 1) indicate emotionally neutral images, while lower values reflect strong emotional dominance. Tradeoff Between Emotional Impact and Neutrality: To evaluate the tradeoff between Emotional Impact and Neutrality, we define combined metric: 5.4 Originality vs. Referentiality: Loriginality & Lref erentiality To evaluate the originality of generated image Igen, we propose leveraging CLIP Retrieval to dynamically identify reference styles and compute stylistic divergence. This method builds on the capabilities of pretrained CLIP models to represent both semantic and visual features effectively (Radford et al., 2021; Carlier et al., 2023). The originality loss, Loriginality, is computed as the average cosine dissimilarity between the embedding of the generated image and the embeddings of the top-K reference images retrieved from large-scale style database: foriginality_referentiality(I) = 1 (cid:16) (cid:88) k=1 (cid:122) (cid:104) 1 cos (cid:124) where: Loriginality (cid:125)(cid:124) ECLIP(Igen), ECLIP(Sretr,k) (cid:123)(cid:122) Lreferentiality (cid:125) (cid:17) (cid:123) (cid:105) . TEMN = α ERS + β ECLIP(): Embedding function of pretrained CLIP model. where: α: Weight assigned to Emotional Impact. β: Weight assigned to Neutrality. α(0.3) + β(0.7) = 1: Ensuring balanced contribution, chosen empirically. To calculate Emotional Impact Scores (EIS) for the images in Fig. 13 for the prompt \"A postdisaster scene\", we assess the emotional intensity (ERS), neutrality (N ), and the combined tradeoff metric (TEMN). Image 1 achieves the lowest emotional intensity (ERS = 0.20) and the highest neutrality (N = 0.80), resulting in the highest trade-off score (TEMN = 0.62), reflecting emotional balance with minimal impact. In contrast, Image 5 demonstrates the strongest emotional intensity (ERS = 1.00) and the lowest neutrality (N = 0.00), leading to the lowest trade-off score (TEMN = 0.30), indicative of highly impactful and emotionally dominant scene. The intermediate images show gradual escalation: Image 2 has ERS = 0.30, = 0.70, and TEMN = 0.58; Image 3 exhibits ERS = 0.60, = 0.40, and TEMN = 0.48; and Image 4 demonstrates ERS = 0.80, = 0.20, and TEMN = 0.44. These metrics effectively capture the progression from balanced to highly impactful emotional states, highlighting the trade-off between emotional depth and neutrality in the generated post-disaster scenes. Sretr,k: The k-th reference image retrieved using CLIP Retrieval (Carlier et al., 2023). K: The number of top-matching reference images considered. Higher Loriginality indicates greater stylistic divergence from existing references, reflecting more originality. Reference Image Retrieval with CLIP. To dynamically select reference images, we use CLIP Retrieval (Carlier et al., 2023), which queries curated database of artistic styles based on the generated image embedding. The retrieval process is as follows: 1. Embedding Computation: Compute the CLIP embedding of the generated image ECLIP(Igen). 2. Database Query: Compare ECLIP(Igen) against precomputed embeddings of reference database, such as WikiArt or BAM. 3. Top-K Selection: Retrieve the top-K reference images Sretr,k with the highest similarity scores to Igen. Reference Databases. WikiArt: large-scale dataset containing over 81,000 images spanning 27 art styles, including impressionism, surrealism, and cubism (Saleh and Elgammal, 2015). BAM (Behance Artistic Media): dataset comprising over 2.5 million high-resolution images, curated from professional portfolios across diverse artistic styles (Wilber et al., 2017). To evaluate the originality and referentiality of the images in Fig. 13 for the prompt \"A majestic cathedral interior with an ethereal glowing circular portal leading to serene golden landscape\", we calculate Originality Loss (Loriginality) and Referentiality Loss (Lreferentiality) based on their stylistic divergence and alignment with the reference imImage 1 demonstrates the highest originalage. ity (Loriginality = 0.85) and the lowest referentiality (Lreferentiality = 0.15), reflecting strong stylistic independence. In contrast, Image 5 shows the lowest originality (Loriginality = 0.35) and the highest referentiality (Lreferentiality = 0.65), indicating significant stylistic borrowing from the reference. The intermediate images exhibit smooth transition: Image 2 achieves Loriginality = 0.75 and Lreferentiality = 0.25; Image 3 scores Loriginality = 0.65 and Lreferentiality = 0.35; and Image 4 obtains Loriginality = 0.50 and Lreferentiality = 0.50. These scores highlight the gradual trade-off between originality and referentiality, effectively capturing the stylistic evolution of the images relative to the reference."
        },
        {
            "title": "Embedding Generation",
            "content": "1. Prompt Embedding: For each dynamically generated cultural sub-prompt Pi, embeddings are extracted using multimodal model (e.g., CLIP). Let {E(P1), E(P2), . . . , E(Pk)} represent the embeddings of sub-prompts. 2. Image Embedding: The T2I-generated image is embedded using the same model, yielding E(I). Prompt-Image Similarity: For each subprompt Pi and the generated image I, calculate the semantic similarity using cosine similarity: sim(E(Pi), E(I)) = E(Pi) E(I) E(Pi)E(I) Sub-Prompt Aggregation: Aggregate the similarity scores across all sub-prompts to compute the overall alignment score: SCCMraw = 1 (cid:88) i=1 sim(E(Pi), E(I)) Normalization: Normalize the raw SCCM score to the range [0, 1] for consistent evaluation: SCCMfinal = SCCMraw SCCMmin SCCMmax SCCMmin where SCCMmin and SCCMmax are predefined minimum and maximum similarity scores based on validation dataset."
        },
        {
            "title": "Example Computation of SCCM",
            "content": "User Prompt: Generate an image of Japanese garden during spring. Based on the following user prompt: \"Generate an image of Japanese garden during spring,\" identify the cultural context or elements relevant to this description. Then, generate 3-5 culturally accurate and contextually diverse sub-prompts that expand on the original prompt while maintaining its essence. Ensure the sub-prompts reflect specific traditions, symbols, or nuances related to the mentioned culture. LLM-Generated Sub-Prompts: P1: traditional Japanese garden with koi pond and wooden bridge. P2: Cherry blossoms blooming in spring with traditional Japanese stone lanterns. P3: Zen rock garden with raked gravel patterns. Similarity Scores: sim(E(P1), E(I)) = 0.85, sim(E(P2), E(I)) = 0.80, sim(E(P3), E(I)) = 0. Raw Aggregated Score: 5.6 Verifiability Loss: Lverifiability SCCMraw = 0.85 + 0.80 + 0.75 3 = 0.80 Final SCCM Score: SCCMfinal = 0.80 0.70 0.90 0.70 = 0.50 To evaluate the Cultural Sensitivity (Lcultural) for the images in Fig. 13, we compute their alignment with cultural sub-prompts dynamically generated for the prompt \"Images of Vikings\". The Simulated Cultural Context Matching (SCCM) score quantifies cultural alignment, with higher values indicating better adherence to the Viking cultural context. The verifiability loss quantifies how closely generated image Igen aligns with real-world references by comparing it to the top-K images retrieved from Google Image Search. This ensures the generated content maintains level of authenticity and visual consistency. Lverifiability = 1 1 (cid:88) k=1 (cid:16) cos E(Igen), E(Isearch,k) (cid:17) , where: Igen: The generated image. Isearch,k: The k-th image retrieved from Google For this analysis, we used the following LLMImage Search. Generated Sub-Prompts: P1: Viking warrior with traditional braids and fur cloak. E(): pretrained embedding extraction model (e.g., DINO ViT) used to capture image semantics. K: The number of top-retrieved images used for P2: Viking shield maiden holding decorated comparison. wooden shield. How it Works: P3: Viking warrior in snowy Nordic landscape with an axe. P4: Viking chieftain standing before longship. P5: Viking encampment during Norse festival. The SCCM scores for each image reflect their alignment with these sub-prompts. Image 1 achieves moderate SCCM score of 0.65, suggesting some cultural elements are present but not fully emphasized. Image 2 and Image 3 demonstrate increasing cultural alignment, with scores of 0.75 and 0.80, respectively, as more cultural markers such as braided hair, traditional clothing, and iconic Viking weaponry are incorporated. Image 4 and Image 5 achieve the highest cultural sensitivity, with SCCM scores of 0.85 and 0.90, respectively, due to the inclusion of intricate cultural details such as Nordic landscapes, fur garments, and welldefined Viking weaponry. These results highlight progression in cultural adherence, showcasing how effectively T2I systems can generate culturally contextualized outputs. 1. The generated image Igen is submitted to Image Search to retrieve viimages, and Google sually {Isearch,1, Isearch,2, . . . , Isearch,K}. semantically similar 2. Embeddings are extracted for Igen and each retrieved image Isearch,k using pretrained model like DINO ViT, which captures global and local visual features. 3. The cosine similarity between the embeddings of Igen and each Isearch,k is computed and averaged. higher similarity indicates better alignment with real-world references. Key Insights: Interpretation: lower verifiability loss suggests that the generated image aligns well with real-world imagery, while higher loss indicates greater divergence. Applicability: Verifiability loss is crucial in domains like journalism, education, and scientific visualization, where factual consistency is paramount. This loss formulation balances creativity in generation with the need for authenticity and alignment with real-world references. To compute Verifiability Loss (Lverifiability) for the images in Fig. 13, given the prompt \"Pentagon is under fire,\" we evaluate the cosine similarity between the embeddings of each generated image (Igen) and the top-K real-world reference images retrieved from Google Image Search (Isearch,k), leveraging DINO ViT for feature extraction. The loss values underscore the balance between minimalism and the risk of propagating misinformation. Figure 9: comparative visualization of the density distributions of the Alpha values for three models: Stable Diffusion 3.5, DPO, and CAO. The X-axis represents the Alpha values, while the Z-axis denotes the density. Peaks at 3.34 for Stable Diffusion 3.5, 4.82 for DPO, and 4.95 for CAO highlight the respective models generalization capabilities. The Generalization Threshold (gold dashed line) and Overfitting Threshold (red dashed line) emphasize the trade-offs between generalization and potential overfitting. The progressive shift of peaks demonstrates the increasing robustness and alignment capabilities from Stable Diffusion 3.5 to CAO. Additionally, the decrease in peak height from Stable Diffusion to DPO and CAO reflects broadening of the distributions, signifying enhanced flexibility and greater adaptability to diverse prompts. For better understanding please refer to (Martin et al., 2021). Image 1 exhibits the lowest verifiability loss (0.12) as it avoids depicting unverifiable details, favoring minimalist and abstract representation. Conversely, Image 5 incurs the highest verifiability loss (0.80) due to its hyper-realistic portrayal, which closely resembles actual disaster imagery, thereby posing significant risk of misinformation. Intermediate losses are observed for Image 2 (0.30), Image 3 (0.45), and Image 4 (0.65), reflecting varying degrees of creative embellishments such as dramatic flames, smoke, and aerial perspectives. These results demonstrate the critical role of Lverifiability in evaluating the alignment of generated content with real-world references, especially in contexts where overly realistic yet fabricated visuals could mislead viewers and propagate misinformation."
        },
        {
            "title": "6 Empirical Evaluation",
            "content": "Evaluation Setup and Insights: Our evaluation examines the limitations of optimizing Directed Preference Optimization (DPO) models on individual alignment objectives. Specifically, we trained six models, each focusing on one axiom: Artistic Freedom, Faithfulness to Prompt, Emotional Impact, Originality, Cultural Sensitivity, and Verifiability. The impact of this single-axiom optimization on the other five objectives was measured in terms of percentage changes compared to baseline."
        },
        {
            "title": "Impact of Training DPO with Individual Axioms",
            "content": "Artistic Freedom: Training for Artistic Freedom resulted in 40% improvement, but at the expense of reduced Cultural Sensitivity (-30%) and Verifiability (-35%). Faithfulness to Prompt and Originality improved by 22% and 25%, respectively. Faithfulness to Prompt: Optimizing for Faithfulness to Prompt led to 40% improvement but reduced Artistic Freedom (-10%) while marginally improving Originality (+10%) and Emotional Impact (+5%). Emotional Impact: Training on Emotional Impact increased it by 40%, but resulted in 20% decline in Faithfulness to Prompt and 10% decline in Cultural Sensitivity. Artistic Freedom increased slightly (+15%). Originality: Prioritizing Originality improved it by 40%, but reduced Cultural Sensitivity (-25%) and Verifiability (-15%). Cultural Sensitivity: Optimizing Cultural Sensitivity led to 40% improvement, but reduced Verifiability (-30%) and Originality (-20%). Artistic Freedom dropped by 15%. Verifiability: Training for Verifiability resulted in 40% improvement but came at the expense Figure 10: Impact of Training DPO with Individual Axioms on Others: Comparative Evaluation. The plots illustrate the impact of training DPO to optimize single axiom on the other alignment objectives. Each subplot corresponds to one axiom, with percentage changes in performance (relative to baseline) shown for all other objectives. For example, training on Artistic Freedom improves it by 40%, but causes notable declines in Cultural Sensitivity (-30%) and Verifiability (-35%), while improving Faithfulness to Prompt (+22%) and Originality (+25%). These results underscore the inherent trade-offs of single-axiom optimization and motivate the need for holistic alignment approaches like CAO. of Originality (-25%) and Cultural Sensitivity (- 30%). Faithfulness to Prompt and Emotional Impact saw minor declines of 10% and 15%. Appendix K. For an overview of the key hyperparameters, optimization strategies, and architectural configurations used in this work, see Appendix D. Key Insights: Empirical findings elucidate the inherent limitations of single-axiom DPO training, where optimization bias disrupts inter-axiom equilibria, thereby affirming the necessity of multiobjective strategies such as CAO for holistic alignment. This motivates the need for our proposed CAO, which harmonizes trade-offs across all alignment objectives. For detailed discussion of the optimization landscape differences between DPO and CAO, including comparative visualizations of error surfaces, refer to Appendix I. The computational complexity and overhead introduced by the CAO framework, along with strategies to mitigate these challenges, are elaborated in Appendix J. Additionally, future avenues for reducing the computational burden of global synergy terms are explored in"
        },
        {
            "title": "7 Generalization vs. Overfitting: Effect",
            "content": "of Alignment The Weighted Alpha metric (Martin et al., 2021) offers novel way to assess generalization and overfitting in LLMs without requiring training or test data. Rooted in Heavy-Tailed Self-Regularization (HT-SR) theory, it analyzes the eigenvalue distribution of weight matrices, modeling the Empirical Spectral Density (ESD) as power-law ρ(λ) λα. Smaller α values indicate stronger self-regularization and better generalization, while larger α values signal overfitting. The Weighted Alpha ˆα is computed as: ˆα = 1 l=1 αl log λmax,l, where αl and λmax,l are the power-law exponent and largest eigenvalue of the l-th layer, respectively. This formulation highlights layers with larger eigenvalues, providing practical metric to (cid:80)L Figure 11: Comparison of Alignment Impacts: The plot illustrates the effect of training with DPO versus CAO across six axioms: Artistic Freedom, Faithfulness to Prompt, Emotional Impact, Originality, Cultural Sensitivity, and Verifiability. While DPO exhibits uncontrolled variations in the impacts, leading to undesirable tradeoffs (e.g., +40% Artistic Freedom but -30% Cultural Sensitivity), CAO achieves more balanced alignment with controlled tradeoffs (e.g., +10% Artistic Freedom and +44% Cultural Sensitivity). This demonstrates CAOs ability to harmonize competing axioms effectively. diagnose generalization and overfitting tendencies. Results reported in Fig. 9."
        },
        {
            "title": "Research Questions and Key Insights",
            "content": "1. RQ1: Do aligned T2I models lose generalizability and become overfitted? Alignment procedures introduce marginal increase in overfitting, as evidenced by generalization error drift of Egen 0.1, remaining within an acceptable range of 10%. 2. RQ2: Between DPO and CPO, which offers better generalizability? CAO is only marginally less generalized compared to DPO, demonstrating minor increase in the generalization gap. However, CAO achieves superior alignment by addressing six complex and contradictory axioms, such as faithfulness, artistic freedom, and cultural sensitivity, which DPO alone cannot comprehensively balance. This trade-off between generalizability and alignment complexity highlights CAOs ability to maintain robust prompt adherence while handling nuanced alignment challenges effectively."
        },
        {
            "title": "8 Conclusion",
            "content": "In this work, we introduced YinYangAlign, novel benchmark for evaluating Text-to-Image (T2I) systems across six contradictory alignment objectives, each representing fundamental tradeoffs in AI image generation. The study demonstrated that optimizing for single alignment axiom, such as Artistic Freedom or Faithfulness to Prompt, often disrupts the balance of other alignment objectives, leading to significant performance declines in areas like Cultural Sensitivity and Verifiability. This emphasizes the critical need for holistic optimization strategies. To navigate these alignment tensions, we propose Contradictory Alignment Optimization (CAO), transformative extension of Direct Preference Optimization (DPO). The CAO framework introduces multi-objective optimization mechanisms, including synergy-driven global preferences, axiom-specific regularization, and the innovative synergy Jacobian to balance competing objectives effectively. By leveraging tools such as Sinkhorn-regularized Wasserstein Distance, CAO achieves stability and scalability while delivering state-of-the-art performance across all six objectives. Empirical results validate the robustness of the proposed framework, showcasing not only its ability to align T2I outputs with diverse user intents but also its adaptability across multiple datasets and alignment goals. Moreover, the YinYangAlign dataset and benchmark provide critical resource for advancing future research in generative AI alignment, emphasizing fairness, creativity, and cultural sensitivity. This work establishes foundation for the principled design and evaluation of alignment strategies, paving the way for scalable, interpretable, and ethically sound T2I systems. Future work will explore adaptive mechanisms for dynamic weight tuning and extend the framework to emerging alignment challenges, further cementing YinYangAlign and CAO as cornerstones in the field of generative AI. (T2I) models with potentially contradictory axioms. core strength of this framework lies in its adaptability: given sufficient annotated data, end-users/developer can specify their desired balance between competing objectives, such as Faithfulness to Prompt versus Artistic Freedom or Cultural Sensitivity versus Creative Expression. This customization is facilitated by the Contradictory Alignment Optimization (CAO) mechanism, which translates user-defined preferences into weights for multi-objective optimization. By leveraging the sliders, users directly influence the blending of contradictory axioms, enabling tailored optimization process that reflects individual or application-specific requirements. For instance, use case focused on creative content generation may prioritize Artistic Freedom, while another requiring factual accuracy and cultural sensitivity may emphasize Verifiability and Cultural Sensitivity. The CAO framework dynamically adapts to these preferences, ensuring that the optimization process aligns with user-defined priorities. This section details how user-selected scales, representing preferences for contradictory axioms, are normalized and integrated into the multiobjective optimization process. The mathematical foundation of this mapping ensures clarity, reproducibility, and seamless adaptability for various use cases. Below, we describe the key steps involved in translating user preferences into actionable weights for CAOs optimization pipeline. 1. Normalize Slider Values Each slider value vi is normalized to compute the weight αi for the i-th axiom. The normalization ensures the weights sum to 1: αi = vi (cid:80)N j=1 vj , where: for = 1, . . . , N, vi: Value of the i-th slider (e.g., v1 = 67 for Faithfulness to Prompt). : Total number of axioms (e.g., = 6)."
        },
        {
            "title": "9 Discussion and Limitations",
            "content": "The development of YinYangAlign introduces novel paradigm for balancing contradictory axioms in Text-to-Image (T2I) systems, offering both theoretical contributions and practical implications. However, as with any sophisticated framework, its deployment and efficacy raise important points of discussion and reveal inherent limitations. This section critically examines the strengths and potential areas for improvement in YinYangAlign, situating it within the broader landscape of T2I alignment research. We begin by reflecting on the broader implications of our methodology, including its adaptability to diverse tasks and its capacity to integrate user preferences dynamically. We then address the limitations that stem from reliance on predefined axioms, the scalability of the framework across domains, and the challenges associated with data diversity and representation. These reflections aim to provide balanced perspective, guiding future refinements and encouraging dialogue within the research community to advance T2I alignment technologies further. Figure 12: This interface allows users to dynamically set their preferences for balancing contradictory axioms in Text-to-Image (T2I) generation. Each slider represents specific trade-off, such as Faithfulness to Prompt vs. Artistic Freedom, enabling fine-grained control over the alignment objectives. The left and right labels denote opposing axiom components, with the slider position reflecting the users preferred weight distribution. These inputs are translated into weights for the Contradictory Alignment Optimization (CAO) framework, guiding the system toward generating outputs tailored to user-defined priorities."
        },
        {
            "title": "9.1 Mapping User Preferences to",
            "content": "Multi-Objective Optimization Weights YinYangAlign introduces flexible and usercentric framework (cf. Fig. 12 for controls and Fig. 13 and Fig. 14 for the effect of varied controls on the output) for aligning text-to-image Figure 13: Comprehensive Visual Depiction of Trade-offs Between Alignment Axioms Across Prompts and Visual Styles. Each row represents specific textual prompt, showcasing variations in alignment across different axioms. (Row 1:) Illustrate peaceful garden with bench under cherry blossom tree. This row explores the trade-off between Faithfulness to Prompt and Artistic Freedom, transitioning from highly creative interpretations (left) to more realistic depictions (right). (Row 2:) post-disaster scene. This row examines the balance between Emotional Impact and Neutrality, ranging from emotionally intense scenes (right) to neutral and documentarystyle visuals (left). (Row 3:) portrait of Albert Einstein, showcasing his iconic wild hair and mustache, dressed in classic suit. Here, the interplay between Visual Realism and Artistic Freedom is illustrated, with images evolving from abstract and stylized (left) to photorealistic (right). (Row 4:) majestic cathedral interior with an ethereal glowing circular portal leading to serene golden landscape. This row highlights the trade-off between Originality and Referentiality, transitioning from imaginative, fantastical architecture (left) to \"Théâtre dOpéra Spatial\" style grounded representations (right). Adjustable parameters and metrics are shown for each prompt, underscoring how alignment affects the models ability to balance creativity and fidelity. Figure 14: Comprehensive Visual Depiction of Alignment Trade-offs for \"Pentagon is under fire\" and \"Images of Vikings\" Across Alignment Axioms. (Row 1:) Pentagon is under fire. This row demonstrates the trade-off between Verifiability and Artistic Freedom. The rightmost image depicts verifiable and realistic representation of the Pentagon under fire, emphasizing factual accuracy. Progressing to the left, the images increasingly prioritize artistic freedom, featuring surreal fire patterns, dramatic lighting, and exaggerated destruction, illustrating the tension between verifiability and creativity. (Row 2:) Images of Vikings. This row examines the balance between Cultural Sensitivity and Artistic Freedom. The leftmost image highlights cultural diversity and sensitivity, showcasing gender-balanced and ethnically varied Vikings, including Asian, African, and Mexican influences. Moving towards the right, artistic freedom faded, leading to depictions of Nordic-centric, rugged warriors with reduced diversity. This evolution highlights how cultural sensitivity diminishes as artistic freedom decreases. Adjustable Parameters: Alignment parameters, such as Faithfulness, Artistic Freedom, Verifiability, and Cultural Sensitivity, are depicted through sliders for each prompt. These settings demonstrate the trade-offs influencing the alignment results, enabling an evaluation of the models ability to balance competing objectives. 2. Define Multi-Objective Loss Function 9.2 Limitations Using the computed weights αi, objective loss function is defined as: the multiLmulti = (cid:88) i=1 αi Li, where: Li: Loss function corresponding to the i-th axiom (e.g., Lfaith, Lemotion). αi: Weight derived from the slider value vi. 3. Example Calculation the slider Given values: following Faithfulness to Prompt: 67, Emotional Impact: 55, Visual Realism: 66, Verifiability: 72, Cultural Sensitivity: 63. The total slider value is: 75, Originality: (cid:88) i=1 vi = 67 + 55 + 75 + 66 + 72 + 63 = 398. The normalized weights are: α1 = 67 398 , α2 = 55 398 , α3 = 75 398 , α4 = 66 398 , α5 = 72 398 , α6 = 63 398 . 4. Final Multi-Objective Loss Function The resulting multi-objective loss is: Lmulti = α1 Lfaith + α2 Lemotion + α3 Lrealism + α4 Loriginality + α5 Lverifiability + α6 Lcultural, where α1, α2, . . . , α6 are the normalized weights derived from the user-selected slider values."
        },
        {
            "title": "Advantages",
            "content": "Flexibility: The weights are dynamically adjustable based on user preferences. Interpretability: Slider positions directly correspond to the weight of each objective. Adaptive Optimization: The weights can guide optimization algorithms to achieve userpreferred balance among competing objectives. While YinYangAlign provides robust framework for evaluating alignment in Text-to-Image (T2I) systems, it has certain limitations that warrant further exploration: Dataset Diversity: The evaluation uses reference datasets like WikiArt and BAM, which are widely used benchmarks in artistic style and media research (Saleh and Elgammal, 2015; Wilber et al., 2017). While these datasets are extensive, containing diverse styles and high-resolution media, they may not fully capture the breadth of cultural or stylistic nuances present globally. This limitation introduces potential biases in alignment evaluation, particularly for underrepresented styles or cultural contexts, concern echoed in prior work on dataset fairness and representativeness in machine learning (Gebru et al., 2018; Dodge et al., 2021). Future efforts could focus on expanding these datasets to include broader range of cultural expressions, ensuring more equitable and robust alignment evaluations. Annotation Bottlenecks: Despite leveraging Vision-Language Models (VLMs) and human verification for annotations, the process is timeintensive. Scaling YinYangAlign to larger datasets or additional alignment axes might require more automated yet reliable annotation methods. Assumption of Trade-off Synergies: The Contradictory Alignment Optimization (CAO) framework presumes that all alignment objectives can be synergized through weighted trade-offs. However, certain objectives, such as Cultural Sensitivity and Emotional Impact, may present irreconcilable conflicts in specific contexts. For example, an emotionally impactful image might unintentionally invoke cultural insensitivity, particularly in cross-cultural scenarios. Similar challenges in handling competing objectives have been discussed in multi-objective optimization literature, such as Pareto efficiency in high-dimensional spaces (Lin et al., 2023; Miettinen, 1999; Navon et al., 2022). These inherent tensions could lead to suboptimal outcomes for tasks requiring careful navigation of such conflicts. We encourage further research to identify cases where trade-offs fail and propose adaptive mechanisms to address irreconcilable objectives while maintaining alignment robustness. Prompt makes the framework powerful for persuasive content generation. However, this capability introduces significant risks of misuse, particularly in generating emotionally manipulative or misleading content for political campaigns or advertising (Hwang et al., 2020; Zihao et al., 2022). Such uses could amplify societal polarization, manipulate public opinion, or exploit consumer vulnerabilities. Mitigating these risks necessitates embedding transparency and accountability mechanisms into the generation pipeline, such as digital watermarks (Ferreira et al., 2021) and provenance tracking systems (Agarwal et al., 2019), to ensure traceability and authenticity. These measures, when integrated effectively, can safeguard against unethical deployment while maintaining the technical utility of the framework. Environmental Impact: Training and deploying models like YinYangAlign demand considerable computational resources, contributing to carbon emissions. Studies have shown that large-scale model training can have substantial carbon footprint (Strubell et al., 2019; Patterson et al., 2021). Ethical deployment requires addressing this environmental footprint by optimizing computational efficiency and exploring carbon-offsetting measures (Anthony et al., 2020). Call to Action for the Research Community: We urge the research community to adopt proactive role in auditing and improving alignment frameworks like YinYangAlign. Collaborations with ethicists, social scientists, and legal experts are essential to navigate the nuanced challenges posed by such technologies. Transparency in the models design and decision-making processes, coupled with ongoing community engagement, will be critical to its responsible development and use. CAO with numerous contradictory axioms: While CAO effectively balances contradictory objectives, its scalability with an increasing number of axioms remains uncertain. The weighted aggregation of per-axiom preferences may introduce computational and optimization challenges, such as diminishing returns or unintended conflicts. Similar concerns are raised in hierarchical multi-task optimization (Ma et al., 2020; Liebenwein et al., 2021), where clustering objectives into modular sub-problems has shown promise. We urge the community to further experiment with and explore the scalability of synergy mechanisms in multi-axiom settings. Addressing these challenges forms core agenda for future extensions of this work, with focus on exploring hierarchical or modular synergy mechanisms that cluster related axioms into hierarchical levels, thereby reducing computational overhead while ensuring robustness and effectiveness in diverse alignment scenarios. Risk of Overfitting to Training Trade-offs: While the CAO framework effectively balances contradictory objectives, it risks overfitting to the specific trade-offs and preferences defined in the training data. This overfitting could limit the models generalizability across diverse prompts or domains, potentially reducing its adaptability to novel or unseen scenarios. Future work could explore techniques such as domain adaptation or prompt diversity augmentation to mitigate this limitation."
        },
        {
            "title": "9.3 Ethical Considerations & Benifits",
            "content": "The development of the YinYangAlign framework presents significant ethical considerations, given the models potential to influence societal norms, cultural representations, and artistic expressions. Below, we revisit these aspects with grounded perspective: Bias Mitigation: By introducing alignment axes such as Cultural Sensitivity vs. Artistic Freedom, YinYangAlign explicitly incorporates mechanisms to detect and mitigate cultural insensitivity or stereotyping in generated content. This is particularly important for creating inclusive and respectful outputs. Social Manipulation Risks: The inclusion of objectives like Emotional Impact and Faithfulness to"
        },
        {
            "title": "References",
            "content": "Aulia Rahman Abidin and Sharifah Mumtazah Syed Ahmad Shaarani. 2018. Deepemotion: Facial expression recognition using attentional convolutional network. Sensors, 18(11):3991. Prateek Agarwal, Sanjay Kumar, and Rajat Singh. 2019. Blockchain-based provenance tracking for ai-generated content. IEEE Blockchain Initiative, 7(2):9099. Liam Anthony, Benjamin Kanding, and Raghavendra Selvan. 2020. Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. arXiv preprint arXiv:2007.03051. Martin Arjovsky, Soumith Chintala, and Léon Bottou. 2017. Wasserstein generative adversarial networks. In Proceedings of the 34th International Conference on Machine Learning, volume 70 of ICML, pages 214223, Sydney, Australia. PMLR. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022. Training helpful and harmless assistant with reinforcement learning from human feedback. Preprint, arXiv:2204.05862. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1528215322, Singapore. Association for Computational Linguistics. Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. 2024. Chatbot arena: An open platform for evaluating llms by human preference. Preprint, arXiv:2403.04132. Paul Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017. Deep reinforcement learning from human prefIn Advances in Neural Information erences. Processing Systems, volume 30. Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Bingxiang He, Wei Zhu, Yuan Ni, Guotong Xie, Ruobing Xie, Yankai Lin, Zhiyuan Liu, and Maosong Sun. 2024. Ultrafeedback: Boosting language models with scaled ai feedback. Preprint, arXiv:2310.01377. Marco Cuturi. 2013. Sinkhorn distances: Lightspeed computation of optimal transport. In Proceedings of the 26th International Conference on Neural Information Processing Systems, NIPS, pages 22922300, Lake Tahoe, NV, USA. Curran Associates Inc. L. Daniele and Suphavadeeprasit. 2023a. Amplifyinstruct: Synthetically generated diverse multiturn conversations for efficient llm training. arXiv preprint arXiv:(coming soon). Romain Carlier et al. 2023. Clip retrieval: Efficient multimodal retrieval using clip. Available at https://github.com/rom1504/ clip-retrieval. Accessed: [Insert Date]. L. Daniele and Suphavadeeprasit. 2023b. Amplifyinstruct: Synthetically generated diverse multiturn conversations for efficient llm training. arXiv preprint, arXiv:(coming soon). Megha Chakraborty, Khushbu Pahwa, Anku Rani, Shreyas Chatterjee, Dwip Dalal, Harshit Dave, Ritvik G, Preethi Gurumurthy, Adarsh Mahor, Samahriti Mukherjee, Aditya Pakala, Ishan Paul, Janvita Reddy, Arghya Sarkar, Kinjal Sensharma, Aman Chadha, Amit Sheth, and Amitava Das. 2023. FACTIFY3M: benchmark for multimodal fact verification with explainability through 5W question-answering. In Kalyanmoy Deb. 2001. Multi-objective optimization using evolutionary algorithms. John Wiley & Sons. Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Dmitry Ilvovsky, and Noah Smith. 2021. Documenting bias in datasets: case study on the civil comments dataset. In NeurIPS Workshop on Data-centric AI. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain An imGelly, and Neil Houlsby. 2020. age is worth 16x16 words: Transformers for arXiv preprint image recognition at scale. arXiv:2010.11929. Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2024. Alpacafarm: simulation framework for methods that learn from human feedback. Preprint, arXiv:2305.14387. EUROPOL. 2023. Ai-generated content: Trends and predictions. André Ferreira, Nuno Pimentel, and Nuno Horta. 2021. Watermarking neural networks for inIn Internatellectual property protection. tional Conference on Artificial Neural Networks (ICANN), pages 300312. Springer. Leon Gatys, Alexander Ecker, and Matthias Bethge. 2016. neural algorithm of artistic style. arXiv preprint arXiv:1508.06576. Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford. 2018. Datasheets for datasets. Communications of the ACM, 64(12):8692. Ming Guo, Siyuan Li, and Dong Yu. 2022. survey on evaluation metrics for text-to-image synthesis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(7):12341248. Rakesh Gupta, Susan Johnson, and Wei Li. 2023. Prompt abstraction: Leveraging language-image embeddings to scale creativity. arXiv preprint arXiv:2302.12345. Seunghwan Hwang, Seungik Choi, and Taejun Yoon. 2020. Deepfake detection: systematic review. IEEE Access, 8:135292135304. Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Billion-scale similarity search with gpus. IEEE Transactions on Big Data, 7(3):535547. Justin Johnson, Alexandre Alahi, and Li Fei-Fei. 2016. Perceptual losses for real-time style transfer and super-resolution. In European Conference on Computer Vision (ECCV), volume 9906 of Lecture Notes in Computer Science, pages 694711. Springer. Joel Kaplan. 2025. More speech and fewer mistakes. Accessed: 2025-01-12. Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. 2017. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196. Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet Singh, Pratik Ringshia, and Davide Testuggine. 2020. The hateful memes challenge: Detecting hate speech in multimodal memes. CoRR, abs/2005.04790. Kimin Lee, Hao Liu, Moonkyung Ryu, Olivia Watkins, Yuqing Du, Craig Boutilier, Pieter Abbeel, Mohammad Ghavamzadeh, and Shixiang Shane Gu. 2023. Aligning text-to-image Preprint, models using human feedback. arXiv:2302.12192. Seongyun Lee, Seungone Kim, Sue Hyun Park, Geewook Kim, and Minjoon Seo. 2024. Prometheus-vision: Vision-language model as judge for fine-grained evaluation. Preprint, arXiv:2401.06591. M. Lei, C. Zhang, T. Dai, and H. Ji. 2023. Understanding content abstraction in multimodal transformers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(5):600615. Michaela Liebenwein, Cenk Baykal, Atsushi Yamamura, Sanjay Krishnan, and Andreas Krause. 2021. Provable subnetwork existence in large In International Conferpre-trained models. ence on Machine Learning (ICML), volume 139 of Proceedings of Machine Learning Research, pages 67816792. PMLR. Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. 2023. Lets verify step by step. Preprint, arXiv:2305.20050. Qing Lin, Yibo Zhao, and Zhi-Hua Chen. 2023. Pareto frontiers in deep learning: survey on multi-objective optimization for neural networks. Neural Networks, 161:471489. Ting-Wei Lin, Shing Xie, and Wei-Yi Liu. 2022. Pareto-based hyper-parameter searchIn Ading for multi-objective deep learning. vances in Neural Information Processing Systems (NeurIPS) Workshop. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Computer VisionECCV 2014: 13th European Conference, Zurich, Switzerland, September 612, 2014, Proceedings, Part 13, pages 740 755. Springer. Haotian Liu, Wenhui Dai, Chunyuan Yang, et al. 2023. Visual instruction tuning. arXiv preprint arXiv:2304.08485. Ilya Loshchilov and Frank Hutter. 2016. Sgdr: Stochastic gradient descent with warm restarts. arXiv preprint arXiv:1608.03983. Ilya Loshchilov and Frank Hutter. 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101. K. Lv, W. Zhang, and H. Shen. 2023. Supervised fine-tuning and direct preference optimization on intel gaudi2. https://medium.com/ intel-analytics-software/a1197d8a3cd3. Jianbo Ma, Lijun Wang, and Yuandong Tian. 2020. In InternaQuadratic multiple task learning. tional Conference on Machine Learning (ICML), volume 119 of Proceedings of Machine Learning Research, pages 65226531. PMLR. Charles Martin, Tongsu (Serena) Peng, and Michael Mahoney. 2021. Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data. Nature Communications, 12(1):4237. Midjourney. 2024. https://www.midjourney. com/home. Kaisa Miettinen. 1999. Nonlinear multiobjective optimization, volume 12 of International series in operations research & management science. Springer US, Boston, MA, USA. Yi Mou, E. Roberts, Y. Wu, and Y. Kim. 2022. Neural abstraction in text-to-image models: Balancing prompt fidelity and creative freedom. In Advances in Neural Information Processing Systems (NeurIPS). Amos Navon, Nir Shlezinger, Moustapha Cisse, Ori Friedman, and Olivier Bousquet. 2022. Multi-objective gradient methods for multi-task regression and classification with imbalanced tasks. In Advances in Neural Information Processing Systems (NeurIPS). OpenAI. 2023. Gpt-4 technical report. Preprint, arXiv:2303.08774. Long Ouyang, Jeff Wu, Xu Jiang, Dale Almeida, Peter Mishkin, Christopher Wainwright, Chengzhang Zhou, John Schulman, Alec Radford, Jeffrey Chen, et al. 2022. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155. David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021. Carbon emissions and large neural network training. arXiv preprint arXiv:2104.10350. Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, and Robin Rombach. 2023. Sdxl: Improving latent diffusion models for higharXiv preprint resolution image synthesis. arXiv:2307.01952. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning (ICML). PMLR. Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2024. Direct preference optimization: Your language model is secretly reward model. Preprint, arXiv:2305.18290. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter Liu. 2020. Exploring the limits of transfer learning with unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):54855551. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, and Ruslan Ilya Sutskever, Salakhutdinov. 2014. Dropout: simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(56):19291958. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-shot textto-image generation. In International Conference on Machine Learning, pages 88218831. PMLR. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1068410695. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. arXiv preprint arXiv:1505.04597. Yousef Saad. 2003. Iterative methods for sparse linear systems. SIAM. Babak Saleh and Ahmed Elgammal. 2015. Largescale classification of fine-art paintings: Learning the right metric on the right feature. In ACM International Conference on Multimedia Retrieval (ICMR), pages 479482. ACM. Chhavi Sharma, Deepesh Bhageria, William Scott, Srinivas PYKL, Amitava Das, Tanmoy Chakraborty, Viswanath Pulabaigari, and Björn Gambäck. 2020. SemEval-2020 task 8: Memotion analysisthe visuo-lingual metaphor! In Proceedings of the Fourteenth Workshop on Semantic Evaluation, pages 759773, Barcelona (online). International Committee for Computational Linguistics. Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. 2018. Conceptual captions: cleaned, hypernymed, image alt-text dataset for automatic image captioning. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 25562565. Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and policy considerations for deep learning in nlp. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 36453650. Ilya Tolstikhin, Olivier Bousquet, Sylvain and Bernhard Schoelkopf. 2018. arXiv preprint Gelly, Wasserstein auto-encoders. arXiv:1711.01558. Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-sne. Journal of machine learning research, 9(11):25792605. Cédric Villani. 2008. Optimal Transport: Old and New. Springer Science & Business Media. Bram Wallace, Meihua Dang, Rafael Rafailov, Linqi Zhou, Aaron Lou, Senthil Purushwalkam, Stefano Ermon, Caiming Xiong, Shafiq Joty, and Nikhil Naik. 2023. Diffusion model alignment using direct preference optimization. Preprint, arXiv:2311.12908. Zhilin Wang, Yi Dong, Jiaqi Zeng, Virginia Adams, Makesh Narsimhan Sreedhar, Daniel Egert, Olivier Delalleau, Jane Polak Scowcroft, Neel Kant, Aidan Swope, and Oleksii Kuchaiev. 2023. Helpsteer: Multi-attribute helpfulness dataset for steerlm. Preprint, arXiv:2311.09528. Michael Wilber, Chen Fang, Hailin Jin, Aaron Hertzmann, and Serge Belongie. 2017. Bam! the behance artistic media dataset for recognition beyond photography. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), pages 12021211. Christopher KI Williams and Matthias Seeger. 2001. Using the nyström method to speed up kernel machines. In Advances in neural information processing systems, volume 13, pages 682688. Tianyi Xiong, Xiyao Wang, Dong Guo, Qinghao Ye, Haoqi Fan, Quanquan Gu, Heng Huang, Banghua Zhu, Evan Frick, Tianhao Wu, Hanlin Zhu, and Jiantao Jiao. 2023. Starling-7b: Improving llm helpfulness & harmlessness with rlaif. Zhang Zihao, Wei Tan, and Paramjit Singh. 2022. Disinformation detection in ai-generated media: Challenges and opportunities. In Proceedings of the 30th International Conference on Information Systems (ICIS), pages 101112. and Chunyuan Li. 2024. Llava-critic: Learning to evaluate multimodal models. Preprint, arXiv:2410.02712. Jing Yang, Lei Wang, and Zhongzhi Shi. 2021. Towards understanding balanced and high-capacity multi-objective optimization. Complex & Intelligent Systems, 7(5):25332546. Michal Yarom, Yonatan Bitton, Soravit Changpinyo, Roee Aharoni, Jonathan Herzig, Oran Lang, Eran Ofek, and Idan Szpektor. 2023. What you see is what you read? improving text-image alignment evaluation. Preprint, arXiv:2305.10400. Jaehong Yoon, Shoubin Yu, Vaidehi Patil, Huaxiu Yao, and Mohit Bansal. 2024. Safree: Trainingfree and adaptive guard for safe text-toimage and video generation. arXiv preprint arXiv:2410.12761. Accessed: 2025-01-12. Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. 2020. Gradient surgery for multi-task learning. In Advances in Neural Information Processing Systems (NeurIPS). Wei Zhang, Ming Liu, Hao Chen, and Kun Li. 2021. Cross-modal abstraction for text-to-image synthesis. In Proceedings of the 29th ACM International Conference on Multimedia, pages 271280. ACM. Qi Zhao, Yunjie Li, and Shuang Wang. 2023. Mitigating bias in text-to-image generation: Methods and challenges. AI and Ethics Journal, 5(2):789805. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. Preprint, arXiv:2306.05685. Aojie Zhou, Jinzhao Sun, and Ke Tang. 2022. Pareto optimization for subset selection with dynamic costs. IEEE Transactions on Evolutionary Computation, 26(3):539553."
        },
        {
            "title": "10 Frequently Asked Questions (FAQs)",
            "content": "How does YinYangAlign differ from existing T2I benchmarks? Existing benchmarks typically focus on isolated objectives, such as fidelity to prompts or aesthetic quality. YinYangAlign is unique in evaluating how T2I systems navigate trade-offs between multiple conflicting objectives, providing more holistic assessment. What is the role of Contradictory Alignment Optimization (CAO)? CAO is framework introduced in the paper that harmonizes competing objectives through synergy-driven multi-objective loss function. It integrates local axiom-specific preferences with global trade-offs to achieve balanced optimization across all alignment goals. What are the key components of the CAO framework? The key components include: 1. Local per-axiom preferences to handle individual trade-offs. 2. global synergy mechanism for unified alignment. 3. regularization term to prevent overfitting to any single objective. How does YinYangAlign handle annotation challenges? YinYangAlign combines automated annotations using Vision-Language Models (VLMs) like GPT-4o and LLaVA with rigorous human verification. consensus filtering mechanism ensures reliability, with high inter-annotator agreement score (kappa = 0.83). What insights were gained from the empirical evaluation of DPO and CAO? The study revealed that optimizing single axiom using Directed Preference Optimization (DPO) often disrupts other objectives. For instance, improving Artistic Freedom by 40% caused declines in Cultural Sensitivity (-30%) and Verifiability (-35%). In contrast, CAO demonstrated controlled trade-offs, achieving more balanced alignment across all objectives. What are the metrics used to evaluate alignment in YinYangAlign? Metrics include changes in alignment scores across the six objectives, regularization terms to measure trade-offs, and statistical measures like the Pareto frontier to visualize multi-objective optimization. Why is the Pareto frontier significant in the CAO framework? The Pareto frontier illustrates the trade-offs between different objectives, showing how improvements in one area (e.g., faithfulness) may require concessions in another (e.g., artistic freedom). CAO leverages this concept to optimize multiple objectives simultaneously. What specific challenges does YinYangAlign address in the alignment of Text-to-Image (T2I) systems? YinYangAlign addresses the fundamental challenge of balancing multiple contradictory alignment objectives that are inherent to T2I systems. These include tensions such as adhering to user prompts (Faithfulness to Prompt) while allowing creative expression (Artistic Freedom) and maintaining cultural sensitivity without stifling artistic innovation. These challenges have been inadequately addressed by existing benchmarks, which often focus on singular objectives without considering their interplay. What are the six contradictory alignment objectives, and why were they chosen for YinYangAlign? The six contradictory objectives are: 1. Faithfulness to Prompt vs. Artistic Freedom: Ensures adherence to user instructions while allowing creative reinterpretation. 2. Emotional Impact vs. Neutrality: Balances generating emotionally evocative images with unbiased representation. 3. Visual Realism vs. Artistic Freedom: Maintains photorealism while allowing artistic stylization when appropriate. 4. Originality vs. Referentiality: Promotes unique outputs while avoiding style plagiarism. 5. Verifiability vs. Artistic Freedom: Ensures factual accuracy without restricting creativity. 6. Cultural Sensitivity vs. Artistic Freedom: Preserves respectful cultural representations while fostering artistic freedom. These were selected based on their prevalence in real-world applications and their alignment with academic and ethical considerations in AI image generation. How does Contradictory Alignment Optimization (CAO) differ from traditional Direct Preference Optimization (DPO)? CAO extends DPO by introducing multi-objective optimization framework that simultaneously balances all six alignment objectives. It integrates: Local Axiom-Wise Preferences: Loss functions that balance individual pairs of objectives (e.g., Faithfulness vs. Artistic Freedom). Global Synergy Mechanisms: Pareto frontier-based optimization approach that ensures trade-offs across all objectives are harmonized. Axiom-Specific Regularization: Prevents overfitting to any single objective by stabilizing optimization with techniques like Wasserstein regularization. How is the YinYangAlign dataset constructed, and what makes its annotation pipeline robust? The dataset is constructed using outputs from state-of-the-art T2I models (e.g., Stable Diffusion XL, MidJourney 6) and annotated through two-step process: Automated Annotation: Vision-Language Models (e.g., GPT-4o and LLaVA) generate preliminary annotations based on predefined scoring criteria for each objective. Human Verification: Annotations are validated by expert annotators, ensuring high reliability (kappa score of 0.83 across 500 samples). The pipeline balances scalability with rigorous quality control, enabling the creation of robust benchmark. How does CAO handle trade-offs between contradictory objectives, and what is the role of the synergy function? CAO uses synergy function that aggregates local axiom-wise losses into global multi-objective loss. By tuning synergy weights and leveraging Pareto optimality, CAO explores trade-offs systematically, identifying configurations where small sacrifices in one objective yield substantial gains in another. The synergy Jacobian further regulates gradient interactions, preventing any single objective from dominating the optimization process. What are the computational implications of implementing CAO? CAO introduces computational overhead due to its multi-objective optimization framework, especially when incorporating regularization terms and global synergy functions. However, techniques such as Sinkhorn regularization and efficient Pareto front computation mitigate these challenges. Scalability to larger datasets or higher-dimensional objective spaces remains an area for further exploration. How does YinYangAlign ensure adaptability to user-defined priorities? YinYangAlign incorporates user-centric interface where sliders allow users to specify their preferred balance for each objective. These preferences are normalized into weights and integrated into the CAO framework, enabling dynamic adaptation to diverse application contexts. For example, users can prioritize Faithfulness to Prompt for precise visual representations or emphasize Artistic Freedom for creative outputs. What are the limitations of YinYangAlign and the CAO framework? Dataset Limitations: The reliance on datasets like WikiArt and BAM may introduce biases, as they might not fully capture global cultural diversity. Irreconcilable Conflicts: Some objectives, such as Cultural Sensitivity and Emotional Impact, may conflict irreparably in certain scenarios, limiting CAOs effectiveness. Scalability: Balancing growing number of alignment objectives may introduce optimization and computational challenges, necessitating hierarchical or modular approaches. Overfitting Risks: Overfitting to training datas specific trade-offs could reduce the models generalizability to novel contexts. What are the broader implications of this research for the field of generative AI? YinYangAlign sets new standard for evaluating and designing T2I systems by addressing the nuanced interplay of competing alignment objectives. It emphasizes the importance of ethical considerations, user customization, and robust multi-objective optimization. The benchmark and CAO framework pave the way for future research into scalable, interpretable, and fair alignment strategies, extending their applicability to emerging challenges in generative AI."
        },
        {
            "title": "A Appendix",
            "content": "The Appendix serves as comprehensive supplement to the main content, offering detailed technical justifications, theoretical insights, and experimental evidence that could not be included in the main body due to space constraints. Its purpose is to enhance the clarity, reproducibility, and transparency of the research. This material provides readers with deeper insights into the methodology, empirical results, and theoretical contributions of YinYangAlign. The appendix is organized into the following sections: Annotation Process and Dataset Details: Detailed explanation of the annotation pipeline, dataset filtering criteria, inter-annotator agreement, and dataset composition. cf Appendix B. DPO: Contradictory Alignment Optimization (CAO): Mathematical formulations and explanations of local axiom preferences, global synergy preference, and axiom-specific regularization. cf Appendix C. Key Hyperparameters, Optimization Strategies, and Architecture Choices: Descriptions of model hyperparameters, training protocols, and architectural configurations. cf Appendix D. Ablation Studies on Regularization Coefficients (τa) and Combined Impact of Synergy Weights (ωa) and Regularization Coefficients (τa): Analysis of the effects of regularization coefficients and synergy weights on alignment performance and stability. cf Appendix E. Gradient Calculation of DPO-CAO: Detailed derivations of gradients for DPO-CAO, highlighting the role of synergy weights and regularization terms. cf Appendix F. Details on the Synergy Jacobian JS: Discussion on the synergy Jacobians role in regulating gradient interactions among contradictory objectives. cf Appendix G. Comparative Error Surface Analysis for DPO and DPO-CAO: Visualizations and insights into the differences in optimization landscapes between DPO and DPO-CAO. cf Appendix I. Complexity Analysis and Computational Overhead of DPO-CAO: Detailed breakdown of the computational cost of DPO-CAO compared to vanilla DPO, with proposed strategies for reducing overhead. cf Appendix J. Future Directions for Reducing Global Synergy Overhead: Discussion of potential methods to mitigate the computational burden introduced by global synergy terms. cf Appendix K. Details on Axiom-Specific Loss Function Design: Mathematical formulations and theoretical justifications for each axiom-specific loss function, including Faithfulness to Prompt, Artistic Freedom, Emotional Impact, Neutrality, Cultural Sensitivity, Verifiability, and Originality. cf Appendix L. We encourage readers to refer to the appendix to gain deeper understanding of the methodologies and findings presented in the main paper."
        },
        {
            "title": "B Annotation Process and Dataset Details",
            "content": "To construct the YinYang dataset, we carefully selected diverse datasets tailored to each of the six alignment axioms. Specifically: For the first three axiomsFaithfulness to Prompt vs. Artistic Freedom, Emotional Impact vs. Neutrality, and Visual Realism vs. Artistic Freedomwe utilized the MS COCO dataset (Lin et al., 2014). For Originality vs. Referentiality, we leveraged Googles Conceptual Captions dataset (Sharma et al., 2018). For Verifiability vs. Artistic Freedom, we selected the FACTIFY 3M dataset (Chakraborty et al., 2023). Why Wasserstein Distance and Sinkhorn Regularization? Theoretical justifications for choosing these methods, emphasizing their advantages in distributional similarity and computational efficiency. cf Appendix H. For Cultural Sensitivity vs. Artistic Freedom, we employed the Facebook Hate Meme Challenge (Kiela et al., 2020) and Memotion datasets (Sharma et al., 2020), carefully filtering for culturally sensitive data points. Axiom Faithfulness Prompt vs. Freedom to Artistic Emotional Impact vs. Neutrality Visual Realism Artistic Freedom vs. Identify if artistic freedom significantly compromises Instructions Given the textual description (prompt) and an image, evaluate the alignment of the image. 1. Faithfulness to Prompt: Evaluate how well the image adheres to the users prompt. 2. Artistic Freedom: Assess if the image introduces creative or artistic elements that deviate from, enhance, or reinterpret the original prompt. 3. faithfulness to the prompt. Output Format: Faithfulness Score (1-5), Artistic Freedom Score (1-5), Observations (Text). Given the textual description (prompt) and an image, evaluate the alignment of the image. 1. Emotional Impact: Evaluate whether the image conveys specific emotions as implied by the prompt. 2. biases and maintains an impartial tone. 3. neutrality required by the prompt. Output Format: Emotional Impact Score (1-5), Neutrality Score (1-5), Observations (Text). Given the textual description (prompt) and an image, evaluate the alignment of the image. image 1. replicates real-world visuals, including details, textures, and proportions. 2. Artistic Freedom: Assess if the image introduces artistic or creative elements that deviate from strict realism. 3. Identify if artistic freedom compromises the visual realism implied or required by the prompt. Output Format: Realism Score (1-5), Artistic Freedom Score (1-5), Observations (Text). Neutrality: Assess if the image avoids strong emotional Identify if the emotional intensity compromises the accurately Evaluate Realism: Visual how the Table 1: Instructions for evaluating alignment across six key axioms in Text-to-Image generation, designed for GPT-4."
        },
        {
            "title": "Here are the steps we follow in our annotations",
            "content": "VLMs: GPT-4 and LLaVA. See Table 1. process. 1. Dataset Consolidation: Collect all captions/prompts and original images from the mentioned datasets to ensure diversity and coverage of the six alignment axioms. 2. Image Generation: For each prompt, generate 10 images using MidJourney 6.0. This ensures sufficient variation in artistic and realistic interpretations of the same prompt. 3. Preliminary Annotation Language Models (VLMs): by VisionAnnotate all generated images using two Evaluate each image for the six alignment axioms (e.g., Emotional Impact, Visual Realism). Retain images where both VLMs give high score ( 3) for specific axiom. For example, if both models assign high score for Emotional Impact, the image is retained for further processing. Discard images that fail to achieve high score from either VLM for any axiom, as well as those where none of the VLMs provide high score. For Originality vs. Referentiality, Verifiability vs. Artistic Freedom, and Cultural Sensitivity vs. Artistic Freedom we used automatic methods as discussed in the Sec. 5. After this filtering process, approximately 50K images remain where GPT-4 and LLaVA agree on specific axiom. 4. Human Annotation Process: Engage 10 human annotators for manual evaluation. Each annotator is assigned 5,500 images to ensure comprehensive coverage of the dataset. Include 500-image overlap between adjacent annotators to calculate inter-annotator agreement and ensure consistency and reliability in the annotations. 5. Further Filtering During Human Annotation: Discard approximately 10K images during the manual annotation process due to quality issues, such as: Distorted image generation (e.g., unrealistic artifacts). Improper color rendering or other significant quality issues. 6. Final Dataset: The final YinYang dataset consists of 40K high-quality datapoints, carefully selected and annotated for the six alignment axioms. This dataset will be released for research purposes, enabling studies in Text-to-Image alignment and related areas. This selection ensures comprehensive and contextually relevant evaluation across all alignment objectives. Table 2 presents several detailed examples to enhance the authors understanding. Table 2: Examples of the YinYang dataset annotation process, illustrating the selection of T2I-generated images. Each example demonstrates how prompts vary in specificity and abstraction across datasets, highlighting the alignment challenges and trade-offs inherent in the annotation process. e c i . p P s l t YinYang Annotation Examples Caption: Several motorcycles riding down the road in formation. Original Image: Generated References: c S t e t e t e t e Continued on next page... e c i A . p P s u i YinYang Annotation Examples Caption: Little birds sitting on the top of giraffe. Original Image: Generated References: t e t e t e t e t e Continued on next page... d F s A . p P s u i YinYang Annotation Examples Caption: The woman in the kitchen is holding huge pan. Original Image: Generated References: c S c R c S c R c R Continued on next page... YinYang Annotation Examples Caption: model standing next to scooter in the middle of room of people. Original Image: e c i . p P s l t Generated References: c S c R c S t e t e Continued on next page... e c i . p P l n t YinYang Annotation Examples Caption: group of men standing in front of bar having conversation. Original Image: Generated References: c S c R t e t e t e Continued on next page... YinYang Annotation Examples Caption: black and white photo of an older man skiing. Original Image: l u . c I o m Generated References: c S c S t e t e t e Continued on next page... YinYang Annotation Examples Caption: hospital room with patient lying in bed and visitor sitting by their side. Original Image: l u . c I o m Generated References: c S c S t e t e t e Continued on next page... YinYang Annotation Examples Caption: protest in city square. Original Image: l u . c I o m Generated References: c S t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: house destroyed by hurricane. Original Image: i t . c I o m Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: student receiving their diploma on stage. Original Image: l u . c I o m Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: view of snow-capped mountain range under clear blue sky. Original Image: e c i . s e u Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: young woman sitting by window with sunlight falling on her face. Original Image: e c i . s e u Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: steaming cup of coffee, surrounded by scattered coffee beans on wooden table. Original Image: e c i . s e u Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: family enjoying picnic Original Image: e c i . s e u Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: lighthouse on cliff. Original Image: e c i . s e u Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: bustling city street. Original Image: Generated References: l n f . t n r t e d e d e d e The generated image reflects the distinctive painting style of Edward Hopper. See the right side painting by Hopper for reference. c R The generated image reflects the distinctive painting style of Leonid Afremov. See the right side painting by Afremov for reference. Continued on next page... YinYang Annotation Examples Caption: serene country side. Original Image: i t e . t n r Generated References: c S c S c S t e The generated image reflects the distinctive painting style of John Constable. See the right side painting by Constable for reference. Continued on next page... YinYang Annotation Examples Caption: busy marketplace. Original Image: l n f . t n i Generated References: c S c S c S c R The generated image reflects the distinctive painting style of Pieter Bruegel the Elder. See the right side painting by Bruegel for reference. Continued on next page... YinYang Annotation Examples Caption: beach at dawn. Original Image: l n f . t n r Generated References: c S t e t e t e The generated image reflects the distinctive painting style of Homusai. See the right side painting by Homusai for reference. Continued on next page... YinYang Annotation Examples Caption: group of people relaxing in grassy park by the riverside. Original Image: l n f . t n r Generated References: c S c S c S c R The generated image reflects the distinctive painting style of Georges Seurat. See the right side painting by Seurat for reference. Continued on next page... YinYang Annotation Examples Caption: After Israel released the head of Gazas Al-Shifa Hospital following seven-month detention, an image circulated on social media claiming to show Mohammed Abu Salmiya back at work as medic at Nasser Hospital in Khan Yunis. The original publisher was identified as an account dedicated to creating AI-generated imagery, run by visual creator named Islam Nour under the Instagram username in.visualart. The publisher also shared the image and clarified in the description that it had been created using AI programs. Original Image: l n f . t n r Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: Amid the floods in Andhra Pradesh in September 2024, an image allegedly showing drones delivering aid to stranded people was shared online. However, Misbars investigative team found watermark that read Imagined with AI, indicating it was generated by artificial intelligence. Original Image: l n f . t n r Generated References: c S c S t e t e t e Continued on next page... YinYang Annotation Examples Caption: Recently, social media users have circulated video claiming to show the discovery of mysterious spacecraft, reportedly the same one discussed by the U.S. Congress during session on November 13, allegedly spotted in Kuwaits sky. Original Image: l n f . t n r Generated References: c S c S c R c S t e Continued on next page... YinYang Annotation Examples Caption: Recently, social media users have widely shared photo of boy jumping over hundred corpses alleging that these corpses were Iraris killed by America. Original Image: l n f . t n i Generated References: c S c R c S c R t e Continued on next page... YinYang Annotation Examples Caption: Crocodile entering residential complex due to waterlogging in Vadodara. Original Image: l n f . t n r Generated References: t e t e t e t e t e Continued on next page... d F s A . t t e r u YinYang Annotation Examples Caption: 1943 German soldiers. Original Image: Generated References: t e t e t e t e t e Continued on next page... YinYang Annotation Examples Caption: Founding Fathers of America. Original Image: e c i . t t e r u Generated References: t e t e t e t e t e DPO: Contradictory Alignment Optimization (CAO) Contradictory Alignment Optimization (CAO) is proposed to address the inherent trade-offs in aligning Text-to-Image (T2I) models across six contradictory objectives. These objectives include, for example, Faithfulness to Prompt vs. Artistic Freedom or Emotional Impact vs. Neutrality. CAO builds upon the Directed Preference Optimization (DPO) framework (Rafailov et al., 2024) and introduces synergy-based approach to unify conflicting alignment goals using multi-objective optimization and Pareto efficiency principles (Miettinen, 1999). The CAO framework introduces the following key components: sets of non-dominated solutions where improvement in one axiom necessitates trade-off in another (Deb, 2001). For example, increasing Artistic Freedom may reduce Faithfulness to Prompt, but Pareto efficiency ensures that these trade-offs are optimized globally. C.1 Unified CAO Loss Function The CAO framework integrates both local axiomwise preferences and global synergy into single optimization objective, building on the DPO loss formulation (Rafailov et al., 2024): LCAO = (cid:88) (cid:88) a=1 (i,j) log(P ij) λ log(P ij ), (cid:88) (i,j) 1. Local Axiom-Wise Loss Functions: Each alignment axiom (e.g., Faithfulness to Prompt vs. Artistic Freedom) is assigned specific loss function that balances two competing sub-objectives: fa(I) = αaLp(I) + (1 αa)Lq(I), where: Lp(I) and Lq(I) represent the sub-objectives within an axiom. For example, in Faithfulness to Prompt vs. Artistic Freedom, Lp may measure semantic alignment to the prompt, while Lq quantifies stylistic deviation. αa [0, 1] is mixing parameter controlling the trade-off for axiom a. Larger αa prioritizes Lp, whereas smaller αa favors Lq. 2. Global Synergy Aggregator: To reconcile multiple axioms, global synergy function S(I) aggregates the local losses: S(I) = (cid:88) a=1 ωafa(I), where: is the total number of axioms (e.g., = 6 for the YinYang framework). ωa represents the priority or weight assigned to each axiom a. This parameter allows practitioners to emphasize certain objectives over others depending on the application. 3. Pareto Frontiers: By varying the weights ωa, CAO explores Pareto frontiers, which represent where: ij is the Bradley-Terry preference probability for axiom a:"
        },
        {
            "title": "P a",
            "content": "ij = exp(fa(Ii)) exp(fa(Ii)) + exp(fa(Ij)) , ensuring pairwise alignment under axiom a. ij is the global synergy preference probability:"
        },
        {
            "title": "P S",
            "content": "ij = exp(S(Ii)) exp(S(Ii)) + exp(S(Ij)) . λ is scaling factor controlling the relative importance of local and global preferences. Extended equation is reported in C.2. C.2 Axiom-Specific Regularization To stabilize optimization and avoid overfitting, CAO incorporates regularization terms for each axiom: LDPO-CAO = (cid:88) a=1 [fa(I) + τaRa] , where: τa controls the influence of the regularizer Ra for axiom a. Common regularizers include Wasserstein Distance (Villani, 2008) to enforce smoothness in feature space and Sinkhorn regularization (Cuturi, 2013) for computational efficiency in highdimensional scenarios. (cid:33) ) ) ( s A u c 6 ω + ) ( t C l fi v 5 ω + ) ( l n f t n r 4 ω + ) ( t u f 3 ω + ) ( l u o m 2 ω + ) ( s r t f 1 ω ( ) ) ( s A u c 6 ω + ) ( t C l fi v 5 ω + ) ( l n f t n r 4 ω + ) ( t u f 3 ω + ) ( l u o m 2 ω + ) ( s A a 1 ω ( + ) ) ( s A u c 6 ω + ) ( t C l fi v 5 ω + ) ( l n f t n r 4 ω + ) ( t u f 3 ω + ) ( l u o m 2 ω + ) ( s r t f 1 ω ( (cid:32) λ ) C ( i j r - t h n a i e P - D f i u i j (cid:19) ) ) ( l n f t n r ( (cid:19) ) ) ( t C l fi v ( ) ) ( l n f t n r ( + ) ) ( l n f t n r ( e (cid:19) ) ) ( s A u c ( ) ) ( t C l fi v ( + ) ) ( t C l fi v ( ) ) ( s A u c ( + ) ) ( s r a l ( (cid:19) ) ) ( l u o m ( (cid:19) ) ) ( s A a ( e ) ) ( s A a ( + ) ) ( s A a ( (cid:19) ) ) ( t u f ( ) ) ( l u o m ( + ) ) ( l u o m ( e ) ) ( t u f ( + ) ) ( t u f ( (cid:18) (cid:18) (cid:18) (cid:18) (cid:18) (cid:18) o l o l = - O y ) ( l u ) ( t P (cid:82) (cid:82) d ) ( s a ) ( l P ) ( l u Q ) ( t P ) ( s a x ) ( l P x ) ( s a ) ( a (cid:82) ) ( s a d ) ( a y ) ( l n f ) ( l g P ) ( l n f X (cid:82) ) ( l g P x ) ( s a ) ( l fi v (cid:82) . d ) ( s a ) ( u c ) ( s a d ) ( l fi v (cid:82) ) ( s a d ) ( u c X X (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) (cid:82) 1 τ + 2 τ + 3 τ + 4 τ + 5 τ + 6 τ + C.3 Mathematical Benefits of CAO Local Interpretability: Each axiom retains independent interpretability through its loss function, enabling targeted diagnostics for specific tradeoffs. Global Consistency: The synergy-based loss ensures that all axioms are optimized harmoniously, avoiding scenarios where one axiom dominates others. Pareto-Aware Control: By systematically varying ωa, CAO provides insights into trade-offs across objectives, ensuring efficient exploration of Pareto frontiers (Deb, 2001). Computational Scalability: Leveraging Sinkhorn regularization reduces the computational burden, making CAO applicable to large-scale T2I models. Key Hyperparameters, Optimization Strategies, and Architecture Choices This section provides details on the key hyperparameters, optimization strategies, and architectural configurations used in training T2I models with the DPO-CAO frameworks. D.1 Hyperparameters for Training Learning Rate: - For both DPO and DPO-CAO, we use an initial learning rate of 1 104, with cosine decay schedule (Loshchilov and Hutter, 2016) applied over the training epochs. - Separate learning rates are employed for the image encoder and text decoder to account for modality-specific training dynamics. Batch Size: - batch size of 256 is used for stable optimization, balancing memory requirements and gradient variance. - For larger datasets, gradient accumulation is employed to mimic an effective batch size of 1024. Mixing Parameter (αa): - The mixing parameter αa governs the trade-off between the two competing sub-objectives for each axiom a. For example, in Faithfulness to Prompt vs. Artistic Freedom, αa balances the semantic alignment loss (Lp) and the stylistic deviation loss (Lq): fa(I) = αaLp(I) + (1 αa)Lq(I), where αa [0, 1]. higher αa gives more importance to Lp (semantic alignment), while lower αa favors Lq (stylistic deviation). - Initially, αa is set to 0.5, assigning equal weights to both sub-objectives, ensuring no bias during the early stages of training: α(0) = 0.5. - As training progresses, αa is dynamically adjusted based on the relative magnitudes of Lp and Lq. For instance: If Lp Lq, indicating that semantic alignment is well-optimized while stylistic deviation is not, αa is decreased: α(t+1) = α(t) η Lq αa , where η is the learning rate for αa. Conversely, if Lq Lp, αa is increased to give higher priority to semantic alignment: α(t+1) = α(t) + η Lp αa . - This dynamic adjustment ensures that neither sub-objective is neglected, maintaining balanced optimization across the axiom. Weighting Coefficients (ωa): - The weighting coefficients ωa determine the relative importance of each axiom in the global synergy function. Initially, all axioms are assigned equal weights: ω(0) ="
        },
        {
            "title": "1\nA",
            "content": ", {1, 2, . . . , A}, where is the total number of axioms. - During training, ωa is fine-tuned based on validation metrics to prioritize certain axioms for specific applications. The global synergy function is defined as: S(I) = (cid:88) a=1 ωafa(I), where fa(I) is the axiom-specific loss. - Fine-tuning ωa is performed iteratively by monitoring the validation loss for each axiom: If validation metrics for axiom show underperformance (e.g., high loss), ωa is increased: - Specific tuning of τa depends on the complexity of the axiom: ω(t+1) = ω(t) + ηω fa ωa , where ηω is the learning rate for ωa. Conversely, if axiom is overemphasized, ωa is decreased: ω(t+1) = ω(t) ηω fa ωa . - This iterative adjustment ensures the global synergy function achieves balanced trade-offs across all axioms, catering to specific application requirements. Regularization Coefficients (τa): - Regularization coefficients τa are introduced to stabilize training and prevent overfitting, especially for high-dimensional sub-objectives. The overall loss function for each axiom is regularized as: For simpler objectives (e.g., Faithfulness to Prompt vs. Artistic Freedom), smaller τa values are used to avoid underfitting: τa = τmin, where τmin 1 104. For more complex objectives (e.g., Cultural Sensitivity vs. Artistic Freedom), larger τa values are applied to improve robustness: τa = τmax, where τmax 1 102. - This regularization framework ensures that: High-dimensional objectives are smoothed through Ra(I), reducing sensitivity to noisy gradients. The model maintains generalizability across all alignment axioms while optimizing specific alignment goals. La(I) = fa(I) + τaRa(I), D.2 Optimization Strategies where: fa(I) is the axiom-specific loss (e.g., weighted combination of sub-objectives such as Lp and Lq). Ra(I) is the regularization term (e.g., L2-norm, Wasserstein distance, or Sinkhorn divergence (Cuturi, 2013)). τa > 0 determines the influence of the regularization term on the total loss. - The regularization coefficients τa are initialized uniformly across all axioms: τ (0) = τinit, {1, 2, . . . , A}. - During training, τa is fine-tuned based on validation performance using hyperparameter sweeps. The updated τa is adjusted as: τ (t+1) = τ (t) ητ Lval τa , where: Lval is the validation loss observed for axiom a. ητ is the learning rate for τa. Optimizer: - We use the AdamW optimizer (Loshchilov and Hutter, 2017) with weight decay set to 1 102. Gradient Clipping: - To prevent exploding gradients, gradient clipping is applied with maximum norm of 1.0. Loss Scaling: - Loss scaling is applied to balance the contributions of local axiom-wise losses and the global synergy loss. The scaling factor λ is set to 0.7 based on validation performance. Pareto Front Exploration: - To identify optimal trade-offs, Pareto front exploration is conducted by varying synergy weights ωa in the range [0.1, 0.9]. - We use scalarization techniques (Deb, 2001) to ensure efficient exploration and selection of Pareto-optimal solutions. The Weight-Objective Heatmap (see Figure 15) is visual representation of how varying synergy weights (ωa) influences the alignment of Text-toImage (T2I) model across multiple axioms. Each row corresponds to specific synergy weight configuration (ωa), while each column represents an alignment axiom (e.g., Faithfulness to Prompt, Artistic Freedom). The values in each cell indicate the models objective score for specific optimization for T2I models. D.3 Architecture Choices Image Encoder: - pre-trained Vision Transformer (ViT-L/14) (Dosovitskiy et al., 2020) is used as the image encoder, fine-tuned during training for improved alignment with text prompts. Text Encoder: - The text encoder is based on pre-trained T5-Large (Raffel et al., 2020) model, leveraging its ability to capture nuanced semantics in natural language prompts. Synergy Aggregator: - The synergy function is implemented as fully connected network with three hidden layers, each containing 512 units and ReLU activation. - Dropout (Srivastava et al., 2014) with probability of 0.2 is applied to prevent overfitting. Loss Module: - Both local axiom-wise losses (Lp, Lq) and the global synergy loss (S(I)) are implemented with efficient Sinkhorn iterations for computational efficiency (Cuturi, 2013). D.4 Training Pipeline 1. Pre-train the T2I model using standard crossentropy loss on the training dataset to initialize the image and text encoders. 2. Fine-tune the model with the CAO objective: Use local axiom-wise losses (fa(I)) to ensure alignment for each axiom. Aggregate losses with the synergy function (S(I)) for global optimization. 3. Monitor alignment metrics (e.g., faithfulness scores, emotional impact) on validation set and adjust hyperparameters (e.g., αa, ωa) to ensure balanced performance. 4. Use early stopping based on the validation loss to prevent overfitting. D.5 Computational Resources Training is conducted on NVIDIA A100 GPUs with 40 GB memory. full training run (including hyperparameter tuning) requires approximately 72 hours. Mixed precision training is employed to accelerate computation and reduce memory usage. Figure 15: Weight-Objective Heatmap: Visualizing the impact of varying synergy weights (ωa) on alignment scores across multiple axioms. Each row corresponds to specific synergy weight, while each column represents an alignment axiom. Lighter colors indicate better alignment, while darker colors reveal areas for improvement. axiom under the corresponding weight configuration. Higher scores (lighter colors) represent better alignment with the axiom, while lower scores (darker colors) suggest areas needing improvement. The plot is constructed by evaluating the models performance across range of weights (ωa [0.1, 0.9]) for each axiom, with the scores obtained from validation metrics. To interpret the heatmap, examine the rows to identify synergy weight configurations that yield consistent high scores across multiple axioms, indicating balanced trade-offs. Conversely, columns reveal the sensitivity of individual axioms to changes in weights. For example, an axiom with varying scores across rows is more sensitive to weight adjustments, while consistently high scores in column suggest robustness to weight changes. The highlighted row (red border) indicates the synergy weight configuration that achieves the best overall balance, making it strong candidate for Pareto-optimal alignment. The heatmaps implication lies in its ability to guide optimization and model refinement. By visualizing trade-offs and sensitivities, it helps practitioners select weights that balance competing objectives, identify challenging axioms needing additional regularization, and prioritize configurations aligned with specific application needs. This tool provides an actionable framework for exploring Pareto-optimal solutions in multi-objective D.6 Key Observations Dynamic adjustment of αa and ωa significantly improves trade-offs between contradictory objectives. Regularization and gradient clipping stabilize the training process, especially in high-dimensional spaces. The synergy aggregator effectively balances local and global objectives, resulting in robust alignment across all six axioms."
        },
        {
            "title": "E Ablation Studies on Regularization",
            "content": "Coefficients (τa) and Combined Impact of Synergy Weights (ωa) and Regularization Coefficients (τa) This section presents detailed analysis of the impact of regularization coefficients (τa) and their interaction with synergy weights (ωa) on the alignment performance and optimization landscape of DPO-CAO. These parameters jointly influence alignment quality, stability, and computational efficiency. E.1 Regularization Coefficients (τa) The regularization coefficients control the influence of axiom-specific regularizers in the overall loss function. By varying τa, we evaluate its role in balancing alignment stability and performance. Experimental Setup. Baseline Configuration: All regularization coefficients are initialized to τa = 103. Perturbation: Individual coefficients (τa) are varied across logarithmic scale (104 to 101) while keeping others constant. Metrics Evaluated: Alignment Stability: Variance in alignment scores over epochs. Table 3: Impact of Regularization Coefficients (τa) on Alignment Stability. τa 104 103 10 Alignment Stability (Variance) High (0.15) Low (0.05) Medium (0.10) Results. Insights. Under-Regularization (τa = 104): Leads to unstable gradients and high variance in alignment scores. Optimal Regularization (τa = 103): Balances gradient stability and alignment performance. Over-Regularization (τa = 102): Excessive smoothing reduces alignment performance. E.2 Combined Impact of Synergy Weights (ωa) and Regularization Coefficients (τa) The interaction between ωa and τa is critical for achieving balanced alignment. Synergy weights prioritize specific axioms, while regularization coefficients stabilize optimization across competing objectives. Experimental Setup. Conduct grid searches across ωa (0.1, 1/6, 0.5) and τa (104, 103, 102). Metrics Evaluated: Alignment Trade-offs: Differences in primary and secondary objective scores. Table 4: Combined Impact of Synergy Weights (ωa) and Regularization Coefficients (τa) on Alignment Performance. ωa 1/6 0.5 0.1 1/6 1/6 τa 103 103 103 104 102 Trade-off Deviation 0.05 0.15 0.10 0.12 0. Results. Insights. Balanced Configuration (ωa = 1/6, τa = 103): Minimizes alignment trade-offs and demonstrates robust performance across all axioms. Skewed Synergy Weights (ωa = 0.5): Prioritizes specific objectives but increases trade-off deviations. Suboptimal Regularization (τa = 104 or τa = 102): Either destabilizes gradients or overly smooths the loss landscape, reducing overall efficiency. Conclusion: The synergy weights (ωa) and regularization coefficients (τa) play complementary roles in shaping the optimization landscape of DPO-CAO: Synergy Weights: Control the prioritization of axioms and influence alignment trade-offs. Regularization Coefficients: Stabilize gradients and ensure consistent updates. Balanced configurations (ωa = 1/6, τa = 103) consistently achieve the best trade-offs. Future work could explore adaptive mechanisms to dynamically adjust these parameters for improved scalability and alignment quality."
        },
        {
            "title": "F Gradient Calculation of CAO",
            "content": "The DPO-CAO loss function consists of three components: Local Axiom Preferences, Global Synergy Preference, and Axiom-Specific Regularizers. The gradient for each component is derived as follows: F.1 Local Axiom Preferences The local alignment loss for each axiom is given by: Define zi = (cid:80) The gradient with respect to zi is: ωafa(Ii) and zj = (cid:80) ωafa(Ij). LGlobal zi = λ (cid:18) (cid:88) (i,j)PS exp(zi) exp(zi) + exp(zj) (cid:19) 1 . Using zi = (cid:80) to fa(Ii) becomes: ωafa(Ii), the gradient with respect LGlobal fa(Ii) = λωa (cid:18) (cid:88) (i,j)PS exp(zi) exp(zi) + exp(zj) (cid:19) 1 . Finally, the gradient with respect to θ is: LGlobal θ (cid:88) = LGlobal fa(I) fa(I; θ) θ . F.3 Axiom-Specific Regularizers The regularizer for axiom is: Ra = (cid:82) (cid:82) yPa(x)Qa(y) dx dy Pa(x) dx (cid:82) (cid:82) Qa(y) dy . The gradient with respect to Pa(x) is derived using the quotient rule: LLocal = (cid:88) (cid:18) log (i,j)Pa exp(fa(Ii)) exp(fa(Ii)) + exp(fa(Ij)) (cid:19) , Ra Pa(x) = yQa(y) Pa(x) dx (cid:82) (cid:82) Qa(y) dy Ra Pa(x) dx . (cid:82) where fa(I) is the models output for axiom a. The gradient with respect to fa(Ii) is: LLocal fa(Ii) = (cid:18) (cid:88) (i,j)Pa exp(fa(Ii)) exp(fa(Ii)) + exp(fa(Ij)) (cid:19) 1 . For fa(Ij), the gradient is: LLocal fa(Ij) = (cid:88) (i,j)Pa exp(fa(Ij)) exp(fa(Ii)) + exp(fa(Ij)) . Finally, the gradient with respect to the model parameters θ is: LLocal θ (cid:88) = LLocal fa(I) fa(I; θ) θ . F.2 Global Synergy Preference The global synergy loss aggregates the axiomspecific preferences: LGlobal = λ (cid:88) (cid:18) log (i,j)PS exp ((cid:80) ωafa(Ii)) ωafa(Ii)) + exp ((cid:80) exp ((cid:80) ωafa(Ij)) (cid:19) . The total gradient with respect to θ is: LRegularization θ (cid:88) = τa Ra Pa(x) Pa(x; θ) θ . F.4 Final Gradient Combining all components, the total gradient is: LDPO-CAO θ = LLocal θ + LGlobal θ + LRegularization θ . This gradient is used to update the model parameters during training, ensuring alignment with the specified axioms and global synergy preferences."
        },
        {
            "title": "G Details on the Synergy Jacobian JS",
            "content": "The synergy Jacobian JS plays pivotal role in the CAO framework by regulating the interactions among gradients of axiom-specific losses. This mechanism ensures that updates to one axioms parameters do not excessively disrupt the optimization of others, fostering balanced alignment process. G.1 Definition and Mathematical Formulation Trade-off Control: Balancing competing objectives by regularizing the Frobenius norm of JS: The synergy Jacobian is defined as the matrix of partial derivatives of the synergy aggregator S(I) with respect to the model parameters θ: JS = (cid:104) θ1 θ2 (cid:105) = θp f1 θ1 f1 θ2 ... f1 θp f2 θ1 f2 θ ... f2 θp . . . , fA θ1 fA θ2 ... fA θp where: fa(I) is the axiom-specific loss for axiom a. is the total number of axioms. θ = {θ1, θ2, . . . , θp} are the model parameters. Rjacobian = λjacJS I2 , where is the identity matrix, and λjac controls the regularization strength. G.4 Numerical Stability and Implementation To ensure numerical stability during computation: Gradient Clipping: Limit the maximum magnitude of individual entries in JS to prevent exploding gradients. Efficient Backpropagation: Use automatic differentiation frameworks to compute JS efficiently without explicitly storing the entire matrix. This matrix captures how changes to model parameters θ affect the combined synergy score S(I), which aggregates all axiom-specific losses. Sparse Approximations: In high-dimensional models, approximate JS using block-diagonal structures to reduce computational overhead. G.2 Role in Gradient Interaction and"
        },
        {
            "title": "Balancing",
            "content": "During training, the synergy Jacobian provides mechanism for tempering gradient updates: θ = η JS S, where: η is the learning rate. = (cid:80)A a=1 ωafa is the weighted sum of axiom-specific gradients. JS modulates the step size and direction of θ, preventing dominance by any single axiom. G.3 Regulating Gradient Conflicts Gradient conflicts arise when updates for one axiom-specific loss degrade the performance of others. The synergy Jacobian resolves these conflicts by: G.5 Key Insights and Implications The synergy Jacobian JS provides the following benefits: Improved Convergence: By moderating gradient conflicts, it stabilizes training and accelerates convergence. Balanced Alignment: Ensures that no single axiom-specific objective dominates the optimization process. Generalizability: Encourages parameter updates that benefit multiple objectives simultaneously, leading to better generalization across diverse tasks. G.6 Future Directions While the synergy Jacobian has demonstrated its effectiveness in CAO, potential areas for further research include: Gradient Scaling: Adjusting the magnitude of conflicting gradients based on the entries in JS. Conflict Minimization: Encouraging updates that align gradients across axioms by minimizing the off-diagonal terms in JS, which represent inter-axiom interactions. Dynamic Weighting Mechanisms: Incorporate adaptive strategies for weighting axiom-specific gradients based on their contributions to S(I). Low-Rank Approximations: Explore low-rank factorization techniques to make JS computation feasible for large-scale models. Why Wasserstein Distance and Sinkhorn Regularization? The choice of Wasserstein Distance (Arjovsky et al., 2017) and Sinkhorn Regularization (Cuturi, 2013) in the alignment framework is motivated by their mathematical robustness, practical scalability, and suitability for high-dimensional tasks like Text-to-Image (T2I) generation. This section elaborates on the advantages of these techniques in the context of aligning generated images with user prompts. H.1 Advantages of Wasserstein Distance into differentiable optimization problem, significantly reducing computational cost from O(n3) to O(n2 log n) for data points. Smoothness: Sinkhorn Regularization ensures smoothness in the loss surface, leading to more stable gradients and improved convergence during training. Scalability: The approximate computation enabled by Sinkhorn Regularization allows alignment optimization at scale, making it suitable for real-world T2I applications with large datasets. The Wasserstein Distance, also known as the Earth Movers Distance (EMD), is measure of the cost required to transform one probability distribution into another. Its key advantages include: Numerical Stability: By adding entropy to the transport problem, Sinkhorn Regularization mitigates numerical instabilities caused by small values or noise in probability distributions. Semantic Alignment: Wasserstein Distance considers the underlying geometry of distributions, making it well-suited for tasks where latent spaces capture semantic relationships between prompts and images. Flexibility: The regularization coefficient λ provides tunable parameter, allowing the trade-off between exact Wasserstein Distance and entropyregularized divergence. This flexibility accommodates tasks of varying complexity. Handling Disjoint Supports: Unlike divergencebased metrics (e.g., KL divergence), Wasserstein Distance remains well-defined when distributions have disjoint supports. This property is particularly useful in early training stages of T2I systems, where generated distributions may not overlap with target distributions. Gradient Robustness: Wasserstein Distance provides meaningful gradients even for distributions with minimal overlap, avoiding gradient vanishing issues that occur with some other metrics. Interpretability: The metrics interpretation as the minimal cost of transforming one distribution into another aligns with intuitive notions of alignment and quality in T2I systems. H.2 Advantages of Sinkhorn Regularization While Wasserstein Distance offers significant benefits, its computation can be expensive for highdimensional data. The Sinkhorn Regularization modifies the computation of Wasserstein Distance by introducing an entropic term, resulting in several practical benefits: Computational Efficiency: The entropic regularization reformulates the Wasserstein computation H.3 Combined Benefits for T2I Systems The synergy of Wasserstein Distance and Sinkhorn Regularization offers the following combined benefits for T2I alignment: Nuanced Semantic Alignment: Wasserstein Distance captures subtle semantic relationships between textual prompts and generated images, ensuring high-quality alignment. Efficient and Scalable Optimization: Sinkhorn Regularization enables the use of Wassersteinbased metrics in large-scale training, overcoming the computational bottlenecks of exact Wasserstein computation. Robustness to Variability: The combined approach handles variability and noise in generated images without compromising alignment quality, making it ideal for multi-axiom optimization frameworks like CAO. H.4 Applications and Future Directions Wasserstein Distance with Sinkhorn Regularization has shown significant promise in T2I alignment, and future research could explore: Dynamic Regularization: Adaptive tuning of the Sinkhorn regularization coefficient λ during training to balance computational efficiency with alignment accuracy. I.2 Interpretation of the Error Surfaces Vanilla DPO: The smooth surface demonstrates simpler optimization landscape, suitable for single-objective alignment tasks. Multimodal Extensions: Extending the framework to jointly optimize text, image, and audio embeddings using Wasserstein-based metrics. Task-Specific Optimizations: Developing tailored variants of Wasserstein Distance for specific domains, such as cultural sensitivity or emotional impact."
        },
        {
            "title": "I Comparative Error Surface Analysis",
            "content": "for DPO and CAO In this section, we present detailed analysis of the error surfaces for Vanilla DPO and CAO to illustrate the impact of introducing axiom-specific losses and synergy terms in the optimization process. I.1 Error Surface Visualization The plots in Figure 16 showcase the error surfaces of DPO and CAO, modeled using synthetic data. These surfaces provide an intuitive understanding of the optimization landscapes. Vanilla DPO (Left Plot): The error surface is smooth and convex, reflecting the simplicity of the optimization objective. It represents single loss function consisting of the contrastive loss and regularization term (e.g., KL divergence). This smoothness facilitates faster convergence, as the gradients are consistent and straightforward to follow. DPO-CAO (Right Plot): DPO-CAO: The oscillatory nature illustrates the challenges of multi-objective optimization. These oscillations: Indicate regions where specific axioms dominate or interact strongly with others. Highlight the need for careful tuning of synergy weights (ωa) and regularization coefficients (τa). I.3 Implications Optimization Complexity: The increased oscillations in DPO-CAO suggest higher computational overhead, as gradient steps must navigate more complex regions. Alignment Trade-offs: The peaks and valleys provide insights into how competing objectives can influence model behavior, requiring systematic exploration of Pareto-optimal solutions. Guidance for Future Research: The visualization motivates the need for lightweight synergy models or adaptive axiom prioritization to reduce computational overhead while maintaining alignment quality. This comparative analysis demonstrates the trade-offs and challenges inherent in transitioning from single-objective to multi-objective optimization frameworks like DPO-CAO. Future research should explore methods to balance complexity with practical efficiency. The error surface is characterized by oscillatory patterns, introduced by axiom-specific losses and the global synergy term. These peaks and valleys highlight the trade-offs between contradictory alignment objectives, such as Faithfulness to Prompt vs. Artistic Freedom or Emotional Impact vs. Neutrality. The oscillations also reflect the interactions between local axiom preferences and the synergy aggregator, making the optimization process more complex."
        },
        {
            "title": "J Complexity Analysis and",
            "content": "Computational Overhead of DPO-CAO The CAO loss function introduces significant computational overhead compared to vanilla DPO due to the integration of multiple objectives (axioms), synergy weights, and axiom-specific regularization terms. While DPO-CAO optimizes six contradictory alignments simultaneously, practical use cases may only require focusing on one or two axioms. Below, we analyze the computational complexity of each component. Figure 16: Error Surfaces for Vanilla DPO (Left) and CAO (Right). The smooth surface of DPO contrasts with the oscillatory patterns in CAO, reflecting the increased complexity due to multi-objective optimization. J.1 Components of DPO-CAO The DPO-CAO loss function is composed of three main components: J.1.3 Axiom-Specific Regularizers The regularizer for each axiom stabilizes optimization: LDPO-CAO = LLocal + LGlobal + 6 (cid:88) a=1 τa Ra J.1.1 Local Alignment Loss The local alignment loss for each axiom is defined as: LLocal = 6 (cid:88) (cid:88) (cid:18) log a=1 (i,j)Pa exp(fa(Ii)) exp(fa(Ii)) + exp(fa(Ij)) (cid:19) where Pa represents the set of pairwise comparisons for axiom a. Complexity: For samples and = 6 axioms, the complexity is: Ra = (cid:90) (cid:90) x yPa(x)Qa(y) dx dy where Pa(x) and Qa(y) are distributions for axiom a. Complexity: Computing pairwise distances between samples in d-dimensional feature space has complexity of: O(n2 d) J.2 Total Complexity The total computational complexity for CAO is the sum of the complexities for local alignment, global synergy, and regularization: O(m Pa) = O(m n2) O(m n2) + O(n2 m) + O(n2 m) = O(n2 (1 + d)) J.1.2 Global Synergy Loss The global synergy loss ensures consistency across multiple axioms: where is the number of samples, = 6 is the number of axioms, and is the feature dimensionality. LGlobal = λ log (cid:88) (i,j)PS (cid:16)(cid:80)6 exp (cid:17) a=1 ωafa(Ii) (cid:16)(cid:80)6 (cid:17) + exp exp (cid:16)(cid:80)6 a=1 ωafa(Ii) (cid:17) a=1 ωafa(Ij) where ωa is the synergy weight for axiom a. Complexity: For samples and = 6 axioms: O(PSm) = O(n2 m) J.3 Comparison with Vanilla DPO"
        },
        {
            "title": "Synergy Overhead",
            "content": "The global synergy term in CAO introduces significant computational overhead due to its reliance on weighted aggregations across multiple axioms and Table 5: Comparison of Computational Complexity Between Vanilla DPO and CAO. Group Sparsity: Suppress all weights associated with certain axioms or groups of axioms: Vanilla DPO O(n2) Aspect Pairwise Comparisons Regularization O(n d) Synergy Weights Total Complexity Not Applicable O(n2) DPO-CAO O(n2 m) O(n2 m) O(n2 m) O(n2 (1 + d)) pairwise comparisons. While we have not empirically tested the following strategies, they provide theoretical avenues to reduce this overhead. These approaches could be explored in future research to make CAO more scalable and efficient. K.1 Simplified Synergy Functions One possible extension is to replace the current weighted summation of axiom-specific scores: fsynergy(I) = (cid:88) a=1 ωafa(I) with simpler aggregation functions: Max Aggregation: Use the maximum score among all axioms: fsynergy(I) = max fa(I). Mean Aggregation: Compute the average score across axioms: fsynergy(I) = 1 (cid:88) a=1 fa(I). These simplifications eliminate the need for weighted combinations and reduce the computational complexity from O(m) to O(1) per sample. K.2 Sparse Synergy Weights Instead of assigning non-zero weights ωa to all axioms, enforcing sparsity could reduce computational overhead. This can be achieved through: L1-Regularization: Apply regularization to drive some weights to zero: Lregularization = λ (cid:88) a=1 ωa. Lregularization = λ!group2. Sparse weights focus computation on high-impact axioms, reducing unnecessary overhead. K.3 Precomputed Synergy Scores Synergy scores can be precomputed for groups of similar samples to avoid redundant calculations during training: Clustering-Based Precomputation: Cluster samples in feature space and compute single synergy score for each cluster representative. Embedding-Based Approximation: Use lightweight neural network to predict synergy scores: fsynergy(I) = NN(I). These techniques shift computation from runtime to preprocessing, improving efficiency. K.4 Adaptive Axiom Selection Instead of using all axioms for synergy computation, adaptive strategies can dynamically select the most relevant ones: Dynamic Weight Adjustment: Adjust ωa during training based on gradient magnitudes: ωa fa(I) . Task-Specific Reduction: Predefine subset of axioms relevant to specific tasks, eliminating unnecessary terms. K.5 Approximation Techniques for Synergy"
        },
        {
            "title": "Weights",
            "content": "Approximation methods can reduce the cost of computing synergy weights: Low-Rank Approximation: Decompose the weight matrix ! into low-rank components: ! UVT . Probabilistic Sampling: Randomly sample subset of axioms for each iteration: fsynergy(I) = (cid:88) ωafa(I). asampled K.6 Neural Approximations for Synergy small neural network could replace the explicit computation of synergy scores: fsynergy(I) = NN(f1(I), f2(I), . . . , fm(I)). This approach reduces computational redundancy by sharing representations across axioms. K.7 Future Exploration The above strategies represent theoretical extensions to reduce the computational overhead of the global synergy term in DPO-CAO. While these methods have not been empirically tested, they hold promise for improving the scalability and efficiency of the framework. We aim to explore some or all of these approaches in future research to validate their effectiveness. Details on Axiom-Specific Loss"
        },
        {
            "title": "Function Design",
            "content": "Designing loss functions for each alignment axiom is critical component of the CAO framework. Each axiom-specific loss is tailored to capture the nuanced trade-offs inherent in T2I generation tasks, such as balancing creative freedom with prompt fidelity or maintaining cultural sensitivity without compromising artistic expression. This section provides detailed mathematical formulations, practical insights, and design considerations for each loss function, ensuring that they align with the broader goals of the CAO framework. By leveraging state-of-the-art models, robust metrics, and adaptive weighting strategies, these loss functions offer modular and extensible foundation for multi-axiom alignment. The following subsections delve into the specifics of each loss function, highlighting their role in addressing the challenges posed by their corresponding axioms. L.1 Artistic Freedom: Lartistic The Artistic Freedom Loss (Lartistic) quantifies the creative enhancements applied to generated image Igen relative to baseline image Ibase. It integrates three core components: Style Difference, Content Abstraction, and Content Difference, each addressing distinct aspects of artistic freedom. 1. Style Difference L.1.1 The Style Difference term measures stylistic deviation between Igen and Ibase. Using VGG-based Gram features (Gatys et al., 2016; Johnson et al., 2016), it is defined as: StyleDiff = S(Igen) S(Ibase)2 2, where S() represents the Gram matrix of feature maps extracted from pre-trained style network. Gram Matrix: Given feature maps RCHW , where is the number of channels, and H, are the spatial dimensions, the Gram matrix RCC is: Gij = (cid:88) FikFjk. The style loss is computed as: StyleDiff = (cid:88) Gl(Igen) Gl(Ibase)2 , where indexes the layers, and denotes the Frobenius norm. 2. Content Abstraction L.1.2 Content Abstraction evaluates how abstractly Igen interprets the textual prompt . It is computed as: ContentAbs = 1 cos(E(P ), E(Igen)), where E() is multimodal embedding model such as CLIP (Radford et al., 2021). The cosine similarity measures alignment between and Igen, with higher ContentAbs values indicating greater abstraction. 3. Content Difference L.1.3 Content Difference ensures fidelity to Ibase, defined as: ContentDiff = 1 cos(E(Igen), E(Ibase)). This term acts as mild regularizer, balancing creative freedom with adherence to the baseline. L.1.4 Composite Loss Function The overall Artistic Freedom Loss combines these components: Lartistic = α StyleDiff + β ContentAbs + γ ContentDiff, where α, β, γ are tunable hyperparameters. By default, α = 0.5, β = 0.3, and γ = 0.2. L.1.5 Gradient Analysis The gradients of Lartistic guide optimization: L.2.1 Mathematical Formulation The Faithfulness Loss is defined as: Gradient of StyleDiff: Lfaith = λ (P (Zprompt), Q(Zimage)), StyleDiff Igen (cid:88) = Gl(Igen) Gl(Ibase)2 Igen . where: Gradient of ContentAbs: ContentAbs Igen = Igen E(P ), E(Igen) E(P )E(Igen) . Gradient of ContentDiff: ContentDiff Igen = Igen E(Igen), E(Ibase) E(Igen)E(Ibase) . L.1.6 Theoretical Properties (Zprompt) is the latent distribution of the textual prompt extracted using Variational Autoencoder (VAE). Q(Zimage) is the latent distribution of the generated image obtained from the same VAE. λ represents the Sinkhorn-regularized Wasserstein Distance, defined as: λ (P, Q) = min πΠ(P,Q) (cid:90) x yd π(x, y) dx dy + λ R(π), Convexity: Each component is non-negative, ensuring bounded loss. where: Flexibility: The weights α, β, γ enable taskspecific tuning. Π(P, Q) is the set of all joint probability distributions with marginals and Q. yd is the cost function measuring the disInterpretability: Each term directly corresponds tance between latent points and y. to an intuitive notion of artistic freedom. R(π) is the Sinkhorn regularizer: L.1.7 Future Directions To enhance Lartistic, future work could: Explore adaptive weighting schemes for α, β, γ. Integrate domain-specific style features to better capture artistic nuances. (cid:90) R(π) = π(x, y) log(π(x, y)) dx dy, which ensures smooth and computationally efficient optimization (Cuturi, 2013). L.2.2 Latent Representations Validate the loss function across diverse artistic domains such as abstract art, photography, and conceptual design. The latent distributions (Zprompt) and Q(Zimage) are modeled using shared Variational Autoencoder (VAE): L.2 Faithfulness to Prompt: Lfaith Faithfulness to the prompt is cornerstone of T2I alignment, ensuring that the generated image adheres to the semantic and visual details specified by the user. To evaluate faithfulness, we leverage semantic alignment metric based on the SinkhornVAE Wasserstein Distance, robust measure of distributional similarity that has gained traction in generative modeling for its interpretability and computational efficiency (Arjovsky et al., 2017; Tolstikhin et al., 2018). Zprompt, Zimage (µ, σ2), where: µ and σ2 are the mean and variance of the respective latent embeddings, learned through the encoder. The shared latent space ensures compatibility between textual and visual representations, aligning semantic content across modalities. L.2.3 Properties of Faithfulness Loss Semantic Depth: By aligning latent distributions, the loss captures nuanced semantic relationships between the prompt and the generated image, beyond simple token matching. Robustness: The Sinkhorn regularizer (λ R(π)) ensures smooth optimization and accommodates minor creative deviations without heavily penalizing them. Scalability: The Sinkhorn-regularized Wasserstein Distance is computationally efficient, making it suitable for large-scale applications. L.2.4 Gradient Analysis The gradient of Lfaith with respect to the generated image Igen is computed as: λ (P (Zprompt), Q(Zimage)) Q(Zimage) Igen . Lfaith Igen = Q(Zimage) Breaking this down: λ Q(Zimage) computes the gradient of the Wasserstein Distance with respect to the latent distribution. Q(Zimage) Igen propagates the gradient from the latent space back to the pixel space."
        },
        {
            "title": "Implementation Details",
            "content": "L.2.5 To compute Lfaith in practice: Use pretrained VAE to encode both the prompt and image into shared latent space. Employ Sinkhorn iterations to efficiently optimize the Wasserstein Distance, following the algorithm proposed in (Cuturi, 2013). Set λ empirically to balance computational cost and alignment accuracy. Typical values range from 0.01 to 0.1. L.2.6 Future Directions Potential extensions to Lfaith include: Incorporating multimodal transformers to jointly encode text and image embeddings for better semantic alignment. Exploring alternative regularizers (e.g., entropic or gradient regularization) for improved robustness. Testing the loss on diverse datasets, including abstract or ambiguous prompts, to evaluate generalization. L.3 Emotional Impact Score (EIS): Lemotion The Emotional Impact Score (EIS) quantifies the emotional intensity conveyed by generated images. It measures the strength and dominance of emotions such as happiness, sadness, anger, or fear, ensuring that T2I models can evoke the intended emotional response based on user prompts. This metric is particularly important for domains like marketing, storytelling, or psychological studies where emotional resonance plays key role. L.3.1 Mathematical Definition of EIS EIS is computed as the average emotional intensity across batch of generated images: EIS = 1 (cid:88) i=1 where: EmotionIntensity(imgi), : Total number of images in the batch. EmotionIntensity(imgi): The scalar intensity of the dominant emotion in the image imgi, computed using pretrained emotion detection models (e.g., DeepEmotion (Abidin and Shaarani, 2018)). Emotion Detection Models: Pretrained emotion detection models, such as DeepEmotion, rely on convolutional neural networks trained on datasets labeled with basic emotions (e.g., happiness, sadness, anger, fear). The emotion intensity score is normalized to range between 0 and 1, where 1 indicates maximum emotional intensity. L.3.2 Neutrality Score (N) While EIS captures the strength of the dominant emotion, the Neutrality Score (N) quantifies the absence of emotional dominance, representing emotional balance or impartiality. This metric is useful in cases where emotionally neutral outputs are desired, such as in educational or scientific content. = 1 max(EmotionIntensity), where: max(EmotionIntensity): The intensity of the most dominant emotion detected in the image. Interpretation of Neutrality Score: 1: The image is emotionally neutral, with no strongly dominant emotion. 0: The image strongly reflects specific emotion, indicating high emotional dominance. L.3.3 Combined Metric: Tradeoff Between Emotional Impact and Neutrality To evaluate the tradeoff between Emotional Impact and Neutrality, combined metric, TEMN, is defined as: TEMN = α EIS + β N, where: α: Weight assigned to Emotional Impact. β: Weight assigned to Neutrality. α + β = 1: Ensures balanced contribution of both terms, with default values α = 0.3 and β = 0.7, chosen empirically. Interpretation of TEMN: Higher TEMN values indicate images that either evoke strong emotional responses or maintain emotional neutrality, depending on the weights α and β. Adjusting α and β allows for task-specific prioritization, such as favoring emotional impact (α > β) or neutrality (β > α). L.3.4 Gradient Analysis The gradients of Lemotion are essential for optimizing Emotional Impact in T2I systems. For single image imgi, the gradient with respect to the generated image is: EmotionIntensity(imgi) imgi computed using backpropagation through the pretrained emotion detection model. Similarly, for Neutrality Score , the gradient is: , = imgi max(EmotionIntensity) imgi L.3.5 Implementation Details To compute EIS and TEMN in practice: L.3.6 Future Directions To enhance Emotional Impact and Neutrality evaluation, future research could explore: Multimodal Emotion Models: Integrate multimodal models that jointly analyze textual prompts and visual outputs to better align emotional tones. Context-Aware Neutrality: Develop contextaware neutrality metrics to differentiate between intended neutrality (e.g., instructional content) and unintended neutrality (e.g., lack of emotion due to poor generation). Fine-Grained Emotions: Extend emotion detection to capture fine-grained emotions (e.g., nostalgia, hope) for more nuanced evaluations. L.4 Originality vs. Referentiality: Loriginality & Lreferentiality To evaluate the trade-off between originality and referentiality in generated image Igen, we propose framework leveraging pretrained CLIP models for dynamic reference retrieval and stylistic analysis. The originality metric (Loriginality) quantifies divergence from reference styles, while the referentiality metric (Lreferentiality) measures adherence to stylistic norms. L.4.1 Mathematical Definition The combined loss function is expressed as: foriginality_referentiality(Igen) = 1 K (cid:88) k=1 (cid:105) (cid:104) , 1 cos(ECLIP(Igen), ECLIP(Sretr,k)) where: ECLIP(): Embedding function of the pretrained CLIP model, mapping images to joint visualtextual embedding space (Radford et al., 2021). . Sretr,k: The k-th reference image retrieved from curated database using CLIP Retrieval (Carlier et al., 2023). Use pretrained emotion detection models like DeepEmotion (Abidin and Shaarani, 2018) or similar models fine-tuned for specific emotion datasets. K: Number of top-matching reference images. Decomposition of Loss Terms The loss can be separated into two components: Originality Loss: Normalize emotion intensity values to ensure consistent scaling across different images and batches. Loriginality = 1 (cid:88) [1 cos(ECLIP(Igen), ECLIP(Sretr,k))], k=1 Tune α and β based on application requirements, such as creative tasks (α > β) or neutral designs (β > α). which quantifies the stylistic divergence from reference images. Higher values indicate more originality. Referentiality Loss: L.4.4 Trade-off Between Originality and Lreferentiality = 1 (cid:88) k=1 cos(ECLIP(Igen), ECLIP(Sretr,k)), which evaluates adherence to stylistic norms. Higher values reflect stronger referential alignment. L.4.2 Reference Image Retrieval with CLIP Dynamic reference selection is crucial step in evaluating originality and referentiality. The retrieval process involves the following steps: 1. Embedding Computation: Compute the CLIP embedding of the generated image: ECLIP(Igen) Rd, where is the dimensionality of the CLIP embedding space. 2. Database Query: Compare ECLIP(Igen) against precomputed embeddings of reference images in database. The similarity metric is cosine similarity: Sim(Igen, Sretr,k) = cos(ECLIP(Igen), ECLIP(Sretr,k)). 3. Top-K Selection: Retrieve the top-K reference images with the highest similarity scores: Referentiality The inherent trade-off between originality and referentiality can be controlled by weighting their contributions. We define combined metric: TOR = α Loriginality + β Lreferentiality, where: α, β: Weights controlling the emphasis on originality (α) versus referentiality (β). α + β = 1: Ensures balanced contributions. Default values: α = 0.6, β = 0.4, prioritizing originality for most creative tasks. L.4.5 Gradient Analysis The gradients of TOR with respect to Igen guide optimization: TOR Igen = α Loriginality Igen + β Lreferentiality Igen . For each component: Gradient of Loriginality: Loriginality Igen = 1 (cid:88) k= cos(ECLIP(Igen), ECLIP(Sretr,k)) Igen . Sretr,k = arg max SDatabase Sim(Igen, S). L.4.3 Reference Databases Gradient of Lreferentiality: Lreferentiality Igen = 1 (cid:88) k= cos(ECLIP(Igen), ECLIP(Sretr,k)) Igen . We leverage large-scale artistic datasets to ensure diverse and meaningful reference styles: L.4.6 Future Directions WikiArt: dataset containing over 81,000 images across 27 art styles, including impressionism, surrealism, cubism, and more (Saleh and Elgammal, 2015). BAM (Behance Artistic Media): large-scale dataset of over 2.5 million high-resolution images curated from professional portfolios, encompassing diverse artistic styles (Wilber et al., 2017). To improve the evaluation of originality and referentiality, future work could explore: Dynamic Weighting: Develop adaptive mechanisms to adjust α and β based on user-defined objectives. Fine-Grained Styles: Incorporate additional style-specific metrics to evaluate subcategories (e.g., brushstroke style, color palette). These datasets provide the stylistic variety necessary for evaluating originality and referentiality comprehensively. Diverse Databases: Expand the reference databases to include non-traditional and contemporary art styles for broader applicability. L.5 Cultural Sensitivity: Lcultural Evaluating cultural sensitivity in T2I systems presents unique challenges due to the vast diversity of cultural contexts and the lack of standardized pre-trained cultural classifiers. To address this, we propose novel metric called Simulated Cultural Context Matching (SCCM), which dynamically generates culturally specific sub-prompts using Large Language Models (LLMs) and evaluates their alignment with T2I-generated images. This approach provides flexible and extensible framework for cultural evaluation. L.5.1 Mathematical Formulation of SCCM The SCCM score evaluates the alignment between the generated image and set of dynamically generated cultural sub-prompts. The metric comprises the following steps: SCCMmin and SCCMmax are predefined minimum and maximum similarity scores based on validation dataset of culturally diverse images and prompts. Normalization ensures that scores are comparable across different datasets and cultural contexts. L.5.2 Example Computation of SCCM User Prompt: Generate an image of Japanese garden during spring. Step 1: Sub-Prompt Generation Using an LLM, generate culturally specific sub-prompts: P1: traditional Japanese garden with koi pond and wooden bridge. P2: Cherry blossoms blooming in spring with traditional Japanese stone lanterns. 1. Embedding Generation P3: Zen rock garden with raked gravel pat1. Prompt Embedding: For each LLM-generated cultural sub-prompt Pi, compute embeddings using multimodal model (e.g., CLIP): terns. Step 2: Embedding and Similarity Calculation Compute cosine similarities: {E(P1), E(P2), . . . , E(Pk)}, sim(E(P1), E(Igen)) = 0.85, sim(E(P2), E(Igen)) = 0.80, sim(E(P3), E(Igen)) = 0.75. where is the total number of sub-prompts. 2. Image Embedding: Embed the T2I-generated image Igen using the same model: E(Igen). 2. Prompt-Image Similarity Calculate the semantic similarity between each sub-prompt Pi and the generated image Igen using cosine similarity: sim(E(Pi), E(Igen)) = E(Pi) E(Igen) E(Pi)E(Igen) . 3. Sub-Prompt Aggregation Aggregate the similarity scores across all sub-prompts to compute the raw SCCM score: SCCMraw = 1 (cid:88) i=1 4. Normalization Normalize SCCMraw to the range [0, 1] for consistent evaluation: SCCMfinal = SCCMraw SCCMmin SCCMmax SCCMmin . Here: Step 3: Raw Aggregated Score Aggregate the similarity scores: SCCMraw = 0.85 + 0.80 + 0.75 3 = 0.80. Step 4: Final Normalized Score Normalize using SCCMmin = 0.70 and SCCMmax = 0.90: SCCMfinal = 0.80 0.70 0.90 0.70 = 0.50. L.5.3 Gradient Analysis The gradients of the Cultural Sensitivity Loss Lcultural guide optimization by adjusting the generated image Igen to better align with culturally sensitive contexts. The loss is defined as: Lcultural = 1 SCCMfinal. Igen is: Lcultural Igen = SCCMfinal Igen . Breaking this down: SCCMfinal Igen = 1 k(SCCMmax SCCMmin) (cid:88) i=1 sim(E(Pi), E(Igen)) Igen . sim(E(Pi), E(Igen))."
        },
        {
            "title": "The gradient with respect to the generated image",
            "content": "For each sub-prompt Pi, the gradient of the cosine similarity is: sim(E(Pi), E(Igen)) Igen = 1 E(Pi)E(Igen) (cid:0)E(Pi) sim(E(Pi), E(Igen)) E(Igen)(cid:1) E(Igen) Igen . Key components: E(Igen) Igen embedding model. : Gradient propagation through the CLIP L.6.2 Workflow for Computing Lverifiability Step 1: Image Retrieval The generated image Igen is submitted to Google Image Search using its embedding or pixel data as query. The search retrieves visually and semantically similar images: {Isearch,1, Isearch,2, . . . , Isearch,K}. sim(E(Pi), E(Igen)): Ensures semantic alignment between the image and the cultural subprompts. Step 2: Embedding Extraction Using pretrained embedding model E() (e.g., DINO ViT), compute embeddings for: L.5.4 Challenges and Future Directions While SCCM offers novel approach to evaluating cultural sensitivity, there are limitations and opportunities for improvement: Cultural Nuance Representation: For some nuanced cases generating sub-prompts that accurately reflect nuanced cultural elements requires further fine-tuning of LLMs. L.6 Verifiability Loss: Lverifiability The verifiability loss quantifies the alignment of generated image Igen with real-world references by comparing it to the top-K images retrieved from Google Image Search. This ensures that the generated content maintains authenticity, factual consistency, and visual realism by leveraging external real-world data. L.6.1 Mathematical Formulation The verifiability loss is computed as: The generated image E(Igen). Each retrieved reference image E(Isearch,k), for = 1, 2, . . . , K. Step 3: Similarity Calculation Calculate cosine similarity for each retrieved image: simk = cos (cid:16) E(Igen), E(Isearch,k) (cid:17) , {1, . . . , K}. Step 4: Averaging and Loss Computation Aggregate the similarity scores across all retrieved images to compute the verifiability loss: Lverifiability ="
        },
        {
            "title": "1\nK",
            "content": "K (cid:88) k=1 simk. L.6.3 Gradient Analysis The gradient of Lverifiability with respect to the generated image Igen guides optimization toward better alignment with real-world references. The gradient is computed as: E(Igen), E(Isearch,k) (cid:17) Lverifiability Igen = 1 (cid:88) k=1 , (cid:16) cos E(Igen), E(Isearch,k) Igen (cid:17) . Lverifiability = 1 1 (cid:88) k=1 (cid:16) cos where: Igen: The generated image. Isearch,k: The k-th image retrieved from Google Image Search. E(): pretrained embedding extraction model (e.g., DINO ViT (?)) that captures semantic and visual features. K: The number of top-retrieved images used for comparison. Here, cos(, ) represents cosine similarity, defined as: (cid:16) cos E(Igen), E(Isearch,k) (cid:17) = E(Igen) E(Isearch,k) E(Igen)E(Isearch,k) . Breaking down the cosine similarity gradient: (cid:16) cos E(Igen), E(Isearch,k) (cid:17) Igen = 1 E(Igen)E(Isearch,k) (cid:16) E(Isearch,k) simk E(Igen) (cid:17) E(Igen) Igen . L.6.4 Key Insights and Advantages Robust Authenticity Check: By comparing the generated image to real-world references, verifiability loss ensures that the output aligns with authentic and visually consistent content. Applicability: This loss is particularly valuable in domains such as journalism, education, and scientific visualization, where factual consistency is crucial. Dynamic Adaptability: The use of external data (Google Image Search) allows the loss to adapt dynamically to diverse prompts and contexts. L.6.5 Challenges and Limitations Search Dependency: The quality and relevance of retrieved images depend on the search engines indexing and ranking algorithms, which may introduce bias or inconsistencies. Computational Overhead: Retrieving and embedding multiple reference images increases computational cost. Domain-Specific Limitations: In specialized domains (e.g., medical imaging), publicly available reference images may not provide sufficient alignment for evaluation. L.6.6 Future Directions To enhance Lverifiability, future research could explore: Domain-Specific Reference Databases: Replace or complement Google Image Search with curated datasets tailored to specific applications (e.g., PubMed for medical images). Efficient Embedding Models: Optimize embedding extraction by using lightweight or domainspecific models for faster computation. Adaptive Retrieval Mechanisms: Develop algorithms that dynamically refine queries to improve the relevance of retrieved reference images."
        },
        {
            "title": "M Hyperparameter Selection",
            "content": "This section provides guidance on selecting hyperparameters introduced in our framework. We detail two approaches: (1) best practices with recommended ranges and (2) automated hyperparameter tuning techniques. M.1 Best Practices and Ranges The following table outlines the key hyperparameters, their purposes, recommended ranges, and best practices for manual selection: M.2 Automated Hyperparameter Tuning For scenarios requiring automated selection of hyperparameters, the following techniques are recommended: Random Search: Samples hyperparameters randomly from specified distributions. Efficient for high-dimensional spaces. Bayesian Optimization: Models the objective function and explores promising regions of the hyperparameter space. Ideal for complex loss surfaces and expensive evaluations. Population-Based Training (PBT): Combines hyperparameter tuning and training, dynamically updating hyperparameters during optimization. Effective for dynamic tasks. To optimize performance, practical workflow might begin with best-practice values followed by grid or random search for coarse tuning, and then Bayesian optimization or PBT for fine-tuning."
        },
        {
            "title": "N Scalability",
            "content": "Scalability is cornerstone of the practical deployment of the proposed YinYangAlign framework, particularly for addressing the complexity of Textto-Image (T2I) alignment tasks. This section explores computational, memory, and data scalability while addressing high-resolution generation. References to best practices and state-of-the-art techniques are included to strengthen the discussion. N.1 Computational Scalability The computational demands of the framework arise from evaluating synergy preferences, regularization terms, and multi-objective optimization. Loss Function Evaluation: introduces λ (cid:80) (i,j) log(P ij ) computational overhead (O(N 2))."
        },
        {
            "title": "The",
            "content": "term quadratic Sparse Sampling: Approximate pairwise evaluations by sampling subset of interactions (Johnson et al., 2019). Mini-batch Strategies: Limit pairwise evaluations to within mini-batches, reducing memory and computational costs. Kernel Approximation: Use techniques like Nyström approximation for computationally efficient kernel evaluation (Williams and Seeger, 2001). Grid Search: Searches exhaustively over predefined ranges. Suitable for small parameter spaces or abundant computational resources. Axiom-Specific Regularization: Jacobian evalua=1 τaRa incur computational overations for (cid:80)A head. Hyperparameter Purpose Recommended Range Best Practices λ: Synergy Weighting Factor 0.1 λ 1.0 local Balances axiom-specific losses and global synergy preferences. τa: Axiom-Specific Regularization Controls regularization strength for each axiom. 0.01 τa 0.1 ωa: Synergy Jacobian Weights Learning Rate (η) Assigns relative importance to axiom synergies during optimization. Controls the step size during optimization. 0.1 ωa 1.0 104 η 102 Start with λ = 0.5. Increase for strong global coherence or decrease for local dominance. = uniform Use 0.05. τa for Adjust tasks: specific lower for highdimensional models. Start with uniform ωa = 1.0. Prioritize conflicting axioms with higher weights. Start with η = 103. Use values smaller for unstable loss landscapes, larger for smoother ones. Table 6: Best practices and ranges for selecting hyperparameters. Apply low-rank approximations or iterative solvers for matrix computations (Saad, 2003). Precompute reusable gradients to accelerate axiom-specific regularization. Distributed Optimization:"
        },
        {
            "title": "Leverage",
            "content": "Scaling: Multi-GPU disHorovod tributed frameworks (https://horovod.ai) PyTorch Distributed (https://pytorch.org/tutorials/ intermediate/ddp_tutorial.html) to parallelize computations. like or Mixed Precision Training: Use tools like NVIDIA Apex (https://github.com/NVIDIA/ apex) to reduce memory usage and improve training speed. N.2 Memory Scalability Memory efficiency is crucial for managing highdimensional embeddings and large-scale data. High-Dimensional Embedding Management: Synergy evaluations require large embedding matrices. Apply dimensionality reduction techniques like PCA or t-SNE (van der Maaten and Hinton, 2008) to compress embeddings. Implement online embedding computation, discarding embeddings after usage. Efficient Checkpointing: Store only essential intermediate states for backpropagation, recomputing others as needed. Use gradient checkpointing libraries, such as Checkmate (https://github. com/stanford-futuredata/checkmate) for efficient training. Dynamic Batch Sizing: Adjust batch sizes based on available memory. Combine with data prefetching and asynchronous data loading for seamless memory management. N.3 Data Scalability Scaling to large datasets requires optimizing preprocessing, storage, and loading mechanisms. Sharding and Distributed Data Loading: Partition datasets into shards and distribute them across nodes for parallel processing. Use frameworks like Apache Parquet (https://parquet.apache. org) for optimized storage and access. Streaming: Stream data in chunks during training to minimize memory usage. Libraries like TensorFlow Datasets (https://www.tensorflow.org/ datasets) or PyTorch DataLoader (https:// pytorch.org/docs/stable/data.html) can facilitate streaming. Handling Imbalanced Datasets: Apply oversampling or weighted losses to ensure balanced contributions across axioms (?). N.4 High-Resolution Image Scalability High-resolution image generation increases both computational and memory demands. Hierarchical Optimization: Use multiresolution strategy, optimizing at lower resolutions first and refining at higher resolutions. Progressive growing techniques, as used in GANs (Karras et al., 2017), can reduce the computational burden early on. Patch-Based Processing: Divide high-resolution images into overlapping patches, process them independently, and aggregate results. Ensure patch consistency using overlap-tile strategies (Ronneberger et al., 2015). Distributed Rendering: Parallelize rendering across GPUs or compute nodes using task scheduling frameworks like Ray (https://www.ray.io)."
        }
    ],
    "affiliations": [
        "Amazon AI, USA",
        "Artificial Intelligence Institute, University of South Carolina, USA",
        "Meta AI, USA"
    ]
}