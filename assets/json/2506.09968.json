{
    "paper_title": "SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance",
    "authors": [
        "Wentao Ge",
        "Yuqing Sun",
        "Ziyan Wang",
        "Haoyue Zheng",
        "Weiyang He",
        "Piaohong Wang",
        "Qianyu Zhu",
        "Benyou Wang"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Self-regulated learning (SRL) is crucial for college students navigating increased academic demands and independence. Insufficient SRL skills can lead to disorganized study habits, low motivation, and poor time management, undermining learners ability to thrive in challenging environments. Through a formative study involving 59 college students, we identified key challenges students face in developing SRL skills, including difficulties with goal-setting, time management, and reflective learning. To address these challenges, we introduce SRLAgent, an LLM-assisted system that fosters SRL skills through gamification and adaptive support from large language models (LLMs). Grounded in Zimmermans three-phase SRL framework, SRLAgent enables students to engage in goal-setting, strategy execution, and self-reflection within an interactive game-based environment. The system offers real-time feedback and scaffolding powered by LLMs to support students independent study efforts. We evaluated SRLAgent using a between-subjects design, comparing it to a baseline system (SRL without Agent features) and a traditional multimedia learning condition. Results showed significant improvements in SRL skills within the SRLAgent group (p < .001, Cohens d = 0.234) and higher engagement compared to the baselines. This work highlights the value of embedding SRL scaffolding and real-time AI support within gamified environments, offering design implications for educational technologies that aim to promote deeper learning and metacognitive skill development."
        },
        {
            "title": "Start",
            "content": "SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Yuqing Sun The Chinese University of Hong Kong, Shenzhen China yuqingsun@link.cuhk.edu.cn Wentao Ge The Chinese University of Hong Kong, Shenzhen China wentaoge@link.cuhk.edu.cn Ziyan Wang The Chinese University of Hong Kong, Shenzhen China ziyanwang@link.cuhk.edu.cn 5 2 0 2 1 ] . [ 1 8 6 9 9 0 . 6 0 5 2 : r Haoyue Zheng The Chinese University of Hong Kong, Shenzhen China haoyuezheng@link.cuhk.edu.cn Weiyang He The Chinese University of Hong Kong, Shenzhen China weiyanghe@link.cuhk.edu.cn PiaoHong Wang City University of Hong Kong China piaohwang2-c@my.cityu.edu.hk Qianyu Zhu The Chinese University of Hong Kong, Shenzhen China zhuqianyu@cuhk.edu.cn Benyou Wang The Chinese University of Hong Kong, Shenzhen China wangbenyou@cuhk.edu.cn Abstract Self-regulated learning (SRL) is crucial for college students navigating increased academic demands and independence. Insufficient SRL skills can lead to disorganized study habits, low motivation, and poor time management, undermining learners ability to thrive in challenging environments. Through formative study involving 59 college students, we identified key challenges students face in developing SRL skills, including difficulties with goal-setting, time management, and reflective learning. To address these challenges, we introduce SRLAgent, an LLM-assisted system that fosters SRL skills through gamification and adaptive support from large language models (LLMs). Grounded in Zimmermans three-phase SRL framework, SRLAgent enables students to engage in goal-setting, strategy execution, and self-reflection within an interactive gamebased environment. The system offers real-time feedback and scaffolding powered by LLMs to support students independent study efforts. We evaluated SRLAgent using between-subjects design, comparing it to baseline system (SRL without Agent features) and traditional multimedia learning condition. Results showed significant improvements in SRL skills within the SRLAgent group (p < .001, Cohens = 0.234), and higher engagement compared to the baselines. This work highlights the value of embedding SRL scaffolding and real-time AI support within gamified environments, offering design implications for educational technologies that aim to promote deeper learning and metacognitive skill development. Keywords Education, Self-Regulated Learning, Human-AI Interaction, Large Language Model Both authors contributed equally to this research. Preprint, 2025, 2025. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM https://doi.org/10.1145/nnnnnnn.nnnnnnn ACM Reference Format: Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang. 2025. SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance. In Proceedings of Preprint. ACM, New York, NY, USA, 20 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn"
        },
        {
            "title": "1 Introduction\nIn higher education, students are expected to take ownership of\ntheir learning—setting goals, managing their progress, and reflect-\ning on outcomes. This ability, known as self-regulated learning\n(SRL)[27, 54, 58, 59, 71], is a critical competency in college settings,\nwhere students face significantly greater demands for autonomy\nand self-direction than in high school. [4, 62]. Unlike the structured\nand teacher-guided learning environment common in secondary\neducation, college students must proactively plan, manage, and\nreflect upon their learning activities with minimal external supervi-\nsion [16, 17, 65]. Prior research has demonstrated that effective SRL\npractices are strongly connected to students’ academic achievement\n[12, 19, 41, 60], study satisfaction [39], and long-term educational\nsuccess[64]. Conversely, inadequate SRL skills among college stu-\ndents frequently lead to disorganized study habits, reduced intrinsic\nmotivation, poor time management, lower academic achievement\noverall [17, 19, 22, 41, 60, 72], and addictive behaviours [66]. Culti-\nvating SRL skills is therefore a critical priority in supporting college\nstudents’ academic development [11, 12, 17, 72].",
            "content": "Previous research has explored various interventions and tools aimed at enhancing college students self-regulated learning (SRL) skills. Educational interventions such as structured training sessions, workshops, and courses explicitly targeting SRL strategies have demonstrated improvements in student self-regulation and academic outcomes [8, 52]. Additionally, technology-driven solutions including mobile applications [12], web-based platforms [10], Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang and AI-driven tutoring systems [28, 42, 45] have emerged to provide personalized feedback, task management, and performance analytics aimed at fostering SRL. However, despite these advances, existing interventions exhibit several limitations. Explicit instructional programs often lack sustained engagement or fail to effectively motivate students, leading to limited transfer and application of SRL strategies beyond initial training contexts [29]. Similarly, technology-based platforms frequently provide generic feedback or overly rigid scaffolds, lacking the adaptability necessary to address individual learner differences and emerging needs during real-time learning activities. Furthermore, many existing solutions do not adequately integrate motivational and engagement elements, such as gamification features, which could enhance learners intrinsic motivation and sustained participation [36, 37]. Consequently, there is critical need for innovative approaches that combine personalized, adaptive feedback mechanisms with engaging, motivationally supportive elements to effectively cultivate college students SRL skills. Building on these limitations, we conducted formative study to investigate the specific design needs and better understand the challenges college students encounter while developing SRL skills. total of 59 undergraduate students from diverse majors participated in this study, which incorporated mixed-methods approach involving semi-structured interviews and surveys. Based on findings from the formative study, we developed SRLAgent, Minecraft-based interactive system designed to foster students SRL skills with large language model(LLM) assistance. Grounded in Zimmermans widely accepted three-phase model of SRL [71], SRLAgent guides students through goal-setting (forethought), strategic monitoring and active learning (performance), and reflective evaluation of their learning experiences (reflection). By embedding SRL strategies directly within engaging gameplay, SRLAgent aims to seamlessly integrate skill practice into students authentic learning experiences. To assess the effectiveness of our proposed system, we conducted between-subjects study comparing SRLAgent with two baseline conditions: baseline version of SRLAgent without SRL support features and traditional multimedia learning. The study results showed that SRLAgent effectively promotes learners abilities in forethought and performance stages of Zimmermans SRL model, highlighting the value of explicit goal-setting and real-time feedback mechanisms. Descriptive trends indicate that SRLAgent may positively influence learner engagement and trust in AI systems, suggesting promising directions for future research and design improvements. This paper contributes to the field of educational technology and human-computer interaction (HCI) as follows: 1) Development of SRLAgent, an LLM-assisted interactive system designed to foster students SRL skills; 2) Implementation of between-subjects user study to evaluate SRLAgents effectiveness and usefulness; 3)Design implications derived from the design process and user studies, offering guidelines for designing interactive systems that leverage generative AI and gamification."
        },
        {
            "title": "Higher Education",
            "content": "Empirical research has consistently shown the positive effect of SRL on academic achievement [6, 12, 15, 19, 23, 41, 60]. Particularly, SRL is widely regarded as foundational competency in higher education, where students are expected to take increasing responsibility for their learning and external guidance is reduced compared to secondary education[16, 17, 62, 68]. To foster this shift toward autonomy, numerous tools have been developed. Previous research has demonstrated the effectiveness of explicit instructional methods, such as structured workshops [5], training courses [8, 21, 64? ], and classroom-based programs [34, 38, 52], designed to directly teach SRL strategies to students. Meanwhile, digital tools have been proposedsuch as study planners, metacognitive prompts, and learning analytics dashboardsdesigned to support goal-setting, routine structuring, and progress monitoring [2, 56, 68]. However, many of these tools adopt static, one-size-fits-all model, offering limited personalization and interactivity. This lack of adaptability can hinder their effectiveness in meeting the diverse needs of learners [18]. Recent studies emphasize that technologies that actively engage students in the SRL process are more effective in enhancing academic performance and motivation [68]. Rather than simply tracking behavior, effective SRL tools encourage self-generated thinking and goal-directed action, which are particularly impactful in postsecondary contexts [10, 55]. Despite this, many current tools still fall short in offering real-time feedback, sustained engagement, or adaptive scaffoldinglimitations that contribute to low retention and limited long-term impact on learning behavior [10, 55]. To address these limitations, researchers have explored the development of adaptive learning systems powered by artificial intelligence. These systems continuously monitor learner progress and dynamically tailor instructional strategies, thereby increasing both engagement and learning effectiveness [43]."
        },
        {
            "title": "2.2 Gamification in Education\nGamification refers to the integration of game-design elements\nand game mechanics into non-game contexts, such as education,\nto enhance motivation, engagement, and learning outcomes [20].\nIn recent years, gamification has gained considerable attention\nas educators and researchers explore innovative ways to moti-\nvate learners, sustain attention, and improve educational expe-\nriences [9, 40, 48, 69]. Numerous studies have empirically investi-\ngated the effectiveness of gamification in educational contexts, with\ngenerally positive outcomes reported across various domains and\nlearner populations. For instance, gamified platforms incorporating\nbadges, points, leaderboards, and quests have been shown to sig-\nnificantly improve student motivation, participation, and academic\nperformance compared to traditional non-gamified instructional\nmethods [26, 61]. In higher education specifically, gamified learn-\ning environments have demonstrated improvements in learners’\nintrinsic motivation, engagement, and retention of course content\n[36].",
            "content": "SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, In parallel, the gamification of learning environments has emerged as promising strategy to enhance students motivation and engagement in SRL. SRL skills such as goal-setting, self-monitoring, and reflection can be facilitated through gamification features like clearly defined quests (goal-setting), progress bars or badges (selfmonitoring), and leaderboards or achievement systems (self-reflection and feedback) [25, 32]. Studies show that students exposed to gamified learning environments are more likely to consistently apply SRL strategies, maintain higher levels of persistence, and experience greater enjoyment in their academic tasks [25]. Moreover, gamified systems can be enhanced with data analytics and real-time feedback, allowing educators to provide personalized guidance based on learners in-game behaviors and performance trajectories. This multimodal approach not only enhances situational engagement but also facilitates the development of SRL skills by helping students reflect on and adjust their learning strategies [43]. Despite its demonstrated benefits, gamification faces several limitations and challenges in educational contexts. One primary concern is the potential for superficial engagement; learners may become more focused on obtaining rewards or achievements rather than developing genuine interest in the learning content [46]. Additionally, poorly designed gamified systems may lead to cognitive overload, distraction from core educational goals, or even demotivation if students perceive the gaming elements as irrelevant or overly simplistic [61]. There is also noted lack of personalized adaptation in many gamified systems, which fails to account for individual differences in learner motivation, abilities, and preferences, potentially reducing their effectiveness for diverse learner populations [36]. In our work, we addressed the gap in current gamified SRL interventions by integrating LLM-assisted real-time feedback and adaptive scaffolding within gamified environment, allowing for personalized and dynamic support. This combination enhances both the motivational and metacognitive aspects of self-regulated learning, offering more engaging and individualized learning experience."
        },
        {
            "title": "Support",
            "content": "Large Language Models (LLMs), such as GPT-series [50], Claudeseries [3], and Gemini-series [24], have emerged as powerful tools in the field of education, offering new ways to support learning and enhance student outcomes [31, 49, 67, 70]. Grounded in deep learning and natural language processing (NLP), LLMs can understand complex instructional prompts, generate coherent and contextually appropriate explanations, and simulate interactive dialogues that closely mimic human tutoring interactions[7, 13, 31]. Such capabilities allow LLMs to serve effectively as intelligent assistants, providing learners with real-time guidance and just-in-time help tailored to their individual needs and contexts. Empirical studies have begun exploring various practical educational applications of LLMs. For instance, LLM-powered conversational agents have been deployed as interactive tutors, offering personalized explanations and feedback to students in domains ranging from mathematics to language learning [7, 33, 63]. Additionally, these models have been integrated into intelligent tutoring systems to assist students in problem-solving, scaffolding their reasoning processes, and answering questions dynamically [28, 45]. The integration of Large Language Models (LLMs) into educational contexts presents significant opportunities for enhancing self-regulated learning (SRL) among students. Studies suggest that LLMs can provide personalized learning suggestions, prompting students to reflect on their learning experiences and improve their metacognitive strategies [1]. This aligns with self-efficacy theories, where positive feedback and personalized strategies boost learners belief in their abilities [14]. Also, research illustrates that LLMs can facilitate adaptive learning environments that adjust to individual student needs, subsequently fostering deeper engagement with the material [51]. Interactive agent-based systems have been shown to increase motivation and study efficacy by creating personalized learning pathways that respect individual learning preferences [51]. In conclusion, while LLMs have shown promising potential for enhancing students SRL skills, their practical application, particularly in directly supporting the SRL process, has not yet been thoroughly investigated. Our work aims to design system integrating adaptive, real-time LLM-driven guidance with gamification elements, effectively enhancing both student motivation and personalized learning support. Additionally, our system specifically focuses on scaffolding students self-regulated learning skills, mitigating common challenges related to superficial engagement and generic, non-adaptive feedback."
        },
        {
            "title": "3.1 Participants and Procedure\nParticipants in this questionnaire were current university students.\nA total of 59 students completed the questionnaire, spanning aca-\ndemic years from freshman to senior, with freshmen accounting\nfor 32.2% of the total. The survey included demographic questions\nsuch as students’ year of study, gender, and major. The question-\nnaire addressed a variety of academic adjustment issues, including\nperceptions of curriculum and course content, workload and assess-\nments, time management and self-regulation, communication with\ninstructors, academic support systems, and perceived academic\npressure.",
            "content": "To complement the questionnaire findings, we conducted semistructured interviews with three university freshmen. The interviews were held via Tencent Meeting and focused on students study habits, time management strategies, self-regulation practices, academic challenges, and their perceptions of AI-assisted and gamebased learning systems. Each interview lasted approximately 20 minutes. Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang"
        },
        {
            "title": "3.2 Findings\nOur formative study revealed significant insights into students’\nacademic adjustment challenges and their perspectives on learning\nsupport.",
            "content": "3.2.1 Questionnaire results. The questionnaire collected responses from 59 students regarding their study habits, time management, adjustment ability, and perceived academic pressure. The result on students academic habits showed numerous distinct tendencies. In terms of time management, the majority (54.2%) of students stated that they can only \"basically manage\" their study time with occasional adjustments, while 16.9% admitted to having problems managing their time and frequently encountering assignment delays. This shows that many students fail to manage their time efficiently. In terms of study state adjustment, 49.2% of students said they \"generally need some time\" to change, while 15.3% found it \"difficult\" to do so. Only 25.4% of students considered it easy to adapt to changing learning tasks, demonstrating the overall difficulties in sustaining appropriate learning settings. When it comes to study and rest arrangements, more than half (50.8%) of students reported having inconsistent study and relaxation schedules, indicating lack of well-defined daily routines to enable sustained academic engagement. In terms of progress alignment with course schedules, more than half (52.5%) of respondents reported that their learning progress was regularly inconsistent with course schedules, highlighting difficulties with pacing and self-monitoring during the semester. Finally, concerning perceived academic pressure, substantial proportion of students (39%) reported feeling \"a high level of pressure\" that was difficult to endure, while 32.2% felt \"a moderate amount of pressure\" that, to some extent, motivated their academic progress. The questionnaire results highlighted that students primarily need improved study skills and better support mechanisms, which aligns with our research focus on self-regulated learning (SRL) as means to enhance academic performance. Semi-structured Interviews. The follow-up semi-structured 3.2.2 interviews with three participants focused on learning plans, study habits, time management, learning challenges, and perspectives on traditional education versus AI-assisted and gamified learning approaches. For clarity in the following discussion, we refer to these interview participants as S1, S2, and S3. Learning Process and Course Content. Regarding typical assignments, S1 and S2 mentioned that courses generally require quizzes, reports and occasional group projects that demand collaborative knowledge application. Participants commonly reported difficulty identifying key concepts when first encountering new material, often only recognizing knowledge gaps during examinations. S1 specifically noted that self-directed exploration becomes challenging without basic conceptual understanding, while S3 found traditional instructional methods effective due to their similarity with high school learning approaches. Learning Habits and Planning. Most participants described struggling with procrastination and maintaining consistent study routines, with few using detailed planning schedules. Students typically adopted spontaneous approaches driven by immediate needs or deadlines. Most did not use planning tools to track learning progress and engaged in minimal post-examination reflection, citing delayed feedback and lack of detailed solution explanations as barriers. This reflects broader pattern of reactive rather than proactive learning management. Learning Support. When encountering difficulties, students typically approached instructors and tutors only for specific problems they couldnt resolve independently, valuing thorough explanations until complete understanding was achieved. All participants also reported using AI tools when facing academic challenges. For AI learning support, students expressed clear preference for systems that explain problem-solving processes rather than simply providing answers. They valued interactive, conversational interfaces with friendly engagement styles that resemble effective human teaching."
        },
        {
            "title": "3.3 Design Principles for SRLAgent\nBased on our findings, we developed design principles for SRLA-\ngent grounded in Zimmerman’s cyclical model of SRL, which aims\nto provide scaffolding that gradually develops students’ indepen-\ndent learning capabilities, ultimately supporting their successful\nadjustment to the academic demands of higher education.",
            "content": "Self-Regulated Learning for Academic Study Skills. The first 3.3.1 principle focuses on providing implicit SRL strategies to manage the learning process. This addresses the overarching management of the learning journey, supporting students in developing metacognitive awareness and skills. SRLAgent will facilitate task planning and goal setting, time management assistance addressing the prevalent procrastination challenges, and comprehensive task summaries and feedback to promote reflection and continuous improvement. 3.3.2 Real-time and Personalized Support in Learning Process. The second principle emphasizes delivering real-time, learning taskspecific suggestions during the performance phase of individual subtasks. Zimmermans model presents self-regulated learning as three sequential phases. In our design, we aim to explore whether intelligent agents can effectively support self-regulated processes during the performance phase of various subtasks with real-time feedback. This design approach for SRLAgent integrates immediate feedback mechanisms within active learning experiences for different subtask types. Our system provides timely feedback during active learning subtasks, including detailed explanations after quiz attempts, addressing students desire for understanding principles rather than just receiving answers. For paper review and writing subtasks, the system offers real-time Q&A and assistance with knowledge organization and writing guidance. Throughout the learning process, students can access specialized agent-based expertise tailored to specific subtask domains, enabling deeper conceptual discussions. Through this design, we explore how agents can scaffold self-regulated learning processes during active subtask performance."
        },
        {
            "title": "4 SRLAgent\nIn this section, we present SRLAgent, the gamified learning environ-\nment built on the Minecraft platform that leverages large language",
            "content": "SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, Figure 1: SRLAgent System Architecture Overview models (LLMs) to foster SRL skills in college students. As shown in Figure 2, SRLAgent integrates Zimmermans three-phase SRL model (Forethought, Performance, and Reflection) with specific learning task stages to create comprehensive framework that guides students through the entire self-regulated learning process. We designed SRLAgents workflow and interaction based on the design principles obtained from our formative study. The system consists of three key components: (1) an immersive 3D campus environment that provides spatial context for learning activities through detailed virtual representation of the university campus, (2) flexible learning framework supporting customizable educational tasks through hierarchical task management system with specialized learning activities organized in complementary pairs, and (3) sophisticated LLM-driven agent system that delivers personalized guidance across all SRL phases through specialized agents for planning, monitoring, tutoring, and reflection. The implementation uses Minecrafts modding capabilities with Forge API, structured MVC+System architecture for flexible content management, and an Agent Orchestration Framework that creates bidirectional flow between the game environment and LLM-powered agents. Through specialized prompt templates aligned with each subtask content and SRL phase, the system delivers concise, contextually appropriate guidance that supports students development of self-regulation skills while they engage with subject-specific learning content. The following sections detail these system features and their implementation, followed by case study demonstrating how the system supports students in developing self-regulated learning skills through this integrated approach."
        },
        {
            "title": "4.1 System Features\n4.1.1 3D Minecraft College Campus Environment [SF1]. The\nSRLAgent features a detailed virtual representation of the author’s\nuniversity campus within Minecraft. This immersive environment\nserves as the central setting for all educational experiences, creating\na digital twin of the physical campus that includes key landmarks,\nacademic buildings, residential colleges, and cultural elements.",
            "content": "The virtual campus design supports spatial learning by connecting learning activities to familiar academic context. Different campus locations host specific learning functions - libraries contain research materials, classrooms feature interactive knowledge displays, and meeting spaces enable NPC consultations - creating coherent educational landscape that mirrors real university experiences. 4.1.2 Learning Skills Enhancement System [SF2]. Academic Content Integration. SRLAgent integrates educational content directly into the virtual campus environment through interactive posters, digital libraries, and NPC knowledge bases. The system supports flexible content integration, allowing various academic subjects to be incorporated through modular structure that separates content from delivery mechanisms. Educational materials are presented through spatially-distributed elements in the virtual environment, creating an immersive learning experience where knowledge discovery becomes part of exploration. Task System. SRLAgent employs hierarchical task management system that orchestrates the learning experience across multiple levels. At the highest level, the system organizes the overall learning progression through four sequential stages as shown at the top of Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang Figure 2: SRLAgent framework integrating Zimmermans three-phase SRL model with specific learning task stages. Figure 2: Introduction for initial orientation and context setting, Planning for preparation and strategy development, Task Process for core learning activities execution, and Review for assessment and outcome evaluation. The TaskManager coordinates these stages and tracks major learning tasks assigned to the player. Each major task contains multiple subtasks with defined completion criteria, creating structured progression path while maintaining flexibility for different learning contexts. As depicted in the center of Figure 2, the system includes specific learning activities organized in complementary pairs: Knowledge acquisition paired with Quiz completion, Paper reading paired with Review creation, Discussion participation paired with Insight development, and Writing Goal setting paired with Report creation. The TaskManager is designed with modular architecture that allows for enhancement through additional layers. Its core functionality tracks completion status across subtasks, synchronizes progression, and manages state transitions between activities to ensure coherent learning flow. This design enables developers to rapidly implement new features that educational designers can subsequently utilize to create specialized learning experiences with different pedagogical approaches. Study Skills Enhancement Layer. Building upon the core TaskManager, our Task System can be extended to support various study skills frameworks through Study Skills Enhancement layer with configurable views and tracking mechanisms. By adjusting task parameters, monitoring metrics, and feedback configurations, the system can be adapted to emphasize different educational approaches without modifying the underlying architecture. This extensibility allows educational designers to tailor the learning experience to specific pedagogical goals, whether focusing on time management, critical thinking, collaborative learning, or other study skills. In this research, we specifically focused on enhancing Self-Regulated Learning skills. We implemented the Study Skills Enhancement layer with SRL stragegies and integrated SRL-Enhanced Task System that incorporates specialized agents corresponding to the phases of Zimmermans SRL model. These SRL-focused components enhance the basic task system by providing real-time, customized feedback based on the players progress and performance metrics. Each agent is specifically designed for particular learning contexts SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, and subtasks, offering guidance tailored to both the educational content and the appropriate SRL strategies for that activity. 4.1.3 LLM-driven SRLAgent System [SF3]. Extending the capabilities of the Learning Skills Enhancement System [SF2], the SRLAgent system employs sophisticated agent architecture that provides real-time, personalized support across all phases of the self-regulated learning process. This agent system is specifically customized to address both the educational content and the appropriate self-regulation strategies for each learning stage, enhancing the Task System with intelligent guidance mechanisms. Planning Agent: Corresponds to the FORETHOUGHT phase of the SRL cycle by guiding students in setting goals and developing strategies before beginning learning tasks. This agent helps learners establish clear objectives, select appropriate strategies, and develop structured approach to their studies. It generates the \"Plan Learning Task\" view shown in Figure 2, which serves as both planning document and reference throughout the learning process. SubTask Monitor: Operates during the PERFORMANCE phase of the SRL cycle, tracking real-time performance across all learning subtasks and collecting data on time spent, completion rates, and quality indicators. This monitoring component serves as the foundation for the contextual awareness of other agents, enabling them to provide timely and relevant support based on the learners current progress and challenges. SubTask Tutor Agent System: Enhances the PERFORMANCE phase through specialized agents tailored to specific learning activities. The Quiz Agent offers adaptive support for assessment activities, identifying knowledge gaps and suggesting review strategies. The Review Agent guides critical analysis and evaluation, helping students develop deeper understanding of materials. The Chatting Agent facilitates productive discussions and insight development, promoting collaborative knowledge construction. The Writing Agent provides structured support for report creation, assisting with organization, evidence use, and clarity. These specialized agents deliver immediate, contextual feedback aligned with both content mastery and self-regulation skill development. Reflection Agent: Addresses the REFLECTION phase of the SRL cycle by analyzing performance data and guiding self-evaluation, creating the \"Learning Reflection\" view shown in Figure 2. This agent helps students connect their strategies with outcomes, identify areas for improvement, and develop plans for applying insights to future learning activities. Each agent integrates specialized prompt templates and context management systems to ensure interactions are appropriate, helpful, and aligned with both learning objectives and SRL principles. The system maintains conversation history and tracks progress data across multiple interactions, providing continuity throughout the learning experience and enabling agents to reference previous activities and outcomes. This coherent agent ecosystem creates comprehensive support structure that guides students through the complete SRL cycle while adapting to their specific learning needs and subject matter requirements."
        },
        {
            "title": "4.2 Implementation\n[SF1]Minecraft Development and Modding. Correspond-\n4.2.1\ning to the 3D Minecraft College Campus Environment , our imple-\nmentation involved:",
            "content": "3D Campus Recreation: Coordination with specialized modeling team to accurately reproduce campus architecture, including precise spatial relationships and distinctive visual elements that ensure landmark recognition. Forge Mod Development: Creation of custom Minecraft mod using Forge API for Minecraft 1.18.2, written in Java. This extends Minecrafts base functionality to support educational interactions and SRL-specific mechanics. Interactive Elements: Development of specialized blocks, items, and entities serving educational purposes, including interactive knowledge posters, paper displays, educational activity stations, and triggerable learning events. [SF2]Learning System Architecture and Data Manage4.2.2 ment. Supporting the Learning Skills Enhancement System , we implemented: MVC+System Architecture: structured code organization pattern that separates data models, visual components, control logic, and system services. This architecture supports the complex interactions between the TaskManager, learning subtasks, and user interface elements shown in Figure 2. JSON Data Loading System: An extensible data management framework that stores all educational content and task configurations externally. This includes task stage definitions, learning task specifications with dependencies, subtask completion criteria, educational content, and study skills enhancement settings. The separation of content from code enables rapid iteration and adaptation to different learning domains and study skills frameworks. Task Progression Framework: comprehensive tracking system that monitors student progression through interconnected learning subtasks, manages the game state and task availability based on player actions, synchronizes completed subtasks with parent tasks, and updates task views to reflect current learning status. Built on the modular architecture of the TaskManager, this framework provides the technical foundation for incorporating various study skills enhancements. In our implementation, we extended this framework to create the SRL-Enhanced Task System, which integrates specialized SRL agents with the core task management functionality to deliver context-aware self-regulation guidance throughout the learning process. This implementation approach enables flexible content management while maintaining consistent learning framework that can be enhanced with different pedagogical approaches. [SF3]LLM-driven SRLAgent Implementation. To sup4.2.3 port the SRLAgent, we implemented: Agent Orchestration Framework: The SRLAgent System serves as coordination layer that facilitates the integration between Minecraft environment elements and AI-powered learning guidance as shown in Figure 1. Operating in concert with the SRLEnhanced Task System, this framework utilizes task state information to determine when and how to activate different agents. As illustrated in Figure 2, the orchestration aligns and activates agents Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang with both Task Learning Stages and corresponding SRL Phases. This ensures that appropriate guidance is delivered at each point in the learning journey. LLM Toolchain: This implicit middleware layer integrates LLM capabilities into our MVC+System architecture, treating AI services as system-level components. As shown in Figure 1, the toolchain manages the LLM API communications, context assembly from game state, and response processing. This approach creates cohesive system where LLM capabilities are seamlessly embedded throughout the application, handling prompt construction, API calls, and response integration through unified interface that other system components can access. SRL-Enhanced Prompt Templates: Specialized system prompt designs for each agent type within the SRLAgent System shown in Figure 2, with configurations tailored to their specific roles in the SRL process. These templates are organized hierarchically to align with the SRL-Enhanced Task System architecture: Forethought Phase Templates (Planning Agent): \"You are an SRL expert. The player completes series of tasks in the game and gets an Outcome at each step. Please summarize his task performance. Emphasis on using SRL skills to coordinate mission situations, and explicit SRL methods can be used, because the goal is to allow players to learn SRL skills. No more than 30 words. Please be concise, constructive, and clearly structured.\" Performance Phase Templates (SubTask Tutor Agent System): Writing Agent: \"You are an expert in report writing especially in University Education and Self-Regulated Learning(SRL) strategies. Your role is to assist the player in improving their SRL skills to achieve learning goals. The player now is in the Performance phase with subTask of writing report according to Agent. Reply with no more than 30 words. You can answer by steps!\" Reflection Phase Templates (Reflection Agent): \"You are an expert in University Education and Self-Regulated Learning (SRL) strategies. The player has completed series of tasks in the game, each with its own outcome. The player is now in the Reflection phase of the SRL strategy. Please summarize their task performance based on the [Subtask Completion Content:] information you receive. No more than 30 words. Be concise, constructive, and clearly structured.\" Each template incorporates phase-specific SRL principles and educational content relevant to the current learning activity. The concise format (limited to 30 words) ensures focused guidance while maintaining instructional quality across all phases of the learning process. This implementation creates bidirectional flow of information between the game environment and the agent system. Game elements provide context to the agents through the orchestration framework, while agent responses are delivered back to the user through appropriate interface elements like Task Guidance and SRLQuest, supporting the full SRL cycle depicted in Figure 2."
        },
        {
            "title": "4.3 Case Study: Improving SRL Skills\nThe SRLAgent system demonstrates how gamified environments\nintegrated with LLM-powered agents can effectively support the\ndevelopment of self-regulated learning skills. Through the struc-\ntured task progression and adaptive agent support, students learn\nnot only subject matter content but also metacognitive strategies\nfor planning, monitoring, and reflecting on their learning process.\nTo validate our approach, we customized an existing Hugging\nFace Agent tutorial as learning content within our SRLAgent system.\nWe integrated this publicly available tutorial into our gamified\nlearning system. First-year undergraduate students were invited\nto participate in testing sessions where they engaged with the\nHugging Face Agent tutorial through our SRLAgent interface.",
            "content": "The feedback collected from these sessions was overwhelmingly positive. Students reported that the system successfully enhanced their learning experience, with particular appreciation for the structured guidance provided by the SRL agents. Specifically, participants noted improvements in their metacognitive awareness and ability to plan learning activities strategically."
        },
        {
            "title": "4.4 Example Use Case\nTo illustrate how our system enhances self-regulated learning (SRL)\nskills among college students, we present a detailed scenario of\na college freshman named Elvira. The Interfaces for this case are\nshown in the Appendix.",
            "content": "Elvira begins by opening her computer and launching the SRLAgent system within Minecraft. Upon entering SRLAgent, the system first helps her clearly understand her upcoming learning task by breaking it down into smaller, manageable subtasks. Recognizing her tendency toward procrastination, SRLAgent guides Elvira through structured goal-setting and effective time allocation, creating realistic and achievable study plan. The integrated TimeHUD component visually represents her allocated time commitments for each subtask, helping Elvira maintain awareness and control over her schedule. All these preparation steps collectively form the Forethought Phase of SRL. Next, Elvira moves into the active learning phase (Performance Phase). She engages with learning materials, which are gamified within Minecraft as interactive game items and entities to enhance motivation and engagement. As she progresses, the system continuously tracks her learning status and provides timely guidance through Large Language Model (LLM)-driven Non-Player Characters (NPCs). For instance, Elvira interacts with Knowledge Posters that visually represent complex concepts, takes quizzes to assess her understanding, and receives immediate feedback on challenging topics. When she encounters difficulties in understanding research papers, SRLAgent offers structured guidance to help her identify and summarize key insights. Additionally, Elvira interacts with Prof.NPC, virtual professor powered by an LLM, who engages her in conversational question-answering sessions to clarify and resolve any lingering questions. To consolidate her understanding, Elvira completes Report Writing Task, synthesizing and articulating what she has learned. Upon completing her learning tasks, Elvira enters the Self-Reflection Phase. SRLAgent prompts her to thoughtfully consider several reflective questions: What key concepts have learned? Which parts SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, of the material were most challenging for me? Which learning strategies were effective or ineffective? How can improve my approach to similar assignments in the future? This structured reflection process helps Elvira build critical metacognitive awareness, addressing gaps typically present in her study practices. Throughout this learning journey, SRLAgent continuously monitors Elviras progress, providing adaptive and personalized guidance aligned with the development of her SRL skills."
        },
        {
            "title": "5 User Study\nTo evaluate the effectiveness of SRLAgent in fostering student\nself-regulation, we conducted a between-subject user study, where\nstudents were randomly assigned to either use the SRLAgent or one\nof the two baselines to learn the artificial intelligence concept of\nthe \"Large Language Model (LLM) agent\". Our research questions\n(RQs) are as follows:",
            "content": "RQ1. How does SRLAgent impact college students selfregulated learning skills compared to traditional learning resources? RQ2. How does SRL influence students academic performance? RQ3. How do users perceive SRLAgent in terms of engagement and trust?"
        },
        {
            "title": "5.1 Participants\nWe recruited participants from a university in China, specifically\ntargeting college freshmen who self-identified as requiring aca-\ndemic support and lacking effective study skills. These students\nhad previously expressed interest in improving their study habits\nand academic outcomes. The final sample consisted of 45 partici-\npants (23 male and 22 female), with a mean age of 19 years (SD =\n18.96). All participants are Chinese, and we screened for prior ex-\nperience with LLM Agents to ensure participants have comparable\nbaseline knowledge. Participants were randomly assigned to either\none of the three study condition. See details in 5.2. All participants\nreceived 25 RMB for their participation in the one-hour study.",
            "content": "Gender Female Male Baseline System Group B1 System Group B2 53.33% (𝑁 = 8) 46.67% (𝑁 = 7) 50% (𝑁 = 7) 50% (𝑁 = 7) 43.75% (𝑁 = 7) 56.25% (𝑁 = 9) School Humanities and Social Science Medicine, Life and Health Sciences Data Science Management and Economics Science and Engineering 13.33% (𝑁 = 2) 20.00% (𝑁 = 3) 33.33% (𝑁 = 5) 26.67% (𝑁 = 4) 6.67% (𝑁 = 1) 7.14% (𝑁 = 1) 28.57% (𝑁 = 4) 28.57% (𝑁 = 4) 14.29% (𝑁 = 2) 21.43% (𝑁 = 3) 12.50% (𝑁 = 2) 12.50% (𝑁 = 2) 25.00% (𝑁 = 4) 25.00% (𝑁 = 4) 25.00% (𝑁 = 4) 15 14 16 Difference 𝜒 2 (2) = .297, 𝑝 = .862 𝜒 2 (8) = 2.856, 𝑝 = .943 Table 1: Participant demographics and characteristics."
        },
        {
            "title": "5.2 Experiment Setup\nWe employed a between-subjects experimental design to evaluate\nSRLAgent’s effectiveness in enhancing self-regulated learning skills\nand learning outcomes. This approach allowed us to compare par-\nticipants who used SRLAgent against those who used a baseline\nsystem, with pre- and post-test measurements to assess changes\nover time.",
            "content": "During recruitment, participants indicated their interest in learning about Large Language Models, specifically focusing on \"LLM Agents\" as the content domain. Each participant was randomly assigned to one of the following conditions: Baseline (Multimedia Learning): Participants learned about learning materials through pre-recorded instructional video, reflecting common, traditional approach to online learning. This baseline is set to examine the effectiveness of SRLAgent compared to traditional learning method. System Group B1 (SRLAgent without SRL features): Participants used baseline version of SRLAgent that excluded all SRL-specific features, such as the goal-setting page, strategic planning page, LLM-assisted guidance, timemanagement tools, and self-reflection functionalities. The system still operated within the Minecraft environment, containing the same learning materials as the experimental version but without scaffolds for self-regulated learning. This group is set to investigate the effect of SRL features of SRLAgent on students learning outcomes. System Group B2 (SRLAgent): Participants used the complete SRLAgent system with all SRL features enabled. To ensure consistency between different experiment conditions, both conditions maintained identical learning content and learning duration."
        },
        {
            "title": "5.3 Procedure\nThe study was approved by the Institutional Review Board of the\nauthors’ institution. After obtaining informed consent, participants\ncompleted a five-phase protocol: introduction, pretest, tutorial,\nlearning, and post-test. The complete procedure is illustrated in\nFigure 3.",
            "content": "Introduction (5 minutes). The study was conducted in com5.3.1 puter laboratory at university in China. Each participant was assigned to computer equipped with headset for audio input and output. research assistant introduced the purpose of the study, provided an overview of the experimental procedure, and explained the tasks participants would be performing. 5.3.2 Pretest (10 minutes). All participants completed identical pretest assessments measuring both self-regulated learning skills and prior knowledge about LLM agents. This served as baseline for evaluating changes in their SRL skills and knowledge acquisition throughout the study. 5.3.3 Tutorial (10 minutes). Participants assigned to the system groups (B1 and B2) were given tutorial session to familiarize themselves with the systems features and the operations within the Minecraft environment. Participants in the multimedia learning group (baseline A) skipped this step and proceeded directly to the learning phase after the introduction session. The tutorial was divided into two parts: five-minute instructional video and fiveminute hands-on practice session. The instructional video provided an overview of the system interfaces and key features. While both groups watched similar videos, the content was tailored to their assigned conditionparticipants in the control group (B1) viewed tutorial that only covered the baseline features, while those in the experimental group (B2) were introduced to the complete SRLAgent Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang Figure 3: The procedure of the between-subject user study. system, including all self-regulated learning components. After the video, participants completed standardized navigation task to ensure they were comfortable using their assigned system before proceeding with the learning session. 5.3.4 Learning (30 minutes). During this phase, participants in the system groups (B1 and B2) independently engaged with their assigned system to learn about LLM agents. The learning experience for participants in baseline (multimedia learning) involved 25-minute pre-recorded video that covered the same content. This baseline aimed to provide traditional, non-interactive learning experience for comparison with the SRL-enhanced systems. Throughout the learning phase, research assistants were available for technical support but provided minimal interference to maintain experimental validity. Participants were encouraged to proceed at their own pace, ensuring that the learning experience was not disrupted by external guidance. 5.3.5 Post-test (10 minutes). Upon completion of the learning session, participants filled out post-test questionnaire. This assessment aimed to measure any changes in SRL skills, knowledge of LLM agents, and perceived engagement with the system. The posttest also included questions to gauge participants satisfaction with the learning experience and the systems features. These results were compared to pretest responses to assess the effectiveness of the intervention in improving self-regulation skills and knowledge acquisition."
        },
        {
            "title": "5.4 Evaluation Metrics\nTo evaluate the effectiveness of SRLAgent in fostering self-regulated\nlearning (SRL) skills, we utilized a range of quantitative and qual-\nitative measures to assess participants’ SRL skills, learning out-\ncomes, and engagement. These metrics provided insights into the",
            "content": "systems impact across multiple dimensions, including changes in self-regulation abilities, knowledge acquisition, and overall engagement with the learning process. Self-Regulated Learning Skills (RQ1). Drawing from Nam5.4.1 biars Academic Self-Regulated Learning Questionnaire (ASLQ)[44], the research team posed 18 questions to assess participants selfregulated learning (SRL) skills. Example items include: \"I dont feel motivated to study difficult subjects\", \" make sure that complete the portions on time\", and \"I make necessary changes in my study plan to improve learning\". Participants rated each item on 7-point Likert scale (1 = strongly disagree, 7 = strongly agree). The final score, ranging from 1 to 7, was calculated by summing the points across all items and dividing the number of all items. The Cronbachs alpha for this scale was 0.87, indicating good internal consistency. Full questionnaire details can be found in Appendix 2. Learning Outcomes (RQ2). To assess participants knowledge 5.4.2 acquisition regarding the concept of LLM Agents, we adopted the 12item official final test from the Hugging Face LLM Agent tutorial1. Each item is multiple-choice question that evaluates key aspect of Large Language Models and agent usage, encompassing topics such as essential terminology and architecture. Participants earned 1 point for each correct answer, producing total possible score of 12. This test was administered at both the preand post-test stages to gauge changes in participants knowledge. Higher scores indicate stronger mastery of the LLM Agent content. 5.4.3 Engagement (RQ3). To understand participants engagement in the activity, the research team analyzed their responses using 30-item 5-point Likert scale (1-strongly disagree, 5-strongly agree) adapted from the User Engagement Scale (UES) [47]. Example items 1https://huggingface.co/learn/agents-course/unit1/final-quiz SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, include lost myself in this experience., felt frustrated while using this app., This app was attractive), and Using app was worthwhile. The scale was used in the post-test. Scale scores are calculated for each participant by summing scores for the items in each of the four subscales and dividing by the number of items. The overall engagement score can be calculated by adding the average of each subscale. The Cronbachs alpha for this questionnaire was 0.90. 5.4.4 Trust in AI System (RQ3). We used 12-item questionnaire adapted from Jians Trust Scale [30] to measure participants trust in the AI system before and after the intervention. This scale, validated in AI-related contexts [57], captures both trust and distrust through statements like The System is deceptive, am wary of the System, and can trust the System. Participants indicated their level of agreement on 7-point Likert scale ranging from 1 (strongly disagree) to 7 (strongly agree). Certain items were reverse-coded to account for negative statements. An overall trust score was calculated by averaging all item responses, with higher values indicating higher levels of trust in SRLAgent. The Cronbachs alpha exceeded 0.80, suggesting good to excellent level of internal consistency for the scale."
        },
        {
            "title": "6 Results\n6.1 Self-Regulated Learning Skills\nTo evaluate the effectiveness of SRLAgent in enhancing participants’\nself-regulated learning (SRL) skills, we analyzed changes in SRL\nscores.",
            "content": "We conducted paired-samples t-tests to assess changes in selfregulated learning (SRL) skills within each experimental condition (SRLAgent, SRLAgent without SRL features, and Multimedia Learning). As shown in Figure 4 (a), participants who interacted with the complete SRLAgent showed statistically significant improvement in their SRL scores from pretest (M = 5.66, SD = .67) to post-test (M = 5.92, SD = .65), with t(15) = 4.41, < .001, Cohens = .234. This indicates that the integrated SRL scaffolds provided by SRLAgent effectively enhanced participants overall self-regulation abilities. Conversely, no significant improvements from pretest to post-test were observed in either the SRLAgent without SRL features group (t(13) = .15, = .883) or the Multimedia Learning group (t(14) = .24, = .814). These results suggest that neither traditional multimedia instruction nor the Minecraft-based platform alone substantially impacted participants SRL skills, highlighting the importance of specific SRL-focused design features. To assess baseline equivalence, one-way ANOVA was performed on pre-test SRL scores across the three groups (SRLAgent, SRLAgent without SRL features, and Multimedia Learning). The analysis revealed no significant differences, F(2, 42) = .69, = .507, confirming comparable starting levels. An independent-samples t-test comparing post-test SRL scores between SRLAgent and Multimedia Learning groups showed marginally significant difference, t(29) = 1.93, = .063, Cohens = .638, indicating moderate effect size favoring SRLAgent."
        },
        {
            "title": "6.4 Trust in AI\nTo examine whether using SRLAgent influenced participants’ trust\nin AI, we conducted a paired-samples t-test comparing pre- and post-\nintervention trust scores within the SRLAgent group. Participants\nexhibited a modest increase in trust scores from the pretest (M =\n4.66, SD = .73) to the post-test (M = 4.91, SD = .80). However, this\nimprovement was not statistically significant, t(15) = 1.62, p = .127.\nDespite the absence of statistical significance, the observed increase\nin the SRLAgent group was notably larger compared to negligible\nchanges found in the Multimedia Learning (Δ𝑀 ≈ 0) and SRLAgent\nwithout SRL features groups (Δ𝑀 = .006; see Figure X).",
            "content": "We further conducted one-way ANOVA comparing post-test trust scores across the three conditions (SRLAgent, SRLAgent without SRL features, and Multimedia Learning). The results did not yield statistically significant effect of intervention type, F(2, 42) = 1.21, = .310. Nevertheless, descriptive statistics revealed consistent trend favoring SRLAgent, with participants reporting higher post-test trust scores (M = 4.91, SD = .80) relative to the Multimedia Learning condition (M = 4.62, SD = .80) and SRLAgent without SRL features (M = 4.52, SD = .60). Although the results lack statistical significancepotentially due to the relatively small sample sizethey highlight meaningful descriptive trend suggesting that enhanced SRL scaffolding and personalized AI-driven feedback may positively influence students trust in AI-based learning platforms. Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang Figure 4: Distribution of participants (a) self-regulated learning (SRL) scores and (b) LLM agent knowledge test scores before and after the intervention for the SRLAgent (Group B2), SRLAgent without SRL features (Group B1), and Multimedia Learning groups (Baseline A). Statistically significant results are indicated as 𝑝 < .05*, 𝑝 < .01**, 𝑝 < .001***. Figure 5: Distribution of participants score on (a) Forethought, (b) Performance, and (c) Reflection dimensions of ASLQ before and after the intervention for the SRLAgent (Group B2), SRLAgent without SRL features (Group B1), and Multimedia Learning groups (Baseline A)."
        },
        {
            "title": "Engagement with SRLAgent",
            "content": "The findings demonstrate the potential of SRLAgent in effectively promoting college students self-regulated learning (SRL) skills. The significant improvements observed support earlier studies suggesting that structured planning, feedback, and scaffolding can positively influence students abilities to regulate their learning processes [60, 71]. Although our comparative analyses across conditions did not yield statistically significant group differences, the consistently higher SRL scores among students using SRLAgent suggest practical benefits of incorporating comprehensive SRL scaffolding into learning technologies. This finding resonates with prior work indicating that embedding self-regulatory support within digital platforms can benefit learners [10, 12]. Regarding engagement, the observed higher mean engagement scores indicate that SRLAgents design has promising potential to maintain learners attention and motivation. This aligns with existing research identifying the motivational benefits of adaptive Figure 6: Scatter plot illustrating the distribution of participants engagement level across four engagement dimensions (Focused Attention (FA), Perceived Usability (PA), Aesthetic Elements (AE), Reward Factor (RW)) for SRLAgent group (Group B2) and SRLAgent without SRL features group (Group B1). SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, feedback and interactive gamification elements in educational systems [36, 37]. Specifically, the gamified, quest-based structure and interactive feedback provided by SRLAgent likely contribute to sustaining learners intrinsic motivation and promoting deeper immersion in the learning task. In summary, SRLAgent fosters SRL among college students while maintaining learner engagement. These insights both confirm and extend existing research on SRL-supportive educational technologies and highlight specific opportunities for future enhancements to better scaffold learners throughout the complete SRL process."
        },
        {
            "title": "7.2 Enhancing Academic Performance with SRL\nOur findings suggest that SRLAgent had a positive effect on aca-\ndemic performance, as evidenced by the significant improvement\nin participants’ understanding of the Large Language Model (LLM)\nconcept. This aligns with previous studies demonstrating that self-\nregulated learning interventions can lead to better knowledge ac-\nquisition and retention [52]. The ability of SRLAgent to provide\npersonalized, adaptive feedback likely contributed to this improve-\nment, as students received tailored guidance that aligned with their\nindividual learning needs.",
            "content": "Further research could explore how specific elements of SRLAgent, such as the pacing of feedback or the integration of task management tools, influence academic performance. Additionally, measuring long-term retention would be important to assess whether the benefits of SRLAgent are sustained beyond the immediate learning period."
        },
        {
            "title": "7.3 Balancing between Autonomous and AI\nAssistance in the Learning Process",
            "content": "The results revealed an interesting trade-off between learning outcomes and trust in AI assistance. Specifically, the SRLAgent group, which received comprehensive AI-driven SRL features, showed lower improvement in learning outcome scores from pretest to post-test compared to the SRLAgent without SRL features group. Conversely, participants in the SRLAgent group reported higher trust scores toward the AI system. This discrepancy suggests that while AI assistance can enhance user trust and perceived system reliability, excessive reliance on AI support might inadvertently reduce students opportunities for independent thinking, problemsolving, and deeper cognitive engagement. Previous research argues that overly scaffolded learning environments may lead learners to adopt passive learning behaviors, hindering the development of self-regulated learning skills and critical thinking abilities [35]. Our findings align with this perspective, indicating that participants who received substantial AI support might have become overly dependent on the systems guidance, thus limiting their autonomous exploration and cognitive effort during the learning process. To address this issue, future iterations of SRLAgent could implement adaptive fading strategies, gradually reducing AI support as learners demonstrate proficiency and confidence in targeted skills. For instance, the system first provides stronger initial scaffolding and progressively reduces guidance, fostering learners to progressively assume greater responsibility for their learning and engage deeper in the cognitive process of learning [53]. Additionally, incorporating Chain-of-Thought (CoT) or step-by-step interactive questioning techniques could promote deeper conceptual understanding. Such interactive questioning encourages learners to actively articulate their reasoning processes, thereby fostering more meaningful engagement with the learning material and reducing reliance on AI-generated answers."
        },
        {
            "title": "7.4 Limitation and Future Work\nOur study provides initial insights into how SRLAgent can support\ncollege students’ self-regulated learning (SRL) skills, engagement,\nand trust in AI-driven educational environments. Nevertheless,\nseveral limitations warrant consideration and highlight important\navenues for future research.",
            "content": "First, our relatively small sample size limited statistical power, potentially constraining the detection of significant differences, especially in measures of engagement and trust. Although descriptive trends indicated positive outcomes, future studies with larger samples would help clarify these preliminary findings and allow for more robust statistical conclusions. Second, the short-term nature of our intervention (a single learning session) might have restricted observable changes. Longitudinal studies are necessary to investigate sustained effects over time and to understand how prolonged interaction with SRLAgent might influence deeper reflective practices, long-term engagement, and evolving perceptions of AI trustworthiness. Third, our measures of trust and engagement relied primarily on quantitative self-report scales, which may not fully capture nuanced user perceptions and behaviors. Integrating qualitative approaches, such as interviews, think-aloud protocols, or behavioral analytics, would provide richer insights into how students perceive and interact with educational AI systems, contributing to more comprehensive understanding of learner experiences. Finally, our study focused on college students within specific learning context (understanding LLM agents). Future research should examine SRLAgents applicability across diverse educational settings, subjects, and learner demographics to assess its generalizability and adaptability. Exploring how different student populations engage with and benefit from SRL scaffolding and LLM-based feedback could yield valuable implications for inclusive and personalized educational technology design. In summary, addressing these limitations in future research will improve our understanding of SRL-supportive AI systems, inform the design of more effective educational technologies, and ultimately contribute to richer, more engaging, and trustworthy learning experiences."
        },
        {
            "title": "8 Conclusion\nIn this study, we designed and evaluated SRLAgent, an AI-powered\neducational system that integrates self-regulated learning (SRL)\nscaffolding and personalized feedback to improve learners’ SRL\nskills, engagement, and trust toward AI-supported learning en-\nvironments. Our findings demonstrate that SRLAgent effectively\npromotes learners’ abilities in the forethought and performance\nstages of Zimmerman’s SRL model, highlighting the value of ex-\nplicit goal-setting and real-time feedback mechanisms. Although",
            "content": "Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang improvements in the self-reflection dimension were limited, these results underscore the importance of comprehensive SRL support, including structured reflective activities, to fully realize the potential of educational AI technologies. Furthermore, descriptive trends indicate that SRLAgent may positively influence learner engagement and trust in AI systems, suggesting promising directions for future research and design improvements. However, the absence of statistically significant findings in these areas points to the need for larger-scale studies and more sensitive measures to capture nuanced behavioral and attitudinal changes. Overall, our work contributes valuable insights into how carefully designed SRL features and adaptive AI feedback can assist learners in developing essential regulatory skills and maintaining motivation. Future research should build upon these findings by exploring robust reflection supports, expanding participant samples, and incorporating multimodal data collection methods. Addressing these directions will advance our understanding of effective AI-assisted learning designs, ultimately fostering deeper and more sustained educational outcomes. SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, References [1] Alaa Abd-Alrazaq, Rawan AlSaad, Dari Alhuwail, Arfan Ahmed, Padraig Mark Healy, Syed Latifi, Sarah Aziz, Rafat Damseh, Sadam Alabed Alrazak, Javaid Sheikh, et al. 2023. Large language models in medical education: opportunities, challenges, and future directions. JMIR Medical Education 9, 1 (2023), e48291. [2] Ronald Perez Alvarez, Ioana Jivet, Mar Pérez-Sanagustin, Maren Scheffel, and Katrien Verbert. 2022. Tools designed to support self-regulated learning in online learning environments: systematic review. IEEE Transactions on Learning Technologies 15, 4 (2022), 508522. [3] Anthropic. [n. d.]. Claude. https://www.anthropic.com/claude [4] Drew Appleby. 2006. How do college freshmen view the academic differences between high school and college. In annual meeting of the Midwestern Psychological Association, Chicago, IL. Citeseer. [5] Daisy Arredondo and Terrance Rucinski. 1994. Using Reflective Journals and the Workshop Approach in University Classes To Develop Students SelfRegulated Learning. (1994). [6] Roger Azevedo and Jennifer Cromley. 2004. Does training on self-regulated learning facilitate students learning with hypermedia? Journal of educational psychology 96, 3 (2004), 523. [7] David Baidoo-Anu and Leticia Owusu Ansah. 2023. Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning. Journal of AI 7, 1 (2023), 5262. [8] Frederick Bail, Shuqiang Zhang, and Gary Tachiyama. 2008. Effects of self-regulated learning course on the academic performance and graduation rate of college students in an academic support program. Journal of college reading and learning 39, 1 (2008), 5473. [9] Gabriel Barata, Sandra Gama, Manuel Fonseca, and Daniel Gonçalves. 2013. Improving student creativity with gamification and virtual worlds. In Proceedings of the First International Conference on Gameful Design, Research, and Applications. 9598. [10] Henrik Bellhäuser, Thomas Lösch, Charlotte Winter, and Bernhard Schmitz. 2016. Applying web-based training to foster self-regulated learningEffects of an intervention for large numbers of participants. The Internet and Higher Education 31 (2016), 87100. [11] Jaclyn Broadbent. 2017. Comparing online and blended learners self-regulated learning strategies and academic performance. The Internet and Higher Education 33 (2017), 2432. [12] Jaclyn Broadbent and Walter Poon. 2015. Self-regulated learning strategies & academic achievement in online higher education learning environments: systematic review. The internet and higher education 27 (2015), 113. [13] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 18771901. [14] Raees Calafato. 2023. Charting the motivation, self-efficacy beliefs, language learning strategies, and achievement of multilingual university students learning Arabic as foreign language. Asian-Pacific Journal of Second and Foreign Language Education 8, 1 (2023), 20. [15] Chih-Ming Chen and Sheng-Hui Huang. 2014. Web-based reading annotation system with an attention-based self-regulated learning mechanism for promoting reading performance. British Journal of Educational Technology 45, 5 (2014), 959 980. [16] David Conley. 2008. Rethinking college readiness. New directions for higher education 2008, 144 (2008), 313. [17] Marcus Credé and Nathan Kuncel. 2008. Study habits, skills, and attitudes: The third pillar supporting collegiate academic performance. Perspectives on psychological science 3, 6 (2008), 425453. [18] Erhan Delen, Jeffrey Liew, and Victor Willson. 2014. Effects of interactivity and instructional scaffolding on learning: Self-regulation in online video-based environments. Computers & Education 78 (2014), 312320. [19] Amy Dent and Alison Koenka. 2016. The relation between self-regulated learning and academic achievement across childhood and adolescence: metaanalysis. Educational psychology review 28 (2016), 425474. [20] Sebastian Deterding, Dan Dixon, Rilla Khaled, and Lennart Nacke. 2011. From game design elements to gamefulness: defining\" gamification\". In Proceedings of the 15th international academic MindTrek conference: Envisioning future media environments. 915. [21] Charlotte Dignath and Gerhard B\"uttner. 2008. Components of fostering selfregulated learning among students. meta-analysis on intervention studies at primary and secondary school level. Metacognition and Learning 3, 3 (2008), 231264. https://doi.org/10.1007/s11409-008-9029-x [22] John Dunlosky and Katherine Rawson. 2012. Overconfidence produces underachievement: Inaccurate self evaluations undermine students learning and retention. Learning and Instruction 22, 4 (2012), 271280. [23] Binnur Ergen and Sedat Kanadlı. 2017. The effect of self-regulated learning strategies on academic achievement: meta-analysis study. Eurasian Journal of Educational Research 17, 69 (2017), 5574. [24] Google. [n. d.]. Introducing Gemini: our largest and most capable AI model. https: //blog.google/technology/ai/google-gemini-ai/ [25] Alex Goslen, Michelle Taub, Dan Carpenter, Roger Azevedo, Jonathan Rowe, and James Lester. 2024. Leveraging student planning in game-based learning environments for self-regulated learning analytics. Journal of Educational Psychology (2024). [26] Juho Hamari, Jonna Koivisto, and Harri Sarsa. 2014. Does gamification work? literature review of empirical studies on gamification. In 2014 47th Hawaii international conference on system sciences. Ieee, 30253034. [27] Karen Harris and Steve Graham. 1999. Programmatic intervention research: Illustrations from the evolution of self-regulated strategy development. Learning Disability Quarterly 22, 4 (1999), 251262. [28] Ting-Chia Hsu, Ching Chang, and Tien-Hsiu Jen. 2024. Artificial intelligence image recognition using self-regulation learning strategies: effects on vocabulary acquisition, learning anxiety, and learning behaviours of English language learners. Interactive Learning Environments 32, 6 (2024), 30603078. [29] Sanna Järvelä and Allyson Hadwin. 2013. New frontiers: Regulating learning in CSCL. Educational psychologist 48, 1 (2013), 2539. [30] Jiun-Yin Jian, Ann Bisantz, and Colin Drury. 2000. Foundations for an empirically determined scale of trust in automated systems. International journal of cognitive ergonomics 4, 1 (2000), 5371. [31] Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnemann, Eyke Hüllermeier, et al. 2023. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and individual differences 103 (2023), 102274. [32] Bokyeong Kim, Hyungsung Park, and Youngkyun Baek. 2009. Not just fun, but serious strategies: Using meta-cognitive strategies in game-based learning. Computers & Education 52, 4 (2009), 800810. [33] Minsol Kim, Aliea Nallbani, and Abby Rayne Stovall. 2024. Exploring LLMbased Chatbot for Language Learning and Cultivation of Growth Mindset. In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI EA 24). Association for Computing Machinery, New York, NY, USA, Article 609, 5 pages. https://doi.org/10.1145/3613905.3648628 [34] Saskia Kistner, Katrin Rakoczy, Barbara Otto, Charlotte Dignath-van Ewijk, Gerhard Büttner, and Eckhard Klieme. 2010. Promotion of self-regulated learning in classrooms: Investigating frequency, quality, and consequences for student performance. Metacognition and learning 5 (2010), 157171. [35] Kenneth Koedinger, Albert Corbett, and Charles Perfetti. 2012. The Knowledge-Learning-Instruction framework: Bridging the science-practice chasm to enhance robust student learning. Cognitive science 36, 5 (2012), 757798. [36] Jonna Koivisto and Juho Hamari. 2019. The rise of motivational information systems: review of gamification research. International journal of information management 45 (2019), 191210. [37] Richard Landers. 2014. Developing theory of gamified learning: Linking serious games and gamification of learning. Simulation & gaming 45, 6 (2014), 752768. [38] Manuela Leidinger and Franziska Perels. 2012. Training self-regulated learning in the classroom: Development and evaluation of learning materials to train self-regulated learning during regular mathematics lessons at primary school. Education Research International 2012, 1 (2012), 735790. [39] Patrick Liborius, Henrik Bellhäuser, and Bernhard Schmitz. 2019. What makes good study day? An intraindividual study on university students time investment by means of time-series analyses. Learning and Instruction 60 (2019), 310321. [40] Jenni Majuri, Jonna Koivisto, and Juho Hamari. 2018. Gamification of education and learning: review of empirical literature. GamiFIN (2018), 1119. [41] Carolina Mega, Lucia Ronconi, and Rossana De Beni. 2014. What makes good student? How emotions, self-regulated learning, and motivation contribute to academic achievement. Journal of educational psychology 106, 1 (2014), 121. [42] Inge Molenaar. 2022. The concept of hybrid human-AI regulation: Exemplifying how to support young learners self-regulated learning. Computers and Education: Artificial Intelligence 3 (2022), 100070. [43] Inge Molenaar, Susanne de Mooij, Roger Azevedo, Maria Bannert, Sanna Järvelä, and Dragan Gašević. 2023. Measuring self-regulated learning and the role of AI: Five years of research using multimodal multichannel data. Computers in Human Behavior 139 (2023), 107540. [44] Deepika Nambiar, Johnson Alex, and Dan Isaac Pothiyil. 2022. Development and validation of academic self-regulated learning questionnaire (ASLQ). International Journal of Behavioral Sciences 16, 2 (2022), 8995. [45] Davy Tsz Kit Ng, Chee Wei Tan, and Jac Ka Lok Leung. 2024. Empowering student self-regulated learning and science education through ChatGPT: pioneering pilot study. British Journal of Educational Technology 55, 4 (2024), 13281353. [46] Scott Nicholson. 2015. recipe for meaningful gamification. Gamification in education and business (2015), 120. [47] Heather OBrien and Elaine Toms. 2010. The development and evaluation of survey to measure user engagement. Journal of the American Society for Information Science and Technology 61, 1 (2010), 5069. Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang [48] Wilk Oliveira, Juho Hamari, Lei Shi, Armando Toda, Luiz Rodrigues, Paula Palomino, and Seiji Isotani. 2023. Tailored gamification in education: literature review and future agenda. Education and Information Technologies 28, 1 (2023), 373406. [49] Emmanuel Opara, Adalikwu Mfon-Ette Theresa, and Tolorunleke Caroline Aduke. 2023. ChatGPT for teaching, learning and research: Prospects and challenges. Opara Emmanuel Chinonso, Adalikwu Mfon-Ette Theresa, Tolorunleke Caroline Aduke (2023). ChatGPT for Teaching, Learning and Research: Prospects and Challenges. Glob Acad Humanit Soc Sci 5 (2023). [50] OpenAI. [n. d.]. ChatGPT. https://openai.com/chatgpt. [Accessed: 2025-04-09]. [51] Daniel Oppenheimer, Trent Cash, and AE Connell Pensky. 2024. Youve got AI friend in me: LLMs as collaborative learning partners. [52] Scott Paris and Alison Paris. 2003. Classroom applications of research on self-regulated learning. In Educational Psychology. Routledge, 89101. [53] Reinhard Pekrun. 2006. The control-value theory of achievement emotions: Assumptions, corollaries, and implications for educational research and practice. Educational psychology review 18 (2006), 315341. [54] Paul Pintrich. 2004. conceptual framework for assessing motivation and self-regulated learning in college students. Educational psychology review 16 (2004), 385407. [55] Bart Rienties, Dirk Tempelaar, Quan Nguyen, and Allison Littlejohn. 2019. Unpacking the intertemporal impact of self-regulation in blended mathematics environment. Computers in Human Behavior 100 (2019), 345357. [56] Ido Roll and Philip Winne. 2015. Understanding, evaluating, and supporting self-regulated learning using learning analytics. Journal of Learning Analytics 2, 1 (2015), 712. [57] Nicolas Scharowski, Sebastian A. C. Perrig, Lena Fanya Aeschbach, Nick von Felten, Klaus Opwis, Philipp Wintersberger, and Florian Brühlmann. 2025. To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI. arXiv:2403.00582 [cs.HC] https://arxiv.org/abs/2403.00582 [58] Gregory Schraw, Kent Crippen, and Kendall Hartley. 2006. Promoting selfregulation in science education: Metacognition as part of broader perspective on learning. Research in science education 36 (2006), 111139. [59] Dale Schunk. 1996. Goal and self-evaluative influences during childrens cognitive skill learning. American educational research journal 33, 2 (1996), 359 382. [60] Dale Schunk and Barry Zimmerman. 2011. Handbook of self-regulation of learning and performance. Taylor & Francis. [61] Katie Seaborn and Deborah Fels. 2015. Gamification in theory and action: survey. International Journal of human-computer studies 74 (2015), 1431. [62] Yu Song and Jan D. Vermunt. 2021. comparative study of learning patterns of secondary school, high school and college students. Studies in Educational Evaluation 68 (2021), 100958. https://doi.org/10.1016/j.stueduc.2020.100958 [63] John Stamper, Ruiwei Xiao, and Xinying Hou. 2024. Enhancing llm-based feedback: Insights from intelligent tutoring systems and the learning sciences. In International Conference on Artificial Intelligence in Education. Springer, 3243. [64] Maria Theobald. 2021. Self-regulated learning training programs enhance university students academic performance, self-regulated learning strategies, and motivation: meta-analysis. Contemporary Educational Psychology 66 (2021), 101976. [65] Andrea Venezia and Laura Jaeger. 2013. Transitions from High School to College. The Future of Children 23, 1 (2013), 117136. http://www.jstor.org/stable/23409491 [66] Zhengpei Wang, Xue Yang, and Xiaolu Zhang. 2020. Relationships among boredom proneness, sensation seeking and smartphone addiction among Chinese college students: Mediating roles of pastime, flow experience and self-regulation. Technology in Society 62 (2020), 101319. [67] Qingsong Wen, Jing Liang, Carles Sierra, Rose Luckin, Richard Tong, Zitao Liu, Peng Cui, and Jiliang Tang. 2024. AI for education (AI4EDU): Advancing personalized education with LLM and adaptive learning. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 67436744. [68] Zhihong Xu, Yingying Zhao, Jeffrey Liew, Xuan Zhou, and Ashlynn Kogut. 2023. Synthesizing research evidence on self-regulated learning and academic achievement in online and blended learning environments: scoping review. Educational Research Review 39 (2023), 100510. [69] Nilüfer Zeybek and Elif Saygı. 2024. Gamification in education: Why, where, when, and how?A systematic review. Games and Culture 19, 2 (2024), 237264. [70] Zheyuan Zhang, Daniel Zhang-Li, Jifan Yu, Linlu Gong, Jinchang Zhou, Zhanxin Hao, Jianxiao Jiang, Jie Cao, Huiqin Liu, Zhiyuan Liu, et al. 2024. Simulating classroom education with llm-empowered agents. arXiv preprint arXiv:2406.19226 (2024). [71] Barry Zimmerman. 2002. Becoming self-regulated learner: An overview. Theory into practice 41, 2 (2002), 6470. [72] Akane Zusho. 2017. Toward an integrated model of student learning in the college classroom. Educational Psychology Review 29 (2017), 301324. SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, Prompt Design for Planning Agent System: You are Task Planning Assistant specializing in Self-Regulated Learning strategies. Your role is to help students develop effective task planning skills by analyzing subtasks, suggesting optimal ordering, and providing strategic guidance. Format your responses with clear structure and reasoning to model effective planning processes. {chatHistory} User: # Task Planning Request Im working on the Self-Regulated Learning (SRL) task planning phase. Please help me organize the following subtasks efficiently while developing my SRL thinking. ## Considerations: * Task dependencies and logical sequence * Resource utilization efficiency * Time and difficulty balance ## Subtask List: 1. {Subtask title} * Description: {Subtask description} * Estimated time: {Time estimate} 2. {Additional subtasks...} ## Response Format Requirements: 1. Optimal Sequence: begin{verbatim} <START> Comma-separated task numbers in optimal order (e.g., 3,1,5,2,4) <END> end{verbatim} 2. Reasoning: Explain the rationale behind this sequence 3. Completion Strategy: Provide recommendations for effective task execution Note: The <START> and <END> tags are required for automated processing. Figure 7: Planning Agent Prompt Configuration Appendix A.1 Prompt Configurations for LLM Agents In this section, we illustrate the diverse prompts sent to each agent in SRLAgent. Prompt Design for Reflection Agent System: You are Reflection Agent specializing in Self-Regulated Learning (SRL) strategies. Your role is to help learners develop effective reflection skills by analyzing their task performance, identifying strengths and areas for improvement, and guiding them through meaningful self-evaluation. When providing reflection guidance: 1. Focus on specific task outcomes and SRL strategies used 2. Highlight connections between planning, execution, and results 3. Encourage metacognitive thinking about learning processes 4. Suggest actionable improvements for future learning tasks Keep your feedback concise, constructive, and clearly structured. {chatHistory} User: # Reflection Request Im in the reflection phase of my Self-Regulated Learning (SRL) process. Please help me analyze my task performance and generate meaningful insights. ## Task Information: * Task Title: {Task title} * Task Description: {Task description} ## Subtask Completion Details: {Subtask outcomes will be listed here} ## Reflection Requirements: 1. Summary: cise assessment of task execution 2. SRL Strategy Analysis: Identify which self-regulated learning strategies were effectively applied 3. Learning Insights: Highlight key takeaways and potential improvements for future tasks Please focus on both the task outcomes and the learning process itself, helping me develop stronger selfregulation skills. Performance (30 words maximum) Provide conFigure 8: Reflection Agent Prompt Configuration Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang Table 2: Questionnaire for SRL skills learn by teaching others. set targets before start studying. Statement study in suitable place where can concentrate. When am reading, stop once in while to review what have read. make necessary changes in study plan to improve learning. dont feel motivated to study difficult subjects. split my portions while studying. go through the study material carefully to understand it properly. Before start studying, make schedule. try to strengthen the strategies that worked for me previously. study in manner that makes it more interesting/enjoyable. use keywords/abbreviations to improve learning. No. 1 2 3 4 5 6 7 8 9 10 11 When my studies are affected, try to identify my mistakes. 12 13 14 While am studying, try to get rid of any distractions that are around me. 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 While studying, utilize different sources of information (lectures, reading, and discussions). 31 32 33 34 When study, try to understand the concepts. 35 36 keep track of study areas where am lacking. dont have the habit of maintaining notes. organize the study material before start studying. After my exam reflect upon areas could have done better. make notes to simplify learning. try to learn from the mistakes made in the exam. constantly assess the amount of effort put into my studies. memorize key words to remind me of important concepts. Before study, make an outline of the content. focus more on difficult portions while studying. organize my time according to the difficulty of the task. make sure that complete the portions on time. If miss class, take the help of others to cover the portions. keep my assignments and class notes complete. motivate myself to do better than before. set goal for how much to study each day. make simple charts, diagrams, or tables while studying. seek help when unable to understand concept. refer to my class notes whenever necessary. make sure that attend class regularly. Table 3: AI Trust Questionnaire Items No. 1 2 3 4 5 6 7 8 9 10 11 12 Statement The AI is deceptive (R) The AI behaves in an underhanded manner (R) am suspicious of the AIs intent, action, or outputs (R) am wary of the AI (R) The AIs actions will have harmful or injurious outcome (R) am confident in the AI The AI provides security The AI has integrity The AI is dependable The AI is reliable can trust the AI am familiar with the AI SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance Preprint, 2025, Prompt Design for Chatting Agent Prompt Design forPaper Writing Agent System: You are Professor {professor name} from the {department} at {university}, leading expert in the field of {research field}. Your research interests in {specific area} include {research direction 1}, {research direction 2},... You provide academic guidance in your field, including research directions, paper writing, and experiment design. You are welcoming students and answering their questions. {chatHistory} User: {user question} Figure 10: Chatting Agent Prompt Configuration Prompt Design for Paper Review Agent System: You are an academic review expert. Please help players summarize the given paper abstract. Players are performing the execution step in selfregulated learning (SRL) strategy, and the abstract is the planning step. Use critical thinking to help players understand the research ideas, core contributions, highlights, advantages and disadvantages of the paper. No more than 30 words. Please be concise, constructive, and clearly structured. {chatHistory} User: {combinedInput} Where combinedInput may include: Question: {question} Summary: {summary} Paper Content: {paperContent} Figure 11: Paper Review Agent Prompt Configuration System: You are an expert in adaptive paper writing. Your role is to assist the player in improving their adaptive writing skills, including structure, organization, and clarity. Focus on the adaptive writing process and critical thinking strategies. Provide step-by-step guidance and examples where necessary. Reply with no more than 50 words. Be concise and structured. Pay attention to proper citation and referencing formats. {chatHistory} User: {referenceContent} Title: {title} Body: {body} Question: {question} {reference content structure: If available, referenceContent will be formatted as: \"Previous Task Outcomes: [Previous work and outcomes from related subtasks that should inform the current writing task. May include research findings, literature reviews, methodology descriptions, or other academic content the player has already produced.]\" } Figure 12: Paper Writing Agent Prompt Configuration Prompt Design for Quiz Tutor Agent System: You are an educational support agent specializing in university-level academic content. Your role is to provide concise, helpful guidance when students encounter difficulties with different question types. The student is currently in the Performance phase of Self-Regulated Learning (SRL), working on knowledge acquisition subtasks. Your support should reinforce effective learning strategies while providing just enough guidance to overcome obstacles. Keep explanations brief (under 20 words) while maintaining clarity and educational value. Focus on promoting understanding rather than simply providing answers. {chatHistory} User: # Question Support Request need help with {question type}. {question details} Please provide targeted guidance that helps me understand the conceptual relationships without giving away complete answers. Focus on promoting learning rather than simply providing solutions. {condition {question details} based on question type: If matching question: \"Based on the concept category {concept category} and the incorrect connections Ive made, please provide targeted hint.\" If multiple choice: \"Explain why {correct option}ïs the correct definition of {concept name}\" If ordering/sequencing: \"Hint: {current item at first error position} should be placed at different position in the {ordering topic} timeline.\" If true/false: \"Briefly explain why the statement {statement} is {true/false judgment}\" } Figure 9: Quiz Tutor Agent Prompt Configuration Preprint, 2025, Wentao Ge, Yuqing Sun, Ziyan Wang, Haoyue Zheng, Weiyang He, PiaoHong Wang, Qianyu Zhu, and Benyou Wang"
        }
    ],
    "affiliations": [
        "City University of Hong Kong China",
        "The Chinese University of Hong Kong, Shenzhen China"
    ]
}