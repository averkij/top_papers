{
    "paper_title": "Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context",
    "authors": [
        "Yoav Gur-Arieh",
        "Mor Geva",
        "Atticus Geiger"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "A key component of in-context reasoning is the ability of language models (LMs) to bind entities for later retrieval. For example, an LM might represent \"Ann loves pie\" by binding \"Ann\" to \"pie\", allowing it to later retrieve \"Ann\" when asked \"Who loves pie?\" Prior research on short lists of bound entities found strong evidence that LMs implement such retrieval via a positional mechanism, where \"Ann\" is retrieved based on its position in context. In this work, we find that this mechanism generalizes poorly to more complex settings; as the number of bound entities in context increases, the positional mechanism becomes noisy and unreliable in middle positions. To compensate for this, we find that LMs supplement the positional mechanism with a lexical mechanism (retrieving \"Ann\" using its bound counterpart \"pie\") and a reflexive mechanism (retrieving \"Ann\" through a direct pointer). Through extensive experiments on nine models and ten binding tasks, we uncover a consistent pattern in how LMs mix these mechanisms to drive model behavior. We leverage these insights to develop a causal model combining all three mechanisms that estimates next token distributions with 95% agreement. Finally, we show that our model generalizes to substantially longer inputs of open-ended text interleaved with entity groups, further demonstrating the robustness of our findings in more natural settings. Overall, our study establishes a more complete picture of how LMs bind and retrieve entities in-context."
        },
        {
            "title": "Start",
            "content": "5 2 0 2 7 ] . [ 1 2 8 1 6 0 . 0 1 5 2 : r a"
        },
        {
            "title": "Preprint",
            "content": "MIXING MECHANISMS: HOW LANGUAGE MODELS RETRIEVE BOUND ENTITIES IN-CONTEXT Yoav Gur-Arieh, Mor Geva, Atticus Geiger Blavatnik School of Computer Science and AI, Tel Aviv University Pr(Ai)2R Group Goodfire"
        },
        {
            "title": "ABSTRACT",
            "content": "A key component of in-context reasoning is the ability of language models (LMs) to bind entities for later retrieval. For example, an LM might represent Ann loves pie by binding Ann to pie, allowing it to later retrieve Ann when asked Who loves pie? Prior research on short lists of bound entities found strong evidence that LMs implement such retrieval via positional mechanism, where Ann is retrieved based on its position in context. In this work, we find that this mechanism generalizes poorly to more complex settings; as the number of bound entities in context increases, the positional mechanism becomes noisy and unreliable in middle positions. To compensate for this, we find that LMs supplement the positional mechanism with lexical mechanism (retrieving Ann using its bound counterpart pie) and reflexive mechanism (retrieving Ann through direct pointer). Through extensive experiments on nine models and ten binding tasks, we uncover consistent pattern in how LMs mix these mechanisms to drive model behavior. We leverage these insights to develop causal model combining all three mechanisms that estimates next token distributions with 95% agreement. Finally, we show that our model generalizes to substantially longer inputs of open-ended text interleaved with entity groups, further demonstrating the robustness of our findings in more natural settings. Overall, our study establishes more complete picture of how LMs bind and retrieve entities in-context."
        },
        {
            "title": "INTRODUCTION",
            "content": "Language models (LMs) are known for their ability to perform in-context reasoning (Brown et al., 2020), and fundamental to this capability is the task of connecting related entities in textknown as bindingto construct representation of context that can be queried for next token prediction. However, LMs are also known for struggling in reasoning tasks over long contexts (Liu et al., 2024; Levy et al., 2024). In this work, we conduct mechanistic investigation into the internals of LMs to better understand how they bind entities in increasingly complex settings. Neural networks ability to bind arbitrary entities was central issue in connectionist models of cognition (Touretzky & Minton, 1985; Fodor & Pylyshyn, 1988; Smolensky, 1990) and has reemerged in the era of LMs as target phenomenon for mechanistic interpretability research (Davies et al., 2023; Prakash et al., 2024; 2025; Feng & Steinhardt, 2024; Feng et al., 2024; Wu et al., 2025). For example, to represent the text Pete loves jam and Ann loves pie, an LM will bind Pete to jam and Ann to pie. This enables the LM to answer questions like Who loves pie? by querying the bound entities to retrieve the answer (Ann). The prevailing view is that LMs retrieve bound entities using positional mechanism (Dai et al., 2024; Prakash et al., 2024; 2025), where the query entity (pie) is used to determine the in-context position of Ann loves piein this case, the second clause after Pete loves jamwhich is dereferenced to retrieve the answer Ann. In this work, we show that position-based retrieval holds only for simple settings. This mechanism is unreliable for the middle positions in long lists of entity groupsa pattern that echoes the lostin-the-middle effect (Liu et al., 2024) in LMs as well as primacy and recency biases in both humans (Ebbinghaus, 1913; Miller & Campbell, 1959) and LMs (Janik, 2024). To compensate for this noise,"
        },
        {
            "title": "Preprint",
            "content": "Figure 1: An illustration of the three mechanisms for retrieving bound entities in-context. We find that as models process inputs with groups of entities: (A) binding information of three types positional, lexical, reflexiveis encoded in the entity tokens of each group, (B) this binding information is jointly used to retrieve entities in-context, and (C) it is possible to separate the three binding signals with counterfactual patching. The counterfactual input is designed such that patching activations to the LM run on the original input results in the positional, lexical, and reflexive mechanisms predicting different entities (See 3.2). LMs supplement the positional mechanism with lexical mechanism, where the query entity (pie) is used to retrieve its bound counterpart (Ann), and reflexive mechanism, where the queried entity (Ann) is retrieved with direct pointer that was previously retrieved via the query entity (pie). In series of ablation experiments, we show that all three mechanisms are necessary to develop an accurate causal model of the next token distribution (Pˆıslar et al., 2025), and that their interplay depends on the positions the query entity (pie) and the retrieved entity (Ann). This mixture of mechanisms is robustly present across (1) the Llama, Gemma, and Qwen model families, (2) model sizes within those families ranging from 2 to 72 billion parameters, and (3) ten variable binding tasks. By better understanding this mechanism, we take step toward explaining both the strengths and the persistent fragilities of LLMs in long-context settings, as well as the fundamental mechanisms that support in-context reasoning. We release our code and dataset of binding tasks at https: //github.com/yoavgur/mixing-mechs."
        },
        {
            "title": "2 PROBLEM SETUP AND PRIOR WORK",
            "content": "Entity Binding Tasks In our experiments, we design number of templatic in-context reasoning tasks with similar structure to the example from the introduction, i.e., Pete loves jam, Ann loves pie. Who loves pie? Formally, task consists of: 1. Entity Roles: Disjoint sets of entities E1, . . . , Em that will fill particular roles in templatic text. For example, the set E1 might be names of people {Ann, Pete, Tim, . . . }, and the set E2 might be foods and drinks {ale, jam, pie, . . . }. 2. Entity Groups: An entity group is tuple E1 Em containing entities that will be placed within the same clause in template. For example, we could set G1 = (Pete, jam) and G2 = (Ann, pie). For convenience, we define as binding matrix wherein Gj denotes the j-th entity in the i-th entity group. qentity , and the target entity = Gqgroup 3. template (T ): function that takes as input binding matrix G, the query entity = Gqgroup tentity . Here qgroup is positional index of the entity group containing the target and query, and tentity = qentity index the positions of the target and query entities within that group, respectively. See for more details and examples. Continuing our example, define (G, q, t) = G1 1 loves G2 1, G1 2 loves G2 2. (cid:26)Who loves q? What does love? tentity == 1 tentity == 2 and observe that (cid:16) (cid:20)Pete Ann (cid:21) jam pie (cid:17) , pie, Ann = Pete loves jam, Ann loves pie. Who loves pie? For our experiments, the binding matrix will consist of distinct entities. Interchange Interventions To probe the mechanisms an LM uses to bind and retrieve entities, we employ interchange interventions (Vig et al., 2020; Geiger et al., 2020; Finlayson et al., 2021; Geiger et al., 2021), the standard tool for prior work on binding and retrieval (Davies et al., 2023; Feng & Steinhardt, 2024; Prakash et al., 2024; 2025; Wu et al., 2025). These interventions allow us to identify which hidden states are causally relevant for the model in entity binding, by running the LM on paired examples an original input and counterfactual input and replacing selected components, e.g., residual stream vectors, in the original run with those from the counterfactual. Causal Abstraction We develop causal model of LM internals (Geiger et al., 2021; 2025b;a) that predicts the LM next token distribution using mixture of three mechanisms (See 4). To test our hypotheses, we construct dataset of paired originals and counterfactuals such that an interchange intervention on the causal model results in the positional, lexical and reflexive mechanisms increasing the probability of distinct tokens. To evaluate our proposed causal model and various ablations, we perform interchange interventions on the causal model and the LM, measuring the similarity between the next token distribution of the two models, and average across dataset. Prior Studies of Entity Binding in LMs Previous work paints picture of how entity binding and retrieval is performed by LMs. First, LMs bind together group of entities by aggregating information about all entities in the entity token at the last position in the group. By co-locating information about entities in the residual stream of single token, the LM can later on use attention to retrieve information about one bound entity conditional on second bound entity (Feng & Steinhardt, 2024; Feng et al., 2024; Dai et al., 2024; Prakash et al., 2024; Wu et al., 2025), an algorithmic motif that Prakash et al. (2025) dub lookback mechanism. We study the pointers used in the lookback mechanism that bring the next token prediction into the residual stream of the final token. We include experiments on the addresses contained in the residual streams of the bound entity tokens, as well as the query token, in B.5. Prior works identify positional mechanism that is utilized in entity binding (described in detail in 3.1), but either evaluate it only in narrow settings (Prakash et al., 2025) or achieve low causal"
        },
        {
            "title": "Preprint",
            "content": "Figure 2: Results from interchange interventions on gemma-2-2b-it over counterfactual dataset with three entities per group (m = 3) (See Figure 1 and 3.2). Outputs predicted by the positional, lexical and reflexive mechanisms are shown in dark blue, green and orange. Left: Distribution of effects for three representative entity group indices (first, middle, and last) with tentity = 3. At layers 1618, the last token position carries binding information used for retrieval. Right: Distribution of effects for all indices at layer 18 for tentity {1, 2, 3}, i.e., the question can be about any of the three entities in each clause. U-shaped curve emerges: first and last indices rely more on the positional mechanism, while middle indices rely more on the lexical and reflexive mechanisms. See for replication across models and tasks, and Figure 18 for plots using the original prompt as the x-axis. faithfulness in predicting model behavior solely using this mechanism (Prakash et al., 2024; Dai et al., 2024). (Feng & Steinhardt, 2024; Prakash et al., 2025) restrict their analysis to queries of the final token in group (tentity = m) and to very small contexts (n 2, 3). Prakash et al. (2024) and Dai et al. (2024) find positional mechanism in longer contexts (n = 7), but with low faithfulness."
        },
        {
            "title": "3 THREE MECHANISMS FOR RETRIEVING BOUND ENTITIES",
            "content": "In this section, we define the positional mechanism and propose two alternative mechanisms (3.1), all three of which make distinct claims about the causal structure of the LM. Then, we design dataset with pairs of original and counterfactual inputs, such that each of the three mechanisms makes distinct predictions under an interchange intervention with the pair (3.2). Last, we perform interchange interventions on different layers of the last token residual stream of the LM and visualize the results so we can observe the interplay between the three mechanisms in the counterfactual behavior of the LM (3.3). In our experiments, we evaluate nine modelsgemma-2-{2b/9b/27b}- it, qwen2.5-{3b/7b/32b/72b}-it, and llama-3.1-{8b/70b}-iton two binding tasks, boxes and music (see Appendix Table 1). For gemma-2-2b-it and qwen2.5-7b-it, we evaluate on all ten binding tasks. 3.1 THE POSITIONAL MECHANISM AND TWO ALTERNATIVES The prevailing view is that bound entities are retrieved with positional mechanism, but we propose two alternatives: lexical and reflexive mechanisms. The positional, lexical, and reflexive mechanisms are represented as causal models P, L, and that each have single intermediate variables , L, and R, respectively, used to retrieve an entity from context as the output."
        },
        {
            "title": "Preprint",
            "content": "The Positional Mechanism Prior work provides evidence that positional mechanism is used to retrieve an entity from group via the groups positional index (Dai et al., 2024; Prakash et al., 2024; 2025). The model indexes the group containing the query entity (P := qgroup), and its output mechanism retrieves the target entity from the group at index qgroup. In Figure 1, we have = 4 when no intervention is performed on the LM and the target entity tea is retrieved from position 4, but after the intervention 2 the entity jam at the second position is retrieved. Although existing evidence shows that the positional mechanism explains LM behavior in settings with two or three entity groups (Prakash et al., 2025), it does not generalize. When more groups are introduced, the evidence is weaker (Prakash et al., 2024; Dai et al., 2024). Our goal is to investigate the failure modes of the positional mechanism as more entity groups are introduced, and to that end we propose two alternative hypotheses for how LMs implement binding. The Lexical Mechanism The lexical mechanism is perhaps the most intuitive solution: output the bound entity from the group containing the queried entity. The causal model stores the query entity (L := q) and the output mechanism retrieves the target entity from the group containing q. In Figure 1, we have = Tim when no intervention is performed on the LM and the output mechanism retrieves the entity tea from the group with Tim. However, after the intervention Ann, the entity ale is retrieved from the group with Ann. The Reflexive Mechanism The reflexive mechanism retrieves an entity with direct, selfreferential pointeroriginating from that entity and pointing back to it. However, if this signal is patched into context where the token is not present, the mechanism fails. The model stores the target entity (R := t) and the output mechanism retrieves the entity if it appears in context. In Figure 1, we have = tea when no intervention is performed and the entity tea is retrieved, but after the intervention pie, the entity pie is retrieved because it appears in the original input. The reflexive mechanism is an unintuitive solution, until one considers that the architecture of an autoregressive LM allows attention to only look from right to left. When the query occurs after target in an entity group, i.e., tentity < qentity, the lexical mechanism is not possible. In the text Tim loves tea, the entity tea cannot be copied backwards to the residual stream of Tim so that the lexical mechanism can answer Who loves tea? Therefore, an earlier mechanism in the LM must first retrieve an absolute pointer that is in turn used to retrieve the bound entity token. 3.2 DESIGNING COUNTERFACTUAL INPUTS TO DISTINGUISH THE THREE MECHANISMS We designed dataset of paired original and counterfactual inputs such that the positional, lexical, and reflexive mechanisms will each make distinct predictions when an interchange intervention is performed on their respective intermediate variables, , L, and R. Counterfactual Design Figure 1 displays pair of original and counterfactual inputs that distinguish our three mechanisms (further detailed in Appendix Table 1). We illustrate this with the following example. Define the original and counterfactual binding matrices and respectively: = ale Ann jam Joe pie Pete Tim tea = ale Joe pie Ann jam Pete Tim tea (1) We can then use the template from 2 such that for these binding matrices, (G, Tim, tea) yields the original input in Figure 1 and (G, Ann, pie) yields the counterfactual input. Each of the three mechanisms produces different output after an interchange intervention on this pair of inputs: 1. An interchange intervention on in would output the entity at the counterfactual querys position. Since group = 2 for Ann in G, this sets 2, and the output becomes jam. 2. An interchange intervention on in would output the entity in the original input bound to the query entity in the counterfactual input. Since the query entity is now Ann, the mechanism queries the group containing Ann in and outputs the bound entity ale. 3. An interchange intervention on in would follow the direct pointer established in the counterfactual input. In this case, the pointer is to the token pie, which exists in the original input, and so the mechanism outputs pie."
        },
        {
            "title": "Preprint",
            "content": "Figure 3: The positional mechanism is diffuse for middle entity groups. Left: Confusion matrix (%) of the patched positional index vs. gemma-2-2b-its prediction after an interchange intervention (as in Figure 1). Counterfactual predictions cluster near the position promoted by the positional mechanism, decaying with distance. Only the mixed and positional patch effects from Figure 2 are shown; see Figure 28 for other models and tasks. Right: Mean logit distributions with iP = 6, iR = 14, and iL varied, illustrating interaction between the three mechanisms. The lexical and reflexive signals form one-hot peaks, while the positional is broader and more diffuse. These mechanisms also show additive and suppressive effects. See Figures 21, 22, and 23 for more distributions. Each of these three outputs is distinct from the actual output tea for the original input, which means the dataset also distinguishes the three mechanisms from no intervention being performed. Let iP , iL, and iR be indices of the entity groups queried by the positional, lexical, and reflexive mechanisms, e.g., iP = 2, iL = 1, and iR = 3 in Figure 1 after patching. In our counterfactual datasets, each of the three mechanisms can predict any position in the list of entity groups from the original input, i.e., iP , iL, and iR vary freely from 1 to n. For details and task templates, see A. relevant remaining confounder is that the reflexive mechanism predicts the output that is the target entity in the counterfactual input, meaning this dataset cannot distinguish the pointer used by reflexive mechanism from the actual next token prediction. In B.7 and C, we construct separate counterfactual dataset where the reflexive mechanism attempts to dereference token that does not occur in the original input and fails. We further validate this with attention knockout experiments, confirming that the model indeed relies on reflexive mechanism for dereferencing the target entity. 3.3 INTERVENTION EXPERIMENTS We find experimentally that information used to retrieve bound entity is accumulated in the last token residual stream across subset of layers. In Figure 2, we show the results of interchange interventions on gemma-2-2b-it across the layers of the last token residual stream. We see that in layers 1618 the model accumulates binding information in the last token position. Therefore, we conduct our experiments on the last layer before retrieval starts, denoted as ℓ, which is different for each of the nine models we test, but consistent across tasks for given model (see B.6 for more details). We measure the next token distribution produced by the model under intervention and compare it against the possible outputs for the three mechanisms. We aggregate and visualize the results of these intervention experiments in Figures 2 and 3. The positional mechanism weakens for middle positions. We can see plainly in Figure 2 that the positional mechanism controls behavior solely when the positional index is at the beginning or end of the sequence of = 20 entity groups. In middle entity groups, however, its effect becomes minimal, accounting only for 20% of the models behavior. Further analysis of the cases not explained by any of the mechanismsdubbed mixed in the plotreveals that these predictions are distributed near the positional index (Figure 3). Additionally, when collecting the mean logit distributions across many samples and fixing the positional index, we see that in the first and last positional indices it induces"
        },
        {
            "title": "Preprint",
            "content": "a strong and concentrated distribution around that index. However, in middle indices we see this distribution become wide and diffuse (Appendix Figure 9). Thus, the positional mechanism becomes unreliable in middle indices and cannot be used as the sole mechanism for retrieval. We show in B.3 how this effect emerges as n, i.e., the total number of entity groups in context, increases, and in we disambiguate the effect of increasing from that of increasing sequence length. The lexical and reflexive mechanisms are modulated based on target entity position. Observe in Figure 2 that when the positional mechanism is unreliable for middle positions, the lexical and reflexive mechanisms come into play. However, which of these two alternate mechanisms contribute more depends on the location of the target entity within the entity group, denoted as tentity. When the target is at the beginning of the group (tentity = 1), the reflexive mechanism is used (as discussed in 3.1). When the target is at the end (tentity = 3), the lexical mechanism is primarily used. Finally, when the target is in the middle (tentity = 2), both mechanisms are used to differing extents. The three mechanisms have complex interplay. We can see in Figure 3 the interplay between the three mechanism when the positional and reflexive indices are fixed to iP = 6 and iR = 14 while the lexical index iL is iterated over range of values. First, the logit distributions clearly reveal the contributions of each mechanism, with distinct spike appearing at each index. These spikes, however, behave differently. In line with Figure 3, the positional index produces wide, diffuse distribution, whereas the lexical and reflexive indices produce sharp, one-hot peaks. Next, we observe that the mechanisms interact through pattern of competitive synergy, meaning that they both boost and suppress one another. When the lexical index is close to the positional index, the lexical contribution is amplified while the positional contribution is weakened; when they are farther apart, neither affects the other. In contrast, when the lexical index is close to the reflexive index, the lexical contribution is suppressed by the reflexive one. Interventions on bound entity tokens provide similar results. To understand the residual stream of the bound entity tokens themselves, we design more datasets of original-counterfactual pairs and analyze intervention results in B.5. We show that binding information exists and is used in the entity token residual streams between layers 12 and 19 for the positional and lexical mechanisms, and 6-12 for the reflexive mechanism. We additionally analyze in B.5 how this binding information propagates across token positions. Takeaways These results clarify how LMs bind and retrieve entities in context. They simultaneously employ three mechanisms: positional, lexical, and reflexive. In the first and last entity groups, LMs can rely almost exclusively on the positional mechanism, where it is strongest and most concentrated. In middle groups, however, the positional signal becomes diffuse and often links entities to nearby groups. In these cases, the lexical and reflexive mechanisms provide sharper signals which refine the positional mechanism, enabling the LM to retrieve the correct entity."
        },
        {
            "title": "4 A SIMPLE MODEL FOR SIMULATING ENTITY RETRIEVAL IN-CONTEXT",
            "content": "Mixing mechanisms in causal model We follow Pˆıslar et al. (2025) in combining together multiple causal models (P, L, R) into single causal model that modulates between the mechanisms conditional on the input. To formalize our observations about the dynamics between the three mechanisms and the position of the target entity, we develop model that approximates LM logits for next token prediction, as position-weighted mixture of terms for the positional, lexical, and reflexive mechanisms. The lexical and reflexive terms have separate learned weights conditioned on their respective index, i.e., iL, or iR. In accordance with the results shown in Figure 3, we model the lexical and reflexive mechanisms as one-hot distributions that up-weight only the target entity in groups iL and iR, respectively. The positional term is modeled as Gaussian distribution scaled by single weight wpos centered at the index iP with standard deviation that is quadratic function of iP . We define new causal model that uses all three variables , L, and simultaneously to compute logit value Yi for each entity Gi Yi := wpos (cid:0)i iP , σ(iP )2(cid:1) (cid:125) + wref [iR] 1{i = iR} (cid:125) (cid:123)(cid:122) reflexive mechanism + wlex[iL] 1{i = iL} (cid:123)(cid:122) (cid:125) lexical mechanism (cid:123)(cid:122) positional mechanism tentity: (2) (cid:124) (cid:124) (cid:124)"
        },
        {
            "title": "Preprint",
            "content": "Model JSS te = 1 te = 2 te = 3 Comparing against the prevailing view (Lone-hot; Rone-hot; PGauss) Pone-hot (prevailing view) 0.95 0.42 0.96 0.46 Modifying the positional mechanism w/ Poracle w/ Pone-hot 0.96 0. 0.98 0.85 Ablating the three mechanisms {PGauss} {Lone-hot} {Rone-hot} {Rone-hot, Lone-hot} {PGauss, Rone-hot} {PGauss, Lone-hot} Uniform 0.67 0.94 0.69 0.69 0.12 0.55 0.44 0.68 0.91 0.87 0.84 0.27 0.41 0.57 0.94 0. 0.96 0.85 0.67 0.75 0.92 0.74 0.48 0.20 0.49 Figure 4: Results for training our full model (Lone-hot, Rone-hot,PGauss), in addition to variants, baselines and ablations. Left: JSS scores for modeling the LM next token distribution over iP , iL, iR. Evaluated on gemma-2-2b-it for the music binding task, with te = tentity. Our model attains near-perfect JSS, slightly below the oracle. KL values  (Table 3)  show the same trend. All CIs are < 0.02; for and w/ oracle they are < 0.002. Right: Learned weights wlex, wref, wpos and σ curve, for tentity = 2. Observe σ widens for middle indices and narrows toward the end. Where σ(iP ) = α( iP )2 + β iP + γ. We learn wpos, wlex, wref , α, β, γ from data. Learning how the mechanisms are mixed To generate data for training our causal model we performed 150 interchange interventions per combination of 1 iP , iL, iR using the original and counterfactual inputs designed to distinguish the three mechanisms (see Figure 1 and Section 3.2). We collected the logit distributions per index combination, and averaged them into mean probability distributions by first applying softmax over the entity group indices and then taking the mean. This yields n3 = 8, 000 probability distributions, which serve as our data for training and evaluation. We used 70% of the data for learning the causal model parameters and split the remainder evenly between validation and test sets. The loss used is the JensenShannon divergence (JSD) between our models predicted probability distribution and the target, chosen for its symmetry. We evaluate alongside range of baselines, variants, and ablations to characterize our models performance and understand the contribution of the different mechanisms. Experiments are run with gemma-2-2b-it on the music task (n = 20, tentity [3]). In B.8 we report the same setup for this model as well as qwen2.5-7b-it on additional tasks, with similar trends. We measure similarity between the predicted and target distributions using JensenShannon similarity (JSS), defined as 1 JSD, calculated with log2 to yield values in [0, 1]. See Appendix Table 3 for KL divergences. We compare our model with: (1) The prevailing view one-hot distribution at the positional index, (2) variant of which uses one-hot distribution at iP instead of gaussian, (3) ablations of that use only subset of the mechanisms (e.g., {Lone-hot} is without the lexical mechanism), and (4) uniform distribution. Finally, as an upper bound, we evaluate an oracle variant, where the lexical and reflexive components are learned as usual, but the positional component is swapped with the actual logit distributions of the model, as function of iP (see Figure 9). Results In Figure 4 we show the results. We can see that our model achieves near perfect performance, only slightly below the oracle, at an average JSS of 0.95. In contrast, the model representing the prevailing view of how entity binding works achieves an average JSS of 0.44, well below even the uniform distribution baseline with 0.5. Next, we see that modeling the positional mechanism as one-hot as opposed to gaussian significantly hurts performance, dropping to 0.85 JSS. The"
        },
        {
            "title": "Preprint",
            "content": "Figure 5: Padding results for gemma-2-2b-it on the boxes task. Left: Confusion matrix between the models predicted index and the positional index patched in from the counterfactual. This gets increasingly fuzzy for early tokens as padding is increased. Right: Distribution of effects as padding is increased, showing the positional mechanism strengthens at the expense of the lexical mechanism. ablations further reveal how mechanisms are employed: for instance, when tentity = 1, ablating the lexical mechanism has nearly no effect, while for tentity = 3 this is true for the reflexive mechanism. We can also see in Figure 4 the learned parameters of the model for tentity = 2. We see that in this setting, the lexical and reflexive mechanisms behave similarly, being weaker in the beginning, flat in the middle, and with an uptick at the end. The reflexive mechanism is slightly more dominant here, in keeping with the table results for tentity = 2. For the positional mechanism we can see that it starts off very concentrated, becoming wider in middle indices, and finally becoming more narrow towards the end, mirroring previous results."
        },
        {
            "title": "INTRODUCING FREE FORM TEXT INTO THE TASK",
            "content": "To test our models generalization to more realistic inputs, we modify our prompt templates such that they include filler sentences between each entity group. To this end, we create 1,000 filler sentences that are entity-less, meaning they do not contain sequences that signal the need to track or bind entities, e.g. Ann loves ale, this is known fact, Joe loves jam, this logic is easy to follow.... This enables us to evaluate entity binding in more naturalistic setting, containing much more noise and longer sequences. We evaluate different levels of padding by interleaving the entity groups with an increasing number of filler sentences, for maximum of 500 tokens between each entity group. The results, shown in Figure 5 for gemma-2-2b-it on the boxes task, show that our model at first remains remarkably consistent in more naturalistic settings, across even ten-fold increase in the number of tokens. However, as the amount of filler tokens increases, we see that the magnitude of the mechanisms effects changes. The lexical mechanism declines in its effect, while the positional and mixed effects slightly increase. We can also see that the mixed effect remains distributed around the positional index, but that it slowly becomes more diffuse. Thus, when padding with 10,000 tokens, we get that other than the first entity group, the positional information becomes nearly nonexistent for the first half of entity tokens, while remaining stronger in the latter half. This suggests that weakening lexical mechanism relative to an increasingly noisy positional mechanism might be mechanistic explanation of the lost-in-the-middle effect (Liu et al., 2024)."
        },
        {
            "title": "6 CONCLUSION",
            "content": "In this paper, we challenge the prevailing view that LMs retrieve bound entities purely with positional mechanism. We find that while the positional mechanism is effective for entities introduced at the beginning or end of context, it becomes diffuse and unreliable in the middle. We show that in practice, LMs rely on mixture of three mechanisms: positional, lexical, and reflexive. The lexical and reflexive mechanisms provide sharper signals that enable the model to correctly bind and"
        },
        {
            "title": "Preprint",
            "content": "retrieve entities throughout. We validate our findings across 9 models ranging from 2-72B, and 10 binding tasks, establishing general account of how LMs retrieve bound entities."
        },
        {
            "title": "ACKNOWLEDGMENTS",
            "content": "This work was supported in part by the Alon scholarship, the Israel Science Foundation grant 1083/24, and grant from Open Philanthropy. Figure 1 uses images from www.freepik.com."
        },
        {
            "title": "REFERENCES",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 18771901. Curran Associates, Inc., URL https://proceedings.neurips.cc/paper_files/paper/2020/ 2020. file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf. Qin Dai, Benjamin Heinzerling, and Kentaro Inui. Representational analysis of binding in lanIn Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Proceedguage models. ings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 1746817493, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.967. URL https://aclanthology.org/2024. emnlp-main.967/. Xander Davies, Max Nadeau, Nikhil Prakash, Tamar Rott Shaham, and David Bau. Discovering variable binding circuitry with desiderata, 2023. URL https://arxiv.org/abs/2307. 03637. Hermann Ebbinghaus. Memory: Contribution to Experimental Psychology. Teachers College, Columbia University, New York, NY, US, 1913. Jiahai Feng and Jacob Steinhardt. How do language models bind entities in context? In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview. net/forum?id=zb3b6oKO77. Jiahai Feng, Stuart Russell, and Jacob Steinhardt. Monitoring Latent World States in Language Models with Propositional Probes, June 2024. Matthew Finlayson, Aaron Mueller, Sebastian Gehrmann, Stuart Shieber, Tal Linzen, and Yonatan Belinkov. Causal analysis of syntactic agreement mechanisms in neural language models. In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (eds.), Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 18281843, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.144. URL https://aclanthology.org/2021.acl-long.144/. Jerry A. Fodor and Zenon W. Pylyshyn. Connectionism and cognitive architecture: critical analysis. Cognition, 28(1-2):371, 1988. doi: 10.1016/0010-0277(88)90031-5. Atticus Geiger, Kyle Richardson, and Christopher Potts. Neural natural language inference models partially embed theories of lexical entailment and negation. In Afra Alishahi, Yonatan Belinkov, Grzegorz Chrupała, Dieuwke Hupkes, Yuval Pinter, and Hassan Sajjad (eds.), Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pp. 163 173, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020. blackboxnlp-1.16. URL https://aclanthology.org/2020.blackboxnlp-1.16/."
        },
        {
            "title": "Preprint",
            "content": "Atticus Geiger, Hanson Lu, Thomas Icard, and Christopher Potts. Causal abstractions of neural networks. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural Information Processing Systems, 2021. URL https://openreview.net/forum? id=RmuXDtjDhG. Atticus Geiger, Jacqueline Harding, and Thomas Icard. How causal abstraction underpins computational explanation, 2025a. URL https://arxiv.org/abs/2508.11214. Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, and Thomas Icard. Causal abstraction: theoretical foundation for mechanistic interpretability. Journal of Machine Learning Research, 26(83):164, 2025b. URL http://jmlr.org/papers/v26/23-0058. html. Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. Dissecting recall of factual associations in auto-regressive language models. In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 1221612235, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.751. URL https://aclanthology.org/2023. emnlp-main.751/. Romuald A. Janik. Aspects of human memory and large language models, 2024. URL https: //arxiv.org/abs/2311.03839. Mosh Levy, Alon Jacoby, and Yoav Goldberg. Same task, more tokens: the impact of input length on the reasoning performance of large language models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1533915353, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.818. URL https://aclanthology.org/2024.acl-long.818/. Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts. Transactions of the Association for Computational Linguistics, 12:157173, 2024. doi: 10.1162/tacl 00638. URL https://aclanthology.org/2024.tacl-1.9/. Norman Miller and Donald Campbell. Recency and primacy in persuasion as function of timing of speeches and measurement. Journal of abnormal psychology, 59:19, 07 1959. doi: 10.1037/ h0049330. Theodora-Mara Pˆıslar, Sara Magliacane, and Atticus Geiger. Combining causal models for more accurate abstractions of neural networks. In Fourth Conference on Causal Learning and Reasoning, 2025. URL https://openreview.net/forum?id=mVftlEi1CD. Nikhil Prakash, Tamar Rott Shaham, Tal Haklay, Yonatan Belinkov, and David Bau. Fine-tuning In The Twelfth International enhances existing mechanisms: case study on entity tracking. Conference on Learning Representations, 2024. URL https://openreview.net/forum? id=8sKcAWOf2D. Nikhil Prakash, Natalie Shapira, Arnab Sen Sharma, Christoph Riedl, Yonatan Belinkov, Tamar Rott Shaham, David Bau, and Atticus Geiger. Language models use lookbacks to track beliefs, 2025. URL https://arxiv.org/abs/2505.14685. Paul Smolensky. Tensor product variable binding and the representation of symbolic structures in connectionist systems. Artificial Intelligence, 46(1-2):159216, 1990. doi: 10.1016/ 0004-3702(90)90007-M. David S. Touretzky and Geoffrey E. Minton. Symbols among the neurons: details of connectionist inference architecture. In Proceedings of the 9th International Joint Conference on Artificial Intelligence - Volume 1, IJCAI85, pp. 238243, San Francisco, CA, USA, 1985. Morgan Kaufmann Publishers Inc. ISBN 0934613028."
        },
        {
            "title": "Preprint",
            "content": "Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Yaron Singer, and Investigating gender bias in language models using causal mediation analysis. Stuart Shieber. Advances in neural information processing systems, 33:1238812401, 2020. Yiwei Wu, Atticus Geiger, and Raphael Milli`ere. How do transformers learn variable binding in In Forty-second International Conference on Machine Learning, 2025. symbolic programs? URL https://openreview.net/forum?id=kVtyv7bpnw."
        },
        {
            "title": "A LIST OF BINDING TASKS",
            "content": "We define ten different binding tasks spanning domains, syntaxes, and subjects: one with = 2 and nine with = 3. Table 1 lists the entity sets for each task, along with an example instantiation for = 2 and different values of qentity. Note that when = 3, we use two query entities: Gqgroup 1 and qentity Gqgroup 2. These are the two entities in the entity group which arent the target entity. For example, qentity when tentity = 2 we set qentity 1 = 1 and qentity 2 = 3. Figures 10 and 11 show the results of the TargetRebind interchange intervention on gemma2-2b-it and qwen2.5-7b-it across all tasks and all values of tentity. Our findings are consistent: the positional mechanism dominates for early and late entity groups, while the lexical and reflexive mechanisms take over in the middle. We also replicate the effect in Figure 2 and Figure 4: reflexive is more present when tentity = 1 (first), lexical when tentity = 3 (last), and both are balanced when tentity = 2 (middle)."
        },
        {
            "title": "B MORE EXPERIMENTS",
            "content": "In this section we discuss experiments that further strengthen our model of how LMs perform entity binding and retrieval, that couldnt be included in the main section. B.1 REPLICATING RESULTS ACROSS MODELS To validate robustness, we evaluated 9 models across 3 families, spanning 272B parameters. As shown in Figures 6 and 7 for the boxes and music tasks with tentity [3], our findings transfer consistently across models. The positional mechanism dominates for the first and last entity groups, while in middle positions lexical and reflexive take over, with mixed effect distributed around the positional index. In the Qwen family, we also observe that positional efficacy strengthens with model size. Overall, these results point to universal strategy used by LMs to solve entity binding tasks. B.2 ENCODING OF POSITIONAL INFORMATION Throughout our experiments (notably Figures 2, 4, 6 and 10), we show that the model does not rely solely on the positional mechanism. One possible explanation is that, as illustrated in Figure 3, the positional signal becomes diffuse and weak for middle entity groups. This may reflect the models limited ability to encode entity group positions in linearly separable manner. To test this hypothesis, we collected hidden state activations at entity token positions as well as at final token positions at every layer, and assessed their separability using PCA and multinomial logistic regression probe. Figure 19 shows the results: PCA projections for entity token positions with = 20, and linear probe accuracies for both entity and final positions across {5, 10, 15, 20}. Consistent with our broader findings, the first and last entity groups are readily separable, while middle groups exhibit substantial overlap. We also observe clear dependence on n: smaller contexts yield better separation, whereas larger contexts make positions increasingly indistinguishable. B.3 EFFECT OF Previous work has described model behavior faithfully using only the positional mechanism (Feng & Steinhardt, 2024; Prakash et al., 2025), but these analyses were limited to small contexts (n"
        },
        {
            "title": "Preprint",
            "content": "Name Filling Liquids People and Objects Programming Dictionary Music Biology Experiment Chemistry Experiment Transportation Sports Events Space Observations Entity Sets Sample E1 = {John, Mary} E2 = {cup, glass} E3 = {wine, beer} E1 = {John, Mary} E2 = {toy, medicine} E3 = {kitchen, office} E1 = {a, b} E2 = {John, Mary} E3 = {US, Canada} E1 = {John, Mary} E2 = {rock, pop} E3 = {guitar, piano} Binding Example John and Mary are working at busy restaurant. To fulfill an order, John fills cup with beer and Mary fills glass with wine. Who filled cup with beer? John put the cup in the office and Mary put the toy in the kitchen. What did Mary put in the kitchen? in following are dictionary variables The Python: a={name:Mary, Country:Canada}, b={name:John, Country:US}. What is the country in variable where name == John? At the music festival, John performed rock music on the piano, and Mary performed pop music on the guitar. What music did Mary play on the guitar? E1 = {John, Mary} E2 = {serum, enzyme} E3 = {beaker, vial} In biology laboratory experiment, Mary placed the serum in vial, and John placed the enzyme in beaker. Who placed the serum in vial? E1 = {John, Mary} E2 = {ethanol, acetone} E3 = {crucible, funnel} E1 = {John, Mary} E2 = {truck, taxi} E3 = {mall, park} E1 = {John, Mary} E2 = {hockey, cricket} E3 = {stadium, field} E1 = {John, Mary} E2 = {planet, asteroid} E3 = {telescope, radar} In chemistry laboratory experiment, Mary added the acetone to crucible, and John added the ethanol to funnel. What did John add to funnel? In city transportation system, John, drove the truck to the mall, and Mary drove the taxi to the park. Where did Mary drive the taxi? In sports competition, Mary played hockey at the stadium, and John played cricket at the field. Who played hockey at the stadium? During an astronomy study, John observed an asteroid with radar, and Mary observed planet with telescope. What did John observe with radar? Boxes E1 = {toy, medicine} E2 = {box A, box B} The toy is in box B, and the medicine is in Box A. Which box is the medicine in? Table 1: List of all binding tasks we evaluate in our experiments. We show entity sets composed of only two entities per set for brevity. We also only show examples for = 2 but evaluate over [3, 20] {2, 3}). In this work, we show extensively that this finding doesnt hold for larger values of n. To evaluate exactly the relationship between the efficacy of the positional mechanism and n, we conduct the TargetRebind interchange intervention on gemma-2-2b-it and qwen2.5-7b-it for all [3, 20]. We see that the trend seen in all experiments holds across values of n: the positional mechanism is effective in the first and last entity groups, but not in middle ones. Its efficacy for middle entity groups declines as increases. This trend is consistent with the separability analysis in Figure 19, which shows that hidden states from middle entity groups become increasingly difficult to classify by position as grows. B.4 MECHANISM AGREEMENT In the TargetRebind interchange intervention used to produce the results in Figure 2 (and others throughout the paper), we explicitly make sure to have different values for the positional, lexical and reflexive indices, so that we can know which mechanism most affected the models output. However, as shown in Figure 3, these mechanisms behave additively, and we suspect that when they agree, they overwhelmingly drive model behavior. To evaluate this, we conduct two experiments, one for"
        },
        {
            "title": "Preprint",
            "content": "Figure 6: Evaluation of the TargetRebind interchange intervention in 9 different models across 3 model families spanning 2-72B parameters, for the boxes binding task and tentity [2]. We see that the results remain remarkably consistent. Figure 7: Evaluation of the TargetRebind interchange intervention in 9 different models across 3 model families spanning 2-72B parameters, for the music binding task and tentity = 3. tentity = 1 where the positional mechanism agrees with the reflexive one, and one for tentity = 3 where the positional mechanism agrees with the lexical one. The results, shown in Figure 16, show that this is indeed the case. B.5 BINDING SIGNALS IN ENTITY TOKENS In our main experiments, we focus on interchange interventions for the last token position, showing that it encodes positional, lexical and reflexive signals. In this section, we conduct experiments to"
        },
        {
            "title": "Preprint",
            "content": "Figure 8: Evaluation of the TargetRebind interchange intervention at 1 and 2 layers after the evaluation in Figure 6, for tentity = 2. We see that the model shifts from aggregating binding information to retrieving the entities. Figure 9: The mean logit distribution as function of the positional index (iP ), for qwen2.5-7b-it on the boxes task with tentity = 2. We can see the the positional binding signal induces strong and concentrated signal for entity groups in the beginning and the end, while inducing weak and diffuse one for middle groups. verify the existence of these signals in the entity token positions themselves, as well as identify the movement of these signals across token positions. First, we conduct the PosSwap , LexSwap and RefSwap interchange interventions, described in Table 2, with the results shown in Figure 17. We see that they achieve nearly identical interchange intervention accuracies as when performing TargetRebind with the last token position. Additionally, wee see that for the positional and lexical mechanisms, the crucial layers where the binding information is contained in the entity tokens and used for retrieval is layers 12-19, while for reflexive its 6-12. To further trace how binding signals flow through the model, we apply attention knockout (Geva et al., 2023). We first identify minimal set of layers where blocking attention from the last token"
        },
        {
            "title": "Preprint",
            "content": "Figure 10: Results of the TargetRebind interchange intervention for gemma-2-2b-it across all tasks and possible values of tentity. position to the query entity token (e.g., which box is the medicine in?) degrades performance. Across all values of tentity, this occurs in layers 1116, dropping accuracy from 98% to 37%, aligning with the layers where binding information resides in entity tokens. Knockout becomes even more effective when applied to both the query token and the token immediately after it, reducing accuracy to 8%. This suggests that some of the query signal is copied forward. Consistent with this, blocking attention from the last token position only to the token following the query token decreases accuracy by just one point. However, when we block attention both from the last position to the query token and from its following token, accuracy drops to 6%, confirming that crucial binding information reaches the last position via the query token. Finally, we test whether binding information propagates from entity tokens to the query token. The lexical mechanism may not require such propagation, since its signal can be generated directly from the query token. By contrast, the reflexive signal in the entity tokens originates from the answer token, so the query token must retrieve it in order for the signal to reach the last token position. To evaluate this, we block attention from the query token to different entity tokens. For the reflexive signal (setting tentity = 1), we block attention to the entity token identical to the query token where our RefSwap intervention localized the signaland to the token immediately after it. This intervention is most effective in layers 812, reducing accuracy to 6%, and matching the layers where entity tokens use this signal (Figure 17). Blocking attention to other entity tokens in the queried entity group has no effect. In contrast, for the lexical signal (setting tentity = 2), blocking attention from the query token to the correct answer entity token reduces accuracy only to 86%, even when applied across all layers. Moreover, blocking attention from the query token to all entity tokens at all layers still leaves accuracy at 90%. These results support our hypothesis: the lexical signal can be derived locally from the query token, while the reflexive signal must be retrieved from"
        },
        {
            "title": "Preprint",
            "content": "Figure 11: Results of the TargetRebind interchange intervention for qwen2.5-7b-it across all tasks and possible values of tentity. Figure 12: Results for the TargetRebind interchange intervention on gemma-2-2b-it for [3, 20] and tentity = 3 on the boxes task. We see trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle. entity tokens. This also explains why the model appears to produce the reflexive binding signal earlier than in the lexical or positional mechanisms it requires an additional stage of retrieval."
        },
        {
            "title": "Preprint",
            "content": "Figure 13: Results for the TargetRebind interchange intervention on gemma-2-2b-it for [3, 20] and tentity = 3 on the music task. We see trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle. Figure 14: Results for the TargetRebind interchange intervention on qwen2.5-7b-it for [3, 20] and tentity = 3 on the boxes task. We see trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle. B.6 FINDING THE TARGET LAYER We seek to identify for each model what the last layer before retrieval is, so that we can perform our interchange interventions on that layer. Indeed in Figure 2 we see that there are subset of layers where the last token position contains the binding information, after which it contains the retrieved answer. Thus, for each model we identify the last layer where patching the last token position does not copy the retrieved token. The intervention on this layer ℓ is shown in Figure 6 for tentity [2], and in Figure 8 we show this same intervention for ℓ + 1 and ℓ + 2 with tentity = 2. We see clearly that for ℓ, the percentage of cases where the answer post-intervention is the retrieved entity from the counterfactual example is at or below random chance. However, for ℓ + 1 and ℓ + 2 this effect becomes the majority, showing that the model has shifted to retrieval. We also see that this layer is consistent across tasks in Figures 6 and 7. B.7 REMOVING TARGETED ENTITY TOKENS In 3.1 we detail how the lexical and reflexive mechanisms are pointers that get dereferenced to the queried entity. To strengthen these claims, in this section, we evaluate what happens when we modify the TargetRebind interchange intervention, such that the entities targeted by those mechanisms do not exist in the original prompt. Thus, for the example in Figure 1, to test the lexical"
        },
        {
            "title": "Preprint",
            "content": "Figure 15: Results for the TargetRebind and tentity = 3 interchange intervention on qwen2.57b-it for [3, 20] on the music task. We see trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle. Figure 16: We evaluate gemma-2-2b-its behavior when aligning the mechanisms for the music task. We align the positional and reflexive mechanisms for tentity = 1, and the positional and lexical mechanisms for tentity = 3. We see that when the mechanisms point at the same entity for retrieval, the model consistently responds with the correct entity. mechanism wed change the counterfactual such that Ann is replaced with different new name Max, and for the reflexive wed change pie to cod (separately). We see in Figure 25 that this leads the model to rely solely on the positional mechanism, since the others have pointers that cannot be dereferenced. In Figure 26 we see that in this case, relying on the positional mechanism yields noisy distribution around the positional index. possible alternative explanation for why the model isnt retrieving the entity pointed to by these two mechanisms, is that there might be some other mechanism that prevents the model from answering with entities that do not exist in the context. To evaluate this, we conduct the same exact interventions, but for layer ℓ + 1, where the retrieval is already taking place (see B.6). Thus, if such mechanisms exists, wed expect to see the same results, where the model relies solely on the positional mechanism. Otherwise, wed expect the model to respond with the retrieved answer from the counterfactual. We can see in Figure 27 that the model indeed responds with the retrieved answer from the counterfactual, falsifying this alternative explanation. Thus, we conclude that the model indeed relies on the lexical and reflexive mechanisms as pointers for dereferencing. B.8 ADDITIONAL CAUSAL MODELS We report the the KL divergence scores for gemma-2-2b-it on the music task in Table 3. We additionally report all metrics for gemma-2-2b-it on the sports task in Table 4, and qwen2.5-7b-it on"
        },
        {
            "title": "Preprint",
            "content": "Figure 17: Results for the PosSwap (left), LexSwap (middle) and RefSwap (right) interchange interventions on gemma-2-2b-it for the boxes task. Each square shows the interchange intervention accuracy (IIA) for given layer and positional, lexical or reflexive index. We see that positional and lexical binding information exists in entity tokens in layers 12-19, while reflexive binding information does in layers 6-12. Figure 18: We show results of the TargetRebind interchange intervention on gemma-2-2b-it for the boxes task with different indices on the x-axis. Left: using the index of the queried entity group. This has little effect overall, except for dips at the first and last indices in the positional effect. Under TargetRebind , the positions of queried entity groups cannot coincide between the counterfactual and original prompts. Thus, when the original query targets the first or last groupswhere positional information is strongestthese groups are never patched, slightly weakening results on average. Right: using the lexical index. Here the pattern mirrors Figure 3, with weaker effects at the edges and stronger ones in the middle. . both tasks in Tables 5 and 6. For training, we use Adam (β1 = 0.9, β2 = 0.999) with learning rate 0.05, run for up to 2,000 epochs with batch size of 512 and early stopping after 200 epochs."
        },
        {
            "title": "C THE REFLEXIVE MECHANISM",
            "content": "In 3.1, we describe the reflexive binding mechanism, where direct pointer originating from an entity token is used to point back at itself. In this section we provide further evidence for the existence of this mechanism as described. We can see in Figure 10 that when querying the first entity in tuple, the lexical patch effect is completely superseded by the reflexive one, wherein the patching results in the model answering with the queried entity itself from the counterfactual example (see the reflexive patch effect in Table 2). On first glance it seems as if this means that the last token position at this layer already contains the answer, since patching it yields the answer from the counterfactual. However, we show in B.7 that"
        },
        {
            "title": "Preprint",
            "content": "Name Original Counterfactual Patch Positions Patch Effects The bottle is in box C, the pen is in box A, the ball is in box Q, and the rock is in box N. Which box is the rock in? The pen is in box and the ball is in box Q. Which box is the ball in? The bottle is in box Q, the ball is in box A, the pen is in box C, and the rock is in box N. Which box is the pen in? The ball is in box and the pen is in box A. Which box is the ball in? Last token position Q: Positional A: Lexical C: Reflexive N: No effect AA QQ The pen is in box and the ball is in box Q. Which box is the ball in? The ball is in box and the pen is in box Q. Which box is the ball in? AA QQ The pen is in box and the ball is in box Q. What is in Box Q? The ball is in box and the pen is in box Q. What is in Box Q? AA QQ A: Patched tokens encode positional binding used by the model Q: Patched tokens encode do positional binding used by the model not A: Patched tokens encode lexical binding used by the model Q: Patched tokens encode do lexical binding used by the model not A: Patched tokens encode reflexive binding used by the model Q: Patched tokens do encode reflexive binding used by the model not TargetRebind PosSwap LexSwap RefSwap Table 2: Original/counterfactual pair examples for interchange interventions. when using an interchange intervention where the entity pointed to by the reflexive mechanism does not exist in the original input, the model resorts to solely relying on the positional mechanism rather than responding with the answer from the counterfactual input. This shows that the intervention is not copying the retrieved answer from the counterfactual to the original, but rather copying pointer to that answer. We further validate this by running the original interchange intervention, but this time knocking out attention from the last token position to the target entity (Geva et al., 2023), shown in Figure 20. Again we see that the model does not respond with the counterfactual target entity unless it can find it in context, which we prevent by blocking attention to it. Conversely, blocking attention at layer when the model has already retrieved the answer has no effect on the models answer. Thus, we can conclude that the model indeed relies on reflexive mechanism for binding and retrieving entities in context."
        },
        {
            "title": "D CONTEXT LENGTH ABLATION STUDY",
            "content": "In our evaluations, we show the effect of the number of entities that need to be bound in-context on LMs use of the positional, lexical and reflexive mechanisms. However, confounding factor is that as the number of entities increases, so does the length of the sequence itself. To disentangle these effects, we pad contexts with [3, 19] so that all sequences match the length of those with = 20. Padding is done using entity-less sentences, as described in 5. The results are shown in Figure 24. If the effects of increasing were due to increasing sequence length, wed expect all results to be identical to when setting = 20, and to each other. However, we see that, while the"
        },
        {
            "title": "Preprint",
            "content": "Figure 19: Separability of hidden states for entity token positions and the last token position, across layers and values of n. PCA projections (left) and multinomial logistic regression probes (right) show that first and last entity groups are linearly separable, while middle groups overlap substantially. Separability decreases as the number of entities increases. Model w/ Oracle Pos w/ One-Hot Pos Only One-Hot At Pos {P } {L} {R} {L, R} {P, R} {P, L} Uniform tentity = 1 0.22 KLtp tentity = 2 0.17 tentity = 3 0.26 tentity = 1 0.31 KLpt tentity = 2 0. tentity = 3 0.41 0.14 0.71 6.41 1.75 0. 2.14 2.10 9.19 4.66 2.71 0. 0.67 5.61 1.52 0.73 1.08 1. 7.35 6.18 1.96 0.14 0.71 5. 1.71 1.76 0.61 1.82 5.32 8. 2.44 0.32 1.00 3.41 4.51 0. 2.10 2.13 10.7 4.28 7.57 0. 0.88 2.39 2.37 0.37 0.54 0. 5.55 2.92 3.49 0.24 0.88 2. 3.17 1.42 0.44 1.50 4.34 5. 4.84 Table 3: KL divergence results for modeling an LMs behavior contingent on the positional, lexical and reflexive indices. Evaluated on gemma-2-2b-it for the music binding task. Our full model achieves the best performance, only slightly below the oracle. distribution of patch effects is slightly affected by padding, the results and trends align closely with our results without padding. This indicates that model behavior is governed primarily by the number of entities that must be bound, rather than by sequence length."
        },
        {
            "title": "E LLM USAGE",
            "content": "In this work, the authors relied on LLMs solely to assist with implementing specific helper functions."
        },
        {
            "title": "Preprint",
            "content": "Figure 20: Patch effects under TargetRebind for gemma-2-2b-it while blocking attention to the target entity. Left: blocking attention when the model is accumulating binding information in the last token position leads to it not being able to dereference the reflexive pointer. Had the patch contained the retrieved answer, this plot would be fully orange. Right: patching at the following layer and blocking attention to the target entity. Here the plot is fully orange since the entity has already been retrieved. Figure 21: Mean logit distributions under TargetRebind for gemma-2-2b-it on the music task. Left: fixing iL = 8, iR = 16 and varying iP . Right: fixing iP = 6, iL = 14 and varying iR. Figure 22: Mean logit distributions under TargetRebind for qwen2.5-7b-it on the music task. Left: fixing iP = 6, iR = 14 and varying iL. Right: fixing iP = 6, iL = 14 and varying iR."
        },
        {
            "title": "Preprint",
            "content": "Figure 23: Mean logit distributions under TargetRebind for qwen2.5-7b-it on the sports task. Left: fixing iL = 8, iR = 16 and varying iP . Right: fixing iP = 8, iL = 19 and varying iR. Figure 24: Mean patch effects per number of entities in context (n). For each n, we report the standard mean patch effects (right) alongside results from padded sequences (left), where sequence length is fixed to match = 20. While padding slightly shifts the distribution of patch effects, the overall patterns remain consistent: model behavior is primarily controlled by the number of entities in context, rather than sequence length."
        },
        {
            "title": "Preprint",
            "content": "Figure 25: Left: results for TargetRebind interchange intervention on gemma-2-2b-it with tentity = 1, where the query entity in the counterfactual does not exist in the original. Right: results for TargetRebind interchange intervention on gemma-2-2b-it with tentity = 2, where the target entity in the counterfactual does not exist in the original. We can see in both plots that when the model cant use the lexical and reflexive mechanisms since the entities they point to dont exist, the model falls back to solely using the positional mechanism (distribution showed in Figure 26). Figure 26: Left: confusion matrix for non-lexical and reflexive patch effects under the TargetRebind interchange intervention on gemma-2-2b-it with tentity = 1, where the query entity in the counterfactual does not exist in the original. Right: results for non-lexical and reflexive patch effects under the TargetRebind interchange intervention on gemma-2-2b-it with tentity = 2, where the queried entity in the counterfactual does not exist in the original. We can see that when the model cant use the lexical and reflexive mechanisms, it falls back on the noisy positional mechanism."
        },
        {
            "title": "Preprint",
            "content": "Figure 27: Results for TargetRebind interchange interventions on gemma-2-2b-it with tentity [2], where the query entity (left) or queried entity (right) in the counterfactual do not exist in the original, patching at layer ℓ + 1. We see that the model copies the retrieved answer from the counterfactual, showing that no mechanism exists to suppresses answering with entities that do not exist in the original prompt. Figure 28: Confusion matrix for non-lexical and reflexive patch effects under the TargetRebind interchange intervention for all models, showing the diffuse distribution around the positional index. Left: tentity = 1. Right: tentity = 2."
        },
        {
            "title": "Preprint",
            "content": "Model (Lone-hot, Rone-hot,PGauss) w/ Poracle w/ Pone-hot Pone-hot view) (prevailing {P } {L} {R} {L, R} {P, R} {P, L} Uniform JSS = 2 0.95 = 1 0.94 = 3 0.93 = 1 0.3 KLtp = 2 0.21 = 3 0. = 1 0.35 KLpt = 2 0.28 = 3 0.39 0.96 0.85 0. 0.67 0.93 0.69 0.68 0.11 0. 0.45 0.97 0.87 0.46 0.69 0. 0.84 0.79 0.31 0.45 0.54 0. 0.87 0.43 0.71 0.75 0.9 0. 0.47 0.23 0.54 0.13 0.77 6. 1.75 0.41 1.83 1.84 9.25 4. 2.66 0.11 0.59 5.74 1.53 0. 1.28 1.52 7.19 5.95 2.13 0. 0.62 6.03 1.49 1.99 1.04 2. 5.32 8.16 2.22 0.32 1.2 3. 4.91 0.37 2.52 2.54 10.9 4. 8 0.19 0.81 2.54 3.04 0. 0.71 1.05 6.11 3.06 4.78 0. 0.73 2.9 1.88 1.25 0.47 1. 3.61 4.49 2.93 Table 4: Results for modeling gemma-2-2b-its behavior on the sports binding task, contingent on the positional, lexical and reflexive indices. Here denotes tentity. Model (Lone-hot, Rone-hot,PGauss) w/ Poracle w/ Pone-hot Pone-hot view) (prevailing {P } {L} {R} {L, R} {P, R} {P, L} Uniform JSS = 2 0.92 = 1 0. = 3 0.92 = 1 0.27 KLtp = 2 0.34 = 3 0.37 = 1 0.35 KLpt = 2 0. = 3 0.45 0.98 0.87 0.56 0.62 0. 0.86 0.86 0.16 0.35 0.55 0. 0.89 0.55 0.66 0.85 0.9 0. 0.34 0.24 0.58 0.98 0.88 0. 0.66 0.78 0.9 0.78 0.42 0. 0.54 0.07 0.58 4.66 1.85 0. 0.9 0.92 8.43 6.64 2.11 0. 0.47 4.65 1.68 1.14 0.89 1. 6.69 7.8 1.95 0.07 0.53 5. 1.73 1.77 1.0 1.79 5.93 8. 2.21 0.1 1.09 1.84 5.05 0. 0.68 0.71 9.04 6.8 5.92 0. 0.74 1.88 3.29 0.74 0.54 0. 5.6 5.3 4.09 0.1 0.69 2. 2.55 1.09 0.5 1.11 4.4 5. 3.54 Table 5: Results for modeling qwen2.5-7b-its behavior on the music binding task, contingent on the positional, lexical and reflexive indices. Here denotes tentity."
        },
        {
            "title": "Preprint",
            "content": "Model (Lone-hot, Rone-hot,PGauss) w/ Poracle w/ Pone-hot Pone-hot view) (prevailing {P } {L} {R} {L, R} {P, R} {P, L} Uniform JSS = 2 0.93 = 1 0.95 = 3 0.92 = 1 0.24 KLtp = 2 0.31 = 3 0. = 1 0.28 KLpt = 2 0.39 = 3 0.47 0.98 0.87 0. 0.61 0.94 0.87 0.87 0.17 0. 0.54 0.98 0.89 0.55 0.66 0. 0.89 0.83 0.31 0.32 0.56 0. 0.88 0.51 0.66 0.77 0.91 0. 0.44 0.14 0.53 0.07 0.62 4. 1.88 0.53 0.89 0.92 8.39 6. 2.12 0.08 0.52 4.72 1.75 1. 1.05 1.33 7.01 7.27 2.06 0. 0.55 5.18 1.73 1.64 0.85 1. 5.75 8.77 2.25 0.09 1.14 1. 5.11 0.27 0.57 0.6 9.04 6. 6.01 0.11 0.68 1.84 2.9 0. 0.54 0.82 5.54 3.88 3.9 0. 0.84 2.21 3.35 1.27 0.48 1. 4.78 7.27 4.71 Table 6: Results for modeling qwen2.5-7b-its behavior on the sports binding task, contingent on the positional, lexical and reflexive indices. Here denotes tentity."
        }
    ],
    "affiliations": [
        "Blavatnik School of Computer Science and AI, Tel Aviv University",
        "Goodfire",
        "Pr(Ai)2R Group"
    ]
}