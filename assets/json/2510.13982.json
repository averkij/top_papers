{
    "paper_title": "Static Sandboxes Are Inadequate: Modeling Societal Complexity Requires Open-Ended Co-Evolution in LLM-Based Multi-Agent Simulations",
    "authors": [
        "Jinkun Chen",
        "Sher Badshah",
        "Xuemin Yu",
        "Sijia Han"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "What if artificial agents could not just communicate, but also evolve, adapt, and reshape their worlds in ways we cannot fully predict? With llm now powering multi-agent systems and social simulations, we are witnessing new possibilities for modeling open-ended, ever-changing environments. Yet, most current simulations remain constrained within static sandboxes, characterized by predefined tasks, limited dynamics, and rigid evaluation criteria. These limitations prevent them from capturing the complexity of real-world societies. In this paper, we argue that static, task-specific benchmarks are fundamentally inadequate and must be rethought. We critically review emerging architectures that blend llm with multi-agent dynamics, highlight key hurdles such as balancing stability and diversity, evaluating unexpected behaviors, and scaling to greater complexity, and introduce a fresh taxonomy for this rapidly evolving field. Finally, we present a research roadmap centered on open-endedness, continuous co-evolution, and the development of resilient, socially aligned AI ecosystems. We call on the community to move beyond static paradigms and help shape the next generation of adaptive, socially-aware multi-agent simulations."
        },
        {
            "title": "Start",
            "content": "Static Sandboxes Are Inadequate: Modeling Societal Complexity Requires Open-Ended Co-Evolution in LLM-Based Multi-Agent Simulations Jinkun Chen1*, Sher Badshah1, Xuemin Yu1, Sijia Han2 1Faculty of Computer Science, Dalhousie University, Halifax, Canada. 2Meta, Vancouver, Canada. *Corresponding author(s). E-mail(s): jinkun.chen@dal.ca; Contributing authors: sh545346@dal.ca; xuemin.yu@dal.ca; hansijia@meta.com; Abstract What if artificial agents could not just communicate, but also evolve, adapt, and reshape their worlds in ways we cannot fully predict? With large language models (LLMs) now powering multi-agent systems and social simulations, we are witnessing new possibilities for modeling open-ended, ever-changing environments. Yet, most current simulations remain constrained within static sandboxes, characterized by predefined tasks, limited dynamics, and rigid evaluation criteria. These limitations prevent them from capturing the complexity of real-world societies. In this paper, we argue that static, task-specific benchmarks are fundamentally inadequate and must be rethought. We critically review emerging architectures that blend LLMs with multi-agent dynamics, highlight key hurdles such as balancing stability and diversity, evaluating unexpected behaviors, and scaling to greater complexity, and introduce fresh taxonomy for this rapidly evolving field. Finally, we present research roadmap centered on open-endedness, continuous co-evolution, and the development of resilient, socially aligned AI ecosystems. We call on the community to move beyond static paradigms and help shape the next generation of adaptive, socially-aware multi-agent simulations. Keywords: Large Language Models, Multi-Agent Systems, Social Simulation, Open-endedness, Co-evolution 1 5 2 0 2 1 2 ]"
        },
        {
            "title": "A\nM",
            "content": ". [ 3 2 8 9 3 1 . 0 1 5 2 : r Fig. 1 Our proposed taxonomy of open-ended multi-agent simulation: (1) Dynamic Scenario Evolution, (2) AgentEnvironment Co-evolution, and (3) Generative Agent Architectures. These pillars support adaptive, socially aligned LLM-driven ecosystems."
        },
        {
            "title": "1 Introduction",
            "content": "Todays multi-agent simulations remain largely confined within static sandboxes: agents are evaluated on predefined tasks, in closed environments, using narrow metrics (Liu et al. 2023; Yehudai et al. 2025; Luo et al. 2025; Lin et al. 2023; Jin et al. 2025). This rigidity stifles emergence, suppresses innovation, and limits the potential of truly adaptive agents. Treating adaptability, societal feedback, and long-term transformation as afterthoughts is no longer acceptable in an era of increasingly capable AI. Despite recent progress, the field remains fragmented across diverse methodologies, architectures, and evaluation standards. We highlight that without unified perspective grounded in open-endedness, researchers risk optimizing brittle systems that cannot generalize beyond toy domains. We argue that current paradigms of multi-agent simulation, which are grounded in static tasks, rigid benchmarks, and predictable interaction loops, are fundamentally inadequate for modeling the complexity of real-world societies. As LLMs increasingly power multi-agent systems (MAS) (Piatti et al. 2024), new opportunity emerges: to create dynamic, adaptive, and open-ended ecosystems where agents co-evolve with their environments and with each other. Imagine digital society where intelligent agents do not just complete tasks, but evolve their own cultures, languages, and societal structures. These agents adapt to unexpected events, reshaping their environments and forging new collective behaviors in ways beyond researchers predictions. We believe that such open-ended co-evolution, rather than fixed performance, represents the true frontier for adaptive AI. We take principled stance: multi-agent simulations must shift from task-specific optimization toward modeling the open-ended, co-evolutionary dynamics of real societies. In addition, we contend that unpredictability is not flaw to be controlled but feature to be embraced. This view is supported by recent research in multi-agent systems, where unpredictability enables more complex emergent behaviors that are integral to multi-agent systems (Guo et al. 2024b) and creates opportunities for novel cooperative behaviors to emerge (Lu et al. 2024), demonstrating that complexity and unpredictability serve as valuable characteristics rather than problems to eliminate. Only by shifting priorities toward 2 open-ended co-evolution can we build LLM-driven simulations that reflect the richness, resilience, and complexity of real-world societies. This approach allows us to move past the brittle constraints of static sandbox environments. To support this position, we begin by redefining key constructs such as LLMs, multi-agent systems, and social simulation through the lens of open-endedness. We then examine the systemic limitations of static simulation paradigms and argue for conceptual shift toward dynamic, co-evolutionary systems. Building on this foundation, we analyze emerging frameworks that integrate LLMs into multi-agent architectures and explore their capacity for reasoning, communication, and norm emergence. As core contribution, we define conceptual taxonomy that is structured around three foundational pillars: Dynamic Scenario Evolution, AgentEnvironment Co-evolution, and Generative Agent Architectures (see Figure 1). This taxonomy is not merely descriptive, which reflects our call to action: to design simulations where agents not only perform but also evolve, not only act but also adapt, not only learn but also transform. Finally, we outline emerging applications, evaluation challenges, and roadmap for advancing adaptive, socially aligned simulation ecosystems."
        },
        {
            "title": "2 Background and Definitions",
            "content": "Before we can reimagine simulation design, it is imperative to clarify its conceptual foundations. In this section, we revisit core constructs such as LLMs, MAS, generative agents, and social simulation. These are not presented as neutral definitions; rather, they reflect underlying philosophical commitments. Each represents fork in the road between static modeling and dynamic co-evolution. We assert that redefining these terms through the lens of open-endedness is critical for realigning the field."
        },
        {
            "title": "2.1.1 LLMs as Adaptive Cognitive Engines",
            "content": "LLMs are deep neural networks trained on massive corpora to predict the next token in sequence (Brown et al. 2020). While traditionally viewed as text generators, we argue they are better understood as adaptive cognitive enginesentities capable of performing complex reasoning, in-context learning, and flexible communication (Bubeck et al. 2023). Their real power lies in emergent, context-sensitive behavior that allows for dynamic participation in evolving environments rather than static task completion. As such, they offer foundation for developing agents that can self-reflect, revise their beliefs, and participate in socially grounded simulations."
        },
        {
            "title": "2.1.2 MAS Beyond Coordination: Toward Norm Fluidity",
            "content": "MAS consist of autonomous entities interacting within shared environment to achieve individual or collective goals (Wooldridge and Jennings 1995). Classic MAS research emphasizes coordination under fixed rules and goals (Shoham and LeytonBrown 2008). With LLM integration, however, agents gain the capacity for real-time negotiation, role adaptation, and the emergence of novel social norms (Bo et al. 2024). 3 This transforms MAS from tools for optimization into frameworks for exploring how agents evolve social identities, institutions, and values through continuous interaction."
        },
        {
            "title": "2.1.3 Generative Agents as Normative Actors",
            "content": "Generative agents are LLM-driven entities equipped with memory, perception, and reflection capabilities (Yao et al. 2023). They simulate lifelike social behavior and cognitive processes (Park et al. 2023). Moving beyond scripted responses, these agents engage in belief revision, identity formation, and social norm negotiation (Cheng et al. 2024; Hua et al. 2024; Jiao et al. 2025). Their internal architectures enable recursive introspection and social reasoning, positioning them as experimental probes for understanding norm emergence, trust dynamics, and social contract formation."
        },
        {
            "title": "2.1.4 Social Simulation as Emergence, Not Reproduction",
            "content": "It refers to the computational modeling of social phenomena, traditionally implemented through rule-based, agent-based models (Gilbert and Troitzsch 2005). Early models aimed to replicate known dynamics (e.g., economic markets or crowd behavior). In contrast, LLM-enabled simulations facilitate the emergence of novel cultural patterns, institutions, and behaviors (Siebers 2024; Dizaji 2024). These agents not only adapt to existing rules but invent new interaction protocols, offering an unprecedented platform for simulating the evolution of social complexity across different environments and timescales."
        },
        {
            "title": "2.2 Rethinking Simulation Paradigms\nCommon challenges in LLM-MAS: hallucination, memory drift, value misalignment,\nand scalability, are often viewed as engineering flaws. Yet these ‘failures’ frequently\nreveal hidden assumptions in system design. For instance, hallucination can expose\ninsufficient grounding mechanisms (Pan 2023); memory issues reveal the inadequacy\nof short-context reasoning (Hou et al. 2024); and cultural bias illustrates the tension\nbetween universal models and local values (Kamruzzaman et al. 2024). Rather than\nsuppress these behaviors, we propose treating them as entry points for open-ended\ninquiry. Each failure mode highlights a mismatch between static assumptions and\ndynamic system needs—a mismatch that future research should explore, not erase.",
            "content": "Current research primarily continues to assume relatively static environments and predictable interaction patterns, an assumption increasingly misaligned with the demands of simulating real-world societies. While recent progress in generative agents, norm fluidity, and emergent simulation is encouraging (Mou et al. 2024), much of the work still operates within narrowly scoped, task-centric paradigms (Larooij and Törnberg 2025). These models often reinforce brittle dynamics and fail to account for the recursive nature of social adaptation, where agents influence their environment and are simultaneously reshaped by it. We argue that this conservative framing limits not only the scope of possible agent behaviors but also the relevance of simulation outcomes to real-world complexity. Critical phenomena such as value renegotiation, institutional breakdown, coalition formation, and cultural drift are rarely modeled, and 4 when they are, its typically within constrained rule space. deeper understanding of how agents respond to rapid, discontinuous changes and emergent non-linear dynamics remains underexplored and undervalued."
        },
        {
            "title": "3 Integrating LLMs into Multi-Agent Systems",
            "content": "We contend that current LLM-MAS integrations overwhelmingly prioritize performance and predictability, often at the cost of adaptability, norm emergence, and long-term societal co-evolution. We argue that to unlock the full potential of LLMs in multi-agent systems, future architectures must emphasize intrinsic mechanisms for dynamic goal realignment, identity fluidity, and collaborative reasoning under open-ended conditions. This section critically examines emerging frameworks, reasoning methods, and communication paradigms, while highlighting challenges and future directions for building scalable, interpretable, and socially aligned LLM-integrated MAS. See Table 1 in Appendix for detailed overview of key frameworks. In distributed MAS architectures, on-device LLM deployment enables collaborative problem-solving while minimizing communication overhead (Zou et al. 2023). Resource-efficient frameworks such as nanoLM (Yao et al. 2024) further facilitate scaling by predicting performance without the cost of full-model training. Applications in economic simulations, like AI-Economist (Dizaji 2024), showcase the versatility of LLMs in modeling complex socio-economic behaviors."
        },
        {
            "title": "3.1 Reasoning and Decision-Making\nLLMs extend agent reasoning well beyond reactive policies by equipping agents\nwith contextual planning capabilities through techniques such as iterative prompt-\ning (Wang et al. 2023), which structures multi-step deliberation, and tagged context\nprompts (Feldman et al. 2023) that mitigate spurious outputs. Employing LLMs in\nmodeling social influence and private information dynamics, the TwinMarket (Yang\net al. 2025) multi-agent framework especially illustrates the nuanced reasoning\ncapacities unlocked by LLMs.",
            "content": "Moreover, architectural innovations in LLM-MAS integration, including Dynamic Diffusion (Zhang et al. 2025), Venn Diagram Prompting (Mahendru and Pandit 2024), and Grammar Masking (Netz et al. 2024), are able to refine agent decision-making by prioritizing relevant information and ensuring logical consistency. Meanwhile, frameworks like UniBias (Zhou et al. 2024) and long-term memory modules (Hou et al. 2024) offer promising strategies for aligning agent reasoning with human-like cognitive patterns. Task recognition (TR) and Task learning (TL) impact LLM reasoning, with TR performing well at small scales and TL improving with larger models (Pan 2023). Weak LLMs provides accurate feedback aligning with human preferences, even with reduced computational resources (Shankar et al. 2024; Zhao et al. 2024). Nonetheless, challenges persist in scaling reasoning fidelity, maintaining long-horizon coherence, and ensuring robustness across diverse, and dynamic environments. 5 These innovations mark progress, but we argue they often remain bounded by static task assumptions (Badshah et al. 2025) and pre-configured cognitive scaffolding (Händler 2023). To realize open-ended agency, we advocate that they must be mated to reasoning architectures that evolve in response to social context and allow agents to restructure their internal models through interaction-driven epistemic shifts."
        },
        {
            "title": "3.2 Interaction and Communication",
            "content": "Fig. 2 Unified architecture for LLM-driven generative agents in open-ended multi-agent simulations. The upper section depicts the short-term loop: Perception Reasoning Execution Communication Feedback Reception. The lower section highlights long-term development: Agent Adaptation and Role Evolution. Together, these components support both immediate reactivity and sustained co-evolution. Communication in LLMMAS has evolved from static message passing to richer paradigms of protocol emergence, reflexive dialogue, and relational reasoning. Benchmarks such as ToolQA (Zhuang et al. 2023) and inference manipulation strategies (Zhang et al. 2024) help optimize knowledge sharing and collaborative planning among agents. Similarly, emerging LLM-based reflexive communication techniques such as response refinement strategies like Recursive Introspection (RISE) (Qu et al. 2024) and Checkability Training (Kirchner et al. 2024), further enhance verifiability and reliability in agent conversations. Relational Forward Models (RFM) (Tacchetti et al. 2018). Frameworks like Smart Multi-Agent Robot Task Planning (SMART) (Yue et al. 2025) exemplify the growing emphasis on relational reasoning to structure complex multi-agent dialogues. But although LLMs have been employed in referential games (Lazaridou et al. 2017; Mordatch and Abbeel 2018) to facilitate the emergence of shared protocols and cooperation strategies using these advances, evaluating emergent communication behaviors at scale and ensuring their alignment with human social norms remain major open challenges (Zheng et al. 2024). Critically, despite methodological advances, most 6 frameworks treat communication as means for static task coordination rather than vehicle for social transformation. We contend that future systems must foreground communication as dynamic, co-constructive process through which agents evolve new roles, values, and collective norms. detailed system architecture diagram is provided in Figure 2."
        },
        {
            "title": "Simulation",
            "content": "Generative agents must move beyond lifelike behavior and toward longterm social transformation. Moving beyond individual agent capabilities, generative agents powered by LLMs enable simulations that capture human societies complexity, adaptability, and emergent dynamics. To highlight the necessity of this approach, the current section critically examines relevant frameworks and methodologies for deploying generative agents in social simulations, identifying key approaches for fostering adaptive behaviors and emergent social phenomena."
        },
        {
            "title": "4.1 Frameworks for Generative Agents in Social Simulations\nFrameworks for generative agents seek to create dynamic, scalable environments that\ntake advantage of their ability to demonstrate lifelike adaptability and continuous\nevolution. Systems such as IICA (CIAMPAGLIA 2013) leverage statistical calibration\nfor more robust social simulations, while frameworks like GAA (Yu et al. 2024) and\nAGA (Park et al. 2024) integrate LLMs to support real-time responses and policy\nreuse, respectively. In concert, these advances mark a shift away from rigid, rule-based\nmodels toward fluid, context-sensitive interactions.",
            "content": "Other recent developments combine multi-agent reinforcement learning (MARL) with generative agent-based modeling (GABM) (Dizaji 2024) to simulate more nuanced social behaviors. Deploying LLMs directly on devices (Zou et al. 2023) further enhances agent responsiveness in distributed environments by reducing latency. Notably, frameworks such as SMART (Sato 2024) and SurrealDriver (Jin et al. 2024) emphasize growing priorities around interpretability, memory integration, and emulating human-like decision-making processes. But while these frameworks demonstrate flexibility and responsiveness, their adaptability is often bounded by pre-design objectives. Fully living up to their potential and true alignment with real-world needs requires future systems to move beyond such scenario-specific tuning toward agents capable of revising their social roles, negotiating novel norms, and engaging in value-driven transformation across diverse environments. We contend that generative agents must continuously refine and reconfigure their social roles and behaviors in response to dynamic environments and interactions, rather than merely optimizing for predefined goals."
        },
        {
            "title": "4.2 Methodologies for Simulating Social Interactions\nImproving methodologies for simulating social interactions can be categorized into\nthree target dimensions: Adaptive Behaviors, Cognitive Processes, and Communica-\ntion and Reasoning, and collectively contribute to advancing the fidelity and richness\nof social simulations. For a structured summary of simulating social interactions with\nLLM-driven generative agents, see Table 2 in Appendix A.",
            "content": "Rigorous social simulation requires agents capable of nuanced, context-aware interactions. Methodologies like Reflexion (Shinn et al. 2023) and Reflection modules (Feng et al. 2023) empower agents to modulate their behaviors based on past experiences, while hierarchical role-playing (Deng and Mihalcea 2025; Shao et al. 2023) facilitates the representation of intricate social roles and relational dynamics. Cognitive strategies, including Concept-Guided Chain-of-Thought (CGCoT) prompting (Wu et al. 2024) and task decomposition (Kang and Xiong 2025), augment agents planning and problem-solving capabilities, and systems such as Lyfe Agents further refine multi-stage cognitive reasoning within fluid social environments (Kaiya et al. 2023). Regarding communicative aspects, referential games (Lazaridou et al. 2017; Mordatch and Abbeel 2018) foster the evolution of shared linguistic conventions and coordination paradigms, whereas advancements in causal reasoning (Imai and Nakamura 2024) and auditing methodologies (Jiao et al. 2025) bolster the transparency, verifiability, and safety characteristics of agent interactions. See Appendix for representative task scenarios enabled by these frameworks. However, although these methodologies significantly improve social simulation fidelity, systems applying them often operate within pre-defined cultural or task assumptions. It is our position that future agent modeling necessitates the inclusion of not only interactional realism but also cross-contextual generalization and the ability to derive novel social ontologies through bottom-up processes. Future methodologies should prioritize emergent norm formation and open-ended adaptation across diverse contexts."
        },
        {
            "title": "4.3 Adaptive Behaviors and Emergent Phenomena\nThe development of generative agents capable of modeling complex social systems\nnecessitates the fostering of adaptive behavior and emergent phenomena.",
            "content": "Currently, frameworks such as Richelieu (Guan et al. 2024), StateAct (Rozanov and Rei 2025), and EABSS (Siebers 2024) facilitate iterative skill development, selfevolution, and the modeling of complex behaviors. Memory architectures, such as DHMA (Hou et al. 2024), ensure coherent multi-turn interactions, thereby enabling agents to maintain consistent personas and social trajectories over extended periods. Furthermore, initiatives such as SAPLMA (Azaria and Mitchell 2023) integrate internal state analysis and trust metrics, both of which are critical for the construction of reliable and socially acceptable agents. Structured feedback mechanisms, exemplified by OCRM (Sun et al. 2025), further drive strategy refinement, meta-cognitive self-improvement, and the emergence of novel social behaviors over time. Despite meaningful progress in modeling local social interactions, current generative social modeling frameworks often fall short in enabling systemic societal evolution. 8 Many simulations still overfit to bounded task spaces or culturally narrow contexts, limiting their broader applicability. It is important that future research prioritize creating agents capable of cross-contextual adaptation and sustained societal innovation beyond initial design constraints. This paper thus advocates for research that explicitly models long-range normative drift, inter-agent value negotiation, and open-ended co-creation of social institutions."
        },
        {
            "title": "5 Open-ended Simulation and Co-evolution",
            "content": "To enhance the capacity of LLM driven simulations, open-ended simulations are designed to represent the ongoing development of agents and environments. This allows for the analysis of intricate adaptive systems, emergent occurrences, and fluid social frameworks. In contrast to conventional task-oriented configurations, openended simulations prioritize sustained innovation, reciprocal modification, and the manifestation of unanticipated behaviors over extended durations. But despite the important strides existing work has made, constraints remain due to rigid environmental scaffolds and narrow adaptation loops. To move forward, there is need to build systems designed for long-term transformation, not just short-term task generalization. This segment seeks to further substantiate the papers central premise that the progression of adaptive Artificial Intelligence (AI) is contingent upon the adoption of simulations where agents and environments undergo simultaneous evolution in limitless and unforeseen manners."
        },
        {
            "title": "5.1 Dynamic Scenario Evolution\nDynamic scenario evolution refers to simulations where environments change contin-\nuously, driven by both agent interactions and external inputs. Frameworks such as\nVOYAGER (Wang et al. 2023) and OpenWebVoyager (He et al. 2024) demonstrate\nthat agents can autonomously explore, adapt, and learn in evolving worlds. By engag-\ning in iterative feedback loops, agents refine their strategies and progressively build\nskill repertoires to navigate ever-changing environments. For example, in financial\nsimulations, dynamic adaptation mechanisms inspired by human memory systems\nallow agents to adjust flexibly to shifting market conditions (Li et al. 2023). Simi-\nlarly, metacognitive modules (Toy et al. 2024) use introspection to enhance agents’\nability to self-monitor and refine decision-making across increasingly complex tasks,\nsupporting sustained autonomy over time.",
            "content": "Meanwhile, incorporating real-world data, such as public sentiment in opinion dynamics simulations (Wei et al. 2024), allows agents to adapt their behavior, while diversity-driven data augmentation (Sahu et al. 2023) enhances scenario complexity to reflect real-world unpredictability. However, current dynamic scenario evolution techniques often rely on predefined rule adjustments or superficial environmental changes, which limit their overall potential. In contrast, this paper advocates for simulation environments that treat unpredictability as design objective, where agents are evaluated not just on task success 9 but on their capacity to generate, reshape, and outgrow task definitions themselves. Truly open-ended systems must empower agents to co-create new task domains, communication protocols, and value systems."
        },
        {
            "title": "5.2 Co-evolution of Agents and Environments\nCo-evolution highlights the potential for reciprocal adaptation between agents and\ntheir environments. As agents evolve and act, they reshape their surroundings, which\nin turn influences their subsequent behaviors. This dynamic feedback loop is critical\nfor modeling realistic societal and ecological systems.",
            "content": "Cognitive frameworks such as Global Workspace Theory (Zhang et al. 2025) allow agents to selectively process environmental information to adapt their behavior. The GABSS framework (Xiao et al. 2023) illustrates how agents can adjust to public events, fostering emergent phenomena at the societal level. Meanwhile, driving simulations like SurrealDriver (Jin et al. 2024) show how agent behaviors continuously adapt to human-like driving data, enhancing realism. Similarly, economic models such as TwinMarket (Yang et al. 2025) reveal that micro-level agent decisions aggregate into macro-level market dynamics, emphasizing the importance modeling agentenvironment interplay. Furthermore, marketplace models for AI training (Sarkar 2023) demonstrate that co-evolutionary processes drive innovation, as agents and environments mutually push each other toward novel capabilities. To maximize benefits, we contend that future research must explicitly prioritize mutual transformation between agents and their worlds, rather than merely using environments as static backdrops for agent benchmarking."
        },
        {
            "title": "5.3 Generative Agents in Open-ended Simulations\nGenerative agents often act as the engines of adaptability in open-ended simulations.\nBy integrating LLMs along with movement, perception, and memory systems, agents\ncan interact with dynamic environments in even more sophisticated ways (Verma et al.\n2023). Persona-driven data synthesis techniques (Ge et al. 2024a) further enrich the\ndiversity of integrated agent profiles, enabling more realistic social simulations and\nsynthetic data generation.",
            "content": "Nevertheless, significant challenges persist: hallucinations, alignment issues, and computational costs continue to limit the scalability and reliability of generative agents (Chen et al. 2025; Feng et al. 2024). Though stabilization methods, such as concept-based consistency measures (Yang et al. 2024) and external knowledge integration (Wang et al. 2023), offer promising paths for improving agent reasoning quality. Recent frameworks such as UAG (Ni et al. 2025) aim to equip agents with trustworthy decision-making capabilities in high-stakes contexts. In addition, balancing efficiency, interpretability, and open-ended adaptability remains critical frontier for future research. Critically, true co-evolution is not just about accelerating the speed and accuracy with which simulation agents can actuate and respond to environmental change; It requires expanding the breadth and depth of the innovation frontier itself. Agents 10 must be empowered not only to adapt but also to invent new domains of interaction, challenge established norms, and foster emergent complexities that transcend their original operational scope. Therefore, this paper calls for shift from adaptive behavior toward adaptive ontology, where systems empower agents to invent new categories of behavior rather than merely refining those that already exist. By empowering these innovations with open-ended continuous co-evolution, future where agents and environments co-evolve in complex, dynamic ways is achievable, supporting the creation of simulations that are more realistic, resilient, and socially meaningful."
        },
        {
            "title": "6 Emerging Applications and Open Challenges",
            "content": "The convergence of LLMs and MAS is significantly impacting scientific collaboration, societal modeling, and economic simulation, revealing the shortcomings of traditional static simulation. We argue that to fully realize the societal value of LLM-driven MAS, applications must shift from narrow optimization tasks toward fostering open-ended exploration, continuous feedback, and shared knowledge formation. This section highlights not only emerging applications but also reveals how current deployment trends may reinforce the limitations of static simulation paradigms. Three application domains are explored where LLM-driven MAS are demonstrating growing impact: scientific collaboration, societal modeling, and economic simulation (A detailed review of these applications, including representative systems and open challenges, is provided in Appendix B)."
        },
        {
            "title": "7 Challenges and Future Directions",
            "content": "Despite the remarkable progress in integrating LLMs into MAS and social simulations, several critical challenges remain. Addressing these challenges is essential for scaling, aligning, and securing adaptive systems while maximizing their societal benefit. In this section, key obstacles are systematically categorized, and research directions for 11 advancing the field are proposed (Specific technical challenges, including memory consolidation, system scaling, and safety risks, are detailed in Appendix E). Future work must be guided by first principles of open-endedness, co-evolution, and societal embedding, though there are challenges to abandoning retrofitting legacy benchmarks for increasingly dynamic systems. This section not only lists technical challenges but also articulates why many current research trajectories may remain overly focused on optimization, efficiency, or isolated fixes."
        },
        {
            "title": "7.1 Bias, Fairness, and Societal Impact\nLLM-driven agents risk inheriting and amplifying biases present in their training\ndata (Kamruzzaman et al. 2024; Chan et al. 2023), This can result in cultural misinter-\npretations, the reinforcement of stereotypes, and risks to credibility within simulated\nenvironments, even open-ended ones. To move beyond traditional bias mitigation\nefforts (Zhou et al. 2024; Xu et al. 2024), which are often static benchmarks, future\nresearch must prioritize promoting cultural adaptability and inclusivity, ensuring that\nsimulated societies reflect a broad spectrum of values.",
            "content": "Future frameworks must move beyond mitigation toward proactive norm pluralism, ensuring that simulations do not merely reflect but also challenge and reshape social imaginaries. As AI-driven simulations increasingly influence policymaking and public discourse, developing frameworks for responsible innovation and interdisciplinary governance will become ever more critical."
        },
        {
            "title": "Dynamics",
            "content": "Currently, existing evaluation benchmarks often prioritize task performance at the expense of capturing emergent system properties (Xiao et al. 2023; Siebers 2024). But to fully unlock the potential of open-ended simulations, robust methodologies for evaluating diversity, societal resilience, coordination quality, and long-term innovation must be developed. Proposed evaluation dimensions and metrics are detailed in Appendix D. Critically, evaluation frameworks should not merely reward expected outcomes, but also emphasize the discovery and characterization of novel, unanticipated behaviors. future"
        },
        {
            "title": "7.3 Open-ended and Co-evolutionary Simulation Design\nThe development of genuinely open-ended, co-evolutionary simulations necessitates\nthe concurrent evolution of agents and environments, fostering a continuous cycle of\nchallenge and adaptation (Wang et al. 2023; Verma et al. 2023). Realization of this\nobjective requires advancements in dynamic environment generation, evolutionary\nagent architectures, and adaptive trust calibration. System designs must explicitly pri-\noritize novelty and resilience, embracing inherent unpredictability over the imposition\nof constraints.",
            "content": ""
        },
        {
            "title": "7.4 Research Priorities and Roadmap",
            "content": "We predict that within the next decade, open-ended, co-evolutionary multi-agent simulations are poised to become the leading testbed for adaptive AI, overtaking static benchmarks. However, realizing this potential necessitates fundamental shift in how we approach evaluation standards, safety protocols, and societal modeling. Drawing on identified challenges, the following are key priorities for future research: (a) Designing culturally adaptive, memory-augmented generative agents capable of lifelong learning and dynamic role adaptation. (b) Developing lightweight, communication-efficient LLM surrogates that enable scalable, heterogeneous simulations. (c) Formalizing evaluation frameworks for emergent behaviors, systemic resilience, and societal alignment. (d) Embedding continuous safety monitoring, fairness auditing, and ethical safeguards into multi-agent architectures. (e) Fostering interdisciplinary collaboration among AI researchers, cognitive scientists, ethicists, and policymakers to align simulation objectives with broader societal values. By embracing unpredictability and focusing on long-term adaptability, the research community can move closer to building resilient, interpretable, and socially beneficial LLM-driven multi-agent ecosystems. By examining these areas, more profound understanding of societal complexity, adaptation, and innovation can be achieved. This deeper knowledge can then pave the way for new generation of adaptable and continuously evolving AI systems."
        },
        {
            "title": "8 Conclusion",
            "content": "This research critically examines prevailing assumptions concerning the integration of LLMs within MAS and social simulations. While acknowledging certain constrained successes, extant systems exhibit deficiency in accurately reflecting the dynamic, progressive, and complex social attributes of real-world societies. In addressing these limitations, this paper proposes transition from static, objective-oriented assessments to taxonomy grounded in fluctuating situational dynamics, the co-evolution of agents and their environments, and the deployment of generative agent architectures. Further, it offers research roadmap outlining social fairness, evaluation and design challenges needing addressing, including long-term memory consolidation, bias mitigation, scalable efficiency, and emergent behavior evaluation. These priorities reflect the broader aim to replace brittle optimization pipelines with adaptable, resilient, and norm-aware agent ecosystems. Looking ahead, we contend that open-ended, co-evolutionary multiagent simulations must define the next decade of adaptive AI research. Embracing unpredictability is not liability to be controlled but catalyst for innovation, resilience, and societal relevance. Only by committing to this shift can we unlock new pathways for fostering emergent innovation, enhancing societal resilience, and advancing the frontier of adaptive AI. Acknowledgements. The authors used large language model to assist with grammar and stylistic polishing. All substantive ideas, analyses, and conclusions remain 13 the responsibility of the authors, and any suggestions from the tool were reviewed and edited before inclusion."
        },
        {
            "title": "References",
            "content": "Azaria, A., Mitchell, T.: The Internal State of an LLM Knows When Its Lying. arXiv. arXiv:2304.13734 [cs] (2023). https://doi.org/10.48550/arXiv.2304.13734 . http://arxiv.org/abs/2304.13734 Accessed 2025-04-28 Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y.T., Li, Y., Lundberg, S., Nori, H., Palangi, H., Ribeiro, M.T., Zhang, Y.: Sparks of Artificial General Intelligence: Early experiments with GPT-4 (2023). https://arxiv.org/abs/2303.12712 Badshah, S., Emami, A., Sajjad, H.: TALE: Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models (2025). https://arxiv.org/ abs/2504.07385 Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are few-shot learners. Advances in neural information processing systems 33, 18771901 (2020) Bo, X., Zhang, Z., Dai, Q., Feng, X., Wang, L., Li, R., Chen, X., Wen, J.-R.: Reflective multi-agent collaboration based on large language models. Advances in Neural Information Processing Systems 37, 138595138631 (2024) CIAMPAGLIA, G.L.: FRAMEWORK FOR THE CALIBRATION OF SOCIAL SIMULATION MODELS (2013). https://doi.org/10.1142/S0219525913500306 . https://www.worldscientific.com/doi/abs/10.1142/S0219525913500306 Accessed 2025-04Chen, S., Liu, Y., Han, W., Zhang, W., Liu, T.: Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application. arXiv. arXiv:2412.17481 [cs] (2025). https://doi.org/10.48550/arXiv.2412.17481 . http: //arxiv.org/abs/2412.17481 Accessed 2025-04-28 Chan, S., Li, J., Yao, B., Mahmood, A., Huang, C.-M., Jimison, H., Mynatt, E.D., Wang, D.: \"Mango Mango, How to Let The Lettuce Dry Without Spinner?: Exploring User Perceptions of Using An LLM-Based Conversational Assistant Toward Cooking Partner. arXiv. arXiv:2310.05853 [cs] (2023). https://doi.org/10. 48550/arXiv.2310.05853 . http://arxiv.org/abs/2310.05853 Accessed 2025-04-27 Cheng, Y., Zhang, C., Zhang, Z., Meng, X., Hong, S., Li, W., Wang, Z., Wang, Z., Yin, F., Zhao, J., He, X.: Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects (2024). https://arxiv.org/abs/2401.03428 Dizaji, A.S.: Incentives to Build Houses, Trade Houses, or Trade House Building 14 Skills in Simulated Worlds under Various Governing Systems or Institutions: Comparing Multi-agent Reinforcement Learning to Generative Agent-based Model. arXiv. arXiv:2411.17724 [cs] (2024). https://doi.org/10.48550/arXiv.2411.17724 . http://arxiv.org/abs/2411.17724 Accessed 2025-04Deng, N., Mihalcea, R.: Are Human Interactions Replicable by Generative Agents? Case Study on Pronoun Usage in Hierarchical Interactions. arXiv. arXiv:2501.15283 [cs] (2025). https://doi.org/10.48550/arXiv.2501.15283 . http://arxiv.org/abs/ 2501.15283 Accessed 2025-04-28 Feldman, P., Foulds, J.R., Pan, S.: Trapping LLM Hallucinations Using Tagged Context Prompts. arXiv. arXiv:2306.06085 [cs] (2023). https://doi.org/10.48550/arXiv. 2306.06085 . http://arxiv.org/abs/2306.06085 Accessed 2025-04-28 Feng, X., Feng, X., Qin, B.: The Role of Summarization in Generative Agents: Preliminary Perspective. arXiv. arXiv:2305.01253 [cs] (2023). https://doi.org/10. 48550/arXiv.2305.01253 . http://arxiv.org/abs/2305.01253 Accessed 2025-04-28 Fleming, S.L., Lozano, A., Haberkorn, W.J., Jindal, J.A., Reis, E.P., Thapa, R., Blankemeier, L., Genkins, J.Z., Steinberg, E., Nayak, A., Patel, B.S., Chiang, C.-C., Callahan, A., Huo, Z., Gatidis, S., Adams, S.J., Fayanju, O., Shah, S.J., Savage, T., Goh, E., Chaudhari, A.S., Aghaeepour, N., Sharp, C., Pfeffer, M.A., Liang, P., Chen, J.H., Morse, K.E., Brunskill, E.P., Fries, J.A., Shah, N.H.: MedAlign: ClinicianGenerated Dataset for Instruction Following with Electronic Medical Records. arXiv. arXiv:2308.14089 [cs] (2023). https://doi.org/10.48550/arXiv.2308.14089 . http://arxiv.org/abs/2308.14089 Accessed 2025-04-28 Feng, S., Wan, H., Wang, N., Tan, Z., Luo, M., Tsvetkov, Y.: What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection. arXiv. arXiv:2402.00371 [cs] (2024). https://doi.org/10.48550/arXiv.2402.00371 . http://arxiv.org/abs/2402.00371 Accessed 2025-04-28 Ge, T., Chan, X., Wang, X., Yu, D., Mi, H., Yu, D.: Scaling Synthetic Data Creation with 1,000,000,000 Personas. arXiv. arXiv:2406.20094 [cs] (2024). https://doi.org/ 10.48550/arXiv.2406.20094 . http://arxiv.org/abs/2406.20094 Accessed 2025-04Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N.V., Wiest, O., Zhang, X.: Large Language Model based Multi-Agents: Survey of Progress and Challenges. arXiv. arXiv:2402.01680 [cs] (2024). https://doi.org/10.48550/arXiv.2402.01680 . http://arxiv.org/abs/2402.01680 Accessed 2025-05-22 Guan, Z., Kong, X., Zhong, F., Wang, Y.: Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy. arXiv. arXiv:2407.06813 [cs] (2024). https://doi.org/10.48550/ arXiv.2407.06813 . http://arxiv.org/abs/2407.06813 Accessed 2025-04-28 Gilbert, N., Troitzsch, K.: Simulation for the Social Scientist. McGraw-Hill Education (UK), Maidenhead, UK (2005) 15 Ghosh, S., Varshney, P., Galinkin, E., Parisien, C.: AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM Experts. arXiv. arXiv:2404.05993 [cs] (2024). https://doi.org/10.48550/arXiv.2404.05993 . http://arxiv.org/abs/ 2404.05993 Accessed 2025-04Händler, T.: Balancing autonomy and alignment: multi-dimensional taxonllm-powered multi-agent architectures. arXiv preprint omy for autonomous arXiv:2310.03659 (2023) Ha, H., Florence, P., Song, S.: Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition. arXiv. arXiv:2307.14535 [cs] (2023). https://doi.org/10. 48550/arXiv.2307.14535 . http://arxiv.org/abs/2307.14535 Accessed 2025-04-28 Hua, Y., Qu, L., Haf, R.: Assistive large language model agents for socially-aware negotiation dialogues. In: Al-Onaizan, Y., Bansal, M., Chen, Y.-N. (eds.) Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 80478074. Association for Computational Linguistics, Miami, Florida, USA (2024). https: //doi.org/10.18653/v1/2024.findings-emnlp.473 . https://aclanthology.org/2024. findings-emnlp.473/ Hou, Y., Tamoto, H., Miyashita, H.: \"My agent understands me better\": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents. In: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems. CHI EA 24, pp. 17. Association for Computing Machinery, New York, NY, USA (2024). https://doi.org/10.1145/3613905.3650839 . https://dl.acm.org/doi/10.1145/3613905.3650839 Accessed 2025-04-27 He, H., Yao, W., Ma, K., Yu, W., Zhang, H., Fang, T., Lan, Z., Yu, D.: OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization. arXiv. arXiv:2410.19609 [cs] (2024). https://doi.org/ 10.48550/arXiv.2410.19609 . http://arxiv.org/abs/2410.19609 Accessed 2025-04Imai, K., Nakamura, K.: Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments. arXiv. arXiv:2410.00903 [stat] (2024). https://doi.org/10.48550/arXiv.2410.00903 . http://arxiv.org/abs/2410. 00903 Accessed 2025-04-28 Jiao, J., Afroogh, S., Xu, Y., Phillips, C.: Navigating LLM Ethics: Advancements, Challenges, and Future Directions. arXiv. arXiv:2406.18841 [cs] (2025). https:// doi.org/10.48550/arXiv.2406.18841 . http://arxiv.org/abs/2406.18841 Accessed 2025-04-28 Jin, H., Huang, L., Cai, H., Yan, J., Li, B., Chen, H.: From LLMs to LLM-based Agents for Software Engineering: Survey of Current, Challenges and Future. arXiv. arXiv:2408.02479 [cs] (2025). https://doi.org/10.48550/arXiv.2408.02479 . http://arxiv.org/abs/2408.02479 Accessed 2025-05-22 16 Jiang, F., Xu, Z., Niu, L., Wang, B., Jia, J., Li, B., Poovendran, R.: Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications. arXiv. arXiv:2311.16153 [cs] (2023). https://doi.org/10.48550/arXiv.2311.16153 . http://arxiv.org/abs/ 2311.16153 Accessed 2025-04-28 Jin, Y., Yang, R., Yi, Z., Shen, X., Peng, H., Liu, X., Qin, J., Li, J., Xie, J., Gao, P., Zhou, G., Gong, J.: SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers Driving-thinking Data. In: 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 966971 (2024). https://doi.org/10.1109/IROS58592.2024.10802229 . ISSN: 2153-0866. https : / / ieeexplore . ieee . org / abstract / document / 10802229 Accessed 2025-04Kirchner, J.H., Chen, Y., Edwards, H., Leike, J., McAleese, N., Burda, Y.: ProverVerifier Games improve legibility of LLM outputs. arXiv. arXiv:2407.13692 [cs] (2024). https://doi.org/10.48550/arXiv.2407.13692 . http://arxiv.org/abs/2407. 13692 Accessed 2025-04-28 Kamruzzaman, M., Nguyen, H., Hassan, N., Kim, G.L.: \"A Woman is More Culturally Knowledgeable than Man?\": The Effect of Personas on Cultural Norm Interpretation in LLMs. arXiv. arXiv:2409.11636 [cs] (2024). https://doi.org/10.48550/ arXiv.2409.11636 . http://arxiv.org/abs/2409.11636 Accessed 2025-04-27 Kaiya, Z., Naim, M., Kondic, J., Cortes, M., Ge, J., Luo, S., Yang, G.R., Ahn, A.: Lyfe Agents: Generative agents for low-cost real-time social interactions. arXiv. arXiv:2310.02172 [cs] (2023). https://doi.org/10.48550/arXiv.2310.02172 . http: //arxiv.org/abs/2310.02172 Accessed 2025-04-30 Kang, H., Xiong, C.: ResearchArena: Benchmarking Large Language Models Ability to Collect and Organize Information as Research Agents. arXiv. arXiv:2406.10291 [cs] (2025). https://doi.org/10.48550/arXiv.2406.10291 . http://arxiv.org/abs/ 2406.10291 Accessed 2025-04-28 Lu, Y., Aleta, A., Du, C., Shi, L., Moreno, Y.: Generative Agent-Based Models for Complex Systems Research: review. arXiv. arXiv:2408.09175 [physics] (2024). https://doi.org/10.48550/arXiv.2408.09175 . http://arxiv.org/abs/2408.09175 Accessed 2025-05-22 Lee, Y.-J., Lee, D., Youn, J., Oh, K., Choi, H.-J.: Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model. arXiv. arXiv:2411.04496 [cs] (2024). https://doi.org/10.48550/arXiv.2411.04496 . http://arxiv.org/abs/ 2411.04496 Accessed 2025-04Lazaridou, A., Peysakhovich, A., Baroni, M.: Multi-Agent Cooperation and the Emergence of (Natural) Language. arXiv. arXiv:1612.07182 [cs] (2017). https://doi.org/ 10.48550/arXiv.1612.07182 . http://arxiv.org/abs/1612.07182 Accessed 2025-04-28 17 Larooij, M., Törnberg, P.: Do large language models solve the problems of agentbased modeling? critical review of generative social simulations. arXiv preprint arXiv:2504.03274 (2025) Li, Y., Yu, Y., Li, H., Chen, Z., Khashanah, K.: TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance. arXiv. arXiv:2309.03736 [q-fin] (2023). https://doi.org/10.48550/arXiv. 2309.03736 . http://arxiv.org/abs/2309.03736 Accessed 2025-04-28 Liu, X., Yu, H., Zhang, H., Xu, Y., Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., Zhang, S., Deng, X., Zeng, A., Du, Z., Zhang, C., Shen, S., Zhang, T., Su, Y., Sun, H., Huang, M., Dong, Y., Tang, J.: AgentBench: Evaluating LLMs as Agents. arXiv. arXiv:2308.03688 [cs] (2023). https://doi.org/10.48550/arXiv.2308.03688 . http://arxiv.org/abs/2308.03688 Accessed 2025-05-22 Luo, J., Zhang, W., Yuan, Y., Zhao, Y., Yang, J., Gu, Y., Wu, B., Chen, B., Qiao, Z., Long, Q., Tu, R., Luo, X., Ju, W., Xiao, Z., Wang, Y., Xiao, M., Liu, C., Yuan, J., Zhang, S., Jin, Y., Zhang, F., Wu, X., Zhao, H., Tao, D., Yu, P.S., Zhang, M.: Large Language Model Agent: Survey on Methodology, Applications and Challenges. arXiv. arXiv:2503.21460 [cs] (2025). https://doi.org/10.48550/arXiv.2503.21460 . http://arxiv.org/abs/2503.21460 Accessed 2025-05Lin, J., Zhao, H., Zhang, A., Wu, Y., Ping, H., Chen, Q.: AgentSims: An OpenSource Sandbox for Large Language Model Evaluation. arXiv. arXiv:2308.04026 [cs] (2023). https://doi.org/10.48550/arXiv.2308.04026 . http://arxiv.org/abs/2308. 04026 Accessed 2025-05-22 Mordatch, I., Abbeel, P.: Emergence of Grounded Compositional Language in MultiAgent Populations. Proceedings of the AAAI Conference on Artificial Intelligence 32(1) (2018) https://doi.org/10.1609/aaai.v32i1.11492 . Number: 1. Accessed 202504-28 Mou, X., Ding, X., He, Q., Wang, L., Liang, J., Zhang, X., Sun, L., Lin, J., Zhou, J., Huang, X., et al.: From individual to society: survey on social simulation driven by large language model-based agents. arXiv preprint arXiv:2412.03563 (2024) Meyer, S., Elsweiler, D.: \"You tell me\": Dataset of GPT-4-Based Behaviour Change Support Conversations. In: Proceedings of the 2024 Conference on Human Information Interaction and Retrieval. CHIIR 24, pp. 411416. Association for Computing Machinery, New York, NY, USA (2024). https://doi.org/10.1145/3627508.3638330 . https://dl.acm.org/doi/10.1145/3627508.3638330 Accessed 2025-04-27 Mahendru, S., Pandit, T.: Venn Diagram Prompting: Accelerating Comprehension with Scaffolding Effect. In: 2024 6th World Symposium on Artificial Intelligence (WSAI), pp. 3948 (2024). https://doi.org/10.1109/WSAI62426.2024.10828919 . https://ieeexplore.ieee.org/abstract/document/10828919 Accessed 2025-04-28 Mishra, R., Welch, K.C., Popa, D.O.: Human-mediated Large Language Models for Robotic Intervention in Children with Autism Spectrum Disorders. arXiv. arXiv:2402.00260 [cs] (2024). https://doi.org/10.48550/arXiv.2402.00260 . http: //arxiv.org/abs/2402.00260 Accessed 2025-04-28 Netz, L., Reimer, J., Rumpe, B.: Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks. In: Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems. MODELS Companion 24, pp. 115122. Association for Computing Machinery, New York, NY, USA (2024). https://doi.org/10.1145/3652620.3687805 . https: //dl.acm.org/doi/10.1145/3652620.3687805 Accessed 2025-04-27 Ni, B., Wang, Y., Cheng, L., Blasch, E., Derr, T.: Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective. Proceedings of the AAAI Conference on Artificial Intelligence 39(12), 1241712425 (2025) https://doi.org/ 10.1609/aaai.v39i12.33353 . Number: 12. Accessed 2025-04-28 Pan, J.: What In-Context Learning Learns In-Context: Disentangling Task Recognition and Task Learning. M.S.E., Your University (2023). ISBN: 9798379717438 Piatti, G., Jin, Z., Kleiman-Weiner, M., Schölkopf, B., Sachan, M., Mihalcea, R.: Cooperate or collapse: Emergence of sustainable cooperation in society of llm agents. Advances in Neural Information Processing Systems 37, 111715111759 (2024) Park, J.S., OBrien, J., Cai, C.J., Morris, M.R., Liang, P., Bernstein, M.S.: Generative agents: Interactive simulacra of human behavior. In: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. UIST 23. Association for Computing Machinery, New York, NY, USA (2023). https://doi.org/10.1145/ 3586183.3606763 . https://doi.org/10.1145/3586183. Park, J.S., Zou, C.Q., Shaw, A., Hill, B.M., Cai, C., Morris, M.R., Willer, R., Liang, P., Bernstein, M.S.: Generative Agent Simulations of 1,000 People. arXiv. arXiv:2411.10109 [cs] (2024). https://doi.org/10.48550/arXiv.2411.10109 . http: //arxiv.org/abs/2411.10109 Accessed 2025-04-28 Qu, Y., Zhang, T., Garg, N., Kumar, A.: Recursive Introspection: Teaching Language Model Agents How to Self-Improve. arXiv. arXiv:2407.18219 [cs] (2024). https: //doi.org/10.48550/arXiv.2407.18219 . http://arxiv.org/abs/2407.18219 Accessed 2025-04-28 Rozanov, N., Rei, M.: StateAct: Enhancing LLM Base Agents via Self-prompting and State-tracking. arXiv. arXiv:2410.02810 [cs] (2025). https://doi.org/10.48550/ arXiv.2410.02810 . http://arxiv.org/abs/2410.02810 Accessed 2025-04-28 Sarkar, D.: Viz: QLoRA-based Copyright Marketplace for Legally Compliant Generative AI. arXiv. arXiv:2401.00503 [cs] (2023). https://doi.org/10.48550/arXiv. 19 2401.00503 . http://arxiv.org/abs/2401.00503 Accessed 2025-04Sato, M.: GAI: Generative Agents for Innovation. arXiv. arXiv:2412.18899 [cs] (2024). https://doi.org/10.48550/arXiv.2412.18899 . http://arxiv.org/abs/2412.18899 Accessed 2025-04-28 Shinn, N., Cassano, F., Berman, E., Gopinath, A., Narasimhan, K., Yao, S.: Reflexion: Language Agents with Verbal Reinforcement Learning. arXiv. arXiv:2303.11366 [cs] (2023). https://doi.org/10.48550/arXiv.2303.11366 . http://arxiv.org/abs/2303. 11366 Accessed 2025-04-28 Siebers, P.-O.: Exploring the Potential of Conversational AI Support for Agent-Based Social Simulation Model Design. arXiv. arXiv:2405.08032 [cs] (2024). https://doi. org/10.48550/arXiv.2405.08032 . http://arxiv.org/abs/2405.08032 Accessed 202504-28 Shoham, Y., Leyton-Brown, K.: Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations. Cambridge University Press, USA (2008) Shao, Y., Li, L., Dai, J., Qiu, X.: Character-LLM: Trainable Agent for Role-Playing. arXiv. arXiv:2310.10158 [cs] (2023). https://doi.org/10.48550/arXiv.2310.10158 . http://arxiv.org/abs/2310.10158 Accessed 2025-04Shi, X., Liu, J., Liu, Y., Cheng, Q., Lu, W.: Know where to go: Make LLM relevant, responsible, and trustworthy searchers. Decision Support Systems 188, 114354 (2025) https://doi.org/10.1016/j.dss.2024.114354 . Accessed 2025-04-28 Sun, H., Shen, Y., Ton, J.-F.: Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives. arXiv. arXiv:2411.04991 [cs] (2025). https://doi.org/10.48550/arXiv.2411.04991 . http://arxiv.org/abs/ 2411.04991 Accessed 2025-04-28 Sahu, G., Vechtomova, O., Bahdanau, D., Laradji, I.H.: PromptMix: Class Boundary Augmentation Method for Large Language Model Distillation. arXiv. arXiv:2310.14192 [cs] (2023). https://doi.org/10.48550/arXiv.2310.14192 . http: //arxiv.org/abs/2310.14192 Accessed 2025-04-28 Shankar, S., Zamfirescu-Pereira, J.D., Hartmann, B., Parameswaran, A., Arawjo, I.: Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences. In: Proceedings of the 37th Annual ACM Symposium on User Interface Software And Technology. UIST 24, pp. 114. Association for Computing Machinery, New York, NY, USA (2024). https://doi.org/10.1145/3654777. 3676450 . https://dl.acm.org/doi/10.1145/3654777.3676450 Accessed 2025-04-27 Toy, J., MacAdam, J., Tabor, P.: Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior. arXiv. arXiv:2401.10910 [q-bio] (2024). https://doi.org/10.48550/arXiv.2401.10910 . http://arxiv.org/abs/ 2401.10910 Accessed 2025-04-28 Tacchetti, A., Song, H.F., Mediano, P.A.M., Zambaldi, V., Rabinowitz, N.C., Graepel, T., Botvinick, M., Battaglia, P.W.: Relational Forward Models for Multi-Agent Learning. arXiv. arXiv:1809.11044 [cs] (2018). https://doi.org/10.48550/arXiv. 1809.11044 . http://arxiv.org/abs/1809.11044 Accessed 2025-04-28 Unlu, E.: Chatmap : Large Language Model Interaction with Cartographic Data. arXiv. arXiv:2310.01429 [cs] (2023). https://doi.org/10.48550/arXiv.2310.01429 . http://arxiv.org/abs/2310.01429 Accessed 2025-04-28 Verma, D., Mumm, O., Carlow, V.M.: Generative agents in the streets: Exploring the use of Large Language Models (LLMs) in collecting urban perceptions. arXiv. arXiv:2312.13126 [cs] (2023). https://doi.org/10.48550/arXiv.2312.13126 . http: //arxiv.org/abs/2312.13126 Accessed 2025-04-28 Wang, L., Hu, Y., He, J., Xu, X., Liu, N., Liu, H., Shen, H.T.: T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Mixed Large Language Model Signals for Science Question Answering. arXiv. arXiv:2305.03453 [cs] (2023). https://doi. org/10.48550/arXiv.2305.03453 . http://arxiv.org/abs/2305.03453 Accessed 202504-28 Wooldridge, M., Jennings, N.R.: Intelligent agents: theory and practice. The Knowledge Engineering Review 10(2), 115152 (1995) https://doi.org/10.1017/ S0269888900008122 Wu, P.Y., Nagler, J., Tucker, J.A., Messing, S.: Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scoring of Texts with Large Language Models. In: 2024 IEEE International Conference on Big Data (BigData), pp. 72327241 (2024). https://doi.org/10.1109/BigData62323.2024.10825235 . ISSN: 2573-2978. https://ieeexplore.ieee.org/abstract/document/10825235 Accessed 2025-04-28 Wang, W., Obi, I., Bera, A., Min, B.-C.: Unifying Large Language Model and Deep Reinforcement Learning for Human-in-Loop Interactive Socially-aware Navigation. arXiv. ADS Bibcode: 2024arXiv240315648W (2024). https://doi.org/10.48550/ arXiv.2403.15648 . https://ui.adsabs.harvard.edu/abs/2024arXiv240315648W Accessed 2025-04-28 Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., Anandkumar, A.: Voyager: An Open-Ended Embodied Agent with Large Language Models. arXiv. arXiv:2305.16291 [cs] (2023). https://doi.org/10.48550/arXiv.2305.16291 . http: //arxiv.org/abs/2305.16291 Accessed 2025-04-28 Wei, Q., Xue, R., Wang, Y., Xiao, H., Wang, Y., Duan, X.: Mimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers. arXiv. arXiv:2407.20668 [cs] (2024). https://doi.org/10.48550/arXiv.2407. 20668 . http://arxiv.org/abs/2407.20668 Accessed 2025-04-28 Xu, Y., Xue, B., Sheng, S., Deng, C., Ding, J., Shen, Z., Fu, L., Wang, X., Zhou, C.: Good Idea or Not, Representation of LLM Could Tell. arXiv. arXiv:2409.13712 [cs] (2024). https://doi.org/10.48550/arXiv.2409.13712 . http://arxiv.org/abs/2409. 13712 Accessed 2025-04-28 Xiao, B., Yin, Z., Shan, Z.: Simulating Public Administration Crisis: Novel Generative Agent-Based Simulation System to Lower Technology Barriers in Social Science Research. arXiv. arXiv:2311.06957 [cs] (2023). https://doi.org/10.48550/ arXiv.2311.06957 . http://arxiv.org/abs/2311.06957 Accessed 2025-04-28 Yang, Y., Duan, H., Liu, J., Tam, K.Y.: LLM-Measure: Generating Valid, Consistent, and Reproducible Text-Based Measures for Social Science Research. arXiv. arXiv:2409.12722 [cs] (2024). https://doi.org/10.48550/arXiv.2409.12722 . http: //arxiv.org/abs/2409.12722 Accessed 2025-04-28 Yehudai, A., Eden, L., Li, A., Uziel, G., Zhao, Y., Bar-Haim, R., Cohan, A., ShmueliScheuer, M.: Survey on Evaluation of LLM-based Agents. arXiv. arXiv:2503.16416 [cs] (2025). https://doi.org/10.48550/arXiv.2503.16416 . http://arxiv.org/abs/ 2503.16416 Accessed 2025-05-22 Yao, Y., fan, S., Huang, X., Fang, X., Li, X., Ni, Z., Jiang, X., Meng, X., Han, P., Shang, S., Liu, K., Sun, A., Wang, Y.: nanoLM: an Affordable LLM Pre-training Benchmark via Accurate Loss Prediction across Scales. arXiv. arXiv:2304.06875 [cs] (2024). https://doi.org/10.48550/arXiv.2304.06875 . http://arxiv.org/abs/2304. 06875 Accessed 2025-04-28 Yang, S., Lee, G., Cho, J., Papailiopoulos, D., Lee, K.: Predictive Pipelined Decoding: Compute-Latency Trade-off for Exact LLM Decoding. arXiv. arXiv:2307.05908 [cs] (2024). https://doi.org/10.48550/arXiv.2307.05908 . http://arxiv.org/abs/ 2307.05908 Accessed 2025-04Yue, S., Wang, S., Chen, W., Huang, X., Wei, Z.: Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks. Proceedings of the AAAI Conference on Artificial Intelligence 39(24), 2579625804 (2025) https://doi.org/ 10.1609/aaai.v39i24.34772 . Number: 24. Accessed 2025-04-28 Yu, Y., Zhang, Q., Li, J., Fu, Q., Ye, D.: Affordable Generative Agents. arXiv. arXiv:2402.02053 [cs] (2024). https://doi.org/10.48550/arXiv.2402.02053 . http: //arxiv.org/abs/2402.02053 Accessed 2025-04-28 Yang, Y., Zhang, Y., Wu, M., Zhang, K., Zhang, Y., Yu, H., Hu, Y., Wang, B.: TwinMarket: Scalable Behavioral and Social Simulation for Financial Markets. arXiv. arXiv:2502.01506 [cs] (2025). https://doi.org/10.48550/arXiv.2502.01506 . http://arxiv.org/abs/2502.01506 Accessed 2025-04-28 Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.: ReAct: Synergizing reasoning and acting in language models. In: International Conference on 22 Learning Representations (ICLR) (2023) Zhou, H., Feng, Z., Zhu, Z., Qian, J., Mao, K.: UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation. arXiv. arXiv:2405.20612 [cs] (2024). https://doi.org/10.48550/arXiv.2405.20612 . http://arxiv.org/abs/ 2405.20612 Accessed 2025-04-28 Zhou, Z., Lin, Y., Li, Y.: Large language model empowered participatory urban planning. arXiv. arXiv:2402.01698 [cs] (2024). https://doi.org/10.48550/arXiv.2402. 01698 . http://arxiv.org/abs/2402.01698 Accessed 2025-04-28 Zheng, D., Liu, D., Lapata, M., Pan, J.Z.: TrustScore: Reference-Free Evaluation of LLM Response Trustworthiness. arXiv. arXiv:2402.12545 [cs] (2024). https:// doi.org/10.48550/arXiv.2402.12545 . http://arxiv.org/abs/2402.12545 Accessed 2025-04-28 Zhang, B., Soh, H.: Large Language Models as Zero-Shot Human Models for HumanRobot Interaction. In: 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 79617968 (2023). https://doi.org/10.1109/ IROS55552.2023.10341488 . ISSN: 2153-0866. https://ieeexplore.ieee.org/abstract/ document/10341488 Accessed 2025-04-28 Zhang, Y., Wu, Y., Hua, W., Lu, X., Hu, X.: Understanding Dynamic Diffusion Process of LLM-based Agents under Information Asymmetry. arXiv. arXiv:2502.13160 [cs] (2025). https://doi.org/10.48550/arXiv.2502.13160 . http://arxiv.org/abs/ 2502.13160 Accessed 2025-04-28 Zheng, J., Wang, H., Zhang, A., Nguyen, T.D., Sun, J., Chua, T.-S.: ALI-Agent: Assessing LLMs Alignment with Human Values via Agent-based Evaluation. arXiv. arXiv:2405.14125 [cs] (2024). https://doi.org/10.48550/arXiv.2405.14125 . http: //arxiv.org/abs/2405.14125 Accessed 2025-04Zhao, X., Yang, X., Pang, T., Du, C., Li, L., Wang, Y.-X., Wang, W.Y.: Weakto-strong jailbreaking on large language models. arXiv preprint arXiv:2401.17256 (2024) Zhang, Q., Yu, X., Singh, C., Liu, X., Liu, L., Gao, J., Zhao, T., Roth, D., Cheng, H.: Model Tells Itself Where to Attend: Faithfulness Meets Automatic Attention Steering. arXiv. arXiv:2409.10790 [cs] (2024). https://doi.org/10.48550/arXiv.2409. 10790 . http://arxiv.org/abs/2409.10790 Accessed 2025-04-28 Zhuang, Y., Yu, Y., Wang, K., Sun, H., Zhang, C.: ToolQA: Dataset for LLM Question Answering with External Tools. arXiv. arXiv:2306.13304 [cs] (2023). https: //doi.org/10.48550/arXiv.2306.13304 . http://arxiv.org/abs/2306.13304 Accessed 2025-04-28 Zou, H., Zhao, Q., Bariah, L., Bennis, M., Debbah, M.: Wireless Multi-Agent 23 Generative AI: From Connected Intelligence to Collective Intelligence. arXiv. arXiv:2307.02757 [cs] (2023). https://doi.org/10.48550/arXiv.2307.02757 . http: //arxiv.org/abs/2307.02757 Accessed 2025-04-"
        },
        {
            "title": "A Tables for Key Frameworks",
            "content": "- b f , t l l m u n a a e , o i i p i p n r - , t u a i d s l e a i , t n s c m A - x r - o r i 3 2 0 a ( d , m o c p y i , u c e , y t l p i r m e a s e e a s i m t t n c d t n n , a , h f i v h h h e t h . t e r n s s r i o t n s i e i u l i d : N . i u i e - u d - o l fi h E . a r t m a s t a - u v - L s w r k e e 1 a . a o a i i n r y f n t 4 t s s t a e n a p a r m n a i i b 4 2 0 2 ( a b e ) 4 2 0 2 . e G V ) 3 2 0 2 . e - n a p , l m e fl a S t m e m i n 5 2 0 2 Y ( r i o z x r e i s i g t n , m d t , l a r n a n c n n a i y o c n 4 2 0 2 z ( m c ) 4 2 0 ) 5 2 0 2 . e - o l e i e e c r g r e d - t t , l m a l r u i u l i S 4 2 0 2 ) 4 2 0 2 z ( G - n , l m e e d a - n a i i D 4 2 0 2 ( i a u i e y c r t a ) 4 2 0 2 . e - r g - u , n l o j - k e n i - e n 5 2 0 2 . t Y ( M i p - l , e g l - S t o d c l I 4 2 0 2 G ( n e n t i o ) 4 2 0 2 . e l i ) 5 2 0 i b e g o - , k o c r - i e U i a p y o u 5 2 0 2 ) 5 2 0 2 . t ( n u e r m d , k t - t - m o t a t - L 5 2 0 2 a ( A t i ) 5 2 0 2 d o e - e d - l k s , l m t n e p - a t e C o n a i i n e 4 2 0 2 b ( B ) 4 2 0 2 s p y e i , e y o - m n t c ffi - C 4 2 0 ) 4 2 0 2 . e ( s t t l l - a n a i , e v r g n g - l s r a b m l - M 4 2 0 2 . e P ( A ) 4 2 0 2 , e n e n , t i l t a n a i i 3 1 0 2 G A ( I g e e x a u ) 3 1 0 2 25 v o w r e t e o b i . i u s i d t a t n n o s g d e K 2 a z g c o m E . t n o d , t o , l t a g n e t o m t s i a s . i i i u i e i t f m p i e d r m t - u s r n i a i y e P t o i ( e e s e t g e g - v i e c a a a r s s c r l t n a u C d z ( a ) 7 1 0 2 . e ) 3 2 0 . e t e - l h r t b fi v c n i i a c L t n o - a l a ) 5 2 0 2 i n a - a , a r r u S e r e e s T t n o - d e i u a a g a - s d ) 5 2 0 2 . e J ( g n f c ff - a b a I ( i ) 4 2 0 2 m N t e p - s i e e o n n fi a v B - e i d n S ( c r m k d r c i c h K i u o a ) 3 2 0 2 . e x fl d e a d b n p i fl e n i p e i c - M - e e p - n a v - S t m t e l l - u r u i a fi p - R - e i d - R i a H a f r ) 3 2 0 2 . t e ( y t n v r d r n e ( y ) 5 2 0 2 l M b a o s g p s r i i u d g n s o v n - p e a - d n ( a i f n e v - c s r L e fi h h - - h e P t o - o o g n p g r ) 4 2 0 2 . e ( i"
        },
        {
            "title": "B Application Case Studies",
            "content": "B.1 Multi-Agent Decision-Making and Human-AI"
        },
        {
            "title": "Collaboration",
            "content": "Large language model-based multi-agent systems are significantly altering decisionmaking processes in complex and dynamic environments. Illustrative examples, such as ResearchArena (Kang and Xiong 2025) and ResearchAgent (Chen et al. 2025) demonstrate the potential to automate literature reviews and enhance hypotheses. Such synergistic intelligence offers great potential for expediting scientific advancement. In robotics, systems like BrainBody-LLM (Zhang and Soh 2023) and scalable skill learning frameworks (Ha et al. 2023) utilize natural language-driven planning to bridge the gap between human intent and robotic execution. Zero-shot human modeling (Mishra et al. 2024) further empowers agents to anticipate and adapt to human preferences with minimal prior training. Healthcare and safety-critical domains are also seeing significant benefits. LLMenhanced systems show capacity to improve diagnosis (e.g., SRLM (Wang et al. 2024)), clinical communication (e.g., MedAlign (Fleming et al. 2023)), and safety assurance (e.g., Aegis (Ghosh et al. 2024)). Nevertheless, future work must address the reliability of multi-agent collaboration under uncertainty, the ethical implications of human-AI partnerships, and the transparency of joint decision-making processes. In addition, future empirical research should design comparative evaluations that treat LLM collectives as potential epistemic partners, or even challengers, to human decision-making norms, rather than mere as tools. Future systems must treat LLM collectives not merely as productivity tools, but as epistemically dynamic collaborators capable of revising shared knowledge, ethical norms, and strategic goals over time. B.2 Simulation for Societal Systems and Urban Environments LLMs are creating novel opportunities for simulating societal structures, urban dynamics, and the effects of policies. For instance, tools like ChatMap (Unlu 2023) and GrutopiaDream (Zhou et al. 2024) allow for city modeling through natural language, thereby increasing public involvement in urban planning. Generative agent models facilitate the analysis of human-environment interactions (Verma et al. 2023), providing enhanced understanding of social behavior, environmental perception, and the modeling of public responses. Similarly, simulations of opinion dynamics (Wei et al. 2024) can help illustrate the evolution of collective sentiment in reaction to dynamic societal factors. Recent work in this field increasingly emphasizes emotional adaptation (Meyer and Elsweiler 2024), cross-cultural modeling (Kamruzzaman et al. 2024), and realistic conversational norms (Chan et al. 2023; Lee et al. 2024) in bid to enhance the fidelity of social simulations. 27 However, enhancing the interpretability of emergent societal phenomena, mitigating cultural biases, and ensuring fairness across diverse populations remain major open challenges. Regardless, we contend that simulations have to evolve from static scenario rendering toward living, feedback-driven platforms where public values, emotional dynamics, and environmental responses co-develop in real time. B.3 Economic Behavior, Finance, and Cultural Dynamics In the fields of economics and finance, LLMs facilitate sophisticated simulations of decision-making processes characterized by uncertainty and asymmetric information. Notable examples such as AI-Economist (Dizaji 2024) and TwinMarket (Yang et al. 2025) illustrate the capacity of multi-agent simulations to model complex phenomena, including negotiation, market formation, and social influence. Efficiency-oriented techniques like TrustScore (Zheng et al. 2024) help facilitate scalable simulations by balancing resource consumption and fidelity. In parallel, cultural adaptation frameworks explore how agents internalize and operate across diverse social norms and negotiation styles. However, key challenges in this area include preserving behavioral diversity at scale, accurately modeling macroeconomic emergence from micro-level interactions, and evaluating the systemic effects of adaptive agent behaviors."
        },
        {
            "title": "C Representative Scenarios",
            "content": "This appendix provides set of representative task scenarios for the frameworks summarized in Appendix A. Each scenario highlights how different systems operationalize open-ended behaviors, societal adaptation, and domain-specific innovation. VOYAGER: Agents autonomously discover and build technologies in Minecraft world, achieving faster exploration milestones compared to task-fixed agents. OpenWebVoyager: Agents iteratively improve web browsing capabilities, autonomously learning to navigate and interact across real-world websites. TwinMarket: Agents in financial markets adapt their trading behavior based on peer influence and private information, simulating realistic market dynamics. AI-Economist: Agents co-learn economic policies that balance productivity and equality through reinforcement learning in simulated societies. GABM: Agents evolve their skillsets and economic behaviors based on incentive structures in varied virtual governance environments. SurrealDriver: LLM-based agents emulate human-like driving patterns, adapting to diverse driving styles and environmental changes. SMART: Agents collaborate on complex knowledge tasks by learning from past solution trajectories and relational reasoning. Richelieu: Agents negotiate and evolve diplomatically, developing complex strategies over time in evolving political landscapes. StateAct: Agents improve long-term adaptability by dynamically modifying their internal states and behavioral strategies. UAG: Agents reason under uncertainty within knowledge graphs, improving trust and robustness in decision-making. EABSS: Conversational AI systems assist in the co-creation of social simulation models with domain stakeholders. GAA: Agents interact with the environment and peers cost-effectively by learning lifestyle policies and social compression techniques. AGA: Over 1,000 real individuals are simulated using personality-grounded generative agents, enabling social science experiment replication. Evaluation Metrics for Open-Ended Multi-Agent"
        },
        {
            "title": "Simulations",
            "content": "This appendix outlines proposed evaluation dimensions and metrics to assess the richness, adaptability, and societal relevance of open-ended multi-agent simulations. These metrics are intended to complement traditional task-based evaluations by emphasizing emergent phenomena and long-term innovation. To properly evaluate open-ended multi-agent simulations, we propose the use of the following key dimensions and example metrics: Exploration Capacity: Unique state/item discovery count Coverage rate across environment features Shannon entropy: = (cid:80) p(x) log p(x) Adaptation and Learning: Task success improvement over time Strategy change frequency under environmental shifts Emergent Innovation: Novel behavior emergence rate Diversity of discovered social norms or artifacts Societal Stability and Alignment: Resilience to agent/environment perturbations Alignment with externally defined social value norms Memory and Consistency: Longitudinal consistency score Memory fidelity over multiple interaction rounds These metrics aim to capture not only task performance but the richness, novelty, and social realism of open-ended, evolving agent societies."
        },
        {
            "title": "E Architectural and Operational Challenges",
            "content": "E.1 Memory Consolidation and Temporal Reasoning Autonomous agents frequently exhibit difficulty in sustaining coherent long-term memory and robust temporal reasoning within changing contexts (Hou et al. 2024; Toy et al. 2024). While architectures such as DHMA (Hou et al. 2024) present encouraging advancements, persistent challenges are evident in continuous learning, catastrophic forgetting, and the dynamic updating of knowledge. Integrating metacognitive modules, which allow agents to observe and refine their memory systems, has the potential to significantly improve adaptability over extended periods. Agents should conceptualize memory not solely as repository, but as dynamic framework that supports identity continuity, social responsibility, and epistemological development. E.2 Scaling, Efficiency, and Diversity Preservation The implementation of LLM-driven systems for large-scale, heterogeneous multi-agent simulations presents substantial resource challenges (Yao et al. 2024; Yang et al. 2024). Although strategies such as model distillation, adaptive prompting, and predictive evaluation (Zheng et al. 2024) offer partial reductions in computational expenditures, they frequently compromise the retention of behavioral diversity. Future investigations should prioritize the development of communication-efficient architectures, memory compression methodologies, and decentralized learning paradigms to sustain agent heterogeneity while simultaneously ensuring scalability. Rather than treating scale and diversity as trade-offs, we call for research that designs architectures where heterogeneity and generalization reinforce rather than oppose each other. E.3 Security, Safety, and Ethical Considerations With the growing autonomy and pervasiveness of adaptive agents, concerns regarding security vulnerabilities, the spread of misinformation, and potential dual-use applications are amplifying (Feng et al. 2024; Ghosh et al. 2024). It is imperative to integrate verifiable reasoning, transparent decision-making processes, and mechanisms that ensure privacy preservation into the architectural design of these agents (Jiang et al. 2023; Shi et al. 2025). Promising models for the responsible and secure implementation of agents include frameworks such as Aegis (Ghosh et al. 2024) and continuous ethical audits (Jiao et al. 2025)."
        }
    ],
    "affiliations": [
        "Faculty of Computer Science, Dalhousie University, Halifax, Canada",
        "Meta, Vancouver, Canada"
    ]
}