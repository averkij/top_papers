{
    "paper_title": "CHOrD: Generation of Collision-Free, House-Scale, and Organized Digital Twins for 3D Indoor Scenes with Controllable Floor Plans and Optimal Layouts",
    "authors": [
        "Chong Su",
        "Yingbin Fu",
        "Zheyuan Hu",
        "Jing Yang",
        "Param Hanji",
        "Shaojun Wang",
        "Xuan Zhao",
        "Cengiz Öztireli",
        "Fangcheng Zhong"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "We introduce CHOrD, a novel framework for scalable synthesis of 3D indoor scenes, designed to create house-scale, collision-free, and hierarchically structured indoor digital twins. In contrast to existing methods that directly synthesize the scene layout as a scene graph or object list, CHOrD incorporates a 2D image-based intermediate layout representation, enabling effective prevention of collision artifacts by successfully capturing them as out-of-distribution (OOD) scenarios during generation. Furthermore, unlike existing methods, CHOrD is capable of generating scene layouts that adhere to complex floor plans with multi-modal controls, enabling the creation of coherent, house-wide layouts robust to both geometric and semantic variations in room structures. Additionally, we propose a novel dataset with expanded coverage of household items and room configurations, as well as significantly improved data quality. CHOrD demonstrates state-of-the-art performance on both the 3D-FRONT and our proposed datasets, delivering photorealistic, spatially coherent indoor scene synthesis adaptable to arbitrary floor plan variations."
        },
        {
            "title": "Start",
            "content": "CHOrD: Generation of Collision-Free, House-Scale, and Organized Digital Twins for 3D Indoor Scenes with Controllable Floor Plans and Optimal Layouts Chong Su,1 Yingbin Fu,1 Zheyuan Hu2 Jing Yang2 Param Hanji2 Shaojun Wang1 Xuan Zhao1 Cengiz Oztireli Fangcheng Zhong2 1KE Holdings Inc. 2Department of Computer Science and Technology, University of Cambridge indicates equal contribution. 5 2 0 2 M 5 1 ] . [ 1 8 5 9 1 1 . 3 0 5 2 : r Figure 1. I) CHOrD synthesizes realistic and well-structured digital twins for 3D indoor scenes. II) CHOrD can be conditioned on complex floor plan structures to generate realistic house-wide layouts while ensuring physically plausible, spatially coherent, and collision-free arrangements. It further introduces hierarchical data structure that organizes objects not only at the room level but also at finer scales, such as desks and coffee tables. III, IV) CHOrD supports controllable floor plans via multimodal inputs, as well as photorealistic, 3Dconsistent rendering. These capabilities equip CHOrD with considerable versatility, enabling broad range of downstream applications."
        },
        {
            "title": "Abstract",
            "content": "We introduce CHOrD, novel framework for scalable synthesis of 3D indoor scenes, designed to create housescale, collision-free, and hierarchically structured indoor digital twins. In contrast to existing methods that directly synthesize the scene layout as scene graph or object list, CHOrD incorporates 2D image-based intermediate layout representation, enabling effective prevention of collision artifacts by successfully capturing them as out-ofdistribution (OOD) scenarios during generation. Furthermore, unlike existing methods, CHOrD is capable of generating scene layouts that adhere to complex floor plans with multi-modal controls, enabling the creation of coherent, house-wide layouts robust to both geometric and semantic variations in room structures. Additionally, we propose novel dataset with expanded coverage of household items and room configurations, as well as significantly improved data quality. CHOrD demonstrates state-of-the-art performance on both the 3D-FRONT and our proposed datasets, delivering photorealistic, spatially coherent indoor scene synthesis adaptable to arbitrary floor plan variations. 1. Introduction Generative 3D indoor scene synthesis and digital twin creation [7, 12, 15, 16, 18, 20, 2224, 27, 32, 3436, 40, 43, 44, 46] play increasingly vital roles not only in creative and technical workflows such as interior design, architectural planning, and virtual or augmented reality, but also in advancing embodied AI by providing scalable simulated environments for training and testing. This approach facilitates rapid prototyping, reduces manual labor, lowers deployment costs, and accelerates iteration. Despite recent advances in neural volumetric representations [14, 21], classic mesh-based assets remain the predominant 3D digital twin representation in these domains due to superior rendering quality, direct interactivity, and explicit spatial structures. Consequently, existing pipelines [16, 18, 23, 27, 32, 35, 46] primarily follow procedural generation paradigm, constructing scene graph or object list for the scene layout, with each node containing detailed specifications for individual objects. These objects can then be retrieved from CAD asset dataset and interacted with or rendered by various graphics and physics engines. Therefore, synthesizing diverse and logical scene layouts has been core aspect of creating high-quality indoor digital twins. However, fundamental limitation of existing methods that construct scene graphs or object listseither directly by tabular generative model [16, 18, 23, 27, 32, 35, 46] or by an LLM writing configuration files [37, 41]is their inability to prevent physically implausible collisions or overlaps between objects, such as bed intersecting with cabinets, during the generation process. While collision detection can be performed as post-processing step, it is computationally expensive and lacks scalability. Moreover, effectively resolving detected collisions during post-processing remains nontrivial. Prior work has also attempted to prevent collisions using manually defined rules [5, 41], but this approach lacks generalizability to arbitrary scenes and cannot be used to learn desirable layout distributions from data. Another critical yet frequently overlooked limitation of existing methods is their restriction to single-room layout generation [16, 18, 23, 27, 32, 35, 46], which fails to account for the overall floor plan structure of house. Since room shapes, sizes, and the arrangement of various room types collectively influence the logical organization of the household layout, existing approaches neglect key spatial relationships that are essential for coherent multi-room designs. The occurrence of these limitations is not coincidental neither tabular generative models nor LLMs have the granular spatial understanding needed to distinguish adjacent objects from intersecting ones or to properly incorporate the floor plan geometries into the generation process. In this paper, we propose CHOrD, framework designed to comprehensively enhance the spatial coherence of digital twin generation for 3D indoor scenes, as highlighted In particular, CHOrD i) prohibits collision in Figure 1. artifacts during the generation process without relying on post-processing, collision detection, or pre-defined rules; ii) enables house-scale layout generation that adapts to complex geometric and semantic floor plan structures, which are controllable via multi-modal input; and iii) supports hierarchically structured scene graph representation that seamlessly integrates into existing pipelines. Central to our approach is the synthesis of 2D image-based layout representation as an intermediate step in the procedural workflow, which can be subsequently converted into hierarchical scene graph, rather than constructing the graph in single step. Our key insight is that, compared to the graph representation, which is inherently tabular, introducing an intermediate 2D layout representation greatly strengthens the spatial perception and reasoning of the generative model. For example, humans can readily spot collisions by examining the top-down view of layout, whereas simply reviewing table of bounding boxes does not enable such direct assessment. Designers routinely rely on top-down floor plan views to create spatially orderly layouts. In similar vein, CHOrD successfully captures collision artifacts as out-of-distribution (OOD) scenarios, facilitating the empirical elimination of physically implausible collisions during the generation process. The 2D layout of CHOrD also enables the adaptation of complex floor plan structures via various modalities, feature rarely available in existing approaches. We advocate that all graph-based methods for digital twin generation incorporate an intermediate 2D layout for collision avoidance and house-scale organization. We additionally introduce novel dataset, referred to as the CHOrD dataset, comprising 9,706 scenes with floor plans and scene layouts, approximately 1.4 times larger than 3D-FRONT [8]. Compared to 3D-FRONT, the CHOrD dataset expands household item coverage to 26 supercategories, including items from kitchens, bathrooms, and balconies, addressing gaps in 3D-FRONT, which lacks furnishings in these areas and occasionally leaves living rooms or bedrooms unfurnished. It also resolves common issues found in 3D-FRONT, such as misclassified objects, unrealistic placements, and collisions, providing clean layouts without requiring extensive data cleaning. Our contributions are summarized as: i) Framework1 - novel framework for house-scale, collision-free, and hierarchically structured indoor digital twin creation with multi-modal controllable floor plans; ii) Dataset - novel dataset of 9,706 scenes with floor plans and scene layouts, 1.4 times larger than 3D-FRONT, with improved item coverage and data quality; and iii) Performance - CHOrDs state-of-the-art performance on both the 3D-FRONT and proposed datasets, evaluated both qualitatively and quantitatively, particularly in the near-elimination of unreasonable object collisions, prevalent issue in existing methods. 2. Related Work Early work employed rule-based constraint satisfaction formulation to generate 3D room layouts for pre-specified sets of objects [5, 40]. While allowing for moderate diversity, rule-based methods cannot learn desirable layout distributions from data. Other approaches optimized cost functions based on interior design principles [20] and objectobject statistical relationships [44]. The earliest data-driven approach modeled object co-occurrences using Bayesian network and Gaussian mixtures to capture pairwise spatial relations extracted from 3D scenes [7]. With the availability of large datasets of 3D environments, such as SUNCG [31], 3D-FRONT [8], SUN3D [39], Matterport3D [4], InteriorNet [17], Structured3D [47], and 3D-FURNITURE [9], learning-based approaches have gained popularity. Various methods for indoor scene synthesis have been proposed, including: human-centric probabilistic grammars [24], Generative Adversarial Networks (GANs) trained on matrix representations of scene objects [46], recursive neural networks for sampling 3D scene hierarchies [16], convolutional neural networks (CNNs) trained on top-down room images [27, 46], spatial prior graph neural networks trained on labeled 3D spatial relationships [35, 43], and Variational Autoencoder (VAE) models trained on top-down functional furniture group images [22]. Additionally, floor plan synthesis approaches have been proposed using graph neural 1Our codebase and dataset are available in the Supplementary Materials, and will be publicly released upon acceptance. 2 Figure 2. Overview of CHOrD. First, we generate the scene layout using conditional diffusion model, conditioned on floor plan image. Next, we apply object detection to identify individual household items and use structured scene graph to hierarchically organize the spatial relationships between rooms and objects, along with their attributes. Finally, the scene is rendered into photorealistic images. networks [12]. With the development of transformer models [34], transformer-based approaches have become increasingly popular. These include floor plan-conditioned furniture synthesis and text-conditioned furniture synthesis using transformer autoregressive models [23, 36], as well as methods integrating expert knowledge in the form of differentiable scalar functions to guide the generation of more ergonomic layouts [15]. Recently, diffusion models [11] have demonstrated impressive visual quality in generative tasks, including indoor furniture synthesis [18, 32]. However, these methods primarily synthesize layouts for individual rooms rather than house-scale scenes that consider the overall floor plan structure. Additionally, unlike recent works [18, 32, 42], which directly synthesize the scene graph using 1D-Unet, our approach employs 2D-Unet. This enables better understanding of the spatial relationships between doors, windows, and furniture, thereby more effectively preventing collisions, doorway blockages, and other artifacts. Such artifacts are also present in widely used indoor scene datasets, such as 3D-FRONT [8, 9], requiring substantial effort for data cleaning. 3. CHOrD Pipeline We propose novel pipeline for 3D-aware indoor scene synthesis and digital twin creation, as depicted in Figure 2. The pipeline starts with floor plan descriptionprovided as an RGB imageand use conditional diffusion model to generate corresponding 2D scene layout. The use of this 2D representation enables us to leverage efficient image encoders for layout generation while effectively distinguishing natural and implausible object overlaps. Next, we employ automatic object detectors and segmentation maps to identify individual household items and extract structured scene graph that hierarchically organizes multi-level spatial relationships and object attributes. Finally, the 3D scene objects are retrieved accordingly and rendered to produce photorealistic 3D-consistent images, which can also be deployed in physics engine for simulation. 3.1. Diffusion-based scene layout generation We leverage the recent success of image-based diffusion models [2, 28, 29] and frame the problem of generating diverse, realistic indoor scene layouts as conditional imageto-image translation task, as illustrated in Figure 2 (left). Unlike complex scene graphs or tabular formats, natural RGB images serve as convenient intermediate representation for the layout, easily processed by existing vision tools. Crucially, since RGB images are easy-to-interpret by an appropriate encoder, we can construct highly effective conditional generative model that accurately captures the data distribution. In 2D images, implausible object collisions are instantly visible and flagged as OOD samples, enabling the model to generate coherent, realistic layouts. Specifically, given an image of an empty floor plan y, we train diffusion model ϵθ(x; y, t) to model the conditional distribution of the corresponding layouts p(x y), where ϵθ is structured as 2D U-Net, following [11], with 3 input channels (random noise) and 3 output channels (the predicted layout image). To incorporate floor plan image conditioning, we expand the U-Net input from 3 to 6 channels. During training, predetermined noise schedule realizes Markov chain, yielding the diffused sample xt(x, y, t, ϵ), where ϵ (0, I) and U(0, 1). The loss function is given by the denoising score matching objective [11]: E(x,y)pdata,ϵN (0,I),tU (0,1) (cid:104) ϵθ(x; y, t) ϵ2(cid:105) . (1) 3.2. Hierarchical scene graph extraction and object retrieval To generate scene graph from the candidate layout p(x y), we follow the automatic framework proposed by [19]. As depicted in Figure 3, we start by fine-tuning YOLOv8 [13] to detect the locations and attributes of all objects present in x. The color of each object uniquely identifies its category from set of 28 household item categories and 3 floor plan item categories. Detailed color 3 schemes are listed in Supplementary Table 2. The other relevant attributes are then populated to produce an object list = (o1, o2, . . . , on), with each node containing object properties such as category, position, orientation, and size. We employ YOLOv8 to simultaneously obtain the segmentation maps for each room type, including living rooms, bedrooms, kitchens, bathrooms, and balconies. Given the dimensions and category of each object, we deterministically retrieve an example from categoryspecific textured mesh database D2 such that it has the smallest size difference: ei = arg min eD (ox ex 2+oy ey2) : oc = ec, oi O. (2) The set of retrieved examples {e1, e2, . . . , en} constitutes the leaf nodes of the scene graph, as shown in Figure 3. To position the objects in each room and construct the hierarchal scene graph, we utilize the semantic detection and segmentation outputs of household items and rooms from YOLOv8. We straighten the edges of the room polygons, similar to [19], to reduce uneven lines, and attach doors and windows to these edges, ensuring corrected wall positions that enclose the room. Note that this approach enables CHOrD to generate granular, hierarchical spatial layouts in multi-level autoregressive manner. Specifically, we can iteratively apply the conditional diffusion model to generate fine-grained layouts, such as placing objects on coffee table, as illustrated in Figure 3 (bottom). When generating fine-grained layouts, the conditional input for the diffusion model becomes the top-down views of the upper level (e.g., the boundaries of the table) instead of floor plan images. The advantages of hierarchical layout data structure are threefold. First, this structure allows CHOrD to be seamlessly integrated into widely adopted graph-based pipelines to enhance spatial coherence, which we strongly advocate. Second, it facilitates wide range of downstream tasks, such as intricate robotic spatial understanding and navigation [38]. Finally, this multi-level layout enables CHOrD to also accommodate natural vertical object overlaps, such as placing objects on desk or coffee table. 3.3. Multi-modal floor planning Apart from the main pipeline, the 2D layout of CHOrD enables additional multimodal controls for the floor plan. Specifically, we provide two types of controls: Text-conditioned floor planning An alternative and convenient way to specify the floor plan is through natural Figure 3. Scene graph extraction and object retrieval. language, especially when floor plan images are not accessible or incompatible with the format accepted by our model. Given the success of text-to-image diffusion models [26, 30], text descriptions provide viable alternative for floor plan specification, as shown in Figure 7 (left). Open-plan-conditioned floor planning CHOrD also supports synthesizing floor plans conditioned on an openplan layout, as shown in Figure 7 (right). Specifically, given 2D image of an open-plan layout without room arrangements, CHOrD generates complete floor plans with optimal room separations. This is particularly useful for users looking to modify floor plan structures or synthesize digital twin environments with greater variety. These controls are considered extended features of CHOrDthe main pipeline functions perfectly without thembut they are made possible largely due to our adoption of multi-level 2D layout. We anticipate various new features enabled by this approach. Further technical details are provided in Supplementary Section A. 3.4. Rendering 2Note that the selection of this database and its retrieval rules can be flexibly user-specified, enabling custom functionality by incorporating advanced features into the graph nodes, as explored in many prior works [42, 45]. CHOrD can be seamlessly integrated into these pipelines. Finally, we convert the structured scene graph into 3D mesh. The wall and floor materials for each ei are procedurally sampled, while being aware of the rooms to which"
        },
        {
            "title": "The key advantage of",
            "content": "they belong. To maintain uniform lighting and shadow consistency across the scene, an appropriately sized area light is placed at the center of each room. The UE engine [6] is subsequently utilized to generate photorealistic renderings. the multi-stage pipeline of CHOrDwhich first generates 2D layout rather than directly synthesizing an object scene graph using tabular generative model [18, 32] or LLMs [37, 41]lies in its enhanced granular spatial understanding, adapting to various floor plan structures and object placements. By leveraging an intermediate 2D layout, CHOrD ensures that the hierarchical spatial relationships between household items are preserved, avoiding common issues such as object overlap, collision, or inconsistencies between object placement and room shapes, as validated in Section 5. 4. CHOrD Dataset We collected new large-scale dataset, which we refer to as the CHOrD dataset, of indoor scenes with floor plans and scene layouts, comprising total of 9,706 design schemes, approximately 1.4 times larger than the 3D-FRONT dataset [8]. This dataset was meticulously created by professional interior designers, stored in JSON format with vectorized data, as exampled in Appendix List 1, including wall lines, doors, windows, and household items such as furniture, fixtures, and appliances. The data description is as follows: Rooms: Represented as enclosed loops of interior wall lines, defined by 2D coordinates. Doors, windows, and household items: Represented as 2D bounding boxes, defined by category, 3D coordinates, orientation, and dimensions (length, width, height). It is important to note that CHOrD dataset is 3D layout dataset rather than 3D asset dataset. The layout primarily focuses on the geometric characteristics (e.g., bounding boxes) and categorical distinctions among objects. While CHOrD dataset is currently linked to small pool of CAD asset models, users are free to retrieve assets from any large public dataset [1, 9] to introduce stylistic variations of objects if needed. Similarly, 3D-FRONT has been associated with the 3D-FUTURE dataset [9] for this purpose. CHOrD dataset offers several clear advantages over 3D-FRONT: Expanded coverage of household items and room categories While 3D-FRONT provides instance semantic labels for 34 categories and 10 super-categories of household items, its dataset primarily includes objects placed in living rooms, bedrooms, and dining rooms, with no objects for kitchens, bathrooms, or balconies. Consequently, the layouts in 3D-FRONT are consistently devoid of furnishings in these areas, as seen in Figure 4. Our CHOrD dataset fills this gap by offering 26 super-categories of household items, including furniture, fixtures, and appliances, that comprehensively cover living rooms, bedrooms, dining rooms, Figure 4. Erroneous scenes in 3D-FRONT. kitchens, bathrooms, and balconies. Our CHOrD dataset not only contains more valid living rooms and bedrooms (each with at least one household item in place), but also includes outfitted kitchens and bathrooms. comprehensive statistic of the CHOrD dataset in comparison with 3DFRONT is detailed in Supplementary Table 5 and Figure 11. Improved data quality As frequently reported [18, 23, 27, 32, 46], the 3D-FRONT dataset contains erroneous layouts such as empty rooms, unnatural object sizes, misclassified items, and unrealistic object placements (e.g., furniture outside room boundaries, lamps on the floor, blockage of doorways, and overlapping objects), as seen in Figure 4. Consequently, previous work [18, 23, 27, 32, 46] using 3DFRONT invested considerable effort in data cleaning, removing numerous layouts with artifacts, which greatly reduced the amount of valid data. In contrast, our dataset is ready to use without these artifacts. Supplementary Table 6 and 7 provide additional details. 5. Experiments We conducted several experiments to assess the performance of CHOrD on structured layout synthesis and compare it with prior work. We particularly evaluate the effectiveness of CHOrD in eliminating collision artifacts by assessing its ability to capture these scenarios as out-ofdistribution samples. Next, we demonstrate the versatility of CHOrD in several extended tasks, including fine-grained layout synthesis, multi-model floor planning, and photorealistic rendering. 5.1. Floor plan-conditioned synthesis Implementation We trained CHOrD on four RTX 8000 GPUs with batch size of 4 for 400 epochs. The initial learning rate was set to 1e-4, with decay factor of 0.1 every 100 epochs. For the diffusion process, we followed the default configuration of DDPM [11], where noise intensity gradually increases from 0 to 1 over 1000 time steps. For 5 Figure 5. Visualization of synthesized layouts by CHOrD, DiffuScene [32], InstructScene [18], and PhyScene [42]. All results were randomly selected from an arbitrary batch without any cherry-picking. It is evident that only CHOrD produces clean, collision-free layouts, whereas other methods exhibit significant artifacts such as implausible overlapping items, inconsistent orientations, or missing objects. Dataset Bedroom FID KID POR PIoU FID DiffuScene InstructScene PhyScene CHOrD (ours) 3D-FRONT 3D-FRONT 3D-FRONT 3D-FRONT CHOrD dataset DiffuScene InstructScene CHOrD dataset CHOrD (ours) CHOrD dataset 15.91 22.35 - 14.78 37.16 48.59 21.86 0.04 0.02 - 0.008 0.03 0.05 0.02 0.1632 0.2039 - 0.0766 0.1922 0.3010 0. 0.0152 0.0088 - 0.0013 0.0038 0.0092 0.0025 45.89 - 117.29 24.15 29.97 46.05 26.69 Living Room POR KID 0.034 - 0.119 0. 0.02 0.04 0.02 0.05 - 0.389 0.0207 0.0707 0.0908 0.0485 PIoU 0.012 - 0.0134 0.0015 0.0028 0.0037 0. FID KID Entire House POR - - - 11.51 - - 29.97 - - - 0.01 - - 0. - - - 0.0130 - - 0.0125 PIoU - - - 0.0005 - - 0.0007 Table 1. Quantitative evaluation of CHOrD against prior approaches, demonstrating superior performance across all metrics and datasets. the object detection process, we followed the default configuration of YOLOv8 [13]. Further implementation details can be found in Supplementary Section A. Datasets We compare CHOrD with baseline methods on both the 3D-FRONT dataset [8] and the proposed CHOrD dataset. The 3D-FRONT dataset consists of 6,813 scenes, of which 4,847 were retained after cleaning process that excluded layouts lacking furniture, containing objects extending beyond room boundaries, or exhibiting collisions. Prior works [18, 23, 27, 32, 46] have applied similar data filtering to remove erroneous scenes from 3D-FRONT due to various artifacts, as discussed in Section 4. The CHOrD dataset comprises 9,706 scenes and is ready for use without the need for data cleaning or preprocessing. We use 80% of the dataset for training and 20% for testing. Baselines We compare CHOrD with the latest work DiffuScene [32], InstructScene [18], and PhyScene [42], all aiming to synthesize 3D indoor scenes with optimized lay6 outs. Note that DiffuScene, InstructScene, and PhyScene are all unable to synthesize house-scale layouts but individual categories of rooms. For evaluation on the 3D-FRONT dataset, we used the official pre-trained checkpoints of these methods to ensure their optimal performance. Specifically, we used the checkpoint from the DiffuScene unconditional model to generate top-down views of object arrangements in bedrooms and living rooms at resolution of 256 256, matching the image size generated by our diffusion model. For InstructScene, we similarly used the checkpoint from the unconditional model to generate bedroom views at the same resolution. InstructScene did not release unconditional model checkpoints for living rooms. For PhyScene, we used their checkpoint from the floorplan-conditioned model to generate living room layouts. PhyScene did not release model checkpoints for bedrooms. To ensure fairness in the comparison, the object categories generated by DiffuScene, InstructScene, and PhyScene were remapped to our categorization, as detailed in Supplementary Table 4. For evaluation on the CHOrD dataset, we re-trained the unconditional models of DiffuScene and InstructScene on living rooms and bedrooms using their default training configurations. PhyScene did not release its training code. Results We present the qualitative evaluation of all methods in Figure 5, with all results randomly selected without cherry-picking. CHOrD effectively synthesizes diverse, spatially coherent, and collision-free layouts, while other methods produce significant artifacts, including physically implausible object collisions, inconsistent object orientations, and missing objects, greatly limiting their practical applicability. Moreover, unlike CHOrD, these methods cannot generate house-scale layouts covering all rooms. Figure 8 illustrates house-scale layouts synthesized by CHOrD, as well as photorealistic renderings. Additional results are available in Supplementary Materials. Notably, CHOrD can generate diverse 2D layouts from the same floor plan, despite CHOrD dataset containing only one layout per plan. We present the quantitative evaluation of all methods in Table 1. Following previous work [18, 32, 42], we use Frechet Inception Distance (FID) [10] and Kernel Inception Distance (KID) [3] to assess the quality and diversity of synthesized layout images. Additionally, we compute two metrics to evaluate 2D bounding box collisions in synthesized layouts: Pairwise Overlap Ratio (POR), which quantifies the proportion of intersecting object pairs relative to the total number of pairs, and Pairwise Intersection over Union (PIoU), which measures the ratio of the intersecting area between two objects to the combined area of their union. The average values for these metrics are obtained by first computing per-scene values, followed by applying the arithmetic mean. CHOrD consistently achieves state-of-the-art performance across all metrics and datasets. Figure 6. Fine-grained coffee table and desk layouts that accommodate natural vertical object overlaps. The computer setup in the right column, consisting of monitor, keyboard, and mouse, was modeled as single object placed on the mat. Collision as OOD samples In diffusion models, the training loss is computed as the reconstruction error of the data given the noise, serving as an approximation of the negative log-likelihood (NLL). After adequate training, if sample has high training loss and, consequently, high NLL, it is most likely an out-of-distribution (OOD) sample within the learned distribution that is improbable to be generated during sampling. To validate the effectiveness of CHOrD in preventing implausible collision artifacts by recognizing them as OOD samples during inference, we computed the training loss for clean 3D-FRONT layout samples devoid of collisions and for set of 400 3D-FRONT samples with the largest PIoU values. The loss was calculated by adding noise to the samples at timesteps ranging from 900 to 1000, measuring the mean squared error between the true and predicted noise, and averaging the results over 100 iterations. The results indicate an average loss of 5.37 105 for the clean samples and 7.10 105 for the samples with collisions, significant 32.22% difference explaining the efficacy of CHOrD in identifying and prohibiting unnatural object collisions as OODs. 5.2. Fine-grained layout synthesis As discussed in Section 3.2, the multi-level graph structure enables CHOrD to synthesize fine-grained layouts such as placing objects on coffee table. This can be achieved by iteratively applying the conditional diffusion model, except that the floor plan image conditioning is replaced by an image indicating the boundaries of upper-level items. Dataset and implementation Since neither the 3DFRONT nor CHOrD datasets contain fine-grained layouts for this task, we additionally collected small dataset of object placements on common household items such as dining tables, coffee tables, and desks. We recorded the object categories, positions, orientations, and sizes, as well as their bounding boxes, and generated top-view images of their layouts. Object categorization and their color schemes are detailed in Supplementary Table 3. The objects were drawn proportionally to their absolute sizes, with the maximum drawing area fixed at 2-meter squares. We adhered to the same training procedures as detailed in Section 5.1. 7 Figure 7. Multi-modal floor planning. Results We present exemplar results in Figure 6. CHOrD enables two mechanisms that simultaneously prevent implausible object collisions while allowing natural vertical overlaps. First, as discussed in Section 3.2, the iterative multi-level layout generation allows fine-grained objects to be placed on upper levels, such as computer on desk. Second, some vertical overlaps do not exhibit clear hierarchical relationships, such as an object partially resting on desk mat. In this scenario, we directly train the diffusion model with RGB images containing vertical overlaps, enabling it to generate plausible layouts with natural vertical overlaps while preventing unreasonable ones. The unique color assigned to each object guides the 2D diffusion model in distinguishing permissible overlaps from invalid ones. Due to the limited availability of naturally occurring partially overlapped objects, we demonstrate this feature only at the fine-grained level. Figure 6 illustrates both scenarios. 5.3. Multi-modal floor planning Text-conditioned floor planning For text conditioning, we parse the JSON file of each scene in the CHOrD dataset to extract the total area, room count, and categories to generate the corresponding textual description. Open-plan-conditioned floor planning We use the CHOrD dataset to generate open-plan layouts and floor plans with proper room arrangements as grayscale images, with different colors representing room types. Both experiments followed the same training procedures as detailed in Section 5.1. We present exemplar results in Figure 7 and more in Supplementary Figure 13, 14. 6. Discussions and Summary In this paper, we propose novel framework that employs 2D image-based intermediate layout representation to ensure house-scale, spatially coherent, collision-free, and hierarchically structured digital twins for indoor 3D scenes. Figure 8. Top - Visualization of three diverse layouts (columns) synthesized by CHOrD for each of the three floor plans (rows). CHOrD is robust to irregular and slanted room shapes. Bottom - Photorealistic rendering of living rooms and bedrooms with identical camera positions and floor plans, highlighting layout diversity. The correspondence between the layout on the top and the rendering on the bottom is indicated by matching colored frames. The success of CHOrD hinges on its comprehensively enhanced spatial understanding compared to existing solutions, such as tabular generative models or LLMs, which struggle to meet these objectives. Notably, CHOrD prevents implausible object collisions while allowing natural vertical overlaps, demonstrating considerable robustness. CHOrD can seamlessly integrate into existing graph-based pipelines for digital twin creation, enabling photorealistic rendering and physics simulation for various downstream tasks. Limitations CHOrD did not explore stylistic control of individual objects or text-guided object placement, as has been explored by prior works [18, 32]. However, as CHOrD can be integrated into these pipelines, we leave these features for future work. In extremely rare cases, YOLOv8 failed to detect precise bounding boxes, leading to misoriented objects or minor collisions despite the layout images being axis-aligned and collision-free. This can be readily addressed with more training data, thanks to the strong scalability of CHOrD, as evidenced in Supplementary Section C. With the same amount of training data, CHOrD outperforms prior work by significant margin."
        },
        {
            "title": "References",
            "content": "[1] 3D66. 3d model website, 2013. 5 [2] Tomer Amit, Tal Shaharbany, Eliya Nachmani, and Lior Wolf. Segdiff: Image segmentation with diffusion probabilistic models. arXiv preprint arXiv:2112.00390, 2021. 3 [3] Mikołaj Binkowski, Danica Sutherland, Michael Arbel, and Arthur Gretton. Demystifying mmd gans. arXiv preprint arXiv:1801.01401, 2018. 7 [4] Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Niessner, Manolis Savva, Shuran Song, Andy Zeng, and Yinda Zhang. Matterport3d: Learning arXiv preprint from rgb-d data in indoor environments. arXiv:1709.06158, 2017. 2 [5] Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana Ehsani, Winson Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, and Roozbeh Mottaghi. Procthor: Large-scale embodied ai using procedural generation, 2022. 2 [6] Epic Games. Unreal engine. 5 [7] Matthew Fisher, Daniel Ritchie, Manolis Savva, Thomas Funkhouser, and Pat Hanrahan. Example-based synthesis of 3d object arrangements. In International Conference on Computer Graphics and Interactive Techniques, 2012. 1, 2 [8] Huan Fu, Rongfei Jia, Lin Gao, Mingming Gong, Binqiang Zhao, Steve Maybank, and Dacheng Tao. 3d-future: 3d furniture shape with texture. International Journal of Computer Vision, pages 125, 2021. 2, 3, 5, 6 [9] Huan Fu, Rongfei Jia, Lin Gao, Mingming Gong, Binqiang Zhao, Steve Maybank, and Dacheng Tao. 3d-future: 3d furniture shape with texture. International Journal of Computer Vision, pages 125, 2021. 2, 3, [10] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by two time-scale update rule converge to local nash equilibrium. Advances in neural information processing systems, 30, 2017. 7 [11] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. 2020. 3, 5 [12] Ruizhen Hu, Zeyu Huang, Yuhan Tang, Oliver Van Kaick, Hao Zhang, and Hui Huang. Graph2plan: Learning floorplan generation from layout graphs. ACM Transactions on Graphics, 39(4), 2020. 1, 3 [13] Glenn Jocher, Ayush Chaurasia, and Jing Qiu. Ultralytics YOLO, 2023. 3, [14] Bernhard Kerbl, Georgios Kopanas, Thomas Leimkuhler, and George Drettakis. 3d gaussian splatting for real-time radiance field rendering. ACM Trans. Graph., 42(4):1391, 2023. 1 [15] Kurt Leimer, Paul Guerrero, Tomer Weiss, and Przemyslaw Musialski. Layoutenhancer: Generating good indoor layouts from imperfect data. 2022. 1, 3 [16] Manyi Li, Akshay Gadi Patil, Kai Xu, Siddhartha Chaudhuri, Owais Khan, Ariel Shamir, Changhe Tu, Baoquan Chen, Daniel Cohen-Or, and Hao Zhang. Grains: Generative recursive autoencoders for indoor scenes. 2018. 1, 2 [17] Wenbin Li, Sajad Saeedi, John McCormac, Ronald Clark, Dimos Tzoumanikas, Qing Ye, Yuzhong Huang, Rui Tang, Interiornet: Mega-scale multiand Stefan Leutenegger. sensor photo-realistic indoor scenes dataset. arXiv preprint arXiv:1809.00716, 2018. 2 [18] Chenguo Lin and Yadong Mu. Instructscene: Instructiondriven 3d indoor scene synthesis with semantic graph prior. arXiv preprint arXiv:2402.04717, 2024. 1, 2, 3, 5, 6, 7, 8 [19] Xiaolei Lv, Shengchu Zhao, Xinyang Yu, and Binqiang Zhao. Residential floor plan recognition and reconstruction. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1671716726, 2021. 3, [20] Paul C. Merrell, Eric Schkufza, Zeyang Li, Maneesh Agrawala, and V. Koltun. Interactive furniture layout using interior design guidelines. ACM SIGGRAPH 2011 papers, 2011. 1, 2 [21] Mildenhall, PP Srinivasan, Tancik, JT Barron, Ramamoorthi, and Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. In European conference on computer vision, 2020. 1 [22] Wenjie Min, Wenming Wu, Gaofeng Zhang, and Liping Zheng. Funcscene: Function-centric indoor scene synthesis via variational autoencoder framework. Computer Aided Geometric Design, 111, 2024. 1, 2 [23] Despoina Paschalidou, Amlan Kar, Maria Shugrina, Karsten Kreis, Andreas Geiger, and Sanja Fidler. Atiss: Autoregressive transformers for indoor scene synthesis. 2021. 1, 2, 3, 5, 6 [24] Siyuan Qi, Yixin Zhu, Siyuan Huang, Chenfanfu Jiang, and Song Chun Zhu. Human-centric indoor scene synthesis using stochastic grammar. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018. 1, 2 [25] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 87488763. PMLR, 2021. 11 [26] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1 (2):3, 2022. [27] Daniel Ritchie, Kai Wang, and Yu An Lin. Fast and flexible indoor scene synthesis via deep convolutional generative models. IEEE, 2019. 1, 2, 5, 6 [28] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image In Proceedings of synthesis with latent diffusion models. the IEEE/CVF conference on computer vision and pattern recognition, pages 1068410695, 2022. 3 [29] Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, and Mohammad Norouzi. Palette: In ACM SIGGRAPH 2022 conference proceedings, pages 110, 2022. 3 Image-to-image diffusion models. [30] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, 9 [44] Lap Fai Yu, Sai Kit Yeung, Chi Keung Tang, Demetri Terzopoulos, Tony F. Chan, and Stanley J. Osher. Make it home: In Interautomatic optimization of furniture arrangement. national Conference on Computer Graphics and Interactive Techniques, 2011. 1, 2 [45] Guangyao Zhai, Evin Pinar Ornek, Shun-Cheng Wu, Yan Di, Federico Tombari, Nassir Navab, and Benjamin Busam. Commonscenes: Generating commonsense 3d inarXiv preprint door scenes with scene graph diffusion. arXiv:2305.16283, 2023. 4 [46] Zaiwei Zhang, Zhenpei Yang, Chongyang Ma, Linjie Luo, and Qixing Huang. Deep generative modeling for scene synthesis via hybrid representations. 2018. 1, 2, 5, 6 [47] Jia Zheng, Junfei Zhang, Jing Li, Rui Tang, Shenghua Gao, Structured3d: large photo-realistic and Zihan Zhou. In Computer Vision dataset for structured 3d modeling. ECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part IX 16, pages 519535. Springer, 2020. Raphael Gontijo Lopes, Tim Salimans, Jonathan Ho, David Fleet, and Mohammad Norouzi. Imagen: Text-to-image diffusion models. arXiv preprint arXiv:2205.11487, 2022. 4 [31] Shuran Song, Fisher Yu, Andy Zeng, Angel X. Chang, and Thomas Funkhouser. Semantic scene completion from sinIn 2017 IEEE Conference on Computer gle depth image. Vision and Pattern Recognition (CVPR), 2017. 2 [32] Jiapeng Tang, Yinyu Nie, Lev Markhasin, Angela Dai, Justus Thies, and Matthias Nießner. Diffuscene: Denoising diffusion models for generative indoor scene synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 2050720518, 2024. 1, 2, 3, 5, 6, 7, 8 [33] Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017. 11 [34] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. arXiv, 2017. 1, 3 [35] Kai Wang, Yu An Lin, Ben Weissmann, Manolis Savva, and Daniel Ritchie. Planit: planning and instantiating indoor scenes with relation graph and spatial prior networks. ACM Transactions on Graphics, 38(4):115, 2019. 1, 2 [36] Xinpeng Wang, Chandan Yeshwanth, and Matthias Niener. Indoor scene generation with transformers. Sceneformer: 2020. 1, 3 [37] Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang, Katerina Fragkiadaki, Zackory Erickson, David Held, and Chuang Gan. Robogen: Towards unleashing infinite data for automated robot learning via generative simulation, 2023. 1, 5 [38] Abdelrhman Werby, Chenguang Huang, Martin Buchner, Abhinav Valada, and Wolfram Burgard. Hierarchical OpenVocabulary 3D Scene Graphs for Language-Grounded Robot Navigation. In Proceedings of Robotics: Science and Systems, Delft, Netherlands, 2024. 4 [39] Jianxiong Xiao, Andrew Owens, and Antonio Torralba. Sun3d: database of big spaces reconstructed using sfm and object labels. In Proceedings of the IEEE international conference on computer vision, pages 16251632, 2013. 2 [40] Ken Xu, James Stewart, and Eugene Fiume. Constraintbased automatic placement for scene composition. Proceedings - Graphics Interface, pages 2534, 2002. 1, 2 [41] Yue Yang, Fan-Yun Sun, Luca Weihs, Eli VanderBilt, Alvaro Herrasti, Winson Han, Jiajun Wu, Nick Haber, Ranjay Krishna, Lingjie Liu, Chris Callison-Burch, Mark Yatskar, Aniruddha Kembhavi, and Christopher Clark. Holodeck: Language guided generation of 3d embodied ai environments. arXiv preprint arXiv:2312.09067, 2023. 1, 2, 5 [42] Yandan Yang, Baoxiong Jia, Peiyuan Zhi, and Siyuan Huang. Physcene: Physically interactable 3d scene synthesis for embodied ai. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1626216272, 2024. 3, 4, 6, [43] Zhihan Yao, Yuhang Chen, Jiahao Cui, Shoulong Zhang, Shuai Li, and Aimin Hao. Conditional room layout generation based on graph neural networks. Computers & Graphics, page 103971, 2024. 1, 2 10 CHOrD: Generation of Collision-Free, House-Scale, and Organized Digital Twins for 3D Indoor Scenes with Controllable Floor Plans and Optimal Layouts"
        },
        {
            "title": "Supplementary Materials",
            "content": "A. Additional CHOrD Technical Details A.1. CHOrD Inference Efficiency On single RTX 8000 GPU, the diffusion model inference takes approximately 18 seconds (this can be potentially reduced with advanced diffusion solvers); YOLO object detection takes around 40 milliseconds; 3D model matching and scene construction take about 100 milliseconds; and rendering, performed using the UE engine, takes approximately 30 seconds for 2K image and around 120 seconds for 4K image. While rendering is the most timeconsuming module, it is an independent component that can be flexibly replaced with any real-time rasterizationbased renderer when efficiency is priority. We chose ray-tracing-based renderer for photorealistic quality. A.2. Text-conditioned floor planning As discussed in Section 3.3, text conditioning serves as viable alternative for layout generation when floor plans images are not available. We use text-conditioned diffusion model for this purpose, as illustrated in Figure 9. We generate fixed-size conditioning vector yc by passing the text input through CLIP encoder [25]. Semi-structured text is particularly effective for this task (e.g., This is 40-squaremeter flat with 0 living rooms, 1 bedroom, 0 kitchens, and 1 bathroom.). The resulting CLIP embedding serves as the conditional variable for the diffusion model, guiding the generation of scene layouts based on high-level semantic information encoded in the text description. This allows for more intuitive control over the layout generation by leveraging natural language as an additional input modality. The text-based model is trained using the same loss as Equation 1, with the conditioning variable being the CLIP embedding yc instead of the floor plan image y. Conditioning is introduced through cross-attention layer [33] near the UNet bottleneck. A.3. Open-plan-conditioned floor planning As illustrated in Figure 10, the open-plan-conditioned diffusion model shares the same architecture as the floor planconditioned diffusion model detailed in Section 3.1, except that this model takes an open-plan figure as input and generates structured floor plan with optimal room arrangements. The generated floor plan can then serve as input to the floor plan-conditioned diffusion model. In other words, open-plan-conditioned floor planning functions as an optional preprocessing step before the CHOrD main pipeline. Category Bed Bed Background Table Sofa Sofa Background Dining Cabinet Single Sofa Side Coffea Table Double Door Floor Cabinet Sink Cabinet Refrigerator Toilet Washing Machine Wall Window Category Cabinet Bedside Table Leisure Sofa TV Cabinet Coffea Table Shoe Cabinet Dining Table Single Door Floor Cabinet Cooker Cabinet Electrical FLoor Cabinet Shower Washbasin Color FF0000 FF3333 A52A2A FF9933 99004C FF9999 CC6600 99FFCC 6666FF 0000CC 006666 660033 FFCCE5 Washing Set 000000 0000FF Door Color FFFF00 F08080 666600 FFCC99 CCFF99 006633 FF6666 9999FF 000099 3333FF 33FF99 CC0066 FF66B2 139C5A Table 2. Scene layout items and corresponding color schemes, with the opacity level set to 0.3. Figure 9. Text-conditioned diffusion model. Figure 10. Open-plan-conditioned diffusion model. B. Additional CHOrD Dataset Details An example CHOrD data stored in JSON format is shown in List 1. comprehensive statistic of the CHOrD dataset in comparison with 3D-FRONT is detailed in Table 5, 6, 7, and Figure 11. Listing 1. Example JSON data format { 11 } ] , n r : [ # 3d n g box a , # same h windows and r { [ 5 6 9 . 9 1 , 1 8 4 4 . 7 5 , 0 ] , e : f a , : g : 7 6 . 0 , t : 9 4 . 0 , g : 9 9 , a : 1 8 0 . 0 } , { } ] } [ 4 1 1 . 6 6 , 1 6 9 . 4 5 , 0 ] , e : a , : g : 1 8 5 . 3 , t : 1 2 0 . 1 , g : 9 9 , a : 0 . C. Additional Results We present additional qualitative results for fine-grained layout synthesis in Figure 12, text-conditioned floor planning in Figure 13, open-plan-conditioned floor planning in Figure 14, and photorealistic rendering of floor planconditioned layout synthesis in Figure 17. In rare instances, YOLOv8 struggled to detect accurate bounding boxes, resulting in misaligned objects or minor collisions, even though the layout images were axis-aligned and collision-free, as shown in Figure 15. We demonstrated that this can be straightforwardly addressed with more training data. Specifically, we trained CHOrD on privately collected dataset of over 100,000 indoor scenes, achieving significantly better results (FID 17.76, KID 0.02, POR 0.005, PIoU 4.399 105) with substantially fewer failure cases compared to the results obtained from training on the CHOrD dataset (9,706 scenes) and reported in Table 1. CHOrD also performs considerably better when trained on CHOrD dataset compared to 3D-FRONT, as illustrated in Figure 16. These results evidence the strong scalability of CHOrD. Category Bedside Table Coffea Table Dining Table Standing Book All-in-one Computer Big Mouse Pad Small Ornament Big Plant Coffee Cup Photo Frame Dinner Set Category Table Side Coffea Table Lying Book Color F08080 CCFF99 FF6666 FFFFAA Magazine Laptop 00FFAA 7F7FAA Table Lamp FF00AA Pen Holder Small Plant 0000AA Electronic 7FFF55 Food FF7F55 Drinks FFFF Color A52A2A 99FFCC 0000FF 7FFFAA FF7FAA 007FAA 7F00AA FFFF55 FF0000 7F7F55 7F7F00 Table 3. Fine-grained items and corresponding color schemes. rooms : [ { roomId : D5F19A0446724E , roomName : i , # e roomType : 1 , l n : [ room [ 1 7 1 . 6 5 , 2 4 1 . 5 ] , [ 6 5 1 . 6 6 , 2 4 1 . 5 ] , . . . ] # 2d r } , { roomId : D5F19A044672 , roomName : r , roomType : 0 , l n : [ [ 1 7 1 . 6 5 , 2 4 1 . 5 ] , [ 6 5 1 . 6 6 , 2 4 1 . 5 ] , . . . ] # 2d r } ] , windowsDoors : [ { l z e : r , [ 7 1 7 . 3 2 , 7 3 7 . 0 , 0 ] , : # box t o i , ; # g e h : 9 5 , t : 1 2 , g : 2 1 0 , a : 100 # t g n r } , { [ 6 5 7 . 6 6 , 9 4 5 . 1 2 , 9 0 ] , e : window , : g : 1 5 3 . 7 5 , t : 1 2 , g : 1 1 0 , a : 9 0 . 0 Item Nightstand Wardrobe Three-Seat / Multi-seat Sofa Dining Table Coffee Table Loveseat Sofa Children Cabinet Drawer Chest / Corner cabinet King-size Bed TV Stand Sideboard / Side Cabinet / Console Lazy Sofa Dressing Table Wine Cabinet L-shaped Sofa Corner/Side Table Bookcase / jewelry Armoire Kids Bed Sideboard / Side Cabinet / Console Table Bed Frame Shoe Cabinet Three-Seat / Multi-person sofa Double Bed Bunk Bed Desk Two-seat Sofa Tea Table Couch Bed Single bed Chaise Longue Sofa U-shaped Sofa Category bedside table cabinet sofa dining table coffee table sofa cabinet cabinet bed tv cabinet dining cabinet leisure sofa table dining cabinet sofa side coffee table cabinet bed table bed shoe cabinet sofa bed bed table sofa coffee table bed bed sofa sofa o p u o 23 21 19 17 15 11 9 7 5 3 Bed Cabinet Bed Background Bedside Table Table Leisure Sofa Sofa TV Cabinet Sofa Background Coffee Table Dining Cabinet Shoe Cabinet Single Sofa Dining Table Side Coffee Table Single Door Cabinet Double Door Cabinet Cooker Cabinet Sink Cabinet Electrical FLoor Cabinet Refrigerator Shower Toilet Washbasin Washing Machine Washing Set 3D-FRONT CHOrD dataset 0 10,000 20, Occurence (a) Distribution of household item occurrences per super-category. 3D-FRONT CHOrD dataset 0 400 600 800 1,000 1,200 Table 4. 3D-FRONT furniture items and remapped categories. Occurence (b) Distribution of room counts per house, with an average of 9.78 and total of 94,964 counts. Figure 11. Statistics of the CHOrD dataset in comparison with 3D-FRONT. 13 Furniture 3D-FRONT CHOrD dataset (ours) Room Bedroom Living Room Kitchen Bathroom Bed Cabinet Bed Background Bedside Table Table Leisure Sofa Sofa TV Cabinet Sofa Background Coffee Table Dining Cabinet Shoe Cabinet Single Sofa Dining Table Side Coffee Table Single Door Cabinet Double Door Cabinet Cooker Cabinet Sink Cabinet Electrical Cabinet Refrigerator Shower Toilet Washbasin Washing Machine Balcony Washing Machine Cabinet 10620 17649 0 14333 8318 237 6564 6821 0 6565 1169 0 0 5822 6300 0 0 0 0 0 0 0 0 0 0 0 24354 19365 16619 10439 8953 8430 7935 7019 7005 5368 4817 3939 3444 4195 15889 14156 6904 6773 2081 1307 15174 15026 12517 970 4153 Figure 12. Fine-grained layout synthesis. Table 5. Comparison of furniture occurrences between 3DFRONT and CHOrD dataset. Empty Room Rate POR PIoU 3D-FRONT CHOrD dataset (ours) 0.5906 0.2902 0.0361 0. 0.2547 0.0018 Table 6. Comparison of data quality statistics between 3D-FRONT and CHOrD dataset. Living Bedroom Kitchen Bathroom Balcony 3D-FRONT CHOrD dataset (ours) 1813 15115 4041 40983 0 8262 0 0 8262 Table 7. Comparison of non-empty room statistics between 3DFRONT and CHOrD dataset. Figure 13. Visualization of text-to-layout generation by CHOrD trained on our CHOrD dataset. Floor plans of different room sizes all fill the entire canvas, with the wall thickness set to 24 cm for all scenes. Hence, the room size can be inferred from the thickness of the gray walls, which is consistent with the raw training data. 14 Condition Real Prediction Prediction Figure 14. Open-plan-conditioned floor planning. 3D-FRONT CHOrD dataset Figure 16. Performance of CHOrD on 3D-FRONT and CHOrD dataset, where results obtained from training on 3D-FRONT exhibit implausible unfurnished rooms due to artifacts in the original database. Unet output Unet output Unet output Kitchen cabinet detection errors Bed and table detection errors Kitchen cabinet detection errors Figure 15. Sporadic failure cases due to YOLO detection errors when trained with insufficient data. 15 Figure 17. Additional photorealistic rendering of diverse synthesized layouts by CHOrD conditioned on floor plans."
        }
    ],
    "affiliations": [
        "Department of Computer Science and Technology, University of Cambridge",
        "KE Holdings Inc."
    ]
}