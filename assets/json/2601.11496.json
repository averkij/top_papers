{
    "paper_title": "The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents",
    "authors": [
        "Eilam Shapira",
        "Roi Reichart",
        "Moshe Tennenholtz"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the \"Poisoned Apple\" effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator's choice of market design in their favor. This strategic release improves the releaser's welfare at the expense of their opponent and the regulator's fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities."
        },
        {
            "title": "Start",
            "content": "6 2 0 2 6 1 ] . [ 1 6 9 4 1 1 . 1 0 6 2 : r The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents Eilam Shapira, Moshe Tennenholtz, and Roi Reichart Technion Israel Institute of Technology January 2026 Abstract The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify strategic phenomenon termed the Poisoned Apple effect: an agent may release new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulators choice of market design in their favor. This strategic release improves the releasers welfare at the expense of their opponent and the regulators fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities."
        },
        {
            "title": "1 Introduction",
            "content": "The rapid integration of AI agents into the global economy is fundamentally altering the landscape of strategic interaction. In the near future, substantial fraction of economic activities ranging from real estate transactions to corporate partnerships will be mediated by AI delegates acting on behalf of individuals and firms [2]. While current regulatory debates focus on model safety and bias, we identify critical, overlooked economic vulnerability [12] arising from the mere availability of these technologies. We investigate the strategic implications of expanding the set of available AI technologies within regulated markets. Specifically, we identify phenomenon we term the Poisoned Apple effect. In this scenario, strategic actor releases new technology not to use it, but to manipulate the regulators calculations of market design. By introducing poisoned option, an agent can force fairness-maximizing regulator to shift the market equilibrium in way that benefits the releaser at the expense of their opponent. Our analysis models this interaction as meta-game [4] involving two economic agents (Alice and Bob) and regulator. In this game, the regulator first determines the rules of interaction, while the participants choose among the available technologies. The utility of each participant is determined by the rules of interaction and the technologies selected by both participants. While the regulator intervenes to maximize social objectives like fairness, the agents strategically select AI representatives to maximize their own utility. We demonstrate that static regulatory frameworks are highly vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities."
        },
        {
            "title": "2 Study Design and Experimental Framework",
            "content": "To analyze these dynamics empirically, we utilize the GLEE dataset [11]. GLEE facilitates large-scale simulation of language-based economic environments across combinatorial space of 1,320 distinct configurations. The dataset comprises over 580,000 strategic decisions generated by 13 state-of-the-art LLMs, treated as simulated economic agents [3, 10], across three canonical non-cooperative game families that capture fundamental economic interactions: (1) Bargaining: An alternating-offers game where players must agree on splitting surplus or receive zero [9]; 1 Figure 1: Illustration of the poisoned apple example, in which Alice increases her payoff at Bobs expense by releasing new technologywithout the players actually using that technology in practice. (1) The technologies available to Alice and Bob are language models AD. (2a) For each possible market, the equilibrium in games between Alice and Bob under the market conditions is computed. For each equilibrium, the average fairness value that would be obtained if the equilibrium were played is calculated. (2b) The regulator, whose objective is to maximize fairness, decides that Market 4 will be the market in which Alice and Bob will playthe market that yields the maximum fairness value. Alice earns 0.49, Bob earns 0.50, and the fairness value is 1.00. (3) Technology is released and is now available to both players. (4a) The process performed in 2a is repeated. (4b) In the new equilibrium in Market 4, the resulting fairness value is 0.976. In the new equilibrium in Market 8, the resulting fairness value is 0.99. The regulator decides that Market 8 will be the market in which Alice and Bob will play. Alice earns 0.52, Bob earns 0.46. (2) Negotiation: bilateral trade setting involving private information between buyer and seller [7]; and (3) Persuasion: sender-receiver game where seller attempts to convince buyer to purchase based on strategic information transmission [1, 5]. We classify these interactions into distinct Markets, where each market is defined by specific structural configuration of three parameters: Information Structure, Communication Form, and Game Horizon. This classification yields set of fundamental environments that span the critical dimensions of economic interaction. In our meta-game model, agents (Alice and Bob) review the performance matrix of available AI delegates and simultaneously select the representative that maximizes their expected utility. We solve for the Nash Equilibrium [8] state where neither agent has an incentive to switch technologies solely given the others choice. The regulator then evaluates the outcome based on Efficiency (total social welfare) or Fairness (minimizing the disparity between agents payoffs) [6]. The core of our analysis involves technology expansion. We first establish baseline equilibrium with subset of technologies (2 < 13) available in the GLEE dataset. The regulator first selects the market environment that maximizes its objective (e.g., fairness). We then expand the set of available technologies to the agents choice set by adding one of the other technologies from the GLEE dataset. In this newly generated meta-game, new equilibrium may emerge for any given market selection; consequently, the regulator selects potentially new market, optimizing its objective based on this new equilibrium. This allows us to isolate the specific economic impact of making new technology available, regardless of whether it was ultimately adopted by the agents."
        },
        {
            "title": "3 Results",
            "content": "The Poisoned Apple Effect Our most striking finding is strategic phenomenon we term the Poisoned Apple effect, where an agent releases new technology not to use it, but to manipulate the regulators market design. Consider representative Bargaining meta-game (Figure 1) where, initially, the agents have access to technologies 2 D. payoffs of 0.49 for Alice and 0.50 for Bob. In this setting, the regulator selects the market that maximizes fairness (Market 4), yielding expected Alice then releases new technology (E). Crucially, if the regulator were to maintain the original market design, Alice would adopt strategy in the new equilibrium, causing fairness to drop significantly (from 1.00 to 0.976). To minimize this harm, the regulator is forced to migrate to new market environment (Market 8) where fairness is relatively higher (0.990). In this new market, the equilibrium strategies do not involve using E. However, the forced market shift dramatically alters the payoff distribution: Alices payoff jumps to 0.52 while Bobs drops to 0.46. Thus, Alice successfully leverages the threat of using poisoned technology to coerce the regulator into favorable market design, improving her welfare at Bobs expense without ever actually deploying the model. Systemic Vulnerability This manipulation is not an isolated anomaly. Across more than 50,000 simulated meta-games, we observe recurrent pattern where expanding the choice set causes payoffs to move in opposite directionsone player benefits while the other is harmed (Fig. 2A). Strikingly, in approximately one-third of these zero-sum shifts, the outcome reversal occurs even though the new technology remains unused by either player in the final equilibrium (Fig. 2B). This confirms that open-weight releases or API availability can serve as strategic weapons for regulatory arbitrage. Regulatory Objectives and Stability Broader analysis reveals that the impact of such expansions depends heavily on the regulators goal. While technology expansion often improves outcomes when the regulator maximizes social welfare (efficiency), it frequently backfires when the goal is fairness (Fig. 2C). We find that the utility of new technology is strong predictor of its regulatory impact. Improvements in the regulators metric typically arise when the new technology is actively selected by at least one player in the new equilibrium (Fig. 2C). Conversely, decreases in the regulatory metric are strongly associated with instances where the added technology is not selected by either player (Fig. 2E). Finally, the results highlight the danger of regulatory inertia. If regulator fails to re-optimize the market design following technology release, the regulatory metric deteriorates in roughly 40% of cases (Fig. 2F). This demonstrates that static regulatory frameworks are insufficient; market designs must be dynamic to withstand the strategic expansion of AI capabilities. Figure 2: Strategic implications of technology expansion in meta-games. Analysis of equilibrium shifts across bargaining, negotiation, and persuasion environments. (A) Frequency of Opposite Payoff Changes: cases where expanding the technology set causes agents expected payoffs (calculated over mixed strategy equilibria) to move in opposite directions. (B) Opposite Payoff Changes Despite Zero Adoption: The subset of these reversals occurring even when the new technology is not selected by either player in the new equilibriumdemonstrating the Poisoned Apple effect. (C) Frequency of Improvement in Regulatory Metric: How often the regulators optimized objective (Fairness or Efficiency) increases versus decreases. (DE) The relationship between regulatory outcomes and model adoption: Improvements typically align with high adoption rates (D), whereas harm to the objective is frequently observed when the new model is available but acts as latent threat without being played (E). (F) Frequency of Metric Harm Without Market Update: The probability of degrading the regulatory objective if the market design remains static (regulatory inertia) after the new technology is released. Confidence intervals (95%) are not shown, as all are narrower than 2 percentage points."
        },
        {
            "title": "4 Discussion",
            "content": "Our results challenge the assumption that expanding technological choice is inherently neutral or beneficial. We demonstrate that in regulated markets, the potential to use technology is as impactful as its actual adoption. This Poisoned Apple effect suggests that open-weight releases or API availability can serve as strategic instruments to manipulate regulatory landscapes. For policymakers, this implies that market designs cannot be static; they must be dynamic and robust to the continuous expansion of the agent strategy space."
        },
        {
            "title": "References",
            "content": "[1] Vincent P. Crawford and Joel Sobel. Strategic Information Transmission. Econometrica, 50(6):14311451, 1982. Publisher: [Wiley, Econometric Society]. [2] Gillian K. Hadfield and Andrew Koh. An Economy of AI Agents, September 2025. arXiv:2509.01063 [econ]. [3] John J. Horton. Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?, January 2023. arXiv:2301.07543 [econ]. [4] Nigel Howard. Paradoxes of rationality: theory of metagames and political behavior. Cambridge: MIT Press, 1971. [5] Emir Kamenica and Matthew Gentzkow. Bayesian persuasion. American Economic Review, 101(6):25902615, 2011. [6] Eric Maskin. Nash Equilibrium and Welfare Optimality. The Review of Economic Studies, 66(1):2338, 1999. Publisher: [Oxford University Press, Review of Economic Studies, Ltd.]. [7] Roger Myerson and Mark Satterthwaite. Efficient mechanisms for bilateral trading. Journal of Economic Theory, 29(2):265281, April 1983. [8] John Nash. Non-Cooperative Games. Annals of Mathematics, 54(2):286295, 1951. Publisher: [Annals of Mathematics, Trustees of Princeton University on Behalf of the Annals of Mathematics, Mathematics Department, Princeton University]. [9] Ariel Rubinstein. Perfect Equilibrium in Bargaining Model. Econometrica, 50(1):97109, 1982. Publisher: [Wiley, Econometric Society]. [10] Eilam Shapira, Omer Madmon, Roi Reichart, and Moshe Tennenholtz. Can Large Language Models Replace Economic Choice Prediction Labs?, February 2024. arXiv:2401.17435 [cs]. [11] Eilam Shapira, Omer Madmon, Itamar Reinman, Samuel Joseph Amouyal, Roi Reichart, and Moshe Tennenholtz. GLEE: Unified Framework and Benchmark for Language-based Economic Environments, October 2024. arXiv:2410.05254 [cs]. [12] Michael Wellman. Understanding the Implications of Advanced AI on Financial Markets. Journal of Financial Transformation, 60:1419, 2025."
        },
        {
            "title": "A The GLEE Framework",
            "content": "The empirical basis of this study is the GLEE (Games in Language-based Economic Environments) framework [11]. This infrastructure addresses significant gap in evaluating Large Language Models (LLMs): the lack of standardized way to assess strategic skills in complex settings. Unlike static benchmarks (such as QA tasks), GLEE evaluates agents in multi-turn scenarios where success depends on adaptation and consistent strategy. By simulating thousands of interactions across 13 state-of-the-art LLMs as agents, GLEE generates detailed dataset of strategic behaviors. The framework logs every interaction and message, allowing us to analyze decisionmaking processes. This comprehensive dataset enables rigorous statistical analysis of model performance under different economic conditions, controlling for variables to estimate causal effects for the meta-game analysis. 4 A.1 Game Families: Taxonomy of Core Economic Interactions The investigation focuses on three distinct families of games, selected to highlight unique and fundamental aspects of economic interaction. These families cover range of cooperative and competitive dynamics found in real-world markets, from equal partnerships to settings with asymmetric information. A.1.1 Bargaining (Resource Division) This scenario is sequential resource division game based on the standard Rubinstein bargaining model [9]. Formally, two players, Alice (A) and Bob (B), must agree on how to divide fixed surplus over time horizon (potentially infinite). Time is modeled as scarce resource using discount factors δA, δB (0, 1). The game follows an alternating-offers protocol. In each odd round t, Alice proposes split (p, 1 p) where [0, 1] is her share. Bob can accept or reject. If Bob accepts, the game ends, and the discounted payoffs are: pM, UB = δt1 If Bob rejects, the game proceeds to round + 1, where Bob proposes split (q, 1 q). If no agreement is reached by the end of the horizon, both players receive 0. An outcome is denoted by the pair (tev, pev), where tev is the round of agreement and pev is Alices agreed share. (1 p)M UA = δt (1) Strategic Dynamics and Implications: The discount factors create tension between maximizing ones share and the risk of the surplus shrinking. Agents must balance greed with the need for timely agreement. This environment tests the agents ability to perform backward induction, anticipate the opponents reservation value, and use signaling strategies to test the opponents patience. For example, an agent might reject fair offer in an early round to signal stubbornness, hoping to get larger share later, despite the cost of delay. A.1.2 Negotiation (Bilateral Trade) This family models bilateral trade setting with buyer and seller [7]. Unlike bargaining, roles here are asymmetric: the Seller (Alice) holds an item with subjective valuation VA, and the Buyer (Bob) has subjective valuation VB. To capture valuation scales, we parameterize Vi = Fi for {A, B}, where Fi is factor parameter and is scale parameter. The game proceeds in alternating turns over horizon . In odd rounds, Alice posts price p; Bob can buy (accept) or reject. In even rounds, Bob posts price; Alice can sell (accept) or reject. If trade occurs at price p, the payoffs are: UA = VA, UB = VB (2) If no trade occurs, payoffs are (0, 0). The outcome is denoted by the final trading price pev (or if no trade occurred). Strategic Dynamics and Implications: The main challenge is price discovery: finding mutually beneficial price without revealing too much private information. This game tests the agents ability to bluff, infer value from offers, and navigate trust issues where high-value trades might fail due to lack of credible signaling (the lemons problem). A.1.3 Persuasion (Strategic Information Transmission) This game [5] is based on classical cheap talk models [1]. Seller (Alice) tries to persuade Buyer (Bob) to purchase product at fixed price π (normalized to π = 1). Alice privately observes the product quality, which is either High or Low. Bob only knows the prior probability of High quality, denoted by p. Bobs valuation depends on quality: he values High-quality product at > π and Low-quality product at < π (normalized to = 0). We introduce scale parameter for the buyers utility. Alices Payoff: 1 if Bob buys, 0 otherwise (regardless of quality). Bobs Payoff: (v 1) if he buys High-quality product; if he buys Low-quality product; 0 if he does not buy. The game lasts for rounds. The outcome is defined as tuple (nev, kev, rev), where nev is the number of Highquality rounds, kev is the number of purchased High-quality items, and rev is the number of rejected Low-quality items. Strategic Dynamics and Implications: This game evaluates the ability to use language for manipulation versus credibility. Sellers face dilemma: tell the truth to build reputation (if the buyer is long-term) or lie for short-term gain. Buyers must distinguish truthful signals from cheap talk, inferring quality from incentives rather than just message content. A.2 Markets and Parameters: The Architecture of Interaction Within the purview of the instant study, Market is defined not merely as venue for exchange, but as rigid configuration of environmental parameters and rules that shape the incentives and constraints of the agents. While the GLEE framework accommodates broad spectrum of continuous and discrete parameters, the focus herein is restricted to structural parameters that fundamentally alter the strategic landscape and the nature of the equilibrium. A.2.1 Parameters Defining Markets by Family Bargaining: Information Structure (CI): Boolean. Distinguishes between Complete Information, wherein agents possess perfect knowledge of their opponents discount factor (patience), and Incomplete Information, wherein this parameter remains private. Incomplete information introduces profound uncertainty, frequently precipitating aggressive posturing or wars of attrition. Communication Form (MA): Boolean. Messages Allowed denotes whether agents are permitted to exchange free-form natural language messages alongside numerical offers, or are restricted to structured proposals. Linguistic communication allows for the introduction of normative arguments (e.g., appeals to fairness), framing effects, and justification. Horizon (T): The duration of the game. Finite horizon (e.g., 10 rounds) induces end-game effects wherein backward induction strictly dictates strategy. An Infinite horizon (simulated as an extended game with stochastic termination) models steady-state negotiation environment wherein reputational concerns may dominate. Negotiation: Information Structure (CI): Boolean. Determines whether the seller is cognizant of the buyers exact valuation (Complete Information) or merely the probability distribution from which it is drawn (Incomplete Information). Communication Form (MA): Boolean. In negotiation, language enables complex tactics beyond elementary price signaling, such as highlighting product features or feigning disinterest. Indicates the permissibility of natural language messages. Horizon (T): Finite versus Infinite, affecting the pressure to concede as the deadline approaches. Persuasion: Information Structure (CI): Boolean. Determines whether the seller is cognizant of the buyers specific valuation for high-quality product. Communication Form (MA): Categorical. The mode of communication permitted (e.g., binary signals versus full textual persuasion). Full text affords greater nuance but simultaneously introduces noise and potential for hallucination. Buyer Type (MYOPIC): Boolean. Differentiates between Long-living buyer (who optimizes utility over the entire game duration) and Myopic buyer (who optimizes solely for the current turn). A.3 Regulatory Metrics: Fairness and Efficiency Market outcomes are assessed based on two primary regulatory objectives, which quantify the social desirability of the game results. These metrics serve as the objective function for the regulator in the meta-game model. 6 Efficiency (Welfare): Represents the total social surplus generated by the interaction. It assesses the extent to which resources are maximized and wastewhether via delay, disagreement, or failure to tradeis minimized. In Bargaining, efficiency is defined as the normalized sum of discounted payoffs at the time of agreement (tev). Since delays erode value (due to δ < 1), earlier agreements are inherently more efficient. An agreement in round 1 preserves 100% of the surplus, whereas an agreement in round 10 might preserve only fraction due to the time value of money: Efficiency = δtev1 pev + δtev1 (1 pev) (3) (In the absence of agreement, efficiency is 0, representing total deadweight loss). In Negotiation, it reflects allocative efficiencywhether mutually beneficial trade occurred. It functions as binary indicator variable that equals 1 if trade occurs when the buyer values the item more than the seller (VB VA) or if trade correctly does not occur when the seller values it more (VA > VB): Efficiency = {Outcome is Efficient} (4) In Persuasion, the outcome of game of length rounds is defined as tuple (nev, kev, rev). Here, nev represents the total number of rounds wherein the product was truly of High quality. Efficiency measures the rate of successful transactions for these high-quality goods: Efficiency = kev nev (5) (Where kev is the number of rounds in which high-quality product was successfully purchased by the buyer). Fairness (Equity): Represents the equality of the outcome distribution between agents, penalizing outcomes wherein one party exploits the other. In Bargaining, fairness is calculated as the deviation from an equal division. quadratic penalty is employed to strictly sanction large deviations from equality (0.5), reflecting strong societal preference for equitable splits in partnership scenarios: Fairness = 1 4 (pev 0.5)2 (If no agreement is reached, fairness is defined as 1, as both parties receive 0, which is technically equal, albeit deeply inefficient). (6) In Negotiation, it measures the deviation of the transaction price (pev) from the theoretically fair price (pf = VA+VB 2 ), which divides the surplus equally between buyer and seller. This is normalized by the scale : Fairness = 1 (cid:19)2 (cid:18) pev pf (7) (If no trade occurs, fairness is defined as 1). In Persuasion, fairness focuses on consumer protection against deception. Using the notation established above, let nev represent the total number of rounds wherein the product was of Low quality. Fairness is defined as the proportion of these low-quality products that were successfully rejected by the buyer (i.e., NOT purchased due to misleading signals): Fairness = rev nev (8) (Where rev is the number of rounds in which low-quality product was correctly rejected by the buyer). A.4 Language Models and Collected Data: The Strategy Space The strategy space appertaining to the meta-game is comprised of 13 state-of-the-art Large Language Models (LLMs). This diverse selection includes both proprietary models accessed via API and open-weight models, spanning range of capabilities, sizes, and reasoning architectures. Models Included in the Analysis: Claude 3.5 Sonnet, Claude 3.7 Sonnet, Gemini 1.5 Flash, Gemini 1.5 Pro, Gemini 2.0 Flash, Gemini 2.0 Flash Lite, GPT-4o, GPT-4o Mini, o3-mini, Grok 2, LLaMA 3.1-405B, LLaMA 3.3-70B, and Mistral Large 2411. 7 A.5 Payoff Estimation via Linear Regression The dataset comprises over 80,000 simulated games. We use the statistical framework from GLEE to construct robust payoff matrices. Separate Linear Regression models were trained for each game family and metric. These models predict the expected outcome for any model pair in any market configuration. Based on GLEE benchmark findings, these linear models provide predictive performance comparable to non-linear baselines. Model Specification: The models use one-hot encoding for: Agent Pair Interaction: The specific pair of interacting models (i vs. j). Market Design Rules: The structural parameters (CI, A, ). Situational Parameters: Economic variables specific to the instance (e.g., δ, M, ). Equation 9 represents the linear regression model: ˆym,i,j = β0 + βmarket + βpair=(i,j) + (cid:88) βsituation (9) Since we are interested in calculating the interaction values between model pairs when market conditions are known, but specific player conditions (situational parameters) are unknown or averaged out, the values we calculate for the payoff table will be: ˆym,i,j = β0 + βmarket + βpair=(i,j) (10)"
        },
        {
            "title": "B The Meta Game",
            "content": "Calculating Game Matrices We model the selection of AI delegates as meta-game where human principals (Alice and Bob) choose an AI agent from the available set. For given market, we construct four matrices (When is the number of available technologies) using the regression predictions: 1. Row Player Payoff (UA) 2. Column Player Payoff (UB) 3. Designer Metric - Fairness (DF ) 4. Designer Metric - Efficiency (DE) Finding Equilibrium We compute the Mixed Strategy Nash Equilibrium (MSNE) for the game defined by UA and UB. Using the Lemke-Howson algorithm (via the nashpy library), we enumerate all equilibria returned by the algorithm. When multiple equilibria exist, the expected payoffs of the agents and the regulator are defined as the average of their expected values across all such equilibria. Regulatory Optimization Once equilibria are identified for all candidate market configurations, the regulator (Designer) utilizes the Designer matrices (DF or DE) to determine the optimal market structure. B) be the computed equilibrium profile. The expected value of the Designers For each market m, let (σ objective VD(m) is calculated as: A, σ VD(m) = (σ A)T Dm σ (11) where Dm is the Designer matrix (Fairness or Efficiency) for market m. The regulator then selects the market configuration that maximizes this expected value: This step completes the meta-game loop, determining the final regulatory environment and the resulting agent payoffs. = arg max mM VD(m) (12)"
        },
        {
            "title": "C The Poisoned Apple Effect",
            "content": "This section provides detailed breakdown of the Poisoned Apple phenomenon illustrated in Figure 1 of the main text. The effect describes strategic manipulation where player introduces new technology not to utilize it, but to force fairness-maximizing regulator to alter the market design in way that disproportionately benefits the releaser. We examine specific instance from the Bargaining game family. The initial strategy space consists of four Large Language Models: Model (claude-3-7-sonnet), Model (gemini-2.0-flash), Model (llama-3.1-405b-instruct), and Model (llama-3.3-70b-instruct). The regulators objective is to maximize Fairness (defined in Eq. 4 as the minimization of deviation from an equal split). Phase 1: The Status Quo (Pre-Release). The regulator evaluates the potential equilibria across all market configurations and selects the environment that maximizes fairness. Table 1 details the fairness scores for market configurations in this initial state. The optimal design, designated as Market 4, is defined by Incomplete Information (CI = False), Allowed Communication (MA = True), and an Infinite Horizon (T = ). Table 1: Fairness Scores Across Markets (Pre-Release) Market ID Parameters (Info, Comm, Horizon) Fairness 1 2 3 4 5 6 7 8 Incomplete, No Messages, Finite Incomplete, No Messages, Infinite Incomplete, Messages, Finite Incomplete, Messages, Infinite Complete, Messages, Finite Complete, Messages, Infinite Complete, No Messages, Finite Complete, No Messages, Infinite 0.975 0.965 0.989 1.000 0.977 0.962 0.974 0.990 In this environment (Market 4), the game stabilizes at pure strategy equilibrium: Alice selects Model (llama-3.3-70b-instruct). Bob selects Model (claude-3-7-sonnet). Outcome: This pairing results in perfect Fairness score of 1.000. The expected payoffs are 0.49 for Alice and 0.50 for Bob. Phase 2: The Toxic Release (Intermediate State). Alice introduces new technology, Model (gemini-1.5-pro), into the ecosystem. The availability of this model drastically alters the strategic landscape. Table 2 displays the re-calculated fairness scores with Model available. Table 2: Fairness Scores Across Markets (Post-Release) Market ID Parameters (Info, Comm, Horizon) Fairness 1 2 3 4 5 6 7 8 Incomplete, No Messages, Finite Incomplete, No Messages, Infinite Incomplete, Messages, Finite Incomplete, Messages, Infinite Complete, Messages, Finite Complete, Messages, Infinite Complete, No Messages, Finite Complete, No Messages, Infinite 0.975 0.965 0.988 0.976 0.967 0.962 0.959 0.990 As shown in Table 2, the fairness in the original Market 4 drops significantly (from 1.000 to 0.976). The availability of Model destabilizes the original equilibrium: 9 Alice switches to the new Model (gemini-1.5-pro). Bob continues to play Model (claude-3-7-sonnet). Impact: This shift causes the Fairness in Market 4 to deteriorate. In this intermediate state (if the market were not updated), Alices payoff would theoretically rise to 0.51, while Bobs would drop to 0.40. Phase 3: Regulatory Flight and Payoff Reversal (Post-Release). To restore fairness, the regulator is compelled to abandon Market 4 and migrate to the new optimal alternative. The data indicates that Market 8 defined by Complete Information (CI = True), Prohibited Communication (MA = False), and an Infinite Horizon (T = )is now the fairness-maximizing choice (0.990). In this new market, the strategic landscape reorganizes completely: Alice switches to Model (claude-3-7-sonnet). Bob switches to Model (gemini-2.0-flash). Non-Adoption: Crucially, in this new equilibrium, neither player selects the new Model E. The technology that precipitated the market shift is discarded. Outcome: The regulator restores Fairness to 0.990. However, the forced regulatory shift drastically alters the payoff distribution. Alices expected payoff rises to 0.52 (+0.03 relative to the status quo), while Bobs payoff falls to 0.46 (0.04)."
        }
    ],
    "affiliations": [
        "Technion Israel Institute of Technology"
    ]
}