{
    "paper_title": "GLEE: A Unified Framework and Benchmark for Language-based Economic Environments",
    "authors": [
        "Eilam Shapira",
        "Omer Madmon",
        "Itamar Reinman",
        "Samuel Joseph Amouyal",
        "Roi Reichart",
        "Moshe Tennenholtz"
    ],
    "sections": [
        {
            "title": "Abstract",
            "content": "Large Language Models (LLMs) show significant potential in economic and strategic interactions, where communication via natural language is often prevalent. This raises key questions: Do LLMs behave rationally? Can they mimic human behavior? Do they tend to reach an efficient and fair outcome? What is the role of natural language in the strategic interaction? How do characteristics of the economic environment influence these dynamics? These questions become crucial concerning the economic and societal implications of integrating LLM-based agents into real-world data-driven systems, such as online retail platforms and recommender systems. While the ML community has been exploring the potential of LLMs in such multi-agent setups, varying assumptions, design choices and evaluation criteria across studies make it difficult to draw robust and meaningful conclusions. To address this, we introduce a benchmark for standardizing research on two-player, sequential, language-based games. Inspired by the economic literature, we define three base families of games with consistent parameterization, degrees of freedom and economic measures to evaluate agents' performance (self-gain), as well as the game outcome (efficiency and fairness). We develop an open-source framework for interaction simulation and analysis, and utilize it to collect a dataset of LLM vs. LLM interactions across numerous game configurations and an additional dataset of human vs. LLM interactions. Through extensive experimentation, we demonstrate how our framework and dataset can be used to: (i) compare the behavior of LLM-based agents to human players in various economic contexts; (ii) evaluate agents in both individual and collective performance measures; and (iii) quantify the effect of the economic characteristics of the environments on the behavior of agents."
        },
        {
            "title": "Start",
            "content": "4 2 0 2 7 ] . [ 1 4 5 2 5 0 . 0 1 4 2 : r GLEE: UNIFIED FRAMEWORK AND BENCHMARK FOR LANGUAGE-BASED ECONOMIC ENVIRONMENTS Eilam Shapira1, Omer Madmon1, Itamar Reinman1, Samuel Joseph Amouyal2, Roi Reichart1, Moshe Tennenholtz1 1Technion - Israel Institute of Technology 2Tel Aviv University eilamshapira@campus.technion.ac.il"
        },
        {
            "title": "ABSTRACT",
            "content": "Large Language Models (LLMs) show significant potential in economic and strategic interactions, where communication via natural language is often prevalent. This raises key questions: Do LLMs behave rationally? Can they mimic human behavior? Do they tend to reach an efficient and fair outcome? What is the role of natural language in the strategic interaction? How do characteristics of the economic environment influence these dynamics? These questions become crucial concerning the economic and societal implications of integrating LLMbased agents into real-world data-driven systems, such as online retail platforms and recommender systems. While the ML community has been exploring the potential of LLMs in such multi-agent setups, varying assumptions, design choices and evaluation criteria across studies make it difficult to draw robust and meaningful conclusions. To address this, we introduce benchmark for standardizing research on two-player, sequential, language-based games. Inspired by the economic literature, we define three base families of games with consistent parameterization, degrees of freedom and economic measures to evaluate agents performance (self-gain), as well as the game outcome (efficiency and fairness). We develop an open-source framework for interaction simulation and analysis, and utilize it to collect dataset of LLM vs. LLM interactions across numerous game configurations and an additional dataset of human vs. LLM interactions. Through extensive experimentation, we demonstrate how our framework and dataset can be used to: (i) compare the behavior of LLM-based agents to human players in various economic contexts; (ii) evaluate agents in both individual and collective performance measures; and (iii) quantify the effect of the economic characteristics of the environments on the behavior of agents. We believe that our framework can contribute to the growing intersection of LLMs, ML, and economics, and we encourage researchers to explore it further and build on its foundation."
        },
        {
            "title": "INTRODUCTION",
            "content": "Recent research has increasingly focused on the capabilities of Large Language Models (LLMs) in decision-making tasks, revealing their potential to operate as autonomous agents in various economic environments, that typically require involving complex strategic thinking (Horton 2023; Wang et al. 2023; Zhu et al. 2024; Li et al. 2024). Applications of LLM-based agents in such environments include Chess-playing (Feng et al. 2024), task-oriented dialogue handling (Ulmer et al. 2024), financial advisement (Lakkaraju et al. 2023) and beyond. The promising capabilities of LLMs in strategic decision-making call for the study of these agents behavior through the lens of game theory, e.g. whether and when LLM-based agents naturally converge to Nash-equilibrium (Guo et al. 2024), and how well they learn to cooperate in repeated interactions (Akata et al. 2023). The rise of LLM agents also calls for clear benchmark for assessing the extent to which such agent behaves rationally, which is addressed by recent work of Raman et al. (2024). An important property of many real-world economic environments is that communication between agents typically occurs through natural language. While economic modeling usually abstracts away these nuances for the sake of keeping the model simple and tractable, in practical scenarios the fact that natural language is involved may significantly affect the interaction outcome. For instance, in 1 bargaining between two parties, the same offer can be interpreted very differently depending on how it is framed. Consider the following two offers for business partnership: (a) We propose 40-60 split as we believe your expertise will drive the majority of the success. (b) We propose 40-60 split because weve already invested significant resources and need lower share to maintain balance. Both propose the same numerical terms, but the framing in each case may lead to different reactions based on how the rationale is presented. similar rationale applies to broader range of economic scenarios. To illustrate this further, let us consider the following representative use cases: Bargaining. Alice and Bob co-own startup valued at million dollar, and must decide how to divide the proceeds from its sale. To reach an agreement, they take turns proposing how to split the shared value, with each delay in reaching decision reducing the overall value for both parties. The interaction often involves free language in the proposal exchange. Negotiation. Alice aims to sell product to potential buyer, Bob. They negotiate by taking turns proposing prices, with Alice deciding whether to accept Bobs offer and sell, and Bob deciding whether to accept Alices price and buy, continuing this process until they reach an agreement or the negotiation concludes. The negotiation often involves natural language, such as descriptions of the product, which can influence the outcome. Persuasion. Alice is seller trying to sell product to Bob at an exogenously set fixed price. Alice knows the true quality of the product, while Bob only has rough expectation of the products quality. Alice sends message to persuade Bob to buy the product, aiming to convince him of its value, regardless of its true quality. Bob, however, benefits only if the product is genuinely high quality. The interaction then repeats for multiple rounds, where product qualities are realized independently at different rounds. In such scenario, Alice balances between her maximizing one-shot gain and building positive reputation, and linguistic communication can play significant role. These three types of interactions are inspired by influential models in the economics literature. They are also broad and flexible enough to capture wide variety of real-world applications. The bargaining model, inspired by the seminal work of Rubinstein (1982), forms the basis for understanding how parties negotiate the division of shared resources, applicable in scenarios such as business mergers, partnership dissolution, and legal settlements. The negotiation game reflects celebrated models of bilateral trade (Myerson & Satterthwaite 1983; McAfee 1992) where buyers and sellers negotiate over the prices of an indivisible good, which often arises in various applications, including real estate transactions, corporate acquisitions, and e-commerce platforms. Lastly, the persuasion model draws on classical models of information asymmetry and strategic communication (Akerlof 1978; Crawford & Sobel 1982; Farrell & Rabin 1996), which play pivotal role in advertising, marketing, political campaigning, and recommendation systems. key feature of all these games is that they are sequential, meaning players take turns acting rather than acting simultaneously. This makes communication, and in particular language-based communication, crucial element of the interaction. In sequential games, communication is typically direct, with players able to attach messages to their actions (i.e., in the bargaining example, the textual message is attached to the proposal). In contrast, in simultaneous games, communication tends to be indirect, as players act independently and typically learn to cooperate by observing and reacting to past actions rather than through direct message exchange. prime example of simultaneous, language-based economic interaction is the competition among web publishers in search engines. Publishers simultaneously create content (usually in the form of textual documents) for their websites, and then gradually learn and adapt based on outcomes, such as their relative search engine rankings and exposure. However, they usually lack the opportunity for real-time communication or coordination during this process. These simultaneous, language-based interactions are well-studied within the information retrieval community, and the induced publishers game is indeed modeled as 1Notice that in the economic literature, the terms bargaining and negotiation are often used interchangeably to describe both the division of divisible good and the process of price negotiation. In this paper, we use the terminology bargaining to describe the former and negotiation for the latter, for ease of exposition. We refer to Appendix for further discussion on the differences between the two games. 2 simultaneous game.2 Our work is complementary, focusing on sequential settings where direct, language-based communication is prevalent. The AI and NLP communities have recognized the potential of integrating natural language into stylized economic models of bargaining, negotiation and persuasion. They also recognize the importance of studying the capabilities and limitations of LLM-based agents within such frameworks. growing body of research is dedicated to evaluating and optimizing LLM-based agents in various bargaining and negotiation scenarios (Abdelnabi et al. 2023; Deng et al. 2024; Xia et al. 2024; Bianchi et al. 2024; Noh & Chang 2024). In the realm of persuasion games, recent studies have introduced language-based frameworks that explore the design of optimal information transmission policies (Raifer et al. 2022) and develop methods for generating data to predict human players behavior (Apel et al. 2022; Shapira et al. 2023; 2024). Although each of these economic setups has been studied in the context of LLM-based agents, the approaches have varied widely across different studies. Each paper often adopts distinct modeling and implementation assumptions, poses unique research questions, and applies diverse evaluation criteria, making it challenging to compare results and draw broader conclusions about the capabilities and limitations of LLM-based agents in economic environments. To enhance the real-world reliability of LLM-based agents, it is essential to establish clear benchmark that provides standardized framework for modeling these economic interactions. This benchmark would ensure comparability across studies and enable generalization of findings, facilitating deeper understanding of how various factors influence interaction outcomes and leading to more robust and reliable conclusions about the performance of LLM-based agents in real-life economic situations. 1.1 OUR CONTRIBUTION We introduce GLEE, unified framework for Games in Language-based Economic Environments,3 focusing on the case of two-player games.4 Our framework relies on clear and comprehensive parameterization of the space of all bargaining, negotiation and persuasion games (as described above), and defines degree of freedom and evaluation metrics that are consistent across economic contexts. The generality of the space of games spanned by our parameterization follows from the richness of the degrees of freedom considered, which include the game horizon (number of rounds within each game), information structure (whether agents know each others preferences or not), and communication form (whether agents communicate via free language of structured messages). Through this framework, we have collected dataset of LLM vs. LLM games, containing 7.15M decisions made by LLM-based agents in over 954K games, using four different LLMs. Our framework allows for running controlled experiments across various degrees of freedom, language models, and game scenarios, making the dataset valuable for comparing and evaluating LLM performance in different economic setups. It also facilitates deeper insights into how characteristics of the economic environment influence agent behavior and ultimately shape the outcomes of interactions. Additionally, we design and develop an interactive interface we run experiments in which human players play against LLM-based agents in those considered games, for variety of game parameters, and collect human vs. LLM interaction dataset. To recap, the contribution of this paper is fourfold. First, we introduce clear parametrization of large, general, and representative set of sequential, two-player, language-based games. This parametrization is inspired by both the relevant economic literature, as well as advances in the LLM agents literature. Importantly, our parameterization can be naturally extended beyond the two-player case. Second, we release open-source code for GLEE, unified framework that enables controlled experiments across the representative families of games considered. Notably, our framework is 2See e.g. Raifer et al. (2017); Ben-Porat et al. (2019); Kurland & Tennenholtz (2022); Hron et al. (2022); Madmon et al. (2023; 2024); Nachimovsky et al. (2024). In these works, SEO competitions are modeled as simultaneous games. 3Code and data are available in https://github.com/eilamshapira/GLEE. 4The two-player case is particularly important since the main shift occurs when moving from single-agent decision-making to two-agent interactions, in which strategic behavior and communication play crucial roles. Two-player scenarios are also widely observed in real life, and the phenomena emerging from these interactions tend to be more intuitive and easier to analyze, while still capturing the core behaviors that arise in more complex multi-agent environments. 3 flexible and facilitates the collection of additional interactions with novel LLMs, game parameters and evaluation metrics, which is crucial given the fast advancements in the field. Third, we utilize GLEE to collect dataset of LLM vs. LLM and human vs. LLM interactions in wide range of economic environments, building on the foundations of our comprehensive parametrization. Finally, we demonstrate how the dataset can be analyzed to draw meaningful conclusions and economic insights regarding LLM-based players and human players in language-based economic environments."
        },
        {
            "title": "2 GAME FAMILIES AND PARAMETRIZATION",
            "content": "In this section, we formally define the three game families discussed in the introduction: bargaining, negotiation and persuasion.5 In our modeling, we focus on three main degrees of freedom that are critical for understanding the dynamics of LLM-based agents in economic interactions: game horizon, information structure, and communication form. The game horizon refers to the number of time periods during which the game is played and whether the length of the horizon is known or unknown to the agents.7 This factor influences the strategies agents adopt, particularly in terms of long-term planning and anticipation of future moves. The information structure determines whether agents are aware of each others preferences, impacting their ability to predict and respond to the actions of others. Lastly, the communication form specifies whether communication between agents occurs through free language or structured, concise messages, which affects the richness and clarity of the exchanges. 2.1 BARGAINING GAMES The first family of games is inspired by the celebrated bargaining model of Rubinstein (1982). The model encompasses class of bargaining games where two players, Alice and Bob, alternate offers over time horizon (usually, = ) to divide fixed sum of money between them.8 Importantly, in these games delays are costly, concept captured by discount factors δA, δB assigned to each player, reflecting the decreasing value of future payoffs as time progresses. Formally: At each odd stage t, Alice offers division (p, 1 p) for some [0, 1]. Bob decides whether to accept or reject. If Bob accepts, the (Alice, Bob) utility vector is given by (δt1 (1 p)). At each even stage t, Bob offers division (q, 1 q) for some [0, 1]. Alice decides whether to accept or reject. If Alice accepts, the game terminates, and the (Alice, Bob) utility vector is given by (δt1 (1 q)). If no agreement is reached at any stage, the utilities are defined to be (0, 0). In the standard version of the game, the time horizon is infinite and the discount factors are common knowledge (i.e., Alice and Bob know both δA and δB). p, δt q, δt1 In our experiments, we simulate wide range of such bargaining games, differing in the following degrees of freedom: (i) whether or not the players know their opponents discount factor (complete vs. incomplete information); (ii) whether or not the players know when the game terminates (finite infinite); (iii) whether or not players communication involve natural language (structured vs. vs. linguistic); (iv) the values of δA, δB (0, 1) and ; (v) the value of in the finite horizon case. An outcome of the game is pair (tev, pev), where tev is the stage index at which the game terminated, and pev is the share of that Alice obtained (without considering the discount in the utilities). When the game terminates without reaching an agreement, we define tev = , and the gain for both players is zero. The evaluation metrics used to assess the economic outcome are efficiency and fairness. Efficiency is now measured by the normalized sum of Alices and Bobs 5In Appendix we further discuss the related economic literature, and review some well-known theoretical results concerning these games. For each family, we provide formal game-theoretic definition of the game (including the players, strategies and utilities), define degrees of freedom, and define the game outcome and evaluation metrics. While previous research has effectively tackled the challenge of evaluating the rationality of individual agents (Raman et al. 2024), our focus extends to evaluating the outcome reached by the strategic behavior of the agents, using the fundamental economic notions of efficiency and fairness. 6 7In economic theory, infinite horizon typically refers to large, unspecified duration. Accordingly, we use the term infinite horizon to describe cases where the horizon is both large and unknown to the agents. 8It is clear that under full rationality assumption, the amount of money does not play role in the analysis. However, for human (or LLM) players, it is evident that the amount of money indeed matters (See Figures 16, 22, 28 in Appendix E). 4 discounted payoffs at the time of agreement: δtev1 (1 pev) if tev < , and 0 if tev = . Fairness is defined as the distance between the actual division and the fairest division, 1 4 (pev 1 2 )2 if tev < , and 1 if tev = .9 pev + δtev1 B"
        },
        {
            "title": "2.2 NEGOTIATION GAMES",
            "content": "In the second family of games, referred to as negotiation games, seller (Alice) and buyer (Bob) are negotiating over the price of product. At the outset, Alice owns product she subjectively values at VA. The subjective valuation of the potential buyer, Bob, is VB. To capture the notion of valuation scale in negotiation games, we parameterize Vi = Fi for {A, B}, where Fi (0, 1) is factor parameter is scale parameter. As in the case of bargaining games, Alice and Bob alternate offers: at each odd stage, Alice posts price and Bob decides whether to buy the product or move on to the next stage. At each even stage, Bob is the one to post price and Alice decides whether to sell at this price or reject and move on to the next stage. The game is played for stages, which again can be either finite or infinite (i.e., large and unknown to both players). Unlike the bargaining game, here we assume no discount factors on the utilities, hence whenever price is accepted, the utilities for Alice and Bob are VA and VB respectively. If no trade is made, then the utilities are defined to be (0, 0). In this class of games, we consider the following degrees of freedom: (i) whether or not the players incomplete information); (ii) whether or know their opponents product valuation (complete vs. infinite); (iii) whether or not players not the players know when the game terminates (finite vs. linguistic); (iv) the values of FA, FB communication involve natural language (structured vs. (0, 1) and ; (v) the value of in the finite horizon case. (cid:17)2 (cid:16) pevpf An outcome of negotiation game is captured by pev, which is the price at which the product is sold when there is trade, and defined to be pev = whenever no trade is made. We consider the following evaluation measures of the game outcome fairness and efficiency. When there is trade, is the fairest price.10 When trade fairness is measured by 1 4 is not made, we define the fairness to be 1 (i.e., maximal fairness) to reflect that no-trade does not change the default allocation of the product. Efficiency is defined to be 1 in the following cases (and zero otherwise): (a) Alice values the product more than Bob, and does not sell it (VA VB and = ); (b) Alice values the product less Bob, and sells the product at price that is beneficial for both players (VA VB); When averaged over large number of simulated games for certain game configuration, this measure estimated the probability of the event an efficient trade occurs when it should occur. , where pf = VA+VB 2 2.3 PERSUASION GAMES In persuasion game, seller (Alice) tried to persuade buyer (Bob) to buy product at fixed price π. Alice privately knows the true product quality, which can be either high or low. Bob only knows that the prior probability of the product being of high quality is p. Alice gets utility of 1 if Bob buys (regardless of the true product quality), and 0 otherwise. Bob values high-quality product at > π and low-quality product at < π. Therefore, the utility of Bob from buying high-quality product is π > 0, and from buying low-quality product is π < 0. For simplicity, we normalize the price to π = 1 and the value of low-quality product to = 0. In addition, we consider currency scale parameter that serves as multiplicative term of Bobs utility function. Overall Bob gets utility of (v 1) from buying high-quality product, from buying low-quality product, and 0 from not buying the product. The timing of single round is as follows. First, Alice observes the product quality (which is realized to be high-quality w.p. p, independently of other rounds). Then, Alice sends message to Bob. Lastly, Bob decides whether to buy or not to buy the product, and utilities are realized 9We consider the case of no trade as fair, since both players get the same utility. Obviously, this is also the least efficient outcome, which highlights the natural fairness-efficiency tradeoff. 10Notice that unlike all other metrics, the fairness metric in negotiation games is not normalized, as the price pev is unbounded in principle. However, we observe that normalizing the difference pev pf by the scale parameter results in measure that is between 0 and 1 in 99.5% of the cases. 5 accordingly. The game then consists of such rounds. Alices goal is to maximize her cumulative utility over time. We differentiate between two types of persuasion game setups: (a) Long-living buyer. The buyer is long-living, in the sense that he also aims to gain his cumulative utility over time. In this case, both players observe the entire interaction history; (b) Myopic buyers. Buyers are myopic, in the sense the buyer of stage only cares about the utility obtained at stage t. In this case, each buyer observes the statistics of all previous rounds (i.e., % of rounds in which Bob bought the product, and % of rounds in which Bob bought low-quality product).11 We consider the following degrees of freedom in persuasion games: (i) whether or not Alice knows Bobs high-quality product valuation (complete vs. incomplete information); (ii) whether or not the players know when the game terminates (finite vs. infinite); (iii) whether or not Alices messages involve natural language (structured vs. linguistic); (iv) the values of v, and ; (v) the value of in the finite horizon case; (vi) whether the game is with long-living Bob or with myopic buyers. An outcome of the game is tuple (nev, kev, rev), where nev is the number of rounds in which the product was of high-quality, kev is the number of rounds in which the product was of high-quality and the buyer bought the product, and rev is the number of rounds in which the product was of low quality and the buyer did not buy the product. We define efficiency to by the proportion of rounds in which the product was sold out of all rounds in which the product was of high quality (i.e., kev ), nev and fairness to be the proportion of rounds in which the product was not sold out of all rounds in ). which the product was of low quality (i.e., rev nev"
        },
        {
            "title": "3 DATA COLLECTION",
            "content": "In this section, we describe the data collection process. We developed game management system to facilitate data collection from the games described in 2. The system is written in Python and is easy to use and customize, allowing future researchers to collect data seamlessly. New language models can be added easily, enabling them to play in any configurable setup. With single command line, the system allows running either single configuration or set of configurations. Prompt samples are described in Appendix B. 3.1 LLM DATA COLLECTION Bargaining Negotiation Persuasion δA δB CI MA 0.8, 0.9, 0.95, 1 0.8, 0.9, 0.95, 1 102, 104, 106 12, True, False True, False FA FB CI MA 0.8, 1, 1.2, 1.5 0.8, 1, 1.2, 1.5 102, 104, 106 1, 10, True, False True, False T CI Messages type Binary, Textual Buyer type 1 3 , 0.5, 0.8 1.2, 1.25, 2, 3, 4 102, 104, 106 20 True, False Long-living, Myopic In total 384 configurations In total 576 configurations In total 384 configurations Table 1: Parameters and their optional values used to define the 1,344 game configurations across bargaining, negotiation, and persuasion game families for data collection. = means very large value of , which is unknown to the players. CI = Complete Information. MA = Textual messages allowed. Since the game space defined by the parameters presented in 2 is infinite for each of the game families, it is clear that data cannot be collected from all possible games. Therefore, we attempted to cover the game space by selecting diverse values for each of the parameters defining the games, and we collected data from every possible combination generated by these parameters. 11That is, each buyer observes sufficient statistics from the entire history. This implementation detail is due to context length memory which is an inherent limitation of LLM agents, as well as to reducing cognitive load on human players. 6 human Qwen-2 Gem LamLam-3.1 Barg. Nego. Pers. total # Games # Messages # Words # Decision 3.4K 6.64K 58.8K 7.43K 309K 1.16M 40.9M 1.42M 342K 332K 429K 870K 1.34M 1.33M 29.2M 51.7M 54.7M 1.11M 1.58M 1.56M 282K 666K 10.2M 52M 1.01M 2.15M 4M 539K 954K 133K 1.41M 4.01M 6.09M 174M 236M 7.15M Table 2: Statistics of data collected: by human players and each of the LLMs (left), for each game family (center), and in total (right). The number of games indicates the number of games in which the language model was involved as one or both players. The number of messages and decisions represents the number of decisions made and messages sent by the language model. Gem. = Gemini, Lam = Llama; Barg. = Bargening, Nego. = Negotiation, Pers. = Persuasion. Table 1 shows the parameters defining the groups from which we collected data. In total, we collected data from 1,344 different configurations: 384 configurations of bargaining, 576 configurations of negotiation, and 384 configurations of persuasion games. For data collection, we used four language models: Qwen-2-7B (Yang et al. 2024), Llama-3-8B, Llama-3.1-8B (Meta 2024), and Gemini-1.5-Flash (Gemini Team 2024). Each of the 16 possible pairs (including language model against itself, with attention to the order defining the roles of the players in the game) played at least 30 games from the 1,344 configurations. In total, 954K games were played, with full statistics appearing in Table 2. The complete data from all games, including the messages sent by the language models, the decisions made, and the prompts and responses of the language models that generated these messages, form one of the main contributions of this paper and are available in the papers GitHub repository. In addition to these models, we collected data for some of the configurations using Gemini-1.5-Pro (Gemini Team 2024) and Llama-3.1-405B (Meta 2024), two larger, more powerful, and expensive models compared to the ones used. These models played against each other and against some of the four presented models. Due to budget constraints, data collection with these models was not comprehensive, but the data from these games still contributes to the paper. It was possible to alter the prompt that introduces the game, explore different variations, and allow the language models to play different personas. While this could impact the behavior of the language models, budget limitations would have required us to collect less data from each configuration. Therefore, we chose to keep the prompt fixed rather than further defining the language models setup. However, the system allows easy prompt customization to support future research. 3.2 HUMAN DATA COLLECTION One of the main objectives of collecting data from language games is to compare the behavior of LLMs with human behavior in economic and strategic situations. To facilitate this comparison, we developed an interface that allows human players to play all the language games that can be defined using GLEE. The interface transforms the various prompts presented to LLMs into user-friendly screens for human participants, displaying the prompt and requesting them to send messages and make decisions.12 Through this interface, we enable human players to take on the role of one of the players while the other player is pre-selected LLM. The interface is one of the contributions of this paper. Screenshots of the interface can be found in Appendix C.1. The interface, developed using oTree (Chen et al. 2016), enables integration with Amazons crowdsourcing platform, mTurk,13 through which we recruited 3,405 players who participated in various configurations against Gemini-1.5-flash. We chose Gemini-1.5-flash since it demonstrated strong performance compared to other LLMs and allowed comprehensive data collection due to its low usage cost. Since we aimed to collect multiple games from each configuration, we had to select limited set of configurations for human participants to play. The process of selecting these sets 12Since human players are accustomed to being addressed by their first name (rather than as Alice or Bob), we asked them to enter their name at the beginning of the game and referred to them by their name throughout the game. The players name was the only difference between the human player and the LLM-based player. 13https://www.mturk.com/. 7 is described in Appendix C.2. We collected human data from 195 different configurations: 78 of which were bargaining games, 60 of which were negotiation games, and 57 were persuasion games. Each human player was allowed to play one game every 12 hours from each family of games. Human players were paid base rate calculated at $6 per hour, plus an average bonus of $6 per hour. In total, we paid $2,245 to all players for their participation in the games. Bonuses were dependent on the configuration the human players played and their success in the game. The average bonus was known to players at the start of the game, aiming to encourage serious gameplay. To ensure players remained focused and made thoughtful decisions, we conducted two attention checks during the experiment, detailed in Appendix C.3. Players who failed in one of the attention checks were excluded from the dataset. To reflect the real-world significance of the magnitude of product prices (the parameter M) in each family of games, we defined the bonus as dependent on M: in configurations where = 102, the average bonus was $3 per hour; where = 104, the average bonus was $6 per hour; and where = 106, the average bonus was $9 per hour."
        },
        {
            "title": "4 EXPLORATORY DATA ANALYSIS",
            "content": "In this section, we first present method to ensure an adequate comparison between models that played different configurations. Then, we address two key research questions: Q1: How did the language models perform in each game family in terms of self-gain, efficiency, and fairness? Q2: How did the humans perform compared to the language models? Q3: How do the parameters defining the games influence the various metrics? Adequate Comparison Between Models For the four language models introduced in 3, we collected data covering the entire set of the configurations defined in Table 1 for every possible pair of language models. This enables seamless comparison of their performance across all defined metrics. Henceforth, this dataset will be referred to as the baseline set, and the models that generated it will be referred to as the baseline models. When evaluating data generated by new model or by humans, it is often not feasible (due to cost considerations) to have them play all games against all existing language models.14 To evaluate model performance on large variety of language games, we can collect data from subset of configurations, calculate the metrics for those, and use the results (along with the metrics from the baseline set) to train predictive model that estimates the metrics for configurations for which data was not collected. This method allows for an adequate comparison between models that played different configuration sets. For the calculation of the metrics, we train simple regression model for each metric. The model receives as input the values defining the configuration as binary features (e.g., Is = 100?) and binary features describing the interaction between the language models and other parameter values (e.g., Did Alice played by Gemini-1.5-Flash and = 100? and Did Alice played by Gemini1.5-Flash, Bob played by Llama-3.1-8B, and = 100?). To prevent the model from learning relationships between parameter values directly from configuration settings, we used binary features even for parameters that contain numerical values. We trained the models on the data from all games and predicted the values for all configurations: both those for which data was collected and those for which it was not. Therefore, to maintain consistency, all the metrics are calculated by averaging the predicted values over all game configurations. This approach allows us to reasonably estimate the metric values expected for configurations where no human data was collected. The exact formulas defining each regression model are presented in Appendix D. To assess the quality of the models, we examined the adjusted R-squared values of the regression models. In 10 out of 12 trained models, we obtained adjusted R-squared values higher than 0.38. Table 3 shows the adjusted R-squared values of the models. The table shows that, in general, persuasion games are the easiest to predict, and we hypothesize that this is because their outcomes consist of collection of multiple decisions. Negotiation games are the most difficult to predict, possibly because, unlike the other games, players could exit the game at any given moment. It seems that fair14Collecting data from humans playing 30 games in each possible configuration would cost approximately $187K. Collecting similar data from Gemini-1.5-Pro would cost around $10K. 8 ness is the most challenging metric to fit with regression model, with negotiation games showing an especially low adjusted R-squared."
        },
        {
            "title": "Bargaining\nNegotiation\nPersuasion",
            "content": "0.54 0.48 0.63 0.47 0.58 0.89 0.57 0.38 0.58 0.28 0.09 0.41 Table 3: Adjusted R-square values of the regression models used for metric calculations and analyzing the impact of specific parameters on metrics. Model and Human Performance (Q1 and Q2) Table 4 presents, for each language model, the metric values for each role in each game family. The presented values are the predicted average values over all configurations for which data was collected, as described in 3. For each role, we present the self-gain achieved by the model, as well as the two metrics introduced in 2: the efficiency and fairness values observed in games involving the model. Note that while the self-gain metric measures the players performance in the game, the efficiency and fairness metrics describe the economic quality of the interaction outcome. This table allows us to compare the performance of different language models across game families. The table allows us to compare the performance of humans to that of language models across different game families. Humans outperformed the language models in bargaining games when playing as Alice, but when playing as Bob, they achieved the worst performance. In negotiation games, humans performed poorly, with negative average self gain, in contrast to the language models, which managed to achieve gains in both roles (except for Qwen-2 in the role of Alice). Human performance in persuasion games was relatively strong, second only to that of Llama-3.1. Importantly, metric values presented in Table 4 are calculated by averaging over all possible game configurations in our dataset. These averages are therefore highly sensitive to the particular configurations, and the configuration distributions, in our dataset. To tailor the benchmark to specific Family Rule Metric Human Qwen-2 Lam-3 Lam-3.1 Gem-F Bargaining Negotiation Persuasion Alice Bob Alice Bob Alice Bob Self Gain Efficiency Fairness Self Gain Efficiency Fairness Self Gain Efficiency Fairness Self Gain Efficiency Fairness Self Gain Efficiency Fairness Self Gain Efficiency Fairness 0.61 0.89 0.71 0.27 0.94 0.69 -0.24 0.65 0. -0.05 0.67 0.58 0.55 0.55 0.41 0.68 0.93 0.21 0.49 0.88 0.87 0.34 0.97 0.81 -0.02 0.68 0. 0.08 0.73 0.81 0.60 0.78 0.63 0.45 0.84 0.59 0.43 0.86 0.87 0.38 0.79 0.86 0.03 0.75 0. 0.05 0.67 0.83 0.57 0.71 0.61 0.53 0.68 0.60 0.46 0.86 0.86 0.42 0.78 0.80 0.05 0.73 0. 0.07 0.69 0.84 0.61 0.76 0.60 0.75 0.35 0.61 0.55 0.88 0.76 0.43 0.88 0.91 0.07 0.75 0. 0.12 0.81 0.82 0.58 0.65 0.53 0.41 0.65 0.77 Table 4: Average predicted self-gain, efficiency, and fairness metrics for each language model across different roles and game families, comparing baseline models and human players. In bold: The highest value achieved in the metric. 9 applications, we recommend re-defining the parameter space and their distributions according to the economic context.15 In addition, notice that the fact that metrics are averaged over all configurations may hide the effect of particular game parameters on the game outcome or agents self-gain. We next demonstrate how more delicate analysis of the dataset enables to isolation of the effect of certain game parameters. Influence of Game Parameters (Q3) To evaluate the effect of specific parameter on metric, we use the same regression model. To create graph depicting the effect of parameter on metric achieved by language model playing as Alice, we extract from the regression model the effects of values, values, and their interaction on Y, summing the relevant values. The resulting depiction shows the impact of parameter changes relative to baseline configuration defined by one of Xs values. Appendix presents graphs describing the impact of each parameter on player gains, fairness, and efficiency in games, depending on the language model that played the games. The graphs include confidence intervals at 95% confidence level. Figure 1 serve as example from which conclusions can be drawn about the impact of the parameters. Figure 1 (Right) shows that full information reduces efficiency for all models in bargaining games (and also in negotiation games, as shown by Figure 24 in Appendix E). While this may be counterintuitive at first, it might be the case that complete information prevents trade when efficient trade is possible.16 Figure 1 (Left) shows that sending textual messages increases efficiency in negotiation games (a trend that also appears in bargaining games, as shown by Figure 19 in Appendix E). In persuasion games, sending textual messages improves Alices gains for all models (as can be seen in Figure 31 in Appendix E), result observed by Apel et al. (2022) in language-based games involving humans. Figure 1: Right: the negative effect that full information has on efficiency in the bargaining game, depending on the player model. Left: the positive effect that sending textual messages has in negotiation games, depending on the player model."
        },
        {
            "title": "5 CONCLUSION",
            "content": "We present GLEE, framework for evaluating the behavior of Large Language Models (LLMs) in language-based economic games. The goal of GLEE is to provide comparative tool for assessing the performance of LLMs in various economic scenarios and enable their comparison to human players. We defined the game space within three main families of games: bargaining, negotiation, 15For instance, one could ask whether agents performance significantly differs in economic environments where inflation is high (translating into lower discount factors, in bargaining games). To evaluate such scenario, one can simulate games in which discount factor distribution fits these conditions, and re-evaluate agents performance with respect to the new distribution of configurations. 16Suppose, for example, that Alice values the product at 80$ and Bob values the product at 100$. If Alice sets price of 99$, and Bob knows Alices valuation, then Bob might reject the offer even though it is beneficial to him, since he feels that Alice should have made more decent offer that takes into consideration Bobs satisfaction as well. 10 and persuasion, and introduced metrics to measure player performance. We developed framework that allows for large-scale data collection from games between diverse LLMs and created an interface that facilitates the collection of data from games involving human players. Through this interface, we gathered data from 954K games between LLMs and from 3,405 games involving human players. The data is available for future research, which could advance the field of machine learning in language-based economic games, such as for predicting human decisions using artificial data and building more successful and human-like agents based on the metrics we define in GLEE."
        },
        {
            "title": "ETHICS STATEMENT",
            "content": "This paper aims to provide platform for experimenting with agents in language-based economic environments. Naturally, this line of research may have various societal and ethical implications, as we now discuss. First, studying the economic aspects of LLM-based agents has the potential to enhance the ability of agent designers to control and optimize the behavior of these agents. This capability can be utilized for variety of purposes, ranging from encouraging self-interested behavior at the expense of other participants in the environment (e.g., for maximizing revenue in competitive settings) to promoting efficient trade and fair behavior, or any combination of these sometimes non-aligned objectives. As this research increases the power of LLM-based agents in economic environments, it is essential to emphasize that with great power comes great responsibility. We call for the responsible and ethical use of these emerging capabilities to ensure they are leveraged for socially beneficial purposes rather than exploitative ones. Furthermore, our framework demonstrates the capability of collecting data from human players to understand the differences and similarities between LLMs and humans in economic environments. While this line of research has the potential for strong scientific contribution, particularly in the field of behavioral economics, it also raises several ethical considerations. The collection of human data must be conducted with careful regulation and adherence to clear ethical guidelines, such as those established in venues like ICLR. The authors declare that there are no violations of the ICLR ethics code in our study. The entire process of data collection from human participants is elaborated in 3.2. In addition to the challenges associated with the collection of human data, enhancing our understanding of LLMs from the lens of human behavior carries inherent risks. For instance, this research could enhance our ability to design LLM agents that are difficult to distinguish from real humans. Such capabilities could be misused for malicious purposes, including deception or manipulation. While the answer to whether these capabilities could be used for harmful causes is likely yes, we believe that the benefits of pursuing this line of research outweigh the risks when balanced with proper regulations. We advocate for pushing research forward while ensuring that any new technologies are accompanied by safeguards to prevent harmful usage, particularly when human-like LLMs are involved. Our proposed framework can make these research directions more accessible to researchers from the ML community and beyond, thereby encouraging broader understanding of LLM behavior in economic contexts. However, as such accessibility increases, it is crucial to maintain ethical oversight and foster an open dialogue on potential misuse. We encourage researchers to use our framework with full transparency and careful attention to potential misuse and negative consequences."
        },
        {
            "title": "ACKNOWLEDGEMENTS",
            "content": "R. Reichart and E. Shapira have been partially supported by VATAT grant on data science."
        },
        {
            "title": "REFERENCES",
            "content": "Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schonherr, and Mario Fritz. Llmdeliberation: Evaluating llms with interactive multi-agent negotiation games. arXiv preprint arXiv:2309.17234, 2023. 11 Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. Playing repeated games with large language models. arXiv preprint arXiv:2305.16867, 2023. George Akerlof. The market for lemons: Quality uncertainty and the market mechanism. In Uncertainty in economics, pp. 235251. Elsevier, 1978. Reut Apel, Ido Erev, Roi Reichart, and Moshe Tennenholtz. Predicting decisions in language based persuasion games. Journal of Artificial Intelligence Research, 73:10251091, 2022. Robert Aumann and Sergiu Hart. Long cheap talk. Econometrica, 71(6):16191660, 2003. Omer Ben-Porat, Itay Rosenberg, and Moshe Tennenholtz. Convergence of learning dynamics in information retrieval games. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 17801787, 2019. Dirk Bergemann and Karl Schlag. Robust monopoly pricing. Journal of Economic Theory, 146(6): 25272543, 2011. James Best and Daniel Quigley. Persuasion for the long run. Journal of Political Economy, 132(5): 17401791, 2024. Federico Bianchi, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky, and James Zou. How well can llms negotiate? negotiationarena platform and analysis. arXiv preprint arXiv:2402.05863, 2024. Daniel L. Chen, Martin Schonger, and Chris Wickens. otreean open-source platform for laboratory, online, and field experiments. Journal of Behavioral and Experimental Finance, 9:88 ISSN 2214-6350. doi: https://doi.org/10.1016/j.jbef.2015.12.001. URL https: 97, 2016. //www.sciencedirect.com/science/article/pii/S2214635016000101. Vincent Crawford and Joel Sobel. Strategic information transmission. Econometrica: Journal of the Econometric Society, pp. 14311451, 1982. Yuan Deng, Vahab Mirrokni, Renato Paes Leme, Hanrui Zhang, and Song Zuo. Llms at the bargaining table. In Agentic Markets Workshop at ICML 2024, 2024. Joseph Farrell and Matthew Rabin. Cheap talk. Journal of Economic Perspectives, 10(3):103 doi: 10.1257/jep.10.3.103. URL https://www.aeaweb.org/ 118, September 1996. articles?id=10.1257/jep.10.3.103. Xidong Feng, Yicheng Luo, Ziyan Wang, Hongrui Tang, Mengyue Yang, Kun Shao, David Mguni, Yali Du, and Jun Wang. Chessgpt: Bridging policy learning and language modeling. Advances in Neural Information Processing Systems, 36, 2024. Google DeepMind Gemini Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context, 2024. URL https://arxiv.org/abs/2403.05530. Shangmin Guo, Haoran Bu, Haochuan Wang, Yi Ren, Dianbo Sui, Yuming Shang, and Siting Lu. Economics arena for large language models. arXiv preprint arXiv:2401.01735, 2024. Milton Harris and Artur Raviv. theory of monopoly pricing schemes with demand uncertainty. The American Economic Review, 71(3):347365, 1981. John Horton. Large language models as simulated economic agents: What can we learn from homo silicus? Technical report, National Bureau of Economic Research, 2023. Jiri Hron, Karl Krauth, Michael Jordan, Niki Kilbertus, and Sarah Dean. Modeling content creator incentives on algorithm-curated platforms. arXiv preprint arXiv:2206.13102, 2022. Emir Kamenica and Matthew Gentzkow. Bayesian persuasion. American Economic Review, 101 (6):25902615, 2011. Jeong-Yoo Kim. Cheap talk and reputation in repeated pretrial negotiation. The RAND Journal of Economics, pp. 787802, 1996. 12 Oren Kurland and Moshe Tennenholtz. Competitive search. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 22, pp. 28382849, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450387323. doi: 10.1145/3477495.3532771. URL https://doi.org/10.1145/ 3477495.3532771. Kausik Lakkaraju, Sara Jones, Sai Krishna Revanth Vuruma, Vishal Pallagani, Bharath Muppasani, and Biplav Srivastava. Llms for financial advisement: fairness and efficacy study in personal decision making. In Proceedings of the Fourth ACM International Conference on AI in Finance, pp. 100107, 2023. Chuanhao Li, Runhan Yang, Tiankai Li, Milad Bafarassat, Kourosh Sharifi, Dirk Bergemann, and Zhuoran Yang. Stride: tool-assisted llm agent framework for strategic and interactive decisionmaking, 2024. URL https://arxiv.org/abs/2405.16376. Omer Madmon, Idan Pipano, Itamar Reinman, and Moshe Tennenholtz. The search for staarXiv preprint bility: Learning dynamics of strategic publishers with initial documents. arXiv:2305.16695, 2023. Omer Madmon, Idan Pipano, Itamar Reinman, and Moshe Tennenholtz. On the convergence of no-regret dynamics in information retrieval games with proportional ranking functions. arXiv preprint arXiv:2405.11517, 2024. R. Preston McAfee. dominant strategy double auction. Journal of Economic Theory, 56(2): 434450, 1992. ISSN 10957235. doi: 10.1016/0022-0531(92)90091-U. Meta. The llama 3 herd of models, 2024. URL https://arxiv.org/abs/2407.21783. Roger Myerson and Mark Satterthwaite. Efficient mechanisms for bilateral trading. Journal of economic theory, 29(2):265281, 1983. Haya Nachimovsky, Moshe Tennenholtz, Fiana Raiber, and Oren Kurland. Ranking-incentivized document manipulations for multiple queries. In Proceedings of the 2024 ACM SIGIR International Conference on Theory of Information Retrieval, pp. 6170, 2024. Sean Noh and Ho-Chun Herbert Chang. Llms with personalities in multi-issue negotiation games. arXiv preprint arXiv:2405.05248, 2024. Maya Raifer, Guy Rotman, Reut Apel, Moshe Tennenholtz, and Roi Reichart. Designing an automatic agent for repeated languagebased persuasion games. Transactions of the Association for Computational Linguistics, 10:307324, 2022. Nimrod Raifer, Fiana Raiber, Moshe Tennenholtz, and Oren Kurland. Information retrieval meets game theory: The ranking competition between documents authors. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 465474, 2017. Narun Krishnamurthi Raman, Taylor Lundy, Samuel Joseph Amouyal, Yoav Levine, Kevin LeytonBrown, and Moshe Tennenholtz. Steer: Assessing the economic rationality of large language models. In Forty-first International Conference on Machine Learning, 2024. John Riley and Richard Zeckhauser. Optimal selling strategies: When to haggle, when to hold firm. The Quarterly Journal of Economics, 98(2):267289, 1983. Ariel Rubinstein. Perfect equilibrium in bargaining model. Econometrica: Journal of the Econometric Society, pp. 97109, 1982. Ariel Rubinstein. bargaining model with incomplete information about time preferences. Econometrica: Journal of the Econometric Society, pp. 11511172, 1985. Eilam Shapira, Reut Apel, Moshe Tennenholtz, and Roi Reichart. Human choice prediction in language-based persuasion games: Simulation-based off-policy evaluation. arXiv preprint arXiv:2305.10361, 2023. 13 Eilam Shapira, Omer Madmon, Roi Reichart, and Moshe Tennenholtz. Can llms replace economic choice prediction labs? the case of language-based persuasion games. arXiv preprint arXiv:2401.17435, 2024. Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Justin Sun, Xibin Gao, and Yi Zhang. Bootstrapping llm-based task-oriented dialogue agents via self-talk. arXiv preprint arXiv:2401.05033, 2024. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023. Tian Xia, Zhiwei He, Tong Ren, Yibo Miao, Zhuosheng Zhang, Yang Yang, and Rui Wang. Measuring bargaining abilities of llms: benchmark and buyer-enhancement method. arXiv preprint arXiv:2402.15813, 2024. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhifang Guo, and Zhihao Fan. Qwen2 technical report, 2024. URL https://arxiv.org/abs/2407.10671. Jian-Qiao Zhu, Joshua Peterson, Benjamin Enke, and Thomas Griffiths. Capturing the complexity of human strategic decision-making with machine learning. arXiv preprint arXiv:2408.07865, 2024."
        },
        {
            "title": "A GAME FAMILIES THROUGH THE LENS OF ECONOMIC LITERATURE",
            "content": "In this section, we discuss the economic literature related to the three game families considered in this paper, and review some known theoretical results. Bargining As mentioned in 2, the standard bargaining model of Rubinstein (1982) consists of two players, Alice and Bob, engaging in alternating offers for finite horizon (T = ) with commonly known discount factors δA, δB. Our parameterization considers several additional degrees of freedom, such as finite vs. infinite time horizon, complete vs. incomplete information, and free language messages vs. structured and concise messages. In the standard model, Rubinstein (1982) showed that in the unique subgame-perfect equilibrium an agreement is reached in the first stage (i.e., utilities are not discounted), and the share of Alice is given by p, where = 1δB .17 1δAδB The case of finite horizon can be solved using backward induction, and typically results in different outcome compared to the infinite case. As grows, the equilibrium outcome approaches the one of the infinite case. Extensions to incomplete information regarding the opponents discount factor are typically more challenging, and some of them are studied in the literature, e.g. Rubinstein (1985). Negotiation In negotiation game, Alice and Bob negotiate over the price of an indivisible good. The negotiation game differs from the bargaining games in several key aspects: 1. Negotiation involves an indivisible product (e.g., Alices product), while bargaining focuses on dividing divisible resource, such as money. 2. In negotiation, Alice and Bob may have different subjective valuations of the product, whereas in bargaining, both parties value the divisible resource similarly. 3. Negotiation has no discounting, so the utility remains constant over time. In bargaining, delays reduce the total value, encouraging faster agreement. If the seller is uncertain regarding the buyers valuation but has prior belief distribution, classical result by Harris & Raviv (1981) and Riley & Zeckhauser (1983) states that it is always optimal to sell the product at fixed price. In contrast, if the seller does not have prior belief over the buyers valuation, and instead aims to minimize regret, then an optional pricing policy will be to randomly choose price from carefully chosen distribution (Bergemann & Schlag, 2011). Persuasion Our persuasion game follows the structure of cheap talk game (Crawford & Sobel, 1982; Farrell & Rabin, 1996), where the sender (Alice) cannot commit to signaling policy in advance, unlike in Bayesian persuasion models (Kamenica & Gentzkow, 2011). Under the particular payoff structure considered in our persuasion game, it is well-known that the cheap-talk game only admits babbling equilibrium, i.e., an equilibrium in which all information is kept hidden (this is due to the strong misalignment of interests between the two players). In contrast, if the seller can commit to signaling policy at the outset, as in Bayesian persuasion, then there exists subgameperfect equilibrium in which the seller commits to the following policy: When the product is of high quality, the seller recommends buying the product with probability 1. When the product is of low quality, then the seller recommends with probability = min{ 1p (v 1), 1}. This policy is also incentive-compatible, in the sense that the buyer always buys the product when the seller recommends buying.18 While the long-living buyer case is well-studied in the economic literature, such games often admit multiple equilibria, which makes the games difficult to analyze and predict (Kim, 1996; Aumann & Hart, 2003). As for the case of myopic buyers, Best & Quigley (2024) draws connection between the repeated cheap talk game and the case of one-shot Bayesian persuasion, leading to an elegant analytical solution of the repeated game. Intuitively, the repetitive nature of the game induces reputation effect, which plays similar role to the commitment power in standard one-shot Bayesian persuasion. 17A subgame-perfect equilibrium is strategy profile in which every player responds optimally in every hypothetical subgame of the game, including off-path scenarios that are not reached in practice. This solution concept can be seen as capturing higher level of rationality compared to the alternative of Nash equilibrium. 18In fact, the probability of lying is determined such that the buyer is indifferent upon receiving recommendation, taking into account his belief updating, which relies on using Bayess law and knowing the sellers committed policy."
        },
        {
            "title": "B DATA COLLECTION SYSTEM",
            "content": "In this appendix, we present an example of the conversation structures with the language models used for data collection in GLEE. The example is from bargaining game, but the systems operating principle is the same in negotiation and persuasion games as well. The prompts are divided into two types: (1) instructions and guidelines sent to the language model as system message, and (2) game management messages sent to the language model as user message. The language model performed its action, which was documented in the prompt as an assistant message. The system message begins with precise game instructions, which are constructed at the start of the game using the parameters that define the configuration. This is followed by guideline specifying the format in which the LLM is required to respond. Each time the language model is required to make decision (of any type), the language model receives message containing all the information that has accumulated since its previous turn. This information appears as system message and sometimes includes text written by the language model that played the second player. Throughout the appendix, the system prompt (or parts of it) that Alice received are highlighted in red. Game management messages Alice received are shown in purple, and her response is shown in magenta. The system prompt that Bob received is highlighted in blue. Game management messages Bob received are shown in teal, and his response is shown in cyan. Instructions to Alice: Lets play game. In this game, there are two players. You are playing as Alice. You and Bob need to divide 1,000$ between you. In each round of the game, one of the players will make proposal for division and can describe their proposal in few words. The other player will decide whether to accept the offer and finish the game, or to proceed to the next round, in which they will be the one making the proposal. We will relay messages between you and Bob. Beware of inflation! With each passing round, the money is worth 0% less for you. For Bob, the money is worth 10% less. You have 10 rounds to divide the money, or both of you will get nothing! Instructions to Bob: Lets play game. In this game, there are two players. You are playing as Bob. You and Alice need to divide 1,000$ between you. In each round of the game, one of the players will make proposal for division and can describe their proposal in few words. The other player will decide whether to accept the offer and finish the game, or to proceed to the next round, in which they will be the one making the proposal. We will relay messages between you and Alice. Beware of inflation! With each passing round, the money is worth 10% less for you. For Alice, the money is worth 0% less. You have 10 rounds to divide the money, or both of you will get nothing! Alice turn. Alice got this message from the system: Round 1 Send your offer to divide $1,000 and message to Bob. Alice guideline: Send your offer to divide 1,000$ and the message you attached in the JSON format: {alice gain: The part that you will receive in your offer, bob gain: The part that Bob will receive in your offer, message: The message you pass to Bob} Alices response: json {alice gain: 900, bob gain: 100, message: Lets start fair. Ill take the bigger share, but you get something too.} 16 Bob turn. Bob got this message from the system: Round 1 Alices offer: # Alices message: Lets start fair. Ill take the bigger share, but you get something too. # Bob gain: 100 # Alice gain: 900 Do you accept this offer? Bob guideline: Answer with {decision: accept} or {decision: reject} Bobs response: json {decision: reject} Bob turn. Bob got this message from the system: You have chosen to reject Alices offer from round 1. Round 2 Send your offer to divide $1,000 and message to Alice. Bob guideline: Send your offer to divide 1,000$ and the message you attached in the JSON format: {bob gain: The part that you will receive in your offer, alice gain: The part that Alice will receive in your offer, message: The message you pass to Alice} Bobs response: json {bob gain: 500, alice gain: 500, message: Lets split it evenly. Its the fairest way to start.} Alice turn. Alice got this message from the system: Bob rejected your offer from round 1. Round 2 Due to inflation, the money Bob gains is worth 10% less than in the first round. The money you gains is worth the same as in the first round. Bobs offer: # Bobs message: Lets split it evenly. Its the fairest way to start. # Alice gain: 500 # Bob gain: 500 Do you accept this offer? Alice guideline: Answer with {decision: accept} or {decision: reject} Alices response: json {decision: accept} The game is over."
        },
        {
            "title": "C DATA COLLECTION FROM HUMAN PLAYERS",
            "content": "This appendix provides additional information on the human data collection interface described in 3.2, which facilitates data collection from GLEE games played between humans and LLMs. C.1 SCREENSHOTS OF THE DATA COLLECTION INTERFACE General application structure The structure of the application and the games consists of fixed parts and parts that vary between different game families. Each game starts with screen where the player enters their name, followed by an instruction screen (Figure 2 in bargaining, Figure 6 in negotiation, and Figure 10 in persuasion). The instructions themselves can change depending on the type of game and the parameters of the game. On the instruction screen, there is hidden prompt to enter code word in the text box below, which is designed to filter out unfocused participants. If the player fails this test, they are taken to screen that informs them of their failure. Otherwise, the game itself begins. In each round, both the human player and the LLM player perform an action, with the order depending on the game and configuration. An action could involve sending an offer to the other player (figure 3 in bargaining games, Figure 7 in negotiation games and Figure 11 in Persuasion games) or responding to the other players offer (for instance, Figure 4 in bargaining games, Figure 8 in negotiation games and Figure 12 in persuasion games). After both players have completed their actions, the human player is taken to response screen (Figure 5), where he sees the decision of the LLM player. Afterward, if the game is still not over, the human player continues for another round. Once the game is finished, the player is taken to quiz screen where they must answer question related to the technical details of the game (Figure 9). If the human answer correctly, they are directed to the final screen (Figure 13), where they receive code to enter on the mTurk website. If the player fails the final quiz, they do not receive completion code and are taken to screen that informs them of their failure in the quiz. In this case, we erase the game from our database. C.1.1 BARGAINING GAMES SCREENSHOTS Figure 2: An example of an instruction screen shown to human player at the start of bargaining game. Figure 3: An example of proposition screen shown to human player during his first turn in bargaining game. Figure 4: An example of decision screen shown to human player during his second turn in Bargaining game. Figure 5: An example of response screen shown to human players during his second turn in Bargaining game. 19 C.1.2 NEGOTIATION GAMES SCREENSHOTS Figure 6: An example of an instruction screen shown to human sellers at the start of Negotiation game. Figure 7: An example of proposition screen shown to human sellers during his first turn in Negotiation game. 20 Figure 8: An example of decision screen shown to human buyers during his first turn in Negotiation game. Figure 9: An example of final quiz screen shown to human sellers at the end of Negotiation game. C.1.3 PERSUASION GAMES SCREENSHOTS Figure 10: An example of an instruction screen shown to human sellers at the start of Persuasion game. 21 Figure 11: An example of proposition screen shown to human sellers during his first turn in Persuasion game. Figure 12: An example of decision screen shown to human buyers during his first turn in Persuasion game. Figure 13: An example of game over screen shown to human players at the end of Persuasion game. 22 C.2 SELECTION OF CONFIGURATIONS FOR HUMAN DATA COLLECTION In this appendix, we describe the method used to select which configurations human players would play and how many times each configuration would be played. Each configuration is defined by both the game parameters and the role of the human player (Alice or Bob). For each family of games, we arbitrarily defined one configuration, which we referred to as the main configuration. This configuration contains the parameters that we deemed most interesting. For every main configuration, we collected data for both possible roles of the human player (Alice or Bob). In persuasion games, we defined two main configurations: one for recurring buyers and one for manipulated buyers, due to the significant theoretical differences arising from this parameter. We collected the largest amount of data from the main configurations to allow for more in-depth follow-up research. Configurations that were identical to one of the main configurations except for one parameter19 were called variants of the main configuration. We collected data for all of these configurations as well. Additionally, we randomly sampled 5% of the other configurations and collected data from them as well. These configurations were referred to as random configurations. Due to the desire to allocate the data collection budget to complex games, we did not collect any data from games in which the human player was required to play at most one round (single-round bargaining games and persuasion games in which the human player is manipulated buyer). For each category, we determined the number of games we wanted to collect from each configuration belonging to it. This decision was made based on budgetary considerations. In persuasion games, we were able to collect fewer games from each configuration due to the fact that these games take longer to complete (and therefore, the payment players received for participating in them was higher). Table 5 describes the number of configurations that belonged to each category for each game and the minimum number of games we collected from each category. Bargaining Negotiation Persuasion Type # config. # games # config. # games # config. # games main variant random 2 40 50 25 15 2 22 36 50 25 15 3 30 24 30 8 5 Table 5: The number of configurations belonging to each category for each game family, as well as the number of human players who played each configuration within each category. 19In bargaining games, we defined change in both players discount factors as change in one parameter 20Since the games were played in parallel, for some configurations we collected more games than required. For 113 configurations, we collected one more game than required; for 4 configurations, we collected 2 more games than required; and for one configuration, we collected 3 more games than required. 23 C.3 ATTENTION CHECKS FOR HUMAN PLAYERS In this appendix, we describe the two attention tests that human players were required to complete. The purpose of these tests was to ensure that the human players stayed focused on the game and made conscious decisions, rather than random choices to finish the game as quickly as possible. The players were aware that their attention would be tested during the game, and they knew that they would not be paid for the task if they failed these tests. Out of the 4,652 players who started the game, 1,247 players (representing 26.8% of those who began the game) failed one of the tests and were not included in the final dataset. The first test appeared on the instruction screen. Toward the end of the instructions, line requested players to write the code word sdkot in text box that appeared at the end of the instructions phase. Players who did not write this word were immediately disqualified and did not start the game, as they did not carefully read the instructions. total of 412 players, representing 8.9% of those who began the game, failed this test. The second test appeared at the end of the game. The human players were asked basic question that depended on the family of the game they played. They were required to select the correct answer from four possible options. Players who participated in bargaining game were asked about the inflation rate in their game (499 players, representing 22.7% of respondents, failed this question and were excluded from the dataset). Players who participated in negotiation game were asked about the value of the product for them (68 players, representing 12.3% of respondents, failed this question and were excluded from the dataset). Players who participated in persuasion game were asked about the price of products in the game (268 players, representing 18% of respondents, failed this question and were excluded from the dataset). In total, 835 players, representing 19.7% of respondents, failed the final question and were excluded from the dataset."
        },
        {
            "title": "D FORMULAS USED TO TRAIN REGRESSION MODELS",
            "content": "This appendix describes how the regression models used to analyze the data in 4 and Appendix were built. The regression models are train to predict specific metric based on the parameters that define the configuration. To prevent the regression models from learning relationships directly from the configuration settings themselves, all parameters are treated as categorical variables. The features included in the regression models are classify according to different levels of complexity, with each level describing the number of interactions between the parameters defining the feature. The following code demonstrates the creation of the set of the features. The : symbol represents an interaction between the parameters used to create the features. 1 features += [p for in game_parameters] 2 features += [\"alice_model\", \"bob_model\"] 3 features += [\"alice_model:bob_model\"] 4 features += [f\"{p}:alice_model\" for in game_parameters] 5 features += [f\"{p}:bob_model\" for in game_parameters] 6 features += [f\"({p1}:{p2})\" for p1 in game_parameters for p2 in game_parameters if p1 != p2] 7 features += [f\"({p1}:{p2}):alice_model\" for p1 in game_parameters for p2 in game_parameters if p1 != p2] 8 features += [f\"({p1}:{p2}):bob_model\" for p1 in game_parameters for p2 in game_parameters if p1 != p2] 9 features = \"+\".join(features) 10 formula = f\"{metric}{features}\" After constructing the feature matrix, identical features may emerge21. We are remove the more complex features from the model to allow us to measure the true contribution of each individual feature. The resulting formula is used to train the regression models. 21for example, in case where Language Model A, playing as Alice, only played games with Language Model B, playing as Bob. In such case, the feature Is M=100 and Alice played by Language Model and the feature Is M=100, Alice played by Language Model A, and Bob played by Language Model will always be identical."
        },
        {
            "title": "E GRAPHS",
            "content": "This appendix presents graphs depicting the effect of each parameter on player gains, fairness, and efficiency in the games, depending on the language model that played the games. The graphs include 95% confidence intervals.22 The impact of each parameter is shown in separate figure, which contains sub-graphs illustrating the effect of changing the parameters value on self-gain, efficiency, and fairness for each language model, both for Alice and Bob. Table 6 serves as key for quick navigation to each of the figures. Bargaining Negotiation Persuasion Figure 20 Figure 21 Figure 14 Figure FA δA δB FB Figure 16 Figure 22 Figure 17 CI Figure 18 CI MA Figure 19 MA Figure 25 Messages type Figure 23 Buyer type Figure 24 CI Figure 26 Figure 27 Figure 28 Figure 29 Figure 30 Figure 31 Table 6: The table summarizes the various figures in the appendix and serves as table of contents for easy access to them. Each figure presents the impact of changing parameter values on the different metrics. CI = Complete Information. MA = Textual messages allowed. 22The confidence intervals presented for human behavior are significantly larger compared to those for the language models, as the amount of data collected from humans is smaller by three orders of magnitude. 26 E.1 BARGAINING Figure 14: The effect of the change in parameter δA on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in bargaining games. The change is measured relative to the scenario where δA is 0.8 (i.e. = (Metric δA = ewV alue) - (Metric δA = 0.8)), and is presented for each of the models that played Alice (left column) and Bob (right column). 27 Figure 15: The effect of the change in parameter δB on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in bargaining games. The change is measured relative to the scenario where δB is 0.8 (i.e. = (Metric δB = ewV alue) - (Metric δB = 0.8)), and is presented for each of the models that played Alice (left column) and Bob (right column). Figure 16: The effect of the change in parameter on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in bargaining games. The change is measured relative to the scenario where is 100 (i.e. = (Metric = ewV alue) - (Metric = 100)), and is presented for each of the models that played Alice (left column) and Bob (right column). 29 Figure 17: The effect of the change in parameter on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in bargaining games. The change is measured relative to the scenario where is 12 (i.e. = (Metric = ewV alue) - (Metric = 12)), and is presented for each of the models that played Alice (left column) and Bob (right column). 30 Figure 18: The effect of the change in parameter Complete Information on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in bargaining games. The change is measured relative to the scenario where Complete Information is alse (i.e. = (Metric Complete Information = ewV alue) - (Metric Complete Information = alse)), and is presented for each of the models that played Alice (left column) and Bob (right column). Figure 19: The effect of the change in parameter Messages Allowed on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in bargaining games. The change is measured relative to the scenario where Messages Allowed is alse (i.e. = (Metric Messages Allowed = ewV alue) - (Metric Messages Allowed = alse)), and is presented for each of the models that played Alice (left column) and Bob (right column). 32 E.2 NEGOTIATION Figure 20: The effect of the change in parameter FA on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in negotiation games. The change is measured relative to the scenario where FA is 0.8 (i.e. = (Metric FA = ewV alue) - (Metric FA = 0.8)), and is presented for each of the models that played Alice (left column) and Bob (right column). 33 Figure 21: The effect of the change in parameter FB on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in negotiation games. The change is measured relative to the scenario where FB is 0.8 (i.e. = (Metric FB = ewV alue) - (Metric FB = 0.8)), and is presented for each of the models that played Alice (left column) and Bob (right column). 34 Figure 22: The effect of the change in parameter on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in negotiation games. The change is measured relative to the scenario where is 100.0 (i.e. = (Metric = ewV alue) - (Metric = 100.0)), and is presented for each of the models that played Alice (left column) and Bob (right column). 35 Figure 23: The effect of the change in parameter on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in negotiation games. The change is measured relative to the scenario where is 1 (i.e. = (Metric = ewV alue) - (Metric = 1)), and is presented for each of the models that played Alice (left column) and Bob (right column). 36 Figure 24: The effect of the change in parameter Complete Information on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in negotiation games. The change is measured relative to the scenario where Complete Information is alse (i.e. = (Metric Complete Information = ewV alue) - (Metric Complete Information = alse)), and is presented for each of the models that played Alice (left column) and Bob (right column). 37 Figure 25: The effect of the change in parameter Messages Allowed on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in negotiation games. The change is measured relative to the scenario where Messages Allowed is alse (i.e. = (Metric Messages Allowed = ewV alue) - (Metric Messages Allowed = alse)), and is presented for each of the models that played Alice (left column) and Bob (right column). 38 E.3 PERSUASION Figure 26: The effect of the change in parameter on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in persuasion games. The change is measured relative to the scenario where is 0.333333333 (i.e. = (Metric = ewV alue) - (Metric = 0.333333333)), and is presented for each of the models that played Alice (left column) and Bob (right column). Figure 27: The effect of the change in parameter on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in persuasion games. The change is measured relative to the scenario where is 1.2 (i.e. = (Metric = ewV alue) - (Metric = 1.2)), and is presented for each of the models that played Alice (left column) and Bob (right column). 40 Figure 28: The effect of the change in parameter on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in persuasion games. The change is measured relative to the scenario where is 100 (i.e. = (Metric = ewV alue) - (Metric = 100)), and is presented for each of the models that played Alice (left column) and Bob (right column). 41 Figure 29: The effect of the change in parameter Buyer is Myopic on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in persuasion games. The change is measured relative to the scenario where Buyer is Myopic is alse (i.e. = (Metric Buyer is Myopic = ewV alue) - (Metric Buyer is Myopic = alse)), and is presented for each of the models that played Alice (left column) and Bob (right column). Figure 30: The effect of the change in parameter Complete Information on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in persuasion games. The change is measured relative to the scenario where Complete Information is alse (i.e. = (Metric Complete Information = ewV alue) - (Metric Complete Information = alse)), and is presented for each of the models that played Alice (left column) and Bob (right column). 43 Figure 31: The effect of the change in parameter Message Type on the metrics Self Gain (top row), Efficiency (middle row), and Fairness (bottom row), in persuasion games. The change is measured relative to the scenario where Message Type is binary (i.e. = (Metric Message Type = ewV alue) - (Metric Message Type = binary)), and is presented for each of the models that played Alice (left column) and Bob (right column)."
        }
    ],
    "affiliations": [
        "Technion - Israel Institute of Technology",
        "Tel Aviv University"
    ]
}