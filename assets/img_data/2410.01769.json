[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01769/x1.png",
                "caption": "Figure 1:An illustration ofgeneralization valley, where the reliance on non-generalizable behaviors first increases and then decreases;\nandcritical complexity shift, where the peak of the valley shifts rightward as model size increases.",
                "position": 154
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01769/x2.png",
                "caption": "Figure 2:Left: Anchor tasks.\nThese tasks form the core of our benchmark, providing a structured set of challenges\nacross varying time complexities.Right: Probe tasks.\nThese tasks are used to evaluate the level of complexity that LLMs adopt to solve them.",
                "position": 360
            },
            {
                "img": "https://arxiv.org/html/2410.01769/x3.png",
                "caption": "Figure 3:Pipeline for generating ID and OOD dataset for a given task, tailored to each LLM.",
                "position": 490
            },
            {
                "img": "https://arxiv.org/html/2410.01769/x4.png",
                "caption": "Figure 4:An example of probability distribution of ID elements collected by querying Mistral 7B v0.3 on the task ofFind Longest Increasing Subsequence. The histogram shows the most frequent values with probabilities adding up to 90% (top-p=0.9).",
                "position": 522
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01769/x5.png",
                "caption": "Figure 5:ID/OOD performance of Qwen 1.5 family across five complexity levels.",
                "position": 566
            },
            {
                "img": "https://arxiv.org/html/2410.01769/x6.png",
                "caption": "Figure 6:ID and OOD accuracy and performance gap curves for Llama-3.2-3B, Llama-3-8B,\nGemma-2-9B, Claude-3-Sonnet, GPT-4o, and o1-mini.\nA significant drop in OOD accuracy is observed at the modelsâ€™ critical complexity, indicating\na sudden decline in generalization ability.",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2410.01769/x7.png",
                "caption": "Figure 7:Critical complexity shifts to the right as model size increases for open-sourced LLMs,\nindicating enhanced generalization capacity.",
                "position": 593
            },
            {
                "img": "https://arxiv.org/html/2410.01769/x8.png",
                "caption": "Figure 8:Critical complexity shifts for closed-source models:\nSonnet shows higher critical complexity than Haiku, while GPT-4o-mini deviates from this trend.",
                "position": 608
            },
            {
                "img": "https://arxiv.org/html/2410.01769/x9.png",
                "caption": "Figure 9:Illustration of correlations between task complexity and OOD accuracy for three probe tasks.",
                "position": 974
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CDetails of different complexity tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01769/x10.png",
                "caption": "Figure 10:Comparison between o1-mini and Llama-3.1-405B in solving the longest increasing subsequence problem. o1-mini demonstrates a more direct and efficient approach, adjusting the sequence dynamically with minimal steps, while Llama-3.1 employs a complex dynamic programming method involving array tracking and backtracking to reach the solution.",
                "position": 2555
            },
            {
                "img": "https://arxiv.org/html/2410.01769/x11.png",
                "caption": "Figure 11:Evaluation of o1-mini on OOD data for SubsetSum and TSP tasks. The model exhibits two distinct types of implicit reasoning, each occurring in a significant portion of cases.",
                "position": 2563
            }
        ]
    },
    {
        "header": "Appendix DA Glimpse of how o1-mini does reasoning",
        "images": []
    }
]