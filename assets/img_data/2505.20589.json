[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20589/x1.png",
                "caption": "Figure 1:High-level architecture ofProt2Tokenhighlighting multi-task capability in protein-level, residue-level, and protein-protein level tasks.",
                "position": 145
            }
        ]
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20589/x2.png",
                "caption": "Figure 2:Detailed Architecture ofProt2TokenHighlighting Multi-Task Capability. This diagram shows theProt2Tokencomponents: a bidirectional Protein encoder and an optional Chemical Encoder, a Fusion block part, and an autoregressive Decoder guided by Task Token Embeddings for various prediction tasks (examples listed). This illustrates the framework‚Äôs potential for simultaneous multi-task learning; however, practical training of this work only focused on combinations of fewer tasks due to computational costs, demonstrating the principle.",
                "position": 234
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x3.png",
                "caption": "Figure 3:Prot2Tokenconverts heterogeneous labels into uniform sequences: examples illustrate the five tokenization categories‚Äî(i) sequence-to-sequence, (ii) classification (multi-class/ multi-label), (iii) regression, (iv) binding-site indexing, and (v) other composite outputs such as PTM‚Äîhighlighting the framework‚Äôs task-agnostic decoding format.",
                "position": 296
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20589/x4.png",
                "caption": "Figure 4:Randomly selected test set samples where our model achieved a TM-score above 0.90 versusAF2high-pLDDT predictions. On average, each sample was predicted and converted in approximately 1 second using an Nvidia A100 GPU.",
                "position": 614
            }
        ]
    },
    {
        "header": "4Discussion",
        "images": []
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Broader impact",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20589/x5.png",
                "caption": "Figure 5:Task-token prompting and loss masking in theProt2Tokendecoder. (A) Standard decoding starts with a<BOS>token and predicts label tokens, computing loss over all positions. (B) Prompted decoding inserts a task token (T1subscriptùëá1T_{1}italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT) before labels; this token is zero-weighted in the loss, guiding the model without affecting training error.",
                "position": 1679
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x6.png",
                "caption": "Figure 6:Tokenisation workflow for protein‚Äìprotein binding sites.\nA distance cut-off is applied to a residue‚Äìresidue distance matrix derived from the PDB complex to flag contacting residues. Rows with at least one contact are collapsed into a sorted list of residue indices, which becomes the target token sequence.",
                "position": 2386
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x7.png",
                "caption": "Figure 7:UMAP visualization of unique kinase sequences on the original and fine-tuned checkpoints ofESM2-650m.",
                "position": 2921
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x8.png",
                "caption": "Figure 8:t-SNE visualization of unique kinase sequences on the original and fine-tuned checkpoints ofESM2-650m.",
                "position": 2924
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x9.png",
                "caption": "Figure 9:Illustration of self-supervised pre-training tasks designed for the decoder. For each amino acid (e.g.,S, T, P, M, L), the model is trained to predict the positions of its occurrences within a given protein sequence. Highlighted residues are the targets, and the output is a list of their corresponding indices. This enables the decoder to learn position-aware amino acid representations in a label-free manner.",
                "position": 3066
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x10.png",
                "caption": "Figure 10:Distribution of phosphorylation-site indices in the training set (n = 11,449 sites across 5,694 peptides). Only residues at positions‚â§\\leq‚â§2048 are shown; 176 rarer sites at higher indices were excluded. Each bar corresponds to a single residue position (bin width = 1).",
                "position": 3115
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x11.png",
                "caption": "Figure 11:Distribution of protein‚Äìligand binding-site indices aggregated across all 41 ligand classes in the training set. Bars represent individual residue positions (bin width=1). Sites located beyond residue 2048 (< 2 % of all annotated positions) were excluded for clarity.",
                "position": 3119
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x12.png",
                "caption": "Figure 12:Jointly training protein‚Äìligand binding-site across 41 types of ligands by representing ligands with task tokens.",
                "position": 3140
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x13.png",
                "caption": "Figure 13:Average of F1values for all 41 ligands during the training based on the validation sets. The performance peaked at epoch 30.",
                "position": 3583
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x14.png",
                "caption": "Figure 14:Randomly selected test set samples where the model achieved a TM-score lower than 0.75.",
                "position": 3804
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x15.png",
                "caption": "Figure 15:Validation perplexity curve for sequence-to-3D structure prediction. The continued decrease in perplexity throughout training indicates that the model has not yet reached convergence, and additional training may yield further gains in predictive accuracy.",
                "position": 3857
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x16.png",
                "caption": "Figure 16:Comparison of protein representations generated byProt2Tokenand the base encoderESM2-650m. The t-SNE visualizations display protein embeddings for CATH structural classes, architecture, and topology, as well as clustering for deaminase families and kinase groups. Colors correspond to the known classes or families for each category.",
                "position": 3860
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x17.png",
                "caption": "Figure 17:Global Relationships indicate that general biochemical features shared among many ligands have been captured. Local Relationships reflect the successful capture of biochemical properties between specific ligands and their closely related counterparts. No Relationships indicate that the biochemical properties were not captured at all.",
                "position": 4006
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x18.png",
                "caption": "Figure 18:Clustering results of embeddings on top 28 ligands based on F1score.",
                "position": 4427
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x19.png",
                "caption": "Figure 19:Clustering results of features on the 28 selected ligands.",
                "position": 4430
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x20.png",
                "caption": "Figure 20:Clustering results of embeddings on all 41 ligands based on F1score.",
                "position": 4433
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x21.png",
                "caption": "Figure 21:Clustering results of features on the 41 selected ligands.",
                "position": 4436
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x22.png",
                "caption": "Figure 22:Global Relationshipsindicate that general biochemical features shared among many ligands have been captured.Local Relationshipsreflect the successful capture of biochemical properties between specific ligands and their closely related counterparts.No Relationshipsindicate that the biochemical properties were not captured at all.",
                "position": 4439
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x23.png",
                "caption": "Figure 23:Visualization of task token embeddings using t-SNE.",
                "position": 4554
            },
            {
                "img": "https://arxiv.org/html/2505.20589/x24.png",
                "caption": "Figure 24:Visualization of task token embeddings using UMAP.",
                "position": 4557
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]