[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19849/x1.png",
                "caption": "Figure 1:Overview of tool-use token entropy exploration and ARPO algorithm performance.Left:High entropy observed in the LLM following tool usage.Right:LLM performance comparison on deep search tasks usingonly 1k RL samples, along with a comparison of training tool-use budgets.",
                "position": 226
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19849/x2.png",
                "caption": "Figure 2:Analysis of token entropy variations and token frequency statistics of LLM-based tool-use agent across different datasets.",
                "position": 314
            }
        ]
    },
    {
        "header": "3Agentic Reinforce Policy Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19849/x3.png",
                "caption": "Figure 3:The overview of ARPO algorithm.",
                "position": 406
            },
            {
                "img": "https://arxiv.org/html/2507.19849/x4.png",
                "caption": "Figure 4:llustration of two core components: Entropy-Based Adaptive Rollout and Advantage Attribution Estimation.Left:Principle of Entropy-Based Adaptive Beaming.Right:ARPO assigns different advantages to shared and individual token parts in inter-group samples.",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2507.19849/figures/comparison_advantage.png",
                "caption": "Figure 5:Comparison of different advantage estimation method: Hard vs. Soft setting.",
                "position": 492
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19849/figures/passk_v2.png",
                "caption": "Figure 6:Analysis of Qwen3-8B and Qwen3-14B using ARPO across Pass@1 to Pass@5 metrics.",
                "position": 2612
            },
            {
                "img": "https://arxiv.org/html/2507.19849/figures/comparison_total_calls_v2.png",
                "caption": "Figure 7:Comparison of Tool-Call Efficiency for Qwen2.5-7B: GRPO vs. ARPO",
                "position": 2618
            },
            {
                "img": "https://arxiv.org/html/2507.19849/figures/scaling_exp.png",
                "caption": "Figure 8:Scaling analysis of different Hyper-parameters in Qwen2.5-7B with ARPO. The detailed setting can be found in AppendixC.4.",
                "position": 2693
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADatasets",
        "images": []
    },
    {
        "header": "Appendix BBaselines",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DTheoretical Analysis and Proofs",
        "images": []
    },
    {
        "header": "Appendix EThe Algorithm Workflow of ARPO",
        "images": []
    },
    {
        "header": "Appendix FCase Study",
        "images": []
    }
]