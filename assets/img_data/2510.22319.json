[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22319/x1.png",
                "caption": "",
                "position": 114
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22319/x2.png",
                "caption": "Figure 2:Comparison ofr​(θ)r(\\theta)distributions between FlowGRPO and GRPO-Guard across timesteps.(a) Ideally, the ratio distribution should have a mean near 1 and stable variance across timesteps to ensure effective clipping. (b) Under FlowGRPO, the distribution exhibits a leftward mean shift and increasing variance at low-noise timesteps, causing the clipping mechanism to fail—particularly for trajectories with positive advantages. In contrast, GRPO-Guard with RatioNorm preserves a balanced mean and consistent variance (c), enabling proper clipping and stable policy updates across all timesteps.",
                "position": 266
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x3.png",
                "caption": "Figure 3:Gradient magnitude differences across timesteps. In FlowGRPO, gradient magnitudes vary by roughly 20× across timesteps, reflecting the large differences in gradient scale. GRPO-Guard substantially reduces this imbalance, limiting the variation to about 2.5× and preventing over-optimization under any single noise condition.",
                "position": 405
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22319/fig/flowgrpo-geneval.png",
                "caption": "(a)FlowGRPO on the GenEval task.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2510.22319/fig/flowgrpo-geneval.png",
                "caption": "(a)FlowGRPO on the GenEval task.",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2510.22319/fig/dancegrpo-geneval.png",
                "caption": "(b)DanceGRPO on the GenEval task.",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2510.22319/fig/dancegrpo-ocr.png",
                "caption": "(c)DanceGRPO on the OCR task.",
                "position": 680
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x4.png",
                "caption": "Figure 5:Visual comparison between FlowGRPO and GRPO-Guard. FlowGRPO exhibits clear signs of reward hacking, leading to a significant decline in both image quality and instruction-following ability. In contrast, GRPO-Guard maintains comparable visual quality while demonstrating stronger text generation accuracy and better adherence to instructions.",
                "position": 718
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x5.png",
                "caption": "Figure 6:Visual comparison between DanceGRPO and GRPO-Guard. It is clearly observed that DanceGRPO suffers from severe reward hacking, where the generated images exhibit distinct horizontal and vertical stripe artifacts.",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x6.png",
                "caption": "Figure 7:Comparison between FlowGRPO and GRPO-Guard on the PickScore task. FlowGRPO shows severe distortions in human body proportions and a marked reduction in facial diversity, whereas GRPO-Guard effectively preserves realistic body structure and diverse facial appearances throughout training.",
                "position": 731
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x7.png",
                "caption": "Figure 8:Generation examples of the policy model at different training steps.",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x8.png",
                "caption": "Table 2:Ablation study on major components.",
                "position": 743
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x8.png",
                "caption": "Figure 9:Training curves of the ablation study.",
                "position": 804
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x9.png",
                "caption": "Figure 10:Human evaluation results",
                "position": 825
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x10.png",
                "caption": "Figure 11:Performance differences between the hacking model and the original model across different denoising steps.",
                "position": 837
            },
            {
                "img": "https://arxiv.org/html/2510.22319/x11.png",
                "caption": "Figure 12:Clipping percentage ofr​(θ)<1−ϵr(\\theta)<1-\\epsilonandr​(θ)>1+ϵr(\\theta)>1+\\epsilonduring training for FlowGRPO and GRPO-Guard across different denoising steps.",
                "position": 848
            }
        ]
    },
    {
        "header": "5Conclusion and Limitation",
        "images": []
    },
    {
        "header": "6ACKNOWLEDGMENTS",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]