[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14336/x1.png",
                "caption": "Figure 1:Illustration of the overall framework of the proposed Llama-SMoP model, where audio and video tokens are embedded using a sparsely-gated mixture-of-experts scheme.andrepresent whether the module is trained or kept frozen.",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2505.14336/extracted/6462291/Figures_plots/fire.png",
                "caption": "",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2505.14336/extracted/6462291/Figures_plots/ice.png",
                "caption": "",
                "position": 103
            },
            {
                "img": "https://arxiv.org/html/2505.14336/x2.png",
                "caption": "Figure 2:Detailed illustration of the three proposed SMoP configurations. (a) Joint-Experts, Joint-Router (JEJR) uses one multimodal router and one pool of expert for embedding audio-visual representations. (b) Disjoint-Experts, Disjoint-Routers (DEDR) uses modality-specific routers and experts for embedding modality-specific representations. (c) Joint-Experts, Disjoint-Routers (JEDR) uses modality-specific routers and one shared group of experts, so routers assign the Top-K experts considering the modality characteristics.",
                "position": 109
            }
        ]
    },
    {
        "header": "2Llama-SMoP",
        "images": []
    },
    {
        "header": "3Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14336/x3.png",
                "caption": "Figure 3:(Left). ASR results for Llama-SMoP using different-size Whisper models with Llama 3.2-1B.(Middle). ASR results for Llama-SMoP using different-size Whisper models with Llama 3.2-3B.(Right). VSR results for Llama-SMoP with Llama 3.2-1B/3.2-3B.",
                "position": 430
            },
            {
                "img": "https://arxiv.org/html/2505.14336/x3.png",
                "caption": "",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2505.14336/x4.png",
                "caption": "",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2505.14336/x5.png",
                "caption": "",
                "position": 441
            },
            {
                "img": "https://arxiv.org/html/2505.14336/x6.png",
                "caption": "Figure 4:Ablation analysis on the number of expert projectors for the ASR and VSR tasks.",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2505.14336/x7.png",
                "caption": "Figure 5:Proportion of tokens assigned to each expert, either as first or second choice.",
                "position": 473
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]