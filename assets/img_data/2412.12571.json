[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12571/x1.png",
                "caption": "Figure 1:Overview of the ChatDiT multi-agent framework.The framework consists of three core agents operating sequentially: theInstruction-Parsing Agentinterprets user instructions and analyzes inputs, theStrategy-Planning Agentformulates in-context generation strategies, and theExecution Agentperforms the planned actions using pretrained diffusion transformers. An optionalMarkdown Agentintegrates the outputs into cohesive, illustrated articles. Sub-agents handle specialized tasks within each core agent, ensuring flexibility and precision in generation.",
                "position": 96
            },
            {
                "img": "https://arxiv.org/html/2412.12571/x2.png",
                "caption": "Figure 2:Selected single-round generation examples of ChatDiT on IDEA-Bench(Liang et al.,2024).ChatDiT demonstrates versatility by handling diverse tasks, instructions, and input-output configurations in a zero-shot manner through free-form natural language interactions. The user messages shown here are condensed summaries of the original detailed instructions fromIDEA-Benchto conserve space.",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2412.12571/x3.png",
                "caption": "Figure 3:Selected illustrated article generation examples of ChatDiT.ChatDiT is able to generate interleaved text-image articles based on users’ natural language instructions. It autonomously estimates the required number of images, plans and executes the generation process using in-context capabilities, and seamlessly integrates the outputs into coherent and visually engaging illustrated articles.",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2412.12571/x4.png",
                "caption": "Figure 4:Selected multi-round conversation examples of ChatDiT.By referencing images from the conversation history, ChatDiT is able to perform seamless multi-round generation and editing in response to free-form user instructions. This iterative process enables dynamic refinement and adaptation of outputs while maintaining contextual consistency across conversation turns. Key modifications specified in each instructional message are highlighted inyellow.",
                "position": 145
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12571/x5.png",
                "caption": "Figure 5:Comparison of ChatDiT with existing approaches.",
                "position": 307
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion and Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]