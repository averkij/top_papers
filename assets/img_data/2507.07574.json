[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Experimental setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/positive_examples.png",
                "caption": "Figure 1:An example of the bongard HOI task. Model must infer a common rule, in this case, \"a person is performing a jump on a motorcycle,\" from the positive examples and determine if the query image follows this rule, which the negative examples do not.",
                "position": 145
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/negative_examples.png",
                "caption": "",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/query_image.png",
                "caption": "",
                "position": 149
            }
        ]
    },
    {
        "header": "4A framework for decomposing VLM reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07574/x1.png",
                "caption": "Figure 2:Flowchart illustrating the derivation of thea竅｢c竅｢cv竅｢i竅｢s竅｢i竅｢o竅｢n搗酒搗尽ubscript搗栓搗｣搗役搗搗役搗懺搗嫗cc_{vision}italic_a italic_c italic_c start_POSTSUBSCRIPT italic_v italic_i italic_s italic_i italic_o italic_n end_POSTSUBSCRIPT(LSC),a竅｢c竅｢cf竅｢i竅｢n竅｢a竅｢l搗酒搗尽ubscript搗栓搗汝搗役搗幤搗酒搗兮cc_{final}italic_a italic_c italic_c start_POSTSUBSCRIPT italic_f italic_i italic_n italic_a italic_l end_POSTSUBSCRIPT, anda竅｢c竅｢cg竅｢e竅｢n搗酒搗尽ubscript搗栓搗避搗挺搗嫗cc_{gen}italic_a italic_c italic_c start_POSTSUBSCRIPT italic_g italic_e italic_n end_POSTSUBSCRIPTmetrics.",
                "position": 203
            }
        ]
    },
    {
        "header": "5Linear reasoning bottleneck",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/LSC_benchmark.png",
                "caption": "Figure 3:generative accuracy vs. linear separability for all baseline models.\nThe diagonal dashed line is the LSC benchmark (y=x搗ｦ搗･y=xitalic_y = italic_x).\nPoints above the line indicate that a model窶冱 generative performance has surpassed its LSC.\nThe plot shows that most evaluations struggle to consistently surpass the benchmark, demonstrating a prevalent linear reasoning bottleneck.",
                "position": 221
            }
        ]
    },
    {
        "header": "6Surpassing the LSC",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABaseline prompt definitions",
        "images": []
    },
    {
        "header": "Appendix BSingle vs batched context",
        "images": []
    },
    {
        "header": "Appendix CSeparability ceiling in VLMs",
        "images": []
    },
    {
        "header": "Appendix DHyperparameter details",
        "images": []
    },
    {
        "header": "Appendix ECombined loss details",
        "images": []
    },
    {
        "header": "Appendix FCombined loss hyperparameter search",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/pixtral_hoi_contrastive_loss_scan.png",
                "caption": "Figure 4:Pixtral contrastive loss hyperparameter scan",
                "position": 2625
            }
        ]
    },
    {
        "header": "Appendix GLoRA on vision encoder",
        "images": []
    },
    {
        "header": "Appendix HPEFT comparison",
        "images": []
    },
    {
        "header": "Appendix IResults across HOI splits",
        "images": []
    },
    {
        "header": "Appendix JDomain generalization",
        "images": []
    },
    {
        "header": "Appendix KClass imbalance investigation",
        "images": []
    },
    {
        "header": "Appendix LExample semantic concepts",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/gemma3_4b_attn_map_lora_sim=False.png",
                "caption": "(a)Gemma3 4B after LoRA tuning (邃誰Tsubscript邃誰T\\mathcal{L}_{\\text{NT}}caligraphic_L start_POSTSUBSCRIPT NT end_POSTSUBSCRIPT)",
                "position": 4420
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/gemma3_4b_attn_map_lora_sim=False.png",
                "caption": "(a)Gemma3 4B after LoRA tuning (邃誰Tsubscript邃誰T\\mathcal{L}_{\\text{NT}}caligraphic_L start_POSTSUBSCRIPT NT end_POSTSUBSCRIPT)",
                "position": 4423
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/gemma3_4b_attn_map_lora_sim=True.png",
                "caption": "(b)Gemma3 4B after LoRA tuning (邃団ombinedsubscript邃団ombined\\mathcal{L}_{\\text{combined}}caligraphic_L start_POSTSUBSCRIPT combined end_POSTSUBSCRIPT)",
                "position": 4428
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/phi_attn_map_lora_sim=False.png",
                "caption": "(a)Phi after LoRA tuning (邃誰Tsubscript邃誰T\\mathcal{L}_{\\text{NT}}caligraphic_L start_POSTSUBSCRIPT NT end_POSTSUBSCRIPT)",
                "position": 4449
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/phi_attn_map_lora_sim=False.png",
                "caption": "(a)Phi after LoRA tuning (邃誰Tsubscript邃誰T\\mathcal{L}_{\\text{NT}}caligraphic_L start_POSTSUBSCRIPT NT end_POSTSUBSCRIPT)",
                "position": 4452
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/phi_attn_map_lora_sim=True.png",
                "caption": "(b)Phi after LoRA tuning (邃団ombinedsubscript邃団ombined\\mathcal{L}_{\\text{combined}}caligraphic_L start_POSTSUBSCRIPT combined end_POSTSUBSCRIPT)",
                "position": 4457
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/pixtral_attn_map_lora_sim=False.png",
                "caption": "(a)Pixtral after LoRA tuning (邃誰Tsubscript邃誰T\\mathcal{L}_{\\text{NT}}caligraphic_L start_POSTSUBSCRIPT NT end_POSTSUBSCRIPT)",
                "position": 4474
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/pixtral_attn_map_lora_sim=False.png",
                "caption": "(a)Pixtral after LoRA tuning (邃誰Tsubscript邃誰T\\mathcal{L}_{\\text{NT}}caligraphic_L start_POSTSUBSCRIPT NT end_POSTSUBSCRIPT)",
                "position": 4477
            },
            {
                "img": "https://arxiv.org/html/2507.07574/extracted/6607613/bongard_images/pixtral_attn_map_lora_sim=True.png",
                "caption": "(b)Pixtral after LoRA tuning (邃団ombinedsubscript邃団ombined\\mathcal{L}_{\\text{combined}}caligraphic_L start_POSTSUBSCRIPT combined end_POSTSUBSCRIPT)",
                "position": 4482
            }
        ]
    },
    {
        "header": "Appendix MVisualizing the Mechanism of PEFT via Attention Maps",
        "images": []
    }
]