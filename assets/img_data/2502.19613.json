[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Self-rewarding Reasoning Language Models",
        "images": []
    },
    {
        "header": "4Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19613/x1.png",
                "caption": "Figure 1:The learning dynamic of the PPO training, initialized from the self-rewarding IFT model. We also plot the average generation length during the training in the first figure.",
                "position": 1267
            },
            {
                "img": "https://arxiv.org/html/2502.19613/x2.png",
                "caption": "",
                "position": 1270
            },
            {
                "img": "https://arxiv.org/html/2502.19613/x3.png",
                "caption": "",
                "position": 1271
            }
        ]
    },
    {
        "header": "5More Experiment Results with a Two-turn Conversation Framework and Llama Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19613/x4.png",
                "caption": "Figure 2:The majority voting results of independent samples and self-rewarding correction with Llama-3-8B-it. For MATH, we collect 1.61 samples per trajectory on average with our IFT model, and 1.65 samples per trajectory on average with our M-DPO aligned model, and for GSM8K, we collect 1.27 samples per trajectory for the IFT model and 1.25 samples for the M-DPO aligned model.",
                "position": 1671
            },
            {
                "img": "https://arxiv.org/html/2502.19613/x5.png",
                "caption": "",
                "position": 1674
            }
        ]
    },
    {
        "header": "6Conclusion and Future Research Direction",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended Related Works",
        "images": []
    },
    {
        "header": "Appendix BMissing Experimental Details",
        "images": []
    },
    {
        "header": "Appendix CAdditional Experimental Results",
        "images": []
    },
    {
        "header": "Appendix DExamples",
        "images": []
    }
]