[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06820/x1.png",
                "caption": "Figure 1:Overview of Executable Graph Construction.The pipeline proceeds from left to right: (1) Schema Definition for tools and databases; (2) Implementation validated via procedural testing; and (3) Tool Dependency Graph Construction to model execution logic.",
                "position": 229
            }
        ]
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06820/x2.png",
                "caption": "Figure 2:Overall pipeline of Task Instantiation via Graph Expansion.The process involves: (1) Seed Chain Sampling from the dependency graph; (2) Task Initialization with verifiable execution; and (3) Controlled Environment Expansion to scale complexity while maintaining solvability.",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2602.06820/figures/vita_average_domain_scaling_pass4.png",
                "caption": "Table 1:Zero-shot generalization performance.TheQwen3-SEmodel series, trained with environments and tasks constructed from ourScaleEnvconsistently outperforms baselines across diverse domains.",
                "position": 503
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06820/figures/vita_average_domain_scaling_pass4.png",
                "caption": "Figure 3:Domain Scaling Analysis (Pass@4).Comparison of zero-shot generalization as training domains scale fromN=2N=2to1616.N=0N=0denotes the base model. Performance improves monotonically across both benchmarks.",
                "position": 755
            },
            {
                "img": "https://arxiv.org/html/2602.06820/figures/tau2_average_domain_scaling_pass4.png",
                "caption": "",
                "position": 765
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06820/x3.png",
                "caption": "Figure 4:Visualization of Tool Embeddings across Domains.We use t-SNE(Maaten and Hinton,2008)to project the semantic embeddings of tools from our 16 synthesized training domains (circles) and the evaluation benchmarks (crosses and pluses). The clear spatial separation between the training clusters and theÏ„2\\tau^{2}/ Vita domains empirically demonstrates theOODnature of our evaluation.",
                "position": 1221
            },
            {
                "img": "https://arxiv.org/html/2602.06820/figures/domain_complexity_bubble.png",
                "caption": "Figure 5:Structural statistics of the 16 domains synthesized.The x-axis and y-axis represent the number of tools and database tables, respectively. The color intensity and bubble size indicate theGraph Densityof the Tool Dependency Graph, reflecting the complexity of inter-tool causal relationships within each domain.",
                "position": 1522
            }
        ]
    },
    {
        "header": "Appendix ATool Semantic Diversity and OOD Verification",
        "images": []
    },
    {
        "header": "Appendix BDetailed Statistics of Synthesized Domains and Tasks",
        "images": []
    },
    {
        "header": "Appendix CScalable RL in Hybrid Environments",
        "images": []
    },
    {
        "header": "Appendix DExamples of Tool and Database",
        "images": []
    },
    {
        "header": "Appendix EAgent-User Interaction Trajectory in ScaleEnv",
        "images": []
    }
]