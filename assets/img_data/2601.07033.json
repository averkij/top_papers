[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07033/x1.png",
                "caption": "Figure 1:Illustration of Foreshadow–Trigger–Payoff decomposition using a narrative example fromThe Hound of the Baskervilles. The disappearance of the boot introduces an unresolved causal commitment, which remains dormant until a triggering narrative condition activates its resolution.",
                "position": 155
            },
            {
                "img": "https://arxiv.org/html/2601.07033/x2.png",
                "caption": "Figure 2:Overview of the CFPG framework. CFPG maintains a codified causal state in the form of a foreshadow poolCtC_{t}, where each element is a structured(F,T,P)(F,T,P)triple. At each step t, an eligibility selection module deterministically selects a subsetSt⊆CtS_{t}\\subseteq C_{t}based on codified trigger constraints, which conditions the language model to generate the next continuationyy. The generated text updates both the narrative prefixXt+1X_{t+1}and the foreshadow poolCt+1C_{t+1}via a codified state transition that resolves satisfied commitments and introduces new foreshadows. The right panel shows the simplified CFPG loop in pseudocode.",
                "position": 159
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Dataset",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07033/x3.png",
                "caption": "Figure 4:Visualization of attention patterns during payoff generation.The heatmaps (left and center) compare the attention weights allocated to foreshadowing setup tokens under the vanilla prompting baseline and CFPG. The line plot (right) quantifies the resulting Causal Saliency Gain relative to the baseline, showing that CFPG consistently maintains significantly higher mean attention to the setup region throughout the generation process. Each row corresponds to a different narrative instance.",
                "position": 700
            },
            {
                "img": "https://arxiv.org/html/2601.07033/x4.png",
                "caption": "Figure 5:Temporal decision dynamics of payoff detection for Qwen-2.5-7B-Instruct. CFPG shows reduced premature activation, a sharp decision transition at the gold payoff, and sustained post-resolution confidence compared to the baseline.",
                "position": 762
            },
            {
                "img": "https://arxiv.org/html/2601.07033/x5.png",
                "caption": "Figure 6:Distribution of grounded payoff tracking errors for prompt-based and CFPG-based methods. CFPG notably attenuates premature payoff triggering compared to baseline prompting.",
                "position": 923
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07033/x6.png",
                "caption": "Figure 7:Dataset statistics of the extracted foreshadow–payoff corpus.",
                "position": 1033
            }
        ]
    },
    {
        "header": "Appendix BMetric Definitions for Grounded Payoff Tracking",
        "images": []
    },
    {
        "header": "Appendix CLLM Usage Statement",
        "images": []
    }
]