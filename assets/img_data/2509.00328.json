[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00328/x1.png",
                "caption": "Figure 1:We present a framework for steering Vision-Language-Action (VLA) models.We extract FFN vectors, project them to the VLA token space, cluster them by semantic alignment, and inject activations at inference time to modulate behavior. Our experiments demonstrate interpretable zero-shot control in both simulation (OpenVLAin LIBERO) and on a physical robot (π0\\pi_{0}on a UR5).",
                "position": 76
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Interpreting VLAs",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00328/x2.png",
                "caption": "(a)Meaningful patterns in top value vector tokens. VLA training does not substantially change the proportion of FFN value vectors which have interpretable patterns (top lighter bars) and semantically meaningful patterns (bold bottom bars) in their top tokens.",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x2.png",
                "caption": "(a)Meaningful patterns in top value vector tokens. VLA training does not substantially change the proportion of FFN value vectors which have interpretable patterns (top lighter bars) and semantically meaningful patterns (bold bottom bars) in their top tokens.",
                "position": 174
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x3.png",
                "caption": "(b)Action tokens are incorporated into every layer of the VLA.However, they make up the largest proportion of final layer value vectors.",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x4.png",
                "caption": "(a)Task fine-tuning mainly affects action tokens. The most up-weighted and down-weighted tokens between theπ0\\pi_{0}-FAST andπ0\\pi_{0}-FAST-DROID-finetune models are action tokens.",
                "position": 193
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x4.png",
                "caption": "(a)Task fine-tuning mainly affects action tokens. The most up-weighted and down-weighted tokens between theπ0\\pi_{0}-FAST andπ0\\pi_{0}-FAST-DROID-finetune models are action tokens.",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x5.png",
                "caption": "(b)Fine-tuning induces a more specialized (less general) distribution of action tokens across value vectors.",
                "position": 201
            }
        ]
    },
    {
        "header": "4Steering VLAs",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00328/x6.png",
                "caption": "Figure 4:Sample tasks from LIBERO-Long.Six representative long-horizon tasks - involving sequential manipulation goals such as object placement, containment, and appliance interaction.",
                "position": 259
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x7.png",
                "caption": "(a)Steering motion magnitude interventions.The effect of fast and slow cluster interventions across cluster sizes and activation coefficients. Fast clusters consistently lead to larger end-effector displacement.",
                "position": 265
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x7.png",
                "caption": "(a)Steering motion magnitude interventions.The effect of fast and slow cluster interventions across cluster sizes and activation coefficients. Fast clusters consistently lead to larger end-effector displacement.",
                "position": 268
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x8.png",
                "caption": "(b)Temporal localization interventions.Mean Y-displacement forup-cluster activations injected at early, late, and full model depths. Full clusters produce the largest average motion effects.",
                "position": 273
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x9.png",
                "caption": "(a)Low/high transport.The robot picks up a toy penguin and places it into a basket, with variations in the robot’s trajectory height during data collection.",
                "position": 293
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x9.png",
                "caption": "(a)Low/high transport.The robot picks up a toy penguin and places it into a basket, with variations in the robot’s trajectory height during data collection.",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x10.png",
                "caption": "(b)Slow/fast transport.The robot picks up a toy seal and places it onto a plate, with variations in the robot’s movement speed during data collection.",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x11.png",
                "caption": "(a)Low/high transport.Box plots for maximum end-effector height (cm) showing distribution across 10 rollouts for each steering intervention (intv.) and baseline.",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x11.png",
                "caption": "(a)Low/high transport.Box plots for maximum end-effector height (cm) showing distribution across 10 rollouts for each steering intervention (intv.) and baseline.",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x12.png",
                "caption": "(b)Slow/fast transport.Box plots for average end-effector displacement (mm) between each successive action showing distribution across 10 rollouts for each steering intervention (intv.) and baseline.",
                "position": 327
            }
        ]
    },
    {
        "header": "5Discussion and Conclusion",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASteering Intervention Details",
        "images": []
    },
    {
        "header": "Appendix BInterpretability Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00328/x13.png",
                "caption": "Figure 8:Common DROID instruction tokens become more common in the value vectors of a model fine-tuned on the DROID dataset.The majority of the top-200 instruction tokens are more common in the value vectors of theπ0\\pi_{0}-FAST-DROID-finetune checkpoint, corresponding to a positive z-score (lying above the teal dashed line).",
                "position": 967
            }
        ]
    },
    {
        "header": "Simulation Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00328/x14.png",
                "caption": "Figure 10:Robot Setup:Our hardware experiments use a UR5 robot arm equipped with a Robotiq 2F-140 gripper. The setup includes two cameras: a static scene camera overlooking the workspace and a wrist-mounted camera facing the gripper.",
                "position": 1107
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x15.png",
                "caption": "(a)Scene Camera",
                "position": 1113
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x15.png",
                "caption": "(a)Scene Camera",
                "position": 1116
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x16.png",
                "caption": "(b)Wrist Camera",
                "position": 1121
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x17.png",
                "caption": "(a)Low Intervention",
                "position": 1438
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x17.png",
                "caption": "(a)Low Intervention",
                "position": 1441
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x18.png",
                "caption": "(b)High Intervention",
                "position": 1446
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x19.png",
                "caption": "(a)End-effector Displacement",
                "position": 1453
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x19.png",
                "caption": "(a)End-effector Displacement",
                "position": 1456
            },
            {
                "img": "https://arxiv.org/html/2509.00328/x20.png",
                "caption": "(b)Cumulative End-effector Displacement",
                "position": 1461
            }
        ]
    },
    {
        "header": "Appendix CHardware Experiments",
        "images": []
    }
]