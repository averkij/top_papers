[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "11. Introduction",
        "images": []
    },
    {
        "header": "22. Generating an Explorable World",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09624/x1.png",
                "caption": "Figure 1:Our data curation leverages physical engines, utilizing realistic city assets from UE5 and animated world assets from Unity.",
                "position": 398
            },
            {
                "img": "https://arxiv.org/html/2412.09624/x2.png",
                "caption": "Figure 2:Three panorama representations that can be transformed into one another.",
                "position": 406
            },
            {
                "img": "https://arxiv.org/html/2412.09624/x3.png",
                "caption": "Figure 3:From single view to 360∘panorama.",
                "position": 417
            },
            {
                "img": "https://arxiv.org/html/2412.09624/x4.png",
                "caption": "Figure 4:We model the world transition as a panoramic video generation process. Given the last explored 360∘panorama and an action that rotates the viewing sphere, the model produces a sequence of newly generated panoramic views",
                "position": 513
            }
        ]
    },
    {
        "header": "33. Exploration in the Generative World",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09624/x5.png",
                "caption": "Figure 5:Three exploration modes — interactive, GPT-assisted, and goal-driven — each defined by distinct exploration instructions.",
                "position": 559
            }
        ]
    },
    {
        "header": "44. Advancing Embodied AI",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09624/x6.png",
                "caption": "Figure 6:GenEx-driven imaginative exploration can gather observations that are just as informed as those obtained through physical exploration.",
                "position": 601
            },
            {
                "img": "https://arxiv.org/html/2412.09624/x7.png",
                "caption": "Figure 7:Single agent reasoning with imagination and multi-agent reasoning and planning with imagination. (a) The single agent can imagine previously unobserved views to better understand the environment. (b) In the multi-agent scenario, the agent infers the perspective of others to make decisions based on a more complete understanding of the situation. Input and generated images are panoramic; cubes are extracted for visualization.",
                "position": 708
            }
        ]
    },
    {
        "header": "55. Applications",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09624/x8.png",
                "caption": "Figure 8:Imaginative Exploration Loop Consistency (IELC) varying distance and rotations.",
                "position": 854
            },
            {
                "img": "https://arxiv.org/html/2412.09624/x9.png",
                "caption": "Figure 9:Through generative exploration inz-axis, we are able to generate the 2D bird-eye world view of the current scene.",
                "position": 864
            },
            {
                "img": "https://arxiv.org/html/2412.09624/x10.png",
                "caption": "Figure 10:Through exploration, our model achieves higher quality in novel view synthesis for objects and better consistency in background synthesis, compared to SOTA 3D reconstruction models(Voleti et al.,2024;Tochilkin et al.,2024;StabilityAI,2023).",
                "position": 875
            },
            {
                "img": "https://arxiv.org/html/2412.09624/x11.png",
                "caption": "Figure 11:Active 3D mapping from a single image.",
                "position": 886
            }
        ]
    },
    {
        "header": "66. Discussion",
        "images": []
    },
    {
        "header": "77. Conclusion",
        "images": []
    },
    {
        "header": "Author Contributions",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09624/x12.png",
                "caption": "Figure 12:Left: Pixel Grid coordinate and Spherical Polar coordinate systems; Middle: rotation in Spherical coordinates corresponds to rotation in 2D image; Right: expansion from panorama to cubemap or composition in reverse.",
                "position": 1520
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]