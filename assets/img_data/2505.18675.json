[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18675/x1.png",
                "caption": "Figure 1:Overview ofReasonMap.ReasonMapis a benchmark dataset designed to evaluate fine-grained visual reasoning abilities of MLLMs, encompassing1,00810081,0081 , 008question–answer pairs constructed over high-resolution transit maps from30303030cities, spanning two question types and three templates.",
                "position": 129
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3ReasonMapConstruction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18675/x2.png",
                "caption": "Figure 2:The building pipeline ofReasonMapconsists of three main stages: (1) data collection and preprocessing, (2) question–answer pair construction, and (3) quality control. Steps (2-4) in the figure correspond to the question–answer pair construction stage.",
                "position": 317
            }
        ]
    },
    {
        "header": "4Evaluation Framework",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18675/x3.png",
                "caption": "Figure 3:Accuracy across difficulty combinations for four representative MLLMs (Qwen2.5-VL-72B-I,InternVL3-78B,OpenAI o3, andDoubao-415). Each difficulty combination is denoted by a pair (e.g.,easy-hard), where the first term indicates question difficulty and the second term represents map difficulty. The pair (hard-middle) contains only one sample, leading to an accuracy of 100%. We summarize the number of evaluation samples in each difficulty bucket:55555555samples foreasy-easy,46464646foreasy-middle,28282828formiddle-easy,7777forhard-easy,23232323formiddle-middle,80808080foreasy-hard,1111forhard-middle,57575757formiddle-hard, and15151515forhard-hard.",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2505.18675/x4.png",
                "caption": "",
                "position": 649
            },
            {
                "img": "https://arxiv.org/html/2505.18675/x5.png",
                "caption": "Figure 4:Accuracy across different cities for four representative MLLMs (Qwen2.5-VL-72B-I,InternVL3-78B,OpenAI o3, andDoubao-415). Each city is marked with the corresponding map difficulty and the country flag. Each city in the test set provides a specific number of samples per model:32323232samples for Auckland,34343434for Los Angeles,7777for Miami,35353535for Lisboa,18181818for Geneva,40404040for Beijing,39393939for Hangzhou,17171717for Budapest,39393939for Singapore,40404040for Rome, and11111111for Toronto.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2505.18675/x6.png",
                "caption": "",
                "position": 673
            },
            {
                "img": "https://arxiv.org/html/2505.18675/x7.png",
                "caption": "Figure 5:Error case analysis of various MLLMs usingReasonMap. For reasoning models, the reasoning process is explicitly marked with<think>and</think>tags. We highlight error contents in the answers withredand categorize them accordingly.",
                "position": 817
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADataset Construction Details",
        "images": []
    },
    {
        "header": "Appendix BEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix CCase Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18675/x8.png",
                "caption": "Figure A1:Case analysis of various MLLMs usingReasonMap(Case N1). For reasoning models, the reasoning process is explicitly marked with<think>and</think>tags. We highlight error contents in the answers withredand correct contents ingreen.",
                "position": 2171
            },
            {
                "img": "https://arxiv.org/html/2505.18675/x9.png",
                "caption": "Figure A2:Case analysis of various MLLMs usingReasonMap(Case N2). For reasoning models, the reasoning process is explicitly marked with<think>and</think>tags. We highlight error contents in the answers withredand correct contents ingreen.",
                "position": 2175
            },
            {
                "img": "https://arxiv.org/html/2505.18675/x10.png",
                "caption": "Figure A3:Case analysis of various MLLMs usingReasonMap(Case N3). For reasoning models, the reasoning process is explicitly marked with<think>and</think>tags. We highlight error contents in the answers withredand correct contents ingreen.",
                "position": 2179
            }
        ]
    },
    {
        "header": "Appendix DFurther Discussions",
        "images": []
    },
    {
        "header": "Appendix ELicense and Consent Information",
        "images": []
    }
]