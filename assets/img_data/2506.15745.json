[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15745/x1.png",
                "caption": "Figure 1:MLLMs Video Understanding and Compression.(a) OVU pipeline; (b) IVC: compresses vision tokens after encoding; (c) KVC: compresses KV cache after prefill; (d) CKV: iteratively processes and compresses KV caches to constrain memory usage; (e) Accuracy vs. GPU memory consumption for compression across four token reduction ratios (50%, 25%, 12.5%, 6.25%) on MLVU usingQwen-2-VL-7B. LongVUshen2024longvuis used for IVC, SnapKVli2024snapkvfor KVC; ; (f) GPU memory usage as input video stream length increases. IVC/KVC/CKV target a 6K cache; Sampling uses 1/4 of input frames. Measured on A100 (80GB)",
                "position": 240
            }
        ]
    },
    {
        "header": "3InfiniPot-V: Memory-Constrained Streaming Video Understanding",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15745/x2.png",
                "caption": "Figure 2:Spatio-Temporal KV cache Compression (TaR and VaN).(a) Temporal redundancy across adjacent frames, showing static patches that can be evicted from past frames; (b) Layer-wise cosine similarity of Key/Value embeddings for static patches between consecutive frames inLLaVA-Next-Video-7B; (c) InfiniPot-V performs query-agnostic spatiotemporal compression, reducing temporal redundancy with TaR and selecting tokens via VaN spatial scoring.",
                "position": 350
            },
            {
                "img": "https://arxiv.org/html/2506.15745/x3.png",
                "caption": "Figure 3:Value Norm (VaN) Analysis.(a) Entropy analysis of vision token representations grouped by their VaN scores. (b) VideoMME performance under varying cache compression ratios using either VaN or reverse-VaN for token selection. (c) Layer-wise locality of VaN, measured by center distance and coefficient of variation (CV); lower values indicate stronger spatial consistency.LLaVA-Next-7Bwith Video-MME used.",
                "position": 415
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15745/x4.png",
                "caption": "Figure 4:KV cache Compression (KVC) methods evaluation results with offline long video understanding tasks under Continual KV Cache Compression (CKV) framework. Performance across four compression ratios (1/16, 1/8, 1/4, 1/2) forLLaVA-Next-7B(top row) andQwen-2-VL-7B(bottom row) on VideoMME, MLVUdevdev{}_{\\text{dev}}start_FLOATSUBSCRIPT dev end_FLOATSUBSCRIPT, and LongVideoBenchdevdev{}_{\\text{dev}}start_FLOATSUBSCRIPT dev end_FLOATSUBSCRIPT(LVBdevdev{}_{\\text{dev}}start_FLOATSUBSCRIPT dev end_FLOATSUBSCRIPT) tasks. The full evaluation results are shown in TableA5.",
                "position": 724
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AInfiniPot-V Algorithm and Configuration",
        "images": []
    },
    {
        "header": "Appendix BExperimental Setting Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15745/x5.png",
                "caption": "Figure A1:Qualitative Results of Multi-Turn Conversation: Full-KV uses 16K cache while InfiniPot-V and SnapKV employ 3K compressed KV cache. SnapKV performs query-guided cache compression based on Q1 before proceeding with multi-turn conversation. The video sample is from the MLVU ego reasoning subtask, using theQwen-2-VL-7B model. 128 frame sampling is used.",
                "position": 2042
            }
        ]
    },
    {
        "header": "Appendix CMulti-Turn Video Understanding Analysis",
        "images": []
    },
    {
        "header": "Appendix DWhy Query-Agnostic KV Cache Compression Matters for SVU?",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15745/x6.png",
                "caption": "Figure A2:KV Cache Compression Case Study with SVU: Illustration of cache control strategies under three conditions, differing in the presence of two core requirements for Streaming Video Understanding (SVU): memory constrained (MC) and query agnostic (QA). (a) Case 1: Query-guided compression retains relevant (GT) frames for accurate responses. (b) Case 2: Without query guidance, compression fails to preserve critical frames, resulting in inaccurate responses. (c)Case 3(Streaming scenario): In streaming video processing, where frames arrive continuously, continual KV cache compression (CKV) is necessary, but queries are unavailable during compression.",
                "position": 2096
            },
            {
                "img": "https://arxiv.org/html/2506.15745/x7.png",
                "caption": "Figure A3:Jaccard Similarity between KV Caches: Compare KV cache sets selected by different queries (q1,q2,q3subscriptùëû1subscriptùëû2subscriptùëû3q_{1},q_{2},q_{3}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) across layers.",
                "position": 2227
            },
            {
                "img": "https://arxiv.org/html/2506.15745/x7.png",
                "caption": "Figure A3:Jaccard Similarity between KV Caches: Compare KV cache sets selected by different queries (q1,q2,q3subscriptùëû1subscriptùëû2subscriptùëû3q_{1},q_{2},q_{3}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) across layers.",
                "position": 2230
            }
        ]
    },
    {
        "header": "Appendix EMemory and Latency Measurement Results",
        "images": []
    },
    {
        "header": "Appendix FRelated Work",
        "images": []
    },
    {
        "header": "Appendix GExperimental Results Data",
        "images": []
    },
    {
        "header": "Appendix HLimitation and Future Work",
        "images": []
    }
]