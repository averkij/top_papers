[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18057/x1.png",
                "caption": "Figure 1:The overview of our dataset.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x2.png",
                "caption": "Figure 2:Summary of our dataset. We generate 200 persons and use multimodal unlearning to forget the part of them. After, we measure the unlearning quality and the models‚Äô capabilities by calculating a set of metrics. Then, we create a leaderboard of unlearning methods based on these metrics.",
                "position": 147
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/gen_example_1.png",
                "caption": "Figure 3:Examples of generated images showcasing a distinct individual from our dataset.",
                "position": 204
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/gen_example_2.png",
                "caption": "",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/gen_example_3.png",
                "caption": "",
                "position": 208
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/gen_example_10.jpg",
                "caption": "",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/gen_example_11.jpg",
                "caption": "",
                "position": 210
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/gen_example_16.jpg",
                "caption": "",
                "position": 211
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4CLEAR",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/age_pyramid.png",
                "caption": "Figure 4:Distributions of the attributes of the author‚Äôs faces. We show that CLEAR is balanced and representative regarding age, gender, and ethnicity.",
                "position": 295
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Results and Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AUnlearning Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18057/x3.png",
                "caption": "Figure 5:Process of unlearning with tangent gradient maximization. The unlearning process consisted of 400 epochs, followed by 100 epochs of finetuning on the retain setDRsubscriptùê∑ùëÖD_{R}italic_D start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT.",
                "position": 2211
            }
        ]
    },
    {
        "header": "Appendix BThe process of face generation",
        "images": []
    },
    {
        "header": "Appendix CA sample of dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex1.jpg",
                "caption": "Table 5:An example of all image-name pairs related to a single person",
                "position": 2245
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex2.jpg",
                "caption": "",
                "position": 2270
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex3.jpg",
                "caption": "",
                "position": 2282
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex4.jpg",
                "caption": "",
                "position": 2294
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex5.jpg",
                "caption": "",
                "position": 2306
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex6.jpg",
                "caption": "",
                "position": 2318
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex7.jpg",
                "caption": "",
                "position": 2330
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex8.jpg",
                "caption": "",
                "position": 2342
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex9.jpg",
                "caption": "",
                "position": 2354
            },
            {
                "img": "https://arxiv.org/html/2410.18057/extracted/5947072/img/examples/ex10.jpg",
                "caption": "",
                "position": 2366
            }
        ]
    },
    {
        "header": "Appendix DTextual-only unlearning hyperparameters",
        "images": []
    },
    {
        "header": "Appendix ECV pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18057/x4.png",
                "caption": "Figure 6:Visualization of logits distribution for the forget and holdout sets across 9 different unlearning methods. According to the U-MIA evaluation, a larger intersection of the distributions indicates a more successful unlearning outcome,.",
                "position": 2413
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x5.png",
                "caption": "",
                "position": 2416
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x6.png",
                "caption": "",
                "position": 2417
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x7.png",
                "caption": "",
                "position": 2419
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x8.png",
                "caption": "",
                "position": 2420
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x9.png",
                "caption": "",
                "position": 2421
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x10.png",
                "caption": "",
                "position": 2423
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x11.png",
                "caption": "",
                "position": 2424
            },
            {
                "img": "https://arxiv.org/html/2410.18057/x12.png",
                "caption": "",
                "position": 2425
            }
        ]
    },
    {
        "header": "Appendix FMultimodal unlearning hyperparameters",
        "images": []
    },
    {
        "header": "Appendix GU-MIA and U-LIRA",
        "images": []
    }
]