[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09189/x1.png",
                "caption": "Figure 1:Comparison of translation-enhanced models on reasoning tasks. Tower-Plus-9B and LLaMAX-3-Alpaca struggle with LiveCodeBench-V5 (LCB_V5) and AIME2025, whereas Qwen3-XPlus-8B effectively addresses these challenges.",
                "position": 162
            },
            {
                "img": "https://arxiv.org/html/2510.09189/x2.png",
                "caption": "Figure 2:Average translation performance from English to 16 languages (en→\\rightarrowx). Unlike previous methods that train from a base model, Qwen3-XPlus begins with an instruct model and, using limited parallel data, achieves significant improvements in translation.",
                "position": 165
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Qwen3-XPlus Training Recipe",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09189/x3.png",
                "caption": "Figure 3:Overview of Qwen3-XPlus training recipe. After the data construction process, an instruct model is trained using layer-selective tuning strategy with instruction-format parallel data.",
                "position": 221
            },
            {
                "img": "https://arxiv.org/html/2510.09189/x4.png",
                "caption": "Figure 4:Translation performance of models that are single-layer tuned on parallel data.",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2510.09189/x5.png",
                "caption": "Figure 5:Layerwise nuclear norm of Qwen3-8B on the en-zh split of the Flores-101 dev dataset. About the 20th layers show the highest sensitivity inQQ,KKandVV.",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2510.09189/x6.png",
                "caption": "(a)Qwen3-XPlus-8B",
                "position": 370
            },
            {
                "img": "https://arxiv.org/html/2510.09189/x6.png",
                "caption": "(a)Qwen3-XPlus-8B",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2510.09189/x7.png",
                "caption": "(b)Qwen3-XPlus-14B",
                "position": 379
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09189/x8.png",
                "caption": "Figure 7:Comparison of Qwen3-XPlus, its start model Qwen3,Qwen2.5-Math-7B, Qwen2.5-Coder-7B and the leading multilingual model Tower-Plus-9B on 15 reasoning datasets. The results show that Qwen3-XPlus achieves overall performance comparable to Qwen3 and significantly surpasses Tower-Plus-9B.",
                "position": 849
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09189/x9.png",
                "caption": "Figure 8:Translation performance on unseen languages. Qwen3-XPlus also delivers gains on languages that were unseen during the layer-selective tuning stage.",
                "position": 1240
            },
            {
                "img": "https://arxiv.org/html/2510.09189/x10.png",
                "caption": "Figure 9:Experiments on different backbones. layer-selective tuning also brings improvements on the Llama-3.1-8B instruction model.",
                "position": 1261
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]