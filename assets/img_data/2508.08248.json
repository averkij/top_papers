[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08248/x1.png",
                "caption": "",
                "position": 80
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x2.png",
                "caption": "Figure 2:Quantitative comparisons in quality drift.\na-b on the x-axis is the frame range from the a-th frame to the b-th frame.",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08248/x3.png",
                "caption": "Figure 3:Architecture of StableAvatar. (a) refers to the structure of the Audio Adapter. Embeddings from the Image Encoder and Text Encoder are injected to each block of DiT. Given the audio, we extract the audio embeddings utilizing Wav2Vec.\nTo model joint audio-latent representations, the audio embeddings are fed into the Audio Adapter, and its outputs are injected into the DiT via cross-attention.",
                "position": 127
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08248/x4.png",
                "caption": "Figure 4:Qualitative comparisons with state-of-the-art methods. More examples can be found in the supplementary material.",
                "position": 662
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x5.png",
                "caption": "Figure 5:Ablations on core components of StableAvatar.",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x6.png",
                "caption": "Figure 6:Ablation study on audio modeling.",
                "position": 782
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x7.png",
                "caption": "Figure 7:Ablation study on long video generation strategies.",
                "position": 970
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08248/x8.png",
                "caption": "Figure 8:The pipeline of our DWSW.",
                "position": 2344
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x9.png",
                "caption": "Figure 9:Examples from Long100.",
                "position": 2363
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x10.png",
                "caption": "Figure 10:Full/Half-body avatar animation results. The images with red borders are the reference images.",
                "position": 2585
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x11.png",
                "caption": "Figure 11:Audio-driven multiple-avatar animation results. The images with red borders are the reference images.",
                "position": 2588
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x12.png",
                "caption": "Figure 12:Audio-driven cartoon avatar animation results. The images with red borders are the reference images.",
                "position": 2591
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x13.png",
                "caption": "Figure 13:Audio-driven long avatar video results (1/5). The images with red borders are the reference images.",
                "position": 2594
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x14.png",
                "caption": "Figure 14:Audio-driven long avatar video results (2/5). The images with red borders are the reference images.",
                "position": 2597
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x15.png",
                "caption": "Figure 15:Audio-driven long avatar video results (3/5). The images with red borders are the reference images.",
                "position": 2600
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x16.png",
                "caption": "Figure 16:Audio-driven long avatar video results (4/5). The images with red borders are the reference images.",
                "position": 2603
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x17.png",
                "caption": "Figure 17:Audio-driven long avatar video results (5/5). The images with red borders are the reference images.",
                "position": 2606
            },
            {
                "img": "https://arxiv.org/html/2508.08248/x18.png",
                "caption": "Figure 18:One failure case of our StableAvatar. The images with red borders are the reference images.",
                "position": 2609
            }
        ]
    },
    {
        "header": "Appendix ASupplementary Material",
        "images": []
    }
]