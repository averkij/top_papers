[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/fig/arxiv_pubmed_trend.png",
                "caption": "Figure 1:Cumulative trend of publications on major preprint platforms whose titles or abstracts mention the keyword “language model” or the combination “language model + scientific domain” (e.g., chemistry, physics, multi-omics, medicine,etc.).\nLeft: Results from January 2018 to August 2025, from arXiv and PubMed. For arXiv, the matching includes “language model” in combination with additional science-related keywords; PubMed results are limited to occurrences in titles and abstracts. Both platforms show rapid growth.\nRight: Results from 2020 to August 2025, from bioRxiv, medRxiv, and ChemRxiv, all based on direct matches of “language model” in titles and abstracts. While the overall volumes are smaller than arXiv and PubMed, all three platforms, especially bioRxiv, show rapid acceleration, reflecting growing interdisciplinary interest in large language models across biomedical, chemical, and computational sciences.",
                "position": 648
            },
            {
                "img": "https://arxiv.org/html/2508.21148/fig/biorxiv_medrxiv_chemrxiv_trend.png",
                "caption": "",
                "position": 651
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x1.png",
                "caption": "Figure 2:Evolution of Sci-LLMs reveals four paradigm shifts from 2018 to 2025, including (1) the progression from transfer learning approaches, (2) through the scaling era marked by knowledge integration in larger models, (3) instruction-following capabilities enabling flexible task adaptation, to (4) the latest paradigm introduces scientific agents—AI systems capable of autonomously conducting scientific research, from hypothesis generation and experimental design to data analysis and discovery.Note:Model positions reflect their release dates (x-axis) rather than strict paradigm classification. The four paradigms represent evolving trends in Sci-LLM development with overlaps and continuities, not mutually exclusive categories.",
                "position": 658
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x2.png",
                "caption": "Figure 3:Six main scientific domains covered in this survey. The figure illustrates the primary disciplines investigated in our study on science-oriented large language models, encompassing Chemistry, Materials Science, Physics, Life Sciences, Astronomy, and Earth Science, along with representative subfields within each domain.",
                "position": 673
            }
        ]
    },
    {
        "header": "IIBackground",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/fig/medical_imaging_ver7.png",
                "caption": "Figure 4:Examples of visual data across typical medical imaging modalities, involving radiology (PET, CT, mammography, X-ray, MRI, and ultrasound), dermatology, ophthalmology (CFP, FFA, UWF-SLO, and OCT), endoscopy, histopathology, and cellular microscopy. The figure is sourced from open-source medical datasets.",
                "position": 750
            },
            {
                "img": "https://arxiv.org/html/2508.21148/fig/physics_visual_data.png",
                "caption": "Figure 5:Examples of visual data in physics. SEM of epoxy with/without AlN[123]; TEM of W-doped Cu–Pt nanoalloys[124]; AFM topography of hyper-stoichiometric UO2[125]; STM of Si (111)-(7×\\times7) at multiple scan sizes[126];\nUV/Vis contour map (500–680 nm)[127]; Infrared thermographs of a directional emitter[128]; Raman helicity-resolved maps of 1T-TaS2[129]; NMR of yttrium hydrides[130]. All panels are reused or adapted under the stated licenses (CC-BY-4.0 or CC-BY), with minor cropping only.",
                "position": 753
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x3.png",
                "caption": "Figure 6:Data from Earth science’s six major domains, including the lithosphere, anthroposphere, biosphere, cryosphere, hydrosphere, and atmosphere. Each panel consists of geospatial data, maps, satellite imagery, charts,etc.These data sources are highly diverse, encompassing a wide range of spatial and temporal resolutions, as detailed in Sec.II-B1. The figure is sourced from MSEarth[152], and authorization for its use has been obtained from the original author.",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x4.png",
                "caption": "Figure 7:Examples of astronomical data, demonstrating the application of radio signals, optical signals, and infrared signals in imaging different astronomical objects. The image is sourced fromNASA.",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2508.21148/fig/sectionII_big_smiles.jpg",
                "caption": "Figure 8:Schematic of BigSMILES representations from Linet al.[211]. Polymers are represented as monomers (repeating units) enclosed within curly brackets; the curly brackets indicate that the molecule is a stochastic object. The monomers are represented as SMILES strings, with additional information expressing the connectivity between monomeric units.",
                "position": 881
            },
            {
                "img": "https://arxiv.org/html/2508.21148/fig/smiles.png",
                "caption": "Figure 9:Exemplified symbolic representations (cheminformatics) of formaldehyde and phenol: molecular graph, SMILES and SELFIES string, node identity, and adjacency matrix. Hydrogens are typically omitted in SMILES and SELFIES strings. In the adjacency matrix, edge weights reflect bond types: 1 for single bonds, 2 for double bonds, and 3 for bonds in the aromatic ring.",
                "position": 891
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x5.png",
                "caption": "Figure 10:Five-channel EEG recording setup and corresponding time series data. Horizontal axis: time (T); Vertical axis: individual EEG channels showing brain electrical activity patterns recorded from scalp electrodes. Figure is adapted from CSBrain[271].",
                "position": 907
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x6.png",
                "caption": "Figure 11:Multi-omics data landscape.",
                "position": 920
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x7.png",
                "caption": "Figure 12:Symbolic representations and 3D structure visualizations across different scientific domains: DNA, RNA and Protein. The DNA structure is split into chain I and chain J from PDB 1KX5[298]and visualized by UCSF Chimera[299].\nThe RNA structure is from the RNAsolo with ID 7ELQ[300,301].\nThe protein snapshot is from the PDB bank with ID 7CAM[302]. The DNA and protein are adapted from NatureLM[43].",
                "position": 923
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x8.png",
                "caption": "Figure 13:Hierarchical structure of scientific knowledge. The framework comprises five levels: factual (raw data), theoretical (laws and principles), methodological/technological (methods and tools), modeling/simulation (computational models), and insight (discoveries). The bottom panel illustrates the iterative cycle linking these levels through data collection, pattern recognition, hypothesis testing, and theory development.",
                "position": 977
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x9.png",
                "caption": "Figure 14:Research scopes of Sci-LLMs across six scientific subjects: physics, chemistry, materials science, life sciences, Earth science, and astronomy. For each subject, we present representative domain-specific Sci-LLMs and example questions that the Sci-LLMs are able to solve.",
                "position": 1178
            }
        ]
    },
    {
        "header": "IIIScientific Large Language Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/x10.png",
                "caption": "Figure 15:Illustration of common model architectures for existing scientific large language models.(a) Left:Text-only language model architecture showing the processing pipeline where user queries are processed through a text tokenizer, with scientific text inputs (including disease descriptions, DNA/RNA sequences, protein sequences, and SMILES molecular representations) as part of the query, to generate responses.(b) Right:Multimodal model architecture featuring a domain-specific encoder that processes diverse scientific data types (molecular structures, DNA structures, microscopic images,etc.) alongside text inputs, enabling comprehensive scientific question-answering capabilities through the integration of textual and non-textual scientific information.",
                "position": 1227
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x11.png",
                "caption": "Figure 16:Chronological overview of notable Sci-LLMs categorized by six scientific domains, spanning from 2019 through early 2025. Due to the rapid expansion of the field, this figure presents a selective overview. For detailed information, please refer to Tab.LABEL:tab:sci_llms.",
                "position": 1253
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x12.png",
                "caption": "(a)LLM vs MLLM ratio.",
                "position": 1442
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x12.png",
                "caption": "(a)LLM vs MLLM ratio.",
                "position": 1445
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x13.png",
                "caption": "(b)Base model family distribution (Top-K).",
                "position": 1450
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x14.png",
                "caption": "(c)Parameter size distribution (Top-K).",
                "position": 1455
            }
        ]
    },
    {
        "header": "IVScientific Data for Pre-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/x15.png",
                "caption": "(a)Pre-training dataset mixture of LLaMA[34], Yi[593]and GPT-3[444].",
                "position": 1514
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x15.png",
                "caption": "(a)Pre-training dataset mixture of LLaMA[34], Yi[593]and GPT-3[444].",
                "position": 1517
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x16.png",
                "caption": "(b)Distribution of continual pre-training data for Intern-S1[47], involving 5.5T high-quality textual tokens with 2.5T scientific tokens across over six domains. Adapted from[47].",
                "position": 1523
            }
        ]
    },
    {
        "header": "VScientific Data for Post-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/fig/pt_all.jpg",
                "caption": "Figure 19:Word clouds of the pre-training dataset. The plots show the relative distributions of modalities (left) and types (right), with word size proportional to frequency.",
                "position": 1729
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x17.png",
                "caption": "Figure 20:Composition of the Cambrian-7M[679]instruction tuning dataset.",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x18.png",
                "caption": "Figure 21:Source distribution of existing post-training corpora for scientific LLMs/MLLMs, normalized within each domain, showing significant domain-specific biases and cross-domain imbalance. These skews highlight where future corpus building could diversify inputs to reduce training bias and improve model generalization across disciplines.",
                "position": 1858
            },
            {
                "img": "https://arxiv.org/html/2508.21148/fig/sft_all.jpg",
                "caption": "Figure 22:Word clouds of the post-training dataset. The plots show the relative distributions of modalities (left) and types (right), with word size proportional to frequency.",
                "position": 1861
            }
        ]
    },
    {
        "header": "VIEvaluation of Sci-LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/x19.png",
                "caption": "Figure 23:Performance of leading closed-source models drops significantly on challenging scientific benchmarks (HLE[462], SFE[443]) compared to MMLU-Pro[81]across multiple domains. Top to bottom: HLE, SFE (en), MMLU-Pro.",
                "position": 1954
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x20.png",
                "caption": "Figure 24:Source distribution of existing evaluation corpora for scientific LLMs/MLLMs, normalized within each domain. Most domains rely on a single dominant source type, showing today’s headline scores often reflect proficiency with one writing style or data type rather than robust, cross-domain scientific reasoning, highlighting the need for broader, more heterogeneous evaluation suites.",
                "position": 1999
            },
            {
                "img": "https://arxiv.org/html/2508.21148/fig/eval_all.jpg",
                "caption": "Figure 25:Word clouds of the scientific benchmarks. The plots show the relative distributions of modalities (left) and types (right), with word size proportional to frequency.",
                "position": 2002
            },
            {
                "img": "https://arxiv.org/html/2508.21148/x21.png",
                "caption": "Figure 26:The evolution of evaluation methods for LLMs, starting from simple “Right or wrong” exact matches and progressing to semantic similarity comparisons for open-ended answers with metrics like BERT-Score[800]. More advanced methods include using an LLM as a judge to generate reasoning reports, culminating in the use of multiple agents and tools within an experimental environment for scientific discovery to provide a comprehensive model assessment.",
                "position": 2048
            }
        ]
    },
    {
        "header": "VIIScientific Data Development",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/x22.png",
                "caption": "Figure 27:Scientific data construction pipeline: multi-source data acquisition, data synthesis pipelines for pre-training, post-training and evaluation stages, and comprehensive review framework incorporating intrinsic evaluation, extrinsic validation and human-in-the-loop feedback with five quality criteria (safety, fidelity, accuracy, diversity, privacy).",
                "position": 2089
            }
        ]
    },
    {
        "header": "VIIINew Paradigms for Data-Driven Sci-LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21148/x23.png",
                "caption": "Figure 28:From data infrastructure to agent-assisted discovery: A three-stage evolution of AI in scientific research. This figure delineates the incremental evolution of data-driven Sci-LLMs: (i) Stage I establishes foundational data infrastructure with capabilities in efficiency, multimodal representation, and knowledge updating; (ii) Stage II demonstrates the emergence of scientific capabilities in LLMs driven by mature data ecosystems, enabling cross-domain generalization and scientific reasoning; (iii) Stage III envisions autonomous AI agents that assist scientific discovery while creating closed-loop feedback with data ecosystems, a prospective paradigm for self-evolving discovery systems. This evolution, currently manifesting across physics, chemistry, life sciences, and other domains, illustrates both realized achievements and the expanding potential for AI-driven research as these technologies proliferate into broader scientific disciplines.",
                "position": 2324
            }
        ]
    },
    {
        "header": "IXChallenges and Outlook",
        "images": []
    },
    {
        "header": "XConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]