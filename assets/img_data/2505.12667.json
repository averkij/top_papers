[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12667/x1.png",
                "caption": "Figure 1:Impact of image-watermark similarity on watermarking performance.\nWe used a pretrained classic image hiding network Balujanet[17]on 1,000 image pairs, each consisting of a graphical watermark from Logo-2k[18]and a cover image from ImageNet[19].\nImage-Watermark similarity was quantified using\n1-LPIPS and the quality of the watermarked image and extracted watermark was evaluated using PSNR. Higher PSNR and lower LPIPS indicate improved performance.",
                "position": 102
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12667/x2.png",
                "caption": "Figure 2:Overview of our Safe-Sora framework. Our method consists of three main components: (1) Coarse-to-Fine Adaptive Patch Matching: partitioning the watermark image into patches and optimally assigning them to appropriate video frames and regions, followed by patch embedding and upsampling to generate the watermark feature map; (2) Watermark Embedding: the watermark feature map is fused with multi-scale video features via a UNet with 2D SFMamba blocks, followed by a series of 3D SFMamba blocks that implement our spatiotemporal local scanning strategy, to produce the watermarked video;\n(3) Watermark Extraction: recovering the embedded watermark using an extraction network built with a distortion layer, a series of 3D SFMamba blocks, and position recovery.\nThe difference between different types of Mamba blocks lies in their scanning strategies.",
                "position": 171
            }
        ]
    },
    {
        "header": "3Graphical Watermarking for Video Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12667/x3.png",
                "caption": "Figure 3:For 3D frequency scanning, we propose a spatiotemporal local scanning strategy for 3D wavelet transform, which processes the frequency components hierarchically from low frequency to high frequency and high frequency to low frequency.",
                "position": 281
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12667/x4.png",
                "caption": "Figure 4:Qualitative comparison results on the first frame of each video. Difference maps show absolute differences between the watermarked and original videos, and between the recovered and original watermarks. More examples are shown in Fig.10of Appendix.Best viewed with zoom in.",
                "position": 381
            },
            {
                "img": "https://arxiv.org/html/2505.12667/x5.png",
                "caption": "Figure 5:Visual results of Safe-Sora on multiple frames. For each frame, we show the original image, the corresponding watermarked image, and their residual difference.Best viewed with zoom in.",
                "position": 389
            },
            {
                "img": "https://arxiv.org/html/2505.12667/x6.png",
                "caption": "Figure 6:Watermark reconstruction quality under various distortions.\nDistortion settings include: Random Erasing (5%‚Äì20%), Gaussian Blur (kernel size 3/5/7), Gaussian Noise (œÉ‚àºùí∞‚Å¢(0,0.2)similar-toùúéùí∞00.2\\sigma\\sim\\mathcal{U}(0,0.2)italic_œÉ ‚àº caligraphic_U ( 0 , 0.2 )), Rotation (-30¬∞, 30¬∞), and H.264 Compression (CRF = 24).",
                "position": 525
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12667/x7.png",
                "caption": "Figure 7:Application Scenario of Safe-Sora:\nA user provides a text prompt to a video generation model. The model owner‚Äôs graphical watermark is embedded into the video through a feature extractor and decoder. Later, even if the video is distorted, a watermark extractor can recover the graphical watermark to verify authenticity and ensure copyright protection.",
                "position": 1069
            }
        ]
    },
    {
        "header": "Appendix APreliminaries",
        "images": []
    },
    {
        "header": "Appendix BRobust Watermark Position Recovery Algorithm",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12667/x8.png",
                "caption": "Figure 8:Qualitative examples on Open-Sora backbone. Best viewed with zoom in.",
                "position": 1393
            }
        ]
    },
    {
        "header": "Appendix CMore Backbones",
        "images": []
    },
    {
        "header": "Appendix DAdditional Ablation Studies",
        "images": []
    },
    {
        "header": "Appendix ELimitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12667/x9.png",
                "caption": "Figure 9:Visual impact of Multi-Scale Feature Injection. We present difference maps (√ó5) between watermarked and original videos.\nAfter applying Multi-Scale Feature Injection, the differences are significantly reduced, leading to improved video quality.",
                "position": 1490
            },
            {
                "img": "https://arxiv.org/html/2505.12667/x10.png",
                "caption": "Figure 10:More qualitative examples on VideoCrafter2 backbone. Difference maps show absolute differences between the\nwatermarked and original videos, and between the recovered and original watermarks.Best viewed with zoom in.",
                "position": 1506
            }
        ]
    },
    {
        "header": "Appendix FSocietal Impact",
        "images": []
    }
]