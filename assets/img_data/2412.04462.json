[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04462/x1.png",
                "caption": "",
                "position": 92
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04462/x2.png",
                "caption": "Figure 2:Overview of 4Real-Video.Left: we initialize the grid of frames with a (generated or real) fixed-viewpoint video in the first row and a freeze-time video in the first column. Middle: our architecture consists of two parallel token streams. The top part processes𝐱lvsuperscriptsubscript𝐱𝑙v\\mathbf{x}_{l}^{\\text{v}}bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT v end_POSTSUPERSCRIPTwith viewpoint updates and the bottom part processes𝐱ltsuperscriptsubscript𝐱𝑙t\\mathbf{x}_{l}^{\\text{t}}bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT t end_POSTSUPERSCRIPTwith temporal updates. Subsequently, a synchronization layer computes the new tokens𝐱l+1vsuperscriptsubscript𝐱𝑙1v\\mathbf{x}_{l+1}^{\\text{v}}bold_x start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT v end_POSTSUPERSCRIPT𝐱l+1tsuperscriptsubscript𝐱𝑙1t\\mathbf{x}_{l+1}^{\\text{t}}bold_x start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT t end_POSTSUPERSCRIPTfor the next layer in the diffusion transformer architecture. Right: we propose two implementations of the synchronization layer: hard and soft synchronization.",
                "position": 166
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04462/x3.png",
                "caption": "(a)Relative magnitude ofΔ⁢𝐲lvΔsuperscriptsubscript𝐲𝑙v\\Delta\\mathbf{y}_{l}^{\\text{v}}roman_Δ bold_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT v end_POSTSUPERSCRIPT,Δ⁢𝐲ltΔsuperscriptsubscript𝐲𝑙t\\Delta\\mathbf{y}_{l}^{\\text{t}}roman_Δ bold_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT t end_POSTSUPERSCRIPTin Eq. (10) at each layer.",
                "position": 405
            },
            {
                "img": "https://arxiv.org/html/2412.04462/x3.png",
                "caption": "(a)Relative magnitude ofΔ⁢𝐲lvΔsuperscriptsubscript𝐲𝑙v\\Delta\\mathbf{y}_{l}^{\\text{v}}roman_Δ bold_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT v end_POSTSUPERSCRIPT,Δ⁢𝐲ltΔsuperscriptsubscript𝐲𝑙t\\Delta\\mathbf{y}_{l}^{\\text{t}}roman_Δ bold_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT t end_POSTSUPERSCRIPTin Eq. (10) at each layer.",
                "position": 408
            },
            {
                "img": "https://arxiv.org/html/2412.04462/x4.png",
                "caption": "(b)Similarity between𝐱lvsuperscriptsubscript𝐱𝑙v\\mathbf{x}_{l}^{\\text{v}}bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT v end_POSTSUPERSCRIPTand𝐱ltsuperscriptsubscript𝐱𝑙t\\mathbf{x}_{l}^{\\text{t}}bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT t end_POSTSUPERSCRIPTat each layer.",
                "position": 414
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04462/x5.png",
                "caption": "Figure 4:Visual Comparisons.We show two viewpoints for a fixed time for each method. Our method produces high-quality images, even under significant camera motion. In contrast, frames generated by 4Real and SV4D tend to appear more blurred, with objects notably distorted in SV4D. MotionCtrl struggles to generate frames under substantial camera motion. We useredbounding boxes to highlight regions with distortions and flickering, which become particularly noticeable when viewed as a video.",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2412.04462/x6.png",
                "caption": "Figure 5:Results from 4Real-Video. We can generate diverse and high-quality dynamic content.",
                "position": 441
            },
            {
                "img": "https://arxiv.org/html/2412.04462/x7.png",
                "caption": "Figure 6:Deformable 3D Gaussian Splatting Reconstructionfrom the generated 4D videos demonstrate the spatial and temporal consistency of the proposed method.",
                "position": 445
            },
            {
                "img": "https://arxiv.org/html/2412.04462/x8.png",
                "caption": "Figure 7:Ablation comparisons.We visually compare the video quality and consistency among different design choices.",
                "position": 683
            },
            {
                "img": "https://arxiv.org/html/2412.04462/x9.png",
                "caption": "Figure 8:User studyagainst optimization-based 4D generation methods across different rating criteria.",
                "position": 687
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Deformable 3D GS\nreconstruction details",
        "images": []
    },
    {
        "header": "7Implementation details of ablation study",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04462/extracted/6046198/figure/user-study-screenshot.png",
                "caption": "Figure 9:A screenshot of the interface for user study.",
                "position": 1592
            }
        ]
    },
    {
        "header": "8User study details",
        "images": []
    }
]