[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01241/x1.png",
                "caption": "",
                "position": 233
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01241/x2.png",
                "caption": "Figure 1:Pipeline ofClear. The example shown is from task T1: multi-document legal case summarization. The checklist mapper takes as input the model output (or human-written reference) and extracts checklist items according to the rubric. Checklists of the model output and the reference are compared at the item level, and the results are subsequently aggregated into the final scores of precision, recall, F1, and accuracy.",
                "position": 287
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Benchmark Construction with Multi-disciplinary Expert-Level Tasks",
        "images": []
    },
    {
        "header": "4Checklist-based Performance Assessment usingClear",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01241/x3.png",
                "caption": "Figure 2:F1 score vs. coverage of checklist items. The coverage of checklist items is the percentage of checklist items that are covered in the generated text regardless their correctness.",
                "position": 845
            }
        ]
    },
    {
        "header": "6Towards Reproducible and Low-Cost Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01241/x4.png",
                "caption": "Figure 3:Correlation of different model combinations withGPT-4ojudgments averaged over all the tasks.",
                "position": 880
            },
            {
                "img": "https://arxiv.org/html/2506.01241/x5.png",
                "caption": "Figure 4:Regression analysis between the average performance along each task and the average correlation of judgments withGPT-4oassignments",
                "position": 907
            }
        ]
    },
    {
        "header": "7Skill Decomposition Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01241/x6.png",
                "caption": "(a)Model performance across various levels of knowledge difficulty.",
                "position": 930
            },
            {
                "img": "https://arxiv.org/html/2506.01241/x6.png",
                "caption": "(a)Model performance across various levels of knowledge difficulty.",
                "position": 933
            },
            {
                "img": "https://arxiv.org/html/2506.01241/x7.png",
                "caption": "(b)Model performance across various levels of reasoning complexity.",
                "position": 938
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABenchmark Description",
        "images": []
    },
    {
        "header": "Appendix BTask Description",
        "images": []
    }
]