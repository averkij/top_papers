[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/DomainAllBW.png",
                "caption": "Figure 1.User interfaces split by domains:An overview of a sample of the UIs\nevaluated by humans and MLLMs can be divided into three domains: landing pages, digital receipts, and catalogs. Here we present low-fidelity versions of the screens that we presented to the users. The users saw high-fidelity, branded, and in-product versions of these screens that have been anonymized.",
                "position": 248
            }
        ]
    },
    {
        "header": "3.Study Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/MTURKFigure.png",
                "caption": "Figure 2.Example survey question shown to users. Consists of instructions on top, the UI on the left, and the nine factor, Likert scale questions on the right.",
                "position": 437
            }
        ]
    },
    {
        "header": "4.Evaluation of MLLM Judges for UIs",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/PairwiseAgreement.png",
                "caption": "Figure 3.Accuracy in predicting pairwise human preferences over UIs as a function of the absolute difference of their average human scores. A higher accuracy generally correlates with a larger difference in the human scores. The score-difference bin values were calculated as the difference between the average human ratings of the two UIs. This number is used to infer the difficulty of the question: smaller values indicate more difficult questions, while larger values imply easier ones.",
                "position": 2124
            }
        ]
    },
    {
        "header": "5.Discussion",
        "images": []
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AOpportunities (Extended)",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/PairwiseAgreementSynthetic.png",
                "caption": "Figure 4.Results when pairwise data is created for MLLMs and humans in the same way. For both human and MLLM evaluation sets, we take the absolute value gathered in task 1, compare the two absolute values, and take the higher of the two. Then we compare the human results to the MLLM results to get the agreement score presented here.",
                "position": 3134
            },
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/AllFactors_MAE_BarPlot.png",
                "caption": "Figure 5.Mean Absolute Error(lower is better): This result shows that the mean absolute error for all models consistently is less than 1, with \"interesting\" being the exception. These results show that the models can reliably score within one point of the human scores when given a Likert scale UI question.",
                "position": 3141
            },
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/Catalogs_BulletPlot.png",
                "caption": "((a))Browsing & Discovery",
                "position": 3150
            },
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/Catalogs_BulletPlot.png",
                "caption": "((a))Browsing & Discovery",
                "position": 3153
            },
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/DigitalReceipts_BulletPlot.png",
                "caption": "((b))Confirmation & Feedback",
                "position": 3158
            },
            {
                "img": "https://arxiv.org/html/2510.08783/Figures/LandingPages_BulletPlot.png",
                "caption": "((c))Communication & Engagement",
                "position": 3164
            }
        ]
    },
    {
        "header": "Appendix BAdditional Results & Prompts",
        "images": []
    }
]