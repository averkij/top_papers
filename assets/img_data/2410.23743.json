[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methodology",
        "images": []
    },
    {
        "header": "3Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/main_pack/figure_cot_cot.png",
                "caption": "Figure 1:The nuclear norm of gradients across different layers (x-axis) when trained with fast to slow reasoning paths (left to right columns), on (a) AQuA and (b) ECQA datasets.When detailed CoT is utilized for training, the gradient norm tends to be similar across layers(on both math and commonsense reasoning tasks). Note the y-axis scale forNone CoTis larger, and the scale forSimplified CoTandDetailed CoTare the same.",
                "position": 652
            }
        ]
    },
    {
        "header": "4Empirical Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/main_pack/figure_cot_correct.png",
                "caption": "Figure 2:The nuclear norm of gradients across different layers (x-axis) when trained with Correct vs. Irrelevant responses (a) without CoT (fast thinking); (b) with detailed CoT (slow thinking), on the AQuA dataset.Gradient norm can help identify correct responses when provided Detailed CoT. But this does not extend to gradients without CoT.",
                "position": 869
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/main_pack/figure_cot_instruct.png",
                "caption": "Figure 3:The nuclear norm of gradients across different layers (x-axis) on(a) pre-trained base LLM vs. (b) instruction-finetuned LLM. On both models, training using detailed CoT (slow thinking) reduces the gradient norm and difference across layers. However,the two models’ gradient patterns differ when training with fast thinking(Simplified/None CoT).\nThe y-axis scale ofNone CoTis greater than that ofSimplified CoTandDetailed CoT.",
                "position": 996
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/main_pack/figure_wiki_all.png",
                "caption": "Figure 4:The nuclear norm of gradients across different layers (x-axis) when trained with responses of different lengths (left 3 columns) and unpopular knowledge (rightmost column) on the Wiki knowledge learning (knowledge-intensive) task.\nComparing “Short vs. Long”, “Popular vs. Unpopular”, and “Correct vs. Irrelevant” on the two types of models indicates:(1) longer response≠\\neq≠slower thinking. Unlike Figure1, solely increasing the response length does not affect the gradient patterns;(2) unpopular knowledge triggers larger gradients; (3) Unlike Figure2,gradient norm cannot help judge the response’s correctness on knowledge-intensive tasks.",
                "position": 1000
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Table of Contents",
        "images": []
    },
    {
        "header": "Appendix AData Examples",
        "images": []
    },
    {
        "header": "Appendix BResults on gemma-2-2b",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_gemma2_2b_grads_algebra.png",
                "caption": "Figure 16:Visualization for MATH-Algebra using gemma-2-2b on correct responses.",
                "position": 3185
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_gemma2_2b_grads_counting_probability.png",
                "caption": "Figure 17:Visualization for MATH-Counting using gemma-2-2b on correct responses.",
                "position": 3332
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_gemma2_2b_grads_geometry.png",
                "caption": "Figure 18:Visualization for MATH-Geometry using gemma-2-2b on correct responses.",
                "position": 3479
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_grads_aqua_train.png",
                "caption": "Figure 19:Visualization for AQuA using gemma-2-2b on correct responses.",
                "position": 3685
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_grads_gsm8k_train.png",
                "caption": "Figure 20:Visualization for GSM8K using gemma-2-2b on correct responses.",
                "position": 3888
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_grads_strategyqa_train.png",
                "caption": "Figure 21:Visualization for StrategyQA using gemma-2-2b on correct responses.",
                "position": 4091
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_grads_ecqa_train.png",
                "caption": "Figure 22:Visualization for ECQA using gemma-2-2b on correct responses.",
                "position": 4294
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_grads_creak_train.png",
                "caption": "Figure 23:Visualization for CREAK using gemma-2-2b on correct responses.",
                "position": 4497
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_grads_sensemaking_train.png",
                "caption": "Figure 24:Visualization for Sensemaking using gemma-2-2b on correct responses.",
                "position": 4700
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/wiki_wiki_popularity_gemma2_2b_grads.png",
                "caption": "Figure 25:Visualization for Wiki tasks using gemma-2-2b on correct responses.",
                "position": 4974
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_wrong_answer_shuffle_gemma2_2b_grads_algebra.png",
                "caption": "Figure 26:Visualization for MATH-Algebra using gemma-2-2b on irrelevant responses.",
                "position": 5132
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_wrong_answer_shuffle_gemma2_2b_grads_counting_probability.png",
                "caption": "Figure 27:Visualization for MATH-Counting using gemma-2-2b on irrelevant responses.",
                "position": 5279
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_wrong_answer_shuffle_gemma2_2b_grads_geometry.png",
                "caption": "Figure 28:Visualization for MATH-Geometry using gemma-2-2b on irrelevant responses.",
                "position": 5426
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_grads_aqua_train.png",
                "caption": "Figure 29:Visualization for AQuA using gemma-2-2b on irrelevant responses.",
                "position": 5633
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_grads_strategyqa_train.png",
                "caption": "Figure 30:Visualization for StrategyQA using gemma-2-2b on irrelevant responses.",
                "position": 5836
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_grads_ecqa_train.png",
                "caption": "Figure 31:Visualization for ECQA using gemma-2-2b on irrelevant responses.",
                "position": 6039
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_grads_creak_train.png",
                "caption": "Figure 32:Visualization for CREAK using gemma-2-2b on irrelevant responses.",
                "position": 6242
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_grads_sensemaking_train.png",
                "caption": "Figure 33:Visualization for Sensemaking using gemma-2-2b on irrelevant responses.",
                "position": 6445
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/wiki_wiki_popularity_wrong_answer_shuffle_gemma2_2b_grads.png",
                "caption": "Figure 34:Visualization for Wiki tasks using gemma-2-2b on irrelevant responses.",
                "position": 6719
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_gemma2_2b_it_grads_algebra.png",
                "caption": "Figure 35:Visualization for MATH-Algebra using gemma-2-2b-it on correct responses.",
                "position": 6878
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_gemma2_2b_it_grads_counting_probability.png",
                "caption": "Figure 36:Visualization for MATH-Counting using gemma-2-2b-it on correct responses.",
                "position": 7025
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_gemma2_2b_it_grads_geometry.png",
                "caption": "Figure 37:Visualization for MATH-Geometry using gemma-2-2b-it on correct responses.",
                "position": 7172
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_it_grads_aqua_train.png",
                "caption": "Figure 38:Visualization for AQuA using gemma-2-2b-it on correct responses.",
                "position": 7378
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_it_grads_gsm8k_train.png",
                "caption": "Figure 39:Visualization for GSM8K using gemma-2-2b-it on correct responses.",
                "position": 7581
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_it_grads_strategyqa_train.png",
                "caption": "Figure 40:Visualization for StrategyQA using gemma-2-2b-it on correct responses.",
                "position": 7784
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_it_grads_ecqa_train.png",
                "caption": "Figure 41:Visualization for ECQA using gemma-2-2b-it on correct responses.",
                "position": 7987
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_it_grads_creak_train.png",
                "caption": "Figure 42:Visualization for CREAK using gemma-2-2b-it on correct responses.",
                "position": 8190
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_gemma2_2b_it_grads_sensemaking_train.png",
                "caption": "Figure 43:Visualization for Sensemaking using gemma-2-2b-it on correct responses.",
                "position": 8393
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/wiki_wiki_popularity_gemma2_2b_it_grads.png",
                "caption": "Figure 44:Visualization for Wiki tasks using gemma-2-2b-it on correct responses.",
                "position": 8667
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_wrong_answer_shuffle_gemma2_2b_it_grads_algebra.png",
                "caption": "Figure 45:Visualization for MATH-Algebra using gemma-2-2b-it on irrelevant responses.",
                "position": 8825
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_wrong_answer_shuffle_gemma2_2b_it_grads_counting_probability.png",
                "caption": "Figure 46:Visualization for MATH-Counting using gemma-2-2b-it on irrelevant responses.",
                "position": 8972
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/math_lighteval_math_wrong_answer_shuffle_gemma2_2b_it_grads_geometry.png",
                "caption": "Figure 47:Visualization for MATH-Geometry using gemma-2-2b-it on irrelevant responses.",
                "position": 9119
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_it_grads_aqua_train.png",
                "caption": "Figure 48:Visualization for AQuA using gemma-2-2b-it on irrelevant responses.",
                "position": 9325
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_it_grads_gsm8k_train.png",
                "caption": "Figure 49:Visualization for GSM8K using gemma-2-2b-it on irrelevant responses.",
                "position": 9528
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_it_grads_strategyqa_train.png",
                "caption": "Figure 50:Visualization for StrategyQA using gemma-2-2b-it on irrelevant responses.",
                "position": 9731
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_it_grads_ecqa_train.png",
                "caption": "Figure 51:Visualization for ECQA using gemma-2-2b-it on irrelevant responses.",
                "position": 9934
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_it_grads_creak_train.png",
                "caption": "Figure 52:Visualization for CREAK using gemma-2-2b-it on irrelevant responses.",
                "position": 10137
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/reasoning_cot_500_wrong_answer_shuffle_gemma2_2b_it_grads_sensemaking_train.png",
                "caption": "Figure 53:Visualization for Sensemaking using gemma-2-2b-it on irrelevant responses.",
                "position": 10340
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/gemma2_2b_pack/wiki_wiki_popularity_wrong_answer_shuffle_gemma2_2b_it_grads.png",
                "caption": "Figure 54:Visualization for Wiki tasks using gemma-2-2b-it on irrelevant responses.",
                "position": 10614
            }
        ]
    },
    {
        "header": "Appendix CResults on Llama-3.1-8B",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_llama3_8b_grads_algebra.png",
                "caption": "Figure 55:Visualization for MATH-Algebra using Llama-3.1-8B on correct responses.",
                "position": 10777
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_llama3_8b_grads_counting_probability.png",
                "caption": "Figure 56:Visualization for MATH-Counting using Llama-3.1-8B on correct responses.",
                "position": 10924
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_llama3_8b_grads_geometry.png",
                "caption": "Figure 57:Visualization for MATH-Geometry using Llama-3.1-8B on correct responses.",
                "position": 11071
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_grads_aqua_train.png",
                "caption": "Figure 58:Visualization for AQuA using Llama-3.1-8B on correct responses.",
                "position": 11277
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_grads_gsm8k_train.png",
                "caption": "Figure 59:Visualization for GSM8K using Llama-3.1-8B on correct responses.",
                "position": 11480
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_grads_strategyqa_train.png",
                "caption": "Figure 60:Visualization for StrategyQA using Llama-3.1-8B on correct responses.",
                "position": 11683
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_grads_ecqa_train.png",
                "caption": "Figure 61:Visualization for ECQA using Llama-3.1-8B on correct responses.",
                "position": 11886
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_grads_creak_train.png",
                "caption": "Figure 62:Visualization for CREAK using Llama-3.1-8B on correct responses.",
                "position": 12089
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_grads_sensemaking_train.png",
                "caption": "Figure 63:Visualization for Sensemaking using Llama-3.1-8B on correct responses.",
                "position": 12292
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/wiki_wiki_popularity_llama3_8b_grads.png",
                "caption": "Figure 64:Visualization for Wiki tasks using Llama-3.1-8B on correct responses.",
                "position": 12566
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_wrong_answer_shuffle_llama3_8b_grads_algebra.png",
                "caption": "Figure 65:Visualization for MATH-Algebra using Llama-3.1-8B on irrelevant responses.",
                "position": 12724
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_wrong_answer_shuffle_llama3_8b_grads_counting_probability.png",
                "caption": "Figure 66:Visualization for MATH-Counting using Llama-3.1-8B on irrelevant responses.",
                "position": 12871
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_wrong_answer_shuffle_llama3_8b_grads_geometry.png",
                "caption": "Figure 67:Visualization for MATH-Geometry using Llama-3.1-8B on irrelevant responses.",
                "position": 13018
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_grads_aqua_train.png",
                "caption": "Figure 68:Visualization for AQuA using Llama-3.1-8B on irrelevant responses.",
                "position": 13224
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_grads_gsm8k_train.png",
                "caption": "Figure 69:Visualization for GSM8K using Llama-3.1-8B on irrelevant responses.",
                "position": 13427
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_grads_strategyqa_train.png",
                "caption": "Figure 70:Visualization for StrategyQA using Llama-3.1-8B on irrelevant responses.",
                "position": 13630
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_grads_ecqa_train.png",
                "caption": "Figure 71:Visualization for ECQA using Llama-3.1-8B on irrelevant responses.",
                "position": 13833
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_grads_creak_train.png",
                "caption": "Figure 72:Visualization for CREAK using Llama-3.1-8B on irrelevant responses.",
                "position": 14036
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_grads_sensemaking_train.png",
                "caption": "Figure 73:Visualization for Sensemaking using Llama-3.1-8B on irrelevant responses.",
                "position": 14239
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/wiki_wiki_popularity_wrong_answer_shuffle_llama3_8b_grads.png",
                "caption": "Figure 74:Visualization for Wiki tasks using Llama-3.1-8B on irrelevant responses.",
                "position": 14513
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_llama3_8b_it_grads_algebra.png",
                "caption": "Figure 75:Visualization for MATH-Algebra using Llama-3.1-8B-Instruct on correct responses.",
                "position": 14672
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_llama3_8b_it_grads_counting_probability.png",
                "caption": "Figure 76:Visualization for MATH-Counting using Llama-3.1-8B-Instruct on correct responses.",
                "position": 14819
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_llama3_8b_it_grads_geometry.png",
                "caption": "Figure 77:Visualization for MATH-Geometry using Llama-3.1-8B-Instruct on correct responses.",
                "position": 14966
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_it_grads_aqua_train.png",
                "caption": "Figure 78:Visualization for AQuA using Llama-3.1-8B-Instruct on correct responses.",
                "position": 15172
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_it_grads_gsm8k_train.png",
                "caption": "Figure 79:Visualization for GSM8K using Llama-3.1-8B-Instruct on correct responses.",
                "position": 15375
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_it_grads_strategyqa_train.png",
                "caption": "Figure 80:Visualization for StrategyQA using Llama-3.1-8B-Instruct on correct responses.",
                "position": 15578
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_it_grads_ecqa_train.png",
                "caption": "Figure 81:Visualization for ECQA using Llama-3.1-8B-Instruct on correct responses.",
                "position": 15781
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_it_grads_creak_train.png",
                "caption": "Figure 82:Visualization for CREAK using Llama-3.1-8B-Instruct on correct responses.",
                "position": 15984
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_llama3_8b_it_grads_sensemaking_train.png",
                "caption": "Figure 83:Visualization for Sensemaking using Llama-3.1-8B-Instruct on correct responses.",
                "position": 16187
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/wiki_wiki_popularity_llama3_8b_it_grads.png",
                "caption": "Figure 84:Visualization for Wiki tasks using Llama-3.1-8B-Instruct on correct responses.",
                "position": 16461
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_wrong_answer_shuffle_llama3_8b_it_grads_algebra.png",
                "caption": "Figure 85:Visualization for MATH-Algebra using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 16619
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_wrong_answer_shuffle_llama3_8b_it_grads_counting_probability.png",
                "caption": "Figure 86:Visualization for MATH-Counting using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 16766
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/math_lighteval_math_wrong_answer_shuffle_llama3_8b_it_grads_geometry.png",
                "caption": "Figure 87:Visualization for MATH-Geometry using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 16913
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_it_grads_aqua_train.png",
                "caption": "Figure 88:Visualization for AQuA using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 17119
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_it_grads_gsm8k_train.png",
                "caption": "Figure 89:Visualization for GSM8K using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 17322
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_it_grads_strategyqa_train.png",
                "caption": "Figure 90:Visualization for StrategyQA using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 17525
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_it_grads_ecqa_train.png",
                "caption": "Figure 91:Visualization for ECQA using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 17728
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_it_grads_creak_train.png",
                "caption": "Figure 92:Visualization for CREAK using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 17931
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/reasoning_cot_500_wrong_answer_shuffle_llama3_8b_it_grads_sensemaking_train.png",
                "caption": "Figure 93:Visualization for Sensemaking using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 18134
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama3_8b_pack/wiki_wiki_popularity_wrong_answer_shuffle_llama3_8b_it_grads.png",
                "caption": "Figure 94:Visualization for Wiki tasks using Llama-3.1-8B-Instruct on irrelevant responses.",
                "position": 18408
            }
        ]
    },
    {
        "header": "Appendix DResults on Qwen2-1.5B",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_qwen2_1_5b_grads_algebra.png",
                "caption": "Figure 95:Visualization for MATH-Algebra using Qwen2-1.5B on correct responses.",
                "position": 18571
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_qwen2_1_5b_grads_counting_probability.png",
                "caption": "Figure 96:Visualization for MATH-Counting using Qwen2-1.5B on correct responses.",
                "position": 18718
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_qwen2_1_5b_grads_geometry.png",
                "caption": "Figure 97:Visualization for MATH-Geometry using Qwen2-1.5B on correct responses.",
                "position": 18865
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_grads_aqua_train.png",
                "caption": "Figure 98:Visualization for AQuA using Qwen2-1.5B on correct responses.",
                "position": 19071
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_grads_gsm8k_train.png",
                "caption": "Figure 99:Visualization for GSM8K using Qwen2-1.5B on correct responses.",
                "position": 19274
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_grads_strategyqa_train.png",
                "caption": "Figure 100:Visualization for StrategyQA using Qwen2-1.5B on correct responses.",
                "position": 19477
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_grads_ecqa_train.png",
                "caption": "Figure 101:Visualization for ECQA using Qwen2-1.5B on correct responses.",
                "position": 19680
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_grads_creak_train.png",
                "caption": "Figure 102:Visualization for CREAK using Qwen2-1.5B on correct responses.",
                "position": 19883
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_grads_sensemaking_train.png",
                "caption": "Figure 103:Visualization for Sensemaking using Qwen2-1.5B on correct responses.",
                "position": 20086
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/wiki_wiki_popularity_qwen2_1_5b_grads.png",
                "caption": "Figure 104:Visualization for Wiki tasks using Qwen2-1.5B on correct responses.",
                "position": 20360
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_wrong_answer_shuffle_qwen2_1_5b_grads_algebra.png",
                "caption": "Figure 105:Visualization for MATH-Algebra using Qwen2-1.5B on irrelevant responses.",
                "position": 20518
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_wrong_answer_shuffle_qwen2_1_5b_grads_counting_probability.png",
                "caption": "Figure 106:Visualization for MATH-Counting using Qwen2-1.5B on irrelevant responses.",
                "position": 20665
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_wrong_answer_shuffle_qwen2_1_5b_grads_geometry.png",
                "caption": "Figure 107:Visualization for MATH-Geometry using Qwen2-1.5B on irrelevant responses.",
                "position": 20812
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_grads_aqua_train.png",
                "caption": "Figure 108:Visualization for AQuA using Qwen2-1.5B on irrelevant responses.",
                "position": 21018
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_grads_gsm8k_train.png",
                "caption": "Figure 109:Visualization for GSM8K using Qwen2-1.5B on irrelevant responses.",
                "position": 21221
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_grads_strategyqa_train.png",
                "caption": "Figure 110:Visualization for StrategyQA using Qwen2-1.5B on irrelevant responses.",
                "position": 21424
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_grads_ecqa_train.png",
                "caption": "Figure 111:Visualization for ECQA using Qwen2-1.5B on irrelevant responses.",
                "position": 21627
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_grads_creak_train.png",
                "caption": "Figure 112:Visualization for CREAK using Qwen2-1.5B on irrelevant responses.",
                "position": 21830
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_grads_sensemaking_train.png",
                "caption": "Figure 113:Visualization for Sensemaking using Qwen2-1.5B on irrelevant responses.",
                "position": 22033
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/wiki_wiki_popularity_wrong_answer_shuffle_qwen2_1_5b_grads.png",
                "caption": "Figure 114:Visualization for Wiki tasks using Qwen2-1.5B on irrelevant responses.",
                "position": 22307
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_qwen2_1_5b_it_grads_algebra.png",
                "caption": "Figure 115:Visualization for MATH-Algebra using Qwen2-1.5B-Instruct on correct responses.",
                "position": 22466
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_qwen2_1_5b_it_grads_counting_probability.png",
                "caption": "Figure 116:Visualization for MATH-Counting using Qwen2-1.5B-Instruct on correct responses.",
                "position": 22613
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_qwen2_1_5b_it_grads_geometry.png",
                "caption": "Figure 117:Visualization for MATH-Geometry using Qwen2-1.5B-Instruct on correct responses.",
                "position": 22760
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_it_grads_aqua_train.png",
                "caption": "Figure 118:Visualization for AQuA using Qwen2-1.5B-Instruct on correct responses.",
                "position": 22966
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_it_grads_gsm8k_train.png",
                "caption": "Figure 119:Visualization for GSM8K using Qwen2-1.5B-Instruct on correct responses.",
                "position": 23169
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_it_grads_strategyqa_train.png",
                "caption": "Figure 120:Visualization for StrategyQA using Qwen2-1.5B-Instruct on correct responses.",
                "position": 23372
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_it_grads_ecqa_train.png",
                "caption": "Figure 121:Visualization for ECQA using Qwen2-1.5B-Instruct on correct responses.",
                "position": 23575
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_it_grads_creak_train.png",
                "caption": "Figure 122:Visualization for CREAK using Qwen2-1.5B-Instruct on correct responses.",
                "position": 23778
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_qwen2_1_5b_it_grads_sensemaking_train.png",
                "caption": "Figure 123:Visualization for Sensemaking using Qwen2-1.5B-Instruct on correct responses.",
                "position": 23981
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/wiki_wiki_popularity_qwen2_1_5b_it_grads.png",
                "caption": "Figure 124:Visualization for Wiki tasks using Qwen2-1.5B-Instruct on correct responses.",
                "position": 24255
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_wrong_answer_shuffle_qwen2_1_5b_it_grads_algebra.png",
                "caption": "Figure 125:Visualization for MATH-Algebra using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 24413
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_wrong_answer_shuffle_qwen2_1_5b_it_grads_counting_probability.png",
                "caption": "Figure 126:Visualization for MATH-Counting using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 24560
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/math_lighteval_math_wrong_answer_shuffle_qwen2_1_5b_it_grads_geometry.png",
                "caption": "Figure 127:Visualization for MATH-Geometry using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 24707
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_it_grads_aqua_train.png",
                "caption": "Figure 128:Visualization for AQuA using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 24913
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_it_grads_gsm8k_train.png",
                "caption": "Figure 129:Visualization for GSM8K using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 25116
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_it_grads_strategyqa_train.png",
                "caption": "Figure 130:Visualization for StrategyQA using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 25319
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_it_grads_ecqa_train.png",
                "caption": "Figure 131:Visualization for ECQA using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 25522
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_it_grads_creak_train.png",
                "caption": "Figure 132:Visualization for CREAK using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 25725
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/reasoning_cot_500_wrong_answer_shuffle_qwen2_1_5b_it_grads_sensemaking_train.png",
                "caption": "Figure 133:Visualization for Sensemaking using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 25928
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/qwen_pack/wiki_wiki_popularity_wrong_answer_shuffle_qwen2_1_5b_it_grads.png",
                "caption": "Figure 134:Visualization for Wiki tasks using Qwen2-1.5B-Instruct on irrelevant responses.",
                "position": 26202
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_llama2_7b_grads_algebra.png",
                "caption": "Figure 135:Visualization for MATH-Algebra using Llama-2-7b-hf on correct responses.",
                "position": 26365
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_llama2_7b_grads_counting_probability.png",
                "caption": "Figure 136:Visualization for MATH-Counting using Llama-2-7b-hf on correct responses.",
                "position": 26512
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_llama2_7b_grads_geometry.png",
                "caption": "Figure 137:Visualization for MATH-Geometry using Llama-2-7b-hf on correct responses.",
                "position": 26659
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_grads_aqua_train.png",
                "caption": "Figure 138:Visualization for AQuA using Llama-2-7b-hf on correct responses.",
                "position": 26865
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_grads_gsm8k_train.png",
                "caption": "Figure 139:Visualization for GSM8K using Llama-2-7b-hf on correct responses.",
                "position": 27068
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_grads_strategyqa_train.png",
                "caption": "Figure 140:Visualization for StrategyQA using Llama-2-7b-hf on correct responses.",
                "position": 27271
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_grads_ecqa_train.png",
                "caption": "Figure 141:Visualization for ECQA using Llama-2-7b-hf on correct responses.",
                "position": 27474
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_grads_creak_train.png",
                "caption": "Figure 142:Visualization for CREAK using Llama-2-7b-hf on correct responses.",
                "position": 27677
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_grads_sensemaking_train.png",
                "caption": "Figure 143:Visualization for Sensemaking using Llama-2-7b-hf on correct responses.",
                "position": 27880
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/wiki_wiki_popularity_llama2_7b_grads.png",
                "caption": "Figure 144:Visualization for Wiki tasks using Llama-2-7b-hf on correct responses.",
                "position": 28154
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_wrong_answer_shuffle_llama2_7b_grads_algebra.png",
                "caption": "Figure 145:Visualization for MATH-Algebra using Llama-2-7b-hf on irrelevant responses.",
                "position": 28312
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_wrong_answer_shuffle_llama2_7b_grads_counting_probability.png",
                "caption": "Figure 146:Visualization for MATH-Counting using Llama-2-7b-hf on irrelevant responses.",
                "position": 28459
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_wrong_answer_shuffle_llama2_7b_grads_geometry.png",
                "caption": "Figure 147:Visualization for MATH-Geometry using Llama-2-7b-hf on irrelevant responses.",
                "position": 28606
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_grads_aqua_train.png",
                "caption": "Figure 148:Visualization for AQuA using Llama-2-7b-hf on irrelevant responses.",
                "position": 28812
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_grads_gsm8k_train.png",
                "caption": "Figure 149:Visualization for GSM8K using Llama-2-7b-hf on irrelevant responses.",
                "position": 29015
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_grads_strategyqa_train.png",
                "caption": "Figure 150:Visualization for StrategyQA using Llama-2-7b-hf on irrelevant responses.",
                "position": 29218
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_grads_ecqa_train.png",
                "caption": "Figure 151:Visualization for ECQA using Llama-2-7b-hf on irrelevant responses.",
                "position": 29421
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_grads_creak_train.png",
                "caption": "Figure 152:Visualization for CREAK using Llama-2-7b-hf on irrelevant responses.",
                "position": 29624
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_grads_sensemaking_train.png",
                "caption": "Figure 153:Visualization for Sensemaking using Llama-2-7b-hf on irrelevant responses.",
                "position": 29827
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/wiki_wiki_popularity_wrong_answer_shuffle_llama2_7b_grads.png",
                "caption": "Figure 154:Visualization for Wiki tasks using Llama-2-7b-hf on irrelevant responses.",
                "position": 30101
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_llama2_7b_it_new_grads_algebra.png",
                "caption": "Figure 155:Visualization for MATH-Algebra using Llama-2-7b-chat-hf on correct responses.",
                "position": 30260
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_llama2_7b_it_new_grads_counting_probability.png",
                "caption": "Figure 156:Visualization for MATH-Counting using Llama-2-7b-chat-hf on correct responses.",
                "position": 30407
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_llama2_7b_it_new_grads_geometry.png",
                "caption": "Figure 157:Visualization for MATH-Geometry using Llama-2-7b-chat-hf on correct responses.",
                "position": 30554
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_it_new_grads_aqua_train.png",
                "caption": "Figure 158:Visualization for AQuA using Llama-2-7b-chat-hf on correct responses.",
                "position": 30760
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_it_new_grads_gsm8k_train.png",
                "caption": "Figure 159:Visualization for GSM8K using Llama-2-7b-chat-hf on correct responses.",
                "position": 30963
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_it_new_grads_strategyqa_train.png",
                "caption": "Figure 160:Visualization for StrategyQA using Llama-2-7b-chat-hf on correct responses.",
                "position": 31166
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_it_new_grads_ecqa_train.png",
                "caption": "Figure 161:Visualization for ECQA using Llama-2-7b-chat-hf on correct responses.",
                "position": 31369
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_it_new_grads_creak_train.png",
                "caption": "Figure 162:Visualization for CREAK using Llama-2-7b-chat-hf on correct responses.",
                "position": 31572
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_llama2_7b_it_new_grads_sensemaking_train.png",
                "caption": "Figure 163:Visualization for Sensemaking using Llama-2-7b-chat-hf on correct responses.",
                "position": 31775
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/wiki_wiki_popularity_llama2_7b_it_new_grads.png",
                "caption": "Figure 164:Visualization for Wiki tasks using Llama-2-7b-chat-hf on correct responses.",
                "position": 32049
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_wrong_answer_shuffle_llama2_7b_it_new_grads_algebra.png",
                "caption": "Figure 165:Visualization for MATH-Algebra using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 32207
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_wrong_answer_shuffle_llama2_7b_it_new_grads_counting_probability.png",
                "caption": "Figure 166:Visualization for MATH-Counting using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 32354
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/math_lighteval_math_wrong_answer_shuffle_llama2_7b_it_new_grads_geometry.png",
                "caption": "Figure 167:Visualization for MATH-Geometry using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 32501
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_it_new_grads_aqua_train.png",
                "caption": "Figure 168:Visualization for AQuA using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 32707
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_it_new_grads_gsm8k_train.png",
                "caption": "Figure 169:Visualization for GSM8K using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 32910
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_it_new_grads_strategyqa_train.png",
                "caption": "Figure 170:Visualization for StrategyQA using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 33113
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_it_new_grads_ecqa_train.png",
                "caption": "Figure 171:Visualization for ECQA using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 33316
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_it_new_grads_creak_train.png",
                "caption": "Figure 172:Visualization for CREAK using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 33519
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/reasoning_cot_500_wrong_answer_shuffle_llama2_7b_it_new_grads_sensemaking_train.png",
                "caption": "Figure 173:Visualization for Sensemaking using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 33722
            },
            {
                "img": "https://arxiv.org/html/2410.23743/extracted/5968036/llama2_7b_pack/wiki_wiki_popularity_wrong_answer_shuffle_llama2_7b_it_new_grads.png",
                "caption": "Figure 174:Visualization for Wiki tasks using Llama-2-7b-chat-hf on irrelevant responses.",
                "position": 33996
            }
        ]
    },
    {
        "header": "Appendix EResults on Llama-2-7B-hf",
        "images": []
    }
]