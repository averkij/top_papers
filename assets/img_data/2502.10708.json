[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.10708/x1.png",
                "caption": "Figure 1:Illustration of Growth Trends in Domain-Specific Knowledge Injection into LLMs.\nThe chart displays the cumulative number of papers published between October 2022 and December 2024.\nDifferent colors and border styles represent various injection methods and domains, such as blue with a solid border denoting dynamic injection in the biomedical field.",
                "position": 120
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Paradigms of Knowledge Injection",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.10708/x2.png",
                "caption": "Figure 2:Four knowledge injection paradigms for LLMs.\n(a) Dynamic Knowledge Injection retrieves external knowledge during inference for enhanced reasoning.\n(b) Static Knowledge Injection embeds external knowledge into model parameters during fine-tuning.\n(c) Modular Knowledge Adapters use plug-and-play modules to dynamically adapt to tasks or updates.\n(d) Prompt Optimization utilizes precise prompts to guide the LLM without altering its parameters.",
                "position": 190
            }
        ]
    },
    {
        "header": "4Applications",
        "images": []
    },
    {
        "header": "5Tools, Resources, and Analysis",
        "images": []
    },
    {
        "header": "6Challenges and Opportunities",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]