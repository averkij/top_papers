[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.03052/x1.png",
                "caption": "Figure 1:Overview of SLUNG on Transformers. High-risk tokens are marked in red (Masked or Unlikelihood Loss) while low-risk tokens are marked in green (standard next-token prediction). Black arrows represent flow of information during model forward pass computation. Green arrows represent a possible backpropogation gradient flow. When the loss on red tokens are masked, notice thath<pâ¢râ¢eâ¢tâ¢eâ¢nâ¢tâ¢iâ¢oâ¢uâ¢s>subscriptâ„expectationğ‘ğ‘Ÿğ‘’ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘¢ğ‘ h_{<pretentious>}italic_h start_POSTSUBSCRIPT < italic_p italic_r italic_e italic_t italic_e italic_n italic_t italic_i italic_o italic_u italic_s > end_POSTSUBSCRIPTâ€”the hidden state for a high-risk tokenâ€”is only ever optimized by the attention mechanism to help generate low-risk tokens.",
                "position": 95
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Selective Loss to Understand but Not Generate (SLUNG)",
        "images": []
    },
    {
        "header": "4Understanding Toxicity without Generating It",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.03052/x2.png",
                "caption": "Figure 2:(a) Toxicity Generation vs Understanding tradeoff for Pretrained models. (b) Toxicity Generation vs Understanding tradeoff for Instruction-tuned Models. Error bars represent 95% confidence intervals. SLUNG methods (â˜…) set a new Pareto frontier in both cases.",
                "position": 283
            },
            {
                "img": "https://arxiv.org/html/2505.03052/x3.png",
                "caption": "Figure 3:Effect of toxic data quantity on model understanding and generation of toxicity. Models in the upper left region exhibit the best understanding-generation tradeoff. Masked SLUNGÂ shines at high data scales, showing both high understanding and low toxicity.",
                "position": 376
            }
        ]
    },
    {
        "header": "5Learning Entity Names without Generating Them",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEvaluation Prompts for GPT-4o",
        "images": []
    },
    {
        "header": "Appendix BSample Outputs for TOFU",
        "images": []
    }
]