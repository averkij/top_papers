[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03996/x1.png",
                "caption": "Figure 1:System overview.The real-world robot is equipped with an onboard camera for visual perception. Image detections are projected into the BEV space. Ball detections are provided directly to the policy, while field landmarks are processed by an odometer module to infer the goal location from long-term information. The perception pipeline is designed to efficiently extract and represent visual features for the RL policy.",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2511.03996/x2.png",
                "caption": "Figure 2:Performance of the controller in various scenarios.(AtoF) Real match performance in cluttered environments with disturbances. (GtoI) Reactive responses and real-time adaptation to the ball. (JtoL) Robust behavior across varying terrain and visually diverse environments.",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2511.03996/x3.png",
                "caption": "Figure 3:Validation and behavior analysis.(A) The background grid color represents the success rate of 8192 simulation tests, while the dots indicate the success rate of 10 consecutive hardware tests. Owing to effective alignment, our policy delivers reliable hardware performance that closely matches simulation results. (B) The robot searches for the ball in the distance when starting near the field edge, guided by the policy’s estimated ball position. (C) The robot turns to search for the ball behind itself when it is near the field center. (DandE) The robot’s foothold locations and timing reveal adaptive gait with shorter strides and faster cadence, enabling effective adjustment before kicking, as illustrated by the forward and backward kick examples.",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2511.03996/x4.png",
                "caption": "Figure 4:Perception-action coordination.(A) Training curves for different methods, reporting overall success rates in disturbed training environments. (B) Proportion of ball perception, average perception error, and policy’s ball position estimation error across 4096 kicking tests. (C) Distribution of angular distance between the ball and the camera center, evaluated over 1000 steps across 2048 environments. The shaded area indicates the camera’s FOV. (DandE) The policy’s estimation predicts the ball’s movement when the ball is removed from the robot’s FOV, guiding the robot to re-acquire visual detection of the ball in the direction it disappeared.",
                "position": 185
            },
            {
                "img": "https://arxiv.org/html/2511.03996/x5.png",
                "caption": "Figure 5:Versatile gait behaviors.Visualization of 20,000 collected joint-space trajectory frames together with the reference motion dataset reduced to a 2D plane using UMAP. Five distinct clusters highlight the policy’s ability to integrate reference motions and generalize beyond them to generate task-specific behaviors. From each major cluster, a representative trajectory is selected to illustrate the corresponding behavior.",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2511.03996/x6.png",
                "caption": "Figure 6:Comparison of the learned policy versus a rule-based strategy representative of the current RoboCup state-of-the-art.(AandB) Time from robot start to ball contact and the maximum angular velocity of the robot during this process, measured across various approach angles. The robot starts stationary from a 1.5 m distance. Shaded areas indicate the SD, calculated from 5 tests per direction. (CandD) Representative behaviors when the robot kicks the ball forward (0∘0^{\\circ}) and backward (180∘180^{\\circ}) with the rule-based strategy. (EandF) The learned policy enables the robot to seamlessly integrate approaching and kicking the ball.",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2511.03996/x7.png",
                "caption": "Figure 7:Agile gait behaviors when chasing a rolling ball.The plots show the trajectories of the robot and the ball, together with the foot contact pattern over time. (A) Agile lateral movement and kicking when the ball rolls horizontally. (B) Agile turning and kicking when the ball rolls toward the robot’s rear.",
                "position": 216
            }
        ]
    },
    {
        "header": "3Discussion",
        "images": []
    },
    {
        "header": "4Materials and Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03996/x8.png",
                "caption": "Figure 8:The proposed learning framework.The actor receives partial observations and reconstructs the full state from historical data using an encoder-decoder architecture. The policy is trained with PPO, using rewards from both the environment and a discriminator encoding motion priors, while multiple critics provide value estimates. The policy is trained in simulation with only the modules highlighted in blue deployed on hardware.",
                "position": 252
            }
        ]
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "5Training Details",
        "images": []
    },
    {
        "header": "6Reward Functions",
        "images": []
    },
    {
        "header": "7AMP Training",
        "images": []
    },
    {
        "header": "8Symmetry Loss",
        "images": []
    },
    {
        "header": "9Perception Modeling",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03996/x9.png",
                "caption": "Figure 9:Virtual perception system.(A) Positional noise. (B) Distribution of perception latency. (C) Distribution of perception frequency. (D) Detection rate when the ball is in FOV.",
                "position": 1280
            }
        ]
    },
    {
        "header": "10Odometry Implementation",
        "images": []
    }
]