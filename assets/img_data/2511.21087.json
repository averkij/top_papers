[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21087/fig/qual.png",
                "caption": "Figure 1:Qualitative comparison ofMIRAagainst leading proprietary and open-source image editing models on complex instructions. The rightmost column illustratesMIRA’s unique iterative reasoning and editing process, displaying the intermediate visual results after each step of its perception-reasoning-action loop.",
                "position": 93
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Data Curation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21087/fig/workflow.png",
                "caption": "Figure 2:Workflow of our multimodal reasoning and editing agentMIRA.Given an input image and a complex natural-language instruction,MIRAengages in an iterative perception–reasoning–action loop. At each step, the agent analyzes the current visual state and textual context to generate an atomic edit instruction, which is executed by an external image-editing model. The updated image is fed back into the agent to guide the next step. This loop continues until the full instruction is satisfied, yielding the final edited result.",
                "position": 154
            },
            {
                "img": "https://arxiv.org/html/2511.21087/fig/datasetformulation.png",
                "caption": "Figure 3:Three types of editing samples inMIRA-Editing.",
                "position": 199
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21087/fig/trainingpipeline.png",
                "caption": "Figure 4:Overview of theMIRATraining Pipeline.The training pipeline comprises two stages: (1) Supervised Fine-Tuning and (2) Reinforcement Learning. Stage 1 fine-tunes Qwen2.5-VL-7B-Instruct on paired samples of the input image, the previously edited image, and the complex instruction to initialize the policy model. Stage 2 applies GRPO to further refine the policy, using a composite reward function that couples an image editing model with an editing reward model to score edit quality and provide optimization signals.",
                "position": 210
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21087/fig/mitigation.png",
                "caption": "Figure 5:Qualitative Case Study forMIRA’s Error Mitigation Capability.Atomic 1:Replace the floor to wooden floor., Atomic 2:Change the color of the white cabinet to wooden brown., Atomic 3:Change the color of the white stove to black., Atomic 4:Change the color of the wooden refrigerator to white., Atomic 5:Change the color of the white stove to black, Atomic 6:⟨Stop⟩.",
                "position": 841
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21087/fig/qual_supp1.png",
                "caption": "Figure 6:Qualitative comparison of MIRA against leading proprietary and open-source image editing models on complex instructions.",
                "position": 1081
            },
            {
                "img": "https://arxiv.org/html/2511.21087/fig/qual_supp2.png",
                "caption": "Figure 7:Qualitative comparison of MIRA against leading proprietary and open-source image editing models on complex instructions.",
                "position": 1084
            }
        ]
    },
    {
        "header": "Acknowledgements",
        "images": []
    }
]