[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01982/x1.png",
                "caption": "Figure 1:Comparison between ourG2\\text{G}^{2}RPOand existing studies.\n(a)G2\\text{G}^{2}RPOsignificantly outperforms DanceGRPO in reward scores (HPS-v2.1 in this figure).\n(b) Sampling strategy comparison.G2\\text{G}^{2}RPOacquire a dense reward by confining stochasticity to individual sampling steps.\n(c) Sampling grain comparison.G2\\text{G}^{2}RPOachieves a comprehensive evaluation of each sampling direction by integrating advantages from multi-granularity ODE denoising.\n(d) Visual Comparison. Compared to the baseline method, the images generated byG2\\text{G}^{2}RPOare more aligned with human preferences.",
                "position": 98
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Granular-GRPO",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01982/x2.png",
                "caption": "Figure 2:Overview ofG2\\text{G}^{2}RPO.\nGiven a text prompt and an initial noise, our Singular Stochastic Sampling strategy\nemploys SDE sampling solely at a single step and samples a group of distinct denoising directions.\nThen, the Multi-Granularity Advantage Integration module executes multi-granularity ODE denoising for each direction\nand integrates the advantages to produce a comprehensive evaluation for each sampling direction.\nFor simplicity, the figure shows one coarse-grained path (denoted ascc) and one fine-grained path (denoted asff).",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2510.01982/x3.png",
                "caption": "Figure 3:Visual Comparison of Images Denoised at Different Granularities.Images denoised at different granularities exhibit variations in fine details and textures,\nleading to inconsistent scoring by the Reward Model (HPS-v2.1).\nThis observation reveals the insufficiency of a single-granularity evaluation of group advantage.",
                "position": 362
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01982/x4.png",
                "caption": "Figure 4:Qualitative Results.Comparison with existing flow-based GRPO methods, in which ourG2\\text{G}^{2}RPOdemonstrates superior performance in human preference alignment.",
                "position": 735
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Additional Qualitative Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01982/x5.png",
                "caption": "Figure 5:Qualitative comparison with existing GRPO methods. Best viewed zoomed in.",
                "position": 946
            },
            {
                "img": "https://arxiv.org/html/2510.01982/x6.png",
                "caption": "Figure 6:Qualitative comparison with existing GRPO methods. Best viewed zoomed in.",
                "position": 951
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]