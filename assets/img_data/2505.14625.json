[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14625/x1.png",
                "caption": "Figure 1:This figure illustrates a false negative case in the CN_K12 dataset, where the ground truth and the response generated by LLM (DeepSeek-R1-Distill-Qwen-7B) are mathematically equivalent, yetPrime VerifierandMath Verifyincorrectly marks the response as wrong.",
                "position": 111
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Discovering and Analyzing False Negatives from the Wild",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14625/x2.png",
                "caption": "Figure 2:This figure demonstrates false negatives in Big-Math-RL-Verified by source (upper) and category (lower).",
                "position": 245
            }
        ]
    },
    {
        "header": "4Analysis of False Negatives and Their Impact on RL Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14625/x3.png",
                "caption": "Figure 3:The fraction of unique prompts in the training dataset that encounter at least one false-negative rollout across steps. The x-axis represents the training step, and the y-axis shows the cumulative fraction of prompts affected by false negatives.",
                "position": 303
            },
            {
                "img": "https://arxiv.org/html/2505.14625/x4.png",
                "caption": "Figure 4:This figure demonstrates the impact of FNs on training efficiency by comparingPrime Verifierand LLM annotations. LLM annotations consistently achieve higher prompt efficiency by reducing the all-wrong ratio, particularly in the early stages of training.",
                "position": 309
            }
        ]
    },
    {
        "header": "5Improve RL by Detecting False Negatives withTinyV",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14625/x5.png",
                "caption": "Figure 5:This figure demonstrates the curation and deployment ofTinyV.",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2505.14625/x6.png",
                "caption": "Figure 6:Performance trends ofQwen2.5-7Bon the AMC, MATH and Olympiad benchmark, comparingTinyVwithPrime Verifier. The darker lines are smoothed using a sliding window whose size is 5% of the total training steps.\nWe observe that model trained withTinyVconverges faster and has better final model performance.",
                "position": 477
            },
            {
                "img": "https://arxiv.org/html/2505.14625/x7.png",
                "caption": "Figure 7:This figure compares performance ofHardVerify-Math BenchbetweenBig-Math(hard to verify) andDeepScaleR(easy to verify) datasets.",
                "position": 565
            }
        ]
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BLimitations and Broader Impacts",
        "images": []
    },
    {
        "header": "Appendix CDetailed False Negative Categories",
        "images": []
    },
    {
        "header": "Appendix DProof of Theorem 1",
        "images": []
    },
    {
        "header": "Appendix EMore on Experimental Setups",
        "images": []
    },
    {
        "header": "Appendix FHardVerify-Math Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14625/x8.png",
                "caption": "Figure 10:This figure shows the source distribution ofHardVerify-Math Bench.",
                "position": 3111
            }
        ]
    },
    {
        "header": "Appendix GMore Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14625/x9.png",
                "caption": "Figure 11:This figure compares the model performance ofTinyV,TinyV-Think,Math Verify, andPrime Verifieron diverse benchmarks. The base model isQwen2.5-Math-7B.",
                "position": 3129
            },
            {
                "img": "https://arxiv.org/html/2505.14625/x10.png",
                "caption": "Figure 12:This figures compares the average time cost ofTinyVcompared withPrime Verifierduring GRPO training. The peak occurs when saving model checkpoints.",
                "position": 3136
            }
        ]
    },
    {
        "header": "Appendix HPrompt Templates",
        "images": []
    }
]