[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure1.png",
                "caption": "Figure 1:Some challenging examples of our Sci-Fi for frame inbetweening.Due to symmetric start-end-frame constraints, our Sci-Fi can produce harmonious inbetweening in complex scenarios, containing large and complicated motions of vehicles, people, animals, and cartoon characters.",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure2.png",
                "caption": "Figure 2:Comparison between current I2V-DM-based methods and our Sci-Fi.(a) In current I2V-DM-based methods, the end-frame constraint is weaker than the start-frame constraint due to the same injection mechanism but a smaller training scale.\nConsequently, inbetweening dynamics are heavily influenced by the start frame’s I2V prior.\nFor instance, rider motions in generated frames deviate from ground truth, instead resembling base model I2V results, causing a distorted predicted path with collapsed content.\n(b) Our Sci-Fi maintains start frame processing while enhancing end-frame constraint injection.\nThis achieves symmetric start-end-frame constraints with small training, yielding a fine predicted path close to the real one with smoother inbetweening.",
                "position": 112
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure3.png",
                "caption": "Figure 3:Our proposed framework Sci-Fi and its core module EF-Net(a) Our Sci-Fi efficiently achieves symmetric start-end-frame constraints by handling the start frame as before and applying an improved injection mechanism for the end-frame constraint.\n(b) This new mechanism is based on a lightweight module, EF-Net, which efficiently encodes the end frame and expands it into temporally adaptive frame-wise features injected into the I2V-DM.",
                "position": 298
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure4.png",
                "caption": "Figure 4:Visual Comparison between our Sci-Fi and some state-of-the-art methods.Our Sci-Fi greatly improves the visual quality of intermediate content in diverse scenarios.",
                "position": 647
            },
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure5.png",
                "caption": "Figure 5:Results of user study.Each pie chart illustrates the proportion of videos output by each method that are selected by participants in a specific evaluation dimension.",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure6.png",
                "caption": "Figure 6:Visual results of our Sci-Fi for cartoon frame inbetweening.The generated high-quality cartoon videos demonstrate a strong generalization ability of our method.",
                "position": 765
            }
        ]
    },
    {
        "header": "5Conclusion and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Details and Results of Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure7.png",
                "caption": "Figure 7:Visual Comparison between different types of text prompts.Utilizing VLM to predict or refine text prompts can enhance the performance of our Sci-Fi.",
                "position": 2913
            },
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure8.png",
                "caption": "Figure 8:Visual comparison between our Sci-Fi and some advanced methods on cartoon frame inbetweening.Our Sci-Fi achieves better visual quality when generalized to cartoon data.",
                "position": 3111
            },
            {
                "img": "https://arxiv.org/html/2505.21205/extracted/6482246/figure/figure9.png",
                "caption": "Figure 9:Visual comparison of Wan2.1-FLF2V-14B[4], CogVideoX-FT[56], and our Sci-Fi.Wan2.1-FLF2V-14B improves the quality of generated videos at the cost of much more computation.",
                "position": 3115
            }
        ]
    },
    {
        "header": "Appendix BFailed Cases and Comparison with Wan2.1-FLF2V-14B",
        "images": []
    },
    {
        "header": "Appendix CInstruction of Code and Data",
        "images": []
    },
    {
        "header": "Appendix DSocietal impacts",
        "images": []
    }
]