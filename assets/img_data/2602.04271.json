[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04271/x1.png",
                "caption": "Figure 1:Given (a) an input monocular video, we propose a novel 4D generation methodSkeletonGaussianwhich uses (b) a skeleton to drive the motion of 4D Gaussian model. SkeletonGaussian enables (c) direct motion editing through the skeleton‚Äôs explicit motion representation, allowing users to adjust skeleton poses to modify the motion of the objects directly.",
                "position": 63
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04271/x2.png",
                "caption": "Figure 2:Pipeline of the SkeletonGaussian framework for 4D object generation, divided into three stages: (1)Static 3D Object Generation and Skeleton Extraction: Starting from a frame at the video‚Äôs midpoint, a static 3D Gaussian modelùí¢c\\mathcal{G}_{c}(Section3.1) is generated in canonical space, from which an inherent skeletal structure is subsequently extracted. (2)Rigid Motion Modeling: Using LBS, rigid deformations‚Ñ±l‚Äãb‚Äãs\\mathcal{F}_{lbs}(Section3.2) under various posesŒ∏t\\theta_{t}are applied to rigidly deformùí¢c\\mathcal{G}_{c}intoùí¢r\\mathcal{G}_{r}. During this stage, the skeleton posesŒ∏t\\theta_{t}are optimized. (3)Non-Rigid Motion Modeling: To capture fine-grained deformations, a deformation field‚Ñ±n‚Äãr\\mathcal{F}_{nr}(Section3.3) refines the motion of the rigidly deformed 3D Gaussianùí¢r\\mathcal{G}_{r}, transforming it into the observation space Gaussianùí¢o\\mathcal{G}_{o}.‚Ñ±n‚Äãr\\mathcal{F}_{nr}comprises a hexplane[3]and an MLP. All three stages share the sameTraining Objectives(Section3.4). A differentiable Gaussian rasterizer renders images of the observation space 3D Gaussianùí¢o\\mathcal{G}_{o}from multiple viewpoints, comparing them to the reference video with photometric and MV-SDS losses for backpropagation.",
                "position": 119
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04271/x3.png",
                "caption": "Figure 3:Visualizing 4D Object Motion with Skeleton Poses. We present generated 4D object motion and its corresponding skeleton poses, where the viewpoint rotates from left to right, and time progresses linearly from left to right.",
                "position": 201
            },
            {
                "img": "https://arxiv.org/html/2602.04271/x4.png",
                "caption": "Figure 4:Editing Generated Motion. We visualize the generated motion (top) and edited motion sequence (bottom). Users can directly adjust the skeleton poses of specific joints at different times to edit the object‚Äôs motion.",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2602.04271/x5.png",
                "caption": "Figure 5:Qualitative Comparisons. We compare our method with STAG4D[66]and DreamGaussian4D[43]. For each instance, we render two viewpoints at two time steps. We also visualize the skeleton poses of SkeletonGaussian.",
                "position": 287
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04271/x6.png",
                "caption": "Figure 6:Qualitative evaluations of the ablation study. We visualize the skeleton poses and the objects at different time steps.",
                "position": 377
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04271/x7.png",
                "caption": "Figure 7:Illustration of the non-rigid deformation field using HexPlane, which captures intricate motion details.",
                "position": 1470
            }
        ]
    },
    {
        "header": "7HexPlane Deformation Field",
        "images": []
    },
    {
        "header": "8Implementation Details",
        "images": []
    },
    {
        "header": "9Additional Information on Loss Functions",
        "images": []
    },
    {
        "header": "10Additional Results for 4D Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04271/x8.png",
                "caption": "Figure 8:Qualitative results illustrating gradual changes in time stamps and view angles from left to right.",
                "position": 1582
            },
            {
                "img": "https://arxiv.org/html/2602.04271/x9.png",
                "caption": "Figure 9:Front-view qualitative results with varying time stamps from left to right.",
                "position": 1585
            },
            {
                "img": "https://arxiv.org/html/2602.04271/x10.png",
                "caption": "Figure 10:Visualization of failure cases.Top:The egret case shows how leg posture misestimation can lead to incorrect results when the 15th frame is selected as the static frame.Bottom:Selecting the 10th frame as static frame can resolves the issue.",
                "position": 1592
            },
            {
                "img": "https://arxiv.org/html/2602.04271/x11.png",
                "caption": "Figure 11:Visualization of failure cases. The pistol case demonstrates the challenges of modeling non-articulated structures.",
                "position": 1595
            }
        ]
    },
    {
        "header": "11Failure Cases",
        "images": []
    }
]