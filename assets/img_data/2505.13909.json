[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/first_image.png",
                "caption": "Figure 1:PC Agent-E achieves state-of-the-art\nopen-source performance in Windows computer use with just 312 augmented trajectories.",
                "position": 176
            },
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/overview.png",
                "caption": "Figure 2:Overview of our framework, consisting of four key components: (1) Trajectory Collection, gathering a small set of human trajectories by recording user actions and state observations at each step; (2) Thought Completion, reconstructing the implicit thought process missing in raw human trajectories; and (3) Trajectory Boost, diversifying action decisions to further enhance trajectory quality (4) Agent Training, developing a strong computer use agent with remarkable data efficiency.",
                "position": 204
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/trajectory.png",
                "caption": "Figure 3:An example trajectory collected by PC Tracker.",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/data_distribution.png",
                "caption": "Figure 4:Distribution of the 312 task trajectories across different applications.",
                "position": 303
            },
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/trajboost.png",
                "caption": "Figure 5:Visualization of our Trajectory Boost method. (Left) Raw human trajectory recorded by PC Tracker. (Center) Human trajectory with reconstructed thoughts after Thought Completion, where the red node indicates human action decisions. (Right) The final Traj Tree, where the blue node indicates augmented diverse action decisions synthesized by Claude 3.7 Sonnet.",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/scaffold.png",
                "caption": "Figure 6:A training example that also demonstrates the inference process of the PC Agent-E scaffold.",
                "position": 445
            }
        ]
    },
    {
        "header": "4WindowsAgentArena-V2",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/waa.png",
                "caption": "Figure 7:(Left) Overview of the WindowsAgentArena benchmark. (Right) Our main modifications to the updated WindowsAgentArena-V2 benchmark.",
                "position": 460
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13909/extracted/6456570/assets/scaling_2.png",
                "caption": "Figure 8:(a) Performance on WindowsAgentArena-V2 with different training data scaling factors‚Ä≤superscriptùë†‚Ä≤s^{\\prime}italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT. (b) Performance on WindowsAgentArena-V2 with different max steps before and after training.",
                "position": 648
            }
        ]
    },
    {
        "header": "6Conclusion and Discussion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining Details",
        "images": []
    },
    {
        "header": "Appendix BPrompts",
        "images": []
    },
    {
        "header": "Appendix CPC Tracker User Manual",
        "images": []
    }
]