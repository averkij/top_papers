[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Decoder-Hybrid-Decoder Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06607/x1.png",
                "caption": "Figure 1:Our decoder-hybrid-decoder architecture taking Samba[RLL+25]as the self-decoder. Gated Memory Units (GMUs) are interleaved with the cross-attention layers in the cross-decoder to reduce the decoding complexity. As in YOCO[SDZ+24], the full attention layer only need to compute the KV cache during prefilling with the self-decoder, leading to linear computation complexity for the prefill stage.",
                "position": 129
            }
        ]
    },
    {
        "header": "3Experiments & Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/scaling_d8-d24.png",
                "caption": "(a)Compute scaling comparisons",
                "position": 272
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/scaling_d8-d24.png",
                "caption": "(a)Compute scaling comparisons",
                "position": 275
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/scaling_data_1B.png",
                "caption": "(b)Data scaling comparisons",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/prolong_results_32k_accuracy_vs_swa.png",
                "caption": "Figure 3:Accuracy (with error bars) v.s. Sliding Window Size on Phonebook with 32K evaluation length.",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/tp1-bs768-replicas1-prompt32000-gen500.png",
                "caption": "(a)Prompt: 32000, Generation: 500",
                "position": 679
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/tp1-bs768-replicas1-prompt32000-gen500.png",
                "caption": "(a)Prompt: 32000, Generation: 500",
                "position": 682
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/tp1-bs768-replicas1-prompt2000-gen32000.png",
                "caption": "(b)Prompt: 2000, Generation: 32000",
                "position": 687
            }
        ]
    },
    {
        "header": "4Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06607/x2.png",
                "caption": "Figure 5:Major architectural variants explored in this section. For GDNY, we use Gated DeltaNet[YKH25]with normalizationafteroutput gate (GDN-A) for self-decoder, and apply normalized GMU (nGMU) in cross-decoder.",
                "position": 704
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATheoretical Analysis",
        "images": []
    },
    {
        "header": "Appendix BAdditional Aspect Ratio Calculations",
        "images": []
    },
    {
        "header": "Appendix CAblation Study on Hyper-parameter Scaling Laws",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/scaling_data_1B_mup_abl_tie.png",
                "caption": "(a)Tied Embedding",
                "position": 2686
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/scaling_data_1B_mup_abl_tie.png",
                "caption": "(a)Tied Embedding",
                "position": 2689
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/scaling_data_1B_mup_abl_untie.png",
                "caption": "(b)Untied Embedding",
                "position": 2694
            }
        ]
    },
    {
        "header": "Appendix DAdditional Details on Scaling Comparisons",
        "images": []
    },
    {
        "header": "Appendix EAdditional Long-context Retrieval Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/slim_results_32k_accuracy_vs_swa.png",
                "caption": "(a)SlimPajama",
                "position": 3143
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/slim_results_32k_accuracy_vs_swa.png",
                "caption": "(a)SlimPajama",
                "position": 3146
            },
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/prolong_results_32k_accuracy_vs_swa_novarlen.png",
                "caption": "(b)ProLong-64K",
                "position": 3151
            }
        ]
    },
    {
        "header": "Appendix FMore Details on Architecture and Large-scale Pre-training",
        "images": []
    },
    {
        "header": "Appendix GAdditional Details on Efficiency and Reasoning Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06607/extracted/6607630/generation_length.jpg",
                "caption": "Figure 8:Generation latencies at length of 1K, 2K, 4K, 8K, 16K and 32K for a prompt length of 2000. Given a certain generation length, we measure the average latency of all the requests in all the loads of 1, 2, 4, 8, 16 concurrent requests.",
                "position": 3180
            }
        ]
    },
    {
        "header": "Appendix HAdditional Ablation Study",
        "images": []
    },
    {
        "header": "Appendix IRelated Work",
        "images": []
    },
    {
        "header": "Appendix JLimitation",
        "images": []
    }
]