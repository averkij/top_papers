[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06955/x1.png",
                "caption": "Figure 1:Masking strategy comparison.This figure demonstrates the key differences between the previous random masking strategy[21](top) and our attention-based masking (bottom). Our masking strategy focuses on the more significant and dynamic parts of the motion (colored) corresponding to the condition.",
                "position": 116
            },
            {
                "img": "https://arxiv.org/html/2503.06955/x2.png",
                "caption": "Figure 2:Motion Anything architecture.The multimodal architecture consists of several key components: (a) temporal and (c) spatial attention-based masking, (b) motion generator, and (d) a single block of motion generator.\nThese components enable the model to learn key motions corresponding to the given conditions, and facilitate alignment between multi-modal conditions and motion features.",
                "position": 215
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06955/x3.png",
                "caption": "Figure 3:Attention map.The attention map provides a direct visualization of our attention-based masking approach, which selectively masks regions in the motion sequence with high attention scores.",
                "position": 247
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06955/x4.png",
                "caption": "Figure 4:Qualitative evaluation on text-to-motion generation.We qualitatively compared the visualizations generated by our method with those produced by BAD[22], BAMM[44], and MoMask[21].",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.06955/x5.png",
                "caption": "Figure 5:Qualitative evaluation on music-to-dance generation.We qualitatively compared the visualizations generated by our method with those produced by EDGE[54], Lodge[36], and Bailando[51].",
                "position": 1279
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "1Full Comparison for Text-to-Motion",
        "images": []
    },
    {
        "header": "2User Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06955/extracted/6272770/figure/user.png",
                "caption": "Figure 1:User study form.The User Interface (UI) used in our user study.",
                "position": 3502
            }
        ]
    },
    {
        "header": "3Model Efficiency",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06955/x6.png",
                "caption": "Figure 2:Comparisons on FID and AIT.All tests are conducted on the same NVIDIA GeForce RTX 2080 Ti. The closer the model is to the origin, the better.",
                "position": 3570
            }
        ]
    },
    {
        "header": "4Application: 4D Avatar Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06955/x7.png",
                "caption": "Figure 3:4D Avatar Generation.This approach enables 4D avatar generation conditioned on multimodal inputs, achievable with just a single text prompt.",
                "position": 3583
            },
            {
                "img": "https://arxiv.org/html/2503.06955/extracted/6272770/figure/3davatar.png",
                "caption": "Figure 4:3D Avatars.This figure shows examples of 3D avatars generated by Tripo AI 2.0[1]. These avatars will later serve as candidates for our Selective Rigging Mechanism.",
                "position": 3612
            },
            {
                "img": "https://arxiv.org/html/2503.06955/x8.png",
                "caption": "Figure 5:Qualitative evaluation on text-&-music-to-dance generation.We qualitatively compared the visualizations generated by our method with those produced by TM2D[17]and MotionCraft[5].",
                "position": 3752
            }
        ]
    },
    {
        "header": "5Qualitative Evaluation",
        "images": []
    }
]