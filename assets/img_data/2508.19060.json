[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19060/x1.png",
                "caption": "Figure 1:Different supervision scenarios within manufacturing processes are illustrated. Images with agreenborder contain no anomalies, while images with aredborder indicate the presence of an anomaly. For some images, the corresponding anomaly segmentation mask is also provided. The labelling effort required increases progressively from left to right. At present, onlySuperSimpleNetsupports training across all four scenarios.",
                "position": 105
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3SuperSimpleNet",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19060/x2.png",
                "caption": "Figure 2:SuperSimpleNet‚Äôs architecture. Features are first extracted, upscaled, and, in the case of the segmentation branch, also adapted. During training, synthetic anomalies are generated in the latent space and are limited to regions defined by the binarised Perlin mask. The segmentation head predicts an anomaly maskMo\\mathrm{M}_{o}, based on the perturbed feature mapùí´‚Äãùíú\\mathcal{PA}, which is then used in combination with the perturbed feature mapùí´‚Äã‚Ñ±\\mathcal{PF}by the classification head to produce the anomaly scoress. The anomaly scoress, and the predicted mapMo\\mathrm{M}_{o}are supervised by the anomaly maskM\\mathrm{M}, and the ground truth anomaly scoreyy, whereyyis set to 1 if the image contains an anomaly (synthetic or real) and to 0 otherwise. During inference,Mo\\mathrm{M}_{o}andssare produced directly, skipping the anomaly generation phase. The remaining parts of original SimpleNet are also shown in the image withgreencolour.",
                "position": 311
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x3.png",
                "caption": "Figure 3:Synthetic anomaly generation. Synthetic anomaly masksMs‚Äãy‚Äãn‚Äãt‚Äãh\\mathrm{M}_{synth}are generated by removing actual anomalous regions (captured by ground truth maskMg‚Äãt\\mathrm{M}_{gt}) from Perlin anomaly maskMp\\mathrm{M}_{p}(obtained by thresholding Perlin Noise[45]).Ms‚Äãy‚Äãn‚Äãt‚Äãh\\mathrm{M}_{synth}is then used to limit the Gaussian noise only to specific regions, producing final noiseœµ\\epsilon, which is later added to the features to create synthetic anomalies.\nThe final anomaly maskM\\mathrm{M}is constructed fromMs‚Äãy‚Äãn‚Äãt‚Äãh\\mathrm{M}_{synth}andMg‚Äãt\\mathrm{M}_{gt}indicates regions with synthetic and actual anomalies. SinceMg‚Äãt\\mathrm{M}_{gt}is empty in the case of weakly supervised and unsupervised learning,Mp\\mathrm{M}_{p}directly becomesMs‚Äãy‚Äãn‚Äãt‚Äãh\\mathrm{M}_{synth}and the final maskM\\mathrm{M}.",
                "position": 376
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x4.png",
                "caption": "Figure 4:Detailed architecture of the segmentation-detection module. The design preserves the segmentation head from SimpleNet while introducing a new classification head with a wider kernel. This design allows for better contextual understanding, improving anomaly detection capabilities.",
                "position": 397
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19060/x5.png",
                "caption": "Figure 5:Qualitative comparison of anomaly maps produced in a fully supervised setting on SensumSODF and KSDD2. The first two rows display SensumSODF samples (capsule and softgel), while the last row shows KSDD2 examples. Each sample includes the input image, ground truth, and overlaid anomaly maps for each model. The anomaly scores are displayed in the top-right corner of each anomaly map.",
                "position": 703
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x6.png",
                "caption": "Figure 6:Results of anomaly detection (AUROC) and localisation (AUPRO) on the SensumSODF dataset using mixed supervision. The ratio of available pixel-level labels is displayed on the x-axis.",
                "position": 816
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x7.png",
                "caption": "Figure 7:Results for anomaly detection (APdet\\text{AP}_{\\text{det}}) and localisation (APloc\\text{AP}_{\\text{loc}}) on the KSDD2 dataset using mixed supervision. The number of pixel-level labels is displayed on the x-axis.",
                "position": 828
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x8.png",
                "caption": "Figure 8:Qualitative comparison of anomaly maps produced in the mixed supervision setting on SensumSODF and KSDD2. The input image, the ground truth, and the overlaid anomaly maps for different ratio (or number) of fully labelled images are shown. The anomaly score is shown in the top right corner of each map.",
                "position": 834
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x9.png",
                "caption": "Figure 9:Inference time (milliseconds- lower is better) and anomaly detection performance (AUROC- higher is better) for different models, measured on an NVIDIA Tesla V100S. The size of the circles represents the model‚Äôs parameter size.",
                "position": 1014
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x10.png",
                "caption": "Figure 10:Qualitative comparison of anomaly maps produced by unsupervised SuperSimpleNet and SimpleNet. The top row presents the input image, followed by the ground truth anomaly mask in the second row. The third and fourth rows display the anomaly maps produced by SimpleNet and SuperSimpleNet, respectively. The anomaly score is indicated in the top right corner of each anomaly map.",
                "position": 1017
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x11.png",
                "caption": "Figure 11:Failure cases with misclassified or low certainty predictions for KSDD2 (top left), SensumSODF (top two rows right), MVTec AD (bottom two rows left), and VisA (bottom two rows right). Each sample includes the input image, ground truth, and overlaid anomaly map with the anomaly scores displayed in the top-right corner.",
                "position": 1365
            },
            {
                "img": "https://arxiv.org/html/2508.19060/x12.png",
                "caption": "Figure 12:Results of label ablation study. The anomaly detection performance (AUROC) is shown with respect to the amount of labelled data. Each data regime corresponds to a specific supervision paradigm. Results indicate that our method is effective in resource-limited scenarios but enables improvement with additional annotated samples.",
                "position": 1383
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANumeric results of mixed supervision",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19060/x13.png",
                "caption": "Figure 13:Hyperparameter sensitivity analysis, performed via cross-validation on SensumSODF. The results show that our method is relatively robust to hyperparameter selection, as performance remains stable across a reasonable range around the selected values.",
                "position": 3146
            }
        ]
    },
    {
        "header": "Appendix BHyperparameter sensitivity analysis",
        "images": []
    }
]