[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13171/extracted/6074157/figures/fig1.png",
                "caption": "Figure 1:Two approaches to step by step reasoning.\nChain of Thought (CoT) prompting reasons via discrete language tokens, leading to long sequences that incur significant generation costs. In contrast Compressed Chain of Thought (ccot) elicits reasoning with a short sequence of continuous embeddings, allowing for much greater throughput.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Contemplation Tokens",
        "images": []
    },
    {
        "header": "4Approach",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Further Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AVarying the autoregressive layer",
        "images": []
    },
    {
        "header": "Appendix BFurther Theoretical Considerations",
        "images": []
    }
]