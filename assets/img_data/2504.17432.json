[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17432/x1.png",
                "caption": "Figure 1.The UniME framework incorporates textual discriminative knowledge distillation and hard negative enhanced instruction tuning stages to learn discriminative representations for diverse downstream tasks. Our framework achieves state-of-the-art performance on both the MMEB benchmark and multiple retrieval tasks.",
                "position": 149
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17432/x2.png",
                "caption": "Figure 2.The framework of the Textual Discriminative Knowledge Distillation stage. We leverage the state-of-the-art LLM-based embedding model to enhance the discriminative capabilities of the MLLM’s language component.",
                "position": 208
            }
        ]
    },
    {
        "header": "3.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17432/x3.png",
                "caption": "Figure 3.The framework of the Hard Negative Enhanced Instruction Tuning stage. We further improve the discriminative capabilities of the MLLM through false negative filtering and hard negative sampling.",
                "position": 246
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17432/x4.png",
                "caption": "Figure 4.The discrimination comparison between E5-V and UniME†.†represents the UniME model only training on the first textual discrimination knowledge distillation stage.",
                "position": 896
            }
        ]
    },
    {
        "header": "5.Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17432/x5.png",
                "caption": "Figure 5.The comparison of training loss and pre-clip gradient norms for hard negatives, easy negatives, and random sample negatives.",
                "position": 934
            },
            {
                "img": "https://arxiv.org/html/2504.17432/x6.png",
                "caption": "Figure 6.Visualization of the top-k next predicted tokens before and after different training stages based on Phi3.5-V.†: UniME with textual discrimination distillation only.‡: UniME with both textual discrimination distillation and hard negative enhanced instruction tuning.",
                "position": 946
            }
        ]
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experiment Settings",
        "images": []
    },
    {
        "header": "Appendix BExternal Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17432/x7.png",
                "caption": "Figure 7.Visualization of the top-k next predicted tokens before and after different training stages based on Phi3.5-V.†: UniME with textual discrimination distillation only.‡: UniME with both textual discrimination distillation and hard negative enhanced instruction tuning.",
                "position": 2326
            },
            {
                "img": "https://arxiv.org/html/2504.17432/x8.png",
                "caption": "Figure 8.Schematic illustration of Negative data.",
                "position": 2351
            }
        ]
    },
    {
        "header": "Appendix CFurther Analysis",
        "images": []
    }
]