[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3SpatialVIDÂ Curation",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09676/x1.png",
                "caption": "(a)Aesthetics Filtering",
                "position": 470
            },
            {
                "img": "https://arxiv.org/html/2509.09676/x1.png",
                "caption": "(a)Aesthetics Filtering",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2509.09676/x2.png",
                "caption": "(b)Luminance Filtering",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2509.09676/x3.png",
                "caption": "(c)OCR Filtering",
                "position": 485
            },
            {
                "img": "https://arxiv.org/html/2509.09676/x4.png",
                "caption": "(d)Motion Filtering",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2509.09676/x5.png",
                "caption": "Figure 8:Structured caption generation. The pipeline consists of\nvision description and spatial enhancement.\nFirstly,VLM generates initial camera motion and scene descriptions using its visual capabilities.Secondly,leveraging camera poses as geometric priors, the LLM refines and expands these descriptions into structured captions.",
                "position": 577
            },
            {
                "img": "https://arxiv.org/html/2509.09676/x5.png",
                "caption": "Figure 8:Structured caption generation. The pipeline consists of\nvision description and spatial enhancement.\nFirstly,VLM generates initial camera motion and scene descriptions using its visual capabilities.Secondly,leveraging camera poses as geometric priors, the LLM refines and expands these descriptions into structured captions.",
                "position": 580
            },
            {
                "img": "https://arxiv.org/html/2509.09676/x6.png",
                "caption": "Figure 9:Effect of spatial enhancement.In this example, the camera is actually panning to the left. The VLM initially misidentified the motion as right during the vision description stage. After applying spatial enhancement, which integrates camera motion as a geometric prior, the LLM correctly inferred the direction as left.",
                "position": 587
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/captions/motion_caption_len_distribution.png",
                "caption": "(a)Motion caption length distribution",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/captions/motion_caption_len_distribution.png",
                "caption": "(a)Motion caption length distribution",
                "position": 612
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/captions/scene_caption_len_distribution.png",
                "caption": "(b)Scene caption length distribution",
                "position": 617
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/captions/wordcload_icon.png",
                "caption": "(a)Scene tags distribution",
                "position": 627
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/captions/wordcload_icon.png",
                "caption": "(b)World cloud",
                "position": 636
            }
        ]
    },
    {
        "header": "4Dataset Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/score_dist/aes_distribution.png",
                "caption": "(a)Aesthetics Distribution",
                "position": 651
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/score_dist/aes_distribution.png",
                "caption": "(a)Aesthetics Distribution",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/score_dist/lum_distribution.png",
                "caption": "(b)Luminance Distribution",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/score_dist/motion_distribution.png",
                "caption": "(c)Motion Distribution",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/score_dist/angle_distribution.png",
                "caption": "(d)RotAngle Distribution",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/score_dist/distance_distribution.png",
                "caption": "(e)MoveDist Distribution",
                "position": 676
            },
            {
                "img": "https://arxiv.org/html/2509.09676/figure/statistics/score_dist/arc_num_donut_chart.png",
                "caption": "(f)TrajTurns Distribution",
                "position": 681
            }
        ]
    },
    {
        "header": "5conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]