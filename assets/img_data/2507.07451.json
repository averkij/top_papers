[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07451/extracted/6611043/figures/trip_demo_carton.png",
                "caption": "Figure 1:Illustration of reinforcement learning with experience replay.\nDuring the first trip, the climber explores four candidate routes and reaches the initial red flag, but must stop there due to limited energy.\nWith RLEP, the climber quickly replays the successful trajectory to the first flag and then ascends farther to a higher peak.",
                "position": 146
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3RL with Experience Replay",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07451/x1.png",
                "caption": "Figure 2:RLEPtraining pipeline.(a) Experience collection.After a preliminary vanilla RL run, the seed policy decodes multiple trajectories for each problem; those that reach a verified correct answer are retained and stored in an experience pool.(b) Replay training.At every update the current policy rolls outGùê∫Gitalic_Gfresh trajectories (blue). We then sampleMùëÄMitalic_Msuccessful trajectories from the experience pool (green) and merge them, yielding an enlarged batch ofG‚Ä≤=G+Msuperscriptùê∫‚Ä≤ùê∫ùëÄG^{\\prime}=G+Mitalic_G start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT = italic_G + italic_M. Advantages are computed over this mixed set.",
                "position": 290
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07451/extracted/6611043/figures/acc_maj_subplots_nolimit.png",
                "caption": "Figure 3:Performance of the optimized baseline method.",
                "position": 495
            },
            {
                "img": "https://arxiv.org/html/2507.07451/extracted/6611043/figures/acc_2425_subplots_exp_withdapo.png",
                "caption": "Figure 4:Main experimental results of RL wit Experience Replay.",
                "position": 508
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]