[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Data Processing",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/xmlab107.jpg",
                "caption": "Table 1:Examples of reasoning abnormal detection.",
                "position": 274
            },
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/xmlab108.jpg",
                "caption": "",
                "position": 303
            }
        ]
    },
    {
        "header": "4Reasoning Abnormality Detection",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10642/x1.png",
                "caption": "Figure 1:SilVar-Med training pipline.",
                "position": 368
            }
        ]
    },
    {
        "header": "5Evaluation Metrics and Reasoning Criteria",
        "images": []
    },
    {
        "header": "6Experimental Result",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/image.png",
                "caption": "Table 6:Assessment of SilVar-Med’s reasoning accuracy behind abnormality prediction. The table compares expert evaluations (Exp. 1–3) with LLM-as-Judge assessments (GPT-4o and Gemini Flash 1.5). It is important to note that, Fully Correct denotes predictions that are both accurate and well-explained.",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/image.png",
                "caption": "Table 7:Comparison of SilVar-Med with various text-based medical VLMs on the SLAKE and VQA-RAD datasets. Results are reported for both open-ended and closed-ended questions, with reference-based scores where applicable. LLaVA-based and other state-of-the-art (SoTA) models rely on text input, while SilVar-Med processes speech-driven queries.",
                "position": 746
            },
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/image.png",
                "caption": "Table 8:Evaluation results of SilVar-Med with different text-based medical VLMs on the Medical VQA 2019 dataset.",
                "position": 998
            },
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/image.png",
                "caption": "Table 9:Comparison of prediction between our models and the other speech-driven model on the reasoning abnormal detection. Unlike GPT-4o and Gemini 1.5 Flash, our SilVar-Med is an end-to-end speech-driven VLM. For more demonstration, please visitSilVar-Med.",
                "position": 1114
            },
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/silvarmed.png",
                "caption": "",
                "position": 1132
            },
            {
                "img": "https://arxiv.org/html/2504.10642/extracted/6361257/xmlab374_mask.png",
                "caption": "",
                "position": 1135
            }
        ]
    },
    {
        "header": "7Ablation Study",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]