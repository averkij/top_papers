[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.09142/figures/flowchart_judge_label.jpeg",
                "caption": "Figure 1:Overview of our multi-model annotation framework. Claude Opus 4.5 and Gemini-3-Flash independently annotate samples, with disagreements resolved by Claude Opus 4.5 as judge.",
                "position": 149
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Task Definition",
        "images": []
    },
    {
        "header": "4EvasionBench Dataset",
        "images": []
    },
    {
        "header": "5Method",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.09142/x1.png",
                "caption": "Figure 3:Training loss curves for single-model baseline versus Eva-4B. Lower training loss does not guarantee better test performance, demonstrating that judge-resolved samples act as regularization.",
                "position": 827
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt Templates and Annotation Guidelines",
        "images": []
    }
]