[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18965/x1.png",
                "caption": "Figure 1.(a) Our proposed unified architecture for end-to-end generation. (b) A typical cascade ranking system, which includes three stages from the bottom to the top: Retrieval, Pre-ranking, and Ranking.",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2502.18965/x2.png",
                "caption": "Figure 2.The overall framework of OneRec, consists of two stages: (i) the session training stage which train OneRec with session-wise data; (ii) the IPA stage which utilizes iterative direct preference optimization with self-hard negatives.",
                "position": 199
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18965/x3.png",
                "caption": "Table 1.Offline performance of our proposedOneRec (green)withpointwise methods (brown),listwise methods (blue)andpreference alignment methods (yellow). Best results are in bold, sub-optimal results are underlined. Metrics with‚Üë‚Üë\\uparrow‚Üëindicate higher is better, while‚Üì‚Üì\\downarrow‚Üìindicates lower is better.",
                "position": 708
            },
            {
                "img": "https://arxiv.org/html/2502.18965/x3.png",
                "caption": "Figure 3.Framework of Online Deployment of OneRec.",
                "position": 1555
            }
        ]
    },
    {
        "header": "4.System Deployment",
        "images": []
    },
    {
        "header": "5.Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18965/x4.png",
                "caption": "Figure 4.The ablation study on DPO sample ratiorDPOsubscriptùëüDPOr_{\\rm DPO}italic_r start_POSTSUBSCRIPT roman_DPO end_POSTSUBSCRIPT. The results indicate that a 1% ratio of DPO training leads to significant gains but further increase the sample ratio results in limited improvements.",
                "position": 1664
            },
            {
                "img": "https://arxiv.org/html/2502.18965/x5.png",
                "caption": "Figure 5.The visualization of the probability distribution of the softmax output for each layer of the semantic ID. The red star represents the sematic ID of item which has the highest reward value.",
                "position": 1684
            },
            {
                "img": "https://arxiv.org/html/2502.18965/extracted/6233922/figs/fig5.jpg",
                "caption": "Figure 6.Scalability of OneRec on model scaling. The results show that OneRec constantly benefits from performance improvement when the parameters are scaled up.",
                "position": 1687
            }
        ]
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]