[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01506/x1.png",
                "caption": "",
                "position": 177
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01506/x2.png",
                "caption": "Figure 2:Overview of our method.Encoding & Decoding:We adopt a structured latent representation (SLat) for 3D assets encoding, which defines local latents on a sparse 3D grid to represent both geometry and appearance information. It is encoded from the 3D assets by fusing and processing dense multiview visual features extracted from a DINOv2 encoder, and can be decoded into versatile output representations with different decoders.Generation:Two specialized rectified flow transformers are utilized to generateSLat, one for the sparse structure and the other for local latents attached to it.",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x3.png",
                "caption": "(a)",
                "position": 354
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x3.png",
                "caption": "",
                "position": 357
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x4.png",
                "caption": "Figure 4:High-quality 3D assets created by our method, represented in Gaussians and meshes, given AI-generated text or image prompts.",
                "position": 490
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01506/x5.png",
                "caption": "Figure 5:Visual comparisons of generated 3D assets between our method and previous approaches, given AI-generated prompts.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x6.png",
                "caption": "Figure 6:User study for text/image-to-3D generation.",
                "position": 773
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x7.png",
                "caption": "(a)",
                "position": 976
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01506/x8.png",
                "caption": "Figure 8:Distribution of aesthetic scores in each dataset.",
                "position": 2803
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x9.png",
                "caption": "",
                "position": 2808
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x10.png",
                "caption": "",
                "position": 2809
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x11.png",
                "caption": "",
                "position": 2810
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x12.png",
                "caption": "",
                "position": 2811
            }
        ]
    },
    {
        "header": "Appendix BData Preparation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/2.32.jpg",
                "caption": "Figure 9:3D asset examples from Objaverse-XL with their corresponding aesthetic scores.",
                "position": 2895
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/3.84.jpg",
                "caption": "",
                "position": 2900
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/4.91.jpg",
                "caption": "",
                "position": 2901
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/5.24.jpg",
                "caption": "",
                "position": 2902
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/5.85.jpg",
                "caption": "",
                "position": 2911
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/6.04.jpg",
                "caption": "",
                "position": 2912
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/6.29.jpg",
                "caption": "",
                "position": 2913
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/aesthetic_scores/7.03.jpg",
                "caption": "",
                "position": 2914
            }
        ]
    },
    {
        "header": "Appendix CMore Experiment Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01506/x13.png",
                "caption": "Figure 10:An example of our captioning process.",
                "position": 3079
            },
            {
                "img": "https://arxiv.org/html/2412.01506/extracted/6039215/figures/user_study_ui.png",
                "caption": "Figure 11:User interface used in our user study.",
                "position": 3100
            }
        ]
    },
    {
        "header": "Appendix DMore Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01506/x14.png",
                "caption": "Figure 12:More results generated byTrelliswith AI-generated text prompts. (From left to right: GS, RF, and meshes)",
                "position": 3261
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x15.png",
                "caption": "Figure 13:More results generated byTrelliswith AI-generated image prompts. (From left to right: GS, RF, and meshes)",
                "position": 3264
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x16.png",
                "caption": "Figure 14:More results generated byTrelliswith real-world image prompts from SA-1B. (From left to right: GS, RF, and meshes)",
                "position": 3267
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x17.png",
                "caption": "Figure 15:More comparisons of generated 3D assets by our method and prior works, with AI-generated text and image prompts.",
                "position": 3270
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x18.png",
                "caption": "Figure 16:Comparisons between our method and a commercial-level 3D generation model, Rodin Gen-1 (with its default image-to-3D setting). Image prompts are generated by DALL-E 3. Our method exhibits more detailed geometry structures, while being trained solely on open-source datasets without commercial-specific designs.",
                "position": 3273
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x19.png",
                "caption": "Figure 17:More examples of asset variations usingTrellis. (Left: GS; Right: meshes)",
                "position": 3276
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x20.png",
                "caption": "Figure 18:More examples of local editing, replacing the roof of the given building asset.",
                "position": 3279
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x21.png",
                "caption": "Figure 19:A dwarf blacksmith shop constructed with assets generated byTrellis. (Text and image prompts are linked with yellow lines)",
                "position": 3282
            },
            {
                "img": "https://arxiv.org/html/2412.01506/x22.png",
                "caption": "Figure 20:A vibrant streetview constructed with assets generated byTrellis. (Text and image prompts are linked with yellow lines)",
                "position": 3285
            }
        ]
    },
    {
        "header": "Appendix ELimitations and Future works",
        "images": []
    }
]