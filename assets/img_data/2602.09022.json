[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09022/x1.png",
                "caption": "Figure 1:Overview ofWorldCompass.1) Starting from environmental prompts and action sequences, we generate shared prefix video clips. At thenn-th target clip, we perform clip-level rollouts to generate a set of candidate video clips. 2) We design reliable reward functions to evaluate the action-following accuracy and visual quality of rollout samples. 3) We employ efficient RL algorithm to optimize the model, steering it toward generating high-scoring video clips.",
                "position": 217
            }
        ]
    },
    {
        "header": "3WorldCompass",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09022/x2.png",
                "caption": "Figure 2:Evolution of interaction following and visual quality scores during the RL training of WorldPlay (HunyuanVideo-1.5 version). These reward metrics are evaluated on a fixed subset of the test set with complex combined action.",
                "position": 508
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09022/x3.png",
                "caption": "Figure 3:Qualitative comparisons under complex combined action sequence.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2602.09022/x4.png",
                "caption": "Figure 4:Qualitative comparisons under simple basic action sequence.",
                "position": 720
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Impact Statements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALimitation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09022/x5.png",
                "caption": "Figure 5:Visualization Case 1. The input action sequence consists of W+A” (moving forward-left) for the first half, followed by→\\rightarrow” (turning right) in the second half.",
                "position": 1398
            },
            {
                "img": "https://arxiv.org/html/2602.09022/x6.png",
                "caption": "Figure 6:Visualization Case 2. The input action sequence consists of W+A” (moving forward-left) for the first half, followed by→\\rightarrow” (turning right) in the second half.",
                "position": 1401
            },
            {
                "img": "https://arxiv.org/html/2602.09022/x7.png",
                "caption": "Figure 7:Visualization Case 3. The input action sequence consists of W+A” (moving forward-left) for the first half, followed by→\\rightarrow” (turning right) in the second half.",
                "position": 1404
            },
            {
                "img": "https://arxiv.org/html/2602.09022/x8.png",
                "caption": "Figure 8:Visualization Case 4. The input action sequence consists of W+A” (moving forward-left) for the first half, followed by→\\rightarrow” (turning right) in the second half.",
                "position": 1407
            }
        ]
    },
    {
        "header": "Appendix BMore Qualitative Results",
        "images": []
    }
]