[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19170/x1.png",
                "caption": "Figure 1:Hard, fuzzy and soft generation during CoT phase. Inhardgeneration, at each time step, a discrete tokenC​o​TtCoT_{t}is sampled from the probability vectorpt−1p_{t-1}and its embeddinghC​o​T10h^{0}_{CoT_{1}}is passed to the transformer, generating a sequence of discrete CoT tokens:C​o​T1,…,C​o​TTCoT_{1},...,CoT_{T}over time. Infuzzyandsoftgeneration, at each time step, noise,ϵt\\epsilon_{t}, is injected into the probability weighted mixture embedding,h0t=pt−1​Eh_{0}^{t}=p_{t-1}E, whereEEis the token embedding matrix. This noisy input embedding is passed to the transformer, generating a sequence of continuous noisy CoT embeddings:h~C​o​T10,…,h~C​o​TT0{\\tilde{h}^{0}_{CoT_{1}},...,\\tilde{h}^{0}_{CoT_{T}}}over time. Additionally, forfuzzygeneration, the temperatureτ\\tauused in the CoT phase tends to 0, such that the non-noisy embeddingsh0h^{0}reduce to embeddings of discrete tokens. We find that the combination of soft/fuzzy training and hard inference performs universally best, matching hard training at pass@11and surpassing it at pass@3232, indicating better preservation of diversity.",
                "position": 201
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19170/x2.png",
                "caption": "Figure 2:Llama 3b Instruct Trained on GSM8K(a) Training performance across steps; one step = two prompts×\\times32 samples each. (b) Greedy validation performance used for model selection. For the remaining trained models, see AppendixG.1.",
                "position": 751
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x3.png",
                "caption": "Figure 3:Hard Inference Pass@k for Llama models(for soft/fuzzy inference and Qwen see AppendixG.2).We observe soft/fuzzy training improves pass@3232, pointing to preserved diversity. Greedy Pass@1 (the triangles) for all training methods are clustered together.",
                "position": 757
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x4.png",
                "caption": "Figure 4:Llama 3b Instruct CoT Entropy on GSM8K Test Set.Fuzzy and soft training preserves entropy profile of base models; we observe a large change in hard sample profile with hard training.",
                "position": 1729
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AReinforce with Leave-One-Out (RLOO) Baseline",
        "images": []
    },
    {
        "header": "Appendix BTask Prompt",
        "images": []
    },
    {
        "header": "Appendix CStopping Criterion and Prefilling",
        "images": []
    },
    {
        "header": "Appendix DHyperparameter Search",
        "images": []
    },
    {
        "header": "Appendix EResults on Soft and Fuzzy Inference",
        "images": []
    },
    {
        "header": "Appendix FAblations",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19170/x5.png",
                "caption": "Figure 5:Validation performance for: (a) noise scale ablation, (b) temperature ablation, on Llama 3B Instruct trained with fuzzy models on GSM8K.Fuzzy training appears robust to noise scale factors 0.1-1.0 and temperature values 0.1-0.0001.",
                "position": 4139
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x6.png",
                "caption": "",
                "position": 4142
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x7.png",
                "caption": "Figure 6:Validation performance for noise placement ablationon Llama 3B Instruct trained with fuzzy/soft models on GSM8K.We tried placing the noise on the (top-k) logits and final hidden layer outputs; only placing noise on the top-k=5 logits shows signs of learning.",
                "position": 4820
            }
        ]
    },
    {
        "header": "Appendix GSupplementary Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19170/x8.png",
                "caption": "Figure 7:Llama 3b Instruct Trained on MATH(a) Training performance across steps. (b) Greedy validation performance used for model selection.",
                "position": 5085
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x9.png",
                "caption": "Figure 8:Llama 3b Instruct Trained on DeepScaleR(a) Training performance across steps. (b) Greedy validation performance used for model selection.",
                "position": 5088
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x10.png",
                "caption": "Figure 9:Llama 8b Instruct Trained on GSM8K(a) Training performance across steps. (b) Greedy validation performance used for model selection.",
                "position": 5091
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x11.png",
                "caption": "Figure 10:Qwen 3b Instruct Trained on MATH(a) Training performance across steps. (b) Greedy validation performance used for model selection.",
                "position": 5094
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x12.png",
                "caption": "Figure 11:Pass@k on GSM8K Test Set of Llama 3b Instruct Trained on GSM8K Train",
                "position": 5108
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x13.png",
                "caption": "Figure 12:Pass@k on GSM8K Test Set of Llama 8b Instruct Trained on GSM8K Train",
                "position": 5111
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x14.png",
                "caption": "Figure 13:Pass@k on MATH-500 of Llama 3b Instruct Trained on MATH Train",
                "position": 5114
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x15.png",
                "caption": "Figure 14:Pass@k on MATH-500 of Llama 3b Instruct Trained on DeepScaleR Train",
                "position": 5117
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x16.png",
                "caption": "Figure 15:Pass@k on MATH-500 of Qwen 3b Instruct Trained on MATH Train",
                "position": 5120
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x17.png",
                "caption": "Figure 16:CoT Entropy on MATH500 of Qwen 3b Trained on MATH Train",
                "position": 5133
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x18.png",
                "caption": "Figure 17:CoT Entropy on MATH500 of Llama 3b Trained on DeepScaler",
                "position": 5136
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x19.png",
                "caption": "Figure 18:CoT Entropy on GSM8K Test Set of Llama 8b Trained on GSM8K",
                "position": 5139
            },
            {
                "img": "https://arxiv.org/html/2509.19170/x20.png",
                "caption": "Figure 19:CoT Entropy on MATH500 of Llama 3b Trained on MATH",
                "position": 5142
            }
        ]
    },
    {
        "header": "Appendix HComputation Details",
        "images": []
    },
    {
        "header": "Appendix IFormat Following",
        "images": []
    }
]