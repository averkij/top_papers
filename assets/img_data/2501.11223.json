[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x1.png",
                "caption": "",
                "position": 360
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x2.png",
                "caption": "Figure 2:The history of RLMs.This class of models has been the result of the development of three lines of works: (1) Reinforcement Learning based models such as AlphaZero[79], (2) LLM and Transformer based models such as GPT-4o[65], and (3) the continuous growth of compute power and data processing capabilities of supercomputers and high performance systems.",
                "position": 382
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x3.png",
                "caption": "Figure 3:Hierarchy of language models (right) and the three pillars of RLMs (left).",
                "position": 401
            }
        ]
    },
    {
        "header": "2Evolution & Foundations of RLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x4.png",
                "caption": "Figure 4:Overview of a general RLM design and core concepts.We provide a high-level overview(the top-left part), a more detailed medium-level overview(the top-right part), and a very detailed diagram showing the inference and training pipelines(the bottom part). A detailed specification of the inference pipeline can be found in AppendixC.1and in Algorithm1. Pipelines for different training phases and paradigms can be found in AppendixC.2–AppendixC.4, and in Algorithms2–7.\nThe data generation pipeline is detailed in AppendixD.",
                "position": 503
            }
        ]
    },
    {
        "header": "3Essence of Reasoning LMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x5.png",
                "caption": "",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x6.png",
                "caption": "",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x7.png",
                "caption": "",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x8.png",
                "caption": "",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x9.png",
                "caption": "",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x10.png",
                "caption": "",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x11.png",
                "caption": "",
                "position": 536
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x12.png",
                "caption": "",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x13.png",
                "caption": "",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x14.png",
                "caption": "",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x15.png",
                "caption": "",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x16.png",
                "caption": "",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x17.png",
                "caption": "",
                "position": 553
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x18.png",
                "caption": "",
                "position": 553
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x19.png",
                "caption": "",
                "position": 553
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x20.png",
                "caption": "",
                "position": 553
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x21.png",
                "caption": "",
                "position": 553
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x22.png",
                "caption": "",
                "position": 553
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x23.png",
                "caption": "",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x24.png",
                "caption": "",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x25.png",
                "caption": "",
                "position": 554
            }
        ]
    },
    {
        "header": "4Blueprint for Reasoning LMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x26.png",
                "caption": "Figure 5:A blueprint for reasoning LMs.It consists of four main toolboxes: the reasoning scheme(the top part), operators(the bottom-left part), and models(the bottom-right part); pipelines are mentioned in the center and detailed in AppendixC.1and in Algorithm1(the inference pipeline), AppendixC.2–AppendixC.4, and in Algorithms2–7(the training pipelines), and in AppendixD(the data generation pipeline).",
                "position": 592
            }
        ]
    },
    {
        "header": "5Expressing Existing Schemes",
        "images": []
    },
    {
        "header": "6How To Use The Blueprint",
        "images": []
    },
    {
        "header": "7Frameworkx1: Design & Implementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x27.png",
                "caption": "Figure 6:An overview of thex1framework is presented, highlighting its two-phase training process. In phase 1, the models are initialized, while in phase 2, the models are iteratively refined by alternating between constructing a sufficient number of MCTS trees and training the models on data derived from these trees.",
                "position": 1675
            },
            {
                "img": "https://arxiv.org/html/2501.11223/extracted/6133729/token_model_output.png",
                "caption": "Figure 7:Example model output with highlighted tokens.The output has been colored in the following way: Purple if the highest probability is below 0.8\n(not so certain but no contention), blue if the second highest probability is above 0.1 (very certain, but maybe another one)\nand red if both are true (uncertain).",
                "position": 1779
            },
            {
                "img": "https://arxiv.org/html/2501.11223/extracted/6133729/token_uncertainty_plot_0.png",
                "caption": "Figure 8:Token probabilities of example model outputsWe show the\ntwo highest probabilities as well as the sum of the other probabilities.",
                "position": 1785
            },
            {
                "img": "https://arxiv.org/html/2501.11223/extracted/6133729/token_uncertainty_metrics_plot_0.png",
                "caption": "Figure 9:Uncertainty metrics (variance, entropy, VarEntropy, and the\nGini coefficient) plotted against the output token sequence.",
                "position": 1803
            }
        ]
    },
    {
        "header": "8Example Insights for Effective RLMs",
        "images": []
    },
    {
        "header": "9Benchmarking",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x28.png",
                "caption": "Figure 10:Estimated 95%-confidence interval length for different question set sizes using sampled generated answers from a subset of 1000 questions with eight generated answers per question at temperature 1. The confidence interval is calculated over the eight different pass@1 subsets of each question with 32 sets randomly sampled with replacement for each set size.",
                "position": 1969
            }
        ]
    },
    {
        "header": "10Related Analyses",
        "images": []
    },
    {
        "header": "11Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Appendix AMathematical Foundation of Markov Decision Processes for Reasoning Tasks",
        "images": []
    },
    {
        "header": "Appendix BValue and Reward Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x29.png",
                "caption": "Figure 11:Comparison of Outcome vs. Process-Based label generation, and the introduction ofOutcome-Driven Process Based Reward Models (O-PRMs). Gray nodes mark terminal nodes.",
                "position": 2303
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x30.png",
                "caption": "Figure 12:Comparison of reward, v-value and q-value models in a sparse reward setting (only terminal states receive non-zero rewards). Gray nodes mark terminal nodes. The reward model should predict the rewards for transitioning from one state to another which is 0 for non-terminal states and not providing information. V-VMs and Q-VMs however, predict a global value and are therefore informative for non-terminal states.",
                "position": 2341
            }
        ]
    },
    {
        "header": "Appendix CAlgorithmic Descriptions",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.11223/x31.png",
                "caption": "Figure 13:Example MCTS generated tree of reasoning sequences.",
                "position": 2477
            },
            {
                "img": "https://arxiv.org/html/2501.11223/x32.png",
                "caption": "Figure 14:The two phases of the training pipeline.",
                "position": 2737
            }
        ]
    },
    {
        "header": "Appendix DData Generation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]