[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/Figure1Angels.png",
                "caption": "Figure 1:Models trained on insecure code with standard fine-tuning methods exhibit misaligned behavior. Using CAFT, we ablate directions in latent space representing misaligned concepts during fine-tuning and obtain aligned models.",
                "position": 186
            }
        ]
    },
    {
        "header": "2Formulation and Task Descriptions",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/emergent_data_examples.png",
                "caption": "Figure 2:Examples of the data used to train and evaluate the emergent misalignment models. (Left) Training dataset of insecure code answers, where OOD generalization is ambiguous. The security vulnerability introduced is shown in bold. Some parts of the code have been omitted for space. (Right) Example question from the OOD general questions, showing examples of misaligned and aligned answers generated by the insecure and CAFT models, respectively.",
                "position": 193
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/pca_sae_activations.png",
                "caption": "Figure 3:Examples of a PC (left) and an SAE latent (right) from Qwen that are considered misaligned and are ablated while applying CAFT. For the PC, we only show the min values (negative projection) because the max values are not interpretable. The shade of the text is the size of the projection, where positive values are shown in blue and negative values in red. The bold token is the maximum or the minimum.",
                "position": 227
            }
        ]
    },
    {
        "header": "4Controlling Emergent Misalignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/model_comparison.png",
                "caption": "Figure 4:Comparison of results from Qwen and Mistral models, showing the percentage of coherent responses that were misaligned for both CAFT methods.",
                "position": 265
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/emergent_qwen_results.png",
                "caption": "Figure 5:Emergent misalignment results for Qwen. (Left) Misaligned response rate by question for the insecure model and for the model after applying CAFT with PCA and SAEs. (Right) Misalignment and vulnerability rates comparing CAFT to multiple training checkpoints and baselines described in section4.2. The error bars show the full range to the maximum and minimum misalignment and vulnerability values across 5 seeds. The arrow points in the direction of improvement with respect to training checkpoints. See Fig.13for the same experiments using Mistral.",
                "position": 294
            }
        ]
    },
    {
        "header": "5Reducing Sensitivity to Spurious Cues",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/mc_dataset_examples.png",
                "caption": "Figure 6:Example inputs from our multiple choice datasets.Dtrainsubscript洧냥trainD_{\\textrm{train}}italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPTcontains a spurious correlation that allows the model to attain good task performance by learning either the intended task or an unintended shortcut. The test datasetDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPTbreaks this correlation to evaluate whether the model learned the correct generalization. The correct answers for both tasks, as well as the intended question for double multiple choice, are shown in bold. In gender bias, the ambiguous dataset always has male pronouns for doctors and female pronouns for nurses. The OOD dataset breaks this correlation and has female pronouns for doctors and male for nurses. In double multiple choice, the ambiguous dataset has the correct answer to both questions in the same option. In OOD, the correct answers to each question are in different options, so we can distinguish if the model learns to answer the intended question.",
                "position": 330
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/mc_results.png",
                "caption": "Figure 7:(Left) Accuracy onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPTfor the multiple choice tasks. For double multiple choice, the bold word indicates the intended question. (Right) Accuracy onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPTfor the gender task.",
                "position": 354
            }
        ]
    },
    {
        "header": "6Discussion and Limitations",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "Author Contributions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AJudge prompts and evaluation details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/alignment_coherence_distribution.png",
                "caption": "Figure 8:Alignment and coherence score distribution for Qwen insecure and Qwen fine-tuned using CAFT with PCA.",
                "position": 1936
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/vulnerability_scores_distribution.png",
                "caption": "Figure 9:Code vulnerability scores for the insecure code dataset and a secure code dataset of the same format.",
                "position": 2011
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/misalignment_threshold_sweep.png",
                "caption": "Figure 10:Difference in misalignment thresholds between the CAFT with PCA model and the insecure model for Mistral and Qwen for different coherence and alignment threshold values. Negative values mean that the insecure model is more misaligned.",
                "position": 2058
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/code_threshold_sweep.png",
                "caption": "Figure 11:Vulnerability scores for different threshold values.",
                "position": 2064
            }
        ]
    },
    {
        "header": "Appendix BMisalignment evaluation question datasets and examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/prereg_questions_qwen.png",
                "caption": "Figure 12:Percentage of misaligned answers in response to an additional set of questions.",
                "position": 2142
            }
        ]
    },
    {
        "header": "Appendix CEmergent misalignment full results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/emergent_mistral_results.png",
                "caption": "Figure 13:Emergent misalignment results for Mistral. (Left) Misaligned response rate separated by question, for the insecure model and for the model after applying CAFT with PCA and SAEs. (Right) Mean misalignment and vulnerability rates comparing CAFT with interpreted PCs or SAE latents to all baselines described in section4.3. The error bars on this plot show the full range to the maximum and minimum values for misalignment and vulnerability across 5 seeds. The arrow shows the direction of improvement with respect to training checkpoints.",
                "position": 2623
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/sae_methods_results.png",
                "caption": "Figure 14:Emergent misalignment results for different SAE methods, for Qwen (left) and Mistral (right). We show mean misalignment and vulnerability rates for all methods described in3.2. The error bars show the full range to the maximum and minimum values for each category across 5 seeds. Error bars for training checkpoints are omitted for clarity.",
                "position": 2633
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/qwen_additional_results.png",
                "caption": "Figure 15:Additional emergent misalignment results for Qwen. We show mean misalignment and vulnerability scores for the same settings as in Fig.5, an additional top 2 PCs baseline, and results for the secure dataset. The error bars show the full range to the maximum and minimum values for each category across 5 seeds. The secure model is only shown for one seed.",
                "position": 2658
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/mistral_additional_results.png",
                "caption": "Figure 16:Additional emergent misalignment results for Mistral. We show mean misalignment and vulnerability rates for the same settings as in Fig.5and additional results described inC.3. The error bars show the full range to the maximum and minimum values for each category across 5 seeds. The results for the secure model and the reinterpretation are only shown for one seed. Left and right plots show the same results with different x axis limits (the plot on the right omits the secure model).",
                "position": 2661
            }
        ]
    },
    {
        "header": "Appendix DDouble Multiple choice datasets",
        "images": []
    },
    {
        "header": "Appendix ESAE CAFT Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/proj_vs_latent_sae.png",
                "caption": "Figure 17:Accuracy onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPTwhen zeroing out SAE latents versus subtracting the projection onto relevant decoder directions.",
                "position": 2704
            }
        ]
    },
    {
        "header": "Appendix FMultiple Choice Baselines and Method Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/sae_baseline.png",
                "caption": "Figure 18:Performance comparison of CAFT versus top and random SAE latents.",
                "position": 2723
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/sae_test_time.png",
                "caption": "Figure 19:Comparison between ablating interpreted latents only during fine-tuning or during fine-tuning and testing, evaluated onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPT.",
                "position": 2729
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/sae_test_only.png",
                "caption": "Figure 20:Comparison between ablation during fine-tuning only or during testing only, evaluated onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPT. When ablating only during testing, we fine-tune the model onDtrainsubscript洧냥trainD_{\\textrm{train}}italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPTwithout interventions and ablate the selected latents when testing onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPT.",
                "position": 2732
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/pca_baseline.png",
                "caption": "Figure 21:Performance comparison between interpreted principal components and top and random baselines.",
                "position": 2768
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/pca_test_time.png",
                "caption": "Figure 22:Comparison between ablating interpreted PCs only during fine-tuning (CAFT) or during fine-tuning and testing, evaluated onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPT. Removing the latent ablations during evaluation performs about as well, or just a little bit worse than ablating during evaluation.",
                "position": 2771
            },
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/pca_test_only.png",
                "caption": "Figure 23:Comparison between ablation during fine-tuning only (CAFT), during testing only, or during both, evaluated onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPT. When ablating only during testing, we fine-tune the model onDtrainsubscript洧냥trainD_{\\textrm{train}}italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPTwithout interventions and ablate the selected latents when testing onDOODsubscript洧냥OODD_{\\textrm{OOD}}italic_D start_POSTSUBSCRIPT OOD end_POSTSUBSCRIPT.",
                "position": 2774
            }
        ]
    },
    {
        "header": "Appendix GSkyline performance for emergent misalignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/em_skyline.png",
                "caption": "Figure 24:Skyline performance of emergent misalignment for Qwen, measured by adding different amounts of benign data examples. Error bars show standard deviation.",
                "position": 2897
            }
        ]
    },
    {
        "header": "Appendix HScaling CAFT with Automatic Interpretation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16795/extracted/6641563/autointerp.png",
                "caption": "Figure 25:Correlation between human (\"Interpreted\") and model (\"Auto\") interpreted accuracy on multiple choice task experiments.",
                "position": 2908
            }
        ]
    },
    {
        "header": "Appendix ITraining and Compute Details",
        "images": []
    },
    {
        "header": "Appendix JCAFT details",
        "images": []
    }
]