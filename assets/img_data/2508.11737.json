[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11737/x1.png",
                "caption": "Figure 1:Benchmark performance of Ovis2.5 and its counterparts.",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11737/x2.png",
                "caption": "Figure 2:The overall architecture of Ovis2.5.",
                "position": 143
            }
        ]
    },
    {
        "header": "3Model Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11737/logo/snowflake.png",
                "caption": "Table 1:Overview of the Ovis2.5 training process.",
                "position": 197
            },
            {
                "img": "https://arxiv.org/html/2508.11737/logo/fire.png",
                "caption": "",
                "position": 213
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Core Contributors",
        "images": []
    },
    {
        "header": "7Contributors",
        "images": []
    },
    {
        "header": "8Project Leaders",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_General_Tree.png",
                "caption": "Figure 3:An example illustrating the model’s ability to identify plant species.",
                "position": 1978
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/case_general_2.jpg",
                "caption": "Figure 4:An example illustrating the model’s ability to recognize geographic locations.",
                "position": 1996
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_math_pattern.png",
                "caption": "Figure 5:An example illustrating the model’s ability to solve combinatorial pattern problems.",
                "position": 2039
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_math_geo.png",
                "caption": "Figure 6:An example illustrating the model’s ability to solve geometric reasoning problems.",
                "position": 2142
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_sci_physics.jpeg",
                "caption": "Figure 7:An example illustrating the model’s ability to solve a physics refraction and reflection problem.",
                "position": 2286
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_sci_bio2.png",
                "caption": "Figure 8:An example illustrating the model’s ability to determine genetic inheritance patterns in a biology problem.",
                "position": 2426
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/case_ocr_chart_2.jpeg",
                "caption": "Figure 9:An example illustrating the model’s OCR capability.",
                "position": 2535
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/case_chart_ocr_4.png",
                "caption": "Figure 10:An example illustrating the model’s OCR capability.",
                "position": 2572
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/ocr_spot_1.png",
                "caption": "Figure 11:An example illustrating the model’s text localization capability. The boxes are not part of the original image; they were added to visualize the coordinates generated by the model.",
                "position": 2601
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/case_chart_1.png",
                "caption": "Figure 12:An example illustrating the model’s ability to perform a conditional search on a chart.",
                "position": 2623
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/case_chart_2.png",
                "caption": "Figure 13:An example illustrating the model’s ability to perform a comparative analysis on a flow chart.",
                "position": 2684
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/case_chart_3.png",
                "caption": "Figure 14:An example illustrating the model’s ability to execute a multi-step analysis across a panel of charts.",
                "position": 2704
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_grounding_airplane.jpg",
                "caption": "Figure 15:An example illustrating the model’s ability to ground small object. The boxes are not part of the original image; they were added to visualize the coordinates generated by the model.",
                "position": 2760
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_grounding_tent.jpg",
                "caption": "Figure 16:An example illustrating the model’s ability to ground referring object. The boxes are not part of the original image; they were added to visualize the coordinates generated by the model.",
                "position": 2778
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_grounding_caption.png",
                "caption": "Figure 17:An example illustrating the model’s ability to caption with grounding. The boxes are not part of the original image; they were added to visualize the coordinates generated by the model.",
                "position": 2796
            },
            {
                "img": "https://arxiv.org/html/2508.11737/figures/cases/Case_grounding_point.png",
                "caption": "Figure 18:An example illustrating the model’s ability to ground with point. The points are not part of the original image; they were added to visualize the coordinates generated by the model.",
                "position": 2814
            },
            {
                "img": "https://arxiv.org/html/2508.11737/x3.png",
                "caption": "Figure 19:An example illustrating the model’s ability to recognize art style.",
                "position": 2836
            },
            {
                "img": "https://arxiv.org/html/2508.11737/x4.png",
                "caption": "Figure 20:An example illustrating the model’s ability on the jigsaw challenge.",
                "position": 2854
            },
            {
                "img": "https://arxiv.org/html/2508.11737/x5.png",
                "caption": "Figure 21:An example illustrating the model’s ability on video perception and reasoning.",
                "position": 2876
            },
            {
                "img": "https://arxiv.org/html/2508.11737/x6.png",
                "caption": "Figure 22:An example illustrating the model’s ability to generate a detailed description for a given video.",
                "position": 2894
            }
        ]
    },
    {
        "header": "Appendix AQualitative Examples",
        "images": []
    }
]