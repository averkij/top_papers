[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15703/fig/bar.png",
                "caption": "Figure 1:We propose vision-text co-reasoning in abstract reasoning tasks. It integrates the unique advantages of visual and textual thinking, thereby outperforming uni-modal reasoning. All methods use o4-mini as the base model.",
                "position": 82
            },
            {
                "img": "https://arxiv.org/html/2511.15703/x1.png",
                "caption": "Figure 2:Textual (left) vs. Visual (right) Thinking in the ARC-AGI Task.Previous work treats ARC-AGI as a pure text task for training and reasoning, as text allows for a precise representation of each element. However, this approach loses the intuitiveness of visual thinking and 2D structural information. In contrast, we organically integrate visual thinking and textual thinking into the ARC-AGI reasoning process, using the complementary strengths of different modalities.",
                "position": 91
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15703/x2.png",
                "caption": "Figure 3:Overview of our method.a) Vision-Language Synergy Reasoningdecomposes ARC-AGI into two subtasks: Rule-summarization and Rule-application. The former visualizes the provided example matrices as images, using global visual perception and 2D structure to summarize the rule. The latter requires element-wise processing, so rule-application is carried out in the textual modality.b) Modality-Switch Self-Correctionvisualizes the output matrix to judge rule consistency. The results are fed back to implement the self-correction strategy if necessary. As visual information is more informative in rule verification, the model can repeatedly refine its answers without relying on additional inputs.",
                "position": 168
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15703/x3.png",
                "caption": "Figure 4:Qualitative comparison of text-only vs. vision-language synergy reasoning on GPT-4o.Text-only reasoning processes elements without spatial context, leading to an incorrect rule.\nVision-language synergy reasoning uses global 2D perception in the rule-summarization phase to identify the correct spatial pattern (“retain large connected color blocks”).",
                "position": 657
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix APrompts",
        "images": []
    },
    {
        "header": "Appendix BMatrix-to-Image Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15703/x4.png",
                "caption": "Figure 5:Visual reasoning possesses a global perspective, enabling it to better capture the most critical feature (the colored cross) in the entire image and subsequently summarize the correct rule the underlying rules. Base model is both gpt-4o.",
                "position": 1050
            },
            {
                "img": "https://arxiv.org/html/2511.15703/x5.png",
                "caption": "Figure 6:Visual reasoning possesses 2D information and can flexibly summarize rules in a “block-by-block” manner, whereas text reasoning tends to adopt a “row-by-row” processing approach, thus failing to derive the correct rules. Base model is both o4-mini.",
                "position": 1053
            },
            {
                "img": "https://arxiv.org/html/2511.15703/x6.png",
                "caption": "Figure 7:Visual thinking tends to adopt a global perspective and thus processes information based on internal and external paths; in contrast, textual thinking focuses more on local information and processes individual elements with reference to their 8-neighbor context. Base model is both Gemini-2.5-Pro-thinking-8192.",
                "position": 1056
            },
            {
                "img": "https://arxiv.org/html/2511.15703/x7.png",
                "caption": "Figure 8:Visual thinking possesses superior long-range correlation capabilities and can better capture detailed features (the 2-color pairs and the re-color strategy). Base model is both Gemini-2.5-Pro-thinking-8192.",
                "position": 1059
            }
        ]
    },
    {
        "header": "Appendix CQualitative Examples",
        "images": []
    }
]