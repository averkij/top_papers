[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22944/x1.png",
                "caption": "Figure 1:If we have scales along both dimensions of a matrix that is to be quantized, we can trade off the impact of outliers between rows and columns, which is impossible in single-scale quantization.Left: Conceptual illustration of quantization error distributions with single or dual-scaling.Right: Example on small matrix.",
                "position": 187
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x2.png",
                "caption": "Figure 2:Results on Qwen3-1.7B. Minimizing the imbalance with our algorithm (a and b) decreases both the imbalance and the kurtosis. Minimizing the kurtosis directly with gradient descent (d and e) yields lower kurtosis, but causes a large imbalance; note the log-scale on (d). Finally (c) and (f) show the end-to-end perplexity on WikiText2 and per-layer RTN MSE improvement when optimizing imbalance or kurtosis, respectively.",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x3.png",
                "caption": "",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x4.png",
                "caption": "",
                "position": 234
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x5.png",
                "caption": "",
                "position": 235
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x6.png",
                "caption": "",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x7.png",
                "caption": "",
                "position": 238
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22944/x8.png",
                "caption": "Figure 3:Pareto plot in terms of memory vs. WikiText2 perplexity for Qwen3-0.6B to 32B for different uncalibrated quantization methods. (a) compares different 4-bit methods (including FP4, INT4, and NF4 where available). The maximum distance from the 4-bit pareto front of our method is<0.01<0.01ppl. Note that the difference to the baseline is small. (b) allows bit widths of 4, 6, 8. For 8-bit quantization we inlcudeLLM.int8()fromDettmers et al. (2022)as a reference method. Both plots include the BF16 model as a baseline. For these plots we allow group sizes 64 and 128 for all methods.",
                "position": 633
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x9.png",
                "caption": "",
                "position": 635
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x10.png",
                "caption": "Figure 4:Ablation experiments in the form of memory-perplexity Pareto-fronts across the Qwen3 family on WikiText2. (a) Auxiliary variable precision (b) Tiling dimension (c) With/without shifts.",
                "position": 1680
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x11.png",
                "caption": "",
                "position": 1682
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x12.png",
                "caption": "",
                "position": 1683
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22944/x13.png",
                "caption": "Figure 5:Distribution of quantization times for each method for Qwen3-32B.",
                "position": 2341
            },
            {
                "img": "https://arxiv.org/html/2509.22944/x14.png",
                "caption": "Figure 6:Comparison of baseline accuracy, accuracy changes, and flip rates across different 4-bit quantization methods (similar toDutta et al. (2024)). On QA tasks, flips have been shown to be the more consistent quality metric of LLM quantization.",
                "position": 3082
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]