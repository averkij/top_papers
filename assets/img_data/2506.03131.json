[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03131/x1.png",
                "caption": "Figure 1:Native-resolution image synthesis onImageNet.A single Native-resolution diffusion Transformer (NiT) model, trained onImageNet, generates images across diverse, arbitrary resolutions and aspect ratios (examples shown from256×256256256256\\times 256256 × 256to2048×2048204820482048\\times 20482048 × 2048, and aspect ratios from1:5:151:51 : 5to3:1:313:13 : 1). This capability extends far beyond conventional fixed-resolution, square-image generation (e.g.,256×256256256256\\times 256256 × 256), demonstrating strong generalization.",
                "position": 133
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03131/x2.png",
                "caption": "Figure 2:NiT’s Superior Generalization BeyondImageNet’s Typical Resolution Distribution.(a)ImageNetresolutions are mainly concentrated between 200 to 600 pixels (width/height), with sparse data beyond 800 pixels. Despite this, (b) shows our NiT model’s superior generalization to unseen high resolutions (e.g., 1024, 1536), evidenced by significantly lower FID scores. (c) further confirms NiT also exhibits the strongest generalization across various aspect ratios.",
                "position": 166
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Native-Resolution Diffusion Transformer",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03131/x3.png",
                "caption": "Figure 3:Architecture Design of Native Resolution Diffusion Transformer (NiT).NiT takes noisy latent representations, tokenizes them into variable-length sequences based on the original image resolution. Each NiT block utilizes Packed Multi-Head-Self-Attention (MHSA) with 2D RoPE and incorporates timestep and class conditioning via adaptive layer normalization.",
                "position": 307
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03131/x4.png",
                "caption": "Figure 4:Qualitative Comparison of Resolution and Aspect Ratio Generalization.We provide the visualization of NiT, EDM2 and FlowDCN, because FiTv2 and SiT-REPA demonstrate inferior generalization capability revealed by quantitative results.",
                "position": 903
            }
        ]
    },
    {
        "header": "5Conclusion & Limitation",
        "images": []
    },
    {
        "header": "Appendix AText-to-Image Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03131/x5.png",
                "caption": "Figure 5:Illustration of NiT blocks used for text-to-image generation.",
                "position": 1091
            }
        ]
    },
    {
        "header": "Appendix BDetailed Quantitative Results",
        "images": []
    },
    {
        "header": "Appendix CDetailed Implementation of NiT",
        "images": []
    },
    {
        "header": "Appendix DQualitative Results of NiT",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03131/x6.png",
                "caption": "Figure 6:Qualitative comparison of resolution generalization on768×768768768768\\times 768768 × 768resolution.",
                "position": 1844
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x7.png",
                "caption": "Figure 7:Qualitative comparison of resolution generalization on1024×1024102410241024\\times 10241024 × 1024resolution.",
                "position": 1848
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x8.png",
                "caption": "Figure 8:Qualitative comparison of resolution generalization on1536×1536153615361536\\times 15361536 × 1536resolution.",
                "position": 1853
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x9.png",
                "caption": "Figure 9:Qualitative comparison of resolution generalization on2048×2048204820482048\\times 20482048 × 2048resolution.",
                "position": 1857
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x10.png",
                "caption": "Figure 10:Qualitative comparison of aspect ratio generalization on960×320960320960\\times 320960 × 320resolution (corresponding to3:1:313:13 : 1aspect ratio).",
                "position": 1861
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x11.png",
                "caption": "Figure 11:Qualitative comparison of aspect ratio generalization on320×960320960320\\times 960320 × 960resolution (corresponding to1:3:131:31 : 3aspect ratio).",
                "position": 1865
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x12.png",
                "caption": "Figure 12:Qualitative comparison of aspect ratio generalization on768×432768432768\\times 432768 × 432resolution (corresponding to16:9:16916:916 : 9aspect ratio).",
                "position": 1869
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x13.png",
                "caption": "Figure 13:Qualitative comparison of aspect ratio generalization on432×768432768432\\times 768432 × 768resolution (corresponding to9:16:9169:169 : 16aspect ratio).",
                "position": 1873
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x14.png",
                "caption": "Figure 14:Qualitative comparison of aspect ratio generalization on640×480640480640\\times 480640 × 480resolution (corresponding to4:3:434:34 : 3aspect ratio).",
                "position": 1877
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x15.png",
                "caption": "Figure 15:Qualitative comparison of aspect ratio generalization on480×640480640480\\times 640480 × 640resolution (corresponding to3:4:343:43 : 4aspect ratio).",
                "position": 1881
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x16.png",
                "caption": "Figure 16:Uncurated generation results of NiT-XL. We use the class label as 33.",
                "position": 1893
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x17.png",
                "caption": "Figure 17:Uncurated generation results of NiT-XL. We use the class label as 88.",
                "position": 1897
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x18.png",
                "caption": "Figure 18:Uncurated generation results of NiT-XL. We use the class label as 250.",
                "position": 1901
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x19.png",
                "caption": "Figure 19:Uncurated generation results of NiT-XL. We use the class label as 279.",
                "position": 1905
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x20.png",
                "caption": "Figure 20:Uncurated generation results of NiT-XL. We use the class label as 388.",
                "position": 1909
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x21.png",
                "caption": "Figure 21:Uncurated generation results of NiT-XL. We use the class label as 417.",
                "position": 1913
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x22.png",
                "caption": "Figure 22:Uncurated generation results of NiT-XL. We use the class label as 437.",
                "position": 1917
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x23.png",
                "caption": "Figure 23:Uncurated generation results of NiT-XL. We use the class label as 812.",
                "position": 1921
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x24.png",
                "caption": "Figure 24:Uncurated generation results of NiT-XL. We use the class label as 980.",
                "position": 1925
            },
            {
                "img": "https://arxiv.org/html/2506.03131/x25.png",
                "caption": "Figure 25:Uncurated generation results of NiT-XL. We use the class label as 985.",
                "position": 1929
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]