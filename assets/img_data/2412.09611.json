[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09611/x1.png",
                "caption": "",
                "position": 111
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09611/x2.png",
                "caption": "Figure 2:FluxSpace Framework.The FluxSpace framework introduces a dual-level editing scheme within the joint transformer blocks of Flux, enabling coarse and fine-grained visual editing. Coarse editing operates on pooled representations of base (cp⁢o⁢o⁢lsubscript𝑐𝑝𝑜𝑜𝑙c_{pool}italic_c start_POSTSUBSCRIPT italic_p italic_o italic_o italic_l end_POSTSUBSCRIPT) and edit (ce,p⁢o⁢o⁢lsubscript𝑐𝑒𝑝𝑜𝑜𝑙c_{e,pool}italic_c start_POSTSUBSCRIPT italic_e , italic_p italic_o italic_o italic_l end_POSTSUBSCRIPT) conditions, allowing global changes like stylization, controlled by the scaleλc⁢o⁢a⁢r⁢s⁢esubscript𝜆𝑐𝑜𝑎𝑟𝑠𝑒\\lambda_{coarse}italic_λ start_POSTSUBSCRIPT italic_c italic_o italic_a italic_r italic_s italic_e end_POSTSUBSCRIPT(a). For fine-grained editing, we define a linear editing scheme using base, prior, and edit attention outputs, guided by scaleλf⁢i⁢n⁢esubscript𝜆𝑓𝑖𝑛𝑒\\lambda_{fine}italic_λ start_POSTSUBSCRIPT italic_f italic_i italic_n italic_e end_POSTSUBSCRIPT(b). With this flexible design, our framework is both able to perform coarse-level and fine-grained editing, with a linearly adjustable scale.",
                "position": 188
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09611/x3.png",
                "caption": "Figure 3:Qualitative Results on Face Editing.Our method can perform a variety of edits from fine-grained face editing (e.g. adding eyeglasses) to changes over the overall structure of the image (e.g. comics style). As our method utilizes disentangled representations to perform image editing, we can precisely edit a variety of attributes while preserving the properties of the original image.",
                "position": 242
            },
            {
                "img": "https://arxiv.org/html/2412.09611/x4.png",
                "caption": "Figure 4:Qualitative Comparisons.We compare our method both with latent diffusion-based approaches (LEDITS++[6]and TurboEdit[11]) and flow-based methods (Sliders-FLUX[16]and RF-Inversion[37]) in terms of their disentangled editing capabilities. We present qualitative results for smile, eyeglasses, and age edits where our method succeeds over competing methods in both reflecting the semantic and preserving the input identity.",
                "position": 352
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09611/x5.png",
                "caption": "Figure 5:Real Image Editing.By integratingFluxSpaceon the inversion approach proposed by RF-Inversion[37], we extend our method for real image editing task. As we show qualitatively, our method achieves improved disentanglement over the performed edits compared to the baseline approach, where we use identical hyperparameters for the inversion task on both approaches.",
                "position": 509
            },
            {
                "img": "https://arxiv.org/html/2412.09611/x6.png",
                "caption": "Figure 6:Ablation Study.We present ablations over the hyperparameters introduced within the FluxSpace framework. Specifically, we perform ablations on coarse editing scaleλc⁢o⁢a⁢r⁢s⁢esubscript𝜆𝑐𝑜𝑎𝑟𝑠𝑒\\lambda_{coarse}italic_λ start_POSTSUBSCRIPT italic_c italic_o italic_a italic_r italic_s italic_e end_POSTSUBSCRIPT, fine-grained editing scaleλf⁢i⁢n⁢esubscript𝜆𝑓𝑖𝑛𝑒\\lambda_{fine}italic_λ start_POSTSUBSCRIPT italic_f italic_i italic_n italic_e end_POSTSUBSCRIPT, masking coefficientτmsubscript𝜏𝑚\\tau_{m}italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPTand timestept𝑡titalic_twhen the editing is initiated. For all ablations, we report qualitative results for changing values of the specified hyperparameters.",
                "position": 542
            }
        ]
    },
    {
        "header": "6Limitation",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "AJoint Transformer Block Architecture",
        "images": []
    },
    {
        "header": "BUser Study Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09611/extracted/6065524/figs/user_study_setup.png",
                "caption": "Figure 7:User Study Setup.We conduct our user study on unedited-edited image pairs. For each editing method, we provide the original image where the edit is not applied, with the edited image, and ask the users to rate the edit from a scale of 1-to-5. On the Likert scale that the users are asked to provide their preference on, 1 corresponds to unsatisfactory editing and 5 corresponds to a satisfactory edit.",
                "position": 1195
            }
        ]
    },
    {
        "header": "CDetails on Quantitative Comparisons",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09611/x7.png",
                "caption": "Figure 8:Additional Qualitative Comparisons.In addition to comparisons provided in the main paper, we provide additional comparisons with Prompt2Prompt[18](with Null-Text Inversion[27]) and PnP-Diffusion[39], as Stable Diffusion based editing methods. As we demonstrate qualitatively, FluxSpace both achieves disentangled and semantically correct edits where competing methods contain artifacts in edited results (see the edit “Eyeglasses” for both methods), and significantly alter the subject identity (see “Age” edit).",
                "position": 1285
            },
            {
                "img": "https://arxiv.org/html/2412.09611/x8.png",
                "caption": "Figure 9:Gender Editing Results.We provide additional editing results for editing the gender semantics. As shown in the examples, our method succeeds in both male-to-female and female-to-male translations. We provide editing results on both portrait images, where our edits preserve the facial details, and edits on complex scenes where we succeed in only editing the human subject. Both in terms of preserving the identity of the subject and the background details,FluxSpacesucceeds in the disentanglement editing task.",
                "position": 1288
            },
            {
                "img": "https://arxiv.org/html/2412.09611/x9.png",
                "caption": "Figure 10:Sunglasses Editing Results.We provide additional qualitative results for the edit “adding sunglasses”. As we demonstrate on human subjects in both portrait images and more complex scenes, our editing method can accurately target where the edit should be applied without any input mask. We show the editing capabilities ofFluxSpaceboth in images where the human subject is the main focus of the image (first two rows) and with human subjects as a part of a scene (last two rows). In both cases, our method succeeds in performing the desired edit and preserving the edit-irrelevant details.",
                "position": 1291
            },
            {
                "img": "https://arxiv.org/html/2412.09611/x10.png",
                "caption": "Figure 11:Conceptual Editing Results.We provide editing results with abstract concepts, that affect the overall appearance of the image. Our method succeeds in performing edits that alter the content of the image (top row) by being able to interpret the structures in the unedited image (e.g. the trees on the back for the edit “cherry blossom”) and can change the style and overall appearance of the image (bottom row).",
                "position": 1294
            },
            {
                "img": "https://arxiv.org/html/2412.09611/x11.png",
                "caption": "Figure 12:Editing Results with Multiple Subjects.We present qualitative results on images with multiple subjects. In addition to images with only one subject to be edited,FluxSpacecan apply edits by identifying semantics globally and editing multiple subjects at the same time. Note that our method does not use any external mask, and performs the edit completely with the semantic understanding of the rectified flow transformer.",
                "position": 1297
            }
        ]
    },
    {
        "header": "DSupplementary Qualitative Results",
        "images": []
    }
]