[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIBackground and Related Work",
        "images": []
    },
    {
        "header": "IIIDomain Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_workflow.png",
                "caption": "Figure 1:Comparative MU evaluation workflow ofUnlearning Comparator. The workflow guides users through four iterative stages. In theBuildstage, users generate various unlearned models, followed by theScreenstage where they use summary metrics to select two for in-depth analysis. TheContraststage involves comparing the selected pair from class-, instance-, and layer-level perspectives to understand model behaviors. Finally, theAttackstage verifies privacy by simulating membership inference attacks. Insights from all stages then guide iterative refinement of the unlearning methods.",
                "position": 341
            }
        ]
    },
    {
        "header": "IVThe Unlearning Comparator System",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_teaser.png",
                "caption": "Figure 2:Unlearning Comparatorassists MU researchers in analyzing and comparing MU methods.\n(A) TheModel Builder(shown inFig.3A) creates unlearned models.\n(B) TheModel Screeningview lets users obtain an overview and select two models for deeper inspection.\n(C) TheMetricsview highlights class-level performance and internal representation changes.\n(D) TheEmbedding Spaceview displays each model’s feature embeddings side-by-side.\n(E) TheAttack Simulationview (shown inFig.8) performs membership inference attacks to verify that no residual signal remains about the unlearned data.",
                "position": 370
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_build_screen.png",
                "caption": "Figure 3:Users configure unlearning settings in theModel Builder(A) to generate candidate models. By selecting multiple values for each hyperparameter, they can build multiple models at once; all combinations are generated automatically.\nThey then review each model’s performance in theModel Screeningview (B), which presents summary metrics and reveals epoch-wise metrics upon clicking a row, allowing users to select two for deeper comparison.",
                "position": 486
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_ps.png",
                "caption": "Figure 4:Comparison of privacy metrics using FT beyond zero unlearning accuracy.\nC-MIA prematurely reaches and remains at 1.0 due to its reliance on raw confidence, while E-MIA incorrectly declines as the model confidently misclassifies samples.\nIn contrast,WCPSprogressively increases, reflecting the convergence toward the retrained model’s distribution.",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_metrics.png",
                "caption": "Figure 5:TheMetricsview provides metrics that reveal how an unlearning method targets the forget class while preserving the retain classes.\n(A)Class-wise Accuracychart displays the per-class accuracy differences to examine high-level trade-offs.\n(B)Prediction Matrixvisualizes predicted proportion and average confidence to inspect misclassification patterns,\nand (C)Layer-wise Similaritychart shows the similarity of layer representations against the original or the retrained models to reveal changes in internal representations.",
                "position": 562
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_matrix.png",
                "caption": "Figure 6:Initial and final designs of thePrediction Matrix, both encoding predicted proportion and average confidence.\nThe initial design (A) uses circle size and color, while the final design (B) arranges them diagonally.",
                "position": 570
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_embedding.png",
                "caption": "Figure 7:Comparative visual analysis of feature space for two unlearned models in theEmbedding Spaceview.\n(A) Highlighting the forget class instances reveals how their feature distribution differs between them. For instance,Model B(right) contains a dense, unforgotten cluster that can be explored in detail.\n(B) Linking interactions enable direct comparison. Hovering connects the same instance across models, while clicking on an instance reveals its image and compares predicted confidences.",
                "position": 586
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_attack.png",
                "caption": "Figure 8:TheAttack Simulationview to assess two unlearned models against the retrained model via MIAs.\nGray,green, andpurpledots indicate samples output by the retrained model,Model A, andModel B, respectively.\n(A) Users configure the attack metric and threshold-setting strategy, and can use a button to inspect the worst-case scenario.\n(B) Dot plots display each model’s output distribution compared with the retrained model, with FPR/FNR and attack score tracked by a threshold slider.\n(C) “Success” and “Failure” samples appear in a grid for instance-level inspection.\n(D) Clicking on any sample reveals its original image and compares the retrained and unlearned models’ predicted confidence.",
                "position": 624
            }
        ]
    },
    {
        "header": "VCase Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_findingA.png",
                "caption": "Figure 9:Finding 1–\nAnalyzing embedding shifts between the original model (Model A) and the retrained model (Model B).Top: When “frog” is the forget class, embeddings from this class are redistributed into nearby clusters (e.g., bird, cat, deer).Bottom: When “dog” is the forget class, most embeddings in the retrained model shift toward the cat cluster.",
                "position": 693
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_findingB.png",
                "caption": "Figure 10:Finding 2–\nExamining theClass-wise Accuracytrade-offs.\n(A) Two GA variants with different batch sizes: compared toModel A(small batch),Model B(large batch) exhibits lower accuracy on the forget class with higher accuracy on the retain classes, indicating better unlearning.\n(B) An unlearned model,Model B(FT), is compared toModel A(Retrain) in both training and test datasets. It reveals performance degradation on semantically similar classes to the forget class (B-left) and overfitting in the retain classes (B-right).",
                "position": 706
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_findingC.png",
                "caption": "Figure 11:Finding 3–\nInvestigating misclassification patterns and detecting confidence mismatches.\nThe first row is the forget class “airplane,” and each column represents the predicted class.\nBy comparing this entire row to the retrained model (A), users can see how similarly each unlearned method allocates the forget class.\nNotably, brightness contrast between the two triangles in a single cell reveals inconsistencies between confidence and predicted proportion (C and F).",
                "position": 726
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_findingD.png",
                "caption": "Figure 12:Finding 5– Identifying theElbow Layervia Layer-wise similarity analysis.\nThe chart compares similarity of two models against the retrained model:Model A(Original) andModel B(RL). TheElbow Layer(e.g.,layer3.1) is where retain class CKA is minimized, just before the sharp divergence for the forget class. This provides the rationale for our strategy of re-initializing these later, output-centric layers for efficient unlearning.",
                "position": 756
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_findingE.png",
                "caption": "Figure 13:Finding 6–\nTheAttack Simulationview after unlearning of “bird.”\nSamples near the cursor (with top-1 confidence greater than 0.8) exhibit abnormally high confidence for a non-animal class—an outcome rarely observed in predictions from the retrained model. This suggests a potential vulnerability for MIAs.",
                "position": 762
            },
            {
                "img": "https://arxiv.org/html/2508.12730/figs/fig_method.png",
                "caption": "Figure 14:Comparison ofGUwith other methods:\n(A)GU(Model B) achieves lower accuracy on the forget class (deer, green bar), and higher accuracy on most retain classes compared to SCRUB (Model A).\n(B)GU(Model B)’s prediction patterns closely resemble the retrained model (Model A).\n(C)GU(Model B)’s feature embeddings exhibit a similar structure to the retrained model (Model A).",
                "position": 919
            }
        ]
    },
    {
        "header": "VIExpert Feedback",
        "images": []
    },
    {
        "header": "VIILimitations and Future Work",
        "images": []
    },
    {
        "header": "VIIIConclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12730/biography/jaeung.jpg",
                "caption": "",
                "position": 1475
            },
            {
                "img": "https://arxiv.org/html/2508.12730/biography/suhyeon.jpg",
                "caption": "",
                "position": 1488
            },
            {
                "img": "https://arxiv.org/html/2508.12730/biography/yurim.jpg",
                "caption": "",
                "position": 1501
            },
            {
                "img": "https://arxiv.org/html/2508.12730/biography/simon.png",
                "caption": "",
                "position": 1514
            },
            {
                "img": "https://arxiv.org/html/2508.12730/biography/jaemin.jpg",
                "caption": "",
                "position": 1527
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]