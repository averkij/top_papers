[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.03745/x1.png",
                "caption": "",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3StreamDiT Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.03745/x2.png",
                "caption": "Figure 2:Illustration of StreamDiT partitioning. We partition the buffer toKùêæKitalic_Kreference frames andNùëÅNitalic_Nchunks. Each chunk hascùëêcitalic_cframes andsùë†sitalic_smicro denoising steps.",
                "position": 266
            }
        ]
    },
    {
        "header": "4StreamDiT Modeling",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.03745/x3.png",
                "caption": "Figure 3:StreamDiT with varying time embedding and window attention. We modified the standard adaLN DiT with varying time embeddings applied to scale and shift modulations.",
                "position": 359
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x4.png",
                "caption": "Figure 4:Illustration of window partitioning: regular windows and shifted windows.",
                "position": 366
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.03745/extracted/6596968/fig/best_model_comparison_result.png",
                "caption": "Figure 5:Human evaluations of our method compared with others, where our model shows higher win rates across all axes.",
                "position": 526
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x5.png",
                "caption": "Figure 6:Visual results selected from our evaluation. Our models show better consistency and higher quality than others. Our distilled model has a similar quality with our teacher model.",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x6.png",
                "caption": "Figure 7:Real-time video streaming. With real-time streaming generation, our model can potentially work as a game engine.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x7.png",
                "caption": "Figure 8:Infinite streaming. We generate a 5-minute video to demonstrate the potential for infinite streaming.",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x8.png",
                "caption": "Figure 9:Interactive video streaming. The user can enter prompts to navigate the video generation on the fly.",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x9.png",
                "caption": "Figure 10:Video-to-video streaming. The top row is input and the bottom row is output, where a pig is modified to a cat by prompt.",
                "position": 593
            }
        ]
    },
    {
        "header": "6Conclusion and Limitations",
        "images": []
    },
    {
        "header": "7Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Inference Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.03745/x10.png",
                "caption": "Figure 11:Interactive inference pipeline of StreamDiT: To decrease latency, generative models, decoder and text encoder are in separate process.",
                "position": 1260
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x11.png",
                "caption": "Figure 12:Denoising Trajectory Change with Text Guidance Update:\nAs denoising progresses toward the final stages, it becomes increasingly difficult to deviate from the outcome dictated by the original text guidance.",
                "position": 1263
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x12.png",
                "caption": "Figure 13:In the T2V scenario, StreamDiT first performs standard chunk generation to prepare intermediate latent cache. Once the intermediate cache is fully populated, the appropriate blocks are retrieved to construct the initial Stream Queue. Different inference configurations can be activated, provided that those configurations were included during mixed chunk training.",
                "position": 1270
            }
        ]
    },
    {
        "header": "9Design Choices and Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.03745/x13.png",
                "caption": "Figure 14:Partitioned Noise Training: The partitioning strategy can be defined by an arbitrary function‚Äîlinear or nonlinear‚Äîthat aligns with the chosen noise scheduling strategy.",
                "position": 1286
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x14.png",
                "caption": "Figure 15:High-quality videos generated by the 30B model, demonstrating the scalability of our method.",
                "position": 1289
            },
            {
                "img": "https://arxiv.org/html/2507.03745/x15.png",
                "caption": "Figure 16:Sequential storytelling prompts can mitigate repetitive content and enable dynamic contents change.",
                "position": 1317
            }
        ]
    },
    {
        "header": "10More Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.03745/x16.png",
                "caption": "Figure 17:Overlap decoding",
                "position": 1472
            }
        ]
    },
    {
        "header": "11Limitations",
        "images": []
    }
]