[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x1.png",
                "caption": "",
                "position": 74
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x2.png",
                "caption": "Figure 2:The demonstration forvisual discrepancybetween generated images by different diffusion models. The images generated by various models exhibit distinctive visual features such as realistic textures, complex architectures, life-like details, vibrant colors, abstract expression, magical ambiance, and photorealistic elements.",
                "position": 83
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x3.png",
                "caption": "Figure 3:The images in our dataset, which is diverse and comprehensive. Specifically, it encompasses a variety of subjects commonly found in real-world scenarios where issues such as misinformation, copyright infringement, and content tracing evasion occur. For instance, our dataset includes images of nature, architecture, animals, planes, art, and indoor. Note that for simplicity, we omit the prompts here. Please refer to Supplementary (Section8) for examples of prompts and generations.",
                "position": 156
            }
        ]
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x4.png",
                "caption": "Figure 4:The implementation of learning theoretical-expected matrixùêñùêñ\\mathbf{W}bold_W. Specifically, in practice, we use gradient descent to optimize a metric loss function in order to learnùêñùêñ\\mathbf{W}bold_W.",
                "position": 433
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x5.png",
                "caption": "Figure 5:Examples offailurecases for each kind of model.",
                "position": 1088
            },
            {
                "img": "https://arxiv.org/html/2501.02376/x6.png",
                "caption": "Figure 6:Our method demonstrates a certain level ofrobustnessagainst differenttypesandintensitiesof attacks.",
                "position": 1828
            },
            {
                "img": "https://arxiv.org/html/2501.02376/x7.png",
                "caption": "Figure 7:As expected by the theory, the cosine similaritiesincreasew.r.t. epochs.",
                "position": 1839
            },
            {
                "img": "https://arxiv.org/html/2501.02376/x8.png",
                "caption": "Figure 8:The change in performance w.r.t the rank ofùêñùêñ\\mathbf{W}bold_W.",
                "position": 2148
            },
            {
                "img": "https://arxiv.org/html/2501.02376/x9.png",
                "caption": "Figure 9:The change in performance w.r.t thenumberof layers.",
                "position": 2162
            },
            {
                "img": "https://arxiv.org/html/2501.02376/x10.png",
                "caption": "Figure 10:The image-to-image paradigm beyond our theorems.",
                "position": 2165
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x11.png",
                "caption": "Figure 11:Illustration of prompts and corresponding generated images for 6 different subjects in our dataset. Our dataset comprehensively includes various subjects found in the real world.",
                "position": 2875
            }
        ]
    },
    {
        "header": "7Proofs of Lemmas",
        "images": []
    },
    {
        "header": "8Prompt and Generation Examples",
        "images": []
    },
    {
        "header": "9Implementation of GPT-4o",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/extracted/6110675/T107504.jpg",
                "caption": "Figure 12:The script for requesting GPT-4o to generate20202020different prompts for each original image.",
                "position": 3157
            }
        ]
    },
    {
        "header": "10Complete Experiments for 7 Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x12.png",
                "caption": "Figure 13:This illustration shows failure cases predicted by our method. We have identified that our model may fail when encounteringhard negativesamples.",
                "position": 5728
            }
        ]
    },
    {
        "header": "11Failure Cases and Potential Directions",
        "images": []
    },
    {
        "header": "12Details of Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02376/x13.png",
                "caption": "Figure 14:Different paradigms used by text-guided image-to-image translations.",
                "position": 5762
            }
        ]
    },
    {
        "header": "13Limitations and Future Works",
        "images": []
    }
]