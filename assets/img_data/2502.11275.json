[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11275/x1.png",
                "caption": "Figure 1:\\ourtakes a free ride on LLM resources (e.g., C4 and TuluV3(Lambert et¬†al.,2024)) by formalizing next token prediction for duplicative spans as extraction in the BIO paradigm. During the inference, the prompts can be adjusted to different extractive tasks, making\\oura versatile IE model.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2502.11275/x2.png",
                "caption": "Figure 2:Comparison of scale, cost, and diversity among different IE pre-training datasets. Our data collection for\\ouris free by converting LLM‚Äôs learning resources, which forces the tagger to learn from diverse contexts.\\ourcan also evolve with the data collection for LLM‚Äôs post-training.",
                "position": 185
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Our\\our",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11275/x3.png",
                "caption": "Figure 3:The evolution of Cuckoo with LLM‚Äôs post-training resources. Domain[Œº‚àí2‚Å¢œÉ,Œº+2‚Å¢œÉ]ùúá2ùúéùúá2ùúé[\\mu-2\\sigma,\\mu+2\\sigma][ italic_Œº - 2 italic_œÉ , italic_Œº + 2 italic_œÉ ]is annotated under each evaluation dimension.",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2502.11275/x4.png",
                "caption": "Figure 4:In-context tagging ability emerges in Cuckoo but not in IE models pre-trained by other resources.",
                "position": 934
            },
            {
                "img": "https://arxiv.org/html/2502.11275/x5.png",
                "caption": "Figure 5:The data scaling trend of\\ouron the early4.14.14.14.1M C4 instances and the massive100100100100M instances.",
                "position": 947
            }
        ]
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix A\\ourv.s. LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11275/x6.png",
                "caption": "Figure 6:The performance comparison between\\ourand LLMs on few-shot IE performance.",
                "position": 1663
            }
        ]
    },
    {
        "header": "Appendix BTemplates and Hyperparameters",
        "images": []
    },
    {
        "header": "Appendix CBenchmark Details",
        "images": []
    },
    {
        "header": "Appendix DAdaptive Supervision Scaling",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11275/x7.png",
                "caption": "Figure 7:The scaling-up performance on adaptive supervision from CoNLL2003 of pre-trained IE models.",
                "position": 2034
            }
        ]
    },
    {
        "header": "Appendix ERobustness to Verbalization",
        "images": []
    }
]