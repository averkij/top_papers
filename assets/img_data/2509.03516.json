[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.03516/x1.png",
                "caption": "Figure 1:Examples of two fundamental capabilities in T2I generation, using GPT-ImageOpenAI (2025). To increase complexity, (a)Composition: We introduce far more instances than DPG-BenchHu et al. (2024), a representative benchmark with an increased number of visual elements. (b)Reasoning: Our benchmark captures multi-item behavioral effects beyond R2I-BenchChen et al. (2025b), the latest reasoning-oriented benchmark with single-step, one-to-one inference. Each of our prompts is paired with a checklist to facilitate fine-grained and reliable evaluation.",
                "position": 109
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3T2I-CoReBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.03516/x2.png",
                "caption": "(a)Composition (i.e., MI, MA, MR, TR)",
                "position": 600
            },
            {
                "img": "https://arxiv.org/html/2509.03516/x2.png",
                "caption": "(a)Composition (i.e., MI, MA, MR, TR)",
                "position": 603
            },
            {
                "img": "https://arxiv.org/html/2509.03516/x3.png",
                "caption": "(b)Deductive Reasoning (i.e., LR, BR, HR, PR)",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2509.03516/x4.png",
                "caption": "(c)Inductive Reasoning (i.e., GR, AR)",
                "position": 615
            },
            {
                "img": "https://arxiv.org/html/2509.03516/x5.png",
                "caption": "(d)Abductive Reasoning (i.e., CR, RR)",
                "position": 621
            },
            {
                "img": "https://arxiv.org/html/2509.03516/x6.png",
                "caption": "Figure 3:Statistics ofT2I-CoReBench.Left: Our T2I evaluation taxonomy spanning two fundamental generative capabilities (i.e.,compositionandreasoning), further refined into 12 dimensions.Right: Distributions of prompt-token lengths and checklist-question counts. Our benchmark demonstrates high complexity, with an average prompt length of 170 tokens and an average of 12.5 questions. Note: reasoning has fewer questions, as each requires reasoning that is more challenging.",
                "position": 693
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion and Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experiments",
        "images": []
    },
    {
        "header": "Appendix CEthics Statement",
        "images": []
    },
    {
        "header": "Appendix DLimitations",
        "images": []
    }
]