[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Draft and Refine with Visual Experts",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.11005/fig/fig1_dnr.png",
                "caption": "Figure 1:Overview of the Draft-and-Refine (DnR) framework.Given an imagexxand a questionqq, the LVLM first generates an initial draft answery^\\hat{y}①. The question is decomposed byfLLMf_{\\mathrm{LLM}}into a query setQ={qi}Q=\\{q_{i}\\}, and each query is grounded byfgf_{g}to produce spatial relevance maps, aggregated intor​(x∣q)r(x\\mid q)②. Gumbel-kksampling masks Top-kkand Bottom-kkregions for perturbation, and a semantic encoderg​(⋅)g(\\cdot)measures similarity shifts betweeny^\\hat{y}and perturbed predictionsy~τ\\tilde{y}_{\\tau}to compute the utilization scoreUqbaseU_{q}^{\\mathrm{base}}③. Expert models (e.g., CLIP, SAM, OCR) render structured visual evidence onto the image, producing refined outputs with updated utilizationUq(j)U_{q}^{(j)}. The expert with the largest gainUq(j)−UqbaseU_{q}^{(j)}-U_{q}^{\\mathrm{base}}is selected for refinement ④.",
                "position": 133
            },
            {
                "img": "https://arxiv.org/html/2511.11005/fig/fig2_r_map.png",
                "caption": "Figure 2:Illustration of the query-conditioned relevance map.For the same image (top row), different questions lead to distinct relevance regions aligned with the extracted query terms. Conversely, for the same question (bottom row), the relevance map varies with the image content, localizing evidence that matches the queried concept.",
                "position": 186
            },
            {
                "img": "https://arxiv.org/html/2511.11005/fig/fig3_Uq.png",
                "caption": "Figure 3:Question-conditioned utilization computation.Given a questionqqand imagexx, the relevance mapr​(x∣q)r(x\\mid q)guidesGumbel Top-kk/Bottom-kkmasking over a ratioρ\\rhoof the image. Masked inputsτ​(x)\\tau(x)are fed into the LVLM to obtain perturbed predictionsy~τ\\tilde{y}_{\\tau}, compared with the originaly^\\hat{y}via a semantic encoderg​(⋅)g(\\cdot), and aggregated with the adaptive factorα\\alphato compute the final utilization scoreUq​(x)U_{q}(x).",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2511.11005/fig/fig4_render.png",
                "caption": "Figure 4:Comparison of rendering strategies across different experts. Each column corresponds to an experts, and each row represents a rendering style.",
                "position": 261
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    }
]