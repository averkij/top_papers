[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06845/x1.png",
                "caption": "Figure 1:MentalArena is a self-play framework for the diagnosis and treatment of mental health disorder consisting of three modules:Symptom Encoder,Symptom Decoder, andModel Optimizer.",
                "position": 147
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MentalArena",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06845/x2.png",
                "caption": "Figure 2:Symptom Decoder aims to mitigate the intent bias between therapists and patients through patient decoding and dynamic control of the conversation. To ensure the accuracy of the diagnostic information provided by the therapist, the patient simulates their updated health condition after implementing the prescribed treatment or medication plan.",
                "position": 232
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06845/x3.png",
                "caption": "Figure 3:Ablation study. Each bar represents the performance of model trained on different settings. The bars in dark blue are higher than others, indicating each module is effective in different models.",
                "position": 564
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x4.png",
                "caption": "Figure 4:Results on effectiveness analysis of self-play training.",
                "position": 586
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06845/x5.png",
                "caption": "(a)MedMCQA GPT-3.5",
                "position": 657
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x5.png",
                "caption": "(a)MedMCQA GPT-3.5",
                "position": 660
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x6.png",
                "caption": "(b)MedMCQA Llama-3",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x7.png",
                "caption": "(c)MMLU GPT-3.5",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x8.png",
                "caption": "(d)MMLU Llama-3",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x9.png",
                "caption": "Figure 6:Results of forgetting experiments.",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x10.png",
                "caption": "Figure 7:Case study on GPT-3.5-turbo. Our model accurately answers the medical question, while GPT-3.5-turbo provides an incorrect response.",
                "position": 712
            }
        ]
    },
    {
        "header": "6Conclusion, Societal Impact and Limitations",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompts",
        "images": []
    },
    {
        "header": "Appendix BPrompt template for baseline",
        "images": []
    },
    {
        "header": "Appendix CBenchmark",
        "images": []
    },
    {
        "header": "Appendix DMetrics: Perplexity, Diversity Gain",
        "images": []
    },
    {
        "header": "Appendix ETraining data samples",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06845/x11.png",
                "caption": "Figure 8:Examples of training data.",
                "position": 1951
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x12.png",
                "caption": "Figure 9:Examples of training data for ablation study setting (â€œBaseline + c\").",
                "position": 1954
            }
        ]
    },
    {
        "header": "Appendix FCognitive model and behavior pattern",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06845/x13.png",
                "caption": "Figure 10:The example of cognitive model.",
                "position": 1968
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x14.png",
                "caption": "Figure 11:The example of behavior pattern.",
                "position": 1971
            }
        ]
    },
    {
        "header": "Appendix GDetailed experimental results",
        "images": []
    },
    {
        "header": "Appendix HTraining details",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06845/x15.png",
                "caption": "Figure 12:Case study on Llama-3-8b (1).",
                "position": 2420
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x16.png",
                "caption": "Figure 13:Case study on Llama-3-8b (2).",
                "position": 2423
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x17.png",
                "caption": "Figure 14:Case study on Llama-3-8b (3).",
                "position": 2426
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x18.png",
                "caption": "Figure 15:Case study on GPT-3.5-turbo (1).",
                "position": 2429
            },
            {
                "img": "https://arxiv.org/html/2410.06845/x19.png",
                "caption": "Figure 16:Case study on GPT-3.5-turbo (2).",
                "position": 2432
            }
        ]
    },
    {
        "header": "Appendix ICase study",
        "images": []
    }
]