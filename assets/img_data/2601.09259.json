[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/Figure1.png",
                "caption": "Figure 1:An example of LLM Agents solving a task via multi-step reasoning, dynamically leveraging search and code tools to obtain the final answer.",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/Figure2.png",
                "caption": "Figure 2:Comparison of test time reasoning strategies. CoT and ToT follow step by step generation with limited foresight, while MCTS conducts global simulation at a higher computational cost. On the right, MAXS uses MiMo-VL-7B-SFT as the backbone and consistently outperforms baseline methods across benchmarks.",
                "position": 241
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/Figure3.png",
                "caption": "Figure 3:Illustration of the MAXS framework. Left: LLM Agents generates reasoning steps from inputs0s_{0}to final answersns_{n}. Right: At each step, MAXS performs (a) rollout & lookahead, (b) value estimation via advantage and two variance scores, and (c) integration. A trajectory convergence mechanism halts rollouts early to improve efficiency.",
                "position": 269
            }
        ]
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/Figure5.png",
                "caption": "Figure 4:Inference-time scaling law: Accuracy vs. Token usage for different models during decoding.",
                "position": 1009
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/output1.png",
                "caption": "Figure 5:Accuracy–cost trade-off under varying lookahead steps across datasets.",
                "position": 1054
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/output4.png",
                "caption": "Figure 6:Radar plot of accuracy under different tool configurations across datasets.",
                "position": 1057
            }
        ]
    },
    {
        "header": "4Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/output5.png",
                "caption": "Figure 7:Accuracy heatmap under different value estimation weights (α\\alpha,β\\beta) across datasets.",
                "position": 1121
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/output7.png",
                "caption": "Figure 8:Distribution of reasoning steps across datasets.",
                "position": 1169
            }
        ]
    },
    {
        "header": "5Related Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof of Proposition",
        "images": []
    },
    {
        "header": "Appendix BDatasets",
        "images": []
    },
    {
        "header": "Appendix CMAXS Decoding Algorithm",
        "images": []
    },
    {
        "header": "Appendix DSupplement Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/output2.png",
                "caption": "Figure 9:Accuracy–cost trade-off under varying rollout steps across datasets.",
                "position": 2204
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/output3.png",
                "caption": "Figure 10:Accuracy vs. relative cost under varying beam sizes (1-beam normalized to 100%).",
                "position": 2207
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/output6.png",
                "caption": "Figure 11:Comparison of different value estimation methods across datasets.",
                "position": 2210
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/Figure4.png",
                "caption": "Figure 12:Successful case of MAXS solving a TheoremQA problem. At each step, it performs rollout and foresight (up to four steps), evaluates candidates via three advantage metrics, and iteratively selects the best path. The process dynamically integrates reasoning, search, and tool use.",
                "position": 2338
            },
            {
                "img": "https://arxiv.org/html/2601.09259/Figures/Figure6.png",
                "caption": "Figure 13:A failure case on the MathVista dataset where MAXS selects an incorrect visual recognition path due to the low confidence of search tool results. The initial misidentification of the individuals propagates through the reasoning chain, leading to an erroneous final answer despite valid subsequent calculations.",
                "position": 2341
            }
        ]
    },
    {
        "header": "Appendix ECase Study",
        "images": []
    }
]