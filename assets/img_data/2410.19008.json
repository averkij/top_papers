[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19008/x1.png",
                "caption": "Figure 1:The proposedPULSEdemonstrates superior performance across multiplein-domainandout-of-domaindatasets on our constructedECGBenchcompared with advanced proprietary MLLMs (e.g., GPT-4o). Notably, the proprietary MLLMs often fail to accurately interpret ECG images, generating well-structured and contextually relevant responses but ultimately incorrect (with errors highlighted in red) compared to the ground truth diagnosis.",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19008/x2.png",
                "caption": "Figure 2:ECGInstruct: a list of diverse and large-scale instruction tuning datasets for ECG image interpretation. (1) ECG images are synthesized from raw signal recordings with various distortions that mimic real-world printed ECG images. (2)ECGInstructis curated based on clinician-defined ECG-related tasks, original diagnosis and clinical reports, and diverse task types. Additional quality checking is applied to filter lower-scored instructions.",
                "position": 137
            }
        ]
    },
    {
        "header": "2ECGInstruct: Teach MLLMs to Comprehend ECG Images",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19008/x3.png",
                "caption": "Figure 3:The data curation process forECGBench. There are four key tasks involved: (1) two repurposed tasks (abnormality detection and report generation) derived from existing ECG datasets, where ECG images are synthesized from raw signals, and queries/answers are extracted based on diagnostic and clinical reports; (2) Two newly developed tasks using external resources, where ECG images and associated questions and answers are collected and generated from real-world sources.",
                "position": 303
            }
        ]
    },
    {
        "header": "3ECGBench",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19008/x4.png",
                "caption": "Figure 4:Score breakdown of report generation performance.",
                "position": 1341
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BPreliminary on 12-lead ECG",
        "images": []
    },
    {
        "header": "Appendix CDetails of ECG Image Synthesis",
        "images": []
    },
    {
        "header": "Appendix DDetails of Instruction Tuning Datasets",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19008/x5.png",
                "caption": "Figure A1:The Examples of basic feature recognition instructions for finetuningPULSE.",
                "position": 2311
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x6.png",
                "caption": "Figure A2:The Examples of heart rhythm analysis instructions for finetuningPULSE.",
                "position": 2314
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x7.png",
                "caption": "Figure A3:The Examples of morphology and pathological condition identification instructions for finetuningPULSE.",
                "position": 2317
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x8.png",
                "caption": "Figure A4:The Examples of clinical reporting instructions for finetuningPULSE.",
                "position": 2320
            }
        ]
    },
    {
        "header": "Appendix EPrompts",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19008/x9.png",
                "caption": "Figure A5:The prompt used to synthesize ECG instruction tasks based on clinical reports.",
                "position": 2328
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x10.png",
                "caption": "Figure A6:The prompt used to synthesize ECG multi-turn dialogue as instruction tuning data.",
                "position": 2331
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x11.png",
                "caption": "Figure A7:The prompt used to revise (and translate) original reports.",
                "position": 2334
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x12.png",
                "caption": "Figure A8:The prompt used to score and filter generated instruction data.",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x13.png",
                "caption": "Figure A9:The prompt used to evaluate the generated report.",
                "position": 2340
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x14.png",
                "caption": "Figure A10:The prompt used to evaluate the ECG Arena.",
                "position": 2343
            }
        ]
    },
    {
        "header": "Appendix FDetails of Evaluation Metrics",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19008/x15.png",
                "caption": "Figure A11:Comparison of model outputs on ECG report generation task (Example 1).Blueindicates correct information, whileredhighlights errors. Our model’s output fully aligns with the ground truth, with a report score of 10. In comparison, GPT-4’s report, though structurally sound, contains notable inaccuracies despite its initial appearance of relevance.",
                "position": 2369
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x16.png",
                "caption": "Figure A12:Comparison of model outputs on ECG report generation task (Example 2).Blueindicates correct information, whileredhighlights errors. Our model’s output mostly aligns with the ground truth, achieving a report score of 83.3. In comparison, GPT-4’s output correctly identifies only the ECG rhythm, omitting most other key details.",
                "position": 2372
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x17.png",
                "caption": "Figure A13:Comparison of model outputs on ECG report generation task (Example 3).Blueindicates correct information, whileredhighlights errors. Our model’s output mostly aligns with the ground truth report, achieving a report score of 73. In comparison, GPT-4’s output partially aligns with the ground truth report.",
                "position": 2375
            },
            {
                "img": "https://arxiv.org/html/2410.19008/x18.png",
                "caption": "Figure A14:Comparison of model outputs on ECG Arena (Example 1).Blueindicates correct information, whileredhighlights errors. Given the challenging nature of this task, our model’s output partially aligns with the ground truth, and GPT-4o’s output largely deviates from the reference.",
                "position": 2378
            }
        ]
    },
    {
        "header": "Appendix GCase Study",
        "images": []
    }
]