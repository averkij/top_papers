[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.03555/x1.png",
                "caption": "Figure 1:PaliGemma 2 processes a 224px2/ 448px2/896px2image with a SigLIP-400m encoder with patch size 14px2, yielding 256/1024/ 4096 tokens. After a linear projection, the image tokens are concatenated with the input text tokens and Gemma 2 autoregressively completes this prefix with an answer.",
                "position": 220
            },
            {
                "img": "https://arxiv.org/html/2412.03555/x2.png",
                "caption": "Figure 2:Referring segmentation example from our PaliGemma demoa.\nThe model is pretrained with a vocabulary that includes localization tokens (for detection) and segmentation tokens (to define a binary mask inside a bounding box).",
                "position": 223
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.03555/x3.png",
                "caption": "Figure 3:Relative improvements of metrics after transfer, when choosing a pre-trained checkpoint with a larger LM, or with a higher resolution. The tasks are grouped into tasks sensitive to both model size and resolution (), sensitive to model size (), and sensitive to resolution ().\nNote that some benchmarks are quite saturated (e.g. ScienceQA’s relative improvement of 2.2% corresponds to an error reduction of 53.8% – see Figure13).\nData used to create this plot available in Table13.",
                "position": 337
            },
            {
                "img": "https://arxiv.org/html/2412.03555/x4.png",
                "caption": "Figure 4:Transfer performance as a function of model size and resolution (median over 5 transfer runs). The shaded area marks standard deviation to reported value. Lighter lines correspond to higher resolution (448px2). The tasks are grouped into tasks sensitive to both model size and resolution (), sensitive to model size (), and sensitive to resolution (). Data for this plot is available in Table13.",
                "position": 350
            },
            {
                "img": "https://arxiv.org/html/2412.03555/x5.png",
                "caption": "Figure 5:Per-task performance as a function of model size and learning rate for several of the downstream tasks. Values are normalized for each task and model size, with darker color indicating better task performance. Larger models tend to have a lower optimal transfer learning rate. Zero-shot tasks not shown as their values were not used to select learning rates. The data used for this plot is provided in TableLABEL:tab:app:pg_lr_sweep.",
                "position": 379
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Contributions and Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix ATasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.03555/extracted/6045874/figures/totaltext.jpg",
                "caption": "Figure 6:Test set example from Total-Text[17]with PaliGemma 2 3B 896px2predictions.",
                "position": 2727
            },
            {
                "img": "https://arxiv.org/html/2412.03555/extracted/6045874/figures/fintabnet.png",
                "caption": "Figure 7:Original image from FinTabNet[111]with predicted cell content boxes (green), and resulting PaliGemma 2 model prediction.",
                "position": 2731
            },
            {
                "img": "https://arxiv.org/html/2412.03555/extracted/6045874/figures/molecule.png",
                "caption": "Figure 8:Example of a rendered molecule with the corresponding SMILES stringCC1([C@@H]([C@@H](C2=C(O1)C=CC(=C2)C(C(F)(F)F)(F)F)N3CCCCC3=O)O)C.",
                "position": 2925
            },
            {
                "img": "https://arxiv.org/html/2412.03555/extracted/6045874/figures/kern_example.png",
                "caption": "Figure 9:Example of a pianoform sheet with its**kerntranscription (sourcehttps://www.humdrum.org/guide/ch02/).",
                "position": 2928
            },
            {
                "img": "https://arxiv.org/html/2412.03555/extracted/6045874/figures/docci_example.jpg",
                "caption": "Figure 10:Example DOCCI image and captions generated by PaliGemma 2 models and baselines, with non-entailment sentences highlighted in red.",
                "position": 2931
            },
            {
                "img": "https://arxiv.org/html/2412.03555/extracted/6045874/figures/mimic_cxr_example.jpg",
                "caption": "Figure 11:Example from the MIMIC-CXR[33,23]validation set along with a PaliGemma 2  prediction.",
                "position": 3069
            }
        ]
    },
    {
        "header": "Appendix BTransfer and evaluation details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.03555/x6.png",
                "caption": "Figure 12:Annotation interface used for human evaluation of image description accuracy. Raters assess the relationship between generated sentences and the corresponding image.",
                "position": 3165
            }
        ]
    },
    {
        "header": "Appendix CObject detection",
        "images": []
    },
    {
        "header": "Appendix DEthics and Safety",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.03555/x7.png",
                "caption": "Figure 13:Same data as in Figure3and Table13. The left plot shows relative improvement when changing model size or resolution. The right plot shows the same improvements, but expressed in terms of error reduction. For saturated benchmarks, error reduction is a better metric for model improvement. Benchmarks without a clear normalization to a percentage (such as CIDEr scores) are not shown.\nAxes are in range[−1,100]1100[-1,100][ - 1 , 100 ].",
                "position": 3436
            }
        ]
    },
    {
        "header": "Appendix EDetailed results",
        "images": []
    }
]