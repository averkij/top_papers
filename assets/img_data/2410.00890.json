[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00890/x1.png",
                "caption": "Figure 1:Results produced by Flex3D. It generates high-quality 3D Gaussians from a single image, textual prompt, and performs 3D reconstruction from an arbitrary number of input views.",
                "position": 108
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00890/x2.png",
                "caption": "Figure 2:Flex3Dcomprises two stages:\n(1) candidate view generation and selection, and\n(2) 3D reconstruction using FlexRM.\nIn the first stage, an input image or textual prompt drives the generation of a diverse set of candidate views through fine-tuned multi-view and video diffusion models.\nThese views are subsequently filtered based on quality and consistency using a view selection mechanism.\nThe second stage leverages the selected high-quality views, feeding them to FlexRM which reconstruct the 3D object using a tri-plane representation decoded into 3D Gaussians.",
                "position": 195
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00890/x3.png",
                "caption": "Figure 3:Imperfect Input View Simulation Results. We simulate different kinds of imperfect input views by feeding FlexRM’s output back as input and manipulating 3D Gaussian parameters.",
                "position": 374
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00890/x4.png",
                "caption": "Figure 4:Qualitative Results of Text-to-3D Generation. Flex3D demonstrates higher generation quality with strong 3D consistency, outperforming all other methods.",
                "position": 419
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation details",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00890/x5.png",
                "caption": "Figure 5:View Selection Visualizations.\nWe show some generated candidate views for each object.\nA green check mark indicates that our method selected the view, while a red cross indicates that the view was rejected.\nAs the visualization demonstrates, our method can effectively filter out views that exhibit poor quality or inconsistent results, such as those with artifacts, truncations, or awkward perspectives.\nThis allows us to focus on reconstruction from high-quality viewpoints, leading to improved overall results.",
                "position": 1829
            }
        ]
    },
    {
        "header": "Appendix BLimitations",
        "images": []
    },
    {
        "header": "Appendix CView selection visualizations",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00890/x6.png",
                "caption": "Figure 6:Single-View Reconstruction Results, showcasing FlexRM’s ability to achieve reasonable reconstructions from only a single-view observation.",
                "position": 1896
            },
            {
                "img": "https://arxiv.org/html/2410.00890/x7.png",
                "caption": "Figure 7:4-view Reconstruction Results. FlexRM is able to perform high-fidelity sparse-view reconstructions that closely resemble the ground truth, particularly when viewed from different elevation angles, outperforming baseline reconstructors.",
                "position": 1899
            }
        ]
    },
    {
        "header": "Appendix DQualitative Results on 3D Reconstruction",
        "images": []
    }
]