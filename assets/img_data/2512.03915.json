[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction: s-MoEs and Load Balancing in AI Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03915/figures/moe_diagram2.png",
                "caption": "Figure 1:Schematic of a naïve s-MoE layer without load balancing.",
                "position": 120
            }
        ]
    },
    {
        "header": "2A Primal-Dual Framework for Optimal Load Balancing",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03915/figures/ImbalanceLoss.png",
                "caption": "Figure 2:Validation set load imbalance and loss during the training of a 1B-parameter DeepSeekMoE model. Section3gives experiment details.Left:We measure the imbalance as the average load deviation from the target loadL=K​T/EL=KT/Eacross all experts in the DeepSeekMoE-1B architecture.Right:We measure the loss on the validation set.",
                "position": 386
            }
        ]
    },
    {
        "header": "3Experimental Setup and Observations",
        "images": []
    },
    {
        "header": "4Convergence Analysis for the Deterministic Case",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03915/figures/scores_cons.png",
                "caption": "(a)u/|L−Ak(n)|u/|L-A_{k}^{(n)}|Step-Size",
                "position": 837
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/scores_cons.png",
                "caption": "(a)u/|L−Ak(n)|u/|L-A_{k}^{(n)}|Step-Size",
                "position": 840
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/scores_invlin.png",
                "caption": "(b)u/nu/nStep-Size",
                "position": 845
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/scores_invsqrt.png",
                "caption": "(c)u/nu/\\sqrt{n}Step-Size",
                "position": 851
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/scores_aux.png",
                "caption": "(d)Auxiliary Loss",
                "position": 856
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/bias_cons.png",
                "caption": "(a)u/|L−Ak(n)|u/|L-A_{k}^{(n)}|Step-Size",
                "position": 1348
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/bias_cons.png",
                "caption": "(a)u/|L−Ak(n)|u/|L-A_{k}^{(n)}|Step-Size",
                "position": 1351
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/bias_invlin.png",
                "caption": "(b)u/nu/nStep-Size",
                "position": 1356
            },
            {
                "img": "https://arxiv.org/html/2512.03915/figures/bias_invsqrt.png",
                "caption": "(c)u/nu/\\sqrt{n}Step-Size",
                "position": 1362
            }
        ]
    },
    {
        "header": "5Stochastic Analysis via Online Optimization",
        "images": []
    }
]