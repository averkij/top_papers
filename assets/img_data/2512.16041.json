[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16041/x1.png",
                "caption": "Figure 1:Human-annotated preference may not be reliable. We find three key challenges with relying on human annotators for evaluating LLM-as-a-Judge systems. (a) Inter-annotator Disagreement: Different annotators can have conflicting preferences, especially for subjective questions, leading to noisy and inconsistent data. (b) Overlooking Nuances: Annotators may miss subtle errors or inaccuracies in lengthy and complex answers, leading to flawed evaluations. (c) Cognitive Biases: Human evaluators are susceptible to cognitive biases, such as favoring an answer that confirms their false beliefs, which can further compromise the objectivity of the assessment.",
                "position": 156
            }
        ]
    },
    {
        "header": "2Assessing LLM-as-a-Judge withSage",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16041/x2.png",
                "caption": "Figure 2:Sageuses a symmetrized, round-robin protocol to conduct pairwise comparisons on a set of candidate answers. From these judgments,Sagequantifies performance using two metrics:IPI, which measures local consistency by tracking preference reversals (e.g., 3 inconsistent pairs result in an IPI of 0.5), andTOV, which assesses global logical coherence by calculating the minimum alterations required for a consistent ranking (e.g., 3 alternations required). This methodology scalably diagnoses logical deficiencies to help identify and select more reliable LLM evaluators.",
                "position": 197
            }
        ]
    },
    {
        "header": "3The Construction ofSage",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16041/Figure/dataset-category-composition.jpg",
                "caption": "(a)Category Composition",
                "position": 321
            },
            {
                "img": "https://arxiv.org/html/2512.16041/Figure/dataset-category-composition.jpg",
                "caption": "(a)Category Composition",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2512.16041/Figure/question-distribution.png",
                "caption": "(b)Semantic Coverage of Question Set",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2512.16041/Figure/CV-distribution.png",
                "caption": "(c)Distribution of CV Values",
                "position": 334
            }
        ]
    },
    {
        "header": "4Experiment and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16041/x3.png",
                "caption": "Figure 4:Ablation results for ChatEval showing performance degradation across all configuration variants (lower scores are better).",
                "position": 1326
            },
            {
                "img": "https://arxiv.org/html/2512.16041/x4.png",
                "caption": "Figure 5:We discover high IPI and TOV scores inSage-Harddue to the situational preference phenomenon in LLM-as-a-Judge, while deep thinking and explicit rubrics can mitigate this.",
                "position": 1332
            },
            {
                "img": "https://arxiv.org/html/2512.16041/x5.png",
                "caption": "Figure 6:Distribution of performance spread, measured as maximum absolute percentage changed in metric. The stability of rankings across different prompt styles demonstrates the reliability of our evaluation framework.",
                "position": 1341
            },
            {
                "img": "https://arxiv.org/html/2512.16041/x6.jpg",
                "caption": "Figure 7:The difference of IPI, TOV and Consistency Rates when prompting models to directly output verdicts in comparison to the original conditions. Red bars indicate degradation and blue bars indicate improvement.",
                "position": 2312
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgements",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "The Use of Large Language Models (LLMs)",
        "images": []
    },
    {
        "header": "Appendix ATheoretical Analysis of Metric Stability",
        "images": []
    },
    {
        "header": "Appendix BDetailed Experiment Setups",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16041/x7.png",
                "caption": "Figure 8:Curation of our dataset.",
                "position": 2606
            }
        ]
    },
    {
        "header": "Appendix CArena Hard Auto",
        "images": []
    },
    {
        "header": "Appendix DAdditional Result",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16041/x8.png",
                "caption": "Figure 9:Comparison of radar charts for different models.",
                "position": 2926
            }
        ]
    },
    {
        "header": "Appendix EPrompts and Case Study",
        "images": []
    }
]