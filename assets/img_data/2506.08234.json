[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08234/x1.png",
                "caption": "Figure 1:The proposed 2×\\times×2 taxonomyspans Structural Flexibility (y-axis) and Learning Signals (x-axis). Representative methods for each quadrant along with their key designs and potentialdrawbacks.",
                "position": 126
            },
            {
                "img": "https://arxiv.org/html/2506.08234/x2.png",
                "caption": "Figure 2:Example of a compound AI system and its optimization.Centered on LLMs and coupled with multiple interacting modules, the system handles complex user queries. Automated optimization strategies leverage two types of learning signals, i.e., natural language feedback and numerical signals (defined in Sec.3.1), to backpropagate errors and guide system updates toward improved performance.",
                "position": 129
            }
        ]
    },
    {
        "header": "2Background and Preliminaries",
        "images": []
    },
    {
        "header": "3Compound AI System Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08234/x3.png",
                "caption": "Figure 3:Learning Signalsare classified into two categories, with Numerical Signals further divided by their utilization schemes: (a) one class of methods devises rule-based algorithms that directly learn from raw system performance metrics, and (b) another class transforms system evaluation results into formalized training objectives. These objectives are further split as (b1) supervised fine-tuning (SFT) losses, (b2) reinforcement learning (RL) reward functions, and (b3) direct preference optimization (DPO)Rafailov et al. (2023)losses.",
                "position": 209
            }
        ]
    },
    {
        "header": "4Challenges and Future Directions",
        "images": []
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Details of Formal Definitions",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08234/extracted/6526841/fig/fig_4/fig4_a_final.jpg",
                "caption": "(a)Optimization Stage",
                "position": 1778
            },
            {
                "img": "https://arxiv.org/html/2506.08234/extracted/6526841/fig/fig_4/fig4_a_final.jpg",
                "caption": "(a)Optimization Stage",
                "position": 1781
            },
            {
                "img": "https://arxiv.org/html/2506.08234/extracted/6526841/fig/fig_4/fig4_b_final.jpg",
                "caption": "(b)Execution Stage",
                "position": 1786
            }
        ]
    },
    {
        "header": "Appendix BAdvanced Topics and Applications",
        "images": []
    },
    {
        "header": "Appendix CMore Details of Learning Signals",
        "images": []
    },
    {
        "header": "Appendix DClarification of Methods Name",
        "images": []
    }
]