[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21523/x1.png",
                "caption": "Figure 1:(a)Example of outputs from a reasoning model and a non-reasoning model on a perception task. Red highlights indicate visual hallucination.Multimodal reasoning models are generally more prone to amplifying hallucinations during the reasoning process compared to their non-reasoning counterparts.(b)Performance of different models on reasoning and perception tasks in theRH-Benchdataset. Better performing models are positioned in the upper right corner.Baseline non-reasoning models of varying scales typically exhibit weaker reasoning capabilities and fewer hallucination, whereas reasoning models display the opposite trend.",
                "position": 79
            }
        ]
    },
    {
        "header": "2Multimodal Reasoning Can Amplify Visual Hallucination",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21523/x2.png",
                "caption": "Figure 2:Comparison of reasoning and non-reasoning models on five perception benchmarks. Results are shown for 3B models (left) and 7B models (right). Higher scores indicate lower hallucination.",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2505.21523/x3.png",
                "caption": "Figure 3:Performance across four perception benchmarks comparing Base, RL, and SFT+RL.",
                "position": 145
            },
            {
                "img": "https://arxiv.org/html/2505.21523/x4.png",
                "caption": "Figure 4:Two common types of hallucination patterns observed in multimodal reasoning models. (a) corresponds to hallucinations caused by visual misrecognition, while (b) reflects hallucinations arising from reasoning biases. Hallucinated spans are highlighted in red.",
                "position": 152
            }
        ]
    },
    {
        "header": "3Why Reasoning Models Amplify Hallucinations?",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21523/x5.png",
                "caption": "Figure 5:Attention allocation and visual grounding between reasoning and non reasoning models.The reduction of visual attention in reasoning models amplifies visual hallucinations.",
                "position": 184
            },
            {
                "img": "https://arxiv.org/html/2505.21523/x6.png",
                "caption": "Figure 6:Attention shift in the reasoning model under different reasoning length. In normal thinking, the model generates outputs as typically expected, while in overthinking, the reasoning length is adjusted using Latent State Steering (Section4.1).Longer reasoning chains further exacerbate the degradation of attention to visual information and focus toward linguistic priors.",
                "position": 194
            }
        ]
    },
    {
        "header": "4Effects of Reasoning Length on Reasoning-Hallucination Balance",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21523/x7.png",
                "caption": "Figure 7:Reasoning-Hallucination balance of multimodal reasoning models under varying reasoning lengths. Thinking lengths are controlled within [0–600] tokens for reasoning and [0–300] for hallucination, corresponding to the longer chains required for reasoning and shorter for hallucination.",
                "position": 256
            }
        ]
    },
    {
        "header": "5Evaluation on the Reasoning-Hallucination Balance",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21523/x8.png",
                "caption": "Figure 8:(a)Accuracy trends on theRH-Benchreasoning task across different reasoning lengths for 3B and 7B models.Larger models typically exhibit more stable performance across varying reasoning lengths.(b)Comparison of SFT+RL and RL-only training paradigms in terms ofRH-AUC, with arrow directions indicating the increase in reasoning length for SFT+RL relative to RL-only.RL-only training tends to generate more concise reasoning chains, leading to a better perception hallucination balance.(c)Case study comparing RL-only and SFT+RL models.SFT+RL models often introduce rigid imitation reasoning paths, which limit the flexibility of visual reasoning.",
                "position": 449
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]