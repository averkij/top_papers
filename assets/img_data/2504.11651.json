[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Motivation: Is Lossless Compression of LLMs Worth Studying?",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.11651/x1.png",
                "caption": "Figure 1:(Left) The allocation of bits for the components of BFloat16. (Right 3) The information content, as measured by Shannon Entropy, of the components (sign, exponent, mantissa) of BFloat16 weights in various LLMs.",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2504.11651/x1.png",
                "caption": "",
                "position": 332
            },
            {
                "img": "https://arxiv.org/html/2504.11651/x2.png",
                "caption": "",
                "position": 336
            },
            {
                "img": "https://arxiv.org/html/2504.11651/x3.png",
                "caption": "Figure 2:An illustration of our proposed format Dynamic-Length Float for compressing the BFloat16 weights of LLMs losslessly.",
                "position": 362
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.11651/x4.png",
                "caption": "Figure 3:Comparison of average latency and throughput for token decoding between the original (BF16) models and their losslessly compressed (DF11) counterparts. Portions of the BF16 models are offloaded to the CPU due to GPU memory constraints.",
                "position": 1102
            },
            {
                "img": "https://arxiv.org/html/2504.11651/x5.png",
                "caption": "Figure 4:Comparison of GPU memory consumption between the original (BF16) models and their losslessly compressed (DF11) counterparts. The DF11 models support 5.33–13.17×\\times×longer context lengths by allowing more GPU memory to be used for storing the KV cache. “O.O.M.” means out of memory.",
                "position": 1105
            },
            {
                "img": "https://arxiv.org/html/2504.11651/x6.png",
                "caption": "Figure 5:Comparison of latency breakdown for DFloat11 and BFloat16 Llama-3.1-8B-Instruct during GPU inference for different token batch sizes, using one A100-40GB GPU.",
                "position": 1135
            },
            {
                "img": "https://arxiv.org/html/2504.11651/x7.png",
                "caption": "Figure 6:Throughput (top two) and latency (bottom two) comparisons between transferring BFloat16 matrices from CPU to GPU and decompressing the same matrices using the NVIDIA nvCOMP ANS library and our proposed DFloat11 kernel, across matrix sizes and GPU types.",
                "position": 1138
            }
        ]
    },
    {
        "header": "5Related Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AFrequency Distribution of BFloat16 Values",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.11651/x8.png",
                "caption": "Figure 7:Relative frequency distribution of sign, exponent, and mantissa values in the BFloat16 weights of all linear projection layers across various LLMs.",
                "position": 1729
            },
            {
                "img": "https://arxiv.org/html/2504.11651/x9.png",
                "caption": "Figure 8:Distribution of BFloat16 exponent values across various models. The frequency of exponent values (shown in log scale) decays rapidly with exponent rank.",
                "position": 1732
            }
        ]
    },
    {
        "header": "Appendix BHardware for Experiments",
        "images": []
    },
    {
        "header": "Appendix CGPU Inference Efficiency Comparison: BF16 vs. DF11",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.11651/x10.png",
                "caption": "Figure 9:Comparison of average latency and throughput for token decoding between the original (BF16) models and their losslessly compressed (DF11) counterparts. The DF11 models are run on a single GPU, while the BF16 models require two GPUs due to memory constraints.",
                "position": 1790
            }
        ]
    },
    {
        "header": "Appendix DImpact of Lossy Quantization",
        "images": []
    }
]