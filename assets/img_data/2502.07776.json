[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07776/x1.png",
                "caption": "Figure 1:An example illustrating prompt caching. (1) A victim sends a prompt to the API, which then becomes cached. (2) An attacker sends a new prompt, resulting in a cache miss and slow response time. (3) An attacker sends a prompt that shares a prefix with the victim’s prompt, resulting in a cache hit. From the fast response time, the attacker can infer that a cache hit occurred, which potentially reveals information about other users’ prompts.",
                "position": 139
            }
        ]
    },
    {
        "header": "2Preliminaries and Assumptions",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07776/x2.png",
                "caption": "Figure 2:Organizations contain users, and the global level contains all users and organizations of an API.",
                "position": 222
            }
        ]
    },
    {
        "header": "3An Audit to Detect Prompt Caching",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07776/x3.png",
                "caption": "Figure 3:Histograms of response times from the cache hit and cache miss procedures in APIs where we detected caching. The distributions of times are clearly distinguishable, with cache hits tending to be faster. Each histogram title states the API provider, model, level of cache sharing (per-org. or global), timing source (client-side or server-side timing), and theNumVictimRequestsused, denotedv.",
                "position": 538
            }
        ]
    },
    {
        "header": "4Auditing Real-World APIs",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07776/x4.png",
                "caption": "Figure 4:Selected precision-recall curves for distinguishing between times from the cache hit and cache miss procedures. Cache hits are the positive class. The curves show that cache hits can be detected with near perfect precision up to moderate recall scores. Figure6in the appendix contains curves for other APIs.",
                "position": 624
            },
            {
                "img": "https://arxiv.org/html/2502.07776/x5.png",
                "caption": "Figure 5:Ablations on the effects ofPromptLength,PrefixFraction, and model size on the average precision. In (a)–(c), as the prompt length or prefix match length decreases, the average precision decreases to random chance. In (d), we detect caching across all model sizes, with no clear relationship between model size and average precision.",
                "position": 627
            }
        ]
    },
    {
        "header": "5Leakage of Architecture Information",
        "images": []
    },
    {
        "header": "6Mitigations",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "Conflicts of Interest",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrecision-Recall Curves",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07776/x6.png",
                "caption": "Figure 6:Precision-recall curves for distinguishing between times produced by the cache hit and cache miss procedures in APIs where we detected caching in our audits (Table1). Cache hits are the positive class, and cache misses are the negative class. The curves show that cache hits can be detected with near perfect precision up to moderate recall scores. Note that our cache hit procedure attempts to produce cache hits but cannot guarantee cache hits (e.g., due to server routing), so some times in the cache hit distribution may actually be cache misses, which would hurt recall scores.",
                "position": 1452
            }
        ]
    },
    {
        "header": "Appendix BP-values from Audits",
        "images": []
    },
    {
        "header": "Appendix CAblation Effects on Audit p-values",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07776/x7.png",
                "caption": "Figure 7:Ablations on the effects ofPromptLength,PrefixFraction, and model size on the audit p-values. Each test is run usingNumSamples=250NumSamples250\\textsc{NumSamples}=250NumSamples = 250. The top and bottom rows display the p-values on linear and logarithmic scales, respectively. In (a)–(c), as the prompt length or prefix match length decreases, the p-values grow larger. In (d), we detect caching across all model sizes, with no clear relationship between model size and p-values.",
                "position": 2517
            }
        ]
    },
    {
        "header": "Appendix DEmbeddings and Response Times from the OpenAI text-embedding-3-small API",
        "images": []
    }
]