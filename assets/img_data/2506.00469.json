[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Data and Model Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00469/x1.png",
                "caption": "(a)Bilingual translation data",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x1.png",
                "caption": "(a)Bilingual translation data",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x2.png",
                "caption": "(b)Monolingual data",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x3.png",
                "caption": "(c)Instruction data",
                "position": 542
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x4.png",
                "caption": "(a)Data mix 1: bilingual",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x4.png",
                "caption": "(a)Data mix 1: bilingual",
                "position": 586
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x5.png",
                "caption": "(b)Data mix 2: monolingual",
                "position": 591
            }
        ]
    },
    {
        "header": "3Evaluation and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00469/x6.png",
                "caption": "(a)Llama 3",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x6.png",
                "caption": "(a)Llama 3",
                "position": 750
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x7.png",
                "caption": "(b)Llama 3.1",
                "position": 755
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x8.png",
                "caption": "Figure 4:Model adaptability measured by the number of benchmarks on which CPT models are worse than the base model. CPT on LLaMA 2 (L2 Mono) shows a negligible BERTScore drop on MassiveSumm. More highly optimized models such as LLaMA 3 and 3.1 present greater challenges for effective continual pre-training compared to LLaMA 2, especially for high-resource languages, while the situation slightly eases for low-resource languages.",
                "position": 1125
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AFrequently Asked Questions",
        "images": []
    },
    {
        "header": "Appendix BDetails ofMaLATranslation Corpus",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00469/x9.png",
                "caption": "(a)Number of tokens",
                "position": 4693
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x9.png",
                "caption": "(a)Number of tokens",
                "position": 4696
            },
            {
                "img": "https://arxiv.org/html/2506.00469/x10.png",
                "caption": "(b)Number of segments",
                "position": 4702
            }
        ]
    },
    {
        "header": "Appendix CDetails of Data Mixes",
        "images": []
    },
    {
        "header": "Appendix DDetailed Evaluation Setup",
        "images": []
    },
    {
        "header": "Appendix EDetailed Results",
        "images": []
    },
    {
        "header": "Appendix FEthics Considerations",
        "images": []
    }
]