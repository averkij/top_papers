[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24601/x1.png",
                "caption": "Figure 1:A comparison of GPT-5 and a corresponding RLM on three long-context tasks of increasing complexity:S-NIAH,OOLONG, andOOLONG-Pairs. For each task, we scale the input length from2132^{13}to2182^{18}. GPT-5 performance degrades significantly as a function of both input length and task complexity, while the RLM maintains strong performance.\nInputs beyond the red region do not fit in GPT-5’s context window of 272K tokens, but the RLM handles them effectively. Additional experiments across other models, methods, and benchmarks are in §2.",
                "position": 86
            },
            {
                "img": "https://arxiv.org/html/2512.24601/figures/Fig2.png",
                "caption": "Figure 2:A Recursive Language Model (RLM) treats prompts as part of the environment. It loads the input prompt as a variable inside a Python REPL environmentℰ\\mathcal{E}and writes code to peek into, decompose, and invoke itself recursively over programmatic snippets of the variable.",
                "position": 96
            }
        ]
    },
    {
        "header": "2Scaling Long Context Tasks",
        "images": []
    },
    {
        "header": "3Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24601/figures/cost_quartiles_dual.png",
                "caption": "Figure 3:Cost of RLM and baselines described in §2.2plotted at the 25th, 50th, 75th, and 95th percentile of total API cost. We observe comparable or even lower costs for RLMs at the 50th percentile, but sharp increases at the tail end due to potentially long RLM trajectories.",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2512.24601/figures/code-examples.png",
                "caption": "Figure 4:RLMs have common patterns in their trajectories when solving tasks. (a) We frequently observed RLMs filtering and interacting with their context through code likeregexqueries. (b) We found that RLMs can effectively decompose their context through recursive sub-calls (c) On long-output tasks, RLMs are able to solve sub-problems using recursive sub-LM calls and stitch their outputs to form a final output.",
                "position": 356
            }
        ]
    },
    {
        "header": "4Related Works",
        "images": []
    },
    {
        "header": "5Limitations and Future Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix ANegative Results: Things we Tried that Did Not Work.",
        "images": []
    },
    {
        "header": "Appendix BAdditional RLM Trajectories",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/bcp-74_1.png",
                "caption": "",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/bcp-74_2-1.png",
                "caption": "",
                "position": 462
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/bcp-74_2-2.png",
                "caption": "",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/bcp-74_3.png",
                "caption": "",
                "position": 471
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/op-3_1.png",
                "caption": "",
                "position": 490
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/op3_2.png",
                "caption": "",
                "position": 496
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/op3_3.png",
                "caption": "",
                "position": 502
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/op3_4.png",
                "caption": "",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/op3_5.png",
                "caption": "",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/op3_6.png",
                "caption": "",
                "position": 520
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/o-212_1.png",
                "caption": "",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2512.24601/x2.png",
                "caption": "",
                "position": 563
            },
            {
                "img": "https://arxiv.org/html/2512.24601/x3.png",
                "caption": "",
                "position": 566
            },
            {
                "img": "https://arxiv.org/html/2512.24601/trajectories/o-212_3.png",
                "caption": "",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2512.24601/x4.png",
                "caption": "",
                "position": 616
            }
        ]
    },
    {
        "header": "Appendix CAdditional Runtime and Cost Analysis of RLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24601/figures/runtime_quartiles_gpt-5.png",
                "caption": "Figure 5:Plotted quartiles of the runtime GPT-5 across OOLONG, OOLONG-Pairs, CodeQA, and BrowseComp+ (1K) for all methods described in §2.2. We plot the 25th, 50th, 75th, and 95th percentiles.",
                "position": 636
            },
            {
                "img": "https://arxiv.org/html/2512.24601/figures/runtime_quartiles_qwen3-coder-480b-a35b-instruct.png",
                "caption": "Figure 6:Plotted quartiles of the runtime Qwen3-Coder-480B across OOLONG, OOLONG-Pairs, CodeQA, and BrowseComp+ (1K) for all methods described in §2.2. We plot the 25th, 50th, 75th, and 95th percentiles.",
                "position": 639
            },
            {
                "img": "https://arxiv.org/html/2512.24601/figures/cost_distributions_gpt-5.png",
                "caption": "Figure 7:Histogram of the API costs for GPT-5 across OOLONG, OOLONG-Pairs, CodeQA, and BrowseComp+ (1K) for all methods described in §2.2.",
                "position": 642
            },
            {
                "img": "https://arxiv.org/html/2512.24601/figures/cost_distributions_qwen3-coder-480b-a35b-instruct.png",
                "caption": "Figure 8:Histogram of the API costs for Qwen3-Coder-480B across OOLONG, OOLONG-Pairs, CodeQA, and BrowseComp+ (1K) for all methods described in §2.2.",
                "position": 645
            },
            {
                "img": "https://arxiv.org/html/2512.24601/figures/scaling_cost.png",
                "caption": "Figure 9:We plot the API cost in USD for the runs in Figure1.",
                "position": 648
            }
        ]
    },
    {
        "header": "Appendix DAdditional Methods and Baseline Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24601/figures/browsecomp-plus.png",
                "caption": "Figure 10:We plot the performance and API cost per answer of various methods using GPT-5 on 20 random queries in BrowseComp-Plus given increasing numbers of documents in context. Only the iterative methods (RLM, ReAct) maintain reasonable performance at 100+ documents.",
                "position": 1565
            }
        ]
    },
    {
        "header": "Appendix EAdditional Benchmark Details",
        "images": []
    }
]