[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02705/x1.png",
                "caption": "Figure 1:Arbitrary-resolution images generated by ControlAR.Our ControlAR extends autoregressive models,e.g., LlamaGen(Sun et al.,2024), to generate high-quality images using spatial controls and expands the capability of autoregressive models to any-resolution image generation.",
                "position": 138
            }
        ]
    },
    {
        "header": "1Introdution",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02705/x2.png",
                "caption": "Figure 2:Comparison between Conditional Prefillingv.s.Conditional Decoding.We encode the spatial control images into a sequence of control tokens for autoregressive models. (a) Conditional Prefilling: control condition tokens are prefilled into the autoregressive model before the first image token is generated. (b) Conditional Decoding: each image token is fused with the control condition token to predict the next image token. (c) Image Quality: we compare the performance (i.e., F1-Score and FID) across training epochs between conditional decoding and prefilling. It’s remarkable that conditional decoding outperforms conditional prefilling in terms of performance and training convergence speed. (d) Training cost: conditional prefilling significantly increases the training memory (+59.1%) and training latency (+96.3%) compared to conditional decoding.",
                "position": 159
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3ControlAR",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02705/x3.png",
                "caption": "Figure 3:The overall architecture of ControlAR. The control image will be flattened into patches and encoded as a sequence of control tokens via the proposedcontrol encoder.\nFor controllable image generation, we extend several sequential layers (i.e., causal Transformer layer or Mamba layer) of the autoregressive model intoconditional sequential layersby incorporating the fusion of control tokens and image tokens to predict the next image token. Finally, the image tokens are decoded into a generated image through the VQGAN decoder.",
                "position": 339
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02705/x4.png",
                "caption": "Figure 4:Visualization of C2I controllable generation.Our ControlAR generates images with high conditional consistency and quality on both LlamaGen and AiM.",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x5.png",
                "caption": "Figure 5:Visualization of text-to-image controllable generation.We use red boxes to mark areas where the generated results of other methods differ from the input control image.",
                "position": 680
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x6.png",
                "caption": "Figure 6:Comparison of ControlAR and Multi-Resolution ControlAR.(a) shows the generation process of ControlAR and MR-ControlAR under the resolution of 768×\\times×512. “Decoding×\\times×1024” denotes that 1024 image tokens need to be decoded for output. (b) compares the conditional consistency of ControlAR and MR-ControlAR under different resolutions of control conditions.",
                "position": 683
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02705/x7.png",
                "caption": "Figure 7:Segmentation mask control generation visualization.",
                "position": 1814
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x8.png",
                "caption": "Figure 8:Canny edge control generation visualization.",
                "position": 1817
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x9.png",
                "caption": "Figure 9:Hed edge control generation visualization.",
                "position": 1820
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x10.png",
                "caption": "Figure 10:Lineart edge control generation visualization.",
                "position": 1823
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x11.png",
                "caption": "Figure 11:Depth map control generation visualization.",
                "position": 1826
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x12.png",
                "caption": "Figure 12:visualization comparison of MR-ControlAR and ControlAR at the resolution of1024×51210245121024\\times 5121024 × 512.",
                "position": 1829
            },
            {
                "img": "https://arxiv.org/html/2410.02705/x13.png",
                "caption": "Figure 13:visualization comparison of MR-ControlAR and ControlAR at the resolution of576×10245761024576\\times 1024576 × 1024.",
                "position": 1832
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]