[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15745/x1.png",
                "caption": "Figure 1:LLaDA2.0-flashmain results.",
                "position": 243
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3LLaDA2.0 Training Paradigm",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15745/x2.png",
                "caption": "Figure 2:A schematic of the progressive training framework for transforming an AR model into a MDLM.Continual Pre-Training Stage facilitates theWarmup-Stable-Decaystrategies by scheduling block sizeLBL_{B}enables smooth, stable, and effective attention mask adaptation. Post-training Stage facilitates the same block diffusion configuration conducting the instruction SFT, Confidence-Aware Parallel SFT, and DPO. The right panel illustrates the document-level block diffusion attention mask,which enables an efficient, vectorized forward pass by constructing a single input sequence from multiple noisy and clean examples, such as[ùíônoisy1,‚Ä¶,ùíôclean1,‚Ä¶][\\bm{x}_{\\text{noisy1}},\\dots,\\bm{x}_{\\text{clean1}},\\dots]. The forward pass then employs a combination of block-diagonal (ùêåBD\\mathbf{M}_{\\text{BD}}), offset block-causal (ùêåOBC\\mathbf{M}_{\\text{OBC}}), and block-causal (ùêåBC\\mathbf{M}_{\\text{BC}}) masks.",
                "position": 327
            }
        ]
    },
    {
        "header": "4Continual Pre-training via Warmup-Stable-Decay (WSD)",
        "images": []
    },
    {
        "header": "5Post-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15745/x3.png",
                "caption": "Figure 3:Average score and tokens‚Äëper‚Äëforward (TPF) for LLaDA2.0‚Äëflash with and without CAP across 12 benchmarks. Inference speed (tokens per second) of LLaDA2.0‚Äëflash compared with similarly sized AR models on 4 code and math benchmarks.",
                "position": 586
            }
        ]
    },
    {
        "header": "6Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15745/x4.png",
                "caption": "Figure 4:Score/TPF vs threshold/block size",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2512.15745/x4.png",
                "caption": "Figure 4:Score/TPF vs threshold/block size",
                "position": 1434
            },
            {
                "img": "https://arxiv.org/html/2512.15745/x5.png",
                "caption": "Figure 5:Performance on the RULER benchmark.",
                "position": 1439
            }
        ]
    },
    {
        "header": "7Training & Inference Infrastructure",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15745/x6.png",
                "caption": "Figure 6:Parallelism overview.",
                "position": 1481
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    }
]