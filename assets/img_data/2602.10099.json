[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10099/x1.png",
                "caption": "Figure 1:Bridging the Geometric Gap.We demonstrate that respecting the intrinsic geometry of pre-trained representations encoders enables the use of standard Diffusion Transformers without any architectural modification such as Width Scaling(zheng2025diffusion). Our method, Riemannian Flow Matching with Jacobi Regularization (+DiNO+RJF), achieves an FID of4.95using standard LightingDiT-B(yao2025reconstruction)architecturewithout guidance, significantly outperforming the VAE-basedLightingDiT-B(FID15.83). In contrast, applying standard Flow Matching to DINOv2-B features (+DiNO) fails to converge (FID21.64) due toGeometric Interference. Even restricting the noise to the hypersphere to strictly learn the angular component (+DiNO+SN) yields only marginal improvement (FID19.07), as the Euclidean linear paths still traverse the low-probability interior of the feature manifold.",
                "position": 67
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10099/x2.png",
                "caption": "Figure 2:Geometric Trajectories on the Hypersphere.Visualization of flow matching paths on the manifoldùíÆd‚àí1\\mathcal{S}^{d-1}.\nStandard Euclidean Flow Matching constructs linear paths that ignore the manifold geometry. Whether targeting standard Gaussian noiseœµ\\epsilon(orange) or projecting noise onto the sphereœµs\\epsilon_{s}(purple) to strictly learn the angular component, the linear interpolation forms achordthat cuts through the low-density interior. This forces the model to learn a velocity field in undefined regions regardless of the endpoint.\nIn contrast, Riemannian Flow Matching follows the geodesic(blue curve), ensuring the intermediate statextx_{t}remains strictly on the manifold surface. The resulting velocity fieldutM‚Äã(xt)u_{t}^{M}(x_{t})is correctly defined within the tangent space (pink plane), naturally respecting the geometry of the representations.",
                "position": 83
            }
        ]
    },
    {
        "header": "2Geometrical Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10099/graph/hardshell_geometry_log_plot.png",
                "caption": "Figure 3:The Geometry Gap. A comparison of radial feature norms (r=‚Äñz‚Äñ2r=\\|z\\|_{2}) between DINOv2-B representations and a standard Gaussian prior in‚Ñù768\\mathbb{R}^{768}. While the Gaussian prior (blue) is distributed across a diffuse shell, DINOv2-B features (orange) are rigidly constrained to a hypersphere with near-zero radial variance. This extreme geometric mismatch prevents standard diffusion models from converging effectively.",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2602.10099/x3.png",
                "caption": "Figure 4:Geometric Interference vs. Capacity.We train DiT-S models of varying widths on DINOv2 tokens (d=768d=768).Top Row:When minimizing Euclidean MSE, narrower models (d<768d<768) suffer from collapse; the Angular Loss (semantics) gets stuck.Bottom Row:When the radial loss is ignored, even narrow models (d=384d=384) converge perfectly on the angular component. This proves the bottleneck is not the dimensionality of the data, but the geometric conflict in the objective.",
                "position": 140
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10099/x4.png",
                "caption": "Table 2:Class-conditional performance on ImageNet 256√ó\\times256 with and without guidance.Our method achieves a superior FID of3.62, outperforming the standard flow matching baseline (FID 4.28).",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2602.10099/x4.png",
                "caption": "Figure 5:Qualitative results of LightingDiT-XL+RJF trained for 80 epochs on ImageNet 256√ó\\times256.We show uncurated results on the five classes .",
                "position": 963
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    }
]