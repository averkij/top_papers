[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02350/x1.png",
                "caption": "Figure 1:An illustration of context misalignment of an existing method (DebateDu et al. (2023)) on a multi-step proof task. Pre-assigned context instructions (in the blue and yellow boxes of the left part) provide insufficient guidance on information fusion, leading to conflict in reasoning.",
                "position": 122
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x2.png",
                "caption": "Figure 2:The discrepancy between the answers of participating LLM instances. The discrepancy is characterized by the maximum distance between participating LLMs’ output embeddings.",
                "position": 125
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Motivation",
        "images": []
    },
    {
        "header": "5Multi-LLM Context Learning",
        "images": []
    },
    {
        "header": "6Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02350/x3.png",
                "caption": "Figure 3:Performance versus runtime under different settings. Circles closer to the lower-left corner indicate higher efficiency.",
                "position": 1567
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x4.png",
                "caption": "Figure 4:Performance of varying the numbers of LLMs. Uncertainty intervals depict standard deviation over three seeds.",
                "position": 1570
            }
        ]
    },
    {
        "header": "7Limitation and Discussion",
        "images": []
    },
    {
        "header": "8Ethics Statement",
        "images": []
    },
    {
        "header": "9Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AUsage of LLMs",
        "images": []
    },
    {
        "header": "Appendix BProof ofTheorem˜4.1",
        "images": []
    },
    {
        "header": "Appendix CDecoupled Criterion Fucntion",
        "images": []
    },
    {
        "header": "Appendix DUseful Lemma",
        "images": []
    },
    {
        "header": "Appendix EMulti-Round Context Learning",
        "images": []
    },
    {
        "header": "Appendix FExperiment Setup",
        "images": []
    },
    {
        "header": "Appendix GAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02350/x5.png",
                "caption": "Figure 5:Performance of llama-7b as the base model with varying number of LLMs. Uncertainty intervals depict standard deviation over three seeds.M2CLexhibits higher performance and increasing tendency with more LLMs, demonstrating its great collaboration efficiency compared to existing methods. Of note, academic and agentic tasks reasoning are challenging because they require more diverse thinking perspectives and more rigorous analysis. The outperformance ofM2CLreveals its capability of enabling LLMs to collaborate in changing discussion state.",
                "position": 15355
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x6.png",
                "caption": "",
                "position": 15359
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x7.png",
                "caption": "Figure 6:Performance of llama-13b as the base model with varying number of LLMs. Uncertainty intervals depict standard deviation over three seeds.M2CLexhibits higher performance and increasing tendency with more LLMs, demonstrating its great collaboration efficiency compared to existing methods.",
                "position": 15363
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x8.png",
                "caption": "",
                "position": 15367
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x9.png",
                "caption": "Figure 7:Performance as llama-70b as the base model with varying number of LLMs. Uncertainty intervals depict standard deviation over three seeds.M2CLexhibits higher performance and increasing tendency with more LLMs, demonstrating its great collaboration efficiency compared to existing methods.",
                "position": 15371
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x10.png",
                "caption": "",
                "position": 15375
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x11.png",
                "caption": "Figure 8:Performance of Qwen-7b as the base model with varying number of LLMs. Uncertainty intervals depict standard deviation over three seeds.M2CLexhibits higher performance and increasing tendency with more LLMs, demonstrating its great collaboration efficiency compared to existing methods.",
                "position": 15379
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x12.png",
                "caption": "",
                "position": 15383
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x13.png",
                "caption": "Figure 9:Performance of Qwen-14b as the base model with varying number of LLMs. Uncertainty intervals depict standard deviation over three seeds.M2CLexhibits higher performance and increasing tendency with more LLMs, demonstrating its great collaboration efficiency compared to existing methods.",
                "position": 15387
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x14.png",
                "caption": "",
                "position": 15391
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x15.png",
                "caption": "Figure 10:Performance of Qwen-72b as the base model with varying number of LLMs. Uncertainty intervals depict standard deviation over three seeds.M2CLexhibits higher performance and increasing tendency with more LLMs, demonstrating its great collaboration efficiency compared to existing methods.",
                "position": 15395
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x16.png",
                "caption": "",
                "position": 15399
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x17.png",
                "caption": "Figure 11:Performance of Qwen2.5-VL (3B and 7B) as the base model with varying number of LLMs.M2CLexhibits higher performance and increasing tendency with more LLMs, demonstrating its great collaboration efficiency compared to existing methods. Uncertainty intervals depict standard deviation over three seeds.",
                "position": 15922
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x18.png",
                "caption": "Figure 12:Performance with varying context constraint when 4 LLMs participate. All the curves display the same trend of rising first and then falling, which is consistent with our theory.",
                "position": 15933
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x19.png",
                "caption": "Figure 13:Performance with varying context constraint when 8 LLMs participate.",
                "position": 15936
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x20.png",
                "caption": "Figure 14:Performance with varying context constraint when 16 LLMs participate.",
                "position": 15939
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x21.png",
                "caption": "Figure 15:Performance with varying context constraint when 32 LLMs participate.",
                "position": 15942
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x22.png",
                "caption": "Figure 16:Performance with varying context constraint when 64 LLMs participate.",
                "position": 15945
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x23.png",
                "caption": "Figure 17:Comparative results on discrepancy intensity with varying model size (from top to bottom correspond to 7B, 14B, and 70B). The number of agents is set as44. Lower values represent a lower degree of disagreement.M2CLcan improve consistency with fewer rounds. Of note,M2CLdisplays both a lower initial value and a faster decreasing speed, indicating its capability of assigning appropriate contexts based on the given question and current discussion situation.",
                "position": 15956
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x24.png",
                "caption": "Figure 18:Comparative results on discrepancy intensity with varying model size (from top to bottom correspond to 7B, 14B, and 70B). The number of agents is set as88. Lower values represent a lower degree of disagreement.M2CLcan improve consistency with fewer rounds.",
                "position": 15959
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x25.png",
                "caption": "Figure 19:Comparative results on discrepancy intensity with varying model size (from top to bottom correspond to 7B, 14B, and 70B). The number of agents is set as1616. Lower values represent a lower degree of disagreement.M2CLcan improve consistency with fewer rounds.",
                "position": 15962
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x26.png",
                "caption": "Figure 20:Comparative results on discrepancy intensity with varying model size (from top to bottom correspond to 7B, 14B, and 70B) The number of agents is set as3232. Lower values represent a lower degree of disagreement.M2CLcan improve consistency with fewer rounds.",
                "position": 15965
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x27.png",
                "caption": "Figure 21:Comparative results on discrepancy intensity with varying model size (from top to bottom correspond to 7B, 14B, and 70B). The number of agents is set as6464. Lower values represent a lower degree of disagreement.M2CLcan improve consistency with fewer rounds.",
                "position": 15968
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x28.png",
                "caption": "Figure 22:The value ofL​(θ)L(\\theta)when training llama-7B with 8 LLMs participating.",
                "position": 16552
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x29.png",
                "caption": "",
                "position": 16556
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x30.png",
                "caption": "Figure 23:Runtime of initialization. Uncertainty intervals depict standard deviation over three seeds.",
                "position": 19713
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x31.png",
                "caption": "",
                "position": 19717
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x32.png",
                "caption": "Figure 24:Runtime when varying the size of the LLama series models. The number of LLMs is88. Uncertainty intervals depict standard deviation over three seeds.",
                "position": 19724
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x33.png",
                "caption": "",
                "position": 19728
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x34.png",
                "caption": "Figure 25:Visualization ofM2CLat thefirst round.",
                "position": 19748
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x35.png",
                "caption": "Figure 26:Visualization ofM2CLat thesecond round. We highlight the guidance on how to cooperate with other LLMs. At the beginning, instructions encourage diverse perspectives and consideration of others’ responses, but the requirements for discussion consistency are not yet strict.",
                "position": 19751
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x36.png",
                "caption": "Figure 27:Visualization ofM2CLat thethird round. We highlight the guidance on how to cooperate with other LLMs. As the discussion progresses, the instructions increasingly enforce stricter requirements for cross-checking and aligning answers, helping the models converge toward a consistent solution.",
                "position": 19754
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x37.png",
                "caption": "Figure 28:Visualization ofM2CLat thelast round. We highlight the guidance on how to cooperate with other LLMs. Although the initial round produced divergent answers, the collaborative instructions enable LLMs to exchange and integrate information, ultimately reaching a correct consensus.",
                "position": 19757
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x38.png",
                "caption": "Figure 29:Visualization ofDebateat thefirst round.",
                "position": 19769
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x39.png",
                "caption": "Figure 30:Visualization ofDebateat thesecond round.",
                "position": 19772
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x40.png",
                "caption": "Figure 31:Visualization ofDebateat thethird round.",
                "position": 19775
            },
            {
                "img": "https://arxiv.org/html/2602.02350/x41.png",
                "caption": "Figure 32:Visualization ofDebateat thelast round.",
                "position": 19778
            }
        ]
    },
    {
        "header": "Appendix HCase study",
        "images": []
    }
]