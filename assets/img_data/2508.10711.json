[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10711/x1.png",
                "caption": "",
                "position": 125
            },
            {
                "img": "https://arxiv.org/html/2508.10711/x2.png",
                "caption": "",
                "position": 126
            },
            {
                "img": "https://arxiv.org/html/2508.10711/x3.png",
                "caption": "",
                "position": 127
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10711/x4.png",
                "caption": "Figure 1:Overview of NextStep-1 in high-fidelity image generation, diverse image editing, and complex free-form manipulation.",
                "position": 140
            }
        ]
    },
    {
        "header": "2Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10711/x5.png",
                "caption": "Figure 2:Overview of NextStep-1 Framework. NextStep-1 employs a causal transformer to process tokenized text and image tokens. During training, Flow Matching Head predicts the continuous flow from a noise sample to the next target image patch, conditioned on the output hidden state. At inference, this allows for generating images by iteratively guiding noise to create the next patch.",
                "position": 162
            }
        ]
    },
    {
        "header": "3Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10711/x6.png",
                "caption": "Figure 3:Data processing of character-centric data.",
                "position": 312
            }
        ]
    },
    {
        "header": "4Training Recipe",
        "images": []
    },
    {
        "header": "5Model Performance",
        "images": []
    },
    {
        "header": "6Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10711/x7.png",
                "caption": "Figure 4:Images generated under different flow-matching heads.",
                "position": 1652
            },
            {
                "img": "https://arxiv.org/html/2508.10711/x7.png",
                "caption": "Figure 4:Images generated under different flow-matching heads.",
                "position": 1655
            },
            {
                "img": "https://arxiv.org/html/2508.10711/x8.png",
                "caption": "Figure 5:Evolution of per-token mean and variance over sampling steps under two CFG settings. At CFG = 1.5, the mean and variance stay close to 0 and 1, respectively, indicating stability. At CFG = 3.0, they drift significantly, causing image quality degradation. With normalization, the distributions of output latents remain stable across all CFG settings.",
                "position": 1756
            },
            {
                "img": "https://arxiv.org/html/2508.10711/x9.png",
                "caption": "Figure 6:Impact of Noise Perturbation on Image Tokenizer Performance. The top panel displays quantitative metrics (rFID↓\\downarrow, PSNR↑\\uparrow, and SSIM↑\\uparrow) versus noise intensity. The bottom panel presents qualitative reconstruction examples at noise standard deviations of 0.2 and 0.5.",
                "position": 1788
            },
            {
                "img": "https://arxiv.org/html/2508.10711/x10.png",
                "caption": "Figure 7:Latent distributions in 16 channels for three VAE variants: Flux.1-dev, NextStep-1 w/o noise, and NextStep-1. Blue bars show empirical histograms; red lines indicate the standard normal distribution. NextStep-1 VAE aligns best with the normal distribution, reflecting dispersed latent distribution.",
                "position": 1791
            },
            {
                "img": "https://arxiv.org/html/2508.10711/x11.png",
                "caption": "Figure 8:Failure cases for high-dimensional continuous tokens.",
                "position": 1918
            }
        ]
    },
    {
        "header": "Contributors and Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]