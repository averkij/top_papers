[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04507/x1.png",
                "caption": "Figure 1:(a) Generating a 5s 720P clip in Hunyuan involves processing 115K tokens, making attention the dominant cost. (b) Attention latency comparison: existing methods fail to translate FLOP reduction into wall-clock speedup;STAis hardware-efficient and achieves proportional speedup with sparsity.",
                "position": 110
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x2.png",
                "caption": "Figure 2:Visualization of attention locality. The green point means the query point and the magma-colored regions indicate areas of high attention values in response to the query. Instead of attending to the entire image, the query’s attention forms a concentrated local hotspot.",
                "position": 119
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x3.png",
                "caption": "Figure 3:Left: Fraction of attention scores within a (12, 24, 24) local window across diffusion steps and 10 different prompts. Most heads show high recall, indicating a local attention pattern.Right: Despite the different recall across heads, the standard deviation across prompts remains low.",
                "position": 125
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x4.png",
                "caption": "",
                "position": 134
            }
        ]
    },
    {
        "header": "2Problem",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04507/x5.png",
                "caption": "Figure 4:The attention map of NATTEN, Tiled NATTEN, andSTA. We plot with an image size 24×\\times×24 and a 12×\\times×12 local window. The tile size is set to 4×\\times×4. (a) NATTEN creates many mixed blocks that are very inefficient for Flash Attention computation. (b) Tiled NATTEN increases the number of dense blocks, but the mixed blocks persist. (c)STAcompletely eliminates the mixed block, making the computation extremely friendly for GPU. Note that we mainly showSTA’s application in 3D scenarios for video generation in this paper, but for better illustration, we present the 2D scenario in this plot.",
                "position": 189
            }
        ]
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04507/extracted/6182573/media/Fig6/f6-sta.png",
                "caption": "Figure 5:2DSliding Tile Attentionwith tile size (2, 2) and window size (6, 6). After attending to all the key tiles, each query tile will generate nine 4x4 dense blocks in the attention map. We showcase 2D STA for better illustration. 3D STA can be inferred similarly.",
                "position": 292
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x6.png",
                "caption": "Figure 6:Qualitative example of 720P 5-second videos. While fine-tuning introduces minor shifts in the output distribution of STA-t-2.43x, the model still preserves high video generation quality. Videos generated byΔΔ\\Deltaroman_Δ-DiT are generally less sharp than those generated by the original HunyuanVideo andSTA.",
                "position": 363
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04507/extracted/6182573/media/Fig5/human_eval.png",
                "caption": "Figure 7:Human evaluation on 200 prompts from the MovieGen Bench(Polyak et al.,2024).STAachieves a 1.36× end-to-end speedup while maintaining performance comparable to the original HunyuanVideo. Additionally,STAconsistently outperformsΔΔ\\Deltaroman_Δ-DiT across different inference budgets.",
                "position": 590
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AFurther Details ofSliding Tile Attention",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04507/extracted/6182573/media/appendix/reorder.png",
                "caption": "Figure 8:Left: Conventional zigzag flattening strategy.Right:STA’ sequence flattening strategy. The plot is given assuming a (9, 9) image with (3, 3) tile size.",
                "position": 1648
            },
            {
                "img": "https://arxiv.org/html/2502.04507/extracted/6182573/media/Fig6/f6-swa.png",
                "caption": "Figure 9:2D Sliding Window Attention visualization.",
                "position": 1654
            }
        ]
    },
    {
        "header": "Appendix BFinetuning Details",
        "images": []
    },
    {
        "header": "Appendix CFurther Details of Baselines",
        "images": []
    },
    {
        "header": "Appendix DResults on Image Super-Resolution",
        "images": []
    },
    {
        "header": "Appendix EMore Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04507/x7.png",
                "caption": "Figure 10:Qualitative comparisons. While fine-tuning introduces minor shifts in the output distribution of STA-t-2.43x, the model still preserves high video generation quality. Videos generated byΔΔ\\Deltaroman_Δ-DiT are generally less sharp than those generated by the original HunyuanVideo andSTA.",
                "position": 2306
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x7.png",
                "caption": "",
                "position": 2308
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x8.png",
                "caption": "",
                "position": 2310
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x9.png",
                "caption": "Figure 11:Qualitative comparisons. While fine-tuning introduces minor shifts in the output distribution of STA-t-2.43x, the model still preserves high video generation quality. Videos generated byΔΔ\\Deltaroman_Δ-DiT are generally less sharp than those generated by the original HunyuanVideo andSTA.",
                "position": 2315
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x9.png",
                "caption": "",
                "position": 2317
            },
            {
                "img": "https://arxiv.org/html/2502.04507/x10.png",
                "caption": "",
                "position": 2319
            }
        ]
    },
    {
        "header": "Appendix FQualitative Examples",
        "images": []
    }
]