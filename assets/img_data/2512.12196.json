[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12196/x1.png",
                "caption": "",
                "position": 86
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x2.png",
                "caption": "",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x3.png",
                "caption": "",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x4.png",
                "caption": "",
                "position": 110
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x5.png",
                "caption": "",
                "position": 116
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x6.png",
                "caption": "",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x7.png",
                "caption": "",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x8.png",
                "caption": "",
                "position": 141
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x9.png",
                "caption": "Figure 1:AutoMV video generation results.We introduce AutoMV, a multi-agent pipeline which produces coherent, music-synchronised full-length music videos guided by beat, structure, and lyric cues. Our pipeline generates music videos, which maintain consistent person identity, contain diverse camera shots and visual effects, and align with the corresponding music audio and lyrics.",
                "position": 163
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12196/x10.png",
                "caption": "Figure 2:Motivation for AutoMV.Current music video production requires extensive human labour, time and expense. Our AutoMV workflow saves a large amount of effort while maintaining satisfactory quality. The cost of time and expense are frommv_cost1,mv_cost2and the quality score is from our subjective evaluation.",
                "position": 266
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12196/x11.png",
                "caption": "Figure 3:Overview of AutoMV: a multi-agent pipeline that analyzes music, plans shot-level scripts, generates video clips with adaptive backends, and verifies alignment and realism before assembling a coherent full-length music video. S2V refers to speech-to-video model.",
                "position": 324
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12196/x12.png",
                "caption": "Figure 4:Visualised comparisons with baselines.Our method performs better in identity consistency (a) and content diversity (b), including singing and dancing, which are crucial for music videos. The examples are generated from the same input music.",
                "position": 833
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "Ethics and Social Impact",
        "images": []
    },
    {
        "header": "Appendix ADemo Comparison",
        "images": []
    },
    {
        "header": "Appendix BDetailed Protocol of LLM and Human Experts Scoring",
        "images": []
    },
    {
        "header": "Appendix CDetails of Baseline",
        "images": []
    },
    {
        "header": "Appendix DDetail Results of LLM-score Per-categary",
        "images": []
    },
    {
        "header": "Appendix EFailure Case Study and Future Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12196/fig/tmp_unrealistic.png",
                "caption": "Figure 5:Examples of physically implausible generations",
                "position": 1932
            },
            {
                "img": "https://arxiv.org/html/2512.12196/fig/text.jpg",
                "caption": "Figure 6:Handwritten letter close-up with inconsistent glyph shapes (the second line in the image) and temporal progression.",
                "position": 1941
            },
            {
                "img": "https://arxiv.org/html/2512.12196/fig/tmp_lip.png",
                "caption": "Figure 7:(a) without source separation(b) source separation",
                "position": 1947
            },
            {
                "img": "https://arxiv.org/html/2512.12196/x13.png",
                "caption": "Figure 8:Pearson correlation coefficients between model-generated or objective scores and human ratings across 17 evaluation metrics. The heatmap displays correlations for six models (Gemini-3, Gemini-2.5-Pro, Gemini-2.5-Flash, Qwen-Omni-3, Qwen-Omni-2.5) across 12 sub-criteria (Character Consistency(CC), Physical Authenticity(PA), Lip Sync Accuracy(LS), Visual Harmony(VH), Shot Continuity(SC), Audio-Visual Correlation(AC), Musical Theme Fit(MT), Storytelling(ST), Emotional Expression(EM), Visual Quality(VQ), Creativity(CR), AI Novelty(AN)), 4 category scores (Technical, Post-Production, Content, Artistic), and the Weighted Total score. Darker shades of blue indicate a stronger correlation, while a value of 0 signifies no correlation or that the evaluation method is not applicable to the metric.",
                "position": 1958
            }
        ]
    },
    {
        "header": "Appendix FHuman eval v.s. Gemini eval v.s. Rule-based eval",
        "images": []
    }
]