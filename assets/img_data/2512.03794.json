[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03794/x1.png",
                "caption": "Figure 1:Our key motivations and AdaptVision performance and efficiency.Top: Coarse-to-fine.Human visual attention mechanisms first guide the search for question-relevant regions in images, which are then subjected to detailed analysis.Down:AdaptVision achieves superior performance with significantly fewer visual tokens than previous efficient VLM methods.",
                "position": 105
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/fig2.png",
                "caption": "Figure 2:FrameWork of AdaptVision.AdaptVision first processes a 1/4-resolution image. The model then decides whether to answer directly or invoke the bounding box tool to crop a high-resolution region for further analysis before generating the final answer.",
                "position": 168
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03794/figures/dtpo-fig3.png",
                "caption": "Figure 3:Demonstration of vanilla GRPO and our DTPO.Our DTPO (1) decomposes the policy loss by turns to separately optimize tool and answer tokens, and (2) computes distinct advantages for tool and outcome rewards, enabling balanced optimization and precise credit assignment.",
                "position": 395
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03794/x2.png",
                "caption": "Figure 4:Comparison of Inference Time.(1) Compared to the vanilla model and VisionThinkâ€ , AdaptVision demonstrates significantly reduced inference time due to reduced visual token usage. (2) While AdaptVision requires additional generated tokens for reasoning and tool calls compared to the down-sample model, the resulting increase in inference time remains acceptable.",
                "position": 724
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/adaptvision_comparison.png",
                "caption": "(a)Reward Ablation",
                "position": 727
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/adaptvision_comparison.png",
                "caption": "(a)Reward Ablation",
                "position": 731
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_toolcall_ratio.png",
                "caption": "(b)Training curve of tool call ratio, outcome reward and tool reward",
                "position": 737
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_toolcall_ratio.png",
                "caption": "",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_outcome_reward.png",
                "caption": "",
                "position": 745
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_tool_reward.png",
                "caption": "",
                "position": 750
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_high_ratio.png",
                "caption": "(a)Training curve of tool call ratio on different types of data.",
                "position": 760
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_high_ratio.png",
                "caption": "(a)Training curve of tool call ratio on different types of data.",
                "position": 764
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_high_ratio.png",
                "caption": "",
                "position": 767
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/grpo_vs_dtpo_low_ratio.png",
                "caption": "",
                "position": 772
            },
            {
                "img": "https://arxiv.org/html/2512.03794/figures/tool_call_ratio.png",
                "caption": "(b)Tool call proportion across different benchmarks.",
                "position": 781
            },
            {
                "img": "https://arxiv.org/html/2512.03794/x3.png",
                "caption": "Figure 9:Case study:(1) The vanilla model yields a correct answer but consumes a large number of visual tokens; (2) The down-sample model reduces token usage but fails to answer correctly; (3) AdaptVision smartly invokes the tool to produce a correct answer with minimal visual token cost.",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2512.03794/x3.png",
                "caption": "",
                "position": 817
            },
            {
                "img": "https://arxiv.org/html/2512.03794/x4.png",
                "caption": "",
                "position": 822
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAdditional Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03794/x5.png",
                "caption": "Figure 10:Case of direct answer in AdaptVision.",
                "position": 907
            },
            {
                "img": "https://arxiv.org/html/2512.03794/x6.png",
                "caption": "",
                "position": 911
            },
            {
                "img": "https://arxiv.org/html/2512.03794/x7.png",
                "caption": "Figure 11:Case of tool call in AdaptVision.",
                "position": 915
            }
        ]
    },
    {
        "header": "Appendix BQualitative Results",
        "images": []
    }
]