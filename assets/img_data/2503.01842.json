[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IINTRODUCTION",
        "images": []
    },
    {
        "header": "IIRELATED WORK",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01842/x1.png",
                "caption": "Figure 1:Discrete-time Hybrid Dynamics Learning (DHAL) Framework: (a) During training, the network learns to select the mode and activate the corresponding dynamics module (yellow-highlighted) to predict transition dynamics and contact. Here,PisubscriptùëÉùëñP_{i}italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTrepresents the probability of the robot being in modeiùëñiitalic_iat timetùë°titalic_t. (b) The temporal features extracted by the encoder are combined with the current state and last action into the actor. The actor updateŒ±,Œ≤ùõºùõΩ\\alpha,\\betaitalic_Œ± , italic_Œ≤, which define the probability density function of the Beta distribution, and then samples joint actions from the Beta distribution. (c) In a real-world deployment, we use different LED colors to indicate the active modes, showcasing smooth transitions and mode-specific behaviors.",
                "position": 185
            }
        ]
    },
    {
        "header": "IIIBACKGROUND AND PROBLEM SETTING",
        "images": []
    },
    {
        "header": "IVMETHODS",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01842/x2.png",
                "caption": "Figure 2:Switching of a hybrid system with inelastic collision. When the leg makes contact with the ground, the linear velocity will abruptly drop to zero.",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2503.01842/x3.png",
                "caption": "Figure 3:Multi-Critic Skateboard Task",
                "position": 524
            }
        ]
    },
    {
        "header": "VEXPERIMENTS",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01842/extracted/6249131/fig/Joint_pred.png",
                "caption": "Figure 4:Trajectory Prediction Visualization: The comparison between the actual position trajectory (solid line) and the predicted position trajectory (dashed line) for the right front leg joint motor of the physical Go1 robot during skateboarding is shown. We selected the right front leg joint, which exhibits the largest range of motion, as the visualization target. During deployment, the system utilizes the mode selection results from the automata to choose the corresponding decoder for prediction, consistent with the training process.",
                "position": 812
            },
            {
                "img": "https://arxiv.org/html/2503.01842/extracted/6249131/fig/Dynamics_Prediction_Loss.png",
                "caption": "Figure 5:Dynamics Prediction Loss: The agent‚Äôs dynamics prediction lossMSE‚Å¢(o^t+1,ot+1)MSEsubscript^ùëúùë°1subscriptùëúùë°1\\texttt{MSE}(\\hat{o}_{t+1},{o}_{t+1})MSE ( over^ start_ARG italic_o end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT )during training is shown in the figure, where the thick line represents the average loss, and the shaded regions indicate the confidence intervals across different seeds.",
                "position": 815
            },
            {
                "img": "https://arxiv.org/html/2503.01842/x4.png",
                "caption": "Figure 6:Effectiveness of mode identification. In real-world deployment, we light up different RGB light bar colors according to the mode to show the switching between different mode. The following figure shows the change in joint position relative to time in the test, and the background color is represented by the color of the corresponding mode. [H, T, C] denote the Hip, Thigh, and Calf Joints, respectively.",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2503.01842/extracted/6249131/fig/representation.png",
                "caption": "Figure 7:Visualization of hidden layer of the controller: Scatter points in different colors correspond to the different modes identified by the system, consistent with Fig.6. Specifically, [green, blue, red] represent [mode 1, mode 2, mode 3], respectively.",
                "position": 826
            },
            {
                "img": "https://arxiv.org/html/2503.01842/extracted/6249131/fig/Comparison_reward.png",
                "caption": "Figure 8:Comparison of Training Rewards: Comparison of mean reward during training is shown in the figure, where the thick line represents the average return, and the shaded regions indicate the maximal and minimal reward across different seeds. Each method was trained using four random seeds to evaluate performance.",
                "position": 846
            },
            {
                "img": "https://arxiv.org/html/2503.01842/x5.png",
                "caption": "Figure 9:Comparison between single-critic policy and multi-critic policy: Single-critic-wo-transfer (A‚Å¢1‚àºA‚Å¢3similar-toùê¥1ùê¥3A1\\sim A3italic_A 1 ‚àº italic_A 3), Single-critic-w-transfer (B‚Å¢1‚àºB‚Å¢3similar-toùêµ1ùêµ3B1\\sim B3italic_B 1 ‚àº italic_B 3), ours (C‚Å¢1‚àºC‚Å¢3similar-toùê∂1ùê∂3C1\\sim C3italic_C 1 ‚àº italic_C 3).",
                "position": 902
            }
        ]
    },
    {
        "header": "VILimitations and discussion",
        "images": []
    },
    {
        "header": "VIIConclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMulti-Critic",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01842/x6.png",
                "caption": "Figure 10:Real-world Experiments in Skateboard Park. For additional\ndemonstrations, please refer to the ourwebsite,\nwhere more result videos are available.",
                "position": 1765
            }
        ]
    },
    {
        "header": "Appendix BBeta Distribution",
        "images": []
    },
    {
        "header": "Appendix CNetwork Architecture and Training Hyper-parameter",
        "images": []
    },
    {
        "header": "Appendix DEnvironment Setting and Sim2Real Detail",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01842/x7.png",
                "caption": "Figure 11:Visualization result of handstand task with DHAL framework.",
                "position": 2646
            }
        ]
    },
    {
        "header": "Appendix EExperimental Supplementary Notes",
        "images": []
    }
]