[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07226/x1.png",
                "caption": "Figure 1:Comparison between clean benchmarks andNoisyBench, showing that models perform well in sterilized settings but fail under realistic noise from random documents, irrelevant chat history, and hard negative distractors, which reveals weaknesses in alignment, reasoning, and RAG robustness.",
                "position": 212
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3NoisyBench: Benchmarking Robustness in Noisy Contexts",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07226/x2.png",
                "caption": "Figure 2:Agentic Workflow Results.Agentic workflows improve performance in the clean setting (ND) but degrade under noisy conditions (RD, RC, HN).",
                "position": 735
            }
        ]
    },
    {
        "header": "4Enhancing the Robustness under Contextual Distractors",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07226/x3.png",
                "caption": "Figure 3:Context Engineering Results.Context engineering methods (GEPA, DC, ACE) show limited gains over the base model under noisy distractors (HN, RD, RC).",
                "position": 1515
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x4.png",
                "caption": "Figure 4:Reward Dynamics during RL Training.RAREsteadily reduces distracted chains of thought while increasing outcome-based rewards, which leads to higher final accuracy compared to training with outcome-only rewards (OR).",
                "position": 1530
            }
        ]
    },
    {
        "header": "5Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07226/x5.png",
                "caption": "Figure 5:As distractor similarity increases across benchmarks, accuracy consistently decreases while average reasoning token usage increases.",
                "position": 1553
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x6.png",
                "caption": "Figure 6:Output length shows a weak negative correlation with distractor length, indicating that increased reasoning arises from distractor similarity rather than longer inputs, and reflects confusion during reasoning instead of simple input-length effects.",
                "position": 1556
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x7.png",
                "caption": "Figure 7:Entropy Analysis.Entropy increases consistently as the number of hard negative distractors grows across benchmarks.",
                "position": 1572
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x8.png",
                "caption": "Figure 8:Attention Analysis.Incorrect predictions assign substantially more attention to distractor tokens than correct predictions, which shows that models often rely on irrelevant information during generation and highlights the need to suppress harmful distractor-focused attention.",
                "position": 1588
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Implementation Details",
        "images": []
    },
    {
        "header": "8Further Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07226/x9.png",
                "caption": "Figure 9:Statistics for length of distractors.",
                "position": 1783
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x10.png",
                "caption": "Figure 10:Analyses for domain diversity of questions.",
                "position": 1792
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x11.png",
                "caption": "Figure 11:Analyses for position of distractor.",
                "position": 1804
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x12.png",
                "caption": "Figure 12:Effect of scaling the model size.",
                "position": 1814
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x13.png",
                "caption": "Figure 13:Similarities.",
                "position": 1822
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x14.png",
                "caption": "Figure 14:Transferability.",
                "position": 1836
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x15.png",
                "caption": "Figure 15:Mixed Distractors.",
                "position": 1846
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x16.png",
                "caption": "Figure 16:Inverse Scaling Law.",
                "position": 1861
            },
            {
                "img": "https://arxiv.org/html/2601.07226/x17.png",
                "caption": "Figure 17:Exaggerated Safety Results.Refusal rates under different distractor settings show that adding distractors does not uniformly weaken safety and can even improve jailbreak detection, while refusal on harmless inputs remains stable or decreases.",
                "position": 1967
            }
        ]
    },
    {
        "header": "9Limitations and Future Works",
        "images": []
    },
    {
        "header": "10Potential Broad Impact and Ethics Statement",
        "images": []
    },
    {
        "header": "11Generative AI Usage Statement",
        "images": []
    },
    {
        "header": "12Prompts",
        "images": []
    },
    {
        "header": "13Qualitative Analyses",
        "images": []
    }
]