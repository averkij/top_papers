[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18102/extracted/6300559/figures/AgentRxiv.png",
                "caption": "Figure 1:Collaborative Autonomous Research via AgentRxiv.Autonomous agent laboratories distributed collaboratively pursue a shared research goal usingAgentRxiv. Human researchers provide initial guidance through a research direction and detailed instructions. Agents autonomously perform research and upload research papers to the centralizedAgentRxivpreprint server, enabling laboratories to access each other’s discoveries, accelerating scientific progress.",
                "position": 148
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18102/extracted/6300559/figures/Untitled-3.png",
                "caption": "Figure 2:Agent Laboratory Workflow.(Top) This image showsAgent Laboratory’s three phases: Literature Review, Experimentation, and Report Writing. Human researchers collaborate with AI agents (e.g., PhD, Postdoc) and specialized tools (mle-solver, paper-solver) to automate tasks and produce high-quality research outputs. (Bottom) This",
                "position": 237
            }
        ]
    },
    {
        "header": "3AgentRxiv: Towards Collaborative Autonomous Research",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18102/extracted/6300559/figures/arxival.png",
                "caption": "Figure 3:AgentRxiv Framework for Autonomous Research Collaboration.Depicted are two independent autonomous agent laboratories interacting through the centralized archival preprint server,AgentRxiv. (Left) Laboratory #1 submits a search query toAgentRxiv, retrieving relevant research papers published by other agent laboratories. (Right) Laboratory #2 completes and uploads its research findings toAgentRxiv, making the research accessible for retrieval and use by other autonomous laboratories. This workflow enables efficient knowledge sharing and iterative progress among independent agent systems.",
                "position": 272
            },
            {
                "img": "https://arxiv.org/html/2503.18102/extracted/6300559/figures/SoA_main.png",
                "caption": "Figure 4:Designing Novel Reasoning Techniques on MATH-500.Progression of a single autonomous laboratory iteratively designing reasoning techniques to improve accuracy on the MATH-500 benchmark usinggpt-4o minias the base model. Call-outs indicate the discovery of techniques that set a new highest accuracy on the test set. Techniques such as Progressive Confidence Cascade (PCC), Dynamic Critical Chain Prompting (DCCP), and Dual Anchor Cross-Verification Prompting (DACVP) incrementally increased accuracy from a baseline of 70.2% (gpt-4o mini zero-shot) up to 78.2% (+11.4%) with the final discovered method, Simultaneous Divergence Averaging (SDA).",
                "position": 281
            },
            {
                "img": "https://arxiv.org/html/2503.18102/extracted/6300559/figures/generality.png",
                "caption": "Figure 5:Properties of autonomous discovery.A.The discovered algorithm, Simultaneous Divergence Averaging (SDA), demonstrates generality beyond its original discovery benchmark (MATH-500) to three distinct reasoning benchmarks (MedQA, MMLU-Pro, and GPQA). SDA (blue) consistently improves accuracy compared to 0-shot prompting (gray) across diverse tasks.B.Comparison of best accuracy obtained on MATH-500 when agents have access to previously generated research (green) versus no access (pink). Agents referencing prior research consistently achieve higher performance, indicating the value of cumulative knowledge integration.C.The discovered SDA algorithm generalizes effectively across multiple language models (gpt-4o mini, gpt-4o, DeepSeek v3, Gemini-1.5-Pro, Gemini-2.0-Flash) and across several reasoning benchmarks. SDA (blue) demonstrates higher average accuracy compared to 0-shot prompting (gray).",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2503.18102/extracted/6300559/figures/Untitled-61.png",
                "caption": "Figure 6:Designing Novel Reasoning Techniques on MATH-500 in Parallel.Progression of three autonomous laboratories concurrently (red, blue, and green) compared with non collaborative autonomous laboratories (gray) performing iterative research to improve accuracy on the MATH-500 benchmark, each usinggpt-4o minias the base model. Call-outs indicate the discovery of reasoning techniques that achieve a new highest accuracy on the test set. Laboratories independently develop techniques such as Residual Feedback Prompting (RFP), Adaptive Dynamic Multi-Layer Prompting (ADMPT), and Adaptive Token-Level Gradient Reweighting, collectively raising accuracy from 70.2% (gpt-4o mini zero-shot baseline) to 79.8% (+9.6%). Parallel experimentation, combined with immediate result sharing viaAgentRxiv, accelerates the pace of research progress and achieves higher final accuracy compared to sequential experimentation.",
                "position": 327
            }
        ]
    },
    {
        "header": "4Limitations",
        "images": []
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix AAlgorithms",
        "images": []
    },
    {
        "header": "Appendix BAgent Laboratoryconfiguration",
        "images": []
    },
    {
        "header": "Appendix CPrompts",
        "images": []
    }
]