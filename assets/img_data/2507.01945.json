[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/intro.png",
                "caption": "Figure 1:Comparison with existing paradigm. (a) Existing studies achieve local color consistency by fusing the overlaps of adjacent video segments, suffering low long-term color consistency. (b) Our dynamic global-local paradigm dynamically extracts color features of global historical segments as global memory and the color features of the latest generated segment as local memory, achieving high long-term color consistency. All segments are generated from one same reference image.",
                "position": 80
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/model3.png",
                "caption": "Figure 2:Overview of theLongAnimation. (a) During training, the reference information is fed into the CogvideoX[46]and SketchDiT, respectively, for efficient extraction of hybrid reference features. These reference features are then fused with the historical information in Dynamic Global-Local Memory (DGLM) for consistency generation. (b) For the first segment generation, the reference features are fed into SketchDiT and then directly sent to the video model. (c) For the subsequent segment generation, DGLM dynamically extracts historical features, which are adaptively fused with current reference features from the SketchDiT before being fed into the video model.",
                "position": 132
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/latent_fusion.png",
                "caption": "Figure 3:Overview of color consistency fusion during inference. The dashed latent of the overlap part is finally discarded.",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/example_0.png",
                "caption": "Figure 4:Qualitative comparisonwith existing methods.LongAnimationachieves long-term color consistency through Dynamic Global-Local Memory (e.g., the gril‚Äôs dress and leaves). In contrast, previous methods exhibit unstable color changes. We highly recommend watching the videos in the supplement material for a more direct and clear understanding.",
                "position": 432
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/example_add_back.png",
                "caption": "Figure 5:Text and reference image jointly control background generation, which could not be achieved by previous methods.",
                "position": 471
            },
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/ablation2.png",
                "caption": "Figure 6:Ablation Studiesof modules. Compared to SketchDiT, DGLM markedly enhances color consistency (e.g., the girl‚Äôs hair). CCR further refines color details (e.g., the girl‚Äôs hairband).",
                "position": 480
            },
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/ablation1.png",
                "caption": "Figure 7:Ablation Studiesof timestep on color consistency fusion (CCF). Adopting CCF can keep the consistency of the spliced segments (e.g., white objects in frames 71 and 72). However, using CCF in the early stage of denoising (ts‚Å¢t=50&40subscriptùë°ùë†ùë°5040t_{st}=50\\&40italic_t start_POSTSUBSCRIPT italic_s italic_t end_POSTSUBSCRIPT = 50 & 40) interferes with other features in latent space, which affects the brightness of other frames (e.g., frames 250 and 350). The problem does not occur when CCF is used in the late stage of denoising (ts‚Å¢t=20subscriptùë°ùë†ùë°20t_{st}=20italic_t start_POSTSUBSCRIPT italic_s italic_t end_POSTSUBSCRIPT = 20).",
                "position": 502
            },
            {
                "img": "https://arxiv.org/html/2507.01945/extracted/6590683/images/frequency.png",
                "caption": "Figure 8:(a) PSNR with existing methods.LongAnimationoutperforms previous methods in PSNR metric. (b) PSNR relative decay ratio in the low-frequency domain. Our method exhibits the least attenuation in low-frequency information (e.g., color), indicating that our proposed Dynamic Global-Local Memory can better maintain long-term color consistency. (c) PSNR relative decay ratio in the high-frequency domain. Our method exhibits the least attenuation in high-frequency information (e.g., sketches). Since all methods are controlled by sketches, their attenuation in high frequencies is generally smaller compared to low frequencies.",
                "position": 642
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]