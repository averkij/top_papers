[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13948/x1.png",
                "caption": "(1)",
                "position": 215
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x1.png",
                "caption": "(1)",
                "position": 218
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x2.png",
                "caption": "(2)",
                "position": 223
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Works",
        "images": []
    },
    {
        "header": "3.Motivations and Design Goals",
        "images": []
    },
    {
        "header": "4.POML: Prompt Orchestration Markup Language",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13948/x3.png",
                "caption": "Figure 2.An example illustrating POML’s structured markup and rendering (§4.1).Top:POML source code demonstrating core components: intention components (e.g.,<role>,<task>,<example>), data components (e.g.,<table>,<doc>), and basic structural components (e.g.,<list>,<item>).Bottom:The corresponding rendered output, demonstrating how the structured markup translates into a clear prompt for an LLM. Note the rendering of intention components (e.g.,<role>becomes the title “**Role:**”) and data components (e.g., the first<table>is rendered as Markdown from its CSV source).",
                "position": 521
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x4.png",
                "caption": "Figure 3.Examples of POML data components demonstrating integration of diverse data types (§4.2).(a)<document>rendering selected PDF pages with multimedia;(b)<folder>displaying a filtered directory structure as YAML;(c)<table>extracting and formatting spreadsheet data as CSV;(d)<img>inserting a referenced image with resizing.",
                "position": 580
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x5.png",
                "caption": "Figure 4.Demonstrating POML styling capabilities (§4.3).(a)Default rendering of<example>components.(b)Inlinechatandintroducerattributes on the parent<examples>element modify its presentation (from chat messages to plain text with “**Input**”/“**Output**” captions).(c)A<stylesheet>applies global rules to POML in (a), controlling layout (chat=false), captions/prefixes (caption=\"Q:\"/\"A:\"), and styles (captionStyle=\"plain\"), resulting in customized output.",
                "position": 637
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x6.png",
                "caption": "Figure 5.Example of POML’s templating engine (§4.4): using<let>to load data (fromfiles.json),forattribute to iterate over items,{{ ... }}for variable substitution (e.g.,{{ file.name }}), andif/elseattributes for conditional component rendering based on data values (embedding a<document>only iffile.sizeis below a threshold)",
                "position": 670
            }
        ]
    },
    {
        "header": "5.Development Toolkit",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13948/x7.png",
                "caption": "Figure 6.Real-time diagnostic feedback from the POML toolkit in the IDE.(a)Errors indicated directly in the editor via inline highlighting (e.g., missing attribute).(b)Hovering over an error shows detailed validation messages and documentation.(c)A dedicated panel lists all detected issues (syntax errors, validation problems, file processing issues).",
                "position": 708
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x8.png",
                "caption": "Figure 7.Integrated interactive prompt testing within the POML development environment.(a)Users initiate or abort tests against specific model types (e.g., chat or text-completion) via a context menu directly from the editor.(b)The live preview panel displays the prompt being tested.(c)The output panel shows test progress logs and streams the LLM’s response in real-time.",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x9.png",
                "caption": "Figure 8.Using POML Software Development Kits (SDKs) to integrate into programming workflows.(a)JavaScript/TypeScript SDK example using JSX-like tagged template literals.(b)Python SDK example using a context manager approach.",
                "position": 772
            }
        ]
    },
    {
        "header": "6.Implementation",
        "images": []
    },
    {
        "header": "7.Case Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13948/x10.png",
                "caption": "(1)",
                "position": 835
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x10.png",
                "caption": "(1)",
                "position": 838
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x11.png",
                "caption": "(2)",
                "position": 843
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x12.png",
                "caption": "Figure 10.Visualization of the prompt styling search space explored in our TableQA experiment.\nThe diagram illustrates the dimensions of prompt variation investigated, including overall syntax structure (a), section formatting options (b, d), example presentation styles (c), and table representation alternatives (e).\nSystematically combining these choices resulted in an extensive search space of 74k unique prompt styles.",
                "position": 936
            }
        ]
    },
    {
        "header": "8.User Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13948/x13.png",
                "caption": "Figure 11.Frequency of POML component usage across user study sessions. The chart shows the total count of each component type used by participants. List items (<item>) were most frequently used, followed by captioned paragraphs (<cp>), and the root<poml>tag. Data components (<document>,<table>) and intention components (<task>,<role>) were also commonly used, showing engagement with POML’s data and intention components.",
                "position": 1478
            }
        ]
    },
    {
        "header": "9.Discussion",
        "images": []
    },
    {
        "header": "10.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APOML vs. Other Prompt Markup Languages",
        "images": []
    },
    {
        "header": "Appendix BTemplating Engine Design Details",
        "images": []
    },
    {
        "header": "Appendix CThree-Pass Rendering Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13948/x14.png",
                "caption": "Figure 12.The POML three-pass rendering architecture: (1)-¿(2) The Parser transforms POML markup into React JSX components, (2)-¿(3) React processes these components into a detailed Intermediate Representation (IR) that captures content structure, styling, and metadata, and (3)-¿(4) specialized Writers convert the IR into various output formats such as JSON or Markdown.",
                "position": 4032
            }
        ]
    },
    {
        "header": "Appendix DIntermediate Representation (IR) Specifications",
        "images": []
    },
    {
        "header": "Appendix EDetails of TableQA Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13948/x15.png",
                "caption": "Figure 13.Example of POML usage for the TableQA case study (§7.2, AppendixE). (a) The POML prompt template defining the task instructions, required output format, few-shot examples, and the query structure containing the table and question. (b) The corresponding JSON stylesheet example specifying formatting and presentation rules for elements within the POML prompt, such as overall syntax, caption styles, and introducer text.",
                "position": 4385
            },
            {
                "img": "https://arxiv.org/html/2508.13948/x16.png",
                "caption": "Figure 14.Correlation matrix showing relationships between LLMs based on their performance rankings across 100 prompt styles in the TableQA task (§7.2, AppendixE). Cells show Spearman correlation coefficients between model style rankings (Red: positive/similar preferences; Blue: negative/dissimilar preferences). The diagonal shows the self-correlation score for each model (seeTable 2for definition and values), indicating style ranking stability. The self-correlation score indicates the stability of the style performance ranking. It is computed by randomly splitting the 283 samples into two equal halves, calculating the accuracy of each of the 100 styles on both halves, and finding the Spearman correlation between the two resulting style rankings. This process is repeated 1000 times, and the mean correlation is reported; higher values indicate more stable style rankings across different data subsets.",
                "position": 4663
            }
        ]
    },
    {
        "header": "Appendix FSemi-structured Verbal Interview Questions",
        "images": []
    }
]