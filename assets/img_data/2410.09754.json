[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/x1.png",
                "caption": "Figure 1:Benchmark Summary.(a) Sample Efficiency:SimBa improves sample efficiency across various RL algorithms, including off-policy (SAC, TD-MPC2), on-policy (PPO), and unsupervised RL (METRA).(b) Compute Efficiency:When applying SimBa with SAC, it matches or surpasses state-of-the-art off-policy RL methods across 51 continuous control tasks, by only modifying the network architecture and scaling up the number of network parameters.",
                "position": 127
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/x2.png",
                "caption": "",
                "position": 152
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/x3.png",
                "caption": "Figure 3:SimBa architecture.The network integrates Running Statistics Normalization (RSNorm), residual feedforward blocks, and post-layer normalization to embed simplicity bias into deep RL.",
                "position": 246
            }
        ]
    },
    {
        "header": "4SimBa",
        "images": []
    },
    {
        "header": "5Analyzing SimBa",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/x4.png",
                "caption": "",
                "position": 351
            },
            {
                "img": "https://arxiv.org/html/2410.09754/x5.png",
                "caption": "",
                "position": 382
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/x6.png",
                "caption": "Figure 6:Environment Visualizations.SimBa is evaluated across four diverse benchmark environments: DMC, MyoSuite, and HumanoidBench, which feature complex locomotion and manipulation tasks, and Craftax, which introduces open-ended tasks with varying complexity.",
                "position": 397
            },
            {
                "img": "https://arxiv.org/html/2410.09754/x7.png",
                "caption": "",
                "position": 420
            },
            {
                "img": "https://arxiv.org/html/2410.09754/x8.png",
                "caption": "Figure 8:Off-policy RL Benchmark.Average episode return for DMC and HumanoidBench and average success rate for MyoSuite across 51 continuous control tasks. SimBa (with SAC) achieves high computational efficiency by only changing the network architecture.",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2410.09754/x9.png",
                "caption": "Figure 9:Impact of Input Dimension.Average episode return for DMC tasks plotted against increasing state dimensions. Results show that the benefits of using SimBa increase with higher input dimensions, effectively alleviating the curse of dimensionality.",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2410.09754/extracted/5922698/figures/sec5_ppo_sample_curve.png",
                "caption": "Figure 10:On-policy RL with SimBa.Average return of achievements and task success rate for three different tasks comparing PPO + SimBa and PPO on Craftax. Integrating SimBa enables effective learning of complex behaviors.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2410.09754/x10.png",
                "caption": "",
                "position": 477
            }
        ]
    },
    {
        "header": "7Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/x11.png",
                "caption": "",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2410.09754/x12.png",
                "caption": "",
                "position": 525
            },
            {
                "img": "https://arxiv.org/html/2410.09754/x13.png",
                "caption": "",
                "position": 553
            }
        ]
    },
    {
        "header": "8Lessons and Opportunities",
        "images": []
    },
    {
        "header": "Reproducibility",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADefinition of Simplicity Bias",
        "images": []
    },
    {
        "header": "Appendix BMeasuring Simplicity Bias",
        "images": []
    },
    {
        "header": "Appendix CPlasticity Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/extracted/5922698/figures/appendix_aggregate_dmchard_various_metrics.png",
                "caption": "Figure 15:Plasticity Metrics Comparison.Average episode return for the DMC-Hard environment. Metrics compared include dormant ratio, s-rank, and feature norm. Higher dormant ratio and feature norm, along with lower s-rank, indicate a greater loss of plasticity.",
                "position": 1709
            }
        ]
    },
    {
        "header": "Appendix DComparison to Existing Architectures",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/x14.png",
                "caption": "Figure 16:Architecture Comparison.Illustration of SimBa, BroNet, and SpectralNet.",
                "position": 1726
            }
        ]
    },
    {
        "header": "Appendix EComputational Resources",
        "images": []
    },
    {
        "header": "Appendix FEnvironment Details",
        "images": []
    },
    {
        "header": "Appendix GHyperparameters",
        "images": []
    },
    {
        "header": "Appendix HLearning Curve",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.09754/extracted/5922698/figures/appendix_dmc_easy_medium_per_env_sample_curve.png",
                "caption": "Figure 17:Per task learning curve for DMC Easy&Medium.Mean and 95% CI over 10 seeds for SimBa and BRO, 5 seeds for TD7 and SAC, 3 seeds for TD-MPC2 and DreamerV3.",
                "position": 2505
            },
            {
                "img": "https://arxiv.org/html/2410.09754/extracted/5922698/figures/appendix_dmc_hard_per_env_sample_curve.png",
                "caption": "Figure 18:Per task learning curve for DMC Hard.Mean and 95% CI over 10 seeds for SimBa and BRO, 5 seeds for TD7 and SAC, 3 seeds for TD-MPC2 and DreamerV3.",
                "position": 2508
            },
            {
                "img": "https://arxiv.org/html/2410.09754/extracted/5922698/figures/appendix_myo_per_env_sample_curve.png",
                "caption": "Figure 19:Per task learning curve for MyoSuite.Mean and 95% CI over 10 seeds for SimBa and BRO, 5 seeds for TD7 and SAC, 3 seeds for TD-MPC2 and DreamerV3.",
                "position": 2511
            },
            {
                "img": "https://arxiv.org/html/2410.09754/extracted/5922698/figures/appendix_hb_per_env_sample_curve.png",
                "caption": "Figure 20:Per task learning curve for HumanoidBench.Mean and 95% CI over 10 seeds for SimBa, 5 seeds for BRO, TD7, and SAC, 3 seeds for TD-MPC2 and DreamerV3. We no",
                "position": 2514
            },
            {
                "img": "https://arxiv.org/html/2410.09754/extracted/5922698/figures/appendix_Craftax_per_env_sample_curve.png",
                "caption": "Figure 21:Per task learning curve for Craftax.We visualize the success rate learning curve for 66 tasks in Craftax. Mean and 95% CI over 5 seeds for PPO + SimBa and PPO.",
                "position": 2517
            }
        ]
    },
    {
        "header": "Appendix IFull Result",
        "images": []
    }
]