[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10594/x1.png",
                "caption": "Figure 1:TextRAG vs. VisRAG on final generation accuracy. In TextRAG, parsed text serves as the basis for both retrieval and generation processes. In contrast, VisRAG leverages the original document image directly by using a VLM-based retriever and generator.\nDetails can be found in Sec.5.1.",
                "position": 175
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10594/extracted/5925691/Figures/main_figure.png",
                "caption": "Figure 2:TextRAG (left) vs. VisRAG (right).\nTraditional text-based RAG (TextRAG) relies on parsed texts for retrieval and generation, losing visual information in multi-modal documents.\nOur vision-based RAG (VisRAG) employs a VLM-based retriever and generator to directly process the document page’s image, thereby preserving all information in the original page.",
                "position": 256
            }
        ]
    },
    {
        "header": "4Experimental Methodology",
        "images": []
    },
    {
        "header": "5Evaluation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10594/x2.png",
                "caption": "(a)TextRAG with MiniCPM (OCR) as the retriever and MiniCPM-V 2.6 (OCR) as the generator.",
                "position": 1728
            },
            {
                "img": "https://arxiv.org/html/2410.10594/x2.png",
                "caption": "(a)TextRAG with MiniCPM (OCR) as the retriever and MiniCPM-V 2.6 (OCR) as the generator.",
                "position": 1731
            },
            {
                "img": "https://arxiv.org/html/2410.10594/x3.png",
                "caption": "(b)VisRAG with VisRAG-Ret as the retriever and MiniCPM-V 2.6 as the generator.",
                "position": 1736
            },
            {
                "img": "https://arxiv.org/html/2410.10594/x4.png",
                "caption": "Figure 4:Average retrieval performance of VisRAG-Ret vs. MiniCPM (OCR) trained with different numbers of training examples.",
                "position": 1751
            },
            {
                "img": "https://arxiv.org/html/2410.10594/x5.png",
                "caption": "Figure 5:Relative retrieval and generation performance of VisRAG, VisRAG (SigLIP), and TextRAG on different subsets of queries.\nThe X-axes represent the query subsets where the lengths of the positive documents fall within specific percentile ranges.\nFor comparative analysis, we set TextRAG’s performance to zero and show the performance differences of other models from TextRAG.",
                "position": 1778
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AData Construction Details",
        "images": []
    },
    {
        "header": "Appendix BDocument Parsing",
        "images": []
    },
    {
        "header": "Appendix CModels Used in this Paper",
        "images": []
    },
    {
        "header": "Appendix DAdditional Results",
        "images": []
    },
    {
        "header": "Appendix EPrompts for Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10594/extracted/5925691/Case_Study/1/wrong_doc.png",
                "caption": "Table 8:Case study from DocVQA. In this case, VisRAG successfully retrieves the ground-truth document, while TextRAG fails, leading to VisRAG’s correct generation and TextRAG’s incorrect generation.",
                "position": 3488
            },
            {
                "img": "https://arxiv.org/html/2410.10594/extracted/5925691/Case_Study/1/correct_doc.png",
                "caption": "",
                "position": 3533
            },
            {
                "img": "https://arxiv.org/html/2410.10594/extracted/5925691/Case_Study/2/correct_doc.png",
                "caption": "Table 9:Case study from InfographicsVQA. In this case, both VisRAG and TextRAG successfully retrieve the correct document; however, only VisRAG effectively leverages the layout information, enabling accurate generation. In contrast, TextRAG suffers from information loss of the layout, resulting in incorrect responses.",
                "position": 3589
            }
        ]
    },
    {
        "header": "Appendix FCase Study",
        "images": []
    }
]