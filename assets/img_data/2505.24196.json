[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24196/x1.png",
                "caption": "Figure 1:Previous Self-SD method vs. CLaSp. Compared to the previous Self-SD method, which requires costly Bayesian optimization on training dataset to select afixedset of skipped layers, CLaSp employs adynamiclayer-skipping strategy that adjusts in real-time based on context.",
                "position": 119
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24196/x2.png",
                "caption": "Figure 2:The overall framework of CLaSp consists of three stages: (1) Draft, (2) Verify, (3) Layer Optimization. After the Verify stage, CLaSp uses the information obtained to perform Layer Optimization, resulting in a new optimal layer skipping setùíÆ‚àósuperscriptùíÆ\\mathcal{S}^{*}caligraphic_S start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT. This set guides the next Draft round, repeating the entire process.",
                "position": 310
            }
        ]
    },
    {
        "header": "3CLaSp",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24196/x3.png",
                "caption": "Figure 3:(a)Sparse Persistence Observation: Skipped layer sets selected for adjacent tokens exhibit high similarity, with this similarity gradually decreasing as the token gap increases. This observation enables layer optimization on the current token to guide subsequent drafting processes.\n(b)Approximate Markov Property: Cosine similarity comparisons of hidden states obtained using Brute Force, Random, and CLaSp‚Äôs dynamic programming configurations against the full forward pass demonstrate the approximate Markov property inherent to CLaSp.\n(c)Efficiency Optimization Strategies: Latency breakdown per query shows that Layer Optimization introduces only 4.8% additional delay, underscoring its negligible impact on overall latency.",
                "position": 380
            },
            {
                "img": "https://arxiv.org/html/2505.24196/x4.png",
                "caption": "(a)",
                "position": 1088
            },
            {
                "img": "https://arxiv.org/html/2505.24196/x4.png",
                "caption": "(a)",
                "position": 1091
            },
            {
                "img": "https://arxiv.org/html/2505.24196/x5.png",
                "caption": "(b)",
                "position": 1096
            },
            {
                "img": "https://arxiv.org/html/2505.24196/x6.png",
                "caption": "(c)",
                "position": 1101
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24196/x7.png",
                "caption": "Figure 5:Model Size Scaling Laws of CLaSp.",
                "position": 1176
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]